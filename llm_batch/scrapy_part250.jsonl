{"custom_id": "scrapy#1bb6c4154c43d03d00147d810147c4f3c807505e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 172 | Contributors (this commit): 11 | Commits (past 90d): 2 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -149,10 +149,6 @@ class S3FeedStorage(BlockingFeedStorage):\n \n class GCSFeedStorage(BlockingFeedStorage):\n \n-    project_id = None\n-    bucket_name = None\n-    blob_name = None\n-\n     def __init__(self, uri, project_id):\n         self.project_id = project_id\n         u = urlparse(uri)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#fc6809b024dc25663432b6c0c5780021a827ea20", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 537 | Contributors (this commit): 42 | Commits (past 90d): 1 | Contributors (cumulative): 42 | DMM Complexity: None\n\nDIFF:\n@@ -145,6 +145,7 @@ FEED_STORAGES_BASE = {\n     'stdout': 'scrapy.extensions.feedexport.StdoutFeedStorage',\n     's3': 'scrapy.extensions.feedexport.S3FeedStorage',\n     'ftp': 'scrapy.extensions.feedexport.FTPFeedStorage',\n+    'gcs': 'scrapy.extensions.feedexport.GCSFeedStorage',\n }\n FEED_EXPORTERS = {}\n FEED_EXPORTERS_BASE = {\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#4a53de165a53433a9a2a8cc4db34e5507c47fbd5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 714 | Contributors (this commit): 44 | Commits (past 90d): 5 | Contributors (cumulative): 53 | DMM Complexity: None\n\nDIFF:\n@@ -146,7 +146,6 @@ class S3FeedStorage(BlockingFeedStorage):\n             key.close()\n \n \n-\n class GCSFeedStorage(BlockingFeedStorage):\n \n     def __init__(self, uri, project_id):\n\n@@ -142,10 +142,10 @@ FEED_STORAGES = {}\n FEED_STORAGES_BASE = {\n     '': 'scrapy.extensions.feedexport.FileFeedStorage',\n     'file': 'scrapy.extensions.feedexport.FileFeedStorage',\n-    'stdout': 'scrapy.extensions.feedexport.StdoutFeedStorage',\n-    's3': 'scrapy.extensions.feedexport.S3FeedStorage',\n     'ftp': 'scrapy.extensions.feedexport.FTPFeedStorage',\n     'gcs': 'scrapy.extensions.feedexport.GCSFeedStorage',\n+    's3': 'scrapy.extensions.feedexport.S3FeedStorage',\n+    'stdout': 'scrapy.extensions.feedexport.StdoutFeedStorage',\n }\n FEED_EXPORTERS = {}\n FEED_EXPORTERS_BASE = {\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#2bbbd02bda368c2f052f3aa38f99498a632328bb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 7 | Files Changed: 3 | Hunks: 11 | Methods Changed: 6 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 23 | Churn Cumulative: 1523 | Contributors (this commit): 46 | Commits (past 90d): 10 | Contributors (cumulative): 65 | DMM Complexity: 1.0\n\nDIFF:\n@@ -148,15 +148,20 @@ class S3FeedStorage(BlockingFeedStorage):\n \n class GCSFeedStorage(BlockingFeedStorage):\n \n-    def __init__(self, uri, project_id):\n+    def __init__(self, uri, project_id, acl):\n         self.project_id = project_id\n+        self.acl = acl\n         u = urlparse(uri)\n         self.bucket_name = u.hostname\n         self.blob_name = u.path[1:]  # remove first \"/\"\n \n     @classmethod\n     def from_crawler(cls, crawler, uri):\n-        return cls(uri, crawler.settings['GCS_PROJECT_ID'])\n+        return cls(\n+            uri,\n+            crawler.settings['GCS_PROJECT_ID'],\n+            crawler.settings['FEED_STORAGE_GCS_ACL']\n+        )\n \n     def _store_in_thread(self, file):\n         file.seek(0)\n@@ -164,7 +169,7 @@ class GCSFeedStorage(BlockingFeedStorage):\n         client = Client(project=self.project_id)\n         bucket = client.get_bucket(self.bucket_name)\n         blob = bucket.blob(self.blob_name)\n-        blob.upload_from_file(file)\n+        blob.upload_from_file(file, predefined_acl=self.acl)\n \n \n class FTPFeedStorage(BlockingFeedStorage):\n\n@@ -159,6 +159,8 @@ FEED_EXPORTERS_BASE = {\n }\n FEED_EXPORT_INDENT = 0\n \n+FEED_STORAGE_GCS_ACL = None\n+\n FILES_STORE_S3_ACL = 'private'\n FILES_STORE_GCS_ACL = ''\n \n\n@@ -191,17 +191,18 @@ class S3FeedStorageTest(unittest.TestCase):\n class GCSFeedStorageTest(unittest.TestCase):\n \n     @mock.patch('scrapy.conf.settings',\n-                new={'GCS_PROJECT_ID': 'conf_id' }, create=True)\n+                new={'GCS_PROJECT_ID': 'conf_id', 'FEED_STORAGE_GCS_ACL': None }, create=True)\n     def test_parse_settings(self):\n         try:\n             from google.cloud.storage import Client\n         except ImportError:\n             raise unittest.SkipTest(\"GCSFeedStorage requires google-cloud-storage\")\n \n-        settings = {'GCS_PROJECT_ID': '123' }\n+        settings = {'GCS_PROJECT_ID': '123', 'FEED_STORAGE_GCS_ACL': 'publicRead' }\n         crawler = get_crawler(settings_dict=settings)\n         storage = GCSFeedStorage.from_crawler(crawler, 'gcs://mybucket/export.csv')\n         assert storage.project_id == '123'\n+        assert storage.acl == 'publicRead'\n         assert storage.bucket_name == 'mybucket'\n         assert storage.blob_name == 'export.csv'\n \n@@ -214,19 +215,20 @@ class GCSFeedStorageTest(unittest.TestCase):\n \n         uri = 'gcs://mybucket/export.csv'\n         project_id = 'myproject-123'\n+        acl = 'publicRead'\n         (client_mock, bucket_mock, blob_mock) = mock_google_cloud_storage()\n         with mock.patch('google.cloud.storage.Client') as m:    \n             m.return_value = client_mock\n \n             f = mock.Mock()\n-            storage = GCSFeedStorage(uri, project_id)\n+            storage = GCSFeedStorage(uri, project_id, acl)\n             yield storage.store(f)\n \n             f.seek.assert_called_once_with(0)\n             m.assert_called_once_with(project=project_id)\n             client_mock.get_bucket.assert_called_once_with('mybucket')\n             bucket_mock.blob.assert_called_once_with('export.csv')\n-            blob_mock.upload_from_file.assert_called_once_with(f)\n+            blob_mock.upload_from_file.assert_called_once_with(f, predefined_acl=acl)\n \n class StdoutFeedStorageTest(unittest.TestCase):\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#cb5f800b0f7029d2bf2e09e9bc1391078c133a92", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 545 | Contributors (this commit): 42 | Commits (past 90d): 4 | Contributors (cumulative): 42 | DMM Complexity: None\n\nDIFF:\n@@ -168,6 +168,8 @@ FTP_USER = 'anonymous'\n FTP_PASSWORD = 'guest'\n FTP_PASSIVE_MODE = True\n \n+GCS_PROJECT_ID = None\n+\n HTTPCACHE_ENABLED = False\n HTTPCACHE_DIR = 'httpcache'\n HTTPCACHE_IGNORE_MISSING = False\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#013568097db04396d780d1c91d37027115af7fe2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): -3/0 | Churn Δ: 6 | Churn Cumulative: 190 | Contributors (this commit): 12 | Commits (past 90d): 5 | Contributors (cumulative): 12 | DMM Complexity: 0.5\n\nDIFF:\n@@ -118,6 +118,7 @@ class S3FeedStorage(BlockingFeedStorage):\n         self.secret_key = u.password or secret_key\n         self.is_botocore = is_botocore()\n         self.keyname = u.path[1:]  # remove first \"/\"\n+        self.policy = settings.get('FEED_STORAGE_S3_ACL', 'private')\n         if self.is_botocore:\n             import botocore.session\n             session = botocore.session.get_session()\n@@ -137,12 +138,13 @@ class S3FeedStorage(BlockingFeedStorage):\n         file.seek(0)\n         if self.is_botocore:\n             self.s3_client.put_object(\n-                Bucket=self.bucketname, Key=self.keyname, Body=file)\n+                Bucket=self.bucketname, Key=self.keyname, Body=file,\n+                ACL=self.policy)\n         else:\n             conn = self.connect_s3(self.access_key, self.secret_key)\n             bucket = conn.get_bucket(self.bucketname, validate=False)\n             key = bucket.new_key(self.keyname)\n-            key.set_contents_from_file(file)\n+            key.set_contents_from_file(file, policy=self.policy)\n             key.close()\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#ad83ffdf1f4d69ffb62b243429e7b59d0930524c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 98 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 8 | Methods Changed: 10 | Complexity Δ (Sum/Max): 4/2 | Churn Δ: 103 | Churn Cumulative: 1089 | Contributors (this commit): 15 | Commits (past 90d): 10 | Contributors (cumulative): 25 | DMM Complexity: 1.0\n\nDIFF:\n@@ -93,7 +93,7 @@ class FileFeedStorage(object):\n \n class S3FeedStorage(BlockingFeedStorage):\n \n-    def __init__(self, uri, access_key=None, secret_key=None):\n+    def __init__(self, uri, access_key=None, secret_key=None, acl=None):\n         # BEGIN Backwards compatibility for initialising without keys (and\n         # without using from_crawler)\n         no_defaults = access_key is None and secret_key is None\n@@ -118,7 +118,7 @@ class S3FeedStorage(BlockingFeedStorage):\n         self.secret_key = u.password or secret_key\n         self.is_botocore = is_botocore()\n         self.keyname = u.path[1:]  # remove first \"/\"\n-        self.policy = settings.get('FEED_STORAGE_S3_ACL', 'private')\n+        self.acl = acl\n         if self.is_botocore:\n             import botocore.session\n             session = botocore.session.get_session()\n@@ -132,19 +132,28 @@ class S3FeedStorage(BlockingFeedStorage):\n     @classmethod\n     def from_crawler(cls, crawler, uri):\n         return cls(uri, crawler.settings['AWS_ACCESS_KEY_ID'],\n-                   crawler.settings['AWS_SECRET_ACCESS_KEY'])\n+                   crawler.settings['AWS_SECRET_ACCESS_KEY'],\n+                   crawler.settings.get('FEED_STORAGE_S3_ACL'))\n \n     def _store_in_thread(self, file):\n         file.seek(0)\n         if self.is_botocore:\n+            kwargs = dict()\n+            if self.acl:\n+                kwargs.update(dict(ACL=self.acl))\n+\n             self.s3_client.put_object(\n                 Bucket=self.bucketname, Key=self.keyname, Body=file,\n-                ACL=self.policy)\n+                **kwargs)\n         else:\n             conn = self.connect_s3(self.access_key, self.secret_key)\n             bucket = conn.get_bucket(self.bucketname, validate=False)\n             key = bucket.new_key(self.keyname)\n-            key.set_contents_from_file(file, policy=self.policy)\n+            kwargs = dict()\n+            if self.acl:\n+                kwargs.update(dict(policy=self.acl))\n+\n+            key.set_contents_from_file(file, **kwargs)\n             key.close()\n \n \n\n@@ -18,6 +18,7 @@ from tests import mock\n from tests.mockserver import MockServer\n from w3lib.url import path_to_file_uri\n \n+import botocore.client\n import scrapy\n from scrapy.exporters import CsvItemExporter\n from scrapy.extensions.feedexport import (\n@@ -186,6 +187,89 @@ class S3FeedStorageTest(unittest.TestCase):\n         content = get_s3_content_and_delete(u.hostname, u.path[1:])\n         self.assertEqual(content, expected_content)\n \n+    def test_init_without_acl(self):\n+        storage = S3FeedStorage(\n+            's3://mybucket/export.csv',\n+            'access_key',\n+            'secret_key'\n+        )\n+        self.assertEqual(storage.access_key, 'access_key')\n+        self.assertEqual(storage.secret_key, 'secret_key')\n+        self.assertEqual(storage.acl, None)\n+\n+    def test_init_with_acl(self):\n+        storage = S3FeedStorage(\n+            's3://mybucket/export.csv',\n+            'access_key',\n+            'secret_key',\n+            'custom-acl'\n+        )\n+        self.assertEqual(storage.access_key, 'access_key')\n+        self.assertEqual(storage.secret_key, 'secret_key')\n+        self.assertEqual(storage.acl, 'custom-acl')\n+\n+    def test_from_crawler_without_acl(self):\n+        settings = {\n+            'AWS_ACCESS_KEY_ID': 'access_key',\n+            'AWS_SECRET_ACCESS_KEY': 'secret_key',\n+        }\n+        crawler = get_crawler(settings_dict=settings)\n+        storage = S3FeedStorage.from_crawler(\n+            crawler,\n+            's3://mybucket/export.csv'\n+        )\n+        self.assertEqual(storage.access_key, 'access_key')\n+        self.assertEqual(storage.secret_key, 'secret_key')\n+        self.assertEqual(storage.acl, None)\n+\n+    def test_from_crawler_with_acl(self):\n+        settings = {\n+            'AWS_ACCESS_KEY_ID': 'access_key',\n+            'AWS_SECRET_ACCESS_KEY': 'secret_key',\n+            'FEED_STORAGE_S3_ACL': 'custom-acl',\n+        }\n+        crawler = get_crawler(settings_dict=settings)\n+        storage = S3FeedStorage.from_crawler(\n+            crawler,\n+            's3://mybucket/export.csv'\n+        )\n+        self.assertEqual(storage.access_key, 'access_key')\n+        self.assertEqual(storage.secret_key, 'secret_key')\n+        self.assertEqual(storage.acl, 'custom-acl')\n+\n+    def test_store_in_thread_without_acl(self):\n+        storage = S3FeedStorage(\n+            's3://mybucket/export.csv',\n+            'access_key',\n+            'secret_key',\n+        )\n+        self.assertEqual(storage.access_key, 'access_key')\n+        self.assertEqual(storage.secret_key, 'secret_key')\n+        self.assertEqual(storage.acl, None)\n+\n+        with mock.patch('botocore.client.BaseClient._make_api_call') as _make_api_call_mock:\n+            storage._store_in_thread(BytesIO(b'test file'))\n+            operation_name, api_params = _make_api_call_mock.call_args[0]\n+            self.assertEqual(operation_name, 'PutObject')\n+            self.assertNotIn('ACL', api_params)\n+\n+    def test_store_in_thread_with_acl(self):\n+        storage = S3FeedStorage(\n+            's3://mybucket/export.csv',\n+            'access_key',\n+            'secret_key',\n+            'custom-acl'\n+        )\n+        self.assertEqual(storage.access_key, 'access_key')\n+        self.assertEqual(storage.secret_key, 'secret_key')\n+        self.assertEqual(storage.acl, 'custom-acl')\n+\n+        with mock.patch('botocore.client.BaseClient._make_api_call') as _make_api_call_mock:\n+            storage._store_in_thread(BytesIO(b'test file'))\n+            operation_name, api_params = _make_api_call_mock.call_args[0]\n+            self.assertEqual(operation_name, 'PutObject')\n+            self.assertEqual(api_params.get('ACL'), 'custom-acl')\n+\n \n class StdoutFeedStorageTest(unittest.TestCase):\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#126207fb7bca21d3d95ed9c66028e82771180370", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 888 | Contributors (this commit): 13 | Commits (past 90d): 5 | Contributors (cumulative): 13 | DMM Complexity: None\n\nDIFF:\n@@ -247,9 +247,9 @@ class S3FeedStorageTest(unittest.TestCase):\n         self.assertEqual(storage.secret_key, 'secret_key')\n         self.assertEqual(storage.acl, None)\n \n-        with mock.patch('botocore.client.BaseClient._make_api_call') as _make_api_call_mock:\n+        with mock.patch('botocore.client.BaseClient._make_api_call') as m:\n             storage._store_in_thread(BytesIO(b'test file'))\n-            operation_name, api_params = _make_api_call_mock.call_args[0]\n+            operation_name, api_params = m.call_args[0]\n             self.assertEqual(operation_name, 'PutObject')\n             self.assertNotIn('ACL', api_params)\n \n@@ -264,9 +264,9 @@ class S3FeedStorageTest(unittest.TestCase):\n         self.assertEqual(storage.secret_key, 'secret_key')\n         self.assertEqual(storage.acl, 'custom-acl')\n \n-        with mock.patch('botocore.client.BaseClient._make_api_call') as _make_api_call_mock:\n+        with mock.patch('botocore.client.BaseClient._make_api_call') as m:\n             storage._store_in_thread(BytesIO(b'test file'))\n-            operation_name, api_params = _make_api_call_mock.call_args[0]\n+            operation_name, api_params = m.call_args[0]\n             self.assertEqual(operation_name, 'PutObject')\n             self.assertEqual(api_params.get('ACL'), 'custom-acl')\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#079af889e7d010a79640e6874c3e6dc394b936ae", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 51 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 3 | Methods Changed: 6 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 53 | Churn Cumulative: 941 | Contributors (this commit): 13 | Commits (past 90d): 6 | Contributors (cumulative): 13 | DMM Complexity: 1.0\n\nDIFF:\n@@ -237,7 +237,7 @@ class S3FeedStorageTest(unittest.TestCase):\n         self.assertEqual(storage.secret_key, 'secret_key')\n         self.assertEqual(storage.acl, 'custom-acl')\n \n-    def test_store_in_thread_without_acl(self):\n+    def test_store_in_thread_botocore_without_acl(self):\n         storage = S3FeedStorage(\n             's3://mybucket/export.csv',\n             'access_key',\n@@ -253,7 +253,7 @@ class S3FeedStorageTest(unittest.TestCase):\n             self.assertEqual(operation_name, 'PutObject')\n             self.assertNotIn('ACL', api_params)\n \n-    def test_store_in_thread_with_acl(self):\n+    def test_store_in_thread_botocore_with_acl(self):\n         storage = S3FeedStorage(\n             's3://mybucket/export.csv',\n             'access_key',\n@@ -270,6 +270,55 @@ class S3FeedStorageTest(unittest.TestCase):\n             self.assertEqual(operation_name, 'PutObject')\n             self.assertEqual(api_params.get('ACL'), 'custom-acl')\n \n+    def test_store_in_thread_not_botocore_without_acl(self):\n+        storage = S3FeedStorage(\n+            's3://mybucket/export.csv',\n+            'access_key',\n+            'secret_key',\n+        )\n+        self.assertEqual(storage.access_key, 'access_key')\n+        self.assertEqual(storage.secret_key, 'secret_key')\n+        self.assertEqual(storage.acl, None)\n+\n+        storage.is_botocore = False\n+        storage.connect_s3 = mock.MagicMock()\n+        self.assertFalse(storage.is_botocore)\n+\n+        storage._store_in_thread(BytesIO(b'test file'))\n+\n+        conn = storage.connect_s3(*storage.connect_s3.call_args)\n+        bucket = conn.get_bucket(*conn.get_bucket.call_args)\n+        key = bucket.new_key(*bucket.new_key.call_args)\n+        self.assertNotIn(\n+            dict(policy='custom-acl'),\n+            key.set_contents_from_file.call_args\n+        )\n+\n+    def test_store_in_thread_not_botocore_with_acl(self):\n+        storage = S3FeedStorage(\n+            's3://mybucket/export.csv',\n+            'access_key',\n+            'secret_key',\n+            'custom-acl'\n+        )\n+        self.assertEqual(storage.access_key, 'access_key')\n+        self.assertEqual(storage.secret_key, 'secret_key')\n+        self.assertEqual(storage.acl, 'custom-acl')\n+\n+        storage.is_botocore = False\n+        storage.connect_s3 = mock.MagicMock()\n+        self.assertFalse(storage.is_botocore)\n+\n+        storage._store_in_thread(BytesIO(b'test file'))\n+\n+        conn = storage.connect_s3(*storage.connect_s3.call_args)\n+        bucket = conn.get_bucket(*conn.get_bucket.call_args)\n+        key = bucket.new_key(*bucket.new_key.call_args)\n+        self.assertIn(\n+            dict(policy='custom-acl'),\n+            key.set_contents_from_file.call_args\n+        )\n+\n \n class StdoutFeedStorageTest(unittest.TestCase):\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#ceae356e62dc2e56465a58b3d9fe00813e289dd6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 547 | Contributors (this commit): 43 | Commits (past 90d): 5 | Contributors (cumulative): 43 | DMM Complexity: None\n\nDIFF:\n@@ -158,6 +158,8 @@ FEED_EXPORTERS_BASE = {\n }\n FEED_EXPORT_INDENT = 0\n \n+FEED_STORAGE_S3_ACL = None\n+\n FILES_STORE_S3_ACL = 'private'\n FILES_STORE_GCS_ACL = ''\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#cfd183a9d19563f09487af942c9a635d665a1905", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 211 | Contributors (this commit): 12 | Commits (past 90d): 7 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -133,7 +133,7 @@ class S3FeedStorage(BlockingFeedStorage):\n     def from_crawler(cls, crawler, uri):\n         return cls(uri, crawler.settings['AWS_ACCESS_KEY_ID'],\n                    crawler.settings['AWS_SECRET_ACCESS_KEY'],\n-                   crawler.settings.get('FEED_STORAGE_S3_ACL'))\n+                   crawler.settings['FEED_STORAGE_S3_ACL'])\n \n     def _store_in_thread(self, file):\n         file.seek(0)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#f824f5b2d17b082dac04505ba27afdfa869a11c7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 28 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 10 | Methods Changed: 12 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 36 | Churn Cumulative: 977 | Contributors (this commit): 13 | Commits (past 90d): 7 | Contributors (cumulative): 13 | DMM Complexity: 1.0\n\nDIFF:\n@@ -237,7 +237,7 @@ class S3FeedStorageTest(unittest.TestCase):\n         self.assertEqual(storage.secret_key, 'secret_key')\n         self.assertEqual(storage.acl, 'custom-acl')\n \n-    def test_store_in_thread_botocore_without_acl(self):\n+    def test_store_botocore_without_acl(self):\n         storage = S3FeedStorage(\n             's3://mybucket/export.csv',\n             'access_key',\n@@ -247,13 +247,19 @@ class S3FeedStorageTest(unittest.TestCase):\n         self.assertEqual(storage.secret_key, 'secret_key')\n         self.assertEqual(storage.acl, None)\n \n+        def _defer(f, *args, **kwargs):\n+            return f(*args, **kwargs)\n+\n         with mock.patch('botocore.client.BaseClient._make_api_call') as m:\n-            storage._store_in_thread(BytesIO(b'test file'))\n+            with mock.patch('twisted.internet.threads.deferToThread',\n+                            new=_defer):\n+                storage.store(BytesIO(b'test file'))\n+\n             operation_name, api_params = m.call_args[0]\n             self.assertEqual(operation_name, 'PutObject')\n             self.assertNotIn('ACL', api_params)\n \n-    def test_store_in_thread_botocore_with_acl(self):\n+    def test_store_botocore_with_acl(self):\n         storage = S3FeedStorage(\n             's3://mybucket/export.csv',\n             'access_key',\n@@ -264,13 +270,19 @@ class S3FeedStorageTest(unittest.TestCase):\n         self.assertEqual(storage.secret_key, 'secret_key')\n         self.assertEqual(storage.acl, 'custom-acl')\n \n+        def _defer(f, *args, **kwargs):\n+            return f(*args, **kwargs)\n+\n         with mock.patch('botocore.client.BaseClient._make_api_call') as m:\n-            storage._store_in_thread(BytesIO(b'test file'))\n+            with mock.patch('twisted.internet.threads.deferToThread',\n+                            new=_defer):\n+                storage.store(BytesIO(b'test file'))\n+\n             operation_name, api_params = m.call_args[0]\n             self.assertEqual(operation_name, 'PutObject')\n             self.assertEqual(api_params.get('ACL'), 'custom-acl')\n \n-    def test_store_in_thread_not_botocore_without_acl(self):\n+    def test_store_not_botocore_without_acl(self):\n         storage = S3FeedStorage(\n             's3://mybucket/export.csv',\n             'access_key',\n@@ -284,7 +296,11 @@ class S3FeedStorageTest(unittest.TestCase):\n         storage.connect_s3 = mock.MagicMock()\n         self.assertFalse(storage.is_botocore)\n \n-        storage._store_in_thread(BytesIO(b'test file'))\n+        def _defer(f, *args, **kwargs):\n+            return f(*args, **kwargs)\n+\n+        with mock.patch('twisted.internet.threads.deferToThread', new=_defer):\n+            storage.store(BytesIO(b'test file'))\n \n         conn = storage.connect_s3(*storage.connect_s3.call_args)\n         bucket = conn.get_bucket(*conn.get_bucket.call_args)\n@@ -294,7 +310,7 @@ class S3FeedStorageTest(unittest.TestCase):\n             key.set_contents_from_file.call_args\n         )\n \n-    def test_store_in_thread_not_botocore_with_acl(self):\n+    def test_store_not_botocore_with_acl(self):\n         storage = S3FeedStorage(\n             's3://mybucket/export.csv',\n             'access_key',\n@@ -309,7 +325,11 @@ class S3FeedStorageTest(unittest.TestCase):\n         storage.connect_s3 = mock.MagicMock()\n         self.assertFalse(storage.is_botocore)\n \n-        storage._store_in_thread(BytesIO(b'test file'))\n+        def _defer(f, *args, **kwargs):\n+            return f(*args, **kwargs)\n+\n+        with mock.patch('twisted.internet.threads.deferToThread', new=_defer):\n+            storage.store(BytesIO(b'test file'))\n \n         conn = storage.connect_s3(*storage.connect_s3.call_args)\n         bucket = conn.get_bucket(*conn.get_bucket.call_args)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#1eac2a163c2c734594d4f1e7e026eab309b2b0b5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 22 | Files Changed: 1 | Hunks: 10 | Methods Changed: 8 | Complexity Δ (Sum/Max): -4/0 | Churn Δ: 30 | Churn Cumulative: 1007 | Contributors (this commit): 13 | Commits (past 90d): 8 | Contributors (cumulative): 13 | DMM Complexity: 0.0\n\nDIFF:\n@@ -237,6 +237,7 @@ class S3FeedStorageTest(unittest.TestCase):\n         self.assertEqual(storage.secret_key, 'secret_key')\n         self.assertEqual(storage.acl, 'custom-acl')\n \n+    @defer.inlineCallbacks\n     def test_store_botocore_without_acl(self):\n         storage = S3FeedStorage(\n             's3://mybucket/export.csv',\n@@ -247,18 +248,14 @@ class S3FeedStorageTest(unittest.TestCase):\n         self.assertEqual(storage.secret_key, 'secret_key')\n         self.assertEqual(storage.acl, None)\n \n-        def _defer(f, *args, **kwargs):\n-            return f(*args, **kwargs)\n-\n         with mock.patch('botocore.client.BaseClient._make_api_call') as m:\n-            with mock.patch('twisted.internet.threads.deferToThread',\n-                            new=_defer):\n-                storage.store(BytesIO(b'test file'))\n+            yield storage.store(BytesIO(b'test file'))\n \n             operation_name, api_params = m.call_args[0]\n             self.assertEqual(operation_name, 'PutObject')\n             self.assertNotIn('ACL', api_params)\n \n+    @defer.inlineCallbacks\n     def test_store_botocore_with_acl(self):\n         storage = S3FeedStorage(\n             's3://mybucket/export.csv',\n@@ -270,18 +267,14 @@ class S3FeedStorageTest(unittest.TestCase):\n         self.assertEqual(storage.secret_key, 'secret_key')\n         self.assertEqual(storage.acl, 'custom-acl')\n \n-        def _defer(f, *args, **kwargs):\n-            return f(*args, **kwargs)\n-\n         with mock.patch('botocore.client.BaseClient._make_api_call') as m:\n-            with mock.patch('twisted.internet.threads.deferToThread',\n-                            new=_defer):\n-                storage.store(BytesIO(b'test file'))\n+            yield storage.store(BytesIO(b'test file'))\n \n             operation_name, api_params = m.call_args[0]\n             self.assertEqual(operation_name, 'PutObject')\n             self.assertEqual(api_params.get('ACL'), 'custom-acl')\n \n+    @defer.inlineCallbacks\n     def test_store_not_botocore_without_acl(self):\n         storage = S3FeedStorage(\n             's3://mybucket/export.csv',\n@@ -296,11 +289,7 @@ class S3FeedStorageTest(unittest.TestCase):\n         storage.connect_s3 = mock.MagicMock()\n         self.assertFalse(storage.is_botocore)\n \n-        def _defer(f, *args, **kwargs):\n-            return f(*args, **kwargs)\n-\n-        with mock.patch('twisted.internet.threads.deferToThread', new=_defer):\n-            storage.store(BytesIO(b'test file'))\n+        yield storage.store(BytesIO(b'test file'))\n \n         conn = storage.connect_s3(*storage.connect_s3.call_args)\n         bucket = conn.get_bucket(*conn.get_bucket.call_args)\n@@ -310,6 +299,7 @@ class S3FeedStorageTest(unittest.TestCase):\n             key.set_contents_from_file.call_args\n         )\n \n+    @defer.inlineCallbacks\n     def test_store_not_botocore_with_acl(self):\n         storage = S3FeedStorage(\n             's3://mybucket/export.csv',\n@@ -325,11 +315,7 @@ class S3FeedStorageTest(unittest.TestCase):\n         storage.connect_s3 = mock.MagicMock()\n         self.assertFalse(storage.is_botocore)\n \n-        def _defer(f, *args, **kwargs):\n-            return f(*args, **kwargs)\n-\n-        with mock.patch('twisted.internet.threads.deferToThread', new=_defer):\n-            storage.store(BytesIO(b'test file'))\n+        yield storage.store(BytesIO(b'test file'))\n \n         conn = storage.connect_s3(*storage.connect_s3.call_args)\n         bucket = conn.get_bucket(*conn.get_bucket.call_args)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#03e61b9908733f085d87da6bd29152389961b81a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 27 | Lines Deleted: 1 | Files Changed: 3 | Hunks: 8 | Methods Changed: 7 | Complexity Δ (Sum/Max): 6/3 | Churn Δ: 28 | Churn Cumulative: 2096 | Contributors (this commit): 23 | Commits (past 90d): 3 | Contributors (cumulative): 33 | DMM Complexity: 1.0\n\nDIFF:\n@@ -7,6 +7,7 @@ import sys\n from twisted.internet import reactor, defer\n from zope.interface.verify import verifyClass, DoesNotImplement\n \n+from scrapy import Spider\n from scrapy.core.engine import ExecutionEngine\n from scrapy.resolver import CachingThreadedResolver\n from scrapy.interfaces import ISpiderLoader\n@@ -27,6 +28,10 @@ logger = logging.getLogger(__name__)\n class Crawler(object):\n \n     def __init__(self, spidercls, settings=None):\n+        if isinstance(spidercls, Spider):\n+            raise ValueError(\n+                'The spidercls argument must be a class, not an object')\n+\n         if isinstance(settings, dict) or settings is None:\n             settings = Settings(settings)\n \n@@ -168,6 +173,10 @@ class CrawlerRunner(object):\n \n         :param dict kwargs: keyword arguments to initialize the spider\n         \"\"\"\n+        if isinstance(crawler_or_spidercls, Spider):\n+            raise ValueError(\n+                'The crawler_or_spidercls argument cannot be a spider object, '\n+                'it must be a spider class (or a Crawler object)')\n         crawler = self.create_crawler(crawler_or_spidercls)\n         return self._crawl(crawler, *args, **kwargs)\n \n@@ -195,6 +204,10 @@ class CrawlerRunner(object):\n           a spider with this name in a Scrapy project (using spider loader),\n           then creates a Crawler instance for it.\n         \"\"\"\n+        if isinstance(crawler_or_spidercls, Spider):\n+            raise ValueError(\n+                'The crawler_or_spidercls argument cannot be a spider object, '\n+                'it must be a spider class (or a Crawler object)')\n         if isinstance(crawler_or_spidercls, Crawler):\n             return crawler_or_spidercls\n         return self._create_crawler(crawler_or_spidercls)\n\n@@ -4,6 +4,7 @@ import warnings\n \n from twisted.internet import defer\n from twisted.trial import unittest\n+from pytest import raises\n \n import scrapy\n from scrapy.crawler import Crawler, CrawlerRunner, CrawlerProcess\n@@ -66,6 +67,10 @@ class CrawlerTestCase(BaseCrawlerTest):\n         crawler = Crawler(DefaultSpider)\n         self.assertOptionIsDefault(crawler.settings, 'RETRY_ENABLED')\n \n+    def test_crawler_rejects_spider_objects(self):\n+        with raises(ValueError):\n+            Crawler(DefaultSpider())\n+\n \n class SpiderSettingsTestCase(unittest.TestCase):\n     def test_spider_custom_settings(self):\n@@ -177,6 +182,14 @@ class CrawlerRunnerTestCase(BaseCrawlerTest):\n             self.assertEqual(len(w), 1)\n             self.assertIn('Please use SPIDER_LOADER_CLASS', str(w[0].message))\n \n+    def test_crawl_rejects_spider_objects(self):\n+        with raises(ValueError):\n+            CrawlerRunner().crawl(DefaultSpider())\n+\n+    def test_create_crawler_rejects_spider_objects(self):\n+        with raises(ValueError):\n+            CrawlerRunner().create_crawler(DefaultSpider())\n+\n \n class CrawlerProcessTest(BaseCrawlerTest):\n     def test_crawler_process_accepts_dict(self):\n\n@@ -25,7 +25,7 @@ class TestHttpProxyMiddleware(TestCase):\n \n     def test_not_enabled(self):\n         settings = Settings({'HTTPPROXY_ENABLED': False})\n-        crawler = Crawler(spider, settings)\n+        crawler = Crawler(Spider, settings)\n         self.assertRaises(NotConfigured, partial(HttpProxyMiddleware.from_crawler, crawler))\n \n     def test_no_environment_proxies(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#7c9f0bd86c5f02ea803fa6bf1242d34d9c9f47d5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 9 | Churn Cumulative: 220 | Contributors (this commit): 12 | Commits (past 90d): 8 | Contributors (cumulative): 12 | DMM Complexity: 1.0\n\nDIFF:\n@@ -131,9 +131,12 @@ class S3FeedStorage(BlockingFeedStorage):\n \n     @classmethod\n     def from_crawler(cls, crawler, uri):\n-        return cls(uri, crawler.settings['AWS_ACCESS_KEY_ID'],\n-                   crawler.settings['AWS_SECRET_ACCESS_KEY'],\n-                   crawler.settings['FEED_STORAGE_S3_ACL'])\n+        return cls(\n+            uri=uri,\n+            access_key=crawler.settings['AWS_ACCESS_KEY_ID'],\n+            secret_key=crawler.settings['AWS_SECRET_ACCESS_KEY'],\n+            acl=crawler.settings['FEED_STORAGE_S3_ACL']\n+        )\n \n     def _store_in_thread(self, file):\n         file.seek(0)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#c2dede27bd56bd783c45fb7302ca06b7c2c025c0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 230 | Contributors (this commit): 12 | Commits (past 90d): 9 | Contributors (cumulative): 12 | DMM Complexity: 0.0\n\nDIFF:\n@@ -141,10 +141,7 @@ class S3FeedStorage(BlockingFeedStorage):\n     def _store_in_thread(self, file):\n         file.seek(0)\n         if self.is_botocore:\n-            kwargs = dict()\n-            if self.acl:\n-                kwargs.update(dict(ACL=self.acl))\n-\n+            kwargs = {'ACL': self.acl} if self.acl else {}\n             self.s3_client.put_object(\n                 Bucket=self.bucketname, Key=self.keyname, Body=file,\n                 **kwargs)\n@@ -152,10 +149,7 @@ class S3FeedStorage(BlockingFeedStorage):\n             conn = self.connect_s3(self.access_key, self.secret_key)\n             bucket = conn.get_bucket(self.bucketname, validate=False)\n             key = bucket.new_key(self.keyname)\n-            kwargs = dict()\n-            if self.acl:\n-                kwargs.update(dict(policy=self.acl))\n-\n+            kwargs = {'policy': self.acl} if self.acl else {}\n             key.set_contents_from_file(file, **kwargs)\n             key.close()\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#984e706fd2e06457bcdd1226366d08950ac101b0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 4 | Churn Cumulative: 781 | Contributors (this commit): 45 | Commits (past 90d): 16 | Contributors (cumulative): 55 | DMM Complexity: None\n\nDIFF:\n@@ -135,7 +135,7 @@ class S3FeedStorage(BlockingFeedStorage):\n             uri=uri,\n             access_key=crawler.settings['AWS_ACCESS_KEY_ID'],\n             secret_key=crawler.settings['AWS_SECRET_ACCESS_KEY'],\n-            acl=crawler.settings['FEED_STORAGE_S3_ACL']\n+            acl=crawler.settings['FEED_STORAGE_S3_ACL'] or None\n         )\n \n     def _store_in_thread(self, file):\n\n@@ -158,7 +158,7 @@ FEED_EXPORTERS_BASE = {\n }\n FEED_EXPORT_INDENT = 0\n \n-FEED_STORAGE_S3_ACL = None\n+FEED_STORAGE_S3_ACL = ''\n \n FILES_STORE_S3_ACL = 'private'\n FILES_STORE_GCS_ACL = ''\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#04ccf79e38561a2175c18440b3b4a53ba2f4992f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 214 | Contributors (this commit): 8 | Commits (past 90d): 1 | Contributors (cumulative): 8 | DMM Complexity: 1.0\n\nDIFF:\n@@ -89,6 +89,7 @@ class ImagesPipeline(FilesPipeline):\n         s3store = cls.STORE_SCHEMES['s3']\n         s3store.AWS_ACCESS_KEY_ID = settings['AWS_ACCESS_KEY_ID']\n         s3store.AWS_SECRET_ACCESS_KEY = settings['AWS_SECRET_ACCESS_KEY']\n+        s3store.AWS_ENDPOINT_URL = settings['AWS_ENDPOINT_URL']\n         s3store.POLICY = settings['IMAGES_STORE_S3_ACL']\n \n         gcs_store = cls.STORE_SCHEMES['gs']\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#430e9392483b3992c16bd0314f1bcaed91a9d392", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 217 | Contributors (this commit): 8 | Commits (past 90d): 2 | Contributors (cumulative): 8 | DMM Complexity: 1.0\n\nDIFF:\n@@ -90,6 +90,9 @@ class ImagesPipeline(FilesPipeline):\n         s3store.AWS_ACCESS_KEY_ID = settings['AWS_ACCESS_KEY_ID']\n         s3store.AWS_SECRET_ACCESS_KEY = settings['AWS_SECRET_ACCESS_KEY']\n         s3store.AWS_ENDPOINT_URL = settings['AWS_ENDPOINT_URL']\n+        s3store.AWS_REGION_NAME = settings['AWS_REGION_NAME']\n+        s3store.AWS_USE_SSL = settings['AWS_USE_SSL']\n+        s3store.AWS_VERIFY = settings['AWS_VERIFY']\n         s3store.POLICY = settings['IMAGES_STORE_S3_ACL']\n \n         gcs_store = cls.STORE_SCHEMES['gs']\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#dc0b643832e9f3400e432c2ef7a34e6c75ac8366", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 10 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 17 | Churn Cumulative: 1024 | Contributors (this commit): 13 | Commits (past 90d): 9 | Contributors (cumulative): 13 | DMM Complexity: 0.0\n\nDIFF:\n@@ -248,12 +248,9 @@ class S3FeedStorageTest(unittest.TestCase):\n         self.assertEqual(storage.secret_key, 'secret_key')\n         self.assertEqual(storage.acl, None)\n \n-        with mock.patch('botocore.client.BaseClient._make_api_call') as m:\n+        storage.s3_client = mock.MagicMock()\n         yield storage.store(BytesIO(b'test file'))\n-\n-            operation_name, api_params = m.call_args[0]\n-            self.assertEqual(operation_name, 'PutObject')\n-            self.assertNotIn('ACL', api_params)\n+        self.assertNotIn('ACL', storage.s3_client.put_object.call_args[1])\n \n     @defer.inlineCallbacks\n     def test_store_botocore_with_acl(self):\n@@ -267,12 +264,12 @@ class S3FeedStorageTest(unittest.TestCase):\n         self.assertEqual(storage.secret_key, 'secret_key')\n         self.assertEqual(storage.acl, 'custom-acl')\n \n-        with mock.patch('botocore.client.BaseClient._make_api_call') as m:\n+        storage.s3_client = mock.MagicMock()\n         yield storage.store(BytesIO(b'test file'))\n-\n-            operation_name, api_params = m.call_args[0]\n-            self.assertEqual(operation_name, 'PutObject')\n-            self.assertEqual(api_params.get('ACL'), 'custom-acl')\n+        self.assertEqual(\n+            storage.s3_client.put_object.call_args[1].get('ACL'),\n+            'custom-acl'\n+        )\n \n     @defer.inlineCallbacks\n     def test_store_not_botocore_without_acl(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#ea8be627d15aa6fe1beaf50fff666cbeb161d94d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 7 | Churn Cumulative: 1031 | Contributors (this commit): 13 | Commits (past 90d): 10 | Contributors (cumulative): 13 | DMM Complexity: 1.0\n\nDIFF:\n@@ -18,7 +18,6 @@ from tests import mock\n from tests.mockserver import MockServer\n from w3lib.url import path_to_file_uri\n \n-import botocore.client\n import scrapy\n from scrapy.exporters import CsvItemExporter\n from scrapy.extensions.feedexport import (\n@@ -239,6 +238,9 @@ class S3FeedStorageTest(unittest.TestCase):\n \n     @defer.inlineCallbacks\n     def test_store_botocore_without_acl(self):\n+        if os.getenv('TOX_ENV_NAME') == 'jessie':\n+            raise unittest.SkipTest('botocore is not supported on jessie')\n+\n         storage = S3FeedStorage(\n             's3://mybucket/export.csv',\n             'access_key',\n@@ -254,6 +256,9 @@ class S3FeedStorageTest(unittest.TestCase):\n \n     @defer.inlineCallbacks\n     def test_store_botocore_with_acl(self):\n+        if os.getenv('TOX_ENV_NAME') == 'jessie':\n+            raise unittest.SkipTest('botocore is not supported on jessie')\n+\n         storage = S3FeedStorage(\n             's3://mybucket/export.csv',\n             'access_key',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#9b8ba4c383df0f3029d1b07ab9647a7d902600f4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 1043 | Contributors (this commit): 13 | Commits (past 90d): 11 | Contributors (cumulative): 13 | DMM Complexity: 1.0\n\nDIFF:\n@@ -238,8 +238,10 @@ class S3FeedStorageTest(unittest.TestCase):\n \n     @defer.inlineCallbacks\n     def test_store_botocore_without_acl(self):\n-        if os.getenv('TOX_ENV_NAME') == 'jessie':\n-            raise unittest.SkipTest('botocore is not supported on jessie')\n+        try:\n+            import botocore\n+        except ImportError:\n+            raise unittest.SkipTest('botocore is required')\n \n         storage = S3FeedStorage(\n             's3://mybucket/export.csv',\n@@ -256,8 +258,10 @@ class S3FeedStorageTest(unittest.TestCase):\n \n     @defer.inlineCallbacks\n     def test_store_botocore_with_acl(self):\n-        if os.getenv('TOX_ENV_NAME') == 'jessie':\n-            raise unittest.SkipTest('botocore is not supported on jessie')\n+        try:\n+            import botocore\n+        except ImportError:\n+            raise unittest.SkipTest('botocore is required')\n \n         storage = S3FeedStorage(\n             's3://mybucket/export.csv',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#b02d26fae8892775ad6ef306d80b02e6bc69d12e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 2 | Churn Cumulative: 429 | Contributors (this commit): 18 | Commits (past 90d): 1 | Contributors (cumulative): 18 | DMM Complexity: None\n\nDIFF:\n@@ -116,7 +116,7 @@ def md5sum(file):\n \n def rel_has_nofollow(rel):\n     \"\"\"Return True if link rel attribute has nofollow type\"\"\"\n-    return True if rel is not None and 'nofollow' in rel.split() else False\n+    return rel is not None and 'nofollow' in rel.split()\n \n \n def create_instance(objcls, settings, crawler, *args, **kwargs):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#0bb3d8ca93cf68e0ef231ee734f8a1a3c4075a72", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): -6/0 | Churn Δ: 4 | Churn Cumulative: 1596 | Contributors (this commit): 45 | Commits (past 90d): 19 | Contributors (cumulative): 56 | DMM Complexity: None\n\nDIFF:\n@@ -143,7 +143,7 @@ FEED_STORAGES_BASE = {\n     '': 'scrapy.extensions.feedexport.FileFeedStorage',\n     'file': 'scrapy.extensions.feedexport.FileFeedStorage',\n     'ftp': 'scrapy.extensions.feedexport.FTPFeedStorage',\n-    'gcs': 'scrapy.extensions.feedexport.GCSFeedStorage',\n+    'gs': 'scrapy.extensions.feedexport.GCSFeedStorage',\n     's3': 'scrapy.extensions.feedexport.S3FeedStorage',\n     'stdout': 'scrapy.extensions.feedexport.StdoutFeedStorage',\n }\n\n@@ -200,7 +200,7 @@ class GCSFeedStorageTest(unittest.TestCase):\n \n         settings = {'GCS_PROJECT_ID': '123', 'FEED_STORAGE_GCS_ACL': 'publicRead' }\n         crawler = get_crawler(settings_dict=settings)\n-        storage = GCSFeedStorage.from_crawler(crawler, 'gcs://mybucket/export.csv')\n+        storage = GCSFeedStorage.from_crawler(crawler, 'gs://mybucket/export.csv')\n         assert storage.project_id == '123'\n         assert storage.acl == 'publicRead'\n         assert storage.bucket_name == 'mybucket'\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
