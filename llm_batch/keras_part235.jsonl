{"custom_id": "keras#738819de0b7e6bc45abed8d0640f02b81c6ac4e9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 39 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 5 | Methods Changed: 4 | Complexity Δ (Sum/Max): 5/4 | Churn Δ: 42 | Churn Cumulative: 3382 | Contributors (this commit): 52 | Commits (past 90d): 23 | Contributors (cumulative): 61 | DMM Complexity: 0.0\n\nDIFF:\n@@ -580,8 +580,6 @@ class ImageDataGenerator(object):\n         # Returns\n             The inputs, normalized.\n         \"\"\"\n-        if self.preprocessing_function:\n-            x = self.preprocessing_function(x)\n         if self.rescale:\n             x *= self.rescale\n         if self.samplewise_center:\n@@ -951,6 +949,8 @@ class NumpyArrayIterator(Iterator):\n                            dtype=K.floatx())\n         for i, j in enumerate(index_array):\n             x = self.x[j]\n+            if self.image_data_generator.preprocessing_function:\n+                x = self.image_data_generator.preprocessing_function(x)\n             x = self.image_data_generator.random_transform(x.astype(K.floatx()))\n             x = self.image_data_generator.standardize(x)\n             batch_x[i] = x\n@@ -1227,8 +1227,21 @@ class DirectoryIterator(Iterator):\n             fname = self.filenames[j]\n             img = load_img(os.path.join(self.directory, fname),\n                            grayscale=grayscale,\n-                           target_size=self.target_size,\n+                           target_size=None,\n                            interpolation=self.interpolation)\n+            if self.image_data_generator.preprocessing_function:\n+                img = self.image_data_generator.preprocessing_function(img)\n+            if self.target_size is not None:\n+                width_height_tuple = (self.target_size[1], self.target_size[0])\n+                if img.size != width_height_tuple:\n+                    if self.interpolation not in _PIL_INTERPOLATION_METHODS:\n+                        raise ValueError(\n+                            'Invalid interpolation method {} specified. Supported '\n+                            'methods are {}'.format(\n+                                self.interpolation,\n+                                \", \".join(_PIL_INTERPOLATION_METHODS.keys())))\n+                    resample = _PIL_INTERPOLATION_METHODS[self.interpolation]\n+                    img = img.resize(width_height_tuple, resample)\n             x = img_to_array(img, data_format=self.data_format)\n             x = self.image_data_generator.random_transform(x)\n             x = self.image_data_generator.standardize(x)\n\n@@ -235,6 +235,29 @@ class TestImage(object):\n         with pytest.raises(ValueError):\n             x1, y1 = dir_seq[9]\n \n+        # Test Preprocessing before resize\n+        def preprocess_test(img):\n+            return img.resize((1, 1))\n+\n+        generator = image.ImageDataGenerator(preprocessing_function=preprocess_test)\n+        dir_seq = generator.flow_from_directory(str(tmpdir),\n+                                                target_size=(26, 26),\n+                                                color_mode='rgb',\n+                                                batch_size=1,\n+                                                class_mode='categorical')\n+\n+        gen_x1, gen_y1 = dir_seq[1]\n+\n+        test_x1 = image.load_img(os.path.join(dir_seq.directory, dir_seq.filenames[1]),\n+                                 grayscale=False)\n+        test_x1 = preprocess_test(test_x1)\n+        test_x1 = test_x1.resize((26, 26))\n+        test_x1 = image.img_to_array(test_x1)\n+        test_x1 = dir_seq.image_data_generator.random_transform(test_x1)\n+        test_x1 = dir_seq.image_data_generator.standardize(test_x1)\n+\n+        assert gen_x1.shape[1:] == test_x1.shape\n+\n     def test_directory_iterator_class_mode_input(self, tmpdir):\n         tmpdir.join('class-1').mkdir()\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cdbe1542d7b694d96e428fcba340fa82bc4cc8e5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 344 | Lines Deleted: 220 | Files Changed: 7 | Hunks: 13 | Methods Changed: 14 | Complexity Δ (Sum/Max): 8/15 | Churn Δ: 564 | Churn Cumulative: 26021 | Contributors (this commit): 125 | Commits (past 90d): 50 | Contributors (cumulative): 195 | DMM Complexity: 0.3181818181818182\n\nDIFF:\n@@ -65,6 +65,7 @@ from ..layers import BatchNormalization\n from ..layers import GlobalAveragePooling2D\n from ..layers import GlobalMaxPooling2D\n from ..layers import Conv2D\n+from ..layers import DepthwiseConv2D\n from .. import initializers\n from .. import regularizers\n from .. import constraints\n@@ -97,204 +98,6 @@ def preprocess_input(x):\n     return imagenet_utils.preprocess_input(x, mode='tf')\n \n \n-class DepthwiseConv2D(Conv2D):\n-    \"\"\"Depthwise separable 2D convolution.\n-\n-    Depthwise Separable convolutions consists in performing\n-    just the first step in a depthwise spatial convolution\n-    (which acts on each input channel separately).\n-    The `depth_multiplier` argument controls how many\n-    output channels are generated per input channel in the depthwise step.\n-\n-    # Arguments\n-        kernel_size: An integer or tuple/list of 2 integers, specifying the\n-            width and height of the 2D convolution window.\n-            Can be a single integer to specify the same value for\n-            all spatial dimensions.\n-        strides: An integer or tuple/list of 2 integers,\n-            specifying the strides of the convolution along the width and height.\n-            Can be a single integer to specify the same value for\n-            all spatial dimensions.\n-            Specifying any stride value != 1 is incompatible with specifying\n-            any `dilation_rate` value != 1.\n-        padding: one of `'valid'` or `'same'` (case-insensitive).\n-        depth_multiplier: The number of depthwise convolution output channels\n-            for each input channel.\n-            The total number of depthwise convolution output\n-            channels will be equal to `filters_in * depth_multiplier`.\n-        data_format: A string,\n-            one of `channels_last` (default) or `channels_first`.\n-            The ordering of the dimensions in the inputs.\n-            `channels_last` corresponds to inputs with shape\n-            `(batch, height, width, channels)` while `channels_first`\n-            corresponds to inputs with shape\n-            `(batch, channels, height, width)`.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be 'channels_last'.\n-        activation: Activation function to use\n-            (see [activations](../activations.md)).\n-            If you don't specify anything, no activation is applied\n-            (ie. 'linear' activation: `a(x) = x`).\n-        use_bias: Boolean, whether the layer uses a bias vector.\n-        depthwise_initializer: Initializer for the depthwise kernel matrix\n-            (see [initializers](../initializers.md)).\n-        bias_initializer: Initializer for the bias vector\n-            (see [initializers](../initializers.md)).\n-        depthwise_regularizer: Regularizer function applied to\n-            the depthwise kernel matrix\n-            (see [regularizer](../regularizers.md)).\n-        bias_regularizer: Regularizer function applied to the bias vector\n-            (see [regularizer](../regularizers.md)).\n-        activity_regularizer: Regularizer function applied to\n-            the output of the layer (its 'activation').\n-            (see [regularizer](../regularizers.md)).\n-        depthwise_constraint: Constraint function applied to\n-            the depthwise kernel matrix\n-            (see [constraints](../constraints.md)).\n-        bias_constraint: Constraint function applied to the bias vector\n-            (see [constraints](../constraints.md)).\n-\n-    # Input shape\n-        4D tensor with shape:\n-        `[batch, channels, rows, cols]` if data_format='channels_first'\n-        or 4D tensor with shape:\n-        `[batch, rows, cols, channels]` if data_format='channels_last'.\n-\n-    # Output shape\n-        4D tensor with shape:\n-        `[batch, filters, new_rows, new_cols]` if data_format='channels_first'\n-        or 4D tensor with shape:\n-        `[batch, new_rows, new_cols, filters]` if data_format='channels_last'.\n-        `rows` and `cols` values might have changed due to padding.\n-    \"\"\"\n-\n-    def __init__(self,\n-                 kernel_size,\n-                 strides=(1, 1),\n-                 padding='valid',\n-                 depth_multiplier=1,\n-                 data_format=None,\n-                 activation=None,\n-                 use_bias=True,\n-                 depthwise_initializer='glorot_uniform',\n-                 bias_initializer='zeros',\n-                 depthwise_regularizer=None,\n-                 bias_regularizer=None,\n-                 activity_regularizer=None,\n-                 depthwise_constraint=None,\n-                 bias_constraint=None,\n-                 **kwargs):\n-        super(DepthwiseConv2D, self).__init__(\n-            filters=None,\n-            kernel_size=kernel_size,\n-            strides=strides,\n-            padding=padding,\n-            data_format=data_format,\n-            activation=activation,\n-            use_bias=use_bias,\n-            bias_regularizer=bias_regularizer,\n-            activity_regularizer=activity_regularizer,\n-            bias_constraint=bias_constraint,\n-            **kwargs)\n-        self.depth_multiplier = depth_multiplier\n-        self.depthwise_initializer = initializers.get(depthwise_initializer)\n-        self.depthwise_regularizer = regularizers.get(depthwise_regularizer)\n-        self.depthwise_constraint = constraints.get(depthwise_constraint)\n-        self.bias_initializer = initializers.get(bias_initializer)\n-\n-    def build(self, input_shape):\n-        if len(input_shape) < 4:\n-            raise ValueError('Inputs to `DepthwiseConv2D` should have rank 4. '\n-                             'Received input shape:', str(input_shape))\n-        if self.data_format == 'channels_first':\n-            channel_axis = 1\n-        else:\n-            channel_axis = 3\n-        if input_shape[channel_axis] is None:\n-            raise ValueError('The channel dimension of the inputs to '\n-                             '`DepthwiseConv2D` '\n-                             'should be defined. Found `None`.')\n-        input_dim = int(input_shape[channel_axis])\n-        depthwise_kernel_shape = (self.kernel_size[0],\n-                                  self.kernel_size[1],\n-                                  input_dim,\n-                                  self.depth_multiplier)\n-\n-        self.depthwise_kernel = self.add_weight(\n-            shape=depthwise_kernel_shape,\n-            initializer=self.depthwise_initializer,\n-            name='depthwise_kernel',\n-            regularizer=self.depthwise_regularizer,\n-            constraint=self.depthwise_constraint)\n-\n-        if self.use_bias:\n-            self.bias = self.add_weight(shape=(input_dim * self.depth_multiplier,),\n-                                        initializer=self.bias_initializer,\n-                                        name='bias',\n-                                        regularizer=self.bias_regularizer,\n-                                        constraint=self.bias_constraint)\n-        else:\n-            self.bias = None\n-        # Set input spec.\n-        self.input_spec = InputSpec(ndim=4, axes={channel_axis: input_dim})\n-        self.built = True\n-\n-    def call(self, inputs, training=None):\n-        outputs = K.depthwise_conv2d(\n-            inputs,\n-            self.depthwise_kernel,\n-            strides=self.strides,\n-            padding=self.padding,\n-            dilation_rate=self.dilation_rate,\n-            data_format=self.data_format)\n-\n-        if self.bias:\n-            outputs = K.bias_add(\n-                outputs,\n-                self.bias,\n-                data_format=self.data_format)\n-\n-        if self.activation is not None:\n-            return self.activation(outputs)\n-\n-        return outputs\n-\n-    def compute_output_shape(self, input_shape):\n-        if self.data_format == 'channels_first':\n-            rows = input_shape[2]\n-            cols = input_shape[3]\n-            out_filters = input_shape[1] * self.depth_multiplier\n-        elif self.data_format == 'channels_last':\n-            rows = input_shape[1]\n-            cols = input_shape[2]\n-            out_filters = input_shape[3] * self.depth_multiplier\n-\n-        rows = conv_utils.conv_output_length(rows, self.kernel_size[0],\n-                                             self.padding,\n-                                             self.strides[0])\n-        cols = conv_utils.conv_output_length(cols, self.kernel_size[1],\n-                                             self.padding,\n-                                             self.strides[1])\n-\n-        if self.data_format == 'channels_first':\n-            return (input_shape[0], out_filters, rows, cols)\n-        elif self.data_format == 'channels_last':\n-            return (input_shape[0], rows, cols, out_filters)\n-\n-    def get_config(self):\n-        config = super(DepthwiseConv2D, self).get_config()\n-        config.pop('filters')\n-        config.pop('kernel_initializer')\n-        config.pop('kernel_regularizer')\n-        config.pop('kernel_constraint')\n-        config['depth_multiplier'] = self.depth_multiplier\n-        config['depthwise_initializer'] = initializers.serialize(self.depthwise_initializer)\n-        config['depthwise_regularizer'] = regularizers.serialize(self.depthwise_regularizer)\n-        config['depthwise_constraint'] = constraints.serialize(self.depthwise_constraint)\n-        return config\n-\n-\n def MobileNet(input_shape=None,\n               alpha=1.0,\n               depth_multiplier=1,\n@@ -306,18 +109,11 @@ def MobileNet(input_shape=None,\n               classes=1000):\n     \"\"\"Instantiates the MobileNet architecture.\n \n-    Note that only TensorFlow is supported for now,\n-    therefore it only works with the data format\n-    `image_data_format='channels_last'` in your Keras config\n-    at `~/.keras/keras.json`.\n-\n     To load a MobileNet model via `load_model`, import the custom\n-    objects `relu6` and `DepthwiseConv2D` and pass them to the\n-    `custom_objects` parameter.\n+    objects `relu6` and pass them to the `custom_objects` parameter.\n     E.g.\n     model = load_model('mobilenet.h5', custom_objects={\n-                       'relu6': mobilenet.relu6,\n-                       'DepthwiseConv2D': mobilenet.DepthwiseConv2D})\n+                       'relu6': mobilenet.relu6})\n \n     # Arguments\n         input_shape: optional shape tuple, only to be specified\n@@ -371,11 +167,6 @@ def MobileNet(input_shape=None,\n             backend that does not support separable convolutions.\n     \"\"\"\n \n-    if K.backend() != 'tensorflow':\n-        raise RuntimeError('Only TensorFlow backend is currently supported, '\n-                           'as other backends do not support '\n-                           'depthwise convolution.')\n-\n     if not (weights in {'imagenet', None} or os.path.exists(weights)):\n         raise ValueError('The `weights` argument should be either '\n                          '`None` (random initialization), `imagenet` '\n\n@@ -1550,7 +1550,33 @@ def separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1),\n \n def depthwise_conv2d(x, depthwise_kernel, strides=(1, 1), padding='valid',\n                      data_format=None, dilation_rate=(1, 1)):\n-    raise NotImplementedError\n+    if data_format is None:\n+        data_format = image_data_format()\n+    if data_format not in {'channels_first', 'channels_last'}:\n+        raise ValueError('Unknown data_format ' + str(data_format))\n+\n+    x = _preprocess_conv2d_input(x, data_format)\n+    depthwise_kernel = _preprocess_conv2d_kernel(depthwise_kernel, data_format)\n+    depthwise_kernel = C.reshape(C.transpose(depthwise_kernel, (1, 0, 2, 3)),\n+                                 (-1, 1) + depthwise_kernel.shape[2:])\n+    padding = _preprocess_border_mode(padding)\n+    if dilation_rate == (1, 1):\n+        strides = (1,) + strides\n+        x = C.convolution(depthwise_kernel, x,\n+                          strides=strides,\n+                          auto_padding=[False, padding, padding],\n+                          groups=x.shape[0])\n+    else:\n+        if dilation_rate[0] != dilation_rate[1]:\n+            raise ValueError('CNTK Backend: non-square dilation_rate is '\n+                             'not supported.')\n+        if strides != (1, 1):\n+            raise ValueError('Invalid strides for dilated convolution')\n+        x = C.convolution(depthwise_kernel, x,\n+                          strides=dilation_rate[0],\n+                          auto_padding=[False, padding, padding],\n+                          groups=x.shape[0])\n+    return _postprocess_conv2d_output(x, data_format)\n \n \n def conv3d(x, kernel, strides=(1, 1, 1), padding='valid',\n\n@@ -1987,7 +1987,60 @@ def separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1),\n \n def depthwise_conv2d(x, depthwise_kernel, strides=(1, 1), padding='valid',\n                      data_format=None, dilation_rate=(1, 1)):\n-    raise NotImplementedError\n+    \"\"\"2D convolution with separable filters.\n+\n+    # Arguments\n+        x: input tensor\n+        depthwise_kernel: convolution kernel for the depthwise convolution.\n+        strides: strides tuple (length 2).\n+        padding: string, `\"same\"` or `\"valid\"`.\n+        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n+        dilation_rate: tuple of integers,\n+            dilation rates for the separable convolution.\n+\n+    # Returns\n+        Output tensor.\n+\n+    # Raises\n+        ValueError: if `data_format` is neither `\"channels_last\"` or `\"channels_first\"`.\n+    \"\"\"\n+    if data_format is None:\n+        data_format = image_data_format()\n+    if data_format not in {'channels_first', 'channels_last'}:\n+        raise ValueError('Unknown data_format ', data_format)\n+\n+    if hasattr(x, '_keras_shape'):\n+        image_shape = _preprocess_conv2d_image_shape(int_shape(x), data_format)\n+    else:\n+        image_shape = None\n+    if hasattr(depthwise_kernel, '_keras_shape'):\n+        depthwise_kernel_shape = depthwise_kernel._keras_shape\n+    else:\n+        # Will only work if `kernel` is a shared variable.\n+        depthwise_kernel_shape = depthwise_kernel.eval().shape\n+    depthwise_kernel_shape = _preprocess_conv2d_filter_shape(depthwise_kernel_shape, data_format)\n+\n+    x = _preprocess_conv2d_input(x, data_format)\n+    depthwise_kernel = _preprocess_conv2d_kernel(depthwise_kernel, data_format)\n+    th_padding = _preprocess_padding(padding)\n+\n+    input_depth = depthwise_kernel_shape[1]\n+    output_depth = depthwise_kernel_shape[0]\n+    depthwise_kernel_shape = (input_depth * output_depth, 1) + depthwise_kernel_shape[2:]\n+    depthwise_kernel = depthwise_kernel.dimshuffle((1, 0, 2, 3))\n+    depthwise_kernel = reshape(depthwise_kernel, depthwise_kernel_shape)\n+    depthwise_kernel = depthwise_kernel[:, :, ::-1, ::-1]\n+\n+    conv_out = T.nnet.conv2d(x, depthwise_kernel,\n+                             border_mode=th_padding,\n+                             subsample=strides,\n+                             input_shape=image_shape,\n+                             filter_shape=depthwise_kernel_shape,\n+                             filter_dilation=dilation_rate,\n+                             num_groups=input_depth)\n+    conv_out = _postprocess_conv2d_output(conv_out, x, padding,\n+                                          depthwise_kernel_shape, strides, data_format)\n+    return conv_out\n \n \n def conv3d(x, kernel, strides=(1, 1, 1),\n\n@@ -1511,6 +1511,203 @@ class SeparableConv2D(_SeparableConv):\n             **kwargs)\n \n \n+class DepthwiseConv2D(Conv2D):\n+    \"\"\"Depthwise separable 2D convolution.\n+\n+    Depthwise Separable convolutions consists in performing\n+    just the first step in a depthwise spatial convolution\n+    (which acts on each input channel separately).\n+    The `depth_multiplier` argument controls how many\n+    output channels are generated per input channel in the depthwise step.\n+\n+    # Arguments\n+        kernel_size: An integer or tuple/list of 2 integers, specifying the\n+            width and height of the 2D convolution window.\n+            Can be a single integer to specify the same value for\n+            all spatial dimensions.\n+        strides: An integer or tuple/list of 2 integers,\n+            specifying the strides of the convolution along the width and height.\n+            Can be a single integer to specify the same value for\n+            all spatial dimensions.\n+            Specifying any stride value != 1 is incompatible with specifying\n+            any `dilation_rate` value != 1.\n+        padding: one of `'valid'` or `'same'` (case-insensitive).\n+        depth_multiplier: The number of depthwise convolution output channels\n+            for each input channel.\n+            The total number of depthwise convolution output\n+            channels will be equal to `filters_in * depth_multiplier`.\n+        data_format: A string,\n+            one of `channels_last` (default) or `channels_first`.\n+            The ordering of the dimensions in the inputs.\n+            `channels_last` corresponds to inputs with shape\n+            `(batch, height, width, channels)` while `channels_first`\n+            corresponds to inputs with shape\n+            `(batch, channels, height, width)`.\n+            It defaults to the `image_data_format` value found in your\n+            Keras config file at `~/.keras/keras.json`.\n+            If you never set it, then it will be 'channels_last'.\n+        activation: Activation function to use\n+            (see [activations](../activations.md)).\n+            If you don't specify anything, no activation is applied\n+            (ie. 'linear' activation: `a(x) = x`).\n+        use_bias: Boolean, whether the layer uses a bias vector.\n+        depthwise_initializer: Initializer for the depthwise kernel matrix\n+            (see [initializers](../initializers.md)).\n+        bias_initializer: Initializer for the bias vector\n+            (see [initializers](../initializers.md)).\n+        depthwise_regularizer: Regularizer function applied to\n+            the depthwise kernel matrix\n+            (see [regularizer](../regularizers.md)).\n+        bias_regularizer: Regularizer function applied to the bias vector\n+            (see [regularizer](../regularizers.md)).\n+        activity_regularizer: Regularizer function applied to\n+            the output of the layer (its 'activation').\n+            (see [regularizer](../regularizers.md)).\n+        depthwise_constraint: Constraint function applied to\n+            the depthwise kernel matrix\n+            (see [constraints](../constraints.md)).\n+        bias_constraint: Constraint function applied to the bias vector\n+            (see [constraints](../constraints.md)).\n+\n+    # Input shape\n+        4D tensor with shape:\n+        `[batch, channels, rows, cols]` if data_format='channels_first'\n+        or 4D tensor with shape:\n+        `[batch, rows, cols, channels]` if data_format='channels_last'.\n+\n+    # Output shape\n+        4D tensor with shape:\n+        `[batch, filters, new_rows, new_cols]` if data_format='channels_first'\n+        or 4D tensor with shape:\n+        `[batch, new_rows, new_cols, filters]` if data_format='channels_last'.\n+        `rows` and `cols` values might have changed due to padding.\n+    \"\"\"\n+\n+    def __init__(self,\n+                 kernel_size,\n+                 strides=(1, 1),\n+                 padding='valid',\n+                 depth_multiplier=1,\n+                 data_format=None,\n+                 activation=None,\n+                 use_bias=True,\n+                 depthwise_initializer='glorot_uniform',\n+                 bias_initializer='zeros',\n+                 depthwise_regularizer=None,\n+                 bias_regularizer=None,\n+                 activity_regularizer=None,\n+                 depthwise_constraint=None,\n+                 bias_constraint=None,\n+                 **kwargs):\n+        super(DepthwiseConv2D, self).__init__(\n+            filters=None,\n+            kernel_size=kernel_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+            activation=activation,\n+            use_bias=use_bias,\n+            bias_regularizer=bias_regularizer,\n+            activity_regularizer=activity_regularizer,\n+            bias_constraint=bias_constraint,\n+            **kwargs)\n+        self.depth_multiplier = depth_multiplier\n+        self.depthwise_initializer = initializers.get(depthwise_initializer)\n+        self.depthwise_regularizer = regularizers.get(depthwise_regularizer)\n+        self.depthwise_constraint = constraints.get(depthwise_constraint)\n+        self.bias_initializer = initializers.get(bias_initializer)\n+\n+    def build(self, input_shape):\n+        if len(input_shape) < 4:\n+            raise ValueError('Inputs to `DepthwiseConv2D` should have rank 4. '\n+                             'Received input shape:', str(input_shape))\n+        if self.data_format == 'channels_first':\n+            channel_axis = 1\n+        else:\n+            channel_axis = 3\n+        if input_shape[channel_axis] is None:\n+            raise ValueError('The channel dimension of the inputs to '\n+                             '`DepthwiseConv2D` '\n+                             'should be defined. Found `None`.')\n+        input_dim = int(input_shape[channel_axis])\n+        depthwise_kernel_shape = (self.kernel_size[0],\n+                                  self.kernel_size[1],\n+                                  input_dim,\n+                                  self.depth_multiplier)\n+\n+        self.depthwise_kernel = self.add_weight(\n+            shape=depthwise_kernel_shape,\n+            initializer=self.depthwise_initializer,\n+            name='depthwise_kernel',\n+            regularizer=self.depthwise_regularizer,\n+            constraint=self.depthwise_constraint)\n+\n+        if self.use_bias:\n+            self.bias = self.add_weight(shape=(input_dim * self.depth_multiplier,),\n+                                        initializer=self.bias_initializer,\n+                                        name='bias',\n+                                        regularizer=self.bias_regularizer,\n+                                        constraint=self.bias_constraint)\n+        else:\n+            self.bias = None\n+        # Set input spec.\n+        self.input_spec = InputSpec(ndim=4, axes={channel_axis: input_dim})\n+        self.built = True\n+\n+    def call(self, inputs, training=None):\n+        outputs = K.depthwise_conv2d(\n+            inputs,\n+            self.depthwise_kernel,\n+            strides=self.strides,\n+            padding=self.padding,\n+            dilation_rate=self.dilation_rate,\n+            data_format=self.data_format)\n+\n+        if self.bias:\n+            outputs = K.bias_add(\n+                outputs,\n+                self.bias,\n+                data_format=self.data_format)\n+\n+        if self.activation is not None:\n+            return self.activation(outputs)\n+\n+        return outputs\n+\n+    def compute_output_shape(self, input_shape):\n+        if self.data_format == 'channels_first':\n+            rows = input_shape[2]\n+            cols = input_shape[3]\n+            out_filters = input_shape[1] * self.depth_multiplier\n+        elif self.data_format == 'channels_last':\n+            rows = input_shape[1]\n+            cols = input_shape[2]\n+            out_filters = input_shape[3] * self.depth_multiplier\n+\n+        rows = conv_utils.conv_output_length(rows, self.kernel_size[0],\n+                                             self.padding,\n+                                             self.strides[0])\n+        cols = conv_utils.conv_output_length(cols, self.kernel_size[1],\n+                                             self.padding,\n+                                             self.strides[1])\n+        if self.data_format == 'channels_first':\n+            return (input_shape[0], out_filters, rows, cols)\n+        elif self.data_format == 'channels_last':\n+            return (input_shape[0], rows, cols, out_filters)\n+\n+    def get_config(self):\n+        config = super(DepthwiseConv2D, self).get_config()\n+        config.pop('filters')\n+        config.pop('kernel_initializer')\n+        config.pop('kernel_regularizer')\n+        config.pop('kernel_constraint')\n+        config['depth_multiplier'] = self.depth_multiplier\n+        config['depthwise_initializer'] = initializers.serialize(self.depthwise_initializer)\n+        config['depthwise_regularizer'] = regularizers.serialize(self.depthwise_regularizer)\n+        config['depthwise_constraint'] = constraints.serialize(self.depthwise_constraint)\n+        return config\n+\n+\n class UpSampling1D(Layer):\n     \"\"\"Upsampling layer for 1D inputs.\n \n\n@@ -137,8 +137,6 @@ def test_inceptionresnetv2():\n     _test_app_pooling(app, last_dim)\n \n \n-@pytest.mark.skipif((K.backend() != 'tensorflow'),\n-                    reason='MobileNets are supported only on TensorFlow')\n def test_mobilenet():\n     app = applications.MobileNet\n     last_dim = 1024\n\n@@ -823,6 +823,25 @@ class TestBackend(object):\n             with pytest.raises(ValueError):\n                 k.conv2d(k.variable(xval), k.variable(kernel_val), data_format='channels_middle')\n \n+    def test_depthwise_conv_2d(self):\n+        # TF kernel shape: (rows, cols, input_depth, depth_multiplier)\n+        # channels_first input shape: (n, input_depth, rows, cols)\n+        for (input_shape, kernel_shape, data_format) in [\n+                ((2, 3, 4, 5), (2, 2, 3, 4), 'channels_first'),\n+                ((2, 3, 5, 6), (4, 3, 3, 4), 'channels_first'),\n+                ((1, 6, 5, 3), (3, 3, 3, 2), 'channels_last')]:\n+            check_two_tensor_operation('depthwise_conv2d',\n+                                       input_shape, kernel_shape,\n+                                       BACKENDS, cntk_dynamicity=True,\n+                                       data_format=data_format)\n+\n+        # Test invalid use cases\n+        for k in BACKENDS:\n+            with pytest.raises(ValueError):\n+                k.depthwise_conv2d(k.variable(np.ones(input_shape)),\n+                                   k.variable(np.ones(kernel_shape)),\n+                                   data_format='channels_middle')\n+\n     def test_conv3d(self):\n         # TH input shape: (samples, input_depth, conv_dim1, conv_dim2, conv_dim3)\n         # TF input shape: (samples, conv_dim1, conv_dim2, conv_dim3, input_depth)\n@@ -897,10 +916,6 @@ class TestBackend(object):\n             for z_i in np.split(z, 6, axis=1 if data_format == 'channels_first' else -1):\n                 assert_allclose(z_i, z_i[0] * np.ones_like(z_i))\n \n-        # Test invalid use cases\n-        with pytest.raises(ValueError):\n-            k.depthwise_conv2d(k.variable(x_val), k.variable(kernel_val), data_format='channels_middle')\n-\n     def test_pool2d(self):\n         check_single_tensor_operation('pool2d', (5, 10, 12, 3),\n                                       BACKENDS, cntk_dynamicity=True,\n\n@@ -332,6 +332,50 @@ def test_separable_conv_2d():\n                                                           batch_input_shape=(None, None, 5, None))])\n \n \n+@keras_test\n+def test_depthwise_conv_2d():\n+    num_samples = 2\n+    stack_size = 3\n+    num_row = 7\n+    num_col = 6\n+\n+    for padding in _convolution_paddings:\n+        for strides in [(1, 1), (2, 2)]:\n+            for multiplier in [1, 2]:\n+                if padding == 'same' and strides != (1, 1):\n+                    continue\n+\n+                layer_test(convolutional.DepthwiseConv2D,\n+                           kwargs={'kernel_size': (3, 3),\n+                                   'padding': padding,\n+                                   'strides': strides,\n+                                   'depth_multiplier': multiplier},\n+                           input_shape=(num_samples,\n+                                        num_row,\n+                                        num_col,\n+                                        stack_size))\n+\n+    layer_test(convolutional.DepthwiseConv2D,\n+               kwargs={'kernel_size': 3,\n+                       'padding': padding,\n+                       'data_format': 'channels_first',\n+                       'activation': None,\n+                       'depthwise_regularizer': 'l2',\n+                       'bias_regularizer': 'l2',\n+                       'activity_regularizer': 'l2',\n+                       'depthwise_constraint': 'unit_norm',\n+                       'strides': strides,\n+                       'depth_multiplier': multiplier},\n+               input_shape=(num_samples, stack_size, num_row, num_col))\n+\n+    # Test invalid use case\n+    with pytest.raises(ValueError):\n+        Sequential([convolutional.DepthwiseConv2D(\n+            kernel_size=3,\n+            padding=padding,\n+            batch_input_shape=(None, None, 5, None))])\n+\n+\n @keras_test\n def test_globalpooling_1d():\n     layer_test(pooling.GlobalMaxPooling1D,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c2a8450279d10796e8b4ca79d375e80d7b8e055c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 6 | Files Changed: 2 | Hunks: 9 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 16 | Churn Cumulative: 1697 | Contributors (this commit): 13 | Commits (past 90d): 8 | Contributors (cumulative): 17 | DMM Complexity: 1.0\n\nDIFF:\n@@ -64,6 +64,7 @@ from ..layers import Reshape\n from ..layers import BatchNormalization\n from ..layers import GlobalAveragePooling2D\n from ..layers import GlobalMaxPooling2D\n+from ..layers import ZeroPadding2D\n from ..layers import Conv2D\n from ..layers import DepthwiseConv2D\n from .. import initializers\n@@ -381,11 +382,12 @@ def _conv_block(inputs, filters, alpha, kernel=(3, 3), strides=(1, 1)):\n     \"\"\"\n     channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n     filters = int(filters * alpha)\n+    x = ZeroPadding2D(padding=(1, 1), name='conv1_pad')(inputs)\n     x = Conv2D(filters, kernel,\n-               padding='same',\n+               padding='valid',\n                use_bias=False,\n                strides=strides,\n-               name='conv1')(inputs)\n+               name='conv1')(x)\n     x = BatchNormalization(axis=channel_axis, name='conv1_bn')(x)\n     return Activation(relu6, name='conv1_relu')(x)\n \n@@ -442,12 +444,13 @@ def _depthwise_conv_block(inputs, pointwise_conv_filters, alpha,\n     channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n     pointwise_conv_filters = int(pointwise_conv_filters * alpha)\n \n+    x = ZeroPadding2D(padding=(1, 1), name='conv_pad_%d' % block_id)(inputs)\n     x = DepthwiseConv2D((3, 3),\n-                        padding='same',\n+                        padding='valid',\n                         depth_multiplier=depth_multiplier,\n                         strides=strides,\n                         use_bias=False,\n-                        name='conv_dw_%d' % block_id)(inputs)\n+                        name='conv_dw_%d' % block_id)(x)\n     x = BatchNormalization(axis=channel_axis, name='conv_dw_%d_bn' % block_id)(x)\n     x = Activation(relu6, name='conv_dw_%d_relu' % block_id)(x)\n \n\n@@ -24,6 +24,7 @@ from ..layers import MaxPooling2D\n from ..layers import AveragePooling2D\n from ..layers import GlobalAveragePooling2D\n from ..layers import GlobalMaxPooling2D\n+from ..layers import ZeroPadding2D\n from ..layers import BatchNormalization\n from ..models import Model\n from .. import backend as K\n@@ -209,8 +210,8 @@ def ResNet50(include_top=True, weights='imagenet',\n     else:\n         bn_axis = 1\n \n-    x = Conv2D(\n-        64, (7, 7), strides=(2, 2), padding='same', name='conv1')(img_input)\n+    x = ZeroPadding2D(padding=(3, 3), name='conv1_pad')(img_input)\n+    x = Conv2D(64, (7, 7), strides=(2, 2), padding='valid', name='conv1')(x)\n     x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n     x = Activation('relu')(x)\n     x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5e797436c3defd2d863ac1ffab11c48dbd42588e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 41 | Lines Deleted: 58 | Files Changed: 1 | Hunks: 9 | Methods Changed: 6 | Complexity Δ (Sum/Max): -4/0 | Churn Δ: 99 | Churn Cumulative: 3374 | Contributors (this commit): 21 | Commits (past 90d): 12 | Contributors (cumulative): 21 | DMM Complexity: 1.0\n\nDIFF:\n@@ -794,34 +794,16 @@ class TestBackend(object):\n                                        strides=strides,\n                                        data_format='channels_last')\n \n-        xval = np.random.random(input_shape)\n-        kernel_val = np.random.random(kernel_shape) - 0.5\n-        # Test invalid use cases\n-        for k in BACKENDS:\n-            with pytest.raises(ValueError):\n-                k.conv1d(k.variable(xval), k.variable(kernel_val), data_format='channels_middle')\n-\n     def test_conv2d(self):\n         # TF kernel shape: (rows, cols, input_depth, depth)\n         # channels_first input shape: (n, input_depth, rows, cols)\n-        for input_shape in [(2, 3, 4, 5), (2, 3, 5, 6)]:\n-            for kernel_shape in [(2, 2, 3, 4), (4, 3, 3, 4)]:\n+        for (input_shape, kernel_shape, data_format) in [\n+                ((2, 3, 4, 5), (2, 2, 3, 4), 'channels_first'),\n+                ((2, 3, 5, 6), (4, 3, 3, 4), 'channels_first'),\n+                ((1, 6, 5, 3), (3, 3, 3, 2), 'channels_last')]:\n             check_two_tensor_operation('conv2d', input_shape, kernel_shape,\n                                        BACKENDS, cntk_dynamicity=True,\n-                                           data_format='channels_first')\n-\n-        input_shape = (1, 6, 5, 3)\n-        kernel_shape = (3, 3, 3, 2)\n-        check_two_tensor_operation('conv2d', input_shape, kernel_shape,\n-                                   BACKENDS, cntk_dynamicity=True,\n-                                   data_format='channels_last')\n-\n-        xval = np.random.random(input_shape)\n-        kernel_val = np.random.random(kernel_shape) - 0.5\n-        # Test invalid use cases\n-        for k in BACKENDS:\n-            with pytest.raises(ValueError):\n-                k.conv2d(k.variable(xval), k.variable(kernel_val), data_format='channels_middle')\n+                                       data_format=data_format)\n \n     def test_depthwise_conv_2d(self):\n         # TF kernel shape: (rows, cols, input_depth, depth_multiplier)\n@@ -835,42 +817,22 @@ class TestBackend(object):\n                                        BACKENDS, cntk_dynamicity=True,\n                                        data_format=data_format)\n \n-        # Test invalid use cases\n-        for k in BACKENDS:\n-            with pytest.raises(ValueError):\n-                k.depthwise_conv2d(k.variable(np.ones(input_shape)),\n-                                   k.variable(np.ones(kernel_shape)),\n-                                   data_format='channels_middle')\n-\n     def test_conv3d(self):\n         # TH input shape: (samples, input_depth, conv_dim1, conv_dim2, conv_dim3)\n         # TF input shape: (samples, conv_dim1, conv_dim2, conv_dim3, input_depth)\n         # TH kernel shape: (depth, input_depth, x, y, z)\n         # TF kernel shape: (x, y, z, input_depth, depth)\n-\n-        # test in data_format = channels_first\n-        for input_shape in [(2, 3, 4, 5, 4), (2, 3, 5, 4, 6)]:\n-            for kernel_shape in [(2, 2, 2, 3, 4), (3, 2, 4, 3, 4)]:\n+        for (input_shape, kernel_shape, data_format) in [\n+                ((2, 3, 4, 5, 4), (2, 2, 2, 3, 4), 'channels_first'),\n+                ((2, 3, 5, 4, 6), (3, 2, 4, 3, 4), 'channels_first'),\n+                ((1, 2, 2, 2, 1), (2, 2, 2, 1, 1), 'channels_last')]:\n             check_two_tensor_operation('conv3d', input_shape, kernel_shape,\n                                        BACKENDS, cntk_dynamicity=True,\n-                                           data_format='channels_first')\n-\n-        # test in data_format = channels_last\n-        input_shape = (1, 2, 2, 2, 1)\n-        kernel_shape = (2, 2, 2, 1, 1)\n-        check_two_tensor_operation('conv3d', input_shape, kernel_shape,\n-                                   BACKENDS, cntk_dynamicity=True,\n-                                   data_format='channels_last')\n-\n-        xval = np.random.random(input_shape)\n-        kernel_val = np.random.random(kernel_shape) - 0.5\n-        # Test invalid use cases\n-        for k in BACKENDS:\n-            with pytest.raises(ValueError):\n-                k.conv3d(k.variable(xval), k.variable(kernel_val), data_format='channels_middle')\n+                                       data_format=data_format)\n \n     def test_separable_conv2d(self):\n-        for (input_shape, data_format) in [((2, 3, 4, 5), 'channels_first'),\n+        for (input_shape, data_format) in [\n+                ((2, 3, 4, 5), 'channels_first'),\n                 ((2, 3, 5, 6), 'channels_first'),\n                 ((1, 6, 5, 3), 'channels_last')]:\n             input_depth = input_shape[1] if data_format == 'channels_first' else input_shape[-1]\n@@ -890,14 +852,6 @@ class TestBackend(object):\n                                                  data_format=data_format)([x_val])[0]\n                     assert_allclose(z_tf, z_c, 1e-3)\n \n-        # Test invalid use cases\n-        for k in [KTF, KC]:\n-            with pytest.raises(ValueError):\n-                k.separable_conv2d(k.variable(x_val),\n-                                   k.variable(depthwise_val),\n-                                   k.variable(pointwise_val),\n-                                   data_format='channels_middle')\n-\n     @pytest.mark.parametrize('k', [KTF], ids=['TensorFlow'])\n     def test_depthwise_conv_2d(self, k):\n         for data_format in ['channels_first', 'channels_last']:\n@@ -981,6 +935,35 @@ class TestBackend(object):\n             assert np.max(rand) == 1\n             assert np.min(rand) == 0\n \n+    def test_conv_invalid_use(self):\n+        for k in BACKENDS:\n+            with pytest.raises(ValueError):\n+                k.conv1d(k.variable(np.ones((4, 8, 2))),\n+                         k.variable(np.ones((3, 2, 3))),\n+                         data_format='channels_middle')\n+\n+            with pytest.raises(ValueError):\n+                k.conv2d(k.variable(np.ones((2, 3, 4, 5))),\n+                         k.variable(np.ones((2, 2, 3, 4))),\n+                         data_format='channels_middle')\n+\n+            with pytest.raises(ValueError):\n+                k.conv3d(k.variable(np.ones((2, 3, 4, 5, 4))),\n+                         k.variable(np.ones((2, 2, 2, 3, 4))),\n+                         data_format='channels_middle')\n+\n+            if k != KTH:\n+                with pytest.raises(ValueError):\n+                    k.separable_conv2d(k.variable(np.ones((2, 3, 4, 5))),\n+                                       k.variable(np.ones((2, 2, 3, 4))),\n+                                       k.variable(np.ones((1, 1, 12, 7))),\n+                                       data_format='channels_middle')\n+\n+            with pytest.raises(ValueError):\n+                k.depthwise_conv2d(k.variable(np.ones((2, 3, 4, 5))),\n+                                   k.variable(np.ones((2, 2, 3, 4))),\n+                                   data_format='channels_middle')\n+\n     def test_pooling_invalid_use(self):\n         for (input_shape, pool_size) in zip([(5, 10, 12, 3), (5, 10, 12, 6, 3)], [(2, 2), (2, 2, 2)]):\n             for k in BACKENDS:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#07c77c65b5ea9c246690d2eb116c7c8570dc5a7e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 11 | Churn Cumulative: 8851 | Contributors (this commit): 87 | Commits (past 90d): 18 | Contributors (cumulative): 101 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2171,14 +2171,10 @@ def pool2d(x, pool_size, strides=(1, 1), padding='valid',\n                                 pad=pad,\n                                 mode='max')\n     elif pool_mode == 'avg':\n-        if padding == 'same':\n-            th_avg_pool_mode = 'average_inc_pad'\n-        elif padding == 'valid':\n-            th_avg_pool_mode = 'average_exc_pad'\n         pool_out = pool.pool_2d(x, ws=pool_size, stride=strides,\n                                 ignore_border=True,\n                                 pad=pad,\n-                                mode=th_avg_pool_mode)\n+                                mode='average_exc_pad')\n     else:\n         raise ValueError('Invalid pooling mode:', pool_mode)\n     if padding == 'same':\n\n@@ -887,6 +887,11 @@ class TestBackend(object):\n                                       BACKENDS, cntk_dynamicity=True,\n                                       pool_size=(2, 3), strides=(1, 1), padding='valid')\n \n+        check_single_tensor_operation('pool2d', (2, 7, 7, 5),\n+                                      BACKENDS, cntk_dynamicity=True,\n+                                      pool_size=(3, 3), strides=(1, 1),\n+                                      padding='same', pool_mode='avg')\n+\n     def test_pool3d(self):\n         check_single_tensor_operation('pool3d', (5, 10, 12, 5, 3),\n                                       BACKENDS, cntk_dynamicity=True,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a82ad3a617b6c8192688c022c7df3fde71fe91f7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 9373 | Contributors (this commit): 107 | Commits (past 90d): 24 | Contributors (cumulative): 107 | DMM Complexity: None\n\nDIFF:\n@@ -3148,7 +3148,7 @@ def l2_normalize(x, axis=None):\n     # Returns\n         A tensor.\n     \"\"\"\n-    return tf.nn.l2_normalize(x, dim=axis)\n+    return tf.nn.l2_normalize(x, axis=axis)\n \n \n def in_top_k(predictions, targets, k):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6b2a04f3af0eb53d4cd9abcbf60593c0e086c027", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1141 | Contributors (this commit): 8 | Commits (past 90d): 5 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -302,7 +302,7 @@ def MobileNet(input_shape=None,\n     # load weights\n     if weights == 'imagenet':\n         if K.image_data_format() == 'channels_first':\n-            raise ValueError('Weights for \"channels_last\" format '\n+            raise ValueError('Weights for \"channels_first\" format '\n                              'are not available.')\n         if alpha == 1.0:\n             alpha_text = '1_0'\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4b74fc5418944c9f449eb88ed4b40ada280fa5ca", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 43 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 8 | Methods Changed: 7 | Complexity Δ (Sum/Max): 10/4 | Churn Δ: 43 | Churn Cumulative: 8937 | Contributors (this commit): 90 | Commits (past 90d): 44 | Contributors (cumulative): 109 | DMM Complexity: 0.6470588235294118\n\nDIFF:\n@@ -2161,6 +2161,9 @@ class Model(Container):\n                                 wait_time=wait_time)\n                         val_enqueuer.start(workers=workers, max_queue_size=max_queue_size)\n                         validation_generator = val_enqueuer.get()\n+                    else:\n+                        if isinstance(validation_data, Sequence):\n+                            validation_generator = iter(validation_data)\n                         else:\n                             validation_generator = validation_data\n                 else:\n@@ -2193,6 +2196,9 @@ class Model(Container):\n                                                  wait_time=wait_time)\n                 enqueuer.start(workers=workers, max_queue_size=max_queue_size)\n                 output_generator = enqueuer.get()\n+            else:\n+                if is_sequence:\n+                    output_generator = iter(generator)\n                 else:\n                     output_generator = generator\n \n@@ -2365,6 +2371,9 @@ class Model(Container):\n                                                  wait_time=wait_time)\n                 enqueuer.start(workers=workers, max_queue_size=max_queue_size)\n                 output_generator = enqueuer.get()\n+            else:\n+                if is_sequence:\n+                    output_generator = iter(generator)\n                 else:\n                     output_generator = generator\n \n@@ -2489,6 +2498,9 @@ class Model(Container):\n                                                  wait_time=wait_time)\n                 enqueuer.start(workers=workers, max_queue_size=max_queue_size)\n                 output_generator = enqueuer.get()\n+            else:\n+                if is_sequence:\n+                    output_generator = iter(generator)\n                 else:\n                     output_generator = generator\n \n\n@@ -366,6 +366,12 @@ class Sequence(object):\n         \"\"\"\n         pass\n \n+    def __iter__(self):\n+        \"\"\"Create an infinite generator that iterate over the Sequence.\"\"\"\n+        while True:\n+            for item in (self[i] for i in range(len(self))):\n+                yield item\n+\n \n # Global variables to be shared across processes\n _SHARED_SEQUENCES = {}\n\n@@ -6,12 +6,21 @@ import numpy as np\n from keras.models import Sequential\n from keras.layers.core import Dense\n from keras.utils.test_utils import keras_test\n+from keras.utils import Sequence\n \n STEPS_PER_EPOCH = 100\n STEPS = 100\n WORKERS = 4\n \n \n+class DummySequence(Sequence):\n+    def __getitem__(self, idx):\n+        return np.zeros([10, 2]), np.ones([10])\n+\n+    def __len__(self):\n+        return 10\n+\n+\n @pytest.fixture\n def in_tmpdir(tmpdir):\n     \"\"\"Runs a function in a temporary directory.\n@@ -175,6 +184,22 @@ def test_multiprocessing_training():\n                         workers=0,\n                         use_multiprocessing=False)\n \n+    # - For Sequence\n+    model.fit_generator(DummySequence(),\n+                        steps_per_epoch=STEPS_PER_EPOCH,\n+                        validation_data=custom_generator(True),\n+                        validation_steps=1,\n+                        max_queue_size=10,\n+                        workers=0,\n+                        use_multiprocessing=True)\n+    model.fit_generator(DummySequence(),\n+                        steps_per_epoch=STEPS_PER_EPOCH,\n+                        validation_data=custom_generator(True),\n+                        validation_steps=1,\n+                        max_queue_size=10,\n+                        workers=0,\n+                        use_multiprocessing=False)\n+\n     # Test invalid use cases\n     def invalid_generator():\n         while True:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
