{"custom_id": "keras#ce1e8230d8f670f4d600bee36e2749bfd61da97d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 399 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 7 | Methods Changed: 14 | Complexity Δ (Sum/Max): 18/10 | Churn Δ: 399 | Churn Cumulative: 1763 | Contributors (this commit): 2 | Commits (past 90d): 17 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -15,6 +15,7 @@ from keras_core.applications import mobilenet_v2\n from keras_core.applications import mobilenet_v3\n from keras_core.applications import nasnet\n from keras_core.applications import resnet\n+from keras_core.applications import resnet_v2\n from keras_core.applications import vgg16\n from keras_core.applications import vgg19\n from keras_core.applications import xception\n@@ -72,6 +73,11 @@ MODEL_LIST = [\n     (nasnet.NASNetLarge, 4032, nasnet),\n     # resnet\n     (resnet.ResNet50, 2048, resnet),\n+    (resnet.ResNet101, 2048, resnet),\n+    (resnet.ResNet152, 2048, resnet),\n+    (resnet_v2.ResNet50V2, 2048, resnet_v2),\n+    (resnet_v2.ResNet101V2, 2048, resnet_v2),\n+    (resnet_v2.ResNet152V2, 2048, resnet_v2),\n ]\n # Add names for `named_parameters`.\n MODEL_LIST = [(e[0].__name__, *e) for e in MODEL_LIST]\n\n@@ -16,6 +16,34 @@ WEIGHTS_HASHES = {\n         \"2cb95161c43110f7111970584f804107\",\n         \"4d473c1dd8becc155b73f8504c6f6626\",\n     ),\n+    \"resnet101\": (\n+        \"f1aeb4b969a6efcfb50fad2f0c20cfc5\",\n+        \"88cf7a10940856eca736dc7b7e228a21\",\n+    ),\n+    \"resnet152\": (\n+        \"100835be76be38e30d865e96f2aaae62\",\n+        \"ee4c566cf9a93f14d82f913c2dc6dd0c\",\n+    ),\n+    \"resnet50v2\": (\n+        \"3ef43a0b657b3be2300d5770ece849e0\",\n+        \"fac2f116257151a9d068a22e544a4917\",\n+    ),\n+    \"resnet101v2\": (\n+        \"6343647c601c52e1368623803854d971\",\n+        \"c0ed64b8031c3730f411d2eb4eea35b5\",\n+    ),\n+    \"resnet152v2\": (\n+        \"a49b44d1979771252814e80f8ec446f9\",\n+        \"ed17cf2e0169df9d443503ef94b23b33\",\n+    ),\n+    \"resnext50\": (\n+        \"67a5b30d522ed92f75a1f16eef299d1a\",\n+        \"62527c363bdd9ec598bed41947b379fc\",\n+    ),\n+    \"resnext101\": (\n+        \"34fb605428fcc7aa4d62f44404c11509\",\n+        \"0f678c91647380debd923963594981b3\",\n+    ),\n }\n \n \n@@ -267,6 +295,92 @@ def stack_residual_blocks_v1(x, filters, blocks, stride1=2, name=None):\n     return x\n \n \n+def residual_block_v2(\n+    x, filters, kernel_size=3, stride=1, conv_shortcut=False, name=None\n+):\n+    \"\"\"A residual block for ResNet*_v2.\n+\n+    Args:\n+        x: Input tensor.\n+        filters: No of filters in the bottleneck layer.\n+        kernel_size: Kernel size of the bottleneck layer. Defaults to 3\n+        stride: Stride of the first layer. Defaults to 1\n+        conv_shortcut: Use convolution shortcut if `True`, otherwise\n+            use identity shortcut. Defaults to `True`\n+        name(optional): Name of the block\n+\n+    Returns:\n+        Output tensor for the residual block.\n+    \"\"\"\n+\n+    if backend.image_data_format() == \"channels_last\":\n+        bn_axis = 3\n+    else:\n+        bn_axis = 1\n+\n+    preact = layers.BatchNormalization(\n+        axis=bn_axis, epsilon=1.001e-5, name=name + \"_preact_bn\"\n+    )(x)\n+    preact = layers.Activation(\"relu\", name=name + \"_preact_relu\")(preact)\n+\n+    if conv_shortcut:\n+        shortcut = layers.Conv2D(\n+            4 * filters, 1, strides=stride, name=name + \"_0_conv\"\n+        )(preact)\n+    else:\n+        shortcut = (\n+            layers.MaxPooling2D(1, strides=stride)(x) if stride > 1 else x\n+        )\n+\n+    x = layers.Conv2D(\n+        filters, 1, strides=1, use_bias=False, name=name + \"_1_conv\"\n+    )(preact)\n+    x = layers.BatchNormalization(\n+        axis=bn_axis, epsilon=1.001e-5, name=name + \"_1_bn\"\n+    )(x)\n+    x = layers.Activation(\"relu\", name=name + \"_1_relu\")(x)\n+\n+    x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name=name + \"_2_pad\")(x)\n+    x = layers.Conv2D(\n+        filters,\n+        kernel_size,\n+        strides=stride,\n+        use_bias=False,\n+        name=name + \"_2_conv\",\n+    )(x)\n+    x = layers.BatchNormalization(\n+        axis=bn_axis, epsilon=1.001e-5, name=name + \"_2_bn\"\n+    )(x)\n+    x = layers.Activation(\"relu\", name=name + \"_2_relu\")(x)\n+\n+    x = layers.Conv2D(4 * filters, 1, name=name + \"_3_conv\")(x)\n+    x = layers.Add(name=name + \"_out\")([shortcut, x])\n+    return x\n+\n+\n+def stack_residual_blocks_v2(x, filters, blocks, stride1=2, name=None):\n+    \"\"\"A set of stacked residual blocks.\n+\n+    Args:\n+        x: Input tensor.\n+        filters: Number of filters in the bottleneck layer in a block.\n+        blocks: Number of blocks in the stacked blocks.\n+        stride1: Stride of the first layer in the first block. Defaults to 2.\n+        name: Stack label.\n+\n+    Returns:\n+        Output tensor for the stacked blocks.\n+    \"\"\"\n+\n+    x = residual_block_v2(x, filters, conv_shortcut=True, name=name + \"_block1\")\n+    for i in range(2, blocks):\n+        x = residual_block_v2(x, filters, name=name + \"_block\" + str(i))\n+    x = residual_block_v2(\n+        x, filters, stride=stride1, name=name + \"_block\" + str(blocks)\n+    )\n+    return x\n+\n+\n @keras_core_export(\n     [\n         \"keras_core.applications.resnet50.ResNet50\",\n@@ -306,6 +420,82 @@ def ResNet50(\n     )\n \n \n+@keras_core_export(\n+    [\n+        \"keras_core.applications.resnet.ResNet101\",\n+        \"keras_core.applications.ResNet101\",\n+    ]\n+)\n+def ResNet101(\n+    include_top=True,\n+    weights=\"imagenet\",\n+    input_tensor=None,\n+    input_shape=None,\n+    pooling=None,\n+    classes=1000,\n+    classifier_activation=\"softmax\",\n+):\n+    \"\"\"Instantiates the ResNet101 architecture.\"\"\"\n+\n+    def stack_fn(x):\n+        x = stack_residual_blocks_v1(x, 64, 3, stride1=1, name=\"conv2\")\n+        x = stack_residual_blocks_v1(x, 128, 4, name=\"conv3\")\n+        x = stack_residual_blocks_v1(x, 256, 23, name=\"conv4\")\n+        return stack_residual_blocks_v1(x, 512, 3, name=\"conv5\")\n+\n+    return ResNet(\n+        stack_fn,\n+        False,\n+        True,\n+        \"resnet101\",\n+        include_top,\n+        weights,\n+        input_tensor,\n+        input_shape,\n+        pooling,\n+        classes,\n+        classifier_activation=classifier_activation,\n+    )\n+\n+\n+@keras_core_export(\n+    [\n+        \"keras_core.applications.resnet.ResNet152\",\n+        \"keras_core.applications.ResNet152\",\n+    ]\n+)\n+def ResNet152(\n+    include_top=True,\n+    weights=\"imagenet\",\n+    input_tensor=None,\n+    input_shape=None,\n+    pooling=None,\n+    classes=1000,\n+    classifier_activation=\"softmax\",\n+):\n+    \"\"\"Instantiates the ResNet152 architecture.\"\"\"\n+\n+    def stack_fn(x):\n+        x = stack_residual_blocks_v1(x, 64, 3, stride1=1, name=\"conv2\")\n+        x = stack_residual_blocks_v1(x, 128, 8, name=\"conv3\")\n+        x = stack_residual_blocks_v1(x, 256, 36, name=\"conv4\")\n+        return stack_residual_blocks_v1(x, 512, 3, name=\"conv5\")\n+\n+    return ResNet(\n+        stack_fn,\n+        False,\n+        True,\n+        \"resnet152\",\n+        include_top,\n+        weights,\n+        input_tensor,\n+        input_shape,\n+        pooling,\n+        classes,\n+        classifier_activation=classifier_activation,\n+    )\n+\n+\n @keras_core_export(\n     [\n         \"keras_core.applications.resnet50.preprocess_input\",\n@@ -390,3 +580,5 @@ Returns:\n \"\"\"\n \n setattr(ResNet50, \"__doc__\", ResNet50.__doc__ + DOC)\n+setattr(ResNet101, \"__doc__\", ResNet101.__doc__ + DOC)\n+setattr(ResNet152, \"__doc__\", ResNet152.__doc__ + DOC)\n\n@@ -0,0 +1,201 @@\n+from keras_core.api_export import keras_core_export\n+from keras_core.applications import imagenet_utils\n+from keras_core.applications import resnet\n+\n+\n+@keras_core_export(\n+    [\n+        \"keras_core.applications.resnet_v2.ResNet50V2\",\n+        \"keras_core.applications.resnet_v2.ResNet50V2\",\n+    ]\n+)\n+def ResNet50V2(\n+    include_top=True,\n+    weights=\"imagenet\",\n+    input_tensor=None,\n+    input_shape=None,\n+    pooling=None,\n+    classes=1000,\n+    classifier_activation=\"softmax\",\n+):\n+    \"\"\"Instantiates the ResNet50V2 architecture.\"\"\"\n+\n+    def stack_fn(x):\n+        x = resnet.stack_residual_blocks_v2(x, 64, 3, name=\"conv2\")\n+        x = resnet.stack_residual_blocks_v2(x, 128, 4, name=\"conv3\")\n+        x = resnet.stack_residual_blocks_v2(x, 256, 6, name=\"conv4\")\n+        return resnet.stack_residual_blocks_v2(\n+            x, 512, 3, stride1=1, name=\"conv5\"\n+        )\n+\n+    return resnet.ResNet(\n+        stack_fn,\n+        True,\n+        True,\n+        \"resnet50v2\",\n+        include_top,\n+        weights,\n+        input_tensor,\n+        input_shape,\n+        pooling,\n+        classes,\n+        classifier_activation=classifier_activation,\n+    )\n+\n+\n+@keras_core_export(\n+    [\n+        \"keras_core.applications.resnet_v2.ResNet101V2\",\n+        \"keras_core.applications.resnet_v2.ResNet101V2\",\n+    ]\n+)\n+def ResNet101V2(\n+    include_top=True,\n+    weights=\"imagenet\",\n+    input_tensor=None,\n+    input_shape=None,\n+    pooling=None,\n+    classes=1000,\n+    classifier_activation=\"softmax\",\n+):\n+    \"\"\"Instantiates the ResNet101V2 architecture.\"\"\"\n+\n+    def stack_fn(x):\n+        x = resnet.stack_residual_blocks_v2(x, 64, 3, name=\"conv2\")\n+        x = resnet.stack_residual_blocks_v2(x, 128, 4, name=\"conv3\")\n+        x = resnet.stack_residual_blocks_v2(x, 256, 23, name=\"conv4\")\n+        return resnet.stack_residual_blocks_v2(\n+            x, 512, 3, stride1=1, name=\"conv5\"\n+        )\n+\n+    return resnet.ResNet(\n+        stack_fn,\n+        True,\n+        True,\n+        \"resnet101v2\",\n+        include_top,\n+        weights,\n+        input_tensor,\n+        input_shape,\n+        pooling,\n+        classes,\n+        classifier_activation=classifier_activation,\n+    )\n+\n+\n+@keras_core_export(\n+    [\n+        \"keras_core.applications.resnet_v2.ResNet152V2\",\n+        \"keras_core.applications.resnet_v2.ResNet152V2\",\n+    ]\n+)\n+def ResNet152V2(\n+    include_top=True,\n+    weights=\"imagenet\",\n+    input_tensor=None,\n+    input_shape=None,\n+    pooling=None,\n+    classes=1000,\n+    classifier_activation=\"softmax\",\n+):\n+    \"\"\"Instantiates the ResNet152V2 architecture.\"\"\"\n+\n+    def stack_fn(x):\n+        x = resnet.stack_residual_blocks_v2(x, 64, 3, name=\"conv2\")\n+        x = resnet.stack_residual_blocks_v2(x, 128, 8, name=\"conv3\")\n+        x = resnet.stack_residual_blocks_v2(x, 256, 36, name=\"conv4\")\n+        return resnet.stack_residual_blocks_v2(\n+            x, 512, 3, stride1=1, name=\"conv5\"\n+        )\n+\n+    return resnet.ResNet(\n+        stack_fn,\n+        True,\n+        True,\n+        \"resnet152v2\",\n+        include_top,\n+        weights,\n+        input_tensor,\n+        input_shape,\n+        pooling,\n+        classes,\n+        classifier_activation=classifier_activation,\n+    )\n+\n+\n+@keras_core_export(\"keras_core.applications.resnet_v2.preprocess_input\")\n+def preprocess_input(x, data_format=None):\n+    return imagenet_utils.preprocess_input(\n+        x, data_format=data_format, mode=\"tf\"\n+    )\n+\n+\n+@keras_core_export(\"keras_core.applications.resnet_v2.decode_predictions\")\n+def decode_predictions(preds, top=5):\n+    return imagenet_utils.decode_predictions(preds, top=top)\n+\n+\n+preprocess_input.__doc__ = imagenet_utils.PREPROCESS_INPUT_DOC.format(\n+    mode=\"\",\n+    ret=imagenet_utils.PREPROCESS_INPUT_RET_DOC_TF,\n+    error=imagenet_utils.PREPROCESS_INPUT_ERROR_DOC,\n+)\n+decode_predictions.__doc__ = imagenet_utils.decode_predictions.__doc__\n+\n+\n+DOC = \"\"\"\n+\n+Reference:\n+- [Identity Mappings in Deep Residual Networks](\n+    https://arxiv.org/abs/1603.05027) (CVPR 2016)\n+\n+For image classification use cases, see [this page for detailed examples](\n+    https://keras.io/api/applications/#usage-examples-for-image-classification-models).\n+\n+For transfer learning use cases, make sure to read the\n+[guide to transfer learning & fine-tuning](\n+    https://keras.io/guides/transfer_learning/).\n+\n+Note: each Keras Application expects a specific kind of input preprocessing.\n+For ResNet, call `keras_core.applications.resnet_v2.preprocess_input` on your\n+inputs before passing them to the model. `resnet_v2.preprocess_input` will\n+scale input pixels between -1 and 1.\n+\n+Args:\n+    include_top: whether to include the fully-connected\n+        layer at the top of the network.\n+    weights: one of `None` (random initialization),\n+        `\"imagenet\"` (pre-training on ImageNet), or the path to the weights\n+        file to be loaded.\n+    input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n+        to use as image input for the model.\n+    input_shape: optional shape tuple, only to be specified if `include_top`\n+        is `False` (otherwise the input shape has to be `(224, 224, 3)`\n+        (with `\"channels_last\"` data format) or `(3, 224, 224)`\n+        (with `\"channels_first\"` data format). It should have exactly 3\n+        inputs channels, and width and height should be no smaller than 32.\n+        E.g. `(200, 200, 3)` would be one valid value.\n+    pooling: Optional pooling mode for feature extraction when `include_top`\n+        is `False`.\n+        - `None` means that the output of the model will be the 4D tensor\n+                output of the last convolutional block.\n+        - `avg` means that global average pooling will be applied to the output\n+                of the last convolutional block, and thus the output of the\n+                model will be a 2D tensor.\n+        - `max` means that global max pooling will be applied.\n+    classes: optional number of classes to classify images into, only to be\n+        specified if `include_top` is `True`, and if no `weights` argument is\n+        specified.\n+    classifier_activation: A `str` or callable. The activation function to\n+        use on the \"top\" layer. Ignored unless `include_top=True`. Set\n+        `classifier_activation=None` to return the logits of the \"top\" layer.\n+        When loading pretrained weights, `classifier_activation` can only\n+        be `None` or `\"softmax\"`.\n+\n+Returns:\n+    A Model instance.\n+\"\"\"\n+\n+setattr(ResNet50V2, \"__doc__\", ResNet50V2.__doc__ + DOC)\n+setattr(ResNet101V2, \"__doc__\", ResNet101V2.__doc__ + DOC)\n+setattr(ResNet152V2, \"__doc__\", ResNet152V2.__doc__ + DOC)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7b38c2389347e222d5065a8c927c5117a4beb1aa", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 281 | Lines Deleted: 101 | Files Changed: 4 | Hunks: 30 | Methods Changed: 21 | Complexity Δ (Sum/Max): 20/20 | Churn Δ: 382 | Churn Cumulative: 5223 | Contributors (this commit): 9 | Commits (past 90d): 60 | Contributors (cumulative): 19 | DMM Complexity: 0.12883435582822086\n\nDIFF:\n@@ -78,3 +78,78 @@ def compute_conv_transpose_output_shape(\n     else:\n         output_shape = [input_shape[0], filters] + output_shape\n     return output_shape\n+\n+\n+def _compute_conv_transpose_padding_one_dim(\n+    input_length,\n+    output_length,\n+    kernel_size,\n+    stride,\n+    padding,\n+    dilation_rate,\n+):\n+    \"\"\"Computes adjusted padding for `conv_transpose` in one dim.\"\"\"\n+    kernel_size = (kernel_size - 1) * dilation_rate + 1\n+    if padding == \"valid\":\n+        padding_before = 0\n+    else:\n+        # padding == \"same\".\n+        padding_needed = max(\n+            0, (input_length - 1) * stride + kernel_size - output_length\n+        )\n+        padding_before = padding_needed // 2\n+\n+    expanded_input_length = (input_length - 1) * stride + 1\n+    padded_out_length = output_length + kernel_size - 1\n+    pad_before = kernel_size - 1 - padding_before\n+    pad_after = padded_out_length - expanded_input_length - pad_before\n+    return (pad_before, pad_after)\n+\n+\n+def compute_conv_transpose_padding(\n+    input_shape,\n+    kernel_shape,\n+    strides=1,\n+    padding=\"valid\",\n+    output_padding=None,\n+    data_format=\"channels_last\",\n+    dilation_rate=1,\n+):\n+    \"\"\"Computes adjusted padding for `conv_transpose`.\"\"\"\n+    num_spatial_dims = len(input_shape) - 2\n+    if isinstance(output_padding, int):\n+        output_padding = (output_padding,) * num_spatial_dims\n+    if isinstance(strides, int):\n+        strides = (strides,) * num_spatial_dims\n+    if isinstance(dilation_rate, int):\n+        dilation_rate = (dilation_rate,) * num_spatial_dims\n+\n+    kernel_spatial_shape = kernel_shape[:-2]\n+    if data_format == \"channels_last\":\n+        input_spatial_shape = input_shape[1:-1]\n+    else:\n+        input_spatial_shape = input_shape[2:]\n+    padding_values = []\n+    for i in range(num_spatial_dims):\n+        input_length = input_spatial_shape[i]\n+        current_output_padding = (\n+            None if output_padding is None else output_padding[i]\n+        )\n+        output_length = compute_conv_transpose_output_length(\n+            input_spatial_shape[i],\n+            kernel_spatial_shape[i],\n+            padding=padding,\n+            output_padding=current_output_padding,\n+            stride=strides[i],\n+            dilation=dilation_rate[i],\n+        )\n+        padding_value = _compute_conv_transpose_padding_one_dim(\n+            input_length,\n+            output_length,\n+            kernel_spatial_shape[i],\n+            strides[i],\n+            padding=padding,\n+            dilation_rate=dilation_rate[i],\n+        )\n+        padding_values.append(padding_value)\n+    return padding_values\n\n@@ -6,7 +6,7 @@ from jax import nn as jnn\n \n from keras_core.backend import standardize_data_format\n from keras_core.backend.common.backend_utils import (\n-    compute_conv_transpose_output_length,\n+    compute_conv_transpose_padding,\n )\n from keras_core.backend.config import epsilon\n from keras_core.backend.jax.core import convert_to_tensor\n@@ -338,81 +338,6 @@ def separable_conv(\n     )\n \n \n-def _compute_padding_value_one_dim(\n-    input_length,\n-    output_length,\n-    kernel_size,\n-    stride,\n-    padding,\n-    dilation_rate,\n-):\n-    \"\"\"Computes adjusted padding for `conv_transpose` in one dim.\"\"\"\n-    kernel_size = (kernel_size - 1) * dilation_rate + 1\n-    if padding == \"valid\":\n-        padding_before = 0\n-    else:\n-        # padding == \"same\".\n-        padding_needed = max(\n-            0, (input_length - 1) * stride + kernel_size - output_length\n-        )\n-        padding_before = padding_needed // 2\n-\n-    expanded_input_length = (input_length - 1) * stride + 1\n-    padded_out_length = output_length + kernel_size - 1\n-    pad_before = kernel_size - 1 - padding_before\n-    pad_after = padded_out_length - expanded_input_length - pad_before\n-    return (pad_before, pad_after)\n-\n-\n-def _compute_padding_values(\n-    input_shape,\n-    kernel_shape,\n-    strides=1,\n-    padding=\"valid\",\n-    output_padding=None,\n-    data_format=\"channels_last\",\n-    dilation_rate=1,\n-):\n-    \"\"\"Computes adjusted padding for `conv_transpose`.\"\"\"\n-    num_spatial_dims = len(input_shape) - 2\n-    if isinstance(output_padding, int):\n-        output_padding = (output_padding,) * num_spatial_dims\n-    if isinstance(strides, int):\n-        strides = (strides,) * num_spatial_dims\n-    if isinstance(dilation_rate, int):\n-        dilation_rate = (dilation_rate,) * num_spatial_dims\n-\n-    kernel_spatial_shape = kernel_shape[:-2]\n-    if data_format == \"channels_last\":\n-        input_spatial_shape = input_shape[1:-1]\n-    else:\n-        input_spatial_shape = input_shape[2:]\n-    padding_values = []\n-    for i in range(num_spatial_dims):\n-        input_length = input_spatial_shape[i]\n-        current_output_padding = (\n-            None if output_padding is None else output_padding[i]\n-        )\n-        output_length = compute_conv_transpose_output_length(\n-            input_spatial_shape[i],\n-            kernel_spatial_shape[i],\n-            padding=padding,\n-            output_padding=current_output_padding,\n-            stride=strides[i],\n-            dilation=dilation_rate[i],\n-        )\n-        padding_value = _compute_padding_value_one_dim(\n-            input_length,\n-            output_length,\n-            kernel_spatial_shape[i],\n-            strides[i],\n-            padding=padding,\n-            dilation_rate=dilation_rate[i],\n-        )\n-        padding_values.append(padding_value)\n-    return padding_values\n-\n-\n def conv_transpose(\n     inputs,\n     kernel,\n@@ -424,7 +349,7 @@ def conv_transpose(\n ):\n     data_format = standardize_data_format(data_format)\n     num_spatial_dims = inputs.ndim - 2\n-    padding_values = _compute_padding_values(\n+    padding_values = compute_conv_transpose_padding(\n         inputs.shape,\n         kernel.shape,\n         strides,\n\n@@ -3,6 +3,9 @@ import torch\n import torch.nn.functional as tnn\n \n from keras_core.backend import standardize_data_format\n+from keras_core.backend.common.backend_utils import (\n+    compute_conv_transpose_padding,\n+)\n from keras_core.backend.config import epsilon\n from keras_core.backend.torch.core import convert_to_tensor\n from keras_core.utils.argument_validation import standardize_tuple\n@@ -101,23 +104,45 @@ def log_softmax(x, axis=None):\n     return tnn.log_softmax(logits, dim=axis)\n \n \n-def _compute_padding_length(kernel_length):\n+def _compute_padding_length(\n+    input_length, kernel_length, stride, dilation_rate=1\n+):\n     \"\"\"Compute padding length along one dimension.\"\"\"\n-    total_padding_length = kernel_length - 1\n+    if (input_length - 1) % stride == 0:\n+        total_padding_length = dilation_rate * (kernel_length - 1)\n+    else:\n+        total_padding_length = (\n+            dilation_rate * (kernel_length - 1) - (input_length - 1) % stride\n+        )\n     left_padding = int(np.floor(total_padding_length / 2))\n     right_padding = int(np.ceil(total_padding_length / 2))\n     return (left_padding, right_padding)\n \n \n-def _apply_same_padding(inputs, kernel_size):\n+def _apply_same_padding(\n+    inputs, kernel_size, strides, operation_type, dilation_rate=1\n+):\n     spatial_shape = inputs.shape[2:]\n     num_spatial_dims = len(spatial_shape)\n     padding = ()\n+\n     for i in range(num_spatial_dims):\n-        padding_size = _compute_padding_length(kernel_size[i])\n+        if operation_type == \"pooling\":\n+            padding_size = _compute_padding_length(\n+                spatial_shape[i], kernel_size[i], strides[i]\n+            )\n+            mode = \"replicate\"\n+        else:\n+            dilation_rate = standardize_tuple(\n+                dilation_rate, num_spatial_dims, \"dilation_rate\"\n+            )\n+            padding_size = _compute_padding_length(\n+                spatial_shape[i], kernel_size[i], strides[i], dilation_rate[i]\n+            )\n+            mode = \"constant\"\n         padding = padding_size + padding\n \n-    return tnn.pad(inputs, padding, mode=\"replicate\")\n+    return tnn.pad(inputs, padding, mode=mode)\n \n \n def _transpose_spatial_inputs(inputs):\n@@ -150,6 +175,19 @@ def _transpose_spatial_outputs(outputs):\n     return outputs\n \n \n+def _transpose_conv_kernel(kernel):\n+    # Torch requires conv kernel of format\n+    # `(out_channels, in_channels, spatial_dims)`, we need to transpose.\n+    num_spatial_dims = len(kernel.shape) - 2\n+    if num_spatial_dims == 1:\n+        kernel = torch.permute(kernel, (2, 1, 0))\n+    elif num_spatial_dims == 2:\n+        kernel = torch.permute(kernel, (3, 2, 0, 1))\n+    elif num_spatial_dims == 3:\n+        kernel = torch.permute(kernel, (4, 3, 0, 1, 2))\n+    return kernel\n+\n+\n def max_pool(\n     inputs,\n     pool_size,\n@@ -172,7 +210,9 @@ def max_pool(\n     if padding == \"same\":\n         # Torch does not natively support `\"same\"` padding, we need to manually\n         # apply the right amount of padding to `inputs`.\n-        inputs = _apply_same_padding(inputs, pool_size)\n+        inputs = _apply_same_padding(\n+            inputs, pool_size, strides, operation_type=\"pooling\"\n+        )\n \n     if num_spatial_dims == 1:\n         outputs = tnn.max_pool1d(inputs, kernel_size=pool_size, stride=strides)\n@@ -182,9 +222,8 @@ def max_pool(\n         outputs = tnn.max_pool3d(inputs, kernel_size=pool_size, stride=strides)\n     else:\n         raise ValueError(\n-            \"Inputs to pooling operation must have ndim=3, 4, or 5 \"\n-            \"corresponding to 1D, 2D and 3D inputs. Received: \"\n-            f\"inputs.shape={inputs.shape}.\"\n+            \"Pooling inputs's shape must be 3, 4 or 5, corresponding to 1D, 2D \"\n+            f\"and 3D inputs. But received shape: {inputs.shape}.\"\n         )\n     if data_format == \"channels_last\":\n         outputs = _transpose_spatial_outputs(outputs)\n@@ -213,7 +252,9 @@ def average_pool(\n     if padding == \"same\":\n         # Torch does not natively support `\"same\"` padding, we need to manually\n         # apply the right amount of padding to `inputs`.\n-        inputs = _apply_same_padding(inputs, pool_size)\n+        inputs = _apply_same_padding(\n+            inputs, pool_size, strides, operation_type=\"pooling\"\n+        )\n \n     if num_spatial_dims == 1:\n         outputs = tnn.avg_pool1d(inputs, kernel_size=pool_size, stride=strides)\n@@ -223,9 +264,8 @@ def average_pool(\n         outputs = tnn.avg_pool3d(inputs, kernel_size=pool_size, stride=strides)\n     else:\n         raise ValueError(\n-            \"Inputs to pooling operation must have ndim=3, 4, or 5 \"\n-            \"corresponding to 1D, 2D and 3D inputs. Received: \"\n-            f\"inputs.shape={inputs.shape}.\"\n+            \"Pooling inputs's shape must be 3, 4 or 5, corresponding to 1D, 2D \"\n+            f\"and 3D inputs. But received shape: {inputs.shape}.\"\n         )\n     if data_format == \"channels_last\":\n         outputs = _transpose_spatial_outputs(outputs)\n@@ -237,10 +277,70 @@ def conv(\n     kernel,\n     strides=1,\n     padding=\"valid\",\n-    data_format=\"channels_last\",\n+    data_format=None,\n     dilation_rate=1,\n ):\n-    raise NotImplementedError(\"`conv` not yet implemented for PyTorch Backend\")\n+    inputs = convert_to_tensor(inputs)\n+    kernel = convert_to_tensor(kernel)\n+    num_spatial_dims = inputs.ndim - 2\n+    strides = standardize_tuple(strides, num_spatial_dims, \"strides\")\n+\n+    data_format = standardize_data_format(data_format)\n+    if data_format == \"channels_last\":\n+        inputs = _transpose_spatial_inputs(inputs)\n+    # Transpose kernel from keras format to torch format.\n+    kernel = _transpose_conv_kernel(kernel)\n+    if padding == \"same\":\n+        inputs = _apply_same_padding(\n+            inputs,\n+            kernel.shape[2:],\n+            strides,\n+            operation_type=\"conv\",\n+            dilation_rate=dilation_rate,\n+        )\n+    channels = inputs.shape[1]\n+    kernel_in_channels = kernel.shape[1]\n+    if channels % kernel_in_channels > 0:\n+        raise ValueError(\n+            \"The number of input channels must be evenly divisible by \"\n+            f\"kernel's in_channels. Received input shape {inputs.shape} and \"\n+            f\"kernel shape {kernel.shape}. \"\n+        )\n+    groups = channels // kernel_in_channels\n+    if num_spatial_dims == 1:\n+        outputs = tnn.conv1d(\n+            inputs,\n+            kernel,\n+            stride=strides,\n+            dilation=dilation_rate,\n+            groups=groups,\n+        )\n+    elif num_spatial_dims == 2:\n+        outputs = tnn.conv2d(\n+            inputs,\n+            kernel,\n+            stride=strides,\n+            dilation=dilation_rate,\n+            groups=groups,\n+        )\n+    elif num_spatial_dims == 3:\n+        outputs = tnn.conv3d(\n+            inputs,\n+            kernel,\n+            stride=strides,\n+            dilation=dilation_rate,\n+            groups=groups,\n+        )\n+    else:\n+        raise ValueError(\n+            \"Inputs to conv operation should have ndim=3, 4, or 5,\"\n+            \"corresponding to 1D, 2D and 3D inputs. Received input \"\n+            f\"shape: {inputs.shape}.\"\n+        )\n+\n+    if data_format == \"channels_last\":\n+        outputs = _transpose_spatial_outputs(outputs)\n+    return outputs\n \n \n def depthwise_conv(\n@@ -248,12 +348,14 @@ def depthwise_conv(\n     kernel,\n     strides=1,\n     padding=\"valid\",\n-    data_format=\"channels_last\",\n+    data_format=None,\n     dilation_rate=1,\n ):\n-    raise NotImplementedError(\n-        \"`depthwise_conv` not yet implemented for PyTorch Backend\"\n+    kernel = convert_to_tensor(kernel)\n+    kernel = torch.reshape(\n+        kernel, kernel.shape[:-2] + (1, kernel.shape[-2] * kernel.shape[-1])\n     )\n+    return conv(inputs, kernel, strides, padding, data_format, dilation_rate)\n \n \n def separable_conv(\n@@ -262,7 +364,7 @@ def separable_conv(\n     pointwise_kernel,\n     strides=1,\n     padding=\"valid\",\n-    data_format=\"channels_last\",\n+    data_format=None,\n     dilation_rate=1,\n ):\n     depthwise_conv_output = depthwise_conv(\n@@ -289,12 +391,77 @@ def conv_transpose(\n     strides=1,\n     padding=\"valid\",\n     output_padding=None,\n-    data_format=\"channels_last\",\n+    data_format=None,\n     dilation_rate=1,\n ):\n-    raise NotImplementedError(\n-        \"`conv_transpose` not yet implemented for PyTorch backend\"\n+    inputs = convert_to_tensor(inputs)\n+    kernel = convert_to_tensor(kernel)\n+    num_spatial_dims = inputs.ndim - 2\n+    strides = standardize_tuple(strides, num_spatial_dims, \"strides\")\n+\n+    data_format = standardize_data_format(data_format)\n+    padding_values = compute_conv_transpose_padding(\n+        inputs.shape,\n+        kernel.shape,\n+        strides,\n+        padding,\n+        output_padding,\n+        data_format,\n+        dilation_rate,\n     )\n+    if data_format == \"channels_last\":\n+        inputs = _transpose_spatial_inputs(inputs)\n+    # Transpose kernel from keras format to torch format.\n+    kernel = _transpose_conv_kernel(kernel)\n+    kernel_spatial_shape = kernel.shape[2:]\n+    padding_arg = []\n+    output_padding_arg = []\n+    for i, value in enumerate(padding_values):\n+        total_padding = value[0] + value[1]\n+        padding_arg.append(\n+            dilation_rate * (kernel_spatial_shape[i] - 1) - total_padding // 2\n+        )\n+        if total_padding % 2 == 0:\n+            output_padding_arg.append(0)\n+        else:\n+            output_padding_arg.append(1)\n+\n+    if num_spatial_dims == 1:\n+        outputs = tnn.conv_transpose1d(\n+            inputs,\n+            kernel,\n+            stride=strides,\n+            padding=padding_arg,\n+            output_padding=output_padding_arg,\n+            dilation=dilation_rate,\n+        )\n+    elif num_spatial_dims == 2:\n+        outputs = tnn.conv_transpose2d(\n+            inputs,\n+            kernel,\n+            stride=strides,\n+            padding=padding_arg,\n+            output_padding=output_padding_arg,\n+            dilation=dilation_rate,\n+        )\n+    elif num_spatial_dims == 3:\n+        outputs = tnn.conv_transpose3d(\n+            inputs,\n+            kernel,\n+            stride=strides,\n+            padding=padding_arg,\n+            output_padding=output_padding_arg,\n+            dilation=dilation_rate,\n+        )\n+    else:\n+        raise ValueError(\n+            \"Inputs to conv transpose operation should have ndim=3, 4, or 5,\"\n+            \"corresponding to 1D, 2D and 3D inputs. Received input \"\n+            f\"shape: {inputs.shape}.\"\n+        )\n+    if data_format == \"channels_last\":\n+        outputs = _transpose_spatial_outputs(outputs)\n+    return outputs\n \n \n def one_hot(x, num_classes, axis=-1):\n\n@@ -771,15 +771,22 @@ class NNOpsCorrectnessTest(testing.TestCase):\n         expected = tf.nn.conv2d(inputs_2d, kernel, (1, 2), padding=\"VALID\")\n         self.assertAllClose(outputs, expected)\n \n+        outputs = knn.conv(inputs_2d, kernel, (1, 2), padding=\"same\")\n+        expected = tf.nn.conv2d(inputs_2d, kernel, (1, 2), padding=\"SAME\")\n+        self.assertAllClose(outputs, expected)\n+\n         outputs = knn.conv(inputs_2d, kernel, 2, padding=\"same\")\n         expected = tf.nn.conv2d(inputs_2d, kernel, 2, padding=\"SAME\")\n         self.assertAllClose(outputs, expected)\n \n+        # Test group > 1.\n+        inputs_2d = np.ones([2, 10, 10, 4])\n+        kernel = np.ones([2, 2, 2, 6])\n         outputs = knn.conv(\n-            inputs_2d, kernel, 1, padding=\"same\", dilation_rate=2\n+            inputs_2d, kernel, 2, padding=\"same\", dilation_rate=1\n         )\n         expected = tf.nn.conv2d(\n-            inputs_2d, kernel, 1, padding=\"SAME\", dilations=2\n+            inputs_2d, kernel, 2, padding=\"SAME\", dilations=1\n         )\n         self.assertAllClose(outputs, expected)\n \n@@ -825,6 +832,12 @@ class NNOpsCorrectnessTest(testing.TestCase):\n         )\n         self.assertAllClose(outputs, expected, rtol=1e-5, atol=1e-5)\n \n+        outputs = knn.conv(inputs_3d, kernel, 2, padding=\"valid\")\n+        expected = tf.nn.conv3d(\n+            inputs_3d, kernel, (1, 2, 2, 2, 1), padding=\"VALID\"\n+        )\n+        self.assertAllClose(outputs, expected, rtol=1e-5, atol=1e-5)\n+\n         outputs = knn.conv(inputs_3d, kernel, 2, padding=\"same\")\n         expected = tf.nn.conv3d(\n             inputs_3d, kernel, (1, 2, 2, 2, 1), padding=\"SAME\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1006d2eca98a529ca45b18587aa0efa216582962", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 39 | Lines Deleted: 29 | Files Changed: 2 | Hunks: 17 | Methods Changed: 15 | Complexity Δ (Sum/Max): 5/5 | Churn Δ: 68 | Churn Cumulative: 3527 | Contributors (this commit): 7 | Commits (past 90d): 31 | Contributors (cumulative): 9 | DMM Complexity: 0.8\n\nDIFF:\n@@ -157,8 +157,9 @@ def _transpose_spatial_inputs(inputs):\n         inputs = torch.permute(inputs, (0, 4, 1, 2, 3))\n     else:\n         raise ValueError(\n-            \"Pooling inputs's shape must be 3, 4 or 5, corresponding to 1D, 2D \"\n-            f\"and 3D inputs. But received shape: {inputs.shape}.\"\n+            \"Inputs must have ndim=3, 4 or 5, \"\n+            \"corresponding to 1D, 2D and 3D inputs. \"\n+            f\"Received input shape: {inputs.shape}.\"\n         )\n     return inputs\n \n@@ -222,8 +223,9 @@ def max_pool(\n         outputs = tnn.max_pool3d(inputs, kernel_size=pool_size, stride=strides)\n     else:\n         raise ValueError(\n-            \"Pooling inputs's shape must be 3, 4 or 5, corresponding to 1D, 2D \"\n-            f\"and 3D inputs. But received shape: {inputs.shape}.\"\n+            \"Inputs to pooling op must have ndim=3, 4 or 5, \"\n+            \"corresponding to 1D, 2D and 3D inputs. \"\n+            f\"Received input shape: {inputs.shape}.\"\n         )\n     if data_format == \"channels_last\":\n         outputs = _transpose_spatial_outputs(outputs)\n@@ -264,8 +266,9 @@ def average_pool(\n         outputs = tnn.avg_pool3d(inputs, kernel_size=pool_size, stride=strides)\n     else:\n         raise ValueError(\n-            \"Pooling inputs's shape must be 3, 4 or 5, corresponding to 1D, 2D \"\n-            f\"and 3D inputs. But received shape: {inputs.shape}.\"\n+            \"Inputs to pooling op must have ndim=3, 4 or 5, \"\n+            \"corresponding to 1D, 2D and 3D inputs. \"\n+            f\"Received input shape: {inputs.shape}.\"\n         )\n     if data_format == \"channels_last\":\n         outputs = _transpose_spatial_outputs(outputs)\n@@ -303,8 +306,8 @@ def conv(\n     if channels % kernel_in_channels > 0:\n         raise ValueError(\n             \"The number of input channels must be evenly divisible by \"\n-            f\"kernel's in_channels. Received input shape {inputs.shape} and \"\n-            f\"kernel shape {kernel.shape}. \"\n+            f\"kernel.shape[1]. Received: inputs.shape={inputs.shape}, \"\n+            f\"kernel.shape={kernel.shape}\"\n         )\n     groups = channels // kernel_in_channels\n     if num_spatial_dims == 1:\n\n@@ -1,5 +1,7 @@\n import numpy as np\n+import pytest\n import tensorflow as tf\n+from absl.testing import parameterized\n \n from keras_core import testing\n from keras_core.backend.common.keras_tensor import KerasTensor\n@@ -565,7 +567,7 @@ class NNOpsStaticShapeTest(testing.TestCase):\n         )\n \n \n-class NNOpsCorrectnessTest(testing.TestCase):\n+class NNOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n     def test_relu(self):\n         x = np.array([-1, 0, 1, 2, 3], dtype=np.float32)\n         self.assertAllClose(knn.relu(x), [0, 0, 1, 2, 3])\n@@ -738,28 +740,35 @@ class NNOpsCorrectnessTest(testing.TestCase):\n             tf.nn.avg_pool2d(x, 2, (2, 1), padding=\"SAME\"),\n         )\n \n-    def test_conv(self):\n-        # Test 1D conv.\n+    @parameterized.product(\n+        strides=(1, 2, 3),\n+        padding=(\"valid\", \"same\"),\n+        dilation_rate=(1, 2),\n+    )\n+    def test_conv_1d(self, strides, padding, dilation_rate):\n+        if strides > 1 and dilation_rate > 1:\n+            pytest.skip(\"Unsupported configuration\")\n+\n         inputs_1d = np.arange(120, dtype=float).reshape([2, 20, 3])\n         kernel = np.arange(24, dtype=float).reshape([4, 3, 2])\n \n-        outputs = knn.conv(inputs_1d, kernel, 1, padding=\"valid\")\n-        expected = tf.nn.conv1d(inputs_1d, kernel, 1, padding=\"VALID\")\n-        self.assertAllClose(outputs, expected)\n-\n-        outputs = knn.conv(inputs_1d, kernel, 2, padding=\"same\")\n-        expected = tf.nn.conv1d(inputs_1d, kernel, 2, padding=\"SAME\")\n-        self.assertAllClose(outputs, expected)\n-\n         outputs = knn.conv(\n-            inputs_1d, kernel, 1, padding=\"same\", dilation_rate=2\n+            inputs_1d,\n+            kernel,\n+            strides=strides,\n+            padding=padding,\n+            dilation_rate=dilation_rate,\n         )\n         expected = tf.nn.conv1d(\n-            inputs_1d, kernel, 1, padding=\"SAME\", dilations=2\n+            inputs_1d,\n+            kernel,\n+            strides,\n+            padding=padding.upper(),\n+            dilations=dilation_rate,\n         )\n         self.assertAllClose(outputs, expected)\n \n-        # Test 2D conv.\n+    def test_conv_2d(self):\n         inputs_2d = np.arange(600, dtype=float).reshape([2, 10, 10, 3])\n         kernel = np.arange(24, dtype=float).reshape([2, 2, 3, 2])\n \n@@ -806,7 +815,7 @@ class NNOpsCorrectnessTest(testing.TestCase):\n         )\n         self.assertAllClose(outputs, expected)\n \n-        # Test 3D conv.\n+    def test_conv_3d(self):\n         inputs_3d = np.arange(3072, dtype=float).reshape([2, 8, 8, 8, 3])\n         kernel = np.arange(162, dtype=float).reshape([3, 3, 3, 3, 2])\n \n@@ -844,8 +853,7 @@ class NNOpsCorrectnessTest(testing.TestCase):\n         )\n         self.assertAllClose(outputs, expected, rtol=1e-5, atol=1e-5)\n \n-    def test_depthwise_conv(self):\n-        # Test 2D conv.\n+    def test_depthwise_conv_2d(self):\n         inputs_2d = np.arange(600, dtype=float).reshape([2, 10, 10, 3])\n         kernel = np.arange(24, dtype=float).reshape([2, 2, 3, 2])\n \n@@ -875,7 +883,7 @@ class NNOpsCorrectnessTest(testing.TestCase):\n         )\n         self.assertAllClose(outputs, expected)\n \n-    def test_separable_conv(self):\n+    def test_separable_conv_2d(self):\n         # Test 2D conv.\n         inputs_2d = np.arange(600, dtype=float).reshape([2, 10, 10, 3])\n         depthwise_kernel = np.arange(24, dtype=float).reshape([2, 2, 3, 2])\n@@ -939,8 +947,7 @@ class NNOpsCorrectnessTest(testing.TestCase):\n         )\n         self.assertAllClose(outputs, expected)\n \n-    def test_conv_transpose(self):\n-        # Test 1D conv.\n+    def test_conv_transpose_1d(self):\n         inputs_1d = np.arange(24, dtype=float).reshape([2, 4, 3])\n         kernel = np.arange(30, dtype=float).reshape([2, 5, 3])\n         outputs = knn.conv_transpose(inputs_1d, kernel, 2, padding=\"valid\")\n@@ -955,7 +962,7 @@ class NNOpsCorrectnessTest(testing.TestCase):\n         )\n         self.assertAllClose(outputs, expected)\n \n-        # Test 2D conv.\n+    def test_conv_transpose_2d(self):\n         inputs_2d = np.arange(96, dtype=float).reshape([2, 4, 4, 3])\n         kernel = np.arange(60, dtype=float).reshape([2, 2, 5, 3])\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a7ae7b53419391c3ab82eafc2b37e08f88226704", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 11/11 | Churn Δ: 2 | Churn Cumulative: 534 | Contributors (this commit): 11 | Commits (past 90d): 2 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -39,7 +39,7 @@ class MixedPrecisionTest(test_combinations.TestCase):\n         os.environ[self.IGNORE_PERF_VAR] = \"1\"\n \n     def tearDown(self):\n-        # Set the IGNORE_PERF_VAR variable back to it's original value.\n+        # Set the IGNORE_PERF_VAR variable back to its original value.\n         if self._original_ignore_perf_value is not None:\n             os.environ[self.IGNORE_PERF_VAR] = self._original_ignore_perf_value\n         else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d2afce2efc59994a7bb25b857caf314ec5765d43", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 10 | Files Changed: 5 | Hunks: 10 | Methods Changed: 10 | Complexity Δ (Sum/Max): 113/92 | Churn Δ: 21 | Churn Cumulative: 38446 | Contributors (this commit): 149 | Commits (past 90d): 30 | Contributors (cumulative): 189 | DMM Complexity: None\n\nDIFF:\n@@ -1624,7 +1624,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n                 `keras.utils.Sequence` input only. If `True`, use process-based\n                 threading. If unspecified, `use_multiprocessing` will default to\n                 `False`. Note that because this implementation relies on\n-                multiprocessing, you should not pass non-picklable arguments to\n+                multiprocessing, you should not pass non-pickleable arguments to\n                 the generator as they can't be passed easily to children\n                 processes.\n \n@@ -2154,7 +2154,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n               `keras.utils.Sequence` input only. If `True`, use process-based\n               threading. If unspecified, `use_multiprocessing` will default to\n               `False`. Note that because this implementation relies on\n-              multiprocessing, you should not pass non-picklable arguments to\n+              multiprocessing, you should not pass non-pickleable arguments to\n               the generator as they can't be passed easily to children\n               processes.\n             return_dict: If `True`, loss and metric results are returned as a\n@@ -2507,7 +2507,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n                 `keras.utils.Sequence` input only. If `True`, use process-based\n                 threading. If unspecified, `use_multiprocessing` will default to\n                 `False`. Note that because this implementation relies on\n-                multiprocessing, you should not pass non-picklable arguments to\n+                multiprocessing, you should not pass non-pickleable arguments to\n                 the generator as they can't be passed easily to children\n                 processes.\n \n\n@@ -93,7 +93,7 @@ def model_iteration(\n         use_multiprocessing: Boolean. If `True`, use process-based threading. If\n           unspecified, `use_multiprocessing` will default to `False`. Note that\n           because this implementation relies on multiprocessing, you should not\n-          pass non-picklable arguments to the generator as they can't be passed\n+          pass non-pickleable arguments to the generator as they can't be passed\n           easily to children processes.\n         shuffle: Boolean. Whether to shuffle the order of the batches at the\n           beginning of each epoch. Only used with instances of `Sequence`\n@@ -423,7 +423,7 @@ def _validate_arguments(\n       use_multiprocessing: Boolean. If `True`, use process-based threading. If\n         unspecified, `use_multiprocessing` will default to `False`. Note that\n         because this implementation relies on multiprocessing, you should not\n-        pass non-picklable arguments to the generator as they can't be passed\n+        pass non-pickleable arguments to the generator as they can't be passed\n         easily to children processes.\n       workers: Integer. Maximum number of processes to spin up when using\n         process-based threading. If unspecified, `workers` will default to 1. If\n\n@@ -823,7 +823,7 @@ class Model(training_lib.Model):\n                 `keras.utils.Sequence` input only. If `True`, use process-based\n                 threading. If unspecified, `use_multiprocessing` will default to\n                 `False`. Note that because this implementation relies on\n-                multiprocessing, you should not pass non-picklable arguments to\n+                multiprocessing, you should not pass non-pickleable arguments to\n                 the generator as they can't be passed easily to children\n                 processes.\n             **kwargs: Used for backwards compatibility.\n@@ -953,7 +953,7 @@ class Model(training_lib.Model):\n                 `keras.utils.Sequence` input only. If `True`, use process-based\n                 threading. If unspecified, `use_multiprocessing` will default to\n                 `False`. Note that because this implementation relies on\n-                multiprocessing, you should not pass non-picklable arguments to\n+                multiprocessing, you should not pass non-pickleable arguments to\n                 the generator as they can't be passed easily to children\n                 processes.\n \n@@ -1037,7 +1037,7 @@ class Model(training_lib.Model):\n                 `keras.utils.Sequence` input only. If `True`, use process-based\n                 threading. If unspecified, `use_multiprocessing` will default to\n                 `False`. Note that because this implementation relies on\n-                multiprocessing, you should not pass non-picklable arguments to\n+                multiprocessing, you should not pass non-pickleable arguments to\n                 the generator as they can't be passed easily to children\n                 processes.\n \n\n@@ -57,7 +57,7 @@ class DropoutRNNCellMixin:\n         ensure same mask is used every time.\n \n         Also the caches are created without tracking. Since they are not\n-        picklable by python when deepcopy, we don't want\n+        pickleable by python when deepcopy, we don't want\n         `layer._obj_reference_counts_dict` to track it by default.\n         \"\"\"\n         self._dropout_mask_cache = backend.ContextValueCache(\n\n@@ -42,7 +42,8 @@ class TestPickleProtocol(test_combinations.TestCase):\n         ),\n     )\n     def test_built_models(self, serializer):\n-        \"\"\"Built models should be copyable and picklable for all model types.\"\"\"\n+        \"\"\"Built models should be copyable and pickleable for all model\n+        types.\"\"\"\n         if not tf.__internal__.tf2.enabled():\n             self.skipTest(\n                 \"pickle model only available in v2 when tf format is used.\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#26f0f4f24cfb6ade0a4f374e5fb92fae515b6182", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 34 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 11 | Methods Changed: 8 | Complexity Δ (Sum/Max): 13/13 | Churn Δ: 36 | Churn Cumulative: 2806 | Contributors (this commit): 4 | Commits (past 90d): 24 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -375,6 +375,12 @@ PYTHON_DTYPES_MAP = {\n     str: \"string\",\n }\n \n+PYTHON_DTYPES_MAP = {\n+    bool: \"bool\",\n+    int: \"int\",  # TBD by backend\n+    float: \"float32\",\n+}\n+\n \n def standardize_dtype(dtype):\n     if dtype is None:\n\n@@ -1,8 +1,16 @@\n import torch\n \n+from keras_core.backend.torch.core import cast\n from keras_core.backend.torch.core import convert_to_tensor\n from keras_core.backend.torch.core import to_torch_dtype\n \n+TORCH_INT_TYPES = (\n+    torch.int8,\n+    torch.int16,\n+    torch.int32,\n+    torch.int64,\n+)\n+\n \n def add(x1, x2):\n     x1, x2 = convert_to_tensor(x1), convert_to_tensor(x2)\n@@ -31,6 +39,8 @@ def multiply(x1, x2):\n \n def mean(x, axis=None, keepdims=False):\n     x = convert_to_tensor(x)\n+    # Conversion to float necessary for `torch.mean`\n+    x = cast(x, \"float32\") if x.dtype in TORCH_INT_TYPES else x\n     return torch.mean(x, axis=axis, keepdims=keepdims)\n \n \n@@ -172,6 +182,8 @@ def array(x, dtype=None):\n \n def average(x, axis=None, weights=None):\n     x = convert_to_tensor(x)\n+    # Conversion to float necessary for `torch.mean`\n+    x = cast(x, \"float32\") if x.dtype in TORCH_INT_TYPES else x\n     if weights is not None:\n         weights = convert_to_tensor(weights)\n         return torch.sum(torch.mul(x, weights), dim=axis) / torch.sum(\n@@ -378,6 +390,10 @@ def imag(x):\n \n def isclose(x1, x2):\n     x1, x2 = convert_to_tensor(x1), convert_to_tensor(x2)\n+    if torch.is_floating_point(x1) and not torch.is_floating_point(x2):\n+        x2 = cast(x2, x1.dtype)\n+    if torch.is_floating_point(x2) and not torch.is_floating_point(x1):\n+        x1 = cast(x1, x2.dtype)\n     return torch.isclose(x1, x2)\n \n \n@@ -450,6 +466,8 @@ def log2(x):\n \n def logaddexp(x1, x2):\n     x1, x2 = convert_to_tensor(x1), convert_to_tensor(x2)\n+    x1 = cast(x1, \"float32\") if x1.dtype in TORCH_INT_TYPES else x1\n+    x2 = cast(x2, \"float32\") if x2.dtype in TORCH_INT_TYPES else x2\n     return torch.logaddexp(x1, x2)\n \n \n@@ -585,7 +603,8 @@ def ravel(x):\n \n \n def real(x):\n-    x = convert_to_tensor(x)\n+    if not isinstance(x, torch.Tensor):\n+        x = torch.from_numpy(x)  # needed for complex type conversion\n     return torch.real(x)\n \n \n@@ -646,6 +665,8 @@ def stack(x, axis=0):\n \n def std(x, axis=None, keepdims=False):\n     x = convert_to_tensor(x)\n+    # Conversion to float necessary for `torch.std`\n+    x = cast(x, \"float32\") if x.dtype in TORCH_INT_TYPES else x\n     # Remove Bessel correction to align with numpy\n     return torch.std(x, dim=axis, keepdim=keepdims, unbiased=False)\n \n@@ -676,6 +697,9 @@ def tan(x):\n \n def tensordot(x1, x2, axes=2):\n     x1, x2 = convert_to_tensor(x1), convert_to_tensor(x2)\n+    # Conversion to long necessary for `torch.tensordot`\n+    x1 = cast(x1, \"int64\") if x1.dtype in TORCH_INT_TYPES else x1\n+    x2 = cast(x2, \"int64\") if x2.dtype in TORCH_INT_TYPES else x2\n     return torch.tensordot(x1, x2, dims=axes)\n \n \n@@ -777,7 +801,9 @@ def transpose(x, axes=None):\n \n \n def var(x, axis=None, keepdims=False):\n-    x = convert_to_tensor(x)\n+    x = convert_to_tensor(x, dtype=\"float32\")\n+    # Conversion to float necessary for `torch.var`\n+    x = cast(x, \"float32\") if x.dtype in TORCH_INT_TYPES else x\n     # Bessel correction removed for numpy compatibility\n     return torch.var(x, dim=axis, keepdim=keepdims, correction=0)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
