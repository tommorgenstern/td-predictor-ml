{"custom_id": "keras#38231e8a434f1841b2e5027cc4a48501ac517d1e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 2817 | Contributors (this commit): 65 | Commits (past 90d): 8 | Contributors (cumulative): 65 | DMM Complexity: 1.0\n\nDIFF:\n@@ -575,6 +575,7 @@ class LearningRateScheduler(Callback):\n         if not isinstance(lr, (float, np.float32, np.float64)):\n             raise ValueError('The output of the \"schedule\" function '\n                              'should be float.')\n+        K.set_value(self.model.optimizer.lr, lr)\n         if self.verbose > 0:\n             print('\\nEpoch %05d: LearningRateScheduler reducing learning '\n                   'rate to %s.' % (epoch + 1, lr))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3bdc086bbd6109f773d0f539d03fd0db253393d0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 9255 | Contributors (this commit): 100 | Commits (past 90d): 26 | Contributors (cumulative): 100 | DMM Complexity: None\n\nDIFF:\n@@ -2925,7 +2925,7 @@ def elu(x, alpha=1.):\n \n     # Arguments\n         x: A tensor or variable to compute the activation function for.\n-        alpha: A scalar, slope of positive section.\n+        alpha: A scalar, slope of negative section.\n \n     # Returns\n         A tensor.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8a0e97abb3c6833655e480df040f52d3424e576d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 2823 | Contributors (this commit): 65 | Commits (past 90d): 9 | Contributors (cumulative): 65 | DMM Complexity: None\n\nDIFF:\n@@ -404,7 +404,7 @@ class ModelCheckpoint(Callback):\n                 else:\n                     if self.monitor_op(current, self.best):\n                         if self.verbose > 0:\n-                            print('Epoch %05d: %s improved from %0.5f to %0.5f,'\n+                            print('\\nEpoch %05d: %s improved from %0.5f to %0.5f,'\n                                   ' saving model to %s'\n                                   % (epoch + 1, self.monitor, self.best,\n                                      current, filepath))\n@@ -415,11 +415,11 @@ class ModelCheckpoint(Callback):\n                             self.model.save(filepath, overwrite=True)\n                     else:\n                         if self.verbose > 0:\n-                            print('Epoch %05d: %s did not improve' %\n+                            print('\\nEpoch %05d: %s did not improve' %\n                                   (epoch + 1, self.monitor))\n             else:\n                 if self.verbose > 0:\n-                    print('Epoch %05d: saving model to %s' % (epoch + 1, filepath))\n+                    print('\\nEpoch %05d: saving model to %s' % (epoch + 1, filepath))\n                 if self.save_weights_only:\n                     self.model.save_weights(filepath, overwrite=True)\n                 else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7be10882318e00d52372974b0caf8eb03c6e0fea", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1382 | Contributors (this commit): 20 | Commits (past 90d): 13 | Contributors (cumulative): 20 | DMM Complexity: None\n\nDIFF:\n@@ -395,7 +395,7 @@ def class_to_source_link(cls):\n     path = module_name.replace('.', '/')\n     path += '.py'\n     line = inspect.getsourcelines(cls)[-1]\n-    link = ('https://github.com/fchollet/'\n+    link = ('https://github.com/keras-team/'\n             'keras/blob/master/' + path + '#L' + str(line))\n     return '[[source]](' + link + ')'\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3aa6cbf9d4311ad2c5150ebde258ebb235318a7e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 21 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 5 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 23 | Churn Cumulative: 8841 | Contributors (this commit): 54 | Commits (past 90d): 14 | Contributors (cumulative): 57 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2898,10 +2898,8 @@ def preprocess_weights_for_loading(layer, weights,\n     # Returns\n         A list of weights values (Numpy arrays).\n     \"\"\"\n-    if original_keras_version == '1':\n     if layer.__class__.__name__ == 'Bidirectional':\n         num_weights_per_layer = len(weights) // 2\n-\n         forward_weights = preprocess_weights_for_loading(layer.forward_layer,\n                                                          weights[:num_weights_per_layer],\n                                                          original_keras_version,\n@@ -2912,6 +2910,7 @@ def preprocess_weights_for_loading(layer, weights,\n                                                           original_backend)\n         weights = forward_weights + backward_weights\n \n+    if original_keras_version == '1':\n         if layer.__class__.__name__ == 'TimeDistributed':\n             weights = preprocess_weights_for_loading(layer.layer,\n                                                      weights,\n\n@@ -368,6 +368,7 @@ def test_load_weights_into_noncudnn_lstm():\n     units = 2\n     num_samples = 32\n \n+    # basic case\n     input_shape = (timesteps, input_size)\n     rnn_layer = keras.layers.LSTM(units, input_shape=input_shape,\n                                   recurrent_activation='sigmoid')\n@@ -385,6 +386,25 @@ def test_load_weights_into_noncudnn_lstm():\n     cudnn_out = cudnn_model.predict(inputs)\n     assert_allclose(out, cudnn_out, atol=1e-4)\n \n+    # bidirectional case\n+    input_shape = (timesteps, input_size)\n+    rnn_layer = keras.layers.LSTM(units, recurrent_activation='sigmoid')\n+    rnn_layer = keras.layers.Bidirectional(rnn_layer, input_shape=input_shape)\n+    cudnn_rnn_layer = keras.layers.CuDNNLSTM(units)\n+    cudnn_rnn_layer = keras.layers.Bidirectional(cudnn_rnn_layer, input_shape=input_shape)\n+\n+    model = keras.models.Sequential([rnn_layer])\n+    cudnn_model = keras.models.Sequential([cudnn_rnn_layer])\n+\n+    weights = cudnn_rnn_layer.get_weights()\n+    weights = keras.engine.topology.preprocess_weights_for_loading(rnn_layer, weights)\n+    rnn_layer.set_weights(weights)\n+\n+    inputs = np.random.random((num_samples, timesteps, input_size))\n+    out = model.predict(inputs)\n+    cudnn_out = cudnn_model.predict(inputs)\n+    assert_allclose(out, cudnn_out, atol=1e-4)\n+\n \n @keras_test\n @pytest.mark.skipif((keras.backend.backend() != 'tensorflow'),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b9429c215c20b10fbabd88a5b91d0b379be8078a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 17 | Files Changed: 1 | Hunks: 15 | Methods Changed: 12 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 34 | Churn Cumulative: 9289 | Contributors (this commit): 101 | Commits (past 90d): 26 | Contributors (cumulative): 101 | DMM Complexity: None\n\nDIFF:\n@@ -1218,7 +1218,7 @@ def max(x, axis=None, keepdims=False):\n     # Returns\n         A tensor with maximum values of `x`.\n     \"\"\"\n-    return tf.reduce_max(x, axis=axis, keep_dims=keepdims)\n+    return tf.reduce_max(x, axis, keepdims)\n \n \n def min(x, axis=None, keepdims=False):\n@@ -1235,7 +1235,7 @@ def min(x, axis=None, keepdims=False):\n     # Returns\n         A tensor with miminum values of `x`.\n     \"\"\"\n-    return tf.reduce_min(x, axis=axis, keep_dims=keepdims)\n+    return tf.reduce_min(x, axis, keepdims)\n \n \n def sum(x, axis=None, keepdims=False):\n@@ -1252,7 +1252,7 @@ def sum(x, axis=None, keepdims=False):\n     # Returns\n         A tensor with sum of `x`.\n     \"\"\"\n-    return tf.reduce_sum(x, axis=axis, keep_dims=keepdims)\n+    return tf.reduce_sum(x, axis, keepdims)\n \n \n def prod(x, axis=None, keepdims=False):\n@@ -1269,7 +1269,7 @@ def prod(x, axis=None, keepdims=False):\n     # Returns\n         A tensor with the product of elements of `x`.\n     \"\"\"\n-    return tf.reduce_prod(x, axis=axis, keep_dims=keepdims)\n+    return tf.reduce_prod(x, axis, keepdims)\n \n \n def cumsum(x, axis=0):\n@@ -1314,11 +1314,11 @@ def var(x, axis=None, keepdims=False):\n     \"\"\"\n     if x.dtype.base_dtype == tf.bool:\n         x = tf.cast(x, floatx())\n-    m = tf.reduce_mean(x, axis=axis, keep_dims=True)\n+    m = tf.reduce_mean(x, axis, True)\n     devs_squared = tf.square(x - m)\n     return tf.reduce_mean(devs_squared,\n-                          axis=axis,\n-                          keep_dims=keepdims)\n+                          axis,\n+                          keepdims)\n \n \n def std(x, axis=None, keepdims=False):\n@@ -1346,7 +1346,7 @@ def mean(x, axis=None, keepdims=False):\n         axis: A list of integer. Axes to compute the mean.\n         keepdims: A boolean, whether to keep the dimensions or not.\n             If `keepdims` is `False`, the rank of the tensor is reduced\n-            by 1 for each entry in `axis`. If `keep_dims` is `True`,\n+            by 1 for each entry in `axis`. If `keepdims` is `True`,\n             the reduced dimensions are retained with length 1.\n \n     # Returns\n@@ -1354,7 +1354,7 @@ def mean(x, axis=None, keepdims=False):\n     \"\"\"\n     if x.dtype.base_dtype == tf.bool:\n         x = tf.cast(x, floatx())\n-    return tf.reduce_mean(x, axis=axis, keep_dims=keepdims)\n+    return tf.reduce_mean(x, axis, keepdims)\n \n \n def any(x, axis=None, keepdims=False):\n@@ -1369,7 +1369,7 @@ def any(x, axis=None, keepdims=False):\n         A uint8 tensor (0s and 1s).\n     \"\"\"\n     x = tf.cast(x, tf.bool)\n-    return tf.reduce_any(x, axis=axis, keep_dims=keepdims)\n+    return tf.reduce_any(x, axis, keepdims)\n \n \n def all(x, axis=None, keepdims=False):\n@@ -1384,7 +1384,7 @@ def all(x, axis=None, keepdims=False):\n         A uint8 tensor (0s and 1s).\n     \"\"\"\n     x = tf.cast(x, tf.bool)\n-    return tf.reduce_all(x, axis=axis, keep_dims=keepdims)\n+    return tf.reduce_all(x, axis, keepdims)\n \n \n def argmax(x, axis=-1):\n@@ -1494,7 +1494,7 @@ def logsumexp(x, axis=None, keepdims=False):\n     # Returns\n         The reduced tensor.\n     \"\"\"\n-    return tf.reduce_logsumexp(x, axis=axis, keep_dims=keepdims)\n+    return tf.reduce_logsumexp(x, axis, keepdims)\n \n \n def round(x):\n@@ -1700,7 +1700,7 @@ def _regular_normalize_batch_in_training(x, gamma, beta,\n         A tuple length of 3, `(normalized_tensor, mean, variance)`.\n     \"\"\"\n     mean, var = tf.nn.moments(x, reduction_axes,\n-                              shift=None, name=None, keep_dims=False)\n+                              None, None, False)\n     normed = tf.nn.batch_normalization(x, mean, var,\n                                        beta, gamma,\n                                        epsilon)\n@@ -1723,7 +1723,7 @@ def _broadcast_normalize_batch_in_training(x, gamma, beta,\n         A tuple length of 3, `(normalized_tensor, mean, variance)`.\n     \"\"\"\n     mean, var = tf.nn.moments(x, reduction_axes,\n-                              shift=None, name=None, keep_dims=False)\n+                              None, None, False)\n     target_shape = []\n     for axis in range(ndim(x)):\n         if axis in reduction_axes:\n@@ -2992,13 +2992,13 @@ def categorical_crossentropy(target, output, from_logits=False):\n     if not from_logits:\n         # scale preds so that the class probas of each sample sum to 1\n         output /= tf.reduce_sum(output,\n-                                axis=len(output.get_shape()) - 1,\n-                                keep_dims=True)\n+                                len(output.get_shape()) - 1,\n+                                True)\n         # manual computation of crossentropy\n         _epsilon = _to_tensor(epsilon(), output.dtype.base_dtype)\n         output = tf.clip_by_value(output, _epsilon, 1. - _epsilon)\n         return - tf.reduce_sum(target * tf.log(output),\n-                               axis=len(output.get_shape()) - 1)\n+                               len(output.get_shape()) - 1)\n     else:\n         return tf.nn.softmax_cross_entropy_with_logits(labels=target,\n                                                        logits=output)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3aff1a077c3b28aa046b0402da23087bb7f6a73f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 9293 | Contributors (this commit): 101 | Commits (past 90d): 27 | Contributors (cumulative): 101 | DMM Complexity: 1.0\n\nDIFF:\n@@ -84,7 +84,9 @@ def clear_session():\n     tf.reset_default_graph()\n     reset_uids()\n     _SESSION = None\n-    phase = tf.placeholder(dtype='bool', name='keras_learning_phase')\n+    phase = tf.placeholder_with_default(False,\n+                                        shape=(),\n+                                        name='keras_learning_phase')\n     _GRAPH_LEARNING_PHASES = {}\n     _GRAPH_LEARNING_PHASES[tf.get_default_graph()] = phase\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#41d967f573868a7828c8b89bac0df9e9cfcc6785", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 249 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -154,7 +154,7 @@ model_stateful = create_model(stateful=True)\n \n \n # split train/test data\n-def split_data(x, y, ratio: int = 0.8):\n+def split_data(x, y, ratio=0.8):\n     to_train = int(input_len * ratio)\n     # tweak to match with batch_size\n     to_train -= to_train % batch_size\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#49c7fa51acbd2af08e1c09a16670a341692bee35", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 19 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 19 | Churn Cumulative: 10104 | Contributors (this commit): 50 | Commits (past 90d): 23 | Contributors (cumulative): 59 | DMM Complexity: 0.8333333333333334\n\nDIFF:\n@@ -602,6 +602,8 @@ class RNN(Layer):\n         # Properly set learning phase\n         if getattr(last_output, '_uses_learning_phase', False):\n             output._uses_learning_phase = True\n+            for state in states:\n+                state._uses_learning_phase = True\n \n         if self.return_state:\n             if not isinstance(states, (list, tuple)):\n\n@@ -413,6 +413,23 @@ def test_state_reuse(layer_class):\n     outputs = model.predict(inputs)\n \n \n+@rnn_test\n+@pytest.mark.skipif((K.backend() in ['theano']),\n+                    reason='Not supported.')\n+def test_state_reuse_with_dropout(layer_class):\n+    input1 = Input(batch_shape=(num_samples, timesteps, embedding_dim))\n+    layer = layer_class(units, return_state=True, return_sequences=True, dropout=0.2)\n+    state = layer(input1)[1:]\n+\n+    input2 = Input(batch_shape=(num_samples, timesteps, embedding_dim))\n+    output = layer_class(units)(input2, initial_state=state)\n+    model = Model([input1, input2], output)\n+\n+    inputs = [np.random.random((num_samples, timesteps, embedding_dim)),\n+              np.random.random((num_samples, timesteps, embedding_dim))]\n+    outputs = model.predict(inputs)\n+\n+\n @keras_test\n def test_minimal_rnn_cell_non_layer():\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#74aaeb32ceb8b1b4a9ac4c908b908d45411ac937", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 2716 | Contributors (this commit): 45 | Commits (past 90d): 12 | Contributors (cumulative): 45 | DMM Complexity: None\n\nDIFF:\n@@ -60,7 +60,7 @@ def random_rotation(x, rg, row_axis=1, col_axis=2, channel_axis=0,\n     # Returns\n         Rotated Numpy image tensor.\n     \"\"\"\n-    theta = np.pi / 180 * np.random.uniform(-rg, rg)\n+    theta = np.deg2rad(np.random.uniform(-rg, rg))\n     rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n                                 [np.sin(theta), np.cos(theta), 0],\n                                 [0, 0, 1]])\n@@ -109,7 +109,7 @@ def random_shear(x, intensity, row_axis=1, col_axis=2, channel_axis=0,\n \n     # Arguments\n         x: Input tensor. Must be 3D.\n-        intensity: Transformation intensity.\n+        intensity: Transformation intensity in degrees.\n         row_axis: Index of axis for rows in the input tensor.\n         col_axis: Index of axis for columns in the input tensor.\n         channel_axis: Index of axis for channels in the input tensor.\n@@ -122,7 +122,7 @@ def random_shear(x, intensity, row_axis=1, col_axis=2, channel_axis=0,\n     # Returns\n         Sheared Numpy image tensor.\n     \"\"\"\n-    shear = np.random.uniform(-intensity, intensity)\n+    shear = np.deg2rad(np.random.uniform(-intensity, intensity))\n     shear_matrix = np.array([[1, -np.sin(shear), 0],\n                              [0, np.cos(shear), 0],\n                              [0, 0, 1]])\n@@ -384,7 +384,7 @@ class ImageDataGenerator(object):\n         rotation_range: degrees (0 to 180).\n         width_shift_range: fraction of total width, if < 1, or pixels if >= 1.\n         height_shift_range: fraction of total height, if < 1, or pixels if >= 1.\n-        shear_range: shear intensity (shear angle in radians).\n+        shear_range: shear intensity (shear angle in degrees).\n         zoom_range: amount of zoom. if scalar z, zoom will be randomly picked\n             in the range [1-z, 1+z]. A sequence of two can be passed instead\n             to select this range.\n@@ -606,7 +606,7 @@ class ImageDataGenerator(object):\n         # use composition of homographies\n         # to generate final transform that needs to be applied\n         if self.rotation_range:\n-            theta = np.pi / 180 * np.random.uniform(-self.rotation_range, self.rotation_range)\n+            theta = np.deg2rad(np.random.uniform(-self.rotation_range, self.rotation_range))\n         else:\n             theta = 0\n \n@@ -625,7 +625,7 @@ class ImageDataGenerator(object):\n             ty = 0\n \n         if self.shear_range:\n-            shear = np.random.uniform(-self.shear_range, self.shear_range)\n+            shear = np.deg2rad(np.random.uniform(-self.shear_range, self.shear_range))\n         else:\n             shear = 0\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#45c838cc7a0a5830c0a54a2f58f48fc61950eb68", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 104 | Lines Deleted: 7 | Files Changed: 2 | Hunks: 10 | Methods Changed: 10 | Complexity Δ (Sum/Max): 27/15 | Churn Δ: 111 | Churn Cumulative: 7401 | Contributors (this commit): 81 | Commits (past 90d): 38 | Contributors (cumulative): 98 | DMM Complexity: 0.7142857142857143\n\nDIFF:\n@@ -10,6 +10,7 @@ import six\n from keras.utils import Sequence\n from keras.utils import GeneratorEnqueuer\n from keras.utils import OrderedEnqueuer\n+from scipy.sparse import issparse\n \n try:\n     import queue\n@@ -1157,6 +1158,13 @@ class Model(Container):\n         for cbk in callbacks:\n             cbk.validation_data = val_ins\n \n+        # To prevent a slowdown, we find beforehand the arrays that need conversion.\n+        feed = self._feed_inputs + self._feed_targets + self._feed_sample_weights\n+        indices_for_conversion_to_dense = []\n+        for i in range(len(feed)):\n+            if issparse(ins[i]) and not K.is_sparse(feed[i]):\n+                indices_for_conversion_to_dense.append(i)\n+\n         for epoch in range(initial_epoch, epochs):\n             callbacks.on_epoch_begin(epoch)\n             epoch_logs = {}\n@@ -1210,6 +1218,9 @@ class Model(Container):\n                     batch_logs['batch'] = batch_index\n                     batch_logs['size'] = len(batch_ids)\n                     callbacks.on_batch_begin(batch_index, batch_logs)\n+                    for i in indices_for_conversion_to_dense:\n+                        ins_batch[i] = ins_batch[i].toarray()\n+\n                     outs = f(ins_batch)\n                     if not isinstance(outs, list):\n                         outs = [outs]\n@@ -1261,6 +1272,12 @@ class Model(Container):\n                 progbar = Progbar(target=steps)\n             else:\n                 progbar = Progbar(target=num_samples)\n+\n+        indices_for_conversion_to_dense = []\n+        for i in range(len(self._feed_inputs)):\n+            if issparse(ins[i]) and not K.is_sparse(self._feed_inputs[i]):\n+                indices_for_conversion_to_dense.append(i)\n+\n         if steps is not None:\n             # Step-based predictions.\n             # Since we do not know how many samples\n@@ -1296,6 +1313,9 @@ class Model(Container):\n                     ins_batch = _slice_arrays(ins[:-1], batch_ids) + [ins[-1]]\n                 else:\n                     ins_batch = _slice_arrays(ins, batch_ids)\n+                for i in indices_for_conversion_to_dense:\n+                    ins_batch[i] = ins_batch[i].toarray()\n+\n                 batch_outs = f(ins_batch)\n                 if not isinstance(batch_outs, list):\n                     batch_outs = [batch_outs]\n@@ -1339,6 +1359,14 @@ class Model(Container):\n                 progbar = Progbar(target=steps)\n             else:\n                 progbar = Progbar(target=num_samples)\n+\n+        # To prevent a slowdown, we find beforehand the arrays that need conversion.\n+        feed = self._feed_inputs + self._feed_targets + self._feed_sample_weights\n+        indices_for_conversion_to_dense = []\n+        for i in range(len(feed)):\n+            if issparse(ins[i]) and not K.is_sparse(feed[i]):\n+                indices_for_conversion_to_dense.append(i)\n+\n         if steps is not None:\n             for step in range(steps):\n                 batch_outs = f(ins)\n@@ -1366,6 +1394,8 @@ class Model(Container):\n                     ins_batch = _slice_arrays(ins[:-1], batch_ids) + [ins[-1]]\n                 else:\n                     ins_batch = _slice_arrays(ins, batch_ids)\n+                for i in indices_for_conversion_to_dense:\n+                    ins_batch[i] = ins_batch[i].toarray()\n \n                 batch_outs = f(ins_batch)\n                 if isinstance(batch_outs, list):\n\n@@ -485,16 +485,83 @@ def test_warnings():\n     assert all(['Sequence' not in str(w_.message) for w_ in w]), 'A warning was raised for Sequence.'\n \n \n+@keras_test\n+def test_sparse_input_target_fit():\n+    test_inputs = [sparse.random(6, 3, density=0.25).tocsr() for _ in range(2)]\n+    test_outputs = [sparse.random(6, i, density=0.25).tocsr() for i in range(3, 5)]\n+    in1 = Input(shape=(3,))\n+    in2 = Input(shape=(3,))\n+    out1 = Dropout(0.5, name='dropout')(in1)\n+    out2 = Dense(4, name='dense_1')(in2)\n+    model = Model([in1, in2], [out1, out2])\n+    model.compile('rmsprop', 'mse')\n+    model.fit(test_inputs, test_outputs, epochs=1, batch_size=2, validation_split=0.2)\n+\n+\n+@keras_test\n+def test_sparse_input_target_evaluate():\n+    test_inputs = [sparse.random(6, 3, density=0.25).tocsr() for _ in range(2)]\n+    test_outputs = [sparse.random(6, i, density=0.25).tocsr() for i in range(3, 5)]\n+    in1 = Input(shape=(3,))\n+    in2 = Input(shape=(3,))\n+    out1 = Dropout(0.5, name='dropout')(in1)\n+    out2 = Dense(4, name='dense_1')(in2)\n+    model = Model([in1, in2], [out1, out2])\n+    model.compile('rmsprop', 'mse')\n+    model.evaluate(test_inputs, test_outputs, batch_size=2)\n+\n+\n+@keras_test\n+def test_sparse_input_predict():\n+    test_inputs = [sparse.random(6, 3, density=0.25).tocsr() for _ in range(2)]\n+    in1 = Input(shape=(3,))\n+    in2 = Input(shape=(3,))\n+    out1 = Dropout(0.5, name='dropout')(in1)\n+    out2 = Dense(4, name='dense_1')(in2)\n+    model = Model([in1, in2], [out1, out2])\n+    model.compile('rmsprop', 'mse')\n+    model.predict(test_inputs, batch_size=2)\n+\n+\n @pytest.mark.skipif(K.backend() != 'tensorflow', reason='sparse operations supported only by TensorFlow')\n @keras_test\n-def test_sparse_input_validation_split():\n-    test_input = sparse.random(6, 3, density=0.25).tocsr()\n-    in1 = Input(shape=(3,), sparse=True)\n-    out1 = Dense(4)(in1)\n-    test_output = np.random.random((6, 4))\n-    model = Model(in1, out1)\n+def test_sparse_placeholder_fit():\n+    test_inputs = [sparse.random(6, 3, density=0.25).tocsr() for _ in range(2)]\n+    test_outputs = [sparse.random(6, i, density=0.25).tocsr() for i in range(3, 5)]\n+    in1 = Input(shape=(3,))\n+    in2 = Input(shape=(3,), sparse=True)\n+    out1 = Dropout(0.5, name='dropout')(in1)\n+    out2 = Dense(4, name='dense_1')(in2)\n+    model = Model([in1, in2], [out1, out2])\n     model.compile('rmsprop', 'mse')\n-    model.fit(test_input, test_output, epochs=1, batch_size=2, validation_split=0.2)\n+    model.fit(test_inputs, test_outputs, epochs=1, batch_size=2, validation_split=0.2)\n+\n+\n+@pytest.mark.skipif(K.backend() != 'tensorflow', reason='sparse operations supported only by TensorFlow')\n+@keras_test\n+def test_sparse_placeholder_evaluate():\n+    test_inputs = [sparse.random(6, 3, density=0.25).tocsr() for _ in range(2)]\n+    test_outputs = [sparse.random(6, i, density=0.25).tocsr() for i in range(3, 5)]\n+    in1 = Input(shape=(3,))\n+    in2 = Input(shape=(3,), sparse=True)\n+    out1 = Dropout(0.5, name='dropout')(in1)\n+    out2 = Dense(4, name='dense_1')(in2)\n+    model = Model([in1, in2], [out1, out2])\n+    model.compile('rmsprop', 'mse')\n+    model.evaluate(test_inputs, test_outputs, batch_size=2)\n+\n+\n+@pytest.mark.skipif(K.backend() != 'tensorflow', reason='sparse operations supported only by TensorFlow')\n+@keras_test\n+def test_sparse_placeholder_predict():\n+    test_inputs = [sparse.random(6, 3, density=0.25).tocsr() for _ in range(2)]\n+    in1 = Input(shape=(3,))\n+    in2 = Input(shape=(3,), sparse=True)\n+    out1 = Dropout(0.5, name='dropout')(in1)\n+    out2 = Dense(4, name='dense_1')(in2)\n+    model = Model([in1, in2], [out1, out2])\n+    model.compile('rmsprop', 'mse')\n+    model.predict(test_inputs, batch_size=2)\n \n \n @keras_test\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4da8c81442fb49eb58b779153f528ea77a9b9006", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 216 | Contributors (this commit): 4 | Commits (past 90d): 3 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -49,11 +49,11 @@ def test_batchnorm_correctness_1d():\n     model = Sequential()\n     norm = normalization.BatchNormalization(input_shape=(10,), momentum=0.8)\n     model.add(norm)\n-    model.compile(loss='mse', optimizer='sgd')\n+    model.compile(loss='mse', optimizer='rmsprop')\n \n     # centered on 5.0, variance 10.0\n     x = np.random.normal(loc=5.0, scale=10.0, size=(1000, 10))\n-    model.fit(x, x, epochs=4, verbose=0)\n+    model.fit(x, x, epochs=5, verbose=0)\n     out = model.predict(x)\n     out -= K.eval(norm.beta)\n     out /= K.eval(norm.gamma)\n@@ -67,11 +67,11 @@ def test_batchnorm_correctness_2d():\n     model = Sequential()\n     norm = normalization.BatchNormalization(axis=1, input_shape=(10, 6), momentum=0.8)\n     model.add(norm)\n-    model.compile(loss='mse', optimizer='sgd')\n+    model.compile(loss='mse', optimizer='rmsprop')\n \n     # centered on 5.0, variance 10.0\n     x = np.random.normal(loc=5.0, scale=10.0, size=(1000, 10, 6))\n-    model.fit(x, x, epochs=4, verbose=0)\n+    model.fit(x, x, epochs=5, verbose=0)\n     out = model.predict(x)\n     out -= np.reshape(K.eval(norm.beta), (1, 10, 1))\n     out /= np.reshape(K.eval(norm.gamma), (1, 10, 1))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6d73fa69e0a6d13948248a8accd60e24d556c802", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 5 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 21 | Churn Cumulative: 677 | Contributors (this commit): 4 | Commits (past 90d): 10 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -25,7 +25,7 @@ import numpy as np\n import os\n \n # Training parameters\n-batch_size = 32\n+batch_size = 32  # orig paper trained all networks with batch_size=128\n epochs = 200\n data_augmentation = True\n num_classes = 10\n@@ -36,14 +36,16 @@ subtract_pixel_mean = True\n # Model parameter\n # ----------------------------------------------------------------------------\n #           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\n-# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1090Ti\n-#           |      | %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\n+# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\n+#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\n # ----------------------------------------------------------------------------\n-# ResNet20  |  3   | 92.16     | 91.25     | -----     | NA        | 35\n-# ResNet32  |  5   | 92.46     | 92.49     | -----     | NA        | 50\n-# ResNet44  |  7   | 92.50     | 92.83     | -----     | NA        | 70\n-# ResNet56  |  9   | 92.71     | 93.03     | 92.60     | NA        | 90 (100)\n-# ResNet110 |  18  | 92.65     | 93.39     | 93.03     | 93.63     | 165(180)\n+# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\n+# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\n+# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\n+# ResNet56  | 9 (6)| 92.71     | 93.03     | 92.60     | NA        | 90 (100)\n+# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.03     | 93.63     | 165(180)\n+# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\n+# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\n # ---------------------------------------------------------------------------\n n = 3\n \n@@ -52,7 +54,10 @@ n = 3\n version = 1\n \n # Computed depth from supplied model parameter n\n+if version == 1:\n     depth = n * 6 + 2\n+elif version == 2:\n+    depth = n * 9 + 2\n \n # Model name, depth and version\n model_type = 'ResNet%dv%d' % (depth, version)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#caf05b43d1eed9f77c8b220be57f7bfd878abb76", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 431 | Lines Deleted: 12 | Files Changed: 4 | Hunks: 14 | Methods Changed: 14 | Complexity Δ (Sum/Max): 49/35 | Churn Δ: 443 | Churn Cumulative: 1501 | Contributors (this commit): 11 | Commits (past 90d): 9 | Contributors (cumulative): 20 | DMM Complexity: 0.24651162790697675\n\nDIFF:\n@@ -5,4 +5,5 @@ from .inception_v3 import InceptionV3\n from .inception_resnet_v2 import InceptionResNetV2\n from .xception import Xception\n from .mobilenet import MobileNet\n+from .densenet import DenseNet121, DenseNet169, DenseNet201\n from .nasnet import NASNetMobile, NASNetLarge\n\n@@ -0,0 +1,336 @@\n+# -*- coding: utf-8 -*-\n+\"\"\"DenseNet models for Keras.\n+\n+# Reference paper:\n+\n+- [Densely Connected Convolutional Networks](https://arxiv.org/abs/1608.06993) (CVPR 2017 Best Paper Award)\n+\n+# Reference implementation:\n+\n+- [Torch DenseNets](https://github.com/liuzhuang13/DenseNet/blob/master/models/densenet.lua)\n+- [TensorNets](https://github.com/taehoonlee/tensornets/blob/master/tensornets/densenets.py)\n+\"\"\"\n+from __future__ import print_function\n+from __future__ import absolute_import\n+\n+import os\n+\n+from .. import backend as K\n+from ..models import Model\n+from ..layers import Activation\n+from ..layers import AveragePooling2D\n+from ..layers import BatchNormalization\n+from ..layers import Concatenate\n+from ..layers import Conv2D\n+from ..layers import Dense\n+from ..layers import Flatten\n+from ..layers import GlobalAveragePooling2D\n+from ..layers import Input\n+from ..layers import MaxPooling2D\n+from ..layers import ZeroPadding2D\n+from ..utils.data_utils import get_file\n+from ..engine.topology import get_source_inputs\n+from . import imagenet_utils\n+from .imagenet_utils import decode_predictions\n+from .imagenet_utils import _obtain_input_shape\n+\n+\n+DENSENET121_WEIGHT_PATH = 'https://github.com/taehoonlee/deep-learning-models/releases/download/densenet/densenet121_weights_tf_dim_ordering_tf_kernels.h5'\n+DENSENET121_WEIGHT_PATH_NO_TOP = 'https://github.com/taehoonlee/deep-learning-models/releases/download/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5'\n+DENSENET169_WEIGHT_PATH = 'https://github.com/taehoonlee/deep-learning-models/releases/download/densenet/densenet169_weights_tf_dim_ordering_tf_kernels.h5'\n+DENSENET169_WEIGHT_PATH_NO_TOP = 'https://github.com/taehoonlee/deep-learning-models/releases/download/densenet/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5'\n+DENSENET201_WEIGHT_PATH = 'https://github.com/taehoonlee/deep-learning-models/releases/download/densenet/densenet201_weights_tf_dim_ordering_tf_kernels.h5'\n+DENSENET201_WEIGHT_PATH_NO_TOP = 'https://github.com/taehoonlee/deep-learning-models/releases/download/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5'\n+\n+\n+def dense_block(x, blocks, name):\n+    \"\"\"A dense block.\n+\n+    # Arguments\n+        x: input tensor.\n+        blocks: integer, the number of building blocks.\n+        name: string, block label.\n+\n+    # Returns\n+        output tensor for the block.\n+    \"\"\"\n+    for i in range(blocks):\n+        x = conv_block(x, 32, name=name + '_block' + str(i + 1))\n+    return x\n+\n+\n+def transition_block(x, reduction, name):\n+    \"\"\"A transition block.\n+\n+    # Arguments\n+        x: input tensor.\n+        reduction: float, compression rate at transition layers.\n+        name: string, block label.\n+\n+    # Returns\n+        output tensor for the block.\n+    \"\"\"\n+    bn_axis = 3 if K.image_data_format() == 'channels_last' else 1\n+    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n+                           name=name + '_bn')(x)\n+    x = Activation('relu', name=name + '_relu')(x)\n+    x = Conv2D(int(x._keras_shape[bn_axis] * reduction), 1, use_bias=False,\n+               name=name + '_conv')(x)\n+    x = AveragePooling2D(2, strides=2, name=name + '_pool')(x)\n+    return x\n+\n+\n+def conv_block(x, growth_rate, name):\n+    \"\"\"A building block for a dense block.\n+\n+    # Arguments\n+        x: input tensor.\n+        growth_rate: float, growth rate at dense layers.\n+        name: string, block label.\n+\n+    # Returns\n+        output tensor for the block.\n+    \"\"\"\n+    bn_axis = 3 if K.image_data_format() == 'channels_last' else 1\n+    x1 = BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n+                            name=name + '_0_bn')(x)\n+    x1 = Activation('relu', name=name + '_0_relu')(x1)\n+    x1 = Conv2D(4 * growth_rate, 1, use_bias=False,\n+                name=name + '_1_conv')(x1)\n+    x1 = BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n+                            name=name + '_1_bn')(x1)\n+    x1 = Activation('relu', name=name + '_1_relu')(x1)\n+    x1 = Conv2D(growth_rate, 3, padding='same', use_bias=False,\n+                name=name + '_2_conv')(x1)\n+    x = Concatenate(axis=bn_axis, name=name + '_concat')([x, x1])\n+    return x\n+\n+\n+def DenseNet(blocks,\n+             include_top=True,\n+             weights='imagenet',\n+             input_tensor=None,\n+             input_shape=None,\n+             pooling=None,\n+             classes=1000):\n+    \"\"\"Instantiates the DenseNet architecture.\n+\n+    Optionally loads weights pre-trained\n+    on ImageNet. Note that when using TensorFlow,\n+    for best performance you should set\n+    `image_data_format='channels_last'` in your Keras config\n+    at ~/.keras/keras.json.\n+\n+    The model and the weights are compatible with\n+    TensorFlow, Theano, and CNTK. The data format\n+    convention used by the model is the one\n+    specified in your Keras config file.\n+\n+    # Arguments\n+        blocks: numbers of building blocks for the four dense layers.\n+        include_top: whether to include the fully-connected\n+            layer at the top of the network.\n+        weights: one of `None` (random initialization),\n+              'imagenet' (pre-training on ImageNet),\n+              or the path to the weights file to be loaded.\n+        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n+            to use as image input for the model.\n+        input_shape: optional shape tuple, only to be specified\n+            if `include_top` is False (otherwise the input shape\n+            has to be `(224, 224, 3)` (with `channels_last` data format)\n+            or `(3, 224, 224)` (with `channels_first` data format).\n+            It should have exactly 3 inputs channels.\n+        pooling: optional pooling mode for feature extraction\n+            when `include_top` is `False`.\n+            - `None` means that the output of the model will be\n+                the 4D tensor output of the\n+                last convolutional layer.\n+            - `avg` means that global average pooling\n+                will be applied to the output of the\n+                last convolutional layer, and thus\n+                the output of the model will be a 2D tensor.\n+            - `max` means that global max pooling will\n+                be applied.\n+        classes: optional number of classes to classify images\n+            into, only to be specified if `include_top` is True, and\n+            if no `weights` argument is specified.\n+\n+    # Returns\n+        A Keras model instance.\n+\n+    # Raises\n+        ValueError: in case of invalid argument for `weights`,\n+            or invalid input shape.\n+    \"\"\"\n+    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n+        raise ValueError('The `weights` argument should be either '\n+                         '`None` (random initialization), `imagenet` '\n+                         '(pre-training on ImageNet), '\n+                         'or the path to the weights file to be loaded.')\n+\n+    if weights == 'imagenet' and include_top and classes != 1000:\n+        raise ValueError('If using `weights` as imagenet with `include_top`'\n+                         ' as true, `classes` should be 1000')\n+\n+    # Determine proper input shape\n+    input_shape = _obtain_input_shape(input_shape,\n+                                      default_size=224,\n+                                      min_size=221,\n+                                      data_format=K.image_data_format(),\n+                                      require_flatten=include_top,\n+                                      weights=weights)\n+\n+    if input_tensor is None:\n+        img_input = Input(shape=input_shape)\n+    else:\n+        if not K.is_keras_tensor(input_tensor):\n+            img_input = Input(tensor=input_tensor, shape=input_shape)\n+        else:\n+            img_input = input_tensor\n+\n+    bn_axis = 3 if K.image_data_format() == 'channels_last' else 1\n+\n+    x = ZeroPadding2D(padding=((3, 3), (3, 3)))(img_input)\n+    x = Conv2D(64, 7, strides=2, use_bias=False, name='conv1/conv')(x)\n+    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n+                           name='conv1/bn')(x)\n+    x = Activation('relu', name='conv1/relu')(x)\n+    x = ZeroPadding2D(padding=((1, 1), (1, 1)))(x)\n+    x = MaxPooling2D(3, strides=2, name='pool1')(x)\n+\n+    x = dense_block(x, blocks[0], name='conv2')\n+    x = transition_block(x, 0.5, name='pool2')\n+    x = dense_block(x, blocks[1], name='conv3')\n+    x = transition_block(x, 0.5, name='pool3')\n+    x = dense_block(x, blocks[2], name='conv4')\n+    x = transition_block(x, 0.5, name='pool4')\n+    x = dense_block(x, blocks[3], name='conv5')\n+\n+    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n+                           name='bn')(x)\n+\n+    if include_top:\n+        x = GlobalAveragePooling2D(name='avg_pool')(x)\n+        x = Dense(classes, activation='softmax', name='fc1000')(x)\n+    else:\n+        if pooling == 'avg':\n+            x = AveragePooling2D(7, name='avg_pool')(x)\n+        elif pooling == 'max':\n+            x = MaxPooling2D(7, name='max_pool')(x)\n+\n+    # Ensure that the model takes into account\n+    # any potential predecessors of `input_tensor`.\n+    if input_tensor is not None:\n+        inputs = get_source_inputs(input_tensor)\n+    else:\n+        inputs = img_input\n+\n+    # Create model.\n+    if blocks == [6, 12, 24, 16]:\n+        model = Model(inputs, x, name='densenet121')\n+    elif blocks == [6, 12, 32, 32]:\n+        model = Model(inputs, x, name='densenet169')\n+    elif blocks == [6, 12, 48, 32]:\n+        model = Model(inputs, x, name='densenet201')\n+    else:\n+        model = Model(inputs, x, name='densenet')\n+\n+    # Load weights.\n+    if weights == 'imagenet':\n+        if include_top:\n+            if blocks == [6, 12, 24, 16]:\n+                weights_path = get_file(\n+                    'densenet121_weights_tf_dim_ordering_tf_kernels.h5',\n+                    DENSENET121_WEIGHT_PATH,\n+                    cache_subdir='models',\n+                    file_hash='0962ca643bae20f9b6771cb844dca3b0')\n+            elif blocks == [6, 12, 32, 32]:\n+                weights_path = get_file(\n+                    'densenet169_weights_tf_dim_ordering_tf_kernels.h5',\n+                    DENSENET169_WEIGHT_PATH,\n+                    cache_subdir='models',\n+                    file_hash='bcf9965cf5064a5f9eb6d7dc69386f43')\n+            elif blocks == [6, 12, 48, 32]:\n+                weights_path = get_file(\n+                    'densenet201_weights_tf_dim_ordering_tf_kernels.h5',\n+                    DENSENET201_WEIGHT_PATH,\n+                    cache_subdir='models',\n+                    file_hash='7bb75edd58cb43163be7e0005fbe95ef')\n+        else:\n+            if blocks == [6, 12, 24, 16]:\n+                weights_path = get_file(\n+                    'densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5',\n+                    DENSENET121_WEIGHT_PATH_NO_TOP,\n+                    cache_subdir='models',\n+                    file_hash='4912a53fbd2a69346e7f2c0b5ec8c6d3')\n+            elif blocks == [6, 12, 32, 32]:\n+                weights_path = get_file(\n+                    'densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5',\n+                    DENSENET169_WEIGHT_PATH_NO_TOP,\n+                    cache_subdir='models',\n+                    file_hash='50662582284e4cf834ce40ab4dfa58c6')\n+            elif blocks == [6, 12, 48, 32]:\n+                weights_path = get_file(\n+                    'densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5',\n+                    DENSENET201_WEIGHT_PATH_NO_TOP,\n+                    cache_subdir='models',\n+                    file_hash='1c2de60ee40562448dbac34a0737e798')\n+        model.load_weights(weights_path)\n+    elif weights is not None:\n+        model.load_weights(weights)\n+\n+    return model\n+\n+\n+def DenseNet121(include_top=True,\n+                weights='imagenet',\n+                input_tensor=None,\n+                input_shape=None,\n+                pooling=None,\n+                classes=1000):\n+    return DenseNet([6, 12, 24, 16],\n+                    include_top, weights,\n+                    input_tensor, input_shape,\n+                    pooling, classes)\n+\n+\n+def DenseNet169(include_top=True,\n+                weights='imagenet',\n+                input_tensor=None,\n+                input_shape=None,\n+                pooling=None,\n+                classes=1000):\n+    return DenseNet([6, 12, 32, 32],\n+                    include_top, weights,\n+                    input_tensor, input_shape,\n+                    pooling, classes)\n+\n+\n+def DenseNet201(include_top=True,\n+                weights='imagenet',\n+                input_tensor=None,\n+                input_shape=None,\n+                pooling=None,\n+                classes=1000):\n+    return DenseNet([6, 12, 48, 32],\n+                    include_top, weights,\n+                    input_tensor, input_shape,\n+                    pooling, classes)\n+\n+\n+def preprocess_input(x, data_format=None):\n+    \"\"\"Preprocesses a numpy array encoding a batch of images.\n+\n+    # Arguments\n+        x: a 3D or 4D numpy array consists of RGB values within [0, 255].\n+        data_format: data format of the image tensor.\n+\n+    # Returns\n+        Preprocessed array.\n+    \"\"\"\n+    return imagenet_utils.preprocess_input(x, data_format, mode='torch')\n+\n+\n+setattr(DenseNet121, '__doc__', DenseNet.__doc__)\n+setattr(DenseNet169, '__doc__', DenseNet.__doc__)\n+setattr(DenseNet201, '__doc__', DenseNet.__doc__)\n\n@@ -18,26 +18,49 @@ def _preprocess_numpy_input(x, data_format, mode):\n         x -= 1.\n         return x\n \n+    if mode == 'torch':\n+        x /= 255.\n+        mean = [0.485, 0.456, 0.406]\n+        std = [0.229, 0.224, 0.225]\n+    else:\n         if data_format == 'channels_first':\n-        if x.ndim == 3:\n             # 'RGB'->'BGR'\n+            if x.ndim == 3:\n                 x = x[::-1, ...]\n-            # Zero-center by mean pixel\n-            x[0, :, :] -= 103.939\n-            x[1, :, :] -= 116.779\n-            x[2, :, :] -= 123.68\n             else:\n                 x = x[:, ::-1, ...]\n-            x[:, 0, :, :] -= 103.939\n-            x[:, 1, :, :] -= 116.779\n-            x[:, 2, :, :] -= 123.68\n         else:\n             # 'RGB'->'BGR'\n             x = x[..., ::-1]\n+        mean = [103.939, 116.779, 123.68]\n+        std = None\n+\n     # Zero-center by mean pixel\n-        x[..., 0] -= 103.939\n-        x[..., 1] -= 116.779\n-        x[..., 2] -= 123.68\n+    if data_format == 'channels_first':\n+        if x.ndim == 3:\n+            x[0, :, :] -= mean[0]\n+            x[1, :, :] -= mean[1]\n+            x[2, :, :] -= mean[2]\n+            if std is not None:\n+                x[0, :, :] /= std[0]\n+                x[1, :, :] /= std[1]\n+                x[2, :, :] /= std[2]\n+        else:\n+            x[:, 0, :, :] -= mean[0]\n+            x[:, 1, :, :] -= mean[1]\n+            x[:, 2, :, :] -= mean[2]\n+            if std is not None:\n+                x[:, 0, :, :] /= std[0]\n+                x[:, 1, :, :] /= std[1]\n+                x[:, 2, :, :] /= std[2]\n+    else:\n+        x[..., 0] -= mean[0]\n+        x[..., 1] -= mean[1]\n+        x[..., 2] -= mean[2]\n+        if std is not None:\n+            x[..., 0] /= std[0]\n+            x[..., 1] /= std[1]\n+            x[..., 2] /= std[2]\n     return x\n \n \n@@ -49,6 +72,11 @@ def _preprocess_symbolic_input(x, data_format, mode):\n         x -= 1.\n         return x\n \n+    if mode == 'torch':\n+        x /= 255.\n+        mean = [0.485, 0.456, 0.406]\n+        std = [0.229, 0.224, 0.225]\n+    else:\n         if data_format == 'channels_first':\n             # 'RGB'->'BGR'\n             if K.ndim(x) == 3:\n@@ -58,14 +86,19 @@ def _preprocess_symbolic_input(x, data_format, mode):\n         else:\n             # 'RGB'->'BGR'\n             x = x[..., ::-1]\n+        mean = [103.939, 116.779, 123.68]\n+        std = None\n \n     if _IMAGENET_MEAN is None:\n-        _IMAGENET_MEAN = K.constant(-np.array([103.939, 116.779, 123.68]))\n+        _IMAGENET_MEAN = K.constant(-np.array(mean))\n+\n     # Zero-center by mean pixel\n     if K.dtype(x) != K.dtype(_IMAGENET_MEAN):\n         x = K.bias_add(x, K.cast(_IMAGENET_MEAN, K.dtype(x)), data_format)\n     else:\n         x = K.bias_add(x, _IMAGENET_MEAN, data_format)\n+    if std is not None:\n+        x /= std\n     return x\n \n \n\n@@ -310,6 +310,55 @@ def test_mobilenet_image_size():\n         model = applications.MobileNet(input_shape=invalid_image_shape, weights='imagenet', include_top=True)\n \n \n+@keras_test\n+@pytest.mark.parametrize('fun', [\n+    applications.DenseNet121,\n+    applications.DenseNet169,\n+    applications.DenseNet201],\n+    ids=['DenseNet121', 'DenseNet169', 'DenseNet201'])\n+def test_densenet(fun):\n+    model = fun(weights=None)\n+    assert model.output_shape == (None, 1000)\n+\n+\n+@keras_test\n+@pytest.mark.parametrize('fun,dim', [\n+    (applications.DenseNet121, 1024),\n+    (applications.DenseNet169, 1664),\n+    (applications.DenseNet201, 1920)],\n+    ids=['DenseNet121', 'DenseNet169', 'DenseNet201'])\n+def test_densenet_no_top(fun, dim):\n+    model = fun(weights=None, include_top=False)\n+    assert model.output_shape == (None, None, None, dim)\n+\n+\n+@keras_test\n+@pytest.mark.parametrize('fun,dim', [\n+    (applications.DenseNet121, 1024),\n+    (applications.DenseNet169, 1664),\n+    (applications.DenseNet201, 1920)],\n+    ids=['DenseNet121', 'DenseNet169', 'DenseNet201'])\n+def test_densenet_pooling(fun, dim):\n+    model = fun(weights=None, include_top=False, pooling='avg')\n+    assert model.output_shape == (None, None, None, dim)\n+\n+\n+@keras_test\n+@pytest.mark.parametrize('fun,dim', [\n+    (applications.DenseNet121, 1024),\n+    (applications.DenseNet169, 1664),\n+    (applications.DenseNet201, 1920)],\n+    ids=['DenseNet121', 'DenseNet169', 'DenseNet201'])\n+def test_densenet_variable_input_channels(fun, dim):\n+    input_shape = (1, None, None) if K.image_data_format() == 'channels_first' else (None, None, 1)\n+    model = fun(weights=None, include_top=False, input_shape=input_shape)\n+    assert model.output_shape == (None, None, None, dim)\n+\n+    input_shape = (4, None, None) if K.image_data_format() == 'channels_first' else (None, None, 4)\n+    model = fun(weights=None, include_top=False, input_shape=input_shape)\n+    assert model.output_shape == (None, None, None, dim)\n+\n+\n @keras_test\n @pytest.mark.skipif((K.backend() != 'tensorflow'),\n                     reason='NASNets are supported only on TensorFlow')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
