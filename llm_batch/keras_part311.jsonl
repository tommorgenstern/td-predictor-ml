{"custom_id": "keras#af1a2eb1f556f97ed2dd94074339e5a1ec159c86", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 7 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 12 | Churn Cumulative: 3332 | Contributors (this commit): 2 | Commits (past 90d): 6 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -27,6 +27,7 @@ import shutil\n from absl.testing import parameterized\n import numpy as np\n from tensorflow.core.protobuf import rewriter_config_pb2\n+from tensorflow.python.framework import test_util as tf_test_util\n import keras\n from keras import combinations\n from keras import keras_parameterized\n@@ -580,6 +581,7 @@ class GRUV2Test(keras_parameterized.TestCase):\n       outputs_trimmed = lstm(inputs[:, :masksteps])\n     self.assertAllClose(outputs_masked[:, -masksteps:], outputs_trimmed)\n \n+  @tf_test_util.enable_output_all_intermediates\n   def test_v1_session_behavior(self):\n     with tf.compat.v1.get_default_graph().as_default():\n       # See b/139132348 for more details.\n\n@@ -28,6 +28,7 @@ import time\n from absl.testing import parameterized\n import numpy as np\n from tensorflow.core.protobuf import rewriter_config_pb2\n+from tensorflow.python.framework import test_util as tf_test_util\n import keras\n from keras import keras_parameterized\n from keras import testing_utils\n@@ -781,6 +782,7 @@ class LSTMV2Test(keras_parameterized.TestCase):\n       outputs_trimmed = lstm(inputs[:, :masksteps])\n     self.assertAllClose(outputs_masked[:, -masksteps:], outputs_trimmed)\n \n+  @tf_test_util.enable_output_all_intermediates\n   def test_v1_session_behavior(self):\n     with tf.compat.v1.get_default_graph().as_default():\n       # See b/139132348 for more details.\n\n@@ -33,6 +33,8 @@ from keras.engine import base_layer_utils\n from keras.layers import core\n from keras.layers.rnn_cell_wrapper_v2 import ResidualWrapper\n from keras.utils import generic_utils\n+from tensorflow.python.eager import context\n+from tensorflow.python.framework import test_util as tf_test_util\n from tensorflow.python.ops.ragged import ragged_tensor\n from tensorflow.python.training.tracking import util as trackable_util\n \n@@ -622,6 +624,7 @@ class BidirectionalTest(tf.test.TestCase, parameterized.TestCase):\n \n   def test_bidirectional_statefulness(self):\n     # Bidirectional and stateful\n+    def run_test():\n       rnn = keras.layers.SimpleRNN\n       samples = 2\n       dim = 2\n@@ -650,6 +653,11 @@ class BidirectionalTest(tf.test.TestCase, parameterized.TestCase):\n         model.compile(loss='mse', optimizer='sgd')\n         model.fit(x, y, epochs=1, batch_size=1)\n \n+    if context.executing_eagerly():\n+      run_test()\n+    else:\n+      tf_test_util.enable_output_all_intermediates(run_test)()\n+\n   @parameterized.parameters(['sum', 'mul', 'ave', 'concat', None])\n   def test_Bidirectional_merged_value(self, merge_mode):\n     rnn = keras.layers.LSTM\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f93ca5174a1a31c362de0d5a5330f99c77a6ad42", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 374 | Lines Deleted: 97 | Files Changed: 11 | Hunks: 40 | Methods Changed: 32 | Complexity Δ (Sum/Max): 17/7 | Churn Δ: 471 | Churn Cumulative: 21181 | Contributors (this commit): 113 | Commits (past 90d): 23 | Contributors (cumulative): 134 | DMM Complexity: 1.0\n\nDIFF:\n@@ -25,6 +25,45 @@ import numpy as np\n from keras.benchmarks import distribution_util\n \n \n+def get_benchmark_name(name):\n+  \"\"\"Split the suffix of the benchmark name.\n+\n+  For example, for the name = 'benchmark_layer_call__Conv2D_small_shape',\n+  the return value is ['Conv2D', 'small', 'shape'].\n+\n+  This is to generate the metadata of the benchmark test.\n+\n+  Arguments:\n+    name: A string, the benchmark name.\n+\n+  Returns:\n+    A list of strings of the suffix in the benchmark name.\n+  \"\"\"\n+  if '__' not in name or '_' not in name:\n+    raise ValueError('The format of the benchmark name is wrong.')\n+  return name.split('__')[-1].split('_')\n+\n+\n+def generate_benchmark_params_cpu_gpu(*params_list):\n+  \"\"\"Extend the benchmark names with CPU and GPU suffix.\n+\n+  Arguments:\n+    *params_list: A list of tuples represents the benchmark parameters.\n+\n+  Returns:\n+    A list of strings with the benchmark name extended with CPU and GPU suffix.\n+  \"\"\"\n+  benchmark_params = []\n+  for params in params_list:\n+    benchmark_params.extend([\n+        ((param[0] + '_CPU',) + param[1:]) for param in params\n+    ])\n+    benchmark_params.extend([\n+        ((param[0] + '_GPU',) + param[1:]) for param in params\n+    ])\n+  return benchmark_params\n+\n+\n class TimerCallBack(tf.keras.callbacks.Callback):\n   \"\"\"Callback for logging time in each epoch or batch.\"\"\"\n \n\n@@ -0,0 +1,53 @@\n+# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Tests for benchmark utitilies.\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n+import tensorflow as tf\n+\n+from keras.benchmarks import benchmark_util\n+\n+\n+class BenchmarkUtilTest(tf.test.TestCase):\n+\n+  def test_get_benchmark_name(self):\n+    name = \"benchmark_layer_call__Conv2D_small_shape\"\n+    expected = [\"Conv2D\", \"small\", \"shape\"]\n+    out = benchmark_util.get_benchmark_name(name)\n+    self.assertAllEqual(out, expected)\n+\n+  def test_generate_benchmark_params_cpu_gpu(self):\n+    adam_opt = tf.keras.optimizers.Adam()\n+    sgd_opt = tf.keras.optimizers.SGD()\n+    params = [\n+        (\"Adam\", adam_opt, 10),\n+        (\"SGD\", sgd_opt, 10),\n+    ]\n+    expected = [\n+        (\"Adam_CPU\", adam_opt, 10),\n+        (\"SGD_CPU\", sgd_opt, 10),\n+        (\"Adam_GPU\", adam_opt, 10),\n+        (\"SGD_GPU\", sgd_opt, 10),\n+    ]\n+\n+    out = benchmark_util.generate_benchmark_params_cpu_gpu(params)\n+    self.assertAllEqual(out, expected)\n+\n+\n+if __name__ == \"__main__\":\n+  tf.test.main()\n\n@@ -23,13 +23,10 @@ import tensorflow as tf\n import functools\n import numpy as np\n import six\n+from keras.benchmarks import benchmark_util\n from keras.benchmarks.layer_benchmarks import layer_benchmarks_test_base\n \n \n-def _get_benchmark_name(name):\n-  return name.split(\"__\")[-1].split(\"_\")\n-\n-\n def _get_metadata(name):\n   return {\n       \"model_name\": \"ideal_layers\",\n@@ -47,16 +44,6 @@ def _get_input_data(inputs):\n                      \"for the benchmark test\")\n \n \n-def _generate_benchmark_params(*params_list):\n-  benchmark_params = []\n-  for params in params_list:\n-    benchmark_params.extend(\n-        [((param[0] + \"_CPU\",) + param[1:]) for param in params])\n-    benchmark_params.extend(\n-        [((param[0] + \"_GPU\",) + param[1:]) for param in params])\n-  return benchmark_params\n-\n-\n def _layer_call_backward(layer, x):\n   with tf.GradientTape() as tape:\n     y = layer(x)\n@@ -73,23 +60,45 @@ class KerasLayerBenchmarks(six.with_metaclass(\n   # the benchmark name. It must follow the convention of\n   # \"{layer_name}_{small|normal|large}_shape\" to make it compatible with\n   # `self.report_benchmark()` method.\n-  _benchmark_parameters = _generate_benchmark_params([\n-      (\"Conv2D_small_shape\", tf.keras.layers.Conv2D,\n-       {\"filters\": 1, \"kernel_size\": 1, \"activation\": \"relu\"},\n-       {\"input_shape\": (1, 1, 1, 1)}, 10),\n-      (\"Conv2D_normal_shape\", tf.keras.layers.Conv2D,\n-       {\"filters\": 1, \"kernel_size\": 1, \"activation\": \"relu\"},\n-       {\"input_shape\": (64, 28, 28, 3)}, 10),\n-      (\"LSTM_small_shape\", tf.keras.layers.LSTM,\n-       {\"units\": 1}, {\"input_shape\": (1, 1, 1)}, 10),\n-      (\"LSTM_normal_shape\", tf.keras.layers.LSTM,\n-       {\"units\": 4}, {\"input_shape\": (32, 10, 8)}, 10),\n-      (\"Embedding_small_shape\", tf.keras.layers.Embedding,\n-       {\"input_dim\": 1, \"output_dim\": 1, \"input_length\": 1},\n-       {\"input\": np.random.randint(1, size=(1, 1))}, 10),\n-      (\"Embedding_normal_shape\", tf.keras.layers.Embedding,\n-       {\"input_dim\": 1000, \"output_dim\": 64, \"input_length\": 10},\n-       {\"input\": np.random.randint(1000, size=(32, 10))}, 10),\n+  _benchmark_parameters = benchmark_util.generate_benchmark_params_cpu_gpu([\n+      (\"Conv2D_small_shape\", tf.keras.layers.Conv2D, {\n+          \"filters\": 1,\n+          \"kernel_size\": 1,\n+          \"activation\": \"relu\"\n+      }, {\n+          \"input_shape\": (1, 1, 1, 1)\n+      }, 10),\n+      (\"Conv2D_normal_shape\", tf.keras.layers.Conv2D, {\n+          \"filters\": 1,\n+          \"kernel_size\": 1,\n+          \"activation\": \"relu\"\n+      }, {\n+          \"input_shape\": (64, 28, 28, 3)\n+      }, 10),\n+      (\"LSTM_small_shape\", tf.keras.layers.LSTM, {\n+          \"units\": 1\n+      }, {\n+          \"input_shape\": (1, 1, 1)\n+      }, 10),\n+      (\"LSTM_normal_shape\", tf.keras.layers.LSTM, {\n+          \"units\": 4\n+      }, {\n+          \"input_shape\": (32, 10, 8)\n+      }, 10),\n+      (\"Embedding_small_shape\", tf.keras.layers.Embedding, {\n+          \"input_dim\": 1,\n+          \"output_dim\": 1,\n+          \"input_length\": 1\n+      }, {\n+          \"input\": np.random.randint(1, size=(1, 1))\n+      }, 10),\n+      (\"Embedding_normal_shape\", tf.keras.layers.Embedding, {\n+          \"input_dim\": 1000,\n+          \"output_dim\": 64,\n+          \"input_length\": 10\n+      }, {\n+          \"input\": np.random.randint(1000, size=(32, 10))\n+      }, 10),\n   ])\n \n   def benchmark_layer_call(self, layer_cls, layer_args, inputs, num_iters):\n@@ -97,7 +106,7 @@ class KerasLayerBenchmarks(six.with_metaclass(\n     x = _get_input_data(inputs)\n \n     fn = functools.partial(layer, x)\n-    name = _get_benchmark_name(self._get_name())\n+    name = benchmark_util.get_benchmark_name(self._get_name())\n     metadata = {\"implementation\": name[0] + \".layer.call\"}\n     metadata.update(_get_metadata(name))\n     self.run_report(fn, num_iters, metadata)\n@@ -109,14 +118,14 @@ class KerasLayerBenchmarks(six.with_metaclass(\n     layer.call = tf.function(layer.call)\n \n     fn = functools.partial(layer, x)\n-    name = _get_benchmark_name(self._get_name())\n+    name = benchmark_util.get_benchmark_name(self._get_name())\n     metadata = {\"implementation\": name[0] + \".layer.call.function\"}\n     metadata.update(_get_metadata(name))\n     self.run_report(fn, num_iters, metadata)\n \n   def benchmark_layer_call_with_xla(\n       self, layer_cls, layer_args, inputs, num_iters):\n-    name = _get_benchmark_name(self._get_name())\n+    name = benchmark_util.get_benchmark_name(self._get_name())\n     # TODO(b/173461426)\n     if layer_cls is tf.keras.layers.Embedding and name[-1] == \"GPU\":\n       return\n@@ -136,7 +145,7 @@ class KerasLayerBenchmarks(six.with_metaclass(\n     x = _get_input_data(inputs)\n \n     fn = functools.partial(_layer_call_backward, layer, x)\n-    name = _get_benchmark_name(self._get_name())\n+    name = benchmark_util.get_benchmark_name(self._get_name())\n     metadata = {\"implementation\": name[0] + \".layer.call.backward\"}\n     metadata.update(_get_metadata(name))\n     self.run_report(fn, num_iters, metadata)\n@@ -148,7 +157,7 @@ class KerasLayerBenchmarks(six.with_metaclass(\n     layer.call = tf.function(layer.call)\n \n     fn = functools.partial(_layer_call_backward, layer, x)\n-    name = _get_benchmark_name(self._get_name())\n+    name = benchmark_util.get_benchmark_name(self._get_name())\n     metadata = {\"implementation\": name[0] + \".layer.call.backward.function\"}\n     metadata.update(_get_metadata(name))\n     self.run_report(fn, num_iters, metadata)\n@@ -158,29 +167,45 @@ class KerasLayerBenchmarksBackwardXLA(six.with_metaclass(\n     tf.__internal__.test.ParameterizedBenchmark,\n     layer_benchmarks_test_base.LayerBenchmarksBase)):\n \n-  _benchmark_parameters = _generate_benchmark_params([\n-      (\"Conv2D_small_shape\", tf.keras.layers.Conv2D,\n-       {\"filters\": 1, \"kernel_size\": 1, \"activation\": \"relu\"},\n-       {\"input_shape\": (1, 1, 1, 1)}, 10000),\n-      (\"Conv2D_normal_shape\", tf.keras.layers.Conv2D,\n-       {\"filters\": 1, \"kernel_size\": 1, \"activation\": \"relu\"},\n-       {\"input_shape\": (64, 28, 28, 3)}, 10000),\n+  _benchmark_parameters = benchmark_util.generate_benchmark_params_cpu_gpu([\n+      (\"Conv2D_small_shape\", tf.keras.layers.Conv2D, {\n+          \"filters\": 1,\n+          \"kernel_size\": 1,\n+          \"activation\": \"relu\"\n+      }, {\n+          \"input_shape\": (1, 1, 1, 1)\n+      }, 10000),\n+      (\"Conv2D_normal_shape\", tf.keras.layers.Conv2D, {\n+          \"filters\": 1,\n+          \"kernel_size\": 1,\n+          \"activation\": \"relu\"\n+      }, {\n+          \"input_shape\": (64, 28, 28, 3)\n+      }, 10000),\n       # TODO(b/153480400)\n       # (\"LSTM_small_shape\", tf.keras.layers.LSTM,\n       #  {\"units\": 1}, {\"input_shape\": (1, 1, 1)}, 10000),\n       # (\"LSTM_normal_shape\", tf.keras.layers.LSTM,\n       #  {\"units\": 4}, {\"input_shape\": (32, 10, 8)}, 10000),\n-      (\"Embedding_small_shape\", tf.keras.layers.Embedding,\n-       {\"input_dim\": 1, \"output_dim\": 1, \"input_length\": 1},\n-       {\"input\": np.random.randint(1, size=(1, 1))}, 10),\n-      (\"Embedding_normal_shape\", tf.keras.layers.Embedding,\n-       {\"input_dim\": 1000, \"output_dim\": 64, \"input_length\": 10},\n-       {\"input\": np.random.randint(1000, size=(32, 10))}, 10),\n+      (\"Embedding_small_shape\", tf.keras.layers.Embedding, {\n+          \"input_dim\": 1,\n+          \"output_dim\": 1,\n+          \"input_length\": 1\n+      }, {\n+          \"input\": np.random.randint(1, size=(1, 1))\n+      }, 10),\n+      (\"Embedding_normal_shape\", tf.keras.layers.Embedding, {\n+          \"input_dim\": 1000,\n+          \"output_dim\": 64,\n+          \"input_length\": 10\n+      }, {\n+          \"input\": np.random.randint(1000, size=(32, 10))\n+      }, 10),\n   ])\n \n   def benchmark_layer_call_backward_with_xla(\n       self, layer_cls, layer_args, inputs, num_iters):\n-    name = _get_benchmark_name(self._get_name())\n+    name = benchmark_util.get_benchmark_name(self._get_name())\n     # TODO(b/173461426)\n     if layer_cls is tf.keras.layers.Embedding and name[-1] == \"GPU\":\n       return\n\n@@ -0,0 +1,86 @@\n+# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Benchmark tests for Keras optimizers.\"\"\"\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n+import tensorflow as tf\n+\n+from keras.benchmarks import benchmark_util\n+from keras.optimizer_v2 import adam\n+from tensorflow.python.platform.benchmark import ParameterizedBenchmark\n+\n+\n+def bidirect_imdb_lstm_config():\n+  \"\"\"Bidirectional LSTM model and IMDB data.\"\"\"\n+\n+  def model_fn():\n+    inputs = tf.keras.Input(shape=(None,), dtype=\"int32\")\n+    x = tf.keras.layers.Embedding(20000, 128)(inputs)\n+    x = tf.keras.layers.Bidirectional(\n+        tf.keras.layers.LSTM(64, return_sequences=True))(\n+            x)\n+    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64))(x)\n+    outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n+    model = tf.keras.Model(inputs, outputs)\n+    return model\n+\n+  (x_train, y_train), _ = tf.keras.datasets.imdb.load_data(num_words=20000)\n+  x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=200)\n+\n+  return model_fn, x_train, y_train\n+\n+\n+class KerasOptimizerBenchmark(\n+    tf.test.Benchmark, metaclass=ParameterizedBenchmark):\n+  \"\"\"Keras optimizer benchmarks.\"\"\"\n+\n+  # The parameter of each benchmark test is a tuple, and the first one is\n+  # the optimizer name.\n+  _benchmark_parameters = benchmark_util.generate_benchmark_params_cpu_gpu([\n+      (\"Adam\", tf.keras.optimizers.Adam(), 10),\n+      (\"NonFusedAdam\", adam.NonFusedAdam(), 10),\n+  ])\n+\n+  def benchmark_optimizer(self, optimizer, num_iters):\n+    \"\"\"Optimizer benchmark with Bidirectional LSTM model on IMDB data.\n+\n+    Arguments:\n+      optimizer: The optimizer instance to be benchmarked.\n+      num_iters: The number of iterations to run for performance measurement.\n+    \"\"\"\n+    model, train_x, train_y = bidirect_imdb_lstm_config()\n+    metrics, wall_time, extras = benchmark_util.measure_performance(\n+        model,\n+        x=train_x,\n+        y=train_y,\n+        batch_size=512,\n+        optimizer=optimizer,\n+        loss=\"binary_crossentropy\",\n+        metrics=[\"accuracy\"])\n+    name = benchmark_util.get_benchmark_name(self._get_name())\n+    metadata = {\n+        \"implementation\": name[0],\n+        \"model_name\": \"optimizers\",\n+        \"parameters\": \"lstm.512\",\n+    }\n+    extras.update(metadata)\n+    self.report_benchmark(\n+        iters=num_iters, wall_time=wall_time, metrics=metrics, extras=extras)\n+\n+\n+if __name__ == \"__main__\":\n+  tf.test.main()\n\n@@ -43,6 +43,7 @@ from keras.mixed_precision import loss_scale_optimizer as lso\n from keras.mixed_precision import policy\n from keras.saving import hdf5_format\n from keras.saving import save\n+from keras.saving import saving_utils\n from keras.saving.saved_model import json_utils\n from keras.saving.saved_model import model_serialization\n from keras.utils import generic_utils\n@@ -2094,7 +2095,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     \"\"\"\n     self._assert_weights_created()\n     filepath = path_to_string(filepath)\n-    filepath_is_h5 = _is_hdf5_filepath(filepath)\n+    filepath_is_h5 = saving_utils.is_hdf5_filepath(filepath)\n     if save_format is None:\n       if filepath_is_h5:\n         save_format = 'h5'\n@@ -2182,7 +2183,8 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     Arguments:\n         filepath: String, path to the weights file to load. For weight files in\n             TensorFlow format, this is the file prefix (the same as was passed\n-            to `save_weights`).\n+            to `save_weights`). This can also be a path to a SavedModel\n+            saved from `model.save`.\n         by_name: Boolean, whether to load weights by name or by topological\n             order. Only topological loading is supported for weight files in\n             TensorFlow format.\n@@ -2209,7 +2211,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     \"\"\"\n     if dist_utils.is_tpu_strategy(self._distribution_strategy):\n       if (self._distribution_strategy.extended.steps_per_run > 1 and\n-          (not _is_hdf5_filepath(filepath))):\n+          (not saving_utils.is_hdf5_filepath(filepath))):\n         raise ValueError('Load weights is not yet supported with TPUStrategy '\n                          'with steps_per_run greater than 1.')\n     if skip_mismatch and not by_name:\n@@ -2217,16 +2219,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n           'When calling model.load_weights, skip_mismatch can only be set to '\n           'True when by_name is True.')\n \n-    filepath = path_to_string(filepath)\n-    if _is_hdf5_filepath(filepath):\n-      save_format = 'h5'\n-    else:\n-      try:\n-        tf.compat.v1.train.NewCheckpointReader(filepath)\n-        save_format = 'tf'\n-      except tf.errors.DataLossError:\n-        # The checkpoint is not readable in TensorFlow format. Try HDF5.\n-        save_format = 'h5'\n+    filepath, save_format = _detect_save_format(filepath)\n     if save_format == 'tf':\n       status = self._trackable_saver.restore(filepath, options)\n       if by_name:\n@@ -2831,6 +2824,40 @@ def _disallow_inside_tf_function(method_name):\n     raise RuntimeError(error_msg)\n \n \n-def _is_hdf5_filepath(filepath):\n-  return (filepath.endswith('.h5') or filepath.endswith('.keras') or\n-          filepath.endswith('.hdf5'))\n+def _detect_save_format(filepath):\n+  \"\"\"Returns path to weights file and save format.\"\"\"\n+\n+  filepath = path_to_string(filepath)\n+  if saving_utils.is_hdf5_filepath(filepath):\n+    return filepath, 'h5'\n+\n+  # Filepath could be a TensorFlow checkpoint file prefix or SavedModel\n+  # directory. It's possible for filepath to be both a prefix and directory.\n+  # Prioritize checkpoint over SavedModel.\n+  if _is_readable_tf_checkpoint(filepath):\n+    save_format = 'tf'\n+  elif tf.saved_model.contains_saved_model(filepath):\n+    ckpt_path = os.path.join(filepath, tf.saved_model.VARIABLES_DIRECTORY,\n+                             tf.saved_model.VARIABLES_FILENAME)\n+    if _is_readable_tf_checkpoint(ckpt_path):\n+      filepath = ckpt_path\n+      save_format = 'tf'\n+    else:\n+      raise ValueError('Unable to load weights. filepath {} appears to be a '\n+                       'SavedModel directory, but checkpoint either doesn\\'t '\n+                       'exist, or is incorrectly formatted.'.format(filepath))\n+  else:\n+    # Not a TensorFlow checkpoint. This filepath is likely an H5 file that\n+    # doesn't have the hdf5/keras extensions.\n+    save_format = 'h5'\n+  return filepath, save_format\n+\n+\n+def _is_readable_tf_checkpoint(filepath):\n+  try:\n+    tf.compat.v1.train.NewCheckpointReader(filepath)\n+    return True\n+  except tf.errors.DataLossError:\n+    # The checkpoint is not readable in TensorFlow format.\n+    return False\n+\n\n@@ -41,6 +41,7 @@ from keras.engine import training_utils_v1\n from keras.mixed_precision import loss_scale_optimizer\n from keras.mixed_precision import policy\n from keras.optimizer_v2 import optimizer_v2\n+from keras.saving import saving_utils\n from keras.saving.saved_model import model_serialization\n from keras.utils import data_utils\n from keras.utils import layer_utils\n@@ -212,7 +213,7 @@ class Model(training_lib.Model):\n     \"\"\"\n     if distributed_training_utils.is_tpu_strategy(self._distribution_strategy):\n       if (self._distribution_strategy.extended.steps_per_run > 1 and\n-          (not training_lib._is_hdf5_filepath(filepath))):  # pylint: disable=protected-access\n+          (not saving_utils.is_hdf5_filepath(filepath))):  # pylint: disable=protected-access\n         raise ValueError('Load weights is not yet supported with TPUStrategy '\n                          'with steps_per_run greater than 1.')\n     return super(Model, self).load_weights(filepath, by_name, skip_mismatch)\n\n@@ -45,7 +45,7 @@ def text_to_word_sequence(input_text,\n   Arguments:\n       input_text: Input text (string).\n       filters: list (or concatenation) of characters to filter out, such as\n-          punctuation. Default: `'!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\\\t\\\\n'`,\n+          punctuation. Default: ``'!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\\\t\\\\n'``,\n             includes basic punctuation, tabs, and newlines.\n       lower: boolean. Whether to convert the input to lowercase.\n       split: str. Separator for word splitting.\n\n@@ -97,22 +97,48 @@ def timeseries_dataset_from_array(\n     can be generated to include them (the next sequence would have started\n     at index 81, and thus its last step would have gone over 99).\n \n-  Example 2: temporal regression. Consider an array `data` of scalar\n-  values, of shape `(steps,)`. To generate a dataset that uses the past 10\n+  Example 2: temporal regression. \n+    Consider an array `data` of scalar values, of shape `(steps,)`. \n+    To generate a dataset that uses the past 10\n     timesteps to predict the next timestep, you would use:\n \n     ```python\n-  input_data = data\n-  offset = 10\n-  targets = data[offset:]\n+    input_data = data[:-10]\n+    targets = data[10:]\n     dataset = tf.keras.preprocessing.timeseries_dataset_from_array(\n-      input_data, targets, sequence_length=offset)\n+        input_data, targets, sequence_length=10)\n     for batch in dataset:\n       inputs, targets = batch\n       assert np.array_equal(inputs[0], data[:10])  # First sequence: steps [0-9]\n       assert np.array_equal(targets[0], data[10])  # Corresponding target: step 10\n       break\n     ```\n+\n+  Example 3: temporal regression for many-to-many architectures.\n+    Consider two arrays of scalar values `X` and `Y`,\n+    both of shape `(100,)`. The resulting dataset should consist samples with \n+    20 timestamps each. The samples should not overlap.\n+    To generate a dataset that uses the current timestamp \n+    to predict the corresponding target timestep, you would use:\n+\n+    ```python\n+    X = np.arange(100)\n+    Y = X*2\n+\n+    sample_length = 20\n+    input_dataset = tf.keras.preprocessing.timeseries_dataset_from_array(\n+      X, None, sequence_length=sample_length, sequence_stride=sample_length)\n+    target_dataset = tf.keras.preprocessing.timeseries_dataset_from_array(\n+      Y, None, sequence_length=sample_length, sequence_stride=sample_length)\n+\n+    for batch in zip(input_dataset, target_dataset):\n+      inputs, targets = batch\n+      assert np.array_equal(inputs[0], X[:sample_length])\n+\n+      # second sample equals output timestamps 20-40\n+      assert np.array_equal(targets[1], Y[sample_length:2*sample_length])\n+      break\n+    ```\n   \"\"\"\n   if start_index and (start_index < 0 or start_index >= len(data)):\n     raise ValueError('start_index must be higher than 0 and lower than the '\n\n@@ -20,9 +20,9 @@ from __future__ import print_function\n \n import tensorflow as tf\n \n-import os\n import six\n from keras.saving import hdf5_format\n+from keras.saving import saving_utils\n from keras.saving.saved_model import load as saved_model_load\n from keras.saving.saved_model import load_context\n from keras.saving.saved_model import save as saved_model_save\n@@ -39,12 +39,6 @@ except ImportError:\n   h5py = None\n # pylint: enable=g-import-not-at-top\n \n-_HDF5_EXTENSIONS = ['.h5', '.hdf5', '.keras']\n-\n-\n-# TODO(kathywu): Remove this when Keras SavedModel is not experimental.\n-_KERAS_SAVED_MODEL_STILL_EXPERIMENTAL = True\n-\n \n @keras_export('keras.models.save_model')\n def save_model(model,\n@@ -140,7 +134,7 @@ def save_model(model,\n \n   if (save_format == 'h5' or\n       (h5py is not None and isinstance(filepath, h5py.File)) or\n-      os.path.splitext(filepath)[1] in _HDF5_EXTENSIONS):\n+      saving_utils.is_hdf5_filepath(filepath)):\n     # TODO(b/130258301): add utility method for detecting model type.\n     if (not model._is_graph_network and  # pylint:disable=protected-access\n         not isinstance(model, sequential.Sequential)):\n\n@@ -45,11 +45,14 @@ except ImportError:\n @combinations.generate(combinations.combine(mode=['graph', 'eager']))\n class TestWeightSavingAndLoading(tf.test.TestCase, parameterized.TestCase):\n \n+  def _save_model_dir(self, dirname='saved_model'):\n+    temp_dir = self.get_temp_dir()\n+    self.addCleanup(shutil.rmtree, temp_dir, ignore_errors=True)\n+    return os.path.join(temp_dir, dirname)\n+\n   @keras_parameterized.run_with_all_weight_formats\n   def test_weight_loading(self):\n-    temp_dir = self.get_temp_dir()\n-    self.addCleanup(shutil.rmtree, temp_dir)\n-    saved_model_dir = os.path.join(temp_dir, 'saved_model')\n+    saved_model_dir = self._save_model_dir()\n     save_format = testing_utils.get_save_format()\n     with self.cached_session():\n       a = keras.layers.Input(shape=(2,))\n@@ -204,9 +207,7 @@ class TestWeightSavingAndLoading(tf.test.TestCase, parameterized.TestCase):\n     if h5py is None:\n       return\n \n-    temp_dir = self.get_temp_dir()\n-    self.addCleanup(shutil.rmtree, temp_dir)\n-    h5_path = os.path.join(temp_dir, 'test.h5')\n+    h5_path = self._save_model_dir('test.h5')\n \n     num_hidden = 5\n     input_dim = 3\n@@ -235,9 +236,7 @@ class TestWeightSavingAndLoading(tf.test.TestCase, parameterized.TestCase):\n       exclude_formats=['tf_no_traces'])\n   def test_nested_model_weight_loading(self):\n     save_format = testing_utils.get_save_format()\n-    temp_dir = self.get_temp_dir()\n-    self.addCleanup(shutil.rmtree, temp_dir)\n-    saved_model_dir = os.path.join(temp_dir, 'saved_model')\n+    saved_model_dir = self._save_model_dir()\n \n     batch_size = 5\n     shape = (None, None, 3)\n@@ -275,9 +274,7 @@ class TestWeightSavingAndLoading(tf.test.TestCase, parameterized.TestCase):\n     if h5py is None:\n       return\n \n-    temp_dir = self.get_temp_dir()\n-    self.addCleanup(shutil.rmtree, temp_dir)\n-    h5_path = os.path.join(temp_dir, 'test.h5')\n+    h5_path = self._save_model_dir('test.h5')\n \n     num_hidden = 5\n     input_dim = 3\n@@ -317,9 +314,7 @@ class TestWeightSavingAndLoading(tf.test.TestCase, parameterized.TestCase):\n     if h5py is None:\n       return\n \n-    temp_dir = self.get_temp_dir()\n-    self.addCleanup(shutil.rmtree, temp_dir)\n-    h5_path = os.path.join(temp_dir, 'test.h5')\n+    h5_path = self._save_model_dir('test.h5')\n \n     num_hidden = 5\n     input_dim = 3\n@@ -358,6 +353,32 @@ class TestWeightSavingAndLoading(tf.test.TestCase, parameterized.TestCase):\n       self.assertAllClose([3.5] * num_classes,\n                           keras.backend.get_value(model.layers[1].bias))\n \n+  @keras_parameterized.run_with_all_saved_model_formats(\n+      exclude_formats=['tf_no_traces'])\n+  @keras_parameterized.run_with_all_model_types\n+  def test_load_weights_from_saved_model(self):\n+    save_path = self._save_model_dir()\n+    save_format = testing_utils.get_save_format()\n+\n+    if save_format == 'h5' and testing_utils.get_model_type() == 'subclass':\n+      # TODO(b/173646281): HDF5 format currently does not allow saving\n+      # subclassed models.\n+      return\n+\n+    with self.cached_session():\n+      model = testing_utils.get_small_mlp(1, 4, input_dim=3)\n+      data = np.random.random((1, 3))\n+      labels = np.random.random((1, 4))\n+      model.compile(loss='mse', optimizer='rmsprop')\n+      model.fit(data, labels)\n+      model.save(save_path, save_format=save_format)\n+      new_model = testing_utils.get_small_mlp(1, 4, input_dim=3)\n+      if testing_utils.get_model_type() == 'subclass':\n+        # Call on test data to build the model.\n+        new_model.predict(data)\n+      new_model.load_weights(save_path)\n+      self.assertAllClose(model.weights, new_model.weights)\n+\n \n class SubclassedModel(training.Model):\n \n\n@@ -322,3 +322,8 @@ def try_build_compiled_arguments(model):\n           'Compiled the loaded model, but the compiled metrics have yet to '\n           'be built. `model.compile_metrics` will be empty until you train '\n           'or evaluate the model.')\n+\n+\n+def is_hdf5_filepath(filepath):\n+  return (filepath.endswith('.h5') or filepath.endswith('.keras') or\n+          filepath.endswith('.hdf5'))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#80bea8363d2ac4515ec7eadede62211b696b8261", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1189 | Lines Deleted: 830 | Files Changed: 134 | Hunks: 863 | Methods Changed: 619 | Complexity Δ (Sum/Max): 48/41 | Churn Δ: 2019 | Churn Cumulative: 236085 | Contributors (this commit): 562 | Commits (past 90d): 345 | Contributors (cumulative): 1467 | DMM Complexity: 0.8918918918918919\n\nDIFF:\n@@ -60,7 +60,7 @@ def softmax(x, axis=-1):\n \n   The input values in are the log-odds of the resulting probability.\n \n-  Arguments:\n+  Args:\n       x : Input tensor.\n       axis: Integer, axis along which the softmax normalization is applied.\n \n@@ -120,7 +120,7 @@ def elu(x, alpha=1.0):\n \n   <tensorflow.python.keras.engine.sequential.Sequential object ...>\n \n-  Arguments:\n+  Args:\n       x: Input tensor.\n       alpha: A scalar, slope of negative section. `alpha` controls the value to\n         which an ELU saturates for negative net inputs.\n@@ -173,7 +173,7 @@ def selu(x):\n   ...                                 activation='selu'))\n   >>> model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n \n-  Arguments:\n+  Args:\n       x: A tensor or variable to compute the activation function for.\n \n   Returns:\n@@ -204,7 +204,7 @@ def softplus(x):\n   array([2.0611537e-09, 3.1326166e-01, 6.9314718e-01, 1.3132616e+00,\n            2.0000000e+01], dtype=float32)\n   \n-  Arguments:\n+  Args:\n       x: Input tensor.\n \n   Returns:\n@@ -225,7 +225,7 @@ def softsign(x):\n   >>> b.numpy()\n   array([-0.5,  0. ,  0.5], dtype=float32)\n \n-  Arguments:\n+  Args:\n       x: Input tensor.\n \n   Returns:\n@@ -253,7 +253,7 @@ def swish(x):\n   array([-4.1223075e-08, -2.6894143e-01,  0.0000000e+00,  7.3105860e-01,\n             2.0000000e+01], dtype=float32)\n \n-  Arguments:\n+  Args:\n       x: Input tensor.\n \n   Returns:\n@@ -289,7 +289,7 @@ def relu(x, alpha=0., max_value=None, threshold=0):\n   >>> tf.keras.activations.relu(foo, threshold=5).numpy()\n   array([-0., -0.,  0.,  0., 10.], dtype=float32)\n \n-  Arguments:\n+  Args:\n       x: Input `tensor` or `variable`.\n       alpha: A `float` that governs the slope for values lower than the\n         threshold.\n@@ -328,7 +328,7 @@ def gelu(x, approximate=False):\n   array([-0.00363752, -0.15880796,  0.        ,  0.841192  ,  2.9963627 ],\n       dtype=float32)\n \n-  Arguments:\n+  Args:\n       x: Input tensor.\n       approximate: A `bool`, whether to enable approximation.\n \n@@ -358,7 +358,7 @@ def tanh(x):\n   >>> b.numpy()\n   array([-0.9950547, -0.7615942,  0.,  0.7615942,  0.9950547], dtype=float32)\n \n-  Arguments:\n+  Args:\n       x: Input tensor.\n \n   Returns:\n@@ -389,7 +389,7 @@ def sigmoid(x):\n   array([2.0611537e-09, 2.6894143e-01, 5.0000000e-01, 7.3105860e-01,\n            1.0000000e+00], dtype=float32)\n \n-  Arguments:\n+  Args:\n       x: Input tensor.\n \n   Returns:\n@@ -413,7 +413,7 @@ def exponential(x):\n   >>> b.numpy()\n   array([0.04978707,  0.36787945,  1.,  2.7182817 , 20.085537], dtype=float32)\n \n-  Arguments:\n+  Args:\n       x: Input tensor.\n \n   Returns:\n@@ -436,7 +436,7 @@ def hard_sigmoid(x):\n   >>> b.numpy()\n   array([0. , 0.3, 0.5, 0.7, 1. ], dtype=float32)\n \n-  Arguments:\n+  Args:\n       x: Input tensor.\n \n   Returns:\n@@ -461,7 +461,7 @@ def linear(x):\n   >>> b.numpy()\n   array([-3., -1.,  0.,  1.,  3.], dtype=float32)\n \n-  Arguments:\n+  Args:\n       x: Input tensor.\n \n   Returns:\n@@ -475,7 +475,7 @@ def linear(x):\n def serialize(activation):\n   \"\"\"Returns the string identifier of an activation function.\n \n-  Arguments:\n+  Args:\n       activation : Function object.\n \n   Returns:\n@@ -549,7 +549,7 @@ def deserialize(name, custom_objects=None):\n def get(identifier):\n   \"\"\"Returns function.\n \n-  Arguments:\n+  Args:\n       identifier: Function or string\n \n   Returns:\n\n@@ -58,7 +58,7 @@ layers = VersionAwareLayers()\n def dense_block(x, blocks, name):\n   \"\"\"A dense block.\n \n-  Arguments:\n+  Args:\n     x: input tensor.\n     blocks: integer, the number of building blocks.\n     name: string, block label.\n@@ -74,7 +74,7 @@ def dense_block(x, blocks, name):\n def transition_block(x, reduction, name):\n   \"\"\"A transition block.\n \n-  Arguments:\n+  Args:\n     x: input tensor.\n     reduction: float, compression rate at transition layers.\n     name: string, block label.\n@@ -100,7 +100,7 @@ def transition_block(x, reduction, name):\n def conv_block(x, growth_rate, name):\n   \"\"\"A building block for a dense block.\n \n-  Arguments:\n+  Args:\n     x: input tensor.\n     growth_rate: float, growth rate at dense layers.\n     name: string, block label.\n@@ -150,7 +150,7 @@ def DenseNet(\n   For DenseNet, call `tf.keras.applications.densenet.preprocess_input` on your\n   inputs before passing them to the model.\n \n-  Arguments:\n+  Args:\n     blocks: numbers of building blocks for the four dense layers.\n     include_top: whether to include the fully-connected\n       layer at the top of the network.\n@@ -389,7 +389,7 @@ DOC = \"\"\"\n   For DenseNet, call `tf.keras.applications.densenet.preprocess_input` on your\n   inputs before passing them to the model.\n \n-  Arguments:\n+  Args:\n     include_top: whether to include the fully-connected\n       layer at the top of the network.\n     weights: one of `None` (random initialization),\n\n@@ -155,7 +155,7 @@ BASE_DOCSTRING = \"\"\"Instantiates the {name} architecture.\n   the one specified in your Keras config at `~/.keras/keras.json`.\n   If you have never configured it, it defaults to `\"channels_last\"`.\n \n-  Arguments:\n+  Args:\n     include_top: Whether to include the fully-connected\n         layer at the top of the network. Defaults to True.\n     weights: One of `None` (random initialization),\n@@ -219,7 +219,7 @@ def EfficientNet(\n   Note that the data format convention used by the model is\n   the one specified in your Keras config at `~/.keras/keras.json`.\n \n-  Arguments:\n+  Args:\n     width_coefficient: float, scaling coefficient for network width.\n     depth_coefficient: float, scaling coefficient for network depth.\n     default_size: integer, default input image size.\n@@ -424,7 +424,7 @@ def block(inputs,\n           id_skip=True):\n   \"\"\"An inverted residual block.\n \n-  Arguments:\n+  Args:\n       inputs: input tensor.\n       activation: activation function.\n       drop_rate: float between 0 and 1, fraction of the input units to drop.\n\n@@ -50,7 +50,7 @@ PREPROCESS_INPUT_DOC = \"\"\"\n   result = model(image)\n   ```\n \n-  Arguments:\n+  Args:\n     x: A floating point `numpy.array` or a `tf.Tensor`, 3D or 4D with 3 color\n       channels, with values in the range [0, 255].\n       The preprocessed data are written over the input data\n@@ -129,7 +129,7 @@ preprocess_input.__doc__ = PREPROCESS_INPUT_DOC.format(\n def decode_predictions(preds, top=5):\n   \"\"\"Decodes the prediction of an ImageNet model.\n \n-  Arguments:\n+  Args:\n     preds: Numpy array encoding a batch of predictions.\n     top: Integer, how many top-guesses to return. Defaults to 5.\n \n@@ -169,7 +169,7 @@ def decode_predictions(preds, top=5):\n def _preprocess_numpy_input(x, data_format, mode):\n   \"\"\"Preprocesses a Numpy array encoding a batch of images.\n \n-  Arguments:\n+  Args:\n     x: Input array, 3D or 4D.\n     data_format: Data format of the image array.\n     mode: One of \"caffe\", \"tf\" or \"torch\".\n@@ -242,7 +242,7 @@ def _preprocess_numpy_input(x, data_format, mode):\n def _preprocess_symbolic_input(x, data_format, mode):\n   \"\"\"Preprocesses a tensor encoding a batch of images.\n \n-  Arguments:\n+  Args:\n     x: Input tensor, 3D or 4D.\n     data_format: Data format of the image tensor.\n     mode: One of \"caffe\", \"tf\" or \"torch\".\n@@ -301,7 +301,7 @@ def obtain_input_shape(input_shape,\n                        weights=None):\n   \"\"\"Internal utility to compute/validate a model's input shape.\n \n-  Arguments:\n+  Args:\n     input_shape: Either None (will return the default network input shape),\n       or a user-provided shape to be validated.\n     default_size: Default input width/height for the model.\n@@ -388,7 +388,7 @@ def obtain_input_shape(input_shape,\n def correct_pad(inputs, kernel_size):\n   \"\"\"Returns a tuple for zero-padding for 2D convolution with downsampling.\n \n-  Arguments:\n+  Args:\n     inputs: Input tensor.\n     kernel_size: An integer or tuple/list of 2 integers.\n \n\n@@ -67,7 +67,7 @@ def InceptionResNetV2(include_top=True,\n   `tf.keras.applications.inception_resnet_v2.preprocess_input`\n   on your inputs before passing them to the model.\n \n-  Arguments:\n+  Args:\n     include_top: whether to include the fully-connected\n       layer at the top of the network.\n     weights: one of `None` (random initialization),\n@@ -261,7 +261,7 @@ def conv2d_bn(x,\n               name=None):\n   \"\"\"Utility function to apply conv + BN.\n \n-  Arguments:\n+  Args:\n     x: input tensor.\n     filters: filters in `Conv2D`.\n     kernel_size: kernel size as in `Conv2D`.\n@@ -303,7 +303,7 @@ def inception_resnet_block(x, scale, block_type, block_idx, activation='relu'):\n   - Inception-ResNet-B: `block_type='block17'`\n   - Inception-ResNet-C: `block_type='block8'`\n \n-  Arguments:\n+  Args:\n     x: input tensor.\n     scale: scaling factor to scale the residuals (i.e., the output of passing\n       `x` through an inception module) before adding them to the shortcut\n\n@@ -68,7 +68,7 @@ def InceptionV3(\n   For InceptionV3, call `tf.keras.applications.inception_v3.preprocess_input`\n   on your inputs before passing them to the model.\n \n-  Arguments:\n+  Args:\n     include_top: Boolean, whether to include the fully-connected\n       layer at the top, as the last layer of the network. Default to `True`.\n     weights: One of `None` (random initialization),\n@@ -370,7 +370,7 @@ def conv2d_bn(x,\n               name=None):\n   \"\"\"Utility function to apply conv + BN.\n \n-  Arguments:\n+  Args:\n     x: input tensor.\n     filters: filters in `Conv2D`.\n     num_row: height of the convolution kernel.\n\n@@ -109,7 +109,7 @@ def MobileNet(input_shape=None,\n   For MobileNet, call `tf.keras.applications.mobilenet.preprocess_input`\n   on your inputs before passing them to the model.\n \n-  Arguments:\n+  Args:\n     input_shape: Optional shape tuple, only to be specified if `include_top`\n       is False (otherwise the input shape has to be `(224, 224, 3)` (with\n       `channels_last` data format) or (3, 224, 224) (with `channels_first`\n@@ -316,7 +316,7 @@ def MobileNet(input_shape=None,\n def _conv_block(inputs, filters, alpha, kernel=(3, 3), strides=(1, 1)):\n   \"\"\"Adds an initial convolution layer (with batch normalization and relu6).\n \n-  Arguments:\n+  Args:\n     inputs: Input tensor of shape `(rows, cols, 3)` (with `channels_last`\n       data format) or (3, rows, cols) (with `channels_first` data format).\n       It should have exactly 3 inputs channels, and width and height should\n@@ -374,7 +374,7 @@ def _depthwise_conv_block(inputs,\n   batch normalization, relu6, pointwise convolution,\n   batch normalization and relu6 activation.\n \n-  Arguments:\n+  Args:\n     inputs: Input tensor of shape `(rows, cols, channels)` (with\n       `channels_last` data format) or (channels, rows, cols) (with\n       `channels_first` data format).\n\n@@ -116,7 +116,7 @@ def MobileNetV2(input_shape=None,\n   For MobileNetV2, call `tf.keras.applications.mobilenet_v2.preprocess_input`\n   on your inputs before passing them to the model.\n \n-  Arguments:\n+  Args:\n     input_shape: Optional shape tuple, to be specified if you would\n       like to use a model with an input image resolution that is not\n       (224, 224, 3).\n\n@@ -78,7 +78,7 @@ BASE_DOCSTRING = \"\"\"Instantiates the {name} architecture.\n \n   Optionally loads weights pre-trained on ImageNet.\n \n-  Arguments:\n+  Args:\n     input_shape: Optional shape tuple, to be specified if you would\n       like to use a model with an input image resolution that is not\n       (224, 224, 3).\n\n@@ -86,7 +86,7 @@ def NASNet(input_shape=None,\n   Note that the data format convention used by the model is\n   the one specified in your Keras config at `~/.keras/keras.json`.\n \n-  Arguments:\n+  Args:\n     input_shape: Optional shape tuple, the input shape\n       is by default `(331, 331, 3)` for NASNetLarge and\n       `(224, 224, 3)` for NASNetMobile.\n@@ -341,7 +341,7 @@ def NASNetMobile(input_shape=None,\n   For NASNet, call `tf.keras.applications.nasnet.preprocess_input` on your\n   inputs before passing them to the model.\n \n-  Arguments:\n+  Args:\n       input_shape: Optional shape tuple, only to be specified\n           if `include_top` is False (otherwise the input shape\n           has to be `(224, 224, 3)` for NASNetMobile\n@@ -418,7 +418,7 @@ def NASNetLarge(input_shape=None,\n   For NASNet, call `tf.keras.applications.nasnet.preprocess_input` on your\n   inputs before passing them to the model.\n \n-  Arguments:\n+  Args:\n       input_shape: Optional shape tuple, only to be specified\n           if `include_top` is False (otherwise the input shape\n           has to be `(331, 331, 3)` for NASNetLarge.\n@@ -480,7 +480,7 @@ def _separable_conv_block(ip,\n                           block_id=None):\n   \"\"\"Adds 2 blocks of [relu-separable conv-batchnorm].\n \n-  Arguments:\n+  Args:\n       ip: Input tensor\n       filters: Number of output filters per layer\n       kernel_size: Kernel size of separable convolutions\n@@ -539,7 +539,7 @@ def _adjust_block(p, ip, filters, block_id=None):\n \n   Used in situations where the output number of filters needs to be changed.\n \n-  Arguments:\n+  Args:\n       p: Input tensor which needs to be modified\n       ip: Input tensor whose shape needs to be matched\n       filters: Number of output filters to be matched\n@@ -622,7 +622,7 @@ def _adjust_block(p, ip, filters, block_id=None):\n def _normal_a_cell(ip, p, filters, block_id=None):\n   \"\"\"Adds a Normal cell for NASNet-A (Fig. 4 in the paper).\n \n-  Arguments:\n+  Args:\n       ip: Input tensor `x`\n       p: Input tensor `p`\n       filters: Number of output filters\n@@ -701,7 +701,7 @@ def _normal_a_cell(ip, p, filters, block_id=None):\n def _reduction_a_cell(ip, p, filters, block_id=None):\n   \"\"\"Adds a Reduction cell for NASNet-A (Fig. 4 in the paper).\n \n-  Arguments:\n+  Args:\n     ip: Input tensor `x`\n     p: Input tensor `p`\n     filters: Number of output filters\n\n@@ -80,7 +80,7 @@ def ResNet(stack_fn,\n   Note that the data format convention used by the model is\n   the one specified in your Keras config at `~/.keras/keras.json`.\n \n-  Arguments:\n+  Args:\n     stack_fn: a function that returns output tensor for the\n       stacked residual blocks.\n     preact: whether to use pre-activation or not\n@@ -227,7 +227,7 @@ def ResNet(stack_fn,\n def block1(x, filters, kernel_size=3, stride=1, conv_shortcut=True, name=None):\n   \"\"\"A residual block.\n \n-  Arguments:\n+  Args:\n     x: input tensor.\n     filters: integer, filters of the bottleneck layer.\n     kernel_size: default 3, kernel size of the bottleneck layer.\n@@ -272,7 +272,7 @@ def block1(x, filters, kernel_size=3, stride=1, conv_shortcut=True, name=None):\n def stack1(x, filters, blocks, stride1=2, name=None):\n   \"\"\"A set of stacked residual blocks.\n \n-  Arguments:\n+  Args:\n     x: input tensor.\n     filters: integer, filters of the bottleneck layer in a block.\n     blocks: integer, blocks in the stacked blocks.\n@@ -291,7 +291,7 @@ def stack1(x, filters, blocks, stride1=2, name=None):\n def block2(x, filters, kernel_size=3, stride=1, conv_shortcut=False, name=None):\n   \"\"\"A residual block.\n \n-  Arguments:\n+  Args:\n       x: input tensor.\n       filters: integer, filters of the bottleneck layer.\n       kernel_size: default 3, kernel size of the bottleneck layer.\n@@ -340,7 +340,7 @@ def block2(x, filters, kernel_size=3, stride=1, conv_shortcut=False, name=None):\n def stack2(x, filters, blocks, stride1=2, name=None):\n   \"\"\"A set of stacked residual blocks.\n \n-  Arguments:\n+  Args:\n       x: input tensor.\n       filters: integer, filters of the bottleneck layer in a block.\n       blocks: integer, blocks in the stacked blocks.\n@@ -366,7 +366,7 @@ def block3(x,\n            name=None):\n   \"\"\"A residual block.\n \n-  Arguments:\n+  Args:\n     x: input tensor.\n     filters: integer, filters of the bottleneck layer.\n     kernel_size: default 3, kernel size of the bottleneck layer.\n@@ -429,7 +429,7 @@ def block3(x,\n def stack3(x, filters, blocks, stride1=2, groups=32, name=None):\n   \"\"\"A set of stacked residual blocks.\n \n-  Arguments:\n+  Args:\n     x: input tensor.\n     filters: integer, filters of the bottleneck layer in a block.\n     blocks: integer, blocks in the stacked blocks.\n@@ -548,7 +548,7 @@ DOC = \"\"\"\n   For ResNet, call `tf.keras.applications.resnet.preprocess_input` on your\n   inputs before passing them to the model.\n \n-  Arguments:\n+  Args:\n     include_top: whether to include the fully-connected\n       layer at the top of the network.\n     weights: one of `None` (random initialization),\n\n@@ -152,7 +152,7 @@ DOC = \"\"\"\n   For ResNetV2, call `tf.keras.applications.resnet_v2.preprocess_input` on your\n   inputs before passing them to the model.\n \n-  Arguments:\n+  Args:\n     include_top: whether to include the fully-connected\n       layer at the top of the network.\n     weights: one of `None` (random initialization),\n\n@@ -71,7 +71,7 @@ def VGG16(\n   For VGG16, call `tf.keras.applications.vgg16.preprocess_input` on your\n   inputs before passing them to the model.\n \n-  Arguments:\n+  Args:\n       include_top: whether to include the 3 fully-connected\n           layers at the top of the network.\n       weights: one of `None` (random initialization),\n\n@@ -71,7 +71,7 @@ def VGG19(\n   For VGG19, call `tf.keras.applications.vgg19.preprocess_input` on your\n   inputs before passing them to the model.\n \n-  Arguments:\n+  Args:\n     include_top: whether to include the 3 fully-connected\n       layers at the top of the network.\n     weights: one of `None` (random initialization),\n\n@@ -73,7 +73,7 @@ def Xception(\n   For Xception, call `tf.keras.applications.xception.preprocess_input` on your\n   inputs before passing them to the model.\n \n-  Arguments:\n+  Args:\n     include_top: whether to include the fully-connected\n       layer at the top of the network.\n     weights: one of `None` (random initialization),\n\n@@ -162,7 +162,7 @@ def backend():\n def cast_to_floatx(x):\n   \"\"\"Cast a Numpy array to the default Keras float type.\n \n-  Arguments:\n+  Args:\n       x: Numpy array or TensorFlow tensor.\n \n   Returns:\n@@ -194,7 +194,7 @@ def cast_to_floatx(x):\n def get_uid(prefix=''):\n   \"\"\"Associates a string prefix with an integer counter in a TensorFlow graph.\n \n-  Arguments:\n+  Args:\n     prefix: String prefix to index.\n \n   Returns:\n@@ -302,7 +302,7 @@ def manual_variable_initialization(value):\n   the user should handle the initialization\n   (e.g. via `tf.compat.v1.initialize_all_variables()`).\n \n-  Arguments:\n+  Args:\n       value: Python boolean.\n   \"\"\"\n   global _MANUAL_VAR_INIT\n@@ -397,7 +397,7 @@ def set_learning_phase(value):\n         training = backend.learning_phase()\n   ```\n \n-  Arguments:\n+  Args:\n       value: Learning phase value, either 0 or 1 (integers).\n              0 = test, 1 = train\n \n@@ -426,7 +426,7 @@ def deprecated_internal_set_learning_phase(value):\n   sets learning phase just for compatibility with code that relied on\n   explicitly setting the learning phase for other values.\n \n-  Arguments:\n+  Args:\n       value: Learning phase value, either 0 or 1 (integers). 0 = test, 1 = train\n \n   Raises:\n@@ -452,7 +452,7 @@ def learning_phase_scope(value):\n \n   The learning phase gets restored to its original value upon exiting the scope.\n \n-  Arguments:\n+  Args:\n      value: Learning phase value, either 0 or 1 (integers).\n             0 = test, 1 = train\n \n@@ -486,7 +486,7 @@ def deprecated_internal_learning_phase_scope(value):\n   We can get rid of this method and its usages when the public API is\n   removed.\n \n-  Arguments:\n+  Args:\n      value: Learning phase value, either 0 or 1 (integers). 0 = test, 1 = train\n \n   Yields:\n@@ -531,7 +531,7 @@ def deprecated_internal_learning_phase_scope(value):\n def eager_learning_phase_scope(value):\n   \"\"\"Internal scope that sets the learning phase in eager / tf.function only.\n \n-  Arguments:\n+  Args:\n       value: Learning phase value, either 0 or 1 (integers).\n              0 = test, 1 = train\n \n@@ -703,7 +703,7 @@ def get_session(op_input_list=()):\n   Note that you can manually set the global session\n   via `K.set_session(sess)`.\n \n-  Arguments:\n+  Args:\n       op_input_list: An option sequence of tensors or ops, which will be used\n         to determine the current graph. Otherwise the default graph will be\n         used.\n@@ -776,7 +776,7 @@ def _scratch_graph(graph=None):\n def set_session(session):\n   \"\"\"Sets the global TensorFlow session.\n \n-  Arguments:\n+  Args:\n       session: A TF Session.\n   \"\"\"\n   global _SESSION\n@@ -843,7 +843,7 @@ def _get_current_tf_device():\n def _is_current_explicit_device(device_type):\n   \"\"\"Check if the current device is explicitly set on the device type specified.\n \n-  Arguments:\n+  Args:\n       device_type: A string containing `GPU` or `CPU` (case-insensitive).\n \n   Returns:\n@@ -901,7 +901,7 @@ def _constant_to_tensor(x, dtype):\n   This is slightly faster than the _to_tensor function, at the cost of\n   handling fewer cases.\n \n-  Arguments:\n+  Args:\n       x: An object to be converted (numpy arrays, floats, ints and lists of\n         them).\n       dtype: The destination type.\n@@ -915,7 +915,7 @@ def _constant_to_tensor(x, dtype):\n def _to_tensor(x, dtype):\n   \"\"\"Convert the input `x` to a tensor of type `dtype`.\n \n-  Arguments:\n+  Args:\n       x: An object to be converted (numpy array, list, tensors).\n       dtype: The destination type.\n \n@@ -930,7 +930,7 @@ def _to_tensor(x, dtype):\n def is_sparse(tensor):\n   \"\"\"Returns whether a tensor is a sparse tensor.\n \n-  Arguments:\n+  Args:\n       tensor: A tensor instance.\n \n   Returns:\n@@ -959,7 +959,7 @@ def is_sparse(tensor):\n def to_dense(tensor):\n   \"\"\"Converts a sparse tensor into a dense tensor and returns it.\n \n-  Arguments:\n+  Args:\n       tensor: A tensor instance (potentially sparse).\n \n   Returns:\n@@ -1019,7 +1019,7 @@ keras_export(v1=['keras.backend.name_scope'], allow_multiple_exports=True)(tf.co\n def variable(value, dtype=None, name=None, constraint=None):\n   \"\"\"Instantiates a variable and returns it.\n \n-  Arguments:\n+  Args:\n       value: Numpy array, initial value of the tensor.\n       dtype: Tensor type.\n       name: Optional name string for the tensor.\n@@ -1094,7 +1094,7 @@ def unique_object_name(name,\n                        avoid_observed_names=False):\n   \"\"\"Makes a object name (or arbitrary string) unique within a TensorFlow graph.\n \n-  Arguments:\n+  Args:\n     name: String name to make unique.\n     name_uid_map: An optional defaultdict(int) to use when creating unique\n       names. If None (default), uses a per-Graph dictionary.\n@@ -1183,7 +1183,7 @@ def _initialize_variables(session):\n def constant(value, dtype=None, shape=None, name=None):\n   \"\"\"Creates a constant tensor.\n \n-  Arguments:\n+  Args:\n       value: A constant value (or list)\n       dtype: The type of the elements of the resulting tensor.\n       shape: Optional dimensions of resulting tensor.\n@@ -1205,7 +1205,7 @@ def is_keras_tensor(x):\n   A \"Keras tensor\" is a tensor that was returned by a Keras layer,\n   (`Layer` class) or by `Input`.\n \n-  Arguments:\n+  Args:\n       x: A candidate tensor.\n \n   Returns:\n@@ -1262,7 +1262,7 @@ def placeholder(shape=None,\n                 ragged=False):\n   \"\"\"Instantiates a placeholder tensor and returns it.\n \n-  Arguments:\n+  Args:\n       shape: Shape of the placeholder\n           (integer tuple, may include `None` entries).\n       ndim: Number of axes of the tensor.\n@@ -1355,7 +1355,7 @@ def placeholder(shape=None,\n def is_placeholder(x):\n   \"\"\"Returns whether `x` is a placeholder.\n \n-  Arguments:\n+  Args:\n       x: A candidate placeholder.\n \n   Returns:\n@@ -1380,7 +1380,7 @@ def is_placeholder(x):\n def shape(x):\n   \"\"\"Returns the symbolic shape of a tensor or variable.\n \n-  Arguments:\n+  Args:\n       x: A tensor or variable.\n \n   Returns:\n@@ -1405,7 +1405,7 @@ def shape(x):\n def int_shape(x):\n   \"\"\"Returns the shape of tensor or variable as a tuple of int or None entries.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n \n   Returns:\n@@ -1436,7 +1436,7 @@ def int_shape(x):\n def ndim(x):\n   \"\"\"Returns the number of axes in a tensor, as an integer.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n \n   Returns:\n@@ -1466,7 +1466,7 @@ def ndim(x):\n def dtype(x):\n   \"\"\"Returns the dtype of a Keras tensor or variable, as a string.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n \n   Returns:\n@@ -1499,7 +1499,7 @@ def dtype(x):\n def eval(x):\n   \"\"\"Evaluates the value of a variable.\n \n-  Arguments:\n+  Args:\n       x: A variable.\n \n   Returns:\n@@ -1522,7 +1522,7 @@ def eval(x):\n def zeros(shape, dtype=None, name=None):\n   \"\"\"Instantiates an all-zeros variable and returns it.\n \n-  Arguments:\n+  Args:\n       shape: Tuple or list of integers, shape of returned Keras variable\n       dtype: data type of returned Keras variable\n       name: name of returned Keras variable\n@@ -1568,7 +1568,7 @@ def zeros(shape, dtype=None, name=None):\n def ones(shape, dtype=None, name=None):\n   \"\"\"Instantiates an all-ones variable and returns it.\n \n-  Arguments:\n+  Args:\n       shape: Tuple of integers, shape of returned Keras variable.\n       dtype: String, data type of returned Keras variable.\n       name: String, name of returned Keras variable.\n@@ -1604,7 +1604,7 @@ def ones(shape, dtype=None, name=None):\n def eye(size, dtype=None, name=None):\n   \"\"\"Instantiate an identity matrix and returns it.\n \n-  Arguments:\n+  Args:\n       size: Integer, number of rows/columns.\n       dtype: String, data type of returned Keras variable.\n       name: String, name of returned Keras variable.\n@@ -1634,7 +1634,7 @@ def eye(size, dtype=None, name=None):\n def zeros_like(x, dtype=None, name=None):\n   \"\"\"Instantiates an all-zeros variable of the same shape as another tensor.\n \n-  Arguments:\n+  Args:\n       x: Keras variable or Keras tensor.\n       dtype: dtype of returned Keras variable.\n              `None` uses the dtype of `x`.\n@@ -1662,7 +1662,7 @@ def zeros_like(x, dtype=None, name=None):\n def ones_like(x, dtype=None, name=None):\n   \"\"\"Instantiates an all-ones variable of the same shape as another tensor.\n \n-  Arguments:\n+  Args:\n       x: Keras variable or tensor.\n       dtype: String, dtype of returned Keras variable.\n            None uses the dtype of x.\n@@ -1686,7 +1686,7 @@ def ones_like(x, dtype=None, name=None):\n def identity(x, name=None):\n   \"\"\"Returns a tensor with the same content as the input tensor.\n \n-  Arguments:\n+  Args:\n       x: The input tensor.\n       name: String, name for the variable to create.\n \n@@ -1701,7 +1701,7 @@ def identity(x, name=None):\n def random_uniform_variable(shape, low, high, dtype=None, name=None, seed=None):\n   \"\"\"Instantiates a variable with values drawn from a uniform distribution.\n \n-  Arguments:\n+  Args:\n       shape: Tuple of integers, shape of returned Keras variable.\n       low: Float, lower boundary of the output interval.\n       high: Float, upper boundary of the output interval.\n@@ -1737,7 +1737,7 @@ def random_normal_variable(shape, mean, scale, dtype=None, name=None,\n                            seed=None):\n   \"\"\"Instantiates a variable with values drawn from a normal distribution.\n \n-  Arguments:\n+  Args:\n       shape: Tuple of integers, shape of returned Keras variable.\n       mean: Float, mean of the normal distribution.\n       scale: Float, standard deviation of the normal distribution.\n@@ -1772,7 +1772,7 @@ def random_normal_variable(shape, mean, scale, dtype=None, name=None,\n def count_params(x):\n   \"\"\"Returns the static number of elements in a variable or tensor.\n \n-  Arguments:\n+  Args:\n       x: Variable or tensor.\n \n   Returns:\n@@ -1799,7 +1799,7 @@ def cast(x, dtype):\n \n   You can cast a Keras variable but it still returns a Keras tensor.\n \n-  Arguments:\n+  Args:\n       x: Keras tensor (or variable).\n       dtype: String, either (`'float16'`, `'float32'`, or `'float64'`).\n \n@@ -1835,7 +1835,7 @@ def update(x, new_x):\n def update_add(x, increment):\n   \"\"\"Update the value of `x` by adding `increment`.\n \n-  Arguments:\n+  Args:\n       x: A Variable.\n       increment: A tensor of same shape as `x`.\n \n@@ -1850,7 +1850,7 @@ def update_add(x, increment):\n def update_sub(x, decrement):\n   \"\"\"Update the value of `x` by subtracting `decrement`.\n \n-  Arguments:\n+  Args:\n       x: A Variable.\n       decrement: A tensor of same shape as `x`.\n \n@@ -1890,7 +1890,7 @@ def moving_average_update(x, value, momentum):\n   >>> x_zdb.numpy()\n   2.0\n \n-  Arguments:\n+  Args:\n       x: A Variable, the moving average.\n       value: A tensor with the same shape as `x`, the new value to be\n         averaged in.\n@@ -1915,7 +1915,7 @@ def dot(x, y):\n \n   This operation corresponds to `numpy.dot(a, b, out=None)`.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n       y: Tensor or variable.\n \n@@ -1987,7 +1987,7 @@ def batch_dot(x, y, axes=None):\n   than the input. If the number of dimensions is reduced to 1,\n   we use `expand_dims` to make sure that ndim is at least 2.\n \n-  Arguments:\n+  Args:\n     x: Keras tensor or variable with `ndim >= 2`.\n     y: Keras tensor or variable with `ndim >= 2`.\n     axes: Tuple or list of integers with target dimensions, or single integer.\n@@ -2170,7 +2170,7 @@ def batch_dot(x, y, axes=None):\n def transpose(x):\n   \"\"\"Transposes a tensor and returns it.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n \n   Returns:\n@@ -2203,7 +2203,7 @@ def transpose(x):\n def gather(reference, indices):\n   \"\"\"Retrieves the elements of indices `indices` in the tensor `reference`.\n \n-  Arguments:\n+  Args:\n       reference: A tensor.\n       indices: An integer tensor of indices.\n \n@@ -2240,7 +2240,7 @@ def gather(reference, indices):\n def max(x, axis=None, keepdims=False):\n   \"\"\"Maximum value in a tensor.\n \n-  Arguments:\n+  Args:\n       x: A tensor or variable.\n       axis: An integer, the axis to find maximum values.\n       keepdims: A boolean, whether to keep the dimensions or not.\n@@ -2260,7 +2260,7 @@ def max(x, axis=None, keepdims=False):\n def min(x, axis=None, keepdims=False):\n   \"\"\"Minimum value in a tensor.\n \n-  Arguments:\n+  Args:\n       x: A tensor or variable.\n       axis: An integer, the axis to find minimum values.\n       keepdims: A boolean, whether to keep the dimensions or not.\n@@ -2280,7 +2280,7 @@ def min(x, axis=None, keepdims=False):\n def sum(x, axis=None, keepdims=False):\n   \"\"\"Sum of the values in a tensor, alongside the specified axis.\n \n-  Arguments:\n+  Args:\n       x: A tensor or variable.\n       axis: An integer, the axis to sum over.\n       keepdims: A boolean, whether to keep the dimensions or not.\n@@ -2300,7 +2300,7 @@ def sum(x, axis=None, keepdims=False):\n def prod(x, axis=None, keepdims=False):\n   \"\"\"Multiplies the values in a tensor, alongside the specified axis.\n \n-  Arguments:\n+  Args:\n       x: A tensor or variable.\n       axis: An integer, the axis to compute the product.\n       keepdims: A boolean, whether to keep the dimensions or not.\n@@ -2320,7 +2320,7 @@ def prod(x, axis=None, keepdims=False):\n def cumsum(x, axis=0):\n   \"\"\"Cumulative sum of the values in a tensor, alongside the specified axis.\n \n-  Arguments:\n+  Args:\n       x: A tensor or variable.\n       axis: An integer, the axis to compute the sum.\n \n@@ -2336,7 +2336,7 @@ def cumsum(x, axis=0):\n def cumprod(x, axis=0):\n   \"\"\"Cumulative product of the values in a tensor, alongside the specified axis.\n \n-  Arguments:\n+  Args:\n       x: A tensor or variable.\n       axis: An integer, the axis to compute the product.\n \n@@ -2351,7 +2351,7 @@ def cumprod(x, axis=0):\n def var(x, axis=None, keepdims=False):\n   \"\"\"Variance of a tensor, alongside the specified axis.\n \n-  Arguments:\n+  Args:\n       x: A tensor or variable.\n       axis: An integer, the axis to compute the variance.\n       keepdims: A boolean, whether to keep the dimensions or not.\n@@ -2375,7 +2375,7 @@ def std(x, axis=None, keepdims=False):\n \n   It is an alias to `tf.math.reduce_std`.\n \n-  Arguments:\n+  Args:\n       x: A tensor or variable. It should have numerical dtypes. Boolean type\n         inputs will be converted to float.\n       axis: An integer, the axis to compute the standard deviation. If `None`\n@@ -2401,7 +2401,7 @@ def std(x, axis=None, keepdims=False):\n def mean(x, axis=None, keepdims=False):\n   \"\"\"Mean of a tensor, alongside the specified axis.\n \n-  Arguments:\n+  Args:\n       x: A tensor or variable.\n       axis: A list of integer. Axes to compute the mean.\n       keepdims: A boolean, whether to keep the dimensions or not.\n@@ -2423,7 +2423,7 @@ def mean(x, axis=None, keepdims=False):\n def any(x, axis=None, keepdims=False):\n   \"\"\"Bitwise reduction (logical OR).\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n       axis: axis along which to perform the reduction.\n       keepdims: whether the drop or broadcast the reduction axes.\n@@ -2441,7 +2441,7 @@ def any(x, axis=None, keepdims=False):\n def all(x, axis=None, keepdims=False):\n   \"\"\"Bitwise reduction (logical AND).\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n       axis: axis along which to perform the reduction.\n       keepdims: whether the drop or broadcast the reduction axes.\n@@ -2459,7 +2459,7 @@ def all(x, axis=None, keepdims=False):\n def argmax(x, axis=-1):\n   \"\"\"Returns the index of the maximum value along an axis.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n       axis: axis along which to perform the reduction.\n \n@@ -2475,7 +2475,7 @@ def argmax(x, axis=-1):\n def argmin(x, axis=-1):\n   \"\"\"Returns the index of the minimum value along an axis.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n       axis: axis along which to perform the reduction.\n \n@@ -2491,7 +2491,7 @@ def argmin(x, axis=-1):\n def square(x):\n   \"\"\"Element-wise square.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n \n   Returns:\n@@ -2506,7 +2506,7 @@ def square(x):\n def abs(x):\n   \"\"\"Element-wise absolute value.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n \n   Returns:\n@@ -2524,7 +2524,7 @@ def sqrt(x):\n      This function clips negative tensor values to 0 before computing the\n      square root.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n \n   Returns:\n@@ -2541,7 +2541,7 @@ def sqrt(x):\n def exp(x):\n   \"\"\"Element-wise exponential.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n \n   Returns:\n@@ -2556,7 +2556,7 @@ def exp(x):\n def log(x):\n   \"\"\"Element-wise log.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n \n   Returns:\n@@ -2572,7 +2572,7 @@ def logsumexp(x, axis=None, keepdims=False):\n   It avoids overflows caused by taking the exp of large inputs and\n   underflows caused by taking the log of small inputs.\n \n-  Arguments:\n+  Args:\n       x: A tensor or variable.\n       axis: An integer, the axis to reduce over.\n       keepdims: A boolean, whether to keep the dimensions or not.\n@@ -2594,7 +2594,7 @@ def round(x):\n \n   In case of tie, the rounding mode used is \"half to even\".\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n \n   Returns:\n@@ -2609,7 +2609,7 @@ def round(x):\n def sign(x):\n   \"\"\"Element-wise sign.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n \n   Returns:\n@@ -2624,7 +2624,7 @@ def sign(x):\n def pow(x, a):\n   \"\"\"Element-wise exponentiation.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n       a: Python integer.\n \n@@ -2640,7 +2640,7 @@ def pow(x, a):\n def clip(x, min_value, max_value):\n   \"\"\"Element-wise value clipping.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n       min_value: Python float, integer, or tensor.\n       max_value: Python float, integer, or tensor.\n@@ -2665,7 +2665,7 @@ def clip(x, min_value, max_value):\n def equal(x, y):\n   \"\"\"Element-wise equality between two tensors.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n       y: Tensor or variable.\n \n@@ -2681,7 +2681,7 @@ def equal(x, y):\n def not_equal(x, y):\n   \"\"\"Element-wise inequality between two tensors.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n       y: Tensor or variable.\n \n@@ -2697,7 +2697,7 @@ def not_equal(x, y):\n def greater(x, y):\n   \"\"\"Element-wise truth value of (x > y).\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n       y: Tensor or variable.\n \n@@ -2713,7 +2713,7 @@ def greater(x, y):\n def greater_equal(x, y):\n   \"\"\"Element-wise truth value of (x >= y).\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n       y: Tensor or variable.\n \n@@ -2729,7 +2729,7 @@ def greater_equal(x, y):\n def less(x, y):\n   \"\"\"Element-wise truth value of (x < y).\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n       y: Tensor or variable.\n \n@@ -2745,7 +2745,7 @@ def less(x, y):\n def less_equal(x, y):\n   \"\"\"Element-wise truth value of (x <= y).\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n       y: Tensor or variable.\n \n@@ -2761,7 +2761,7 @@ def less_equal(x, y):\n def maximum(x, y):\n   \"\"\"Element-wise maximum of two tensors.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n       y: Tensor or variable.\n \n@@ -2787,7 +2787,7 @@ def maximum(x, y):\n def minimum(x, y):\n   \"\"\"Element-wise minimum of two tensors.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n       y: Tensor or variable.\n \n@@ -2803,7 +2803,7 @@ def minimum(x, y):\n def sin(x):\n   \"\"\"Computes sin of x element-wise.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n \n   Returns:\n@@ -2818,7 +2818,7 @@ def sin(x):\n def cos(x):\n   \"\"\"Computes cos of x element-wise.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n \n   Returns:\n@@ -2834,7 +2834,7 @@ def _regular_normalize_batch_in_training(x,\n                                          epsilon=1e-3):\n   \"\"\"Non-fused version of `normalize_batch_in_training`.\n \n-  Arguments:\n+  Args:\n       x: Input tensor or variable.\n       gamma: Tensor by which to scale the input.\n       beta: Tensor with which to center the input.\n@@ -2857,7 +2857,7 @@ def _broadcast_normalize_batch_in_training(x,\n                                            epsilon=1e-3):\n   \"\"\"Non-fused, broadcast version of `normalize_batch_in_training`.\n \n-  Arguments:\n+  Args:\n       x: Input tensor or variable.\n       gamma: Tensor by which to scale the input.\n       beta: Tensor with which to center the input.\n@@ -2900,7 +2900,7 @@ def _fused_normalize_batch_in_training(x,\n                                        epsilon=1e-3):\n   \"\"\"Fused version of `normalize_batch_in_training`.\n \n-  Arguments:\n+  Args:\n       x: Input tensor or variable.\n       gamma: Tensor by which to scale the input.\n       beta: Tensor with which to center the input.\n@@ -2934,7 +2934,7 @@ def _fused_normalize_batch_in_training(x,\n def normalize_batch_in_training(x, gamma, beta, reduction_axes, epsilon=1e-3):\n   \"\"\"Computes mean and std for batch then apply batch_normalization on batch.\n \n-  Arguments:\n+  Args:\n       x: Input tensor or variable.\n       gamma: Tensor by which to scale the input.\n       beta: Tensor with which to center the input.\n@@ -2969,7 +2969,7 @@ def batch_normalization(x, mean, var, beta, gamma, axis=-1, epsilon=1e-3):\n   I.e. returns:\n   `output = (x - mean) / (sqrt(var) + epsilon) * gamma + beta`\n \n-  Arguments:\n+  Args:\n       x: Input tensor or variable.\n       mean: Mean of batch.\n       var: Variance of batch.\n@@ -3030,7 +3030,7 @@ def batch_normalization(x, mean, var, beta, gamma, axis=-1, epsilon=1e-3):\n def concatenate(tensors, axis=-1):\n   \"\"\"Concatenates a list of tensors alongside the specified axis.\n \n-  Arguments:\n+  Args:\n       tensors: list of tensors to concatenate.\n       axis: concatenation axis.\n \n@@ -3069,7 +3069,7 @@ def concatenate(tensors, axis=-1):\n def reshape(x, shape):\n   \"\"\"Reshapes a tensor to the specified shape.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n       shape: Target shape tuple.\n \n@@ -3100,7 +3100,7 @@ def reshape(x, shape):\n def permute_dimensions(x, pattern):\n   \"\"\"Permutes axes in a tensor.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n       pattern: A tuple of\n           dimension indices, e.g. `(0, 2, 1)`.\n@@ -3134,7 +3134,7 @@ def resize_images(x, height_factor, width_factor, data_format,\n                   interpolation='nearest'):\n   \"\"\"Resizes the images contained in a 4D tensor.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable to resize.\n       height_factor: Positive integer.\n       width_factor: Positive integer.\n@@ -3198,7 +3198,7 @@ def resize_images(x, height_factor, width_factor, data_format,\n def resize_volumes(x, depth_factor, height_factor, width_factor, data_format):\n   \"\"\"Resizes the volume contained in a 5D tensor.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable to resize.\n       depth_factor: Positive integer.\n       height_factor: Positive integer.\n@@ -3235,7 +3235,7 @@ def repeat_elements(x, rep, axis):\n   If `x` has shape `(s1, s2, s3)` and `axis` is `1`, the output\n   will have shape `(s1, s2 * rep, s3)`.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n       rep: Python integer, number of times to repeat.\n       axis: Axis along which to repeat.\n@@ -3298,7 +3298,7 @@ def repeat(x, n):\n   if `x` has shape (samples, dim) and `n` is `2`,\n   the output will have shape `(samples, 2, dim)`.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n       n: Python integer, number of times to repeat.\n \n@@ -3339,7 +3339,7 @@ def arange(start, stop=None, step=1, dtype='int32'):\n   The default type of the returned tensor is `'int32'` to\n   match TensorFlow's default.\n \n-  Arguments:\n+  Args:\n       start: Start value.\n       stop: Stop value.\n       step: Difference between two successive values.\n@@ -3372,7 +3372,7 @@ def arange(start, stop=None, step=1, dtype='int32'):\n def tile(x, n):\n   \"\"\"Creates a tensor by tiling `x` by `n`.\n \n-  Arguments:\n+  Args:\n       x: A tensor or variable\n       n: A list of integer. The length must be the same as the number of\n           dimensions in `x`.\n@@ -3391,7 +3391,7 @@ def tile(x, n):\n def flatten(x):\n   \"\"\"Flatten a tensor.\n \n-  Arguments:\n+  Args:\n       x: A tensor or variable.\n \n   Returns:\n@@ -3420,7 +3420,7 @@ def batch_flatten(x):\n \n   In other words, it flattens each data samples of a batch.\n \n-  Arguments:\n+  Args:\n       x: A tensor or variable.\n \n   Returns:\n@@ -3445,7 +3445,7 @@ def batch_flatten(x):\n def expand_dims(x, axis=-1):\n   \"\"\"Adds a 1-sized dimension at index \"axis\".\n \n-  Arguments:\n+  Args:\n       x: A tensor or variable.\n       axis: Position where to add a new axis.\n \n@@ -3461,7 +3461,7 @@ def expand_dims(x, axis=-1):\n def squeeze(x, axis):\n   \"\"\"Removes a 1-dimension from the tensor at index \"axis\".\n \n-  Arguments:\n+  Args:\n       x: A tensor or variable.\n       axis: Axis to drop.\n \n@@ -3477,7 +3477,7 @@ def squeeze(x, axis):\n def temporal_padding(x, padding=(1, 1)):\n   \"\"\"Pads the middle dimension of a 3D tensor.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n       padding: Tuple of 2 integers, how many zeros to\n           add at the start and end of dim 1.\n@@ -3496,7 +3496,7 @@ def temporal_padding(x, padding=(1, 1)):\n def spatial_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None):\n   \"\"\"Pads the 2nd and 3rd dimensions of a 4D tensor.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n       padding: Tuple of 2 tuples, padding pattern.\n       data_format: One of `channels_last` or `channels_first`.\n@@ -3537,7 +3537,7 @@ def spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None):\n   For 'channels_first' data_format,\n   the 3rd, 4th and 5th dimension will be padded.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n       padding: Tuple of 3 tuples, padding pattern.\n       data_format: One of `channels_last` or `channels_first`.\n@@ -3575,7 +3575,7 @@ def spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None):\n def stack(x, axis=0):\n   \"\"\"Stacks a list of rank `R` tensors into a rank `R+1` tensor.\n \n-  Arguments:\n+  Args:\n       x: List of tensors.\n       axis: Axis along which to perform stacking.\n \n@@ -3603,7 +3603,7 @@ def stack(x, axis=0):\n def one_hot(indices, num_classes):\n   \"\"\"Computes the one-hot representation of an integer tensor.\n \n-  Arguments:\n+  Args:\n       indices: nD integer tensor of shape\n           `(batch_size, dim1, dim2, ... dim(n-1))`\n       num_classes: Integer, number of classes to consider.\n@@ -3624,7 +3624,7 @@ def one_hot(indices, num_classes):\n def reverse(x, axes):\n   \"\"\"Reverse a tensor along the specified axes.\n \n-  Arguments:\n+  Args:\n       x: Tensor to reverse.\n       axes: Integer or iterable of integers.\n           Axes to reverse.\n@@ -3677,7 +3677,7 @@ def get_value(x):\n \n   {snippet}\n \n-  Arguments:\n+  Args:\n       x: input variable.\n \n   Returns:\n@@ -3707,7 +3707,7 @@ def get_value(x):\n def batch_get_value(tensors):\n   \"\"\"Returns the value of more than one tensor variable.\n \n-  Arguments:\n+  Args:\n       tensors: list of ops to run.\n \n   Returns:\n@@ -3737,7 +3737,7 @@ def set_value(x, value):\n \n   {snippet}\n \n-  Arguments:\n+  Args:\n       x: Variable to set to a new value.\n       value: Value to set the tensor to, as a Numpy array\n           (of the same shape).\n@@ -3771,7 +3771,7 @@ def set_value(x, value):\n def batch_set_value(tuples):\n   \"\"\"Sets the values of many tensor variables at once.\n \n-  Arguments:\n+  Args:\n       tuples: a list of tuples `(tensor, value)`.\n           `value` should be a Numpy array.\n   \"\"\"\n@@ -3827,7 +3827,7 @@ def print_tensor(x, message=''):\n     array([[1., 2.],\n            [3., 4.]], dtype=float32)>\n \n-  Arguments:\n+  Args:\n       x: Tensor to print.\n       message: Message to print jointly with the tensor.\n \n@@ -3857,7 +3857,7 @@ class GraphExecutionFunction(object):\n   we can modify the values in the dictionary. Through this feed_dict we can\n   provide additional substitutions besides Keras inputs.\n \n-  Arguments:\n+  Args:\n       inputs: Feed placeholders to the computation graph.\n       outputs: Output tensors to fetch.\n       updates: Additional update ops to be run at function call.\n@@ -3925,7 +3925,7 @@ class GraphExecutionFunction(object):\n   def _make_callable(self, feed_arrays, feed_symbols, symbol_vals, session):\n     \"\"\"Generates a callable that runs the graph.\n \n-    Arguments:\n+    Args:\n       feed_arrays: List of input tensors to be fed Numpy arrays at runtime.\n       feed_symbols: List of input tensors to be fed symbolic tensors at runtime.\n       symbol_vals: List of symbolic tensors to be fed to `feed_symbols`.\n@@ -4054,7 +4054,7 @@ def eval_in_eager_or_function(outputs):\n   longer needed, after Keras switches to KerasTensors and op layers\n   work via dispatch.\n \n-  Arguments:\n+  Args:\n     outputs: tensors to fetch.\n   Returns:\n     The value of the tensors (as numpy arrays).\n@@ -4118,7 +4118,7 @@ def eval_in_eager_or_function(outputs):\n def function(inputs, outputs, updates=None, name=None, **kwargs):\n   \"\"\"Instantiates a Keras function.\n \n-  Arguments:\n+  Args:\n       inputs: List of placeholder tensors.\n       outputs: List of output tensors.\n       updates: List of update ops.\n@@ -4166,7 +4166,7 @@ def function(inputs, outputs, updates=None, name=None, **kwargs):\n def gradients(loss, variables):\n   \"\"\"Returns the gradients of `loss` w.r.t. `variables`.\n \n-  Arguments:\n+  Args:\n       loss: Scalar tensor to minimize.\n       variables: List of variables.\n \n@@ -4183,7 +4183,7 @@ def gradients(loss, variables):\n def stop_gradient(variables):\n   \"\"\"Returns `variables` but with zero gradient w.r.t. every other variable.\n \n-  Arguments:\n+  Args:\n       variables: Tensor or list of tensors to consider constant with respect\n         to any other variable.\n \n@@ -4214,7 +4214,7 @@ def rnn(step_function,\n         zero_output_for_mask=False):\n   \"\"\"Iterates over the time dimension of a tensor.\n \n-  Arguments:\n+  Args:\n       step_function: RNN step function.\n           Args;\n               input; Tensor with shape `(samples, ...)` (no time dimension),\n@@ -4492,7 +4492,7 @@ def rnn(step_function,\n       def _step(time, output_ta_t, prev_output, *states):\n         \"\"\"RNN step function.\n \n-        Arguments:\n+        Args:\n             time: Current timestep value.\n             output_ta_t: TensorArray.\n             prev_output: tuple of outputs from time - 1.\n@@ -4540,7 +4540,7 @@ def rnn(step_function,\n       def _step(time, output_ta_t, *states):\n         \"\"\"RNN step function.\n \n-        Arguments:\n+        Args:\n             time: Current timestep value.\n             output_ta_t: TensorArray.\n             *states: List of states.\n@@ -4604,7 +4604,7 @@ def switch(condition, then_expression, else_expression):\n   Note that both `then_expression` and `else_expression`\n   should be symbolic tensors of the *same shape*.\n \n-  Arguments:\n+  Args:\n       condition: tensor (`int` or `bool`).\n       then_expression: either a tensor, or a callable that returns a tensor.\n       else_expression: either a tensor, or a callable that returns a tensor.\n@@ -4668,7 +4668,7 @@ def in_train_phase(x, alt, training=None):\n \n   Note that `alt` should have the *same shape* as `x`.\n \n-  Arguments:\n+  Args:\n       x: What to return in train phase\n           (tensor or callable that returns a tensor).\n       alt: What to return otherwise\n@@ -4714,7 +4714,7 @@ def in_test_phase(x, alt, training=None):\n \n   Note that `alt` should have the *same shape* as `x`.\n \n-  Arguments:\n+  Args:\n       x: What to return in test phase\n           (tensor or callable that returns a tensor).\n       alt: What to return otherwise\n@@ -4745,7 +4745,7 @@ def relu(x, alpha=0., max_value=None, threshold=0):\n   `f(x) = x` for `threshold <= x < max_value`,\n   `f(x) = alpha * (x - threshold)` otherwise.\n \n-  Arguments:\n+  Args:\n       x: A tensor or variable.\n       alpha: A scalar, slope of negative section (default=`0.`).\n       max_value: float. Saturation threshold.\n@@ -4796,7 +4796,7 @@ def relu(x, alpha=0., max_value=None, threshold=0):\n def elu(x, alpha=1.):\n   \"\"\"Exponential linear unit.\n \n-  Arguments:\n+  Args:\n       x: A tensor or variable to compute the activation function for.\n       alpha: A scalar, slope of negative section.\n \n@@ -4816,7 +4816,7 @@ def elu(x, alpha=1.):\n def softmax(x, axis=-1):\n   \"\"\"Softmax of a tensor.\n \n-  Arguments:\n+  Args:\n       x: A tensor or variable.\n       axis: The dimension softmax would be performed on.\n           The default is -1 which indicates the last dimension.\n@@ -4833,7 +4833,7 @@ def softmax(x, axis=-1):\n def softplus(x):\n   \"\"\"Softplus of a tensor.\n \n-  Arguments:\n+  Args:\n       x: A tensor or variable.\n \n   Returns:\n@@ -4848,7 +4848,7 @@ def softplus(x):\n def softsign(x):\n   \"\"\"Softsign of a tensor.\n \n-  Arguments:\n+  Args:\n       x: A tensor or variable.\n \n   Returns:\n@@ -4863,7 +4863,7 @@ def softsign(x):\n def categorical_crossentropy(target, output, from_logits=False, axis=-1):\n   \"\"\"Categorical crossentropy between an output tensor and a target tensor.\n \n-  Arguments:\n+  Args:\n       target: A tensor of the same shape as `output`.\n       output: A tensor resulting from a softmax\n           (unless `from_logits` is True, in which\n@@ -4946,7 +4946,7 @@ def categorical_crossentropy(target, output, from_logits=False, axis=-1):\n def sparse_categorical_crossentropy(target, output, from_logits=False, axis=-1):\n   \"\"\"Categorical crossentropy with integer targets.\n \n-  Arguments:\n+  Args:\n       target: An integer tensor.\n       output: A tensor resulting from a softmax\n           (unless `from_logits` is True, in which\n@@ -5040,7 +5040,7 @@ def sparse_categorical_crossentropy(target, output, from_logits=False, axis=-1):\n def binary_crossentropy(target, output, from_logits=False):\n   \"\"\"Binary crossentropy between an output tensor and a target tensor.\n \n-  Arguments:\n+  Args:\n       target: A tensor with the same shape as `output`.\n       output: A tensor.\n       from_logits: Whether `output` is expected to be a logits tensor.\n@@ -5091,7 +5091,7 @@ def binary_crossentropy(target, output, from_logits=False):\n def sigmoid(x):\n   \"\"\"Element-wise sigmoid.\n \n-  Arguments:\n+  Args:\n       x: A tensor or variable.\n \n   Returns:\n@@ -5110,7 +5110,7 @@ def hard_sigmoid(x):\n   Returns `0.` if `x < -2.5`, `1.` if `x > 2.5`.\n   In `-2.5 <= x <= 2.5`, returns `0.2 * x + 0.5`.\n \n-  Arguments:\n+  Args:\n       x: A tensor or variable.\n \n   Returns:\n@@ -5130,7 +5130,7 @@ def hard_sigmoid(x):\n def tanh(x):\n   \"\"\"Element-wise tanh.\n \n-  Arguments:\n+  Args:\n       x: A tensor or variable.\n \n   Returns:\n@@ -5145,7 +5145,7 @@ def tanh(x):\n def dropout(x, level, noise_shape=None, seed=None):\n   \"\"\"Sets entries in `x` to zero at random, while scaling the entire tensor.\n \n-  Arguments:\n+  Args:\n       x: tensor\n       level: fraction of the entries in the tensor\n           that will be set to 0.\n@@ -5167,7 +5167,7 @@ def dropout(x, level, noise_shape=None, seed=None):\n def l2_normalize(x, axis=None):\n   \"\"\"Normalizes a tensor wrt the L2 norm alongside the specified axis.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n       axis: axis along which to perform normalization.\n \n@@ -5183,7 +5183,7 @@ def l2_normalize(x, axis=None):\n def in_top_k(predictions, targets, k):\n   \"\"\"Returns whether the `targets` are in the top `k` `predictions`.\n \n-  Arguments:\n+  Args:\n       predictions: A tensor of shape `(batch_size, classes)` and type `float32`.\n       targets: A 1D tensor of length `batch_size` and type `int32` or `int64`.\n       k: An `int`, number of top elements to consider.\n@@ -5202,7 +5202,7 @@ def in_top_k(predictions, targets, k):\n def _preprocess_conv1d_input(x, data_format):\n   \"\"\"Transpose and cast the input before the conv1d.\n \n-  Arguments:\n+  Args:\n       x: input tensor.\n       data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n \n@@ -5221,7 +5221,7 @@ def _preprocess_conv1d_input(x, data_format):\n def _preprocess_conv2d_input(x, data_format, force_transpose=False):\n   \"\"\"Transpose and cast the input before the conv2d.\n \n-  Arguments:\n+  Args:\n       x: input tensor.\n       data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n       force_transpose: Boolean. If True, the input will always be transposed\n@@ -5244,7 +5244,7 @@ def _preprocess_conv2d_input(x, data_format, force_transpose=False):\n def _preprocess_conv3d_input(x, data_format):\n   \"\"\"Transpose and cast the input before the conv3d.\n \n-  Arguments:\n+  Args:\n       x: input tensor.\n       data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n \n@@ -5263,7 +5263,7 @@ def _preprocess_conv3d_input(x, data_format):\n def _preprocess_padding(padding):\n   \"\"\"Convert keras' padding to TensorFlow's padding.\n \n-  Arguments:\n+  Args:\n       padding: string, one of 'same' , 'valid'\n \n   Returns:\n@@ -5292,7 +5292,7 @@ def conv1d(x,\n            dilation_rate=1):\n   \"\"\"1D convolution.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n       kernel: kernel tensor.\n       strides: stride integer.\n@@ -5344,7 +5344,7 @@ def conv2d(x,\n            dilation_rate=(1, 1)):\n   \"\"\"2D convolution.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n       kernel: kernel tensor.\n       strides: strides tuple.\n@@ -5392,7 +5392,7 @@ def conv2d_transpose(x,\n \n   transposed convolution).\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n       kernel: kernel tensor.\n       output_shape: 1D int tensor for the output shape.\n@@ -5462,7 +5462,7 @@ def separable_conv1d(x,\n                      dilation_rate=1):\n   \"\"\"1D convolution with separable filters.\n \n-  Arguments:\n+  Args:\n       x: input tensor\n       depthwise_kernel: convolution kernel for the depthwise convolution.\n       pointwise_kernel: kernel for the 1x1 convolution.\n@@ -5532,7 +5532,7 @@ def separable_conv2d(x,\n                      dilation_rate=(1, 1)):\n   \"\"\"2D convolution with separable filters.\n \n-  Arguments:\n+  Args:\n       x: input tensor\n       depthwise_kernel: convolution kernel for the depthwise convolution.\n       pointwise_kernel: kernel for the 1x1 convolution.\n@@ -5590,7 +5590,7 @@ def depthwise_conv2d(x,\n                      dilation_rate=(1, 1)):\n   \"\"\"2D convolution with separable filters.\n \n-  Arguments:\n+  Args:\n       x: input tensor\n       depthwise_kernel: convolution kernel for the depthwise convolution.\n       strides: strides tuple (length 2).\n@@ -5641,7 +5641,7 @@ def conv3d(x,\n            dilation_rate=(1, 1, 1)):\n   \"\"\"3D convolution.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n       kernel: kernel tensor.\n       strides: strides tuple.\n@@ -5685,7 +5685,7 @@ def conv3d_transpose(x,\n \n   transposed convolution).\n \n-  Arguments:\n+  Args:\n       x: input tensor.\n       kernel: kernel tensor.\n       output_shape: 1D int tensor for the output shape.\n@@ -5745,7 +5745,7 @@ def pool2d(x,\n            pool_mode='max'):\n   \"\"\"2D Pooling.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n       pool_size: tuple of 2 integers.\n       strides: tuple of 2 integers.\n@@ -5806,7 +5806,7 @@ def pool3d(x,\n            pool_mode='max'):\n   \"\"\"3D Pooling.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n       pool_size: tuple of 3 integers.\n       strides: tuple of 3 integers.\n@@ -5858,7 +5858,7 @@ def local_conv(inputs,\n                data_format=None):\n   \"\"\"Apply N-D convolution with un-shared weights.\n \n-  Arguments:\n+  Args:\n       inputs: (N+2)-D tensor with shape\n           (batch_size, channels_in, d_in1, ..., d_inN)\n           if data_format='channels_first', or\n@@ -5933,7 +5933,7 @@ def local_conv(inputs,\n def local_conv1d(inputs, kernel, kernel_size, strides, data_format=None):\n   \"\"\"Apply 1D conv with un-shared weights.\n \n-  Arguments:\n+  Args:\n       inputs: 3D tensor with shape:\n           (batch_size, steps, input_dim)\n           if data_format is \"channels_last\" or\n@@ -5975,7 +5975,7 @@ def local_conv2d(inputs,\n                  data_format=None):\n   \"\"\"Apply 2D conv with un-shared weights.\n \n-  Arguments:\n+  Args:\n       inputs: 4D tensor with shape:\n           (batch_size, filters, new_rows, new_cols)\n           if data_format='channels_first'\n@@ -6013,7 +6013,7 @@ def local_conv2d(inputs,\n def bias_add(x, bias, data_format=None):\n   \"\"\"Adds a bias vector to a tensor.\n \n-  Arguments:\n+  Args:\n       x: Tensor or variable.\n       bias: Bias tensor to add.\n       data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n@@ -6061,7 +6061,7 @@ def random_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n \n   It is an alias to `tf.random.normal`.\n \n-  Arguments:\n+  Args:\n       shape: A tuple of integers, the shape of tensor to create.\n       mean: A float, the mean value of the normal distribution to draw samples.\n         Default to 0.0.\n@@ -6097,7 +6097,7 @@ def random_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n def random_uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None):\n   \"\"\"Returns a tensor with uniform distribution of values.\n \n-  Arguments:\n+  Args:\n       shape: A tuple of integers, the shape of tensor to create.\n       minval: A float, lower boundary of the uniform distribution\n           to draw samples.\n@@ -6137,7 +6137,7 @@ def random_binomial(shape, p=0.0, dtype=None, seed=None):\n   distribution of the number of successful Bernoulli process. Only supports\n   `n` = 1 for now.\n \n-  Arguments:\n+  Args:\n       shape: A tuple of integers, the shape of tensor to create.\n       p: A float, `0. <= p <= 1`, probability of binomial distribution.\n       dtype: String, dtype of returned tensor.\n@@ -6166,7 +6166,7 @@ def random_binomial(shape, p=0.0, dtype=None, seed=None):\n def random_bernoulli(shape, p=0.0, dtype=None, seed=None):\n   \"\"\"Returns a tensor with random bernoulli distribution of values.\n \n-  Arguments:\n+  Args:\n       shape: A tuple of integers, the shape of tensor to create.\n       p: A float, `0. <= p <= 1`, probability of bernoulli distribution.\n       dtype: String, dtype of returned tensor.\n@@ -6195,7 +6195,7 @@ def truncated_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n   except that values whose magnitude is more than\n   two standard deviations from the mean are dropped and re-picked.\n \n-  Arguments:\n+  Args:\n       shape: A tuple of integers, the shape of tensor to create.\n       mean: Mean of the values.\n       stddev: Standard deviation of the values.\n@@ -6226,7 +6226,7 @@ def truncated_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n def ctc_label_dense_to_sparse(labels, label_lengths):\n   \"\"\"Converts CTC labels from dense to sparse.\n \n-  Arguments:\n+  Args:\n       labels: dense CTC labels.\n       label_lengths: length of the labels.\n \n@@ -6274,7 +6274,7 @@ def ctc_label_dense_to_sparse(labels, label_lengths):\n def ctc_batch_cost(y_true, y_pred, input_length, label_length):\n   \"\"\"Runs CTC loss algorithm on each batch element.\n \n-  Arguments:\n+  Args:\n       y_true: tensor `(samples, max_string_length)`\n           containing the truth labels.\n       y_pred: tensor `(samples, time_steps, num_categories)`\n@@ -6311,7 +6311,7 @@ def ctc_decode(y_pred, input_length, greedy=True, beam_width=100, top_paths=1):\n   Can use either greedy search (also known as best path)\n   or a constrained dictionary search.\n \n-  Arguments:\n+  Args:\n       y_pred: tensor `(samples, time_steps, num_categories)`\n           containing the prediction, or output of the softmax.\n       input_length: tensor `(samples, )` containing the sequence length for\n@@ -6365,7 +6365,7 @@ def ctc_decode(y_pred, input_length, greedy=True, beam_width=100, top_paths=1):\n def map_fn(fn, elems, name=None, dtype=None):\n   \"\"\"Map the function fn over the elements elems and return the outputs.\n \n-  Arguments:\n+  Args:\n       fn: Callable that will be called upon each element in elems\n       elems: tensor\n       name: A string name for the map node in the graph\n@@ -6382,7 +6382,7 @@ def map_fn(fn, elems, name=None, dtype=None):\n def foldl(fn, elems, initializer=None, name=None):\n   \"\"\"Reduce elems using fn to combine them from left to right.\n \n-  Arguments:\n+  Args:\n       fn: Callable that will be called upon each element in elems and an\n           accumulator, for instance `lambda acc, x: acc + x`\n       elems: tensor\n@@ -6400,7 +6400,7 @@ def foldl(fn, elems, initializer=None, name=None):\n def foldr(fn, elems, initializer=None, name=None):\n   \"\"\"Reduce elems using fn to combine them from right to left.\n \n-  Arguments:\n+  Args:\n       fn: Callable that will be called upon each element in elems and an\n           accumulator, for instance `lambda acc, x: acc + x`\n       elems: tensor\n\n@@ -49,7 +49,7 @@ def epsilon():\n def set_epsilon(value):\n   \"\"\"Sets the value of the fuzz factor used in numeric expressions.\n \n-  Arguments:\n+  Args:\n       value: float. New value of epsilon.\n \n   Example:\n@@ -91,7 +91,7 @@ def set_floatx(value):\n   [mixed precision guide](\n     https://www.tensorflow.org/guide/keras/mixed_precision) for details.\n \n-  Arguments:\n+  Args:\n       value: String; `'float16'`, `'float32'`, or `'float64'`.\n \n   Example:\n@@ -130,7 +130,7 @@ def image_data_format():\n def set_image_data_format(data_format):\n   \"\"\"Sets the value of the image data format convention.\n \n-  Arguments:\n+  Args:\n       data_format: string. `'channels_first'` or `'channels_last'`.\n \n   Example:\n\n@@ -33,7 +33,7 @@ def get_benchmark_name(name):\n \n   This is to generate the metadata of the benchmark test.\n \n-  Arguments:\n+  Args:\n     name: A string, the benchmark name.\n \n   Returns:\n@@ -47,7 +47,7 @@ def get_benchmark_name(name):\n def generate_benchmark_params_cpu_gpu(*params_list):\n   \"\"\"Extend the benchmark names with CPU and GPU suffix.\n \n-  Arguments:\n+  Args:\n     *params_list: A list of tuples represents the benchmark parameters.\n \n   Returns:\n@@ -64,6 +64,16 @@ def generate_benchmark_params_cpu_gpu(*params_list):\n   return benchmark_params\n \n \n+def get_keras_examples_metadata(keras_model,\n+                                batch_size,\n+                                impl='.keras.cfit_graph'):\n+  return {\n+      'model_name': 'keras_examples',\n+      'implementation': keras_model + impl,\n+      'parameters': 'bs_' + str(batch_size),\n+  }\n+\n+\n class TimerCallBack(tf.keras.callbacks.Callback):\n   \"\"\"Callback for logging time in each epoch or batch.\"\"\"\n \n@@ -99,7 +109,7 @@ def measure_performance(model_fn,\n                         distribution_strategy='off'):\n   \"\"\"Run models and measure the performance.\n \n-  Arguments:\n+  Args:\n     model_fn: Model function to be benchmarked.\n     x: Input data. See `x` in the `fit()` method of `keras.Model`.\n     y: Target data. See `y` in the `fit()` method of `keras.Model`.\n\n@@ -65,6 +65,9 @@ class AntirectifierBenchmark(tf.test.Benchmark):\n         loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n         metrics=[\"sparse_categorical_accuracy\"])\n \n+    metadata = benchmark_util.get_keras_examples_metadata(\n+        \"antirectifier\", batch_size)\n+    extras.update(metadata)\n     self.report_benchmark(wall_time=wall_time, metrics=metrics, extras=extras)\n \n   def benchmark_antirectifier_bs_256(self):\n@@ -79,6 +82,9 @@ class AntirectifierBenchmark(tf.test.Benchmark):\n         loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n         metrics=[\"sparse_categorical_accuracy\"])\n \n+    metadata = benchmark_util.get_keras_examples_metadata(\n+        \"antirectifier\", batch_size)\n+    extras.update(metadata)\n     self.report_benchmark(wall_time=wall_time, metrics=metrics, extras=extras)\n \n   def benchmark_antirectifier_bs_512(self):\n@@ -93,6 +99,9 @@ class AntirectifierBenchmark(tf.test.Benchmark):\n         loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n         metrics=[\"sparse_categorical_accuracy\"])\n \n+    metadata = benchmark_util.get_keras_examples_metadata(\n+        \"antirectifier\", batch_size)\n+    extras.update(metadata)\n     self.report_benchmark(wall_time=wall_time, metrics=metrics, extras=extras)\n \n   def benchmark_antirectifier_bs_512_gpu_2(self):\n@@ -112,6 +121,9 @@ class AntirectifierBenchmark(tf.test.Benchmark):\n         loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n         metrics=[\"sparse_categorical_accuracy\"])\n \n+    metadata = benchmark_util.get_keras_examples_metadata(\n+        \"antirectifier\", batch_size)\n+    extras.update(metadata)\n     self.report_benchmark(wall_time=wall_time, metrics=metrics, extras=extras)\n \n \n\n@@ -67,6 +67,9 @@ class BidirectionalLSTMBenchmark(tf.test.Benchmark):\n         loss='binary_crossentropy',\n         metrics=['accuracy'])\n \n+    metadata = benchmark_util.get_keras_examples_metadata(\n+        'bidirectional_lstm', batch_size)\n+    extras.update(metadata)\n     self.report_benchmark(wall_time=wall_time, metrics=metrics, extras=extras)\n \n   def benchmark_bidirect_lstm_imdb_bs_256(self):\n@@ -81,6 +84,9 @@ class BidirectionalLSTMBenchmark(tf.test.Benchmark):\n         loss='binary_crossentropy',\n         metrics=['accuracy'])\n \n+    metadata = benchmark_util.get_keras_examples_metadata(\n+        'bidirectional_lstm', batch_size)\n+    extras.update(metadata)\n     self.report_benchmark(wall_time=wall_time, metrics=metrics, extras=extras)\n \n   def benchmark_bidirect_lstm_imdb_bs_512(self):\n@@ -95,6 +101,9 @@ class BidirectionalLSTMBenchmark(tf.test.Benchmark):\n         loss='binary_crossentropy',\n         metrics=['accuracy'])\n \n+    metadata = benchmark_util.get_keras_examples_metadata(\n+        'bidirectional_lstm', batch_size)\n+    extras.update(metadata)\n     self.report_benchmark(wall_time=wall_time, metrics=metrics, extras=extras)\n \n   def benchmark_bidirect_lstm_imdb_bs_512_gpu_2(self):\n@@ -114,6 +123,9 @@ class BidirectionalLSTMBenchmark(tf.test.Benchmark):\n         loss='binary_crossentropy',\n         metrics=['accuracy'])\n \n+    metadata = benchmark_util.get_keras_examples_metadata(\n+        'bidirectional_lstm', batch_size)\n+    extras.update(metadata)\n     self.report_benchmark(wall_time=wall_time, metrics=metrics, extras=extras)\n \n \n\n@@ -82,6 +82,8 @@ class Cifar10CNNBenchmark(tf.test.Benchmark):\n         loss='categorical_crossentropy',\n         metrics=['accuracy'])\n \n+    metadata = benchmark_util.get_keras_examples_metadata('cnn', batch_size)\n+    extras.update(metadata)\n     self.report_benchmark(wall_time=wall_time, metrics=metrics, extras=extras)\n \n   def benchmark_cnn_cifar10_bs_512(self):\n@@ -97,6 +99,8 @@ class Cifar10CNNBenchmark(tf.test.Benchmark):\n         loss='categorical_crossentropy',\n         metrics=['accuracy'])\n \n+    metadata = benchmark_util.get_keras_examples_metadata('cnn', batch_size)\n+    extras.update(metadata)\n     self.report_benchmark(wall_time=wall_time, metrics=metrics, extras=extras)\n \n   def benchmark_cnn_cifar10_bs_1024(self):\n@@ -112,6 +116,8 @@ class Cifar10CNNBenchmark(tf.test.Benchmark):\n         loss='categorical_crossentropy',\n         metrics=['accuracy'])\n \n+    metadata = benchmark_util.get_keras_examples_metadata('cnn', batch_size)\n+    extras.update(metadata)\n     self.report_benchmark(wall_time=wall_time, metrics=metrics, extras=extras)\n \n   def benchmark_cnn_cifar10_bs_1024_gpu_2(self):\n@@ -132,6 +138,8 @@ class Cifar10CNNBenchmark(tf.test.Benchmark):\n         loss='categorical_crossentropy',\n         metrics=['accuracy'])\n \n+    metadata = benchmark_util.get_keras_examples_metadata('cnn', batch_size)\n+    extras.update(metadata)\n     self.report_benchmark(wall_time=wall_time, metrics=metrics, extras=extras)\n \n \n\n@@ -73,6 +73,8 @@ class ConvMnistBenchmark(tf.test.Benchmark):\n         loss='categorical_crossentropy',\n         metrics=['accuracy'])\n \n+    metadata = benchmark_util.get_keras_examples_metadata('conv', batch_size)\n+    extras.update(metadata)\n     self.report_benchmark(wall_time=wall_time, metrics=metrics, extras=extras)\n \n   def benchmark_conv_mnist_bs_256(self):\n@@ -88,6 +90,8 @@ class ConvMnistBenchmark(tf.test.Benchmark):\n         loss='categorical_crossentropy',\n         metrics=['accuracy'])\n \n+    metadata = benchmark_util.get_keras_examples_metadata('conv', batch_size)\n+    extras.update(metadata)\n     self.report_benchmark(wall_time=wall_time, metrics=metrics, extras=extras)\n \n   def benchmark_conv_mnist_bs_512(self):\n@@ -103,6 +107,8 @@ class ConvMnistBenchmark(tf.test.Benchmark):\n         loss='categorical_crossentropy',\n         metrics=['accuracy'])\n \n+    metadata = benchmark_util.get_keras_examples_metadata('conv', batch_size)\n+    extras.update(metadata)\n     self.report_benchmark(wall_time=wall_time, metrics=metrics, extras=extras)\n \n   def benchmark_conv_mnist_bs_512_gpu_2(self):\n@@ -123,6 +129,8 @@ class ConvMnistBenchmark(tf.test.Benchmark):\n         loss='categorical_crossentropy',\n         metrics=['accuracy'])\n \n+    metadata = benchmark_util.get_keras_examples_metadata('conv', batch_size)\n+    extras.update(metadata)\n     self.report_benchmark(wall_time=wall_time, metrics=metrics, extras=extras)\n \n \n\n@@ -22,6 +22,7 @@ import tensorflow as tf\n import timeit\n import numpy as np\n \n+from keras.benchmarks import benchmark_util\n from keras.benchmarks import distribution_util\n \n \n@@ -66,7 +67,7 @@ class CustomMnistBenchmark(tf.test.Benchmark):\n   def train_step(self, inputs, model, loss_fn, optimizer, batch_size):\n     \"\"\"Compute loss and optimize model by optimizer.\n \n-    Arguments:\n+    Args:\n       inputs: `tf.data`.\n       model: See `model` in `train_function()` method.\n       loss_fn: See `loss_fn` in `train_function()` method.\n@@ -89,7 +90,7 @@ class CustomMnistBenchmark(tf.test.Benchmark):\n                              batch_size, distribution_strategy):\n     \"\"\"Train step in distribution strategy setting.\n \n-    Arguments:\n+    Args:\n       batch_dataset: `tf.data`.\n       model: See `model` in `train_function()` method.\n       loss_fn: See `loss_fn` in `train_function()` method.\n@@ -125,7 +126,7 @@ class CustomMnistBenchmark(tf.test.Benchmark):\n \n     train_step_time.\n \n-    Arguments:\n+    Args:\n       model: Model function to be benchmarked.\n       train_dataset: `tf.data` dataset. Should return a tuple of either (inputs,\n         targets) or (inputs, targets, sample_weights).\n@@ -180,7 +181,7 @@ class CustomMnistBenchmark(tf.test.Benchmark):\n                           distribution_strategy=None):\n     \"\"\"Run models and measure the performance.\n \n-    Arguments:\n+    Args:\n       model_fn: Model function to be benchmarked.\n       dataset: `tf.data` dataset. Should return a tuple of either (inputs,\n         targets) or (inputs, targets, sample_weights).\n@@ -281,7 +282,10 @@ class CustomMnistBenchmark(tf.test.Benchmark):\n     metrics, wall_time = self.measure_performance(model, train_dataset, loss_fn,\n                                                   optimizer, batch_size,\n                                                   run_iters, self.epochs)\n-    self.report_benchmark(iters=run_iters, wall_time=wall_time, metrics=metrics)\n+    extras = benchmark_util.get_keras_examples_metadata('conv', batch_size,\n+                                                        '.keras.ctl_graph')\n+    self.report_benchmark(\n+        iters=run_iters, wall_time=wall_time, metrics=metrics, extras=extras)\n \n   def benchmark_custom_training_mnist_bs_256(self):\n     \"\"\"Measure performance with batch_size=256 and run_iters=5.\"\"\"\n@@ -300,7 +304,10 @@ class CustomMnistBenchmark(tf.test.Benchmark):\n     metrics, wall_time = self.measure_performance(model, train_dataset, loss_fn,\n                                                   optimizer, batch_size,\n                                                   run_iters, self.epochs)\n-    self.report_benchmark(iters=run_iters, wall_time=wall_time, metrics=metrics)\n+    extras = benchmark_util.get_keras_examples_metadata('conv', batch_size,\n+                                                        '.keras.ctl_graph')\n+    self.report_benchmark(\n+        iters=run_iters, wall_time=wall_time, metrics=metrics, extras=extras)\n \n   def benchmark_custom_training_mnist_bs_512(self):\n     \"\"\"Measure performance with batch_size=512 and run_iters=10.\"\"\"\n@@ -319,7 +326,10 @@ class CustomMnistBenchmark(tf.test.Benchmark):\n     metrics, wall_time = self.measure_performance(model, train_dataset, loss_fn,\n                                                   optimizer, batch_size,\n                                                   run_iters, self.epochs)\n-    self.report_benchmark(iters=run_iters, wall_time=wall_time, metrics=metrics)\n+    extras = benchmark_util.get_keras_examples_metadata('conv', batch_size,\n+                                                        '.keras.ctl_graph')\n+    self.report_benchmark(\n+        iters=run_iters, wall_time=wall_time, metrics=metrics, extras=extras)\n \n   def benchmark_custom_training_mnist_bs_512_gpu_2(self):\n     \"\"\"Measure performance with batch_size=512, run_iters=10, gpu=2 and\n@@ -353,7 +363,10 @@ class CustomMnistBenchmark(tf.test.Benchmark):\n                                                   optimizer, batch_size,\n                                                   run_iters, self.epochs,\n                                                   strategy)\n-    self.report_benchmark(iters=run_iters, wall_time=wall_time, metrics=metrics)\n+    extras = benchmark_util.get_keras_examples_metadata('conv', batch_size,\n+                                                        '.keras.ctl_graph')\n+    self.report_benchmark(\n+        iters=run_iters, wall_time=wall_time, metrics=metrics, extras=extras)\n \n \n if __name__ == '__main__':\n\n@@ -73,6 +73,9 @@ class HierarchicalRNNBenchmark(tf.test.Benchmark):\n         loss='categorical_crossentropy',\n         metrics=['accuracy'])\n \n+    metadata = benchmark_util.get_keras_examples_metadata(\n+        'hierarchical_rnn', batch_size)\n+    extras.update(metadata)\n     self.report_benchmark(wall_time=wall_time, metrics=metrics, extras=extras)\n \n   def benchmark_hrnn_mnist_bs_512(self):\n@@ -87,6 +90,9 @@ class HierarchicalRNNBenchmark(tf.test.Benchmark):\n         loss='categorical_crossentropy',\n         metrics=['accuracy'])\n \n+    metadata = benchmark_util.get_keras_examples_metadata(\n+        'hierarchical_rnn', batch_size)\n+    extras.update(metadata)\n     self.report_benchmark(wall_time=wall_time, metrics=metrics, extras=extras)\n \n   def benchmark_hrnn_mnist_bs_1024(self):\n@@ -101,6 +107,9 @@ class HierarchicalRNNBenchmark(tf.test.Benchmark):\n         loss='categorical_crossentropy',\n         metrics=['accuracy'])\n \n+    metadata = benchmark_util.get_keras_examples_metadata(\n+        'hierarchical_rnn', batch_size)\n+    extras.update(metadata)\n     self.report_benchmark(wall_time=wall_time, metrics=metrics, extras=extras)\n \n   def benchmark_hrnn_mnist_bs_1024_gpu_2(self):\n@@ -120,6 +129,9 @@ class HierarchicalRNNBenchmark(tf.test.Benchmark):\n         loss='categorical_crossentropy',\n         metrics=['accuracy'])\n \n+    metadata = benchmark_util.get_keras_examples_metadata(\n+        'hierarchical_rnn', batch_size)\n+    extras.update(metadata)\n     self.report_benchmark(wall_time=wall_time, metrics=metrics, extras=extras)\n \n \n\n@@ -73,6 +73,8 @@ class IRNNMnistBenchmark(tf.test.Benchmark):\n         loss='categorical_crossentropy',\n         metrics=['accuracy'])\n \n+    metadata = benchmark_util.get_keras_examples_metadata('irnn', batch_size)\n+    extras.update(metadata)\n     self.report_benchmark(wall_time=wall_time, metrics=metrics, extras=extras)\n \n   def benchmark_irnn_mnist_bs_512(self):\n@@ -87,6 +89,8 @@ class IRNNMnistBenchmark(tf.test.Benchmark):\n         loss='categorical_crossentropy',\n         metrics=['accuracy'])\n \n+    metadata = benchmark_util.get_keras_examples_metadata('irnn', batch_size)\n+    extras.update(metadata)\n     self.report_benchmark(wall_time=wall_time, metrics=metrics, extras=extras)\n \n   def benchmark_irnn_mnist_bs_1024(self):\n@@ -101,6 +105,8 @@ class IRNNMnistBenchmark(tf.test.Benchmark):\n         loss='categorical_crossentropy',\n         metrics=['accuracy'])\n \n+    metadata = benchmark_util.get_keras_examples_metadata('irnn', batch_size)\n+    extras.update(metadata)\n     self.report_benchmark(wall_time=wall_time, metrics=metrics, extras=extras)\n \n   def benchmark_irnn_mnist_bs_1024_gpu_2(self):\n@@ -120,6 +126,8 @@ class IRNNMnistBenchmark(tf.test.Benchmark):\n         loss='categorical_crossentropy',\n         metrics=['accuracy'])\n \n+    metadata = benchmark_util.get_keras_examples_metadata('irnn', batch_size)\n+    extras.update(metadata)\n     self.report_benchmark(wall_time=wall_time, metrics=metrics, extras=extras)\n \n \n\n@@ -73,6 +73,8 @@ class MLPReutersBenchmark(tf.test.Benchmark):\n         loss='categorical_crossentropy',\n         metrics=['accuracy'])\n \n+    metadata = benchmark_util.get_keras_examples_metadata('mlp', batch_size)\n+    extras.update(metadata)\n     self.report_benchmark(wall_time=wall_time, metrics=metrics, extras=extras)\n \n   def benchmark_mlp_reuters_bs_256(self):\n@@ -88,6 +90,8 @@ class MLPReutersBenchmark(tf.test.Benchmark):\n         loss='categorical_crossentropy',\n         metrics=['accuracy'])\n \n+    metadata = benchmark_util.get_keras_examples_metadata('mlp', batch_size)\n+    extras.update(metadata)\n     self.report_benchmark(wall_time=wall_time, metrics=metrics, extras=extras)\n \n   def benchmark_mlp_reuters_bs_512(self):\n@@ -103,6 +107,8 @@ class MLPReutersBenchmark(tf.test.Benchmark):\n         loss='categorical_crossentropy',\n         metrics=['accuracy'])\n \n+    metadata = benchmark_util.get_keras_examples_metadata('mlp', batch_size)\n+    extras.update(metadata)\n     self.report_benchmark(wall_time=wall_time, metrics=metrics, extras=extras)\n \n   def benchmark_mlp_reuters_bs_512_gpu_2(self):\n@@ -123,6 +129,8 @@ class MLPReutersBenchmark(tf.test.Benchmark):\n         loss='categorical_crossentropy',\n         metrics=['accuracy'])\n \n+    metadata = benchmark_util.get_keras_examples_metadata('mlp', batch_size)\n+    extras.update(metadata)\n     self.report_benchmark(wall_time=wall_time, metrics=metrics, extras=extras)\n \n \n\n@@ -77,6 +77,9 @@ class TextWithTransformerBenchmark(tf.test.Benchmark):\n         loss='sparse_categorical_crossentropy',\n         metrics=['accuracy'])\n \n+    metadata = benchmark_util.get_keras_examples_metadata(\n+        'transformer', batch_size)\n+    extras.update(metadata)\n     self.report_benchmark(wall_time=wall_time, metrics=metrics, extras=extras)\n \n   def benchmark_text_classification_bs_256(self):\n@@ -91,6 +94,9 @@ class TextWithTransformerBenchmark(tf.test.Benchmark):\n         loss='sparse_categorical_crossentropy',\n         metrics=['accuracy'])\n \n+    metadata = benchmark_util.get_keras_examples_metadata(\n+        'transformer', batch_size)\n+    extras.update(metadata)\n     self.report_benchmark(wall_time=wall_time, metrics=metrics, extras=extras)\n \n   def benchmark_text_classification_bs_512(self):\n@@ -105,6 +111,9 @@ class TextWithTransformerBenchmark(tf.test.Benchmark):\n         loss='sparse_categorical_crossentropy',\n         metrics=['accuracy'])\n \n+    metadata = benchmark_util.get_keras_examples_metadata(\n+        'transformer', batch_size)\n+    extras.update(metadata)\n     self.report_benchmark(wall_time=wall_time, metrics=metrics, extras=extras)\n \n   def benchmark_text_classification_bs_512_gpu_2(self):\n@@ -124,6 +133,9 @@ class TextWithTransformerBenchmark(tf.test.Benchmark):\n         loss='sparse_categorical_crossentropy',\n         metrics=['accuracy'])\n \n+    metadata = benchmark_util.get_keras_examples_metadata(\n+        'transformer', batch_size)\n+    extras.update(metadata)\n     self.report_benchmark(wall_time=wall_time, metrics=metrics, extras=extras)\n \n \n\n@@ -58,7 +58,7 @@ class KerasOptimizerBenchmark(\n   def benchmark_optimizer(self, optimizer, num_iters):\n     \"\"\"Optimizer benchmark with Bidirectional LSTM model on IMDB data.\n \n-    Arguments:\n+    Args:\n       optimizer: The optimizer instance to be benchmarked.\n       num_iters: The number of iterations to run for performance measurement.\n     \"\"\"\n\n@@ -55,6 +55,7 @@ except ImportError:\n   requests = None\n \n \n+# Note: `configure_callbacks` is only used in TF1.\n def configure_callbacks(callbacks,\n                         model,\n                         do_validation=False,\n@@ -67,7 +68,7 @@ def configure_callbacks(callbacks,\n                         mode=ModeKeys.TRAIN):\n   \"\"\"Configures callbacks for use in various training loops.\n \n-  Arguments:\n+  Args:\n       callbacks: List of Callbacks.\n       model: Model being trained.\n       do_validation: Whether or not validation loop will be run.\n@@ -128,7 +129,7 @@ def set_callback_parameters(callback_list,\n                             mode=ModeKeys.TRAIN):\n   \"\"\"Sets callback parameters.\n \n-  Arguments:\n+  Args:\n       callback_list: CallbackList instance.\n       model: Model being trained.\n       do_validation: Whether or not validation loop will be run.\n@@ -198,7 +199,7 @@ class CallbackList(object):\n     to call them all at once via a single endpoint\n     (e.g. `callback_list.on_epoch_end(...)`).\n \n-    Arguments:\n+    Args:\n       callbacks: List of `Callback` instances.\n       add_history: Whether a `History` callback should be added, if one does not\n         already exist in the `callbacks` list.\n@@ -379,7 +380,7 @@ class CallbackList(object):\n \n     This function should only be called during TRAIN mode.\n \n-    Arguments:\n+    Args:\n         epoch: Integer, index of epoch.\n         logs: Dict. Currently no data is passed to this argument for this method\n           but that may change in the future.\n@@ -399,7 +400,7 @@ class CallbackList(object):\n \n     This function should only be called during TRAIN mode.\n \n-    Arguments:\n+    Args:\n         epoch: Integer, index of epoch.\n         logs: Dict, metric results for this training epoch, and for the\n           validation epoch if validation is performed. Validation result keys\n@@ -418,7 +419,7 @@ class CallbackList(object):\n   def on_train_batch_begin(self, batch, logs=None):\n     \"\"\"Calls the `on_train_batch_begin` methods of its callbacks.\n \n-    Arguments:\n+    Args:\n         batch: Integer, index of batch within the current epoch.\n         logs: Dict, contains the return value of `model.train_step`. Typically,\n           the values of the `Model`'s metrics are returned.  Example:\n@@ -430,7 +431,7 @@ class CallbackList(object):\n   def on_train_batch_end(self, batch, logs=None):\n     \"\"\"Calls the `on_train_batch_end` methods of its callbacks.\n \n-    Arguments:\n+    Args:\n         batch: Integer, index of batch within the current epoch.\n         logs: Dict. Aggregated metric results up until this batch.\n     \"\"\"\n@@ -440,7 +441,7 @@ class CallbackList(object):\n   def on_test_batch_begin(self, batch, logs=None):\n     \"\"\"Calls the `on_test_batch_begin` methods of its callbacks.\n \n-    Arguments:\n+    Args:\n         batch: Integer, index of batch within the current epoch.\n         logs: Dict, contains the return value of `model.test_step`. Typically,\n           the values of the `Model`'s metrics are returned.  Example:\n@@ -452,7 +453,7 @@ class CallbackList(object):\n   def on_test_batch_end(self, batch, logs=None):\n     \"\"\"Calls the `on_test_batch_end` methods of its callbacks.\n \n-    Arguments:\n+    Args:\n         batch: Integer, index of batch within the current epoch.\n         logs: Dict. Aggregated metric results up until this batch.\n     \"\"\"\n@@ -462,7 +463,7 @@ class CallbackList(object):\n   def on_predict_batch_begin(self, batch, logs=None):\n     \"\"\"Calls the `on_predict_batch_begin` methods of its callbacks.\n \n-    Arguments:\n+    Args:\n         batch: Integer, index of batch within the current epoch.\n         logs: Dict, contains the return value of `model.predict_step`,\n           it typically returns a dict with a key 'outputs' containing\n@@ -474,7 +475,7 @@ class CallbackList(object):\n   def on_predict_batch_end(self, batch, logs=None):\n     \"\"\"Calls the `on_predict_batch_end` methods of its callbacks.\n \n-    Arguments:\n+    Args:\n         batch: Integer, index of batch within the current epoch.\n         logs: Dict. Aggregated metric results up until this batch.\n     \"\"\"\n@@ -484,7 +485,7 @@ class CallbackList(object):\n   def on_train_begin(self, logs=None):\n     \"\"\"Calls the `on_train_begin` methods of its callbacks.\n \n-    Arguments:\n+    Args:\n         logs: Dict. Currently no data is passed to this argument for this method\n           but that may change in the future.\n     \"\"\"\n@@ -501,7 +502,7 @@ class CallbackList(object):\n   def on_train_end(self, logs=None):\n     \"\"\"Calls the `on_train_end` methods of its callbacks.\n \n-    Arguments:\n+    Args:\n         logs: Dict. Currently no data is passed to this argument for this method\n           but that may change in the future.\n     \"\"\"\n@@ -518,7 +519,7 @@ class CallbackList(object):\n   def on_test_begin(self, logs=None):\n     \"\"\"Calls the `on_test_begin` methods of its callbacks.\n \n-    Arguments:\n+    Args:\n         logs: Dict. Currently no data is passed to this argument for this method\n           but that may change in the future.\n     \"\"\"\n@@ -535,7 +536,7 @@ class CallbackList(object):\n   def on_test_end(self, logs=None):\n     \"\"\"Calls the `on_test_end` methods of its callbacks.\n \n-    Arguments:\n+    Args:\n         logs: Dict. Currently no data is passed to this argument for this method\n           but that may change in the future.\n     \"\"\"\n@@ -552,7 +553,7 @@ class CallbackList(object):\n   def on_predict_begin(self, logs=None):\n     \"\"\"Calls the 'on_predict_begin` methods of its callbacks.\n \n-    Arguments:\n+    Args:\n         logs: Dict. Currently no data is passed to this argument for this method\n           but that may change in the future.\n     \"\"\"\n@@ -569,7 +570,7 @@ class CallbackList(object):\n   def on_predict_end(self, logs=None):\n     \"\"\"Calls the `on_predict_end` methods of its callbacks.\n \n-    Arguments:\n+    Args:\n         logs: Dict. Currently no data is passed to this argument for this method\n           but that may change in the future.\n     \"\"\"\n@@ -634,7 +635,7 @@ class Callback(object):\n     Subclasses should override for any actions to run. This function should only\n     be called during TRAIN mode.\n \n-    Arguments:\n+    Args:\n         epoch: Integer, index of epoch.\n         logs: Dict. Currently no data is passed to this argument for this method\n           but that may change in the future.\n@@ -647,7 +648,7 @@ class Callback(object):\n     Subclasses should override for any actions to run. This function should only\n     be called during TRAIN mode.\n \n-    Arguments:\n+    Args:\n         epoch: Integer, index of epoch.\n         logs: Dict, metric results for this training epoch, and for the\n           validation epoch if validation is performed. Validation result keys\n@@ -666,7 +667,7 @@ class Callback(object):\n     `tf.keras.Model` is set to `N`, this method will only be called every `N`\n     batches.\n \n-    Arguments:\n+    Args:\n         batch: Integer, index of batch within the current epoch.\n         logs: Dict, contains the return value of `model.train_step`. Typically,\n           the values of the `Model`'s metrics are returned.  Example:\n@@ -686,7 +687,7 @@ class Callback(object):\n     `tf.keras.Model` is set to `N`, this method will only be called every `N`\n     batches.\n \n-    Arguments:\n+    Args:\n         batch: Integer, index of batch within the current epoch.\n         logs: Dict. Aggregated metric results up until this batch.\n     \"\"\"\n@@ -707,7 +708,7 @@ class Callback(object):\n     `tf.keras.Model` is set to `N`, this method will only be called every `N`\n     batches.\n \n-    Arguments:\n+    Args:\n         batch: Integer, index of batch within the current epoch.\n         logs: Dict, contains the return value of `model.test_step`. Typically,\n           the values of the `Model`'s metrics are returned.  Example:\n@@ -728,7 +729,7 @@ class Callback(object):\n     `tf.keras.Model` is set to `N`, this method will only be called every `N`\n     batches.\n \n-    Arguments:\n+    Args:\n         batch: Integer, index of batch within the current epoch.\n         logs: Dict. Aggregated metric results up until this batch.\n     \"\"\"\n@@ -744,7 +745,7 @@ class Callback(object):\n     `tf.keras.Model` is set to `N`, this method will only be called every `N`\n     batches.\n \n-    Arguments:\n+    Args:\n         batch: Integer, index of batch within the current epoch.\n         logs: Dict, contains the return value of `model.predict_step`,\n           it typically returns a dict with a key 'outputs' containing\n@@ -762,7 +763,7 @@ class Callback(object):\n     `tf.keras.Model` is set to `N`, this method will only be called every `N`\n     batches.\n \n-    Arguments:\n+    Args:\n         batch: Integer, index of batch within the current epoch.\n         logs: Dict. Aggregated metric results up until this batch.\n     \"\"\"\n@@ -773,7 +774,7 @@ class Callback(object):\n \n     Subclasses should override for any actions to run.\n \n-    Arguments:\n+    Args:\n         logs: Dict. Currently no data is passed to this argument for this method\n           but that may change in the future.\n     \"\"\"\n@@ -784,7 +785,7 @@ class Callback(object):\n \n     Subclasses should override for any actions to run.\n \n-    Arguments:\n+    Args:\n         logs: Dict. Currently the output of the last call to `on_epoch_end()`\n           is passed to this argument for this method but that may change in\n           the future.\n@@ -796,7 +797,7 @@ class Callback(object):\n \n     Subclasses should override for any actions to run.\n \n-    Arguments:\n+    Args:\n         logs: Dict. Currently no data is passed to this argument for this method\n           but that may change in the future.\n     \"\"\"\n@@ -807,7 +808,7 @@ class Callback(object):\n \n     Subclasses should override for any actions to run.\n \n-    Arguments:\n+    Args:\n         logs: Dict. Currently the output of the last call to\n           `on_test_batch_end()` is passed to this argument for this method\n           but that may change in the future.\n@@ -819,7 +820,7 @@ class Callback(object):\n \n     Subclasses should override for any actions to run.\n \n-    Arguments:\n+    Args:\n         logs: Dict. Currently no data is passed to this argument for this method\n           but that may change in the future.\n     \"\"\"\n@@ -830,7 +831,7 @@ class Callback(object):\n \n     Subclasses should override for any actions to run.\n \n-    Arguments:\n+    Args:\n         logs: Dict. Currently no data is passed to this argument for this method\n           but that may change in the future.\n     \"\"\"\n@@ -859,7 +860,7 @@ class BaseLogger(Callback):\n \n   This callback is automatically applied to every Keras model.\n \n-  Arguments:\n+  Args:\n       stateful_metrics: Iterable of string names of metrics that\n           should *not* be averaged over an epoch.\n           Metrics in this list will be logged as-is in `on_epoch_end`.\n@@ -925,7 +926,7 @@ class TerminateOnNaN(Callback):\n class ProgbarLogger(Callback):\n   \"\"\"Callback that prints metrics to stdout.\n \n-  Arguments:\n+  Args:\n       count_mode: One of `\"steps\"` or `\"samples\"`.\n           Whether the progress bar should\n           count samples seen or steps (batches) seen.\n@@ -1154,7 +1155,7 @@ class ModelCheckpoint(Callback):\n   model.load_weights(checkpoint_filepath)\n   ```\n \n-  Arguments:\n+  Args:\n       filepath: string or `PathLike`, path to save the model file. e.g.\n         filepath = os.path.join(working_dir, 'ckpt', file_name). `filepath`\n         can contain named formatting options, which will be filled the value of\n@@ -1349,7 +1350,7 @@ class ModelCheckpoint(Callback):\n   def _save_model(self, epoch, logs):\n     \"\"\"Saves the model.\n \n-    Arguments:\n+    Args:\n         epoch: the epoch this iteration is in.\n         logs: the `logs` dict passed in to `on_batch_end` or `on_epoch_end`.\n     \"\"\"\n@@ -1470,7 +1471,7 @@ class ModelCheckpoint(Callback):\n         file_paths[-1])\n     ```\n \n-    Arguments:\n+    Args:\n         pattern: The file pattern that may optionally contain python placeholder\n             such as `{epoch:02d}`.\n \n@@ -1574,7 +1575,7 @@ class BackupAndRestore(Callback):\n   >>> len(history.history['loss'])\n   6\n \n-  Arguments:\n+  Args:\n       backup_dir: String, path to store the checkpoint.\n         e.g. backup_dir = os.path.join(working_dir, 'backup')\n         This is the directory in which the system stores temporary files to\n@@ -1657,7 +1658,7 @@ class EarlyStopping(Callback):\n   The quantity to be monitored needs to be available in `logs` dict.\n   To make it so, pass the loss or metrics at `model.compile()`.\n \n-  Arguments:\n+  Args:\n     monitor: Quantity to be monitored.\n     min_delta: Minimum change in the monitored quantity\n         to qualify as an improvement, i.e. an absolute\n@@ -1790,7 +1791,7 @@ class RemoteMonitor(Callback):\n   `\"application/json\"`.\n   Otherwise the serialized JSON will be sent within a form.\n \n-  Arguments:\n+  Args:\n     root: String; root url of the target server.\n     path: String; path relative to `root` to which the events will be sent.\n     field: String; JSON field under which the data will be stored.\n@@ -1850,7 +1851,7 @@ class LearningRateScheduler(Callback):\n   and current learning rate, and applies the updated learning rate\n   on the optimizer.\n \n-  Arguments:\n+  Args:\n     schedule: a function that takes an epoch index (integer, indexed from 0)\n         and current learning rate (float) as inputs and returns a new\n         learning rate as output (float).\n@@ -1976,7 +1977,7 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):\n   You can find more information about TensorBoard\n   [here](https://www.tensorflow.org/get_started/summaries_and_tensorboard).\n \n-  Arguments:\n+  Args:\n       log_dir: the path of the directory where to save the log files to be\n         parsed by TensorBoard. e.g. log_dir = os.path.join(working_dir, 'logs')\n         This directory should not be reused by any other callbacks.\n@@ -2282,7 +2283,7 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):\n   def _init_profile_batch(self, profile_batch):\n     \"\"\"Validate profile_batch value and set the range of batches to profile.\n \n-    Arguments:\n+    Args:\n       profile_batch: The range of batches to profile. Should be a non-negative\n         integer or a comma separated string of pair of positive integers. A pair\n         of positive integers signify a range of batches to profile.\n@@ -2423,7 +2424,7 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):\n   def _log_epoch_metrics(self, epoch, logs):\n     \"\"\"Writes epoch metrics out as scalar summaries.\n \n-    Arguments:\n+    Args:\n         epoch: Int. The global step to use for TensorBoard.\n         logs: Dict. Keys are scalar summary names, values are scalars.\n     \"\"\"\n@@ -2506,7 +2507,7 @@ class ReduceLROnPlateau(Callback):\n   model.fit(X_train, Y_train, callbacks=[reduce_lr])\n   ```\n \n-  Arguments:\n+  Args:\n       monitor: quantity to be monitored.\n       factor: factor by which the learning rate will be reduced.\n         `new_lr = lr * factor`.\n@@ -2627,7 +2628,7 @@ class CSVLogger(Callback):\n   model.fit(X_train, Y_train, callbacks=[csv_logger])\n   ```\n \n-  Arguments:\n+  Args:\n       filename: Filename of the CSV file, e.g. `'run/log.csv'`.\n       separator: String used to separate elements in the CSV file.\n       append: Boolean. True: append if file exists (useful for continuing\n@@ -2719,7 +2720,7 @@ class LambdaCallback(Callback):\n   - `on_train_begin` and `on_train_end` expect one positional argument:\n     `logs`\n \n-  Arguments:\n+  Args:\n       on_epoch_begin: called at the beginning of every epoch.\n       on_epoch_end: called at the end of every epoch.\n       on_batch_begin: called at the beginning of every batch.\n\n@@ -54,7 +54,7 @@ class TensorBoard(callbacks.TensorBoard):\n   You can find more information about TensorBoard\n   [here](https://www.tensorflow.org/get_started/summaries_and_tensorboard).\n \n-  Arguments:\n+  Args:\n       log_dir: the path of the directory where to save the log files to be\n         parsed by TensorBoard.\n       histogram_freq: frequency (in epochs) at which to compute activation and\n@@ -311,7 +311,7 @@ class TensorBoard(callbacks.TensorBoard):\n   def _write_custom_summaries(self, step, logs=None):\n     \"\"\"Writes metrics out as custom scalar summaries.\n \n-    Arguments:\n+    Args:\n         step: the global step to use for TensorBoard.\n         logs: dict. Keys are scalar summary names, values are\n             NumPy scalars.\n\n@@ -48,7 +48,7 @@ class MaxNorm(Constraint):\n \n   Also available via the shortcut function `tf.keras.constraints.max_norm`.\n \n-  Arguments:\n+  Args:\n     max_value: the maximum norm value for the incoming weights.\n     axis: integer, axis along which to calculate weight norms.\n       For instance, in a `Dense` layer the weight matrix\n@@ -97,7 +97,7 @@ class UnitNorm(Constraint):\n \n   Also available via the shortcut function `tf.keras.constraints.unit_norm`.\n \n-  Arguments:\n+  Args:\n     axis: integer, axis along which to calculate weight norms.\n       For instance, in a `Dense` layer the weight matrix\n       has shape `(input_dim, output_dim)`,\n@@ -135,7 +135,7 @@ class MinMaxNorm(Constraint):\n \n   Also available via the shortcut function `tf.keras.constraints.min_max_norm`.\n \n-  Arguments:\n+  Args:\n     min_value: the minimum norm for the incoming weights.\n     max_value: the maximum norm for the incoming weights.\n     rate: rate for enforcing the constraint: weights will be\n\n@@ -38,7 +38,7 @@ def load_data(path='boston_housing.npz', test_split=0.2, seed=113):\n   The attributes themselves are defined in the\n   [StatLib website](http://lib.stat.cmu.edu/datasets/boston).\n \n-  Arguments:\n+  Args:\n       path: path where to cache the dataset locally\n           (relative to `~/.keras/datasets`).\n       test_split: fraction of the data to reserve as test set.\n\n@@ -26,7 +26,7 @@ from six.moves import cPickle\n def load_batch(fpath, label_key='labels'):\n   \"\"\"Internal utility for parsing CIFAR data.\n \n-  Arguments:\n+  Args:\n       fpath: path the file to parse.\n       label_key: key for label data in the retrieve\n           dictionary.\n\n@@ -37,7 +37,7 @@ def load_data(label_mode='fine'):\n   grouped into 20 coarse-grained classes. See more info at the\n   [CIFAR homepage](https://www.cs.toronto.edu/~kriz/cifar.html).\n \n-  Arguments:\n+  Args:\n       label_mode: one of \"fine\", \"coarse\". If it is \"fine\" the category labels\n       are the fine-grained labels, if it is \"coarse\" the output labels are the\n       coarse-grained superclasses.\n\n@@ -52,7 +52,7 @@ def load_data(path='imdb.npz',\n   As a convention, \"0\" does not stand for a specific word, but instead is used\n   to encode any unknown word.\n \n-  Arguments:\n+  Args:\n       path: where to cache the data (relative to `~/.keras/dataset`).\n       num_words: integer or None. Words are\n           ranked by how often they occur (in the training set) and only\n@@ -166,7 +166,7 @@ def load_data(path='imdb.npz',\n def get_word_index(path='imdb_word_index.json'):\n   \"\"\"Retrieves a dict mapping words to their index in the IMDB dataset.\n \n-  Arguments:\n+  Args:\n       path: where to cache the data (relative to `~/.keras/dataset`).\n \n   Returns:\n\n@@ -34,7 +34,7 @@ def load_data(path='mnist.npz'):\n   [MNIST homepage](http://yann.lecun.com/exdb/mnist/).\n \n \n-  Arguments:\n+  Args:\n       path: path where to cache the dataset locally\n           (relative to `~/.keras/datasets`).\n \n\n@@ -60,7 +60,7 @@ def load_data(path='reuters.npz',\n   to encode any unknown word.\n \n \n-  Arguments:\n+  Args:\n       path: where to cache the data (relative to `~/.keras/dataset`).\n       num_words: integer or None. Words are\n           ranked by how often they occur (in the training set) and only\n@@ -155,7 +155,7 @@ def load_data(path='reuters.npz',\n def get_word_index(path='reuters_word_index.json'):\n   \"\"\"Retrieves a dict mapping words to their index in the Reuters dataset.\n \n-  Arguments:\n+  Args:\n       path: where to cache the data (relative to `~/.keras/dataset`).\n \n   Returns:\n\n@@ -41,7 +41,7 @@ def call_replica_local_fn(fn, *args, **kwargs):\n   This function correctly handles calling `fn` in a cross-replica\n   context.\n \n-  Arguments:\n+  Args:\n     fn: The function to call.\n     *args: Positional arguments to the `fn`.\n     **kwargs: Keyword argument to `fn`.\n\n@@ -596,7 +596,7 @@ def _get_input_from_iterator(iterator, model):\n def _prepare_feed_values(model, inputs, targets, sample_weights, mode):\n   \"\"\"Prepare feed values to the model execution function.\n \n-  Arguments:\n+  Args:\n     model: Model to prepare feed values for.\n     inputs: List or dict of model inputs.\n     targets: Optional list of model targets.\n@@ -1082,7 +1082,7 @@ def is_current_worker_chief():\n def filter_distributed_callbacks(callbacks_list, model):\n   \"\"\"Filter Callbacks based on the worker context when running multi-worker.\n \n-  Arguments:\n+  Args:\n     callbacks_list: A list of `Callback` instances.\n     model: Keras model instance.\n \n\n@@ -408,7 +408,7 @@ class TestDistributionStrategyCorrectnessBase(tf.test.TestCase,\n     We only provide a default implementation of this method here. If you need\n     more customized way of providing input to your model, overwrite this method.\n \n-    Arguments:\n+    Args:\n       **kwargs: key word arguments about how to create the input dictionaries\n \n     Returns:\n@@ -515,7 +515,7 @@ class TestDistributionStrategyCorrectnessBase(tf.test.TestCase,\n     We only provide a default implementation of this method here. If you need\n     more customized way of providing input to your model, overwrite this method.\n \n-    Arguments:\n+    Args:\n       **kwargs: key word arguments about how to create the input dictionaries\n \n     Returns:\n\n@@ -20,6 +20,8 @@ from __future__ import division\n from __future__ import print_function\n \n import tensorflow as tf\n+\n+import re\n from tensorflow.python.ops import summary_ops_v2\n from tensorflow.python.platform import tf_logging as logging\n \n@@ -27,6 +29,26 @@ _PRINT_EVAL_STEP_EVERY_SEC = 60.0\n _ITERATIONS_UNINITIALIZED = -1\n \n \n+def list_checkpoint_attributes(ckpt_dir_or_file):\n+  \"\"\"Lists all the attributes in a checkpoint.\n+\n+  Checkpoint keys are paths in a checkpoint graph, and attribute is the first\n+  element in the path. e.g. with a checkpoint key\n+  \"optimizer/iter/.ATTRIBUTES/VARIABLE_VALUE\", optimizer is the attribute. The\n+  attribute is also used to save/restore a variable in a checkpoint,\n+  e.g. tf.train.Checkpoint(optimizer=optimizer, model=model).\n+\n+  Args:\n+    ckpt_dir_or_file: Directory with checkpoints file or path to checkpoint.\n+\n+  Returns:\n+    Set of attributes in a checkpoint.\n+  \"\"\"\n+  reader = tf.train.load_checkpoint(ckpt_dir_or_file)\n+  variable_map = reader.get_variable_to_shape_map()\n+  return {name.split('/')[0] for name in variable_map.keys()}\n+\n+\n class SidecarEvaluator(object):\n   \"\"\"A class designed for a dedicated evaluator task.\n \n@@ -143,6 +165,21 @@ class SidecarEvaluator(object):\n         # `expect_partial` because the checkpoint can have other `Trackable`s\n         # such as `optimizer`.\n         checkpoint.restore(latest_checkpoint).expect_partial()\n+        checkpoint_attributes = list_checkpoint_attributes(latest_checkpoint)\n+        # The checkpoint should contain model and optimizer for SidecarEvaluator\n+        # to work. But the model weights saved by ModelCheckpoint callback does\n+        # not contain model as an attribute. To make SidecarEvaluator compatibly\n+        # work in this case, if model attribute is not found but\n+        # layer_with_weights attribute is found, use model.load_weights to load\n+        # the model's weights, while self._iterations is still restored by\n+        # checkpoint variable.\n+        if 'model' not in checkpoint_attributes:\n+          for attribute in checkpoint_attributes:\n+            # check whether the checkpoint has the required attributes for\n+            # model.load_weights to work.\n+            if re.match(r'^layer_with_weights-[\\d+]', attribute) is not None:\n+              self.model.load_weights(latest_checkpoint)\n+              break\n       except (tf.errors.OpError,) as e:\n         # A couple errors can happen here with the coordinator racing to write\n         # checkpoint:\n\n@@ -22,7 +22,6 @@ from __future__ import print_function\n import tensorflow as tf\n \n import os\n-import unittest\n \n from absl import logging\n import numpy as np\n@@ -31,6 +30,8 @@ import keras\n from keras.distribute import sidecar_evaluator as sidecar_evaluator_lib\n from keras.optimizer_v2 import gradient_descent\n \n+_BATCH_SIZE = 32\n+\n \n class SidecarEvaluatorTest(tf.test.TestCase):\n \n@@ -125,7 +126,6 @@ class SidecarEvaluatorTest(tf.test.TestCase):\n \n     self.assertSummaryEventsWritten(log_dir)\n \n-  @unittest.skip('b/172976255')\n   def testSidecarEvaluatorOutputsSummarySavedWithCallback(self):\n     checkpoint_dir = os.path.join(self.get_temp_dir(), 'checkpoints')\n     log_dir = os.path.join(self.get_temp_dir(), 'summary')\n@@ -134,7 +134,7 @@ class SidecarEvaluatorTest(tf.test.TestCase):\n     data = np.random.random((1000, 32))\n     labels = np.random.random((1000, 10))\n     dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n-    dataset = dataset.batch(32)\n+    dataset = dataset.batch(_BATCH_SIZE)\n     save_callback = keras.callbacks.ModelCheckpoint(\n         filepath=os.path.join(checkpoint_dir, 'ckpt-{epoch}'),\n         save_weights_only=True)\n@@ -147,17 +147,22 @@ class SidecarEvaluatorTest(tf.test.TestCase):\n     # Create a new model used for evaluation.\n     eval_model = self.createTestModel(compile_model=True)\n     # Have an sidecar_evaluator evaluate once.\n-    sidecar_evaluator_lib.SidecarEvaluator(\n+    sidecar_evaluator = sidecar_evaluator_lib.SidecarEvaluator(\n         eval_model,\n         data=dataset,\n         checkpoint_dir=checkpoint_dir,\n         log_dir=log_dir,\n-        max_evaluations=1).start()\n+        max_evaluations=1)\n+    sidecar_evaluator.start()\n+\n     # Eval model has been restored to the same state as the original model, so\n     # their weights should match. If not, restoration of the model didn't\n     # work.\n     self.assertModelsSameVariables(model, eval_model)\n \n+    # check the iterations is restored.\n+    self.assertEqual(sidecar_evaluator._iterations.numpy(), _BATCH_SIZE)\n+\n     self.assertSummaryEventsWritten(log_dir)\n \n \n\n@@ -83,7 +83,7 @@ class WorkerTrainingState(object):\n   def back_up(self, epoch):\n     \"\"\"Back up the current state of training into a checkpoint file.\n \n-    Arguments:\n+    Args:\n       epoch: The current epoch information to be saved.\n     \"\"\"\n     K.set_value(self._ckpt_saved_epoch, epoch)\n@@ -120,7 +120,7 @@ class WorkerTrainingState(object):\n     infer `initial_epoch` from `self._ckpt_saved_epoch` to continue previous\n     unfinished training from certain epoch.\n \n-    Arguments:\n+    Args:\n       initial_epoch: The original initial_epoch user passes in in `fit()`.\n       mode: The mode for running `model.fit()`.\n \n\n@@ -101,7 +101,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n \n   Users will just instantiate a layer and then treat it as a callable.\n \n-  Arguments:\n+  Args:\n     trainable: Boolean, whether the layer's variables should be trainable.\n     name: String name of the layer.\n     dtype: The dtype of the layer's computations and weights. Can also be a\n@@ -438,7 +438,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n \n     This is typically used to create the weights of `Layer` subclasses.\n \n-    Arguments:\n+    Args:\n       input_shape: Instance of `TensorShape`, or list of instances of\n         `TensorShape` if the layer expects a list of inputs\n         (one instance per input).\n@@ -457,7 +457,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n     layers as additional arguments. Whereas `tf.keras` has `compute_mask()`\n     method to support masking.\n \n-    Arguments:\n+    Args:\n         inputs: Input tensor, or list/tuple of input tensors.\n         **kwargs: Additional keyword arguments. Currently unused.\n \n@@ -470,7 +470,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n   def _add_trackable(self, trackable_object, trainable):\n     \"\"\"Adds a Trackable object to this layer's state.\n \n-    Arguments:\n+    Args:\n       trackable_object: The tf.tracking.Trackable object to add.\n       trainable: Boolean, whether the variable should be part of the layer's\n         \"trainable_variables\" (e.g. variables, biases) or\n@@ -501,7 +501,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n                  **kwargs):\n     \"\"\"Adds a new variable to the layer.\n \n-    Arguments:\n+    Args:\n       name: Variable name.\n       shape: Variable shape. Defaults to scalar if unspecified.\n       dtype: The type of the variable. Defaults to `self.dtype`.\n@@ -696,7 +696,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n     dictionary. It does not handle layer connectivity\n     (handled by Network), nor weights (handled by `set_weights`).\n \n-    Arguments:\n+    Args:\n         config: A Python dictionary, typically the\n             output of get_config.\n \n@@ -712,7 +712,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n     layer. This assumes that the layer will later be used with inputs that\n     match the input shape provided here.\n \n-    Arguments:\n+    Args:\n         input_shape: Shape tuple (tuple of integers)\n             or list of shape tuples (one per output tensor of the layer).\n             Shape tuples can include None for free dimensions,\n@@ -865,7 +865,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n   def compute_mask(self, inputs, mask=None):  # pylint: disable=unused-argument\n     \"\"\"Computes an output mask tensor.\n \n-    Arguments:\n+    Args:\n         inputs: Tensor or list of tensors.\n         mask: Tensor or list of tensors.\n \n@@ -886,7 +886,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n   def __call__(self, *args, **kwargs):\n     \"\"\"Wraps `call`, applying pre- and post-processing steps.\n \n-    Arguments:\n+    Args:\n       *args: Positional arguments to be passed to `self.call`.\n       **kwargs: Keyword arguments to be passed to `self.call`.\n \n@@ -903,6 +903,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n         for `inputs` by the previous layer (if `input` did come from\n         a layer that generated a corresponding mask, i.e. if it came from\n         a Keras layer with masking support.\n+      - If the layer is not built, the method will call `build`.\n \n     Raises:\n       ValueError: if the layer's `call` method returns None (an invalid value).\n@@ -1509,7 +1510,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n     model.add_loss(lambda: tf.reduce_mean(d.kernel))\n     ```\n \n-    Arguments:\n+    Args:\n       losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n         may also be zero-argument callables which create a loss tensor.\n       **kwargs: Additional keyword arguments for backward compatibility.\n@@ -1751,7 +1752,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n     updates are run on the fly and thus do not need to be tracked for later\n     execution).\n \n-    Arguments:\n+    Args:\n       updates: Update op, or list/tuple of update ops, or zero-arg callable\n         that returns an update op. A zero-arg callable should be passed in\n         order to disable running the updates by setting `trainable=False`\n@@ -1806,7 +1807,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n            [1.],\n            [1.]], dtype=float32), array([0.], dtype=float32)]\n \n-    Arguments:\n+    Args:\n         weights: a list of Numpy arrays. The number\n             of arrays and their shape must match\n             number of the dimensions of the weights\n@@ -1903,7 +1904,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n \n     Retrieves updates relevant to a specific set of inputs.\n \n-    Arguments:\n+    Args:\n       inputs: Input tensor or list/tuple of input tensors.\n \n     Returns:\n@@ -1920,7 +1921,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n \n     Retrieves losses relevant to a specific set of inputs.\n \n-    Arguments:\n+    Args:\n       inputs: Input tensor or list/tuple of input tensors.\n \n     Returns:\n@@ -1935,7 +1936,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n   def get_input_mask_at(self, node_index):\n     \"\"\"Retrieves the input mask tensor(s) of a layer at a given node.\n \n-    Arguments:\n+    Args:\n         node_index: Integer, index of the node\n             from which to retrieve the attribute.\n             E.g. `node_index=0` will correspond to the\n@@ -1955,7 +1956,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n   def get_output_mask_at(self, node_index):\n     \"\"\"Retrieves the output mask tensor(s) of a layer at a given node.\n \n-    Arguments:\n+    Args:\n         node_index: Integer, index of the node\n             from which to retrieve the attribute.\n             E.g. `node_index=0` will correspond to the\n@@ -2019,7 +2020,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n   def get_input_shape_at(self, node_index):\n     \"\"\"Retrieves the input shape(s) of a layer at a given node.\n \n-    Arguments:\n+    Args:\n         node_index: Integer, index of the node\n             from which to retrieve the attribute.\n             E.g. `node_index=0` will correspond to the\n@@ -2039,7 +2040,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n   def get_output_shape_at(self, node_index):\n     \"\"\"Retrieves the output shape(s) of a layer at a given node.\n \n-    Arguments:\n+    Args:\n         node_index: Integer, index of the node\n             from which to retrieve the attribute.\n             E.g. `node_index=0` will correspond to the\n@@ -2059,7 +2060,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n   def get_input_at(self, node_index):\n     \"\"\"Retrieves the input tensor(s) of a layer at a given node.\n \n-    Arguments:\n+    Args:\n         node_index: Integer, index of the node\n             from which to retrieve the attribute.\n             E.g. `node_index=0` will correspond to the\n@@ -2078,7 +2079,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n   def get_output_at(self, node_index):\n     \"\"\"Retrieves the output tensor(s) of a layer at a given node.\n \n-    Arguments:\n+    Args:\n         node_index: Integer, index of the node\n             from which to retrieve the attribute.\n             E.g. `node_index=0` will correspond to the\n@@ -2239,7 +2240,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n \n     This is an alias of `self.__call__`.\n \n-    Arguments:\n+    Args:\n       inputs: Input tensor(s).\n       *args: additional positional arguments to be passed to `self.call`.\n       **kwargs: additional keyword arguments to be passed to `self.call`.\n@@ -2628,7 +2629,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n         - get_input_at\n         etc...\n \n-    Arguments:\n+    Args:\n         node_index: Integer index of the node from which\n             to retrieve the attribute.\n         attr: Exact node attribute name.\n@@ -2894,7 +2895,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n   def _flatten_modules(self, recursive=True, include_self=True):\n     \"\"\"Flattens `tf.Module` instances (excluding `Metrics`).\n \n-    Arguments:\n+    Args:\n       recursive: Whether to recursively flatten through submodules.\n       include_self: Whether to include this `Layer` instance.\n \n\n@@ -64,7 +64,7 @@ def make_variable(name,\n \n   TODO(fchollet): remove this method when no longer needed.\n \n-  Arguments:\n+  Args:\n     name: Variable name.\n     shape: Variable shape.\n     dtype: The type of the variable. Defaults to `self.dtype` or `float32`.\n@@ -133,7 +133,7 @@ def make_variable(name,\n def collect_previous_mask(input_tensors):\n   \"\"\"Retrieves the output mask(s) of the previous node.\n \n-  Arguments:\n+  Args:\n       input_tensors: An arbitrary structure of Tensors.\n \n   Returns:\n@@ -165,7 +165,7 @@ def create_keras_history(tensors):\n   Any Tensors not originating from a Keras `Input` Layer will be treated as\n   constants when constructing `TensorFlowOpLayer` instances.\n \n-  Arguments:\n+  Args:\n     tensors: A structure of Tensors, some of which come from raw TensorFlow\n       operations and need to have Keras metadata assigned to them.\n \n@@ -193,7 +193,7 @@ _UNSAFE_GRAPH_OP_LAYER_CREATION = False\n def _create_keras_history_helper(tensors, processed_ops, created_layers):\n   \"\"\"Helper method for `create_keras_history`.\n \n-  Arguments:\n+  Args:\n     tensors: A structure of Tensors for which to create Keras metadata.\n     processed_ops: Set. TensorFlow operations that have already been wrapped in\n       `TensorFlowOpLayer` instances.\n@@ -300,7 +300,7 @@ def needs_keras_history(tensors, ignore_call_context=False):\n   if one or more of `tensors` originates from a `keras.Input` and\n   does not have `_keras_history` set.\n \n-  Arguments:\n+  Args:\n     tensors: An arbitrary nested structure of Tensors.\n     ignore_call_context: Whether to ignore the check of if currently\n       outside of a `call` context. This is `True` when creating\n@@ -358,7 +358,7 @@ def uses_keras_history(tensors):\n   already been checked to not originate from a `keras.Input`\n   are marked as `_keras_history_checked`.\n \n-  Arguments:\n+  Args:\n     tensors: An arbitrary nested structure of Tensors.\n \n   Returns:\n@@ -400,7 +400,7 @@ def mark_checked(tensors):\n   This prevents Layers from attempting to create TensorFlowOpLayers\n   for these Tensors.\n \n-  Arguments:\n+  Args:\n     tensors: An arbitrary structure of Tensors.\n   \"\"\"\n \n@@ -457,7 +457,7 @@ class CallContext(object):\n   def enter(self, layer, inputs, build_graph, training, saving=None):\n     \"\"\"Push a Layer and its inputs and state onto the current call context.\n \n-    Arguments:\n+    Args:\n       layer: The `Layer` whose `call` is currently active.\n       inputs: The inputs to the currently active `Layer`.\n       build_graph: Whether currently inside a Graph or FuncGraph.\n@@ -572,7 +572,7 @@ def check_graph_consistency(tensor=None, method='add_loss', force_raise=False):\n   the underlying tensor gets created in a FuncGraph managed by control_flow_v2.\n   We need to raise clear error messages in such cases.\n \n-  Arguments:\n+  Args:\n     tensor: Tensor to check, or `False` if it is known that an error\n       should be raised.\n     method: Caller method, one of {'add_metric', 'add_loss', 'add_update'}.\n\n@@ -82,7 +82,7 @@ class Layer(base_layer.Layer):\n     once. Should actually perform the logic of applying the layer to the\n     input tensors (which should be passed in as the first argument).\n \n-  Arguments:\n+  Args:\n     trainable: Boolean, whether the layer's variables should be trainable.\n     name: String name of the layer.\n     dtype: The dtype of the layer's computations and weights (default of\n@@ -260,7 +260,7 @@ class Layer(base_layer.Layer):\n \n     This is typically used to create the weights of `Layer` subclasses.\n \n-    Arguments:\n+    Args:\n       input_shape: Instance of `TensorShape`, or list of instances of\n         `TensorShape` if the layer expects a list of inputs\n         (one instance per input).\n@@ -273,7 +273,7 @@ class Layer(base_layer.Layer):\n   def call(self, inputs, **kwargs):  # pylint: disable=unused-argument\n     \"\"\"This is where the layer's logic lives.\n \n-    Arguments:\n+    Args:\n         inputs: Input tensor, or list/tuple of input tensors.\n         **kwargs: Additional keyword arguments.\n \n@@ -286,7 +286,7 @@ class Layer(base_layer.Layer):\n   def _add_trackable(self, trackable_object, trainable):\n     \"\"\"Adds a Trackable object to this layer's state.\n \n-    Arguments:\n+    Args:\n       trackable_object: The tf.tracking.Trackable object to add.\n       trainable: Boolean, whether the variable should be part of the layer's\n         \"trainable_variables\" (e.g. variables, biases) or\n@@ -318,7 +318,7 @@ class Layer(base_layer.Layer):\n                  **kwargs):\n     \"\"\"Adds a new variable to the layer.\n \n-    Arguments:\n+    Args:\n       name: Variable name.\n       shape: Variable shape. Defaults to scalar if unspecified.\n       dtype: The type of the variable. Defaults to `self.dtype` or `float32`.\n@@ -510,7 +510,7 @@ class Layer(base_layer.Layer):\n     dictionary. It does not handle layer connectivity\n     (handled by Network), nor weights (handled by `set_weights`).\n \n-    Arguments:\n+    Args:\n         config: A Python dictionary, typically the\n             output of get_config.\n \n@@ -526,7 +526,7 @@ class Layer(base_layer.Layer):\n     layer. This assumes that the layer will later be used with inputs that\n     match the input shape provided here.\n \n-    Arguments:\n+    Args:\n         input_shape: Shape tuple (tuple of integers)\n             or list of shape tuples (one per output tensor of the layer).\n             Shape tuples can include None for free dimensions,\n@@ -605,7 +605,7 @@ class Layer(base_layer.Layer):\n   def compute_mask(self, inputs, mask=None):  # pylint: disable=unused-argument\n     \"\"\"Computes an output mask tensor.\n \n-    Arguments:\n+    Args:\n         inputs: Tensor or list of tensors.\n         mask: Tensor or list of tensors.\n \n@@ -626,7 +626,7 @@ class Layer(base_layer.Layer):\n   def __call__(self, *args, **kwargs):\n     \"\"\"Wraps `call`, applying pre- and post-processing steps.\n \n-    Arguments:\n+    Args:\n       *args: Positional arguments to be passed to `self.call`.\n       **kwargs: Keyword arguments to be passed to `self.call`.\n \n@@ -1001,7 +1001,7 @@ class Layer(base_layer.Layer):\n     The `get_losses_for` method allows to retrieve the losses relevant to a\n     specific set of inputs.\n \n-    Arguments:\n+    Args:\n       losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n         may also be zero-argument callables which create a loss tensor.\n       inputs: Ignored when executing eagerly. If anything other than None is\n@@ -1154,7 +1154,7 @@ class Layer(base_layer.Layer):\n     updates are run on the fly and thus do not need to be tracked for later\n     execution).\n \n-    Arguments:\n+    Args:\n       updates: Update op, or list/tuple of update ops, or zero-arg callable\n         that returns an update op. A zero-arg callable should be passed in\n         order to disable running the updates by setting `trainable=False`\n@@ -1186,7 +1186,7 @@ class Layer(base_layer.Layer):\n     def process_update(x):\n       \"\"\"Standardize update ops.\n \n-      Arguments:\n+      Args:\n         x: Tensor, op, or callable.\n \n       Returns:\n@@ -1242,7 +1242,7 @@ class Layer(base_layer.Layer):\n            [1.],\n            [1.]], dtype=float32), array([0.], dtype=float32)]\n \n-    Arguments:\n+    Args:\n         weights: a list of Numpy arrays. The number\n             of arrays and their shape must match\n             number of the dimensions of the weights\n@@ -1336,7 +1336,7 @@ class Layer(base_layer.Layer):\n   def get_updates_for(self, inputs):\n     \"\"\"Retrieves updates relevant to a specific set of inputs.\n \n-    Arguments:\n+    Args:\n       inputs: Input tensor or list/tuple of input tensors.\n \n     Returns:\n@@ -1355,7 +1355,7 @@ class Layer(base_layer.Layer):\n   def get_losses_for(self, inputs):\n     \"\"\"Retrieves losses relevant to a specific set of inputs.\n \n-    Arguments:\n+    Args:\n       inputs: Input tensor or list/tuple of input tensors.\n \n     Returns:\n@@ -1374,7 +1374,7 @@ class Layer(base_layer.Layer):\n   def get_input_mask_at(self, node_index):\n     \"\"\"Retrieves the input mask tensor(s) of a layer at a given node.\n \n-    Arguments:\n+    Args:\n         node_index: Integer, index of the node\n             from which to retrieve the attribute.\n             E.g. `node_index=0` will correspond to the\n@@ -1393,7 +1393,7 @@ class Layer(base_layer.Layer):\n   def get_output_mask_at(self, node_index):\n     \"\"\"Retrieves the output mask tensor(s) of a layer at a given node.\n \n-    Arguments:\n+    Args:\n         node_index: Integer, index of the node\n             from which to retrieve the attribute.\n             E.g. `node_index=0` will correspond to the\n@@ -1454,7 +1454,7 @@ class Layer(base_layer.Layer):\n   def get_input_shape_at(self, node_index):\n     \"\"\"Retrieves the input shape(s) of a layer at a given node.\n \n-    Arguments:\n+    Args:\n         node_index: Integer, index of the node\n             from which to retrieve the attribute.\n             E.g. `node_index=0` will correspond to the\n@@ -1473,7 +1473,7 @@ class Layer(base_layer.Layer):\n   def get_output_shape_at(self, node_index):\n     \"\"\"Retrieves the output shape(s) of a layer at a given node.\n \n-    Arguments:\n+    Args:\n         node_index: Integer, index of the node\n             from which to retrieve the attribute.\n             E.g. `node_index=0` will correspond to the\n@@ -1492,7 +1492,7 @@ class Layer(base_layer.Layer):\n   def get_input_at(self, node_index):\n     \"\"\"Retrieves the input tensor(s) of a layer at a given node.\n \n-    Arguments:\n+    Args:\n         node_index: Integer, index of the node\n             from which to retrieve the attribute.\n             E.g. `node_index=0` will correspond to the\n@@ -1510,7 +1510,7 @@ class Layer(base_layer.Layer):\n   def get_output_at(self, node_index):\n     \"\"\"Retrieves the output tensor(s) of a layer at a given node.\n \n-    Arguments:\n+    Args:\n         node_index: Integer, index of the node\n             from which to retrieve the attribute.\n             E.g. `node_index=0` will correspond to the\n@@ -1669,7 +1669,7 @@ class Layer(base_layer.Layer):\n \n     This is an alias of `self.__call__`.\n \n-    Arguments:\n+    Args:\n       inputs: Input tensor(s).\n       *args: additional positional arguments to be passed to `self.call`.\n       **kwargs: additional keyword arguments to be passed to `self.call`.\n@@ -2015,7 +2015,7 @@ class Layer(base_layer.Layer):\n         - get_input_at\n         etc...\n \n-    Arguments:\n+    Args:\n         node_index: Integer index of the node from which\n             to retrieve the attribute.\n         attr: Exact node attribute name.\n\n@@ -47,7 +47,7 @@ class PreprocessingLayer(Layer):\n     # TODO(momernick): Add examples.\n     \"\"\"Fits the state of the preprocessing layer to the data being passed.\n \n-    Arguments:\n+    Args:\n         data: The data to train on. It can be passed either as a tf.data\n           Dataset, or as a numpy array.\n         reset_state: Optional argument specifying whether to clear the state of\n@@ -129,7 +129,7 @@ class CombinerPreprocessingLayer(PreprocessingLayer):\n   def adapt(self, data, reset_state=True):\n     \"\"\"Fits the state of the preprocessing layer to the data being passed.\n \n-    Arguments:\n+    Args:\n       data: The data to train on. It can be passed either as a tf.data Dataset,\n         or as a numpy array.\n       reset_state: Optional argument specifying whether to clear the state of\n\n@@ -49,7 +49,7 @@ class Container(object):\n     (2) Fill missing keys in a dict w/ `None`s.\n     (3) Map a single item to all outputs.\n \n-    Arguments:\n+    Args:\n       outputs: Model predictions.\n       struct: Arbitrary nested structure (e.g. of labels, sample_weights,\n         losses, or metrics).\n@@ -70,7 +70,7 @@ class Container(object):\n     NOTE: This method should only be called for Metrics / Losses, not for\n     y_true / sample_weight.\n \n-    Arguments:\n+    Args:\n       outputs: Model predictions.\n       objects: Arbitrary nested structure (e.g. of losses or metrics)\n \n@@ -165,7 +165,7 @@ class LossesContainer(Container):\n                regularization_losses=None):\n     \"\"\"Computes the overall loss.\n \n-    Arguments:\n+    Args:\n       y_true: An arbitrary structure of Tensors representing the ground truth.\n       y_pred: An arbitrary structure of Tensors representing a Model's outputs.\n       sample_weight: An arbitrary structure of Tensors representing the\n@@ -248,7 +248,7 @@ class LossesContainer(Container):\n     Converts the user-supplied loss to a `Loss` object. Also allows\n     `SUM_OVER_BATCH_SIZE` reduction to be used for this loss.\n \n-    Arguments:\n+    Args:\n       loss: A string, function, or `Loss` object.\n \n     Returns:\n@@ -434,7 +434,7 @@ class MetricsContainer(Container):\n   def _get_metric_object(self, metric, y_t, y_p):\n     \"\"\"Converts user-supplied metric to a `Metric` object.\n \n-    Arguments:\n+    Args:\n       metric: A string, function, or `Metric` object.\n       y_t: Sample of label.\n       y_p: Sample of output.\n@@ -531,7 +531,7 @@ def _create_pseudo_names(tensors, prefix):\n   `[x, y]` becomes:\n   `['output_1', 'output_2']`\n \n-  Arguments:\n+  Args:\n     tensors: `Model`'s outputs or inputs.\n     prefix: 'output_' for outputs, 'input_' for inputs.\n \n@@ -576,7 +576,7 @@ def map_to_output_names(y_pred, output_names, struct):\n   This mapping preserves backwards compatibility for `compile` and\n   `fit`.\n \n-  Arguments:\n+  Args:\n     y_pred: Sample outputs of the Model, to determine if this convenience\n       feature should be applied (`struct` is returned unmodified if `y_pred`\n       isn't a flat list).\n@@ -657,7 +657,7 @@ def apply_mask(y_p, sw, mask):\n def get_custom_object_name(obj):\n   \"\"\"Returns the name to use for a custom loss or metric callable.\n \n-  Arguments:\n+  Args:\n     obj: Custom loss of metric callable\n \n   Returns:\n\n@@ -1252,7 +1252,7 @@ def _make_class_weight_map_fn(class_weight):\n   The `Dataset` is assumed to be in format `(x, y)` or `(x, y, sw)`, where\n   `y` must be a single `Tensor`.\n \n-  Arguments:\n+  Args:\n     class_weight: A map where the keys are integer class ids and values are\n       the class weights, e.g. `{0: 0.2, 1: 0.6, 2: 0.3}`\n \n@@ -1320,7 +1320,7 @@ def train_validation_split(arrays, validation_split):\n \n   The last part of data will become validation data.\n \n-  Arguments:\n+  Args:\n     arrays: Tensors to split. Allowed inputs are arbitrarily nested structures\n       of Tensors and NumPy arrays.\n     validation_split: Float between 0 and 1. The proportion of the dataset to\n@@ -1418,7 +1418,7 @@ def unpack_x_y_sample_weight(data):\n       return {m.name: m.result() for m in self.metrics}\n   ```\n \n-  Arguments:\n+  Args:\n     data: A tuple of the form `(x,)`, `(x, y)`, or `(x, y, sample_weight)`.\n \n   Returns:\n@@ -1458,7 +1458,7 @@ def pack_x_y_sample_weight(x, y=None, sample_weight=None):\n   True\n   >>> x, y = data\n \n-  Arguments:\n+  Args:\n     x: Features to pass to `Model`.\n     y: Ground-truth targets to pass to `Model`.\n     sample_weight: Sample weight for each element.\n\n@@ -86,7 +86,7 @@ class Functional(training_lib.Model):\n   model = keras.Model(inputs, outputs)\n   ```\n \n-  Arguments:\n+  Args:\n     inputs: List of input tensors (must be created via `tf.keras.Input()`).\n     outputs: List of outputs tensors.\n     name: String, optional. Name of the model.\n@@ -408,7 +408,7 @@ class Functional(training_lib.Model):\n     all ops in the graph to the new inputs\n     (e.g. build a new computational graph from the provided inputs).\n \n-    Arguments:\n+    Args:\n         inputs: A tensor or list of tensors.\n         training: Boolean or boolean scalar tensor, indicating whether to run\n           the `Network` in training mode or inference mode.\n@@ -517,7 +517,7 @@ class Functional(training_lib.Model):\n     # Note:\n         - Can be run on non-Keras tensors.\n \n-    Arguments:\n+    Args:\n         inputs: Tensor or nested structure of Tensors.\n         training: Boolean learning phase.\n         mask: (Optional) Tensor or nested structure of Tensors.\n@@ -651,7 +651,7 @@ class Functional(training_lib.Model):\n   def from_config(cls, config, custom_objects=None):\n     \"\"\"Instantiates a Model from its config (output of `get_config()`).\n \n-    Arguments:\n+    Args:\n         config: Model config dictionary.\n         custom_objects: Optional dictionary mapping names\n             (strings) to custom classes or functions to be\n@@ -734,7 +734,7 @@ class Functional(training_lib.Model):\n     They will not be added to the Network's outputs.\n \n \n-    Arguments:\n+    Args:\n       layers: Arbitrary nested structure of Layers. Layers must be reachable\n         from one or more of the `keras.Input` Tensors that correspond to this\n         Network's inputs.\n@@ -882,7 +882,7 @@ def _make_node_key(layer_name, node_index):\n def _map_graph_network(inputs, outputs):\n   \"\"\"Validates a network's topology and gather its layers and nodes.\n \n-  Arguments:\n+  Args:\n     inputs: List of input tensors.\n     outputs: List of outputs tensors.\n \n@@ -1183,7 +1183,7 @@ def reconstruct_from_config(config, custom_objects=None, created_layers=None):\n   def process_node(layer, node_data):\n     \"\"\"Deserialize a node.\n \n-    Arguments:\n+    Args:\n         layer: layer instance.\n         node_data: Nested structure of `ListWrapper`.\n \n@@ -1239,7 +1239,7 @@ def reconstruct_from_config(config, custom_objects=None, created_layers=None):\n   def process_layer(layer_data):\n     \"\"\"Deserializes a layer, then call it on appropriate inputs.\n \n-    Arguments:\n+    Args:\n         layer_data: layer config dict.\n \n     Raises:\n@@ -1401,7 +1401,7 @@ class ModuleWrapper(base_layer.Layer):\n   def __init__(self, module, method_name=None, **kwargs):\n     \"\"\"Initializes the wrapper Layer for this module.\n \n-    Arguments:\n+    Args:\n       module: The `tf.Module` instance to be wrapped.\n       method_name: (Optional) str. The name of the method to use as the forward\n         pass of the module. If not set, defaults to '__call__' if defined, or\n\n@@ -67,7 +67,7 @@ class InputLayer(base_layer.Layer):\n             np.ones((10, 8)))\n   ```\n \n-  Arguments:\n+  Args:\n       input_shape: Shape tuple (not including the batch axis), or `TensorShape`\n         instance (not including the batch axis).\n       batch_size: Optional input batch size (integer or None).\n@@ -222,7 +222,7 @@ def Input(  # pylint: disable=invalid-name\n   it becomes possible to do:\n   `model = Model(input=[a, b], output=c)`\n \n-  Arguments:\n+  Args:\n       shape: A shape tuple (integers), not including the batch size.\n           For instance, `shape=(32,)` indicates that the expected input\n           will be batches of 32-dimensional vectors. Elements of this tuple\n\n@@ -40,7 +40,7 @@ class InputSpec(object):\n   A None entry in a shape is compatible with any dimension,\n   a None shape is compatible with any shape.\n \n-  Arguments:\n+  Args:\n     dtype: Expected DataType of the input.\n     shape: Shape tuple, expected shape of the input\n       (may include None for unchecked axes). Includes the batch size.\n@@ -159,7 +159,7 @@ def assert_input_compatibility(input_spec, inputs, layer_name):\n   This checks that the tensor(s) `inputs` verify the input assumptions\n   of a layer (if any). If not, a clear and actional exception gets raised.\n \n-  Arguments:\n+  Args:\n       input_spec: An InputSpec instance, list of InputSpec instances, a nested\n           structure of InputSpec instances, or None.\n       inputs: Input tensor, list of input tensors, or a nested structure of\n\n@@ -41,7 +41,7 @@ class Node(object):\n   Each time the output of a layer is used by another layer,\n   a node is added to `layer._outbound_nodes`.\n \n-  Arguments:\n+  Args:\n       layer: The Layer for the Layer.__call__ this node represents.\n       call_args: The positional arguments the Layer was called with.\n       call_kwargs: The keyword arguments the Layer was called with.\n\n@@ -155,7 +155,7 @@ class Sequential(functional.Functional):\n   def add(self, layer):\n     \"\"\"Adds a layer instance on top of the layer stack.\n \n-    Arguments:\n+    Args:\n         layer: layer instance.\n \n     Raises:\n@@ -417,7 +417,7 @@ class Sequential(functional.Functional):\n \n     The input samples are processed batch by batch.\n \n-    Arguments:\n+    Args:\n         x: input data, as a Numpy array or list of Numpy arrays\n             (if the model has multiple inputs).\n         batch_size: integer.\n@@ -442,7 +442,7 @@ class Sequential(functional.Functional):\n \n     The input samples are processed batch by batch.\n \n-    Arguments:\n+    Args:\n         x: input data, as a Numpy array or list of Numpy arrays\n             (if the model has multiple inputs).\n         batch_size: integer.\n\n@@ -120,7 +120,7 @@ def is_functional_model_init_params(args, kwargs):\n class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n   \"\"\"`Model` groups layers into an object with training and inference features.\n \n-  Arguments:\n+  Args:\n       inputs: The input(s) of the model: a `keras.Input` object or list of\n           `keras.Input` objects.\n       outputs: The output(s) of the model. See Functional API example below.\n@@ -445,7 +445,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     To call a model on an input, always use the `__call__` method,\n     i.e. `model(inputs)`, which relies on the underlying `call` method.\n \n-    Arguments:\n+    Args:\n         inputs: A tensor or list of tensors.\n         training: Boolean or boolean scalar tensor, indicating whether to run\n           the `Network` in training mode or inference mode.\n@@ -470,7 +470,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n               **kwargs):\n     \"\"\"Configures the model for training.\n \n-    Arguments:\n+    Args:\n         optimizer: String (name of optimizer) or optimizer instance. See\n           `tf.keras.optimizers`.\n         loss: String (name of objective function), objective function or\n@@ -748,7 +748,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     `tf.distribute.Strategy` settings), should be left to\n     `Model.make_train_function`, which can also be overridden.\n \n-    Arguments:\n+    Args:\n       data: A nested structure of `Tensor`s.\n \n     Returns:\n@@ -854,7 +854,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n           use_multiprocessing=False):\n     \"\"\"Trains the model for a fixed number of epochs (iterations on a dataset).\n \n-    Arguments:\n+    Args:\n         x: Input data. It could be:\n           - A Numpy array (or array-like), or a list of arrays\n             (in case the model has multiple inputs).\n@@ -1182,7 +1182,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     `tf.distribute.Strategy` settings), should be left to\n     `Model.make_test_function`, which can also be overridden.\n \n-    Arguments:\n+    Args:\n       data: A nested structure of `Tensor`s.\n \n     Returns:\n@@ -1276,7 +1276,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n \n     Computation is done in batches (see the `batch_size` arg.)\n \n-    Arguments:\n+    Args:\n         x: Input data. It could be:\n           - A Numpy array (or array-like), or a list of arrays\n             (in case the model has multiple inputs).\n@@ -1435,7 +1435,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     `tf.distribute.Strategy` settings), should be left to\n     `Model.make_predict_function`, which can also be overridden.\n \n-    Arguments:\n+    Args:\n       data: A nested structure of `Tensor`s.\n \n     Returns:\n@@ -1531,7 +1531,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     inference. Also, note the fact that test loss is not affected by\n     regularization layers like noise and dropout.\n \n-    Arguments:\n+    Args:\n         x: Input samples. It could be:\n           - A Numpy array (or array-like), or a list of arrays\n             (in case the model has multiple inputs).\n@@ -1690,7 +1690,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n                      return_dict=False):\n     \"\"\"Runs a single gradient update on a single batch of data.\n \n-    Arguments:\n+    Args:\n         x: Input data. It could be:\n           - A Numpy array (or array-like), or a list of arrays\n               (in case the model has multiple inputs).\n@@ -1758,7 +1758,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n                     return_dict=False):\n     \"\"\"Test the model on a single batch of samples.\n \n-    Arguments:\n+    Args:\n         x: Input data. It could be: - A Numpy array (or array-like), or a list\n           of arrays (in case the model has multiple inputs). - A TensorFlow\n           tensor, or a list of tensors (in case the model has multiple inputs).\n@@ -1812,7 +1812,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n   def predict_on_batch(self, x):\n     \"\"\"Returns predictions for a single batch of samples.\n \n-    Arguments:\n+    Args:\n         x: Input data. It could be: - A Numpy array (or array-like), or a list\n           of arrays (in case the model has multiple inputs). - A TensorFlow\n           tensor, or a list of tensors (in case the model has multiple inputs).\n@@ -1989,7 +1989,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     [Serialization and Saving guide](https://keras.io/guides/serialization_and_saving/)\n     for details.\n \n-    Arguments:\n+    Args:\n         filepath: String, PathLike, path to SavedModel or H5 file to save the\n             model.\n         overwrite: Whether to silently overwrite any existing file at the\n@@ -2075,7 +2075,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     checkpoints](https://www.tensorflow.org/guide/checkpoint) for details\n     on the TensorFlow format.\n \n-    Arguments:\n+    Args:\n         filepath: String or PathLike, path to the file to save the weights to.\n             When saving in TensorFlow format, this is the prefix used for\n             checkpoint files (multiple files are generated). Note that the '.h5'\n@@ -2180,7 +2180,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     TensorFlow format loads based on the object-local names of attributes to\n     which layers are assigned in the `Model`'s constructor.\n \n-    Arguments:\n+    Args:\n         filepath: String, path to the weights file to load. For weight files in\n             TensorFlow format, this is the file prefix (the same as was passed\n             to `save_weights`). This can also be a path to a SavedModel\n@@ -2286,7 +2286,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     To load a network from a JSON save file, use\n     `keras.models.model_from_json(json_string, custom_objects={})`.\n \n-    Arguments:\n+    Args:\n         **kwargs: Additional keyword arguments\n             to be passed to `json.dumps()`.\n \n@@ -2307,7 +2307,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     the names of custom losses / layers / etc to the corresponding\n     functions / classes.\n \n-    Arguments:\n+    Args:\n         **kwargs: Additional keyword arguments\n             to be passed to `yaml.dump()`.\n \n@@ -2376,7 +2376,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n   def summary(self, line_length=None, positions=None, print_fn=None):\n     \"\"\"Prints a string summary of the network.\n \n-    Arguments:\n+    Args:\n         line_length: Total length of printed lines\n             (e.g. set this to adapt the display to different\n             terminal window sizes).\n@@ -2412,7 +2412,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     If `name` and `index` are both provided, `index` will take precedence.\n     Indices are based on order of horizontal graph traversal (bottom-up).\n \n-    Arguments:\n+    Args:\n         name: String, name of layer.\n         index: Integer, index of layer.\n \n@@ -2589,7 +2589,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     Refer to tensorflow/python/keras/distribute/worker_training_state.py\n     for more information.\n \n-    Arguments:\n+    Args:\n       initial_epoch: The original initial_epoch user passes in in `fit()`.\n \n     Returns:\n@@ -2694,7 +2694,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n def reduce_per_replica(values, strategy, reduction='first'):\n   \"\"\"Reduce PerReplica objects.\n \n-  Arguments:\n+  Args:\n     values: Structure of `PerReplica` objects or `Tensor`s. `Tensor`s are\n       returned as-is.\n     strategy: `tf.distribute.Strategy` object.\n@@ -2860,4 +2860,3 @@ def _is_readable_tf_checkpoint(filepath):\n   except tf.errors.DataLossError:\n     # The checkpoint is not readable in TensorFlow format.\n     return False\n-\n\n@@ -62,7 +62,7 @@ def model_iteration(model,\n                     **kwargs):\n   \"\"\"Loop function for arrays of data with modes TRAIN/TEST/PREDICT.\n \n-  Arguments:\n+  Args:\n       model: Keras Model instance.\n       inputs: Either a list or dictionary of arrays, or a dataset instance.\n       targets: List/dictionary of input arrays.\n@@ -482,7 +482,7 @@ def _get_num_samples_or_steps(ins, batch_size, steps_per_epoch):\n def _prepare_feed_values(model, inputs, targets, sample_weights, mode):\n   \"\"\"Prepare feed values to the model execution function.\n \n-  Arguments:\n+  Args:\n     model: Model to prepare feed values for.\n     inputs: List or dict of model inputs.\n     targets: Optional list of model targets.\n\n@@ -55,7 +55,7 @@ def _build_model(strategy, model, mode, inputs, targets=None):\n def _make_train_step_fn(model, mode, strategy, output_labels):\n   \"\"\"Create step fn.\n \n-  Arguments:\n+  Args:\n     model: a Keras Model instance.\n     mode: One of ModeKeys.TRAIN/ModeKeys.TEST/ModeKeys.PREDICT.\n     strategy: a `tf.distribute.Strategy` instance.\n@@ -127,7 +127,7 @@ def experimental_tpu_fit_loop(model,\n                               validation_freq=1):\n   \"\"\"Fit loop for training with TPU tf.distribute.Strategy.\n \n-  Arguments:\n+  Args:\n       model: Keras Model instance.\n       dataset: Dataset that returns inputs and targets\n       epochs: Number of times to iterate over the data\n@@ -292,7 +292,7 @@ def experimental_tpu_test_loop(model,\n                                callbacks=None):\n   \"\"\"Test loop for evaluating with TPU tf.distribute.Strategy.\n \n-  Arguments:\n+  Args:\n       model: Keras Model instance.\n       dataset: Dataset for input data.\n       verbose: Integer, Verbosity mode 0 or 1.\n@@ -423,7 +423,7 @@ def experimental_tpu_predict_loop(model,\n                                   callbacks=None):\n   \"\"\"Predict loop for predicting with TPU tf.distribute.Strategy.\n \n-  Arguments:\n+  Args:\n       model: Keras Model instance.\n       dataset: Dataset for input data.\n       verbose: Integer, Verbosity mode 0 or 1.\n\n@@ -41,7 +41,7 @@ def _eager_loss_fn(outputs, targets, loss_fn, output_name):\n def _eager_metrics_fn(model, outputs, targets, sample_weights=None, masks=None):\n   \"\"\"Calculates the metrics for each output of the given model.\n \n-  Arguments:\n+  Args:\n       model: The model on which metrics are being calculated.\n       outputs: The outputs of the given model.\n       targets: The predictions or targets of the given model.\n@@ -89,7 +89,7 @@ def _model_loss(model,\n                 training=False):\n   \"\"\"Calculates the loss for a given model.\n \n-  Arguments:\n+  Args:\n       model: The model on which metrics are being calculated.\n       inputs: Either a dictionary of inputs to the model or a list of input\n         arrays.\n@@ -230,7 +230,7 @@ def _process_single_batch(model,\n \n      The model weights are updated if training is set to True.\n \n-  Arguments:\n+  Args:\n       model: Model whose loss has to be calculated.\n       inputs: List of input arrays.\n       targets: List of target arrays.\n@@ -290,7 +290,7 @@ def train_on_batch(model,\n                    output_loss_metrics=None):\n   \"\"\"Calculates the loss and gradient updates for one input batch.\n \n-  Arguments:\n+  Args:\n       model: Model whose loss has to be calculated.\n       inputs: Input batch data.\n       targets: Target batch data.\n@@ -331,7 +331,7 @@ def test_on_batch(model,\n                   output_loss_metrics=None):\n   \"\"\"Calculates the loss for one input batch.\n \n-  Arguments:\n+  Args:\n       model: Model whose loss has to be calculated.\n       inputs: Input batch data.\n       targets: Target batch data.\n\n@@ -56,7 +56,7 @@ def model_iteration(model,\n                     **kwargs):\n   \"\"\"Loop function for arrays of data with modes TRAIN/TEST/PREDICT.\n \n-  Arguments:\n+  Args:\n       model: Keras Model instance.\n       data: Either a tuple of NumPy/Tensor inputs (i.e. `(x,)` or `(x, y)` or\n         `(x, y, sample_weights)`) or a generator or\n@@ -366,7 +366,7 @@ def _validate_arguments(is_sequence, is_dataset, use_multiprocessing, workers,\n                         mode, kwargs):\n   \"\"\"Raises errors if arguments are invalid.\n \n-  Arguments:\n+  Args:\n     is_sequence: Boolean, whether data is a `keras.utils.data_utils.Sequence`\n       instance.\n     is_dataset: Boolean, whether data is a dataset instance.\n@@ -425,7 +425,7 @@ def convert_to_generator_like(data,\n                               shuffle=False):\n   \"\"\"Make a generator out of NumPy or EagerTensor inputs.\n \n-  Arguments:\n+  Args:\n     data: Either a generator or `keras.utils.data_utils.Sequence` object or\n       `Dataset`, `Iterator`, or a {1,2,3}-tuple of NumPy arrays or EagerTensors.\n       If a tuple, the elements represent `(x, y, sample_weights)` and may be\n\n@@ -32,7 +32,7 @@ def slice_arrays(arrays, indices, contiguous=True):\n   and we have to implement this workaround based on `concat`. This has a\n   performance cost.\n \n-  Arguments:\n+  Args:\n     arrays: Single array or list of arrays.\n     indices: List of indices in the array that should be included in the output\n       batch.\n@@ -203,7 +203,7 @@ def get_input_shape_and_dtype(layer):\n def get_static_batch_size(layer):\n   \"\"\"Gets the static batch size of a Layer.\n \n-  Arguments:\n+  Args:\n     layer: a `Layer` instance.\n \n   Returns:\n\n@@ -76,7 +76,7 @@ class Aggregator(object):\n   def create(self, batch_outs):\n     \"\"\"Creates the initial results from the first batch outputs.\n \n-    Arguments:\n+    Args:\n       batch_outs: A list of batch-level outputs.\n     \"\"\"\n     raise NotImplementedError('Must be implemented in subclasses.')\n@@ -85,7 +85,7 @@ class Aggregator(object):\n   def aggregate(self, batch_outs, batch_start=None, batch_end=None):\n     \"\"\"Aggregates batch-level results into total results.\n \n-    Arguments:\n+    Args:\n       batch_outs: A list of batch-level outputs.\n       batch_start: The start index of this batch. Always `None` if `use_steps`\n         is `True`.\n@@ -207,7 +207,7 @@ def _append_composite_tensor(target, to_append):\n   working with CompositeTensor Value objects that have no connection with the\n   CompositeTensors that created them.\n \n-  Arguments:\n+  Args:\n     target: CompositeTensor or CompositeTensor value object that will be\n       appended to.\n     to_append: CompositeTensor or CompositeTensor value object to append to.\n@@ -467,7 +467,7 @@ def check_num_samples(ins, batch_size=None, steps=None, steps_name='steps'):\n   The number of samples is not defined when running with `steps`,\n   in which case the number of samples is set to `None`.\n \n-  Arguments:\n+  Args:\n       ins: List of tensors to be fed to the Keras function.\n       batch_size: Integer batch size or `None` if not defined.\n       steps: Total number of steps (batches of samples) before declaring\n@@ -539,7 +539,7 @@ def standardize_input_data(data,\n   arrays (same order as `names`), while checking that the provided\n   arrays have shapes that match the network's expectations.\n \n-  Arguments:\n+  Args:\n       data: User-provided input data (polymorphic).\n       names: List of expected array names.\n       shapes: Optional list of expected array shapes.\n@@ -656,7 +656,7 @@ def standardize_input_data(data,\n def standardize_sample_or_class_weights(x_weight, output_names, weight_type):\n   \"\"\"Maps `sample_weight` or `class_weight` to model outputs.\n \n-  Arguments:\n+  Args:\n       x_weight: User-provided `sample_weight` or `class_weight` argument.\n       output_names: List of output names (strings) in the model.\n       weight_type: A string used purely for exception printing.\n@@ -712,7 +712,7 @@ def standardize_sample_weights(sample_weight, output_names):\n def check_array_lengths(inputs, targets, weights=None):\n   \"\"\"Does user input validation for numpy arrays.\n \n-  Arguments:\n+  Args:\n       inputs: list of Numpy arrays of inputs.\n       targets: list of Numpy arrays of targets.\n       weights: list of Numpy arrays of sample weights.\n@@ -769,7 +769,7 @@ def check_loss_and_target_compatibility(targets, loss_fns, output_shapes):\n   This helps prevent users from using loss functions incorrectly. This check\n   is purely for UX purposes.\n \n-  Arguments:\n+  Args:\n       targets: list of Numpy arrays of targets.\n       loss_fns: list of loss functions.\n       output_shapes: list of shapes of model outputs.\n@@ -829,7 +829,7 @@ def collect_per_output_metric_info(metrics,\n                                    is_weighted=False):\n   \"\"\"Maps metric names and functions to model outputs.\n \n-  Arguments:\n+  Args:\n       metrics: a list or a list of lists or a dict of metric functions.\n       output_names: a list of the names (strings) of model outputs.\n       output_shapes: a list of the shapes (strings) of model outputs.\n@@ -907,7 +907,7 @@ def batch_shuffle(index_array, batch_size):\n   Useful for shuffling HDF5 arrays\n   (where one cannot access arbitrary indices).\n \n-  Arguments:\n+  Args:\n       index_array: array of indices to be shuffled.\n       batch_size: integer.\n \n@@ -935,7 +935,7 @@ def standardize_weights(y,\n   weight array. If both `sample_weight` and `class_weight` are provided,\n   the weights are multiplied.\n \n-  Arguments:\n+  Args:\n       y: Numpy array or Tensor of model targets to be weighted.\n       sample_weight: User-provided `sample_weight` argument.\n       class_weight: User-provided `class_weight` argument.\n@@ -1079,7 +1079,7 @@ def has_tensors(ls):\n def get_metric_name(metric, weighted=False):\n   \"\"\"Returns the name corresponding to the given metric input.\n \n-  Arguments:\n+  Args:\n     metric: Metric function name or reference.\n     weighted: Boolean indicating if the given metric is weighted.\n \n@@ -1114,7 +1114,7 @@ def get_metric_name(metric, weighted=False):\n def get_metric_function(metric, output_shape=None, loss_fn=None):\n   \"\"\"Returns the metric function corresponding to the given metric input.\n \n-  Arguments:\n+  Args:\n       metric: Metric function name or reference.\n       output_shape: The shape of the output that this metric will be calculated\n         for.\n@@ -1212,7 +1212,7 @@ def get_loss_function(loss):\n def validate_dataset_input(x, y, sample_weight, validation_split=None):\n   \"\"\"Validates user input arguments when a dataset iterator is passed.\n \n-  Arguments:\n+  Args:\n     x: Input data. A `tf.data` dataset or iterator.\n     y: Target data. It could be either Numpy array(s) or TensorFlow tensor(s).\n       Expected to be `None` when `x` is a dataset iterator.\n@@ -1290,7 +1290,7 @@ def check_steps_argument(input_data, steps, steps_name):\n        required and is `None`.\n     3. input data passed is a symbolic tensor.\n \n-  Arguments:\n+  Args:\n       input_data: Input data. Can be Numpy array(s) or TensorFlow tensor(s) or\n         tf.data.Dataset iterator or `None`.\n       steps: Integer or `None`. Total number of steps (batches of samples) to\n@@ -1438,7 +1438,7 @@ def prepare_sample_weight_modes(training_endpoints, sample_weight_mode):\n def prepare_loss_functions(loss, output_names):\n   \"\"\"Converts loss to a list of loss functions.\n \n-  Arguments:\n+  Args:\n       loss: String (name of objective function), objective function or\n         `tf.losses.Loss` instance. See `tf.losses`. If the model has multiple\n         outputs, you can use a different loss on each output by passing a\n@@ -1482,7 +1482,7 @@ def prepare_loss_weights(training_endpoints, loss_weights=None):\n \n   The result loss weights will be populated on the training endpoint.\n \n-  Arguments:\n+  Args:\n       training_endpoints: List of model training endpoints.\n       loss_weights: Optional list or dictionary specifying scalar coefficients\n         (Python floats) to weight the loss contributions of different model\n@@ -1589,7 +1589,7 @@ def initialize_iterator(iterator):\n def extract_tensors_from_dataset(dataset):\n   \"\"\"Extract a tuple of tensors `inputs, targets, sample_weight` from a dataset.\n \n-  Arguments:\n+  Args:\n     dataset: Dataset instance.\n \n   Returns:\n@@ -1603,7 +1603,7 @@ def extract_tensors_from_dataset(dataset):\n def unpack_iterator_input(iterator):\n   \"\"\"Convert a dataset iterator to a tuple of tensors `x, y, sample_weights`.\n \n-  Arguments:\n+  Args:\n     iterator: Instance of a dataset iterator.\n \n   Returns:\n@@ -1641,7 +1641,7 @@ def infer_steps_for_dataset(model,\n                             steps_name='steps'):\n   \"\"\"Infers steps_per_epoch needed to loop through a dataset.\n \n-  Arguments:\n+  Args:\n       model: Keras model instance.\n       dataset: Input data of type tf.data.Dataset.\n       steps: Number of steps to draw from the dataset (may be None if unknown).\n@@ -1785,7 +1785,7 @@ def generic_output_names(outputs_list):\n def should_run_validation(validation_freq, epoch):\n   \"\"\"Checks if validation should be run this epoch.\n \n-  Arguments:\n+  Args:\n     validation_freq: Integer or list. If an integer, specifies how many training\n       epochs to run before a new validation run is performed. If a list,\n       specifies the epochs on which to run validation.\n\n@@ -185,7 +185,7 @@ class Model(training_lib.Model):\n     TensorFlow format loads based on the object-local names of attributes to\n     which layers are assigned in the `Model`'s constructor.\n \n-    Arguments:\n+    Args:\n         filepath: String, path to the weights file to load. For weight files in\n             TensorFlow format, this is the file prefix (the same as was passed\n             to `save_weights`).\n@@ -231,7 +231,7 @@ class Model(training_lib.Model):\n               **kwargs):\n     \"\"\"Configures the model for training.\n \n-    Arguments:\n+    Args:\n         optimizer: String (name of optimizer) or optimizer instance.\n             See `tf.keras.optimizers`.\n         loss: String (name of objective function), objective function or\n@@ -620,7 +620,7 @@ class Model(training_lib.Model):\n           **kwargs):\n     \"\"\"Trains the model for a fixed number of epochs (iterations on a dataset).\n \n-    Arguments:\n+    Args:\n         x: Input data. It could be:\n           - A Numpy array (or array-like), or a list of arrays\n             (in case the model has multiple inputs).\n@@ -813,7 +813,7 @@ class Model(training_lib.Model):\n \n     Computation is done in batches (see the `batch_size` arg.)\n \n-    Arguments:\n+    Args:\n         x: Input data. It could be:\n           - A Numpy array (or array-like), or a list of arrays\n             (in case the model has multiple inputs).\n@@ -917,7 +917,7 @@ class Model(training_lib.Model):\n \n     Computation is done in batches (see the `batch_size` arg.)\n \n-    Arguments:\n+    Args:\n         x: Input samples. It could be:\n           - A Numpy array (or array-like), or a list of arrays\n             (in case the model has multiple inputs).\n@@ -999,7 +999,7 @@ class Model(training_lib.Model):\n                      reset_metrics=True):\n     \"\"\"Runs a single gradient update on a single batch of data.\n \n-    Arguments:\n+    Args:\n         x: Input data. It could be:\n           - A Numpy array (or array-like), or a list of arrays\n               (in case the model has multiple inputs).\n@@ -1088,7 +1088,7 @@ class Model(training_lib.Model):\n   def test_on_batch(self, x, y=None, sample_weight=None, reset_metrics=True):\n     \"\"\"Test the model on a single batch of samples.\n \n-    Arguments:\n+    Args:\n         x: Input data. It could be:\n           - A Numpy array (or array-like), or a list of arrays\n             (in case the model has multiple inputs).\n@@ -1164,7 +1164,7 @@ class Model(training_lib.Model):\n   def predict_on_batch(self, x):\n     \"\"\"Returns predictions for a single batch of samples.\n \n-    Arguments:\n+    Args:\n         x: Input data. It could be:\n           - A Numpy array (or array-like), or a list of arrays\n             (in case the model has multiple inputs).\n@@ -1553,7 +1553,7 @@ class Model(training_lib.Model):\n   def _prepare_total_loss(self, masks):\n     \"\"\"Computes total loss from loss functions.\n \n-    Arguments:\n+    Args:\n         masks: List of mask values corresponding to each model output.\n \n     Returns:\n@@ -1679,7 +1679,7 @@ class Model(training_lib.Model):\n     raised if `x` is a tf.data.Dataset and `batch_size` is specified as we\n     expect users to provide batched datasets.\n \n-    Arguments:\n+    Args:\n       batch_size: The batch_size provided as an argument to\n         fit/evaluate/predict.\n       steps: The steps provided as an argument to fit/evaluate/predict.\n@@ -1798,7 +1798,7 @@ class Model(training_lib.Model):\n       If there are multiple outputs for which the metrics are calculated, the\n       metric names have to be made unique by appending an integer.\n \n-    Arguments:\n+    Args:\n       metric_name: Metric name that corresponds to the metric specified by the\n           user. For example: 'acc'.\n       output_index: The index of the model output for which the metric name is\n@@ -1826,7 +1826,7 @@ class Model(training_lib.Model):\n   def _set_per_output_metric_attributes(self, metrics_dict, output_index):\n     \"\"\"Sets the metric attributes on the model for the given output.\n \n-    Arguments:\n+    Args:\n       metrics_dict: A dict with metric names as keys and metric fns as values.\n       output_index: The index of the model output for which the metric\n         attributes are added.\n@@ -1882,7 +1882,7 @@ class Model(training_lib.Model):\n                                  weights=None):\n     \"\"\"Calls metric functions for a single output.\n \n-    Arguments:\n+    Args:\n       metrics_dict: A dict with metric names as keys and metric fns as values.\n       y_true: Target output.\n       y_pred: Predicted output.\n@@ -1910,7 +1910,7 @@ class Model(training_lib.Model):\n                       return_weighted_and_unweighted_metrics=False):\n     \"\"\"Handles calling metric functions.\n \n-    Arguments:\n+    Args:\n       outputs: List of outputs (predictions).\n       targets: List of targets.\n       skip_target_masks: Optional. List of boolean for whether the corresponding\n@@ -2740,7 +2740,7 @@ class Model(training_lib.Model):\n     Refer to tensorflow/python/keras/distribute/worker_training_state.py\n     for more information.\n \n-    Arguments:\n+    Args:\n       initial_epoch: The original initial_epoch user passes in in `fit()`.\n       mode: The mode for running `model.fit()`.\n \n@@ -3094,7 +3094,7 @@ class _TrainingEndpoint(object):\n class _TrainingTarget(object):\n   \"\"\"Container for a target tensor (y_true) and its metadata (shape, loss...).\n \n-  Arguments:\n+  Args:\n     target: A target tensor for the model. It may be `None` if the\n       output is excluded from loss computation. It is still kept as None\n       since each output of the model should have a corresponding target. If\n@@ -3138,7 +3138,7 @@ def _convert_scipy_sparse_tensor(value, expected_input):\n   not a scipy sparse tensor, or scipy is not imported, we pass it through\n   unchanged.\n \n-  Arguments:\n+  Args:\n     value: An object that may be a scipy sparse tensor\n     expected_input: The expected input placeholder.\n \n@@ -3169,7 +3169,7 @@ def _get_metrics_from_layers(layers):\n \n   This will not include the `compile` metrics of a model layer.\n \n-  Arguments:\n+  Args:\n     layers: List of layers.\n \n   Returns:\n\n@@ -20,10 +20,15 @@ from __future__ import division\n from __future__ import print_function\n \n import tensorflow as tf\n+\n+import math\n from keras import backend\n-from tensorflow.python.ops import init_ops_v2\n+from tensorflow.python.ops import stateless_random_ops\n from tensorflow.python.util.tf_export import keras_export\n \n+_PARTITION_SHAPE = 'partition_shape'\n+_PARTITION_OFFSET = 'partition_offset'\n+\n \n @keras_export('keras.initializers.Initializer')\n class Initializer(object):\n@@ -307,7 +312,7 @@ class RandomNormal(tf.random_normal_initializer, Initializer):\n @keras_export('keras.initializers.TruncatedNormal',\n               'keras.initializers.truncated_normal',\n               v1=[])\n-class TruncatedNormal(init_ops_v2.TruncatedNormal, Initializer):\n+class TruncatedNormal(Initializer):\n   \"\"\"Initializer that generates a truncated normal distribution.\n \n   Also available via the shortcut function\n@@ -337,6 +342,12 @@ class TruncatedNormal(init_ops_v2.TruncatedNormal, Initializer):\n       always produce the same random tensor for a given shape and dtype.\n   \"\"\"\n \n+  def __init__(self, mean=0.0, stddev=0.05, seed=None):\n+    self.mean = mean\n+    self.stddev = stddev\n+    self.seed = seed\n+    self._random_generator = _RandomGenerator(seed)\n+\n   def __call__(self, shape, dtype=None, **kwargs):\n     \"\"\"Returns a tensor object initialized to random normal values (truncated).\n \n@@ -348,14 +359,25 @@ class TruncatedNormal(init_ops_v2.TruncatedNormal, Initializer):\n         `tf.keras.backend.set_floatx(float_dtype)`)\n       **kwargs: Additional keyword arguments.\n     \"\"\"\n-    return super(TruncatedNormal, self).__call__(\n-        shape, dtype=_get_dtype(dtype), **kwargs)\n+    _validate_kwargs(self.__class__.__name__, kwargs)\n+    dtype = _assert_float_dtype(_get_dtype(dtype))\n+    if _PARTITION_SHAPE in kwargs:\n+      shape = kwargs[_PARTITION_SHAPE]\n+    return self._random_generator.truncated_normal(shape, self.mean,\n+                                                   self.stddev, dtype)\n+\n+  def get_config(self):\n+    return {\n+        'mean': self.mean,\n+        'stddev': self.stddev,\n+        'seed': self.seed\n+    }\n \n \n @keras_export('keras.initializers.VarianceScaling',\n               'keras.initializers.variance_scaling',\n               v1=[])\n-class VarianceScaling(init_ops_v2.VarianceScaling, Initializer):\n+class VarianceScaling(Initializer):\n   \"\"\"Initializer capable of adapting its scale to the shape of weights tensors.\n \n   Also available via the shortcut function\n@@ -394,6 +416,28 @@ class VarianceScaling(init_ops_v2.VarianceScaling, Initializer):\n       always produce the same random tensor for a given shape and dtype.\n   \"\"\"\n \n+  def __init__(self,\n+               scale=1.0,\n+               mode='fan_in',\n+               distribution='truncated_normal',\n+               seed=None):\n+    if scale <= 0.:\n+      raise ValueError('`scale` must be positive float.')\n+    if mode not in {'fan_in', 'fan_out', 'fan_avg'}:\n+      raise ValueError('Invalid `mode` argument:', mode)\n+    distribution = distribution.lower()\n+    # Compatibility with keras-team/keras.\n+    if distribution == 'normal':\n+      distribution = 'truncated_normal'\n+    if distribution not in {'uniform', 'truncated_normal',\n+                            'untruncated_normal'}:\n+      raise ValueError('Invalid `distribution` argument:', distribution)\n+    self.scale = scale\n+    self.mode = mode\n+    self.distribution = distribution\n+    self.seed = seed\n+    self._random_generator = _RandomGenerator(seed)\n+\n   def __call__(self, shape, dtype=None, **kwargs):\n     \"\"\"Returns a tensor object initialized as specified by the initializer.\n \n@@ -405,14 +449,42 @@ class VarianceScaling(init_ops_v2.VarianceScaling, Initializer):\n         `tf.keras.backend.set_floatx(float_dtype)`)\n       **kwargs: Additional keyword arguments.\n     \"\"\"\n-    return super(VarianceScaling, self).__call__(\n-        shape, dtype=_get_dtype(dtype), **kwargs)\n+    _validate_kwargs(self.__class__.__name__, kwargs)\n+    dtype = _assert_float_dtype(_get_dtype(dtype))\n+    scale = self.scale\n+    fan_in, fan_out = _compute_fans(shape)\n+    if _PARTITION_SHAPE in kwargs:\n+      shape = kwargs[_PARTITION_SHAPE]\n+    if self.mode == 'fan_in':\n+      scale /= max(1., fan_in)\n+    elif self.mode == 'fan_out':\n+      scale /= max(1., fan_out)\n+    else:\n+      scale /= max(1., (fan_in + fan_out) / 2.)\n+    if self.distribution == 'truncated_normal':\n+      # constant from scipy.stats.truncnorm.std(a=-2, b=2, loc=0., scale=1.)\n+      stddev = math.sqrt(scale) / .87962566103423978\n+      return self._random_generator.truncated_normal(shape, 0.0, stddev, dtype)\n+    elif self.distribution == 'untruncated_normal':\n+      stddev = math.sqrt(scale)\n+      return self._random_generator.random_normal(shape, 0.0, stddev, dtype)\n+    else:\n+      limit = math.sqrt(3.0 * scale)\n+      return self._random_generator.random_uniform(shape, -limit, limit, dtype)\n+\n+  def get_config(self):\n+    return {\n+        'scale': self.scale,\n+        'mode': self.mode,\n+        'distribution': self.distribution,\n+        'seed': self.seed\n+    }\n \n \n @keras_export('keras.initializers.Orthogonal',\n               'keras.initializers.orthogonal',\n               v1=[])\n-class Orthogonal(init_ops_v2.Orthogonal, Initializer):\n+class Orthogonal(Initializer):\n   \"\"\"Initializer that generates an orthogonal matrix.\n \n   Also available via the shortcut function `tf.keras.initializers.orthogonal`.\n@@ -448,6 +520,11 @@ class Orthogonal(init_ops_v2.Orthogonal, Initializer):\n       ([pdf](https://arxiv.org/pdf/1312.6120.pdf))\n   \"\"\"\n \n+  def __init__(self, gain=1.0, seed=None):\n+    self.gain = gain\n+    self.seed = seed\n+    self._random_generator = _RandomGenerator(seed)\n+\n   def __call__(self, shape, dtype=None, **kwargs):\n     \"\"\"Returns a tensor object initialized to an orthogonal matrix.\n \n@@ -459,14 +536,39 @@ class Orthogonal(init_ops_v2.Orthogonal, Initializer):\n        (via `tf.keras.backend.set_floatx(float_dtype)`)\n       **kwargs: Additional keyword arguments.\n     \"\"\"\n-    return super(Orthogonal, self).__call__(\n-        shape, dtype=_get_dtype(dtype), **kwargs)\n+    _validate_kwargs(self.__class__.__name__, kwargs, support_partition=False)\n+    dtype = _assert_float_dtype(_get_dtype(dtype))\n+    # Check the shape\n+    if len(shape) < 2:\n+      raise ValueError('The tensor to initialize must be '\n+                       'at least two-dimensional')\n+    # Flatten the input shape with the last dimension remaining\n+    # its original shape so it works for conv2d\n+    num_rows = 1\n+    for dim in shape[:-1]:\n+      num_rows *= dim\n+    num_cols = shape[-1]\n+    flat_shape = (max(num_cols, num_rows), min(num_cols, num_rows))\n+\n+    # Generate a random matrix\n+    a = self._random_generator.random_normal(flat_shape, dtype=dtype)\n+    # Compute the qr factorization\n+    q, r = tf.linalg.qr(a, full_matrices=False)\n+    # Make Q uniform\n+    d = tf.linalg.tensor_diag_part(r)\n+    q *= tf.sign(d)\n+    if num_rows < num_cols:\n+      q = tf.linalg.matrix_transpose(q)\n+    return self.gain * tf.reshape(q, shape)\n+\n+  def get_config(self):\n+    return {'gain': self.gain, 'seed': self.seed}\n \n \n @keras_export('keras.initializers.Identity',\n               'keras.initializers.identity',\n               v1=[])\n-class Identity(init_ops_v2.Identity, Initializer):\n+class Identity(Initializer):\n   \"\"\"Initializer that generates the identity matrix.\n \n   Also available via the shortcut function `tf.keras.initializers.identity`.\n@@ -487,6 +589,9 @@ class Identity(init_ops_v2.Identity, Initializer):\n     gain: Multiplicative factor to apply to the identity matrix.\n   \"\"\"\n \n+  def __init__(self, gain=1.0):\n+    self.gain = gain\n+\n   def __call__(self, shape, dtype=None, **kwargs):\n     \"\"\"Returns a tensor object initialized to a 2D identity matrix.\n \n@@ -498,8 +603,16 @@ class Identity(init_ops_v2.Identity, Initializer):\n        (via `tf.keras.backend.set_floatx(float_dtype)`)\n       **kwargs: Additional keyword arguments.\n     \"\"\"\n-    return super(Identity, self).__call__(\n-        shape, dtype=_get_dtype(dtype), **kwargs)\n+    _validate_kwargs(self.__class__.__name__, kwargs, support_partition=False)\n+    dtype = _assert_float_dtype(_get_dtype(dtype))\n+    if len(shape) != 2:\n+      raise ValueError(\n+          'Identity matrix initializer can only be used for 2D matrices.')\n+    initializer = tf.eye(*shape, dtype=dtype)\n+    return self.gain * initializer\n+\n+  def get_config(self):\n+    return {'gain': self.gain}\n \n \n @keras_export('keras.initializers.GlorotUniform',\n@@ -616,7 +729,7 @@ class LecunNormal(VarianceScaling):\n   >>> initializer = tf.keras.initializers.LecunNormal()\n   >>> layer = tf.keras.layers.Dense(3, kernel_initializer=initializer)\n \n-  Arguments:\n+  Args:\n     seed: A Python integer. Used to seed the random generator.\n \n   References:\n@@ -660,7 +773,7 @@ class LecunUniform(VarianceScaling):\n   >>> initializer = tf.keras.initializers.LecunUniform()\n   >>> layer = tf.keras.layers.Dense(3, kernel_initializer=initializer)\n \n-  Arguments:\n+  Args:\n     seed: A Python integer. An initializer created with a given seed will\n       always produce the same random tensor for a given shape and dtype.\n \n@@ -703,7 +816,7 @@ class HeNormal(VarianceScaling):\n   >>> initializer = tf.keras.initializers.HeNormal()\n   >>> layer = tf.keras.layers.Dense(3, kernel_initializer=initializer)\n \n-  Arguments:\n+  Args:\n     seed: A Python integer. An initializer created with a given seed will\n       always produce the same random tensor for a given shape and dtype.\n \n@@ -743,7 +856,7 @@ class HeUniform(VarianceScaling):\n   >>> initializer = tf.keras.initializers.HeUniform()\n   >>> layer = tf.keras.layers.Dense(3, kernel_initializer=initializer)\n \n-  Arguments:\n+  Args:\n     seed: A Python integer. An initializer created with a given seed will\n       always produce the same random tensor for a given shape and dtype.\n \n@@ -764,3 +877,98 @@ def _get_dtype(dtype):\n   if dtype is None:\n     dtype = backend.floatx()\n   return tf.as_dtype(dtype)\n+\n+\n+def _assert_float_dtype(dtype):\n+  \"\"\"Validate and return floating point type based on `dtype`.\n+\n+  `dtype` must be a floating point type.\n+\n+  Args:\n+    dtype: The data type to validate.\n+\n+  Returns:\n+    Validated type.\n+\n+  Raises:\n+    ValueError: if `dtype` is not a floating point type.\n+  \"\"\"\n+  dtype = tf.as_dtype(dtype)\n+  if not dtype.is_floating:\n+    raise ValueError('Expected floating point type, got %s.' % dtype)\n+  return dtype\n+\n+\n+class _RandomGenerator(object):\n+  \"\"\"Random generator that selects appropriate random ops.\"\"\"\n+\n+  def __init__(self, seed=None):\n+    super(_RandomGenerator, self).__init__()\n+    if seed is not None:\n+      # Stateless random ops requires 2-int seed.\n+      self.seed = [seed, 0]\n+    else:\n+      self.seed = None\n+\n+  def random_normal(self, shape, mean=0.0, stddev=1, dtype=tf.float32):\n+    \"\"\"A deterministic random normal if seed is passed.\"\"\"\n+    if self.seed:\n+      op = tf.random.stateless_normal\n+    else:\n+      op = tf.random.normal\n+    return op(\n+        shape=shape, mean=mean, stddev=stddev, dtype=dtype, seed=self.seed)\n+\n+  def random_uniform(self, shape, minval, maxval, dtype):\n+    \"\"\"A deterministic random uniform if seed is passed.\"\"\"\n+    if self.seed:\n+      op = stateless_random_ops.stateless_random_uniform\n+    else:\n+      op = tf.random.uniform\n+    return op(\n+        shape=shape, minval=minval, maxval=maxval, dtype=dtype, seed=self.seed)\n+\n+  def truncated_normal(self, shape, mean, stddev, dtype):\n+    \"\"\"A deterministic truncated normal if seed is passed.\"\"\"\n+    if self.seed:\n+      op = tf.random.stateless_truncated_normal\n+    else:\n+      op = tf.random.truncated_normal\n+    return op(\n+        shape=shape, mean=mean, stddev=stddev, dtype=dtype, seed=self.seed)\n+\n+\n+def _compute_fans(shape):\n+  \"\"\"Computes the number of input and output units for a weight shape.\n+\n+  Args:\n+    shape: Integer shape tuple or TF tensor shape.\n+\n+  Returns:\n+    A tuple of integer scalars (fan_in, fan_out).\n+  \"\"\"\n+  if len(shape) < 1:  # Just to avoid errors for constants.\n+    fan_in = fan_out = 1\n+  elif len(shape) == 1:\n+    fan_in = fan_out = shape[0]\n+  elif len(shape) == 2:\n+    fan_in = shape[0]\n+    fan_out = shape[1]\n+  else:\n+    # Assuming convolution kernels (2D, 3D, or more).\n+    # kernel shape: (..., input_depth, depth)\n+    receptive_field_size = 1\n+    for dim in shape[:-2]:\n+      receptive_field_size *= dim\n+    fan_in = shape[-2] * receptive_field_size\n+    fan_out = shape[-1] * receptive_field_size\n+  return int(fan_in), int(fan_out)\n+\n+\n+def _validate_kwargs(cls_name, kwargs, support_partition=True):\n+  for kwarg in kwargs:\n+    if kwarg not in [_PARTITION_SHAPE, _PARTITION_OFFSET]:\n+      raise TypeError('Unknown keyword arguments: %s' % kwarg)\n+    elif not support_partition:\n+      raise ValueError('%s initializer doesn\\'t support partition-related '\n+                       'arguments' % cls_name)\n\n@@ -63,7 +63,7 @@ class LeakyReLU(Layer):\n   Output shape:\n     Same shape as the input.\n \n-  Arguments:\n+  Args:\n     alpha: Float >= 0. Negative slope coefficient. Default to 0.3.\n \n   \"\"\"\n@@ -107,7 +107,7 @@ class PReLU(Layer):\n   Output shape:\n     Same shape as the input.\n \n-  Arguments:\n+  Args:\n     alpha_initializer: Initializer function for the weights.\n     alpha_regularizer: Regularizer for the weights.\n     alpha_constraint: Constraint for the weights.\n@@ -199,7 +199,7 @@ class ELU(Layer):\n   Output shape:\n     Same shape as the input.\n \n-  Arguments:\n+  Args:\n     alpha: Scale for the negative factor.\n   \"\"\"\n \n@@ -240,7 +240,7 @@ class ThresholdedReLU(Layer):\n   Output shape:\n     Same shape as the input.\n \n-  Arguments:\n+  Args:\n     theta: Float >= 0. Threshold location of activation.\n   \"\"\"\n \n@@ -302,7 +302,7 @@ class Softmax(Layer):\n   Output shape:\n     Same shape as the input.\n \n-  Arguments:\n+  Args:\n     axis: Integer, or list of Integers, axis along which the softmax\n       normalization is applied.\n   Call arguments:\n@@ -388,7 +388,7 @@ class ReLU(Layer):\n   Output shape:\n     Same shape as the input.\n \n-  Arguments:\n+  Args:\n     max_value: Float >= 0. Maximum activation value. Default to None, which\n       means unlimited.\n     negative_slope: Float >= 0. Negative slope coefficient. Default to 0.\n\n@@ -58,7 +58,7 @@ class Conv(Layer):\n   Note: layer attributes cannot be modified after the layer has been called\n   once (except the `trainable` attribute).\n \n-  Arguments:\n+  Args:\n     rank: An integer, the rank of the convolution, e.g. \"2\" for 2D convolution.\n     filters: Integer, the dimensionality of the output space (i.e. the number\n       of filters in the convolution).\n@@ -69,9 +69,9 @@ class Conv(Layer):\n       Specifying any stride value != 1 is incompatible with specifying\n       any `dilation_rate` value != 1.\n     padding: One of `\"valid\"`,  `\"same\"`, or `\"causal\"` (case-insensitive).\n-      `\"valid\"` means no padding. `\"same\"` results in padding evenly to \n-      the left/right or up/down of the input such that output has the same \n-      height/width dimension as the input. `\"causal\"` results in causal \n+      `\"valid\"` means no padding. `\"same\"` results in padding with zeros\n+      evenly to the left/right or up/down of the input such that output has the\n+      same height/width dimension as the input. `\"causal\"` results in causal\n       (dilated) convolutions, e.g. `output[t]` does not depend on `input[t+1:]`.\n     data_format: A string, one of `channels_last` (default) or `channels_first`.\n       The ordering of the dimensions in the inputs.\n@@ -406,7 +406,7 @@ class Conv1D(Conv):\n   >>> print(y.shape)\n   (4, 7, 8, 32)\n \n-  Arguments:\n+  Args:\n     filters: Integer, the dimensionality of the output space\n       (i.e. the number of output filters in the convolution).\n     kernel_size: An integer or tuple/list of a single integer,\n@@ -416,8 +416,8 @@ class Conv1D(Conv):\n       Specifying any stride value != 1 is incompatible with specifying\n       any `dilation_rate` value != 1.\n     padding: One of `\"valid\"`, `\"same\"` or `\"causal\"` (case-insensitive).\n-      `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n-      the left/right or up/down of the input such that output has the same\n+      `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly\n+      to the left/right or up/down of the input such that output has the same\n       height/width dimension as the input.\n       `\"causal\"` results in causal (dilated) convolutions, e.g. `output[t]`\n       does not depend on `input[t+1:]`. Useful when modeling temporal data\n@@ -561,7 +561,7 @@ class Conv2D(Conv):\n   (4, 7, 26, 26, 2)\n \n \n-  Arguments:\n+  Args:\n     filters: Integer, the dimensionality of the output space (i.e. the number of\n       output filters in the convolution).\n     kernel_size: An integer or tuple/list of 2 integers, specifying the height\n@@ -572,8 +572,8 @@ class Conv2D(Conv):\n       specify the same value for all spatial dimensions. Specifying any stride\n       value != 1 is incompatible with specifying any `dilation_rate` value != 1.\n     padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n-      `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n-      the left/right or up/down of the input such that output has the same\n+      `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly\n+      to the left/right or up/down of the input such that output has the same\n       height/width dimension as the input.\n     data_format: A string, one of `channels_last` (default) or `channels_first`.\n       The ordering of the dimensions in the inputs. `channels_last` corresponds\n@@ -705,7 +705,7 @@ class Conv3D(Conv):\n   >>> print(y.shape)\n   (4, 7, 26, 26, 26, 2)\n \n-  Arguments:\n+  Args:\n     filters: Integer, the dimensionality of the output space (i.e. the number of\n       output filters in the convolution).\n     kernel_size: An integer or tuple/list of 3 integers, specifying the depth,\n@@ -716,8 +716,8 @@ class Conv3D(Conv):\n       specify the same value for all spatial dimensions. Specifying any stride\n       value != 1 is incompatible with specifying any `dilation_rate` value != 1.\n     padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n-      `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n-      the left/right or up/down of the input such that output has the same\n+      `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly\n+      to the left/right or up/down of the input such that output has the same\n       height/width dimension as the input.\n     data_format: A string, one of `channels_last` (default) or `channels_first`.\n       The ordering of the dimensions in the inputs. `channels_last` corresponds\n@@ -832,7 +832,7 @@ class Conv1DTranspose(Conv1D):\n   (tuple of integers or `None`, does not include the sample axis),\n   e.g. `input_shape=(128, 3)` for data with 128 time steps and 3 channels.\n \n-  Arguments:\n+  Args:\n     filters: Integer, the dimensionality of the output space\n       (i.e. the number of output filters in the convolution).\n     kernel_size: An integer length of the 1D convolution window.\n@@ -840,8 +840,8 @@ class Conv1DTranspose(Conv1D):\n       time dimension. Specifying a stride value != 1 is incompatible with\n       specifying a `dilation_rate` value != 1. Defaults to 1.\n     padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n-      `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n-      the left/right or up/down of the input such that output has the same\n+      `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly\n+      to the left/right or up/down of the input such that output has the same\n       height/width dimension as the input.\n     output_padding: An integer specifying the amount of padding along\n       the time dimension of the output tensor.\n@@ -1080,7 +1080,7 @@ class Conv2DTranspose(Conv2D):\n   e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n   in `data_format=\"channels_last\"`.\n \n-  Arguments:\n+  Args:\n     filters: Integer, the dimensionality of the output space\n       (i.e. the number of output filters in the convolution).\n     kernel_size: An integer or tuple/list of 2 integers, specifying the\n@@ -1094,8 +1094,8 @@ class Conv2DTranspose(Conv2D):\n       Specifying any stride value != 1 is incompatible with specifying\n       any `dilation_rate` value != 1.\n     padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n-      `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n-      the left/right or up/down of the input such that output has the same\n+      `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly\n+      to the left/right or up/down of the input such that output has the same\n       height/width dimension as the input.\n     output_padding: An integer or tuple/list of 2 integers,\n       specifying the amount of padding along the height and width\n@@ -1383,7 +1383,7 @@ class Conv3DTranspose(Conv3D):\n   e.g. `input_shape=(128, 128, 128, 3)` for a 128x128x128 volume with 3 channels\n   if `data_format=\"channels_last\"`.\n \n-  Arguments:\n+  Args:\n     filters: Integer, the dimensionality of the output space\n       (i.e. the number of output filters in the convolution).\n     kernel_size: An integer or tuple/list of 3 integers, specifying the\n@@ -1398,8 +1398,8 @@ class Conv3DTranspose(Conv3D):\n       Specifying any stride value != 1 is incompatible with specifying\n       any `dilation_rate` value != 1.\n     padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n-      `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n-      the left/right or up/down of the input such that output has the same\n+      `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly\n+      to the left/right or up/down of the input such that output has the same\n       height/width dimension as the input.\n     output_padding: An integer or tuple/list of 3 integers,\n       specifying the amount of padding along the depth, height, and\n@@ -1685,7 +1685,7 @@ class SeparableConv(Conv):\n   it adds a bias vector to the output.\n   It then optionally applies an activation function to produce the final output.\n \n-  Arguments:\n+  Args:\n     rank: An integer, the rank of the convolution, e.g. \"2\" for 2D convolution.\n     filters: Integer, the dimensionality of the output space (i.e. the number\n       of filters in the convolution).\n@@ -1698,8 +1698,8 @@ class SeparableConv(Conv):\n       Specifying any `stride` value != 1 is incompatible with specifying\n       any `dilation_rate` value != 1.\n     padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n-      `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n-      the left/right or up/down of the input such that output has the same\n+      `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly\n+      to the left/right or up/down of the input such that output has the same\n       height/width dimension as the input.\n     data_format: A string, one of `channels_last` (default) or `channels_first`.\n       The ordering of the dimensions in the inputs.\n@@ -1894,7 +1894,7 @@ class SeparableConv1D(SeparableConv):\n   it adds a bias vector to the output.\n   It then optionally applies an activation function to produce the final output.\n \n-  Arguments:\n+  Args:\n     filters: Integer, the dimensionality of the output space (i.e. the number\n       of filters in the convolution).\n     kernel_size: A single integer specifying the spatial\n@@ -1904,8 +1904,8 @@ class SeparableConv1D(SeparableConv):\n       Specifying any `stride` value != 1 is incompatible with specifying\n       any `dilation_rate` value != 1.\n     padding: One of `\"valid\"`, `\"same\"`, or `\"causal\"` (case-insensitive).\n-      `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n-      the left/right or up/down of the input such that output has the same\n+      `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly\n+      to the left/right or up/down of the input such that output has the same\n       height/width dimension as the input. `\"causal\"` results in causal\n       (dilated) convolutions, e.g. `output[t]` does not depend on `input[t+1:]`.\n     data_format: A string, one of `channels_last` (default) or `channels_first`.\n@@ -2078,7 +2078,7 @@ class SeparableConv2D(SeparableConv):\n   a way to factorize a convolution kernel into two smaller kernels,\n   or as an extreme version of an Inception block.\n \n-  Arguments:\n+  Args:\n     filters: Integer, the dimensionality of the output space\n       (i.e. the number of output filters in the convolution).\n     kernel_size: An integer or tuple/list of 2 integers, specifying the\n@@ -2092,8 +2092,8 @@ class SeparableConv2D(SeparableConv):\n       Specifying any stride value != 1 is incompatible with specifying\n       any `dilation_rate` value != 1.\n     padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n-      `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n-      the left/right or up/down of the input such that output has the same\n+      `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly\n+      to the left/right or up/down of the input such that output has the same\n       height/width dimension as the input.\n     data_format: A string,\n       one of `channels_last` (default) or `channels_first`.\n@@ -2243,7 +2243,7 @@ class DepthwiseConv2D(Conv2D):\n   The `depth_multiplier` argument controls how many\n   output channels are generated per input channel in the depthwise step.\n \n-  Arguments:\n+  Args:\n     kernel_size: An integer or tuple/list of 2 integers, specifying the\n       height and width of the 2D convolution window.\n       Can be a single integer to specify the same value for\n@@ -2255,8 +2255,8 @@ class DepthwiseConv2D(Conv2D):\n       Specifying any stride value != 1 is incompatible with specifying\n       any `dilation_rate` value != 1.\n     padding: one of `'valid'` or `'same'` (case-insensitive).\n-      `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n-      the left/right or up/down of the input such that output has the same\n+      `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly\n+      to the left/right or up/down of the input such that output has the same\n       height/width dimension as the input.\n     depth_multiplier: The number of depthwise convolution output channels\n       for each input channel.\n@@ -2477,7 +2477,7 @@ class UpSampling1D(Layer):\n       [ 9 10 11]\n       [ 9 10 11]]], shape=(2, 4, 3), dtype=int64)\n \n-  Arguments:\n+  Args:\n     size: Integer. Upsampling factor.\n \n   Input shape:\n@@ -2535,7 +2535,7 @@ class UpSampling2D(Layer):\n       [[ 9 10 11]\n        [ 9 10 11]]]], shape=(2, 2, 2, 3), dtype=int64)\n \n-  Arguments:\n+  Args:\n     size: Int, or tuple of 2 integers.\n       The upsampling factors for rows and columns.\n     data_format: A string,\n@@ -2626,7 +2626,7 @@ class UpSampling3D(Layer):\n   >>> print(y.shape)\n   (2, 2, 4, 2, 3)\n \n-  Arguments:\n+  Args:\n     size: Int, or tuple of 3 integers.\n       The upsampling factors for dim1, dim2 and dim3.\n     data_format: A string,\n@@ -2721,7 +2721,7 @@ class ZeroPadding1D(Layer):\n       [ 0  0  0]\n       [ 0  0  0]]], shape=(2, 6, 3), dtype=int64)\n \n-  Arguments:\n+  Args:\n       padding: Int, or tuple of int (length 2), or dictionary.\n           - If int:\n           How many zeros to add at the beginning and end of\n@@ -2788,7 +2788,7 @@ class ZeroPadding2D(Layer):\n        [0 0]\n        [0 0]]]], shape=(1, 3, 4, 2), dtype=int64)\n \n-  Arguments:\n+  Args:\n     padding: Int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.\n       - If int: the same symmetric padding\n         is applied to height and width.\n@@ -2895,7 +2895,7 @@ class ZeroPadding3D(Layer):\n   >>> print(y.shape)\n   (1, 5, 6, 6, 3)\n \n-  Arguments:\n+  Args:\n     padding: Int, or tuple of 3 ints, or tuple of 3 tuples of 2 ints.\n       - If int: the same symmetric padding\n         is applied to height and width.\n@@ -3032,7 +3032,7 @@ class Cropping1D(Layer):\n     [[[2 3]]\n      [[8 9]]], shape=(2, 1, 2), dtype=int64)\n \n-  Arguments:\n+  Args:\n     cropping: Int or tuple of int (length 2)\n       How many units should be trimmed off at the beginning and end of\n       the cropping dimension (axis 1).\n@@ -3084,7 +3084,7 @@ class Cropping2D(Layer):\n   >>> print(y.shape)\n   (2, 24, 20, 3)\n \n-  Arguments:\n+  Args:\n     cropping: Int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.\n       - If int: the same symmetric cropping\n         is applied to height and width.\n@@ -3209,7 +3209,7 @@ class Cropping3D(Layer):\n   >>> print(y.shape)\n   (2, 24, 20, 6, 3)\n \n-  Arguments:\n+  Args:\n     cropping: Int, or tuple of 3 ints, or tuple of 3 tuples of 2 ints.\n       - If int: the same symmetric cropping\n         is applied to depth, height, and width.\n\n@@ -41,7 +41,7 @@ from tensorflow.python.util.tf_export import keras_export\n class ConvRNN2D(RNN):\n   \"\"\"Base class for convolutional-recurrent layers.\n \n-  Arguments:\n+  Args:\n     cell: A RNN cell instance. A RNN cell is a class that has:\n       - a `call(input_at_t, states_at_t)` method, returning\n         `(output_at_t, states_at_t_plus_1)`. The call method of the\n@@ -425,7 +425,7 @@ class ConvRNN2D(RNN):\n class ConvLSTM2DCell(DropoutRNNCellMixin, Layer):\n   \"\"\"Cell class for the ConvLSTM2D layer.\n \n-  Arguments:\n+  Args:\n     filters: Integer, the dimensionality of the output space\n       (i.e. the number of output filters in the convolution).\n     kernel_size: An integer or tuple/list of n integers, specifying the\n@@ -704,7 +704,7 @@ class ConvLSTM2D(ConvRNN2D):\n   It is similar to an LSTM layer, but the input transformations\n   and recurrent transformations are both convolutional.\n \n-  Arguments:\n+  Args:\n     filters: Integer, the dimensionality of the output space\n       (i.e. the number of output filters in the convolution).\n     kernel_size: An integer or tuple/list of n integers, specifying the\n\n@@ -162,7 +162,7 @@ class Dropout(Layer):\n    [ 7.5   8.75]\n    [10.    0.  ]], shape=(5, 2), dtype=float32)\n \n-  Arguments:\n+  Args:\n     rate: Float between 0 and 1. Fraction of the input units to drop.\n     noise_shape: 1D integer tensor representing the shape of the\n       binary dropout mask that will be multiplied with the input.\n@@ -242,7 +242,7 @@ class SpatialDropout1D(Dropout):\n   decrease. In this case, SpatialDropout1D will help promote independence\n   between feature maps and should be used instead.\n \n-  Arguments:\n+  Args:\n     rate: Float between 0 and 1. Fraction of the input units to drop.\n \n   Call arguments:\n@@ -284,7 +284,7 @@ class SpatialDropout2D(Dropout):\n   decrease. In this case, SpatialDropout2D will help promote independence\n   between feature maps and should be used instead.\n \n-  Arguments:\n+  Args:\n     rate: Float between 0 and 1. Fraction of the input units to drop.\n     data_format: 'channels_first' or 'channels_last'.\n       In 'channels_first' mode, the channels dimension\n@@ -343,7 +343,7 @@ class SpatialDropout3D(Dropout):\n   decrease. In this case, SpatialDropout3D will help promote independence\n   between feature maps and should be used instead.\n \n-  Arguments:\n+  Args:\n     rate: Float between 0 and 1. Fraction of the input units to drop.\n     data_format: 'channels_first' or 'channels_last'.\n         In 'channels_first' mode, the channels dimension (the depth)\n@@ -393,7 +393,7 @@ class SpatialDropout3D(Dropout):\n class Activation(Layer):\n   \"\"\"Applies an activation function to an output.\n \n-  Arguments:\n+  Args:\n     activation: Activation function, such as `tf.nn.relu`, or string name of\n       built-in activation function, such as \"relu\".\n \n@@ -484,7 +484,7 @@ class Reshape(Layer):\n     This is a near direct port of the internal Numpy function\n     `_fix_unknown_dimension` in `numpy/core/src/multiarray/shape.c`\n \n-    Arguments:\n+    Args:\n       input_shape: Shape of array being reshaped\n       output_shape: Desired shape of the array with at most\n         a single -1 which indicates a dimension that should be\n@@ -564,7 +564,7 @@ class Permute(Layer):\n   # note: `None` is the batch dimension\n   ```\n \n-  Arguments:\n+  Args:\n     dims: Tuple of integers. Permutation pattern does not include the\n       samples dimension. Indexing starts at 1.\n       For instance, `(2, 1)` permutes the first and second dimensions\n@@ -614,7 +614,7 @@ class Flatten(Layer):\n   Note: If inputs are shaped `(batch,)` without a feature axis, then\n   flattening adds an extra channel dimension and output shape is `(batch, 1)`.\n \n-  Arguments:\n+  Args:\n     data_format: A string,\n       one of `channels_last` (default) or `channels_first`.\n       The ordering of the dimensions in the inputs.\n@@ -711,7 +711,7 @@ class RepeatVector(Layer):\n   # now: model.output_shape == (None, 3, 32)\n   ```\n \n-  Arguments:\n+  Args:\n     n: Integer, repetition factor.\n \n   Input shape:\n@@ -808,7 +808,7 @@ class Lambda(Layer):\n     In general, Lambda layers can be convenient for simple stateless\n     computation, but anything more complex should use a subclass Layer instead.\n \n-  Arguments:\n+  Args:\n     function: The function to be evaluated. Takes input tensor as first\n       argument.\n     output_shape: Expected output shape from function. This argument can be\n@@ -1100,7 +1100,7 @@ class Dense(Layer):\n   >>> model.output_shape\n   (None, 32)\n \n-  Arguments:\n+  Args:\n     units: Positive integer, dimensionality of the output space.\n     activation: Activation function to use.\n       If you don't specify anything, no activation is applied\n@@ -1237,7 +1237,7 @@ class Dense(Layer):\n class ActivityRegularization(Layer):\n   \"\"\"Layer that applies an update to the cost function based input activity.\n \n-  Arguments:\n+  Args:\n     l1: L1 regularization factor (positive float).\n     l2: L2 regularization factor (positive float).\n \n@@ -1608,7 +1608,7 @@ def _delegate_property(keras_tensor_cls, property_name):  # pylint: disable=inva\n   `InstanceProperty` layer to access the property on the represented\n   intermediate values in the model.\n \n-  Arguments:\n+  Args:\n     keras_tensor_cls: The KerasTensor subclass that should expose the property.\n     property_name: The name of the property to expose and delegate to the\n       represented (Composite)Tensor.\n@@ -1628,7 +1628,7 @@ def _delegate_method(keras_tensor_cls, method_name):  # pylint: disable=invalid-\n   an `InstanceMethod` layer to run the desired method on the represented\n   intermediate values in the model.\n \n-  Arguments:\n+  Args:\n     keras_tensor_cls: The KerasTensor subclass that should expose the property.\n     method_name: The name of the method to expose and delegate to the\n       represented (Composite)Tensor.\n\n@@ -34,7 +34,7 @@ from tensorflow.python.util.tf_export import keras_export\n class _CuDNNRNN(RNN):\n   \"\"\"Private base class for CuDNNGRU and CuDNNLSTM layers.\n \n-  Arguments:\n+  Args:\n     return_sequences: Boolean. Whether to return the last output\n         in the output sequence, or the full sequence.\n     return_state: Boolean. Whether to return the last state\n@@ -163,7 +163,7 @@ class CuDNNGRU(_CuDNNRNN):\n   developer website](https://developer.nvidia.com/cudnn).\n   Can only be run on GPU.\n \n-  Arguments:\n+  Args:\n       units: Positive integer, dimensionality of the output space.\n       kernel_initializer: Initializer for the `kernel` weights matrix, used for\n         the linear transformation of the inputs.\n@@ -343,7 +343,7 @@ class CuDNNLSTM(_CuDNNRNN):\n   developer website](https://developer.nvidia.com/cudnn).\n   Can only be run on GPU.\n \n-  Arguments:\n+  Args:\n       units: Positive integer, dimensionality of the output space.\n       kernel_initializer: Initializer for the `kernel` weights matrix, used for\n         the linear transformation of the inputs.\n\n@@ -44,7 +44,7 @@ class BaseDenseAttention(Layer):\n     dropout: Float between 0 and 1. Fraction of the units to drop for the\n       attention scores.\n \n-  Call Arguments:\n+  Call Args:\n \n     inputs: List of the following tensors:\n       * query: Query `Tensor` of shape `[batch_size, Tq, dim]`.\n@@ -236,7 +236,7 @@ class Attention(BaseDenseAttention):\n     dropout: Float between 0 and 1. Fraction of the units to drop for the\n       attention scores.\n \n-  Call Arguments:\n+  Call Args:\n \n     inputs: List of the following tensors:\n       * query: Query `Tensor` of shape `[batch_size, Tq, dim]`.\n@@ -375,7 +375,7 @@ class AdditiveAttention(BaseDenseAttention):\n     dropout: Float between 0 and 1. Fraction of the units to drop for the\n       attention scores.\n \n-  Call Arguments:\n+  Call Args:\n \n     inputs: List of the following tensors:\n       * query: Query `Tensor` of shape `[batch_size, Tq, dim]`.\n\n@@ -35,7 +35,7 @@ class EinsumDense(Layer):\n \n   This layer can perform einsum calculations of arbitrary dimensionality.\n \n-  Arguments:\n+  Args:\n     equation: An equation describing the einsum to perform. This equation must\n       be a valid einsum string of the form `ab,bc->ac`, `...ab,bc->...ac`, or\n       `ab...,bc->ac...` where 'ab', 'bc', and 'ac' can be any valid einsum axis\n\n@@ -54,7 +54,7 @@ class Embedding(Layer):\n   >>> print(output_array.shape)\n   (32, 10, 64)\n \n-  Arguments:\n+  Args:\n     input_dim: Integer. Size of the vocabulary,\n       i.e. maximum integer index + 1.\n     output_dim: Integer. Dimension of the dense embedding.\n\n@@ -115,7 +115,7 @@ class RandomFourierFeatures(base_layer.Layer):\n       ...)\n   ```\n \n-  Arguments:\n+  Args:\n     output_dim: Positive integer, the dimension of the layer's output, i.e., the\n       number of random features used to approximate the kernel.\n     kernel_initializer: Determines the distribution of the parameters of the\n\n@@ -330,6 +330,12 @@ class RNNCell(base_layer.Layer):\n   def get_config(self):  # pylint: disable=useless-super-delegation\n     return super(RNNCell, self).get_config()\n \n+  @property\n+  def _use_input_spec_as_call_signature(self):\n+    # We do not store the shape information for the state argument in the call\n+    # function for legacy RNN cells, so do not generate an input signature.\n+    return False\n+\n \n class LayerRNNCell(RNNCell):\n   \"\"\"Subclass of RNNCells that act like proper `tf.Layer` objects.\n\n@@ -57,7 +57,7 @@ class LocallyConnected1D(Layer):\n       # now model.output_shape == (None, 6, 32)\n   ```\n \n-  Arguments:\n+  Args:\n       filters: Integer, the dimensionality of the output space (i.e. the number\n         of output filters in the convolution).\n       kernel_size: An integer or tuple/list of a single integer, specifying the\n@@ -349,7 +349,7 @@ class LocallyConnected2D(Layer):\n       # now model.output_shape == (None, 28, 28, 32)\n   ```\n \n-  Arguments:\n+  Args:\n       filters: Integer, the dimensionality of the output space (i.e. the number\n         of output filters in the convolution).\n       kernel_size: An integer or tuple/list of 2 integers, specifying the width\n@@ -651,7 +651,7 @@ def get_locallyconnected_mask(input_shape, kernel_shape, strides, padding,\n   to make it perform an unshared convolution with given `kernel_shape`,\n   `strides`, `padding` and `data_format`.\n \n-  Arguments:\n+  Args:\n     input_shape: tuple of size N: `(d_in1, ..., d_inN)` spatial shape of the\n       input.\n     kernel_shape: tuple of size N, spatial shape of the convolutional kernel /\n@@ -703,7 +703,7 @@ def local_conv_matmul(inputs, kernel, kernel_mask, output_shape):\n   (the remaining entries in `kernel`) weights. It also does the necessary\n   reshapes to make `inputs` and `kernel` 2-D and `output` (N+2)-D.\n \n-  Arguments:\n+  Args:\n       inputs: (N+2)-D tensor with shape `(batch_size, channels_in, d_in1, ...,\n         d_inN)` or `(batch_size, d_in1, ..., d_inN, channels_in)`.\n       kernel: the unshared weights for N-D convolution,\n@@ -748,7 +748,7 @@ def local_conv_sparse_matmul(inputs, kernel, kernel_idxs, kernel_shape,\n   values=kernel, dense_shape=kernel_shape)`, with `.` standing for\n   matrix-multiply. It also reshapes `inputs` to 2-D and `output` to (N+2)-D.\n \n-  Arguments:\n+  Args:\n       inputs: (N+2)-D tensor with shape `(batch_size, channels_in, d_in1, ...,\n         d_inN)` or `(batch_size, d_in1, ..., d_inN, channels_in)`.\n       kernel: a 1-D tensor with shape `(len(kernel_idxs),)` containing all the\n@@ -787,7 +787,7 @@ def make_2d(tensor, split_dim):\n   Dimensions before (excluding) and after (including) `split_dim` are grouped\n   together.\n \n-  Arguments:\n+  Args:\n     tensor: a tensor of shape `(d0, ..., d(N-1))`.\n     split_dim: an integer from 1 to N-1, index of the dimension to group\n       dimensions before (excluding) and after (including).\n\n@@ -38,7 +38,7 @@ class _Merge(Layer):\n   def __init__(self, **kwargs):\n     \"\"\"Intializes a Merge layer.\n \n-    Arguments:\n+    Args:\n       **kwargs: standard layer keyword arguments.\n     \"\"\"\n     super(_Merge, self).__init__(**kwargs)\n@@ -50,7 +50,7 @@ class _Merge(Layer):\n   def _compute_elemwise_op_output_shape(self, shape1, shape2):\n     \"\"\"Computes the shape of the resultant of an elementwise operation.\n \n-    Arguments:\n+    Args:\n         shape1: tuple or None. Shape of the first tensor\n         shape2: tuple or None. Shape of the second tensor\n \n@@ -476,7 +476,7 @@ class Concatenate(_Merge):\n             [15, 16, 17, 18, 19],\n             [25, 26, 27, 28, 29]]])>\n \n-    Arguments:\n+    Args:\n       axis: Axis along which to concatenate.\n       **kwargs: standard layer keyword arguments.\n     \"\"\"\n@@ -627,7 +627,7 @@ class Dot(_Merge):\n       array([[[260, 360],\n               [320, 445]]])>\n \n-    Arguments:\n+    Args:\n       axes: Integer or tuple of integers,\n         axis or axes along which to take the dot product. If a tuple, should\n         be two integers corresponding to the desired axis from the first input\n@@ -740,7 +740,7 @@ class Dot(_Merge):\n def add(inputs, **kwargs):\n   \"\"\"Functional interface to the `tf.keras.layers.Add` layer.\n \n-  Arguments:\n+  Args:\n       inputs: A list of input tensors (at least 2) with the same shape.\n       **kwargs: Standard layer keyword arguments.\n \n@@ -774,7 +774,7 @@ def add(inputs, **kwargs):\n def subtract(inputs, **kwargs):\n   \"\"\"Functional interface to the `Subtract` layer.\n \n-  Arguments:\n+  Args:\n       inputs: A list of input tensors (exactly 2).\n       **kwargs: Standard layer keyword arguments.\n \n@@ -803,7 +803,7 @@ def subtract(inputs, **kwargs):\n def multiply(inputs, **kwargs):\n   \"\"\"Functional interface to the `Multiply` layer.\n \n-  Arguments:\n+  Args:\n       inputs: A list of input tensors (at least 2).\n       **kwargs: Standard layer keyword arguments.\n \n@@ -835,7 +835,7 @@ def average(inputs, **kwargs):\n   >>> out = tf.keras.layers.Dense(4)(avg)\n   >>> model = tf.keras.models.Model(inputs=[input1, input2], outputs=out)\n \n-  Arguments:\n+  Args:\n       inputs: A list of input tensors (at least 2).\n       **kwargs: Standard layer keyword arguments.\n \n@@ -867,7 +867,7 @@ def maximum(inputs, **kwargs):\n   model = tf.keras.models.Model(inputs=[input1, input2], outputs=out)\n   ```\n \n-  Arguments:\n+  Args:\n       inputs: A list of input tensors (at least 2) of same shape.\n       **kwargs: Standard layer keyword arguments.\n \n@@ -885,7 +885,7 @@ def maximum(inputs, **kwargs):\n def minimum(inputs, **kwargs):\n   \"\"\"Functional interface to the `Minimum` layer.\n \n-  Arguments:\n+  Args:\n       inputs: A list of input tensors (at least 2).\n       **kwargs: Standard layer keyword arguments.\n \n@@ -919,7 +919,7 @@ def concatenate(inputs, axis=-1, **kwargs):\n         [15, 16, 17, 18, 19],\n         [25, 26, 27, 28, 29]]])>\n \n-  Arguments:\n+  Args:\n       inputs: A list of input tensors (at least 2).\n       axis: Concatenation axis.\n       **kwargs: Standard layer keyword arguments.\n@@ -934,7 +934,7 @@ def concatenate(inputs, axis=-1, **kwargs):\n def dot(inputs, axes, normalize=False, **kwargs):\n   \"\"\"Functional interface to the `Dot` layer.\n \n-  Arguments:\n+  Args:\n       inputs: A list of input tensors (at least 2).\n       axes: Integer or tuple of integers,\n           axis or axes along which to take the dot product.\n\n@@ -165,7 +165,7 @@ class MultiHeadAttention(Layer):\n   >>> print(output_tensor.shape)\n   (None, 5, 3, 4, 16)\n \n-  Arguments:\n+  Args:\n     num_heads: Number of attention heads.\n     key_dim: Size of each attention head for query and key.\n     value_dim:  Size of each attention head for value.\n\n@@ -39,7 +39,7 @@ class GaussianNoise(Layer):\n \n   As it is a regularization layer, it is only active at training time.\n \n-  Arguments:\n+  Args:\n     stddev: Float, standard deviation of the noise distribution.\n \n   Call arguments:\n@@ -88,7 +88,7 @@ class GaussianDropout(Layer):\n \n   As it is a regularization layer, it is only active at training time.\n \n-  Arguments:\n+  Args:\n     rate: Float, drop probability (as with `Dropout`).\n       The multiplicative noise will have\n       standard deviation `sqrt(rate / (1 - rate))`.\n@@ -146,7 +146,7 @@ class AlphaDropout(Layer):\n   Alpha Dropout fits well to Scaled Exponential Linear Units\n   by randomly setting activations to the negative saturation value.\n \n-  Arguments:\n+  Args:\n     rate: float, drop probability (as with `Dropout`).\n       The multiplicative noise will have\n       standard deviation `sqrt(rate / (1 - rate))`.\n\n@@ -72,7 +72,7 @@ class BatchNormalizationBase(Layer):\n   *after having been trained on data that has similar statistics as the\n   inference data*.\n \n-  Arguments:\n+  Args:\n     axis: Integer or a list of integers, the axis that should be normalized\n     (typically the features axis). For instance, after a `Conv2D` layer with\n       `data_format=\"channels_first\"`, set `axis=1` in `BatchNormalization`.\n@@ -1055,7 +1055,7 @@ class LayerNormalization(Layer):\n   So, this Layer Normalization implementation will not match a Group\n   Normalization layer with group size set to 1.\n \n-  Arguments:\n+  Args:\n     axis: Integer or List/Tuple. The axis or axes to normalize across. Typically\n       this is the features axis/axes. The left-out axes are typically the batch\n       axis/axes. This argument defaults to `-1`, the last dimension in the\n\n@@ -51,7 +51,7 @@ class SyncBatchNormalization(normalization.BatchNormalizationBase):\n     model.add(tf.keras.layers.experimental.SyncBatchNormalization())\n   ```\n \n-  Arguments:\n+  Args:\n     axis: Integer, the axis that should be normalized\n       (typically the features axis).\n       For instance, after a `Conv2D` layer with\n@@ -224,7 +224,7 @@ class BatchNormalization(normalization.BatchNormalizationBase):\n   *after having been trained on data that has similar statistics as the\n   inference data*.\n \n-  Arguments:\n+  Args:\n     axis: Integer, the axis that should be normalized (typically the features\n       axis). For instance, after a `Conv2D` layer with\n       `data_format=\"channels_first\"`, set `axis=1` in `BatchNormalization`.\n\n@@ -24,7 +24,7 @@ import tensorflow as tf\n def dense(inputs, kernel, bias=None, activation=None, dtype=None):\n   \"\"\"Densely connected NN layer op.\n \n-  Arguments:\n+  Args:\n     inputs: `tf.Tensor` or `tf.SparseTensor`. Inputs to operation.\n     kernel: `tf.Variable`. Matrix kernel.\n     bias: (Optional) `tf.Variable`. Bias to add to outputs.\n\n@@ -33,7 +33,7 @@ class Pooling1D(Layer):\n \n   This class only exists for code reuse. It will never be an exposed API.\n \n-  Arguments:\n+  Args:\n     pool_function: The pooling function to apply, e.g. `tf.nn.max_pool2d`.\n     pool_size: An integer or tuple/list of a single integer,\n       representing the size of the pooling window.\n@@ -155,7 +155,7 @@ class MaxPooling1D(Pooling1D):\n           [5.],\n           [5.]]], dtype=float32)>\n \n-  Arguments:\n+  Args:\n     pool_size: Integer, size of the max pooling window.\n     strides: Integer, or None. Specifies how much the pooling window moves\n       for each pooling step.\n@@ -201,7 +201,7 @@ class MaxPooling1D(Pooling1D):\n class AveragePooling1D(Pooling1D):\n   \"\"\"Average pooling for temporal data.\n \n-  Arguments:\n+  Args:\n     pool_size: Integer, size of the average pooling windows.\n     strides: Integer, or None. Factor by which to downscale.\n       E.g. 2 will halve the input.\n@@ -247,7 +247,7 @@ class Pooling2D(Layer):\n \n   This class only exists for code reuse. It will never be an exposed API.\n \n-  Arguments:\n+  Args:\n     pool_function: The pooling function to apply, e.g. `tf.nn.max_pool2d`.\n     pool_size: An integer or tuple/list of 2 integers: (pool_height, pool_width)\n       specifying the size of the pooling window.\n@@ -411,7 +411,7 @@ class MaxPooling2D(Pooling2D):\n              [9.],\n              [9.]]]], dtype=float32)>\n \n-  Arguments:\n+  Args:\n     pool_size: integer or tuple of 2 integers,\n       window size over which to take the maximum.\n       `(2, 2)` will take the max value over a 2x2 pooling window.\n@@ -468,7 +468,7 @@ class MaxPooling2D(Pooling2D):\n class AveragePooling2D(Pooling2D):\n   \"\"\"Average pooling operation for spatial data.\n \n-  Arguments:\n+  Args:\n     pool_size: integer or tuple of 2 integers,\n       factors by which to downscale (vertical, horizontal).\n       `(2, 2)` will halve the input in both spatial dimension.\n@@ -522,7 +522,7 @@ class Pooling3D(Layer):\n \n   This class only exists for code reuse. It will never be an exposed API.\n \n-  Arguments:\n+  Args:\n     pool_function: The pooling function to apply, e.g. `tf.nn.max_pool2d`.\n     pool_size: An integer or tuple/list of 3 integers:\n       (pool_depth, pool_height, pool_width)\n@@ -617,7 +617,7 @@ class Pooling3D(Layer):\n class MaxPooling3D(Pooling3D):\n   \"\"\"Max pooling operation for 3D data (spatial or spatio-temporal).\n \n-  Arguments:\n+  Args:\n     pool_size: Tuple of 3 integers,\n       factors by which to downscale (dim1, dim2, dim3).\n       `(2, 2, 2)` will halve the size of the 3D input in each dimension.\n@@ -670,7 +670,7 @@ class MaxPooling3D(Pooling3D):\n class AveragePooling3D(Pooling3D):\n   \"\"\"Average pooling operation for 3D data (spatial or spatio-temporal).\n \n-  Arguments:\n+  Args:\n     pool_size: tuple of 3 integers,\n       factors by which to downscale (dim1, dim2, dim3).\n       `(2, 2, 2)` will halve the size of the 3D input in each dimension.\n@@ -756,7 +756,7 @@ class GlobalAveragePooling1D(GlobalPooling1D):\n   >>> print(y.shape)\n   (2, 4)\n \n-  Arguments:\n+  Args:\n     data_format: A string,\n       one of `channels_last` (default) or `channels_first`.\n       The ordering of the dimensions in the inputs.\n@@ -826,7 +826,7 @@ class GlobalMaxPooling1D(GlobalPooling1D):\n          [6.],\n          [9.], dtype=float32)>\n \n-  Arguments:\n+  Args:\n     data_format: A string,\n       one of `channels_last` (default) or `channels_first`.\n       The ordering of the dimensions in the inputs.\n@@ -890,7 +890,7 @@ class GlobalAveragePooling2D(GlobalPooling2D):\n   >>> print(y.shape)\n   (2, 3)\n \n-  Arguments:\n+  Args:\n       data_format: A string,\n         one of `channels_last` (default) or `channels_first`.\n         The ordering of the dimensions in the inputs.\n@@ -931,7 +931,7 @@ class GlobalMaxPooling2D(GlobalPooling2D):\n   >>> print(y.shape)\n   (2, 3)\n \n-  Arguments:\n+  Args:\n     data_format: A string,\n       one of `channels_last` (default) or `channels_first`.\n       The ordering of the dimensions in the inputs.\n@@ -989,7 +989,7 @@ class GlobalPooling3D(Layer):\n class GlobalAveragePooling3D(GlobalPooling3D):\n   \"\"\"Global Average pooling operation for 3D data.\n \n-  Arguments:\n+  Args:\n     data_format: A string,\n       one of `channels_last` (default) or `channels_first`.\n       The ordering of the dimensions in the inputs.\n@@ -1024,7 +1024,7 @@ class GlobalAveragePooling3D(GlobalPooling3D):\n class GlobalMaxPooling3D(GlobalPooling3D):\n   \"\"\"Global Max pooling operation for 3D data.\n \n-  Arguments:\n+  Args:\n     data_format: A string,\n       one of `channels_last` (default) or `channels_first`.\n       The ordering of the dimensions in the inputs.\n\n@@ -55,7 +55,7 @@ class CategoryCrossing(base_preprocessing_layer.PreprocessingLayer):\n            [b'b-e'],\n            [b'c-f']], dtype=object)>\n \n-  Arguments:\n+  Args:\n     depth: depth of input crossing. By default None, all inputs are crossed into\n       one output. It can also be an int or tuple/list of ints. Passing an\n       integer will create combinations of crossed outputs with depth up to that\n\n@@ -88,7 +88,7 @@ class CategoryEncoding(base_preprocessing_layer.CombinerPreprocessingLayer):\n            [0. , 0.2, 0.3, 0. ],\n            [0. , 0.2, 0. , 0.4]])>\n \n-  Arguments:\n+  Args:\n     max_tokens: The maximum size of the vocabulary for this layer. If None,\n       there is no cap on the size of the vocabulary.\n     output_mode: Specification for the output of the layer.\n@@ -181,7 +181,7 @@ class CategoryEncoding(base_preprocessing_layer.CombinerPreprocessingLayer):\n     Overrides the default adapt method to apply relevant preprocessing to the\n     inputs before passing to the combiner.\n \n-    Arguments:\n+    Args:\n       data: The data to train on. It can be passed either as a tf.data Dataset,\n         or as a numpy array.\n       reset_state: Optional argument specifying whether to clear the state of\n\n@@ -45,7 +45,7 @@ def summarize(values, epsilon):\n   If the target num_bins is larger than the size of values, the whole array is\n   returned (with weights of 1).\n \n-  Arguments:\n+  Args:\n       values: 1-D `np.ndarray` to be summarized.\n       epsilon: A `'float32'` that determines the approxmiate desired precision.\n \n@@ -77,7 +77,7 @@ def compress(summary, epsilon):\n   Taking the difference of the cumulative weights from the previous bin's\n   cumulative weight will give the new weight for that bin.\n \n-  Arguments:\n+  Args:\n       summary: 2-D `np.ndarray` summary to be compressed.\n       epsilon: A `'float32'` that determines the approxmiate desired precision.\n \n@@ -105,7 +105,7 @@ def merge_summaries(prev_summary, next_summary, epsilon):\n   Given two summaries of distinct data, this function merges (and compresses)\n   them to stay within `epsilon` error tolerance.\n \n-  Arguments:\n+  Args:\n       prev_summary: 2-D `np.ndarray` summary to be merged with `next_summary`.\n       next_summary: 2-D `np.ndarray` summary to be merged with `prev_summary`.\n       epsilon: A `'float32'` that determines the approxmiate desired precision.\n\n@@ -103,7 +103,7 @@ class Hashing(base_preprocessing_layer.PreprocessingLayer):\n \n   Reference: [SipHash with salt](https://www.131002.net/siphash/siphash.pdf)\n \n-  Arguments:\n+  Args:\n     num_bins: Number of hash bins.\n     salt: A single unsigned integer or None.\n       If passed, the hash function used will be SipHash64, with these values\n\n@@ -64,7 +64,7 @@ class Resizing(PreprocessingLayer):\n   Resize the batched image input to target height and width. The input should\n   be a 4-D tensor in the format of NHWC.\n \n-  Arguments:\n+  Args:\n     height: Integer, the height of the output shape.\n     width: Integer, the width of the output shape.\n     interpolation: String, the interpolation method. Defaults to `bilinear`.\n@@ -124,7 +124,7 @@ class CenterCrop(PreprocessingLayer):\n   If the input height/width is even and the target height/width is odd (or\n   inversely), the input image is left-padded by 1 pixel.\n \n-  Arguments:\n+  Args:\n     height: Integer, the height of the output shape.\n     width: Integer, the width of the output shape.\n     name: A string, the name of the layer.\n@@ -196,7 +196,7 @@ class RandomCrop(PreprocessingLayer):\n     4D tensor with shape:\n     `(samples, target_height, target_width, channels)`.\n \n-  Arguments:\n+  Args:\n     height: Integer, the height of the output shape.\n     width: Integer, the width of the output shape.\n     seed: Integer. Used to create a random seed.\n@@ -305,7 +305,7 @@ class Rescaling(PreprocessingLayer):\n   Output shape:\n     Same as input.\n \n-  Arguments:\n+  Args:\n     scale: Float, the scale to apply to the inputs.\n     offset: Float, the offset to apply to the inputs.\n     name: A string, the name of the layer.\n@@ -425,7 +425,7 @@ class RandomFlip(PreprocessingLayer):\n class RandomTranslation(PreprocessingLayer):\n   \"\"\"Randomly translate each image during training.\n \n-  Arguments:\n+  Args:\n     height_factor: a float represented as fraction of value, or a tuple\n       of size 2 representing lower and upper bound for shifting vertically.\n       A negative value means shifting image up, while a positive value\n@@ -877,7 +877,7 @@ class RandomRotation(PreprocessingLayer):\n class RandomZoom(PreprocessingLayer):\n   \"\"\"Randomly zoom each image during training.\n \n-  Arguments:\n+  Args:\n     height_factor: a float represented as fraction of value, or a tuple\n       of size 2 representing lower and upper bound for zooming vertically.\n       When represented as a single float, this value is used for both the\n@@ -1154,7 +1154,7 @@ class RandomHeight(PreprocessingLayer):\n \n   By default, this layer is inactive during inference.\n \n-  Arguments:\n+  Args:\n     factor: A positive float (fraction of original height), or a tuple of size 2\n       representing lower and upper bound for resizing vertically. When\n       represented as a single float, this value is used for both the upper and\n@@ -1253,7 +1253,7 @@ class RandomWidth(PreprocessingLayer):\n \n   By default, this layer is inactive during inference.\n \n-  Arguments:\n+  Args:\n     factor: A positive float (fraction of original height), or a tuple of size 2\n       representing lower and upper bound for resizing vertically. When\n       represented as a single float, this value is used for both the upper and\n\n@@ -60,7 +60,7 @@ class IndexLookup(base_preprocessing_layer.CombinerPreprocessingLayer):\n   vocabulary size, the most frequent terms will be used to create the\n   vocabulary.\n \n-  Arguments:\n+  Args:\n     max_tokens: The maximum size of the vocabulary for this layer. If None,\n       there is no cap on the size of the vocabulary. Note that this vocabulary\n       includes the OOV and mask tokens, so the effective number of tokens is\n@@ -209,7 +209,7 @@ class IndexLookup(base_preprocessing_layer.CombinerPreprocessingLayer):\n     Overrides the default adapt method to apply relevant preprocessing to the\n     inputs before passing to the combiner.\n \n-    Arguments:\n+    Args:\n       data: The data to train on. It can be passed either as a tf.data Dataset,\n         or as a numpy array.\n       reset_state: Optional argument specifying whether to clear the state of\n@@ -389,7 +389,7 @@ class IndexLookup(base_preprocessing_layer.CombinerPreprocessingLayer):\n     information is already known. If vocabulary data is already present in the\n     layer, this method will either replace it\n \n-    Arguments:\n+    Args:\n       vocab: An array of hashable tokens.\n \n     Raises:\n\n@@ -40,7 +40,7 @@ class IntegerLookup(index_lookup.IndexLookup):\n   vocabulary size, the most frequent values will be used to create the\n   vocabulary (and the values that don't make the cut will be treated as OOV).\n \n-  Arguments:\n+  Args:\n     max_values: The maximum size of the vocabulary for this layer. If None,\n       there is no cap on the size of the vocabulary. Note that this vocabulary\n       includes the OOV and mask values, so the effective number of values is\n\n@@ -53,7 +53,7 @@ class Normalization(base_preprocessing_layer.CombinerPreprocessingLayer):\n     as the layer's weights. `adapt` should be called before `fit`, `evaluate`,\n     or `predict`.\n \n-  Arguments:\n+  Args:\n       axis: Integer or tuple of integers, the axis or axes that should be\n         \"kept\". These axes are not be summed over when calculating the\n         normalization statistics. By default the last axis, the `features` axis\n\n@@ -35,7 +35,7 @@ class PreprocessingStage(base_preprocessing_layer.PreprocessingLayer,\n   Sequential-like object that enables you to `adapt()` the whole list via\n   a single `adapt()` call on the preprocessing stage.\n \n-  Arguments:\n+  Args:\n     layers: List of layers. Can include layers that aren't preprocessing layers.\n     name: String. Optional name for the preprocessing stage object.\n   \"\"\"\n@@ -43,7 +43,7 @@ class PreprocessingStage(base_preprocessing_layer.PreprocessingLayer,\n   def adapt(self, data, reset_state=True):\n     \"\"\"Adapt the state of the layers of the preprocessing stage to the data.\n \n-    Arguments:\n+    Args:\n       data: A batched Dataset object, or a NumPy array, or an EagerTensor.\n         Data to be iterated over to adapt the state of the layers in this\n         preprocessing stage.\n@@ -123,7 +123,7 @@ class FunctionalPreprocessingStage(base_preprocessing_layer.PreprocessingLayer,\n   >>> outputs = [inputs['x1'], [y, z]]\n   >>> stage = FunctionalPreprocessingStage(inputs, outputs)\n \n-  Arguments:\n+  Args:\n     inputs: An input tensor (must be created via `tf.keras.Input()`), or a list,\n       a dict, or a nested strcture of input tensors.\n     outputs: An output tensor, or a list, a dict or a nested structure of output\n@@ -140,7 +140,7 @@ class FunctionalPreprocessingStage(base_preprocessing_layer.PreprocessingLayer,\n   def adapt(self, data, reset_state=True):\n     \"\"\"Adapt the state of the layers of the preprocessing stage to the data.\n \n-    Arguments:\n+    Args:\n       data: A batched Dataset object, a NumPy array, an EagerTensor, or a list,\n         dict or nested structure of Numpy Arrays or EagerTensors. The elements\n         of Dataset object need to conform with inputs of the stage. The first\n@@ -240,7 +240,7 @@ class FunctionalPreprocessingStage(base_preprocessing_layer.PreprocessingLayer,\n def _unzip_dataset(ds):\n   \"\"\"Unzip dataset into a list of single element datasets.\n \n-  Arguments:\n+  Args:\n     ds: A Dataset object.\n \n   Returns:\n\n@@ -48,7 +48,7 @@ class Reduction(Layer):\n   This layer performs a reduction across one axis of its input data. This\n   data may optionally be weighted by passing in an identical float tensor.\n \n-  Arguments:\n+  Args:\n     reduction: The type of reduction to perform. Can be one of the following:\n       \"max\", \"mean\", \"min\", \"prod\", or \"sum\". This layer uses the Tensorflow\n       reduce op which corresponds to that reduction (so, for \"mean\", we use\n\n@@ -40,7 +40,7 @@ class StringLookup(index_lookup.IndexLookup):\n   vocabulary size, the most frequent terms will be used to create the\n   vocabulary (and the terms that don't make the cut will be treated as OOV).\n \n-  Arguments:\n+  Args:\n     max_tokens: The maximum size of the vocabulary for this layer. If None,\n       there is no cap on the size of the vocabulary. Note that this vocabulary\n       includes the OOV and mask tokens, so the effective number of tokens is\n\n@@ -108,7 +108,7 @@ class TextVectorization(base_preprocessing_layer.CombinerPreprocessingLayer):\n        [\"another\", \"string\", \"to\", \"split\"]]`. This makes the callable site\n        natively compatible with `tf.strings.split()`.\n \n-  Arguments:\n+  Args:\n     max_tokens: The maximum size of the vocabulary for this layer. If None,\n       there is no cap on the size of the vocabulary. Note that this vocabulary\n       contains 1 OOV token, so the effective number of tokens is `(max_tokens -\n@@ -390,7 +390,7 @@ class TextVectorization(base_preprocessing_layer.CombinerPreprocessingLayer):\n     Overrides the default adapt method to apply relevant preprocessing to the\n     inputs before passing to the combiner.\n \n-    Arguments:\n+    Args:\n       data: The data to train on. It can be passed either as a tf.data Dataset,\n         as a NumPy array, a string tensor, or as a list of texts.\n       reset_state: Optional argument specifying whether to clear the state of\n@@ -475,7 +475,7 @@ class TextVectorization(base_preprocessing_layer.CombinerPreprocessingLayer):\n     vocabulary data is already present in the layer, this method will replace\n     it.\n \n-    Arguments:\n+    Args:\n       vocab: An array of string tokens, or a path to a file containing one\n         token per line.\n       df_data: An array of document frequency data. Only necessary if the layer\n\n@@ -54,7 +54,7 @@ class StackedRNNCells(Layer):\n \n   Used to implement efficient stacked RNNs.\n \n-  Arguments:\n+  Args:\n     cells: List of RNN cell instances.\n \n   Examples:\n@@ -197,7 +197,7 @@ class RNN(Layer):\n   See [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)\n   for details about the usage of RNN API.\n \n-  Arguments:\n+  Args:\n     cell: A RNN cell instance or a list of RNN cell instances.\n       A RNN cell is a class that has:\n       - A `call(input_at_t, states_at_t)` method, returning\n@@ -1232,7 +1232,7 @@ class SimpleRNNCell(DropoutRNNCellMixin, Layer):\n   This class processes one step within the whole time sequence input, whereas\n   `tf.keras.layer.SimpleRNN` processes the whole sequence.\n \n-  Arguments:\n+  Args:\n     units: Positive integer, dimensionality of the output space.\n     activation: Activation function to use.\n       Default: hyperbolic tangent (`tanh`).\n@@ -1431,7 +1431,7 @@ class SimpleRNN(RNN):\n   See [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)\n   for details about the usage of RNN API.\n \n-  Arguments:\n+  Args:\n     units: Positive integer, dimensionality of the output space.\n     activation: Activation function to use.\n       Default: hyperbolic tangent (`tanh`).\n@@ -1682,7 +1682,7 @@ class SimpleRNN(RNN):\n class GRUCell(DropoutRNNCellMixin, Layer):\n   \"\"\"Cell class for the GRU layer.\n \n-  Arguments:\n+  Args:\n     units: Positive integer, dimensionality of the output space.\n     activation: Activation function to use.\n       Default: hyperbolic tangent (`tanh`).\n@@ -1966,7 +1966,7 @@ class GRU(RNN):\n   `recurrent_kernel`. Use `'reset_after'=True` and\n   `recurrent_activation='sigmoid'`.\n \n-  Arguments:\n+  Args:\n     units: Positive integer, dimensionality of the output space.\n     activation: Activation function to use.\n       Default: hyperbolic tangent (`tanh`).\n@@ -2236,7 +2236,7 @@ class GRU(RNN):\n class LSTMCell(DropoutRNNCellMixin, Layer):\n   \"\"\"Cell class for the LSTM layer.\n \n-  Arguments:\n+  Args:\n     units: Positive integer, dimensionality of the output space.\n     activation: Activation function to use.\n       Default: hyperbolic tangent (`tanh`).\n@@ -2639,7 +2639,7 @@ class LSTM(RNN):\n    Note that this cell is not optimized for performance on GPU. Please use\n   `tf.compat.v1.keras.layers.CuDNNLSTM` for better performance on GPU.\n \n-  Arguments:\n+  Args:\n     units: Positive integer, dimensionality of the output space.\n     activation: Activation function to use.\n       Default: hyperbolic tangent (`tanh`).\n@@ -2929,7 +2929,7 @@ def _standardize_args(inputs, initial_state, constants, num_constants):\n   makes sure the arguments are separated and that `initial_state` and\n   `constants` are lists of tensors (or None).\n \n-  Arguments:\n+  Args:\n     inputs: Tensor or list/tuple of tensors. which may include constants\n       and initial states. In that case `num_constant` must be specified.\n     initial_state: Tensor or list of tensors or None, initial states.\n\n@@ -120,7 +120,7 @@ class GRUCell(recurrent.GRUCell):\n   >>> print(final_state.shape)\n   (32, 4)\n \n-  Arguments:\n+  Args:\n     units: Positive integer, dimensionality of the output space.\n     activation: Activation function to use. Default: hyperbolic tangent\n       (`tanh`). If you pass None, no activation is applied\n@@ -253,7 +253,7 @@ class GRU(recurrent.DropoutRNNCellMixin, recurrent.GRU):\n   >>> print(final_state.shape)\n   (32, 4)\n \n-  Arguments:\n+  Args:\n     units: Positive integer, dimensionality of the output space.\n     activation: Activation function to use.\n       Default: hyperbolic tangent (`tanh`).\n@@ -553,7 +553,7 @@ def standard_gru(inputs, init_h, kernel, recurrent_kernel, bias, mask,\n   counterpart. The RNN step logic has been simplified, eg dropout and mask is\n   removed since CuDNN implementation does not support that.\n \n-  Arguments:\n+  Args:\n     inputs: Input tensor of GRU layer.\n     init_h: Initial state tensor for the cell output.\n     kernel: Weights for cell kernel.\n@@ -869,7 +869,7 @@ class LSTMCell(recurrent.LSTMCell):\n   >>> print(final_carry_state.shape)\n   (32, 4)\n \n-  Arguments:\n+  Args:\n     units: Positive integer, dimensionality of the output space.\n     activation: Activation function to use. Default: hyperbolic tangent\n       (`tanh`). If you pass `None`, no activation is applied (ie. \"linear\"\n@@ -995,7 +995,7 @@ class LSTM(recurrent.DropoutRNNCellMixin, recurrent.LSTM):\n   >>> print(final_carry_state.shape)\n   (32, 4)\n \n-  Arguments:\n+  Args:\n     units: Positive integer, dimensionality of the output space.\n     activation: Activation function to use.\n       Default: hyperbolic tangent (`tanh`). If you pass `None`, no activation\n\n@@ -161,7 +161,7 @@ def serialize(layer):\n def deserialize(config, custom_objects=None):\n   \"\"\"Instantiates a layer from a config dictionary.\n \n-  Arguments:\n+  Args:\n       config: dict of the form {'class_name': str, 'config': dict}\n       custom_objects: dict mapping class names (or function names)\n           of custom (non-Keras) objects to class/functions\n\n@@ -41,7 +41,7 @@ class Wrapper(Layer):\n   Do not use this class as a layer, it is only an abstract base class.\n   Two usable wrappers are the `TimeDistributed` and `Bidirectional` wrappers.\n \n-  Arguments:\n+  Args:\n     layer: The layer to be wrapped.\n   \"\"\"\n \n@@ -101,7 +101,7 @@ class TimeDistributed(Wrapper):\n   Because `TimeDistributed` applies the same instance of `Conv2D` to each of the\n   timestamps, the same set of weights are used at each timestamp.\n \n-  Arguments:\n+  Args:\n     layer: a `tf.keras.layers.Layer` instance.\n \n   Call arguments:\n@@ -138,7 +138,7 @@ class TimeDistributed(Wrapper):\n \n     The static shapes are replaced with the corresponding dynamic shapes of the\n     tensor.\n-    Arguments:\n+    Args:\n       init_tuple: a tuple, the first part of the output shape\n       tensor: the tensor from which to get the (static and dynamic) shapes\n         as the last part of the output shape\n@@ -306,7 +306,7 @@ class TimeDistributed(Wrapper):\n     (E.g., `mask` is not used at all)\n     Return `None`.\n \n-    Arguments:\n+    Args:\n       inputs: Tensor with shape [batch size, timesteps, ...] indicating the\n         input to TimeDistributed. If static shape information is available for\n         \"batch size\", `mask` is returned unmodified.\n@@ -380,7 +380,7 @@ class TimeDistributed(Wrapper):\n class Bidirectional(Wrapper):\n   \"\"\"Bidirectional wrapper for RNNs.\n \n-  Arguments:\n+  Args:\n     layer: `keras.layers.RNN` instance, such as `keras.layers.LSTM` or\n       `keras.layers.GRU`. It could also be a `keras.layers.Layer` instance\n       that meets the following criteria:\n\n@@ -156,7 +156,7 @@ class Layer(base_layer.Layer):\n   It is considered legacy, and we recommend the use of `tf.keras.layers.Layer`\n   instead.\n \n-  Arguments:\n+  Args:\n     trainable: Boolean, whether the layer's variables should be trainable.\n     name: String name of the layer.\n     dtype: Default dtype of the layer's weights (default of `None` means use the\n@@ -327,7 +327,7 @@ class Layer(base_layer.Layer):\n                  **kwargs):\n     \"\"\"Adds a new variable to the layer, or gets an existing one; returns it.\n \n-    Arguments:\n+    Args:\n       name: variable name.\n       shape: variable shape.\n       dtype: The type of the variable. Defaults to `self.dtype` or `float32`.\n@@ -482,7 +482,7 @@ class Layer(base_layer.Layer):\n   def __call__(self, inputs, *args, **kwargs):\n     \"\"\"Wraps `call`, applying pre- and post-processing steps.\n \n-    Arguments:\n+    Args:\n       inputs: input tensor(s).\n       *args: additional positional arguments to be passed to `self.call`.\n       **kwargs: additional keyword arguments to be passed to `self.call`.\n\n@@ -38,7 +38,7 @@ class Conv1D(keras_layers.Conv1D, base.Layer):\n   a bias vector is created and added to the outputs. Finally, if\n   `activation` is not `None`, it is applied to the outputs as well.\n \n-  Arguments:\n+  Args:\n     filters: Integer, the dimensionality of the output space (i.e. the number\n       of filters in the convolution).\n     kernel_size: An integer or tuple/list of a single integer, specifying the\n@@ -148,7 +148,7 @@ def conv1d(inputs,\n   a bias vector is created and added to the outputs. Finally, if\n   `activation` is not `None`, it is applied to the outputs as well.\n \n-  Arguments:\n+  Args:\n     inputs: Tensor input.\n     filters: Integer, the dimensionality of the output space (i.e. the number\n       of filters in the convolution).\n@@ -236,7 +236,7 @@ class Conv2D(keras_layers.Conv2D, base.Layer):\n   a bias vector is created and added to the outputs. Finally, if\n   `activation` is not `None`, it is applied to the outputs as well.\n \n-  Arguments:\n+  Args:\n     filters: Integer, the dimensionality of the output space (i.e. the number\n       of filters in the convolution).\n     kernel_size: An integer or tuple/list of 2 integers, specifying the\n@@ -353,7 +353,7 @@ def conv2d(inputs,\n   a bias vector is created and added to the outputs. Finally, if\n   `activation` is not `None`, it is applied to the outputs as well.\n \n-  Arguments:\n+  Args:\n     inputs: Tensor input.\n     filters: Integer, the dimensionality of the output space (i.e. the number\n       of filters in the convolution).\n@@ -448,7 +448,7 @@ class Conv3D(keras_layers.Conv3D, base.Layer):\n   a bias vector is created and added to the outputs. Finally, if\n   `activation` is not `None`, it is applied to the outputs as well.\n \n-  Arguments:\n+  Args:\n     filters: Integer, the dimensionality of the output space (i.e. the number\n       of filters in the convolution).\n     kernel_size: An integer or tuple/list of 3 integers, specifying the\n@@ -566,7 +566,7 @@ def conv3d(inputs,\n   a bias vector is created and added to the outputs. Finally, if\n   `activation` is not `None`, it is applied to the outputs as well.\n \n-  Arguments:\n+  Args:\n     inputs: Tensor input.\n     filters: Integer, the dimensionality of the output space (i.e. the number\n       of filters in the convolution).\n@@ -662,7 +662,7 @@ class SeparableConv1D(keras_layers.SeparableConv1D, base.Layer):\n   it adds a bias vector to the output.\n   It then optionally applies an activation function to produce the final output.\n \n-  Arguments:\n+  Args:\n     filters: Integer, the dimensionality of the output space (i.e. the number\n       of filters in the convolution).\n     kernel_size: A single integer specifying the spatial\n@@ -772,7 +772,7 @@ class SeparableConv2D(keras_layers.SeparableConv2D, base.Layer):\n   it adds a bias vector to the output.\n   It then optionally applies an activation function to produce the final output.\n \n-  Arguments:\n+  Args:\n     filters: Integer, the dimensionality of the output space (i.e. the number\n       of filters in the convolution).\n     kernel_size: A tuple or list of 2 integers specifying the spatial\n@@ -909,7 +909,7 @@ def separable_conv1d(inputs,\n   it adds a bias vector to the output.\n   It then optionally applies an activation function to produce the final output.\n \n-  Arguments:\n+  Args:\n     inputs: Input tensor.\n     filters: Integer, the dimensionality of the output space (i.e. the number\n       of filters in the convolution).\n@@ -1032,7 +1032,7 @@ def separable_conv2d(inputs,\n   it adds a bias vector to the output.\n   It then optionally applies an activation function to produce the final output.\n \n-  Arguments:\n+  Args:\n     inputs: Input tensor.\n     filters: Integer, the dimensionality of the output space (i.e. the number\n       of filters in the convolution).\n@@ -1139,7 +1139,7 @@ class Conv2DTranspose(keras_layers.Conv2DTranspose, base.Layer):\n   while maintaining a connectivity pattern that is compatible with\n   said convolution.\n \n-  Arguments:\n+  Args:\n     filters: Integer, the dimensionality of the output space (i.e. the number\n       of filters in the convolution).\n     kernel_size: A tuple or list of 2 positive integers specifying the spatial\n@@ -1244,7 +1244,7 @@ def conv2d_transpose(inputs,\n   while maintaining a connectivity pattern that is compatible with\n   said convolution.\n \n-  Arguments:\n+  Args:\n     inputs: Input tensor.\n     filters: Integer, the dimensionality of the output space (i.e. the number\n       of filters in the convolution).\n@@ -1321,7 +1321,7 @@ def conv2d_transpose(inputs,\n class Conv3DTranspose(keras_layers.Conv3DTranspose, base.Layer):\n   \"\"\"Transposed 3D convolution layer (sometimes called 3D Deconvolution).\n \n-  Arguments:\n+  Args:\n     filters: Integer, the dimensionality of the output space (i.e. the number\n       of filters in the convolution).\n     kernel_size: An integer or tuple/list of 3 integers, specifying the\n@@ -1423,7 +1423,7 @@ def conv3d_transpose(inputs,\n                      reuse=None):\n   \"\"\"Functional interface for transposed 3D convolution layer.\n \n-  Arguments:\n+  Args:\n     inputs: Input tensor.\n     filters: Integer, the dimensionality of the output space (i.e. the number\n       of filters in the convolution).\n\n@@ -41,7 +41,7 @@ class Dense(keras_layers.Dense, base.Layer):\n   and `bias` is a bias vector created by the layer\n   (only if `use_bias` is `True`).\n \n-  Arguments:\n+  Args:\n     units: Integer or Long, dimensionality of the output space.\n     activation: Activation function (callable). Set it to None to maintain a\n       linear activation.\n@@ -135,7 +135,7 @@ def dense(\n   and `bias` is a bias vector created by the layer\n   (only if `use_bias` is `True`).\n \n-  Arguments:\n+  Args:\n     inputs: Tensor input.\n     units: Integer or Long, dimensionality of the output space.\n     activation: Activation function (callable). Set it to None to maintain a\n@@ -198,7 +198,7 @@ class Dropout(keras_layers.Dropout, base.Layer):\n   The units that are kept are scaled by `1 / (1 - rate)`, so that their\n   sum is unchanged at training time and inference time.\n \n-  Arguments:\n+  Args:\n     rate: The dropout rate, between 0 and 1. E.g. `rate=0.1` would drop out\n       10% of input units.\n     noise_shape: 1D tensor of type `int32` representing the shape of the\n@@ -242,7 +242,7 @@ def dropout(inputs,\n   The units that are kept are scaled by `1 / (1 - rate)`, so that their\n   sum is unchanged at training time and inference time.\n \n-  Arguments:\n+  Args:\n     inputs: Tensor input.\n     rate: The dropout rate, between 0 and 1. E.g. \"rate=0.1\" would drop out\n       10% of input units.\n@@ -277,7 +277,7 @@ def dropout(inputs,\n class Flatten(keras_layers.Flatten, base.Layer):\n   \"\"\"Flattens an input tensor while preserving the batch axis (axis 0).\n \n-  Arguments:\n+  Args:\n     data_format: A string, one of `channels_last` (default) or `channels_first`.\n       The ordering of the dimensions in the inputs.\n       `channels_last` corresponds to inputs with shape\n@@ -303,7 +303,7 @@ class Flatten(keras_layers.Flatten, base.Layer):\n def flatten(inputs, name=None, data_format='channels_last'):\n   \"\"\"Flattens an input tensor while preserving the batch axis (axis 0).\n \n-  Arguments:\n+  Args:\n     inputs: Tensor input.\n     name: The name of the layer (string).\n     data_format: A string, one of `channels_last` (default) or `channels_first`.\n\n@@ -44,7 +44,7 @@ class BatchNormalization(keras_normalization.BatchNormalization, base.Layer):\n     train_op = tf.group([train_op, update_ops])\n   ```\n \n-  Arguments:\n+  Args:\n     axis: An `int` or list of `int`, the axis or axes that should be normalized,\n       typically the features axis/axes. For instance, after a `Conv2D` layer\n       with `data_format=\"channels_first\"`, set `axis=1`. If a list of axes is\n@@ -217,7 +217,7 @@ def batch_normalization(inputs,\n     train_op = tf.group([train_op, update_ops])\n   ```\n \n-  Arguments:\n+  Args:\n     inputs: Tensor input.\n     axis: An `int`, the axis that should be normalized (typically the features\n       axis). For instance, after a `Convolution2D` layer with\n\n@@ -30,7 +30,7 @@ from tensorflow.python.util.tf_export import tf_export\n class AveragePooling1D(keras_layers.AveragePooling1D, base.Layer):\n   \"\"\"Average Pooling layer for 1D inputs.\n \n-  Arguments:\n+  Args:\n     pool_size: An integer or tuple/list of a single integer,\n       representing the size of the pooling window.\n     strides: An integer or tuple/list of a single integer, specifying the\n@@ -65,7 +65,7 @@ def average_pooling1d(inputs, pool_size, strides,\n                       name=None):\n   \"\"\"Average Pooling layer for 1D inputs.\n \n-  Arguments:\n+  Args:\n     inputs: The tensor over which to pool. Must have rank 3.\n     pool_size: An integer or tuple/list of a single integer,\n       representing the size of the pooling window.\n@@ -101,7 +101,7 @@ def average_pooling1d(inputs, pool_size, strides,\n class MaxPooling1D(keras_layers.MaxPooling1D, base.Layer):\n   \"\"\"Max Pooling layer for 1D inputs.\n \n-  Arguments:\n+  Args:\n     pool_size: An integer or tuple/list of a single integer,\n       representing the size of the pooling window.\n     strides: An integer or tuple/list of a single integer, specifying the\n@@ -136,7 +136,7 @@ def max_pooling1d(inputs, pool_size, strides,\n                   name=None):\n   \"\"\"Max Pooling layer for 1D inputs.\n \n-  Arguments:\n+  Args:\n     inputs: The tensor over which to pool. Must have rank 3.\n     pool_size: An integer or tuple/list of a single integer,\n       representing the size of the pooling window.\n@@ -172,7 +172,7 @@ def max_pooling1d(inputs, pool_size, strides,\n class AveragePooling2D(keras_layers.AveragePooling2D, base.Layer):\n   \"\"\"Average pooling layer for 2D inputs (e.g. images).\n \n-  Arguments:\n+  Args:\n     pool_size: An integer or tuple/list of 2 integers: (pool_height, pool_width)\n       specifying the size of the pooling window.\n       Can be a single integer to specify the same value for\n@@ -208,7 +208,7 @@ def average_pooling2d(inputs,\n                       name=None):\n   \"\"\"Average pooling layer for 2D inputs (e.g. images).\n \n-  Arguments:\n+  Args:\n     inputs: The tensor over which to pool. Must have rank 4.\n     pool_size: An integer or tuple/list of 2 integers: (pool_height, pool_width)\n       specifying the size of the pooling window.\n@@ -246,7 +246,7 @@ def average_pooling2d(inputs,\n class MaxPooling2D(keras_layers.MaxPooling2D, base.Layer):\n   \"\"\"Max pooling layer for 2D inputs (e.g. images).\n \n-  Arguments:\n+  Args:\n     pool_size: An integer or tuple/list of 2 integers: (pool_height, pool_width)\n       specifying the size of the pooling window.\n       Can be a single integer to specify the same value for\n@@ -282,7 +282,7 @@ def max_pooling2d(inputs,\n                   name=None):\n   \"\"\"Max pooling layer for 2D inputs (e.g. images).\n \n-  Arguments:\n+  Args:\n     inputs: The tensor over which to pool. Must have rank 4.\n     pool_size: An integer or tuple/list of 2 integers: (pool_height, pool_width)\n       specifying the size of the pooling window.\n@@ -320,7 +320,7 @@ def max_pooling2d(inputs,\n class AveragePooling3D(keras_layers.AveragePooling3D, base.Layer):\n   \"\"\"Average pooling layer for 3D inputs (e.g. volumes).\n \n-  Arguments:\n+  Args:\n     pool_size: An integer or tuple/list of 3 integers:\n       (pool_depth, pool_height, pool_width)\n       specifying the size of the pooling window.\n@@ -358,7 +358,7 @@ def average_pooling3d(inputs,\n                       name=None):\n   \"\"\"Average pooling layer for 3D inputs (e.g. volumes).\n \n-  Arguments:\n+  Args:\n     inputs: The tensor over which to pool. Must have rank 5.\n     pool_size: An integer or tuple/list of 3 integers:\n       (pool_depth, pool_height, pool_width)\n@@ -398,7 +398,7 @@ def average_pooling3d(inputs,\n class MaxPooling3D(keras_layers.MaxPooling3D, base.Layer):\n   \"\"\"Max pooling layer for 3D inputs (e.g. volumes).\n \n-  Arguments:\n+  Args:\n     pool_size: An integer or tuple/list of 3 integers:\n       (pool_depth, pool_height, pool_width)\n       specifying the size of the pooling window.\n@@ -438,7 +438,7 @@ def max_pooling3d(inputs,\n \n   volumes).\n \n-  Arguments:\n+  Args:\n     inputs: The tensor over which to pool. Must have rank 5.\n     pool_size: An integer or tuple/list of 3 integers: (pool_depth, pool_height,\n       pool_width) specifying the size of the pooling window. Can be a single\n\n@@ -1832,7 +1832,7 @@ def is_categorical_crossentropy(loss):\n def serialize(loss):\n   \"\"\"Serializes loss function or `Loss` instance.\n \n-  Arguments:\n+  Args:\n     loss: A Keras `Loss` instance or a loss function.\n \n   Returns:\n@@ -1845,7 +1845,7 @@ def serialize(loss):\n def deserialize(name, custom_objects=None):\n   \"\"\"Deserializes a serialized loss class/function instance.\n \n-  Arguments:\n+  Args:\n       name: Loss configuration.\n       custom_objects: Optional dictionary mapping names (strings) to custom\n         objects (classes and functions) to be considered during deserialization.\n@@ -1883,7 +1883,7 @@ def get(identifier):\n   >>> type(loss)\n   <class '...tensorflow.python.keras.losses.CategoricalCrossentropy'>\n \n-  Arguments:\n+  Args:\n     identifier: A loss identifier. One of None or string name of a loss\n       function/class or loss configuration dictionary or a loss function or a\n       loss class instance\n\n@@ -3481,7 +3481,7 @@ def clone_metrics(metrics):\n def serialize(metric):\n   \"\"\"Serializes metric function or `Metric` instance.\n \n-  Arguments:\n+  Args:\n     metric: A Keras `Metric` instance or a metric function.\n \n   Returns:\n@@ -3494,7 +3494,7 @@ def serialize(metric):\n def deserialize(config, custom_objects=None):\n   \"\"\"Deserializes a serialized metric class/function instance.\n \n-  Arguments:\n+  Args:\n     config: Metric configuration.\n     custom_objects: Optional dictionary mapping names (strings) to custom\n       objects (classes and functions) to be considered during deserialization.\n@@ -3532,7 +3532,7 @@ def get(identifier):\n   >>> type(metric)\n   <class '...tensorflow.python.keras.metrics.CategoricalCrossentropy'>\n \n-  Arguments:\n+  Args:\n     identifier: A metric identifier. One of None or string name of a metric\n       function/class or metric configuration dictionary or a metric function or\n       a metric class instance\n\n@@ -138,7 +138,7 @@ def _clone_functional_model(model, input_tensors=None, layer_fn=_clone_layer):\n \n   Input layers are always cloned.\n \n-  Arguments:\n+  Args:\n       model: Instance of `Model`.\n       input_tensors: optional list of input tensors\n           to build the model upon. If not provided,\n@@ -286,7 +286,7 @@ def _clone_sequential_model(model, input_tensors=None, layer_fn=_clone_layer):\n   except that it creates new layers (and thus new weights) instead\n   of sharing the weights of the existing layers.\n \n-  Arguments:\n+  Args:\n       model: Instance of `Sequential`.\n       input_tensors: optional list of input tensors\n           to build the model upon. If not provided,\n@@ -392,7 +392,7 @@ def clone_model(model, input_tensors=None, clone_function=None):\n   except that it creates new layers (and thus new weights) instead\n   of sharing the weights of the existing layers.\n \n-  Arguments:\n+  Args:\n       model: Instance of `Model`\n           (could be a functional model or a Sequential model).\n       input_tensors: optional list of input tensors or InputLayer objects\n\n@@ -77,7 +77,7 @@ class Optimizer(object):\n   def get_gradients(self, loss, params):\n     \"\"\"Returns gradients of `loss` with respect to `params`.\n \n-    Arguments:\n+    Args:\n         loss: Loss tensor.\n         params: List of variables.\n \n@@ -110,7 +110,7 @@ class Optimizer(object):\n     Should only be called after computing the gradients\n     (otherwise the optimizer has no weights).\n \n-    Arguments:\n+    Args:\n         weights: a list of Numpy arrays. The number of arrays and their shape\n           must match number of the dimensions of the weights of the optimizer\n           (i.e. it should match the output of `get_weights`).\n@@ -161,7 +161,7 @@ class SGD(Optimizer):\n   Includes support for momentum,\n   learning rate decay, and Nesterov momentum.\n \n-  Arguments:\n+  Args:\n       lr: float >= 0. Learning rate.\n       momentum: float >= 0. Parameter that accelerates SGD in the relevant\n         direction and dampens oscillations.\n@@ -231,7 +231,7 @@ class RMSprop(Optimizer):\n   at their default values\n   (except the learning rate, which can be freely tuned).\n \n-  Arguments:\n+  Args:\n       lr: float >= 0. Learning rate.\n       rho: float >= 0.\n       epsilon: float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n@@ -458,7 +458,7 @@ class Adam(Optimizer):\n \n   Default parameters follow those provided in the original paper.\n \n-  Arguments:\n+  Args:\n       lr: float >= 0. Learning rate.\n       beta_1: float, 0 < beta < 1. Generally close to 1.\n       beta_2: float, 0 < beta < 1. Generally close to 1.\n@@ -557,7 +557,7 @@ class Adamax(Optimizer):\n   It is a variant of Adam based on the infinity norm.\n   Default parameters follow those provided in the paper.\n \n-  Arguments:\n+  Args:\n       lr: float >= 0. Learning rate.\n       beta_1/beta_2: floats, 0 < beta < 1. Generally close to 1.\n       epsilon: float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n@@ -649,7 +649,7 @@ class Nadam(Optimizer):\n   It is recommended to leave the parameters of this optimizer\n   at their default values.\n \n-  Arguments:\n+  Args:\n       lr: float >= 0. Learning rate.\n       beta_1/beta_2: floats, 0 < beta < 1. Generally close to 1.\n       epsilon: float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n\n@@ -105,7 +105,7 @@ class Adagrad(optimizer_v2.OptimizerV2):\n     capable of instantiating the same optimizer from the config\n     dictionary.\n \n-    Arguments:\n+    Args:\n         config: A Python dictionary, typically the output of get_config.\n         custom_objects: A Python dictionary mapping names to additional Python\n           objects used to create this optimizer, such as a function used for a\n\n@@ -723,7 +723,7 @@ class OptimizerV2(tf.__internal__.tracking.Trackable):\n \n     Should be used only in legacy v1 graph mode.\n \n-    Arguments:\n+    Args:\n       loss: Loss tensor.\n       params: List of variables.\n \n@@ -1022,7 +1022,7 @@ class OptimizerV2(tf.__internal__.tracking.Trackable):\n     capable of instantiating the same optimizer from the config\n     dictionary.\n \n-    Arguments:\n+    Args:\n         config: A Python dictionary, typically the output of get_config.\n         custom_objects: A Python dictionary mapping names to additional Python\n           objects used to create this optimizer, such as a function used for a\n@@ -1116,7 +1116,7 @@ class OptimizerV2(tf.__internal__.tracking.Trackable):\n     >>> opt.iterations\n     <tf.Variable 'RMSprop/iter:0' shape=() dtype=int64, numpy=10>\n \n-    Arguments:\n+    Args:\n         weights: weight values as a list of numpy arrays.\n     \"\"\"\n     params = self.weights\n\n@@ -51,7 +51,7 @@ def serialize(optimizer):\n def deserialize(config, custom_objects=None):\n   \"\"\"Inverse of the `serialize` function.\n \n-  Arguments:\n+  Args:\n       config: Optimizer configuration dictionary.\n       custom_objects: Optional dictionary mapping names (strings) to custom\n         objects (classes and functions) to be considered during deserialization.\n@@ -92,7 +92,7 @@ def deserialize(config, custom_objects=None):\n def get(identifier):\n   \"\"\"Retrieves a Keras Optimizer instance.\n \n-  Arguments:\n+  Args:\n       identifier: Optimizer identifier, one of\n           - String: name of an optimizer\n           - Dictionary: configuration dictionary. - Keras Optimizer instance (it\n\n@@ -129,7 +129,7 @@ def iter_valid_files(directory, follow_links, formats):\n def index_subdirectory(directory, class_indices, follow_links, formats):\n   \"\"\"Recursively walks directory and list image paths and their class index.\n \n-  Arguments:\n+  Args:\n     directory: string, target directory.\n     class_indices: dict mapping class names to their index.\n     follow_links: boolean, whether to recursively follow subdirectories\n\n@@ -92,7 +92,7 @@ def smart_resize(x, size, interpolation='bilinear'):\n   2. Resize the cropped image to the target size. In the example above,\n   we resize the `(340, 340)` crop to `(200, 200)`.\n \n-  Arguments:\n+  Args:\n     x: Input image (as a tensor or NumPy array). Must be in format\n       `(height, width, channels)`.\n     size: Tuple of `(height, width)` integer. Target size.\n@@ -158,7 +158,7 @@ def array_to_img(x, data_format=None, scale=True, dtype=None):\n   ```\n \n \n-  Arguments:\n+  Args:\n       x: Input Numpy array.\n       data_format: Image data format, can be either \"channels_first\" or\n         \"channels_last\". Defaults to `None`, in which case the global setting\n@@ -202,7 +202,7 @@ def img_to_array(img, data_format=None, dtype=None):\n   ```\n \n \n-  Arguments:\n+  Args:\n       img: Input PIL Image instance.\n       data_format: Image data format, can be either \"channels_first\" or\n         \"channels_last\". Defaults to `None`, in which case the global setting\n@@ -238,7 +238,7 @@ def save_img(path,\n              **kwargs):\n   \"\"\"Saves an image stored as a Numpy array to a path or file object.\n \n-  Arguments:\n+  Args:\n       path: Path or file object.\n       x: Numpy array.\n       data_format: Image data format,\n@@ -272,7 +272,7 @@ def load_img(path, grayscale=False, color_mode='rgb', target_size=None,\n   predictions = model.predict(input_arr)\n   ```\n \n-  Arguments:\n+  Args:\n       path: Path to image file.\n       grayscale: DEPRECATED use `color_mode=\"grayscale\"`.\n       color_mode: One of \"grayscale\", \"rgb\", \"rgba\". Default: \"rgb\".\n@@ -306,7 +306,7 @@ class Iterator(image.Iterator, data_utils.Sequence):\n class DirectoryIterator(image.DirectoryIterator, Iterator):\n   \"\"\"Iterator capable of reading images from a directory on disk.\n \n-  Arguments:\n+  Args:\n       directory: Path to the directory to read images from.\n           Each subdirectory in this directory will be\n           considered to contain images from one class,\n@@ -397,7 +397,7 @@ class DirectoryIterator(image.DirectoryIterator, Iterator):\n class NumpyArrayIterator(image.NumpyArrayIterator, Iterator):\n   \"\"\"Iterator yielding data from a Numpy array.\n \n-  Arguments:\n+  Args:\n       x: Numpy array of input data or tuple.\n           If tuple, the second elements is either\n           another numpy array or a list of numpy arrays,\n@@ -460,7 +460,7 @@ class NumpyArrayIterator(image.NumpyArrayIterator, Iterator):\n class DataFrameIterator(image.DataFrameIterator, Iterator):\n   \"\"\"Iterator capable of reading images from a directory on disk as a dataframe.\n \n-  Arguments:\n+  Args:\n       dataframe: Pandas dataframe containing the filepaths relative to\n         `directory` (or absolute paths if `directory` is None) of the images in\n         a string column. It should include other column/s\n@@ -580,7 +580,7 @@ class ImageDataGenerator(image.ImageDataGenerator):\n \n    The data will be looped over (in batches).\n \n-  Arguments:\n+  Args:\n       featurewise_center: Boolean.\n           Set input mean to 0 over the dataset, feature-wise.\n       samplewise_center: Boolean. Set each sample mean to 0.\n@@ -814,7 +814,7 @@ class ImageDataGenerator(image.ImageDataGenerator):\n            subset=None):\n     \"\"\"Takes data & label arrays, generates batches of augmented data.\n \n-    Arguments:\n+    Args:\n         x: Input data. Numpy array of rank 4 or a tuple. If tuple, the first\n           element should contain the images and the second element another numpy\n           array or a list of numpy arrays that gets passed to the output without\n@@ -878,7 +878,7 @@ class ImageDataGenerator(image.ImageDataGenerator):\n                           interpolation='nearest'):\n     \"\"\"Takes the path to a directory & generates batches of augmented data.\n \n-    Arguments:\n+    Args:\n         directory: string, path to the target directory. It should contain one\n           subdirectory per class. Any PNG, JPG, BMP, PPM or TIF images inside\n           each of the subdirectories directory tree will be included in the\n@@ -981,7 +981,7 @@ class ImageDataGenerator(image.ImageDataGenerator):\n     **A simple tutorial can be found **[here](\n                                 http://bit.ly/keras_flow_from_dataframe).\n \n-    Arguments:\n+    Args:\n         dataframe: Pandas dataframe containing the filepaths relative to\n           `directory` (or absolute paths if `directory` is None) of the images\n           in a string column. It should include other column/s\n\n@@ -65,7 +65,7 @@ def image_dataset_from_directory(directory,\n   Supported image formats: jpeg, png, bmp, gif.\n   Animated gifs are truncated to the first frame.\n \n-  Arguments:\n+  Args:\n     directory: Directory where the data is located.\n         If `labels` is \"inferred\", it should contain\n         subdirectories, each containing images for a class.\n\n@@ -132,7 +132,7 @@ def pad_sequences(sequences, maxlen=None, dtype='int32',\n          [2, 3],\n          [5, 6]], dtype=int32)\n \n-  Arguments:\n+  Args:\n       sequences: List of sequences (each sequence is a list of integers).\n       maxlen: Optional Int, maximum length of all sequences. If not provided,\n           sequences will be padded to the length of the longest individual\n\n@@ -42,7 +42,7 @@ def text_to_word_sequence(input_text,\n   >>> tf.keras.preprocessing.text.text_to_word_sequence(sample_text)\n   ['this', 'is', 'a', 'sample', 'sentence']\n \n-  Arguments:\n+  Args:\n       input_text: Input text (string).\n       filters: list (or concatenation) of characters to filter out, such as\n           punctuation. Default: ``'!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\\\t\\\\n'``,\n@@ -69,7 +69,7 @@ def one_hot(input_text,\n   list of encoded integers each corresponding to a word (or token)\n   in the given input string.\n \n-  Arguments:\n+  Args:\n       input_text: Input text (string).\n       n: int. Size of vocabulary.\n       filters: list (or concatenation) of characters to filter out, such as\n\n@@ -57,7 +57,7 @@ def text_dataset_from_directory(directory,\n \n   Only `.txt` files are supported at this time.\n \n-  Arguments:\n+  Args:\n     directory: Directory where the data is located.\n         If `labels` is \"inferred\", it should contain\n         subdirectories, each containing text files for a class.\n\n@@ -43,7 +43,7 @@ def timeseries_dataset_from_array(\n   length of the sequences/windows, spacing between two sequence/windows, etc.,\n   to produce batches of timeseries inputs and targets.\n \n-  Arguments:\n+  Args:\n     data: Numpy array or eager tensor\n       containing consecutive data points (timesteps).\n       Axis 0 is expected to be the time dimension.\n\n@@ -184,7 +184,7 @@ class Regularizer(object):\n     loading models to HDF5 formats, Keras model cloning, some visualization\n     utilities, and exporting models to and from JSON.\n \n-    Arguments:\n+    Args:\n         config: A Python dictionary, typically the output of get_config.\n \n     Returns:\n@@ -336,7 +336,7 @@ def l1_l2(l1=0.01, l2=0.01):  # pylint: disable=redefined-outer-name\n   The L2 regularization penalty is computed as:\n   `loss = l2 * reduce_sum(square(x))`\n \n-  Arguments:\n+  Args:\n       l1: Float; L1 regularization factor.\n       l2: Float; L2 regularization factor.\n \n\n@@ -66,7 +66,7 @@ def save_model_to_hdf5(model, filepath, overwrite=True, include_optimizer=True):\n   the exact same state, without any of the code\n   used for model definition or training.\n \n-  Arguments:\n+  Args:\n       model: Keras model instance to be saved.\n       filepath: One of the following:\n           - String, path where to save the model\n@@ -139,7 +139,7 @@ def save_model_to_hdf5(model, filepath, overwrite=True, include_optimizer=True):\n def load_model_from_hdf5(filepath, custom_objects=None, compile=True):  # pylint: disable=redefined-builtin\n   \"\"\"Loads a model saved via `save_model_to_hdf5`.\n \n-  Arguments:\n+  Args:\n       filepath: One of the following:\n           - String, path to the saved model\n           - `h5py.File` object from which to load the model\n@@ -237,7 +237,7 @@ def preprocess_weights_for_loading(layer,\n   Converts layers weights from Keras 1 format to Keras 2 and also weights of\n   CuDNN layers in Keras 2.\n \n-  Arguments:\n+  Args:\n       layer: Layer instance.\n       weights: List of weights values (Numpy arrays).\n       original_keras_version: Keras version for the weights, as a string.\n@@ -253,7 +253,7 @@ def preprocess_weights_for_loading(layer,\n     This function uses `preprocess_weights_for_loading()` for converting\n     layers.\n \n-    Arguments:\n+    Args:\n         weights: List of weights values (Numpy arrays).\n \n     Returns:\n@@ -274,7 +274,7 @@ def preprocess_weights_for_loading(layer,\n     This function uses `preprocess_weights_for_loading()` for converting nested\n     layers.\n \n-    Arguments:\n+    Args:\n         weights: List of weights values (Numpy arrays).\n \n     Returns:\n@@ -289,7 +289,7 @@ def preprocess_weights_for_loading(layer,\n     This function uses `preprocess_weights_for_loading()` for converting nested\n     layers.\n \n-    Arguments:\n+    Args:\n         weights: List of weights values (Numpy arrays).\n \n     Returns:\n@@ -427,7 +427,7 @@ def _convert_rnn_weights(layer, weights):\n \n   For missing biases in `LSTM`/`GRU` (`use_bias=False`) no conversion is made.\n \n-  Arguments:\n+  Args:\n       layer: Target layer instance.\n       weights: List of source weights values (input kernels, recurrent\n           kernels, [biases]) (Numpy arrays).\n@@ -442,7 +442,7 @@ def _convert_rnn_weights(layer, weights):\n   def transform_kernels(kernels, func, n_gates):\n     \"\"\"Transforms kernel for each gate separately using given function.\n \n-    Arguments:\n+    Args:\n         kernels: Stacked array of kernels for individual gates.\n         func: Function applied to kernel of each gate.\n         n_gates: Number of gates (4 for LSTM, 3 for GRU).\n@@ -465,7 +465,7 @@ def _convert_rnn_weights(layer, weights):\n \n     It can be passed to `transform_kernels()`.\n \n-    Arguments:\n+    Args:\n         from_cudnn: `True` if source weights are in CuDNN format, `False`\n             if they're in plain Keras format.\n \n@@ -501,7 +501,7 @@ def _convert_rnn_weights(layer, weights):\n     def convert_lstm_weights(weights, from_cudnn=True):\n       \"\"\"Converts the weights between CuDNNLSTM and LSTM.\n \n-      Arguments:\n+      Args:\n         weights: Original weights.\n         from_cudnn: Indicates whether original weights are from CuDNN layer.\n \n@@ -538,7 +538,7 @@ def _convert_rnn_weights(layer, weights):\n     def convert_gru_weights(weights, from_cudnn=True):\n       \"\"\"Converts the weights between CuDNNGRU and GRU.\n \n-      Arguments:\n+      Args:\n         weights: Original weights.\n         from_cudnn: Indicates whether original weights are from CuDNN layer.\n \n@@ -584,7 +584,7 @@ def _convert_rnn_weights(layer, weights):\n def save_optimizer_weights_to_hdf5_group(hdf5_group, optimizer):\n   \"\"\"Saves optimizer weights of a optimizer to a HDF5 group.\n \n-  Arguments:\n+  Args:\n       hdf5_group: HDF5 group.\n       optimizer: optimizer instance.\n   \"\"\"\n@@ -608,7 +608,7 @@ def save_optimizer_weights_to_hdf5_group(hdf5_group, optimizer):\n def load_optimizer_weights_from_hdf5_group(hdf5_group):\n   \"\"\"Load optimizer weights from a HDF5 group.\n \n-  Arguments:\n+  Args:\n       hdf5_group: A pointer to a HDF5 group.\n \n   Returns:\n@@ -623,7 +623,7 @@ def load_optimizer_weights_from_hdf5_group(hdf5_group):\n def save_weights_to_hdf5_group(f, layers):\n   \"\"\"Saves the weights of a list of layers to a HDF5 group.\n \n-  Arguments:\n+  Args:\n       f: HDF5 group.\n       layers: List of layer instances.\n   \"\"\"\n@@ -654,7 +654,7 @@ def save_weights_to_hdf5_group(f, layers):\n def load_weights_from_hdf5_group(f, layers):\n   \"\"\"Implements topological (order-based) weight loading.\n \n-  Arguments:\n+  Args:\n       f: A pointer to a HDF5 group.\n       layers: a list of target layers.\n \n@@ -726,7 +726,7 @@ def load_weights_from_hdf5_group_by_name(\n \n   Layers that have no matching name are skipped.\n \n-  Arguments:\n+  Args:\n       f: A pointer to a HDF5 group.\n       layers: a list of target layers.\n       skip_mismatch: Boolean, whether to skip loading of layers\n@@ -810,7 +810,7 @@ def save_attributes_to_hdf5_group(group, name, data):\n   This method deals with an inherent problem of HDF5 file which is not\n   able to store data larger than HDF5_OBJECT_HEADER_LIMIT bytes.\n \n-  Arguments:\n+  Args:\n       group: A pointer to a HDF5 group.\n       name: A name of the attributes to save.\n       data: Attributes data to store.\n@@ -853,7 +853,7 @@ def load_attributes_from_hdf5_group(group, name):\n   of HDF5 file which is not able to store\n   data larger than HDF5_OBJECT_HEADER_LIMIT bytes.\n \n-  Arguments:\n+  Args:\n       group: A pointer to a HDF5 group.\n       name: A name of the attributes to load.\n \n\n@@ -44,7 +44,7 @@ def model_from_config(config, custom_objects=None):\n   tf.keras.Sequential().from_config(model.get_config())\n   ```\n \n-  Arguments:\n+  Args:\n       config: Configuration dictionary.\n       custom_objects: Optional dictionary mapping names\n           (strings) to custom classes or functions to be\n@@ -80,7 +80,7 @@ def model_from_yaml(yaml_string, custom_objects=None):\n   ... except ImportError:\n   ...   pass\n \n-  Arguments:\n+  Args:\n       yaml_string: YAML string or open file encoding a model configuration.\n       custom_objects: Optional dictionary mapping names\n           (strings) to custom classes or functions to be\n@@ -117,7 +117,7 @@ def model_from_json(json_string, custom_objects=None):\n   >>> config = model.to_json()\n   >>> loaded_model = tf.keras.models.model_from_json(config)\n \n-  Arguments:\n+  Args:\n       json_string: JSON string encoding a model configuration.\n       custom_objects: Optional dictionary mapping names\n           (strings) to custom classes or functions to be\n\n@@ -98,7 +98,7 @@ def save_model(model,\n   option, then you _must_ provide all custom class definitions when loading\n   the model. See the `custom_objects` argument in `tf.keras.models.load_model`.\n \n-  Arguments:\n+  Args:\n       model: Keras model instance to be saved.\n       filepath: One of the following:\n         - String or `pathlib.Path` object, path where to save the model\n@@ -171,7 +171,7 @@ def load_model(filepath, custom_objects=None, compile=True, options=None):  # py\n   `\"dense_1/kernel:0\"`. It is recommended that you use the layer properties to\n   access specific variables, e.g. `model.get_layer(\"dense_1\").kernel`.\n \n-  Arguments:\n+  Args:\n       filepath: One of the following:\n           - String or `pathlib.Path` object, path to the saved model\n           - `h5py.File` object from which to load the model\n\n@@ -82,7 +82,7 @@ def _decode_helper(obj):\n def get_json_type(obj):\n   \"\"\"Serializes any object to a JSON-serializable structure.\n \n-  Arguments:\n+  Args:\n       obj: the object to serialize\n \n   Returns:\n@@ -140,4 +140,3 @@ def get_json_type(obj):\n                        .format(obj, type(obj)))\n \n   raise TypeError('Not JSON Serializable:', obj)\n-\n\n@@ -59,7 +59,7 @@ def get_test_data(train_samples,\n                   random_seed=None):\n   \"\"\"Generates test data to train a model on.\n \n-  Arguments:\n+  Args:\n     train_samples: Integer, how many training samples to generate.\n     test_samples: Integer, how many test samples to generate.\n     input_shape: Tuple of integers, shape of the inputs.\n@@ -97,7 +97,7 @@ def layer_test(layer_cls,\n                supports_masking=None):\n   \"\"\"Test routine for a layer with a single input and single output.\n \n-  Arguments:\n+  Args:\n     layer_cls: Layer class object.\n     kwargs: Optional dictionary of keyword arguments for instantiating the\n       layer.\n@@ -316,7 +316,7 @@ def model_type_scope(value):\n \n   The model type gets restored to its original value upon exiting the scope.\n \n-  Arguments:\n+  Args:\n      value: model type value\n \n   Yields:\n@@ -337,7 +337,7 @@ def run_eagerly_scope(value):\n \n   The boolean gets restored to its original value upon exiting the scope.\n \n-  Arguments:\n+  Args:\n      value: Bool specifying if we should run models eagerly in the active test.\n      Should be True or False.\n \n@@ -359,7 +359,7 @@ def use_keras_tensors_scope(value):\n \n   The boolean gets restored to its original value upon exiting the scope.\n \n-  Arguments:\n+  Args:\n      value: Bool specifying if we should build functional models\n       using KerasTensors in the active test.\n      Should be True or False.\n@@ -393,7 +393,7 @@ def saved_model_format_scope(value, **kwargs):\n   The saved model format gets restored to its original value upon exiting the\n   scope.\n \n-  Arguments:\n+  Args:\n      value: saved model format value\n      **kwargs: optional kwargs to pass to the save function.\n \n\n@@ -160,7 +160,7 @@ class Layer(object):\n   [Making new Layers and Models via subclassing](\n     https://www.tensorflow.org/guide/keras/custom_layers_and_models)\n \n-  Arguments:\n+  Args:\n     trainable: Boolean, whether the layer's variables should be trainable.\n     name: String name of the layer.\n     dtype: The dtype of the layer's computations and weights (default of\n\n@@ -92,7 +92,7 @@ def smart_cond(pred, true_fn=None, false_fn=None, name=None):  # pylint: disable\n   If `pred` is a bool or has a constant value, we return either `true_fn()`\n   or `false_fn()`, otherwise we use `tf.cond` to dynamically route to both.\n \n-  Arguments:\n+  Args:\n     pred: A scalar determining whether to return the result of `true_fn` or\n       `false_fn`.\n     true_fn: The callable to be performed if pred is true.\n@@ -115,7 +115,7 @@ def smart_cond(pred, true_fn=None, false_fn=None, name=None):  # pylint: disable\n def constant_value(pred):  # pylint: disable=invalid-name\n   \"\"\"Return the bool value for `pred`, or None if `pred` had a dynamic value.\n \n-  Arguments:\n+  Args:\n     pred: A scalar, either a Python bool or a TensorFlow boolean variable\n       or tensor, or the Python integer 1 or 0.\n \n\n@@ -51,7 +51,7 @@ def convert_data_format(data_format, ndim):\n def normalize_tuple(value, n, name):\n   \"\"\"Transforms a single integer or iterable of integers into an integer tuple.\n \n-  Arguments:\n+  Args:\n     value: The value to validate and convert. Could an int, or any iterable of\n       ints.\n     n: The size of the tuple to be returned.\n@@ -90,7 +90,7 @@ def normalize_tuple(value, n, name):\n def conv_output_length(input_length, filter_size, padding, stride, dilation=1):\n   \"\"\"Determines output length of a convolution given input length.\n \n-  Arguments:\n+  Args:\n       input_length: integer.\n       filter_size: integer.\n       padding: one of \"same\", \"valid\", \"full\", \"causal\"\n@@ -116,7 +116,7 @@ def conv_output_length(input_length, filter_size, padding, stride, dilation=1):\n def conv_input_length(output_length, filter_size, padding, stride):\n   \"\"\"Determines input length of a convolution given output length.\n \n-  Arguments:\n+  Args:\n       output_length: integer.\n       filter_size: integer.\n       padding: one of \"same\", \"valid\", \"full\".\n@@ -145,7 +145,7 @@ def deconv_output_length(input_length,\n                          dilation=1):\n   \"\"\"Determines output length of a transposed convolution given input length.\n \n-  Arguments:\n+  Args:\n       input_length: Integer.\n       filter_size: Integer.\n       padding: one of `\"same\"`, `\"valid\"`, `\"full\"`.\n\n@@ -70,7 +70,7 @@ if True:  # This gets transformed to `if sys.version_info[0] == 2:` in OSS.  # p\n     Under Python 2, `urlretrieve` relies on `FancyURLopener` from legacy\n     `urllib` module, known to have issues with proxy management.\n \n-    Arguments:\n+    Args:\n         url: url to retrieve.\n         filename: where to store the retrieved data locally.\n         reporthook: a hook function that will be called once on establishment of\n@@ -115,7 +115,7 @@ def is_generator_or_sequence(x):\n def _extract_archive(file_path, path='.', archive_format='auto'):\n   \"\"\"Extracts an archive if it matches tar, tar.gz, tar.bz, or zip formats.\n \n-  Arguments:\n+  Args:\n       file_path: path to the archive file\n       path: path to extract the archive file\n       archive_format: Archive format to try for extracting the file.\n@@ -192,7 +192,7 @@ def get_file(fname,\n       untar=True)\n   ```\n \n-  Arguments:\n+  Args:\n       fname: Name of the file. If an absolute path `/path/to/file.txt` is\n           specified the file will be saved at that location.\n       origin: Original URL of the file.\n@@ -315,7 +315,7 @@ def _hash_file(fpath, algorithm='sha256', chunk_size=65535):\n   'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855'\n   ```\n \n-  Arguments:\n+  Args:\n       fpath: path to the file being validated\n       algorithm: hash algorithm, one of `'auto'`, `'sha256'`, or `'md5'`.\n           The default `'auto'` detects the hash algorithm in use.\n@@ -339,7 +339,7 @@ def _hash_file(fpath, algorithm='sha256', chunk_size=65535):\n def validate_file(fpath, file_hash, algorithm='auto', chunk_size=65535):\n   \"\"\"Validates a file against a sha256 or md5 hash.\n \n-  Arguments:\n+  Args:\n       fpath: path to the file being validated\n       file_hash:  The expected hash string of the file.\n           The sha256 and md5 hash algorithms are both supported.\n@@ -455,7 +455,7 @@ class Sequence(object):\n   def __getitem__(self, index):\n     \"\"\"Gets batch at position `index`.\n \n-    Arguments:\n+    Args:\n         index: position of the batch in the Sequence.\n \n     Returns:\n@@ -486,7 +486,7 @@ class Sequence(object):\n def iter_sequence_infinite(seq):\n   \"\"\"Iterates indefinitely over a Sequence.\n \n-  Arguments:\n+  Args:\n     seq: `Sequence` instance.\n \n   Yields:\n@@ -556,7 +556,7 @@ def get_index(uid, i):\n   get a specific one. A single Sequence would cause the validation to\n   overwrite the training Sequence.\n \n-  Arguments:\n+  Args:\n       uid: int, Sequence identifier\n       i: index\n \n@@ -624,7 +624,7 @@ class SequenceEnqueuer(object):\n   def start(self, workers=1, max_queue_size=10):\n     \"\"\"Starts the handler's workers.\n \n-    Arguments:\n+    Args:\n         workers: Number of workers.\n         max_queue_size: queue size\n             (when full, workers could block on `put()`)\n@@ -651,7 +651,7 @@ class SequenceEnqueuer(object):\n \n     Should be called by the same thread which called `start()`.\n \n-    Arguments:\n+    Args:\n         timeout: maximum time to wait on `thread.join()`\n     \"\"\"\n     self.stop_signal.set()\n@@ -675,7 +675,7 @@ class SequenceEnqueuer(object):\n   def _get_executor_init(self, workers):\n     \"\"\"Gets the Pool initializer for multiprocessing.\n \n-    Arguments:\n+    Args:\n         workers: Number of workers.\n \n     Returns:\n@@ -701,7 +701,7 @@ class OrderedEnqueuer(SequenceEnqueuer):\n \n   Used in `fit_generator`, `evaluate_generator`, `predict_generator`.\n \n-  Arguments:\n+  Args:\n       sequence: A `tf.keras.utils.data_utils.Sequence` object.\n       use_multiprocessing: use multiprocessing if True, otherwise threading\n       shuffle: whether to shuffle the data at the beginning of each epoch\n@@ -714,7 +714,7 @@ class OrderedEnqueuer(SequenceEnqueuer):\n   def _get_executor_init(self, workers):\n     \"\"\"Gets the Pool initializer for multiprocessing.\n \n-    Arguments:\n+    Args:\n         workers: Number of workers.\n \n     Returns:\n@@ -821,7 +821,7 @@ def next_sample(uid):\n   get a specific one. A single generator would cause the validation to\n   overwrite the training generator.\n \n-  Arguments:\n+  Args:\n       uid: int, generator identifier\n \n   Returns:\n@@ -839,7 +839,7 @@ class GeneratorEnqueuer(SequenceEnqueuer):\n \n   Used in `fit_generator`, `evaluate_generator`, `predict_generator`.\n \n-  Arguments:\n+  Args:\n       generator: a generator function which yields data\n       use_multiprocessing: use multiprocessing if True, otherwise threading\n       wait_time: time to sleep in-between calls to `put()`\n@@ -856,7 +856,7 @@ class GeneratorEnqueuer(SequenceEnqueuer):\n   def _get_executor_init(self, workers):\n     \"\"\"Gets the Pool initializer for multiprocessing.\n \n-    Arguments:\n+    Args:\n       workers: Number of works.\n \n     Returns:\n\n@@ -70,7 +70,7 @@ class CustomObjectScope(object):\n     layer = Dense.from_config(config)\n   ```\n \n-  Arguments:\n+  Args:\n       *args: Dictionary or dictionaries of `{name: object}` pairs.\n   \"\"\"\n \n@@ -130,7 +130,7 @@ def register_keras_serializable(package='Custom', name=None):\n   The object will be registered under the key 'package>name' where `name`,\n   defaults to the object name if not passed.\n \n-  Arguments:\n+  Args:\n     package: The package that this class belongs to.\n     name: The name to serialize this class under in this package. If None, the\n       class' name will be used.\n@@ -402,7 +402,7 @@ def deserialize_keras_object(identifier,\n def func_dump(func):\n   \"\"\"Serializes a user defined function.\n \n-  Arguments:\n+  Args:\n       func: the function to serialize.\n \n   Returns:\n@@ -425,7 +425,7 @@ def func_dump(func):\n def func_load(code, defaults=None, closure=None, globs=None):\n   \"\"\"Deserializes a user defined function.\n \n-  Arguments:\n+  Args:\n       code: bytecode of the function.\n       defaults: defaults of the function.\n       closure: closure of the function.\n@@ -442,7 +442,7 @@ def func_load(code, defaults=None, closure=None, globs=None):\n   def ensure_value_to_cell(value):\n     \"\"\"Ensures that a value is converted to a python cell object.\n \n-    Arguments:\n+    Args:\n         value: Any value that needs to be casted to the cell type\n \n     Returns:\n@@ -474,7 +474,7 @@ def func_load(code, defaults=None, closure=None, globs=None):\n def has_arg(fn, name, accept_all=False):\n   \"\"\"Checks if a callable accepts a given keyword argument.\n \n-  Arguments:\n+  Args:\n       fn: Callable to inspect.\n       name: Check if `fn` can be called with `name` as a keyword argument.\n       accept_all: What to return if there is no parameter called `name` but the\n@@ -493,7 +493,7 @@ def has_arg(fn, name, accept_all=False):\n class Progbar(object):\n   \"\"\"Displays a progress bar.\n \n-  Arguments:\n+  Args:\n       target: Total number of steps expected, None if unknown.\n       width: Progress bar width on screen.\n       verbose: Verbosity mode, 0 (silent), 1 (verbose), 2 (semi-verbose)\n@@ -540,7 +540,7 @@ class Progbar(object):\n   def update(self, current, values=None, finalize=None):\n     \"\"\"Updates the progress bar.\n \n-    Arguments:\n+    Args:\n         current: Index of current step.\n         values: List of tuples: `(name, value_for_last_step)`. If `name` is in\n           `stateful_metrics`, `value_for_last_step` will be displayed as-is.\n@@ -681,7 +681,7 @@ class Progbar(object):\n     (i.e. `current == 0`) then zero is given as an estimate. The duration\n     estimate ignores the duration of the (assumed to be non-representative)\n     first step for estimates when more steps are available (i.e. `current>1`).\n-    Arguments:\n+    Args:\n       current: Index of current step.\n       now: The current time.\n     Returns: Estimate of the duration of a single step.\n@@ -707,7 +707,7 @@ class Progbar(object):\n def make_batches(size, batch_size):\n   \"\"\"Returns a list of batch indices (tuples of indices).\n \n-  Arguments:\n+  Args:\n       size: Integer, total size of the data to slice into batches.\n       batch_size: Integer, batch size.\n \n@@ -729,7 +729,7 @@ def slice_arrays(arrays, start=None, stop=None):\n \n   Can also work on list/array of indices: `slice_arrays(x, indices)`\n \n-  Arguments:\n+  Args:\n       arrays: Single array or list of arrays.\n       start: can be an integer index (start index) or a list/array of indices\n       stop: integer (stop index); should be None if `start` was a list.\n@@ -771,7 +771,7 @@ def to_list(x):\n   If a tensor is passed, we return\n   a list of size 1 containing the tensor.\n \n-  Arguments:\n+  Args:\n       x: target object to be normalized.\n \n   Returns:\n\n@@ -69,7 +69,7 @@ def path_to_string(path):\n def ask_to_proceed_with_overwrite(filepath):\n   \"\"\"Produces a prompt asking about overwriting a file.\n \n-  Arguments:\n+  Args:\n       filepath: the path to the file to be overwritten.\n \n   Returns:\n\n@@ -36,7 +36,7 @@ def get_source_inputs(tensor, layer=None, node_index=None):\n   Output will always be a list of tensors\n   (potentially with 1 element).\n \n-  Arguments:\n+  Args:\n       tensor: The tensor to start from.\n       layer: Origin layer of the tensor. Will be\n           determined via tensor._keras_history if not provided.\n@@ -94,7 +94,7 @@ def validate_string_arg(input_data,\n def count_params(weights):\n   \"\"\"Count the total number of scalars composing the weights.\n \n-  Arguments:\n+  Args:\n       weights: An iterable containing the weights on which to compute params\n \n   Returns:\n@@ -111,7 +111,7 @@ def count_params(weights):\n def print_summary(model, line_length=None, positions=None, print_fn=None):\n   \"\"\"Prints a summary of a model.\n \n-  Arguments:\n+  Args:\n       model: Keras model instance.\n       line_length: Total length of printed lines\n           (e.g. set this to adapt the display to different\n@@ -196,7 +196,7 @@ def print_summary(model, line_length=None, positions=None, print_fn=None):\n   def print_layer_summary(layer):\n     \"\"\"Prints a summary for a single layer.\n \n-    Arguments:\n+    Args:\n         layer: target layer.\n     \"\"\"\n     try:\n@@ -219,7 +219,7 @@ def print_summary(model, line_length=None, positions=None, print_fn=None):\n   def print_layer_summary_with_connections(layer):\n     \"\"\"Prints a summary for a single layer (including topological connections).\n \n-    Arguments:\n+    Args:\n         layer: target layer.\n     \"\"\"\n     try:\n@@ -342,7 +342,7 @@ def convert_dense_weights_data_format(dense,\n   followed by a `Dense` layer, the weights of that `Dense` layer\n   should be updated to reflect the new dimension ordering.\n \n-  Arguments:\n+  Args:\n       dense: The target `Dense` layer.\n       previous_feature_map_shape: A shape tuple of 3 integers,\n           e.g. `(512, 7, 7)`. The shape of the convolutional\n\n@@ -54,7 +54,7 @@ def multi_gpu_model(model, gpus, cpu_merge=True, cpu_relocation=False):\n   This function is only available with the TensorFlow backend\n   for the time being.\n \n-  Arguments:\n+  Args:\n       model: A Keras model instance. To avoid OOM errors,\n           this model could have been built on CPU, for instance\n           (see usage example below).\n@@ -179,7 +179,7 @@ def multi_gpu_model(model, gpus, cpu_merge=True, cpu_relocation=False):\n   def get_slice(data, i, parts):\n     \"\"\"Slice an array into `parts` slices and return slice `i`.\n \n-    Arguments:\n+    Args:\n       data: array to slice.\n       i: index of slice to return.\n       parts: number of slices to make.\n\n@@ -27,7 +27,7 @@ def to_categorical(y, num_classes=None, dtype='float32'):\n \n   E.g. for use with categorical_crossentropy.\n \n-  Arguments:\n+  Args:\n       y: class vector to be converted into a matrix\n           (integers from 0 to num_classes).\n       num_classes: total number of classes. If `None`, this would be inferred\n@@ -85,7 +85,7 @@ def to_categorical(y, num_classes=None, dtype='float32'):\n def normalize(x, axis=-1, order=2):\n   \"\"\"Normalizes a Numpy array.\n \n-  Arguments:\n+  Args:\n       x: Numpy array to normalize.\n       axis: axis along which to normalize.\n       order: Normalization order (e.g. `order=2` for L2 norm).\n\n@@ -96,7 +96,7 @@ def get_reachable_from_inputs(inputs, targets=None):\n def map_structure_with_atomic(is_atomic_fn, map_fn, nested):\n   \"\"\"Maps the atomic elements of a nested structure.\n \n-  Arguments:\n+  Args:\n     is_atomic_fn: A function that determines if an element of `nested` is\n       atomic.\n     map_fn: The function to apply to atomic elements of `nested`.\n@@ -150,7 +150,7 @@ def convert_shapes(input_shape, to_tuples=True):\n   - ints\n   - None\n \n-  Arguments:\n+  Args:\n     input_shape: A nested structure of objects to be converted to TensorShapes.\n     to_tuples: If `True`, converts all TensorShape to tuples. Otherwise converts\n       all tuples representing shapes to TensorShapes.\n@@ -200,7 +200,7 @@ class ListWrapper(object):\n def convert_inner_node_data(nested, wrap=False):\n   \"\"\"Either wraps or unwraps innermost node data lists in `ListWrapper` objects.\n \n-  Arguments:\n+  Args:\n     nested: A nested data structure.\n     wrap: If `True`, wrap innermost lists in `ListWrapper` objects. If `False`,\n       unwraps `ListWrapper` objects into lists.\n@@ -247,7 +247,7 @@ def shape_type_conversion(fn):\n \n   Used in `compute_output_shape` and `build`.\n \n-  Arguments:\n+  Args:\n     fn: function to wrap.\n \n   Returns:\n@@ -283,7 +283,7 @@ def is_extension_type(tensor):\n   but this will be changed to use an appropriate extensiontype protocol\n   check once ExtensionType is made public.\n \n-  Arguments:\n+  Args:\n     tensor: An object to test\n \n   Returns:\n@@ -298,7 +298,7 @@ def is_symbolic_tensor(tensor):\n   A Variable can be seen as either: it is considered symbolic\n   when we are in a graph scope, and eager when we are in an eager scope.\n \n-  Arguments:\n+  Args:\n     tensor: A tensor instance to test.\n \n   Returns:\n@@ -350,7 +350,7 @@ def register_symbolic_tensor_type(cls):\n   layer = tf.keras.layers.Lambda(lambda input_: Foo(input_))\n   ```\n \n-  Arguments:\n+  Args:\n     cls: A `class` type which shall be regarded as a symbolic `Tensor`.\n   \"\"\"\n   global _user_convertible_tensor_types\n@@ -412,7 +412,7 @@ def assert_no_legacy_layers(layers):\n def maybe_init_scope(layer):\n   \"\"\"Open an `init_scope` if in V2 mode and using the keras graph.\n \n-  Arguments:\n+  Args:\n     layer: The Layer/Model that is currently active.\n \n   Yields:\n\n@@ -78,7 +78,7 @@ def model_to_dot(model,\n                  subgraph=False):\n   \"\"\"Convert a Keras model to dot format.\n \n-  Arguments:\n+  Args:\n     model: A Keras model instance.\n     show_shapes: whether to display shape information.\n     show_dtype: whether to display layer dtypes.\n@@ -305,7 +305,7 @@ def plot_model(model,\n   tf.keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True)\n   ```\n \n-  Arguments:\n+  Args:\n     model: A Keras model instance\n     to_file: File name of the plot image.\n     show_shapes: whether to display shape information.\n\n@@ -36,7 +36,7 @@ class BaseWrapper(object):\n   Warning: This class should not be used directly.\n   Use descendant classes instead.\n \n-  Arguments:\n+  Args:\n       build_fn: callable function or class instance\n       **sk_params: model parameters & fitting parameters\n \n@@ -79,7 +79,7 @@ class BaseWrapper(object):\n   def check_params(self, params):\n     \"\"\"Checks for user typos in `params`.\n \n-    Arguments:\n+    Args:\n         params: dictionary; the parameters to be checked\n \n     Raises:\n@@ -108,7 +108,7 @@ class BaseWrapper(object):\n   def get_params(self, **params):  # pylint: disable=unused-argument\n     \"\"\"Gets parameters for this estimator.\n \n-    Arguments:\n+    Args:\n         **params: ignored (exists for API compatibility).\n \n     Returns:\n@@ -121,7 +121,7 @@ class BaseWrapper(object):\n   def set_params(self, **params):\n     \"\"\"Sets the parameters of this estimator.\n \n-    Arguments:\n+    Args:\n         **params: Dictionary of parameter names mapped to their values.\n \n     Returns:\n@@ -134,7 +134,7 @@ class BaseWrapper(object):\n   def fit(self, x, y, **kwargs):\n     \"\"\"Constructs a new model with `build_fn` & fit the model to `(x, y)`.\n \n-    Arguments:\n+    Args:\n         x : array-like, shape `(n_samples, n_features)`\n             Training samples where `n_samples` is the number of samples\n             and `n_features` is the number of features.\n@@ -170,7 +170,7 @@ class BaseWrapper(object):\n   def filter_sk_params(self, fn, override=None):\n     \"\"\"Filters `sk_params` and returns those in `fn`'s arguments.\n \n-    Arguments:\n+    Args:\n         fn : arbitrary function\n         override: dictionary, values to override `sk_params`\n \n@@ -195,7 +195,7 @@ class KerasClassifier(BaseWrapper):\n   def fit(self, x, y, **kwargs):\n     \"\"\"Constructs a new model with `build_fn` & fit the model to `(x, y)`.\n \n-    Arguments:\n+    Args:\n         x : array-like, shape `(n_samples, n_features)`\n             Training samples where `n_samples` is the number of samples\n             and `n_features` is the number of features.\n@@ -225,7 +225,7 @@ class KerasClassifier(BaseWrapper):\n   def predict(self, x, **kwargs):\n     \"\"\"Returns the class predictions for the given test data.\n \n-    Arguments:\n+    Args:\n         x: array-like, shape `(n_samples, n_features)`\n             Test samples where `n_samples` is the number of samples\n             and `n_features` is the number of features.\n@@ -244,7 +244,7 @@ class KerasClassifier(BaseWrapper):\n   def predict_proba(self, x, **kwargs):\n     \"\"\"Returns class probability estimates for the given test data.\n \n-    Arguments:\n+    Args:\n         x: array-like, shape `(n_samples, n_features)`\n             Test samples where `n_samples` is the number of samples\n             and `n_features` is the number of features.\n@@ -272,7 +272,7 @@ class KerasClassifier(BaseWrapper):\n   def score(self, x, y, **kwargs):\n     \"\"\"Returns the mean accuracy on the given test data and labels.\n \n-    Arguments:\n+    Args:\n         x: array-like, shape `(n_samples, n_features)`\n             Test samples where `n_samples` is the number of samples\n             and `n_features` is the number of features.\n@@ -318,7 +318,7 @@ class KerasRegressor(BaseWrapper):\n   def predict(self, x, **kwargs):\n     \"\"\"Returns predictions for the given test data.\n \n-    Arguments:\n+    Args:\n         x: array-like, shape `(n_samples, n_features)`\n             Test samples where `n_samples` is the number of samples\n             and `n_features` is the number of features.\n@@ -335,7 +335,7 @@ class KerasRegressor(BaseWrapper):\n   def score(self, x, y, **kwargs):\n     \"\"\"Returns the mean loss on the given test data and labels.\n \n-    Arguments:\n+    Args:\n         x: array-like, shape `(n_samples, n_features)`\n             Test samples where `n_samples` is the number of samples\n             and `n_features` is the number of features.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
