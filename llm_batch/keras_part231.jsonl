{"custom_id": "keras#b574263adefccc6aea5a3770edd80bbb9f170f41", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 24 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 10 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 30 | Churn Cumulative: 9202 | Contributors (this commit): 49 | Commits (past 90d): 22 | Contributors (cumulative): 49 | DMM Complexity: None\n\nDIFF:\n@@ -783,7 +783,8 @@ class SimpleRNNCell(Layer):\n         units: Positive integer, dimensionality of the output space.\n         activation: Activation function to use\n             (see [activations](../activations.md)).\n-            If you pass None, no activation is applied\n+            Default: hyperbolic tangent (`tanh`).\n+            If you pass `None`, no activation is applied\n             (ie. \"linear\" activation: `a(x) = x`).\n         use_bias: Boolean, whether the layer uses a bias vector.\n         kernel_initializer: Initializer for the `kernel` weights matrix,\n@@ -941,7 +942,8 @@ class SimpleRNN(RNN):\n         units: Positive integer, dimensionality of the output space.\n         activation: Activation function to use\n             (see [activations](../activations.md)).\n-            If you pass None, no activation is applied\n+            Default: hyperbolic tangent (`tanh`).\n+            If you pass `None`, no activation is applied\n             (ie. \"linear\" activation: `a(x) = x`).\n         use_bias: Boolean, whether the layer uses a bias vector.\n         kernel_initializer: Initializer for the `kernel` weights matrix,\n@@ -1153,11 +1155,15 @@ class GRUCell(Layer):\n         units: Positive integer, dimensionality of the output space.\n         activation: Activation function to use\n             (see [activations](../activations.md)).\n-            If you pass None, no activation is applied\n+            Default: hyperbolic tangent (`tanh`).\n+            If you pass `None`, no activation is applied\n             (ie. \"linear\" activation: `a(x) = x`).\n         recurrent_activation: Activation function to use\n             for the recurrent step\n             (see [activations](../activations.md)).\n+            Default: hard sigmoid (`hard_sigmoid`).\n+            If you pass `None`, no activation is applied\n+            (ie. \"linear\" activation: `a(x) = x`).\n         use_bias: Boolean, whether the layer uses a bias vector.\n         kernel_initializer: Initializer for the `kernel` weights matrix,\n             used for the linear transformation of the inputs\n@@ -1393,11 +1399,15 @@ class GRU(RNN):\n         units: Positive integer, dimensionality of the output space.\n         activation: Activation function to use\n             (see [activations](../activations.md)).\n-            If you pass None, no activation is applied\n+            Default: hyperbolic tangent (`tanh`).\n+            If you pass `None`, no activation is applied\n             (ie. \"linear\" activation: `a(x) = x`).\n         recurrent_activation: Activation function to use\n             for the recurrent step\n             (see [activations](../activations.md)).\n+            Default: hard sigmoid (`hard_sigmoid`).\n+            If you pass `None`, no activation is applied\n+            (ie. \"linear\" activation: `a(x) = x`).\n         use_bias: Boolean, whether the layer uses a bias vector.\n         kernel_initializer: Initializer for the `kernel` weights matrix,\n             used for the linear transformation of the inputs\n@@ -1632,11 +1642,15 @@ class LSTMCell(Layer):\n         units: Positive integer, dimensionality of the output space.\n         activation: Activation function to use\n             (see [activations](../activations.md)).\n-            If you pass None, no activation is applied\n+            Default: hyperbolic tangent (`tanh`).\n+            If you pass `None`, no activation is applied\n             (ie. \"linear\" activation: `a(x) = x`).\n         recurrent_activation: Activation function to use\n             for the recurrent step\n             (see [activations](../activations.md)).\n+            Default: hard sigmoid (`hard_sigmoid`).\n+            If you pass `None`, no activation is applied\n+            (ie. \"linear\" activation: `a(x) = x`).x\n         use_bias: Boolean, whether the layer uses a bias vector.\n         kernel_initializer: Initializer for the `kernel` weights matrix,\n             used for the linear transformation of the inputs\n@@ -1896,11 +1910,15 @@ class LSTM(RNN):\n         units: Positive integer, dimensionality of the output space.\n         activation: Activation function to use\n             (see [activations](../activations.md)).\n-            If you pass None, no activation is applied\n+            Default: hyperbolic tangent (`tanh`).\n+            If you pass `None`, no activation is applied\n             (ie. \"linear\" activation: `a(x) = x`).\n         recurrent_activation: Activation function to use\n             for the recurrent step\n             (see [activations](../activations.md)).\n+            Default: hard sigmoid (`hard_sigmoid`).\n+            If you pass `None`, no activation is applied\n+            (ie. \"linear\" activation: `a(x) = x`).\n         use_bias: Boolean, whether the layer uses a bias vector.\n         kernel_initializer: Initializer for the `kernel` weights matrix,\n             used for the linear transformation of the inputs.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d954164a54350f72848212b30b883f879de5396c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 15 | Churn Cumulative: 3070 | Contributors (this commit): 48 | Commits (past 90d): 16 | Contributors (cumulative): 54 | DMM Complexity: 1.0\n\nDIFF:\n@@ -748,11 +748,10 @@ class ImageDataGenerator(object):\n \n         if self.zca_whitening:\n             flat_x = np.reshape(x, (x.shape[0], x.shape[1] * x.shape[2] * x.shape[3]))\n-            num_examples = flat_x.shape[0]\n-            _, s, vt = linalg.svd(flat_x / np.sqrt(num_examples))\n-            s_expand = np.hstack((s, np.zeros(vt.shape[0] - num_examples,\n-                                              dtype=flat_x.dtype)))\n-            self.principal_components = (vt.T / np.sqrt(s_expand ** 2 + self.zca_epsilon)).dot(vt)\n+            sigma = np.dot(flat_x.T, flat_x) / flat_x.shape[0]\n+            u, s, _ = linalg.svd(sigma)\n+            s_inv = 1. / np.sqrt(s[np.newaxis] + self.zca_epsilon)\n+            self.principal_components = (u * s_inv).dot(u.T)\n \n \n class Iterator(Sequence):\n\n@@ -123,6 +123,9 @@ class TestImage(object):\n         # Test RBG\n         x = np.random.random((32, 10, 10, 3))\n         generator.fit(x)\n+        # Test more samples than dims\n+        x = np.random.random((32, 4, 4, 1))\n+        generator.fit(x)\n         generator = image.ImageDataGenerator(\n             featurewise_center=True,\n             samplewise_center=True,\n@@ -136,6 +139,9 @@ class TestImage(object):\n         # Test RBG\n         x = np.random.random((32, 3, 10, 10))\n         generator.fit(x)\n+        # Test more samples than dims\n+        x = np.random.random((32, 1, 4, 4))\n+        generator.fit(x)\n \n     def test_directory_iterator(self, tmpdir):\n         num_classes = 2\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6d13240c1b1e3d68a453f3e8cc965196cf943c58", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 6253 | Contributors (this commit): 81 | Commits (past 90d): 40 | Contributors (cumulative): 81 | DMM Complexity: None\n\nDIFF:\n@@ -514,7 +514,7 @@ def _standardize_weights(y, sample_weight=None, class_weight=None,\n             raise ValueError('`class_weight` not supported for '\n                              '3+ dimensional targets.')\n         if y.shape[1] > 1:\n-            y_classes = y.argmax(axis=1)\n+            y_classes = np.argmax(y, axis=1)\n         elif y.shape[1] == 1:\n             y_classes = np.reshape(y, y.shape[0])\n         else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f51a7ef0904d011647f41e6b572c934e1fcd2f84", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 8 | Churn Cumulative: 1207 | Contributors (this commit): 22 | Commits (past 90d): 5 | Contributors (cumulative): 22 | DMM Complexity: 1.0\n\nDIFF:\n@@ -180,6 +180,14 @@ class BatchNormalization(Layer):\n             inputs, self.gamma, self.beta, reduction_axes,\n             epsilon=self.epsilon)\n \n+        if K.backend() != 'cntk':\n+            sample_size = K.prod([K.shape(inputs)[axis]\n+                                  for axis in reduction_axes])\n+            sample_size = K.cast(sample_size, dtype=K.dtype(inputs))\n+\n+            # sample variance - unbiased estimator of population variance\n+            variance *= sample_size / (sample_size - (1.0 + self.epsilon))\n+\n         self.add_update([K.moving_average_update(self.moving_mean,\n                                                  mean,\n                                                  self.momentum),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#83ae7d69692b892915a78b48eaf159a5f2377c91", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 5 | Churn Cumulative: 2760 | Contributors (this commit): 47 | Commits (past 90d): 16 | Contributors (cumulative): 47 | DMM Complexity: 0.0\n\nDIFF:\n@@ -962,6 +962,9 @@ def _count_valid_files_in_directory(directory, white_list_formats, follow_links)\n         for fname in files:\n             is_valid = False\n             for extension in white_list_formats:\n+                if fname.lower().endswith('.tiff'):\n+                    warnings.warn('Using \\'.tiff\\' files with multiple bands will cause distortion. '\n+                                  'Please verify your output.')\n                 if fname.lower().endswith('.' + extension):\n                     is_valid = True\n                     break\n@@ -1093,7 +1096,7 @@ class DirectoryIterator(Iterator):\n         self.save_format = save_format\n         self.interpolation = interpolation\n \n-        white_list_formats = {'png', 'jpg', 'jpeg', 'bmp', 'ppm'}\n+        white_list_formats = {'png', 'jpg', 'jpeg', 'bmp', 'ppm', 'tif', 'tiff'}\n \n         # first, count the number of samples and classes\n         self.samples = 0\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a3ace15d3f8f8b808fc9d9876039d84c2a35e163", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 2812 | Contributors (this commit): 16 | Commits (past 90d): 9 | Contributors (cumulative): 16 | DMM Complexity: None\n\nDIFF:\n@@ -2079,8 +2079,8 @@ def switch(condition, then_expression, else_expression):\n         raise ValueError('Rank of condition should be less'\n                          ' than or equal to rank of then and'\n                          ' else expressions. ndim(condition)=' +\n-                         str(cond_ndim) + ', ndim(then_expression)'\n-                         '=' + str(expr_ndim))\n+                         str(ndim_cond) + ', ndim(then_expression)'\n+                         '=' + str(ndim_expr))\n     elif ndim_cond < ndim_expr:\n         shape_expr = int_shape(then_expression)\n         ndim_diff = ndim_expr - ndim_cond\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8a6fb0b15aeb8ed887f1cc216da55fda26d35264", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 5 | Files Changed: 4 | Hunks: 5 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 12418 | Contributors (this commit): 112 | Commits (past 90d): 40 | Contributors (cumulative): 127 | DMM Complexity: None\n\nDIFF:\n@@ -57,9 +57,9 @@ def augment_2d(inputs, rotation=0, horizontal_flip=False, vertical_flip=False):\n       rotation: A float, the degree range for rotation (0 <= rotation < 180),\n           e.g. 3 for random image rotation between (-3.0, 3.0).\n       horizontal_flip: A boolean, whether to allow random horizontal flip,\n-          e.g. true for 50% possiblity to flip image horizontally.\n+          e.g. true for 50% possibility to flip image horizontally.\n       vertical_flip: A boolean, whether to allow random vertical flip,\n-          e.g. true for 50% possiblity to flip image vertically.\n+          e.g. true for 50% possibility to flip image vertically.\n \n     # Returns\n       input data after augmentation, whose shape is the same as its original.\n\n@@ -565,7 +565,7 @@ def transpose(x):\n def gather(reference, indices):\n     # There is a bug in cntk gather op which may cause crash.\n     # We have made a fix but not catched in CNTK 2.1 release.\n-    # Will udpate with gather op in next release\n+    # Will update with gather op in next release\n     if _get_cntk_version() >= 2.2:\n         return C.ops.gather(reference, indices)\n     else:\n\n@@ -2061,7 +2061,7 @@ def arange(start, stop=None, step=1, dtype='int32'):\n         An integer tensor.\n \n     \"\"\"\n-    # Match the behavior of numpy and Theano by returning an empty seqence.\n+    # Match the behavior of numpy and Theano by returning an empty sequence.\n     if stop is None:\n         try:\n             if start < 0:\n\n@@ -74,7 +74,7 @@ def test_tokenizer_oov_flag():\n     x_train = ['This text has only known words']\n     x_test = ['This text has some unknown words']  # 2 OOVs: some, unknown\n \n-    # Defalut, without OOV flag\n+    # Default, without OOV flag\n     tokenizer = Tokenizer()\n     tokenizer.fit_on_texts(x_train)\n     x_test_seq = tokenizer.texts_to_sequences(x_test)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6ec99d967ab790d80c376d95d806f6a7520f3743", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 4 | Methods Changed: 5 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 2768 | Contributors (this commit): 47 | Commits (past 90d): 17 | Contributors (cumulative): 47 | DMM Complexity: None\n\nDIFF:\n@@ -872,9 +872,9 @@ class NumpyArrayIterator(Iterator):\n                  data_format=None,\n                  save_to_dir=None, save_prefix='', save_format='png'):\n         if y is not None and len(x) != len(y):\n-            raise ValueError('X (images tensor) and y (labels) '\n+            raise ValueError('x (images tensor) and y (labels) '\n                              'should have the same length. '\n-                             'Found: X.shape = %s, y.shape = %s' %\n+                             'Found: x.shape = %s, y.shape = %s' %\n                              (np.asarray(x).shape, np.asarray(y).shape))\n \n         if data_format is None:\n@@ -955,7 +955,7 @@ def _count_valid_files_in_directory(directory, white_list_formats, follow_links)\n         the directory.\n     \"\"\"\n     def _recursive_list(subpath):\n-        return sorted(os.walk(subpath, followlinks=follow_links), key=lambda tpl: tpl[0])\n+        return sorted(os.walk(subpath, followlinks=follow_links), key=lambda x: x[0])\n \n     samples = 0\n     for _, _, files in _recursive_list(directory):\n@@ -992,7 +992,7 @@ def _list_valid_filenames_in_directory(directory, white_list_formats,\n             the filenames will be [\"class1/file1.jpg\", \"class1/file2.jpg\", ...]).\n     \"\"\"\n     def _recursive_list(subpath):\n-        return sorted(os.walk(subpath, followlinks=follow_links), key=lambda tpl: tpl[0])\n+        return sorted(os.walk(subpath, followlinks=follow_links), key=lambda x: x[0])\n \n     classes = []\n     filenames = []\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1cd238a460ac7608654856864e8adf224a1b2a2c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1710 | Contributors (this commit): 12 | Commits (past 90d): 4 | Contributors (cumulative): 12 | DMM Complexity: 1.0\n\nDIFF:\n@@ -302,6 +302,7 @@ def test_clone_functional_model():\n \n     x_a = dense_1(input_a)\n     x_a = keras.layers.Dropout(0.5)(x_a)\n+    x_a = keras.layers.BatchNormalization()(x_a)\n     x_b = dense_1(input_b)\n     x_a = dense_2(x_a)\n     outputs = keras.layers.add([x_a, x_b])\n@@ -340,6 +341,7 @@ def test_clone_sequential_model():\n \n     model = keras.models.Sequential()\n     model.add(keras.layers.Dense(4, input_shape=(4,)))\n+    model.add(keras.layers.BatchNormalization())\n     model.add(keras.layers.Dropout(0.5))\n     model.add(keras.layers.Dense(4))\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#db0707b7b25d16d3a26c8c9651987a7d0a441e5b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 5 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 19 | Churn Cumulative: 7873 | Contributors (this commit): 84 | Commits (past 90d): 50 | Contributors (cumulative): 103 | DMM Complexity: 0.7777777777777778\n\nDIFF:\n@@ -60,17 +60,19 @@ def _standardize_input_data(data, names, shapes=None,\n     if isinstance(data, dict):\n         try:\n             data = [data[x].values if data[x].__class__.__name__ == 'DataFrame' else data[x] for x in names]\n-            data = [np.expand_dims(x, 1) if x.ndim == 1 else x for x in data]\n         except KeyError as e:\n             raise ValueError(\n                 'No data provided for \"' + e.args[0] + '\". Need data '\n                 'for each key in: ' + str(names))\n     elif isinstance(data, list):\n+        if len(names) == 1 and data and isinstance(data[0], (float, int)):\n+            data = [np.asarray(data)]\n+        else:\n             data = [x.values if x.__class__.__name__ == 'DataFrame' else x for x in data]\n-        data = [np.expand_dims(x, 1) if x is not None and x.ndim == 1 else x for x in data]\n     else:\n         data = data.values if data.__class__.__name__ == 'DataFrame' else data\n-        data = [np.expand_dims(data, 1)] if data.ndim == 1 else [data]\n+        data = [data]\n+    data = [np.expand_dims(x, 1) if x is not None and x.ndim == 1 else x for x in data]\n \n     if len(data) != len(names):\n         if data and hasattr(data[0], 'shape'):\n\n@@ -568,6 +568,17 @@ def test_trainable_argument():\n     assert_allclose(out, out_2)\n \n \n+@keras_test\n+def test_with_list_as_targets():\n+    model = Sequential()\n+    model.add(Dense(1, input_dim=3, trainable=False))\n+    model.compile('rmsprop', 'mse')\n+\n+    x = np.random.random((2, 3))\n+    y = [0, 1]\n+    model.train_on_batch(x, y)\n+\n+\n @keras_test\n def test_check_not_failing():\n     a = np.random.random((2, 1, 3))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#21f78b62a3081b6be209c2827ac6a68114725a47", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 12 | Churn Cumulative: 231 | Contributors (this commit): 8 | Commits (past 90d): 9 | Contributors (cumulative): 8 | DMM Complexity: 0.0\n\nDIFF:\n@@ -19,7 +19,7 @@ def _normalize_device_name(name):\n     return name\n \n \n-def multi_gpu_model(model, gpus):\n+def multi_gpu_model(model, gpus=None):\n     \"\"\"Replicates a model on different GPUs.\n \n     Specifically, this function implements single-machine\n@@ -101,6 +101,14 @@ def multi_gpu_model(model, gpus):\n     if K.backend() != 'tensorflow':\n         raise ValueError('`multi_gpu_model` is only available '\n                          'with the TensorFlow backend.')\n+\n+    available_devices = _get_available_devices()\n+    available_devices = [_normalize_device_name(name) for name in available_devices]\n+    if not gpus:\n+        # Using all visible GPUs when not specifying `gpus`\n+        # e.g. CUDA_VISIBLE_DEVICES=0,2 python3 keras_mgpu.py\n+        gpus = len([x for x in available_devices if 'gpu' in x])\n+\n     if isinstance(gpus, (list, tuple)):\n         if len(gpus) <= 1:\n             raise ValueError('For multi-gpu usage to be effective, '\n@@ -119,8 +127,6 @@ def multi_gpu_model(model, gpus):\n     import tensorflow as tf\n \n     target_devices = ['/cpu:0'] + ['/gpu:%d' % i for i in target_gpu_ids]\n-    available_devices = _get_available_devices()\n-    available_devices = [_normalize_device_name(name) for name in available_devices]\n     for device in target_devices:\n         if device not in available_devices:\n             raise ValueError(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#81f6b3aa5b2b6215a533180e848a3b4dff851d03", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 9358 | Contributors (this commit): 104 | Commits (past 90d): 27 | Contributors (cumulative): 104 | DMM Complexity: None\n\nDIFF:\n@@ -2046,7 +2046,7 @@ def arange(start, stop=None, step=1, dtype='int32'):\n \n     The function arguments use the same convention as\n     Theano's arange: if only one argument is provided,\n-    it is in fact the \"stop\" argument.\n+    it is in fact the \"stop\" argument and \"start\" is 0.\n \n     The default type of the returned tensor is `'int32'` to\n     match TensorFlow's default.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c6f81d393cc34f75583007379831a33d30b6d2e9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 6 | Churn Cumulative: 1410 | Contributors (this commit): 21 | Commits (past 90d): 7 | Contributors (cumulative): 24 | DMM Complexity: 0.0\n\nDIFF:\n@@ -176,7 +176,7 @@ class KerasClassifier(BaseWrapper):\n     \"\"\"Implementation of the scikit-learn classifier API for Keras.\n     \"\"\"\n \n-    def fit(self, x, y, **kwargs):\n+    def fit(self, x, y, sample_weight=None, **kwargs):\n         \"\"\"Constructs a new model with `build_fn` & fit the model to `(x, y)`.\n \n         # Arguments\n@@ -204,6 +204,8 @@ class KerasClassifier(BaseWrapper):\n         else:\n             raise ValueError('Invalid shape for y: ' + str(y.shape))\n         self.n_classes_ = len(self.classes_)\n+        if sample_weight is not None:\n+            kwargs['sample_weight'] = sample_weight\n         return super(KerasClassifier, self).fit(x, y, **kwargs)\n \n     def predict(self, x, **kwargs):\n\n@@ -75,7 +75,7 @@ def test_classify_inherit_class_build_fn():\n \n \n def assert_classification_works(clf):\n-    clf.fit(X_train, y_train, batch_size=batch_size, epochs=epochs)\n+    clf.fit(X_train, y_train, sample_weight=np.ones(X_train.shape[0]), batch_size=batch_size, epochs=epochs)\n \n     score = clf.score(X_train, y_train, batch_size=batch_size)\n     assert np.isscalar(score) and np.isfinite(score)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8be65329ec49049bffa8fb990b949fdc5b845c2b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 22 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 22 | Churn Cumulative: 1727 | Contributors (this commit): 12 | Commits (past 90d): 4 | Contributors (cumulative): 12 | DMM Complexity: 1.0\n\nDIFF:\n@@ -656,6 +656,28 @@ def test_recursion_with_bn_and_loss():\n     model2.fit(x, y, verbose=0, epochs=1)\n \n \n+@keras_test\n+def test_activity_regularization_with_model_composition():\n+    # Ensures that the shape of the input to the activity\n+    # regularizer is the same under model composition.\n+    # Tests for regressions of issue #9267\n+    wrong_size = 10\n+    correct_size = 2\n+    def reg(x):\n+        assert x.shape[-1] == correct_size\n+        return 0\n+\n+    net_a_input = Input([2])\n+    net_a = net_a_input\n+    net_a = Dense(wrong_size)(net_a)\n+    net_a = Dense(correct_size, activity_regularizer=reg)(net_a)\n+    model_a = Model([net_a_input], [net_a])\n+\n+    net_b_input = Input([2])\n+    net_b = Dense(10)(model_a(net_b_input))\n+    model_b = Model([net_b_input], [net_b])\n+\n+\n @keras_test\n def test_shared_layer_depth_is_correct():\n     # Basic outline here: we have a shared embedding layer, and two inputs that go through\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#45e478a5c0bf3e43bc178e14c470c9831e0a3383", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 8546 | Contributors (this commit): 57 | Commits (past 90d): 14 | Contributors (cumulative): 57 | DMM Complexity: None\n\nDIFF:\n@@ -2246,7 +2246,7 @@ class Container(Layer):\n \n                         # Apply activity regularizer if any:\n                         if hasattr(layer, 'activity_regularizer') and layer.activity_regularizer is not None:\n-                            regularization_losses = [layer.activity_regularizer(x) for x in computed_tensors]\n+                            regularization_losses = [layer.activity_regularizer(x) for x in output_tensors]\n                             layer.add_loss(regularization_losses, computed_tensors)\n \n                     # Update model updates and losses:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fb1887d132a8ce8548ff53d868a6ba531cd63b34", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 6 | Methods Changed: 2 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 11 | Churn Cumulative: 10398 | Contributors (this commit): 105 | Commits (past 90d): 30 | Contributors (cumulative): 115 | DMM Complexity: 0.0\n\nDIFF:\n@@ -3416,10 +3416,10 @@ def separable_conv1d(x, depthwise_kernel, pointwise_kernel, strides=1,\n     padding = _preprocess_padding(padding)\n     if tf_data_format == 'NHWC':\n         spatial_start_dim = 1\n-        strides = (1, 1) + strides + (1,)\n+        strides = (1,) + strides * 2 + (1,)\n     else:\n         spatial_start_dim = 2\n-        strides = (1, 1, 1) + strides\n+        strides = (1, 1) + strides * 2\n     x = tf.expand_dims(x, spatial_start_dim)\n     depthwise_kernel = tf.expand_dims(depthwise_kernel, 0)\n     pointwise_kernel = tf.expand_dims(pointwise_kernel, 0)\n\n@@ -238,18 +238,19 @@ def test_separable_conv_1d():\n     num_step = 9\n \n     for padding in _convolution_paddings:\n+        for strides in [1, 2]:\n             for multiplier in [1, 2]:\n                 for dilation_rate in [1, 2]:\n-                if padding == 'same':\n+                    if padding == 'same' and strides != 1:\n                         continue\n-                if dilation_rate != 1:\n+                    if dilation_rate != 1 and strides != 1:\n                         continue\n \n                     layer_test(convolutional.SeparableConv1D,\n                                kwargs={'filters': filters,\n                                        'kernel_size': 3,\n                                        'padding': padding,\n-                                   'strides': 1,\n+                                       'strides': strides,\n                                        'depth_multiplier': multiplier,\n                                        'dilation_rate': dilation_rate},\n                                input_shape=(num_samples, num_step, stack_size))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#dc4dd03683e1a691adae4b6c5fe8266987998f4e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 6265 | Contributors (this commit): 82 | Commits (past 90d): 41 | Contributors (cumulative): 82 | DMM Complexity: None\n\nDIFF:\n@@ -1116,7 +1116,7 @@ class Model(Container):\n                 count_mode = 'steps'\n             else:\n                 count_mode = 'samples'\n-            callbacks += [cbks.ProgbarLogger(count_mode)]\n+            callbacks.insert(1, cbks.ProgbarLogger(count_mode))\n         callbacks = cbks.CallbackList(callbacks)\n         out_labels = out_labels or []\n \n@@ -2087,7 +2087,7 @@ class Model(Container):\n         self.history = cbks.History()\n         callbacks = [cbks.BaseLogger()] + (callbacks or []) + [self.history]\n         if verbose:\n-            callbacks += [cbks.ProgbarLogger(count_mode='steps')]\n+            callbacks.insert(1, cbks.ProgbarLogger(count_mode='steps'))\n         callbacks = cbks.CallbackList(callbacks)\n \n         # it's possible to callback a different model than self:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a2e3d24fcbe73e9cf8b5b1737b1b2913960f7d96", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 7 | Files Changed: 3 | Hunks: 7 | Methods Changed: 4 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 13 | Churn Cumulative: 4054 | Contributors (this commit): 83 | Commits (past 90d): 30 | Contributors (cumulative): 103 | DMM Complexity: 0.0\n\nDIFF:\n@@ -307,7 +307,7 @@ class ProgbarLogger(Callback):\n             if k in logs:\n                 self.log_values.append((k, logs[k]))\n         if self.verbose:\n-            self.progbar.update(self.seen, self.log_values, force=True)\n+            self.progbar.update(self.seen, self.log_values)\n \n \n class History(Callback):\n\n@@ -304,14 +304,14 @@ class Progbar(object):\n                                   sys.stdout.isatty()) or\n                                  'ipykernel' in sys.modules)\n \n-    def update(self, current, values=None, force=False):\n+    def update(self, current, values=None):\n         \"\"\"Updates the progress bar.\n \n         # Arguments\n             current: Index of current step.\n-            values: List of tuples (name, value_for_last_step).\n+            values: List of tuples:\n+                `(name, value_for_last_step)`.\n                 The progress bar will display averages for these values.\n-            force: Whether to force visual progress update.\n         \"\"\"\n         values = values or []\n         for k, v in values:\n@@ -327,7 +327,7 @@ class Progbar(object):\n         now = time.time()\n         info = ' - %.0fs' % (now - self.start)\n         if self.verbose == 1:\n-            if (not force and (now - self.last_update) < self.interval and\n+            if (now - self.last_update < self.interval and\n                     self.target is not None and current < self.target):\n                 return\n \n\n@@ -21,9 +21,8 @@ def test_progbar():\n     for target in (len(values_s) - 1, None):\n         for verbose in (0, 1, 2):\n             bar = Progbar(target, width=30, verbose=verbose, interval=0.05)\n-            for force in (False, True):\n             for current, values in enumerate(values_s):\n-                    bar.update(current, values=values, force=force)\n+                bar.update(current, values=values)\n \n \n def test_custom_objects_scope():\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fce3e075ebb4e890c2675396b7c232670015e4b7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 22 | Lines Deleted: 50 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/6 | Churn Δ: 72 | Churn Cumulative: 4712 | Contributors (this commit): 23 | Commits (past 90d): 19 | Contributors (cumulative): 29 | DMM Complexity: 1.0\n\nDIFF:\n@@ -4,7 +4,6 @@ import os\n from multiprocessing import Process, Queue\n from keras.utils.test_utils import keras_test\n from keras.utils.test_utils import layer_test\n-from keras.utils.generic_utils import CustomObjectScope\n from keras.models import Sequential\n from keras import applications\n from keras import backend as K\n@@ -170,54 +169,5 @@ def test_nasnet():\n     _test_app_pooling(app, last_dim)\n \n \n-@pytest.mark.skipif(K.backend() != 'tensorflow', reason='Requires TF backend')\n-@keras_test\n-def test_depthwise_conv_2d():\n-    _convolution_paddings = ['valid', 'same']\n-    num_samples = 2\n-    stack_size = 3\n-    num_row = 7\n-    num_col = 6\n-\n-    with CustomObjectScope(\n-        {'relu6': applications.mobilenet.relu6,\n-         'DepthwiseConv2D': applications.mobilenet.DepthwiseConv2D}):\n-        for padding in _convolution_paddings:\n-            for strides in [(1, 1), (2, 2)]:\n-                for multiplier in [1, 2]:\n-                    if padding == 'same' and strides != (1, 1):\n-                        continue\n-\n-                    layer_test(applications.mobilenet.DepthwiseConv2D,\n-                               kwargs={'kernel_size': (3, 3),\n-                                       'padding': padding,\n-                                       'strides': strides,\n-                                       'depth_multiplier': multiplier},\n-                               input_shape=(num_samples,\n-                                            num_row,\n-                                            num_col,\n-                                            stack_size))\n-\n-        layer_test(applications.mobilenet.DepthwiseConv2D,\n-                   kwargs={'kernel_size': 3,\n-                           'padding': padding,\n-                           'data_format': 'channels_first',\n-                           'activation': None,\n-                           'depthwise_regularizer': 'l2',\n-                           'bias_regularizer': 'l2',\n-                           'activity_regularizer': 'l2',\n-                           'depthwise_constraint': 'unit_norm',\n-                           'strides': strides,\n-                           'depth_multiplier': multiplier},\n-                   input_shape=(num_samples, stack_size, num_row, num_col))\n-\n-        # Test invalid use case\n-        with pytest.raises(ValueError):\n-            Sequential([applications.mobilenet.DepthwiseConv2D(\n-                kernel_size=3,\n-                padding=padding,\n-                batch_input_shape=(None, None, 5, None))])\n-\n-\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n@@ -844,6 +844,28 @@ class TestBackend(object):\n             with pytest.raises(ValueError):\n                 k.conv3d(k.variable(xval), k.variable(kernel_val), data_format='channels_middle')\n \n+    @pytest.mark.parametrize('k', [KTF], ids=['TensorFlow'])\n+    def test_depthwise_conv_2d(self, k):\n+        for data_format in ['channels_first', 'channels_last']:\n+            x_shape = (4, 4)\n+            if data_format == 'channels_first':\n+                input_shape = (2, 3) + x_shape\n+            elif data_format == 'channels_last':\n+                input_shape = (2,) + x_shape + (3,)\n+            kernel_shape = (3, 3, 3, 2)\n+\n+            x_val = np.ones(input_shape)\n+            kernel_val = np.arange(np.prod(kernel_shape)).reshape(kernel_shape)\n+            z = k.eval(k.depthwise_conv2d(k.variable(x_val), k.variable(kernel_val),\n+                                          data_format=data_format))\n+\n+            for z_i in np.split(z, 6, axis=1 if data_format == 'channels_first' else -1):\n+                assert_allclose(z_i, z_i[0] * np.ones_like(z_i))\n+\n+        # Test invalid use cases\n+        with pytest.raises(ValueError):\n+            k.depthwise_conv2d(k.variable(x_val), k.variable(kernel_val), data_format='channels_middle')\n+\n     def test_pool2d(self):\n         check_single_tensor_operation('pool2d', (5, 10, 12, 3),\n                                       BACKENDS, cntk_dynamicity=True,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#649fd0d961d9176ba0c82c73e3b79ad770ecfa6a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 3 | Churn Cumulative: 2866 | Contributors (this commit): 67 | Commits (past 90d): 12 | Contributors (cumulative): 67 | DMM Complexity: 0.0\n\nDIFF:\n@@ -546,6 +546,9 @@ class RemoteMonitor(Callback):\n         send = {}\n         send['epoch'] = epoch\n         for k, v in logs.items():\n+            if isinstance(v, (np.ndarray, np.generic)):\n+                send[k] = v.item()\n+            else:\n                 send[k] = v\n         try:\n             requests.post(self.root + self.path,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3a5a090b231a67b6531cc2da3c40ee4dc34801c2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 17 | Files Changed: 2 | Hunks: 5 | Methods Changed: 2 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 25 | Churn Cumulative: 427 | Contributors (this commit): 16 | Commits (past 90d): 4 | Contributors (cumulative): 19 | DMM Complexity: 0.0\n\nDIFF:\n@@ -4,9 +4,9 @@ from __future__ import division\n from __future__ import print_function\n \n import numpy as np\n-import sys\n from collections import defaultdict\n \n+import six\n try:\n     import h5py\n except ImportError:\n@@ -141,13 +141,11 @@ def ask_to_proceed_with_overwrite(filepath):\n     # Returns\n         True if we can proceed with overwrite, False otherwise.\n     \"\"\"\n-    get_input = input\n-    if sys.version_info[:2] <= (2, 7):\n-        get_input = raw_input\n-    overwrite = get_input('[WARNING] %s already exists - overwrite? '\n-                          '[y/n]' % (filepath))\n-    while overwrite not in ['y', 'n']:\n-        overwrite = get_input('Enter \"y\" (overwrite) or \"n\" (cancel).')\n+    overwrite = six.moves.input('[WARNING] %s already exists - overwrite? '\n+                                '[y/n]' % (filepath)).strip().lower()\n+    while overwrite not in ('y', 'n'):\n+        overwrite = six.moves.input('Enter \"y\" (overwrite) or \"n\" '\n+                                    '(cancel).').strip().lower()\n     if overwrite == 'n':\n         return False\n     print('[TIP] Next time specify overwrite=True!')\n\n@@ -8,6 +8,7 @@ from keras.layers import Dense\n from keras.utils.io_utils import HDF5Matrix\n from keras.utils.io_utils import ask_to_proceed_with_overwrite\n import numpy as np\n+import six\n import warnings\n import h5py\n try:\n@@ -106,15 +107,7 @@ def test_io_utils(in_tmpdir):\n \n \n def test_ask_to_proceed_with_overwrite():\n-    if sys.version_info[:2] <= (2, 7):\n-        with patch('__builtin__.raw_input') as mock:\n-            mock.return_value = 'y'\n-            assert ask_to_proceed_with_overwrite('/tmp/not_exists')\n-\n-            mock.return_value = 'n'\n-            assert not ask_to_proceed_with_overwrite('/tmp/not_exists')\n-    else:\n-        with patch('builtins.input') as mock:\n+    with patch('six.moves.input') as mock:\n         mock.return_value = 'y'\n         assert ask_to_proceed_with_overwrite('/tmp/not_exists')\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ad00676b80556a6354180a1bfa3009d4db316d3e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 8 | Churn Cumulative: 2874 | Contributors (this commit): 67 | Commits (past 90d): 13 | Contributors (cumulative): 67 | DMM Complexity: 1.0\n\nDIFF:\n@@ -564,8 +564,8 @@ class LearningRateScheduler(Callback):\n \n     # Arguments\n         schedule: a function that takes an epoch index as input\n-            (integer, indexed from 0) and returns a new\n-            learning rate as output (float).\n+            (integer, indexed from 0) and current learning rate\n+            and returns a new learning rate as output (float).\n         verbose: int. 0: quiet, 1: update messages.\n     \"\"\"\n \n@@ -577,6 +577,10 @@ class LearningRateScheduler(Callback):\n     def on_epoch_begin(self, epoch, logs=None):\n         if not hasattr(self.model.optimizer, 'lr'):\n             raise ValueError('Optimizer must have a \"lr\" attribute.')\n+        lr = float(K.get_value(self.model.optimizer.lr))\n+        try:  # new API\n+            lr = self.schedule(epoch, lr=lr)\n+        except TypeError:  # old API for backward compatibility\n             lr = self.schedule(epoch)\n         if not isinstance(lr, (float, np.float32, np.float64)):\n             raise ValueError('The output of the \"schedule\" function '\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4cde148de0c37981c50f3a8e4a59fa4e5f653e17", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 42 | Lines Deleted: 47 | Files Changed: 17 | Hunks: 38 | Methods Changed: 12 | Complexity Δ (Sum/Max): -1/1 | Churn Δ: 89 | Churn Cumulative: 31507 | Contributors (this commit): 221 | Commits (past 90d): 137 | Contributors (cumulative): 358 | DMM Complexity: 1.0\n\nDIFF:\n@@ -489,13 +489,18 @@ for subdir, dirs, fnames in os.walk('templates'):\n             new_fpath = fpath.replace('templates', 'sources')\n             shutil.copy(fpath, new_fpath)\n \n+\n # Take care of index page.\n-readme = open('../README.md').read()\n-index = open('templates/index.md').read()\n+def read_file(path):\n+    with open(path) as f:\n+        return f.read()\n+\n+\n+readme = read_file('../README.md')\n+index = read_file('templates/index.md')\n index = index.replace('{{autogenerated}}', readme[readme.find('##'):])\n-f = open('sources/index.md', 'w')\n+with open('sources/index.md', 'w') as f:\n     f.write(index)\n-f.close()\n \n print('Starting autogeneration.')\n for page_data in PAGES:\n@@ -564,7 +569,7 @@ for page_data in PAGES:\n     page_name = page_data['page']\n     path = os.path.join('sources', page_name)\n     if os.path.exists(path):\n-        template = open(path).read()\n+        template = read_file(path)\n         assert '{{autogenerated}}' in template, ('Template found for ' + path +\n                                                  ' but missing {{autogenerated}} tag.')\n         mkdown = template.replace('{{autogenerated}}', mkdown)\n@@ -574,6 +579,7 @@ for page_data in PAGES:\n     subdir = os.path.dirname(path)\n     if not os.path.exists(subdir):\n         os.makedirs(subdir)\n-    open(path, 'w').write(mkdown)\n+    with open(path, 'w') as f:\n+        f.write(mkdown)\n \n shutil.copyfile('../CONTRIBUTING.md', 'sources/contributing.md')\n\n@@ -100,7 +100,7 @@ except:\n           '$ wget http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2.tar.gz\\n'\n           '$ mv tasks_1-20_v1-2.tar.gz ~/.keras/datasets/babi-tasks-v1-2.tar.gz')\n     raise\n-tar = tarfile.open(path)\n+\n \n challenges = {\n     # QA1 with 10,000 samples\n@@ -112,6 +112,7 @@ challenge_type = 'single_supporting_fact_10k'\n challenge = challenges[challenge_type]\n \n print('Extracting stories for the challenge:', challenge_type)\n+with tarfile.open(path) as tar:\n     train_stories = get_stories(tar.extractfile(challenge.format('train')))\n     test_stories = get_stories(tar.extractfile(challenge.format('test')))\n \n\n@@ -160,7 +160,7 @@ except:\n           '$ wget http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2.tar.gz\\n'\n           '$ mv tasks_1-20_v1-2.tar.gz ~/.keras/datasets/babi-tasks-v1-2.tar.gz')\n     raise\n-tar = tarfile.open(path)\n+\n # Default QA1 with 1000 samples\n # challenge = 'tasks_1-20_v1-2/en/qa1_single-supporting-fact_{}.txt'\n # QA1 with 10,000 samples\n@@ -169,6 +169,7 @@ tar = tarfile.open(path)\n challenge = 'tasks_1-20_v1-2/en/qa2_two-supporting-facts_{}.txt'\n # QA2 with 10,000 samples\n # challenge = 'tasks_1-20_v1-2/en-10k/qa2_two-supporting-facts_{}.txt'\n+with tarfile.open(path) as tar:\n     train = get_stories(tar.extractfile(challenge.format('train')))\n     test = get_stories(tar.extractfile(challenge.format('test')))\n \n\n@@ -66,7 +66,8 @@ input_texts = []\n target_texts = []\n input_characters = set()\n target_characters = set()\n-lines = open(data_path, 'r', encoding='utf-8').read().split('\\n')\n+with open(data_path, 'r', encoding='utf-8') as f:\n+    lines = f.read().split('\\n')\n for line in lines[: min(num_samples, len(lines) - 1)]:\n     input_text, target_text = line.split('\\t')\n     # We use \"tab\" as the \"start sequence\" character\n\n@@ -29,7 +29,8 @@ input_texts = []\n target_texts = []\n input_characters = set()\n target_characters = set()\n-lines = open(data_path, 'r', encoding='utf-8').read().split('\\n')\n+with open(data_path, 'r', encoding='utf-8') as f:\n+    lines = f.read().split('\\n')\n for line in lines[: min(num_samples, len(lines) - 1)]:\n     input_text, target_text = line.split('\\t')\n     # We use \"tab\" as the \"start sequence\" character\n\n@@ -23,7 +23,8 @@ import sys\n import io\n \n path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n-text = io.open(path, encoding='utf-8').read().lower()\n+with io.open(path, encoding='utf-8') as f:\n+    text = f.read().lower()\n print('corpus length:', len(text))\n \n chars = sorted(list(set(text)))\n\n@@ -341,5 +341,5 @@ if __name__ == '__main__':\n         Image.fromarray(img).save(\n             'plot_epoch_{0:03d}_generated.png'.format(epoch))\n \n-    pickle.dump({'train': train_history, 'test': test_history},\n-                open('acgan-history.pkl', 'wb'))\n+    with open('acgan-history.pkl', 'wb') as f:\n+        pickle.dump({'train': train_history, 'test': test_history}, f)\n\n@@ -38,13 +38,12 @@ VALIDATION_SPLIT = 0.2\n print('Indexing word vectors.')\n \n embeddings_index = {}\n-f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'))\n+with open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt')) as f:\n     for line in f:\n         values = line.split()\n         word = values[0]\n         coefs = np.asarray(values[1:], dtype='float32')\n         embeddings_index[word] = coefs\n-f.close()\n \n print('Found %s word vectors.' % len(embeddings_index))\n \n@@ -62,16 +61,13 @@ for name in sorted(os.listdir(TEXT_DATA_DIR)):\n         for fname in sorted(os.listdir(path)):\n             if fname.isdigit():\n                 fpath = os.path.join(path, fname)\n-                if sys.version_info < (3,):\n-                    f = open(fpath)\n-                else:\n-                    f = open(fpath, encoding='latin-1')\n+                args = {} if sys.version_info < (3,) else {'encoding': 'latin-1'}\n+                with open(fpath, **args) as f:\n                     t = f.read()\n                     i = t.find('\\n\\n')  # skip header\n                     if 0 < i:\n                         t = t[i:]\n                     texts.append(t)\n-                f.close()\n                 labels.append(label_id)\n \n print('Found %s texts.' % len(texts))\n\n@@ -205,7 +205,8 @@ def decode_predictions(preds, top=5):\n                          CLASS_INDEX_PATH,\n                          cache_subdir='models',\n                          file_hash='c2c37ea517e94d9795004a39431a14cb')\n-        CLASS_INDEX = json.load(open(fpath))\n+        with open(fpath) as f:\n+            CLASS_INDEX = json.load(f)\n     results = []\n     for pred in preds:\n         top_indices = pred.argsort()[-top:][::-1]\n\n@@ -24,7 +24,8 @@ _BACKEND = 'tensorflow'\n _config_path = os.path.expanduser(os.path.join(_keras_dir, 'keras.json'))\n if os.path.exists(_config_path):\n     try:\n-        _config = json.load(open(_config_path))\n+        with open(_config_path) as f:\n+            _config = json.load(f)\n     except ValueError:\n         _config = {}\n     _floatx = _config.get('floatx', floatx())\n\n@@ -20,7 +20,7 @@ def load_batch(fpath, label_key='labels'):\n     # Returns\n         A tuple `(data, labels)`.\n     \"\"\"\n-    f = open(fpath, 'rb')\n+    with open(fpath, 'rb') as f:\n         if sys.version_info < (3,):\n             d = cPickle.load(f)\n         else:\n@@ -30,7 +30,6 @@ def load_batch(fpath, label_key='labels'):\n             for k, v in d.items():\n                 d_decoded[k.decode('utf8')] = v\n             d = d_decoded\n-    f.close()\n     data = d['data']\n     labels = d[label_key]\n \n\n@@ -114,7 +114,5 @@ def get_word_index(path='imdb_word_index.json'):\n     path = get_file(path,\n                     origin='https://s3.amazonaws.com/text-datasets/imdb_word_index.json',\n                     file_hash='bfafd718b763782e994055a2d397834f')\n-    f = open(path)\n-    data = json.load(f)\n-    f.close()\n-    return data\n+    with open(path) as f:\n+        return json.load(f)\n\n@@ -2603,10 +2603,9 @@ class Container(Layer):\n             proceed = ask_to_proceed_with_overwrite(filepath)\n             if not proceed:\n                 return\n-        f = h5py.File(filepath, 'w')\n+        with h5py.File(filepath, 'w') as f:\n             save_weights_to_hdf5_group(f, self.layers)\n             f.flush()\n-        f.close()\n \n     def load_weights(self, filepath, by_name=False,\n                      skip_mismatch=False, reshape=False):\n@@ -2641,7 +2640,7 @@ class Container(Layer):\n         \"\"\"\n         if h5py is None:\n             raise ImportError('`load_weights` requires h5py.')\n-        f = h5py.File(filepath, mode='r')\n+        with h5py.File(filepath, mode='r') as f:\n             if 'layer_names' not in f.attrs and 'model_weights' in f:\n                 f = f['model_weights']\n             if by_name:\n@@ -2652,9 +2651,6 @@ class Container(Layer):\n                 load_weights_from_hdf5_group(\n                     f, self.layers, reshape=reshape)\n \n-        if hasattr(f, 'close'):\n-            f.close()\n-\n     def _updated_config(self):\n         \"\"\"Util hared between different serialization methods.\n \n\n@@ -2027,13 +2027,12 @@ class Model(Container):\n         ```python\n             def generate_arrays_from_file(path):\n                 while 1:\n-                    f = open(path)\n+                    with open(path) as f:\n                         for line in f:\n                             # create numpy arrays of input data\n                             # and labels, from each line in the file\n                             x1, x2, y = process_line(line)\n                             yield ({'input_1': x1, 'input_2': x2}, {'output': y})\n-                    f.close()\n \n             model.fit_generator(generate_arrays_from_file('/my_file.txt'),\n                                 steps_per_epoch=10000, epochs=10)\n\n@@ -721,7 +721,7 @@ class Sequential(Model):\n     def load_weights(self, filepath, by_name=False, skip_mismatch=False, reshape=False):\n         if h5py is None:\n             raise ImportError('`load_weights` requires h5py.')\n-        f = h5py.File(filepath, mode='r')\n+        with h5py.File(filepath, mode='r') as f:\n             if 'layer_names' not in f.attrs and 'model_weights' in f:\n                 f = f['model_weights']\n \n@@ -736,8 +736,6 @@ class Sequential(Model):\n                                                               reshape=reshape)\n             else:\n                 topology.load_weights_from_hdf5_group(f, layers, reshape=reshape)\n-        if hasattr(f, 'close'):\n-            f.close()\n \n     def save_weights(self, filepath, overwrite=True):\n         if h5py is None:\n@@ -753,10 +751,9 @@ class Sequential(Model):\n         else:\n             layers = self.layers\n \n-        f = h5py.File(filepath, 'w')\n+        with h5py.File(filepath, 'w') as f:\n             topology.save_weights_to_hdf5_group(f, layers)\n             f.flush()\n-        f.close()\n \n     def compile(self, optimizer, loss,\n                 metrics=None,\n@@ -1227,13 +1224,12 @@ class Sequential(Model):\n         ```python\n             def generate_arrays_from_file(path):\n                 while 1:\n-                    f = open(path)\n+                    with open(path) as f:\n                         for line in f:\n                             # create Numpy arrays of input data\n                             # and labels, from each line in the file\n                             x, y = process_line(line)\n                             yield (x, y)\n-                    f.close()\n \n             model.fit_generator(generate_arrays_from_file('/my_file.txt'),\n                                 steps_per_epoch=1000, epochs=10)\n\n@@ -66,8 +66,7 @@ if sys.version_info[0] == 2:\n                 else:\n                     break\n \n-        response = urlopen(url, data)\n-        with open(filename, 'wb') as fd:\n+        with closing(urlopen(url, data)) as response, open(filename, 'wb') as fd:\n                 for chunk in chunk_read(response, reporthook=reporthook):\n                     fd.write(chunk)\n else:\n\n@@ -31,14 +31,13 @@ def in_tmpdir(tmpdir):\n def create_dataset(h5_path='test.h5'):\n     X = np.random.randn(200, 10).astype('float32')\n     y = np.random.randint(0, 2, size=(200, 1))\n-    f = h5py.File(h5_path, 'w')\n+    with h5py.File(h5_path, 'w') as f:\n         # Creating dataset to store features\n         X_dset = f.create_dataset('my_data', (200, 10), dtype='f')\n         X_dset[:] = X\n         # Creating dataset to store labels\n         y_dset = f.create_dataset('my_labels', (200, 1), dtype='i')\n         y_dset[:] = y\n-    f.close()\n \n \n def test_io_utils(in_tmpdir):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
