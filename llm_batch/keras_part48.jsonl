{"custom_id": "keras#78c61c65c2ed3ecc985d53d0908b86c029974b96", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 785 | Contributors (this commit): 12 | Commits (past 90d): 15 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -305,7 +305,7 @@ class Graph(Layer):\n             input = inputs[i]\n             if input in self.nodes:\n                 n = self.nodes[input]\n-                if n.__class__.__name__ = 'Siamese':\n+                if n.__class__.__name__ == 'Siamese':\n                     if n.merge_mode is None:\n                         for j in range(len(n.inputs)):\n                             sh = SiameseHead(j)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#aca4a7735ef64db812e292fb6d555cf39023ca46", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 789 | Contributors (this commit): 12 | Commits (past 90d): 16 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -4,7 +4,7 @@ from __future__ import print_function\n \n from collections import OrderedDict\n import theano.tensor as T\n-from ..layers.core import Layer, Merge\n+from ..layers.core import Layer, Merge, Siamese, SiameseHead\n from ..utils.theano_utils import ndim_tensor\n from six.moves import range\n \n@@ -317,7 +317,7 @@ class Graph(Layer):\n                 n = self.inputs[input]\n                 layers.append(n)\n             else:\n-                raise Exception('Unknown identifier: ' + n)\n+                raise Exception('Unknown identifier: ' + input)\n         s = Siamese(layer, layers, merge_mode, concat_axis=concat_axis, dot_axes=dot_axes)\n         s.set_name(name)\n         self.namespace.add(name)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cbb9d00106308508e6e0e66e8b71cc8c3af456a5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 5 | Churn Cumulative: 5529 | Contributors (this commit): 31 | Commits (past 90d): 85 | Contributors (cumulative): 31 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1234,7 +1234,10 @@ class Siamese(Layer):\n         return self.layer.get_output(train)\n \n     def get_output_shape(self, head, train=False):\n-        self.layer.set_previous(self.inputs[head])\n+        if hasattr(self.layer, 'previous'):\n+            self.layer.previous = self.inputs[head]\n+        else:\n+            self.layer.layers[0].previous = self.inputs[head]\n         return self.layer.output_shape\n \n     def get_output_join(self, train=False):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b92cec3d484b502e681c0543424a257a64b83c35", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 16 | Churn Cumulative: 5545 | Contributors (this commit): 31 | Commits (past 90d): 86 | Contributors (cumulative): 31 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1226,18 +1226,18 @@ class Siamese(Layer):\n     def get_params(self):\n         return self.params, self.regularizers, self.constraints, self.updates\n \n+    def set_layer_input(self, index):\n+        l = self.layer\n+        while not hasattr(l, 'previous'):\n+            l = l.layers[0]\n+        l.previous = self.inputs[index]\n+\n     def get_output_at(self, head, train=False):\n-        if hasattr(self.layer, 'previous'):\n-            self.layer.previous = self.inputs[head]\n-        else:\n-            self.layer.layers[0].previous = self.inputs[head]\n+        self.set_layer_input(head)\n         return self.layer.get_output(train)\n \n     def get_output_shape(self, head, train=False):\n-        if hasattr(self.layer, 'previous'):\n-            self.layer.previous = self.inputs[head]\n-        else:\n-            self.layer.layers[0].previous = self.inputs[head]\n+        self.set_layer_input(head)\n         return self.layer.output_shape\n \n     def get_output_join(self, train=False):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9c1afbb66782fe67c796fae85cd68d8f619b8aa6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 791 | Contributors (this commit): 12 | Commits (past 90d): 17 | Contributors (cumulative): 12 | DMM Complexity: 0.0\n\nDIFF:\n@@ -313,6 +313,8 @@ class Graph(Layer):\n                             layers.append(sh)\n                     else:\n                         layers.append(n)\n+                else:\n+                    layers.append(n)\n             elif input in self.inputs:\n                 n = self.inputs[input]\n                 layers.append(n)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#47ed18a3af8be20dce91286a331d4671074ee0ca", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 522 | Lines Deleted: 641 | Files Changed: 6 | Hunks: 93 | Methods Changed: 39 | Complexity Δ (Sum/Max): -123/6 | Churn Δ: 1163 | Churn Cumulative: 9634 | Contributors (this commit): 36 | Commits (past 90d): 118 | Contributors (cumulative): 47 | DMM Complexity: 0.0\n\nDIFF:\n@@ -331,10 +331,78 @@ def gradients(loss, variables):\n \n # CONTROL FLOW\n \n-def rnn(step_function, inputs, initial_states, go_backwards=False):\n-    '''TODO\n+def rnn(step_function, inputs, initial_states,\n+        go_backwards=False, masking=True):\n+    '''Iterates over the time dimension of a tensor.\n+\n+    Parameters\n+    ----------\n+    inputs: tensor of temporal data of shape (samples, time, ...)\n+        (at least 3D).\n+    step_function:\n+        Parameters:\n+            input: tensor with shape (samples, ...) (no time dimension),\n+                representing input for the batch of samples at a certain\n+                time step.\n+            states: list of tensors.\n+        Returns:\n+            output: tensor with shape (samples, ...) (no time dimension),\n+            new_states: list of tensors, same length and shapes\n+                as 'states'.\n+    initial_states: tensor with shape (samples, ...) (no time dimension),\n+        containing the initial values for the states used in\n+        the step function.\n+    go_backwards: boolean. If True, do the iteration over\n+        the time dimension in reverse order.\n+    masking: boolean. If true, any input timestep inputs[s, i]\n+        that is all-zeros will be skipped (states will be passed to\n+        the next step unchanged) and the corresponding output will\n+        be all zeros.\n+\n+    Returns\n+    -------\n+    A tuple (last_output, outputs, new_states).\n+        last_output: the latest output of the rnn, of shape (samples, ...)\n+        outputs: tensor with shape (samples, time, ...) where each\n+            entry outputs[s, t] is the output of the step function\n+            at time t for sample s.\n+        new_states: list of tensors, latest states returned by\n+            the step function, of shape (samples, ...).\n     '''\n-    pass\n+    inputs = tf.transpose(inputs, (1, 0, 2))\n+    input_list = tf.unpack(inputs)\n+\n+    states = initial_states\n+    successive_states = []\n+    successive_outputs = []\n+    if go_backwards:\n+        input_list = input_list.reverse()\n+    for input in input_list:\n+        output, new_states = step_function(input, states)\n+        if masking:\n+            # if all-zero input timestep, return\n+            # all-zero output and unchanged states\n+            switch = tf.reduce_any(input)\n+            output = tf.control_flow_ops.cond(switch,\n+                                              lambda: output,\n+                                              lambda: 0. * output)\n+            return_states = []\n+            for state, new_state in zip(states, new_states):\n+                return_states.append(tf.control_flow_ops.cond(switch,\n+                                                              lambda: new_state,\n+                                                              lambda: state))\n+            states = return_states\n+        else:\n+            states = new_states\n+        successive_outputs.append(output)\n+        successive_states.append(states)\n+\n+    last_output = successive_outputs[-1]\n+    outputs = tf.pack(successive_outputs)\n+    new_states = successive_states[-1]\n+\n+    outputs = tf.transpose(outputs, (1, 0, 2))\n+    return last_output, outputs, states\n \n \n def switch(condition, then_expression, else_expression):\n@@ -442,6 +510,11 @@ def conv2d(x, kernel, strides=(1, 1), border_mode='valid', dim_ordering='th'):\n \n     strides = (1,) + strides + (1,)\n \n+    if _FLOATX == 'float64':\n+        # tf conv2d only supports float32\n+        x = tf.cast(x, 'float32')\n+        kernel = tf.cast(kernel, 'float32')\n+\n     if dim_ordering == 'th':\n         # TF uses the last dimension as channel dimension,\n         # instead of the 2nd one.\n@@ -457,6 +530,9 @@ def conv2d(x, kernel, strides=(1, 1), border_mode='valid', dim_ordering='th'):\n         x = tf.nn.conv2d(x, kernel, strides, padding=padding)\n     else:\n         raise Exception('Unknown dim_ordering: ' + str(dim_ordering))\n+\n+    if _FLOATX == 'float64':\n+        x = tf.cast(x, 'float64')\n     return x\n \n \n@@ -478,6 +554,10 @@ def maxpool2d(x, pool_size, strides=(1, 1),\n     strides = (1,) + strides + (1,)\n     pool_size = (1,) + pool_size + (1,)\n \n+    if _FLOATX == 'float64':\n+        # tf max_pool only supports float32\n+        x = tf.cast(x, 'float32')\n+\n     if dim_ordering == 'th':\n         # TF uses the last dimension as channel dimension,\n         # instead of the 2nd one.\n@@ -492,6 +572,9 @@ def maxpool2d(x, pool_size, strides=(1, 1),\n         x = tf.nn.max_pool(x, pool_size, strides, padding=padding)\n     else:\n         raise Exception('Unknown dim_ordering: ' + str(dim_ordering))\n+\n+    if _FLOATX == 'float64':\n+        x = tf.cast(x, 'float64')\n     return x\n \n \n\n@@ -353,12 +353,83 @@ def gradients(loss, variables):\n \n # CONTROL FLOW\n \n-def rnn(step_function, inputs, initial_states, go_backwards=False):\n-    '''TODO\n+def rnn(step_function, inputs, initial_states,\n+        go_backwards=False, masking=True):\n+    '''Iterates over the time dimension of a tensor.\n \n-    Wrapper for scan\n+    Parameters\n+    ----------\n+    inputs: tensor of temporal data of shape (samples, time, ...)\n+        (at least 3D).\n+    step_function:\n+        Parameters:\n+            input: tensor with shape (samples, ...) (no time dimension),\n+                representing input for the batch of samples at a certain\n+                time step.\n+            states: list of tensors.\n+        Returns:\n+            output: tensor with shape (samples, ...) (no time dimension),\n+            new_states: list of tensors, same length and shapes\n+                as 'states'.\n+    initial_states: tensor with shape (samples, ...) (no time dimension),\n+        containing the initial values for the states used in\n+        the step function.\n+    go_backwards: boolean. If True, do the iteration over\n+        the time dimension in reverse order.\n+    masking: boolean. If true, any input timestep inputs[s, i]\n+        that is all-zeros will be skipped (states will be passed to\n+        the next step unchanged) and the corresponding output will\n+        be all zeros.\n+\n+    Returns\n+    -------\n+    A tuple (last_output, outputs, new_states).\n+        last_output: the latest output of the rnn, of shape (samples, ...)\n+        outputs: tensor with shape (samples, time, ...) where each\n+            entry outputs[s, t] is the output of the step function\n+            at time t for sample s.\n+        new_states: list of tensors, latest states returned by\n+            the step function, of shape (samples, ...).\n     '''\n-    pass\n+    inputs = inputs.dimshuffle((1, 0, 2))\n+\n+    def _step(*args):\n+        global single_result\n+        input = args[0]\n+        states = args[1:]\n+        output, new_states = step_function(input, states)\n+        if masking:\n+            # if all-zero input timestep, return\n+            # all-zero output and unchanged states\n+            switch = T.any(input)\n+            output = T.switch(switch, output, 0. * output)\n+            return_states = []\n+            for state, new_state in zip(states, new_states):\n+                return_states.append(T.switch(switch, new_state, state))\n+            return [output] + return_states\n+        else:\n+            return [output] + new_states\n+\n+    results, _ = theano.scan(\n+        _step,\n+        sequences=inputs,\n+        outputs_info=[None] + initial_states,\n+        go_backwards=go_backwards)\n+\n+    # deal with Theano API inconsistency\n+    if type(results) is list:\n+        outputs = results[0]\n+        states = results[1:]\n+    else:\n+        outputs = results\n+        states = []\n+\n+    outputs = T.squeeze(outputs)\n+    last_output = outputs[-1]\n+\n+    outputs = outputs.dimshuffle((1, 0, 2))\n+    states = [T.squeeze(state[-1]) for state in states]\n+    return last_output, outputs, states\n \n \n def switch(condition, then_expression, else_expression):\n\n@@ -782,9 +782,15 @@ class TimeDistributedDense(MaskedLayer):\n \n     def get_output(self, train=False):\n         X = self.get_input(train)\n-        output = self.activation(K.dot(K.permute_dimensions(X, (1, 0, 2)),\n-                                       self.W) + self.b)\n-        return K.permute_dimensions(output, (1, 0, 2))\n+\n+        def step(x, states):\n+            output = K.dot(x, self.W) + self.b\n+            return output, []\n+\n+        last_output, outputs, states = K.rnn(step, X, [], masking=False)\n+\n+        outputs = self.activation(outputs)\n+        return outputs\n \n     def get_config(self):\n         config = {\"name\": self.__class__.__name__,\n\n@@ -1,42 +1,36 @@\n # -*- coding: utf-8 -*-\n from __future__ import absolute_import\n-import theano\n-import theano.tensor as T\n import numpy as np\n \n+from .. import backend as K\n from .. import activations, initializations\n-from ..utils.theano_utils import shared_scalar, shared_zeros, alloc_zeros_matrix\n-from ..layers.core import Layer, MaskedLayer\n-from six.moves import range\n+from ..layers.core import MaskedLayer\n \n \n class Recurrent(MaskedLayer):\n     input_ndim = 3\n \n-    def get_output_mask(self, train=None):\n+    def __init__(self, weights=None,\n+                 return_sequences=False, input_dim=None,\n+                 input_length=None, go_backwards=False,\n+                 stateful=False, **kwargs):\n+        self.return_sequences = return_sequences\n+        self.initial_weights = weights\n+        self.go_backwards = go_backwards\n+        self.stateful = stateful\n+\n+        self.input_dim = input_dim\n+        self.input_length = input_length\n+        if self.input_dim:\n+            kwargs['input_shape'] = (self.input_length, self.input_dim)\n+        super(Recurrent, self).__init__(**kwargs)\n+\n+    def get_output_mask(self, train=False):\n         if self.return_sequences:\n             return super(Recurrent, self).get_output_mask(train)\n         else:\n             return None\n \n-    def get_padded_shuffled_mask(self, train, X, pad=0):\n-        mask = self.get_input_mask(train)\n-        if mask is None:\n-            mask = T.ones_like(X.sum(axis=-1))  # is there a better way to do this without a sum?\n-\n-        # TODO: reimplement\n-        # mask is (nb_samples, time)\n-        mask = T.shape_padright(mask)  # (nb_samples, time, 1)\n-        mask = T.addbroadcast(mask, -1)  # the new dimension (the '1') is made broadcastable\n-        # see http://deeplearning.net/software/theano/library/tensor/basic.html#broadcasting-in-theano-vs-numpy\n-        mask = mask.dimshuffle(1, 0, 2)  # (time, nb_samples, 1)\n-\n-        if pad > 0:\n-            # left-pad in time with 0\n-            padding = alloc_zeros_matrix(pad, mask.shape[1], 1)\n-            mask = T.concatenate([padding, mask], axis=0)\n-        return mask.astype('int8')\n-\n     @property\n     def output_shape(self):\n         input_shape = self.input_shape\n@@ -45,193 +39,118 @@ class Recurrent(MaskedLayer):\n         else:\n             return (input_shape[0], self.output_dim)\n \n+    def step(self, x, states):\n+        raise NotImplementedError\n+\n+    def get_output(self, train=False):\n+        # input shape: (nb_samples, time (padded with zeros), input_dim)\n+        X = self.get_input(train)\n+        assert K.ndim(X) == 3\n+\n+        mask = self.get_output_mask(train)\n+        if mask:\n+            # apply mask\n+            X *= K.expand_dims(mask)\n+            masking = True\n+        else:\n+            masking = False\n+\n+        if self.stateful:\n+            initial_states = self.states\n+        else:\n+            # build an all-zero tensor of shape (samples, output_dim)\n+            initial_state = K.zeros_like(X)  # (samples, timesteps, input_dim)\n+            initial_state = K.sum(initial_state, axis=1)  # (samples, input_dim)\n+            reducer = K.zeros((self.input_dim, self.output_dim))\n+            initial_state = K.dot(initial_state, reducer)  # (samples, output_dim)\n+            initial_states = [initial_state for _ in range(len(self.states))]\n+        last_output, outputs, states = K.rnn(self.step, X, initial_states,\n+                                             go_backwards=self.go_backwards,\n+                                             masking=masking)\n+        if self.stateful:\n+            for i in range(len(states)):\n+                K.set_value(self.states[i], states[i])\n+\n+        if self.return_sequences:\n+            return outputs\n+        else:\n+            return last_output\n+\n+    def get_config(self):\n+        config = {\"name\": self.__class__.__name__,\n+                  \"return_sequences\": self.return_sequences,\n+                  \"input_dim\": self.input_dim,\n+                  \"input_length\": self.input_length,\n+                  \"go_backwards\": self.go_backwards,\n+                  \"stateful\": self.stateful}\n+        base_config = super(Recurrent, self).get_config()\n+        return dict(list(base_config.items()) + list(config.items()))\n+\n \n class SimpleRNN(Recurrent):\n     '''\n-        Fully connected RNN where output is to fed back to input.\n+        Fully-connected RNN where the output is to fed back to input.\n \n-        Not a particularly useful model,\n-        included for demonstration purposes\n-        (demonstrates how to use theano.scan to build a basic RNN).\n+        Takes inputs with shape:\n+        (nb_samples, max_sample_length, input_dim)\n+        (samples shorter than `max_sample_length`\n+         are padded with zeros at the end)\n+\n+        and returns outputs with shape:\n+        if not return_sequences:\n+            (nb_samples, output_dim)\n+        if return_sequences:\n+            (nb_samples, max_sample_length, output_dim)\n     '''\n     def __init__(self, output_dim,\n-                 init='glorot_uniform', inner_init='orthogonal', activation='sigmoid', weights=None,\n-                 truncate_gradient=-1, return_sequences=False, input_dim=None,\n-                 input_length=None, go_backwards=False, **kwargs):\n+                 init='glorot_uniform', inner_init='orthogonal',\n+                 activation='sigmoid', **kwargs):\n         self.output_dim = output_dim\n         self.init = initializations.get(init)\n         self.inner_init = initializations.get(inner_init)\n-        self.truncate_gradient = truncate_gradient\n         self.activation = activations.get(activation)\n-        self.return_sequences = return_sequences\n-        self.initial_weights = weights\n-        self.go_backwards = go_backwards\n-\n-        self.input_dim = input_dim\n-        self.input_length = input_length\n-        if self.input_dim:\n-            kwargs['input_shape'] = (self.input_length, self.input_dim)\n         super(SimpleRNN, self).__init__(**kwargs)\n \n     def build(self):\n-        input_dim = self.input_shape[2]\n-        self.input = T.tensor3()\n+        input_shape = self.input_shape\n+        if self.stateful:\n+            if not input_shape[0]:\n+                raise Exception('If a RNN is stateful, a complete ' +\n+                                'input_shape must be provided ' +\n+                                '(including batch size).')\n+            self.states = [K.zeros(input_shape[0], self.output_dim)]\n+        else:\n+            # initial states: all-zero tensor of shape (output_dim)\n+            self.states = [None]\n+        input_dim = input_shape[2]\n+        self.input_dim = input_dim\n \n         self.W = self.init((input_dim, self.output_dim))\n         self.U = self.inner_init((self.output_dim, self.output_dim))\n-        self.b = shared_zeros((self.output_dim))\n+        self.b = K.zeros((self.output_dim))\n         self.params = [self.W, self.U, self.b]\n \n         if self.initial_weights is not None:\n             self.set_weights(self.initial_weights)\n             del self.initial_weights\n \n-    def _step(self, x_t, mask_tm1, h_tm1, u):\n-        '''\n-            Variable names follow the conventions from:\n-            http://deeplearning.net/software/theano/library/scan.html\n-\n-        '''\n-        return self.activation(x_t + mask_tm1 * T.dot(h_tm1, u))\n-\n-    def get_output(self, train=False):\n-        X = self.get_input(train)  # shape: (nb_samples, time (padded with zeros), input_dim)\n-        # new shape: (time, nb_samples, input_dim) -> because theano.scan iterates over main dimension\n-        padded_mask = self.get_padded_shuffled_mask(train, X, pad=1)\n-        X = X.dimshuffle((1, 0, 2))\n-        x = T.dot(X, self.W) + self.b\n-\n-        # scan = theano symbolic loop.\n-        # See: http://deeplearning.net/software/theano/library/scan.html\n-        # Iterate over the first dimension of the x array (=time).\n-        outputs, updates = theano.scan(\n-            self._step,  # this will be called with arguments (sequences[i], outputs[i-1], non_sequences[i])\n-            sequences=[x, dict(input=padded_mask, taps=[-1])],  # tensors to iterate over, inputs to _step\n-            # initialization of the output. Input to _step with default tap=-1.\n-            outputs_info=T.unbroadcast(alloc_zeros_matrix(X.shape[1], self.output_dim), 1),\n-            non_sequences=self.U,  # static inputs to _step\n-            truncate_gradient=self.truncate_gradient,\n-            go_backwards=self.go_backwards)\n-\n-        if self.return_sequences:\n-            return outputs.dimshuffle((1, 0, 2))\n-        return outputs[-1]\n+    def step(self, x, states):\n+        # states only contains the previous output.\n+        assert len(states) == 1\n+        prev_output = states[0]\n+        h = K.dot(x, self.W) + self.b\n+        output = self.activation(h * K.dot(prev_output, self.U))\n+        return output, [output]\n \n     def get_config(self):\n-        config = {\"name\": self.__class__.__name__,\n-                  \"output_dim\": self.output_dim,\n+        config = {\"output_dim\": self.output_dim,\n                   \"init\": self.init.__name__,\n                   \"inner_init\": self.inner_init.__name__,\n-                  \"activation\": self.activation.__name__,\n-                  \"truncate_gradient\": self.truncate_gradient,\n-                  \"return_sequences\": self.return_sequences,\n-                  \"input_dim\": self.input_dim,\n-                  \"input_length\": self.input_length,\n-                  \"go_backwards\": self.go_backwards}\n+                  \"activation\": self.activation.__name__}\n         base_config = super(SimpleRNN, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n \n \n-class SimpleDeepRNN(Recurrent):\n-    '''\n-        Fully connected RNN where the output of multiple timesteps\n-        (up to \"depth\" steps in the past) is fed back to the input:\n-\n-        output = activation( W.x_t + b + inner_activation(U_1.h_tm1) + inner_activation(U_2.h_tm2) + ... )\n-\n-        This demonstrates how to build RNNs with arbitrary lookback.\n-        Also (probably) not a super useful model.\n-    '''\n-    def __init__(self, output_dim, depth=3,\n-                 init='glorot_uniform', inner_init='orthogonal',\n-                 activation='sigmoid', inner_activation='hard_sigmoid',\n-                 weights=None, truncate_gradient=-1, return_sequences=False,\n-                 input_dim=None, input_length=None, go_backwards=False, **kwargs):\n-        self.output_dim = output_dim\n-        self.init = initializations.get(init)\n-        self.inner_init = initializations.get(inner_init)\n-        self.truncate_gradient = truncate_gradient\n-        self.activation = activations.get(activation)\n-        self.inner_activation = activations.get(inner_activation)\n-        self.depth = depth\n-        self.return_sequences = return_sequences\n-        self.initial_weights = weights\n-        self.go_backwards = go_backwards\n-\n-        self.input_dim = input_dim\n-        self.input_length = input_length\n-        if self.input_dim:\n-            kwargs['input_shape'] = (self.input_length, self.input_dim)\n-        super(SimpleDeepRNN, self).__init__(**kwargs)\n-\n-    def build(self):\n-        input_dim = self.input_shape[2]\n-        self.input = T.tensor3()\n-        self.W = self.init((input_dim, self.output_dim))\n-        self.Us = [self.inner_init((self.output_dim, self.output_dim)) for _ in range(self.depth)]\n-        self.b = shared_zeros((self.output_dim))\n-        self.params = [self.W] + self.Us + [self.b]\n-\n-        if self.initial_weights is not None:\n-            self.set_weights(self.initial_weights)\n-            del self.initial_weights\n-\n-    def _step(self, x_t, *args):\n-        o = x_t\n-        for i in range(self.depth):\n-            mask_tmi = args[i]\n-            h_tmi = args[i + self.depth]\n-            U_tmi = args[i + 2*self.depth]\n-            o += mask_tmi*self.inner_activation(T.dot(h_tmi, U_tmi))\n-        return self.activation(o)\n-\n-    def get_output(self, train=False):\n-        X = self.get_input(train)\n-        padded_mask = self.get_padded_shuffled_mask(train, X, pad=self.depth)\n-        X = X.dimshuffle((1, 0, 2))\n-\n-        x = T.dot(X, self.W) + self.b\n-\n-        if self.depth == 1:\n-            initial = T.unbroadcast(alloc_zeros_matrix(X.shape[1], self.output_dim), 1)\n-        else:\n-            initial = T.unbroadcast(T.unbroadcast(alloc_zeros_matrix(self.depth, X.shape[1], self.output_dim), 0), 2)\n-\n-        outputs, updates = theano.scan(\n-            self._step,\n-            sequences=[x, dict(\n-                input=padded_mask,\n-                taps=[(-i) for i in range(self.depth)]\n-            )],\n-            outputs_info=[dict(\n-                initial=initial,\n-                taps=[(-i-1) for i in range(self.depth)]\n-            )],\n-            non_sequences=self.Us,\n-            truncate_gradient=self.truncate_gradient,\n-            go_backwards=self.go_backwards)\n-\n-        if self.return_sequences:\n-            return outputs.dimshuffle((1, 0, 2))\n-        return outputs[-1]\n-\n-    def get_config(self):\n-        config = {\"name\": self.__class__.__name__,\n-                  \"output_dim\": self.output_dim,\n-                  \"depth\": self.depth,\n-                  \"init\": self.init.__name__,\n-                  \"inner_init\": self.inner_init.__name__,\n-                  \"activation\": self.activation.__name__,\n-                  \"inner_activation\": self.inner_activation.__name__,\n-                  \"truncate_gradient\": self.truncate_gradient,\n-                  \"return_sequences\": self.return_sequences,\n-                  \"input_dim\": self.input_dim,\n-                  \"input_length\": self.input_length,\n-                  \"go_backwards\": self.go_backwards}\n-        base_config = super(SimpleDeepRNN, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n class GRU(Recurrent):\n     '''\n         Gated Recurrent Unit - Cho et al. 2014\n@@ -239,8 +158,10 @@ class GRU(Recurrent):\n         Acts as a spatiotemporal projection,\n         turning a sequence of vectors into a single vector.\n \n-        Eats inputs with shape:\n-        (nb_samples, max_sample_length (samples shorter than this are padded with zeros at the end), input_dim)\n+        Takes inputs with shape:\n+        (nb_samples, max_sample_length, input_dim)\n+        (samples shorter than `max_sample_length`\n+         are padded with zeros at the end)\n \n         and returns outputs with shape:\n         if not return_sequences:\n@@ -249,101 +170,80 @@ class GRU(Recurrent):\n             (nb_samples, max_sample_length, output_dim)\n \n         References:\n-            On the Properties of Neural Machine Translation: Encoder–Decoder Approaches\n+            On the Properties of Neural Machine Translation:\n+            Encoder–Decoder Approaches\n                 http://www.aclweb.org/anthology/W14-4012\n-            Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling\n+            Empirical Evaluation of Gated Recurrent Neural Networks\n+            on Sequence Modeling\n                 http://arxiv.org/pdf/1412.3555v1.pdf\n     '''\n     def __init__(self, output_dim,\n                  init='glorot_uniform', inner_init='orthogonal',\n                  activation='sigmoid', inner_activation='hard_sigmoid',\n-                 weights=None, truncate_gradient=-1, return_sequences=False,\n-                 input_dim=None, input_length=None, go_backwards=False, **kwargs):\n+                 **kwargs):\n         self.output_dim = output_dim\n         self.init = initializations.get(init)\n         self.inner_init = initializations.get(inner_init)\n         self.activation = activations.get(activation)\n         self.inner_activation = activations.get(inner_activation)\n-        self.truncate_gradient = truncate_gradient\n-        self.return_sequences = return_sequences\n-        self.initial_weights = weights\n-        self.go_backwards = go_backwards\n-\n-        self.input_dim = input_dim\n-        self.input_length = input_length\n-        if self.input_dim:\n-            kwargs['input_shape'] = (self.input_length, self.input_dim)\n         super(GRU, self).__init__(**kwargs)\n \n     def build(self):\n-        input_dim = self.input_shape[2]\n-        self.input = T.tensor3()\n+        input_shape = self.input_shape\n+        input_dim = input_shape[2]\n+        self.input_dim = input_dim\n+        self.input = K.placeholder(input_shape)\n \n         self.W_z = self.init((input_dim, self.output_dim))\n         self.U_z = self.inner_init((self.output_dim, self.output_dim))\n-        self.b_z = shared_zeros((self.output_dim))\n+        self.b_z = K.zeros((self.output_dim,))\n \n         self.W_r = self.init((input_dim, self.output_dim))\n         self.U_r = self.inner_init((self.output_dim, self.output_dim))\n-        self.b_r = shared_zeros((self.output_dim))\n+        self.b_r = K.zeros((self.output_dim,))\n \n         self.W_h = self.init((input_dim, self.output_dim))\n         self.U_h = self.inner_init((self.output_dim, self.output_dim))\n-        self.b_h = shared_zeros((self.output_dim))\n+        self.b_h = K.zeros((self.output_dim,))\n \n-        self.params = [\n-            self.W_z, self.U_z, self.b_z,\n+        self.params = [self.W_z, self.U_z, self.b_z,\n                        self.W_r, self.U_r, self.b_r,\n-            self.W_h, self.U_h, self.b_h,\n-        ]\n+                       self.W_h, self.U_h, self.b_h]\n+\n+        if self.stateful:\n+            if not input_shape[0]:\n+                raise Exception('If a RNN is stateful, a complete ' +\n+                                'input_shape must be provided ' +\n+                                '(including batch size).')\n+            self.states = [K.zeros(input_shape[0], self.output_dim)]\n+        else:\n+            # initial states: all-zero tensor of shape (output_dim)\n+            self.states = [None]\n \n         if self.initial_weights is not None:\n             self.set_weights(self.initial_weights)\n             del self.initial_weights\n \n-    def _step(self,\n-              xz_t, xr_t, xh_t, mask_tm1,\n-              h_tm1,\n-              u_z, u_r, u_h):\n-        h_mask_tm1 = mask_tm1 * h_tm1\n-        z = self.inner_activation(xz_t + T.dot(h_mask_tm1, u_z))\n-        r = self.inner_activation(xr_t + T.dot(h_mask_tm1, u_r))\n-        hh_t = self.activation(xh_t + T.dot(r * h_mask_tm1, u_h))\n-        h_t = z * h_mask_tm1 + (1 - z) * hh_t\n-        return h_t\n+    def step(self, x, states):\n+        assert len(states) == 1\n+        x_z = K.dot(x, self.W_z) + self.b_z\n+        x_r = K.dot(x, self.W_r) + self.b_r\n+        x_h = K.dot(x, self.W_h) + self.b_h\n \n-    def get_output(self, train=False):\n-        X = self.get_input(train)\n-        padded_mask = self.get_padded_shuffled_mask(train, X, pad=1)\n-        X = X.dimshuffle((1, 0, 2))\n+        h_tm1 = states[0]\n+        z = self.inner_activation(x_z + K.dot(h_tm1, self.U_z))\n+        r = self.inner_activation(x_r + K.dot(h_tm1, self.U_r))\n \n-        x_z = T.dot(X, self.W_z) + self.b_z\n-        x_r = T.dot(X, self.W_r) + self.b_r\n-        x_h = T.dot(X, self.W_h) + self.b_h\n-        outputs, updates = theano.scan(\n-            self._step,\n-            sequences=[x_z, x_r, x_h, padded_mask],\n-            outputs_info=T.unbroadcast(alloc_zeros_matrix(X.shape[1], self.output_dim), 1),\n-            non_sequences=[self.U_z, self.U_r, self.U_h],\n-            truncate_gradient=self.truncate_gradient,\n-            go_backwards=self.go_backwards)\n-\n-        if self.return_sequences:\n-            return outputs.dimshuffle((1, 0, 2))\n-        return outputs[-1]\n+        hh = self.inner_activation(x_h + K.dot(r * h_tm1, self.U_h))\n+        h = z * h_tm1 + (1 - z) * hh\n+        return h, [h]\n \n     def get_config(self):\n-        config = {\"name\": self.__class__.__name__,\n-                  \"output_dim\": self.output_dim,\n+        config = {\"output_dim\": self.output_dim,\n                   \"init\": self.init.__name__,\n                   \"inner_init\": self.inner_init.__name__,\n                   \"activation\": self.activation.__name__,\n-                  \"inner_activation\": self.inner_activation.__name__,\n-                  \"truncate_gradient\": self.truncate_gradient,\n-                  \"return_sequences\": self.return_sequences,\n-                  \"input_dim\": self.input_dim,\n-                  \"input_length\": self.input_length,\n-                  \"go_backwards\": self.go_backwards}\n+                  \"inner_activation\": self.inner_activation.__name__}\n         base_config = super(GRU, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n \n@@ -353,8 +253,10 @@ class LSTM(Recurrent):\n         Acts as a spatiotemporal projection,\n         turning a sequence of vectors into a single vector.\n \n-        Eats inputs with shape:\n-        (nb_samples, max_sample_length (samples shorter than this are padded with zeros at the end), input_dim)\n+        Takes inputs with shape:\n+        (nb_samples, max_sample_length, input_dim)\n+        (samples shorter than `max_sample_length`\n+         are padded with zeros at the end)\n \n         and returns outputs with shape:\n         if not return_sequences:\n@@ -374,34 +276,37 @@ class LSTM(Recurrent):\n                 http://www.cs.toronto.edu/~graves/preprint.pdf\n     '''\n     def __init__(self, output_dim,\n-                 init='glorot_uniform', inner_init='orthogonal', forget_bias_init='one',\n-                 activation='tanh', inner_activation='hard_sigmoid',\n-                 weights=None, truncate_gradient=-1, return_sequences=False,\n-                 input_dim=None, input_length=None, go_backwards=False, **kwargs):\n+                 init='glorot_uniform', inner_init='orthogonal',\n+                 forget_bias_init='one', activation='tanh',\n+                 inner_activation='hard_sigmoid', **kwargs):\n         self.output_dim = output_dim\n         self.init = initializations.get(init)\n         self.inner_init = initializations.get(inner_init)\n         self.forget_bias_init = initializations.get(forget_bias_init)\n         self.activation = activations.get(activation)\n         self.inner_activation = activations.get(inner_activation)\n-        self.truncate_gradient = truncate_gradient\n-        self.return_sequences = return_sequences\n-        self.initial_weights = weights\n-        self.go_backwards = go_backwards\n-\n-        self.input_dim = input_dim\n-        self.input_length = input_length\n-        if self.input_dim:\n-            kwargs['input_shape'] = (self.input_length, self.input_dim)\n         super(LSTM, self).__init__(**kwargs)\n \n     def build(self):\n-        input_dim = self.input_shape[2]\n-        self.input = T.tensor3()\n+        input_shape = self.input_shape\n+        input_dim = input_shape[2]\n+        self.input_dim = input_dim\n+        self.input = K.placeholder(input_shape)\n+\n+        if self.stateful:\n+            if not input_shape[0]:\n+                raise Exception('If a RNN is stateful, a complete ' +\n+                                'input_shape must be provided ' +\n+                                '(including batch size).')\n+            self.states = [K.zeros(input_shape[0], self.output_dim),\n+                           K.zeros(input_shape[0], self.output_dim)]\n+        else:\n+            # initial states: 2 all-zero tensor of shape (output_dim)\n+            self.states = [None, None]\n \n         self.W_i = self.init((input_dim, self.output_dim))\n         self.U_i = self.inner_init((self.output_dim, self.output_dim))\n-        self.b_i = shared_zeros((self.output_dim))\n+        self.b_i = K.zeros((self.output_dim))\n \n         self.W_f = self.init((input_dim, self.output_dim))\n         self.U_f = self.inner_init((self.output_dim, self.output_dim))\n@@ -409,94 +314,55 @@ class LSTM(Recurrent):\n \n         self.W_c = self.init((input_dim, self.output_dim))\n         self.U_c = self.inner_init((self.output_dim, self.output_dim))\n-        self.b_c = shared_zeros((self.output_dim))\n+        self.b_c = K.zeros((self.output_dim))\n \n         self.W_o = self.init((input_dim, self.output_dim))\n         self.U_o = self.inner_init((self.output_dim, self.output_dim))\n-        self.b_o = shared_zeros((self.output_dim))\n+        self.b_o = K.zeros((self.output_dim))\n \n-        self.params = [\n-            self.W_i, self.U_i, self.b_i,\n+        self.params = [self.W_i, self.U_i, self.b_i,\n                        self.W_c, self.U_c, self.b_c,\n                        self.W_f, self.U_f, self.b_f,\n-            self.W_o, self.U_o, self.b_o,\n-        ]\n+                       self.W_o, self.U_o, self.b_o]\n \n         if self.initial_weights is not None:\n             self.set_weights(self.initial_weights)\n             del self.initial_weights\n \n-    def _step(self,\n-              xi_t, xf_t, xo_t, xc_t, mask_tm1,\n-              h_tm1, c_tm1,\n-              u_i, u_f, u_o, u_c):\n-        h_mask_tm1 = mask_tm1 * h_tm1\n-        c_mask_tm1 = mask_tm1 * c_tm1\n+    def step(self, x, states):\n+        assert len(states) == 2\n+        h_tm1 = states[0]\n+        c_tm1 = states[1]\n \n-        i_t = self.inner_activation(xi_t + T.dot(h_mask_tm1, u_i))\n-        f_t = self.inner_activation(xf_t + T.dot(h_mask_tm1, u_f))\n-        c_t = f_t * c_mask_tm1 + i_t * self.activation(xc_t + T.dot(h_mask_tm1, u_c))\n-        o_t = self.inner_activation(xo_t + T.dot(h_mask_tm1, u_o))\n-        h_t = o_t * self.activation(c_t)\n-        return h_t, c_t\n+        x_i = K.dot(x, self.W_i) + self.b_i\n+        x_f = K.dot(x, self.W_f) + self.b_f\n+        x_c = K.dot(x, self.W_c) + self.b_c\n+        x_o = K.dot(x, self.W_o) + self.b_o\n \n-    def get_output(self, train=False):\n-        X = self.get_input(train)\n-        padded_mask = self.get_padded_shuffled_mask(train, X, pad=1)\n-        X = X.dimshuffle((1, 0, 2))\n-\n-        xi = T.dot(X, self.W_i) + self.b_i\n-        xf = T.dot(X, self.W_f) + self.b_f\n-        xc = T.dot(X, self.W_c) + self.b_c\n-        xo = T.dot(X, self.W_o) + self.b_o\n-\n-        [outputs, memories], updates = theano.scan(\n-            self._step,\n-            sequences=[xi, xf, xo, xc, padded_mask],\n-            outputs_info=[\n-                T.unbroadcast(alloc_zeros_matrix(X.shape[1], self.output_dim), 1),\n-                T.unbroadcast(alloc_zeros_matrix(X.shape[1], self.output_dim), 1)\n-            ],\n-            non_sequences=[self.U_i, self.U_f, self.U_o, self.U_c],\n-            truncate_gradient=self.truncate_gradient,\n-            go_backwards=self.go_backwards)\n-\n-        if self.return_sequences:\n-            return outputs.dimshuffle((1, 0, 2))\n-        return outputs[-1]\n+        i = self.inner_activation(x_i + K.dot(h_tm1, self.U_i))\n+        f = self.inner_activation(x_f + K.dot(h_tm1, self.U_f))\n+        c = f * c_tm1 + i * self.activation(x_c + K.dot(h_tm1, self.U_c))\n+        o = self.inner_activation(x_o + K.dot(h_tm1, self.U_o))\n+        h = o * self.activation(c)\n+        return h, [h, c]\n \n     def get_config(self):\n-        config = {\"name\": self.__class__.__name__,\n-                  \"output_dim\": self.output_dim,\n+        config = {\"output_dim\": self.output_dim,\n                   \"init\": self.init.__name__,\n                   \"inner_init\": self.inner_init.__name__,\n                   \"forget_bias_init\": self.forget_bias_init.__name__,\n                   \"activation\": self.activation.__name__,\n-                  \"inner_activation\": self.inner_activation.__name__,\n-                  \"truncate_gradient\": self.truncate_gradient,\n-                  \"return_sequences\": self.return_sequences,\n-                  \"input_dim\": self.input_dim,\n-                  \"input_length\": self.input_length,\n-                  \"go_backwards\": self.go_backwards}\n+                  \"inner_activation\": self.inner_activation.__name__}\n         base_config = super(LSTM, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n \n \n-class JZS1(Recurrent):\n+class JZS(Recurrent):\n     '''\n-        Evolved recurrent neural network architectures from the evaluation of thousands\n-        of models, serving as alternatives to LSTMs and GRUs. See Jozefowicz et al. 2015.\n-\n-        This corresponds to the `MUT1` architecture described in the paper.\n-\n-        Takes inputs with shape:\n-        (nb_samples, max_sample_length (samples shorter than this are padded with zeros at the end), input_dim)\n-\n-        and returns outputs with shape:\n-        if not return_sequences:\n-            (nb_samples, output_dim)\n-        if return_sequences:\n-            (nb_samples, max_sample_length, output_dim)\n+        Evolved recurrent neural network architectures\n+        from the evaluation of thousands\n+        of models, serving as alternatives to LSTMs and GRUs.\n+        See Jozefowicz et al. 2015.\n \n         References:\n             An Empirical Exploration of Recurrent Network Architectures\n@@ -505,334 +371,146 @@ class JZS1(Recurrent):\n     def __init__(self, output_dim,\n                  init='glorot_uniform', inner_init='orthogonal',\n                  activation='tanh', inner_activation='sigmoid',\n-                 weights=None, truncate_gradient=-1, return_sequences=False,\n-                 input_dim=None, input_length=None, go_backwards=False, **kwargs):\n+                 **kwargs):\n         self.output_dim = output_dim\n         self.init = initializations.get(init)\n         self.inner_init = initializations.get(inner_init)\n         self.activation = activations.get(activation)\n         self.inner_activation = activations.get(inner_activation)\n-        self.truncate_gradient = truncate_gradient\n-        self.return_sequences = return_sequences\n-        self.initial_weights = weights\n-        self.go_backwards = go_backwards\n-\n-        self.input_dim = input_dim\n-        self.input_length = input_length\n-        if self.input_dim:\n-            kwargs['input_shape'] = (self.input_length, self.input_dim)\n-        super(JZS1, self).__init__(**kwargs)\n+        super(JZS, self).__init__(**kwargs)\n \n     def build(self):\n-        input_dim = self.input_shape[2]\n-        self.input = T.tensor3()\n+        input_shape = self.input_shape\n+        input_dim = input_shape[2]\n+        self.input_dim = input_dim\n+        self.input = K.placeholder(input_shape)\n \n-        self.W_z = self.init((input_dim, self.output_dim))\n-        self.b_z = shared_zeros((self.output_dim))\n-\n-        self.W_r = self.init((input_dim, self.output_dim))\n-        self.U_r = self.inner_init((self.output_dim, self.output_dim))\n-        self.b_r = shared_zeros((self.output_dim))\n-\n-        self.U_h = self.inner_init((self.output_dim, self.output_dim))\n-        self.b_h = shared_zeros((self.output_dim))\n-\n-        # P_h used to project X onto different dimension, using sparse random projections\n-        if input_dim == self.output_dim:\n-            self.Pmat = theano.shared(np.identity(self.output_dim, dtype=theano.config.floatX), name=None)\n+        if self.stateful:\n+            if not input_shape[0]:\n+                raise Exception('If a RNN is stateful, a complete ' +\n+                                'input_shape must be provided ' +\n+                                '(including batch size).')\n+            self.states = [K.zeros(input_shape[0], self.output_dim)]\n         else:\n-            P = np.random.binomial(1, 0.5, size=(input_dim, self.output_dim)).astype(theano.config.floatX) * 2 - 1\n-            P = 1 / np.sqrt(input_dim) * P\n-            self.Pmat = theano.shared(P, name=None)\n-\n-        self.params = [\n-            self.W_z, self.b_z,\n-            self.W_r, self.U_r, self.b_r,\n-            self.U_h, self.b_h,\n-            self.Pmat\n-        ]\n-\n-        if self.initial_weights is not None:\n-            self.set_weights(self.initial_weights)\n-            del self.initial_weights\n-\n-    def _step(self,\n-              xz_t, xr_t, xh_t, mask_tm1,\n-              h_tm1,\n-              u_r, u_h):\n-        h_mask_tm1 = mask_tm1 * h_tm1\n-        z = self.inner_activation(xz_t)\n-        r = self.inner_activation(xr_t + T.dot(h_mask_tm1, u_r))\n-        hh_t = self.activation(xh_t + T.dot(r * h_mask_tm1, u_h))\n-        h_t = hh_t * z + h_mask_tm1 * (1 - z)\n-        return h_t\n-\n-    def get_output(self, train=False):\n-        X = self.get_input(train)\n-        padded_mask = self.get_padded_shuffled_mask(train, X, pad=1)\n-        X = X.dimshuffle((1, 0, 2))\n-\n-        x_z = T.dot(X, self.W_z) + self.b_z\n-        x_r = T.dot(X, self.W_r) + self.b_r\n-        x_h = T.tanh(T.dot(X, self.Pmat)) + self.b_h\n-        outputs, updates = theano.scan(\n-            self._step,\n-            sequences=[x_z, x_r, x_h, padded_mask],\n-            outputs_info=T.unbroadcast(alloc_zeros_matrix(X.shape[1], self.output_dim), 1),\n-            non_sequences=[self.U_r, self.U_h],\n-            truncate_gradient=self.truncate_gradient,\n-            go_backwards=self.go_backwards)\n-        if self.return_sequences:\n-            return outputs.dimshuffle((1, 0, 2))\n-        return outputs[-1]\n-\n-    def get_config(self):\n-        config = {\"name\": self.__class__.__name__,\n-                  \"output_dim\": self.output_dim,\n-                  \"init\": self.init.__name__,\n-                  \"inner_init\": self.inner_init.__name__,\n-                  \"activation\": self.activation.__name__,\n-                  \"inner_activation\": self.inner_activation.__name__,\n-                  \"truncate_gradient\": self.truncate_gradient,\n-                  \"return_sequences\": self.return_sequences,\n-                  \"input_dim\": self.input_dim,\n-                  \"input_length\": self.input_length,\n-                  \"go_backwards\": self.go_backwards}\n-        base_config = super(JZS1, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class JZS2(Recurrent):\n-    '''\n-        Evolved recurrent neural network architectures from the evaluation of thousands\n-        of models, serving as alternatives to LSTMs and GRUs. See Jozefowicz et al. 2015.\n-\n-        This corresponds to the `MUT2` architecture described in the paper.\n-\n-        Takes inputs with shape:\n-        (nb_samples, max_sample_length (samples shorter than this are padded with zeros at the end), input_dim)\n-\n-        and returns outputs with shape:\n-        if not return_sequences:\n-            (nb_samples, output_dim)\n-        if return_sequences:\n-            (nb_samples, max_sample_length, output_dim)\n-\n-        References:\n-            An Empirical Exploration of Recurrent Network Architectures\n-                http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf\n-    '''\n-    def __init__(self, output_dim,\n-                 init='glorot_uniform', inner_init='orthogonal',\n-                 activation='tanh', inner_activation='sigmoid',\n-                 weights=None, truncate_gradient=-1, return_sequences=False,\n-                 input_dim=None, input_length=None, go_backwards=False, **kwargs):\n-        self.output_dim = output_dim\n-        self.init = initializations.get(init)\n-        self.inner_init = initializations.get(inner_init)\n-        self.activation = activations.get(activation)\n-        self.inner_activation = activations.get(inner_activation)\n-        self.truncate_gradient = truncate_gradient\n-        self.return_sequences = return_sequences\n-        self.initial_weights = weights\n-        self.go_backwards = go_backwards\n-\n-        self.input_dim = input_dim\n-        self.input_length = input_length\n-        if self.input_dim:\n-            kwargs['input_shape'] = (self.input_length, self.input_dim)\n-        super(JZS2, self).__init__(**kwargs)\n-\n-    def build(self):\n-        input_dim = self.input_shape[2]\n-        self.input = T.tensor3()\n+            # initial states: all-zero tensor of shape (output_dim)\n+            self.states = [None]\n \n         self.W_z = self.init((input_dim, self.output_dim))\n         self.U_z = self.inner_init((self.output_dim, self.output_dim))\n-        self.b_z = shared_zeros((self.output_dim))\n+        self.b_z = K.zeros((self.output_dim))\n \n+        self.W_r = self.init((input_dim, self.output_dim))\n         self.U_r = self.inner_init((self.output_dim, self.output_dim))\n-        self.b_r = shared_zeros((self.output_dim))\n+        self.b_r = K.zeros((self.output_dim))\n \n         self.W_h = self.init((input_dim, self.output_dim))\n         self.U_h = self.inner_init((self.output_dim, self.output_dim))\n-        self.b_h = shared_zeros((self.output_dim))\n+        self.b_h = K.zeros((self.output_dim))\n \n-        # P_h used to project X onto different dimension, using sparse random projections\n+        # P matrix used to project X onto different dimension,\n+        # using sparse random projections\n         if input_dim == self.output_dim:\n-            self.Pmat = theano.shared(np.identity(self.output_dim, dtype=theano.config.floatX), name=None)\n+            self.P = K.variable(np.identity(self.output_dim))\n         else:\n-            P = np.random.binomial(1, 0.5, size=(input_dim, self.output_dim)).astype(theano.config.floatX) * 2 - 1\n-            P = 1 / np.sqrt(input_dim) * P\n-            self.Pmat = theano.shared(P, name=None)\n+            P = np.random.binomial(1, 0.5, size=(input_dim, self.output_dim))\n+            P = 1. / np.sqrt(input_dim) * (P * 2. - 1.)\n+            self.P = K.variable(P)\n \n-        self.params = [\n-            self.W_z, self.U_z, self.b_z,\n-            self.U_r, self.b_r,\n-            self.W_h, self.U_h, self.b_h,\n-            self.Pmat\n-        ]\n+        self.params = [self.W_z, self.b_z,\n+                       self.W_r, self.U_r, self.b_r,\n+                       self.U_h, self.b_h,\n+                       self.P]\n \n         if self.initial_weights is not None:\n             self.set_weights(self.initial_weights)\n             del self.initial_weights\n \n-    def _step(self,\n-              xz_t, xr_t, xh_t, mask_tm1,\n-              h_tm1,\n-              u_z, u_r, u_h):\n-        h_mask_tm1 = mask_tm1 * h_tm1\n-        z = self.inner_activation(xz_t + T.dot(h_mask_tm1, u_z))\n-        r = self.inner_activation(xr_t + T.dot(h_mask_tm1, u_r))\n-        hh_t = self.activation(xh_t + T.dot(r * h_mask_tm1, u_h))\n-        h_t = hh_t * z + h_mask_tm1 * (1 - z)\n-        return h_t\n-\n-    def get_output(self, train=False):\n-        X = self.get_input(train)\n-        padded_mask = self.get_padded_shuffled_mask(train, X, pad=1)\n-        X = X.dimshuffle((1, 0, 2))\n-\n-        x_z = T.dot(X, self.W_z) + self.b_z\n-        x_r = T.dot(X, self.Pmat) + self.b_r\n-        x_h = T.dot(X, self.W_h) + self.b_h\n-        outputs, updates = theano.scan(\n-            self._step,\n-            sequences=[x_z, x_r, x_h, padded_mask],\n-            outputs_info=T.unbroadcast(alloc_zeros_matrix(X.shape[1], self.output_dim), 1),\n-            non_sequences=[self.U_z, self.U_r, self.U_h],\n-            truncate_gradient=self.truncate_gradient,\n-            go_backwards=self.go_backwards)\n-\n-        if self.return_sequences:\n-            return outputs.dimshuffle((1, 0, 2))\n-        return outputs[-1]\n-\n     def get_config(self):\n-        config = {\"name\": self.__class__.__name__,\n-                  \"output_dim\": self.output_dim,\n+        config = {\"output_dim\": self.output_dim,\n                   \"init\": self.init.__name__,\n                   \"inner_init\": self.inner_init.__name__,\n                   \"activation\": self.activation.__name__,\n-                  \"inner_activation\": self.inner_activation.__name__,\n-                  \"truncate_gradient\": self.truncate_gradient,\n-                  \"return_sequences\": self.return_sequences,\n-                  \"input_dim\": self.input_dim,\n-                  \"input_length\": self.input_length,\n-                  \"go_backwards\": self.go_backwards}\n-        base_config = super(JZS2, self).get_config()\n+                  \"inner_activation\": self.inner_activation.__name__}\n+        base_config = super(JZS, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n \n \n+class JZS1(JZS):\n+    '''\n+        Evolved recurrent neural network architectures\n+        from the evaluation of thousands\n+        of models, serving as alternatives to LSTMs and GRUs.\n+        See Jozefowicz et al. 2015.\n+\n+        This corresponds to the `MUT1` architecture described in the paper.\n+    '''\n+    def __init__(self, *args, **kwargs):\n+        super(JZS1, self).__init__(*args, **kwargs)\n+\n+    def step(self, x, states):\n+        assert len(states) == 1\n+        h_tm1 = states[0]\n+\n+        x_z = K.dot(x, self.W_z) + self.b_z\n+        x_r = K.dot(x, self.P) + self.b_r\n+        x_h = K.dot(x, self.W_h) + self.b_h\n+\n+        z = self.inner_activation(x_z)\n+        r = self.inner_activation(x_r + K.dot(h_tm1, self.U_r))\n+        hh = self.activation(x_h + K.dot(r * h_tm1, self.U_h))\n+        h = hh * z + h_tm1 * (1. - z)\n+        return h, [h]\n+\n+\n+class JZS2(JZS):\n+    '''\n+        Evolved recurrent neural network architectures\n+        from the evaluation of thousands\n+        of models, serving as alternatives to LSTMs and GRUs.\n+        See Jozefowicz et al. 2015.\n+\n+        This corresponds to the `MUT2` architecture described in the paper.\n+    '''\n+    def __init__(self, *args, **kwargs):\n+        super(JZS2, self).__init__(*args, **kwargs)\n+\n+    def step(self, x, states):\n+        assert len(states) == 1\n+        h_tm1 = states[0]\n+\n+        x_z = K.dot(x, self.W_z) + self.b_z\n+        x_r = K.dot(x, self.P) + self.b_r\n+        x_h = K.dot(x, self.W_h) + self.b_h\n+\n+        z = self.inner_activation(x_z + K.dot(h_tm1, self.U_z))\n+        r = self.inner_activation(x_r + K.dot(h_tm1, self.U_r))\n+        hh = self.activation(x_h + K.dot(r * h_tm1, self.U_h))\n+        h = hh * z + h_tm1 * (1. - z)\n+        return h, [h]\n+\n+\n class JZS3(Recurrent):\n     '''\n-        Evolved recurrent neural network architectures from the evaluation of thousands\n-        of models, serving as alternatives to LSTMs and GRUs. See Jozefowicz et al. 2015.\n+        Evolved recurrent neural network architectures\n+        from the evaluation of thousands\n+        of models, serving as alternatives to LSTMs and GRUs.\n+        See Jozefowicz et al. 2015.\n \n         This corresponds to the `MUT3` architecture described in the paper.\n-\n-        Takes inputs with shape:\n-        (nb_samples, max_sample_length (samples shorter than this are padded with zeros at the end), input_dim)\n-\n-        and returns outputs with shape:\n-        if not return_sequences:\n-            (nb_samples, output_dim)\n-        if return_sequences:\n-            (nb_samples, max_sample_length, output_dim)\n-\n-        References:\n-            An Empirical Exploration of Recurrent Network Architectures\n-                http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf\n     '''\n-    def __init__(self, output_dim,\n-                 init='glorot_uniform', inner_init='orthogonal',\n-                 activation='tanh', inner_activation='sigmoid',\n-                 weights=None, truncate_gradient=-1, return_sequences=False,\n-                 input_dim=None, input_length=None, go_backwards=False, **kwargs):\n-        self.output_dim = output_dim\n-        self.init = initializations.get(init)\n-        self.inner_init = initializations.get(inner_init)\n-        self.activation = activations.get(activation)\n-        self.inner_activation = activations.get(inner_activation)\n-        self.truncate_gradient = truncate_gradient\n-        self.return_sequences = return_sequences\n-        self.initial_weights = weights\n-        self.go_backwards = go_backwards\n+    def __init__(self, *args, **kwargs):\n+        super(JZS3, self).__init__(*args, **kwargs)\n \n-        self.input_dim = input_dim\n-        self.input_length = input_length\n-        if self.input_dim:\n-            kwargs['input_shape'] = (self.input_length, self.input_dim)\n-        super(JZS3, self).__init__(**kwargs)\n+    def step(self, x, states):\n+        assert len(states) == 1\n+        h_tm1 = states[0]\n \n-    def build(self):\n-        input_dim = self.input_shape[2]\n-        self.input = T.tensor3()\n+        x_z = K.dot(x, self.W_z) + self.b_z\n+        x_r = K.dot(x, self.P) + self.b_r\n+        x_h = K.dot(x, self.W_h) + self.b_h\n \n-        self.W_z = self.init((input_dim, self.output_dim))\n-        self.U_z = self.inner_init((self.output_dim, self.output_dim))\n-        self.b_z = shared_zeros((self.output_dim))\n-\n-        self.W_r = self.init((input_dim, self.output_dim))\n-        self.U_r = self.inner_init((self.output_dim, self.output_dim))\n-        self.b_r = shared_zeros((self.output_dim))\n-\n-        self.W_h = self.init((input_dim, self.output_dim))\n-        self.U_h = self.inner_init((self.output_dim, self.output_dim))\n-        self.b_h = shared_zeros((self.output_dim))\n-\n-        self.params = [\n-            self.W_z, self.U_z, self.b_z,\n-            self.W_r, self.U_r, self.b_r,\n-            self.W_h, self.U_h, self.b_h,\n-        ]\n-\n-        if self.initial_weights is not None:\n-            self.set_weights(self.initial_weights)\n-            del self.initial_weights\n-\n-    def _step(self,\n-              xz_t, xr_t, xh_t, mask_tm1,\n-              h_tm1,\n-              u_z, u_r, u_h):\n-        h_mask_tm1 = mask_tm1 * h_tm1\n-        z = self.inner_activation(xz_t + T.dot(T.tanh(h_mask_tm1), u_z))\n-        r = self.inner_activation(xr_t + T.dot(h_mask_tm1, u_r))\n-        hh_t = self.activation(xh_t + T.dot(r * h_mask_tm1, u_h))\n-        h_t = hh_t * z + h_mask_tm1 * (1 - z)\n-        return h_t\n-\n-    def get_output(self, train=False):\n-        X = self.get_input(train)\n-        padded_mask = self.get_padded_shuffled_mask(train, X, pad=1)\n-        X = X.dimshuffle((1, 0, 2))\n-\n-        x_z = T.dot(X, self.W_z) + self.b_z\n-        x_r = T.dot(X, self.W_r) + self.b_r\n-        x_h = T.dot(X, self.W_h) + self.b_h\n-        outputs, updates = theano.scan(\n-            self._step,\n-            sequences=[x_z, x_r, x_h, padded_mask],\n-            outputs_info=T.unbroadcast(alloc_zeros_matrix(X.shape[1], self.output_dim), 1),\n-            non_sequences=[self.U_z, self.U_r, self.U_h],\n-            truncate_gradient=self.truncate_gradient,\n-            go_backwards=self.go_backwards)\n-        \n-        if self.return_sequences:\n-            return outputs.dimshuffle((1, 0, 2))\n-        return outputs[-1]\n-\n-    def get_config(self):\n-        config = {\"name\": self.__class__.__name__,\n-                  \"output_dim\": self.output_dim,\n-                  \"init\": self.init.__name__,\n-                  \"inner_init\": self.inner_init.__name__,\n-                  \"activation\": self.activation.__name__,\n-                  \"inner_activation\": self.inner_activation.__name__,\n-                  \"truncate_gradient\": self.truncate_gradient,\n-                  \"return_sequences\": self.return_sequences,\n-                  \"input_dim\": self.input_dim,\n-                  \"input_length\": self.input_length,\n-                  \"go_backwards\": self.go_backwards}\n-        base_config = super(JZS3, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n+        z = self.inner_activation(x_z + K.dot(K.tanh(h_tm1), self.U_z))\n+        r = self.inner_activation(x_r + K.dot(h_tm1, self.U_r))\n+        hh = self.activation(x_h + K.dot(r * h_tm1, self.U_h))\n+        h = hh * z + h_tm1 * (1. - z)\n+        return h, [h]\n\n@@ -2,8 +2,6 @@ import unittest\n from numpy.testing import assert_allclose\n import numpy as np\n \n-np.random.seed(1337)\n-\n from keras.backend import theano_backend as KTH\n from keras.backend import tensorflow_backend as KTF\n \n@@ -177,7 +175,54 @@ class TestBackend(unittest.TestCase):\n         assert_allclose(new_val_th, new_val_tf, atol=1e-06)\n \n     def test_rnn(self):\n-        pass\n+        # implement a simple RNN\n+        input_dim = 8\n+        output_dim = 4\n+        timesteps = 5\n+\n+        input_val = np.random.random((32, timesteps, input_dim))\n+        init_state_val = np.random.random((32, output_dim))\n+        W_i_val = np.random.random((input_dim, output_dim))\n+        W_o_val = np.random.random((output_dim, output_dim))\n+\n+        def rnn_step_fn(input_dim, output_dim, K):\n+            W_i = K.variable(W_i_val)\n+            W_o = K.variable(W_o_val)\n+\n+            def step_function(x, states):\n+                assert len(states) == 1\n+                prev_output = states[0]\n+                output = K.dot(x, W_i) + K.dot(prev_output, W_o)\n+                return output, [output]\n+            return step_function\n+\n+        th_rnn_step_fn = rnn_step_fn(input_dim, output_dim, KTH)\n+        inputs = KTH.variable(input_val)\n+        initial_states = [KTH.variable(init_state_val)]\n+        last_output, outputs, new_states = KTH.rnn(th_rnn_step_fn, inputs,\n+                                                   initial_states,\n+                                                   go_backwards=False,\n+                                                   masking=False)\n+        th_last_output = KTH.eval(last_output)\n+        th_outputs = KTH.eval(outputs)\n+        assert len(new_states) == 1\n+        th_state = KTH.eval(new_states[0])\n+\n+        tf_rnn_step_fn = rnn_step_fn(input_dim, output_dim, KTF)\n+        inputs = KTF.variable(input_val)\n+        initial_states = [KTF.variable(init_state_val)]\n+        last_output, outputs, new_states = KTF.rnn(tf_rnn_step_fn, inputs,\n+                                                   initial_states,\n+                                                   go_backwards=False,\n+                                                   masking=False)\n+        tf_last_output = KTF.eval(last_output)\n+        tf_outputs = KTF.eval(outputs)\n+        assert len(new_states) == 1\n+        tf_state = KTF.eval(new_states[0])\n+\n+        assert_allclose(tf_last_output, th_last_output, atol=1e-06)\n+        assert_allclose(tf_outputs, th_outputs, atol=1e-06)\n+        assert_allclose(tf_state, th_state, atol=1e-06)\n \n     def test_switch(self):\n         val = np.random.random()\n\n@@ -1,24 +1,25 @@\n import unittest\n import numpy as np\n-import theano\n \n from keras.layers import recurrent\n+from keras import backend as K\n \n nb_samples, timesteps, input_dim, output_dim = 3, 3, 10, 5\n \n \n def _runner(layer_class):\n     \"\"\"\n-    All the recurrent layers share the same interface, so we can run through them with a single\n-    function.\n+    All the recurrent layers share the same interface,\n+    so we can run through them with a single function.\n     \"\"\"\n     for ret_seq in [True, False]:\n-        layer = layer_class(output_dim, return_sequences=ret_seq, weights=None, input_shape=(None, input_dim))\n-        layer.input = theano.shared(value=np.ones((nb_samples, timesteps, input_dim)))\n+        layer = layer_class(output_dim, return_sequences=ret_seq,\n+                            weights=None, input_shape=(None, input_dim))\n+        layer.input = K.variable(np.ones((nb_samples, timesteps, input_dim)))\n         config = layer.get_config()\n \n         for train in [True, False]:\n-            out = layer.get_output(train).eval()\n+            out = K.eval(layer.get_output(train))\n             # Make sure the output has the desired shape\n             if ret_seq:\n                 assert(out.shape == (nb_samples, timesteps, output_dim))\n@@ -35,23 +36,20 @@ class TestRNNS(unittest.TestCase):\n     def test_simple(self):\n         _runner(recurrent.SimpleRNN)\n \n-    def test_simple_deep(self):\n-        _runner(recurrent.SimpleDeepRNN)\n-\n     def test_gru(self):\n         _runner(recurrent.GRU)\n \n     def test_lstm(self):\n         _runner(recurrent.LSTM)\n \n-    def test_jzs1(self):\n-        _runner(recurrent.JZS1)\n+    # def test_jzs1(self):\n+    #     _runner(recurrent.JZS1)\n \n-    def test_jzs2(self):\n-        _runner(recurrent.JZS2)\n+    # def test_jzs2(self):\n+    #     _runner(recurrent.JZS2)\n \n-    def test_jzs3(self):\n-        _runner(recurrent.JZS3)\n+    # def test_jzs3(self):\n+    #     _runner(recurrent.JZS3)\n \n \n if __name__ == '__main__':\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
