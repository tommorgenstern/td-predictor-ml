{"custom_id": "scrapy#464f24f8c160466f93eb8ebb4ec8b84d1824eaa0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 34 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 4/2 | Churn Δ: 37 | Churn Cumulative: 359 | Contributors (this commit): 3 | Commits (past 90d): 2 | Contributors (cumulative): 5 | DMM Complexity: 0.8846153846153846\n\nDIFF:\n@@ -17,8 +17,8 @@ class CurlParser(argparse.ArgumentParser):\n curl_parser = CurlParser()\n curl_parser.add_argument('url')\n curl_parser.add_argument('-H', '--header', dest='headers', action='append')\n-curl_parser.add_argument('-X', '--request', dest='method', default='get')\n-curl_parser.add_argument('-d', '--data', dest='data')\n+curl_parser.add_argument('-X', '--request', dest='method')\n+curl_parser.add_argument('-d', '--data', '--data-raw', dest='data')\n curl_parser.add_argument('-u', '--user', dest='auth')\n \n \n@@ -66,7 +66,9 @@ def curl_to_request_kwargs(curl_command, ignore_unknown_options=True):\n     if not parsed_url.scheme:\n         url = 'http://' + url\n \n-    result = {'method': parsed_args.method.upper(), 'url': url}\n+    method = parsed_args.method or 'GET'\n+\n+    result = {'method': method.upper(), 'url': url}\n \n     headers = []\n     cookies = {}\n@@ -90,5 +92,9 @@ def curl_to_request_kwargs(curl_command, ignore_unknown_options=True):\n         result['cookies'] = cookies\n     if parsed_args.data:\n         result['body'] = parsed_args.data\n+        if not parsed_args.method:\n+            # if the \"data\" is specified but the \"method\" is not specified,\n+            # the default method is 'POST'\n+            result['method'] = 'POST'\n \n     return result\n\n@@ -141,6 +141,31 @@ class CurlToRequestKwargsTest(unittest.TestCase):\n         }\n         self._test_command(curl_command, expected_result)\n \n+    def test_post_data_raw(self):\n+        curl_command = (\n+            \"curl 'https://www.example.org/' --data-raw 'excerptLength=200&ena\"\n+            \"bleDidYouMean=true&sortCriteria=ffirstz32xnamez32x201740686%20asc\"\n+            \"ending&queryFunctions=%5B%5D&rankingFunctions=%5B%5D'\"\n+        )\n+        expected_result = {\n+            \"method\": \"POST\",\n+            \"url\": \"https://www.example.org/\",\n+            \"body\": (\n+                \"excerptLength=200&enableDidYouMean=true&sortCriteria=ffirstz3\"\n+                \"2xnamez32x201740686%20ascending&queryFunctions=%5B%5D&ranking\"\n+                \"Functions=%5B%5D\")\n+        }\n+        self._test_command(curl_command, expected_result)\n+\n+    def test_explicit_get_with_data(self):\n+        curl_command = 'curl httpbin.org/anything -X GET --data asdf'\n+        expected_result = {\n+            \"method\": \"GET\",\n+            \"url\": \"http://httpbin.org/anything\",\n+            \"body\": \"asdf\"\n+        }\n+        self._test_command(curl_command, expected_result)\n+\n     def test_patch(self):\n         curl_command = (\n             'curl \"https://example.com/api/fake\" -u \"username:password\" -H \"Ac'\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#23906b6bee953d9bc5dd8042e785711b11840797", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 167 | Lines Deleted: 126 | Files Changed: 4 | Hunks: 63 | Methods Changed: 24 | Complexity Δ (Sum/Max): 2/3 | Churn Δ: 293 | Churn Cumulative: 2288 | Contributors (this commit): 24 | Commits (past 90d): 34 | Contributors (cumulative): 27 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2,6 +2,7 @@ import ipaddress\n import itertools\n import logging\n from collections import deque\n+from typing import Union, Dict\n \n from h2.config import H2Configuration\n from h2.connection import H2Connection\n@@ -9,20 +10,18 @@ from h2.events import (\n     DataReceived, ResponseReceived, SettingsAcknowledged,\n     StreamEnded, StreamReset, WindowUpdated\n )\n+from h2.exceptions import ProtocolError\n from twisted.internet.protocol import connectionDone, Protocol\n from twisted.internet.ssl import Certificate\n \n from scrapy.core.http2.stream import Stream, StreamCloseReason\n+from scrapy.core.http2.types import H2ConnectionMetadataDict\n from scrapy.http import Request\n \n-LOGGER = logging.getLogger(__name__)\n+logger = logging.getLogger(__name__)\n \n \n class H2ClientProtocol(Protocol):\n-    # TODO:\n-    #  1. Check for user-agent while testing\n-    #  2. Handle case when received events have StreamID = 0 (applied to H2Connection)\n-\n     def __init__(self):\n         config = H2Configuration(client_side=True, header_encoding='utf-8')\n         self.conn = H2Connection(config=config)\n@@ -37,7 +36,7 @@ class H2ClientProtocol(Protocol):\n         self.stream_id_count = itertools.count(start=1, step=2)\n \n         # Streams are stored in a dictionary keyed off their stream IDs\n-        self.streams = {}\n+        self.streams: Dict[int, Stream] = {}\n \n         # Boolean to keep track the connection is made\n         # If requests are received before connection is made\n@@ -46,9 +45,11 @@ class H2ClientProtocol(Protocol):\n         self.is_connection_made = False\n         self._pending_request_stream_pool = deque()\n \n-        # Some meta data of this connection\n-        # initialized when connection is successfully made\n-        self._metadata = {\n+        # Save an instance of ProtocolError raised by hyper-h2\n+        # We pass this instance to the streams ResponseFailed() failure\n+        self._protocol_error: Union[None, ProtocolError] = None\n+\n+        self._metadata: H2ConnectionMetadataDict = {\n             'certificate': None,\n             'ip_address': None\n         }\n@@ -68,7 +69,6 @@ class H2ClientProtocol(Protocol):\n             request=request,\n             connection=self.conn,\n             conn_metadata=self._metadata,\n-            write_to_transport=self._write_to_transport,\n             cb_close=self._stream_close_cb\n         )\n \n@@ -89,10 +89,10 @@ class H2ClientProtocol(Protocol):\n         data = self.conn.data_to_send()\n         self.transport.write(data)\n \n-        LOGGER.debug(\"Sent {} bytes to {} via transport\".format(len(data), self._metadata['ip_address']))\n+        logger.debug(\"Sent {} bytes to {} via transport\".format(len(data), self._metadata['ip_address']))\n \n-    def request(self, _request: Request):\n-        stream = self._new_stream(_request)\n+    def request(self, request: Request):\n+        stream = self._new_stream(request)\n         d = stream.get_response()\n \n         # If connection is not yet established then add the\n@@ -109,7 +109,7 @@ class H2ClientProtocol(Protocol):\n         sending some data now: we should open with the connection preamble.\n         \"\"\"\n         self.destination = self.transport.getPeer()\n-        LOGGER.info('Connection made to {}'.format(self.destination))\n+        logger.info('Connection made to {}'.format(self.destination))\n \n         self._metadata['certificate'] = Certificate(self.transport.getPeerCertificate())\n         self._metadata['ip_address'] = ipaddress.ip_address(self.destination.host)\n@@ -119,8 +119,20 @@ class H2ClientProtocol(Protocol):\n         self.is_connection_made = True\n \n     def dataReceived(self, data):\n+        try:\n             events = self.conn.receive_data(data)\n             self._handle_events(events)\n+        except ProtocolError as e:\n+            # TODO: In case of InvalidBodyLengthError -- terminate only one stream\n+\n+            # Save this error as ultimately the connection will be dropped\n+            # internally by hyper-h2. Saved error will be passed to all the streams\n+            # closed with the connection.\n+            self._protocol_error = e\n+\n+            # We lose the transport connection here\n+            self.transport.loseConnection()\n+        finally:\n             self._write_to_transport()\n \n     def connectionLost(self, reason=connectionDone):\n@@ -128,12 +140,16 @@ class H2ClientProtocol(Protocol):\n         No need to write anything to transport here.\n         \"\"\"\n         # Pop all streams which were pending and were not yet started\n-        for stream_id in list(self.streams):\n-            self.streams[stream_id].close(StreamCloseReason.CONNECTION_LOST, reason)\n+        # NOTE: Stream.close() pops the element from the streams dictionary\n+        # which raises `RuntimeError: dictionary changed size during iteration`\n+        # Hence, we copy the streams into a list.\n+        for stream in list(self.streams.values()):\n+            stream.close(StreamCloseReason.CONNECTION_LOST, self._protocol_error)\n \n         self.conn.close_connection()\n \n-        LOGGER.warning(\"Connection lost with reason \" + str(reason))\n+        if not reason.check(connectionDone):\n+            logger.warning(\"Connection lost with reason \" + str(reason))\n \n     def _handle_events(self, events):\n         \"\"\"Private method which acts as a bridge between the events\n@@ -144,7 +160,7 @@ class H2ClientProtocol(Protocol):\n                 triggered by sending data\n         \"\"\"\n         for event in events:\n-            LOGGER.debug(event)\n+            logger.debug(event)\n             if isinstance(event, DataReceived):\n                 self.data_received(event)\n             elif isinstance(event, ResponseReceived):\n@@ -158,16 +174,14 @@ class H2ClientProtocol(Protocol):\n             elif isinstance(event, SettingsAcknowledged):\n                 self.settings_acknowledged(event)\n             else:\n-                LOGGER.info(\"Received unhandled event {}\".format(event))\n+                logger.info(\"Received unhandled event {}\".format(event))\n \n     # Event handler functions starts here\n     def data_received(self, event: DataReceived):\n-        stream_id = event.stream_id\n-        self.streams[stream_id].receive_data(event.data, event.flow_controlled_length)\n+        self.streams[event.stream_id].receive_data(event.data, event.flow_controlled_length)\n \n     def response_received(self, event: ResponseReceived):\n-        stream_id = event.stream_id\n-        self.streams[stream_id].receive_headers(event.headers)\n+        self.streams[event.stream_id].receive_headers(event.headers)\n \n     def settings_acknowledged(self, event: SettingsAcknowledged):\n         # Send off all the pending requests\n@@ -175,8 +189,7 @@ class H2ClientProtocol(Protocol):\n         self._send_pending_requests()\n \n     def stream_ended(self, event: StreamEnded):\n-        stream_id = event.stream_id\n-        self.streams[stream_id].close(StreamCloseReason.ENDED)\n+        self.streams[event.stream_id].close(StreamCloseReason.ENDED)\n \n     def stream_reset(self, event: StreamReset):\n         self.streams[event.stream_id].close(StreamCloseReason.RESET)\n\n@@ -1,7 +1,7 @@\n import logging\n-from enum import IntFlag, auto\n+from enum import Enum\n from io import BytesIO\n-from typing import Dict\n+from typing import Callable, List\n from urllib.parse import urlparse\n \n from h2.connection import H2Connection\n@@ -10,45 +10,31 @@ from h2.exceptions import StreamClosedError\n from twisted.internet.defer import Deferred, CancelledError\n from twisted.python.failure import Failure\n from twisted.web.client import ResponseFailed\n-# for python < 3.8 -- typing.TypedDict is undefined\n-from typing_extensions import TypedDict\n \n+from scrapy.core.http2.types import H2ConnectionMetadataDict, H2ResponseDict\n from scrapy.http import Request\n from scrapy.http.headers import Headers\n from scrapy.responsetypes import responsetypes\n \n-\n-class _ResponseTypedDict(TypedDict):\n-    # Data received frame by frame from the server is appended\n-    # and passed to the response Deferred when completely received.\n-    body: BytesIO\n-\n-    # The amount of data received that counts against the flow control\n-    # window\n-    flow_controlled_size: int\n-\n-    # Headers received after sending the request\n-    headers: Headers\n+logger = logging.getLogger(__name__)\n \n \n-LOGGER = logging.getLogger(__name__)\n-\n-\n-class StreamCloseReason(IntFlag):\n+class StreamCloseReason(Enum):\n     # Received a StreamEnded event\n-    ENDED = auto()\n+    ENDED = 1\n \n     # Received a StreamReset event -- ended abruptly\n-    RESET = auto()\n+    RESET = 2\n \n     # Transport connection was lost\n-    CONNECTION_LOST = auto()\n+    CONNECTION_LOST = 3\n \n     # Expected response body size is more than allowed limit\n-    MAXSIZE_EXCEEDED = auto()\n+    MAXSIZE_EXCEEDED = 4\n \n-    # When the response deferred is cancelled\n-    CANCELLED = auto()\n+    # When the response deferred is cancelled by the client\n+    # (happens when client called response_deferred.cancel())\n+    CANCELLED = 5\n \n \n class Stream:\n@@ -67,30 +53,26 @@ class Stream:\n         stream_id: int,\n         request: Request,\n         connection: H2Connection,\n-            conn_metadata: Dict,\n-            write_to_transport,\n-            cb_close,\n-            download_maxsize=0,\n-            download_warnsize=0,\n-            fail_on_data_loss=True\n+        conn_metadata: H2ConnectionMetadataDict,\n+        cb_close: Callable[[int], None],\n+        download_maxsize: int = 0,\n+        download_warnsize: int = 0,\n+        fail_on_data_loss: bool = True\n     ):\n         \"\"\"\n         Arguments:\n-            stream_id {int} -- For one HTTP/2 connection each stream is\n+            stream_id -- For one HTTP/2 connection each stream is\n                 uniquely identified by a single integer\n-            request {Request} -- HTTP request\n-            connection {H2Connection} -- HTTP/2 connection this stream belongs to.\n-            conn_metadata {Dict} -- Reference to dictionary having metadata of HTTP/2 connection\n-            write_to_transport {callable} -- Method used to write & send data to the server\n-                This method should be used whenever some frame is to be sent to the server.\n-            cb_close {callable} -- Method called when this stream is closed\n+            request -- HTTP request\n+            connection -- HTTP/2 connection this stream belongs to.\n+            conn_metadata -- Reference to dictionary having metadata of HTTP/2 connection\n+            cb_close -- Method called when this stream is closed\n                 to notify the TCP connection instance.\n         \"\"\"\n         self.stream_id = stream_id\n         self._request = request\n         self._conn = connection\n         self._conn_metadata = conn_metadata\n-        self._write_to_transport = write_to_transport\n         self._cb_close = cb_close\n \n         self._download_maxsize = self._request.meta.get('download_maxsize', download_maxsize)\n@@ -119,7 +101,7 @@ class Stream:\n         # Private variable used to build the response\n         # this response is then converted to appropriate Response class\n         # passed to the response deferred callback\n-        self._response: _ResponseTypedDict = {\n+        self._response: H2ResponseDict = {\n             'body': BytesIO(),\n             'flow_controlled_size': 0,\n             'headers': Headers({})\n@@ -136,6 +118,25 @@ class Stream:\n \n     __repr__ = __str__\n \n+    @property\n+    def _log_warnsize(self) -> bool:\n+        \"\"\"Checks if we have received data which exceeds the download warnsize\n+        and whether we have not already logged about it.\n+\n+        Returns:\n+            True if both the above conditions hold true\n+            False if any of the conditions is false\n+        \"\"\"\n+        content_length_header = int(self._response['headers'].get(b'Content-Length', -1))\n+        return (\n+            self._download_warnsize\n+            and (\n+                self._response['flow_controlled_size'] > self._download_warnsize\n+                or content_length_header > self._download_warnsize\n+            )\n+            and not self._reached_warnsize\n+        )\n+\n     def get_response(self):\n         \"\"\"Simply return a Deferred which fires when response\n         from the asynchronous request is available\n@@ -166,10 +167,7 @@ class Stream:\n     def initiate_request(self):\n         headers = self._get_request_headers()\n         self._conn.send_headers(self.stream_id, headers, end_stream=False)\n-        self._write_to_transport()\n-\n         self.request_sent = True\n-\n         self.send_data()\n \n     def send_data(self):\n@@ -211,20 +209,19 @@ class Stream:\n             self.remaining_content_length = self.remaining_content_length - chunk_size\n \n         self.remaining_content_length = max(0, self.remaining_content_length)\n-        LOGGER.debug(\"{} sending {}/{} data bytes ({} frames) to {}\".format(\n-            self,\n-            self.content_length - self.remaining_content_length, self.content_length,\n-            data_frames_sent,\n-            self._conn_metadata['ip_address'])\n+        logger.debug(\n+            \"{stream} sending {received}/{expected} data bytes ({frames} frames) to {ip_address}\".format(\n+                stream=self,\n+                received=self.content_length - self.remaining_content_length,\n+                expected=self.content_length,\n+                frames=data_frames_sent,\n+                ip_address=self._conn_metadata['ip_address'])\n         )\n \n         # End the stream if no more data needs to be send\n         if self.remaining_content_length == 0:\n             self._conn.end_stream(self.stream_id)\n \n-        # Write data to transport -- Empty the outstanding data\n-        self._write_to_transport()\n-\n         # Q. What about the rest of the data?\n         # Ans: Remaining Data frames will be sent when we get a WindowUpdate frame\n \n@@ -240,24 +237,21 @@ class Stream:\n         self._response['body'].write(data)\n         self._response['flow_controlled_size'] += flow_controlled_length\n \n+        # We check maxsize here in case the Content-Length header was not received\n         if self._download_maxsize and self._response['flow_controlled_size'] > self._download_maxsize:\n-            # Clear buffer earlier to avoid keeping data in memory for a long time\n-            self._response['body'].truncate(0)\n             self.reset_stream(StreamCloseReason.MAXSIZE_EXCEEDED)\n             return\n \n-        if self._download_warnsize \\\n-                and self._response['flow_controlled_size'] > self._download_warnsize \\\n-                and not self._reached_warnsize:\n+        if self._log_warnsize:\n             self._reached_warnsize = True\n-            warning_msg = ('Received more ({bytes}) bytes than download ',\n-                           'warn size ({warnsize}) in request {request}')\n+            warning_msg = 'Received more ({bytes}) bytes than download ' \\\n+                          + 'warn size ({warnsize}) in request {request}'\n             warning_args = {\n                 'bytes': self._response['flow_controlled_size'],\n                 'warnsize': self._download_warnsize,\n                 'request': self._request\n             }\n-            LOGGER.warning(warning_msg, warning_args)\n+            logger.warning(warning_msg.format(**warning_args))\n \n         # Acknowledge the data received\n         self._conn.acknowledge_received_data(\n@@ -275,23 +269,27 @@ class Stream:\n             self.reset_stream(StreamCloseReason.MAXSIZE_EXCEEDED)\n             return\n \n-        if self._download_warnsize and expected_size > self._download_warnsize:\n-            warning_msg = (\"Expected response size ({size}) larger than \",\n-                           \"download warn size ({warnsize}) in request {request}.\")\n+        if self._log_warnsize:\n+            self._reached_warnsize = True\n+            warning_msg = 'Expected response size ({size}) larger than ' \\\n+                          + 'download warn size ({warnsize}) in request {request}'\n             warning_args = {\n-                'size': expected_size, 'warnsize': self._download_warnsize,\n+                'size': expected_size,\n+                'warnsize': self._download_warnsize,\n                 'request': self._request\n             }\n-            LOGGER.warning(warning_msg, warning_args)\n+            logger.warning(warning_msg.format(**warning_args))\n \n     def reset_stream(self, reason=StreamCloseReason.RESET):\n         \"\"\"Close this stream by sending a RST_FRAME to the remote peer\"\"\"\n         if self.stream_closed_local:\n             raise StreamClosedError(self.stream_id)\n \n+        # Clear buffer earlier to avoid keeping data in memory for a long time\n+        self._response['body'].truncate(0)\n+\n         self.stream_closed_local = True\n         self._conn.reset_stream(self.stream_id, ErrorCodes.REFUSED_STREAM)\n-        self._write_to_transport()\n         self.close(reason)\n \n     def _is_data_lost(self) -> bool:\n@@ -302,8 +300,11 @@ class Stream:\n \n         return expected_size != received_body_size\n \n-    def close(self, reason: StreamCloseReason, failure=None):\n+    def close(self, reason: StreamCloseReason, error: Exception = None):\n         \"\"\"Based on the reason sent we will handle each case.\n+\n+        Arguments:\n+            reason -- One if StreamCloseReason\n         \"\"\"\n         if self.stream_closed_server:\n             raise StreamClosedError(self.stream_id)\n@@ -311,35 +312,16 @@ class Stream:\n         self._cb_close(self.stream_id)\n         self.stream_closed_server = True\n \n-        # Do nothing if the response deferred was cancelled\n         flags = None\n         if b'Content-Length' not in self._response['headers']:\n-            # Missing Content-Length - PotentialDataLoss\n+            # Missing Content-Length - {twisted.web.http.PotentialDataLoss}\n             flags = ['partial']\n-        elif self._is_data_lost():\n-            if self._fail_on_dataloss:\n-                self._deferred_response.errback(ResponseFailed([Failure()]))\n-                return\n-            else:\n-                flags = ['dataloss']\n \n-        if reason is StreamCloseReason.ENDED:\n-            self._fire_response_deferred(flags)\n-\n-        # Stream was abruptly ended here\n-        elif reason is StreamCloseReason.CANCELLED:\n-            # Client has cancelled the request. Remove all the data\n-            # received and fire the response deferred with no flags set\n-            self._response['body'].truncate(0)\n-            self._response['headers'].clear()\n-            self._fire_response_deferred()\n-\n-        elif reason in (StreamCloseReason.RESET | StreamCloseReason.CONNECTION_LOST):\n-            if failure is None:\n-                self._deferred_response.errback(ResponseFailed([Failure()]))\n-            else:\n-                self._deferred_response.errback(failure)\n-        elif reason is StreamCloseReason.MAXSIZE_EXCEEDED:\n+        # NOTE: Order of handling the events is important here\n+        # As we immediately cancel the request when maxsize is exceeded while\n+        # receiving DATA_FRAME's when we have received the headers (not\n+        # having Content-Length)\n+        if reason is StreamCloseReason.MAXSIZE_EXCEEDED:\n             expected_size = int(self._response['headers'].get(b'Content-Length', -1))\n             error_msg = (\"Cancelling download of {url}: expected response \"\n                          \"size ({size}) larger than download max size ({maxsize}).\")\n@@ -349,14 +331,34 @@ class Stream:\n                 'maxsize': self._download_maxsize\n             }\n \n-            LOGGER.error(error_msg, error_args)\n+            logger.error(error_msg, error_args)\n             self._deferred_response.errback(CancelledError(error_msg.format(**error_args)))\n \n-    def _fire_response_deferred(self, flags=None):\n+        elif reason is StreamCloseReason.ENDED:\n+            self._fire_response_deferred(flags)\n+\n+        # Stream was abruptly ended here\n+        elif reason is StreamCloseReason.CANCELLED:\n+            # Client has cancelled the request. Remove all the data\n+            # received and fire the response deferred with no flags set\n+\n+            # NOTE: The data is already flushed in Stream.reset_stream() called\n+            # immediately when the stream needs to be cancelled\n+\n+            # There maybe no :status in headers, we make\n+            # HTTP Status Code: 499 - Client Closed Request\n+            self._response['headers'][':status'] = '499'\n+            self._fire_response_deferred()\n+\n+        elif reason in (StreamCloseReason.RESET, StreamCloseReason.CONNECTION_LOST):\n+            self._deferred_response.errback(ResponseFailed([\n+                error if error else Failure()\n+            ]))\n+\n+    def _fire_response_deferred(self, flags: List[str] = None):\n         \"\"\"Builds response from the self._response dict\n         and fires the response deferred callback with the\n         generated response instance\"\"\"\n-        # TODO: Update Client Side Status Codes here\n \n         body = self._response['body'].getvalue()\n         response_cls = responsetypes.from_args(\n@@ -365,11 +367,7 @@ class Stream:\n             body=body\n         )\n \n-        # If there is no :status in headers\n-        # (happens when client called response_deferred.cancel())\n-        # HTTP Status Code: 499 - Client Closed Request\n-        status = self._response['headers'].get(':status', '499')\n-\n+        status = self._response['headers'][':status']\n         response = response_cls(\n             url=self._request.url,\n             status=status,\n\n@@ -0,0 +1,30 @@\n+from io import BytesIO\n+from ipaddress import IPv4Address, IPv6Address\n+from typing import Union\n+\n+from twisted.internet.ssl import Certificate\n+# for python < 3.8 -- typing.TypedDict is undefined\n+from typing_extensions import TypedDict\n+\n+from scrapy.http.headers import Headers\n+\n+\n+class H2ConnectionMetadataDict(TypedDict):\n+    \"\"\"Some meta data of this connection\n+    initialized when connection is successfully made\n+    \"\"\"\n+    certificate: Union[None, Certificate]\n+    ip_address: Union[None, IPv4Address, IPv6Address]\n+\n+\n+class H2ResponseDict(TypedDict):\n+    # Data received frame by frame from the server is appended\n+    # and passed to the response Deferred when completely received.\n+    body: BytesIO\n+\n+    # The amount of data received that counts against the flow control\n+    # window\n+    flow_controlled_size: int\n+\n+    # Headers received after sending the request\n+    headers: Headers\n\n@@ -67,7 +67,7 @@ setup(\n     ],\n     python_requires='>=3.5.2',\n     install_requires=[\n-        'Twisted[http2]>=17.9.0'\n+        'Twisted[http2]>=17.9.0',\n         'cryptography>=2.0',\n         'cssselect>=0.9.1',\n         'lxml>=3.5.0',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#90a7007f8818dbc224dbe51b95f07199cb730204", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 133 | Lines Deleted: 16 | Files Changed: 1 | Hunks: 19 | Methods Changed: 17 | Complexity Δ (Sum/Max): 15/15 | Churn Δ: 149 | Churn Cumulative: 612 | Contributors (this commit): 1 | Commits (past 90d): 4 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,26 +1,26 @@\n-# TODO: Add test cases for\n-#   1. No Content Length response header\n-#   2. Cancel Response Deferred\n import json\n import os\n import random\n+import re\n import shutil\n import string\n \n+from h2.exceptions import InvalidBodyLengthError\n from twisted.internet import reactor\n-from twisted.internet.defer import inlineCallbacks, DeferredList\n+from twisted.internet.defer import inlineCallbacks, DeferredList, CancelledError\n from twisted.internet.endpoints import SSL4ClientEndpoint, SSL4ServerEndpoint, TCP4ServerEndpoint\n from twisted.internet.protocol import Factory\n from twisted.internet.ssl import optionsForClientTLS, PrivateCertificate\n+from twisted.python.failure import Failure\n from twisted.trial.unittest import TestCase\n from twisted.web.http import Request as TxRequest\n-from twisted.web.resource import Resource\n-from twisted.web.server import Site\n+from twisted.web.server import Site, NOT_DONE_YET\n from twisted.web.static import File\n \n from scrapy.core.http2.protocol import H2ClientProtocol\n from scrapy.http import Request, Response, JsonRequest\n-from tests.mockserver import ssl_context_factory\n+from scrapy.utils.python import to_bytes, to_unicode\n+from tests.mockserver import ssl_context_factory, LeafResource\n \n \n def generate_random_string(size):\n@@ -35,7 +35,7 @@ def make_html_body(val):\n <h1>Hello from HTTP2<h1>\n <p>{}</p>\n </html>'''.format(val)\n-    return bytes(response, 'utf-8')\n+    return to_bytes(response)\n \n \n class Data:\n@@ -54,9 +54,8 @@ class Data:\n     JSON_SMALL = {'data': STR_SMALL}\n     JSON_LARGE = {'data': STR_LARGE}\n \n-\n-class LeafResource(Resource):\n-    isLeaf = True\n+    DATALOSS = b'Dataloss Content'\n+    NO_CONTENT_LENGTH = b'This response do not have any content-length header'\n \n \n class GetDataHtmlSmall(LeafResource):\n@@ -80,9 +79,9 @@ class PostDataJsonMixin:\n             'extra-data': extra_data\n         }\n         for k, v in request.requestHeaders.getAllRawHeaders():\n-            response['request-headers'][k.decode('utf-8')] = v[0].decode('utf-8')\n+            response['request-headers'][to_unicode(k)] = to_unicode(v[0])\n \n-        response_bytes = bytes(json.dumps(response), 'utf-8')\n+        response_bytes = to_bytes(json.dumps(response))\n         request.setHeader('Content-Type', 'application/json')\n         return response_bytes\n \n@@ -97,6 +96,31 @@ class PostDataJsonLarge(LeafResource, PostDataJsonMixin):\n         return self.make_response(request, Data.EXTRA_LARGE)\n \n \n+class Dataloss(LeafResource):\n+\n+    def render_GET(self, request: TxRequest):\n+        request.setHeader(b\"Content-Length\", b\"1024\")\n+        self.deferRequest(request, 0, self._delayed_render, request)\n+        return NOT_DONE_YET\n+\n+    @staticmethod\n+    def _delayed_render(request: TxRequest):\n+        request.write(Data.DATALOSS)\n+        request.finish()\n+\n+\n+class NoContentLengthHeader(LeafResource):\n+    def render_GET(self, request: TxRequest):\n+        request.requestHeaders.removeHeader('Content-Length')\n+        self.deferRequest(request, 0, self._delayed_render, request)\n+        return NOT_DONE_YET\n+\n+    @staticmethod\n+    def _delayed_render(request: TxRequest):\n+        request.write(Data.NO_CONTENT_LENGTH)\n+        request.finish()\n+\n+\n def get_client_certificate(key_file, certificate_file):\n     with open(key_file, 'r') as key, open(certificate_file, 'r') as certificate:\n         pem = ''.join(key.readlines()) + ''.join(certificate.readlines())\n@@ -118,6 +142,9 @@ class Https2ClientProtocolTestCase(TestCase):\n \n         r.putChild(b'post-data-json-small', PostDataJsonSmall())\n         r.putChild(b'post-data-json-large', PostDataJsonLarge())\n+\n+        r.putChild(b'dataloss', Dataloss())\n+        r.putChild(b'no-content-length-header', NoContentLengthHeader())\n         return r\n \n     @inlineCallbacks\n@@ -237,7 +264,7 @@ class Https2ClientProtocolTestCase(TestCase):\n             self.assertEqual(len(response.body), content_length)\n \n             # Parse the body\n-            body = json.loads(response.body.decode('utf-8'))\n+            body = json.loads(to_unicode(response.body))\n             self.assertIn('request-body', body)\n             self.assertIn('extra-data', body)\n             self.assertIn('request-headers', body)\n@@ -251,11 +278,12 @@ class Https2ClientProtocolTestCase(TestCase):\n             # Check if headers were sent successfully\n             request_headers = body['request-headers']\n             for k, v in request.headers.items():\n-                k_str = k.decode('utf-8')\n+                k_str = to_unicode(k)\n                 self.assertIn(k_str, request_headers)\n-                self.assertEqual(request_headers[k_str], v[0].decode('utf-8'))\n+                self.assertEqual(request_headers[k_str], to_unicode(v[0]))\n \n         d.addCallback(assert_response)\n+        d.addErrback(self.fail)\n         return d\n \n     def test_POST_small_json(self):\n@@ -310,6 +338,95 @@ class Https2ClientProtocolTestCase(TestCase):\n \n         d = self.client.request(request)\n         d.addCallback(assert_response)\n+        d.addErrback(self.fail)\n         d.cancel()\n \n         return d\n+\n+    def test_download_maxsize_exceeded(self):\n+        request = Request(url=self.get_url('/get-data-html-large'), meta={'download_maxsize': 1000})\n+\n+        def assert_cancelled_error(failure):\n+            self.assertIsInstance(failure.value, CancelledError)\n+\n+        d = self.client.request(request)\n+        d.addCallback(self.fail)\n+        d.addErrback(assert_cancelled_error)\n+        return d\n+\n+    # TODO: Test in multiple requests if one request fails due to dataloss\n+    #  remaining request do not fail (change expected behaviour)\n+    #  Can be done only when hyper-h2 don't terminate connection over\n+    #  InvalidBodyLengthError check\n+    def test_received_dataloss_response(self):\n+        \"\"\"In case when value of Header Content-Length != len(Received Data)\n+        ProtocolError is raised\"\"\"\n+        request = Request(url=self.get_url('/dataloss'))\n+\n+        def assert_failure(failure: Failure):\n+            self.assertTrue(len(failure.value.reasons) > 0)\n+            self.assertTrue(any(\n+                isinstance(error, InvalidBodyLengthError)\n+                for error in failure.value.reasons\n+            ))\n+\n+        d = self.client.request(request)\n+        d.addCallback(self.fail)\n+        d.addErrback(assert_failure)\n+        return d\n+\n+    def test_missing_content_length_header(self):\n+        request = Request(url=self.get_url('/no-content-length-header'))\n+\n+        def assert_content_length(response: Response):\n+            self.assertEqual(response.status, 200)\n+            self.assertEqual(response.body, Data.NO_CONTENT_LENGTH)\n+            self.assertEqual(response.request, request)\n+            self.assertEqual(response.url, request.url)\n+            self.assertIn('partial', response.flags)\n+            self.assertNotIn('Content-Length', response.headers)\n+\n+        d = self.client.request(request)\n+        d.addCallback(assert_content_length)\n+        d.addErrback(self.fail)\n+        return d\n+\n+    @inlineCallbacks\n+    def _check_log_warnsize(\n+        self,\n+        request,\n+        warn_pattern,\n+        expected_body\n+    ):\n+        with self.assertLogs('scrapy.core.http2.stream', level='WARNING') as cm:\n+            response = yield self.client.request(request)\n+            self.assertEqual(response.status, 200)\n+            self.assertEqual(response.request, request)\n+            self.assertEqual(response.url, request.url)\n+            self.assertEqual(response.body, expected_body)\n+\n+            # Check the warning is raised only once for this request\n+            self.assertEqual(sum(\n+                len(re.findall(warn_pattern, log))\n+                for log in cm.output\n+            ), 1)\n+\n+    @inlineCallbacks\n+    def test_log_expected_warnsize(self):\n+        request = Request(url=self.get_url('/get-data-html-large'), meta={'download_warnsize': 1000})\n+        warn_pattern = re.compile(\n+            r'Expected response size \\(\\d*\\) larger than '\n+            r'download warn size \\(1000\\) in request {}'.format(request)\n+        )\n+\n+        yield self._check_log_warnsize(request, warn_pattern, Data.HTML_LARGE)\n+\n+    @inlineCallbacks\n+    def test_log_received_warnsize(self):\n+        request = Request(url=self.get_url('/no-content-length-header'), meta={'download_warnsize': 10})\n+        warn_pattern = re.compile(\n+            r'Received more \\(\\d*\\) bytes than download '\n+            r'warn size \\(10\\) in request {}'.format(request)\n+        )\n+\n+        yield self._check_log_warnsize(request, warn_pattern, Data.NO_CONTENT_LENGTH)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#26ab3e4137ddee3c643ae63c0709529efc698433", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 123 | Lines Deleted: 31 | Files Changed: 3 | Hunks: 26 | Methods Changed: 22 | Complexity Δ (Sum/Max): 14/7 | Churn Δ: 154 | Churn Cumulative: 2496 | Contributors (this commit): 1 | Commits (past 90d): 34 | Contributors (cumulative): 3 | DMM Complexity: 0.9795918367346939\n\nDIFF:\n@@ -38,13 +38,16 @@ class H2ClientProtocol(Protocol):\n         # Streams are stored in a dictionary keyed off their stream IDs\n         self.streams: Dict[int, Stream] = {}\n \n-        # Boolean to keep track the connection is made\n-        # If requests are received before connection is made\n-        # we keep all requests in a pool and send them as the connection\n-        # is made\n-        self.is_connection_made = False\n+        # If requests are received before connection is made we keep\n+        # all requests in a pool and send them as the connection is made\n         self._pending_request_stream_pool = deque()\n \n+        # Counter to keep track of opened stream. This counter\n+        # is used to make sure that not more than MAX_CONCURRENT_STREAMS\n+        # streams are opened which leads to ProtocolError\n+        # We use simple FIFO policy to handle pending requests\n+        self._active_streams = 0\n+\n         # Save an instance of ProtocolError raised by hyper-h2\n         # We pass this instance to the streams ResponseFailed() failure\n         self._protocol_error: Union[None, ProtocolError] = None\n@@ -54,10 +57,46 @@ class H2ClientProtocol(Protocol):\n             'ip_address': None\n         }\n \n+    @property\n+    def is_connected(self):\n+        \"\"\"Boolean to keep track of the connection status.\n+        This is used while initiating pending streams to make sure\n+        that we initiate stream only during active HTTP/2 Connection\n+        \"\"\"\n+        return bool(self.transport.connected)\n+\n+    @property\n+    def allowed_max_concurrent_streams(self) -> int:\n+        \"\"\"We keep total two streams for client (sending data) and\n+        server side (receiving data) for a single request. To be safe\n+        we choose the minimum. Since this value can change in event\n+        RemoteSettingsChanged we make variable a property.\n+        \"\"\"\n+        return min(\n+            self.conn.local_settings.max_concurrent_streams,\n+            self.conn.remote_settings.max_concurrent_streams\n+        )\n+\n+    def _send_pending_requests(self):\n+        \"\"\"Initiate all pending requests from the deque following FIFO\n+        We make sure that at any time {allowed_max_concurrent_streams}\n+        streams are active.\n+        \"\"\"\n+        while (\n+            self._pending_request_stream_pool\n+            and self._active_streams < self.allowed_max_concurrent_streams\n+            and self.is_connected\n+        ):\n+            self._active_streams += 1\n+            stream = self._pending_request_stream_pool.popleft()\n+            stream.initiate_request()\n+\n     def _stream_close_cb(self, stream_id: int):\n         \"\"\"Called when stream is closed completely\n         \"\"\"\n-        self.streams.pop(stream_id, None)\n+        self.streams.pop(stream_id)\n+        self._active_streams -= 1\n+        self._send_pending_requests()\n \n     def _new_stream(self, request: Request):\n         \"\"\"Instantiates a new Stream object\n@@ -75,13 +114,6 @@ class H2ClientProtocol(Protocol):\n         self.streams[stream.stream_id] = stream\n         return stream\n \n-    def _send_pending_requests(self):\n-        # TODO: handle MAX_CONCURRENT_STREAMS\n-        # Initiate all pending requests\n-        while self._pending_request_stream_pool:\n-            stream = self._pending_request_stream_pool.popleft()\n-            stream.initiate_request()\n-\n     def _write_to_transport(self):\n         \"\"\" Write data to the underlying transport connection\n         from the HTTP2 connection instance if any\n@@ -89,19 +121,12 @@ class H2ClientProtocol(Protocol):\n         data = self.conn.data_to_send()\n         self.transport.write(data)\n \n-        logger.debug(\"Sent {} bytes to {} via transport\".format(len(data), self._metadata['ip_address']))\n-\n     def request(self, request: Request):\n         stream = self._new_stream(request)\n         d = stream.get_response()\n \n-        # If connection is not yet established then add the\n-        # stream to pool or initiate request\n-        if self.is_connection_made:\n-            stream.initiate_request()\n-        else:\n+        # Add the stream to the request pool\n         self._pending_request_stream_pool.append(stream)\n-\n         return d\n \n     def connectionMade(self):\n@@ -116,7 +141,6 @@ class H2ClientProtocol(Protocol):\n \n         self.conn.initiate_connection()\n         self._write_to_transport()\n-        self.is_connection_made = True\n \n     def dataReceived(self, data):\n         try:\n@@ -144,7 +168,10 @@ class H2ClientProtocol(Protocol):\n         # which raises `RuntimeError: dictionary changed size during iteration`\n         # Hence, we copy the streams into a list.\n         for stream in list(self.streams.values()):\n+            if stream.request_sent:\n                 stream.close(StreamCloseReason.CONNECTION_LOST, self._protocol_error)\n+            else:\n+                stream.close(StreamCloseReason.INACTIVE)\n \n         self.conn.close_connection()\n \n@@ -160,7 +187,6 @@ class H2ClientProtocol(Protocol):\n                 triggered by sending data\n         \"\"\"\n         for event in events:\n-            logger.debug(event)\n             if isinstance(event, DataReceived):\n                 self.data_received(event)\n             elif isinstance(event, ResponseReceived):\n@@ -174,7 +200,7 @@ class H2ClientProtocol(Protocol):\n             elif isinstance(event, SettingsAcknowledged):\n                 self.settings_acknowledged(event)\n             else:\n-                logger.info(\"Received unhandled event {}\".format(event))\n+                logger.debug(\"Received unhandled event {}\".format(event))\n \n     # Event handler functions starts here\n     def data_received(self, event: DataReceived):\n@@ -184,8 +210,8 @@ class H2ClientProtocol(Protocol):\n         self.streams[event.stream_id].receive_headers(event.headers)\n \n     def settings_acknowledged(self, event: SettingsAcknowledged):\n-        # Send off all the pending requests\n-        # as now we have established a proper HTTP/2 connection\n+        # Send off all the pending requests as now we have\n+        # established a proper HTTP/2 connection\n         self._send_pending_requests()\n \n     def stream_ended(self, event: StreamEnded):\n@@ -195,9 +221,8 @@ class H2ClientProtocol(Protocol):\n         self.streams[event.stream_id].close(StreamCloseReason.RESET)\n \n     def window_updated(self, event: WindowUpdated):\n-        stream_id = event.stream_id\n-        if stream_id != 0:\n-            self.streams[stream_id].receive_window_update()\n+        if event.stream_id != 0:\n+            self.streams[event.stream_id].receive_window_update()\n         else:\n             # Send leftover data for all the streams\n             for stream in self.streams.values():\n\n@@ -8,6 +8,7 @@ from h2.connection import H2Connection\n from h2.errors import ErrorCodes\n from h2.exceptions import StreamClosedError\n from twisted.internet.defer import Deferred, CancelledError\n+from twisted.internet.error import ConnectionClosed\n from twisted.python.failure import Failure\n from twisted.web.client import ResponseFailed\n \n@@ -19,6 +20,15 @@ from scrapy.responsetypes import responsetypes\n logger = logging.getLogger(__name__)\n \n \n+class InactiveStreamClosed(ConnectionClosed):\n+    \"\"\"Connection was closed without sending request headers\n+    of the stream. This happens when a stream is waiting for other\n+    streams to close and connection is lost.\"\"\"\n+\n+    def __init__(self, request: Request):\n+        self.request = request\n+\n+\n class StreamCloseReason(Enum):\n     # Received a StreamEnded event\n     ENDED = 1\n@@ -32,10 +42,13 @@ class StreamCloseReason(Enum):\n     # Expected response body size is more than allowed limit\n     MAXSIZE_EXCEEDED = 4\n \n-    # When the response deferred is cancelled by the client\n+    # Response deferred is cancelled by the client\n     # (happens when client called response_deferred.cancel())\n     CANCELLED = 5\n \n+    # Connection lost and the stream was not initiated\n+    INACTIVE = 6\n+\n \n class Stream:\n     \"\"\"Represents a single HTTP/2 Stream.\n@@ -108,8 +121,12 @@ class Stream:\n         }\n \n         def _cancel(_):\n-            # Close this stream as gracefully as possible :)\n+            # Close this stream as gracefully as possible\n+            # Check if the stream has started\n+            if self.request_sent:\n                 self.reset_stream(StreamCloseReason.CANCELLED)\n+            else:\n+                self.close(StreamCloseReason.CANCELLED)\n \n         self._deferred_response = Deferred(_cancel)\n \n@@ -355,6 +372,9 @@ class Stream:\n                 error if error else Failure()\n             ]))\n \n+        elif reason is StreamCloseReason.INACTIVE:\n+            self._deferred_response.errback(InactiveStreamClosed(self._request))\n+\n     def _fire_response_deferred(self, flags: List[str] = None):\n         \"\"\"Builds response from the self._response dict\n         and fires the response deferred callback with the\n\n@@ -18,6 +18,7 @@ from twisted.web.server import Site, NOT_DONE_YET\n from twisted.web.static import File\n \n from scrapy.core.http2.protocol import H2ClientProtocol\n+from scrapy.core.http2.stream import InactiveStreamClosed\n from scrapy.http import Request, Response, JsonRequest\n from scrapy.utils.python import to_bytes, to_unicode\n from tests.mockserver import ssl_context_factory, LeafResource\n@@ -174,8 +175,12 @@ class Https2ClientProtocolTestCase(TestCase):\n         client_endpoint = SSL4ClientEndpoint(reactor, self.hostname, self.port_number, client_options)\n         self.client = yield client_endpoint.connect(h2_client_factory)\n \n+        # Increase the total time taken for each tests\n+        self.timeout = 180 # default is 120 seconds\n+\n     @inlineCallbacks\n     def tearDown(self):\n+        if self.client.is_connected:\n             yield self.client.transport.loseConnection()\n             yield self.client.transport.abortConnection()\n         yield self.server.stopListening()\n@@ -430,3 +435,45 @@ class Https2ClientProtocolTestCase(TestCase):\n         )\n \n         yield self._check_log_warnsize(request, warn_pattern, Data.NO_CONTENT_LENGTH)\n+\n+    def test_max_concurrent_streams(self):\n+        \"\"\"Send 1000 requests to check if we can handle\n+        very large number of request\n+        \"\"\"\n+\n+        def get_deferred():\n+            return self._check_GET(\n+                Request(self.get_url('/get-data-html-small')),\n+                Data.HTML_SMALL,\n+                200\n+            )\n+\n+        return self._check_repeat(get_deferred, 1000)\n+\n+    def test_inactive_stream(self):\n+        \"\"\"Here we send 110 requests considering the MAX_CONCURRENT_STREAMS\n+        by default is 100. After sending the first 100 requests we close the\n+        connection.\"\"\"\n+        d_list = []\n+\n+        def assert_inactive_stream(failure):\n+            self.assertIsNotNone(failure.check(InactiveStreamClosed))\n+\n+        # Send 100 request (we do not check the result)\n+        for _ in range(100):\n+            d = self.client.request(Request(self.get_url('/get-data-html-small')))\n+            d.addBoth(lambda _: None)\n+            d_list.append(d)\n+\n+        # Now send 10 extra request and save the response deferred in a list\n+        for _ in range(10):\n+            d = self.client.request(Request(self.get_url('/get-data-html-small')))\n+            d.addCallback(self.fail)\n+            d.addErrback(assert_inactive_stream)\n+            d_list.append(d)\n+\n+        # Close the connection now to fire all the extra 10 requests errback\n+        # with InactiveStreamClosed\n+        self.client.transport.abortConnection()\n+\n+        return DeferredList(d_list, consumeErrors=True, fireOnOneErrback=True)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#50dd9271b4566785430106cfa9384d51103f73d9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 23 | Files Changed: 2 | Hunks: 12 | Methods Changed: 14 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 35 | Churn Cumulative: 1688 | Contributors (this commit): 1 | Commits (past 90d): 21 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -226,14 +226,6 @@ class Stream:\n             self.remaining_content_length = self.remaining_content_length - chunk_size\n \n         self.remaining_content_length = max(0, self.remaining_content_length)\n-        logger.debug(\n-            \"{stream} sending {received}/{expected} data bytes ({frames} frames) to {ip_address}\".format(\n-                stream=self,\n-                received=self.content_length - self.remaining_content_length,\n-                expected=self.content_length,\n-                frames=data_frames_sent,\n-                ip_address=self._conn_metadata['ip_address'])\n-        )\n \n         # End the stream if no more data needs to be send\n         if self.remaining_content_length == 0:\n\n@@ -175,9 +175,6 @@ class Https2ClientProtocolTestCase(TestCase):\n         client_endpoint = SSL4ClientEndpoint(reactor, self.hostname, self.port_number, client_options)\n         self.client = yield client_endpoint.connect(h2_client_factory)\n \n-        # Increase the total time taken for each tests\n-        self.timeout = 180 # default is 120 seconds\n-\n     @inlineCallbacks\n     def tearDown(self):\n         if self.client.is_connected:\n@@ -231,21 +228,21 @@ class Https2ClientProtocolTestCase(TestCase):\n         request = Request(self.get_url('/get-data-html-large'))\n         return self._check_GET(request, Data.HTML_LARGE, 200)\n \n-    def _check_GET_x20(self, *args, **kwargs):\n+    def _check_GET_x10(self, *args, **kwargs):\n         def get_deferred():\n             return self._check_GET(*args, **kwargs)\n \n-        return self._check_repeat(get_deferred, 20)\n+        return self._check_repeat(get_deferred, 10)\n \n-    def test_GET_small_body_x20(self):\n-        return self._check_GET_x20(\n+    def test_GET_small_body_x10(self):\n+        return self._check_GET_x10(\n             Request(self.get_url('/get-data-html-small')),\n             Data.HTML_SMALL,\n             200\n         )\n \n-    def test_GET_large_body_x20(self):\n-        return self._check_GET_x20(\n+    def test_GET_large_body_x10(self):\n+        return self._check_GET_x10(\n             Request(self.get_url('/get-data-html-large')),\n             Data.HTML_LARGE,\n             200\n@@ -309,24 +306,24 @@ class Https2ClientProtocolTestCase(TestCase):\n             200\n         )\n \n-    def _check_POST_json_x20(self, *args, **kwargs):\n+    def _check_POST_json_x10(self, *args, **kwargs):\n         def get_deferred():\n             return self._check_POST_json(*args, **kwargs)\n \n-        return self._check_repeat(get_deferred, 20)\n+        return self._check_repeat(get_deferred, 10)\n \n-    def test_POST_small_json_x20(self):\n+    def test_POST_small_json_x10(self):\n         request = JsonRequest(url=self.get_url('/post-data-json-small'), method='POST', data=Data.JSON_SMALL)\n-        return self._check_POST_json_x20(\n+        return self._check_POST_json_x10(\n             request,\n             Data.JSON_SMALL,\n             Data.EXTRA_SMALL,\n             200\n         )\n \n-    def test_POST_large_json_x20(self):\n+    def test_POST_large_json_x10(self):\n         request = JsonRequest(url=self.get_url('/post-data-json-large'), method='POST', data=Data.JSON_LARGE)\n-        return self._check_POST_json_x20(\n+        return self._check_POST_json_x10(\n             request,\n             Data.JSON_LARGE,\n             Data.EXTRA_LARGE,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
