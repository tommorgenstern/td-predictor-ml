{"custom_id": "requests#248122a69787651ce157ba3b4cac49c3e827ed98", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 743 | Contributors (this commit): 40 | Commits (past 90d): 4 | Contributors (cumulative): 40 | DMM Complexity: None\n\nDIFF:\n@@ -95,6 +95,7 @@ setup(\n         'Programming Language :: Python :: 3.7',\n         'Programming Language :: Python :: 3.8',\n         'Programming Language :: Python :: 3.9',\n+        'Programming Language :: Python :: 3.10',\n         'Programming Language :: Python :: Implementation :: CPython',\n         'Programming Language :: Python :: Implementation :: PyPy'\n     ],\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#fc106ab586b9bfeca37c54780387b24b5d2b13b4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 3095 | Contributors (this commit): 101 | Commits (past 90d): 4 | Contributors (cumulative): 101 | DMM Complexity: None\n\nDIFF:\n@@ -154,7 +154,7 @@ def super_len(o):\n                 current_position = total_length\n         else:\n             if hasattr(o, 'seek') and total_length is None:\n-                # StringIO and BytesIO have seek but no useable fileno\n+                # StringIO and BytesIO have seek but no usable fileno\n                 try:\n                     # seek to end of file\n                     o.seek(0, 2)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#99b3b492418d0751ca960178d274f89805095e4c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 44 | Lines Deleted: 17 | Files Changed: 3 | Hunks: 7 | Methods Changed: 4 | Complexity Δ (Sum/Max): 3/5 | Churn Δ: 61 | Churn Cumulative: 11737 | Contributors (this commit): 227 | Commits (past 90d): 4 | Contributors (cumulative): 292 | DMM Complexity: 1.0\n\nDIFF:\n@@ -29,7 +29,7 @@ from .adapters import HTTPAdapter\n \n from .utils import (\n     requote_uri, get_environ_proxies, get_netrc_auth, should_bypass_proxies,\n-    get_auth_from_url, rewind_body\n+    get_auth_from_url, rewind_body, resolve_proxies\n )\n \n from .status_codes import codes\n@@ -269,7 +269,6 @@ class SessionRedirectMixin(object):\n         if new_auth is not None:\n             prepared_request.prepare_auth(new_auth)\n \n-\n     def rebuild_proxies(self, prepared_request, proxies):\n         \"\"\"This method re-evaluates the proxy configuration by considering the\n         environment variables. If we are redirected to a URL covered by\n@@ -282,21 +281,9 @@ class SessionRedirectMixin(object):\n \n         :rtype: dict\n         \"\"\"\n-        proxies = proxies if proxies is not None else {}\n         headers = prepared_request.headers\n-        url = prepared_request.url\n-        scheme = urlparse(url).scheme\n-        new_proxies = proxies.copy()\n-        no_proxy = proxies.get('no_proxy')\n-\n-        bypass_proxy = should_bypass_proxies(url, no_proxy=no_proxy)\n-        if self.trust_env and not bypass_proxy:\n-            environ_proxies = get_environ_proxies(url, no_proxy=no_proxy)\n-\n-            proxy = environ_proxies.get(scheme, environ_proxies.get('all'))\n-\n-            if proxy:\n-                new_proxies.setdefault(scheme, proxy)\n+        scheme = urlparse(prepared_request.url).scheme\n+        new_proxies = resolve_proxies(prepared_request, proxies, self.trust_env)\n \n         if 'Proxy-Authorization' in headers:\n             del headers['Proxy-Authorization']\n@@ -633,7 +620,10 @@ class Session(SessionRedirectMixin):\n         kwargs.setdefault('stream', self.stream)\n         kwargs.setdefault('verify', self.verify)\n         kwargs.setdefault('cert', self.cert)\n-        kwargs.setdefault('proxies', self.rebuild_proxies(request, self.proxies))\n+        if 'proxies' not in kwargs:\n+            kwargs['proxies'] = resolve_proxies(\n+                request, self.proxies, self.trust_env\n+            )\n \n         # It's possible that users might accidentally send a Request object.\n         # Guard against that specific failure case.\n\n@@ -830,6 +830,34 @@ def select_proxy(url, proxies):\n     return proxy\n \n \n+def resolve_proxies(request, proxies, trust_env=True):\n+    \"\"\"This method takes proxy information from a request and configuration\n+    input to resolve a mapping of target proxies. This will consider settings\n+    such a NO_PROXY to strip proxy configurations.\n+\n+    :param request: Request or PreparedRequest\n+    :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs\n+    :param trust_env: Boolean declaring whether to trust environment configs\n+\n+    :rtype: dict\n+    \"\"\"\n+    proxies = proxies if proxies is not None else {}\n+    url = request.url\n+    scheme = urlparse(url).scheme\n+    no_proxy = proxies.get('no_proxy')\n+    new_proxies = proxies.copy()\n+\n+    bypass_proxy = should_bypass_proxies(url, no_proxy=no_proxy)\n+    if trust_env and not bypass_proxy:\n+        environ_proxies = get_environ_proxies(url, no_proxy=no_proxy)\n+\n+        proxy = environ_proxies.get(scheme, environ_proxies.get('all'))\n+\n+        if proxy:\n+            new_proxies.setdefault(scheme, proxy)\n+    return new_proxies\n+\n+\n def default_user_agent(name=\"python-requests\"):\n     \"\"\"\n     Return a string representing the default user agent.\n\n@@ -590,6 +590,15 @@ class TestRequests:\n                 session = requests.Session()\n                 session.request(method='GET', url=httpbin())\n \n+    def test_proxy_authorization_preserved_on_request(self, httpbin):\n+        proxy_auth_value = \"Bearer XXX\"\n+        session = requests.Session()\n+        session.headers.update({\"Proxy-Authorization\": proxy_auth_value})\n+        resp = session.request(method='GET', url=httpbin('get'))\n+        sent_headers = resp.json().get('headers', {})\n+\n+        assert sent_headers.get(\"Proxy-Authorization\") == proxy_auth_value\n+\n     def test_basicauth_with_netrc(self, httpbin):\n         auth = ('user', 'pass')\n         wrong_auth = ('wronguser', 'wrongpass')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#55da533a87afe188282b7f8dfbadeb30c21743d8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 65 | Contributors (this commit): 4 | Commits (past 90d): 1 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -13,7 +13,6 @@ import threading\n \n import pytest\n from requests.compat import urljoin\n-import trustme\n \n \n def prepare_url(value):\n@@ -38,6 +37,10 @@ def httpbin_secure(httpbin_secure):\n \n @pytest.fixture\n def nosan_server(tmp_path_factory):\n+    # delay importing until the fixture in order to make it possible\n+    # to deselect the test via command-line when trustme is not available\n+    import trustme\n+\n     tmpdir = tmp_path_factory.mktemp(\"certs\")\n     ca = trustme.CA()\n     # only commonName, no subjectAltName\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#2d2447e210cf0b9e8c7484bfc6f158de9b24c171", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 18 | Churn Cumulative: 4614 | Contributors (this commit): 108 | Commits (past 90d): 4 | Contributors (cumulative): 134 | DMM Complexity: 1.0\n\nDIFF:\n@@ -124,7 +124,10 @@ def super_len(o):\n     elif hasattr(o, 'fileno'):\n         try:\n             fileno = o.fileno()\n-        except io.UnsupportedOperation:\n+        except (io.UnsupportedOperation, AttributeError):\n+            # AttributeError is a surprising exception, seeing as how we've just checked\n+            # that `hasattr(o, 'fileno')`.  It happens for objects obtained via\n+            # `Tarfile.extractfile()`, per issue 5229.\n             pass\n         else:\n             total_length = os.fstat(fileno).st_size\n\n@@ -4,6 +4,7 @@ import os\n import copy\n import filecmp\n from io import BytesIO\n+import tarfile\n import zipfile\n from collections import deque\n \n@@ -86,6 +87,18 @@ class TestSuperLen:\n             assert super_len(fd) == 4\n         assert len(recwarn) == warnings_num\n \n+    def test_tarfile_member(self, tmpdir):\n+        file_obj = tmpdir.join('test.txt')\n+        file_obj.write('Test')\n+\n+        tar_obj = str(tmpdir.join('test.tar'))\n+        with tarfile.open(tar_obj, 'w') as tar:\n+            tar.add(str(file_obj), arcname='test.txt')\n+\n+        with tarfile.open(tar_obj) as tar:\n+            member = tar.extractfile('test.txt')\n+            assert super_len(member) == 4\n+\n     def test_super_len_with__len__(self):\n         foo = [1,2,3,4]\n         len_foo = super_len(foo)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#658c10e84a461e5298199f20f17b510b90ac478a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 14741 | Contributors (this commit): 239 | Commits (past 90d): 20 | Contributors (cumulative): 281 | DMM Complexity: None\n\nDIFF:\n@@ -403,7 +403,7 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n                 host = self._get_idna_encoded_host(host)\n             except UnicodeError:\n                 raise InvalidURL('URL has an invalid label.')\n-        elif host.startswith(u'*'):\n+        elif host.startswith((u'*', u'.')):\n             raise InvalidURL('URL has an invalid label.')\n \n         # Carefully reconstruct the network location\n\n@@ -81,6 +81,8 @@ class TestRequests:\n             (InvalidSchema, 'localhost.localdomain:3128/'),\n             (InvalidSchema, '10.122.1.1:3128/'),\n             (InvalidURL, 'http://'),\n+            (InvalidURL, 'http://*example.com'),\n+            (InvalidURL, 'http://.example.com'),\n         ))\n     def test_invalid_url(self, exception, url):\n         with pytest.raises(exception):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#4246792b818ce804fb1bb98877c8ec7e8f71b2ca", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 10133 | Contributors (this commit): 203 | Commits (past 90d): 2 | Contributors (cumulative): 222 | DMM Complexity: None\n\nDIFF:\n@@ -80,11 +80,11 @@ class TooManyRedirects(RequestException):\n \n \n class MissingSchema(RequestException, ValueError):\n-    \"\"\"The URL schema (e.g. http or https) is missing.\"\"\"\n+    \"\"\"The URL scheme (e.g. http or https) is missing.\"\"\"\n \n \n class InvalidSchema(RequestException, ValueError):\n-    \"\"\"See defaults.py for valid schemas.\"\"\"\n+    \"\"\"The URL scheme provided is either invalid or unsupported.\"\"\"\n \n \n class InvalidURL(RequestException, ValueError):\n\n@@ -386,7 +386,7 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n             raise InvalidURL(*e.args)\n \n         if not scheme:\n-            error = (\"Invalid URL {0!r}: No schema supplied. Perhaps you meant http://{0}?\")\n+            error = (\"Invalid URL {0!r}: No scheme supplied. Perhaps you meant http://{0}?\")\n             error = error.format(to_native_string(url, 'utf8'))\n \n             raise MissingSchema(error)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#ef59aa0227bf463f0ed3d752b26db9b3acc64afb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 15 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 5 | Methods Changed: 1 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 20 | Churn Cumulative: 4634 | Contributors (this commit): 108 | Commits (past 90d): 10 | Contributors (cumulative): 134 | DMM Complexity: 1.0\n\nDIFF:\n@@ -21,6 +21,7 @@ import warnings\n import zipfile\n from collections import OrderedDict\n from urllib3.util import make_headers\n+from urllib3.util import parse_url\n \n from .__version__ import __version__\n from . import certs\n@@ -963,15 +964,23 @@ def prepend_scheme_if_needed(url, new_scheme):\n \n     :rtype: str\n     \"\"\"\n-    scheme, netloc, path, params, query, fragment = urlparse(url, new_scheme)\n+    parsed = parse_url(url)\n+    scheme, auth, host, port, path, query, fragment = parsed\n \n-    # urlparse is a finicky beast, and sometimes decides that there isn't a\n-    # netloc present. Assume that it's being over-cautious, and switch netloc\n-    # and path if urlparse decided there was no netloc.\n+    # A defect in urlparse determines that there isn't a netloc present in some\n+    # urls. We previously assumed parsing was overly cautious, and swapped the\n+    # netloc and path. Due to a lack of tests on the original defect, this is\n+    # maintained with parse_url for backwards compatibility.\n+    netloc = parsed.netloc\n     if not netloc:\n         netloc, path = path, netloc\n \n-    return urlunparse((scheme, netloc, path, params, query, fragment))\n+    if scheme is None:\n+        scheme = new_scheme\n+    if path is None:\n+        path = ''\n+\n+    return urlunparse((scheme, netloc, path, '', query, fragment))\n \n \n def get_auth_from_url(url):\n\n@@ -601,6 +601,7 @@ def test_parse_header_links(value, expected):\n     'value, expected', (\n         ('example.com/path', 'http://example.com/path'),\n         ('//example.com/path', 'http://example.com/path'),\n+        ('example.com:80', 'http://example.com:80'),\n     ))\n def test_prepend_scheme_if_needed(value, expected):\n     assert prepend_scheme_if_needed(value, 'http') == expected\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#0d5347e6281c85059be176fe650b0aa7128f1dcb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 3 | Churn Cumulative: 3150 | Contributors (this commit): 103 | Commits (past 90d): 3 | Contributors (cumulative): 103 | DMM Complexity: 0.0\n\nDIFF:\n@@ -850,8 +850,7 @@ def resolve_proxies(request, proxies, trust_env=True):\n     no_proxy = proxies.get('no_proxy')\n     new_proxies = proxies.copy()\n \n-    bypass_proxy = should_bypass_proxies(url, no_proxy=no_proxy)\n-    if trust_env and not bypass_proxy:\n+    if trust_env and not should_bypass_proxies(url, no_proxy=no_proxy):\n         environ_proxies = get_environ_proxies(url, no_proxy=no_proxy)\n \n         proxy = environ_proxies.get(scheme, environ_proxies.get('all'))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#17e6e27a93131b7295165408e69b4cadb098b0d7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 4 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 751 | Contributors (this commit): 40 | Commits (past 90d): 1 | Contributors (cumulative): 40 | DMM Complexity: None\n\nDIFF:\n@@ -84,9 +84,11 @@ setup(\n     zip_safe=False,\n     classifiers=[\n         'Development Status :: 5 - Production/Stable',\n+        'Environment :: Web Environment',\n         'Intended Audience :: Developers',\n-        'Natural Language :: English',\n         'License :: OSI Approved :: Apache Software License',\n+        'Natural Language :: English',\n+        'Operating System :: OS Independent',\n         'Programming Language :: Python',\n         'Programming Language :: Python :: 2',\n         'Programming Language :: Python :: 2.7',\n@@ -97,7 +99,9 @@ setup(\n         'Programming Language :: Python :: 3.9',\n         'Programming Language :: Python :: 3.10',\n         'Programming Language :: Python :: Implementation :: CPython',\n-        'Programming Language :: Python :: Implementation :: PyPy'\n+        'Programming Language :: Python :: Implementation :: PyPy',\n+        'Topic :: Internet :: WWW/HTTP',\n+        'Topic :: Software Development :: Libraries',\n     ],\n     cmdclass={'test': PyTest},\n     tests_require=test_requirements,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#0192aac24123735b3eaf9b08df46429bb770c283", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 164 | Contributors (this commit): 5 | Commits (past 90d): 1 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -5,10 +5,10 @@\n __title__ = 'requests'\n __description__ = 'Python HTTP for Humans.'\n __url__ = 'https://requests.readthedocs.io'\n-__version__ = '2.26.0'\n-__build__ = 0x022600\n+__version__ = '2.27.0'\n+__build__ = 0x022700\n __author__ = 'Kenneth Reitz'\n __author_email__ = 'me@kennethreitz.org'\n __license__ = 'Apache 2.0'\n-__copyright__ = 'Copyright 2020 Kenneth Reitz'\n+__copyright__ = 'Copyright 2022 Kenneth Reitz'\n __cake__ = u'\\u2728 \\U0001f370 \\u2728'\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#38f3f8ecb93cadfac03a6b7b3173018ac829d0cf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 12 | Churn Cumulative: 4649 | Contributors (this commit): 108 | Commits (past 90d): 6 | Contributors (cumulative): 135 | DMM Complexity: 1.0\n\nDIFF:\n@@ -974,6 +974,10 @@ def prepend_scheme_if_needed(url, new_scheme):\n     if not netloc:\n         netloc, path = path, netloc\n \n+    if auth:\n+        # parse_url doesn't provide the netloc with auth\n+        # so we'll add it ourselves.\n+        netloc = '@'.join([auth, netloc])\n     if scheme is None:\n         scheme = new_scheme\n     if path is None:\n\n@@ -602,6 +602,14 @@ def test_parse_header_links(value, expected):\n         ('example.com/path', 'http://example.com/path'),\n         ('//example.com/path', 'http://example.com/path'),\n         ('example.com:80', 'http://example.com:80'),\n+        (\n+            'http://user:pass@example.com/path?query',\n+            'http://user:pass@example.com/path?query'\n+        ),\n+        (\n+            'http://user@example.com/path?query',\n+            'http://user@example.com/path?query'\n+        )\n     ))\n def test_prepend_scheme_if_needed(value, expected):\n     assert prepend_scheme_if_needed(value, 'http') == expected\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#31a89d9c8463c3394ca00f408f4b86d814421a09", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 168 | Contributors (this commit): 5 | Commits (past 90d): 2 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -5,8 +5,8 @@\n __title__ = 'requests'\n __description__ = 'Python HTTP for Humans.'\n __url__ = 'https://requests.readthedocs.io'\n-__version__ = '2.27.0'\n-__build__ = 0x022700\n+__version__ = '2.27.1'\n+__build__ = 0x022701\n __author__ = 'Kenneth Reitz'\n __author_email__ = 'me@kennethreitz.org'\n __license__ = 'Apache 2.0'\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#fa1b0a367abc8488542f7ce7c02a3614ad8aa09d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 23 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 5 | Methods Changed: 3 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 26 | Churn Cumulative: 5122 | Contributors (this commit): 95 | Commits (past 90d): 4 | Contributors (cumulative): 108 | DMM Complexity: 1.0\n\nDIFF:\n@@ -34,6 +34,16 @@ class InvalidJSONError(RequestException):\n class JSONDecodeError(InvalidJSONError, CompatJSONDecodeError):\n     \"\"\"Couldn't decode the text into json\"\"\"\n \n+    def __init__(self, *args, **kwargs):\n+        \"\"\"\n+        Construct the JSONDecodeError instance first with all\n+        args. Then use it's args to construct the IOError so that\n+        the json specific args aren't used as IOError specific args\n+        and the error message from JSONDecodeError is preserved.\n+        \"\"\"\n+        CompatJSONDecodeError.__init__(self, *args)\n+        InvalidJSONError.__init__(self, *self.args, **kwargs)\n+\n \n class HTTPError(RequestException):\n     \"\"\"An HTTP error occurred.\"\"\"\n\n@@ -23,14 +23,14 @@ from requests.cookies import (\n     cookiejar_from_dict, morsel_to_cookie)\n from requests.exceptions import (\n     ConnectionError, ConnectTimeout, InvalidSchema, InvalidURL,\n-    MissingSchema, ReadTimeout, Timeout, RetryError, TooManyRedirects,\n+    MissingSchema, ReadTimeout, Timeout, RetryError, RequestException, TooManyRedirects,\n     ProxyError, InvalidHeader, UnrewindableBodyError, SSLError, InvalidProxyURL, InvalidJSONError)\n from requests.models import PreparedRequest\n from requests.structures import CaseInsensitiveDict\n from requests.sessions import SessionRedirectMixin\n from requests.models import urlencode\n from requests.hooks import default_hooks\n-from requests.compat import MutableMapping\n+from requests.compat import JSONDecodeError, is_py3, MutableMapping\n \n from .compat import StringIO, u\n from .utils import override_environ\n@@ -2585,5 +2585,15 @@ class TestPreparingURLs(object):\n \n     def test_json_decode_compatibility(self, httpbin):\n         r = requests.get(httpbin('bytes/20'))\n-        with pytest.raises(requests.exceptions.JSONDecodeError):\n+        with pytest.raises(requests.exceptions.JSONDecodeError) as excinfo:\n             r.json()\n+        assert isinstance(excinfo.value, RequestException)\n+        assert isinstance(excinfo.value, JSONDecodeError)\n+        assert r.text not in str(excinfo.value)\n+\n+    @pytest.mark.skipif(not is_py3, reason=\"doc attribute is only present on py3\")\n+    def test_json_decode_persists_doc_attr(self, httpbin):\n+        r = requests.get(httpbin('bytes/20'))\n+        with pytest.raises(requests.exceptions.JSONDecodeError) as excinfo:\n+            r.json()\n+        assert excinfo.value.doc == r.text\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#95f456733656ed93645ff0250bfa54f6d256f6fe", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 50 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 7 | Methods Changed: 4 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 55 | Churn Cumulative: 14814 | Contributors (this commit): 240 | Commits (past 90d): 5 | Contributors (cumulative): 283 | DMM Complexity: 0.8\n\nDIFF:\n@@ -19,7 +19,12 @@ from urllib3.fields import RequestField\n from urllib3.filepost import encode_multipart_formdata\n from urllib3.util import parse_url\n from urllib3.exceptions import (\n-    DecodeError, ReadTimeoutError, ProtocolError, LocationParseError)\n+    DecodeError,\n+    LocationParseError,\n+    ProtocolError,\n+    ReadTimeoutError,\n+    SSLError,\n+)\n \n from io import UnsupportedOperation\n from .hooks import default_hooks\n@@ -32,6 +37,7 @@ from .exceptions import (\n     ContentDecodingError, ConnectionError, StreamConsumedError,\n     InvalidJSONError)\n from .exceptions import JSONDecodeError as RequestsJSONDecodeError\n+from .exceptions import SSLError as RequestsSSLError\n from ._internal_utils import to_native_string, unicode_is_ascii\n from .utils import (\n     guess_filename, get_auth_from_url, requote_uri,\n@@ -765,6 +771,8 @@ class Response(object):\n                     raise ContentDecodingError(e)\n                 except ReadTimeoutError as e:\n                     raise ConnectionError(e)\n+                except SSLError as e:\n+                    raise RequestsSSLError(e)\n             else:\n                 # Standard file-like object.\n                 while True:\n\n@@ -14,6 +14,7 @@ import re\n import io\n import requests\n import pytest\n+import urllib3\n from requests.adapters import HTTPAdapter\n from requests.auth import HTTPDigestAuth, _basic_auth_str\n from requests.compat import (\n@@ -22,9 +23,25 @@ from requests.compat import (\n from requests.cookies import (\n     cookiejar_from_dict, morsel_to_cookie)\n from requests.exceptions import (\n-    ConnectionError, ConnectTimeout, InvalidSchema, InvalidURL,\n-    MissingSchema, ReadTimeout, Timeout, RetryError, RequestException, TooManyRedirects,\n-    ProxyError, InvalidHeader, UnrewindableBodyError, SSLError, InvalidProxyURL, InvalidJSONError)\n+    ChunkedEncodingError,\n+    ConnectionError,\n+    ConnectTimeout,\n+    ContentDecodingError,\n+    InvalidHeader,\n+    InvalidJSONError,\n+    InvalidProxyURL,\n+    InvalidSchema,\n+    InvalidURL,\n+    MissingSchema,\n+    ProxyError,\n+    ReadTimeout,\n+    RequestException,\n+    RetryError,\n+    Timeout,\n+    TooManyRedirects,\n+    UnrewindableBodyError,\n+)\n+from requests.exceptions import SSLError as RequestsSSLError\n from requests.models import PreparedRequest\n from requests.structures import CaseInsensitiveDict\n from requests.sessions import SessionRedirectMixin\n@@ -910,7 +927,7 @@ class TestRequests:\n         \"\"\"\n         When underlying SSL problems occur, an SSLError is raised.\n         \"\"\"\n-        with pytest.raises(SSLError):\n+        with pytest.raises(RequestsSSLError):\n             # Our local httpbin does not have a trusted CA, so this call will\n             # fail if we use our default trust bundle.\n             requests.get(httpbin_secure('status', '200'))\n@@ -1320,6 +1337,26 @@ class TestRequests:\n         with pytest.raises(TypeError):\n             chunks = r.iter_content(\"1024\")\n \n+    @pytest.mark.parametrize(\n+        'exception, args, expected', (\n+            (urllib3.exceptions.ProtocolError, tuple(), ChunkedEncodingError),\n+            (urllib3.exceptions.DecodeError, tuple(), ContentDecodingError),\n+            (urllib3.exceptions.ReadTimeoutError, (None, '', ''), ConnectionError),\n+            (urllib3.exceptions.SSLError, tuple(), RequestsSSLError),\n+        )\n+    )\n+    def test_iter_content_wraps_exceptions(\n+        self, httpbin, mocker, exception, args, expected\n+    ):\n+        r = requests.Response()\n+        r.raw = mocker.Mock()\n+        # ReadTimeoutError can't be initialized by mock\n+        # so we'll manually create the instance with args\n+        r.raw.stream.side_effect = exception(*args)\n+\n+        with pytest.raises(expected):\n+            next(r.iter_content(1024))\n+\n     def test_request_and_response_are_pickleable(self, httpbin):\n         r = requests.get(httpbin('get'))\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#79c4a017fe341fb989d3a7876cf4e44b87601b58", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 49 | Lines Deleted: 6 | Files Changed: 2 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 55 | Churn Cumulative: 8732 | Contributors (this commit): 163 | Commits (past 90d): 4 | Contributors (cumulative): 192 | DMM Complexity: 0.6111111111111112\n\nDIFF:\n@@ -702,11 +702,14 @@ class Session(SessionRedirectMixin):\n             for (k, v) in env_proxies.items():\n                 proxies.setdefault(k, v)\n \n-            # Look for requests environment configuration and be compatible\n-            # with cURL.\n+            # Look for requests environment configuration\n+            # and be compatible with cURL.\n             if verify is True or verify is None:\n-                verify = (os.environ.get('REQUESTS_CA_BUNDLE') or\n-                          os.environ.get('CURL_CA_BUNDLE'))\n+                verify = (\n+                    os.environ.get('REQUESTS_CA_BUNDLE')\n+                    or os.environ.get('CURL_CA_BUNDLE')\n+                    or verify\n+                )\n \n         # Merge all the kwargs.\n         proxies = merge_setting(proxies, self.proxies)\n@@ -714,8 +717,12 @@ class Session(SessionRedirectMixin):\n         verify = merge_setting(verify, self.verify)\n         cert = merge_setting(cert, self.cert)\n \n-        return {'verify': verify, 'proxies': proxies, 'stream': stream,\n-                'cert': cert}\n+        return {\n+            'proxies': proxies,\n+            'stream': stream,\n+            'verify': verify,\n+            'cert': cert\n+        }\n \n     def get_adapter(self, url):\n         \"\"\"\n\n@@ -898,6 +898,42 @@ class TestRequests:\n             requests.get(httpbin_secure(), cert=('.', INVALID_PATH))\n         assert str(e.value) == 'Could not find the TLS key file, invalid path: {}'.format(INVALID_PATH)\n \n+    @pytest.mark.parametrize(\n+        'env, expected', (\n+            ({}, True),\n+            ({'REQUESTS_CA_BUNDLE': '/some/path'}, '/some/path'),\n+            ({'REQUESTS_CA_BUNDLE': ''}, True),\n+            ({'CURL_CA_BUNDLE': '/some/path'}, '/some/path'),\n+            ({'CURL_CA_BUNDLE': ''}, True),\n+            ({'REQUESTS_CA_BUNDLE': '', 'CURL_CA_BUNDLE': ''}, True),\n+            (\n+                {\n+                    'REQUESTS_CA_BUNDLE': '/some/path',\n+                    'CURL_CA_BUNDLE': '/curl/path',\n+                },\n+                '/some/path',\n+            ),\n+            (\n+                {\n+                    'REQUESTS_CA_BUNDLE': '',\n+                    'CURL_CA_BUNDLE': '/curl/path',\n+                },\n+                '/curl/path',\n+            ),\n+        )\n+    )\n+    def test_env_cert_bundles(self, httpbin, mocker, env, expected):\n+        s = requests.Session()\n+        mocker.patch('os.environ', env)\n+        settings = s.merge_environment_settings(\n+            url=httpbin('get'),\n+            proxies={},\n+            stream=False,\n+            verify=True,\n+            cert=None\n+        )\n+        assert settings['verify'] == expected\n+\n     def test_http_with_certificate(self, httpbin):\n         r = requests.get(httpbin(), cert='.')\n         assert r.status_code == 200\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#8bce583b9547c7b82d44c8e97f37cf9a16cbe758", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 93 | Lines Deleted: 136 | Files Changed: 12 | Hunks: 71 | Methods Changed: 19 | Complexity Δ (Sum/Max): -15/0 | Churn Δ: 229 | Churn Cumulative: 26201 | Contributors (this commit): 399 | Commits (past 90d): 22 | Contributors (cumulative): 664 | DMM Complexity: 0.8333333333333334\n\nDIFF:\n@@ -8,7 +8,7 @@ Provides utility functions that are consumed internally by Requests\n which depend on extremely few external helpers (such as compat)\n \"\"\"\n \n-from .compat import is_py2, builtin_str, str\n+from .compat import builtin_str\n \n \n def to_native_string(string, encoding='ascii'):\n@@ -18,9 +18,6 @@ def to_native_string(string, encoding='ascii'):\n     \"\"\"\n     if isinstance(string, builtin_str):\n         out = string\n-    else:\n-        if is_py2:\n-            out = string.encode(encoding)\n     else:\n         out = string.decode(encoding)\n \n\n@@ -477,11 +477,6 @@ class HTTPAdapter(BaseAdapter):\n                     low_conn.send(b'0\\r\\n\\r\\n')\n \n                     # Receive the response from the server\n-                    try:\n-                        # For Python 2.7, use buffering of HTTP responses\n-                        r = low_conn.getresponse(buffering=True)\n-                    except TypeError:\n-                        # For compatibility with Python 3.3+\n                     r = low_conn.getresponse()\n \n                     resp = HTTPResponse.from_httplib(\n\n@@ -4,8 +4,9 @@\n requests.compat\n ~~~~~~~~~~~~~~~\n \n-This module handles import compatibility issues between Python 2 and\n-Python 3.\n+This module previously handled import compatibility issues\n+between Python 2 and Python 3. It remains for backwards\n+compatibility until the next major version.\n \"\"\"\n \n try:\n@@ -28,6 +29,7 @@ is_py2 = (_ver[0] == 2)\n #: Python 3.x?\n is_py3 = (_ver[0] == 3)\n \n+# json/simplejson module import resolution\n has_simplejson = False\n try:\n     import simplejson as json\n@@ -35,43 +37,23 @@ try:\n except ImportError:\n     import json\n \n+if has_simplejson:\n+    from simplejson import JSONDecodeError\n+else:\n+    from json import JSONDecodeError\n+\n # ---------\n-# Specifics\n+# Legacy Imports\n # ---------\n-\n-if is_py2:\n-    from urllib import (\n-        quote, unquote, quote_plus, unquote_plus, urlencode, getproxies,\n-        proxy_bypass, proxy_bypass_environment, getproxies_environment)\n-    from urlparse import urlparse, urlunparse, urljoin, urlsplit, urldefrag\n-    from urllib2 import parse_http_list\n-    import cookielib\n-    from Cookie import Morsel\n-    from StringIO import StringIO\n-    # Keep OrderedDict for backwards compatibility.\n-    from collections import Callable, Mapping, MutableMapping, OrderedDict\n-\n-    builtin_str = str\n-    bytes = str\n-    str = unicode\n-    basestring = basestring\n-    numeric_types = (int, long, float)\n-    integer_types = (int, long)\n-    JSONDecodeError = ValueError\n-\n-elif is_py3:\n from urllib.parse import urlparse, urlunparse, urljoin, urlsplit, urlencode, quote, unquote, quote_plus, unquote_plus, urldefrag\n from urllib.request import parse_http_list, getproxies, proxy_bypass, proxy_bypass_environment, getproxies_environment\n from http import cookiejar as cookielib\n from http.cookies import Morsel\n from io import StringIO\n+\n # Keep OrderedDict for backwards compatibility.\n from collections import OrderedDict\n from collections.abc import Callable, Mapping, MutableMapping\n-    if has_simplejson:\n-        from simplejson import JSONDecodeError\n-    else:\n-        from json import JSONDecodeError\n \n builtin_str = str\n str = str\n\n@@ -36,8 +36,8 @@ def _implementation():\n     \"\"\"Return a dict with the Python implementation and version.\n \n     Provide both the name and the version of the Python implementation\n-    currently running. For example, on CPython 2.7.5 it will return\n-    {'name': 'CPython', 'version': '2.7.5'}.\n+    currently running. For example, on CPython 3.10.3 it will return\n+    {'name': 'CPython', 'version': '3.10.3'}.\n \n     This function works best on CPython and PyPy: in particular, it probably\n     doesn't work for Jython or IronPython. Future investigation should be done\n\n@@ -8,7 +8,6 @@ This module contains the primary objects that power Requests.\n \"\"\"\n \n import datetime\n-import sys\n \n # Import encoding now, to avoid implicit import later.\n # Implicit import within threads may cause LookupError when standard library is in a ZIP,\n@@ -45,8 +44,8 @@ from .utils import (\n     iter_slices, guess_json_utf, super_len, check_header_validity)\n from .compat import (\n     Callable, Mapping,\n-    cookielib, urlunparse, urlsplit, urlencode, str, bytes,\n-    is_py2, chardet, builtin_str, basestring, JSONDecodeError)\n+    cookielib, urlunparse, urlsplit, urlencode,\n+    chardet, builtin_str, basestring, JSONDecodeError)\n from .compat import json as complexjson\n from .status_codes import codes\n \n@@ -373,7 +372,7 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n         if isinstance(url, bytes):\n             url = url.decode('utf8')\n         else:\n-            url = unicode(url) if is_py2 else str(url)\n+            url = str(url)\n \n         # Remove leading whitespaces from url\n         url = url.lstrip()\n@@ -424,18 +423,6 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n         if not path:\n             path = '/'\n \n-        if is_py2:\n-            if isinstance(scheme, str):\n-                scheme = scheme.encode('utf-8')\n-            if isinstance(netloc, str):\n-                netloc = netloc.encode('utf-8')\n-            if isinstance(path, str):\n-                path = path.encode('utf-8')\n-            if isinstance(query, str):\n-                query = query.encode('utf-8')\n-            if isinstance(fragment, str):\n-                fragment = fragment.encode('utf-8')\n-\n         if isinstance(params, (str, bytes)):\n             params = to_native_string(params)\n \n@@ -919,9 +906,6 @@ class Response(object):\n         except JSONDecodeError as e:\n             # Catch JSON-related errors and raise as requests.JSONDecodeError\n             # This aliases json.JSONDecodeError and simplejson.JSONDecodeError\n-            if is_py2: # e is a ValueError\n-                raise RequestsJSONDecodeError(e.message)\n-            else:\n             raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)\n \n     @property\n\n@@ -14,7 +14,7 @@ from datetime import timedelta\n from collections import OrderedDict\n \n from .auth import _basic_auth_str\n-from .compat import cookielib, is_py3, urljoin, urlparse, Mapping\n+from .compat import cookielib, urljoin, urlparse, Mapping\n from .cookies import (\n     cookiejar_from_dict, extract_cookies_to_jar, RequestsCookieJar, merge_cookies)\n from .models import Request, PreparedRequest, DEFAULT_REDIRECT_LIMIT\n@@ -39,10 +39,7 @@ from .models import REDIRECT_STATI\n \n # Preferred clock, based on which one is more accurate on a given system.\n if sys.platform == 'win32':\n-    try:  # Python 3.4+\n     preferred_clock = time.perf_counter\n-    except AttributeError:  # Earlier than Python 3.\n-        preferred_clock = time.clock\n else:\n     preferred_clock = time.time\n \n@@ -111,7 +108,6 @@ class SessionRedirectMixin(object):\n             # It is more likely to get UTF8 header rather than latin1.\n             # This causes incorrect handling of UTF8 encoded location headers.\n             # To solve this, we re-encode the location in latin1.\n-            if is_py3:\n             location = location.encode('latin1')\n             return to_native_string(location, 'utf8')\n         return None\n\n@@ -30,7 +30,7 @@ from ._internal_utils import to_native_string\n from .compat import parse_http_list as _parse_list_header\n from .compat import (\n     quote, urlparse, bytes, str, unquote, getproxies,\n-    proxy_bypass, urlunparse, basestring, integer_types, is_py3,\n+    proxy_bypass, urlunparse, basestring, integer_types,\n     proxy_bypass_environment, getproxies_environment, Mapping)\n from .cookies import cookiejar_from_dict\n from .structures import CaseInsensitiveDict\n@@ -54,10 +54,7 @@ if sys.platform == 'win32':\n \n     def proxy_bypass_registry(host):\n         try:\n-            if is_py3:\n             import winreg\n-            else:\n-                import _winreg as winreg\n         except ImportError:\n             return False\n \n@@ -281,12 +278,11 @@ def extract_zipped_paths(path):\n @contextlib.contextmanager\n def atomic_open(filename):\n     \"\"\"Write a file to the disk in an atomic fashion\"\"\"\n-    replacer = os.rename if sys.version_info[0] == 2 else os.replace\n     tmp_descriptor, tmp_name = tempfile.mkstemp(dir=os.path.dirname(filename))\n     try:\n         with os.fdopen(tmp_descriptor, 'wb') as tmp_handler:\n             yield tmp_handler\n-        replacer(tmp_name, filename)\n+        os.replace(tmp_name, filename)\n     except BaseException:\n         os.remove(tmp_name)\n         raise\n\n@@ -1,5 +1,4 @@\n #!/usr/bin/env python\n-# Learn more: https://github.com/kennethreitz/setup.py\n import os\n import sys\n \n@@ -8,7 +7,27 @@ from codecs import open\n from setuptools import setup\n from setuptools.command.test import test as TestCommand\n \n-here = os.path.abspath(os.path.dirname(__file__))\n+\n+CURRENT_PYTHON = sys.version_info[:2]\n+REQUIRED_PYTHON = (3, 7)\n+\n+if CURRENT_PYTHON < REQUIRED_PYTHON:\n+    sys.stderr.write(\n+        \"\"\"\n+==========================\n+Unsupported Python version\n+==========================\n+This version of Requests requires at least Python {}.{}, but\n+you're trying to install it on Python {}.{}. To resolve this,\n+consider upgrading to a supported Python version.\n+\n+If you can't upgrade your Python version, you'll need to\n+pin to an older version of Requests (<2.28).\n+\"\"\".format(\n+            *(REQUIRED_PYTHON + CURRENT_PYTHON)\n+        )\n+    )\n+    sys.exit(1)\n \n class PyTest(TestCommand):\n     user_options = [('pytest-args=', 'a', \"Arguments to pass into py.test\")]\n@@ -38,16 +57,11 @@ if sys.argv[-1] == 'publish':\n     os.system('twine upload dist/*')\n     sys.exit()\n \n-packages = ['requests']\n-\n requires = [\n-    'charset_normalizer~=2.0.0; python_version >= \"3\"',\n-    'chardet>=3.0.2,<5; python_version < \"3\"',\n-    'idna>=2.5,<3; python_version < \"3\"',\n-    'idna>=2.5,<4; python_version >= \"3\"',\n+    'charset_normalizer~=2.0.0',\n+    'idna>=2.5,<4',\n     'urllib3>=1.21.1,<1.27',\n-    'certifi>=2017.4.17'\n-\n+    'certifi>=2017.4.17',\n ]\n test_requirements = [\n     'pytest-httpbin==0.0.7',\n@@ -55,10 +69,11 @@ test_requirements = [\n     'pytest-mock',\n     'pytest-xdist',\n     'PySocks>=1.5.6, !=1.5.7',\n-    'pytest>=3'\n+    'pytest>=3',\n ]\n \n about = {}\n+here = os.path.abspath(os.path.dirname(__file__))\n with open(os.path.join(here, 'requests', '__version__.py'), 'r', 'utf-8') as f:\n     exec(f.read(), about)\n \n@@ -74,11 +89,11 @@ setup(\n     author=about['__author__'],\n     author_email=about['__author_email__'],\n     url=about['__url__'],\n-    packages=packages,\n+    packages=['requests'],\n     package_data={'': ['LICENSE', 'NOTICE']},\n     package_dir={'requests': 'requests'},\n     include_package_data=True,\n-    python_requires=\">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*, !=3.5.*\",\n+    python_requires=\">=3.7, <4\",\n     install_requires=requires,\n     license=about['__license__'],\n     zip_safe=False,\n@@ -90,14 +105,13 @@ setup(\n         'Natural Language :: English',\n         'Operating System :: OS Independent',\n         'Programming Language :: Python',\n-        'Programming Language :: Python :: 2',\n-        'Programming Language :: Python :: 2.7',\n         'Programming Language :: Python :: 3',\n-        'Programming Language :: Python :: 3.6',\n         'Programming Language :: Python :: 3.7',\n         'Programming Language :: Python :: 3.8',\n         'Programming Language :: Python :: 3.9',\n         'Programming Language :: Python :: 3.10',\n+        'Programming Language :: Python :: 3.11',\n+        'Programming Language :: Python :: 3 :: Only',\n         'Programming Language :: Python :: Implementation :: CPython',\n         'Programming Language :: Python :: Implementation :: PyPy',\n         'Topic :: Internet :: WWW/HTTP',\n@@ -108,7 +122,6 @@ setup(\n     extras_require={\n         'security': [],\n         'socks': ['PySocks>=1.5.6, !=1.5.7'],\n-        'socks:sys_platform == \"win32\" and python_version == \"2.7\"': ['win_inet_pton'],\n         'use_chardet_on_py3': ['chardet>=3.0.2,<5']\n     },\n     project_urls={\n\n@@ -1,7 +1,5 @@\n # -*- coding: utf-8 -*-\n-\n-from requests.compat import is_py3\n-\n+import warnings\n \n try:\n     import StringIO\n@@ -13,9 +11,14 @@ try:\n except ImportError:\n     cStringIO = None\n \n-if is_py3:\n+\n def u(s):\n+    warnings.warn(\n+        (\n+            \"This helper function is no longer relevant in Python 3. \"\n+            \"Usage of this alias should be discontinued as it will be \"\n+            \"removed in a future release of Requests.\"\n+        ),\n+        DeprecationWarning,\n+    )\n     return s\n-else:\n-    def u(s):\n-        return s.decode('unicode-escape')\n\n@@ -2,7 +2,6 @@\n \n \"\"\"Tests for Requests.\"\"\"\n \n-from __future__ import division\n import json\n import os\n import pickle\n@@ -18,7 +17,7 @@ import urllib3\n from requests.adapters import HTTPAdapter\n from requests.auth import HTTPDigestAuth, _basic_auth_str\n from requests.compat import (\n-    Morsel, cookielib, getproxies, str, urlparse,\n+    Morsel, cookielib, getproxies, urlparse,\n     builtin_str)\n from requests.cookies import (\n     cookiejar_from_dict, morsel_to_cookie)\n@@ -47,9 +46,9 @@ from requests.structures import CaseInsensitiveDict\n from requests.sessions import SessionRedirectMixin\n from requests.models import urlencode\n from requests.hooks import default_hooks\n-from requests.compat import JSONDecodeError, is_py3, MutableMapping\n+from requests.compat import JSONDecodeError, MutableMapping\n \n-from .compat import StringIO, u\n+from .compat import StringIO\n from .utils import override_environ\n from urllib3.util import Timeout as Urllib3Timeout\n \n@@ -519,7 +518,7 @@ class TestRequests:\n     @pytest.mark.parametrize(\n         'username, password', (\n             ('user', 'pass'),\n-            (u'имя'.encode('utf-8'), u'пароль'.encode('utf-8')),\n+            ('имя'.encode('utf-8'), 'пароль'.encode('utf-8')),\n             (42, 42),\n             (None, None),\n         ))\n@@ -843,8 +842,6 @@ class TestRequests:\n         with open('requirements-dev.txt') as f:\n             with pytest.raises(ValueError):\n                 requests.post(url, data='[{\"some\": \"data\"}]', files={'some': f})\n-            with pytest.raises(ValueError):\n-                requests.post(url, data=u('[{\"some\": \"data\"}]'), files={'some': f})\n \n     def test_request_ok_set(self, httpbin):\n         r = requests.get(httpbin('status', '404'))\n@@ -989,8 +986,8 @@ class TestRequests:\n \n     @pytest.mark.parametrize(\n         'data', (\n-            {'stuff': u('ëlïxr')},\n-            {'stuff': u('ëlïxr').encode('utf-8')},\n+            {'stuff': 'ëlïxr'},\n+            {'stuff': 'ëlïxr'.encode('utf-8')},\n             {'stuff': 'elixr'},\n             {'stuff': 'elixr'.encode('utf-8')},\n         ))\n@@ -1013,13 +1010,13 @@ class TestRequests:\n     def test_unicode_method_name(self, httpbin):\n         files = {'file': open(__file__, 'rb')}\n         r = requests.request(\n-            method=u('POST'), url=httpbin('post'), files=files)\n+            method='POST', url=httpbin('post'), files=files)\n         assert r.status_code == 200\n \n     def test_unicode_method_name_with_request_object(self, httpbin):\n         files = {'file': open(__file__, 'rb')}\n         s = requests.Session()\n-        req = requests.Request(u('POST'), httpbin('post'), files=files)\n+        req = requests.Request('POST', httpbin('post'), files=files)\n         prep = s.prepare_request(req)\n         assert isinstance(prep.method, builtin_str)\n         assert prep.method == 'POST'\n@@ -1029,7 +1026,7 @@ class TestRequests:\n \n     def test_non_prepared_request_error(self):\n         s = requests.Session()\n-        req = requests.Request(u('POST'), '/')\n+        req = requests.Request('POST', '/')\n \n         with pytest.raises(ValueError) as e:\n             s.send(req)\n@@ -1336,8 +1333,8 @@ class TestRequests:\n     def test_response_reason_unicode(self):\n         # check for unicode HTTP status\n         r = requests.Response()\n-        r.url = u'unicode URL'\n-        r.reason = u'Komponenttia ei löydy'.encode('utf-8')\n+        r.url = 'unicode URL'\n+        r.reason = 'Komponenttia ei löydy'.encode('utf-8')\n         r.status_code = 404\n         r.encoding = None\n         assert not r.ok  # old behaviour - crashes here\n@@ -1346,7 +1343,7 @@ class TestRequests:\n         # check raise_status falls back to ISO-8859-1\n         r = requests.Response()\n         r.url = 'some url'\n-        reason = u'Komponenttia ei löydy'\n+        reason = 'Komponenttia ei löydy'\n         r.reason = reason.encode('latin-1')\n         r.status_code = 500\n         r.encoding = None\n@@ -1593,7 +1590,7 @@ class TestRequests:\n         assert r.url == url\n \n     def test_header_keys_are_native(self, httpbin):\n-        headers = {u('unicode'): 'blah', 'byte'.encode('ascii'): 'blah'}\n+        headers = {'unicode': 'blah', 'byte'.encode('ascii'): 'blah'}\n         r = requests.Request('GET', httpbin('get'), headers=headers)\n         p = r.prepare()\n \n@@ -1605,7 +1602,7 @@ class TestRequests:\n     def test_header_validation(self, httpbin):\n         \"\"\"Ensure prepare_headers regex isn't flagging valid header contents.\"\"\"\n         headers_ok = {'foo': 'bar baz qux',\n-                      'bar': u'fbbq'.encode('utf8'),\n+                      'bar': 'fbbq'.encode('utf8'),\n                       'baz': '',\n                       'qux': '1'}\n         r = requests.get(httpbin('get'), headers=headers_ok)\n@@ -1885,7 +1882,7 @@ class TestRequests:\n     @pytest.mark.parametrize(\n         'username, password, auth_str', (\n             ('test', 'test', 'Basic dGVzdDp0ZXN0'),\n-            (u'имя'.encode('utf-8'), u'пароль'.encode('utf-8'), 'Basic 0LjQvNGPOtC/0LDRgNC+0LvRjA=='),\n+            ('имя'.encode('utf-8'), 'пароль'.encode('utf-8'), 'Basic 0LjQvNGPOtC/0LDRgNC+0LvRjA=='),\n         ))\n     def test_basic_auth_str_is_always_native(self, username, password, auth_str):\n         s = _basic_auth_str(username, password)\n@@ -2469,7 +2466,7 @@ def test_data_argument_accepts_tuples(data):\n         },\n         {\n             'method': 'GET',\n-            'url': u('http://www.example.com/üniçø∂é')\n+            'url': 'http://www.example.com/üniçø∂é'\n         },\n     ))\n def test_prepared_copy(kwargs):\n@@ -2507,39 +2504,39 @@ class TestPreparingURLs(object):\n         'url,expected',\n         (\n             ('http://google.com', 'http://google.com/'),\n-            (u'http://ジェーピーニック.jp', u'http://xn--hckqz9bzb1cyrb.jp/'),\n-            (u'http://xn--n3h.net/', u'http://xn--n3h.net/'),\n+            ('http://ジェーピーニック.jp', 'http://xn--hckqz9bzb1cyrb.jp/'),\n+            ('http://xn--n3h.net/', 'http://xn--n3h.net/'),\n             (\n-                u'http://ジェーピーニック.jp'.encode('utf-8'),\n-                u'http://xn--hckqz9bzb1cyrb.jp/'\n+                'http://ジェーピーニック.jp'.encode('utf-8'),\n+                'http://xn--hckqz9bzb1cyrb.jp/'\n             ),\n             (\n-                u'http://straße.de/straße',\n-                u'http://xn--strae-oqa.de/stra%C3%9Fe'\n+                'http://straße.de/straße',\n+                'http://xn--strae-oqa.de/stra%C3%9Fe'\n             ),\n             (\n-                u'http://straße.de/straße'.encode('utf-8'),\n-                u'http://xn--strae-oqa.de/stra%C3%9Fe'\n+                'http://straße.de/straße'.encode('utf-8'),\n+                'http://xn--strae-oqa.de/stra%C3%9Fe'\n             ),\n             (\n-                u'http://Königsgäßchen.de/straße',\n-                u'http://xn--knigsgchen-b4a3dun.de/stra%C3%9Fe'\n+                'http://Königsgäßchen.de/straße',\n+                'http://xn--knigsgchen-b4a3dun.de/stra%C3%9Fe'\n             ),\n             (\n-                u'http://Königsgäßchen.de/straße'.encode('utf-8'),\n-                u'http://xn--knigsgchen-b4a3dun.de/stra%C3%9Fe'\n+                'http://Königsgäßchen.de/straße'.encode('utf-8'),\n+                'http://xn--knigsgchen-b4a3dun.de/stra%C3%9Fe'\n             ),\n             (\n                 b'http://xn--n3h.net/',\n-                u'http://xn--n3h.net/'\n+                'http://xn--n3h.net/'\n             ),\n             (\n                 b'http://[1200:0000:ab00:1234:0000:2552:7777:1313]:12345/',\n-                u'http://[1200:0000:ab00:1234:0000:2552:7777:1313]:12345/'\n+                'http://[1200:0000:ab00:1234:0000:2552:7777:1313]:12345/'\n             ),\n             (\n-                u'http://[1200:0000:ab00:1234:0000:2552:7777:1313]:12345/',\n-                u'http://[1200:0000:ab00:1234:0000:2552:7777:1313]:12345/'\n+                'http://[1200:0000:ab00:1234:0000:2552:7777:1313]:12345/',\n+                'http://[1200:0000:ab00:1234:0000:2552:7777:1313]:12345/'\n             )\n         )\n     )\n@@ -2664,7 +2661,6 @@ class TestPreparingURLs(object):\n         assert isinstance(excinfo.value, JSONDecodeError)\n         assert r.text not in str(excinfo.value)\n \n-    @pytest.mark.skipif(not is_py3, reason=\"doc attribute is only present on py3\")\n     def test_json_decode_persists_doc_attr(self, httpbin):\n         r = requests.get(httpbin('bytes/20'))\n         with pytest.raises(requests.exceptions.JSONDecodeError) as excinfo:\n\n@@ -749,10 +749,7 @@ def test_should_bypass_proxies_win_registry(url, expected, override,\n     \"\"\"\n     if override is None:\n         override = '192.168.*;127.0.0.1;localhost.localdomain;172.16.1.1'\n-    if compat.is_py3:\n     import winreg\n-    else:\n-        import _winreg as winreg\n \n     class RegHandle:\n         def Close(self):\n\n@@ -78,9 +78,7 @@ class Server(threading.Thread):\n     def _create_socket_and_bind(self):\n         sock = socket.socket()\n         sock.bind((self.host, self.port))\n-        # NB: when Python 2.7 is no longer supported, the argument\n-        # can be removed to use a default backlog size\n-        sock.listen(5)\n+        sock.listen()\n         return sock\n \n     def _close_server_sock_ignore_errors(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
