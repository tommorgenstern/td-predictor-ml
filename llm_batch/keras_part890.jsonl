{"custom_id": "keras#9250be211e76025d1fa6101febd3bdb9af47a360", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 29 | Files Changed: 2 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 36 | Churn Cumulative: 428 | Contributors (this commit): 2 | Commits (past 90d): 7 | Contributors (cumulative): 4 | DMM Complexity: 0.0\n\nDIFF:\n@@ -17,10 +17,12 @@ def get_input_signature(model):\n             \"The model provided has not yet been built. It must be built \"\n             \"before export.\"\n         )\n-    if isinstance(model, (models.Functional, models.Sequential)):\n+    if isinstance(model, models.Functional):\n+        input_signature = [\n+            tree.map_structure(make_input_spec, model._inputs_struct)\n+        ]\n+    elif isinstance(model, models.Sequential):\n         input_signature = tree.map_structure(make_input_spec, model.inputs)\n-        if isinstance(input_signature, list) and len(input_signature) > 1:\n-            input_signature = [input_signature]\n     else:\n         input_signature = _infer_input_signature_from_model(model)\n         if not input_signature or not model._called:\n\n@@ -728,19 +728,7 @@ class ExportArchiveTest(testing.TestCase):\n         ref_inputs = [tf.random.normal((3, 2)), tf.random.normal((3, 2))]\n         ref_outputs = model(ref_inputs)\n \n-        export_archive = saved_model.ExportArchive()\n-        export_archive.track(model)\n-        export_archive.add_endpoint(\n-            \"serve\",\n-            model.__call__,\n-            input_signature=[\n-                [\n-                    tf.TensorSpec(shape=(None, 2), dtype=tf.float32),\n-                    tf.TensorSpec(shape=(None, 2), dtype=tf.float32),\n-                ]\n-            ],\n-        )\n-        export_archive.write_out(temp_filepath)\n+        model.export(temp_filepath)\n         revived_model = tf.saved_model.load(temp_filepath)\n         self.assertAllClose(ref_outputs[0], revived_model.serve(ref_inputs)[0])\n         self.assertAllClose(ref_outputs[1], revived_model.serve(ref_inputs)[1])\n@@ -758,19 +746,7 @@ class ExportArchiveTest(testing.TestCase):\n         }\n         ref_outputs = model(ref_inputs)\n \n-        export_archive = saved_model.ExportArchive()\n-        export_archive.track(model)\n-        export_archive.add_endpoint(\n-            \"serve\",\n-            model.__call__,\n-            input_signature=[\n-                {\n-                    \"x1\": tf.TensorSpec(shape=(None, 2), dtype=tf.float32),\n-                    \"x2\": tf.TensorSpec(shape=(None, 2), dtype=tf.float32),\n-                }\n-            ],\n-        )\n-        export_archive.write_out(temp_filepath)\n+        model.export(temp_filepath)\n         revived_model = tf.saved_model.load(temp_filepath)\n         self.assertAllClose(ref_outputs[0], revived_model.serve(ref_inputs)[0])\n         self.assertAllClose(ref_outputs[1], revived_model.serve(ref_inputs)[1])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7deeec5c5476a99eff28af0d7b124230e1d80c3c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 339 | Contributors (this commit): 13 | Commits (past 90d): 4 | Contributors (cumulative): 13 | DMM Complexity: 1.0\n\nDIFF:\n@@ -578,8 +578,9 @@ def scatter_update(inputs, indices, updates):\n     updates = convert_to_tensor(updates)\n     indices = torch.transpose(indices, 0, 1)\n \n-    inputs[tuple(indices)] = updates\n-    return inputs\n+    outputs = torch.clone(inputs)\n+    outputs[tuple(indices)] = updates\n+    return outputs\n \n \n def slice(inputs, start_indices, shape):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3f8b065e82b17884bd43fcfbd4bd79f18a7019fe", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 38 | Lines Deleted: 18 | Files Changed: 1 | Hunks: 9 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 56 | Churn Cumulative: 105 | Contributors (this commit): 6 | Commits (past 90d): 1 | Contributors (cumulative): 6 | DMM Complexity: 0.0\n\nDIFF:\n@@ -224,24 +224,26 @@ class ModelCheckpoint(Callback):\n             return True\n         return False\n \n-    def _save_model(self, epoch, batch, logs):\n-        \"\"\"Saves the model.\n+    def _should_save_model(self, epoch, batch, logs, filepath):\n+        \"\"\"Determines whether the model should be saved.\n+\n+        The model should be saved in the following cases:\n+\n+        - self.save_best_only is False\n+        - self.save_best_only is True and `monitor` is a numpy array or\n+          backend tensor (falls back to `save_best_only=False`)\n+        - self.save_best_only is True and `self.monitor_op(current, self.best)`\n+          evaluates to True.\n \n         Args:\n             epoch: the epoch this iteration is in.\n             batch: the batch this iteration is in. `None` if the `save_freq`\n                 is set to `\"epoch\"`.\n-            logs: the `logs` dict passed in to `on_batch_end` or `on_epoch_end`.\n+            logs: the `logs` dict passed in to `on_batch_end` or\n+                `on_epoch_end`.\n+            filepath: the path where the model would be saved\n         \"\"\"\n         logs = logs or {}\n-\n-        filepath = self._get_file_path(epoch, batch, logs)\n-        # Create host directory if it doesn't exist.\n-        dirname = os.path.dirname(filepath)\n-        if dirname and not file_utils.exists(dirname):\n-            file_utils.makedirs(dirname)\n-\n-        try:\n         if self.save_best_only:\n             current = logs.get(self.monitor)\n             if current is None:\n@@ -250,16 +252,16 @@ class ModelCheckpoint(Callback):\n                     \"available, skipping.\",\n                     stacklevel=2,\n                 )\n+                return False\n             elif (\n-                    isinstance(current, np.ndarray)\n-                    or backend.is_tensor(current)\n+                isinstance(current, np.ndarray) or backend.is_tensor(current)\n             ) and len(current.shape) > 0:\n                 warnings.warn(\n                     \"Can save best model only when `monitor` is \"\n                     f\"a scalar value. Received: {current}. \"\n                     \"Falling back to `save_best_only=False`.\"\n                 )\n-                    self.model.save(filepath, overwrite=True)\n+                return True\n             else:\n                 if self.monitor_op(current, self.best):\n                     if self.verbose > 0:\n@@ -270,10 +272,7 @@ class ModelCheckpoint(Callback):\n                             f\"saving model to {filepath}\"\n                         )\n                     self.best = current\n-                        if self.save_weights_only:\n-                            self.model.save_weights(filepath, overwrite=True)\n-                        else:\n-                            self.model.save(filepath, overwrite=True)\n+                    return True\n                 else:\n                     if self.verbose > 0:\n                         io_utils.print_msg(\n@@ -281,11 +280,32 @@ class ModelCheckpoint(Callback):\n                             f\"{self.monitor} did not improve \"\n                             f\"from {self.best:.5f}\"\n                         )\n+                    return False\n         else:\n             if self.verbose > 0:\n                 io_utils.print_msg(\n                     f\"\\nEpoch {epoch + 1}: saving model to {filepath}\"\n                 )\n+            return True\n+\n+    def _save_model(self, epoch, batch, logs):\n+        \"\"\"Saves the model.\n+\n+        Args:\n+            epoch: the epoch this iteration is in.\n+            batch: the batch this iteration is in. `None` if the `save_freq`\n+                is set to `\"epoch\"`.\n+            logs: the `logs` dict passed in to `on_batch_end` or `on_epoch_end`.\n+        \"\"\"\n+        filepath = self._get_file_path(epoch, batch, logs)\n+\n+        try:\n+            if self._should_save_model(epoch, batch, logs, filepath):\n+                # Create host directory if it doesn't exist.\n+                dirname = os.path.dirname(filepath)\n+                if dirname and not file_utils.exists(dirname):\n+                    file_utils.makedirs(dirname)\n+\n                 if self.save_weights_only:\n                     self.model.save_weights(filepath, overwrite=True)\n                 else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e1c59ff376178715a6bd3ed175debaa3dcfca29e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 56 | Lines Deleted: 29 | Files Changed: 1 | Hunks: 16 | Methods Changed: 9 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 85 | Churn Cumulative: 762 | Contributors (this commit): 9 | Commits (past 90d): 4 | Contributors (cumulative): 9 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,5 +1,5 @@\n import pickle\n-from unittest.mock import patch\n+from unittest import mock\n \n import numpy as np\n import pytest\n@@ -14,11 +14,25 @@ from keras.src import models\n from keras.src import ops\n from keras.src import testing\n from keras.src.backend.common import global_state\n-from keras.src.backend.common import remat\n from keras.src.backend.common.remat import RematScope\n from keras.src.models import Model\n \n \n+class MockRemat:\n+    \"\"\"Mock remat by returning a wrapper Mock calling the original function\"\"\"\n+\n+    def __init__(self):\n+        self.rematted_functions = {}\n+\n+    def __call__(self, func):\n+        if func in self.rematted_functions:\n+            return self.rematted_functions[func]\n+\n+        wrapped_func = mock.Mock(wraps=func)\n+        self.rematted_functions[func] = wrapped_func\n+        return wrapped_func\n+\n+\n class LayerTest(testing.TestCase):\n     def test_compute_output_spec(self):\n         # Test that implementing compute_output_shape\n@@ -173,9 +187,10 @@ class LayerTest(testing.TestCase):\n     def test_layer_with_remat(self):\n         \"\"\"Test rematerialization on a simple layer.\"\"\"\n         # Create a mock to track calls to remat\n-        with patch(\n-            \"keras.src.backend.common.remat.remat\", wraps=remat.remat\n-        ) as mock_remat:\n+        mock_remat = MockRemat()\n+        with mock.patch(\n+            \"keras.src.backend.common.remat.remat\", wraps=mock_remat\n+        ):\n \n             class SomeLayer(layers.Layer):\n                 def call(self, x):\n@@ -195,13 +210,15 @@ class LayerTest(testing.TestCase):\n             self.assertAllClose(output_no_remat, output_with_remat)\n \n         # Ensure remat was applied in the second case\n-            mock_remat.assert_called()\n+        self.assertLen(mock_remat.rematted_functions, 1)\n+        next(iter(mock_remat.rematted_functions.values())).assert_called()\n \n     def test_quantized_layer_with_remat(self):\n         \"\"\"Test rematerialization on a quantized layer.\"\"\"\n-        with patch(\n-            \"keras.src.backend.common.remat.remat\", wraps=remat.remat\n-        ) as mock_remat:\n+        mock_remat = MockRemat()\n+        with mock.patch(\n+            \"keras.src.backend.common.remat.remat\", wraps=mock_remat\n+        ):\n             input_tensor = backend.random.uniform((2, 4))\n \n             # Case 2: With rematerialization\n@@ -212,16 +229,19 @@ class LayerTest(testing.TestCase):\n                 layer(input_tensor)\n \n         # Ensure remat was applied\n-            mock_remat.assert_called()\n+        self.assertLen(mock_remat.rematted_functions, 1)\n+        next(iter(mock_remat.rematted_functions.values())).assert_called()\n \n     def test_functional_model_with_remat(self):\n         if backend.backend() in (\"openvino\", \"numpy\"):\n             self.skipTest(\n                 \"remat is not supported in openvino and numpy backends.\"\n             )\n-        with patch(\n-            \"keras.src.backend.common.remat.remat\", wraps=remat.remat\n-        ) as mock_remat:\n+        # traceback_utils.enable_traceback_filtering()\n+        mock_remat = MockRemat()\n+        with mock.patch(\n+            \"keras.src.backend.common.remat.remat\", wraps=mock_remat\n+        ):\n             # Define model inputs\n             inputs = Input(shape=(32, 32, 3))\n \n@@ -241,14 +261,17 @@ class LayerTest(testing.TestCase):\n             y_train = np.random.random((10, 64)).astype(np.float32)\n \n             # Run training to ensure `RematScope` is applied correctly\n-            model.fit(x_train, y_train, epochs=1, batch_size=2)\n-            self.assertGreater(mock_remat.call_count, 1)\n+            model.fit(x_train, y_train, epochs=1, batch_size=2, verbose=0)\n+\n+        self.assertLen(mock_remat.rematted_functions, 1)\n+        next(iter(mock_remat.rematted_functions.values())).assert_called()\n \n     def test_remat_wrapper_list_of_layers(self):\n         \"\"\"Test rematerialization using list_of_layers mode.\"\"\"\n-        with patch(\n-            \"keras.src.backend.common.remat.remat\", wraps=remat.remat\n-        ) as mock_remat:\n+        mock_remat = MockRemat()\n+        with mock.patch(\n+            \"keras.src.backend.common.remat.remat\", wraps=mock_remat\n+        ):\n \n             class TestLayer(layers.Layer):\n                 def call(self, x):\n@@ -271,13 +294,15 @@ class LayerTest(testing.TestCase):\n             self.assertAllClose(output_other, input_tensor * 2)\n \n         # Ensure remat was applied to the correct layer\n-            mock_remat.assert_called_once()\n+        self.assertLen(mock_remat.rematted_functions, 1)\n+        next(iter(mock_remat.rematted_functions.values())).assert_called()\n \n     def test_remat_larger_than_mode(self):\n         \"\"\"Test rematerialization using larger_than mode.\"\"\"\n-        with patch(\n-            \"keras.src.backend.common.remat.remat\", wraps=remat.remat\n-        ) as mock_remat:\n+        mock_remat = MockRemat()\n+        with mock.patch(\n+            \"keras.src.backend.common.remat.remat\", wraps=mock_remat\n+        ):\n \n             class TestLayer(layers.Layer):\n                 def compute_output_shape(self, input_shape):\n@@ -295,13 +320,15 @@ class LayerTest(testing.TestCase):\n             self.assertAllClose(output, input_tensor + 1)\n \n         # Ensure remat was applied\n-            mock_remat.assert_called()\n+        self.assertLen(mock_remat.rematted_functions, 1)\n+        next(iter(mock_remat.rematted_functions.values())).assert_called()\n \n     def test_remat_larger_than_mode_high_threshold(self):\n         \"\"\"Test rematerialization using larger_than mode.\"\"\"\n-        with patch(\n-            \"keras.src.backend.common.remat.remat\", wraps=remat.remat\n-        ) as mock_remat:\n+        mock_remat = MockRemat()\n+        with mock.patch(\n+            \"keras.src.backend.common.remat.remat\", wraps=mock_remat\n+        ):\n \n             class TestLayer(layers.Layer):\n                 def compute_output_shape(self, input_shape):\n@@ -318,8 +345,8 @@ class LayerTest(testing.TestCase):\n \n             self.assertAllClose(output, input_tensor + 1)\n \n-            # Ensure remat was applied\n-            mock_remat.assert_not_called()\n+        # Ensure remat was not applied\n+        self.assertLen(mock_remat.rematted_functions, 0)\n \n     def test_rng_seed_tracking(self):\n         class RNGLayer(layers.Layer):\n@@ -740,7 +767,7 @@ class LayerTest(testing.TestCase):\n         )\n         model.compile(loss=\"mse\")\n         targets = np.array([[[1.0, 1.0], [2.0, 2.0], [3.0, 3.0], [1.0, 1.0]]])\n-        loss = model.evaluate(np.array([[1, 0, 0, 1]]), targets)\n+        loss = model.evaluate(np.array([[1, 0, 0, 1]]), targets, verbose=0)\n         self.assertAllClose(loss, 0.0)\n \n     @pytest.mark.skipif(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7577b3a88393842f1f66bf7fce98a915a0f25ec9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 30 | Lines Deleted: 14 | Files Changed: 3 | Hunks: 16 | Methods Changed: 5 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 44 | Churn Cumulative: 1352 | Contributors (this commit): 12 | Commits (past 90d): 14 | Contributors (cumulative): 25 | DMM Complexity: 0.5333333333333333\n\nDIFF:\n@@ -17,6 +17,7 @@ And some more magic:\n \"\"\"\n \n import collections\n+import functools\n import inspect\n import math\n import warnings\n@@ -1053,11 +1054,13 @@ class Layer(BackendLayer, Operation, KerasSaveable):\n                 if self._remat_mode is not None:\n                     outputs = self.rematerialized_call(\n                         self.quantized_call, *args, **kwargs\n-                    )\n+                    )(*args, **kwargs)\n                 else:\n                     outputs = self.quantized_call(*args, **kwargs)\n             elif self._remat_mode is not None:\n-                outputs = self.rematerialized_call(self.call, *args, **kwargs)\n+                outputs = self.rematerialized_call(self.call, *args, **kwargs)(\n+                    *args, **kwargs\n+                )\n             else:\n                 outputs = self.call(*args, **kwargs)\n             if return_losses:\n@@ -1611,13 +1614,13 @@ class Layer(BackendLayer, Operation, KerasSaveable):\n \n         # Full rematerialization\n         if self._remat_mode.mode == \"full\":\n-            return remat.remat(layer_call)(*args, **kwargs)\n+            return remat.remat(layer_call)\n \n         # Apply rematerialization to specific layers\n         elif self._remat_mode.mode == \"list_of_layers\" and (\n             self.name in self._remat_mode.layer_names\n         ):\n-            return remat.remat(layer_call)(*args, **kwargs)\n+            return remat.remat(layer_call)\n \n         # Apply rematerialization based on output size threshold\n         elif self._remat_mode.mode == \"larger_than\":\n@@ -1629,20 +1632,24 @@ class Layer(BackendLayer, Operation, KerasSaveable):\n                 output_size\n                 and output_size > self._remat_mode.output_size_threshold\n             ):\n-                return remat.remat(layer_call)(*args, **kwargs)\n+                return remat.remat(layer_call)\n         elif self._remat_mode.mode == \"activations\":\n             has_activation = (\n                 hasattr(self, \"activation\") and self.activation is not None\n             )\n             if has_activation:\n-                not_rematted_activation = self.activation\n+\n+                @functools.wraps(layer_call)\n+                def rematerialized_activation_call_wrapper(*args, **kwargs):\n+                    original_activation = self.activation\n+                    self.activation = remat.remat(original_activation)\n                     try:\n-                    self.activation = remat.remat(not_rematted_activation)\n                         return layer_call(*args, **kwargs)\n                     finally:\n-                    self.activation = not_rematted_activation\n+                        self.activation = original_activation\n \n-        return layer_call(*args, **kwargs)\n+                return rematerialized_activation_call_wrapper\n+        return layer_call\n \n \n def is_backend_tensor_or_symbolic(x, allow_none=False):\n\n@@ -16,6 +16,7 @@ from keras.src import testing\n from keras.src.backend.common import global_state\n from keras.src.backend.common.remat import RematScope\n from keras.src.models import Model\n+from keras.src.utils import traceback_utils\n \n \n class MockRemat:\n@@ -237,7 +238,7 @@ class LayerTest(testing.TestCase):\n             self.skipTest(\n                 \"remat is not supported in openvino and numpy backends.\"\n             )\n-        # traceback_utils.enable_traceback_filtering()\n+        traceback_utils.enable_traceback_filtering()\n         mock_remat = MockRemat()\n         with mock.patch(\n             \"keras.src.backend.common.remat.remat\", wraps=mock_remat\n\n@@ -37,9 +37,15 @@ class Operation:\n             else:\n                 if getattr(self, \"_remat_mode\", None) is not None:\n                     if getattr(self, \"quantization_mode\", None) is not None:\n-                        call_fn = self.rematerialized_call(self.quantized_call)\n+                        call_fn = self.rematerialized_call(\n+                            self.quantized_call,\n+                            *args,\n+                            **kwargs,\n+                        )\n                     else:\n-                        call_fn = self.rematerialized_call(self.call)\n+                        call_fn = self.rematerialized_call(\n+                            self.call, *args, **kwargs\n+                        )\n                 else:\n                     if getattr(self, \"quantization_mode\", None) is not None:\n                         call_fn = self.quantized_call\n@@ -58,9 +64,11 @@ class Operation:\n             if getattr(self, \"quantization_mode\", None) is not None:\n                 return self.rematerialized_call(\n                     self.quantized_call, *args, **kwargs\n-                )\n+                )(*args, **kwargs)\n             else:\n-                return self.rematerialized_call(self.call, *args, **kwargs)\n+                return self.rematerialized_call(self.call, *args, **kwargs)(\n+                    *args, **kwargs\n+                )\n         else:\n             if getattr(self, \"quantization_mode\", None) is not None:\n                 return self.quantized_call(*args, **kwargs)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6d26efbe97c72323566ef12ca639a888ab3ea340", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 22 | Contributors (this commit): 3 | Commits (past 90d): 1 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -20,7 +20,7 @@ class TrackingTest(testing.TestCase):\n         v2 = backend.Variable(2.0)\n         lst = tracking.TrackedList([], tracker)\n         lst.append(v1)\n-        lst.append(None)\n+        lst.append(float(\"nan\"))\n         lst.append(v2)\n         lst.append(0)\n \n@@ -38,7 +38,7 @@ class TrackingTest(testing.TestCase):\n \n         lst2 = tracking.TrackedList([], tracker)\n         lst2.append(v1)\n-        lst2.append(None)\n+        lst2.append(float(\"nan\"))\n         lst2.append(v2)\n         lst2.append(0)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e61e83df13a43301ff132a62ed998d534ee49089", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 57 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 2 | Methods Changed: 4 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 58 | Churn Cumulative: 160 | Contributors (this commit): 7 | Commits (past 90d): 3 | Contributors (cumulative): 9 | DMM Complexity: 1.0\n\nDIFF:\n@@ -116,7 +116,7 @@ def get(identifier):\n     if identifier is None:\n         return linear\n     if isinstance(identifier, dict):\n-        obj = deserialize(identifier)\n+        obj = serialization_lib.deserialize_keras_object(identifier)\n     elif isinstance(identifier, str):\n         obj = ALL_OBJECTS_DICT.get(identifier, None)\n     else:\n\n@@ -367,6 +367,62 @@ class SerializationLibTest(testing.TestCase):\n         obj = serialization_lib.deserialize_keras_object(config)\n         self.assertIs(obj, custom_registered_fn)\n \n+    def test_layer_instance_as_activation(self):\n+        \"\"\"Tests serialization when activation is a Layer instance.\"\"\"\n+\n+        # Dense layer with ReLU layer as activation\n+        layer_dense_relu = keras.layers.Dense(\n+            units=4, activation=keras.layers.ReLU(name=\"my_relu\")\n+        )\n+        # Build the layer to ensure weights/state are initialized if needed\n+        layer_dense_relu.build(input_shape=(None, 8))\n+        _, restored_dense_relu, _ = self.roundtrip(layer_dense_relu)\n+\n+        # Verify the activation is correctly deserialized as a ReLU layer\n+        self.assertIsInstance(restored_dense_relu.activation, keras.layers.ReLU)\n+        # Verify properties are preserved\n+        self.assertEqual(restored_dense_relu.activation.name, \"my_relu\")\n+\n+    def test_layer_instance_with_config_as_activation(self):\n+        \"\"\"\n+        Tests serialization when activation is a Layer instance with config.\n+        \"\"\"\n+\n+        # Conv1D layer with LeakyReLU layer (with config) as activation\n+        leaky_activation = keras.layers.LeakyReLU(\n+            negative_slope=0.15, name=\"my_leaky\"\n+        )\n+        layer_conv_leaky = keras.layers.Conv1D(\n+            filters=2, kernel_size=3, activation=leaky_activation\n+        )\n+        # Build the layer\n+        layer_conv_leaky.build(input_shape=(None, 10, 4))\n+        _, restored_conv_leaky, _ = self.roundtrip(layer_conv_leaky)\n+\n+        # Verify the activation is correctly deserialized as LeakyReLU\n+        self.assertIsInstance(\n+            restored_conv_leaky.activation, keras.layers.LeakyReLU\n+        )\n+        # Verify configuration of the activation layer is preserved\n+        self.assertEqual(restored_conv_leaky.activation.negative_slope, 0.15)\n+        self.assertEqual(restored_conv_leaky.activation.name, \"my_leaky\")\n+\n+    def test_layer_string_as_activation(self):\n+        \"\"\"Tests serialization when activation is a string.\"\"\"\n+\n+        layer_dense_relu_string = keras.layers.Dense(units=4, activation=\"relu\")\n+        layer_dense_relu_string.build(input_shape=(None, 8))\n+        _, restored_dense_relu_string, _ = self.roundtrip(\n+            layer_dense_relu_string\n+        )\n+\n+        # Verify the activation is correctly deserialized to the relu function\n+        self.assertTrue(callable(restored_dense_relu_string.activation))\n+        # Check if it resolves to the canonical keras activation function\n+        self.assertEqual(\n+            restored_dense_relu_string.activation, keras.activations.relu\n+        )\n+\n \n @keras.saving.register_keras_serializable()\n class MyDense(keras.layers.Layer):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7b4367cd7c0a24d8b38be1d9b5fd774ca0dec86e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 217 | Contributors (this commit): 7 | Commits (past 90d): 1 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -187,6 +187,7 @@ def elu(x, alpha=1.0):\n \n     Args:\n         x: Input tensor.\n+        alpha: A scalar, slope of positive section. Defaults to `1.0`.\n \n     Reference:\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9f3ab34776722398f513951777b82c84ef395f0d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 10 | Churn Cumulative: 1513 | Contributors (this commit): 14 | Commits (past 90d): 21 | Contributors (cumulative): 14 | DMM Complexity: 1.0\n\nDIFF:\n@@ -703,7 +703,15 @@ def expand_dims(x, axis):\n \n \n def expm1(x):\n-    raise NotImplementedError(\"`expm1` is not supported with openvino backend\")\n+    x = get_ov_output(x)\n+    x_type = x.get_element_type()\n+    if x_type.is_integral():\n+        ov_type = OPENVINO_DTYPES[config.floatx()]\n+        x = ov_opset.convert(x, ov_type)\n+    exp_x = ov_opset.exp(x).output(0)\n+    const_one = ov_opset.constant(1, exp_x.get_element_type())\n+    result = ov_opset.subtract(exp_x, const_one).output(0)\n+    return OpenVINOKerasTensor(result)\n \n \n def flip(x, axis=None):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#574d36f10004fb12d1fd75c84ebebafed5264aac", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 40 | Lines Deleted: 7 | Files Changed: 2 | Hunks: 9 | Methods Changed: 3 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 47 | Churn Cumulative: 957 | Contributors (this commit): 14 | Commits (past 90d): 9 | Contributors (cumulative): 18 | DMM Complexity: 0.7368421052631579\n\nDIFF:\n@@ -34,6 +34,7 @@ from keras.src.api_export import keras_export\n from keras.src.backend import KerasTensor\n from keras.src.backend.common import global_state\n from keras.src.backend.common import remat\n+from keras.src.backend.common.keras_tensor import any_symbolic_tensors\n from keras.src.backend.common.name_scope import current_path\n from keras.src.backend.common.remat import get_current_remat_mode\n from keras.src.backend.common.symbolic_scope import in_symbolic_scope\n@@ -41,6 +42,7 @@ from keras.src.distribution import distribution_lib\n from keras.src.dtype_policies import DTypePolicyMap\n from keras.src.layers import input_spec\n from keras.src.metrics.metric import Metric\n+from keras.src.ops.node import Node\n from keras.src.ops.operation import Operation\n from keras.src.saving.keras_saveable import KerasSaveable\n from keras.src.utils import python_utils\n@@ -791,12 +793,19 @@ class Layer(BackendLayer, Operation, KerasSaveable):\n     def compute_mask(self, inputs, previous_mask):\n         return previous_mask\n \n+    def symbolic_call(self, *args, **kwargs):\n+        # Node is created at the end of `__call__` instead of `symbolic_call`.\n+        return self.compute_output_spec(*args, **kwargs)\n+\n     @traceback_utils.filter_traceback\n     def __call__(self, *args, **kwargs):\n         self._check_super_called()\n         self._called = True\n \n-        #####################################\n+        original_args = args\n+        original_kwargs = kwargs\n+\n+        #############################################################\n         # 1. Convert any array arguments to tensors of correct dtype.\n         def maybe_convert(x):\n             return self.dtype_policy.convert_input(\n@@ -807,7 +816,7 @@ class Layer(BackendLayer, Operation, KerasSaveable):\n         if (\n             kwargs\n             or len(args) != 1\n-            or not backend.is_tensor(args[0])\n+            or not is_backend_tensor_or_symbolic(args[0], allow_none=False)\n             or backend.standardize_dtype(args[0].dtype) != self.input_dtype\n         ) and self._convert_input_args:\n             args = tree.map_structure(maybe_convert, args)\n@@ -817,11 +826,7 @@ class Layer(BackendLayer, Operation, KerasSaveable):\n         # 2. Enforce that only tensors can be passed positionally.\n         if not self._allow_non_tensor_positional_args:\n             for arg in tree.flatten(args):\n-                if (\n-                    not isinstance(arg, KerasTensor)\n-                    and not backend.is_tensor(arg)\n-                    and arg is not None\n-                ):\n+                if not is_backend_tensor_or_symbolic(arg, allow_none=True):\n                     raise ValueError(\n                         \"Only input tensors may be passed as \"\n                         \"positional arguments. The following argument value \"\n@@ -957,6 +962,17 @@ class Layer(BackendLayer, Operation, KerasSaveable):\n         finally:\n             # Destroy call context if we created it\n             self._maybe_reset_call_context()\n+\n+        ################################################\n+        # 8. Add a node in the graph for symbolic calls.\n+        if any_symbolic_tensors(original_args, original_kwargs):\n+            Node(\n+                operation=self,\n+                call_args=original_args,\n+                call_kwargs=original_kwargs,\n+                outputs=outputs,\n+            )\n+\n         return outputs\n \n     def call(self, *args, **kwargs):\n\n@@ -11,6 +11,7 @@ from keras.src import layers\n from keras.src import ops\n from keras.src import saving\n from keras.src import testing\n+from keras.src.dtype_policies import dtype_policy\n from keras.src.layers.core.input_layer import Input\n from keras.src.layers.input_spec import InputSpec\n from keras.src.models import Functional\n@@ -748,3 +749,19 @@ class FunctionalTest(testing.TestCase):\n             \"The structure of `inputs` doesn't match the expected structure\",\n         ):\n             model([x1, x2])\n+\n+    def test_functional_with_dtype_policy(self):\n+        original_dtype_policy = dtype_policy.dtype_policy()\n+        try:\n+            dtype_policy.set_dtype_policy(\"mixed_float16\")\n+\n+            inputs = Input((10,), name=\"input\")\n+            outputs = layers.Dense(5)(inputs)\n+            model = Model(inputs=inputs, outputs=outputs)\n+\n+            # Verify that no cast node appears in the graph.\n+            self.assertLen(model.operations, 2)\n+            self.assertIsInstance(model.operations[0], layers.InputLayer)\n+            self.assertIsInstance(model.operations[1], layers.Dense)\n+        finally:\n+            dtype_policy.set_dtype_policy(original_dtype_policy)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1c4fba93f7afe00d8df569305e7742e4d451691f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 1265 | Contributors (this commit): 6 | Commits (past 90d): 1 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -620,8 +620,8 @@ val_py_dataset = ExamplePyDataset(x_val, y_val, batch_size=32)\n \"\"\"\n To fit the model, pass the dataset instead as the `x` argument (no need for a `y`\n argument since the dataset includes the targets), and pass the validation dataset\n-as the `validation_data` argument. And no need for the `batch_size` argument, since\n-the dataset is already batched!\n+as the `validation_data` argument. And no need for the `validation_batch_size`\n+argument, since the dataset is already batched!\n \"\"\"\n \n model = get_compiled_model()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ec47a68d59dc2d7645525dc86cb3d12c3d0ba036", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 12 | Churn Cumulative: 1525 | Contributors (this commit): 14 | Commits (past 90d): 22 | Contributors (cumulative): 14 | DMM Complexity: 1.0\n\nDIFF:\n@@ -776,9 +776,17 @@ def hstack(xs):\n \n \n def identity(n, dtype=None):\n-    raise NotImplementedError(\n-        \"`identity` is not supported with openvino backend\"\n+    n = get_ov_output(n)\n+    dtype = Type.f32 if dtype is None else dtype\n+    if isinstance(dtype, str):\n+        ov_dtype = OPENVINO_DTYPES[dtype]\n+    else:\n+        ov_dtype = dtype\n+    n32 = ov_opset.convert(n, Type.i32).output(0)\n+    identity_matrix = ov_opset.eye(\n+        num_rows=n32, num_columns=n32, diagonal_index=0, output_type=ov_dtype\n     )\n+    return OpenVINOKerasTensor(identity_matrix.output(0))\n \n \n def imag(x):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#862a37922c37052939e14b4cbd3fa122cc121303", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 301 | Lines Deleted: 1 | Files Changed: 3 | Hunks: 6 | Methods Changed: 6 | Complexity Δ (Sum/Max): 12/12 | Churn Δ: 302 | Churn Cumulative: 2859 | Contributors (this commit): 22 | Commits (past 90d): 9 | Contributors (cumulative): 32 | DMM Complexity: 0.9929078014184397\n\nDIFF:\n@@ -720,7 +720,10 @@ def sparse_categorical_crossentropy(target, output, from_logits=False, axis=-1):\n             \"Received: \"\n             f\"output.shape={output.shape}\"\n         )\n-    if target.shape != output.shape[:-1]:\n+    output_shape_without_class_dim = list(output.shape)\n+    del output_shape_without_class_dim[axis]\n+\n+    if list(target.shape) != output_shape_without_class_dim:\n         raise ValueError(\n             \"Arguments `target` and `output` must have the same shape \"\n             \"up until the last dimension: \"\n\n@@ -1172,6 +1172,8 @@ class SparseCategoricalCrossentropy(LossFunctionWrapper):\n             sample size, and `\"mean_with_sample_weight\"` sums the loss and\n             divides by the sum of the sample weights. `\"none\"` and `None`\n             perform no aggregation. Defaults to `\"sum_over_batch_size\"`.\n+        axis: The axis along which to compute crossentropy (the features\n+            axis). Defaults to `-1`.\n         name: Optional name for the loss instance.\n         dtype: The dtype of the loss's computations. Defaults to `None`, which\n             means using `keras.backend.floatx()`. `keras.backend.floatx()` is a\n@@ -1217,6 +1219,7 @@ class SparseCategoricalCrossentropy(LossFunctionWrapper):\n         from_logits=False,\n         ignore_class=None,\n         reduction=\"sum_over_batch_size\",\n+        axis=-1,\n         name=\"sparse_categorical_crossentropy\",\n         dtype=None,\n     ):\n@@ -1227,6 +1230,7 @@ class SparseCategoricalCrossentropy(LossFunctionWrapper):\n             dtype=dtype,\n             from_logits=from_logits,\n             ignore_class=ignore_class,\n+            axis=axis,\n         )\n         self.from_logits = from_logits\n         self.ignore_class = ignore_class\n\n@@ -1,3 +1,5 @@\n+import re\n+\n import numpy as np\n import pytest\n \n@@ -1325,6 +1327,297 @@ class SparseCategoricalCrossentropyTest(testing.TestCase):\n         loss = cce_obj(y_true, logits)\n         self.assertAllClose([[0.0, 1.480129]], loss)\n \n+    def test_binary_segmentation(self):\n+        y_true = np.array(\n+            [[0, 1, 1, 0], [1, 0, 1, 0], [0, 0, 1, 1], [1, 1, 0, 1]]\n+        )\n+        y_pred = np.array(\n+            [\n+                [[1.0, 0.0], [0.0, 1.0], [0.0, 1.0], [1.0, 0.0]],\n+                [[0.0, 1.0], [1.0, 0.0], [0.0, 1.0], [1.0, 0.0]],\n+                [[1.0, 0.0], [1.0, 0.0], [0.0, 1.0], [0.0, 1.0]],\n+                [[0.0, 1.0], [0.0, 1.0], [1.0, 0.0], [0.0, 1.0]],\n+            ]\n+        )\n+        output = losses.SparseCategoricalCrossentropy()(y_true, y_pred)\n+        self.assertAllClose(output, 0.0)\n+\n+        y_true = np.array(\n+            [[0, 1, 1, 0], [1, 0, 1, 0], [0, 0, 1, 1], [1, 1, 0, 1]]\n+        )\n+        y_pred = np.array(\n+            [\n+                [[1.0, 0.0], [0.0, 1.0], [0.0, 1.0], [0.2, 0.8]],\n+                [[0.0, 1.0], [1.0, 0.0], [0.0, 1.0], [1.0, 0.0]],\n+                [[1.0, 0.0], [1.0, 0.0], [0.0, 1.0], [0.0, 1.0]],\n+                [[0.0, 1.0], [0.0, 1.0], [1.0, 0.0], [0.6, 0.4]],\n+            ]\n+        )\n+        expected = np.array([-np.log(0.2), -np.log(0.4)])\n+        output = losses.SparseCategoricalCrossentropy()(y_true, y_pred)\n+        self.assertAllClose(output, expected.sum() / 16.0)  # 16 pixels\n+\n+    def test_binary_segmentation_different_axis(self):\n+        y_true = np.array(\n+            [[0, 1, 1, 0], [1, 0, 1, 0], [0, 0, 1, 1], [1, 1, 0, 1]]\n+        )\n+        y_pred = np.array(\n+            [\n+                [[1.0, 0.0], [0.0, 1.0], [0.0, 1.0], [1.0, 0.0]],\n+                [[0.0, 1.0], [1.0, 0.0], [0.0, 1.0], [1.0, 0.0]],\n+                [[1.0, 0.0], [1.0, 0.0], [0.0, 1.0], [0.0, 1.0]],\n+                [[0.0, 1.0], [0.0, 1.0], [1.0, 0.0], [0.0, 1.0]],\n+            ]\n+        )\n+        y_pred_reshaped = np.moveaxis(y_pred, source=2, destination=0)\n+        if backend.backend() == \"tensorflow\":\n+            expected_message = (\n+                \"Only axis=-1 is currently supported. Received: axis=0\"\n+            )\n+            escaped_message = re.escape(expected_message)\n+\n+            with pytest.raises(ValueError, match=escaped_message):\n+                losses.SparseCategoricalCrossentropy(axis=0)(\n+                    y_true, y_pred_reshaped\n+                )\n+        elif backend.backend() == \"jax\":\n+            expected_message = (\n+                \"Arguments `target` and `output` \"\n+                \"must have the same shape up until\"\n+                \" the last dimension: target.shape=(4, 4),\"\n+                \" output.shape=(2, 4, 4)\"\n+            )\n+            escaped_message = re.escape(expected_message)\n+\n+            with pytest.raises(ValueError, match=escaped_message):\n+                losses.SparseCategoricalCrossentropy(axis=0)(\n+                    y_true, y_pred_reshaped\n+                )\n+        elif backend.backend() == \"torch\":\n+            output = losses.SparseCategoricalCrossentropy(axis=0)(\n+                y_true, y_pred_reshaped\n+            )\n+            self.assertAllClose(output, 0.0)\n+\n+        if backend.backend() == \"torch\":\n+            y_true = np.array(\n+                [[0, 1, 1, 0], [1, 0, 1, 0], [0, 0, 1, 1], [1, 1, 0, 1]]\n+            )\n+            y_pred = np.array(\n+                [\n+                    [[1.0, 0.0], [0.0, 1.0], [0.0, 1.0], [0.2, 0.8]],\n+                    [[0.0, 1.0], [1.0, 0.0], [0.0, 1.0], [1.0, 0.0]],\n+                    [[1.0, 0.0], [1.0, 0.0], [0.0, 1.0], [0.0, 1.0]],\n+                    [[0.0, 1.0], [0.0, 1.0], [1.0, 0.0], [0.6, 0.4]],\n+                ]\n+            )\n+            y_pred_reshaped = np.moveaxis(y_pred, source=2, destination=0)\n+            expected = np.array([-np.log(0.2), -np.log(0.4)])\n+            output = losses.SparseCategoricalCrossentropy(axis=0)(\n+                y_true, y_pred_reshaped\n+            )\n+            self.assertAllClose(output, expected.sum() / 16.0)\n+\n+            y_true = np.array([y_true, y_true, y_true])\n+            y_pred_reshaped = np.array(\n+                [y_pred_reshaped, y_pred_reshaped, y_pred_reshaped]\n+            )\n+            output = losses.SparseCategoricalCrossentropy(axis=1)(\n+                y_true, y_pred_reshaped\n+            )\n+            self.assertAllClose(output, expected.sum() / 16.0)\n+\n+    def test_multi_class_segmentation(self):\n+        y_true = np.array(\n+            [[0, 1, 2, 0], [1, 0, 1, 0], [0, 0, 1, 1], [1, 1, 0, 1]]\n+        )\n+        y_pred = np.array(\n+            [\n+                [\n+                    [1.0, 0.0, 0.0],\n+                    [0.0, 1.0, 0.0],\n+                    [0.0, 0.0, 1.0],\n+                    [1.0, 0.0, 0.0],\n+                ],\n+                [\n+                    [0.0, 1.0, 0.0],\n+                    [1.0, 0.0, 0.0],\n+                    [0.0, 1.0, 0.0],\n+                    [1.0, 0.0, 0.0],\n+                ],\n+                [\n+                    [1.0, 0.0, 0.0],\n+                    [1.0, 0.0, 0.0],\n+                    [0.0, 1.0, 0.0],\n+                    [0.0, 1.0, 0.0],\n+                ],\n+                [\n+                    [0.0, 1.0, 0.0],\n+                    [0.0, 1.0, 0.0],\n+                    [1.0, 0.0, 0.0],\n+                    [0.0, 1.0, 0.0],\n+                ],\n+            ]\n+        )\n+        output = losses.SparseCategoricalCrossentropy()(y_true, y_pred)\n+        self.assertAllClose(output, 0.0)\n+\n+        y_true = np.array(\n+            [[0, 1, 2, 0], [1, 0, 1, 0], [0, 0, 1, 1], [1, 1, 0, 1]]\n+        )\n+        y_pred = np.array(\n+            [\n+                [\n+                    [1.0, 0.0, 0.0],\n+                    [0.0, 1.0, 0.0],\n+                    [0.0, 0.0, 1.0],\n+                    [0.2, 0.0, 0.8],\n+                ],\n+                [\n+                    [0.7, 0.3, 0.0],\n+                    [1.0, 0.0, 0.0],\n+                    [0.0, 1.0, 0.0],\n+                    [1.0, 0.0, 0.0],\n+                ],\n+                [\n+                    [1.0, 0.0, 0.0],\n+                    [1.0, 0.0, 0.0],\n+                    [0.0, 1.0, 0.0],\n+                    [0.0, 1.0, 0.0],\n+                ],\n+                [\n+                    [0.0, 1.0, 0.0],\n+                    [0.0, 1.0, 0.0],\n+                    [0.5, 0.5, 0.0],\n+                    [0.0, 1.0, 0.0],\n+                ],\n+            ]\n+        )\n+        expected = np.array(\n+            [\n+                -np.log(0.2),\n+                -np.log(0.3),\n+                -np.log(0.5),\n+            ]\n+        )\n+        output = losses.SparseCategoricalCrossentropy()(y_true, y_pred)\n+        self.assertAllClose(output, expected.sum() / 16.0)  # 16 pixels\n+\n+    def test_multi_class_segmentation_different_axis(self):\n+        y_true = np.array(\n+            [[0, 1, 2, 0], [1, 0, 1, 0], [0, 0, 1, 1], [1, 1, 0, 1]]\n+        )\n+        y_pred = np.array(\n+            [\n+                [\n+                    [1.0, 0.0, 0.0],\n+                    [0.0, 1.0, 0.0],\n+                    [0.0, 0.0, 1.0],\n+                    [1.0, 0.0, 0.0],\n+                ],\n+                [\n+                    [0.0, 1.0, 0.0],\n+                    [1.0, 0.0, 0.0],\n+                    [0.0, 1.0, 0.0],\n+                    [1.0, 0.0, 0.0],\n+                ],\n+                [\n+                    [1.0, 0.0, 0.0],\n+                    [1.0, 0.0, 0.0],\n+                    [0.0, 1.0, 0.0],\n+                    [0.0, 1.0, 0.0],\n+                ],\n+                [\n+                    [0.0, 1.0, 0.0],\n+                    [0.0, 1.0, 0.0],\n+                    [1.0, 0.0, 0.0],\n+                    [0.0, 1.0, 0.0],\n+                ],\n+            ]\n+        )\n+        y_pred_reshaped = np.moveaxis(y_pred, source=2, destination=0)\n+        if backend.backend() == \"tensorflow\":\n+            expected_message = (\n+                \"Only axis=-1 is currently supported. Received: axis=0\"\n+            )\n+            escaped_message = re.escape(expected_message)\n+\n+            with pytest.raises(ValueError, match=escaped_message):\n+                losses.SparseCategoricalCrossentropy(axis=0)(\n+                    y_true, y_pred_reshaped\n+                )\n+        elif backend.backend() == \"jax\":\n+            expected_message = (\n+                \"Arguments `target` and `output` \"\n+                \"must have the same shape up until\"\n+                \" the last dimension: target.shape=(4, 4),\"\n+                \" output.shape=(3, 4, 4)\"\n+            )\n+            escaped_message = re.escape(expected_message)\n+\n+            with pytest.raises(ValueError, match=escaped_message):\n+                losses.SparseCategoricalCrossentropy(axis=0)(\n+                    y_true, y_pred_reshaped\n+                )\n+        elif backend.backend() == \"torch\":\n+            output = losses.SparseCategoricalCrossentropy(axis=0)(\n+                y_true, y_pred_reshaped\n+            )\n+            self.assertAllClose(output, 0.0)\n+\n+        if backend.backend() == \"torch\":\n+            y_true = np.array(\n+                [[0, 1, 2, 0], [1, 0, 1, 0], [0, 0, 1, 1], [1, 1, 0, 1]]\n+            )\n+            y_pred = np.array(\n+                [\n+                    [\n+                        [1.0, 0.0, 0.0],\n+                        [0.0, 1.0, 0.0],\n+                        [0.0, 0.0, 1.0],\n+                        [0.2, 0.0, 0.8],\n+                    ],\n+                    [\n+                        [0.7, 0.3, 0.0],\n+                        [1.0, 0.0, 0.0],\n+                        [0.0, 1.0, 0.0],\n+                        [1.0, 0.0, 0.0],\n+                    ],\n+                    [\n+                        [1.0, 0.0, 0.0],\n+                        [1.0, 0.0, 0.0],\n+                        [0.0, 1.0, 0.0],\n+                        [0.0, 1.0, 0.0],\n+                    ],\n+                    [\n+                        [0.0, 1.0, 0.0],\n+                        [0.0, 1.0, 0.0],\n+                        [0.5, 0.5, 0.0],\n+                        [0.0, 1.0, 0.0],\n+                    ],\n+                ]\n+            )\n+            expected = np.array(\n+                [\n+                    -np.log(0.2),\n+                    -np.log(0.3),\n+                    -np.log(0.5),\n+                ]\n+            )\n+            y_pred_reshaped = np.moveaxis(y_pred, source=2, destination=0)\n+            output = losses.SparseCategoricalCrossentropy(axis=0)(\n+                y_true, y_pred_reshaped\n+            )\n+            self.assertAllClose(output, expected.sum() / 16.0)\n+            y_true = np.array([y_true, y_true, y_true])\n+            y_pred_reshaped = np.array(\n+                [y_pred_reshaped, y_pred_reshaped, y_pred_reshaped]\n+            )\n+            output = losses.SparseCategoricalCrossentropy(axis=1)(\n+                y_true, y_pred_reshaped\n+            )\n+            self.assertAllClose(output, expected.sum() / 16.0)\n+\n     def test_dtype_arg(self):\n         y_true = np.array([[0], [1], [2]], dtype=\"int64\")\n         y_pred = np.array(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
