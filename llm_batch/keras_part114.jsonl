{"custom_id": "keras#9bc2e60fd587389701c077f5bbff69250d6fb0b1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 21 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 28 | Churn Cumulative: 1666 | Contributors (this commit): 25 | Commits (past 90d): 11 | Contributors (cumulative): 25 | DMM Complexity: 0.14285714285714285\n\nDIFF:\n@@ -451,7 +451,7 @@ class TensorBoard(Callback):\n             write_graph is set to True.\n     '''\n \n-    def __init__(self, log_dir='./logs', histogram_freq=0, write_graph=True):\n+    def __init__(self, log_dir='./logs', histogram_freq=0, write_graph=True, write_images=False):\n         super(TensorBoard, self).__init__()\n         if K._BACKEND != 'tensorflow':\n             raise Exception('TensorBoard callback only works '\n@@ -460,6 +460,7 @@ class TensorBoard(Callback):\n         self.histogram_freq = histogram_freq\n         self.merged = None\n         self.write_graph = write_graph\n+        self.write_images = write_images\n \n     def _set_model(self, model):\n         import tensorflow as tf\n@@ -468,12 +469,25 @@ class TensorBoard(Callback):\n         self.model = model\n         self.sess = KTF.get_session()\n         if self.histogram_freq and self.merged is None:\n-            layers = self.model.layers\n-            for layer in layers:\n-                if hasattr(layer, 'W'):\n-                    tf.histogram_summary('{}_W'.format(layer.name), layer.W)\n-                if hasattr(layer, 'b'):\n-                    tf.histogram_summary('{}_b'.format(layer.name), layer.b)\n+            for layer in self.model.layers:\n+\n+                for weight in layer.weights:\n+                    tf.histogram_summary(weight.name, weight)\n+\n+                    if self.write_images:\n+                        w_img = tf.squeeze(weight)\n+\n+                        shape = w_img.get_shape()\n+                        if len(shape) > 1 and shape[0] > shape[1]:\n+                            w_img = tf.transpose(w_img)\n+\n+                        if len(shape) == 1:\n+                            w_img = tf.expand_dims(w_img, 0)\n+\n+                        w_img = tf.expand_dims(tf.expand_dims(w_img, 0), -1)\n+\n+                        tf.image_summary(weight.name, w_img)\n+\n                 if hasattr(layer, 'output'):\n                     tf.histogram_summary('{}_out'.format(layer.name),\n                                          layer.output)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4b2093ef67ab9a267dc371e3a193749ad764f78e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 2735 | Contributors (this commit): 33 | Commits (past 90d): 50 | Contributors (cumulative): 33 | DMM Complexity: None\n\nDIFF:\n@@ -1185,10 +1185,8 @@ def rnn(step_function, inputs, initial_states,\n                     new_state = tf.concat(1, new_states)\n                 return output, new_state\n \n-        # state size is assumed to be the same as output size\n-        # (always the case)\n         _step.state_size = state_size * nb_states\n-        _step.output_size = state_size\n+        _step.output_size = int(_step(tf.unpack(inputs)[0], state)[0].get_shape()[-1])\n \n         (outputs, final_state) = _dynamic_rnn_loop(\n             _step,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#25874ceab26bd9e08e532c442dc845bccf0590d5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 433 | Contributors (this commit): 4 | Commits (past 90d): 3 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -118,7 +118,8 @@ class TimeDistributed(Wrapper):\n                 return output, []\n \n             last_output, outputs, states = K.rnn(step, X,\n-                                                 initial_states=[])\n+                                                 initial_states=[],\n+                                                 unroll=True)\n             y = outputs\n         else:\n             # no batch size specified, therefore the layer will be able\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#40685c3b2a8c535f6c68fa3917ce5f1507dce186", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 363 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 13 | Complexity Δ (Sum/Max): 25/25 | Churn Δ: 363 | Churn Cumulative: 363 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,363 @@\n+'''Neural doodle with Keras\r\n+\r\n+Script Usage:\r\n+    # Arguments:\r\n+    ```\r\n+    --nlabels:              # of regions (colors) in mask images\r\n+    --style-image:          image to learn style from\r\n+    --style-mask:           semantic labels for style image\r\n+    --target-mask:          semantic labels for target image (your doodle)\r\n+    --content-image:        optional image to learn content from\r\n+    --target-image-prefix:  path prefix for generated target images\r\n+    ```\r\n+\r\n+    # Example 1: doodle using a style image, style mask\r\n+    and target mask.\r\n+    ```\r\n+    python neural_doodle.py --nlabels 4 --style-image Monet/style.png \\\r\n+    --style-mask Monet/style_mask.png --target-mask Monet/target_mask.png \\\r\n+    --target-image-prefix generated/monet\r\n+    ```\r\n+\r\n+    # Example 2: doodle using a style image, style mask,\r\n+    target mask and an optional content image.\r\n+    ```\r\n+    python neural_doodle.py --nlabels 4 --style-image Renoir/style.png \\\r\n+    --style-mask Renoir/style_mask.png --target-mask Renoir/target_mask.png \\\r\n+    --content-image Renoir/creek.jpg \\\r\n+    --target-image-prefix generated/renoir\r\n+    ```\r\n+\r\n+References:\r\n+[Dmitry Ulyanov's blog on fast-neural-doodle](http://dmitryulyanov.github.io/feed-forward-neural-doodle/)\r\n+[Torch code for fast-neural-doodle](https://github.com/DmitryUlyanov/fast-neural-doodle)\r\n+[Torch code for online-neural-doodle](https://github.com/DmitryUlyanov/online-neural-doodle)\r\n+[Paper Texture Networks: Feed-forward Synthesis of Textures and Stylized Images](http://arxiv.org/abs/1603.03417)\r\n+[Discussion on parameter tuning](https://github.com/fchollet/keras/issues/3705)\r\n+\r\n+Resources:\r\n+Example images can be downloaded from\r\n+https://github.com/DmitryUlyanov/fast-neural-doodle/tree/master/data\r\n+'''\r\n+from __future__ import print_function\r\n+import time\r\n+import argparse\r\n+import numpy as np\r\n+from scipy.optimize import fmin_l_bfgs_b\r\n+from scipy.misc import imread, imsave\r\n+\r\n+from keras import backend as K\r\n+from keras.layers import Input, Convolution2D, MaxPooling2D, AveragePooling2D\r\n+from keras.models import Model\r\n+from keras.preprocessing.image import load_img, img_to_array\r\n+from keras.applications import vgg19\r\n+\r\n+# Command line arguments\r\n+parser = argparse.ArgumentParser(description='Keras neural doodle example')\r\n+parser.add_argument('--nlabels', type=int,\r\n+                    help='number of semantic labels'\r\n+                    ' (regions in differnet colors)'\r\n+                    ' in style_mask/target_mask')\r\n+parser.add_argument('--style-image', type=str,\r\n+                    help='path to image to learn style from')\r\n+parser.add_argument('--style-mask', type=str,\r\n+                    help='path to semantic mask of style image')\r\n+parser.add_argument('--target-mask', type=str,\r\n+                    help='path to semantic mask of target image')\r\n+parser.add_argument('--content-image', type=str, default=None,\r\n+                    help='path to optional content image')\r\n+parser.add_argument('--target-image-prefix', type=str,\r\n+                    help='path prefix for generated results')\r\n+args = parser.parse_args()\r\n+\r\n+style_img_path = args.style_image\r\n+style_mask_path = args.style_mask\r\n+target_mask_path = args.target_mask\r\n+content_img_path = args.content_image\r\n+target_img_prefix = args.target_image_prefix\r\n+use_content_img = content_img_path is not None\r\n+\r\n+nb_labels = args.nlabels\r\n+nb_colors = 3  # RGB\r\n+# determine image sizes based on target_mask\r\n+ref_img = imread(target_mask_path)\r\n+img_nrows, img_ncols = ref_img.shape[:2]\r\n+\r\n+total_variation_weight = 8.5e-5\r\n+style_weight = 1.\r\n+content_weight = 0.1 if use_content_img else 0\r\n+\r\n+content_feature_layers = ['block5_conv2']\r\n+# To get better generation qualities, use more conv layers for style features\r\n+style_feature_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1',\r\n+                        'block4_conv1', 'block5_conv1']\r\n+\r\n+\r\n+# helper functions for reading/processing images\r\n+def preprocess_image(image_path):\r\n+    img = load_img(image_path, target_size=(img_nrows, img_ncols))\r\n+    img = img_to_array(img)\r\n+    img = np.expand_dims(img, axis=0)\r\n+    img = vgg19.preprocess_input(img)\r\n+    return img\r\n+\r\n+\r\n+def deprocess_image(x):\r\n+    if K.image_dim_ordering() == 'th':\r\n+        x = x.reshape((3, img_nrows, img_ncols))\r\n+        x = x.transpose((1, 2, 0))\r\n+    else:\r\n+        x = x.reshape((img_nrows, img_ncols, 3))\r\n+    x = x[:, :, ::-1]\r\n+    x[:, :, 0] += 103.939\r\n+    x[:, :, 1] += 116.779\r\n+    x[:, :, 2] += 123.68\r\n+    x = np.clip(x, 0, 255).astype('uint8')\r\n+    return x\r\n+\r\n+\r\n+def kmeans(xs, k):\r\n+    assert xs.ndim == 2\r\n+    try:\r\n+        from sklearn.cluster import k_means\r\n+        _, labels, _ = k_means(xs.astype(\"float64\"), k)\r\n+    except ImportError:\r\n+        from scipy.cluster.vq import kmeans2\r\n+        _, labels = kmeans2(xs, k, missing='raise')\r\n+    return labels\r\n+\r\n+\r\n+def load_mask_labels():\r\n+    '''Load both target and style masks.\r\n+    A mask image (nr x nc) with m labels/colors will be loaded\r\n+    as a 4D boolean tensor: (1, m, nr, nc) for 'th' or (1, nr, nc, m) for 'tf'\r\n+    '''\r\n+    target_mask_img = load_img(target_mask_path,\r\n+                               target_size=(img_nrows, img_ncols))\r\n+    target_mask_img = img_to_array(target_mask_img)\r\n+    style_mask_img = load_img(style_mask_path,\r\n+                              target_size=(img_nrows, img_ncols))\r\n+    style_mask_img = img_to_array(style_mask_img)\r\n+    if K.image_dim_ordering() == 'th':\r\n+        mask_vecs = np.vstack([style_mask_img.reshape((3, -1)).T,\r\n+                               target_mask_img.reshape((3, -1)).T])\r\n+    else:\r\n+        mask_vecs = np.vstack([style_mask_img.reshape((-1, 3)),\r\n+                               target_mask_img.reshape((-1, 3))])\r\n+\r\n+    labels = kmeans(mask_vecs, nb_labels)\r\n+    style_mask_label = labels[:img_nrows *\r\n+                              img_ncols].reshape((img_nrows, img_ncols))\r\n+    target_mask_label = labels[img_nrows *\r\n+                               img_ncols:].reshape((img_nrows, img_ncols))\r\n+\r\n+    stack_axis = 0 if K.image_dim_ordering() == 'th' else -1\r\n+    style_mask = np.stack([style_mask_label == r for r in xrange(nb_labels)],\r\n+                          axis=stack_axis)\r\n+    target_mask = np.stack([target_mask_label == r for r in xrange(nb_labels)],\r\n+                           axis=stack_axis)\r\n+\r\n+    return (np.expand_dims(style_mask, axis=0),\r\n+            np.expand_dims(target_mask, axis=0))\r\n+\r\n+# Create tensor variables for images\r\n+if K.image_dim_ordering() == 'th':\r\n+    shape = (1, nb_colors, img_nrows, img_ncols)\r\n+else:\r\n+    shape = (1, img_nrows, img_ncols, nb_colors)\r\n+\r\n+style_image = K.variable(preprocess_image(style_img_path))\r\n+target_image = K.placeholder(shape=shape)\r\n+if use_content_img:\r\n+    content_image = K.variable(preprocess_image(content_img_path))\r\n+else:\r\n+    content_image = K.zeros(shape=shape)\r\n+\r\n+images = K.concatenate([style_image, target_image, content_image], axis=0)\r\n+\r\n+# Create tensor variables for masks\r\n+raw_style_mask, raw_target_mask = load_mask_labels()\r\n+style_mask = K.variable(raw_style_mask.astype(\"float32\"))\r\n+target_mask = K.variable(raw_target_mask.astype(\"float32\"))\r\n+masks = K.concatenate([style_mask, target_mask], axis=0)\r\n+\r\n+# index constants for images and tasks variables\r\n+STYLE, TARGET, CONTENT = 0, 1, 2\r\n+\r\n+# Build image model, mask model and use layer outputs as features\r\n+# image model as VGG19\r\n+image_model = vgg19.VGG19(include_top=False, input_tensor=images)\r\n+\r\n+# mask model as a series of pooling\r\n+mask_input = Input(tensor=masks, shape=(None, None, None), name=\"mask_input\")\r\n+x = mask_input\r\n+for layer in image_model.layers[1:]:\r\n+    name = 'mask_%s' % layer.name\r\n+    if 'conv' in layer.name:\r\n+        x = AveragePooling2D((3, 3), strides=(\r\n+            1, 1), name=name, border_mode=\"same\")(x)\r\n+    elif 'pool' in layer.name:\r\n+        x = AveragePooling2D((2, 2), name=name)(x)\r\n+mask_model = Model(mask_input, x)\r\n+\r\n+# Collect features from image_model and task_model\r\n+image_features = {}\r\n+mask_features = {}\r\n+for img_layer, mask_layer in zip(image_model.layers, mask_model.layers):\r\n+    if 'conv' in img_layer.name:\r\n+        assert 'mask_' + img_layer.name == mask_layer.name\r\n+        layer_name = img_layer.name\r\n+        img_feat, mask_feat = img_layer.output, mask_layer.output\r\n+        image_features[layer_name] = img_feat\r\n+        mask_features[layer_name] = mask_feat\r\n+\r\n+\r\n+# Define loss functions\r\n+def gram_matrix(x):\r\n+    assert K.ndim(x) == 3\r\n+    features = K.batch_flatten(x)\r\n+    gram = K.dot(features, K.transpose(features))\r\n+    return gram\r\n+\r\n+\r\n+def region_style_loss(style_image, target_image, style_mask, target_mask):\r\n+    '''Calculate style loss between style_image and target_image,\r\n+    for one common region specified by their (boolean) masks\r\n+    '''\r\n+    assert 3 == K.ndim(style_image) == K.ndim(target_image)\r\n+    assert 2 == K.ndim(style_mask) == K.ndim(target_mask)\r\n+    if K.image_dim_ordering() == 'th':\r\n+        masked_style = style_image * style_mask\r\n+        masked_target = target_image * target_mask\r\n+    else:\r\n+        masked_style = K.permute_dimensions(\r\n+            style_image, (2, 0, 1)) * style_mask\r\n+        masked_target = K.permute_dimensions(\r\n+            target_image, (2, 0, 1)) * target_mask\r\n+    s = gram_matrix(masked_style) * K.sum(style_mask)\r\n+    c = gram_matrix(masked_target) * K.sum(target_mask)\r\n+    return K.sum(K.square(s - c))\r\n+\r\n+\r\n+def style_loss(style_image, target_image, style_masks, target_masks):\r\n+    '''Calculate style loss between style_image and target_image,\r\n+    in all regions.\r\n+    '''\r\n+    assert 3 == K.ndim(style_image) == K.ndim(target_image)\r\n+    assert 3 == K.ndim(style_masks) == K.ndim(target_masks)\r\n+    loss = K.variable(0)\r\n+    for i in xrange(nb_labels):\r\n+        if K.image_dim_ordering() == 'th':\r\n+            style_mask = style_masks[i, :, :]\r\n+            target_mask = target_masks[i, :, :]\r\n+        else:\r\n+            style_mask = style_masks[:, :, i]\r\n+            target_mask = target_masks[:, :, i]\r\n+        loss += region_style_loss(style_image,\r\n+                                  target_image, style_mask, target_mask)\r\n+    size = img_nrows * img_ncols\r\n+    return loss / (4. * nb_colors**2 * size**2)\r\n+\r\n+\r\n+def content_loss(content_image, target_image):\r\n+    return K.sum(K.square(target_image - content_image))\r\n+\r\n+\r\n+def total_variation_loss(x):\r\n+    assert 4 == K.ndim(x)\r\n+    if K.image_dim_ordering() == 'th':\r\n+        a = K.square(x[:, :, :img_nrows - 1, :img_ncols - 1] -\r\n+                     x[:, :, 1:, :img_ncols - 1])\r\n+        b = K.square(x[:, :, :img_nrows - 1, :img_ncols - 1] -\r\n+                     x[:, :, :img_nrows - 1, 1:])\r\n+    else:\r\n+        a = K.square(x[:, :img_nrows - 1, :img_ncols - 1, :] -\r\n+                     x[:, 1:, :img_ncols - 1, :])\r\n+        b = K.square(x[:, :img_nrows - 1, :img_ncols - 1, :] -\r\n+                     x[:, :img_nrows - 1, 1:, :])\r\n+    return K.sum(K.pow(a + b, 1.25))\r\n+\r\n+# Overall loss is the weighted sum of content_loss, style_loss and tv_loss\r\n+# Each individual loss uses features from image/mask models.\r\n+loss = K.variable(0)\r\n+for layer in content_feature_layers:\r\n+    content_feat = image_features[layer][CONTENT, :, :, :]\r\n+    target_feat = image_features[layer][TARGET, :, :, :]\r\n+    loss += content_weight * content_loss(content_feat, target_feat)\r\n+\r\n+for layer in style_feature_layers:\r\n+    style_feat = image_features[layer][STYLE, :, :, :]\r\n+    target_feat = image_features[layer][TARGET, :, :, :]\r\n+    style_masks = mask_features[layer][STYLE, :, :, :]\r\n+    target_masks = mask_features[layer][TARGET, :, :, :]\r\n+    sl = style_loss(style_feat, target_feat, style_masks, target_masks)\r\n+    loss += (style_weight / len(style_feature_layers)) * sl\r\n+\r\n+loss += total_variation_weight * total_variation_loss(target_image)\r\n+loss_grads = K.gradients(loss, target_image)\r\n+\r\n+# Evaluator class for computing efficiency\r\n+outputs = [loss]\r\n+if type(loss_grads) in {list, tuple}:\r\n+    outputs += loss_grads\r\n+else:\r\n+    outputs.append(loss_grads)\r\n+\r\n+f_outputs = K.function([target_image], outputs)\r\n+\r\n+\r\n+def eval_loss_and_grads(x):\r\n+    if K.image_dim_ordering() == 'th':\r\n+        x = x.reshape((1, 3, img_nrows, img_ncols))\r\n+    else:\r\n+        x = x.reshape((1, img_nrows, img_ncols, 3))\r\n+    outs = f_outputs([x])\r\n+    loss_value = outs[0]\r\n+    if len(outs[1:]) == 1:\r\n+        grad_values = outs[1].flatten().astype('float64')\r\n+    else:\r\n+        grad_values = np.array(outs[1:]).flatten().astype('float64')\r\n+    return loss_value, grad_values\r\n+\r\n+\r\n+class Evaluator(object):\r\n+\r\n+    def __init__(self):\r\n+        self.loss_value = None\r\n+        self.grads_values = None\r\n+\r\n+    def loss(self, x):\r\n+        assert self.loss_value is None\r\n+        loss_value, grad_values = eval_loss_and_grads(x)\r\n+        self.loss_value = loss_value\r\n+        self.grad_values = grad_values\r\n+        return self.loss_value\r\n+\r\n+    def grads(self, x):\r\n+        assert self.loss_value is not None\r\n+        grad_values = np.copy(self.grad_values)\r\n+        self.loss_value = None\r\n+        self.grad_values = None\r\n+        return grad_values\r\n+\r\n+evaluator = Evaluator()\r\n+\r\n+# Generate images by iterative optimization\r\n+if K.image_dim_ordering() == 'th':\r\n+    x = np.random.uniform(0, 255, (1, 3, img_nrows, img_ncols)) - 128.\r\n+else:\r\n+    x = np.random.uniform(0, 255, (1, img_nrows, img_ncols, 3)) - 128.\r\n+\r\n+for i in range(100):\r\n+    print('Start of iteration', i)\r\n+    start_time = time.time()\r\n+    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\r\n+                                     fprime=evaluator.grads, maxfun=20)\r\n+    print('Current loss value:', min_val)\r\n+    # save current generated image\r\n+    img = deprocess_image(x.copy())\r\n+    fname = target_img_prefix + '_at_iteration_%d.png' % i\r\n+    imsave(fname, img)\r\n+    end_time = time.time()\r\n+    print('Image saved as', fname)\r\n+    print('Iteration %d completed in %ds' % (i, end_time - start_time))\r\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#79edae58d5892c5a7eb19b68f9e79dfae4682e20", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 203 | Lines Deleted: 20 | Files Changed: 6 | Hunks: 38 | Methods Changed: 31 | Complexity Δ (Sum/Max): 36/14 | Churn Δ: 223 | Churn Cumulative: 11656 | Contributors (this commit): 77 | Commits (past 90d): 142 | Contributors (cumulative): 134 | DMM Complexity: 0.543859649122807\n\nDIFF:\n@@ -9,6 +9,7 @@ import os\n import copy\n import warnings\n from .common import _FLOATX, _EPSILON, _IMAGE_DIM_ORDERING, reset_uids\n+py_all = all\n \n # INTERNAL UTILS\n \n@@ -117,6 +118,17 @@ def _to_tensor(x, dtype):\n     return x\n \n \n+def is_sparse(tensor):\n+    return isinstance(tensor, tf.SparseTensor)\n+\n+\n+def to_dense(tensor):\n+    if is_sparse(tensor):\n+        return tf.sparse_tensor_to_dense(tensor)\n+    else:\n+        return tensor\n+\n+\n def variable(value, dtype=_FLOATX, name=None):\n     '''Instantiates a tensor.\n \n@@ -128,6 +140,12 @@ def variable(value, dtype=_FLOATX, name=None):\n     # Returns\n         Tensor variable instance.\n     '''\n+    if hasattr(value, 'tocoo'):\n+        sparse_coo = value.tocoo()\n+        indices = np.concatenate((np.expand_dims(sparse_coo.row, 1), np.expand_dims(sparse_coo.col, 1)), 1)\n+        # SparseTensor doesn't need initialization\n+        return tf.SparseTensor(indices=indices, values=value.data, shape=value.shape)\n+\n     v = tf.Variable(value, dtype=_convert_string_dtype(dtype), name=name)\n     if _MANUAL_VAR_INIT:\n         return v\n@@ -148,7 +166,7 @@ def variable(value, dtype=_FLOATX, name=None):\n     return v\n \n \n-def placeholder(shape=None, ndim=None, dtype=_FLOATX, name=None):\n+def placeholder(shape=None, ndim=None, dtype=_FLOATX, sparse=False, name=None):\n     '''Instantiates a placeholder.\n \n     # Arguments\n@@ -166,6 +184,10 @@ def placeholder(shape=None, ndim=None, dtype=_FLOATX, name=None):\n     if not shape:\n         if ndim:\n             shape = tuple([None for _ in range(ndim)])\n+    if sparse:\n+        tf_shape = tf.constant(np.array(list([0 for _ in range(len(shape))]), dtype=np.int64))\n+        x = tf.sparse_placeholder(dtype, shape=tf_shape, name=name)\n+    else:\n         x = tf.placeholder(dtype, shape=shape, name=name)\n     x._keras_shape = shape\n     x._uses_learning_phase = False\n@@ -190,6 +212,9 @@ def int_shape(x):\n def ndim(x):\n     '''Returns the number of axes in a tensor, as an integer.\n     '''\n+    if is_sparse(x):\n+        return int(x.shape.get_shape()[0])\n+\n     dims = x.get_shape()._dims\n     if dims is not None:\n         return len(dims)\n@@ -206,7 +231,7 @@ def eval(x):\n     '''Evaluates the value of a tensor.\n     Returns a Numpy array.\n     '''\n-    return x.eval(session=get_session())\n+    return to_dense(x).eval(session=get_session())\n \n \n def zeros(shape, dtype=_FLOATX, name=None):\n@@ -318,6 +343,9 @@ def dot(x, y):\n         xt = tf.reshape(x, [-1, x_shape[-1]])\n         yt = tf.reshape(tf.transpose(y, perm=y_permute_dim), [y_shape[-2], -1])\n         return tf.reshape(tf.matmul(xt, yt), x_shape[:-1] + y_shape[:-2] + y_shape[-1:])\n+    if is_sparse(x):\n+        out = tf.sparse_tensor_dense_matmul(x, y)\n+    else:\n         out = tf.matmul(x, y)\n     return out\n \n@@ -676,11 +704,16 @@ def concatenate(tensors, axis=-1):\n     '''Concantes a list of tensors alongside the specified axis.\n     '''\n     if axis < 0:\n-        if len(tensors[0].get_shape()):\n-            axis = axis % len(tensors[0].get_shape())\n+        dims = ndim(tensors[0])\n+        if dims:\n+            axis = axis % dims\n         else:\n             axis = 0\n-    return tf.concat(axis, tensors)\n+\n+    if py_all([is_sparse(x) for x in tensors]):\n+        return tf.sparse_concat(axis, tensors)\n+    else:\n+        return tf.concat(axis, [to_dense(x) for x in tensors])\n \n \n def reshape(x, shape):\n@@ -969,8 +1002,13 @@ class Function(object):\n \n     def __call__(self, inputs):\n         assert type(inputs) in {list, tuple}\n-        names = [getattr(v, 'name', None) for v in self.inputs]\n-        feed_dict = dict(zip(names, inputs))\n+        feed_dict = {}\n+        for tensor, value in zip(self.inputs, inputs):\n+            if is_sparse(tensor):\n+                sparse_coo = value.tocoo()\n+                indices = np.concatenate((np.expand_dims(sparse_coo.row, 1), np.expand_dims(sparse_coo.col, 1)), 1)\n+                value = (indices, value.data, value.shape)\n+            feed_dict[tensor] = value\n         session = get_session()\n         updated = session.run(self.outputs + [self.updates_op], feed_dict=feed_dict)\n         return updated[:len(self.outputs)]\n\n@@ -4,6 +4,10 @@ from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n from theano.tensor.signal import pool\n from theano.tensor.nnet import conv3d2d\n from theano.printing import Print\n+try:\n+    import theano.sparse as th_sparse_module\n+except ImportError:\n+    th_sparse_module = None\n try:\n     from theano.tensor.nnet.nnet import softsign as T_softsign\n except ImportError:\n@@ -11,6 +15,7 @@ except ImportError:\n import inspect\n import numpy as np\n from .common import _FLOATX, _EPSILON, _IMAGE_DIM_ORDERING\n+py_all = all\n \n \n # INTERNAL UTILS\n@@ -30,17 +35,38 @@ def set_learning_phase(value):\n                          '0 or 1.')\n     _LEARNING_PHASE = value\n \n-\n # VARIABLE MANIPULATION\n \n+\n+def _assert_sparse_module():\n+    if not th_sparse_module:\n+        raise ImportError(\"Failed to import theano.sparse\\n\"\n+                          \"You probably need to pip install nose-parameterized\")\n+\n+\n+def is_sparse(tensor):\n+    return th_sparse_module and isinstance(tensor.type, th_sparse_module.SparseType)\n+\n+\n+def to_dense(tensor):\n+    if is_sparse(tensor):\n+        return th_sparse_module.dense_from_sparse(tensor)\n+    else:\n+        return tensor\n+\n+\n def variable(value, dtype=_FLOATX, name=None):\n     '''Instantiate a tensor variable.\n     '''\n+    if hasattr(value, 'tocoo'):\n+        _assert_sparse_module()\n+        return th_sparse_module.as_sparse_variable(value)\n+    else:\n         value = np.asarray(value, dtype=dtype)\n         return theano.shared(value=value, name=name, strict=False)\n \n \n-def placeholder(shape=None, ndim=None, dtype=_FLOATX, name=None):\n+def placeholder(shape=None, ndim=None, dtype=_FLOATX, sparse=False, name=None):\n     '''Instantiate an input data placeholder variable.\n     '''\n     if shape is None and ndim is None:\n@@ -51,6 +77,10 @@ def placeholder(shape=None, ndim=None, dtype=_FLOATX, name=None):\n         shape = tuple([None for _ in range(ndim)])\n \n     broadcast = (False,) * ndim\n+    if sparse:\n+        _assert_sparse_module()\n+        x = th_sparse_module.csr_matrix(name=name, dtype=dtype)\n+    else:\n         x = T.TensorType(dtype, broadcast)(name)\n     x._keras_shape = shape\n     x._uses_learning_phase = False\n@@ -77,7 +107,7 @@ def dtype(x):\n def eval(x):\n     '''Run a graph.\n     '''\n-    return x.eval()\n+    return to_dense(x).eval()\n \n \n def zeros(shape, dtype=_FLOATX, name=None):\n@@ -156,6 +186,9 @@ Assumed overridden:\n \n \n def dot(x, y):\n+    if is_sparse(x):\n+        return th_sparse_module.basic.structured_dot(x, y)\n+    else:\n         return T.dot(x, y)\n \n \n@@ -402,7 +435,16 @@ def batch_normalization(x, mean, var, beta, gamma, epsilon=0.0001):\n # SHAPE OPERATIONS\n \n def concatenate(tensors, axis=-1):\n-    return T.concatenate(tensors, axis=axis)\n+    if py_all([is_sparse(x) for x in tensors]):\n+        axis = axis % ndim(tensors[0])\n+        if axis == 0:\n+            return th_sparse_module.basic.vstack(tensors, format='csr')\n+        elif axis == 1:\n+            return th_sparse_module.basic.hstack(tensors, format='csr')\n+        else:\n+            raise Exception('Invalid concat axis for sparse matrix: ' + axis)\n+    else:\n+        return T.concatenate([to_dense(x) for x in tensors], axis=axis)\n \n \n def reshape(x, shape):\n\n@@ -947,7 +947,7 @@ class InputLayer(Layer):\n     '''TODO: dosctring\n     '''\n     def __init__(self, input_shape=None, batch_input_shape=None,\n-                 input_dtype=None, input_tensor=None, name=None):\n+                 input_dtype=None, input_tensor=None, sparse=False, name=None):\n         self.input_spec = None\n         self.supports_masking = False\n         self.uses_learning_phase = False\n@@ -964,6 +964,8 @@ class InputLayer(Layer):\n         self.regularizers = []\n         self.constraints = {}\n \n+        self.sparse = sparse\n+\n         if not name:\n             prefix = 'input'\n             name = prefix + '_' + str(K.get_uid(prefix))\n@@ -1004,6 +1006,7 @@ class InputLayer(Layer):\n         if input_tensor is None:\n             input_tensor = K.placeholder(shape=batch_input_shape,\n                                          dtype=input_dtype,\n+                                         sparse=self.sparse,\n                                          name=self.name)\n         else:\n             input_tensor._keras_shape = batch_input_shape\n@@ -1025,12 +1028,13 @@ class InputLayer(Layer):\n     def get_config(self):\n         config = {'batch_input_shape': self.batch_input_shape,\n                   'input_dtype': self.input_dtype,\n+                  'sparse': self.sparse,\n                   'name': self.name}\n         return config\n \n \n def Input(shape=None, batch_shape=None,\n-          name=None, dtype=K.floatx(),\n+          name=None, dtype=K.floatx(), sparse=False,\n           tensor=None):\n     '''`Input()` is used to instantiate a Keras tensor.\n     A Keras tensor is a tensor object from the underlying backend\n@@ -1063,6 +1067,7 @@ def Input(shape=None, batch_shape=None,\n             It will be autogenerated if it isn't provided.\n         dtype: The data type expected by the input, as a string\n             (`float32`, `float64`, `int32`...)\n+        sparse: a boolean specifying whether this will be a sparse tensor\n \n     # Example usage\n \n@@ -1082,6 +1087,7 @@ def Input(shape=None, batch_shape=None,\n         batch_shape = (None,) + tuple(shape)\n     input_layer = InputLayer(batch_input_shape=batch_shape,\n                              name=name, input_dtype=dtype,\n+                             sparse=sparse,\n                              input_tensor=tensor)\n     # return tensor including _keras_shape and _keras_history\n     # note that in this case train_output and test_output are the same pointer.\n\n@@ -763,9 +763,9 @@ class Model(Container):\n             do_validation = True\n             if verbose:\n                 print('Train on %d samples, validate on %d samples' %\n-                      (len(ins[0]), len(val_ins[0])))\n+                      (ins[0].shape[0], val_ins[0].shape[0]))\n \n-        nb_train_sample = len(ins[0])\n+        nb_train_sample = ins[0].shape[0]\n         index_array = np.arange(nb_train_sample)\n \n         self.history = cbks.History()\n@@ -859,7 +859,7 @@ class Model(Container):\n             or list of arrays of predictions\n             (if the model has multiple outputs).\n         '''\n-        nb_sample = len(ins[0])\n+        nb_sample = ins[0].shape[0]\n         outs = []\n         if verbose == 1:\n             progbar = Progbar(target=nb_sample)\n@@ -904,7 +904,7 @@ class Model(Container):\n             and/or metrics). The attribute `model.metrics_names` will give you\n             the display labels for the scalar outputs.\n         '''\n-        nb_sample = len(ins[0])\n+        nb_sample = ins[0].shape[0]\n         outs = []\n         if verbose == 1:\n             progbar = Progbar(target=nb_sample)\n@@ -1426,11 +1426,11 @@ class Model(Container):\n                 # build batch logs\n                 batch_logs = {}\n                 if type(x) is list:\n-                    batch_size = len(x[0])\n+                    batch_size = x[0].shape[0]\n                 elif type(x) is dict:\n-                    batch_size = len(list(x.values())[0])\n+                    batch_size = list(x.values())[0].shape[0]\n                 else:\n-                    batch_size = len(x)\n+                    batch_size = x.shape[0]\n                 batch_logs['batch'] = batch_index\n                 batch_logs['size'] = batch_size\n                 callbacks.on_batch_begin(batch_index, batch_logs)\n\n@@ -2,6 +2,7 @@ import sys\n import pytest\n from numpy.testing import assert_allclose\n import numpy as np\n+import scipy.sparse as sparse\n \n from keras.backend import theano_backend as KTH\n from keras.backend import tensorflow_backend as KTF\n@@ -780,6 +781,61 @@ class TestBackend(object):\n             koh = K.eval(K.one_hot(K.variable(indices, dtype='int32'), nb_classes))\n             assert np.all(koh == oh)\n \n+    def test_sparse_dot(self):\n+        x_d = np.array([0, 7, 2, 3], dtype=np.float32)\n+        x_r = np.array([0, 2, 2, 3], dtype=np.int64)\n+        x_c = np.array([4, 3, 2, 3], dtype=np.int64)\n+\n+        x_sparse = sparse.csr_matrix((x_d, (x_r, x_c)), shape=(4, 5))\n+        x_dense = x_sparse.toarray()\n+\n+        W = np.random.random((5, 4))\n+\n+        backends = [KTF]\n+        if KTH.th_sparse_module:\n+            # Theano has some dependency issues for sparse\n+            backends.append(KTH)\n+\n+        for K in backends:\n+            t_W = K.variable(W)\n+            k_s = K.eval(K.dot(K.variable(x_sparse), t_W))\n+            k_d = K.eval(K.dot(K.variable(x_dense), t_W))\n+\n+            assert k_s.shape == k_d.shape\n+            assert_allclose(k_s, k_d, atol=1e-05)\n+\n+    def test_sparse_concat(self):\n+        x_d = np.array([0, 7, 2, 3], dtype=np.float32)\n+        x_r = np.array([0, 2, 2, 3], dtype=np.int64)\n+        x_c = np.array([4, 3, 2, 3], dtype=np.int64)\n+\n+        x_sparse_1 = sparse.csr_matrix((x_d, (x_r, x_c)), shape=(4, 5))\n+\n+        x_d = np.array([0, 7, 2, 3], dtype=np.float32)\n+        x_r = np.array([0, 2, 2, 3], dtype=np.int64)\n+        x_c = np.array([4, 3, 2, 3], dtype=np.int64)\n+\n+        x_sparse_2 = sparse.csr_matrix((x_d, (x_r, x_c)), shape=(4, 5))\n+\n+        x_dense_1 = x_sparse_1.toarray()\n+        x_dense_2 = x_sparse_2.toarray()\n+\n+        backends = [KTF]\n+        if KTH.th_sparse_module:\n+            # Theano has some dependency issues for sparse\n+            backends.append(KTH)\n+\n+        for K in backends:\n+            k_s = K.concatenate([K.variable(x_sparse_1), K.variable(x_sparse_2)])\n+            assert K.is_sparse(k_s)\n+\n+            k_s_d = K.eval(k_s)\n+\n+            k_d = K.eval(K.concatenate([K.variable(x_dense_1), K.variable(x_dense_2)]))\n+\n+            assert k_s_d.shape == k_d.shape\n+            assert_allclose(k_s_d, k_d, atol=1e-05)\n+\n \n if __name__ == '__main__':\n     pytest.main([__file__])\n\n@@ -0,0 +1,41 @@\n+from __future__ import absolute_import\r\n+from __future__ import print_function\r\n+import pytest\r\n+\r\n+from keras.models import Model\r\n+from keras.layers import Dense, Input\r\n+from keras.utils.test_utils import keras_test\r\n+from keras import backend as K\r\n+from keras.backend import theano_backend as KTH\r\n+from keras.backend import tensorflow_backend as KTF\r\n+\r\n+import scipy.sparse as sparse\r\n+import numpy as np\r\n+np.random.seed(1337)\r\n+\r\n+\r\n+input_dim = 16\r\n+nb_hidden = 8\r\n+nb_class = 4\r\n+batch_size = 32\r\n+nb_epoch = 1\r\n+\r\n+\r\n+def do_sparse():\r\n+    return K == KTF or KTH.th_sparse_module\r\n+\r\n+\r\n+@keras_test\r\n+def test_sparse_mlp():\r\n+    if not do_sparse():\r\n+        return\r\n+\r\n+    input = Input(batch_shape=(None, input_dim), sparse=True)\r\n+    hidden = Dense(nb_hidden, activation='relu')(input)\r\n+    hidden = Dense(nb_hidden, activation='relu')(hidden)\r\n+    predictions = Dense(nb_class, activation='sigmoid')(hidden)\r\n+    model = Model(input=[input], output=predictions)\r\n+    model.compile(loss='mse', optimizer='sgd')\r\n+    x = sparse.rand(batch_size, input_dim, density=0.1, format='csr')\r\n+    y = np.random.random((batch_size, nb_class))\r\n+    model.fit(x, y, nb_epoch=1)\r\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d9c4d8a76af48f9be4ed9f25f6f5feaf4146ae8f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 5 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 15 | Churn Cumulative: 378 | Contributors (this commit): 1 | Commits (past 90d): 2 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -83,7 +83,7 @@ nb_colors = 3  # RGB\n ref_img = imread(target_mask_path)\r\n img_nrows, img_ncols = ref_img.shape[:2]\r\n \r\n-total_variation_weight = 8.5e-5\r\n+total_variation_weight = 50.\r\n style_weight = 1.\r\n content_weight = 0.1 if use_content_img else 0\r\n \r\n@@ -229,14 +229,16 @@ def region_style_loss(style_image, target_image, style_mask, target_mask):\n     if K.image_dim_ordering() == 'th':\r\n         masked_style = style_image * style_mask\r\n         masked_target = target_image * target_mask\r\n+        nb_channels = K.shape(style_image)[0]\r\n     else:\r\n         masked_style = K.permute_dimensions(\r\n             style_image, (2, 0, 1)) * style_mask\r\n         masked_target = K.permute_dimensions(\r\n             target_image, (2, 0, 1)) * target_mask\r\n-    s = gram_matrix(masked_style) * K.sum(style_mask)\r\n-    c = gram_matrix(masked_target) * K.sum(target_mask)\r\n-    return K.sum(K.square(s - c))\r\n+        nb_channels = K.shape(style_image)[-1]\r\n+    s = gram_matrix(masked_style) / K.mean(style_mask) / nb_channels\r\n+    c = gram_matrix(masked_target) / K.mean(target_mask) / nb_channels\r\n+    return K.mean(K.square(s - c))\r\n \r\n \r\n def style_loss(style_image, target_image, style_masks, target_masks):\r\n@@ -255,8 +257,7 @@ def style_loss(style_image, target_image, style_masks, target_masks):\n             target_mask = target_masks[:, :, i]\r\n         loss += region_style_loss(style_image,\r\n                                   target_image, style_mask, target_mask)\r\n-    size = img_nrows * img_ncols\r\n-    return loss / (4. * nb_colors**2 * size**2)\r\n+    return loss\r\n \r\n \r\n def content_loss(content_image, target_image):\r\n@@ -348,7 +349,7 @@ if K.image_dim_ordering() == 'th':\n else:\r\n     x = np.random.uniform(0, 255, (1, img_nrows, img_ncols, 3)) - 128.\r\n \r\n-for i in range(100):\r\n+for i in range(50):\r\n     print('Start of iteration', i)\r\n     start_time = time.time()\r\n     x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\r\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a375cb322fbd3b2af3d014643b091c6f22fa4c32", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 75 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 7/7 | Churn Δ: 79 | Churn Cumulative: 151 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -5,8 +5,9 @@ Based on Joulin et al's paper:\n Bags of Tricks for Efficient Text Classification\n https://arxiv.org/abs/1607.01759\n \n-Can achieve accuracy around 88% after 5 epochs in 70s.\n-\n+Results on IMDB datasets with uni and bi-gram embeddings:\n+    Uni-gram: 0.8813 test accuracy after 5 epochs. 15s/epoch on i7 cpu.\n+    Bi-gram : 0.9056 test accuracy after 5 epochs. 5s/epoch on GTX 1080 gpu.\n '''\n \n from __future__ import print_function\n@@ -21,17 +22,87 @@ from keras.layers import AveragePooling1D\n from keras.datasets import imdb\n \n \n-# set parameters:\n+def create_ngram_set(input_list, ngram_value=2):\n+    \"\"\"\n+    Extract a set of n-grams from a list of integers.\n+\n+    >>> create_ngram_set([1, 4, 9, 4, 1, 4], ngram_value=2)\n+    {(4, 9), (4, 1), (1, 4), (9, 4)}\n+\n+    >>> create_ngram_set([1, 4, 9, 4, 1, 4], ngram_value=3)\n+    [(1, 4, 9), (4, 9, 4), (9, 4, 1), (4, 1, 4)]\n+    \"\"\"\n+    return set(zip(*[input_list[i:] for i in range(ngram_value)]))\n+\n+\n+def add_ngram(sequences, token_indice, ngram_range=2):\n+    \"\"\"\n+    Augment the input list of list (sequences) by appending n-grams values.\n+\n+    Example: adding bi-gram\n+    >>> sequences = [[1, 3, 4, 5], [1, 3, 7, 9, 2]]\n+    >>> token_indice = {(1, 3): 1337, (9, 2): 42, (4, 5): 2017}\n+    >>> add_ngram(sequences, token_indice, ngram_range=2)\n+    [[1, 3, 4, 5, 1337, 2017], [1, 3, 7, 9, 2, 1337, 42]]\n+\n+    Example: adding tri-gram\n+    >>> sequences = [[1, 3, 4, 5], [1, 3, 7, 9, 2]]\n+    >>> token_indice = {(1, 3): 1337, (9, 2): 42, (4, 5): 2017, (7, 9, 2): 2018}\n+    >>> add_ngram(sequences, token_indice, ngram_range=3)\n+    [[1, 3, 4, 5, 1337], [1, 3, 7, 9, 2, 1337, 2018]]\n+    \"\"\"\n+    new_sequences = []\n+    for input_list in sequences:\n+        new_list = input_list[:]\n+        for i in range(len(new_list)-ngram_range+1):\n+            for ngram_value in range(2, ngram_range+1):\n+                ngram = tuple(new_list[i:i+ngram_value])\n+                if ngram in token_indice:\n+                    new_list.append(token_indice[ngram])\n+        new_sequences.append(new_list)\n+\n+    return new_sequences\n+\n+# Set parameters:\n+# ngram_range = 2 will add bi-grams features\n+ngram_range = 1\n max_features = 20000\n maxlen = 400\n batch_size = 32\n-embedding_dims = 20\n+embedding_dims = 50\n nb_epoch = 5\n \n print('Loading data...')\n (X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features)\n print(len(X_train), 'train sequences')\n print(len(X_test), 'test sequences')\n+print('Average train sequence length: {}'.format(np.mean(list(map(len, X_train)), dtype=int)))\n+print('Average test sequence length: {}'.format(np.mean(list(map(len, X_test)), dtype=int)))\n+\n+if ngram_range > 1:\n+    print('Adding {}-gram features'.format(ngram_range))\n+    # Create set of unique n-gram from the training set.\n+    ngram_set = set()\n+    for input_list in X_train:\n+        for i in range(2, ngram_range+1):\n+            set_of_ngram = create_ngram_set(input_list, ngram_value=i)\n+            ngram_set.update(set_of_ngram)\n+\n+    # Dictionary mapping n-gram token to a unique integer.\n+    # Integer values are greater than max_features in order\n+    # to avoid collision with existing features.\n+    start_index = max_features + 1\n+    token_indice = {v: k+start_index for k, v in enumerate(ngram_set)}\n+    indice_token = {token_indice[k]: k for k in token_indice}\n+\n+    # max_features is the highest integer that could be found in the dataset.\n+    max_features = np.max(list(indice_token.keys())) + 1\n+\n+    # Augmenting X_train and X_test with n-grams features\n+    X_train = add_ngram(X_train, token_indice, ngram_range)\n+    X_test = add_ngram(X_test, token_indice, ngram_range)\n+    print('Average train sequence length: {}'.format(np.mean(list(map(len, X_train)), dtype=int)))\n+    print('Average test sequence length: {}'.format(np.mean(list(map(len, X_test)), dtype=int)))\n \n print('Pad sequences (samples x time)')\n X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b2e8d5ab7c476fbed088ebee27ec3373e508af47", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 60 | Lines Deleted: 11 | Files Changed: 2 | Hunks: 27 | Methods Changed: 17 | Complexity Δ (Sum/Max): 6/6 | Churn Δ: 71 | Churn Cumulative: 1548 | Contributors (this commit): 17 | Commits (past 90d): 9 | Contributors (cumulative): 20 | DMM Complexity: 0.0\n\nDIFF:\n@@ -135,11 +135,16 @@ class SGD(Optimizer):\n         self.lr = K.variable(lr)\n         self.momentum = K.variable(momentum)\n         self.decay = K.variable(decay)\n+        self.inital_decay = decay\n \n     def get_updates(self, params, constraints, loss):\n         grads = self.get_gradients(loss, params)\n-        lr = self.lr * (1. / (1. + self.decay * self.iterations))\n-        self.updates = [K.update_add(self.iterations, 1)]\n+        self.updates = []\n+\n+        lr = self.lr\n+        if self.inital_decay > 0:\n+            lr *= (1. / (1. + self.decay * self.iterations))\n+            self.updates .append(K.update_add(self.iterations, 1))\n \n         # momentum\n         shapes = [K.get_variable_shape(p) for p in params]\n@@ -185,12 +190,17 @@ class RMSprop(Optimizer):\n         lr: float >= 0. Learning rate.\n         rho: float >= 0.\n         epsilon: float >= 0. Fuzz factor.\n+        decay: float >= 0. Learning rate decay over each update.\n     '''\n-    def __init__(self, lr=0.001, rho=0.9, epsilon=1e-8, **kwargs):\n+    def __init__(self, lr=0.001, rho=0.9, epsilon=1e-8, decay=0.,\n+                 **kwargs):\n         super(RMSprop, self).__init__(**kwargs)\n         self.__dict__.update(locals())\n         self.lr = K.variable(lr)\n         self.rho = K.variable(rho)\n+        self.decay = K.variable(decay)\n+        self.inital_decay = decay\n+        self.iterations = K.variable(0.)\n \n     def get_updates(self, params, constraints, loss):\n         grads = self.get_gradients(loss, params)\n@@ -199,11 +209,16 @@ class RMSprop(Optimizer):\n         self.weights = accumulators\n         self.updates = []\n \n+        lr = self.lr\n+        if self.inital_decay > 0:\n+            lr *= (1. / (1. + self.decay * self.iterations))\n+            self.updates.append(K.update_add(self.iterations, 1))\n+\n         for p, g, a in zip(params, grads, accumulators):\n             # update accumulator\n             new_a = self.rho * a + (1. - self.rho) * K.square(g)\n             self.updates.append(K.update(a, new_a))\n-            new_p = p - self.lr * g / (K.sqrt(new_a) + self.epsilon)\n+            new_p = p - lr * g / (K.sqrt(new_a) + self.epsilon)\n \n             # apply constraints\n             if p in constraints:\n@@ -233,10 +248,13 @@ class Adagrad(Optimizer):\n     # References\n         - [Adaptive Subgradient Methods for Online Learning and Stochastic Optimization](http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf)\n     '''\n-    def __init__(self, lr=0.01, epsilon=1e-8, **kwargs):\n+    def __init__(self, lr=0.01, epsilon=1e-8, decay=0., **kwargs):\n         super(Adagrad, self).__init__(**kwargs)\n         self.__dict__.update(locals())\n         self.lr = K.variable(lr)\n+        self.decay = K.variable(decay)\n+        self.inital_decay = decay\n+        self.iterations = K.variable(0.)\n \n     def get_updates(self, params, constraints, loss):\n         grads = self.get_gradients(loss, params)\n@@ -245,10 +263,15 @@ class Adagrad(Optimizer):\n         self.weights = accumulators\n         self.updates = []\n \n+        lr = self.lr\n+        if self.inital_decay > 0:\n+            lr *= (1. / (1. + self.decay * self.iterations))\n+            self.updates.append(K.update_add(self.iterations, 1))\n+\n         for p, g, a in zip(params, grads, accumulators):\n             new_a = a + K.square(g)  # update accumulator\n             self.updates.append(K.update(a, new_a))\n-            new_p = p - self.lr * g / (K.sqrt(new_a) + self.epsilon)\n+            new_p = p - lr * g / (K.sqrt(new_a) + self.epsilon)\n             # apply constraints\n             if p in constraints:\n                 c = constraints[p]\n@@ -278,10 +301,14 @@ class Adadelta(Optimizer):\n     # References\n         - [Adadelta - an adaptive learning rate method](http://arxiv.org/abs/1212.5701)\n     '''\n-    def __init__(self, lr=1.0, rho=0.95, epsilon=1e-8, **kwargs):\n+    def __init__(self, lr=1.0, rho=0.95, epsilon=1e-8, decay=0.,\n+                 **kwargs):\n         super(Adadelta, self).__init__(**kwargs)\n         self.__dict__.update(locals())\n         self.lr = K.variable(lr)\n+        self.decay = K.variable(decay)\n+        self.inital_decay = decay\n+        self.iterations = K.variable(0.)\n \n     def get_updates(self, params, constraints, loss):\n         grads = self.get_gradients(loss, params)\n@@ -291,6 +318,11 @@ class Adadelta(Optimizer):\n         self.weights = accumulators + delta_accumulators\n         self.updates = []\n \n+        lr = self.lr\n+        if self.inital_decay > 0:\n+            lr *= (1. / (1. + self.decay * self.iterations))\n+            self.updates.append(K.update_add(self.iterations, 1))\n+\n         for p, g, a, d_a in zip(params, grads, accumulators, delta_accumulators):\n             # update accumulator\n             new_a = self.rho * a + (1. - self.rho) * K.square(g)\n@@ -299,7 +331,7 @@ class Adadelta(Optimizer):\n             # use the new accumulator and the *old* delta_accumulator\n             update = g * K.sqrt(d_a + self.epsilon) / K.sqrt(new_a + self.epsilon)\n \n-            new_p = p - self.lr * update\n+            new_p = p - lr * update\n             # apply constraints\n             if p in constraints:\n                 c = constraints[p]\n@@ -333,20 +365,26 @@ class Adam(Optimizer):\n         - [Adam - A Method for Stochastic Optimization](http://arxiv.org/abs/1412.6980v8)\n     '''\n     def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999,\n-                 epsilon=1e-8, **kwargs):\n+                 epsilon=1e-8, decay=0., **kwargs):\n         super(Adam, self).__init__(**kwargs)\n         self.__dict__.update(locals())\n         self.iterations = K.variable(0)\n         self.lr = K.variable(lr)\n         self.beta_1 = K.variable(beta_1)\n         self.beta_2 = K.variable(beta_2)\n+        self.decay = K.variable(decay)\n+        self.inital_decay = decay\n \n     def get_updates(self, params, constraints, loss):\n         grads = self.get_gradients(loss, params)\n         self.updates = [K.update_add(self.iterations, 1)]\n \n+        lr = self.lr\n+        if self.inital_decay > 0:\n+            lr *= (1. / (1. + self.decay * self.iterations))\n+\n         t = self.iterations + 1\n-        lr_t = self.lr * K.sqrt(1. - K.pow(self.beta_2, t)) / (1. - K.pow(self.beta_1, t))\n+        lr_t = lr * K.sqrt(1. - K.pow(self.beta_2, t)) / (1. - K.pow(self.beta_1, t))\n \n         shapes = [K.get_variable_shape(p) for p in params]\n         ms = [K.zeros(shape) for shape in shapes]\n@@ -393,18 +431,24 @@ class Adamax(Optimizer):\n         - [Adam - A Method for Stochastic Optimization](http://arxiv.org/abs/1412.6980v8)\n     '''\n     def __init__(self, lr=0.002, beta_1=0.9, beta_2=0.999,\n-                 epsilon=1e-8, **kwargs):\n+                 epsilon=1e-8, decay=0., **kwargs):\n         super(Adamax, self).__init__(**kwargs)\n         self.__dict__.update(locals())\n         self.iterations = K.variable(0.)\n         self.lr = K.variable(lr)\n         self.beta_1 = K.variable(beta_1)\n         self.beta_2 = K.variable(beta_2)\n+        self.decay = K.variable(decay)\n+        self.inital_decay = decay\n \n     def get_updates(self, params, constraints, loss):\n         grads = self.get_gradients(loss, params)\n         self.updates = [K.update_add(self.iterations, 1)]\n \n+        lr = self.lr\n+        if self.inital_decay > 0:\n+            lr *= (1. / (1. + self.decay * self.iterations))\n+\n         t = self.iterations + 1\n         lr_t = self.lr / (1. - K.pow(self.beta_1, t))\n \n\n@@ -45,22 +45,27 @@ def test_sgd():\n \n def test_rmsprop():\n     _test_optimizer(RMSprop())\n+    _test_optimizer(RMSprop(decay=1e-3))\n \n \n def test_adagrad():\n     _test_optimizer(Adagrad())\n+    _test_optimizer(Adagrad(decay=1e-3))\n \n \n def test_adadelta():\n     _test_optimizer(Adadelta())\n+    _test_optimizer(Adadelta(decay=1e-3))\n \n \n def test_adam():\n     _test_optimizer(Adam())\n+    _test_optimizer(Adam(decay=1e-3))\n \n \n def test_adamax():\n     _test_optimizer(Adamax())\n+    _test_optimizer(Adamax(decay=1e-3))\n \n \n def test_nadam():\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
