{"custom_id": "keras#9e0c0ee4316976d854dac359a981a70298e01a4d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 107 | Lines Deleted: 10 | Files Changed: 2 | Hunks: 10 | Methods Changed: 9 | Complexity Δ (Sum/Max): 20/10 | Churn Δ: 117 | Churn Cumulative: 2257 | Contributors (this commit): 3 | Commits (past 90d): 27 | Contributors (cumulative): 4 | DMM Complexity: 0.7439024390243902\n\nDIFF:\n@@ -79,12 +79,20 @@ def split_dataset(dataset,\n   left_split = list(dataset_as_list[:left_size])\n   right_split = list(dataset_as_list[-right_size:])\n   \n-  left_split = _restore_dataset_from_list(left_split,dataset_type_spec)\n-  right_split = _restore_dataset_from_list(right_split,dataset_type_spec)\n+  left_split = _restore_dataset_from_list(left_split,dataset_type_spec,dataset)\n+  right_split = _restore_dataset_from_list(right_split,dataset_type_spec,\n+                                           dataset)\n \n   left_split = tf.data.Dataset.from_tensor_slices(left_split)\n   right_split = tf.data.Dataset.from_tensor_slices(right_split)\n \n+  # Batch the splits if the `dataset` is batched\n+  if dataset_type_spec is tf.data.Dataset and is_batched(dataset):   \n+    batch_size = get_batch_size(dataset)\n+    if batch_size is not None:\n+      left_split = left_split.batch(batch_size)\n+      right_split = right_split.batch(batch_size)\n+  \n   left_split = left_split.prefetch(tf.data.AUTOTUNE)\n   right_split = right_split.prefetch(tf.data.AUTOTUNE)\n \n@@ -112,8 +120,6 @@ def _convert_dataset_to_list(dataset,\n   Returns:\n       List: A list of tuples/numpy arrays.\n   \"\"\"\n-  # TODO (prakashsellathurai): add support for Batched  and unbatched dict tf datasets\n-  \n   dataset_iterator = _get_data_iterator_from_dataset(dataset,dataset_type_spec)\n   dataset_as_list = []\n \n@@ -259,12 +265,22 @@ def _get_next_sample(dataset_iterator,\n           data_size_warning_flag = False\n     yield sample\n \n-def _restore_dataset_from_list(dataset,dataset_type_spec):\n-  \"\"\"Restore the dataset from the list of arrays.\n-  \"\"\"\n+def _restore_dataset_from_list(dataset_as_list,dataset_type_spec,\n+                               original_dataset):\n+  \"\"\"Restore the dataset from the list of arrays.\"\"\"  \n   if dataset_type_spec  in [tuple,list]:\n-    dataset = tuple(np.array(sample) for sample in zip(*dataset))\n-  return dataset\n+    return tuple(np.array(sample) for sample in zip(*dataset_as_list))\n+  elif dataset_type_spec == tf.data.Dataset:\n+    if type(original_dataset.element_spec) is dict:\n+      restored_dataset = dict()\n+      for d in dataset_as_list:\n+        for k, v in d.items():\n+          if k not in restored_dataset:\n+            restored_dataset[k] = [np.array(v)]\n+          else:\n+            restored_dataset[k].append(np.array(v))\n+      return restored_dataset\n+  return dataset_as_list\n \n def _rescale_dataset_split_sizes(left_size,right_size,total_length):\n   \"\"\"Rescale the dataset split sizes to ensure that the sum of \n@@ -384,6 +400,13 @@ def is_batched(tf_dataset):\n   except :\n     return False\n   \n+def get_batch_size(tf_dataset):\n+  \"\"\"Get the batch size of the dataset.\"\"\"\n+  if is_batched(tf_dataset):\n+    return tf_dataset._batch_size\n+  else:\n+    return None\n+\n def index_directory(directory,\n                     labels,\n                     formats,\n\n@@ -118,9 +118,12 @@ class SplitDatasetTest(tf.test.TestCase):\n     dataset = dataset.batch(10)\n     left_split,right_split=dataset_utils.split_dataset(dataset,left_size=2)\n \n+    # Ensure that the splits are batched\n+    self.assertAllEqual(np.array(list(right_split)).shape,(10,))\n+    \n+    left_split,right_split = left_split.unbatch(),right_split.unbatch()\n     self.assertAllEqual(np.array(list(left_split)).shape,(2,32,32,1))\n     self.assertAllEqual(np.array(list(right_split)).shape,(98,32,32,1))\n-\n     dataset = dataset.unbatch()\n     self.assertAllEqual(list(dataset),list(left_split)+list(right_split))\n \n@@ -130,6 +133,11 @@ class SplitDatasetTest(tf.test.TestCase):\n     dataset = dataset.batch(2)\n     left_split,right_split=dataset_utils.split_dataset(dataset,left_size=4)\n \n+    # Ensure that the splits are batched\n+    self.assertEqual(np.array(list(right_split)).shape,(3, 2, 2, 32, 32))\n+    self.assertEqual(np.array(list(left_split)).shape,(2, 2, 2, 32, 32))\n+    \n+    left_split,right_split = left_split.unbatch(),right_split.unbatch()\n     self.assertAllEqual(np.array(list(left_split)).shape,(4,2,32,32))\n     self.assertAllEqual(np.array(list(right_split)).shape,(6,2,32,32))\n \n@@ -157,6 +165,72 @@ class SplitDatasetTest(tf.test.TestCase):\n \n     self.assertAllEqual(list(dataset),list(left_split)+list(right_split))\n     \n+  def test_unbatched_tf_dataset_of_dict_of_vectors(self):\n+    # test with dict of np arrays of same shape\n+    dict_samples = {'X':np.random.rand(10,2),\n+                    'Y':np.random.rand(10,2)}\n+    dataset = tf.data.Dataset.from_tensor_slices(dict_samples)\n+    left_split,right_split=dataset_utils.split_dataset(dataset,left_size=2)\n+    self.assertEqual(len(list(left_split)),2)\n+    self.assertEqual(len(list(right_split)),8)\n+    for i in range(10):\n+      if i < 2:\n+        self.assertEqual(list(left_split)[i],list(dataset)[i])\n+      else:\n+        self.assertEqual(list(right_split)[i-2],list(dataset)[i])\n+    \n+    # test with dict of np arrays with different shapes\n+    dict_samples = {'images':np.random.rand(10,16,16,3),\n+                    'labels':np.random.rand(10,)}\n+    dataset = tf.data.Dataset.from_tensor_slices(dict_samples)\n+    left_split,right_split=dataset_utils.split_dataset(dataset,left_size=0.3) \n+    self.assertEqual(len(list(left_split)),3)\n+    self.assertEqual(len(list(right_split)),7)\n+    for i in range(10):\n+      if i < 3:\n+        self.assertEqual(list(left_split)[i],list(dataset)[i])\n+      else:\n+        self.assertEqual(list(right_split)[i-3],list(dataset)[i])\n+        \n+  def test_batched_tf_dataset_of_dict_of_vectors(self):\n+    dict_samples = {'X':np.random.rand(10,3),\n+                    'Y':np.random.rand(10,3)}\n+    dataset = tf.data.Dataset.from_tensor_slices(dict_samples)\n+    dataset = dataset.batch(2)\n+    left_split,right_split=dataset_utils.split_dataset(dataset,left_size=2)\n+    \n+    self.assertAllEqual(np.array(list(left_split)).shape,(1,))\n+    self.assertAllEqual(np.array(list(right_split)).shape,(4,))  \n+    \n+    left_split,right_split = left_split.unbatch(),right_split.unbatch()\n+    self.assertEqual(len(list(left_split)),2)\n+    self.assertEqual(len(list(right_split)),8)\n+    for i in range(10):\n+      if i < 2:\n+        self.assertEqual(list(left_split)[i],list(dataset.unbatch())[i])\n+      else:\n+        self.assertEqual(list(right_split)[i-2],list(dataset.unbatch())[i])\n+    \n+    # test with dict of np arrays with different shapes\n+    dict_samples = {'images':np.random.rand(10,16,16,3),\n+                    'labels':np.random.rand(10,)}\n+    dataset = tf.data.Dataset.from_tensor_slices(dict_samples)\n+    dataset = dataset.batch(1)\n+    left_split,right_split=dataset_utils.split_dataset(dataset,right_size=0.3) \n+    \n+    self.assertAllEqual(np.array(list(left_split)).shape,(7,))\n+    self.assertAllEqual(np.array(list(right_split)).shape,(3,))\n+    \n+    dataset = dataset.unbatch()\n+    left_split,right_split = left_split.unbatch(),right_split.unbatch()\n+    self.assertEqual(len(list(left_split)),7)\n+    self.assertEqual(len(list(right_split)),3)\n+    for i in range(10):\n+      if i < 7:\n+        self.assertEqual(list(left_split)[i],list(dataset)[i])\n+      else:\n+        self.assertEqual(list(right_split)[i-7],list(dataset)[i])\n+   \n   def test_list_dataset(self):\n     dataset = [np.ones(shape=(10,10,10)) for _ in range(10)]\n     left_split,right_split = dataset_utils.split_dataset(dataset,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3337f8716967b9b5c9c575e73c66cef0a17e891f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 18 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 19 | Churn Cumulative: 2276 | Contributors (this commit): 3 | Commits (past 90d): 29 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -86,7 +86,7 @@ def split_dataset(dataset,\n   left_split = tf.data.Dataset.from_tensor_slices(left_split)\n   right_split = tf.data.Dataset.from_tensor_slices(right_split)\n \n-  # Batch the splits if the `dataset` is batched\n+  # apply batching to the splits if the dataset is batched\n   if dataset_type_spec is tf.data.Dataset and is_batched(dataset):\n     batch_size = get_batch_size(dataset)\n     if batch_size is not None:\n\n@@ -5,6 +5,7 @@ import tensorflow.compat.v2 as tf\n \n import numpy as np\n from keras.utils import dataset_utils\n+from keras.datasets import mnist\n \n class SplitDatasetTest(tf.test.TestCase):\n   def test_numpy_array(self):\n@@ -403,5 +404,21 @@ class SplitDatasetTest(tf.test.TestCase):\n       dataset_utils.split_dataset(np.array([1,2,3]),left_size=0.5,\n                                   right_size='1')\n \n+  def test_mnist_dataset(self):\n+    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n+    assert x_train.shape == (60000, 28, 28)\n+    assert x_test.shape == (10000, 28, 28)\n+    assert y_train.shape == (60000,)\n+    assert y_test.shape == (10000,)\n+\n+    dataset = (x_train[:100], y_train[:100])\n+    left_split,right_split = dataset_utils.split_dataset(dataset,left_size=0.8)\n+\n+    self.assertIsInstance(left_split, tf.data.Dataset)\n+    self.assertIsInstance(right_split, tf.data.Dataset)\n+\n+    self.assertEqual(len(left_split), 80)\n+    self.assertEqual(len(right_split), 20)\n+\n if __name__ == \"__main__\":\n   tf.test.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#dc2beed2dc2c580ee823336cb1348b2f71d537be", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 67 | Lines Deleted: 49 | Files Changed: 2 | Hunks: 4 | Methods Changed: 5 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 116 | Churn Cumulative: 2392 | Contributors (this commit): 3 | Commits (past 90d): 31 | Contributors (cumulative): 4 | DMM Complexity: 0.8461538461538461\n\nDIFF:\n@@ -280,6 +280,8 @@ def _restore_dataset_from_list(dataset_as_list,dataset_type_spec,\n           else:\n             restored_dataset[k].append(np.array(v))\n       return restored_dataset\n+    else:\n+      return tuple(np.array(sample) for sample in zip(*dataset_as_list))\n   return dataset_as_list\n \n def _rescale_dataset_split_sizes(left_size,right_size,total_length):\n\n@@ -120,7 +120,7 @@ class SplitDatasetTest(tf.test.TestCase):\n     left_split,right_split=dataset_utils.split_dataset(dataset,left_size=2)\n \n     # Ensure that the splits are batched\n-    self.assertAllEqual(np.array(list(right_split)).shape,(10,))\n+    self.assertEqual(len(list(right_split)),10)\n \n     left_split,right_split = left_split.unbatch(),right_split.unbatch()\n     self.assertAllEqual(np.array(list(left_split)).shape,(2,32,32,1))\n@@ -145,54 +145,6 @@ class SplitDatasetTest(tf.test.TestCase):\n     dataset = dataset.unbatch()\n     self.assertAllEqual(list(dataset),list(left_split)+list(right_split))\n \n-  def test_unbatched_tf_dataset_of_vectors(self):\n-    dataset = tf.data.Dataset.from_tensor_slices(np.ones(shape=(100,16, 16,3)))\n-\n-    left_split,right_split=dataset_utils.split_dataset(dataset,left_size=0.25)\n-\n-    self.assertAllEqual(np.array(list(left_split)).shape,(25,16, 16,3))\n-    self.assertAllEqual(np.array(list(right_split)).shape,(75,16, 16,3))\n-\n-    self.assertAllEqual(list(dataset),list(left_split)+list(right_split))\n-\n-  def test_unbatched_tf_dataset_of_tuple_of_vectors(self):\n-    X,Y = (np.random.rand(10,32,32,1),np.random.rand(10,32,32,1))\n-    dataset = tf.data.Dataset.from_tensor_slices((X,Y))\n-\n-    left_split,right_split=dataset_utils.split_dataset(dataset,left_size=5)\n-\n-    self.assertAllEqual(np.array(list(left_split)).shape,(5,2,32,32,1))\n-    self.assertAllEqual(np.array(list(right_split)).shape,(5,2,32,32,1))\n-\n-    self.assertAllEqual(list(dataset),list(left_split)+list(right_split))\n-\n-  def test_unbatched_tf_dataset_of_dict_of_vectors(self):\n-    # test with dict of np arrays of same shape\n-    dict_samples = {'X':np.random.rand(10,2),\n-                    'Y':np.random.rand(10,2)}\n-    dataset = tf.data.Dataset.from_tensor_slices(dict_samples)\n-    left_split,right_split=dataset_utils.split_dataset(dataset,left_size=2)\n-    self.assertEqual(len(list(left_split)),2)\n-    self.assertEqual(len(list(right_split)),8)\n-    for i in range(10):\n-      if i < 2:\n-        self.assertEqual(list(left_split)[i],list(dataset)[i])\n-      else:\n-        self.assertEqual(list(right_split)[i-2],list(dataset)[i])\n-\n-    # test with dict of np arrays with different shapes\n-    dict_samples = {'images':np.random.rand(10,16,16,3),\n-                    'labels':np.random.rand(10,)}\n-    dataset = tf.data.Dataset.from_tensor_slices(dict_samples)\n-    left_split,right_split=dataset_utils.split_dataset(dataset,left_size=0.3)\n-    self.assertEqual(len(list(left_split)),3)\n-    self.assertEqual(len(list(right_split)),7)\n-    for i in range(10):\n-      if i < 3:\n-        self.assertEqual(list(left_split)[i],list(dataset)[i])\n-      else:\n-        self.assertEqual(list(right_split)[i-3],list(dataset)[i])\n-\n   def test_batched_tf_dataset_of_dict_of_vectors(self):\n     dict_samples = {'X':np.random.rand(10,3),\n                     'Y':np.random.rand(10,3)}\n@@ -232,6 +184,70 @@ class SplitDatasetTest(tf.test.TestCase):\n       else:\n         self.assertEqual(list(right_split)[i-7],list(dataset)[i])\n \n+  def test_unbatched_tf_dataset_of_vectors(self):\n+    dataset = tf.data.Dataset.from_tensor_slices(np.ones(shape=(100,16, 16,3)))\n+\n+    left_split,right_split=dataset_utils.split_dataset(dataset,left_size=0.25)\n+\n+    self.assertAllEqual(np.array(list(left_split)).shape,(25,16, 16,3))\n+    self.assertAllEqual(np.array(list(right_split)).shape,(75,16, 16,3))\n+\n+    self.assertAllEqual(list(dataset),list(left_split)+list(right_split))\n+\n+    dataset = [np.random.rand(10,3,3) for _ in range(5)]\n+    dataset = tf.data.Dataset.from_tensor_slices(dataset)\n+\n+    left_split,right_split=dataset_utils.split_dataset(dataset,left_size=2)\n+    self.assertAllEqual(list(dataset),list(left_split)+list(right_split))\n+\n+  def test_unbatched_tf_dataset_of_tuple_of_vectors(self):\n+    # test with tuple of np arrays with same shape\n+    X,Y = (np.random.rand(10,32,32,1),np.random.rand(10,32,32,1))\n+    dataset = tf.data.Dataset.from_tensor_slices((X,Y))\n+\n+    left_split,right_split=dataset_utils.split_dataset(dataset,left_size=5)\n+\n+    self.assertEqual(len(list(left_split)),5)\n+    self.assertEqual(len(list(right_split)),5)\n+    self.assertAllEqual(list(dataset),list(left_split)+list(right_split))\n+\n+    # test with tuple of np arrays with different shapes\n+    X,Y = (np.random.rand(5,3,3),np.random.rand(5,))\n+    dataset = tf.data.Dataset.from_tensor_slices((X,Y))\n+    left_split,right_split=dataset_utils.split_dataset(dataset,left_size=0.5)\n+\n+    self.assertEqual(len(list(left_split)),2)\n+    self.assertEqual(len(list(right_split)),3)\n+    self.assertEqual(np.array(list(left_split)[0][0]).shape,(3,3))\n+    self.assertEqual(np.array(list(left_split)[0][1]).shape,())\n+\n+  def test_unbatched_tf_dataset_of_dict_of_vectors(self):\n+    # test with dict of np arrays of same shape\n+    dict_samples = {'X':np.random.rand(10,2),\n+                    'Y':np.random.rand(10,2)}\n+    dataset = tf.data.Dataset.from_tensor_slices(dict_samples)\n+    left_split,right_split=dataset_utils.split_dataset(dataset,left_size=2)\n+    self.assertEqual(len(list(left_split)),2)\n+    self.assertEqual(len(list(right_split)),8)\n+    for i in range(10):\n+      if i < 2:\n+        self.assertEqual(list(left_split)[i],list(dataset)[i])\n+      else:\n+        self.assertEqual(list(right_split)[i-2],list(dataset)[i])\n+\n+    # test with dict of np arrays with different shapes\n+    dict_samples = {'images':np.random.rand(10,16,16,3),\n+                    'labels':np.random.rand(10,)}\n+    dataset = tf.data.Dataset.from_tensor_slices(dict_samples)\n+    left_split,right_split=dataset_utils.split_dataset(dataset,left_size=0.3)\n+    self.assertEqual(len(list(left_split)),3)\n+    self.assertEqual(len(list(right_split)),7)\n+    for i in range(10):\n+      if i < 3:\n+        self.assertEqual(list(left_split)[i],list(dataset)[i])\n+      else:\n+        self.assertEqual(list(right_split)[i-3],list(dataset)[i])\n+\n   def test_list_dataset(self):\n     dataset = [np.ones(shape=(10,10,10)) for _ in range(10)]\n     left_split,right_split = dataset_utils.split_dataset(dataset,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d2717dfe14961e8775346a6ee383e5a04c84441a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 53 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 10/6 | Churn Δ: 53 | Churn Cumulative: 135 | Contributors (this commit): 4 | Commits (past 90d): 8 | Contributors (cumulative): 6 | DMM Complexity: 0.07317073170731707\n\nDIFF:\n@@ -494,6 +494,24 @@ class MultiHeadAttention(Layer):\n     if key is None:\n       key = value\n \n+    query_is_ragged = isinstance(query, tf.RaggedTensor)\n+    if query_is_ragged:\n+      query_lengths = query.nested_row_lengths()\n+      query = query.to_tensor()\n+\n+    key_is_ragged = isinstance(key, tf.RaggedTensor)\n+    value_is_ragged = isinstance(value, tf.RaggedTensor)\n+    if key_is_ragged and value_is_ragged:\n+      # Ensure they have the same shape.\n+      bounding_shape = tf.math.maximum(\n+          key.bounding_shape(), value.bounding_shape())\n+      key = key.to_tensor(shape=bounding_shape)\n+      value = value.to_tensor(shape=bounding_shape)\n+    elif key_is_ragged:\n+      key = key.to_tensor(shape=tf.shape(value))\n+    elif value_is_ragged:\n+      value = value.to_tensor(shape=tf.shape(key))\n+\n     #   N = `num_attention_heads`\n     #   H = `size_per_head`\n     # `query` = [B, T, N ,H]\n@@ -509,6 +527,10 @@ class MultiHeadAttention(Layer):\n         query, key, value, attention_mask, training)\n     attention_output = self._output_dense(attention_output)\n \n+    if query_is_ragged:\n+      attention_output = tf.RaggedTensor.from_tensor(\n+          attention_output, lengths=query_lengths)\n+\n     if return_attention_scores:\n       return attention_output, attention_scores\n     return attention_output\n\n@@ -234,6 +234,37 @@ class MultiHeadAttentionTest(test_combinations.TestCase):\n         keras.backend.eval(train_out),\n         keras.backend.eval(test_out))\n \n+  @test_combinations.generate(test_combinations.combine(\n+      ragged_query=[True, False],\n+      ragged_value=[True, False],\n+      ragged_key=[True, False]))\n+  def test_ragged_tensor(self, ragged_query, ragged_value, ragged_key):\n+    if ragged_query:\n+      query = tf.ragged.constant(\n+          [[[3., 1.], [4., 1.]], [[5., 9.], [2., 6.], [3., 1.]], [[1., 2.]]],\n+          inner_shape=(2,))\n+    else:\n+      query = keras.backend.ones(shape=(3, 2, 2))\n+\n+    if ragged_value:\n+      value = tf.ragged.constant(\n+          [[[3., 1.], [4., 1.]], [[5., 9.]], [[1., 2.]]], inner_shape=(2,))\n+    else:\n+      value = keras.backend.ones(shape=(3, 4, 2))\n+\n+    if ragged_key:\n+      key = tf.ragged.constant(\n+          [[[3., 1.], [4., 1.]],\n+           [[5., 9.], [2., 6.], [3., 1.], [1., 5.]],\n+           [[1., 2.]]],\n+          inner_shape=(2,))\n+    else:\n+      key = keras.backend.ones(shape=(3, 4, 2))\n+\n+    test_layer = keras.layers.MultiHeadAttention(num_heads=5, key_dim=2)\n+    results = test_layer(query, value, key)\n+    self.assertAllEqual(results.shape.as_list(), query.shape.as_list())\n+\n \n class SubclassAttention(keras.layers.MultiHeadAttention):\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#14579168fb86cc8508e953678150bd5d26a3bb0c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 3 | Churn Cumulative: 4040 | Contributors (this commit): 8 | Commits (past 90d): 25 | Contributors (cumulative): 8 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1523,6 +1523,9 @@ class RandomBrightness(BaseImageAugmentationLayer):\n       transformation = self.get_random_transformation()\n     return self._brightness_adjust(image, transformation['rgb_delta'])\n \n+  def augment_label(self, label, transformation=None):\n+    return label\n+\n   def get_random_transformation(self,\n                                 image=None,\n                                 label=None,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#467ae88624c835b9d42d8185c49a8ec1643106fc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 16936 | Contributors (this commit): 127 | Commits (past 90d): 29 | Contributors (cumulative): 127 | DMM Complexity: None\n\nDIFF:\n@@ -582,6 +582,9 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n           `tf.keras.metrics.SparseCategoricalAccuracy` based on the loss\n           function used and the model output shape. We do a similar\n           conversion for the strings 'crossentropy' and 'ce' as well.\n+          The metrics passed here are evaluated without sample weighting; if you\n+          would like sample weighting to apply, you can specify your\n+          metrics via the `weighted_metrics` argument instead.\n         loss_weights: Optional list or dictionary specifying scalar coefficients\n           (Python floats) to weight the loss contributions of different model\n           outputs. The loss value that will be minimized by the model will then\n@@ -1140,7 +1143,10 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n             See `tf.keras.utils.experimental.DatasetCreator` doc for more\n             information.\n           A more detailed description of unpacking behavior for iterator types\n-          (Dataset, generator, Sequence) is given below. If using\n+          (Dataset, generator, Sequence) is given below. If these include\n+          `sample_weights` as a third component, note that sample weighting\n+          applies to the `weighted_metrics` argument but not the `metrics`\n+          argument in `compile()`. If using\n           `tf.distribute.experimental.ParameterServerStrategy`, only\n           `DatasetCreator` type is supported for `x`.\n         y: Target data. Like the input data `x`,\n@@ -1236,6 +1242,10 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n             argument is not supported when `x` is a dataset, generator, or\n            `keras.utils.Sequence` instance, instead provide the sample_weights\n             as the third element of `x`.\n+            Note that sample weighting does not apply to metrics specified\n+            via the `metrics` argument in `compile()`. To apply sample weighting\n+            to your metrics, you can specify them via the `weighted_metrics` in\n+            `compile()` instead.\n         initial_epoch: Integer.\n             Epoch at which to start training\n             (useful for resuming a previous training run).\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f46cb3ea6f8308b57a027aedf7fd6c2fb12c5b9d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 25 | Lines Deleted: 15 | Files Changed: 1 | Hunks: 5 | Methods Changed: 4 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 40 | Churn Cumulative: 1146 | Contributors (this commit): 28 | Commits (past 90d): 6 | Contributors (cumulative): 28 | DMM Complexity: 0.4\n\nDIFF:\n@@ -42,8 +42,13 @@ except ImportError:\n \n \n def check_pydot():\n-  \"\"\"Returns True if PyDot and Graphviz are available.\"\"\"\n-  if pydot is None:\n+  \"\"\"Returns True if PyDot is available.\"\"\"\n+  return pydot is not None\n+\n+\n+def check_graphviz():\n+  \"\"\"Returns True if both PyDot and Graphviz are available.\"\"\"\n+  if not check_pydot():\n     return False\n   try:\n     # Attempt to create an image of a blank graph\n@@ -136,7 +141,7 @@ def model_to_dot(model,\n \n   Raises:\n     ValueError: if `model_to_dot` is called before the model is built.\n-    ImportError: if graphviz or pydot are not available.\n+    ImportError: if pydot is not available.\n   \"\"\"\n \n   if not model.built:\n@@ -149,18 +154,8 @@ def model_to_dot(model,\n   from keras.engine import functional\n \n   if not check_pydot():\n-    message = (\n-        'You must install pydot (`pip install pydot`) '\n-        'and install graphviz '\n-        '(see instructions at https://graphviz.gitlab.io/download/) '\n-        'for plot_model/model_to_dot to work.')\n-    if 'IPython.core.magics.namespace' in sys.modules:\n-      # We don't raise an exception here in order to avoid crashing notebook\n-      # tests where graphviz is not available.\n-      io_utils.print_msg(message)\n-      return\n-    else:\n-      raise ImportError(message)\n+    raise ImportError('You must install pydot (`pip install pydot`) for '\n+                      'model_to_dot to work.')\n \n   if subgraph:\n     dot = pydot.Cluster(style='dashed', graph_name=model.name)\n@@ -406,6 +401,7 @@ def plot_model(model,\n       have an `activation` property).\n \n   Raises:\n+    ImportError: if graphviz or pydot are not available.\n     ValueError: if `plot_model` is called before the model is built.\n \n   Returns:\n@@ -418,6 +414,20 @@ def plot_model(model,\n                      'Build the model first by calling `build()` or by calling '\n                      'the model on a batch of data.')\n \n+  if not check_graphviz():\n+    message = (\n+        'You must install pydot (`pip install pydot`) '\n+        'and install graphviz '\n+        '(see instructions at https://graphviz.gitlab.io/download/) '\n+        'for plot_model to work.')\n+    if 'IPython.core.magics.namespace' in sys.modules:\n+      # We don't raise an exception here in order to avoid crashing notebook\n+      # tests where graphviz is not available.\n+      io_utils.print_msg(message)\n+      return\n+    else:\n+      raise ImportError(message)\n+\n   dot = model_to_dot(\n       model,\n       show_shapes=show_shapes,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b5578812245d151e7c4f479380638e1d40fd0733", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 514 | Contributors (this commit): 1 | Commits (past 90d): 11 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -200,7 +200,7 @@ class ObjectPathMappingTest(test_util.DTensorBaseTest):\n     result = model(inputs, training=True)\n     self.assertAllClose(result, tf.zeros((10, 1000), layout=self.layout_2d))\n \n-  def _test_init_functional_model_variable_with_layout(self):\n+  def test_init_functional_model_variable_with_layout(self):\n     # Note that the functional model is using layers name + attribute name\n     # the layer name are unique among the functional model, and when the layer\n     # doesn't have a name, keras will give it a unique name based on the layer\n@@ -244,7 +244,7 @@ class ObjectPathMappingTest(test_util.DTensorBaseTest):\n         expected_result, layout=self.layout_2d)\n     self.assertAllClose(result, expected_result)\n \n-  def _test_init_sequential_model_variable_with_layout(self):\n+  def test_init_sequential_model_variable_with_layout(self):\n     # Note that the sequential model is using layers name + attribute name\n     # the layer name are unique among the functional model, and when the layer\n     # doesn't have a name, keras will give it a unique name based on the layer\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c8b3ffd02a3c3983e02274a299365ac384105366", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 15 | Files Changed: 2 | Hunks: 8 | Methods Changed: 3 | Complexity Δ (Sum/Max): -3/0 | Churn Δ: 29 | Churn Cumulative: 1410 | Contributors (this commit): 28 | Commits (past 90d): 4 | Contributors (cumulative): 29 | DMM Complexity: 0.0\n\nDIFF:\n@@ -14,12 +14,13 @@\n # ==============================================================================\n \"\"\"Built-in activation functions.\"\"\"\n \n+import sys\n+\n import tensorflow.compat.v2 as tf\n \n from keras import backend\n import keras.layers.activation as activation_layers\n-from keras.utils.generic_utils import deserialize_keras_object\n-from keras.utils.generic_utils import serialize_keras_object\n+from keras.utils import generic_utils\n from tensorflow.python.util.tf_export import keras_export\n \n # b/123041942\n@@ -505,7 +506,7 @@ def serialize(activation):\n   if (hasattr(activation, '__name__') and\n       activation.__name__ in _TF_ACTIVATIONS_V2):\n     return _TF_ACTIVATIONS_V2[activation.__name__]\n-  return serialize_keras_object(activation)\n+  return generic_utils.serialize_keras_object(activation)\n \n \n # Add additional globals so that deserialize can find these common activation\n@@ -544,17 +545,19 @@ def deserialize(name, custom_objects=None):\n       ValueError: `Unknown activation function` if the input string does not\n       denote any defined Tensorflow activation function.\n   \"\"\"\n-  globs = globals()\n+  activation_functions = {}\n+  current_module = sys.modules[__name__]\n \n-  # only replace missing activations\n-  activation_globs = activation_layers.get_globals()\n-  for key, val in activation_globs.items():\n-    if key not in globs:\n-      globs[key] = val\n+  # we put 'current_module' after 'activation_layers' to prefer the local one\n+  # if there is a collision\n+  generic_utils.populate_dict_with_module_objects(\n+      activation_functions,\n+      (activation_layers, current_module),\n+      obj_filter=callable)\n \n-  return deserialize_keras_object(\n+  return generic_utils.deserialize_keras_object(\n       name,\n-      module_objects=globs,\n+      module_objects=activation_functions,\n       custom_objects=custom_objects,\n       printable_module_name='activation function')\n \n\n@@ -21,7 +21,3 @@ from keras.layers.activation.leaky_relu import LeakyReLU\n from keras.layers.activation.prelu import PReLU\n from keras.layers.activation.elu import ELU\n from keras.layers.activation.thresholded_relu import ThresholdedReLU\n-\n-\n-def get_globals():\n-  return globals()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0b05419afd4d1debde8d4d514efad23bc1d45e64", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 19/19 | Churn Δ: 4 | Churn Cumulative: 4 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -42,7 +42,7 @@ class WideDeepModel(keras_training.Model):\n   dnn_model = keras.Sequential([keras.layers.Dense(units=64),\n                                keras.layers.Dense(units=1)])\n   combined_model = WideDeepModel(linear_model, dnn_model)\n-  combined_model.compile(optimizer=['sgd', 'adam'], 'mse', ['mse'])\n+  combined_model.compile(optimizer=['sgd', 'adam'], loss='mse', metrics=['mse'])\n   # define dnn_inputs and linear_inputs as separate numpy arrays or\n   # a single numpy array if dnn_inputs is same as linear_inputs.\n   combined_model.fit([linear_inputs, dnn_inputs], y, epochs)\n@@ -64,7 +64,7 @@ class WideDeepModel(keras_training.Model):\n   dnn_model.compile('rmsprop', 'mse')\n   dnn_model.fit(dnn_inputs, y, epochs)\n   combined_model = WideDeepModel(linear_model, dnn_model)\n-  combined_model.compile(optimizer=['sgd', 'adam'], 'mse', ['mse'])\n+  combined_model.compile(optimizer=['sgd', 'adam'], loss='mse', metrics=['mse'])\n   combined_model.fit([linear_inputs, dnn_inputs], y, epochs)\n   ```\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ab840ae3827c18287ccdaab83c3d3ebe0bbe45d0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 35 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 3/2 | Churn Δ: 35 | Churn Cumulative: 6845 | Contributors (this commit): 9 | Commits (past 90d): 39 | Contributors (cumulative): 16 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1135,6 +1135,9 @@ class RandomRotation(BaseImageAugmentationLayer):\n     output.set_shape(original_shape)\n     return output\n \n+  def augment_label(self, label, transformation=None):\n+    return label\n+\n   def compute_output_shape(self, input_shape):\n     return input_shape\n \n@@ -1298,6 +1301,9 @@ class RandomZoom(BaseImageAugmentationLayer):\n     output.set_shape(original_shape)\n     return output\n \n+  def augment_label(self, label, transformation=None):\n+    return label\n+\n   def compute_output_shape(self, input_shape):\n     return input_shape\n \n\n@@ -1868,6 +1868,35 @@ class RandomWidthTest(test_combinations.TestCase):\n     self.assertAllEqual(layer(inputs).dtype, 'uint8')\n \n \n+@test_combinations.run_all_keras_modes(always_skip_v1=True)\n+class WithLabelsTest(test_combinations.TestCase):\n+\n+  @parameterized.named_parameters(\n+      ('RandomZoom', image_preprocessing.RandomZoom, {\n+          'height_factor': 0.1\n+      }),\n+      ('RandomBrightness', image_preprocessing.RandomBrightness, {\n+          'factor': 0.5\n+      }),\n+      ('RandomContrast', image_preprocessing.RandomContrast, {\n+          'factor': 0.5\n+      }),\n+      ('RandomRotation', image_preprocessing.RandomRotation, {\n+          'factor': 0.2\n+      }),\n+  )\n+  def test_layer_with_labels(self, layer_cls, init_args):\n+    layer = layer_cls(**init_args)\n+\n+    img = tf.random.uniform(\n+        shape=(3, 512, 512, 3), minval=0, maxval=1, dtype=tf.float32)\n+    labels = tf.constant(([[1, 0, 0], [0, 0, 1], [0, 1, 0]]), dtype=tf.float32)\n+\n+    inputs = {'images': img, 'labels': labels}\n+    outputs = layer(inputs)\n+    self.assertAllClose(labels, outputs[\"labels\"])\n+\n+\n @test_combinations.run_all_keras_modes(always_skip_v1=True)\n class LearningPhaseTest(test_combinations.TestCase):\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#711af35aed585e5f76a2414f732960edd4802db4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 293 | Contributors (this commit): 2 | Commits (past 90d): 9 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -157,7 +157,7 @@ def call_with_layout(fn, layout, *args, **kwargs):\n     The output of fn, with potential relayout with the layout specified.\n   \"\"\"\n   if layout:\n-    with dtensor.run_on(layout):\n+    with dtensor.run_on(layout.mesh):\n       result = fn(*args, **kwargs)\n       return dtensor.relayout(result, layout)\n   return fn(*args, **kwargs)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#aea9728313bcaa8262774699c21976288171b209", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 140 | Lines Deleted: 140 | Files Changed: 121 | Hunks: 133 | Methods Changed: 0 | Complexity Δ (Sum/Max): 48/40 | Churn Δ: 280 | Churn Cumulative: 100941 | Contributors (this commit): 284 | Commits (past 90d): 460 | Contributors (cumulative): 783 | DMM Complexity: None\n\nDIFF:\n@@ -33,7 +33,7 @@ from keras.utils import layer_utils\n \n import tensorflow.compat.v2 as tf\n \n-from tensorflow.python.util.tf_export import keras_export  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.util.tf_export import keras_export\n \n \n BASE_WEIGHTS_PATH = 'https://storage.googleapis.com/keras-applications/'\n\n@@ -31,7 +31,7 @@ from keras.engine import training\n from keras.utils import data_utils\n from keras.utils import layer_utils\n import tensorflow.compat.v2 as tf\n-# pylint: disable=g-direct-tensorflow-import\n+\n from tensorflow.python.util.tf_export import keras_export\n \n BASE_WEIGHTS_PATH = \"https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/\"\n\n@@ -15,7 +15,7 @@\n # pylint: disable=invalid-name\n # pylint: disable=missing-docstring\n # pylint: disable=g-classes-have-attributes\n-# pylint: disable=g-direct-tensorflow-import\n+\n \"\"\"RegNet models for Keras.\n \n References:\n\n@@ -31,7 +31,7 @@ from keras.utils import data_utils\n from keras.utils import layer_utils\n import tensorflow.compat.v2 as tf\n \n-# pylint: disable=g-direct-tensorflow-import\n+\n from tensorflow.python.util.tf_export import keras_export\n \n BASE_WEIGHTS_URL = (\"https://storage.googleapis.com/tensorflow/\"\n\n@@ -24,7 +24,7 @@ import numpy as np\n import scipy.sparse\n from tensorflow.python.eager import context\n from tensorflow.python.eager.context import get_config\n-from tensorflow.python.framework import test_util as tf_test_utils  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.framework import test_util as tf_test_utils\n from keras import activations\n from keras import backend\n from keras.testing_infra import test_combinations\n\n@@ -41,7 +41,7 @@ import numpy as np\n import tensorflow.compat.v2 as tf\n \n from tensorflow.python.platform import tf_logging as logging\n-from tensorflow.python.util import deprecation  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.util import deprecation\n from tensorflow.python.util.tf_export import keras_export\n from tensorflow.tools.docs import doc_controls\n \n\n@@ -25,7 +25,7 @@ from keras.testing_infra import test_utils\n import numpy as np\n import tensorflow.compat.v2 as tf\n \n-from tensorflow.python.ops.losses import losses_impl  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.ops.losses import losses_impl\n \n _NUM_SAMPLES = 66\n _BATCH_SIZE = 32\n\n@@ -18,7 +18,7 @@ import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np\n-from tensorflow.python.framework import test_util as tf_test_utils  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.framework import test_util as tf_test_utils\n from keras import metrics\n from keras.distribute import strategy_combinations\n \n\n@@ -17,7 +17,7 @@\n import tensorflow.compat.v2 as tf\n \n import numpy as np\n-from tensorflow.python.framework import test_util as tf_test_utils  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.framework import test_util as tf_test_utils\n from keras.testing_infra import test_utils\n from keras.distribute import dataset_creator_model_fit_test_base as test_base\n from keras.distribute import strategy_combinations\n\n@@ -26,7 +26,7 @@ import threading\n \n from absl.testing import parameterized\n \n-# pylint: disable=g-direct-tensorflow-import\n+\n import keras\n from keras import backend\n from keras import callbacks\n@@ -37,7 +37,7 @@ from keras.distribute import multi_worker_testing_utils\n from keras.optimizers.optimizer_v2 import rmsprop\n from keras.utils import kpl_test_utils\n \n-# pylint: disable=g-direct-tensorflow-import\n+\n \n \n def _clone_and_build_model(model, strategy):\n\n@@ -16,8 +16,8 @@\n \n import tensorflow.compat.v2 as tf\n from tensorflow.python.platform import tf_logging as logging\n-from tensorflow.python.util import deprecation  # pylint: disable=g-direct-tensorflow-import\n-from tensorflow.python.util.tf_export import keras_export  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.util import deprecation\n+from tensorflow.python.util.tf_export import keras_export\n \n _PRINT_EVAL_STEP_EVERY_SEC = 60.0\n _ITERATIONS_UNINITIALIZED = -1\n\n@@ -26,7 +26,7 @@ from keras.optimizers.optimizer_v2 import gradient_descent\n from keras.testing_infra import test_utils\n import numpy as np\n import tensorflow.compat.v2 as tf\n-from tensorflow.python.platform import tf_logging as logging  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.platform import tf_logging as logging\n \n _BATCH_SIZE = 32\n \n\n@@ -24,7 +24,7 @@ from keras.dtensor import lazy_variable\n from keras.dtensor import utils\n from keras.engine import base_layer\n \n-from tensorflow.python.util.tf_export import keras_export  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.util.tf_export import keras_export\n \n # pylint: disable=missing-class-docstring\n \n\n@@ -16,7 +16,7 @@\n \n import threading\n \n-# pylint: disable=g-direct-tensorflow-import\n+\n from tensorflow.core.framework import attr_value_pb2\n from tensorflow.python.eager import context\n from tensorflow.python.framework import ops\n\n@@ -23,10 +23,10 @@ from keras.utils import tf_utils\n \n import tensorflow.compat.v2 as tf\n \n-# pylint: disable=g-direct-tensorflow-import\n+\n from tensorflow.dtensor.python import mesh_util\n from tensorflow.dtensor.python import tpu_util\n-# pylint: enable=g-direct-tensorflow-import\n+\n \n \n class MnistTest(test_util.DTensorBaseTest):\n\n@@ -25,7 +25,7 @@ from keras.optimizers.schedules import learning_rate_schedule\n \n import tensorflow.compat.v2 as tf\n \n-from tensorflow.python.util.tf_export import keras_export  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.util.tf_export import keras_export\n from tensorflow.tools.docs import doc_controls\n \n \n\n@@ -19,7 +19,7 @@ import numpy as np\n \n import tensorflow.compat.v2 as tf\n \n-# pylint: disable=g-direct-tensorflow-import\n+\n from tensorflow.dtensor.python import api as dtensor_api\n from tensorflow.python.eager import context\n \n\n@@ -20,7 +20,7 @@ from keras.engine import data_adapter\n from keras.engine.base_layer import Layer\n from keras.utils import version_utils\n import tensorflow.compat.v2 as tf\n-# pylint: disable=g-direct-tensorflow-import\n+\n from tensorflow.python.eager import context\n from tensorflow.python.util.tf_export import keras_export\n from tensorflow.tools.docs import doc_controls\n\n@@ -13,7 +13,7 @@\n # limitations under the License.\n # ==============================================================================\n \"\"\"Adapter module that convert different input data objects into tf.dataset.\"\"\"\n-# pylint: disable=g-direct-tensorflow-import\n+\n import tensorflow.compat.v2 as tf\n \n import abc\n\n@@ -33,10 +33,10 @@ from keras.utils import tf_utils\n import numpy as np\n import tensorflow.compat.v2 as tf\n \n-# pylint: disable=g-direct-tensorflow-import\n+\n from tensorflow.python.framework import extension_type\n from tensorflow.python.training.tracking.util import Checkpoint\n-# pylint: enable=g-direct-tensorflow-import\n+\n \n \n class NetworkConstructionTest(test_combinations.TestCase):\n\n@@ -17,7 +17,7 @@\n from keras.utils import object_identity\n import tensorflow.compat.v2 as tf\n \n-from tensorflow.python.data.util import structure  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.data.util import structure\n \n # pylint: disable=g-classes-have-attributes\n \n\n@@ -20,7 +20,7 @@ from absl.testing import parameterized\n import numpy as np\n \n import keras\n-from tensorflow.python.framework import test_util as tf_test_utils  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.framework import test_util as tf_test_utils\n from keras.testing_infra import test_combinations\n from keras.testing_infra import test_utils\n \n\n@@ -24,7 +24,7 @@ from absl.testing import parameterized\n import numpy as np\n \n import keras\n-from tensorflow.python.framework import test_util as tf_test_utils  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.framework import test_util as tf_test_utils\n from keras.engine import data_adapter\n from keras.testing_infra import test_combinations\n from keras.testing_infra import test_utils\n\n@@ -42,7 +42,7 @@ from keras.utils import np_utils\n import numpy as np\n import tensorflow.compat.v2 as tf\n \n-from tensorflow.python.framework import test_util as tf_test_utils  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.framework import test_util as tf_test_utils\n from tensorflow.python.platform import tf_logging as logging\n from tensorflow.python.training.rmsprop import RMSPropOptimizer\n \n\n@@ -23,7 +23,7 @@ import tensorflow.compat.v2 as tf\n from absl.testing import parameterized\n import numpy as np\n from tensorflow.python.eager import backprop\n-from tensorflow.python.framework import test_util as tf_test_utils  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.framework import test_util as tf_test_utils\n from keras.testing_infra import test_combinations\n from keras.feature_column import dense_features as df\n \n\n@@ -25,7 +25,7 @@ from google.protobuf import text_format\n \n from tensorflow.core.example import example_pb2\n from tensorflow.core.example import feature_pb2\n-from tensorflow.python.framework import test_util as tf_test_utils  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.framework import test_util as tf_test_utils\n from keras import backend\n from keras.feature_column import dense_features\n from keras.feature_column import sequence_feature_column as ksfc\n\n@@ -17,7 +17,7 @@ import gc\n \n import tensorflow.compat.v2 as tf\n \n-from tensorflow.python.framework import test_util as tf_test_utils  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.framework import test_util as tf_test_utils\n from tensorflow.python.platform import test as test_lib\n \n layers = tf.keras.layers\n\n@@ -20,7 +20,7 @@ import tempfile\n from absl import flags\n \n import tensorflow.compat.v2 as tf\n-from tensorflow.python.framework import test_util as tf_test_utils  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.framework import test_util as tf_test_utils\n \n FLAGS = flags.FLAGS\n flags.DEFINE_string(\"tpu\", \"\", \"Name of TPU to connect to.\")\n\n@@ -13,7 +13,7 @@\n # limitations under the License.\n # ==============================================================================\n \"\"\"Tests for convolutional layers.\"\"\"\n-# pylint: disable=g-direct-tensorflow-import\n+\n \n from absl.testing import parameterized\n import keras\n@@ -22,7 +22,7 @@ from keras.testing_infra import test_utils\n import numpy as np\n import tensorflow.compat.v2 as tf\n \n-from tensorflow.python.framework import test_util as tf_test_utils  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.framework import test_util as tf_test_utils\n \n \n @test_combinations.run_all_keras_modes\n\n@@ -13,7 +13,7 @@\n # limitations under the License.\n # ==============================================================================\n \"\"\"Tests for Keras-based einsum dense layer.\"\"\"\n-# pylint: disable=g-direct-tensorflow-import\n+\n \n from absl.testing import parameterized\n import keras\n\n@@ -23,7 +23,7 @@ import shutil\n \n from absl.testing import parameterized\n import numpy as np\n-from tensorflow.python.framework import test_util as tf_test_utils  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.framework import test_util as tf_test_utils\n from keras import backend as keras_backend\n from keras.testing_infra import test_combinations\n from keras import initializers\n\n@@ -13,7 +13,7 @@\n # limitations under the License.\n # ==============================================================================\n \"\"\"Tests for locally-connected layers.\"\"\"\n-# pylint: disable=g-direct-tensorflow-import\n+\n \n import os\n \n\n@@ -13,7 +13,7 @@\n # limitations under the License.\n # ==============================================================================\n \"\"\"Layer that adds several inputs.\"\"\"\n-# pylint: disable=g-direct-tensorflow-import\n+\n \n from keras.layers.merging.base_merge import _Merge\n \n\n@@ -13,7 +13,7 @@\n # limitations under the License.\n # ==============================================================================\n \"\"\"Layer that averages several inputs.\"\"\"\n-# pylint: disable=g-direct-tensorflow-import\n+\n \n from keras.layers.merging.base_merge import _Merge\n \n\n@@ -13,7 +13,7 @@\n # limitations under the License.\n # ==============================================================================\n \"\"\"Layer that concatenates several inputs.\"\"\"\n-# pylint: disable=g-direct-tensorflow-import\n+\n \n from keras import backend\n from keras.layers.merging.base_merge import _Merge\n\n@@ -13,7 +13,7 @@\n # limitations under the License.\n # ==============================================================================\n \"\"\"Layer that computes the dot product between two inputs.\"\"\"\n-# pylint: disable=g-direct-tensorflow-import\n+\n \n from keras import backend\n from keras.engine import base_layer_utils\n\n@@ -13,7 +13,7 @@\n # limitations under the License.\n # ==============================================================================\n \"\"\"Layer that computes the maximum (element-wise) of several inputs.\"\"\"\n-# pylint: disable=g-direct-tensorflow-import\n+\n \n from keras.layers.merging.base_merge import _Merge\n import tensorflow.compat.v2 as tf\n\n@@ -13,7 +13,7 @@\n # limitations under the License.\n # ==============================================================================\n \"\"\"Layer that computes the minimum (element-wise) of several inputs.\"\"\"\n-# pylint: disable=g-direct-tensorflow-import\n+\n \n from keras.layers.merging.base_merge import _Merge\n import tensorflow.compat.v2 as tf\n\n@@ -13,7 +13,7 @@\n # limitations under the License.\n # ==============================================================================\n \"\"\"Layer that multiplies (element-wise) several inputs.\"\"\"\n-# pylint: disable=g-direct-tensorflow-import\n+\n \n from keras.layers.merging.base_merge import _Merge\n \n\n@@ -13,7 +13,7 @@\n # limitations under the License.\n # ==============================================================================\n \"\"\"Layer that subtracts two inputs.\"\"\"\n-# pylint: disable=g-direct-tensorflow-import\n+\n \n from keras.layers.merging.base_merge import _Merge\n from keras.utils import tf_utils\n\n@@ -14,7 +14,7 @@\n # ==============================================================================\n \"\"\"Unit Normalization layer.\"\"\"\n # pylint: disable=g-bad-import-order\n-# pylint: disable=g-direct-tensorflow-import\n+\n # pylint: disable=g-classes-have-attributes\n \n import tensorflow.compat.v2 as tf\n\n@@ -13,7 +13,7 @@\n # limitations under the License.\n # ==============================================================================\n \"\"\"Benchmark for KPL implementation of categorical cross hash columns with dense inputs.\"\"\"\n-# pylint: disable=g-direct-tensorflow-import\n+\n \n import keras\n from keras.layers.preprocessing import hashed_crossing\n\n@@ -15,7 +15,7 @@\n \"\"\"Keras CategoryEncoding preprocessing layer.\"\"\"\n \n # pylint: disable=g-classes-have-attributes\n-# pylint: disable=g-direct-tensorflow-import\n+\n \n from keras import backend\n from keras.engine import base_layer\n\n@@ -14,7 +14,7 @@\n # ==============================================================================\n \"\"\"Distribution tests for keras.layers.preprocessing.category_encoding.\"\"\"\n \n-# pylint: disable=g-direct-tensorflow-import\n+\n \n import keras\n from keras import backend\n@@ -25,7 +25,7 @@ from keras.testing_infra import test_combinations\n from keras.testing_infra import test_utils\n import numpy as np\n import tensorflow.compat.v2 as tf\n-from tensorflow.python.framework import test_util as tf_test_utils  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.framework import test_util as tf_test_utils\n \n \n def batch_wrapper(dataset, batch_size, strategy, repeat=None):\n\n@@ -15,7 +15,7 @@\n \"\"\"Keras discretization preprocessing layer.\"\"\"\n \n # pylint: disable=g-classes-have-attributes\n-# pylint: disable=g-direct-tensorflow-import\n+\n \n from keras import backend\n from keras.engine import base_preprocessing_layer\n\n@@ -14,7 +14,7 @@\n # ==============================================================================\n \"\"\"Distribution tests for keras.layers.preprocessing.discretization.\"\"\"\n \n-# pylint: disable=g-direct-tensorflow-import\n+\n \n import keras\n from keras.distribute import strategy_combinations\n\n@@ -15,7 +15,7 @@\n \"\"\"Keras hashed crossing preprocessing layer.\"\"\"\n \n # pylint: disable=g-classes-have-attributes\n-# pylint: disable=g-direct-tensorflow-import\n+\n \n from keras import backend\n from keras.engine import base_layer\n\n@@ -15,7 +15,7 @@\n \"\"\"Keras hashing preprocessing layer.\"\"\"\n \n # pylint: disable=g-classes-have-attributes\n-# pylint: disable=g-direct-tensorflow-import\n+\n \n from keras import backend\n from keras.engine import base_layer\n\n@@ -14,7 +14,7 @@\n # ==============================================================================\n \"\"\"Tests for keras.layers.preprocessing.hashing.\"\"\"\n \n-# pylint: disable=g-direct-tensorflow-import\n+\n \n import keras\n from keras import backend\n@@ -25,7 +25,7 @@ from keras.testing_infra import test_combinations\n from keras.testing_infra import test_utils\n import numpy as np\n import tensorflow.compat.v2 as tf\n-from tensorflow.python.framework import test_util as tf_test_utils  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.framework import test_util as tf_test_utils\n \n \n @test_utils.run_v2_only\n\n@@ -15,7 +15,7 @@\n \"\"\"Keras image preprocessing layers.\"\"\"\n \n # pylint: disable=g-classes-have-attributes\n-# pylint: disable=g-direct-tensorflow-import\n+\n \n from keras import backend\n from keras.engine import base_layer\n\n@@ -24,7 +24,7 @@ from keras.testing_infra import test_combinations\n from keras.testing_infra import test_utils\n import numpy as np\n import tensorflow.compat.v2 as tf\n-# pylint: disable=g-direct-tensorflow-import\n+\n from tensorflow.python.ops import stateless_random_ops\n \n \n\n@@ -15,7 +15,7 @@\n \"\"\"Keras index lookup preprocessing layer.\"\"\"\n \n # pylint: disable=g-classes-have-attributes\n-# pylint: disable=g-direct-tensorflow-import\n+\n \n import collections\n \n\n@@ -14,7 +14,7 @@\n # ==============================================================================\n \"\"\"Distribution tests for keras.layers.preprocessing.index_lookup.\"\"\"\n \n-# pylint: disable=g-direct-tensorflow-import\n+\n \n import os\n \n@@ -27,7 +27,7 @@ from keras.testing_infra import test_combinations\n from keras.testing_infra import test_utils\n import numpy as np\n import tensorflow.compat.v2 as tf\n-from tensorflow.python.framework import test_util as tf_test_utils  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.framework import test_util as tf_test_utils\n \n \n @test_utils.run_v2_only\n\n@@ -15,7 +15,7 @@\n \"\"\"Keras string lookup preprocessing layer.\"\"\"\n \n # pylint: disable=g-classes-have-attributes\n-# pylint: disable=g-direct-tensorflow-import\n+\n \n from keras.engine import base_preprocessing_layer\n from keras.layers.preprocessing import index_lookup\n\n@@ -15,7 +15,7 @@\n \"\"\"Normalization preprocessing layer.\"\"\"\n \n # pylint: disable=g-classes-have-attributes\n-# pylint: disable=g-direct-tensorflow-import\n+\n \n from keras import backend\n from keras.engine import base_preprocessing_layer\n\n@@ -15,7 +15,7 @@\n \"\"\"Keras text vectorization preprocessing layer.\"\"\"\n \n # pylint: disable=g-classes-have-attributes\n-# pylint: disable=g-direct-tensorflow-import\n+\n \n from keras import backend\n from keras.engine import base_preprocessing_layer\n\n@@ -14,7 +14,7 @@\n # ==============================================================================\n \"\"\"Distribution tests for keras.layers.preprocessing.text_vectorization.\"\"\"\n \n-# pylint: disable=g-direct-tensorflow-import\n+\n \n import keras\n from keras import backend\n@@ -25,7 +25,7 @@ from keras.testing_infra import test_combinations\n from keras.testing_infra import test_utils\n import numpy as np\n import tensorflow.compat.v2 as tf\n-from tensorflow.python.framework import test_util as tf_test_utils  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.framework import test_util as tf_test_utils\n \n \n @test_utils.run_v2_only\n\n@@ -13,7 +13,7 @@\n # limitations under the License.\n # ==============================================================================\n \"\"\"Tests for up-sampling layers.\"\"\"\n-# pylint: disable=g-direct-tensorflow-import\n+\n \n import keras\n from keras.testing_infra import test_combinations\n@@ -21,7 +21,7 @@ from keras.testing_infra import test_utils\n import numpy as np\n import tensorflow.compat.v2 as tf\n \n-from tensorflow.python.framework import test_util as tf_test_utils  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.framework import test_util as tf_test_utils\n \n \n @tf_test_utils.for_all_test_methods(tf_test_utils.disable_xla,\n\n@@ -16,7 +16,7 @@\n \n See also: lstm_test.py, gru_test.py, simplernn_test.py.\n \"\"\"\n-# pylint: disable=g-direct-tensorflow-import\n+\n \n import collections\n \n\n@@ -13,7 +13,7 @@\n # limitations under the License.\n # ==============================================================================\n \"\"\"Tests for Bidirectional wrapper.\"\"\"\n-# pylint: disable=g-direct-tensorflow-import\n+\n \n import copy\n \n\n@@ -13,7 +13,7 @@\n # limitations under the License.\n # ==============================================================================\n \"\"\"Module implementing RNN wrappers.\"\"\"\n-# pylint: disable=g-direct-tensorflow-import\n+\n \n # Note that all the APIs under this module are exported as tf.nn.*. This is due\n # to the fact that those APIs were from tf.nn.rnn_cell_impl. They are ported\n\n@@ -23,7 +23,7 @@ from absl.testing import parameterized\n import numpy as np\n \n import keras\n-from tensorflow.python.framework import test_util as tf_test_utils  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.framework import test_util as tf_test_utils\n from keras.testing_infra import test_combinations\n from keras.testing_infra import test_utils\n from keras.optimizers.optimizer_v2.rmsprop import RMSprop\n\n@@ -13,7 +13,7 @@\n # limitations under the License.\n # ==============================================================================\n \"\"\"Mixin holding dropout fields for RNN cells.\"\"\"\n-# pylint: disable=g-direct-tensorflow-import\n+\n \n from keras import backend\n import tensorflow.compat.v2 as tf\n\n@@ -13,7 +13,7 @@\n # limitations under the License.\n # ==============================================================================\n \"\"\"Utilities used by both the GRU and LSTM classes.\"\"\"\n-# pylint: disable=g-direct-tensorflow-import\n+\n \n import uuid\n \n\n@@ -13,7 +13,7 @@\n # limitations under the License.\n # ==============================================================================\n \"\"\"Tests for GRU layer.\"\"\"\n-# pylint: disable=g-direct-tensorflow-import\n+\n \n import copy\n import os\n\n@@ -13,7 +13,7 @@\n # limitations under the License.\n # ==============================================================================\n \"\"\"Tests for GRU V1 layer.\"\"\"\n-# pylint: disable=g-direct-tensorflow-import\n+\n \n from absl.testing import parameterized\n import keras\n\n@@ -13,7 +13,7 @@\n # limitations under the License.\n # ==============================================================================\n \"\"\"Tests for LSTM layer.\"\"\"\n-# pylint: disable=g-direct-tensorflow-import\n+\n \n import copy\n import os\n\n@@ -13,7 +13,7 @@\n # limitations under the License.\n # ==============================================================================\n \"\"\"Tests for LSTM V1 layer.\"\"\"\n-# pylint: disable=g-direct-tensorflow-import\n+\n \n import time\n \n\n@@ -13,7 +13,7 @@\n # limitations under the License.\n # ==============================================================================\n \"\"\"Utilities for RNN cells and layers.\"\"\"\n-# pylint: disable=g-direct-tensorflow-import,protected-access\n+# pylint: disable=protected-access\n \n from keras.utils import control_flow_util\n import tensorflow.compat.v2 as tf\n\n@@ -13,7 +13,7 @@\n # limitations under the License.\n # ==============================================================================\n \"\"\"Tests for TimeDistributed wrapper.\"\"\"\n-# pylint: disable=g-direct-tensorflow-import\n+\n \n from absl.testing import parameterized\n import keras\n\n@@ -25,7 +25,7 @@ import platform\n \n from absl.testing import parameterized\n import numpy as np\n-from tensorflow.python.framework import test_util as tf_test_utils  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.framework import test_util as tf_test_utils\n from keras.testing_infra import test_combinations\n from keras.legacy_tf_layers import core as core_layers\n from tensorflow.python.ops import variable_scope\n\n@@ -9,7 +9,7 @@ import sys\n \n import tensorflow.compat.v2 as tf\n \n-from tensorflow.python.util.tf_export import keras_export  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.util.tf_export import keras_export\n \n \n @keras_export(v1=[\"keras.utils.DeterministicRandomTestTool\"])\n\n@@ -25,7 +25,7 @@ import os\n import numpy as np\n \n from tensorflow.core.protobuf import saver_pb2\n-from tensorflow.python.framework import test_util as tf_test_utils  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.framework import test_util as tf_test_utils\n from keras.legacy_tf_layers import convolutional as conv_layers\n from keras.legacy_tf_layers import normalization as normalization_layers\n \n\n@@ -20,7 +20,7 @@ from __future__ import print_function\n \n import tensorflow.compat.v2 as tf\n \n-from tensorflow.python.framework import test_util as tf_test_utils  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.framework import test_util as tf_test_utils\n from keras.legacy_tf_layers import pooling as pooling_layers\n \n \n\n@@ -26,9 +26,9 @@ from keras.utils import layer_utils\n from keras.utils import tf_inspect\n import tensorflow.compat.v2 as tf\n \n-from tensorflow.python.ops import variable_scope as vs  # pylint: disable=g-direct-tensorflow-import\n-from tensorflow.python.platform import tf_logging as logging  # pylint: disable=g-direct-tensorflow-import\n-from tensorflow.python.util.tf_export import keras_export  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.ops import variable_scope as vs\n+from tensorflow.python.platform import tf_logging as logging\n+from tensorflow.python.util.tf_export import keras_export\n \n \n def as_shape(shape):\n\n@@ -35,8 +35,8 @@ from keras.testing_infra import test_combinations\n import numpy\n import tensorflow as tf\n \n-from tensorflow.python.framework import test_util as tf_test_utils  # pylint: disable=g-direct-tensorflow-import\n-from tensorflow.python.ops import variable_scope   # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.framework import test_util as tf_test_utils\n+from tensorflow.python.ops import variable_scope \n \n \n def run_inside_wrap_function_in_eager_mode(graph_function):\n\n@@ -22,7 +22,7 @@ from keras.optimizers.optimizer_v2 import utils as optimizer_utils\n from keras.utils import generic_utils\n \n import tensorflow.compat.v2 as tf\n-# pylint: disable=g-direct-tensorflow-import\n+\n from tensorflow.python.keras.optimizer_v2 import optimizer_v2 as legacy_optimizer\n from tensorflow.python.platform import tf_logging\n from tensorflow.python.util.tf_export import keras_export\n\n@@ -31,8 +31,8 @@ from keras.testing_infra import test_combinations\n \n import numpy as np\n import tensorflow.compat.v2 as tf\n-# pylint: disable=g-direct-tensorflow-import\n-from tensorflow.python.framework import test_util as tf_test_utils  # pylint: disable=g-direct-tensorflow-import\n+\n+from tensorflow.python.framework import test_util as tf_test_utils\n from tensorflow.python.keras.optimizer_v2 import gradient_descent as legacy_sgd\n from tensorflow.python.platform import tf_logging\n \n\n@@ -21,7 +21,7 @@ from keras.layers import deserialize as deserialize_layer\n from keras.models import Model\n from keras.utils import generic_utils\n import tensorflow.compat.v2 as tf\n-# pylint: disable=g-direct-tensorflow-import\n+\n from tensorflow.python.util.tf_export import keras_export\n \n # pylint: disable=g-classes-have-attributes\n\n@@ -15,7 +15,7 @@\n \"\"\"Legacy Adadelta optimizer implementation.\"\"\"\n \n from keras.optimizers.optimizer_v2 import adadelta\n-# pylint: disable=g-direct-tensorflow-import\n+\n from tensorflow.python.util.tf_export import keras_export\n \n \n\n@@ -15,7 +15,7 @@\n \"\"\"Legacy Adagrad optimizer implementation.\"\"\"\n \n from keras.optimizers.optimizer_v2 import adagrad\n-# pylint: disable=g-direct-tensorflow-import\n+\n from tensorflow.python.util.tf_export import keras_export\n \n \n\n@@ -15,7 +15,7 @@\n \"\"\"Legacy Adam optimizer implementation.\"\"\"\n \n from keras.optimizers.optimizer_v2 import adam\n-# pylint: disable=g-direct-tensorflow-import\n+\n from tensorflow.python.util.tf_export import keras_export\n \n \n\n@@ -15,7 +15,7 @@\n \"\"\"Legacy Adamax optimizer implementation.\"\"\"\n \n from keras.optimizers.optimizer_v2 import adamax\n-# pylint: disable=g-direct-tensorflow-import\n+\n from tensorflow.python.util.tf_export import keras_export\n \n \n\n@@ -15,7 +15,7 @@\n \"\"\"Legacy Ftrl optimizer implementation.\"\"\"\n \n from keras.optimizers.optimizer_v2 import ftrl\n-# pylint: disable=g-direct-tensorflow-import\n+\n from tensorflow.python.util.tf_export import keras_export\n \n \n\n@@ -15,7 +15,7 @@\n \"\"\"Legacy Nadam optimizer implementation.\"\"\"\n \n from keras.optimizers.optimizer_v2 import nadam\n-# pylint: disable=g-direct-tensorflow-import\n+\n from tensorflow.python.util.tf_export import keras_export\n \n \n\n@@ -15,7 +15,7 @@\n \"\"\"Legacy Adam optimizer implementation.\"\"\"\n \n from keras.optimizers.optimizer_v2 import optimizer_v2\n-# pylint: disable=g-direct-tensorflow-import\n+\n from tensorflow.python.util.tf_export import keras_export\n \n \n\n@@ -15,7 +15,7 @@\n \"\"\"Legacy RMSprop optimizer implementation.\"\"\"\n \n from keras.optimizers.optimizer_v2 import rmsprop\n-# pylint: disable=g-direct-tensorflow-import\n+\n from tensorflow.python.util.tf_export import keras_export\n \n \n\n@@ -15,7 +15,7 @@\n \"\"\"Legacy SGD optimizer implementation.\"\"\"\n \n from keras.optimizers.optimizer_v2 import gradient_descent\n-# pylint: disable=g-direct-tensorflow-import\n+\n from tensorflow.python.util.tf_export import keras_export\n \n \n\n@@ -17,7 +17,7 @@\n from keras.optimizers.optimizer_experimental import optimizer\n from keras.utils import generic_utils\n import tensorflow.compat.v2 as tf\n-# pylint: disable=g-direct-tensorflow-import\n+\n from tensorflow.python.util.tf_export import keras_export\n \n \n\n@@ -18,7 +18,7 @@ from keras import initializers\n from keras.optimizers.optimizer_experimental import optimizer\n from keras.utils import generic_utils\n import tensorflow.compat.v2 as tf\n-# pylint: disable=g-direct-tensorflow-import\n+\n from tensorflow.python.util.tf_export import keras_export\n \n \n\n@@ -17,7 +17,7 @@\n from keras.optimizers.optimizer_experimental import optimizer\n from keras.utils import generic_utils\n import tensorflow.compat.v2 as tf\n-# pylint: disable=g-direct-tensorflow-import\n+\n from tensorflow.python.util.tf_export import keras_export\n \n \n\n@@ -17,7 +17,7 @@\n from keras.optimizers.optimizer_experimental import optimizer\n from keras.utils import generic_utils\n import tensorflow.compat.v2 as tf\n-# pylint: disable=g-direct-tensorflow-import\n+\n from tensorflow.python.util.tf_export import keras_export\n \n \n\n@@ -17,7 +17,7 @@\n from keras.optimizers.optimizer_experimental import optimizer\n from keras.utils import generic_utils\n import tensorflow.compat.v2 as tf\n-# pylint: disable=g-direct-tensorflow-import\n+\n from tensorflow.python.util.tf_export import keras_export\n \n \n\n@@ -17,7 +17,7 @@\n from keras.optimizers.optimizer_experimental import optimizer\n from keras.utils import generic_utils\n import tensorflow.compat.v2 as tf\n-# pylint: disable=g-direct-tensorflow-import\n+\n from tensorflow.python.util.tf_export import keras_export\n \n \n\n@@ -17,7 +17,7 @@\n from keras.optimizers.optimizer_experimental import optimizer\n from keras.utils import generic_utils\n import tensorflow.compat.v2 as tf\n-# pylint: disable=g-direct-tensorflow-import\n+\n from tensorflow.python.util.tf_export import keras_export\n \n \n\n@@ -25,7 +25,7 @@ from keras import initializers\n from keras.optimizers.optimizer_v2 import utils as optimizer_utils\n from keras.optimizers.schedules import learning_rate_schedule\n import tensorflow.compat.v2 as tf\n-# pylint: disable=g-direct-tensorflow-import\n+\n from tensorflow.python.util.tf_export import keras_export\n from tensorflow.tools.docs import doc_controls\n \n\n@@ -17,7 +17,7 @@\n from keras.optimizers.optimizer_experimental import optimizer\n from keras.utils import generic_utils\n import tensorflow.compat.v2 as tf\n-# pylint: disable=g-direct-tensorflow-import\n+\n from tensorflow.python.util.tf_export import keras_export\n \n \n\n@@ -17,7 +17,7 @@\n from keras.optimizers.optimizer_experimental import optimizer\n from keras.utils import generic_utils\n import tensorflow.compat.v2 as tf\n-# pylint: disable=g-direct-tensorflow-import\n+\n from tensorflow.python.util.tf_export import keras_export\n \n \n\n@@ -18,7 +18,7 @@\n \n import tensorflow.compat.v2 as tf\n from keras.optimizers.optimizer_v2 import optimizer_v2\n-from tensorflow.python.util.tf_export import keras_export  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.util.tf_export import keras_export\n \n \n # pylint: disable=g-classes-have-attributes\n\n@@ -17,7 +17,7 @@\n # pylint: disable=g-classes-have-attributes\n import tensorflow.compat.v2 as tf\n from keras.optimizers.optimizer_v2 import optimizer_v2\n-from tensorflow.python.util.tf_export import keras_export  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.util.tf_export import keras_export\n \n \n # pylint: disable=g-classes-have-attributes\n\n@@ -30,7 +30,7 @@ from keras.utils import layer_utils\n from keras.utils import tf_inspect\n from keras.utils import tf_utils\n import tensorflow.compat.v2 as tf\n-from tensorflow.python.util.tf_export import keras_export  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.util.tf_export import keras_export\n \n \n keras_optimizers_gauge = tf.__internal__.monitoring.BoolGauge(\n\n@@ -43,7 +43,7 @@ from keras.utils import np_utils\n import numpy as np\n import tensorflow.compat.v2 as tf\n \n-from tensorflow.python.framework import test_util as tf_test_utils  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.framework import test_util as tf_test_utils\n \n \n _DATA_TYPES = [tf.half, tf.float32, tf.float64]\n\n@@ -22,7 +22,7 @@ import math\n \n from absl.testing import parameterized\n import numpy as np\n-from tensorflow.python.framework import test_util as tf_test_utils  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.framework import test_util as tf_test_utils\n from keras.testing_infra import test_combinations\n from keras.testing_infra import test_utils\n from keras.optimizers.schedules import learning_rate_schedule\n\n@@ -22,7 +22,7 @@ from keras.engine import base_layer\n from keras.engine import input_spec\n from keras.engine import training\n from keras.layers import core\n-from tensorflow.python.util import deprecation  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.util import deprecation\n from tensorflow.python.util.tf_export import keras_export\n \n \n\n@@ -22,7 +22,7 @@ from keras.engine import base_layer\n from keras.engine import data_adapter\n from keras.engine import training as keras_training\n from keras.utils import generic_utils\n-from tensorflow.python.util import deprecation  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.util import deprecation\n from tensorflow.python.util.tf_export import keras_export\n \n \n\n@@ -15,7 +15,7 @@\n # pylint: disable=invalid-name\n # pylint: disable=g-import-not-at-top\n # pylint: disable=g-classes-have-attributes\n-# pylint: disable=g-direct-tensorflow-import\n+\n \"\"\"Utilies for image preprocessing and augmentation.\n \n Deprecated: `tf.keras.preprocessing.image` APIs do not operate on tensors and\n\n@@ -22,7 +22,7 @@ for more details.\n \"\"\"\n # pylint: disable=invalid-name\n # pylint: disable=g-classes-have-attributes\n-# pylint: disable=g-direct-tensorflow-import\n+\n \n import json\n import random\n\n@@ -25,7 +25,7 @@ and [preprocessing layer guide]\n \"\"\"\n # pylint: disable=invalid-name\n # pylint: disable=g-classes-have-attributes\n-# pylint: disable=g-direct-tensorflow-import\n+\n \n import collections\n import hashlib\n\n@@ -5,9 +5,9 @@ import subprocess\n from absl import flags\n import tensorflow.compat.v2 as tf\n \n-# pylint: disable=g-direct-tensorflow-import\n+\n from tensorflow.core.protobuf import saved_model_pb2\n-# pylint: enable=g-direct-tensorflow-import\n+\n \n FLAGS = flags.FLAGS\n \n\n@@ -32,7 +32,7 @@ import wrapt\n \n from keras.utils import generic_utils\n \n-# pylint: disable=g-direct-tensorflow-import\n+\n from tensorflow.python.framework import type_spec\n \n \n\n@@ -36,8 +36,8 @@ from keras.utils import tf_contextlib\n from keras.utils import tf_inspect\n import numpy as np\n import tensorflow.compat.v2 as tf\n-from tensorflow.python.framework import test_util as tf_test_utils  # pylint: disable=g-direct-tensorflow-import\n-from tensorflow.python.util.tf_export import keras_export  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.framework import test_util as tf_test_utils\n+from tensorflow.python.util.tf_export import keras_export\n \n \n def string_test(actual, expected):\n\n@@ -35,8 +35,8 @@ import tensorflow.compat.v2 as tf\n from tensorboard.plugins.histogram import summary_v2 as histogram_summary_v2\n from tensorboard.plugins.image import summary_v2 as image_summary_v2\n from tensorboard.plugins.scalar import summary_v2 as scalar_summary_v2\n-from tensorflow.python.eager.context import set_soft_device_placement  # pylint: disable=g-direct-tensorflow-import\n-from tensorflow.python.framework import test_util as tf_test_utils  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.eager.context import set_soft_device_placement\n+from tensorflow.python.framework import test_util as tf_test_utils\n \n NUM_CLASSES = 4\n \n\n@@ -23,7 +23,7 @@ from absl.testing import parameterized\n import numpy as np\n \n import keras\n-from tensorflow.python.framework import test_util as tf_test_utils  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.framework import test_util as tf_test_utils\n from keras.testing_infra import test_combinations\n from keras.testing_infra import test_utils\n from keras.tests import model_subclassing_test_util as model_util\n\n@@ -17,7 +17,7 @@\n import tensorflow.compat.v2 as tf\n \n import os\n-from tensorflow.python.framework import test_util as tf_test_utils  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.framework import test_util as tf_test_utils\n from keras.layers import core\n from keras.optimizers.optimizer_v2 import adam\n \n\n@@ -19,7 +19,7 @@ import tensorflow.compat.v2 as tf\n import os\n import weakref\n from tensorflow.python.eager import context\n-from tensorflow.python.framework import test_util as tf_test_utils  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.framework import test_util as tf_test_utils\n from keras.testing_infra import test_combinations\n from keras.testing_infra import test_utils\n from keras.engine import input_layer\n\n@@ -19,7 +19,7 @@ import tensorflow.compat.v2 as tf\n import functools\n import os\n from tensorflow.python.eager import context\n-from tensorflow.python.framework import test_util as tf_test_utils  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.framework import test_util as tf_test_utils\n from keras.testing_infra import test_combinations\n from keras.testing_infra import test_utils\n from keras.engine import training\n\n@@ -13,7 +13,7 @@\n # limitations under the License.\n # ==============================================================================\n \"\"\"Utilities related to image handling.\"\"\"\n-# pylint: disable=g-direct-tensorflow-import\n+\n # pylint: disable=g-import-not-at-top\n \n import io\n\n@@ -21,9 +21,9 @@ import threading\n \n from absl import logging\n from keras.utils import keras_logging\n-# pylint: disable=g-direct-tensorflow-import\n+\n from tensorflow.python.util.tf_export import keras_export\n-# pylint: enable=g-direct-tensorflow-import\n+\n \n INTERACTIVE_LOGGING = threading.local()\n INTERACTIVE_LOGGING.enable = keras_logging.INTERACTIVE_LOGGING_DEFAULT\n\n@@ -24,7 +24,7 @@ from keras.utils import tf_inspect\n import numpy as np\n \n import tensorflow.compat.v2 as tf\n-from tensorflow.python.util.tf_export import keras_export  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.util.tf_export import keras_export\n \n \n @keras_export('keras.utils.get_source_inputs')\n\n@@ -26,10 +26,10 @@ from keras.utils import tf_contextlib\n import numpy as np\n \n import tensorflow.compat.v2 as tf\n-# pylint: disable=g-direct-tensorflow-import\n+\n from tensorflow.python.framework import ops\n from tensorflow.python.util.tf_export import keras_export\n-# pylint: enable=g-direct-tensorflow-import\n+\n \n \n @keras_export('keras.utils.set_random_seed', v1=[])\n\n@@ -26,7 +26,7 @@ from keras.models import Sequential\n from keras.utils.generic_utils import has_arg\n from keras.utils.np_utils import to_categorical\n from tensorflow.python.util.tf_export import keras_export\n-from tensorflow.tools.docs import doc_controls  # pylint: disable=g-direct-tensorflow-import\n+from tensorflow.tools.docs import doc_controls\n \n \n class BaseWrapper:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
