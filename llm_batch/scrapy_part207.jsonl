{"custom_id": "scrapy#2946b674144833254f3ec6dd6aece0156f71a21b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 504 | Contributors (this commit): 1 | Commits (past 90d): 3 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -156,13 +156,15 @@ class AddonManager(Mapping):\n     \"\"\"This class facilitates loading and storing :ref:`topics-addons`.\n \n     You can treat it like a read-only dictionary in which keys correspond to\n-    add-on names and values correspond to the add-on objects::\n+    add-on names and values correspond to the add-on objects. Add-on\n+    configurations are saved in the :attr:`config` dictionary attribute::\n \n         addons = AddonManager()\n         # ... load some add-ons here\n         print addons.enabled  # prints names of all enabled add-ons\n         print addons['TestAddon'].version  # prints version of add-on with name\n                                            # 'TestAddon'\n+        print addons.configs['TestAddon']  # prints configuration of 'TestAddon'\n \n     \"\"\"\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#25498c3c210ea5aa1a45aed02618033d832cfc1c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 6 | Files Changed: 2 | Hunks: 5 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 899 | Contributors (this commit): 1 | Commits (past 90d): 6 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -1,7 +1,5 @@\n from collections import defaultdict, Mapping\n-from importlib import import_module\n from inspect import isclass\n-import os\n import six\n import warnings\n \n@@ -11,7 +9,6 @@ from zope.interface.verify import verifyObject\n \n from scrapy.exceptions import NotConfigured\n from scrapy.interfaces import IAddon\n-from scrapy.settings import BaseSettings\n from scrapy.utils.conf import config_from_filepath, get_config\n from scrapy.utils.misc import load_module_or_object\n from scrapy.utils.project import get_project_path\n\n@@ -1,7 +1,5 @@\n import os.path\n import six\n-from six.moves.configparser import SafeConfigParser\n-import sys\n from tests import mock\n import unittest\n import warnings\n@@ -15,7 +13,7 @@ import scrapy.addons\n from scrapy.addons import Addon, AddonManager\n from scrapy.crawler import Crawler\n from scrapy.interfaces import IAddon\n-from scrapy.settings import BaseSettings, Settings\n+from scrapy.settings import BaseSettings\n \n from . import addons\n from . import addonmod\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#d18b6a61d7db295c5f4b1800402a064ed1f40059", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 16 | Churn Cumulative: 408 | Contributors (this commit): 1 | Commits (past 90d): 3 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -14,6 +14,7 @@ from scrapy.addons import Addon, AddonManager\n from scrapy.crawler import Crawler\n from scrapy.interfaces import IAddon\n from scrapy.settings import BaseSettings\n+from scrapy.utils.conf import config_from_filepath\n \n from . import addons\n from . import addonmod\n@@ -244,8 +245,7 @@ class AddonManagerTest(unittest.TestCase):\n         _test_load_method('load_settings', settings)\n \n     def test_load_cfg(self):\n-        manager = AddonManager()\n-        manager.load_cfg(self.TESTCFGPATH)\n+        def _check_loaded_addons(manager):\n             six.assertCountEqual(self, manager, ['GoodAddon', 'AddonModule'])\n             self.assertIsInstance(manager['GoodAddon'], addons.GoodAddon)\n             six.assertCountEqual(self, manager.configs['GoodAddon'], ['key'])\n@@ -254,6 +254,13 @@ class AddonManagerTest(unittest.TestCase):\n             self.assertEqual(manager['AddonModule'].name, addonmod.name)\n             six.assertCountEqual(self, manager.configs['AddonModule'], ['key'])\n             self.assertEqual(manager.configs['AddonModule']['key'], 'val2')\n+        manager = AddonManager()\n+        manager.load_cfg(self.TESTCFGPATH)\n+        _check_loaded_addons(manager)\n+        manager = AddonManager()\n+        preloaded_cfg = config_from_filepath(self.TESTCFGPATH)\n+        manager.load_cfg(preloaded_cfg)\n+        _check_loaded_addons(manager)\n \n     def test_enabled_disabled(self):\n         manager = AddonManager()\n@@ -330,6 +337,11 @@ class AddonManagerTest(unittest.TestCase):\n             self.assertEqual(us_first.call_count, 1)\n             self.assertEqual(us_second.call_count, 2)\n \n+        # This will become relevant when we let spiders implement the add-on\n+        # interface and should be replaced with a test where\n+        # AddonManager.spidercls = None then.\n+        manager._call_if_exists(None, 'irrelevant')\n+\n     def test_update_addons_last_minute_add(self):\n         class AddedAddon(addons.GoodAddon):\n             name = 'AddedAddon'\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#9f7fcf5582ed61787180df20a62a301cc09fce4a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 3/2 | Churn Δ: 7 | Churn Cumulative: 381 | Contributors (this commit): 7 | Commits (past 90d): 3 | Contributors (cumulative): 10 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,5 +1,6 @@\n \"\"\"Some helpers for deprecation messages\"\"\"\n \n+import six\n import warnings\n import inspect\n from scrapy.exceptions import ScrapyDeprecationWarning\n@@ -149,6 +150,8 @@ DEPRECATION_RULES = [\n \n def update_classpath(path):\n     \"\"\"Update a deprecated path from an object with its new location\"\"\"\n+    if not isinstance(path, six.string_types):\n+        return path\n     for prefix, replacement in DEPRECATION_RULES:\n         if path.startswith(prefix):\n             new_path = path.replace(prefix, replacement, 1)\n\n@@ -279,3 +279,7 @@ class UpdateClassPathTest(unittest.TestCase):\n             output = update_classpath('scrapy.unmatched.Path')\n         self.assertEqual(output, 'scrapy.unmatched.Path')\n         self.assertEqual(len(w), 0)\n+\n+    def test_returns_nonstring(self):\n+        for notastring in [None, True, [1, 2, 3], object()]:\n+            self.assertEqual(update_classpath(notastring), notastring)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#f7ed239fcb47663d881e72ffab4386244b215ce4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 32 | Lines Deleted: 13 | Files Changed: 3 | Hunks: 10 | Methods Changed: 5 | Complexity Δ (Sum/Max): 7/7 | Churn Δ: 45 | Churn Cumulative: 1388 | Contributors (this commit): 22 | Commits (past 90d): 12 | Contributors (cumulative): 24 | DMM Complexity: 0.15384615384615385\n\nDIFF:\n@@ -1,4 +1,4 @@\n-from collections import defaultdict, Mapping\n+from collections import defaultdict, Mapping, OrderedDict\n from inspect import isclass\n import six\n import warnings\n@@ -9,7 +9,8 @@ from zope.interface.verify import verifyObject\n \n from scrapy.exceptions import NotConfigured\n from scrapy.interfaces import IAddon\n-from scrapy.utils.conf import config_from_filepath, get_config\n+from scrapy.utils.conf import (build_component_list, config_from_filepath,\n+                               get_config)\n from scrapy.utils.misc import load_module_or_object\n from scrapy.utils.project import get_project_path\n \n@@ -166,7 +167,7 @@ class AddonManager(Mapping):\n     \"\"\"\n \n     def __init__(self):\n-        self._addons = {}\n+        self._addons = OrderedDict()\n         self.configs = {}\n         self._disable_on_add = []\n \n@@ -310,15 +311,15 @@ class AddonManager(Mapping):\n         \"\"\"Load add-ons and configurations from settings object.\n \n         This will invoke :meth:`get_addon` for every add-on path in the\n-        ``INSTALLED_ADDONS`` setting. For each of these add-ons, the\n-        configuration will be read from the dictionary setting whose name\n-        matches the uppercase add-on name.\n+        ``ADDONS`` setting. For each of these add-ons, the configuration will be\n+        read from the dictionary setting whose name matches the uppercase add-on\n+        name.\n \n         :param settings: The :class:`~scrapy.settings.Settings` object from \\\n             which to read the add-on configuration\n         :type settings: :class:`~scrapy.settings.Settings`\n         \"\"\"\n-        paths = settings.getlist('INSTALLED_ADDONS')\n+        paths = build_component_list(settings['ADDONS'])\n         addons = [self.get_addon(path) for path in paths]\n         configs = [settings.getdict(addon.name.upper()) for addon in addons]\n         for a, c in zip(addons, configs):\n\n@@ -18,6 +18,8 @@ import sys\n from importlib import import_module\n from os.path import join, abspath, dirname\n \n+ADDONS = {}\n+\n AJAXCRAWL_ENABLED = False\n \n AUTOTHROTTLE_ENABLED = False\n@@ -167,8 +169,6 @@ HTTPCACHE_DBM_MODULE = 'anydbm'\n HTTPCACHE_POLICY = 'scrapy.extensions.httpcache.DummyPolicy'\n HTTPCACHE_GZIP = False\n \n-INSTALLED_ADDONS = ()\n-\n ITEM_PROCESSOR = 'scrapy.pipelines.ItemPipelineManager'\n \n ITEM_PIPELINES = {}\n\n@@ -1,3 +1,5 @@\n+from collections import OrderedDict\n+import itertools\n import os.path\n import six\n from tests import mock\n@@ -236,14 +238,30 @@ class AddonManagerTest(unittest.TestCase):\n         _test_load_method('load_dict', addonsdict)\n \n         settings = BaseSettings()\n-        settings.set('INSTALLED_ADDONS', [\n-                self.ADDONMODPATH,\n-                'tests.test_addons.addons.GoodAddon',\n-                ])\n+        settings.set('ADDONS', {self.ADDONMODPATH: 0,\n+                                'tests.test_addons.addons.GoodAddon': 0})\n         settings.set('ADDONMODULE', {'key': 'val1'})\n         settings.set('GOODADDON', {'key': 'val2'})\n         _test_load_method('load_settings', settings)\n \n+    def test_load_dict_load_settings_order(self):\n+        def _test_load_method(expected_order, func, *args, **kwargs):\n+            manager = AddonManager()\n+            getattr(manager, func)(*args, **kwargs)\n+            self.assertEqual(list(manager.keys()), expected_order)\n+\n+        # Get three addons named 0, 1, 2\n+        addonlist = [addons.GoodAddon(str(x)) for x in range(3)]\n+        # Test both methods for every possible mutation\n+        for ordered_addons in itertools.permutations(addonlist):\n+            expected_order = [a.name for a in ordered_addons]\n+            addonsdict = OrderedDict((a, {}) for a in ordered_addons)\n+            _test_load_method(expected_order, 'load_dict', addonsdict)\n+            settings = BaseSettings({\n+                'ADDONS': {a: i for i, a in enumerate(ordered_addons)}\n+            })\n+            _test_load_method(expected_order, 'load_settings', settings)\n+\n     def test_load_cfg(self):\n         def _check_loaded_addons(manager):\n             six.assertCountEqual(self, manager, ['GoodAddon', 'AddonModule'])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#b10caf91a14dcf0d0d4fe89865a53e2542588772", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 48 | Files Changed: 3 | Hunks: 6 | Methods Changed: 4 | Complexity Δ (Sum/Max): -7/0 | Churn Δ: 49 | Churn Cumulative: 1591 | Contributors (this commit): 8 | Commits (past 90d): 12 | Contributors (cumulative): 10 | DMM Complexity: 0.03571428571428571\n\nDIFF:\n@@ -9,8 +9,7 @@ from zope.interface.verify import verifyObject\n \n from scrapy.exceptions import NotConfigured\n from scrapy.interfaces import IAddon\n-from scrapy.utils.conf import (build_component_list, config_from_filepath,\n-                               get_config)\n+from scrapy.utils.conf import build_component_list\n from scrapy.utils.misc import load_module_or_object\n from scrapy.utils.project import get_project_path\n \n@@ -325,31 +324,6 @@ class AddonManager(Mapping):\n         for a, c in zip(addons, configs):\n             self.add(a, c)\n \n-    def load_cfg(self, cfg=None):\n-        \"\"\"Load add-ons and configurations from given ``ConfigParser`` object or\n-        config file path.\n-\n-        Each add-on should have its own section, where the section has a name in\n-        the form ``addon:my_addon_path``. The add-on object is searched for via\n-        the :meth:`get_addon` method, ``my_addon_path`` can be either a Python\n-        or a file path.\n-\n-        If ``cfg`` is ``None``, ``scrapy.cfg`` will be used.\n-\n-        :param cfg: ``ConfigParser`` object or config file path from which to \\\n-            read add-on configuration\n-        :type cfg: ``ConfigParser`` or ``str``\n-        \"\"\"\n-        if cfg is None:\n-            cfg = get_config()\n-        elif isinstance(cfg, six.string_types):\n-            cfg = config_from_filepath(cfg)\n-        for secname in cfg.sections():\n-            if secname.startswith(\"addon:\"):\n-                addonkey = secname.split(\"addon:\", 1)[1]\n-                addoncfg = dict(cfg.items(secname))\n-                self.add(addonkey, addoncfg)\n-\n     def check_dependency_clashes(self):\n         \"\"\"Check for incompatibilities in add-on dependencies.\n \n\n@@ -120,7 +120,6 @@ def execute(argv=None, settings=None):\n     # ------------------------------------------------------------------\n \n     addons = AddonManager()\n-    addons.load_cfg()\n \n     inproject = inside_project()\n     cmds = _get_commands_dict(settings, inproject)\n\n@@ -16,7 +16,6 @@ from scrapy.addons import Addon, AddonManager\n from scrapy.crawler import Crawler\n from scrapy.interfaces import IAddon\n from scrapy.settings import BaseSettings\n-from scrapy.utils.conf import config_from_filepath\n \n from . import addons\n from . import addonmod\n@@ -107,7 +106,6 @@ class AddonTest(unittest.TestCase):\n \n class AddonManagerTest(unittest.TestCase):\n \n-    TESTCFGPATH = os.path.join(os.path.dirname(__file__), 'cfg.cfg')\n     ADDONMODPATH = os.path.join(os.path.dirname(__file__), 'addonmod.py')\n \n     def setUp(self):\n@@ -262,24 +260,6 @@ class AddonManagerTest(unittest.TestCase):\n             })\n             _test_load_method(expected_order, 'load_settings', settings)\n \n-    def test_load_cfg(self):\n-        def _check_loaded_addons(manager):\n-            six.assertCountEqual(self, manager, ['GoodAddon', 'AddonModule'])\n-            self.assertIsInstance(manager['GoodAddon'], addons.GoodAddon)\n-            six.assertCountEqual(self, manager.configs['GoodAddon'], ['key'])\n-            self.assertEqual(manager.configs['GoodAddon']['key'], 'val1')\n-            # XXX: Check module equality, see above\n-            self.assertEqual(manager['AddonModule'].name, addonmod.name)\n-            six.assertCountEqual(self, manager.configs['AddonModule'], ['key'])\n-            self.assertEqual(manager.configs['AddonModule']['key'], 'val2')\n-        manager = AddonManager()\n-        manager.load_cfg(self.TESTCFGPATH)\n-        _check_loaded_addons(manager)\n-        manager = AddonManager()\n-        preloaded_cfg = config_from_filepath(self.TESTCFGPATH)\n-        manager.load_cfg(preloaded_cfg)\n-        _check_loaded_addons(manager)\n-\n     def test_enabled_disabled(self):\n         manager = AddonManager()\n         manager.add(addons.GoodAddon('FirstAddon'))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#8e5d067af1e50a32f8930294199798535357edf2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 84 | Files Changed: 10 | Hunks: 13 | Methods Changed: 2 | Complexity Δ (Sum/Max): -3/0 | Churn Δ: 87 | Churn Cumulative: 1126 | Contributors (this commit): 1 | Commits (past 90d): 28 | Contributors (cumulative): 10 | DMM Complexity: 0.8461538461538461\n\nDIFF:\n@@ -7,11 +7,9 @@ from pkg_resources import WorkingSet, Distribution, Requirement\n import zope.interface\n from zope.interface.verify import verifyObject\n \n-from scrapy.exceptions import NotConfigured\n from scrapy.interfaces import IAddon\n from scrapy.utils.conf import build_component_list\n from scrapy.utils.misc import load_module_or_object\n-from scrapy.utils.project import get_project_path\n \n \n @zope.interface.implementer(IAddon)\n@@ -244,14 +242,8 @@ class AddonManager(Mapping):\n         \"\"\"Get an add-on object by its Python or file path.\n \n         ``path`` is assumed to be either a Python or a file path of a Scrapy\n-        add-on. If no object is found at ``path``, it is tried again first with\n-        ``projectname.addons`` prepended (pointing to the current project's\n-        ``addons`` folder), then with ``scrapy.addons`` prepended (poiting to\n-        Scrapy's built-in add-ons). These convenience shortcuts will only work\n-        with Python paths, not file paths.\n-\n-        If the object or module pointed to by ``path`` has an attribute named\n-        ``_addon`` that attribute will be assumed to be the add-on.\n+        add-on. If the object or module pointed to by ``path`` has an attribute\n+        named ``_addon`` that attribute will be assumed to be the add-on.\n         :meth:`get_addon` will keep following ``_addon`` attributes until it\n         finds an object that does not have an attribute named ``_addon``.\n \n@@ -259,20 +251,9 @@ class AddonManager(Mapping):\n         :type path: ``str``\n         \"\"\"\n         if isinstance(path, six.string_types):\n-            prefixes = ['', 'scrapy.addons.']\n             try:\n-                prefixes.insert(1, get_project_path() + '.addons.')\n-            except NotConfigured:\n-                warnings.warn(\"Unable to locate project Python path\")\n-            for prefix in prefixes:\n-                fullpath = prefix + path\n-                try:\n-                    obj = load_module_or_object(fullpath)\n+                obj = load_module_or_object(path)\n             except NameError:\n-                    pass\n-                else:\n-                    break\n-            else:\n                 raise NameError(\"Could not find add-on '%s'\" % path)\n         else:\n             obj = path\n\n@@ -11,7 +11,6 @@ import zope.interface\n from zope.interface.verify import verifyObject\n from zope.interface.exceptions import BrokenImplementation\n \n-import scrapy.addons\n from scrapy.addons import Addon, AddonManager\n from scrapy.crawler import Crawler\n from scrapy.interfaces import IAddon\n@@ -187,32 +186,6 @@ class AddonManagerTest(unittest.TestCase):\n         x._addon._addon = addons.GoodAddon('inner')\n         self.assertIs(self.manager.get_addon(x), x._addon._addon)\n \n-    @mock.patch.object(scrapy.addons, 'get_project_path',\n-                       return_value='tests.test_addons.project')\n-    def test_get_addon_prefixes(self, get_project_path_mock):\n-        # From python path\n-        self.assertEqual(self.manager.get_addon('addonmod').FROM,\n-                         'test_addons.addonmod')\n-\n-        # From project 'addons' folder\n-        self.assertEqual(self.manager.get_addon('addonmod2').FROM,\n-                         'test_addons.project.addons.addonmod2')\n-        # Assert prefix priority '' > 'project.addons'\n-        self.assertEqual(self.manager.get_addon('addonmod').FROM,\n-                         'test_addons.addonmod')\n-\n-        # From scrapy's 'addons'\n-        from . import scrapy_addons\n-        with mock.patch.dict('sys.modules', {'scrapy.addons': scrapy_addons}):\n-            self.assertEqual(self.manager.get_addon('addonmod3').FROM,\n-                             'test_addons.scrapy_addons.addonmod3')\n-            # Assert prefix priority 'project.addons' > 'scrapy.addons'\n-            self.assertEqual(self.manager.get_addon('addonmod2').FROM,\n-                             'test_addons.project.addons.addonmod2')\n-            # Assert prefix priority '' > 'scrapy.addons.'\n-            self.assertEqual(self.manager.get_addon('addonmod').FROM,\n-                             'test_addons.addonmod')\n-\n     def test_load_dict_load_settings(self):\n         def _test_load_method(func, *args, **kwargs):\n             manager = AddonManager()\n\n\n\n@@ -1,7 +0,0 @@\n-import zope.interface\n-\n-from scrapy.interfaces import IAddon\n-\n-zope.interface.moduleProvides(IAddon)\n-\n-FROM = 'test_addons.project.addons.addonmod'\n\n@@ -1,7 +0,0 @@\n-import zope.interface\n-\n-from scrapy.interfaces import IAddon\n-\n-zope.interface.moduleProvides(IAddon)\n-\n-FROM = 'test_addons.project.addons.addonmod2'\n\n\n@@ -1,7 +0,0 @@\n-import zope.interface\n-\n-from scrapy.interfaces import IAddon\n-\n-zope.interface.moduleProvides(IAddon)\n-\n-FROM = 'test_addons.scrapy_addons.addonmod'\n\n@@ -1,7 +0,0 @@\n-import zope.interface\n-\n-from scrapy.interfaces import IAddon\n-\n-zope.interface.moduleProvides(IAddon)\n-\n-FROM = 'test_addons.scrapy_addons.addonmod2'\n\n@@ -1,7 +0,0 @@\n-import zope.interface\n-\n-from scrapy.interfaces import IAddon\n-\n-zope.interface.moduleProvides(IAddon)\n-\n-FROM = 'test_addons.scrapy_addons.addonmod3'\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#388c5c4b78509adaf801fb8f66d2d1fdbe1ce9d4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 1062 | Contributors (this commit): 1 | Commits (past 90d): 14 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -84,7 +84,7 @@ class Addon(object):\n                 # e.g. for DOWNLOADER_MIDDLEWARES: {'myclass': 100}\n                 k = comp\n                 v = config.get('order', self.component_order)\n-            settings.set(self.component_type, {k: v}, 'addon')\n+            settings[self.component_type].update({k: v}, 'addon')\n \n     def export_basics(self, settings):\n         \"\"\"Export the :attr:`basic_settings` attribute into the settings object.\n\n@@ -38,7 +38,9 @@ class AddonTest(unittest.TestCase):\n         verifyObject(IAddon, self.testaddon)\n \n     def test_export_component(self):\n-        settings = BaseSettings({'ITEM_PIPELINES': {}}, 'default')\n+        settings = BaseSettings({'ITEM_PIPELINES': BaseSettings(),\n+                                 'DOWNLOAD_HANDLERS': BaseSettings()},\n+                                'default')\n         self.testaddon.component_type = None\n         self.testaddon.export_component({}, settings)\n         self.assertEqual(len(settings['ITEM_PIPELINES']), 0)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#e924d382380a6bc7285b8a9713ac14588681af3b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 36 | Lines Deleted: 227 | Files Changed: 2 | Hunks: 37 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 263 | Churn Cumulative: 598 | Contributors (this commit): 1 | Commits (past 90d): 4 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -16,14 +16,11 @@ __all__ = ['make_builtin_addon',\n            ]\n \n \n-def make_builtin_addon(addon_name, comp_type, comp, order=0,\n-                       addon_default_config=None, addon_version=None):\n+def make_builtin_addon(addon_name, addon_default_config=None,\n+                       addon_version=None):\n     class ThisAddon(Addon):\n         name = addon_name\n         version = addon_version or scrapy.__version__\n-        component_type = comp_type\n-        component = comp\n-        component_order = order\n         default_config = addon_default_config or {}\n \n     return ThisAddon\n@@ -36,73 +33,26 @@ def make_builtin_addon(addon_name, comp_type, comp, order=0,\n \n # SPIDER MIDDLEWARES\n \n-depth = make_builtin_addon(\n-    'depth',\n-    'SPIDER_MIDDLEWARES',\n-    'scrapy.spidermiddlewares.depth.DepthMiddleware',\n-    900,\n-)\n+depth = make_builtin_addon('depth')\n \n-httperror = make_builtin_addon(\n-    'httperror',\n-    'SPIDER_MIDDLEWARES',\n-    'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n-    50,\n-)\n+httperror = make_builtin_addon('httperror')\n \n-offsite = make_builtin_addon(\n-    'offsite',\n-    'SPIDER_MIDDLEWARES',\n-    'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n-    500,\n-)\n+offsite = make_builtin_addon('offsite')\n \n-referer = make_builtin_addon(\n-    'referer',\n-    'SPIDER_MIDDLEWARES',\n-    'scrapy.spidermiddlewares.referer.RefererMiddleware',\n-    700,\n-    {'enabled': True},\n-)\n+referer = make_builtin_addon('referer')\n \n-urllength = make_builtin_addon(\n-    'urllength',\n-    'SPIDER_MIDDLEWARES',\n-    'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n-    800,\n-)\n+urllength = make_builtin_addon('urllength')\n \n \n # DOWNLOADER MIDDLEWARES\n \n-ajaxcrawl = make_builtin_addon(\n-    'ajaxcrawl',\n-    'DOWNLOADER_MIDDLEWARES',\n-    'scrapy.downloadermiddlewares.ajaxcrawl.AjaxCrawlMiddleware',\n-    560,\n-)\n+ajaxcrawl = make_builtin_addon('ajaxcrawl', {'enabled': True})\n \n-chunked = make_builtin_addon(\n-    'chunked',\n-    'DOWNLOADER_MIDDLEWARES',\n-    'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',\n-    830,\n-)\n+chunked = make_builtin_addon('chunked')\n \n-cookies = make_builtin_addon(\n-    'cookies',\n-    'DOWNLOADER_MIDDLEWARES',\n-    'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n-    700,\n-    {'enabled': True},\n-)\n+cookies = make_builtin_addon('cookies')\n \n-defaultheaders = make_builtin_addon(\n-    'defaultheaders',\n-    'DOWNLOADER_MIDDLEWARES',\n-    'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n-    550,\n-)\n+defaultheaders = make_builtin_addon('defaultheaders')\n # Assume every config entry is a header\n def defaultheaders_export_config(self, config, settings):\n     conf = self.default_config or {}\n@@ -110,92 +60,31 @@ def defaultheaders_export_config(self, config, settings):\n     settings.set('DEFAULT_REQUEST_HEADERS', conf, 'addon')\n defaultheaders.export_config = defaultheaders_export_config\n \n-downloadtimeout = make_builtin_addon(\n-    'downloadtimeout',\n-    'DOWNLOADER_MIDDLEWARES',\n-    'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n-    350,\n-)\n+downloadtimeout = make_builtin_addon('downloadtimeout')\n downloadtimeout.config_mapping = {'timeout': 'DOWNLOAD_TIMEOUT',\n                                   'download_timeout': 'DOWNLOAD_TIMEOUT'}\n \n-httpauth = make_builtin_addon(\n-    'httpauth',\n-    'DOWNLOADER_MIDDLEWARES',\n-    'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n-    300,\n-)\n+httpauth = make_builtin_addon('httpauth')\n \n-httpcache = make_builtin_addon(\n-    'httpcache',\n-    'DOWNLOADER_MIDDLEWARES',\n-    'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware',\n-    900,\n-    {'enabled': True},\n-)\n+httpcache = make_builtin_addon('httpcache', {'enabled': True})\n \n-httpcompression = make_builtin_addon(\n-    'httpcompression',\n-    'DOWNLOADER_MIDDLEWARES',\n-    'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n-    590,\n-    {'enabled': True},\n-)\n+httpcompression = make_builtin_addon('httpcompression')\n httpcompression.config_mapping = {'enabled': 'COMPRESSION_ENABLED'}\n \n-httpproxy = make_builtin_addon(\n-    'httpproxy',\n-    'DOWNLOADER_MIDDLEWARES',\n-    'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n-    750,\n-)\n+httpproxy = make_builtin_addon('httpproxy')\n \n-metarefresh = make_builtin_addon(\n-    'metarefresh',\n-    'DOWNLOADER_MIDDLEWARES',\n-    'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n-    580,\n-    {'enabled': True},\n-)\n+metarefresh = make_builtin_addon('metarefresh')\n metarefresh.config_mapping = {'max_times': 'REDIRECT_MAX_TIMES'}\n \n-redirect = make_builtin_addon(\n-    'redirect',\n-    'DOWNLOADER_MIDDLEWARES',\n-    'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n-    600,\n-    {'enabled': True},\n-)\n+redirect = make_builtin_addon('redirect')\n \n-retry = make_builtin_addon(\n-    'retry',\n-    'DOWNLOADER_MIDDLEWARES',\n-    'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n-    500,\n-    {'enabled': True},\n-)\n+retry = make_builtin_addon('retry')\n \n-robotstxt = make_builtin_addon(\n-    'robotstxt',\n-    'DOWNLOADER_MIDDLEWARES',\n-    'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n-    100,\n-    {'obey': True},\n-)\n+robotstxt = make_builtin_addon('robotstxt', {'obey': True})\n \n-stats = make_builtin_addon(\n-    'stats',\n-    'DOWNLOADER_MIDDLEWARES',\n-    'scrapy.downloadermiddlewares.stats.DownloaderStats',\n-    850,\n-)\n+stats = make_builtin_addon('stats')\n \n-useragent = make_builtin_addon(\n-    'useragent',\n-    'DOWNLOADER_MIDDLEWARES',\n-    'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n-    400,\n-)\n+useragent = make_builtin_addon('useragent')\n useragent.config_mapping = {'user_agent': 'USER_AGENT'}\n \n \n@@ -204,90 +93,27 @@ useragent.config_mapping = {'user_agent': 'USER_AGENT'}\n \n # EXTENSIONS\n \n-autothrottle = make_builtin_addon(\n-    'throttle',\n-    'EXTENSIONS',\n-    'scrapy.extensions.throttle.AutoThrottle',\n-    0,\n-    {'enabled': True},\n-)\n+autothrottle = make_builtin_addon('autothrottle', {'enabled': True})\n \n-corestats = make_builtin_addon(\n-    'corestats',\n-    'EXTENSIONS'\n-    'scrapy.extensions.corestats.CoreStats',\n-    0,\n-)\n+corestats = make_builtin_addon('corestats')\n \n-closespider = make_builtin_addon(\n-    'closespider',\n-    'EXTENSIONS'\n-    'scrapy.extensions.closespider.CloseSpider',\n-    0,\n-)\n+closespider = make_builtin_addon('closespider')\n \n-debugger = make_builtin_addon(\n-    'debugger',\n-    'EXTENSIONS'\n-    'scrapy.extensions.debug.Debugger',\n-    0,\n-)\n+debugger = make_builtin_addon('debugger')\n \n-feedexport = make_builtin_addon(\n-    'feedexport',\n-    'EXTENSIONS'\n-    'scrapy.extensions.feedexport.FeedExporter',\n-    0,\n-)\n+feedexport = make_builtin_addon('feedexport')\n feedexport.settings_prefix = 'FEED'\n \n-logstats = make_builtin_addon(\n-    'logstats',\n-    'EXTENSIONS'\n-    'scrapy.extensions.logstats.LogStats',\n-    0,\n-)\n+logstats = make_builtin_addon('logstats')\n \n-memdebug = make_builtin_addon(\n-    'memdebug',\n-    'EXTENSIONS'\n-    'scrapy.extensions.memdebug.MemoryDebugger',\n-    0,\n-    {'enabled': True},\n-)\n+memdebug = make_builtin_addon('memdebug', {'enabled': True})\n \n-memusage = make_builtin_addon(\n-    'memusage',\n-    'EXTENSIONS'\n-    'scrapy.extensions.memusage.MemoryUsage',\n-    0,\n-    {'enabled': True},\n-)\n+memusage = make_builtin_addon('memusage', {'enabled': True})\n \n-spiderstate = make_builtin_addon(\n-    'spiderstate',\n-    'EXTENSIONS'\n-    'scrapy.extensions.spiderstate.SpiderState',\n-    0,\n-)\n+spiderstate = make_builtin_addon('spiderstate')\n \n-stacktracedump = make_builtin_addon(\n-    'stacktracedump',\n-    'EXTENSIONS'\n-    'scrapy.extensions.debug.StackTraceDump',\n-    0,\n-)\n+stacktracedump = make_builtin_addon('stacktracedump')\n \n-statsmailer = make_builtin_addon(\n-    'statsmailer',\n-    'EXTENSIONS'\n-    'scrapy.extensions.statsmailer.StatsMailer',\n-    0,\n-)\n+statsmailer = make_builtin_addon('statsmailer')\n \n-telnetconsole = make_builtin_addon(\n-    'telnetconsole',\n-    'EXTENSIONS'\n-    'scrapy.telnet.TelnetConsole',\n-    0,\n-)\n+telnetconsole = make_builtin_addon('telnetconsole')\n\n@@ -9,28 +9,11 @@ from scrapy.settings import Settings\n class BuiltinAddonsTest(unittest.TestCase):\n \n     def test_make_builtin_addon(self):\n-        httpcache = make_builtin_addon(\n-            'httpcache',\n-            'DOWNLOADER_MIDDLEWARES',\n-            'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware',\n-            900,\n-            {'enabled': True},\n-        )\n+        httpcache = make_builtin_addon('httpcache', {'enabled': True})\n         self.assertEqual(httpcache.name, 'httpcache')\n-        self.assertEqual(httpcache.component_type, 'DOWNLOADER_MIDDLEWARES')\n-        self.assertEqual(httpcache.component, 'scrapy.downloadermiddlewares.'\n-                                              'httpcache.HttpCacheMiddleware')\n-        self.assertEqual(httpcache.component_order, 900)\n         self.assertEqual(httpcache.default_config, {'enabled': True})\n         self.assertEqual(httpcache.version, scrapy.__version__)\n-        httpcache = make_builtin_addon(\n-            'httpcache',\n-            'DOWNLOADER_MIDDLEWARES',\n-            'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware',\n-            900,\n-            {'enabled': True},\n-            '99.9',\n-        )\n+        httpcache = make_builtin_addon('httpcache', {'enabled': True}, '99.9')\n         self.assertEqual(httpcache.version, '99.9')\n \n     def test_defaultheaders_export_config(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#b7b00fb95669196167a5e5f76b1f3b8e2feb7b84", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 8 | Methods Changed: 7 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 14 | Churn Cumulative: 1076 | Contributors (this commit): 1 | Commits (past 90d): 16 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -323,6 +323,7 @@ class AddonManager(Mapping):\n         \"\"\"\n         # Collect all active add-ons and the components they provide\n         ws = WorkingSet('')\n+\n         def add_dist(project_name, version, **kwargs):\n             if project_name in ws.entry_keys.get('scrapy', []):\n                 raise ImportError(\"Component {} provided by multiple add-ons\"\n@@ -355,7 +356,8 @@ class AddonManager(Mapping):\n             if ws.find(req) is None:\n                 raise ImportError(\n                     \"Add-ons {} require or modify missing component {}\"\n-                          \"\".format(required[reqstr]+modified[reqstr], reqstr))\n+                    \"\".format(required[reqstr]+modified[reqstr], reqstr)\n+                )\n \n         mod_and_req = set(required.keys()).intersection(modified.keys())\n         for conflict in mod_and_req:\n\n@@ -24,6 +24,7 @@ class AddonTest(unittest.TestCase):\n \n     def setUp(self):\n         self.rawaddon = Addon()\n+\n         class AddonWithAttributes(Addon):\n             name = 'Test'\n             version = '1.0'\n@@ -145,11 +146,13 @@ class AddonManagerTest(unittest.TestCase):\n \n     def test_remove(self):\n         manager = AddonManager()\n+\n         def test_gets_removed(removearg):\n             manager.add(addonmod)\n             self.assertIn('AddonModule', manager)\n             manager.remove(removearg)\n             self.assertNotIn('AddonModule', manager)\n+\n         test_gets_removed('AddonModule')\n         test_gets_removed(addonmod)\n         test_gets_removed('tests.test_addons.addonmod')\n@@ -158,8 +161,7 @@ class AddonManagerTest(unittest.TestCase):\n         self.assertRaises(KeyError, manager.remove, addons.GoodAddon())\n \n     def test_get_addon(self):\n-        goodaddon = self.manager.get_addon(\n-                                      'tests.test_addons.addons.GoodAddon')\n+        goodaddon = self.manager.get_addon('tests.test_addons.addons.GoodAddon')\n         self.assertIs(goodaddon, addons.GoodAddon)\n \n         loaded_addonmod = self.manager.get_addon(self.ADDONMODPATH)\n@@ -194,8 +196,7 @@ class AddonManagerTest(unittest.TestCase):\n             getattr(manager, func)(*args, **kwargs)\n             six.assertCountEqual(self, manager, ['GoodAddon', 'AddonModule'])\n             self.assertIsInstance(manager['GoodAddon'], addons.GoodAddon)\n-            six.assertCountEqual(self, manager.configs['GoodAddon'],\n-                                       ['key'])\n+            six.assertCountEqual(self, manager.configs['GoodAddon'], ['key'])\n             self.assertEqual(manager.configs['GoodAddon']['key'], 'val2')\n             # XXX: Check module equality, see above\n             self.assertEqual(manager['AddonModule'].name, addonmod.name)\n@@ -321,6 +322,7 @@ class AddonManagerTest(unittest.TestCase):\n \n         class FirstAddon(addons.GoodAddon):\n             name = 'FirstAddon'\n+\n             def update_addons(self, config, addons):\n                 addons.add(AddedAddon())\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#33dfb3e167f7d31e2573ab39c2b80bf7728c2b00", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 39 | Files Changed: 2 | Hunks: 2 | Methods Changed: 3 | Complexity Δ (Sum/Max): -5/0 | Churn Δ: 39 | Churn Cumulative: 269 | Contributors (this commit): 7 | Commits (past 90d): 4 | Contributors (cumulative): 8 | DMM Complexity: 0.0\n\nDIFF:\n@@ -71,15 +71,3 @@ def get_project_settings():\n         settings.setdict(env_overrides, priority='project')\n \n     return settings\n-\n-def get_project_path():\n-    \"\"\"Return the Python path of the current project.\n-\n-    This fails when the settings module does not live in the project's root.\n-    \"\"\"\n-    if not inside_project():\n-        raise NotConfigured(\"Not inside a project\")\n-    settings_module_path = os.environ.get(ENVVAR)\n-    if not settings_module_path:\n-        raise NotConfigured(\"Unable to locate project's python path\")\n-    return settings_module_path.rsplit('.', 1)[0]\n\n@@ -1,27 +0,0 @@\n-import os\n-from tests import mock\n-import unittest\n-\n-from scrapy.exceptions import NotConfigured\n-from scrapy.utils.project import get_project_path, inside_project\n-\n-\n-class UtilsProjectTestCase(unittest.TestCase):\n-\n-    @mock.patch('scrapy.utils.project.inside_project', return_value=True)\n-    def test_get_project_path(self, mock_ip):\n-        def _test(settingsmod, expected):\n-            with mock.patch.dict('os.environ',\n-                                 {'SCRAPY_SETTINGS_MODULE': settingsmod}):\n-                self.assertEqual(get_project_path(), expected)\n-        _test('project.settings', 'project')\n-        _test('project.othername', 'project')\n-        _test('nested.project.settings', 'nested.project')\n-\n-        with mock.patch.dict('os.environ', {}, clear=True):\n-            self.assertRaises(NotConfigured, get_project_path)\n-\n-        mock_ip.return_value = False\n-        with mock.patch.dict('os.environ',\n-                             {'SCRAPY_SETTINGS_MODULE': 'some.settings'}):\n-            self.assertRaises(NotConfigured, get_project_path)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#a65fc0db7d7d728bc8abbb37eff358870ce7a9b5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 63 | Files Changed: 5 | Hunks: 17 | Methods Changed: 8 | Complexity Δ (Sum/Max): -4/0 | Churn Δ: 71 | Churn Cumulative: 988 | Contributors (this commit): 14 | Commits (past 90d): 17 | Contributors (cumulative): 19 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1,8 +1,5 @@\n \"\"\"Helper functions which doesn't fit anywhere else\"\"\"\n-import itertools\n-import os.path\n import re\n-import sys\n import hashlib\n from importlib import import_module\n from pkgutil import iter_modules\n@@ -72,10 +69,6 @@ def load_module_or_object(path):\n         return load_object(path)\n     except (ValueError, NameError, ImportError):\n         pass\n-    try:\n-        return get_module_from_filepath(path)\n-    except ImportError:\n-        pass\n     raise NameError(\"Could not load '%s'\" % path)\n \n \n@@ -101,23 +94,6 @@ def walk_modules(path):\n     return mods\n \n \n-def get_module_from_filepath(path):\n-    \"\"\"Load and return a python module/package from a file path\"\"\"\n-    path = path.rstrip(\"/\")\n-    if path.endswith('.py'):\n-        path = path.rsplit('.py', 1)[0]\n-    basefolder, modname = os.path.split(path)\n-    # XXX: There are other ways to import modules from a full path which don't\n-    #      need to modify PYTHONPATH, see\n-    #          https://stackoverflow.com/questions/67631/\n-    #      These methods differ between py2 and py3, and apparently the\n-    #      py3 method was deprecated in Python 3.4\n-    sys.path.insert(0, basefolder)\n-    mod = import_module(modname)\n-    sys.path.pop(0)\n-    return mod\n-\n-\n def extract_regex(regex, text, encoding='utf-8'):\n     \"\"\"Extract a list of unicode strings from the given text/encoding using the following policies:\n \n\n@@ -108,8 +108,6 @@ class AddonTest(unittest.TestCase):\n \n class AddonManagerTest(unittest.TestCase):\n \n-    ADDONMODPATH = os.path.join(os.path.dirname(__file__), 'addonmod.py')\n-\n     def setUp(self):\n         self.manager = AddonManager()\n \n@@ -156,7 +154,6 @@ class AddonManagerTest(unittest.TestCase):\n         test_gets_removed('AddonModule')\n         test_gets_removed(addonmod)\n         test_gets_removed('tests.test_addons.addonmod')\n-        test_gets_removed(self.ADDONMODPATH)\n         self.assertRaises(KeyError, manager.remove, 'nonexistent')\n         self.assertRaises(KeyError, manager.remove, addons.GoodAddon())\n \n@@ -164,18 +161,12 @@ class AddonManagerTest(unittest.TestCase):\n         goodaddon = self.manager.get_addon('tests.test_addons.addons.GoodAddon')\n         self.assertIs(goodaddon, addons.GoodAddon)\n \n-        loaded_addonmod = self.manager.get_addon(self.ADDONMODPATH)\n-        # XXX: The module is in fact imported twice under different names into\n-        #      sys.modules, is there a good assertion for module equality?\n-        self.assertEqual(loaded_addonmod.name, addonmod.name)\n+        loaded_addonmod = self.manager.get_addon(\"tests.test_addons.addonmod\")\n+        self.assertIs(loaded_addonmod, addonmod)\n \n-        # Does not provide interface, but has _addon attribute pointing to\n-        # GoodAddon instance\n         addonspath = os.path.join(os.path.dirname(__file__), 'addons.py')\n-        goodaddon = self.manager.get_addon(addonspath)\n-        # XXX: Again, the imported class and addons.GoodAddon are different\n-        #      since they are imported twice. How to use isInstance?\n-        self.assertEqual(goodaddon.name, addons.GoodAddon.name)\n+        goodaddon = self.manager.get_addon(\"tests.test_addons.addons\")\n+        self.assertIsInstance(goodaddon, addons.GoodAddon)\n \n         self.assertRaises(NameError, self.manager.get_addon, 'xy.n_onexistent')\n \n@@ -198,21 +189,18 @@ class AddonManagerTest(unittest.TestCase):\n             self.assertIsInstance(manager['GoodAddon'], addons.GoodAddon)\n             six.assertCountEqual(self, manager.configs['GoodAddon'], ['key'])\n             self.assertEqual(manager.configs['GoodAddon']['key'], 'val2')\n-            # XXX: Check module equality, see above\n-            self.assertEqual(manager['AddonModule'].name, addonmod.name)\n+            self.assertEqual(manager['AddonModule'], addonmod)\n             self.assertIn('key', manager.configs['AddonModule'])\n             self.assertEqual(manager.configs['AddonModule']['key'], 'val1')\n \n         addonsdict = {\n-            self.ADDONMODPATH: {\n-                'key': 'val1',\n-                },\n+            \"tests.test_addons.addonmod\": {'key': 'val1'},\n             'tests.test_addons.addons.GoodAddon': {'key': 'val2'},\n             }\n         _test_load_method('load_dict', addonsdict)\n \n         settings = BaseSettings()\n-        settings.set('ADDONS', {self.ADDONMODPATH: 0,\n+        settings.set('ADDONS', {\"tests.test_addons.addonmod\": 0,\n                                 'tests.test_addons.addons.GoodAddon': 0})\n         settings.set('ADDONMODULE', {'key': 'val1'})\n         settings.set('GOODADDON', {'key': 'val2'})\n\n@@ -4,7 +4,7 @@ import unittest\n \n from scrapy.item import Item, Field\n from scrapy.utils.misc import (load_object, load_module_or_object, arg_to_iter,\n-                               walk_modules, get_module_from_filepath)\n+                               walk_modules)\n \n __doctests__ = ['scrapy.utils.misc']\n \n@@ -21,9 +21,6 @@ class UtilsMiscTestCase(unittest.TestCase):\n     def test_load_module_or_object(self):\n         testmod = load_module_or_object(__name__ + '.testmod')\n         self.assertTrue(hasattr(testmod, 'TESTVAR'))\n-        testmod = load_module_or_object(\n-                    os.path.join(os.path.dirname(__file__), 'testmod.py'))\n-        self.assertTrue(hasattr(testmod, 'TESTVAR'))\n         obj = load_object('scrapy.utils.misc.load_object')\n         self.assertIs(obj, load_object)\n \n@@ -67,20 +64,6 @@ class UtilsMiscTestCase(unittest.TestCase):\n         finally:\n             sys.path.remove(egg)\n \n-    def test_get_module_from_filepath(self):\n-        testmodpath = os.path.join(os.path.dirname(__file__), 'testmod.py')\n-        testmod = get_module_from_filepath(testmodpath)\n-        self.assertTrue(hasattr(testmod, 'TESTVAR'))\n-\n-        testpkgpath = os.path.join(os.path.dirname(__file__), 'testpkg')\n-        testpkg = get_module_from_filepath(testpkgpath)\n-        self.assertTrue(hasattr(testpkg, 'TESTVAR2'))\n-        # Check submodule access\n-        import testpkg.submod\n-        self.assertTrue(hasattr(testpkg.submod, 'TESTVAR3'))\n-        self.assertIs(testpkg.submod.TESTVAR3,\n-                      load_object(testpkg.__name__ + \".submod.TESTVAR3\"))\n-\n     def test_arg_to_iter(self):\n \n         class TestItem(Item):\n\n@@ -1 +0,0 @@\n-TESTVAR2 = True\n\n@@ -1 +0,0 @@\n-TESTVAR3 = True\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#881bf19e6804c3b82543f4f23d6ed60e1a4bb651", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 13 | Churn Cumulative: 269 | Contributors (this commit): 6 | Commits (past 90d): 2 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -305,6 +305,19 @@ class FormRequestTest(RequestTest):\n         request = FormRequest.from_response(response, url='/relative')\n         self.assertEqual(request.url, 'http://example.com/relative')\n \n+    def test_from_response_case_insensitive(self):\n+        response = _buildresponse(\n+            \"\"\"<form action=\"get.php\" method=\"GET\">\n+            <input type=\"SuBmIt\" name=\"clickable1\" value=\"clicked1\">\n+            <input type=\"iMaGe\" name=\"i1\" src=\"http://my.image.org/1.jpg\">\n+            <input type=\"submit\" name=\"clickable2\" value=\"clicked2\">\n+            </form>\"\"\")\n+        req = self.request_class.from_response(response)\n+        fs = _qs(req)\n+        self.assertEqual(fs['clickable1'], ['clicked1'])\n+        self.assertFalse('i1' in fs, fs)  # xpath in _get_inputs()\n+        self.assertFalse('clickable2' in fs, fs)  # xpath in _get_clickable()\n+\n     def test_from_response_submit_first_clickable(self):\n         response = _buildresponse(\n             \"\"\"<form action=\"get.php\" method=\"GET\">\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#650acad2b73c1abafe8ff95808b4d77b65ef67cb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 15 | Churn Cumulative: 739 | Contributors (this commit): 18 | Commits (past 90d): 2 | Contributors (cumulative): 18 | DMM Complexity: 0.0\n\nDIFF:\n@@ -107,8 +107,13 @@ def _get_inputs(form, formdata, dont_click, clickdata, response):\n \n     inputs = form.xpath('descendant::textarea'\n                         '|descendant::select'\n-                        '|descendant::input[@type!=\"submit\" and @type!=\"image\" and @type!=\"reset\"'\n-                        'and ((@type!=\"checkbox\" and @type!=\"radio\") or @checked)]')\n+                        '|descendant::input[@type['\n+                        ' translate(., \"SUBMIT\", \"submit\") != \"submit\"'\n+                        ' and translate(., \"IMAGE\", \"image\") !=\"image\"'\n+                        ' and translate(., \"RESET\", \"reset\") != \"reset\"'\n+                        ' and (../@checked or ('\n+                        '  translate(., \"CHECKBOX\", \"checkbox\") != \"checkbox\"'\n+                        '  and translate(., \"RADIO\", \"radio\") != \"radio\"))]]')\n     values = [(k, u'' if v is None else v)\n               for k, v in (_value(e) for e in inputs)\n               if k and k not in formdata]\n@@ -151,8 +156,10 @@ def _get_clickable(clickdata, form):\n     if the latter is given. If not, it returns the first\n     clickable element found\n     \"\"\"\n-    clickables = [el for el in form.xpath('descendant::input[@type=\"submit\"]'\n-                                          '|descendant::button[@type=\"submit\"]'\n+    clickables = [\n+        el for el in form.xpath(\n+            'descendant::*[(self::input or self::button)'\n+            ' and translate(@type, \"SUBMIT\", \"submit\") = \"submit\"]'\n             '|descendant::button[not(@type)]')]\n     if not clickables:\n         return\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
