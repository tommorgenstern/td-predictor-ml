{"custom_id": "keras#ddb3c3a296ac358a4c394722a478fed898048a7b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 129 | Lines Deleted: 91 | Files Changed: 2 | Hunks: 26 | Methods Changed: 15 | Complexity Δ (Sum/Max): 6/4 | Churn Δ: 220 | Churn Cumulative: 2088 | Contributors (this commit): 6 | Commits (past 90d): 14 | Contributors (cumulative): 10 | DMM Complexity: 0.5555555555555556\n\nDIFF:\n@@ -183,7 +183,7 @@ class ExportArchive:\n                     resource.non_trainable_variables\n                 )\n \n-    def add_endpoint(self, name, fn, input_signature=None):\n+    def add_endpoint(self, name, fn, input_signature=None, jax2tf_kwargs=None):\n         \"\"\"Register a new serving endpoint.\n \n         Arguments:\n@@ -203,6 +203,13 @@ class ExportArchive:\n                 per positional input argument of `fn`). Nested arguments are\n                 allowed (see below for an example showing a Functional model\n                 with 2 input arguments).\n+            jax2tf_kwargs: Dict for additional arguments to pass to `jax2tf`.\n+                Supported only when the backend is JAX. See documentation for\n+                [`jax2tf.convert`](\n+                    https://github.com/google/jax/blob/main/jax/experimental/jax2tf/README.md).\n+\n+        Returns:\n+            The `tf.function` wrapping `fn` that was added to the archive.\n \n         Example:\n \n@@ -293,6 +300,12 @@ class ExportArchive:\n         if name in self._endpoint_names:\n             raise ValueError(f\"Endpoint name '{name}' is already taken.\")\n \n+        if jax2tf_kwargs and backend.backend() != \"jax\":\n+            raise ValueError(\n+                \"'jax2tf_kwargs' is only supported with the jax backend. \"\n+                f\"Current backend: {backend.backend()}\"\n+            )\n+\n         if input_signature:\n             if backend.backend() == \"tensorflow\":\n                 decorated_fn = tf.function(fn, input_signature=input_signature)\n@@ -315,7 +328,9 @@ class ExportArchive:\n                 ]\n \n                 jax2tf_stateless_fn = self._convert_jax2tf_function(\n-                    stateless_fn, [variables_spec] + input_signature\n+                    stateless_fn,\n+                    [variables_spec] + input_signature,\n+                    jax2tf_kwargs=jax2tf_kwargs,\n                 )\n \n                 def stateful_fn(*args, **kwargs):\n@@ -373,6 +388,7 @@ class ExportArchive:\n                 )\n         setattr(self._tf_trackable, name, decorated_fn)\n         self._endpoint_names.append(name)\n+        return decorated_fn\n \n     def add_variable_collection(self, name, variables):\n         \"\"\"Register a set of variables to be retrieved after reloading.\n@@ -510,17 +526,24 @@ class ExportArchive:\n                     ):\n                         self._tf_trackable._misc_assets.append(trackable)\n \n-    def _convert_jax2tf_function(self, fn, input_signature):\n+    def _convert_jax2tf_function(self, fn, input_signature, jax2tf_kwargs=None):\n         from jax.experimental import jax2tf\n \n-        native_serialization = self._check_device_compatible()\n+        if jax2tf_kwargs is None:\n+            jax2tf_kwargs = {}\n+        if \"native_serialization\" not in jax2tf_kwargs:\n+            jax2tf_kwargs[\"native_serialization\"] = (\n+                self._check_device_compatible()\n+            )\n+\n         shapes = []\n         for spec in input_signature:\n             shapes.append(self._spec_to_poly_shape(spec))\n+\n         return jax2tf.convert(\n             fn,\n             polymorphic_shapes=shapes,\n-            native_serialization=native_serialization,\n+            **jax2tf_kwargs,\n         )\n \n     def _spec_to_poly_shape(self, spec):\n\n@@ -80,13 +80,8 @@ class ExportArchiveTest(testing.TestCase):\n         export_archive.track(model)\n         export_archive.add_endpoint(\n             \"call\",\n-            model.call,\n-            input_signature=[\n-                tf.TensorSpec(\n-                    shape=(None, 10),\n-                    dtype=tf.float32,\n-                )\n-            ],\n+            model.__call__,\n+            input_signature=[tf.TensorSpec(shape=(None, 10), dtype=tf.float32)],\n         )\n         export_archive.write_out(temp_filepath)\n         revived_model = tf.saved_model.load(temp_filepath)\n@@ -94,6 +89,83 @@ class ExportArchiveTest(testing.TestCase):\n             ref_output, revived_model.call(ref_input), atol=1e-6\n         )\n \n+    def test_low_level_model_export_with_alias(self):\n+        temp_filepath = os.path.join(self.get_temp_dir(), \"exported_model\")\n+\n+        model = get_model()\n+        ref_input = tf.random.normal((3, 10))\n+        ref_output = model(ref_input)\n+\n+        export_archive = export_lib.ExportArchive()\n+        export_archive.track(model)\n+        fn = export_archive.add_endpoint(\n+            \"call\",\n+            model.__call__,\n+            input_signature=[tf.TensorSpec(shape=(None, 10), dtype=tf.float32)],\n+        )\n+        export_archive.write_out(\n+            temp_filepath,\n+            tf.saved_model.SaveOptions(function_aliases={\"call_alias\": fn}),\n+        )\n+        revived_model = tf.saved_model.load(\n+            temp_filepath,\n+            options=tf.saved_model.LoadOptions(\n+                experimental_load_function_aliases=True\n+            ),\n+        )\n+        self.assertAllClose(\n+            ref_output,\n+            revived_model.function_aliases[\"call_alias\"](ref_input),\n+            atol=1e-6,\n+        )\n+\n+    @pytest.mark.skipif(\n+        backend.backend() != \"jax\",\n+        reason=\"This test is only for the JAX backend.\",\n+    )\n+    def test_low_level_model_export_with_jax2tf_kwargs(self):\n+        temp_filepath = os.path.join(self.get_temp_dir(), \"exported_model\")\n+\n+        model = get_model()\n+        ref_input = tf.random.normal((3, 10))\n+        ref_output = model(ref_input)\n+\n+        export_archive = export_lib.ExportArchive()\n+        export_archive.track(model)\n+        export_archive.add_endpoint(\n+            \"call\",\n+            model.__call__,\n+            input_signature=[tf.TensorSpec(shape=(None, 10), dtype=tf.float32)],\n+            jax2tf_kwargs={\n+                \"native_serialization\": True,\n+                \"native_serialization_platforms\": (\"cpu\", \"tpu\"),\n+            },\n+        )\n+        with self.assertRaisesRegex(\n+            ValueError, \"native_serialization_platforms.*bogus\"\n+        ):\n+            export_archive.add_endpoint(\n+                \"call2\",\n+                model.__call__,\n+                input_signature=[\n+                    tf.TensorSpec(shape=(None, 10), dtype=tf.float32)\n+                ],\n+                jax2tf_kwargs={\n+                    \"native_serialization\": True,\n+                    \"native_serialization_platforms\": (\"cpu\", \"bogus\"),\n+                },\n+            )\n+        export_archive.write_out(temp_filepath)\n+        revived_model = tf.saved_model.load(\n+            temp_filepath,\n+            options=tf.saved_model.LoadOptions(\n+                experimental_load_function_aliases=True\n+            ),\n+        )\n+        self.assertAllClose(\n+            ref_output, revived_model.call(ref_input), atol=1e-6\n+        )\n+\n     @pytest.mark.skipif(\n         backend.backend() != \"tensorflow\",\n         reason=\"This test is native to the TF backend.\",\n@@ -281,12 +353,7 @@ class ExportArchiveTest(testing.TestCase):\n         export_archive.add_endpoint(\n             \"call\",\n             layer.call,\n-            input_signature=[\n-                tf.TensorSpec(\n-                    shape=(None, 10),\n-                    dtype=tf.float32,\n-                )\n-            ],\n+            input_signature=[tf.TensorSpec(shape=(None, 10), dtype=tf.float32)],\n         )\n         export_archive.write_out(temp_filepath)\n         revived_layer = tf.saved_model.load(temp_filepath)\n@@ -309,17 +376,11 @@ class ExportArchiveTest(testing.TestCase):\n         export_archive.track(model)\n         export_archive.add_endpoint(\n             \"serve\",\n-            model.call,\n+            model.__call__,\n             input_signature=[\n                 [\n-                    tf.TensorSpec(\n-                        shape=(None, 2),\n-                        dtype=tf.float32,\n-                    ),\n-                    tf.TensorSpec(\n-                        shape=(None, 2),\n-                        dtype=tf.float32,\n-                    ),\n+                    tf.TensorSpec(shape=(None, 2), dtype=tf.float32),\n+                    tf.TensorSpec(shape=(None, 2), dtype=tf.float32),\n                 ]\n             ],\n         )\n@@ -349,17 +410,11 @@ class ExportArchiveTest(testing.TestCase):\n         export_archive.track(model)\n         export_archive.add_endpoint(\n             \"serve\",\n-            model.call,\n+            model.__call__,\n             input_signature=[\n                 {\n-                    \"x1\": tf.TensorSpec(\n-                        shape=(None, 2),\n-                        dtype=tf.float32,\n-                    ),\n-                    \"x2\": tf.TensorSpec(\n-                        shape=(None, 2),\n-                        dtype=tf.float32,\n-                    ),\n+                    \"x1\": tf.TensorSpec(shape=(None, 2), dtype=tf.float32),\n+                    \"x2\": tf.TensorSpec(shape=(None, 2), dtype=tf.float32),\n                 }\n             ],\n         )\n@@ -411,22 +466,12 @@ class ExportArchiveTest(testing.TestCase):\n         export_archive.add_endpoint(\n             \"call_1\",\n             layer_1.call,\n-            input_signature=[\n-                tf.TensorSpec(\n-                    shape=(None, 4),\n-                    dtype=tf.float32,\n-                ),\n-            ],\n+            input_signature=[tf.TensorSpec(shape=(None, 4), dtype=tf.float32)],\n         )\n         export_archive.add_endpoint(\n             \"call_2\",\n             layer_2.call,\n-            input_signature=[\n-                tf.TensorSpec(\n-                    shape=(None, 5),\n-                    dtype=tf.float32,\n-                ),\n-            ],\n+            input_signature=[tf.TensorSpec(shape=(None, 5), dtype=tf.float32)],\n         )\n         export_archive.write_out(temp_filepath)\n         revived_layer = tf.saved_model.load(temp_filepath)\n@@ -454,14 +499,8 @@ class ExportArchiveTest(testing.TestCase):\n             \"call\",\n             layer.call,\n             input_signature=[\n-                tf.TensorSpec(\n-                    shape=(None, 2, 2),\n-                    dtype=tf.float32,\n-                ),\n-                tf.TensorSpec(\n-                    shape=(None, 2, 2),\n-                    dtype=tf.float32,\n-                ),\n+                tf.TensorSpec(shape=(None, 2, 2), dtype=tf.float32),\n+                tf.TensorSpec(shape=(None, 2, 2), dtype=tf.float32),\n             ],\n         )\n         export_archive.write_out(temp_filepath)\n@@ -485,14 +524,8 @@ class ExportArchiveTest(testing.TestCase):\n             \"call\",\n             layer.call,\n             input_signature=[\n-                tf.TensorSpec(\n-                    shape=(None, 2, 2),\n-                    dtype=tf.float32,\n-                ),\n-                tf.TensorSpec(\n-                    shape=(None, 2, 2),\n-                    dtype=tf.float32,\n-                ),\n+                tf.TensorSpec(shape=(None, 2, 2), dtype=tf.float32),\n+                tf.TensorSpec(shape=(None, 2, 2), dtype=tf.float32),\n             ],\n         )\n         export_archive.write_out(temp_filepath)\n@@ -519,13 +552,8 @@ class ExportArchiveTest(testing.TestCase):\n         export_archive.track(model)\n         export_archive.add_endpoint(\n             \"call\",\n-            model.call,\n-            input_signature=[\n-                tf.TensorSpec(\n-                    shape=(None, 10),\n-                    dtype=tf.float32,\n-                )\n-            ],\n+            model.__call__,\n+            input_signature=[tf.TensorSpec(shape=(None, 10), dtype=tf.float32)],\n         )\n         export_archive.add_variable_collection(\n             \"my_vars\", model.layers[1].weights\n@@ -572,23 +600,15 @@ class ExportArchiveTest(testing.TestCase):\n         export_archive.track(model)\n         export_archive.add_endpoint(\n             \"call\",\n-            model.call,\n-            input_signature=[\n-                tf.TensorSpec(\n-                    shape=(None, 3),\n-                    dtype=tf.float32,\n-                )\n-            ],\n+            model.__call__,\n+            input_signature=[tf.TensorSpec(shape=(None, 3), dtype=tf.float32)],\n         )\n         with self.assertRaisesRegex(ValueError, \"already taken\"):\n             export_archive.add_endpoint(\n                 \"call\",\n-                model.call,\n+                model.__call__,\n                 input_signature=[\n-                    tf.TensorSpec(\n-                        shape=(None, 3),\n-                        dtype=tf.float32,\n-                    )\n+                    tf.TensorSpec(shape=(None, 3), dtype=tf.float32)\n                 ],\n             )\n \n@@ -611,7 +631,7 @@ class ExportArchiveTest(testing.TestCase):\n         ):\n             export_archive.add_endpoint(\n                 \"call\",\n-                model.call,\n+                model.__call__,\n             )\n \n         # Set endpoint that has never been called\n@@ -664,13 +684,8 @@ class ExportArchiveTest(testing.TestCase):\n         export_archive = export_lib.ExportArchive()\n         export_archive.add_endpoint(\n             \"call\",\n-            model.call,\n-            input_signature=[\n-                tf.TensorSpec(\n-                    shape=(None, 3),\n-                    dtype=tf.float32,\n-                )\n-            ],\n+            model.__call__,\n+            input_signature=[tf.TensorSpec(shape=(None, 3), dtype=tf.float32)],\n         )\n         export_archive.write_out(temp_filepath)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#71b768953fcf63b4f695ce799e150cff4638a68a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -4/0 | Churn Δ: 14 | Churn Cumulative: 971 | Contributors (this commit): 6 | Commits (past 90d): 9 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -115,7 +115,19 @@ class ExportArchive:\n         return self._tf_trackable.non_trainable_variables\n \n     def track(self, resource):\n-        \"\"\"Track the variables (and other assets) of a layer or model.\"\"\"\n+        \"\"\"Track the variables (and other assets) of a layer or model.\n+        \n+        By default, all variables used by an endpoint function\n+        are automatically tracked when you call `add_endpoint()`.\n+        However, non-variables assets such as lookup tables\n+        need to be tracked manually. Note that lookup tables\n+        used by built-in Keras layers\n+        (`TextVectorization`, `IntegerLookup`, `StringLookup`)\n+        are automatically tracked in `add_endpoint()`.\n+\n+        Arguments:\n+            resource: A trackable TensorFlow resource.\n+        \"\"\"\n         if backend.backend() == \"tensorflow\" and not isinstance(\n             resource, tf.__internal__.tracking.Trackable\n         ):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#000e394e9b2ccc54c563fc7e36185101389168aa", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 78 | Lines Deleted: 22 | Files Changed: 4 | Hunks: 14 | Methods Changed: 8 | Complexity Δ (Sum/Max): 6/6 | Churn Δ: 100 | Churn Cumulative: 2500 | Contributors (this commit): 12 | Commits (past 90d): 11 | Contributors (cumulative): 20 | DMM Complexity: 0.2962962962962963\n\nDIFF:\n@@ -1,6 +1,5 @@\n import inspect\n import json\n-import os\n import warnings\n \n from keras import backend\n@@ -9,9 +8,7 @@ from keras.api_export import keras_export\n from keras.layers.layer import Layer\n from keras.models.variable_mapping import map_trackable_variables\n from keras.saving import saving_api\n-from keras.saving import saving_lib\n from keras.trainers import trainer as base_trainer\n-from keras.utils import io_utils\n from keras.utils import summary_utils\n from keras.utils import traceback_utils\n \n@@ -315,20 +312,7 @@ class Model(Trainer, Layer):\n                 at the target location, or instead ask the user\n                 via an interactive prompt.\n         \"\"\"\n-        if not str(filepath).endswith(\".weights.h5\"):\n-            raise ValueError(\n-                \"The filename must end in `.weights.h5`. \"\n-                f\"Received: filepath={filepath}\"\n-            )\n-        try:\n-            exists = os.path.exists(filepath)\n-        except TypeError:\n-            exists = False\n-        if exists and not overwrite:\n-            proceed = io_utils.ask_to_proceed_with_overwrite(filepath)\n-            if not proceed:\n-                return\n-        saving_lib.save_weights_only(self, filepath)\n+        return saving_api.save_weights(self, filepath, overwrite=True)\n \n     @traceback_utils.filter_traceback\n     def load_weights(self, filepath, skip_mismatch=False, **kwargs):\n\n@@ -203,6 +203,25 @@ def load_model(filepath, custom_objects=None, compile=True, safe_mode=True):\n         )\n \n \n+@keras_export(\"keras.saving.save_weights\")\n+def save_weights(model, filepath, overwrite=True, **kwargs):\n+    if not str(filepath).endswith(\".weights.h5\"):\n+        raise ValueError(\n+            \"The filename must end in `.weights.h5`. \"\n+            f\"Received: filepath={filepath}\"\n+        )\n+    try:\n+        exists = os.path.exists(filepath)\n+    except TypeError:\n+        exists = False\n+    if exists and not overwrite:\n+        proceed = io_utils.ask_to_proceed_with_overwrite(filepath)\n+        if not proceed:\n+            return\n+    saving_lib.save_weights_only(model, filepath, **kwargs)\n+\n+\n+@keras_export(\"keras.saving.load_weights\")\n def load_weights(model, filepath, skip_mismatch=False, **kwargs):\n     if str(filepath).endswith(\".keras\"):\n         if kwargs:\n@@ -211,10 +230,14 @@ def load_weights(model, filepath, skip_mismatch=False, **kwargs):\n             model, filepath, skip_mismatch=skip_mismatch\n         )\n     elif str(filepath).endswith(\".weights.h5\"):\n+        objects_to_skip = kwargs.pop(\"objects_to_skip\", None)\n         if kwargs:\n             raise ValueError(f\"Invalid keyword arguments: {kwargs}\")\n         saving_lib.load_weights_only(\n-            model, filepath, skip_mismatch=skip_mismatch\n+            model,\n+            filepath,\n+            skip_mismatch=skip_mismatch,\n+            objects_to_skip=objects_to_skip,\n         )\n     elif str(filepath).endswith(\".h5\") or str(filepath).endswith(\".hdf5\"):\n         by_name = kwargs.pop(\"by_name\", False)\n\n@@ -64,6 +64,44 @@ class SaveModelTests(test_case.TestCase):\n         ):\n             saving_api.save_model(model, \"model.png\")\n \n+    def test_objects_to_skip(self):\n+        model = Sequential(\n+            [\n+                layers.Input((3,)),\n+                layers.Dense(5),\n+                layers.Dense(5),\n+            ]\n+        )\n+        skip = model.layers[0]\n+        filepath = os.path.join(self.get_temp_dir(), \"test_model.weights.h5\")\n+        saving_api.save_weights(model, filepath, objects_to_skip=[skip])\n+        new_model = Sequential(\n+            [\n+                layers.Input((3,)),\n+                layers.Dense(5),\n+                layers.Dense(5),\n+            ]\n+        )\n+        new_model.load_weights(filepath, objects_to_skip=[new_model.layers[0]])\n+        self.assertNotAllClose(\n+            new_model.layers[0].get_weights()[0],\n+            model.layers[0].get_weights()[0],\n+        )\n+        self.assertAllClose(\n+            new_model.layers[0].get_weights()[1],\n+            model.layers[0].get_weights()[1],\n+        )\n+        saving_api.save_weights(model, filepath)\n+        new_model.load_weights(filepath, objects_to_skip=[new_model.layers[0]])\n+        self.assertNotAllClose(\n+            new_model.layers[0].get_weights()[0],\n+            model.layers[0].get_weights()[0],\n+        )\n+        self.assertAllClose(\n+            new_model.layers[0].get_weights()[1],\n+            model.layers[0].get_weights()[1],\n+        )\n+\n \n class LoadModelTests(test_case.TestCase, parameterized.TestCase):\n     def get_model(self, dtype=None):\n\n@@ -208,7 +208,7 @@ def _load_model_from_fileobj(fileobj, custom_objects, compile, safe_mode):\n     return model\n \n \n-def save_weights_only(model, filepath):\n+def save_weights_only(model, filepath, objects_to_skip=None):\n     \"\"\"Save only the weights of a model to a target filepath (.weights.h5).\n \n     Note: only supports h5 for now.\n@@ -222,17 +222,23 @@ def save_weights_only(model, filepath):\n             f\"Received: filepath={filepath}\"\n         )\n     weights_store = H5IOStore(filepath, mode=\"w\")\n+    if objects_to_skip is not None:\n+        visited_trackables = set(id(o) for o in objects_to_skip)\n+    else:\n+        visited_trackables = set()\n     _save_state(\n         model,\n         weights_store=weights_store,\n         assets_store=None,\n         inner_path=\"\",\n-        visited_trackables=set(),\n+        visited_trackables=visited_trackables,\n     )\n     weights_store.close()\n \n \n-def load_weights_only(model, filepath, skip_mismatch=False):\n+def load_weights_only(\n+    model, filepath, skip_mismatch=False, objects_to_skip=None\n+):\n     \"\"\"Load the weights of a model from a filepath (.keras or .weights.h5).\n \n     Note: only supports h5 for now.\n@@ -249,6 +255,11 @@ def load_weights_only(model, filepath, skip_mismatch=False):\n         )\n \n     failed_trackables = set()\n+    print(\"objects_to_skip\", objects_to_skip)\n+    if objects_to_skip is not None:\n+        visited_trackables = set(id(o) for o in objects_to_skip)\n+    else:\n+        visited_trackables = set()\n     error_msgs = {}\n     _load_state(\n         model,\n@@ -256,7 +267,7 @@ def load_weights_only(model, filepath, skip_mismatch=False):\n         assets_store=None,\n         inner_path=\"\",\n         skip_mismatch=skip_mismatch,\n-        visited_trackables=set(),\n+        visited_trackables=visited_trackables,\n         failed_trackables=failed_trackables,\n         error_msgs=error_msgs,\n     )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c9e8d8cd1c7a20d08745fff01d9014acd814a647", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 9 | Churn Cumulative: 627 | Contributors (this commit): 7 | Commits (past 90d): 11 | Contributors (cumulative): 7 | DMM Complexity: 0.0\n\nDIFF:\n@@ -727,9 +727,9 @@ def median(x, axis=None, keepdims=False):\n \n     result = jnp.median(x, axis=axis, keepdims=keepdims)\n \n-    # TODO: jnp.median failed to keepdims when axis is None\n+    # TODO: with jax < 0.4.26 jnp.median failed to keepdims when axis is None\n     if keepdims is True and axis is None:\n-        for _ in range(x.ndim - 1):\n+        while result.ndim < x.ndim:\n             result = jnp.expand_dims(result, axis=-1)\n     return result\n \n@@ -818,9 +818,10 @@ def quantile(x, q, axis=None, method=\"linear\", keepdims=False):\n \n     result = jnp.quantile(x, q, axis=axis, method=method, keepdims=keepdims)\n \n-    # TODO: jnp.quantile failed to keepdims when axis is None\n+    # TODO: with jax < 0.4.26 jnp.quantile failed to keepdims when axis is None\n     if keepdims is True and axis is None:\n-        for _ in range(x.ndim - 1):\n+        result_ndim = x.ndim + (1 if len(q.shape) > 0 else 0)\n+        while result.ndim < result_ndim:\n             result = jnp.expand_dims(result, axis=-1)\n     return result\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8d671b09c8827a145a3cb8486b1fab6c09ee8111", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 29 | Lines Deleted: 4 | Files Changed: 3 | Hunks: 9 | Methods Changed: 8 | Complexity Δ (Sum/Max): 5/3 | Churn Δ: 33 | Churn Cumulative: 1909 | Contributors (this commit): 8 | Commits (past 90d): 29 | Contributors (cumulative): 13 | DMM Complexity: 0.3333333333333333\n\nDIFF:\n@@ -204,7 +204,7 @@ class JAXTrainer(base_trainer.Trainer):\n \n     def make_train_function(self, force=False):\n         if self.train_function is not None and not force:\n-            return self.train_function\n+            return\n \n         def one_train_step(state, data):\n             data = data[0]\n@@ -236,7 +236,7 @@ class JAXTrainer(base_trainer.Trainer):\n \n     def make_test_function(self, force=False):\n         if self.test_function is not None and not force:\n-            return self.test_function\n+            return\n \n         def one_test_step(state, data):\n             data = data[0]\n\n@@ -6,6 +6,7 @@ from keras import backend\n from keras.api_export import keras_export\n from keras.layers.layer import Layer\n from keras.saving import serialization_lib\n+from keras.utils import jax_utils\n from keras.utils import tracking\n from keras.utils import tree\n from keras.utils.module_utils import jax\n@@ -228,9 +229,11 @@ class JaxLayer(Layer):\n         super().__init__(**kwargs)\n         self.call_fn = call_fn\n         self.init_fn = init_fn\n+        self.seed_generator = backend.random.SeedGenerator(seed)\n         self.tracked_params = self._create_variables(params, trainable=True)\n         self.tracked_state = self._create_variables(state, trainable=False)\n-        self.seed_generator = backend.random.SeedGenerator(seed)\n+        if self.params is not None or self.state is not None:\n+            self.built = True\n \n         self.call_fn_arguments = self._validate_signature(\n             call_fn,\n@@ -311,7 +314,8 @@ class JaxLayer(Layer):\n         else:\n             self.state = variables\n \n-        return jax.tree_util.tree_flatten(variables)\n+        flat_variables, _ = jax.tree_util.tree_flatten(variables)\n+        return flat_variables\n \n     def _get_init_rng(self):\n         \"\"\"\n@@ -349,6 +353,11 @@ class JaxLayer(Layer):\n         if self.params is not None or self.state is not None:\n             return\n \n+        if jax_utils.is_in_jax_tracing_scope():\n+            # This exception is not actually shown, it is caught and a detailed\n+            # warning about calling 'build' is printed.\n+            raise ValueError(\"'JaxLayer' cannot be built in tracing scope\")\n+\n         # Initialize `params` and `state` if needed by calling `init_fn`.\n         def create_input(shape):\n             shape = [d if d is not None else 1 for d in shape]\n@@ -374,6 +383,7 @@ class JaxLayer(Layer):\n             init_params, trainable=True\n         )\n         self.tracked_state = self._create_variables(init_state, trainable=False)\n+        self.built = True\n \n     def call(self, inputs, training=False):\n         def unwrap_variable(variable):\n\n@@ -327,6 +327,21 @@ class TestJaxLayer(testing.TestCase, parameterized.TestCase):\n         output4 = model4.serve(x_test)\n         self.assertAllClose(output1, output4)\n \n+        # test subclass model building without a build method\n+        class TestModel(models.Model):\n+\n+            def __init__(self, layer):\n+                super().__init__()\n+                self._layer = layer\n+\n+            def call(self, inputs):\n+                return self._layer(inputs)\n+\n+        layer5 = layer_class(**layer_init_kwargs)\n+        model5 = TestModel(layer5)\n+        output5 = model5(x_test)\n+        self.assertNotAllClose(output5, 0.0)\n+\n     @parameterized.named_parameters(\n         {\n             \"testcase_name\": \"training_independent\",\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bd50263ee4eb3a2155d5a1e7c7d4402a78826800", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 107 | Lines Deleted: 19 | Files Changed: 4 | Hunks: 18 | Methods Changed: 12 | Complexity Δ (Sum/Max): 6/4 | Churn Δ: 126 | Churn Cumulative: 1812 | Contributors (this commit): 11 | Commits (past 90d): 48 | Contributors (cumulative): 24 | DMM Complexity: 0.9871794871794872\n\nDIFF:\n@@ -31,6 +31,7 @@ class JAXTrainer(base_trainer.Trainer):\n         self,\n         trainable_variables,\n         non_trainable_variables,\n+        metrics_variables,\n         x,\n         y,\n         sample_weight,\n@@ -41,6 +42,8 @@ class JAXTrainer(base_trainer.Trainer):\n         kwargs = {}\n         if self._call_has_training_arg:\n             kwargs[\"training\"] = training\n+\n+        # Run stateless forward pass\n         y_pred, non_trainable_variables, losses = self.stateless_call(\n             trainable_variables,\n             non_trainable_variables,\n@@ -49,25 +52,36 @@ class JAXTrainer(base_trainer.Trainer):\n             **kwargs,\n         )\n \n-        var_mapping = list(zip(self.trainable_variables, trainable_variables))\n-        var_mapping.extend(\n-            zip(self.non_trainable_variables, non_trainable_variables)\n+        loss, variables = self.stateless_compute_loss(\n+            trainable_variables,\n+            non_trainable_variables,\n+            metrics_variables,\n+            x=x,\n+            y=y,\n+            y_pred=y_pred,\n+            sample_weight=sample_weight,\n         )\n-        with backend.StatelessScope(state_mapping=var_mapping):\n-            # Note that this is needed for the regularization loss, which need\n-            # the latest value of train/non-trainable variables.\n-            loss = self.compute_loss(\n-                x, y, y_pred, sample_weight=sample_weight, allow_empty=True\n+        (trainable_variables, non_trainable_variables, metrics_variables) = (\n+            variables\n         )\n+\n+        # Sum forward pass losses\n         if losses:\n             loss += ops.sum(losses)\n+\n+        # Handle loss scaling\n         unscaled_loss = loss\n         if training and self.optimizer is not None:\n             # Scale loss with a StatelessScope, to use an update scale variable.\n             mapping = list(zip(self.optimizer.variables, optimizer_variables))\n             with backend.StatelessScope(state_mapping=mapping):\n                 loss = self.optimizer.scale_loss(loss)\n-        return loss, (unscaled_loss, y_pred, non_trainable_variables)\n+        return loss, (\n+            unscaled_loss,\n+            y_pred,\n+            non_trainable_variables,\n+            metrics_variables,\n+        )\n \n     def train_step(self, state, data):\n         (\n@@ -83,13 +97,16 @@ class JAXTrainer(base_trainer.Trainer):\n         (loss, aux), grads = grad_fn(\n             trainable_variables,\n             non_trainable_variables,\n+            metrics_variables,\n             x,\n             y,\n             sample_weight,\n             training=True,\n             optimizer_variables=optimizer_variables,\n         )\n-        (unscaled_loss, y_pred, non_trainable_variables) = aux\n+        (unscaled_loss, y_pred, non_trainable_variables, metrics_variables) = (\n+            aux\n+        )\n \n         (\n             trainable_variables,\n@@ -135,12 +152,15 @@ class JAXTrainer(base_trainer.Trainer):\n         loss, aux = self.compute_loss_and_updates(\n             trainable_variables,\n             non_trainable_variables,\n+            metrics_variables,\n             x,\n             y,\n             sample_weight,\n             training=False,\n         )\n-        (unscaled_loss, y_pred, non_trainable_variables) = aux\n+        (unscaled_loss, y_pred, non_trainable_variables, metrics_variables) = (\n+            aux\n+        )\n \n         with backend.StatelessScope(\n             state_mapping=[\n\n@@ -972,10 +972,7 @@ class Layer(BackendLayer, Operation):\n         non_trainable_variables = []\n         for v in self.non_trainable_variables:\n             new_v = scope.get_current_value(v)\n-            if new_v is not None:\n             non_trainable_variables.append(new_v)\n-            else:\n-                non_trainable_variables.append(v)\n \n         if return_losses:\n             return outputs, non_trainable_variables, losses\n\n@@ -263,7 +263,11 @@ class Trainer:\n             m.reset_state()\n \n     def compute_loss(\n-        self, x=None, y=None, y_pred=None, sample_weight=None, allow_empty=False\n+        self,\n+        x=None,\n+        y=None,\n+        y_pred=None,\n+        sample_weight=None,\n     ):\n         \"\"\"Compute the total loss, validate it, and return it.\n \n@@ -308,9 +312,6 @@ class Trainer:\n             y: Target data.\n             y_pred: Predictions returned by the model (output of `model(x)`)\n             sample_weight: Sample weights for weighting the loss function.\n-            allow_empty: If `False`, the method will error out if\n-                no loss has been computed by the model. If `True`, then\n-                if no loss is computed, the method returns 0.\n \n         Returns:\n             The total loss as a scalar tensor, or `None` if no loss results\n@@ -324,7 +325,7 @@ class Trainer:\n                 losses.append(loss)\n         for loss in self.losses:\n             losses.append(ops.cast(loss, dtype=backend.floatx()))\n-        if not allow_empty and len(losses) == 0:\n+        if backend.backend() != \"jax\" and len(losses) == 0:\n             raise ValueError(\n                 \"No loss to compute. Provide a `loss` argument in `compile()`.\"\n             )\n@@ -336,6 +337,48 @@ class Trainer:\n             total_loss = ops.sum(losses)\n         return total_loss\n \n+    def stateless_compute_loss(\n+        self,\n+        trainable_variables,\n+        non_trainable_variables,\n+        metrics_variables,\n+        x=None,\n+        y=None,\n+        y_pred=None,\n+        sample_weight=None,\n+    ):\n+        var_mapping = list(zip(self.trainable_variables, trainable_variables))\n+        var_mapping.extend(\n+            zip(self.non_trainable_variables, non_trainable_variables)\n+        )\n+        var_mapping.extend(zip(self.metrics_variables, metrics_variables))\n+        with backend.StatelessScope(state_mapping=var_mapping) as scope:\n+            # Note that this is needed for the regularization loss, which need\n+            # the latest value of train/non-trainable variables.\n+            loss = self.compute_loss(\n+                x,\n+                y,\n+                y_pred,\n+                sample_weight=sample_weight,\n+            )\n+\n+        # Update non trainable vars (may have been updated in compute_loss)\n+        non_trainable_variables = []\n+        for v in self.non_trainable_variables:\n+            new_v = scope.get_current_value(v)\n+            non_trainable_variables.append(new_v)\n+\n+        # Update metrics vars (may have been updated in compute_loss)\n+        metrics_variables = []\n+        for v in self.metrics_variables:\n+            new_v = scope.get_current_value(v)\n+            metrics_variables.append(new_v)\n+        return loss, (\n+            trainable_variables,\n+            non_trainable_variables,\n+            metrics_variables,\n+        )\n+\n     def compute_metrics(self, x, y, y_pred, sample_weight=None):\n         \"\"\"Update metric states and collect all metrics to be returned.\n \n\n@@ -1291,3 +1291,31 @@ class TestTrainer(testing.TestCase, parameterized.TestCase):\n         )\n         self.assertAlmostEqual(cbk.eager_call_counter_predict, 4)\n         self.assertAlmostEqual(model.predict_counter.numpy(), 4)\n+\n+    def test_metric_update_in_compute_loss(self):\n+\n+        class MyModel(keras.Model):\n+            def __init__(self):\n+                super().__init__()\n+                self.custom_metric = keras.metrics.Mean(name=\"custom\")\n+                self.dense = keras.layers.Dense(2)\n+\n+            def call(self, x):\n+                return self.dense(x)\n+\n+            def compute_loss(\n+                self, x=None, y=None, y_pred=None, sample_weight=None\n+            ):\n+                loss = super().compute_loss(x, y, y_pred, sample_weight)\n+                print(\"loss\", loss)\n+                self.custom_metric.update_state(loss * 4)\n+                return loss\n+\n+        model = MyModel()\n+        model.compile(optimizer=\"sgd\", loss=\"mse\")\n+        x = np.ones((32, 4))\n+        y = np.ones((32, 2)) * 2\n+        history = model.fit(x, y)\n+        self.assertAlmostEqual(\n+            history.history[\"custom\"][0], history.history[\"loss\"][0] * 4\n+        )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#641aa48966977b7aff96553d53738b7dcd137061", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 654 | Contributors (this commit): 6 | Commits (past 90d): 10 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -1292,6 +1292,7 @@ class TestTrainer(testing.TestCase, parameterized.TestCase):\n         self.assertAlmostEqual(cbk.eager_call_counter_predict, 4)\n         self.assertAlmostEqual(model.predict_counter.numpy(), 4)\n \n+    @pytest.mark.requires_trainable_backend\n     def test_metric_update_in_compute_loss(self):\n \n         class MyModel(keras.Model):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1d58956b9f59a1aa69f8d0944bd43790da9a1c26", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 655 | Contributors (this commit): 6 | Commits (past 90d): 11 | Contributors (cumulative): 6 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1308,7 +1308,6 @@ class TestTrainer(testing.TestCase, parameterized.TestCase):\n                 self, x=None, y=None, y_pred=None, sample_weight=None\n             ):\n                 loss = super().compute_loss(x, y, y_pred, sample_weight)\n-                print(\"loss\", loss)\n                 self.custom_metric.update_state(loss * 4)\n                 return loss\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ddb80da84b635082007bccb306acbc4e164122d8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 30 | Lines Deleted: 2 | Files Changed: 4 | Hunks: 13 | Methods Changed: 7 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 32 | Churn Cumulative: 1016 | Contributors (this commit): 14 | Commits (past 90d): 37 | Contributors (cumulative): 25 | DMM Complexity: 0.4090909090909091\n\nDIFF:\n@@ -19,6 +19,7 @@ class KerasVariable:\n         dtype=None,\n         trainable=True,\n         autocast=True,\n+        aggregation=\"mean\",\n         name=None,\n     ):\n         name = name or auto_name(self.__class__.__name__)\n@@ -28,6 +29,12 @@ class KerasVariable:\n                 \"cannot contain character `/`. \"\n                 f\"Received: name={name}\"\n             )\n+        if aggregation not in (\"mean\", \"sum\", \"only_first_replica\"):\n+            raise ValueError(\n+                \"Invalid valid for argument `aggregation`. Expected \"\n+                \"one of {'mean', 'sum', 'only_first_replica'}. \"\n+                f\"Received: aggregation={aggregation}\"\n+            )\n         self.name = name\n         parent_path = current_path()\n         if parent_path:\n@@ -42,6 +49,7 @@ class KerasVariable:\n         self._constraint = None\n         self._trainable = trainable\n         self._autocast = autocast\n+        self._aggregation = aggregation\n         if isinstance(initializer, str):\n             from keras import initializers\n \n@@ -122,6 +130,10 @@ class KerasVariable:\n     def numpy(self):\n         return np.array(self)\n \n+    @property\n+    def aggregation(self):\n+        return self._aggregation\n+\n     @property\n     def value(self):\n         if in_stateless_scope():\n\n@@ -455,6 +455,7 @@ class Layer(BackendLayer, Operation):\n         autocast=True,\n         regularizer=None,\n         constraint=None,\n+        aggregation=\"mean\",\n         name=None,\n     ):\n         \"\"\"Add a weight variable to the layer.\n@@ -481,6 +482,10 @@ class Layer(BackendLayer, Operation):\n             constraint: Contrainst object to call on the variable after any\n                 optimizer update, or string name of a built-in constraint.\n                 Defaults to `None`.\n+            aggregation: String, one of `'mean'`, `'sum'`,\n+                `'only_first_replica'`. Annotates the variable with the type\n+                of multi-replica aggregation to be used for this variable\n+                when writing custom data parallel training loops.\n             name: String name of the variable. Useful for debugging purposes.\n         \"\"\"\n         self._check_super_called()\n@@ -503,6 +508,7 @@ class Layer(BackendLayer, Operation):\n                 dtype=dtype,\n                 trainable=trainable,\n                 autocast=autocast,\n+                aggregation=aggregation,\n                 name=name,\n             )\n         # Will be added to layer.losses\n\n@@ -179,7 +179,9 @@ class Metric:\n     def dtype(self):\n         return self._dtype\n \n-    def add_variable(self, shape, initializer, dtype=None, name=None):\n+    def add_variable(\n+        self, shape, initializer, dtype=None, aggregation=\"sum\", name=None\n+    ):\n         self._check_super_called()\n         with backend.name_scope(self.name.replace(\"/\", \">\"), caller=self):\n             initializer = initializers.get(initializer)\n@@ -188,6 +190,7 @@ class Metric:\n                 shape=shape,\n                 dtype=dtype,\n                 trainable=False,\n+                aggregation=aggregation,\n                 name=name,\n             )\n         # Prevent double-tracking\n\n@@ -101,7 +101,11 @@ class BaseOptimizer:\n         # (since int64 is disallowed in JAX) and to int64 in TF.\n         with backend.name_scope(self.name, caller=self):\n             iterations = backend.Variable(\n-                0, name=\"iteration\", dtype=\"int\", trainable=False\n+                0,\n+                name=\"iteration\",\n+                dtype=\"int\",\n+                trainable=False,\n+                aggregation=\"only_first_replica\",\n             )\n         self._track_variable(iterations)\n         self.iterations = iterations\n@@ -128,6 +132,7 @@ class BaseOptimizer:\n                     name=\"learning_rate\",\n                     dtype=backend.floatx(),\n                     trainable=False,\n+                    aggregation=\"only_first_replica\",\n                 )\n             self._track_variable(learning_rate)\n             self._learning_rate = learning_rate\n@@ -176,6 +181,7 @@ class BaseOptimizer:\n         shape,\n         initializer=\"zeros\",\n         dtype=None,\n+        aggregation=\"mean\",\n         name=None,\n     ):\n         self._check_super_called()\n@@ -186,6 +192,7 @@ class BaseOptimizer:\n                 shape=shape,\n                 dtype=dtype,\n                 trainable=False,\n+                aggregation=aggregation,\n                 name=name,\n             )\n         self._track_variable(variable)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b451d660a243e1e1c40668a369f377e8de57ce5b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 121 | Lines Deleted: 38 | Files Changed: 3 | Hunks: 19 | Methods Changed: 11 | Complexity Δ (Sum/Max): 9/4 | Churn Δ: 159 | Churn Cumulative: 7278 | Contributors (this commit): 17 | Commits (past 90d): 8 | Contributors (cumulative): 30 | DMM Complexity: 0.5866666666666667\n\nDIFF:\n@@ -538,39 +538,6 @@ def _do_lstm_arguments_support_cudnn(\n     )\n \n \n-def _is_sequence_right_padded(mask):\n-    \"\"\"Check the mask tensor and see if it right padded.\n-\n-    For cuDNN kernel, it uses the sequence length param to skip the tailing\n-    timestep. If the data is left padded, or not a strict right padding (has\n-    masked value in the middle of the sequence), then cuDNN kernel won't be work\n-    properly in those cases.\n-\n-    Left padded data: [[False, False, True, True, True]].\n-    Right padded data: [[True, True, True, False, False]].\n-    Mixture of mask/unmasked data: [[True, False, True, False, False]].\n-\n-    Note that for the mixed data example above, the actually data RNN should see\n-    are those 2 Trues (index 0 and 2), the index 1 False should be ignored and\n-    not pollute the internal states.\n-\n-    Args:\n-      mask: the Boolean tensor with shape [batch, timestep]\n-\n-    Returns:\n-      boolean scalar tensor, whether the mask is strictly right padded.\n-    \"\"\"\n-    max_seq_length = tf.shape(mask)[1]\n-    count_of_true = tf.reduce_sum(tf.cast(mask, tf.int32), axis=1)\n-    right_padded_mask = tf.sequence_mask(count_of_true, maxlen=max_seq_length)\n-    return tf.reduce_all(\n-        tf.equal(\n-            tf.cast(mask, dtype=\"bool\"),\n-            tf.cast(right_padded_mask, dtype=\"bool\"),\n-        )\n-    )\n-\n-\n def _has_fully_masked_sequence(mask):\n     # Cudnn kernel will error out if the input sequence contains any\n     # fully masked data. We walk around this issue by rerouting the computation\n@@ -582,6 +549,28 @@ def _has_fully_masked_sequence(mask):\n     )\n \n \n+def _assert_valid_mask(mask):\n+    valid = tf.logical_and(\n+        tf.logical_not(_has_fully_masked_sequence(mask)),\n+        _is_sequence_right_padded(mask),\n+    )\n+    tf.Assert(\n+        valid,\n+        [\n+            (\n+                \"You are passing a RNN mask that does not correspond to \"\n+                \"right-padded sequences, while using cuDNN, which is not \"\n+                \"supported. With cuDNN, RNN masks can only be used for \"\n+                \"right-padding, e.g. `[[True, True, False, False]]` would \"\n+                \"be a valid mask, but any mask that isn't just contiguous \"\n+                \"`True`'s on the left and contiguous `False`'s on the right \"\n+                \"would be invalid. You can pass `use_cudnn=False` to your \"\n+                \"RNN layer to stop using cuDNN (this may be slower).\"\n+            )\n+        ],\n+    )\n+\n+\n def _standardize_cudnn_weights(weights, biases, shape, transpose_weights=False):\n     \"\"\"Utility function convert variable to cuDNN compatible parameter.\n \n@@ -615,6 +604,39 @@ def _standardize_cudnn_weights(weights, biases, shape, transpose_weights=False):\n     return tf.concat(weights + biases, axis=0)\n \n \n+def _is_sequence_right_padded(mask):\n+    \"\"\"Check the mask tensor and see if it right padded.\n+\n+    cuDNN uses the sequence length param to skip the tailing\n+    timestep. If the data is left padded, or not a strict right padding (has\n+    masked value in the middle of the sequence), then cuDNN won't work\n+    properly in those cases.\n+\n+    Left padded data: [[False, False, True, True, True]].\n+    Right padded data: [[True, True, True, False, False]].\n+    Mixture of mask/unmasked data: [[True, False, True, False, False]].\n+\n+    Note that for the mixed data example above, the actually data RNN should see\n+    are those 2 Trues (index 0 and 2), the index 1 False should be ignored and\n+    not pollute the internal states.\n+\n+    Args:\n+        mask: the Boolean tensor with shape [batch, timestep]\n+\n+    Returns:\n+        boolean scalar tensor, whether the mask is strictly right padded.\n+    \"\"\"\n+    max_seq_length = tf.shape(mask)[1]\n+    count_of_true = tf.reduce_sum(tf.cast(mask, tf.int32), axis=1)\n+    right_padded_mask = tf.sequence_mask(count_of_true, maxlen=max_seq_length)\n+    return tf.reduce_all(\n+        tf.equal(\n+            tf.cast(mask, dtype=\"bool\"),\n+            tf.cast(right_padded_mask, dtype=\"bool\"),\n+        )\n+    )\n+\n+\n def _compute_sequence_length_from_mask(mask, time_major):\n     \"\"\"Calculate the sequence length tensor (1-D) based on the masking tensor.\n \n@@ -628,10 +650,11 @@ def _compute_sequence_length_from_mask(mask, time_major):\n     padded that could be checked by, e.g., `is_sequence_right_padded()`.\n \n     Args:\n-      mask: Boolean tensor with shape [batch, timestep] or [timestep, batch] if\n-        time_major=True.\n+        mask: Boolean tensor with shape [batch, timestep] or [timestep, batch]\n+            if time_major=True.\n         time_major: Boolean, which indicates whether the mask is time major or\n             batch major.\n+\n     Returns:\n         sequence_length: 1D int32 tensor.\n     \"\"\"\n@@ -656,6 +679,7 @@ def _cudnn_gru(\n ):\n     \"\"\"GRU with cuDNN implementation which is only available for GPU.\"\"\"\n     if mask is not None:\n+        _assert_valid_mask(mask)\n         sequence_lengths = _compute_sequence_length_from_mask(mask, time_major)\n     else:\n         sequence_lengths = None\n@@ -853,6 +877,20 @@ def _cudnn_lstm(\n     return_sequences,\n ):\n     if mask is not None:\n+        is_valid_mask = _is_sequence_right_padded(mask, time_major)\n+        tf.Assert(\n+            is_valid_mask,\n+            message=(\n+                \"You are passing a RNN mask that does not correspond to \"\n+                \"right-padded sequences, while using cuDNN, which is not \"\n+                \"supported. With cuDNN, RNN masks can only be used for \"\n+                \"right-padding, e.g. `[[True, True, False, False]]` would \"\n+                \"be a valid mask, but any mask that isn't just contiguous \"\n+                \"`True`'s on the left and contiguous `False`'s on the right \"\n+                \"would be invalid. You can pass `use_cudnn=False` to your \"\n+                \"RNN layer to stop using cuDNN (this may be slower).\"\n+            ),\n+        )\n         sequence_lengths = _compute_sequence_length_from_mask(mask, time_major)\n     else:\n         sequence_lengths = None\n\n@@ -431,6 +431,9 @@ class GRU(RNN):\n         reset_after: GRU convention (whether to apply reset gate after or\n             before matrix multiplication). `False` is `\"before\"`,\n             `True` is `\"after\"` (default and cuDNN compatible).\n+        use_cudnn: Whether to use a cuDNN-backed implementation. `\"auto\"` will\n+            attempt to use cuDNN when feasible, and will fallback to the\n+            default implementation if not.\n \n     Call arguments:\n         inputs: A 3D tensor, with shape `(batch, timesteps, feature)`.\n@@ -473,6 +476,7 @@ class GRU(RNN):\n         stateful=False,\n         unroll=False,\n         reset_after=True,\n+        use_cudnn=\"auto\",\n         **kwargs,\n     ):\n         cell = GRUCell(\n@@ -508,12 +512,23 @@ class GRU(RNN):\n             **kwargs,\n         )\n         self.input_spec = InputSpec(ndim=3)\n-        if backend.backend() == \"tensorflow\" and backend.cudnn_ok(\n+        if use_cudnn not in (\"auto\", True, False):\n+            raise ValueError(\n+                \"Invalid valid received for argument `use_cudnn`. \"\n+                \"Expected one of {'auto', True, False}. \"\n+                f\"Received: use_cudnn={use_cudnn}\"\n+            )\n+        self.use_cudnn = use_cudnn\n+        if (\n+            backend.backend() == \"tensorflow\"\n+            and backend.cudnn_ok(\n                 cell.activation,\n                 cell.recurrent_activation,\n                 self.unroll,\n                 cell.use_bias,\n                 reset_after=reset_after,\n+            )\n+            and use_cudnn in (True, \"auto\")\n         ):\n             self.supports_jit = False\n \n@@ -522,7 +537,7 @@ class GRU(RNN):\n             initial_state = initial_state[0]\n         if tree.is_nested(mask):\n             mask = mask[0]\n-\n+        if self.use_cudnn in (\"auto\", True):\n             if not self.dropout and not self.recurrent_dropout:\n                 try:\n                     # Backends are allowed to specify (optionally) optimized\n@@ -550,6 +565,13 @@ class GRU(RNN):\n                     return out\n                 except NotImplementedError:\n                     pass\n+        if self.use_cudnn is True:\n+            raise ValueError(\n+                \"use_cudnn=True was specified, \"\n+                \"but cuDNN is not supported for this layer configuration \"\n+                \"with this backend. Pass use_cudnn='auto' to fallback \"\n+                \"to a non-cuDNN implementation.\"\n+            )\n         return super().inner_loop(\n             sequences, initial_state, mask=mask, training=training\n         )\n\n@@ -412,6 +412,9 @@ class LSTM(RNN):\n             Unrolling can speed-up a RNN,\n             although it tends to be more memory-intensive.\n             Unrolling is only suitable for short sequences.\n+        use_cudnn: Whether to use a cuDNN-backed implementation. `\"auto\"` will\n+            attempt to use cuDNN when feasible, and will fallback to the\n+            default implementation if not.\n \n     Call arguments:\n         inputs: A 3D tensor, with shape `(batch, timesteps, feature)`.\n@@ -454,6 +457,7 @@ class LSTM(RNN):\n         go_backwards=False,\n         stateful=False,\n         unroll=False,\n+        use_cudnn=\"auto\",\n         **kwargs,\n     ):\n         cell = LSTMCell(\n@@ -490,11 +494,22 @@ class LSTM(RNN):\n             **kwargs,\n         )\n         self.input_spec = InputSpec(ndim=3)\n-        if backend.backend() == \"tensorflow\" and backend.cudnn_ok(\n+        if use_cudnn not in (\"auto\", True, False):\n+            raise ValueError(\n+                \"Invalid valid received for argument `use_cudnn`. \"\n+                \"Expected one of {'auto', True, False}. \"\n+                f\"Received: use_cudnn={use_cudnn}\"\n+            )\n+        self.use_cudnn = use_cudnn\n+        if (\n+            backend.backend() == \"tensorflow\"\n+            and backend.cudnn_ok(\n                 cell.activation,\n                 cell.recurrent_activation,\n                 self.unroll,\n                 cell.use_bias,\n+            )\n+            and use_cudnn in (True, \"auto\")\n         ):\n             self.supports_jit = False\n \n@@ -502,6 +517,7 @@ class LSTM(RNN):\n         if tree.is_nested(mask):\n             mask = mask[0]\n \n+        if self.use_cudnn in (\"auto\", True):\n             if not self.dropout and not self.recurrent_dropout:\n                 try:\n                     # Backends are allowed to specify (optionally) optimized\n@@ -529,6 +545,13 @@ class LSTM(RNN):\n                     return out\n                 except NotImplementedError:\n                     pass\n+        if self.use_cudnn is True:\n+            raise ValueError(\n+                \"use_cudnn=True was specified, \"\n+                \"but cuDNN is not supported for this layer configuration \"\n+                \"with this backend. Pass use_cudnn='auto' to fallback \"\n+                \"to a non-cuDNN implementation.\"\n+            )\n         return super().inner_loop(\n             sequences, initial_state, mask=mask, training=training\n         )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
