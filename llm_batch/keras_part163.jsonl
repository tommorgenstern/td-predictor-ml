{"custom_id": "keras#ac4b365e0b08bd2a655bb86573995344ef750071", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 8 | Files Changed: 2 | Hunks: 7 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 21 | Churn Cumulative: 3003 | Contributors (this commit): 39 | Commits (past 90d): 35 | Contributors (cumulative): 40 | DMM Complexity: None\n\nDIFF:\n@@ -787,7 +787,11 @@ class NumpyArrayIterator(Iterator):\n         super(NumpyArrayIterator, self).__init__(x.shape[0], batch_size, shuffle, seed)\n \n     def next(self):\n-        # For python 2.x. Yields the next batch.\n+        \"\"\"For python 2.x.\n+\n+        # Returns\n+            The next batch.\n+        \"\"\"\n         # Keeps under lock only the mechanism which advances\n         # the indexing of each batch.\n         with self.lock:\n@@ -937,7 +941,10 @@ class DirectoryIterator(Iterator):\n         super(DirectoryIterator, self).__init__(self.samples, batch_size, shuffle, seed)\n \n     def next(self):\n-        \"\"\"For python 2.x. Yields the next batch.\n+        \"\"\"For python 2.x.\n+\n+        # Returns\n+            The next batch.\n         \"\"\"\n         with self.lock:\n             index_array, current_index, current_batch_size = next(self.index_generator)\n\n@@ -1,11 +1,9 @@\n from __future__ import print_function\n \n-from .generic_utils import deserialize_keras_object\n from .conv_utils import convert_kernel\n-py_sum = sum\n-from ..layers import *\n from ..models import Model, Sequential\n from .. import backend as K\n+import numpy as np\n \n \n def print_summary(model, line_length=None, positions=None):\n@@ -25,7 +23,7 @@ def print_summary(model, line_length=None, positions=None):\n         sequential_like = True\n     else:\n         sequential_like = True\n-        for k, v in model.nodes_by_depth.items():\n+        for v in model.nodes_by_depth.values():\n             if len(v) > 1:\n                 sequential_like = False\n \n@@ -150,8 +148,8 @@ def count_total_params(layers, layer_set=None):\n             trainable_count += t\n             non_trainable_count += nt\n         else:\n-            trainable_count += py_sum([K.count_params(p) for p in layer.trainable_weights])\n-            non_trainable_count += py_sum([K.count_params(p) for p in layer.non_trainable_weights])\n+            trainable_count += np.sum([K.count_params(p) for p in layer.trainable_weights])\n+            non_trainable_count += np.sum([K.count_params(p) for p in layer.non_trainable_weights])\n     return trainable_count, non_trainable_count\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#26e6df8a98670802286978e1657526fe2afa61d5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 26 | Lines Deleted: 50 | Files Changed: 1 | Hunks: 27 | Methods Changed: 9 | Complexity Δ (Sum/Max): -9/0 | Churn Δ: 76 | Churn Cumulative: 6539 | Contributors (this commit): 61 | Commits (past 90d): 53 | Contributors (cumulative): 61 | DMM Complexity: 0.9\n\nDIFF:\n@@ -828,20 +828,16 @@ def dot(x, y):\n         (2, 4, 5)\n     ```\n     \"\"\"\n-    if hasattr(tf, 'unstack'):\n-        unstack = tf.unstack\n-    else:\n-        unstack = tf.unpack\n     if ndim(x) is not None and (ndim(x) > 2 or ndim(y) > 2):\n         x_shape = []\n-        for i, s in zip(int_shape(x), unstack(tf.shape(x))):\n+        for i, s in zip(int_shape(x), tf.unstack(tf.shape(x))):\n             if i is not None:\n                 x_shape.append(i)\n             else:\n                 x_shape.append(s)\n         x_shape = tuple(x_shape)\n         y_shape = []\n-        for i, s in zip(int_shape(y), unstack(tf.shape(y))):\n+        for i, s in zip(int_shape(y), tf.unstack(tf.shape(y))):\n             if i is not None:\n                 y_shape.append(i)\n             else:\n@@ -930,13 +926,6 @@ def batch_dot(x, y, axes=None):\n         else:\n             adj_x = None\n             adj_y = None\n-        # TODO: remove later.\n-        if hasattr(tf, 'batch_matmul'):\n-            try:\n-                out = tf.batch_matmul(x, y, adj_a=adj_x, adj_b=adj_y)\n-            except TypeError:\n-                out = tf.batch_matmul(x, y, adj_x=adj_x, adj_y=adj_y)\n-        else:\n         out = tf.matmul(x, y, adjoint_a=adj_x, adjoint_b=adj_y)\n     if ndim(out) == 1:\n         out = expand_dims(out, 1)\n@@ -1436,7 +1425,7 @@ def normalize_batch_in_training(x, gamma, beta,\n                 target_shape.append(1)\n             else:\n                 target_shape.append(tf.shape(x)[axis])\n-        target_shape = stack(target_shape)\n+        target_shape = tf.stack(target_shape)\n \n         broadcast_mean = tf.reshape(mean, target_shape)\n         broadcast_var = tf.reshape(var, target_shape)\n@@ -1607,7 +1596,7 @@ def repeat(x, n):\n     \"\"\"\n     assert ndim(x) == 2\n     x = tf.expand_dims(x, 1)\n-    pattern = stack([1, n, 1])\n+    pattern = tf.stack([1, n, 1])\n     return tf.tile(x, pattern)\n \n \n@@ -1664,7 +1653,7 @@ def batch_flatten(x):\n     # Returns\n         A tensor.\n     \"\"\"\n-    x = tf.reshape(x, stack([-1, prod(shape(x)[1:])]))\n+    x = tf.reshape(x, tf.stack([-1, prod(shape(x)[1:])]))\n     return x\n \n \n@@ -1811,10 +1800,7 @@ def stack(x):\n     # Returns\n         A tensor.\n     \"\"\"\n-    try:\n     return tf.stack(x)\n-    except AttributeError:\n-        return tf.pack(x)\n \n \n def one_hot(indices, num_classes):\n@@ -2080,16 +2066,6 @@ def rnn(step_function, inputs, initial_states,\n     if constants is None:\n         constants = []\n \n-    # TODO: remove later.\n-    if hasattr(tf, 'select'):\n-        tf.where = tf.select\n-    if hasattr(tf, 'stack'):\n-        stack = tf.stack\n-        unstack = tf.unstack\n-    else:\n-        stack = tf.pack\n-        unstack = tf.unpack\n-\n     if unroll:\n         if not inputs.get_shape()[0]:\n             raise ValueError('Unrolling requires a '\n@@ -2098,12 +2074,12 @@ def rnn(step_function, inputs, initial_states,\n         successive_states = []\n         successive_outputs = []\n \n-        input_list = unstack(inputs)\n+        input_list = tf.unstack(inputs)\n         if go_backwards:\n             input_list.reverse()\n \n         if mask is not None:\n-            mask_list = unstack(mask)\n+            mask_list = tf.unstack(mask)\n             if go_backwards:\n                 mask_list.reverse()\n \n@@ -2121,7 +2097,7 @@ def rnn(step_function, inputs, initial_states,\n                 # it just repeats the mask along its second dimension\n                 # n times.\n                 tiled_mask_t = tf.tile(mask_t,\n-                                       stack([1, tf.shape(output)[1]]))\n+                                       tf.stack([1, tf.shape(output)[1]]))\n \n                 if len(successive_outputs) == 0:\n                     prev_output = zeros_like(output)\n@@ -2134,7 +2110,7 @@ def rnn(step_function, inputs, initial_states,\n                 for state, new_state in zip(states, new_states):\n                     # (see earlier comment for tile explanation)\n                     tiled_mask_t = tf.tile(mask_t,\n-                                           stack([1, tf.shape(new_state)[1]]))\n+                                           tf.stack([1, tf.shape(new_state)[1]]))\n                     return_states.append(tf.where(tiled_mask_t,\n                                                   new_state,\n                                                   state))\n@@ -2143,7 +2119,7 @@ def rnn(step_function, inputs, initial_states,\n                 successive_states.append(states)\n                 last_output = successive_outputs[-1]\n                 new_states = successive_states[-1]\n-                outputs = stack(successive_outputs)\n+                outputs = tf.stack(successive_outputs)\n         else:\n             for input in input_list:\n                 output, states = step_function(input, states + constants)\n@@ -2151,7 +2127,7 @@ def rnn(step_function, inputs, initial_states,\n                 successive_states.append(states)\n             last_output = successive_outputs[-1]\n             new_states = successive_states[-1]\n-            outputs = stack(successive_outputs)\n+            outputs = tf.stack(successive_outputs)\n \n     else:\n         if go_backwards:\n@@ -2168,10 +2144,7 @@ def rnn(step_function, inputs, initial_states,\n             dtype=inputs.dtype,\n             size=time_steps,\n             tensor_array_name='input_ta')\n-        if hasattr(input_ta, 'unstack'):\n         input_ta = input_ta.unstack(inputs)\n-        else:\n-            input_ta = input_ta.unpack(inputs)\n         time = tf.constant(0, dtype='int32', name='time')\n \n         if mask is not None:\n@@ -2189,10 +2162,7 @@ def rnn(step_function, inputs, initial_states,\n                 dtype=tf.bool,\n                 size=time_steps,\n                 tensor_array_name='mask_ta')\n-            if hasattr(mask_ta, 'unstack'):\n             mask_ta = mask_ta.unstack(mask)\n-            else:\n-                mask_ta = mask_ta.unpack(mask)\n \n             def _step(time, output_ta_t, *states):\n                 current_input = input_ta.read(time)\n@@ -2203,7 +2173,7 @@ def rnn(step_function, inputs, initial_states,\n                 for state, new_state in zip(states, new_states):\n                     new_state.set_shape(state.get_shape())\n                 tiled_mask_t = tf.tile(mask_t,\n-                                       stack([1, tf.shape(output)[1]]))\n+                                       tf.stack([1, tf.shape(output)[1]]))\n                 output = tf.where(tiled_mask_t, output, states[0])\n                 new_states = [tf.where(tiled_mask_t, new_states[i], states[i]) for i in range(len(states))]\n                 output_ta_t = output_ta_t.write(time, output)\n@@ -2229,10 +2199,7 @@ def rnn(step_function, inputs, initial_states,\n         output_ta = final_outputs[1]\n         new_states = final_outputs[2:]\n \n-        if hasattr(output_ta, 'stack'):\n         outputs = output_ta.stack()\n-        else:\n-            outputs = output_ta.pack()\n         last_output = output_ta.read(last_time - 1)\n \n     axes = [1, 0] + list(range(2, len(outputs.get_shape())))\n@@ -2765,16 +2732,25 @@ def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n     x = tf.nn.conv2d_transpose(x, kernel, output_shape, strides,\n                                padding=padding)\n     x = _postprocess_conv2d_output(x, data_format)\n-    # TODO: set_shape with static shape\n     return x\n \n \n def separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1),\n                      padding='valid', data_format=None, dilation_rate=(1, 1)):\n-    \"\"\"2-D convolution with separable filters.\n+    \"\"\"2D convolution with separable filters.\n \n     # Arguments\n-        # TODO\n+        x: input tensor\n+        depthwise_kernel: convolution kernel for the depthwise convolution.\n+        pointwise_kernel: kernel for the 1x1 convolution.\n+        strides: strides tuple (length 2).\n+        padding: padding mode, \"valid\" or \"same\".\n+        data_format: data format, \"channels_first\" or \"channels_last\".\n+        dilation_rate: tuple of integers,\n+            dilation rates for the separable convolution.\n+\n+    # Returns\n+        Output tensor.\n \n     # Raises\n         ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n@@ -3045,8 +3021,8 @@ def ctc_label_dense_to_sparse(labels, label_lengths):\n     # undocumented feature soon to be made public\n     from tensorflow.python.ops import functional_ops\n     label_shape = tf.shape(labels)\n-    num_batches_tns = stack([label_shape[0]])\n-    max_num_labels_tns = stack([label_shape[1]])\n+    num_batches_tns = tf.stack([label_shape[0]])\n+    max_num_labels_tns = tf.stack([label_shape[1]])\n \n     def range_less_than(previous_state, current_input):\n         return tf.expand_dims(tf.range(label_shape[1]), 0) < tf.fill(max_num_labels_tns, current_input)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ac2a7254c2c29b4c13fb97740f2aaaf46a0282dc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 12150 | Contributors (this commit): 59 | Commits (past 90d): 28 | Contributors (cumulative): 59 | DMM Complexity: 0.0\n\nDIFF:\n@@ -812,11 +812,7 @@ class Dense(Layer):\n \n     def build(self, input_shape):\n         assert len(input_shape) >= 2\n-\n         input_dim = input_shape[-1]\n-        # TODO: check last dim in input_dim\n-        self.input_spec = [InputSpec(dtype=K.floatx(),\n-                                     ndim='2+')]\n \n         self.kernel = self.add_weight((input_dim, self.units),\n                                       initializer=self.kernel_initializer,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1422baaa8d94fd2aa42e784c9fd474ec3d3298c9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 6 | Files Changed: 2 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 1622 | Contributors (this commit): 17 | Commits (past 90d): 21 | Contributors (cumulative): 18 | DMM Complexity: None\n\nDIFF:\n@@ -248,7 +248,6 @@ class Merge(Layer):\n             elif self._output_shape is not None:\n                 return (input_shape[0][0],) + tuple(self._output_shape)\n             else:\n-                # TODO: consider shape auto-inference with TF.\n                 raise ValueError('The Merge layer ' + self.name +\n                                  ' has a callable `mode` argument, '\n                                  'and we cannot infer its output shape '\n\n@@ -7,16 +7,13 @@ import numpy as np\n \n \n def print_summary(model, line_length=None, positions=None):\n-    \"\"\"Prints a summary of a layer.\n+    \"\"\"Prints a summary of a model.\n \n     # Arguments\n         model: Keras model instance.\n         line_length: total length of printed lines\n         positions: relative or absolute positions of log elements in each line.\n             If not provided, defaults to `[.33, .55, .67, 1.]`.\n-\n-    # TODO: don't print connectivity for sequential models\n-    maybe change API to accept a model instance\n     \"\"\"\n \n     if isinstance(model, Sequential):\n@@ -42,7 +39,7 @@ def print_summary(model, line_length=None, positions=None):\n         # header names for the different log elements\n         to_display = ['Layer (type)', 'Output Shape', 'Param #', 'Connected to']\n         relevant_nodes = []\n-        for k, v in model.nodes_by_depth.items():\n+        for v in model.nodes_by_depth.values():\n             relevant_nodes += v\n \n     def print_row(fields, positions):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#13f271c7d6d259e8a478657fa05822f9584090c4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 24 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 24 | Churn Cumulative: 24 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,24 @@\n+import pytest\n+from keras.utils.generic_utils import custom_object_scope\n+from keras import activations\n+from keras import regularizers\n+\n+\n+def test_custom_objects_scope():\n+\n+    def custom_fn():\n+        pass\n+\n+    class CustomClass(object):\n+        pass\n+\n+    with custom_object_scope({'CustomClass': CustomClass,\n+                              'custom_fn': custom_fn}):\n+        act = activations.get('custom_fn')\n+        assert act == custom_fn\n+        cl = regularizers.get('CustomClass')\n+        assert cl.__class__ == CustomClass\n+\n+\n+if __name__ == '__main__':\n+    pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#79192f8358199b28a3f4b69d5aee9dd78c482d4f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 245 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 245 | Churn Cumulative: 10072 | Contributors (this commit): 54 | Commits (past 90d): 24 | Contributors (cumulative): 55 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1053,9 +1053,6 @@ class Sequential(Model):\n         model = cls()\n \n         def get_or_create_layer(layer_data):\n-            if layer_data['class_name'] == 'Sequential':\n-                return Sequential.from_config(layer_data['config'],\n-                                              layer_cache=layer_cache)\n             name = layer_data['config'].get('name')\n             if name in layer_cache:\n                 return layer_cache[name]\n\n@@ -313,247 +313,5 @@ def test_sequential_regression():\n     outer_model.fit([x, y, z], labels, epochs=1)\n \n \n-\n-\n-# @keras_test\n-# def test_merge_sum():\n-#     (x_train, y_train), (x_test, y_test) = _get_test_data()\n-#     left = models.Sequential()\n-#     left.add(layers.Dense(num_hidden, input_shape=(input_dim,)))\n-#     left.add(layers.Activation('relu'))\n-\n-#     right = models.Sequential()\n-#     right.add(layers.Dense(num_hidden, input_shape=(input_dim,)))\n-#     right.add(layers.Activation('relu'))\n-\n-#     model = models.Sequential()\n-#     model.add(legacy_layers.Merge([left, right], mode='sum'))\n-#     model.add(layers.Dense(num_class))\n-#     model.add(layers.Activation('softmax'))\n-#     model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n-\n-#     model.fit([x_train, x_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0, validation_data=([x_test, x_test], y_test))\n-#     model.fit([x_train, x_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0, validation_split=0.1)\n-#     model.fit([x_train, x_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0)\n-#     model.fit([x_train, x_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0, shuffle=False)\n-\n-#     loss = model.evaluate([x_test, x_test], y_test, verbose=0)\n-\n-#     model.predict([x_test, x_test], verbose=0)\n-#     model.predict_classes([x_test, x_test], verbose=0)\n-#     model.predict_proba([x_test, x_test], verbose=0)\n-\n-#     # test weight saving\n-#     fname = 'test_merge_sum_temp.h5'\n-#     model.save_weights(fname, overwrite=True)\n-#     left = Sequential()\n-#     left.add(Dense(num_hidden, input_shape=(input_dim,)))\n-#     left.add(Activation('relu'))\n-#     right = Sequential()\n-#     right.add(Dense(num_hidden, input_shape=(input_dim,)))\n-#     right.add(Activation('relu'))\n-#     model = Sequential()\n-#     model.add(Merge([left, right], mode='sum'))\n-#     model.add(Dense(num_class))\n-#     model.add(Activation('softmax'))\n-#     model.load_weights(fname)\n-#     os.remove(fname)\n-#     model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n-\n-#     nloss = model.evaluate([x_test, x_test], y_test, verbose=0)\n-#     assert(loss == nloss)\n-\n-#     # test serialization\n-#     config = model.get_config()\n-#     Sequential.from_config(config)\n-\n-#     model.summary()\n-#     json_str = model.to_json()\n-#     model_from_json(json_str)\n-\n-#     yaml_str = model.to_yaml()\n-#     model_from_yaml(yaml_str)\n-\n-\n-# @keras_test\n-# def test_merge_dot():\n-#     (x_train, y_train), (x_test, y_test) = _get_test_data()\n-\n-#     left = Sequential()\n-#     left.add(Dense(input_dim=input_dim, output_dim=num_hidden))\n-#     left.add(Activation('relu'))\n-\n-#     right = Sequential()\n-#     right.add(Dense(input_dim=input_dim, output_dim=num_hidden))\n-#     right.add(Activation('relu'))\n-\n-#     model = Sequential()\n-#     model.add(Merge([left, right], mode='dot', dot_axes=1))\n-#     model.add(Dense(num_class))\n-#     model.add(Activation('softmax'))\n-\n-#     model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n-\n-#     left = Sequential()\n-#     left.add(Dense(input_dim=input_dim, output_dim=num_hidden))\n-#     left.add(Activation('relu'))\n-\n-#     right = Sequential()\n-#     right.add(Dense(input_dim=input_dim, output_dim=num_hidden))\n-#     right.add(Activation('relu'))\n-\n-#     model = Sequential()\n-#     model.add(Merge([left, right], mode='dot', dot_axes=[1, 1]))\n-#     model.add(Dense(num_class))\n-#     model.add(Activation('softmax'))\n-\n-#     model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n-\n-\n-# @keras_test\n-# def test_merge_concat():\n-#     (x_train, y_train), (x_test, y_test) = _get_test_data()\n-\n-#     left = Sequential(name='branch_1')\n-#     left.add(Dense(num_hidden, input_shape=(input_dim,), name='dense_1'))\n-#     left.add(Activation('relu', name='relu_1'))\n-\n-#     right = Sequential(name='branch_2')\n-#     right.add(Dense(num_hidden, input_shape=(input_dim,), name='dense_2'))\n-#     right.add(Activation('relu', name='relu_2'))\n-\n-#     model = Sequential(name='merged_branches')\n-#     model.add(Merge([left, right], mode='concat', name='merge'))\n-#     model.add(Dense(num_class, name='final_dense'))\n-#     model.add(Activation('softmax', name='softmax'))\n-#     model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n-\n-#     model.fit([x_train, x_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0, validation_data=([x_test, x_test], y_test))\n-#     model.fit([x_train, x_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0, validation_split=0.1)\n-#     model.fit([x_train, x_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0)\n-#     model.fit([x_train, x_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0, shuffle=False)\n-\n-#     loss = model.evaluate([x_test, x_test], y_test, verbose=0)\n-\n-#     model.predict([x_test, x_test], verbose=0)\n-#     model.predict_classes([x_test, x_test], verbose=0)\n-#     model.predict_proba([x_test, x_test], verbose=0)\n-#     model.get_config()\n-\n-#     fname = 'test_merge_concat_temp.h5'\n-#     model.save_weights(fname, overwrite=True)\n-#     model.fit([x_train, x_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0)\n-#     model.load_weights(fname)\n-#     os.remove(fname)\n-\n-#     nloss = model.evaluate([x_test, x_test], y_test, verbose=0)\n-#     assert(loss == nloss)\n-\n-\n-# @keras_test\n-# def test_merge_recursivity():\n-#     (x_train, y_train), (x_test, y_test) = _get_test_data()\n-#     left = Sequential()\n-#     left.add(Dense(num_hidden, input_shape=(input_dim,)))\n-#     left.add(Activation('relu'))\n-\n-#     right = Sequential()\n-#     right.add(Dense(num_hidden, input_shape=(input_dim,)))\n-#     right.add(Activation('relu'))\n-\n-#     righter = Sequential()\n-#     righter.add(Dense(num_hidden, input_shape=(input_dim,)))\n-#     righter.add(Activation('relu'))\n-\n-#     intermediate = Sequential()\n-#     intermediate.add(Merge([left, right], mode='sum'))\n-#     intermediate.add(Dense(num_hidden))\n-#     intermediate.add(Activation('relu'))\n-\n-#     model = Sequential()\n-#     model.add(Merge([intermediate, righter], mode='sum'))\n-#     model.add(Dense(num_class))\n-#     model.add(Activation('softmax'))\n-#     model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n-\n-#     model.fit([x_train, x_train, x_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0, validation_data=([x_test, x_test, x_test], y_test))\n-#     model.fit([x_train, x_train, x_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0, validation_split=0.1)\n-#     model.fit([x_train, x_train, x_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0)\n-#     model.fit([x_train, x_train, x_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0, shuffle=False)\n-\n-#     loss = model.evaluate([x_test, x_test, x_test], y_test, verbose=0)\n-\n-#     model.predict([x_test, x_test, x_test], verbose=0)\n-#     model.predict_classes([x_test, x_test, x_test], verbose=0)\n-#     model.predict_proba([x_test, x_test, x_test], verbose=0)\n-\n-#     fname = 'test_merge_recursivity_temp.h5'\n-#     model.save_weights(fname, overwrite=True)\n-#     model.load_weights(fname)\n-#     os.remove(fname)\n-\n-#     nloss = model.evaluate([x_test, x_test, x_test], y_test, verbose=0)\n-#     assert(loss == nloss)\n-\n-#     # test serialization\n-#     config = model.get_config()\n-#     Sequential.from_config(config)\n-\n-#     model.summary()\n-#     json_str = model.to_json()\n-#     model_from_json(json_str)\n-\n-#     yaml_str = model.to_yaml()\n-#     model_from_yaml(yaml_str)\n-\n-\n-# @keras_test\n-# def test_merge_overlap():\n-#     (x_train, y_train), (x_test, y_test) = _get_test_data()\n-#     left = Sequential()\n-#     left.add(Dense(num_hidden, input_shape=(input_dim,)))\n-#     left.add(Activation('relu'))\n-\n-#     model = Sequential()\n-#     model.add(Merge([left, left], mode='sum'))\n-#     model.add(Dense(num_class))\n-#     model.add(Activation('softmax'))\n-#     model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n-\n-#     model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n-#     model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=2, validation_split=0.1)\n-#     model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=0)\n-#     model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, shuffle=False)\n-\n-#     model.train_on_batch(x_train[:32], y_train[:32])\n-\n-#     loss = model.evaluate(x_test, y_test, verbose=0)\n-#     model.predict(x_test, verbose=0)\n-#     model.predict_classes(x_test, verbose=0)\n-#     model.predict_proba(x_test, verbose=0)\n-\n-#     fname = 'test_merge_overlap_temp.h5'\n-#     print(model.layers)\n-#     model.save_weights(fname, overwrite=True)\n-#     print(model.trainable_weights)\n-\n-#     model.load_weights(fname)\n-#     os.remove(fname)\n-\n-#     nloss = model.evaluate(x_test, y_test, verbose=0)\n-#     assert(loss == nloss)\n-\n-#     # test serialization\n-#     config = model.get_config()\n-#     Sequential.from_config(config)\n-\n-#     model.summary()\n-#     json_str = model.to_json()\n-#     model_from_json(json_str)\n-\n-#     yaml_str = model.to_yaml()\n-#     model_from_yaml(yaml_str)\n-\n-\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b7116b991dba0c1256146c71496fc558cb3dbb41", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 7060 | Contributors (this commit): 27 | Commits (past 90d): 34 | Contributors (cumulative): 27 | DMM Complexity: None\n\nDIFF:\n@@ -2318,7 +2318,7 @@ class Container(Layer):\n \n     def _updated_config(self):\n         \"\"\"Shared between different serialization methods.\"\"\"\n-        from keras import __version__ as keras_version\n+        from .. import __version__ as keras_version\n \n         config = self.get_config()\n         model_config = {\n@@ -2361,7 +2361,7 @@ class Container(Layer):\n         return yaml.dump(self._updated_config(), **kwargs)\n \n     def summary(self, line_length=None, positions=None):\n-        from keras.utils.layer_utils import print_summary\n+        from ..utils.layer_utils import print_summary\n         print_summary(self,\n                       line_length=line_length,\n                       positions=positions)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#197fb886cba673b385189809a1a90032032f5c26", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 27 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 12/12 | Churn Δ: 27 | Churn Cumulative: 1639 | Contributors (this commit): 4 | Commits (past 90d): 2 | Contributors (cumulative): 4 | DMM Complexity: 0.09090909090909091\n\nDIFF:\n@@ -0,0 +1,27 @@\n+from .layers import Merge\n+\n+\n+def needs_legacy_support(model):\n+    return isinstance(model.layers[0], Merge)\n+\n+\n+def legacy_sequential_layers(model):\n+    layers = []\n+    if model.layers:\n+        if isinstance(model.layers[0], Merge):\n+            merge = model.layers[0]\n+            for layer in merge.layers:\n+                if hasattr(layer, 'layers'):\n+                    for sublayer in layer.layers:\n+                        if sublayer not in layers:\n+                            layers.append(sublayer)\n+                else:\n+                    if layer not in layers:\n+                        layers.append(layer)\n+        else:\n+            if model.layers[0] not in layers:\n+                layers.append(model.layers[0])\n+        for layer in model.layers[1:]:\n+            if layer not in layers:\n+                layers.append(layer)\n+    return layers\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#dab228bc565592230e8158ec774da40f24691c79", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 65 | Lines Deleted: 14 | Files Changed: 1 | Hunks: 15 | Methods Changed: 7 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 79 | Churn Cumulative: 8740 | Contributors (this commit): 54 | Commits (past 90d): 21 | Contributors (cumulative): 54 | DMM Complexity: None\n\nDIFF:\n@@ -27,11 +27,43 @@ except ImportError:\n \n \n def save_model(model, filepath, overwrite=True):\n+    \"\"\"Save a model to a HDF5 file.\n+\n+    The saved model contains:\n+        - the model's configuration (topology)\n+        - the model's weights\n+        - the model's optimizer's state (if any)\n+\n+    Thus the saved model can be reinstantiated in\n+    the exact same state, without any of the code\n+    used for model definition or training.\n+\n+    # Arguments\n+        model: Keras model instance to be saved.\n+        filepath: String, path where to save the model.\n+        overwrite: Whether we should overwrite any existing\n+            model at the target location, or instead\n+            ask the user with a manual prompt.\n+\n+    # Raises\n+        ImportError: if h5py is not available.\n+    \"\"\"\n \n     if h5py is None:\n         raise ImportError('`save_model` requires h5py.')\n \n     def get_json_type(obj):\n+        \"\"\"Serialize any object to a JSON-serializable structure.\n+\n+        # Arguments\n+            obj: the object to serialize\n+\n+        # Returns\n+            JSON-serializable structure representing `obj`.\n+\n+        # Raises\n+            TypeError: if `obj` cannot be serialized.\n+        \"\"\"\n         # if obj is a serializable Keras class instance\n         # e.g. optimizer, layer\n         if hasattr(obj, 'get_config'):\n@@ -54,7 +86,7 @@ def save_model(model, filepath, overwrite=True):\n \n     from keras import __version__ as keras_version\n \n-    # if file exists and should not be overwritten\n+    # If file exists and should not be overwritten.\n     if not overwrite and os.path.isfile(filepath):\n         proceed = ask_to_proceed_with_overwrite(filepath)\n         if not proceed:\n@@ -126,6 +158,23 @@ def save_model(model, filepath, overwrite=True):\n \n \n def load_model(filepath, custom_objects=None):\n+    \"\"\"Loads a model saved via `save_model`.\n+\n+    # Arguments\n+        filepath: String, path to the saved model.\n+        custom_objects: Optional dictionary mapping names\n+            (strings) to custom classes or functions to be\n+            considered during deserialization.\n+\n+    # Returns\n+        A Keras model instance. If an optimizer was found\n+        as part of the saved model, the model is already\n+        compiled. Otherwise, the model is uncompiled and\n+        a warning will be displayed.\n+\n+    # Raises\n+        ImportError: if h5py is not available.\n+    \"\"\"\n     if h5py is None:\n         raise ImportError('`save_model` requires h5py.')\n \n@@ -177,22 +226,22 @@ def load_model(filepath, custom_objects=None):\n     optimizer = optimizers.deserialize(optimizer_config,\n                                        custom_objects=custom_objects)\n \n-    # recover loss functions and metrics\n+    # Recover loss functions and metrics.\n     loss = deserialize(training_config['loss'])\n     metrics = deserialize(training_config['metrics'])\n     sample_weight_mode = training_config['sample_weight_mode']\n     loss_weights = training_config['loss_weights']\n \n-    # compile model\n+    # Compile model.\n     model.compile(optimizer=optimizer,\n                   loss=loss,\n                   metrics=metrics,\n                   loss_weights=loss_weights,\n                   sample_weight_mode=sample_weight_mode)\n \n-    # set optimizer weights\n+    # Set optimizer weights.\n     if 'optimizer_weights' in f:\n-        # build train function (to get weight updates)\n+        # Build train function (to get weight updates).\n         if isinstance(model, Sequential):\n             model.model._make_train_function()\n         else:\n@@ -206,6 +255,8 @@ def load_model(filepath, custom_objects=None):\n \n \n def model_from_config(config, custom_objects=None):\n+    \"\"\"\n+    \"\"\"\n     if isinstance(config, list):\n         raise TypeError('`model_fom_config` expects a dictionary, not a list. '\n                         'Maybe you meant to use '\n@@ -214,16 +265,14 @@ def model_from_config(config, custom_objects=None):\n \n \n def model_from_yaml(yaml_string, custom_objects=None):\n-    \"\"\"Parses a yaml model configuration file\n-    and returns a model instance.\n+    \"\"\"Parses a yaml model configuration file and returns a model instance.\n     \"\"\"\n     config = yaml.load(yaml_string)\n     return layers.deserialize(config, custom_objects=custom_objects)\n \n \n def model_from_json(json_string, custom_objects=None):\n-    \"\"\"Parses a JSON model configuration file\n-    and returns a model instance.\n+    \"\"\"Parses a JSON model configuration file and returns a model instance.\n     \"\"\"\n     config = json.loads(json_string)\n     return layers.deserialize(config, custom_objects=custom_objects)\n@@ -267,23 +316,25 @@ class Sequential(Model):\n     \"\"\"\n \n     def __init__(self, layers=None, name=None):\n-        self.layers = []  # stack of layers\n-        self.model = None  # internal Model instance\n-        self.inputs = []  # tensors\n-        self.outputs = []  # tensors (length 1)\n+        self.layers = []  # Stack of layers.\n+        self.model = None  # Internal Model instance.\n+        self.inputs = []  # List of input tensors\n+        self.outputs = []  # List of length 1: the output tensor (unique).\n         self._trainable = True\n         self._initial_weights = None\n \n-        # model attributes\n+        # Model attributes.\n         self.inbound_nodes = []\n         self.outbound_nodes = []\n         self.built = False\n \n+        # Set model name.\n         if not name:\n             prefix = 'sequential_'\n             name = prefix + str(K.get_uid(prefix))\n         self.name = name\n \n+        # Add to the model any layers passed to the constructor.\n         if layers:\n             for layer in layers:\n                 self.add(layer)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b03b2b614011b1b11a010c3d76f305552df528d0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 70 | Lines Deleted: 21 | Files Changed: 1 | Hunks: 24 | Methods Changed: 23 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 91 | Churn Cumulative: 8831 | Contributors (this commit): 54 | Commits (past 90d): 22 | Contributors (cumulative): 54 | DMM Complexity: None\n\nDIFF:\n@@ -130,7 +130,7 @@ def save_model(model, filepath, overwrite=True):\n                 'loss_weights': model.loss_weights,\n             }, default=get_json_type).encode('utf8')\n \n-            # save optimizer weights\n+            # Save optimizer weights.\n             symbolic_weights = getattr(model.optimizer, 'weights')\n             if symbolic_weights:\n                 optimizer_weights_group = f.create_group('optimizer_weights')\n@@ -181,7 +181,7 @@ def load_model(filepath, custom_objects=None):\n     if not custom_objects:\n         custom_objects = {}\n \n-    def deserialize(obj):\n+    def convert_custom_objects(obj):\n         if isinstance(obj, list):\n             deserialized = []\n             for value in obj:\n@@ -227,8 +227,8 @@ def load_model(filepath, custom_objects=None):\n                                        custom_objects=custom_objects)\n \n     # Recover loss functions and metrics.\n-    loss = deserialize(training_config['loss'])\n-    metrics = deserialize(training_config['metrics'])\n+    loss = convert_custom_objects(training_config['loss'])\n+    metrics = convert_custom_objects(training_config['metrics'])\n     sample_weight_mode = training_config['sample_weight_mode']\n     loss_weights = training_config['loss_weights']\n \n@@ -255,7 +255,16 @@ def load_model(filepath, custom_objects=None):\n \n \n def model_from_config(config, custom_objects=None):\n-    \"\"\"\n+    \"\"\"Instantiates a Keras model from its config.\n+\n+    # Arguments\n+        config: Configuration dictionary.\n+        custom_objects: Optional dictionary mapping names\n+            (strings) to custom classes or functions to be\n+            considered during deserialization.\n+\n+    # Returns\n+        A Keras model instance (uncompiled).\n     \"\"\"\n     if isinstance(config, list):\n         raise TypeError('`model_fom_config` expects a dictionary, not a list. '\n@@ -266,6 +275,15 @@ def model_from_config(config, custom_objects=None):\n \n def model_from_yaml(yaml_string, custom_objects=None):\n     \"\"\"Parses a yaml model configuration file and returns a model instance.\n+\n+    # Arguments\n+        yaml_string: YAML string encoding a model configuration.\n+        custom_objects: Optional dictionary mapping names\n+            (strings) to custom classes or functions to be\n+            considered during deserialization.\n+\n+    # Returns\n+        A Keras model instance (uncompiled).\n     \"\"\"\n     config = yaml.load(yaml_string)\n     return layers.deserialize(config, custom_objects=custom_objects)\n@@ -273,6 +291,15 @@ def model_from_yaml(yaml_string, custom_objects=None):\n \n def model_from_json(json_string, custom_objects=None):\n     \"\"\"Parses a JSON model configuration file and returns a model instance.\n+\n+    # Arguments\n+        json_string: JSON string encoding a model configuration.\n+        custom_objects: Optional dictionary mapping names\n+            (strings) to custom classes or functions to be\n+            considered during deserialization.\n+\n+    # Returns\n+        A Keras model instance (uncompiled).\n     \"\"\"\n     config = json.loads(json_string)\n     return layers.deserialize(config, custom_objects=custom_objects)\n@@ -413,6 +440,9 @@ class Sequential(Model):\n \n     def pop(self):\n         \"\"\"Removes the last layer in the model.\n+\n+        # Raises\n+            TypeError: if there are no layers in the model.\n         \"\"\"\n         if not self.layers:\n             raise TypeError('There are no layers in the model.')\n@@ -446,10 +476,10 @@ class Sequential(Model):\n             self.build()\n         return self.model.get_layer(name, index)\n \n-    def call(self, x, mask=None):\n+    def call(self, inputs, mask=None):\n         if self.model is None:\n             self.build()\n-        return self.model.call(x, mask)\n+        return self.model.call(inputs, mask)\n \n     def build(self, input_shape=None):\n         if not self.inputs or not self.outputs:\n@@ -476,7 +506,8 @@ class Sequential(Model):\n         self.output_names = self.model.output_names\n         self.input_names = self.model.input_names\n \n-        # make sure child model callbacks will call the parent Sequential model:\n+        # Make sure child model callbacks\n+        # will call the parent Sequential model.\n         self.model.callback_model = self\n \n         self.built = True\n@@ -587,8 +618,7 @@ class Sequential(Model):\n         return self.model.constraints\n \n     def get_weights(self):\n-        \"\"\"Returns the weights of the model,\n-        as a flat list of Numpy arrays.\n+        \"\"\"Returns the weights of the model, as a flat list of Numpy arrays.\n         \"\"\"\n         # Legacy support\n         if legacy_models.needs_legacy_support(self):\n@@ -604,7 +634,9 @@ class Sequential(Model):\n \n     def set_weights(self, weights):\n         \"\"\"Sets the weights of the model.\n-        The `weights` argument should be a list\n+\n+        # Arguments\n+            weights: Should be a list\n                 of Numpy arrays with shapes and types matching\n                 the output of `model.get_weights()`.\n         \"\"\"\n@@ -749,6 +781,9 @@ class Sequential(Model):\n             a record of training loss values and metrics values\n             at successive epochs, as well as validation loss values\n             and validation metrics values (if applicable).\n+\n+        # Raises\n+            RuntimeError: if the model was never compiled.\n         \"\"\"\n         if self.model is None:\n             raise RuntimeError('The model needs to be compiled '\n@@ -782,6 +817,9 @@ class Sequential(Model):\n             or list of scalars (if the model computes other metrics).\n             The attribute `model.metrics_names` will give you\n             the display labels for the scalar outputs.\n+\n+        # Raises\n+            RuntimeError: if the model was never compiled.\n         \"\"\"\n         if self.model is None:\n             raise RuntimeError('The model needs to be compiled '\n@@ -792,8 +830,7 @@ class Sequential(Model):\n                                    sample_weight=sample_weight)\n \n     def predict(self, x, batch_size=32, verbose=0):\n-        \"\"\"Generates output predictions for the input samples,\n-        processing the samples in a batched way.\n+        \"\"\"Generates output predictions for the input samples, processing the samples in a batched way.\n \n         # Arguments\n             x: the input data, as a Numpy array.\n@@ -831,6 +868,9 @@ class Sequential(Model):\n             or list of scalars (if the model computes other metrics).\n             The attribute `model.metrics_names` will give you\n             the display labels for the scalar outputs.\n+\n+        # Raises\n+            RuntimeError: if the model was never compiled.\n         \"\"\"\n         if self.model is None:\n             raise RuntimeError('The model needs to be compiled '\n@@ -854,6 +894,9 @@ class Sequential(Model):\n             or list of scalars (if the model computes other metrics).\n             The attribute `model.metrics_names` will give you\n             the display labels for the scalar outputs.\n+\n+        # Raises\n+            RuntimeError: if the model was never compiled.\n         \"\"\"\n         if self.model is None:\n             raise RuntimeError('The model needs to be compiled '\n@@ -862,8 +905,7 @@ class Sequential(Model):\n                                         sample_weight=sample_weight)\n \n     def predict_proba(self, x, batch_size=32, verbose=1):\n-        \"\"\"Generates class probability predictions for the input samples\n-        batch by batch.\n+        \"\"\"Generates class probability predictions for the input samples batch by batch.\n \n         # Arguments\n             x: input data, as a Numpy array or list of Numpy arrays\n@@ -906,8 +948,8 @@ class Sequential(Model):\n                       validation_data=None, num_val_samples=None,\n                       class_weight=None, max_q_size=10, workers=1,\n                       pickle_safe=False, initial_epoch=0):\n-        \"\"\"Fits the model on data generated batch-by-batch by\n-        a Python generator.\n+        \"\"\"Fits the model on data generated batch-by-batch by a Python generator.\n+\n         The generator is run in parallel to the model, for efficiency.\n         For instance, this allows you to do real-time data augmentation\n         on images on CPU in parallel to training your model on GPU.\n@@ -947,6 +989,9 @@ class Sequential(Model):\n         # Returns\n             A `History` object.\n \n+        # Raises\n+            RuntimeError: if the model was never compiled.\n+\n         # Example\n \n         ```python\n@@ -983,8 +1028,10 @@ class Sequential(Model):\n     def evaluate_generator(self, generator, val_samples,\n                            max_q_size=10, workers=1,\n                            pickle_safe=False):\n-        \"\"\"Evaluates the model on a data generator. The generator should\n-        return the same kind of data as accepted by `test_on_batch`.\n+        \"\"\"Evaluates the model on a data generator.\n+\n+        The generator should return the same kind of data\n+        as accepted by `test_on_batch`.\n \n         # Arguments\n             generator:\n@@ -999,6 +1046,9 @@ class Sequential(Model):\n                 this implementation relies on multiprocessing, you should not pass non\n                 non picklable arguments to the generator as they can't be passed\n                 easily to children processes.\n+\n+        # Raises\n+            RuntimeError: if the model was never compiled.\n         \"\"\"\n         if self.model is None:\n             raise RuntimeError('The model needs to be compiled '\n@@ -1012,6 +1062,7 @@ class Sequential(Model):\n     def predict_generator(self, generator, val_samples,\n                           max_q_size=10, workers=1, pickle_safe=False):\n         \"\"\"Generates predictions for the input samples from a data generator.\n+\n         The generator should return the same kind of data as accepted by\n         `predict_on_batch`.\n \n@@ -1083,8 +1134,6 @@ class Sequential(Model):\n \n     @classmethod\n     def legacy_from_config(cls, config, layer_cache=None):\n-        \"\"\"Supports legacy formats.\n-        \"\"\"\n         if not layer_cache:\n             layer_cache = {}\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4828bde0ce2cd1193f6bc660d213f6fc0664562b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 10 | Files Changed: 1 | Hunks: 4 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 24 | Churn Cumulative: 7084 | Contributors (this commit): 27 | Commits (past 90d): 35 | Contributors (cumulative): 27 | DMM Complexity: 0.0\n\nDIFF:\n@@ -33,10 +33,14 @@ class InputSpec(object):\n     a None shape is compatible with any shape.\n \n     # Arguments\n-        TODO\n-\n-    # Attributes\n-        TODO\n+        dtype: Expected datatype of the input.\n+        shape: Shape tuple, expected shape of the input\n+            (may include None for unchecked axes).\n+        ndim: Integer, expected rank of the input.\n+        max_ndim: Integer, maximum rank of the input.\n+        min_ndim: Integer, minimum rank of the input.\n+        axes: Dictionary mapping integer axes to\n+            a specific dimension value.\n     \"\"\"\n \n     def __init__(self, dtype=None,\n@@ -1373,14 +1377,11 @@ class Container(Layer):\n         # List of initial layers (1 to 1 mapping with self.inputs,\n         # hence the same layer might appear twice)\n         self.input_layers = []\n-        # TODO: probably useless because input layers must be Input layers\n-        # (node_indices = [0], tensor_indices = [0])\n         self.input_layers_node_indices = []\n         self.input_layers_tensor_indices = []\n         # list of layers (1 to 1 mapping with self.inputs,\n         # hence the same layer might appear twice)\n         self.output_layers = []\n-        # TODO: probably useless\n         self.output_layers_node_indices = []\n         self.output_layers_tensor_indices = []\n         # all layers in order of horizontal graph traversal.\n@@ -1491,9 +1492,12 @@ class Container(Layer):\n \n         def build_map_of_graph(tensor, seen_nodes=set(), depth=0,\n                                layer=None, node_index=None, tensor_index=None):\n-            \"\"\"This recursively updates the maps nodes_depths,\n-            layers_depths and the set container_nodes.\n-            Does not try to detect cycles in graph (TODO?)\n+            \"\"\"Builds a map of the graph of layers.\n+\n+            This recursively updates the maps `nodes_depths`,\n+            `layers_depths` and the set `container_nodes`.\n+\n+            Does not try to detect cycles in the graph.\n \n             # Arguments\n                 tensor: Some tensor in a graph.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
