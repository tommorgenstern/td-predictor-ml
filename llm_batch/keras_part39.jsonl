{"custom_id": "keras#eb62075078fca2e6adce82a313dd6f7e68c461bd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 2448 | Contributors (this commit): 25 | Commits (past 90d): 44 | Contributors (cumulative): 25 | DMM Complexity: None\n\nDIFF:\n@@ -346,7 +346,8 @@ class Merge(Layer):\n             for i in range(len(self.layers)):\n                 X = self.layers[i].get_output(train)\n                 if X.name is None:\n-                    raise ValueError(\"merge_mode='join' only works with named inputs\")\n+                    inputs['input' + str(i)] = self.layers[i].get_output(train)\n+                    #raise ValueError(\"merge_mode='join' only works with named inputs\")\n                 else:\n                     inputs[X.name] = self.layers[i].get_output(train)\n             return inputs\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a58e03771550a5571e10eff21d813fa41984ee30", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 16 | Churn Cumulative: 2464 | Contributors (this commit): 25 | Commits (past 90d): 45 | Contributors (cumulative): 25 | DMM Complexity: None\n\nDIFF:\n@@ -904,6 +904,22 @@ class MaxoutDense(Layer):\n \n \n class Lambda(Layer):\n+\t\n+    \"\"\"Lambda layer for evaluating arbitrary function\n+    Input shape\n+    -----------\n+    output_shape of previous layer \n+    \n+    Output shape\n+    ------------\n+    Specified by output_argument\n+    \n+    Arguments\n+    ---------\n+    function - The function to be evaluated. Takes one argument : ouput of previous layer\n+    output_shape - Expected output shape from function. Could be a tuple or a function of input layers\n+    \"\"\"\n+    \n \tdef __init__(self, function, output_shape=None, ndim=2):\n \t\tsuper(Lambda, self).__init__()\n \t\tself.input = ndim_tensor(ndim)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#25aab5d40577e49a6c0f09e2f1caab8d16f40c12", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2466 | Contributors (this commit): 25 | Commits (past 90d): 46 | Contributors (cumulative): 25 | DMM Complexity: None\n\nDIFF:\n@@ -912,7 +912,7 @@ class Lambda(Layer):\n \t\n \tOutput shape\n \t------------\n-    Specified by output_argument\n+\tSpecified by output_shape argument\n     \n \tArguments\n \t---------\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#45577f7959dab9e29044d5ac794c8349624b4bcc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 6 | Churn Cumulative: 2472 | Contributors (this commit): 25 | Commits (past 90d): 47 | Contributors (cumulative): 25 | DMM Complexity: 1.0\n\nDIFF:\n@@ -944,7 +944,11 @@ class Lambda(Layer):\n \t\telse:\n \t\t\toutput_shape_func = marshal.loads(self._output_shape)\n \t\t\toutput_shape_func = types.FunctionType(output_shape_func, globals())\n-\t\t\treturn output_shape_func(self.previous)\n+\t\t\tshape = output_shape_func(self.previous)\n+\t\t\tif type(shape) not in {list,tuple}:\n+\t\t\t\traise Exception (\"output_shape function must return a tuple\")\n+\t\t\treturn tuple(shape)\n+\n \n \tdef get_output(self, train=False):\n \t\tfunc = marshal.loads(self.function)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a069161d0fc816b134d53f9b94cc89a549bcb50c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 467 | Contributors (this commit): 4 | Commits (past 90d): 14 | Contributors (cumulative): 4 | DMM Complexity: 0.0\n\nDIFF:\n@@ -293,12 +293,10 @@ class TestSequential(unittest.TestCase):\n         left = Sequential()\n         left.add(Dense(nb_hidden, input_shape=(input_dim,)))\n         left.add(Activation('relu'))\n-        left.set_name('left')\n         \n         right = Sequential()\n         right.add(Dense(nb_hidden, input_shape=(input_dim,)))\n         right.add(Activation('relu'))\n-        right.set_name('right')\n         \n         model = Sequential()\n         model.add(Merge([left, right], mode='join'))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#07f8cef29c39aeb2020d71d1e95d7ebc3c6437bb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 2475 | Contributors (this commit): 25 | Commits (past 90d): 48 | Contributors (cumulative): 25 | DMM Complexity: None\n\nDIFF:\n@@ -346,8 +346,7 @@ class Merge(Layer):\n             for i in range(len(self.layers)):\n                 X = self.layers[i].get_output(train)\n                 if X.name is None:\n-                    inputs['input' + str(i)] = self.layers[i].get_output(train)\n-                    #raise ValueError(\"merge_mode='join' only works with named inputs\")\n+                    raise ValueError(\"merge_mode='join' only works with named inputs\")\n                 else:\n                     inputs[X.name] = self.layers[i].get_output(train)\n             return inputs\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#29e788dc2e56b5ab5bffd236be785d29b2e04b25", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 469 | Contributors (this commit): 4 | Commits (past 90d): 15 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -293,10 +293,12 @@ class TestSequential(unittest.TestCase):\n         left = Sequential()\n         left.add(Dense(nb_hidden, input_shape=(input_dim,)))\n         left.add(Activation('relu'))\n+        left.set_name('left')\n         \n         right = Sequential()\n         right.add(Dense(nb_hidden, input_shape=(input_dim,)))\n         right.add(Activation('relu'))\n+        right.set_name('right')\n         \n         model = Sequential()\n         model.add(Merge([left, right], mode='join'))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f5896236fad6bb94fff0282d0d2321b1d1799cef", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 3 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 5 | Churn Cumulative: 2480 | Contributors (this commit): 25 | Commits (past 90d): 49 | Contributors (cumulative): 25 | DMM Complexity: 0.0\n\nDIFF:\n@@ -277,7 +277,7 @@ class TimeDistributedMerge(Layer):\n \n \n class Merge(Layer):\n-    def __init__(self, layers, mode='sum', concat_axis=-1):\n+    def __init__(self, layers, mode='sum', concat_axis=-1, auto_name=False):\n         ''' Merge the output of a list of layers or containers into a single tensor.\n             mode: {'sum', 'mul', 'concat', 'ave', 'join'}\n         '''\n@@ -346,6 +346,9 @@ class Merge(Layer):\n             for i in range(len(self.layers)):\n                 X = self.layers[i].get_output(train)\n                 if X.name is None:\n+                    if auto_name:\n+                        inputs['input' + str(i)] = self.layers[i].get_output(train) \n+                    else:\n                         raise ValueError(\"merge_mode='join' only works with named inputs\")\n                 else:\n                     inputs[X.name] = self.layers[i].get_output(train)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#315a12ac58d373640942cebe9b6ac6a314344c82", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 473 | Contributors (this commit): 4 | Commits (past 90d): 16 | Contributors (cumulative): 4 | DMM Complexity: 0.0\n\nDIFF:\n@@ -293,15 +293,13 @@ class TestSequential(unittest.TestCase):\n         left = Sequential()\n         left.add(Dense(nb_hidden, input_shape=(input_dim,)))\n         left.add(Activation('relu'))\n-        left.set_name('left')\n         \n         right = Sequential()\n         right.add(Dense(nb_hidden, input_shape=(input_dim,)))\n         right.add(Activation('relu'))\n-        right.set_name('right')\n         \n         model = Sequential()\n-        model.add(Merge([left, right], mode='join'))\n+        model.add(Merge([left, right], mode='join', auto_name=True))\n \n         model.add(Lambda(function=func,output_shape=output_shape))\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c90d2dfc0c5d31cfc1640bd993031b70ca074b6c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 2483 | Contributors (this commit): 25 | Commits (past 90d): 50 | Contributors (cumulative): 25 | DMM Complexity: 0.0\n\nDIFF:\n@@ -299,6 +299,7 @@ class Merge(Layer):\n \n         self.mode = mode\n         self.concat_axis = concat_axis\n+        self.auto_name = auto_name\n         self.layers = layers\n         self.params = []\n         self.regularizers = []\n@@ -346,7 +347,7 @@ class Merge(Layer):\n             for i in range(len(self.layers)):\n                 X = self.layers[i].get_output(train)\n                 if X.name is None:\n-                    if auto_name:\n+                    if self.auto_name:\n                         inputs['input' + str(i)] = self.layers[i].get_output(train) \n                     else:\n                         raise ValueError(\"merge_mode='join' only works with named inputs\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a9d09058970afdf74a9ebe459398aa44837feca2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 4 | Churn Cumulative: 660 | Contributors (this commit): 10 | Commits (past 90d): 15 | Contributors (cumulative): 10 | DMM Complexity: 1.0\n\nDIFF:\n@@ -85,6 +85,10 @@ class Sequential(Layer):\n             self.set_input()\n         return self.layers[0].get_input(train)\n  \n+    @property\n+    def input_shape(self):\n+        return self.layers[0].input_shape\n+    \n     @property\n     def input(self):\n         return self.get_input()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c140939c5a0ac77841f2cd22c4450bb2d4b2b402", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2485 | Contributors (this commit): 25 | Commits (past 90d): 51 | Contributors (cumulative): 25 | DMM Complexity: None\n\nDIFF:\n@@ -347,7 +347,7 @@ class Merge(Layer):\n             for i in range(len(self.layers)):\n                 X = self.layers[i].get_output(train)\n                 if X.name is None:\n-                    if self.auto_name:\n+                    if self.auto_name == True:\n                         inputs['input' + str(i)] = self.layers[i].get_output(train) \n                     else:\n                         raise ValueError(\"merge_mode='join' only works with named inputs\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c6c3a0247c70fbea7344ef2e5ea710a9244e7745", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 2488 | Contributors (this commit): 25 | Commits (past 90d): 52 | Contributors (cumulative): 25 | DMM Complexity: 1.0\n\nDIFF:\n@@ -399,7 +399,8 @@ class Merge(Layer):\n         config = {\"name\": self.__class__.__name__,\n                   \"layers\": [l.get_config() for l in self.layers],\n                   \"mode\": self.mode,\n-                  \"concat_axis\": self.concat_axis}\n+                  \"concat_axis\": self.concat_axis,\n+                  \"auto_name\": self.auto_name}\n         base_config = super(Merge, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ba389ffb113b1edb1fbc332fa7dc1afaa0887618", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 100 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 11 | Complexity Δ (Sum/Max): 29/29 | Churn Δ: 100 | Churn Cumulative: 2588 | Contributors (this commit): 25 | Commits (past 90d): 53 | Contributors (cumulative): 25 | DMM Complexity: 0.6219512195121951\n\nDIFF:\n@@ -963,3 +963,103 @@ class Lambda(Layer):\n \t\t\treturn func(self.input)\n class MaskedLambda(MaskedLayer, Lambda):\n \tpass\n+\n+class LambdaMerge(Lambda):\n+    def __init__(self, layers, function, output_shape=None, ndim=2)\n+        if len(layers) < 2:\n+            raise Exception(\"Please specify two or more input layers (or containers) to merge\")\n+        self.input = ndim_tensor(ndim)\n+        self.layers = layers\n+        self.params = []\n+        self.regularizers = []\n+        self.constraints = []\n+        self.updates = []\n+        for l in self.layers:\n+            params, regs, consts, updates = l.get_params()\n+            self.regularizers += regs\n+            self.updates += updates\n+            # params and constraints have the same size\n+            for p, c in zip(params, consts):\n+                if p not in self.params:\n+                    self.params.append(p)\n+                    self.constraints.append(c)\n+        py3 = sys.version_info[0] == 3\n+        if py3:\n+            self.function = marshal.dumps(function.__code__)\n+        else:\n+            self.function = marshal.dumps(function.func_code)\n+        if output_shape is None:\n+            output_shape = input_shape\n+        elif type(output_shape) in {tuple, list}:\n+            self._output_shape = tuple(output_shape)\n+        else:\n+            if py3:\n+                self._output_shape = marshal.dumps(output_shape.__code__)\n+            else:\n+                self._output_shape = marshal.dumps(output_shape.func_code)\n+\n+    @property\n+    def output_shape(self):\n+        if type(self._output_shape) == tuple:\n+            return self._output_shape\n+        else:\n+            output_shape_func = marshal.loads(self._output_shape)\n+            output_shape_func = types.FunctionType(output_shape_func, globals())\n+            shape = output_shape_func(layers)\n+            if type(shape) not in {list,tuple}:\n+                raise Exception (\"output_shape function must return a tuple\")\n+            return tuple(shape)\n+\n+\n+    def get_params(self):\n+        return self.params, self.regularizers, self.constraints, self.updates\n+\n+ \n+    def get_output(self, train=False):\n+        func = marshal.loads(self.function)\n+        func = types.FunctionType(func, globals())\n+        inputs=[layer.get_output(train) for layer in self.layers]\n+        return func(inputs)\n+\n+    def get_input(self, train=False):\n+        res = []\n+        for i in range(len(self.layers)):\n+            o = self.layers[i].get_input(train)\n+            if not type(o) == list:\n+                o = [o]\n+            for output in o:\n+                if output not in res:\n+                    res.append(output)\n+        return res\n+\n+    @property\n+    def input(self):\n+        return self.get_input()\n+\n+    def supports_masked_input(self):\n+        return False\n+\n+    def get_output_mask(self, train=None):\n+        return None\n+\n+    def get_weights(self):\n+        weights = []\n+        for l in self.layers:\n+            weights += l.get_weights()\n+        return weights\n+\n+    def set_weights(self, weights):\n+        for i in range(len(self.layers)):\n+            nb_param = len(self.layers[i].params)\n+            self.layers[i].set_weights(weights[:nb_param])\n+            weights = weights[nb_param:]\n+\n+    def get_config(self):\n+        config = {\"name\": self.__class__.__name__,\n+                  \"layers\": [l.get_config() for l in self.layers],\n+                  \"function\":self.function,\n+                  \"output_shape\":self._output_shape\n+                  }\n+        base_config = super(LambdaMerge, self).get_config()\n+        return dict(list(base_config.items()) + list(config.items()))\n+\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#feac8dba01dbd04fe37ed48beae115768753f8f5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 5 | Methods Changed: 4 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 10 | Churn Cumulative: 483 | Contributors (this commit): 4 | Commits (past 90d): 17 | Contributors (cumulative): 4 | DMM Complexity: 0.0\n\nDIFF:\n@@ -5,7 +5,7 @@ import numpy as np\n np.random.seed(1337)\n \n from keras.models import Sequential, model_from_json, model_from_yaml\n-from keras.layers.core import Dense, Activation, Merge, Lambda\n+from keras.layers.core import Dense, Activation, Merge, Lambda, LambdaMerge\n from keras.utils import np_utils\n from keras.utils.test_utils import get_test_data\n import pickle\n@@ -281,14 +281,13 @@ class TestSequential(unittest.TestCase):\n         print('Test lambda: sum')\n \n         def func(X):\n-            X = [X[i] for i in list(X)]\n             s = X[0]\n             for i in range(1,len(X)):\n                 s += X[i]\n             return s\n \n-        def output_shape(previous):\n-            return previous.layers[0].output_shape\n+        def output_shape(layers):\n+            return layers[0].output_shape\n \n         left = Sequential()\n         left.add(Dense(nb_hidden, input_shape=(input_dim,)))\n@@ -299,9 +298,8 @@ class TestSequential(unittest.TestCase):\n         right.add(Activation('relu'))\n         \n         model = Sequential()\n-        model.add(Merge([left, right], mode='join', auto_name=True))\n \n-        model.add(Lambda(function=func,output_shape=output_shape))\n+        model.add(LambdaMerge([left, right], function=func, output_shape=output_shape))\n \n         model.add(Dense(nb_class))\n         model.add(Activation('softmax'))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c015acb41341c66743b258a41d64f870bcdf3494", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2590 | Contributors (this commit): 25 | Commits (past 90d): 54 | Contributors (cumulative): 25 | DMM Complexity: None\n\nDIFF:\n@@ -965,7 +965,7 @@ class MaskedLambda(MaskedLayer, Lambda):\n \tpass\n \n class LambdaMerge(Lambda):\n-    def __init__(self, layers, function, output_shape=None, ndim=2)\n+    def __init__(self, layers, function, output_shape=None, ndim=2):\n         if len(layers) < 2:\n             raise Exception(\"Please specify two or more input layers (or containers) to merge\")\n         self.input = ndim_tensor(ndim)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6a052477115740af2eaf07fdb10b56c468a8ed3e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2592 | Contributors (this commit): 25 | Commits (past 90d): 55 | Contributors (cumulative): 25 | DMM Complexity: None\n\nDIFF:\n@@ -964,7 +964,7 @@ class Lambda(Layer):\n class MaskedLambda(MaskedLayer, Lambda):\n \tpass\n \n-class LambdaMerge(Lambda):\n+class LambdaMerge(Layer):\n     def __init__(self, layers, function, output_shape=None, ndim=2):\n         if len(layers) < 2:\n             raise Exception(\"Please specify two or more input layers (or containers) to merge\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cb836091ecd7502097e6e415222db0a2aca1021c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 2595 | Contributors (this commit): 25 | Commits (past 90d): 56 | Contributors (cumulative): 25 | DMM Complexity: 1.0\n\nDIFF:\n@@ -965,10 +965,9 @@ class MaskedLambda(MaskedLayer, Lambda):\n \tpass\n \n class LambdaMerge(Layer):\n-    def __init__(self, layers, function, output_shape=None, ndim=2):\n+    def __init__(self, layers, function, output_shape=None):\n         if len(layers) < 2:\n             raise Exception(\"Please specify two or more input layers (or containers) to merge\")\n-        self.input = ndim_tensor(ndim)\n         self.layers = layers\n         self.params = []\n         self.regularizers = []\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#42a65d4b83e0ac8267cb17f7d925990cb315f66b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2597 | Contributors (this commit): 25 | Commits (past 90d): 57 | Contributors (cumulative): 25 | DMM Complexity: None\n\nDIFF:\n@@ -1004,7 +1004,7 @@ class LambdaMerge(Layer):\n         else:\n             output_shape_func = marshal.loads(self._output_shape)\n             output_shape_func = types.FunctionType(output_shape_func, globals())\n-            shape = output_shape_func(layers)\n+            shape = output_shape_func(self.layers)\n             if type(shape) not in {list,tuple}:\n                 raise Exception (\"output_shape function must return a tuple\")\n             return tuple(shape)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#01a3e298fb35d537910574858007617024c94989", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 45 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 9 | Methods Changed: 5 | Complexity Δ (Sum/Max): -26/0 | Churn Δ: 50 | Churn Cumulative: 2647 | Contributors (this commit): 25 | Commits (past 90d): 58 | Contributors (cumulative): 25 | DMM Complexity: 0.025\n\nDIFF:\n@@ -276,21 +276,33 @@ class TimeDistributedMerge(Layer):\n \n \n class Merge(Layer):\n-    def __init__(self, layers, mode='sum', concat_axis=-1):\n+    def __init__(self, layers, mode='sum', concat_axis=-1, dot_axes=-1):\n         ''' Merge the output of a list of layers or containers into a single tensor.\n             mode: {'sum', 'mul', 'concat', 'ave', 'join'}\n         '''\n         if len(layers) < 2:\n             raise Exception(\"Please specify two or more input layers (or containers) to merge\")\n \n-        if mode not in {'sum', 'mul', 'concat', 'ave', 'join'}:\n+        if mode not in {'sum', 'mul', 'concat', 'ave', 'join', 'cos', 'dot'}:\n             raise Exception(\"Invalid merge mode: \" + str(mode))\n \n-        if mode in {'sum', 'mul', 'ave'}:\n+        if mode in {'sum', 'mul', 'ave', 'cos'}:\n             input_shapes = set([l.output_shape for l in layers])\n             if len(input_shapes) > 1:\n                 raise Exception(\"Only layers of same output shape can be merged using \" + mode + \" mode\")\n-\n+        if mode in {'cos', 'dot'}:\n+            if len(layers) > 2:\n+                raise Exception(mode + \" merge takes exactly 2 layers\")\n+            shape1 = layers[0].output_shape\n+            shape2 = layers[1].output_shape\n+            if mode == 'dot':\n+                if type(dot_axes) == int:\n+                    if dot_axes < 0:\n+                        dot_axes = len(shape1) - 1\n+                    dot_axes = [range(len(shape1) - dot_axes, len(shape2)), range(1, dot_axes + 1)]\n+                for i in range(len(dot_axes[0])):\n+                    if shape1[dot_axes[0][i]] != shape2[dot_axes[1][i]]:\n+                        raise Exception(\" Dot incompatible layers can not be merged using dot mode\")\n         elif mode == 'concat':\n             input_shapes = set([list(l.output_shape).pop(concat_axis) for l in layers])\n             if len(input_shapes) > 1:\n@@ -298,6 +310,7 @@ class Merge(Layer):\n \n         self.mode = mode\n         self.concat_axis = concat_axis\n+        self.dot_axes = dot_axes\n         self.layers = layers\n         self.params = []\n         self.regularizers = []\n@@ -325,6 +338,19 @@ class Merge(Layer):\n             return tuple(output_shape)\n         elif self.mode == 'join':\n             return None\n+        elif self.mode == 'dot':\n+            shape1 = list(input_shapes[0])\n+            shape2 = list(input_shapes[1])\n+            for i in self.dot_axes[0]:\n+                shape1.pop(i)\n+            for i in self.dot_axes[1]:\n+                shape2.pop(i)\n+            shape = shape1 + shape2[1:]\n+            if len(shape) == 1:\n+                shape.append(1)\n+            return tuple(shape)\n+        elif self.mode == 'cos':\n+            return tuple(input_shapes[0][0], 1)\n \n     def get_params(self):\n         return self.params, self.regularizers, self.constraints, self.updates\n@@ -354,6 +380,18 @@ class Merge(Layer):\n             for i in range(1, len(self.layers)):\n                 s *= self.layers[i].get_output(train)\n             return s\n+        elif self.mode == 'dot':\n+            l1 = self.layers[0].get_output(train)\n+            l2 = self.layers[1].get_output(train)\n+            output = T.batched_tensordot(l1, l2, self.dot_axes)\n+            output = output.dimshuffle((0, 'x'))\n+            return output\n+        elif self.mode == 'cos':\n+            l1 = self.layers[0].get_output(train)\n+            l2 = self.layers[1].get_output(train)\n+            output, _ = theano.scan(lambda v1, v2: T.dot(v1, v2)/T.sqrt(T.dot(v1, v1) * T.dot(v2, v2)), sequences=[l1, l2], outputs_info=None)\n+            output = output.dimshuffle((0, 'x'))\n+            return output\n         else:\n             raise Exception('Unknown merge mode')\n \n@@ -394,11 +432,13 @@ class Merge(Layer):\n         config = {\"name\": self.__class__.__name__,\n                   \"layers\": [l.get_config() for l in self.layers],\n                   \"mode\": self.mode,\n-                  \"concat_axis\": self.concat_axis}\n+                  \"concat_axis\": self.concat_axis,\n+                  \"dot_axes\": self.dot_axes}\n         base_config = super(Merge, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n \n \n+\n class Dropout(MaskedLayer):\n     '''\n         Hinton's dropout.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c34578aece6fc95a99d6b0e1007fa9f57752da3c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 35 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): -3/0 | Churn Δ: 35 | Churn Cumulative: 518 | Contributors (this commit): 4 | Commits (past 90d): 18 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -129,6 +129,41 @@ class TestSequential(unittest.TestCase):\n         print(nloss)\n         assert(loss == nloss)\n         \n+    def test_merge_dot1(self):\n+        print('Test merge: dot')\n+        left = Sequential()\n+        left.add(Dense(input_dim=input_dim, output_dim=nb_hidden))\n+        left.add(Activation('relu'))\n+\n+        right = Sequential()\n+        right.add(Dense(input_dim=input_dim, output_dim=nb_hidden))\n+        right.add(Activation('relu'))\n+\n+        model = Sequential()\n+        model.add(Merge([left, right], mode='dot', dot_axes=1))\n+\n+        model.add(Dense(nb_class))\n+        model.add(Activation('softmax'))\n+\n+        model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n+        \n+    def test_merge_dot2(self):\n+        print('Test merge: dot')\n+        left = Sequential()\n+        left.add(Dense(input_dim=input_dim, output_dim=nb_hidden))\n+        left.add(Activation('relu'))\n+\n+        right = Sequential()\n+        right.add(Dense(input_dim=input_dim, output_dim=nb_hidden))\n+        right.add(Activation('relu'))\n+\n+        model = Sequential()\n+        model.add(Merge([left, right], mode='dot', dot_axes=([1],[1])))\n+\n+        model.add(Dense(nb_class))\n+        model.add(Activation('softmax'))\n+\n+        model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n     def test_merge_concat(self):\n         print('Test merge: concat')\n         left = Sequential()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#21dcabb6e8f01cd702d071bf13d1f2b45a1110bd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 4 | Churn Cumulative: 522 | Contributors (this commit): 4 | Commits (past 90d): 19 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -331,8 +331,7 @@ class TestSequential(unittest.TestCase):\n         right.add(Dense(nb_hidden, input_shape=(input_dim,)))\n         right.add(Activation('relu'))\n         model = Sequential()\n-        model.add(Merge([left, right], mode='join'))\n-        model.add(Lambda(function=func,output_shape=output_shape))\n+        model.add(LambdaMerge([left, right], function=func, output_shape=output_shape))\n         model.add(Dense(nb_class))\n         model.add(Activation('softmax'))\n         model.load_weights('temp.h5')\n@@ -343,6 +342,7 @@ class TestSequential(unittest.TestCase):\n         assert(loss == nloss)\n         \n         print ('test serializing')\n+        func = None # Make sure that the model has the function code, not just the function name.\n         model_str = pickle.dumps(model)\n         model = pickle.loads(model_str)\n         nloss = model.evaluate([X_train, X_train], y_train, verbose=0)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7b0be6475763230dffc3631d93034273f5ecd130", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 30 | Lines Deleted: 14 | Files Changed: 1 | Hunks: 16 | Methods Changed: 4 | Complexity Δ (Sum/Max): 25/25 | Churn Δ: 44 | Churn Cumulative: 2691 | Contributors (this commit): 25 | Commits (past 90d): 59 | Contributors (cumulative): 25 | DMM Complexity: 0.8\n\nDIFF:\n@@ -16,8 +16,11 @@ from ..regularizers import ActivityRegularizer, Regularizer\n from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n from six.moves import zip\n \n-import marshal, types\n+import marshal\n+import types\n import sys\n+\n+\n class Layer(object):\n     def __init__(self, **kwargs):\n         for kwarg in kwargs:\n@@ -277,7 +280,7 @@ class TimeDistributedMerge(Layer):\n \n \n class Merge(Layer):\n-    def __init__(self, layers, mode='sum', concat_axis=-1, auto_name=False):\n+    def __init__(self, layers, mode='sum', concat_axis=-1):\n         ''' Merge the output of a list of layers or containers into a single tensor.\n             mode: {'sum', 'mul', 'concat', 'ave', 'join'}\n         '''\n@@ -299,7 +302,6 @@ class Merge(Layer):\n \n         self.mode = mode\n         self.concat_axis = concat_axis\n-        self.auto_name = auto_name\n         self.layers = layers\n         self.params = []\n         self.regularizers = []\n@@ -347,10 +349,7 @@ class Merge(Layer):\n             for i in range(len(self.layers)):\n                 X = self.layers[i].get_output(train)\n                 if X.name is None:\n-                    if self.auto_name == True:\n                     inputs['input' + str(i)] = self.layers[i].get_output(train)\n-                    else:\n-                        raise ValueError(\"merge_mode='join' only works with named inputs\")\n                 else:\n                     inputs[X.name] = self.layers[i].get_output(train)\n             return inputs\n@@ -399,8 +398,8 @@ class Merge(Layer):\n         config = {\"name\": self.__class__.__name__,\n                   \"layers\": [l.get_config() for l in self.layers],\n                   \"mode\": self.mode,\n-                  \"concat_axis\": self.concat_axis,\n-                  \"auto_name\": self.auto_name}\n+                  \"concat_axis\": self.concat_axis}\n+\n         base_config = super(Merge, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n \n@@ -910,6 +909,7 @@ class MaxoutDense(Layer):\n class Lambda(Layer):\n \n     \"\"\"Lambda layer for evaluating arbitrary function\n+\n     Input shape\n     -----------\n     output_shape of previous layer\n@@ -921,7 +921,7 @@ class Lambda(Layer):\n     Arguments\n     ---------\n     function - The function to be evaluated. Takes one argument : ouput of previous layer\n-\toutput_shape - Expected output shape from function. Could be a tuple or a function of input layers\n+    output_shape - Expected output shape from function. Could be a tuple or a function of input layer\n     \"\"\"\n \n     def __init__(self, function, output_shape=None, ndim=2):\n@@ -941,6 +941,7 @@ class Lambda(Layer):\n                 self._output_shape = marshal.dumps(output_shape.__code__)\n             else:\n                 self._output_shape = marshal.dumps(output_shape.func_code)\n+\n     @property\n     def output_shape(self):\n         if type(self._output_shape) == tuple:\n@@ -953,7 +954,6 @@ class Lambda(Layer):\n                 raise Exception(\"output_shape function must return a tuple\")\n             return tuple(shape)\n \n-\n     def get_output(self, train=False):\n         func = marshal.loads(self.function)\n         func = types.FunctionType(func, globals())\n@@ -961,10 +961,29 @@ class Lambda(Layer):\n             return func(self.previous.get_output(train))\n         else:\n             return func(self.input)\n+\n+\n class MaskedLambda(MaskedLayer, Lambda):\n     pass\n \n-class LambdaMerge(Layer):\n+\n+class LambdaMerge(Lambda):\n+    \"\"\"LambdaMerge layer for evaluating arbitrary function over multiple inputs\n+\n+    Input shape\n+    -----------\n+    None\n+\n+    Output shape\n+    ------------\n+    Specified by output_shape argument\n+\n+    Arguments\n+    ---------\n+    layers - Input layers. Similar to layers argument of Merge\n+    function - The function to be evaluated. Takes one argument : list of outputs from input layers\n+    output_shape - Expected output shape from function. Could be a tuple or a function of list of input layers\n+    \"\"\"\n     def __init__(self, layers, function, output_shape=None):\n         if len(layers) < 2:\n             raise Exception(\"Please specify two or more input layers (or containers) to merge\")\n@@ -1009,11 +1028,9 @@ class LambdaMerge(Layer):\n                 raise Exception(\"output_shape function must return a tuple\")\n             return tuple(shape)\n \n-\n     def get_params(self):\n         return self.params, self.regularizers, self.constraints, self.updates\n \n- \n     def get_output(self, train=False):\n         func = marshal.loads(self.function)\n         func = types.FunctionType(func, globals())\n@@ -1061,4 +1078,3 @@ class LambdaMerge(Layer):\n                   }\n         base_config = super(LambdaMerge, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n-\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fbe2ea653720fea9af41ce665021abda1566f01c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2693 | Contributors (this commit): 25 | Commits (past 90d): 60 | Contributors (cumulative): 25 | DMM Complexity: None\n\nDIFF:\n@@ -349,7 +349,7 @@ class Merge(Layer):\n             for i in range(len(self.layers)):\n                 X = self.layers[i].get_output(train)\n                 if X.name is None:\n-                    inputs['input' + str(i)] = self.layers[i].get_output(train)\n+                    raise ValueError(\"merge_mode='join' only works with named inputs\")\n                 else:\n                     inputs[X.name] = self.layers[i].get_output(train)\n             return inputs\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1f0178e793ebe8876d8bbd65b86e8acb2eb3ea32", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 2694 | Contributors (this commit): 25 | Commits (past 90d): 61 | Contributors (cumulative): 25 | DMM Complexity: None\n\nDIFF:\n@@ -399,7 +399,6 @@ class Merge(Layer):\n                   \"layers\": [l.get_config() for l in self.layers],\n                   \"mode\": self.mode,\n                   \"concat_axis\": self.concat_axis}\n-\n         base_config = super(Merge, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#22566c37ce75ec6ddecf62be27b8ba98456695e2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -25/0 | Churn Δ: 2 | Churn Cumulative: 2696 | Contributors (this commit): 25 | Commits (past 90d): 62 | Contributors (cumulative): 25 | DMM Complexity: None\n\nDIFF:\n@@ -298,7 +298,7 @@ class Merge(Layer):\n             if mode == 'dot':\n                 if type(dot_axes) == int:\n                     if dot_axes < 0:\n-                        dot_axes = len(shape1) - 1\n+                        dot_axes = dot_axes % len(shape1)\n                     dot_axes = [range(len(shape1) - dot_axes, len(shape2)), range(1, dot_axes + 1)]\n                 for i in range(len(dot_axes[0])):\n                     if shape1[dot_axes[0][i]] != shape2[dot_axes[1][i]]:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1c7585a5639970837a3e37b5c87ac8fe0f2ae212", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 220 | Contributors (this commit): 2 | Commits (past 90d): 4 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -32,7 +32,7 @@ class TestTasks(unittest.TestCase):\n         model.add(Dense(y_train.shape[-1]))\n         model.add(Activation('softmax'))\n         model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n-        history = model.fit(X_train, y_train, nb_epoch=12, batch_size=16, validation_data=(X_test, y_test), show_accuracy=True, verbose=2)\n+        history = model.fit(X_train, y_train, nb_epoch=15, batch_size=16, validation_data=(X_test, y_test), show_accuracy=True, verbose=2)\n         print(history.history)\n         self.assertTrue(history.history['val_acc'][-1] > 0.9)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#455d7d10db1b105e082747dedeae0352a6bb0f99", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 6 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 672 | Contributors (this commit): 11 | Commits (past 90d): 16 | Contributors (cumulative): 11 | DMM Complexity: 0.0\n\nDIFF:\n@@ -240,7 +240,7 @@ class Graph(Layer):\n                                   'dtype': dtype})\n \n     def add_node(self, layer, name, input=None, inputs=[],\n-                 merge_mode='concat', concat_axis=-1, create_output=False):\n+                 merge_mode='concat', concat_axis=-1, dot_axes=-1, create_output=False):\n         if hasattr(layer, 'set_name'):\n             layer.set_name(name)\n         if name in self.namespace:\n@@ -261,7 +261,7 @@ class Graph(Layer):\n                     to_merge.append(self.inputs[n])\n                 else:\n                     raise Exception('Unknown identifier: ' + n)\n-            merge = Merge(to_merge, mode=merge_mode, concat_axis=concat_axis)\n+            merge = Merge(to_merge, mode=merge_mode, concat_axis=concat_axis, dot_axes=dot_axes)\n             layer.set_previous(merge)\n \n         self.namespace.add(name)\n@@ -271,13 +271,14 @@ class Graph(Layer):\n                                  'inputs': inputs,\n                                  'merge_mode': merge_mode,\n                                  'concat_axis': concat_axis,\n+                                 'dot_axes': dot_axes,\n                                  'create_output': create_output})\n \n         if create_output:\n             self.add_output(name, input=name)\n \n     def add_output(self, name, input=None, inputs=[],\n-                   merge_mode='concat', concat_axis=-1):\n+                   merge_mode='concat', concat_axis=-1, dot_axes=-1):\n         if name in self.output_order:\n             raise Exception('Duplicate output identifier: ' + name)\n         if input:\n@@ -293,7 +294,7 @@ class Graph(Layer):\n                 if n not in self.nodes:\n                     raise Exception('Unknown identifier: ' + n)\n                 to_merge.append(self.nodes[n])\n-            merge = Merge(to_merge, mode=merge_mode, concat_axis=concat_axis)\n+            merge = Merge(to_merge, mode=merge_mode, concat_axis=concat_axis, dot_axes=dot_axes)\n             self.outputs[name] = merge\n \n         self.output_order.append(name)\n@@ -301,7 +302,8 @@ class Graph(Layer):\n                                    'input': input,\n                                    'inputs': inputs,\n                                    'merge_mode': merge_mode,\n-                                   'concat_axis': concat_axis})\n+                                   'concat_axis': concat_axis,\n+                                   'dot_axes': dot_axes})\n \n     def get_config(self):\n         return {\"name\": self.__class__.__name__,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a4552fb00492c47f67261a8c1b9538a0614cbb71", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 4 | Methods Changed: 1 | Complexity Δ (Sum/Max): 26/26 | Churn Δ: 11 | Churn Cumulative: 2707 | Contributors (this commit): 25 | Commits (past 90d): 63 | Contributors (cumulative): 25 | DMM Complexity: 1.0\n\nDIFF:\n@@ -919,8 +919,8 @@ class Lambda(Layer):\n \n     Arguments\n     ---------\n-    function - The function to be evaluated. Takes one argument : ouput of previous layer\n-    output_shape - Expected output shape from function. Could be a tuple or a function of input layer\n+    function - The function to be evaluated. Takes one argument : output of previous layer\n+    output_shape - Expected output shape from function. Could be a tuple or a function of the shape of the input\n     \"\"\"\n \n     def __init__(self, function, output_shape=None, ndim=2):\n@@ -948,7 +948,7 @@ class Lambda(Layer):\n         else:\n             output_shape_func = marshal.loads(self._output_shape)\n             output_shape_func = types.FunctionType(output_shape_func, globals())\n-            shape = output_shape_func(self.previous)\n+            shape = output_shape_func(self.previous.output_shape)\n             if type(shape) not in {list, tuple}:\n                 raise Exception(\"output_shape function must return a tuple\")\n             return tuple(shape)\n@@ -981,7 +981,7 @@ class LambdaMerge(Lambda):\n     ---------\n     layers - Input layers. Similar to layers argument of Merge\n     function - The function to be evaluated. Takes one argument : list of outputs from input layers\n-    output_shape - Expected output shape from function. Could be a tuple or a function of list of input layers\n+    output_shape - Expected output shape from function. Could be a tuple or a function of list of input shapes\n     \"\"\"\n     def __init__(self, layers, function, output_shape=None):\n         if len(layers) < 2:\n@@ -1022,7 +1022,8 @@ class LambdaMerge(Lambda):\n         else:\n             output_shape_func = marshal.loads(self._output_shape)\n             output_shape_func = types.FunctionType(output_shape_func, globals())\n-            shape = output_shape_func(self.layers)\n+            input_shapes = [layer.output_shape for layer in self.layers]\n+            shape = output_shape_func(input_shapes)\n             if type(shape) not in {list, tuple}:\n                 raise Exception(\"output_shape function must return a tuple\")\n             return tuple(shape)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
