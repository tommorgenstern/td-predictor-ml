{"custom_id": "keras#cbadaf00e28f7fe42762b55f52294e3a7bb90515", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 57 | Files Changed: 1 | Hunks: 14 | Methods Changed: 4 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 74 | Churn Cumulative: 600 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: 0.16129032258064516\n\nDIFF:\n@@ -146,7 +146,6 @@ def _make_divisible(v, divisor, min_value=None):\n def MobileNetV2(input_shape=None,\n                 alpha=1.0,\n                 depth_multiplier=1,\n-                dropout=1e-3,\n                 include_top=True,\n                 weights='imagenet',\n                 input_tensor=None,\n@@ -180,7 +179,6 @@ def MobileNetV2(input_shape=None,\n                  are used at each layer.\n         depth_multiplier: depth multiplier for depthwise convolution\n             (also called the resolution multiplier)\n-        dropout: dropout rate, dropout is currently not in use\n         include_top: whether to include the fully-connected\n             layer at the top of the network.\n         weights: one of `None` (random initialization),\n@@ -350,12 +348,8 @@ def MobileNetV2(input_shape=None,\n     x = BatchNormalization(epsilon=1e-3, momentum=0.999, name='bn_Conv1')(x)\n     x = Activation(relu6, name='Conv1_relu')(x)\n \n-    x = _first_inverted_res_block(x,\n-                                  filters=16,\n-                                  alpha=alpha,\n-                                  stride=1,\n-                                  expansion=1,\n-                                  block_id=0)\n+    x = _inverted_res_block(x, filters=16, alpha=alpha, stride=1,\n+                            expansion=1, block_id=0)\n \n     x = _inverted_res_block(x, filters=24, alpha=alpha, stride=2,\n                             expansion=6, block_id=1)\n@@ -454,73 +448,39 @@ def MobileNetV2(input_shape=None,\n \n def _inverted_res_block(inputs, expansion, stride, alpha, filters, block_id):\n     in_channels = inputs._keras_shape[-1]\n-    prefix = 'features.' + str(block_id) + '.conv.'\n     pointwise_conv_filters = int(filters * alpha)\n     pointwise_filters = _make_divisible(pointwise_conv_filters, 8)\n-    # Expand\n+    x = inputs\n+    prefix = 'block_{}_'.format(block_id)\n \n+    if block_id:\n+        # Expand\n         x = Conv2D(expansion * in_channels, kernel_size=1, padding='same',\n                    use_bias=False, activation=None,\n-               name='mobl%d_conv_expand' % block_id)(inputs)\n+                   name=prefix + 'expand')(x)\n         x = BatchNormalization(epsilon=1e-3, momentum=0.999,\n-                           name='bn%d_conv_bn_expand' %\n-                           block_id)(x)\n-    x = Activation(relu6, name='conv_%d_relu' % block_id)(x)\n+                               name=prefix + 'expand_BN')(x)\n+        x = Activation(relu6, name=prefix + 'expand_relu')(x)\n+    else:\n+        prefix = 'expanded_conv_'\n \n     # Depthwise\n     x = DepthwiseConv2D(kernel_size=3, strides=stride, activation=None,\n                         use_bias=False, padding='same',\n-                        name='mobl%d_conv_depthwise' % block_id)(x)\n+                        name=prefix + 'depthwise')(x)\n     x = BatchNormalization(epsilon=1e-3, momentum=0.999,\n-                           name='bn%d_conv_depthwise' % block_id)(x)\n+                           name=prefix + 'depthwise_BN')(x)\n \n-    x = Activation(relu6, name='conv_dw_%d_relu' % block_id)(x)\n+    x = Activation(relu6, name=prefix + 'depthwise_relu')(x)\n \n     # Project\n     x = Conv2D(pointwise_filters,\n                kernel_size=1, padding='same', use_bias=False, activation=None,\n-               name='mobl%d_conv_project' % block_id)(x)\n+               name=prefix + 'project')(x)\n     x = BatchNormalization(epsilon=1e-3, momentum=0.999,\n-                           name='bn%d_conv_bn_project' % block_id)(x)\n+                           name=prefix + 'project_BN')(x)\n \n     if in_channels == pointwise_filters and stride == 1:\n-        return Add(name='res_connect_' + str(block_id))([inputs, x])\n-\n-    return x\n-\n-\n-def _first_inverted_res_block(inputs,\n-                              expansion, stride,\n-                              alpha, filters, block_id):\n-    in_channels = inputs._keras_shape[-1]\n-    prefix = 'features.' + str(block_id) + '.conv.'\n-    pointwise_conv_filters = int(filters * alpha)\n-    pointwise_filters = _make_divisible(pointwise_conv_filters, 8)\n-\n-    # Depthwise\n-    x = DepthwiseConv2D(kernel_size=3,\n-                        strides=stride, activation=None,\n-                        use_bias=False, padding='same',\n-                        name='mobl%d_conv_depthwise' %\n-                        block_id)(inputs)\n-    x = BatchNormalization(epsilon=1e-3, momentum=0.999,\n-                           name='bn%d_conv_depthwise' %\n-                           block_id)(x)\n-    x = Activation(relu6, name='conv_dw_%d_relu' % block_id)(x)\n-\n-    # Project\n-    x = Conv2D(pointwise_filters,\n-               kernel_size=1,\n-               padding='same',\n-               use_bias=False,\n-               activation=None,\n-               name='mobl%d_conv_project' %\n-               block_id)(x)\n-    x = BatchNormalization(epsilon=1e-3, momentum=0.999,\n-                           name='bn%d_conv_project' %\n-                           block_id)(x)\n-\n-    if in_channels == pointwise_filters and stride == 1:\n-        return Add(name='res_connect_' + str(block_id))([inputs, x])\n+        return Add(name=prefix + 'add')([inputs, x])\n \n     return x\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b7c8c49d7bd36cf4180af81cf2e9aa3134d171fc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2969 | Contributors (this commit): 71 | Commits (past 90d): 8 | Contributors (cumulative): 71 | DMM Complexity: None\n\nDIFF:\n@@ -625,7 +625,7 @@ class LearningRateScheduler(Callback):\n             raise ValueError('Optimizer must have a \"lr\" attribute.')\n         lr = float(K.get_value(self.model.optimizer.lr))\n         try:  # new API\n-            lr = self.schedule(epoch, lr=lr)\n+            lr = self.schedule(epoch, lr)\n         except TypeError:  # old API for backward compatibility\n             lr = self.schedule(epoch)\n         if not isinstance(lr, (float, np.float32, np.float64)):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#32921f412bb8b228d5d15cc78682ea62bab99109", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 1524 | Contributors (this commit): 25 | Commits (past 90d): 7 | Contributors (cumulative): 25 | DMM Complexity: None\n\nDIFF:\n@@ -164,6 +164,7 @@ PAGES = [\n         'classes': [\n             layers.Conv1D,\n             layers.Conv2D,\n+            layers.SeparableConv1D,\n             layers.SeparableConv2D,\n             layers.Conv2DTranspose,\n             layers.Conv3D,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a6afe7c8149c61372b2aae6ae331d1584eb8a19e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 35 | Lines Deleted: 30 | Files Changed: 1 | Hunks: 14 | Methods Changed: 4 | Complexity Δ (Sum/Max): 7/7 | Churn Δ: 65 | Churn Cumulative: 5855 | Contributors (this commit): 82 | Commits (past 90d): 14 | Contributors (cumulative): 82 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1731,6 +1731,17 @@ def _preprocess_conv2d_kernel(kernel, data_format):\n     return kernel\n \n \n+def _preprocess_conv2d_depthwise_kernel(kernel, kernel_shape, data_format):\n+    # As of Keras 2.0.0, all kernels are normalized\n+    # on the format `(rows, cols, input_depth, depth)`,\n+    # independently of `data_format`.\n+    # Theano expects `(input_depth * depth, 1, rows, cols)` for depthwise convolution.\n+    kernel = kernel[::-1, ::-1, :, :]\n+    kernel = kernel.dimshuffle((2, 3, 0, 1))\n+    kernel = reshape(kernel, kernel_shape)\n+    return kernel\n+\n+\n def _preprocess_conv3d_kernel(kernel, data_format):\n     # As of Keras 2.0.0, all kernels are normalized\n     # on the format `(space, input_depth, depth)`,\n@@ -1799,6 +1810,21 @@ def _preprocess_conv2d_filter_shape(filter_shape, data_format):\n     return filter_shape\n \n \n+def _preprocess_conv2d_depthwise_filter_shape(filter_shape, data_format):\n+    # Theano might not accept long type\n+    def int_or_none(value):\n+        try:\n+            return int(value)\n+        except TypeError:\n+            return None\n+    if filter_shape:\n+        filter_shape = (filter_shape[3] * filter_shape[2], 1,\n+                        filter_shape[0], filter_shape[1])\n+    if filter_shape is not None:\n+        filter_shape = tuple(int_or_none(v) for v in filter_shape)\n+    return filter_shape\n+\n+\n def _preprocess_conv3d_filter_shape(filter_shape, data_format):\n     # Theano might not accept long type\n     def int_or_none(value):\n@@ -2032,31 +2058,24 @@ def separable_conv1d(x, depthwise_kernel, pointwise_kernel, strides=1,\n     depthwise_kernel_shape = int_shape(depthwise_kernel)\n     if depthwise_kernel_shape is None:\n         depthwise_kernel_shape = depthwise_kernel.eval().shape  # in case of a shared variable\n-    depthwise_kernel_shape = _preprocess_conv2d_filter_shape(depthwise_kernel_shape, data_format)\n+    depthwise_kernel_shape = _preprocess_conv2d_depthwise_filter_shape(depthwise_kernel_shape, data_format)\n     pointwise_kernel_shape = int_shape(pointwise_kernel)\n     if pointwise_kernel_shape is None:\n         pointwise_kernel_shape = pointwise_kernel.eval().shape  # in case of a shared variable\n     pointwise_kernel_shape = _preprocess_conv2d_filter_shape(pointwise_kernel_shape, data_format)\n \n     x = _preprocess_conv2d_input(x, data_format)\n-    depthwise_kernel = _preprocess_conv2d_kernel(depthwise_kernel, data_format)\n+    depthwise_kernel = _preprocess_conv2d_depthwise_kernel(depthwise_kernel, depthwise_kernel_shape, data_format)\n     pointwise_kernel = _preprocess_conv2d_kernel(pointwise_kernel, data_format)\n     th_padding = _preprocess_padding(padding)\n \n-    input_depth = depthwise_kernel_shape[1]\n-    output_depth = depthwise_kernel_shape[0]\n-    depthwise_kernel_shape = (input_depth * output_depth, 1) + depthwise_kernel_shape[2:]\n-    depthwise_kernel = depthwise_kernel.dimshuffle((1, 0, 2, 3))\n-    depthwise_kernel = reshape(depthwise_kernel, depthwise_kernel_shape)\n-    depthwise_kernel = depthwise_kernel[:, :, ::-1, ::-1]\n-\n     conv_out = T.nnet.conv2d(x, depthwise_kernel,\n                              border_mode=th_padding,\n                              subsample=strides,\n                              input_shape=image_shape,\n                              filter_shape=depthwise_kernel_shape,\n                              filter_dilation=dilation_rate,\n-                             num_groups=input_depth)\n+                             num_groups=image_shape[1])\n     conv_out = T.nnet.conv2d(conv_out, pointwise_kernel,\n                              border_mode=th_padding,\n                              subsample=(1, 1),\n@@ -2099,31 +2118,24 @@ def separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1),\n     depthwise_kernel_shape = int_shape(depthwise_kernel)\n     if depthwise_kernel_shape is None:\n         depthwise_kernel_shape = depthwise_kernel.eval().shape  # in case of a shared variable\n-    depthwise_kernel_shape = _preprocess_conv2d_filter_shape(depthwise_kernel_shape, data_format)\n+    depthwise_kernel_shape = _preprocess_conv2d_depthwise_filter_shape(depthwise_kernel_shape, data_format)\n     pointwise_kernel_shape = int_shape(pointwise_kernel)\n     if pointwise_kernel_shape is None:\n         pointwise_kernel_shape = pointwise_kernel.eval().shape  # in case of a shared variable\n     pointwise_kernel_shape = _preprocess_conv2d_filter_shape(pointwise_kernel_shape, data_format)\n \n     x = _preprocess_conv2d_input(x, data_format)\n-    depthwise_kernel = _preprocess_conv2d_kernel(depthwise_kernel, data_format)\n+    depthwise_kernel = _preprocess_conv2d_depthwise_kernel(depthwise_kernel, depthwise_kernel_shape, data_format)\n     pointwise_kernel = _preprocess_conv2d_kernel(pointwise_kernel, data_format)\n     th_padding = _preprocess_padding(padding)\n \n-    input_depth = depthwise_kernel_shape[1]\n-    output_depth = depthwise_kernel_shape[0]\n-    depthwise_kernel_shape = (input_depth * output_depth, 1) + depthwise_kernel_shape[2:]\n-    depthwise_kernel = depthwise_kernel.dimshuffle((1, 0, 2, 3))\n-    depthwise_kernel = reshape(depthwise_kernel, depthwise_kernel_shape)\n-    depthwise_kernel = depthwise_kernel[:, :, ::-1, ::-1]\n-\n     conv_out = T.nnet.conv2d(x, depthwise_kernel,\n                              border_mode=th_padding,\n                              subsample=strides,\n                              input_shape=image_shape,\n                              filter_shape=depthwise_kernel_shape,\n                              filter_dilation=dilation_rate,\n-                             num_groups=input_depth)\n+                             num_groups=image_shape[1])\n     conv_out = T.nnet.conv2d(conv_out, pointwise_kernel,\n                              border_mode=th_padding,\n                              subsample=(1, 1),\n@@ -2164,26 +2176,19 @@ def depthwise_conv2d(x, depthwise_kernel, strides=(1, 1), padding='valid',\n     depthwise_kernel_shape = int_shape(depthwise_kernel)\n     if depthwise_kernel_shape is None:\n         depthwise_kernel_shape = depthwise_kernel.eval().shape  # in case of a shared variable\n-    depthwise_kernel_shape = _preprocess_conv2d_filter_shape(depthwise_kernel_shape, data_format)\n+    depthwise_kernel_shape = _preprocess_conv2d_depthwise_filter_shape(depthwise_kernel_shape, data_format)\n \n     x = _preprocess_conv2d_input(x, data_format)\n-    depthwise_kernel = _preprocess_conv2d_kernel(depthwise_kernel, data_format)\n+    depthwise_kernel = _preprocess_conv2d_depthwise_kernel(depthwise_kernel, depthwise_kernel_shape, data_format)\n     th_padding = _preprocess_padding(padding)\n \n-    input_depth = depthwise_kernel_shape[1]\n-    output_depth = depthwise_kernel_shape[0]\n-    depthwise_kernel_shape = (input_depth * output_depth, 1) + depthwise_kernel_shape[2:]\n-    depthwise_kernel = depthwise_kernel.dimshuffle((1, 0, 2, 3))\n-    depthwise_kernel = reshape(depthwise_kernel, depthwise_kernel_shape)\n-    depthwise_kernel = depthwise_kernel[:, :, ::-1, ::-1]\n-\n     conv_out = T.nnet.conv2d(x, depthwise_kernel,\n                              border_mode=th_padding,\n                              subsample=strides,\n                              input_shape=image_shape,\n                              filter_shape=depthwise_kernel_shape,\n                              filter_dilation=dilation_rate,\n-                             num_groups=input_depth)\n+                             num_groups=image_shape[1])\n     conv_out = _postprocess_conv2d_output(conv_out, x, padding,\n                                           depthwise_kernel_shape, strides, data_format)\n     return conv_out\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d7884570b10951d156aa086ee29a4df9eab79cf3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 12 | Churn Cumulative: 1907 | Contributors (this commit): 6 | Commits (past 90d): 11 | Contributors (cumulative): 8 | DMM Complexity: 1.0\n\nDIFF:\n@@ -143,7 +143,7 @@ def NASNet(input_shape=None,\n         RuntimeError: If attempting to run this model with a\n             backend that does not support separable convolutions.\n     '''\n-    if K.backend() != 'tensorflow':\n+    if K.backend() in ['cntk', 'theano']:\n         raise RuntimeError('Only TensorFlow backend is currently supported, '\n                            'as other backends do not support '\n                            'separable convolution.')\n\n@@ -837,7 +837,15 @@ def _need_convert_kernel(original_backend):\n     uses_correlation = {'tensorflow': True,\n                         'theano': False,\n                         'cntk': True}\n-    return uses_correlation[original_backend] != uses_correlation[K.backend()]\n+    if original_backend not in uses_correlation:\n+        # By default, do not convert the kernels if the original backend is unknown\n+        return False\n+    if K.backend() in uses_correlation:\n+        current_uses_correlation = uses_correlation[K.backend()]\n+    else:\n+        # Assume unknown backends use correlation\n+        current_uses_correlation = True\n+    return uses_correlation[original_backend] != current_uses_correlation\n \n \n def load_weights_from_hdf5_group(f, layers, reshape=False):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bcf0031b54d555179be81c088cc3df0a723d7907", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 7 | Files Changed: 2 | Hunks: 5 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 21 | Churn Cumulative: 4519 | Contributors (this commit): 74 | Commits (past 90d): 13 | Contributors (cumulative): 97 | DMM Complexity: 0.42857142857142855\n\nDIFF:\n@@ -786,6 +786,10 @@ class TensorBoard(Callback):\n                         tf.summary.image(mapped_weight_name, w_img)\n \n                 if hasattr(layer, 'output'):\n+                    if isinstance(layer.output, list):\n+                        for i, output in enumerate(layer.output):\n+                            tf.summary.histogram('{}_out_{}'.format(layer.name, i), output)\n+                    else:\n                         tf.summary.histogram('{}_out'.format(layer.name),\n                                              layer.output)\n         self.merged = tf.summary.merge_all()\n\n@@ -10,9 +10,9 @@ from keras import optimizers\n from keras import initializers\n from keras import callbacks\n from keras.models import Sequential, Model\n-from keras.layers import Input, Dense, Dropout, add\n+from keras.layers import Input, Dense, Dropout, add, dot, Lambda\n from keras.layers.convolutional import Conv2D\n-from keras.layers.pooling import MaxPooling2D, GlobalAveragePooling2D\n+from keras.layers.pooling import MaxPooling2D, GlobalAveragePooling1D, GlobalAveragePooling2D\n from keras.utils.test_utils import get_test_data\n from keras.utils.test_utils import keras_test\n from keras import backend as K\n@@ -623,7 +623,7 @@ def test_TensorBoard_multi_input_output(tmpdir):\n     (X_train, y_train), (X_test, y_test) = get_test_data(\n         num_train=train_samples,\n         num_test=test_samples,\n-        input_shape=(input_dim,),\n+        input_shape=(input_dim, input_dim),\n         classification=True,\n         num_classes=num_classes)\n     y_test = np_utils.to_categorical(y_test)\n@@ -646,10 +646,13 @@ def test_TensorBoard_multi_input_output(tmpdir):\n             i += 1\n             i = i % max_batch_index\n \n-    inp1 = Input((input_dim,))\n-    inp2 = Input((input_dim,))\n-    inp = add([inp1, inp2])\n-    hidden = Dense(num_hidden, activation='relu')(inp)\n+    inp1 = Input((input_dim, input_dim))\n+    inp2 = Input((input_dim, input_dim))\n+    inp_3d = add([inp1, inp2])\n+    inp_2d = GlobalAveragePooling1D()(inp_3d)\n+    inp_pair = Lambda(lambda x: x)([inp_3d, inp_2d])  # test a layer with a list of output tensors\n+    hidden = dot(inp_pair, axes=-1)\n+    hidden = Dense(num_hidden, activation='relu')(hidden)\n     hidden = Dropout(0.1)(hidden)\n     output1 = Dense(num_classes, activation='softmax')(hidden)\n     output2 = Dense(num_classes, activation='softmax')(hidden)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#50411ccb0e7059ad2bd9286b64ffc2cda8957025", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 232 | Contributors (this commit): 13 | Commits (past 90d): 2 | Contributors (cumulative): 13 | DMM Complexity: None\n\nDIFF:\n@@ -12,7 +12,11 @@ from .common import cast_to_floatx\n from .common import image_data_format\n from .common import set_image_data_format\n \n-# Obtain Keras base dir path: either ~/.keras or /tmp.\n+# Set Keras base dir path given KERAS_HOME env variable, if applicable.\n+# Otherwise either ~/.keras or /tmp.\n+if 'KERAS_HOME' in os.environ:\n+    _keras_dir = os.environ.get('KERAS_HOME')\n+else:\n     _keras_base_dir = os.path.expanduser('~')\n     if not os.access(_keras_base_dir, os.W_OK):\n         _keras_base_dir = '/tmp'\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0511438e5b20ea08bd10786c0ef9310b8256f67a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 845 | Contributors (this commit): 5 | Commits (past 90d): 1 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -130,7 +130,7 @@ def resnet_layer(inputs,\n         activation (string): activation name\n         batch_normalization (bool): whether to include batch normalization\n         conv_first (bool): conv-bn-activation (True) or\n-            activation-bn-conv (False)\n+            bn-activation-conv (False)\n \n     # Returns\n         x (tensor): tensor as input to the next layer\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8532744ad3de309e807ade1b9b6eff9603305b1a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 47 | Lines Deleted: 14 | Files Changed: 2 | Hunks: 10 | Methods Changed: 3 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 61 | Churn Cumulative: 5383 | Contributors (this commit): 75 | Commits (past 90d): 24 | Contributors (cumulative): 80 | DMM Complexity: 0.9333333333333333\n\nDIFF:\n@@ -453,6 +453,26 @@ def count_leading_spaces(s):\n         return 0\n \n \n+def process_list_block(docstring, anchor, marker):\n+    anchor_pos = docstring.find(anchor)\n+    starting_point = anchor_pos + len(anchor) + 1\n+    block = \"\"\n+    if anchor_pos > -1:\n+        block = docstring[starting_point:docstring.find(\"\\n\\n\", starting_point)]\n+        # Place marker for later reinjection.\n+        docstring = docstring.replace(block, marker)\n+        # White spaces to be removed in order to correctly align the block.\n+        whitespace_n = re.search(\"[^\\s]\", block).start()\n+        # Remove the computed number of leading white spaces from each line.\n+        lines = [re.sub('^' + ' ' * whitespace_n, '', line) for line in block.split('\\n')]\n+        # Format docstring lists\n+        top_level_regex = r'^([^\\s\\\\\\(]+):(.*)'\n+        top_level_replacement = r'- __\\1__:\\2'\n+        lines = [re.sub(top_level_regex, top_level_replacement, line) for line in lines]\n+        block = '\\n'.join(lines)\n+    return docstring, block\n+\n+\n def process_docstring(docstring):\n     # First, extract code blocks and process them.\n     code_blocks = []\n@@ -492,19 +512,23 @@ def process_docstring(docstring):\n             code_blocks.append(snippet)\n             tmp = tmp[index:]\n \n+    # Format docstring lists.\n+    docstring, arguments = process_list_block(docstring, \"# Arguments\", \"$ARGUMENTS$\")\n+    docstring, returns = process_list_block(docstring, \"# Returns\", \"$RETURNS$\")\n+\n     # Format docstring section titles.\n     docstring = re.sub(r'\\n(\\s+)# (.*)\\n',\n                        r'\\n\\1__\\2__\\n\\n',\n                        docstring)\n-    # Format docstring lists.\n-    docstring = re.sub(r'    ([^\\s\\\\\\(]+):(.*)\\n',\n-                       r'    - __\\1__:\\2\\n',\n-                       docstring)\n \n     # Strip all leading spaces.\n     lines = docstring.split('\\n')\n     docstring = '\\n'.join([line.lstrip(' ') for line in lines])\n \n+    # Reinject arguments and returns blocks.\n+    docstring = docstring.replace(\"$ARGUMENTS$\", arguments)\n+    docstring = docstring.replace(\"$RETURNS$\", returns)\n+\n     # Reinject code blocks.\n     for i, code_block in enumerate(code_blocks):\n         docstring = docstring.replace(\n\n@@ -455,15 +455,25 @@ class ImageDataGenerator(object):\n         zca_whitening: Boolean. Apply ZCA whitening.\n         rotation_range: Int. Degree range for random rotations.\n         width_shift_range: Float, 1-D array-like or int\n-            float: fraction of total width, if < 1, or pixels if >= 1.\n-            1-D array-like: random elements from the array.\n-            int: integer number of pixels from interval\n+            - float: fraction of total width, if < 1, or pixels if >= 1.\n+            - 1-D array-like: random elements from the array.\n+            - int: integer number of pixels from interval\n                 `(-width_shift_range, +width_shift_range)`\n-            With `width_shift_range=2` possible values\n+            - With `width_shift_range=2` possible values\n                 are integers `[-1, 0, +1]`,\n             same as with `width_shift_range=[-1, 0, +1]`,\n             while with `width_shift_range=1.0` possible values are floats in\n             the interval [-1.0, +1.0).\n+        height_shift_range: Float, 1-D array-like or int\n+            - float: fraction of total height, if < 1, or pixels if >= 1.\n+            - 1-D array-like: random elements from the array.\n+            - int: integer number of pixels from interval\n+                `(-height_shift_range, +height_shift_range)`\n+            - With `height_shift_range=2` possible values\n+                are integers `[-1, 0, +1]`,\n+            same as with `height_shift_range=[-1, 0, +1]`,\n+            while with `height_shift_range=1.0` possible values are floats in\n+            the interval [-1.0, +1.0).\n         shear_range: Float. Shear Intensity\n             (Shear angle in counter-clockwise direction in degrees)\n         zoom_range: Float or [lower, upper]. Range for random zoom.\n@@ -473,10 +483,10 @@ class ImageDataGenerator(object):\n             Default is 'nearest'.\n             Points outside the boundaries of the input are filled\n             according to the given mode:\n-            'constant': kkkkkkkk|abcd|kkkkkkkk (cval=k)\n-            'nearest':  aaaaaaaa|abcd|dddddddd\n-            'reflect':  abcddcba|abcd|dcbaabcd\n-            'wrap':  abcdabcd|abcd|abcdabcd\n+            - 'constant': kkkkkkkk|abcd|kkkkkkkk (cval=k)\n+            - 'nearest':  aaaaaaaa|abcd|dddddddd\n+            - 'reflect':  abcddcba|abcd|dcbaabcd\n+            - 'wrap':  abcdabcd|abcd|abcdabcd\n         cval: Float or Int.\n             Value used for points outside the boundaries\n             when `fill_mode = \"constant\"`.\n@@ -725,7 +735,6 @@ class ImageDataGenerator(object):\n                 without any modifications.\n                 Can be used to feed the model miscellaneous data\n                 along with the images.\n-\n                 In case of grayscale data, the channels axis of the image array\n                 should have value 1, and in case\n                 of RGB data, it should have value 3.\n@@ -812,7 +821,7 @@ class ImageDataGenerator(object):\n                     \"sparse\" will be 1D integer labels,\n                 - \"input\" will be images identical\n                     to input images (mainly used to work with autoencoders).\n-                If None, no labels are returned\n+                - If None, no labels are returned\n                 (the generator will only yield batches of image data,\n                 which is useful to use with `model.predict_generator()`,\n                 `model.evaluate_generator()`, etc.).\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#90a13a2b3057336bbff25ad8689cc298246ed775", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 76 | Lines Deleted: 18 | Files Changed: 5 | Hunks: 23 | Methods Changed: 13 | Complexity Δ (Sum/Max): 4/1 | Churn Δ: 94 | Churn Cumulative: 18947 | Contributors (this commit): 143 | Commits (past 90d): 51 | Contributors (cumulative): 217 | DMM Complexity: 0.9629629629629629\n\nDIFF:\n@@ -2468,6 +2468,10 @@ def reverse(x, axes):\n     return C.slice(x, cntk_axes, begin_index, end_index, strides)\n \n \n+def slice(x, start, size):\n+    raise NotImplementedError\n+\n+\n def _reshape_batch(x, shape):\n     # there is a bug in cntk 2.1's unpack_batch implementation\n     if hasattr(C, 'unpack_batch') and _get_cntk_version() >= 2.2:\n\n@@ -2293,7 +2293,7 @@ def one_hot(indices, num_classes):\n \n \n def reverse(x, axes):\n-    \"\"\"Reverse a tensor along the specified axes.\n+    \"\"\"Reverses a tensor along the specified axes.\n \n     # Arguments\n         x: Tensor to reverse.\n@@ -2308,6 +2308,26 @@ def reverse(x, axes):\n     return tf.reverse(x, axes)\n \n \n+def slice(x, start, size):\n+    \"\"\"Extracts a slice from a tensor.\n+\n+    # Arguments\n+        x: Input tensor.\n+        start: Integer list/tuple or tensor\n+            indicating the start indices of the slice\n+            along each axis.\n+        size: Integer list/tuple or tensor\n+            indicating how many dimensions to slice\n+            along each axis.\n+\n+    # Returns\n+        Tensor `x[start[0]: start[0] + size[0],\n+                  ...,\n+                  start[-1]: start[-1] + size[-1]]`\n+    \"\"\"\n+    return tf.slice(x, start, size)\n+\n+\n # VALUE MANIPULATION\n \n \n\n@@ -1186,6 +1186,10 @@ def reverse(x, axes):\n     return x[slices]\n \n \n+def slice(x, start, size):\n+    raise NotImplementedError\n+\n+\n def pattern_broadcast(x, broadcastable):\n     return T.patternbroadcast(x, broadcastable)\n \n\n@@ -144,10 +144,11 @@ def multi_gpu_model(model, gpus=None, cpu_merge=True, cpu_relocation=False):\n                          'with the TensorFlow backend.')\n \n     available_devices = _get_available_devices()\n-    available_devices = [_normalize_device_name(name) for name in available_devices]\n+    available_devices = [_normalize_device_name(name)\n+                         for name in available_devices]\n     if not gpus:\n         # Using all visible GPUs when not specifying `gpus`\n-        # e.g. CUDA_VISIBLE_DEVICES=0,2 python3 keras_mgpu.py\n+        # e.g. CUDA_VISIBLE_DEVICES=0,2 python keras_mgpu.py\n         gpus = len([x for x in available_devices if 'gpu' in x])\n \n     if isinstance(gpus, (list, tuple)):\n@@ -171,7 +172,7 @@ def multi_gpu_model(model, gpus=None, cpu_merge=True, cpu_relocation=False):\n     for device in target_devices:\n         if device not in available_devices:\n             raise ValueError(\n-                'To call `multi_gpu_model` with `gpus=%d`, '\n+                'To call `multi_gpu_model` with `gpus=%s`, '\n                 'we expect the following devices to be available: %s. '\n                 'However this machine only has: %s. '\n                 'Try reducing `gpus`.' % (gpus,\n@@ -179,7 +180,7 @@ def multi_gpu_model(model, gpus=None, cpu_merge=True, cpu_relocation=False):\n                                           available_devices))\n \n     def get_slice(data, i, parts):\n-        shape = tf.shape(data)\n+        shape = K.shape(data)\n         batch_size = shape[:1]\n         input_shape = shape[1:]\n         step = batch_size // parts\n@@ -187,10 +188,10 @@ def multi_gpu_model(model, gpus=None, cpu_merge=True, cpu_relocation=False):\n             size = batch_size - step * i\n         else:\n             size = step\n-        size = tf.concat([size, input_shape], axis=0)\n-        stride = tf.concat([step, input_shape * 0], axis=0)\n+        size = K.concatenate([size, input_shape], axis=0)\n+        stride = K.concatenate([step, input_shape * 0], axis=0)\n         start = stride * i\n-        return tf.slice(data, start, size)\n+        return K.slice(data, start, size)\n \n     # Relocate the model definition under CPU device scope if needed\n     if cpu_relocation:\n@@ -209,7 +210,7 @@ def multi_gpu_model(model, gpus=None, cpu_merge=True, cpu_relocation=False):\n                 inputs = []\n                 # Retrieve a slice of the input.\n                 for x in model.inputs:\n-                    input_shape = tuple(x.get_shape().as_list())[1:]\n+                    input_shape = K.int_shape(x)[1:]\n                     slice_i = Lambda(get_slice,\n                                      output_shape=input_shape,\n                                      arguments={'i': i,\n\n@@ -9,11 +9,14 @@ from keras.utils import multi_gpu_model\n import numpy as np\n import pytest\n import time\n+import tempfile\n import tensorflow as tf\n+from keras.utils.test_utils import keras_test\n from keras.preprocessing.image import ImageDataGenerator\n \n \n-def multi_gpu_test_simple_model():\n+@keras_test\n+def test_multi_gpu_simple_model():\n     print('####### test simple model')\n     num_samples = 1000\n     input_dim = 10\n@@ -39,7 +42,8 @@ def multi_gpu_test_simple_model():\n     parallel_model.fit(x, y, epochs=epochs)\n \n \n-def multi_gpu_test_multi_io_model():\n+@keras_test\n+def test_multi_gpu_multi_io_model():\n     print('####### test multi-io model')\n     num_samples = 1000\n     input_dim_a = 10\n@@ -74,34 +78,63 @@ def multi_gpu_test_multi_io_model():\n     parallel_model.fit([a_x, b_x], [a_y, b_y], epochs=epochs)\n \n \n-def multi_gpu_test_invalid_devices():\n+@keras_test\n+def test_multi_gpu_invalid_devices():\n     input_shape = (1000, 10)\n     model = keras.models.Sequential()\n     model.add(keras.layers.Dense(10,\n                                  activation='relu',\n                                  input_shape=input_shape[1:]))\n     model.add(keras.layers.Dense(1, activation='sigmoid'))\n-    model.compile(loss='mse', optimizer='rmsprop')\n \n     x = np.random.random(input_shape)\n     y = np.random.random((input_shape[0], 1))\n     with pytest.raises(ValueError):\n         parallel_model = multi_gpu_model(model, gpus=10)\n+        parallel_model.compile(loss='mse', optimizer='rmsprop')\n         parallel_model.fit(x, y, epochs=2)\n \n     with pytest.raises(ValueError):\n         parallel_model = multi_gpu_model(model, gpus=[0, 2, 4, 6, 8])\n+        parallel_model.compile(loss='mse', optimizer='rmsprop')\n         parallel_model.fit(x, y, epochs=2)\n \n     with pytest.raises(ValueError):\n         parallel_model = multi_gpu_model(model, gpus=1)\n+        parallel_model.compile(loss='mse', optimizer='rmsprop')\n         parallel_model.fit(x, y, epochs=2)\n \n     with pytest.raises(ValueError):\n         parallel_model = multi_gpu_model(model, gpus=[0])\n+        parallel_model.compile(loss='mse', optimizer='rmsprop')\n         parallel_model.fit(x, y, epochs=2)\n \n \n+@keras_test\n+def test_serialization():\n+    model = keras.models.Sequential()\n+    model.add(keras.layers.Dense(3,\n+                                 input_shape=(4,)))\n+    model.add(keras.layers.Dense(4))\n+\n+    x = np.random.random((100, 4))\n+    y = np.random.random((100, 4))\n+\n+    parallel_model = multi_gpu_model(model, gpus=2)\n+    parallel_model.compile(loss='mse', optimizer='rmsprop')\n+    parallel_model.fit(x, y, epochs=1)\n+\n+    ref_output = parallel_model.predict(x)\n+\n+    _, fname = tempfile.mkstemp('.h5')\n+    parallel_model.save(fname)\n+\n+    K.clear_session()\n+    parallel_model = keras.models.load_model(fname)\n+    output = parallel_model.predict(x)\n+    np.testing.assert_allclose(ref_output, output, atol=1e-5)\n+\n+\n def multi_gpu_application_np_array_benchmark():\n     print('####### Xception benchmark - np i/o')\n     model_cls = keras.applications.Xception\n@@ -230,8 +263,4 @@ def multi_gpu_application_folder_generator_benchmark():\n \n \n if __name__ == '__main__':\n-    multi_gpu_test_simple_model()\n-    multi_gpu_test_multi_io_model()\n-    multi_gpu_test_invalid_devices()\n-    multi_gpu_application_np_array_benchmark()\n-    multi_gpu_application_folder_generator_benchmark()\n+    pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f0ce6bdaff2bb20cc7efc29efb6e54f2096675a4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 9 | Churn Cumulative: 295 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -15,6 +15,13 @@ from keras.utils.test_utils import keras_test\n from keras.preprocessing.image import ImageDataGenerator\n \n \n+available_devices = keras.utils.multi_gpu_utils._get_available_devices()\n+available_devices = [keras.utils.multi_gpu_utils._normalize_device_name(name)\n+                     for name in available_devices]\n+pytestmark = pytest.mark.skipif('/gpu:7' not in available_devices,\n+                                reason='Requires 8 GPUs.')\n+\n+\n @keras_test\n def test_multi_gpu_simple_model():\n     print('####### test simple model')\n@@ -167,7 +174,7 @@ def multi_gpu_application_np_array_benchmark():\n     total_time = time.time() - start_time\n     print('baseline inference:', total_time)\n \n-    for i in range(8, 9):\n+    for i in range(2, 9, 2):\n         K.clear_session()\n         with tf.device('/cpu:0'):\n             model = model_cls(weights=None,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#526e6ba32d4eee837d27d6fb40fabebdc2c5a0d0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 28 | Lines Deleted: 25 | Files Changed: 3 | Hunks: 14 | Methods Changed: 7 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 53 | Churn Cumulative: 18643 | Contributors (this commit): 141 | Commits (past 90d): 50 | Contributors (cumulative): 213 | DMM Complexity: None\n\nDIFF:\n@@ -13,6 +13,7 @@ import warnings\n C.set_global_option('align_axis', 1)\n \n b_any = any\n+py_slice = slice\n \n \n dev = C.device.use_default_device()\n@@ -2396,7 +2397,7 @@ def local_conv1d(inputs, kernel, kernel_size, strides, data_format=None):\n \n     xs = []\n     for i in range(output_length):\n-        slice_length = slice(i * stride,\n+        slice_length = py_slice(i * stride,\n                                 i * stride + kernel_size[0])\n         xs.append(reshape(inputs[:, slice_length, :],\n                           (-1, 1, feature_dim)))\n@@ -2430,9 +2431,9 @@ def local_conv2d(inputs,\n \n     for i in range(output_row):\n         for j in range(output_col):\n-            slice_row = slice(i * stride_row,\n+            slice_row = py_slice(i * stride_row,\n                                  i * stride_row + kernel_size[0])\n-            slice_col = slice(j * stride_col,\n+            slice_col = py_slice(j * stride_col,\n                                  j * stride_col + kernel_size[1])\n             if data_format == 'channels_first':\n                 xs.append(reshape(inputs[:, :, slice_row, slice_col],\n\n@@ -28,6 +28,7 @@ from .common import image_dim_ordering\n py_all = all\n py_any = any\n py_sum = sum\n+py_slice = slice\n \n # INTERNAL UTILS\n \n@@ -4260,7 +4261,7 @@ def local_conv1d(inputs, kernel, kernel_size, strides, data_format=None):\n \n     xs = []\n     for i in range(output_length):\n-        slice_length = slice(i * stride,\n+        slice_length = py_slice(i * stride,\n                                 i * stride + kernel_size[0])\n         xs.append(reshape(inputs[:, slice_length, :],\n                           (1, -1, feature_dim)))\n@@ -4314,9 +4315,9 @@ def local_conv2d(inputs, kernel, kernel_size, strides, output_shape, data_format\n     xs = []\n     for i in range(output_row):\n         for j in range(output_col):\n-            slice_row = slice(i * stride_row,\n+            slice_row = py_slice(i * stride_row,\n                                  i * stride_row + kernel_size[0])\n-            slice_col = slice(j * stride_col,\n+            slice_col = py_slice(j * stride_col,\n                                  j * stride_col + kernel_size[1])\n             if data_format == 'channels_first':\n                 xs.append(reshape(inputs[:, :, slice_row, slice_col],\n\n@@ -28,6 +28,7 @@ from .common import set_image_dim_ordering, image_dim_ordering\n py_all = all\n py_any = any\n py_sum = sum\n+py_slice = slice\n \n \n # INTERNAL UTILS\n@@ -1103,10 +1104,10 @@ def spatial_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None):\n                         input_shape[2] + top_pad + bottom_pad,\n                         input_shape[3] + left_pad + right_pad)\n         output = T.zeros(output_shape)\n-        indices = (slice(None),\n-                   slice(None),\n-                   slice(top_pad, input_shape[2] + top_pad),\n-                   slice(left_pad, input_shape[3] + left_pad))\n+        indices = (py_slice(None),\n+                   py_slice(None),\n+                   py_slice(top_pad, input_shape[2] + top_pad),\n+                   py_slice(left_pad, input_shape[3] + left_pad))\n \n     else:\n         output_shape = (input_shape[0],\n@@ -1114,10 +1115,10 @@ def spatial_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None):\n                         input_shape[2] + left_pad + right_pad,\n                         input_shape[3])\n         output = T.zeros(output_shape)\n-        indices = (slice(None),\n-                   slice(top_pad, input_shape[1] + top_pad),\n-                   slice(left_pad, input_shape[2] + left_pad),\n-                   slice(None))\n+        indices = (py_slice(None),\n+                   py_slice(top_pad, input_shape[1] + top_pad),\n+                   py_slice(left_pad, input_shape[2] + left_pad),\n+                   py_slice(None))\n     y = T.set_subtensor(output[indices], x)\n     y._keras_shape = output_shape\n     return y\n@@ -1140,11 +1141,11 @@ def spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None):\n                         input_shape[3] + padding[1][0] + padding[1][1],\n                         input_shape[4] + padding[2][0] + padding[2][1])\n         output = T.zeros(output_shape)\n-        indices = (slice(None),\n-                   slice(None),\n-                   slice(padding[0][0], input_shape[2] + padding[0][0]),\n-                   slice(padding[1][0], input_shape[3] + padding[1][0]),\n-                   slice(padding[2][0], input_shape[4] + padding[2][0]))\n+        indices = (py_slice(None),\n+                   py_slice(None),\n+                   py_slice(padding[0][0], input_shape[2] + padding[0][0]),\n+                   py_slice(padding[1][0], input_shape[3] + padding[1][0]),\n+                   py_slice(padding[2][0], input_shape[4] + padding[2][0]))\n \n     else:\n         output_shape = (input_shape[0],\n@@ -1153,11 +1154,11 @@ def spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None):\n                         input_shape[3] + padding[2][0] + padding[2][1],\n                         input_shape[4])\n         output = T.zeros(output_shape)\n-        indices = (slice(None),\n-                   slice(padding[0][0], input_shape[1] + padding[0][0]),\n-                   slice(padding[1][0], input_shape[2] + padding[1][0]),\n-                   slice(padding[2][0], input_shape[3] + padding[2][0]),\n-                   slice(None))\n+        indices = (py_slice(None),\n+                   py_slice(padding[0][0], input_shape[1] + padding[0][0]),\n+                   py_slice(padding[1][0], input_shape[2] + padding[1][0]),\n+                   py_slice(padding[2][0], input_shape[3] + padding[2][0]),\n+                   py_slice(None))\n     return T.set_subtensor(output[indices], x)\n \n \n@@ -1182,7 +1183,7 @@ def reverse(x, axes):\n     \"\"\"\n     if isinstance(axes, int):\n         axes = [axes]\n-    slices = [slice(None, None, -1) if i in axes else slice(None, None, None) for i in range(x.ndim)]\n+    slices = [py_slice(None, None, -1) if i in axes else py_slice(None, None, None) for i in range(x.ndim)]\n     return x[slices]\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e8fad1be1c1187926a02a35b7f25bc6ab7732699", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 6 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 13 | Churn Cumulative: 6206 | Contributors (this commit): 83 | Commits (past 90d): 20 | Contributors (cumulative): 84 | DMM Complexity: None\n\nDIFF:\n@@ -2663,7 +2663,7 @@ def local_conv1d(inputs, kernel, kernel_size, strides, data_format=None):\n \n     xs = []\n     for i in range(output_length):\n-        slice_length = slice(i * stride,\n+        slice_length = py_slice(i * stride,\n                                 i * stride + kernel_size[0])\n         xs.append(reshape(inputs[:, slice_length, :],\n                           (1, -1, feature_dim)))\n@@ -2688,9 +2688,9 @@ def local_conv2d(inputs, kernel, kernel_size, strides, output_shape, data_format\n         output = []\n         for i in range(output_row):\n             for j in range(output_col):\n-                slice_row = slice(i * stride_row,\n+                slice_row = py_slice(i * stride_row,\n                                      i * stride_row + kernel_size[0])\n-                slice_col = slice(j * stride_col,\n+                slice_col = py_slice(j * stride_col,\n                                      j * stride_col + kernel_size[1])\n                 x_flatten = reshape(inputs[:, :, slice_row, slice_col],\n                                     (1, -1, feature_dim))\n@@ -2704,9 +2704,9 @@ def local_conv2d(inputs, kernel, kernel_size, strides, output_shape, data_format\n         xs = []\n         for i in range(output_row):\n             for j in range(output_col):\n-                slice_row = slice(i * stride_row,\n+                slice_row = py_slice(i * stride_row,\n                                      i * stride_row + kernel_size[0])\n-                slice_col = slice(j * stride_col,\n+                slice_col = py_slice(j * stride_col,\n                                      j * stride_col + kernel_size[1])\n                 xs.append(reshape(inputs[:, slice_row, slice_col, :],\n                                   (1, -1, feature_dim)))\n\n@@ -15,6 +15,9 @@ from keras.utils.test_utils import keras_test\n from keras.preprocessing.image import ImageDataGenerator\n \n \n+pytestmark = pytest.mark.skipif(K.backend() != 'tensorflow',\n+                                reason='Requires TF.')\n+if K.backend() == 'tensorflow':\n     available_devices = keras.utils.multi_gpu_utils._get_available_devices()\n     available_devices = [keras.utils.multi_gpu_utils._normalize_device_name(name)\n                          for name in available_devices]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3e9048bccaba33805d96ec29f5139e5d6ec40358", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 705 | Contributors (this commit): 20 | Commits (past 90d): 6 | Contributors (cumulative): 20 | DMM Complexity: 0.0\n\nDIFF:\n@@ -333,9 +333,8 @@ class TimeseriesGenerator(Sequence):\n                              % (self.start_index, self.end_index))\n \n     def __len__(self):\n-        return int(np.ceil(\n-            (self.end_index - self.start_index + 1) /\n-            (self.batch_size * self.stride)))\n+        return (self.end_index - self.start_index +\n+                self.batch_size * self.stride) // (self.batch_size * self.stride)\n \n     def _empty_batch(self, num_rows):\n         samples_shape = [num_rows, self.length // self.sampling_rate]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
