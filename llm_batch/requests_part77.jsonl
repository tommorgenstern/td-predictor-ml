{"custom_id": "requests#4d8cb3244e8e4f84b250c10a48e025f9a8bf6137", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 51 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 7/7 | Churn Δ: 52 | Churn Cumulative: 2780 | Contributors (this commit): 52 | Commits (past 90d): 12 | Contributors (cumulative): 52 | DMM Complexity: 0.0\n\nDIFF:\n@@ -12,6 +12,7 @@ import os\n from collections import Mapping\n from datetime import datetime\n \n+from .auth import _basic_auth_str\n from .compat import cookielib, OrderedDict, urljoin, urlparse, builtin_str\n from .cookies import (\n     cookiejar_from_dict, extract_cookies_to_jar, RequestsCookieJar, merge_cookies)\n@@ -23,7 +24,10 @@ from .structures import CaseInsensitiveDict\n \n from .adapters import HTTPAdapter\n \n-from .utils import requote_uri, get_environ_proxies, get_netrc_auth\n+from .utils import (\n+    requote_uri, get_environ_proxies, get_netrc_auth, should_bypass_proxies,\n+    get_auth_from_url\n+)\n \n from .status_codes import codes\n \n@@ -154,6 +158,8 @@ class SessionRedirectMixin(object):\n             prepared_request._cookies.update(self.cookies)\n             prepared_request.prepare_cookies(prepared_request._cookies)\n \n+            # Rebuild auth and proxy information.\n+            proxies = self.rebuild_proxies(prepared_request, proxies)\n             self.rebuild_auth(prepared_request, resp)\n \n             resp = self.send(\n@@ -196,6 +202,50 @@ class SessionRedirectMixin(object):\n \n         return\n \n+    def rebuild_proxies(self, prepared_request, proxies):\n+        \"\"\"\n+        This method re-evaluates the proxy configuration by considering the\n+        environment variables. If we are redirected to a URL covered by\n+        NO_PROXY, we strip the proxy configuration. Otherwise, we set missing\n+        proxy keys for this URL (in case they were stripped by a previous\n+        redirect).\n+\n+        This method also replaces the Proxy-Authorization header where\n+        necessary.\n+        \"\"\"\n+        headers = prepared_request.headers\n+        url = prepared_request.url\n+        new_proxies = {}\n+\n+        # Consider proxies. First evaluate the new proxy config. If we are\n+        # being redirected to a host on the NO_PROXY list then we want to\n+        # remove the proxy dictionary entirely. Otherwise, if there's a relevant\n+        # environment proxy, set it if we don't already have a proxy to go to.\n+        if not should_bypass_proxies(url):\n+            environ_proxies = get_environ_proxies(url)\n+            scheme = urlparse(url).scheme\n+\n+            try:\n+                new_proxies.setdefault(scheme, environ_proxies[scheme])\n+            except KeyError:\n+                pass\n+\n+        # If there's a proxy-authorization header present, remove it, then add\n+        # a new one (potentially re-adding the one we just removed).\n+        if 'Proxy-Authorization' in headers:\n+            del headers['Proxy-Authorization']\n+\n+        try:\n+            username, password = get_auth_from_url(new_proxies[scheme])\n+            if username and password:\n+                headers['Proxy-Authorization'] = _basic_auth_str(\n+                    username, password\n+                )\n+        except KeyError:\n+            pass\n+\n+        return new_proxies\n+\n \n class Session(SessionRedirectMixin):\n     \"\"\"A Requests session.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#4f6dca42ea0fb3d1c4706e63e594e43f7a3237f7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 2786 | Contributors (this commit): 52 | Commits (past 90d): 13 | Contributors (cumulative): 52 | DMM Complexity: None\n\nDIFF:\n@@ -217,10 +217,6 @@ class SessionRedirectMixin(object):\n         url = prepared_request.url\n         new_proxies = {}\n \n-        # Consider proxies. First evaluate the new proxy config. If we are\n-        # being redirected to a host on the NO_PROXY list then we want to\n-        # remove the proxy dictionary entirely. Otherwise, if there's a relevant\n-        # environment proxy, set it if we don't already have a proxy to go to.\n         if not should_bypass_proxies(url):\n             environ_proxies = get_environ_proxies(url)\n             scheme = urlparse(url).scheme\n@@ -230,8 +226,6 @@ class SessionRedirectMixin(object):\n             except KeyError:\n                 pass\n \n-        # If there's a proxy-authorization header present, remove it, then add\n-        # a new one (potentially re-adding the one we just removed).\n         if 'Proxy-Authorization' in headers:\n             del headers['Proxy-Authorization']\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#724038e4b5e94addb0bf6c767b7f5578b172c659", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 17 | Churn Cumulative: 4372 | Contributors (this commit): 73 | Commits (past 90d): 13 | Contributors (cumulative): 73 | DMM Complexity: 1.0\n\nDIFF:\n@@ -17,6 +17,7 @@ from requests.compat import (\n     Morsel, cookielib, getproxies, str, urljoin, urlparse)\n from requests.cookies import cookiejar_from_dict, morsel_to_cookie\n from requests.exceptions import InvalidURL, MissingSchema\n+from requests.models import PreparedRequest, Response\n from requests.structures import CaseInsensitiveDict\n \n try:\n@@ -865,6 +866,22 @@ class RequestsTestCase(unittest.TestCase):\n             preq = req.prepare()\n             assert test_url == preq.url\n \n+    def test_auth_is_stripped_on_redirect_off_host(self):\n+        r = requests.get(\n+            httpbin('redirect-to'),\n+            params={'url': 'http://www.google.co.uk'},\n+            auth=('user', 'pass'),\n+        )\n+        assert r.history[0].request.headers['Authorization']\n+        assert not r.request.headers.get('Authorization', '')\n+\n+    def test_auth_is_retained_for_redirect_on_host(self):\n+        r = requests.get(httpbin('redirect/1'), auth=('user', 'pass'))\n+        h1 = r.history[0].request.headers['Authorization']\n+        h2 = r.request.headers['Authorization']\n+\n+        assert h1 == h2\n+\n \n class TestContentEncodingDetection(unittest.TestCase):\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#daf56b3f62f91c7b6ae783ef74ee41ff3c7af89f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): -9/0 | Churn Δ: 11 | Churn Cumulative: 7169 | Contributors (this commit): 102 | Commits (past 90d): 28 | Contributors (cumulative): 125 | DMM Complexity: 1.0\n\nDIFF:\n@@ -527,7 +527,6 @@ class Session(SessionRedirectMixin):\n             history.insert(0, r)\n             # Get the last request made\n             r = history.pop()\n-            r.history = tuple(history)\n \n         return r\n \n\n@@ -211,6 +211,16 @@ class RequestsTestCase(unittest.TestCase):\n         req_urls = [r.request.url for r in resp.history]\n         assert urls == req_urls\n \n+    def test_history_is_always_a_list(self):\n+        \"\"\"\n+        Show that even with redirects, Response.history is always a list.\n+        \"\"\"\n+        resp = requests.get(httpbin('get'))\n+        assert isinstance(resp.history, list)\n+        resp = requests.get(httpbin('redirect/1'))\n+        assert isinstance(resp.history, list)\n+        assert not isinstance(resp.history, tuple)\n+\n     def test_headers_on_session_with_None_are_not_sent(self):\n         \"\"\"Do not send headers in Session.headers with None values.\"\"\"\n         ses = requests.Session()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#8d693a2a27d0a073c0d03823cab71a3716001285", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 65 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 5 | Methods Changed: 6 | Complexity Δ (Sum/Max): 6/6 | Churn Δ: 66 | Churn Cumulative: 7235 | Contributors (this commit): 102 | Commits (past 90d): 30 | Contributors (cumulative): 125 | DMM Complexity: 0.972972972972973\n\nDIFF:\n@@ -168,8 +168,11 @@ class SessionRedirectMixin(object):\n             if new_auth is not None:\n                 prepared_request.prepare_auth(new_auth)\n \n+            # Override the original request.\n+            req = prepared_request\n+\n             resp = self.send(\n-                prepared_request,\n+                req,\n                 stream=stream,\n                 timeout=timeout,\n                 verify=verify,\n\n@@ -8,6 +8,7 @@ import json\n import os\n import pickle\n import unittest\n+import collections\n \n import requests\n import pytest\n@@ -18,6 +19,7 @@ from requests.compat import (\n from requests.cookies import cookiejar_from_dict, morsel_to_cookie\n from requests.exceptions import InvalidURL, MissingSchema\n from requests.structures import CaseInsensitiveDict\n+from requests.sessions import SessionRedirectMixin\n \n try:\n     import StringIO\n@@ -1187,5 +1189,64 @@ class TestTimeout:\n             assert 'Read timed out' in e.args[0].args[0]\n \n \n+SendCall = collections.namedtuple('SendCall', ('args', 'kwargs'))\n+\n+\n+class RedirectSession(SessionRedirectMixin):\n+    def __init__(self, order_of_redirects):\n+        self.redirects = order_of_redirects\n+        self.calls = []\n+        self.max_redirects = 30\n+        self.cookies = {}\n+        self.trust_env = False\n+\n+    def send(self, *args, **kwargs):\n+        self.calls.append(SendCall(args, kwargs))\n+        return self.build_response()\n+\n+    def build_response(self):\n+        request = self.calls[-1].args[0]\n+        r = requests.Response()\n+\n+        try:\n+            r.status_code = int(self.redirects.pop(0))\n+        except IndexError:\n+            r.status_code = 200\n+\n+        r.headers = CaseInsensitiveDict({'Location': '/'})\n+        r.raw = self._build_raw()\n+        r.request = request\n+        return r\n+\n+    def _build_raw(self):\n+        string = StringIO.StringIO('')\n+        setattr(string, 'release_conn', lambda *args: args)\n+        return string\n+\n+\n+class TestRedirects:\n+    default_keyword_args = {\n+        'stream': False,\n+        'verify': True,\n+        'cert': None,\n+        'timeout': None,\n+        'allow_redirects': False,\n+        'proxies': None,\n+    }\n+\n+    def test_requests_are_updated_each_time(self):\n+        session = RedirectSession([303, 307])\n+        prep = requests.Request('POST', 'http://httpbin.org/post').prepare()\n+        r0 = session.send(prep)\n+        assert r0.request.method == 'POST'\n+        assert session.calls[-1] == SendCall((r0.request,), {})\n+        redirect_generator = session.resolve_redirects(r0, prep)\n+        for response in redirect_generator:\n+            assert response.request.method == 'GET'\n+            send_call = SendCall((response.request,),\n+                                 TestRedirects.default_keyword_args)\n+            assert session.calls[-1] == send_call\n+\n+\n if __name__ == '__main__':\n     unittest.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#8fc6a65be892651e6f16597fcaf9e608ab5d958b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 2793 | Contributors (this commit): 52 | Commits (past 90d): 16 | Contributors (cumulative): 52 | DMM Complexity: 0.0\n\nDIFF:\n@@ -527,6 +527,7 @@ class Session(SessionRedirectMixin):\n             history.insert(0, r)\n             # Get the last request made\n             r = history.pop()\n+            r.history = history\n \n         return r\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#98ac3df71369a6cf9bde35b8e5c8dc5935b028d0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 3 | Churn Cumulative: 1721 | Contributors (this commit): 10 | Commits (past 90d): 1 | Contributors (cumulative): 10 | DMM Complexity: 1.0\n\nDIFF:\n@@ -108,6 +108,9 @@ class CaseInsensitiveDict(collections.MutableMapping):\n     def __repr__(self):\n         return '%s(%r)' % (self.__class__.__name__, dict(self.items()))\n \n+    def __str__(self):\n+        return '%s' % (dict(self.items())\n+\n \n class LookupDict(dict):\n     \"\"\"Dictionary lookup object.\"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#90f73378582e4e2cbc75a189a2cfa7826824f29e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 4 | Methods Changed: 1 | Complexity Δ (Sum/Max): 8/8 | Churn Δ: 15 | Churn Cumulative: 2808 | Contributors (this commit): 52 | Commits (past 90d): 16 | Contributors (cumulative): 52 | DMM Complexity: 1.0\n\nDIFF:\n@@ -221,22 +221,21 @@ class SessionRedirectMixin(object):\n             environ_proxies = get_environ_proxies(url)\n             scheme = urlparse(url).scheme\n \n-            try:\n+            proxy = environ_proxies.get(scheme)\n+\n+            if proxy:\n                 new_proxies.setdefault(scheme, environ_proxies[scheme])\n-            except KeyError:\n-                pass\n \n         if 'Proxy-Authorization' in headers:\n             del headers['Proxy-Authorization']\n \n         try:\n             username, password = get_auth_from_url(new_proxies[scheme])\n-            if username and password:\n-                headers['Proxy-Authorization'] = _basic_auth_str(\n-                    username, password\n-                )\n         except KeyError:\n-            pass\n+            username, password = None, None\n+\n+        if username and password:\n+            headers['Proxy-Authorization'] = _basic_auth_str(username, password)\n \n         return new_proxies\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#a3fb689942e8a215858ef0619d0ec95e22186c77", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1723 | Contributors (this commit): 10 | Commits (past 90d): 2 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -109,7 +109,7 @@ class CaseInsensitiveDict(collections.MutableMapping):\n         return '%s(%r)' % (self.__class__.__name__, dict(self.items()))\n \n     def __str__(self):\n-        return '%s' % (dict(self.items())\n+        return '%s' % (dict(self.items()))\n \n \n class LookupDict(dict):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#c2e6fe4d5dfbb2bf4e31d70bb7c3f3eda2435beb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1725 | Contributors (this commit): 10 | Commits (past 90d): 3 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -109,7 +109,7 @@ class CaseInsensitiveDict(collections.MutableMapping):\n         return '%s(%r)' % (self.__class__.__name__, dict(self.items()))\n \n     def __str__(self):\n-        return '%s' % (dict(self.items()))\n+        return str(dict(self.items()))\n \n \n class LookupDict(dict):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#b92f4ec6fb8e53c71603dcd91f8e0883539e678d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 2 | Churn Cumulative: 4445 | Contributors (this commit): 73 | Commits (past 90d): 13 | Contributors (cumulative): 73 | DMM Complexity: None\n\nDIFF:\n@@ -1258,7 +1258,7 @@ class TestRedirects:\n         'cert': None,\n         'timeout': None,\n         'allow_redirects': False,\n-        'proxies': None,\n+        'proxies': {},\n     }\n \n     def test_requests_are_updated_each_time(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#24819e8aae62170ed2c8439e400cc16423207660", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 28 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 31 | Churn Cumulative: 13568 | Contributors (this commit): 157 | Commits (past 90d): 34 | Contributors (cumulative): 201 | DMM Complexity: 1.0\n\nDIFF:\n@@ -408,9 +408,7 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n \n         is_stream = all([\n             hasattr(data, '__iter__'),\n-            not isinstance(data, basestring),\n-            not isinstance(data, list),\n-            not isinstance(data, dict)\n+            not isinstance(data, (basestring, list, tuple, dict))\n         ])\n \n         try:\n\n@@ -21,6 +21,8 @@ from requests.exceptions import InvalidURL, MissingSchema\n from requests.models import PreparedRequest, Response\n from requests.structures import CaseInsensitiveDict\n from requests.sessions import SessionRedirectMixin\n+from requests.models import PreparedRequest, urlencode\n+from requests.hooks import default_hooks\n \n try:\n     import StringIO\n@@ -1275,5 +1277,30 @@ class TestRedirects:\n             assert session.calls[-1] == send_call\n \n \n+@pytest.fixture\n+def list_of_tuples():\n+    return [\n+            (('a', 'b'), ('c', 'd')),\n+            (('c', 'd'), ('a', 'b')),\n+            (('a', 'b'), ('c', 'd'), ('e', 'f')),\n+            ]\n+\n+\n+def test_data_argument_accepts_tuples(list_of_tuples):\n+    \"\"\"\n+    Ensure that the data argument will accept tuples of strings\n+    and properly encode them.\n+    \"\"\"\n+    for data in list_of_tuples:\n+        p = PreparedRequest()\n+        p.prepare(\n+            method='GET',\n+            url='http://www.example.com',\n+            data=data,\n+            hooks=default_hooks()\n+        )\n+        assert p.body == urlencode(data)\n+        \n+\n if __name__ == '__main__':\n     unittest.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#6c839985b9520ceeb0e48f204d86c92eb018bf3e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 219 | Lines Deleted: 68 | Files Changed: 8 | Hunks: 46 | Methods Changed: 23 | Complexity Δ (Sum/Max): 24/20 | Churn Δ: 287 | Churn Cumulative: 5509 | Contributors (this commit): 14 | Commits (past 90d): 13 | Contributors (cumulative): 42 | DMM Complexity: 0.8260869565217391\n\nDIFF:\n@@ -10,7 +10,7 @@ urllib3 - Thread-safe connection pooling and re-using.\n \n __author__ = 'Andrey Petrov (andrey.petrov@shazow.net)'\n __license__ = 'MIT'\n-__version__ = 'dev'\n+__version__ = '1.8'\n \n \n from .connectionpool import (\n\n@@ -4,7 +4,7 @@\n # This module is part of urllib3 and is released under\n # the MIT License: http://www.opensource.org/licenses/mit-license.php\n \n-from collections import MutableMapping\n+from collections import Mapping, MutableMapping\n try:\n     from threading import RLock\n except ImportError: # Platform-specific: No threads available\n@@ -20,9 +20,10 @@ try: # Python 2.7+\n     from collections import OrderedDict\n except ImportError:\n     from .packages.ordered_dict import OrderedDict\n+from .packages.six import itervalues\n \n \n-__all__ = ['RecentlyUsedContainer']\n+__all__ = ['RecentlyUsedContainer', 'HTTPHeaderDict']\n \n \n _Null = object()\n@@ -101,3 +102,104 @@ class RecentlyUsedContainer(MutableMapping):\n     def keys(self):\n         with self.lock:\n             return self._container.keys()\n+\n+\n+class HTTPHeaderDict(MutableMapping):\n+    \"\"\"\n+    :param headers:\n+        An iterable of field-value pairs. Must not contain multiple field names\n+        when compared case-insensitively.\n+\n+    :param kwargs:\n+        Additional field-value pairs to pass in to ``dict.update``.\n+\n+    A ``dict`` like container for storing HTTP Headers.\n+\n+    Field names are stored and compared case-insensitively in compliance with\n+    RFC 2616. Iteration provides the first case-sensitive key seen for each\n+    case-insensitive pair.\n+\n+    Using ``__setitem__`` syntax overwrites fields that compare equal\n+    case-insensitively in order to maintain ``dict``'s api. For fields that\n+    compare equal, instead create a new ``HTTPHeaderDict`` and use ``.add``\n+    in a loop.\n+\n+    If multiple fields that are equal case-insensitively are passed to the\n+    constructor or ``.update``, the behavior is undefined and some will be\n+    lost.\n+\n+    >>> headers = HTTPHeaderDict()\n+    >>> headers.add('Set-Cookie', 'foo=bar')\n+    >>> headers.add('set-cookie', 'baz=quxx')\n+    >>> headers['content-length'] = '7'\n+    >>> headers['SET-cookie']\n+    'foo=bar, baz=quxx'\n+    >>> headers['Content-Length']\n+    '7'\n+\n+    If you want to access the raw headers with their original casing\n+    for debugging purposes you can access the private ``._data`` attribute\n+    which is a normal python ``dict`` that maps the case-insensitive key to a\n+    list of tuples stored as (case-sensitive-original-name, value). Using the\n+    structure from above as our example:\n+\n+    >>> headers._data\n+    {'set-cookie': [('Set-Cookie', 'foo=bar'), ('set-cookie', 'baz=quxx')],\n+    'content-length': [('content-length', '7')]}\n+    \"\"\"\n+\n+    def __init__(self, headers=None, **kwargs):\n+        self._data = {}\n+        if headers is None:\n+            headers = {}\n+        self.update(headers, **kwargs)\n+\n+    def add(self, key, value):\n+        \"\"\"Adds a (name, value) pair, doesn't overwrite the value if it already\n+        exists.\n+\n+        >>> headers = HTTPHeaderDict(foo='bar')\n+        >>> headers.add('Foo', 'baz')\n+        >>> headers['foo']\n+        'bar, baz'\n+        \"\"\"\n+        self._data.setdefault(key.lower(), []).append((key, value))\n+\n+    def getlist(self, key):\n+        \"\"\"Returns a list of all the values for the named field. Returns an\n+        empty list if the key doesn't exist.\"\"\"\n+        return self[key].split(', ') if key in self else []\n+\n+    def copy(self):\n+        h = HTTPHeaderDict()\n+        for key in self._data:\n+            for rawkey, value in self._data[key]:\n+                h.add(rawkey, value)\n+        return h\n+\n+    def __eq__(self, other):\n+        if not isinstance(other, Mapping):\n+            return False\n+        other = HTTPHeaderDict(other)\n+        return dict((k1, self[k1]) for k1 in self._data) == \\\n+                dict((k2, other[k2]) for k2 in other._data)\n+\n+    def __getitem__(self, key):\n+        values = self._data[key.lower()]\n+        return ', '.join(value[1] for value in values)\n+\n+    def __setitem__(self, key, value):\n+        self._data[key.lower()] = [(key, value)]\n+\n+    def __delitem__(self, key):\n+        del self._data[key.lower()]\n+\n+    def __len__(self):\n+        return len(self._data)\n+\n+    def __iter__(self):\n+        for headers in itervalues(self._data):\n+            yield headers[0][0]\n+\n+    def __repr__(self):\n+        return '%s(%r)' % (self.__class__.__name__, dict(self.items()))\n\n@@ -4,6 +4,7 @@\n # This module is part of urllib3 and is released under\n # the MIT License: http://www.opensource.org/licenses/mit-license.php\n \n+import sys\n import socket\n from socket import timeout as SocketTimeout\n \n@@ -38,6 +39,7 @@ from .exceptions import (\n     ConnectTimeoutError,\n )\n from .packages.ssl_match_hostname import match_hostname\n+from .packages import six\n from .util import (\n     assert_fingerprint,\n     resolve_cert_reqs,\n@@ -53,26 +55,39 @@ port_by_scheme = {\n \n \n class HTTPConnection(_HTTPConnection, object):\n+    \"\"\"\n+    Based on httplib.HTTPConnection but provides an extra constructor\n+    backwards-compatibility layer between older and newer Pythons.\n+    \"\"\"\n+\n     default_port = port_by_scheme['http']\n \n     # By default, disable Nagle's Algorithm.\n     tcp_nodelay = 1\n \n+    def __init__(self, *args, **kw):\n+        if six.PY3:  # Python 3\n+            kw.pop('strict', None)\n+\n+        if sys.version_info < (2, 7):  # Python 2.6 and earlier\n+            kw.pop('source_address', None)\n+            self.source_address = None\n+\n+        _HTTPConnection.__init__(self, *args, **kw)\n+\n     def _new_conn(self):\n         \"\"\" Establish a socket connection and set nodelay settings on it\n \n         :return: a new socket connection\n         \"\"\"\n-        try:\n-            conn = socket.create_connection(\n-                (self.host, self.port),\n-                self.timeout,\n-                self.source_address,\n-            )\n-        except AttributeError: # Python 2.6\n+        extra_args = []\n+        if self.source_address:  # Python 2.7+\n+            extra_args.append(self.source_address)\n+\n         conn = socket.create_connection(\n             (self.host, self.port),\n             self.timeout,\n+            *extra_args\n         )\n         conn.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY,\n                         self.tcp_nodelay)\n@@ -95,10 +110,12 @@ class HTTPSConnection(HTTPConnection):\n     def __init__(self, host, port=None, key_file=None, cert_file=None,\n                  strict=None, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,\n                  source_address=None):\n-        try:\n-            HTTPConnection.__init__(self, host, port, strict, timeout, source_address)\n-        except TypeError: # Python 2.6\n-            HTTPConnection.__init__(self, host, port, strict, timeout)\n+\n+        HTTPConnection.__init__(self, host, port,\n+                                strict=strict,\n+                                timeout=timeout,\n+                                source_address=source_address)\n+\n         self.key_file = key_file\n         self.cert_file = cert_file\n \n\n@@ -19,6 +19,7 @@ except ImportError:\n \n from .exceptions import (\n     ClosedPoolError,\n+    ConnectionError,\n     ConnectTimeoutError,\n     EmptyPoolError,\n     HostChangedError,\n@@ -170,13 +171,9 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n         log.info(\"Starting new HTTP connection (%d): %s\" %\n                  (self.num_connections, self.host))\n \n-        extra_params = {}\n-        if not six.PY3:  # Python 2\n-            extra_params['strict'] = self.strict\n-\n         conn = self.ConnectionCls(host=self.host, port=self.port,\n                                   timeout=self.timeout.connect_timeout,\n-                                  **extra_params)\n+                                  strict=self.strict)\n         if self.proxy is not None:\n             # Enable Nagle's algorithm for proxies, to avoid packet\n             # fragmentation.\n@@ -238,8 +235,9 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n             pass\n         except Full:\n             # This should never happen if self.block == True\n-            log.warning(\"HttpConnectionPool is full, discarding connection: %s\"\n-                        % self.host)\n+            log.warning(\n+                \"Connection pool is full, discarding connection: %s\" %\n+                self.host)\n \n         # Connection never got put back into the pool, close it.\n         if conn:\n@@ -414,10 +412,13 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n \n         :param retries:\n             Number of retries to allow before raising a MaxRetryError exception.\n+            If `False`, then retries are disabled and any exception is raised\n+            immediately.\n \n         :param redirect:\n             If True, automatically handle redirects (status codes 301, 302,\n-            303, 307, 308). Each redirect counts as a retry.\n+            303, 307, 308). Each redirect counts as a retry. Disabling retries\n+            will disable redirect, too.\n \n         :param assert_same_host:\n             If ``True``, will make sure that the host of the pool requests is\n@@ -451,7 +452,7 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n         if headers is None:\n             headers = self.headers\n \n-        if retries < 0:\n+        if retries < 0 and retries is not False:\n             raise MaxRetryError(self, url)\n \n         if release_conn is None:\n@@ -470,6 +471,10 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n             headers = headers.copy()\n             headers.update(self.proxy_headers)\n \n+        # Must keep the exception bound to a separate variable or else Python 3\n+        # complains about UnboundLocalError.\n+        err = None\n+\n         try:\n             # Request a connection from the queue\n             conn = self._get_conn(timeout=pool_timeout)\n@@ -497,38 +502,41 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n             #     ``response.read()``)\n \n         except Empty:\n-            # Timed out by queue\n+            # Timed out by queue.\n             raise EmptyPoolError(self, \"No pool connections are available.\")\n \n-        except BaseSSLError as e:\n+        except (BaseSSLError, CertificateError) as e:\n+            # Release connection unconditionally because there is no way to\n+            # close it externally in case of exception.\n+            release_conn = True\n             raise SSLError(e)\n \n-        except CertificateError as e:\n-            # Name mismatch\n-            raise SSLError(e)\n-\n-        except TimeoutError as e:\n-            # Connection broken, discard.\n+        except (TimeoutError, HTTPException, SocketError) as e:\n+            if conn:\n+                # Discard the connection for these exceptions. It will be\n+                # be replaced during the next _get_conn() call.\n+                conn.close()\n                 conn = None\n-            # Save the error off for retry logic.\n-            err = e\n \n-            if retries == 0:\n+            if not retries:\n+                if isinstance(e, TimeoutError):\n+                    # TimeoutError is exempt from MaxRetryError-wrapping.\n+                    # FIXME: ... Not sure why. Add a reason here.\n                     raise\n \n-        except (HTTPException, SocketError) as e:\n-            # Connection broken, discard. It will be replaced next _get_conn().\n-            conn = None\n-            # This is necessary so we can access e below\n-            err = e\n+                # Wrap unexpected exceptions with the most appropriate\n+                # module-level exception and re-raise.\n+                if isinstance(e, SocketError) and self.proxy:\n+                    raise ProxyError('Cannot connect to proxy.', e)\n+\n+                if retries is False:\n+                    raise ConnectionError('Connection failed.', e)\n \n-            if retries == 0:\n-                if isinstance(e, SocketError) and self.proxy is not None:\n-                    raise ProxyError('Cannot connect to proxy. '\n-                                     'Socket error: %s.' % e)\n-                else:\n                 raise MaxRetryError(self, url, e)\n \n+            # Keep track of the error for the retry warning.\n+            err = e\n+\n         finally:\n             if release_conn:\n                 # Put the connection back to be reused. If the connection is\n@@ -538,7 +546,7 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n \n         if not conn:\n             # Try again\n-            log.warn(\"Retrying (%d attempts remain) after connection \"\n+            log.warning(\"Retrying (%d attempts remain) after connection \"\n                         \"broken by '%r': %s\" % (retries, err, url))\n             return self.urlopen(method, url, body, headers, retries - 1,\n                                 redirect, assert_same_host,\n@@ -547,7 +555,7 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n \n         # Handle redirect?\n         redirect_location = redirect and response.get_redirect_location()\n-        if redirect_location:\n+        if redirect_location and retries is not False:\n             if response.status == 303:\n                 method = 'GET'\n             log.info(\"Redirecting %s -> %s\" % (url, redirect_location))\n\n@@ -29,9 +29,8 @@ Module Variables\n ----------------\n \n :var DEFAULT_SSL_CIPHER_LIST: The list of supported SSL/TLS cipher suites.\n-    Default: ``EECDH+ECDSA+AESGCM EECDH+aRSA+AESGCM EECDH+ECDSA+SHA256\n-    EECDH+aRSA+SHA256 EECDH+aRSA+RC4 EDH+aRSA EECDH RC4 !aNULL !eNULL !LOW !3DES\n-    !MD5 !EXP !PSK !SRP !DSS'``\n+    Default: ``ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:\n+    ECDH+3DES:DH+3DES:RSA+AESGCM:RSA+AES:RSA+3DES:!aNULL:!MD5:!DSS``\n \n .. _sni: https://en.wikipedia.org/wiki/Server_Name_Indication\n .. _crime attack: https://en.wikipedia.org/wiki/CRIME_(security_exploit)\n@@ -43,7 +42,7 @@ from ndg.httpsclient.subj_alt_name import SubjectAltName as BaseSubjectAltName\n import OpenSSL.SSL\n from pyasn1.codec.der import decoder as der_decoder\n from pyasn1.type import univ, constraint\n-from socket import _fileobject\n+from socket import _fileobject, timeout\n import ssl\n import select\n from cStringIO import StringIO\n@@ -69,12 +68,22 @@ _openssl_verify = {\n                        + OpenSSL.SSL.VERIFY_FAIL_IF_NO_PEER_CERT,\n }\n \n-# Default SSL/TLS cipher list.\n-# Recommendation by https://community.qualys.com/blogs/securitylabs/2013/08/05/\n-# configuring-apache-nginx-and-openssl-for-forward-secrecy\n-DEFAULT_SSL_CIPHER_LIST = 'EECDH+ECDSA+AESGCM EECDH+aRSA+AESGCM ' + \\\n-        'EECDH+ECDSA+SHA256 EECDH+aRSA+SHA256 EECDH+aRSA+RC4 EDH+aRSA ' + \\\n-        'EECDH RC4 !aNULL !eNULL !LOW !3DES !MD5 !EXP !PSK !SRP !DSS'\n+# A secure default.\n+# Sources for more information on TLS ciphers:\n+#\n+# - https://wiki.mozilla.org/Security/Server_Side_TLS\n+# - https://www.ssllabs.com/projects/best-practices/index.html\n+# - https://hynek.me/articles/hardening-your-web-servers-ssl-ciphers/\n+#\n+# The general intent is:\n+# - Prefer cipher suites that offer perfect forward secrecy (DHE/ECDHE),\n+# - prefer ECDHE over DHE for better performance,\n+# - prefer any AES-GCM over any AES-CBC for better performance and security,\n+# - use 3DES as fallback which is secure but slow,\n+# - disable NULL authentication, MD5 MACs and DSS for security reasons.\n+DEFAULT_SSL_CIPHER_LIST = \"ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:\" + \\\n+    \"ECDH+AES128:DH+AES:ECDH+3DES:DH+3DES:RSA+AESGCM:RSA+AES:RSA+3DES:\" + \\\n+    \"!aNULL:!MD5:!DSS\"\n \n \n orig_util_HAS_SNI = util.HAS_SNI\n@@ -139,6 +148,13 @@ def get_subj_alt_name(peer_cert):\n \n class fileobject(_fileobject):\n \n+    def _wait_for_sock(self):\n+        rd, wd, ed = select.select([self._sock], [], [],\n+                                   self._sock.gettimeout())\n+        if not rd:\n+            raise timeout()\n+\n+\n     def read(self, size=-1):\n         # Use max, disallow tiny reads in a loop as they are very inefficient.\n         # We never leave read() with any leftover data from a new recv() call\n@@ -156,6 +172,7 @@ class fileobject(_fileobject):\n                 try:\n                     data = self._sock.recv(rbufsize)\n                 except OpenSSL.SSL.WantReadError:\n+                    self._wait_for_sock()\n                     continue\n                 if not data:\n                     break\n@@ -183,6 +200,7 @@ class fileobject(_fileobject):\n                 try:\n                     data = self._sock.recv(left)\n                 except OpenSSL.SSL.WantReadError:\n+                    self._wait_for_sock()\n                     continue\n                 if not data:\n                     break\n@@ -234,6 +252,7 @@ class fileobject(_fileobject):\n                                 break\n                             buffers.append(data)\n                     except OpenSSL.SSL.WantReadError:\n+                        self._wait_for_sock()\n                         continue\n                     break\n                 return \"\".join(buffers)\n@@ -244,6 +263,7 @@ class fileobject(_fileobject):\n                 try:\n                     data = self._sock.recv(self._rbufsize)\n                 except OpenSSL.SSL.WantReadError:\n+                    self._wait_for_sock()\n                     continue\n                 if not data:\n                     break\n@@ -271,6 +291,7 @@ class fileobject(_fileobject):\n                 try:\n                     data = self._sock.recv(self._rbufsize)\n                 except OpenSSL.SSL.WantReadError:\n+                    self._wait_for_sock()\n                     continue\n                 if not data:\n                     break\n@@ -366,6 +387,8 @@ def ssl_wrap_socket(sock, keyfile=None, certfile=None, cert_reqs=None,\n             ctx.load_verify_locations(ca_certs, None)\n         except OpenSSL.SSL.Error as e:\n             raise ssl.SSLError('bad ca_certs: %r' % ca_certs, e)\n+    else:\n+        ctx.set_default_verify_paths()\n \n     # Disable TLS compression to migitate CRIME attack (issue #309)\n     OP_NO_COMPRESSION = 0x20000\n\n@@ -44,6 +44,11 @@ class ProxyError(HTTPError):\n     pass\n \n \n+class ConnectionError(HTTPError):\n+    \"Raised when a normal connection fails.\"\n+    pass\n+\n+\n class DecodeError(HTTPError):\n     \"Raised when automatic decoding based on Content-Type fails.\"\n     pass\n\n@@ -7,7 +7,7 @@ except ImportError:\n         from backports.ssl_match_hostname import CertificateError, match_hostname\n     except ImportError:\n         # Our vendored copy\n-        from _implementation import CertificateError, match_hostname\n+        from ._implementation import CertificateError, match_hostname\n \n # Not needed, but documenting what we provide.\n __all__ = ('CertificateError', 'match_hostname')\n\n@@ -9,6 +9,7 @@ import logging\n import zlib\n import io\n \n+from ._collections import HTTPHeaderDict\n from .exceptions import DecodeError\n from .packages.six import string_types as basestring, binary_type\n from .util import is_fp_closed\n@@ -79,7 +80,10 @@ class HTTPResponse(io.IOBase):\n     def __init__(self, body='', headers=None, status=0, version=0, reason=None,\n                  strict=0, preload_content=True, decode_content=True,\n                  original_response=None, pool=None, connection=None):\n-        self.headers = headers or {}\n+\n+        self.headers = HTTPHeaderDict()\n+        if headers:\n+            self.headers.update(headers)\n         self.status = status\n         self.version = version\n         self.reason = reason\n@@ -249,17 +253,9 @@ class HTTPResponse(io.IOBase):\n         with ``original_response=r``.\n         \"\"\"\n \n-        # Normalize headers between different versions of Python\n-        headers = {}\n+        headers = HTTPHeaderDict()\n         for k, v in r.getheaders():\n-            # Python 3: Header keys are returned capitalised\n-            k = k.lower()\n-\n-            has_value = headers.get(k)\n-            if has_value: # Python 3: Repeating header keys are unmerged.\n-                v = ', '.join([has_value, v])\n-\n-            headers[k] = v\n+            headers.add(k, v)\n \n         # HTTPResponse objects in Python 3 don't have a .strict attribute\n         strict = getattr(r, 'strict', 0)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#4ca4865170ac98226ca214854975ce02062cdcac", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2169 | Contributors (this commit): 50 | Commits (past 90d): 9 | Contributors (cumulative): 50 | DMM Complexity: None\n\nDIFF:\n@@ -61,7 +61,7 @@ def super_len(o):\n             return os.fstat(fileno).st_size\n \n     if hasattr(o, 'getvalue'):\n-        # e.g. BytesIO, cStringIO.StringI\n+        # e.g. BytesIO, cStringIO.StringIO\n         return len(o.getvalue())\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#36b0481f24aa45a0229791630b467971dd58c92f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 737 | Lines Deleted: 677 | Files Changed: 12 | Hunks: 34 | Methods Changed: 60 | Complexity Δ (Sum/Max): 4/31 | Churn Δ: 1414 | Churn Cumulative: 6033 | Contributors (this commit): 15 | Commits (past 90d): 16 | Contributors (cumulative): 44 | DMM Complexity: 0.7142857142857143\n\nDIFF:\n@@ -10,7 +10,7 @@ urllib3 - Thread-safe connection pooling and re-using.\n \n __author__ = 'Andrey Petrov (andrey.petrov@shazow.net)'\n __license__ = 'MIT'\n-__version__ = '1.8'\n+__version__ = '1.8.2'\n \n \n from .connectionpool import (\n\n@@ -68,15 +68,17 @@ class HTTPConnection(_HTTPConnection, object):\n     def __init__(self, *args, **kw):\n         if six.PY3:  # Python 3\n             kw.pop('strict', None)\n-\n-        if sys.version_info < (2, 7):  # Python 2.6 and earlier\n+        if sys.version_info < (2, 7):  # Python 2.6 and older\n             kw.pop('source_address', None)\n-            self.source_address = None\n \n+        # Pre-set source_address in case we have an older Python like 2.6.\n+        self.source_address = kw.get('source_address')\n+\n+        # Superclass also sets self.source_address in Python 2.7+.\n         _HTTPConnection.__init__(self, *args, **kw)  \n \n     def _new_conn(self):\n-        \"\"\" Establish a socket connection and set nodelay settings on it\n+        \"\"\" Establish a socket connection and set nodelay settings on it.\n \n         :return: a new socket connection\n         \"\"\"\n@@ -85,12 +87,10 @@ class HTTPConnection(_HTTPConnection, object):\n             extra_args.append(self.source_address)\n \n         conn = socket.create_connection(\n-            (self.host, self.port),\n-            self.timeout,\n-            *extra_args\n-        )\n-        conn.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY,\n-                        self.tcp_nodelay)\n+            (self.host, self.port), self.timeout, *extra_args)\n+        conn.setsockopt(\n+            socket.IPPROTO_TCP, socket.TCP_NODELAY, self.tcp_nodelay)\n+\n         return conn\n \n     def _prepare_conn(self, conn):\n@@ -108,17 +108,18 @@ class HTTPSConnection(HTTPConnection):\n     default_port = port_by_scheme['https']\n \n     def __init__(self, host, port=None, key_file=None, cert_file=None,\n-                 strict=None, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,\n-                 source_address=None):\n+                 strict=None, timeout=socket._GLOBAL_DEFAULT_TIMEOUT, **kw):\n \n-        HTTPConnection.__init__(self, host, port,\n-                                strict=strict,\n-                                timeout=timeout,\n-                                source_address=source_address)\n+        HTTPConnection.__init__(self, host, port, strict=strict,\n+                                timeout=timeout, **kw)\n \n         self.key_file = key_file\n         self.cert_file = cert_file\n \n+        # Required property for Google AppEngine 1.9.0 which otherwise causes\n+        # HTTPS requests to go out as HTTP. (See Issue #356)\n+        self._protocol = 'https'\n+\n     def connect(self):\n         conn = self._new_conn()\n         self._prepare_conn(conn)\n@@ -133,6 +134,7 @@ class VerifiedHTTPSConnection(HTTPSConnection):\n     cert_reqs = None\n     ca_certs = None\n     ssl_version = None\n+    conn_kw = {}\n \n     def set_cert(self, key_file=None, cert_file=None,\n                  cert_reqs=None, ca_certs=None,\n@@ -147,11 +149,11 @@ class VerifiedHTTPSConnection(HTTPSConnection):\n \n     def connect(self):\n         # Add certificate verification\n+\n         try:\n             sock = socket.create_connection(\n-                address=(self.host, self.port),\n-                timeout=self.timeout,\n-            )\n+                address=(self.host, self.port), timeout=self.timeout,\n+                **self.conn_kw)\n         except SocketTimeout:\n             raise ConnectTimeoutError(\n                 self, \"Connection to %s timed out. (connect timeout=%s)\" %\n\n@@ -4,6 +4,7 @@\n # This module is part of urllib3 and is released under\n # the MIT License: http://www.opensource.org/licenses/mit-license.php\n \n+import sys\n import errno\n import logging\n \n@@ -23,6 +24,7 @@ from .exceptions import (\n     ConnectTimeoutError,\n     EmptyPoolError,\n     HostChangedError,\n+    LocationParseError,\n     MaxRetryError,\n     SSLError,\n     TimeoutError,\n@@ -40,7 +42,6 @@ from .connection import (\n from .request import RequestMethods\n from .response import HTTPResponse\n from .util import (\n-    assert_fingerprint,\n     get_host,\n     is_connection_dropped,\n     Timeout,\n@@ -65,6 +66,9 @@ class ConnectionPool(object):\n     QueueCls = LifoQueue\n \n     def __init__(self, host, port=None):\n+        if host is None:\n+            raise LocationParseError(host)\n+\n         # httplib doesn't like it when we include brackets in ipv6 addresses\n         host = host.strip('[]')\n \n@@ -136,7 +140,7 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n \n     def __init__(self, host, port=None, strict=False,\n                  timeout=Timeout.DEFAULT_TIMEOUT, maxsize=1, block=False,\n-                 headers=None, _proxy=None, _proxy_headers=None):\n+                 headers=None, _proxy=None, _proxy_headers=None, **conn_kw):\n         ConnectionPool.__init__(self, host, port)\n         RequestMethods.__init__(self, headers)\n \n@@ -163,6 +167,10 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n         self.num_connections = 0\n         self.num_requests = 0\n \n+        if sys.version_info < (2, 7):  # Python 2.6 and older\n+            conn_kw.pop('source_address', None)\n+        self.conn_kw = conn_kw\n+\n     def _new_conn(self):\n         \"\"\"\n         Return a fresh :class:`HTTPConnection`.\n@@ -173,7 +181,7 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n \n         conn = self.ConnectionCls(host=self.host, port=self.port,\n                                   timeout=self.timeout.connect_timeout,\n-                                  strict=self.strict)\n+                                  strict=self.strict, **self.conn_kw)\n         if self.proxy is not None:\n             # Enable Nagle's algorithm for proxies, to avoid packet\n             # fragmentation.\n@@ -594,10 +602,14 @@ class HTTPSConnectionPool(HTTPConnectionPool):\n                  _proxy=None, _proxy_headers=None,\n                  key_file=None, cert_file=None, cert_reqs=None,\n                  ca_certs=None, ssl_version=None,\n-                 assert_hostname=None, assert_fingerprint=None):\n+                 assert_hostname=None, assert_fingerprint=None,\n+                 **conn_kw):\n+\n+        if sys.version_info < (2, 7):  # Python 2.6 or older\n+            conn_kw.pop('source_address', None)\n \n         HTTPConnectionPool.__init__(self, host, port, strict, timeout, maxsize,\n-                                    block, headers, _proxy, _proxy_headers)\n+                                    block, headers, _proxy, _proxy_headers, **conn_kw)\n         self.key_file = key_file\n         self.cert_file = cert_file\n         self.cert_reqs = cert_reqs\n@@ -605,6 +617,7 @@ class HTTPSConnectionPool(HTTPConnectionPool):\n         self.ssl_version = ssl_version\n         self.assert_hostname = assert_hostname\n         self.assert_fingerprint = assert_fingerprint\n+        self.conn_kw = conn_kw\n \n     def _prepare_conn(self, conn):\n         \"\"\"\n@@ -620,6 +633,7 @@ class HTTPSConnectionPool(HTTPConnectionPool):\n                           assert_hostname=self.assert_hostname,\n                           assert_fingerprint=self.assert_fingerprint)\n             conn.ssl_version = self.ssl_version\n+            conn.conn_kw = self.conn_kw\n \n         if self.proxy is not None:\n             # Python 2.7+\n@@ -656,6 +670,7 @@ class HTTPSConnectionPool(HTTPConnectionPool):\n         extra_params = {}\n         if not six.PY3:  # Python 2\n             extra_params['strict'] = self.strict\n+        extra_params.update(self.conn_kw)\n \n         conn = self.ConnectionCls(host=actual_host, port=actual_port,\n                                   timeout=self.timeout.connect_timeout,\n\n@@ -1,4 +1,7 @@\n-'''SSL with SNI_-support for Python 2.\n+'''SSL with SNI_-support for Python 2. Follow these instructions if you would\n+like to verify SSL certificates in Python 2. Note, the default libraries do\n+*not* do certificate checking; you need to do additional work to validate\n+certificates yourself.\n \n This needs the following packages installed:\n \n@@ -6,9 +9,15 @@ This needs the following packages installed:\n * ndg-httpsclient (tested with 0.3.2)\n * pyasn1 (tested with 0.1.6)\n \n-To activate it call :func:`~urllib3.contrib.pyopenssl.inject_into_urllib3`.\n-This can be done in a ``sitecustomize`` module, or at any other time before\n-your application begins using ``urllib3``, like this::\n+You can install them with the following command:\n+\n+    pip install pyopenssl ndg-httpsclient pyasn1\n+\n+To activate certificate checking, call\n+:func:`~urllib3.contrib.pyopenssl.inject_into_urllib3` from your Python code\n+before you begin making HTTP requests. This can be done in a ``sitecustomize``\n+module, or at any other time before your application begins using ``urllib3``,\n+like this::\n \n     try:\n         import urllib3.contrib.pyopenssl\n\n@@ -1,648 +0,0 @@\n-# urllib3/util.py\n-# Copyright 2008-2013 Andrey Petrov and contributors (see CONTRIBUTORS.txt)\n-#\n-# This module is part of urllib3 and is released under\n-# the MIT License: http://www.opensource.org/licenses/mit-license.php\n-\n-\n-from base64 import b64encode\n-from binascii import hexlify, unhexlify\n-from collections import namedtuple\n-from hashlib import md5, sha1\n-from socket import error as SocketError, _GLOBAL_DEFAULT_TIMEOUT\n-import time\n-\n-try:\n-    from select import poll, POLLIN\n-except ImportError:  # `poll` doesn't exist on OSX and other platforms\n-    poll = False\n-    try:\n-        from select import select\n-    except ImportError:  # `select` doesn't exist on AppEngine.\n-        select = False\n-\n-try:  # Test for SSL features\n-    SSLContext = None\n-    HAS_SNI = False\n-\n-    import ssl\n-    from ssl import wrap_socket, CERT_NONE, PROTOCOL_SSLv23\n-    from ssl import SSLContext  # Modern SSL?\n-    from ssl import HAS_SNI  # Has SNI?\n-except ImportError:\n-    pass\n-\n-from .packages import six\n-from .exceptions import LocationParseError, SSLError, TimeoutStateError\n-\n-\n-_Default = object()\n-# The default timeout to use for socket connections. This is the attribute used\n-# by httplib to define the default timeout\n-\n-\n-def current_time():\n-    \"\"\"\n-    Retrieve the current time, this function is mocked out in unit testing.\n-    \"\"\"\n-    return time.time()\n-\n-\n-class Timeout(object):\n-    \"\"\"\n-    Utility object for storing timeout values.\n-\n-    Example usage:\n-\n-    .. code-block:: python\n-\n-        timeout = urllib3.util.Timeout(connect=2.0, read=7.0)\n-        pool = HTTPConnectionPool('www.google.com', 80, timeout=timeout)\n-        pool.request(...) # Etc, etc\n-\n-    :param connect:\n-        The maximum amount of time to wait for a connection attempt to a server\n-        to succeed. Omitting the parameter will default the connect timeout to\n-        the system default, probably `the global default timeout in socket.py\n-        <http://hg.python.org/cpython/file/603b4d593758/Lib/socket.py#l535>`_.\n-        None will set an infinite timeout for connection attempts.\n-\n-    :type connect: integer, float, or None\n-\n-    :param read:\n-        The maximum amount of time to wait between consecutive\n-        read operations for a response from the server. Omitting\n-        the parameter will default the read timeout to the system\n-        default, probably `the global default timeout in socket.py\n-        <http://hg.python.org/cpython/file/603b4d593758/Lib/socket.py#l535>`_.\n-        None will set an infinite timeout.\n-\n-    :type read: integer, float, or None\n-\n-    :param total:\n-        This combines the connect and read timeouts into one; the read timeout\n-        will be set to the time leftover from the connect attempt. In the\n-        event that both a connect timeout and a total are specified, or a read\n-        timeout and a total are specified, the shorter timeout will be applied.\n-\n-        Defaults to None.\n-\n-    :type total: integer, float, or None\n-\n-    .. note::\n-\n-        Many factors can affect the total amount of time for urllib3 to return\n-        an HTTP response. Specifically, Python's DNS resolver does not obey the\n-        timeout specified on the socket. Other factors that can affect total\n-        request time include high CPU load, high swap, the program running at a\n-        low priority level, or other behaviors. The observed running time for\n-        urllib3 to return a response may be greater than the value passed to\n-        `total`.\n-\n-        In addition, the read and total timeouts only measure the time between\n-        read operations on the socket connecting the client and the server,\n-        not the total amount of time for the request to return a complete\n-        response. For most requests, the timeout is raised because the server\n-        has not sent the first byte in the specified time. This is not always\n-        the case; if a server streams one byte every fifteen seconds, a timeout\n-        of 20 seconds will not ever trigger, even though the request will\n-        take several minutes to complete.\n-\n-        If your goal is to cut off any request after a set amount of wall clock\n-        time, consider having a second \"watcher\" thread to cut off a slow\n-        request.\n-    \"\"\"\n-\n-    #: A sentinel object representing the default timeout value\n-    DEFAULT_TIMEOUT = _GLOBAL_DEFAULT_TIMEOUT\n-\n-    def __init__(self, total=None, connect=_Default, read=_Default):\n-        self._connect = self._validate_timeout(connect, 'connect')\n-        self._read = self._validate_timeout(read, 'read')\n-        self.total = self._validate_timeout(total, 'total')\n-        self._start_connect = None\n-\n-    def __str__(self):\n-        return '%s(connect=%r, read=%r, total=%r)' % (\n-            type(self).__name__, self._connect, self._read, self.total)\n-\n-\n-    @classmethod\n-    def _validate_timeout(cls, value, name):\n-        \"\"\" Check that a timeout attribute is valid\n-\n-        :param value: The timeout value to validate\n-        :param name: The name of the timeout attribute to validate. This is used\n-            for clear error messages\n-        :return: the value\n-        :raises ValueError: if the type is not an integer or a float, or if it\n-            is a numeric value less than zero\n-        \"\"\"\n-        if value is _Default:\n-            return cls.DEFAULT_TIMEOUT\n-\n-        if value is None or value is cls.DEFAULT_TIMEOUT:\n-            return value\n-\n-        try:\n-            float(value)\n-        except (TypeError, ValueError):\n-            raise ValueError(\"Timeout value %s was %s, but it must be an \"\n-                             \"int or float.\" % (name, value))\n-\n-        try:\n-            if value < 0:\n-                raise ValueError(\"Attempted to set %s timeout to %s, but the \"\n-                                 \"timeout cannot be set to a value less \"\n-                                 \"than 0.\" % (name, value))\n-        except TypeError: # Python 3\n-            raise ValueError(\"Timeout value %s was %s, but it must be an \"\n-                             \"int or float.\" % (name, value))\n-\n-        return value\n-\n-    @classmethod\n-    def from_float(cls, timeout):\n-        \"\"\" Create a new Timeout from a legacy timeout value.\n-\n-        The timeout value used by httplib.py sets the same timeout on the\n-        connect(), and recv() socket requests. This creates a :class:`Timeout`\n-        object that sets the individual timeouts to the ``timeout`` value passed\n-        to this function.\n-\n-        :param timeout: The legacy timeout value\n-        :type timeout: integer, float, sentinel default object, or None\n-        :return: a Timeout object\n-        :rtype: :class:`Timeout`\n-        \"\"\"\n-        return Timeout(read=timeout, connect=timeout)\n-\n-    def clone(self):\n-        \"\"\" Create a copy of the timeout object\n-\n-        Timeout properties are stored per-pool but each request needs a fresh\n-        Timeout object to ensure each one has its own start/stop configured.\n-\n-        :return: a copy of the timeout object\n-        :rtype: :class:`Timeout`\n-        \"\"\"\n-        # We can't use copy.deepcopy because that will also create a new object\n-        # for _GLOBAL_DEFAULT_TIMEOUT, which socket.py uses as a sentinel to\n-        # detect the user default.\n-        return Timeout(connect=self._connect, read=self._read,\n-                       total=self.total)\n-\n-    def start_connect(self):\n-        \"\"\" Start the timeout clock, used during a connect() attempt\n-\n-        :raises urllib3.exceptions.TimeoutStateError: if you attempt\n-            to start a timer that has been started already.\n-        \"\"\"\n-        if self._start_connect is not None:\n-            raise TimeoutStateError(\"Timeout timer has already been started.\")\n-        self._start_connect = current_time()\n-        return self._start_connect\n-\n-    def get_connect_duration(self):\n-        \"\"\" Gets the time elapsed since the call to :meth:`start_connect`.\n-\n-        :return: the elapsed time\n-        :rtype: float\n-        :raises urllib3.exceptions.TimeoutStateError: if you attempt\n-            to get duration for a timer that hasn't been started.\n-        \"\"\"\n-        if self._start_connect is None:\n-            raise TimeoutStateError(\"Can't get connect duration for timer \"\n-                                    \"that has not started.\")\n-        return current_time() - self._start_connect\n-\n-    @property\n-    def connect_timeout(self):\n-        \"\"\" Get the value to use when setting a connection timeout.\n-\n-        This will be a positive float or integer, the value None\n-        (never timeout), or the default system timeout.\n-\n-        :return: the connect timeout\n-        :rtype: int, float, :attr:`Timeout.DEFAULT_TIMEOUT` or None\n-        \"\"\"\n-        if self.total is None:\n-            return self._connect\n-\n-        if self._connect is None or self._connect is self.DEFAULT_TIMEOUT:\n-            return self.total\n-\n-        return min(self._connect, self.total)\n-\n-    @property\n-    def read_timeout(self):\n-        \"\"\" Get the value for the read timeout.\n-\n-        This assumes some time has elapsed in the connection timeout and\n-        computes the read timeout appropriately.\n-\n-        If self.total is set, the read timeout is dependent on the amount of\n-        time taken by the connect timeout. If the connection time has not been\n-        established, a :exc:`~urllib3.exceptions.TimeoutStateError` will be\n-        raised.\n-\n-        :return: the value to use for the read timeout\n-        :rtype: int, float, :attr:`Timeout.DEFAULT_TIMEOUT` or None\n-        :raises urllib3.exceptions.TimeoutStateError: If :meth:`start_connect`\n-            has not yet been called on this object.\n-        \"\"\"\n-        if (self.total is not None and\n-            self.total is not self.DEFAULT_TIMEOUT and\n-            self._read is not None and\n-            self._read is not self.DEFAULT_TIMEOUT):\n-            # in case the connect timeout has not yet been established.\n-            if self._start_connect is None:\n-                return self._read\n-            return max(0, min(self.total - self.get_connect_duration(),\n-                              self._read))\n-        elif self.total is not None and self.total is not self.DEFAULT_TIMEOUT:\n-            return max(0, self.total - self.get_connect_duration())\n-        else:\n-            return self._read\n-\n-\n-class Url(namedtuple('Url', ['scheme', 'auth', 'host', 'port', 'path', 'query', 'fragment'])):\n-    \"\"\"\n-    Datastructure for representing an HTTP URL. Used as a return value for\n-    :func:`parse_url`.\n-    \"\"\"\n-    slots = ()\n-\n-    def __new__(cls, scheme=None, auth=None, host=None, port=None, path=None, query=None, fragment=None):\n-        return super(Url, cls).__new__(cls, scheme, auth, host, port, path, query, fragment)\n-\n-    @property\n-    def hostname(self):\n-        \"\"\"For backwards-compatibility with urlparse. We're nice like that.\"\"\"\n-        return self.host\n-\n-    @property\n-    def request_uri(self):\n-        \"\"\"Absolute path including the query string.\"\"\"\n-        uri = self.path or '/'\n-\n-        if self.query is not None:\n-            uri += '?' + self.query\n-\n-        return uri\n-\n-    @property\n-    def netloc(self):\n-        \"\"\"Network location including host and port\"\"\"\n-        if self.port:\n-            return '%s:%d' % (self.host, self.port)\n-        return self.host\n-\n-\n-def split_first(s, delims):\n-    \"\"\"\n-    Given a string and an iterable of delimiters, split on the first found\n-    delimiter. Return two split parts and the matched delimiter.\n-\n-    If not found, then the first part is the full input string.\n-\n-    Example: ::\n-\n-        >>> split_first('foo/bar?baz', '?/=')\n-        ('foo', 'bar?baz', '/')\n-        >>> split_first('foo/bar?baz', '123')\n-        ('foo/bar?baz', '', None)\n-\n-    Scales linearly with number of delims. Not ideal for large number of delims.\n-    \"\"\"\n-    min_idx = None\n-    min_delim = None\n-    for d in delims:\n-        idx = s.find(d)\n-        if idx < 0:\n-            continue\n-\n-        if min_idx is None or idx < min_idx:\n-            min_idx = idx\n-            min_delim = d\n-\n-    if min_idx is None or min_idx < 0:\n-        return s, '', None\n-\n-    return s[:min_idx], s[min_idx+1:], min_delim\n-\n-\n-def parse_url(url):\n-    \"\"\"\n-    Given a url, return a parsed :class:`.Url` namedtuple. Best-effort is\n-    performed to parse incomplete urls. Fields not provided will be None.\n-\n-    Partly backwards-compatible with :mod:`urlparse`.\n-\n-    Example: ::\n-\n-        >>> parse_url('http://google.com/mail/')\n-        Url(scheme='http', host='google.com', port=None, path='/', ...)\n-        >>> parse_url('google.com:80')\n-        Url(scheme=None, host='google.com', port=80, path=None, ...)\n-        >>> parse_url('/foo?bar')\n-        Url(scheme=None, host=None, port=None, path='/foo', query='bar', ...)\n-    \"\"\"\n-\n-    # While this code has overlap with stdlib's urlparse, it is much\n-    # simplified for our needs and less annoying.\n-    # Additionally, this implementations does silly things to be optimal\n-    # on CPython.\n-\n-    scheme = None\n-    auth = None\n-    host = None\n-    port = None\n-    path = None\n-    fragment = None\n-    query = None\n-\n-    # Scheme\n-    if '://' in url:\n-        scheme, url = url.split('://', 1)\n-\n-    # Find the earliest Authority Terminator\n-    # (http://tools.ietf.org/html/rfc3986#section-3.2)\n-    url, path_, delim = split_first(url, ['/', '?', '#'])\n-\n-    if delim:\n-        # Reassemble the path\n-        path = delim + path_\n-\n-    # Auth\n-    if '@' in url:\n-        # Last '@' denotes end of auth part\n-        auth, url = url.rsplit('@', 1)\n-\n-    # IPv6\n-    if url and url[0] == '[':\n-        host, url = url.split(']', 1)\n-        host += ']'\n-\n-    # Port\n-    if ':' in url:\n-        _host, port = url.split(':', 1)\n-\n-        if not host:\n-            host = _host\n-\n-        if port:\n-            # If given, ports must be integers.\n-            if not port.isdigit():\n-                raise LocationParseError(\"Failed to parse: %s\" % url)\n-            port = int(port)\n-        else:\n-            # Blank ports are cool, too. (rfc3986#section-3.2.3)\n-            port = None\n-\n-    elif not host and url:\n-        host = url\n-\n-    if not path:\n-        return Url(scheme, auth, host, port, path, query, fragment)\n-\n-    # Fragment\n-    if '#' in path:\n-        path, fragment = path.split('#', 1)\n-\n-    # Query\n-    if '?' in path:\n-        path, query = path.split('?', 1)\n-\n-    return Url(scheme, auth, host, port, path, query, fragment)\n-\n-\n-def get_host(url):\n-    \"\"\"\n-    Deprecated. Use :func:`.parse_url` instead.\n-    \"\"\"\n-    p = parse_url(url)\n-    return p.scheme or 'http', p.hostname, p.port\n-\n-\n-def make_headers(keep_alive=None, accept_encoding=None, user_agent=None,\n-                 basic_auth=None, proxy_basic_auth=None):\n-    \"\"\"\n-    Shortcuts for generating request headers.\n-\n-    :param keep_alive:\n-        If ``True``, adds 'connection: keep-alive' header.\n-\n-    :param accept_encoding:\n-        Can be a boolean, list, or string.\n-        ``True`` translates to 'gzip,deflate'.\n-        List will get joined by comma.\n-        String will be used as provided.\n-\n-    :param user_agent:\n-        String representing the user-agent you want, such as\n-        \"python-urllib3/0.6\"\n-\n-    :param basic_auth:\n-        Colon-separated username:password string for 'authorization: basic ...'\n-        auth header.\n-\n-    :param proxy_basic_auth:\n-        Colon-separated username:password string for 'proxy-authorization: basic ...'\n-        auth header.\n-\n-    Example: ::\n-\n-        >>> make_headers(keep_alive=True, user_agent=\"Batman/1.0\")\n-        {'connection': 'keep-alive', 'user-agent': 'Batman/1.0'}\n-        >>> make_headers(accept_encoding=True)\n-        {'accept-encoding': 'gzip,deflate'}\n-    \"\"\"\n-    headers = {}\n-    if accept_encoding:\n-        if isinstance(accept_encoding, str):\n-            pass\n-        elif isinstance(accept_encoding, list):\n-            accept_encoding = ','.join(accept_encoding)\n-        else:\n-            accept_encoding = 'gzip,deflate'\n-        headers['accept-encoding'] = accept_encoding\n-\n-    if user_agent:\n-        headers['user-agent'] = user_agent\n-\n-    if keep_alive:\n-        headers['connection'] = 'keep-alive'\n-\n-    if basic_auth:\n-        headers['authorization'] = 'Basic ' + \\\n-            b64encode(six.b(basic_auth)).decode('utf-8')\n-\n-    if proxy_basic_auth:\n-        headers['proxy-authorization'] = 'Basic ' + \\\n-            b64encode(six.b(proxy_basic_auth)).decode('utf-8')\n-\n-    return headers\n-\n-\n-def is_connection_dropped(conn):  # Platform-specific\n-    \"\"\"\n-    Returns True if the connection is dropped and should be closed.\n-\n-    :param conn:\n-        :class:`httplib.HTTPConnection` object.\n-\n-    Note: For platforms like AppEngine, this will always return ``False`` to\n-    let the platform handle connection recycling transparently for us.\n-    \"\"\"\n-    sock = getattr(conn, 'sock', False)\n-    if not sock: # Platform-specific: AppEngine\n-        return False\n-\n-    if not poll:\n-        if not select: # Platform-specific: AppEngine\n-            return False\n-\n-        try:\n-            return select([sock], [], [], 0.0)[0]\n-        except SocketError:\n-            return True\n-\n-    # This version is better on platforms that support it.\n-    p = poll()\n-    p.register(sock, POLLIN)\n-    for (fno, ev) in p.poll(0.0):\n-        if fno == sock.fileno():\n-            # Either data is buffered (bad), or the connection is dropped.\n-            return True\n-\n-\n-def resolve_cert_reqs(candidate):\n-    \"\"\"\n-    Resolves the argument to a numeric constant, which can be passed to\n-    the wrap_socket function/method from the ssl module.\n-    Defaults to :data:`ssl.CERT_NONE`.\n-    If given a string it is assumed to be the name of the constant in the\n-    :mod:`ssl` module or its abbrevation.\n-    (So you can specify `REQUIRED` instead of `CERT_REQUIRED`.\n-    If it's neither `None` nor a string we assume it is already the numeric\n-    constant which can directly be passed to wrap_socket.\n-    \"\"\"\n-    if candidate is None:\n-        return CERT_NONE\n-\n-    if isinstance(candidate, str):\n-        res = getattr(ssl, candidate, None)\n-        if res is None:\n-            res = getattr(ssl, 'CERT_' + candidate)\n-        return res\n-\n-    return candidate\n-\n-\n-def resolve_ssl_version(candidate):\n-    \"\"\"\n-    like resolve_cert_reqs\n-    \"\"\"\n-    if candidate is None:\n-        return PROTOCOL_SSLv23\n-\n-    if isinstance(candidate, str):\n-        res = getattr(ssl, candidate, None)\n-        if res is None:\n-            res = getattr(ssl, 'PROTOCOL_' + candidate)\n-        return res\n-\n-    return candidate\n-\n-\n-def assert_fingerprint(cert, fingerprint):\n-    \"\"\"\n-    Checks if given fingerprint matches the supplied certificate.\n-\n-    :param cert:\n-        Certificate as bytes object.\n-    :param fingerprint:\n-        Fingerprint as string of hexdigits, can be interspersed by colons.\n-    \"\"\"\n-\n-    # Maps the length of a digest to a possible hash function producing\n-    # this digest.\n-    hashfunc_map = {\n-        16: md5,\n-        20: sha1\n-    }\n-\n-    fingerprint = fingerprint.replace(':', '').lower()\n-\n-    digest_length, rest = divmod(len(fingerprint), 2)\n-\n-    if rest or digest_length not in hashfunc_map:\n-        raise SSLError('Fingerprint is of invalid length.')\n-\n-    # We need encode() here for py32; works on py2 and p33.\n-    fingerprint_bytes = unhexlify(fingerprint.encode())\n-\n-    hashfunc = hashfunc_map[digest_length]\n-\n-    cert_digest = hashfunc(cert).digest()\n-\n-    if not cert_digest == fingerprint_bytes:\n-        raise SSLError('Fingerprints did not match. Expected \"{0}\", got \"{1}\".'\n-                       .format(hexlify(fingerprint_bytes),\n-                               hexlify(cert_digest)))\n-\n-def is_fp_closed(obj):\n-    \"\"\"\n-    Checks whether a given file-like object is closed.\n-\n-    :param obj:\n-        The file-like object to check.\n-    \"\"\"\n-    if hasattr(obj, 'fp'):\n-        # Object is a container for another file-like object that gets released\n-        # on exhaustion (e.g. HTTPResponse)\n-        return obj.fp is None\n-\n-    return obj.closed\n-\n-\n-if SSLContext is not None:  # Python 3.2+\n-    def ssl_wrap_socket(sock, keyfile=None, certfile=None, cert_reqs=None,\n-                        ca_certs=None, server_hostname=None,\n-                        ssl_version=None):\n-        \"\"\"\n-        All arguments except `server_hostname` have the same meaning as for\n-        :func:`ssl.wrap_socket`\n-\n-        :param server_hostname:\n-            Hostname of the expected certificate\n-        \"\"\"\n-        context = SSLContext(ssl_version)\n-        context.verify_mode = cert_reqs\n-\n-        # Disable TLS compression to migitate CRIME attack (issue #309)\n-        OP_NO_COMPRESSION = 0x20000\n-        context.options |= OP_NO_COMPRESSION\n-\n-        if ca_certs:\n-            try:\n-                context.load_verify_locations(ca_certs)\n-            # Py32 raises IOError\n-            # Py33 raises FileNotFoundError\n-            except Exception as e:  # Reraise as SSLError\n-                raise SSLError(e)\n-        if certfile:\n-            # FIXME: This block needs a test.\n-            context.load_cert_chain(certfile, keyfile)\n-        if HAS_SNI:  # Platform-specific: OpenSSL with enabled SNI\n-            return context.wrap_socket(sock, server_hostname=server_hostname)\n-        return context.wrap_socket(sock)\n-\n-else:  # Python 3.1 and earlier\n-    def ssl_wrap_socket(sock, keyfile=None, certfile=None, cert_reqs=None,\n-                        ca_certs=None, server_hostname=None,\n-                        ssl_version=None):\n-        return wrap_socket(sock, keyfile=keyfile, certfile=certfile,\n-                           ca_certs=ca_certs, cert_reqs=cert_reqs,\n-                           ssl_version=ssl_version)\n\n@@ -0,0 +1,27 @@\n+# urllib3/util/__init__.py\n+# Copyright 2008-2014 Andrey Petrov and contributors (see CONTRIBUTORS.txt)\n+#\n+# This module is part of urllib3 and is released under\n+# the MIT License: http://www.opensource.org/licenses/mit-license.php\n+\n+from .connection import is_connection_dropped\n+from .request import make_headers\n+from .response import is_fp_closed\n+from .ssl_ import (\n+    SSLContext,\n+    HAS_SNI,\n+    assert_fingerprint,\n+    resolve_cert_reqs,\n+    resolve_ssl_version,\n+    ssl_wrap_socket,\n+)\n+from .timeout import (\n+    current_time,\n+    Timeout,\n+)\n+from .url import (\n+    get_host,\n+    parse_url,\n+    split_first,\n+    Url,\n+)\n\n@@ -0,0 +1,45 @@\n+from socket import error as SocketError\n+try:\n+    from select import poll, POLLIN\n+except ImportError:  # `poll` doesn't exist on OSX and other platforms\n+    poll = False\n+    try:\n+        from select import select\n+    except ImportError:  # `select` doesn't exist on AppEngine.\n+        select = False\n+\n+def is_connection_dropped(conn):  # Platform-specific\n+    \"\"\"\n+    Returns True if the connection is dropped and should be closed.\n+\n+    :param conn:\n+        :class:`httplib.HTTPConnection` object.\n+\n+    Note: For platforms like AppEngine, this will always return ``False`` to\n+    let the platform handle connection recycling transparently for us.\n+    \"\"\"\n+    sock = getattr(conn, 'sock', False)\n+    if sock is False:  # Platform-specific: AppEngine\n+        return False\n+    if sock is None:  # Connection already closed (such as by httplib).\n+        return False\n+\n+    if not poll:\n+        if not select:  # Platform-specific: AppEngine\n+            return False\n+\n+        try:\n+            return select([sock], [], [], 0.0)[0]\n+        except SocketError:\n+            return True\n+\n+    # This version is better on platforms that support it.\n+    p = poll()\n+    p.register(sock, POLLIN)\n+    for (fno, ev) in p.poll(0.0):\n+        if fno == sock.fileno():\n+            # Either data is buffered (bad), or the connection is dropped.\n+            return True\n+\n+\n+\n\n@@ -0,0 +1,68 @@\n+from base64 import b64encode\n+\n+from ..packages import six\n+\n+\n+ACCEPT_ENCODING = 'gzip,deflate'\n+\n+\n+def make_headers(keep_alive=None, accept_encoding=None, user_agent=None,\n+                 basic_auth=None, proxy_basic_auth=None):\n+    \"\"\"\n+    Shortcuts for generating request headers.\n+\n+    :param keep_alive:\n+        If ``True``, adds 'connection: keep-alive' header.\n+\n+    :param accept_encoding:\n+        Can be a boolean, list, or string.\n+        ``True`` translates to 'gzip,deflate'.\n+        List will get joined by comma.\n+        String will be used as provided.\n+\n+    :param user_agent:\n+        String representing the user-agent you want, such as\n+        \"python-urllib3/0.6\"\n+\n+    :param basic_auth:\n+        Colon-separated username:password string for 'authorization: basic ...'\n+        auth header.\n+\n+    :param proxy_basic_auth:\n+        Colon-separated username:password string for 'proxy-authorization: basic ...'\n+        auth header.\n+\n+    Example: ::\n+\n+        >>> make_headers(keep_alive=True, user_agent=\"Batman/1.0\")\n+        {'connection': 'keep-alive', 'user-agent': 'Batman/1.0'}\n+        >>> make_headers(accept_encoding=True)\n+        {'accept-encoding': 'gzip,deflate'}\n+    \"\"\"\n+    headers = {}\n+    if accept_encoding:\n+        if isinstance(accept_encoding, str):\n+            pass\n+        elif isinstance(accept_encoding, list):\n+            accept_encoding = ','.join(accept_encoding)\n+        else:\n+            accept_encoding = ACCEPT_ENCODING\n+        headers['accept-encoding'] = accept_encoding\n+\n+    if user_agent:\n+        headers['user-agent'] = user_agent\n+\n+    if keep_alive:\n+        headers['connection'] = 'keep-alive'\n+\n+    if basic_auth:\n+        headers['authorization'] = 'Basic ' + \\\n+            b64encode(six.b(basic_auth)).decode('utf-8')\n+\n+    if proxy_basic_auth:\n+        headers['proxy-authorization'] = 'Basic ' + \\\n+            b64encode(six.b(proxy_basic_auth)).decode('utf-8')\n+\n+    return headers\n+\n+\n\n@@ -0,0 +1,13 @@\n+def is_fp_closed(obj):\n+    \"\"\"\n+    Checks whether a given file-like object is closed.\n+\n+    :param obj:\n+        The file-like object to check.\n+    \"\"\"\n+    if hasattr(obj, 'fp'):\n+        # Object is a container for another file-like object that gets released\n+        # on exhaustion (e.g. HTTPResponse)\n+        return obj.fp is None\n+\n+    return obj.closed\n\n@@ -0,0 +1,133 @@\n+from binascii import hexlify, unhexlify\n+from hashlib import md5, sha1\n+\n+from ..exceptions import SSLError\n+\n+\n+try:  # Test for SSL features\n+    SSLContext = None\n+    HAS_SNI = False\n+\n+    import ssl\n+    from ssl import wrap_socket, CERT_NONE, PROTOCOL_SSLv23\n+    from ssl import SSLContext  # Modern SSL?\n+    from ssl import HAS_SNI  # Has SNI?\n+except ImportError:\n+    pass\n+\n+\n+def assert_fingerprint(cert, fingerprint):\n+    \"\"\"\n+    Checks if given fingerprint matches the supplied certificate.\n+\n+    :param cert:\n+        Certificate as bytes object.\n+    :param fingerprint:\n+        Fingerprint as string of hexdigits, can be interspersed by colons.\n+    \"\"\"\n+\n+    # Maps the length of a digest to a possible hash function producing\n+    # this digest.\n+    hashfunc_map = {\n+        16: md5,\n+        20: sha1\n+    }\n+\n+    fingerprint = fingerprint.replace(':', '').lower()\n+\n+    digest_length, rest = divmod(len(fingerprint), 2)\n+\n+    if rest or digest_length not in hashfunc_map:\n+        raise SSLError('Fingerprint is of invalid length.')\n+\n+    # We need encode() here for py32; works on py2 and p33.\n+    fingerprint_bytes = unhexlify(fingerprint.encode())\n+\n+    hashfunc = hashfunc_map[digest_length]\n+\n+    cert_digest = hashfunc(cert).digest()\n+\n+    if not cert_digest == fingerprint_bytes:\n+        raise SSLError('Fingerprints did not match. Expected \"{0}\", got \"{1}\".'\n+                       .format(hexlify(fingerprint_bytes),\n+                               hexlify(cert_digest)))\n+\n+\n+def resolve_cert_reqs(candidate):\n+    \"\"\"\n+    Resolves the argument to a numeric constant, which can be passed to\n+    the wrap_socket function/method from the ssl module.\n+    Defaults to :data:`ssl.CERT_NONE`.\n+    If given a string it is assumed to be the name of the constant in the\n+    :mod:`ssl` module or its abbrevation.\n+    (So you can specify `REQUIRED` instead of `CERT_REQUIRED`.\n+    If it's neither `None` nor a string we assume it is already the numeric\n+    constant which can directly be passed to wrap_socket.\n+    \"\"\"\n+    if candidate is None:\n+        return CERT_NONE\n+\n+    if isinstance(candidate, str):\n+        res = getattr(ssl, candidate, None)\n+        if res is None:\n+            res = getattr(ssl, 'CERT_' + candidate)\n+        return res\n+\n+    return candidate\n+\n+\n+def resolve_ssl_version(candidate):\n+    \"\"\"\n+    like resolve_cert_reqs\n+    \"\"\"\n+    if candidate is None:\n+        return PROTOCOL_SSLv23\n+\n+    if isinstance(candidate, str):\n+        res = getattr(ssl, candidate, None)\n+        if res is None:\n+            res = getattr(ssl, 'PROTOCOL_' + candidate)\n+        return res\n+\n+    return candidate\n+\n+\n+if SSLContext is not None:  # Python 3.2+\n+    def ssl_wrap_socket(sock, keyfile=None, certfile=None, cert_reqs=None,\n+                        ca_certs=None, server_hostname=None,\n+                        ssl_version=None):\n+        \"\"\"\n+        All arguments except `server_hostname` have the same meaning as for\n+        :func:`ssl.wrap_socket`\n+\n+        :param server_hostname:\n+            Hostname of the expected certificate\n+        \"\"\"\n+        context = SSLContext(ssl_version)\n+        context.verify_mode = cert_reqs\n+\n+        # Disable TLS compression to migitate CRIME attack (issue #309)\n+        OP_NO_COMPRESSION = 0x20000\n+        context.options |= OP_NO_COMPRESSION\n+\n+        if ca_certs:\n+            try:\n+                context.load_verify_locations(ca_certs)\n+            # Py32 raises IOError\n+            # Py33 raises FileNotFoundError\n+            except Exception as e:  # Reraise as SSLError\n+                raise SSLError(e)\n+        if certfile:\n+            # FIXME: This block needs a test.\n+            context.load_cert_chain(certfile, keyfile)\n+        if HAS_SNI:  # Platform-specific: OpenSSL with enabled SNI\n+            return context.wrap_socket(sock, server_hostname=server_hostname)\n+        return context.wrap_socket(sock)\n+\n+else:  # Python 3.1 and earlier\n+    def ssl_wrap_socket(sock, keyfile=None, certfile=None, cert_reqs=None,\n+                        ca_certs=None, server_hostname=None,\n+                        ssl_version=None):\n+        return wrap_socket(sock, keyfile=keyfile, certfile=certfile,\n+                           ca_certs=ca_certs, cert_reqs=cert_reqs,\n+                           ssl_version=ssl_version)\n\n@@ -0,0 +1,234 @@\n+from socket import _GLOBAL_DEFAULT_TIMEOUT\n+import time\n+\n+from ..exceptions import TimeoutStateError\n+\n+\n+def current_time():\n+    \"\"\"\n+    Retrieve the current time, this function is mocked out in unit testing.\n+    \"\"\"\n+    return time.time()\n+\n+\n+_Default = object()\n+# The default timeout to use for socket connections. This is the attribute used\n+# by httplib to define the default timeout\n+\n+\n+class Timeout(object):\n+    \"\"\"\n+    Utility object for storing timeout values.\n+\n+    Example usage:\n+\n+    .. code-block:: python\n+\n+        timeout = urllib3.util.Timeout(connect=2.0, read=7.0)\n+        pool = HTTPConnectionPool('www.google.com', 80, timeout=timeout)\n+        pool.request(...) # Etc, etc\n+\n+    :param connect:\n+        The maximum amount of time to wait for a connection attempt to a server\n+        to succeed. Omitting the parameter will default the connect timeout to\n+        the system default, probably `the global default timeout in socket.py\n+        <http://hg.python.org/cpython/file/603b4d593758/Lib/socket.py#l535>`_.\n+        None will set an infinite timeout for connection attempts.\n+\n+    :type connect: integer, float, or None\n+\n+    :param read:\n+        The maximum amount of time to wait between consecutive\n+        read operations for a response from the server. Omitting\n+        the parameter will default the read timeout to the system\n+        default, probably `the global default timeout in socket.py\n+        <http://hg.python.org/cpython/file/603b4d593758/Lib/socket.py#l535>`_.\n+        None will set an infinite timeout.\n+\n+    :type read: integer, float, or None\n+\n+    :param total:\n+        This combines the connect and read timeouts into one; the read timeout\n+        will be set to the time leftover from the connect attempt. In the\n+        event that both a connect timeout and a total are specified, or a read\n+        timeout and a total are specified, the shorter timeout will be applied.\n+\n+        Defaults to None.\n+\n+    :type total: integer, float, or None\n+\n+    .. note::\n+\n+        Many factors can affect the total amount of time for urllib3 to return\n+        an HTTP response. Specifically, Python's DNS resolver does not obey the\n+        timeout specified on the socket. Other factors that can affect total\n+        request time include high CPU load, high swap, the program running at a\n+        low priority level, or other behaviors. The observed running time for\n+        urllib3 to return a response may be greater than the value passed to\n+        `total`.\n+\n+        In addition, the read and total timeouts only measure the time between\n+        read operations on the socket connecting the client and the server,\n+        not the total amount of time for the request to return a complete\n+        response. For most requests, the timeout is raised because the server\n+        has not sent the first byte in the specified time. This is not always\n+        the case; if a server streams one byte every fifteen seconds, a timeout\n+        of 20 seconds will not ever trigger, even though the request will\n+        take several minutes to complete.\n+\n+        If your goal is to cut off any request after a set amount of wall clock\n+        time, consider having a second \"watcher\" thread to cut off a slow\n+        request.\n+    \"\"\"\n+\n+    #: A sentinel object representing the default timeout value\n+    DEFAULT_TIMEOUT = _GLOBAL_DEFAULT_TIMEOUT\n+\n+    def __init__(self, total=None, connect=_Default, read=_Default):\n+        self._connect = self._validate_timeout(connect, 'connect')\n+        self._read = self._validate_timeout(read, 'read')\n+        self.total = self._validate_timeout(total, 'total')\n+        self._start_connect = None\n+\n+    def __str__(self):\n+        return '%s(connect=%r, read=%r, total=%r)' % (\n+            type(self).__name__, self._connect, self._read, self.total)\n+\n+\n+    @classmethod\n+    def _validate_timeout(cls, value, name):\n+        \"\"\" Check that a timeout attribute is valid\n+\n+        :param value: The timeout value to validate\n+        :param name: The name of the timeout attribute to validate. This is used\n+            for clear error messages\n+        :return: the value\n+        :raises ValueError: if the type is not an integer or a float, or if it\n+            is a numeric value less than zero\n+        \"\"\"\n+        if value is _Default:\n+            return cls.DEFAULT_TIMEOUT\n+\n+        if value is None or value is cls.DEFAULT_TIMEOUT:\n+            return value\n+\n+        try:\n+            float(value)\n+        except (TypeError, ValueError):\n+            raise ValueError(\"Timeout value %s was %s, but it must be an \"\n+                             \"int or float.\" % (name, value))\n+\n+        try:\n+            if value < 0:\n+                raise ValueError(\"Attempted to set %s timeout to %s, but the \"\n+                                 \"timeout cannot be set to a value less \"\n+                                 \"than 0.\" % (name, value))\n+        except TypeError: # Python 3\n+            raise ValueError(\"Timeout value %s was %s, but it must be an \"\n+                             \"int or float.\" % (name, value))\n+\n+        return value\n+\n+    @classmethod\n+    def from_float(cls, timeout):\n+        \"\"\" Create a new Timeout from a legacy timeout value.\n+\n+        The timeout value used by httplib.py sets the same timeout on the\n+        connect(), and recv() socket requests. This creates a :class:`Timeout`\n+        object that sets the individual timeouts to the ``timeout`` value passed\n+        to this function.\n+\n+        :param timeout: The legacy timeout value\n+        :type timeout: integer, float, sentinel default object, or None\n+        :return: a Timeout object\n+        :rtype: :class:`Timeout`\n+        \"\"\"\n+        return Timeout(read=timeout, connect=timeout)\n+\n+    def clone(self):\n+        \"\"\" Create a copy of the timeout object\n+\n+        Timeout properties are stored per-pool but each request needs a fresh\n+        Timeout object to ensure each one has its own start/stop configured.\n+\n+        :return: a copy of the timeout object\n+        :rtype: :class:`Timeout`\n+        \"\"\"\n+        # We can't use copy.deepcopy because that will also create a new object\n+        # for _GLOBAL_DEFAULT_TIMEOUT, which socket.py uses as a sentinel to\n+        # detect the user default.\n+        return Timeout(connect=self._connect, read=self._read,\n+                       total=self.total)\n+\n+    def start_connect(self):\n+        \"\"\" Start the timeout clock, used during a connect() attempt\n+\n+        :raises urllib3.exceptions.TimeoutStateError: if you attempt\n+            to start a timer that has been started already.\n+        \"\"\"\n+        if self._start_connect is not None:\n+            raise TimeoutStateError(\"Timeout timer has already been started.\")\n+        self._start_connect = current_time()\n+        return self._start_connect\n+\n+    def get_connect_duration(self):\n+        \"\"\" Gets the time elapsed since the call to :meth:`start_connect`.\n+\n+        :return: the elapsed time\n+        :rtype: float\n+        :raises urllib3.exceptions.TimeoutStateError: if you attempt\n+            to get duration for a timer that hasn't been started.\n+        \"\"\"\n+        if self._start_connect is None:\n+            raise TimeoutStateError(\"Can't get connect duration for timer \"\n+                                    \"that has not started.\")\n+        return current_time() - self._start_connect\n+\n+    @property\n+    def connect_timeout(self):\n+        \"\"\" Get the value to use when setting a connection timeout.\n+\n+        This will be a positive float or integer, the value None\n+        (never timeout), or the default system timeout.\n+\n+        :return: the connect timeout\n+        :rtype: int, float, :attr:`Timeout.DEFAULT_TIMEOUT` or None\n+        \"\"\"\n+        if self.total is None:\n+            return self._connect\n+\n+        if self._connect is None or self._connect is self.DEFAULT_TIMEOUT:\n+            return self.total\n+\n+        return min(self._connect, self.total)\n+\n+    @property\n+    def read_timeout(self):\n+        \"\"\" Get the value for the read timeout.\n+\n+        This assumes some time has elapsed in the connection timeout and\n+        computes the read timeout appropriately.\n+\n+        If self.total is set, the read timeout is dependent on the amount of\n+        time taken by the connect timeout. If the connection time has not been\n+        established, a :exc:`~urllib3.exceptions.TimeoutStateError` will be\n+        raised.\n+\n+        :return: the value to use for the read timeout\n+        :rtype: int, float, :attr:`Timeout.DEFAULT_TIMEOUT` or None\n+        :raises urllib3.exceptions.TimeoutStateError: If :meth:`start_connect`\n+            has not yet been called on this object.\n+        \"\"\"\n+        if (self.total is not None and\n+            self.total is not self.DEFAULT_TIMEOUT and\n+            self._read is not None and\n+            self._read is not self.DEFAULT_TIMEOUT):\n+            # in case the connect timeout has not yet been established.\n+            if self._start_connect is None:\n+                return self._read\n+            return max(0, min(self.total - self.get_connect_duration(),\n+                              self._read))\n+        elif self.total is not None and self.total is not self.DEFAULT_TIMEOUT:\n+            return max(0, self.total - self.get_connect_duration())\n+        else:\n+            return self._read\n\n@@ -0,0 +1,162 @@\n+from collections import namedtuple\n+\n+from ..exceptions import LocationParseError\n+\n+\n+class Url(namedtuple('Url', ['scheme', 'auth', 'host', 'port', 'path', 'query', 'fragment'])):\n+    \"\"\"\n+    Datastructure for representing an HTTP URL. Used as a return value for\n+    :func:`parse_url`.\n+    \"\"\"\n+    slots = ()\n+\n+    def __new__(cls, scheme=None, auth=None, host=None, port=None, path=None, query=None, fragment=None):\n+        return super(Url, cls).__new__(cls, scheme, auth, host, port, path, query, fragment)\n+\n+    @property\n+    def hostname(self):\n+        \"\"\"For backwards-compatibility with urlparse. We're nice like that.\"\"\"\n+        return self.host\n+\n+    @property\n+    def request_uri(self):\n+        \"\"\"Absolute path including the query string.\"\"\"\n+        uri = self.path or '/'\n+\n+        if self.query is not None:\n+            uri += '?' + self.query\n+\n+        return uri\n+\n+    @property\n+    def netloc(self):\n+        \"\"\"Network location including host and port\"\"\"\n+        if self.port:\n+            return '%s:%d' % (self.host, self.port)\n+        return self.host\n+\n+\n+def split_first(s, delims):\n+    \"\"\"\n+    Given a string and an iterable of delimiters, split on the first found\n+    delimiter. Return two split parts and the matched delimiter.\n+\n+    If not found, then the first part is the full input string.\n+\n+    Example: ::\n+\n+        >>> split_first('foo/bar?baz', '?/=')\n+        ('foo', 'bar?baz', '/')\n+        >>> split_first('foo/bar?baz', '123')\n+        ('foo/bar?baz', '', None)\n+\n+    Scales linearly with number of delims. Not ideal for large number of delims.\n+    \"\"\"\n+    min_idx = None\n+    min_delim = None\n+    for d in delims:\n+        idx = s.find(d)\n+        if idx < 0:\n+            continue\n+\n+        if min_idx is None or idx < min_idx:\n+            min_idx = idx\n+            min_delim = d\n+\n+    if min_idx is None or min_idx < 0:\n+        return s, '', None\n+\n+    return s[:min_idx], s[min_idx+1:], min_delim\n+\n+\n+def parse_url(url):\n+    \"\"\"\n+    Given a url, return a parsed :class:`.Url` namedtuple. Best-effort is\n+    performed to parse incomplete urls. Fields not provided will be None.\n+\n+    Partly backwards-compatible with :mod:`urlparse`.\n+\n+    Example: ::\n+\n+        >>> parse_url('http://google.com/mail/')\n+        Url(scheme='http', host='google.com', port=None, path='/', ...)\n+        >>> parse_url('google.com:80')\n+        Url(scheme=None, host='google.com', port=80, path=None, ...)\n+        >>> parse_url('/foo?bar')\n+        Url(scheme=None, host=None, port=None, path='/foo', query='bar', ...)\n+    \"\"\"\n+\n+    # While this code has overlap with stdlib's urlparse, it is much\n+    # simplified for our needs and less annoying.\n+    # Additionally, this implementations does silly things to be optimal\n+    # on CPython.\n+\n+    scheme = None\n+    auth = None\n+    host = None\n+    port = None\n+    path = None\n+    fragment = None\n+    query = None\n+\n+    # Scheme\n+    if '://' in url:\n+        scheme, url = url.split('://', 1)\n+\n+    # Find the earliest Authority Terminator\n+    # (http://tools.ietf.org/html/rfc3986#section-3.2)\n+    url, path_, delim = split_first(url, ['/', '?', '#'])\n+\n+    if delim:\n+        # Reassemble the path\n+        path = delim + path_\n+\n+    # Auth\n+    if '@' in url:\n+        # Last '@' denotes end of auth part\n+        auth, url = url.rsplit('@', 1)\n+\n+    # IPv6\n+    if url and url[0] == '[':\n+        host, url = url.split(']', 1)\n+        host += ']'\n+\n+    # Port\n+    if ':' in url:\n+        _host, port = url.split(':', 1)\n+\n+        if not host:\n+            host = _host\n+\n+        if port:\n+            # If given, ports must be integers.\n+            if not port.isdigit():\n+                raise LocationParseError(url)\n+            port = int(port)\n+        else:\n+            # Blank ports are cool, too. (rfc3986#section-3.2.3)\n+            port = None\n+\n+    elif not host and url:\n+        host = url\n+\n+    if not path:\n+        return Url(scheme, auth, host, port, path, query, fragment)\n+\n+    # Fragment\n+    if '#' in path:\n+        path, fragment = path.split('#', 1)\n+\n+    # Query\n+    if '?' in path:\n+        path, query = path.split('?', 1)\n+\n+    return Url(scheme, auth, host, port, path, query, fragment)\n+\n+\n+def get_host(url):\n+    \"\"\"\n+    Deprecated. Use :func:`.parse_url` instead.\n+    \"\"\"\n+    p = parse_url(url)\n+    return p.scheme or 'http', p.hostname, p.port\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
