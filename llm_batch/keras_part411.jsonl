{"custom_id": "keras#8015f697d0109ccd6021fe1b8f2bf5b133b259b9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 923 | Lines Deleted: 853 | Files Changed: 9 | Hunks: 22 | Methods Changed: 31 | Complexity Δ (Sum/Max): 64/61 | Churn Δ: 1776 | Churn Cumulative: 6809 | Contributors (this commit): 31 | Commits (past 90d): 33 | Contributors (cumulative): 56 | DMM Complexity: 1.0\n\nDIFF:\n@@ -127,8 +127,8 @@ from keras.layers.embeddings import Embedding\n from keras.layers.einsum_dense import EinsumDense\n \n # Locally-connected layers.\n-from keras.layers.local import LocallyConnected1D\n-from keras.layers.local import LocallyConnected2D\n+from keras.layers.locally_connected.locally_connected1d import LocallyConnected1D\n+from keras.layers.locally_connected.locally_connected2d import LocallyConnected2D\n \n # Merging layers.\n from keras.layers.merging.add import Add\n\n@@ -1,832 +0,0 @@\n-# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n-#\n-# Licensed under the Apache License, Version 2.0 (the \"License\");\n-# you may not use this file except in compliance with the License.\n-# You may obtain a copy of the License at\n-#\n-#     http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing, software\n-# distributed under the License is distributed on an \"AS IS\" BASIS,\n-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-# See the License for the specific language governing permissions and\n-# limitations under the License.\n-# ==============================================================================\n-# pylint: disable=g-classes-have-attributes\n-\"\"\"Locally-connected layers.\"\"\"\n-\n-import tensorflow.compat.v2 as tf\n-\n-import numpy as np\n-\n-from keras import activations\n-from keras import backend\n-from keras import constraints\n-from keras import initializers\n-from keras import regularizers\n-from keras.engine.base_layer import Layer\n-from keras.engine.input_spec import InputSpec\n-from keras.utils import conv_utils\n-from keras.utils import tf_utils\n-from tensorflow.python.util.tf_export import keras_export\n-\n-\n-@keras_export('keras.layers.LocallyConnected1D')\n-class LocallyConnected1D(Layer):\n-  \"\"\"Locally-connected layer for 1D inputs.\n-\n-  The `LocallyConnected1D` layer works similarly to\n-  the `Conv1D` layer, except that weights are unshared,\n-  that is, a different set of filters is applied at each different patch\n-  of the input.\n-\n-  Note: layer attributes cannot be modified after the layer has been called\n-  once (except the `trainable` attribute).\n-\n-  Example:\n-  ```python\n-      # apply a unshared weight convolution 1d of length 3 to a sequence with\n-      # 10 timesteps, with 64 output filters\n-      model = Sequential()\n-      model.add(LocallyConnected1D(64, 3, input_shape=(10, 32)))\n-      # now model.output_shape == (None, 8, 64)\n-      # add a new conv1d on top\n-      model.add(LocallyConnected1D(32, 3))\n-      # now model.output_shape == (None, 6, 32)\n-  ```\n-\n-  Args:\n-      filters: Integer, the dimensionality of the output space (i.e. the number\n-        of output filters in the convolution).\n-      kernel_size: An integer or tuple/list of a single integer, specifying the\n-        length of the 1D convolution window.\n-      strides: An integer or tuple/list of a single integer, specifying the\n-        stride length of the convolution.\n-      padding: Currently only supports `\"valid\"` (case-insensitive). `\"same\"`\n-        may be supported in the future. `\"valid\"` means no padding.\n-      data_format: A string, one of `channels_last` (default) or\n-        `channels_first`. The ordering of the dimensions in the inputs.\n-        `channels_last` corresponds to inputs with shape `(batch, length,\n-        channels)` while `channels_first` corresponds to inputs with shape\n-        `(batch, channels, length)`. It defaults to the `image_data_format`\n-        value found in your Keras config file at `~/.keras/keras.json`. If you\n-        never set it, then it will be \"channels_last\".\n-      activation: Activation function to use. If you don't specify anything, no\n-        activation is applied\n-          (ie. \"linear\" activation: `a(x) = x`).\n-      use_bias: Boolean, whether the layer uses a bias vector.\n-      kernel_initializer: Initializer for the `kernel` weights matrix.\n-      bias_initializer: Initializer for the bias vector.\n-      kernel_regularizer: Regularizer function applied to the `kernel` weights\n-        matrix.\n-      bias_regularizer: Regularizer function applied to the bias vector.\n-      activity_regularizer: Regularizer function applied to the output of the\n-        layer (its \"activation\")..\n-      kernel_constraint: Constraint function applied to the kernel matrix.\n-      bias_constraint: Constraint function applied to the bias vector.\n-      implementation: implementation mode, either `1`, `2`, or `3`. `1` loops\n-        over input spatial locations to perform the forward pass. It is\n-        memory-efficient but performs a lot of (small) ops.  `2` stores layer\n-        weights in a dense but sparsely-populated 2D matrix and implements the\n-        forward pass as a single matrix-multiply. It uses a lot of RAM but\n-        performs few (large) ops.  `3` stores layer weights in a sparse tensor\n-        and implements the forward pass as a single sparse matrix-multiply.\n-          How to choose:\n-          `1`: large, dense models,\n-          `2`: small models,\n-          `3`: large, sparse models,  where \"large\" stands for large\n-            input/output activations (i.e. many `filters`, `input_filters`,\n-            large `input_size`, `output_size`), and \"sparse\" stands for few\n-            connections between inputs and outputs, i.e. small ratio `filters *\n-            input_filters * kernel_size / (input_size * strides)`, where inputs\n-            to and outputs of the layer are assumed to have shapes `(input_size,\n-            input_filters)`, `(output_size, filters)` respectively.  It is\n-            recommended to benchmark each in the setting of interest to pick the\n-            most efficient one (in terms of speed and memory usage). Correct\n-            choice of implementation can lead to dramatic speed improvements\n-            (e.g. 50X), potentially at the expense of RAM.  Also, only\n-            `padding=\"valid\"` is supported by `implementation=1`.\n-  Input shape:\n-      3D tensor with shape: `(batch_size, steps, input_dim)`\n-  Output shape:\n-      3D tensor with shape: `(batch_size, new_steps, filters)` `steps` value\n-        might have changed due to padding or strides.\n-  \"\"\"\n-\n-  def __init__(self,\n-               filters,\n-               kernel_size,\n-               strides=1,\n-               padding='valid',\n-               data_format=None,\n-               activation=None,\n-               use_bias=True,\n-               kernel_initializer='glorot_uniform',\n-               bias_initializer='zeros',\n-               kernel_regularizer=None,\n-               bias_regularizer=None,\n-               activity_regularizer=None,\n-               kernel_constraint=None,\n-               bias_constraint=None,\n-               implementation=1,\n-               **kwargs):\n-    super(LocallyConnected1D, self).__init__(**kwargs)\n-    self.filters = filters\n-    self.kernel_size = conv_utils.normalize_tuple(kernel_size, 1, 'kernel_size')\n-    self.strides = conv_utils.normalize_tuple(\n-        strides, 1, 'strides', allow_zero=True)\n-    self.padding = conv_utils.normalize_padding(padding)\n-    if self.padding != 'valid' and implementation == 1:\n-      raise ValueError('Invalid border mode for LocallyConnected1D '\n-                       '(only \"valid\" is supported if implementation is 1): ' +\n-                       padding)\n-    self.data_format = conv_utils.normalize_data_format(data_format)\n-    self.activation = activations.get(activation)\n-    self.use_bias = use_bias\n-    self.kernel_initializer = initializers.get(kernel_initializer)\n-    self.bias_initializer = initializers.get(bias_initializer)\n-    self.kernel_regularizer = regularizers.get(kernel_regularizer)\n-    self.bias_regularizer = regularizers.get(bias_regularizer)\n-    self.activity_regularizer = regularizers.get(activity_regularizer)\n-    self.kernel_constraint = constraints.get(kernel_constraint)\n-    self.bias_constraint = constraints.get(bias_constraint)\n-    self.implementation = implementation\n-    self.input_spec = InputSpec(ndim=3)\n-\n-  @property\n-  def _use_input_spec_as_call_signature(self):\n-    return False\n-\n-  @tf_utils.shape_type_conversion\n-  def build(self, input_shape):\n-    if self.data_format == 'channels_first':\n-      input_dim, input_length = input_shape[1], input_shape[2]\n-    else:\n-      input_dim, input_length = input_shape[2], input_shape[1]\n-\n-    if input_dim is None:\n-      raise ValueError(\n-          'Axis 2 of input should be fully-defined. '\n-          'Found shape:', input_shape)\n-    self.output_length = conv_utils.conv_output_length(input_length,\n-                                                       self.kernel_size[0],\n-                                                       self.padding,\n-                                                       self.strides[0])\n-\n-    if self.output_length <= 0:\n-      raise ValueError(\n-          f'One of the dimensions in the output is <= 0 '\n-          f'due to downsampling in {self.name}. Consider '\n-          f'increasing the input size. '\n-          f'Received input shape {input_shape} which would produce '\n-          f'output shape with a zero or negative value in a '\n-          f'dimension.')\n-\n-    if self.implementation == 1:\n-      self.kernel_shape = (self.output_length, self.kernel_size[0] * input_dim,\n-                           self.filters)\n-\n-      self.kernel = self.add_weight(\n-          shape=self.kernel_shape,\n-          initializer=self.kernel_initializer,\n-          name='kernel',\n-          regularizer=self.kernel_regularizer,\n-          constraint=self.kernel_constraint)\n-\n-    elif self.implementation == 2:\n-      if self.data_format == 'channels_first':\n-        self.kernel_shape = (input_dim, input_length, self.filters,\n-                             self.output_length)\n-      else:\n-        self.kernel_shape = (input_length, input_dim, self.output_length,\n-                             self.filters)\n-\n-      self.kernel = self.add_weight(\n-          shape=self.kernel_shape,\n-          initializer=self.kernel_initializer,\n-          name='kernel',\n-          regularizer=self.kernel_regularizer,\n-          constraint=self.kernel_constraint)\n-\n-      self.kernel_mask = get_locallyconnected_mask(\n-          input_shape=(input_length,),\n-          kernel_shape=self.kernel_size,\n-          strides=self.strides,\n-          padding=self.padding,\n-          data_format=self.data_format,\n-      )\n-\n-    elif self.implementation == 3:\n-      self.kernel_shape = (self.output_length * self.filters,\n-                           input_length * input_dim)\n-\n-      self.kernel_idxs = sorted(\n-          conv_utils.conv_kernel_idxs(\n-              input_shape=(input_length,),\n-              kernel_shape=self.kernel_size,\n-              strides=self.strides,\n-              padding=self.padding,\n-              filters_in=input_dim,\n-              filters_out=self.filters,\n-              data_format=self.data_format))\n-\n-      self.kernel = self.add_weight(\n-          shape=(len(self.kernel_idxs),),\n-          initializer=self.kernel_initializer,\n-          name='kernel',\n-          regularizer=self.kernel_regularizer,\n-          constraint=self.kernel_constraint)\n-\n-    else:\n-      raise ValueError('Unrecognized implementation mode: %d.' %\n-                       self.implementation)\n-\n-    if self.use_bias:\n-      self.bias = self.add_weight(\n-          shape=(self.output_length, self.filters),\n-          initializer=self.bias_initializer,\n-          name='bias',\n-          regularizer=self.bias_regularizer,\n-          constraint=self.bias_constraint)\n-    else:\n-      self.bias = None\n-\n-    if self.data_format == 'channels_first':\n-      self.input_spec = InputSpec(ndim=3, axes={1: input_dim})\n-    else:\n-      self.input_spec = InputSpec(ndim=3, axes={-1: input_dim})\n-    self.built = True\n-\n-  @tf_utils.shape_type_conversion\n-  def compute_output_shape(self, input_shape):\n-    if self.data_format == 'channels_first':\n-      input_length = input_shape[2]\n-    else:\n-      input_length = input_shape[1]\n-\n-    length = conv_utils.conv_output_length(input_length, self.kernel_size[0],\n-                                           self.padding, self.strides[0])\n-\n-    if self.data_format == 'channels_first':\n-      return (input_shape[0], self.filters, length)\n-    elif self.data_format == 'channels_last':\n-      return (input_shape[0], length, self.filters)\n-\n-  def call(self, inputs):\n-    if self.implementation == 1:\n-      output = backend.local_conv(\n-          inputs, self.kernel, self.kernel_size, self.strides,\n-          (self.output_length,), self.data_format)\n-\n-    elif self.implementation == 2:\n-      output = local_conv_matmul(inputs, self.kernel, self.kernel_mask,\n-                                 self.compute_output_shape(inputs.shape))\n-\n-    elif self.implementation == 3:\n-      output = local_conv_sparse_matmul(inputs, self.kernel, self.kernel_idxs,\n-                                        self.kernel_shape,\n-                                        self.compute_output_shape(inputs.shape))\n-\n-    else:\n-      raise ValueError('Unrecognized implementation mode: %d.' %\n-                       self.implementation)\n-\n-    if self.use_bias:\n-      output = backend.bias_add(output, self.bias, data_format=self.data_format)\n-\n-    output = self.activation(output)\n-    return output\n-\n-  def get_config(self):\n-    config = {\n-        'filters':\n-            self.filters,\n-        'kernel_size':\n-            self.kernel_size,\n-        'strides':\n-            self.strides,\n-        'padding':\n-            self.padding,\n-        'data_format':\n-            self.data_format,\n-        'activation':\n-            activations.serialize(self.activation),\n-        'use_bias':\n-            self.use_bias,\n-        'kernel_initializer':\n-            initializers.serialize(self.kernel_initializer),\n-        'bias_initializer':\n-            initializers.serialize(self.bias_initializer),\n-        'kernel_regularizer':\n-            regularizers.serialize(self.kernel_regularizer),\n-        'bias_regularizer':\n-            regularizers.serialize(self.bias_regularizer),\n-        'activity_regularizer':\n-            regularizers.serialize(self.activity_regularizer),\n-        'kernel_constraint':\n-            constraints.serialize(self.kernel_constraint),\n-        'bias_constraint':\n-            constraints.serialize(self.bias_constraint),\n-        'implementation':\n-            self.implementation\n-    }\n-    base_config = super(LocallyConnected1D, self).get_config()\n-    return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-@keras_export('keras.layers.LocallyConnected2D')\n-class LocallyConnected2D(Layer):\n-  \"\"\"Locally-connected layer for 2D inputs.\n-\n-  The `LocallyConnected2D` layer works similarly\n-  to the `Conv2D` layer, except that weights are unshared,\n-  that is, a different set of filters is applied at each\n-  different patch of the input.\n-\n-  Note: layer attributes cannot be modified after the layer has been called\n-  once (except the `trainable` attribute).\n-\n-  Examples:\n-  ```python\n-      # apply a 3x3 unshared weights convolution with 64 output filters on a\n-      32x32 image\n-      # with `data_format=\"channels_last\"`:\n-      model = Sequential()\n-      model.add(LocallyConnected2D(64, (3, 3), input_shape=(32, 32, 3)))\n-      # now model.output_shape == (None, 30, 30, 64)\n-      # notice that this layer will consume (30*30)*(3*3*3*64) + (30*30)*64\n-      parameters\n-\n-      # add a 3x3 unshared weights convolution on top, with 32 output filters:\n-      model.add(LocallyConnected2D(32, (3, 3)))\n-      # now model.output_shape == (None, 28, 28, 32)\n-  ```\n-\n-  Args:\n-      filters: Integer, the dimensionality of the output space (i.e. the number\n-        of output filters in the convolution).\n-      kernel_size: An integer or tuple/list of 2 integers, specifying the width\n-        and height of the 2D convolution window. Can be a single integer to\n-        specify the same value for all spatial dimensions.\n-      strides: An integer or tuple/list of 2 integers, specifying the strides of\n-        the convolution along the width and height. Can be a single integer to\n-        specify the same value for all spatial dimensions.\n-      padding: Currently only support `\"valid\"` (case-insensitive). `\"same\"`\n-        will be supported in future. `\"valid\"` means no padding.\n-      data_format: A string, one of `channels_last` (default) or\n-        `channels_first`. The ordering of the dimensions in the inputs.\n-        `channels_last` corresponds to inputs with shape `(batch, height, width,\n-        channels)` while `channels_first` corresponds to inputs with shape\n-        `(batch, channels, height, width)`. It defaults to the\n-        `image_data_format` value found in your Keras config file at\n-        `~/.keras/keras.json`. If you never set it, then it will be\n-        \"channels_last\".\n-      activation: Activation function to use. If you don't specify anything, no\n-        activation is applied\n-          (ie. \"linear\" activation: `a(x) = x`).\n-      use_bias: Boolean, whether the layer uses a bias vector.\n-      kernel_initializer: Initializer for the `kernel` weights matrix.\n-      bias_initializer: Initializer for the bias vector.\n-      kernel_regularizer: Regularizer function applied to the `kernel` weights\n-        matrix.\n-      bias_regularizer: Regularizer function applied to the bias vector.\n-      activity_regularizer: Regularizer function applied to the output of the\n-        layer (its \"activation\").\n-      kernel_constraint: Constraint function applied to the kernel matrix.\n-      bias_constraint: Constraint function applied to the bias vector.\n-      implementation: implementation mode, either `1`, `2`, or `3`. `1` loops\n-        over input spatial locations to perform the forward pass. It is\n-        memory-efficient but performs a lot of (small) ops.  `2` stores layer\n-        weights in a dense but sparsely-populated 2D matrix and implements the\n-        forward pass as a single matrix-multiply. It uses a lot of RAM but\n-        performs few (large) ops.  `3` stores layer weights in a sparse tensor\n-        and implements the forward pass as a single sparse matrix-multiply.\n-          How to choose:\n-          `1`: large, dense models,\n-          `2`: small models,\n-          `3`: large, sparse models,  where \"large\" stands for large\n-            input/output activations (i.e. many `filters`, `input_filters`,\n-            large `np.prod(input_size)`, `np.prod(output_size)`), and \"sparse\"\n-            stands for few connections between inputs and outputs, i.e. small\n-            ratio `filters * input_filters * np.prod(kernel_size) /\n-            (np.prod(input_size) * np.prod(strides))`, where inputs to and\n-            outputs of the layer are assumed to have shapes `input_size +\n-            (input_filters,)`, `output_size + (filters,)` respectively.  It is\n-            recommended to benchmark each in the setting of interest to pick the\n-            most efficient one (in terms of speed and memory usage). Correct\n-            choice of implementation can lead to dramatic speed improvements\n-            (e.g. 50X), potentially at the expense of RAM.  Also, only\n-            `padding=\"valid\"` is supported by `implementation=1`.\n-  Input shape:\n-      4D tensor with shape: `(samples, channels, rows, cols)` if\n-        data_format='channels_first'\n-      or 4D tensor with shape: `(samples, rows, cols, channels)` if\n-        data_format='channels_last'.\n-  Output shape:\n-      4D tensor with shape: `(samples, filters, new_rows, new_cols)` if\n-        data_format='channels_first'\n-      or 4D tensor with shape: `(samples, new_rows, new_cols, filters)` if\n-        data_format='channels_last'. `rows` and `cols` values might have changed\n-        due to padding.\n-  \"\"\"\n-\n-  def __init__(self,\n-               filters,\n-               kernel_size,\n-               strides=(1, 1),\n-               padding='valid',\n-               data_format=None,\n-               activation=None,\n-               use_bias=True,\n-               kernel_initializer='glorot_uniform',\n-               bias_initializer='zeros',\n-               kernel_regularizer=None,\n-               bias_regularizer=None,\n-               activity_regularizer=None,\n-               kernel_constraint=None,\n-               bias_constraint=None,\n-               implementation=1,\n-               **kwargs):\n-    super(LocallyConnected2D, self).__init__(**kwargs)\n-    self.filters = filters\n-    self.kernel_size = conv_utils.normalize_tuple(kernel_size, 2, 'kernel_size')\n-    self.strides = conv_utils.normalize_tuple(\n-        strides, 2, 'strides', allow_zero=True)\n-    self.padding = conv_utils.normalize_padding(padding)\n-    if self.padding != 'valid' and implementation == 1:\n-      raise ValueError('Invalid border mode for LocallyConnected2D '\n-                       '(only \"valid\" is supported if implementation is 1): ' +\n-                       padding)\n-    self.data_format = conv_utils.normalize_data_format(data_format)\n-    self.activation = activations.get(activation)\n-    self.use_bias = use_bias\n-    self.kernel_initializer = initializers.get(kernel_initializer)\n-    self.bias_initializer = initializers.get(bias_initializer)\n-    self.kernel_regularizer = regularizers.get(kernel_regularizer)\n-    self.bias_regularizer = regularizers.get(bias_regularizer)\n-    self.activity_regularizer = regularizers.get(activity_regularizer)\n-    self.kernel_constraint = constraints.get(kernel_constraint)\n-    self.bias_constraint = constraints.get(bias_constraint)\n-    self.implementation = implementation\n-    self.input_spec = InputSpec(ndim=4)\n-\n-  @property\n-  def _use_input_spec_as_call_signature(self):\n-    return False\n-\n-  @tf_utils.shape_type_conversion\n-  def build(self, input_shape):\n-    if self.data_format == 'channels_last':\n-      input_row, input_col = input_shape[1:-1]\n-      input_filter = input_shape[3]\n-    else:\n-      input_row, input_col = input_shape[2:]\n-      input_filter = input_shape[1]\n-    if input_row is None or input_col is None:\n-      raise ValueError('The spatial dimensions of the inputs to '\n-                       ' a LocallyConnected2D layer '\n-                       'should be fully-defined, but layer received '\n-                       'the inputs shape ' + str(input_shape))\n-    output_row = conv_utils.conv_output_length(input_row, self.kernel_size[0],\n-                                               self.padding, self.strides[0])\n-    output_col = conv_utils.conv_output_length(input_col, self.kernel_size[1],\n-                                               self.padding, self.strides[1])\n-    self.output_row = output_row\n-    self.output_col = output_col\n-\n-    if self.output_row <= 0 or self.output_col <= 0:\n-      raise ValueError(\n-          f'One of the dimensions in the output is <= 0 '\n-          f'due to downsampling in {self.name}. Consider '\n-          f'increasing the input size. '\n-          f'Received input shape {input_shape} which would produce '\n-          f'output shape with a zero or negative value in a '\n-          f'dimension.')\n-\n-    if self.implementation == 1:\n-      self.kernel_shape = (output_row * output_col, self.kernel_size[0] *\n-                           self.kernel_size[1] * input_filter, self.filters)\n-\n-      self.kernel = self.add_weight(\n-          shape=self.kernel_shape,\n-          initializer=self.kernel_initializer,\n-          name='kernel',\n-          regularizer=self.kernel_regularizer,\n-          constraint=self.kernel_constraint)\n-\n-    elif self.implementation == 2:\n-      if self.data_format == 'channels_first':\n-        self.kernel_shape = (input_filter, input_row, input_col, self.filters,\n-                             self.output_row, self.output_col)\n-      else:\n-        self.kernel_shape = (input_row, input_col, input_filter,\n-                             self.output_row, self.output_col, self.filters)\n-\n-      self.kernel = self.add_weight(\n-          shape=self.kernel_shape,\n-          initializer=self.kernel_initializer,\n-          name='kernel',\n-          regularizer=self.kernel_regularizer,\n-          constraint=self.kernel_constraint)\n-\n-      self.kernel_mask = get_locallyconnected_mask(\n-          input_shape=(input_row, input_col),\n-          kernel_shape=self.kernel_size,\n-          strides=self.strides,\n-          padding=self.padding,\n-          data_format=self.data_format,\n-      )\n-\n-    elif self.implementation == 3:\n-      self.kernel_shape = (self.output_row * self.output_col * self.filters,\n-                           input_row * input_col * input_filter)\n-\n-      self.kernel_idxs = sorted(\n-          conv_utils.conv_kernel_idxs(\n-              input_shape=(input_row, input_col),\n-              kernel_shape=self.kernel_size,\n-              strides=self.strides,\n-              padding=self.padding,\n-              filters_in=input_filter,\n-              filters_out=self.filters,\n-              data_format=self.data_format))\n-\n-      self.kernel = self.add_weight(\n-          shape=(len(self.kernel_idxs),),\n-          initializer=self.kernel_initializer,\n-          name='kernel',\n-          regularizer=self.kernel_regularizer,\n-          constraint=self.kernel_constraint)\n-\n-    else:\n-      raise ValueError('Unrecognized implementation mode: %d.' %\n-                       self.implementation)\n-\n-    if self.use_bias:\n-      self.bias = self.add_weight(\n-          shape=(output_row, output_col, self.filters),\n-          initializer=self.bias_initializer,\n-          name='bias',\n-          regularizer=self.bias_regularizer,\n-          constraint=self.bias_constraint)\n-    else:\n-      self.bias = None\n-    if self.data_format == 'channels_first':\n-      self.input_spec = InputSpec(ndim=4, axes={1: input_filter})\n-    else:\n-      self.input_spec = InputSpec(ndim=4, axes={-1: input_filter})\n-    self.built = True\n-\n-  @tf_utils.shape_type_conversion\n-  def compute_output_shape(self, input_shape):\n-    if self.data_format == 'channels_first':\n-      rows = input_shape[2]\n-      cols = input_shape[3]\n-    elif self.data_format == 'channels_last':\n-      rows = input_shape[1]\n-      cols = input_shape[2]\n-\n-    rows = conv_utils.conv_output_length(rows, self.kernel_size[0],\n-                                         self.padding, self.strides[0])\n-    cols = conv_utils.conv_output_length(cols, self.kernel_size[1],\n-                                         self.padding, self.strides[1])\n-\n-    if self.data_format == 'channels_first':\n-      return (input_shape[0], self.filters, rows, cols)\n-    elif self.data_format == 'channels_last':\n-      return (input_shape[0], rows, cols, self.filters)\n-\n-  def call(self, inputs):\n-    if self.implementation == 1:\n-      output = backend.local_conv(\n-          inputs, self.kernel, self.kernel_size, self.strides,\n-          (self.output_row, self.output_col),\n-          self.data_format)\n-\n-    elif self.implementation == 2:\n-      output = local_conv_matmul(inputs, self.kernel, self.kernel_mask,\n-                                 self.compute_output_shape(inputs.shape))\n-\n-    elif self.implementation == 3:\n-      output = local_conv_sparse_matmul(inputs, self.kernel, self.kernel_idxs,\n-                                        self.kernel_shape,\n-                                        self.compute_output_shape(inputs.shape))\n-\n-    else:\n-      raise ValueError('Unrecognized implementation mode: %d.' %\n-                       self.implementation)\n-\n-    if self.use_bias:\n-      output = backend.bias_add(output, self.bias, data_format=self.data_format)\n-\n-    output = self.activation(output)\n-    return output\n-\n-  def get_config(self):\n-    config = {\n-        'filters':\n-            self.filters,\n-        'kernel_size':\n-            self.kernel_size,\n-        'strides':\n-            self.strides,\n-        'padding':\n-            self.padding,\n-        'data_format':\n-            self.data_format,\n-        'activation':\n-            activations.serialize(self.activation),\n-        'use_bias':\n-            self.use_bias,\n-        'kernel_initializer':\n-            initializers.serialize(self.kernel_initializer),\n-        'bias_initializer':\n-            initializers.serialize(self.bias_initializer),\n-        'kernel_regularizer':\n-            regularizers.serialize(self.kernel_regularizer),\n-        'bias_regularizer':\n-            regularizers.serialize(self.bias_regularizer),\n-        'activity_regularizer':\n-            regularizers.serialize(self.activity_regularizer),\n-        'kernel_constraint':\n-            constraints.serialize(self.kernel_constraint),\n-        'bias_constraint':\n-            constraints.serialize(self.bias_constraint),\n-        'implementation':\n-            self.implementation\n-    }\n-    base_config = super(LocallyConnected2D, self).get_config()\n-    return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-def get_locallyconnected_mask(input_shape, kernel_shape, strides, padding,\n-                              data_format):\n-  \"\"\"Return a mask representing connectivity of a locally-connected operation.\n-\n-  This method returns a masking numpy array of 0s and 1s (of type `np.float32`)\n-  that, when element-wise multiplied with a fully-connected weight tensor, masks\n-  out the weights between disconnected input-output pairs and thus implements\n-  local connectivity through a sparse fully-connected weight tensor.\n-\n-  Assume an unshared convolution with given parameters is applied to an input\n-  having N spatial dimensions with `input_shape = (d_in1, ..., d_inN)`\n-  to produce an output with spatial shape `(d_out1, ..., d_outN)` (determined\n-  by layer parameters such as `strides`).\n-\n-  This method returns a mask which can be broadcast-multiplied (element-wise)\n-  with a 2*(N+1)-D weight matrix (equivalent to a fully-connected layer between\n-  (N+1)-D activations (N spatial + 1 channel dimensions for input and output)\n-  to make it perform an unshared convolution with given `kernel_shape`,\n-  `strides`, `padding` and `data_format`.\n-\n-  Args:\n-    input_shape: tuple of size N: `(d_in1, ..., d_inN)` spatial shape of the\n-      input.\n-    kernel_shape: tuple of size N, spatial shape of the convolutional kernel /\n-      receptive field.\n-    strides: tuple of size N, strides along each spatial dimension.\n-    padding: type of padding, string `\"same\"` or `\"valid\"`.\n-    data_format: a string, `\"channels_first\"` or `\"channels_last\"`.\n-\n-  Returns:\n-    a `np.float32`-type `np.ndarray` of shape\n-    `(1, d_in1, ..., d_inN, 1, d_out1, ..., d_outN)`\n-    if `data_format == `\"channels_first\"`, or\n-    `(d_in1, ..., d_inN, 1, d_out1, ..., d_outN, 1)`\n-    if `data_format == \"channels_last\"`.\n-\n-  Raises:\n-    ValueError: if `data_format` is neither `\"channels_first\"` nor\n-                `\"channels_last\"`.\n-  \"\"\"\n-  mask = conv_utils.conv_kernel_mask(\n-      input_shape=input_shape,\n-      kernel_shape=kernel_shape,\n-      strides=strides,\n-      padding=padding)\n-\n-  ndims = int(mask.ndim / 2)\n-\n-  if data_format == 'channels_first':\n-    mask = np.expand_dims(mask, 0)\n-    mask = np.expand_dims(mask, -ndims - 1)\n-\n-  elif data_format == 'channels_last':\n-    mask = np.expand_dims(mask, ndims)\n-    mask = np.expand_dims(mask, -1)\n-\n-  else:\n-    raise ValueError('Unrecognized data_format: ' + str(data_format))\n-\n-  return mask\n-\n-\n-def local_conv_matmul(inputs, kernel, kernel_mask, output_shape):\n-  \"\"\"Apply N-D convolution with un-shared weights using a single matmul call.\n-\n-  This method outputs `inputs . (kernel * kernel_mask)`\n-  (with `.` standing for matrix-multiply and `*` for element-wise multiply)\n-  and requires a precomputed `kernel_mask` to zero-out weights in `kernel` and\n-  hence perform the same operation as a convolution with un-shared\n-  (the remaining entries in `kernel`) weights. It also does the necessary\n-  reshapes to make `inputs` and `kernel` 2-D and `output` (N+2)-D.\n-\n-  Args:\n-      inputs: (N+2)-D tensor with shape `(batch_size, channels_in, d_in1, ...,\n-        d_inN)` or `(batch_size, d_in1, ..., d_inN, channels_in)`.\n-      kernel: the unshared weights for N-D convolution,\n-          an (N+2)-D tensor of shape: `(d_in1, ..., d_inN, channels_in, d_out2,\n-            ..., d_outN, channels_out)` or `(channels_in, d_in1, ..., d_inN,\n-            channels_out, d_out2, ..., d_outN)`, with the ordering of channels\n-            and spatial dimensions matching that of the input. Each entry is the\n-            weight between a particular input and output location, similarly to\n-            a fully-connected weight matrix.\n-      kernel_mask: a float 0/1 mask tensor of shape: `(d_in1, ..., d_inN, 1,\n-        d_out2, ..., d_outN, 1)` or `(1, d_in1, ..., d_inN, 1, d_out2, ...,\n-        d_outN)`, with the ordering of singleton and spatial dimensions matching\n-        that of the input. Mask represents the connectivity pattern of the layer\n-        and is\n-           precomputed elsewhere based on layer parameters: stride, padding, and\n-             the receptive field shape.\n-      output_shape: a tuple of (N+2) elements representing the output shape:\n-        `(batch_size, channels_out, d_out1, ..., d_outN)` or `(batch_size,\n-        d_out1, ..., d_outN, channels_out)`, with the ordering of channels and\n-        spatial dimensions matching that of the input.\n-\n-  Returns:\n-      Output (N+2)-D tensor with shape `output_shape`.\n-  \"\"\"\n-  inputs_flat = backend.reshape(inputs, (backend.shape(inputs)[0], -1))\n-\n-  kernel = kernel_mask * kernel\n-  kernel = make_2d(kernel, split_dim=backend.ndim(kernel) // 2)\n-\n-  output_flat = tf.matmul(inputs_flat, kernel, b_is_sparse=True)\n-  output = backend.reshape(output_flat, [\n-      backend.shape(output_flat)[0],\n-  ] + output_shape.as_list()[1:])\n-  return output\n-\n-\n-def local_conv_sparse_matmul(inputs, kernel, kernel_idxs, kernel_shape,\n-                             output_shape):\n-  \"\"\"Apply N-D convolution with un-shared weights using a single sparse matmul.\n-\n-  This method outputs `inputs . tf.sparse.SparseTensor(indices=kernel_idxs,\n-  values=kernel, dense_shape=kernel_shape)`, with `.` standing for\n-  matrix-multiply. It also reshapes `inputs` to 2-D and `output` to (N+2)-D.\n-\n-  Args:\n-      inputs: (N+2)-D tensor with shape `(batch_size, channels_in, d_in1, ...,\n-        d_inN)` or `(batch_size, d_in1, ..., d_inN, channels_in)`.\n-      kernel: a 1-D tensor with shape `(len(kernel_idxs),)` containing all the\n-        weights of the layer.\n-      kernel_idxs:  a list of integer tuples representing indices in a sparse\n-        matrix performing the un-shared convolution as a matrix-multiply.\n-      kernel_shape: a tuple `(input_size, output_size)`, where `input_size =\n-        channels_in * d_in1 * ... * d_inN` and `output_size = channels_out *\n-        d_out1 * ... * d_outN`.\n-      output_shape: a tuple of (N+2) elements representing the output shape:\n-        `(batch_size, channels_out, d_out1, ..., d_outN)` or `(batch_size,\n-        d_out1, ..., d_outN, channels_out)`, with the ordering of channels and\n-        spatial dimensions matching that of the input.\n-\n-  Returns:\n-      Output (N+2)-D dense tensor with shape `output_shape`.\n-  \"\"\"\n-  inputs_flat = backend.reshape(inputs, (backend.shape(inputs)[0], -1))\n-  output_flat = tf.sparse.sparse_dense_matmul(\n-      sp_a=tf.SparseTensor(kernel_idxs, kernel, kernel_shape),\n-      b=inputs_flat,\n-      adjoint_b=True)\n-  output_flat_transpose = backend.transpose(output_flat)\n-\n-  output_reshaped = backend.reshape(output_flat_transpose, [\n-      backend.shape(output_flat_transpose)[0],\n-  ] + output_shape.as_list()[1:])\n-  return output_reshaped\n-\n-\n-def make_2d(tensor, split_dim):\n-  \"\"\"Reshapes an N-dimensional tensor into a 2D tensor.\n-\n-  Dimensions before (excluding) and after (including) `split_dim` are grouped\n-  together.\n-\n-  Args:\n-    tensor: a tensor of shape `(d0, ..., d(N-1))`.\n-    split_dim: an integer from 1 to N-1, index of the dimension to group\n-      dimensions before (excluding) and after (including).\n-\n-  Returns:\n-    Tensor of shape\n-    `(d0 * ... * d(split_dim-1), d(split_dim) * ... * d(N-1))`.\n-  \"\"\"\n-  shape = tf.shape(tensor)\n-  in_dims = shape[:split_dim]\n-  out_dims = shape[split_dim:]\n-\n-  in_size = tf.reduce_prod(in_dims)\n-  out_size = tf.reduce_prod(out_dims)\n-\n-  return tf.reshape(tensor, (in_size, out_size))\n\n@@ -0,0 +1,18 @@\n+# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Keras locally-connected layers.\"\"\"\n+\n+from keras.layers.locally_connected.locally_connected1d import LocallyConnected1D\n+from keras.layers.locally_connected.locally_connected2d import LocallyConnected2D\n\n@@ -0,0 +1,333 @@\n+# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+# pylint: disable=g-classes-have-attributes,g-direct-tensorflow-import\n+\"\"\"Locally-connected layer for 1D input.\"\"\"\n+\n+from keras import activations\n+from keras import backend\n+from keras import constraints\n+from keras import initializers\n+from keras import regularizers\n+from keras.engine.base_layer import Layer\n+from keras.engine.input_spec import InputSpec\n+from keras.layers.locally_connected import locally_connected_utils\n+from keras.utils import conv_utils\n+from keras.utils import tf_utils\n+\n+from tensorflow.python.util.tf_export import keras_export\n+\n+\n+@keras_export('keras.layers.LocallyConnected1D')\n+class LocallyConnected1D(Layer):\n+  \"\"\"Locally-connected layer for 1D inputs.\n+\n+  The `LocallyConnected1D` layer works similarly to\n+  the `Conv1D` layer, except that weights are unshared,\n+  that is, a different set of filters is applied at each different patch\n+  of the input.\n+\n+  Note: layer attributes cannot be modified after the layer has been called\n+  once (except the `trainable` attribute).\n+\n+  Example:\n+  ```python\n+      # apply a unshared weight convolution 1d of length 3 to a sequence with\n+      # 10 timesteps, with 64 output filters\n+      model = Sequential()\n+      model.add(LocallyConnected1D(64, 3, input_shape=(10, 32)))\n+      # now model.output_shape == (None, 8, 64)\n+      # add a new conv1d on top\n+      model.add(LocallyConnected1D(32, 3))\n+      # now model.output_shape == (None, 6, 32)\n+  ```\n+\n+  Args:\n+      filters: Integer, the dimensionality of the output space (i.e. the number\n+        of output filters in the convolution).\n+      kernel_size: An integer or tuple/list of a single integer, specifying the\n+        length of the 1D convolution window.\n+      strides: An integer or tuple/list of a single integer, specifying the\n+        stride length of the convolution.\n+      padding: Currently only supports `\"valid\"` (case-insensitive). `\"same\"`\n+        may be supported in the future. `\"valid\"` means no padding.\n+      data_format: A string, one of `channels_last` (default) or\n+        `channels_first`. The ordering of the dimensions in the inputs.\n+        `channels_last` corresponds to inputs with shape `(batch, length,\n+        channels)` while `channels_first` corresponds to inputs with shape\n+        `(batch, channels, length)`. It defaults to the `image_data_format`\n+        value found in your Keras config file at `~/.keras/keras.json`. If you\n+        never set it, then it will be \"channels_last\".\n+      activation: Activation function to use. If you don't specify anything, no\n+        activation is applied\n+          (ie. \"linear\" activation: `a(x) = x`).\n+      use_bias: Boolean, whether the layer uses a bias vector.\n+      kernel_initializer: Initializer for the `kernel` weights matrix.\n+      bias_initializer: Initializer for the bias vector.\n+      kernel_regularizer: Regularizer function applied to the `kernel` weights\n+        matrix.\n+      bias_regularizer: Regularizer function applied to the bias vector.\n+      activity_regularizer: Regularizer function applied to the output of the\n+        layer (its \"activation\")..\n+      kernel_constraint: Constraint function applied to the kernel matrix.\n+      bias_constraint: Constraint function applied to the bias vector.\n+      implementation: implementation mode, either `1`, `2`, or `3`. `1` loops\n+        over input spatial locations to perform the forward pass. It is\n+        memory-efficient but performs a lot of (small) ops.  `2` stores layer\n+        weights in a dense but sparsely-populated 2D matrix and implements the\n+        forward pass as a single matrix-multiply. It uses a lot of RAM but\n+        performs few (large) ops.  `3` stores layer weights in a sparse tensor\n+        and implements the forward pass as a single sparse matrix-multiply.\n+          How to choose:\n+          `1`: large, dense models,\n+          `2`: small models,\n+          `3`: large, sparse models,  where \"large\" stands for large\n+            input/output activations (i.e. many `filters`, `input_filters`,\n+            large `input_size`, `output_size`), and \"sparse\" stands for few\n+            connections between inputs and outputs, i.e. small ratio `filters *\n+            input_filters * kernel_size / (input_size * strides)`, where inputs\n+            to and outputs of the layer are assumed to have shapes `(input_size,\n+            input_filters)`, `(output_size, filters)` respectively.  It is\n+            recommended to benchmark each in the setting of interest to pick the\n+            most efficient one (in terms of speed and memory usage). Correct\n+            choice of implementation can lead to dramatic speed improvements\n+            (e.g. 50X), potentially at the expense of RAM.  Also, only\n+            `padding=\"valid\"` is supported by `implementation=1`.\n+  Input shape:\n+      3D tensor with shape: `(batch_size, steps, input_dim)`\n+  Output shape:\n+      3D tensor with shape: `(batch_size, new_steps, filters)` `steps` value\n+        might have changed due to padding or strides.\n+  \"\"\"\n+\n+  def __init__(self,\n+               filters,\n+               kernel_size,\n+               strides=1,\n+               padding='valid',\n+               data_format=None,\n+               activation=None,\n+               use_bias=True,\n+               kernel_initializer='glorot_uniform',\n+               bias_initializer='zeros',\n+               kernel_regularizer=None,\n+               bias_regularizer=None,\n+               activity_regularizer=None,\n+               kernel_constraint=None,\n+               bias_constraint=None,\n+               implementation=1,\n+               **kwargs):\n+    super(LocallyConnected1D, self).__init__(**kwargs)\n+    self.filters = filters\n+    self.kernel_size = conv_utils.normalize_tuple(kernel_size, 1, 'kernel_size')\n+    self.strides = conv_utils.normalize_tuple(\n+        strides, 1, 'strides', allow_zero=True)\n+    self.padding = conv_utils.normalize_padding(padding)\n+    if self.padding != 'valid' and implementation == 1:\n+      raise ValueError('Invalid border mode for LocallyConnected1D '\n+                       '(only \"valid\" is supported if implementation is 1): ' +\n+                       padding)\n+    self.data_format = conv_utils.normalize_data_format(data_format)\n+    self.activation = activations.get(activation)\n+    self.use_bias = use_bias\n+    self.kernel_initializer = initializers.get(kernel_initializer)\n+    self.bias_initializer = initializers.get(bias_initializer)\n+    self.kernel_regularizer = regularizers.get(kernel_regularizer)\n+    self.bias_regularizer = regularizers.get(bias_regularizer)\n+    self.activity_regularizer = regularizers.get(activity_regularizer)\n+    self.kernel_constraint = constraints.get(kernel_constraint)\n+    self.bias_constraint = constraints.get(bias_constraint)\n+    self.implementation = implementation\n+    self.input_spec = InputSpec(ndim=3)\n+\n+  @property\n+  def _use_input_spec_as_call_signature(self):\n+    return False\n+\n+  @tf_utils.shape_type_conversion\n+  def build(self, input_shape):\n+    if self.data_format == 'channels_first':\n+      input_dim, input_length = input_shape[1], input_shape[2]\n+    else:\n+      input_dim, input_length = input_shape[2], input_shape[1]\n+\n+    if input_dim is None:\n+      raise ValueError(\n+          'Axis 2 of input should be fully-defined. '\n+          'Found shape:', input_shape)\n+    self.output_length = conv_utils.conv_output_length(input_length,\n+                                                       self.kernel_size[0],\n+                                                       self.padding,\n+                                                       self.strides[0])\n+\n+    if self.output_length <= 0:\n+      raise ValueError(\n+          f'One of the dimensions in the output is <= 0 '\n+          f'due to downsampling in {self.name}. Consider '\n+          f'increasing the input size. '\n+          f'Received input shape {input_shape} which would produce '\n+          f'output shape with a zero or negative value in a '\n+          f'dimension.')\n+\n+    if self.implementation == 1:\n+      self.kernel_shape = (self.output_length, self.kernel_size[0] * input_dim,\n+                           self.filters)\n+\n+      self.kernel = self.add_weight(\n+          shape=self.kernel_shape,\n+          initializer=self.kernel_initializer,\n+          name='kernel',\n+          regularizer=self.kernel_regularizer,\n+          constraint=self.kernel_constraint)\n+\n+    elif self.implementation == 2:\n+      if self.data_format == 'channels_first':\n+        self.kernel_shape = (input_dim, input_length, self.filters,\n+                             self.output_length)\n+      else:\n+        self.kernel_shape = (input_length, input_dim, self.output_length,\n+                             self.filters)\n+\n+      self.kernel = self.add_weight(\n+          shape=self.kernel_shape,\n+          initializer=self.kernel_initializer,\n+          name='kernel',\n+          regularizer=self.kernel_regularizer,\n+          constraint=self.kernel_constraint)\n+\n+      self.kernel_mask = locally_connected_utils.get_locallyconnected_mask(\n+          input_shape=(input_length,),\n+          kernel_shape=self.kernel_size,\n+          strides=self.strides,\n+          padding=self.padding,\n+          data_format=self.data_format,\n+      )\n+\n+    elif self.implementation == 3:\n+      self.kernel_shape = (self.output_length * self.filters,\n+                           input_length * input_dim)\n+\n+      self.kernel_idxs = sorted(\n+          conv_utils.conv_kernel_idxs(\n+              input_shape=(input_length,),\n+              kernel_shape=self.kernel_size,\n+              strides=self.strides,\n+              padding=self.padding,\n+              filters_in=input_dim,\n+              filters_out=self.filters,\n+              data_format=self.data_format))\n+\n+      self.kernel = self.add_weight(\n+          shape=(len(self.kernel_idxs),),\n+          initializer=self.kernel_initializer,\n+          name='kernel',\n+          regularizer=self.kernel_regularizer,\n+          constraint=self.kernel_constraint)\n+\n+    else:\n+      raise ValueError('Unrecognized implementation mode: %d.' %\n+                       self.implementation)\n+\n+    if self.use_bias:\n+      self.bias = self.add_weight(\n+          shape=(self.output_length, self.filters),\n+          initializer=self.bias_initializer,\n+          name='bias',\n+          regularizer=self.bias_regularizer,\n+          constraint=self.bias_constraint)\n+    else:\n+      self.bias = None\n+\n+    if self.data_format == 'channels_first':\n+      self.input_spec = InputSpec(ndim=3, axes={1: input_dim})\n+    else:\n+      self.input_spec = InputSpec(ndim=3, axes={-1: input_dim})\n+    self.built = True\n+\n+  @tf_utils.shape_type_conversion\n+  def compute_output_shape(self, input_shape):\n+    if self.data_format == 'channels_first':\n+      input_length = input_shape[2]\n+    else:\n+      input_length = input_shape[1]\n+\n+    length = conv_utils.conv_output_length(input_length, self.kernel_size[0],\n+                                           self.padding, self.strides[0])\n+\n+    if self.data_format == 'channels_first':\n+      return (input_shape[0], self.filters, length)\n+    elif self.data_format == 'channels_last':\n+      return (input_shape[0], length, self.filters)\n+\n+  def call(self, inputs):\n+    if self.implementation == 1:\n+      output = backend.local_conv(\n+          inputs, self.kernel, self.kernel_size, self.strides,\n+          (self.output_length,), self.data_format)\n+\n+    elif self.implementation == 2:\n+      output = locally_connected_utils.local_conv_matmul(\n+          inputs, self.kernel, self.kernel_mask,\n+          self.compute_output_shape(inputs.shape))\n+\n+    elif self.implementation == 3:\n+      output = locally_connected_utils.local_conv_sparse_matmul(\n+          inputs, self.kernel, self.kernel_idxs, self.kernel_shape,\n+          self.compute_output_shape(inputs.shape))\n+\n+    else:\n+      raise ValueError('Unrecognized implementation mode: %d.' %\n+                       self.implementation)\n+\n+    if self.use_bias:\n+      output = backend.bias_add(output, self.bias, data_format=self.data_format)\n+\n+    output = self.activation(output)\n+    return output\n+\n+  def get_config(self):\n+    config = {\n+        'filters':\n+            self.filters,\n+        'kernel_size':\n+            self.kernel_size,\n+        'strides':\n+            self.strides,\n+        'padding':\n+            self.padding,\n+        'data_format':\n+            self.data_format,\n+        'activation':\n+            activations.serialize(self.activation),\n+        'use_bias':\n+            self.use_bias,\n+        'kernel_initializer':\n+            initializers.serialize(self.kernel_initializer),\n+        'bias_initializer':\n+            initializers.serialize(self.bias_initializer),\n+        'kernel_regularizer':\n+            regularizers.serialize(self.kernel_regularizer),\n+        'bias_regularizer':\n+            regularizers.serialize(self.bias_regularizer),\n+        'activity_regularizer':\n+            regularizers.serialize(self.activity_regularizer),\n+        'kernel_constraint':\n+            constraints.serialize(self.kernel_constraint),\n+        'bias_constraint':\n+            constraints.serialize(self.bias_constraint),\n+        'implementation':\n+            self.implementation\n+    }\n+    base_config = super(LocallyConnected1D, self).get_config()\n+    return dict(list(base_config.items()) + list(config.items()))\n\n@@ -0,0 +1,355 @@\n+# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+# pylint: disable=g-classes-have-attributes,g-direct-tensorflow-import\n+\"\"\"Locally-connected layer for 2D input.\"\"\"\n+\n+from keras import activations\n+from keras import backend\n+from keras import constraints\n+from keras import initializers\n+from keras import regularizers\n+from keras.engine.base_layer import Layer\n+from keras.engine.input_spec import InputSpec\n+from keras.layers.locally_connected import locally_connected_utils\n+from keras.utils import conv_utils\n+from keras.utils import tf_utils\n+\n+from tensorflow.python.util.tf_export import keras_export\n+\n+\n+@keras_export('keras.layers.LocallyConnected2D')\n+class LocallyConnected2D(Layer):\n+  \"\"\"Locally-connected layer for 2D inputs.\n+\n+  The `LocallyConnected2D` layer works similarly\n+  to the `Conv2D` layer, except that weights are unshared,\n+  that is, a different set of filters is applied at each\n+  different patch of the input.\n+\n+  Note: layer attributes cannot be modified after the layer has been called\n+  once (except the `trainable` attribute).\n+\n+  Examples:\n+  ```python\n+      # apply a 3x3 unshared weights convolution with 64 output filters on a\n+      32x32 image\n+      # with `data_format=\"channels_last\"`:\n+      model = Sequential()\n+      model.add(LocallyConnected2D(64, (3, 3), input_shape=(32, 32, 3)))\n+      # now model.output_shape == (None, 30, 30, 64)\n+      # notice that this layer will consume (30*30)*(3*3*3*64) + (30*30)*64\n+      parameters\n+\n+      # add a 3x3 unshared weights convolution on top, with 32 output filters:\n+      model.add(LocallyConnected2D(32, (3, 3)))\n+      # now model.output_shape == (None, 28, 28, 32)\n+  ```\n+\n+  Args:\n+      filters: Integer, the dimensionality of the output space (i.e. the number\n+        of output filters in the convolution).\n+      kernel_size: An integer or tuple/list of 2 integers, specifying the width\n+        and height of the 2D convolution window. Can be a single integer to\n+        specify the same value for all spatial dimensions.\n+      strides: An integer or tuple/list of 2 integers, specifying the strides of\n+        the convolution along the width and height. Can be a single integer to\n+        specify the same value for all spatial dimensions.\n+      padding: Currently only support `\"valid\"` (case-insensitive). `\"same\"`\n+        will be supported in future. `\"valid\"` means no padding.\n+      data_format: A string, one of `channels_last` (default) or\n+        `channels_first`. The ordering of the dimensions in the inputs.\n+        `channels_last` corresponds to inputs with shape `(batch, height, width,\n+        channels)` while `channels_first` corresponds to inputs with shape\n+        `(batch, channels, height, width)`. It defaults to the\n+        `image_data_format` value found in your Keras config file at\n+        `~/.keras/keras.json`. If you never set it, then it will be\n+        \"channels_last\".\n+      activation: Activation function to use. If you don't specify anything, no\n+        activation is applied\n+          (ie. \"linear\" activation: `a(x) = x`).\n+      use_bias: Boolean, whether the layer uses a bias vector.\n+      kernel_initializer: Initializer for the `kernel` weights matrix.\n+      bias_initializer: Initializer for the bias vector.\n+      kernel_regularizer: Regularizer function applied to the `kernel` weights\n+        matrix.\n+      bias_regularizer: Regularizer function applied to the bias vector.\n+      activity_regularizer: Regularizer function applied to the output of the\n+        layer (its \"activation\").\n+      kernel_constraint: Constraint function applied to the kernel matrix.\n+      bias_constraint: Constraint function applied to the bias vector.\n+      implementation: implementation mode, either `1`, `2`, or `3`. `1` loops\n+        over input spatial locations to perform the forward pass. It is\n+        memory-efficient but performs a lot of (small) ops.  `2` stores layer\n+        weights in a dense but sparsely-populated 2D matrix and implements the\n+        forward pass as a single matrix-multiply. It uses a lot of RAM but\n+        performs few (large) ops.  `3` stores layer weights in a sparse tensor\n+        and implements the forward pass as a single sparse matrix-multiply.\n+          How to choose:\n+          `1`: large, dense models,\n+          `2`: small models,\n+          `3`: large, sparse models,  where \"large\" stands for large\n+            input/output activations (i.e. many `filters`, `input_filters`,\n+            large `np.prod(input_size)`, `np.prod(output_size)`), and \"sparse\"\n+            stands for few connections between inputs and outputs, i.e. small\n+            ratio `filters * input_filters * np.prod(kernel_size) /\n+            (np.prod(input_size) * np.prod(strides))`, where inputs to and\n+            outputs of the layer are assumed to have shapes `input_size +\n+            (input_filters,)`, `output_size + (filters,)` respectively.  It is\n+            recommended to benchmark each in the setting of interest to pick the\n+            most efficient one (in terms of speed and memory usage). Correct\n+            choice of implementation can lead to dramatic speed improvements\n+            (e.g. 50X), potentially at the expense of RAM.  Also, only\n+            `padding=\"valid\"` is supported by `implementation=1`.\n+  Input shape:\n+      4D tensor with shape: `(samples, channels, rows, cols)` if\n+        data_format='channels_first'\n+      or 4D tensor with shape: `(samples, rows, cols, channels)` if\n+        data_format='channels_last'.\n+  Output shape:\n+      4D tensor with shape: `(samples, filters, new_rows, new_cols)` if\n+        data_format='channels_first'\n+      or 4D tensor with shape: `(samples, new_rows, new_cols, filters)` if\n+        data_format='channels_last'. `rows` and `cols` values might have changed\n+        due to padding.\n+  \"\"\"\n+\n+  def __init__(self,\n+               filters,\n+               kernel_size,\n+               strides=(1, 1),\n+               padding='valid',\n+               data_format=None,\n+               activation=None,\n+               use_bias=True,\n+               kernel_initializer='glorot_uniform',\n+               bias_initializer='zeros',\n+               kernel_regularizer=None,\n+               bias_regularizer=None,\n+               activity_regularizer=None,\n+               kernel_constraint=None,\n+               bias_constraint=None,\n+               implementation=1,\n+               **kwargs):\n+    super(LocallyConnected2D, self).__init__(**kwargs)\n+    self.filters = filters\n+    self.kernel_size = conv_utils.normalize_tuple(kernel_size, 2, 'kernel_size')\n+    self.strides = conv_utils.normalize_tuple(\n+        strides, 2, 'strides', allow_zero=True)\n+    self.padding = conv_utils.normalize_padding(padding)\n+    if self.padding != 'valid' and implementation == 1:\n+      raise ValueError('Invalid border mode for LocallyConnected2D '\n+                       '(only \"valid\" is supported if implementation is 1): ' +\n+                       padding)\n+    self.data_format = conv_utils.normalize_data_format(data_format)\n+    self.activation = activations.get(activation)\n+    self.use_bias = use_bias\n+    self.kernel_initializer = initializers.get(kernel_initializer)\n+    self.bias_initializer = initializers.get(bias_initializer)\n+    self.kernel_regularizer = regularizers.get(kernel_regularizer)\n+    self.bias_regularizer = regularizers.get(bias_regularizer)\n+    self.activity_regularizer = regularizers.get(activity_regularizer)\n+    self.kernel_constraint = constraints.get(kernel_constraint)\n+    self.bias_constraint = constraints.get(bias_constraint)\n+    self.implementation = implementation\n+    self.input_spec = InputSpec(ndim=4)\n+\n+  @property\n+  def _use_input_spec_as_call_signature(self):\n+    return False\n+\n+  @tf_utils.shape_type_conversion\n+  def build(self, input_shape):\n+    if self.data_format == 'channels_last':\n+      input_row, input_col = input_shape[1:-1]\n+      input_filter = input_shape[3]\n+    else:\n+      input_row, input_col = input_shape[2:]\n+      input_filter = input_shape[1]\n+    if input_row is None or input_col is None:\n+      raise ValueError('The spatial dimensions of the inputs to '\n+                       ' a LocallyConnected2D layer '\n+                       'should be fully-defined, but layer received '\n+                       'the inputs shape ' + str(input_shape))\n+    output_row = conv_utils.conv_output_length(input_row, self.kernel_size[0],\n+                                               self.padding, self.strides[0])\n+    output_col = conv_utils.conv_output_length(input_col, self.kernel_size[1],\n+                                               self.padding, self.strides[1])\n+    self.output_row = output_row\n+    self.output_col = output_col\n+\n+    if self.output_row <= 0 or self.output_col <= 0:\n+      raise ValueError(\n+          f'One of the dimensions in the output is <= 0 '\n+          f'due to downsampling in {self.name}. Consider '\n+          f'increasing the input size. '\n+          f'Received input shape {input_shape} which would produce '\n+          f'output shape with a zero or negative value in a '\n+          f'dimension.')\n+\n+    if self.implementation == 1:\n+      self.kernel_shape = (output_row * output_col, self.kernel_size[0] *\n+                           self.kernel_size[1] * input_filter, self.filters)\n+\n+      self.kernel = self.add_weight(\n+          shape=self.kernel_shape,\n+          initializer=self.kernel_initializer,\n+          name='kernel',\n+          regularizer=self.kernel_regularizer,\n+          constraint=self.kernel_constraint)\n+\n+    elif self.implementation == 2:\n+      if self.data_format == 'channels_first':\n+        self.kernel_shape = (input_filter, input_row, input_col, self.filters,\n+                             self.output_row, self.output_col)\n+      else:\n+        self.kernel_shape = (input_row, input_col, input_filter,\n+                             self.output_row, self.output_col, self.filters)\n+\n+      self.kernel = self.add_weight(\n+          shape=self.kernel_shape,\n+          initializer=self.kernel_initializer,\n+          name='kernel',\n+          regularizer=self.kernel_regularizer,\n+          constraint=self.kernel_constraint)\n+\n+      self.kernel_mask = locally_connected_utils.get_locallyconnected_mask(\n+          input_shape=(input_row, input_col),\n+          kernel_shape=self.kernel_size,\n+          strides=self.strides,\n+          padding=self.padding,\n+          data_format=self.data_format,\n+      )\n+\n+    elif self.implementation == 3:\n+      self.kernel_shape = (self.output_row * self.output_col * self.filters,\n+                           input_row * input_col * input_filter)\n+\n+      self.kernel_idxs = sorted(\n+          conv_utils.conv_kernel_idxs(\n+              input_shape=(input_row, input_col),\n+              kernel_shape=self.kernel_size,\n+              strides=self.strides,\n+              padding=self.padding,\n+              filters_in=input_filter,\n+              filters_out=self.filters,\n+              data_format=self.data_format))\n+\n+      self.kernel = self.add_weight(\n+          shape=(len(self.kernel_idxs),),\n+          initializer=self.kernel_initializer,\n+          name='kernel',\n+          regularizer=self.kernel_regularizer,\n+          constraint=self.kernel_constraint)\n+\n+    else:\n+      raise ValueError('Unrecognized implementation mode: %d.' %\n+                       self.implementation)\n+\n+    if self.use_bias:\n+      self.bias = self.add_weight(\n+          shape=(output_row, output_col, self.filters),\n+          initializer=self.bias_initializer,\n+          name='bias',\n+          regularizer=self.bias_regularizer,\n+          constraint=self.bias_constraint)\n+    else:\n+      self.bias = None\n+    if self.data_format == 'channels_first':\n+      self.input_spec = InputSpec(ndim=4, axes={1: input_filter})\n+    else:\n+      self.input_spec = InputSpec(ndim=4, axes={-1: input_filter})\n+    self.built = True\n+\n+  @tf_utils.shape_type_conversion\n+  def compute_output_shape(self, input_shape):\n+    if self.data_format == 'channels_first':\n+      rows = input_shape[2]\n+      cols = input_shape[3]\n+    elif self.data_format == 'channels_last':\n+      rows = input_shape[1]\n+      cols = input_shape[2]\n+\n+    rows = conv_utils.conv_output_length(rows, self.kernel_size[0],\n+                                         self.padding, self.strides[0])\n+    cols = conv_utils.conv_output_length(cols, self.kernel_size[1],\n+                                         self.padding, self.strides[1])\n+\n+    if self.data_format == 'channels_first':\n+      return (input_shape[0], self.filters, rows, cols)\n+    elif self.data_format == 'channels_last':\n+      return (input_shape[0], rows, cols, self.filters)\n+\n+  def call(self, inputs):\n+    if self.implementation == 1:\n+      output = backend.local_conv(\n+          inputs, self.kernel, self.kernel_size, self.strides,\n+          (self.output_row, self.output_col),\n+          self.data_format)\n+\n+    elif self.implementation == 2:\n+      output = locally_connected_utils.local_conv_matmul(\n+          inputs, self.kernel, self.kernel_mask,\n+          self.compute_output_shape(inputs.shape))\n+\n+    elif self.implementation == 3:\n+      output = locally_connected_utils.local_conv_sparse_matmul(\n+          inputs, self.kernel, self.kernel_idxs, self.kernel_shape,\n+          self.compute_output_shape(inputs.shape))\n+\n+    else:\n+      raise ValueError('Unrecognized implementation mode: %d.' %\n+                       self.implementation)\n+\n+    if self.use_bias:\n+      output = backend.bias_add(output, self.bias, data_format=self.data_format)\n+\n+    output = self.activation(output)\n+    return output\n+\n+  def get_config(self):\n+    config = {\n+        'filters':\n+            self.filters,\n+        'kernel_size':\n+            self.kernel_size,\n+        'strides':\n+            self.strides,\n+        'padding':\n+            self.padding,\n+        'data_format':\n+            self.data_format,\n+        'activation':\n+            activations.serialize(self.activation),\n+        'use_bias':\n+            self.use_bias,\n+        'kernel_initializer':\n+            initializers.serialize(self.kernel_initializer),\n+        'bias_initializer':\n+            initializers.serialize(self.bias_initializer),\n+        'kernel_regularizer':\n+            regularizers.serialize(self.kernel_regularizer),\n+        'bias_regularizer':\n+            regularizers.serialize(self.bias_regularizer),\n+        'activity_regularizer':\n+            regularizers.serialize(self.activity_regularizer),\n+        'kernel_constraint':\n+            constraints.serialize(self.kernel_constraint),\n+        'bias_constraint':\n+            constraints.serialize(self.bias_constraint),\n+        'implementation':\n+            self.implementation\n+    }\n+    base_config = super(LocallyConnected2D, self).get_config()\n+    return dict(list(base_config.items()) + list(config.items()))\n\n@@ -13,18 +13,20 @@\n # limitations under the License.\n # ==============================================================================\n \"\"\"Tests for locally-connected layers.\"\"\"\n-\n-import tensorflow.compat.v2 as tf\n+# pylint: disable=g-direct-tensorflow-import\n \n import os\n-from absl.testing import parameterized\n-import numpy as np\n \n+from absl.testing import parameterized\n import keras\n-from tensorflow.python.framework import test_util as tf_test_util\n from keras import combinations\n from keras import testing_utils\n+from keras.layers.locally_connected import locally_connected_utils\n from keras.optimizer_v2 import rmsprop\n+import numpy as np\n+import tensorflow.compat.v2 as tf\n+\n+from tensorflow.python.framework import test_util as tf_test_util\n from tensorflow.python.training.rmsprop import RMSPropOptimizer\n \n \n@@ -137,11 +139,11 @@ class LocallyConnected1DLayersTest(tf.test.TestCase, parameterized.TestCase):\n       with self.cached_session():\n         layer = keras.layers.LocallyConnected1D(**kwargs)\n         layer.build((num_samples, num_steps, input_dim))\n-        self.assertEqual(len(layer.losses), 2)\n+        self.assertLen(layer.losses, 2)\n         layer(\n             keras.backend.variable(\n                 np.ones((num_samples, num_steps, input_dim))))\n-        self.assertEqual(len(layer.losses), 3)\n+        self.assertLen(layer.losses, 3)\n \n       k_constraint = keras.constraints.max_norm(0.01)\n       b_constraint = keras.constraints.max_norm(0.01)\n@@ -251,11 +253,11 @@ class LocallyConnected2DLayersTest(tf.test.TestCase, parameterized.TestCase):\n       with self.cached_session():\n         layer = keras.layers.LocallyConnected2D(**kwargs)\n         layer.build((num_samples, num_row, num_col, stack_size))\n-        self.assertEqual(len(layer.losses), 2)\n+        self.assertLen(layer.losses, 2)\n         layer(\n             keras.backend.variable(\n                 np.ones((num_samples, num_row, num_col, stack_size))))\n-        self.assertEqual(len(layer.losses), 3)\n+        self.assertLen(layer.losses, 3)\n \n       k_constraint = keras.constraints.max_norm(0.01)\n       b_constraint = keras.constraints.max_norm(0.01)\n@@ -522,7 +524,7 @@ class LocallyConnectedImplementationModeTest(tf.test.TestCase,\n                   int(np.prod(inputs.shape[split_dim:])))\n       inputs_2d = np.reshape(inputs, shape_2d)\n \n-      inputs_2d_tf = keras.layers.local.make_2d(inputs_tf, split_dim)\n+      inputs_2d_tf = locally_connected_utils.make_2d(inputs_tf, split_dim)\n       inputs_2d_tf = keras.backend.get_value(inputs_2d_tf)\n \n       self.assertAllCloseAccordingToType(inputs_2d, inputs_2d_tf)\n@@ -674,7 +676,7 @@ def copy_lc_weights_2_to_3(lc_layer_2_from, lc_layer_3_to):\n   lc_2_kernel, lc_2_bias = lc_layer_2_from.weights\n   lc_2_kernel_masked = lc_2_kernel * lc_layer_2_from.kernel_mask\n \n-  lc_2_kernel_masked = keras.layers.local.make_2d(\n+  lc_2_kernel_masked = locally_connected_utils.make_2d(\n       lc_2_kernel_masked, split_dim=keras.backend.ndim(lc_2_kernel_masked) // 2)\n   lc_2_kernel_masked = keras.backend.transpose(lc_2_kernel_masked)\n   lc_2_kernel_mask = tf.not_equal(lc_2_kernel_masked, 0)\n\n@@ -0,0 +1,193 @@\n+# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Private utilities for locally-connected layers.\"\"\"\n+\n+from keras import backend\n+from keras.utils import conv_utils\n+import numpy as np\n+import tensorflow.compat.v2 as tf\n+\n+\n+def get_locallyconnected_mask(input_shape, kernel_shape, strides, padding,\n+                              data_format):\n+  \"\"\"Return a mask representing connectivity of a locally-connected operation.\n+\n+  This method returns a masking numpy array of 0s and 1s (of type `np.float32`)\n+  that, when element-wise multiplied with a fully-connected weight tensor, masks\n+  out the weights between disconnected input-output pairs and thus implements\n+  local connectivity through a sparse fully-connected weight tensor.\n+\n+  Assume an unshared convolution with given parameters is applied to an input\n+  having N spatial dimensions with `input_shape = (d_in1, ..., d_inN)`\n+  to produce an output with spatial shape `(d_out1, ..., d_outN)` (determined\n+  by layer parameters such as `strides`).\n+\n+  This method returns a mask which can be broadcast-multiplied (element-wise)\n+  with a 2*(N+1)-D weight matrix (equivalent to a fully-connected layer between\n+  (N+1)-D activations (N spatial + 1 channel dimensions for input and output)\n+  to make it perform an unshared convolution with given `kernel_shape`,\n+  `strides`, `padding` and `data_format`.\n+\n+  Args:\n+    input_shape: tuple of size N: `(d_in1, ..., d_inN)` spatial shape of the\n+      input.\n+    kernel_shape: tuple of size N, spatial shape of the convolutional kernel /\n+      receptive field.\n+    strides: tuple of size N, strides along each spatial dimension.\n+    padding: type of padding, string `\"same\"` or `\"valid\"`.\n+    data_format: a string, `\"channels_first\"` or `\"channels_last\"`.\n+\n+  Returns:\n+    a `np.float32`-type `np.ndarray` of shape\n+    `(1, d_in1, ..., d_inN, 1, d_out1, ..., d_outN)`\n+    if `data_format == `\"channels_first\"`, or\n+    `(d_in1, ..., d_inN, 1, d_out1, ..., d_outN, 1)`\n+    if `data_format == \"channels_last\"`.\n+\n+  Raises:\n+    ValueError: if `data_format` is neither `\"channels_first\"` nor\n+                `\"channels_last\"`.\n+  \"\"\"\n+  mask = conv_utils.conv_kernel_mask(\n+      input_shape=input_shape,\n+      kernel_shape=kernel_shape,\n+      strides=strides,\n+      padding=padding)\n+\n+  ndims = int(mask.ndim / 2)\n+\n+  if data_format == 'channels_first':\n+    mask = np.expand_dims(mask, 0)\n+    mask = np.expand_dims(mask, -ndims - 1)\n+\n+  elif data_format == 'channels_last':\n+    mask = np.expand_dims(mask, ndims)\n+    mask = np.expand_dims(mask, -1)\n+\n+  else:\n+    raise ValueError('Unrecognized data_format: ' + str(data_format))\n+\n+  return mask\n+\n+\n+def local_conv_matmul(inputs, kernel, kernel_mask, output_shape):\n+  \"\"\"Apply N-D convolution with un-shared weights using a single matmul call.\n+\n+  This method outputs `inputs . (kernel * kernel_mask)`\n+  (with `.` standing for matrix-multiply and `*` for element-wise multiply)\n+  and requires a precomputed `kernel_mask` to zero-out weights in `kernel` and\n+  hence perform the same operation as a convolution with un-shared\n+  (the remaining entries in `kernel`) weights. It also does the necessary\n+  reshapes to make `inputs` and `kernel` 2-D and `output` (N+2)-D.\n+\n+  Args:\n+      inputs: (N+2)-D tensor with shape `(batch_size, channels_in, d_in1, ...,\n+        d_inN)` or `(batch_size, d_in1, ..., d_inN, channels_in)`.\n+      kernel: the unshared weights for N-D convolution,\n+          an (N+2)-D tensor of shape: `(d_in1, ..., d_inN, channels_in, d_out2,\n+            ..., d_outN, channels_out)` or `(channels_in, d_in1, ..., d_inN,\n+            channels_out, d_out2, ..., d_outN)`, with the ordering of channels\n+            and spatial dimensions matching that of the input. Each entry is the\n+            weight between a particular input and output location, similarly to\n+            a fully-connected weight matrix.\n+      kernel_mask: a float 0/1 mask tensor of shape: `(d_in1, ..., d_inN, 1,\n+        d_out2, ..., d_outN, 1)` or `(1, d_in1, ..., d_inN, 1, d_out2, ...,\n+        d_outN)`, with the ordering of singleton and spatial dimensions matching\n+        that of the input. Mask represents the connectivity pattern of the layer\n+        and is\n+           precomputed elsewhere based on layer parameters: stride, padding, and\n+             the receptive field shape.\n+      output_shape: a tuple of (N+2) elements representing the output shape:\n+        `(batch_size, channels_out, d_out1, ..., d_outN)` or `(batch_size,\n+        d_out1, ..., d_outN, channels_out)`, with the ordering of channels and\n+        spatial dimensions matching that of the input.\n+\n+  Returns:\n+      Output (N+2)-D tensor with shape `output_shape`.\n+  \"\"\"\n+  inputs_flat = backend.reshape(inputs, (backend.shape(inputs)[0], -1))\n+\n+  kernel = kernel_mask * kernel\n+  kernel = make_2d(kernel, split_dim=backend.ndim(kernel) // 2)\n+\n+  output_flat = tf.matmul(inputs_flat, kernel, b_is_sparse=True)\n+  output = backend.reshape(output_flat, [\n+      backend.shape(output_flat)[0],\n+  ] + output_shape.as_list()[1:])\n+  return output\n+\n+\n+def local_conv_sparse_matmul(inputs, kernel, kernel_idxs, kernel_shape,\n+                             output_shape):\n+  \"\"\"Apply N-D convolution with un-shared weights using a single sparse matmul.\n+\n+  This method outputs `inputs . tf.sparse.SparseTensor(indices=kernel_idxs,\n+  values=kernel, dense_shape=kernel_shape)`, with `.` standing for\n+  matrix-multiply. It also reshapes `inputs` to 2-D and `output` to (N+2)-D.\n+\n+  Args:\n+      inputs: (N+2)-D tensor with shape `(batch_size, channels_in, d_in1, ...,\n+        d_inN)` or `(batch_size, d_in1, ..., d_inN, channels_in)`.\n+      kernel: a 1-D tensor with shape `(len(kernel_idxs),)` containing all the\n+        weights of the layer.\n+      kernel_idxs:  a list of integer tuples representing indices in a sparse\n+        matrix performing the un-shared convolution as a matrix-multiply.\n+      kernel_shape: a tuple `(input_size, output_size)`, where `input_size =\n+        channels_in * d_in1 * ... * d_inN` and `output_size = channels_out *\n+        d_out1 * ... * d_outN`.\n+      output_shape: a tuple of (N+2) elements representing the output shape:\n+        `(batch_size, channels_out, d_out1, ..., d_outN)` or `(batch_size,\n+        d_out1, ..., d_outN, channels_out)`, with the ordering of channels and\n+        spatial dimensions matching that of the input.\n+\n+  Returns:\n+      Output (N+2)-D dense tensor with shape `output_shape`.\n+  \"\"\"\n+  inputs_flat = backend.reshape(inputs, (backend.shape(inputs)[0], -1))\n+  output_flat = tf.sparse.sparse_dense_matmul(\n+      sp_a=tf.SparseTensor(kernel_idxs, kernel, kernel_shape),\n+      b=inputs_flat,\n+      adjoint_b=True)\n+  output_flat_transpose = backend.transpose(output_flat)\n+\n+  output_reshaped = backend.reshape(output_flat_transpose, [\n+      backend.shape(output_flat_transpose)[0],\n+  ] + output_shape.as_list()[1:])\n+  return output_reshaped\n+\n+\n+def make_2d(tensor, split_dim):\n+  \"\"\"Reshapes an N-dimensional tensor into a 2D tensor.\n+\n+  Dimensions before (excluding) and after (including) `split_dim` are grouped\n+  together.\n+\n+  Args:\n+    tensor: a tensor of shape `(d0, ..., d(N-1))`.\n+    split_dim: an integer from 1 to N-1, index of the dimension to group\n+      dimensions before (excluding) and after (including).\n+\n+  Returns:\n+    Tensor of shape\n+    `(d0 * ... * d(split_dim-1), d(split_dim) * ... * d(N-1))`.\n+  \"\"\"\n+  shape = tf.shape(tensor)\n+  in_dims = shape[:split_dim]\n+  out_dims = shape[split_dim:]\n+\n+  in_size = tf.reduce_prod(in_dims)\n+  out_size = tf.reduce_prod(out_dims)\n+\n+  return tf.reshape(tensor, (in_size, out_size))\n\n@@ -29,7 +29,7 @@ from keras.layers import core\n from keras.layers import cudnn_recurrent\n from keras.layers import einsum_dense\n from keras.layers import embeddings\n-from keras.layers import local\n+from keras.layers import locally_connected\n from keras.layers import merging\n from keras.layers import noise\n from keras.layers import pooling\n@@ -59,10 +59,10 @@ from tensorflow.python.util.tf_export import keras_export\n \n ALL_MODULES = (base_layer, input_layer, advanced_activations, attention,\n                convolutional, convolutional_recurrent, core, cudnn_recurrent,\n-               embeddings, einsum_dense, local, merging, batch_normalization_v1,\n-               layer_normalization, unit_normalization, pooling,\n-               image_preprocessing, recurrent, regularization, reshaping,\n-               wrappers, hashing, hashed_crossing, category_encoding,\n+               embeddings, einsum_dense, locally_connected, merging,\n+               batch_normalization_v1, layer_normalization, unit_normalization,\n+               pooling, image_preprocessing, recurrent, regularization,\n+               reshaping, wrappers, hashing, hashed_crossing, category_encoding,\n                discretization, integer_lookup, preprocessing_normalization,\n                string_lookup, text_vectorization)\n ALL_V2_MODULES = (rnn_cell_wrapper_v2, batch_normalization, layer_normalization,\n\n@@ -28,7 +28,7 @@ from keras.layers import convolutional\n from keras.layers import convolutional_recurrent\n from keras.layers import core\n from keras.layers import embeddings\n-from keras.layers import local\n+from keras.layers import locally_connected\n from keras.layers import merging\n from keras.layers import pooling\n from keras.layers import recurrent\n@@ -118,8 +118,9 @@ class LayerCorrectnessTest(keras_parameterized.TestCase):\n                                                           (2, 3, 3)]),\n       ('Embedding', lambda: embeddings.Embedding(4, 4),\n        (2, 4), 2e-3, 2e-3, np.random.randint(4, size=(2, 4))),\n-      ('LocallyConnected1D', lambda: local.LocallyConnected1D(2, 2), (2, 2, 1)),\n-      ('LocallyConnected2D', lambda: local.LocallyConnected2D(2, 2),\n+      ('LocallyConnected1D', lambda: locally_connected.LocallyConnected1D(2, 2),\n+       (2, 2, 1)),\n+      ('LocallyConnected2D', lambda: locally_connected.LocallyConnected2D(2, 2),\n        (2, 2, 2, 1)),\n       ('Add', merging.Add, [(2, 2), (2, 2)]),\n       ('Subtract', merging.Subtract, [(2, 2), (2, 2)]),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
