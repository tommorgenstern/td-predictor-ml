{"custom_id": "requests#4a41c591f88c3be7bb1319c8e6b8eba631fea8da", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 14 | Churn Cumulative: 5503 | Contributors (this commit): 101 | Commits (past 90d): 24 | Contributors (cumulative): 101 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1785,6 +1785,20 @@ class TestTestServer(unittest.TestCase):\n             new_sock = socket.socket()\n             new_sock.connect((host, port))\n \n+    def test_text_response(self):\n+        server = Server.text_response_server(\n+            \"HTTP/1.1 200 OK\\r\\n\" + \n+            \"Content-Length: 6\\r\\n\" +\n+            \"\\r\\nroflol\"\n+        )\n+\n+        with server as (host, port):\n+            r = requests.get('http://{}:{}'.format(host, port))\n+\n+            assert r.status_code == 200\n+            assert r.text == 'roflol'\n+            assert r.headers['Content-Length'] == '6'\n+            \n     def test_basic_response(self):\n         with Server.basic_response_server() as (host, port):\n             r = requests.get('http://{}:{}'.format(host, port))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#578b03255594d446b4fc8c6e00ec67dd3c8b440f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 17 | Churn Cumulative: 5520 | Contributors (this commit): 101 | Commits (past 90d): 25 | Contributors (cumulative): 101 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1817,5 +1817,22 @@ class TestTestServer(unittest.TestCase):\n             sock.send(b'still alive')\n             block_server.set() # release server block\n \n+    def test_multiple_requests(self):\n+        requests_to_handle = 5\n+        \n+        server = Server.basic_response_server(requests_to_handle=requests_to_handle)\n+\n+        with server as (host, port):\n+            server_url = 'http://{}:{}'.format(host, port)\n+            for _ in range(requests_to_handle):\n+                r = requests.get(server_url)\n+                assert r.status_code == 200\n+\n+            # the (n+1)th request fails\n+            with pytest.raises(requests.exceptions.ConnectionError):\n+                r = requests.get(server_url)\n+\n+\n+\n if __name__ == '__main__':\n     unittest.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#3eeea3771b274e1089317faa302730e74203b37c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 48 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 11 | Methods Changed: 9 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 53 | Churn Cumulative: 5675 | Contributors (this commit): 101 | Commits (past 90d): 35 | Contributors (cumulative): 102 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1779,6 +1779,7 @@ class TestTestServer(unittest.TestCase):\n         with Server.basic_response_server() as (host, port):\n             sock = socket.socket()\n             sock.connect((host, port))\n+\n             sock.close()\n \n         with pytest.raises(socket.error):\n@@ -1832,6 +1833,25 @@ class TestTestServer(unittest.TestCase):\n             with pytest.raises(requests.exceptions.ConnectionError):\n                 r = requests.get(server_url)\n \n+    def test_request_recovery(self):\n+        server = Server.basic_response_server(requests_to_handle=2)\n+        first_request = \"put your hands up in the air\"\n+        second_request = \"put your hand down in the floor\"\n+\n+        with server as address:\n+            sock1 = socket.socket()\n+            sock2 = socket.socket()\n+            \n+            sock1.connect(address)\n+            sock1.send(first_request.encode())\n+            sock1.close()\n+\n+            sock2.connect(address)\n+            sock2.send(second_request.encode())\n+            sock2.close()\n+\n+        assert server.handler_results[0] == first_request\n+        assert server.handler_results[1] == second_request\n \n \n if __name__ == '__main__':\n\n@@ -2,18 +2,35 @@\n \n import threading \n import socket\n+import select\n \n-def consume_socket(sock, chunks=65536):\n-    while not sock.recv(chunks).endswith(b'\\r\\n\\r\\n'):\n-            pass\n \n+def consume_socket_content(sock, chunks=65536, timeout=0.5):\n+    content = \"\"\n+    more_to_read = select.select([sock], [], [], timeout)[0]\n+\n+    while more_to_read:\n+        new_content = sock.recv(chunks).decode(\"utf-8\")\n+\n+        if len(new_content) == 0:\n+            more_to_read = False # empty recv means the socket disconnected\n+\n+        else:\n+            content += new_content \n+            # stop reading if no new data is received for a while \n+            more_to_read = select.select([sock], [], [], timeout)[0] \n+\n+    return content\n \n class Server(threading.Thread):\n     \"\"\" Dummy server using for unit testing \"\"\"\n \n     def __init__(self, handler, host='localhost', port=0, requests_to_handle=1, wait_to_close_event=None):\n         threading.Thread.__init__(self)\n+\n         self.handler = handler\n+        self.handler_results = []\n+\n         self.host = host\n         self.port = port\n         self.requests_to_handle = requests_to_handle\n@@ -23,10 +40,14 @@ class Server(threading.Thread):\n         self.stop_event = threading.Event()\n \n     @classmethod\n-    def text_response_server(cls, text, **kwargs):\n+    def text_response_server(cls, text, request_timeout=0.5, **kwargs):\n         def text_response_handler(sock):\n+            request_content = consume_socket_content(sock, timeout=request_timeout)\n             sock.send(text.encode())\n \n+            return request_content\n+\n+\n         server = Server(text_response_handler, **kwargs)\n \n         return server\n@@ -61,7 +82,9 @@ class Server(threading.Thread):\n     def _handle_requests_and_close_server(self, server_sock):\n         for _ in range(self.requests_to_handle):\n             sock = server_sock.accept()[0]\n-            self.handler(sock)\n+            handler_result = self.handler(sock)\n+\n+            self.handler_results.append(handler_result)\n         \n         if self.wait_to_close_event:\n             self.wait_to_close_event.wait()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#534ee814fcb9d7b563413ea77ce6838090ead25f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 25 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 25 | Churn Cumulative: 5565 | Contributors (this commit): 101 | Commits (past 90d): 27 | Contributors (cumulative): 101 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1853,6 +1853,31 @@ class TestTestServer(unittest.TestCase):\n         assert server.handler_results[0] == first_request\n         assert server.handler_results[1] == second_request\n \n+    def test_requests_after_timeout_are_not_received(self):\n+        server = Server.basic_response_server(request_timeout=1)\n+\n+        with server as address:\n+            sock = socket.socket()\n+            sock.connect(address)\n+            time.sleep(1.5)\n+            sock.send(b\"hehehe, not received\")\n+            sock.close()\n+\n+        assert server.handler_results[0] == \"\"\n+\n+\n+    def test_request_recovery_with_bigger_timeout(self):\n+        server = Server.basic_response_server(request_timeout=3)\n+        data = \"bananadine\"\n+\n+        with server as address:\n+            sock = socket.socket() \n+            sock.connect(address)\n+            time.sleep(1.5)\n+            sock.send(data.encode())\n+            sock.close()\n+            \n+        assert server.handler_results[0] == data\n \n if __name__ == '__main__':\n     unittest.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#3ad66349ea651d13459d7cd2db1613c1b91b40e1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 3068 | Contributors (this commit): 69 | Commits (past 90d): 5 | Contributors (cumulative): 69 | DMM Complexity: None\n\nDIFF:\n@@ -434,7 +434,7 @@ class Session(SessionRedirectMixin):\n         :param stream: (optional) whether to immediately download the response\n             content. Defaults to ``False``.\n         :param verify: (optional) if ``True``, the SSL cert will be verified.\n-            A CA_BUNDLE path can also be provided.\n+            A CA_BUNDLE path can also be provided. Defaults to ``True``.\n         :param cert: (optional) if String, path to ssl client cert file (.pem).\n             If Tuple, ('cert', 'key') pair.\n         \"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#9a20afd6b5140da4b9f187a3c0c6ea7010baeee9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 4240 | Contributors (this commit): 83 | Commits (past 90d): 8 | Contributors (cumulative): 105 | DMM Complexity: None\n\nDIFF:\n@@ -33,7 +33,7 @@ def request(method, url, **kwargs):\n     :param allow_redirects: (optional) Boolean. Set to True if POST/PUT/DELETE redirect following is allowed.\n     :type allow_redirects: bool\n     :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.\n-    :param verify: (optional) if ``True``, the SSL cert will be verified. A CA_BUNDLE path can also be provided.\n+    :param verify: (optional) whether the SSL cert will be verified. A CA_BUNDLE path can also be provided. Defaults to ``True``.\n     :param stream: (optional) if ``False``, the response content will be immediately downloaded.\n     :param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, ('cert', 'key') pair.\n     :return: :class:`Response <Response>` object\n\n@@ -400,8 +400,8 @@ class Session(SessionRedirectMixin):\n         allow_redirects=True,\n         proxies=None,\n         hooks=None,\n-        stream=None,\n-        verify=None,\n+        stream=False,\n+        verify=True,\n         cert=None,\n         json=None):\n         \"\"\"Constructs a :class:`Request <Request>`, prepares it and sends it.\n@@ -433,7 +433,7 @@ class Session(SessionRedirectMixin):\n             hostname to the URL of the proxy.\n         :param stream: (optional) whether to immediately download the response\n             content. Defaults to ``False``.\n-        :param verify: (optional) if ``True``, the SSL cert will be verified.\n+        :param verify: (optional) whether the SSL cert will be verified.\n             A CA_BUNDLE path can also be provided. Defaults to ``True``.\n         :param cert: (optional) if String, path to ssl client cert file (.pem).\n             If Tuple, ('cert', 'key') pair.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#9aca57d4bf7fe7906dd7b6d9e7c4836b6f38735d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 3078 | Contributors (this commit): 69 | Commits (past 90d): 7 | Contributors (cumulative): 69 | DMM Complexity: None\n\nDIFF:\n@@ -400,8 +400,8 @@ class Session(SessionRedirectMixin):\n         allow_redirects=True,\n         proxies=None,\n         hooks=None,\n-        stream=False,\n-        verify=True,\n+        stream=None,\n+        verify=None,\n         cert=None,\n         json=None):\n         \"\"\"Constructs a :class:`Request <Request>`, prepares it and sends it.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#3c0f0b9ab510d7ac6b556088d29fcc050c995357", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 208 | Lines Deleted: 75 | Files Changed: 22 | Hunks: 92 | Methods Changed: 29 | Complexity Δ (Sum/Max): 7/4 | Churn Δ: 283 | Churn Cumulative: 11413 | Contributors (this commit): 21 | Commits (past 90d): 32 | Contributors (cumulative): 133 | DMM Complexity: 0.0\n\nDIFF:\n@@ -2,10 +2,8 @@\n urllib3 - Thread-safe connection pooling and re-using.\n \"\"\"\n \n-__author__ = 'Andrey Petrov (andrey.petrov@shazow.net)'\n-__license__ = 'MIT'\n-__version__ = '1.12'\n-\n+from __future__ import absolute_import\n+import warnings\n \n from .connectionpool import (\n     HTTPConnectionPool,\n@@ -32,8 +30,30 @@ except ImportError:\n         def emit(self, record):\n             pass\n \n+__author__ = 'Andrey Petrov (andrey.petrov@shazow.net)'\n+__license__ = 'MIT'\n+__version__ = '1.13'\n+\n+__all__ = (\n+    'HTTPConnectionPool',\n+    'HTTPSConnectionPool',\n+    'PoolManager',\n+    'ProxyManager',\n+    'HTTPResponse',\n+    'Retry',\n+    'Timeout',\n+    'add_stderr_logger',\n+    'connection_from_url',\n+    'disable_warnings',\n+    'encode_multipart_formdata',\n+    'get_host',\n+    'make_headers',\n+    'proxy_from_url',\n+)\n+\n logging.getLogger(__name__).addHandler(NullHandler())\n \n+\n def add_stderr_logger(level=logging.DEBUG):\n     \"\"\"\n     Helper for quickly adding a StreamHandler to the logger. Useful for\n@@ -55,7 +75,6 @@ def add_stderr_logger(level=logging.DEBUG):\n del NullHandler\n \n \n-import warnings\n # SecurityWarning's always go off by default.\n warnings.simplefilter('always', exceptions.SecurityWarning, append=True)\n # SubjectAltNameWarning's should go off once per host\n@@ -63,6 +82,9 @@ warnings.simplefilter('default', exceptions.SubjectAltNameWarning)\n # InsecurePlatformWarning's don't vary between requests, so we keep it default.\n warnings.simplefilter('default', exceptions.InsecurePlatformWarning,\n                       append=True)\n+# SNIMissingWarnings should go off only once.\n+warnings.simplefilter('default', exceptions.SNIMissingWarning)\n+\n \n def disable_warnings(category=exceptions.HTTPWarning):\n     \"\"\"\n\n@@ -1,3 +1,4 @@\n+from __future__ import absolute_import\n from collections import Mapping, MutableMapping\n try:\n     from threading import RLock\n@@ -234,7 +235,7 @@ class HTTPHeaderDict(MutableMapping):\n         \"\"\"\n         if len(args) > 1:\n             raise TypeError(\"extend() takes at most 1 positional \"\n-                            \"arguments ({} given)\".format(len(args)))\n+                            \"arguments ({0} given)\".format(len(args)))\n         other = args[0] if len(args) >= 1 else ()\n \n         if isinstance(other, HTTPHeaderDict):\n\n@@ -1,4 +1,6 @@\n+from __future__ import absolute_import\n import datetime\n+import os\n import sys\n import socket\n from socket import error as SocketError, timeout as SocketTimeout\n@@ -6,18 +8,13 @@ import warnings\n from .packages import six\n \n try:  # Python 3\n-    from http.client import HTTPConnection as _HTTPConnection, HTTPException\n+    from http.client import HTTPConnection as _HTTPConnection\n+    from http.client import HTTPException  # noqa: unused in this module\n except ImportError:\n-    from httplib import HTTPConnection as _HTTPConnection, HTTPException\n-\n-\n-class DummyConnection(object):\n-    \"Used to detect a failed ConnectionCls import.\"\n-    pass\n-\n+    from httplib import HTTPConnection as _HTTPConnection\n+    from httplib import HTTPException  # noqa: unused in this module\n \n try:  # Compiled with SSL?\n-    HTTPSConnection = DummyConnection\n     import ssl\n     BaseSSLError = ssl.SSLError\n except (ImportError, AttributeError):  # Platform-specific: No SSL.\n@@ -61,6 +58,11 @@ port_by_scheme = {\n RECENT_DATE = datetime.date(2014, 1, 1)\n \n \n+class DummyConnection(object):\n+    \"\"\"Used to detect a failed ConnectionCls import.\"\"\"\n+    pass\n+\n+\n class HTTPConnection(_HTTPConnection, object):\n     \"\"\"\n     Based on httplib.HTTPConnection but provides an extra constructor\n@@ -205,10 +207,10 @@ class VerifiedHTTPSConnection(HTTPSConnection):\n         self.key_file = key_file\n         self.cert_file = cert_file\n         self.cert_reqs = cert_reqs\n-        self.ca_certs = ca_certs\n-        self.ca_cert_dir = ca_cert_dir\n         self.assert_hostname = assert_hostname\n         self.assert_fingerprint = assert_fingerprint\n+        self.ca_certs = ca_certs and os.path.expanduser(ca_certs)\n+        self.ca_cert_dir = ca_cert_dir and os.path.expanduser(ca_cert_dir)\n \n     def connect(self):\n         # Add certificate verification\n@@ -265,8 +267,8 @@ class VerifiedHTTPSConnection(HTTPSConnection):\n                 )\n             match_hostname(cert, self.assert_hostname or hostname)\n \n-        self.is_verified = (resolved_cert_reqs == ssl.CERT_REQUIRED\n-                            or self.assert_fingerprint is not None)\n+        self.is_verified = (resolved_cert_reqs == ssl.CERT_REQUIRED or\n+                            self.assert_fingerprint is not None)\n \n \n if ssl:\n\n@@ -1,3 +1,4 @@\n+from __future__ import absolute_import\n import errno\n import logging\n import sys\n@@ -10,7 +11,8 @@ try:  # Python 3\n     from queue import LifoQueue, Empty, Full\n except ImportError:\n     from Queue import LifoQueue, Empty, Full\n-    import Queue as _  # Platform-specific: Windows\n+    # Queue is imported for side effects on MS Windows\n+    import Queue as _unused_module_Queue  # noqa: unused\n \n \n from .exceptions import (\n@@ -22,7 +24,6 @@ from .exceptions import (\n     LocationValueError,\n     MaxRetryError,\n     ProxyError,\n-    ConnectTimeoutError,\n     ReadTimeoutError,\n     SSLError,\n     TimeoutError,\n@@ -35,7 +36,7 @@ from .connection import (\n     port_by_scheme,\n     DummyConnection,\n     HTTPConnection, HTTPSConnection, VerifiedHTTPSConnection,\n-    HTTPException, BaseSSLError, ConnectionError\n+    HTTPException, BaseSSLError,\n )\n from .request import RequestMethods\n from .response import HTTPResponse\n@@ -54,7 +55,7 @@ log = logging.getLogger(__name__)\n _Default = object()\n \n \n-## Pool objects\n+# Pool objects\n class ConnectionPool(object):\n     \"\"\"\n     Base class for all connection pools, such as\n@@ -68,8 +69,7 @@ class ConnectionPool(object):\n         if not host:\n             raise LocationValueError(\"No host specified.\")\n \n-        # httplib doesn't like it when we include brackets in ipv6 addresses\n-        self.host = host.strip('[]')\n+        self.host = host\n         self.port = port\n \n     def __str__(self):\n@@ -645,7 +645,8 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n                 return response\n \n             log.info(\"Redirecting %s -> %s\" % (url, redirect_location))\n-            return self.urlopen(method, redirect_location, body, headers,\n+            return self.urlopen(\n+                method, redirect_location, body, headers,\n                 retries=retries, redirect=redirect,\n                 assert_same_host=assert_same_host,\n                 timeout=timeout, pool_timeout=pool_timeout,\n@@ -656,7 +657,8 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n             retries = retries.increment(method, url, response=response, _pool=self)\n             retries.sleep()\n             log.info(\"Forced retry: %s\" % url)\n-            return self.urlopen(method, url, body, headers,\n+            return self.urlopen(\n+                method, url, body, headers,\n                 retries=retries, redirect=redirect,\n                 assert_same_host=assert_same_host,\n                 timeout=timeout, pool_timeout=pool_timeout,\n\n@@ -1,3 +1,4 @@\n+from __future__ import absolute_import\n import logging\n import os\n import warnings\n@@ -60,7 +61,7 @@ class AppEngineManager(RequestMethods):\n             raise AppEnginePlatformError(\n                 \"URLFetch is not available in this environment.\")\n \n-        if is_prod_appengine_v2():\n+        if is_prod_appengine_mvms():\n             raise AppEnginePlatformError(\n                 \"Use normal urllib3.PoolManager instead of AppEngineManager\"\n                 \"on Managed VMs, as using URLFetch is not necessary in \"\n@@ -108,14 +109,14 @@ class AppEngineManager(RequestMethods):\n             raise TimeoutError(self, e)\n \n         except urlfetch.InvalidURLError as e:\n-            if 'too large' in e.message:\n+            if 'too large' in str(e):\n                 raise AppEnginePlatformError(\n                     \"URLFetch request too large, URLFetch only \"\n                     \"supports requests up to 10mb in size.\", e)\n             raise ProtocolError(e)\n \n         except urlfetch.DownloadError as e:\n-            if 'Too many redirects' in e.message:\n+            if 'Too many redirects' in str(e):\n                 raise MaxRetryError(self, url, reason=e)\n             raise ProtocolError(e)\n \n@@ -155,7 +156,7 @@ class AppEngineManager(RequestMethods):\n \n     def _urlfetch_response_to_http_response(self, urlfetch_resp, **response_kw):\n \n-        if is_prod_appengine_v1():\n+        if is_prod_appengine():\n             # Production GAE handles deflate encoding automatically, but does\n             # not remove the encoding header.\n             content_encoding = urlfetch_resp.headers.get('content-encoding')\n@@ -176,7 +177,7 @@ class AppEngineManager(RequestMethods):\n         if timeout is Timeout.DEFAULT_TIMEOUT:\n             return 5  # 5s is the default timeout for URLFetch.\n         if isinstance(timeout, Timeout):\n-            if not timeout.read is timeout.connect:\n+            if timeout.read is not timeout.connect:\n                 warnings.warn(\n                     \"URLFetch does not support granular timeout settings, \"\n                     \"reverting to total timeout.\", AppEnginePlatformWarning)\n@@ -199,12 +200,12 @@ class AppEngineManager(RequestMethods):\n \n def is_appengine():\n     return (is_local_appengine() or\n-            is_prod_appengine_v1() or\n-            is_prod_appengine_v2())\n+            is_prod_appengine() or\n+            is_prod_appengine_mvms())\n \n \n def is_appengine_sandbox():\n-    return is_appengine() and not is_prod_appengine_v2()\n+    return is_appengine() and not is_prod_appengine_mvms()\n \n \n def is_local_appengine():\n@@ -212,11 +213,11 @@ def is_local_appengine():\n             'Development/' in os.environ['SERVER_SOFTWARE'])\n \n \n-def is_prod_appengine_v1():\n+def is_prod_appengine():\n     return ('APPENGINE_RUNTIME' in os.environ and\n             'Google App Engine/' in os.environ['SERVER_SOFTWARE'] and\n-            not is_prod_appengine_v2())\n+            not is_prod_appengine_mvms())\n \n \n-def is_prod_appengine_v2():\n+def is_prod_appengine_mvms():\n     return os.environ.get('GAE_VM', False) == 'true'\n\n@@ -3,6 +3,7 @@ NTLM authenticating pool, contributed by erikcederstran\n \n Issue #10, see: http://code.google.com/p/urllib3/issues/detail?id=10\n \"\"\"\n+from __future__ import absolute_import\n \n try:\n     from http.client import HTTPSConnection\n\n@@ -43,6 +43,7 @@ Module Variables\n .. _crime attack: https://en.wikipedia.org/wiki/CRIME_(security_exploit)\n \n '''\n+from __future__ import absolute_import\n \n try:\n     from ndg.httpsclient.ssl_peer_verification import SUBJ_ALT_NAME_SUPPORT\n@@ -53,7 +54,7 @@ except SyntaxError as e:\n import OpenSSL.SSL\n from pyasn1.codec.der import decoder as der_decoder\n from pyasn1.type import univ, constraint\n-from socket import _fileobject, timeout\n+from socket import _fileobject, timeout, error as SocketError\n import ssl\n import select\n \n@@ -71,6 +72,12 @@ _openssl_versions = {\n     ssl.PROTOCOL_TLSv1: OpenSSL.SSL.TLSv1_METHOD,\n }\n \n+if hasattr(ssl, 'PROTOCOL_TLSv1_1') and hasattr(OpenSSL.SSL, 'TLSv1_1_METHOD'):\n+    _openssl_versions[ssl.PROTOCOL_TLSv1_1] = OpenSSL.SSL.TLSv1_1_METHOD\n+\n+if hasattr(ssl, 'PROTOCOL_TLSv1_2') and hasattr(OpenSSL.SSL, 'TLSv1_2_METHOD'):\n+    _openssl_versions[ssl.PROTOCOL_TLSv1_2] = OpenSSL.SSL.TLSv1_2_METHOD\n+\n try:\n     _openssl_versions.update({ssl.PROTOCOL_SSLv3: OpenSSL.SSL.SSLv3_METHOD})\n except AttributeError:\n@@ -79,8 +86,8 @@ except AttributeError:\n _openssl_verify = {\n     ssl.CERT_NONE: OpenSSL.SSL.VERIFY_NONE,\n     ssl.CERT_OPTIONAL: OpenSSL.SSL.VERIFY_PEER,\n-    ssl.CERT_REQUIRED: OpenSSL.SSL.VERIFY_PEER\n-                       + OpenSSL.SSL.VERIFY_FAIL_IF_NO_PEER_CERT,\n+    ssl.CERT_REQUIRED:\n+        OpenSSL.SSL.VERIFY_PEER + OpenSSL.SSL.VERIFY_FAIL_IF_NO_PEER_CERT,\n }\n \n DEFAULT_SSL_CIPHER_LIST = util.ssl_.DEFAULT_CIPHERS\n@@ -88,12 +95,6 @@ DEFAULT_SSL_CIPHER_LIST = util.ssl_.DEFAULT_CIPHERS\n # OpenSSL will only write 16K at a time\n SSL_WRITE_BLOCKSIZE = 16384\n \n-try:\n-    _ = memoryview\n-    has_memoryview = True\n-except NameError:\n-    has_memoryview = False\n-\n orig_util_HAS_SNI = util.HAS_SNI\n orig_connection_ssl_wrap_socket = connection.ssl_wrap_socket\n \n@@ -112,7 +113,7 @@ def extract_from_urllib3():\n     util.HAS_SNI = orig_util_HAS_SNI\n \n \n-### Note: This is a slightly bug-fixed version of same from ndg-httpsclient.\n+# Note: This is a slightly bug-fixed version of same from ndg-httpsclient.\n class SubjectAltName(BaseSubjectAltName):\n     '''ASN.1 implementation for subjectAltNames support'''\n \n@@ -123,7 +124,7 @@ class SubjectAltName(BaseSubjectAltName):\n         constraint.ValueSizeConstraint(1, 1024)\n \n \n-### Note: This is a slightly bug-fixed version of same from ndg-httpsclient.\n+# Note: This is a slightly bug-fixed version of same from ndg-httpsclient.\n def get_subj_alt_name(peer_cert):\n     # Search through extensions\n     dns_name = []\n@@ -181,7 +182,7 @@ class WrappedSocket(object):\n             if self.suppress_ragged_eofs and e.args == (-1, 'Unexpected EOF'):\n                 return b''\n             else:\n-                raise\n+                raise SocketError(e)\n         except OpenSSL.SSL.ZeroReturnError as e:\n             if self.connection.get_shutdown() == OpenSSL.SSL.RECEIVED_SHUTDOWN:\n                 return b''\n@@ -212,9 +213,6 @@ class WrappedSocket(object):\n                 continue\n \n     def sendall(self, data):\n-        if has_memoryview and not isinstance(data, memoryview):\n-            data = memoryview(data)\n-\n         total_sent = 0\n         while total_sent < len(data):\n             sent = self._send_until_done(data[total_sent:total_sent + SSL_WRITE_BLOCKSIZE])\n@@ -226,7 +224,10 @@ class WrappedSocket(object):\n \n     def close(self):\n         if self._makefile_refs < 1:\n+            try:\n                 return self.connection.close()\n+            except OpenSSL.SSL.Error:\n+                return\n         else:\n             self._makefile_refs -= 1\n \n\n@@ -1,16 +1,17 @@\n+from __future__ import absolute_import\n+# Base Exceptions\n \n-## Base Exceptions\n \n class HTTPError(Exception):\n     \"Base exception used by this module.\"\n     pass\n \n+\n class HTTPWarning(Warning):\n     \"Base warning used by this module.\"\n     pass\n \n \n-\n class PoolError(HTTPError):\n     \"Base exception for errors caused within a pool.\"\n     def __init__(self, pool, message):\n@@ -57,7 +58,7 @@ class ProtocolError(HTTPError):\n ConnectionError = ProtocolError\n \n \n-## Leaf Exceptions\n+# Leaf Exceptions\n \n class MaxRetryError(RequestError):\n     \"\"\"Raised when the maximum number of retries is exceeded.\n@@ -112,10 +113,12 @@ class ConnectTimeoutError(TimeoutError):\n     \"Raised when a socket timeout occurs while connecting to a server\"\n     pass\n \n+\n class NewConnectionError(ConnectTimeoutError, PoolError):\n     \"Raised when we fail to establish a new connection. Usually ECONNREFUSED.\"\n     pass\n \n+\n class EmptyPoolError(PoolError):\n     \"Raised when a pool runs out of connections and no more are allowed.\"\n     pass\n@@ -172,6 +175,11 @@ class InsecurePlatformWarning(SecurityWarning):\n     pass\n \n \n+class SNIMissingWarning(HTTPWarning):\n+    \"Warned when making a HTTPS request without SNI available.\"\n+    pass\n+\n+\n class ResponseNotChunked(ProtocolError, ValueError):\n     \"Response needs to be chunked in order to read it as chunks.\"\n     pass\n\n@@ -1,3 +1,4 @@\n+from __future__ import absolute_import\n import email.utils\n import mimetypes\n \n\n@@ -1,3 +1,4 @@\n+from __future__ import absolute_import\n import codecs\n \n from uuid import uuid4\n\n@@ -2,3 +2,4 @@ from __future__ import absolute_import\n \n from . import ssl_match_hostname\n \n+__all__ = ('ssl_match_hostname', )\n\n@@ -1,3 +1,4 @@\n+from __future__ import absolute_import\n import logging\n \n try:  # Python 3\n@@ -25,7 +26,7 @@ pool_classes_by_scheme = {\n log = logging.getLogger(__name__)\n \n SSL_KEYWORDS = ('key_file', 'cert_file', 'cert_reqs', 'ca_certs',\n-                'ssl_version')\n+                'ssl_version', 'ca_cert_dir')\n \n \n class PoolManager(RequestMethods):\n\n@@ -1,3 +1,4 @@\n+from __future__ import absolute_import\n try:\n     from urllib.parse import urlencode\n except ImportError:\n@@ -133,7 +134,8 @@ class RequestMethods(object):\n \n         if fields:\n             if 'body' in urlopen_kw:\n-                raise TypeError('request got values for both \\'fields\\' and \\'body\\', can only specify one.')\n+                raise TypeError(\n+                    \"request got values for both 'fields' and 'body', can only specify one.\")\n \n             if encode_multipart:\n                 body, content_type = encode_multipart_formdata(fields, boundary=multipart_boundary)\n\n@@ -1,7 +1,9 @@\n+from __future__ import absolute_import\n from contextlib import contextmanager\n import zlib\n import io\n from socket import timeout as SocketTimeout\n+from socket import error as SocketError\n \n from ._collections import HTTPHeaderDict\n from .exceptions import (\n@@ -130,8 +132,8 @@ class HTTPResponse(io.IOBase):\n         if \"chunked\" in encodings:\n             self.chunked = True\n \n-        # We certainly don't want to preload content when the response is chunked.\n-        if not self.chunked and preload_content and not self._body:\n+        # If requested, preload the body.\n+        if preload_content and not self._body:\n             self._body = self.read(decode_content=decode_content)\n \n     def get_redirect_location(self):\n@@ -194,12 +196,22 @@ class HTTPResponse(io.IOBase):\n                 \"Received response with content-encoding: %s, but \"\n                 \"failed to decode it.\" % content_encoding, e)\n \n-        if flush_decoder and decode_content and self._decoder:\n-            buf = self._decoder.decompress(binary_type())\n-            data += buf + self._decoder.flush()\n+        if flush_decoder and decode_content:\n+            data += self._flush_decoder()\n \n         return data\n \n+    def _flush_decoder(self):\n+        \"\"\"\n+        Flushes the decoder. Should only be called if the decoder is actually\n+        being used.\n+        \"\"\"\n+        if self._decoder:\n+            buf = self._decoder.decompress(b'')\n+            return buf + self._decoder.flush()\n+\n+        return b''\n+\n     @contextmanager\n     def _error_catcher(self):\n         \"\"\"\n@@ -227,15 +239,22 @@ class HTTPResponse(io.IOBase):\n \n                 raise ReadTimeoutError(self._pool, None, 'Read timed out.')\n \n-            except HTTPException as e:\n+            except (HTTPException, SocketError) as e:\n                 # This includes IncompleteRead.\n                 raise ProtocolError('Connection broken: %r' % e, e)\n+\n         except Exception:\n             # The response may not be closed but we're not going to use it anymore\n             # so close it now to ensure that the connection is released back to the pool.\n             if self._original_response and not self._original_response.isclosed():\n                 self._original_response.close()\n \n+            # Closing the response may not actually be sufficient to close\n+            # everything, so if we have a hold of the connection close that\n+            # too.\n+            if self._connection is not None:\n+                self._connection.close()\n+\n             raise\n         finally:\n             if self._original_response and self._original_response.isclosed():\n@@ -301,7 +320,6 @@ class HTTPResponse(io.IOBase):\n \n         return data\n \n-\n     def stream(self, amt=2**16, decode_content=None):\n         \"\"\"\n         A generator wrapper for the read() method. A call will block until\n@@ -454,7 +472,8 @@ class HTTPResponse(io.IOBase):\n         self._init_decoder()\n         # FIXME: Rewrite this method and make it a class with a better structured logic.\n         if not self.chunked:\n-            raise ResponseNotChunked(\"Response is not chunked. \"\n+            raise ResponseNotChunked(\n+                \"Response is not chunked. \"\n                 \"Header 'transfer-encoding: chunked' is missing.\")\n \n         # Don't bother reading the body of a HEAD request.\n@@ -468,8 +487,18 @@ class HTTPResponse(io.IOBase):\n                 if self.chunk_left == 0:\n                     break\n                 chunk = self._handle_chunk(amt)\n-                yield self._decode(chunk, decode_content=decode_content,\n-                                   flush_decoder=True)\n+                decoded = self._decode(chunk, decode_content=decode_content,\n+                                       flush_decoder=False)\n+                if decoded:\n+                    yield decoded\n+\n+            if decode_content:\n+                # On CPython and PyPy, we should never need to flush the\n+                # decoder. However, on Jython we *might* need to, so\n+                # lets defensively do it anyway.\n+                decoded = self._flush_decoder()\n+                if decoded:  # Platform-specific: Jython.\n+                    yield decoded\n \n             # Chunk content ends with \\r\\n: discard it.\n             while True:\n\n@@ -1,3 +1,4 @@\n+from __future__ import absolute_import\n # For backwards compatibility, provide imports that used to be here.\n from .connection import is_connection_dropped\n from .request import make_headers\n@@ -22,3 +23,22 @@ from .url import (\n     split_first,\n     Url,\n )\n+\n+__all__ = (\n+    'HAS_SNI',\n+    'SSLContext',\n+    'Retry',\n+    'Timeout',\n+    'Url',\n+    'assert_fingerprint',\n+    'current_time',\n+    'is_connection_dropped',\n+    'is_fp_closed',\n+    'get_host',\n+    'parse_url',\n+    'make_headers',\n+    'resolve_cert_reqs',\n+    'resolve_ssl_version',\n+    'split_first',\n+    'ssl_wrap_socket',\n+)\n\n@@ -1,3 +1,4 @@\n+from __future__ import absolute_import\n import socket\n try:\n     from select import poll, POLLIN\n\n@@ -1,3 +1,4 @@\n+from __future__ import absolute_import\n from base64 import b64encode\n \n from ..packages.six import b\n\n@@ -1,3 +1,4 @@\n+from __future__ import absolute_import\n from ..packages.six.moves import http_client as httplib\n \n from ..exceptions import HeaderParsingError\n@@ -44,7 +45,7 @@ def assert_header_parsing(headers):\n     # This will fail silently if we pass in the wrong kind of parameter.\n     # To make debugging easier add an explicit check.\n     if not isinstance(headers, httplib.HTTPMessage):\n-        raise TypeError('expected httplib.Message, got {}.'.format(\n+        raise TypeError('expected httplib.Message, got {0}.'.format(\n             type(headers)))\n \n     defects = getattr(headers, 'defects', None)\n\n@@ -1,3 +1,4 @@\n+from __future__ import absolute_import\n import time\n import logging\n \n@@ -206,7 +207,8 @@ class Retry(object):\n \n         return min(retry_counts) < 0\n \n-    def increment(self, method=None, url=None, response=None, error=None, _pool=None, _stacktrace=None):\n+    def increment(self, method=None, url=None, response=None, error=None,\n+                  _pool=None, _stacktrace=None):\n         \"\"\" Return a new Retry object with incremented retry counters.\n \n         :param response: A response object, or None, if the server did not\n@@ -274,7 +276,6 @@ class Retry(object):\n \n         return new_retry\n \n-\n     def __repr__(self):\n         return ('{cls.__name__}(total={self.total}, connect={self.connect}, '\n                 'read={self.read}, redirect={self.redirect})').format(\n\n@@ -1,7 +1,12 @@\n+from __future__ import absolute_import\n+import errno\n+import warnings\n+import hmac\n+\n from binascii import hexlify, unhexlify\n from hashlib import md5, sha1, sha256\n \n-from ..exceptions import SSLError, InsecurePlatformWarning\n+from ..exceptions import SSLError, InsecurePlatformWarning, SNIMissingWarning\n \n \n SSLContext = None\n@@ -15,8 +20,23 @@ HASHFUNC_MAP = {\n     64: sha256,\n }\n \n-import errno\n-import warnings\n+\n+def _const_compare_digest_backport(a, b):\n+    \"\"\"\n+    Compare two digests of equal length in constant time.\n+\n+    The digests must be of type str/bytes.\n+    Returns True if the digests match, and False otherwise.\n+    \"\"\"\n+    result = abs(len(a) - len(b))\n+    for l, r in zip(bytearray(a), bytearray(b)):\n+        result |= l ^ r\n+    return result == 0\n+\n+\n+_const_compare_digest = getattr(hmac, 'compare_digest',\n+                                _const_compare_digest_backport)\n+\n \n try:  # Test for SSL features\n     import ssl\n@@ -134,7 +154,7 @@ def assert_fingerprint(cert, fingerprint):\n \n     cert_digest = hashfunc(cert).digest()\n \n-    if cert_digest != fingerprint_bytes:\n+    if not _const_compare_digest(cert_digest, fingerprint_bytes):\n         raise SSLError('Fingerprints did not match. Expected \"{0}\", got \"{1}\".'\n                        .format(fingerprint, hexlify(cert_digest)))\n \n@@ -283,4 +303,15 @@ def ssl_wrap_socket(sock, keyfile=None, certfile=None, cert_reqs=None,\n         context.load_cert_chain(certfile, keyfile)\n     if HAS_SNI:  # Platform-specific: OpenSSL with enabled SNI\n         return context.wrap_socket(sock, server_hostname=server_hostname)\n+\n+    warnings.warn(\n+        'An HTTPS request has been made, but the SNI (Subject Name '\n+        'Indication) extension to TLS is not available on this platform. '\n+        'This may cause the server to present an incorrect TLS '\n+        'certificate, which can cause validation failures. For more '\n+        'information, see '\n+        'https://urllib3.readthedocs.org/en/latest/security.html'\n+        '#snimissingwarning.',\n+        SNIMissingWarning\n+    )\n     return context.wrap_socket(sock)\n\n@@ -1,3 +1,4 @@\n+from __future__ import absolute_import\n # The default socket timeout, used by httplib to indicate that no timeout was\n # specified by the user\n from socket import _GLOBAL_DEFAULT_TIMEOUT\n@@ -9,6 +10,7 @@ from ..exceptions import TimeoutStateError\n # urllib3\n _Default = object()\n \n+\n def current_time():\n     \"\"\"\n     Retrieve the current time. This function is mocked out in unit testing.\n\n@@ -1,3 +1,4 @@\n+from __future__ import absolute_import\n from collections import namedtuple\n \n from ..exceptions import LocationParseError\n@@ -85,6 +86,7 @@ class Url(namedtuple('Url', url_attrs)):\n     def __str__(self):\n         return self.url\n \n+\n def split_first(s, delims):\n     \"\"\"\n     Given a string and an iterable of delimiters, split on the first found\n@@ -206,6 +208,7 @@ def parse_url(url):\n \n     return Url(scheme, auth, host, port, path, query, fragment)\n \n+\n def get_host(url):\n     \"\"\"\n     Deprecated. Use :func:`.parse_url` instead.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#5f7a3a74aab1625c2bb65f643197ee885e3da576", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 619 | Contributors (this commit): 13 | Commits (past 90d): 4 | Contributors (cumulative): 13 | DMM Complexity: None\n\nDIFF:\n@@ -42,8 +42,8 @@ is at <http://python-requests.org>.\n \"\"\"\n \n __title__ = 'requests'\n-__version__ = '2.8.1'\n-__build__ = 0x020801\n+__version__ = '2.9.0'\n+__build__ = 0x020900\n __author__ = 'Kenneth Reitz'\n __license__ = 'Apache 2.0'\n __copyright__ = 'Copyright 2015 Kenneth Reitz'\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#fc8fa1aa265bb14d59c68eb68a179bce17953967", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): -11/1 | Churn Δ: 10 | Churn Cumulative: 14994 | Contributors (this commit): 194 | Commits (past 90d): 38 | Contributors (cumulative): 255 | DMM Complexity: 0.6666666666666666\n\nDIFF:\n@@ -81,7 +81,7 @@ class RequestEncodingMixin(object):\n         \"\"\"\n \n         if isinstance(data, (str, bytes)):\n-            return to_native_string(data)\n+            return data\n         elif hasattr(data, 'read'):\n             return data\n         elif hasattr(data, '__iter__'):\n@@ -385,6 +385,9 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n             if isinstance(fragment, str):\n                 fragment = fragment.encode('utf-8')\n \n+        if isinstance(params, (str, bytes)):\n+            params = to_native_string(params)\n+\n         enc_params = self._encode_params(params)\n         if enc_params:\n             if query:\n\n@@ -157,6 +157,11 @@ class TestRequests(object):\n                                    params=b'test=foo').prepare()\n         assert request.url == 'http://example.com/?test=foo'\n \n+    def test_binary_put(self):\n+        request = requests.Request('PUT', 'http://example.com',\n+                                   data=u\"ööö\".encode(\"utf-8\")).prepare()\n+        assert isinstance(request.body, bytes)\n+\n     def test_mixed_case_scheme_acceptable(self, httpbin):\n         s = requests.Session()\n         s.proxies = getproxies()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#589f13ca9d81a3ba2bace8b889f84b8b7c5e4881", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 5 | Churn Cumulative: 2338 | Contributors (this commit): 57 | Commits (past 90d): 4 | Contributors (cumulative): 57 | DMM Complexity: 0.0\n\nDIFF:\n@@ -116,7 +116,10 @@ def get_netrc_auth(url, raise_errors=False):\n         ri = urlparse(url)\n \n         # Strip port numbers from netloc\n-        host = ri.netloc.split(':')[0]\n+        if isinstance(url, str):\n+            host = ri.netloc.split(u':')[0]\n+        else:\n+            host = ri.netloc.split(b':')[0]\n \n         try:\n             _netrc = netrc(netrc_path).authenticators(host)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#834a9601c3eb3291558ef8d1c16a92b376bf49e0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 13 | Churn Cumulative: 803 | Contributors (this commit): 9 | Commits (past 90d): 6 | Contributors (cumulative): 16 | DMM Complexity: 0.0\n\nDIFF:\n@@ -32,7 +32,7 @@ except ImportError:\n \n __author__ = 'Andrey Petrov (andrey.petrov@shazow.net)'\n __license__ = 'MIT'\n-__version__ = '1.13'\n+__version__ = '1.13.1'\n \n __all__ = (\n     'HTTPConnectionPool',\n\n@@ -265,7 +265,16 @@ class VerifiedHTTPSConnection(HTTPSConnection):\n                     'for details.)'.format(hostname)),\n                     SubjectAltNameWarning\n                 )\n-            match_hostname(cert, self.assert_hostname or hostname)\n+\n+            # In case the hostname is an IPv6 address, strip the square\n+            # brackets from it before using it to validate. This is because\n+            # a certificate with an IPv6 address in it won't have square\n+            # brackets around that address. Sadly, match_hostname won't do this\n+            # for us: it expects the plain host part without any extra work\n+            # that might have been done to make it palatable to httplib.\n+            asserted_hostname = self.assert_hostname or hostname\n+            asserted_hostname = asserted_hostname.strip('[]')\n+            match_hostname(cert, asserted_hostname)\n \n         self.is_verified = (resolved_cert_reqs == ssl.CERT_REQUIRED or\n                             self.assert_fingerprint is not None)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#6e0649d9f896ce2dde57911e7f56b1c968575d74", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 9 | Churn Cumulative: 2347 | Contributors (this commit): 57 | Commits (past 90d): 5 | Contributors (cumulative): 57 | DMM Complexity: None\n\nDIFF:\n@@ -115,11 +115,12 @@ def get_netrc_auth(url, raise_errors=False):\n \n         ri = urlparse(url)\n \n-        # Strip port numbers from netloc\n+        # Strip port numbers from netloc. This weird `if...encode`` dance is\n+        # used for Python 3.2, which doesn't support unicode literals.\n+        splitstr = b':'\n         if isinstance(url, str):\n-            host = ri.netloc.split(u':')[0]\n-        else:\n-            host = ri.netloc.split(b':')[0]\n+            splitstr = splitstr.decode('ascii')\n+        host = ri.netloc.split(splitstr)[0]\n \n         try:\n             _netrc = netrc(netrc_path).authenticators(host)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#1108058626450b863d154bb74d669754b480caa4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 623 | Contributors (this commit): 13 | Commits (past 90d): 5 | Contributors (cumulative): 13 | DMM Complexity: None\n\nDIFF:\n@@ -42,8 +42,8 @@ is at <http://python-requests.org>.\n \"\"\"\n \n __title__ = 'requests'\n-__version__ = '2.9.0'\n-__build__ = 0x020900\n+__version__ = '2.9.1'\n+__build__ = 0x020901\n __author__ = 'Kenneth Reitz'\n __license__ = 'Apache 2.0'\n __copyright__ = 'Copyright 2015 Kenneth Reitz'\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#cd84b3ff943f733c2e76bb047ab2d3a60cac5ba2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 228 | Lines Deleted: 37 | Files Changed: 10 | Hunks: 30 | Methods Changed: 21 | Complexity Δ (Sum/Max): 13/12 | Churn Δ: 265 | Churn Cumulative: 6312 | Contributors (this commit): 19 | Commits (past 90d): 25 | Contributors (cumulative): 63 | DMM Complexity: 0.44155844155844154\n\nDIFF:\n@@ -32,7 +32,7 @@ except ImportError:\n \n __author__ = 'Andrey Petrov (andrey.petrov@shazow.net)'\n __license__ = 'MIT'\n-__version__ = '1.13.1'\n+__version__ = '1.14'\n \n __all__ = (\n     'HTTPConnectionPool',\n@@ -68,7 +68,7 @@ def add_stderr_logger(level=logging.DEBUG):\n     handler.setFormatter(logging.Formatter('%(asctime)s %(levelname)s %(message)s'))\n     logger.addHandler(handler)\n     logger.setLevel(level)\n-    logger.debug('Added a stderr logging handler to logger: %s' % __name__)\n+    logger.debug('Added a stderr logging handler to logger: %s', __name__)\n     return handler\n \n # ... Clean up.\n\n@@ -203,8 +203,8 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n         Return a fresh :class:`HTTPConnection`.\n         \"\"\"\n         self.num_connections += 1\n-        log.info(\"Starting new HTTP connection (%d): %s\" %\n-                 (self.num_connections, self.host))\n+        log.info(\"Starting new HTTP connection (%d): %s\",\n+                 self.num_connections, self.host)\n \n         conn = self.ConnectionCls(host=self.host, port=self.port,\n                                   timeout=self.timeout.connect_timeout,\n@@ -239,7 +239,7 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n \n         # If this is a persistent connection, check if it got disconnected\n         if conn and is_connection_dropped(conn):\n-            log.info(\"Resetting dropped connection: %s\" % self.host)\n+            log.info(\"Resetting dropped connection: %s\", self.host)\n             conn.close()\n             if getattr(conn, 'auto_open', 1) == 0:\n                 # This is a proxied connection that has been mutated by\n@@ -272,7 +272,7 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n         except Full:\n             # This should never happen if self.block == True\n             log.warning(\n-                \"Connection pool is full, discarding connection: %s\" %\n+                \"Connection pool is full, discarding connection: %s\",\n                 self.host)\n \n         # Connection never got put back into the pool, close it.\n@@ -382,9 +382,8 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n \n         # AppEngine doesn't have a version attr.\n         http_version = getattr(conn, '_http_vsn_str', 'HTTP/?')\n-        log.debug(\"\\\"%s %s %s\\\" %s %s\" % (method, url, http_version,\n-                                          httplib_response.status,\n-                                          httplib_response.length))\n+        log.debug(\"\\\"%s %s %s\\\" %s %s\", method, url, http_version,\n+                  httplib_response.status, httplib_response.length)\n \n         try:\n             assert_header_parsing(httplib_response.msg)\n@@ -622,7 +621,7 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n         if not conn:\n             # Try again\n             log.warning(\"Retrying (%r) after connection \"\n-                        \"broken by '%r': %s\" % (retries, err, url))\n+                        \"broken by '%r': %s\", retries, err, url)\n             return self.urlopen(method, url, body, headers, retries,\n                                 redirect, assert_same_host,\n                                 timeout=timeout, pool_timeout=pool_timeout,\n@@ -644,7 +643,7 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n                     raise\n                 return response\n \n-            log.info(\"Redirecting %s -> %s\" % (url, redirect_location))\n+            log.info(\"Redirecting %s -> %s\", url, redirect_location)\n             return self.urlopen(\n                 method, redirect_location, body, headers,\n                 retries=retries, redirect=redirect,\n@@ -656,7 +655,7 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n         if retries.is_forced_retry(method, status_code=response.status):\n             retries = retries.increment(method, url, response=response, _pool=self)\n             retries.sleep()\n-            log.info(\"Forced retry: %s\" % url)\n+            log.info(\"Forced retry: %s\", url)\n             return self.urlopen(\n                 method, url, body, headers,\n                 retries=retries, redirect=redirect,\n@@ -754,8 +753,8 @@ class HTTPSConnectionPool(HTTPConnectionPool):\n         Return a fresh :class:`httplib.HTTPSConnection`.\n         \"\"\"\n         self.num_connections += 1\n-        log.info(\"Starting new HTTPS connection (%d): %s\"\n-                 % (self.num_connections, self.host))\n+        log.info(\"Starting new HTTPS connection (%d): %s\",\n+                 self.num_connections, self.host)\n \n         if not self.ConnectionCls or self.ConnectionCls is DummyConnection:\n             raise SSLError(\"Can't connect to HTTPS URL because the SSL \"\n\n@@ -144,7 +144,7 @@ class AppEngineManager(RequestMethods):\n         if retries.is_forced_retry(method, status_code=http_response.status):\n             retries = retries.increment(\n                 method, url, response=http_response, _pool=self)\n-            log.info(\"Forced retry: %s\" % url)\n+            log.info(\"Forced retry: %s\", url)\n             retries.sleep()\n             return self.urlopen(\n                 method, url,\n@@ -164,6 +164,14 @@ class AppEngineManager(RequestMethods):\n             if content_encoding == 'deflate':\n                 del urlfetch_resp.headers['content-encoding']\n \n+        transfer_encoding = urlfetch_resp.headers.get('transfer-encoding')\n+        # We have a full response's content,\n+        # so let's make sure we don't report ourselves as chunked data.\n+        if transfer_encoding == 'chunked':\n+            encodings = transfer_encoding.split(\",\")\n+            encodings.remove('chunked')\n+            urlfetch_resp.headers['transfer-encoding'] = ','.join(encodings)\n+\n         return HTTPResponse(\n             # In order for decoding to work, we must present the content as\n             # a file-like object.\n@@ -177,7 +185,7 @@ class AppEngineManager(RequestMethods):\n         if timeout is Timeout.DEFAULT_TIMEOUT:\n             return 5  # 5s is the default timeout for URLFetch.\n         if isinstance(timeout, Timeout):\n-            if timeout.read is not timeout.connect:\n+            if timeout._read is not timeout._connect:\n                 warnings.warn(\n                     \"URLFetch does not support granular timeout settings, \"\n                     \"reverting to total timeout.\", AppEnginePlatformWarning)\n\n@@ -43,8 +43,8 @@ class NTLMConnectionPool(HTTPSConnectionPool):\n         # Performs the NTLM handshake that secures the connection. The socket\n         # must be kept open while requests are performed.\n         self.num_connections += 1\n-        log.debug('Starting NTLM HTTPS connection no. %d: https://%s%s' %\n-                  (self.num_connections, self.host, self.authurl))\n+        log.debug('Starting NTLM HTTPS connection no. %d: https://%s%s',\n+                  self.num_connections, self.host, self.authurl)\n \n         headers = {}\n         headers['Connection'] = 'Keep-Alive'\n@@ -56,13 +56,13 @@ class NTLMConnectionPool(HTTPSConnectionPool):\n         # Send negotiation message\n         headers[req_header] = (\n             'NTLM %s' % ntlm.create_NTLM_NEGOTIATE_MESSAGE(self.rawuser))\n-        log.debug('Request headers: %s' % headers)\n+        log.debug('Request headers: %s', headers)\n         conn.request('GET', self.authurl, None, headers)\n         res = conn.getresponse()\n         reshdr = dict(res.getheaders())\n-        log.debug('Response status: %s %s' % (res.status, res.reason))\n-        log.debug('Response headers: %s' % reshdr)\n-        log.debug('Response data: %s [...]' % res.read(100))\n+        log.debug('Response status: %s %s', res.status, res.reason)\n+        log.debug('Response headers: %s', reshdr)\n+        log.debug('Response data: %s [...]', res.read(100))\n \n         # Remove the reference to the socket, so that it can not be closed by\n         # the response object (we want to keep the socket open)\n@@ -87,12 +87,12 @@ class NTLMConnectionPool(HTTPSConnectionPool):\n                                                          self.pw,\n                                                          NegotiateFlags)\n         headers[req_header] = 'NTLM %s' % auth_msg\n-        log.debug('Request headers: %s' % headers)\n+        log.debug('Request headers: %s', headers)\n         conn.request('GET', self.authurl, None, headers)\n         res = conn.getresponse()\n-        log.debug('Response status: %s %s' % (res.status, res.reason))\n-        log.debug('Response headers: %s' % dict(res.getheaders()))\n-        log.debug('Response data: %s [...]' % res.read()[:100])\n+        log.debug('Response status: %s %s', res.status, res.reason)\n+        log.debug('Response headers: %s', dict(res.getheaders()))\n+        log.debug('Response data: %s [...]', res.read()[:100])\n         if res.status != 200:\n             if res.status == 401:\n                 raise Exception('Server rejected request: wrong '\n\n@@ -0,0 +1,172 @@\n+# -*- coding: utf-8 -*-\n+\"\"\"\n+SOCKS support for urllib3\n+~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+This contrib module contains provisional support for SOCKS proxies from within\n+urllib3. This module supports SOCKS4 (specifically the SOCKS4A variant) and\n+SOCKS5. To enable its functionality, either install PySocks or install this\n+module with the ``socks`` extra.\n+\n+Known Limitations:\n+\n+- Currently PySocks does not support contacting remote websites via literal\n+  IPv6 addresses. Any such connection attempt will fail.\n+- Currently PySocks does not support IPv6 connections to the SOCKS proxy. Any\n+  such connection attempt will fail.\n+\"\"\"\n+from __future__ import absolute_import\n+\n+try:\n+    import socks\n+except ImportError:\n+    import warnings\n+    from urllib3.exceptions import DependencyWarning\n+\n+    warnings.warn((\n+        'SOCKS support in urllib3 requires the installation of optional '\n+        'dependencies: specifically, PySocks.  For more information, see '\n+        'https://urllib3.readthedocs.org/en/latest/contrib.html#socks-proxies'\n+        ),\n+        DependencyWarning\n+    )\n+    raise\n+\n+from socket import error as SocketError, timeout as SocketTimeout\n+\n+from urllib3.connection import (\n+    HTTPConnection, HTTPSConnection\n+)\n+from urllib3.connectionpool import (\n+    HTTPConnectionPool, HTTPSConnectionPool\n+)\n+from urllib3.exceptions import ConnectTimeoutError, NewConnectionError\n+from urllib3.poolmanager import PoolManager\n+from urllib3.util.url import parse_url\n+\n+try:\n+    import ssl\n+except ImportError:\n+    ssl = None\n+\n+\n+class SOCKSConnection(HTTPConnection):\n+    \"\"\"\n+    A plain-text HTTP connection that connects via a SOCKS proxy.\n+    \"\"\"\n+    def __init__(self, *args, **kwargs):\n+        self._socks_options = kwargs.pop('_socks_options')\n+        super(SOCKSConnection, self).__init__(*args, **kwargs)\n+\n+    def _new_conn(self):\n+        \"\"\"\n+        Establish a new connection via the SOCKS proxy.\n+        \"\"\"\n+        extra_kw = {}\n+        if self.source_address:\n+            extra_kw['source_address'] = self.source_address\n+\n+        if self.socket_options:\n+            extra_kw['socket_options'] = self.socket_options\n+\n+        try:\n+            conn = socks.create_connection(\n+                (self.host, self.port),\n+                proxy_type=self._socks_options['socks_version'],\n+                proxy_addr=self._socks_options['proxy_host'],\n+                proxy_port=self._socks_options['proxy_port'],\n+                proxy_username=self._socks_options['username'],\n+                proxy_password=self._socks_options['password'],\n+                timeout=self.timeout,\n+                **extra_kw\n+            )\n+\n+        except SocketTimeout as e:\n+            raise ConnectTimeoutError(\n+                self, \"Connection to %s timed out. (connect timeout=%s)\" %\n+                (self.host, self.timeout))\n+\n+        except socks.ProxyError as e:\n+            # This is fragile as hell, but it seems to be the only way to raise\n+            # useful errors here.\n+            if e.socket_err:\n+                error = e.socket_err\n+                if isinstance(error, SocketTimeout):\n+                    raise ConnectTimeoutError(\n+                        self,\n+                        \"Connection to %s timed out. (connect timeout=%s)\" %\n+                        (self.host, self.timeout)\n+                    )\n+                else:\n+                    raise NewConnectionError(\n+                        self,\n+                        \"Failed to establish a new connection: %s\" % error\n+                    )\n+            else:\n+                raise NewConnectionError(\n+                    self,\n+                    \"Failed to establish a new connection: %s\" % e\n+                )\n+\n+        except SocketError as e:  # Defensive: PySocks should catch all these.\n+            raise NewConnectionError(\n+                self, \"Failed to establish a new connection: %s\" % e)\n+\n+        return conn\n+\n+\n+# We don't need to duplicate the Verified/Unverified distinction from\n+# urllib3/connection.py here because the HTTPSConnection will already have been\n+# correctly set to either the Verified or Unverified form by that module. This\n+# means the SOCKSHTTPSConnection will automatically be the correct type.\n+class SOCKSHTTPSConnection(SOCKSConnection, HTTPSConnection):\n+    pass\n+\n+\n+class SOCKSHTTPConnectionPool(HTTPConnectionPool):\n+    ConnectionCls = SOCKSConnection\n+\n+\n+class SOCKSHTTPSConnectionPool(HTTPSConnectionPool):\n+    ConnectionCls = SOCKSHTTPSConnection\n+\n+\n+class SOCKSProxyManager(PoolManager):\n+    \"\"\"\n+    A version of the urllib3 ProxyManager that routes connections via the\n+    defined SOCKS proxy.\n+    \"\"\"\n+    pool_classes_by_scheme = {\n+        'http': SOCKSHTTPConnectionPool,\n+        'https': SOCKSHTTPSConnectionPool,\n+    }\n+\n+    def __init__(self, proxy_url, username=None, password=None,\n+                 num_pools=10, headers=None, **connection_pool_kw):\n+        parsed = parse_url(proxy_url)\n+\n+        if parsed.scheme == 'socks5':\n+            socks_version = socks.PROXY_TYPE_SOCKS5\n+        elif parsed.scheme == 'socks4':\n+            socks_version = socks.PROXY_TYPE_SOCKS4\n+        else:\n+            raise ValueError(\n+                \"Unable to determine SOCKS version from %s\" % proxy_url\n+            )\n+\n+        self.proxy_url = proxy_url\n+\n+        socks_options = {\n+            'socks_version': socks_version,\n+            'proxy_host': parsed.host,\n+            'proxy_port': parsed.port,\n+            'username': username,\n+            'password': password,\n+        }\n+        connection_pool_kw['_socks_options'] = socks_options\n+\n+        super(SOCKSProxyManager, self).__init__(\n+            num_pools, headers, **connection_pool_kw\n+        )\n+\n+        self.pool_classes_by_scheme = SOCKSProxyManager.pool_classes_by_scheme\n\n@@ -180,6 +180,14 @@ class SNIMissingWarning(HTTPWarning):\n     pass\n \n \n+class DependencyWarning(HTTPWarning):\n+    \"\"\"\n+    Warned when an attempt is made to import a module with missing optional\n+    dependencies.\n+    \"\"\"\n+    pass\n+\n+\n class ResponseNotChunked(ProtocolError, ValueError):\n     \"Response needs to be chunked in order to read it as chunks.\"\n     pass\n\n@@ -18,16 +18,16 @@ from .util.retry import Retry\n __all__ = ['PoolManager', 'ProxyManager', 'proxy_from_url']\n \n \n-pool_classes_by_scheme = {\n-    'http': HTTPConnectionPool,\n-    'https': HTTPSConnectionPool,\n-}\n-\n log = logging.getLogger(__name__)\n \n SSL_KEYWORDS = ('key_file', 'cert_file', 'cert_reqs', 'ca_certs',\n                 'ssl_version', 'ca_cert_dir')\n \n+pool_classes_by_scheme = {\n+    'http': HTTPConnectionPool,\n+    'https': HTTPSConnectionPool,\n+}\n+\n \n class PoolManager(RequestMethods):\n     \"\"\"\n@@ -65,6 +65,9 @@ class PoolManager(RequestMethods):\n         self.pools = RecentlyUsedContainer(num_pools,\n                                            dispose_func=lambda p: p.close())\n \n+        # Locally set the pool classes so other PoolManagers can override them.\n+        self.pool_classes_by_scheme = pool_classes_by_scheme\n+\n     def __enter__(self):\n         return self\n \n@@ -81,7 +84,7 @@ class PoolManager(RequestMethods):\n         by :meth:`connection_from_url` and companion methods. It is intended\n         to be overridden for customization.\n         \"\"\"\n-        pool_cls = pool_classes_by_scheme[scheme]\n+        pool_cls = self.pool_classes_by_scheme[scheme]\n         kwargs = self.connection_pool_kw\n         if scheme == 'http':\n             kwargs = self.connection_pool_kw.copy()\n@@ -186,7 +189,7 @@ class PoolManager(RequestMethods):\n         kw['retries'] = retries\n         kw['redirect'] = redirect\n \n-        log.info(\"Redirecting %s -> %s\" % (url, redirect_location))\n+        log.info(\"Redirecting %s -> %s\", url, redirect_location)\n         return self.urlopen(method, redirect_location, **kw)\n \n \n\n@@ -61,7 +61,7 @@ def assert_header_parsing(headers):\n \n def is_response_to_head(response):\n     \"\"\"\n-    Checks, wether a the request of a response has been a HEAD-request.\n+    Checks whether the request of a response has been a HEAD-request.\n     Handles the quirks of AppEngine.\n \n     :param conn:\n\n@@ -153,7 +153,7 @@ class Retry(object):\n \n         redirect = bool(redirect) and None\n         new_retries = cls(retries, redirect=redirect)\n-        log.debug(\"Converted retries value: %r -> %r\" % (retries, new_retries))\n+        log.debug(\"Converted retries value: %r -> %r\", retries, new_retries)\n         return new_retries\n \n     def get_backoff_time(self):\n@@ -272,7 +272,7 @@ class Retry(object):\n         if new_retry.is_exhausted():\n             raise MaxRetryError(_pool, url, error or ResponseError(cause))\n \n-        log.debug(\"Incremented Retry for (url='%s'): %r\" % (url, new_retry))\n+        log.debug(\"Incremented Retry for (url='%s'): %r\", url, new_retry)\n \n         return new_retry\n \n\n@@ -110,7 +110,7 @@ except ImportError:\n                 )\n             self.ciphers = cipher_suite\n \n-        def wrap_socket(self, socket, server_hostname=None):\n+        def wrap_socket(self, socket, server_hostname=None, server_side=False):\n             warnings.warn(\n                 'A true SSLContext object is not available. This prevents '\n                 'urllib3 from configuring SSL appropriately and may cause '\n@@ -125,6 +125,7 @@ except ImportError:\n                 'ca_certs': self.ca_certs,\n                 'cert_reqs': self.verify_mode,\n                 'ssl_version': self.protocol,\n+                'server_side': server_side,\n             }\n             if self.supports_set_ciphers:  # Platform-specific: Python 2.7+\n                 return wrap_socket(socket, ciphers=self.ciphers, **kwargs)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
