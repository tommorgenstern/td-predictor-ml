{"custom_id": "scrapy#baed7c436f8c6e52a1aab62fbaf900c0a0f3bbda", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 279 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 6 | Methods Changed: 10 | Complexity Δ (Sum/Max): 35/31 | Churn Δ: 280 | Churn Cumulative: 286 | Contributors (this commit): 4 | Commits (past 90d): 2 | Contributors (cumulative): 6 | DMM Complexity: 0.8431372549019608\n\nDIFF:\n@@ -2,22 +2,226 @@\n RefererMiddleware: populates Request referer field, based on the Response which\n originated it.\n \"\"\"\n+from six.moves.urllib.parse import urlsplit, urlunsplit\n \n from scrapy.http import Request\n from scrapy.exceptions import NotConfigured\n+from scrapy.utils.python import to_native_str\n+\n+\n+LOCAL_SCHEMES = ('about', 'blob', 'data', 'filesystem',)\n+\n+class ReferrerPolicy(object):\n+\n+    NOREFERRER_SCHEMES = LOCAL_SCHEMES\n+\n+    def referrer(self, response, request):\n+        raise NotImplementedError()\n+\n+    def strip_url(self, url, origin_only=False):\n+        \"\"\"\n+        https://www.w3.org/TR/referrer-policy/#strip-url\n+\n+        If url is null, return no referrer.\n+        If url's scheme is a local scheme, then return no referrer.\n+        Set url's username to the empty string.\n+        Set url's password to null.\n+        Set url's fragment to null.\n+        If the origin-only flag is true, then:\n+            Set url's path to null.\n+            Set url's query to null.\n+        Return url.\n+        \"\"\"\n+        if url is None or not url:\n+            return None\n+        parsed = urlsplit(url, allow_fragments=True)\n+\n+        if parsed.scheme in self.NOREFERRER_SCHEMES:\n+            return None\n+        if parsed.username or parsed.password:\n+            netloc = parsed.netloc.replace('{p.username}:{p.password}@'.format(p=parsed), '')\n+        else:\n+            netloc = parsed.netloc\n+        return urlunsplit((\n+            parsed.scheme,\n+            netloc,\n+            '' if origin_only else parsed.path,\n+            '' if origin_only else parsed.query,\n+            ''))\n+\n+\n+class NoReferrerPolicy(ReferrerPolicy):\n+    \"\"\"\n+    https://www.w3.org/TR/referrer-policy/#referrer-policy-no-referrer\n+\n+    The simplest policy is \"no-referrer\", which specifies that no referrer information\n+    is to be sent along with requests made from a particular request client to any origin.\n+    The header will be omitted entirely.\n+    \"\"\"\n+    name = \"no-referrer\"\n+\n+    def referrer(self, response, request):\n+        return None\n+\n+\n+class NoReferrerWhenDowngradePolicy(ReferrerPolicy):\n+    \"\"\"\n+    https://www.w3.org/TR/referrer-policy/#referrer-policy-no-referrer-when-downgrade\n+\n+    The \"no-referrer-when-downgrade\" policy sends a full URL\n+    along with requests from a TLS-protected environment settings object\n+    to a a priori authenticated URL,\n+    and requests from request clients which are not TLS-protected to any origin.\n+\n+    Requests from TLS-protected request clients to non-a priori authenticated URLs,\n+    on the other hand, will contain no referrer information.\n+    A Referer HTTP header will not be sent.\n+\n+    This is a user agent's default behavior, if no policy is otherwise specified.\n+    \"\"\"\n+    name = \"no-referrer-when-downgrade\"\n+\n+    def referrer(self, response, request):\n+        target_url = request.url\n+\n+        referrer_source = response.url\n+        referrer_url = self.strip_url(referrer_source)\n+\n+        # https://www.w3.org/TR/referrer-policy/#determine-requests-referrer:\n+        #\n+        # If environment is TLS-protected\n+        # and the origin of request's current URL is not an a priori authenticated URL,\n+        # then return no referrer.\n+        if urlsplit(referrer_source).scheme in ('https', 'ftps') and \\\n+            urlsplit(target_url).scheme in ('http',):\n+                return None\n+        return referrer_url\n+\n+\n+class SameOriginPolicy(ReferrerPolicy):\n+    \"\"\"\n+    https://www.w3.org/TR/referrer-policy/#referrer-policy-same-origin\n+\n+    The \"same-origin\" policy specifies that a full URL, stripped for use as a referrer,\n+    is sent as referrer information when making same-origin requests from a particular request client.\n+\n+    Cross-origin requests, on the other hand, will contain no referrer information.\n+    A Referer HTTP header will not be sent.\n+    \"\"\"\n+    name = \"same-origin\"\n+\n+    def referrer(self, response, request):\n+        target_url = request.url\n+        referrer_source = response.url\n+        if urlsplit(referrer_source).netloc == urlsplit(target_url).netloc:\n+            return self.strip_url(referrer_source)\n+        else:\n+            return None\n+\n+\n+class OriginPolicy(ReferrerPolicy):\n+    \"\"\"\n+    https://www.w3.org/TR/referrer-policy/#referrer-policy-origin\n+\n+    The \"origin\" policy specifies that only the ASCII serialization\n+    of the origin of the request client is sent as referrer information\n+    when making both same-origin requests and cross-origin requests\n+    from a particular request client.\n+    \"\"\"\n+    name = \"origin\"\n+\n+    def referrer(self, response, request):\n+        return self.strip_url(referrer_source, origin_only=True)\n+\n+\n+class OriginWhenCrossOriginPolicy(ReferrerPolicy):\n+    \"\"\"\n+    https://www.w3.org/TR/referrer-policy/#referrer-policy-origin-when-cross-origin\n+\n+    The \"origin-when-cross-origin\" policy specifies that a full URL,\n+    stripped for use as a referrer, is sent as referrer information\n+    when making same-origin requests from a particular request client,\n+    and only the ASCII serialization of the origin of the request client\n+    is sent as referrer information when making cross-origin requests\n+    from a particular request client.\n+    \"\"\"\n+    name = \"origin-when-cross-origin\"\n+\n+    def referrer(self, response, request):\n+        target_url = request.url\n+        referrer_source = response.url\n+\n+        # same origin --> send full referrer\n+        # different origin --> send only \"origin\" as referrer\n+        if urlsplit(referrer_source).netloc != urlsplit(target_url).netloc:\n+            origin_only = True\n+        return self.strip_url(referrer_source, origin_only=origin_only)\n+\n+\n+class UnsafeUrlPolicy(ReferrerPolicy):\n+    \"\"\"\n+    https://www.w3.org/TR/referrer-policy/#referrer-policy-unsafe-url\n+\n+    The \"unsafe-url\" policy specifies that a full URL, stripped for use as a referrer,\n+    is sent along with both cross-origin requests\n+    and same-origin requests made from a particular request client.\n+\n+    Note: The policy's name doesn't lie; it is unsafe.\n+    This policy will leak origins and paths from TLS-protected resources\n+    to insecure origins.\n+    Carefully consider the impact of setting such a policy for potentially sensitive documents.\n+    \"\"\"\n+    name = \"unsafe-url\"\n+\n+    def referrer(self, response, request):\n+        referrer_source = response.url\n+        return self.strip_url(referrer_source)\n+\n+\n+class LegacyPolicy(ReferrerPolicy):\n+    def referrer(self, response, request):\n+        return response.url\n+\n+\n+class DefaultReferrerPolicy(NoReferrerWhenDowngradePolicy):\n+\n+    NOREFERRER_SCHEMES = LOCAL_SCHEMES + ('file', 's3')\n+\n+\n+_policies = {p.name: p for p in (\n+    NoReferrerPolicy,\n+    NoReferrerWhenDowngradePolicy,\n+    SameOriginPolicy,\n+    OriginPolicy,\n+    OriginWhenCrossOriginPolicy,\n+    UnsafeUrlPolicy,\n+)}\n \n class RefererMiddleware(object):\n \n+    def __init__(self, policy_class=DefaultReferrerPolicy):\n+        self.default_policy = policy_class\n+\n     @classmethod\n     def from_crawler(cls, crawler):\n         if not crawler.settings.getbool('REFERER_ENABLED'):\n             raise NotConfigured\n         return cls()\n \n+    def policy(self, response, request):\n+        policy_name = request.meta.get('referrer_policy')\n+        if policy_name is None:\n+            policy_name = to_native_str(response.headers.get('Referrer-Policy', '').decode('latin1'))\n+\n+        policy_class = _policies.get(policy_name.lower(), self.default_policy)\n+        return policy_class()\n+\n     def process_spider_output(self, response, result, spider):\n         def _set_referer(r):\n             if isinstance(r, Request):\n-                r.headers.setdefault('Referer', response.url)\n+                referrer = self.policy(response, r).referrer(response, r)\n+                if referrer is not None:\n+                    r.headers.setdefault('Referer', referrer)\n             return r\n         return (_set_referer(r) for r in result or ())\n \n\n@@ -19,3 +19,77 @@ class TestRefererMiddleware(TestCase):\n         self.assertEquals(out[0].headers.get('Referer'),\n                           b'http://scrapytest.org')\n \n+    def test_policy_default(self):\n+        \"\"\"\n+        Based on https://www.w3.org/TR/referrer-policy/#referrer-policy-no-referrer-when-downgrade\n+\n+        with some additional filtering of s3://\n+        \"\"\"\n+        # a) https:// --> https://  -- include Referer header\n+        origin = Response('https://example.com/')\n+        target = Request('https://scrapy.org/')\n+\n+        out = list(self.mw.process_spider_output(origin, [target], self.spider))\n+        self.assertEquals(out[0].headers.get('Referer'),\n+                          b'https://example.com/')\n+\n+        # b.1) http:// --> http://  -- include Referer header\n+        origin = Response('http://example.com/')\n+        target = Request('http://scrapy.org/')\n+\n+        out = list(self.mw.process_spider_output(origin, [target], self.spider))\n+        self.assertEquals(out[0].headers.get('Referer'),\n+                          b'http://example.com/')\n+\n+        # b.2) http:// --> https://  -- include Referer header\n+        origin = Response('http://example.com/')\n+        target = Request('https://scrapy.org/')\n+\n+        out = list(self.mw.process_spider_output(origin, [target], self.spider))\n+        self.assertEquals(out[0].headers.get('Referer'),\n+                          b'http://example.com/')\n+\n+        # c) https:// --> http://  -- Referer header NOT sent\n+        origin = Response('https://example.com/')\n+        target = Request('http://scrapy.org/')\n+\n+        out = list(self.mw.process_spider_output(origin, [target], self.spider))\n+        self.assertEquals(out[0].headers.get('Referer'), None)\n+\n+    def test_policy_default_no_credentials_leak(self):\n+        origin = Response('http://user:password@example.com/')\n+        target = Request('https://scrapy.org/')\n+\n+        out = list(self.mw.process_spider_output(origin, [target], self.spider))\n+        self.assertEquals(out[0].headers.get('Referer'),\n+                          b'http://example.com/')\n+\n+    def test_policy_default_file_no_referrer_leak(self):\n+        # file:// --> https://  -- Referrer NOT sent\n+        origin = Response('file:///home/path/to/somefile.html')\n+        target = Request('https://scrapy.org/')\n+\n+        out = list(self.mw.process_spider_output(origin, [target], self.spider))\n+        self.assertEquals(out[0].headers.get('Referer'), None)\n+\n+        # file:// --> http://  -- Referrer NOT sent\n+        origin = Response('file:///home/path/to/somefile.html')\n+        target = Request('http://scrapy.org/')\n+\n+        out = list(self.mw.process_spider_output(origin, [target], self.spider))\n+        self.assertEquals(out[0].headers.get('Referer'), None)\n+\n+    def test_policy_default_s3_no_referrer_leak(self):\n+        # s3:// --> https://  -- Referrer NOT sent\n+        origin = Response('s3://mybucket/path/to/data.csv')\n+        target = Request('https://scrapy.org/')\n+\n+        out = list(self.mw.process_spider_output(origin, [target], self.spider))\n+        self.assertEquals(out[0].headers.get('Referer'), None)\n+\n+        # s3:// --> http://  -- Referrer NOT sent\n+        origin = Response('s3://mybucket/path/to/data.csv')\n+        target = Request('http://scrapy.org/')\n+\n+        out = list(self.mw.process_spider_output(origin, [target], self.spider))\n+        self.assertEquals(out[0].headers.get('Referer'), None)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#7ec1b5f6c316f6c251821441f513e3f71cf63da0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 235 | Lines Deleted: 73 | Files Changed: 2 | Hunks: 39 | Methods Changed: 14 | Complexity Δ (Sum/Max): 13/10 | Churn Δ: 308 | Churn Cumulative: 594 | Contributors (this commit): 4 | Commits (past 90d): 4 | Contributors (cumulative): 6 | DMM Complexity: 0.9809523809523809\n\nDIFF:\n@@ -11,6 +11,15 @@ from scrapy.utils.python import to_native_str\n \n LOCAL_SCHEMES = ('about', 'blob', 'data', 'filesystem',)\n \n+POLICY_NO_REFERRER = \"no-referrer\"\n+POLICY_NO_REFERRER_WHEN_DOWNGRADE = \"no-referrer-when-downgrade\"\n+POLICY_SAME_ORIGIN = \"same-origin\"\n+POLICY_ORIGIN = \"origin\"\n+POLICY_ORIGIN_WHEN_CROSS_ORIGIN = \"origin-when-cross-origin\"\n+POLICY_UNSAFE_URL = \"unsafe-url\"\n+POLICY_SCRAPY_DEFAULT = \"scrapy-default\"\n+\n+\n class ReferrerPolicy(object):\n \n     NOREFERRER_SCHEMES = LOCAL_SCHEMES\n@@ -38,17 +47,29 @@ class ReferrerPolicy(object):\n \n         if parsed.scheme in self.NOREFERRER_SCHEMES:\n             return None\n-        if parsed.username or parsed.password:\n-            netloc = parsed.netloc.replace('{p.username}:{p.password}@'.format(p=parsed), '')\n-        else:\n+\n         netloc = parsed.netloc\n+        # strip username and password if present\n+        if parsed.username or parsed.password:\n+            netloc = netloc.replace('{p.username}:{p.password}@'.format(p=parsed), '')\n+\n+        # strip standard protocol numbers\n+        # Note: strictly speaking, standard port numbers should only be\n+        # stripped when comparing origins\n+        if parsed.port:\n+            if (parsed.scheme, parsed.port) in (('http', 80), ('https', 443)):\n+                netloc = netloc.replace(':{p.port}'.format(p=parsed), '')\n+\n         return urlunsplit((\n             parsed.scheme,\n             netloc,\n-            '' if origin_only else parsed.path,\n+            '/' if origin_only else parsed.path,\n             '' if origin_only else parsed.query,\n             ''))\n \n+    def origin(self, url):\n+        return self.strip_url(url, origin_only=True)\n+\n \n class NoReferrerPolicy(ReferrerPolicy):\n     \"\"\"\n@@ -58,7 +79,7 @@ class NoReferrerPolicy(ReferrerPolicy):\n     is to be sent along with requests made from a particular request client to any origin.\n     The header will be omitted entirely.\n     \"\"\"\n-    name = \"no-referrer\"\n+    name = POLICY_NO_REFERRER\n \n     def referrer(self, response, request):\n         return None\n@@ -79,7 +100,7 @@ class NoReferrerWhenDowngradePolicy(ReferrerPolicy):\n \n     This is a user agent's default behavior, if no policy is otherwise specified.\n     \"\"\"\n-    name = \"no-referrer-when-downgrade\"\n+    name = POLICY_NO_REFERRER_WHEN_DOWNGRADE\n \n     def referrer(self, response, request):\n         target_url = request.url\n@@ -108,12 +129,12 @@ class SameOriginPolicy(ReferrerPolicy):\n     Cross-origin requests, on the other hand, will contain no referrer information.\n     A Referer HTTP header will not be sent.\n     \"\"\"\n-    name = \"same-origin\"\n+    name = POLICY_SAME_ORIGIN\n \n     def referrer(self, response, request):\n         target_url = request.url\n         referrer_source = response.url\n-        if urlsplit(referrer_source).netloc == urlsplit(target_url).netloc:\n+        if self.origin(referrer_source) == self.origin(target_url):\n             return self.strip_url(referrer_source)\n         else:\n             return None\n@@ -128,10 +149,10 @@ class OriginPolicy(ReferrerPolicy):\n     when making both same-origin requests and cross-origin requests\n     from a particular request client.\n     \"\"\"\n-    name = \"origin\"\n+    name = POLICY_ORIGIN\n \n     def referrer(self, response, request):\n-        return self.strip_url(referrer_source, origin_only=True)\n+        return self.strip_url(response.url, origin_only=True)\n \n \n class OriginWhenCrossOriginPolicy(ReferrerPolicy):\n@@ -145,17 +166,17 @@ class OriginWhenCrossOriginPolicy(ReferrerPolicy):\n     is sent as referrer information when making cross-origin requests\n     from a particular request client.\n     \"\"\"\n-    name = \"origin-when-cross-origin\"\n+    name = POLICY_ORIGIN_WHEN_CROSS_ORIGIN\n \n     def referrer(self, response, request):\n         target_url = request.url\n         referrer_source = response.url\n+        source_origin = self.origin(referrer_source)\n+        if source_origin == self.origin(target_url):\n+            return self.strip_url(referrer_source, origin_only=False)\n+        else:\n+            return source_origin\n \n-        # same origin --> send full referrer\n-        # different origin --> send only \"origin\" as referrer\n-        if urlsplit(referrer_source).netloc != urlsplit(target_url).netloc:\n-            origin_only = True\n-        return self.strip_url(referrer_source, origin_only=origin_only)\n \n \n class UnsafeUrlPolicy(ReferrerPolicy):\n@@ -171,7 +192,7 @@ class UnsafeUrlPolicy(ReferrerPolicy):\n     to insecure origins.\n     Carefully consider the impact of setting such a policy for potentially sensitive documents.\n     \"\"\"\n-    name = \"unsafe-url\"\n+    name = POLICY_UNSAFE_URL\n \n     def referrer(self, response, request):\n         referrer_source = response.url\n@@ -186,15 +207,17 @@ class LegacyPolicy(ReferrerPolicy):\n class DefaultReferrerPolicy(NoReferrerWhenDowngradePolicy):\n \n     NOREFERRER_SCHEMES = LOCAL_SCHEMES + ('file', 's3')\n+    name = POLICY_SCRAPY_DEFAULT\n \n \n-_policies = {p.name: p for p in (\n+_policy_classes = {p.name: p for p in (\n     NoReferrerPolicy,\n     NoReferrerWhenDowngradePolicy,\n     SameOriginPolicy,\n     OriginPolicy,\n     OriginWhenCrossOriginPolicy,\n     UnsafeUrlPolicy,\n+    DefaultReferrerPolicy,\n )}\n \n class RefererMiddleware(object):\n@@ -211,10 +234,11 @@ class RefererMiddleware(object):\n     def policy(self, response, request):\n         policy_name = request.meta.get('referrer_policy')\n         if policy_name is None:\n-            policy_name = to_native_str(response.headers.get('Referrer-Policy', '').decode('latin1'))\n+            policy_name = to_native_str(\n+                response.headers.get('Referrer-Policy', '').decode('latin1'))\n \n-        policy_class = _policies.get(policy_name.lower(), self.default_policy)\n-        return policy_class()\n+        cls = _policy_classes.get(policy_name.lower(), self.default_policy)\n+        return cls()\n \n     def process_spider_output(self, response, result, spider):\n         def _set_referer(r):\n\n@@ -2,7 +2,10 @@ from unittest import TestCase\n \n from scrapy.http import Response, Request\n from scrapy.spiders import Spider\n-from scrapy.spidermiddlewares.referer import RefererMiddleware\n+from scrapy.spidermiddlewares.referer import RefererMiddleware, \\\n+    POLICY_NO_REFERRER, POLICY_NO_REFERRER_WHEN_DOWNGRADE, \\\n+    POLICY_SAME_ORIGIN, POLICY_ORIGIN, POLICY_ORIGIN_WHEN_CROSS_ORIGIN, \\\n+    POLICY_UNSAFE_URL\n \n \n class TestRefererMiddleware(TestCase):\n@@ -25,71 +28,206 @@ class TestRefererMiddleware(TestCase):\n \n         with some additional filtering of s3://\n         \"\"\"\n-        # a) https:// --> https://  -- include Referer header\n-        origin = Response('https://example.com/')\n-        target = Request('https://scrapy.org/')\n+        for origin, target, referrer in [\n+                ('https://example.com/',    'https://scrapy.org/',  b'https://example.com/'),\n+                ('http://example.com/',     'http://scrapy.org/',   b'http://example.com/'),\n+                ('http://example.com/',     'https://scrapy.org/',  b'http://example.com/'),\n+                ('https://example.com/',    'http://scrapy.org/',   None),\n \n-        out = list(self.mw.process_spider_output(origin, [target], self.spider))\n-        self.assertEquals(out[0].headers.get('Referer'),\n-                          b'https://example.com/')\n+                # no credentials leak\n+                ('http://user:password@example.com/',  'https://scrapy.org/', b'http://example.com/'),\n \n-        # b.1) http:// --> http://  -- include Referer header\n-        origin = Response('http://example.com/')\n-        target = Request('http://scrapy.org/')\n+                # no referrer leak for local schemes\n+                ('file:///home/path/to/somefile.html',  'https://scrapy.org/', None),\n+                ('file:///home/path/to/somefile.html',  'http://scrapy.org/',  None),\n \n-        out = list(self.mw.process_spider_output(origin, [target], self.spider))\n-        self.assertEquals(out[0].headers.get('Referer'),\n-                          b'http://example.com/')\n+                # no referrer leak for s3 origins\n+                ('s3://mybucket/path/to/data.csv',  'https://scrapy.org/', None),\n+                ('s3://mybucket/path/to/data.csv',  'http://scrapy.org/',  None),\n+            ]:\n+            response = Response(origin)\n+            request = Request(target)\n \n-        # b.2) http:// --> https://  -- include Referer header\n-        origin = Response('http://example.com/')\n-        target = Request('https://scrapy.org/')\n+            out = list(self.mw.process_spider_output(response, [request], self.spider))\n+            self.assertEquals(out[0].headers.get('Referer'), referrer)\n \n-        out = list(self.mw.process_spider_output(origin, [target], self.spider))\n-        self.assertEquals(out[0].headers.get('Referer'),\n-                          b'http://example.com/')\n+    def test_policy_no_referrer(self):\n \n-        # c) https:// --> http://  -- Referer header NOT sent\n-        origin = Response('https://example.com/')\n-        target = Request('http://scrapy.org/')\n+        for origin, target, referrer in [\n+                ('https://example.com/page.html',       'https://example.com/', None),\n+                ('http://www.example.com/',             'https://scrapy.org/',  None),\n+                ('http://www.example.com/',             'http://scrapy.org/',   None),\n+                ('https://www.example.com/',            'http://scrapy.org/',   None),\n+                ('file:///home/path/to/somefile.html',  'http://scrapy.org/',   None),\n+            ]:\n+            response = Response(origin)\n+            request = Request(target, meta={'referrer_policy': POLICY_NO_REFERRER})\n \n-        out = list(self.mw.process_spider_output(origin, [target], self.spider))\n-        self.assertEquals(out[0].headers.get('Referer'), None)\n+            out = list(self.mw.process_spider_output(response, [request], self.spider))\n+            self.assertEquals(out[0].headers.get('Referer'), referrer)\n \n-    def test_policy_default_no_credentials_leak(self):\n-        origin = Response('http://user:password@example.com/')\n-        target = Request('https://scrapy.org/')\n+    def test_policy_no_referrer_when_downgrade(self):\n \n-        out = list(self.mw.process_spider_output(origin, [target], self.spider))\n-        self.assertEquals(out[0].headers.get('Referer'),\n-                          b'http://example.com/')\n+        for origin, target, referrer in [\n+                # TLS to TLS: send non-empty referrer\n+                ('https://example.com/page.html',       'https://not.example.com/', b'https://example.com/page.html'),\n+                ('https://example.com/page.html',       'https://scrapy.org/',      b'https://example.com/page.html'),\n+                ('https://example.com:443/page.html',   'https://scrapy.org/',      b'https://example.com/page.html'),\n+                ('https://example.com:444/page.html',   'https://scrapy.org/',      b'https://example.com:444/page.html'),\n+                ('ftps://example.com/urls.zip',         'https://scrapy.org/',      b'ftps://example.com/urls.zip'),\n \n-    def test_policy_default_file_no_referrer_leak(self):\n-        # file:// --> https://  -- Referrer NOT sent\n-        origin = Response('file:///home/path/to/somefile.html')\n-        target = Request('https://scrapy.org/')\n+                # TLS to non-TLS: do not send referrer\n+                ('https://example.com/page.html',       'http://not.example.com/',  None),\n+                ('https://example.com/page.html',       'http://scrapy.org/',       None),\n+                ('ftps://example.com/urls.zip',         'http://scrapy.org/',       None),\n \n-        out = list(self.mw.process_spider_output(origin, [target], self.spider))\n-        self.assertEquals(out[0].headers.get('Referer'), None)\n+                # non-TLS to TLS or non-TLS: send referrer\n+                ('http://example.com/page.html',        'https://not.example.com/', b'http://example.com/page.html'),\n+                ('http://example.com/page.html',        'https://scrapy.org/',      b'http://example.com/page.html'),\n+                ('http://example.com:8080/page.html',   'https://scrapy.org/',      b'http://example.com:8080/page.html'),\n+                ('http://example.com:80/page.html',     'http://not.example.com/',  b'http://example.com/page.html'),\n+                ('http://example.com/page.html',        'http://scrapy.org/',       b'http://example.com/page.html'),\n+                ('http://example.com:443/page.html',    'http://scrapy.org/',       b'http://example.com:443/page.html'),\n+                ('ftp://example.com/urls.zip',          'http://scrapy.org/',       b'ftp://example.com/urls.zip'),\n+                ('ftp://example.com/urls.zip',          'https://scrapy.org/',      b'ftp://example.com/urls.zip'),\n \n-        # file:// --> http://  -- Referrer NOT sent\n-        origin = Response('file:///home/path/to/somefile.html')\n-        target = Request('http://scrapy.org/')\n+                # test for user/password stripping\n+                ('http://user:password@example.com/page.html', 'https://not.example.com/', b'http://example.com/page.html'),\n+            ]:\n+            response = Response(origin)\n+            request = Request(target, meta={'referrer_policy': POLICY_NO_REFERRER_WHEN_DOWNGRADE})\n \n-        out = list(self.mw.process_spider_output(origin, [target], self.spider))\n-        self.assertEquals(out[0].headers.get('Referer'), None)\n+            out = list(self.mw.process_spider_output(response, [request], self.spider))\n+            self.assertEquals(out[0].headers.get('Referer'), referrer)\n \n-    def test_policy_default_s3_no_referrer_leak(self):\n-        # s3:// --> https://  -- Referrer NOT sent\n-        origin = Response('s3://mybucket/path/to/data.csv')\n-        target = Request('https://scrapy.org/')\n+    def test_policy_same_origin(self):\n \n-        out = list(self.mw.process_spider_output(origin, [target], self.spider))\n-        self.assertEquals(out[0].headers.get('Referer'), None)\n+        for origin, target, referrer in [\n+                # Same origin (protocol, host, port): send referrer\n+                ('https://example.com/page.html',       'https://example.com/not-page.html',        b'https://example.com/page.html'),\n+                ('http://example.com/page.html',        'http://example.com/not-page.html',         b'http://example.com/page.html'),\n+                ('https://example.com:443/page.html',   'https://example.com/not-page.html',        b'https://example.com/page.html'),\n+                ('http://example.com:80/page.html',     'http://example.com/not-page.html',         b'http://example.com/page.html'),\n+                ('http://example.com/page.html',        'http://example.com:80/not-page.html',      b'http://example.com/page.html'),\n+                ('http://example.com:8888/page.html',   'http://example.com:8888/not-page.html',    b'http://example.com:8888/page.html'),\n \n-        # s3:// --> http://  -- Referrer NOT sent\n-        origin = Response('s3://mybucket/path/to/data.csv')\n-        target = Request('http://scrapy.org/')\n+                # Different host: do NOT send referrer\n+                ('https://example.com/page.html',       'https://not.example.com/otherpage.html',   None),\n+                ('http://example.com/page.html',        'http://not.example.com/otherpage.html',    None),\n+                ('http://example.com/page.html',        'http://www.example.com/otherpage.html',    None),\n \n-        out = list(self.mw.process_spider_output(origin, [target], self.spider))\n-        self.assertEquals(out[0].headers.get('Referer'), None)\n+                # Different port: do NOT send referrer\n+                ('https://example.com:444/page.html',   'https://example.com/not-page.html',    None),\n+                ('http://example.com:81/page.html',     'http://example.com/not-page.html',     None),\n+                ('http://example.com/page.html',        'http://example.com:81/not-page.html',  None),\n+\n+                # Different protocols: do NOT send refferer\n+                ('https://example.com/page.html',   'http://example.com/not-page.html',     None),\n+                ('https://example.com/page.html',   'http://not.example.com/',              None),\n+                ('ftps://example.com/urls.zip',     'https://example.com/not-page.html',    None),\n+                ('ftp://example.com/urls.zip',      'http://example.com/not-page.html',     None),\n+                ('ftps://example.com/urls.zip',     'https://example.com/not-page.html',    None),\n+\n+                # test for user/password stripping\n+                ('https://user:password@example.com/page.html', 'https://example.com/not-page.html',    b'https://example.com/page.html'),\n+                ('https://user:password@example.com/page.html', 'http://example.com/not-page.html',     None),\n+            ]:\n+            response = Response(origin)\n+            request = Request(target, meta={'referrer_policy': POLICY_SAME_ORIGIN})\n+\n+            out = list(self.mw.process_spider_output(response, [request], self.spider))\n+            self.assertEquals(out[0].headers.get('Referer'), referrer)\n+\n+    def test_policy_origin(self):\n+\n+        for origin, target, referrer in [\n+                # TLS or non-TLS to TLS or non-TLS: referrer origin is sent (yes, even for downgrades)\n+                ('https://example.com/page.html',   'https://example.com/not-page.html',    b'https://example.com/'),\n+                ('https://example.com/page.html',   'https://scrapy.org',                   b'https://example.com/'),\n+                ('https://example.com/page.html',   'http://scrapy.org',                    b'https://example.com/'),\n+                ('http://example.com/page.html',    'http://scrapy.org',                    b'http://example.com/'),\n+\n+                # test for user/password stripping\n+                ('https://user:password@example.com/page.html', 'http://scrapy.org', b'https://example.com/'),\n+            ]:\n+            response = Response(origin)\n+            request = Request(target, meta={'referrer_policy': POLICY_ORIGIN})\n+\n+            out = list(self.mw.process_spider_output(response, [request], self.spider))\n+            self.assertEquals(out[0].headers.get('Referer'), referrer)\n+\n+    def test_policy_origin_when_cross_origin(self):\n+\n+        for origin, target, referrer in [\n+                # Same origin (protocol, host, port): send referrer\n+                ('https://example.com/page.html',       'https://example.com/not-page.html',        b'https://example.com/page.html'),\n+                ('http://example.com/page.html',        'http://example.com/not-page.html',         b'http://example.com/page.html'),\n+                ('https://example.com:443/page.html',   'https://example.com/not-page.html',        b'https://example.com/page.html'),\n+                ('http://example.com:80/page.html',     'http://example.com/not-page.html',         b'http://example.com/page.html'),\n+                ('http://example.com/page.html',        'http://example.com:80/not-page.html',      b'http://example.com/page.html'),\n+                ('http://example.com:8888/page.html',   'http://example.com:8888/not-page.html',    b'http://example.com:8888/page.html'),\n+\n+                # Different host: send origin as referrer\n+                ('https://example2.com/page.html',  'https://scrapy.org/otherpage.html',        b'https://example2.com/'),\n+                ('https://example2.com/page.html',  'https://not.example2.com/otherpage.html',  b'https://example2.com/'),\n+                ('http://example2.com/page.html',   'http://not.example2.com/otherpage.html',   b'http://example2.com/'),\n+                # exact match required\n+                ('http://example2.com/page.html',   'http://www.example2.com/otherpage.html',   b'http://example2.com/'),\n+\n+                # Different port: send origin as referrer\n+                ('https://example3.com:444/page.html',  'https://example3.com/not-page.html',   b'https://example3.com:444/'),\n+                ('http://example3.com:81/page.html',    'http://example3.com/not-page.html',    b'http://example3.com:81/'),\n+\n+                # Different protocols: send origin as referrer\n+                ('https://example4.com/page.html',  'http://example4.com/not-page.html',    b'https://example4.com/'),\n+                ('https://example4.com/page.html',  'http://not.example4.com/',             b'https://example4.com/'),\n+                ('ftps://example4.com/urls.zip',    'https://example4.com/not-page.html',   b'ftps://example4.com/'),\n+                ('ftp://example4.com/urls.zip',     'http://example4.com/not-page.html',    b'ftp://example4.com/'),\n+                ('ftps://example4.com/urls.zip',    'https://example4.com/not-page.html',   b'ftps://example4.com/'),\n+\n+                # test for user/password stripping\n+                ('https://user:password@example5.com/page.html', 'https://example5.com/not-page.html',  b'https://example5.com/page.html'),\n+                # TLS to non-TLS downgrade: send origin\n+                ('https://user:password@example5.com/page.html', 'http://example5.com/not-page.html',   b'https://example5.com/'),\n+            ]:\n+            response = Response(origin)\n+            request = Request(target, meta={'referrer_policy': POLICY_ORIGIN_WHEN_CROSS_ORIGIN})\n+\n+            out = list(self.mw.process_spider_output(response, [request], self.spider))\n+            self.assertEquals(out[0].headers.get('Referer'), referrer)\n+\n+    def test_policy_unsafe_url(self):\n+\n+        for origin, target, referrer in [\n+                # TLS to TLS: send referrer\n+                ('https://example.com/sekrit.html',     'http://not.example.com/',      b'https://example.com/sekrit.html'),\n+                ('https://example1.com/page.html',      'https://not.example1.com/',    b'https://example1.com/page.html'),\n+                ('https://example1.com/page.html',      'https://scrapy.org/',          b'https://example1.com/page.html'),\n+                ('https://example1.com:443/page.html',  'https://scrapy.org/',          b'https://example1.com/page.html'),\n+                ('https://example1.com:444/page.html',  'https://scrapy.org/',          b'https://example1.com:444/page.html'),\n+                ('ftps://example1.com/urls.zip',        'https://scrapy.org/',          b'ftps://example1.com/urls.zip'),\n+\n+                # TLS to non-TLS: send referrer (yes, it's unsafe)\n+                ('https://example2.com/page.html',  'http://not.example2.com/', b'https://example2.com/page.html'),\n+                ('https://example2.com/page.html',  'http://scrapy.org/',       b'https://example2.com/page.html'),\n+                ('ftps://example2.com/urls.zip',    'http://scrapy.org/',       b'ftps://example2.com/urls.zip'),\n+\n+                # non-TLS to TLS or non-TLS: send referrer (yes, it's unsafe)\n+                ('http://example3.com/page.html',       'https://not.example3.com/',    b'http://example3.com/page.html'),\n+                ('http://example3.com/page.html',       'https://scrapy.org/',          b'http://example3.com/page.html'),\n+                ('http://example3.com:8080/page.html',  'https://scrapy.org/',          b'http://example3.com:8080/page.html'),\n+                ('http://example3.com:80/page.html',    'http://not.example3.com/',     b'http://example3.com/page.html'),\n+                ('http://example3.com/page.html',       'http://scrapy.org/',           b'http://example3.com/page.html'),\n+                ('http://example3.com:443/page.html',   'http://scrapy.org/',           b'http://example3.com:443/page.html'),\n+                ('ftp://example3.com/urls.zip',         'http://scrapy.org/',           b'ftp://example3.com/urls.zip'),\n+                ('ftp://example3.com/urls.zip',         'https://scrapy.org/',          b'ftp://example3.com/urls.zip'),\n+\n+                # test for user/password stripping\n+                ('http://user:password@example4.com/page.html',     'https://not.example4.com/',    b'http://example4.com/page.html'),\n+                ('https://user:password@example4.com/page.html',    'http://scrapy.org/',           b'https://example4.com/page.html'),\n+            ]:\n+            response = Response(origin)\n+            request = Request(target, meta={'referrer_policy': POLICY_UNSAFE_URL})\n+\n+            out = list(self.mw.process_spider_output(response, [request], self.spider))\n+            self.assertEquals(out[0].headers.get('Referer'), referrer)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#3af88a2877f947c74c6d9003da620629b27d5a17", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 60 | Lines Deleted: 19 | Files Changed: 1 | Hunks: 12 | Methods Changed: 4 | Complexity Δ (Sum/Max): 15/15 | Churn Δ: 79 | Churn Cumulative: 351 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -2,11 +2,12 @@\n RefererMiddleware: populates Request referer field, based on the Response which\n originated it.\n \"\"\"\n-from six.moves.urllib.parse import urlsplit, urlunsplit\n+from six.moves.urllib.parse import urlparse, urlunparse, ParseResult\n \n from scrapy.http import Request\n from scrapy.exceptions import NotConfigured\n from scrapy.utils.python import to_native_str\n+from scrapy.utils.httpobj import urlparse_cached\n \n \n LOCAL_SCHEMES = ('about', 'blob', 'data', 'filesystem',)\n@@ -27,7 +28,7 @@ class ReferrerPolicy(object):\n     def referrer(self, response, request):\n         raise NotImplementedError()\n \n-    def strip_url(self, url, origin_only=False):\n+    def strip_url_parsed(self, req_or_resp, origin_only=False):\n         \"\"\"\n         https://www.w3.org/TR/referrer-policy/#strip-url\n \n@@ -41,9 +42,9 @@ class ReferrerPolicy(object):\n             Set url's query to null.\n         Return url.\n         \"\"\"\n-        if url is None or not url:\n+        if req_or_resp.url is None or not req_or_resp.url:\n             return None\n-        parsed = urlsplit(url, allow_fragments=True)\n+        parsed = urlparse_cached(req_or_resp)\n \n         if parsed.scheme in self.NOREFERRER_SCHEMES:\n             return None\n@@ -60,16 +61,61 @@ class ReferrerPolicy(object):\n             if (parsed.scheme, parsed.port) in (('http', 80), ('https', 443)):\n                 netloc = netloc.replace(':{p.port}'.format(p=parsed), '')\n \n-        return urlunsplit((\n+        return ParseResult(parsed.scheme,\n+                           netloc,\n+                           '/' if origin_only else parsed.path,\n+                           '' if origin_only else parsed.params,\n+                           '' if origin_only else parsed.query,\n+                           '')\n+\n+    def strip_url(self, url, origin_only=False):\n+        \"\"\"\n+        https://www.w3.org/TR/referrer-policy/#strip-url\n+\n+        If url is null, return no referrer.\n+        If url's scheme is a local scheme, then return no referrer.\n+        Set url's username to the empty string.\n+        Set url's password to null.\n+        Set url's fragment to null.\n+        If the origin-only flag is true, then:\n+            Set url's path to null.\n+            Set url's query to null.\n+        Return url.\n+        \"\"\"\n+        if url is None or not url:\n+            return None\n+        parsed = urlparse(url, allow_fragments=True)\n+\n+        if parsed.scheme in self.NOREFERRER_SCHEMES:\n+            return None\n+\n+        netloc = parsed.netloc\n+        # strip username and password if present\n+        if parsed.username or parsed.password:\n+            netloc = netloc.replace('{p.username}:{p.password}@'.format(p=parsed), '')\n+\n+        # strip standard protocol numbers\n+        # Note: strictly speaking, standard port numbers should only be\n+        # stripped when comparing origins\n+        if parsed.port:\n+            if (parsed.scheme, parsed.port) in (('http', 80), ('https', 443)):\n+                netloc = netloc.replace(':{p.port}'.format(p=parsed), '')\n+\n+        return urlunparse((\n             parsed.scheme,\n             netloc,\n             '/' if origin_only else parsed.path,\n+            '' if origin_only else parsed.params,\n             '' if origin_only else parsed.query,\n             ''))\n \n     def origin(self, url):\n         return self.strip_url(url, origin_only=True)\n \n+    def origin_parsed(self, req_or_resp):\n+        \"\"\"Return (scheme, host, path) tuple for a request or response URL.\"\"\"\n+        return tuple(self.strip_url_parsed(req_or_resp, origin_only=True)[:3])\n+\n \n class NoReferrerPolicy(ReferrerPolicy):\n     \"\"\"\n@@ -103,20 +149,17 @@ class NoReferrerWhenDowngradePolicy(ReferrerPolicy):\n     name = POLICY_NO_REFERRER_WHEN_DOWNGRADE\n \n     def referrer(self, response, request):\n-        target_url = request.url\n-\n-        referrer_source = response.url\n-        referrer_url = self.strip_url(referrer_source)\n-\n         # https://www.w3.org/TR/referrer-policy/#determine-requests-referrer:\n         #\n         # If environment is TLS-protected\n         # and the origin of request's current URL is not an a priori authenticated URL,\n         # then return no referrer.\n-        if urlsplit(referrer_source).scheme in ('https', 'ftps') and \\\n-            urlsplit(target_url).scheme in ('http',):\n+        if urlparse_cached(response).scheme in ('https', 'ftps') and \\\n+            urlparse_cached(request).scheme in ('http',):\n                 return None\n-        return referrer_url\n+        stripped = self.strip_url_parsed(response)\n+        if stripped is not None:\n+            return urlunparse(stripped)\n \n \n class SameOriginPolicy(ReferrerPolicy):\n@@ -132,12 +175,10 @@ class SameOriginPolicy(ReferrerPolicy):\n     name = POLICY_SAME_ORIGIN\n \n     def referrer(self, response, request):\n-        target_url = request.url\n-        referrer_source = response.url\n-        if self.origin(referrer_source) == self.origin(target_url):\n-            return self.strip_url(referrer_source)\n-        else:\n-            return None\n+        if self.origin_parsed(response) == self.origin_parsed(request):\n+            stripped = self.strip_url_parsed(response)\n+            if stripped is not None:\n+                return urlunparse(stripped)\n \n \n class OriginPolicy(ReferrerPolicy):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#f2ee6be3bb311bb8f89ccd929bc0ebd8412d0183", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 4 | Churn Cumulative: 355 | Contributors (this commit): 2 | Commits (past 90d): 4 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -193,7 +193,9 @@ class OriginPolicy(ReferrerPolicy):\n     name = POLICY_ORIGIN\n \n     def referrer(self, response, request):\n-        return self.strip_url(response.url, origin_only=True)\n+        stripped = self.strip_url_parsed(response, origin_only=True)\n+        if stripped is not None:\n+            return urlunparse(stripped)\n \n \n class OriginWhenCrossOriginPolicy(ReferrerPolicy):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#59cb884ace1cb1c3339f1d0f05895501dd4d0447", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 10 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 19 | Churn Cumulative: 374 | Contributors (this commit): 2 | Commits (past 90d): 5 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -193,9 +193,9 @@ class OriginPolicy(ReferrerPolicy):\n     name = POLICY_ORIGIN\n \n     def referrer(self, response, request):\n-        stripped = self.strip_url_parsed(response, origin_only=True)\n-        if stripped is not None:\n-            return urlunparse(stripped)\n+        origin = self.strip_url_parsed(response, origin_only=True)\n+        if origin is not None:\n+            return urlunparse(origin)\n \n \n class OriginWhenCrossOriginPolicy(ReferrerPolicy):\n@@ -212,14 +212,13 @@ class OriginWhenCrossOriginPolicy(ReferrerPolicy):\n     name = POLICY_ORIGIN_WHEN_CROSS_ORIGIN\n \n     def referrer(self, response, request):\n-        target_url = request.url\n-        referrer_source = response.url\n-        source_origin = self.origin(referrer_source)\n-        if source_origin == self.origin(target_url):\n-            return self.strip_url(referrer_source, origin_only=False)\n+        origin = self.origin_parsed(response)\n+        if origin == self.origin_parsed(request):\n+            stripped = self.strip_url_parsed(response)\n+            if stripped is not None:\n+                return urlunparse(stripped)\n         else:\n-            return source_origin\n-\n+            return urlunparse(origin + ('', '', ''))\n \n \n class UnsafeUrlPolicy(ReferrerPolicy):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#f6a800fde67447d94480d4271de62f5e9a60bfb0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 57 | Files Changed: 1 | Hunks: 9 | Methods Changed: 7 | Complexity Δ (Sum/Max): -11/0 | Churn Δ: 71 | Churn Cumulative: 445 | Contributors (this commit): 2 | Commits (past 90d): 6 | Contributors (cumulative): 2 | DMM Complexity: 0.95\n\nDIFF:\n@@ -2,7 +2,7 @@\n RefererMiddleware: populates Request referer field, based on the Response which\n originated it.\n \"\"\"\n-from six.moves.urllib.parse import urlparse, urlunparse, ParseResult\n+from six.moves.urllib.parse import ParseResult, urlunparse\n \n from scrapy.http import Request\n from scrapy.exceptions import NotConfigured\n@@ -28,7 +28,7 @@ class ReferrerPolicy(object):\n     def referrer(self, response, request):\n         raise NotImplementedError()\n \n-    def strip_url_parsed(self, req_or_resp, origin_only=False):\n+    def strip_url(self, req_or_resp, origin_only=False):\n         \"\"\"\n         https://www.w3.org/TR/referrer-policy/#strip-url\n \n@@ -68,53 +68,9 @@ class ReferrerPolicy(object):\n                            '' if origin_only else parsed.query,\n                            '')\n \n-    def strip_url(self, url, origin_only=False):\n-        \"\"\"\n-        https://www.w3.org/TR/referrer-policy/#strip-url\n-\n-        If url is null, return no referrer.\n-        If url's scheme is a local scheme, then return no referrer.\n-        Set url's username to the empty string.\n-        Set url's password to null.\n-        Set url's fragment to null.\n-        If the origin-only flag is true, then:\n-            Set url's path to null.\n-            Set url's query to null.\n-        Return url.\n-        \"\"\"\n-        if url is None or not url:\n-            return None\n-        parsed = urlparse(url, allow_fragments=True)\n-\n-        if parsed.scheme in self.NOREFERRER_SCHEMES:\n-            return None\n-\n-        netloc = parsed.netloc\n-        # strip username and password if present\n-        if parsed.username or parsed.password:\n-            netloc = netloc.replace('{p.username}:{p.password}@'.format(p=parsed), '')\n-\n-        # strip standard protocol numbers\n-        # Note: strictly speaking, standard port numbers should only be\n-        # stripped when comparing origins\n-        if parsed.port:\n-            if (parsed.scheme, parsed.port) in (('http', 80), ('https', 443)):\n-                netloc = netloc.replace(':{p.port}'.format(p=parsed), '')\n-\n-        return urlunparse((\n-            parsed.scheme,\n-            netloc,\n-            '/' if origin_only else parsed.path,\n-            '' if origin_only else parsed.params,\n-            '' if origin_only else parsed.query,\n-            ''))\n-\n-    def origin(self, url):\n-        return self.strip_url(url, origin_only=True)\n-\n-    def origin_parsed(self, req_or_resp):\n+    def origin(self, req_or_resp):\n         \"\"\"Return (scheme, host, path) tuple for a request or response URL.\"\"\"\n-        return tuple(self.strip_url_parsed(req_or_resp, origin_only=True)[:3])\n+        return tuple(self.strip_url(req_or_resp, origin_only=True)[:3])\n \n \n class NoReferrerPolicy(ReferrerPolicy):\n@@ -157,7 +113,7 @@ class NoReferrerWhenDowngradePolicy(ReferrerPolicy):\n         if urlparse_cached(response).scheme in ('https', 'ftps') and \\\n             urlparse_cached(request).scheme in ('http',):\n                 return None\n-        stripped = self.strip_url_parsed(response)\n+        stripped = self.strip_url(response)\n         if stripped is not None:\n             return urlunparse(stripped)\n \n@@ -175,8 +131,8 @@ class SameOriginPolicy(ReferrerPolicy):\n     name = POLICY_SAME_ORIGIN\n \n     def referrer(self, response, request):\n-        if self.origin_parsed(response) == self.origin_parsed(request):\n-            stripped = self.strip_url_parsed(response)\n+        if self.origin(response) == self.origin(request):\n+            stripped = self.strip_url(response)\n             if stripped is not None:\n                 return urlunparse(stripped)\n \n@@ -193,7 +149,7 @@ class OriginPolicy(ReferrerPolicy):\n     name = POLICY_ORIGIN\n \n     def referrer(self, response, request):\n-        origin = self.strip_url_parsed(response, origin_only=True)\n+        origin = self.strip_url(response, origin_only=True)\n         if origin is not None:\n             return urlunparse(origin)\n \n@@ -212,9 +168,9 @@ class OriginWhenCrossOriginPolicy(ReferrerPolicy):\n     name = POLICY_ORIGIN_WHEN_CROSS_ORIGIN\n \n     def referrer(self, response, request):\n-        origin = self.origin_parsed(response)\n-        if origin == self.origin_parsed(request):\n-            stripped = self.strip_url_parsed(response)\n+        origin = self.origin(response)\n+        if origin == self.origin(request):\n+            stripped = self.strip_url(response)\n             if stripped is not None:\n                 return urlunparse(stripped)\n         else:\n@@ -237,8 +193,9 @@ class UnsafeUrlPolicy(ReferrerPolicy):\n     name = POLICY_UNSAFE_URL\n \n     def referrer(self, response, request):\n-        referrer_source = response.url\n-        return self.strip_url(referrer_source)\n+        stripped = self.strip_url(response)\n+        if stripped is not None:\n+            return urlunparse(stripped)\n \n \n class LegacyPolicy(ReferrerPolicy):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
