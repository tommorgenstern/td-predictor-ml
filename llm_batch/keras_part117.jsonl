{"custom_id": "keras#de66211afbc994a0687fb387ab0ba68c20f34be0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 116 | Contributors (this commit): 7 | Commits (past 90d): 8 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -23,7 +23,12 @@ _keras_dir = os.path.join(_keras_base_dir, '.keras')\n if not os.path.exists(_keras_dir):\n     os.makedirs(_keras_dir)\n \n+# Set theano as default backend for Windows users since tensorflow is not available for Windows yet.\n+if os.name == 'nt':\n+    _BACKEND = 'theano'\n+else:\n     _BACKEND = 'tensorflow'\n+\n _config_path = os.path.expanduser(os.path.join(_keras_dir, 'keras.json'))\n if os.path.exists(_config_path):\n     _config = json.load(open(_config_path))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cfc9b4d41d4a1701120a5d81df08a9a6f088d856", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 86 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 10/7 | Churn Δ: 86 | Churn Cumulative: 2168 | Contributors (this commit): 26 | Commits (past 90d): 11 | Contributors (cumulative): 30 | DMM Complexity: 0.6190476190476191\n\nDIFF:\n@@ -532,3 +532,58 @@ class TensorBoard(Callback):\n             summary_value.tag = name\n             self.writer.add_summary(summary, epoch)\n         self.writer.flush()\n+\n+\n+class LambdaCallback(Callback):\n+    \"\"\"Callback for creating simple, custom callbacks on-the-fly.\n+\n+    This callback is constructed with anonymous functions that will be called\n+    at the appropiate time. Note that the callbacks expects positional\n+    arguments, as:\n+     - `on_epoch_begin` and `on_epoch_end` expect two positional arguments: `epoch`, `logs`\n+     - `on_batch_begin` and `on_batch_end` expect two positional arguments: `batch`, `logs`\n+     - `on_train_begin` and `on_train_end` expect one positional argument: `logs`\n+\n+    # Arguments\n+        on_epoch_begin: called at the beginning of every epoch.\n+        on_epoch_end: called at the end of every epoch.\n+        on_batch_begin: called at the beginning of every batch.\n+        on_batch_end: called at the end of every batch.\n+        on_train_begin: called at the beginning of model training.\n+        on_train_end: called at the end of model training.\n+\n+    # Example\n+        ```python\n+        # Print the batch number at the beginning of every batch.\n+        batch_print_callback = LambdaCallback(on_batch_begin=lambda batch, logs: print(batch))\n+\n+        # Plot the loss after every epoch.\n+        import numpy as np\n+        import matplotlib.pyplot as plt\n+        plot_loss_callback = LambdaCallback(on_epoch_end=lambda epoch, logs: plt.plot(np.arange(epoch), logs['loss']))\n+\n+        # Terminate some processes after having finished model training.\n+        processes = ...\n+        cleanup_callback = LambdaCallback(on_train_end=lambda logs: [p.terminate() for p in processes if p.is_alive()])\n+\n+        model.fit(..., callbacks=[batch_print_callback, plot_loss_callback, cleanup_callback])\n+        ```\n+\n+    \"\"\"\n+\n+    def __init__(self,\n+                 on_epoch_begin=None,\n+                 on_epoch_end=None,\n+                 on_batch_begin=None,\n+                 on_batch_end=None,\n+                 on_train_begin=None,\n+                 on_train_end=None,\n+                 **kwargs):\n+        super(Callback, self).__init__()\n+        self.__dict__.update(kwargs)\n+        self.on_epoch_begin = on_epoch_begin if on_epoch_begin else lambda epoch, logs: None\n+        self.on_epoch_end = on_epoch_end if on_epoch_end else lambda epoch, logs: None\n+        self.on_batch_begin = on_batch_begin if on_batch_begin else lambda batch, logs: None\n+        self.on_batch_end = on_batch_end if on_batch_end else lambda batch, logs: None\n+        self.on_train_begin = on_train_begin if on_train_begin else lambda logs: None\n+        self.on_train_end = on_train_end if on_train_end else lambda logs: None\n\n@@ -1,6 +1,7 @@\n import pytest\n import os\n import sys\n+import multiprocessing\n import numpy as np\n np.random.seed(1337)\n \n@@ -272,5 +273,35 @@ def test_TensorBoard():\n \n     KTF.set_session(old_session)\n     \n+def test_LambdaCallback():\n+    (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=train_samples,\n+                                                         nb_test=test_samples,\n+                                                         input_shape=(input_dim,),\n+                                                         classification=True,\n+                                                         nb_class=nb_class)\n+    y_test = np_utils.to_categorical(y_test)\n+    y_train = np_utils.to_categorical(y_train)\n+    model = Sequential()\n+    model.add(Dense(nb_hidden, input_dim=input_dim, activation='relu'))\n+    model.add(Dense(nb_class, activation='softmax'))\n+    model.compile(loss='categorical_crossentropy',\n+                  optimizer='sgd',\n+                  metrics=['accuracy'])\n+    \n+    # Start an arbitrary process that should run during model training and be terminated after training has completed.\n+    def f():\n+        while True:\n+            pass\n+    p = multiprocessing.Process(target=f)\n+    p.start()\n+    cleanup_callback = callbacks.LambdaCallback(on_train_end=lambda logs: p.terminate())\n+    \n+    cbks = [cleanup_callback]\n+    model.fit(X_train, y_train, batch_size=batch_size,\n+              validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=5)\n+    p.join()\n+    assert not p.is_alive()\n+    \n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f0d9867d09be9aad4d42aba9d2ec5a9a020037f7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 52 | Lines Deleted: 5 | Files Changed: 6 | Hunks: 7 | Methods Changed: 8 | Complexity Δ (Sum/Max): 6/2 | Churn Δ: 57 | Churn Cumulative: 7508 | Contributors (this commit): 60 | Commits (past 90d): 102 | Contributors (cumulative): 117 | DMM Complexity: 1.0\n\nDIFF:\n@@ -15,6 +15,9 @@ def softmax(x):\n                         'Here, ndim=' + str(ndim))\n \n \n+def elu(x, alpha=1.0):\n+    return K.elu(x, alpha)\n+\n def softplus(x):\n     return K.softplus(x)\n \n\n@@ -1348,6 +1348,19 @@ def relu(x, alpha=0., max_value=None):\n     return x\n \n \n+def elu(x, alpha=1.):\n+    \"\"\" Exponential linear unit\n+\n+    # Arguments\n+        x: Tensor to compute the activation function for.\n+        alpha: scalar\n+    \"\"\"\n+    res = tf.nn.elu(x)\n+    if alpha == 1:\n+        return res\n+    else:\n+        return tf.select(x > 0, res, alpha*res)\n+\n def softmax(x):\n     '''Softmax of a tensor.\n     '''\n\n@@ -931,11 +931,26 @@ def in_test_phase(x, alt):\n \n # NN OPERATIONS\n \n-def relu(x, alpha=0., max_value=None):\n-    assert hasattr(T.nnet, 'relu'), ('It looks like like your version of '\n+def _assert_has_capability(module, func):\n+    assert hasattr(module, func), ('It looks like like your version of '\n                                    'Theano is out of date. '\n                                    'Install the latest version with:\\n'\n                                    'pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps')\n+\n+\n+def elu(x, alpha=1.0):\n+    \"\"\" Exponential linear unit\n+\n+    # Arguments\n+        x: Tensor to compute the activation function for.\n+        alpha: scalar\n+    \"\"\"\n+    _assert_has_capability(T.nnet, 'elu')\n+    return T.nnet.elu(x, alpha)\n+\n+\n+def relu(x, alpha=0., max_value=None):\n+    _assert_has_capability(T.nnet, 'relu')\n     x = T.nnet.relu(x, alpha)\n     if max_value is not None:\n         x = T.minimum(x, max_value)\n\n@@ -107,9 +107,7 @@ class ELU(Layer):\n         super(ELU, self).__init__(**kwargs)\n \n     def call(self, x, mask=None):\n-        pos = K.relu(x)\n-        neg = (x - abs(x)) * 0.5\n-        return pos + self.alpha * (K.exp(neg) - 1.)\n+        return K.elu(x, self.alpha)\n \n     def get_config(self):\n         config = {'alpha': float(self.alpha)}\n\n@@ -492,6 +492,7 @@ class TestBackend(object):\n         check_single_tensor_operation('relu', (4, 2), alpha=0.1, max_value=0.5)\n         check_single_tensor_operation('softmax', (4, 10))\n         check_single_tensor_operation('softplus', (4, 10))\n+        check_single_tensor_operation('elu', (4, 10), alpha=0.5)\n \n         check_single_tensor_operation('sigmoid', (4, 2))\n         check_single_tensor_operation('hard_sigmoid', (4, 2))\n\n@@ -131,6 +131,23 @@ def test_relu():\n     assert_allclose(result, test_values, rtol=1e-05)\n \n \n+def test_elu():\n+    x = K.placeholder(ndim=2)\n+    f = K.function([x], [activations.elu(x, 0.5)])\n+\n+    test_values = get_standard_values()\n+    result = f([test_values])[0]\n+\n+    # because no negatives in test values\n+    assert_allclose(result, test_values, rtol=1e-05)\n+\n+    negative_values = np.array([[-1, -2]], dtype=K.floatx())\n+    result = f([negative_values])[0]\n+    true_result = (np.exp(negative_values) - 1) / 2\n+\n+    assert_allclose(result, true_result)\n+\n+\n def test_tanh():\n     test_values = get_standard_values()\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#56aa9f364ae0f56c08f145b55bd1068a30e750d4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 5904 | Contributors (this commit): 27 | Commits (past 90d): 28 | Contributors (cumulative): 32 | DMM Complexity: None\n\nDIFF:\n@@ -158,6 +158,9 @@ PAGES = [\n             convolutional.SeparableConvolution2D,\n             convolutional.Deconvolution2D,\n             convolutional.Convolution3D,\n+            convolutional.Cropping1D,\n+            convolutional.Cropping2D,\n+            convolutional.Cropping3D,\n             convolutional.UpSampling1D,\n             convolutional.UpSampling2D,\n             convolutional.UpSampling3D,\n\n@@ -1674,7 +1674,7 @@ class Cropping2D(Layer):\n         return dict(list(base_config.items()) + list(config.items()))\n \n class Cropping3D(Layer):\n-    '''Cropping layer for 2D input (e.g. picture).\n+    '''Cropping layer for 3D data (e.g. spatial or saptio-temporal).\n \n     # Arguments\n         cropping: tuple of tuple of int (length 3)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4c01c0c4d77348416fff70e00ed6c25955c33ef6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 199 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 9 | Methods Changed: 10 | Complexity Δ (Sum/Max): 29/27 | Churn Δ: 201 | Churn Cumulative: 2369 | Contributors (this commit): 27 | Commits (past 90d): 13 | Contributors (cumulative): 32 | DMM Complexity: 0.7931034482758621\n\nDIFF:\n@@ -1,12 +1,14 @@\n from __future__ import absolute_import\n from __future__ import print_function\n \n+import csv\n+\n import numpy as np\n import time\n import json\n import warnings\n \n-from collections import deque\n+from collections import deque, OrderedDict, Iterable\n from .utils.generic_utils import Progbar\n from keras import backend as K\n from pkg_resources import parse_version\n@@ -534,6 +536,161 @@ class TensorBoard(Callback):\n         self.writer.flush()\n \n \n+class ReduceLROnPlateau(Callback):\n+    '''Reduce learning rate when a metric has stopped improving.\n+\n+    Models often benefit from reducing the learning rate by a factor\n+    of 2-10 once learning stagnates. This callback monitors a\n+    quantity and if no improvement is seen for a 'patience' number\n+    of epochs, the learning rate is reduced.\n+\n+    # Example\n+        ```python\n+            reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n+                                          patience=5, min_lr=0.001)\n+            model.fit(X_train, Y_train, callbacks=[reduce_lr])\n+        ```\n+\n+    # Arguments\n+        monitor: quantity to be monitored.\n+        factor: factor by which the learning rate will\n+            be reduced. new_lr = lr * factor\n+        patience: number of epochs with no improvement\n+            after which learning rate will be reduced.\n+        verbose: int. 0: quiet, 1: update messages.\n+        mode: one of {auto, min, max}. In `min` mode,\n+            lr will be reduced when the quantity\n+            monitored has stopped decreasing; in `max`\n+            mode it will be reduced when the quantity\n+            monitored has stopped increasing; in `auto`\n+            mode, the direction is automatically inferred\n+            from the name of the monitored quantity.\n+        epsilon: threshold for measuring the new optimum,\n+            to only focus on significant changes.\n+        cooldown: number of epochs to wait before resuming\n+            normal operation after lr has been reduced.\n+        min_lr: lower bound on the learning rate.\n+    '''\n+\n+    def __init__(self, monitor='val_loss', factor=0.1, patience=10,\n+                 verbose=0, mode='auto', epsilon=1e-4, cooldown=0, min_lr=0):\n+        super(Callback, self).__init__()\n+\n+        self.monitor = monitor\n+        if factor >= 1.0:\n+            raise ValueError('ReduceLROnPlateau does not support a factor >= 1.0.')\n+        self.factor = factor\n+        self.min_lr = min_lr\n+        self.epsilon = epsilon\n+        self.patience = patience\n+        self.verbose = verbose\n+        self.cooldown = cooldown\n+        self.cooldown_counter = 0  # Cooldown counter.\n+        self.wait = 0\n+        self.best = 0\n+        self.mode = mode\n+        self.monitor_op = None\n+        self.reset()\n+\n+    def reset(self):\n+        if self.mode not in ['auto', 'min', 'max']:\n+            warnings.warn('Learning Rate Plateau Reducing mode %s is unknown, '\n+                          'fallback to auto mode.' % (self.mode), RuntimeWarning)\n+            self.mode = 'auto'\n+        if self.mode == 'min' or (self.mode == 'auto' and 'acc' not in self.monitor):\n+            self.monitor_op = lambda a, b: np.less(a, b - self.epsilon)\n+            self.best = np.Inf\n+        else:\n+            self.monitor_op = lambda a, b: np.greater(a, b + self.epsilon)\n+            self.best = -np.Inf\n+        self.cooldown_counter = 0\n+        self.wait = 0\n+        self.lr_epsilon = self.min_lr * 1e-4\n+\n+    def on_train_begin(self, logs={}):\n+        self.reset()\n+\n+    def on_epoch_end(self, epoch, logs={}):\n+        logs['lr'] = K.get_value(self.model.optimizer.lr)\n+        current = logs.get(self.monitor)\n+        if current is None:\n+            warnings.warn('Learning Rate Plateau Reducing requires %s available!' %\n+                          self.monitor, RuntimeWarning)\n+        else:\n+            if self.cooldown_counter > 0:\n+                self.cooldown_counter -= 1\n+                self.wait = 0\n+\n+            if self.monitor_op(current, self.best):\n+                self.best = current\n+                self.wait = 0\n+            elif self.cooldown_counter <= 0:\n+                if self.wait >= self.patience:\n+                    old_lr = float(K.get_value(self.model.optimizer.lr))\n+                    if old_lr > self.min_lr + self.lr_epsilon:\n+                        new_lr = old_lr * self.factor\n+                        new_lr = max(new_lr, self.min_lr)\n+                        K.set_value(self.model.optimizer.lr, new_lr)\n+                        if self.verbose > 0:\n+                            print('\\nEpoch %05d: reducing learning rate to %s.' % (epoch, new_lr))\n+                        self.cooldown_counter = self.cooldown\n+                self.wait += 1\n+\n+\n+class CSVLogger(Callback):\n+    '''Callback that streams epoch results to a csv file.\n+    Supports all values that can be represented as a string,\n+    including 1D iterables such as np.ndarray.\n+\n+    # Example\n+        ```python\n+            csv_logger = CSVLogger('training.log')\n+            model.fit(X_train, Y_train, callbacks=[csv_logger])\n+        ```\n+\n+    Arguments\n+        filename: filename of the csv file, e.g. 'run/log.csv'.\n+        separator: string used to separate elements in the csv file.\n+        append: True: append if file exists (useful for continuing\n+            training). False: overwrite existing file,\n+    '''\n+\n+    def __init__(self, filename, separator=',', append=False):\n+        self.sep = separator\n+        self.filename = filename\n+        self.append = append\n+        self.writer = None\n+        self.keys = None\n+        super(CSVLogger, self).__init__()\n+\n+    def on_train_begin(self, logs={}):\n+        if self.append:\n+            self.csv_file = open(self.filename, 'a')\n+        else:\n+            self.csv_file = open(self.filename, 'w')\n+\n+    def on_epoch_end(self, epoch, logs={}):\n+        def handle_value(k):\n+            is_zero_dim_ndarray = isinstance(k, np.ndarray) and k.ndim == 0\n+            if isinstance(k, Iterable) and not is_zero_dim_ndarray:\n+                return '\"[%s]\"' % (', '.join(map(lambda x: str(x), k)))\n+            else:\n+                return k\n+\n+        if not self.writer:\n+            self.keys = sorted(logs.keys())\n+            self.writer = csv.DictWriter(self.csv_file, fieldnames=['epoch'] + self.keys)\n+            self.writer.writeheader()\n+\n+        row_dict = OrderedDict({'epoch': epoch})\n+        row_dict.update((key, handle_value(logs[key])) for key in self.keys)\n+        self.writer.writerow(row_dict)\n+        self.csv_file.flush()\n+\n+    def on_train_end(self, logs={}):\n+        self.csv_file.close()\n+\n+\n class LambdaCallback(Callback):\n     \"\"\"Callback for creating simple, custom callbacks on-the-fly.\n \n\n@@ -1,8 +1,11 @@\n-import pytest\n import os\n import sys\n import multiprocessing\n+\n import numpy as np\n+import pytest\n+from keras import optimizers\n+\n np.random.seed(1337)\n \n from keras import callbacks\n@@ -148,6 +151,41 @@ def test_LearningRateScheduler():\n     assert (float(K.get_value(model.optimizer.lr)) - 0.2) < K.epsilon()\n \n \n+def test_ReduceLROnPlateau():\n+    (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=train_samples,\n+                                                         nb_test=test_samples,\n+                                                         input_shape=(input_dim,),\n+                                                         classification=True,\n+                                                         nb_class=nb_class)\n+    y_test = np_utils.to_categorical(y_test)\n+    y_train = np_utils.to_categorical(y_train)\n+\n+    def make_model():\n+        np.random.seed(1337)\n+        model = Sequential()\n+        model.add(Dense(nb_hidden, input_dim=input_dim, activation='relu'))\n+        model.add(Dense(nb_class, activation='softmax'))\n+\n+        model.compile(loss='categorical_crossentropy',\n+                      optimizer=optimizers.SGD(lr=0.1),\n+                      metrics=['accuracy'])\n+        return model\n+\n+    model = make_model()\n+\n+    # This should reduce the LR after the first epoch (due to high epsilon).\n+    cbks = [callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, epsilon=10, patience=1, cooldown=5)]\n+    model.fit(X_train, y_train, batch_size=batch_size,\n+              validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=5, verbose=2)\n+    assert np.allclose(float(K.get_value(model.optimizer.lr)), 0.01, atol=K.epsilon())\n+\n+    model = make_model()\n+    cbks = [callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, epsilon=0, patience=1, cooldown=5)]\n+    model.fit(X_train, y_train, batch_size=batch_size,\n+              validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=5, verbose=2)\n+    assert np.allclose(float(K.get_value(model.optimizer.lr)), 0.1, atol=K.epsilon())\n+\n+\n @pytest.mark.skipif((K._BACKEND != 'tensorflow'),\n                     reason=\"Requires tensorflow backend\")\n def test_TensorBoard():\n@@ -273,6 +311,7 @@ def test_TensorBoard():\n \n     KTF.set_session(old_session)\n \n+\n def test_LambdaCallback():\n     (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=train_samples,\n                                                          nb_test=test_samples,\n@@ -292,6 +331,7 @@ def test_LambdaCallback():\n     def f():\n         while True:\n             pass\n+\n     p = multiprocessing.Process(target=f)\n     p.start()\n     cleanup_callback = callbacks.LambdaCallback(on_train_end=lambda logs: p.terminate())\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d5f1250a8b76a09ddeebcbe2dfb83a4faa5b8a3e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 15 | Churn Cumulative: 58 | Contributors (this commit): 1 | Commits (past 90d): 2 | Contributors (cumulative): 1 | DMM Complexity: 0.0\n\nDIFF:\n@@ -28,16 +28,21 @@ def preprocess_input(x, dim_ordering='default'):\n     return x\n \n \n-def decode_predictions(preds):\n+def decode_predictions(preds, top=5):\n     global CLASS_INDEX\n-    assert len(preds.shape) == 2 and preds.shape[1] == 1000\n+    if len(preds.shape) != 2 or preds.shape[1] != 1000:\n+        raise ValueError('`decode_predictions` expects '\n+                         'a batch of predictions '\n+                         '(i.e. a 2D array of shape (samples, 1000)). '\n+                         'Found array with shape: ' + str(preds.shape))\n     if CLASS_INDEX is None:\n         fpath = get_file('imagenet_class_index.json',\n                          CLASS_INDEX_PATH,\n                          cache_subdir='models')\n         CLASS_INDEX = json.load(open(fpath))\n-    indices = np.argmax(preds, axis=-1)\n     results = []\n-    for i in indices:\n-        results.append(CLASS_INDEX[str(i)])\n+    for pred in preds:\n+        top_indices = np.argpartition(pred, -top)[-top:][::-1]\n+        result = [tuple(CLASS_INDEX[str(i)]) + (pred[i],) for i in top_indices]\n+        results.append(result)\n     return results\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#43060d8c7d76a11f9807e0dc918228fccc5a5701", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 236 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 4 | Complexity Δ (Sum/Max): 22/11 | Churn Δ: 236 | Churn Cumulative: 236 | Contributors (this commit): 1 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: 0.13157894736842105\n\nDIFF:\n@@ -0,0 +1,82 @@\n+import numpy as np\n+from .. import backend as K\n+\n+if librosa_exists():\n+    import librosa\n+else:\n+    raise RuntimeError('librosa is required to process audio files\\n' +\n+                       'In short, $ pip install librosa\\nor visit ' +\n+                       'http://librosa.github.io/librosa/ for details.')\n+\n+TAGS = ['rock', 'pop', 'alternative', 'indie', 'electronic',\n+        'female vocalists', 'dance', '00s', 'alternative rock', 'jazz',\n+        'beautiful', 'metal', 'chillout', 'male vocalists',\n+        'classic rock', 'soul', 'indie rock', 'Mellow', 'electronica',\n+        '80s', 'folk', '90s', 'chill', 'instrumental', 'punk',\n+        'oldies', 'blues', 'hard rock', 'ambient', 'acoustic',\n+        'experimental', 'female vocalist', 'guitar', 'Hip-Hop',\n+        '70s', 'party', 'country', 'easy listening',\n+        'sexy', 'catchy', 'funk', 'electro', 'heavy metal',\n+        'Progressive rock', '60s', 'rnb', 'indie pop',\n+        'sad', 'House', 'happy']\n+\n+\n+def librosa_exists():\n+    try:\n+        __import__('librosa')\n+    except ImportError:\n+        return False\n+    else:\n+        return True\n+\n+\n+def preprocess_input(audio_path, dim_ordering='default'):\n+    if dim_ordering == 'default':\n+        dim_ordering = K.image_dim_ordering()\n+    assert dim_ordering in {'tf', 'th'}\n+\n+    # mel-spectrogram parameters\n+    SR = 12000\n+    N_FFT = 512\n+    N_MELS = 96\n+    HOP_LEN = 256\n+    DURA = 29.12\n+\n+    src, sr = librosa.load(audio_path, sr=SR)\n+    n_sample = src.shape[0]\n+    n_sample_wanted = int(DURA * SR)\n+\n+    # trim the signal at the center\n+    if n_sample < n_sample_wanted:  # if too short\n+        src = np.hstack((src, np.zeros((int(DURA * SR) - n_sample,))))\n+    elif n_sample > n_sample_wanted:  # if too long\n+        src = src[(n_sample - n_sample_wanted) / 2:\n+                  (n_sample + n_sample_wanted) / 2]\n+\n+    logam = librosa.logamplitude\n+    melgram = librosa.feature.melspectrogram\n+    x = logam(melgram(y=src, sr=SR, hop_length=HOP_LEN,\n+                      n_fft=N_FFT, n_mels=N_MELS) ** 2,\n+              ref_power=1.0)\n+\n+    if dim_ordering == 'th':\n+        x = x[np.newaxis, :]\n+    elif dim_ordering == 'tf':\n+        x = x[:, np.newaxis]\n+    return x\n+\n+\n+def decode_predictions(preds, top_n=5):\n+    '''\n+    # Arguments\n+        preds: 2-dimensional numpy array\n+        top_n: integer in [0, 50], number of items to show\n+\n+    '''\n+    assert len(preds.shape) == 2 and preds.shape[1] == 50\n+    results = []\n+    for pred in preds:\n+        result = zip(TAGS, pred)\n+        result = sorted(result, key=lambda x: x[1], reverse=True)\n+        results.append(result[:top_n])\n+    return results\n\n@@ -0,0 +1,154 @@\n+# -*- coding: utf-8 -*-\n+'''MusicTaggerCRNN model for Keras.\n+\n+# Reference:\n+\n+- [Music-auto_tagging-keras](https://github.com/keunwoochoi/music-auto_tagging-keras)\n+\n+'''\n+from __future__ import print_function\n+from __future__ import absolute_import\n+\n+from .. import backend as K\n+from ..layers import Input, Dense\n+from ..models import Model\n+from ..layers import Dense, Dropout, Reshape, Permute\n+from ..layers.convolutional import Convolution2D\n+from ..layers.convolutional import MaxPooling2D, ZeroPadding2D\n+from ..layers.normalization import BatchNormalization\n+from ..layers.advanced_activations import ELU\n+from ..layers.recurrent import GRU\n+from ..utils.data_utils import get_file\n+from .audio_conv_utils import decode_predictions, load_preprocess_input\n+\n+TH_WEIGHTS_PATH = 'https://github.com/keunwoochoi/music-auto_tagging-keras/blob/master/data/music_tagger_crnn_weights_theano.h5'\n+TF_WEIGHTS_PATH = 'https://github.com/keunwoochoi/music-auto_tagging-keras/blob/master/data/music_tagger_crnn_weights_tensorflow.h5'\n+\n+\n+def MusicTaggerCRNN(weights='msd', input_tensor=None,\n+                    include_top=True):\n+    '''Instantiate the MusicTaggerCRNN architecture,\n+    optionally loading weights pre-trained\n+    on Million Song Dataset. Note that when using TensorFlow,\n+    for best performance you should set\n+    `image_dim_ordering=\"tf\"` in your Keras config\n+    at ~/.keras/keras.json.\n+\n+    The model and the weights are compatible with both\n+    TensorFlow and Theano. The dimension ordering\n+    convention used by the model is the one\n+    specified in your Keras config file.\n+\n+    For preparing mel-spectrogram input, see\n+    `audio_conv_utils.py` in [applications](https://github.com/fchollet/keras/tree/master/keras/applications).\n+    You will need to install [Librosa](http://librosa.github.io/librosa/)\n+    to use it.\n+\n+    # Arguments\n+        weights: one of `None` (random initialization)\n+            or \"msd\" (pre-training on ImageNet).\n+        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n+            to use as image input for the model.\n+        include_top: whether to include the 1 fully-connected\n+            layer (output layer) at the top of the network.\n+            If False, the network outputs 32-dim features.\n+\n+\n+    # Returns\n+        A Keras model instance.\n+    '''\n+    if weights not in {'msd', None}:\n+        raise ValueError('The `weights` argument should be either '\n+                         '`None` (random initialization) or `msd` '\n+                         '(pre-training on Million Song Dataset).')\n+\n+    # Determine proper input shape\n+    if K.image_dim_ordering() == 'th':\n+        input_shape = (1, 96, 1366)\n+    else:\n+        input_shape = (96, 1366, 1)\n+\n+    if input_tensor is None:\n+        melgram_input = Input(shape=input_shape)\n+    else:\n+        if not K.is_keras_tensor(input_tensor):\n+            melgram_input = Input(tensor=input_tensor, shape=input_shape)\n+        else:\n+            melgram_input = input_tensor\n+\n+    # Determine input axis\n+    if K.image_dim_ordering() == 'th':\n+        channel_axis = 1\n+        freq_axis = 2\n+        time_axis = 3\n+    else:\n+        channel_axis = 3\n+        freq_axis = 1\n+        time_axis = 2\n+\n+    # Input block\n+    x = ZeroPadding2D(padding=(0, 37))(melgram_input)\n+    x = BatchNormalization(axis=time_axis, name='bn_0_freq')(x)\n+\n+    # Conv block 1\n+    x = Convolution2D(64, 3, 3, border_mode='same', name='conv1')(x)\n+    x = BatchNormalization(axis=channel_axis, mode=0, name='bn1')(x)\n+    x = ELU()(x)\n+    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='pool1')(x)\n+    x = Dropout(0.5, name='dropout1')(x)\n+\n+    # Conv block 2\n+    x = Convolution2D(128, 3, 3, border_mode='same', name='conv2')(x)\n+    x = BatchNormalization(axis=channel_axis, mode=0, name='bn2')(x)\n+    x = ELU()(x)\n+    x = MaxPooling2D(pool_size=(3, 3), strides=(3, 3), name='pool2')(x)\n+    x = Dropout(0.5, name='dropout2')(x)\n+\n+    # Conv block 3\n+    x = Convolution2D(128, 3, 3, border_mode='same', name='conv3')(x)\n+    x = BatchNormalization(axis=channel_axis, mode=0, name='bn3')(x)\n+    x = ELU()(x)\n+    x = MaxPooling2D(pool_size=(4, 4), strides=(4, 4), name='pool3')(x)\n+    x = Dropout(0.5, name='dropout3')(x)\n+\n+    # Conv block 4\n+    x = Convolution2D(128, 3, 3, border_mode='same', name='conv4')(x)\n+    x = BatchNormalization(axis=channel_axis, mode=0, name='bn4')(x)\n+    x = ELU()(x)\n+    x = MaxPooling2D(pool_size=(4, 4), strides=(4, 4), name='pool4')(x)\n+    x = Dropout(0.5, name='dropout4')(x)\n+\n+    # reshaping\n+    if K.image_dim_ordering() == 'th':\n+        x = Permute((3, 1, 2))(x)\n+    x = Reshape((15, 128))(x)\n+\n+    # GRU block 1, 2, output\n+    x = GRU(32, return_sequences=True, name='gru1')(x)\n+    x = GRU(32, return_sequences=False, name='gru2')(x)\n+    x = Dropout(0.3)(x)\n+\n+    if include_top:\n+        x = Dense(50, activation='sigmoid', name='output')(x)\n+\n+    # Create model\n+    model = Model(melgram_input, x)\n+    if weights is None:\n+        return model\n+    else:\n+        # Load weights\n+        if K.image_dim_ordering == 'tf':\n+            raise RuntimeError(\"Please set image_dim_ordering == 'th'.\"\n+                               \"You can set it at ~/.keras/keras.json\")\n+\n+        if K._BACKEND == 'theano':\n+            weights_path = get_file('music_tagger_crnn_weights_theano.h5',\n+                                    TH_WEIGHTS_PATH,\n+                                    cache_subdir='models')\n+        else:\n+            weights_path = get_file('music_tagger_crnn_weights_tensorflow.h5',\n+                                    TF_WEIGHTS_PATH,\n+                                    cache_subdir='models')\n+\n+        model.load_weights(weights_path, by_name=True)\n+        return model\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ed131973ef5748915ab3a03c9f60c9051d34881c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 10 | Files Changed: 2 | Hunks: 5 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 21 | Churn Cumulative: 257 | Contributors (this commit): 2 | Commits (past 90d): 4 | Contributors (cumulative): 4 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1,12 +1,6 @@\n import numpy as np\n from .. import backend as K\n \n-if librosa_exists():\n-    import librosa\n-else:\n-    raise RuntimeError('librosa is required to process audio files\\n' +\n-                       'In short, $ pip install librosa\\nor visit ' +\n-                       'http://librosa.github.io/librosa/ for details.')\n \n TAGS = ['rock', 'pop', 'alternative', 'indie', 'electronic',\n         'female vocalists', 'dance', '00s', 'alternative rock', 'jazz',\n@@ -35,6 +29,13 @@ def preprocess_input(audio_path, dim_ordering='default'):\n         dim_ordering = K.image_dim_ordering()\n     assert dim_ordering in {'tf', 'th'}\n \n+    if librosa_exists():\n+        import librosa\n+    else:\n+        raise RuntimeError('librosa is required to process audio files\\n' +\n+                           'In short, $ pip install librosa\\nor visit ' +\n+                           'http://librosa.github.io/librosa/ for details.')\n+\n     # mel-spectrogram parameters\n     SR = 12000\n     N_FFT = 512\n\n@@ -19,10 +19,10 @@ from ..layers.normalization import BatchNormalization\n from ..layers.advanced_activations import ELU\n from ..layers.recurrent import GRU\n from ..utils.data_utils import get_file\n-from .audio_conv_utils import decode_predictions, load_preprocess_input\n+from .audio_conv_utils import decode_predictions, preprocess_input\n \n-TH_WEIGHTS_PATH = 'https://github.com/keunwoochoi/music-auto_tagging-keras/blob/master/data/music_tagger_crnn_weights_theano.h5'\n-TF_WEIGHTS_PATH = 'https://github.com/keunwoochoi/music-auto_tagging-keras/blob/master/data/music_tagger_crnn_weights_tensorflow.h5'\n+TH_WEIGHTS_PATH = 'https://github.com/keunwoochoi/music-auto_tagging-keras/raw/master/data/music_tagger_crnn_weights_theano.h5'\n+TF_WEIGHTS_PATH = 'https://github.com/keunwoochoi/music-auto_tagging-keras/raw/master/data/music_tagger_crnn_weights_tensorflow.h5'\n \n \n def MusicTaggerCRNN(weights='msd', input_tensor=None,\n@@ -137,7 +137,7 @@ def MusicTaggerCRNN(weights='msd', input_tensor=None,\n         return model\n     else:\n         # Load weights\n-        if K.image_dim_ordering == 'tf':\n+        if K.image_dim_ordering() == 'tf':\n             raise RuntimeError(\"Please set image_dim_ordering == 'th'.\"\n                                \"You can set it at ~/.keras/keras.json\")\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fb6a2941b90494c18fdb995e11315c15b5b7738e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 166 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -138,8 +138,8 @@ def MusicTaggerCRNN(weights='msd', input_tensor=None,\n     else:\n         # Load weights\n         if K.image_dim_ordering() == 'tf':\n-            raise RuntimeError(\"Please set image_dim_ordering == 'th'.\"\n-                               \"You can set it at ~/.keras/keras.json\")\n+            raise RuntimeError('Please set `image_dim_ordering` to \"th\".'\n+                               'You can set it at `~/.keras/keras.json`.')\n \n         if K._BACKEND == 'theano':\n             weights_path = get_file('music_tagger_crnn_weights_theano.h5',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#25dbe8097fba9a6a429e19d0625d78c3b8731527", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1506 | Contributors (this commit): 16 | Commits (past 90d): 8 | Contributors (cumulative): 16 | DMM Complexity: None\n\nDIFF:\n@@ -301,7 +301,7 @@ class Adadelta(Optimizer):\n     # References\n         - [Adadelta - an adaptive learning rate method](http://arxiv.org/abs/1212.5701)\n     '''\n-    def __init__(self, lr=1.0, rho=0.95, epsilon=1e-8, decay=0.,\n+    def __init__(self, lr=0.01, rho=0.95, epsilon=1e-8, decay=0.,\n                  **kwargs):\n         super(Adadelta, self).__init__(**kwargs)\n         self.__dict__.update(locals())\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9045616bdab0b012e6320e824d4d1c83bf2a294b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1508 | Contributors (this commit): 16 | Commits (past 90d): 9 | Contributors (cumulative): 16 | DMM Complexity: None\n\nDIFF:\n@@ -301,7 +301,7 @@ class Adadelta(Optimizer):\n     # References\n         - [Adadelta - an adaptive learning rate method](http://arxiv.org/abs/1212.5701)\n     '''\n-    def __init__(self, lr=0.01, rho=0.95, epsilon=1e-8, decay=0.,\n+    def __init__(self, lr=1.0, rho=0.95, epsilon=1e-8, decay=0.,\n                  **kwargs):\n         super(Adadelta, self).__init__(**kwargs)\n         self.__dict__.update(locals())\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e3a64cc8a74a0fd2f50615e80970df1d6263e7e8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 9 | Churn Cumulative: 430 | Contributors (this commit): 9 | Commits (past 90d): 1 | Contributors (cumulative): 9 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,3 +1,5 @@\n+import os\n+\n try:\n     # pydot-ng is a fork of pydot that is better maintained\n     import pydot_ng as pydot\n@@ -64,4 +66,9 @@ def model_to_dot(model, show_shapes=False, show_layer_names=True):\n \n def plot(model, to_file='model.png', show_shapes=False, show_layer_names=True):\n     dot = model_to_dot(model, show_shapes, show_layer_names)\n-    dot.write_png(to_file)\n+    _, format = os.path.splitext(to_file)\n+    if not format:\n+        format = 'png'\n+    else:\n+        format = format[1:]\n+    dot.write(to_file, format=format)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#458576bbe7114afc4ea7b1af61bcee1f39b32e34", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 1237 | Contributors (this commit): 17 | Commits (past 90d): 6 | Contributors (cumulative): 17 | DMM Complexity: None\n\nDIFF:\n@@ -181,7 +181,7 @@ def load_img(path, grayscale=False, target_size=None):\n \n \n def list_pictures(directory, ext='jpg|jpeg|bmp|png'):\n-    return [os.path.join(directory, f) for f in os.listdir(directory)\n+    return [os.path.join(directory, f) for f in sorted(os.listdir(directory))\n             if os.path.isfile(os.path.join(directory, f)) and re.match('([\\w]+\\.(?:' + ext + '))', f)]\n \n \n@@ -563,7 +563,7 @@ class DirectoryIterator(Iterator):\n \n         for subdir in classes:\n             subpath = os.path.join(directory, subdir)\n-            for fname in os.listdir(subpath):\n+            for fname in sorted(os.listdir(subpath)):\n                 is_valid = False\n                 for extension in white_list_formats:\n                     if fname.lower().endswith('.' + extension):\n@@ -579,7 +579,7 @@ class DirectoryIterator(Iterator):\n         i = 0\n         for subdir in classes:\n             subpath = os.path.join(directory, subdir)\n-            for fname in os.listdir(subpath):\n+            for fname in sorted(os.listdir(subpath)):\n                 is_valid = False\n                 for extension in white_list_formats:\n                     if fname.lower().endswith('.' + extension):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#51c85dd8d637ad76857b914f0378436f807e0437", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 88 | Lines Deleted: 38 | Files Changed: 3 | Hunks: 20 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 126 | Churn Cumulative: 5418 | Contributors (this commit): 30 | Commits (past 90d): 29 | Contributors (cumulative): 35 | DMM Complexity: 0.0\n\nDIFF:\n@@ -16,6 +16,7 @@ original_dim = 784\n latent_dim = 2\n intermediate_dim = 256\n nb_epoch = 50\n+epsilon_std = 0.01\n \n x = Input(batch_shape=(batch_size, original_dim))\n h = Dense(intermediate_dim, activation='relu')(x)\n@@ -25,7 +26,8 @@ z_log_var = Dense(latent_dim)(h)\n \n def sampling(args):\n     z_mean, z_log_var = args\n-    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0.)\n+    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0.,\n+                              std=epsilon_std)\n     return z_mean + K.exp(z_log_var / 2) * epsilon\n \n # note that \"output_shape\" isn't necessary with the TensorFlow backend\n\n@@ -15,11 +15,11 @@ from keras.datasets import mnist\n # input image dimensions\n img_rows, img_cols, img_chns = 28, 28, 1\n # number of convolutional filters to use\n-nb_filters = 32\n+nb_filters = 64\n # convolution kernel size\n nb_conv = 3\n \n-batch_size = 16\n+batch_size = 100\n original_dim = (img_chns, img_rows, img_cols)\n latent_dim = 2\n intermediate_dim = 128\n@@ -28,12 +28,21 @@ nb_epoch = 5\n \n \n x = Input(batch_shape=(batch_size,) + original_dim)\n-c = Convolution2D(nb_filters, nb_conv, nb_conv, border_mode='same', activation='relu')(x)\n-f = Flatten()(c)\n-h = Dense(intermediate_dim, activation='relu')(f)\n+conv_1 = Convolution2D(img_chns, 2, 2, border_mode='same', activation='relu')(x)\n+conv_2 = Convolution2D(nb_filters, 2, 2,\n+                       border_mode='same', activation='relu',\n+                       subsample=(2, 2))(conv_1)\n+conv_3 = Convolution2D(nb_filters, nb_conv, nb_conv,\n+                       border_mode='same', activation='relu',\n+                       subsample=(1, 1))(conv_2)\n+conv_4 = Convolution2D(nb_filters, nb_conv, nb_conv,\n+                       border_mode='same', activation='relu',\n+                       subsample=(1, 1))(conv_3)\n+flat = Flatten()(conv_4)\n+hidden = Dense(intermediate_dim, activation='relu')(flat)\n \n-z_mean = Dense(latent_dim)(h)\n-z_log_var = Dense(latent_dim)(h)\n+z_mean = Dense(latent_dim)(hidden)\n+z_log_var = Dense(latent_dim)(hidden)\n \n \n def sampling(args):\n@@ -47,28 +56,43 @@ def sampling(args):\n z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n \n # we instantiate these layers separately so as to reuse them later\n-decoder_h = Dense(intermediate_dim, activation='relu')\n-decoder_f = Dense(nb_filters*img_rows*img_cols, activation='relu')\n-decoder_c = Reshape((nb_filters, img_rows, img_cols))\n-decoder_mean = Deconvolution2D(img_chns, nb_conv, nb_conv,\n-                               (batch_size, img_chns, img_rows, img_cols),\n-                               border_mode='same')\n-\n-h_decoded = decoder_h(z)\n-f_decoded = decoder_f(h_decoded)\n-c_decoded = decoder_c(f_decoded)\n-x_decoded_mean = decoder_mean(c_decoded)\n+decoder_hid = Dense(intermediate_dim, activation='relu')\n+decoder_upsample = Dense(nb_filters * 14 * 14, activation='relu')\n+decoder_reshape = Reshape((nb_filters, 14, 14))\n+decoder_deconv_1 = Deconvolution2D(nb_filters, nb_conv, nb_conv,\n+                                   (batch_size, nb_filters, 14, 14),\n+                                   border_mode='same',\n+                                   subsample=(1, 1),\n+                                   activation='relu')\n+decoder_deconv_2 = Deconvolution2D(nb_filters, nb_conv, nb_conv,\n+                                   (batch_size, nb_filters, 14, 14),\n+                                   border_mode='same',\n+                                   subsample=(1, 1),\n+                                   activation='relu')\n+decoder_deconv_3_upsamp = Deconvolution2D(nb_filters, 2, 2,\n+                                          (batch_size, nb_filters, 29, 29),\n+                                          border_mode='valid',\n+                                          subsample=(2, 2),\n+                                          activation='relu')\n+decoder_mean_squash = Convolution2D(img_chns, 2, 2, border_mode='valid', activation='sigmoid')\n \n+hid_decoded = decoder_hid(z)\n+up_decoded = decoder_upsample(hid_decoded)\n+reshape_decoded = decoder_reshape(up_decoded)\n+deconv_1_decoded = decoder_deconv_1(reshape_decoded)\n+deconv_2_decoded = decoder_deconv_2(deconv_1_decoded)\n+x_decoded_relu = decoder_deconv_3_upsamp(deconv_2_decoded)\n+x_decoded_mean_squash = decoder_mean_squash(x_decoded_relu)\n \n def vae_loss(x, x_decoded_mean):\n     # NOTE: binary_crossentropy expects a batch_size by dim for x and x_decoded_mean, so we MUST flatten these!\n     x = K.flatten(x)\n     x_decoded_mean = K.flatten(x_decoded_mean)\n-    xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)\n+    xent_loss = img_rows * img_cols * objectives.binary_crossentropy(x, x_decoded_mean)\n     kl_loss = - 0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n     return xent_loss + kl_loss\n \n-vae = Model(x, x_decoded_mean)\n+vae = Model(x, x_decoded_mean_squash)\n vae.compile(optimizer='rmsprop', loss=vae_loss)\n vae.summary()\n \n@@ -78,6 +102,8 @@ vae.summary()\n x_train = x_train.astype('float32')[:, None, :, :] / 255.\n x_test = x_test.astype('float32')[:, None, :, :] / 255.\n \n+print(x_train.shape)\n+\n vae.fit(x_train, x_train,\n         shuffle=True,\n         nb_epoch=nb_epoch,\n@@ -97,11 +123,14 @@ plt.show()\n \n # build a digit generator that can sample from the learned distribution\n decoder_input = Input(shape=(latent_dim,))\n-_h_decoded = decoder_h(decoder_input)\n-_f_decoded = decoder_f(_h_decoded)\n-_c_decoded = decoder_c(_f_decoded)\n-_x_decoded_mean = decoder_mean(_c_decoded)\n-generator = Model(decoder_input, _x_decoded_mean)\n+_hid_decoded = decoder_hid(decoder_input)\n+_up_decoded = decoder_upsample(_hid_decoded)\n+_reshape_decoded = decoder_reshape(_up_decoded)\n+_deconv_1_decoded = decoder_deconv_1(_reshape_decoded)\n+_deconv_2_decoded = decoder_deconv_2(_deconv_1_decoded)\n+_x_decoded_relu = decoder_deconv_3_upsamp(_deconv_2_decoded)\n+_x_decoded_mean_squash = decoder_mean_squash(_x_decoded_relu)\n+generator = Model(decoder_input, _x_decoded_mean_squash)\n \n # display a 2D manifold of the digits\n n = 15  # figure with 15x15 digits\n@@ -114,7 +143,8 @@ grid_y = np.linspace(-15, 15, n)\n for i, yi in enumerate(grid_x):\n     for j, xi in enumerate(grid_y):\n         z_sample = np.array([[xi, yi]])\n-        x_decoded = generator.predict(z_sample)\n+        z_sample = np.tile(z_sample, batch_size).reshape(batch_size, 2)\n+        x_decoded = generator.predict(z_sample, batch_size=batch_size)\n         digit = x_decoded[0].reshape(digit_size, digit_size)\n         figure[i * digit_size: (i + 1) * digit_size,\n                j * digit_size: (j + 1) * digit_size] = digit\n\n@@ -506,19 +506,39 @@ class Deconvolution2D(Convolution2D):\n     (tuple of integers, does not include the sample axis),\n     e.g. `input_shape=(3, 128, 128)` for 128x128 RGB pictures.\n \n+    To pass the correct `output_shape` to this layer,\n+    one could use a test model to predict and observe the actual output shape.\n+\n     # Examples\n \n     ```python\n         # apply a 3x3 transposed convolution with stride 1x1 and 3 output filters on a 12x12 image:\n         model = Sequential()\n         model.add(Deconvolution2D(3, 3, 3, output_shape=(None, 3, 14, 14), border_mode='valid', input_shape=(3, 12, 12)))\n-        # output_shape will be (None, 3, 14, 14)\n+        # Note that you will have to change the output_shape depending on the backend used.\n+\n+        # we can predict with the model and print the shape of the array.\n+        dummy_input = np.ones((32, 3, 12, 12))\n+        # For TensorFlow dummy_input = np.ones((32, 12, 12, 3))\n+        preds = model.predict(dummy_input)\n+        print(preds.shape)\n+        # Theano GPU: (None, 3, 13, 13)\n+        # Theano CPU: (None, 3, 14, 14)\n+        # TensorFlow: (None, 14, 14, 3)\n \n         # apply a 3x3 transposed convolution with stride 2x2 and 3 output filters on a 12x12 image:\n         model = Sequential()\n         model.add(Deconvolution2D(3, 3, 3, output_shape=(None, 3, 25, 25), subsample=(2, 2), border_mode='valid', input_shape=(3, 12, 12)))\n         model.summary()\n-        # output_shape will be (None, 3, 25, 25)\n+\n+        # we can predict with the model and print the shape of the array.\n+        dummy_input = np.ones((32, 3, 12, 12))\n+        # For TensorFlow dummy_input = np.ones((32, 12, 12, 3))\n+        preds = model.predict(dummy_input)\n+        print(preds.shape)\n+        # Theano GPU: (None, 3, 25, 25)\n+        # Theano CPU: (None, 3, 25, 25)\n+        # TensorFlow: (None, 25, 25, 3)\n     ```\n \n     # Arguments\n@@ -536,6 +556,9 @@ class Deconvolution2D(Convolution2D):\n                     p - padding size,\n                     a - user-specified quantity used to distinguish between\n                         the s different possible output sizes.\n+             Because a is not specified explicitly and Theano and Tensorflow\n+             use different values, it is better to use a dummy input and observe\n+             the actual output shape of a layer as specified in the examples.\n         init: name of initialization function for the weights of the layer\n             (see [initializations](../initializations.md)), or alternatively,\n             Theano function to use for weights initialization.\n@@ -610,19 +633,14 @@ class Deconvolution2D(Convolution2D):\n \n     def get_output_shape_for(self, input_shape):\n         if self.dim_ordering == 'th':\n-            rows = input_shape[2]\n-            cols = input_shape[3]\n+            rows = self.output_shape_[2]\n+            cols = self.output_shape_[3]\n         elif self.dim_ordering == 'tf':\n-            rows = input_shape[1]\n-            cols = input_shape[2]\n+            rows = self.output_shape_[1]\n+            cols = self.output_shape_[2]\n         else:\n             raise Exception('Invalid dim_ordering: ' + self.dim_ordering)\n \n-        rows = conv_input_length(rows, self.nb_row,\n-                                 self.border_mode, self.subsample[0])\n-        cols = conv_input_length(cols, self.nb_col,\n-                                 self.border_mode, self.subsample[1])\n-\n         if self.dim_ordering == 'th':\n             return (input_shape[0], self.nb_filter, rows, cols)\n         elif self.dim_ordering == 'tf':\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
