{"custom_id": "keras#0df0177437ce672d654db6d7edfdc653aaf67533", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 25 | Lines Deleted: 17 | Files Changed: 2 | Hunks: 14 | Methods Changed: 6 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 42 | Churn Cumulative: 1780 | Contributors (this commit): 18 | Commits (past 90d): 9 | Contributors (cumulative): 20 | DMM Complexity: None\n\nDIFF:\n@@ -72,13 +72,13 @@ style_weight = 1.\n content_weight = 0.025\n \n # dimensions of the generated picture.\n-img_width = 400\n-img_height = 400\n-assert img_height == img_width, 'Due to the use of the Gram matrix, width and height must match.'\n+img_nrows = 400\n+img_ncols = 400\n+assert img_ncols == img_nrows, 'Due to the use of the Gram matrix, width and height must match.'\n \n # util function to open, resize and format pictures into appropriate tensors\n def preprocess_image(image_path):\n-    img = load_img(image_path, target_size=(img_width, img_height))\n+    img = load_img(image_path, target_size=(img_nrows, img_ncols))\n     img = img_to_array(img)\n     img = np.expand_dims(img, axis=0)\n     img = vgg16.preprocess_input(img)\n@@ -87,10 +87,10 @@ def preprocess_image(image_path):\n # util function to convert a tensor into a valid image\n def deprocess_image(x):\n     if K.image_dim_ordering() == 'th':\n-        x = x.reshape((3, img_width, img_height))\n+        x = x.reshape((3, img_nrows, img_ncols))\n         x = x.transpose((1, 2, 0))\n     else:\n-        x = x.reshape((img_width, img_height, 3))\n+        x = x.reshape((img_nrows, img_ncols, 3))\n     x = x[:, :, ::-1]\n     x[:, :, 0] += 103.939\n     x[:, :, 1] += 116.779\n@@ -104,9 +104,9 @@ style_reference_image = K.variable(preprocess_image(style_reference_image_path))\n \n # this will contain our generated image\n if K.image_dim_ordering() == 'th':\n-    combination_image = K.placeholder((1, 3, img_width, img_height))\n+    combination_image = K.placeholder((1, 3, img_nrows, img_ncols))\n else:\n-    combination_image = K.placeholder((1, img_width, img_height, 3))\n+    combination_image = K.placeholder((1, img_nrows, img_ncols, 3))\n \n # combine the 3 images into a single Keras tensor\n input_tensor = K.concatenate([base_image,\n@@ -143,7 +143,7 @@ def style_loss(style, combination):\n     S = gram_matrix(style)\n     C = gram_matrix(combination)\n     channels = 3\n-    size = img_width * img_height\n+    size = img_nrows * img_ncols\n     return K.sum(K.square(S - C)) / (4. * (channels ** 2) * (size ** 2))\n \n # an auxiliary loss function\n@@ -157,11 +157,11 @@ def content_loss(base, combination):\n def total_variation_loss(x):\n     assert K.ndim(x) == 4\n     if K.image_dim_ordering() == 'th':\n-        a = K.square(x[:, :, :img_width-1, :img_height-1] - x[:, :, 1:, :img_height-1])\n-        b = K.square(x[:, :, :img_width-1, :img_height-1] - x[:, :, :img_width-1, 1:])\n+        a = K.square(x[:, :, :img_nrows-1, :img_ncols-1] - x[:, :, 1:, :img_ncols-1])\n+        b = K.square(x[:, :, :img_nrows-1, :img_ncols-1] - x[:, :, :img_nrows-1, 1:])\n     else:\n-        a = K.square(x[:, :img_width-1, :img_height-1, :] - x[:, 1:, :img_height-1, :])\n-        b = K.square(x[:, :img_width-1, :img_height-1, :] - x[:, :img_width-1, 1:, :])\n+        a = K.square(x[:, :img_nrows-1, :img_ncols-1, :] - x[:, 1:, :img_ncols-1, :])\n+        b = K.square(x[:, :img_nrows-1, :img_ncols-1, :] - x[:, :img_nrows-1, 1:, :])\n     return K.sum(K.pow(a + b, 1.25))\n \n # combine these loss functions into a single scalar\n@@ -196,9 +196,9 @@ f_outputs = K.function([combination_image], outputs)\n \n def eval_loss_and_grads(x):\n     if K.image_dim_ordering() == 'th':\n-        x = x.reshape((1, 3, img_width, img_height))\n+        x = x.reshape((1, 3, img_nrows, img_ncols))\n     else:\n-        x = x.reshape((1, img_width, img_height, 3))\n+        x = x.reshape((1, img_nrows, img_ncols, 3))\n     outs = f_outputs([x])\n     loss_value = outs[0]\n     if len(outs[1:]) == 1:\n@@ -237,9 +237,9 @@ evaluator = Evaluator()\n # run scipy-based optimization (L-BFGS) over the pixels of the generated image\n # so as to minimize the neural style loss\n if K.image_dim_ordering() == 'th':\n-    x = np.random.uniform(0, 255, (1, 3, img_width, img_height)) - 128.\n+    x = np.random.uniform(0, 255, (1, 3, img_nrows, img_ncols)) - 128.\n else:\n-    x = np.random.uniform(0, 255, (1, img_width, img_height, 3)) - 128.\n+    x = np.random.uniform(0, 255, (1, img_nrows, img_ncols, 3)) - 128.\n \n for i in range(10):\n     print('Start of iteration', i)\n\n@@ -161,6 +161,14 @@ def img_to_array(img, dim_ordering='default'):\n \n \n def load_img(path, grayscale=False, target_size=None):\n+    '''Load an image into PIL format.\n+    \n+    # Arguments\n+        path: path to image file\n+        grayscale: boolean\n+        target_size: None (default to original size)\n+            or (img_height, img_width)\n+    '''\n     from PIL import Image\n     img = Image.open(path)\n     if grayscale:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b8fddc862e3c5dc8b00fba7ba63498a3adb5750f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 476 | Contributors (this commit): 6 | Commits (past 90d): 2 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -173,6 +173,7 @@ match = Sequential()\n match.add(Merge([input_encoder_m, question_encoder],\n                 mode='dot',\n                 dot_axes=[2, 2]))\n+match.add(Activation('softmax'))\n # output: (samples, story_maxlen, query_maxlen)\n # embed the input into a single vector with size = story_maxlen:\n input_encoder_c = Sequential()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#607635d2ce421d77eea96dc3eb9c9a592ac312bc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 176 | Lines Deleted: 6 | Files Changed: 2 | Hunks: 12 | Methods Changed: 10 | Complexity Δ (Sum/Max): 19/13 | Churn Δ: 182 | Churn Cumulative: 3648 | Contributors (this commit): 23 | Commits (past 90d): 32 | Contributors (cumulative): 25 | DMM Complexity: 0.6666666666666666\n\nDIFF:\n@@ -2469,14 +2469,30 @@ class Container(Layer):\n                 else:\n                     param_dset[:] = val\n \n-    def load_weights(self, filepath):\n+    def load_weights(self, filepath, by_name=False):\n         '''Load all layer weights from a HDF5 save file.\n+\n+        If `by_name` is False (default) weights are loaded\n+        based on the network's topology, meaning the architecture\n+        should be the same as when the weights were saved.\n+        Note that layers that don't have weights are not taken\n+        into account in the topological ordering, so adding or\n+        removing layers is fine as long as they don't have weights.\n+\n+        If `by_name` is True, weights are loaded into layers\n+        only if they share the same name. This is useful\n+        for fine-tuning or transfer-learning models where\n+        some of the layers have changed.\n         '''\n         import h5py\n         f = h5py.File(filepath, mode='r')\n         if 'layer_names' not in f.attrs and 'model_weights' in f:\n             f = f['model_weights']\n+        if by_name:\n+            self.load_weights_from_hdf5_group_by_name(f)\n+        else:\n             self.load_weights_from_hdf5_group(f)\n+\n         if hasattr(f, 'close'):\n             f.close()\n \n@@ -2552,6 +2568,54 @@ class Container(Layer):\n                 weight_value_tuples += zip(symbolic_weights, weight_values)\n             K.batch_set_value(weight_value_tuples)\n \n+    def load_weights_from_hdf5_group_by_name(self, f):\n+        ''' Name-based weight loading\n+        (instead of topological weight loading).\n+        Layers that have no matching name are skipped.\n+        '''\n+        if hasattr(self, 'flattened_layers'):\n+            # support for legacy Sequential/Merge behavior\n+            flattened_layers = self.flattened_layers\n+        else:\n+            flattened_layers = self.layers\n+\n+        if 'nb_layers' in f.attrs:\n+                raise Exception('The weight file you are trying to load is' +\n+                                ' in a legacy format that does not support' +\n+                                ' name-based weight loading.')\n+        else:\n+            # new file format\n+            layer_names = [n.decode('utf8') for n in f.attrs['layer_names']]\n+\n+            # Reverse index of layer name to list of layers with name.\n+            index = {}\n+            for layer in flattened_layers:\n+                if layer.name:\n+                    index.setdefault(layer.name, []).append(layer)\n+\n+            # we batch weight value assignments in a single backend call\n+            # which provides a speedup in TensorFlow.\n+            weight_value_tuples = []\n+            for k, name in enumerate(layer_names):\n+                g = f[name]\n+                weight_names = [n.decode('utf8') for n in g.attrs['weight_names']]\n+                weight_values = [g[weight_name] for weight_name in weight_names]\n+\n+                for layer in index.get(name, []):\n+                    symbolic_weights = layer.weights\n+                    if len(weight_values) != len(symbolic_weights):\n+                        raise Exception('Layer #' + str(k) +\n+                                        ' (named \"' + layer.name +\n+                                        '\") expects ' +\n+                                        str(len(symbolic_weights)) +\n+                                        ' weight(s), but the saved weights' +\n+                                        ' have ' + str(len(weight_values)) +\n+                                        ' element(s).')\n+                    # set values\n+                    for i in range(len(weight_values)):\n+                        weight_value_tuples.append((symbolic_weights[i], weight_values[i]))\n+            K.batch_set_value(weight_value_tuples)\n+\n     def _updated_config(self):\n         '''shared between different serialization methods'''\n         from keras import __version__ as keras_version\n\n@@ -1,5 +1,6 @@\n import pytest\n import os\n+import tempfile\n import numpy as np\n from numpy.testing import assert_allclose\n \n@@ -28,7 +29,7 @@ def test_sequential_model_saving():\n     model.train_on_batch(x, y)\n \n     out = model.predict(x)\n-    fname = 'tmp_' + str(np.random.randint(10000)) + '.h5'\n+    _, fname = tempfile.mkstemp('.h5')\n     save_model(model, fname)\n \n     new_model = load_model(fname)\n@@ -62,7 +63,7 @@ def test_sequential_model_saving_2():\n     model.train_on_batch(x, y)\n \n     out = model.predict(x)\n-    fname = 'tmp_' + str(np.random.randint(10000)) + '.h5'\n+    _, fname = tempfile.mkstemp('.h5')\n     save_model(model, fname)\n \n     model = load_model(fname,\n@@ -89,7 +90,7 @@ def test_fuctional_model_saving():\n     model.train_on_batch(x, y)\n \n     out = model.predict(x)\n-    fname = 'tmp_' + str(np.random.randint(10000)) + '.h5'\n+    _, fname = tempfile.mkstemp('.h5')\n     save_model(model, fname)\n \n     model = load_model(fname)\n@@ -106,7 +107,7 @@ def test_saving_without_compilation():\n     model.add(Dense(3))\n     model.compile(loss='mse', optimizer='sgd', metrics=['acc'])\n \n-    fname = 'tmp_' + str(np.random.randint(10000)) + '.h5'\n+    _, fname = tempfile.mkstemp('.h5')\n     save_model(model, fname)\n     model = load_model(fname)\n     os.remove(fname)\n@@ -120,11 +121,116 @@ def test_saving_right_after_compilation():\n     model.compile(loss='mse', optimizer='sgd', metrics=['acc'])\n     model.model._make_train_function()\n \n-    fname = 'tmp_' + str(np.random.randint(10000)) + '.h5'\n+    _, fname = tempfile.mkstemp('.h5')\n     save_model(model, fname)\n     model = load_model(fname)\n     os.remove(fname)\n \n \n+@keras_test\n+def test_loading_weights_by_name():\n+    \"\"\"\n+    test loading model weights by name on:\n+        - sequential model\n+    \"\"\"\n+\n+    # test with custom optimizer, loss\n+    custom_opt = optimizers.rmsprop\n+    custom_loss = objectives.mse\n+\n+    # sequential model\n+    model = Sequential()\n+    model.add(Dense(2, input_dim=3, name=\"rick\"))\n+    model.add(Dense(3, name=\"morty\"))\n+    model.compile(loss=custom_loss, optimizer=custom_opt(), metrics=['acc'])\n+\n+    x = np.random.random((1, 3))\n+    y = np.random.random((1, 3))\n+    model.train_on_batch(x, y)\n+\n+    out = model.predict(x)\n+    old_weights = [layer.get_weights() for layer in model.layers]\n+    _, fname = tempfile.mkstemp('.h5')\n+\n+    model.save_weights(fname)\n+\n+    # delete and recreate model\n+    del(model)\n+    model = Sequential()\n+    model.add(Dense(2, input_dim=3, name=\"rick\"))\n+    model.add(Dense(3, name=\"morty\"))\n+    model.compile(loss=custom_loss, optimizer=custom_opt(), metrics=['acc'])\n+\n+    # load weights from first model\n+    model.load_weights(fname, by_name=True)\n+    os.remove(fname)\n+\n+    out2 = model.predict(x)\n+    assert_allclose(out, out2, atol=1e-05)\n+    for i in range(len(model.layers)):\n+        new_weights = model.layers[i].get_weights()\n+        for j in range(len(new_weights)):\n+            assert_allclose(old_weights[i][j], new_weights[j], atol=1e-05)\n+\n+\n+@keras_test\n+def test_loading_weights_by_name_2():\n+    \"\"\"\n+    test loading model weights by name on:\n+        - both sequential and functional api models\n+        - different architecture with shared names\n+    \"\"\"\n+\n+    # test with custom optimizer, loss\n+    custom_opt = optimizers.rmsprop\n+    custom_loss = objectives.mse\n+\n+    # sequential model\n+    model = Sequential()\n+    model.add(Dense(2, input_dim=3, name=\"rick\"))\n+    model.add(Dense(3, name=\"morty\"))\n+    model.compile(loss=custom_loss, optimizer=custom_opt(), metrics=['acc'])\n+\n+    x = np.random.random((1, 3))\n+    y = np.random.random((1, 3))\n+    model.train_on_batch(x, y)\n+\n+    out = model.predict(x)\n+    old_weights = [layer.get_weights() for layer in model.layers]\n+    _, fname = tempfile.mkstemp('.h5')\n+\n+    model.save_weights(fname)\n+\n+    # delete and recreate model using Functional API\n+    del(model)\n+    data = Input(shape=(3,))\n+    rick = Dense(2, name=\"rick\")(data)\n+    jerry = Dense(3, name=\"jerry\")(rick)  # add 2 layers (but maintain shapes)\n+    jessica = Dense(2, name=\"jessica\")(jerry)\n+    morty = Dense(3, name=\"morty\")(jessica)\n+\n+    model = Model(input=[data], output=[morty])\n+    model.compile(loss=custom_loss, optimizer=custom_opt(), metrics=['acc'])\n+\n+    # load weights from first model\n+    model.load_weights(fname, by_name=True)\n+    os.remove(fname)\n+\n+    out2 = model.predict(x)\n+    assert np.max(np.abs(out - out2)) > 1e-05\n+\n+    rick = model.layers[1].get_weights()\n+    jerry = model.layers[2].get_weights()\n+    jessica = model.layers[3].get_weights()\n+    morty = model.layers[4].get_weights()\n+\n+    assert_allclose(old_weights[0][0], rick[0], atol=1e-05)\n+    assert_allclose(old_weights[0][1], rick[1], atol=1e-05)\n+    assert_allclose(old_weights[1][0], morty[0], atol=1e-05)\n+    assert_allclose(old_weights[1][1], morty[1], atol=1e-05)\n+    assert_allclose(np.zeros_like(jerry[1]), jerry[1])  # biases init to 0\n+    assert_allclose(np.zeros_like(jessica[1]), jessica[1])  # biases init to 0\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4325843ef07b00eb3f234d5d3dd5c92205effe9f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 21 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 21 | Churn Cumulative: 151 | Contributors (this commit): 4 | Commits (past 90d): 2 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -71,6 +71,26 @@ def cosine_proximity(y_true, y_pred):\n     return -K.mean(y_true * y_pred)\n \n \n+def matthews_correlation(y_true, y_pred):\n+    ''' Matthews correlation coefficient\n+    '''\n+    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n+    y_pred_neg = 1 - y_pred_pos\n+\n+    y_pos = K.round(K.clip(y_true, 0, 1))\n+    y_neg = 1 - y_pos\n+\n+    tp = K.sum(y_pos * y_pred_pos)\n+    tn = K.sum(y_neg * y_pred_neg)\n+\n+    fp = K.sum(1 - y_neg * y_pred_pos)\n+    fn = K.sum(1 - y_pos * y_pred_neg)\n+    \n+    numerator = (tp * tn - fp * fn)\n+    denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n+\n+    return numerator / (denominator + K.epsilon())\n+\n # aliases\n mse = MSE = mean_squared_error\n mae = MAE = mean_absolute_error\n\n@@ -17,6 +17,7 @@ all_metrics = [\n     metrics.binary_crossentropy,\n     metrics.poisson,\n     metrics.cosine_proximity,\n+    metrics.matthews_correlation,\n ]\n \n all_sparse_metrics = [\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f05cd95fadfd9a2084f27eb88ff62d1bdfe5d5e5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 3316 | Contributors (this commit): 23 | Commits (past 90d): 27 | Contributors (cumulative): 23 | DMM Complexity: None\n\nDIFF:\n@@ -1233,7 +1233,7 @@ class Merge(Layer):\n                 raise Exception('Invalid format for dot_axes - list elements should be \"int\".')\n             if shape1[self.dot_axes[0]] != shape2[self.dot_axes[1]]:\n                 raise Exception('Dimension incompatibility using dot mode: ' +\n-                                '%s != %s. ' % (shape1[dot_axes[0]], shape2[dot_axes[1]]) +\n+                                '%s != %s. ' % (shape1[self.dot_axes[0]], shape2[self.dot_axes[1]]) +\n                                 'Layer shapes: %s, %s' % (shape1, shape2))\n         elif mode == 'concat':\n             reduced_inputs_shapes = [list(shape) for shape in input_shapes]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cc92025fdc862e00cf787cc309c741e8944ed0a7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 70 | Lines Deleted: 314 | Files Changed: 7 | Hunks: 42 | Methods Changed: 8 | Complexity Δ (Sum/Max): 5/4 | Churn Δ: 384 | Churn Cumulative: 1971 | Contributors (this commit): 15 | Commits (past 90d): 10 | Contributors (cumulative): 23 | DMM Complexity: 0.0\n\nDIFF:\n@@ -43,7 +43,7 @@ Y_test = np_utils.to_categorical(y_test, nb_classes)\n model = Sequential()\n \n model.add(Convolution2D(32, 3, 3, border_mode='same',\n-                        input_shape=(img_channels, img_rows, img_cols)))\n+                        input_shape=X_train.shape[1:]))\n model.add(Activation('relu'))\n model.add(Convolution2D(32, 3, 3))\n model.add(Activation('relu'))\n\n@@ -61,6 +61,7 @@ OUTPUT_DIR = \"image_ocr\"\n \n np.random.seed(55)\n \n+\n # this creates larger \"blotches\" of noise which look\n # more realistic than just adding gaussian noise\n # assumes greyscale with pixels ranging from 0 to 1\n@@ -73,6 +74,7 @@ def speckle(img):\n     img_speck[img_speck <= 0] = 0\n     return img_speck\n \n+\n # paints the string in a random location the bounding box\n # also uses a random font, a slight random rotation,\n # and a random amount of speckle noise\n@@ -114,6 +116,7 @@ def paint_text(text, w, h):\n \n     return a\n \n+\n def shuffle_mats_or_lists(matrix_list, stop_ind=None):\n     ret = []\n     assert all([len(i) == len(matrix_list[0]) for i in matrix_list])\n@@ -131,9 +134,11 @@ def shuffle_mats_or_lists(matrix_list, stop_ind=None):\n         elif isinstance(mat, list):\n             ret.append([mat[i] for i in a])\n         else:\n-            raise TypeError('shuffle_mats_or_lists only supports numpy.array and list objects')\n+            raise TypeError('shuffle_mats_or_lists only supports '\n+                            'numpy.array and list objects')\n     return ret\n \n+\n def text_to_labels(text, num_classes):\n     ret = []\n     for char in text:\n@@ -143,6 +148,7 @@ def text_to_labels(text, num_classes):\n             ret.append(26)\n     return ret\n \n+\n # only a-z and space..probably not to difficult\n # to expand to uppercase and symbols\n \n@@ -150,14 +156,15 @@ def is_valid_str(in_str):\n     search = re.compile(r'[^a-z\\ ]').search\n     return not bool(search(in_str))\n \n+\n # Uses generator functions to supply train/test with\n # data. Image renderings are text are created on the fly\n # each time with random perturbations\n \n class TextImageGenerator(keras.callbacks.Callback):\n \n-    def __init__(self, monogram_file, bigram_file, minibatch_size, img_w,\n-                 img_h, downsample_width, val_split,\n+    def __init__(self, monogram_file, bigram_file, minibatch_size,\n+                 img_w, img_h, downsample_width, val_split,\n                  absolute_max_string_len=16):\n \n         self.minibatch_size = minibatch_size\n@@ -221,7 +228,10 @@ class TextImageGenerator(keras.callbacks.Callback):\n     # each time an image is requested from train/val/test, a new random\n     # painting of the text is performed\n     def get_batch(self, index, size, train):\n+        if K.image_dim_ordering() == 'th':\n             X_data = np.ones([size, 1, self.img_h, self.img_w])\n+        else:\n+            X_data = np.ones([size, self.img_h, self.img_w, 1])\n         labels = np.ones([size, self.absolute_max_string_len])\n         input_length = np.zeros([size, 1])\n         label_length = np.zeros([size, 1])\n@@ -231,13 +241,19 @@ class TextImageGenerator(keras.callbacks.Callback):\n             # Mix in some blank inputs.  This seems to be important for\n             # achieving translational invariance\n             if train and i > size - 4:\n+                if K.image_dim_ordering() == 'th':\n                     X_data[i, 0, :, :] = paint_text('', self.img_w, self.img_h)\n+                else:\n+                    X_data[i, :, :, 0] = paint_text('', self.img_w, self.img_h)\n                 labels[i, 0] = self.blank_label\n                 input_length[i] = self.downsample_width\n                 label_length[i] = 1\n                 source_str.append('')\n             else:\n+                if K.image_dim_ordering() == 'th':\n                     X_data[i, 0, :, :] = paint_text(self.X_text[index + i], self.img_w, self.img_h)\n+                else:\n+                    X_data[i, :, :, 0] = paint_text(self.X_text[index + i], self.img_w, self.img_h)\n                 labels[i, :] = self.Y_data[index + i]\n                 input_length[i] = self.downsample_width\n                 label_length[i] = self.Y_len[index + i]\n@@ -285,6 +301,7 @@ class TextImageGenerator(keras.callbacks.Callback):\n         if epoch == 30:\n             self.build_word_list(64000, 12, 0.5)\n \n+\n # the actual loss calc occurs here despite it not being\n # an internal Keras loss function\n \n@@ -295,6 +312,7 @@ def ctc_lambda_func(args):\n     y_pred = y_pred[:, 2:, :]\n     return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n \n+\n # For a real OCR application, this should be beam search with a dictionary\n # and language model.  For this example, best path is sufficient.\n \n@@ -314,6 +332,7 @@ def decode_batch(test_func, word_batch):\n         ret.append(outstr)\n     return ret\n \n+\n class VizCallback(keras.callbacks.Callback):\n \n     def __init__(self, test_func, text_img_gen, num_display_words=6):\n@@ -350,7 +369,11 @@ class VizCallback(keras.callbacks.Callback):\n \n         for i in range(self.num_display_words):\n             pylab.subplot(self.num_display_words, 1, i + 1)\n-            pylab.imshow(word_batch['the_input'][i, 0, :, :], cmap='Greys_r')\n+            if K.image_dim_ordering() == 'th':\n+                the_input = word_batch['the_input'][i, 0, :, :]\n+            else:\n+                the_input = word_batch['the_input'][i, :, :, 0]\n+            pylab.imshow(the_input, cmap='Greys_r')\n             pylab.xlabel('Truth = \\'%s\\' Decoded = \\'%s\\'' % (word_batch['source_str'][i], res[i]))\n         fig = pylab.gcf()\n         fig.set_size_inches(10, 12)\n@@ -375,6 +398,11 @@ time_dense_size = 32\n rnn_size = 512\n time_steps = img_w / (pool_size_1 * pool_size_2)\n \n+if K.image_dim_ordering() == 'th':\n+    input_shape = (1, img_h, img_w)\n+else:\n+    input_shape = (img_h, img_w, 1)\n+\n fdir = os.path.dirname(get_file('wordlists.tgz',\n                                 origin='http://www.isosemi.com/datasets/wordlists.tgz', untar=True))\n \n@@ -387,7 +415,7 @@ img_gen = TextImageGenerator(monogram_file=os.path.join(fdir, 'wordlist_mono_cle\n                              val_split=words_per_epoch - val_words)\n \n act = 'relu'\n-input_data = Input(name='the_input', shape=(1, img_h, img_w), dtype='float32')\n+input_data = Input(name='the_input', shape=input_shape, dtype='float32')\n inner = Convolution2D(conv_num_filters, filter_size, filter_size, border_mode='same',\n                       activation=act, name='conv1')(input_data)\n inner = MaxPooling2D(pool_size=(pool_size_1, pool_size_1), name='max1')(inner)\n\n@@ -1,290 +0,0 @@\n-'''This script demonstrates how to build the Inception v3 architecture\n-using the Keras functional API.\n-We are not actually training it here, for lack of appropriate data.\n-\n-For more information about this architecture, see:\n-\n-\"Rethinking the Inception Architecture for Computer Vision\"\n-Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, Zbigniew Wojna\n-http://arxiv.org/abs/1512.00567\n-'''\n-from keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D\n-from keras.layers import BatchNormalization, Flatten, Dense, Dropout\n-from keras.layers import Input, merge\n-from keras.models import Model\n-from keras import regularizers\n-\n-\n-# global constants\n-NB_CLASS = 1000  # number of classes\n-DIM_ORDERING = 'th'  # 'th' (channels, width, height) or 'tf' (width, height, channels)\n-WEIGHT_DECAY = 0.  # L2 regularization factor\n-USE_BN = False  # whether to use batch normalization\n-\n-\n-def conv2D_bn(x, nb_filter, nb_row, nb_col,\n-              border_mode='same', subsample=(1, 1),\n-              activation='relu', batch_norm=USE_BN,\n-              weight_decay=WEIGHT_DECAY, dim_ordering=DIM_ORDERING):\n-    '''Utility function to apply to a tensor a module conv + BN\n-    with optional weight decay (L2 weight regularization).\n-    '''\n-    if weight_decay:\n-        W_regularizer = regularizers.l2(weight_decay)\n-        b_regularizer = regularizers.l2(weight_decay)\n-    else:\n-        W_regularizer = None\n-        b_regularizer = None\n-    x = Convolution2D(nb_filter, nb_row, nb_col,\n-                      subsample=subsample,\n-                      activation=activation,\n-                      border_mode=border_mode,\n-                      W_regularizer=W_regularizer,\n-                      b_regularizer=b_regularizer,\n-                      dim_ordering=dim_ordering)(x)\n-    if batch_norm:\n-        x = BatchNormalization()(x)\n-    return x\n-\n-# Define image input layer\n-\n-if DIM_ORDERING == 'th':\n-    img_input = Input(shape=(3, 299, 299))\n-    CONCAT_AXIS = 1\n-elif DIM_ORDERING == 'tf':\n-    img_input = Input(shape=(299, 299, 3))\n-    CONCAT_AXIS = 3\n-else:\n-    raise Exception('Invalid dim ordering: ' + str(DIM_ORDERING))\n-\n-# Entry module\n-\n-x = conv2D_bn(img_input, 32, 3, 3, subsample=(2, 2), border_mode='valid')\n-x = conv2D_bn(x, 32, 3, 3, border_mode='valid')\n-x = conv2D_bn(x, 64, 3, 3)\n-x = MaxPooling2D((3, 3), strides=(2, 2), dim_ordering=DIM_ORDERING)(x)\n-\n-x = conv2D_bn(x, 80, 1, 1, border_mode='valid')\n-x = conv2D_bn(x, 192, 3, 3, border_mode='valid')\n-x = MaxPooling2D((3, 3), strides=(2, 2), dim_ordering=DIM_ORDERING)(x)\n-\n-# mixed: 35 x 35 x 256\n-\n-branch1x1 = conv2D_bn(x, 64, 1, 1)\n-\n-branch5x5 = conv2D_bn(x, 48, 1, 1)\n-branch5x5 = conv2D_bn(branch5x5, 64, 5, 5)\n-\n-branch3x3dbl = conv2D_bn(x, 64, 1, 1)\n-branch3x3dbl = conv2D_bn(branch3x3dbl, 96, 3, 3)\n-branch3x3dbl = conv2D_bn(branch3x3dbl, 96, 3, 3)\n-\n-branch_pool = AveragePooling2D((3, 3), strides=(1, 1), border_mode='same', dim_ordering=DIM_ORDERING)(x)\n-branch_pool = conv2D_bn(branch_pool, 32, 1, 1)\n-x = merge([branch1x1, branch5x5, branch3x3dbl, branch_pool], mode='concat', concat_axis=CONCAT_AXIS)\n-\n-# mixed_1: 35 x 35 x 288\n-\n-branch1x1 = conv2D_bn(x, 64, 1, 1)\n-\n-branch5x5 = conv2D_bn(x, 48, 1, 1)\n-branch5x5 = conv2D_bn(branch5x5, 64, 5, 5)\n-\n-branch3x3dbl = conv2D_bn(x, 64, 1, 1)\n-branch3x3dbl = conv2D_bn(branch3x3dbl, 96, 3, 3)\n-branch3x3dbl = conv2D_bn(branch3x3dbl, 96, 3, 3)\n-\n-branch_pool = AveragePooling2D((3, 3), strides=(1, 1), border_mode='same', dim_ordering=DIM_ORDERING)(x)\n-branch_pool = conv2D_bn(branch_pool, 64, 1, 1)\n-x = merge([branch1x1, branch5x5, branch3x3dbl, branch_pool], mode='concat', concat_axis=CONCAT_AXIS)\n-\n-# mixed2: 35 x 35 x 288\n-\n-branch1x1 = conv2D_bn(x, 64, 1, 1)\n-\n-branch5x5 = conv2D_bn(x, 48, 1, 1)\n-branch5x5 = conv2D_bn(branch5x5, 64, 5, 5)\n-\n-branch3x3dbl = conv2D_bn(x, 64, 1, 1)\n-branch3x3dbl = conv2D_bn(branch3x3dbl, 96, 3, 3)\n-branch3x3dbl = conv2D_bn(branch3x3dbl, 96, 3, 3)\n-\n-branch_pool = AveragePooling2D((3, 3), strides=(1, 1), border_mode='same', dim_ordering=DIM_ORDERING)(x)\n-branch_pool = conv2D_bn(branch_pool, 64, 1, 1)\n-x = merge([branch1x1, branch5x5, branch3x3dbl, branch_pool], mode='concat', concat_axis=CONCAT_AXIS)\n-\n-# mixed3: 17 x 17 x 768\n-\n-branch3x3 = conv2D_bn(x, 384, 3, 3, subsample=(2, 2), border_mode='valid')\n-\n-branch3x3dbl = conv2D_bn(x, 64, 1, 1)\n-branch3x3dbl = conv2D_bn(branch3x3dbl, 96, 3, 3)\n-branch3x3dbl = conv2D_bn(branch3x3dbl, 96, 3, 3, subsample=(2, 2), border_mode='valid')\n-\n-branch_pool = MaxPooling2D((3, 3), strides=(2, 2), dim_ordering=DIM_ORDERING)(x)\n-x = merge([branch3x3, branch3x3dbl, branch_pool], mode='concat', concat_axis=CONCAT_AXIS)\n-\n-# mixed4: 17 x 17 x 768\n-\n-branch1x1 = conv2D_bn(x, 192, 1, 1)\n-\n-branch7x7 = conv2D_bn(x, 128, 1, 1)\n-branch7x7 = conv2D_bn(branch7x7, 128, 1, 7)\n-branch7x7 = conv2D_bn(branch7x7, 192, 7, 1)\n-\n-branch7x7dbl = conv2D_bn(x, 128, 1, 1)\n-branch7x7dbl = conv2D_bn(branch7x7dbl, 128, 7, 1)\n-branch7x7dbl = conv2D_bn(branch7x7dbl, 128, 1, 7)\n-branch7x7dbl = conv2D_bn(branch7x7dbl, 128, 7, 1)\n-branch7x7dbl = conv2D_bn(branch7x7dbl, 192, 1, 7)\n-\n-branch_pool = AveragePooling2D((3, 3), strides=(1, 1), border_mode='same', dim_ordering=DIM_ORDERING)(x)\n-branch_pool = conv2D_bn(branch_pool, 192, 1, 1)\n-x = merge([branch1x1, branch7x7, branch7x7dbl, branch_pool], mode='concat', concat_axis=CONCAT_AXIS)\n-\n-# mixed5: 17 x 17 x 768\n-\n-branch1x1 = conv2D_bn(x, 192, 1, 1)\n-\n-branch7x7 = conv2D_bn(x, 160, 1, 1)\n-branch7x7 = conv2D_bn(branch7x7, 160, 1, 7)\n-branch7x7 = conv2D_bn(branch7x7, 192, 7, 1)\n-\n-branch7x7dbl = conv2D_bn(x, 160, 1, 1)\n-branch7x7dbl = conv2D_bn(branch7x7dbl, 160, 7, 1)\n-branch7x7dbl = conv2D_bn(branch7x7dbl, 160, 1, 7)\n-branch7x7dbl = conv2D_bn(branch7x7dbl, 160, 7, 1)\n-branch7x7dbl = conv2D_bn(branch7x7dbl, 192, 1, 7)\n-\n-branch_pool = AveragePooling2D((3, 3), strides=(1, 1), border_mode='same', dim_ordering=DIM_ORDERING)(x)\n-branch_pool = conv2D_bn(branch_pool, 192, 1, 1)\n-x = merge([branch1x1, branch7x7, branch7x7dbl, branch_pool], mode='concat', concat_axis=CONCAT_AXIS)\n-\n-# mixed5: 17 x 17 x 768\n-\n-branch1x1 = conv2D_bn(x, 192, 1, 1)\n-\n-branch7x7 = conv2D_bn(x, 160, 1, 1)\n-branch7x7 = conv2D_bn(branch7x7, 160, 1, 7)\n-branch7x7 = conv2D_bn(branch7x7, 192, 7, 1)\n-\n-branch7x7dbl = conv2D_bn(x, 160, 1, 1)\n-branch7x7dbl = conv2D_bn(branch7x7dbl, 160, 7, 1)\n-branch7x7dbl = conv2D_bn(branch7x7dbl, 160, 1, 7)\n-branch7x7dbl = conv2D_bn(branch7x7dbl, 160, 7, 1)\n-branch7x7dbl = conv2D_bn(branch7x7dbl, 192, 1, 7)\n-\n-branch_pool = AveragePooling2D((3, 3), strides=(1, 1), border_mode='same', dim_ordering=DIM_ORDERING)(x)\n-branch_pool = conv2D_bn(branch_pool, 192, 1, 1)\n-x = merge([branch1x1, branch7x7, branch7x7dbl, branch_pool], mode='concat', concat_axis=CONCAT_AXIS)\n-\n-# mixed6: 17 x 17 x 768\n-\n-branch1x1 = conv2D_bn(x, 192, 1, 1)\n-\n-branch7x7 = conv2D_bn(x, 160, 1, 1)\n-branch7x7 = conv2D_bn(branch7x7, 160, 1, 7)\n-branch7x7 = conv2D_bn(branch7x7, 192, 7, 1)\n-\n-branch7x7dbl = conv2D_bn(x, 160, 1, 1)\n-branch7x7dbl = conv2D_bn(branch7x7dbl, 160, 7, 1)\n-branch7x7dbl = conv2D_bn(branch7x7dbl, 192, 1, 7)\n-branch7x7dbl = conv2D_bn(branch7x7dbl, 160, 7, 1)\n-branch7x7dbl = conv2D_bn(branch7x7dbl, 192, 1, 7)\n-\n-branch_pool = AveragePooling2D((3, 3), strides=(1, 1), border_mode='same', dim_ordering=DIM_ORDERING)(x)\n-branch_pool = conv2D_bn(branch_pool, 192, 1, 1)\n-x = merge([branch1x1, branch7x7, branch7x7dbl, branch_pool], mode='concat', concat_axis=CONCAT_AXIS)\n-\n-# mixed7: 17 x 17 x 768\n-\n-branch1x1 = conv2D_bn(x, 192, 1, 1)\n-\n-branch7x7 = conv2D_bn(x, 192, 1, 1)\n-branch7x7 = conv2D_bn(branch7x7, 192, 1, 7)\n-branch7x7 = conv2D_bn(branch7x7, 192, 7, 1)\n-\n-branch7x7dbl = conv2D_bn(x, 160, 1, 1)\n-branch7x7dbl = conv2D_bn(branch7x7dbl, 192, 7, 1)\n-branch7x7dbl = conv2D_bn(branch7x7dbl, 192, 1, 7)\n-branch7x7dbl = conv2D_bn(branch7x7dbl, 192, 7, 1)\n-branch7x7dbl = conv2D_bn(branch7x7dbl, 192, 1, 7)\n-\n-branch_pool = AveragePooling2D((3, 3), strides=(1, 1), border_mode='same', dim_ordering=DIM_ORDERING)(x)\n-branch_pool = conv2D_bn(branch_pool, 192, 1, 1)\n-x = merge([branch1x1, branch7x7, branch7x7dbl, branch_pool], mode='concat', concat_axis=CONCAT_AXIS)\n-\n-# Auxiliary head\n-\n-aux_logits = AveragePooling2D((5, 5), strides=(3, 3), dim_ordering=DIM_ORDERING)(x)\n-aux_logits = conv2D_bn(aux_logits, 128, 1, 1)\n-aux_logits = conv2D_bn(aux_logits, 728, 5, 5, border_mode='valid')\n-aux_logits = Flatten()(aux_logits)\n-aux_preds = Dense(NB_CLASS, activation='softmax')(aux_logits)\n-\n-# mixed8: 8 x 8 x 1280\n-\n-branch3x3 = conv2D_bn(x, 192, 1, 1)\n-branch3x3 = conv2D_bn(branch3x3, 320, 3, 3, subsample=(2, 2), border_mode='valid')\n-\n-branch7x7x3 = conv2D_bn(x, 192, 1, 1)\n-branch7x7x3 = conv2D_bn(branch7x7x3, 192, 1, 7)\n-branch7x7x3 = conv2D_bn(branch7x7x3, 192, 7, 1)\n-branch7x7x3 = conv2D_bn(branch7x7x3, 192, 3, 3, subsample=(2, 2), border_mode='valid')\n-\n-branch_pool = AveragePooling2D((3, 3), strides=(2, 2), dim_ordering=DIM_ORDERING)(x)\n-x = merge([branch3x3, branch7x7x3, branch_pool], mode='concat', concat_axis=CONCAT_AXIS)\n-\n-# mixed9: 8 x 8 x 2048\n-\n-branch1x1 = conv2D_bn(x, 320, 1, 1)\n-\n-branch3x3 = conv2D_bn(x, 384, 1, 1)\n-branch3x3_1 = conv2D_bn(branch3x3, 384, 1, 3)\n-branch3x3_2 = conv2D_bn(branch3x3, 384, 3, 1)\n-branch3x3 = merge([branch3x3_1, branch3x3_2], mode='concat', concat_axis=CONCAT_AXIS)\n-\n-branch3x3dbl = conv2D_bn(x, 448, 1, 1)\n-branch3x3dbl = conv2D_bn(branch3x3dbl, 384, 3, 3)\n-branch3x3dbl_1 = conv2D_bn(branch3x3dbl, 384, 1, 3)\n-branch3x3dbl_2 = conv2D_bn(branch3x3dbl, 384, 3, 1)\n-branch3x3dbl = merge([branch3x3dbl_1, branch3x3dbl_2], mode='concat', concat_axis=CONCAT_AXIS)\n-\n-branch_pool = AveragePooling2D((3, 3), strides=(1, 1), border_mode='same', dim_ordering=DIM_ORDERING)(x)\n-branch_pool = conv2D_bn(branch_pool, 192, 1, 1)\n-x = merge([branch1x1, branch3x3, branch3x3dbl, branch_pool], mode='concat', concat_axis=CONCAT_AXIS)\n-\n-# mixed10: 8 x 8 x 2048\n-\n-branch1x1 = conv2D_bn(x, 320, 1, 1)\n-\n-branch3x3 = conv2D_bn(x, 384, 1, 1)\n-branch3x3_1 = conv2D_bn(branch3x3, 384, 1, 3)\n-branch3x3_2 = conv2D_bn(branch3x3, 384, 3, 1)\n-branch3x3 = merge([branch3x3_1, branch3x3_2], mode='concat', concat_axis=CONCAT_AXIS)\n-\n-branch3x3dbl = conv2D_bn(x, 448, 1, 1)\n-branch3x3dbl = conv2D_bn(branch3x3dbl, 384, 3, 3)\n-branch3x3dbl_1 = conv2D_bn(branch3x3dbl, 384, 1, 3)\n-branch3x3dbl_2 = conv2D_bn(branch3x3dbl, 384, 3, 1)\n-branch3x3dbl = merge([branch3x3dbl_1, branch3x3dbl_2], mode='concat', concat_axis=CONCAT_AXIS)\n-\n-branch_pool = AveragePooling2D((3, 3), strides=(1, 1), border_mode='same', dim_ordering=DIM_ORDERING)(x)\n-branch_pool = conv2D_bn(branch_pool, 192, 1, 1)\n-x = merge([branch1x1, branch3x3, branch3x3dbl, branch_pool], mode='concat', concat_axis=CONCAT_AXIS)\n-\n-# Final pooling and prediction\n-\n-x = AveragePooling2D((8, 8), strides=(1, 1), dim_ordering=DIM_ORDERING)(x)\n-x = Dropout(0.5)(x)\n-x = Flatten()(x)\n-preds = Dense(NB_CLASS, activation='softmax')(x)\n-\n-# Define model\n-\n-model = Model(input=img_input, output=[preds, aux_preds])\n-model.compile('rmsprop', 'categorical_crossentropy')\n-\n-# train via e.g. `model.fit(x_train, [y_train] * 2, batch_size=32, nb_epoch=100)`\n-# Note that for a large dataset it would be preferable\n-# to train using `fit_generator` (see Keras docs).\n\n@@ -14,6 +14,7 @@ from keras.models import Sequential\n from keras.layers import Dense, Dropout, Activation, Flatten\n from keras.layers import Convolution2D, MaxPooling2D\n from keras.utils import np_utils\n+from keras import backend as K\n \n batch_size = 128\n nb_classes = 10\n@@ -24,15 +25,22 @@ img_rows, img_cols = 28, 28\n # number of convolutional filters to use\n nb_filters = 32\n # size of pooling area for max pooling\n-nb_pool = 2\n+pool_size = (2, 2)\n # convolution kernel size\n kernel_size = (3, 3)\n \n # the data, shuffled and split between train and test sets\n (X_train, y_train), (X_test, y_test) = mnist.load_data()\n \n+if K.image_dim_ordering() == 'th':\n     X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n     X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n+    input_shape = (1, img_rows, img_cols)\n+else:\n+    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n+    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n+    input_shape = (img_rows, img_cols, 1)\n+\n X_train = X_train.astype('float32')\n X_test = X_test.astype('float32')\n X_train /= 255\n@@ -49,11 +57,11 @@ model = Sequential()\n \n model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],\n                         border_mode='valid',\n-                        input_shape=(1, img_rows, img_cols)))\n+                        input_shape=input_shape))\n model.add(Activation('relu'))\n model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1]))\n model.add(Activation('relu'))\n-model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n+model.add(MaxPooling2D(pool_size=pool_size))\n model.add(Dropout(0.25))\n \n model.add(Flatten())\n\n@@ -22,7 +22,7 @@ from keras.models import Sequential\n from keras.layers import Dense, Dropout, Activation, Flatten\n from keras.layers import Convolution2D, MaxPooling2D\n from keras.utils import np_utils\n-\n+from keras import backend as K\n \n now = datetime.datetime.now\n \n@@ -35,14 +35,19 @@ img_rows, img_cols = 28, 28\n # number of convolutional filters to use\n nb_filters = 32\n # size of pooling area for max pooling\n-nb_pool = 2\n+pool_size = 2\n # convolution kernel size\n-nb_conv = 3\n+kernel_size = 3\n+\n+if K.image_dim_ordering() == 'th':\n+    input_shape = (1, img_rows, img_cols)\n+else:\n+    input_shape = (img_rows, img_cols, 1)\n \n \n def train_model(model, train, test, nb_classes):\n-    X_train = train[0].reshape(train[0].shape[0], 1, img_rows, img_cols)\n-    X_test = test[0].reshape(test[0].shape[0], 1, img_rows, img_cols)\n+    X_train = train[0].reshape((train[0].shape[0],) + input_shape)\n+    X_test = test[0].reshape((test[0].shape[0],) + input_shape)\n     X_train = X_train.astype('float32')\n     X_test = X_test.astype('float32')\n     X_train /= 255\n@@ -86,13 +91,13 @@ y_test_gte5 = y_test[y_test >= 5] - 5\n \n # define two groups of layers: feature (convolutions) and classification (dense)\n feature_layers = [\n-    Convolution2D(nb_filters, nb_conv, nb_conv,\n+    Convolution2D(nb_filters, kernel_size, kernel_size,\n                   border_mode='valid',\n-                  input_shape=(1, img_rows, img_cols)),\n+                  input_shape=input_shape),\n     Activation('relu'),\n-    Convolution2D(nb_filters, nb_conv, nb_conv),\n+    Convolution2D(nb_filters, kernel_size, kernel_size),\n     Activation('relu'),\n-    MaxPooling2D(pool_size=(nb_pool, nb_pool)),\n+    MaxPooling2D(pool_size=(pool_size, pool_size)),\n     Dropout(0.25),\n     Flatten(),\n ]\n@@ -105,9 +110,7 @@ classification_layers = [\n ]\n \n # create complete model\n-model = Sequential()\n-for l in feature_layers + classification_layers:\n-    model.add(l)\n+model = Sequential(feature_layers + classification_layers)\n \n # train model for 5-digit classification [0..4]\n train_model(model,\n\n@@ -1,6 +1,7 @@\n from __future__ import absolute_import\n from .cifar import load_batch\n from ..utils.data_utils import get_file\n+from .. import backend as K\n import numpy as np\n import os\n \n@@ -27,4 +28,8 @@ def load_data():\n     y_train = np.reshape(y_train, (len(y_train), 1))\n     y_test = np.reshape(y_test, (len(y_test), 1))\n \n+    if K.image_dim_ordering() == 'tf':\n+        X_train = X_train.transpose(0, 2, 3, 1)\n+        X_test = X_test.transpose(0, 2, 3, 1)\n+\n     return (X_train, y_train), (X_test, y_test)\n\n@@ -1,6 +1,7 @@\n from __future__ import absolute_import\n from .cifar import load_batch\n from ..utils.data_utils import get_file\n+from .. import backend as K\n import numpy as np\n import os\n \n@@ -13,9 +14,6 @@ def load_data(label_mode='fine'):\n     origin = \"http://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\"\n     path = get_file(dirname, origin=origin, untar=True)\n \n-    nb_test_samples = 10000\n-    nb_train_samples = 50000\n-\n     fpath = os.path.join(path, 'train')\n     X_train, y_train = load_batch(fpath, label_key=label_mode+'_labels')\n \n@@ -25,4 +23,8 @@ def load_data(label_mode='fine'):\n     y_train = np.reshape(y_train, (len(y_train), 1))\n     y_test = np.reshape(y_test, (len(y_test), 1))\n \n+    if K.image_dim_ordering() == 'tf':\n+        X_train = X_train.transpose(0, 2, 3, 1)\n+        X_test = X_test.transpose(0, 2, 3, 1)\n+\n     return (X_train, y_train), (X_test, y_test)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f5ad1c57532c34c91931a24ad228d7bfe8ca03e2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 3 | Churn Cumulative: 559 | Contributors (this commit): 4 | Commits (past 90d): 4 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -128,7 +128,10 @@ outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n # the gram matrix of an image tensor (feature-wise outer product)\n def gram_matrix(x):\n     assert K.ndim(x) == 3\n+    if K.image_dim_ordering() == 'th':\n         features = K.batch_flatten(x)\n+    else:\n+        features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n     gram = K.dot(features, K.transpose(features))\n     return gram\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#685ce7573d7282f6279882c5f624ef00b43fc3f4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 167 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 167 | Churn Cumulative: 167 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,167 @@\n+'''Trains a stacked what-where autoencoder built on residual blocks on the\r\n+MNIST dataset.  It exemplifies two influential methods that have been developed\r\n+in the past few years.\r\n+\r\n+The first is the idea of properly \"unpooling.\" During any max pool, the\r\n+exact location (the \"where\") of the maximal value in a pooled receptive field\r\n+is lost, however it can be very useful in the overall reconstruction of an\r\n+input image.  Therefore, if the \"where\" is handed from the encoder\r\n+to the corresponding decoder layer, features being decoded can be \"placed\" in\r\n+the right location, allowing for reconstructions of much higher fidelity.\r\n+\r\n+References:\r\n+[1]\r\n+\"Visualizing and Understanding Convolutional Networks\"\r\n+Matthew D Zeiler, Rob Fergus\r\n+https://arxiv.org/abs/1311.2901v3\r\n+\r\n+[2]\r\n+\"Stacked What-Where Auto-encoders\"\r\n+Junbo Zhao, Michael Mathieu, Ross Goroshin, Yann LeCun\r\n+https://arxiv.org/abs/1506.02351v8\r\n+\r\n+The second idea exploited here is that of residual learning.  Residual blocks\r\n+ease the training process by allowing skip connections that give the network\r\n+the ability to be as linear (or non-linear) as the data sees fit.  This allows\r\n+for much deep networks to be easily trained.  The residual element seems to\r\n+be advantageous in the context of this example as it allows a nice symmetry\r\n+between the encoder and decoder.  Normally, in the decoder, the final\r\n+projection to the space where the image is reconstructed is linear, however\r\n+this does not have to be the case for a residual block as the degree to which\r\n+its output is linear or non-linear is determined by the data it is fed.\r\n+However, in order to cap the reconstruction in this example, a hard softmax is\r\n+applied as a bias because we know the MNIST digits are mapped to [0,1].\r\n+\r\n+References:\r\n+[3]\r\n+\"Deep Residual Learning for Image Recognition\"\r\n+Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\r\n+https://arxiv.org/abs/1512.03385v1\r\n+\r\n+[4]\r\n+\"Identity Mappings in Deep Residual Networks\"\r\n+Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\r\n+https://arxiv.org/abs/1603.05027v3\r\n+\r\n+'''\r\n+\r\n+from __future__ import print_function\r\n+import numpy as np\r\n+np.random.seed(1337)  # for reproducibility\r\n+\r\n+from keras.datasets import mnist\r\n+from keras.models import Model\r\n+from keras.layers import Activation, merge\r\n+from keras.layers import UpSampling2D, Convolution2D, MaxPooling2D\r\n+from keras.layers import Input, BatchNormalization\r\n+import matplotlib.pyplot as plt\r\n+import keras.backend as K\r\n+\r\n+\r\n+def convresblock(x, nfeats=8, ksize=3, nskipped=2):\r\n+    ''' The proposed residual block from [4]'''\r\n+    y0 = Convolution2D(nfeats, ksize, ksize, border_mode='same')(x)\r\n+    y = y0\r\n+    for i in range(nskipped):\r\n+        y = BatchNormalization(mode=0, axis=1)(y)\r\n+        y = Activation('relu')(y)\r\n+        y = Convolution2D(nfeats, ksize, ksize, border_mode='same')(y)\r\n+    return merge([y0, y], mode='sum')\r\n+\r\n+\r\n+def getwhere(x):\r\n+    ''' Calculate the \"where\" mask that contains switches indicating which\r\n+    index contained the max value when MaxPool2D was applied.  Using the\r\n+    gradient of the sum is a nice trick to keep everything high level.'''\r\n+    y_prepool, y_postpool = x\r\n+    return K.gradients(K.sum(y_postpool), y_prepool)\r\n+\r\n+# input image dimensions\r\n+img_rows, img_cols = 28, 28\r\n+\r\n+# the data, shuffled and split between train and test sets\r\n+(X_train, _), (X_test, _) = mnist.load_data()\r\n+\r\n+X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\r\n+X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\r\n+X_train = X_train.astype('float32')\r\n+X_test = X_test.astype('float32')\r\n+X_train /= 255\r\n+X_test /= 255\r\n+print('X_train shape:', X_train.shape)\r\n+print(X_train.shape[0], 'train samples')\r\n+print(X_test.shape[0], 'test samples')\r\n+\r\n+# The size of the kernel used for the MaxPooling2D\r\n+pool_size = 2\r\n+# The total number of feature maps at each layer\r\n+nfeats = [8, 16, 32, 64, 128]\r\n+# The sizes of the pooling kernel at each layer\r\n+pool_sizes = np.array([1, 1, 1, 1, 1]) * pool_size\r\n+# The convolution kernel size\r\n+ksize = 3\r\n+# Number of epochs to train for\r\n+nb_epoch = 5\r\n+# Batch size during training\r\n+batch_size = 128\r\n+\r\n+if pool_size == 2:\r\n+    # if using a 5 layer net of pool_size = 2\r\n+    X_train = np.pad(X_train, [[0, 0], [0, 0], [2, 2], [2, 2]],\r\n+                     mode='constant')\r\n+    X_test = np.pad(X_test, [[0, 0], [0, 0], [2, 2], [2, 2]], mode='constant')\r\n+    nlayers = 5\r\n+elif pool_size == 3:\r\n+    # if using a 3 layer net of pool_size = 3\r\n+    X_train = X_train[:, :, :-1, :-1]\r\n+    X_test = X_test[:, :, :-1, :-1]\r\n+    nlayers = 3\r\n+else:\r\n+    import sys\r\n+    sys.exit(\"Script supports pool_size of 2 and 3.\")\r\n+\r\n+# Shape of input to train on (note that model is fully convolutional however)\r\n+input_shape = X_train.shape[1:]\r\n+# The final list of the size of axis=1 for all layers, including input\r\n+nfeats_all = [input_shape[0]] + nfeats\r\n+\r\n+# First build the encoder, all the while keeping track of the \"where\" masks\r\n+img_input = Input(shape=input_shape)\r\n+\r\n+# We push the \"where\" masks to the following list\r\n+wheres = [None] * nlayers\r\n+y = img_input\r\n+for i in range(nlayers):\r\n+    y_prepool = convresblock(y, nfeats=nfeats_all[i + 1], ksize=ksize)\r\n+    y = MaxPooling2D(pool_size=(pool_sizes[i], pool_sizes[i]))(y_prepool)\r\n+    wheres[i] = merge([y_prepool, y], mode=getwhere,\r\n+                      output_shape=lambda x: x[0])\r\n+\r\n+# Now build the decoder, and use the stored \"where\" masks to place the features\r\n+for i in range(nlayers):\r\n+    ind = nlayers - 1 - i\r\n+    y = UpSampling2D(size=(pool_sizes[ind], pool_sizes[ind]))(y)\r\n+    y = merge([y, wheres[ind]], mode='mul')\r\n+    y = convresblock(y, nfeats=nfeats_all[ind], ksize=ksize)\r\n+\r\n+# Use hard_simgoid to clip range of reconstruction\r\n+y = Activation('hard_sigmoid')(y)\r\n+\r\n+# Define the model and it's mean square error loss, and compile it with Adam\r\n+model = Model(img_input, y)\r\n+model.compile('adam', 'mse')\r\n+\r\n+# Fit the model\r\n+model.fit(X_train, X_train, validation_data=(X_test, X_test),\r\n+          batch_size=batch_size, nb_epoch=nb_epoch)\r\n+\r\n+# Plot\r\n+X_recon = model.predict(X_test[:25])\r\n+X_plot = np.concatenate((X_test[:25], X_recon), axis=1)\r\n+X_plot = X_plot.reshape((5, 10, input_shape[-2], input_shape[-1]))\r\n+X_plot = np.vstack([np.hstack(x) for x in X_plot])\r\n+plt.figure()\r\n+plt.axis('off')\r\n+plt.title('Test Samples: Originals/Reconstructions')\r\n+plt.imshow(X_plot, interpolation='none', cmap='gray')\r\n+plt.savefig('reconstructions.png')\r\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
