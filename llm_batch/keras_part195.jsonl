{"custom_id": "keras#5834747dc7a99ed28410bc80be4f87f715482cff", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 15 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): -5/0 | Churn Δ: 17 | Churn Cumulative: 9216 | Contributors (this commit): 73 | Commits (past 90d): 18 | Contributors (cumulative): 73 | DMM Complexity: 1.0\n\nDIFF:\n@@ -214,25 +214,12 @@ def load_model(filepath, custom_objects=None, compile=True):\n         if isinstance(obj, list):\n             deserialized = []\n             for value in obj:\n-                if value in custom_objects:\n-                    deserialized.append(custom_objects[value])\n-                else:\n-                    deserialized.append(value)\n+                deserialized.append(convert_custom_objects(value))\n             return deserialized\n         if isinstance(obj, dict):\n             deserialized = {}\n             for key, value in obj.items():\n-                deserialized[key] = []\n-                if isinstance(value, list):\n-                    for element in value:\n-                        if element in custom_objects:\n-                            deserialized[key].append(custom_objects[element])\n-                        else:\n-                            deserialized[key].append(element)\n-                elif value in custom_objects:\n-                    deserialized[key] = custom_objects[value]\n-                else:\n-                    deserialized[key] = value\n+                deserialized[key] = convert_custom_objects(value)\n             return deserialized\n         if obj in custom_objects:\n             return custom_objects[obj]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#eafdffff75a16801860a27281c93267b1d445177", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 4 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 848 | Contributors (this commit): 7 | Commits (past 90d): 9 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -389,7 +389,7 @@ class SequenceEnqueuer(object):\n \n     @abstractmethod\n     def is_running(self):\n-        raise NotImplemented\n+        raise NotImplementedError\n \n     @abstractmethod\n     def start(self, workers=1, max_queue_size=10):\n@@ -400,7 +400,7 @@ class SequenceEnqueuer(object):\n             max_queue_size: queue size\n                 (when full, threads could block on `put()`).\n         \"\"\"\n-        raise NotImplemented\n+        raise NotImplementedError\n \n     @abstractmethod\n     def stop(self, timeout=None):\n@@ -411,7 +411,7 @@ class SequenceEnqueuer(object):\n         # Arguments\n             timeout: maximum time to wait on thread.join()\n         \"\"\"\n-        raise NotImplemented\n+        raise NotImplementedError\n \n     @abstractmethod\n     def get(self):\n@@ -423,7 +423,7 @@ class SequenceEnqueuer(object):\n             Generator yielding tuples `(inputs, targets)`\n                 or `(inputs, targets, sample_weights)`.\n         \"\"\"\n-        raise NotImplemented\n+        raise NotImplementedError\n \n \n class OrderedEnqueuer(SequenceEnqueuer):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ec048edffc1f6292b7d9ca54b31af3659b902353", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 9218 | Contributors (this commit): 73 | Commits (past 90d): 19 | Contributors (cumulative): 73 | DMM Complexity: None\n\nDIFF:\n@@ -1067,7 +1067,7 @@ class Sequential(Model):\n                 for the class.\n             max_queue_size: Maximum size for the generator queue\n             workers: Maximum number of processes to spin up\n-            use_multiprocessing: Ff True, use process based threading.\n+            use_multiprocessing: if True, use process based threading.\n                 Note that because\n                 this implementation relies on multiprocessing,\n                 you should not pass\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8040ad72dd488feac9843caca4f875186d3b75c1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 19 | Lines Deleted: 25 | Files Changed: 1 | Hunks: 8 | Methods Changed: 1 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 44 | Churn Cumulative: 827 | Contributors (this commit): 2 | Commits (past 90d): 6 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -371,7 +371,20 @@ def MobileNet(input_shape=None,\n         raise ValueError('If using `weights` as ImageNet with `include_top` '\n                          'as true, `classes` should be 1000')\n \n-    if weights == 'imagenet' and depth_multiplier != 1:\n+    # Determine proper input shape.\n+    input_shape = _obtain_input_shape(input_shape,\n+                                      default_size=224,\n+                                      min_size=32,\n+                                      data_format=K.image_data_format(),\n+                                      include_top=include_top or weights)\n+    if K.image_data_format() == 'channels_last':\n+        row_axis, col_axis = (0, 1)\n+    else:\n+        row_axis, col_axis = (1, 2)\n+    rows = input_shape[row_axis]\n+    cols = input_shape[col_axis]\n+\n+    if weights == 'imagenet':\n         if depth_multiplier != 1:\n             raise ValueError('If imagenet weights are being loaded, '\n                              'depth multiplier must be 1')\n@@ -381,15 +394,11 @@ def MobileNet(input_shape=None,\n                              'alpha can be one of'\n                              '`0.25`, `0.50`, `0.75` or `1.0` only.')\n \n-        rows, cols = (0, 1) if K.image_data_format() == 'channels_last' else (1, 2)\n-        rows = int(input_shape[rows])\n-        cols = int(input_shape[cols])\n-\n         if rows != cols or rows not in [128, 160, 192, 224]:\n             raise ValueError('If imagenet weights are being loaded, '\n-                             'image must have a square shape (one of '\n+                             'input must have a static square shape (one of '\n                              '(128,128), (160,160), (192,192), or (224, 224)).'\n-                             'Image shape provided = (%d, %d)' % (rows, cols))\n+                             ' Input shape provided = %s' % (input_shape,))\n \n     if K.image_data_format() != 'channels_last':\n         warnings.warn('The MobileNet family of models is only available '\n@@ -397,8 +406,8 @@ def MobileNet(input_shape=None,\n                       '(width, height, channels). '\n                       'However your settings specify the default '\n                       'data format \"channels_first\" (channels, width, height).'\n-                      'You should set `image_data_format=\"channels_last\"` in your Keras '\n-                      'config located at ~/.keras/keras.json. '\n+                      ' You should set `image_data_format=\"channels_last\"` '\n+                      'in your Keras config located at ~/.keras/keras.json. '\n                       'The model being returned right now will expect inputs '\n                       'to follow the \"channels_last\" data format.')\n         K.set_image_data_format('channels_last')\n@@ -406,15 +415,6 @@ def MobileNet(input_shape=None,\n     else:\n         old_data_format = None\n \n-    # Determine proper input shape. Note, include_top is False by default, as\n-    # input shape can be anything larger than 32x32\n-    # and the same number of parameters will be used.\n-    input_shape = _obtain_input_shape(input_shape,\n-                                      default_size=224,\n-                                      min_size=32,\n-                                      data_format=K.image_data_format(),\n-                                      include_top=False)\n-\n     if input_tensor is None:\n         img_input = Input(shape=input_shape)\n     else:\n@@ -472,14 +472,8 @@ def MobileNet(input_shape=None,\n     else:\n         inputs = img_input\n \n-    rows, cols = (0, 1) if K.image_data_format() == 'channels_last' else (1, 2)\n-    if input_shape[rows] is None:\n-        size = 'None'\n-    else:\n-        size = str(input_shape[rows])\n-\n     # Create model.\n-    model = Model(inputs, x, name='mobilenet_%0.2f_%s' % (alpha, size))\n+    model = Model(inputs, x, name='mobilenet_%0.2f_%s' % (alpha, rows))\n \n     # load weights\n     if weights == 'imagenet':\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b42f6760bc79151a4be925531ba978a7a79e58c6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 8 | Churn Cumulative: 835 | Contributors (this commit): 2 | Commits (past 90d): 7 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -72,7 +72,6 @@ from ..utils.data_utils import get_file\n from ..engine.topology import get_source_inputs\n from ..engine import InputSpec\n from ..applications.imagenet_utils import _obtain_input_shape\n-from ..applications.imagenet_utils import preprocess_input\n from ..applications.imagenet_utils import decode_predictions\n from .. import backend as K\n \n@@ -84,6 +83,13 @@ def relu6(x):\n     return K.relu(x, max_value=6)\n \n \n+def preprocess_input(x):\n+    x /= 255.\n+    x -= 0.5\n+    x *= 2.\n+    return x\n+\n+\n class DepthwiseConv2D(Conv2D):\n     \"\"\"Depthwise separable 2D convolution.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d9255f15a4db9bb231a039ff963a07fb4625e542", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 837 | Contributors (this commit): 2 | Commits (past 90d): 8 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -76,7 +76,7 @@ from ..applications.imagenet_utils import decode_predictions\n from .. import backend as K\n \n \n-BASE_WEIGHT_PATH = 'https://github.com/titu1994/MobileNetworks/releases/download/v1.0/'\n+BASE_WEIGHT_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.6/'\n \n \n def relu6(x):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4de120f051cd21ea7b7f11ec72b4606a1577fd4d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 578 | Contributors (this commit): 4 | Commits (past 90d): 3 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -458,7 +458,7 @@ def _compute_fans(shape, data_format='channels_last'):\n             fan_in = shape[1] * receptive_field_size\n             fan_out = shape[0] * receptive_field_size\n         elif data_format == 'channels_last':\n-            receptive_field_size = np.prod(shape[:2])\n+            receptive_field_size = np.prod(shape[:-2])\n             fan_in = shape[-2] * receptive_field_size\n             fan_out = shape[-1] * receptive_field_size\n         else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#59cd1c3994153a66084b00fadcafad2af5a15dd7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 2333 | Contributors (this commit): 15 | Commits (past 90d): 13 | Contributors (cumulative): 18 | DMM Complexity: None\n\nDIFF:\n@@ -443,7 +443,7 @@ def train(run_name, start_epoch, stop_epoch, img_w):\n     # cuts down input size going into RNN:\n     inner = Dense(time_dense_size, activation=act, name='dense1')(inner)\n \n-    # Two layers of bidirecitonal GRUs\n+    # Two layers of bidirectional GRUs\n     # GRU seems to work as well, if not better than LSTM:\n     gru_1 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru1')(inner)\n     gru_1b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru1_b')(inner)\n\n@@ -583,7 +583,7 @@ class TestBackend(object):\n             assert_allclose(zero_list[i], z_list[i], atol=1e-05)\n             assert_allclose(zero_list[i + 1], zero_list[i + 1], atol=1e-05)\n \n-    # cntk currently not support funciton in this way, so can't test as this\n+    # cntk currently not support function in this way, so can't test as this\n     def test_function(self):\n         test_backend = [KTH, KTF]\n         val = np.random.random((4, 2))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#985c4410141cda5d28c2ac0abb6341d6d0d4c4ca", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 27 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 4/2 | Churn Δ: 28 | Churn Cumulative: 5344 | Contributors (this commit): 57 | Commits (past 90d): 26 | Contributors (cumulative): 59 | DMM Complexity: 0.5555555555555556\n\nDIFF:\n@@ -579,7 +579,18 @@ def _standardize_weights(y, sample_weight=None, class_weight=None,\n             y_classes = np.reshape(y, y.shape[0])\n         else:\n             y_classes = y\n-        weights = np.asarray([class_weight[cls] for cls in y_classes])\n+\n+        weights = np.asarray([class_weight[cls] for cls in y_classes\n+                              if cls in class_weight])\n+\n+        if len(weights) != len(y_classes):\n+            # subtract the sets to pick all missing classes\n+            existing_classes = set(y_classes)\n+            existing_class_weight = set(class_weight.keys())\n+            raise ValueError('`class_weight` must contain all classes in the data.'\n+                             ' The classes %s exist in the data but not in '\n+                             '`class_weight`.'\n+                             % (existing_classes - existing_class_weight))\n         return weights\n     else:\n         if sample_weight_mode is None:\n\n@@ -148,5 +148,20 @@ def test_sequential_temporal_sample_weights():\n     assert(score < standard_score_sequential)\n \n \n+@keras_test\n+def test_class_weight_wrong_classes():\n+    model = create_sequential_model()\n+    model.compile(loss=loss, optimizer='rmsprop')\n+\n+    (x_train, y_train), (x_test, y_test), (sample_weight, class_weight, test_ids) = _get_test_data()\n+\n+    del class_weight[1]\n+    try:\n+        model.fit(x_train, y_train, epochs=0, verbose=0, class_weight=class_weight)\n+        assert False\n+    except ValueError:\n+        pass  # expected behavior is to raise a ValueError with a suitable message\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bcc68e90406cc53a2887a4cebb253ce96d95117c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 2288 | Contributors (this commit): 29 | Commits (past 90d): 8 | Contributors (cumulative): 29 | DMM Complexity: None\n\nDIFF:\n@@ -365,8 +365,9 @@ class ImageDataGenerator(object):\n         horizontal_flip: whether to randomly flip images horizontally.\n         vertical_flip: whether to randomly flip images vertically.\n         rescale: rescaling factor. If None or 0, no rescaling is applied,\n-            otherwise we multiply the data by the value provided\n-            (before applying any other transformation).\n+            otherwise we multiply the data by the value provided. This is\n+            applied after the `preprocessing_function` (if any provided)\n+            but before any other transformation.\n         preprocessing_function: function that will be implied on each input.\n             The function will run before any other modification on it.\n             The function should take one argument:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3fe78376913cfa310a13990589d312d47440399d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 497 | Contributors (this commit): 5 | Commits (past 90d): 1 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -313,7 +313,7 @@ def make_deeper_student_model(teacher_model, train_data,\n     # add another fc layer to make original fc1 deeper\n     if init == 'net2deeper':\n         # net2deeper for fc layer with relu, is just an identity initializer\n-        model.add(Dense(64, init='identity',\n+        model.add(Dense(64, kernel_initializer='identity',\n                         activation='relu', name='fc1-deeper'))\n     elif init == 'random-init':\n         model.add(Dense(64, activation='relu', name='fc1-deeper'))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#205c61178d10089cbe0fbc90950dbe0cb9d380dc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 22 | Lines Deleted: 22 | Files Changed: 7 | Hunks: 17 | Methods Changed: 6 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 44 | Churn Cumulative: 30054 | Contributors (this commit): 183 | Commits (past 90d): 114 | Contributors (cumulative): 306 | DMM Complexity: None\n\nDIFF:\n@@ -42,7 +42,7 @@ the 100 % MobileNet on various input sizes:\n ------------------------------------------------------------------------\n \n The weights for all 16 models are obtained and translated\n-from Tensorflow checkpoints found at\n+from TensorFlow checkpoints found at\n https://github.com/tensorflow/models/blob/master/slim/nets/mobilenet_v1.md\n \n # Reference\n@@ -364,7 +364,7 @@ def MobileNet(input_shape=None,\n     \"\"\"\n \n     if K.backend() != 'tensorflow':\n-        raise RuntimeError('Only Tensorflow backend is currently supported, '\n+        raise RuntimeError('Only TensorFlow backend is currently supported, '\n                            'as other backends do not support '\n                            'depthwise convolution.')\n \n\n@@ -374,10 +374,10 @@ def is_keras_tensor(x):\n     ```python\n         >>> from keras import backend as K\n         >>> np_var = numpy.array([1, 2])\n-        >>> K.is_keras_tensor(np_var) # A numpy array is not a symbolic yensor.\n+        >>> K.is_keras_tensor(np_var) # A numpy array is not a symbolic tensor.\n         ValueError\n         >>> k_var = tf.placeholder('float32', shape=(1,1))\n-        >>> K.is_keras_tensor(k_var) # A variable created directly from tensorflow/theano is not a Keras tensor.\n+        >>> K.is_keras_tensor(k_var) # A variable indirectly created outside of keras is not a Keras tensor.\n         False\n         >>> keras_var = K.variable(np_var)\n         >>> K.is_keras_tensor(keras_var)  # A variable created with the keras backend is a Keras tensor.\n@@ -2287,7 +2287,7 @@ def function(inputs, outputs, updates=None, **kwargs):\n     if kwargs:\n         for key in kwargs:\n             if not (has_arg(tf.Session.run, key, True) or has_arg(Function.__init__, key, True)):\n-                msg = 'Invalid argument \"%s\" passed to K.function with Tensorflow backend' % key\n+                msg = 'Invalid argument \"%s\" passed to K.function with TensorFlow backend' % key\n                 raise ValueError(msg)\n     return Function(inputs, outputs, updates=updates, **kwargs)\n \n@@ -3127,7 +3127,7 @@ def conv2d(x, kernel, strides=(1, 1), padding='valid',\n         strides: strides tuple.\n         padding: string, `\"same\"` or `\"valid\"`.\n         data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n-            Whether to use Theano or TensorFlow data format\n+            Whether to use Theano or TensorFlow/CNTK data format\n             for inputs/kernels/outputs.\n         dilation_rate: tuple of 2 integers.\n \n@@ -3168,7 +3168,7 @@ def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n         strides: strides tuple.\n         padding: string, `\"same\"` or `\"valid\"`.\n         data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n-            Whether to use Theano or TensorFlow data format\n+            Whether to use Theano or TensorFlow/CNTK data format\n             for inputs/kernels/outputs.\n \n     # Returns\n@@ -3276,7 +3276,7 @@ def conv3d(x, kernel, strides=(1, 1, 1), padding='valid',\n         strides: strides tuple.\n         padding: string, `\"same\"` or `\"valid\"`.\n         data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n-            Whether to use Theano or TensorFlow data format\n+            Whether to use Theano or TensorFlow/CNTK data format\n             for inputs/kernels/outputs.\n         dilation_rate: tuple of 3 integers.\n \n@@ -3317,7 +3317,7 @@ def conv3d_transpose(x, kernel, output_shape, strides=(1, 1, 1),\n         strides: strides tuple.\n         padding: string, \"same\" or \"valid\".\n         data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n-            Whether to use Theano or TensorFlow data format\n+            Whether to use Theano or TensorFlow/CNTK data format\n             for inputs/kernels/outputs.\n \n     # Returns\n\n@@ -1894,8 +1894,8 @@ def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n \n     if padding == 'same' and kernel_shape[0] % 2 == 0:\n         raise ValueError('In `Conv2DTranspose`, with padding mode `same`, '\n-                         'even kernel sizes are only supported with Tensorflow. '\n-                         'With Theano, set `kernel_size` to an odd number.')\n+                         'even kernel sizes are not supported with Theano. '\n+                         'You can set `kernel_size` to an odd number.')\n \n     kernel_shape = _preprocess_conv2d_filter_shape(kernel_shape, data_format)\n \n@@ -2005,8 +2005,8 @@ def conv3d_transpose(x, kernel, output_shape, strides=(1, 1, 1),\n \n     if padding == 'same' and kernel_shape[0] % 2 == 0:\n         raise ValueError('In `Conv3DTranspose`, with padding mode `same`, '\n-                         'even kernel sizes are only supported with Tensorflow. '\n-                         'With Theano, set `kernel_size` to an odd number.')\n+                         'even kernel sizes are not supported with Theano. '\n+                         'You can set `kernel_size` to an odd number.')\n \n     kernel_shape = _preprocess_conv3d_filter_shape(kernel_shape, data_format)\n \n\n@@ -637,8 +637,8 @@ class Model(Container):\n                 If the model has multiple outputs, you can use a different\n                 `sample_weight_mode` on each output by passing a\n                 dictionary or a list of modes.\n-            **kwargs: when using the Theano backend, these arguments\n-                are passed into K.function. When using the Tensorflow backend,\n+            **kwargs: when using the Theano/CNTK backends, these arguments\n+                are passed into K.function. When using the TensorFlow backend,\n                 these arguments are passed into `tf.Session.run`.\n \n         # Raises\n\n@@ -758,9 +758,9 @@ class Sequential(Model):\n             sample_weight_mode: if you need to do timestep-wise\n                 sample weighting (2D weights), set this to \"temporal\".\n                 \"None\" defaults to sample-wise weights (1D).\n-            **kwargs: for Theano backend, these are passed into K.function.\n-                When using the Tensorflow backend, these are passed into\n-                `tf.Session.run`.\n+            **kwargs: for Theano/CNTK backends, these are passed into\n+                K.function. When using the TensorFlow backend, these are\n+                passed into `tf.Session.run`.\n \n         # Example\n             ```python\n\n@@ -171,7 +171,7 @@ def test_inceptionv3_pooling():\n \n @keras_test\n @pytest.mark.skipif((K.backend() != 'tensorflow'),\n-                    reason=\"MobileNets are supported only on Tensorflow\")\n+                    reason=\"MobileNets are supported only on TensorFlow\")\n def test_mobilenet():\n     model = applications.MobileNet(weights=None)\n     assert model.output_shape == (None, 1000)\n@@ -179,7 +179,7 @@ def test_mobilenet():\n \n @keras_test\n @pytest.mark.skipif((K.backend() != 'tensorflow'),\n-                    reason=\"MobileNets are supported only on Tensorflow\")\n+                    reason=\"MobileNets are supported only on TensorFlow\")\n def test_mobilenet_no_top():\n     model = applications.MobileNet(weights=None, include_top=False)\n     assert model.output_shape == (None, None, None, 1024)\n@@ -187,7 +187,7 @@ def test_mobilenet_no_top():\n \n @keras_test\n @pytest.mark.skipif((K.backend() != 'tensorflow'),\n-                    reason=\"MobileNets are supported only on Tensorflow\")\n+                    reason=\"MobileNets are supported only on TensorFlow\")\n def test_mobilenet_pooling():\n     model = applications.MobileNet(weights=None, include_top=False, pooling='avg')\n     assert model.output_shape == (None, 1024)\n\n@@ -1396,7 +1396,7 @@ class TestBackend(object):\n         label_lens = np.expand_dims(np.asarray([5, 4]), 1)\n         input_lens = np.expand_dims(np.asarray([5, 5]), 1)  # number of timesteps\n \n-        # the Theano and Tensorflow CTC code use different methods to ensure\n+        # the Theano and TensorFlow CTC code use different methods to ensure\n         # numerical stability.  The Theano code subtracts out the max\n         # before the final log, so the results are different but scale\n         # identically and still train properly\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#94dbc3042f5a85b399f5ce2859d4e8fbafd235b9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 74 | Lines Deleted: 184 | Files Changed: 1 | Hunks: 25 | Methods Changed: 13 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 258 | Churn Cumulative: 1822 | Contributors (this commit): 11 | Commits (past 90d): 12 | Contributors (cumulative): 11 | DMM Complexity: 0.0\n\nDIFF:\n@@ -10,6 +10,9 @@ from keras.utils.conv_utils import convert_kernel\n from keras.backend import cntk_backend as KC\n \n BACKENDS = [KTH, KTF, KC]\n+# for special test cases of CNTK which treat dynamic axis\n+KCSD = 'CNTK_single_tensor_dynamicity'\n+KCTD = 'CNTK_two_tensor_dynamicity'\n \n \n def check_dtype(var, dtype):\n@@ -19,103 +22,65 @@ def check_dtype(var, dtype):\n         assert var.dtype.name == '%s_ref' % dtype\n \n \n+def cntk_func_single_tensor(function_name, x_shape, **kwargs):\n+    xc = KC.placeholder(x_shape)\n+    output_cntk = getattr(KC, function_name)(xc, **kwargs)\n+    return KC.function([xc], [output_cntk])\n+\n+\n+def cntk_func_two_tensor(function_name, x_shape, y, **kwargs):\n+    if type(y).__name__ == 'ndarray':\n+        xc = KC.placeholder(x_shape)\n+        output_cntk = getattr(KC, function_name)(xc, KC.variable(y), **kwargs)\n+        return KC.function([xc], [output_cntk])\n+    else:\n+        xc = KC.placeholder(ndim=len(x_shape))\n+        yc = KC.placeholder(y)\n+        output_cntk = getattr(KC, function_name)(xc, yc, **kwargs)\n+        return KC.function([xc, yc], [output_cntk])\n+\n+\n def check_single_tensor_operation(function_name, input_shape, backend_list, **kwargs):\n     val = np.random.random(input_shape) - 0.5\n-    x_list = [k.variable(val) for k in backend_list]\n \n     z_list = []\n-    for x, k in zip(x_list, backend_list):\n-        z_list.append(k.eval(getattr(k, function_name)(x, **kwargs)))\n+    for k in backend_list:\n+        if k == KCSD:\n+            z = cntk_func_single_tensor(function_name, input_shape,\n+                                        **kwargs)([val])[0]\n+        else:\n+            z = k.eval(getattr(k, function_name)(k.variable(val), **kwargs))\n+        if hasattr(z, '_keras_shape'):\n+            assert z._keras_shape == z.shape\n+        z_list += [z]\n \n-    for i in range(len(z_list) - 1):\n-        assert z_list[i].shape == z_list[i + 1].shape\n-        assert_allclose(z_list[i], z_list[i + 1], atol=1e-05)\n-        if hasattr(z_list[i], '_keras_shape'):\n-            assert z_list[i]._keras_shape == z_list[i].shape\n+    for (z1, z2) in zip(z_list[1:], z_list[:-1]):\n+        assert z1.shape == z2.shape\n+        assert_allclose(z1, z2, atol=1e-05)\n \n \n def check_two_tensor_operation(function_name, x_input_shape,\n                                y_input_shape, backend_list, **kwargs):\n     xval = np.random.random(x_input_shape) - 0.5\n-    x_list = [k.variable(xval) for k in backend_list]\n-\n     yval = np.random.random(y_input_shape) - 0.5\n \n-    y_list = [k.variable(yval) for k in backend_list]\n-\n     z_list = []\n-    for x, y, k in zip(x_list, y_list, backend_list):\n-        z_list.append(k.eval(getattr(k, function_name)(x, y, **kwargs)))\n+    for k in backend_list:\n+        if k == KCSD:\n+            z = cntk_func_two_tensor(function_name, x_input_shape,\n+                                     y=yval, **kwargs)([xval])[0]\n+        elif k == KCTD:\n+            z = cntk_func_two_tensor(function_name, x_input_shape,\n+                                     y=y_input_shape, **kwargs)([xval, yval])[0]\n+        else:\n+            z = k.eval(getattr(k, function_name)(k.variable(xval), k.variable(yval), **kwargs))\n+        if hasattr(z, '_keras_shape'):\n+            assert z._keras_shape == z.shape\n+        z_list += [z]\n \n-    for i in range(len(z_list) - 1):\n-        assert z_list[i].shape == z_list[i + 1].shape\n-        assert_allclose(z_list[i], z_list[i + 1], atol=1e-05)\n-        if hasattr(z_list[i], '_keras_shape'):\n-            assert z_list[i]._keras_shape == z_list[i].shape\n-\n-\n-def cntk_check_single_tensor_operation(function_name, input_shape, **kwargs):\n-    val = np.random.random(input_shape) - 0.5\n-    xtf = KTF.variable(val)\n-    xc = KC.placeholder(input_shape)\n-\n-    ztf = KTF.eval(getattr(KTF, function_name)(xtf, **kwargs))\n-\n-    output_cntk = getattr(KC, function_name)(xc, **kwargs)\n-    func_cntk = KC.function([xc], [output_cntk, ])\n-    zc = func_cntk([val])\n-    # Keras function return a list, take the first output\n-    assert len(zc) == 1\n-    zc = zc[0]\n-\n-    assert ztf.shape == zc.shape\n-    assert_allclose(ztf, zc, atol=1e-05)\n-\n-\n-def cntk_check_two_tensor_operation_with_batch(function_name, x_input_shape,\n-                                               y_input_shape, **kwargs):\n-    xval = np.random.random(x_input_shape) - 0.5\n-    xtf = KTF.variable(xval)\n-    xc = KC.placeholder(ndim=len(x_input_shape))\n-\n-    yval = np.random.random(y_input_shape) - 0.5\n-    ytf = KTF.variable(yval)\n-    yc = KC.placeholder(y_input_shape)\n-\n-    ztf = KTF.eval(getattr(KTF, function_name)(xtf, ytf, **kwargs))\n-\n-    output_cntk = getattr(KC, function_name)(xc, yc, **kwargs)\n-    func_cntk = KC.function([xc, yc], [output_cntk, ])\n-    zc = func_cntk([xval, yval])\n-    # Keras function return a list, take the first output\n-    assert len(zc) == 1\n-    zc = zc[0]\n-\n-    assert ztf.shape == zc.shape\n-    assert_allclose(ztf, zc, atol=1e-05)\n-\n-\n-def cntk_check_two_tensor_operation_with_single_batch(function_name, x_input_shape,\n-                                                      y_input_shape, **kwargs):\n-    xval = np.random.random(x_input_shape) - 0.5\n-    xtf = KTF.variable(xval)\n-    xc = KC.placeholder(x_input_shape)\n-\n-    yval = np.random.random(y_input_shape) - 0.5\n-    ytf = KTF.variable(yval)\n-    yc = KC.variable(yval)\n-\n-    ztf = KTF.eval(getattr(KTF, function_name)(xtf, ytf, **kwargs))\n-\n-    output_cntk = getattr(KC, function_name)(xc, yc, **kwargs)\n-    func_cntk = KC.function([xc, ], [output_cntk, ])\n-    zc = func_cntk([xval])\n-    # Keras function return a list, take the first output\n-    assert len(zc) == 1\n-    zc = zc[0]\n-\n-    assert ztf.shape == zc.shape\n-    assert_allclose(ztf, zc, atol=1e-05)\n+    for (z1, z2) in zip(z_list[1:], z_list[:-1]):\n+        assert z1.shape == z2.shape\n+        assert_allclose(z1, z2, atol=1e-05)\n \n \n def check_cross_entropy_with_valid_probability_distribution():\n@@ -198,58 +163,12 @@ class TestBackend(object):\n     def test_linear_operations(self):\n         check_two_tensor_operation('dot', (4, 2), (2, 4), BACKENDS)\n         check_two_tensor_operation('dot', (4, 2), (5, 2, 3), BACKENDS)\n-        # cntk doesn't support batch_dot with static axis as batch axis\n-        check_two_tensor_operation('batch_dot', (4, 2, 3), (4, 5, 3), [KTF, KTH], axes=(2, 2))\n-        check_two_tensor_operation('batch_dot', (4, 2, 3), (4, 3), [KTF, KTH], axes=(2, 1))\n-        check_two_tensor_operation('batch_dot', (4, 2), (4, 2, 3), [KTF, KTH], axes=(1, 1))\n-        check_two_tensor_operation('batch_dot', (32, 20), (32, 20), [KTF, KTH], axes=1)\n-        check_two_tensor_operation('batch_dot', (32, 20), (32, 20), [KTF, KTH], axes=(1, 1))\n-        # create special test case for CNTK which treat the first axis as dynamic axis\n-        cntk_check_two_tensor_operation_with_batch('batch_dot', (4, 2, 3), (4, 5, 3), axes=(2, 2))\n-        cntk_check_two_tensor_operation_with_batch('batch_dot', (4, 2, 3), (4, 3), axes=(2, 1))\n-        cntk_check_two_tensor_operation_with_batch('batch_dot', (4, 2), (4, 2, 3), axes=(1, 1))\n-        cntk_check_two_tensor_operation_with_batch('batch_dot', (32, 20), (32, 20), axes=1)\n-        cntk_check_two_tensor_operation_with_batch('batch_dot', (32, 20), (32, 20), axes=(1, 1))\n-        cntk_check_two_tensor_operation_with_single_batch('bias_add',\n-                                                          (20, 10, 6),\n-                                                          (6,),\n-                                                          data_format='channels_last')\n-        cntk_check_two_tensor_operation_with_single_batch('bias_add',\n-                                                          (20, 6, 10),\n-                                                          (6,),\n-                                                          data_format='channels_first')\n-        cntk_check_two_tensor_operation_with_single_batch('bias_add',\n-                                                          (20, 10, 20, 5),\n-                                                          (5,),\n-                                                          data_format='channels_last')\n-        cntk_check_two_tensor_operation_with_single_batch('bias_add',\n-                                                          (20, 5, 10, 20),\n-                                                          (5,),\n-                                                          data_format='channels_first')\n-        cntk_check_two_tensor_operation_with_single_batch('bias_add',\n-                                                          (40, 10, 30, 20, 8),\n-                                                          (8,),\n-                                                          data_format='channels_last')\n-        cntk_check_two_tensor_operation_with_single_batch('bias_add',\n-                                                          (40, 8, 10, 30, 20),\n-                                                          (8,),\n-                                                          data_format='channels_first')\n-        cntk_check_two_tensor_operation_with_single_batch('bias_add',\n-                                                          (40, 8),\n-                                                          (8,),\n-                                                          data_format='channels_last')\n-        cntk_check_two_tensor_operation_with_single_batch('bias_add',\n-                                                          (40, 8),\n-                                                          (8,),\n-                                                          data_format='channels_first')\n-        cntk_check_two_tensor_operation_with_single_batch('bias_add',\n-                                                          (20, 10, 6),\n-                                                          (10, 6),\n-                                                          data_format='channels_last')\n-        cntk_check_two_tensor_operation_with_single_batch('bias_add',\n-                                                          (20, 6, 10),\n-                                                          (10, 6),\n-                                                          data_format='channels_first')\n+\n+        check_two_tensor_operation('batch_dot', (4, 2, 3), (4, 5, 3), [KTF, KTH, KCTD], axes=(2, 2))\n+        check_two_tensor_operation('batch_dot', (4, 2, 3), (4, 3), [KTF, KTH, KCTD], axes=(2, 1))\n+        check_two_tensor_operation('batch_dot', (4, 2), (4, 2, 3), [KTF, KTH, KCTD], axes=(1, 1))\n+        check_two_tensor_operation('batch_dot', (32, 20), (32, 20), [KTF, KTH, KCTD], axes=1)\n+        check_two_tensor_operation('batch_dot', (32, 20), (32, 20), [KTF, KTH, KCTD], axes=(1, 1))\n \n         check_single_tensor_operation('transpose', (4, 2), BACKENDS)\n         # cntk doesn't support reverse yet\n@@ -304,10 +223,7 @@ class TestBackend(object):\n                                       pattern=(2, 0, 1))\n         check_single_tensor_operation('repeat', (4, 1), BACKENDS, n=3)\n         check_single_tensor_operation('flatten', (4, 1), BACKENDS)\n-        # cntk need create batch as dynamic axis, so can't test in this way\n-        check_single_tensor_operation('batch_flatten', (20, 2, 5), [KTH, KTF])\n-        # create special test case for CNTK which treat the first axis as dynamic axis\n-        cntk_check_single_tensor_operation('batch_flatten', (20, 2, 5))\n+        check_single_tensor_operation('batch_flatten', (20, 2, 5), [KTH, KTF, KCSD])\n         check_single_tensor_operation('expand_dims', (4, 3), BACKENDS, axis=-1)\n         check_single_tensor_operation('expand_dims', (4, 3, 2), BACKENDS, axis=1)\n         check_single_tensor_operation('squeeze', (4, 3, 1), BACKENDS, axis=2)\n@@ -315,14 +231,6 @@ class TestBackend(object):\n         check_composed_tensor_operations('reshape', {'shape': (4, 3, 1, 1)},\n                                          'squeeze', {'axis': 2},\n                                          (4, 3, 1, 1), BACKENDS)\n-        cntk_check_single_tensor_operation('resize_images', (20, 3, 40, 40),\n-                                           height_factor=2,\n-                                           width_factor=3,\n-                                           data_format='channels_first')\n-        cntk_check_single_tensor_operation('resize_images', (20, 40, 40, 3),\n-                                           height_factor=3,\n-                                           width_factor=2,\n-                                           data_format='channels_last')\n         check_single_tensor_operation('temporal_padding',\n                                       (4, 3, 3),\n                                       BACKENDS)\n@@ -1129,57 +1037,31 @@ class TestBackend(object):\n         assert_allclose(ztf, zc, atol=1e-05)\n \n     def test_pool2d(self):\n-        # cntk need pooling on dynamic axes, can't test in this way, is coverred in a seperate case\n-        check_single_tensor_operation('pool2d', (5, 10, 12, 3), [KTH, KTF], pool_size=(2, 2),\n+        check_single_tensor_operation('pool2d', (5, 10, 12, 3), [KTH, KTF, KCSD], pool_size=(2, 2),\n                                       strides=(1, 1), padding='valid')\n \n-        cntk_check_single_tensor_operation('pool2d', (5, 10, 12, 3), pool_size=(2, 2),\n+        check_single_tensor_operation('pool2d', (5, 9, 11, 3), [KTH, KTF, KCSD], pool_size=(2, 2),\n                                       strides=(1, 1), padding='valid')\n \n-        check_single_tensor_operation('pool2d', (5, 9, 11, 3), [KTH, KTF], pool_size=(2, 2),\n-                                      strides=(1, 1), padding='valid')\n-\n-        check_single_tensor_operation('pool2d', (5, 9, 11, 3), [KTH, KTF], pool_size=(2, 2),\n+        check_single_tensor_operation('pool2d', (5, 9, 11, 3), [KTH, KTF, KCSD], pool_size=(2, 2),\n                                       strides=(1, 1), pool_mode='avg')\n \n-        cntk_check_single_tensor_operation('pool2d', (5, 9, 11, 3), pool_size=(2, 2),\n+        check_single_tensor_operation('pool2d', (5, 9, 11, 3), [KTH, KTF, KCSD], pool_size=(2, 3),\n                                       strides=(1, 1), padding='valid')\n \n-        check_single_tensor_operation('pool2d', (5, 9, 11, 3), [KTH, KTF], pool_size=(2, 3),\n-                                      strides=(1, 1), padding='valid')\n-\n-        cntk_check_single_tensor_operation('pool2d', (5, 9, 11, 3), pool_size=(2, 3),\n-                                           strides=(1, 1), padding='valid')\n-\n-        cntk_check_single_tensor_operation('pool2d', (5, 9, 11, 3), pool_size=(2, 3),\n-                                           strides=(1, 1), pool_mode='avg')\n-\n     def test_pool3d(self):\n-        # cntk need pooling on dynamic axes, can't test in this way, is coverred in a seperate case\n-        check_single_tensor_operation('pool3d', (5, 10, 12, 5, 3), [KTH, KTF], pool_size=(2, 2, 2),\n+        check_single_tensor_operation('pool3d', (5, 10, 12, 5, 3), [KTH, KTF, KCSD], pool_size=(2, 2, 2),\n                                       strides=(1, 1, 1), padding='valid')\n \n-        cntk_check_single_tensor_operation('pool3d', (5, 10, 12, 5, 3), pool_size=(2, 2, 2),\n+        check_single_tensor_operation('pool3d', (5, 9, 11, 5, 3), [KTH, KTF, KCSD], pool_size=(2, 2, 2),\n                                       strides=(1, 1, 1), padding='valid')\n \n-        check_single_tensor_operation('pool3d', (5, 9, 11, 5, 3), [KTH, KTF], pool_size=(2, 2, 2),\n-                                      strides=(1, 1, 1), padding='valid')\n-\n-        check_single_tensor_operation('pool3d', (5, 9, 11, 5, 3), [KTH, KTF], pool_size=(2, 2, 2),\n+        check_single_tensor_operation('pool3d', (5, 9, 11, 5, 3), [KTH, KTF, KCSD], pool_size=(2, 2, 2),\n                                       strides=(1, 1, 1), pool_mode='avg')\n \n-        cntk_check_single_tensor_operation('pool3d', (5, 9, 11, 5, 3), pool_size=(2, 2, 2),\n+        check_single_tensor_operation('pool3d', (5, 9, 11, 5, 3), [KTH, KTF, KCSD], pool_size=(2, 3, 2),\n                                       strides=(1, 1, 1), padding='valid')\n \n-        check_single_tensor_operation('pool3d', (5, 9, 11, 5, 3), [KTH, KTF], pool_size=(2, 3, 2),\n-                                      strides=(1, 1, 1), padding='valid')\n-\n-        cntk_check_single_tensor_operation('pool3d', (5, 9, 11, 5, 3), pool_size=(2, 3, 2),\n-                                           strides=(1, 1, 1), padding='valid')\n-\n-        cntk_check_single_tensor_operation('pool3d', (5, 9, 11, 5, 3), pool_size=(2, 3, 2),\n-                                           strides=(1, 1, 1), pool_mode='avg')\n-\n         check_single_tensor_operation('pool3d', (2, 6, 6, 6, 3), [KTH, KTF], pool_size=(3, 3, 3),\n                                       strides=(1, 1, 1), padding='same', pool_mode='avg')\n \n@@ -1278,7 +1160,7 @@ class TestBackend(object):\n             elif data_format == 'channels_last':\n                 x_shape = (2,) + shape + (3,)\n             check_single_tensor_operation('resize_images', x_shape,\n-                                          BACKENDS,\n+                                          [KTH, KTF, KCSD],\n                                           height_factor=2,\n                                           width_factor=2,\n                                           data_format=data_format)\n@@ -1356,14 +1238,22 @@ class TestBackend(object):\n \n     def test_bias_add(self):\n         for data_format in ['channels_first', 'channels_last']:\n-            for shape in [(3,), (2, 3), (5, 3, 2)]:\n+            for shape in [(), (3,), (2, 3), (5, 3, 2)]:\n                 if data_format == 'channels_first':\n                     x_shape = (1, 4) + shape\n                 else:\n                     x_shape = (1,) + shape + (4,)\n                 bias_shape = (4,)\n                 check_two_tensor_operation('bias_add', x_shape, bias_shape,\n-                                           [KTH, KTF],\n+                                           [KTH, KTF, KCSD],\n+                                           data_format=data_format)\n+\n+            if data_format == 'channels_first':\n+                x_shape = (20, 6, 10)\n+            else:\n+                x_shape = (20, 10, 6)\n+            check_two_tensor_operation('bias_add', x_shape, (10, 6),\n+                                       [KTH, KTF, KCSD],\n                                        data_format=data_format)\n \n         # Test invalid use casess\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cebf2084ebb0a603383ceb6807653921796cd095", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 6 | Churn Cumulative: 2294 | Contributors (this commit): 30 | Commits (past 90d): 9 | Contributors (cumulative): 30 | DMM Complexity: 0.0\n\nDIFF:\n@@ -527,11 +527,12 @@ class ImageDataGenerator(object):\n                               'first by calling `.fit(numpy_data)`.')\n         return x\n \n-    def random_transform(self, x):\n+    def random_transform(self, x, seed=None):\n         \"\"\"Randomly augment a single image tensor.\n \n         # Arguments\n             x: 3D tensor, single image.\n+            seed: random seed.\n \n         # Returns\n             A randomly transformed version of the input (same shape).\n@@ -541,6 +542,9 @@ class ImageDataGenerator(object):\n         img_col_axis = self.col_axis - 1\n         img_channel_axis = self.channel_axis - 1\n \n+        if seed is not None:\n+            np.random.seed(seed)\n+\n         # use composition of homographies\n         # to generate final transform that needs to be applied\n         if self.rotation_range:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cad3d1e7d999d083ce31687e6576963cbd79dc28", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 32 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 5 | Methods Changed: 6 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 34 | Churn Cumulative: 882 | Contributors (this commit): 7 | Commits (past 90d): 8 | Contributors (cumulative): 7 | DMM Complexity: 1.0\n\nDIFF:\n@@ -4,6 +4,7 @@ from __future__ import print_function\n \n import hashlib\n import multiprocessing\n+import multiprocessing.managers\n import os\n import random\n import shutil\n@@ -352,11 +353,37 @@ class Sequence(object):\n         raise NotImplementedError\n \n \n+class HolderManager(multiprocessing.managers.BaseManager):\n+    \"\"\"Custom manager to share a Holder object.\"\"\"\n+    pass\n+\n+\n+class Holder(object):\n+    \"\"\"Object to encapsulate a Sequence.\n+\n+    This allows the Sequence to be shared across multiple workers.\n+\n+    # Arguments\n+        seq: Sequence object to be shared.\n+    \"\"\"\n+    def __init__(self, seq):\n+        self.seq = seq\n+\n+    def __getitem__(self, idx):\n+        return self.seq[idx]\n+\n+    def __len__(self):\n+        return len(self.seq)\n+\n+# Register the Holder class using the ListProxy (allows __len__ and __getitem__)\n+HolderManager.register('Holder', Holder, multiprocessing.managers.ListProxy)\n+\n+\n def get_index(ds, i):\n     \"\"\"Quick fix for Python2, otherwise, it cannot be pickled.\n \n     # Arguments\n-        ds: a Sequence object\n+        ds: a Holder or Sequence object\n         i: index\n \n     # Returns\n@@ -440,7 +467,9 @@ class OrderedEnqueuer(SequenceEnqueuer):\n     def __init__(self, sequence,\n                  use_multiprocessing=False,\n                  scheduling='sequential'):\n-        self.sequence = sequence\n+        self.manager = HolderManager()\n+        self.manager.start()\n+        self.sequence = self.manager.Holder(sequence)\n         self.use_multiprocessing = use_multiprocessing\n         self.scheduling = scheduling\n         self.workers = 0\n@@ -517,6 +546,7 @@ class OrderedEnqueuer(SequenceEnqueuer):\n         self.executor.close()\n         self.executor.join()\n         self.run_thread.join(timeout)\n+        self.manager.shutdown()\n \n \n class GeneratorEnqueuer(SequenceEnqueuer):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
