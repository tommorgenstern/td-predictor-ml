{"custom_id": "keras#fbc4f37037a29bfda9e07fcc265a431a7fbc84b3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 255 | Contributors (this commit): 5 | Commits (past 90d): 4 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -38,7 +38,7 @@ print('X_test shape:', X_test.shape)\n \n print('Build model...')\n model = Sequential()\n-model.add(Embedding(max_features, 128, input_length=maxlen, dropout=0.2))\n+model.add(Embedding(max_features, 128, dropout=0.2))\n model.add(LSTM(128, dropout_W=0.2, dropout_U=0.2))  # try using a GRU instead, for fun\n model.add(Dense(1))\n model.add(Activation('sigmoid'))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ee8fd78383462327f65579bae46d9f82051fc81a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 463 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -31,6 +31,7 @@ class LocallyConnected1D(Layer):\n         model.add(LocallyConnected1D(32, 3))\n         # now model.output_shape == (None, 6, 32)\n     ```\n+\n     # Arguments\n         nb_filter: Dimensionality of the output.\n         filter_length: The extension (spatial or temporal) of each filter.\n@@ -65,8 +66,10 @@ class LocallyConnected1D(Layer):\n             This argument is required if you are going to connect\n             `Flatten` then `Dense` layers upstream\n             (without it, the shape of the dense outputs cannot be computed).\n+\n     # Input shape\n         3D tensor with shape: `(samples, steps, input_dim)`.\n+\n     # Output shape\n         3D tensor with shape: `(samples, new_steps, nb_filter)`.\n         `steps` value might have changed due to padding.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#534f6b7975dcd334f6d68eef14598d75c79e7921", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 36 | Files Changed: 1 | Hunks: 2 | Methods Changed: 3 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 37 | Churn Cumulative: 218 | Contributors (this commit): 1 | Commits (past 90d): 5 | Contributors (cumulative): 1 | DMM Complexity: 0.0\n\nDIFF:\n@@ -15,41 +15,6 @@ from keras.models import save_model, load_model\n \n @keras_test\n def test_sequential_model_saving():\n-    model = Sequential()\n-    model.add(Dense(2, input_dim=3))\n-    model.add(Dense(3))\n-    model.compile(loss='mse', optimizer='rmsprop', metrics=['acc'])\n-\n-    x = np.random.random((1, 3))\n-    y = np.random.random((1, 3))\n-    model.train_on_batch(x, y)\n-\n-    out = model.predict(x)\n-    fname = 'tmp_' + str(np.random.randint(10000)) + '.h5'\n-    save_model(model, fname)\n-\n-    new_model = load_model(fname)\n-\n-    out2 = new_model.predict(x)\n-    assert_allclose(out, out2, atol=1e-05)\n-\n-    # test that new updates are the same with both models\n-    x = np.random.random((1, 3))\n-    y = np.random.random((1, 3))\n-    model.train_on_batch(x, y)\n-    new_model.train_on_batch(x, y)\n-    out = model.predict(x)\n-    out2 = new_model.predict(x)\n-    assert_allclose(out, out2, atol=1e-05)\n-\n-    # test load_weights on model file\n-    model.load_weights(fname)\n-    os.remove(fname)\n-\n-\n-@keras_test\n-def test_sequential_model_saving_2():\n-    # test with funkier config\n     model = Sequential()\n     model.add(Dense(2, input_dim=3))\n     model.add(RepeatVector(3))\n@@ -83,7 +48,7 @@ def test_sequential_model_saving_2():\n \n \n @keras_test\n-def test_sequential_model_saving_3():\n+def test_sequential_model_saving_2():\n     # test with custom optimizer, loss\n     custom_opt = optimizers.rmsprop\n     custom_loss = objectives.mse\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4984c5fc7cb28efccfdcde4d14470924ea62792c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 884 | Contributors (this commit): 4 | Commits (past 90d): 7 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -214,7 +214,6 @@ PAGES = [\n         'all_module_classes': [wrappers],\n     },\n \n-\n     {\n         'page': 'optimizers.md',\n         'all_module_classes': [optimizers],\n\n@@ -0,0 +1,4 @@\n+from .vgg16 import VGG16\n+from .vgg19 import VGG19\n+from .resnet50 import ResNet50\n+from .inception_v3 import InceptionV3\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ca37e806b90f10b7fe23de0f70c4a3e407c0f9a4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 12705 | Contributors (this commit): 63 | Commits (past 90d): 31 | Contributors (cumulative): 73 | DMM Complexity: None\n\nDIFF:\n@@ -721,8 +721,6 @@ class SeparableConvolution2D(Layer):\n             Also called strides elsewhere.\n         depth_multiplier: how many output channel to use per input channel\n             for the depthwise convolution step.\n-        atrous_rate: tuple of length 2. Factor for kernel dilation.\n-            Also called filter_dilation elsewhere.\n         depthwise_regularizer: instance of [WeightRegularizer](../regularizers.md)\n             (eg. L1 or L2 regularization), applied to the depthwise weights matrix.\n         pointwise_regularizer: instance of [WeightRegularizer](../regularizers.md)\n\n@@ -877,7 +877,7 @@ class Sequential(Model):\n         '''Evaluates the model on a data generator. The generator should\n         return the same kind of data as accepted by `test_on_batch`.\n \n-        Arguments:\n+        # Arguments\n             generator:\n                 generator yielding tuples (inputs, targets)\n                 or (inputs, targets, sample_weights)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#065fb2a74ccde5f411483df9cfa1e95c64800c73", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 164 | Lines Deleted: 15 | Files Changed: 3 | Hunks: 9 | Methods Changed: 9 | Complexity Δ (Sum/Max): 16/15 | Churn Δ: 179 | Churn Cumulative: 2625 | Contributors (this commit): 12 | Commits (past 90d): 21 | Contributors (cumulative): 15 | DMM Complexity: 1.0\n\nDIFF:\n@@ -65,6 +65,7 @@ if sys.version[0] == '2':\n     sys.setdefaultencoding('utf8')\n \n from keras.layers import convolutional\n+from keras.layers import pooling\n from keras.layers import local\n from keras.layers import recurrent\n from keras.layers import core\n@@ -165,12 +166,16 @@ PAGES = [\n     {\n         'page': 'layers/pooling.md',\n         'classes': [\n-            convolutional.MaxPooling1D,\n-            convolutional.MaxPooling2D,\n-            convolutional.MaxPooling3D,\n-            convolutional.AveragePooling1D,\n-            convolutional.AveragePooling2D,\n-            convolutional.AveragePooling3D,\n+            pooling.MaxPooling1D,\n+            pooling.MaxPooling2D,\n+            pooling.MaxPooling3D,\n+            pooling.AveragePooling1D,\n+            pooling.AveragePooling2D,\n+            pooling.AveragePooling3D,\n+            pooling.GlobalMaxPooling1D,\n+            pooling.GlobalAveragePooling1D,\n+            pooling.GlobalMaxPooling2D,\n+            pooling.GlobalAveragePooling2D,\n         ],\n     },\n     {\n\n@@ -398,3 +398,125 @@ class AveragePooling3D(_Pooling3D):\n         output = K.pool3d(inputs, pool_size, strides,\n                           border_mode, dim_ordering, pool_mode='avg')\n         return output\n+\n+\n+class _GlobalPooling1D(Layer):\n+\n+    def __init__(self, **kwargs):\n+        super(_GlobalPooling1D, self).__init__(**kwargs)\n+        self.input_spec = [InputSpec(ndim=3)]\n+\n+    def get_output_shape_for(self, input_shape):\n+        return (input_shape[0], input_shape[2])\n+\n+    def call(self, x, mask=None):\n+        raise NotImplementedError\n+\n+\n+class GlobalAveragePooling1D(_GlobalPooling1D):\n+    '''Global average pooling operation for temporal data.\n+\n+    # Input shape\n+        3D tensor with shape: `(samples, steps, features)`.\n+\n+    # Output shape\n+        2D tensor with shape: `(samples, features)`.\n+    '''\n+\n+    def call(self, x, mask=None):\n+        return K.mean(x, axis=1)\n+\n+\n+class GlobalMaxPooling1D(_GlobalPooling1D):\n+    '''Global max pooling operation for temporal data.\n+\n+    # Input shape\n+        3D tensor with shape: `(samples, steps, features)`.\n+\n+    # Output shape\n+        2D tensor with shape: `(samples, features)`.\n+    '''\n+\n+    def call(self, x, mask=None):\n+        return K.max(x, axis=1)\n+\n+\n+class _GlobalPooling2D(Layer):\n+\n+    def __init__(self, dim_ordering='default', **kwargs):\n+        super(_GlobalPooling2D, self).__init__(**kwargs)\n+        if dim_ordering == 'default':\n+            dim_ordering = K.image_dim_ordering()\n+        print(dim_ordering)\n+        self.dim_ordering = dim_ordering\n+        self.input_spec = [InputSpec(ndim=4)]\n+\n+    def get_output_shape_for(self, input_shape):\n+        if self.dim_ordering == 'tf':\n+            return (input_shape[0], input_shape[3])\n+        else:\n+            return (input_shape[0], input_shape[1])\n+\n+    def call(self, x, mask=None):\n+        raise NotImplementedError\n+\n+    def get_config(self):\n+        config = {'dim_ordering': self.dim_ordering}\n+        base_config = super(_GlobalPooling2D, self).get_config()\n+        return dict(list(base_config.items()) + list(config.items()))\n+\n+\n+class GlobalAveragePooling2D(_GlobalPooling2D):\n+    '''Global average pooling operation for spatial data.\n+\n+    # Arguments\n+        dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension\n+            (the depth) is at index 1, in 'tf' mode is it at index 3.\n+            It defaults to the `image_dim_ordering` value found in your\n+            Keras config file at `~/.keras/keras.json`.\n+            If you never set it, then it will be \"th\".\n+\n+    # Input shape\n+        4D tensor with shape:\n+        `(samples, channels, rows, cols)` if dim_ordering='th'\n+        or 4D tensor with shape:\n+        `(samples, rows, cols, channels)` if dim_ordering='tf'.\n+\n+    # Output shape\n+        2D tensor with shape:\n+        `(nb_samples, channels)`\n+    '''\n+\n+    def call(self, x, mask=None):\n+        if self.dim_ordering == 'tf':\n+            return K.mean(x, axis=[1, 2])\n+        else:\n+            return K.mean(x, axis=[2, 3])\n+\n+\n+class GlobalMaxPooling2D(_GlobalPooling2D):\n+    '''Global max pooling operation for spatial data.\n+\n+    # Arguments\n+        dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension\n+            (the depth) is at index 1, in 'tf' mode is it at index 3.\n+            It defaults to the `image_dim_ordering` value found in your\n+            Keras config file at `~/.keras/keras.json`.\n+            If you never set it, then it will be \"th\".\n+\n+    # Input shape\n+        4D tensor with shape:\n+        `(samples, channels, rows, cols)` if dim_ordering='th'\n+        or 4D tensor with shape:\n+        `(samples, rows, cols, channels)` if dim_ordering='tf'.\n+\n+    # Output shape\n+        2D tensor with shape:\n+        `(nb_samples, channels)`\n+    '''\n+\n+    def call(self, x, mask=None):\n+        if self.dim_ordering == 'tf':\n+            return K.max(x, axis=[1, 2])\n+        else:\n+            return K.max(x, axis=[2, 3])\n\n@@ -5,7 +5,7 @@ from numpy.testing import assert_allclose\n from keras.utils.test_utils import layer_test, keras_test\n from keras.utils.np_utils import conv_input_length\n from keras import backend as K\n-from keras.layers import convolutional\n+from keras.layers import convolutional, pooling\n \n \n @keras_test\n@@ -206,6 +206,30 @@ def test_separable_conv_2d():\n                            input_shape=(nb_samples, stack_size, nb_row, nb_col))\n \n \n+@keras_test\n+def test_globalpooling_1d():\n+    layer_test(pooling.GlobalMaxPooling1D,\n+               input_shape=(3, 4, 5))\n+    layer_test(pooling.GlobalAveragePooling1D,\n+               input_shape=(3, 4, 5))\n+\n+\n+@keras_test\n+def test_globalpooling_2d():\n+    layer_test(pooling.GlobalMaxPooling2D,\n+               kwargs={'dim_ordering': 'th'},\n+               input_shape=(3, 4, 5, 6))\n+    layer_test(pooling.GlobalMaxPooling2D,\n+               kwargs={'dim_ordering': 'tf'},\n+               input_shape=(3, 5, 6, 4))\n+    layer_test(pooling.GlobalAveragePooling2D,\n+               kwargs={'dim_ordering': 'th'},\n+               input_shape=(3, 4, 5, 6))\n+    layer_test(pooling.GlobalAveragePooling2D,\n+               kwargs={'dim_ordering': 'tf'},\n+               input_shape=(3, 5, 6, 4))\n+\n+\n @keras_test\n def test_maxpooling_2d():\n     pool_size = (3, 3)\n@@ -455,11 +479,12 @@ def test_cropping_1d():\n                kwargs={'cropping': (2, 2)},\n                input_shape=input.shape)\n \n+\n def test_cropping_2d():\n     nb_samples = 2\n     stack_size = 2\n-    input_len_dim1 = 10\n-    input_len_dim2 = 20\n+    input_len_dim1 = 8\n+    input_len_dim2 = 8\n     cropping = ((2, 2), (3, 3))\n     dim_ordering = K.image_dim_ordering()\n \n@@ -495,9 +520,9 @@ def test_cropping_2d():\n def test_cropping_3d():\n     nb_samples = 2\n     stack_size = 2\n-    input_len_dim1 = 10\n-    input_len_dim2 = 20\n-    input_len_dim3 = 30\n+    input_len_dim1 = 8\n+    input_len_dim2 = 8\n+    input_len_dim3 = 8\n     cropping = ((2, 2), (3, 3), (2, 3))\n     dim_ordering = K.image_dim_ordering()\n \n@@ -531,8 +556,5 @@ def test_cropping_3d():\n \n     assert_allclose(out, expected_out)\n \n-\n-def test_cropping_3d():\n-    pass\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9e58b8237bce22e7c2bc625c6820b288c3887890", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2688 | Contributors (this commit): 30 | Commits (past 90d): 48 | Contributors (cumulative): 30 | DMM Complexity: None\n\nDIFF:\n@@ -993,7 +993,7 @@ def gradients(loss, variables):\n     '''Returns the gradients of `variables` (list of tensor variables)\n     with regard to `loss`.\n     '''\n-    return tf.gradients(loss, variables)\n+    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)\n \n \n def stop_gradient(variables):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9c28d21b4f89260cde311099195fd0d8e21f6f56", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 10551 | Contributors (this commit): 50 | Commits (past 90d): 10 | Contributors (cumulative): 50 | DMM Complexity: None\n\nDIFF:\n@@ -484,7 +484,7 @@ class Lambda(Layer):\n \n     # Arguments\n         function: The function to be evaluated.\n-            Takes one argument: the output of previous layer\n+            Takes input tensor as first argument.\n         output_shape: Expected output shape from function.\n             Can be a tuple or function.\n             If a tuple, it only specifies the first dimension onward; \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d5649da5f80af3a7ca7593e5419630123e4dc471", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 10555 | Contributors (this commit): 51 | Commits (past 90d): 11 | Contributors (cumulative): 51 | DMM Complexity: None\n\nDIFF:\n@@ -492,8 +492,8 @@ class Lambda(Layer):\n                  `output_shape = (input_shape[0], ) + output_shape`\n                  or, the input is `None` and the sample dimension is also `None`:\n                  `output_shape = (None, ) + output_shape`\n-            If a function, it specifies the entire shape as a function of \n-                 the input shape: `output_shape = f(input_shape)`\n+            If a function, it specifies the entire shape as a function of the\n+            input shape: `output_shape = f(input_shape)`\n         arguments: optional dictionary of keyword arguments to be passed\n             to the function.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3a4c683d5c83b53d401f0eef6d930a23ad3db7d7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 792 | Contributors (this commit): 7 | Commits (past 90d): 2 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -95,7 +95,7 @@ def vectorize_stories(data, word_idx, story_maxlen, query_maxlen):\n \n \n try:\n-    path = get_file('babi-tasks-v1-2.tar.gz', origin='http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2.tar.gz')\n+    path = get_file('babi-tasks-v1-2.tar.gz', origin='https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz')\n except:\n     print('Error downloading dataset, please download it manually:\\n'\n           '$ wget http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2.tar.gz\\n'\n\n@@ -147,7 +147,7 @@ EPOCHS = 40\n print('RNN / Embed / Sent / Query = {}, {}, {}, {}'.format(RNN, EMBED_HIDDEN_SIZE, SENT_HIDDEN_SIZE, QUERY_HIDDEN_SIZE))\n \n try:\n-    path = get_file('babi-tasks-v1-2.tar.gz', origin='http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2.tar.gz')\n+    path = get_file('babi-tasks-v1-2.tar.gz', origin='https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz')\n except:\n     print('Error downloading dataset, please download it manually:\\n'\n           '$ wget http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2.tar.gz\\n'\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#109441a7086a3431db286a78bf8b745ba4b791ac", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2329 | Contributors (this commit): 35 | Commits (past 90d): 29 | Contributors (cumulative): 35 | DMM Complexity: None\n\nDIFF:\n@@ -646,7 +646,7 @@ def batch_set_value(tuples):\n \n \n def get_variable_shape(x):\n-    return x.get_value().shape\n+    return x.get_value(borrow=True, return_internal_type=True).shape\n \n \n def print_tensor(x, message=''):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c478409dadb4a9c33fd5481efbdcaa06a5f8c4f0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 2 | Churn Cumulative: 3224 | Contributors (this commit): 21 | Commits (past 90d): 25 | Contributors (cumulative): 21 | DMM Complexity: None\n\nDIFF:\n@@ -1950,7 +1950,7 @@ class Container(Layer):\n         cons = {}\n         for layer in self.layers:\n             for key, value in layer.constraints.items():\n-                if key in cons:\n+                if key in cons and cons[key] != value:\n                     raise Exception('Received multiple constraints '\n                                     'for one weight tensor: ' + str(key))\n                 cons[key] = value\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7ae36d132ab20c6ce7853f89259411458d10227e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 1638 | Contributors (this commit): 25 | Commits (past 90d): 12 | Contributors (cumulative): 25 | DMM Complexity: None\n\nDIFF:\n@@ -471,11 +471,11 @@ class TensorBoard(Callback):\n             layers = self.model.layers\n             for layer in layers:\n                 if hasattr(layer, 'W'):\n-                    tf.histogram_summary('{}_W'.format(layer), layer.W)\n+                    tf.histogram_summary('{}_W'.format(layer.name), layer.W)\n                 if hasattr(layer, 'b'):\n-                    tf.histogram_summary('{}_b'.format(layer), layer.b)\n+                    tf.histogram_summary('{}_b'.format(layer.name), layer.b)\n                 if hasattr(layer, 'output'):\n-                    tf.histogram_summary('{}_out'.format(layer),\n+                    tf.histogram_summary('{}_out'.format(layer.name),\n                                          layer.output)\n         self.merged = tf.merge_all_summaries()\n         if self.write_graph:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c939cebf0d73cf97a91d1ed46eb0446b6cd3e28f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 4367 | Contributors (this commit): 28 | Commits (past 90d): 10 | Contributors (cumulative): 28 | DMM Complexity: 0.0\n\nDIFF:\n@@ -31,9 +31,11 @@ def time_distributed_dense(x, w, b=None, dropout=None,\n     if b:\n         x = x + b\n     # reshape to 3D tensor\n-    x = K.reshape(x, K.pack([-1, timesteps, output_dim]))\n     if K.backend() == 'tensorflow':\n+        x = K.reshape(x, K.pack([-1, timesteps, output_dim]))\n         x.set_shape([None, None, output_dim])\n+    else:\n+        x = K.reshape(x, (-1, timesteps, output_dim))\n     return x\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6417d90d5c1f70844d8d346312f1b40f449545a5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 49 | Lines Deleted: 32 | Files Changed: 3 | Hunks: 16 | Methods Changed: 7 | Complexity Δ (Sum/Max): 7/11 | Churn Δ: 81 | Churn Cumulative: 14027 | Contributors (this commit): 68 | Commits (past 90d): 40 | Contributors (cumulative): 85 | DMM Complexity: 1.0\n\nDIFF:\n@@ -5,8 +5,6 @@ from __future__ import division\n \n import numpy as np\n \n-import sys\n-import marshal\n import types as python_types\n import warnings\n import copy\n@@ -15,6 +13,7 @@ from six.moves import zip\n \n from .. import backend as K\n from ..utils.io_utils import ask_to_proceed_with_overwrite\n+from ..utils.generic_utils import func_dump, func_load\n \n \n def to_list(x):\n@@ -1414,13 +1413,8 @@ class Merge(Layer):\n             raise Exception('Invalid merge mode: {}'.format(self.mode))\n \n     def get_config(self):\n-        py3 = sys.version_info[0] == 3\n-\n         if isinstance(self.mode, python_types.LambdaType):\n-            if py3:\n-                mode = marshal.dumps(self.mode.__code__).decode('raw_unicode_escape')\n-            else:\n-                mode = marshal.dumps(self.mode.func_code).decode('raw_unicode_escape')\n+            mode = func_dump(self.mode)\n             mode_type = 'lambda'\n         elif callable(self.mode):\n             mode = self.mode.__name__\n@@ -1430,10 +1424,7 @@ class Merge(Layer):\n             mode_type = 'raw'\n \n         if isinstance(self._output_shape, python_types.LambdaType):\n-            if py3:\n-                output_shape = marshal.dumps(self._output_shape.__code__).decode('raw_unicode_escape')\n-            else:\n-                output_shape = marshal.dumps(self._output_shape.func_code).decode('raw_unicode_escape')\n+            output_shape = func_dump(self._output_shape)\n             output_shape_type = 'lambda'\n         elif callable(self._output_shape):\n             output_shape = self._output_shape.__name__\n@@ -1456,8 +1447,7 @@ class Merge(Layer):\n         if mode_type == 'function':\n             mode = globals()[config['mode']]\n         elif mode_type == 'lambda':\n-            mode = marshal.loads(config['mode'].encode('raw_unicode_escape'))\n-            mode = python_types.FunctionType(mode, globals())\n+            mode = func_load(config['mode'], globs=globals())\n         else:\n             mode = config['mode']\n \n@@ -1465,8 +1455,7 @@ class Merge(Layer):\n         if output_shape_type == 'function':\n             output_shape = globals()[config['output_shape']]\n         elif output_shape_type == 'lambda':\n-            output_shape = marshal.loads(config['output_shape'].encode('raw_unicode_escape'))\n-            output_shape = python_types.FunctionType(output_shape, globals())\n+            output_shape = func_load(config['output_shape'], globs=globals())\n         else:\n             output_shape = config['output_shape']\n \n\n@@ -7,14 +7,13 @@ import numpy as np\n import copy\n import inspect\n import types as python_types\n-import marshal\n-import sys\n import warnings\n \n from .. import backend as K\n from .. import activations, initializations, regularizers, constraints\n from ..engine import InputSpec, Layer, Merge\n from ..regularizers import ActivityRegularizer\n+from ..utils.generic_utils import func_dump, func_load\n \n \n class Masking(Layer):\n@@ -554,23 +553,15 @@ class Lambda(Layer):\n         return self.function(x, **arguments)\n \n     def get_config(self):\n-        py3 = sys.version_info[0] == 3\n-\n         if isinstance(self.function, python_types.LambdaType):\n-            if py3:\n-                function = marshal.dumps(self.function.__code__).decode('raw_unicode_escape')\n-            else:\n-                function = marshal.dumps(self.function.func_code).decode('raw_unicode_escape')\n+            function = func_dump(self.function)\n             function_type = 'lambda'\n         else:\n             function = self.function.__name__\n             function_type = 'function'\n \n         if isinstance(self._output_shape, python_types.LambdaType):\n-            if py3:\n-                output_shape = marshal.dumps(self._output_shape.__code__).decode('raw_unicode_escape')\n-            else:\n-                output_shape = marshal.dumps(self._output_shape.func_code).decode('raw_unicode_escape')\n+            output_shape = func_dump(self._output_shape)\n             output_shape_type = 'lambda'\n         elif callable(self._output_shape):\n             output_shape = self._output_shape.__name__\n@@ -593,8 +584,7 @@ class Lambda(Layer):\n         if function_type == 'function':\n             function = globals()[config['function']]\n         elif function_type == 'lambda':\n-            function = marshal.loads(config['function'].encode('raw_unicode_escape'))\n-            function = python_types.FunctionType(function, globals())\n+            function = func_load(config['function'], globs=globals())\n         else:\n             raise Exception('Unknown function type: ' + function_type)\n \n@@ -602,8 +592,7 @@ class Lambda(Layer):\n         if output_shape_type == 'function':\n             output_shape = globals()[config['output_shape']]\n         elif output_shape_type == 'lambda':\n-            output_shape = marshal.loads(config['output_shape'].encode('raw_unicode_escape'))\n-            output_shape = python_types.FunctionType(output_shape, globals())\n+            output_shape = func_load(config['output_shape'], globs=globals())\n         else:\n             output_shape = config['output_shape']\n \n\n@@ -3,6 +3,8 @@ import numpy as np\n import time\n import sys\n import six\n+import marshal\n+import types as python_types\n \n \n def get_from_module(identifier, module_params, module_name,\n@@ -33,6 +35,43 @@ def make_tuple(*args):\n     return args\n \n \n+def func_dump(func):\n+    '''Serialize user defined function.'''\n+    code = marshal.dumps(func.__code__).decode('raw_unicode_escape')\n+    defaults = func.__defaults__\n+    if func.__closure__:\n+        closure = tuple(c.cell_contents for c in func.__closure__)\n+    else:\n+        closure = None\n+    return code, defaults, closure\n+\n+\n+def func_load(code, defaults=None, closure=None, globs=None):\n+    '''Deserialize user defined function.'''\n+    if isinstance(code, (tuple, list)):  # unpack previous dump\n+        code, defaults, closure = code\n+    code = marshal.loads(code.encode('raw_unicode_escape'))\n+    if closure is not None:\n+        closure = func_reconstruct_closure(closure)\n+    if globs is None:\n+        globs = globals()\n+    return python_types.FunctionType(code, globs, name=code.co_name, argdefs=defaults, closure=closure)\n+\n+\n+def func_reconstruct_closure(values):\n+    '''Deserialization helper that reconstructs a closure.'''\n+    nums = range(len(values))\n+    src = [\"def func(arg):\"]\n+    src += [\"  _%d = arg[%d]\" % (n, n) for n in nums]\n+    src += [\"  return lambda:(%s)\" % ','.join([\"_%d\" % n for n in nums]), \"\"]\n+    src = '\\n'.join(src)\n+    try:\n+        exec(src)\n+    except:\n+        raise SyntaxError(src)\n+    return func(values).__closure__\n+\n+\n class Progbar(object):\n     def __init__(self, target, width=30, verbose=1, interval=0.01):\n         '''\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1bf1055395bf3c12f0f14f04a5645ffd3fc45f5e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 899 | Contributors (this commit): 5 | Commits (past 90d): 7 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -133,6 +133,8 @@ PAGES = [\n             core.Dense,\n             core.Activation,\n             core.Dropout,\n+            core.SpatialDropout2D,\n+            core.SpatialDropout3D,\n             core.Flatten,\n             core.Reshape,\n             core.Permute,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6f54b233f101323c55fc1d34696938713c2679b2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 5 | Files Changed: 5 | Hunks: 7 | Methods Changed: 5 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 11 | Churn Cumulative: 4104 | Contributors (this commit): 22 | Commits (past 90d): 35 | Contributors (cumulative): 26 | DMM Complexity: None\n\nDIFF:\n@@ -106,7 +106,7 @@ def InceptionV3(include_top=True, weights='imagenet',\n         img_input = Input(shape=input_shape)\n     else:\n         if not K.is_keras_tensor(input_tensor):\n-            img_input = Input(tensor=input_tensor)\n+            img_input = Input(tensor=input_tensor, shape=input_shape)\n         else:\n             img_input = input_tensor\n \n\n@@ -152,7 +152,7 @@ def ResNet50(include_top=True, weights='imagenet',\n         img_input = Input(shape=input_shape)\n     else:\n         if not K.is_keras_tensor(input_tensor):\n-            img_input = Input(tensor=input_tensor)\n+            img_input = Input(tensor=input_tensor, shape=input_shape)\n         else:\n             img_input = input_tensor\n     if K.image_dim_ordering() == 'tf':\n\n@@ -71,7 +71,7 @@ def VGG16(include_top=True, weights='imagenet',\n         img_input = Input(shape=input_shape)\n     else:\n         if not K.is_keras_tensor(input_tensor):\n-            img_input = Input(tensor=input_tensor)\n+            img_input = Input(tensor=input_tensor, shape=input_shape)\n         else:\n             img_input = input_tensor\n     # Block 1\n\n@@ -71,7 +71,7 @@ def VGG19(include_top=True, weights='imagenet',\n         img_input = Input(shape=input_shape)\n     else:\n         if not K.is_keras_tensor(input_tensor):\n-            img_input = Input(tensor=input_tensor)\n+            img_input = Input(tensor=input_tensor, shape=input_shape)\n         else:\n             img_input = input_tensor\n     # Block 1\n\n@@ -974,11 +974,11 @@ class InputLayer(Layer):\n                              'batch_input_shape argument to '\n                              'InputLayer, not both at the same time.')\n         if input_tensor is not None:\n-            if not input_shape and not batch_input_shape:\n             # attempt automatic input shape inference\n             try:\n                 batch_input_shape = K.int_shape(input_tensor)\n             except:\n+                if not input_shape and not batch_input_shape:\n                     raise ValueError('InputLayer was provided an input_tensor argument, '\n                                      'but its input shape cannot be automatically inferred. '\n                                      'You should pass an input_shape or batch_input_shape '\n@@ -1078,6 +1078,7 @@ def Input(shape=None, batch_shape=None,\n                        ' or a `batch_shape` argument. Note that ' +\n                        '`shape` does not include the batch '\n                        'dimension.')\n+    if shape and not batch_shape:\n         batch_shape = (None,) + tuple(shape)\n     input_layer = InputLayer(batch_input_shape=batch_shape,\n                              name=name, input_dtype=dtype,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#48ae7217e482a1a3624d6e5380c972a653cacfaf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2690 | Contributors (this commit): 31 | Commits (past 90d): 49 | Contributors (cumulative): 31 | DMM Complexity: None\n\nDIFF:\n@@ -1136,7 +1136,7 @@ def rnn(step_function, inputs, initial_states,\n \n         if mask is not None:\n             if go_backwards:\n-                mask = tf.reverse(mask, [True] + [False] * (ndim - 1))\n+                mask = tf.reverse(mask, [True] + [False] * (ndim - 2))\n \n             # Transpose not supported by bool tensor types, hence round-trip to uint8.\n             mask = tf.cast(mask, tf.uint8)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2321fbbc1d1168a281b59612d35419d15a6cb485", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 5 | Churn Cumulative: 2334 | Contributors (this commit): 36 | Commits (past 90d): 29 | Contributors (cumulative): 36 | DMM Complexity: 1.0\n\nDIFF:\n@@ -386,7 +386,10 @@ def normalize_batch_in_training(x, gamma, beta,\n def batch_normalization(x, mean, var, beta, gamma, epsilon=0.0001):\n     '''Apply batch normalization on x given mean, var, beta and gamma.\n     '''\n-    if theano.config.device.startswith('cuda') or theano.config.device.startswith('gpu'):\n+    ndim = x.ndim\n+    dev = theano.config.device\n+    use_cudnn = ndim < 5 and (dev.startswith('cuda') or dev.startswith('gpu'))\n+    if use_cudnn:\n         try:\n             return theano.sandbox.cuda.dnn.dnn_batch_normalization_test(x, gamma, beta, mean, var,\n                                                                         'spatial', epsilon)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#799bec66a2a812bb60f32f49bd8744dfa498fada", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 130 | Lines Deleted: 21 | Files Changed: 2 | Hunks: 11 | Methods Changed: 5 | Complexity Δ (Sum/Max): 4/5 | Churn Δ: 151 | Churn Cumulative: 3687 | Contributors (this commit): 34 | Commits (past 90d): 64 | Contributors (cumulative): 48 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,5 +1,9 @@\n import tensorflow as tf\n from tensorflow.python.training import moving_averages\n+try:\n+    import tensorflow.contrib.ctc as ctc\r\n+except ImportError:\n+    from tensorflow.python.ops import ctc_ops as ctc\r\n import numpy as np\n import os\n import copy\n@@ -1757,13 +1761,13 @@ def ctc_batch_cost(y_true, y_pred, input_length, label_length):\n \n     y_pred = tf.log(tf.transpose(y_pred, perm=[1, 0, 2]) + 1e-8)\n \n-    return tf.expand_dims(tf.contrib.ctc.ctc_loss(inputs=y_pred,\n+    return tf.expand_dims(ctc.ctc_loss(inputs=y_pred,\r\n                                        labels=sparse_labels,\r\n                                        sequence_length=input_length), 1)\r\n \n \n-def ctc_decode(y_pred, input_length, greedy=True, beam_width=None,\n-               dict_seq_lens=None, dict_values=None):\n+def ctc_decode(y_pred, input_length, greedy=True, beam_width=100,\n+               top_paths=1):\n     '''Decodes the output of a softmax using either\n        greedy (also known as best path) or a constrained dictionary\n        search.\n@@ -1771,38 +1775,33 @@ def ctc_decode(y_pred, input_length, greedy=True, beam_width=None,\n     # Arguments\n         y_pred: tensor (samples, time_steps, num_categories) containing the prediction,\n                 or output of the softmax\n-        input_length: tensor (samples,1) containing the sequence length for\n+        input_length: tensor (samples,) containing the sequence length for\n                 each batch item in y_pred\n         greedy: perform much faster best-path search if true.  This does\n                 not use a dictionary\n-        beam_width:  if greedy is false and this value is not none, then\n-                the constrained dictionary search uses a beam of this width\n-        dict_seq_lens: the length of each element in the dict_values list\n-        dict_values:  list of lists representing the dictionary.\n+        beam_width: if greedy is false: a beam search decoder will be used\n+                with a beam of this width\n+        top_paths: if greedy is false: how many of the most probable paths will be returned\n \n     # Returns\n-        Tensor with shape (samples,time_steps,num_categories) containing the\n-            path probabilities (in softmax output format).  Note that a function that\n-            pulls out the argmax and collapses blank labels is still needed.\n+        Tuple:\n+            List: if greedy is true, returns a list of one element that contains\n+                the decoded sequence. If false, returns the `top_paths` most probable\n+                decoded sequences. Important: blank labels are returned as -1\n+            Tensor (top_paths,) that contains the log probability of each decoded sequence\n     '''\n     y_pred = tf.log(tf.transpose(y_pred, perm=[1, 0, 2]) + 1e-8)\n-    input_length = tf.to_int32(tf.squeeze(input_length))\n+    input_length = tf.to_int32(input_length)\n \n     if greedy:\n-        (decoded, log_prob) = tf.contrib.ctc.ctc_greedy_decoder(\n+        (decoded, log_prob) = ctc.ctc_greedy_decoder(\r\n             inputs=y_pred,\n             sequence_length=input_length)\n     else:\n-        if beam_width is not None:\n-            (decoded, log_prob) = tf.contrib.ctc.ctc_beam_search_decoder(\n-                inputs=y_pred,\n-                sequence_length=input_length,\n-                dict_seq_lens=dict_seq_lens, dict_values=dict_values)\n-        else:\n-            (decoded, log_prob) = tf.contrib.ctc.ctc_beam_search_decoder(\n+        (decoded, log_prob) = ctc.ctc_beam_search_decoder(\r\n             inputs=y_pred,\n             sequence_length=input_length, beam_width=beam_width,\n-                dict_seq_lens=dict_seq_lens, dict_values=dict_values)\n+            top_paths=top_paths)\n \n     decoded_dense = [tf.sparse_to_dense(st.indices, st.shape, st.values, default_value=-1)\n                      for st in decoded]\n\n@@ -660,6 +660,116 @@ class TestBackend(object):\n         res = KTH.eval(KTH.ctc_batch_cost(labels_th, inputs_th, input_lens_th, label_lens_th))\n         assert_allclose(res[0, :], loss_log_probs_th, atol=1e-05)\n \n+    def test_ctc_decode_greedy(self):\n+        # Test adapted from tensorflow\n+        \"\"\"Test two batch entries - best path decoder.\"\"\"\n+        max_time_steps = 6\n+\n+        seq_len_0 = 4\n+        input_prob_matrix_0 = np.asarray(\n+            [[1.0, 0.0, 0.0, 0.0],  # t=0\n+             [0.0, 0.0, 0.4, 0.6],  # t=1\n+             [0.0, 0.0, 0.4, 0.6],  # t=2\n+             [0.0, 0.9, 0.1, 0.0],  # t=3\n+             [0.0, 0.0, 0.0, 0.0],  # t=4 (ignored)\n+             [0.0, 0.0, 0.0, 0.0]],  # t=5 (ignored)\n+            dtype=np.float32)\n+        input_log_prob_matrix_0 = np.log(input_prob_matrix_0)\n+\n+        seq_len_1 = 5\n+        # dimensions are time x depth\n+\n+        input_prob_matrix_1 = np.asarray(\n+            [[0.1, 0.9, 0.0, 0.0],  # t=0\n+             [0.0, 0.9, 0.1, 0.0],  # t=1\n+             [0.0, 0.0, 0.1, 0.9],  # t=2\n+             [0.0, 0.9, 0.1, 0.1],  # t=3\n+             [0.9, 0.1, 0.0, 0.0],  # t=4\n+             [0.0, 0.0, 0.0, 0.0]],  # t=5 (ignored)\n+            dtype=np.float32)\n+\n+        # len max_time_steps array of batch_size x depth matrices\n+        inputs = [np.vstack([input_prob_matrix_0[t, :],\n+                             input_prob_matrix_1[t, :]])\n+                  for t in range(max_time_steps)]\n+\n+        # change tensorflow order to keras backend order\n+        inputs = KTF.variable(np.asarray(inputs).transpose((1, 0, 2)))\n+        # batch_size length vector of sequence_lengths\n+        input_length = KTF.variable(np.array([seq_len_0, seq_len_1], dtype=np.int32))\n+\n+        # batch_size length vector of negative log probabilities\n+        log_prob_truth = np.array([\n+            np.sum(-np.log([1.0, 0.6, 0.6, 0.9])),\n+            np.sum(-np.log([0.9, 0.9, 0.9, 0.9, 0.9]))\n+        ], np.float32)[:, np.newaxis]\n+\n+        # keras output, unlike tensorflow, is a dense (not sparse) tensor\n+        decode_truth = np.array([[0, 1, -1], [1, 1, 0]])\n+\n+        decode_pred_tf, log_prob_pred_tf = KTF.ctc_decode(inputs,\n+                                                          input_length,\n+                                                          greedy=True)\n+\n+        assert len(decode_pred_tf) == 1\n+\n+        decode_pred = KTF.eval(decode_pred_tf[0])\n+        log_prob_pred = KTF.eval(log_prob_pred_tf)\n+\n+        assert np.alltrue(decode_truth == decode_pred)\n+        assert np.allclose(log_prob_truth, log_prob_pred)\n+\n+    def test_ctc_decode_beam_search(self):\n+        \"\"\"Test one batch, two beams - hibernating beam search.\"\"\"\n+\n+        depth = 6\n+\n+        seq_len_0 = 5\n+        input_prob_matrix_0 = np.asarray(\n+            [[0.30999, 0.309938, 0.0679938, 0.0673362, 0.0708352, 0.173908],\n+             [0.215136, 0.439699, 0.0370931, 0.0393967, 0.0381581, 0.230517],\n+             [0.199959, 0.489485, 0.0233221, 0.0251417, 0.0233289, 0.238763],\n+             [0.279611, 0.452966, 0.0204795, 0.0209126, 0.0194803, 0.20655],\n+             [0.51286, 0.288951, 0.0243026, 0.0220788, 0.0219297, 0.129878],\n+             # Random entry added in at time=5\n+             [0.155251, 0.164444, 0.173517, 0.176138, 0.169979, 0.160671]],\n+            dtype=np.float32)\n+\n+        # len max_time_steps array of batch_size x depth matrices\n+        inputs = ([input_prob_matrix_0[t, :][np.newaxis, :]\n+                  for t in range(seq_len_0)] +  # Pad to max_time_steps = 8\n+                  2 * [np.zeros((1, depth), dtype=np.float32)])\n+\n+        inputs = KTF.variable(np.asarray(inputs).transpose((1, 0, 2)))\n+\n+        # batch_size length vector of sequence_lengths\n+        input_length = KTF.variable(np.array([seq_len_0], dtype=np.int32))\n+        # batch_size length vector of negative log probabilities\n+        log_prob_truth = np.array([\n+            0.584855,  # output beam 0\n+            0.389139  # output beam 1\n+        ], np.float32)[np.newaxis, :]\n+\n+        decode_truth = [np.array([1, 0]), np.array([0, 1, 0])]\n+\n+        beam_width = 2\n+        top_paths = 2\n+\n+        decode_pred_tf, log_prob_pred_tf = KTF.ctc_decode(inputs,\n+                                                          input_length,\n+                                                          greedy=False,\n+                                                          beam_width=beam_width,\n+                                                          top_paths=top_paths)\n+\n+        assert len(decode_pred_tf) == top_paths\n+\n+        log_prob_pred = KTF.eval(log_prob_pred_tf)\n+\n+        for i in range(top_paths):\n+            assert np.alltrue(decode_truth[i] == KTF.eval(decode_pred_tf[i]))\n+\n+        assert np.allclose(log_prob_truth, log_prob_pred)\n+\n     def test_one_hot(self):\n         input_length = 10\n         nb_classes = 20\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#870d7f7f936bab348589d8d0bcc4d252c6ed832f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 3 | Churn Cumulative: 10579 | Contributors (this commit): 52 | Commits (past 90d): 12 | Contributors (cumulative): 52 | DMM Complexity: 0.0\n\nDIFF:\n@@ -537,6 +537,9 @@ class Lambda(Layer):\n             # otherwise, we default to the input shape\n             return input_shape\n         elif type(self._output_shape) in {tuple, list}:\n+            if type(input_shape) is list:\n+                nb_samples = input_shape[0][0]\n+            else:\n                 nb_samples = input_shape[0] if input_shape else None\n             return (nb_samples,) + tuple(self._output_shape)\n         else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f90cbcd1e3e4fd21c2e91bd89933d689514a557c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 24 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 8 | Methods Changed: 5 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 27 | Churn Cumulative: 932 | Contributors (this commit): 15 | Commits (past 90d): 13 | Contributors (cumulative): 17 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,5 +1,5 @@\n from ..engine import Layer, InputSpec\n-from .. import initializations\n+from .. import initializations, regularizers\n from .. import backend as K\n \n \n@@ -44,6 +44,10 @@ class BatchNormalization(Layer):\n             [initializations](../initializations.md)), or alternatively,\n             Theano/TensorFlow function to use for weights initialization.\n             This parameter is only relevant if you don't pass a `weights` argument.\n+        gamma_regularizer: instance of [WeightRegularizer](../regularizers.md)\n+            (eg. L1 or L2 regularization), applied to the gamma vector.\n+        beta_regularizer: instance of [WeightRegularizer](../regularizers.md),\n+            applied to the beta vector.\n \n     # Input shape\n         Arbitrary. Use the keyword argument `input_shape`\n@@ -57,7 +61,8 @@ class BatchNormalization(Layer):\n         - [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](http://jmlr.org/proceedings/papers/v37/ioffe15.html)\n     '''\n     def __init__(self, epsilon=1e-5, mode=0, axis=-1, momentum=0.99,\n-                 weights=None, beta_init='zero', gamma_init='one', **kwargs):\n+                 weights=None, beta_init='zero', gamma_init='one',\n+                 gamma_regularizer=None, beta_regularizer=None, **kwargs):\n         self.supports_masking = True\n         self.beta_init = initializations.get(beta_init)\n         self.gamma_init = initializations.get(gamma_init)\n@@ -65,6 +70,8 @@ class BatchNormalization(Layer):\n         self.mode = mode\n         self.axis = axis\n         self.momentum = momentum\n+        self.gamma_regularizer = regularizers.get(gamma_regularizer)\n+        self.beta_regularizer = regularizers.get(beta_regularizer)\n         self.initial_weights = weights\n         if self.mode == 0:\n             self.uses_learning_phase = True\n@@ -78,6 +85,15 @@ class BatchNormalization(Layer):\n         self.beta = self.beta_init(shape, name='{}_beta'.format(self.name))\n         self.trainable_weights = [self.gamma, self.beta]\n \n+        self.regularizers = []\n+        if self.gamma_regularizer:\n+            self.gamma_regularizer.set_param(self.gamma)\n+            self.regularizers.append(self.gamma_regularizer)\n+\n+        if self.beta_regularizer:\n+            self.beta_regularizer.set_param(self.beta)\n+            self.regularizers.append(self.beta_regularizer)\n+\n         self.running_mean = K.zeros(shape,\n                                     name='{}_running_mean'.format(self.name))\n         self.running_std = K.ones(shape,\n@@ -155,6 +171,8 @@ class BatchNormalization(Layer):\n         config = {\"epsilon\": self.epsilon,\n                   \"mode\": self.mode,\n                   \"axis\": self.axis,\n+                  \"gamma_regularizer\": self.gamma_regularizer.get_config() if self.gamma_regularizer else None,\n+                  \"beta_regularizer\": self.beta_regularizer.get_config() if self.beta_regularizer else None,\n                   \"momentum\": self.momentum}\n         base_config = super(BatchNormalization, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n\n@@ -16,8 +16,11 @@ input_shapes = [np.ones((10, 10)), np.ones((10, 10, 10))]\n \n @keras_test\n def basic_batchnorm_test():\n+    from keras import regularizers\n     layer_test(normalization.BatchNormalization,\n-               kwargs={'mode': 1},\n+               kwargs={'mode': 1,\n+                       'gamma_regularizer': regularizers.l2(0.01),\n+                       'beta_regularizer': regularizers.l2(0.01)},\n                input_shape=(3, 4, 2))\n     layer_test(normalization.BatchNormalization,\n                kwargs={'mode': 0},\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
