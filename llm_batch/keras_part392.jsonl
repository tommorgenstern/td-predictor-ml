{"custom_id": "keras#8d06a12d90cbcfcde64a7776752fd050cc19af39", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): -4/0 | Churn Δ: 13 | Churn Cumulative: 10772 | Contributors (this commit): 102 | Commits (past 90d): 21 | Contributors (cumulative): 110 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1984,7 +1984,7 @@ class LearningRateScheduler(Callback):\n     if self.verbose > 0:\n       io_utils.print_msg(\n           f'\\nEpoch {epoch + 1}: LearningRateScheduler setting learning '\n-          'rate to {lr}.')\n+          f'rate to {lr}.')\n \n   def on_epoch_end(self, epoch, logs=None):\n     logs = logs or {}\n\n@@ -1329,15 +1329,20 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n           optimizer='sgd',\n           metrics=['accuracy'])\n \n-      cbks = [keras.callbacks.LearningRateScheduler(lambda x: 1. / (1. + x))]\n+      cbks = [\n+          keras.callbacks.LearningRateScheduler(\n+              lambda x: 1. / (1. + x), verbose=1)\n+      ]\n+      with self.captureWritesToStream(sys.stdout) as printed:\n         model.fit(\n             x_train,\n             y_train,\n             batch_size=BATCH_SIZE,\n             validation_data=(x_test, y_test),\n             callbacks=cbks,\n-          epochs=5,\n-          verbose=0)\n+            epochs=5)\n+        self.assertIn('LearningRateScheduler setting learning rate to 1.0',\n+                      printed.contents())\n       assert (\n           float(keras.backend.get_value(\n               model.optimizer.lr)) - 0.2) < keras.backend.epsilon()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#275565f24ca6a3ab74e20afb473ceb08b3638ef2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1585 | Lines Deleted: 1 | Files Changed: 3 | Hunks: 5 | Methods Changed: 41 | Complexity Δ (Sum/Max): 78/80 | Churn Δ: 1586 | Churn Cumulative: 1984 | Contributors (this commit): 5 | Commits (past 90d): 9 | Contributors (cumulative): 10 | DMM Complexity: 0.8727272727272727\n\nDIFF:\n@@ -29,6 +29,7 @@ from keras.applications import mobilenet\n from keras.applications import mobilenet_v2\n from keras.applications import mobilenet_v3\n from keras.applications import nasnet\n+from keras.applications import regnet\n from keras.applications import resnet\n from keras.applications import resnet_v2\n from keras.applications import vgg16\n@@ -69,7 +70,16 @@ ARG_TO_MODEL = {\n         efficientnet_v2.EfficientNetV2B2, efficientnet_v2.EfficientNetV2B3,\n         efficientnet_v2.EfficientNetV2S, efficientnet_v2.EfficientNetV2M,\n         efficientnet_v2.EfficientNetV2L\n-    ])\n+    ]),\n+    'regnet': (regnet,\n+        [regnet.RegNetX002, regnet.RegNetX004, regnet.RegNetX006,\n+         regnet.RegNetX008, regnet.RegNetX016, regnet.RegNetX032,\n+         regnet.RegNetX040, regnet.RegNetX064, regnet.RegNetX080,\n+         regnet.RegNetX120, regnet.RegNetX160, regnet.RegNetX320,\n+         regnet.RegNetY002, regnet.RegNetY004, regnet.RegNetY006,\n+         regnet.RegNetY008, regnet.RegNetY016, regnet.RegNetY032,\n+         regnet.RegNetY040, regnet.RegNetY064, regnet.RegNetY080,\n+         regnet.RegNetY120, regnet.RegNetY160, regnet.RegNetY320])\n }\n \n TEST_IMAGE_PATH = ('https://storage.googleapis.com/tensorflow/'\n\n@@ -28,6 +28,7 @@ from keras.applications import mobilenet\n from keras.applications import mobilenet_v2\n from keras.applications import mobilenet_v3\n from keras.applications import nasnet\n+from keras.applications import regnet\n from keras.applications import resnet\n from keras.applications import resnet_v2\n from keras.applications import vgg16\n@@ -69,6 +70,30 @@ MODEL_LIST_NO_NASNET = [\n     (efficientnet_v2.EfficientNetV2S, 1280),\n     (efficientnet_v2.EfficientNetV2M, 1280),\n     (efficientnet_v2.EfficientNetV2L, 1280),\n+    (regnet.RegNetX002, 368),\n+    (regnet.RegNetX004, 384),\n+    (regnet.RegNetX006, 528),\n+    (regnet.RegNetX008, 672),\n+    (regnet.RegNetX016, 912),\n+    (regnet.RegNetX032, 1008),\n+    (regnet.RegNetX040, 1360),\n+    (regnet.RegNetX064, 1624),\n+    (regnet.RegNetX080, 1920),\n+    (regnet.RegNetX120, 2240),\n+    (regnet.RegNetX160, 2048),\n+    (regnet.RegNetX320, 2520),\n+    (regnet.RegNetY002, 368),\n+    (regnet.RegNetY004, 440),\n+    (regnet.RegNetY006, 608),\n+    (regnet.RegNetY008, 768),\n+    (regnet.RegNetY016, 888),\n+    (regnet.RegNetY032, 1512),\n+    (regnet.RegNetY040, 1088),\n+    (regnet.RegNetY064, 1296),\n+    (regnet.RegNetY080, 2016),\n+    (regnet.RegNetY120, 2240),\n+    (regnet.RegNetY160, 3024),\n+    (regnet.RegNetY320, 3712)\n ]\n \n NASNET_LIST = [\n\n@@ -0,0 +1,1549 @@\n+# Copyright 2021 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+# pylint: disable=invalid-name\n+# pylint: disable=missing-docstring\n+\"\"\"RegNet models for Keras.\n+\n+References:\n+\n+- [Designing Network Design Spaces](https://arxiv.org/abs/2003.13678)\n+  (CVPR 2020)\n+- [Fast and Accurate Model Scaling](https://arxiv.org/abs/2103.06877)\n+  (CVPR 2021)\n+\"\"\"\n+\n+import tensorflow as tf\n+\n+from keras import backend\n+from keras import layers\n+from keras.applications import imagenet_utils\n+from keras.engine import training\n+from keras.utils import layer_utils\n+from keras.utils import data_utils\n+from tensorflow.python.util.tf_export import keras_export\n+\n+BASE_WEIGHTS_PATH = \"\"\n+\n+WEIGHTS_HASHES = {\n+    \"x002\": (\"\", \"\"),\n+    \"x004\": (\"\", \"\"),\n+    \"x006\": (\"\", \"\"),\n+    \"x008\": (\"\", \"\"),\n+    \"x016\": (\"\", \"\"),\n+    \"x032\": (\"\", \"\"),\n+    \"x040\": (\"\", \"\"),\n+    \"x064\": (\"\", \"\"),\n+    \"x080\": (\"\", \"\"),\n+    \"x120\": (\"\", \"\"),\n+    \"x160\": (\"\", \"\"),\n+    \"x320\": (\"\", \"\"),\n+    \"y002\": (\"\", \"\"),\n+    \"y004\": (\"\", \"\"),\n+    \"y006\": (\"\", \"\"),\n+    \"y008\": (\"\", \"\"),\n+    \"y016\": (\"\", \"\"),\n+    \"y032\": (\"\", \"\"),\n+    \"y040\": (\"\", \"\"),\n+    \"y064\": (\"\", \"\"),\n+    \"y080\": (\"\", \"\"),\n+    \"y120\": (\"\", \"\"),\n+    \"y160\": (\"\", \"\"),\n+    \"y320\": (\"\", \"\")\n+}\n+\n+# The widths and depths are deduced from a quantized linear function. For\n+# more information, please refer to \"Designing Network Design Spaces\" by\n+# Radosavovic et al.\n+\n+# BatchNorm momentum and epsilon values taken from original implementation.\n+\n+MODEL_CONFIGS = {\n+    \"x002\": {\n+        \"depths\": [1, 1, 4, 7],\n+        \"widths\": [24, 56, 152, 368],\n+        \"group_width\": 8,\n+        \"default_size\": 224\n+    },\n+    \"x004\": {\n+        \"depths\": [1, 2, 7, 12],\n+        \"widths\": [32, 64, 160, 384],\n+        \"group_width\": 16,\n+        \"default_size\": 224\n+    },\n+    \"x006\": {\n+        \"depths\": [1, 3, 5, 7],\n+        \"widths\": [48, 96, 240, 528],\n+        \"group_width\": 24,\n+        \"default_size\": 224\n+    },\n+    \"x008\": {\n+        \"depths\": [1, 3, 7, 5],\n+        \"widths\": [64, 128, 288, 672],\n+        \"group_width\": 16,\n+        \"default_size\": 224\n+    },\n+    \"x016\": {\n+        \"depths\": [2, 4, 10, 2],\n+        \"widths\": [72, 168, 408, 912],\n+        \"group_width\": 24,\n+        \"default_size\": 224\n+    },\n+    \"x032\": {\n+        \"depths\": [2, 6, 15, 2],\n+        \"widths\": [96, 192, 432, 1008],\n+        \"group_width\": 48,\n+        \"default_size\": 224\n+    },\n+    \"x040\": {\n+        \"depths\": [2, 5, 14, 2],\n+        \"widths\": [80, 240, 560, 1360],\n+        \"group_width\": 40,\n+        \"default_size\": 224\n+    },\n+    \"x064\": {\n+        \"depths\": [2, 4, 10, 1],\n+        \"widths\": [168, 392, 784, 1624],\n+        \"group_width\": 56,\n+        \"default_size\": 224\n+    },\n+    \"x080\": {\n+        \"depths\": [2, 5, 15, 1],\n+        \"widths\": [80, 240, 720, 1920],\n+        \"group_width\": 120,\n+        \"default_size\": 224\n+    },\n+    \"x120\": {\n+        \"depths\": [2, 5, 11, 1],\n+        \"widths\": [224, 448, 896, 2240],\n+        \"group_width\": 112,\n+        \"default_size\": 224\n+    },\n+    \"x160\": {\n+        \"depths\": [2, 6, 13, 1],\n+        \"widths\": [256, 512, 896, 2048],\n+        \"group_width\": 128,\n+        \"default_size\": 224\n+    },\n+    \"x320\": {\n+        \"depths\": [2, 7, 13, 1],\n+        \"widths\": [336, 672, 1344, 2520],\n+        \"group_width\": 168,\n+        \"default_size\": 224\n+    },\n+    \"y002\": {\n+        \"depths\": [1, 1, 4, 7],\n+        \"widths\": [24, 56, 152, 368],\n+        \"group_width\": 8,\n+        \"default_size\": 224\n+    },\n+    \"y004\": {\n+        \"depths\": [1, 3, 6, 6],\n+        \"widths\": [48, 104, 208, 440],\n+        \"group_width\": 8,\n+        \"default_size\": 224\n+    },\n+    \"y006\": {\n+        \"depths\": [1, 3, 7, 4],\n+        \"widths\": [48, 112, 256, 608],\n+        \"group_width\": 16,\n+        \"default_size\": 224\n+    },\n+    \"y008\": {\n+        \"depths\": [1, 3, 8, 2],\n+        \"widths\": [64, 128, 320, 768],\n+        \"group_width\": 16,\n+        \"default_size\": 224\n+    },\n+    \"y016\": {\n+        \"depths\": [2, 6, 17, 2],\n+        \"widths\": [48, 120, 336, 888],\n+        \"group_width\": 24,\n+        \"default_size\": 224\n+    },\n+    \"y032\": {\n+        \"depths\": [2, 5, 13, 1],\n+        \"widths\": [72, 216, 576, 1512],\n+        \"group_width\": 24,\n+        \"default_size\": 224\n+    },\n+    \"y040\": {\n+        \"depths\": [2, 6, 12, 2],\n+        \"widths\": [128, 192, 512, 1088],\n+        \"group_width\": 64,\n+        \"default_size\": 224\n+    },\n+    \"y064\": {\n+        \"depths\": [2, 7, 14, 2],\n+        \"widths\": [144, 288, 576, 1296],\n+        \"group_width\": 72,\n+        \"default_size\": 224\n+    },\n+    \"y080\": {\n+        \"depths\": [2, 4, 10, 1],\n+        \"widths\": [168, 448, 896, 2016],\n+        \"group_width\": 56,\n+        \"default_size\": 224\n+    },\n+    \"y120\": {\n+        \"depths\": [2, 5, 11, 1],\n+        \"widths\": [224, 448, 896, 2240],\n+        \"group_width\": 112,\n+        \"default_size\": 224\n+    },\n+    \"y160\": {\n+        \"depths\": [2, 4, 11, 1],\n+        \"widths\": [224, 448, 1232, 3024],\n+        \"group_width\": 112,\n+        \"default_size\": 224\n+    },\n+    \"y320\": {\n+        \"depths\": [2, 5, 12, 1],\n+        \"widths\": [232, 696, 1392, 3712],\n+        \"group_width\": 232,\n+        \"default_size\": 224\n+    }\n+}\n+\n+BASE_DOCSTRING = \"\"\"Instantiates Regnet architecture.\n+\n+  References:\n+    - [Designing Network Design Spaces](https://arxiv.org/abs/2003.13678)\n+    (CVPR 2020)\n+    - [Fast and Accurate Model Scaling](https://arxiv.org/abs/2103.06877)\n+    (CVPR 2021)\n+\n+  For image classification use cases, see\n+  [this page for detailed examples](\n+  https://keras.io/api/applications/#usage-examples-for-image-classification-models).\n+\n+  For transfer learning use cases, make sure to read the\n+  [guide to transfer learning & fine-tuning](\n+    https://keras.io/guides/transfer_learning/).\n+\n+  Note: Each Keras Application expects a specific kind of input preprocessing.\n+  For Regnets, preprocessing is included in the model using a `Rescaling` layer.\n+  RegNet models expect their inputs to be float or uint8 tensors of pixels with \n+  values in the [0-255] range.\n+\n+  The naming of models is as follows: `RegNet{block_type}{flops}` where \n+  `block_type` is one of `(Y, Z)` and `flops` signifies hundred million \n+  floating point operations. For example RegNetY64 corresponds to RegNet with \n+  Y block and 6.4 giga flops (64 hundred million flops). \n+\n+  Args:\n+    include_top: Whether to include the fully-connected\n+        layer at the top of the network. Defaults to True.\n+    weights: One of `None` (random initialization),\n+          \"imagenet\" (pre-training on ImageNet),\n+          or the path to the weights file to be loaded. Defaults to \"imagenet\".\n+    input_tensor: Optional Keras tensor\n+        (i.e. output of `layers.Input()`)\n+        to use as image input for the model.\n+    input_shape: Optional shape tuple, only to be specified\n+        if `include_top` is False.\n+        It should have exactly 3 inputs channels.\n+    pooling: Optional pooling mode for feature extraction\n+        when `include_top` is `False`. Defaults to None.\n+        - `None` means that the output of the model will be\n+            the 4D tensor output of the\n+            last convolutional layer.\n+        - `avg` means that global average pooling\n+            will be applied to the output of the\n+            last convolutional layer, and thus\n+            the output of the model will be a 2D tensor.\n+        - `max` means that global max pooling will\n+            be applied.\n+    classes: Optional number of classes to classify images\n+        into, only to be specified if `include_top` is True, and\n+        if no `weights` argument is specified. Defaults to 1000 (number of\n+        ImageNet classes).\n+    classifier_activation: A `str` or callable. The activation function to use\n+        on the \"top\" layer. Ignored unless `include_top=True`. Set\n+        `classifier_activation=None` to return the logits of the \"top\" layer.\n+        Defaults to \"softmax\".\n+        When loading pretrained weights, `classifier_activation` can only\n+        be `None` or `\"softmax\"`.\n+\n+  Returns:\n+    A `keras.Model` instance.\n+\"\"\"\n+\n+\n+def PreStem(name=None):\n+  \"\"\"\n+  Rescales and normalizes inputs to [0,1] and ImageNet mean and std.\n+  \n+  Args:\n+    name: name prefix\n+    \n+  Returns:\n+    Rescaled and normalized tensor\n+  \"\"\"\n+  if name is None:\n+    name = \"prestem\" + str(backend.get_uid(\"prestem\"))\n+\n+  def apply(x):\n+    x = layers.Rescaling(scale=1. / 255., name=name + \"_prestem_rescaling\")(x)\n+\n+    return x\n+\n+  return apply\n+\n+\n+def Stem(name=None):\n+  \"\"\"\n+  Implementation of RegNet stem. (Common to all model variants)\n+  \n+  Args:\n+    name: name prefix   \n+\n+  Returns:\n+    Output tensor of the Stem\n+  \"\"\"\n+  if name is None:\n+    name = \"stem\" + str(backend.get_uid(\"stem\"))\n+\n+  def apply(x):\n+    x = layers.Conv2D(32, (3, 3),\n+                      strides=2,\n+                      use_bias=False,\n+                      padding=\"same\",\n+                      kernel_initializer=\"he_normal\",\n+                      name=name + \"_stem_conv\")(x)\n+    x = layers.BatchNormalization(momentum=0.9,\n+                                  epsilon=1e-5,\n+                                  name=name + \"_stem_bn\")(x)\n+    x = layers.ReLU(name=name + \"_stem_relu\")(x)\n+\n+    return x\n+\n+  return apply\n+\n+\n+def SqueezeAndExciteBlock(filters_in, se_filters, name=None):\n+  \"\"\"\n+  Implements the Squeeze and excite block(https://arxiv.org/abs/1709.01507)\n+  \n+  Args:\n+    filters_in: input filters to the block\n+    se_filters: filters to squeeze to\n+    name: name prefix\n+  \n+  Returns:\n+    A function object   \n+  \"\"\"\n+  if name is None:\n+    name = str(backend.get_uid(\"squeeze_and_excite\"))\n+\n+  def apply(inputs):\n+    x = layers.GlobalAveragePooling2D(\n+        name=name + \"_squeeze_and_excite_gap\", keepdims=True)(inputs)\n+    x = layers.Conv2D(se_filters, (1, 1),\n+                      activation=\"relu\",\n+                      kernel_initializer=\"he_normal\",\n+                      name=name + \"_squeeze_and_excite_squeeze\")(x)\n+    x = layers.Conv2D(filters_in, (1, 1),\n+                      activation=\"sigmoid\",\n+                      kernel_initializer=\"he_normal\",\n+                      name=name + \"_squeeze_and_excite_excite\")(x)\n+    x = tf.math.multiply(x, inputs)\n+    return x\n+\n+  return apply\n+\n+\n+def XBlock(filters_in, filters_out, group_width, stride=1, name=None):\n+  \"\"\"\n+  Implementation of X Block. \n+  Reference: [Designing Network Design Spaces](https://arxiv.org/abs/2003.13678)\n+\n+  Args:\n+    filters_in: filters in the input tensor\n+    filters_out: filters in the output tensor\n+    group_width: group width\n+    stride: stride\n+    name: name prefix\n+\n+  Return:\n+    Output tensor of the block \n+  \"\"\"\n+  if name is None:\n+    name = str(backend.get_uid(\"xblock\"))\n+\n+  def apply(inputs):\n+    if filters_in != filters_out and stride == 1:\n+      raise ValueError(\n+          \"\"\"Input filters and output filters are not equal for stride\n+                          1. Please check inputs and try again.\"\"\")\n+\n+    # Declare layers\n+    groups = filters_out // group_width\n+\n+    if stride != 1:\n+      skip = layers.Conv2D(filters_out, (1, 1),\n+                           strides=stride,\n+                           use_bias=False,\n+                           kernel_initializer=\"he_normal\",\n+                           name=name + \"_skip_1x1\")(inputs)\n+      skip = layers.BatchNormalization(momentum=0.9,\n+                                       epsilon=1e-5,\n+                                       name=name + \"_skip_bn\")(skip)\n+    else:\n+      skip = inputs\n+\n+    # Build block\n+    # conv_1x1_1\n+    x = layers.Conv2D(filters_out, (1, 1),\n+                      use_bias=False,\n+                      kernel_initializer=\"he_normal\",\n+                      name=name + \"_conv_1x1_1\")(inputs)\n+    x = layers.BatchNormalization(momentum=0.9,\n+                                  epsilon=1e-5,\n+                                  name=name + \"_conv_1x1_1_bn\")(x)\n+    x = layers.ReLU(name=name + \"_conv_1x1_1_relu\")(x)\n+\n+    # conv_3x3\n+    x = layers.Conv2D(filters_out, (3, 3),\n+                      use_bias=False,\n+                      strides=stride,\n+                      groups=groups,\n+                      padding=\"same\",\n+                      kernel_initializer=\"he_normal\",\n+                      name=name + \"_conv_3x3\")(x)\n+    x = layers.BatchNormalization(momentum=0.9,\n+                                  epsilon=1e-5,\n+                                  name=name + \"_conv_3x3_bn\")(x)\n+    x = layers.ReLU(name=name + \"_conv_3x3_relu\")(x)\n+\n+    # conv_1x1_2\n+    x = layers.Conv2D(filters_out, (1, 1),\n+                      use_bias=False,\n+                      kernel_initializer=\"he_normal\",\n+                      name=name + \"_conv_1x1_2\")(x)\n+    x = layers.BatchNormalization(momentum=0.9,\n+                                  epsilon=1e-5,\n+                                  name=name + \"_conv_1x1_2_bn\")(x)\n+\n+    x = layers.ReLU(name=name + \"_exit_relu\")(x + skip)\n+\n+    return x\n+\n+  return apply\n+\n+\n+def YBlock(filters_in,\n+           filters_out,\n+           group_width,\n+           stride=1,\n+           squeeze_excite_ratio=0.25,\n+           name=None):\n+  \"\"\"\n+  Implementation of Y Block. \n+  Reference: [Designing Network Design Spaces](https://arxiv.org/abs/2003.13678)\n+\n+  Args:\n+    filters_in: filters in the input tensor\n+    filters_out: filters in the output tensor\n+    group_width: group width\n+    stride: stride\n+    squeeze_excite_ratio: expansion ration for Squeeze and Excite block\n+    name: name prefix\n+\n+  Return:\n+    Output tensor of the block \n+  \"\"\"\n+  if name is None:\n+    name = str(backend.get_uid(\"yblock\"))\n+\n+  def apply(inputs):\n+    if filters_in != filters_out and stride == 1:\n+      raise ValueError(\n+          f\"\"\"Input filters({filters_in}) and output filters({filters_out}) are not equal for stride\n+                          {stride}. Input and output filters must be equal for stride={stride}.\"\"\"\n+      )\n+\n+    groups = filters_out // group_width\n+    se_filters = int(filters_in * squeeze_excite_ratio)\n+\n+    if stride != 1:\n+      skip = layers.Conv2D(filters_out, (1, 1),\n+                           strides=stride,\n+                           use_bias=False,\n+                           kernel_initializer=\"he_normal\",\n+                           name=name + \"_skip_1x1\")(inputs)\n+      skip = layers.BatchNormalization(momentum=0.9,\n+                                       epsilon=1e-5,\n+                                       name=name + \"_skip_bn\")(skip)\n+    else:\n+      skip = inputs\n+\n+    # Build block\n+    # conv_1x1_1\n+    x = layers.Conv2D(filters_out, (1, 1),\n+                      use_bias=False,\n+                      kernel_initializer=\"he_normal\",\n+                      name=name + \"_conv_1x1_1\")(inputs)\n+    x = layers.BatchNormalization(momentum=0.9,\n+                                  epsilon=1e-5,\n+                                  name=name + \"_conv_1x1_1_bn\")(x)\n+    x = layers.ReLU(name=name + \"_conv_1x1_1_relu\")(x)\n+\n+    # conv_3x3\n+    x = layers.Conv2D(filters_out, (3, 3),\n+                      use_bias=False,\n+                      strides=stride,\n+                      groups=groups,\n+                      padding=\"same\",\n+                      kernel_initializer=\"he_normal\",\n+                      name=name + \"_conv_3x3\")(x)\n+    x = layers.BatchNormalization(momentum=0.9,\n+                                  epsilon=1e-5,\n+                                  name=name + \"_conv_3x3_bn\")(x)\n+    x = layers.ReLU(name=name + \"_conv_3x3_relu\")(x)\n+\n+    # Squeeze-Excitation block (https://arxiv.org/abs/1709.01507)\n+    x = SqueezeAndExciteBlock(filters_out, se_filters, name=name)(x)\n+\n+    # conv_1x1_2\n+    x = layers.Conv2D(filters_out, (1, 1),\n+                      use_bias=False,\n+                      kernel_initializer=\"he_normal\",\n+                      name=name + \"_conv_1x1_2\")(x)\n+    x = layers.BatchNormalization(momentum=0.9,\n+                                  epsilon=1e-5,\n+                                  name=name + \"_conv_1x1_2_bn\")(x)\n+\n+    x = layers.ReLU(name=name + \"_exit_relu\")(x + skip)\n+\n+    return x\n+\n+  return apply\n+\n+\n+def ZBlock(filters_in,\n+           filters_out,\n+           group_width,\n+           stride=1,\n+           squeeze_excite_ratio=0.25,\n+           bottleneck_ratio=0.25,\n+           name=None):\n+  \"\"\"\n+  Implementation of Z block\n+  Reference: [Fast and Accurate Model Scaling](https://arxiv.org/abs/2103.06877).\n+  \n+  Args:\n+    filters_in: filters in the input tensor\n+    filters_out: filters in the output tensor\n+    group_width: group width\n+    stride: stride\n+    squeeze_excite_ratio: expansion ration for Squeeze and Excite block\n+    bottleneck_ratio: inverted bottleneck ratio \n+    name: name prefix\n+\n+  Return:\n+    Output tensor of the block \n+  \"\"\"\n+  if name is None:\n+    name = str(backend.get_uid(\"zblock\"))\n+\n+  def apply(inputs):\n+    if filters_in != filters_out and stride == 1:\n+      raise ValueError(\n+          f\"\"\"Input filters({filters_in}) and output filters({filters_out}) are not equal for stride\n+                          {stride}. Input and output filters must be equal for stride={stride}.\"\"\"\n+      )\n+\n+    groups = filters_out // group_width\n+    se_filters = int(filters_in * squeeze_excite_ratio)\n+\n+    inv_btlneck_filters = int(filters_out / bottleneck_ratio)\n+\n+    # Build block\n+    # conv_1x1_1\n+    x = layers.Conv2D(inv_btlneck_filters, (1, 1),\n+                      use_bias=False,\n+                      kernel_initializer=\"he_normal\",\n+                      name=name + \"_conv_1x1_1\")(inputs)\n+    x = layers.BatchNormalization(momentum=0.9,\n+                                  epsilon=1e-5,\n+                                  name=name + \"_conv_1x1_1_bn\")(x)\n+    x = tf.nn.silu(x)\n+\n+    # conv_3x3\n+    x = layers.Conv2D(inv_btlneck_filters, (3, 3),\n+                      use_bias=False,\n+                      strides=stride,\n+                      groups=groups,\n+                      padding=\"same\",\n+                      kernel_initializer=\"he_normal\",\n+                      name=name + \"_conv_3x3\")(x)\n+    x = layers.BatchNormalization(momentum=0.9,\n+                                  epsilon=1e-5,\n+                                  name=name + \"_conv_3x3_bn\")(x)\n+    x = tf.nn.silu(x)\n+\n+    # Squeeze-Excitation block (https://arxiv.org/abs/1709.01507)\n+    x = SqueezeAndExciteBlock(inv_btlneck_filters, se_filters, name=name)\n+\n+    # conv_1x1_2\n+    x = layers.Conv2D(filters_out, (1, 1),\n+                      use_bias=False,\n+                      kernel_initializer=\"he_normal\",\n+                      name=name + \"_conv_1x1_2\")(x)\n+    x = layers.BatchNormalization(momentum=0.9,\n+                                  epsilon=1e-5,\n+                                  name=name + \"_conv_1x1_2_bn\")(x)\n+\n+    if stride != 1:\n+      return x\n+    else:\n+      return x + inputs\n+\n+  return apply\n+\n+\n+def Stage(block_type, depth, group_width, filters_in, filters_out, name=None):\n+  \"\"\"\n+  Implementation of Stage in RegNet.\n+\n+  Args:\n+    block_type: must be one of \"X\", \"Y\", \"Z\"\n+    depth: depth of stage, number of blocks to use\n+    group_width: group width of all blocks in  this stage\n+    filters_in: input filters to this stage\n+    filters_out: output filters from this stage\n+    name: name prefix\n+\n+  Returns:\n+    Output tensor of Stage\n+  \"\"\"\n+  if name is None:\n+    name = str(backend.get_uid(\"stage\"))\n+\n+  def apply(inputs):\n+    x = inputs\n+    if block_type == \"X\":\n+      x = XBlock(filters_in,\n+                 filters_out,\n+                 group_width,\n+                 stride=2,\n+                 name=name + \"_XBlock_0\")(x)\n+      for i in range(depth - 1):\n+        x = XBlock(filters_out,\n+                   filters_out,\n+                   group_width,\n+                   name=name + \"_XBlock_\" + str(i+1))(x)\n+    elif block_type == \"Y\":\n+      x = YBlock(filters_in,\n+                 filters_out,\n+                 group_width,\n+                 stride=2,\n+                 name=name + \"_YBlock_0\")(x)\n+      for i in range(depth - 1):\n+        x = YBlock(filters_out,\n+                   filters_out,\n+                   group_width,\n+                   name=name + \"_YBlock_\" + str(i+1))(x)\n+    elif block_type == \"Z\":\n+      x = ZBlock(filters_in,\n+                 filters_out,\n+                 group_width,\n+                 stride=2,\n+                 name=name + \"_ZBlock_0\")(x)\n+      for i in range(depth - 1):\n+        x = ZBlock(filters_out,\n+                   filters_out,\n+                   group_width,\n+                   name=name + \"_ZBlock_\" + str(i+1))(x)\n+    else:\n+      raise NotImplementedError(f\"\"\"Block type `{block_type}` not recognized. \n+                                block_type must be one of (\"X\", \"Y\", \"Z\"). \"\"\")\n+    return x\n+\n+  return apply\n+\n+\n+def Head(num_classes=1000, name=None):\n+  \"\"\"\n+  Implementation of classification head of RegNet\n+  \n+  Args:\n+  x: Input tensor\n+    num_classes: number of classes for Dense layer\n+  \n+  Returns:\n+    Output logits tensor. \n+  \"\"\"\n+  if name is None:\n+    name = str(backend.get_uid(\"head\"))\n+\n+  def apply(x):\n+    x = layers.GlobalAveragePooling2D(name=name + \"_head_gap\")(x)\n+    x = layers.Dense(num_classes, name=name + \"head_dense\")(x)\n+    return x\n+\n+  return apply\n+\n+\n+def RegNet(depths,\n+           widths,\n+           group_width,\n+           block_type,\n+           default_size,\n+           model_name=\"regnet\",\n+           include_preprocessing=True,\n+           include_top=True,\n+           weights=\"imagenet\",\n+           input_tensor=None,\n+           input_shape=None,\n+           pooling=None,\n+           classes=1000,\n+           classifier_activation=\"softmax\"):\n+  \"\"\" \n+  Instantiates RegNet architecture given specific configuration.\n+\n+  Args:\n+    depths: An iterable containing depths for each individual stages. \n+    widths: An iterable containing output channel width of each individual \n+      stages\n+    group_width: Number of channels to be used in each group. See grouped \n+      convolutions for more information.\n+    block_type: Must be one of {\"x\", \"y\", \"z\"}. For more details see the\n+      papers \"Designing network design spaces\" and \"Fast and Accurate Model \n+      Scaling\"\n+    default_size: Default input image size. \n+    model_name: An optional name for the model.\n+    include_preprocessing: boolean denoting whther to include preprocessing in \n+      the model\n+    include_top: Boolean denoting whether to include classification head to \n+      the model.\n+    weights: one of `None` (random initialization),\n+      \"imagenet\" (pre-training on ImageNet),\n+      or the path to the weights file to be loaded.\n+    input_tensor: optional Keras tensor\n+      (i.e. output of `layers.Input()`)\n+      to use as image input for the model.\n+    input_shape: optional shape tuple, only to be specified\n+      if `include_top` is False.\n+      It should have exactly 3 inputs channels.\n+    pooling: optional pooling mode for feature extraction\n+      when `include_top` is `False`.\n+      - `None` means that the output of the model will be\n+          the 4D tensor output of the\n+          last convolutional layer.\n+      - `avg` means that global average pooling\n+          will be applied to the output of the\n+          last convolutional layer, and thus\n+          the output of the model will be a 2D tensor.\n+      - `max` means that global max pooling will\n+          be applied.\n+    classes: optional number of classes to classify images\n+      into, only to be specified if `include_top` is True, and\n+      if no `weights` argument is specified.\n+    classifier_activation: A `str` or callable. The activation function to use\n+      on the \"top\" layer. Ignored unless `include_top=True`. Set\n+      `classifier_activation=None` to return the logits of the \"top\" layer.        \n+  \n+  Returns:\n+  A `keras.Model` instance.\n+  Raises:\n+      ValueError: in case of invalid argument for `weights`,\n+        or invalid input shape.\n+      ValueError: if `classifier_activation` is not `softmax` or `None` when\n+        using a pretrained top layer.\n+      ValueError: if `include_top` is True but `num_classes` is not 1000.\n+      ValueError: if `block_type` is not one of `{\"X\", \"Y\", \"Z\"}`\n+  \n+  \"\"\"\n+  if not (weights in {\"imagenet\", None} or tf.io.gfile.exists(weights)):\n+    raise ValueError(\"The `weights` argument should be either \"\n+                     \"`None` (random initialization), `imagenet` \"\n+                     \"(pre-training on ImageNet), \"\n+                     \"or the path to the weights file to be loaded.\")\n+\n+  if weights == \"imagenet\" and include_top and classes != 1000:\n+    raise ValueError(\"If using `weights` as `'imagenet'` with `include_top`\"\n+                     \" as true, `classes` should be 1000\")\n+\n+  # Determine proper input shape\n+  input_shape = imagenet_utils.obtain_input_shape(\n+      input_shape,\n+      default_size=default_size,\n+      min_size=32,\n+      data_format=backend.image_data_format(),\n+      require_flatten=include_top,\n+      weights=weights)\n+\n+  if input_tensor is None:\n+    img_input = layers.Input(shape=input_shape)\n+  else:\n+    if not backend.is_keras_tensor(input_tensor):\n+      img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n+    else:\n+      img_input = input_tensor\n+\n+  if input_tensor is not None:\n+    inputs = layer_utils.get_source_inputs(input_tensor)\n+  else:\n+    inputs = img_input\n+\n+  x = inputs\n+  if include_preprocessing:\n+    x = PreStem(name=model_name)(x)\n+  x = Stem(name=model_name)(x)\n+\n+  in_channels = 32  # Output from Stem\n+\n+  for num_stage in range(4):\n+    depth = depths[num_stage]\n+    out_channels = widths[num_stage]\n+\n+    x = Stage(block_type,\n+              depth,\n+              group_width,\n+              in_channels,\n+              out_channels,\n+              name=model_name + \"_Stage_\" + str(num_stage))(x)\n+    in_channels = out_channels\n+\n+  if include_top:\n+    x = Head(num_classes=classes)(x)\n+    imagenet_utils.validate_activation(classifier_activation, weights)\n+\n+  else:\n+    if pooling == \"avg\":\n+      x = layers.GlobalAveragePooling2D()(x)\n+    elif pooling == \"max\":\n+      x = layers.GlobalMaxPooling2D()(x)\n+\n+  model = training.Model(inputs=inputs, outputs=x, name=model_name)\n+\n+  # Load weights.\n+  if weights == \"imagenet\":\n+    if include_top:\n+      file_suffix = \".h5\"\n+      file_hash = WEIGHTS_HASHES[model_name[-2:]][0]\n+    else:\n+      file_suffix = \"_notop.h5\"\n+      file_hash = WEIGHTS_HASHES[model_name[-2:]][1]\n+    file_name = model_name + file_suffix\n+    weights_path = data_utils.get_file(file_name,\n+                                       BASE_WEIGHTS_PATH + file_name,\n+                                       cache_subdir=\"models\",\n+                                       file_hash=file_hash)\n+    model.load_weights(weights_path)\n+  elif weights is not None:\n+    model.load_weights(weights)\n+\n+  return model\n+\n+\n+## Instantiating variants ##\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetX002\",\n+              \"keras.applications.RegNetX002\")\n+def RegNetX002(model_name=\"regnetx002\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(\n+      MODEL_CONFIGS[\"x002\"][\"depths\"],\n+      MODEL_CONFIGS[\"x002\"][\"widths\"],\n+      MODEL_CONFIGS[\"x002\"][\"group_width\"],\n+      \"X\",\n+      MODEL_CONFIGS[\"x002\"][\"default_size\"],\n+      model_name=model_name,\n+      include_top=include_top,\n+      include_preprocessing=include_preprocessing,\n+      weights=weights,\n+      input_tensor=input_tensor,\n+      input_shape=input_shape,\n+      pooling=pooling,\n+      classes=classes,\n+      classifier_activation=classifier_activation\n+  )\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetX004\",\n+              \"keras.applications.RegNetX004\")\n+def RegNetX004(model_name=\"regnetx004\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(\n+      MODEL_CONFIGS[\"x004\"][\"depths\"],\n+      MODEL_CONFIGS[\"x004\"][\"widths\"],\n+      MODEL_CONFIGS[\"x004\"][\"group_width\"],\n+      \"X\",\n+      MODEL_CONFIGS[\"x004\"][\"default_size\"],\n+      model_name=model_name,\n+      include_top=include_top,\n+      include_preprocessing=include_preprocessing,\n+      weights=weights,\n+      input_tensor=input_tensor,\n+      input_shape=input_shape,\n+      pooling=pooling,\n+      classes=classes,\n+      classifier_activation=classifier_activation\n+  )\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetX006\",\n+              \"keras.applications.RegNetX006\")\n+def RegNetX006(model_name=\"regnetx006\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(\n+      MODEL_CONFIGS[\"x006\"][\"depths\"],\n+      MODEL_CONFIGS[\"x006\"][\"widths\"],\n+      MODEL_CONFIGS[\"x006\"][\"group_width\"],\n+      \"X\",\n+      MODEL_CONFIGS[\"x006\"][\"default_size\"],\n+      model_name=model_name,\n+      include_top=include_top,\n+      include_preprocessing=include_preprocessing,\n+      weights=weights,\n+      input_tensor=input_tensor,\n+      input_shape=input_shape,\n+      pooling=pooling,\n+      classes=classes,\n+      classifier_activation=classifier_activation\n+  )\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetX008\",\n+              \"keras.applications.RegNetX008\")\n+def RegNetX008(model_name=\"regnetx008\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(\n+      MODEL_CONFIGS[\"x008\"][\"depths\"],\n+      MODEL_CONFIGS[\"x008\"][\"widths\"],\n+      MODEL_CONFIGS[\"x008\"][\"group_width\"],\n+      \"X\",\n+      MODEL_CONFIGS[\"x008\"][\"default_size\"],\n+      model_name=model_name,\n+      include_top=include_top,\n+      include_preprocessing=include_preprocessing,\n+      weights=weights,\n+      input_tensor=input_tensor,\n+      input_shape=input_shape,\n+      pooling=pooling,\n+      classes=classes,\n+      classifier_activation=classifier_activation\n+  )\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetX016\",\n+              \"keras.applications.RegNetX016\")\n+def RegNetX016(model_name=\"regnetx016\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(\n+      MODEL_CONFIGS[\"x016\"][\"depths\"],\n+      MODEL_CONFIGS[\"x016\"][\"widths\"],\n+      MODEL_CONFIGS[\"x016\"][\"group_width\"],\n+      \"X\",\n+      MODEL_CONFIGS[\"x016\"][\"default_size\"],\n+      model_name=model_name,\n+      include_top=include_top,\n+      include_preprocessing=include_preprocessing,\n+      weights=weights,\n+      input_tensor=input_tensor,\n+      input_shape=input_shape,\n+      pooling=pooling,\n+      classes=classes,\n+      classifier_activation=classifier_activation\n+  )\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetX032\",\n+              \"keras.applications.RegNetX032\")\n+def RegNetX032(model_name=\"regnetx032\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(\n+      MODEL_CONFIGS[\"x032\"][\"depths\"],\n+      MODEL_CONFIGS[\"x032\"][\"widths\"],\n+      MODEL_CONFIGS[\"x032\"][\"group_width\"],\n+      \"X\",\n+      MODEL_CONFIGS[\"x032\"][\"default_size\"],\n+      model_name=model_name,\n+      include_top=include_top,\n+      include_preprocessing=include_preprocessing,\n+      weights=weights,\n+      input_tensor=input_tensor,\n+      input_shape=input_shape,\n+      pooling=pooling,\n+      classes=classes,\n+      classifier_activation=classifier_activation\n+  )\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetX040\",\n+              \"keras.applications.RegNetX040\")\n+def RegNetX040(model_name=\"regnetx040\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(\n+      MODEL_CONFIGS[\"x040\"][\"depths\"],\n+      MODEL_CONFIGS[\"x040\"][\"widths\"],\n+      MODEL_CONFIGS[\"x040\"][\"group_width\"],\n+      \"X\",\n+      MODEL_CONFIGS[\"x040\"][\"default_size\"],\n+      model_name=model_name,\n+      include_top=include_top,\n+      include_preprocessing=include_preprocessing,\n+      weights=weights,\n+      input_tensor=input_tensor,\n+      input_shape=input_shape,\n+      pooling=pooling,\n+      classes=classes,\n+      classifier_activation=classifier_activation\n+  )\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetX064\",\n+              \"keras.applications.RegNetX064\")\n+def RegNetX064(model_name=\"regnetx064\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(\n+      MODEL_CONFIGS[\"x064\"][\"depths\"],\n+      MODEL_CONFIGS[\"x064\"][\"widths\"],\n+      MODEL_CONFIGS[\"x064\"][\"group_width\"],\n+      \"X\",\n+      MODEL_CONFIGS[\"x064\"][\"default_size\"],\n+      model_name=model_name,\n+      include_top=include_top,\n+      include_preprocessing=include_preprocessing,\n+      weights=weights,\n+      input_tensor=input_tensor,\n+      input_shape=input_shape,\n+      pooling=pooling,\n+      classes=classes,\n+      classifier_activation=classifier_activation\n+  )\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetX080\",\n+              \"keras.applications.RegNetX080\")\n+def RegNetX080(model_name=\"regnetx080\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(\n+      MODEL_CONFIGS[\"x080\"][\"depths\"],\n+      MODEL_CONFIGS[\"x080\"][\"widths\"],\n+      MODEL_CONFIGS[\"x080\"][\"group_width\"],\n+      \"X\",\n+      MODEL_CONFIGS[\"x080\"][\"default_size\"],\n+      model_name=model_name,\n+      include_top=include_top,\n+      include_preprocessing=include_preprocessing,\n+      weights=weights,\n+      input_tensor=input_tensor,\n+      input_shape=input_shape,\n+      pooling=pooling,\n+      classes=classes,\n+      classifier_activation=classifier_activation\n+  )\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetX120\",\n+              \"keras.applications.RegNetX120\")\n+def RegNetX120(model_name=\"regnetx120\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(\n+      MODEL_CONFIGS[\"x120\"][\"depths\"],\n+      MODEL_CONFIGS[\"x120\"][\"widths\"],\n+      MODEL_CONFIGS[\"x120\"][\"group_width\"],\n+      \"X\",\n+      MODEL_CONFIGS[\"x120\"][\"default_size\"],\n+      model_name=model_name,\n+      include_top=include_top,\n+      include_preprocessing=include_preprocessing,\n+      weights=weights,\n+      input_tensor=input_tensor,\n+      input_shape=input_shape,\n+      pooling=pooling,\n+      classes=classes,\n+      classifier_activation=classifier_activation\n+  )\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetX160\",\n+              \"keras.applications.RegNetX160\")\n+def RegNetX160(model_name=\"regnetx160\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(\n+      MODEL_CONFIGS[\"x160\"][\"depths\"],\n+      MODEL_CONFIGS[\"x160\"][\"widths\"],\n+      MODEL_CONFIGS[\"x160\"][\"group_width\"],\n+      \"X\",\n+      MODEL_CONFIGS[\"x160\"][\"default_size\"],\n+      model_name=model_name,\n+      include_top=include_top,\n+      include_preprocessing=include_preprocessing,\n+      weights=weights,\n+      input_tensor=input_tensor,\n+      input_shape=input_shape,\n+      pooling=pooling,\n+      classes=classes,\n+      classifier_activation=classifier_activation\n+  )\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetX320\",\n+              \"keras.applications.RegNetX320\")\n+def RegNetX320(model_name=\"regnetx320\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(\n+      MODEL_CONFIGS[\"x320\"][\"depths\"],\n+      MODEL_CONFIGS[\"x320\"][\"widths\"],\n+      MODEL_CONFIGS[\"x320\"][\"group_width\"],\n+      \"X\",\n+      MODEL_CONFIGS[\"x320\"][\"default_size\"],\n+      model_name=model_name,\n+      include_top=include_top,\n+      include_preprocessing=include_preprocessing,\n+      weights=weights,\n+      input_tensor=input_tensor,\n+      input_shape=input_shape,\n+      pooling=pooling,\n+      classes=classes,\n+      classifier_activation=classifier_activation\n+  )\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetY002\",\n+              \"keras.applications.RegNetY002\")\n+def RegNetY002(model_name=\"regnety002\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(\n+      MODEL_CONFIGS[\"y002\"][\"depths\"],\n+      MODEL_CONFIGS[\"y002\"][\"widths\"],\n+      MODEL_CONFIGS[\"y002\"][\"group_width\"],\n+      \"Y\",\n+      MODEL_CONFIGS[\"y002\"][\"default_size\"],\n+      model_name=model_name,\n+      include_top=include_top,\n+      include_preprocessing=include_preprocessing,\n+      weights=weights,\n+      input_tensor=input_tensor,\n+      input_shape=input_shape,\n+      pooling=pooling,\n+      classes=classes,\n+      classifier_activation=classifier_activation\n+  )\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetY004\",\n+              \"keras.applications.RegNetY004\")\n+def RegNetY004(model_name=\"regnety004\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(\n+      MODEL_CONFIGS[\"y004\"][\"depths\"],\n+      MODEL_CONFIGS[\"y004\"][\"widths\"],\n+      MODEL_CONFIGS[\"y004\"][\"group_width\"],\n+      \"Y\",\n+      MODEL_CONFIGS[\"y004\"][\"default_size\"],\n+      model_name=model_name,\n+      include_top=include_top,\n+      include_preprocessing=include_preprocessing,\n+      weights=weights,\n+      input_tensor=input_tensor,\n+      input_shape=input_shape,\n+      pooling=pooling,\n+      classes=classes,\n+      classifier_activation=classifier_activation\n+  )\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetY006\",\n+              \"keras.applications.RegNetY006\")\n+def RegNetY006(model_name=\"regnety006\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(\n+      MODEL_CONFIGS[\"y006\"][\"depths\"],\n+      MODEL_CONFIGS[\"y006\"][\"widths\"],\n+      MODEL_CONFIGS[\"y006\"][\"group_width\"],\n+      \"Y\",\n+      MODEL_CONFIGS[\"y006\"][\"default_size\"],\n+      model_name=model_name,\n+      include_top=include_top,\n+      include_preprocessing=include_preprocessing,\n+      weights=weights,\n+      input_tensor=input_tensor,\n+      input_shape=input_shape,\n+      pooling=pooling,\n+      classes=classes,\n+      classifier_activation=classifier_activation\n+  )\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetY008\",\n+              \"keras.applications.RegNetY008\")\n+def RegNetY008(model_name=\"regnety008\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(\n+      MODEL_CONFIGS[\"y008\"][\"depths\"],\n+      MODEL_CONFIGS[\"y008\"][\"widths\"],\n+      MODEL_CONFIGS[\"y008\"][\"group_width\"],\n+      \"Y\",\n+      MODEL_CONFIGS[\"y008\"][\"default_size\"],\n+      model_name=model_name,\n+      include_top=include_top,\n+      include_preprocessing=include_preprocessing,\n+      weights=weights,\n+      input_tensor=input_tensor,\n+      input_shape=input_shape,\n+      pooling=pooling,\n+      classes=classes,\n+      classifier_activation=classifier_activation\n+  )\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetY016\",\n+              \"keras.applications.RegNetY016\")\n+def RegNetY016(model_name=\"regnety016\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(\n+      MODEL_CONFIGS[\"y016\"][\"depths\"],\n+      MODEL_CONFIGS[\"y016\"][\"widths\"],\n+      MODEL_CONFIGS[\"y016\"][\"group_width\"],\n+      \"Y\",\n+      MODEL_CONFIGS[\"y016\"][\"default_size\"],\n+      model_name=model_name,\n+      include_top=include_top,\n+      include_preprocessing=include_preprocessing,\n+      weights=weights,\n+      input_tensor=input_tensor,\n+      input_shape=input_shape,\n+      pooling=pooling,\n+      classes=classes,\n+      classifier_activation=classifier_activation\n+  )\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetY032\",\n+              \"keras.applications.RegNetY032\")\n+def RegNetY032(model_name=\"regnety032\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(\n+      MODEL_CONFIGS[\"y032\"][\"depths\"],\n+      MODEL_CONFIGS[\"y032\"][\"widths\"],\n+      MODEL_CONFIGS[\"y032\"][\"group_width\"],\n+      \"Y\",\n+      MODEL_CONFIGS[\"y032\"][\"default_size\"],\n+      model_name=model_name,\n+      include_top=include_top,\n+      include_preprocessing=include_preprocessing,\n+      weights=weights,\n+      input_tensor=input_tensor,\n+      input_shape=input_shape,\n+      pooling=pooling,\n+      classes=classes,\n+      classifier_activation=classifier_activation\n+  )\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetY040\",\n+              \"keras.applications.RegNetY040\")\n+def RegNetY040(model_name=\"regnety040\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(\n+      MODEL_CONFIGS[\"y040\"][\"depths\"],\n+      MODEL_CONFIGS[\"y040\"][\"widths\"],\n+      MODEL_CONFIGS[\"y040\"][\"group_width\"],\n+      \"Y\",\n+      MODEL_CONFIGS[\"y040\"][\"default_size\"],\n+      model_name=model_name,\n+      include_top=include_top,\n+      include_preprocessing=include_preprocessing,\n+      weights=weights,\n+      input_tensor=input_tensor,\n+      input_shape=input_shape,\n+      pooling=pooling,\n+      classes=classes,\n+      classifier_activation=classifier_activation\n+  )\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetY064\",\n+              \"keras.applications.RegNetY064\")\n+def RegNetY064(model_name=\"regnety064\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(\n+      MODEL_CONFIGS[\"y064\"][\"depths\"],\n+      MODEL_CONFIGS[\"y064\"][\"widths\"],\n+      MODEL_CONFIGS[\"y064\"][\"group_width\"],\n+      \"Y\",\n+      MODEL_CONFIGS[\"y064\"][\"default_size\"],\n+      model_name=model_name,\n+      include_top=include_top,\n+      include_preprocessing=include_preprocessing,\n+      weights=weights,\n+      input_tensor=input_tensor,\n+      input_shape=input_shape,\n+      pooling=pooling,\n+      classes=classes,\n+      classifier_activation=classifier_activation\n+  )\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetY080\",\n+              \"keras.applications.RegNetY080\")\n+def RegNetY080(model_name=\"regnety080\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(\n+      MODEL_CONFIGS[\"y080\"][\"depths\"],\n+      MODEL_CONFIGS[\"y080\"][\"widths\"],\n+      MODEL_CONFIGS[\"y080\"][\"group_width\"],\n+      \"Y\",\n+      MODEL_CONFIGS[\"y080\"][\"default_size\"],\n+      model_name=model_name,\n+      include_top=include_top,\n+      include_preprocessing=include_preprocessing,\n+      weights=weights,\n+      input_tensor=input_tensor,\n+      input_shape=input_shape,\n+      pooling=pooling,\n+      classes=classes,\n+      classifier_activation=classifier_activation\n+  )\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetY120\",\n+              \"keras.applications.RegNetY120\")\n+def RegNetY120(model_name=\"regnety120\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(\n+      MODEL_CONFIGS[\"y120\"][\"depths\"],\n+      MODEL_CONFIGS[\"y120\"][\"widths\"],\n+      MODEL_CONFIGS[\"y120\"][\"group_width\"],\n+      \"Y\",\n+      MODEL_CONFIGS[\"y120\"][\"default_size\"],\n+      model_name=model_name,\n+      include_top=include_top,\n+      include_preprocessing=include_preprocessing,\n+      weights=weights,\n+      input_tensor=input_tensor,\n+      input_shape=input_shape,\n+      pooling=pooling,\n+      classes=classes,\n+      classifier_activation=classifier_activation\n+  )\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetY160\",\n+              \"keras.applications.RegNetY160\")\n+def RegNetY160(model_name=\"regnety160\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(\n+      MODEL_CONFIGS[\"y160\"][\"depths\"],\n+      MODEL_CONFIGS[\"y160\"][\"widths\"],\n+      MODEL_CONFIGS[\"y160\"][\"group_width\"],\n+      \"Y\",\n+      MODEL_CONFIGS[\"y160\"][\"default_size\"],\n+      model_name=model_name,\n+      include_top=include_top,\n+      include_preprocessing=include_preprocessing,\n+      weights=weights,\n+      input_tensor=input_tensor,\n+      input_shape=input_shape,\n+      pooling=pooling,\n+      classes=classes,\n+      classifier_activation=classifier_activation\n+  )\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetY320\",\n+              \"keras.applications.RegNetY320\")\n+def RegNetY320(model_name=\"regnety320\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(\n+      MODEL_CONFIGS[\"y320\"][\"depths\"],\n+      MODEL_CONFIGS[\"y320\"][\"widths\"],\n+      MODEL_CONFIGS[\"y320\"][\"group_width\"],\n+      \"Y\",\n+      MODEL_CONFIGS[\"y320\"][\"default_size\"],\n+      model_name=model_name,\n+      include_top=include_top,\n+      include_preprocessing=include_preprocessing,\n+      weights=weights,\n+      input_tensor=input_tensor,\n+      input_shape=input_shape,\n+      pooling=pooling,\n+      classes=classes,\n+      classifier_activation=classifier_activation\n+  )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
