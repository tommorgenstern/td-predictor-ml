{"custom_id": "keras#a6ddf604714cd5a4ea6da9001ba2d996d2a3fd0b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 78 | Lines Deleted: 46 | Files Changed: 5 | Hunks: 24 | Methods Changed: 6 | Complexity Δ (Sum/Max): -10/0 | Churn Δ: 124 | Churn Cumulative: 4585 | Contributors (this commit): 10 | Commits (past 90d): 71 | Contributors (cumulative): 24 | DMM Complexity: 0.8888888888888888\n\nDIFF:\n@@ -6,6 +6,28 @@ from keras_core.utils.naming import auto_name\n \n @keras_core_export(\"keras_core.KerasTensor\")\n class KerasTensor:\n+    \"\"\"Symbolic tensor -- encapsulates a shape and a dtype.\n+\n+    You can use `KerasTensor` instances to build computation\n+    graphs of Keras operations, such as `keras_core.Function`\n+    objects or Functional `keras_core.models.Model` objects.\n+\n+    Example:\n+\n+    >>> x = keras_core.KerasTensor(shape=(3, 4), dtype=\"float32\")\n+    >>> x.shape\n+    (3, 4)\n+    >>> x.dtype\n+    float32\n+\n+    Calling a Keras operation (including a layer or a model)\n+    on a `KerasTensor` instance will return another `KerasTensor`\n+    instance with the appropriate shape and dtype. This is\n+    called a \"symbolic call\" (since there is no actual data\n+    involved). The computation of the correct output shape and\n+    dtype is called \"static shape inference\".\n+    \"\"\"\n+\n     def __init__(self, shape, dtype=\"float32\", record_history=True, name=None):\n         from keras_core import backend\n \n\n@@ -532,9 +532,7 @@ def binary_crossentropy(target, output, from_logits=False):\n         )\n \n     if from_logits:\n-        log_logits = jax.nn.log_sigmoid(output)\n-        log_neg_logits = jax.nn.log_sigmoid(-output)\n-        return -1.0 * target * log_logits - (1.0 - target) * log_neg_logits\n+        output = jnn.sigmoid(output)\n \n     output = jnp.clip(output, epsilon(), 1.0 - epsilon())\n     bce = target * jnp.log(output)\n\n@@ -9,6 +9,39 @@ from keras_core.operations.operation import Operation\n \n @keras_core_export(\"keras_core.Function\")\n class Function(Operation):\n+    \"\"\"Class that encapsulates a computation graph of Keras operations.\n+\n+    You can use a `Function` to capture the computation graph linking\n+    some input tensors to some output tensors, and reapply the same\n+    computation on new inputs.\n+\n+    A `Function` is similar to a Functional Model, with the difference\n+    that it is stateless (it does not track state variables)\n+    and does not implement the `Layer` API.\n+\n+    Example:\n+\n+    ```python\n+    input_1 = keras_core.KerasTensor(shape=(None, 2, 3))\n+    input_2 = keras_core.KerasTensor(shape=(None, 2, 3))\n+    x = input_1 + input_2\n+    output = keras_core.operations.sigmoid(x)\n+    fn = keras_core.Function(inputs=[input_1, input_2], outputs=output)\n+\n+    input_1_val = np.random.random((4, 2, 3))\n+    input_2_val = np.random.random((4, 2, 3))\n+    output_val = fn([input_1_val, input_2_val])\n+    ```\n+\n+    Args:\n+        inputs: `KerasTensor` instance or nested structured of\n+            `KerasTensor` instances.\n+        outputs: `KerasTensor` instance or nested structured of\n+            `KerasTensor` instances. They should be computable\n+            given only the values of `inputs`.\n+        name: String. The name of the function.\n+    \"\"\"\n+\n     def __init__(self, inputs, outputs, name=None):\n         super().__init__(name=name)\n \n\n@@ -78,14 +78,14 @@ class NNOpsDynamicShapeTest(testing.TestCase):\n             knn.max_pool(x, 2, 2, padding=\"same\").shape, (None, 4, 3)\n         )\n \n-        x = KerasTensor([None, 8, None, 3])\n-        self.assertEqual(knn.max_pool(x, 2, 1).shape, (None, 7, None, 3))\n+        x = KerasTensor([None, 8, 8, 3])\n+        self.assertEqual(knn.max_pool(x, 2, 1).shape, (None, 7, 7, 3))\n         self.assertEqual(\n-            knn.max_pool(x, 2, 2, padding=\"same\").shape, (None, 4, None, 3)\n+            knn.max_pool(x, 2, 2, padding=\"same\").shape, (None, 4, 4, 3)\n         )\n         self.assertEqual(\n             knn.max_pool(x, (2, 2), (2, 2), padding=\"same\").shape,\n-            (None, 4, None, 3),\n+            (None, 4, 4, 3),\n         )\n \n     def test_average_pool(self):\n@@ -95,14 +95,14 @@ class NNOpsDynamicShapeTest(testing.TestCase):\n             knn.average_pool(x, 2, 2, padding=\"same\").shape, (None, 4, 3)\n         )\n \n-        x = KerasTensor([None, 8, None, 3])\n-        self.assertEqual(knn.average_pool(x, 2, 1).shape, (None, 7, None, 3))\n+        x = KerasTensor([None, 8, 8, 3])\n+        self.assertEqual(knn.average_pool(x, 2, 1).shape, (None, 7, 7, 3))\n         self.assertEqual(\n-            knn.average_pool(x, 2, 2, padding=\"same\").shape, (None, 4, None, 3)\n+            knn.average_pool(x, 2, 2, padding=\"same\").shape, (None, 4, 4, 3)\n         )\n         self.assertEqual(\n             knn.average_pool(x, (2, 2), (2, 2), padding=\"same\").shape,\n-            (None, 4, None, 3),\n+            (None, 4, 4, 3),\n         )\n \n     def test_conv(self):\n@@ -121,37 +121,37 @@ class NNOpsDynamicShapeTest(testing.TestCase):\n         )\n \n         # Test 2D conv.\n-        inputs_2d = KerasTensor([None, 10, None, 3])\n+        inputs_2d = KerasTensor([None, 10, 10, 3])\n         kernel = KerasTensor([2, 2, 3, 2])\n         self.assertEqual(\n             knn.conv(inputs_2d, kernel, 1, padding=\"valid\").shape,\n-            (None, 9, None, 2),\n+            (None, 9, 9, 2),\n         )\n         self.assertEqual(\n             knn.conv(inputs_2d, kernel, 1, padding=\"same\").shape,\n-            (None, 10, None, 2),\n+            (None, 10, 10, 2),\n         )\n         self.assertEqual(\n             knn.conv(inputs_2d, kernel, (2, 1), dilation_rate=(2, 1)).shape,\n-            (None, 4, None, 2),\n+            (None, 4, 9, 2),\n         )\n \n         # Test 3D conv.\n-        inputs_3d = KerasTensor([None, 8, None, 8, 3])\n+        inputs_3d = KerasTensor([None, 8, 8, 8, 3])\n         kernel = KerasTensor([3, 3, 3, 3, 2])\n         self.assertEqual(\n             knn.conv(inputs_3d, kernel, 1, padding=\"valid\").shape,\n-            (None, 6, None, 6, 2),\n+            (None, 6, 6, 6, 2),\n         )\n         self.assertEqual(\n             knn.conv(inputs_3d, kernel, (2, 1, 2), padding=\"same\").shape,\n-            (None, 4, None, 4, 2),\n+            (None, 4, 8, 4, 2),\n         )\n         self.assertEqual(\n             knn.conv(\n                 inputs_3d, kernel, 1, padding=\"valid\", dilation_rate=(1, 2, 2)\n             ).shape,\n-            (None, 6, None, 4, 2),\n+            (None, 6, 4, 4, 2),\n         )\n \n     def test_depthwise_conv(self):\n\n@@ -18,20 +18,13 @@ def compute_pooling_output_shape(\n         spatial_shape = input_shape[1:-1]\n     else:\n         spatial_shape = input_shape[2:]\n-    none_dims = []\n-    for i in range(len(spatial_shape)):\n-        if spatial_shape[i] is None:\n-            # Set `None` shape to a manual value so that we can run numpy\n-            # computation on `spatial_shape`.\n-            spatial_shape[i] = -1\n-            none_dims.append(i)\n     pool_size = np.array(pool_size)\n     if padding == \"valid\":\n         output_spatial_shape = (\n             np.floor((spatial_shape - pool_size) / strides) + 1\n         )\n-        for i in range(len(output_spatial_shape)):\n-            if i not in none_dims and output_spatial_shape[i] < 0:\n+        negative_in_shape = np.all(output_spatial_shape < 0)\n+        if negative_in_shape:\n             raise ValueError(\n                 \"Computed output size would be negative. Received: \"\n                 f\"`inputs.shape={input_shape}` and `pool_size={pool_size}`.\"\n@@ -43,10 +36,7 @@ def compute_pooling_output_shape(\n             \"`padding` must be either `'valid'` or `'same'`. Received \"\n             f\"{padding}.\"\n         )\n-    output_spatial_shape = [int(i) for i in output_spatial_shape]\n-    for i in none_dims:\n-        output_spatial_shape[i] = None\n-    output_spatial_shape = tuple(output_spatial_shape)\n+    output_spatial_shape = tuple([int(i) for i in output_spatial_shape])\n     if data_format == \"channels_last\":\n         output_shape = (\n             (input_shape_origin[0],)\n@@ -94,15 +84,7 @@ def compute_conv_output_shape(\n             f\"`dilation_rate={dilation_rate}` and \"\n             f\"input of shape {input_shape}.\"\n         )\n-    none_dims = []\n     spatial_shape = np.array(spatial_shape)\n-    for i in range(len(spatial_shape)):\n-        if spatial_shape[i] is None:\n-            # Set `None` shape to a manual value so that we can run numpy\n-            # computation on `spatial_shape`.\n-            spatial_shape[i] = -1\n-            none_dims.append(i)\n-\n     kernel_spatial_shape = np.array(kernel_shape[:-2])\n     dilation_rate = np.array(dilation_rate)\n     if padding == \"valid\":\n@@ -113,8 +95,8 @@ def compute_conv_output_shape(\n             )\n             + 1\n         )\n-        for i in range(len(output_spatial_shape)):\n-            if i not in none_dims and output_spatial_shape[i] < 0:\n+        negative_in_shape = np.all(output_spatial_shape < 0)\n+        if negative_in_shape:\n             raise ValueError(\n                 \"Computed output size would be negative. Received \"\n                 f\"`inputs shape={input_shape}`, \"\n@@ -123,10 +105,7 @@ def compute_conv_output_shape(\n             )\n     elif padding == \"same\" or padding == \"causal\":\n         output_spatial_shape = np.floor((spatial_shape - 1) / strides) + 1\n-    output_spatial_shape = [int(i) for i in output_spatial_shape]\n-    for i in none_dims:\n-        output_spatial_shape[i] = None\n-    output_spatial_shape = tuple(output_spatial_shape)\n+    output_spatial_shape = tuple([int(i) for i in output_spatial_shape])\n     if data_format == \"channels_last\":\n         output_shape = (\n             (input_shape[0],) + output_spatial_shape + (kernel_shape[-1],)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#934ca21d941f98dd8f3475e0baa744b950b5331f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 49 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 10/9 | Churn Δ: 49 | Churn Cumulative: 400 | Contributors (this commit): 4 | Commits (past 90d): 11 | Contributors (cumulative): 5 | DMM Complexity: 0.28\n\nDIFF:\n@@ -1,6 +1,7 @@\n import math\n \n import numpy as np\n+from tensorflow import nest\n \n \n def compute_pooling_output_shape(\n@@ -181,3 +182,37 @@ def reduce_shape(shape, axis=None, keepdims=False):\n             shape[ax] = -1\n         output_shape = list(filter((-1).__ne__, shape))\n         return output_shape\n+\n+\n+def get_source_inputs(tensor):\n+    \"\"\"Returns the list of input tensors necessary to compute `tensor`.\n+\n+    Output will always be a list of tensors\n+    (potentially with 1 element).\n+\n+    Args:\n+        tensor: The tensor to start from.\n+\n+    Returns:\n+        List of input tensors.\n+    \"\"\"\n+    if not hasattr(tensor, \"_keras_history\"):\n+        return tensor\n+\n+    operation, node_index, _ = tensor._keras_history\n+    if not operation or not operation._inbound_nodes:\n+        return [tensor]\n+    else:\n+        node = operation._inbound_nodes[node_index]\n+        if node.is_input:\n+            # Reached input node, stop recursion.\n+            return nest.flatten(node.input_tensors)\n+        else:\n+            source_tensors = []\n+            for tensor in node.input_tensors:\n+                previous_sources = get_source_inputs(tensor)\n+                # Avoid input redundancy.\n+                for x in previous_sources:\n+                    if all(x is not t for t in source_tensors):\n+                        source_tensors.append(x)\n+            return source_tensors\n\n@@ -0,0 +1,14 @@\n+from keras_core import backend\n+from keras_core import operations as ops\n+from keras_core import testing\n+from keras_core.operations import operation_utils\n+\n+\n+class OperationUtilsTest(testing.TestCase):\n+    def test_get_source_inputs(self):\n+        x1 = backend.KerasTensor(shape=(2,))\n+        x2 = backend.KerasTensor(shape=(2,))\n+        x = x1 + x2\n+        x += 2\n+        x = ops.square(x)\n+        self.assertEqual(operation_utils.get_source_inputs(x), [x1, x2])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b5b0796752246ff7af6882feda10c96155692ed3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 46 | Lines Deleted: 23 | Files Changed: 3 | Hunks: 22 | Methods Changed: 6 | Complexity Δ (Sum/Max): 10/10 | Churn Δ: 69 | Churn Cumulative: 4509 | Contributors (this commit): 10 | Commits (past 90d): 56 | Contributors (cumulative): 18 | DMM Complexity: 0.1111111111111111\n\nDIFF:\n@@ -532,7 +532,9 @@ def binary_crossentropy(target, output, from_logits=False):\n         )\n \n     if from_logits:\n-        output = jnn.sigmoid(output)\n+        log_logits = jax.nn.log_sigmoid(output)\n+        log_neg_logits = jax.nn.log_sigmoid(-output)\n+        return -1.0 * target * log_logits - (1.0 - target) * log_neg_logits\n \n     output = jnp.clip(output, epsilon(), 1.0 - epsilon())\n     bce = target * jnp.log(output)\n\n@@ -78,14 +78,14 @@ class NNOpsDynamicShapeTest(testing.TestCase):\n             knn.max_pool(x, 2, 2, padding=\"same\").shape, (None, 4, 3)\n         )\n \n-        x = KerasTensor([None, 8, 8, 3])\n-        self.assertEqual(knn.max_pool(x, 2, 1).shape, (None, 7, 7, 3))\n+        x = KerasTensor([None, 8, None, 3])\n+        self.assertEqual(knn.max_pool(x, 2, 1).shape, (None, 7, None, 3))\n         self.assertEqual(\n-            knn.max_pool(x, 2, 2, padding=\"same\").shape, (None, 4, 4, 3)\n+            knn.max_pool(x, 2, 2, padding=\"same\").shape, (None, 4, None, 3)\n         )\n         self.assertEqual(\n             knn.max_pool(x, (2, 2), (2, 2), padding=\"same\").shape,\n-            (None, 4, 4, 3),\n+            (None, 4, None, 3),\n         )\n \n     def test_average_pool(self):\n@@ -95,14 +95,14 @@ class NNOpsDynamicShapeTest(testing.TestCase):\n             knn.average_pool(x, 2, 2, padding=\"same\").shape, (None, 4, 3)\n         )\n \n-        x = KerasTensor([None, 8, 8, 3])\n-        self.assertEqual(knn.average_pool(x, 2, 1).shape, (None, 7, 7, 3))\n+        x = KerasTensor([None, 8, None, 3])\n+        self.assertEqual(knn.average_pool(x, 2, 1).shape, (None, 7, None, 3))\n         self.assertEqual(\n-            knn.average_pool(x, 2, 2, padding=\"same\").shape, (None, 4, 4, 3)\n+            knn.average_pool(x, 2, 2, padding=\"same\").shape, (None, 4, None, 3)\n         )\n         self.assertEqual(\n             knn.average_pool(x, (2, 2), (2, 2), padding=\"same\").shape,\n-            (None, 4, 4, 3),\n+            (None, 4, None, 3),\n         )\n \n     def test_conv(self):\n@@ -121,37 +121,37 @@ class NNOpsDynamicShapeTest(testing.TestCase):\n         )\n \n         # Test 2D conv.\n-        inputs_2d = KerasTensor([None, 10, 10, 3])\n+        inputs_2d = KerasTensor([None, 10, None, 3])\n         kernel = KerasTensor([2, 2, 3, 2])\n         self.assertEqual(\n             knn.conv(inputs_2d, kernel, 1, padding=\"valid\").shape,\n-            (None, 9, 9, 2),\n+            (None, 9, None, 2),\n         )\n         self.assertEqual(\n             knn.conv(inputs_2d, kernel, 1, padding=\"same\").shape,\n-            (None, 10, 10, 2),\n+            (None, 10, None, 2),\n         )\n         self.assertEqual(\n             knn.conv(inputs_2d, kernel, (2, 1), dilation_rate=(2, 1)).shape,\n-            (None, 4, 9, 2),\n+            (None, 4, None, 2),\n         )\n \n         # Test 3D conv.\n-        inputs_3d = KerasTensor([None, 8, 8, 8, 3])\n+        inputs_3d = KerasTensor([None, 8, None, 8, 3])\n         kernel = KerasTensor([3, 3, 3, 3, 2])\n         self.assertEqual(\n             knn.conv(inputs_3d, kernel, 1, padding=\"valid\").shape,\n-            (None, 6, 6, 6, 2),\n+            (None, 6, None, 6, 2),\n         )\n         self.assertEqual(\n             knn.conv(inputs_3d, kernel, (2, 1, 2), padding=\"same\").shape,\n-            (None, 4, 8, 4, 2),\n+            (None, 4, None, 4, 2),\n         )\n         self.assertEqual(\n             knn.conv(\n                 inputs_3d, kernel, 1, padding=\"valid\", dilation_rate=(1, 2, 2)\n             ).shape,\n-            (None, 6, 4, 4, 2),\n+            (None, 6, None, 4, 2),\n         )\n \n     def test_depthwise_conv(self):\n\n@@ -19,13 +19,20 @@ def compute_pooling_output_shape(\n         spatial_shape = input_shape[1:-1]\n     else:\n         spatial_shape = input_shape[2:]\n+    none_dims = []\n+    for i in range(len(spatial_shape)):\n+        if spatial_shape[i] is None:\n+            # Set `None` shape to a manual value so that we can run numpy\n+            # computation on `spatial_shape`.\n+            spatial_shape[i] = -1\n+            none_dims.append(i)\n     pool_size = np.array(pool_size)\n     if padding == \"valid\":\n         output_spatial_shape = (\n             np.floor((spatial_shape - pool_size) / strides) + 1\n         )\n-        negative_in_shape = np.all(output_spatial_shape < 0)\n-        if negative_in_shape:\n+        for i in range(len(output_spatial_shape)):\n+            if i not in none_dims and output_spatial_shape[i] < 0:\n                 raise ValueError(\n                     \"Computed output size would be negative. Received: \"\n                     f\"`inputs.shape={input_shape}` and `pool_size={pool_size}`.\"\n@@ -37,7 +44,10 @@ def compute_pooling_output_shape(\n             \"`padding` must be either `'valid'` or `'same'`. Received \"\n             f\"{padding}.\"\n         )\n-    output_spatial_shape = tuple([int(i) for i in output_spatial_shape])\n+    output_spatial_shape = [int(i) for i in output_spatial_shape]\n+    for i in none_dims:\n+        output_spatial_shape[i] = None\n+    output_spatial_shape = tuple(output_spatial_shape)\n     if data_format == \"channels_last\":\n         output_shape = (\n             (input_shape_origin[0],)\n@@ -85,7 +95,15 @@ def compute_conv_output_shape(\n             f\"`dilation_rate={dilation_rate}` and \"\n             f\"input of shape {input_shape}.\"\n         )\n+    none_dims = []\n     spatial_shape = np.array(spatial_shape)\n+    for i in range(len(spatial_shape)):\n+        if spatial_shape[i] is None:\n+            # Set `None` shape to a manual value so that we can run numpy\n+            # computation on `spatial_shape`.\n+            spatial_shape[i] = -1\n+            none_dims.append(i)\n+\n     kernel_spatial_shape = np.array(kernel_shape[:-2])\n     dilation_rate = np.array(dilation_rate)\n     if padding == \"valid\":\n@@ -96,8 +114,8 @@ def compute_conv_output_shape(\n             )\n             + 1\n         )\n-        negative_in_shape = np.all(output_spatial_shape < 0)\n-        if negative_in_shape:\n+        for i in range(len(output_spatial_shape)):\n+            if i not in none_dims and output_spatial_shape[i] < 0:\n                 raise ValueError(\n                     \"Computed output size would be negative. Received \"\n                     f\"`inputs shape={input_shape}`, \"\n@@ -106,7 +124,10 @@ def compute_conv_output_shape(\n                 )\n     elif padding == \"same\" or padding == \"causal\":\n         output_spatial_shape = np.floor((spatial_shape - 1) / strides) + 1\n-    output_spatial_shape = tuple([int(i) for i in output_spatial_shape])\n+    output_spatial_shape = [int(i) for i in output_spatial_shape]\n+    for i in none_dims:\n+        output_spatial_shape[i] = None\n+    output_spatial_shape = tuple(output_spatial_shape)\n     if data_format == \"channels_last\":\n         output_shape = (\n             (input_shape[0],) + output_spatial_shape + (kernel_shape[-1],)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0b3660a0384c60ad8b2e821738d0feefeec5ecff", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1445 | Lines Deleted: 0 | Files Changed: 7 | Hunks: 7 | Methods Changed: 26 | Complexity Δ (Sum/Max): 144/71 | Churn Δ: 1445 | Churn Cumulative: 3397 | Contributors (this commit): 7 | Commits (past 90d): 52 | Contributors (cumulative): 15 | DMM Complexity: 0.16811955168119552\n\nDIFF:\n@@ -0,0 +1,95 @@\n+import numpy as np\n+from absl.testing import parameterized\n+\n+from keras_core import backend\n+from keras_core import testing\n+from keras_core.applications import vgg16\n+from keras_core.applications import vgg19\n+from keras_core.applications import xception\n+from keras_core.utils import file_utils\n+from keras_core.utils import image_utils\n+\n+MODEL_LIST = [\n+    # cls, last_dim\n+    (vgg16.VGG16, 512, vgg16),\n+    (vgg19.VGG19, 512, vgg19),\n+    (xception.Xception, 2048, xception),\n+]\n+\n+\n+def _get_elephant(target_size):\n+    # For models that don't include a Flatten step,\n+    # the default is to accept variable-size inputs\n+    # even when loading ImageNet weights (since it is possible).\n+    # In this case, default to 299x299.\n+    TEST_IMAGE_PATH = (\n+        \"https://storage.googleapis.com/tensorflow/\"\n+        \"keras-applications/tests/elephant.jpg\"\n+    )\n+\n+    if target_size[0] is None:\n+        target_size = (299, 299)\n+    test_image = file_utils.get_file(\"elephant.jpg\", TEST_IMAGE_PATH)\n+    img = image_utils.load_img(test_image, target_size=tuple(target_size))\n+    x = image_utils.img_to_array(img)\n+    return np.expand_dims(x, axis=0)\n+\n+\n+class ApplicationsTest(testing.TestCase, parameterized.TestCase):\n+    @parameterized.parameters(MODEL_LIST)\n+    def test_application_notop_variable_input_channels(self, app, last_dim, _):\n+        # Test compatibility with 1 channel\n+        if backend.image_data_format() == \"channels_first\":\n+            input_shape = (1, None, None)\n+        else:\n+            input_shape = (None, None, 1)\n+        model = app(weights=None, include_top=False, input_shape=input_shape)\n+        output_shape = list(model.outputs[0].shape)\n+        self.assertEqual(output_shape, [None, None, None, last_dim])\n+\n+        # Test compatibility with 4 channels\n+        if backend.image_data_format() == \"channels_first\":\n+            input_shape = (4, None, None)\n+        else:\n+            input_shape = (None, None, 4)\n+        model = app(weights=None, include_top=False, input_shape=input_shape)\n+        output_shape = list(model.outputs[0].shape)\n+        self.assertEqual(output_shape, [None, None, None, last_dim])\n+\n+    @parameterized.parameters(MODEL_LIST)\n+    def test_application_base(self, app, _, app_module):\n+        # Can be instantiated with default arguments\n+        model = app(weights=\"imagenet\")\n+\n+        # Can run a correct inference on a test image\n+        x = _get_elephant(model.input_shape[1:3])\n+        x = app_module.preprocess_input(x)\n+        preds = model.predict(x)\n+        names = [p[1] for p in app_module.decode_predictions(preds)[0]]\n+        # Test correct label is in top 3 (weak correctness test).\n+        self.assertIn(\"African_elephant\", names[:3])\n+\n+        # Can be serialized and deserialized\n+        config = model.get_config()\n+        reconstructed_model = model.__class__.from_config(config)\n+        self.assertEqual(len(model.weights), len(reconstructed_model.weights))\n+\n+    @parameterized.parameters(MODEL_LIST)\n+    def test_application_notop_custom_input_shape(self, app, last_dim, _):\n+        model = app(weights=None, include_top=False, input_shape=(123, 123, 3))\n+        output_shape = list(model.outputs[0].shape)\n+        self.assertEqual(output_shape[-1], last_dim)\n+\n+    @parameterized.parameters(MODEL_LIST)\n+    def test_application_pooling(self, app, last_dim, _):\n+        model = app(weights=None, include_top=False, pooling=\"max\")\n+        output_shape = list(model.outputs[0].shape)\n+        self.assertEqual(output_shape, [None, last_dim])\n+\n+    @parameterized.parameters(MODEL_LIST)\n+    def test_application_classifier_activation(self, app, *_):\n+        model = app(\n+            weights=None, include_top=True, classifier_activation=\"softmax\"\n+        )\n+        last_layer_act = model.layers[-1].activation.__name__\n+        self.assertEqual(last_layer_act, \"softmax\")\n\n@@ -0,0 +1,460 @@\n+import json\n+import warnings\n+\n+import numpy as np\n+\n+from keras_core import activations\n+from keras_core import backend\n+from keras_core.api_export import keras_core_export\n+from keras_core.utils import file_utils\n+\n+CLASS_INDEX = None\n+CLASS_INDEX_PATH = (\n+    \"https://storage.googleapis.com/download.tensorflow.org/\"\n+    \"data/imagenet_class_index.json\"\n+)\n+\n+\n+PREPROCESS_INPUT_DOC = \"\"\"\n+  Preprocesses a tensor or Numpy array encoding a batch of images.\n+\n+  Usage example with `applications.MobileNet`:\n+\n+  ```python\n+  i = keras_core.layers.Input([None, None, 3], dtype=\"uint8\")\n+  x = ops.cast(i, \"float32\")\n+  x = keras_core.applications.mobilenet.preprocess_input(x)\n+  core = keras_core.applications.MobileNet()\n+  x = core(x)\n+  model = keras_core.Model(inputs=[i], outputs=[x])\n+  result = model(image)\n+  ```\n+\n+  Args:\n+        x: A floating point `numpy.array` or a backend-native tensor,\n+            3D or 4D with 3 color\n+            channels, with values in the range [0, 255].\n+            The preprocessed data are written over the input data\n+        if the data types are compatible. To avoid this\n+        behaviour, `numpy.copy(x)` can be used.\n+        data_format: Optional data format of the image tensor/array. None, means\n+        the global setting `keras_core.backend.image_data_format()` is used\n+        (unless you changed it, it uses \"channels_last\").{mode}\n+        Defaults to `None`.\n+\n+  Returns:\n+      Preprocessed array with type `float32`.\n+      {ret}\n+\n+  Raises:\n+      {error}\n+  \"\"\"\n+\n+PREPROCESS_INPUT_MODE_DOC = \"\"\"\n+    mode: One of \"caffe\", \"tf\" or \"torch\".\n+      - caffe: will convert the images from RGB to BGR,\n+          then will zero-center each color channel with\n+          respect to the ImageNet dataset,\n+          without scaling.\n+      - tf: will scale pixels between -1 and 1,\n+          sample-wise.\n+      - torch: will scale pixels between 0 and 1 and then\n+          will normalize each channel with respect to the\n+          ImageNet dataset.\n+      Defaults to \"caffe\".\n+  \"\"\"\n+\n+PREPROCESS_INPUT_DEFAULT_ERROR_DOC = \"\"\"\n+    ValueError: In case of unknown `mode` or `data_format` argument.\"\"\"\n+\n+PREPROCESS_INPUT_ERROR_DOC = \"\"\"\n+    ValueError: In case of unknown `data_format` argument.\"\"\"\n+\n+PREPROCESS_INPUT_RET_DOC_TF = \"\"\"\n+      The inputs pixel values are scaled between -1 and 1, sample-wise.\"\"\"\n+\n+PREPROCESS_INPUT_RET_DOC_TORCH = \"\"\"\n+      The input pixels values are scaled between 0 and 1 and each channel is\n+      normalized with respect to the ImageNet dataset.\"\"\"\n+\n+PREPROCESS_INPUT_RET_DOC_CAFFE = \"\"\"\n+      The images are converted from RGB to BGR, then each color channel is\n+      zero-centered with respect to the ImageNet dataset, without scaling.\"\"\"\n+\n+\n+@keras_core_export(\"keras_core.applications.imagenet_utils.preprocess_input\")\n+def preprocess_input(x, data_format=None, mode=\"caffe\"):\n+    \"\"\"Preprocesses a tensor or Numpy array encoding a batch of images.\"\"\"\n+    if mode not in {\"caffe\", \"tf\", \"torch\"}:\n+        raise ValueError(\n+            \"Expected mode to be one of `caffe`, `tf` or `torch`. \"\n+            f\"Received: mode={mode}\"\n+        )\n+\n+    if data_format is None:\n+        data_format = backend.image_data_format()\n+    elif data_format not in {\"channels_first\", \"channels_last\"}:\n+        raise ValueError(\n+            \"Expected data_format to be one of `channels_first` or \"\n+            f\"`channels_last`. Received: data_format={data_format}\"\n+        )\n+\n+    if isinstance(x, np.ndarray):\n+        return _preprocess_numpy_input(x, data_format=data_format, mode=mode)\n+    else:\n+        return _preprocess_symbolic_input(x, data_format=data_format, mode=mode)\n+\n+\n+preprocess_input.__doc__ = PREPROCESS_INPUT_DOC.format(\n+    mode=PREPROCESS_INPUT_MODE_DOC,\n+    ret=\"\",\n+    error=PREPROCESS_INPUT_DEFAULT_ERROR_DOC,\n+)\n+\n+\n+@keras_core_export(\"keras_core.applications.imagenet_utils.decode_predictions\")\n+def decode_predictions(preds, top=5):\n+    \"\"\"Decodes the prediction of an ImageNet model.\n+\n+    Args:\n+      preds: Numpy array encoding a batch of predictions.\n+      top: Integer, how many top-guesses to return. Defaults to 5.\n+\n+    Returns:\n+      A list of lists of top class prediction tuples\n+      `(class_name, class_description, score)`.\n+      One list of tuples per sample in batch input.\n+\n+    Raises:\n+      ValueError: In case of invalid shape of the `pred` array\n+        (must be 2D).\n+    \"\"\"\n+    global CLASS_INDEX\n+\n+    if len(preds.shape) != 2 or preds.shape[1] != 1000:\n+        raise ValueError(\n+            \"`decode_predictions` expects \"\n+            \"a batch of predictions \"\n+            \"(i.e. a 2D array of shape (samples, 1000)). \"\n+            \"Found array with shape: \" + str(preds.shape)\n+        )\n+    if CLASS_INDEX is None:\n+        fpath = file_utils.get_file(\n+            \"imagenet_class_index.json\",\n+            CLASS_INDEX_PATH,\n+            cache_subdir=\"models\",\n+            file_hash=\"c2c37ea517e94d9795004a39431a14cb\",\n+        )\n+        with open(fpath) as f:\n+            CLASS_INDEX = json.load(f)\n+    results = []\n+    for pred in preds:\n+        top_indices = pred.argsort()[-top:][::-1]\n+        result = [tuple(CLASS_INDEX[str(i)]) + (pred[i],) for i in top_indices]\n+        result.sort(key=lambda x: x[2], reverse=True)\n+        results.append(result)\n+    return results\n+\n+\n+def _preprocess_numpy_input(x, data_format, mode):\n+    \"\"\"Preprocesses a NumPy array encoding a batch of images.\n+\n+    Args:\n+      x: Input array, 3D or 4D.\n+      data_format: Data format of the image array.\n+      mode: One of \"caffe\", \"tf\" or \"torch\".\n+        - caffe: will convert the images from RGB to BGR,\n+            then will zero-center each color channel with\n+            respect to the ImageNet dataset,\n+            without scaling.\n+        - tf: will scale pixels between -1 and 1,\n+            sample-wise.\n+        - torch: will scale pixels between 0 and 1 and then\n+            will normalize each channel with respect to the\n+            ImageNet dataset.\n+\n+    Returns:\n+        Preprocessed Numpy array.\n+    \"\"\"\n+    if not issubclass(x.dtype.type, np.floating):\n+        x = x.astype(backend.floatx(), copy=False)\n+\n+    if mode == \"tf\":\n+        x /= 127.5\n+        x -= 1.0\n+        return x\n+    elif mode == \"torch\":\n+        x /= 255.0\n+        mean = [0.485, 0.456, 0.406]\n+        std = [0.229, 0.224, 0.225]\n+    else:\n+        if data_format == \"channels_first\":\n+            # 'RGB'->'BGR'\n+            if x.ndim == 3:\n+                x = x[::-1, ...]\n+            else:\n+                x = x[:, ::-1, ...]\n+        else:\n+            # 'RGB'->'BGR'\n+            x = x[..., ::-1]\n+        mean = [103.939, 116.779, 123.68]\n+        std = None\n+\n+    # Zero-center by mean pixel\n+    if data_format == \"channels_first\":\n+        if x.ndim == 3:\n+            x[0, :, :] -= mean[0]\n+            x[1, :, :] -= mean[1]\n+            x[2, :, :] -= mean[2]\n+            if std is not None:\n+                x[0, :, :] /= std[0]\n+                x[1, :, :] /= std[1]\n+                x[2, :, :] /= std[2]\n+        else:\n+            x[:, 0, :, :] -= mean[0]\n+            x[:, 1, :, :] -= mean[1]\n+            x[:, 2, :, :] -= mean[2]\n+            if std is not None:\n+                x[:, 0, :, :] /= std[0]\n+                x[:, 1, :, :] /= std[1]\n+                x[:, 2, :, :] /= std[2]\n+    else:\n+        x[..., 0] -= mean[0]\n+        x[..., 1] -= mean[1]\n+        x[..., 2] -= mean[2]\n+        if std is not None:\n+            x[..., 0] /= std[0]\n+            x[..., 1] /= std[1]\n+            x[..., 2] /= std[2]\n+    return x\n+\n+\n+def _preprocess_symbolic_input(x, data_format, mode):\n+    \"\"\"Preprocesses a tensor encoding a batch of images.\n+\n+    Args:\n+      x: Input tensor, 3D or 4D.\n+      data_format: Data format of the image tensor.\n+      mode: One of \"caffe\", \"tf\" or \"torch\".\n+        - caffe: will convert the images from RGB to BGR,\n+            then will zero-center each color channel with\n+            respect to the ImageNet dataset,\n+            without scaling.\n+        - tf: will scale pixels between -1 and 1,\n+            sample-wise.\n+        - torch: will scale pixels between 0 and 1 and then\n+            will normalize each channel with respect to the\n+            ImageNet dataset.\n+\n+    Returns:\n+        Preprocessed tensor.\n+    \"\"\"\n+    if mode == \"tf\":\n+        x /= 127.5\n+        x -= 1.0\n+        return x\n+    elif mode == \"torch\":\n+        x /= 255.0\n+        mean = [0.485, 0.456, 0.406]\n+        std = [0.229, 0.224, 0.225]\n+    else:\n+        if data_format == \"channels_first\":\n+            # 'RGB'->'BGR'\n+            if backend.ndim(x) == 3:\n+                x = x[::-1, ...]\n+            else:\n+                x = x[:, ::-1, ...]\n+        else:\n+            # 'RGB'->'BGR'\n+            x = x[..., ::-1]\n+        mean = [103.939, 116.779, 123.68]\n+        std = None\n+\n+    mean_tensor = backend.constant(-np.array(mean))\n+\n+    # Zero-center by mean pixel\n+    if backend.dtype(x) != backend.dtype(mean_tensor):\n+        x = backend.bias_add(\n+            x,\n+            backend.cast(mean_tensor, backend.dtype(x)),\n+            data_format=data_format,\n+        )\n+    else:\n+        x = backend.bias_add(x, mean_tensor, data_format)\n+    if std is not None:\n+        std_tensor = backend.constant(np.array(std), dtype=backend.dtype(x))\n+        if data_format == \"channels_first\":\n+            std_tensor = backend.reshape(std_tensor, (-1, 1, 1))\n+        x /= std_tensor\n+    return x\n+\n+\n+def obtain_input_shape(\n+    input_shape,\n+    default_size,\n+    min_size,\n+    data_format,\n+    require_flatten,\n+    weights=None,\n+):\n+    \"\"\"Internal utility to compute/validate a model's input shape.\n+\n+    Args:\n+      input_shape: Either None (will return the default network input shape),\n+        or a user-provided shape to be validated.\n+      default_size: Default input width/height for the model.\n+      min_size: Minimum input width/height accepted by the model.\n+      data_format: Image data format to use.\n+      require_flatten: Whether the model is expected to\n+        be linked to a classifier via a Flatten layer.\n+      weights: One of `None` (random initialization)\n+        or 'imagenet' (pre-training on ImageNet).\n+        If weights='imagenet' input channels must be equal to 3.\n+\n+    Returns:\n+      An integer shape tuple (may include None entries).\n+\n+    Raises:\n+      ValueError: In case of invalid argument values.\n+    \"\"\"\n+    if weights != \"imagenet\" and input_shape and len(input_shape) == 3:\n+        if data_format == \"channels_first\":\n+            if input_shape[0] not in {1, 3}:\n+                warnings.warn(\n+                    \"This model usually expects 1 or 3 input channels. \"\n+                    \"However, it was passed an input_shape \"\n+                    f\"with {input_shape[0]} input channels.\",\n+                    stacklevel=2,\n+                )\n+            default_shape = (input_shape[0], default_size, default_size)\n+        else:\n+            if input_shape[-1] not in {1, 3}:\n+                warnings.warn(\n+                    \"This model usually expects 1 or 3 input channels. \"\n+                    \"However, it was passed an input_shape \"\n+                    f\"with {input_shape[-1]} input channels.\",\n+                    stacklevel=2,\n+                )\n+            default_shape = (default_size, default_size, input_shape[-1])\n+    else:\n+        if data_format == \"channels_first\":\n+            default_shape = (3, default_size, default_size)\n+        else:\n+            default_shape = (default_size, default_size, 3)\n+    if weights == \"imagenet\" and require_flatten:\n+        if input_shape is not None:\n+            if input_shape != default_shape:\n+                raise ValueError(\n+                    \"When setting `include_top=True` \"\n+                    \"and loading `imagenet` weights, \"\n+                    f\"`input_shape` should be {default_shape}.  \"\n+                    f\"Received: input_shape={input_shape}\"\n+                )\n+        return default_shape\n+    if input_shape:\n+        if data_format == \"channels_first\":\n+            if input_shape is not None:\n+                if len(input_shape) != 3:\n+                    raise ValueError(\n+                        \"`input_shape` must be a tuple of three integers.\"\n+                    )\n+                if input_shape[0] != 3 and weights == \"imagenet\":\n+                    raise ValueError(\n+                        \"The input must have 3 channels; Received \"\n+                        f\"`input_shape={input_shape}`\"\n+                    )\n+                if (\n+                    input_shape[1] is not None and input_shape[1] < min_size\n+                ) or (input_shape[2] is not None and input_shape[2] < min_size):\n+                    raise ValueError(\n+                        f\"Input size must be at least {min_size}\"\n+                        f\"x{min_size}; Received: \"\n+                        f\"input_shape={input_shape}\"\n+                    )\n+        else:\n+            if input_shape is not None:\n+                if len(input_shape) != 3:\n+                    raise ValueError(\n+                        \"`input_shape` must be a tuple of three integers.\"\n+                    )\n+                if input_shape[-1] != 3 and weights == \"imagenet\":\n+                    raise ValueError(\n+                        \"The input must have 3 channels; Received \"\n+                        f\"`input_shape={input_shape}`\"\n+                    )\n+                if (\n+                    input_shape[0] is not None and input_shape[0] < min_size\n+                ) or (input_shape[1] is not None and input_shape[1] < min_size):\n+                    raise ValueError(\n+                        \"Input size must be at least \"\n+                        f\"{min_size}x{min_size}; Received: \"\n+                        f\"input_shape={input_shape}\"\n+                    )\n+    else:\n+        if require_flatten:\n+            input_shape = default_shape\n+        else:\n+            if data_format == \"channels_first\":\n+                input_shape = (3, None, None)\n+            else:\n+                input_shape = (None, None, 3)\n+    if require_flatten:\n+        if None in input_shape:\n+            raise ValueError(\n+                \"If `include_top` is True, \"\n+                \"you should specify a static `input_shape`. \"\n+                f\"Received: input_shape={input_shape}\"\n+            )\n+    return input_shape\n+\n+\n+def correct_pad(inputs, kernel_size):\n+    \"\"\"Returns a tuple for zero-padding for 2D convolution with downsampling.\n+\n+    Args:\n+      inputs: Input tensor.\n+      kernel_size: An integer or tuple/list of 2 integers.\n+\n+    Returns:\n+      A tuple.\n+    \"\"\"\n+    img_dim = 2 if backend.image_data_format() == \"channels_first\" else 1\n+    input_size = backend.int_shape(inputs)[img_dim : (img_dim + 2)]\n+    if isinstance(kernel_size, int):\n+        kernel_size = (kernel_size, kernel_size)\n+    if input_size[0] is None:\n+        adjust = (1, 1)\n+    else:\n+        adjust = (1 - input_size[0] % 2, 1 - input_size[1] % 2)\n+    correct = (kernel_size[0] // 2, kernel_size[1] // 2)\n+    return (\n+        (correct[0] - adjust[0], correct[0]),\n+        (correct[1] - adjust[1], correct[1]),\n+    )\n+\n+\n+def validate_activation(classifier_activation, weights):\n+    \"\"\"validates that the classifer_activation is compatible with the weights.\n+\n+    Args:\n+      classifier_activation: str or callable activation function\n+      weights: The pretrained weights to load.\n+\n+    Raises:\n+      ValueError: if an activation other than `None` or `softmax` are used with\n+        pretrained weights.\n+    \"\"\"\n+    if weights is None:\n+        return\n+\n+    classifier_activation = activations.get(classifier_activation)\n+    if classifier_activation not in {\n+        activations.get(\"softmax\"),\n+        activations.get(None),\n+    }:\n+        raise ValueError(\n+            \"Only `None` and `softmax` activations are allowed \"\n+            \"for the `classifier_activation` argument when using \"\n+            \"pretrained weights, with `include_top=True`; Received: \"\n+            f\"classifier_activation={classifier_activation}\"\n+        )\n\n@@ -0,0 +1,249 @@\n+from tensorflow.io import gfile\n+\n+from keras_core import backend\n+from keras_core import layers\n+from keras_core.api_export import keras_core_export\n+from keras_core.applications import imagenet_utils\n+from keras_core.models import Functional\n+from keras_core.operations import operation_utils\n+from keras_core.utils import file_utils\n+\n+WEIGHTS_PATH = (\n+    \"https://storage.googleapis.com/tensorflow/keras-applications/\"\n+    \"vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\"\n+)\n+WEIGHTS_PATH_NO_TOP = (\n+    \"https://storage.googleapis.com/tensorflow/\"\n+    \"keras-applications/vgg16/\"\n+    \"vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n+)\n+\n+\n+@keras_core_export(\n+    [\"keras_core.applications.vgg16.VGG16\", \"keras_core.applications.VGG16\"]\n+)\n+def VGG16(\n+    include_top=True,\n+    weights=\"imagenet\",\n+    input_tensor=None,\n+    input_shape=None,\n+    pooling=None,\n+    classes=1000,\n+    classifier_activation=\"softmax\",\n+):\n+    \"\"\"Instantiates the VGG16 model.\n+\n+    Reference:\n+    - [Very Deep Convolutional Networks for Large-Scale Image Recognition](\n+    https://arxiv.org/abs/1409.1556) (ICLR 2015)\n+\n+    For image classification use cases, see\n+    [this page for detailed examples](\n+      https://keras.io/api/applications/#usage-examples-for-image-classification-models).\n+\n+    For transfer learning use cases, make sure to read the\n+    [guide to transfer learning & fine-tuning](\n+      https://keras.io/guides/transfer_learning/).\n+\n+    The default input size for this model is 224x224.\n+\n+    Note: each Keras Application expects a specific kind of input preprocessing.\n+    For VGG16, call `keras_core.applications.vgg16.preprocess_input` on your\n+    inputs before passing them to the model.\n+    `vgg16.preprocess_input` will convert the input images from RGB to BGR,\n+    then will zero-center each color channel with respect to the ImageNet\n+    dataset, without scaling.\n+\n+    Args:\n+        include_top: whether to include the 3 fully-connected\n+            layers at the top of the network.\n+        weights: one of `None` (random initialization),\n+            `\"imagenet\"` (pre-training on ImageNet),\n+            or the path to the weights file to be loaded.\n+        input_tensor: optional Keras tensor\n+            (i.e. output of `layers.Input()`)\n+            to use as image input for the model.\n+        input_shape: optional shape tuple, only to be specified\n+            if `include_top` is `False` (otherwise the input shape\n+            has to be `(224, 224, 3)`\n+            (with `channels_last` data format) or\n+            `(3, 224, 224)` (with `\"channels_first\"` data format).\n+            It should have exactly 3 input channels,\n+            and width and height should be no smaller than 32.\n+            E.g. `(200, 200, 3)` would be one valid value.\n+        pooling: Optional pooling mode for feature extraction\n+            when `include_top` is `False`.\n+            - `None` means that the output of the model will be\n+                the 4D tensor output of the\n+                last convolutional block.\n+            - `avg` means that global average pooling\n+                will be applied to the output of the\n+                last convolutional block, and thus\n+                the output of the model will be a 2D tensor.\n+            - `max` means that global max pooling will\n+                be applied.\n+        classes: optional number of classes to classify images\n+            into, only to be specified if `include_top` is `True`, and\n+            if no `weights` argument is specified.\n+        classifier_activation: A `str` or callable. The activation function to\n+            use on the \"top\" layer. Ignored unless `include_top=True`. Set\n+            `classifier_activation=None` to return the logits of the \"top\"\n+            layer.  When loading pretrained weights, `classifier_activation` can\n+            only be `None` or `\"softmax\"`.\n+\n+    Returns:\n+        A model instance.\n+    \"\"\"\n+    if not (weights in {\"imagenet\", None} or gfile.exists(weights)):\n+        raise ValueError(\n+            \"The `weights` argument should be either \"\n+            \"`None` (random initialization), `imagenet` \"\n+            \"(pre-training on ImageNet), \"\n+            \"or the path to the weights file to be loaded.  Received: \"\n+            f\"weights={weights}\"\n+        )\n+\n+    if weights == \"imagenet\" and include_top and classes != 1000:\n+        raise ValueError(\n+            'If using `weights` as `\"imagenet\"` with `include_top` '\n+            \"as true, `classes` should be 1000.  \"\n+            f\"Received `classes={classes}`\"\n+        )\n+    # Determine proper input shape\n+    input_shape = imagenet_utils.obtain_input_shape(\n+        input_shape,\n+        default_size=224,\n+        min_size=32,\n+        data_format=backend.image_data_format(),\n+        require_flatten=include_top,\n+        weights=weights,\n+    )\n+\n+    if input_tensor is None:\n+        img_input = layers.Input(shape=input_shape)\n+    else:\n+        if not backend.is_keras_tensor(input_tensor):\n+            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n+        else:\n+            img_input = input_tensor\n+    # Block 1\n+    x = layers.Conv2D(\n+        64, (3, 3), activation=\"relu\", padding=\"same\", name=\"block1_conv1\"\n+    )(img_input)\n+    x = layers.Conv2D(\n+        64, (3, 3), activation=\"relu\", padding=\"same\", name=\"block1_conv2\"\n+    )(x)\n+    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block1_pool\")(x)\n+\n+    # Block 2\n+    x = layers.Conv2D(\n+        128, (3, 3), activation=\"relu\", padding=\"same\", name=\"block2_conv1\"\n+    )(x)\n+    x = layers.Conv2D(\n+        128, (3, 3), activation=\"relu\", padding=\"same\", name=\"block2_conv2\"\n+    )(x)\n+    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block2_pool\")(x)\n+\n+    # Block 3\n+    x = layers.Conv2D(\n+        256, (3, 3), activation=\"relu\", padding=\"same\", name=\"block3_conv1\"\n+    )(x)\n+    x = layers.Conv2D(\n+        256, (3, 3), activation=\"relu\", padding=\"same\", name=\"block3_conv2\"\n+    )(x)\n+    x = layers.Conv2D(\n+        256, (3, 3), activation=\"relu\", padding=\"same\", name=\"block3_conv3\"\n+    )(x)\n+    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block3_pool\")(x)\n+\n+    # Block 4\n+    x = layers.Conv2D(\n+        512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block4_conv1\"\n+    )(x)\n+    x = layers.Conv2D(\n+        512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block4_conv2\"\n+    )(x)\n+    x = layers.Conv2D(\n+        512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block4_conv3\"\n+    )(x)\n+    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block4_pool\")(x)\n+\n+    # Block 5\n+    x = layers.Conv2D(\n+        512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block5_conv1\"\n+    )(x)\n+    x = layers.Conv2D(\n+        512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block5_conv2\"\n+    )(x)\n+    x = layers.Conv2D(\n+        512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block5_conv3\"\n+    )(x)\n+    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block5_pool\")(x)\n+\n+    if include_top:\n+        # Classification block\n+        x = layers.Flatten(name=\"flatten\")(x)\n+        x = layers.Dense(4096, activation=\"relu\", name=\"fc1\")(x)\n+        x = layers.Dense(4096, activation=\"relu\", name=\"fc2\")(x)\n+\n+        imagenet_utils.validate_activation(classifier_activation, weights)\n+        x = layers.Dense(\n+            classes, activation=classifier_activation, name=\"predictions\"\n+        )(x)\n+    else:\n+        if pooling == \"avg\":\n+            x = layers.GlobalAveragePooling2D()(x)\n+        elif pooling == \"max\":\n+            x = layers.GlobalMaxPooling2D()(x)\n+\n+    # Ensure that the model takes into account\n+    # any potential predecessors of `input_tensor`.\n+    if input_tensor is not None:\n+        inputs = operation_utils.get_source_inputs(input_tensor)\n+    else:\n+        inputs = img_input\n+\n+    # Create model.\n+    model = Functional(inputs, x, name=\"vgg16\")\n+\n+    # Load weights.\n+    if weights == \"imagenet\":\n+        if include_top:\n+            weights_path = file_utils.get_file(\n+                \"vgg16_weights_tf_dim_ordering_tf_kernels.h5\",\n+                WEIGHTS_PATH,\n+                cache_subdir=\"models\",\n+                file_hash=\"64373286793e3c8b2b4e3219cbf3544b\",\n+            )\n+        else:\n+            weights_path = file_utils.get_file(\n+                \"vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n+                WEIGHTS_PATH_NO_TOP,\n+                cache_subdir=\"models\",\n+                file_hash=\"6d6bbae143d832006294945121d1f1fc\",\n+            )\n+        model.load_weights(weights_path)\n+    elif weights is not None:\n+        model.load_weights(weights)\n+\n+    return model\n+\n+\n+@keras_core_export(\"keras_core.applications.vgg16.preprocess_input\")\n+def preprocess_input(x, data_format=None):\n+    return imagenet_utils.preprocess_input(\n+        x, data_format=data_format, mode=\"caffe\"\n+    )\n+\n+\n+@keras_core_export(\"keras_core.applications.vgg16.decode_predictions\")\n+def decode_predictions(preds, top=5):\n+    return imagenet_utils.decode_predictions(preds, top=top)\n+\n+\n+preprocess_input.__doc__ = imagenet_utils.PREPROCESS_INPUT_DOC.format(\n+    mode=\"\",\n+    ret=imagenet_utils.PREPROCESS_INPUT_RET_DOC_CAFFE,\n+    error=imagenet_utils.PREPROCESS_INPUT_ERROR_DOC,\n+)\n+decode_predictions.__doc__ = imagenet_utils.decode_predictions.__doc__\n\n@@ -0,0 +1,257 @@\n+from tensorflow.io import gfile\n+\n+from keras_core import backend\n+from keras_core import layers\n+from keras_core.api_export import keras_core_export\n+from keras_core.applications import imagenet_utils\n+from keras_core.models import Functional\n+from keras_core.operations import operation_utils\n+from keras_core.utils import file_utils\n+\n+WEIGHTS_PATH = (\n+    \"https://storage.googleapis.com/tensorflow/keras-applications/\"\n+    \"vgg19/vgg19_weights_tf_dim_ordering_tf_kernels.h5\"\n+)\n+WEIGHTS_PATH_NO_TOP = (\n+    \"https://storage.googleapis.com/tensorflow/\"\n+    \"keras-applications/vgg19/\"\n+    \"vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n+)\n+\n+\n+@keras_core_export(\n+    [\"keras_core.applications.vgg19.VGG19\", \"keras_core.applications.VGG19\"]\n+)\n+def VGG19(\n+    include_top=True,\n+    weights=\"imagenet\",\n+    input_tensor=None,\n+    input_shape=None,\n+    pooling=None,\n+    classes=1000,\n+    classifier_activation=\"softmax\",\n+):\n+    \"\"\"Instantiates the VGG19 model.\n+\n+    Reference:\n+    - [Very Deep Convolutional Networks for Large-Scale Image Recognition](\n+    https://arxiv.org/abs/1409.1556) (ICLR 2015)\n+\n+    For image classification use cases, see\n+    [this page for detailed examples](\n+      https://keras.io/api/applications/#usage-examples-for-image-classification-models).\n+\n+    For transfer learning use cases, make sure to read the\n+    [guide to transfer learning & fine-tuning](\n+      https://keras.io/guides/transfer_learning/).\n+\n+    The default input size for this model is 224x224.\n+\n+    Note: each Keras Application expects a specific kind of input preprocessing.\n+    For VGG19, call `keras_core.applications.vgg19.preprocess_input` on your\n+    inputs before passing them to the model.\n+    `vgg19.preprocess_input` will convert the input images from RGB to BGR,\n+    then will zero-center each color channel with respect to the ImageNet\n+    dataset, without scaling.\n+\n+    Args:\n+        include_top: whether to include the 3 fully-connected\n+            layers at the top of the network.\n+        weights: one of `None` (random initialization),\n+            `\"imagenet\"` (pre-training on ImageNet),\n+            or the path to the weights file to be loaded.\n+        input_tensor: optional Keras tensor\n+            (i.e. output of `layers.Input()`)\n+            to use as image input for the model.\n+        input_shape: optional shape tuple, only to be specified\n+            if `include_top` is `False` (otherwise the input shape\n+            has to be `(224, 224, 3)`\n+            (with `channels_last` data format) or\n+            `(3, 224, 224)` (with `\"channels_first\"` data format).\n+            It should have exactly 3 input channels,\n+            and width and height should be no smaller than 32.\n+            E.g. `(200, 200, 3)` would be one valid value.\n+        pooling: Optional pooling mode for feature extraction\n+            when `include_top` is `False`.\n+            - `None` means that the output of the model will be\n+                the 4D tensor output of the\n+                last convolutional block.\n+            - `avg` means that global average pooling\n+                will be applied to the output of the\n+                last convolutional block, and thus\n+                the output of the model will be a 2D tensor.\n+            - `max` means that global max pooling will\n+                be applied.\n+        classes: optional number of classes to classify images\n+            into, only to be specified if `include_top` is `True`, and\n+            if no `weights` argument is specified.\n+        classifier_activation: A `str` or callable. The activation function to\n+            use on the \"top\" layer. Ignored unless `include_top=True`. Set\n+            `classifier_activation=None` to return the logits of the \"top\"\n+            layer.  When loading pretrained weights, `classifier_activation` can\n+            only be `None` or `\"softmax\"`.\n+\n+    Returns:\n+        A model instance.\n+    \"\"\"\n+    if not (weights in {\"imagenet\", None} or gfile.exists(weights)):\n+        raise ValueError(\n+            \"The `weights` argument should be either \"\n+            \"`None` (random initialization), `imagenet` \"\n+            \"(pre-training on ImageNet), \"\n+            \"or the path to the weights file to be loaded.  Received: \"\n+            f\"weights={weights}\"\n+        )\n+\n+    if weights == \"imagenet\" and include_top and classes != 1000:\n+        raise ValueError(\n+            'If using `weights` as `\"imagenet\"` with `include_top` '\n+            \"as true, `classes` should be 1000.  \"\n+            f\"Received `classes={classes}`\"\n+        )\n+    # Determine proper input shape\n+    input_shape = imagenet_utils.obtain_input_shape(\n+        input_shape,\n+        default_size=224,\n+        min_size=32,\n+        data_format=backend.image_data_format(),\n+        require_flatten=include_top,\n+        weights=weights,\n+    )\n+\n+    if input_tensor is None:\n+        img_input = layers.Input(shape=input_shape)\n+    else:\n+        if not backend.is_keras_tensor(input_tensor):\n+            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n+        else:\n+            img_input = input_tensor\n+    # Block 1\n+    x = layers.Conv2D(\n+        64, (3, 3), activation=\"relu\", padding=\"same\", name=\"block1_conv1\"\n+    )(img_input)\n+    x = layers.Conv2D(\n+        64, (3, 3), activation=\"relu\", padding=\"same\", name=\"block1_conv2\"\n+    )(x)\n+    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block1_pool\")(x)\n+\n+    # Block 2\n+    x = layers.Conv2D(\n+        128, (3, 3), activation=\"relu\", padding=\"same\", name=\"block2_conv1\"\n+    )(x)\n+    x = layers.Conv2D(\n+        128, (3, 3), activation=\"relu\", padding=\"same\", name=\"block2_conv2\"\n+    )(x)\n+    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block2_pool\")(x)\n+\n+    # Block 3\n+    x = layers.Conv2D(\n+        256, (3, 3), activation=\"relu\", padding=\"same\", name=\"block3_conv1\"\n+    )(x)\n+    x = layers.Conv2D(\n+        256, (3, 3), activation=\"relu\", padding=\"same\", name=\"block3_conv2\"\n+    )(x)\n+    x = layers.Conv2D(\n+        256, (3, 3), activation=\"relu\", padding=\"same\", name=\"block3_conv3\"\n+    )(x)\n+    x = layers.Conv2D(\n+        256, (3, 3), activation=\"relu\", padding=\"same\", name=\"block3_conv4\"\n+    )(x)\n+    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block3_pool\")(x)\n+\n+    # Block 4\n+    x = layers.Conv2D(\n+        512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block4_conv1\"\n+    )(x)\n+    x = layers.Conv2D(\n+        512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block4_conv2\"\n+    )(x)\n+    x = layers.Conv2D(\n+        512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block4_conv3\"\n+    )(x)\n+    x = layers.Conv2D(\n+        512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block4_conv4\"\n+    )(x)\n+    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block4_pool\")(x)\n+\n+    # Block 5\n+    x = layers.Conv2D(\n+        512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block5_conv1\"\n+    )(x)\n+    x = layers.Conv2D(\n+        512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block5_conv2\"\n+    )(x)\n+    x = layers.Conv2D(\n+        512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block5_conv3\"\n+    )(x)\n+    x = layers.Conv2D(\n+        512, (3, 3), activation=\"relu\", padding=\"same\", name=\"block5_conv4\"\n+    )(x)\n+    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"block5_pool\")(x)\n+\n+    if include_top:\n+        # Classification block\n+        x = layers.Flatten(name=\"flatten\")(x)\n+        x = layers.Dense(4096, activation=\"relu\", name=\"fc1\")(x)\n+        x = layers.Dense(4096, activation=\"relu\", name=\"fc2\")(x)\n+        imagenet_utils.validate_activation(classifier_activation, weights)\n+        x = layers.Dense(\n+            classes, activation=classifier_activation, name=\"predictions\"\n+        )(x)\n+    else:\n+        if pooling == \"avg\":\n+            x = layers.GlobalAveragePooling2D()(x)\n+        elif pooling == \"max\":\n+            x = layers.GlobalMaxPooling2D()(x)\n+\n+    # Ensure that the model takes into account\n+    # any potential predecessors of `input_tensor`.\n+    if input_tensor is not None:\n+        inputs = operation_utils.get_source_inputs(input_tensor)\n+    else:\n+        inputs = img_input\n+\n+    # Create model.\n+    model = Functional(inputs, x, name=\"vgg19\")\n+\n+    # Load weights.\n+    if weights == \"imagenet\":\n+        if include_top:\n+            weights_path = file_utils.get_file(\n+                \"vgg19_weights_tf_dim_ordering_tf_kernels.h5\",\n+                WEIGHTS_PATH,\n+                cache_subdir=\"models\",\n+                file_hash=\"cbe5617147190e668d6c5d5026f83318\",\n+            )\n+        else:\n+            weights_path = file_utils.get_file(\n+                \"vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n+                WEIGHTS_PATH_NO_TOP,\n+                cache_subdir=\"models\",\n+                file_hash=\"253f8cb515780f3b799900260a226db6\",\n+            )\n+        model.load_weights(weights_path)\n+    elif weights is not None:\n+        model.load_weights(weights)\n+\n+    return model\n+\n+\n+@keras_core_export(\"keras_core.applications.vgg19.preprocess_input\")\n+def preprocess_input(x, data_format=None):\n+    return imagenet_utils.preprocess_input(\n+        x, data_format=data_format, mode=\"caffe\"\n+    )\n+\n+\n+@keras_core_export(\"keras_core.applications.vgg19.decode_predictions\")\n+def decode_predictions(preds, top=5):\n+    return imagenet_utils.decode_predictions(preds, top=top)\n+\n+\n+preprocess_input.__doc__ = imagenet_utils.PREPROCESS_INPUT_DOC.format(\n+    mode=\"\",\n+    ret=imagenet_utils.PREPROCESS_INPUT_RET_DOC_CAFFE,\n+    error=imagenet_utils.PREPROCESS_INPUT_ERROR_DOC,\n+)\n+decode_predictions.__doc__ = imagenet_utils.decode_predictions.__doc__\n\n@@ -0,0 +1,354 @@\n+from tensorflow.io import gfile\n+\n+from keras_core import backend\n+from keras_core import layers\n+from keras_core.api_export import keras_core_export\n+from keras_core.applications import imagenet_utils\n+from keras_core.models import Functional\n+from keras_core.operations import operation_utils\n+from keras_core.utils import file_utils\n+\n+WEIGHTS_PATH = (\n+    \"https://storage.googleapis.com/tensorflow/keras-applications/\"\n+    \"xception/xception_weights_tf_dim_ordering_tf_kernels.h5\"\n+)\n+WEIGHTS_PATH_NO_TOP = (\n+    \"https://storage.googleapis.com/tensorflow/keras-applications/\"\n+    \"xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n+)\n+\n+\n+@keras_core_export(\n+    [\n+        \"keras_core.applications.xception.Xception\",\n+        \"keras_core.applications.Xception\",\n+    ]\n+)\n+def Xception(\n+    include_top=True,\n+    weights=\"imagenet\",\n+    input_tensor=None,\n+    input_shape=None,\n+    pooling=None,\n+    classes=1000,\n+    classifier_activation=\"softmax\",\n+):\n+    \"\"\"Instantiates the Xception architecture.\n+\n+    Reference:\n+    - [Xception: Deep Learning with Depthwise Separable Convolutions](\n+        https://arxiv.org/abs/1610.02357) (CVPR 2017)\n+\n+    For image classification use cases, see\n+    [this page for detailed examples](\n+      https://keras.io/api/applications/#usage-examples-for-image-classification-models).\n+\n+    For transfer learning use cases, make sure to read the\n+    [guide to transfer learning & fine-tuning](\n+      https://keras.io/guides/transfer_learning/).\n+\n+    The default input image size for this model is 299x299.\n+\n+    Note: each Keras Application expects a specific kind of input preprocessing.\n+    For Xception, call `tf.keras.applications.xception.preprocess_input` on your\n+    inputs before passing them to the model.\n+    `xception.preprocess_input` will scale input pixels between -1 and 1.\n+\n+    Args:\n+        include_top: whether to include the 3 fully-connected\n+            layers at the top of the network.\n+        weights: one of `None` (random initialization),\n+            `\"imagenet\"` (pre-training on ImageNet),\n+            or the path to the weights file to be loaded.\n+        input_tensor: optional Keras tensor\n+            (i.e. output of `layers.Input()`)\n+            to use as image input for the model.\n+        input_shape: optional shape tuple, only to be specified\n+            if `include_top` is `False` (otherwise the input shape\n+            has to be `(299, 299, 3)`.\n+            It should have exactly 3 inputs channels,\n+            and width and height should be no smaller than 71.\n+            E.g. `(150, 150, 3)` would be one valid value.\n+        pooling: Optional pooling mode for feature extraction\n+            when `include_top` is `False`.\n+            - `None` means that the output of the model will be\n+                the 4D tensor output of the\n+                last convolutional block.\n+            - `avg` means that global average pooling\n+                will be applied to the output of the\n+                last convolutional block, and thus\n+                the output of the model will be a 2D tensor.\n+            - `max` means that global max pooling will\n+                be applied.\n+        classes: optional number of classes to classify images\n+            into, only to be specified if `include_top` is `True`, and\n+            if no `weights` argument is specified.\n+        classifier_activation: A `str` or callable. The activation function to\n+            use on the \"top\" layer. Ignored unless `include_top=True`. Set\n+            `classifier_activation=None` to return the logits of the \"top\"\n+            layer.  When loading pretrained weights, `classifier_activation` can\n+            only be `None` or `\"softmax\"`.\n+\n+    Returns:\n+        A model instance.\n+    \"\"\"\n+    if not (weights in {\"imagenet\", None} or gfile.exists(weights)):\n+        raise ValueError(\n+            \"The `weights` argument should be either \"\n+            \"`None` (random initialization), `imagenet` \"\n+            \"(pre-training on ImageNet), \"\n+            \"or the path to the weights file to be loaded.\"\n+        )\n+\n+    if weights == \"imagenet\" and include_top and classes != 1000:\n+        raise ValueError(\n+            'If using `weights` as `\"imagenet\"` with `include_top`'\n+            \" as true, `classes` should be 1000\"\n+        )\n+\n+    # Determine proper input shape\n+    input_shape = imagenet_utils.obtain_input_shape(\n+        input_shape,\n+        default_size=299,\n+        min_size=71,\n+        data_format=backend.image_data_format(),\n+        require_flatten=include_top,\n+        weights=weights,\n+    )\n+\n+    if input_tensor is None:\n+        img_input = layers.Input(shape=input_shape)\n+    else:\n+        if not backend.is_keras_tensor(input_tensor):\n+            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n+        else:\n+            img_input = input_tensor\n+\n+    channel_axis = 1 if backend.image_data_format() == \"channels_first\" else -1\n+\n+    x = layers.Conv2D(\n+        32, (3, 3), strides=(2, 2), use_bias=False, name=\"block1_conv1\"\n+    )(img_input)\n+    x = layers.BatchNormalization(axis=channel_axis, name=\"block1_conv1_bn\")(x)\n+    x = layers.Activation(\"relu\", name=\"block1_conv1_act\")(x)\n+    x = layers.Conv2D(64, (3, 3), use_bias=False, name=\"block1_conv2\")(x)\n+    x = layers.BatchNormalization(axis=channel_axis, name=\"block1_conv2_bn\")(x)\n+    x = layers.Activation(\"relu\", name=\"block1_conv2_act\")(x)\n+\n+    residual = layers.Conv2D(\n+        128, (1, 1), strides=(2, 2), padding=\"same\", use_bias=False\n+    )(x)\n+    residual = layers.BatchNormalization(axis=channel_axis)(residual)\n+\n+    x = layers.SeparableConv2D(\n+        128, (3, 3), padding=\"same\", use_bias=False, name=\"block2_sepconv1\"\n+    )(x)\n+    x = layers.BatchNormalization(axis=channel_axis, name=\"block2_sepconv1_bn\")(\n+        x\n+    )\n+    x = layers.Activation(\"relu\", name=\"block2_sepconv2_act\")(x)\n+    x = layers.SeparableConv2D(\n+        128, (3, 3), padding=\"same\", use_bias=False, name=\"block2_sepconv2\"\n+    )(x)\n+    x = layers.BatchNormalization(axis=channel_axis, name=\"block2_sepconv2_bn\")(\n+        x\n+    )\n+\n+    x = layers.MaxPooling2D(\n+        (3, 3), strides=(2, 2), padding=\"same\", name=\"block2_pool\"\n+    )(x)\n+    x = layers.add([x, residual])\n+\n+    residual = layers.Conv2D(\n+        256, (1, 1), strides=(2, 2), padding=\"same\", use_bias=False\n+    )(x)\n+    residual = layers.BatchNormalization(axis=channel_axis)(residual)\n+\n+    x = layers.Activation(\"relu\", name=\"block3_sepconv1_act\")(x)\n+    x = layers.SeparableConv2D(\n+        256, (3, 3), padding=\"same\", use_bias=False, name=\"block3_sepconv1\"\n+    )(x)\n+    x = layers.BatchNormalization(axis=channel_axis, name=\"block3_sepconv1_bn\")(\n+        x\n+    )\n+    x = layers.Activation(\"relu\", name=\"block3_sepconv2_act\")(x)\n+    x = layers.SeparableConv2D(\n+        256, (3, 3), padding=\"same\", use_bias=False, name=\"block3_sepconv2\"\n+    )(x)\n+    x = layers.BatchNormalization(axis=channel_axis, name=\"block3_sepconv2_bn\")(\n+        x\n+    )\n+\n+    x = layers.MaxPooling2D(\n+        (3, 3), strides=(2, 2), padding=\"same\", name=\"block3_pool\"\n+    )(x)\n+    x = layers.add([x, residual])\n+\n+    residual = layers.Conv2D(\n+        728, (1, 1), strides=(2, 2), padding=\"same\", use_bias=False\n+    )(x)\n+    residual = layers.BatchNormalization(axis=channel_axis)(residual)\n+\n+    x = layers.Activation(\"relu\", name=\"block4_sepconv1_act\")(x)\n+    x = layers.SeparableConv2D(\n+        728, (3, 3), padding=\"same\", use_bias=False, name=\"block4_sepconv1\"\n+    )(x)\n+    x = layers.BatchNormalization(axis=channel_axis, name=\"block4_sepconv1_bn\")(\n+        x\n+    )\n+    x = layers.Activation(\"relu\", name=\"block4_sepconv2_act\")(x)\n+    x = layers.SeparableConv2D(\n+        728, (3, 3), padding=\"same\", use_bias=False, name=\"block4_sepconv2\"\n+    )(x)\n+    x = layers.BatchNormalization(axis=channel_axis, name=\"block4_sepconv2_bn\")(\n+        x\n+    )\n+\n+    x = layers.MaxPooling2D(\n+        (3, 3), strides=(2, 2), padding=\"same\", name=\"block4_pool\"\n+    )(x)\n+    x = layers.add([x, residual])\n+\n+    for i in range(8):\n+        residual = x\n+        prefix = \"block\" + str(i + 5)\n+\n+        x = layers.Activation(\"relu\", name=prefix + \"_sepconv1_act\")(x)\n+        x = layers.SeparableConv2D(\n+            728,\n+            (3, 3),\n+            padding=\"same\",\n+            use_bias=False,\n+            name=prefix + \"_sepconv1\",\n+        )(x)\n+        x = layers.BatchNormalization(\n+            axis=channel_axis, name=prefix + \"_sepconv1_bn\"\n+        )(x)\n+        x = layers.Activation(\"relu\", name=prefix + \"_sepconv2_act\")(x)\n+        x = layers.SeparableConv2D(\n+            728,\n+            (3, 3),\n+            padding=\"same\",\n+            use_bias=False,\n+            name=prefix + \"_sepconv2\",\n+        )(x)\n+        x = layers.BatchNormalization(\n+            axis=channel_axis, name=prefix + \"_sepconv2_bn\"\n+        )(x)\n+        x = layers.Activation(\"relu\", name=prefix + \"_sepconv3_act\")(x)\n+        x = layers.SeparableConv2D(\n+            728,\n+            (3, 3),\n+            padding=\"same\",\n+            use_bias=False,\n+            name=prefix + \"_sepconv3\",\n+        )(x)\n+        x = layers.BatchNormalization(\n+            axis=channel_axis, name=prefix + \"_sepconv3_bn\"\n+        )(x)\n+\n+        x = layers.add([x, residual])\n+\n+    residual = layers.Conv2D(\n+        1024, (1, 1), strides=(2, 2), padding=\"same\", use_bias=False\n+    )(x)\n+    residual = layers.BatchNormalization(axis=channel_axis)(residual)\n+\n+    x = layers.Activation(\"relu\", name=\"block13_sepconv1_act\")(x)\n+    x = layers.SeparableConv2D(\n+        728, (3, 3), padding=\"same\", use_bias=False, name=\"block13_sepconv1\"\n+    )(x)\n+    x = layers.BatchNormalization(\n+        axis=channel_axis, name=\"block13_sepconv1_bn\"\n+    )(x)\n+    x = layers.Activation(\"relu\", name=\"block13_sepconv2_act\")(x)\n+    x = layers.SeparableConv2D(\n+        1024, (3, 3), padding=\"same\", use_bias=False, name=\"block13_sepconv2\"\n+    )(x)\n+    x = layers.BatchNormalization(\n+        axis=channel_axis, name=\"block13_sepconv2_bn\"\n+    )(x)\n+\n+    x = layers.MaxPooling2D(\n+        (3, 3), strides=(2, 2), padding=\"same\", name=\"block13_pool\"\n+    )(x)\n+    x = layers.add([x, residual])\n+\n+    x = layers.SeparableConv2D(\n+        1536, (3, 3), padding=\"same\", use_bias=False, name=\"block14_sepconv1\"\n+    )(x)\n+    x = layers.BatchNormalization(\n+        axis=channel_axis, name=\"block14_sepconv1_bn\"\n+    )(x)\n+    x = layers.Activation(\"relu\", name=\"block14_sepconv1_act\")(x)\n+\n+    x = layers.SeparableConv2D(\n+        2048, (3, 3), padding=\"same\", use_bias=False, name=\"block14_sepconv2\"\n+    )(x)\n+    x = layers.BatchNormalization(\n+        axis=channel_axis, name=\"block14_sepconv2_bn\"\n+    )(x)\n+    x = layers.Activation(\"relu\", name=\"block14_sepconv2_act\")(x)\n+\n+    if include_top:\n+        x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(x)\n+        imagenet_utils.validate_activation(classifier_activation, weights)\n+        x = layers.Dense(\n+            classes, activation=classifier_activation, name=\"predictions\"\n+        )(x)\n+    else:\n+        if pooling == \"avg\":\n+            x = layers.GlobalAveragePooling2D()(x)\n+        elif pooling == \"max\":\n+            x = layers.GlobalMaxPooling2D()(x)\n+\n+    # Ensure that the model takes into account\n+    # any potential predecessors of `input_tensor`.\n+    if input_tensor is not None:\n+        inputs = operation_utils.get_source_inputs(input_tensor)\n+    else:\n+        inputs = img_input\n+    # Create model.\n+    model = Functional(inputs, x, name=\"xception\")\n+\n+    # Load weights.\n+    if weights == \"imagenet\":\n+        if include_top:\n+            weights_path = file_utils.get_file(\n+                \"xception_weights_tf_dim_ordering_tf_kernels.h5\",\n+                WEIGHTS_PATH,\n+                cache_subdir=\"models\",\n+                file_hash=\"0a58e3b7378bc2990ea3b43d5981f1f6\",\n+            )\n+        else:\n+            weights_path = file_utils.get_file(\n+                \"xception_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n+                WEIGHTS_PATH_NO_TOP,\n+                cache_subdir=\"models\",\n+                file_hash=\"b0042744bf5b25fce3cb969f33bebb97\",\n+            )\n+        model.load_weights(weights_path)\n+    elif weights is not None:\n+        model.load_weights(weights)\n+\n+    return model\n+\n+\n+@keras_core_export(\"keras_core.applications.xception.preprocess_input\")\n+def preprocess_input(x, data_format=None):\n+    return imagenet_utils.preprocess_input(\n+        x, data_format=data_format, mode=\"tf\"\n+    )\n+\n+\n+@keras_core_export(\"keras_core.applications.xception.decode_predictions\")\n+def decode_predictions(preds, top=5):\n+    return imagenet_utils.decode_predictions(preds, top=top)\n+\n+\n+preprocess_input.__doc__ = imagenet_utils.PREPROCESS_INPUT_DOC.format(\n+    mode=\"\",\n+    ret=imagenet_utils.PREPROCESS_INPUT_RET_DOC_TF,\n+    error=imagenet_utils.PREPROCESS_INPUT_ERROR_DOC,\n+)\n+decode_predictions.__doc__ = imagenet_utils.decode_predictions.__doc__\n\n@@ -118,6 +118,20 @@ class Functional(Function, Model):\n     def build(self, input_shape):\n         self.built = True\n \n+    @property\n+    def input_shape(self):\n+        input_shapes = nest.map_structure(lambda x: x.shape, self.inputs)\n+        if isinstance(input_shapes, list) and len(input_shapes) == 1:\n+            return input_shapes[0]\n+        return input_shapes\n+\n+    @property\n+    def output_shape(self):\n+        output_shapes = nest.map_structure(lambda x: x.shape, self.outputs)\n+        if isinstance(output_shapes, list) and len(output_shapes) == 1:\n+            return output_shapes[0]\n+        return output_shapes\n+\n     def _assert_input_compatibility(self, *args):\n         return super(Model, self)._assert_input_compatibility(*args)\n \n\n@@ -165,6 +165,22 @@ class Sequential(Model):\n             inputs = outputs\n         return outputs\n \n+    @property\n+    def input_shape(self):\n+        if self._functional:\n+            return self._functional.input_shape\n+        raise ValueError(\n+            f\"Sequential model '{self.name}' has no defined input shape yet.\"\n+        )\n+\n+    @property\n+    def output_shape(self):\n+        if self._functional:\n+            return self._functional.output_shape\n+        raise ValueError(\n+            f\"Sequential model '{self.name}' has no defined output shape yet.\"\n+        )\n+\n     def _is_layer_name_unique(self, layer):\n         for ref_layer in self._layers:\n             if layer.name == ref_layer.name and ref_layer is not layer:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
