{"custom_id": "keras#49855e75e0491e8b15fdd00fed500d83a18684eb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 22 | Files Changed: 2 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 194/137 | Churn Δ: 22 | Churn Cumulative: 3018 | Contributors (this commit): 13 | Commits (past 90d): 5 | Contributors (cumulative): 23 | DMM Complexity: 1.0\n\nDIFF:\n@@ -17,7 +17,6 @@\n import collections\n import contextlib\n import copy\n-import platform\n import random\n import threading\n \n@@ -708,13 +707,6 @@ def _astuple(attrs):\n \n def can_jit_compile(warn=False):\n     \"\"\"Returns True if TensorFlow XLA is available for the platform.\"\"\"\n-    if platform.system() == \"Darwin\" and \"arm\" in platform.processor().lower():\n-        if warn:\n-            logging.warning(\n-                \"XLA (`jit_compile`) is not yet supported on Apple M1/M2 ARM \"\n-                \"processors. Falling back to `jit_compile=False`.\"\n-            )\n-        return False\n     if pywrap_tfe.TF_ListPluggablePhysicalDevices():\n         if warn:\n             logging.warning(\n\n@@ -14,9 +14,6 @@\n # ==============================================================================\n \"\"\"Tests for Keras TF utils.\"\"\"\n \n-from unittest.mock import MagicMock\n-from unittest.mock import patch\n-\n import numpy as np\n import tensorflow.compat.v2 as tf\n from absl.testing import parameterized\n@@ -473,16 +470,5 @@ class TestSyncToNumpyOrPythonType(parameterized.TestCase):\n         self.assertEqual(tf_utils.sync_to_numpy_or_python_type(tensor), value)\n \n \n-class TestCanJitCompile(tf.test.TestCase):\n-    def test_darwin_arm_xla(self):\n-        with patch(\"platform.processor\", MagicMock(return_value=\"arm\")):\n-            with patch(\"platform.system\", MagicMock(return_value=\"Darwin\")):\n-                self.assertFalse(tf_utils.can_jit_compile())\n-\n-    def test_linux_xla(self):\n-        with patch(\"platform.system\", MagicMock(return_value=\"Linux\")):\n-            self.assertTrue(tf_utils.can_jit_compile())\n-\n-\n if __name__ == \"__main__\":\n     tf.test.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f022a2c566808687464a5d83685ca0b6c902d6f0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 40 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 9 | Methods Changed: 11 | Complexity Δ (Sum/Max): 6/4 | Churn Δ: 43 | Churn Cumulative: 1832 | Contributors (this commit): 7 | Commits (past 90d): 59 | Contributors (cumulative): 9 | DMM Complexity: 1.0\n\nDIFF:\n@@ -12,11 +12,20 @@ from keras_core.trainers.epoch_iterator import EpochIterator\n \n class JAXTrainer(base_trainer.Trainer):\n     def compute_loss_and_updates(\n-        self, trainable_variables, non_trainable_variables, x, y, sample_weight\n+        self,\n+        trainable_variables,\n+        non_trainable_variables,\n+        x,\n+        y,\n+        sample_weight,\n+        training=False,\n     ):\n         \"\"\"This method is stateless and is intended for use with jax.grad.\"\"\"\n+        kwargs = {}\n+        if self._call_has_training_arg():\n+            kwargs[\"training\"] = training\n         y_pred, non_trainable_variables = self.stateless_call(\n-            trainable_variables, non_trainable_variables, x\n+            trainable_variables, non_trainable_variables, x, **kwargs\n         )\n \n         loss = self.compute_loss(x, y, y_pred, sample_weight)\n@@ -136,6 +145,7 @@ class JAXTrainer(base_trainer.Trainer):\n                 x,\n                 y,\n                 sample_weight,\n+                training=True,\n             )\n \n             (\n@@ -367,6 +377,7 @@ class JAXTrainer(base_trainer.Trainer):\n                 x,\n                 y,\n                 sample_weight,\n+                training=False,\n             )\n \n             with backend.StatelessScope(\n@@ -488,8 +499,11 @@ class JAXTrainer(base_trainer.Trainer):\n             )\n \n         def _predict_step(trainable_variables, non_trainable_variables, data):\n+            kwargs = {}\n+            if self._call_has_training_arg():\n+                kwargs[\"training\"] = False\n             outputs, _ = self.stateless_call(\n-                trainable_variables, non_trainable_variables, data[0]\n+                trainable_variables, non_trainable_variables, data[0], **kwargs\n             )\n             return outputs\n \n\n@@ -51,6 +51,17 @@ class StructModel(layers.Layer, Trainer):\n         }\n \n \n+class TrainingTestingLayer(layers.Layer, Trainer):\n+    def __init__(self):\n+        layers.Layer.__init__(self)\n+        Trainer.__init__(self)\n+\n+    def call(self, x, training=False):\n+        if training:\n+            return x\n+        return x * 0\n+\n+\n class TestTrainer(testing.TestCase):\n     def test_metric_tracking(self):\n         class ModelWithMetric(layers.Dense, Trainer):\n@@ -252,3 +263,15 @@ class TestTrainer(testing.TestCase):\n             model_2.predict(x, batch_size=batch_size),\n         )\n         self.assertAllClose(model.evaluate(x, y), model_2.evaluate(x, y))\n+\n+    def test_training_arg(self):\n+        model = TrainingTestingLayer()\n+        model.compile(optimizer=\"rmsprop\", loss=\"mse\")\n+        x = np.ones((128, 1))\n+        y = np.zeros((128, 1))\n+        history = model.fit(x, y, batch_size=32)\n+        self.assertAllClose(history.history[\"loss\"], [1.0])\n+        val_loss = model.evaluate(x, y, batch_size=32)\n+        self.assertAllClose(val_loss, 0.0)\n+        preds = model.predict(x)\n+        self.assertAllClose(preds, np.zeros((128, 1)))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cb0bfcb4a1307b0ffb8d886790dba552a82b4fd1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 5 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 16 | Churn Cumulative: 92 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,8 +1,9 @@\n+from keras_core import backend\n from keras_core import operations as ops\n-from keras_core.backend import image_data_format\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n from keras_core.operations.operation_utils import compute_pooling_output_shape\n+from keras_core.utils import argument_validation\n \n \n class BasePooling(Layer):\n@@ -21,13 +22,16 @@ class BasePooling(Layer):\n     ):\n         super().__init__(name=name, **kwargs)\n \n-        self.pool_size = pool_size\n-        self.strides = pool_size if strides is None else strides\n+        self.pool_size = argument_validation.standardize_tuple(\n+            pool_size, pool_dimensions, \"pool_size\"\n+        )\n+        strides = pool_size if strides is None else strides\n+        self.strides = argument_validation.standardize_tuple(\n+            strides, pool_dimensions, \"strides\", allow_zero=True\n+        )\n         self.pool_mode = pool_mode\n         self.padding = padding\n-        self.data_format = (\n-            image_data_format() if data_format is None else data_format\n-        )\n+        self.data_format = backend.standardize_data_format(data_format)\n \n         self.input_spec = InputSpec(ndim=pool_dimensions + 2)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#219bbe18f61ac2b6f4b995ddf6983a5db1ef17ed", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 79 | Lines Deleted: 26 | Files Changed: 3 | Hunks: 12 | Methods Changed: 6 | Complexity Δ (Sum/Max): 11/10 | Churn Δ: 105 | Churn Cumulative: 10120 | Contributors (this commit): 9 | Commits (past 90d): 74 | Contributors (cumulative): 18 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1514,33 +1514,71 @@ def full_like(x, fill_value, dtype=None):\n \n class GetItem(Operation):\n     def call(self, x, key):\n-        if not isinstance(key, int):\n-            # TODO: support slicing.\n-            raise ValueError(\n-                \"Only scalar int keys are supported at this time. Cannot \"\n-                f\"process key {key}\"\n-            )\n         return x[key]\n \n     def compute_output_spec(self, x, key):\n-        if not isinstance(key, int):\n-            # TODO: support slicing.\n+        remaining_shape = list(x.shape)\n+        new_shape = []\n+        if isinstance(key, int):\n+            remaining_key = [key]\n+        elif isinstance(key, tuple):\n+            remaining_key = list(key)\n+        else:\n             raise ValueError(\n-                \"Only scalar int keys are supported at this time. Cannot \"\n-                f\"process key {key}\"\n+                f\"Unsupported key type for array slice. Recieved: `{key}`\"\n             )\n-        if len(x.shape) == 0:\n+        num_ellipses = remaining_key.count(Ellipsis)\n+        if num_ellipses > 1:\n             raise ValueError(\n-                f\"Too many indices for array: array is scalar \"\n-                f\"but index {key} was requested. A scalar array \"\n-                \"cannot be indexed.\"\n+                f\"Slice should only have one ellipsis. Recieved: `{key}`\"\n             )\n-        if x.shape[0] is not None and key >= x.shape[0]:\n+        elif num_ellipses == 0:\n+            # Add an implicit final ellipsis.\n+            remaining_key.append(Ellipsis)\n+        # Consume slice key element by element.\n+        while True:\n+            if not remaining_key:\n+                break\n+            subkey = remaining_key.pop(0)\n+            # Check for `newaxis` and `Ellipsis`.\n+            if subkey == Ellipsis:\n+                # Keep as many slices remain in our key, omitting `newaxis`.\n+                needed = len(remaining_key) - remaining_key.count(np.newaxis)\n+                consumed = len(remaining_shape) - needed\n+                new_shape += remaining_shape[:consumed]\n+                remaining_shape = remaining_shape[consumed:]\n+                continue\n+            # All frameworks follow numpy for newaxis. `np.newaxis == None`.\n+            if subkey == np.newaxis:\n+                new_shape.append(1)\n+                continue\n+            # At this point, we need to consume a new axis from the shape.\n+            if not remaining_shape:\n                 raise ValueError(\n-                f\"Array has shape {x.shape} \"\n-                f\"but out-of-bound index {key} was requested.\"\n+                    f\"Array has shape {x.shape} but slice \"\n+                    f\"has to many indices. Recieved: `{key}`\"\n                 )\n-        return KerasTensor(x.shape[1:], dtype=x.dtype)\n+            length = remaining_shape.pop(0)\n+            if isinstance(subkey, int):\n+                if length is not None:\n+                    index = subkey if subkey >= 0 else subkey + length\n+                    if index < 0 or index >= length:\n+                        raise ValueError(\n+                            f\"Array has shape {x.shape} but out-of-bounds \"\n+                            f\"index {key} was requested.\"\n+                        )\n+            elif isinstance(subkey, slice):\n+                if length is not None:\n+                    # python3 friendly way to compute a slice length.\n+                    new_length = len(range(*subkey.indices(length)))\n+                    new_shape.append(new_length)\n+                else:\n+                    new_shape.append(length)\n+            else:\n+                raise ValueError(\n+                    f\"Unsupported key type for array slice. Recieved: `{key}`\"\n+                )\n+        return KerasTensor(tuple(new_shape), dtype=x.dtype)\n \n \n @keras_core_export(\n@@ -1549,12 +1587,6 @@ class GetItem(Operation):\n def get_item(x, key):\n     if any_symbolic_tensors((x,)):\n         return GetItem().symbolic_call(x, key)\n-    if not isinstance(key, int):\n-        # TODO: support slicing.\n-        raise ValueError(\n-            \"Only scalar int keys are supported at this time. Cannot \"\n-            f\"process key {key}\"\n-        )\n     return x[key]\n \n \n\n@@ -882,8 +882,26 @@ class NumpyOneInputOpsDynamicShapeTest(testing.TestCase):\n         self.assertEqual(knp.floor(x).shape, (None, 3))\n \n     def test_get_item(self):\n-        x = KerasTensor([None, None])\n-        self.assertEqual(knp.get_item(x, 5).shape, (None,))\n+        x = KerasTensor([None, 5, 16])\n+        # Simple slice.\n+        sliced = knp.get_item(x, 5)\n+        self.assertEqual(sliced.shape, (5, 16))\n+        # Ellipsis slice.\n+        sliced = knp.get_item(x, np.s_[..., -1])\n+        self.assertEqual(sliced.shape, (None, 5))\n+        # `newaxis` slice.\n+        sliced = knp.get_item(x, np.s_[:, np.newaxis, ...])\n+        self.assertEqual(sliced.shape, (None, 1, 5, 16))\n+        # Strided slice.\n+        sliced = knp.get_item(x, np.s_[:5, 3:, 3:12:2])\n+        self.assertEqual(sliced.shape, (None, 2, 5))\n+        # Error states.\n+        with self.assertRaises(ValueError):\n+            sliced = knp.get_item(x, np.s_[:, 17, :])\n+        with self.assertRaises(ValueError):\n+            sliced = knp.get_item(x, np.s_[..., 5, ...])\n+        with self.assertRaises(ValueError):\n+            sliced = knp.get_item(x, np.s_[:, :, :, :])\n \n     def test_hstack(self):\n         x = KerasTensor([None, 3])\n\n@@ -1,3 +1,5 @@\n+import typing\n+\n from tensorflow import nest\n \n from keras_core.backend import KerasTensor\n@@ -41,6 +43,7 @@ class SymbolicArguments:\n             return (tensor_dict[self._single_positional_tensor],), {}\n \n         def switch_fn(x):\n+            if isinstance(x, typing.Hashable):\n                 val = tensor_dict.get(x, None)\n                 if val is not None:\n                     return val\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#75aa8fff5e2fab1ce37bead74dc694f5f622a554", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 89 | Lines Deleted: 32 | Files Changed: 4 | Hunks: 17 | Methods Changed: 7 | Complexity Δ (Sum/Max): 10/10 | Churn Δ: 121 | Churn Cumulative: 10454 | Contributors (this commit): 9 | Commits (past 90d): 84 | Contributors (cumulative): 21 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1,8 +1,9 @@\n+from keras_core import backend\n from keras_core import operations as ops\n-from keras_core.backend import image_data_format\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n from keras_core.operations.operation_utils import compute_pooling_output_shape\n+from keras_core.utils import argument_validation\n \n \n class BasePooling(Layer):\n@@ -21,13 +22,16 @@ class BasePooling(Layer):\n     ):\n         super().__init__(name=name, **kwargs)\n \n-        self.pool_size = pool_size\n-        self.strides = pool_size if strides is None else strides\n+        self.pool_size = argument_validation.standardize_tuple(\n+            pool_size, pool_dimensions, \"pool_size\"\n+        )\n+        strides = pool_size if strides is None else strides\n+        self.strides = argument_validation.standardize_tuple(\n+            strides, pool_dimensions, \"strides\", allow_zero=True\n+        )\n         self.pool_mode = pool_mode\n         self.padding = padding\n-        self.data_format = (\n-            image_data_format() if data_format is None else data_format\n-        )\n+        self.data_format = backend.standardize_data_format(data_format)\n \n         self.input_spec = InputSpec(ndim=pool_dimensions + 2)\n \n\n@@ -1514,33 +1514,71 @@ def full_like(x, fill_value, dtype=None):\n \n class GetItem(Operation):\n     def call(self, x, key):\n-        if not isinstance(key, int):\n-            # TODO: support slicing.\n-            raise ValueError(\n-                \"Only scalar int keys are supported at this time. Cannot \"\n-                f\"process key {key}\"\n-            )\n         return x[key]\n \n     def compute_output_spec(self, x, key):\n-        if not isinstance(key, int):\n-            # TODO: support slicing.\n+        remaining_shape = list(x.shape)\n+        new_shape = []\n+        if isinstance(key, int):\n+            remaining_key = [key]\n+        elif isinstance(key, tuple):\n+            remaining_key = list(key)\n+        else:\n             raise ValueError(\n-                \"Only scalar int keys are supported at this time. Cannot \"\n-                f\"process key {key}\"\n+                f\"Unsupported key type for array slice. Recieved: `{key}`\"\n             )\n-        if len(x.shape) == 0:\n+        num_ellipses = remaining_key.count(Ellipsis)\n+        if num_ellipses > 1:\n             raise ValueError(\n-                f\"Too many indices for array: array is scalar \"\n-                f\"but index {key} was requested. A scalar array \"\n-                \"cannot be indexed.\"\n+                f\"Slice should only have one ellipsis. Recieved: `{key}`\"\n             )\n-        if x.shape[0] is not None and key >= x.shape[0]:\n+        elif num_ellipses == 0:\n+            # Add an implicit final ellipsis.\n+            remaining_key.append(Ellipsis)\n+        # Consume slice key element by element.\n+        while True:\n+            if not remaining_key:\n+                break\n+            subkey = remaining_key.pop(0)\n+            # Check for `newaxis` and `Ellipsis`.\n+            if subkey == Ellipsis:\n+                # Keep as many slices remain in our key, omitting `newaxis`.\n+                needed = len(remaining_key) - remaining_key.count(np.newaxis)\n+                consumed = len(remaining_shape) - needed\n+                new_shape += remaining_shape[:consumed]\n+                remaining_shape = remaining_shape[consumed:]\n+                continue\n+            # All frameworks follow numpy for newaxis. `np.newaxis == None`.\n+            if subkey == np.newaxis:\n+                new_shape.append(1)\n+                continue\n+            # At this point, we need to consume a new axis from the shape.\n+            if not remaining_shape:\n                 raise ValueError(\n-                f\"Array has shape {x.shape} \"\n-                f\"but out-of-bound index {key} was requested.\"\n+                    f\"Array has shape {x.shape} but slice \"\n+                    f\"has to many indices. Recieved: `{key}`\"\n                 )\n-        return KerasTensor(x.shape[1:], dtype=x.dtype)\n+            length = remaining_shape.pop(0)\n+            if isinstance(subkey, int):\n+                if length is not None:\n+                    index = subkey if subkey >= 0 else subkey + length\n+                    if index < 0 or index >= length:\n+                        raise ValueError(\n+                            f\"Array has shape {x.shape} but out-of-bounds \"\n+                            f\"index {key} was requested.\"\n+                        )\n+            elif isinstance(subkey, slice):\n+                if length is not None:\n+                    # python3 friendly way to compute a slice length.\n+                    new_length = len(range(*subkey.indices(length)))\n+                    new_shape.append(new_length)\n+                else:\n+                    new_shape.append(length)\n+            else:\n+                raise ValueError(\n+                    f\"Unsupported key type for array slice. Recieved: `{key}`\"\n+                )\n+        return KerasTensor(tuple(new_shape), dtype=x.dtype)\n \n \n @keras_core_export(\n@@ -1549,12 +1587,6 @@ class GetItem(Operation):\n def get_item(x, key):\n     if any_symbolic_tensors((x,)):\n         return GetItem().symbolic_call(x, key)\n-    if not isinstance(key, int):\n-        # TODO: support slicing.\n-        raise ValueError(\n-            \"Only scalar int keys are supported at this time. Cannot \"\n-            f\"process key {key}\"\n-        )\n     return x[key]\n \n \n\n@@ -882,8 +882,26 @@ class NumpyOneInputOpsDynamicShapeTest(testing.TestCase):\n         self.assertEqual(knp.floor(x).shape, (None, 3))\n \n     def test_get_item(self):\n-        x = KerasTensor([None, None])\n-        self.assertEqual(knp.get_item(x, 5).shape, (None,))\n+        x = KerasTensor([None, 5, 16])\n+        # Simple slice.\n+        sliced = knp.get_item(x, 5)\n+        self.assertEqual(sliced.shape, (5, 16))\n+        # Ellipsis slice.\n+        sliced = knp.get_item(x, np.s_[..., -1])\n+        self.assertEqual(sliced.shape, (None, 5))\n+        # `newaxis` slice.\n+        sliced = knp.get_item(x, np.s_[:, np.newaxis, ...])\n+        self.assertEqual(sliced.shape, (None, 1, 5, 16))\n+        # Strided slice.\n+        sliced = knp.get_item(x, np.s_[:5, 3:, 3:12:2])\n+        self.assertEqual(sliced.shape, (None, 2, 5))\n+        # Error states.\n+        with self.assertRaises(ValueError):\n+            sliced = knp.get_item(x, np.s_[:, 17, :])\n+        with self.assertRaises(ValueError):\n+            sliced = knp.get_item(x, np.s_[..., 5, ...])\n+        with self.assertRaises(ValueError):\n+            sliced = knp.get_item(x, np.s_[:, :, :, :])\n \n     def test_hstack(self):\n         x = KerasTensor([None, 3])\n\n@@ -1,3 +1,5 @@\n+import typing\n+\n from tensorflow import nest\n \n from keras_core.backend import KerasTensor\n@@ -41,6 +43,7 @@ class SymbolicArguments:\n             return (tensor_dict[self._single_positional_tensor],), {}\n \n         def switch_fn(x):\n+            if isinstance(x, typing.Hashable):\n                 val = tensor_dict.get(x, None)\n                 if val is not None:\n                     return val\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#df7ce56cf164f850e9684e2c29d8463f18273b10", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 5 | Methods Changed: 3 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 16 | Churn Cumulative: 2047 | Contributors (this commit): 7 | Commits (past 90d): 46 | Contributors (cumulative): 10 | DMM Complexity: 0.0\n\nDIFF:\n@@ -143,7 +143,13 @@ class Functional(Function, Model):\n                 f\"(of type {type(outputs)})\"\n             )\n \n+        trainable = kwargs.pop(\"trainable\", None)\n+\n         Function.__init__(self, inputs, outputs, name=name, **kwargs)\n+\n+        if trainable is not None:\n+            self.trainable = trainable\n+\n         self._layers = self.layers\n         self.built = True\n \n@@ -499,6 +505,7 @@ class Functional(Function, Model):\n \n         # Create lits of input and output tensors and return new class\n         name = config.get(\"name\")\n+        trainable = config.get(\"trainable\")\n         input_tensors = []\n         output_tensors = []\n         for layer_data in config[\"input_layers\"]:\n@@ -517,7 +524,12 @@ class Functional(Function, Model):\n                 node_index\n             ].output_tensors\n             output_tensors.append(layer_output_tensors[tensor_index])\n-        return cls(inputs=input_tensors, outputs=output_tensors, name=name)\n+        return cls(\n+            inputs=input_tensors,\n+            outputs=output_tensors,\n+            name=name,\n+            trainable=trainable,\n+        )\n \n \n def operation_fn(operation, training):\n\n@@ -164,7 +164,7 @@ class FunctionalTest(testing.TestCase):\n         # Test basic model\n         inputs = Input(shape=(3,), batch_size=2)\n         outputs = layers.Dense(3)(inputs)\n-        model = Functional(inputs, outputs)\n+        model = Functional(inputs, outputs, trainable=False)\n         self.run_class_serialization_test(model)\n \n         # Test multi-io model\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#02dcb428f26209086804b0ff83faaa5fd294701f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 497 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 13 | Complexity Δ (Sum/Max): 33/33 | Churn Δ: 497 | Churn Cumulative: 497 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 0.7857142857142857\n\nDIFF:\n@@ -0,0 +1,497 @@\n+\"\"\"\n+Title: Model interpretability with Integrated Gradients\n+Author: [A_K_Nain](https://twitter.com/A_K_Nain)\n+Date created: 2020/06/02\n+Last modified: 2020/06/02\n+Description: How to obtain integrated gradients for a classification model.\n+Accelerator: NONE\n+\"\"\"\n+\n+\"\"\"\n+## Integrated Gradients\n+\n+[Integrated Gradients](https://arxiv.org/abs/1703.01365) is a technique for\n+attributing a classification model's prediction to its input features. It is\n+a model interpretability technique: you can use it to visualize the relationship\n+between input features and model predictions.\n+\n+Integrated Gradients is a variation on computing\n+the gradient of the prediction output with regard to features of the input.\n+To compute integrated gradients, we need to perform the following steps:\n+\n+1. Identify the input and the output. In our case, the input is an image and the\n+output is the last layer of our model (dense layer with softmax activation).\n+\n+2. Compute which features are important to a neural network\n+when making a prediction on a particular data point. To identify these features, we\n+need to choose a baseline input. A baseline input can be a black image (all pixel\n+values set to zero) or random noise. The shape of the baseline input needs to be\n+the same as our input image, e.g. (299, 299, 3).\n+\n+3. Interpolate the baseline for a given number of steps. The number of steps represents\n+the steps we need in the gradient approximation for a given input image. The number of\n+steps is a hyperparameter. The authors recommend using anywhere between\n+20 and 1000 steps.\n+\n+4. Preprocess these interpolated images and do a forward pass.\n+5. Get the gradients for these interpolated images.\n+6. Approximate the gradients integral using the trapezoidal rule.\n+\n+To read in-depth about integrated gradients and why this method works,\n+consider reading this excellent\n+[article](https://distill.pub/2020/attribution-baselines/).\n+\n+**References:**\n+\n+- Integrated Gradients original [paper](https://arxiv.org/abs/1703.01365)\n+- [Original implementation](https://github.com/ankurtaly/Integrated-Gradients)\n+\"\"\"\n+\n+\"\"\"\n+## Setup\n+\"\"\"\n+\n+\n+import numpy as np\n+import matplotlib.pyplot as plt\n+from scipy import ndimage\n+from IPython.display import Image, display\n+\n+import tensorflow as tf\n+import keras_core as keras\n+from keras_core import layers\n+from keras_core.applications import xception\n+\n+keras.config.disable_traceback_filtering()\n+\n+\n+# Size of the input image\n+img_size = (299, 299, 3)\n+\n+# Load Xception model with imagenet weights\n+model = xception.Xception(weights=\"imagenet\")\n+\n+# The local path to our target image\n+img_path = keras.utils.get_file(\"elephant.jpg\", \"https://i.imgur.com/Bvro0YD.png\")\n+display(Image(img_path))\n+\n+\"\"\"\n+## Integrated Gradients algorithm\n+\"\"\"\n+\n+\n+def get_img_array(img_path, size=(299, 299)):\n+    # `img` is a PIL image of size 299x299\n+    img = keras.utils.load_img(img_path, target_size=size)\n+    # `array` is a float32 Numpy array of shape (299, 299, 3)\n+    array = keras.utils.img_to_array(img)\n+    # We add a dimension to transform our array into a \"batch\"\n+    # of size (1, 299, 299, 3)\n+    array = np.expand_dims(array, axis=0)\n+    return array\n+\n+\n+def get_gradients(img_input, top_pred_idx):\n+    \"\"\"Computes the gradients of outputs w.r.t input image.\n+\n+    Args:\n+        img_input: 4D image tensor\n+        top_pred_idx: Predicted label for the input image\n+\n+    Returns:\n+        Gradients of the predictions w.r.t img_input\n+    \"\"\"\n+    images = tf.cast(img_input, tf.float32)\n+\n+    with tf.GradientTape() as tape:\n+        tape.watch(images)\n+        preds = model(images)\n+        top_class = preds[:, top_pred_idx]\n+\n+    grads = tape.gradient(top_class, images)\n+    return grads\n+\n+\n+def get_integrated_gradients(img_input, top_pred_idx, baseline=None, num_steps=50):\n+    \"\"\"Computes Integrated Gradients for a predicted label.\n+\n+    Args:\n+        img_input (ndarray): Original image\n+        top_pred_idx: Predicted label for the input image\n+        baseline (ndarray): The baseline image to start with for interpolation\n+        num_steps: Number of interpolation steps between the baseline\n+            and the input used in the computation of integrated gradients. These\n+            steps along determine the integral approximation error. By default,\n+            num_steps is set to 50.\n+\n+    Returns:\n+        Integrated gradients w.r.t input image\n+    \"\"\"\n+    # If baseline is not provided, start with a black image\n+    # having same size as the input image.\n+    if baseline is None:\n+        baseline = np.zeros(img_size).astype(np.float32)\n+    else:\n+        baseline = baseline.astype(np.float32)\n+\n+    # 1. Do interpolation.\n+    img_input = img_input.astype(np.float32)\n+    interpolated_image = [\n+        baseline + (step / num_steps) * (img_input - baseline)\n+        for step in range(num_steps + 1)\n+    ]\n+    interpolated_image = np.array(interpolated_image).astype(np.float32)\n+\n+    # 2. Preprocess the interpolated images\n+    interpolated_image = xception.preprocess_input(interpolated_image)\n+\n+    # 3. Get the gradients\n+    grads = []\n+    for i, img in enumerate(interpolated_image):\n+        img = tf.expand_dims(img, axis=0)\n+        grad = get_gradients(img, top_pred_idx=top_pred_idx)\n+        grads.append(grad[0])\n+    grads = tf.convert_to_tensor(grads, dtype=tf.float32)\n+\n+    # 4. Approximate the integral using the trapezoidal rule\n+    grads = (grads[:-1] + grads[1:]) / 2.0\n+    avg_grads = tf.reduce_mean(grads, axis=0)\n+\n+    # 5. Calculate integrated gradients and return\n+    integrated_grads = (img_input - baseline) * avg_grads\n+    return integrated_grads\n+\n+\n+def random_baseline_integrated_gradients(\n+    img_input, top_pred_idx, num_steps=50, num_runs=2\n+):\n+    \"\"\"Generates a number of random baseline images.\n+\n+    Args:\n+        img_input (ndarray): 3D image\n+        top_pred_idx: Predicted label for the input image\n+        num_steps: Number of interpolation steps between the baseline\n+            and the input used in the computation of integrated gradients. These\n+            steps along determine the integral approximation error. By default,\n+            num_steps is set to 50.\n+        num_runs: number of baseline images to generate\n+\n+    Returns:\n+        Averaged integrated gradients for `num_runs` baseline images\n+    \"\"\"\n+    # 1. List to keep track of Integrated Gradients (IG) for all the images\n+    integrated_grads = []\n+\n+    # 2. Get the integrated gradients for all the baselines\n+    for run in range(num_runs):\n+        baseline = np.random.random(img_size) * 255\n+        igrads = get_integrated_gradients(\n+            img_input=img_input,\n+            top_pred_idx=top_pred_idx,\n+            baseline=baseline,\n+            num_steps=num_steps,\n+        )\n+        integrated_grads.append(igrads)\n+\n+    # 3. Return the average integrated gradients for the image\n+    integrated_grads = tf.convert_to_tensor(integrated_grads)\n+    return tf.reduce_mean(integrated_grads, axis=0)\n+\n+\n+\"\"\"\n+## Helper class for visualizing gradients and integrated gradients\n+\"\"\"\n+\n+\n+class GradVisualizer:\n+    \"\"\"Plot gradients of the outputs w.r.t an input image.\"\"\"\n+\n+    def __init__(self, positive_channel=None, negative_channel=None):\n+        if positive_channel is None:\n+            self.positive_channel = [0, 255, 0]\n+        else:\n+            self.positive_channel = positive_channel\n+\n+        if negative_channel is None:\n+            self.negative_channel = [255, 0, 0]\n+        else:\n+            self.negative_channel = negative_channel\n+\n+    def apply_polarity(self, attributions, polarity):\n+        if polarity == \"positive\":\n+            return np.clip(attributions, 0, 1)\n+        else:\n+            return np.clip(attributions, -1, 0)\n+\n+    def apply_linear_transformation(\n+        self,\n+        attributions,\n+        clip_above_percentile=99.9,\n+        clip_below_percentile=70.0,\n+        lower_end=0.2,\n+    ):\n+        # 1. Get the thresholds\n+        m = self.get_thresholded_attributions(\n+            attributions, percentage=100 - clip_above_percentile\n+        )\n+        e = self.get_thresholded_attributions(\n+            attributions, percentage=100 - clip_below_percentile\n+        )\n+\n+        # 2. Transform the attributions by a linear function f(x) = a*x + b such that\n+        # f(m) = 1.0 and f(e) = lower_end\n+        transformed_attributions = (1 - lower_end) * (np.abs(attributions) - e) / (\n+            m - e\n+        ) + lower_end\n+\n+        # 3. Make sure that the sign of transformed attributions is the same as original attributions\n+        transformed_attributions *= np.sign(attributions)\n+\n+        # 4. Only keep values that are bigger than the lower_end\n+        transformed_attributions *= transformed_attributions >= lower_end\n+\n+        # 5. Clip values and return\n+        transformed_attributions = np.clip(transformed_attributions, 0.0, 1.0)\n+        return transformed_attributions\n+\n+    def get_thresholded_attributions(self, attributions, percentage):\n+        if percentage == 100.0:\n+            return np.min(attributions)\n+\n+        # 1. Flatten the attributions\n+        flatten_attr = attributions.flatten()\n+\n+        # 2. Get the sum of the attributions\n+        total = np.sum(flatten_attr)\n+\n+        # 3. Sort the attributions from largest to smallest.\n+        sorted_attributions = np.sort(np.abs(flatten_attr))[::-1]\n+\n+        # 4. Calculate the percentage of the total sum that each attribution\n+        # and the values about it contribute.\n+        cum_sum = 100.0 * np.cumsum(sorted_attributions) / total\n+\n+        # 5. Threshold the attributions by the percentage\n+        indices_to_consider = np.where(cum_sum >= percentage)[0][0]\n+\n+        # 6. Select the desired attributions and return\n+        attributions = sorted_attributions[indices_to_consider]\n+        return attributions\n+\n+    def binarize(self, attributions, threshold=0.001):\n+        return attributions > threshold\n+\n+    def morphological_cleanup_fn(self, attributions, structure=np.ones((4, 4))):\n+        closed = ndimage.grey_closing(attributions, structure=structure)\n+        opened = ndimage.grey_opening(closed, structure=structure)\n+        return opened\n+\n+    def draw_outlines(\n+        self, attributions, percentage=90, connected_component_structure=np.ones((3, 3))\n+    ):\n+        # 1. Binarize the attributions.\n+        attributions = self.binarize(attributions)\n+\n+        # 2. Fill the gaps\n+        attributions = ndimage.binary_fill_holes(attributions)\n+\n+        # 3. Compute connected components\n+        connected_components, num_comp = ndimage.label(\n+            attributions, structure=connected_component_structure\n+        )\n+\n+        # 4. Sum up the attributions for each component\n+        total = np.sum(attributions[connected_components > 0])\n+        component_sums = []\n+        for comp in range(1, num_comp + 1):\n+            mask = connected_components == comp\n+            component_sum = np.sum(attributions[mask])\n+            component_sums.append((component_sum, mask))\n+\n+        # 5. Compute the percentage of top components to keep\n+        sorted_sums_and_masks = sorted(component_sums, key=lambda x: x[0], reverse=True)\n+        sorted_sums = list(zip(*sorted_sums_and_masks))[0]\n+        cumulative_sorted_sums = np.cumsum(sorted_sums)\n+        cutoff_threshold = percentage * total / 100\n+        cutoff_idx = np.where(cumulative_sorted_sums >= cutoff_threshold)[0][0]\n+        if cutoff_idx > 2:\n+            cutoff_idx = 2\n+\n+        # 6. Set the values for the kept components\n+        border_mask = np.zeros_like(attributions)\n+        for i in range(cutoff_idx + 1):\n+            border_mask[sorted_sums_and_masks[i][1]] = 1\n+\n+        # 7. Make the mask hollow and show only the border\n+        eroded_mask = ndimage.binary_erosion(border_mask, iterations=1)\n+        border_mask[eroded_mask] = 0\n+\n+        # 8. Return the outlined mask\n+        return border_mask\n+\n+    def process_grads(\n+        self,\n+        image,\n+        attributions,\n+        polarity=\"positive\",\n+        clip_above_percentile=99.9,\n+        clip_below_percentile=0,\n+        morphological_cleanup=False,\n+        structure=np.ones((3, 3)),\n+        outlines=False,\n+        outlines_component_percentage=90,\n+        overlay=True,\n+    ):\n+        if polarity not in [\"positive\", \"negative\"]:\n+            raise ValueError(\n+                f\"\"\" Allowed polarity values: 'positive' or 'negative'\n+                                    but provided {polarity}\"\"\"\n+            )\n+        if clip_above_percentile < 0 or clip_above_percentile > 100:\n+            raise ValueError(\"clip_above_percentile must be in [0, 100]\")\n+\n+        if clip_below_percentile < 0 or clip_below_percentile > 100:\n+            raise ValueError(\"clip_below_percentile must be in [0, 100]\")\n+\n+        # 1. Apply polarity\n+        if polarity == \"positive\":\n+            attributions = self.apply_polarity(attributions, polarity=polarity)\n+            channel = self.positive_channel\n+        else:\n+            attributions = self.apply_polarity(attributions, polarity=polarity)\n+            attributions = np.abs(attributions)\n+            channel = self.negative_channel\n+\n+        # 2. Take average over the channels\n+        attributions = np.average(attributions, axis=2)\n+\n+        # 3. Apply linear transformation to the attributions\n+        attributions = self.apply_linear_transformation(\n+            attributions,\n+            clip_above_percentile=clip_above_percentile,\n+            clip_below_percentile=clip_below_percentile,\n+            lower_end=0.0,\n+        )\n+\n+        # 4. Cleanup\n+        if morphological_cleanup:\n+            attributions = self.morphological_cleanup_fn(\n+                attributions, structure=structure\n+            )\n+        # 5. Draw the outlines\n+        if outlines:\n+            attributions = self.draw_outlines(\n+                attributions, percentage=outlines_component_percentage\n+            )\n+\n+        # 6. Expand the channel axis and convert to RGB\n+        attributions = np.expand_dims(attributions, 2) * channel\n+\n+        # 7.Superimpose on the original image\n+        if overlay:\n+            attributions = np.clip((attributions * 0.8 + image), 0, 255)\n+        return attributions\n+\n+    def visualize(\n+        self,\n+        image,\n+        gradients,\n+        integrated_gradients,\n+        polarity=\"positive\",\n+        clip_above_percentile=99.9,\n+        clip_below_percentile=0,\n+        morphological_cleanup=False,\n+        structure=np.ones((3, 3)),\n+        outlines=False,\n+        outlines_component_percentage=90,\n+        overlay=True,\n+        figsize=(15, 8),\n+    ):\n+        # 1. Make two copies of the original image\n+        img1 = np.copy(image)\n+        img2 = np.copy(image)\n+\n+        # 2. Process the normal gradients\n+        grads_attr = self.process_grads(\n+            image=img1,\n+            attributions=gradients,\n+            polarity=polarity,\n+            clip_above_percentile=clip_above_percentile,\n+            clip_below_percentile=clip_below_percentile,\n+            morphological_cleanup=morphological_cleanup,\n+            structure=structure,\n+            outlines=outlines,\n+            outlines_component_percentage=outlines_component_percentage,\n+            overlay=overlay,\n+        )\n+\n+        # 3. Process the integrated gradients\n+        igrads_attr = self.process_grads(\n+            image=img2,\n+            attributions=integrated_gradients,\n+            polarity=polarity,\n+            clip_above_percentile=clip_above_percentile,\n+            clip_below_percentile=clip_below_percentile,\n+            morphological_cleanup=morphological_cleanup,\n+            structure=structure,\n+            outlines=outlines,\n+            outlines_component_percentage=outlines_component_percentage,\n+            overlay=overlay,\n+        )\n+\n+        _, ax = plt.subplots(1, 3, figsize=figsize)\n+        ax[0].imshow(image)\n+        ax[1].imshow(grads_attr.astype(np.uint8))\n+        ax[2].imshow(igrads_attr.astype(np.uint8))\n+\n+        ax[0].set_title(\"Input\")\n+        ax[1].set_title(\"Normal gradients\")\n+        ax[2].set_title(\"Integrated gradients\")\n+        plt.show()\n+\n+\n+\"\"\"\n+## Let's test-drive it\n+\"\"\"\n+\n+# 1. Convert the image to numpy array\n+img = get_img_array(img_path)\n+\n+# 2. Keep a copy of the original image\n+orig_img = np.copy(img[0]).astype(np.uint8)\n+\n+# 3. Preprocess the image\n+img_processed = tf.cast(xception.preprocess_input(img), dtype=tf.float32)\n+\n+# 4. Get model predictions\n+preds = model.predict(img_processed)\n+top_pred_idx = tf.argmax(preds[0])\n+print(\"Predicted:\", top_pred_idx, xception.decode_predictions(preds, top=1)[0])\n+\n+# 5. Get the gradients of the last layer for the predicted label\n+grads = get_gradients(img_processed, top_pred_idx=top_pred_idx)\n+\n+# 6. Get the integrated gradients\n+igrads = random_baseline_integrated_gradients(\n+    np.copy(orig_img), top_pred_idx=top_pred_idx, num_steps=50, num_runs=2\n+)\n+\n+# 7. Process the gradients and plot\n+vis = GradVisualizer()\n+vis.visualize(\n+    image=orig_img,\n+    gradients=grads[0].numpy(),\n+    integrated_gradients=igrads.numpy(),\n+    clip_above_percentile=99,\n+    clip_below_percentile=0,\n+)\n+\n+vis.visualize(\n+    image=orig_img,\n+    gradients=grads[0].numpy(),\n+    integrated_gradients=igrads.numpy(),\n+    clip_above_percentile=95,\n+    clip_below_percentile=28,\n+    morphological_cleanup=True,\n+    outlines=True,\n+)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9e58d0d0fb0017f25597423eac44ffaa46948609", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 26 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 4 | Methods Changed: 4 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 27 | Churn Cumulative: 111 | Contributors (this commit): 4 | Commits (past 90d): 7 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,6 +1,8 @@\n import numpy as np\n+import pytest\n from absl.testing import parameterized\n \n+import keras_core\n from keras_core import testing\n from keras_core.operations import numpy as knp\n from keras_core.random import random\n@@ -61,3 +63,23 @@ class RandomTest(testing.TestCase, parameterized.TestCase):\n         x_res = random.dropout(x, rate=0.8, seed=0)\n         self.assertGreater(knp.max(x_res), knp.max(x))\n         self.assertGreater(knp.sum(x_res == 0), 2)\n+\n+    @pytest.mark.skipif(\n+        keras_core.backend.backend() != \"jax\",\n+        reason=\"This test requires `jax` as the backend.\",\n+    )\n+    def test_dropout_jax_jit_stateless(self):\n+        import jax\n+        import jax.numpy as jnp\n+\n+        x = knp.ones(3)\n+\n+        @jax.jit\n+        def train_step(x):\n+            with keras_core.backend.StatelessScope():\n+                x = keras_core.layers.Dropout(rate=0.1)(x, training=True)\n+            return x\n+\n+        keras_core.utils.traceback_utils.disable_traceback_filtering()\n+        x = train_step(x)\n+        assert isinstance(x, jnp.ndarray)\n\n@@ -16,7 +16,10 @@ class SeedGenerator:\n             )\n \n         def seed_initializer(*args, **kwargs):\n-            return [seed, 0]\n+            from keras_core.backend import convert_to_tensor\n+\n+            dtype = kwargs.get(\"dtype\", None)\n+            return convert_to_tensor([seed, 0], dtype=dtype)\n \n         self.state = Variable(\n             seed_initializer,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e8ab3a936bd732b5bf811b1938d35a14a0905afc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 58 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 10 | Methods Changed: 5 | Complexity Δ (Sum/Max): 52/51 | Churn Δ: 61 | Churn Cumulative: 13672 | Contributors (this commit): 118 | Commits (past 90d): 10 | Contributors (cumulative): 122 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1519,9 +1519,12 @@ class ModelCheckpoint(Callback):\n             self.epochs_since_last_save = 0\n             filepath = self._get_file_path(epoch, batch, logs)\n \n-            # Create host directory if it doesn't exist.\n             dirname = os.path.dirname(filepath)\n-            if dirname and not tf.io.gfile.exists(dirname):\n+            if (\n+                dirname\n+                and not dirname.startswith(\"gs://\")\n+                and not tf.io.gfile.exists(dirname)\n+            ):\n                 tf.io.gfile.makedirs(dirname)\n \n             try:\n\n@@ -30,6 +30,8 @@ try:\n except ImportError:\n     h5py = None\n \n+is_oss = True\n+\n \n @keras_export(\"keras.saving.save_model\", \"keras.models.save_model\")\n def save_model(model, filepath, overwrite=True, save_format=None, **kwargs):\n@@ -118,6 +120,16 @@ def save_model(model, filepath, overwrite=True, save_format=None, **kwargs):\n     \"\"\"\n     save_format = get_save_format(filepath, save_format)\n \n+    # Supports GCS URIs through bigstore via a temporary file\n+    gs_filepath = None\n+    if str(filepath).startswith(\"gs://\"):\n+        gs_filepath = filepath\n+        if not is_oss:\n+            gs_filepath = filepath.replace(\"gs://\", \"/bigstore/\")\n+        filepath = os.path.join(\n+            saving_lib.get_temp_dir(), os.path.basename(gs_filepath)\n+        )\n+\n     # Deprecation warnings\n     if save_format == \"h5\":\n         warnings.warn(\n@@ -146,7 +158,7 @@ def save_model(model, filepath, overwrite=True, save_format=None, **kwargs):\n         saving_lib.save_model(model, filepath)\n     else:\n         # Legacy case\n-        return legacy_sm_saving_lib.save_model(\n+        legacy_sm_saving_lib.save_model(\n             model,\n             filepath,\n             overwrite=overwrite,\n@@ -154,6 +166,10 @@ def save_model(model, filepath, overwrite=True, save_format=None, **kwargs):\n             **kwargs,\n         )\n \n+    # Copy from temporary directory to GCS filepath\n+    if gs_filepath is not None:\n+        tf.io.gfile.copy(filepath, gs_filepath, overwrite=overwrite)\n+\n \n @keras_export(\"keras.saving.load_model\", \"keras.models.load_model\")\n def load_model(\n@@ -199,6 +215,17 @@ def load_model(\n     It is recommended that you use layer attributes to\n     access specific variables, e.g. `model.get_layer(\"dense_1\").kernel`.\n     \"\"\"\n+    # Supports GCS URIs by copying data to temporary file\n+    if str(filepath).startswith(\"gs://\"):\n+        gs_filepath = filepath\n+        if not is_oss:\n+            gs_filepath = filepath.replace(\"gs://\", \"/bigstore/\")\n+        filepath = os.path.join(\n+            saving_lib.get_temp_dir(), os.path.basename(gs_filepath)\n+        )\n+        if gs_filepath is not None:\n+            tf.io.gfile.copy(gs_filepath, filepath, overwrite=True)\n+\n     is_keras_zip = str(filepath).endswith(\".keras\") and zipfile.is_zipfile(\n         filepath\n     )\n@@ -241,6 +268,16 @@ def load_model(\n \n \n def save_weights(model, filepath, overwrite=True, **kwargs):\n+    # Supports GCS URIs through bigstore via a temporary file\n+    gs_filepath = None\n+    if str(filepath).startswith(\"gs://\"):\n+        gs_filepath = filepath\n+        if not is_oss:\n+            gs_filepath = filepath.replace(\"gs://\", \"/bigstore/\")\n+        filepath = os.path.join(\n+            saving_lib.get_temp_dir(), os.path.basename(gs_filepath)\n+        )\n+\n     if str(filepath).endswith(\".weights.h5\"):\n         # If file exists and should not be overwritten.\n         try:\n@@ -257,8 +294,23 @@ def save_weights(model, filepath, overwrite=True, **kwargs):\n             model, filepath, overwrite=overwrite, **kwargs\n         )\n \n+    # Copy from temporary directory to GCS filepath\n+    if gs_filepath is not None:\n+        tf.io.gfile.copy(filepath, gs_filepath, overwrite=overwrite)\n+\n \n def load_weights(model, filepath, skip_mismatch=False, **kwargs):\n+    # Supports GCS URIs by copying data to temporary file\n+    if str(filepath).startswith(\"gs://\"):\n+        gs_filepath = filepath\n+        if not is_oss:\n+            gs_filepath = filepath.replace(\"gs://\", \"/bigstore/\")\n+        filepath = os.path.join(\n+            saving_lib.get_temp_dir(), os.path.basename(gs_filepath)\n+        )\n+        if gs_filepath is not None:\n+            tf.io.gfile.copy(gs_filepath, filepath, overwrite=True)\n+\n     if str(filepath).endswith(\".keras\") and zipfile.is_zipfile(filepath):\n         saving_lib.load_weights_only(\n             model, filepath, skip_mismatch=skip_mismatch\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
