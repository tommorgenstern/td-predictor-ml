{"custom_id": "keras#2fadce57f0e12cf96f11fa1d42286986eccd70a8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 2 | Files Changed: 3 | Hunks: 6 | Methods Changed: 6 | Complexity Δ (Sum/Max): 6/2 | Churn Δ: 16 | Churn Cumulative: 25233 | Contributors (this commit): 166 | Commits (past 90d): 55 | Contributors (cumulative): 256 | DMM Complexity: 1.0\n\nDIFF:\n@@ -532,12 +532,16 @@ def eye(size, dtype=None, name=None):\n \n def zeros_like(x, dtype=None, name=None):\n     name = name or ''\n-    return C.zeros_like(x, name)\n+    if dtype is None:\n+        dtype = floatx()\n+    return C.cast(C.zeros_like(x, name), dtype)\n \n \n def ones_like(x, dtype=None, name=None):\n     name = name or ''\n-    return C.ones_like(x, name)\n+    if dtype is None:\n+        dtype = floatx()\n+    return C.cast(C.ones_like(x, name), dtype)\n \n \n def count_params(x):\n\n@@ -814,6 +814,8 @@ def zeros_like(x, dtype=None, name=None):\n     ```\n     {{np_implementation}}\n     \"\"\"\n+    if dtype is None:\n+        dtype = floatx()\n     return tf.zeros_like(x, dtype=dtype, name=name)\n \n \n@@ -840,6 +842,8 @@ def ones_like(x, dtype=None, name=None):\n     ```\n     {{np_implementation}}\n     \"\"\"\n+    if dtype is None:\n+        dtype = floatx()\n     return tf.ones_like(x, dtype=dtype, name=name)\n \n \n\n@@ -328,10 +328,14 @@ def eye(size, dtype=None, name=None):\n \n \n def ones_like(x, dtype=None, name=None):\n+    if dtype is None:\n+        dtype = floatx()\n     return T.ones_like(x, dtype=dtype)\n \n \n def zeros_like(x, dtype=None, name=None):\n+    if dtype is None:\n+        dtype = floatx()\n     return T.zeros_like(x, dtype=dtype)\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d7ea34fcc87159ec7d3b5a802b34629f756dd923", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 539 | Contributors (this commit): 15 | Commits (past 90d): 3 | Contributors (cumulative): 15 | DMM Complexity: None\n\nDIFF:\n@@ -100,7 +100,7 @@ def plot_results(models,\n \n     plt.figure(figsize=(10, 10))\n     start_range = digit_size // 2\n-    end_range = n * digit_size + start_range + 1\n+    end_range = (n - 1) * digit_size + start_range + 1\n     pixel_range = np.arange(start_range, end_range, digit_size)\n     sample_range_x = np.round(grid_x, 1)\n     sample_range_y = np.round(grid_y, 1)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ed144aa1299d6876263420a45460ed638a575903", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 13 | Churn Cumulative: 3004 | Contributors (this commit): 26 | Commits (past 90d): 4 | Contributors (cumulative): 29 | DMM Complexity: 0.0\n\nDIFF:\n@@ -246,8 +246,17 @@ class ConvRNN2D(RNN):\n         initial_state = K.sum(initial_state, axis=1)\n         shape = list(self.cell.kernel_shape)\n         shape[-1] = self.cell.filters\n+\n+        if K.backend() == 'tensorflow':\n+            # We need to force this to be a tensor\n+            # and not a variable, to avoid variable initialization\n+            # issues.\n+            import tensorflow as tf\n+            kernel = tf.zeros(tuple(shape))\n+        else:\n+            K.zeros(tuple(shape))\n         initial_state = self.cell.input_conv(initial_state,\n-                                             K.zeros(tuple(shape)),\n+                                             kernel,\n                                              padding=self.cell.padding)\n         # Fix for Theano because it needs\n         # K.int_shape to work in call() with initial_state.\n\n@@ -430,7 +430,7 @@ def test_finite_generator_enqueuer_processes():\n \n @pytest.mark.skipif('TRAVIS_PYTHON_VERSION' in os.environ,\n                     reason='Takes 150s to run')\n-def test_missing_inputs():\n+def DISABLED_test_missing_inputs():\n     missing_idx = 10\n \n     class TimeOutSequence(DummySequence):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#30fe4ff1f12ff0c45bac8738b4d2690eadd056b2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 246 | Contributors (this commit): 13 | Commits (past 90d): 1 | Contributors (cumulative): 13 | DMM Complexity: None\n\nDIFF:\n@@ -41,9 +41,8 @@ print('Indexing word vectors.')\n embeddings_index = {}\n with open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt')) as f:\n     for line in f:\n-        values = line.split()\n-        word = values[0]\n-        coefs = np.asarray(values[1:], dtype='float32')\n+        word, coefs = line.split(maxsplit=1)\n+        coefs = np.fromstring(coefs, 'f', sep=' ')\n         embeddings_index[word] = coefs\n \n print('Found %s word vectors.' % len(embeddings_index))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e361a26463bfda37c42acd3df1e4efb6d97215fe", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): -53/4 | Churn Δ: 14 | Churn Cumulative: 15341 | Contributors (this commit): 135 | Commits (past 90d): 37 | Contributors (cumulative): 141 | DMM Complexity: 1.0\n\nDIFF:\n@@ -986,7 +986,10 @@ def eye(size, dtype=None, name=None):\n     else:\n         n, m = size, size\n     with tf_ops.init_scope():\n-        return variable(tf.eye(n, m, dtype=dtype), dtype, name)\n+        v = tf.eye(n, m, dtype=dtype, name=name)\n+        if py_all(v.shape.as_list()):\n+            return variable(v, dtype=dtype, name=name)\n+        return v\n \n \n @symbolic\n\n@@ -282,8 +282,8 @@ class Identity(Initializer):\n     \"\"\"Initializer that generates the identity matrix.\n \n     Only use for 2D matrices.\n-    If the desired matrix is not square, it pads with zeros on the\n-    additional rows/columns\n+    If the desired matrix is not square, it gets padded\n+    with zeros for the additional rows/columns.\n \n     # Arguments\n         gain: Multiplicative factor to apply to the identity matrix.\n@@ -292,11 +292,12 @@ class Identity(Initializer):\n     def __init__(self, gain=1.):\n         self.gain = gain\n \n+    @K.eager\n     def __call__(self, shape, dtype=None):\n         if len(shape) != 2:\n             raise ValueError(\n-                'Identity matrix initializer can only be used for 2D matrices.')\n-\n+                'Identity matrix initializer '\n+                'can only be used for 2D matrices.')\n         return self.gain * K.eye((shape[0], shape[1]), dtype=dtype)\n \n     def get_config(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7d57c58bf5b404e0b91bedc4bc2215555312662a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 14637 | Contributors (this commit): 129 | Commits (past 90d): 32 | Contributors (cumulative): 129 | DMM Complexity: None\n\nDIFF:\n@@ -3698,8 +3698,6 @@ def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n             `\"channels_last\"` nor `\"channels_first\"`.\n     \"\"\"\n     data_format = normalize_data_format(data_format)\n-    if isinstance(output_shape, (tuple, list)):\n-        output_shape = tf.stack(output_shape)\n \n     # tf.nn.atrous_conv2d_transpose input only supports NHWC format\n     if data_format == 'channels_first' and dilation_rate != (1, 1):\n@@ -3715,7 +3713,8 @@ def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n                         output_shape[3],\n                         output_shape[1])\n     if output_shape[0] is None:\n-        output_shape = (tf.shape(x)[0],) + tuple(output_shape[1:])\n+        output_shape = (shape(x)[0],) + tuple(output_shape[1:])\n+\n     output_shape = tf.stack(list(output_shape))\n \n     padding = _preprocess_padding(padding)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#10970b9db17b5046fa5b779e5da67d7519475afa", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 15 | Churn Cumulative: 7064 | Contributors (this commit): 39 | Commits (past 90d): 34 | Contributors (cumulative): 39 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1137,12 +1137,16 @@ class TestBackend(object):\n     def test_crossentropy(self):\n         # toy label matrix (4 samples, 2 classes)\n         label = np.array([[.4, .6], [.3, .7], [.1, .9], [.2, .8]], dtype=np.float32)\n-        binary_targets = np.array([[.3, .7], [.2, .8], [.4, .6], [.1, .9]], dtype=np.float32)\n-        categorical_targets = np.array([[1, 0], [1, 0], [0, 1], [0, 1]], dtype=np.float32)\n-        check_two_tensor_operation('binary_crossentropy', label, binary_targets, WITH_NP)\n+        binary_targets = np.array([[.3, .7], [.2, .8], [.4, .6], [.1, .9]],\n+                                  dtype=np.float32)\n+        categorical_targets = np.array([[1, 0], [1, 0], [0, 1], [0, 1]],\n+                                       dtype=np.float32)\n+        check_two_tensor_operation(\n+            'binary_crossentropy', label, binary_targets, WITH_NP)\n         check_two_tensor_operation('binary_crossentropy', label, (4, 2),\n                                    WITH_NP, from_logits=True)\n-        check_two_tensor_operation('categorical_crossentropy', label, categorical_targets,\n+        check_two_tensor_operation(\n+            'categorical_crossentropy', label, categorical_targets,\n             WITH_NP, cntk_two_dynamicity=True)\n         check_two_tensor_operation('categorical_crossentropy', label, (4, 2),\n                                    WITH_NP, cntk_two_dynamicity=True,\n@@ -1151,7 +1155,8 @@ class TestBackend(object):\n         # toy label matrix (2 samples, 3 classes)\n         label = np.array([[.4, .1, .5], [.2, .6, .2]], dtype=np.float32)\n         categorical_targets = np.array([[0, 1, 0], [1, 0, 0]], dtype=np.float32)\n-        check_two_tensor_operation('categorical_crossentropy', label, categorical_targets,\n+        check_two_tensor_operation(\n+            'categorical_crossentropy', label, categorical_targets,\n             WITH_NP, cntk_two_dynamicity=True)\n         check_two_tensor_operation('categorical_crossentropy', label, (2, 3),\n                                    WITH_NP, cntk_two_dynamicity=True,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b2771d13b0f9146cde43af00f5a5156f56614436", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 14 | Files Changed: 2 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): -4/0 | Churn Δ: 19 | Churn Cumulative: 2123 | Contributors (this commit): 9 | Commits (past 90d): 7 | Contributors (cumulative): 12 | DMM Complexity: 1.0\n\nDIFF:\n@@ -4,7 +4,6 @@ from __future__ import print_function\n from __future__ import absolute_import\n from __future__ import division\n \n-import copy\n import re\n from six.moves import zip\n \n@@ -139,10 +138,7 @@ class Layer(object):\n             if 'batch_input_shape' in kwargs:\n                 batch_input_shape = tuple(kwargs['batch_input_shape'])\n             elif 'input_shape' in kwargs:\n-                if 'batch_size' in kwargs:\n-                    batch_size = kwargs['batch_size']\n-                else:\n-                    batch_size = None\n+                batch_size = kwargs.get('batch_size')\n                 batch_input_shape = (\n                     batch_size,) + tuple(kwargs['input_shape'])\n             self.batch_input_shape = batch_input_shape\n@@ -155,10 +151,7 @@ class Layer(object):\n                 dtype = K.floatx()\n             self.dtype = dtype\n \n-        if 'weights' in kwargs:\n-            self._initial_weights = kwargs['weights']\n-        else:\n-            self._initial_weights = None\n+        self._initial_weights = kwargs.get('weights')\n \n     @staticmethod\n     def _node_key(layer, node_index):\n@@ -441,7 +434,7 @@ class Layer(object):\n \n             # Handle mask propagation.\n             previous_mask = _collect_previous_mask(inputs)\n-            user_kwargs = copy.copy(kwargs)\n+            user_kwargs = kwargs.copy()\n             if not is_all_none(previous_mask):\n                 # The previous layer generated a mask.\n                 if has_arg(self.call, 'mask'):\n\n@@ -431,8 +431,7 @@ def test_loop(model, f, ins,\n             batch_outs = f(ins)\n             if isinstance(batch_outs, list):\n                 if step == 0:\n-                    for _ in enumerate(batch_outs):\n-                        outs.append(0.)\n+                    outs.extend([0.] * len(batch_outs))\n                 for i, batch_out in enumerate(batch_outs):\n                     if i in stateful_metric_indices:\n                         outs[i] = float(batch_out)\n@@ -471,8 +470,7 @@ def test_loop(model, f, ins,\n             batch_outs = f(ins_batch)\n             if isinstance(batch_outs, list):\n                 if batch_index == 0:\n-                    for batch_out in enumerate(batch_outs):\n-                        outs.append(0.)\n+                    outs.extend([0.] * len(batch_outs))\n                 for i, batch_out in enumerate(batch_outs):\n                     if i in stateful_metric_indices:\n                         outs[i] = batch_out\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f1e14ef9c57da498f37b8fe9ac7fe86bff0b3f76", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 453 | Contributors (this commit): 12 | Commits (past 90d): 2 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -26,7 +26,7 @@ class MaxNorm(Constraint):\n     to have a norm less than or equal to a desired value.\n \n     # Arguments\n-        m: the maximum norm for the incoming weights.\n+        max_value: the maximum norm for the incoming weights.\n         axis: integer, axis along which to calculate weight norms.\n             For instance, in a `Dense` layer the weight matrix\n             has shape `(input_dim, output_dim)`,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#35093bc9bb14a66d09fe6ea26e302df8ffad64f4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 12476 | Contributors (this commit): 85 | Commits (past 90d): 4 | Contributors (cumulative): 85 | DMM Complexity: None\n\nDIFF:\n@@ -498,7 +498,7 @@ class Flatten(Layer):\n         if not all(input_shape[1:]):\n             raise ValueError('The shape of the input to \"Flatten\" '\n                              'is not fully defined '\n-                             '(got ' + str(input_shape[1:]) + '. '\n+                             '(got ' + str(input_shape[1:]) + '). '\n                              'Make sure to pass a complete \"input_shape\" '\n                              'or \"batch_input_shape\" argument to the first '\n                              'layer in your model.')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#261bcb2515a82ba4c96c03e4960c03195218ddb4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 9 | Files Changed: 2 | Hunks: 8 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 18 | Churn Cumulative: 1170 | Contributors (this commit): 22 | Commits (past 90d): 2 | Contributors (cumulative): 30 | DMM Complexity: None\n\nDIFF:\n@@ -44,13 +44,13 @@ def sparse_categorical_accuracy(y_true, y_pred):\n \n \n def top_k_categorical_accuracy(y_true, y_pred, k=5):\n-    return K.mean(K.in_top_k(y_pred, K.argmax(y_true, axis=-1), k), axis=-1)\n+    return K.cast(K.in_top_k(y_pred, K.argmax(y_true, axis=-1), k), K.floatx())\n \n \n def sparse_top_k_categorical_accuracy(y_true, y_pred, k=5):\n     # If the shape of y_true is (num_samples, 1), flatten to (num_samples,)\n-    return K.mean(K.in_top_k(y_pred, K.cast(K.flatten(y_true), 'int32'), k),\n-                  axis=-1)\n+    return K.cast(K.in_top_k(y_pred, K.cast(K.flatten(y_true), 'int32'), k),\n+                  K.floatx())\n \n \n # Aliases\n\n@@ -87,13 +87,13 @@ def test_top_k_categorical_accuracy():\n     y_true = K.variable(np.array([[0, 1, 0], [1, 0, 0]]))\n     success_result = K.eval(metrics.top_k_categorical_accuracy(y_true, y_pred,\n                                                                k=3))\n-    assert success_result == 1\n+    assert np.mean(success_result) == 1\n     partial_result = K.eval(metrics.top_k_categorical_accuracy(y_true, y_pred,\n                                                                k=2))\n-    assert partial_result == 0.5\n+    assert np.mean(partial_result) == 0.5\n     failure_result = K.eval(metrics.top_k_categorical_accuracy(y_true, y_pred,\n                                                                k=1))\n-    assert failure_result == 0\n+    assert np.mean(failure_result) == 0\n \n \n @pytest.mark.skipif((K.backend() == 'cntk'),\n@@ -110,15 +110,15 @@ def test_sparse_top_k_categorical_accuracy(y_pred, y_true):\n     success_result = K.eval(\n         metrics.sparse_top_k_categorical_accuracy(y_true, y_pred, k=3))\n \n-    assert success_result == 1\n+    assert np.mean(success_result) == 1\n     partial_result = K.eval(\n         metrics.sparse_top_k_categorical_accuracy(y_true, y_pred, k=2))\n \n-    assert partial_result == 0.5\n+    assert np.mean(partial_result) == 0.5\n     failure_result = K.eval(\n         metrics.sparse_top_k_categorical_accuracy(y_true, y_pred, k=1))\n \n-    assert failure_result == 0\n+    assert np.mean(failure_result) == 0\n \n \n # TODO: resolve flakyness issue. Tracked with #11064\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#747ef0f16884b563d05605bf4919721a3b347479", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1624 | Contributors (this commit): 11 | Commits (past 90d): 1 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -14,7 +14,7 @@ from keras.utils import Sequence\n from keras import backend as K\n \n pytestmark = pytest.mark.skipif(\n-    six.PY2 and 'TRAVIS_PYTHON_VERSION' in os.environ,\n+    True,\n     reason='Temporarily disabled until the use_multiprocessing problem is solved')\n \n skip_generators = pytest.mark.skipif(K.backend() in {'tensorflow', 'cntk'} and\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f69e046eef93af5a28de5330bfe15ee348520b2d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 66 | Lines Deleted: 17 | Files Changed: 1 | Hunks: 11 | Methods Changed: 4 | Complexity Δ (Sum/Max): 14/14 | Churn Δ: 83 | Churn Cumulative: 266 | Contributors (this commit): 13 | Commits (past 90d): 3 | Contributors (cumulative): 13 | DMM Complexity: 0.21212121212121213\n\nDIFF:\n@@ -4,6 +4,8 @@ from __future__ import division\n from __future__ import print_function\n \n import os\n+from ..models import Model\n+from ..layers.wrappers import Wrapper\n \n # `pydot` is an optional dependency,\n # see `extras_require` in `setup.py`.\n@@ -31,6 +33,19 @@ def _check_pydot():\n             'and ensure that its executables are in the $PATH.')\n \n \n+def is_model(layer):\n+    return isinstance(layer, Model)\n+\n+\n+def is_wrapped_model(layer):\n+    return isinstance(layer, Wrapper) and isinstance(layer.layer, Model)\n+\n+\n+def add_edge(dot, src, dst):\n+    if not dot.get_edge(src, dst):\n+        dot.add_edge(pydot.Edge(src, dst))\n+\n+\n def model_to_dot(model,\n                  show_shapes=False,\n                  show_layer_names=True,\n@@ -63,7 +78,7 @@ def model_to_dot(model,\n \n     _check_pydot()\n     if subgraph:\n-        dot = pydot.Cluster(style='dashed')\n+        dot = pydot.Cluster(style='dashed', graph_name=model.name)\n         dot.set('label', model.name)\n         dot.set('labeljust', 'l')\n     else:\n@@ -85,24 +100,34 @@ def model_to_dot(model,\n         # Append a wrapped layer's label to node's label, if it exists.\n         layer_name = layer.name\n         class_name = layer.__class__.__name__\n+\n         if isinstance(layer, Wrapper):\n             if expand_nested and isinstance(layer.layer, Model):\n-                submodel = model_to_dot(layer.layer, show_shapes,\n-                                        show_layer_names, rankdir, expand_nested,\n+                submodel_wrapper = model_to_dot(layer.layer, show_shapes,\n+                                                show_layer_names, rankdir,\n+                                                expand_nested,\n                                                 subgraph=True)\n-                model_nodes = submodel.get_nodes()\n-                dot.add_edge(pydot.Edge(layer_id, model_nodes[0].get_name()))\n-                if len(layers) > i + 1:\n-                    next_layer_id = str(id(layers[i + 1]))\n-                    dot.add_edge(pydot.Edge(\n-                        model_nodes[len(model_nodes) - 1].get_name(),\n-                        next_layer_id))\n-                dot.add_subgraph(submodel)\n+                # sub_w : submodel_wrapper\n+                sub_w_nodes = submodel_wrapper.get_nodes()\n+                sub_w_first_node = sub_w_nodes[0]\n+                sub_w_last_node = sub_w_nodes[len(sub_w_nodes) - 1]\n+                dot.add_subgraph(submodel_wrapper)\n             else:\n                 layer_name = '{}({})'.format(layer_name, layer.layer.name)\n                 child_class_name = layer.layer.__class__.__name__\n                 class_name = '{}({})'.format(class_name, child_class_name)\n \n+        if expand_nested and isinstance(layer, Model):\n+            submodel_not_wrapper = model_to_dot(layer, show_shapes,\n+                                                show_layer_names, rankdir,\n+                                                expand_nested,\n+                                                subgraph=True)\n+            # sub_n : submodel_not_wrapper\n+            sub_n_nodes = submodel_not_wrapper.get_nodes()\n+            sub_n_first_node = sub_n_nodes[0]\n+            sub_n_last_node = sub_n_nodes[len(sub_n_nodes) - 1]\n+            dot.add_subgraph(submodel_not_wrapper)\n+\n         # Create node's label.\n         if show_layer_names:\n             label = '{}: {}'.format(layer_name, class_name)\n@@ -125,6 +150,8 @@ def model_to_dot(model,\n             label = '%s\\n|{input:|output:}|{{%s}|{%s}}' % (label,\n                                                            inputlabels,\n                                                            outputlabels)\n+\n+        if not expand_nested or not isinstance(layer, Model):\n             node = pydot.Node(layer_id, label=label)\n             dot.add_node(node)\n \n@@ -135,16 +162,38 @@ def model_to_dot(model,\n             node_key = layer.name + '_ib-' + str(i)\n             if node_key in model._network_nodes:\n                 for inbound_layer in node.inbound_layers:\n-                    if not expand_nested or not (\n-                            isinstance(inbound_layer, Wrapper) and\n-                            isinstance(inbound_layer.layer, Model)):\n                     inbound_layer_id = str(id(inbound_layer))\n-                        # Make sure that both nodes exist before connecting them with\n-                        # an edge, as add_edge would otherwise\n-                        # create any missing node.\n+                    if not expand_nested:\n                         assert dot.get_node(inbound_layer_id)\n                         assert dot.get_node(layer_id)\n                         dot.add_edge(pydot.Edge(inbound_layer_id, layer_id))\n+                    else:\n+                        # if inbound_layer is not Model or wrapped Model\n+                        if not is_model(inbound_layer) and (\n+                                not is_wrapped_model(inbound_layer)):\n+                            # if current layer is not Model or wrapped Model\n+                            if not is_model(layer) and (\n+                                    not is_wrapped_model(layer)):\n+                                assert dot.get_node(inbound_layer_id)\n+                                assert dot.get_node(layer_id)\n+                                dot.add_edge(pydot.Edge(inbound_layer_id,\n+                                                        layer_id))\n+                            # if current layer is Model\n+                            elif is_model(layer):\n+                                add_edge(dot, inbound_layer_id,\n+                                         sub_n_first_node.get_name())\n+                            # if current layer is wrapped Model\n+                            elif is_wrapped_model(layer):\n+                                dot.add_edge(pydot.Edge(inbound_layer_id,\n+                                                        layer_id))\n+                                dot.add_edge(pydot.Edge(layer_id,\n+                                                        sub_w_first_node.get_name()))\n+                        # if inbound_layer is Model\n+                        elif is_model(inbound_layer):\n+                            add_edge(dot, sub_n_last_node.get_name(), layer_id)\n+                        # if inbound_layer is wrapped Model\n+                        elif is_wrapped_model(inbound_layer):\n+                            add_edge(dot, sub_w_last_node.get_name(), layer_id)\n     return dot\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9416f3647ac4c9ec0c57575a66d66aeac077d56c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 383 | Contributors (this commit): 14 | Commits (past 90d): 2 | Contributors (cumulative): 14 | DMM Complexity: None\n\nDIFF:\n@@ -55,7 +55,7 @@ def load_data(path='imdb.npz', num_words=None, skip_top=0,\n     path = get_file(path,\n                     origin='https://s3.amazonaws.com/text-datasets/imdb.npz',\n                     file_hash='599dadb1135973df5b59232a0e9a887c')\n-    with np.load(path) as f:\n+    with np.load(path, allow_pickle=True) as f:\n         x_train, labels_train = f['x_train'], f['y_train']\n         x_test, labels_test = f['x_test'], f['y_test']\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#34231971fa47cb2477b357c1a368978de4128294", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 3 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 838 | Contributors (this commit): 16 | Commits (past 90d): 5 | Contributors (cumulative): 25 | DMM Complexity: None\n\nDIFF:\n@@ -26,7 +26,7 @@ def load_data(path='boston_housing.npz', test_split=0.2, seed=113):\n         path,\n         origin='https://s3.amazonaws.com/keras-datasets/boston_housing.npz',\n         file_hash='f553886a1f8d56431e820c5b82552d9d95cfcb96d1e678153f8839538947dff5')\n-    with np.load(path) as f:\n+    with np.load(path, allow_pickle=True) as f:\n         x = f['x']\n         y = f['y']\n \n\n@@ -21,7 +21,7 @@ def load_data(path='mnist.npz'):\n     path = get_file(path,\n                     origin='https://s3.amazonaws.com/img-datasets/mnist.npz',\n                     file_hash='8a61469f7ea1b51cbae51d4f78837e45')\n-    with np.load(path) as f:\n+    with np.load(path, allow_pickle=True) as f:\n         x_train, y_train = f['x_train'], f['y_train']\n         x_test, y_test = f['x_test'], f['y_test']\n     return (x_train, y_train), (x_test, y_test)\n\n@@ -53,7 +53,7 @@ def load_data(path='reuters.npz', num_words=None, skip_top=0,\n     path = get_file(path,\n                     origin='https://s3.amazonaws.com/text-datasets/reuters.npz',\n                     file_hash='87aedbeb0cb229e378797a632c1997b6')\n-    with np.load(path) as f:\n+    with np.load(path, allow_pickle=True) as f:\n         xs, labels = f['x'], f['y']\n \n     rng = np.random.RandomState(seed)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2a76796d87291e7a893d092cbf106cf3b9ad42c9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 15 | Lines Deleted: 15 | Files Changed: 1 | Hunks: 15 | Methods Changed: 7 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 30 | Churn Cumulative: 1654 | Contributors (this commit): 12 | Commits (past 90d): 2 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -127,7 +127,7 @@ def test_multiprocessing_training():\n     #   - BUT on Windows, `multiprocessing` won't marshall generators across\n     #     process boundaries -> make sure `fit_generator()` raises ValueError\n     #     exception and does not attempt to run the generator.\n-    if os.name is 'nt':\n+    if os.name == 'nt':\n         with pytest.raises(ValueError):\n             model.fit_generator(custom_generator(),\n                                 steps_per_epoch=STEPS_PER_EPOCH,\n@@ -163,7 +163,7 @@ def test_multiprocessing_training():\n     #   - BUT on Windows, `multiprocessing` won't marshall generators across\n     #     process boundaries -> make sure `fit_generator()` raises ValueError\n     #     exception and does not attempt to run the generator.\n-    if os.name is 'nt':\n+    if os.name == 'nt':\n         with pytest.raises(ValueError):\n             model.fit_generator(custom_generator(True),\n                                 steps_per_epoch=STEPS_PER_EPOCH,\n@@ -202,7 +202,7 @@ def test_multiprocessing_training():\n     #   - BUT on Windows, `multiprocessing` won't marshall generators across\n     #     process boundaries -> make sure `fit_generator()` raises ValueError\n     #     exception and does not attempt to run the generator.\n-    if os.name is 'nt':\n+    if os.name == 'nt':\n         with pytest.raises(ValueError):\n             model.fit_generator(custom_generator(True),\n                                 steps_per_epoch=STEPS_PER_EPOCH,\n@@ -334,7 +334,7 @@ def test_multiprocessing_training_from_file(in_tmpdir):\n     #   - BUT on Windows, `multiprocessing` won't marshall generators across\n     #     process boundaries -> make sure `fit_generator()` raises ValueError\n     #     exception and does not attempt to run the generator.\n-    if os.name is 'nt':\n+    if os.name == 'nt':\n         with pytest.raises(ValueError):\n             model.fit_generator(custom_generator(),\n                                 steps_per_epoch=STEPS_PER_EPOCH,\n@@ -359,7 +359,7 @@ def test_multiprocessing_training_from_file(in_tmpdir):\n     #   - BUT on Windows, `multiprocessing` won't marshall generators across\n     #     process boundaries -> make sure `fit_generator()` raises ValueError\n     #     exception and does not attempt to run the generator.\n-    if os.name is 'nt':\n+    if os.name == 'nt':\n         with pytest.raises(ValueError):\n             model.fit_generator(custom_generator(),\n                                 steps_per_epoch=STEPS_PER_EPOCH,\n@@ -482,7 +482,7 @@ def test_multiprocessing_predicting():\n     #   - BUT on Windows, `multiprocessing` won't marshall generators across\n     #     process boundaries -> make sure `predict_generator()` raises ValueError\n     #     exception and does not attempt to run the generator.\n-    if os.name is 'nt':\n+    if os.name == 'nt':\n         with pytest.raises(ValueError):\n             model.predict_generator(custom_generator(),\n                                     steps=STEPS,\n@@ -501,7 +501,7 @@ def test_multiprocessing_predicting():\n     #   - BUT on Windows, `multiprocessing` won't marshall generators across\n     #     process boundaries -> make sure `predict_generator()` raises ValueError\n     #     exception and does not attempt to run the generator.\n-    if os.name is 'nt':\n+    if os.name == 'nt':\n         with pytest.raises(ValueError):\n             model.predict_generator(custom_generator(),\n                                     steps=STEPS,\n@@ -598,7 +598,7 @@ def test_multiprocessing_evaluating():\n     #     process boundaries\n     #       -> make sure `evaluate_generator()` raises raises ValueError\n     #          exception and does not attempt to run the generator.\n-    if os.name is 'nt':\n+    if os.name == 'nt':\n         with pytest.raises(ValueError):\n             model.evaluate_generator(custom_generator(),\n                                      steps=STEPS,\n@@ -617,7 +617,7 @@ def test_multiprocessing_evaluating():\n     #   - BUT on Windows, `multiprocessing` won't marshall generators across\n     #     process boundaries -> make sure `evaluate_generator()` raises ValueError\n     #     exception and does not attempt to run the generator.\n-    if os.name is 'nt':\n+    if os.name == 'nt':\n         with pytest.raises(ValueError):\n             model.evaluate_generator(custom_generator(),\n                                      steps=STEPS,\n@@ -719,7 +719,7 @@ def test_multiprocessing_fit_error():\n     #     process boundaries -> make sure `fit_generator()` raises ValueError\n     #     exception and does not attempt to run the generator.\n     #   - On other platforms, make sure `RuntimeError` exception bubbles up\n-    if os.name is 'nt':\n+    if os.name == 'nt':\n         with pytest.raises(RuntimeError):\n             model.fit_generator(custom_generator(),\n                                 steps_per_epoch=samples,\n@@ -742,7 +742,7 @@ def test_multiprocessing_fit_error():\n     #     process boundaries -> make sure `fit_generator()` raises ValueError\n     #     exception and does not attempt to run the generator.\n     #   - On other platforms, make sure `RuntimeError` exception bubbles up\n-    if os.name is 'nt':\n+    if os.name == 'nt':\n         with pytest.raises(RuntimeError):\n             model.fit_generator(custom_generator(),\n                                 steps_per_epoch=samples,\n@@ -859,7 +859,7 @@ def test_multiprocessing_evaluate_error():\n     #     process boundaries -> make sure `evaluate_generator()` raises ValueError\n     #     exception and does not attempt to run the generator.\n     #   - On other platforms, make sure `RuntimeError` exception bubbles up\n-    if os.name is 'nt':\n+    if os.name == 'nt':\n         with pytest.raises(ValueError):\n             model.evaluate_generator(custom_generator(),\n                                      steps=good_batches * WORKERS + 1,\n@@ -880,7 +880,7 @@ def test_multiprocessing_evaluate_error():\n     #     process boundaries -> make sure `evaluate_generator()` raises ValueError\n     #     exception and does not attempt to run the generator.\n     #   - On other platforms, make sure `RuntimeError` exception bubbles up\n-    if os.name is 'nt':\n+    if os.name == 'nt':\n         with pytest.raises(RuntimeError):\n             model.evaluate_generator(custom_generator(),\n                                      steps=good_batches + 1,\n@@ -989,7 +989,7 @@ def test_multiprocessing_predict_error():\n     #     process boundaries -> make sure `predict_generator()` raises ValueError\n     #     exception and does not attempt to run the generator.\n     #   - On other platforms, make sure `RuntimeError` exception bubbles up\n-    if os.name is 'nt':\n+    if os.name == 'nt':\n         with pytest.raises(StopIteration):\n             model.predict_generator(custom_generator(),\n                                     steps=good_batches * WORKERS + 1,\n@@ -1010,7 +1010,7 @@ def test_multiprocessing_predict_error():\n     #     process boundaries -> make sure `predict_generator()` raises ValueError\n     #     exception and does not attempt to run the generator.\n     #   - On other platforms, make sure `RuntimeError` exception bubbles up\n-    if os.name is 'nt':\n+    if os.name == 'nt':\n         with pytest.raises(RuntimeError):\n             model.predict_generator(custom_generator(),\n                                     steps=good_batches + 1,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#47e1b18c0b7e3ddeef4e9fcded409a55d0479a4f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2026 | Contributors (this commit): 23 | Commits (past 90d): 1 | Contributors (cumulative): 23 | DMM Complexity: None\n\nDIFF:\n@@ -250,7 +250,7 @@ def _hash_file(fpath, algorithm='sha256', chunk_size=65535):\n     # Example\n \n     ```python\n-        >>> from keras.data_utils import _hash_file\n+        >>> from keras.utils.data_utils import _hash_file\n         >>> _hash_file('/path/to/file.zip')\n         'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855'\n     ```\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3b2e5e5af82f5e273862913b5e75aeb0971a20b6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 21704 | Contributors (this commit): 138 | Commits (past 90d): 59 | Contributors (cumulative): 168 | DMM Complexity: 0.0\n\nDIFF:\n@@ -627,6 +627,7 @@ def constant(value, dtype=None, shape=None, name=None):\n     # Returns\n         A Constant Tensor.\n     \"\"\"\n+    with tf_ops.init_scope():\n         return tf_keras_backend.constant(\n             value, dtype=dtype, shape=shape, name=name)\n \n\n@@ -1069,8 +1069,6 @@ class TestBackend(object):\n         # non scalar\n         shapes = []\n         shapes.append([(4, 3, 2), (4, 3, 2), (4, 3, 2)])\n-        shapes.append([(4, 3,), (4, 3, 2), (4, 3, 2)])\n-        shapes.append([(4,), (4, 3, 2), (4, 3, 2)])\n         for s in shapes:\n             z_list = []\n             arrays = list(map(np.random.random, s))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#510f9f0b1d97ca3567c858e0300c913a4bc2bf53", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2381 | Contributors (this commit): 17 | Commits (past 90d): 3 | Contributors (cumulative): 17 | DMM Complexity: None\n\nDIFF:\n@@ -254,7 +254,7 @@ class ConvRNN2D(RNN):\n             import tensorflow as tf\n             kernel = tf.zeros(tuple(shape))\n         else:\n-            K.zeros(tuple(shape))\n+            kernel = K.zeros(tuple(shape))\n         initial_state = self.cell.input_conv(initial_state,\n                                              kernel,\n                                              padding=self.cell.padding)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5430a7b4e95b88e8807c8a1a34059c76522791b6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 5 | Churn Cumulative: 14643 | Contributors (this commit): 129 | Commits (past 90d): 29 | Contributors (cumulative): 129 | DMM Complexity: 0.0\n\nDIFF:\n@@ -987,10 +987,7 @@ def eye(size, dtype=None, name=None):\n     else:\n         n, m = size, size\n     with tf_ops.init_scope():\n-        v = tf.eye(n, m, dtype=dtype, name=name)\n-        if py_all(v.shape.as_list()):\n-            return variable(v, dtype=dtype, name=name)\n-        return v\n+        return tf.eye(n, m, dtype=dtype, name=name)\n \n \n @symbolic\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#627bf95c11199419eb6d2017c322a0d78ef3dc3c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 207 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 207 | Churn Cumulative: 207 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -0,0 +1,207 @@\n+'''# Sequence-to-sequence example in Keras (character-level).\n+\n+This script demonstrates how to implement a basic character-level CNN\n+sequence-to-sequence model. We apply it to translating\n+short English sentences into short French sentences,\n+character-by-character. Note that it is fairly unusual to\n+do character-level machine translation, as word-level\n+models are much more common in this domain. This example\n+is for demonstration purposes only.\n+\n+**Summary of the algorithm**\n+\n+- We start with input sequences from a domain (e.g. English sentences)\n+    and corresponding target sequences from another domain\n+    (e.g. French sentences).\n+- An encoder CNN encodes the input character sequence.\n+- A decoder CNN is trained to turn the target sequences into\n+    the same sequence but offset by one timestep in the future,\n+    a training process called \"teacher forcing\" in this context.\n+    It uses the output from the encoder.\n+    Effectively, the decoder learns to generate `targets[t+1...]`\n+    given `targets[...t]`, conditioned on the input sequence.\n+- In inference mode, when we want to decode unknown input sequences, we:\n+    - Encode the input sequence.\n+    - Start with a target sequence of size 1\n+        (just the start-of-sequence character)\n+    - Feed the input sequence and 1-char target sequence\n+        to the decoder to produce predictions for the next character\n+    - Sample the next character using these predictions\n+        (we simply use argmax).\n+    - Append the sampled character to the target sequence\n+    - Repeat until we hit the character limit.\n+\n+**Data download**\n+\n+[English to French sentence pairs.\n+](http://www.manythings.org/anki/fra-eng.zip)\n+\n+[Lots of neat sentence pairs datasets.\n+](http://www.manythings.org/anki/)\n+\n+**References**\n+\n+- lstm_seq2seq.py\n+- https://wanasit.github.io/attention-based-sequence-to-sequence-in-keras.html\n+'''\n+from __future__ import print_function\n+\n+import numpy as np\n+\n+from keras.layers import Input, Convolution1D, Dot, Dense, Activation, Concatenate\n+from keras.models import Model\n+\n+batch_size = 64  # Batch size for training.\n+epochs = 100  # Number of epochs to train for.\n+num_samples = 10000  # Number of samples to train on.\n+# Path to the data txt file on disk.\n+data_path = 'fra-eng/fra.txt'\n+\n+# Vectorize the data.\n+input_texts = []\n+target_texts = []\n+input_characters = set()\n+target_characters = set()\n+with open(data_path, 'r', encoding='utf-8') as f:\n+    lines = f.read().split('\\n')\n+for line in lines[: min(num_samples, len(lines) - 1)]:\n+    input_text, target_text = line.split('\\t')\n+    # We use \"tab\" as the \"start sequence\" character\n+    # for the targets, and \"\\n\" as \"end sequence\" character.\n+    target_text = '\\t' + target_text + '\\n'\n+    input_texts.append(input_text)\n+    target_texts.append(target_text)\n+    for char in input_text:\n+        if char not in input_characters:\n+            input_characters.add(char)\n+    for char in target_text:\n+        if char not in target_characters:\n+            target_characters.add(char)\n+\n+input_characters = sorted(list(input_characters))\n+target_characters = sorted(list(target_characters))\n+num_encoder_tokens = len(input_characters)\n+num_decoder_tokens = len(target_characters)\n+max_encoder_seq_length = max([len(txt) for txt in input_texts])\n+max_decoder_seq_length = max([len(txt) for txt in target_texts])\n+\n+print('Number of samples:', len(input_texts))\n+print('Number of unique input tokens:', num_encoder_tokens)\n+print('Number of unique output tokens:', num_decoder_tokens)\n+print('Max sequence length for inputs:', max_encoder_seq_length)\n+print('Max sequence length for outputs:', max_decoder_seq_length)\n+\n+input_token_index = dict(\n+    [(char, i) for i, char in enumerate(input_characters)])\n+target_token_index = dict(\n+    [(char, i) for i, char in enumerate(target_characters)])\n+\n+encoder_input_data = np.zeros(\n+    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n+    dtype='float32')\n+decoder_input_data = np.zeros(\n+    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n+    dtype='float32')\n+decoder_target_data = np.zeros(\n+    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n+    dtype='float32')\n+\n+for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n+    for t, char in enumerate(input_text):\n+        encoder_input_data[i, t, input_token_index[char]] = 1.\n+    for t, char in enumerate(target_text):\n+        # decoder_target_data is ahead of decoder_input_data by one timestep\n+        decoder_input_data[i, t, target_token_index[char]] = 1.\n+        if t > 0:\n+            # decoder_target_data will be ahead by one timestep\n+            # and will not include the start character.\n+            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n+\n+# Define an input sequence and process it.\n+encoder_inputs = Input(shape=(None, num_encoder_tokens))\n+# Encoder\n+x_encoder = Convolution1D(256, kernel_size=3, activation='relu',\n+                          padding='causal')(encoder_inputs)\n+x_encoder = Convolution1D(256, kernel_size=3, activation='relu',\n+                          padding='causal', dilation_rate=2)(x_encoder)\n+x_encoder = Convolution1D(256, kernel_size=3, activation='relu',\n+                          padding='causal', dilation_rate=4)(x_encoder)\n+\n+decoder_inputs = Input(shape=(None, num_decoder_tokens))\n+# Decoder\n+x_decoder = Convolution1D(256, kernel_size=3, activation='relu',\n+                          padding='causal')(decoder_inputs)\n+x_decoder = Convolution1D(256, kernel_size=3, activation='relu',\n+                          padding='causal', dilation_rate=2)(x_decoder)\n+x_decoder = Convolution1D(256, kernel_size=3, activation='relu',\n+                          padding='causal', dilation_rate=4)(x_decoder)\n+# Attention\n+attention = Dot(axes=[2, 2])([x_decoder, x_encoder])\n+attention = Activation('softmax')(attention)\n+\n+context = Dot(axes=[2, 1])([attention, x_encoder])\n+decoder_combined_context = Concatenate(axis=-1)([context, x_decoder])\n+\n+decoder_outputs = Convolution1D(64, kernel_size=3, activation='relu',\n+                                padding='causal')(decoder_combined_context)\n+decoder_outputs = Convolution1D(64, kernel_size=3, activation='relu',\n+                                padding='causal')(decoder_outputs)\n+# Output\n+decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n+decoder_outputs = decoder_dense(decoder_outputs)\n+\n+# Define the model that will turn\n+# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n+model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n+model.summary()\n+\n+# Run training\n+model.compile(optimizer='adam', loss='categorical_crossentropy')\n+model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n+          batch_size=batch_size,\n+          epochs=epochs,\n+          validation_split=0.2)\n+# Save model\n+model.save('cnn_s2s.h5')\n+\n+# Next: inference mode (sampling).\n+\n+# Define sampling models\n+reverse_input_char_index = dict(\n+    (i, char) for char, i in input_token_index.items())\n+reverse_target_char_index = dict(\n+    (i, char) for char, i in target_token_index.items())\n+\n+nb_examples = 100\n+in_encoder = encoder_input_data[:nb_examples]\n+in_decoder = np.zeros(\n+    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n+    dtype='float32')\n+\n+in_decoder[:, 0, target_token_index[\"\\t\"]] = 1\n+\n+predict = np.zeros(\n+    (len(input_texts), max_decoder_seq_length),\n+    dtype='float32')\n+\n+for i in range(max_decoder_seq_length - 1):\n+    predict = model.predict([in_encoder, in_decoder])\n+    predict = predict.argmax(axis=-1)\n+    predict_ = predict[:, i].ravel().tolist()\n+    for j, x in enumerate(predict_):\n+        in_decoder[j, i + 1, x] = 1\n+\n+for seq_index in range(nb_examples):\n+    # Take one sequence (part of the training set)\n+    # for trying out decoding.\n+    output_seq = predict[seq_index, :].ravel().tolist()\n+    decoded = []\n+    for x in output_seq:\n+        if reverse_target_char_index[x] == \"\\n\":\n+            break\n+        else:\n+            decoded.append(reverse_target_char_index[x])\n+    decoded_sentence = \"\".join(decoded)\n+    print('-')\n+    print('Input sentence:', input_texts[seq_index])\n+    print('Decoded sentence:', decoded_sentence)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
