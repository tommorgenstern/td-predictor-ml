{"custom_id": "keras#0b76b9144aa736735cb2e460de0d591335a88409", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 4 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 16 | Churn Cumulative: 32 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -1,11 +1,19 @@\n-\"\"\"Image classification benchmark with EfficientNetV2B0.\n+\"\"\"Image classification benchmark.\n+\n+This script runs image classification benchmark with \"dogs vs cats\" datasets. It \n+supports the following 3 models:\n+- EfficientNetV2B0\n+- Xception\n+- ResNet50V2\n \n To run the benchmark, make sure you are in model_benchmark/ directory, and run\n the command below:\n \n-python3 -m model_benchmark.efficient_net_image_classification_benchmark \\\n+python3 -m model_benchmark.image_classification_benchmark \\\n+    --model=\"EfficientNetV2B0\" \\\n     --epochs=2 \\\n-    --batch_size=32\n+    --batch_size=32 \\\n+    --mixed_precision_policy=\"mixed_float16\"\n \"\"\"\n \n import time\n@@ -93,7 +101,7 @@ def main(_):\n     logging.info(\n         \"Benchmarking configs...\\n\"\n         \"=========================\\n\"\n-        f\"MODEL: EfficientNetV2B0\\n\"\n+        f\"MODEL: {FLAGS.model}\\n\"\n         f\"TASK: image classification/dogs-vs-cats \\n\"\n         f\"BATCH_SIZE: {FLAGS.batch_size}\\n\"\n         f\"EPOCHS: {FLAGS.epochs}\\n\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6a05407841c717e53c361c2d2f29968a71e52c4e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 10 | Churn Cumulative: 12920 | Contributors (this commit): 119 | Commits (past 90d): 8 | Contributors (cumulative): 119 | DMM Complexity: 0.0\n\nDIFF:\n@@ -2889,8 +2889,14 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):\n         if not logs:\n             return\n \n-        train_logs = {k: v for k, v in logs.items() if not k.startswith(\"val_\")}\n-        val_logs = {k: v for k, v in logs.items() if k.startswith(\"val_\")}\n+        train_logs = dict()\n+        val_logs = dict()\n+        for k, v in logs.items():\n+            if k.startswith(\"val_\"):\n+                val_logs[k] = v\n+            else:\n+                train_logs[k] = v\n+\n         train_logs = self._collect_learning_rate(train_logs)\n         if self.write_steps_per_second:\n             train_logs[\"steps_per_second\"] = self._compute_steps_per_second()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cf4fa20bae61b80df6babef35a548383aac65161", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 58 | Lines Deleted: 7 | Files Changed: 5 | Hunks: 6 | Methods Changed: 2 | Complexity Δ (Sum/Max): 18/13 | Churn Δ: 65 | Churn Cumulative: 3751 | Contributors (this commit): 10 | Commits (past 90d): 50 | Contributors (cumulative): 15 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,7 +1,8 @@\n \"\"\"Image classification benchmark.\n \n-This script runs image classification benchmark with \"dogs vs cats\" datasets. It \n-supports the following 3 models:\n+This script runs image classification benchmark with \"dogs vs cats\" datasets.\n+It supports the following 3 models:\n+\n - EfficientNetV2B0\n - Xception\n - ResNet50V2\n\n@@ -33,7 +33,9 @@ def get_global_setting(name, default=None, set_to_default=False):\n     return attr\n \n \n-@keras_core_export(\"keras_core.backend.clear_session\")\n+@keras_core_export(\n+    [\"keras_core.utils.clear_session\", \"keras_core.backend.clear_session\"]\n+)\n def clear_session():\n     \"\"\"Resets all state generated by Keras.\n \n\n@@ -10,9 +10,7 @@ else:\n     BackendOptimizer = base_optimizer.BaseOptimizer\n \n \n-keras_core_export([\"keras_core.Optimizer\", \"keras_core.optimizers.Optimizer\"])\n-\n-\n+@keras_core_export([\"keras_core.Optimizer\", \"keras_core.optimizers.Optimizer\"])\n class Optimizer(BackendOptimizer):\n     pass\n \n\n@@ -6,6 +6,7 @@ from tensorflow.io import gfile\n from keras_core.api_export import keras_core_export\n from keras_core.saving import saving_lib\n from keras_core.saving.legacy import legacy_h5_format\n+from keras_core.utils import io_utils\n \n try:\n     import h5py\n@@ -13,6 +14,55 @@ except ImportError:\n     h5py = None\n \n \n+@keras_core_export(\n+    [\"keras_core.saving.save_model\", \"keras_core.models.save_model\"]\n+)\n+def save_model(model, filepath, overwrite=True):\n+    \"\"\"Saves a model as a `.keras` file.\n+\n+    Args:\n+        model: Keras model instance to be saved.\n+        filepath: `str` or `pathlib.Path` object. Path where to save the model.\n+        overwrite: Whether we should overwrite any existing model at the target\n+            location, or instead ask the user via an interactive prompt.\n+\n+    Example:\n+\n+    ```python\n+    model = keras_core.Sequential(\n+        [\n+            keras_core.layers.Dense(5, input_shape=(3,)),\n+            keras_core.layers.Softmax(),\n+        ],\n+    )\n+    model.save(\"model.keras\")\n+    loaded_model = keras_core.saving.load_model(\"model.keras\")\n+    x = keras.random.uniform((10, 3))\n+    assert np.allclose(model.predict(x), loaded_model.predict(x))\n+    ```\n+\n+    Note that `model.save()` is an alias for `keras_core.saving.save_model()`.\n+\n+    The saved `.keras` file contains:\n+\n+    - The model's configuration (architecture)\n+    - The model's weights\n+    - The model's optimizer's state (if any)\n+\n+    Thus models can be reinstantiated in the exact same state.\n+    \"\"\"\n+    # If file exists and should not be overwritten.\n+    try:\n+        exists = os.path.exists(filepath)\n+    except TypeError:\n+        exists = False\n+    if exists and not overwrite:\n+        proceed = io_utils.ask_to_proceed_with_overwrite(filepath)\n+        if not proceed:\n+            return\n+    saving_lib.save_model(model, filepath)\n+\n+\n @keras_core_export(\n     [\"keras_core.saving.load_model\", \"keras_core.models.load_model\"]\n )\n\n@@ -42,7 +42,7 @@ def save_model(model, filepath, weights_format=\"h5\"):\n \n     - JSON-based configuration file (config.json): Records of model, layer, and\n         other trackables' configuration.\n-    - NPZ-based trackable state files, found in respective directories, such as\n+    - H5-based trackable state files, found in respective directories, such as\n         model/states.npz, model/dense_layer/states.npz, etc.\n     - Metadata file.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fc6262664a45ccb8bcfee2384a4551c73cd58361", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 31 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 31 | Churn Cumulative: 2844 | Contributors (this commit): 11 | Commits (past 90d): 96 | Contributors (cumulative): 16 | DMM Complexity: 0.896551724137931\n\nDIFF:\n@@ -75,6 +75,10 @@ class Trainer:\n         self._loss_tracker = metrics_module.Mean(name=\"loss\")\n         self.steps_per_execution = steps_per_execution\n \n+        self.train_function = None\n+        self.test_function = None\n+        self.predict_function = None\n+\n         self._compile_config = serialization_lib.SerializableDict(\n             optimizer=optimizer,\n             loss=loss,\n\n@@ -536,3 +536,30 @@ class TestTrainer(testing.TestCase, parameterized.TestCase):\n         out2 = model.predict_on_batch(np.ones((2, 20)))\n         out3 = model.predict_on_batch(np.ones((2, 20)))\n         self.assertGreater(5, np.sum(np.abs(out2 - out3)))\n+\n+    def test_recompile(self):\n+        inputs = layers.Input((2,))\n+        outputs = layers.Dense(3)(inputs)\n+        model = keras_core.Model(inputs, outputs)\n+        model.compile(optimizer=\"sgd\", loss=\"mse\", metrics=[\"mse\"])\n+        history_1 = model.fit(np.ones((3, 2)), np.ones((3, 3))).history\n+        eval_out_1 = model.evaluate(\n+            np.ones((3, 2)), np.ones((3, 3)), return_dict=True\n+        )\n+        model.compile(optimizer=\"sgd\", loss=\"mse\", metrics=[\"mae\"])\n+        history_2 = model.fit(np.ones((3, 2)), np.ones((3, 3))).history\n+        eval_out_2 = model.evaluate(\n+            np.ones((3, 2)), np.ones((3, 3)), return_dict=True\n+        )\n+        self.assertEqual(\n+            sorted(list(history_1.keys())), [\"loss\", \"mean_squared_error\"]\n+        )\n+        self.assertEqual(\n+            sorted(list(eval_out_1.keys())), [\"loss\", \"mean_squared_error\"]\n+        )\n+        self.assertEqual(\n+            sorted(list(history_2.keys())), [\"loss\", \"mean_absolute_error\"]\n+        )\n+        self.assertEqual(\n+            sorted(list(eval_out_2.keys())), [\"loss\", \"mean_absolute_error\"]\n+        )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d8846c61d15ca6fe1ab7f478c355ea199ea4cca9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 17 | Churn Cumulative: 768 | Contributors (this commit): 6 | Commits (past 90d): 14 | Contributors (cumulative): 8 | DMM Complexity: 1.0\n\nDIFF:\n@@ -9,6 +9,9 @@ from keras_core.backend.common.backend_utils import (\n from keras_core.backend.config import epsilon\n from keras_core.backend.torch.core import convert_to_tensor\n from keras_core.backend.torch.core import get_device\n+from keras_core.backend.torch.numpy import expand_dims\n+from keras_core.backend.torch.numpy import maximum\n+from keras_core.backend.torch.numpy import where\n from keras_core.utils.argument_validation import standardize_tuple\n \n \n@@ -516,7 +519,13 @@ def one_hot(x, num_classes, axis=-1, dtype=\"float32\"):\n     # Axis is the output axis. By default, PyTorch, outputs to last axis.\n     # If axis is not last, change output to axis and shift remaining elements.\n     x = convert_to_tensor(x, dtype=torch.long)\n-    output = tnn.one_hot(x, num_classes)\n+\n+    # Torch one_hot does not natively handle negative values, so we add some\n+    # manual handling for negatives in the input to one_hot by using max(x, 0).\n+    # The output will have some invalid results, so we set them back to 0 using\n+    # `where` afterwards.\n+    output = tnn.one_hot(maximum(x, 0), num_classes)\n+    output = where(expand_dims(x, axis=-1) >= 0, output, 0)\n     output = convert_to_tensor(output, dtype=dtype)\n     dims = output.dim()\n     if axis != -1 and axis != dims:\n\n@@ -1022,6 +1022,12 @@ class NNOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             tf.one_hot(indices_2d, 4, axis=1),\n         )\n \n+        # Test 1D one-hot with negative inputs\n+        indices_1d = np.array([0, -1, -1, 3])\n+        self.assertAllClose(\n+            knn.one_hot(indices_1d, 4), tf.one_hot(indices_1d, 4)\n+        )\n+\n     def test_binary_crossentropy(self):\n         # Test with from_logits=False\n         target = np.array([[0.1], [0.9], [0.2], [1.0]])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#75ac72f43e56dd0a211e2b75d6d02c47dc49c0bc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 30 | Lines Deleted: 20 | Files Changed: 4 | Hunks: 13 | Methods Changed: 3 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 50 | Churn Cumulative: 3032 | Contributors (this commit): 12 | Commits (past 90d): 116 | Contributors (cumulative): 21 | DMM Complexity: 0.0\n\nDIFF:\n@@ -9,9 +9,6 @@ from keras_core.backend.common.backend_utils import (\n from keras_core.backend.config import epsilon\n from keras_core.backend.torch.core import convert_to_tensor\n from keras_core.backend.torch.core import get_device\n-from keras_core.backend.torch.numpy import expand_dims\n-from keras_core.backend.torch.numpy import maximum\n-from keras_core.backend.torch.numpy import where\n from keras_core.utils.argument_validation import standardize_tuple\n \n \n@@ -519,13 +516,7 @@ def one_hot(x, num_classes, axis=-1, dtype=\"float32\"):\n     # Axis is the output axis. By default, PyTorch, outputs to last axis.\n     # If axis is not last, change output to axis and shift remaining elements.\n     x = convert_to_tensor(x, dtype=torch.long)\n-\n-    # Torch one_hot does not natively handle negative values, so we add some\n-    # manual handling for negatives in the input to one_hot by using max(x, 0).\n-    # The output will have some invalid results, so we set them back to 0 using\n-    # `where` afterwards.\n-    output = tnn.one_hot(maximum(x, 0), num_classes)\n-    output = where(expand_dims(x, axis=-1) >= 0, output, 0)\n+    output = tnn.one_hot(x, num_classes)\n     output = convert_to_tensor(output, dtype=dtype)\n     dims = output.dim()\n     if axis != -1 and axis != dims:\n\n@@ -606,11 +606,18 @@ class Layer(BackendLayer, Operation):\n             # Wasn't passed explicitly: use context value\n             training = call_context.training\n             if training is None:\n-                # Get signature default value; else False\n-                training = call_spec.arguments_dict.get(\"training\", False)\n+                # Get signature default value\n+                training = call_spec.arguments_dict.get(\"training\", None)\n         call_context.training = training\n         if self._call_has_training_arg():\n+            if training is not None:\n+                # Only populate arg if it has a concrete value\n                 kwargs[\"training\"] = training\n+            elif \"training\" in kwargs:\n+                # In some cases the value None may have been passed explicitly\n+                # (e.g. by a parent Sequential).\n+                # That's invalid, so don't propagate it.\n+                kwargs.pop(\"training\")\n \n         ##############################\n         # 6. Populate mask argument(s)\n\n@@ -1022,12 +1022,6 @@ class NNOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             tf.one_hot(indices_2d, 4, axis=1),\n         )\n \n-        # Test 1D one-hot with negative inputs\n-        indices_1d = np.array([0, -1, -1, 3])\n-        self.assertAllClose(\n-            knn.one_hot(indices_1d, 4), tf.one_hot(indices_1d, 4)\n-        )\n-\n     def test_binary_crossentropy(self):\n         # Test with from_logits=False\n         target = np.array([[0.1], [0.9], [0.2], [1.0]])\n\n@@ -11,6 +11,8 @@ GLOBAL_CUSTOM_NAMES = {}\n     [\n         \"keras_core.saving.CustomObjectScope\",\n         \"keras_core.saving.custom_object_scope\",\n+        \"keras_core.utils.CustomObjectScope\",\n+        \"keras_core.utils.custom_object_scope\",\n     ]\n )\n class CustomObjectScope:\n@@ -63,7 +65,10 @@ custom_object_scope = CustomObjectScope\n \n \n @keras_core_export(\n+    [\n         \"keras_core.saving.get_custom_objects\",\n+        \"keras_core.utils.get_custom_objects\",\n+    ]\n )\n def get_custom_objects():\n     \"\"\"Retrieves a live reference to the global dictionary of custom objects.\n@@ -86,7 +91,10 @@ def get_custom_objects():\n \n \n @keras_core_export(\n+    [\n         \"keras_core.saving.register_keras_serializable\",\n+        \"keras_core.utils.register_keras_serializable\",\n+    ]\n )\n def register_keras_serializable(package=\"Custom\", name=None):\n     \"\"\"Registers an object with the Keras serialization framework.\n@@ -147,7 +155,12 @@ def register_keras_serializable(package=\"Custom\", name=None):\n     return decorator\n \n \n-@keras_core_export(\"keras_core.saving.get_registered_name\")\n+@keras_core_export(\n+    [\n+        \"keras_core.saving.get_registered_name\",\n+        \"keras_core.utils.get_registered_name\",\n+    ]\n+)\n def get_registered_name(obj):\n     \"\"\"Returns the name registered to an object within the Keras framework.\n \n@@ -168,7 +181,12 @@ def get_registered_name(obj):\n         return obj.__name__\n \n \n-@keras_core_export(\"keras_core.saving.get_registered_object\")\n+@keras_core_export(\n+    [\n+        \"keras_core.saving.get_registered_object\",\n+        \"keras_core.utils.get_registered_object\",\n+    ]\n+)\n def get_registered_object(name, custom_objects=None, module_objects=None):\n     \"\"\"Returns the class associated with `name` if it is registered with Keras.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7be8f274707efe63e8315db64366e2468cbf1606", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 17 | Churn Cumulative: 802 | Contributors (this commit): 6 | Commits (past 90d): 18 | Contributors (cumulative): 8 | DMM Complexity: 1.0\n\nDIFF:\n@@ -9,6 +9,9 @@ from keras_core.backend.common.backend_utils import (\n from keras_core.backend.config import epsilon\n from keras_core.backend.torch.core import convert_to_tensor\n from keras_core.backend.torch.core import get_device\n+from keras_core.backend.torch.numpy import expand_dims\n+from keras_core.backend.torch.numpy import maximum\n+from keras_core.backend.torch.numpy import where\n from keras_core.utils.argument_validation import standardize_tuple\n \n \n@@ -516,7 +519,13 @@ def one_hot(x, num_classes, axis=-1, dtype=\"float32\"):\n     # Axis is the output axis. By default, PyTorch, outputs to last axis.\n     # If axis is not last, change output to axis and shift remaining elements.\n     x = convert_to_tensor(x, dtype=torch.long)\n-    output = tnn.one_hot(x, num_classes)\n+\n+    # Torch one_hot does not natively handle negative values, so we add some\n+    # manual handling for negatives in the input to one_hot by using max(x, 0).\n+    # The output will have some invalid results, so we set them back to 0 using\n+    # `where` afterwards.\n+    output = tnn.one_hot(maximum(x, 0), num_classes)\n+    output = where(expand_dims(x, axis=-1) >= 0, output, 0)\n     output = convert_to_tensor(output, dtype=dtype)\n     dims = output.dim()\n     if axis != -1 and axis != dims:\n\n@@ -1022,6 +1022,12 @@ class NNOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             tf.one_hot(indices_2d, 4, axis=1),\n         )\n \n+        # Test 1D one-hot with negative inputs\n+        indices_1d = np.array([0, -1, -1, 3])\n+        self.assertAllClose(\n+            knn.one_hot(indices_1d, 4), tf.one_hot(indices_1d, 4)\n+        )\n+\n     def test_binary_crossentropy(self):\n         # Test with from_logits=False\n         target = np.array([[0.1], [0.9], [0.2], [1.0]])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5f4c9e7083bc649941e5c00b9b1d7a926deaa159", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 8 | Files Changed: 3 | Hunks: 4 | Methods Changed: 4 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 11 | Churn Cumulative: 4322 | Contributors (this commit): 11 | Commits (past 90d): 166 | Contributors (cumulative): 23 | DMM Complexity: 0.0\n\nDIFF:\n@@ -609,15 +609,9 @@ class Layer(BackendLayer, Operation):\n                 # Get signature default value\n                 training = call_spec.arguments_dict.get(\"training\", None)\n         call_context.training = training\n-        if self._call_has_training_arg():\n-            if training is not None:\n+        if self._call_has_training_arg() and training is not None:\n             # Only populate arg if it has a concrete value\n             kwargs[\"training\"] = training\n-            elif \"training\" in kwargs:\n-                # In some cases the value None may have been passed explicitly\n-                # (e.g. by a parent Sequential).\n-                # That's invalid, so don't propagate it.\n-                kwargs.pop(\"training\")\n \n         ##############################\n         # 6. Populate mask argument(s)\n\n@@ -543,6 +543,7 @@ def operation_fn(operation, training):\n         if (\n             hasattr(operation, \"_call_has_training_arg\")\n             and operation._call_has_training_arg()\n+            and training is not None\n         ):\n             kwargs[\"training\"] = training\n         return operation(*args, **kwargs)\n\n@@ -179,7 +179,7 @@ class Sequential(Model):\n             kwargs = {}\n             if layer._call_has_mask_arg():\n                 kwargs[\"mask\"] = mask\n-            if layer._call_has_training_arg():\n+            if layer._call_has_training_arg() and training is not None:\n                 kwargs[\"training\"] = training\n             outputs = layer(inputs, **kwargs)\n             inputs = outputs\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6d5484798dbafd3f8d83e3a56c8309c78f1dc8ed", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 7 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 545 | Contributors (this commit): 22 | Commits (past 90d): 4 | Contributors (cumulative): 22 | DMM Complexity: None\n\nDIFF:\n@@ -29,21 +29,24 @@ setup(\n     name=\"keras-core\",\n     description=\"Multi-backend Keras.\",\n     long_description_content_type=\"text/markdown\",\n+    long_description=README,\n     version=VERSION,\n     url=\"https://github.com/keras-team/keras-core\",\n     author=\"Keras team\",\n-    author_email=\"keras@google.com\",\n+    author_email=\"keras-users@googlegroups.com\",\n     license=\"Apache License 2.0\",\n     install_requires=[\n+        \"tensorflow\",\n         \"absl-py\",\n         \"numpy\",\n-        \"packaging\",\n         \"rich\",\n+        \"namex\",\n+        \"h5py\",\n     ],\n     # Supported Python versions\n     python_requires=\">=3.8\",\n     classifiers=[\n-        \"Development Status :: 3 - Alpha\",\n+        \"Development Status :: 4 - Beta\",\n         \"Programming Language :: Python :: 3\",\n         \"Programming Language :: Python :: 3.8\",\n         \"Programming Language :: Python :: 3.9\",\n@@ -51,7 +54,6 @@ setup(\n         \"Programming Language :: Python :: 3.11\",\n         \"Programming Language :: Python :: 3 :: Only\",\n         \"Operating System :: Unix\",\n-        \"Operating System :: Microsoft :: Windows\",\n         \"Operating System :: MacOS\",\n         \"Intended Audience :: Science/Research\",\n         \"Topic :: Scientific/Engineering\",\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6edbda4fe05b7c79a03f6982c5d9fea5fe4de1e7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 6 | Files Changed: 2 | Hunks: 7 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 13 | Churn Cumulative: 327 | Contributors (this commit): 2 | Commits (past 90d): 7 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -113,7 +113,7 @@ def train(model, train_loader, num_epochs, optimizer, loss_fn):\n \n def setup(current_gpu_index, num_gpu):\n     # Device setup\n-    os.environ[\"MASTER_ADDR\"] = \"keras-core-torch\"\n+    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n     os.environ[\"MASTER_PORT\"] = \"56492\"\n     device = torch.device(\"cuda:{}\".format(current_gpu_index))\n     dist.init_process_group(\n\n@@ -52,7 +52,7 @@ import keras_core as keras\n def get_model():\n     # Make a simple convnet with batch normalization and dropout.\n     inputs = keras.Input(shape=(28, 28, 1))\n-    x = keras.layers.Rescaling(1.0 / 255.0)(x)\n+    x = keras.layers.Rescaling(1.0 / 255.0)(inputs)\n     x = keras.layers.Conv2D(\n         filters=12, kernel_size=3, padding=\"same\", use_bias=False\n     )(x)\n@@ -172,7 +172,7 @@ Here's how it works:\n - We use `torch.multiprocessing.spawn` to spawn multiple Python processes, one\n per device. Each process will run the `per_device_launch_fn` function.\n - The `per_device_launch_fn` function does the following:\n-    - It uses `torch.distributed.dist.init_process_group` and `torch.cuda.set_device`\n+    - It uses `torch.distributed.init_process_group` and `torch.cuda.set_device`\n     to configure the device to be used for that process.\n     - It uses `torch.utils.data.distributed.DistributedSampler`\n     and `torch.utils.data.DataLoader` to turn our data into a distributed data loader.\n@@ -194,10 +194,10 @@ print(f\"Running on {num_gpu} GPUs\")\n \n def setup_device(current_gpu_index, num_gpus):\n     # Device setup\n-    os.environ[\"MASTER_ADDR\"] = \"keras-core-torch\"\n+    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n     os.environ[\"MASTER_PORT\"] = \"56492\"\n     device = torch.device(\"cuda:{}\".format(current_gpu_index))\n-    torch.distributed.dist.init_process_group(\n+    torch.distributed.init_process_group(\n         backend=\"nccl\",\n         init_method=\"env://\",\n         world_size=num_gpus,\n@@ -207,7 +207,7 @@ def setup_device(current_gpu_index, num_gpus):\n \n \n def cleanup():\n-    torch.distributed.dist.dist.destroy_process_group()\n+    torch.distributed.destroy_process_group()\n \n \n def prepare_dataloader(dataset, current_gpu_index, num_gpus, batch_size):\n@@ -259,6 +259,7 @@ def per_device_launch_fn(current_gpu_index, num_gpu):\n Time to spawn:\n \"\"\"\n \n+if __name__ == '__main__':\n     torch.multiprocessing.spawn(\n         per_device_launch_fn,\n         args=(num_gpu,),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#76a225d370ede8e998fd99b422e381d94b85aec7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 207 | Lines Deleted: 13 | Files Changed: 9 | Hunks: 30 | Methods Changed: 25 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 220 | Churn Cumulative: 4232 | Contributors (this commit): 12 | Commits (past 90d): 190 | Contributors (cumulative): 30 | DMM Complexity: 1.0\n\nDIFF:\n@@ -113,7 +113,7 @@ def train(model, train_loader, num_epochs, optimizer, loss_fn):\n \n def setup(current_gpu_index, num_gpu):\n     # Device setup\n-    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n+    os.environ[\"MASTER_ADDR\"] = \"keras-core-torch\"\n     os.environ[\"MASTER_PORT\"] = \"56492\"\n     device = torch.device(\"cuda:{}\".format(current_gpu_index))\n     dist.init_process_group(\n\n@@ -52,7 +52,7 @@ import keras_core as keras\n def get_model():\n     # Make a simple convnet with batch normalization and dropout.\n     inputs = keras.Input(shape=(28, 28, 1))\n-    x = keras.layers.Rescaling(1.0 / 255.0)(inputs)\n+    x = keras.layers.Rescaling(1.0 / 255.0)(x)\n     x = keras.layers.Conv2D(\n         filters=12, kernel_size=3, padding=\"same\", use_bias=False\n     )(x)\n@@ -172,7 +172,7 @@ Here's how it works:\n - We use `torch.multiprocessing.spawn` to spawn multiple Python processes, one\n per device. Each process will run the `per_device_launch_fn` function.\n - The `per_device_launch_fn` function does the following:\n-    - It uses `torch.distributed.init_process_group` and `torch.cuda.set_device`\n+    - It uses `torch.distributed.dist.init_process_group` and `torch.cuda.set_device`\n     to configure the device to be used for that process.\n     - It uses `torch.utils.data.distributed.DistributedSampler`\n     and `torch.utils.data.DataLoader` to turn our data into a distributed data loader.\n@@ -194,10 +194,10 @@ print(f\"Running on {num_gpu} GPUs\")\n \n def setup_device(current_gpu_index, num_gpus):\n     # Device setup\n-    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n+    os.environ[\"MASTER_ADDR\"] = \"keras-core-torch\"\n     os.environ[\"MASTER_PORT\"] = \"56492\"\n     device = torch.device(\"cuda:{}\".format(current_gpu_index))\n-    torch.distributed.init_process_group(\n+    torch.distributed.dist.init_process_group(\n         backend=\"nccl\",\n         init_method=\"env://\",\n         world_size=num_gpus,\n@@ -207,7 +207,7 @@ def setup_device(current_gpu_index, num_gpus):\n \n \n def cleanup():\n-    torch.distributed.destroy_process_group()\n+    torch.distributed.dist.dist.destroy_process_group()\n \n \n def prepare_dataloader(dataset, current_gpu_index, num_gpus, batch_size):\n@@ -259,7 +259,6 @@ def per_device_launch_fn(current_gpu_index, num_gpu):\n Time to spawn:\n \"\"\"\n \n-if __name__ == '__main__':\n torch.multiprocessing.spawn(\n     per_device_launch_fn,\n     args=(num_gpu,),\n\n@@ -390,11 +390,51 @@ class Layer(BackendLayer, Operation):\n         self._track_variable(variable)\n         return variable\n \n-    def add_weight(self, *args, **kwargs):\n-        return self.add_variable(*args, **kwargs)\n+    def add_weight(\n+        self,\n+        shape,\n+        initializer,\n+        dtype=None,\n+        trainable=True,\n+        regularizer=None,\n+        constraint=None,\n+        name=None,\n+    ):\n+        \"\"\"Add a weight variable to the layer.\n+\n+        Alias of `add_variable()`.\n+\n+        Args:\n+            shape: Shape tuple for the variable.\n+                Must be fully-defined (no `None` entries).\n+            initializer: Initializer object to use to\n+                populate the initial variable value,\n+                or string name of a built-in initializer\n+                (e.g. `\"random_normal\"`).\n+            dtype: Dtype of the variable to create,\n+                e.g. `\"float32\"`.\n+            trainable: Boolean, whether the variable should\n+                be trainable via backprop or whether its\n+                updates are managed manually.\n+            constraint: Contrainst object to call on the\n+                variable after any optimizer update,\n+                or string name of a built-in constraint.\n+            name: String name of the variable. Useful\n+                for debugging purposes.\n+        \"\"\"\n+        return self.add_variable(\n+            shape=shape,\n+            initializer=initializer,\n+            dtype=dtype,\n+            trainable=trainable,\n+            regularizer=regularizer,\n+            constraint=constraint,\n+            name=name,\n+        )\n \n     @property\n     def trainable(self):\n+        \"\"\"Settable boolean, whether this layer should be trainable or not.\"\"\"\n         return self._trainable\n \n     @trainable.setter\n@@ -453,6 +493,7 @@ class Layer(BackendLayer, Operation):\n \n     @property\n     def weights(self):\n+        \"\"\"List of weight variables of the layer.\"\"\"\n         # Return only \"own weights\" of all Layers, recursively.\n         # Also deduplicate them.\n         weights = []\n@@ -470,20 +511,32 @@ class Layer(BackendLayer, Operation):\n \n     @property\n     def trainable_weights(self):\n+        \"\"\"List of trainable weight variables of the layer.\n+\n+        These are the weights that get updated by the optimizer\n+        during training.\n+        \"\"\"\n         if not self.trainable:\n             return []\n         return [v for v in self.weights if v.trainable]\n \n     @property\n     def non_trainable_weights(self):\n+        \"\"\"List of non-trainable weight variables of the layer.\n+\n+        Non-trainable weights may include batch normalization statistics,\n+        metric variables, or RNG seed variables.\n+        \"\"\"\n         if not self.trainable:\n             return self.weights\n         return [v for v in self.weights if not v.trainable]\n \n     def get_weights(self):\n+        \"\"\"Return the values of `layer.weights` as a list of NumPy arrays.\"\"\"\n         return [v.numpy() for v in self.weights]\n \n     def set_weights(self, weights):\n+        \"\"\"Sets the values of `layer.weights` from a list of NumPy arrays.\"\"\"\n         layer_weights = self.weights\n         if len(layer_weights) != len(weights):\n             raise ValueError(\n@@ -832,6 +885,18 @@ class Layer(BackendLayer, Operation):\n         return NotImplementedError\n \n     def add_loss(self, loss):\n+        \"\"\"Can be called inside of the `call()` method to add a scalar loss.\n+\n+        Example:\n+\n+        ```python\n+        class MyLayer(Layer):\n+            ...\n+            def call(self, x):\n+                self.add_loss(ops.sum(x))\n+                return x\n+        ```\n+        \"\"\"\n         # Eager only.\n         losses = nest.flatten(loss)\n         for x in losses:\n@@ -862,6 +927,7 @@ class Layer(BackendLayer, Operation):\n \n     @property\n     def losses(self):\n+        \"\"\"List of scalar losses added via `add_loss()` during layer call.\"\"\"\n         losses = self._get_own_losses()\n         for layer in self._layers:\n             losses.extend(layer._get_own_losses())\n\n@@ -5,6 +5,48 @@ from keras_core.backend.common import global_state\n \n @keras_core_export(\"keras_core.mixed_precision.DTypePolicy\")\n class DTypePolicy:\n+    \"\"\"A dtype policy for a Keras layer.\n+\n+    A dtype policy determines a layer's computation and variable dtypes. Each\n+    layer has a policy. Policies can be passed to the `dtype` argument of layer\n+    constructors, or a global policy can be set with\n+    `keras_core.mixed_precision.set_dtype_policy`.\n+\n+    Args:\n+        name: The policy name, which determines the compute and variable dtypes.\n+            Can be any dtype name, such as `\"float32\"` or `\"float64\"`,\n+            which causes both the compute and variable dtypes\n+            will be that dtype.\n+            Can also be the string `\"mixed_float16\"` or `\"mixed_bfloat16\"`,\n+            which causes the compute dtype to be `float16` or `bfloat16`\n+            and the variable dtype to be `float32`.\n+\n+    Typically you only need to interact with dtype policies when using mixed\n+    precision, which is the use of float16 or bfloat16 for computations and\n+    float32 for variables. This is why the term `mixed_precision` appears in the\n+    API name. Mixed precision can be enabled by passing `\"mixed_float16\"` or\n+    `\"mixed_bfloat16\"` to `keras_core.mixed_precision.set_dtype_policy()`.\n+\n+    >>> keras_core.mixed_precision.set_dtype_policy(\"mixed_float16\")\n+    >>> layer1 = keras_core.layers.Dense(10)\n+    >>> layer1.dtype_policy  # layer1 will automatically use mixed precision\n+    <DTypePolicy \"mixed_float16\">\n+    >>> # Can optionally override layer to use float32\n+    >>> # instead of mixed precision.\n+    >>> layer2 = keras_core.layers.Dense(10, dtype=\"float32\")\n+    >>> layer2.dtype_policy\n+    <DTypePolicy \"float32\">\n+    >>> # Set policy back to initial float32.\n+    >>> keras_core.mixed_precision.set_dtype_policy('float32')\n+\n+    In the example above, passing `dtype=\"float32\"` to the layer is\n+    equivalent to passing\n+    `dtype=keras_core.mixed_precision.DTypePolicy(\"float32\")`.\n+    In general, passing a dtype policy name to a layer is equivalent\n+    to passing the corresponding policy, so it is never necessary\n+    to explicitly construct a `DTypePolicy` object.\n+    \"\"\"\n+\n     def __init__(self, name):\n         if not isinstance(name, str):\n             raise TypeError(\n@@ -100,6 +142,12 @@ class DTypePolicy:\n     ]\n )\n def set_dtype_policy(policy):\n+    \"\"\"Sets the default dtype policy globally.\n+\n+    Example:\n+\n+    >>> keras_core.mixed_precision.set_dtype_policy(\"mixed_float16\")\n+    \"\"\"\n     if not isinstance(policy, DTypePolicy):\n         if isinstance(policy, str):\n             policy = DTypePolicy(policy)\n@@ -116,6 +164,7 @@ def set_dtype_policy(policy):\n \n @keras_core_export(\"keras_core.mixed_precision.dtype_policy\")\n def dtype_policy():\n+    \"\"\"Returns the current default dtype policy object.\"\"\"\n     policy = global_state.get_global_setting(\"dtype_policy\", None)\n     if policy is None:\n         policy = DTypePolicy(backend.floatx())\n\n@@ -261,6 +261,43 @@ class Model(Trainer, Layer):\n \n     @traceback_utils.filter_traceback\n     def save(self, filepath, overwrite=True, save_format=\"keras\"):\n+        \"\"\"Saves a model as a `.keras` file.\n+\n+        Args:\n+            filepath: `str` or `pathlib.Path` object.\n+                Path where to save the model. Must end in `.keras`.\n+            overwrite: Whether we should overwrite any existing model\n+                at the target location, or instead ask the user\n+                via an interactive prompt.\n+            save_format: Format to use, as a string. Only the `\"keras\"`\n+                format is supported at this time.\n+\n+        Example:\n+\n+        ```python\n+        model = keras_core.Sequential(\n+            [\n+                keras_core.layers.Dense(5, input_shape=(3,)),\n+                keras_core.layers.Softmax(),\n+            ],\n+        )\n+        model.save(\"model.keras\")\n+        loaded_model = keras_core.saving.load_model(\"model.keras\")\n+        x = keras.random.uniform((10, 3))\n+        assert np.allclose(model.predict(x), loaded_model.predict(x))\n+        ```\n+\n+        Note that `model.save()` is an alias for\n+        `keras_core.saving.save_model()`.\n+\n+        The saved `.keras` file contains:\n+\n+        - The model's configuration (architecture)\n+        - The model's weights\n+        - The model's optimizer's state (if any)\n+\n+        Thus models can be reinstantiated in the exact same state.\n+        \"\"\"\n         if save_format in [\"h5\", \"tf\"]:\n             raise ValueError(\n                 \"`'h5'` and `'t5'` formats are no longer supported via the \"\n@@ -289,6 +326,15 @@ class Model(Trainer, Layer):\n \n     @traceback_utils.filter_traceback\n     def save_weights(self, filepath, overwrite=True):\n+        \"\"\"Saves all layer weights to a `.weights.h5` file.\n+\n+        Args:\n+            filepath: `str` or `pathlib.Path` object.\n+                Path where to save the model. Must end in `.weights.h5`.\n+            overwrite: Whether we should overwrite any existing model\n+                at the target location, or instead ask the user\n+                via an interactive prompt.\n+        \"\"\"\n         if not str(filepath).endswith(\".weights.h5\"):\n             raise ValueError(\n                 \"The filename must end in `.weights.h5`. \"\n@@ -306,6 +352,31 @@ class Model(Trainer, Layer):\n \n     @traceback_utils.filter_traceback\n     def load_weights(self, filepath, skip_mismatch=False, **kwargs):\n+        \"\"\"Load weights from a file saved via `save_weights()`.\n+\n+        Weights are loaded based on the network's\n+        topology. This means the architecture should be the same as when the\n+        weights were saved. Note that layers that don't have weights are not\n+        taken into account in the topological ordering, so adding or removing\n+        layers is fine as long as they don't have weights.\n+\n+        **Partial weight loading**\n+\n+        If you have modified your model, for instance by adding a new layer\n+        (with weights) or by changing the shape of the weights of a layer,\n+        you can choose to ignore errors and continue loading\n+        by setting `skip_mismatch=True`. In this case any layer with\n+        mismatching weights will be skipped. A warning will be displayed\n+        for each skipped layer.\n+\n+        Args:\n+            filepath: String, path to the weights file to load.\n+                It can either be a `.weights.h5` file\n+                or a legacy `.h5` weights file.\n+            skip_mismatch: Boolean, whether to skip loading of layers where\n+                there is a mismatch in the number of weights, or a mismatch in\n+                the shape of the weights.\n+        \"\"\"\n         saving_api.load_weights(\n             self, filepath, skip_mismatch=skip_mismatch, **kwargs\n         )\n\n@@ -68,6 +68,11 @@ class Sequential(Model):\n             self._maybe_rebuild()\n \n     def add(self, layer, rebuild=True):\n+        \"\"\"Adds a layer instance on top of the layer stack.\n+\n+        Args:\n+            layer: layer instance.\n+        \"\"\"\n         # Legacy case: if the first layer has an input_shape arg,\n         # use it to build an InputLayer.\n         if not self._layers:\n@@ -107,6 +112,7 @@ class Sequential(Model):\n             self._functional = None\n \n     def pop(self, rebuild=True):\n+        \"\"\"Removes the last layer in the model.\"\"\"\n         layer = self._layers.pop()\n         self.built = False\n         self._tracker.locked = False\n\n@@ -124,10 +124,7 @@ class Operation:\n         \"\"\"Returns the config of the object.\n \n         An object config is a Python dictionary (serializable)\n-        containing the information needed to re-insstantiate it.\n-\n-        Returns:\n-            Python dictionary.\n+        containing the information needed to re-instantiate it.\n         \"\"\"\n         config = {\n             \"name\": self.name,\n\n@@ -2,6 +2,7 @@ import inspect\n import os\n import traceback\n import types\n+from functools import wraps\n \n from tensorflow import errors as tf_errors\n from tensorflow import nest\n@@ -108,6 +109,7 @@ def _process_traceback_frames(tb):\n def filter_traceback(fn):\n     \"\"\"Filter out Keras-internal traceback frames in exceptions raised by fn.\"\"\"\n \n+    @wraps(fn)\n     def error_handler(*args, **kwargs):\n         if not is_traceback_filtering_enabled():\n             return fn(*args, **kwargs)\n@@ -141,6 +143,7 @@ def inject_argument_info_in_traceback(fn, object_name=None):\n         A wrapped version of `fn`.\n     \"\"\"\n \n+    @wraps(fn)\n     def error_handler(*args, **kwargs):\n         if not is_traceback_filtering_enabled():\n             return fn(*args, **kwargs)\n\n@@ -1,3 +1,5 @@\n+from functools import wraps\n+\n from keras_core.backend.common.global_state import get_global_attribute\n from keras_core.backend.common.global_state import set_global_attribute\n \n@@ -16,6 +18,7 @@ def is_tracking_enabled():\n \n \n def no_automatic_dependency_tracking(fn):\n+    @wraps(fn)\n     def wrapper(*args, **kwargs):\n         with DotNotTrackScope():\n             return fn(*args, **kwargs)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#46b8fd2d6df3b38ad1c4f38875998f428d81b868", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 6 | Files Changed: 2 | Hunks: 7 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 13 | Churn Cumulative: 353 | Contributors (this commit): 2 | Commits (past 90d): 11 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -113,7 +113,7 @@ def train(model, train_loader, num_epochs, optimizer, loss_fn):\n \n def setup(current_gpu_index, num_gpu):\n     # Device setup\n-    os.environ[\"MASTER_ADDR\"] = \"keras-core-torch\"\n+    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n     os.environ[\"MASTER_PORT\"] = \"56492\"\n     device = torch.device(\"cuda:{}\".format(current_gpu_index))\n     dist.init_process_group(\n\n@@ -52,7 +52,7 @@ import keras_core as keras\n def get_model():\n     # Make a simple convnet with batch normalization and dropout.\n     inputs = keras.Input(shape=(28, 28, 1))\n-    x = keras.layers.Rescaling(1.0 / 255.0)(x)\n+    x = keras.layers.Rescaling(1.0 / 255.0)(inputs)\n     x = keras.layers.Conv2D(\n         filters=12, kernel_size=3, padding=\"same\", use_bias=False\n     )(x)\n@@ -172,7 +172,7 @@ Here's how it works:\n - We use `torch.multiprocessing.spawn` to spawn multiple Python processes, one\n per device. Each process will run the `per_device_launch_fn` function.\n - The `per_device_launch_fn` function does the following:\n-    - It uses `torch.distributed.dist.init_process_group` and `torch.cuda.set_device`\n+    - It uses `torch.distributed.init_process_group` and `torch.cuda.set_device`\n     to configure the device to be used for that process.\n     - It uses `torch.utils.data.distributed.DistributedSampler`\n     and `torch.utils.data.DataLoader` to turn our data into a distributed data loader.\n@@ -194,10 +194,10 @@ print(f\"Running on {num_gpu} GPUs\")\n \n def setup_device(current_gpu_index, num_gpus):\n     # Device setup\n-    os.environ[\"MASTER_ADDR\"] = \"keras-core-torch\"\n+    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n     os.environ[\"MASTER_PORT\"] = \"56492\"\n     device = torch.device(\"cuda:{}\".format(current_gpu_index))\n-    torch.distributed.dist.init_process_group(\n+    torch.distributed.init_process_group(\n         backend=\"nccl\",\n         init_method=\"env://\",\n         world_size=num_gpus,\n@@ -207,7 +207,7 @@ def setup_device(current_gpu_index, num_gpus):\n \n \n def cleanup():\n-    torch.distributed.dist.dist.destroy_process_group()\n+    torch.distributed.destroy_process_group()\n \n \n def prepare_dataloader(dataset, current_gpu_index, num_gpus, batch_size):\n@@ -259,6 +259,7 @@ def per_device_launch_fn(current_gpu_index, num_gpu):\n Time to spawn:\n \"\"\"\n \n+if __name__ == '__main__':\n     torch.multiprocessing.spawn(\n         per_device_launch_fn,\n         args=(num_gpu,),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2abd396a240bed83ccfa747a1581838cbe28e222", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 49 | Lines Deleted: 21 | Files Changed: 4 | Hunks: 17 | Methods Changed: 9 | Complexity Δ (Sum/Max): 5/5 | Churn Δ: 70 | Churn Cumulative: 500 | Contributors (this commit): 5 | Commits (past 90d): 20 | Contributors (cumulative): 9 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,6 +1,6 @@\n-from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.layers.preprocessing.tf_data_layer import TFDataLayer\n+from keras_core.random.seed_generator import SeedGenerator\n \n \n @keras_core_export(\"keras_core.layers.RandomBrightness\")\n@@ -75,7 +75,7 @@ class RandomBrightness(TFDataLayer):\n         self._set_factor(factor)\n         self._set_value_range(value_range)\n         self.seed = seed\n-        self.generator = backend.random.SeedGenerator(seed)\n+        self.generator = SeedGenerator(seed)\n \n     def _set_value_range(self, value_range):\n         if not isinstance(value_range, (tuple, list)):\n@@ -136,11 +136,7 @@ class RandomBrightness(TFDataLayer):\n                 f\"inputs.shape={images.shape}\"\n             )\n \n-        if backend.backend() != self.backend._backend:\n-            seed_generator = self.backend.random.SeedGenerator(self.seed)\n-        else:\n-            seed_generator = self.generator\n-\n+        seed_generator = self._get_seed_generator(self.backend._backend)\n         rgb_delta = self.backend.random.uniform(\n             minval=self._factor[0],\n             maxval=self._factor[1],\n\n@@ -1,6 +1,6 @@\n-from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.layers.preprocessing.tf_data_layer import TFDataLayer\n+from keras_core.random.seed_generator import SeedGenerator\n \n \n @keras_core_export(\"keras_core.layers.RandomContrast\")\n@@ -56,15 +56,12 @@ class RandomContrast(TFDataLayer):\n                 f\"Received: factor={factor}\"\n             )\n         self.seed = seed\n-        self.generator = backend.random.SeedGenerator(seed)\n+        self.generator = SeedGenerator(seed)\n \n     def call(self, inputs, training=True):\n         inputs = self.backend.cast(inputs, self.compute_dtype)\n         if training:\n-            if backend.backend() != self.backend._backend:\n-                seed_generator = self.backend.random.SeedGenerator(self.seed)\n-            else:\n-                seed_generator = self.generator\n+            seed_generator = self._get_seed_generator(self.backend._backend)\n             factor = self.backend.random.uniform(\n                 shape=(),\n                 minval=1.0 - self.lower,\n\n@@ -2,7 +2,9 @@ from tensorflow import nest\n \n from keras_core import backend\n from keras_core.layers.layer import Layer\n+from keras_core.random.seed_generator import SeedGenerator\n from keras_core.utils import backend_utils\n+from keras_core.utils import tracking\n \n \n class TFDataLayer(Layer):\n@@ -42,3 +44,15 @@ class TFDataLayer(Layer):\n                     self._convert_input_args = True\n             return outputs\n         return super().__call__(inputs, **kwargs)\n+\n+    @tracking.no_automatic_dependency_tracking\n+    def _get_seed_generator(self, backend=None):\n+        if backend is None or backend == self.backend._backend:\n+            return self.generator\n+        if not hasattr(self, \"_backend_generators\"):\n+            self._backend_generators = {}\n+        if backend in self._backend_generators:\n+            return self._backend_generators[backend]\n+        seed_generator = SeedGenerator(self.seed, backend=self.backend)\n+        self._backend_generators[backend] = seed_generator\n+        return seed_generator\n\n@@ -2,14 +2,37 @@ import random as python_random\n \n import numpy as np\n \n-from keras_core import backend\n from keras_core.api_export import keras_core_export\n \n \n @keras_core_export(\"keras_core.random.SeedGenerator\")\n class SeedGenerator:\n-    def __init__(self, seed):\n-        from keras_core.backend import Variable\n+    \"\"\"Generates variable seeds upon each call to a RNG-using function.\n+\n+    In Keras, all RNG-using methods (such as `keras_core.random.normal()`)\n+    are stateless, meaning that if you pass an integer seed to them\n+    (such as `seed=42`), they will return the same values at each call.\n+    In order to get different values at each call, you must use a\n+    `SeedGenerator` instead as the seed argument. The `SeedGenerator`\n+    instead is stateful.\n+\n+    Example:\n+\n+    ```python\n+    seed_gen = keras_core.random.SeedGenerator(seed=42)\n+    values = keras_core.random.normal(shape=(2, 3), seed=seed_gen)\n+    new_values = keras_core.random.normal(shape=(2, 3), seed=seed_gen)\n+    ```\n+    \"\"\"\n+\n+    def __init__(self, seed, **kwargs):\n+        custom_backend = kwargs.pop(\"backend\", None)\n+        if kwargs:\n+            raise ValueError(f\"Unrecognized keyword arguments: {kwargs}\")\n+        if custom_backend is not None:\n+            backend = custom_backend\n+        else:\n+            from keras_core import backend\n \n         if seed is None:\n             seed = make_default_seed()\n@@ -19,12 +42,10 @@ class SeedGenerator:\n             )\n \n         def seed_initializer(*args, **kwargs):\n-            from keras_core.backend import convert_to_tensor\n-\n             dtype = kwargs.get(\"dtype\", None)\n-            return convert_to_tensor([seed, 0], dtype=dtype)\n+            return backend.convert_to_tensor([seed, 0], dtype=dtype)\n \n-        self.state = Variable(\n+        self.state = backend.Variable(\n             seed_initializer,\n             shape=(2,),\n             dtype=\"uint32\",\n@@ -44,7 +65,7 @@ def draw_seed(seed):\n         seed_state = seed.state\n         # Use * 1 to create a copy\n         new_seed_value = seed_state.value * 1\n-        increment = backend.convert_to_tensor(np.array([0, 1]), dtype=\"uint32\")\n+        increment = convert_to_tensor(np.array([0, 1]), dtype=\"uint32\")\n         seed.state.assign(seed_state + increment)\n         return new_seed_value\n     elif isinstance(seed, int):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
