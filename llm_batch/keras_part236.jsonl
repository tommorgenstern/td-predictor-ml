{"custom_id": "keras#d79200a51710a23cc47b4ca5ad3f8df7c32f4eae", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 42 | Lines Deleted: 41 | Files Changed: 1 | Hunks: 11 | Methods Changed: 10 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 83 | Churn Cumulative: 3462 | Contributors (this commit): 21 | Commits (past 90d): 14 | Contributors (cumulative): 21 | DMM Complexity: 1.0\n\nDIFF:\n@@ -227,21 +227,21 @@ class TestBackend(object):\n                                       mean=0., scale=1.,\n                                       shape_or_val=False, assert_value_equality=False)\n \n-    @pytest.mark.parametrize('k', [KTF], ids=['TensorFlow'])\n-    def test_batch_dot_shape(self, k):\n-        x_batch = k.ones(shape=(32, 20))\n-        y_batch = k.ones(shape=(32, 20))\n-        xy_batch_dot = k.batch_dot(x_batch, y_batch, axes=1)\n-        assert_allclose(k.eval(xy_batch_dot), np.ones((32, 1)) * 20, atol=1e-05)\n-        xy_batch_dot = k.batch_dot(x_batch, y_batch, axes=0)\n-        assert_allclose(k.eval(xy_batch_dot), np.ones((20, 1)) * 32, atol=1e-05)\n+    @pytest.mark.skipif(K.backend() != 'tensorflow', reason='Not supported.')\n+    def test_batch_dot_shape(self):\n+        x_batch = K.ones(shape=(32, 20))\n+        y_batch = K.ones(shape=(32, 20))\n+        xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=1)\n+        assert_allclose(K.eval(xy_batch_dot), np.ones((32, 1)) * 20, atol=1e-05)\n+        xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=0)\n+        assert_allclose(K.eval(xy_batch_dot), np.ones((20, 1)) * 32, atol=1e-05)\n         # making sure swapping axes when ndim == 2 works\n-        x_batch = k.ones(shape=(32, 20))\n-        y_batch = k.ones(shape=(20, 32))\n-        xy_batch_dot = k.batch_dot(x_batch, y_batch, axes=(0, 1))\n-        assert_allclose(k.eval(xy_batch_dot), np.ones((20, 1)) * 32, atol=1e-05)\n-        xy_batch_dot = k.batch_dot(x_batch, y_batch, axes=(1, 0))\n-        assert_allclose(k.eval(xy_batch_dot), np.ones((32, 1)) * 20, atol=1e-05)\n+        x_batch = K.ones(shape=(32, 20))\n+        y_batch = K.ones(shape=(20, 32))\n+        xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=(0, 1))\n+        assert_allclose(K.eval(xy_batch_dot), np.ones((20, 1)) * 32, atol=1e-05)\n+        xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=(1, 0))\n+        assert_allclose(K.eval(xy_batch_dot), np.ones((32, 1)) * 20, atol=1e-05)\n \n     def test_shape_operations(self):\n         check_two_tensor_operation('concatenate', (4, 3), (4, 2), BACKENDS,\n@@ -1125,11 +1125,12 @@ class TestBackend(object):\n     # numerical stability.  The Theano code subtracts out the max\n     # before the final log, so the results are different but scale\n     # identically and still train properly\n-    @pytest.mark.parametrize('k,ref', [\n-        (KTF, [3.34211, 5.42262]),\n-        (KTH, [1.73308, 3.81351]),\n-    ], ids=['TensorFlow', 'Theano'])\n-    def test_ctc(self, k, ref):\n+    @pytest.mark.skipif(K.backend() == 'cntk', reason='Not supported.')\n+    def test_ctc(self):\n+        if K.backend() == 'theano':\n+            ref = [1.73308, 3.81351]\n+        else:\n+            ref = [3.34211, 5.42262]\n         # simplified version of TensorFlow's test\n \n         label_lens = np.expand_dims(np.asarray([5, 4]), 1)\n@@ -1150,12 +1151,12 @@ class TestBackend(object):\n               [0.423286, 0.315517, 0.0338439, 0.0393744, 0.0339315, 0.154046]]],\n             dtype=np.float32)\n \n-        k_labels = k.variable(labels, dtype=\"int32\")\n-        k_inputs = k.variable(inputs, dtype=\"float32\")\n-        k_input_lens = k.variable(input_lens, dtype=\"int32\")\n-        k_label_lens = k.variable(label_lens, dtype=\"int32\")\n-        res = k.eval(k.ctc_batch_cost(k_labels, k_inputs, k_input_lens, k_label_lens))\n-        assert_allclose(res[:, 0] if k == KTF else res[0, :], ref, atol=1e-05)\n+        k_labels = K.variable(labels, dtype=\"int32\")\n+        k_inputs = K.variable(inputs, dtype=\"float32\")\n+        k_input_lens = K.variable(input_lens, dtype=\"int32\")\n+        k_label_lens = K.variable(label_lens, dtype=\"int32\")\n+        res = K.eval(K.ctc_batch_cost(k_labels, k_inputs, k_input_lens, k_label_lens))\n+        assert_allclose(res[0, :] if K.backend() == 'theano' else res[:, 0], ref, atol=1e-05)\n \n     '''only tensorflow tested, need special handle'''\n \n@@ -1337,17 +1338,17 @@ class TestBackend(object):\n             assert k_s_d.shape == k_d.shape\n             assert_allclose(k_s_d, k_d, atol=1e-05)\n \n-    @pytest.mark.parametrize('k', [KTH, KTF], ids=['Theano', 'TensorFlow'])\n-    def test_map(self, k):\n+    @pytest.mark.skipif(K.backend() == 'cntk', reason='Not supported.')\n+    def test_map(self):\n         x = np.random.rand(10, 3).astype(np.float32)\n-        vx = k.variable(x)\n-        kx = k.eval(k.map_fn(k.sum, vx))\n+        vx = K.variable(x)\n+        kx = K.eval(K.map_fn(K.sum, vx))\n         # make sure we can also walk the indexes in tensorflow which we\n         # can't without specifying dtype\n-        kx2 = k.eval(k.map_fn(\n-            lambda i: k.sum(vx[i]),\n-            k.arange(10),\n-            dtype=k.floatx()\n+        kx2 = K.eval(K.map_fn(\n+            lambda i: K.sum(vx[i]),\n+            K.arange(10),\n+            dtype=K.floatx()\n         ))\n \n         assert (10,) == kx.shape\n@@ -1355,24 +1356,24 @@ class TestBackend(object):\n         assert_allclose(x.sum(axis=1), kx, atol=1e-05)\n         assert_allclose(kx, kx2, atol=1e-05)\n \n-    @pytest.mark.parametrize('k', [KTH, KTF], ids=['Theano', 'TensorFlow'])\n-    def test_foldl(self, k):\n+    @pytest.mark.skipif(K.backend() == 'cntk', reason='Not supported.')\n+    def test_foldl(self):\n         x = np.random.rand(10, 3).astype(np.float32)\n-        kx = k.eval(k.foldl(lambda a, b: a + b, k.variable(x)))\n+        kx = K.eval(K.foldl(lambda a, b: a + b, K.variable(x)))\n \n         assert (3,) == kx.shape\n         assert_allclose(x.sum(axis=0), kx, atol=1e-05)\n \n-    @pytest.mark.parametrize('k', [KTH, KTF], ids=['Theano', 'TensorFlow'])\n-    def test_foldr(self, k):\n+    @pytest.mark.skipif(K.backend() == 'cntk', reason='Not supported.')\n+    def test_foldr(self):\n         # This test aims to make sure that we walk the array from right to left\n         # and checks it in the following way: multiplying left to right 1e-40\n         # cannot be held into a float32 so it causes an underflow while from\n         # right to left we have no such problem and the result is larger\n         x = np.array([1e-20, 1e-20, 10, 10, 10], dtype=np.float32)\n-        vx = k.variable(x)\n-        p1 = k.eval(k.foldl(lambda a, b: a * b, vx))\n-        p2 = k.eval(k.foldr(lambda a, b: a * b, vx))\n+        vx = K.variable(x)\n+        p1 = K.eval(K.foldl(lambda a, b: a * b, vx))\n+        p2 = K.eval(K.foldr(lambda a, b: a * b, vx))\n \n         assert p1 < p2\n         assert 9e-38 < p2 <= 1e-37\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5c5c1b58ec49e4499be07538bec24e6e74637760", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 8821 | Contributors (this commit): 59 | Commits (past 90d): 18 | Contributors (cumulative): 59 | DMM Complexity: None\n\nDIFF:\n@@ -1855,6 +1855,8 @@ class Container(Layer):\n     def get_layer(self, name=None, index=None):\n         \"\"\"Retrieves a layer based on either its name (unique) or index.\n         \n+        If `name` and `index` are both provided, `index` will take precedence.\n+\n         Indices are based on order of horizontal graph traversal (bottom-up).\n \n         # Arguments\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#98ffe08a03ebcd5140112c4fdf844b1f4b7e711d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 41 | Contributors (this commit): 4 | Commits (past 90d): 2 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -22,4 +22,4 @@ from .layer_utils import print_summary\n from .vis_utils import plot_model\n from .np_utils import to_categorical\n from .np_utils import normalize\n-from .training_utils import multi_gpu_model\n+from .multi_gpu_utils import multi_gpu_model\n\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#500401bac7dfbb922408de79a1e217856cc7c627", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 228 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -44,8 +44,8 @@ def softmax(x, axis=-1):\n # define the margin loss like hinge loss\n def margin_loss(y_true, y_pred):\n     lamb, margin = 0.5, 0.1\n-    return y_true * K.square(K.relu(1 - margin - y_pred)) + lamb * (\n-        1 - y_true) * K.square(K.relu(y_pred - margin))\n+    return K.sum(y_true * K.square(K.relu(1 - margin - y_pred)) + lamb * (\n+        1 - y_true) * K.square(K.relu(y_pred - margin)), axis=-1)\n \n \n class Capsule(Layer):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ca27e445a15fba61401b2ee23765349515d3f28d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 8 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 16 | Churn Cumulative: 492 | Contributors (this commit): 12 | Commits (past 90d): 1 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -5,7 +5,7 @@ Input: \"535+61\"\n Output: \"596\"\n Padding is handled by using a repeated sentinel character (space)\n \n-Input may optionally be inverted, shown to increase performance in many tasks in:\n+Input may optionally be reversed, shown to increase performance in many tasks in:\n \"Learning to Execute\"\n http://arxiv.org/abs/1410.4615\n and\n@@ -13,16 +13,16 @@ and\n http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\n Theoretically it introduces shorter term dependencies between source and target.\n \n-Two digits inverted:\n+Two digits reversed:\n + One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\n \n-Three digits inverted:\n+Three digits reversed:\n + One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\n \n-Four digits inverted:\n+Four digits reversed:\n + One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\n \n-Five digits inverted:\n+Five digits reversed:\n + One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs\n '''\n \n@@ -75,7 +75,7 @@ class colors:\n # Parameters for the model and dataset.\n TRAINING_SIZE = 50000\n DIGITS = 3\n-INVERT = True\n+REVERSE = True\n \n # Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n # int is DIGITS.\n@@ -105,7 +105,7 @@ while len(questions) < TRAINING_SIZE:\n     ans = str(a + b)\n     # Answers can be of maximum size DIGITS + 1.\n     ans += ' ' * (DIGITS + 1 - len(ans))\n-    if INVERT:\n+    if REVERSE:\n         # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n         # space used for padding.)\n         query = query[::-1]\n@@ -193,7 +193,7 @@ for iteration in range(1, 200):\n         q = ctable.decode(rowx[0])\n         correct = ctable.decode(rowy[0])\n         guess = ctable.decode(preds[0], calc_argmax=False)\n-        print('Q', q[::-1] if INVERT else q, end=' ')\n+        print('Q', q[::-1] if REVERSE else q, end=' ')\n         print('T', correct, end=' ')\n         if correct == guess:\n             print(colors.ok + '☑' + colors.close, end=' ')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#eb97bc385599dec8182963fe263bd958b9ab0057", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 77 | Lines Deleted: 55 | Files Changed: 2 | Hunks: 20 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 132 | Churn Cumulative: 16545 | Contributors (this commit): 143 | Commits (past 90d): 44 | Contributors (cumulative): 168 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1962,7 +1962,7 @@ class Model(Container):\n                       use_multiprocessing=False,\n                       shuffle=True,\n                       initial_epoch=0):\n-        \"\"\"Trains the model on data yielded batch-by-batch by a Python generator.\n+        \"\"\"Trains the model on data generated batch-by-batch by a Python generator or an instance of `Sequence`.\n \n         The generator is run in parallel to the model, for efficiency.\n         For instance, this allows you to do real-time data augmentation\n@@ -1981,10 +1981,10 @@ class Model(Container):\n                 - a tuple `(inputs, targets, sample_weights)`.\n                 This tuple (a single output of the generator) makes a single\n                 batch. Therefore, all arrays in this tuple must have the same\n-                length (equal to the size of this batch). Different batches\n-                may have different sizes. For example, the last batch of the\n-                epoch is commonly smaller than the others, if the size of the\n-                dataset is not divisible by the batch size.\n+                length (equal to the size of this batch). Different batches may\n+                have different sizes. For example, the last batch of the epoch\n+                is commonly smaller than the others, if the size of the dataset\n+                is not divisible by the batch size.\n                 The generator is expected to loop over its data\n                 indefinitely. An epoch finishes when `steps_per_epoch`\n                 batches have been seen by the model.\n@@ -2018,32 +2018,32 @@ class Model(Container):\n                 The model will not be trained on this data.\n             validation_steps: Only relevant if `validation_data`\n                 is a generator. Total number of steps (batches of samples)\n-                to yield from `validation_data` generator before stopping.\n+                to yield from `validation_data` generator before stopping\n+                at the end of every epoch. It should typically\n+                be equal to the number of samples of your\n+                validation dataset divided by the batch size.\n                 Optional for `Sequence`: if unspecified, will use\n                 the `len(validation_data)` as a number of steps.\n             class_weight: Optional dictionary mapping class indices (integers)\n                 to a weight (float) value, used for weighting the loss function\n-                (during training only).\n-                This can be useful to tell the model to\n-                \"pay more attention\" to samples from\n-                an under-represented class.\n+                (during training only). This can be useful to tell the model to\n+                \"pay more attention\" to samples from an under-represented class.\n             max_queue_size: Integer. Maximum size for the generator queue.\n                 If unspecified, `max_queue_size` will default to 10.\n             workers: Integer. Maximum number of processes to spin up\n-                when using process based threading.\n+                when using process-based threading.\n                 If unspecified, `workers` will default to 1. If 0, will\n                 execute the generator on the main thread.\n-            use_multiprocessing: Boolean. If True, use process based threading.\n-                If unspecified, `use_multiprocessing` will default to False.\n-                Note that because\n-                this implementation relies on multiprocessing,\n-                you should not pass\n-                non picklable arguments to the generator\n-                as they can't be passed\n-                easily to children processes.\n-            shuffle: Boolean. Whether to shuffle the training data\n-                in batch-sized chunks before each epoch.\n-                Only used with instances of `Sequence` (`keras.utils.Sequence`).\n+            use_multiprocessing: Boolean.\n+                If `True`, use process-based threading.\n+                If unspecified, `use_multiprocessing` will default to `False`.\n+                Note that because this implementation relies on multiprocessing,\n+                you should not pass non-picklable arguments to the generator\n+                as they can't be passed easily to children processes.\n+            shuffle: Boolean. Whether to shuffle the order of the batches at\n+                the beginning of each epoch. Only used with instances\n+                of `Sequence` (`keras.utils.Sequence`).\n+                Has no effect when `steps_per_epoch` is not `None`.\n             initial_epoch: Integer.\n                 Epoch at which to start training\n                 (useful for resuming a previous training run).\n@@ -2054,11 +2054,14 @@ class Model(Container):\n             at successive epochs, as well as validation loss values\n             and validation metrics values (if applicable).\n \n+        # Raises\n+            ValueError: In case the generator yields data in an invalid format.\n+\n         # Example\n \n         ```python\n             def generate_arrays_from_file(path):\n-                while 1:\n+                while True:\n                     with open(path) as f:\n                         for line in f:\n                             # create numpy arrays of input data\n@@ -2069,10 +2072,6 @@ class Model(Container):\n             model.fit_generator(generate_arrays_from_file('/my_file.txt'),\n                                 steps_per_epoch=10000, epochs=10)\n         ```\n-\n-        # Raises\n-            ValueError: In case the generator yields\n-                data in an invalid format.\n         \"\"\"\n         wait_time = 0.01  # in seconds\n         epoch = initial_epoch\n\n@@ -1142,7 +1142,8 @@ class Sequential(Model):\n             return (proba > 0.5).astype('int32')\n \n     @interfaces.legacy_generator_methods_support\n-    def fit_generator(self, generator,\n+    def fit_generator(self,\n+                      generator,\n                       steps_per_epoch=None,\n                       epochs=1,\n                       verbose=1,\n@@ -1161,12 +1162,23 @@ class Sequential(Model):\n         For instance, this allows you to do real-time data augmentation\n         on images on CPU in parallel to training your model on GPU.\n \n+        The use of `keras.utils.Sequence` guarantees the ordering\n+        and guarantees the single use of every input per epoch when\n+        using `use_multiprocessing=True`.\n+\n         # Arguments\n-            generator: A generator.\n+            generator: A generator or an instance of `Sequence`\n+                (`keras.utils.Sequence`) object in order to avoid duplicate data\n+                    when using multiprocessing.\n                 The output of the generator must be either\n-                - a tuple (inputs, targets)\n-                - a tuple (inputs, targets, sample_weights).\n-                All arrays should contain the same number of samples.\n+                - a tuple `(inputs, targets)`\n+                - a tuple `(inputs, targets, sample_weights)`.\n+                This tuple (a single output of the generator) makes a single\n+                batch. Therefore, all arrays in this tuple must have the same\n+                length (equal to the size of this batch). Different batches may\n+                have different sizes. For example, the last batch of the epoch\n+                is commonly smaller than the others, if the size of the dataset\n+                is not divisible by the batch size.\n                 The generator is expected to loop over its data\n                 indefinitely. An epoch finishes when `steps_per_epoch`\n                 batches have been seen by the model.\n@@ -1181,36 +1193,46 @@ class Sequential(Model):\n                 Note that in conjunction with initial_epoch, the parameter\n                 epochs is to be understood as \"final epoch\". The model is\n                 not trained for n steps given by epochs, but until the\n-                epoch of index `epochs` is reached.\n-            verbose: Verbosity mode, 0, 1, or 2.\n-            callbacks: List of callbacks to be called during training.\n+                epoch epochs is reached.\n+            verbose: Integer. 0, 1, or 2. Verbosity mode.\n+                0 = silent, 1 = progress bar, 2 = one line per epoch.\n+            callbacks: List of `keras.callbacks.Callback` instances.\n+                List of callbacks to apply during training.\n+                See [callbacks](/callbacks).\n             validation_data: This can be either\n-                - A generator for the validation data\n-                - A tuple (inputs, targets)\n-                - A tuple (inputs, targets, sample_weights).\n+                - a generator for the validation data\n+                - a tuple `(inputs, targets)`\n+                - a tuple `(inputs, targets, sample_weights)`.\n             validation_steps: Only relevant if `validation_data`\n-                is a generator.\n-                Number of steps to yield from validation generator\n+                is a generator. Total number of steps (batches of samples)\n+                to yield from `validation_data` generator before stopping\n                 at the end of every epoch. It should typically\n                 be equal to the number of samples of your\n                 validation dataset divided by the batch size.\n                 Optional for `Sequence`: if unspecified, will use\n                 the `len(validation_data)` as a number of steps.\n-            class_weight: Dictionary mapping class indices to a weight\n-                for the class.\n-            max_queue_size: Maximum size for the generator queue\n-            workers: Maximum number of processes to spin up\n-            use_multiprocessing: if True, use process based threading.\n-                Note that because\n-                this implementation relies on multiprocessing,\n-                you should not pass\n-                non picklable arguments to the generator\n-                as they can't be passed\n-                easily to children processes.\n-            shuffle: Whether to shuffle the order of the batches at\n+            class_weight: Optional dictionary mapping class indices (integers)\n+                to a weight (float) value, used for weighting the loss function\n+                (during training only). This can be useful to tell the model to\n+                \"pay more attention\" to samples from an under-represented class.\n+            max_queue_size: Integer. Maximum size for the generator queue.\n+                If unspecified, `max_queue_size` will default to 10.\n+            workers: Integer. Maximum number of processes to spin up\n+                when using process-based threading.\n+                If unspecified, `workers` will default to 1. If 0, will\n+                execute the generator on the main thread.\n+            use_multiprocessing: Boolean.\n+                If `True`, use process-based threading.\n+                If unspecified, `use_multiprocessing` will default to `False`.\n+                Note that because this implementation relies on multiprocessing,\n+                you should not pass non-picklable arguments to the generator\n+                as they can't be passed easily to children processes.\n+            shuffle: Boolean (whether to shuffle the order of the batches at\n                 the beginning of each epoch. Only used with instances\n-                of `Sequence` (keras.utils.Sequence).\n-            initial_epoch: Epoch at which to start training\n+                of `Sequence` (`keras.utils.Sequence`).\n+                Has no effect when `steps_per_epoch` is not `None`.\n+            initial_epoch: Integer.\n+                Epoch at which to start training\n                 (useful for resuming a previous training run).\n \n         # Returns\n@@ -1218,12 +1240,13 @@ class Sequential(Model):\n \n         # Raises\n             RuntimeError: if the model was never compiled.\n+            ValueError: In case the generator yields data in an invalid format.\n \n         # Example\n \n         ```python\n             def generate_arrays_from_file(path):\n-                while 1:\n+                while True:\n                     with open(path) as f:\n                         for line in f:\n                             # create Numpy arrays of input data\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9118ea65f40874e915dd1299efd1cc3a7ca2c333", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 26 | Files Changed: 2 | Hunks: 6 | Methods Changed: 2 | Complexity Δ (Sum/Max): -4/0 | Churn Δ: 37 | Churn Cumulative: 8133 | Contributors (this commit): 87 | Commits (past 90d): 36 | Contributors (cumulative): 106 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2144,28 +2144,8 @@ class Model(Container):\n         val_enqueuer = None\n \n         try:\n-            if do_validation:\n-                if val_gen:\n-                    if workers > 0:\n-                        if isinstance(validation_data, Sequence):\n-                            val_enqueuer = OrderedEnqueuer(\n-                                validation_data,\n-                                use_multiprocessing=use_multiprocessing)\n-                            if validation_steps is None:\n-                                validation_steps = len(validation_data)\n-                        else:\n-                            val_enqueuer = GeneratorEnqueuer(\n-                                validation_data,\n-                                use_multiprocessing=use_multiprocessing,\n-                                wait_time=wait_time)\n-                        val_enqueuer.start(workers=workers, max_queue_size=max_queue_size)\n-                        validation_generator = val_enqueuer.get()\n-                    else:\n-                        if isinstance(validation_data, Sequence):\n-                            validation_generator = iter(validation_data)\n-                        else:\n-                            validation_generator = validation_data\n-                else:\n+            if do_validation and not val_gen:\n+                # Prepare data for validation\n                 if len(validation_data) == 2:\n                     val_x, val_y = validation_data\n                     val_sample_weight = None\n@@ -2257,9 +2237,11 @@ class Model(Container):\n                     if steps_done >= steps_per_epoch and do_validation:\n                         if val_gen:\n                             val_outs = self.evaluate_generator(\n-                                validation_generator,\n+                                validation_data,\n                                 validation_steps,\n-                                workers=0)\n+                                workers=workers,\n+                                use_multiprocessing=use_multiprocessing,\n+                                max_queue_size=max_queue_size)\n                         else:\n                             # No need for try/except because\n                             # data has already been validated.\n\n@@ -428,7 +428,8 @@ def test_model_methods():\n \n     # Need range check here as filling of the queue depends on sleep in the enqueuers\n     assert 6 <= gen_counters[0] <= 8\n-    assert 3 <= gen_counters[1] <= 5\n+    # 12 = (epoch * workers * validation steps * max_queue_size)\n+    assert 3 <= gen_counters[1] <= 12\n \n     gen_counters = [0]\n     out = model.fit_generator(generator=RandomSequence(3), epochs=3,\n@@ -436,8 +437,10 @@ def test_model_methods():\n                               validation_steps=1,\n                               max_queue_size=2,\n                               workers=2)\n+\n+    # 12 = (epoch * workers * validation steps * max_queue_size)\n     # Need range check here as filling of the queue depends on sleep in the enqueuers\n-    assert 3 <= gen_counters[0] <= 5\n+    assert 3 <= gen_counters[0] <= 12\n \n     # predict_generator output shape behavior should be consistent\n     def expected_shape(batch_size, n_batches):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f47e362a18dee71f31f350a660ed2883699df05a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 79 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 9 | Methods Changed: 10 | Complexity Δ (Sum/Max): 19/19 | Churn Δ: 82 | Churn Cumulative: 3544 | Contributors (this commit): 21 | Commits (past 90d): 14 | Contributors (cumulative): 21 | DMM Complexity: 0.17857142857142858\n\nDIFF:\n@@ -1,6 +1,7 @@\n import pytest\n from numpy.testing import assert_allclose\n import numpy as np\n+import scipy.signal as signal\n import scipy.sparse as sparse\n import warnings\n from keras.utils.test_utils import keras_test\n@@ -99,6 +100,7 @@ def check_single_tensor_operation(function_name, x_shape_or_val, backend_list, *\n     assert_value_equality = kwargs.pop('assert_value_equality', True)\n     assert_value_with_ref = kwargs.pop('assert_value_with_ref', None)\n     cntk_dynamicity = kwargs.pop('cntk_dynamicity', False)\n+    return_results = kwargs.pop('return_results', False)\n \n     if shape_or_val:\n         x_shape, x_val = parse_shape_or_val(x_shape_or_val)\n@@ -115,6 +117,12 @@ def check_single_tensor_operation(function_name, x_shape_or_val, backend_list, *\n             z = k.eval(getattr(k, function_name)(x_shape_or_val, **kwargs))\n         z_list += [z]\n \n+    if return_results:\n+        if len(z_list) > 1:\n+            return z_list\n+        else:\n+            return z_list[0]\n+\n     if assert_value_with_ref is not None:\n         assert_list_with_ref(z_list, assert_value_with_ref)\n     else:\n@@ -129,6 +137,7 @@ def check_two_tensor_operation(function_name, x_shape_or_val,\n     concat_args = kwargs.pop('concat_args', False)\n     cntk_dynamicity = kwargs.pop('cntk_dynamicity', False)\n     cntk_two_dynamicity = kwargs.pop('cntk_two_dynamicity', False)\n+    return_results = kwargs.pop('return_results', False)\n \n     if shape_or_val:\n         x_shape, x_val = parse_shape_or_val(x_shape_or_val)\n@@ -157,6 +166,12 @@ def check_two_tensor_operation(function_name, x_shape_or_val,\n                 x_shape_or_val, y_shape_or_val, **kwargs))\n         z_list += [z]\n \n+    if return_results:\n+        if len(z_list) > 1:\n+            return z_list\n+        else:\n+            return z_list[0]\n+\n     assert_list_pairwise(z_list)\n     assert_list_keras_shape(z_list)\n \n@@ -177,6 +192,44 @@ def check_composed_tensor_operations(first_function_name, first_function_args,\n     assert_list_pairwise(z_list)\n \n \n+def ref_conv(x, w, padding, data_format):\n+    if x.ndim == 3:\n+        w = np.flipud(w)\n+        w = np.transpose(w, (1, 2, 0))\n+        if data_format == 'channels_last':\n+            x = np.transpose(x, (0, 2, 1))\n+    elif x.ndim == 4:\n+        w = np.fliplr(np.flipud(w))\n+        w = np.transpose(w, (2, 3, 0, 1))\n+        if data_format == 'channels_last':\n+            x = np.transpose(x, (0, 3, 1, 2))\n+    else:\n+        w = np.flip(np.fliplr(np.flipud(w)), axis=2)\n+        w = np.transpose(w, (3, 4, 0, 1, 2))\n+        if data_format == 'channels_last':\n+            x = np.transpose(x, (0, 4, 1, 2, 3))\n+\n+    y = []\n+    for i in range(x.shape[0]):\n+        _y = []\n+        for j in range(w.shape[1]):\n+            __y = []\n+            for k in range(w.shape[0]):\n+                __y.append(signal.convolve(x[i, k], w[k, j], mode=padding))\n+            _y.append(np.sum(np.stack(__y, axis=-1), axis=-1))\n+        y.append(_y)\n+    y = np.array(y)\n+\n+    if data_format == 'channels_last':\n+        if y.ndim == 3:\n+            y = np.transpose(y, (0, 2, 1))\n+        elif y.ndim == 4:\n+            y = np.transpose(y, (0, 2, 3, 1))\n+        else:\n+            y = np.transpose(y, (0, 2, 3, 4, 1))\n+    return y\n+\n+\n class TestBackend(object):\n \n     def test_is_keras_tensor(self):\n@@ -784,7 +837,30 @@ class TestBackend(object):\n                       for b in [KTH, KTF]]\n             assert_list_pairwise(z_list)\n \n-    def test_conv1d(self):\n+    @pytest.mark.parametrize('op,input_shape,kernel_shape,padding,data_format', [\n+        ('conv1d', (2, 8, 2), (3, 2, 3), 'same', 'channels_last'),\n+        ('conv1d', (1, 8, 2), (3, 2, 3), 'valid', 'channels_last'),\n+        ('conv2d', (2, 3, 4, 5), (3, 3, 3, 2), 'same', 'channels_first'),\n+        ('conv2d', (2, 3, 5, 6), (4, 3, 3, 4), 'valid', 'channels_first'),\n+        ('conv2d', (1, 6, 5, 3), (3, 4, 3, 2), 'valid', 'channels_last'),\n+        ('conv2d', (1, 7, 6, 3), (3, 3, 3, 4), 'same', 'channels_last'),\n+        ('conv3d', (2, 3, 4, 5, 4), (3, 3, 3, 3, 4), 'same', 'channels_first'),\n+        ('conv3d', (2, 3, 5, 4, 6), (3, 2, 4, 3, 4), 'valid', 'channels_first'),\n+        ('conv3d', (1, 2, 2, 2, 1), (2, 2, 2, 1, 1), 'valid', 'channels_last'),\n+        ('conv3d', (1, 3, 5, 4, 2), (3, 3, 3, 2, 3), 'same', 'channels_last'),\n+    ])\n+    def test_conv(self, op, input_shape, kernel_shape, padding, data_format):\n+        k = K.backend()\n+        _, x = parse_shape_or_val(input_shape)\n+        _, w = parse_shape_or_val(kernel_shape)\n+        y1 = ref_conv(x, w, padding, data_format)\n+        y2 = check_two_tensor_operation(\n+            op, x, w, [KTH if k == 'theano' else KC if k == 'cntk' else KTF],\n+            padding=padding, data_format=data_format,\n+            cntk_dynamicity=True, return_results=True)\n+        assert_allclose(y1, y2, atol=1e-05)\n+\n+    def legacy_test_conv1d(self):\n         # channels_last input shape: (n, length, input_depth)\n         input_shape = (4, 8, 2)\n         kernel_shape = (3, 2, 3)\n@@ -794,7 +870,7 @@ class TestBackend(object):\n                                        strides=strides,\n                                        data_format='channels_last')\n \n-    def test_conv2d(self):\n+    def legacy_test_conv2d(self):\n         # TF kernel shape: (rows, cols, input_depth, depth)\n         # channels_first input shape: (n, input_depth, rows, cols)\n         for (input_shape, kernel_shape, data_format) in [\n@@ -817,7 +893,7 @@ class TestBackend(object):\n                                        BACKENDS, cntk_dynamicity=True,\n                                        data_format=data_format)\n \n-    def test_conv3d(self):\n+    def legacy_test_conv3d(self):\n         # TH input shape: (samples, input_depth, conv_dim1, conv_dim2, conv_dim3)\n         # TF input shape: (samples, conv_dim1, conv_dim2, conv_dim3, input_depth)\n         # TH kernel shape: (depth, input_depth, x, y, z)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7a1b9005c220afb9271d20a73e168cf18d0cd631", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 184 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 4 | Methods Changed: 5 | Complexity Δ (Sum/Max): 13/8 | Churn Δ: 184 | Churn Cumulative: 588 | Contributors (this commit): 18 | Commits (past 90d): 5 | Contributors (cumulative): 20 | DMM Complexity: 1.0\n\nDIFF:\n@@ -9,6 +9,8 @@ import numpy as np\n import random\n from six.moves import range\n \n+from ..utils.data_utils import Sequence\n+\n \n def pad_sequences(sequences, maxlen=None, dtype='int32',\n                   padding='pre', truncating='pre', value=0.):\n@@ -216,3 +218,107 @@ def _remove_long_seq(maxlen, seq, label):\n             new_seq.append(x)\n             new_label.append(y)\n     return new_seq, new_label\n+\n+\n+class TimeseriesGenerator(Sequence):\n+    \"\"\"Utility class for generating batches of temporal data.\n+\n+    This class takes in a sequence of data-points gathered at\n+    equal intervals, along with time series parameters such as\n+    stride, length of history etc., to produce batches for\n+    training/validation.\n+\n+    # Arguments\n+        data: indexable generator (such as list or Numpy array)\n+            containing consecutive data points.\n+        targets: targets corresponding to instances in `data`.\n+            Should have same length as `data`.\n+        length: length of history to consider for prediction.\n+            `data[i-length : i+1]` is used to prepare the input.\n+        sampling_rate: period between successive individual data\n+            points. For rate `r`, points\n+            `data[i]`, `data[i-r]`, ... `data[i - length]`\n+            are used as input.\n+        stride: period between successive sub-sequences used for\n+            training. For stride `s`, consecutive training samples would\n+            be centered around `data[i]`, `data[i+s]`, `data[i+2*s]`, ...\n+        start_index, end_index: delimiters for sub-sets of `data` & `targets`\n+            to be used for batch generation. Useful to reserve part of\n+            data for validation.\n+        shuffle: whether to shuffle training samples, or draw them in\n+            chronological order.\n+        reverse: if `true`, input points are provided in reverse order.\n+        batch_size: number of timeseries samples in each batch\n+            (except maybe last one)\n+\n+    # Returns\n+        A `Sequence` instance.\n+\n+    # Examples\n+\n+    ```data = np.array([[i] for i in range(50)])\n+       targets = np.array([[i] for i in range(50)])\n+\n+       data_gen = TimeseriesGenerator(data, targets,\n+                                      length=10, sampling_rate=2,\n+                                      batch_size=2)\n+       assert len(data_gen) == 20\n+       assert (np.array_equal(data_gen[0][0],\n+                              np.array([[[0], [2], [4], [6], [8]],\n+                                        [[1], [3], [5], [7], [9]]])))\n+       assert (np.array_equal(data_gen[0][1],\n+                              np.array([[10], [11]])))\n+    ```\n+    \"\"\"\n+\n+    def __init__(self, data, targets,\n+                 length,\n+                 sampling_rate=1,\n+                 stride=1,\n+                 start_index=0,\n+                 end_index=None,\n+                 shuffle=False,\n+                 reverse=False,\n+                 batch_size=128):\n+        self.data = data\n+        self.targets = targets\n+        self.length = length\n+        self.sampling_rate = sampling_rate\n+        self.stride = stride\n+        self.start_index = start_index + length\n+        if end_index is None:\n+            end_index = len(data) - 1\n+        self.end_index = end_index\n+        self.shuffle = shuffle\n+        self.reverse = reverse\n+        self.batch_size = batch_size\n+\n+    def __len__(self):\n+        return int(np.ceil(\n+            (self.end_index - self.start_index) /\n+            (self.batch_size * self.stride)))\n+\n+    def _empty_batch(self, num_rows):\n+        samples_shape = [num_rows, self.length // self.sampling_rate]\n+        samples_shape.extend(self.data.shape[1:])\n+        targets_shape = [num_rows]\n+        targets_shape.extend(self.targets.shape[1:])\n+        return np.empty(samples_shape), np.empty(targets_shape)\n+\n+    def __getitem__(self, index):\n+        if self.shuffle:\n+            rows = np.random.randint(\n+                self.start_index, self.end_index, size=self.batch_size)\n+        else:\n+            i = self.start_index + self.batch_size * self.stride * index\n+            rows = np.arange(i, min(i + self.batch_size *\n+                                    self.stride, self.end_index), self.stride)\n+\n+        samples, targets = self._empty_batch(len(rows))\n+        for j, row in enumerate(rows):\n+            indices = range(rows[j] - self.length, rows[j], self.sampling_rate)\n+            samples[j] = self.data[indices]\n+            targets[j] = self.targets[rows[j]]\n+        if self.reverse:\n+            return samples[:, ::-1, ...], targets\n+        return samples, targets\n\n@@ -7,6 +7,7 @@ from keras.preprocessing.sequence import pad_sequences\n from keras.preprocessing.sequence import make_sampling_table\n from keras.preprocessing.sequence import skipgrams\n from keras.preprocessing.sequence import _remove_long_seq\n+from keras.preprocessing.sequence import TimeseriesGenerator\n \n \n def test_pad_sequences():\n@@ -95,5 +96,82 @@ def test_remove_long_seq():\n     assert new_label == ['a']\n \n \n+def test_TimeseriesGenerator():\n+    data = np.array([[i] for i in range(50)])\n+    targets = np.array([[i] for i in range(50)])\n+\n+    data_gen = TimeseriesGenerator(data, targets,\n+                                   length=10, sampling_rate=2,\n+                                   batch_size=2)\n+    assert len(data_gen) == 20\n+    assert (np.allclose(data_gen[0][0],\n+                        np.array([[[0], [2], [4], [6], [8]],\n+                                  [[1], [3], [5], [7], [9]]])))\n+    assert (np.allclose(data_gen[0][1],\n+                        np.array([[10], [11]])))\n+    assert (np.allclose(data_gen[1][0],\n+                        np.array([[[2], [4], [6], [8], [10]],\n+                                  [[3], [5], [7], [9], [11]]])))\n+    assert (np.allclose(data_gen[1][1],\n+                        np.array([[12], [13]])))\n+\n+    data_gen = TimeseriesGenerator(data, targets,\n+                                   length=10, sampling_rate=2, reverse=True,\n+                                   batch_size=2)\n+    assert len(data_gen) == 20\n+    assert (np.allclose(data_gen[0][0],\n+                        np.array([[[8], [6], [4], [2], [0]],\n+                                  [[9], [7], [5], [3], [1]]])))\n+    assert (np.allclose(data_gen[0][1],\n+                        np.array([[10], [11]])))\n+\n+    data_gen = TimeseriesGenerator(data, targets,\n+                                   length=10, sampling_rate=2, shuffle=True,\n+                                   batch_size=1)\n+    batch = data_gen[0]\n+    r = batch[1][0][0]\n+    assert (np.allclose(batch[0],\n+                        np.array([[[r - 10],\n+                                   [r - 8],\n+                                   [r - 6],\n+                                   [r - 4],\n+                                   [r - 2]]])))\n+    assert (np.allclose(batch[1], np.array([[r], ])))\n+\n+    data_gen = TimeseriesGenerator(data, targets,\n+                                   length=10, sampling_rate=2, stride=2,\n+                                   batch_size=2)\n+    assert len(data_gen) == 10\n+    assert (np.allclose(data_gen[1][0],\n+                        np.array([[[4], [6], [8], [10], [12]],\n+                                  [[6], [8], [10], [12], [14]]])))\n+    assert (np.allclose(data_gen[1][1],\n+                        np.array([[14], [16]])))\n+\n+    data_gen = TimeseriesGenerator(data, targets,\n+                                   length=10, sampling_rate=2,\n+                                   start_index=10, end_index=30,\n+                                   batch_size=2)\n+    assert len(data_gen) == 5\n+    assert (np.allclose(data_gen[0][0],\n+                        np.array([[[10], [12], [14], [16], [18]],\n+                                  [[11], [13], [15], [17], [19]]])))\n+    assert (np.allclose(data_gen[0][1],\n+                        np.array([[20], [21]])))\n+\n+    data = np.array([np.random.random_sample((1, 2, 3, 4)) for i in range(50)])\n+    targets = np.array([np.random.random_sample((3, 2, 1)) for i in range(50)])\n+    data_gen = TimeseriesGenerator(data, targets,\n+                                   length=10, sampling_rate=2,\n+                                   start_index=10, end_index=30,\n+                                   batch_size=2)\n+\n+    assert len(data_gen) == 5\n+    assert np.allclose(data_gen[0][0], np.array(\n+        [np.array(data[10:19:2]), np.array(data[11:20:2])]))\n+    assert (np.allclose(data_gen[0][1],\n+                        np.array([targets[20], targets[21]])))\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1bdc4a931f599cb8581207d0621d5aea5c39bf8e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 77 | Lines Deleted: 61 | Files Changed: 1 | Hunks: 22 | Methods Changed: 5 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 138 | Churn Cumulative: 635 | Contributors (this commit): 17 | Commits (past 90d): 4 | Contributors (cumulative): 17 | DMM Complexity: 0.0\n\nDIFF:\n@@ -24,19 +24,21 @@ def pad_sequences(sequences, maxlen=None, dtype='int32',\n     Supports post-padding and pre-padding (default).\n \n     # Arguments\n-        sequences: list of lists where each element is a sequence\n-        maxlen: int, maximum length\n-        dtype: type to cast the resulting sequence.\n-        padding: 'pre' or 'post', pad either before or after each sequence.\n-        truncating: 'pre' or 'post', remove values from sequences larger than\n-            maxlen either in the beginning or in the end of the sequence\n-        value: float, value to pad the sequences to the desired value.\n+        sequences: List of lists, where each element is a sequence.\n+        maxlen: Int, maximum length of all sequences.\n+        dtype: Type of the output sequences.\n+        padding: String, 'pre' or 'post':\n+            pad either before or after each sequence.\n+        truncating: String, 'pre' or 'post':\n+            remove values from sequences larger than\n+            `maxlen`, either at the beginning or at the end of the sequences.\n+        value: Float, padding value.\n \n     # Returns\n-        x: numpy array with dimensions (number_of_sequences, maxlen)\n+        x: Numpy array with shape `(len(sequences), maxlen)`\n \n     # Raises\n-        ValueError: in case of invalid values for `truncating` or `padding`,\n+        ValueError: In case of invalid values for `truncating` or `padding`,\n             or in case of invalid shape for a `sequences` entry.\n     \"\"\"\n     if not hasattr(sequences, '__len__'):\n@@ -69,12 +71,14 @@ def pad_sequences(sequences, maxlen=None, dtype='int32',\n         elif truncating == 'post':\n             trunc = s[:maxlen]\n         else:\n-            raise ValueError('Truncating type \"%s\" not understood' % truncating)\n+            raise ValueError('Truncating type \"%s\" '\n+                             'not understood' % truncating)\n \n         # check `trunc` has expected shape\n         trunc = np.asarray(trunc, dtype=dtype)\n         if trunc.shape[1:] != sample_shape:\n-            raise ValueError('Shape of sample %s of sequence at position %s is different from expected shape %s' %\n+            raise ValueError('Shape of sample %s of sequence at position %s '\n+                             'is different from expected shape %s' %\n                              (trunc.shape[1:], idx, sample_shape))\n \n         if padding == 'post':\n@@ -94,16 +98,16 @@ def make_sampling_table(size, sampling_factor=1e-5):\n     according to the sampling distribution used in word2vec.\n \n     The word2vec formula is:\n-        p(word) = min(1, sqrt(word.frequency/sampling_factor) / (word.frequency/sampling_factor))\n+        `p(word) = min(1, sqrt(word.frequency/sampling_factor) / (word.frequency/sampling_factor))`\n \n     We assume that the word frequencies follow Zipf's law (s=1) to derive\n     a numerical approximation of frequency(rank):\n-       frequency(rank) ~ 1/(rank * (log(rank) + gamma) + 1/2 - 1/(12*rank))\n-        where gamma is the Euler-Mascheroni constant.\n+       `frequency(rank) ~ 1/(rank * (log(rank) + gamma) + 1/2 - 1/(12*rank))`\n+        where `gamma` is the Euler-Mascheroni constant.\n \n     # Arguments\n-        size: int, number of possible words to sample.\n-        sampling_factor: the sampling factor in the word2vec formula.\n+        size: Int, number of possible words to sample.\n+        sampling_factor: The sampling factor in the word2vec formula.\n \n     # Returns\n         A 1D Numpy array of length `size` where the ith entry\n@@ -124,29 +128,32 @@ def skipgrams(sequence, vocabulary_size,\n     \"\"\"Generates skipgram word pairs.\n \n     Takes a sequence (list of indexes of words),\n-    returns couples of [word_index, other_word index] and labels (1s or 0s),\n-    where label = 1 if 'other_word' belongs to the context of 'word',\n-    and label=0 if 'other_word' is randomly sampled\n+    returns couples of samples `[word_index, other_word index]`\n+    and labels (1s or 0s),\n+    where `label == 1` if 'other_word' belongs to the context of 'word',\n+    and `label == 0` if 'other_word' is randomly sampled.\n \n     # Arguments\n-        sequence: a word sequence (sentence), encoded as a list\n+        sequence: A word sequence (sentence), encoded as a list\n             of word indices (integers). If using a `sampling_table`,\n             word indices are expected to match the rank\n             of the words in a reference dataset (e.g. 10 would encode\n             the 10-th most frequently occurring token).\n             Note that index 0 is expected to be a non-word and will be skipped.\n-        vocabulary_size: int. maximum possible word index + 1\n-        window_size: int. actually half-window.\n-            The window of a word wi will be [i-window_size, i+window_size+1]\n-        negative_samples: float >= 0. 0 for no negative (=random) samples.\n-            1 for same number as positive samples. etc.\n-        shuffle: whether to shuffle the word couples before returning them.\n+        vocabulary_size: Int, maximum possible word index + 1\n+        window_size: Int, size of sampling windows (technically half-window).\n+            The window of a word `w_i` will be\n+            `[i - window_size, i + window_size+1]`.\n+        negative_samples: Float >= 0. 0 for no negative (i.e. random) samples.\n+            1 for same number as positive samples.\n+        shuffle: Whether to shuffle the word couples before returning them.\n         categorical: bool. if False, labels will be\n-            integers (eg. [0, 1, 1 .. ]),\n-            if True labels will be categorical eg. [[1,0],[0,1],[0,1] .. ]\n+            integers (eg. `[0, 1, 1 .. ]`),\n+            if `True`, labels will be categorical, e.g.\n+            `[[1,0],[0,1],[0,1] .. ]`.\n         sampling_table: 1D array of size `vocabulary_size` where the entry i\n             encodes the probability to sample a word of rank i.\n-        seed: random seed.\n+        seed: Random seed.\n \n     # Returns\n         couples, labels: where `couples` are int pairs and\n@@ -184,7 +191,8 @@ def skipgrams(sequence, vocabulary_size,\n         random.shuffle(words)\n \n         couples += [[words[i % len(words)],\n-                    random.randint(1, vocabulary_size - 1)] for i in range(num_negative_samples)]\n+                    random.randint(1, vocabulary_size - 1)]\n+                    for i in range(num_negative_samples)]\n         if categorical:\n             labels += [[1, 0]] * num_negative_samples\n         else:\n@@ -205,9 +213,9 @@ def _remove_long_seq(maxlen, seq, label):\n     \"\"\"Removes sequences that exceed the maximum length.\n \n     # Arguments\n-        maxlen: int, maximum length\n-        seq: list of lists where each sublist is a sequence\n-        label: list where each element is an integer\n+        maxlen: Int, maximum length of the output sequences.\n+        seq: List of lists, where each sublist is a sequence.\n+        label: List where each element is an integer.\n \n     # Returns\n         new_seq, new_label: shortened lists for `seq` and `label`.\n@@ -225,54 +233,62 @@ class TimeseriesGenerator(Sequence):\n \n     This class takes in a sequence of data-points gathered at\n     equal intervals, along with time series parameters such as\n-    stride, length of history etc., to produce batches for\n+    stride, length of history, etc., to produce batches for\n     training/validation.\n \n     # Arguments\n-        data: indexable generator (such as list or Numpy array)\n-            containing consecutive data points.\n-        targets: targets corresponding to instances in `data`.\n-            Should have same length as `data`.\n-        length: length of history to consider for prediction.\n-            `data[i-length : i+1]` is used to prepare the input.\n-        sampling_rate: period between successive individual data\n-            points. For rate `r`, points\n+        data: Indexable generator (such as list or Numpy array)\n+            containing consecutive data points (timesteps).\n+            The data should be at 2D, and axis 0 is expected\n+            to be the time dimension.\n+        targets: Targets corresponding to timesteps in `data`.\n+            It should have same length as `data`.\n+        length: Length of the output sequences (in number of timesteps).\n+        sampling_rate: Period between successive individual timesteps\n+            within sequences. For rate `r`, timesteps\n             `data[i]`, `data[i-r]`, ... `data[i - length]`\n-            are used as input.\n-        stride: period between successive sub-sequences used for\n-            training. For stride `s`, consecutive training samples would\n-            be centered around `data[i]`, `data[i+s]`, `data[i+2*s]`, ...\n-        start_index, end_index: delimiters for sub-sets of `data` & `targets`\n-            to be used for batch generation. Useful to reserve part of\n-            data for validation.\n-        shuffle: whether to shuffle training samples, or draw them in\n-            chronological order.\n-        reverse: if `true`, input points are provided in reverse order.\n-        batch_size: number of timeseries samples in each batch\n-            (except maybe last one)\n+            are used for create a sample sequence.\n+        stride: Period between successive output sequences.\n+            For stride `s`, consecutive output samples would\n+            be centered around `data[i]`, `data[i+s]`, `data[i+2*s]`, etc.\n+        start_index, end_index: Data points earlier than `start_index`\n+            or later than `end_index` will not be used in the output sequences.\n+            This is seful to reserve part of the data for test or validation.\n+        shuffle: Whether to shuffle output samples,\n+            or instead draw them in chronological order.\n+        reverse: Boolean: if `true`, timesteps in each output sample will be\n+            in reverse chronological order.\n+        batch_size: Number of timeseries samples in each batch\n+            (except maybe the last one).\n \n     # Returns\n         A `Sequence` instance.\n \n     # Examples\n \n-    ```data = np.array([[i] for i in range(50)])\n+    ```python\n+    from keras.preprocessing.sequence import TimeseriesGenerator\n+    import numpy as np\n+\n+    data = np.array([[i] for i in range(50)])\n     targets = np.array([[i] for i in range(50)])\n \n     data_gen = TimeseriesGenerator(data, targets,\n                                    length=10, sampling_rate=2,\n                                    batch_size=2)\n     assert len(data_gen) == 20\n-       assert (np.array_equal(data_gen[0][0],\n+\n+    batch_0 = data_gen[0]\n+    x, y = batch_0\n+    assert np.array_equal(x,\n                           np.array([[[0], [2], [4], [6], [8]],\n-                                        [[1], [3], [5], [7], [9]]])))\n-       assert (np.array_equal(data_gen[0][1],\n-                              np.array([[10], [11]])))\n+                                    [[1], [3], [5], [7], [9]]]))\n+    assert np.array_equal(y,\n+                          np.array([[10], [11]]))\n     ```\n     \"\"\"\n \n-    def __init__(self, data, targets,\n-                 length,\n+    def __init__(self, data, targets, length,\n                  sampling_rate=1,\n                  stride=1,\n                  start_index=0,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
