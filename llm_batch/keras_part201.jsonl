{"custom_id": "keras#33a03fdb7908f84adaf4827adfc308365fb73ff2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2305 | Contributors (this commit): 33 | Commits (past 90d): 11 | Contributors (cumulative): 33 | DMM Complexity: None\n\nDIFF:\n@@ -779,7 +779,7 @@ class NumpyArrayIterator(Iterator):\n                              'with shape', self.x.shape)\n         channels_axis = 3 if data_format == 'channels_last' else 1\n         if self.x.shape[channels_axis] not in {1, 3, 4}:\n-            raise ValueError('NumpyArrayIterator is set to use the '\n+            warnings.warn('NumpyArrayIterator is set to use the '\n                           'data format convention \"' + data_format + '\" '\n                           '(channels on axis ' + str(channels_axis) + '), i.e. expected '\n                           'either 1, 3 or 4 channels on axis ' + str(channels_axis) + '. '\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3d7df0a72f8414b222cf4a600120af5057a41889", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 21 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 4 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 25 | Churn Cumulative: 2890 | Contributors (this commit): 14 | Commits (past 90d): 19 | Contributors (cumulative): 14 | DMM Complexity: None\n\nDIFF:\n@@ -2,14 +2,31 @@ import pytest\n from numpy.testing import assert_allclose\n import numpy as np\n import scipy.sparse as sparse\n+import warnings\n \n from keras import backend as K\n-from keras.backend import theano_backend as KTH, floatx, set_floatx, variable\n-from keras.backend import tensorflow_backend as KTF\n+from keras.backend import floatx, set_floatx, variable\n from keras.utils.conv_utils import convert_kernel\n-from keras.backend import cntk_backend as KC\n \n-BACKENDS = [KTH, KTF, KC]\n+BACKENDS = []  # Holds a list of all available back-ends\n+\n+try:\n+    from keras.backend import cntk_backend as KC\n+    BACKENDS.append(KC)\n+except ImportError:\n+    warnings.warn('Could not import the CNTK backend')\n+\n+try:\n+    from keras.backend import tensorflow_backend as KTF\n+    BACKENDS.append(KTF)\n+except ImportError:\n+    warnings.warn('Could not import the Tensorflow backend.')\n+\n+try:\n+    from keras.backend import theano_backend as KTH\n+    BACKENDS.append(KTH)\n+except ImportError:\n+    warnings.warn('Could not import the Theano backend')\n \n \n def check_dtype(var, dtype):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cd16f5104d5553afe116abb90129e78c9c6d837c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 91 | Lines Deleted: 16 | Files Changed: 3 | Hunks: 13 | Methods Changed: 11 | Complexity Δ (Sum/Max): 11/14 | Churn Δ: 107 | Churn Cumulative: 10745 | Contributors (this commit): 52 | Commits (past 90d): 33 | Contributors (cumulative): 64 | DMM Complexity: 0.7872340425531915\n\nDIFF:\n@@ -1845,11 +1845,11 @@ class Container(Layer):\n         else:\n             if not name:\n                 raise ValueError('Provide either a layer name or layer index.')\n-        layer = None\n+\n         for layer in self.layers:\n             if layer.name == name:\n                 return layer\n-        if not layer:\n+\n         raise ValueError('No such layer: ' + name)\n \n     @property\n\n@@ -2,9 +2,9 @@ import pytest\n import json\n import numpy as np\n \n-from keras.layers import Dense, Dropout, InputLayer\n+from keras.layers import Dense, Dropout, Conv2D, InputLayer\n from keras import layers\n-from keras.engine import Input, Layer, get_source_inputs\n+from keras.engine import Input, Layer, topology, get_source_inputs\n from keras.models import Model, Sequential\n from keras import backend as K\n from keras.models import model_from_json, model_from_yaml\n@@ -76,6 +76,37 @@ def test_trainable_weights():\n     assert model.non_trainable_weights == weights\n \n \n+def test_valid_compute_mask():\n+    model = Sequential()\n+    model.add(Dense(1, input_dim=2))\n+    assert model.layers[0].supports_masking is True\n+    assert model.layers[0].compute_mask([model.input], [0., 1.]) == [0., 1.]\n+\n+\n+def test_invalid_compute_mask():\n+    model = Sequential()\n+    model.add(Conv2D(1, [2, 2], input_shape=[3, 3, 1]))\n+    assert model.layers[0].supports_masking is False\n+    assert model.layers[0].compute_mask([model.input], [None]) is None\n+\n+    mask = np.array([[0., 1.], [1., 0.]])\n+    with pytest.raises(TypeError):\n+        model.layers[0].compute_mask([model.input], [mask])\n+    with pytest.raises(TypeError):\n+        model.layers[0].compute_mask([model.input], mask)\n+\n+\n+def test_get_layer():\n+    model = Sequential()\n+    model.add(Dense(1, input_dim=2))\n+    with pytest.raises(ValueError):\n+        model.get_layer(index=5)\n+    with pytest.raises(ValueError):\n+        model.get_layer(index=None)\n+    with pytest.raises(ValueError):\n+        model.get_layer(name='conv')\n+\n+\n def test_learning_phase():\n     a = Input(shape=(32,), name='input_a')\n     b = Input(shape=(32,), name='input_b')\n@@ -181,6 +212,9 @@ def test_node_construction():\n     assert dense.inbound_nodes[0].input_tensors == [a]\n     assert dense.inbound_nodes[1].input_tensors == [b]\n \n+    assert dense.inbound_nodes[0].get_config()['inbound_layers'] == ['input_a']\n+    assert dense.inbound_nodes[1].get_config()['inbound_layers'] == ['input_b']\n+\n     # test layer properties\n     test_layer = Dense(16, name='test_layer')\n     a_test = test_layer(a)\n@@ -491,7 +525,6 @@ def test_recursion():\n def test_load_layers():\n     from keras.layers import ConvLSTM2D, TimeDistributed, Bidirectional, Conv2D, Input\n     from keras.models import Model\n-    from keras.engine.topology import preprocess_weights_for_loading\n \n     if K.backend() == 'tensorflow' or K.backend() == 'cntk':\n         inputs = Input(shape=(10, 20, 20, 1))\n@@ -512,7 +545,8 @@ def test_load_layers():\n     weight_tensor_td_conv_old.append(np.zeros((15,)))\n     td_conv_layer = model.layers[1]\n     td_conv_layer.layer.data_format = 'channels_first'\n-    weight_tensor_td_conv_new = preprocess_weights_for_loading(td_conv_layer,\n+    weight_tensor_td_conv_new = topology.preprocess_weights_for_loading(\n+        td_conv_layer,\n         weight_tensor_td_conv_old,\n         original_keras_version='1')\n     symbolic_weights = td_conv_layer.weights\n@@ -529,7 +563,8 @@ def test_load_layers():\n             weight_tensor_bi_convlstm_old.append(np.zeros((10,)))  # bias\n \n     bi_convlstm_layer = model.layers[2]\n-    weight_tensor_bi_convlstm_new = preprocess_weights_for_loading(bi_convlstm_layer,\n+    weight_tensor_bi_convlstm_new = topology.preprocess_weights_for_loading(\n+        bi_convlstm_layer,\n         weight_tensor_bi_convlstm_old,\n         original_keras_version='1')\n \n@@ -549,6 +584,55 @@ def test_load_layers():\n     assert np.all(K.eval(model.layers[2].weights[5]) == weight_tensor_bi_convlstm_new[5])\n \n \n+def convert_weights(layer, weights):\n+    if layer.__class__.__name__ == 'GRU':\n+        W = [np.split(w, 3, axis=-1) for w in weights]\n+        return sum(map(list, zip(*W)), [])\n+    elif layer.__class__.__name__ in ('LSTM', 'ConvLSTM2D'):\n+        W = [np.split(w, 4, axis=-1) for w in weights]\n+        for w in W:\n+            w[2], w[1] = w[1], w[2]\n+        return sum(map(list, zip(*W)), [])\n+    elif layer.__class__.__name__ == 'Conv2DTranspose':\n+        return [np.transpose(weights[0], (2, 3, 0, 1)), weights[1]]\n+    return weights\n+\n+\n+@keras_test\n+@pytest.mark.parametrize(\"layer\", [\n+    layers.GRU(2, input_shape=[3, 5]),\n+    layers.LSTM(2, input_shape=[3, 5]),\n+    layers.ConvLSTM2D(5, (3, 3),\n+                      input_shape=[6, 6, 6, 6],\n+                      data_format='channels_first'),\n+])\n+def test_preprocess_weights_for_loading(layer):\n+    model = Sequential([layer])\n+    weights1 = layer.get_weights()\n+    weights2 = topology.preprocess_weights_for_loading(\n+        layer, convert_weights(layer, weights1),\n+        original_keras_version='1')\n+    assert all([np.allclose(x, y, 1e-5)\n+                for (x, y) in zip(weights1, weights2)])\n+\n+\n+@keras_test\n+@pytest.mark.parametrize(\"layer\", [\n+    layers.Conv2D(2, (3, 3), input_shape=[5, 5, 3]),\n+    layers.Conv2DTranspose(2, (5, 5),\n+                           input_shape=[7, 7, 3],\n+                           data_format='channels_first'),\n+])\n+def test_preprocess_weights_for_loading_for_model(layer):\n+    model = Sequential([layer])\n+    weights1 = model.get_weights()\n+    weights2 = topology.preprocess_weights_for_loading(\n+        model, convert_weights(layer, weights1),\n+        original_keras_version='1')\n+    assert all([np.allclose(x, y, 1e-5)\n+                for (x, y) in zip(weights1, weights2)])\n+\n+\n @keras_test\n def test_recursion_with_bn_and_loss():\n     model1 = Sequential([\n\n@@ -1,7 +1,6 @@\n import pytest\n import json\n from keras.utils.test_utils import keras_test\n-from keras.engine.topology import preprocess_weights_for_loading\n import keras\n import numpy as np\n \n@@ -110,10 +109,6 @@ def test_lstm_legacy_interface():\n     new_layer = keras.layers.LSTM(2, input_shape=[3, 5], name='d')\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n \n-    preprocess_weights_for_loading(new_layer,\n-                                   [np.random.random(x) for x in [(5, 2), (2, 2), (2,)] * 4],\n-                                   original_keras_version='1')\n-\n     old_layer = keras.layers.LSTM(input_shape=[3, 5], output_dim=2, name='d', consume_less='mem')\n     new_layer = keras.layers.LSTM(2, input_shape=[3, 5], name='d', implementation=1)\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n@@ -212,10 +207,6 @@ def test_gru_legacy_interface():\n     new_layer = keras.layers.GRU(2, input_shape=[3, 5], name='d')\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n \n-    preprocess_weights_for_loading(new_layer,\n-                                   [np.random.random(x) for x in [(5, 2), (2, 2), (2,)] * 3],\n-                                   original_keras_version='1')\n-\n     old_layer = keras.layers.GRU(2, init='normal',\n                                  inner_init='glorot_uniform',\n                                  inner_activation='hard_sigmoid',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#57bc4da51329a48937f809aed0b80d23575bc209", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 4973 | Contributors (this commit): 60 | Commits (past 90d): 24 | Contributors (cumulative): 60 | DMM Complexity: None\n\nDIFF:\n@@ -72,7 +72,7 @@ def _standardize_input_data(data, names, shapes=None,\n                                  'that you are passing to your model '\n                                  'is not the size the model expected. '\n                                  'Expected to see ' + str(len(names)) +\n-                                 ' arrays but instead got '\n+                                 ' array(s), but instead got '\n                                  'the following list of ' + str(len(data)) +\n                                  ' arrays: ' + str(data)[:200] +\n                                  '...')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e27b8b9343da4558b98570d6d45599bd0e365723", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 310 | Lines Deleted: 2 | Files Changed: 3 | Hunks: 6 | Methods Changed: 8 | Complexity Δ (Sum/Max): 40/36 | Churn Δ: 312 | Churn Cumulative: 19310 | Contributors (this commit): 109 | Commits (past 90d): 39 | Contributors (cumulative): 132 | DMM Complexity: 0.3191489361702128\n\nDIFF:\n@@ -1790,7 +1790,8 @@ class Container(Layer):\n                 raise RuntimeError('The name \"' + name + '\" is used ' +\n                                    str(all_names.count(name)) +\n                                    ' times in the model. '\n-                                   'All layer names should be unique.')\n+                                   'All layer names should be unique. '\n+                                   'Layer names: ', all_names)\n \n         # Layer parameters.\n         # The new container starts with a single inbound node\n\n@@ -13,6 +13,7 @@ from . import backend as K\n from . import optimizers\n from . import layers as layer_module\n from .utils.io_utils import ask_to_proceed_with_overwrite\n+from .utils.generic_utils import has_arg\n from .engine.training import Model\n from .engine import topology\n from .engine.topology import Layer\n@@ -560,7 +561,6 @@ class Sequential(Model):\n         # Make sure child model callbacks\n         # will call the parent Sequential model.\n         self.model.callback_model = self\n-\n         self.built = True\n \n     @property\n@@ -1299,3 +1299,231 @@ class Sequential(Model):\n             layer = get_or_create_layer(conf)\n             model.add(layer)\n         return model\n+\n+\n+def _clone_functional_model(model, input_tensors=None):\n+    \"\"\"Clone a functional `Model` instance.\n+\n+    Model cloning is similar to calling a model on new inputs,\n+    except that it creates new layers (and thus new weights) instead\n+    of sharing the weights of the existing layers.\n+\n+    # Arguments\n+        model: Instance of `Model`.\n+        input_tensors: optional list of input tensors\n+            to build the model upon. If not provided,\n+            placeholders will be created.\n+\n+    # Returns\n+        An instance of `Model` reproducing the behavior\n+        of the original model, on top of new inputs tensors,\n+        using newly instantiated weights.\n+\n+    # Raises\n+        ValueError: in case of invalid `model` argument value.\n+    \"\"\"\n+    if not isinstance(model, Model):\n+        raise ValueError('Expected `model` argument '\n+                         'to be a `Model` instance, got ', model)\n+    if isinstance(model, Sequential):\n+        raise ValueError('Expected `model` argument '\n+                         'to be a functional `Model` instance, '\n+                         'got a `Sequential` instance instead:', model)\n+\n+    layer_map = {}  # Cache for created layers.\n+    tensor_map = {}  # Map {reference_tensor: (corresponding_tensor, mask)}\n+    if input_tensors is None:\n+        # Create placeholders to build the model on top of.\n+        input_layers = []\n+        input_tensors = []\n+        for layer in model.input_layers:\n+            input_tensor = Input(batch_shape=layer.batch_input_shape,\n+                                 dtype=layer.dtype,\n+                                 sparse=layer.sparse,\n+                                 name=layer.name)\n+            input_tensors.append(input_tensor)\n+            # Cache newly created input layer.\n+            newly_created_input_layer = input_tensor._keras_history[0]\n+            layer_map[layer] = newly_created_input_layer\n+        for original_input_layer, cloned_input_layer in zip(model.input_layers, input_layers):\n+            layer_map[original_input_layer] = cloned_input_layer\n+    else:\n+        # Make sure that all input tensors come from a Keras layer.\n+        # If tensor comes from an input layer: cache the input layer.\n+        input_tensors = topology._to_list(input_tensors)\n+        _input_tensors = []\n+        for i, x in enumerate(input_tensors):\n+            if not K.is_keras_tensor(x):\n+                name = model.input_layers[i].name\n+                input_tensor = Input(tensor=x,\n+                                     name='input_wrapper_for_' + name)\n+                _input_tensors.append(input_tensor)\n+                # Cache newly created input layer.\n+                original_input_layer = x._keras_history[0]\n+                newly_created_input_layer = input_tensor._keras_history[0]\n+                layer_map[original_input_layer] = newly_created_input_layer\n+            else:\n+                _input_tensors.append(x)\n+        input_tensors = _input_tensors\n+\n+    for x, y in zip(model.inputs, input_tensors):\n+        tensor_map[x] = (y, None)  # tensor, mask\n+\n+    # Iterated over every node in the reference model, in depth order.\n+    depth_keys = list(model.nodes_by_depth.keys())\n+    depth_keys.sort(reverse=True)\n+    for depth in depth_keys:\n+        nodes = model.nodes_by_depth[depth]\n+        for node in nodes:\n+            # Recover the corresponding layer.\n+            layer = node.outbound_layer\n+\n+            # Get or create layer.\n+            if layer not in layer_map:\n+                # Clone layer.\n+                new_layer = layer.__class__.from_config(layer.get_config())\n+                layer_map[layer] = new_layer\n+                layer = new_layer\n+            else:\n+                # Reuse previously cloned layer.\n+                layer = layer_map[layer]\n+                # Don't call InputLayer multiple times.\n+                if isinstance(layer, topology.InputLayer):\n+                    continue\n+\n+            # Gather inputs to call the new layer.\n+            reference_input_tensors = node.input_tensors\n+            reference_output_tensors = node.output_tensors\n+\n+            # If all previous input tensors are available in tensor_map,\n+            # then call node.inbound_layer on them.\n+            computed_data = []  # List of tuples (input, mask).\n+            for x in reference_input_tensors:\n+                if x in tensor_map:\n+                    computed_data.append(tensor_map[x])\n+\n+            if len(computed_data) == len(reference_input_tensors):\n+                # Call layer.\n+                if node.arguments:\n+                    kwargs = node.arguments\n+                else:\n+                    kwargs = {}\n+                if len(computed_data) == 1:\n+                    computed_tensor, computed_mask = computed_data[0]\n+                    if has_arg(layer.call, 'mask'):\n+                        if 'mask' not in kwargs:\n+                            kwargs['mask'] = computed_mask\n+                    output_tensors = topology._to_list(\n+                        layer(computed_tensor, **kwargs))\n+                    output_masks = topology._to_list(\n+                        layer.compute_mask(computed_tensor,\n+                                           computed_mask))\n+                    computed_tensors = [computed_tensor]\n+                    computed_masks = [computed_mask]\n+                else:\n+                    computed_tensors = [x[0] for x in computed_data]\n+                    computed_masks = [x[1] for x in computed_data]\n+                    if has_arg(layer.call, 'mask'):\n+                        if 'mask' not in kwargs:\n+                            kwargs['mask'] = computed_masks\n+                    output_tensors = topology._to_list(\n+                        layer(computed_tensors, **kwargs))\n+                    output_masks = topology._to_list(\n+                        layer.compute_mask(computed_tensors,\n+                                           computed_masks))\n+                # Update tensor_map.\n+                for x, y, mask in zip(reference_output_tensors,\n+                                      output_tensors,\n+                                      output_masks):\n+                    tensor_map[x] = (y, mask)\n+\n+    # Check that we did compute the model outputs,\n+    # then instantiate a new model from inputs and outputs.\n+    output_tensors = []\n+    for x in model.outputs:\n+        assert x in tensor_map, 'Could not compute output ' + str(x)\n+        tensor, _ = tensor_map[x]\n+        output_tensors.append(tensor)\n+    return Model(input_tensors, output_tensors, name=model.name)\n+\n+\n+def _clone_sequential_model(model, input_tensors=None):\n+    \"\"\"Clone a `Sequential` model instance.\n+\n+    Model cloning is similar to calling a model on new inputs,\n+    except that it creates new layers (and thus new weights) instead\n+    of sharing the weights of the existing layers.\n+\n+    # Arguments\n+        model: Instance of `Sequential`.\n+        input_tensors: optional list of input tensors\n+            to build the model upon. If not provided,\n+            placeholders will be created.\n+\n+    # Returns\n+        An instance of `Sequential` reproducing the behavior\n+        of the original model, on top of new inputs tensors,\n+        using newly instantiated weights.\n+\n+    # Raises\n+        ValueError: in case of invalid `model` argument value.\n+    \"\"\"\n+    if not isinstance(model, Sequential):\n+        raise ValueError('Expected `model` argument '\n+                         'to be a `Sequential` model instance, '\n+                         'but got:', model)\n+\n+    def clone(layer):\n+        return layer.__class__.from_config(layer.get_config())\n+\n+    layers = [clone(layer) for layer in model.layers]\n+    if input_tensors is None:\n+        return Sequential(layers=layers, name=model.name)\n+    else:\n+        if len(topology._to_list(input_tensors)) != 1:\n+            raise ValueError('To clone a `Sequential` model, we expect '\n+                             ' at most one tensor '\n+                             'as part of `input_tensors`.')\n+        x = topology._to_list(input_tensors)[0]\n+        if K.is_keras_tensor(x):\n+            origin_layer = x._keras_history[0]\n+            if isinstance(origin_layer, topology.InputLayer):\n+                return Sequential(layers=[origin_layer] + layers,\n+                                  name=model.name)\n+            else:\n+                raise ValueError('Cannot clone a `Sequential` model on top '\n+                                 'of a tensor that comes from a Keras layer '\n+                                 'other than an `InputLayer`. '\n+                                 'Use the functional API instead.')\n+        input_tensor = Input(tensor=x,\n+                             name='input_wrapper_for_' + str(x.name))\n+        input_layer = input_tensor._keras_history[0]\n+        return Sequential(layers=[input_layer] + layers, name=model.name)\n+\n+\n+def clone_model(model, input_tensors=None):\n+    \"\"\"Clone any `Model` instance.\n+\n+    Model cloning is similar to calling a model on new inputs,\n+    except that it creates new layers (and thus new weights) instead\n+    of sharing the weights of the existing layers.\n+\n+    # Arguments\n+        model: Instance of `Model`\n+            (could be a functional model or a Sequential model).\n+        input_tensors: optional list of input tensors\n+            to build the model upon. If not provided,\n+            placeholders will be created.\n+\n+    # Returns\n+        An instance of `Model` reproducing the behavior\n+        of the original model, on top of new inputs tensors,\n+        using newly instantiated weights.\n+\n+    # Raises\n+        ValueError: in case of invalid `model` argument value.\n+    \"\"\"\n+    if isinstance(model, Sequential):\n+        return _clone_sequential_model(model, input_tensors=input_tensors)\n+    else:\n+        return _clone_functional_model(model, input_tensors=input_tensors)\n\n@@ -5,6 +5,7 @@ import os\n import numpy as np\n \n from keras import backend as K\n+import keras\n from keras.models import Sequential\n from keras.layers import Dense, Activation\n from keras.utils import np_utils\n@@ -267,5 +268,83 @@ def test_rebuild_model():\n     assert(model.get_layer(index=-1).output_shape == (None, 32))\n \n \n+@keras_test\n+def test_clone_functional_model():\n+    val_a = np.random.random((10, 4))\n+    val_b = np.random.random((10, 4))\n+    val_out = np.random.random((10, 4))\n+\n+    input_a = keras.Input(shape=(4,))\n+    input_b = keras.Input(shape=(4,))\n+    dense_1 = keras.layers.Dense(4,)\n+    dense_2 = keras.layers.Dense(4,)\n+\n+    x_a = dense_1(input_a)\n+    x_a = keras.layers.Dropout(0.5)(x_a)\n+    x_b = dense_1(input_b)\n+    x_a = dense_2(x_a)\n+    outputs = keras.layers.add([x_a, x_b])\n+    model = keras.models.Model([input_a, input_b], outputs)\n+\n+    if K.backend() == 'tensorflow':\n+        # Everything should work in a new session.\n+        K.clear_session()\n+\n+    # With placeholder creation\n+    new_model = keras.models.clone_model(model)\n+    new_model.compile('rmsprop', 'mse')\n+    new_model.train_on_batch([val_a, val_b], val_out)\n+\n+    # On top of new tensors\n+    input_a = keras.Input(shape=(4,), name='a')\n+    input_b = keras.Input(shape=(4,), name='b')\n+    new_model = keras.models.clone_model(\n+        model, input_tensors=[input_a, input_b])\n+    new_model.compile('rmsprop', 'mse')\n+    new_model.train_on_batch([val_a, val_b], val_out)\n+\n+    # On top of new, non-Keras tensors\n+    input_a = keras.backend.variable(val_a)\n+    input_b = keras.backend.variable(val_b)\n+    new_model = keras.models.clone_model(\n+        model, input_tensors=[input_a, input_b])\n+    new_model.compile('rmsprop', 'mse')\n+    new_model.train_on_batch(None, val_out)\n+\n+\n+@keras_test\n+def test_clone_sequential_model():\n+    val_a = np.random.random((10, 4))\n+    val_out = np.random.random((10, 4))\n+\n+    model = keras.models.Sequential()\n+    model.add(keras.layers.Dense(4, input_shape=(4,)))\n+    model.add(keras.layers.Dropout(0.5))\n+    model.add(keras.layers.Dense(4))\n+\n+    if K.backend() == 'tensorflow':\n+        # Everything should work in a new session.\n+        K.clear_session()\n+\n+    # With placeholder creation\n+    new_model = keras.models.clone_model(model)\n+    new_model.compile('rmsprop', 'mse')\n+    new_model.train_on_batch(val_a, val_out)\n+\n+    # On top of new tensor\n+    input_a = keras.Input(shape=(4,))\n+    new_model = keras.models.clone_model(\n+        model, input_tensors=input_a)\n+    new_model.compile('rmsprop', 'mse')\n+    new_model.train_on_batch(val_a, val_out)\n+\n+    # On top of new, non-Keras tensor\n+    input_a = keras.backend.variable(val_a)\n+    new_model = keras.models.clone_model(\n+        model, input_tensors=input_a)\n+    new_model.compile('rmsprop', 'mse')\n+    new_model.train_on_batch(None, val_out)\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#71bfb00788ec6e899abc8d2de1a67a281879bccd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 28 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 4 | Methods Changed: 4 | Complexity Δ (Sum/Max): 6/3 | Churn Δ: 30 | Churn Cumulative: 546 | Contributors (this commit): 12 | Commits (past 90d): 5 | Contributors (cumulative): 15 | DMM Complexity: 0.2\n\nDIFF:\n@@ -38,7 +38,13 @@ def text_to_word_sequence(text,\n     \"\"\"\n     if lower:\n         text = text.lower()\n-    text = text.translate(maketrans(filters, split * len(filters)))\n+\n+    if sys.version_info < (3,) and isinstance(text, unicode):\n+        translate_map = dict((ord(c), unicode(split)) for c in filters)\n+    else:\n+        translate_map = maketrans(filters, split * len(filters))\n+\n+    text = text.translate(translate_map)\n     seq = text.split(split)\n     return [i for i in seq if i]\n \n\n@@ -1,7 +1,9 @@\n+# -*- coding: utf-8 -*-\n+\n import numpy as np\n import pytest\n \n-from keras.preprocessing.text import Tokenizer, one_hot, hashing_trick\n+from keras.preprocessing.text import Tokenizer, one_hot, hashing_trick, text_to_word_sequence\n \n \n def test_one_hot():\n@@ -47,5 +49,23 @@ def test_tokenizer():\n         matrix = tokenizer.texts_to_matrix(texts, mode)\n \n \n+def test_text_to_word_sequence():\n+    text = 'hello! ? world!'\n+    assert text_to_word_sequence(text) == ['hello', 'world']\n+\n+\n+def test_text_to_word_sequence_unicode():\n+    text = u'ali! veli? kırk dokuz elli'\n+    assert text_to_word_sequence(text) == [u'ali', u'veli', u'kırk', u'dokuz', u'elli']\n+\n+\n+def test_tokenizer_unicode():\n+    texts = [u'ali veli kırk dokuz elli', u'ali veli kırk dokuz elli veli kırk dokuz']\n+    tokenizer = Tokenizer(num_words=5)\n+    tokenizer.fit_on_texts(texts)\n+\n+    assert len(tokenizer.word_counts) == 5\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3f9c0a30ab6a024c9b6fbd83f4ae9119c93718b9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 217 | Contributors (this commit): 3 | Commits (past 90d): 2 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -103,13 +103,13 @@ def _obtain_input_shape(input_shape,\n     \"\"\"\n     if weights != 'imagenet' and input_shape is not None and len(input_shape) == 3:\n         if data_format == 'channels_first':\n-            if input_shape[0] != 3 or input_shape[0] != 1:\n+            if input_shape[0] != 3 and input_shape[0] != 1:\n                 warnings.warn(\n                     'This model usually expects 1 or 3 input channels. '\n                     'However, it was passed ' + str(input_shape[0]) + ' input channels.')\n             default_shape = (input_shape[0], default_size, default_size)\n         else:\n-            if input_shape[-1] != 3 or input_shape[-1] != 1:\n+            if input_shape[-1] != 3 and input_shape[-1] != 1:\n                 warnings.warn(\n                     'This model usually expects 1 or 3 input channels. '\n                     'However, it was passed ' + str(input_shape[-1]) + ' input channels.')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f9481339a378272258bf5b3832012ea317bc35cb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 2893 | Contributors (this commit): 14 | Commits (past 90d): 20 | Contributors (cumulative): 14 | DMM Complexity: None\n\nDIFF:\n@@ -14,18 +14,21 @@ try:\n     from keras.backend import cntk_backend as KC\n     BACKENDS.append(KC)\n except ImportError:\n+    KC = None\n     warnings.warn('Could not import the CNTK backend')\n \n try:\n     from keras.backend import tensorflow_backend as KTF\n     BACKENDS.append(KTF)\n except ImportError:\n+    KTF = None\n     warnings.warn('Could not import the Tensorflow backend.')\n \n try:\n     from keras.backend import theano_backend as KTH\n     BACKENDS.append(KTH)\n except ImportError:\n+    KTH = None\n     warnings.warn('Could not import the Theano backend')\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a90d0428d5b48be9872979d6c18ac05d9888fd7b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 136 | Lines Deleted: 33 | Files Changed: 2 | Hunks: 18 | Methods Changed: 4 | Complexity Δ (Sum/Max): 11/10 | Churn Δ: 169 | Churn Cumulative: 6085 | Contributors (this commit): 62 | Commits (past 90d): 38 | Contributors (cumulative): 73 | DMM Complexity: 0.55\n\nDIFF:\n@@ -52,6 +52,10 @@ def _standardize_input_data(data, names, shapes=None,\n         ValueError: in case of improperly formatted user-provided data.\n     \"\"\"\n     if not names:\n+        if data:\n+            raise ValueError('Error when checking model ' +\n+                             exception_prefix + ': '\n+                             'expected no data, but got:', data)\n         return []\n     if data is None:\n         return [None for _ in range(len(names))]\n@@ -564,7 +568,8 @@ class Model(Container):\n     \"\"\"\n \n     def compile(self, optimizer, loss, metrics=None, loss_weights=None,\n-                sample_weight_mode=None, weighted_metrics=None, **kwargs):\n+                sample_weight_mode=None, weighted_metrics=None,\n+                target_tensors=None, **kwargs):\n         \"\"\"Configures the model for training.\n \n         # Arguments\n@@ -597,6 +602,14 @@ class Model(Container):\n                 If the model has multiple outputs, you can use a different\n                 `sample_weight_mode` on each output by passing a\n                 dictionary or a list of modes.\n+            target_tensors: by default, Keras will create placeholders for the\n+                model's target, which will be fed with the target data during\n+                training. If instead you would like to use your own\n+                target tensors (in turn, Keras will not expect external\n+                Numpy data for these targets at training time), you\n+                can specify them via the `target_tensors` argument. It can be\n+                a single tensor (for a single-output model), a list of tensors,\n+                or a dict mapping output names to target tensors.\n             weighted_metrics: list of metrics to be evaluated and weighted\n                 by sample_weight or class_weight during training and testing\n             **kwargs: when using the Theano/CNTK backends, these arguments\n@@ -644,19 +657,16 @@ class Model(Container):\n             loss_functions = [loss_function for _ in range(len(self.outputs))]\n         self.loss_functions = loss_functions\n         weighted_losses = [_weighted_masked_objective(fn) for fn in loss_functions]\n-        skip_indices = []\n+        skip_target_indices = []\n+        skip_target_weighing_indices = []\n         self._feed_outputs = []\n         self._feed_output_names = []\n         self._feed_output_shapes = []\n         self._feed_loss_fns = []\n         for i in range(len(weighted_losses)):\n             if weighted_losses[i] is None:\n-                skip_indices.append(i)\n-            else:\n-                self._feed_outputs.append(self.outputs[i])\n-                self._feed_output_names.append(self.output_names[i])\n-                self._feed_output_shapes.append(self.internal_output_shapes[i])\n-                self._feed_loss_fns.append(self.loss_functions[i])\n+                skip_target_indices.append(i)\n+                skip_target_weighing_indices.append(i)\n \n         # Prepare output masks.\n         masks = self.compute_mask(self.inputs, mask=None)\n@@ -691,6 +701,56 @@ class Model(Container):\n                             str(loss_weights) +\n                             ' - expected a list of dicts.')\n \n+        # Prepare targets of model.\n+        self.targets = []\n+        self._feed_targets = []\n+        if target_tensors is not None:\n+            if isinstance(target_tensors, list):\n+                if len(target_tensors) != len(self.outputs):\n+                    raise ValueError(\n+                        'When passing a list as `target_tensors`, '\n+                        'it should have one entry per model outputs. '\n+                        'The model has ' + str(len(self.outputs)) +\n+                        ' outputs, but you passed target_tensors=' +\n+                        str(target_tensors))\n+            elif isinstance(target_tensors, dict):\n+                for name in target_tensors:\n+                    if name not in self.output_names:\n+                        raise ValueError('Unknown entry in `target_tensors` '\n+                                         'dictionary: \"' + name + '\". '\n+                                         'Only expected the following keys: ' +\n+                                         str(self.output_names))\n+                _target_tensors = []\n+                for name in self.output_names:\n+                    _target_tensors.append(target_tensors.get(name, None))\n+                target_tensors = _target_tensors\n+            else:\n+                raise TypeError('Expected `target_tensors` to be '\n+                                'a list or dict, but got:', target_tensors)\n+        for i in range(len(self.outputs)):\n+            if i in skip_target_indices:\n+                self.targets.append(None)\n+            else:\n+                shape = self.internal_output_shapes[i]\n+                name = self.output_names[i]\n+                if target_tensors is not None:\n+                    target = target_tensors[i]\n+                else:\n+                    target = None\n+                if target is None:\n+                    target = K.placeholder(ndim=len(shape),\n+                                           name=name + '_target',\n+                                           sparse=K.is_sparse(self.outputs[i]),\n+                                           dtype=K.dtype(self.outputs[i]))\n+                    self._feed_targets.append(target)\n+                    self._feed_outputs.append(self.outputs[i])\n+                    self._feed_output_names.append(name)\n+                    self._feed_output_shapes.append(shape)\n+                    self._feed_loss_fns.append(self.loss_functions[i])\n+                else:\n+                    skip_target_weighing_indices.append(i)\n+                self.targets.append(target)\n+\n         # Prepare sample weights.\n         sample_weights = []\n         sample_weight_modes = []\n@@ -703,7 +763,7 @@ class Model(Container):\n                                      'Only expected the following keys: ' +\n                                      str(self.output_names))\n             for i, name in enumerate(self.output_names):\n-                if i in skip_indices:\n+                if i in skip_target_weighing_indices:\n                     weight = None\n                     sample_weight_modes.append(None)\n                 else:\n@@ -729,7 +789,7 @@ class Model(Container):\n                                  'sample_weight_mode=' +\n                                  str(sample_weight_mode))\n             for i in range(len(self.output_names)):\n-                if i in skip_indices:\n+                if i in skip_target_weighing_indices:\n                     weight = None\n                     sample_weight_modes.append(None)\n                 else:\n@@ -746,7 +806,7 @@ class Model(Container):\n                 sample_weights.append(weight)\n         else:\n             for i, name in enumerate(self.output_names):\n-                if i in skip_indices:\n+                if i in skip_target_weighing_indices:\n                     sample_weight_modes.append(None)\n                     sample_weights.append(None)\n                 else:\n@@ -763,25 +823,9 @@ class Model(Container):\n         self.sample_weight_modes = sample_weight_modes\n         self._feed_sample_weight_modes = []\n         for i in range(len(self.outputs)):\n-            if i not in skip_indices:\n+            if i not in skip_target_weighing_indices:\n                 self._feed_sample_weight_modes.append(self.sample_weight_modes[i])\n \n-        # Prepare targets of model.\n-        self.targets = []\n-        self._feed_targets = []\n-        for i in range(len(self.outputs)):\n-            if i in skip_indices:\n-                self.targets.append(None)\n-            else:\n-                shape = self.internal_output_shapes[i]\n-                name = self.output_names[i]\n-                target = K.placeholder(ndim=len(shape),\n-                                       name=name + '_target',\n-                                       sparse=K.is_sparse(self.outputs[i]),\n-                                       dtype=K.dtype(self.outputs[i]))\n-                self.targets.append(target)\n-                self._feed_targets.append(target)\n-\n         # Prepare metrics.\n         self.metrics = metrics\n         self.weighted_metrics = weighted_metrics\n@@ -792,7 +836,7 @@ class Model(Container):\n         total_loss = None\n         with K.name_scope('loss'):\n             for i in range(len(self.outputs)):\n-                if i in skip_indices:\n+                if i in skip_target_indices:\n                     continue\n                 y_true = self.targets[i]\n                 y_pred = self.outputs[i]\n@@ -836,7 +880,7 @@ class Model(Container):\n \n         with K.name_scope('metrics'):\n             for i in range(len(self.outputs)):\n-                if i in skip_indices:\n+                if i in skip_target_indices:\n                     continue\n \n                 y_true = self.targets[i]\n@@ -884,7 +928,7 @@ class Model(Container):\n         self.sample_weights = sample_weights\n         self._feed_sample_weights = []\n         for i in range(len(self.sample_weights)):\n-            if i not in skip_indices:\n+            if i not in skip_target_weighing_indices:\n                 self._feed_sample_weights.append(sample_weights[i])\n \n         # Functions for train, test and predict will\n\n@@ -4,10 +4,10 @@ from numpy.testing import assert_allclose\n import sys\n import scipy.sparse as sparse\n \n+import keras\n from keras.layers import Dense, Dropout\n from keras.engine.topology import Input\n from keras.engine.training import Model\n-from keras.engine.training import Model\n from keras.engine.training import _check_loss_and_target_compatibility\n from keras.engine.training import _weighted_masked_objective\n from keras.engine.training import _check_array_lengths\n@@ -673,7 +673,7 @@ def test_model_with_partial_loss():\n \n @keras_test\n @pytest.mark.skipif((K.backend() == 'cntk'),\n-                    reason=\"cntk does not support external loss yet\")\n+                    reason='cntk does not support external loss yet')\n def test_model_with_external_loss():\n     # None loss, only regularization loss.\n     a = Input(shape=(3,), name='input_a')\n@@ -749,5 +749,64 @@ def test_model_with_external_loss():\n         assert out.shape == (10, 4)\n \n \n+@keras_test\n+def test_target_tensors():\n+    # single-output, as list\n+    model = keras.models.Sequential()\n+    model.add(keras.layers.Dense(4, input_shape=(4,), name='dense'))\n+    input_val = np.random.random((10, 4))\n+    target_val = np.random.random((10, 4))\n+    target = keras.backend.variable(target_val)\n+    model.compile(optimizer='rmsprop', loss='mse', target_tensors=[target])\n+    model.train_on_batch(input_val, None)\n+\n+    # single-output, as dict\n+    model.compile(optimizer='rmsprop', loss='mse',\n+                  target_tensors={'dense': target})\n+    model.train_on_batch(input_val, None)\n+\n+    # test invalid arguments\n+    with pytest.raises(TypeError):\n+        model.compile(optimizer='rmsprop', loss='mse',\n+                      target_tensors=set())\n+    with pytest.raises(ValueError):\n+        model.compile(optimizer='rmsprop', loss='mse',\n+                      target_tensors=[target, target])\n+    with pytest.raises(ValueError):\n+        model.compile(optimizer='rmsprop', loss='mse',\n+                      target_tensors={'dense2': None})\n+    with pytest.raises(ValueError):\n+        model.compile(optimizer='rmsprop', loss='mse',\n+                      target_tensors=[target])\n+        model.train_on_batch(input_val, target_val)\n+\n+    # multi-output, as list\n+    input_val = np.random.random((10, 4))\n+    target_val_a = np.random.random((10, 4))\n+    target_val_b = np.random.random((10, 4))\n+    target_a = keras.backend.variable(target_val_a)\n+    target_b = keras.backend.variable(target_val_b)\n+\n+    inputs = keras.layers.Input(shape=(4,))\n+    output_a = keras.layers.Dense(4, name='dense_a')(inputs)\n+    output_b = keras.layers.Dense(4, name='dense_b')(inputs)\n+    model = keras.models.Model(inputs, [output_a, output_b])\n+    model.compile(optimizer='rmsprop', loss='mse',\n+                  target_tensors=[target_a, target_b])\n+    model.train_on_batch(input_val, None)\n+\n+    # multi-output, as dict\n+    model.compile(optimizer='rmsprop', loss='mse',\n+                  target_tensors={'dense_a': target_a,\n+                                  'dense_b': target_b})\n+    model.train_on_batch(input_val, None)\n+\n+    # test with sample weights\n+    model.compile(optimizer='rmsprop', loss='mse',\n+                  target_tensors=[target_a, target_b])\n+    model.train_on_batch(input_val, None,\n+                         sample_weight={'dense_a': np.random.random((10,))})\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ec0e7667f9e4c4f18e4286df6027520fdc88d454", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 21 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 21 | Churn Cumulative: 133 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -39,6 +39,19 @@ def test_obtain_input_shape():\n \n     # Test invalid use cases\n     for data_format in ['channels_last', 'channels_first']:\n+\n+        # test warning\n+        shape = (139, 139)\n+        input_shape = shape + (99,) if data_format == 'channels_last' else (99,) + shape\n+        with pytest.warns(UserWarning):\n+            utils._obtain_input_shape(\n+                input_shape=input_shape,\n+                default_size=None,\n+                min_size=139,\n+                data_format=data_format,\n+                include_top=False,\n+                weights='fake_weights')\n+\n         # input_shape is smaller than min_size.\n         shape = (100, 100)\n         input_shape = shape + (3,) if data_format == 'channels_last' else (3,) + shape\n@@ -72,6 +85,14 @@ def test_obtain_input_shape():\n                 data_format=data_format,\n                 include_top=False)\n \n+    # test include top\n+    assert utils._obtain_input_shape(\n+        input_shape=None,\n+        default_size=None,\n+        min_size=139,\n+        data_format='channels_first',\n+        include_top=True,) == (3, None, None)\n+\n     assert utils._obtain_input_shape(\n         input_shape=None,\n         default_size=None,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e49916888d5099061bd73dc5aa1e86afe93589f5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 52 | Lines Deleted: 10 | Files Changed: 2 | Hunks: 14 | Methods Changed: 7 | Complexity Δ (Sum/Max): 4/3 | Churn Δ: 62 | Churn Cumulative: 8758 | Contributors (this commit): 50 | Commits (past 90d): 24 | Contributors (cumulative): 55 | DMM Complexity: 0.7857142857142857\n\nDIFF:\n@@ -310,6 +310,21 @@ class Layer(object):\n         else:\n             self._initial_weights = None\n \n+    @staticmethod\n+    def _node_key(layer, node_index):\n+        \"\"\"Converts a layer and its index to a unique (immutable type) name.\n+        This function is used internally with `self.container_nodes`.\n+\n+        # Arguments\n+            layer: The layer.\n+            node_index: The layer's position (e.g. via enumerate) in a list of\n+                nodes.\n+\n+        # Returns\n+            The unique name.\n+        \"\"\"\n+        return layer.name + '_ib-' + str(node_index)\n+\n     @property\n     def losses(self):\n         return self._losses\n@@ -1669,9 +1684,8 @@ class Container(Layer):\n             if node in finished_nodes:\n                 return\n \n-            node_key = layer.name + '_ib-' + str(node_index)\n             # Update container_nodes.\n-            container_nodes.add(node_key)\n+            container_nodes.add(self._node_key(layer, node_index))\n \n             # Store the traversal order for layer sorting.\n             if layer not in layer_indices:\n@@ -1871,7 +1885,7 @@ class Container(Layer):\n                 # Collect updates that are dependent on inputs\n                 # that are part of the model.\n                 for node_index, node in enumerate(layer.inbound_nodes):\n-                    node_key = layer.name + '_ib-' + str(node_index)\n+                    node_key = self._node_key(layer, node_index)\n                     if node_key in self.container_nodes:\n                         # The model owns this layer node.\n                         inputs = node.input_tensors\n@@ -1899,7 +1913,7 @@ class Container(Layer):\n                 # Collect losses that are dependent on inputs\n                 # that are part of the model.\n                 for node_index, node in enumerate(layer.inbound_nodes):\n-                    node_key = layer.name + '_ib-' + str(node_index)\n+                    node_key = self._node_key(layer, node_index)\n                     if node_key in self.container_nodes:\n                         # The model owns this layer node.\n                         inputs = node.input_tensors\n@@ -2286,6 +2300,10 @@ class Container(Layer):\n         config = {\n             'name': self.name,\n         }\n+\n+        # Build a map from a layer unique name (self._node_key)\n+        # to the index of the nodes that are saved in the config.\n+        # Only nodes in container_nodes are saved.\n         node_conversion_map = {}\n         for layer in self.layers:\n             if issubclass(layer.__class__, Container):\n@@ -2295,17 +2313,20 @@ class Container(Layer):\n             else:\n                 kept_nodes = 0\n             for original_node_index, node in enumerate(layer.inbound_nodes):\n-                node_key = layer.name + '_ib-' + str(original_node_index)\n+                node_key = self._node_key(layer, original_node_index)\n                 if node_key in self.container_nodes:\n+                    # i.e. we mark it to be saved\n                     node_conversion_map[node_key] = kept_nodes\n                     kept_nodes += 1\n+\n+        # serialize and save the layers in layer_configs\n         layer_configs = []\n         for layer in self.layers:  # From the earliest layers on.\n             layer_class_name = layer.__class__.__name__\n             layer_config = layer.get_config()\n             filtered_inbound_nodes = []\n             for original_node_index, node in enumerate(layer.inbound_nodes):\n-                node_key = layer.name + '_ib-' + str(original_node_index)\n+                node_key = self._node_key(layer, original_node_index)\n                 if node_key in self.container_nodes:\n                     # The node is relevant to the model:\n                     # add to filtered_inbound_nodes.\n@@ -2329,8 +2350,9 @@ class Container(Layer):\n                             inbound_layer = node.inbound_layers[i]\n                             node_index = node.node_indices[i]\n                             tensor_index = node.tensor_indices[i]\n-                            node_key = inbound_layer.name + '_ib-' + str(node_index)\n-                            new_node_index = node_conversion_map.get(node_key, 0)\n+\n+                            new_node_index = node_conversion_map.get(\n+                                self._node_key(inbound_layer, node_index), 0)\n                             node_data.append([inbound_layer.name,\n                                               new_node_index,\n                                               tensor_index,\n@@ -2349,7 +2371,10 @@ class Container(Layer):\n         for i in range(len(self.input_layers)):\n             layer = self.input_layers[i]\n             node_index = self.input_layers_node_indices[i]\n-            node_key = layer.name + '_ib-' + str(node_index)\n+\n+            node_key = self._node_key(layer, node_index)\n+            if node_key not in self.container_nodes:\n+                continue\n             new_node_index = node_conversion_map[node_key]\n             tensor_index = self.input_layers_tensor_indices[i]\n             model_inputs.append([layer.name, new_node_index, tensor_index])\n@@ -2358,7 +2383,10 @@ class Container(Layer):\n         for i in range(len(self.output_layers)):\n             layer = self.output_layers[i]\n             node_index = self.output_layers_node_indices[i]\n-            node_key = layer.name + '_ib-' + str(node_index)\n+\n+            node_key = self._node_key(layer, node_index)\n+            if node_key not in self.container_nodes:\n+                continue\n             new_node_index = node_conversion_map[node_key]\n             tensor_index = self.output_layers_tensor_indices[i]\n             model_outputs.append([layer.name, new_node_index, tensor_index])\n\n@@ -158,6 +158,20 @@ def test_saving_right_after_compilation():\n     os.remove(fname)\n \n \n+@keras_test\n+def test_saving_unused_layers_is_ok():\n+    a = Input(shape=(256, 512, 6))\n+    b = Input(shape=(256, 512, 1))\n+    c = Lambda(lambda x: x[:, :, :, :1])(a)\n+\n+    model = Model(inputs=[a, b], outputs=c)\n+\n+    _, fname = tempfile.mkstemp('.h5')\n+    save_model(model, fname)\n+    load_model(fname)\n+    os.remove(fname)\n+\n+\n @keras_test\n def test_loading_weights_by_name():\n     \"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
