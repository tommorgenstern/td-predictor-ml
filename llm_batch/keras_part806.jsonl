{"custom_id": "keras#61bbff593a0914f5a2c426c14caadb7372f56da0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 131 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 6 | Methods Changed: 8 | Complexity Δ (Sum/Max): 8/5 | Churn Δ: 131 | Churn Cumulative: 727 | Contributors (this commit): 4 | Commits (past 90d): 10 | Contributors (cumulative): 9 | DMM Complexity: 1.0\n\nDIFF:\n@@ -21,6 +21,7 @@ from keras.losses.losses import MeanSquaredLogarithmicError\n from keras.losses.losses import Poisson\n from keras.losses.losses import SparseCategoricalCrossentropy\n from keras.losses.losses import SquaredHinge\n+from keras.losses.losses import Tversky\n from keras.losses.losses import binary_crossentropy\n from keras.losses.losses import binary_focal_crossentropy\n from keras.losses.losses import categorical_crossentropy\n@@ -40,6 +41,7 @@ from keras.losses.losses import mean_squared_logarithmic_error\n from keras.losses.losses import poisson\n from keras.losses.losses import sparse_categorical_crossentropy\n from keras.losses.losses import squared_hinge\n+from keras.losses.losses import tversky\n from keras.saving import serialization_lib\n \n ALL_OBJECTS = {\n@@ -68,6 +70,7 @@ ALL_OBJECTS = {\n     CategoricalHinge,\n     # Image segmentation\n     Dice,\n+    Tversky,\n     # Probabilistic\n     kl_divergence,\n     poisson,\n@@ -90,6 +93,7 @@ ALL_OBJECTS = {\n     categorical_hinge,\n     # Image segmentation\n     dice,\n+    tversky,\n }\n \n ALL_OBJECTS_DICT = {cls.__name__: cls for cls in ALL_OBJECTS}\n\n@@ -2000,3 +2000,93 @@ def dice(y_true, y_pred):\n     )\n \n     return 1 - dice\n+\n+\n+@keras_export(\"keras.losses.Tversky\")\n+class Tversky(LossFunctionWrapper):\n+    \"\"\"Computes the Tversky loss value between `y_true` and `y_pred`.\n+\n+    This loss function is weighted by the alpha and beta coefficients\n+    that penalize false positives and false negatives.\n+\n+    With `alpha=0.5` and `beta=0.5`, the loss value becomes equivalent to\n+    Dice Loss.\n+\n+    Args:\n+        y_true: tensor of true targets.\n+        y_pred: tensor of predicted targets.\n+        alpha: coefficient controlling incidence of false positives.\n+        beta: coefficient controlling incidence of false negatives.\n+\n+    Returns:\n+        Tversky loss value.\n+\n+    Reference:\n+\n+    - [Salehi et al., 2017](https://arxiv.org/abs/1706.05721)\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        alpha=0.5,\n+        beta=0.5,\n+        reduction=\"sum_over_batch_size\",\n+        name=\"tversky\",\n+    ):\n+        super().__init__(\n+            tversky,\n+            alpha=alpha,\n+            beta=beta,\n+            name=name,\n+            reduction=reduction,\n+        )\n+        self.alpha = alpha\n+        self.beta = beta\n+\n+    def get_config(self):\n+        return {\n+            \"name\": self.name,\n+            \"alpha\": self.alpha,\n+            \"beta\": self.beta,\n+            \"reduction\": self.reduction,\n+        }\n+\n+\n+@keras_export(\"keras.losses.tversky\")\n+def tversky(y_true, y_pred, alpha=0.5, beta=0.5):\n+    \"\"\"Computes the Tversky loss value between `y_true` and `y_pred`.\n+\n+    This loss function is weighted by the alpha and beta coefficients\n+    that penalize false positives and false negatives.\n+\n+    With `alpha=0.5` and `beta=0.5`, the loss value becomes equivalent to\n+    Dice Loss.\n+\n+    Args:\n+        y_true: tensor of true targets.\n+        y_pred: tensor of predicted targets.\n+        alpha: coefficient controlling incidence of false positives.\n+        beta: coefficient controlling incidence of false negatives.\n+\n+    Returns:\n+        Tversky loss value.\n+\n+    Reference:\n+\n+    - [Salehi et al., 2017](https://arxiv.org/abs/1706.05721)\n+    \"\"\"\n+    y_pred = ops.convert_to_tensor(y_pred)\n+    y_true = ops.cast(y_true, y_pred.dtype)\n+\n+    inputs = ops.reshape(y_true, [-1])\n+    targets = ops.reshape(y_pred, [-1])\n+\n+    intersection = ops.sum(inputs * targets)\n+    fp = ops.sum((1 - targets) * inputs)\n+    fn = ops.sum(targets * (1 - inputs))\n+    tversky = ops.divide(\n+        intersection,\n+        intersection + fp * alpha + fn * beta + backend.epsilon(),\n+    )\n+\n+    return 1 - tversky\n\n@@ -1409,3 +1409,40 @@ class DiceTest(testing.TestCase):\n         )\n         output = losses.Dice()(y_true, y_pred)\n         self.assertAllClose(output, 0.77777773)\n+\n+\n+class TverskyTest(testing.TestCase):\n+    def test_config(self):\n+        self.run_class_serialization_test(losses.Tversky(name=\"mytversky\"))\n+\n+    def test_correctness(self):\n+        y_true = np.array(([[1, 2], [1, 2]]))\n+        y_pred = np.array(([[4, 1], [6, 1]]))\n+        output = losses.Tversky()(y_true, y_pred)\n+        self.assertAllClose(output, -0.55555546)\n+\n+    def test_correctness_custom_coefficients(self):\n+        y_true = np.array(([[1, 2], [1, 2]]))\n+        y_pred = np.array(([[4, 1], [6, 1]]))\n+        output = losses.Tversky(alpha=0.2, beta=0.8)(y_true, y_pred)\n+        self.assertAllClose(output, -0.29629636)\n+\n+    def test_binary_segmentation(self):\n+        y_true = np.array(\n+            ([[1, 0, 1, 0], [0, 1, 0, 1], [1, 0, 1, 0], [0, 1, 0, 1]])\n+        )\n+        y_pred = np.array(\n+            ([[0, 1, 0, 1], [1, 0, 1, 1], [0, 1, 0, 1], [1, 0, 1, 1]])\n+        )\n+        output = losses.Tversky()(y_true, y_pred)\n+        self.assertAllClose(output, 0.77777773)\n+\n+    def test_binary_segmentation_custom_coefficients(self):\n+        y_true = np.array(\n+            ([[1, 0, 1, 0], [0, 1, 0, 1], [1, 0, 1, 0], [0, 1, 0, 1]])\n+        )\n+        y_pred = np.array(\n+            ([[0, 1, 0, 1], [1, 0, 1, 1], [0, 1, 0, 1], [1, 0, 1, 1]])\n+        )\n+        output = losses.Tversky(alpha=0.2, beta=0.8)(y_true, y_pred)\n+        self.assertAllClose(output, 0.7916667)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6503b6d988a494e4785373917ada8b66031f5fef", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 1330 | Contributors (this commit): 7 | Commits (past 90d): 6 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -342,6 +342,10 @@ class KLDivergence(LossFunctionWrapper):\n     loss = y_true * log(y_true / y_pred)\n     ```\n \n+    `y_true` and `y_pred` are expected to be probability\n+    distributions, with values between 0 and 1. They will get\n+    clipped to the `[0, 1]` range.\n+\n     Args:\n         reduction: Type of reduction to apply to the loss. In almost all cases\n             this should be `\"sum_over_batch_size\"`.\n@@ -1443,6 +1447,10 @@ def kl_divergence(y_true, y_pred):\n     loss = y_true * log(y_true / y_pred)\n     ```\n \n+    `y_true` and `y_pred` are expected to be probability\n+    distributions, with values between 0 and 1. They will get\n+    clipped to the `[0, 1]` range.\n+\n     Args:\n         y_true: Tensor of true targets.\n         y_pred: Tensor of predicted targets.\n\n@@ -18,6 +18,10 @@ class KLDivergence(reduction_metrics.MeanMetricWrapper):\n     metric = y_true * log(y_true / y_pred)\n     ```\n \n+    `y_true` and `y_pred` are expected to be probability\n+    distributions, with values between 0 and 1. They will get\n+    clipped to the `[0, 1]` range.\n+\n     Args:\n         name: (Optional) string name of the metric instance.\n         dtype: (Optional) data type of the metric result.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6b9430d5f7b6d3ecbb1c35a37690a661759341b5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 41 | Lines Deleted: 25 | Files Changed: 3 | Hunks: 20 | Methods Changed: 12 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 66 | Churn Cumulative: 929 | Contributors (this commit): 10 | Commits (past 90d): 39 | Contributors (cumulative): 17 | DMM Complexity: 1.0\n\nDIFF:\n@@ -635,14 +635,19 @@ class Layer(BackendLayer, Operation):\n             return self.weights\n         return [v for v in self.weights if not v.trainable]\n \n+    @property\n+    def metrics(self):\n+        \"\"\"List of all metrics.\"\"\"\n+        metrics = list(self._metrics)\n+        for layer in self._layers:\n+            metrics.extend(layer.metrics)\n+        return metrics\n+\n     @property\n     def metrics_variables(self):\n         \"\"\"List of all metric variables.\"\"\"\n         vars = []\n-        for metric in self._metrics:\n-            vars.extend(metric.variables)\n-        for layer in self._layers:\n-            for metric in layer._metrics:\n+        for metric in self.metrics:\n             vars.extend(metric.variables)\n         return vars\n \n\n@@ -176,7 +176,7 @@ class LayerTest(testing.TestCase):\n         self.assertAllClose(layer.variables[1], [10, 1])\n \n     def test_layer_tracking(self):\n-        class NestedLayer(layers.Layer):\n+        class LayerWithDenseLayers(layers.Layer):\n             def __init__(self, units):\n                 super().__init__()\n                 self.dense1 = layers.Dense(units)\n@@ -185,6 +185,7 @@ class LayerTest(testing.TestCase):\n                 }\n                 self.layer_list = [layers.Dense(units)]\n                 self.units = units\n+                self.seed_generator = backend.random.SeedGenerator(seed=1)\n \n             def build(self, input_shape):\n                 self.layer_list.append(layers.Dense(self.units))\n@@ -196,24 +197,31 @@ class LayerTest(testing.TestCase):\n                 x = self.layer_list[1](x)\n                 return x\n \n-        class DoubleNestedLayer(layers.Layer):\n-            def __init__(self, units):\n+        class ParentLayer(layers.Layer):\n+            def __init__(self, inner_layer):\n                 super().__init__()\n-                self.inner_layer = NestedLayer(units)\n+                self.inner_layer = inner_layer\n \n             def call(self, x):\n                 return self.inner_layer(x)\n \n-        layer = NestedLayer(3)\n+        layer = LayerWithDenseLayers(3)\n         layer.build((1, 3))\n         self.assertLen(layer._layers, 4)\n         layer(np.zeros((1, 3)))\n+        self.assertLen(layer.variables, 9)\n         self.assertLen(layer.weights, 8)\n \n-        layer = DoubleNestedLayer(3)\n+        layer = ParentLayer(LayerWithDenseLayers(3))\n         self.assertLen(layer._layers, 1)\n         layer(np.zeros((1, 3)))\n-        self.assertLen(layer.inner_layer.weights, 8)\n+        self.assertLen(layer.variables, 9)\n+        self.assertLen(layer.weights, 8)\n+\n+        layer = ParentLayer(ParentLayer(LayerWithDenseLayers(3)))\n+        self.assertLen(layer._layers, 1)\n+        layer(np.zeros((1, 3)))\n+        self.assertLen(layer.variables, 9)\n         self.assertLen(layer.weights, 8)\n \n     def test_metric_tracking(self):\n@@ -229,32 +237,42 @@ class LayerTest(testing.TestCase):\n             def call(self, x):\n                 return self.dense(x)\n \n-        class NestedLayerWithMetric(layers.Layer):\n-            def __init__(self, units):\n+        class ParentLayerWithMetric(layers.Layer):\n+            def __init__(self, inner_layer):\n                 super().__init__()\n-                self.layer_with_metric = LayerWithMetric(units)\n+                self.inner_layer = inner_layer\n                 self.metric = metrics.MeanSquaredError(name=\"my_metric\")\n \n             def build(self, input_shape):\n-                self.layer_with_metric.build(input_shape)\n+                self.inner_layer.build(input_shape)\n \n             def call(self, x):\n-                return self.layer_with_metric(x)\n+                return self.inner_layer(x)\n \n         layer = LayerWithMetric(3)\n         layer.build((1, 3))\n \n+        self.assertLen(layer.metrics, 1)\n         self.assertLen(layer.metrics_variables, 2)\n         self.assertLen(layer.trainable_variables, 2)\n         self.assertLen(layer.non_trainable_variables, 0)\n \n-        layer = NestedLayerWithMetric(3)\n+        layer = ParentLayerWithMetric(LayerWithMetric(3))\n         layer.build((1, 3))\n \n+        self.assertLen(layer.metrics, 2)\n         self.assertLen(layer.metrics_variables, 4)\n         self.assertLen(layer.trainable_variables, 2)\n         self.assertLen(layer.non_trainable_variables, 0)\n \n+        layer = ParentLayerWithMetric(ParentLayerWithMetric(LayerWithMetric(3)))\n+        layer.build((1, 3))\n+\n+        self.assertLen(layer.metrics, 3)\n+        self.assertLen(layer.metrics_variables, 6)\n+        self.assertLen(layer.trainable_variables, 2)\n+        self.assertLen(layer.non_trainable_variables, 0)\n+\n     def test_build_on_call(self):\n         class LayerWithUnbuiltState(layers.Layer):\n             def __init__(self, units):\n\n@@ -242,7 +242,7 @@ class Trainer:\n     @property\n     def metrics(self):\n         metrics = [self._loss_tracker] if self.compiled else []\n-        metrics.extend(self._metrics[:])\n+        metrics.extend(super().metrics)\n         if self.compiled and self._compile_metrics is not None:\n             metrics += [self._compile_metrics]\n         return metrics\n@@ -251,13 +251,6 @@ class Trainer:\n     def metrics_names(self):\n         return [m.name for m in self.metrics]\n \n-    @property\n-    def metrics_variables(self):\n-        vars = []\n-        for metric in self.metrics:\n-            vars.extend(metric.variables)\n-        return vars\n-\n     def reset_metrics(self):\n         for m in self.metrics:\n             m.reset_state()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2ff3f94751bec84512ad6d0452799334c275aec0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 2580 | Contributors (this commit): 4 | Commits (past 90d): 3 | Contributors (cumulative): 6 | DMM Complexity: 0.0\n\nDIFF:\n@@ -115,10 +115,12 @@ class _IoUBase(Metric):\n                 self.ignore_class, y_true.dtype\n             )\n             valid_mask = ops.not_equal(y_true, ignore_class)\n-            y_true = y_true[valid_mask]\n-            y_pred = y_pred[valid_mask]\n+            y_true = y_true * ops.cast(valid_mask, y_true.dtype)\n+            y_pred = y_pred * ops.cast(valid_mask, y_pred.dtype)\n             if sample_weight is not None:\n-                sample_weight = sample_weight[valid_mask]\n+                sample_weight = sample_weight * ops.cast(\n+                    valid_mask, sample_weight.dtype\n+                )\n \n         y_pred = ops.cast(y_pred, dtype=self.dtype)\n         y_true = ops.cast(y_true, dtype=self.dtype)\n\n@@ -98,7 +98,7 @@ class IoUTest(testing.TestCase):\n \n     @pytest.mark.requires_trainable_backend\n     def test_compilation(self):\n-        m_obj = metrics.MeanIoU(num_classes=2)\n+        m_obj = metrics.MeanIoU(num_classes=2, ignore_class=0)\n         model = models.Sequential(\n             [\n                 layers.Dense(2, activation=\"softmax\"),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5b9992297398a7d7f5ed113747f074685081a2a4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 394 | Lines Deleted: 6 | Files Changed: 6 | Hunks: 8 | Methods Changed: 39 | Complexity Δ (Sum/Max): 36/12 | Churn Δ: 400 | Churn Cumulative: 15063 | Contributors (this commit): 22 | Commits (past 90d): 10 | Contributors (cumulative): 56 | DMM Complexity: 1.0\n\nDIFF:\n@@ -260,3 +260,71 @@ class CategoryEncodingTest(testing.TestCase, parameterized.TestCase):\n         for output in ds.take(1):\n             output = output.numpy()\n         self.assertAllClose(output, expected_output)\n+\n+    def test_category_encoding_without_num_tokens(self):\n+        with self.assertRaisesRegex(\n+            ValueError, r\"num_tokens must be set to use this layer\"\n+        ):\n+            layers.CategoryEncoding(output_mode=\"multi_hot\")\n+\n+    def test_category_encoding_with_invalid_num_tokens(self):\n+        with self.assertRaisesRegex(ValueError, r\"`num_tokens` must be >= 1\"):\n+            layers.CategoryEncoding(num_tokens=0, output_mode=\"multi_hot\")\n+\n+        with self.assertRaisesRegex(ValueError, r\"`num_tokens` must be >= 1\"):\n+            layers.CategoryEncoding(num_tokens=-1, output_mode=\"multi_hot\")\n+\n+    def test_category_encoding_with_unnecessary_count_weights(self):\n+        layer = layers.CategoryEncoding(num_tokens=4, output_mode=\"multi_hot\")\n+        input_data = np.array([0, 1, 2, 3])\n+        count_weights = np.array([0.1, 0.2, 0.3, 0.4])\n+        with self.assertRaisesRegex(\n+            ValueError, r\"`count_weights` is not used when `output_mode`\"\n+        ):\n+            layer(input_data, count_weights=count_weights)\n+\n+    def test_invalid_output_mode_raises_error(self):\n+        with self.assertRaisesRegex(\n+            ValueError, r\"Unknown arg for output_mode: invalid_mode\"\n+        ):\n+            layers.CategoryEncoding(num_tokens=4, output_mode=\"invalid_mode\")\n+\n+    def test_encode_one_hot_single_sample(self):\n+        layer = layers.CategoryEncoding(num_tokens=4, output_mode=\"one_hot\")\n+        input_array = np.array([1, 2, 3, 1])\n+        expected_output = np.array(\n+            [\n+                [0, 1, 0, 0],\n+                [0, 0, 1, 0],\n+                [0, 0, 0, 1],\n+                [0, 1, 0, 0],\n+            ]\n+        )\n+        output = layer._encode(input_array)\n+        self.assertAllClose(expected_output, output)\n+\n+    def test_encode_one_hot_batched_samples(self):\n+        layer = layers.CategoryEncoding(num_tokens=4, output_mode=\"one_hot\")\n+        input_array = np.array([[3, 2, 0, 1], [3, 2, 0, 1]])\n+        expected_output = np.array(\n+            [\n+                [[0, 0, 0, 1], [0, 0, 1, 0], [1, 0, 0, 0], [0, 1, 0, 0]],\n+                [[0, 0, 0, 1], [0, 0, 1, 0], [1, 0, 0, 0], [0, 1, 0, 0]],\n+            ]\n+        )\n+        output = layer._encode(input_array)\n+        self.assertAllClose(expected_output, output)\n+\n+    def test_count_single_sample(self):\n+        layer = layers.CategoryEncoding(num_tokens=4, output_mode=\"count\")\n+        input_array = np.array([1, 2, 3, 1])\n+        expected_output = np.array([0, 2, 1, 1])\n+        output = layer._count(input_array)\n+        self.assertAllClose(expected_output, output)\n+\n+    def test_count_batched_samples(self):\n+        layer = layers.CategoryEncoding(num_tokens=4, output_mode=\"count\")\n+        input_array = np.array([[1, 2, 3, 1], [0, 3, 1, 0]])\n+        expected_output = np.array([[0, 2, 1, 1], [2, 1, 0, 1]])\n+        output = layer._count(input_array)\n+        self.assertAllClose(expected_output, output)\n\n@@ -393,6 +393,43 @@ class HashingTest(testing.TestCase, parameterized.TestCase):\n             expected, backend.convert_to_numpy(out_data).tolist()\n         )\n \n+    def test_hashing_invalid_num_bins(self):\n+        # Test with `num_bins` set to None\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"The `num_bins` for `Hashing` cannot be `None` or non-positive\",\n+        ):\n+            layers.Hashing(num_bins=None)\n+\n+        # Test with `num_bins` set to 0\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"The `num_bins` for `Hashing` cannot be `None` or non-positive\",\n+        ):\n+            layers.Hashing(num_bins=0)\n+\n+    def test_hashing_invalid_output_mode(self):\n+        # Test with an unsupported `output_mode`\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"Invalid value for argument `output_mode`. Expected one of\",\n+        ):\n+            layers.Hashing(num_bins=3, output_mode=\"unsupported_mode\")\n+\n+    def test_hashing_invalid_dtype_for_int_mode(self):\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            'When `output_mode=\"int\"`, `dtype` should be an integer type,',\n+        ):\n+            layers.Hashing(num_bins=3, output_mode=\"int\", dtype=\"float32\")\n+\n+    def test_hashing_sparse_with_int_mode(self):\n+        # Test setting `sparse=True` with `output_mode='int'`\n+        with self.assertRaisesRegex(\n+            ValueError, \"`sparse` may only be true if `output_mode` is\"\n+        ):\n+            layers.Hashing(num_bins=3, output_mode=\"int\", sparse=True)\n+\n \n # TODO: support tf.RaggedTensor.\n # def test_hash_ragged_string_input_farmhash(self):\n\n@@ -427,3 +427,193 @@ class IndexLookupLayerTest(testing.TestCase, parameterized.TestCase):\n         self.assertEqual(list(output), [2, 3, 1])\n         if backend.backend() != \"torch\":\n             self.run_class_serialization_test(layer)\n+\n+    def test_max_tokens_less_than_two(self):\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"If set, `max_tokens` must be greater than 1.\",\n+        ):\n+            layers.IndexLookup(\n+                max_tokens=1,\n+                num_oov_indices=1,\n+                mask_token=None,\n+                oov_token=None,\n+                vocabulary_dtype=\"int64\",\n+            )\n+\n+    def test_max_tokens_none_with_pad_to_max_tokens(self):\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"If pad_to_max_tokens is True, must set `max_tokens`.\",\n+        ):\n+            layers.IndexLookup(\n+                num_oov_indices=1,\n+                max_tokens=None,\n+                mask_token=None,\n+                oov_token=None,\n+                vocabulary_dtype=\"int64\",\n+                pad_to_max_tokens=True,\n+            )\n+\n+    def test_negative_num_oov_indices(self):\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"`num_oov_indices` must be greater than or equal to 0.\",\n+        ):\n+            layers.IndexLookup(\n+                max_tokens=10,\n+                num_oov_indices=-1,\n+                mask_token=None,\n+                oov_token=None,\n+                vocabulary_dtype=\"int64\",\n+            )\n+\n+    def test_invert_with_non_int_output_mode(self):\n+        with self.assertRaisesRegex(\n+            ValueError, r\"`output_mode` must be `'int'` when `invert` is true.\"\n+        ):\n+            layers.IndexLookup(\n+                num_oov_indices=1,\n+                max_tokens=None,\n+                mask_token=None,\n+                oov_token=None,\n+                vocabulary_dtype=\"string\",\n+                invert=True,\n+                output_mode=\"one_hot\",  # Invalid combination\n+            )\n+\n+    def test_sparse_true_with_int_output_mode(self):\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            r\"`sparse` may only be true if `output_mode` is `'one_hot'`\",\n+        ):\n+            layers.IndexLookup(\n+                num_oov_indices=1,\n+                max_tokens=None,\n+                mask_token=None,\n+                oov_token=None,\n+                vocabulary_dtype=\"string\",\n+                sparse=True,\n+                output_mode=\"int\",  # Invalid combination\n+            )\n+\n+    def test_idf_weights_set_with_non_tfidf_output_mode(self):\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            r\"`idf_weights` should only be set if `output_mode` is `'tf_idf'`\",\n+        ):\n+            layers.IndexLookup(\n+                num_oov_indices=1,\n+                max_tokens=None,\n+                mask_token=None,\n+                oov_token=None,\n+                vocabulary_dtype=\"string\",\n+                idf_weights=[\n+                    0.5,\n+                    0.1,\n+                    0.3,\n+                ],  # Should not be set for non-TF-IDF modes\n+                output_mode=\"int\",\n+            )\n+\n+    def test_unrecognized_kwargs(self):\n+        with self.assertRaisesRegex(\n+            ValueError, \"Unrecognized keyword argument\"\n+        ):\n+            layers.IndexLookup(\n+                num_oov_indices=1,\n+                max_tokens=None,\n+                mask_token=None,\n+                oov_token=None,\n+                vocabulary_dtype=\"string\",\n+                output_mode=\"int\",\n+                # This is an unrecognized argument\n+                extra_arg=True,\n+            )\n+\n+    def test_non_tf_idf_with_idf_weights(self):\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"`idf_weights` should only be set if `output_mode` is\",\n+        ):\n+            layers.IndexLookup(\n+                num_oov_indices=1,\n+                max_tokens=None,\n+                mask_token=None,\n+                oov_token=None,\n+                vocabulary_dtype=\"string\",\n+                output_mode=\"multi_hot\",\n+                idf_weights=[\n+                    0.5,\n+                    0.1,\n+                    0.3,\n+                ],  # idf_weights not valid for multi_hot mode\n+            )\n+\n+    def test_vocabulary_file_does_not_exist(self):\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"Vocabulary file path/to/missing_vocab.txt does not exist\",\n+        ):\n+            layers.IndexLookup(\n+                num_oov_indices=1,\n+                max_tokens=None,\n+                mask_token=None,\n+                oov_token=None,\n+                vocabulary_dtype=\"string\",\n+                output_mode=\"int\",\n+                # Nonexistent file path\n+                vocabulary=\"path/to/missing_vocab.txt\",\n+            )\n+\n+    def test_repeated_tokens_in_vocabulary(self):\n+        with self.assertRaisesRegex(\n+            ValueError, \"The passed vocabulary has at least one repeated term.\"\n+        ):\n+            layers.IndexLookup(\n+                num_oov_indices=1,\n+                max_tokens=None,\n+                mask_token=None,\n+                oov_token=None,\n+                vocabulary_dtype=\"string\",\n+                vocabulary=[\"token\", \"token\", \"unique\"],\n+            )\n+\n+    def test_mask_token_in_wrong_position(self):\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"Found reserved mask token at unexpected location in `vocabulary`.\",\n+        ):\n+            layers.IndexLookup(\n+                num_oov_indices=1,\n+                max_tokens=None,\n+                mask_token=\"mask\",\n+                oov_token=None,\n+                vocabulary_dtype=\"string\",\n+                vocabulary=[\n+                    \"token\",\n+                    \"mask\",\n+                    \"unique\",\n+                ],  # 'mask' should be at the start if included explicitly\n+            )\n+\n+    def test_ensure_known_vocab_size_without_vocabulary(self):\n+        kwargs = {\n+            \"num_oov_indices\": 1,\n+            # Assume empty string or some default token is valid.\n+            \"mask_token\": \"\",\n+            # Assume [OOV] or some default token is valid.\n+            \"oov_token\": \"[OOV]\",\n+            \"output_mode\": \"multi_hot\",\n+            \"pad_to_max_tokens\": False,\n+            \"vocabulary_dtype\": \"string\",\n+            \"max_tokens\": None,\n+        }\n+        layer = layers.IndexLookup(**kwargs)\n+\n+        # Try calling the layer without setting the vocabulary.\n+        with self.assertRaisesRegex(\n+            RuntimeError, \"When using `output_mode=multi_hot` and\"\n+        ):\n+            input_data = [\"sample\", \"data\"]\n+            layer(input_data)\n\n@@ -91,10 +91,6 @@ class NormalizationTest(testing.TestCase, parameterized.TestCase):\n         self.assertAllClose(np.var(output, axis=(0, 3)), 1.0, atol=1e-5)\n         self.assertAllClose(np.mean(output, axis=(0, 3)), 0.0, atol=1e-5)\n \n-    def test_normalization_errors(self):\n-        # TODO\n-        pass\n-\n     @pytest.mark.skipif(\n         backend.backend() != \"torch\",\n         reason=\"Test symbolic call for torch meta device.\",\n@@ -107,3 +103,44 @@ class NormalizationTest(testing.TestCase, parameterized.TestCase):\n         layer.adapt(data)\n         with core.device_scope(\"meta\"):\n             layer(data)\n+\n+    def test_normalization_with_mean_only_raises_error(self):\n+        # Test error when only `mean` is provided\n+        with self.assertRaisesRegex(\n+            ValueError, \"both `mean` and `variance` must be set\"\n+        ):\n+            layers.Normalization(mean=0.5)\n+\n+    def test_normalization_with_variance_only_raises_error(self):\n+        # Test error when only `variance` is provided\n+        with self.assertRaisesRegex(\n+            ValueError, \"both `mean` and `variance` must be set\"\n+        ):\n+            layers.Normalization(variance=0.1)\n+\n+    def test_normalization_axis_too_high(self):\n+        with self.assertRaisesRegex(\n+            ValueError, \"All `axis` values must be in the range\"\n+        ):\n+            layer = layers.Normalization(axis=3)\n+            layer.build((2, 2))\n+\n+    def test_normalization_axis_too_low(self):\n+        with self.assertRaisesRegex(\n+            ValueError, \"All `axis` values must be in the range\"\n+        ):\n+            layer = layers.Normalization(axis=-4)\n+            layer.build((2, 3, 4))\n+\n+    def test_normalization_unknown_axis_shape(self):\n+        with self.assertRaisesRegex(ValueError, \"All `axis` values to be kept\"):\n+            layer = layers.Normalization(axis=1)\n+            layer.build((None, None))\n+\n+    def test_normalization_adapt_with_incompatible_shape(self):\n+        layer = layers.Normalization(axis=-1)\n+        initial_shape = (10, 5)\n+        layer.build(initial_shape)\n+        new_shape_data = np.random.random((10, 3))\n+        with self.assertRaisesRegex(ValueError, \"an incompatible shape\"):\n+            layer.adapt(new_shape_data)\n\n@@ -80,12 +80,12 @@ class RandomBrightness(TFDataLayer):\n     def _set_value_range(self, value_range):\n         if not isinstance(value_range, (tuple, list)):\n             raise ValueError(\n-                self.value_range_VALIDATION_ERROR\n+                self._VALUE_RANGE_VALIDATION_ERROR\n                 + f\"Received: value_range={value_range}\"\n             )\n         if len(value_range) != 2:\n             raise ValueError(\n-                self.value_range_VALIDATION_ERROR\n+                self._VALUE_RANGE_VALIDATION_ERROR\n                 + f\"Received: value_range={value_range}\"\n             )\n         self.value_range = sorted(value_range)\n\n@@ -58,3 +58,59 @@ class RandomBrightnessTest(testing.TestCase):\n         ds = tf_data.Dataset.from_tensor_slices(input_data).batch(2).map(layer)\n         for output in ds.take(1):\n             output.numpy()\n+\n+    def test_value_range_incorrect_type(self):\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"The `value_range` argument should be a list of two numbers.*\",\n+        ):\n+            layers.RandomBrightness(factor=0.1, value_range=\"incorrect_type\")\n+\n+    def test_value_range_incorrect_length(self):\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"The `value_range` argument should be a list of two numbers.*\",\n+        ):\n+            layers.RandomBrightness(factor=0.1, value_range=[10])\n+\n+    def test_set_factor_incorrect_length(self):\n+        layer = layers.RandomBrightness(factor=0.5)\n+        with self.assertRaisesRegex(\n+            ValueError, \"The `factor` argument should be a number.*\"\n+        ):\n+            layer._set_factor([0.1])  # Only one element in list\n+\n+    def test_set_factor_incorrect_type(self):\n+        layer = layers.RandomBrightness(factor=0.5)\n+        with self.assertRaisesRegex(\n+            ValueError, \"The `factor` argument should be a number.*\"\n+        ):\n+            layer._set_factor(\n+                \"invalid_type\"\n+            )  # Passing a string instead of a number or a list/tuple of numbers\n+\n+    def test_factor_range_below_lower_bound(self):\n+        with self.assertRaisesRegex(\n+            ValueError, \"The `factor` argument should be a number.*\"\n+        ):\n+            # Passing a value less than -1.0\n+            layers.RandomBrightness(factor=-1.1)\n+\n+    def test_factor_range_above_upper_bound(self):\n+        with self.assertRaisesRegex(\n+            ValueError, \"The `factor` argument should be a number.*\"\n+        ):\n+            # Passing a value more than 1.0\n+            layers.RandomBrightness(factor=1.1)\n+\n+    def test_randomly_adjust_brightness_input_incorrect_rank(self):\n+        layer = layers.RandomBrightness(factor=0.1)\n+        wrong_rank_input = np.random.rand(10, 10)\n+\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"Expected the input image to be rank 3 or 4.\",\n+        ):\n+            layer(\n+                wrong_rank_input, training=True\n+            )  # Call the method that triggers the error\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d33b5852b9f8ef7a8fe6c69ee2eae566fe6b7bf2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 16 | Churn Cumulative: 441 | Contributors (this commit): 5 | Commits (past 90d): 3 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -4,6 +4,7 @@ import pytest\n from keras import backend\n from keras import initializers\n from keras import layers\n+from keras import models\n from keras import testing\n \n \n@@ -66,3 +67,18 @@ class SpectralNormalizationTest(testing.TestCase):\n         self.assertAllClose(result, expected_output)\n         # max eigen value of 2x2 matrix of ones is 2\n         self.assertAllClose(result_train, expected_output / 2)\n+\n+    def test_end_to_end(self):\n+        sn_wrapper = layers.SpectralNormalization(\n+            layers.Conv2D(\n+                3,\n+                (2, 2),\n+                padding=\"same\",\n+            ),\n+            power_iterations=2,\n+        )\n+        model = models.Sequential([sn_wrapper])\n+        model.compile(\"rmsprop\", loss=\"mse\")\n+        x = np.random.random((4, 8, 8, 3))\n+        y = np.random.random((4, 8, 8, 3))\n+        model.fit(x, y)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a4e27166eaa58b35667aedac6e2ff5c38bf9c3b0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 442 | Contributors (this commit): 5 | Commits (past 90d): 4 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -68,6 +68,7 @@ class SpectralNormalizationTest(testing.TestCase):\n         # max eigen value of 2x2 matrix of ones is 2\n         self.assertAllClose(result_train, expected_output / 2)\n \n+    @pytest.mark.requires_trainable_backend\n     def test_end_to_end(self):\n         sn_wrapper = layers.SpectralNormalization(\n             layers.Conv2D(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#344b3e3f4d03b2b76dbdfd231cecb70f6bb94ed1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 443 | Contributors (this commit): 5 | Commits (past 90d): 5 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -75,6 +75,7 @@ class SpectralNormalizationTest(testing.TestCase):\n                 3,\n                 (2, 2),\n                 padding=\"same\",\n+                data_format=\"channels_last\"\n             ),\n             power_iterations=2,\n         )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#559f1dd9ff3ccaedc22e217c2564964f0a119828", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 448 | Contributors (this commit): 5 | Commits (past 90d): 6 | Contributors (cumulative): 5 | DMM Complexity: 0.0\n\nDIFF:\n@@ -72,10 +72,7 @@ class SpectralNormalizationTest(testing.TestCase):\n     def test_end_to_end(self):\n         sn_wrapper = layers.SpectralNormalization(\n             layers.Conv2D(\n-                3,\n-                (2, 2),\n-                padding=\"same\",\n-                data_format=\"channels_last\"\n+                3, (2, 2), padding=\"same\", data_format=\"channels_last\"\n             ),\n             power_iterations=2,\n         )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1937d487b0ee4cf265051c7bd0524f2fd1a2cb51", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6846 | Lines Deleted: 3466 | Files Changed: 751 | Hunks: 943 | Methods Changed: 145 | Complexity Δ (Sum/Max): 19763/895 | Churn Δ: 10312 | Churn Cumulative: 17151 | Contributors (this commit): 76 | Commits (past 90d): 774 | Contributors (cumulative): 915 | DMM Complexity: 0.8292682926829268\n\nDIFF:\n@@ -0,0 +1,175 @@\n+\"\"\"Script to generate keras public API in `keras/api` directory.\n+\n+Usage:\n+\n+Run via `./shell/api_gen.sh`.\n+It generates API and formats user and generated APIs.\n+\"\"\"\n+\n+import os\n+import shutil\n+\n+import namex\n+\n+package = \"keras\"\n+\n+\n+def ignore_files(_, filenames):\n+    return [f for f in filenames if f.endswith(\"_test.py\")]\n+\n+\n+def create_legacy_directory():\n+    API_DIR = os.path.join(package, \"api\")\n+    # Make keras/_tf_keras/ by copying keras/\n+    tf_keras_dirpath_parent = os.path.join(API_DIR, \"_tf_keras\")\n+    tf_keras_dirpath = os.path.join(tf_keras_dirpath_parent, \"keras\")\n+    os.makedirs(tf_keras_dirpath, exist_ok=True)\n+    with open(os.path.join(tf_keras_dirpath_parent, \"__init__.py\"), \"w\") as f:\n+        f.write(\"from keras.api._tf_keras import keras\\n\")\n+    with open(os.path.join(API_DIR, \"__init__.py\")) as f:\n+        init_file = f.read()\n+        init_file = init_file.replace(\n+            \"from keras.api import _legacy\",\n+            \"from keras.api import _tf_keras\",\n+        )\n+    with open(os.path.join(API_DIR, \"__init__.py\"), \"w\") as f:\n+        f.write(init_file)\n+    # Remove the import of `_tf_keras` in `keras/_tf_keras/keras/__init__.py`\n+    init_file = init_file.replace(\"from keras.api import _tf_keras\\n\", \"\\n\")\n+    with open(os.path.join(tf_keras_dirpath, \"__init__.py\"), \"w\") as f:\n+        f.write(init_file)\n+    for dirname in os.listdir(API_DIR):\n+        dirpath = os.path.join(API_DIR, dirname)\n+        if os.path.isdir(dirpath) and dirname not in (\n+            \"_legacy\",\n+            \"_tf_keras\",\n+            \"src\",\n+        ):\n+            destpath = os.path.join(tf_keras_dirpath, dirname)\n+            if os.path.exists(destpath):\n+                shutil.rmtree(destpath)\n+            shutil.copytree(\n+                dirpath,\n+                destpath,\n+                ignore=ignore_files,\n+            )\n+\n+    # Copy keras/_legacy/ file contents to keras/_tf_keras/keras\n+    legacy_submodules = [\n+        path[:-3]\n+        for path in os.listdir(os.path.join(package, \"src\", \"legacy\"))\n+        if path.endswith(\".py\")\n+    ]\n+    legacy_submodules += [\n+        path\n+        for path in os.listdir(os.path.join(package, \"src\", \"legacy\"))\n+        if os.path.isdir(os.path.join(package, \"src\", \"legacy\", path))\n+    ]\n+\n+    for root, _, fnames in os.walk(os.path.join(package, \"_legacy\")):\n+        for fname in fnames:\n+            if fname.endswith(\".py\"):\n+                legacy_fpath = os.path.join(root, fname)\n+                tf_keras_root = root.replace(\"/_legacy\", \"/_tf_keras/keras\")\n+                core_api_fpath = os.path.join(\n+                    root.replace(\"/_legacy\", \"\"), fname\n+                )\n+                if not os.path.exists(tf_keras_root):\n+                    os.makedirs(tf_keras_root)\n+                tf_keras_fpath = os.path.join(tf_keras_root, fname)\n+                with open(legacy_fpath) as f:\n+                    legacy_contents = f.read()\n+                    legacy_contents = legacy_contents.replace(\n+                        \"keras.api._legacy\", \"keras.api._tf_keras.keras\"\n+                    )\n+                if os.path.exists(core_api_fpath):\n+                    with open(core_api_fpath) as f:\n+                        core_api_contents = f.read()\n+                    core_api_contents = core_api_contents.replace(\n+                        \"from keras.api import _tf_keras\\n\", \"\"\n+                    )\n+                    for legacy_submodule in legacy_submodules:\n+                        core_api_contents = core_api_contents.replace(\n+                            f\"from keras.api import {legacy_submodule}\\n\",\n+                            \"\",\n+                        )\n+                        core_api_contents = core_api_contents.replace(\n+                            f\"keras.api.{legacy_submodule}\",\n+                            f\"keras.api._tf_keras.keras.{legacy_submodule}\",\n+                        )\n+                    legacy_contents = core_api_contents + \"\\n\" + legacy_contents\n+                with open(tf_keras_fpath, \"w\") as f:\n+                    f.write(legacy_contents)\n+\n+    # Delete keras/api/_legacy/\n+    shutil.rmtree(os.path.join(API_DIR, \"_legacy\"))\n+\n+\n+def export_version_string():\n+    API_INIT = os.path.join(package, \"api\", \"__init__.py\")\n+    with open(API_INIT) as f:\n+        contents = f.read()\n+    with open(API_INIT, \"w\") as f:\n+        contents += \"from keras.src.version import __version__\\n\"\n+        f.write(contents)\n+\n+\n+def update_package_init():\n+    contents = \"\"\"\n+# Import everything from /api/ into keras.\n+from keras.api import *  # noqa: F403\n+from keras.api import __version__  # Import * ignores names start with \"_\".\n+\n+import os\n+\n+# Add everything in /api/ to the module search path.\n+__path__.append(os.path.join(os.path.dirname(__file__), \"api\"))  # noqa: F405\n+\n+# Don't pollute namespace.\n+del os\n+\n+# Never autocomplete `.src` or `.api` on an imported keras object.\n+def __dir__():\n+    keys = dict.fromkeys((globals().keys()))\n+    keys.pop(\"src\")\n+    keys.pop(\"api\")\n+    return list(keys)\n+\n+\n+# Don't import `.src` or `.api` during `from keras import *`.\n+__all__ = [\n+    name\n+    for name in globals().keys()\n+    if not (name.startswith(\"_\") or name in (\"src\", \"api\"))\n+]\"\"\"\n+    with open(os.path.join(package, \"__init__.py\")) as f:\n+        init_contents = f.read()\n+    with open(os.path.join(package, \"__init__.py\"), \"w\") as f:\n+        f.write(init_contents.replace(\"\\nfrom keras import api\", contents))\n+\n+\n+if __name__ == \"__main__\":\n+    # Backup the `keras/__init__.py` and restore it on error in api gen.\n+    os.makedirs(os.path.join(package, \"api\"), exist_ok=True)\n+    init_fname = os.path.join(package, \"__init__.py\")\n+    backup_init_fname = os.path.join(package, \"__init__.py.bak\")\n+    try:\n+        if os.path.exists(init_fname):\n+            shutil.move(init_fname, backup_init_fname)\n+        # Generates `keras/api` directory.\n+        namex.generate_api_files(\n+            \"keras\", code_directory=\"src\", target_directory=\"api\"\n+        )\n+        # Creates `keras/__init__.py` importing from `keras/api`\n+        update_package_init()\n+    except Exception as e:\n+        if os.path.exists(backup_init_fname):\n+            shutil.move(backup_init_fname, init_fname)\n+        raise e\n+    finally:\n+        if os.path.exists(backup_init_fname):\n+            os.remove(backup_init_fname)\n+    # Add __version__ to keras package\n+    export_version_string()\n+    # Creates `_tf_keras` with full keras API\n+    create_legacy_directory()\n\n@@ -14,7 +14,7 @@ except ImportError:\n \n import pytest  # noqa: E402\n \n-from keras.backend import backend  # noqa: E402\n+from keras.src.backend import backend  # noqa: E402\n \n \n def pytest_configure(config):\n\n@@ -2,11 +2,11 @@ import numpy as np\n import pytest\n \n import keras\n-from keras import layers\n-from keras import losses\n-from keras import metrics\n-from keras import optimizers\n-from keras import testing\n+from keras.src import layers\n+from keras.src import losses\n+from keras.src import metrics\n+from keras.src import optimizers\n+from keras.src import testing\n \n \n class MyModel(keras.Model):\n\n@@ -1,5 +1,5 @@\n-from keras import testing\n-from keras.datasets import boston_housing\n+from keras.src import testing\n+from keras.src.datasets import boston_housing\n \n \n class BostonHousingTest(testing.TestCase):\n\n@@ -1,5 +1,5 @@\n-from keras import testing\n-from keras.datasets import california_housing\n+from keras.src import testing\n+from keras.src.datasets import california_housing\n \n \n class CaliforniaHousingTest(testing.TestCase):\n\n@@ -1,7 +1,7 @@\n import numpy as np\n \n-from keras import testing\n-from keras.datasets import cifar100\n+from keras.src import testing\n+from keras.src.datasets import cifar100\n \n \n class Cifar100LoadDataTest(testing.TestCase):\n\n@@ -1,7 +1,7 @@\n import numpy as np\n \n-from keras import testing\n-from keras.datasets import cifar10\n+from keras.src import testing\n+from keras.src.datasets import cifar10\n \n \n class Cifar10LoadDataTest(testing.TestCase):\n\n@@ -1,7 +1,7 @@\n import numpy as np\n \n-from keras import testing\n-from keras.datasets import fashion_mnist\n+from keras.src import testing\n+from keras.src.datasets import fashion_mnist\n \n \n class FashionMnistLoadDataTest(testing.TestCase):\n\n@@ -1,7 +1,7 @@\n import numpy as np\n \n-from keras import testing\n-from keras.datasets import imdb\n+from keras.src import testing\n+from keras.src.datasets import imdb\n \n \n class ImdbLoadDataTest(testing.TestCase):\n\n@@ -1,7 +1,7 @@\n import numpy as np\n \n-from keras import testing\n-from keras.datasets import mnist\n+from keras.src import testing\n+from keras.src.datasets import mnist\n \n \n class MnistLoadDataTest(testing.TestCase):\n\n@@ -1,7 +1,7 @@\n import numpy as np\n \n-from keras import testing\n-from keras.datasets import reuters\n+from keras.src import testing\n+from keras.src.datasets import reuters\n \n \n class ReutersLoadDataTest(testing.TestCase):\n\n@@ -2,12 +2,16 @@ import os\n import re\n import subprocess\n \n-from keras import backend\n+from keras.src import backend\n \n+# For torch, use index url to avoid installing nvidia drivers for the test.\n BACKEND_REQ = {\n-    \"tensorflow\": \"tensorflow\",\n-    \"torch\": \"torch torchvision\",\n-    \"jax\": \"jax jaxlib\",\n+    \"tensorflow\": (\"tensorflow-cpu\", \"\"),\n+    \"torch\": (\n+        \"torch torchvision\",\n+        \"--extra-index-url https://download.pytorch.org/whl/cpu \",\n+    ),\n+    \"jax\": (\"jax[cpu]\", \"\"),\n }\n \n \n@@ -43,16 +47,17 @@ def create_virtualenv():\n \n def manage_venv_installs(whl_path):\n     other_backends = list(set(BACKEND_REQ.keys()) - {backend.backend()})\n+    backend_pkg, backend_extra_url = BACKEND_REQ[backend.backend()]\n     install_setup = [\n         # Installs the backend's package and common requirements\n-        \"pip install \" + BACKEND_REQ[backend.backend()],\n+        \"pip install \" + backend_extra_url + backend_pkg,\n         \"pip install -r requirements-common.txt\",\n         \"pip install pytest\",\n         # Ensure other backends are uninstalled\n         \"pip uninstall -y \"\n-        + BACKEND_REQ[other_backends[0]]\n+        + BACKEND_REQ[other_backends[0]][0]\n         + \" \"\n-        + BACKEND_REQ[other_backends[1]],\n+        + BACKEND_REQ[other_backends[1]][0],\n         # Install `.whl` package\n         \"pip install \" + whl_path,\n     ]\n\n@@ -1,5 +1,5 @@\n import keras\n-from keras.utils import plot_model\n+from keras.src.utils import plot_model\n \n \n def plot_sequential_model():\n\n@@ -2,12 +2,12 @@ import numpy as np\n import tensorflow as tf\n \n import keras\n-from keras import layers\n-from keras import losses\n-from keras import metrics\n-from keras import models\n-from keras import optimizers\n-from keras.callbacks import LearningRateScheduler\n+from keras.src import layers\n+from keras.src import losses\n+from keras.src import metrics\n+from keras.src import models\n+from keras.src import optimizers\n+from keras.src.callbacks import LearningRateScheduler\n \n \n def test_model_fit():\n\n@@ -1,8 +1,8 @@\n import torch\n \n-from keras import layers\n-from keras import testing\n-from keras.backend.common import KerasVariable\n+from keras.src import layers\n+from keras.src import testing\n+from keras.src.backend.common import KerasVariable\n \n \n class Net(torch.nn.Module):\n\n@@ -1,19 +1,33 @@\n-from keras import activations\n-from keras import applications\n-from keras import backend\n-from keras import constraints\n-from keras import datasets\n-from keras import initializers\n-from keras import layers\n-from keras import models\n-from keras import ops\n-from keras import optimizers\n-from keras import regularizers\n-from keras import utils\n-from keras.backend import KerasTensor\n-from keras.layers import Input\n-from keras.layers import Layer\n-from keras.models import Functional\n-from keras.models import Model\n-from keras.models import Sequential\n-from keras.version import __version__\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+import os\n+\n+# Import everything from /api/ into keras.\n+from keras.api import *  # noqa: F403\n+from keras.api import __version__  # Import * ignores names start with \"_\".\n+\n+# Add everything in /api/ to the module search path.\n+__path__.append(os.path.join(os.path.dirname(__file__), \"api\"))  # noqa: F405\n+\n+# Don't pollute namespace.\n+del os\n+\n+\n+# Never autocomplete `.src` or `.api` on an imported keras object.\n+def __dir__():\n+    keys = dict.fromkeys((globals().keys()))\n+    keys.pop(\"src\")\n+    keys.pop(\"api\")\n+    return list(keys)\n+\n+\n+# Don't import `.src` or `.api` during `from keras import *`.\n+__all__ = [\n+    name\n+    for name in globals().keys()\n+    if not (name.startswith(\"_\") or name in (\"src\", \"api\"))\n+]\n\n@@ -0,0 +1,58 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.api import _tf_keras\n+from keras.api import activations\n+from keras.api import applications\n+from keras.api import backend\n+from keras.api import callbacks\n+from keras.api import config\n+from keras.api import constraints\n+from keras.api import datasets\n+from keras.api import distribution\n+from keras.api import dtype_policies\n+from keras.api import export\n+from keras.api import initializers\n+from keras.api import layers\n+from keras.api import legacy\n+from keras.api import losses\n+from keras.api import metrics\n+from keras.api import mixed_precision\n+from keras.api import models\n+from keras.api import ops\n+from keras.api import optimizers\n+from keras.api import preprocessing\n+from keras.api import quantizers\n+from keras.api import random\n+from keras.api import regularizers\n+from keras.api import saving\n+from keras.api import tree\n+from keras.api import utils\n+from keras.src.backend.common.keras_tensor import KerasTensor\n+from keras.src.backend.common.stateless_scope import StatelessScope\n+from keras.src.backend.exports import Variable\n+from keras.src.backend.exports import device\n+from keras.src.backend.exports import name_scope\n+from keras.src.dtype_policies.dtype_policy import DTypePolicy\n+from keras.src.dtype_policies.dtype_policy import FloatDTypePolicy\n+from keras.src.dtype_policies.dtype_policy import QuantizedDTypePolicy\n+from keras.src.dtype_policies.dtype_policy import QuantizedFloat8DTypePolicy\n+from keras.src.initializers.initializer import Initializer\n+from keras.src.layers.core.input_layer import Input\n+from keras.src.layers.input_spec import InputSpec\n+from keras.src.layers.layer import Layer\n+from keras.src.losses.loss import Loss\n+from keras.src.metrics.metric import Metric\n+from keras.src.models.model import Model\n+from keras.src.models.sequential import Sequential\n+from keras.src.ops.function import Function\n+from keras.src.ops.operation import Operation\n+from keras.src.optimizers.optimizer import Optimizer\n+from keras.src.quantizers.quantizers import AbsMaxQuantizer\n+from keras.src.quantizers.quantizers import Quantizer\n+from keras.src.regularizers.regularizers import Regularizer\n+from keras.src.version import __version__\n+from keras.src.version import version\n\n@@ -0,0 +1 @@\n+from keras.api._tf_keras import keras\n\n@@ -0,0 +1,57 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.api import activations\n+from keras.api import applications\n+from keras.api import backend\n+from keras.api import callbacks\n+from keras.api import config\n+from keras.api import constraints\n+from keras.api import datasets\n+from keras.api import distribution\n+from keras.api import dtype_policies\n+from keras.api import export\n+from keras.api import initializers\n+from keras.api import layers\n+from keras.api import legacy\n+from keras.api import losses\n+from keras.api import metrics\n+from keras.api import mixed_precision\n+from keras.api import models\n+from keras.api import ops\n+from keras.api import optimizers\n+from keras.api import preprocessing\n+from keras.api import quantizers\n+from keras.api import random\n+from keras.api import regularizers\n+from keras.api import saving\n+from keras.api import tree\n+from keras.api import utils\n+from keras.src.backend.common.keras_tensor import KerasTensor\n+from keras.src.backend.common.stateless_scope import StatelessScope\n+from keras.src.backend.exports import Variable\n+from keras.src.backend.exports import device\n+from keras.src.backend.exports import name_scope\n+from keras.src.dtype_policies.dtype_policy import DTypePolicy\n+from keras.src.dtype_policies.dtype_policy import FloatDTypePolicy\n+from keras.src.dtype_policies.dtype_policy import QuantizedDTypePolicy\n+from keras.src.dtype_policies.dtype_policy import QuantizedFloat8DTypePolicy\n+from keras.src.initializers.initializer import Initializer\n+from keras.src.layers.core.input_layer import Input\n+from keras.src.layers.input_spec import InputSpec\n+from keras.src.layers.layer import Layer\n+from keras.src.losses.loss import Loss\n+from keras.src.metrics.metric import Metric\n+from keras.src.models.model import Model\n+from keras.src.models.sequential import Sequential\n+from keras.src.ops.function import Function\n+from keras.src.ops.operation import Operation\n+from keras.src.optimizers.optimizer import Optimizer\n+from keras.src.quantizers.quantizers import AbsMaxQuantizer\n+from keras.src.quantizers.quantizers import Quantizer\n+from keras.src.regularizers.regularizers import Regularizer\n+from keras.src.version import __version__\n+from keras.src.version import version\n\n@@ -0,0 +1,29 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.activations import deserialize\n+from keras.src.activations import get\n+from keras.src.activations import serialize\n+from keras.src.activations.activations import elu\n+from keras.src.activations.activations import exponential\n+from keras.src.activations.activations import gelu\n+from keras.src.activations.activations import hard_sigmoid\n+from keras.src.activations.activations import hard_silu\n+from keras.src.activations.activations import hard_silu as hard_swish\n+from keras.src.activations.activations import leaky_relu\n+from keras.src.activations.activations import linear\n+from keras.src.activations.activations import log_softmax\n+from keras.src.activations.activations import mish\n+from keras.src.activations.activations import relu\n+from keras.src.activations.activations import relu6\n+from keras.src.activations.activations import selu\n+from keras.src.activations.activations import sigmoid\n+from keras.src.activations.activations import silu\n+from keras.src.activations.activations import silu as swish\n+from keras.src.activations.activations import softmax\n+from keras.src.activations.activations import softplus\n+from keras.src.activations.activations import softsign\n+from keras.src.activations.activations import tanh\n\n@@ -0,0 +1,63 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.api.applications import convnext\n+from keras.api.applications import densenet\n+from keras.api.applications import efficientnet\n+from keras.api.applications import efficientnet_v2\n+from keras.api.applications import imagenet_utils\n+from keras.api.applications import inception_resnet_v2\n+from keras.api.applications import inception_v3\n+from keras.api.applications import mobilenet\n+from keras.api.applications import mobilenet_v2\n+from keras.api.applications import mobilenet_v3\n+from keras.api.applications import nasnet\n+from keras.api.applications import resnet\n+from keras.api.applications import resnet50\n+from keras.api.applications import resnet_v2\n+from keras.api.applications import vgg16\n+from keras.api.applications import vgg19\n+from keras.api.applications import xception\n+from keras.src.applications.convnext import ConvNeXtBase\n+from keras.src.applications.convnext import ConvNeXtLarge\n+from keras.src.applications.convnext import ConvNeXtSmall\n+from keras.src.applications.convnext import ConvNeXtTiny\n+from keras.src.applications.convnext import ConvNeXtXLarge\n+from keras.src.applications.densenet import DenseNet121\n+from keras.src.applications.densenet import DenseNet169\n+from keras.src.applications.densenet import DenseNet201\n+from keras.src.applications.efficientnet import EfficientNetB0\n+from keras.src.applications.efficientnet import EfficientNetB1\n+from keras.src.applications.efficientnet import EfficientNetB2\n+from keras.src.applications.efficientnet import EfficientNetB3\n+from keras.src.applications.efficientnet import EfficientNetB4\n+from keras.src.applications.efficientnet import EfficientNetB5\n+from keras.src.applications.efficientnet import EfficientNetB6\n+from keras.src.applications.efficientnet import EfficientNetB7\n+from keras.src.applications.efficientnet_v2 import EfficientNetV2B0\n+from keras.src.applications.efficientnet_v2 import EfficientNetV2B1\n+from keras.src.applications.efficientnet_v2 import EfficientNetV2B2\n+from keras.src.applications.efficientnet_v2 import EfficientNetV2B3\n+from keras.src.applications.efficientnet_v2 import EfficientNetV2L\n+from keras.src.applications.efficientnet_v2 import EfficientNetV2M\n+from keras.src.applications.efficientnet_v2 import EfficientNetV2S\n+from keras.src.applications.inception_resnet_v2 import InceptionResNetV2\n+from keras.src.applications.inception_v3 import InceptionV3\n+from keras.src.applications.mobilenet import MobileNet\n+from keras.src.applications.mobilenet_v2 import MobileNetV2\n+from keras.src.applications.mobilenet_v3 import MobileNetV3Large\n+from keras.src.applications.mobilenet_v3 import MobileNetV3Small\n+from keras.src.applications.nasnet import NASNetLarge\n+from keras.src.applications.nasnet import NASNetMobile\n+from keras.src.applications.resnet import ResNet50\n+from keras.src.applications.resnet import ResNet101\n+from keras.src.applications.resnet import ResNet152\n+from keras.src.applications.resnet_v2 import ResNet50V2\n+from keras.src.applications.resnet_v2 import ResNet101V2\n+from keras.src.applications.resnet_v2 import ResNet152V2\n+from keras.src.applications.vgg16 import VGG16\n+from keras.src.applications.vgg19 import VGG19\n+from keras.src.applications.xception import Xception\n\n@@ -0,0 +1,13 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.applications.convnext import ConvNeXtBase\n+from keras.src.applications.convnext import ConvNeXtLarge\n+from keras.src.applications.convnext import ConvNeXtSmall\n+from keras.src.applications.convnext import ConvNeXtTiny\n+from keras.src.applications.convnext import ConvNeXtXLarge\n+from keras.src.applications.convnext import decode_predictions\n+from keras.src.applications.convnext import preprocess_input\n\n@@ -0,0 +1,11 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.applications.densenet import DenseNet121\n+from keras.src.applications.densenet import DenseNet169\n+from keras.src.applications.densenet import DenseNet201\n+from keras.src.applications.densenet import decode_predictions\n+from keras.src.applications.densenet import preprocess_input\n\n@@ -0,0 +1,16 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.applications.efficientnet import EfficientNetB0\n+from keras.src.applications.efficientnet import EfficientNetB1\n+from keras.src.applications.efficientnet import EfficientNetB2\n+from keras.src.applications.efficientnet import EfficientNetB3\n+from keras.src.applications.efficientnet import EfficientNetB4\n+from keras.src.applications.efficientnet import EfficientNetB5\n+from keras.src.applications.efficientnet import EfficientNetB6\n+from keras.src.applications.efficientnet import EfficientNetB7\n+from keras.src.applications.efficientnet import decode_predictions\n+from keras.src.applications.efficientnet import preprocess_input\n\n@@ -0,0 +1,15 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.applications.efficientnet_v2 import EfficientNetV2B0\n+from keras.src.applications.efficientnet_v2 import EfficientNetV2B1\n+from keras.src.applications.efficientnet_v2 import EfficientNetV2B2\n+from keras.src.applications.efficientnet_v2 import EfficientNetV2B3\n+from keras.src.applications.efficientnet_v2 import EfficientNetV2L\n+from keras.src.applications.efficientnet_v2 import EfficientNetV2M\n+from keras.src.applications.efficientnet_v2 import EfficientNetV2S\n+from keras.src.applications.efficientnet_v2 import decode_predictions\n+from keras.src.applications.efficientnet_v2 import preprocess_input\n\n@@ -0,0 +1,8 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.applications.imagenet_utils import decode_predictions\n+from keras.src.applications.imagenet_utils import preprocess_input\n\n@@ -0,0 +1,9 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.applications.inception_resnet_v2 import InceptionResNetV2\n+from keras.src.applications.inception_resnet_v2 import decode_predictions\n+from keras.src.applications.inception_resnet_v2 import preprocess_input\n\n@@ -0,0 +1,9 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.applications.inception_v3 import InceptionV3\n+from keras.src.applications.inception_v3 import decode_predictions\n+from keras.src.applications.inception_v3 import preprocess_input\n\n@@ -0,0 +1,9 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.applications.mobilenet import MobileNet\n+from keras.src.applications.mobilenet import decode_predictions\n+from keras.src.applications.mobilenet import preprocess_input\n\n@@ -0,0 +1,9 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.applications.mobilenet_v2 import MobileNetV2\n+from keras.src.applications.mobilenet_v2 import decode_predictions\n+from keras.src.applications.mobilenet_v2 import preprocess_input\n\n@@ -0,0 +1,8 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.applications.mobilenet_v3 import decode_predictions\n+from keras.src.applications.mobilenet_v3 import preprocess_input\n\n@@ -0,0 +1,10 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.applications.nasnet import NASNetLarge\n+from keras.src.applications.nasnet import NASNetMobile\n+from keras.src.applications.nasnet import decode_predictions\n+from keras.src.applications.nasnet import preprocess_input\n\n@@ -0,0 +1,11 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.applications.resnet import ResNet50\n+from keras.src.applications.resnet import ResNet101\n+from keras.src.applications.resnet import ResNet152\n+from keras.src.applications.resnet import decode_predictions\n+from keras.src.applications.resnet import preprocess_input\n\n@@ -0,0 +1,9 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.applications.resnet import ResNet50\n+from keras.src.applications.resnet import decode_predictions\n+from keras.src.applications.resnet import preprocess_input\n\n@@ -0,0 +1,11 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.applications.resnet_v2 import ResNet50V2\n+from keras.src.applications.resnet_v2 import ResNet101V2\n+from keras.src.applications.resnet_v2 import ResNet152V2\n+from keras.src.applications.resnet_v2 import decode_predictions\n+from keras.src.applications.resnet_v2 import preprocess_input\n\n@@ -0,0 +1,9 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.applications.vgg16 import VGG16\n+from keras.src.applications.vgg16 import decode_predictions\n+from keras.src.applications.vgg16 import preprocess_input\n\n@@ -0,0 +1,9 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.applications.vgg19 import VGG19\n+from keras.src.applications.vgg19 import decode_predictions\n+from keras.src.applications.vgg19 import preprocess_input\n\n@@ -0,0 +1,9 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.applications.xception import Xception\n+from keras.src.applications.xception import decode_predictions\n+from keras.src.applications.xception import preprocess_input\n\n@@ -0,0 +1,20 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.backend.common.dtypes import result_type\n+from keras.src.backend.common.global_state import clear_session\n+from keras.src.backend.common.keras_tensor import is_keras_tensor\n+from keras.src.backend.common.variables import is_float_dtype\n+from keras.src.backend.common.variables import is_int_dtype\n+from keras.src.backend.common.variables import standardize_dtype\n+from keras.src.backend.config import backend\n+from keras.src.backend.config import epsilon\n+from keras.src.backend.config import floatx\n+from keras.src.backend.config import image_data_format\n+from keras.src.backend.config import set_epsilon\n+from keras.src.backend.config import set_floatx\n+from keras.src.backend.config import set_image_data_format\n+from keras.src.utils.naming import get_uid\n\n@@ -0,0 +1,21 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.callbacks.backup_and_restore import BackupAndRestore\n+from keras.src.callbacks.callback import Callback\n+from keras.src.callbacks.callback_list import CallbackList\n+from keras.src.callbacks.csv_logger import CSVLogger\n+from keras.src.callbacks.early_stopping import EarlyStopping\n+from keras.src.callbacks.history import History\n+from keras.src.callbacks.lambda_callback import LambdaCallback\n+from keras.src.callbacks.learning_rate_scheduler import LearningRateScheduler\n+from keras.src.callbacks.model_checkpoint import ModelCheckpoint\n+from keras.src.callbacks.progbar_logger import ProgbarLogger\n+from keras.src.callbacks.reduce_lr_on_plateau import ReduceLROnPlateau\n+from keras.src.callbacks.remote_monitor import RemoteMonitor\n+from keras.src.callbacks.swap_ema_weights import SwapEMAWeights\n+from keras.src.callbacks.tensorboard import TensorBoard\n+from keras.src.callbacks.terminate_on_nan import TerminateOnNaN\n\n@@ -0,0 +1,23 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.backend.config import backend\n+from keras.src.backend.config import epsilon\n+from keras.src.backend.config import floatx\n+from keras.src.backend.config import image_data_format\n+from keras.src.backend.config import set_epsilon\n+from keras.src.backend.config import set_floatx\n+from keras.src.backend.config import set_image_data_format\n+from keras.src.dtype_policies.dtype_policy import dtype_policy\n+from keras.src.dtype_policies.dtype_policy import set_dtype_policy\n+from keras.src.saving.serialization_lib import enable_unsafe_deserialization\n+from keras.src.utils.backend_utils import set_backend\n+from keras.src.utils.io_utils import disable_interactive_logging\n+from keras.src.utils.io_utils import enable_interactive_logging\n+from keras.src.utils.io_utils import is_interactive_logging_enabled\n+from keras.src.utils.traceback_utils import disable_traceback_filtering\n+from keras.src.utils.traceback_utils import enable_traceback_filtering\n+from keras.src.utils.traceback_utils import is_traceback_filtering_enabled\n\n@@ -0,0 +1,18 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.constraints import deserialize\n+from keras.src.constraints import get\n+from keras.src.constraints import serialize\n+from keras.src.constraints.constraints import Constraint\n+from keras.src.constraints.constraints import MaxNorm\n+from keras.src.constraints.constraints import MaxNorm as max_norm\n+from keras.src.constraints.constraints import MinMaxNorm\n+from keras.src.constraints.constraints import MinMaxNorm as min_max_norm\n+from keras.src.constraints.constraints import NonNeg\n+from keras.src.constraints.constraints import NonNeg as non_neg\n+from keras.src.constraints.constraints import UnitNorm\n+from keras.src.constraints.constraints import UnitNorm as unit_norm\n\n@@ -0,0 +1,14 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.api.datasets import boston_housing\n+from keras.api.datasets import california_housing\n+from keras.api.datasets import cifar10\n+from keras.api.datasets import cifar100\n+from keras.api.datasets import fashion_mnist\n+from keras.api.datasets import imdb\n+from keras.api.datasets import mnist\n+from keras.api.datasets import reuters\n\n@@ -0,0 +1,7 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.datasets.boston_housing import load_data\n\n@@ -0,0 +1,7 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.datasets.california_housing import load_data\n\n@@ -0,0 +1,7 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.datasets.cifar10 import load_data\n\n@@ -0,0 +1,7 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.datasets.cifar100 import load_data\n\n@@ -0,0 +1,7 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.datasets.fashion_mnist import load_data\n\n@@ -0,0 +1,8 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.datasets.imdb import get_word_index\n+from keras.src.datasets.imdb import load_data\n\n@@ -0,0 +1,7 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.datasets.mnist import load_data\n\n@@ -0,0 +1,9 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.datasets.reuters import get_label_names\n+from keras.src.datasets.reuters import get_word_index\n+from keras.src.datasets.reuters import load_data\n\n@@ -0,0 +1,16 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.distribution.distribution_lib import DataParallel\n+from keras.src.distribution.distribution_lib import DeviceMesh\n+from keras.src.distribution.distribution_lib import LayoutMap\n+from keras.src.distribution.distribution_lib import ModelParallel\n+from keras.src.distribution.distribution_lib import TensorLayout\n+from keras.src.distribution.distribution_lib import distribute_tensor\n+from keras.src.distribution.distribution_lib import distribution\n+from keras.src.distribution.distribution_lib import initialize\n+from keras.src.distribution.distribution_lib import list_devices\n+from keras.src.distribution.distribution_lib import set_distribution\n\n@@ -0,0 +1,10 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.dtype_policies.dtype_policy import DTypePolicy\n+from keras.src.dtype_policies.dtype_policy import FloatDTypePolicy\n+from keras.src.dtype_policies.dtype_policy import QuantizedDTypePolicy\n+from keras.src.dtype_policies.dtype_policy import QuantizedFloat8DTypePolicy\n\n@@ -0,0 +1,7 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.export.export_lib import ExportArchive\n\n@@ -0,0 +1,64 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.initializers import deserialize\n+from keras.src.initializers import get\n+from keras.src.initializers import serialize\n+from keras.src.initializers.constant_initializers import Constant\n+from keras.src.initializers.constant_initializers import Constant as constant\n+from keras.src.initializers.constant_initializers import Identity\n+from keras.src.initializers.constant_initializers import (\n+    Identity as IdentityInitializer,\n+)\n+from keras.src.initializers.constant_initializers import Identity as identity\n+from keras.src.initializers.constant_initializers import Ones\n+from keras.src.initializers.constant_initializers import Ones as ones\n+from keras.src.initializers.constant_initializers import Zeros\n+from keras.src.initializers.constant_initializers import Zeros as zeros\n+from keras.src.initializers.initializer import Initializer\n+from keras.src.initializers.random_initializers import GlorotNormal\n+from keras.src.initializers.random_initializers import (\n+    GlorotNormal as glorot_normal,\n+)\n+from keras.src.initializers.random_initializers import GlorotUniform\n+from keras.src.initializers.random_initializers import (\n+    GlorotUniform as glorot_uniform,\n+)\n+from keras.src.initializers.random_initializers import HeNormal\n+from keras.src.initializers.random_initializers import HeNormal as he_normal\n+from keras.src.initializers.random_initializers import HeUniform\n+from keras.src.initializers.random_initializers import HeUniform as he_uniform\n+from keras.src.initializers.random_initializers import LecunNormal\n+from keras.src.initializers.random_initializers import (\n+    LecunNormal as lecun_normal,\n+)\n+from keras.src.initializers.random_initializers import LecunUniform\n+from keras.src.initializers.random_initializers import (\n+    LecunUniform as lecun_uniform,\n+)\n+from keras.src.initializers.random_initializers import OrthogonalInitializer\n+from keras.src.initializers.random_initializers import (\n+    OrthogonalInitializer as Orthogonal,\n+)\n+from keras.src.initializers.random_initializers import (\n+    OrthogonalInitializer as orthogonal,\n+)\n+from keras.src.initializers.random_initializers import RandomNormal\n+from keras.src.initializers.random_initializers import (\n+    RandomNormal as random_normal,\n+)\n+from keras.src.initializers.random_initializers import RandomUniform\n+from keras.src.initializers.random_initializers import (\n+    RandomUniform as random_uniform,\n+)\n+from keras.src.initializers.random_initializers import TruncatedNormal\n+from keras.src.initializers.random_initializers import (\n+    TruncatedNormal as truncated_normal,\n+)\n+from keras.src.initializers.random_initializers import VarianceScaling\n+from keras.src.initializers.random_initializers import (\n+    VarianceScaling as variance_scaling,\n+)\n\n@@ -0,0 +1,195 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.export.export_lib import TFSMLayer\n+from keras.src.layers import deserialize\n+from keras.src.layers import serialize\n+from keras.src.layers.activations.activation import Activation\n+from keras.src.layers.activations.elu import ELU\n+from keras.src.layers.activations.leaky_relu import LeakyReLU\n+from keras.src.layers.activations.prelu import PReLU\n+from keras.src.layers.activations.relu import ReLU\n+from keras.src.layers.activations.softmax import Softmax\n+from keras.src.layers.attention.additive_attention import AdditiveAttention\n+from keras.src.layers.attention.attention import Attention\n+from keras.src.layers.attention.grouped_query_attention import (\n+    GroupedQueryAttention as GroupQueryAttention,\n+)\n+from keras.src.layers.attention.multi_head_attention import MultiHeadAttention\n+from keras.src.layers.convolutional.conv1d import Conv1D\n+from keras.src.layers.convolutional.conv1d import Conv1D as Convolution1D\n+from keras.src.layers.convolutional.conv1d_transpose import Conv1DTranspose\n+from keras.src.layers.convolutional.conv1d_transpose import (\n+    Conv1DTranspose as Convolution1DTranspose,\n+)\n+from keras.src.layers.convolutional.conv2d import Conv2D\n+from keras.src.layers.convolutional.conv2d import Conv2D as Convolution2D\n+from keras.src.layers.convolutional.conv2d_transpose import Conv2DTranspose\n+from keras.src.layers.convolutional.conv2d_transpose import (\n+    Conv2DTranspose as Convolution2DTranspose,\n+)\n+from keras.src.layers.convolutional.conv3d import Conv3D\n+from keras.src.layers.convolutional.conv3d import Conv3D as Convolution3D\n+from keras.src.layers.convolutional.conv3d_transpose import Conv3DTranspose\n+from keras.src.layers.convolutional.conv3d_transpose import (\n+    Conv3DTranspose as Convolution3DTranspose,\n+)\n+from keras.src.layers.convolutional.depthwise_conv1d import DepthwiseConv1D\n+from keras.src.layers.convolutional.depthwise_conv2d import DepthwiseConv2D\n+from keras.src.layers.convolutional.separable_conv1d import SeparableConv1D\n+from keras.src.layers.convolutional.separable_conv1d import (\n+    SeparableConv1D as SeparableConvolution1D,\n+)\n+from keras.src.layers.convolutional.separable_conv2d import SeparableConv2D\n+from keras.src.layers.convolutional.separable_conv2d import (\n+    SeparableConv2D as SeparableConvolution2D,\n+)\n+from keras.src.layers.core.dense import Dense\n+from keras.src.layers.core.einsum_dense import EinsumDense\n+from keras.src.layers.core.embedding import Embedding\n+from keras.src.layers.core.identity import Identity\n+from keras.src.layers.core.input_layer import Input\n+from keras.src.layers.core.input_layer import InputLayer\n+from keras.src.layers.core.lambda_layer import Lambda\n+from keras.src.layers.core.masking import Masking\n+from keras.src.layers.core.wrapper import Wrapper\n+from keras.src.layers.input_spec import InputSpec\n+from keras.src.layers.layer import Layer\n+from keras.src.layers.merging.add import Add\n+from keras.src.layers.merging.add import add\n+from keras.src.layers.merging.average import Average\n+from keras.src.layers.merging.average import average\n+from keras.src.layers.merging.concatenate import Concatenate\n+from keras.src.layers.merging.concatenate import concatenate\n+from keras.src.layers.merging.dot import Dot\n+from keras.src.layers.merging.dot import dot\n+from keras.src.layers.merging.maximum import Maximum\n+from keras.src.layers.merging.maximum import maximum\n+from keras.src.layers.merging.minimum import Minimum\n+from keras.src.layers.merging.minimum import minimum\n+from keras.src.layers.merging.multiply import Multiply\n+from keras.src.layers.merging.multiply import multiply\n+from keras.src.layers.merging.subtract import Subtract\n+from keras.src.layers.merging.subtract import subtract\n+from keras.src.layers.normalization.batch_normalization import (\n+    BatchNormalization,\n+)\n+from keras.src.layers.normalization.group_normalization import (\n+    GroupNormalization,\n+)\n+from keras.src.layers.normalization.layer_normalization import (\n+    LayerNormalization,\n+)\n+from keras.src.layers.normalization.spectral_normalization import (\n+    SpectralNormalization,\n+)\n+from keras.src.layers.normalization.unit_normalization import UnitNormalization\n+from keras.src.layers.pooling.average_pooling1d import AveragePooling1D\n+from keras.src.layers.pooling.average_pooling1d import (\n+    AveragePooling1D as AvgPool1D,\n+)\n+from keras.src.layers.pooling.average_pooling2d import AveragePooling2D\n+from keras.src.layers.pooling.average_pooling2d import (\n+    AveragePooling2D as AvgPool2D,\n+)\n+from keras.src.layers.pooling.average_pooling3d import AveragePooling3D\n+from keras.src.layers.pooling.average_pooling3d import (\n+    AveragePooling3D as AvgPool3D,\n+)\n+from keras.src.layers.pooling.global_average_pooling1d import (\n+    GlobalAveragePooling1D,\n+)\n+from keras.src.layers.pooling.global_average_pooling1d import (\n+    GlobalAveragePooling1D as GlobalAvgPool1D,\n+)\n+from keras.src.layers.pooling.global_average_pooling2d import (\n+    GlobalAveragePooling2D,\n+)\n+from keras.src.layers.pooling.global_average_pooling2d import (\n+    GlobalAveragePooling2D as GlobalAvgPool2D,\n+)\n+from keras.src.layers.pooling.global_average_pooling3d import (\n+    GlobalAveragePooling3D,\n+)\n+from keras.src.layers.pooling.global_average_pooling3d import (\n+    GlobalAveragePooling3D as GlobalAvgPool3D,\n+)\n+from keras.src.layers.pooling.global_max_pooling1d import GlobalMaxPooling1D\n+from keras.src.layers.pooling.global_max_pooling1d import (\n+    GlobalMaxPooling1D as GlobalMaxPool1D,\n+)\n+from keras.src.layers.pooling.global_max_pooling2d import GlobalMaxPooling2D\n+from keras.src.layers.pooling.global_max_pooling2d import (\n+    GlobalMaxPooling2D as GlobalMaxPool2D,\n+)\n+from keras.src.layers.pooling.global_max_pooling3d import GlobalMaxPooling3D\n+from keras.src.layers.pooling.global_max_pooling3d import (\n+    GlobalMaxPooling3D as GlobalMaxPool3D,\n+)\n+from keras.src.layers.pooling.max_pooling1d import MaxPooling1D\n+from keras.src.layers.pooling.max_pooling1d import MaxPooling1D as MaxPool1D\n+from keras.src.layers.pooling.max_pooling2d import MaxPooling2D\n+from keras.src.layers.pooling.max_pooling2d import MaxPooling2D as MaxPool2D\n+from keras.src.layers.pooling.max_pooling3d import MaxPooling3D\n+from keras.src.layers.pooling.max_pooling3d import MaxPooling3D as MaxPool3D\n+from keras.src.layers.preprocessing.audio_preprocessing import MelSpectrogram\n+from keras.src.layers.preprocessing.category_encoding import CategoryEncoding\n+from keras.src.layers.preprocessing.center_crop import CenterCrop\n+from keras.src.layers.preprocessing.discretization import Discretization\n+from keras.src.layers.preprocessing.hashed_crossing import HashedCrossing\n+from keras.src.layers.preprocessing.hashing import Hashing\n+from keras.src.layers.preprocessing.integer_lookup import IntegerLookup\n+from keras.src.layers.preprocessing.normalization import Normalization\n+from keras.src.layers.preprocessing.random_brightness import RandomBrightness\n+from keras.src.layers.preprocessing.random_contrast import RandomContrast\n+from keras.src.layers.preprocessing.random_crop import RandomCrop\n+from keras.src.layers.preprocessing.random_flip import RandomFlip\n+from keras.src.layers.preprocessing.random_rotation import RandomRotation\n+from keras.src.layers.preprocessing.random_translation import RandomTranslation\n+from keras.src.layers.preprocessing.random_zoom import RandomZoom\n+from keras.src.layers.preprocessing.rescaling import Rescaling\n+from keras.src.layers.preprocessing.resizing import Resizing\n+from keras.src.layers.preprocessing.string_lookup import StringLookup\n+from keras.src.layers.preprocessing.text_vectorization import TextVectorization\n+from keras.src.layers.regularization.activity_regularization import (\n+    ActivityRegularization,\n+)\n+from keras.src.layers.regularization.alpha_dropout import AlphaDropout\n+from keras.src.layers.regularization.dropout import Dropout\n+from keras.src.layers.regularization.gaussian_dropout import GaussianDropout\n+from keras.src.layers.regularization.gaussian_noise import GaussianNoise\n+from keras.src.layers.regularization.spatial_dropout import SpatialDropout1D\n+from keras.src.layers.regularization.spatial_dropout import SpatialDropout2D\n+from keras.src.layers.regularization.spatial_dropout import SpatialDropout3D\n+from keras.src.layers.reshaping.cropping1d import Cropping1D\n+from keras.src.layers.reshaping.cropping2d import Cropping2D\n+from keras.src.layers.reshaping.cropping3d import Cropping3D\n+from keras.src.layers.reshaping.flatten import Flatten\n+from keras.src.layers.reshaping.permute import Permute\n+from keras.src.layers.reshaping.repeat_vector import RepeatVector\n+from keras.src.layers.reshaping.reshape import Reshape\n+from keras.src.layers.reshaping.up_sampling1d import UpSampling1D\n+from keras.src.layers.reshaping.up_sampling2d import UpSampling2D\n+from keras.src.layers.reshaping.up_sampling3d import UpSampling3D\n+from keras.src.layers.reshaping.zero_padding1d import ZeroPadding1D\n+from keras.src.layers.reshaping.zero_padding2d import ZeroPadding2D\n+from keras.src.layers.reshaping.zero_padding3d import ZeroPadding3D\n+from keras.src.layers.rnn.bidirectional import Bidirectional\n+from keras.src.layers.rnn.conv_lstm1d import ConvLSTM1D\n+from keras.src.layers.rnn.conv_lstm2d import ConvLSTM2D\n+from keras.src.layers.rnn.conv_lstm3d import ConvLSTM3D\n+from keras.src.layers.rnn.gru import GRU\n+from keras.src.layers.rnn.gru import GRUCell\n+from keras.src.layers.rnn.lstm import LSTM\n+from keras.src.layers.rnn.lstm import LSTMCell\n+from keras.src.layers.rnn.rnn import RNN\n+from keras.src.layers.rnn.simple_rnn import SimpleRNN\n+from keras.src.layers.rnn.simple_rnn import SimpleRNNCell\n+from keras.src.layers.rnn.stacked_rnn_cells import StackedRNNCells\n+from keras.src.layers.rnn.time_distributed import TimeDistributed\n+from keras.src.utils.jax_layer import FlaxLayer\n+from keras.src.utils.jax_layer import JaxLayer\n+from keras.src.utils.torch_utils import TorchModuleWrapper\n\n@@ -0,0 +1,7 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.api.legacy import saving\n\n@@ -0,0 +1,8 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.legacy.saving.serialization import deserialize_keras_object\n+from keras.src.legacy.saving.serialization import serialize_keras_object\n\n@@ -0,0 +1,50 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.losses import deserialize\n+from keras.src.losses import get\n+from keras.src.losses import serialize\n+from keras.src.losses.loss import Loss\n+from keras.src.losses.losses import CTC\n+from keras.src.losses.losses import BinaryCrossentropy\n+from keras.src.losses.losses import BinaryFocalCrossentropy\n+from keras.src.losses.losses import CategoricalCrossentropy\n+from keras.src.losses.losses import CategoricalFocalCrossentropy\n+from keras.src.losses.losses import CategoricalHinge\n+from keras.src.losses.losses import CosineSimilarity\n+from keras.src.losses.losses import Dice\n+from keras.src.losses.losses import Hinge\n+from keras.src.losses.losses import Huber\n+from keras.src.losses.losses import KLDivergence\n+from keras.src.losses.losses import LogCosh\n+from keras.src.losses.losses import MeanAbsoluteError\n+from keras.src.losses.losses import MeanAbsolutePercentageError\n+from keras.src.losses.losses import MeanSquaredError\n+from keras.src.losses.losses import MeanSquaredLogarithmicError\n+from keras.src.losses.losses import Poisson\n+from keras.src.losses.losses import SparseCategoricalCrossentropy\n+from keras.src.losses.losses import SquaredHinge\n+from keras.src.losses.losses import Tversky\n+from keras.src.losses.losses import binary_crossentropy\n+from keras.src.losses.losses import binary_focal_crossentropy\n+from keras.src.losses.losses import categorical_crossentropy\n+from keras.src.losses.losses import categorical_focal_crossentropy\n+from keras.src.losses.losses import categorical_hinge\n+from keras.src.losses.losses import cosine_similarity\n+from keras.src.losses.losses import ctc\n+from keras.src.losses.losses import dice\n+from keras.src.losses.losses import hinge\n+from keras.src.losses.losses import huber\n+from keras.src.losses.losses import kl_divergence\n+from keras.src.losses.losses import log_cosh\n+from keras.src.losses.losses import mean_absolute_error\n+from keras.src.losses.losses import mean_absolute_percentage_error\n+from keras.src.losses.losses import mean_squared_error\n+from keras.src.losses.losses import mean_squared_logarithmic_error\n+from keras.src.losses.losses import poisson\n+from keras.src.losses.losses import sparse_categorical_crossentropy\n+from keras.src.losses.losses import squared_hinge\n+from keras.src.losses.losses import tversky\n\n@@ -0,0 +1,76 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.losses.losses import binary_crossentropy\n+from keras.src.losses.losses import binary_focal_crossentropy\n+from keras.src.losses.losses import categorical_crossentropy\n+from keras.src.losses.losses import categorical_focal_crossentropy\n+from keras.src.losses.losses import categorical_hinge\n+from keras.src.losses.losses import hinge\n+from keras.src.losses.losses import huber\n+from keras.src.losses.losses import kl_divergence\n+from keras.src.losses.losses import log_cosh\n+from keras.src.losses.losses import mean_absolute_error\n+from keras.src.losses.losses import mean_absolute_percentage_error\n+from keras.src.losses.losses import mean_squared_error\n+from keras.src.losses.losses import mean_squared_logarithmic_error\n+from keras.src.losses.losses import poisson\n+from keras.src.losses.losses import sparse_categorical_crossentropy\n+from keras.src.losses.losses import squared_hinge\n+from keras.src.metrics import deserialize\n+from keras.src.metrics import get\n+from keras.src.metrics import serialize\n+from keras.src.metrics.accuracy_metrics import Accuracy\n+from keras.src.metrics.accuracy_metrics import BinaryAccuracy\n+from keras.src.metrics.accuracy_metrics import CategoricalAccuracy\n+from keras.src.metrics.accuracy_metrics import SparseCategoricalAccuracy\n+from keras.src.metrics.accuracy_metrics import SparseTopKCategoricalAccuracy\n+from keras.src.metrics.accuracy_metrics import TopKCategoricalAccuracy\n+from keras.src.metrics.accuracy_metrics import binary_accuracy\n+from keras.src.metrics.accuracy_metrics import categorical_accuracy\n+from keras.src.metrics.accuracy_metrics import sparse_categorical_accuracy\n+from keras.src.metrics.accuracy_metrics import sparse_top_k_categorical_accuracy\n+from keras.src.metrics.accuracy_metrics import top_k_categorical_accuracy\n+from keras.src.metrics.confusion_metrics import AUC\n+from keras.src.metrics.confusion_metrics import FalseNegatives\n+from keras.src.metrics.confusion_metrics import FalsePositives\n+from keras.src.metrics.confusion_metrics import Precision\n+from keras.src.metrics.confusion_metrics import PrecisionAtRecall\n+from keras.src.metrics.confusion_metrics import Recall\n+from keras.src.metrics.confusion_metrics import RecallAtPrecision\n+from keras.src.metrics.confusion_metrics import SensitivityAtSpecificity\n+from keras.src.metrics.confusion_metrics import SpecificityAtSensitivity\n+from keras.src.metrics.confusion_metrics import TrueNegatives\n+from keras.src.metrics.confusion_metrics import TruePositives\n+from keras.src.metrics.f_score_metrics import F1Score\n+from keras.src.metrics.f_score_metrics import FBetaScore\n+from keras.src.metrics.hinge_metrics import CategoricalHinge\n+from keras.src.metrics.hinge_metrics import Hinge\n+from keras.src.metrics.hinge_metrics import SquaredHinge\n+from keras.src.metrics.iou_metrics import BinaryIoU\n+from keras.src.metrics.iou_metrics import IoU\n+from keras.src.metrics.iou_metrics import MeanIoU\n+from keras.src.metrics.iou_metrics import OneHotIoU\n+from keras.src.metrics.iou_metrics import OneHotMeanIoU\n+from keras.src.metrics.metric import Metric\n+from keras.src.metrics.probabilistic_metrics import BinaryCrossentropy\n+from keras.src.metrics.probabilistic_metrics import CategoricalCrossentropy\n+from keras.src.metrics.probabilistic_metrics import KLDivergence\n+from keras.src.metrics.probabilistic_metrics import Poisson\n+from keras.src.metrics.probabilistic_metrics import (\n+    SparseCategoricalCrossentropy,\n+)\n+from keras.src.metrics.reduction_metrics import Mean\n+from keras.src.metrics.reduction_metrics import MeanMetricWrapper\n+from keras.src.metrics.reduction_metrics import Sum\n+from keras.src.metrics.regression_metrics import CosineSimilarity\n+from keras.src.metrics.regression_metrics import LogCoshError\n+from keras.src.metrics.regression_metrics import MeanAbsoluteError\n+from keras.src.metrics.regression_metrics import MeanAbsolutePercentageError\n+from keras.src.metrics.regression_metrics import MeanSquaredError\n+from keras.src.metrics.regression_metrics import MeanSquaredLogarithmicError\n+from keras.src.metrics.regression_metrics import R2Score\n+from keras.src.metrics.regression_metrics import RootMeanSquaredError\n\n@@ -0,0 +1,15 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.dtype_policies.dtype_policy import DTypePolicy\n+from keras.src.dtype_policies.dtype_policy import DTypePolicy as Policy\n+from keras.src.dtype_policies.dtype_policy import dtype_policy\n+from keras.src.dtype_policies.dtype_policy import dtype_policy as global_policy\n+from keras.src.dtype_policies.dtype_policy import set_dtype_policy\n+from keras.src.dtype_policies.dtype_policy import (\n+    set_dtype_policy as set_global_policy,\n+)\n+from keras.src.optimizers.loss_scale_optimizer import LossScaleOptimizer\n\n@@ -0,0 +1,12 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.models.cloning import clone_model\n+from keras.src.models.model import Model\n+from keras.src.models.model import model_from_json\n+from keras.src.models.sequential import Sequential\n+from keras.src.saving.saving_api import load_model\n+from keras.src.saving.saving_api import save_model\n\n@@ -0,0 +1,223 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.api.ops import image\n+from keras.api.ops import linalg\n+from keras.api.ops import nn\n+from keras.api.ops import numpy\n+from keras.src.ops.core import cast\n+from keras.src.ops.core import cond\n+from keras.src.ops.core import convert_to_numpy\n+from keras.src.ops.core import convert_to_tensor\n+from keras.src.ops.core import custom_gradient\n+from keras.src.ops.core import fori_loop\n+from keras.src.ops.core import is_tensor\n+from keras.src.ops.core import scatter\n+from keras.src.ops.core import scatter_update\n+from keras.src.ops.core import shape\n+from keras.src.ops.core import slice\n+from keras.src.ops.core import slice_update\n+from keras.src.ops.core import stop_gradient\n+from keras.src.ops.core import unstack\n+from keras.src.ops.core import vectorized_map\n+from keras.src.ops.core import while_loop\n+from keras.src.ops.linalg import cholesky\n+from keras.src.ops.linalg import det\n+from keras.src.ops.linalg import eig\n+from keras.src.ops.linalg import inv\n+from keras.src.ops.linalg import lu_factor\n+from keras.src.ops.linalg import norm\n+from keras.src.ops.linalg import qr\n+from keras.src.ops.linalg import solve\n+from keras.src.ops.linalg import solve_triangular\n+from keras.src.ops.linalg import svd\n+from keras.src.ops.math import erf\n+from keras.src.ops.math import erfinv\n+from keras.src.ops.math import extract_sequences\n+from keras.src.ops.math import fft\n+from keras.src.ops.math import fft2\n+from keras.src.ops.math import in_top_k\n+from keras.src.ops.math import irfft\n+from keras.src.ops.math import istft\n+from keras.src.ops.math import logsumexp\n+from keras.src.ops.math import rfft\n+from keras.src.ops.math import rsqrt\n+from keras.src.ops.math import segment_max\n+from keras.src.ops.math import segment_sum\n+from keras.src.ops.math import stft\n+from keras.src.ops.math import top_k\n+from keras.src.ops.nn import average_pool\n+from keras.src.ops.nn import batch_normalization\n+from keras.src.ops.nn import binary_crossentropy\n+from keras.src.ops.nn import categorical_crossentropy\n+from keras.src.ops.nn import conv\n+from keras.src.ops.nn import conv_transpose\n+from keras.src.ops.nn import ctc_loss\n+from keras.src.ops.nn import depthwise_conv\n+from keras.src.ops.nn import elu\n+from keras.src.ops.nn import gelu\n+from keras.src.ops.nn import hard_sigmoid\n+from keras.src.ops.nn import hard_silu\n+from keras.src.ops.nn import hard_silu as hard_swish\n+from keras.src.ops.nn import leaky_relu\n+from keras.src.ops.nn import log_sigmoid\n+from keras.src.ops.nn import log_softmax\n+from keras.src.ops.nn import max_pool\n+from keras.src.ops.nn import moments\n+from keras.src.ops.nn import multi_hot\n+from keras.src.ops.nn import normalize\n+from keras.src.ops.nn import one_hot\n+from keras.src.ops.nn import relu\n+from keras.src.ops.nn import relu6\n+from keras.src.ops.nn import selu\n+from keras.src.ops.nn import separable_conv\n+from keras.src.ops.nn import sigmoid\n+from keras.src.ops.nn import silu\n+from keras.src.ops.nn import silu as swish\n+from keras.src.ops.nn import softmax\n+from keras.src.ops.nn import softplus\n+from keras.src.ops.nn import softsign\n+from keras.src.ops.nn import sparse_categorical_crossentropy\n+from keras.src.ops.numpy import abs\n+from keras.src.ops.numpy import absolute\n+from keras.src.ops.numpy import add\n+from keras.src.ops.numpy import all\n+from keras.src.ops.numpy import amax\n+from keras.src.ops.numpy import amin\n+from keras.src.ops.numpy import any\n+from keras.src.ops.numpy import append\n+from keras.src.ops.numpy import arange\n+from keras.src.ops.numpy import arccos\n+from keras.src.ops.numpy import arccosh\n+from keras.src.ops.numpy import arcsin\n+from keras.src.ops.numpy import arcsinh\n+from keras.src.ops.numpy import arctan\n+from keras.src.ops.numpy import arctan2\n+from keras.src.ops.numpy import arctanh\n+from keras.src.ops.numpy import argmax\n+from keras.src.ops.numpy import argmin\n+from keras.src.ops.numpy import argsort\n+from keras.src.ops.numpy import array\n+from keras.src.ops.numpy import average\n+from keras.src.ops.numpy import bincount\n+from keras.src.ops.numpy import broadcast_to\n+from keras.src.ops.numpy import ceil\n+from keras.src.ops.numpy import clip\n+from keras.src.ops.numpy import concatenate\n+from keras.src.ops.numpy import conj\n+from keras.src.ops.numpy import conjugate\n+from keras.src.ops.numpy import copy\n+from keras.src.ops.numpy import correlate\n+from keras.src.ops.numpy import cos\n+from keras.src.ops.numpy import cosh\n+from keras.src.ops.numpy import count_nonzero\n+from keras.src.ops.numpy import cross\n+from keras.src.ops.numpy import cumprod\n+from keras.src.ops.numpy import cumsum\n+from keras.src.ops.numpy import diag\n+from keras.src.ops.numpy import diagonal\n+from keras.src.ops.numpy import diff\n+from keras.src.ops.numpy import digitize\n+from keras.src.ops.numpy import divide\n+from keras.src.ops.numpy import divide_no_nan\n+from keras.src.ops.numpy import dot\n+from keras.src.ops.numpy import einsum\n+from keras.src.ops.numpy import empty\n+from keras.src.ops.numpy import equal\n+from keras.src.ops.numpy import exp\n+from keras.src.ops.numpy import expand_dims\n+from keras.src.ops.numpy import expm1\n+from keras.src.ops.numpy import eye\n+from keras.src.ops.numpy import flip\n+from keras.src.ops.numpy import floor\n+from keras.src.ops.numpy import floor_divide\n+from keras.src.ops.numpy import full\n+from keras.src.ops.numpy import full_like\n+from keras.src.ops.numpy import get_item\n+from keras.src.ops.numpy import greater\n+from keras.src.ops.numpy import greater_equal\n+from keras.src.ops.numpy import hstack\n+from keras.src.ops.numpy import identity\n+from keras.src.ops.numpy import imag\n+from keras.src.ops.numpy import isclose\n+from keras.src.ops.numpy import isfinite\n+from keras.src.ops.numpy import isinf\n+from keras.src.ops.numpy import isnan\n+from keras.src.ops.numpy import less\n+from keras.src.ops.numpy import less_equal\n+from keras.src.ops.numpy import linspace\n+from keras.src.ops.numpy import log\n+from keras.src.ops.numpy import log1p\n+from keras.src.ops.numpy import log2\n+from keras.src.ops.numpy import log10\n+from keras.src.ops.numpy import logaddexp\n+from keras.src.ops.numpy import logical_and\n+from keras.src.ops.numpy import logical_not\n+from keras.src.ops.numpy import logical_or\n+from keras.src.ops.numpy import logical_xor\n+from keras.src.ops.numpy import logspace\n+from keras.src.ops.numpy import matmul\n+from keras.src.ops.numpy import max\n+from keras.src.ops.numpy import maximum\n+from keras.src.ops.numpy import mean\n+from keras.src.ops.numpy import median\n+from keras.src.ops.numpy import meshgrid\n+from keras.src.ops.numpy import min\n+from keras.src.ops.numpy import minimum\n+from keras.src.ops.numpy import mod\n+from keras.src.ops.numpy import moveaxis\n+from keras.src.ops.numpy import multiply\n+from keras.src.ops.numpy import nan_to_num\n+from keras.src.ops.numpy import ndim\n+from keras.src.ops.numpy import negative\n+from keras.src.ops.numpy import nonzero\n+from keras.src.ops.numpy import not_equal\n+from keras.src.ops.numpy import ones\n+from keras.src.ops.numpy import ones_like\n+from keras.src.ops.numpy import outer\n+from keras.src.ops.numpy import pad\n+from keras.src.ops.numpy import power\n+from keras.src.ops.numpy import prod\n+from keras.src.ops.numpy import quantile\n+from keras.src.ops.numpy import ravel\n+from keras.src.ops.numpy import real\n+from keras.src.ops.numpy import reciprocal\n+from keras.src.ops.numpy import repeat\n+from keras.src.ops.numpy import reshape\n+from keras.src.ops.numpy import roll\n+from keras.src.ops.numpy import round\n+from keras.src.ops.numpy import sign\n+from keras.src.ops.numpy import sin\n+from keras.src.ops.numpy import sinh\n+from keras.src.ops.numpy import size\n+from keras.src.ops.numpy import sort\n+from keras.src.ops.numpy import split\n+from keras.src.ops.numpy import sqrt\n+from keras.src.ops.numpy import square\n+from keras.src.ops.numpy import squeeze\n+from keras.src.ops.numpy import stack\n+from keras.src.ops.numpy import std\n+from keras.src.ops.numpy import subtract\n+from keras.src.ops.numpy import sum\n+from keras.src.ops.numpy import swapaxes\n+from keras.src.ops.numpy import take\n+from keras.src.ops.numpy import take_along_axis\n+from keras.src.ops.numpy import tan\n+from keras.src.ops.numpy import tanh\n+from keras.src.ops.numpy import tensordot\n+from keras.src.ops.numpy import tile\n+from keras.src.ops.numpy import trace\n+from keras.src.ops.numpy import transpose\n+from keras.src.ops.numpy import tri\n+from keras.src.ops.numpy import tril\n+from keras.src.ops.numpy import triu\n+from keras.src.ops.numpy import true_divide\n+from keras.src.ops.numpy import var\n+from keras.src.ops.numpy import vdot\n+from keras.src.ops.numpy import vstack\n+from keras.src.ops.numpy import where\n+from keras.src.ops.numpy import zeros\n+from keras.src.ops.numpy import zeros_like\n\n@@ -0,0 +1,13 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.ops.image import affine_transform\n+from keras.src.ops.image import crop_images\n+from keras.src.ops.image import extract_patches\n+from keras.src.ops.image import map_coordinates\n+from keras.src.ops.image import pad_images\n+from keras.src.ops.image import resize\n+from keras.src.ops.image import rgb_to_grayscale\n\n@@ -0,0 +1,16 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.ops.linalg import cholesky\n+from keras.src.ops.linalg import det\n+from keras.src.ops.linalg import eig\n+from keras.src.ops.linalg import inv\n+from keras.src.ops.linalg import lu_factor\n+from keras.src.ops.linalg import norm\n+from keras.src.ops.linalg import qr\n+from keras.src.ops.linalg import solve\n+from keras.src.ops.linalg import solve_triangular\n+from keras.src.ops.linalg import svd\n\n@@ -0,0 +1,38 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.ops.nn import average_pool\n+from keras.src.ops.nn import batch_normalization\n+from keras.src.ops.nn import binary_crossentropy\n+from keras.src.ops.nn import categorical_crossentropy\n+from keras.src.ops.nn import conv\n+from keras.src.ops.nn import conv_transpose\n+from keras.src.ops.nn import ctc_loss\n+from keras.src.ops.nn import depthwise_conv\n+from keras.src.ops.nn import elu\n+from keras.src.ops.nn import gelu\n+from keras.src.ops.nn import hard_sigmoid\n+from keras.src.ops.nn import hard_silu\n+from keras.src.ops.nn import hard_silu as hard_swish\n+from keras.src.ops.nn import leaky_relu\n+from keras.src.ops.nn import log_sigmoid\n+from keras.src.ops.nn import log_softmax\n+from keras.src.ops.nn import max_pool\n+from keras.src.ops.nn import moments\n+from keras.src.ops.nn import multi_hot\n+from keras.src.ops.nn import normalize\n+from keras.src.ops.nn import one_hot\n+from keras.src.ops.nn import relu\n+from keras.src.ops.nn import relu6\n+from keras.src.ops.nn import selu\n+from keras.src.ops.nn import separable_conv\n+from keras.src.ops.nn import sigmoid\n+from keras.src.ops.nn import silu\n+from keras.src.ops.nn import silu as swish\n+from keras.src.ops.nn import softmax\n+from keras.src.ops.nn import softplus\n+from keras.src.ops.nn import softsign\n+from keras.src.ops.nn import sparse_categorical_crossentropy\n\n@@ -0,0 +1,146 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.ops.numpy import abs\n+from keras.src.ops.numpy import absolute\n+from keras.src.ops.numpy import add\n+from keras.src.ops.numpy import all\n+from keras.src.ops.numpy import amax\n+from keras.src.ops.numpy import amin\n+from keras.src.ops.numpy import any\n+from keras.src.ops.numpy import append\n+from keras.src.ops.numpy import arange\n+from keras.src.ops.numpy import arccos\n+from keras.src.ops.numpy import arccosh\n+from keras.src.ops.numpy import arcsin\n+from keras.src.ops.numpy import arcsinh\n+from keras.src.ops.numpy import arctan\n+from keras.src.ops.numpy import arctan2\n+from keras.src.ops.numpy import arctanh\n+from keras.src.ops.numpy import argmax\n+from keras.src.ops.numpy import argmin\n+from keras.src.ops.numpy import argsort\n+from keras.src.ops.numpy import array\n+from keras.src.ops.numpy import average\n+from keras.src.ops.numpy import bincount\n+from keras.src.ops.numpy import broadcast_to\n+from keras.src.ops.numpy import ceil\n+from keras.src.ops.numpy import clip\n+from keras.src.ops.numpy import concatenate\n+from keras.src.ops.numpy import conj\n+from keras.src.ops.numpy import conjugate\n+from keras.src.ops.numpy import copy\n+from keras.src.ops.numpy import correlate\n+from keras.src.ops.numpy import cos\n+from keras.src.ops.numpy import cosh\n+from keras.src.ops.numpy import count_nonzero\n+from keras.src.ops.numpy import cross\n+from keras.src.ops.numpy import cumprod\n+from keras.src.ops.numpy import cumsum\n+from keras.src.ops.numpy import diag\n+from keras.src.ops.numpy import diagonal\n+from keras.src.ops.numpy import diff\n+from keras.src.ops.numpy import digitize\n+from keras.src.ops.numpy import divide\n+from keras.src.ops.numpy import divide_no_nan\n+from keras.src.ops.numpy import dot\n+from keras.src.ops.numpy import einsum\n+from keras.src.ops.numpy import empty\n+from keras.src.ops.numpy import equal\n+from keras.src.ops.numpy import exp\n+from keras.src.ops.numpy import expand_dims\n+from keras.src.ops.numpy import expm1\n+from keras.src.ops.numpy import eye\n+from keras.src.ops.numpy import flip\n+from keras.src.ops.numpy import floor\n+from keras.src.ops.numpy import floor_divide\n+from keras.src.ops.numpy import full\n+from keras.src.ops.numpy import full_like\n+from keras.src.ops.numpy import get_item\n+from keras.src.ops.numpy import greater\n+from keras.src.ops.numpy import greater_equal\n+from keras.src.ops.numpy import hstack\n+from keras.src.ops.numpy import identity\n+from keras.src.ops.numpy import imag\n+from keras.src.ops.numpy import isclose\n+from keras.src.ops.numpy import isfinite\n+from keras.src.ops.numpy import isinf\n+from keras.src.ops.numpy import isnan\n+from keras.src.ops.numpy import less\n+from keras.src.ops.numpy import less_equal\n+from keras.src.ops.numpy import linspace\n+from keras.src.ops.numpy import log\n+from keras.src.ops.numpy import log1p\n+from keras.src.ops.numpy import log2\n+from keras.src.ops.numpy import log10\n+from keras.src.ops.numpy import logaddexp\n+from keras.src.ops.numpy import logical_and\n+from keras.src.ops.numpy import logical_not\n+from keras.src.ops.numpy import logical_or\n+from keras.src.ops.numpy import logical_xor\n+from keras.src.ops.numpy import logspace\n+from keras.src.ops.numpy import matmul\n+from keras.src.ops.numpy import max\n+from keras.src.ops.numpy import maximum\n+from keras.src.ops.numpy import mean\n+from keras.src.ops.numpy import median\n+from keras.src.ops.numpy import meshgrid\n+from keras.src.ops.numpy import min\n+from keras.src.ops.numpy import minimum\n+from keras.src.ops.numpy import mod\n+from keras.src.ops.numpy import moveaxis\n+from keras.src.ops.numpy import multiply\n+from keras.src.ops.numpy import nan_to_num\n+from keras.src.ops.numpy import ndim\n+from keras.src.ops.numpy import negative\n+from keras.src.ops.numpy import nonzero\n+from keras.src.ops.numpy import not_equal\n+from keras.src.ops.numpy import ones\n+from keras.src.ops.numpy import ones_like\n+from keras.src.ops.numpy import outer\n+from keras.src.ops.numpy import pad\n+from keras.src.ops.numpy import power\n+from keras.src.ops.numpy import prod\n+from keras.src.ops.numpy import quantile\n+from keras.src.ops.numpy import ravel\n+from keras.src.ops.numpy import real\n+from keras.src.ops.numpy import reciprocal\n+from keras.src.ops.numpy import repeat\n+from keras.src.ops.numpy import reshape\n+from keras.src.ops.numpy import roll\n+from keras.src.ops.numpy import round\n+from keras.src.ops.numpy import sign\n+from keras.src.ops.numpy import sin\n+from keras.src.ops.numpy import sinh\n+from keras.src.ops.numpy import size\n+from keras.src.ops.numpy import sort\n+from keras.src.ops.numpy import split\n+from keras.src.ops.numpy import sqrt\n+from keras.src.ops.numpy import square\n+from keras.src.ops.numpy import squeeze\n+from keras.src.ops.numpy import stack\n+from keras.src.ops.numpy import std\n+from keras.src.ops.numpy import subtract\n+from keras.src.ops.numpy import sum\n+from keras.src.ops.numpy import swapaxes\n+from keras.src.ops.numpy import take\n+from keras.src.ops.numpy import take_along_axis\n+from keras.src.ops.numpy import tan\n+from keras.src.ops.numpy import tanh\n+from keras.src.ops.numpy import tensordot\n+from keras.src.ops.numpy import tile\n+from keras.src.ops.numpy import trace\n+from keras.src.ops.numpy import transpose\n+from keras.src.ops.numpy import tri\n+from keras.src.ops.numpy import tril\n+from keras.src.ops.numpy import triu\n+from keras.src.ops.numpy import true_divide\n+from keras.src.ops.numpy import var\n+from keras.src.ops.numpy import vdot\n+from keras.src.ops.numpy import vstack\n+from keras.src.ops.numpy import where\n+from keras.src.ops.numpy import zeros\n+from keras.src.ops.numpy import zeros_like\n\n@@ -0,0 +1,24 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.api.optimizers import legacy\n+from keras.api.optimizers import schedules\n+from keras.src.optimizers import deserialize\n+from keras.src.optimizers import get\n+from keras.src.optimizers import serialize\n+from keras.src.optimizers.adadelta import Adadelta\n+from keras.src.optimizers.adafactor import Adafactor\n+from keras.src.optimizers.adagrad import Adagrad\n+from keras.src.optimizers.adam import Adam\n+from keras.src.optimizers.adamax import Adamax\n+from keras.src.optimizers.adamw import AdamW\n+from keras.src.optimizers.ftrl import Ftrl\n+from keras.src.optimizers.lion import Lion\n+from keras.src.optimizers.loss_scale_optimizer import LossScaleOptimizer\n+from keras.src.optimizers.nadam import Nadam\n+from keras.src.optimizers.optimizer import Optimizer\n+from keras.src.optimizers.rmsprop import RMSprop\n+from keras.src.optimizers.sgd import SGD\n\n@@ -0,0 +1,12 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.optimizers import LegacyOptimizerWarning as Adagrad\n+from keras.src.optimizers import LegacyOptimizerWarning as Adam\n+from keras.src.optimizers import LegacyOptimizerWarning as Ftrl\n+from keras.src.optimizers import LegacyOptimizerWarning as Optimizer\n+from keras.src.optimizers import LegacyOptimizerWarning as RMSprop\n+from keras.src.optimizers import LegacyOptimizerWarning as SGD\n\n@@ -0,0 +1,27 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.optimizers.schedules.learning_rate_schedule import CosineDecay\n+from keras.src.optimizers.schedules.learning_rate_schedule import (\n+    CosineDecayRestarts,\n+)\n+from keras.src.optimizers.schedules.learning_rate_schedule import (\n+    ExponentialDecay,\n+)\n+from keras.src.optimizers.schedules.learning_rate_schedule import (\n+    InverseTimeDecay,\n+)\n+from keras.src.optimizers.schedules.learning_rate_schedule import (\n+    LearningRateSchedule,\n+)\n+from keras.src.optimizers.schedules.learning_rate_schedule import (\n+    PiecewiseConstantDecay,\n+)\n+from keras.src.optimizers.schedules.learning_rate_schedule import (\n+    PolynomialDecay,\n+)\n+from keras.src.optimizers.schedules.learning_rate_schedule import deserialize\n+from keras.src.optimizers.schedules.learning_rate_schedule import serialize\n\n@@ -0,0 +1,13 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.api.preprocessing import image\n+from keras.api.preprocessing import sequence\n+from keras.src.utils.image_dataset_utils import image_dataset_from_directory\n+from keras.src.utils.text_dataset_utils import text_dataset_from_directory\n+from keras.src.utils.timeseries_dataset_utils import (\n+    timeseries_dataset_from_array,\n+)\n\n@@ -0,0 +1,11 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.utils.image_utils import array_to_img\n+from keras.src.utils.image_utils import img_to_array\n+from keras.src.utils.image_utils import load_img\n+from keras.src.utils.image_utils import save_img\n+from keras.src.utils.image_utils import smart_resize\n\n@@ -0,0 +1,7 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.utils.sequence_utils import pad_sequences\n\n@@ -0,0 +1,15 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.quantizers import deserialize\n+from keras.src.quantizers import get\n+from keras.src.quantizers import serialize\n+from keras.src.quantizers.quantizers import AbsMaxQuantizer\n+from keras.src.quantizers.quantizers import Quantizer\n+from keras.src.quantizers.quantizers import abs_max_quantize\n+from keras.src.quantizers.quantizers import compute_float8_amax_history\n+from keras.src.quantizers.quantizers import compute_float8_scale\n+from keras.src.quantizers.quantizers import quantize_and_dequantize\n\n@@ -0,0 +1,17 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.random.random import beta\n+from keras.src.random.random import binomial\n+from keras.src.random.random import categorical\n+from keras.src.random.random import dropout\n+from keras.src.random.random import gamma\n+from keras.src.random.random import normal\n+from keras.src.random.random import randint\n+from keras.src.random.random import shuffle\n+from keras.src.random.random import truncated_normal\n+from keras.src.random.random import uniform\n+from keras.src.random.seed_generator import SeedGenerator\n\n@@ -0,0 +1,20 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.regularizers import deserialize\n+from keras.src.regularizers import get\n+from keras.src.regularizers import serialize\n+from keras.src.regularizers.regularizers import L1\n+from keras.src.regularizers.regularizers import L1 as l1\n+from keras.src.regularizers.regularizers import L1L2\n+from keras.src.regularizers.regularizers import L1L2 as l1_l2\n+from keras.src.regularizers.regularizers import L2\n+from keras.src.regularizers.regularizers import L2 as l2\n+from keras.src.regularizers.regularizers import OrthogonalRegularizer\n+from keras.src.regularizers.regularizers import (\n+    OrthogonalRegularizer as orthogonal_regularizer,\n+)\n+from keras.src.regularizers.regularizers import Regularizer\n\n@@ -0,0 +1,20 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.saving.object_registration import CustomObjectScope\n+from keras.src.saving.object_registration import (\n+    CustomObjectScope as custom_object_scope,\n+)\n+from keras.src.saving.object_registration import get_custom_objects\n+from keras.src.saving.object_registration import get_registered_name\n+from keras.src.saving.object_registration import get_registered_object\n+from keras.src.saving.object_registration import register_keras_serializable\n+from keras.src.saving.saving_api import load_model\n+from keras.src.saving.saving_api import load_weights\n+from keras.src.saving.saving_api import save_model\n+from keras.src.saving.saving_api import save_weights\n+from keras.src.saving.serialization_lib import deserialize_keras_object\n+from keras.src.saving.serialization_lib import serialize_keras_object\n\n@@ -0,0 +1,15 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.tree.tree_api import assert_same_structure\n+from keras.src.tree.tree_api import flatten\n+from keras.src.tree.tree_api import is_nested\n+from keras.src.tree.tree_api import lists_to_tuples\n+from keras.src.tree.tree_api import map_shape_structure\n+from keras.src.tree.tree_api import map_structure\n+from keras.src.tree.tree_api import map_structure_up_to\n+from keras.src.tree.tree_api import pack_sequence_as\n+from keras.src.tree.tree_api import traverse\n\n@@ -0,0 +1,54 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.api.utils import legacy\n+from keras.src.backend.common.global_state import clear_session\n+from keras.src.backend.common.keras_tensor import is_keras_tensor\n+from keras.src.backend.common.variables import standardize_dtype\n+from keras.src.layers.preprocessing.feature_space import FeatureSpace\n+from keras.src.ops.operation_utils import get_source_inputs\n+from keras.src.saving.object_registration import CustomObjectScope\n+from keras.src.saving.object_registration import (\n+    CustomObjectScope as custom_object_scope,\n+)\n+from keras.src.saving.object_registration import get_custom_objects\n+from keras.src.saving.object_registration import get_registered_name\n+from keras.src.saving.object_registration import get_registered_object\n+from keras.src.saving.object_registration import register_keras_serializable\n+from keras.src.saving.serialization_lib import deserialize_keras_object\n+from keras.src.saving.serialization_lib import serialize_keras_object\n+from keras.src.trainers.data_adapters.data_adapter_utils import (\n+    pack_x_y_sample_weight,\n+)\n+from keras.src.trainers.data_adapters.data_adapter_utils import (\n+    unpack_x_y_sample_weight,\n+)\n+from keras.src.trainers.data_adapters.py_dataset_adapter import PyDataset\n+from keras.src.trainers.data_adapters.py_dataset_adapter import (\n+    PyDataset as Sequence,\n+)\n+from keras.src.utils.audio_dataset_utils import audio_dataset_from_directory\n+from keras.src.utils.dataset_utils import split_dataset\n+from keras.src.utils.file_utils import get_file\n+from keras.src.utils.image_dataset_utils import image_dataset_from_directory\n+from keras.src.utils.image_utils import array_to_img\n+from keras.src.utils.image_utils import img_to_array\n+from keras.src.utils.image_utils import load_img\n+from keras.src.utils.image_utils import save_img\n+from keras.src.utils.io_utils import disable_interactive_logging\n+from keras.src.utils.io_utils import enable_interactive_logging\n+from keras.src.utils.io_utils import is_interactive_logging_enabled\n+from keras.src.utils.model_visualization import model_to_dot\n+from keras.src.utils.model_visualization import plot_model\n+from keras.src.utils.numerical_utils import normalize\n+from keras.src.utils.numerical_utils import to_categorical\n+from keras.src.utils.progbar import Progbar\n+from keras.src.utils.rng_utils import set_random_seed\n+from keras.src.utils.sequence_utils import pad_sequences\n+from keras.src.utils.text_dataset_utils import text_dataset_from_directory\n+from keras.src.utils.timeseries_dataset_utils import (\n+    timeseries_dataset_from_array,\n+)\n\n@@ -0,0 +1,8 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.legacy.saving.serialization import deserialize_keras_object\n+from keras.src.legacy.saving.serialization import serialize_keras_object\n\n@@ -0,0 +1,29 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.activations import deserialize\n+from keras.src.activations import get\n+from keras.src.activations import serialize\n+from keras.src.activations.activations import elu\n+from keras.src.activations.activations import exponential\n+from keras.src.activations.activations import gelu\n+from keras.src.activations.activations import hard_sigmoid\n+from keras.src.activations.activations import hard_silu\n+from keras.src.activations.activations import hard_silu as hard_swish\n+from keras.src.activations.activations import leaky_relu\n+from keras.src.activations.activations import linear\n+from keras.src.activations.activations import log_softmax\n+from keras.src.activations.activations import mish\n+from keras.src.activations.activations import relu\n+from keras.src.activations.activations import relu6\n+from keras.src.activations.activations import selu\n+from keras.src.activations.activations import sigmoid\n+from keras.src.activations.activations import silu\n+from keras.src.activations.activations import silu as swish\n+from keras.src.activations.activations import softmax\n+from keras.src.activations.activations import softplus\n+from keras.src.activations.activations import softsign\n+from keras.src.activations.activations import tanh\n\n@@ -0,0 +1,63 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.api.applications import convnext\n+from keras.api.applications import densenet\n+from keras.api.applications import efficientnet\n+from keras.api.applications import efficientnet_v2\n+from keras.api.applications import imagenet_utils\n+from keras.api.applications import inception_resnet_v2\n+from keras.api.applications import inception_v3\n+from keras.api.applications import mobilenet\n+from keras.api.applications import mobilenet_v2\n+from keras.api.applications import mobilenet_v3\n+from keras.api.applications import nasnet\n+from keras.api.applications import resnet\n+from keras.api.applications import resnet50\n+from keras.api.applications import resnet_v2\n+from keras.api.applications import vgg16\n+from keras.api.applications import vgg19\n+from keras.api.applications import xception\n+from keras.src.applications.convnext import ConvNeXtBase\n+from keras.src.applications.convnext import ConvNeXtLarge\n+from keras.src.applications.convnext import ConvNeXtSmall\n+from keras.src.applications.convnext import ConvNeXtTiny\n+from keras.src.applications.convnext import ConvNeXtXLarge\n+from keras.src.applications.densenet import DenseNet121\n+from keras.src.applications.densenet import DenseNet169\n+from keras.src.applications.densenet import DenseNet201\n+from keras.src.applications.efficientnet import EfficientNetB0\n+from keras.src.applications.efficientnet import EfficientNetB1\n+from keras.src.applications.efficientnet import EfficientNetB2\n+from keras.src.applications.efficientnet import EfficientNetB3\n+from keras.src.applications.efficientnet import EfficientNetB4\n+from keras.src.applications.efficientnet import EfficientNetB5\n+from keras.src.applications.efficientnet import EfficientNetB6\n+from keras.src.applications.efficientnet import EfficientNetB7\n+from keras.src.applications.efficientnet_v2 import EfficientNetV2B0\n+from keras.src.applications.efficientnet_v2 import EfficientNetV2B1\n+from keras.src.applications.efficientnet_v2 import EfficientNetV2B2\n+from keras.src.applications.efficientnet_v2 import EfficientNetV2B3\n+from keras.src.applications.efficientnet_v2 import EfficientNetV2L\n+from keras.src.applications.efficientnet_v2 import EfficientNetV2M\n+from keras.src.applications.efficientnet_v2 import EfficientNetV2S\n+from keras.src.applications.inception_resnet_v2 import InceptionResNetV2\n+from keras.src.applications.inception_v3 import InceptionV3\n+from keras.src.applications.mobilenet import MobileNet\n+from keras.src.applications.mobilenet_v2 import MobileNetV2\n+from keras.src.applications.mobilenet_v3 import MobileNetV3Large\n+from keras.src.applications.mobilenet_v3 import MobileNetV3Small\n+from keras.src.applications.nasnet import NASNetLarge\n+from keras.src.applications.nasnet import NASNetMobile\n+from keras.src.applications.resnet import ResNet50\n+from keras.src.applications.resnet import ResNet101\n+from keras.src.applications.resnet import ResNet152\n+from keras.src.applications.resnet_v2 import ResNet50V2\n+from keras.src.applications.resnet_v2 import ResNet101V2\n+from keras.src.applications.resnet_v2 import ResNet152V2\n+from keras.src.applications.vgg16 import VGG16\n+from keras.src.applications.vgg19 import VGG19\n+from keras.src.applications.xception import Xception\n\n@@ -0,0 +1,13 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.applications.convnext import ConvNeXtBase\n+from keras.src.applications.convnext import ConvNeXtLarge\n+from keras.src.applications.convnext import ConvNeXtSmall\n+from keras.src.applications.convnext import ConvNeXtTiny\n+from keras.src.applications.convnext import ConvNeXtXLarge\n+from keras.src.applications.convnext import decode_predictions\n+from keras.src.applications.convnext import preprocess_input\n\n@@ -0,0 +1,11 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.applications.densenet import DenseNet121\n+from keras.src.applications.densenet import DenseNet169\n+from keras.src.applications.densenet import DenseNet201\n+from keras.src.applications.densenet import decode_predictions\n+from keras.src.applications.densenet import preprocess_input\n\n@@ -0,0 +1,16 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.applications.efficientnet import EfficientNetB0\n+from keras.src.applications.efficientnet import EfficientNetB1\n+from keras.src.applications.efficientnet import EfficientNetB2\n+from keras.src.applications.efficientnet import EfficientNetB3\n+from keras.src.applications.efficientnet import EfficientNetB4\n+from keras.src.applications.efficientnet import EfficientNetB5\n+from keras.src.applications.efficientnet import EfficientNetB6\n+from keras.src.applications.efficientnet import EfficientNetB7\n+from keras.src.applications.efficientnet import decode_predictions\n+from keras.src.applications.efficientnet import preprocess_input\n\n@@ -0,0 +1,15 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.applications.efficientnet_v2 import EfficientNetV2B0\n+from keras.src.applications.efficientnet_v2 import EfficientNetV2B1\n+from keras.src.applications.efficientnet_v2 import EfficientNetV2B2\n+from keras.src.applications.efficientnet_v2 import EfficientNetV2B3\n+from keras.src.applications.efficientnet_v2 import EfficientNetV2L\n+from keras.src.applications.efficientnet_v2 import EfficientNetV2M\n+from keras.src.applications.efficientnet_v2 import EfficientNetV2S\n+from keras.src.applications.efficientnet_v2 import decode_predictions\n+from keras.src.applications.efficientnet_v2 import preprocess_input\n\n@@ -0,0 +1,8 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.applications.imagenet_utils import decode_predictions\n+from keras.src.applications.imagenet_utils import preprocess_input\n\n@@ -0,0 +1,9 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.applications.inception_resnet_v2 import InceptionResNetV2\n+from keras.src.applications.inception_resnet_v2 import decode_predictions\n+from keras.src.applications.inception_resnet_v2 import preprocess_input\n\n@@ -0,0 +1,9 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.applications.inception_v3 import InceptionV3\n+from keras.src.applications.inception_v3 import decode_predictions\n+from keras.src.applications.inception_v3 import preprocess_input\n\n@@ -0,0 +1,9 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.applications.mobilenet import MobileNet\n+from keras.src.applications.mobilenet import decode_predictions\n+from keras.src.applications.mobilenet import preprocess_input\n\n@@ -0,0 +1,9 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.applications.mobilenet_v2 import MobileNetV2\n+from keras.src.applications.mobilenet_v2 import decode_predictions\n+from keras.src.applications.mobilenet_v2 import preprocess_input\n\n@@ -0,0 +1,8 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.applications.mobilenet_v3 import decode_predictions\n+from keras.src.applications.mobilenet_v3 import preprocess_input\n\n@@ -0,0 +1,10 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.applications.nasnet import NASNetLarge\n+from keras.src.applications.nasnet import NASNetMobile\n+from keras.src.applications.nasnet import decode_predictions\n+from keras.src.applications.nasnet import preprocess_input\n\n@@ -0,0 +1,11 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.applications.resnet import ResNet50\n+from keras.src.applications.resnet import ResNet101\n+from keras.src.applications.resnet import ResNet152\n+from keras.src.applications.resnet import decode_predictions\n+from keras.src.applications.resnet import preprocess_input\n\n@@ -0,0 +1,9 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.applications.resnet import ResNet50\n+from keras.src.applications.resnet import decode_predictions\n+from keras.src.applications.resnet import preprocess_input\n\n@@ -0,0 +1,11 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.applications.resnet_v2 import ResNet50V2\n+from keras.src.applications.resnet_v2 import ResNet101V2\n+from keras.src.applications.resnet_v2 import ResNet152V2\n+from keras.src.applications.resnet_v2 import decode_predictions\n+from keras.src.applications.resnet_v2 import preprocess_input\n\n@@ -0,0 +1,9 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.applications.vgg16 import VGG16\n+from keras.src.applications.vgg16 import decode_predictions\n+from keras.src.applications.vgg16 import preprocess_input\n\n@@ -0,0 +1,9 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.applications.vgg19 import VGG19\n+from keras.src.applications.vgg19 import decode_predictions\n+from keras.src.applications.vgg19 import preprocess_input\n\n@@ -0,0 +1,9 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.applications.xception import Xception\n+from keras.src.applications.xception import decode_predictions\n+from keras.src.applications.xception import preprocess_input\n\n@@ -0,0 +1,20 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.backend.common.dtypes import result_type\n+from keras.src.backend.common.global_state import clear_session\n+from keras.src.backend.common.keras_tensor import is_keras_tensor\n+from keras.src.backend.common.variables import is_float_dtype\n+from keras.src.backend.common.variables import is_int_dtype\n+from keras.src.backend.common.variables import standardize_dtype\n+from keras.src.backend.config import backend\n+from keras.src.backend.config import epsilon\n+from keras.src.backend.config import floatx\n+from keras.src.backend.config import image_data_format\n+from keras.src.backend.config import set_epsilon\n+from keras.src.backend.config import set_floatx\n+from keras.src.backend.config import set_image_data_format\n+from keras.src.utils.naming import get_uid\n\n@@ -0,0 +1,21 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.callbacks.backup_and_restore import BackupAndRestore\n+from keras.src.callbacks.callback import Callback\n+from keras.src.callbacks.callback_list import CallbackList\n+from keras.src.callbacks.csv_logger import CSVLogger\n+from keras.src.callbacks.early_stopping import EarlyStopping\n+from keras.src.callbacks.history import History\n+from keras.src.callbacks.lambda_callback import LambdaCallback\n+from keras.src.callbacks.learning_rate_scheduler import LearningRateScheduler\n+from keras.src.callbacks.model_checkpoint import ModelCheckpoint\n+from keras.src.callbacks.progbar_logger import ProgbarLogger\n+from keras.src.callbacks.reduce_lr_on_plateau import ReduceLROnPlateau\n+from keras.src.callbacks.remote_monitor import RemoteMonitor\n+from keras.src.callbacks.swap_ema_weights import SwapEMAWeights\n+from keras.src.callbacks.tensorboard import TensorBoard\n+from keras.src.callbacks.terminate_on_nan import TerminateOnNaN\n\n@@ -0,0 +1,23 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.backend.config import backend\n+from keras.src.backend.config import epsilon\n+from keras.src.backend.config import floatx\n+from keras.src.backend.config import image_data_format\n+from keras.src.backend.config import set_epsilon\n+from keras.src.backend.config import set_floatx\n+from keras.src.backend.config import set_image_data_format\n+from keras.src.dtype_policies.dtype_policy import dtype_policy\n+from keras.src.dtype_policies.dtype_policy import set_dtype_policy\n+from keras.src.saving.serialization_lib import enable_unsafe_deserialization\n+from keras.src.utils.backend_utils import set_backend\n+from keras.src.utils.io_utils import disable_interactive_logging\n+from keras.src.utils.io_utils import enable_interactive_logging\n+from keras.src.utils.io_utils import is_interactive_logging_enabled\n+from keras.src.utils.traceback_utils import disable_traceback_filtering\n+from keras.src.utils.traceback_utils import enable_traceback_filtering\n+from keras.src.utils.traceback_utils import is_traceback_filtering_enabled\n\n@@ -0,0 +1,18 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.constraints import deserialize\n+from keras.src.constraints import get\n+from keras.src.constraints import serialize\n+from keras.src.constraints.constraints import Constraint\n+from keras.src.constraints.constraints import MaxNorm\n+from keras.src.constraints.constraints import MaxNorm as max_norm\n+from keras.src.constraints.constraints import MinMaxNorm\n+from keras.src.constraints.constraints import MinMaxNorm as min_max_norm\n+from keras.src.constraints.constraints import NonNeg\n+from keras.src.constraints.constraints import NonNeg as non_neg\n+from keras.src.constraints.constraints import UnitNorm\n+from keras.src.constraints.constraints import UnitNorm as unit_norm\n\n@@ -0,0 +1,14 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.api.datasets import boston_housing\n+from keras.api.datasets import california_housing\n+from keras.api.datasets import cifar10\n+from keras.api.datasets import cifar100\n+from keras.api.datasets import fashion_mnist\n+from keras.api.datasets import imdb\n+from keras.api.datasets import mnist\n+from keras.api.datasets import reuters\n\n@@ -0,0 +1,7 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.datasets.boston_housing import load_data\n\n@@ -0,0 +1,7 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.datasets.california_housing import load_data\n\n@@ -0,0 +1,7 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.datasets.cifar10 import load_data\n\n@@ -0,0 +1,7 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.datasets.cifar100 import load_data\n\n@@ -0,0 +1,7 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.datasets.fashion_mnist import load_data\n\n@@ -0,0 +1,8 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.datasets.imdb import get_word_index\n+from keras.src.datasets.imdb import load_data\n\n@@ -0,0 +1,7 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.datasets.mnist import load_data\n\n@@ -0,0 +1,9 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.datasets.reuters import get_label_names\n+from keras.src.datasets.reuters import get_word_index\n+from keras.src.datasets.reuters import load_data\n\n@@ -0,0 +1,16 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.distribution.distribution_lib import DataParallel\n+from keras.src.distribution.distribution_lib import DeviceMesh\n+from keras.src.distribution.distribution_lib import LayoutMap\n+from keras.src.distribution.distribution_lib import ModelParallel\n+from keras.src.distribution.distribution_lib import TensorLayout\n+from keras.src.distribution.distribution_lib import distribute_tensor\n+from keras.src.distribution.distribution_lib import distribution\n+from keras.src.distribution.distribution_lib import initialize\n+from keras.src.distribution.distribution_lib import list_devices\n+from keras.src.distribution.distribution_lib import set_distribution\n\n@@ -0,0 +1,10 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.dtype_policies.dtype_policy import DTypePolicy\n+from keras.src.dtype_policies.dtype_policy import FloatDTypePolicy\n+from keras.src.dtype_policies.dtype_policy import QuantizedDTypePolicy\n+from keras.src.dtype_policies.dtype_policy import QuantizedFloat8DTypePolicy\n\n@@ -0,0 +1,7 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.export.export_lib import ExportArchive\n\n@@ -0,0 +1,64 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.initializers import deserialize\n+from keras.src.initializers import get\n+from keras.src.initializers import serialize\n+from keras.src.initializers.constant_initializers import Constant\n+from keras.src.initializers.constant_initializers import Constant as constant\n+from keras.src.initializers.constant_initializers import Identity\n+from keras.src.initializers.constant_initializers import (\n+    Identity as IdentityInitializer,\n+)\n+from keras.src.initializers.constant_initializers import Identity as identity\n+from keras.src.initializers.constant_initializers import Ones\n+from keras.src.initializers.constant_initializers import Ones as ones\n+from keras.src.initializers.constant_initializers import Zeros\n+from keras.src.initializers.constant_initializers import Zeros as zeros\n+from keras.src.initializers.initializer import Initializer\n+from keras.src.initializers.random_initializers import GlorotNormal\n+from keras.src.initializers.random_initializers import (\n+    GlorotNormal as glorot_normal,\n+)\n+from keras.src.initializers.random_initializers import GlorotUniform\n+from keras.src.initializers.random_initializers import (\n+    GlorotUniform as glorot_uniform,\n+)\n+from keras.src.initializers.random_initializers import HeNormal\n+from keras.src.initializers.random_initializers import HeNormal as he_normal\n+from keras.src.initializers.random_initializers import HeUniform\n+from keras.src.initializers.random_initializers import HeUniform as he_uniform\n+from keras.src.initializers.random_initializers import LecunNormal\n+from keras.src.initializers.random_initializers import (\n+    LecunNormal as lecun_normal,\n+)\n+from keras.src.initializers.random_initializers import LecunUniform\n+from keras.src.initializers.random_initializers import (\n+    LecunUniform as lecun_uniform,\n+)\n+from keras.src.initializers.random_initializers import OrthogonalInitializer\n+from keras.src.initializers.random_initializers import (\n+    OrthogonalInitializer as Orthogonal,\n+)\n+from keras.src.initializers.random_initializers import (\n+    OrthogonalInitializer as orthogonal,\n+)\n+from keras.src.initializers.random_initializers import RandomNormal\n+from keras.src.initializers.random_initializers import (\n+    RandomNormal as random_normal,\n+)\n+from keras.src.initializers.random_initializers import RandomUniform\n+from keras.src.initializers.random_initializers import (\n+    RandomUniform as random_uniform,\n+)\n+from keras.src.initializers.random_initializers import TruncatedNormal\n+from keras.src.initializers.random_initializers import (\n+    TruncatedNormal as truncated_normal,\n+)\n+from keras.src.initializers.random_initializers import VarianceScaling\n+from keras.src.initializers.random_initializers import (\n+    VarianceScaling as variance_scaling,\n+)\n\n@@ -0,0 +1,195 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.export.export_lib import TFSMLayer\n+from keras.src.layers import deserialize\n+from keras.src.layers import serialize\n+from keras.src.layers.activations.activation import Activation\n+from keras.src.layers.activations.elu import ELU\n+from keras.src.layers.activations.leaky_relu import LeakyReLU\n+from keras.src.layers.activations.prelu import PReLU\n+from keras.src.layers.activations.relu import ReLU\n+from keras.src.layers.activations.softmax import Softmax\n+from keras.src.layers.attention.additive_attention import AdditiveAttention\n+from keras.src.layers.attention.attention import Attention\n+from keras.src.layers.attention.grouped_query_attention import (\n+    GroupedQueryAttention as GroupQueryAttention,\n+)\n+from keras.src.layers.attention.multi_head_attention import MultiHeadAttention\n+from keras.src.layers.convolutional.conv1d import Conv1D\n+from keras.src.layers.convolutional.conv1d import Conv1D as Convolution1D\n+from keras.src.layers.convolutional.conv1d_transpose import Conv1DTranspose\n+from keras.src.layers.convolutional.conv1d_transpose import (\n+    Conv1DTranspose as Convolution1DTranspose,\n+)\n+from keras.src.layers.convolutional.conv2d import Conv2D\n+from keras.src.layers.convolutional.conv2d import Conv2D as Convolution2D\n+from keras.src.layers.convolutional.conv2d_transpose import Conv2DTranspose\n+from keras.src.layers.convolutional.conv2d_transpose import (\n+    Conv2DTranspose as Convolution2DTranspose,\n+)\n+from keras.src.layers.convolutional.conv3d import Conv3D\n+from keras.src.layers.convolutional.conv3d import Conv3D as Convolution3D\n+from keras.src.layers.convolutional.conv3d_transpose import Conv3DTranspose\n+from keras.src.layers.convolutional.conv3d_transpose import (\n+    Conv3DTranspose as Convolution3DTranspose,\n+)\n+from keras.src.layers.convolutional.depthwise_conv1d import DepthwiseConv1D\n+from keras.src.layers.convolutional.depthwise_conv2d import DepthwiseConv2D\n+from keras.src.layers.convolutional.separable_conv1d import SeparableConv1D\n+from keras.src.layers.convolutional.separable_conv1d import (\n+    SeparableConv1D as SeparableConvolution1D,\n+)\n+from keras.src.layers.convolutional.separable_conv2d import SeparableConv2D\n+from keras.src.layers.convolutional.separable_conv2d import (\n+    SeparableConv2D as SeparableConvolution2D,\n+)\n+from keras.src.layers.core.dense import Dense\n+from keras.src.layers.core.einsum_dense import EinsumDense\n+from keras.src.layers.core.embedding import Embedding\n+from keras.src.layers.core.identity import Identity\n+from keras.src.layers.core.input_layer import Input\n+from keras.src.layers.core.input_layer import InputLayer\n+from keras.src.layers.core.lambda_layer import Lambda\n+from keras.src.layers.core.masking import Masking\n+from keras.src.layers.core.wrapper import Wrapper\n+from keras.src.layers.input_spec import InputSpec\n+from keras.src.layers.layer import Layer\n+from keras.src.layers.merging.add import Add\n+from keras.src.layers.merging.add import add\n+from keras.src.layers.merging.average import Average\n+from keras.src.layers.merging.average import average\n+from keras.src.layers.merging.concatenate import Concatenate\n+from keras.src.layers.merging.concatenate import concatenate\n+from keras.src.layers.merging.dot import Dot\n+from keras.src.layers.merging.dot import dot\n+from keras.src.layers.merging.maximum import Maximum\n+from keras.src.layers.merging.maximum import maximum\n+from keras.src.layers.merging.minimum import Minimum\n+from keras.src.layers.merging.minimum import minimum\n+from keras.src.layers.merging.multiply import Multiply\n+from keras.src.layers.merging.multiply import multiply\n+from keras.src.layers.merging.subtract import Subtract\n+from keras.src.layers.merging.subtract import subtract\n+from keras.src.layers.normalization.batch_normalization import (\n+    BatchNormalization,\n+)\n+from keras.src.layers.normalization.group_normalization import (\n+    GroupNormalization,\n+)\n+from keras.src.layers.normalization.layer_normalization import (\n+    LayerNormalization,\n+)\n+from keras.src.layers.normalization.spectral_normalization import (\n+    SpectralNormalization,\n+)\n+from keras.src.layers.normalization.unit_normalization import UnitNormalization\n+from keras.src.layers.pooling.average_pooling1d import AveragePooling1D\n+from keras.src.layers.pooling.average_pooling1d import (\n+    AveragePooling1D as AvgPool1D,\n+)\n+from keras.src.layers.pooling.average_pooling2d import AveragePooling2D\n+from keras.src.layers.pooling.average_pooling2d import (\n+    AveragePooling2D as AvgPool2D,\n+)\n+from keras.src.layers.pooling.average_pooling3d import AveragePooling3D\n+from keras.src.layers.pooling.average_pooling3d import (\n+    AveragePooling3D as AvgPool3D,\n+)\n+from keras.src.layers.pooling.global_average_pooling1d import (\n+    GlobalAveragePooling1D,\n+)\n+from keras.src.layers.pooling.global_average_pooling1d import (\n+    GlobalAveragePooling1D as GlobalAvgPool1D,\n+)\n+from keras.src.layers.pooling.global_average_pooling2d import (\n+    GlobalAveragePooling2D,\n+)\n+from keras.src.layers.pooling.global_average_pooling2d import (\n+    GlobalAveragePooling2D as GlobalAvgPool2D,\n+)\n+from keras.src.layers.pooling.global_average_pooling3d import (\n+    GlobalAveragePooling3D,\n+)\n+from keras.src.layers.pooling.global_average_pooling3d import (\n+    GlobalAveragePooling3D as GlobalAvgPool3D,\n+)\n+from keras.src.layers.pooling.global_max_pooling1d import GlobalMaxPooling1D\n+from keras.src.layers.pooling.global_max_pooling1d import (\n+    GlobalMaxPooling1D as GlobalMaxPool1D,\n+)\n+from keras.src.layers.pooling.global_max_pooling2d import GlobalMaxPooling2D\n+from keras.src.layers.pooling.global_max_pooling2d import (\n+    GlobalMaxPooling2D as GlobalMaxPool2D,\n+)\n+from keras.src.layers.pooling.global_max_pooling3d import GlobalMaxPooling3D\n+from keras.src.layers.pooling.global_max_pooling3d import (\n+    GlobalMaxPooling3D as GlobalMaxPool3D,\n+)\n+from keras.src.layers.pooling.max_pooling1d import MaxPooling1D\n+from keras.src.layers.pooling.max_pooling1d import MaxPooling1D as MaxPool1D\n+from keras.src.layers.pooling.max_pooling2d import MaxPooling2D\n+from keras.src.layers.pooling.max_pooling2d import MaxPooling2D as MaxPool2D\n+from keras.src.layers.pooling.max_pooling3d import MaxPooling3D\n+from keras.src.layers.pooling.max_pooling3d import MaxPooling3D as MaxPool3D\n+from keras.src.layers.preprocessing.audio_preprocessing import MelSpectrogram\n+from keras.src.layers.preprocessing.category_encoding import CategoryEncoding\n+from keras.src.layers.preprocessing.center_crop import CenterCrop\n+from keras.src.layers.preprocessing.discretization import Discretization\n+from keras.src.layers.preprocessing.hashed_crossing import HashedCrossing\n+from keras.src.layers.preprocessing.hashing import Hashing\n+from keras.src.layers.preprocessing.integer_lookup import IntegerLookup\n+from keras.src.layers.preprocessing.normalization import Normalization\n+from keras.src.layers.preprocessing.random_brightness import RandomBrightness\n+from keras.src.layers.preprocessing.random_contrast import RandomContrast\n+from keras.src.layers.preprocessing.random_crop import RandomCrop\n+from keras.src.layers.preprocessing.random_flip import RandomFlip\n+from keras.src.layers.preprocessing.random_rotation import RandomRotation\n+from keras.src.layers.preprocessing.random_translation import RandomTranslation\n+from keras.src.layers.preprocessing.random_zoom import RandomZoom\n+from keras.src.layers.preprocessing.rescaling import Rescaling\n+from keras.src.layers.preprocessing.resizing import Resizing\n+from keras.src.layers.preprocessing.string_lookup import StringLookup\n+from keras.src.layers.preprocessing.text_vectorization import TextVectorization\n+from keras.src.layers.regularization.activity_regularization import (\n+    ActivityRegularization,\n+)\n+from keras.src.layers.regularization.alpha_dropout import AlphaDropout\n+from keras.src.layers.regularization.dropout import Dropout\n+from keras.src.layers.regularization.gaussian_dropout import GaussianDropout\n+from keras.src.layers.regularization.gaussian_noise import GaussianNoise\n+from keras.src.layers.regularization.spatial_dropout import SpatialDropout1D\n+from keras.src.layers.regularization.spatial_dropout import SpatialDropout2D\n+from keras.src.layers.regularization.spatial_dropout import SpatialDropout3D\n+from keras.src.layers.reshaping.cropping1d import Cropping1D\n+from keras.src.layers.reshaping.cropping2d import Cropping2D\n+from keras.src.layers.reshaping.cropping3d import Cropping3D\n+from keras.src.layers.reshaping.flatten import Flatten\n+from keras.src.layers.reshaping.permute import Permute\n+from keras.src.layers.reshaping.repeat_vector import RepeatVector\n+from keras.src.layers.reshaping.reshape import Reshape\n+from keras.src.layers.reshaping.up_sampling1d import UpSampling1D\n+from keras.src.layers.reshaping.up_sampling2d import UpSampling2D\n+from keras.src.layers.reshaping.up_sampling3d import UpSampling3D\n+from keras.src.layers.reshaping.zero_padding1d import ZeroPadding1D\n+from keras.src.layers.reshaping.zero_padding2d import ZeroPadding2D\n+from keras.src.layers.reshaping.zero_padding3d import ZeroPadding3D\n+from keras.src.layers.rnn.bidirectional import Bidirectional\n+from keras.src.layers.rnn.conv_lstm1d import ConvLSTM1D\n+from keras.src.layers.rnn.conv_lstm2d import ConvLSTM2D\n+from keras.src.layers.rnn.conv_lstm3d import ConvLSTM3D\n+from keras.src.layers.rnn.gru import GRU\n+from keras.src.layers.rnn.gru import GRUCell\n+from keras.src.layers.rnn.lstm import LSTM\n+from keras.src.layers.rnn.lstm import LSTMCell\n+from keras.src.layers.rnn.rnn import RNN\n+from keras.src.layers.rnn.simple_rnn import SimpleRNN\n+from keras.src.layers.rnn.simple_rnn import SimpleRNNCell\n+from keras.src.layers.rnn.stacked_rnn_cells import StackedRNNCells\n+from keras.src.layers.rnn.time_distributed import TimeDistributed\n+from keras.src.utils.jax_layer import FlaxLayer\n+from keras.src.utils.jax_layer import JaxLayer\n+from keras.src.utils.torch_utils import TorchModuleWrapper\n\n@@ -0,0 +1,7 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.api.legacy import saving\n\n@@ -0,0 +1,8 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.legacy.saving.serialization import deserialize_keras_object\n+from keras.src.legacy.saving.serialization import serialize_keras_object\n\n@@ -0,0 +1,50 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.losses import deserialize\n+from keras.src.losses import get\n+from keras.src.losses import serialize\n+from keras.src.losses.loss import Loss\n+from keras.src.losses.losses import CTC\n+from keras.src.losses.losses import BinaryCrossentropy\n+from keras.src.losses.losses import BinaryFocalCrossentropy\n+from keras.src.losses.losses import CategoricalCrossentropy\n+from keras.src.losses.losses import CategoricalFocalCrossentropy\n+from keras.src.losses.losses import CategoricalHinge\n+from keras.src.losses.losses import CosineSimilarity\n+from keras.src.losses.losses import Dice\n+from keras.src.losses.losses import Hinge\n+from keras.src.losses.losses import Huber\n+from keras.src.losses.losses import KLDivergence\n+from keras.src.losses.losses import LogCosh\n+from keras.src.losses.losses import MeanAbsoluteError\n+from keras.src.losses.losses import MeanAbsolutePercentageError\n+from keras.src.losses.losses import MeanSquaredError\n+from keras.src.losses.losses import MeanSquaredLogarithmicError\n+from keras.src.losses.losses import Poisson\n+from keras.src.losses.losses import SparseCategoricalCrossentropy\n+from keras.src.losses.losses import SquaredHinge\n+from keras.src.losses.losses import Tversky\n+from keras.src.losses.losses import binary_crossentropy\n+from keras.src.losses.losses import binary_focal_crossentropy\n+from keras.src.losses.losses import categorical_crossentropy\n+from keras.src.losses.losses import categorical_focal_crossentropy\n+from keras.src.losses.losses import categorical_hinge\n+from keras.src.losses.losses import cosine_similarity\n+from keras.src.losses.losses import ctc\n+from keras.src.losses.losses import dice\n+from keras.src.losses.losses import hinge\n+from keras.src.losses.losses import huber\n+from keras.src.losses.losses import kl_divergence\n+from keras.src.losses.losses import log_cosh\n+from keras.src.losses.losses import mean_absolute_error\n+from keras.src.losses.losses import mean_absolute_percentage_error\n+from keras.src.losses.losses import mean_squared_error\n+from keras.src.losses.losses import mean_squared_logarithmic_error\n+from keras.src.losses.losses import poisson\n+from keras.src.losses.losses import sparse_categorical_crossentropy\n+from keras.src.losses.losses import squared_hinge\n+from keras.src.losses.losses import tversky\n\n@@ -0,0 +1,76 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.losses.losses import binary_crossentropy\n+from keras.src.losses.losses import binary_focal_crossentropy\n+from keras.src.losses.losses import categorical_crossentropy\n+from keras.src.losses.losses import categorical_focal_crossentropy\n+from keras.src.losses.losses import categorical_hinge\n+from keras.src.losses.losses import hinge\n+from keras.src.losses.losses import huber\n+from keras.src.losses.losses import kl_divergence\n+from keras.src.losses.losses import log_cosh\n+from keras.src.losses.losses import mean_absolute_error\n+from keras.src.losses.losses import mean_absolute_percentage_error\n+from keras.src.losses.losses import mean_squared_error\n+from keras.src.losses.losses import mean_squared_logarithmic_error\n+from keras.src.losses.losses import poisson\n+from keras.src.losses.losses import sparse_categorical_crossentropy\n+from keras.src.losses.losses import squared_hinge\n+from keras.src.metrics import deserialize\n+from keras.src.metrics import get\n+from keras.src.metrics import serialize\n+from keras.src.metrics.accuracy_metrics import Accuracy\n+from keras.src.metrics.accuracy_metrics import BinaryAccuracy\n+from keras.src.metrics.accuracy_metrics import CategoricalAccuracy\n+from keras.src.metrics.accuracy_metrics import SparseCategoricalAccuracy\n+from keras.src.metrics.accuracy_metrics import SparseTopKCategoricalAccuracy\n+from keras.src.metrics.accuracy_metrics import TopKCategoricalAccuracy\n+from keras.src.metrics.accuracy_metrics import binary_accuracy\n+from keras.src.metrics.accuracy_metrics import categorical_accuracy\n+from keras.src.metrics.accuracy_metrics import sparse_categorical_accuracy\n+from keras.src.metrics.accuracy_metrics import sparse_top_k_categorical_accuracy\n+from keras.src.metrics.accuracy_metrics import top_k_categorical_accuracy\n+from keras.src.metrics.confusion_metrics import AUC\n+from keras.src.metrics.confusion_metrics import FalseNegatives\n+from keras.src.metrics.confusion_metrics import FalsePositives\n+from keras.src.metrics.confusion_metrics import Precision\n+from keras.src.metrics.confusion_metrics import PrecisionAtRecall\n+from keras.src.metrics.confusion_metrics import Recall\n+from keras.src.metrics.confusion_metrics import RecallAtPrecision\n+from keras.src.metrics.confusion_metrics import SensitivityAtSpecificity\n+from keras.src.metrics.confusion_metrics import SpecificityAtSensitivity\n+from keras.src.metrics.confusion_metrics import TrueNegatives\n+from keras.src.metrics.confusion_metrics import TruePositives\n+from keras.src.metrics.f_score_metrics import F1Score\n+from keras.src.metrics.f_score_metrics import FBetaScore\n+from keras.src.metrics.hinge_metrics import CategoricalHinge\n+from keras.src.metrics.hinge_metrics import Hinge\n+from keras.src.metrics.hinge_metrics import SquaredHinge\n+from keras.src.metrics.iou_metrics import BinaryIoU\n+from keras.src.metrics.iou_metrics import IoU\n+from keras.src.metrics.iou_metrics import MeanIoU\n+from keras.src.metrics.iou_metrics import OneHotIoU\n+from keras.src.metrics.iou_metrics import OneHotMeanIoU\n+from keras.src.metrics.metric import Metric\n+from keras.src.metrics.probabilistic_metrics import BinaryCrossentropy\n+from keras.src.metrics.probabilistic_metrics import CategoricalCrossentropy\n+from keras.src.metrics.probabilistic_metrics import KLDivergence\n+from keras.src.metrics.probabilistic_metrics import Poisson\n+from keras.src.metrics.probabilistic_metrics import (\n+    SparseCategoricalCrossentropy,\n+)\n+from keras.src.metrics.reduction_metrics import Mean\n+from keras.src.metrics.reduction_metrics import MeanMetricWrapper\n+from keras.src.metrics.reduction_metrics import Sum\n+from keras.src.metrics.regression_metrics import CosineSimilarity\n+from keras.src.metrics.regression_metrics import LogCoshError\n+from keras.src.metrics.regression_metrics import MeanAbsoluteError\n+from keras.src.metrics.regression_metrics import MeanAbsolutePercentageError\n+from keras.src.metrics.regression_metrics import MeanSquaredError\n+from keras.src.metrics.regression_metrics import MeanSquaredLogarithmicError\n+from keras.src.metrics.regression_metrics import R2Score\n+from keras.src.metrics.regression_metrics import RootMeanSquaredError\n\n@@ -0,0 +1,15 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.dtype_policies.dtype_policy import DTypePolicy\n+from keras.src.dtype_policies.dtype_policy import DTypePolicy as Policy\n+from keras.src.dtype_policies.dtype_policy import dtype_policy\n+from keras.src.dtype_policies.dtype_policy import dtype_policy as global_policy\n+from keras.src.dtype_policies.dtype_policy import set_dtype_policy\n+from keras.src.dtype_policies.dtype_policy import (\n+    set_dtype_policy as set_global_policy,\n+)\n+from keras.src.optimizers.loss_scale_optimizer import LossScaleOptimizer\n\n@@ -0,0 +1,12 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.models.cloning import clone_model\n+from keras.src.models.model import Model\n+from keras.src.models.model import model_from_json\n+from keras.src.models.sequential import Sequential\n+from keras.src.saving.saving_api import load_model\n+from keras.src.saving.saving_api import save_model\n\n@@ -0,0 +1,223 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.api.ops import image\n+from keras.api.ops import linalg\n+from keras.api.ops import nn\n+from keras.api.ops import numpy\n+from keras.src.ops.core import cast\n+from keras.src.ops.core import cond\n+from keras.src.ops.core import convert_to_numpy\n+from keras.src.ops.core import convert_to_tensor\n+from keras.src.ops.core import custom_gradient\n+from keras.src.ops.core import fori_loop\n+from keras.src.ops.core import is_tensor\n+from keras.src.ops.core import scatter\n+from keras.src.ops.core import scatter_update\n+from keras.src.ops.core import shape\n+from keras.src.ops.core import slice\n+from keras.src.ops.core import slice_update\n+from keras.src.ops.core import stop_gradient\n+from keras.src.ops.core import unstack\n+from keras.src.ops.core import vectorized_map\n+from keras.src.ops.core import while_loop\n+from keras.src.ops.linalg import cholesky\n+from keras.src.ops.linalg import det\n+from keras.src.ops.linalg import eig\n+from keras.src.ops.linalg import inv\n+from keras.src.ops.linalg import lu_factor\n+from keras.src.ops.linalg import norm\n+from keras.src.ops.linalg import qr\n+from keras.src.ops.linalg import solve\n+from keras.src.ops.linalg import solve_triangular\n+from keras.src.ops.linalg import svd\n+from keras.src.ops.math import erf\n+from keras.src.ops.math import erfinv\n+from keras.src.ops.math import extract_sequences\n+from keras.src.ops.math import fft\n+from keras.src.ops.math import fft2\n+from keras.src.ops.math import in_top_k\n+from keras.src.ops.math import irfft\n+from keras.src.ops.math import istft\n+from keras.src.ops.math import logsumexp\n+from keras.src.ops.math import rfft\n+from keras.src.ops.math import rsqrt\n+from keras.src.ops.math import segment_max\n+from keras.src.ops.math import segment_sum\n+from keras.src.ops.math import stft\n+from keras.src.ops.math import top_k\n+from keras.src.ops.nn import average_pool\n+from keras.src.ops.nn import batch_normalization\n+from keras.src.ops.nn import binary_crossentropy\n+from keras.src.ops.nn import categorical_crossentropy\n+from keras.src.ops.nn import conv\n+from keras.src.ops.nn import conv_transpose\n+from keras.src.ops.nn import ctc_loss\n+from keras.src.ops.nn import depthwise_conv\n+from keras.src.ops.nn import elu\n+from keras.src.ops.nn import gelu\n+from keras.src.ops.nn import hard_sigmoid\n+from keras.src.ops.nn import hard_silu\n+from keras.src.ops.nn import hard_silu as hard_swish\n+from keras.src.ops.nn import leaky_relu\n+from keras.src.ops.nn import log_sigmoid\n+from keras.src.ops.nn import log_softmax\n+from keras.src.ops.nn import max_pool\n+from keras.src.ops.nn import moments\n+from keras.src.ops.nn import multi_hot\n+from keras.src.ops.nn import normalize\n+from keras.src.ops.nn import one_hot\n+from keras.src.ops.nn import relu\n+from keras.src.ops.nn import relu6\n+from keras.src.ops.nn import selu\n+from keras.src.ops.nn import separable_conv\n+from keras.src.ops.nn import sigmoid\n+from keras.src.ops.nn import silu\n+from keras.src.ops.nn import silu as swish\n+from keras.src.ops.nn import softmax\n+from keras.src.ops.nn import softplus\n+from keras.src.ops.nn import softsign\n+from keras.src.ops.nn import sparse_categorical_crossentropy\n+from keras.src.ops.numpy import abs\n+from keras.src.ops.numpy import absolute\n+from keras.src.ops.numpy import add\n+from keras.src.ops.numpy import all\n+from keras.src.ops.numpy import amax\n+from keras.src.ops.numpy import amin\n+from keras.src.ops.numpy import any\n+from keras.src.ops.numpy import append\n+from keras.src.ops.numpy import arange\n+from keras.src.ops.numpy import arccos\n+from keras.src.ops.numpy import arccosh\n+from keras.src.ops.numpy import arcsin\n+from keras.src.ops.numpy import arcsinh\n+from keras.src.ops.numpy import arctan\n+from keras.src.ops.numpy import arctan2\n+from keras.src.ops.numpy import arctanh\n+from keras.src.ops.numpy import argmax\n+from keras.src.ops.numpy import argmin\n+from keras.src.ops.numpy import argsort\n+from keras.src.ops.numpy import array\n+from keras.src.ops.numpy import average\n+from keras.src.ops.numpy import bincount\n+from keras.src.ops.numpy import broadcast_to\n+from keras.src.ops.numpy import ceil\n+from keras.src.ops.numpy import clip\n+from keras.src.ops.numpy import concatenate\n+from keras.src.ops.numpy import conj\n+from keras.src.ops.numpy import conjugate\n+from keras.src.ops.numpy import copy\n+from keras.src.ops.numpy import correlate\n+from keras.src.ops.numpy import cos\n+from keras.src.ops.numpy import cosh\n+from keras.src.ops.numpy import count_nonzero\n+from keras.src.ops.numpy import cross\n+from keras.src.ops.numpy import cumprod\n+from keras.src.ops.numpy import cumsum\n+from keras.src.ops.numpy import diag\n+from keras.src.ops.numpy import diagonal\n+from keras.src.ops.numpy import diff\n+from keras.src.ops.numpy import digitize\n+from keras.src.ops.numpy import divide\n+from keras.src.ops.numpy import divide_no_nan\n+from keras.src.ops.numpy import dot\n+from keras.src.ops.numpy import einsum\n+from keras.src.ops.numpy import empty\n+from keras.src.ops.numpy import equal\n+from keras.src.ops.numpy import exp\n+from keras.src.ops.numpy import expand_dims\n+from keras.src.ops.numpy import expm1\n+from keras.src.ops.numpy import eye\n+from keras.src.ops.numpy import flip\n+from keras.src.ops.numpy import floor\n+from keras.src.ops.numpy import floor_divide\n+from keras.src.ops.numpy import full\n+from keras.src.ops.numpy import full_like\n+from keras.src.ops.numpy import get_item\n+from keras.src.ops.numpy import greater\n+from keras.src.ops.numpy import greater_equal\n+from keras.src.ops.numpy import hstack\n+from keras.src.ops.numpy import identity\n+from keras.src.ops.numpy import imag\n+from keras.src.ops.numpy import isclose\n+from keras.src.ops.numpy import isfinite\n+from keras.src.ops.numpy import isinf\n+from keras.src.ops.numpy import isnan\n+from keras.src.ops.numpy import less\n+from keras.src.ops.numpy import less_equal\n+from keras.src.ops.numpy import linspace\n+from keras.src.ops.numpy import log\n+from keras.src.ops.numpy import log1p\n+from keras.src.ops.numpy import log2\n+from keras.src.ops.numpy import log10\n+from keras.src.ops.numpy import logaddexp\n+from keras.src.ops.numpy import logical_and\n+from keras.src.ops.numpy import logical_not\n+from keras.src.ops.numpy import logical_or\n+from keras.src.ops.numpy import logical_xor\n+from keras.src.ops.numpy import logspace\n+from keras.src.ops.numpy import matmul\n+from keras.src.ops.numpy import max\n+from keras.src.ops.numpy import maximum\n+from keras.src.ops.numpy import mean\n+from keras.src.ops.numpy import median\n+from keras.src.ops.numpy import meshgrid\n+from keras.src.ops.numpy import min\n+from keras.src.ops.numpy import minimum\n+from keras.src.ops.numpy import mod\n+from keras.src.ops.numpy import moveaxis\n+from keras.src.ops.numpy import multiply\n+from keras.src.ops.numpy import nan_to_num\n+from keras.src.ops.numpy import ndim\n+from keras.src.ops.numpy import negative\n+from keras.src.ops.numpy import nonzero\n+from keras.src.ops.numpy import not_equal\n+from keras.src.ops.numpy import ones\n+from keras.src.ops.numpy import ones_like\n+from keras.src.ops.numpy import outer\n+from keras.src.ops.numpy import pad\n+from keras.src.ops.numpy import power\n+from keras.src.ops.numpy import prod\n+from keras.src.ops.numpy import quantile\n+from keras.src.ops.numpy import ravel\n+from keras.src.ops.numpy import real\n+from keras.src.ops.numpy import reciprocal\n+from keras.src.ops.numpy import repeat\n+from keras.src.ops.numpy import reshape\n+from keras.src.ops.numpy import roll\n+from keras.src.ops.numpy import round\n+from keras.src.ops.numpy import sign\n+from keras.src.ops.numpy import sin\n+from keras.src.ops.numpy import sinh\n+from keras.src.ops.numpy import size\n+from keras.src.ops.numpy import sort\n+from keras.src.ops.numpy import split\n+from keras.src.ops.numpy import sqrt\n+from keras.src.ops.numpy import square\n+from keras.src.ops.numpy import squeeze\n+from keras.src.ops.numpy import stack\n+from keras.src.ops.numpy import std\n+from keras.src.ops.numpy import subtract\n+from keras.src.ops.numpy import sum\n+from keras.src.ops.numpy import swapaxes\n+from keras.src.ops.numpy import take\n+from keras.src.ops.numpy import take_along_axis\n+from keras.src.ops.numpy import tan\n+from keras.src.ops.numpy import tanh\n+from keras.src.ops.numpy import tensordot\n+from keras.src.ops.numpy import tile\n+from keras.src.ops.numpy import trace\n+from keras.src.ops.numpy import transpose\n+from keras.src.ops.numpy import tri\n+from keras.src.ops.numpy import tril\n+from keras.src.ops.numpy import triu\n+from keras.src.ops.numpy import true_divide\n+from keras.src.ops.numpy import var\n+from keras.src.ops.numpy import vdot\n+from keras.src.ops.numpy import vstack\n+from keras.src.ops.numpy import where\n+from keras.src.ops.numpy import zeros\n+from keras.src.ops.numpy import zeros_like\n\n@@ -0,0 +1,13 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.ops.image import affine_transform\n+from keras.src.ops.image import crop_images\n+from keras.src.ops.image import extract_patches\n+from keras.src.ops.image import map_coordinates\n+from keras.src.ops.image import pad_images\n+from keras.src.ops.image import resize\n+from keras.src.ops.image import rgb_to_grayscale\n\n@@ -0,0 +1,16 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.ops.linalg import cholesky\n+from keras.src.ops.linalg import det\n+from keras.src.ops.linalg import eig\n+from keras.src.ops.linalg import inv\n+from keras.src.ops.linalg import lu_factor\n+from keras.src.ops.linalg import norm\n+from keras.src.ops.linalg import qr\n+from keras.src.ops.linalg import solve\n+from keras.src.ops.linalg import solve_triangular\n+from keras.src.ops.linalg import svd\n\n@@ -0,0 +1,38 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.ops.nn import average_pool\n+from keras.src.ops.nn import batch_normalization\n+from keras.src.ops.nn import binary_crossentropy\n+from keras.src.ops.nn import categorical_crossentropy\n+from keras.src.ops.nn import conv\n+from keras.src.ops.nn import conv_transpose\n+from keras.src.ops.nn import ctc_loss\n+from keras.src.ops.nn import depthwise_conv\n+from keras.src.ops.nn import elu\n+from keras.src.ops.nn import gelu\n+from keras.src.ops.nn import hard_sigmoid\n+from keras.src.ops.nn import hard_silu\n+from keras.src.ops.nn import hard_silu as hard_swish\n+from keras.src.ops.nn import leaky_relu\n+from keras.src.ops.nn import log_sigmoid\n+from keras.src.ops.nn import log_softmax\n+from keras.src.ops.nn import max_pool\n+from keras.src.ops.nn import moments\n+from keras.src.ops.nn import multi_hot\n+from keras.src.ops.nn import normalize\n+from keras.src.ops.nn import one_hot\n+from keras.src.ops.nn import relu\n+from keras.src.ops.nn import relu6\n+from keras.src.ops.nn import selu\n+from keras.src.ops.nn import separable_conv\n+from keras.src.ops.nn import sigmoid\n+from keras.src.ops.nn import silu\n+from keras.src.ops.nn import silu as swish\n+from keras.src.ops.nn import softmax\n+from keras.src.ops.nn import softplus\n+from keras.src.ops.nn import softsign\n+from keras.src.ops.nn import sparse_categorical_crossentropy\n\n@@ -0,0 +1,146 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.ops.numpy import abs\n+from keras.src.ops.numpy import absolute\n+from keras.src.ops.numpy import add\n+from keras.src.ops.numpy import all\n+from keras.src.ops.numpy import amax\n+from keras.src.ops.numpy import amin\n+from keras.src.ops.numpy import any\n+from keras.src.ops.numpy import append\n+from keras.src.ops.numpy import arange\n+from keras.src.ops.numpy import arccos\n+from keras.src.ops.numpy import arccosh\n+from keras.src.ops.numpy import arcsin\n+from keras.src.ops.numpy import arcsinh\n+from keras.src.ops.numpy import arctan\n+from keras.src.ops.numpy import arctan2\n+from keras.src.ops.numpy import arctanh\n+from keras.src.ops.numpy import argmax\n+from keras.src.ops.numpy import argmin\n+from keras.src.ops.numpy import argsort\n+from keras.src.ops.numpy import array\n+from keras.src.ops.numpy import average\n+from keras.src.ops.numpy import bincount\n+from keras.src.ops.numpy import broadcast_to\n+from keras.src.ops.numpy import ceil\n+from keras.src.ops.numpy import clip\n+from keras.src.ops.numpy import concatenate\n+from keras.src.ops.numpy import conj\n+from keras.src.ops.numpy import conjugate\n+from keras.src.ops.numpy import copy\n+from keras.src.ops.numpy import correlate\n+from keras.src.ops.numpy import cos\n+from keras.src.ops.numpy import cosh\n+from keras.src.ops.numpy import count_nonzero\n+from keras.src.ops.numpy import cross\n+from keras.src.ops.numpy import cumprod\n+from keras.src.ops.numpy import cumsum\n+from keras.src.ops.numpy import diag\n+from keras.src.ops.numpy import diagonal\n+from keras.src.ops.numpy import diff\n+from keras.src.ops.numpy import digitize\n+from keras.src.ops.numpy import divide\n+from keras.src.ops.numpy import divide_no_nan\n+from keras.src.ops.numpy import dot\n+from keras.src.ops.numpy import einsum\n+from keras.src.ops.numpy import empty\n+from keras.src.ops.numpy import equal\n+from keras.src.ops.numpy import exp\n+from keras.src.ops.numpy import expand_dims\n+from keras.src.ops.numpy import expm1\n+from keras.src.ops.numpy import eye\n+from keras.src.ops.numpy import flip\n+from keras.src.ops.numpy import floor\n+from keras.src.ops.numpy import floor_divide\n+from keras.src.ops.numpy import full\n+from keras.src.ops.numpy import full_like\n+from keras.src.ops.numpy import get_item\n+from keras.src.ops.numpy import greater\n+from keras.src.ops.numpy import greater_equal\n+from keras.src.ops.numpy import hstack\n+from keras.src.ops.numpy import identity\n+from keras.src.ops.numpy import imag\n+from keras.src.ops.numpy import isclose\n+from keras.src.ops.numpy import isfinite\n+from keras.src.ops.numpy import isinf\n+from keras.src.ops.numpy import isnan\n+from keras.src.ops.numpy import less\n+from keras.src.ops.numpy import less_equal\n+from keras.src.ops.numpy import linspace\n+from keras.src.ops.numpy import log\n+from keras.src.ops.numpy import log1p\n+from keras.src.ops.numpy import log2\n+from keras.src.ops.numpy import log10\n+from keras.src.ops.numpy import logaddexp\n+from keras.src.ops.numpy import logical_and\n+from keras.src.ops.numpy import logical_not\n+from keras.src.ops.numpy import logical_or\n+from keras.src.ops.numpy import logical_xor\n+from keras.src.ops.numpy import logspace\n+from keras.src.ops.numpy import matmul\n+from keras.src.ops.numpy import max\n+from keras.src.ops.numpy import maximum\n+from keras.src.ops.numpy import mean\n+from keras.src.ops.numpy import median\n+from keras.src.ops.numpy import meshgrid\n+from keras.src.ops.numpy import min\n+from keras.src.ops.numpy import minimum\n+from keras.src.ops.numpy import mod\n+from keras.src.ops.numpy import moveaxis\n+from keras.src.ops.numpy import multiply\n+from keras.src.ops.numpy import nan_to_num\n+from keras.src.ops.numpy import ndim\n+from keras.src.ops.numpy import negative\n+from keras.src.ops.numpy import nonzero\n+from keras.src.ops.numpy import not_equal\n+from keras.src.ops.numpy import ones\n+from keras.src.ops.numpy import ones_like\n+from keras.src.ops.numpy import outer\n+from keras.src.ops.numpy import pad\n+from keras.src.ops.numpy import power\n+from keras.src.ops.numpy import prod\n+from keras.src.ops.numpy import quantile\n+from keras.src.ops.numpy import ravel\n+from keras.src.ops.numpy import real\n+from keras.src.ops.numpy import reciprocal\n+from keras.src.ops.numpy import repeat\n+from keras.src.ops.numpy import reshape\n+from keras.src.ops.numpy import roll\n+from keras.src.ops.numpy import round\n+from keras.src.ops.numpy import sign\n+from keras.src.ops.numpy import sin\n+from keras.src.ops.numpy import sinh\n+from keras.src.ops.numpy import size\n+from keras.src.ops.numpy import sort\n+from keras.src.ops.numpy import split\n+from keras.src.ops.numpy import sqrt\n+from keras.src.ops.numpy import square\n+from keras.src.ops.numpy import squeeze\n+from keras.src.ops.numpy import stack\n+from keras.src.ops.numpy import std\n+from keras.src.ops.numpy import subtract\n+from keras.src.ops.numpy import sum\n+from keras.src.ops.numpy import swapaxes\n+from keras.src.ops.numpy import take\n+from keras.src.ops.numpy import take_along_axis\n+from keras.src.ops.numpy import tan\n+from keras.src.ops.numpy import tanh\n+from keras.src.ops.numpy import tensordot\n+from keras.src.ops.numpy import tile\n+from keras.src.ops.numpy import trace\n+from keras.src.ops.numpy import transpose\n+from keras.src.ops.numpy import tri\n+from keras.src.ops.numpy import tril\n+from keras.src.ops.numpy import triu\n+from keras.src.ops.numpy import true_divide\n+from keras.src.ops.numpy import var\n+from keras.src.ops.numpy import vdot\n+from keras.src.ops.numpy import vstack\n+from keras.src.ops.numpy import where\n+from keras.src.ops.numpy import zeros\n+from keras.src.ops.numpy import zeros_like\n\n@@ -0,0 +1,24 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.api.optimizers import legacy\n+from keras.api.optimizers import schedules\n+from keras.src.optimizers import deserialize\n+from keras.src.optimizers import get\n+from keras.src.optimizers import serialize\n+from keras.src.optimizers.adadelta import Adadelta\n+from keras.src.optimizers.adafactor import Adafactor\n+from keras.src.optimizers.adagrad import Adagrad\n+from keras.src.optimizers.adam import Adam\n+from keras.src.optimizers.adamax import Adamax\n+from keras.src.optimizers.adamw import AdamW\n+from keras.src.optimizers.ftrl import Ftrl\n+from keras.src.optimizers.lion import Lion\n+from keras.src.optimizers.loss_scale_optimizer import LossScaleOptimizer\n+from keras.src.optimizers.nadam import Nadam\n+from keras.src.optimizers.optimizer import Optimizer\n+from keras.src.optimizers.rmsprop import RMSprop\n+from keras.src.optimizers.sgd import SGD\n\n@@ -0,0 +1,12 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.optimizers import LegacyOptimizerWarning as Adagrad\n+from keras.src.optimizers import LegacyOptimizerWarning as Adam\n+from keras.src.optimizers import LegacyOptimizerWarning as Ftrl\n+from keras.src.optimizers import LegacyOptimizerWarning as Optimizer\n+from keras.src.optimizers import LegacyOptimizerWarning as RMSprop\n+from keras.src.optimizers import LegacyOptimizerWarning as SGD\n\n@@ -0,0 +1,27 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.optimizers.schedules.learning_rate_schedule import CosineDecay\n+from keras.src.optimizers.schedules.learning_rate_schedule import (\n+    CosineDecayRestarts,\n+)\n+from keras.src.optimizers.schedules.learning_rate_schedule import (\n+    ExponentialDecay,\n+)\n+from keras.src.optimizers.schedules.learning_rate_schedule import (\n+    InverseTimeDecay,\n+)\n+from keras.src.optimizers.schedules.learning_rate_schedule import (\n+    LearningRateSchedule,\n+)\n+from keras.src.optimizers.schedules.learning_rate_schedule import (\n+    PiecewiseConstantDecay,\n+)\n+from keras.src.optimizers.schedules.learning_rate_schedule import (\n+    PolynomialDecay,\n+)\n+from keras.src.optimizers.schedules.learning_rate_schedule import deserialize\n+from keras.src.optimizers.schedules.learning_rate_schedule import serialize\n\n@@ -0,0 +1,13 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.api.preprocessing import image\n+from keras.api.preprocessing import sequence\n+from keras.src.utils.image_dataset_utils import image_dataset_from_directory\n+from keras.src.utils.text_dataset_utils import text_dataset_from_directory\n+from keras.src.utils.timeseries_dataset_utils import (\n+    timeseries_dataset_from_array,\n+)\n\n@@ -0,0 +1,11 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.utils.image_utils import array_to_img\n+from keras.src.utils.image_utils import img_to_array\n+from keras.src.utils.image_utils import load_img\n+from keras.src.utils.image_utils import save_img\n+from keras.src.utils.image_utils import smart_resize\n\n@@ -0,0 +1,7 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.utils.sequence_utils import pad_sequences\n\n@@ -0,0 +1,15 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.quantizers import deserialize\n+from keras.src.quantizers import get\n+from keras.src.quantizers import serialize\n+from keras.src.quantizers.quantizers import AbsMaxQuantizer\n+from keras.src.quantizers.quantizers import Quantizer\n+from keras.src.quantizers.quantizers import abs_max_quantize\n+from keras.src.quantizers.quantizers import compute_float8_amax_history\n+from keras.src.quantizers.quantizers import compute_float8_scale\n+from keras.src.quantizers.quantizers import quantize_and_dequantize\n\n@@ -0,0 +1,17 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.random.random import beta\n+from keras.src.random.random import binomial\n+from keras.src.random.random import categorical\n+from keras.src.random.random import dropout\n+from keras.src.random.random import gamma\n+from keras.src.random.random import normal\n+from keras.src.random.random import randint\n+from keras.src.random.random import shuffle\n+from keras.src.random.random import truncated_normal\n+from keras.src.random.random import uniform\n+from keras.src.random.seed_generator import SeedGenerator\n\n@@ -0,0 +1,20 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.regularizers import deserialize\n+from keras.src.regularizers import get\n+from keras.src.regularizers import serialize\n+from keras.src.regularizers.regularizers import L1\n+from keras.src.regularizers.regularizers import L1 as l1\n+from keras.src.regularizers.regularizers import L1L2\n+from keras.src.regularizers.regularizers import L1L2 as l1_l2\n+from keras.src.regularizers.regularizers import L2\n+from keras.src.regularizers.regularizers import L2 as l2\n+from keras.src.regularizers.regularizers import OrthogonalRegularizer\n+from keras.src.regularizers.regularizers import (\n+    OrthogonalRegularizer as orthogonal_regularizer,\n+)\n+from keras.src.regularizers.regularizers import Regularizer\n\n@@ -0,0 +1,20 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.saving.object_registration import CustomObjectScope\n+from keras.src.saving.object_registration import (\n+    CustomObjectScope as custom_object_scope,\n+)\n+from keras.src.saving.object_registration import get_custom_objects\n+from keras.src.saving.object_registration import get_registered_name\n+from keras.src.saving.object_registration import get_registered_object\n+from keras.src.saving.object_registration import register_keras_serializable\n+from keras.src.saving.saving_api import load_model\n+from keras.src.saving.saving_api import load_weights\n+from keras.src.saving.saving_api import save_model\n+from keras.src.saving.saving_api import save_weights\n+from keras.src.saving.serialization_lib import deserialize_keras_object\n+from keras.src.saving.serialization_lib import serialize_keras_object\n\n@@ -0,0 +1,15 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.tree.tree_api import assert_same_structure\n+from keras.src.tree.tree_api import flatten\n+from keras.src.tree.tree_api import is_nested\n+from keras.src.tree.tree_api import lists_to_tuples\n+from keras.src.tree.tree_api import map_shape_structure\n+from keras.src.tree.tree_api import map_structure\n+from keras.src.tree.tree_api import map_structure_up_to\n+from keras.src.tree.tree_api import pack_sequence_as\n+from keras.src.tree.tree_api import traverse\n\n@@ -0,0 +1,54 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.api.utils import legacy\n+from keras.src.backend.common.global_state import clear_session\n+from keras.src.backend.common.keras_tensor import is_keras_tensor\n+from keras.src.backend.common.variables import standardize_dtype\n+from keras.src.layers.preprocessing.feature_space import FeatureSpace\n+from keras.src.ops.operation_utils import get_source_inputs\n+from keras.src.saving.object_registration import CustomObjectScope\n+from keras.src.saving.object_registration import (\n+    CustomObjectScope as custom_object_scope,\n+)\n+from keras.src.saving.object_registration import get_custom_objects\n+from keras.src.saving.object_registration import get_registered_name\n+from keras.src.saving.object_registration import get_registered_object\n+from keras.src.saving.object_registration import register_keras_serializable\n+from keras.src.saving.serialization_lib import deserialize_keras_object\n+from keras.src.saving.serialization_lib import serialize_keras_object\n+from keras.src.trainers.data_adapters.data_adapter_utils import (\n+    pack_x_y_sample_weight,\n+)\n+from keras.src.trainers.data_adapters.data_adapter_utils import (\n+    unpack_x_y_sample_weight,\n+)\n+from keras.src.trainers.data_adapters.py_dataset_adapter import PyDataset\n+from keras.src.trainers.data_adapters.py_dataset_adapter import (\n+    PyDataset as Sequence,\n+)\n+from keras.src.utils.audio_dataset_utils import audio_dataset_from_directory\n+from keras.src.utils.dataset_utils import split_dataset\n+from keras.src.utils.file_utils import get_file\n+from keras.src.utils.image_dataset_utils import image_dataset_from_directory\n+from keras.src.utils.image_utils import array_to_img\n+from keras.src.utils.image_utils import img_to_array\n+from keras.src.utils.image_utils import load_img\n+from keras.src.utils.image_utils import save_img\n+from keras.src.utils.io_utils import disable_interactive_logging\n+from keras.src.utils.io_utils import enable_interactive_logging\n+from keras.src.utils.io_utils import is_interactive_logging_enabled\n+from keras.src.utils.model_visualization import model_to_dot\n+from keras.src.utils.model_visualization import plot_model\n+from keras.src.utils.numerical_utils import normalize\n+from keras.src.utils.numerical_utils import to_categorical\n+from keras.src.utils.progbar import Progbar\n+from keras.src.utils.rng_utils import set_random_seed\n+from keras.src.utils.sequence_utils import pad_sequences\n+from keras.src.utils.text_dataset_utils import text_dataset_from_directory\n+from keras.src.utils.timeseries_dataset_utils import (\n+    timeseries_dataset_from_array,\n+)\n\n@@ -0,0 +1,8 @@\n+\"\"\"DO NOT EDIT.\n+\n+This file was autogenerated. Do not edit it by hand,\n+since your modifications would be overwritten.\n+\"\"\"\n+\n+from keras.src.legacy.saving.serialization import deserialize_keras_object\n+from keras.src.legacy.saving.serialization import serialize_keras_object\n\n@@ -1,45 +0,0 @@\n-from keras.backend.config import backend\n-\n-if backend() == \"torch\":\n-    # When using the torch backend,\n-    # torch needs to be imported first, otherwise it will segfault\n-    # upon import.\n-    import torch\n-\n-from keras.backend.common.dtypes import result_type\n-from keras.backend.common.keras_tensor import KerasTensor\n-from keras.backend.common.keras_tensor import any_symbolic_tensors\n-from keras.backend.common.keras_tensor import is_keras_tensor\n-from keras.backend.common.name_scope import name_scope\n-from keras.backend.common.stateless_scope import StatelessScope\n-from keras.backend.common.stateless_scope import get_stateless_scope\n-from keras.backend.common.stateless_scope import in_stateless_scope\n-from keras.backend.common.variables import AutocastScope\n-from keras.backend.common.variables import get_autocast_scope\n-from keras.backend.common.variables import is_float_dtype\n-from keras.backend.common.variables import is_int_dtype\n-from keras.backend.common.variables import standardize_dtype\n-from keras.backend.common.variables import standardize_shape\n-from keras.backend.config import epsilon\n-from keras.backend.config import floatx\n-from keras.backend.config import image_data_format\n-from keras.backend.config import set_epsilon\n-from keras.backend.config import set_floatx\n-from keras.backend.config import set_image_data_format\n-from keras.backend.config import standardize_data_format\n-\n-# Import backend functions.\n-if backend() == \"tensorflow\":\n-    from keras.backend.tensorflow import *  # noqa: F403\n-elif backend() == \"jax\":\n-    from keras.backend.jax import *  # noqa: F403\n-elif backend() == \"torch\":\n-    from keras.backend.torch import *  # noqa: F403\n-\n-    distribution_lib = None\n-elif backend() == \"numpy\":\n-    from keras.backend.numpy import *  # noqa: F403\n-\n-    distribution_lib = None\n-else:\n-    raise ValueError(f\"Unable to import backend : {backend()}\")\n\n@@ -1,10 +0,0 @@\n-from keras.backend.common import backend_utils\n-from keras.backend.common.dtypes import result_type\n-from keras.backend.common.variables import AutocastScope\n-from keras.backend.common.variables import KerasVariable\n-from keras.backend.common.variables import get_autocast_scope\n-from keras.backend.common.variables import is_float_dtype\n-from keras.backend.common.variables import is_int_dtype\n-from keras.backend.common.variables import standardize_dtype\n-from keras.backend.common.variables import standardize_shape\n-from keras.random import random\n\n@@ -1,25 +0,0 @@\n-from keras.backend.jax import core\n-from keras.backend.jax import distribution_lib\n-from keras.backend.jax import image\n-from keras.backend.jax import linalg\n-from keras.backend.jax import math\n-from keras.backend.jax import nn\n-from keras.backend.jax import numpy\n-from keras.backend.jax import random\n-from keras.backend.jax.core import SUPPORTS_SPARSE_TENSORS\n-from keras.backend.jax.core import Variable\n-from keras.backend.jax.core import cast\n-from keras.backend.jax.core import compute_output_spec\n-from keras.backend.jax.core import cond\n-from keras.backend.jax.core import convert_to_numpy\n-from keras.backend.jax.core import convert_to_tensor\n-from keras.backend.jax.core import device_scope\n-from keras.backend.jax.core import is_tensor\n-from keras.backend.jax.core import scatter\n-from keras.backend.jax.core import shape\n-from keras.backend.jax.core import stop_gradient\n-from keras.backend.jax.core import vectorized_map\n-from keras.backend.jax.rnn import cudnn_ok\n-from keras.backend.jax.rnn import gru\n-from keras.backend.jax.rnn import lstm\n-from keras.backend.jax.rnn import rnn\n\n@@ -1,21 +0,0 @@\n-from keras.backend.numpy import core\n-from keras.backend.numpy import image\n-from keras.backend.numpy import linalg\n-from keras.backend.numpy import math\n-from keras.backend.numpy import nn\n-from keras.backend.numpy import numpy\n-from keras.backend.numpy import random\n-from keras.backend.numpy.core import SUPPORTS_SPARSE_TENSORS\n-from keras.backend.numpy.core import Variable\n-from keras.backend.numpy.core import cast\n-from keras.backend.numpy.core import compute_output_spec\n-from keras.backend.numpy.core import cond\n-from keras.backend.numpy.core import convert_to_numpy\n-from keras.backend.numpy.core import convert_to_tensor\n-from keras.backend.numpy.core import is_tensor\n-from keras.backend.numpy.core import shape\n-from keras.backend.numpy.core import vectorized_map\n-from keras.backend.numpy.rnn import cudnn_ok\n-from keras.backend.numpy.rnn import gru\n-from keras.backend.numpy.rnn import lstm\n-from keras.backend.numpy.rnn import rnn\n\n@@ -1,27 +0,0 @@\n-from keras.backend.tensorflow import core\n-from keras.backend.tensorflow import distribution_lib\n-from keras.backend.tensorflow import image\n-from keras.backend.tensorflow import linalg\n-from keras.backend.tensorflow import math\n-from keras.backend.tensorflow import nn\n-from keras.backend.tensorflow import numpy\n-from keras.backend.tensorflow import random\n-from keras.backend.tensorflow import tensorboard\n-from keras.backend.tensorflow.core import SUPPORTS_SPARSE_TENSORS\n-from keras.backend.tensorflow.core import Variable\n-from keras.backend.tensorflow.core import cast\n-from keras.backend.tensorflow.core import compute_output_spec\n-from keras.backend.tensorflow.core import cond\n-from keras.backend.tensorflow.core import convert_to_numpy\n-from keras.backend.tensorflow.core import convert_to_tensor\n-from keras.backend.tensorflow.core import device_scope\n-from keras.backend.tensorflow.core import is_tensor\n-from keras.backend.tensorflow.core import name_scope\n-from keras.backend.tensorflow.core import scatter\n-from keras.backend.tensorflow.core import shape\n-from keras.backend.tensorflow.core import stop_gradient\n-from keras.backend.tensorflow.core import vectorized_map\n-from keras.backend.tensorflow.rnn import cudnn_ok\n-from keras.backend.tensorflow.rnn import gru\n-from keras.backend.tensorflow.rnn import lstm\n-from keras.backend.tensorflow.rnn import rnn\n\n@@ -1,41 +0,0 @@\n-\"\"\"Torch backend APIs.\n-\n-# Note on device placement\n-\n-Torch has a different device placement style compared to TF and JAX.\n-In short, variables/tensors are not created on GPU by default,\n-and the GPU cannot directly communicate with the CPU.\n-To bring Torch behavior in line with TF and JAX automated device placement,\n-we are doing the following to automate device placement if a GPU is available:\n-\n-- Variables are created on GPU.\n-- Input data will be placed on GPU at the first `keras.layers.Layer` call.\n-- Tensor creation happens on GPU, e.g., `zeros()` will create a tensor on GPU.\n-- `convert_to_numpy` will bring the tensor to CPU before converting it to NumPy.\n-\"\"\"\n-\n-from keras.backend.torch import core\n-from keras.backend.torch import image\n-from keras.backend.torch import linalg\n-from keras.backend.torch import math\n-from keras.backend.torch import nn\n-from keras.backend.torch import numpy\n-from keras.backend.torch import random\n-from keras.backend.torch.core import SUPPORTS_SPARSE_TENSORS\n-from keras.backend.torch.core import Variable\n-from keras.backend.torch.core import cast\n-from keras.backend.torch.core import compute_output_spec\n-from keras.backend.torch.core import cond\n-from keras.backend.torch.core import convert_to_numpy\n-from keras.backend.torch.core import convert_to_tensor\n-from keras.backend.torch.core import device_scope\n-from keras.backend.torch.core import is_tensor\n-from keras.backend.torch.core import scatter\n-from keras.backend.torch.core import shape\n-from keras.backend.torch.core import stop_gradient\n-from keras.backend.torch.core import to_torch_dtype\n-from keras.backend.torch.core import vectorized_map\n-from keras.backend.torch.rnn import cudnn_ok\n-from keras.backend.torch.rnn import gru\n-from keras.backend.torch.rnn import lstm\n-from keras.backend.torch.rnn import rnn\n\n@@ -1 +0,0 @@\n-from keras.backend.torch.optimizers.torch_optimizer import TorchOptimizer\n\n@@ -1,6 +0,0 @@\n-from keras import optimizers\n-from keras.backend.torch.optimizers import torch_adam\n-\n-\n-class AdamW(torch_adam.Adam, optimizers.AdamW):\n-    pass\n\n@@ -1,15 +0,0 @@\n-from keras.callbacks.backup_and_restore import BackupAndRestore\n-from keras.callbacks.callback import Callback\n-from keras.callbacks.callback_list import CallbackList\n-from keras.callbacks.csv_logger import CSVLogger\n-from keras.callbacks.early_stopping import EarlyStopping\n-from keras.callbacks.history import History\n-from keras.callbacks.lambda_callback import LambdaCallback\n-from keras.callbacks.learning_rate_scheduler import LearningRateScheduler\n-from keras.callbacks.model_checkpoint import ModelCheckpoint\n-from keras.callbacks.progbar_logger import ProgbarLogger\n-from keras.callbacks.reduce_lr_on_plateau import ReduceLROnPlateau\n-from keras.callbacks.remote_monitor import RemoteMonitor\n-from keras.callbacks.swap_ema_weights import SwapEMAWeights\n-from keras.callbacks.tensorboard import TensorBoard\n-from keras.callbacks.terminate_on_nan import TerminateOnNaN\n\n@@ -1,10 +0,0 @@\n-\"\"\"Small NumPy datasets for debugging/testing.\"\"\"\n-\n-from keras.datasets import boston_housing\n-from keras.datasets import california_housing\n-from keras.datasets import cifar10\n-from keras.datasets import cifar100\n-from keras.datasets import fashion_mnist\n-from keras.datasets import imdb\n-from keras.datasets import mnist\n-from keras.datasets import reuters\n\n@@ -1,11 +0,0 @@\n-from keras.distribution.distribution_lib import DataParallel\n-from keras.distribution.distribution_lib import DeviceMesh\n-from keras.distribution.distribution_lib import Distribution\n-from keras.distribution.distribution_lib import LayoutMap\n-from keras.distribution.distribution_lib import ModelParallel\n-from keras.distribution.distribution_lib import TensorLayout\n-from keras.distribution.distribution_lib import distribute_tensor\n-from keras.distribution.distribution_lib import distribution\n-from keras.distribution.distribution_lib import initialize\n-from keras.distribution.distribution_lib import list_devices\n-from keras.distribution.distribution_lib import set_distribution\n\n@@ -1 +0,0 @@\n-from keras.export.export_lib import ExportArchive\n\n@@ -1,161 +0,0 @@\n-from keras.api_export import keras_export\n-from keras.layers.activations.activation import Activation\n-from keras.layers.activations.elu import ELU\n-from keras.layers.activations.leaky_relu import LeakyReLU\n-from keras.layers.activations.prelu import PReLU\n-from keras.layers.activations.relu import ReLU\n-from keras.layers.activations.softmax import Softmax\n-from keras.layers.attention.additive_attention import AdditiveAttention\n-from keras.layers.attention.attention import Attention\n-from keras.layers.attention.grouped_query_attention import GroupedQueryAttention\n-from keras.layers.attention.multi_head_attention import MultiHeadAttention\n-from keras.layers.convolutional.conv1d import Conv1D\n-from keras.layers.convolutional.conv1d_transpose import Conv1DTranspose\n-from keras.layers.convolutional.conv2d import Conv2D\n-from keras.layers.convolutional.conv2d_transpose import Conv2DTranspose\n-from keras.layers.convolutional.conv3d import Conv3D\n-from keras.layers.convolutional.conv3d_transpose import Conv3DTranspose\n-from keras.layers.convolutional.depthwise_conv1d import DepthwiseConv1D\n-from keras.layers.convolutional.depthwise_conv2d import DepthwiseConv2D\n-from keras.layers.convolutional.separable_conv1d import SeparableConv1D\n-from keras.layers.convolutional.separable_conv2d import SeparableConv2D\n-from keras.layers.core.dense import Dense\n-from keras.layers.core.einsum_dense import EinsumDense\n-from keras.layers.core.embedding import Embedding\n-from keras.layers.core.identity import Identity\n-from keras.layers.core.input_layer import Input\n-from keras.layers.core.input_layer import InputLayer\n-from keras.layers.core.lambda_layer import Lambda\n-from keras.layers.core.masking import Masking\n-from keras.layers.core.wrapper import Wrapper\n-from keras.layers.layer import Layer\n-from keras.layers.merging.add import Add\n-from keras.layers.merging.add import add\n-from keras.layers.merging.average import Average\n-from keras.layers.merging.average import average\n-from keras.layers.merging.concatenate import Concatenate\n-from keras.layers.merging.concatenate import concatenate\n-from keras.layers.merging.dot import Dot\n-from keras.layers.merging.dot import dot\n-from keras.layers.merging.maximum import Maximum\n-from keras.layers.merging.maximum import maximum\n-from keras.layers.merging.minimum import Minimum\n-from keras.layers.merging.minimum import minimum\n-from keras.layers.merging.multiply import Multiply\n-from keras.layers.merging.multiply import multiply\n-from keras.layers.merging.subtract import Subtract\n-from keras.layers.merging.subtract import subtract\n-from keras.layers.normalization.batch_normalization import BatchNormalization\n-from keras.layers.normalization.group_normalization import GroupNormalization\n-from keras.layers.normalization.layer_normalization import LayerNormalization\n-from keras.layers.normalization.spectral_normalization import (\n-    SpectralNormalization,\n-)\n-from keras.layers.normalization.unit_normalization import UnitNormalization\n-from keras.layers.pooling.average_pooling1d import AveragePooling1D\n-from keras.layers.pooling.average_pooling2d import AveragePooling2D\n-from keras.layers.pooling.average_pooling3d import AveragePooling3D\n-from keras.layers.pooling.global_average_pooling1d import GlobalAveragePooling1D\n-from keras.layers.pooling.global_average_pooling2d import GlobalAveragePooling2D\n-from keras.layers.pooling.global_average_pooling3d import GlobalAveragePooling3D\n-from keras.layers.pooling.global_max_pooling1d import GlobalMaxPooling1D\n-from keras.layers.pooling.global_max_pooling2d import GlobalMaxPooling2D\n-from keras.layers.pooling.global_max_pooling3d import GlobalMaxPooling3D\n-from keras.layers.pooling.max_pooling1d import MaxPooling1D\n-from keras.layers.pooling.max_pooling2d import MaxPooling2D\n-from keras.layers.pooling.max_pooling3d import MaxPooling3D\n-from keras.layers.preprocessing.audio_preprocessing import MelSpectrogram\n-from keras.layers.preprocessing.category_encoding import CategoryEncoding\n-from keras.layers.preprocessing.center_crop import CenterCrop\n-from keras.layers.preprocessing.discretization import Discretization\n-from keras.layers.preprocessing.hashed_crossing import HashedCrossing\n-from keras.layers.preprocessing.hashing import Hashing\n-from keras.layers.preprocessing.index_lookup import IndexLookup\n-from keras.layers.preprocessing.integer_lookup import IntegerLookup\n-from keras.layers.preprocessing.normalization import Normalization\n-from keras.layers.preprocessing.random_brightness import RandomBrightness\n-from keras.layers.preprocessing.random_contrast import RandomContrast\n-from keras.layers.preprocessing.random_crop import RandomCrop\n-from keras.layers.preprocessing.random_flip import RandomFlip\n-from keras.layers.preprocessing.random_rotation import RandomRotation\n-from keras.layers.preprocessing.random_translation import RandomTranslation\n-from keras.layers.preprocessing.random_zoom import RandomZoom\n-from keras.layers.preprocessing.rescaling import Rescaling\n-from keras.layers.preprocessing.resizing import Resizing\n-from keras.layers.preprocessing.string_lookup import StringLookup\n-from keras.layers.preprocessing.text_vectorization import TextVectorization\n-from keras.layers.regularization.activity_regularization import (\n-    ActivityRegularization,\n-)\n-from keras.layers.regularization.alpha_dropout import AlphaDropout\n-from keras.layers.regularization.dropout import Dropout\n-from keras.layers.regularization.gaussian_dropout import GaussianDropout\n-from keras.layers.regularization.gaussian_noise import GaussianNoise\n-from keras.layers.regularization.spatial_dropout import SpatialDropout1D\n-from keras.layers.regularization.spatial_dropout import SpatialDropout2D\n-from keras.layers.regularization.spatial_dropout import SpatialDropout3D\n-from keras.layers.reshaping.cropping1d import Cropping1D\n-from keras.layers.reshaping.cropping2d import Cropping2D\n-from keras.layers.reshaping.cropping3d import Cropping3D\n-from keras.layers.reshaping.flatten import Flatten\n-from keras.layers.reshaping.permute import Permute\n-from keras.layers.reshaping.repeat_vector import RepeatVector\n-from keras.layers.reshaping.reshape import Reshape\n-from keras.layers.reshaping.up_sampling1d import UpSampling1D\n-from keras.layers.reshaping.up_sampling2d import UpSampling2D\n-from keras.layers.reshaping.up_sampling3d import UpSampling3D\n-from keras.layers.reshaping.zero_padding1d import ZeroPadding1D\n-from keras.layers.reshaping.zero_padding2d import ZeroPadding2D\n-from keras.layers.reshaping.zero_padding3d import ZeroPadding3D\n-from keras.layers.rnn.bidirectional import Bidirectional\n-from keras.layers.rnn.conv_lstm1d import ConvLSTM1D\n-from keras.layers.rnn.conv_lstm2d import ConvLSTM2D\n-from keras.layers.rnn.conv_lstm3d import ConvLSTM3D\n-from keras.layers.rnn.gru import GRU\n-from keras.layers.rnn.gru import GRUCell\n-from keras.layers.rnn.lstm import LSTM\n-from keras.layers.rnn.lstm import LSTMCell\n-from keras.layers.rnn.rnn import RNN\n-from keras.layers.rnn.simple_rnn import SimpleRNN\n-from keras.layers.rnn.simple_rnn import SimpleRNNCell\n-from keras.layers.rnn.stacked_rnn_cells import StackedRNNCells\n-from keras.layers.rnn.time_distributed import TimeDistributed\n-from keras.saving import serialization_lib\n-\n-\n-@keras_export(\"keras.layers.serialize\")\n-def serialize(layer):\n-    \"\"\"Returns the layer configuration as a Python dict.\n-\n-    Args:\n-        layer: A `keras.layers.Layer` instance to serialize.\n-\n-    Returns:\n-        Python dict which contains the configuration of the layer.\n-    \"\"\"\n-    return serialization_lib.serialize_keras_object(layer)\n-\n-\n-@keras_export(\"keras.layers.deserialize\")\n-def deserialize(config, custom_objects=None):\n-    \"\"\"Returns a Keras layer object via its configuration.\n-\n-    Args:\n-        config: A python dict containing a serialized layer configuration.\n-        custom_objects: Optional dictionary mapping names (strings) to custom\n-            objects (classes and functions) to be considered during\n-            deserialization.\n-\n-    Returns:\n-        A Keras layer instance.\n-    \"\"\"\n-    obj = serialization_lib.deserialize_keras_object(\n-        config,\n-        custom_objects=custom_objects,\n-    )\n-    if not isinstance(obj, Layer):\n-        raise ValueError(\n-            \"`keras.layers.deserialize` was passed a `config` object that is \"\n-            f\"not a `keras.layers.Layer`. Received: {config}\"\n-        )\n-    return obj\n\n@@ -1,5 +0,0 @@\n-from keras.layers.activations.elu import ELU\n-from keras.layers.activations.leaky_relu import LeakyReLU\n-from keras.layers.activations.prelu import PReLU\n-from keras.layers.activations.relu import ReLU\n-from keras.layers.activations.softmax import Softmax\n\n@@ -1,3 +0,0 @@\n-from keras.models.functional import Functional\n-from keras.models.model import Model\n-from keras.models.sequential import Sequential\n\n@@ -1,16 +0,0 @@\n-# from keras.ops.numpy import Matmul, matmul\n-# from keras.ops.numpy import Add, add\n-# from keras.ops.numpy import Multiply, multiply\n-\n-from keras.backend import cast\n-from keras.backend import cond\n-from keras.backend import is_tensor\n-from keras.backend import name_scope\n-from keras.backend import random\n-from keras.ops import image\n-from keras.ops import operation_utils\n-from keras.ops.core import *  # noqa: F403\n-from keras.ops.linalg import *  # noqa: F403\n-from keras.ops.math import *  # noqa: F403\n-from keras.ops.nn import *  # noqa: F403\n-from keras.ops.numpy import *  # noqa: F403\n\n@@ -1,10 +0,0 @@\n-from keras.optimizers.schedules.learning_rate_schedule import CosineDecay\n-from keras.optimizers.schedules.learning_rate_schedule import (\n-    CosineDecayRestarts,\n-)\n-from keras.optimizers.schedules.learning_rate_schedule import ExponentialDecay\n-from keras.optimizers.schedules.learning_rate_schedule import InverseTimeDecay\n-from keras.optimizers.schedules.learning_rate_schedule import (\n-    PiecewiseConstantDecay,\n-)\n-from keras.optimizers.schedules.learning_rate_schedule import PolynomialDecay\n\n@@ -1,9 +0,0 @@\n-from keras.random.random import categorical\n-from keras.random.random import dropout\n-from keras.random.random import gamma\n-from keras.random.random import normal\n-from keras.random.random import randint\n-from keras.random.random import shuffle\n-from keras.random.random import truncated_normal\n-from keras.random.random import uniform\n-from keras.random.seed_generator import SeedGenerator\n\n@@ -1,9 +0,0 @@\n-from keras.saving.object_registration import CustomObjectScope\n-from keras.saving.object_registration import custom_object_scope\n-from keras.saving.object_registration import get_custom_objects\n-from keras.saving.object_registration import get_registered_name\n-from keras.saving.object_registration import get_registered_object\n-from keras.saving.object_registration import register_keras_serializable\n-from keras.saving.saving_api import load_model\n-from keras.saving.serialization_lib import deserialize_keras_object\n-from keras.saving.serialization_lib import serialize_keras_object\n\n@@ -0,0 +1,19 @@\n+from keras.src import activations\n+from keras.src import applications\n+from keras.src import backend\n+from keras.src import constraints\n+from keras.src import datasets\n+from keras.src import initializers\n+from keras.src import layers\n+from keras.src import models\n+from keras.src import ops\n+from keras.src import optimizers\n+from keras.src import regularizers\n+from keras.src import utils\n+from keras.src.backend import KerasTensor\n+from keras.src.layers import Input\n+from keras.src.layers import Layer\n+from keras.src.models import Functional\n+from keras.src.models import Model\n+from keras.src.models import Sequential\n+from keras.src.version import __version__\n\n@@ -1,26 +1,26 @@\n import types\n \n-from keras.activations.activations import elu\n-from keras.activations.activations import exponential\n-from keras.activations.activations import gelu\n-from keras.activations.activations import hard_sigmoid\n-from keras.activations.activations import hard_silu\n-from keras.activations.activations import leaky_relu\n-from keras.activations.activations import linear\n-from keras.activations.activations import log_softmax\n-from keras.activations.activations import mish\n-from keras.activations.activations import relu\n-from keras.activations.activations import relu6\n-from keras.activations.activations import selu\n-from keras.activations.activations import sigmoid\n-from keras.activations.activations import silu\n-from keras.activations.activations import softmax\n-from keras.activations.activations import softplus\n-from keras.activations.activations import softsign\n-from keras.activations.activations import tanh\n-from keras.api_export import keras_export\n-from keras.saving import object_registration\n-from keras.saving import serialization_lib\n+from keras.src.activations.activations import elu\n+from keras.src.activations.activations import exponential\n+from keras.src.activations.activations import gelu\n+from keras.src.activations.activations import hard_sigmoid\n+from keras.src.activations.activations import hard_silu\n+from keras.src.activations.activations import leaky_relu\n+from keras.src.activations.activations import linear\n+from keras.src.activations.activations import log_softmax\n+from keras.src.activations.activations import mish\n+from keras.src.activations.activations import relu\n+from keras.src.activations.activations import relu6\n+from keras.src.activations.activations import selu\n+from keras.src.activations.activations import sigmoid\n+from keras.src.activations.activations import silu\n+from keras.src.activations.activations import softmax\n+from keras.src.activations.activations import softplus\n+from keras.src.activations.activations import softsign\n+from keras.src.activations.activations import tanh\n+from keras.src.api_export import keras_export\n+from keras.src.saving import object_registration\n+from keras.src.saving import serialization_lib\n \n ALL_OBJECTS = {\n     relu,\n\n@@ -1,6 +1,6 @@\n-from keras import backend\n-from keras import ops\n-from keras.api_export import keras_export\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n \n \n @keras_export(\"keras.activations.relu\")\n\n@@ -1,8 +1,8 @@\n import numpy as np\n \n-from keras import activations\n-from keras import backend\n-from keras import testing\n+from keras.src import activations\n+from keras.src import backend\n+from keras.src import testing\n \n \n def _ref_softmax(values):\n\n\n\n@@ -4,26 +4,26 @@ import numpy as np\n import pytest\n from absl.testing import parameterized\n \n-from keras import backend\n-from keras import testing\n-from keras.applications import convnext\n-from keras.applications import densenet\n-from keras.applications import efficientnet\n-from keras.applications import efficientnet_v2\n-from keras.applications import inception_resnet_v2\n-from keras.applications import inception_v3\n-from keras.applications import mobilenet\n-from keras.applications import mobilenet_v2\n-from keras.applications import mobilenet_v3\n-from keras.applications import nasnet\n-from keras.applications import resnet\n-from keras.applications import resnet_v2\n-from keras.applications import vgg16\n-from keras.applications import vgg19\n-from keras.applications import xception\n-from keras.saving import serialization_lib\n-from keras.utils import file_utils\n-from keras.utils import image_utils\n+from keras.src import backend\n+from keras.src import testing\n+from keras.src.applications import convnext\n+from keras.src.applications import densenet\n+from keras.src.applications import efficientnet\n+from keras.src.applications import efficientnet_v2\n+from keras.src.applications import inception_resnet_v2\n+from keras.src.applications import inception_v3\n+from keras.src.applications import mobilenet\n+from keras.src.applications import mobilenet_v2\n+from keras.src.applications import mobilenet_v3\n+from keras.src.applications import nasnet\n+from keras.src.applications import resnet\n+from keras.src.applications import resnet_v2\n+from keras.src.applications import vgg16\n+from keras.src.applications import vgg19\n+from keras.src.applications import xception\n+from keras.src.saving import serialization_lib\n+from keras.src.utils import file_utils\n+from keras.src.utils import image_utils\n \n try:\n     import PIL\n\n@@ -1,17 +1,17 @@\n import numpy as np\n \n-from keras import backend\n-from keras import initializers\n-from keras import layers\n-from keras import ops\n-from keras import random\n-from keras.api_export import keras_export\n-from keras.applications import imagenet_utils\n-from keras.layers.layer import Layer\n-from keras.models import Functional\n-from keras.models import Sequential\n-from keras.ops import operation_utils\n-from keras.utils import file_utils\n+from keras.src import backend\n+from keras.src import initializers\n+from keras.src import layers\n+from keras.src import ops\n+from keras.src import random\n+from keras.src.api_export import keras_export\n+from keras.src.applications import imagenet_utils\n+from keras.src.layers.layer import Layer\n+from keras.src.models import Functional\n+from keras.src.models import Sequential\n+from keras.src.ops import operation_utils\n+from keras.src.utils import file_utils\n \n BASE_WEIGHTS_PATH = (\n     \"https://storage.googleapis.com/tensorflow/keras-applications/convnext/\"\n\n@@ -1,10 +1,10 @@\n-from keras import backend\n-from keras import layers\n-from keras.api_export import keras_export\n-from keras.applications import imagenet_utils\n-from keras.models import Functional\n-from keras.ops import operation_utils\n-from keras.utils import file_utils\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src.api_export import keras_export\n+from keras.src.applications import imagenet_utils\n+from keras.src.models import Functional\n+from keras.src.ops import operation_utils\n+from keras.src.utils import file_utils\n \n BASE_WEIGHTS_PATH = (\n     \"https://storage.googleapis.com/tensorflow/keras-applications/densenet/\"\n\n@@ -1,13 +1,13 @@\n import copy\n import math\n \n-from keras import backend\n-from keras import layers\n-from keras.api_export import keras_export\n-from keras.applications import imagenet_utils\n-from keras.models import Functional\n-from keras.ops import operation_utils\n-from keras.utils import file_utils\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src.api_export import keras_export\n+from keras.src.applications import imagenet_utils\n+from keras.src.models import Functional\n+from keras.src.ops import operation_utils\n+from keras.src.utils import file_utils\n \n BASE_WEIGHTS_PATH = \"https://storage.googleapis.com/keras-applications/\"\n \n\n@@ -1,14 +1,14 @@\n import copy\n import math\n \n-from keras import backend\n-from keras import initializers\n-from keras import layers\n-from keras.api_export import keras_export\n-from keras.applications import imagenet_utils\n-from keras.models import Functional\n-from keras.ops import operation_utils\n-from keras.utils import file_utils\n+from keras.src import backend\n+from keras.src import initializers\n+from keras.src import layers\n+from keras.src.api_export import keras_export\n+from keras.src.applications import imagenet_utils\n+from keras.src.models import Functional\n+from keras.src.ops import operation_utils\n+from keras.src.utils import file_utils\n \n BASE_WEIGHTS_PATH = \"https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/\"  # noqa: E501\n \n\n@@ -3,11 +3,11 @@ import warnings\n \n import numpy as np\n \n-from keras import activations\n-from keras import backend\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.utils import file_utils\n+from keras.src import activations\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.utils import file_utils\n \n CLASS_INDEX = None\n CLASS_INDEX_PATH = (\n\n@@ -3,10 +3,10 @@ import pytest\n from absl.testing import parameterized\n \n import keras\n-from keras import backend\n-from keras import testing\n-from keras.applications import imagenet_utils as utils\n-from keras.dtype_policies.dtype_policy import set_dtype_policy\n+from keras.src import backend\n+from keras.src import testing\n+from keras.src.applications import imagenet_utils as utils\n+from keras.src.dtype_policies.dtype_policy import set_dtype_policy\n \n \n class TestImageNetUtils(testing.TestCase, parameterized.TestCase):\n\n@@ -1,11 +1,11 @@\n-from keras import backend\n-from keras import layers\n-from keras.api_export import keras_export\n-from keras.applications import imagenet_utils\n-from keras.layers.layer import Layer\n-from keras.models import Functional\n-from keras.ops import operation_utils\n-from keras.utils import file_utils\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src.api_export import keras_export\n+from keras.src.applications import imagenet_utils\n+from keras.src.layers.layer import Layer\n+from keras.src.models import Functional\n+from keras.src.ops import operation_utils\n+from keras.src.utils import file_utils\n \n BASE_WEIGHT_URL = (\n     \"https://storage.googleapis.com/tensorflow/\"\n\n@@ -1,10 +1,10 @@\n-from keras import backend\n-from keras import layers\n-from keras.api_export import keras_export\n-from keras.applications import imagenet_utils\n-from keras.models import Functional\n-from keras.ops import operation_utils\n-from keras.utils import file_utils\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src.api_export import keras_export\n+from keras.src.applications import imagenet_utils\n+from keras.src.models import Functional\n+from keras.src.ops import operation_utils\n+from keras.src.utils import file_utils\n \n WEIGHTS_PATH = (\n     \"https://storage.googleapis.com/tensorflow/keras-applications/\"\n\n@@ -1,12 +1,12 @@\n import warnings\n \n-from keras import backend\n-from keras import layers\n-from keras.api_export import keras_export\n-from keras.applications import imagenet_utils\n-from keras.models import Functional\n-from keras.ops import operation_utils\n-from keras.utils import file_utils\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src.api_export import keras_export\n+from keras.src.applications import imagenet_utils\n+from keras.src.models import Functional\n+from keras.src.ops import operation_utils\n+from keras.src.utils import file_utils\n \n BASE_WEIGHT_PATH = (\n     \"https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/\"\n\n@@ -1,12 +1,12 @@\n import warnings\n \n-from keras import backend\n-from keras import layers\n-from keras.api_export import keras_export\n-from keras.applications import imagenet_utils\n-from keras.models import Functional\n-from keras.ops import operation_utils\n-from keras.utils import file_utils\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src.api_export import keras_export\n+from keras.src.applications import imagenet_utils\n+from keras.src.models import Functional\n+from keras.src.ops import operation_utils\n+from keras.src.utils import file_utils\n \n BASE_WEIGHT_PATH = (\n     \"https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/\"\n\n@@ -1,12 +1,12 @@\n import warnings\n \n-from keras import backend\n-from keras import layers\n-from keras.api_export import keras_export\n-from keras.applications import imagenet_utils\n-from keras.models import Functional\n-from keras.ops import operation_utils\n-from keras.utils import file_utils\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src.api_export import keras_export\n+from keras.src.applications import imagenet_utils\n+from keras.src.models import Functional\n+from keras.src.ops import operation_utils\n+from keras.src.utils import file_utils\n \n BASE_WEIGHT_PATH = (\n     \"https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/\"\n\n@@ -1,12 +1,12 @@\n import warnings\n \n-from keras import backend\n-from keras import layers\n-from keras.api_export import keras_export\n-from keras.applications import imagenet_utils\n-from keras.models import Functional\n-from keras.ops import operation_utils\n-from keras.utils import file_utils\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src.api_export import keras_export\n+from keras.src.applications import imagenet_utils\n+from keras.src.models import Functional\n+from keras.src.ops import operation_utils\n+from keras.src.utils import file_utils\n \n BASE_WEIGHTS_PATH = (\n     \"https://storage.googleapis.com/tensorflow/keras-applications/nasnet/\"\n\n@@ -1,10 +1,10 @@\n-from keras import backend\n-from keras import layers\n-from keras.api_export import keras_export\n-from keras.applications import imagenet_utils\n-from keras.models import Functional\n-from keras.ops import operation_utils\n-from keras.utils import file_utils\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src.api_export import keras_export\n+from keras.src.applications import imagenet_utils\n+from keras.src.models import Functional\n+from keras.src.ops import operation_utils\n+from keras.src.utils import file_utils\n \n BASE_WEIGHTS_PATH = (\n     \"https://storage.googleapis.com/tensorflow/keras-applications/resnet/\"\n\n@@ -1,6 +1,6 @@\n-from keras.api_export import keras_export\n-from keras.applications import imagenet_utils\n-from keras.applications import resnet\n+from keras.src.api_export import keras_export\n+from keras.src.applications import imagenet_utils\n+from keras.src.applications import resnet\n \n \n @keras_export(\n\n@@ -1,10 +1,10 @@\n-from keras import backend\n-from keras import layers\n-from keras.api_export import keras_export\n-from keras.applications import imagenet_utils\n-from keras.models import Functional\n-from keras.ops import operation_utils\n-from keras.utils import file_utils\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src.api_export import keras_export\n+from keras.src.applications import imagenet_utils\n+from keras.src.models import Functional\n+from keras.src.ops import operation_utils\n+from keras.src.utils import file_utils\n \n WEIGHTS_PATH = (\n     \"https://storage.googleapis.com/tensorflow/keras-applications/\"\n\n@@ -1,10 +1,10 @@\n-from keras import backend\n-from keras import layers\n-from keras.api_export import keras_export\n-from keras.applications import imagenet_utils\n-from keras.models import Functional\n-from keras.ops import operation_utils\n-from keras.utils import file_utils\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src.api_export import keras_export\n+from keras.src.applications import imagenet_utils\n+from keras.src.models import Functional\n+from keras.src.ops import operation_utils\n+from keras.src.utils import file_utils\n \n WEIGHTS_PATH = (\n     \"https://storage.googleapis.com/tensorflow/keras-applications/\"\n\n@@ -1,10 +1,10 @@\n-from keras import backend\n-from keras import layers\n-from keras.api_export import keras_export\n-from keras.applications import imagenet_utils\n-from keras.models import Functional\n-from keras.ops import operation_utils\n-from keras.utils import file_utils\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src.api_export import keras_export\n+from keras.src.applications import imagenet_utils\n+from keras.src.models import Functional\n+from keras.src.ops import operation_utils\n+from keras.src.utils import file_utils\n \n WEIGHTS_PATH = (\n     \"https://storage.googleapis.com/tensorflow/keras-applications/\"\n\n@@ -0,0 +1,45 @@\n+from keras.src.backend.config import backend\n+\n+if backend() == \"torch\":\n+    # When using the torch backend,\n+    # torch needs to be imported first, otherwise it will segfault\n+    # upon import.\n+    import torch\n+\n+from keras.src.backend.common.dtypes import result_type\n+from keras.src.backend.common.keras_tensor import KerasTensor\n+from keras.src.backend.common.keras_tensor import any_symbolic_tensors\n+from keras.src.backend.common.keras_tensor import is_keras_tensor\n+from keras.src.backend.common.name_scope import name_scope\n+from keras.src.backend.common.stateless_scope import StatelessScope\n+from keras.src.backend.common.stateless_scope import get_stateless_scope\n+from keras.src.backend.common.stateless_scope import in_stateless_scope\n+from keras.src.backend.common.variables import AutocastScope\n+from keras.src.backend.common.variables import get_autocast_scope\n+from keras.src.backend.common.variables import is_float_dtype\n+from keras.src.backend.common.variables import is_int_dtype\n+from keras.src.backend.common.variables import standardize_dtype\n+from keras.src.backend.common.variables import standardize_shape\n+from keras.src.backend.config import epsilon\n+from keras.src.backend.config import floatx\n+from keras.src.backend.config import image_data_format\n+from keras.src.backend.config import set_epsilon\n+from keras.src.backend.config import set_floatx\n+from keras.src.backend.config import set_image_data_format\n+from keras.src.backend.config import standardize_data_format\n+\n+# Import backend functions.\n+if backend() == \"tensorflow\":\n+    from keras.src.backend.tensorflow import *  # noqa: F403\n+elif backend() == \"jax\":\n+    from keras.src.backend.jax import *  # noqa: F403\n+elif backend() == \"torch\":\n+    from keras.src.backend.torch import *  # noqa: F403\n+\n+    distribution_lib = None\n+elif backend() == \"numpy\":\n+    from keras.src.backend.numpy import *  # noqa: F403\n+\n+    distribution_lib = None\n+else:\n+    raise ValueError(f\"Unable to import backend : {backend()}\")\n\n@@ -0,0 +1,10 @@\n+from keras.src.backend.common import backend_utils\n+from keras.src.backend.common.dtypes import result_type\n+from keras.src.backend.common.variables import AutocastScope\n+from keras.src.backend.common.variables import KerasVariable\n+from keras.src.backend.common.variables import get_autocast_scope\n+from keras.src.backend.common.variables import is_float_dtype\n+from keras.src.backend.common.variables import is_int_dtype\n+from keras.src.backend.common.variables import standardize_dtype\n+from keras.src.backend.common.variables import standardize_shape\n+from keras.src.random import random\n\n\n@@ -1,19 +1,19 @@\n-from keras.backend.common.backend_utils import (\n+from keras.src.backend.common.backend_utils import (\n     _convert_conv_tranpose_padding_args_from_keras_to_jax,\n )\n-from keras.backend.common.backend_utils import (\n+from keras.src.backend.common.backend_utils import (\n     _convert_conv_tranpose_padding_args_from_keras_to_torch,\n )\n-from keras.backend.common.backend_utils import (\n+from keras.src.backend.common.backend_utils import (\n     _get_output_shape_given_tf_padding,\n )\n-from keras.backend.common.backend_utils import (\n+from keras.src.backend.common.backend_utils import (\n     compute_conv_transpose_padding_args_for_jax,\n )\n-from keras.backend.common.backend_utils import (\n+from keras.src.backend.common.backend_utils import (\n     compute_conv_transpose_padding_args_for_torch,\n )\n-from keras.testing import test_case\n+from keras.src.testing import test_case\n \n \n class ConvertConvTransposePaddingArgsJAXTest(test_case.TestCase):\n\n@@ -1,7 +1,7 @@\n import pytest\n \n-from keras import backend\n-from keras import testing\n+from keras.src import backend\n+from keras.src import testing\n \n \n def example_fn(x):\n\n@@ -1,8 +1,8 @@\n import functools\n \n-from keras.api_export import keras_export\n-from keras.backend import config\n-from keras.backend.common.variables import standardize_dtype\n+from keras.src.api_export import keras_export\n+from keras.src.backend import config\n+from keras.src.backend.common.variables import standardize_dtype\n \n BOOL_TYPES = (\"bool\",)\n INT_TYPES = (\n\n@@ -2,18 +2,18 @@ from unittest.mock import patch\n \n from absl.testing import parameterized\n \n-from keras import backend\n-from keras import ops\n-from keras.backend.common import dtypes\n-from keras.testing import test_case\n-from keras.testing.test_utils import named_product\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src.backend.common import dtypes\n+from keras.src.testing import test_case\n+from keras.src.testing.test_utils import named_product\n \n \n class DtypesTest(test_case.TestCase, parameterized.TestCase):\n     \"\"\"Test the dtype to verify that the behavior matches JAX.\"\"\"\n \n     if backend.backend() == \"torch\":\n-        from keras.backend.torch.core import to_torch_dtype\n+        from keras.src.backend.torch.core import to_torch_dtype\n \n         # TODO: torch doesn't support uint64.\n         ALL_DTYPES = []\n\n@@ -1,8 +1,8 @@\n import gc\n import threading\n \n-from keras import backend\n-from keras.api_export import keras_export\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n \n GLOBAL_STATE_TRACKER = threading.local()\n GLOBAL_SETTINGS_TRACKER = threading.local()\n@@ -77,7 +77,7 @@ def clear_session(free_memory=True):\n     GLOBAL_SETTINGS_TRACKER = threading.local()\n \n     if backend.backend() == \"tensorflow\":\n-        from keras.utils.module_utils import tensorflow as tf\n+        from keras.src.utils.module_utils import tensorflow as tf\n \n         tf.compat.v1.reset_default_graph()\n         if tf.executing_eagerly():\n\n@@ -1,6 +1,6 @@\n-from keras.backend.common import global_state\n-from keras.testing import test_case\n-from keras.utils.naming import auto_name\n+from keras.src.backend.common import global_state\n+from keras.src.testing import test_case\n+from keras.src.utils.naming import auto_name\n \n \n class GlobalStateTest(test_case.TestCase):\n\n@@ -1,6 +1,6 @@\n-from keras import tree\n-from keras.api_export import keras_export\n-from keras.utils.naming import auto_name\n+from keras.src import tree\n+from keras.src.api_export import keras_export\n+from keras.src.utils.naming import auto_name\n \n \n @keras_export(\"keras.KerasTensor\")\n@@ -35,7 +35,7 @@ class KerasTensor:\n         record_history=True,\n         name=None,\n     ):\n-        from keras import backend\n+        from keras.src import backend\n \n         self.shape = backend.standardize_shape(shape)\n         self.dtype = backend.standardize_dtype(dtype)\n@@ -48,12 +48,12 @@ class KerasTensor:\n         return len(self.shape)\n \n     def reshape(self, newshape):\n-        from keras import ops\n+        from keras.src import ops\n \n         return ops.Reshape(newshape)(self)\n \n     def squeeze(self, axis=None):\n-        from keras import ops\n+        from keras.src import ops\n \n         return ops.Squeeze(axis)(self)\n \n@@ -125,167 +125,167 @@ class KerasTensor:\n         raise TypeError(\"A symbolic KerasTensor cannot be used as a boolean.\")\n \n     def __add__(self, other):\n-        from keras import ops\n+        from keras.src import ops\n \n         return ops.Add().symbolic_call(self, other)\n \n     def __radd__(self, other):\n-        from keras import ops\n+        from keras.src import ops\n \n         return ops.Add().symbolic_call(other, self)\n \n     def __sub__(self, other):\n-        from keras import ops\n+        from keras.src import ops\n \n         return ops.Subtract().symbolic_call(self, other)\n \n     def __rsub__(self, other):\n-        from keras import ops\n+        from keras.src import ops\n \n         return ops.Subtract().symbolic_call(other, self)\n \n     def __mul__(self, other):\n-        from keras import ops\n+        from keras.src import ops\n \n         return ops.Multiply().symbolic_call(self, other)\n \n     def __rmul__(self, other):\n-        from keras import ops\n+        from keras.src import ops\n \n         return ops.Multiply().symbolic_call(other, self)\n \n     def __matmul__(self, other):\n-        from keras import ops\n+        from keras.src import ops\n \n         return ops.Matmul().symbolic_call(self, other)\n \n     def __rmatmul__(self, other):\n-        from keras import ops\n+        from keras.src import ops\n \n         return ops.Matmul().symbolic_call(other, self)\n \n     def __div__(self, other):\n-        from keras import ops\n+        from keras.src import ops\n \n         return ops.Divide().symbolic_call(self, other)\n \n     def __rdiv__(self, other):\n-        from keras import ops\n+        from keras.src import ops\n \n         return ops.Divide().symbolic_call(other, self)\n \n     def __truediv__(self, other):\n-        from keras import ops\n+        from keras.src import ops\n \n         return ops.TrueDivide().symbolic_call(self, other)\n \n     def __rtruediv__(self, other):\n-        from keras import ops\n+        from keras.src import ops\n \n         return ops.TrueDivide().symbolic_call(other, self)\n \n     def __neg__(self):\n-        from keras import ops\n+        from keras.src import ops\n \n         return ops.Negative().symbolic_call(self)\n \n     def __abs__(self):\n-        from keras import ops\n+        from keras.src import ops\n \n         return ops.Absolute().symbolic_call(self)\n \n     def __pow__(self, other):\n-        from keras import ops\n+        from keras.src import ops\n \n         return ops.Power().symbolic_call(self, other)\n \n     def __rpow__(self, other):\n-        from keras import ops\n+        from keras.src import ops\n \n         return ops.Power().symbolic_call(other, self)\n \n     def __floordiv__(self, other):\n-        from keras import ops\n+        from keras.src import ops\n \n         return ops.FloorDivide().symbolic_call(self, other)\n \n     def __rfloordiv__(self, other):\n-        from keras import ops\n+        from keras.src import ops\n \n         return ops.FloorDivide().symbolic_call(other, self)\n \n     def __mod__(self, other):\n-        from keras import ops\n+        from keras.src import ops\n \n         return ops.Mod().symbolic_call(self, other)\n \n     def __rmod__(self, other):\n-        from keras import ops\n+        from keras.src import ops\n \n         return ops.Mod().symbolic_call(other, self)\n \n     def __lt__(self, other):\n-        from keras import ops\n+        from keras.src import ops\n \n         return ops.Less().symbolic_call(self, other)\n \n     def __le__(self, other):\n-        from keras import ops\n+        from keras.src import ops\n \n         return ops.LessEqual().symbolic_call(self, other)\n \n     def __gt__(self, other):\n-        from keras import ops\n+        from keras.src import ops\n \n         return ops.Greater().symbolic_call(self, other)\n \n     def __ge__(self, other):\n-        from keras import ops\n+        from keras.src import ops\n \n         return ops.GreaterEqual().symbolic_call(self, other)\n \n     def __ne__(self, other):\n-        from keras import ops\n+        from keras.src import ops\n \n         return ops.NotEqual().symbolic_call(self, other)\n \n     def __and__(self, other):\n-        from keras import ops\n+        from keras.src import ops\n \n         return ops.LogicalAnd().symbolic_call(self, other)\n \n     def __rand__(self, other):\n-        from keras import ops\n+        from keras.src import ops\n \n         return ops.LogicalAnd().symbolic_call(other, self)\n \n     def __or__(self, other):\n-        from keras import ops\n+        from keras.src import ops\n \n         return ops.LogicalOr().symbolic_call(self, other)\n \n     def __ror__(self, other):\n-        from keras import ops\n+        from keras.src import ops\n \n         return ops.LogicalOr().symbolic_call(other, self)\n \n     def __invert__(self):\n-        from keras import ops\n+        from keras.src import ops\n \n         return ops.LogicalNot().symbolic_call(self)\n \n     def __xor__(self, other):\n-        from keras import ops\n+        from keras.src import ops\n \n         return ops.LogicalXor().symbolic_call(self, other)\n \n     def __rxor__(self, other):\n-        from keras import ops\n+        from keras.src import ops\n \n         return ops.LogicalXor().symbolic_call(other, self)\n \n     def __getitem__(self, key):\n-        from keras import ops\n+        from keras.src import ops\n \n         return ops.GetItem().symbolic_call(self, key)\n \n\n@@ -4,10 +4,10 @@ from unittest.mock import patch\n import numpy as np\n import tensorflow as tf\n \n-from keras import backend\n-from keras import ops\n-from keras import testing\n-from keras.backend.common import keras_tensor\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src import testing\n+from keras.src.backend.common import keras_tensor\n \n \n class KerasTensorTest(testing.TestCase):\n@@ -80,7 +80,7 @@ class KerasTensorTest(testing.TestCase):\n         y = np.array([1, 2, 3])\n         self.assertFalse(keras_tensor.is_keras_tensor(y))\n \n-    @patch(\"keras.ops.Absolute.symbolic_call\")\n+    @patch(\"keras.src.ops.Absolute.symbolic_call\")\n     def test_abs_method(self, mock_symbolic_call):\n         mock_tensor = Mock()\n         mock_symbolic_call.return_value = mock_tensor\n@@ -89,51 +89,51 @@ class KerasTensorTest(testing.TestCase):\n         mock_symbolic_call.assert_called_once_with(x)\n         self.assertEqual(abs_x, mock_tensor)\n \n-    @patch(\"keras.ops.Negative.symbolic_call\")\n+    @patch(\"keras.src.ops.Negative.symbolic_call\")\n     def test_neg_method(self, mock_method):\n         self._test_unary_op_method(mock_method, lambda x: -x)\n \n-    @patch(\"keras.ops.Subtract.symbolic_call\")\n+    @patch(\"keras.src.ops.Subtract.symbolic_call\")\n     def test_sub_method(self, mock_method):\n         y = Mock()\n         self._test_binary_op_method(mock_method, y, lambda x, y: x - y)\n \n-    @patch(\"keras.ops.Multiply.symbolic_call\")\n+    @patch(\"keras.src.ops.Multiply.symbolic_call\")\n     def test_mul_method(self, mock_method):\n         y = Mock()\n         self._test_binary_op_method(mock_method, y, lambda x, y: x * y)\n \n-    @patch(\"keras.ops.Matmul.symbolic_call\")\n+    @patch(\"keras.src.ops.Matmul.symbolic_call\")\n     def test_matmul_method(self, mock_method):\n         y = Mock()\n         self._test_binary_op_method(mock_method, y, lambda x, y: x @ y)\n \n-    @patch(\"keras.ops.Power.symbolic_call\")\n+    @patch(\"keras.src.ops.Power.symbolic_call\")\n     def test_pow_method(self, mock_method):\n         y = Mock()\n         self._test_binary_op_method(mock_method, y, lambda x, y: x**y)\n \n-    @patch(\"keras.ops.Mod.symbolic_call\")\n+    @patch(\"keras.src.ops.Mod.symbolic_call\")\n     def test_mod_method(self, mock_method):\n         y = Mock()\n         self._test_binary_op_method(mock_method, y, lambda x, y: x % y)\n \n-    @patch(\"keras.ops.Less.symbolic_call\")\n+    @patch(\"keras.src.ops.Less.symbolic_call\")\n     def test_lt_method(self, mock_method):\n         y = Mock()\n         self._test_binary_op_method(mock_method, y, lambda x, y: x < y)\n \n-    @patch(\"keras.ops.LogicalAnd.symbolic_call\")\n+    @patch(\"keras.src.ops.LogicalAnd.symbolic_call\")\n     def test_and_method(self, mock_method):\n         y = Mock()\n         self._test_binary_op_method(mock_method, y, lambda x, y: x & y)\n \n-    @patch(\"keras.ops.LogicalOr.symbolic_call\")\n+    @patch(\"keras.src.ops.LogicalOr.symbolic_call\")\n     def test_or_method(self, mock_method):\n         y = Mock()\n         self._test_binary_op_method(mock_method, y, lambda x, y: x | y)\n \n-    @patch(\"keras.ops.GetItem.symbolic_call\")\n+    @patch(\"keras.src.ops.GetItem.symbolic_call\")\n     def test_getitem_method(self, mock_method):\n         y = Mock()\n         self._test_binary_op_method(mock_method, y, lambda x, y: x[y])\n@@ -154,7 +154,7 @@ class KerasTensorTest(testing.TestCase):\n         mock_method.assert_called_once_with(x, other)\n         self.assertEqual(result, mock_tensor)\n \n-    @patch(\"keras.ops.Add.symbolic_call\")\n+    @patch(\"keras.src.ops.Add.symbolic_call\")\n     def test_radd_method(self, mock_symbolic_call):\n         \"\"\"Test __radd__ method\"\"\"\n         mock_tensor = Mock()\n@@ -165,7 +165,7 @@ class KerasTensorTest(testing.TestCase):\n         mock_symbolic_call.assert_called_once_with(y, x)\n         self.assertEqual(result, mock_tensor)\n \n-    @patch(\"keras.ops.Subtract.symbolic_call\")\n+    @patch(\"keras.src.ops.Subtract.symbolic_call\")\n     def test_rsub_method(self, mock_symbolic_call):\n         \"\"\"Test __rsub__ method\"\"\"\n         mock_tensor = Mock()\n@@ -176,7 +176,7 @@ class KerasTensorTest(testing.TestCase):\n         mock_symbolic_call.assert_called_once_with(y, x)\n         self.assertEqual(result, mock_tensor)\n \n-    @patch(\"keras.ops.Multiply.symbolic_call\")\n+    @patch(\"keras.src.ops.Multiply.symbolic_call\")\n     def test_rmul_method(self, mock_symbolic_call):\n         \"\"\"Test __rmul__ method\"\"\"\n         mock_tensor = Mock()\n@@ -187,7 +187,7 @@ class KerasTensorTest(testing.TestCase):\n         mock_symbolic_call.assert_called_once_with(y, x)\n         self.assertEqual(result, mock_tensor)\n \n-    @patch(\"keras.ops.Matmul.symbolic_call\")\n+    @patch(\"keras.src.ops.Matmul.symbolic_call\")\n     def test_rmatmul_method(self, mock_symbolic_call):\n         \"\"\"Test __rmatmul__ method\"\"\"\n         mock_tensor = Mock()\n@@ -198,7 +198,7 @@ class KerasTensorTest(testing.TestCase):\n         mock_symbolic_call.assert_called_once_with(y, x)\n         self.assertEqual(result, mock_tensor)\n \n-    @patch(\"keras.ops.Power.symbolic_call\")\n+    @patch(\"keras.src.ops.Power.symbolic_call\")\n     def test_rpow_method(self, mock_symbolic_call):\n         \"\"\"Test __rpow__ method\"\"\"\n         mock_tensor = Mock()\n@@ -209,7 +209,7 @@ class KerasTensorTest(testing.TestCase):\n         mock_symbolic_call.assert_called_once_with(y, x)\n         self.assertEqual(result, mock_tensor)\n \n-    @patch(\"keras.ops.FloorDivide.symbolic_call\")\n+    @patch(\"keras.src.ops.FloorDivide.symbolic_call\")\n     def test_floordiv_method(self, mock_symbolic_call):\n         \"\"\"Test __floordiv__ method\"\"\"\n         mock_tensor = Mock()\n@@ -220,7 +220,7 @@ class KerasTensorTest(testing.TestCase):\n         mock_symbolic_call.assert_called_once_with(x, y)\n         self.assertEqual(result, mock_tensor)\n \n-    @patch(\"keras.ops.FloorDivide.symbolic_call\")\n+    @patch(\"keras.src.ops.FloorDivide.symbolic_call\")\n     def test_rfloordiv_method(self, mock_symbolic_call):\n         \"\"\"Test __rfloordiv__ method\"\"\"\n         mock_tensor = Mock()\n@@ -231,7 +231,7 @@ class KerasTensorTest(testing.TestCase):\n         mock_symbolic_call.assert_called_once_with(y, x)\n         self.assertEqual(result, mock_tensor)\n \n-    @patch(\"keras.ops.Mod.symbolic_call\")\n+    @patch(\"keras.src.ops.Mod.symbolic_call\")\n     def test_rmod_method(self, mock_symbolic_call):\n         \"\"\"Test __rmod__ method\"\"\"\n         mock_tensor = Mock()\n@@ -242,7 +242,7 @@ class KerasTensorTest(testing.TestCase):\n         mock_symbolic_call.assert_called_once_with(y, x)\n         self.assertEqual(result, mock_tensor)\n \n-    @patch(\"keras.ops.LessEqual.symbolic_call\")\n+    @patch(\"keras.src.ops.LessEqual.symbolic_call\")\n     def test_le_method(self, mock_symbolic_call):\n         \"\"\"Test __le__ method\"\"\"\n         mock_tensor = Mock()\n@@ -253,7 +253,7 @@ class KerasTensorTest(testing.TestCase):\n         mock_symbolic_call.assert_called_once_with(x, y)\n         self.assertEqual(result, mock_tensor)\n \n-    @patch(\"keras.ops.Greater.symbolic_call\")\n+    @patch(\"keras.src.ops.Greater.symbolic_call\")\n     def test_gt_method(self, mock_symbolic_call):\n         \"\"\"Test __gt__ method\"\"\"\n         mock_tensor = Mock()\n@@ -264,7 +264,7 @@ class KerasTensorTest(testing.TestCase):\n         mock_symbolic_call.assert_called_once_with(x, y)\n         self.assertEqual(result, mock_tensor)\n \n-    @patch(\"keras.ops.GreaterEqual.symbolic_call\")\n+    @patch(\"keras.src.ops.GreaterEqual.symbolic_call\")\n     def test_ge_method(self, mock_symbolic_call):\n         \"\"\"Test __ge__ method\"\"\"\n         mock_tensor = Mock()\n@@ -275,7 +275,7 @@ class KerasTensorTest(testing.TestCase):\n         mock_symbolic_call.assert_called_once_with(x, y)\n         self.assertEqual(result, mock_tensor)\n \n-    @patch(\"keras.ops.NotEqual.symbolic_call\")\n+    @patch(\"keras.src.ops.NotEqual.symbolic_call\")\n     def test_ne_method(self, mock_symbolic_call):\n         \"\"\"Test __ne__ method\"\"\"\n         mock_tensor = Mock()\n@@ -286,7 +286,7 @@ class KerasTensorTest(testing.TestCase):\n         mock_symbolic_call.assert_called_once_with(x, y)\n         self.assertEqual(result, mock_tensor)\n \n-    @patch(\"keras.ops.LogicalAnd.symbolic_call\")\n+    @patch(\"keras.src.ops.LogicalAnd.symbolic_call\")\n     def test_rand_method(self, mock_symbolic_call):\n         \"\"\"Test __rand__ method\"\"\"\n         mock_tensor = Mock()\n@@ -297,7 +297,7 @@ class KerasTensorTest(testing.TestCase):\n         mock_symbolic_call.assert_called_once_with(y, x)\n         self.assertEqual(result, mock_tensor)\n \n-    @patch(\"keras.ops.LogicalOr.symbolic_call\")\n+    @patch(\"keras.src.ops.LogicalOr.symbolic_call\")\n     def test_ror_method(self, mock_symbolic_call):\n         \"\"\"Test __ror__ method\"\"\"\n         mock_tensor = Mock()\n@@ -308,7 +308,7 @@ class KerasTensorTest(testing.TestCase):\n         mock_symbolic_call.assert_called_once_with(y, x)\n         self.assertEqual(result, mock_tensor)\n \n-    @patch(\"keras.ops.LogicalNot.symbolic_call\")\n+    @patch(\"keras.src.ops.LogicalNot.symbolic_call\")\n     def test_invert_method(self, mock_symbolic_call):\n         \"\"\"Test __invert__ method\"\"\"\n         mock_tensor = Mock()\n@@ -318,7 +318,7 @@ class KerasTensorTest(testing.TestCase):\n         mock_symbolic_call.assert_called_once_with(x)\n         self.assertEqual(result, mock_tensor)\n \n-    @patch(\"keras.ops.LogicalXor.symbolic_call\")\n+    @patch(\"keras.src.ops.LogicalXor.symbolic_call\")\n     def test_xor_method(self, mock_symbolic_call):\n         \"\"\"Test __xor__ method\"\"\"\n         mock_tensor = Mock()\n@@ -329,7 +329,7 @@ class KerasTensorTest(testing.TestCase):\n         mock_symbolic_call.assert_called_once_with(x, y)\n         self.assertEqual(result, mock_tensor)\n \n-    @patch(\"keras.ops.LogicalXor.symbolic_call\")\n+    @patch(\"keras.src.ops.LogicalXor.symbolic_call\")\n     def test_rxor_method(self, mock_symbolic_call):\n         \"\"\"Test __rxor__ method\"\"\"\n         mock_tensor = Mock()\n@@ -340,7 +340,7 @@ class KerasTensorTest(testing.TestCase):\n         mock_symbolic_call.assert_called_once_with(y, x)\n         self.assertEqual(result, mock_tensor)\n \n-    @patch(\"keras.ops.TrueDivide.symbolic_call\")\n+    @patch(\"keras.src.ops.TrueDivide.symbolic_call\")\n     def test_truediv_method(self, mock_symbolic_call):\n         \"\"\"Test __truediv__ method\"\"\"\n         mock_tensor = Mock()\n@@ -351,7 +351,7 @@ class KerasTensorTest(testing.TestCase):\n         mock_symbolic_call.assert_called_once_with(x, y)\n         self.assertEqual(result, mock_tensor)\n \n-    @patch(\"keras.ops.TrueDivide.symbolic_call\")\n+    @patch(\"keras.src.ops.TrueDivide.symbolic_call\")\n     def test_rtruediv_method(self, mock_symbolic_call):\n         \"\"\"Test __rtruediv__ method\"\"\"\n         mock_tensor = Mock()\n@@ -362,7 +362,7 @@ class KerasTensorTest(testing.TestCase):\n         mock_symbolic_call.assert_called_once_with(y, x)\n         self.assertEqual(result, mock_tensor)\n \n-    @patch(\"keras.ops.Divide.symbolic_call\")\n+    @patch(\"keras.src.ops.Divide.symbolic_call\")\n     def test_div_method(self, mock_symbolic_call):\n         \"\"\"Test __div__ method\"\"\"\n         mock_tensor = Mock()\n@@ -374,7 +374,7 @@ class KerasTensorTest(testing.TestCase):\n         mock_symbolic_call.assert_called_once_with(x, y)\n         self.assertEqual(result, mock_tensor)\n \n-    @patch(\"keras.ops.Divide.symbolic_call\")\n+    @patch(\"keras.src.ops.Divide.symbolic_call\")\n     def test_rdiv_method(self, mock_symbolic_call):\n         \"\"\"Test __rdiv__ method\"\"\"\n         mock_tensor = Mock()\n\n@@ -1,4 +1,4 @@\n-from keras.backend.common import global_state\n+from keras.src.backend.common import global_state\n \n \n class name_scope:\n\n@@ -1,6 +1,6 @@\n-from keras import testing\n-from keras.backend.common.name_scope import current_path\n-from keras.backend.common.name_scope import name_scope\n+from keras.src import testing\n+from keras.src.backend.common.name_scope import current_path\n+from keras.src.backend.common.name_scope import name_scope\n \n \n class NameScopeTest(testing.TestCase):\n\n@@ -1,5 +1,5 @@\n-from keras.api_export import keras_export\n-from keras.backend.common import global_state\n+from keras.src.api_export import keras_export\n+from keras.src.backend.common import global_state\n \n \n @keras_export(\"keras.StatelessScope\")\n@@ -38,8 +38,8 @@ class StatelessScope:\n         collect_losses=False,\n         initialize_variables=True,\n     ):\n-        from keras import backend\n-        from keras.backend.common.variables import KerasVariable\n+        from keras.src import backend\n+        from keras.src.backend.common.variables import KerasVariable\n \n         self.collect_losses = collect_losses\n         self.initialize_variables = initialize_variables\n@@ -90,7 +90,9 @@ class StatelessScope:\n             # We're back in eager scope;\n             # if any variables were created within the stateless\n             # scope, we initialize them here.\n-            from keras.backend.common.variables import initialize_all_variables\n+            from keras.src.backend.common.variables import (\n+                initialize_all_variables,\n+            )\n \n             initialize_all_variables()\n \n\n@@ -1,9 +1,9 @@\n import numpy as np\n \n-from keras import backend\n-from keras import ops\n-from keras import testing\n-from keras.backend.common.stateless_scope import StatelessScope\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src import testing\n+from keras.src.backend.common.stateless_scope import StatelessScope\n \n \n class TestStatelessScope(testing.TestCase):\n\n@@ -1,14 +1,14 @@\n import numpy as np\n \n-from keras.api_export import keras_export\n-from keras.backend import config\n-from keras.backend.common import dtypes\n-from keras.backend.common import global_state\n-from keras.backend.common.name_scope import current_path\n-from keras.backend.common.stateless_scope import get_stateless_scope\n-from keras.backend.common.stateless_scope import in_stateless_scope\n-from keras.utils.module_utils import tensorflow as tf\n-from keras.utils.naming import auto_name\n+from keras.src.api_export import keras_export\n+from keras.src.backend import config\n+from keras.src.backend.common import dtypes\n+from keras.src.backend.common import global_state\n+from keras.src.backend.common.name_scope import current_path\n+from keras.src.backend.common.stateless_scope import get_stateless_scope\n+from keras.src.backend.common.stateless_scope import in_stateless_scope\n+from keras.src.utils.module_utils import tensorflow as tf\n+from keras.src.utils.naming import auto_name\n \n \n class KerasVariable:\n@@ -55,7 +55,7 @@ class KerasVariable:\n     **Using a Keras initializer to create a `Variable`:**\n \n     ```python\n-    from keras.initializers import Ones\n+    from keras.src.initializers import Ones\n     variable_from_initializer = keras.Variable(\n         initializer=Ones(), shape=(3, 3), dtype=\"float32\"\n     )\n@@ -120,7 +120,7 @@ class KerasVariable:\n         # Ref: https://github.com/google/flax/blob/main/flax/linen/fp8_ops.py\n         self._overwrite_with_gradient = False\n         if isinstance(initializer, str):\n-            from keras import initializers\n+            from keras.src import initializers\n \n             initializer = initializers.get(initializer)\n         if callable(initializer):\n@@ -298,7 +298,7 @@ class KerasVariable:\n \n     @regularizer.setter\n     def regularizer(self, value):\n-        from keras.regularizers import Regularizer\n+        from keras.src.regularizers import Regularizer\n \n         if value is not None and not isinstance(value, Regularizer):\n             raise ValueError(\n@@ -314,7 +314,7 @@ class KerasVariable:\n \n     @constraint.setter\n     def constraint(self, value):\n-        from keras.constraints import Constraint\n+        from keras.src.constraints import Constraint\n \n         if value is not None and not isinstance(value, Constraint):\n             raise ValueError(\n@@ -605,7 +605,7 @@ class AutocastScope:\n         self.original_scope = None\n \n     def maybe_cast(self, value):\n-        from keras import backend\n+        from keras.src import backend\n \n         if self.dtype is not None and is_float_dtype(value.dtype):\n             return backend.cast(value, dtype=self.dtype)\n\n@@ -2,15 +2,15 @@ import numpy as np\n import pytest\n from absl.testing import parameterized\n \n-from keras import backend\n-from keras import initializers\n-from keras.backend.common import dtypes\n-from keras.backend.common.variables import AutocastScope\n-from keras.backend.common.variables import KerasVariable\n-from keras.backend.common.variables import shape_equal\n-from keras.backend.common.variables import standardize_dtype\n-from keras.backend.common.variables import standardize_shape\n-from keras.testing import test_case\n+from keras.src import backend\n+from keras.src import initializers\n+from keras.src.backend.common import dtypes\n+from keras.src.backend.common.variables import AutocastScope\n+from keras.src.backend.common.variables import KerasVariable\n+from keras.src.backend.common.variables import shape_equal\n+from keras.src.backend.common.variables import standardize_dtype\n+from keras.src.backend.common.variables import standardize_shape\n+from keras.src.testing import test_case\n \n \n class VariableInitializationTest(test_case.TestCase):\n@@ -267,7 +267,7 @@ class VariableNumpyValueAndAssignmentTest(test_case.TestCase):\n         reason=\"Tests for MirroredVariable under tf backend\",\n     )\n     def test_variable_numpy_scalar(self):\n-        from keras.utils.module_utils import tensorflow as tf\n+        from keras.src.utils.module_utils import tensorflow as tf\n \n         strategy = tf.distribute.MirroredStrategy([\"cpu:0\", \"cpu:1\"])\n         with strategy.scope():\n\n@@ -1,7 +1,7 @@\n import json\n import os\n \n-from keras.api_export import keras_export\n+from keras.src.api_export import keras_export\n \n # The type of float to use throughout a session.\n _FLOATX = \"float32\"\n\n@@ -1,5 +1,5 @@\n-from keras import backend\n-from keras.api_export import keras_export\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n \n if backend.backend() == \"tensorflow\":\n     BackendVariable = backend.tensorflow.core.Variable\n@@ -11,7 +11,7 @@ elif backend.backend() == \"torch\":\n     BackendVariable = backend.torch.core.Variable\n     backend_name_scope = backend.common.name_scope.name_scope\n elif backend.backend() == \"numpy\":\n-    from keras.backend.numpy.core import Variable as NumpyVariable\n+    from keras.src.backend.numpy.core import Variable as NumpyVariable\n \n     BackendVariable = NumpyVariable\n     backend_name_scope = backend.common.name_scope.name_scope\n\n@@ -0,0 +1,25 @@\n+from keras.src.backend.jax import core\n+from keras.src.backend.jax import distribution_lib\n+from keras.src.backend.jax import image\n+from keras.src.backend.jax import linalg\n+from keras.src.backend.jax import math\n+from keras.src.backend.jax import nn\n+from keras.src.backend.jax import numpy\n+from keras.src.backend.jax import random\n+from keras.src.backend.jax.core import SUPPORTS_SPARSE_TENSORS\n+from keras.src.backend.jax.core import Variable\n+from keras.src.backend.jax.core import cast\n+from keras.src.backend.jax.core import compute_output_spec\n+from keras.src.backend.jax.core import cond\n+from keras.src.backend.jax.core import convert_to_numpy\n+from keras.src.backend.jax.core import convert_to_tensor\n+from keras.src.backend.jax.core import device_scope\n+from keras.src.backend.jax.core import is_tensor\n+from keras.src.backend.jax.core import scatter\n+from keras.src.backend.jax.core import shape\n+from keras.src.backend.jax.core import stop_gradient\n+from keras.src.backend.jax.core import vectorized_map\n+from keras.src.backend.jax.rnn import cudnn_ok\n+from keras.src.backend.jax.rnn import gru\n+from keras.src.backend.jax.rnn import lstm\n+from keras.src.backend.jax.rnn import rnn\n\n@@ -4,13 +4,13 @@ import jax.numpy as jnp\n import ml_dtypes\n import numpy as np\n \n-from keras import tree\n-from keras.backend.common import KerasVariable\n-from keras.backend.common import global_state\n-from keras.backend.common import standardize_dtype\n-from keras.backend.common.keras_tensor import KerasTensor\n-from keras.backend.common.stateless_scope import StatelessScope\n-from keras.backend.jax import distribution_lib\n+from keras.src import tree\n+from keras.src.backend.common import KerasVariable\n+from keras.src.backend.common import global_state\n+from keras.src.backend.common import standardize_dtype\n+from keras.src.backend.common.keras_tensor import KerasTensor\n+from keras.src.backend.common.stateless_scope import StatelessScope\n+from keras.src.backend.jax import distribution_lib\n \n SUPPORTS_SPARSE_TENSORS = True\n \n\n@@ -9,7 +9,7 @@ with other backends in the future.\n import jax\n import numpy as np\n \n-from keras.utils import jax_utils\n+from keras.src.utils import jax_utils\n \n \n def list_devices(device_type=None):\n\n@@ -8,12 +8,12 @@ import jax\n import numpy as np\n import pytest\n \n-from keras import backend\n-from keras import layers\n-from keras import models\n-from keras import testing\n-from keras.backend import distribution_lib as backend_dlib\n-from keras.distribution import distribution_lib\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import models\n+from keras.src import testing\n+from keras.src.backend import distribution_lib as backend_dlib\n+from keras.src.distribution import distribution_lib\n \n if backend.backend() == \"jax\":\n     # Due to https://github.com/google/jax/issues/17188, we can't\n\n@@ -3,7 +3,7 @@ import functools\n import jax\n import jax.numpy as jnp\n \n-from keras.backend.jax.core import convert_to_tensor\n+from keras.src.backend.jax.core import convert_to_tensor\n \n RESIZE_INTERPOLATIONS = (\n     \"bilinear\",\n\n\n@@ -2,11 +2,11 @@ import jax\n import jax.numpy as jnp\n import jax.scipy as jsp\n \n-from keras.backend import config\n-from keras.backend import standardize_dtype\n-from keras.backend.common import dtypes\n-from keras.backend.jax.core import cast\n-from keras.backend.jax.core import convert_to_tensor\n+from keras.src.backend import config\n+from keras.src.backend import standardize_dtype\n+from keras.src.backend.common import dtypes\n+from keras.src.backend.jax.core import cast\n+from keras.src.backend.jax.core import convert_to_tensor\n \n \n def cholesky(a):\n\n@@ -3,12 +3,12 @@ import math\n import jax\n import jax.numpy as jnp\n \n-from keras.backend import config\n-from keras.backend import standardize_dtype\n-from keras.backend.common import dtypes\n-from keras.backend.jax.core import cast\n-from keras.backend.jax.core import convert_to_tensor\n-from keras.utils.module_utils import scipy\n+from keras.src.backend import config\n+from keras.src.backend import standardize_dtype\n+from keras.src.backend.common import dtypes\n+from keras.src.backend.jax.core import cast\n+from keras.src.backend.jax.core import convert_to_tensor\n+from keras.src.utils.module_utils import scipy\n \n \n def segment_sum(data, segment_ids, num_segments=None, sorted=False):\n\n@@ -5,14 +5,14 @@ import numpy as np\n from jax import lax\n from jax import nn as jnn\n \n-from keras.backend import standardize_data_format\n-from keras.backend import standardize_dtype\n-from keras.backend.common.backend_utils import (\n+from keras.src.backend import standardize_data_format\n+from keras.src.backend import standardize_dtype\n+from keras.src.backend.common.backend_utils import (\n     compute_conv_transpose_padding_args_for_jax,\n )\n-from keras.backend.config import epsilon\n-from keras.backend.jax.core import cast\n-from keras.backend.jax.core import convert_to_tensor\n+from keras.src.backend.config import epsilon\n+from keras.src.backend.jax.core import cast\n+from keras.src.backend.jax.core import convert_to_tensor\n \n \n def relu(x):\n\n@@ -4,15 +4,15 @@ import math\n import jax.experimental.sparse as jax_sparse\n import jax.numpy as jnp\n \n-from keras.backend import config\n-from keras.backend.common import dtypes\n-from keras.backend.common.backend_utils import canonicalize_axis\n-from keras.backend.common.backend_utils import to_tuple_or_list\n-from keras.backend.common.variables import standardize_dtype\n-from keras.backend.jax import nn\n-from keras.backend.jax import sparse\n-from keras.backend.jax.core import cast\n-from keras.backend.jax.core import convert_to_tensor\n+from keras.src.backend import config\n+from keras.src.backend.common import dtypes\n+from keras.src.backend.common.backend_utils import canonicalize_axis\n+from keras.src.backend.common.backend_utils import to_tuple_or_list\n+from keras.src.backend.common.variables import standardize_dtype\n+from keras.src.backend.jax import nn\n+from keras.src.backend.jax import sparse\n+from keras.src.backend.jax.core import cast\n+from keras.src.backend.jax.core import convert_to_tensor\n \n \n @sparse.elementwise_binary_union(linear=True, use_sparsify=True)\n@@ -860,7 +860,7 @@ def repeat(x, repeats, axis=None):\n \n def reshape(x, newshape):\n     if isinstance(x, jax_sparse.BCOO):\n-        from keras.ops import operation_utils\n+        from keras.src.ops import operation_utils\n \n         # Resolve the -1 in `new_shape` if applicable and possible\n         output_shape = operation_utils.compute_reshape_output_shape(\n\n@@ -1,7 +1,7 @@\n import jax\n from jax import numpy as jnp\n \n-from keras.optimizers import base_optimizer\n+from keras.src.optimizers import base_optimizer\n \n \n class JaxOptimizer(base_optimizer.BaseOptimizer):\n\n@@ -1,9 +1,9 @@\n import jax\n \n-from keras.backend.config import floatx\n-from keras.random.seed_generator import SeedGenerator\n-from keras.random.seed_generator import draw_seed\n-from keras.random.seed_generator import make_default_seed\n+from keras.src.backend.config import floatx\n+from keras.src.random.seed_generator import SeedGenerator\n+from keras.src.random.seed_generator import draw_seed\n+from keras.src.random.seed_generator import make_default_seed\n \n \n def jax_draw_seed(seed):\n\n@@ -3,8 +3,8 @@ import contextlib\n from jax import lax\n from jax import numpy as jnp\n \n-from keras import tree\n-from keras.backend.common import stateless_scope\n+from keras.src import tree\n+from keras.src.backend.common import stateless_scope\n \n \n def rnn(\n\n@@ -3,7 +3,7 @@ import functools\n import jax.experimental.sparse as jax_sparse\n import jax.numpy as jnp\n \n-from keras.utils import jax_utils\n+from keras.src.utils import jax_utils\n \n \n def axis_shape_dims_for_broadcast_in_dim(axis, input_shape, insert_dims):\n\n@@ -5,17 +5,17 @@ from functools import partial\n import jax\n import numpy as np\n \n-from keras import backend\n-from keras import callbacks as callbacks_module\n-from keras import optimizers as optimizers_module\n-from keras import tree\n-from keras.backend import distribution_lib as jax_distribution_lib\n-from keras.distribution import distribution_lib\n-from keras.trainers import trainer as base_trainer\n-from keras.trainers.data_adapters import array_slicing\n-from keras.trainers.data_adapters import data_adapter_utils\n-from keras.trainers.epoch_iterator import EpochIterator\n-from keras.utils import traceback_utils\n+from keras.src import backend\n+from keras.src import callbacks as callbacks_module\n+from keras.src import optimizers as optimizers_module\n+from keras.src import tree\n+from keras.src.backend import distribution_lib as jax_distribution_lib\n+from keras.src.distribution import distribution_lib\n+from keras.src.trainers import trainer as base_trainer\n+from keras.src.trainers.data_adapters import array_slicing\n+from keras.src.trainers.data_adapters import data_adapter_utils\n+from keras.src.trainers.epoch_iterator import EpochIterator\n+from keras.src.utils import traceback_utils\n \n \n class JAXTrainer(base_trainer.Trainer):\n\n@@ -0,0 +1,21 @@\n+from keras.src.backend.numpy import core\n+from keras.src.backend.numpy import image\n+from keras.src.backend.numpy import linalg\n+from keras.src.backend.numpy import math\n+from keras.src.backend.numpy import nn\n+from keras.src.backend.numpy import numpy\n+from keras.src.backend.numpy import random\n+from keras.src.backend.numpy.core import SUPPORTS_SPARSE_TENSORS\n+from keras.src.backend.numpy.core import Variable\n+from keras.src.backend.numpy.core import cast\n+from keras.src.backend.numpy.core import compute_output_spec\n+from keras.src.backend.numpy.core import cond\n+from keras.src.backend.numpy.core import convert_to_numpy\n+from keras.src.backend.numpy.core import convert_to_tensor\n+from keras.src.backend.numpy.core import is_tensor\n+from keras.src.backend.numpy.core import shape\n+from keras.src.backend.numpy.core import vectorized_map\n+from keras.src.backend.numpy.rnn import cudnn_ok\n+from keras.src.backend.numpy.rnn import gru\n+from keras.src.backend.numpy.rnn import lstm\n+from keras.src.backend.numpy.rnn import rnn\n\n@@ -1,11 +1,11 @@\n import numpy as np\n \n-from keras import tree\n-from keras.backend.common import KerasVariable\n-from keras.backend.common import standardize_dtype\n-from keras.backend.common.dtypes import result_type\n-from keras.backend.common.keras_tensor import KerasTensor\n-from keras.backend.common.stateless_scope import StatelessScope\n+from keras.src import tree\n+from keras.src.backend.common import KerasVariable\n+from keras.src.backend.common import standardize_dtype\n+from keras.src.backend.common.dtypes import result_type\n+from keras.src.backend.common.keras_tensor import KerasTensor\n+from keras.src.backend.common.stateless_scope import StatelessScope\n \n SUPPORTS_SPARSE_TENSORS = False\n \n\n@@ -1,8 +1,8 @@\n import jax\n import numpy as np\n \n-from keras.backend.numpy.core import convert_to_tensor\n-from keras.utils.module_utils import scipy\n+from keras.src.backend.numpy.core import convert_to_tensor\n+from keras.src.utils.module_utils import scipy\n \n RESIZE_INTERPOLATIONS = (\n     \"bilinear\",\n\n\n@@ -1,9 +1,9 @@\n import numpy as np\n import scipy.linalg as sl\n \n-from keras.backend import standardize_dtype\n-from keras.backend.common import dtypes\n-from keras.backend.numpy.core import convert_to_tensor\n+from keras.src.backend import standardize_dtype\n+from keras.src.backend.common import dtypes\n+from keras.src.backend.numpy.core import convert_to_tensor\n \n \n def cholesky(a):\n\n@@ -1,11 +1,11 @@\n import numpy as np\n \n-from keras.backend import standardize_dtype\n-from keras.backend.common import dtypes\n-from keras.backend.jax.math import fft as jax_fft\n-from keras.backend.jax.math import fft2 as jax_fft2\n-from keras.backend.numpy.core import convert_to_tensor\n-from keras.utils.module_utils import scipy\n+from keras.src.backend import standardize_dtype\n+from keras.src.backend.common import dtypes\n+from keras.src.backend.jax.math import fft as jax_fft\n+from keras.src.backend.jax.math import fft2 as jax_fft2\n+from keras.src.backend.numpy.core import convert_to_tensor\n+from keras.src.utils.module_utils import scipy\n \n \n def segment_sum(data, segment_ids, num_segments=None, sorted=False):\n\n@@ -3,16 +3,16 @@ import numpy as np\n from jax import lax\n from jax import numpy as jnp\n \n-from keras.backend import standardize_data_format\n-from keras.backend import standardize_dtype\n-from keras.backend.common.backend_utils import (\n+from keras.src.backend import standardize_data_format\n+from keras.src.backend import standardize_dtype\n+from keras.src.backend.common.backend_utils import (\n     compute_conv_transpose_padding_args_for_jax,\n )\n-from keras.backend.config import epsilon\n-from keras.backend.numpy.core import cast\n-from keras.backend.numpy.core import convert_to_tensor\n-from keras.backend.numpy.core import is_tensor\n-from keras.utils.module_utils import scipy\n+from keras.src.backend.config import epsilon\n+from keras.src.backend.numpy.core import cast\n+from keras.src.backend.numpy.core import convert_to_tensor\n+from keras.src.backend.numpy.core import is_tensor\n+from keras.src.utils.module_utils import scipy\n \n \n def relu(x):\n\n@@ -1,11 +1,11 @@\n import numpy as np\n \n-from keras import tree\n-from keras.backend import config\n-from keras.backend import standardize_dtype\n-from keras.backend.common import dtypes\n-from keras.backend.common.backend_utils import standardize_axis_for_numpy\n-from keras.backend.numpy.core import convert_to_tensor\n+from keras.src import tree\n+from keras.src.backend import config\n+from keras.src.backend import standardize_dtype\n+from keras.src.backend.common import dtypes\n+from keras.src.backend.common.backend_utils import standardize_axis_for_numpy\n+from keras.src.backend.numpy.core import convert_to_tensor\n \n \n def add(x1, x2):\n\n@@ -1,10 +1,10 @@\n import numpy as np\n \n-from keras.backend.config import floatx\n-from keras.backend.numpy.nn import softmax\n-from keras.random.seed_generator import SeedGenerator\n-from keras.random.seed_generator import draw_seed\n-from keras.random.seed_generator import make_default_seed\n+from keras.src.backend.config import floatx\n+from keras.src.backend.numpy.nn import softmax\n+from keras.src.random.seed_generator import SeedGenerator\n+from keras.src.random.seed_generator import draw_seed\n+from keras.src.random.seed_generator import make_default_seed\n \n \n def normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n\n@@ -1,6 +1,6 @@\n import numpy as np\n \n-from keras import tree\n+from keras.src import tree\n \n \n def rnn(\n\n@@ -1,15 +1,15 @@\n import numpy as np\n \n-from keras import backend\n-from keras import callbacks as callbacks_module\n-from keras import tree\n-from keras.backend.common import standardize_dtype\n-from keras.backend.common.keras_tensor import KerasTensor\n-from keras.backend.numpy.core import is_tensor\n-from keras.trainers import trainer as base_trainer\n-from keras.trainers.data_adapters import data_adapter_utils\n-from keras.trainers.epoch_iterator import EpochIterator\n-from keras.utils import traceback_utils\n+from keras.src import backend\n+from keras.src import callbacks as callbacks_module\n+from keras.src import tree\n+from keras.src.backend.common import standardize_dtype\n+from keras.src.backend.common.keras_tensor import KerasTensor\n+from keras.src.backend.numpy.core import is_tensor\n+from keras.src.trainers import trainer as base_trainer\n+from keras.src.trainers.data_adapters import data_adapter_utils\n+from keras.src.trainers.epoch_iterator import EpochIterator\n+from keras.src.utils import traceback_utils\n \n \n class NumpyTrainer(base_trainer.Trainer):\n\n@@ -0,0 +1,27 @@\n+from keras.src.backend.tensorflow import core\n+from keras.src.backend.tensorflow import distribution_lib\n+from keras.src.backend.tensorflow import image\n+from keras.src.backend.tensorflow import linalg\n+from keras.src.backend.tensorflow import math\n+from keras.src.backend.tensorflow import nn\n+from keras.src.backend.tensorflow import numpy\n+from keras.src.backend.tensorflow import random\n+from keras.src.backend.tensorflow import tensorboard\n+from keras.src.backend.tensorflow.core import SUPPORTS_SPARSE_TENSORS\n+from keras.src.backend.tensorflow.core import Variable\n+from keras.src.backend.tensorflow.core import cast\n+from keras.src.backend.tensorflow.core import compute_output_spec\n+from keras.src.backend.tensorflow.core import cond\n+from keras.src.backend.tensorflow.core import convert_to_numpy\n+from keras.src.backend.tensorflow.core import convert_to_tensor\n+from keras.src.backend.tensorflow.core import device_scope\n+from keras.src.backend.tensorflow.core import is_tensor\n+from keras.src.backend.tensorflow.core import name_scope\n+from keras.src.backend.tensorflow.core import scatter\n+from keras.src.backend.tensorflow.core import shape\n+from keras.src.backend.tensorflow.core import stop_gradient\n+from keras.src.backend.tensorflow.core import vectorized_map\n+from keras.src.backend.tensorflow.rnn import cudnn_ok\n+from keras.src.backend.tensorflow.rnn import gru\n+from keras.src.backend.tensorflow.rnn import lstm\n+from keras.src.backend.tensorflow.rnn import rnn\n\n@@ -2,16 +2,16 @@ import numpy as np\n import tensorflow as tf\n from tensorflow.compiler.tf2xla.python.xla import dynamic_update_slice\n \n-from keras import tree\n-from keras.backend.common import KerasVariable\n-from keras.backend.common import global_state\n-from keras.backend.common import standardize_dtype\n-from keras.backend.common.keras_tensor import KerasTensor\n-from keras.backend.common.name_scope import name_scope as base_name_scope\n-from keras.backend.common.stateless_scope import StatelessScope\n-from keras.backend.common.stateless_scope import in_stateless_scope\n-from keras.backend.tensorflow.sparse import sparse_to_dense\n-from keras.utils.naming import auto_name\n+from keras.src import tree\n+from keras.src.backend.common import KerasVariable\n+from keras.src.backend.common import global_state\n+from keras.src.backend.common import standardize_dtype\n+from keras.src.backend.common.keras_tensor import KerasTensor\n+from keras.src.backend.common.name_scope import name_scope as base_name_scope\n+from keras.src.backend.common.stateless_scope import StatelessScope\n+from keras.src.backend.common.stateless_scope import in_stateless_scope\n+from keras.src.backend.tensorflow.sparse import sparse_to_dense\n+from keras.src.utils.naming import auto_name\n \n SUPPORTS_SPARSE_TENSORS = True\n \n\n@@ -5,11 +5,11 @@ import pytest\n import tensorflow as tf\n from tensorflow.python.eager import context\n \n-from keras import backend\n-from keras import layers\n-from keras import models\n-from keras import testing\n-from keras.backend.tensorflow import trainer as tf_trainer\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import models\n+from keras.src import testing\n+from keras.src.backend.tensorflow import trainer as tf_trainer\n \n \n @pytest.mark.skipif(\n\n\n@@ -4,7 +4,7 @@ import operator\n \n import tensorflow as tf\n \n-from keras.backend.tensorflow.core import convert_to_tensor\n+from keras.src.backend.tensorflow.core import convert_to_tensor\n \n RESIZE_INTERPOLATIONS = (\n     \"bilinear\",\n\n@@ -1,9 +1,9 @@\n import tensorflow as tf\n \n-from keras import tree\n-from keras.backend.tensorflow.trackable import KerasAutoTrackable\n-from keras.utils import tf_utils\n-from keras.utils import tracking\n+from keras.src import tree\n+from keras.src.backend.tensorflow.trackable import KerasAutoTrackable\n+from keras.src.utils import tf_utils\n+from keras.src.utils import tracking\n \n \n class TFLayer(KerasAutoTrackable):\n@@ -77,9 +77,9 @@ class TFLayer(KerasAutoTrackable):\n     def _default_save_signature(self):\n         \"\"\"For SavedModel support: returns the default serving signature.\"\"\"\n \n-        from keras.models.functional import Functional\n-        from keras.models.model import Model\n-        from keras.models.sequential import Sequential\n+        from keras.src.models.functional import Functional\n+        from keras.src.models.model import Model\n+        from keras.src.models.sequential import Sequential\n \n         if not isinstance(self, Model):\n             return None\n\n@@ -1,11 +1,11 @@\n import tensorflow as tf\n from tensorflow.experimental import numpy as tfnp\n \n-from keras.backend import config\n-from keras.backend import standardize_dtype\n-from keras.backend.common import dtypes\n-from keras.backend.tensorflow.core import cast\n-from keras.backend.tensorflow.core import convert_to_tensor\n+from keras.src.backend import config\n+from keras.src.backend import standardize_dtype\n+from keras.src.backend.common import dtypes\n+from keras.src.backend.tensorflow.core import cast\n+from keras.src.backend.tensorflow.core import convert_to_tensor\n \n \n def cholesky(a):\n\n@@ -1,11 +1,11 @@\n import tensorflow as tf\n from tensorflow.experimental import numpy as tfnp\n \n-from keras.backend import config\n-from keras.backend import standardize_dtype\n-from keras.backend.common import dtypes\n-from keras.backend.tensorflow.core import cast\n-from keras.backend.tensorflow.core import convert_to_tensor\n+from keras.src.backend import config\n+from keras.src.backend import standardize_dtype\n+from keras.src.backend.common import dtypes\n+from keras.src.backend.tensorflow.core import cast\n+from keras.src.backend.tensorflow.core import convert_to_tensor\n \n \n def segment_sum(data, segment_ids, num_segments=None, sorted=False):\n\n@@ -1,7 +1,7 @@\n import tensorflow as tf\n \n-from keras.backend.tensorflow.core import name_scope\n-from keras.testing import TestCase\n+from keras.src.backend.tensorflow.core import name_scope\n+from keras.src.testing import TestCase\n \n \n class TFNameScopeTest(TestCase):\n\n@@ -3,14 +3,14 @@ import warnings\n \n import tensorflow as tf\n \n-from keras.backend import standardize_data_format\n-from keras.backend import standardize_dtype\n-from keras.backend.common.backend_utils import (\n+from keras.src.backend import standardize_data_format\n+from keras.src.backend import standardize_dtype\n+from keras.src.backend.common.backend_utils import (\n     compute_conv_transpose_output_shape,\n )\n-from keras.backend.config import epsilon\n-from keras.backend.tensorflow.core import cast\n-from keras.backend.tensorflow.core import convert_to_tensor\n+from keras.src.backend.config import epsilon\n+from keras.src.backend.tensorflow.core import cast\n+from keras.src.backend.tensorflow.core import convert_to_tensor\n \n \n def relu(x):\n\n@@ -10,15 +10,15 @@ import tensorflow as tf\n from tensorflow.experimental import numpy as tfnp\n from tensorflow.python.ops.linalg.sparse import sparse_csr_matrix_ops\n \n-from keras import tree\n-from keras.backend import config\n-from keras.backend import standardize_dtype\n-from keras.backend.common import dtypes\n-from keras.backend.common.backend_utils import canonicalize_axis\n-from keras.backend.common.backend_utils import to_tuple_or_list\n-from keras.backend.tensorflow import sparse\n-from keras.backend.tensorflow.core import cast\n-from keras.backend.tensorflow.core import convert_to_tensor\n+from keras.src import tree\n+from keras.src.backend import config\n+from keras.src.backend import standardize_dtype\n+from keras.src.backend.common import dtypes\n+from keras.src.backend.common.backend_utils import canonicalize_axis\n+from keras.src.backend.common.backend_utils import to_tuple_or_list\n+from keras.src.backend.tensorflow import sparse\n+from keras.src.backend.tensorflow.core import cast\n+from keras.src.backend.tensorflow.core import convert_to_tensor\n \n \n @sparse.elementwise_binary_union(tf.sparse.add)\n@@ -442,7 +442,7 @@ def matmul(x1, x2):\n         )\n \n     if x1_sparse or x2_sparse:\n-        from keras.ops.operation_utils import compute_matmul_output_shape\n+        from keras.src.ops.operation_utils import compute_matmul_output_shape\n \n         output_shape = compute_matmul_output_shape(x1_shape, x2_shape)\n         if x1_sparse and x2_sparse:\n@@ -1022,7 +1022,9 @@ def expand_dims(x, axis):\n     out_ndim = len(x.shape) + len(axis)\n     axis = sorted([canonicalize_axis(a, out_ndim) for a in axis])\n     if isinstance(x, tf.SparseTensor):\n-        from keras.ops.operation_utils import compute_expand_dims_output_shape\n+        from keras.src.ops.operation_utils import (\n+            compute_expand_dims_output_shape,\n+        )\n \n         output_shape = compute_expand_dims_output_shape(x.shape, axis)\n         for a in axis:\n@@ -1607,7 +1609,7 @@ def repeat(x, repeats, axis=None):\n def reshape(x, newshape):\n     x = convert_to_tensor(x)\n     if isinstance(x, tf.SparseTensor):\n-        from keras.ops.operation_utils import compute_reshape_output_shape\n+        from keras.src.ops.operation_utils import compute_reshape_output_shape\n \n         output_shape = compute_reshape_output_shape(\n             x.shape, newshape, \"newshape\"\n@@ -2011,7 +2013,7 @@ def squeeze(x, axis=None):\n \n def transpose(x, axes=None):\n     if isinstance(x, tf.SparseTensor):\n-        from keras.ops.operation_utils import compute_transpose_output_shape\n+        from keras.src.ops.operation_utils import compute_transpose_output_shape\n \n         output = tf.sparse.transpose(x, perm=axes)\n         output.set_shape(compute_transpose_output_shape(x.shape, axes))\n\n@@ -2,10 +2,10 @@ import warnings\n \n import tensorflow as tf\n \n-from keras import backend\n-from keras.backend.common import KerasVariable\n-from keras.backend.tensorflow.trackable import KerasAutoTrackable\n-from keras.optimizers import base_optimizer\n+from keras.src import backend\n+from keras.src.backend.common import KerasVariable\n+from keras.src.backend.tensorflow.trackable import KerasAutoTrackable\n+from keras.src.optimizers import base_optimizer\n \n \n class TFOptimizer(KerasAutoTrackable, base_optimizer.BaseOptimizer):\n\n@@ -5,9 +5,9 @@ import pytest\n import tensorflow as tf\n from tensorflow.python.eager import context\n \n-from keras import backend\n-from keras import testing\n-from keras.optimizers.sgd import SGD\n+from keras.src import backend\n+from keras.src import testing\n+from keras.src.optimizers.sgd import SGD\n \n \n @pytest.mark.skipif(\n\n@@ -1,11 +1,11 @@\n import tensorflow as tf\n from tensorflow.experimental import numpy as tfnp\n \n-from keras.backend.common import standardize_dtype\n-from keras.backend.config import floatx\n-from keras.random.seed_generator import SeedGenerator\n-from keras.random.seed_generator import draw_seed\n-from keras.random.seed_generator import make_default_seed\n+from keras.src.backend.common import standardize_dtype\n+from keras.src.backend.config import floatx\n+from keras.src.random.seed_generator import SeedGenerator\n+from keras.src.random.seed_generator import draw_seed\n+from keras.src.random.seed_generator import make_default_seed\n \n \n def tf_draw_seed(seed):\n\n@@ -1,6 +1,6 @@\n import tensorflow as tf\n \n-from keras import tree\n+from keras.src import tree\n \n \n def rnn(\n@@ -471,7 +471,7 @@ def gru(\n     if not cudnn_supported:\n         raise NotImplementedError\n \n-    from keras.backend.tensorflow import Variable\n+    from keras.src.backend.tensorflow import Variable\n \n     if isinstance(kernel, Variable):\n         kernel = kernel.value\n@@ -507,8 +507,8 @@ def _do_gru_arguments_support_cudnn(\n     use_bias,\n     reset_after,\n ):\n-    from keras import activations\n-    from keras import ops\n+    from keras.src import activations\n+    from keras.src import ops\n \n     return (\n         activation in (activations.tanh, tf.tanh, ops.tanh)\n@@ -526,8 +526,8 @@ def _do_lstm_arguments_support_cudnn(\n     unroll,\n     use_bias,\n ):\n-    from keras import activations\n-    from keras import ops\n+    from keras.src import activations\n+    from keras.src import ops\n \n     return (\n         activation in (activations.tanh, tf.tanh, ops.tanh)\n@@ -828,7 +828,7 @@ def lstm(\n     if not cudnn_supported:\n         raise NotImplementedError\n \n-    from keras.backend.tensorflow import Variable\n+    from keras.src.backend.tensorflow import Variable\n \n     if isinstance(kernel, Variable):\n         kernel = kernel.value\n\n@@ -6,13 +6,13 @@ import numpy as np\n import pytest\n import tensorflow as tf\n \n-from keras import backend\n-from keras import layers\n-from keras import metrics\n-from keras import models\n-from keras import optimizers\n-from keras import testing\n-from keras.saving import object_registration\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import metrics\n+from keras.src import models\n+from keras.src import optimizers\n+from keras.src import testing\n+from keras.src.saving import object_registration\n \n \n @object_registration.register_keras_serializable(package=\"my_package\")\n\n\n\n@@ -1,6 +1,6 @@\n import tensorflow as tf\n \n-from keras.utils import tracking\n+from keras.src.utils import tracking\n \n \n class KerasAutoTrackable(tf.__internal__.tracking.AutoTrackable):\n\n@@ -5,15 +5,15 @@ import numpy as np\n import tensorflow as tf\n from tensorflow.python.eager import context as tf_context\n \n-from keras import callbacks as callbacks_module\n-from keras import metrics as metrics_module\n-from keras import optimizers as optimizers_module\n-from keras import tree\n-from keras.trainers import trainer as base_trainer\n-from keras.trainers.data_adapters import array_slicing\n-from keras.trainers.data_adapters import data_adapter_utils\n-from keras.trainers.epoch_iterator import EpochIterator\n-from keras.utils import traceback_utils\n+from keras.src import callbacks as callbacks_module\n+from keras.src import metrics as metrics_module\n+from keras.src import optimizers as optimizers_module\n+from keras.src import tree\n+from keras.src.trainers import trainer as base_trainer\n+from keras.src.trainers.data_adapters import array_slicing\n+from keras.src.trainers.data_adapters import data_adapter_utils\n+from keras.src.trainers.epoch_iterator import EpochIterator\n+from keras.src.utils import traceback_utils\n \n \n class TensorFlowTrainer(base_trainer.Trainer):\n\n@@ -2,9 +2,9 @@ import unittest\n \n import pytest\n \n-from keras import backend\n-from keras import ops\n-from keras.backend.common.keras_tensor import KerasTensor\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src.backend.common.keras_tensor import KerasTensor\n \n \n def single_arg_test_fn(x):\n\n@@ -1,7 +1,7 @@\n import pytest\n \n-from keras import backend\n-from keras import testing\n+from keras.src import backend\n+from keras.src import testing\n \n \n class DeviceTest(testing.TestCase):\n\n@@ -0,0 +1,41 @@\n+\"\"\"Torch backend APIs.\n+\n+# Note on device placement\n+\n+Torch has a different device placement style compared to TF and JAX.\n+In short, variables/tensors are not created on GPU by default,\n+and the GPU cannot directly communicate with the CPU.\n+To bring Torch behavior in line with TF and JAX automated device placement,\n+we are doing the following to automate device placement if a GPU is available:\n+\n+- Variables are created on GPU.\n+- Input data will be placed on GPU at the first `keras.layers.Layer` call.\n+- Tensor creation happens on GPU, e.g., `zeros()` will create a tensor on GPU.\n+- `convert_to_numpy` will bring the tensor to CPU before converting it to NumPy.\n+\"\"\"\n+\n+from keras.src.backend.torch import core\n+from keras.src.backend.torch import image\n+from keras.src.backend.torch import linalg\n+from keras.src.backend.torch import math\n+from keras.src.backend.torch import nn\n+from keras.src.backend.torch import numpy\n+from keras.src.backend.torch import random\n+from keras.src.backend.torch.core import SUPPORTS_SPARSE_TENSORS\n+from keras.src.backend.torch.core import Variable\n+from keras.src.backend.torch.core import cast\n+from keras.src.backend.torch.core import compute_output_spec\n+from keras.src.backend.torch.core import cond\n+from keras.src.backend.torch.core import convert_to_numpy\n+from keras.src.backend.torch.core import convert_to_tensor\n+from keras.src.backend.torch.core import device_scope\n+from keras.src.backend.torch.core import is_tensor\n+from keras.src.backend.torch.core import scatter\n+from keras.src.backend.torch.core import shape\n+from keras.src.backend.torch.core import stop_gradient\n+from keras.src.backend.torch.core import to_torch_dtype\n+from keras.src.backend.torch.core import vectorized_map\n+from keras.src.backend.torch.rnn import cudnn_ok\n+from keras.src.backend.torch.rnn import gru\n+from keras.src.backend.torch.rnn import lstm\n+from keras.src.backend.torch.rnn import rnn\n\n@@ -5,14 +5,14 @@ import ml_dtypes\n import numpy as np\n import torch\n \n-from keras import tree\n-from keras.backend.common import KerasVariable\n-from keras.backend.common import global_state\n-from keras.backend.common import standardize_dtype\n-from keras.backend.common.dtypes import result_type\n-from keras.backend.common.keras_tensor import KerasTensor\n-from keras.backend.common.stateless_scope import StatelessScope\n-from keras.backend.config import floatx\n+from keras.src import tree\n+from keras.src.backend.common import KerasVariable\n+from keras.src.backend.common import global_state\n+from keras.src.backend.common import standardize_dtype\n+from keras.src.backend.common.dtypes import result_type\n+from keras.src.backend.common.keras_tensor import KerasTensor\n+from keras.src.backend.common.stateless_scope import StatelessScope\n+from keras.src.backend.config import floatx\n \n SUPPORTS_SPARSE_TENSORS = False\n \n\n@@ -4,7 +4,7 @@ import operator\n \n import torch\n \n-from keras.backend.torch.core import convert_to_tensor\n+from keras.src.backend.torch.core import convert_to_tensor\n \n RESIZE_INTERPOLATIONS = {}  # populated after torchvision import\n \n\n@@ -1,7 +1,7 @@\n import torch\n \n-from keras.backend.common.stateless_scope import in_stateless_scope\n-from keras.ops.operation import Operation\n+from keras.src.backend.common.stateless_scope import in_stateless_scope\n+from keras.src.ops.operation import Operation\n \n \n class TorchLayer(torch.nn.Module):\n@@ -27,14 +27,14 @@ class TorchLayer(torch.nn.Module):\n         return Operation.__call__(self, *args, **kwargs)\n \n     def _setattr_hook(self, name, value):\n-        from keras.layers import Layer\n+        from keras.src.layers import Layer\n \n         if (\n             isinstance(value, torch.nn.Module)\n             and not isinstance(value, Layer)\n             and not name == \"torch_params\"\n         ):\n-            from keras.utils.torch_utils import TorchModuleWrapper\n+            from keras.src.utils.torch_utils import TorchModuleWrapper\n \n             if not isinstance(self, TorchModuleWrapper):\n                 value = TorchModuleWrapper(value)\n\n@@ -1,10 +1,10 @@\n import torch\n \n-from keras.backend import config\n-from keras.backend import standardize_dtype\n-from keras.backend.common import dtypes\n-from keras.backend.torch.core import cast\n-from keras.backend.torch.core import convert_to_tensor\n+from keras.src.backend import config\n+from keras.src.backend import standardize_dtype\n+from keras.src.backend.common import dtypes\n+from keras.src.backend.torch.core import cast\n+from keras.src.backend.torch.core import convert_to_tensor\n \n \n def cholesky(x):\n\n@@ -2,13 +2,13 @@ import math\n \n import torch\n \n-from keras.backend import config\n-from keras.backend import standardize_dtype\n-from keras.backend.common import dtypes\n-from keras.backend.torch.core import cast\n-from keras.backend.torch.core import convert_to_tensor\n-from keras.backend.torch.core import get_device\n-from keras.backend.torch.numpy import pad\n+from keras.src.backend import config\n+from keras.src.backend import standardize_dtype\n+from keras.src.backend.common import dtypes\n+from keras.src.backend.torch.core import cast\n+from keras.src.backend.torch.core import convert_to_tensor\n+from keras.src.backend.torch.core import get_device\n+from keras.src.backend.torch.numpy import pad\n \n \n def segment_sum(data, segment_ids, num_segments=None, **kwargs):\n\n@@ -1,20 +1,20 @@\n import torch\n import torch.nn.functional as tnn\n \n-from keras import tree\n-from keras.backend import standardize_data_format\n-from keras.backend import standardize_dtype\n-from keras.backend.common.backend_utils import (\n+from keras.src import tree\n+from keras.src.backend import standardize_data_format\n+from keras.src.backend import standardize_dtype\n+from keras.src.backend.common.backend_utils import (\n     compute_conv_transpose_padding_args_for_torch,\n )\n-from keras.backend.config import epsilon\n-from keras.backend.torch.core import cast\n-from keras.backend.torch.core import convert_to_tensor\n-from keras.backend.torch.core import get_device\n-from keras.backend.torch.numpy import expand_dims\n-from keras.backend.torch.numpy import maximum\n-from keras.backend.torch.numpy import where\n-from keras.utils.argument_validation import standardize_tuple\n+from keras.src.backend.config import epsilon\n+from keras.src.backend.torch.core import cast\n+from keras.src.backend.torch.core import convert_to_tensor\n+from keras.src.backend.torch.core import get_device\n+from keras.src.backend.torch.numpy import expand_dims\n+from keras.src.backend.torch.numpy import maximum\n+from keras.src.backend.torch.numpy import where\n+from keras.src.utils.argument_validation import standardize_tuple\n \n \n def relu(x):\n\n@@ -3,17 +3,17 @@ import math\n \n import torch\n \n-from keras.backend import KerasTensor\n-from keras.backend import config\n-from keras.backend.common import dtypes\n-from keras.backend.common.backend_utils import canonicalize_axis\n-from keras.backend.common.backend_utils import to_tuple_or_list\n-from keras.backend.common.variables import standardize_dtype\n-from keras.backend.torch.core import cast\n-from keras.backend.torch.core import convert_to_tensor\n-from keras.backend.torch.core import get_device\n-from keras.backend.torch.core import is_tensor\n-from keras.backend.torch.core import to_torch_dtype\n+from keras.src.backend import KerasTensor\n+from keras.src.backend import config\n+from keras.src.backend.common import dtypes\n+from keras.src.backend.common.backend_utils import canonicalize_axis\n+from keras.src.backend.common.backend_utils import to_tuple_or_list\n+from keras.src.backend.common.variables import standardize_dtype\n+from keras.src.backend.torch.core import cast\n+from keras.src.backend.torch.core import convert_to_tensor\n+from keras.src.backend.torch.core import get_device\n+from keras.src.backend.torch.core import is_tensor\n+from keras.src.backend.torch.core import to_torch_dtype\n \n TORCH_INT_TYPES = (\n     torch.int8,\n\n@@ -0,0 +1 @@\n+from keras.src.backend.torch.optimizers.torch_optimizer import TorchOptimizer\n\n@@ -1,8 +1,8 @@\n import torch\n \n-from keras import ops\n-from keras import optimizers\n-from keras.backend.torch.optimizers import torch_parallel_optimizer\n+from keras.src import ops\n+from keras.src import optimizers\n+from keras.src.backend.torch.optimizers import torch_parallel_optimizer\n \n \n class Adadelta(\n\n@@ -1,8 +1,8 @@\n import torch\n \n-from keras import ops\n-from keras import optimizers\n-from keras.backend.torch.optimizers import torch_parallel_optimizer\n+from keras.src import ops\n+from keras.src import optimizers\n+from keras.src.backend.torch.optimizers import torch_parallel_optimizer\n \n \n class Adagrad(\n\n@@ -1,8 +1,8 @@\n import torch\n \n-from keras import ops\n-from keras import optimizers\n-from keras.backend.torch.optimizers import torch_parallel_optimizer\n+from keras.src import ops\n+from keras.src import optimizers\n+from keras.src.backend.torch.optimizers import torch_parallel_optimizer\n \n \n class Adam(torch_parallel_optimizer.TorchParallelOptimizer, optimizers.Adam):\n\n@@ -1,8 +1,8 @@\n import torch\n \n-from keras import ops\n-from keras import optimizers\n-from keras.backend.torch.optimizers import torch_parallel_optimizer\n+from keras.src import ops\n+from keras.src import optimizers\n+from keras.src.backend.torch.optimizers import torch_parallel_optimizer\n \n \n class Adamax(\n\n@@ -0,0 +1,6 @@\n+from keras.src import optimizers\n+from keras.src.backend.torch.optimizers import torch_adam\n+\n+\n+class AdamW(torch_adam.Adam, optimizers.AdamW):\n+    pass\n\n@@ -1,8 +1,8 @@\n import torch\n \n-from keras import ops\n-from keras import optimizers\n-from keras.backend.torch.optimizers import torch_parallel_optimizer\n+from keras.src import ops\n+from keras.src import optimizers\n+from keras.src.backend.torch.optimizers import torch_parallel_optimizer\n \n \n class Lion(torch_parallel_optimizer.TorchParallelOptimizer, optimizers.Lion):\n\n@@ -1,9 +1,9 @@\n import torch\n \n-from keras import ops\n-from keras import optimizers\n-from keras.backend.torch import core\n-from keras.backend.torch.optimizers import torch_parallel_optimizer\n+from keras.src import ops\n+from keras.src import optimizers\n+from keras.src.backend.torch import core\n+from keras.src.backend.torch.optimizers import torch_parallel_optimizer\n \n \n class Nadam(torch_parallel_optimizer.TorchParallelOptimizer, optimizers.Nadam):\n\n@@ -1,22 +1,22 @@\n import torch\n \n-from keras import optimizers\n-from keras.optimizers.base_optimizer import BaseOptimizer\n-from keras.utils import torch_utils\n+from keras.src import optimizers\n+from keras.src.optimizers.base_optimizer import BaseOptimizer\n+from keras.src.utils import torch_utils\n \n \n class TorchOptimizer(BaseOptimizer):\n     def __new__(cls, *args, **kwargs):\n         # Import locally to avoid circular imports.\n-        from keras.backend.torch.optimizers import torch_adadelta\n-        from keras.backend.torch.optimizers import torch_adagrad\n-        from keras.backend.torch.optimizers import torch_adam\n-        from keras.backend.torch.optimizers import torch_adamax\n-        from keras.backend.torch.optimizers import torch_adamw\n-        from keras.backend.torch.optimizers import torch_lion\n-        from keras.backend.torch.optimizers import torch_nadam\n-        from keras.backend.torch.optimizers import torch_rmsprop\n-        from keras.backend.torch.optimizers import torch_sgd\n+        from keras.src.backend.torch.optimizers import torch_adadelta\n+        from keras.src.backend.torch.optimizers import torch_adagrad\n+        from keras.src.backend.torch.optimizers import torch_adam\n+        from keras.src.backend.torch.optimizers import torch_adamax\n+        from keras.src.backend.torch.optimizers import torch_adamw\n+        from keras.src.backend.torch.optimizers import torch_lion\n+        from keras.src.backend.torch.optimizers import torch_nadam\n+        from keras.src.backend.torch.optimizers import torch_rmsprop\n+        from keras.src.backend.torch.optimizers import torch_sgd\n \n         OPTIMIZERS = {\n             optimizers.Adadelta: torch_adadelta.Adadelta,\n\n@@ -1,7 +1,7 @@\n import torch\n \n-from keras.optimizers.base_optimizer import BaseOptimizer\n-from keras.utils import torch_utils\n+from keras.src.optimizers.base_optimizer import BaseOptimizer\n+from keras.src.utils import torch_utils\n \n \n class TorchParallelOptimizer(BaseOptimizer):\n\n@@ -1,8 +1,8 @@\n import torch\n \n-from keras import ops\n-from keras import optimizers\n-from keras.backend.torch.optimizers import torch_parallel_optimizer\n+from keras.src import ops\n+from keras.src import optimizers\n+from keras.src.backend.torch.optimizers import torch_parallel_optimizer\n \n \n class RMSprop(\n\n@@ -1,7 +1,7 @@\n import torch\n \n-from keras import optimizers\n-from keras.backend.torch.optimizers import torch_parallel_optimizer\n+from keras.src import optimizers\n+from keras.src.backend.torch.optimizers import torch_parallel_optimizer\n \n \n class SGD(torch_parallel_optimizer.TorchParallelOptimizer, optimizers.SGD):\n\n@@ -2,13 +2,13 @@ import torch\n import torch._dynamo as dynamo\n import torch.nn.functional as tnn\n \n-from keras.backend.config import floatx\n-from keras.backend.torch.core import convert_to_tensor\n-from keras.backend.torch.core import get_device\n-from keras.backend.torch.core import to_torch_dtype\n-from keras.random.seed_generator import SeedGenerator\n-from keras.random.seed_generator import draw_seed\n-from keras.random.seed_generator import make_default_seed\n+from keras.src.backend.config import floatx\n+from keras.src.backend.torch.core import convert_to_tensor\n+from keras.src.backend.torch.core import get_device\n+from keras.src.backend.torch.core import to_torch_dtype\n+from keras.src.random.seed_generator import SeedGenerator\n+from keras.src.random.seed_generator import draw_seed\n+from keras.src.random.seed_generator import make_default_seed\n \n \n # torch.Generator not supported with dynamo\n\n@@ -1,7 +1,7 @@\n import torch\n \n-from keras import tree\n-from keras.backend.torch.core import convert_to_tensor\n+from keras.src import tree\n+from keras.src.backend.torch.core import convert_to_tensor\n \n \n def rnn(\n\n@@ -4,15 +4,15 @@ import numpy as np\n import torch\n from packaging.version import parse\n \n-from keras import backend\n-from keras import callbacks as callbacks_module\n-from keras import optimizers as optimizers_module\n-from keras import tree\n-from keras.trainers import trainer as base_trainer\n-from keras.trainers.data_adapters import array_slicing\n-from keras.trainers.data_adapters import data_adapter_utils\n-from keras.trainers.epoch_iterator import EpochIterator\n-from keras.utils import traceback_utils\n+from keras.src import backend\n+from keras.src import callbacks as callbacks_module\n+from keras.src import optimizers as optimizers_module\n+from keras.src import tree\n+from keras.src.trainers import trainer as base_trainer\n+from keras.src.trainers.data_adapters import array_slicing\n+from keras.src.trainers.data_adapters import data_adapter_utils\n+from keras.src.trainers.epoch_iterator import EpochIterator\n+from keras.src.utils import traceback_utils\n \n \n class TorchTrainer(base_trainer.Trainer):\n\n@@ -0,0 +1,15 @@\n+from keras.src.callbacks.backup_and_restore import BackupAndRestore\n+from keras.src.callbacks.callback import Callback\n+from keras.src.callbacks.callback_list import CallbackList\n+from keras.src.callbacks.csv_logger import CSVLogger\n+from keras.src.callbacks.early_stopping import EarlyStopping\n+from keras.src.callbacks.history import History\n+from keras.src.callbacks.lambda_callback import LambdaCallback\n+from keras.src.callbacks.learning_rate_scheduler import LearningRateScheduler\n+from keras.src.callbacks.model_checkpoint import ModelCheckpoint\n+from keras.src.callbacks.progbar_logger import ProgbarLogger\n+from keras.src.callbacks.reduce_lr_on_plateau import ReduceLROnPlateau\n+from keras.src.callbacks.remote_monitor import RemoteMonitor\n+from keras.src.callbacks.swap_ema_weights import SwapEMAWeights\n+from keras.src.callbacks.tensorboard import TensorBoard\n+from keras.src.callbacks.terminate_on_nan import TerminateOnNaN\n\n@@ -1,8 +1,8 @@\n import json\n \n-from keras.api_export import keras_export\n-from keras.callbacks.callback import Callback\n-from keras.utils import file_utils\n+from keras.src.api_export import keras_export\n+from keras.src.callbacks.callback import Callback\n+from keras.src.utils import file_utils\n \n \n @keras_export(\"keras.callbacks.BackupAndRestore\")\n\n@@ -1,11 +1,11 @@\n import numpy as np\n import pytest\n \n-from keras import callbacks\n-from keras import layers\n-from keras import testing\n-from keras.models import Sequential\n-from keras.utils import file_utils\n+from keras.src import callbacks\n+from keras.src import layers\n+from keras.src import testing\n+from keras.src.models import Sequential\n+from keras.src.utils import file_utils\n \n \n class InterruptingCallback(callbacks.Callback):\n\n@@ -1,5 +1,5 @@\n-from keras import backend\n-from keras.api_export import keras_export\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n \n \n @keras_export(\"keras.callbacks.Callback\")\n\n@@ -1,8 +1,8 @@\n-from keras import tree\n-from keras.api_export import keras_export\n-from keras.callbacks.callback import Callback\n-from keras.callbacks.history import History\n-from keras.callbacks.progbar_logger import ProgbarLogger\n+from keras.src import tree\n+from keras.src.api_export import keras_export\n+from keras.src.callbacks.callback import Callback\n+from keras.src.callbacks.history import History\n+from keras.src.callbacks.progbar_logger import ProgbarLogger\n \n \n @keras_export(\"keras.callbacks.CallbackList\")\n\n@@ -1,9 +1,9 @@\n import numpy as np\n import pytest\n \n-from keras import models\n-from keras import testing\n-from keras.callbacks.callback import Callback\n+from keras.src import models\n+from keras.src import testing\n+from keras.src.callbacks.callback import Callback\n \n \n class CallbackTest(testing.TestCase):\n\n@@ -3,9 +3,9 @@ import csv\n \n import numpy as np\n \n-from keras.api_export import keras_export\n-from keras.callbacks.callback import Callback\n-from keras.utils import file_utils\n+from keras.src.api_export import keras_export\n+from keras.src.callbacks.callback import Callback\n+from keras.src.utils import file_utils\n \n \n @keras_export(\"keras.callbacks.CSVLogger\")\n\n@@ -6,12 +6,12 @@ import tempfile\n import numpy as np\n import pytest\n \n-from keras import callbacks\n-from keras import initializers\n-from keras import layers\n-from keras import testing\n-from keras.models import Sequential\n-from keras.utils import numerical_utils\n+from keras.src import callbacks\n+from keras.src import initializers\n+from keras.src import layers\n+from keras.src import testing\n+from keras.src.models import Sequential\n+from keras.src.utils import numerical_utils\n \n TRAIN_SAMPLES = 10\n TEST_SAMPLES = 10\n\n@@ -1,10 +1,10 @@\n import warnings\n \n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.callbacks.callback import Callback\n-from keras.trainers import compile_utils\n-from keras.utils import io_utils\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.callbacks.callback import Callback\n+from keras.src.trainers import compile_utils\n+from keras.src.utils import io_utils\n \n \n @keras_export(\"keras.callbacks.EarlyStopping\")\n\n@@ -1,12 +1,12 @@\n import numpy as np\n import pytest\n \n-from keras import callbacks\n-from keras import layers\n-from keras import metrics\n-from keras import models\n-from keras import ops\n-from keras import testing\n+from keras.src import callbacks\n+from keras.src import layers\n+from keras.src import metrics\n+from keras.src import models\n+from keras.src import ops\n+from keras.src import testing\n \n \n class EarlyStoppingTest(testing.TestCase):\n\n@@ -1,5 +1,5 @@\n-from keras.api_export import keras_export\n-from keras.callbacks.callback import Callback\n+from keras.src.api_export import keras_export\n+from keras.src.callbacks.callback import Callback\n \n \n @keras_export(\"keras.callbacks.History\")\n\n@@ -1,5 +1,5 @@\n-from keras.api_export import keras_export\n-from keras.callbacks.callback import Callback\n+from keras.src.api_export import keras_export\n+from keras.src.callbacks.callback import Callback\n \n \n @keras_export(\"keras.callbacks.LambdaCallback\")\n\n@@ -2,12 +2,12 @@ import numpy as np\n import pytest\n from absl import logging\n \n-from keras import callbacks\n-from keras import layers\n-from keras import losses\n-from keras import optimizers\n-from keras import testing\n-from keras.models.sequential import Sequential\n+from keras.src import callbacks\n+from keras.src import layers\n+from keras.src import losses\n+from keras.src import optimizers\n+from keras.src import testing\n+from keras.src.models.sequential import Sequential\n \n \n class LambdaCallbackTest(testing.TestCase):\n\n@@ -1,9 +1,9 @@\n import numpy as np\n \n-from keras import backend\n-from keras.api_export import keras_export\n-from keras.callbacks.callback import Callback\n-from keras.utils import io_utils\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.callbacks.callback import Callback\n+from keras.src.utils import io_utils\n \n \n @keras_export(\"keras.callbacks.LearningRateScheduler\")\n\n@@ -1,13 +1,13 @@\n import pytest\n \n-from keras import callbacks\n-from keras import layers\n-from keras import optimizers\n-from keras import testing\n-from keras.models import Sequential\n-from keras.testing import test_utils\n-from keras.utils import io_utils\n-from keras.utils import numerical_utils\n+from keras.src import callbacks\n+from keras.src import layers\n+from keras.src import optimizers\n+from keras.src import testing\n+from keras.src.models import Sequential\n+from keras.src.testing import test_utils\n+from keras.src.utils import io_utils\n+from keras.src.utils import numerical_utils\n \n \n class LearningRateSchedulerTest(testing.TestCase):\n\n@@ -4,11 +4,11 @@ import warnings\n \n import numpy as np\n \n-from keras import backend\n-from keras.api_export import keras_export\n-from keras.callbacks.callback import Callback\n-from keras.utils import file_utils\n-from keras.utils import io_utils\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.callbacks.callback import Callback\n+from keras.src.utils import file_utils\n+from keras.src.utils import io_utils\n \n \n @keras_export(\"keras.callbacks.ModelCheckpoint\")\n\n@@ -3,15 +3,15 @@ import warnings\n \n import pytest\n \n-from keras import callbacks\n-from keras import layers\n-from keras import metrics\n-from keras import models\n-from keras import saving\n-from keras import testing\n-from keras.models import Sequential\n-from keras.testing import test_utils\n-from keras.utils import numerical_utils\n+from keras.src import callbacks\n+from keras.src import layers\n+from keras.src import metrics\n+from keras.src import models\n+from keras.src import saving\n+from keras.src import testing\n+from keras.src.models import Sequential\n+from keras.src.testing import test_utils\n+from keras.src.utils import numerical_utils\n \n try:\n     import h5py\n\n@@ -1,7 +1,7 @@\n-from keras.api_export import keras_export\n-from keras.callbacks.callback import Callback\n-from keras.utils import io_utils\n-from keras.utils.progbar import Progbar\n+from keras.src.api_export import keras_export\n+from keras.src.callbacks.callback import Callback\n+from keras.src.utils import io_utils\n+from keras.src.utils.progbar import Progbar\n \n \n @keras_export(\"keras.callbacks.ProgbarLogger\")\n\n@@ -2,10 +2,10 @@ import warnings\n \n import numpy as np\n \n-from keras import backend\n-from keras.api_export import keras_export\n-from keras.callbacks.callback import Callback\n-from keras.utils import io_utils\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.callbacks.callback import Callback\n+from keras.src.utils import io_utils\n \n \n @keras_export(\"keras.callbacks.ReduceLROnPlateau\")\n\n@@ -1,13 +1,13 @@\n import pytest\n \n-from keras import callbacks\n-from keras import layers\n-from keras import optimizers\n-from keras import testing\n-from keras.models import Sequential\n-from keras.testing import test_utils\n-from keras.utils import io_utils\n-from keras.utils import numerical_utils\n+from keras.src import callbacks\n+from keras.src import layers\n+from keras.src import optimizers\n+from keras.src import testing\n+from keras.src.models import Sequential\n+from keras.src.testing import test_utils\n+from keras.src.utils import io_utils\n+from keras.src.utils import numerical_utils\n \n \n class ReduceLROnPlateauTest(testing.TestCase):\n\n@@ -3,8 +3,8 @@ import warnings\n \n import numpy as np\n \n-from keras.api_export import keras_export\n-from keras.callbacks.callback import Callback\n+from keras.src.api_export import keras_export\n+from keras.src.callbacks.callback import Callback\n \n try:\n     import requests\n\n@@ -3,12 +3,12 @@ from unittest import mock\n \n import numpy as np\n \n-from keras import backend\n-from keras import callbacks\n-from keras import layers\n-from keras import testing\n-from keras.models import Sequential\n-from keras.utils import numerical_utils\n+from keras.src import backend\n+from keras.src import callbacks\n+from keras.src import layers\n+from keras.src import testing\n+from keras.src.models import Sequential\n+from keras.src.utils import numerical_utils\n \n try:\n     import requests\n\n@@ -1,7 +1,7 @@\n-from keras import backend\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.callbacks.callback import Callback\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.callbacks.callback import Callback\n \n \n @keras_export(\"keras.callbacks.SwapEMAWeights\")\n\n@@ -4,17 +4,17 @@ import pytest\n import tensorflow as tf\n from tensorflow.python.eager import context\n \n-from keras import backend\n-from keras import callbacks\n-from keras import layers\n-from keras import losses\n-from keras import metrics\n-from keras import optimizers\n-from keras import saving\n-from keras import testing\n-from keras.models import Sequential\n-from keras.testing import test_utils\n-from keras.utils import numerical_utils\n+from keras.src import backend\n+from keras.src import callbacks\n+from keras.src import layers\n+from keras.src import losses\n+from keras.src import metrics\n+from keras.src import optimizers\n+from keras.src import saving\n+from keras.src import testing\n+from keras.src.models import Sequential\n+from keras.src.testing import test_utils\n+from keras.src.utils import numerical_utils\n \n \n class SwapEMAWeightsTest(testing.TestCase):\n\n@@ -4,14 +4,14 @@ import sys\n import time\n import warnings\n \n-from keras import backend\n-from keras import ops\n-from keras import tree\n-from keras.api_export import keras_export\n-from keras.callbacks.callback import Callback\n-from keras.layers import Embedding\n-from keras.optimizers import Optimizer\n-from keras.utils import file_utils\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src import tree\n+from keras.src.api_export import keras_export\n+from keras.src.callbacks.callback import Callback\n+from keras.src.layers import Embedding\n+from keras.src.optimizers import Optimizer\n+from keras.src.utils import file_utils\n \n \n @keras_export(\"keras.callbacks.TensorBoard\")\n\n@@ -9,15 +9,15 @@ from tensorflow.compat.v1 import SummaryMetadata\n from tensorflow.core.util import event_pb2\n from tensorflow.python.lib.io import tf_record\n \n-from keras import backend\n-from keras import callbacks\n-from keras import layers\n-from keras import losses\n-from keras import models\n-from keras import ops\n-from keras import optimizers\n-from keras import testing\n-from keras.optimizers import schedules\n+from keras.src import backend\n+from keras.src import callbacks\n+from keras.src import layers\n+from keras.src import losses\n+from keras.src import models\n+from keras.src import ops\n+from keras.src import optimizers\n+from keras.src import testing\n+from keras.src.optimizers import schedules\n \n # Note: this file and tensorboard in general has a dependency on tensorflow\n \n\n@@ -1,8 +1,8 @@\n import numpy as np\n \n-from keras.api_export import keras_export\n-from keras.callbacks.callback import Callback\n-from keras.utils import io_utils\n+from keras.src.api_export import keras_export\n+from keras.src.callbacks.callback import Callback\n+from keras.src.utils import io_utils\n \n \n @keras_export(\"keras.callbacks.TerminateOnNaN\")\n\n@@ -1,12 +1,12 @@\n import numpy as np\n import pytest\n \n-from keras import callbacks\n-from keras import initializers\n-from keras import layers\n-from keras import testing\n-from keras.models import Sequential\n-from keras.utils import numerical_utils\n+from keras.src import callbacks\n+from keras.src import initializers\n+from keras.src import layers\n+from keras.src import testing\n+from keras.src.models import Sequential\n+from keras.src.utils import numerical_utils\n \n \n class TerminateOnNaNTest(testing.TestCase):\n\n@@ -1,13 +1,13 @@\n import inspect\n \n-from keras.api_export import keras_export\n-from keras.constraints.constraints import Constraint\n-from keras.constraints.constraints import MaxNorm\n-from keras.constraints.constraints import MinMaxNorm\n-from keras.constraints.constraints import NonNeg\n-from keras.constraints.constraints import UnitNorm\n-from keras.saving import serialization_lib\n-from keras.utils.naming import to_snake_case\n+from keras.src.api_export import keras_export\n+from keras.src.constraints.constraints import Constraint\n+from keras.src.constraints.constraints import MaxNorm\n+from keras.src.constraints.constraints import MinMaxNorm\n+from keras.src.constraints.constraints import NonNeg\n+from keras.src.constraints.constraints import UnitNorm\n+from keras.src.saving import serialization_lib\n+from keras.src.utils.naming import to_snake_case\n \n ALL_OBJECTS = {\n     Constraint,\n\n@@ -1,6 +1,6 @@\n-from keras import backend\n-from keras import ops\n-from keras.api_export import keras_export\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n \n \n @keras_export(\"keras.constraints.Constraint\")\n\n@@ -1,8 +1,8 @@\n import numpy as np\n \n-from keras import backend\n-from keras import constraints\n-from keras import testing\n+from keras.src import backend\n+from keras.src import constraints\n+from keras.src import testing\n \n \n def get_example_array():\n\n@@ -0,0 +1,10 @@\n+\"\"\"Small NumPy datasets for debugging/testing.\"\"\"\n+\n+from keras.src.datasets import boston_housing\n+from keras.src.datasets import california_housing\n+from keras.src.datasets import cifar10\n+from keras.src.datasets import cifar100\n+from keras.src.datasets import fashion_mnist\n+from keras.src.datasets import imdb\n+from keras.src.datasets import mnist\n+from keras.src.datasets import reuters\n\n@@ -1,7 +1,7 @@\n import numpy as np\n \n-from keras.api_export import keras_export\n-from keras.utils.file_utils import get_file\n+from keras.src.api_export import keras_export\n+from keras.src.utils.file_utils import get_file\n \n \n @keras_export(\"keras.datasets.boston_housing.load_data\")\n\n@@ -2,8 +2,8 @@\n \n import numpy as np\n \n-from keras.api_export import keras_export\n-from keras.utils.file_utils import get_file\n+from keras.src.api_export import keras_export\n+from keras.src.utils.file_utils import get_file\n \n \n @keras_export(\"keras.datasets.california_housing.load_data\")\n\n\n@@ -4,10 +4,10 @@ import os\n \n import numpy as np\n \n-from keras import backend\n-from keras.api_export import keras_export\n-from keras.datasets.cifar import load_batch\n-from keras.utils.file_utils import get_file\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.datasets.cifar import load_batch\n+from keras.src.utils.file_utils import get_file\n \n \n @keras_export(\"keras.datasets.cifar10.load_data\")\n\n@@ -4,10 +4,10 @@ import os\n \n import numpy as np\n \n-from keras import backend\n-from keras.api_export import keras_export\n-from keras.datasets.cifar import load_batch\n-from keras.utils.file_utils import get_file\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.datasets.cifar import load_batch\n+from keras.src.utils.file_utils import get_file\n \n \n @keras_export(\"keras.datasets.cifar100.load_data\")\n\n@@ -5,8 +5,8 @@ import os\n \n import numpy as np\n \n-from keras.api_export import keras_export\n-from keras.utils.file_utils import get_file\n+from keras.src.api_export import keras_export\n+from keras.src.utils.file_utils import get_file\n \n \n @keras_export(\"keras.datasets.fashion_mnist.load_data\")\n\n@@ -4,9 +4,9 @@ import json\n \n import numpy as np\n \n-from keras.api_export import keras_export\n-from keras.utils.file_utils import get_file\n-from keras.utils.python_utils import remove_long_seq\n+from keras.src.api_export import keras_export\n+from keras.src.utils.file_utils import get_file\n+from keras.src.utils.python_utils import remove_long_seq\n \n \n @keras_export(\"keras.datasets.imdb.load_data\")\n\n@@ -2,8 +2,8 @@\n \n import numpy as np\n \n-from keras.api_export import keras_export\n-from keras.utils.file_utils import get_file\n+from keras.src.api_export import keras_export\n+from keras.src.utils.file_utils import get_file\n \n \n @keras_export(\"keras.datasets.mnist.load_data\")\n\n@@ -4,9 +4,9 @@ import json\n \n import numpy as np\n \n-from keras.api_export import keras_export\n-from keras.utils.file_utils import get_file\n-from keras.utils.python_utils import remove_long_seq\n+from keras.src.api_export import keras_export\n+from keras.src.utils.file_utils import get_file\n+from keras.src.utils.python_utils import remove_long_seq\n \n \n @keras_export(\"keras.datasets.reuters.load_data\")\n\n@@ -0,0 +1,11 @@\n+from keras.src.distribution.distribution_lib import DataParallel\n+from keras.src.distribution.distribution_lib import DeviceMesh\n+from keras.src.distribution.distribution_lib import Distribution\n+from keras.src.distribution.distribution_lib import LayoutMap\n+from keras.src.distribution.distribution_lib import ModelParallel\n+from keras.src.distribution.distribution_lib import TensorLayout\n+from keras.src.distribution.distribution_lib import distribute_tensor\n+from keras.src.distribution.distribution_lib import distribution\n+from keras.src.distribution.distribution_lib import initialize\n+from keras.src.distribution.distribution_lib import list_devices\n+from keras.src.distribution.distribution_lib import set_distribution\n\n@@ -14,10 +14,10 @@ import warnings\n \n import numpy as np\n \n-from keras.api_export import keras_export\n-from keras.backend import KerasTensor\n-from keras.backend import distribution_lib\n-from keras.backend.common import global_state\n+from keras.src.api_export import keras_export\n+from keras.src.backend import KerasTensor\n+from keras.src.backend import distribution_lib\n+from keras.src.backend.common import global_state\n \n DEFAULT_BATCH_DIM_NAME = \"batch\"\n GLOBAL_ATTRIBUTE_NAME = \"distribution\"\n@@ -452,7 +452,7 @@ class DataParallel(Distribution):\n             distribute as tf_data_distribute,\n         )\n \n-        from keras.utils.module_utils import tensorflow as tf\n+        from keras.src.utils.module_utils import tensorflow as tf\n \n         if not isinstance(dataset, tf.data.Dataset):\n             raise ValueError(\n@@ -594,7 +594,7 @@ class ModelParallel(Distribution):\n             distribute as tf_data_distribute,\n         )\n \n-        from keras.utils.module_utils import tensorflow as tf\n+        from keras.src.utils.module_utils import tensorflow as tf\n \n         if not isinstance(dataset, tf.data.Dataset):\n             raise ValueError(\n\n@@ -7,10 +7,10 @@ import numpy as np\n import pytest\n import tensorflow as tf\n \n-from keras import backend\n-from keras import testing\n-from keras.backend import distribution_lib as backend_dlib\n-from keras.distribution import distribution_lib\n+from keras.src import backend\n+from keras.src import testing\n+from keras.src.backend import distribution_lib as backend_dlib\n+from keras.src.distribution import distribution_lib\n \n \n @pytest.mark.skipif(\n\n@@ -1,16 +1,16 @@\n-from keras import backend\n-from keras.dtype_policies import dtype_policy\n-from keras.dtype_policies.dtype_policy import QUANTIZATION_MODES\n-from keras.dtype_policies.dtype_policy import FloatDTypePolicy\n-from keras.dtype_policies.dtype_policy import QuantizedDTypePolicy\n-from keras.dtype_policies.dtype_policy import QuantizedFloat8DTypePolicy\n+from keras.src import backend\n+from keras.src.dtype_policies import dtype_policy\n+from keras.src.dtype_policies.dtype_policy import QUANTIZATION_MODES\n+from keras.src.dtype_policies.dtype_policy import FloatDTypePolicy\n+from keras.src.dtype_policies.dtype_policy import QuantizedDTypePolicy\n+from keras.src.dtype_policies.dtype_policy import QuantizedFloat8DTypePolicy\n \n \n def get(identifier):\n-    from keras.dtype_policies.dtype_policy import (\n+    from keras.src.dtype_policies.dtype_policy import (\n         _get_quantized_dtype_policy_by_str,\n     )\n-    from keras.saving import serialization_lib\n+    from keras.src.saving import serialization_lib\n \n     if identifier is None:\n         return dtype_policy.dtype_policy()\n\n@@ -1,7 +1,7 @@\n-from keras import backend\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.backend.common import global_state\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.backend.common import global_state\n \n QUANTIZATION_MODES = (\"int8\", \"float8\")\n \n\n@@ -1,12 +1,12 @@\n from absl.testing import parameterized\n \n-from keras.dtype_policies.dtype_policy import DTypePolicy\n-from keras.dtype_policies.dtype_policy import FloatDTypePolicy\n-from keras.dtype_policies.dtype_policy import QuantizedDTypePolicy\n-from keras.dtype_policies.dtype_policy import QuantizedFloat8DTypePolicy\n-from keras.dtype_policies.dtype_policy import dtype_policy\n-from keras.dtype_policies.dtype_policy import set_dtype_policy\n-from keras.testing import test_case\n+from keras.src.dtype_policies.dtype_policy import DTypePolicy\n+from keras.src.dtype_policies.dtype_policy import FloatDTypePolicy\n+from keras.src.dtype_policies.dtype_policy import QuantizedDTypePolicy\n+from keras.src.dtype_policies.dtype_policy import QuantizedFloat8DTypePolicy\n+from keras.src.dtype_policies.dtype_policy import dtype_policy\n+from keras.src.dtype_policies.dtype_policy import set_dtype_policy\n+from keras.src.testing import test_case\n \n \n class DTypePolicyTest(test_case.TestCase):\n@@ -293,7 +293,7 @@ class QuantizedDTypePolicyTest(test_case.TestCase, parameterized.TestCase):\n         (\"float8_from_mixed_bfloat16\", \"float8_from_mixed_bfloat16\"),\n     )\n     def test_get_quantized_dtype_policy_by_str(self, name):\n-        from keras.dtype_policies.dtype_policy import (\n+        from keras.src.dtype_policies.dtype_policy import (\n             _get_quantized_dtype_policy_by_str,\n         )\n \n@@ -301,7 +301,7 @@ class QuantizedDTypePolicyTest(test_case.TestCase, parameterized.TestCase):\n         self.assertEqual(policy.name, name)\n \n     def test_invalid_get_quantized_dtype_policy_by_str(self):\n-        from keras.dtype_policies.dtype_policy import (\n+        from keras.src.dtype_policies.dtype_policy import (\n             _get_quantized_dtype_policy_by_str,\n         )\n \n\n@@ -0,0 +1 @@\n+from keras.src.export.export_lib import ExportArchive\n\n@@ -6,15 +6,15 @@ import string\n \n from absl import logging\n \n-from keras import backend\n-from keras import tree\n-from keras.api_export import keras_export\n-from keras.backend.common.stateless_scope import StatelessScope\n-from keras.layers import Layer\n-from keras.models import Functional\n-from keras.models import Sequential\n-from keras.utils import io_utils\n-from keras.utils.module_utils import tensorflow as tf\n+from keras.src import backend\n+from keras.src import tree\n+from keras.src.api_export import keras_export\n+from keras.src.backend.common.stateless_scope import StatelessScope\n+from keras.src.layers import Layer\n+from keras.src.models import Functional\n+from keras.src.models import Sequential\n+from keras.src.utils import io_utils\n+from keras.src.utils.module_utils import tensorflow as tf\n \n \n @keras_export(\"keras.export.ExportArchive\")\n@@ -524,9 +524,9 @@ class ExportArchive:\n         # Next, track lookup tables.\n         # Hopefully, one day this will be automated at the tf.function level.\n         self._tf_trackable._misc_assets = []\n-        from keras.layers import IntegerLookup\n-        from keras.layers import StringLookup\n-        from keras.layers import TextVectorization\n+        from keras.src.layers import IntegerLookup\n+        from keras.src.layers import StringLookup\n+        from keras.src.layers import TextVectorization\n \n         if hasattr(self, \"_tracked\"):\n             for root in self._tracked:\n\n@@ -7,17 +7,17 @@ import pytest\n import tensorflow as tf\n from absl.testing import parameterized\n \n-from keras import backend\n-from keras import layers\n-from keras import models\n-from keras import ops\n-from keras import random\n-from keras import testing\n-from keras import tree\n-from keras import utils\n-from keras.export import export_lib\n-from keras.saving import saving_lib\n-from keras.testing.test_utils import named_product\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import models\n+from keras.src import ops\n+from keras.src import random\n+from keras.src import testing\n+from keras.src import tree\n+from keras.src import utils\n+from keras.src.export import export_lib\n+from keras.src.saving import saving_lib\n+from keras.src.testing.test_utils import named_product\n \n \n class CustomModel(models.Model):\n\n@@ -1,24 +1,24 @@\n import inspect\n \n-from keras.api_export import keras_export\n-from keras.initializers.constant_initializers import Constant\n-from keras.initializers.constant_initializers import Identity\n-from keras.initializers.constant_initializers import Ones\n-from keras.initializers.constant_initializers import Zeros\n-from keras.initializers.initializer import Initializer\n-from keras.initializers.random_initializers import GlorotNormal\n-from keras.initializers.random_initializers import GlorotUniform\n-from keras.initializers.random_initializers import HeNormal\n-from keras.initializers.random_initializers import HeUniform\n-from keras.initializers.random_initializers import LecunNormal\n-from keras.initializers.random_initializers import LecunUniform\n-from keras.initializers.random_initializers import OrthogonalInitializer\n-from keras.initializers.random_initializers import RandomNormal\n-from keras.initializers.random_initializers import RandomUniform\n-from keras.initializers.random_initializers import TruncatedNormal\n-from keras.initializers.random_initializers import VarianceScaling\n-from keras.saving import serialization_lib\n-from keras.utils.naming import to_snake_case\n+from keras.src.api_export import keras_export\n+from keras.src.initializers.constant_initializers import Constant\n+from keras.src.initializers.constant_initializers import Identity\n+from keras.src.initializers.constant_initializers import Ones\n+from keras.src.initializers.constant_initializers import Zeros\n+from keras.src.initializers.initializer import Initializer\n+from keras.src.initializers.random_initializers import GlorotNormal\n+from keras.src.initializers.random_initializers import GlorotUniform\n+from keras.src.initializers.random_initializers import HeNormal\n+from keras.src.initializers.random_initializers import HeUniform\n+from keras.src.initializers.random_initializers import LecunNormal\n+from keras.src.initializers.random_initializers import LecunUniform\n+from keras.src.initializers.random_initializers import OrthogonalInitializer\n+from keras.src.initializers.random_initializers import RandomNormal\n+from keras.src.initializers.random_initializers import RandomUniform\n+from keras.src.initializers.random_initializers import TruncatedNormal\n+from keras.src.initializers.random_initializers import VarianceScaling\n+from keras.src.saving import serialization_lib\n+from keras.src.utils.naming import to_snake_case\n \n ALL_OBJECTS = {\n     Initializer,\n\n@@ -1,8 +1,8 @@\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.backend import standardize_dtype\n-from keras.initializers.initializer import Initializer\n-from keras.saving import serialization_lib\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.backend import standardize_dtype\n+from keras.src.initializers.initializer import Initializer\n+from keras.src.saving import serialization_lib\n \n \n @keras_export([\"keras.initializers.Constant\", \"keras.initializers.constant\"])\n\n@@ -1,8 +1,8 @@\n import numpy as np\n \n-from keras import backend\n-from keras import initializers\n-from keras import testing\n+from keras.src import backend\n+from keras.src import initializers\n+from keras.src import testing\n \n \n class ConstantInitializersTest(testing.TestCase):\n\n@@ -1,4 +1,4 @@\n-from keras.api_export import keras_export\n+from keras.src.api_export import keras_export\n \n \n @keras_export([\"keras.Initializer\", \"keras.initializers.Initializer\"])\n\n@@ -1,10 +1,10 @@\n import math\n \n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.backend import random\n-from keras.initializers.initializer import Initializer\n-from keras.saving import serialization_lib\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.backend import random\n+from keras.src.initializers.initializer import Initializer\n+from keras.src.saving import serialization_lib\n \n \n @keras_export(\n\n@@ -1,9 +1,9 @@\n import numpy as np\n \n-from keras import backend\n-from keras import initializers\n-from keras import testing\n-from keras import utils\n+from keras.src import backend\n+from keras.src import initializers\n+from keras.src import testing\n+from keras.src import utils\n \n \n class InitializersTest(testing.TestCase):\n\n@@ -0,0 +1,175 @@\n+from keras.src.api_export import keras_export\n+from keras.src.layers.activations.activation import Activation\n+from keras.src.layers.activations.elu import ELU\n+from keras.src.layers.activations.leaky_relu import LeakyReLU\n+from keras.src.layers.activations.prelu import PReLU\n+from keras.src.layers.activations.relu import ReLU\n+from keras.src.layers.activations.softmax import Softmax\n+from keras.src.layers.attention.additive_attention import AdditiveAttention\n+from keras.src.layers.attention.attention import Attention\n+from keras.src.layers.attention.grouped_query_attention import (\n+    GroupedQueryAttention,\n+)\n+from keras.src.layers.attention.multi_head_attention import MultiHeadAttention\n+from keras.src.layers.convolutional.conv1d import Conv1D\n+from keras.src.layers.convolutional.conv1d_transpose import Conv1DTranspose\n+from keras.src.layers.convolutional.conv2d import Conv2D\n+from keras.src.layers.convolutional.conv2d_transpose import Conv2DTranspose\n+from keras.src.layers.convolutional.conv3d import Conv3D\n+from keras.src.layers.convolutional.conv3d_transpose import Conv3DTranspose\n+from keras.src.layers.convolutional.depthwise_conv1d import DepthwiseConv1D\n+from keras.src.layers.convolutional.depthwise_conv2d import DepthwiseConv2D\n+from keras.src.layers.convolutional.separable_conv1d import SeparableConv1D\n+from keras.src.layers.convolutional.separable_conv2d import SeparableConv2D\n+from keras.src.layers.core.dense import Dense\n+from keras.src.layers.core.einsum_dense import EinsumDense\n+from keras.src.layers.core.embedding import Embedding\n+from keras.src.layers.core.identity import Identity\n+from keras.src.layers.core.input_layer import Input\n+from keras.src.layers.core.input_layer import InputLayer\n+from keras.src.layers.core.lambda_layer import Lambda\n+from keras.src.layers.core.masking import Masking\n+from keras.src.layers.core.wrapper import Wrapper\n+from keras.src.layers.layer import Layer\n+from keras.src.layers.merging.add import Add\n+from keras.src.layers.merging.add import add\n+from keras.src.layers.merging.average import Average\n+from keras.src.layers.merging.average import average\n+from keras.src.layers.merging.concatenate import Concatenate\n+from keras.src.layers.merging.concatenate import concatenate\n+from keras.src.layers.merging.dot import Dot\n+from keras.src.layers.merging.dot import dot\n+from keras.src.layers.merging.maximum import Maximum\n+from keras.src.layers.merging.maximum import maximum\n+from keras.src.layers.merging.minimum import Minimum\n+from keras.src.layers.merging.minimum import minimum\n+from keras.src.layers.merging.multiply import Multiply\n+from keras.src.layers.merging.multiply import multiply\n+from keras.src.layers.merging.subtract import Subtract\n+from keras.src.layers.merging.subtract import subtract\n+from keras.src.layers.normalization.batch_normalization import (\n+    BatchNormalization,\n+)\n+from keras.src.layers.normalization.group_normalization import (\n+    GroupNormalization,\n+)\n+from keras.src.layers.normalization.layer_normalization import (\n+    LayerNormalization,\n+)\n+from keras.src.layers.normalization.spectral_normalization import (\n+    SpectralNormalization,\n+)\n+from keras.src.layers.normalization.unit_normalization import UnitNormalization\n+from keras.src.layers.pooling.average_pooling1d import AveragePooling1D\n+from keras.src.layers.pooling.average_pooling2d import AveragePooling2D\n+from keras.src.layers.pooling.average_pooling3d import AveragePooling3D\n+from keras.src.layers.pooling.global_average_pooling1d import (\n+    GlobalAveragePooling1D,\n+)\n+from keras.src.layers.pooling.global_average_pooling2d import (\n+    GlobalAveragePooling2D,\n+)\n+from keras.src.layers.pooling.global_average_pooling3d import (\n+    GlobalAveragePooling3D,\n+)\n+from keras.src.layers.pooling.global_max_pooling1d import GlobalMaxPooling1D\n+from keras.src.layers.pooling.global_max_pooling2d import GlobalMaxPooling2D\n+from keras.src.layers.pooling.global_max_pooling3d import GlobalMaxPooling3D\n+from keras.src.layers.pooling.max_pooling1d import MaxPooling1D\n+from keras.src.layers.pooling.max_pooling2d import MaxPooling2D\n+from keras.src.layers.pooling.max_pooling3d import MaxPooling3D\n+from keras.src.layers.preprocessing.audio_preprocessing import MelSpectrogram\n+from keras.src.layers.preprocessing.category_encoding import CategoryEncoding\n+from keras.src.layers.preprocessing.center_crop import CenterCrop\n+from keras.src.layers.preprocessing.discretization import Discretization\n+from keras.src.layers.preprocessing.hashed_crossing import HashedCrossing\n+from keras.src.layers.preprocessing.hashing import Hashing\n+from keras.src.layers.preprocessing.index_lookup import IndexLookup\n+from keras.src.layers.preprocessing.integer_lookup import IntegerLookup\n+from keras.src.layers.preprocessing.normalization import Normalization\n+from keras.src.layers.preprocessing.random_brightness import RandomBrightness\n+from keras.src.layers.preprocessing.random_contrast import RandomContrast\n+from keras.src.layers.preprocessing.random_crop import RandomCrop\n+from keras.src.layers.preprocessing.random_flip import RandomFlip\n+from keras.src.layers.preprocessing.random_rotation import RandomRotation\n+from keras.src.layers.preprocessing.random_translation import RandomTranslation\n+from keras.src.layers.preprocessing.random_zoom import RandomZoom\n+from keras.src.layers.preprocessing.rescaling import Rescaling\n+from keras.src.layers.preprocessing.resizing import Resizing\n+from keras.src.layers.preprocessing.string_lookup import StringLookup\n+from keras.src.layers.preprocessing.text_vectorization import TextVectorization\n+from keras.src.layers.regularization.activity_regularization import (\n+    ActivityRegularization,\n+)\n+from keras.src.layers.regularization.alpha_dropout import AlphaDropout\n+from keras.src.layers.regularization.dropout import Dropout\n+from keras.src.layers.regularization.gaussian_dropout import GaussianDropout\n+from keras.src.layers.regularization.gaussian_noise import GaussianNoise\n+from keras.src.layers.regularization.spatial_dropout import SpatialDropout1D\n+from keras.src.layers.regularization.spatial_dropout import SpatialDropout2D\n+from keras.src.layers.regularization.spatial_dropout import SpatialDropout3D\n+from keras.src.layers.reshaping.cropping1d import Cropping1D\n+from keras.src.layers.reshaping.cropping2d import Cropping2D\n+from keras.src.layers.reshaping.cropping3d import Cropping3D\n+from keras.src.layers.reshaping.flatten import Flatten\n+from keras.src.layers.reshaping.permute import Permute\n+from keras.src.layers.reshaping.repeat_vector import RepeatVector\n+from keras.src.layers.reshaping.reshape import Reshape\n+from keras.src.layers.reshaping.up_sampling1d import UpSampling1D\n+from keras.src.layers.reshaping.up_sampling2d import UpSampling2D\n+from keras.src.layers.reshaping.up_sampling3d import UpSampling3D\n+from keras.src.layers.reshaping.zero_padding1d import ZeroPadding1D\n+from keras.src.layers.reshaping.zero_padding2d import ZeroPadding2D\n+from keras.src.layers.reshaping.zero_padding3d import ZeroPadding3D\n+from keras.src.layers.rnn.bidirectional import Bidirectional\n+from keras.src.layers.rnn.conv_lstm1d import ConvLSTM1D\n+from keras.src.layers.rnn.conv_lstm2d import ConvLSTM2D\n+from keras.src.layers.rnn.conv_lstm3d import ConvLSTM3D\n+from keras.src.layers.rnn.gru import GRU\n+from keras.src.layers.rnn.gru import GRUCell\n+from keras.src.layers.rnn.lstm import LSTM\n+from keras.src.layers.rnn.lstm import LSTMCell\n+from keras.src.layers.rnn.rnn import RNN\n+from keras.src.layers.rnn.simple_rnn import SimpleRNN\n+from keras.src.layers.rnn.simple_rnn import SimpleRNNCell\n+from keras.src.layers.rnn.stacked_rnn_cells import StackedRNNCells\n+from keras.src.layers.rnn.time_distributed import TimeDistributed\n+from keras.src.saving import serialization_lib\n+\n+\n+@keras_export(\"keras.layers.serialize\")\n+def serialize(layer):\n+    \"\"\"Returns the layer configuration as a Python dict.\n+\n+    Args:\n+        layer: A `keras.layers.Layer` instance to serialize.\n+\n+    Returns:\n+        Python dict which contains the configuration of the layer.\n+    \"\"\"\n+    return serialization_lib.serialize_keras_object(layer)\n+\n+\n+@keras_export(\"keras.layers.deserialize\")\n+def deserialize(config, custom_objects=None):\n+    \"\"\"Returns a Keras layer object via its configuration.\n+\n+    Args:\n+        config: A python dict containing a serialized layer configuration.\n+        custom_objects: Optional dictionary mapping names (strings) to custom\n+            objects (classes and functions) to be considered during\n+            deserialization.\n+\n+    Returns:\n+        A Keras layer instance.\n+    \"\"\"\n+    obj = serialization_lib.deserialize_keras_object(\n+        config,\n+        custom_objects=custom_objects,\n+    )\n+    if not isinstance(obj, Layer):\n+        raise ValueError(\n+            \"`keras.layers.deserialize` was passed a `config` object that is \"\n+            f\"not a `keras.layers.Layer`. Received: {config}\"\n+        )\n+    return obj\n\n@@ -0,0 +1,5 @@\n+from keras.src.layers.activations.elu import ELU\n+from keras.src.layers.activations.leaky_relu import LeakyReLU\n+from keras.src.layers.activations.prelu import PReLU\n+from keras.src.layers.activations.relu import ReLU\n+from keras.src.layers.activations.softmax import Softmax\n\n@@ -1,6 +1,6 @@\n-from keras import activations\n-from keras.api_export import keras_export\n-from keras.layers.layer import Layer\n+from keras.src import activations\n+from keras.src.api_export import keras_export\n+from keras.src.layers.layer import Layer\n \n \n @keras_export(\"keras.layers.Activation\")\n\n@@ -1,8 +1,8 @@\n import pytest\n \n-from keras import activations\n-from keras import layers\n-from keras import testing\n+from keras.src import activations\n+from keras.src import layers\n+from keras.src import testing\n \n \n class ActivationTest(testing.TestCase):\n\n@@ -1,6 +1,6 @@\n-from keras import activations\n-from keras.api_export import keras_export\n-from keras.layers.layer import Layer\n+from keras.src import activations\n+from keras.src.api_export import keras_export\n+from keras.src.layers.layer import Layer\n \n \n @keras_export(\"keras.layers.ELU\")\n\n@@ -1,8 +1,8 @@\n import numpy as np\n import pytest\n \n-from keras import testing\n-from keras.layers.activations import elu\n+from keras.src import testing\n+from keras.src.layers.activations import elu\n \n \n class ELUTest(testing.TestCase):\n\n@@ -1,8 +1,8 @@\n import warnings\n \n-from keras import activations\n-from keras.api_export import keras_export\n-from keras.layers.layer import Layer\n+from keras.src import activations\n+from keras.src.api_export import keras_export\n+from keras.src.layers.layer import Layer\n \n \n @keras_export(\"keras.layers.LeakyReLU\")\n\n@@ -1,8 +1,8 @@\n import numpy as np\n import pytest\n \n-from keras import testing\n-from keras.layers.activations import leaky_relu\n+from keras.src import testing\n+from keras.src.layers.activations import leaky_relu\n \n \n class LeakyReLUTest(testing.TestCase):\n\n@@ -1,10 +1,10 @@\n-from keras import activations\n-from keras import constraints\n-from keras import initializers\n-from keras import regularizers\n-from keras.api_export import keras_export\n-from keras.layers.input_spec import InputSpec\n-from keras.layers.layer import Layer\n+from keras.src import activations\n+from keras.src import constraints\n+from keras.src import initializers\n+from keras.src import regularizers\n+from keras.src.api_export import keras_export\n+from keras.src.layers.input_spec import InputSpec\n+from keras.src.layers.layer import Layer\n \n \n @keras_export(\"keras.layers.PReLU\")\n\n@@ -1,8 +1,8 @@\n import numpy as np\n import pytest\n \n-from keras import testing\n-from keras.layers.activations import prelu\n+from keras.src import testing\n+from keras.src.layers.activations import prelu\n \n \n class PReLUTest(testing.TestCase):\n\n@@ -1,6 +1,6 @@\n-from keras import activations\n-from keras.api_export import keras_export\n-from keras.layers.layer import Layer\n+from keras.src import activations\n+from keras.src.api_export import keras_export\n+from keras.src.layers.layer import Layer\n \n \n @keras_export(\"keras.layers.ReLU\")\n\n@@ -1,8 +1,8 @@\n import numpy as np\n import pytest\n \n-from keras import testing\n-from keras.layers.activations import relu\n+from keras.src import testing\n+from keras.src.layers.activations import relu\n \n \n class ReLUTest(testing.TestCase):\n\n@@ -1,7 +1,7 @@\n-from keras import activations\n-from keras import backend\n-from keras.api_export import keras_export\n-from keras.layers.layer import Layer\n+from keras.src import activations\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.layers.layer import Layer\n \n \n def _large_negative_number(dtype):\n\n@@ -1,8 +1,8 @@\n import numpy as np\n import pytest\n \n-from keras import testing\n-from keras.layers.activations import softmax\n+from keras.src import testing\n+from keras.src.layers.activations import softmax\n \n \n class SoftmaxTest(testing.TestCase):\n\n\n@@ -1,6 +1,6 @@\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.layers.attention.attention import Attention\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.layers.attention.attention import Attention\n \n \n @keras_export(\"keras.layers.AdditiveAttention\")\n\n@@ -1,7 +1,7 @@\n import numpy as np\n \n-from keras import layers\n-from keras import testing\n+from keras.src import layers\n+from keras.src import testing\n \n \n class AdditiveAttentionTest(testing.TestCase):\n\n@@ -1,7 +1,7 @@\n-from keras import backend\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.layers.layer import Layer\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.layers.layer import Layer\n \n \n @keras_export(\"keras.layers.Attention\")\n\n@@ -1,8 +1,8 @@\n import numpy as np\n \n-from keras import layers\n-from keras import ops\n-from keras import testing\n+from keras.src import layers\n+from keras.src import ops\n+from keras.src import testing\n \n \n class AttentionTest(testing.TestCase):\n\n@@ -1,12 +1,12 @@\n-from keras import constraints\n-from keras import initializers\n-from keras import ops\n-from keras import regularizers\n-from keras.api_export import keras_export\n-from keras.layers.activations.softmax import Softmax\n-from keras.layers.core.einsum_dense import EinsumDense\n-from keras.layers.layer import Layer\n-from keras.layers.regularization.dropout import Dropout\n+from keras.src import constraints\n+from keras.src import initializers\n+from keras.src import ops\n+from keras.src import regularizers\n+from keras.src.api_export import keras_export\n+from keras.src.layers.activations.softmax import Softmax\n+from keras.src.layers.core.einsum_dense import EinsumDense\n+from keras.src.layers.layer import Layer\n+from keras.src.layers.regularization.dropout import Dropout\n \n \n @keras_export(\"keras.layers.GroupQueryAttention\")\n\n@@ -2,10 +2,10 @@ import numpy as np\n import pytest\n from absl.testing import parameterized\n \n-from keras import backend\n-from keras import initializers\n-from keras import layers\n-from keras import testing\n+from keras.src import backend\n+from keras.src import initializers\n+from keras.src import layers\n+from keras.src import testing\n \n \n class GroupedQueryAttentionTest(testing.TestCase, parameterized.TestCase):\n\n@@ -4,16 +4,16 @@ import string\n \n import numpy as np\n \n-from keras import backend\n-from keras import constraints\n-from keras import initializers\n-from keras import ops\n-from keras import regularizers\n-from keras.api_export import keras_export\n-from keras.layers.activations.softmax import Softmax\n-from keras.layers.core.einsum_dense import EinsumDense\n-from keras.layers.layer import Layer\n-from keras.layers.regularization.dropout import Dropout\n+from keras.src import backend\n+from keras.src import constraints\n+from keras.src import initializers\n+from keras.src import ops\n+from keras.src import regularizers\n+from keras.src.api_export import keras_export\n+from keras.src.layers.activations.softmax import Softmax\n+from keras.src.layers.core.einsum_dense import EinsumDense\n+from keras.src.layers.layer import Layer\n+from keras.src.layers.regularization.dropout import Dropout\n \n \n @keras_export(\"keras.layers.MultiHeadAttention\")\n\n@@ -4,13 +4,13 @@ import numpy as np\n import pytest\n from absl.testing import parameterized\n \n-from keras import backend\n-from keras import constraints\n-from keras import initializers\n-from keras import layers\n-from keras import models\n-from keras import saving\n-from keras import testing\n+from keras.src import backend\n+from keras.src import constraints\n+from keras.src import initializers\n+from keras.src import layers\n+from keras.src import models\n+from keras.src import saving\n+from keras.src import testing\n \n \n class MultiHeadAttentionTest(testing.TestCase, parameterized.TestCase):\n\n\n@@ -1,16 +1,16 @@\n \"\"\"Keras base class for convolution layers.\"\"\"\n \n-from keras import activations\n-from keras import constraints\n-from keras import initializers\n-from keras import ops\n-from keras import regularizers\n-from keras.backend import standardize_data_format\n-from keras.layers.input_spec import InputSpec\n-from keras.layers.layer import Layer\n-from keras.ops.operation_utils import compute_conv_output_shape\n-from keras.utils.argument_validation import standardize_padding\n-from keras.utils.argument_validation import standardize_tuple\n+from keras.src import activations\n+from keras.src import constraints\n+from keras.src import initializers\n+from keras.src import ops\n+from keras.src import regularizers\n+from keras.src.backend import standardize_data_format\n+from keras.src.layers.input_spec import InputSpec\n+from keras.src.layers.layer import Layer\n+from keras.src.ops.operation_utils import compute_conv_output_shape\n+from keras.src.utils.argument_validation import standardize_padding\n+from keras.src.utils.argument_validation import standardize_tuple\n \n \n class BaseConv(Layer):\n\n@@ -1,18 +1,18 @@\n \"\"\"Keras base class for transpose convolution layers.\"\"\"\n \n-from keras import activations\n-from keras import constraints\n-from keras import initializers\n-from keras import ops\n-from keras import regularizers\n-from keras.backend import standardize_data_format\n-from keras.backend.common.backend_utils import (\n+from keras.src import activations\n+from keras.src import constraints\n+from keras.src import initializers\n+from keras.src import ops\n+from keras.src import regularizers\n+from keras.src.backend import standardize_data_format\n+from keras.src.backend.common.backend_utils import (\n     compute_conv_transpose_output_shape,\n )\n-from keras.layers.input_spec import InputSpec\n-from keras.layers.layer import Layer\n-from keras.utils.argument_validation import standardize_padding\n-from keras.utils.argument_validation import standardize_tuple\n+from keras.src.layers.input_spec import InputSpec\n+from keras.src.layers.layer import Layer\n+from keras.src.utils.argument_validation import standardize_padding\n+from keras.src.utils.argument_validation import standardize_tuple\n \n \n class BaseConvTranspose(Layer):\n\n@@ -1,16 +1,16 @@\n \"\"\"Keras base class for depthwise convolution layers.\"\"\"\n \n-from keras import activations\n-from keras import constraints\n-from keras import initializers\n-from keras import ops\n-from keras import regularizers\n-from keras.backend import standardize_data_format\n-from keras.layers.input_spec import InputSpec\n-from keras.layers.layer import Layer\n-from keras.ops.operation_utils import compute_conv_output_shape\n-from keras.utils.argument_validation import standardize_padding\n-from keras.utils.argument_validation import standardize_tuple\n+from keras.src import activations\n+from keras.src import constraints\n+from keras.src import initializers\n+from keras.src import ops\n+from keras.src import regularizers\n+from keras.src.backend import standardize_data_format\n+from keras.src.layers.input_spec import InputSpec\n+from keras.src.layers.layer import Layer\n+from keras.src.ops.operation_utils import compute_conv_output_shape\n+from keras.src.utils.argument_validation import standardize_padding\n+from keras.src.utils.argument_validation import standardize_tuple\n \n \n class BaseDepthwiseConv(Layer):\n\n@@ -1,16 +1,16 @@\n \"\"\"Keras abstract base layer for separable convolution.\"\"\"\n \n-from keras import activations\n-from keras import constraints\n-from keras import initializers\n-from keras import ops\n-from keras import regularizers\n-from keras.backend import standardize_data_format\n-from keras.layers.input_spec import InputSpec\n-from keras.layers.layer import Layer\n-from keras.ops.operation_utils import compute_conv_output_shape\n-from keras.utils.argument_validation import standardize_padding\n-from keras.utils.argument_validation import standardize_tuple\n+from keras.src import activations\n+from keras.src import constraints\n+from keras.src import initializers\n+from keras.src import ops\n+from keras.src import regularizers\n+from keras.src.backend import standardize_data_format\n+from keras.src.layers.input_spec import InputSpec\n+from keras.src.layers.layer import Layer\n+from keras.src.ops.operation_utils import compute_conv_output_shape\n+from keras.src.utils.argument_validation import standardize_padding\n+from keras.src.utils.argument_validation import standardize_tuple\n \n \n class BaseSeparableConv(Layer):\n\n@@ -1,6 +1,6 @@\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.layers.convolutional.base_conv import BaseConv\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.layers.convolutional.base_conv import BaseConv\n \n \n @keras_export([\"keras.layers.Conv1D\", \"keras.layers.Convolution1D\"])\n\n@@ -1,5 +1,5 @@\n-from keras.api_export import keras_export\n-from keras.layers.convolutional.base_conv_transpose import BaseConvTranspose\n+from keras.src.api_export import keras_export\n+from keras.src.layers.convolutional.base_conv_transpose import BaseConvTranspose\n \n \n @keras_export(\n\n@@ -1,5 +1,5 @@\n-from keras.api_export import keras_export\n-from keras.layers.convolutional.base_conv import BaseConv\n+from keras.src.api_export import keras_export\n+from keras.src.layers.convolutional.base_conv import BaseConv\n \n \n @keras_export([\"keras.layers.Conv2D\", \"keras.layers.Convolution2D\"])\n\n@@ -1,5 +1,5 @@\n-from keras.api_export import keras_export\n-from keras.layers.convolutional.base_conv_transpose import BaseConvTranspose\n+from keras.src.api_export import keras_export\n+from keras.src.layers.convolutional.base_conv_transpose import BaseConvTranspose\n \n \n @keras_export(\n\n@@ -1,5 +1,5 @@\n-from keras.api_export import keras_export\n-from keras.layers.convolutional.base_conv import BaseConv\n+from keras.src.api_export import keras_export\n+from keras.src.layers.convolutional.base_conv import BaseConv\n \n \n @keras_export([\"keras.layers.Conv3D\", \"keras.layers.Convolution3D\"])\n\n@@ -1,5 +1,5 @@\n-from keras.api_export import keras_export\n-from keras.layers.convolutional.base_conv_transpose import BaseConvTranspose\n+from keras.src.api_export import keras_export\n+from keras.src.layers.convolutional.base_conv_transpose import BaseConvTranspose\n \n \n @keras_export(\n\n@@ -5,12 +5,12 @@ import pytest\n from absl.testing import parameterized\n from numpy.lib.stride_tricks import as_strided\n \n-from keras import backend\n-from keras import constraints\n-from keras import layers\n-from keras import models\n-from keras import saving\n-from keras import testing\n+from keras.src import backend\n+from keras.src import constraints\n+from keras.src import layers\n+from keras.src import models\n+from keras.src import saving\n+from keras.src import testing\n \n \n def _same_padding(input_size, kernel_size, stride):\n\n@@ -2,16 +2,16 @@ import numpy as np\n import pytest\n from absl.testing import parameterized\n \n-from keras import backend\n-from keras import layers\n-from keras import testing\n-from keras.backend.common.backend_utils import (\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n+from keras.src.backend.common.backend_utils import (\n     _convert_conv_tranpose_padding_args_from_keras_to_torch,\n )\n-from keras.backend.common.backend_utils import (\n+from keras.src.backend.common.backend_utils import (\n     compute_conv_transpose_output_shape,\n )\n-from keras.backend.common.backend_utils import (\n+from keras.src.backend.common.backend_utils import (\n     compute_conv_transpose_padding_args_for_jax,\n )\n \n\n@@ -1,5 +1,5 @@\n-from keras.api_export import keras_export\n-from keras.layers.convolutional.base_depthwise_conv import BaseDepthwiseConv\n+from keras.src.api_export import keras_export\n+from keras.src.layers.convolutional.base_depthwise_conv import BaseDepthwiseConv\n \n \n @keras_export(\"keras.layers.DepthwiseConv1D\")\n\n@@ -1,5 +1,5 @@\n-from keras.api_export import keras_export\n-from keras.layers.convolutional.base_depthwise_conv import BaseDepthwiseConv\n+from keras.src.api_export import keras_export\n+from keras.src.layers.convolutional.base_depthwise_conv import BaseDepthwiseConv\n \n \n @keras_export(\"keras.layers.DepthwiseConv2D\")\n\n@@ -3,8 +3,8 @@ import pytest\n from absl.testing import parameterized\n from numpy.lib.stride_tricks import as_strided\n \n-from keras import layers\n-from keras import testing\n+from keras.src import layers\n+from keras.src import testing\n \n \n def _same_padding(input_size, kernel_size, stride):\n\n@@ -1,5 +1,5 @@\n-from keras.api_export import keras_export\n-from keras.layers.convolutional.base_separable_conv import BaseSeparableConv\n+from keras.src.api_export import keras_export\n+from keras.src.layers.convolutional.base_separable_conv import BaseSeparableConv\n \n \n @keras_export(\n\n@@ -1,5 +1,5 @@\n-from keras.api_export import keras_export\n-from keras.layers.convolutional.base_separable_conv import BaseSeparableConv\n+from keras.src.api_export import keras_export\n+from keras.src.layers.convolutional.base_separable_conv import BaseSeparableConv\n \n \n @keras_export(\n\n@@ -2,12 +2,16 @@ import numpy as np\n import pytest\n from absl.testing import parameterized\n \n-from keras import layers\n-from keras import testing\n-from keras.layers.convolutional.conv_test import np_conv1d\n-from keras.layers.convolutional.conv_test import np_conv2d\n-from keras.layers.convolutional.depthwise_conv_test import np_depthwise_conv1d\n-from keras.layers.convolutional.depthwise_conv_test import np_depthwise_conv2d\n+from keras.src import layers\n+from keras.src import testing\n+from keras.src.layers.convolutional.conv_test import np_conv1d\n+from keras.src.layers.convolutional.conv_test import np_conv2d\n+from keras.src.layers.convolutional.depthwise_conv_test import (\n+    np_depthwise_conv1d,\n+)\n+from keras.src.layers.convolutional.depthwise_conv_test import (\n+    np_depthwise_conv2d,\n+)\n \n \n class SeparableConvBasicTest(testing.TestCase, parameterized.TestCase):\n\n\n@@ -1,16 +1,16 @@\n import ml_dtypes\n \n-from keras import activations\n-from keras import backend\n-from keras import constraints\n-from keras import dtype_policies\n-from keras import initializers\n-from keras import ops\n-from keras import quantizers\n-from keras import regularizers\n-from keras.api_export import keras_export\n-from keras.layers.input_spec import InputSpec\n-from keras.layers.layer import Layer\n+from keras.src import activations\n+from keras.src import backend\n+from keras.src import constraints\n+from keras.src import dtype_policies\n+from keras.src import initializers\n+from keras.src import ops\n+from keras.src import quantizers\n+from keras.src import regularizers\n+from keras.src.api_export import keras_export\n+from keras.src.layers.input_spec import InputSpec\n+from keras.src.layers.layer import Layer\n \n \n @keras_export(\"keras.layers.Dense\")\n\n@@ -4,17 +4,17 @@ import numpy as np\n import pytest\n from absl.testing import parameterized\n \n-from keras import backend\n-from keras import constraints\n-from keras import layers\n-from keras import models\n-from keras import ops\n-from keras import optimizers\n-from keras import random\n-from keras import saving\n-from keras import testing\n-from keras.backend.common import keras_tensor\n-from keras.export import export_lib\n+from keras.src import backend\n+from keras.src import constraints\n+from keras.src import layers\n+from keras.src import models\n+from keras.src import ops\n+from keras.src import optimizers\n+from keras.src import random\n+from keras.src import saving\n+from keras.src import testing\n+from keras.src.backend.common import keras_tensor\n+from keras.src.export import export_lib\n \n \n class DenseTest(testing.TestCase, parameterized.TestCase):\n@@ -556,7 +556,7 @@ class DenseTest(testing.TestCase, parameterized.TestCase):\n     def test_quantize_float8(self):\n         import ml_dtypes\n \n-        from keras import quantizers\n+        from keras.src import quantizers\n \n         layer = layers.Dense(units=32)\n         layer.build((None, 16))\n\n@@ -4,17 +4,17 @@ import string\n import ml_dtypes\n import numpy as np\n \n-from keras import activations\n-from keras import backend\n-from keras import constraints\n-from keras import dtype_policies\n-from keras import initializers\n-from keras import ops\n-from keras import quantizers\n-from keras import regularizers\n-from keras.api_export import keras_export\n-from keras.layers.input_spec import InputSpec\n-from keras.layers.layer import Layer\n+from keras.src import activations\n+from keras.src import backend\n+from keras.src import constraints\n+from keras.src import dtype_policies\n+from keras.src import initializers\n+from keras.src import ops\n+from keras.src import quantizers\n+from keras.src import regularizers\n+from keras.src.api_export import keras_export\n+from keras.src.layers.input_spec import InputSpec\n+from keras.src.layers.layer import Layer\n \n \n @keras_export(\"keras.layers.EinsumDense\")\n\n@@ -4,16 +4,16 @@ import numpy as np\n import pytest\n from absl.testing import parameterized\n \n-from keras import backend\n-from keras import constraints\n-from keras import layers\n-from keras import models\n-from keras import ops\n-from keras import optimizers\n-from keras import random\n-from keras import saving\n-from keras import testing\n-from keras.export import export_lib\n+from keras.src import backend\n+from keras.src import constraints\n+from keras.src import layers\n+from keras.src import models\n+from keras.src import ops\n+from keras.src import optimizers\n+from keras.src import random\n+from keras.src import saving\n+from keras.src import testing\n+from keras.src.export import export_lib\n \n \n class EinsumDenseTest(testing.TestCase, parameterized.TestCase):\n@@ -659,7 +659,7 @@ class EinsumDenseTest(testing.TestCase, parameterized.TestCase):\n     def test_quantize_float8(self):\n         import ml_dtypes\n \n-        from keras import quantizers\n+        from keras.src import quantizers\n \n         layer = layers.EinsumDense(\n             \"ab,bc->ac\",\n\n@@ -1,14 +1,14 @@\n import warnings\n \n-from keras import backend\n-from keras import constraints\n-from keras import dtype_policies\n-from keras import initializers\n-from keras import ops\n-from keras import quantizers\n-from keras import regularizers\n-from keras.api_export import keras_export\n-from keras.layers.layer import Layer\n+from keras.src import backend\n+from keras.src import constraints\n+from keras.src import dtype_policies\n+from keras.src import initializers\n+from keras.src import ops\n+from keras.src import quantizers\n+from keras.src import regularizers\n+from keras.src.api_export import keras_export\n+from keras.src.layers.layer import Layer\n \n \n @keras_export(\"keras.layers.Embedding\")\n\n@@ -4,14 +4,14 @@ import numpy as np\n import pytest\n from absl.testing import parameterized\n \n-from keras import backend\n-from keras import constraints\n-from keras import layers\n-from keras import models\n-from keras import ops\n-from keras import saving\n-from keras.export import export_lib\n-from keras.testing import test_case\n+from keras.src import backend\n+from keras.src import constraints\n+from keras.src import layers\n+from keras.src import models\n+from keras.src import ops\n+from keras.src import saving\n+from keras.src.export import export_lib\n+from keras.src.testing import test_case\n \n \n class EmbeddingTest(test_case.TestCase, parameterized.TestCase):\n\n@@ -1,7 +1,7 @@\n-from keras import tree\n-from keras.api_export import keras_export\n-from keras.backend import KerasTensor\n-from keras.layers.layer import Layer\n+from keras.src import tree\n+from keras.src.api_export import keras_export\n+from keras.src.backend import KerasTensor\n+from keras.src.layers.layer import Layer\n \n \n @keras_export(\"keras.layers.Identity\")\n\n@@ -1,9 +1,9 @@\n import pytest\n from absl.testing import parameterized\n \n-from keras import backend\n-from keras import layers\n-from keras import testing\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n \n \n class IdentityTest(testing.TestCase, parameterized.TestCase):\n\n@@ -1,9 +1,9 @@\n import warnings\n \n-from keras import backend\n-from keras.api_export import keras_export\n-from keras.layers.layer import Layer\n-from keras.ops.node import Node\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.layers.layer import Layer\n+from keras.src.ops.node import Node\n \n \n @keras_export(\"keras.layers.InputLayer\")\n\n@@ -1,10 +1,10 @@\n import numpy as np\n from absl.testing import parameterized\n \n-from keras import backend\n-from keras import testing\n-from keras.backend import KerasTensor\n-from keras.layers import InputLayer\n+from keras.src import backend\n+from keras.src import testing\n+from keras.src.backend import KerasTensor\n+from keras.src.layers import InputLayer\n \n \n class InputLayerTest(testing.TestCase, parameterized.TestCase):\n\n@@ -1,12 +1,12 @@\n import inspect\n import types\n \n-from keras import backend\n-from keras import tree\n-from keras.api_export import keras_export\n-from keras.layers.layer import Layer\n-from keras.saving import serialization_lib\n-from keras.utils import python_utils\n+from keras.src import backend\n+from keras.src import tree\n+from keras.src.api_export import keras_export\n+from keras.src.layers.layer import Layer\n+from keras.src.saving import serialization_lib\n+from keras.src.utils import python_utils\n \n \n @keras_export(\"keras.layers.Lambda\")\n\n@@ -1,9 +1,9 @@\n import numpy as np\n import pytest\n \n-from keras import layers\n-from keras import ops\n-from keras import testing\n+from keras.src import layers\n+from keras.src import ops\n+from keras.src import testing\n \n \n class LambdaTest(testing.TestCase):\n\n@@ -1,7 +1,7 @@\n-from keras import backend\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.layers.layer import Layer\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.layers.layer import Layer\n \n \n @keras_export(\"keras.layers.Masking\")\n\n@@ -1,9 +1,9 @@\n import numpy as np\n import pytest\n \n-from keras import layers\n-from keras import models\n-from keras import testing\n+from keras.src import layers\n+from keras.src import models\n+from keras.src import testing\n \n \n class MaskingTest(testing.TestCase):\n\n@@ -1,6 +1,6 @@\n-from keras.api_export import keras_export\n-from keras.layers.layer import Layer\n-from keras.saving import serialization_lib\n+from keras.src.api_export import keras_export\n+from keras.src.layers.layer import Layer\n+from keras.src.saving import serialization_lib\n \n \n @keras_export(\"keras.layers.Wrapper\")\n\n@@ -1,8 +1,8 @@\n import pytest\n \n-from keras import layers\n-from keras import ops\n-from keras import testing\n+from keras.src import layers\n+from keras.src import ops\n+from keras.src import testing\n \n \n class ExampleWrapper(layers.Wrapper):\n\n@@ -1,6 +1,6 @@\n-from keras import backend\n-from keras import tree\n-from keras.api_export import keras_export\n+from keras.src import backend\n+from keras.src import tree\n+from keras.src.api_export import keras_export\n \n \n @keras_export([\"keras.InputSpec\", \"keras.layers.InputSpec\"])\n\n@@ -21,34 +21,34 @@ import inspect\n import warnings\n from functools import wraps\n \n-from keras import backend\n-from keras import constraints\n-from keras import dtype_policies\n-from keras import initializers\n-from keras import regularizers\n-from keras import tree\n-from keras import utils\n-from keras.api_export import keras_export\n-from keras.backend import KerasTensor\n-from keras.backend.common import global_state\n-from keras.backend.common.name_scope import current_path\n-from keras.distribution import distribution_lib\n-from keras.layers import input_spec\n-from keras.metrics.metric import Metric\n-from keras.ops.operation import Operation\n-from keras.utils import python_utils\n-from keras.utils import summary_utils\n-from keras.utils import traceback_utils\n-from keras.utils import tracking\n+from keras.src import backend\n+from keras.src import constraints\n+from keras.src import dtype_policies\n+from keras.src import initializers\n+from keras.src import regularizers\n+from keras.src import tree\n+from keras.src import utils\n+from keras.src.api_export import keras_export\n+from keras.src.backend import KerasTensor\n+from keras.src.backend.common import global_state\n+from keras.src.backend.common.name_scope import current_path\n+from keras.src.distribution import distribution_lib\n+from keras.src.layers import input_spec\n+from keras.src.metrics.metric import Metric\n+from keras.src.ops.operation import Operation\n+from keras.src.utils import python_utils\n+from keras.src.utils import summary_utils\n+from keras.src.utils import traceback_utils\n+from keras.src.utils import tracking\n \n if backend.backend() == \"tensorflow\":\n-    from keras.backend.tensorflow.layer import TFLayer as BackendLayer\n+    from keras.src.backend.tensorflow.layer import TFLayer as BackendLayer\n elif backend.backend() == \"jax\":\n-    from keras.backend.jax.layer import JaxLayer as BackendLayer\n+    from keras.src.backend.jax.layer import JaxLayer as BackendLayer\n elif backend.backend() == \"torch\":\n-    from keras.backend.torch.layer import TorchLayer as BackendLayer\n+    from keras.src.backend.torch.layer import TorchLayer as BackendLayer\n elif backend.backend() == \"numpy\":\n-    from keras.backend.numpy.layer import NumpyLayer as BackendLayer\n+    from keras.src.backend.numpy.layer import NumpyLayer as BackendLayer\n else:\n     raise RuntimeError(\n         f\"Backend '{backend.backend()}' must implement a layer mixin class.\"\n\n@@ -1,13 +1,13 @@\n import numpy as np\n import pytest\n \n-from keras import backend\n-from keras import dtype_policies\n-from keras import layers\n-from keras import metrics\n-from keras import models\n-from keras import ops\n-from keras import testing\n+from keras.src import backend\n+from keras.src import dtype_policies\n+from keras.src import layers\n+from keras.src import metrics\n+from keras.src import models\n+from keras.src import ops\n+from keras.src import testing\n \n \n class LayerTest(testing.TestCase):\n\n\n@@ -1,6 +1,6 @@\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.layers.merging.base_merge import Merge\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.layers.merging.base_merge import Merge\n \n \n @keras_export(\"keras.layers.Add\")\n\n@@ -1,6 +1,6 @@\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.layers.merging.base_merge import Merge\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.layers.merging.base_merge import Merge\n \n \n @keras_export(\"keras.layers.Average\")\n\n@@ -1,7 +1,7 @@\n-from keras import backend\n-from keras import ops\n-from keras.backend.common.keras_tensor import KerasTensor\n-from keras.layers.layer import Layer\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src.backend.common.keras_tensor import KerasTensor\n+from keras.src.layers.layer import Layer\n \n \n class Merge(Layer):\n\n@@ -1,6 +1,6 @@\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.layers.merging.base_merge import Merge\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.layers.merging.base_merge import Merge\n \n \n @keras_export(\"keras.layers.Concatenate\")\n\n@@ -1,7 +1,7 @@\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.layers.merging.base_merge import Merge\n-from keras.utils.numerical_utils import normalize\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.layers.merging.base_merge import Merge\n+from keras.src.utils.numerical_utils import normalize\n \n \n def batch_dot(x, y, axes=None):\n\n@@ -1,6 +1,6 @@\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.layers.merging.base_merge import Merge\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.layers.merging.base_merge import Merge\n \n \n @keras_export(\"keras.layers.Maximum\")\n\n@@ -2,10 +2,10 @@ import numpy as np\n import pytest\n from absl.testing import parameterized\n \n-from keras import backend\n-from keras import layers\n-from keras import models\n-from keras import testing\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import models\n+from keras.src import testing\n \n \n def np_dot(a, b, axes):\n\n@@ -1,6 +1,6 @@\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.layers.merging.base_merge import Merge\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.layers.merging.base_merge import Merge\n \n \n @keras_export(\"keras.layers.Minimum\")\n\n@@ -1,6 +1,6 @@\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.layers.merging.base_merge import Merge\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.layers.merging.base_merge import Merge\n \n \n @keras_export(\"keras.layers.Multiply\")\n\n@@ -1,6 +1,6 @@\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.layers.merging.base_merge import Merge\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.layers.merging.base_merge import Merge\n \n \n @keras_export(\"keras.layers.Subtract\")\n\n\n@@ -1,12 +1,12 @@\n-from keras import backend\n-from keras import constraints\n-from keras import initializers\n-from keras import ops\n-from keras import regularizers\n-from keras.api_export import keras_export\n-from keras.backend import standardize_dtype\n-from keras.layers.input_spec import InputSpec\n-from keras.layers.layer import Layer\n+from keras.src import backend\n+from keras.src import constraints\n+from keras.src import initializers\n+from keras.src import ops\n+from keras.src import regularizers\n+from keras.src.api_export import keras_export\n+from keras.src.backend import standardize_dtype\n+from keras.src.layers.input_spec import InputSpec\n+from keras.src.layers.layer import Layer\n \n \n @keras_export(\"keras.layers.BatchNormalization\")\n\n@@ -2,12 +2,12 @@ import numpy as np\n import pytest\n from absl.testing import parameterized\n \n-from keras import backend\n-from keras import layers\n-from keras import ops\n-from keras import testing\n-from keras.losses import MeanSquaredError\n-from keras.models import Model\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import ops\n+from keras.src import testing\n+from keras.src.losses import MeanSquaredError\n+from keras.src.models import Model\n \n \n class BatchNormalizationTest(testing.TestCase, parameterized.TestCase):\n\n@@ -1,10 +1,10 @@\n-from keras import constraints\n-from keras import initializers\n-from keras import ops\n-from keras import regularizers\n-from keras.api_export import keras_export\n-from keras.layers.input_spec import InputSpec\n-from keras.layers.layer import Layer\n+from keras.src import constraints\n+from keras.src import initializers\n+from keras.src import ops\n+from keras.src import regularizers\n+from keras.src.api_export import keras_export\n+from keras.src.layers.input_spec import InputSpec\n+from keras.src.layers.layer import Layer\n \n \n @keras_export(\"keras.layers.GroupNormalization\")\n\n@@ -1,10 +1,10 @@\n import numpy as np\n import pytest\n \n-from keras import constraints\n-from keras import layers\n-from keras import regularizers\n-from keras import testing\n+from keras.src import constraints\n+from keras.src import layers\n+from keras.src import regularizers\n+from keras.src import testing\n \n \n class GroupNormalizationTest(testing.TestCase):\n\n@@ -1,9 +1,9 @@\n-from keras import constraints\n-from keras import initializers\n-from keras import ops\n-from keras import regularizers\n-from keras.api_export import keras_export\n-from keras.layers.layer import Layer\n+from keras.src import constraints\n+from keras.src import initializers\n+from keras.src import ops\n+from keras.src import regularizers\n+from keras.src.api_export import keras_export\n+from keras.src.layers.layer import Layer\n \n \n @keras_export(\"keras.layers.LayerNormalization\")\n\n@@ -1,11 +1,11 @@\n import numpy as np\n import pytest\n \n-from keras import backend\n-from keras import layers\n-from keras import ops\n-from keras import regularizers\n-from keras import testing\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import ops\n+from keras.src import regularizers\n+from keras.src import testing\n \n \n class LayerNormalizationTest(testing.TestCase):\n\n@@ -1,9 +1,9 @@\n-from keras import initializers\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.layers import Wrapper\n-from keras.layers.input_spec import InputSpec\n-from keras.utils.numerical_utils import normalize\n+from keras.src import initializers\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.layers import Wrapper\n+from keras.src.layers.input_spec import InputSpec\n+from keras.src.utils.numerical_utils import normalize\n \n \n @keras_export(\"keras.layers.SpectralNormalization\")\n\n@@ -1,11 +1,11 @@\n import numpy as np\n import pytest\n \n-from keras import backend\n-from keras import initializers\n-from keras import layers\n-from keras import models\n-from keras import testing\n+from keras.src import backend\n+from keras.src import initializers\n+from keras.src import layers\n+from keras.src import models\n+from keras.src import testing\n \n \n class SpectralNormalizationTest(testing.TestCase):\n\n@@ -1,6 +1,6 @@\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.layers.layer import Layer\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.layers.layer import Layer\n \n \n @keras_export(\"keras.layers.UnitNormalization\")\n\n@@ -1,9 +1,9 @@\n import numpy as np\n import pytest\n \n-from keras import backend\n-from keras import layers\n-from keras import testing\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n \n \n def squared_l2_norm(x):\n\n\n@@ -1,5 +1,5 @@\n-from keras.api_export import keras_export\n-from keras.layers.pooling.base_pooling import BasePooling\n+from keras.src.api_export import keras_export\n+from keras.src.layers.pooling.base_pooling import BasePooling\n \n \n @keras_export([\"keras.layers.AveragePooling1D\", \"keras.layers.AvgPool1D\"])\n\n@@ -1,5 +1,5 @@\n-from keras.api_export import keras_export\n-from keras.layers.pooling.base_pooling import BasePooling\n+from keras.src.api_export import keras_export\n+from keras.src.layers.pooling.base_pooling import BasePooling\n \n \n @keras_export([\"keras.layers.AveragePooling2D\", \"keras.layers.AvgPool2D\"])\n\n@@ -1,5 +1,5 @@\n-from keras.api_export import keras_export\n-from keras.layers.pooling.base_pooling import BasePooling\n+from keras.src.api_export import keras_export\n+from keras.src.layers.pooling.base_pooling import BasePooling\n \n \n @keras_export([\"keras.layers.AveragePooling3D\", \"keras.layers.AvgPool3D\"])\n\n@@ -3,9 +3,9 @@ import pytest\n from absl.testing import parameterized\n from numpy.lib.stride_tricks import as_strided\n \n-from keras import backend\n-from keras import layers\n-from keras import testing\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n \n \n def _same_padding(input_size, pool_size, stride):\n\n@@ -1,6 +1,6 @@\n-from keras import backend\n-from keras.layers.input_spec import InputSpec\n-from keras.layers.layer import Layer\n+from keras.src import backend\n+from keras.src.layers.input_spec import InputSpec\n+from keras.src.layers.layer import Layer\n \n \n class BaseGlobalPooling(Layer):\n\n@@ -1,9 +1,9 @@\n-from keras import backend\n-from keras import ops\n-from keras.layers.input_spec import InputSpec\n-from keras.layers.layer import Layer\n-from keras.ops.operation_utils import compute_pooling_output_shape\n-from keras.utils import argument_validation\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src.layers.input_spec import InputSpec\n+from keras.src.layers.layer import Layer\n+from keras.src.ops.operation_utils import compute_pooling_output_shape\n+from keras.src.utils import argument_validation\n \n \n class BasePooling(Layer):\n\n@@ -1,7 +1,7 @@\n-from keras import backend\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.layers.pooling.base_global_pooling import BaseGlobalPooling\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.layers.pooling.base_global_pooling import BaseGlobalPooling\n \n \n @keras_export(\n\n@@ -1,6 +1,6 @@\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.layers.pooling.base_global_pooling import BaseGlobalPooling\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.layers.pooling.base_global_pooling import BaseGlobalPooling\n \n \n @keras_export(\n\n@@ -1,6 +1,6 @@\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.layers.pooling.base_global_pooling import BaseGlobalPooling\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.layers.pooling.base_global_pooling import BaseGlobalPooling\n \n \n @keras_export(\n\n@@ -2,8 +2,8 @@ import numpy as np\n import pytest\n from absl.testing import parameterized\n \n-from keras import layers\n-from keras import testing\n+from keras.src import layers\n+from keras.src import testing\n \n \n @pytest.mark.requires_trainable_backend\n\n@@ -1,6 +1,6 @@\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.layers.pooling.base_global_pooling import BaseGlobalPooling\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.layers.pooling.base_global_pooling import BaseGlobalPooling\n \n \n @keras_export(\n\n@@ -1,6 +1,6 @@\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.layers.pooling.base_global_pooling import BaseGlobalPooling\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.layers.pooling.base_global_pooling import BaseGlobalPooling\n \n \n @keras_export(\n\n@@ -1,6 +1,6 @@\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.layers.pooling.base_global_pooling import BaseGlobalPooling\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.layers.pooling.base_global_pooling import BaseGlobalPooling\n \n \n @keras_export(\n\n@@ -2,8 +2,8 @@ import numpy as np\n import pytest\n from absl.testing import parameterized\n \n-from keras import layers\n-from keras import testing\n+from keras.src import layers\n+from keras.src import testing\n \n \n @pytest.mark.requires_trainable_backend\n\n@@ -1,5 +1,5 @@\n-from keras.api_export import keras_export\n-from keras.layers.pooling.base_pooling import BasePooling\n+from keras.src.api_export import keras_export\n+from keras.src.layers.pooling.base_pooling import BasePooling\n \n \n @keras_export([\"keras.layers.MaxPooling1D\", \"keras.layers.MaxPool1D\"])\n\n@@ -1,5 +1,5 @@\n-from keras.api_export import keras_export\n-from keras.layers.pooling.base_pooling import BasePooling\n+from keras.src.api_export import keras_export\n+from keras.src.layers.pooling.base_pooling import BasePooling\n \n \n @keras_export([\"keras.layers.MaxPooling2D\", \"keras.layers.MaxPool2D\"])\n\n@@ -1,5 +1,5 @@\n-from keras.api_export import keras_export\n-from keras.layers.pooling.base_pooling import BasePooling\n+from keras.src.api_export import keras_export\n+from keras.src.layers.pooling.base_pooling import BasePooling\n \n \n @keras_export([\"keras.layers.MaxPooling3D\", \"keras.layers.MaxPool3D\"])\n\n@@ -3,8 +3,8 @@ import pytest\n from absl.testing import parameterized\n from numpy.lib.stride_tricks import as_strided\n \n-from keras import layers\n-from keras import testing\n+from keras.src import layers\n+from keras.src import testing\n \n \n def _same_padding(input_size, pool_size, stride):\n\n\n@@ -1,5 +1,5 @@\n-from keras.api_export import keras_export\n-from keras.layers.preprocessing.tf_data_layer import TFDataLayer\n+from keras.src.api_export import keras_export\n+from keras.src.layers.preprocessing.tf_data_layer import TFDataLayer\n \n # mel spectrum constants.\n _MEL_BREAK_FREQUENCY_HERTZ = 700.0\n\n@@ -3,8 +3,8 @@ import pytest\n from absl.testing import parameterized\n from tensorflow import data as tf_data\n \n-from keras import layers\n-from keras import testing\n+from keras.src import layers\n+from keras.src import testing\n \n \n class MelSpectrogramTest(testing.TestCase, parameterized.TestCase):\n\n@@ -1,7 +1,7 @@\n-from keras.api_export import keras_export\n-from keras.backend import KerasTensor\n-from keras.layers.preprocessing.tf_data_layer import TFDataLayer\n-from keras.utils import backend_utils\n+from keras.src.api_export import keras_export\n+from keras.src.backend import KerasTensor\n+from keras.src.layers.preprocessing.tf_data_layer import TFDataLayer\n+from keras.src.utils import backend_utils\n \n \n @keras_export(\"keras.layers.CategoryEncoding\")\n\n@@ -2,9 +2,9 @@ import numpy as np\n from absl.testing import parameterized\n from tensorflow import data as tf_data\n \n-from keras import backend\n-from keras import layers\n-from keras import testing\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n \n TEST_CASES = [{\"testcase_name\": \"dense\", \"sparse\": False}]\n if backend.SUPPORTS_SPARSE_TENSORS:\n\n@@ -1,7 +1,7 @@\n-from keras import backend\n-from keras.api_export import keras_export\n-from keras.layers.preprocessing.tf_data_layer import TFDataLayer\n-from keras.utils import image_utils\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.layers.preprocessing.tf_data_layer import TFDataLayer\n+from keras.src.utils import image_utils\n \n \n @keras_export(\"keras.layers.CenterCrop\")\n\n@@ -3,9 +3,9 @@ import pytest\n from absl.testing import parameterized\n from tensorflow import data as tf_data\n \n-from keras import backend\n-from keras import layers\n-from keras import testing\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n \n \n class CenterCropTest(testing.TestCase, parameterized.TestCase):\n\n@@ -1,11 +1,11 @@\n import numpy as np\n \n-from keras import backend\n-from keras.api_export import keras_export\n-from keras.layers.preprocessing.tf_data_layer import TFDataLayer\n-from keras.utils import argument_validation\n-from keras.utils import numerical_utils\n-from keras.utils.module_utils import tensorflow as tf\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.layers.preprocessing.tf_data_layer import TFDataLayer\n+from keras.src.utils import argument_validation\n+from keras.src.utils import numerical_utils\n+from keras.src.utils.module_utils import tensorflow as tf\n \n \n @keras_export(\"keras.layers.Discretization\")\n\n@@ -5,11 +5,11 @@ import pytest\n from absl.testing import parameterized\n from tensorflow import data as tf_data\n \n-from keras import backend\n-from keras import layers\n-from keras import models\n-from keras import testing\n-from keras.saving import saving_api\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import models\n+from keras.src import testing\n+from keras.src.saving import saving_api\n \n \n class DiscretizationTest(testing.TestCase, parameterized.TestCase):\n@@ -169,7 +169,7 @@ class DiscretizationTest(testing.TestCase, parameterized.TestCase):\n         reason=\"Sparse tensor only works in TensorFlow\",\n     )\n     def test_sparse_output(self, output_mode, input_array, expected_output):\n-        from keras.utils.module_utils import tensorflow as tf\n+        from keras.src.utils.module_utils import tensorflow as tf\n \n         x = np.array(input_array)\n         layer = layers.Discretization(\n\n@@ -1,13 +1,13 @@\n-from keras import backend\n-from keras import layers\n-from keras import tree\n-from keras.api_export import keras_export\n-from keras.layers.layer import Layer\n-from keras.saving import saving_lib\n-from keras.saving import serialization_lib\n-from keras.utils import backend_utils\n-from keras.utils.module_utils import tensorflow as tf\n-from keras.utils.naming import auto_name\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import tree\n+from keras.src.api_export import keras_export\n+from keras.src.layers.layer import Layer\n+from keras.src.saving import saving_lib\n+from keras.src.saving import serialization_lib\n+from keras.src.utils import backend_utils\n+from keras.src.utils.module_utils import tensorflow as tf\n+from keras.src.utils.naming import auto_name\n \n \n class Cross:\n@@ -277,7 +277,7 @@ class FeatureSpace(Layer):\n \n     @classmethod\n     def float(cls, name=None):\n-        from keras.layers.core import identity\n+        from keras.src.layers.core import identity\n \n         name = name or auto_name(\"float\")\n         preprocessor = identity.Identity(\n\n@@ -3,13 +3,13 @@ import os\n import pytest\n from tensorflow import data as tf_data\n \n-from keras import backend\n-from keras import layers\n-from keras import models\n-from keras import ops\n-from keras import testing\n-from keras.layers.preprocessing import feature_space\n-from keras.saving import saving_api\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import models\n+from keras.src import ops\n+from keras.src import testing\n+from keras.src.layers.preprocessing import feature_space\n+from keras.src.saving import saving_api\n \n \n class FeatureSpaceTest(testing.TestCase):\n\n@@ -1,10 +1,10 @@\n-from keras import backend\n-from keras.api_export import keras_export\n-from keras.layers.layer import Layer\n-from keras.utils import argument_validation\n-from keras.utils import backend_utils\n-from keras.utils import tf_utils\n-from keras.utils.module_utils import tensorflow as tf\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.layers.layer import Layer\n+from keras.src.utils import argument_validation\n+from keras.src.utils import backend_utils\n+from keras.src.utils import tf_utils\n+from keras.src.utils.module_utils import tensorflow as tf\n \n \n @keras_export(\"keras.layers.HashedCrossing\")\n\n@@ -2,9 +2,9 @@ import numpy as np\n import pytest\n import tensorflow as tf\n \n-from keras import backend\n-from keras import layers\n-from keras import testing\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n \n \n class HashedCrossingTest(testing.TestCase):\n\n@@ -1,9 +1,9 @@\n-from keras import backend\n-from keras.api_export import keras_export\n-from keras.layers.layer import Layer\n-from keras.utils import backend_utils\n-from keras.utils import tf_utils\n-from keras.utils.module_utils import tensorflow as tf\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.layers.layer import Layer\n+from keras.src.utils import backend_utils\n+from keras.src.utils import tf_utils\n+from keras.src.utils.module_utils import tensorflow as tf\n \n \n @keras_export(\"keras.layers.Hashing\")\n\n@@ -5,11 +5,11 @@ import pytest\n import tensorflow as tf\n from absl.testing import parameterized\n \n-from keras import backend\n-from keras import layers\n-from keras import models\n-from keras import testing\n-from keras.saving import load_model\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import models\n+from keras.src import testing\n+from keras.src.saving import load_model\n \n \n class ArrayLike:\n\n@@ -2,11 +2,11 @@ import collections\n \n import numpy as np\n \n-from keras import backend\n-from keras.layers.layer import Layer\n-from keras.utils import argument_validation\n-from keras.utils import tf_utils\n-from keras.utils.module_utils import tensorflow as tf\n+from keras.src import backend\n+from keras.src.layers.layer import Layer\n+from keras.src.utils import argument_validation\n+from keras.src.utils import tf_utils\n+from keras.src.utils.module_utils import tensorflow as tf\n \n \n class IndexLookup(Layer):\n\n@@ -5,11 +5,11 @@ import pytest\n from absl.testing import parameterized\n from tensorflow import data as tf_data\n \n-from keras import backend\n-from keras import layers\n-from keras import models\n-from keras import testing\n-from keras.saving import saving_api\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import models\n+from keras.src import testing\n+from keras.src.saving import saving_api\n \n \n @pytest.mark.skipif(\n\n@@ -1,10 +1,10 @@\n import numpy as np\n \n-from keras import backend\n-from keras.api_export import keras_export\n-from keras.layers.preprocessing.index_lookup import IndexLookup\n-from keras.utils import backend_utils\n-from keras.utils.module_utils import tensorflow as tf\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.layers.preprocessing.index_lookup import IndexLookup\n+from keras.src.utils import backend_utils\n+from keras.src.utils.module_utils import tensorflow as tf\n \n \n @keras_export(\"keras.layers.IntegerLookup\")\n\n@@ -1,9 +1,9 @@\n import numpy as np\n from tensorflow import data as tf_data\n \n-from keras import backend\n-from keras import layers\n-from keras import testing\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n \n \n class IntegerLookupTest(testing.TestCase):\n\n@@ -2,11 +2,11 @@ import math\n \n import numpy as np\n \n-from keras import backend\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.layers.layer import Layer\n-from keras.utils.module_utils import tensorflow as tf\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.layers.layer import Layer\n+from keras.src.utils.module_utils import tensorflow as tf\n \n \n @keras_export(\"keras.layers.Normalization\")\n\n@@ -3,9 +3,9 @@ import pytest\n from absl.testing import parameterized\n from tensorflow import data as tf_data\n \n-from keras import backend\n-from keras import layers\n-from keras import testing\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n \n \n class NormalizationTest(testing.TestCase, parameterized.TestCase):\n@@ -96,7 +96,7 @@ class NormalizationTest(testing.TestCase, parameterized.TestCase):\n         reason=\"Test symbolic call for torch meta device.\",\n     )\n     def test_call_on_meta_device_after_built(self):\n-        from keras.backend.torch import core\n+        from keras.src.backend.torch import core\n \n         layer = layers.Normalization()\n         data = np.random.random((32, 4))\n\n@@ -1,6 +1,6 @@\n-from keras.api_export import keras_export\n-from keras.layers.preprocessing.tf_data_layer import TFDataLayer\n-from keras.random.seed_generator import SeedGenerator\n+from keras.src.api_export import keras_export\n+from keras.src.layers.preprocessing.tf_data_layer import TFDataLayer\n+from keras.src.random.seed_generator import SeedGenerator\n \n \n @keras_export(\"keras.layers.RandomBrightness\")\n\n@@ -2,9 +2,9 @@ import numpy as np\n import pytest\n from tensorflow import data as tf_data\n \n-from keras import backend\n-from keras import layers\n-from keras import testing\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n \n \n class RandomBrightnessTest(testing.TestCase):\n\n@@ -1,6 +1,6 @@\n-from keras.api_export import keras_export\n-from keras.layers.preprocessing.tf_data_layer import TFDataLayer\n-from keras.random.seed_generator import SeedGenerator\n+from keras.src.api_export import keras_export\n+from keras.src.layers.preprocessing.tf_data_layer import TFDataLayer\n+from keras.src.random.seed_generator import SeedGenerator\n \n \n @keras_export(\"keras.layers.RandomContrast\")\n\n@@ -2,9 +2,9 @@ import numpy as np\n import pytest\n from tensorflow import data as tf_data\n \n-from keras import backend\n-from keras import layers\n-from keras import testing\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n \n \n class RandomContrastTest(testing.TestCase):\n\n@@ -1,8 +1,8 @@\n-from keras import backend\n-from keras.api_export import keras_export\n-from keras.layers.preprocessing.tf_data_layer import TFDataLayer\n-from keras.random.seed_generator import SeedGenerator\n-from keras.utils import image_utils\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.layers.preprocessing.tf_data_layer import TFDataLayer\n+from keras.src.random.seed_generator import SeedGenerator\n+from keras.src.utils import image_utils\n \n \n @keras_export(\"keras.layers.RandomCrop\")\n\n@@ -1,9 +1,9 @@\n import numpy as np\n from tensorflow import data as tf_data\n \n-from keras import backend\n-from keras import layers\n-from keras import testing\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n \n \n class RandomCropTest(testing.TestCase):\n\n@@ -1,6 +1,6 @@\n-from keras.api_export import keras_export\n-from keras.layers.preprocessing.tf_data_layer import TFDataLayer\n-from keras.random.seed_generator import SeedGenerator\n+from keras.src.api_export import keras_export\n+from keras.src.layers.preprocessing.tf_data_layer import TFDataLayer\n+from keras.src.random.seed_generator import SeedGenerator\n \n HORIZONTAL = \"horizontal\"\n VERTICAL = \"vertical\"\n\n@@ -4,10 +4,10 @@ import numpy as np\n from absl.testing import parameterized\n from tensorflow import data as tf_data\n \n-from keras import backend\n-from keras import layers\n-from keras import testing\n-from keras import utils\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n+from keras.src import utils\n \n \n class MockedRandomFlip(layers.RandomFlip):\n\n@@ -1,9 +1,9 @@\n import numpy as np\n \n-from keras import backend\n-from keras.api_export import keras_export\n-from keras.layers.preprocessing.tf_data_layer import TFDataLayer\n-from keras.random.seed_generator import SeedGenerator\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.layers.preprocessing.tf_data_layer import TFDataLayer\n+from keras.src.random.seed_generator import SeedGenerator\n \n \n @keras_export(\"keras.layers.RandomRotation\")\n\n@@ -2,9 +2,9 @@ import numpy as np\n from absl.testing import parameterized\n from tensorflow import data as tf_data\n \n-from keras import backend\n-from keras import layers\n-from keras import testing\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n \n \n class RandomRotationTest(testing.TestCase, parameterized.TestCase):\n\n@@ -1,7 +1,7 @@\n-from keras import backend\n-from keras.api_export import keras_export\n-from keras.layers.preprocessing.tf_data_layer import TFDataLayer\n-from keras.random.seed_generator import SeedGenerator\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.layers.preprocessing.tf_data_layer import TFDataLayer\n+from keras.src.random.seed_generator import SeedGenerator\n \n \n @keras_export(\"keras.layers.RandomTranslation\")\n\n@@ -2,9 +2,9 @@ import numpy as np\n from absl.testing import parameterized\n from tensorflow import data as tf_data\n \n-from keras import backend\n-from keras import layers\n-from keras import testing\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n \n \n class RandomTranslationTest(testing.TestCase, parameterized.TestCase):\n\n@@ -1,7 +1,7 @@\n-from keras import backend\n-from keras.api_export import keras_export\n-from keras.layers.preprocessing.tf_data_layer import TFDataLayer\n-from keras.random.seed_generator import SeedGenerator\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.layers.preprocessing.tf_data_layer import TFDataLayer\n+from keras.src.random.seed_generator import SeedGenerator\n \n \n @keras_export(\"keras.layers.RandomZoom\")\n\n@@ -3,10 +3,10 @@ import pytest\n from absl.testing import parameterized\n from tensorflow import data as tf_data\n \n-from keras import backend\n-from keras import layers\n-from keras import models\n-from keras import testing\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import models\n+from keras.src import testing\n \n \n class RandomZoomTest(testing.TestCase, parameterized.TestCase):\n\n@@ -1,6 +1,6 @@\n-from keras import backend\n-from keras.api_export import keras_export\n-from keras.layers.preprocessing.tf_data_layer import TFDataLayer\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.layers.preprocessing.tf_data_layer import TFDataLayer\n \n \n @keras_export(\"keras.layers.Rescaling\")\n\n@@ -2,9 +2,9 @@ import numpy as np\n import pytest\n from tensorflow import data as tf_data\n \n-from keras import backend\n-from keras import layers\n-from keras import testing\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n \n \n class RescalingTest(testing.TestCase):\n\n@@ -1,6 +1,6 @@\n-from keras import backend\n-from keras.api_export import keras_export\n-from keras.layers.preprocessing.tf_data_layer import TFDataLayer\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.layers.preprocessing.tf_data_layer import TFDataLayer\n \n \n @keras_export(\"keras.layers.Resizing\")\n\n@@ -3,10 +3,10 @@ import pytest\n from absl.testing import parameterized\n from tensorflow import data as tf_data\n \n-from keras import Sequential\n-from keras import backend\n-from keras import layers\n-from keras import testing\n+from keras.src import Sequential\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n \n \n class ResizingTest(testing.TestCase, parameterized.TestCase):\n\n@@ -1,10 +1,10 @@\n import numpy as np\n \n-from keras import backend\n-from keras.api_export import keras_export\n-from keras.layers.preprocessing.index_lookup import IndexLookup\n-from keras.utils import backend_utils\n-from keras.utils.module_utils import tensorflow as tf\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.layers.preprocessing.index_lookup import IndexLookup\n+from keras.src.utils import backend_utils\n+from keras.src.utils.module_utils import tensorflow as tf\n \n \n @keras_export(\"keras.layers.StringLookup\")\n\n@@ -1,9 +1,9 @@\n import numpy as np\n from tensorflow import data as tf_data\n \n-from keras import backend\n-from keras import layers\n-from keras import testing\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n \n \n class StringLookupTest(testing.TestCase):\n\n@@ -1,15 +1,15 @@\n import numpy as np\n \n-from keras import backend\n-from keras.api_export import keras_export\n-from keras.layers.layer import Layer\n-from keras.layers.preprocessing.index_lookup import listify_tensors\n-from keras.layers.preprocessing.string_lookup import StringLookup\n-from keras.saving import serialization_lib\n-from keras.utils import argument_validation\n-from keras.utils import backend_utils\n-from keras.utils import tf_utils\n-from keras.utils.module_utils import tensorflow as tf\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.layers.layer import Layer\n+from keras.src.layers.preprocessing.index_lookup import listify_tensors\n+from keras.src.layers.preprocessing.string_lookup import StringLookup\n+from keras.src.saving import serialization_lib\n+from keras.src.utils import argument_validation\n+from keras.src.utils import backend_utils\n+from keras.src.utils import tf_utils\n+from keras.src.utils.module_utils import tensorflow as tf\n \n \n @keras_export(\"keras.layers.TextVectorization\")\n\n@@ -5,12 +5,12 @@ import pytest\n import tensorflow as tf\n from tensorflow import data as tf_data\n \n-from keras import Sequential\n-from keras import backend\n-from keras import layers\n-from keras import models\n-from keras import saving\n-from keras import testing\n+from keras.src import Sequential\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import models\n+from keras.src import saving\n+from keras.src import testing\n \n \n class TextVectorizationTest(testing.TestCase):\n\n@@ -1,9 +1,9 @@\n-import keras.backend\n-from keras import tree\n-from keras.layers.layer import Layer\n-from keras.random.seed_generator import SeedGenerator\n-from keras.utils import backend_utils\n-from keras.utils import tracking\n+import keras.src.backend\n+from keras.src import tree\n+from keras.src.layers.layer import Layer\n+from keras.src.random.seed_generator import SeedGenerator\n+from keras.src.utils import backend_utils\n+from keras.src.utils import tracking\n \n \n class TFDataLayer(Layer):\n\n\n@@ -1,6 +1,6 @@\n-from keras import regularizers\n-from keras.api_export import keras_export\n-from keras.layers.layer import Layer\n+from keras.src import regularizers\n+from keras.src.api_export import keras_export\n+from keras.src.layers.layer import Layer\n \n \n @keras_export(\"keras.layers.ActivityRegularization\")\n\n@@ -1,8 +1,8 @@\n import numpy as np\n import pytest\n \n-from keras import layers\n-from keras.testing import test_case\n+from keras.src import layers\n+from keras.src.testing import test_case\n \n \n class ActivityRegularizationTest(test_case.TestCase):\n\n@@ -1,7 +1,7 @@\n-from keras import backend\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.layers.layer import Layer\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.layers.layer import Layer\n \n \n @keras_export(\"keras.layers.AlphaDropout\")\n\n@@ -1,9 +1,9 @@\n import numpy as np\n import pytest\n \n-from keras import backend\n-from keras import layers\n-from keras import testing\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n \n \n class AlphaDropoutTest(testing.TestCase):\n\n@@ -1,6 +1,6 @@\n-from keras import backend\n-from keras.api_export import keras_export\n-from keras.layers.layer import Layer\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.layers.layer import Layer\n \n \n @keras_export(\"keras.layers.Dropout\")\n\n@@ -1,9 +1,9 @@\n import numpy as np\n import pytest\n \n-from keras import backend\n-from keras import layers\n-from keras import testing\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n \n \n class DropoutTest(testing.TestCase):\n\n@@ -1,9 +1,9 @@\n import math\n \n-from keras import backend\n-from keras import layers\n-from keras import ops\n-from keras.api_export import keras_export\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n \n \n @keras_export(\"keras.layers.GaussianDropout\")\n\n@@ -1,9 +1,9 @@\n import numpy as np\n import pytest\n \n-from keras import backend\n-from keras import layers\n-from keras import testing\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n \n \n class GaussianDropoutTest(testing.TestCase):\n\n@@ -1,7 +1,7 @@\n-from keras import backend\n-from keras import layers\n-from keras import ops\n-from keras.api_export import keras_export\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n \n \n @keras_export(\"keras.layers.GaussianNoise\")\n\n@@ -1,9 +1,9 @@\n import numpy as np\n import pytest\n \n-from keras import backend\n-from keras import layers\n-from keras import testing\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n \n \n class GaussianNoiseTest(testing.TestCase):\n\n@@ -1,8 +1,8 @@\n-from keras import backend\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.layers.input_spec import InputSpec\n-from keras.layers.regularization.dropout import Dropout\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.layers.input_spec import InputSpec\n+from keras.src.layers.regularization.dropout import Dropout\n \n \n class BaseSpatialDropout(Dropout):\n\n@@ -1,9 +1,9 @@\n import numpy as np\n import pytest\n \n-from keras import backend\n-from keras import layers\n-from keras.testing import test_case\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src.testing import test_case\n \n \n class SpatialDropoutTest(test_case.TestCase):\n\n\n@@ -1,7 +1,7 @@\n-from keras.api_export import keras_export\n-from keras.layers.input_spec import InputSpec\n-from keras.layers.layer import Layer\n-from keras.utils import argument_validation\n+from keras.src.api_export import keras_export\n+from keras.src.layers.input_spec import InputSpec\n+from keras.src.layers.layer import Layer\n+from keras.src.utils import argument_validation\n \n \n @keras_export(\"keras.layers.Cropping1D\")\n\n@@ -1,9 +1,9 @@\n import numpy as np\n import pytest\n \n-from keras import layers\n-from keras import ops\n-from keras import testing\n+from keras.src import layers\n+from keras.src import ops\n+from keras.src import testing\n \n \n class Cropping1DTest(testing.TestCase):\n\n@@ -1,8 +1,8 @@\n-from keras import backend\n-from keras.api_export import keras_export\n-from keras.layers.input_spec import InputSpec\n-from keras.layers.layer import Layer\n-from keras.utils import argument_validation\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.layers.input_spec import InputSpec\n+from keras.src.layers.layer import Layer\n+from keras.src.utils import argument_validation\n \n \n @keras_export(\"keras.layers.Cropping2D\")\n\n@@ -2,10 +2,10 @@ import numpy as np\n import pytest\n from absl.testing import parameterized\n \n-from keras import backend\n-from keras import layers\n-from keras import ops\n-from keras import testing\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import ops\n+from keras.src import testing\n \n \n class Cropping2DTest(testing.TestCase, parameterized.TestCase):\n\n@@ -1,8 +1,8 @@\n-from keras import backend\n-from keras.api_export import keras_export\n-from keras.layers.input_spec import InputSpec\n-from keras.layers.layer import Layer\n-from keras.utils import argument_validation\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.layers.input_spec import InputSpec\n+from keras.src.layers.layer import Layer\n+from keras.src.utils import argument_validation\n \n \n @keras_export(\"keras.layers.Cropping3D\")\n\n@@ -2,10 +2,10 @@ import numpy as np\n import pytest\n from absl.testing import parameterized\n \n-from keras import backend\n-from keras import layers\n-from keras import ops\n-from keras import testing\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import ops\n+from keras.src import testing\n \n \n class Cropping3DTest(testing.TestCase, parameterized.TestCase):\n\n@@ -1,11 +1,11 @@\n import math\n \n-from keras import backend\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.backend.common.keras_tensor import KerasTensor\n-from keras.layers.input_spec import InputSpec\n-from keras.layers.layer import Layer\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.backend.common.keras_tensor import KerasTensor\n+from keras.src.layers.input_spec import InputSpec\n+from keras.src.layers.layer import Layer\n \n \n @keras_export(\"keras.layers.Flatten\")\n\n@@ -2,10 +2,10 @@ import numpy as np\n import pytest\n from absl.testing import parameterized\n \n-from keras import backend\n-from keras import layers\n-from keras import ops\n-from keras import testing\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import ops\n+from keras.src import testing\n \n \n class FlattenTest(testing.TestCase, parameterized.TestCase):\n\n@@ -1,8 +1,8 @@\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.backend.common.keras_tensor import KerasTensor\n-from keras.layers.input_spec import InputSpec\n-from keras.layers.layer import Layer\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.backend.common.keras_tensor import KerasTensor\n+from keras.src.layers.input_spec import InputSpec\n+from keras.src.layers.layer import Layer\n \n \n @keras_export(\"keras.layers.Permute\")\n\n@@ -2,10 +2,10 @@ import numpy as np\n import pytest\n from absl.testing import parameterized\n \n-from keras import backend\n-from keras import layers\n-from keras import ops\n-from keras import testing\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import ops\n+from keras.src import testing\n \n \n class PermuteTest(testing.TestCase, parameterized.TestCase):\n\n@@ -1,7 +1,7 @@\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.layers.input_spec import InputSpec\n-from keras.layers.layer import Layer\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.layers.input_spec import InputSpec\n+from keras.src.layers.layer import Layer\n \n \n @keras_export(\"keras.layers.RepeatVector\")\n\n@@ -1,9 +1,9 @@\n import numpy as np\n import pytest\n \n-from keras import layers\n-from keras import ops\n-from keras import testing\n+from keras.src import layers\n+from keras.src import ops\n+from keras.src import testing\n \n \n class FlattenTest(testing.TestCase):\n\n@@ -1,8 +1,8 @@\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.backend.common.keras_tensor import KerasTensor\n-from keras.layers.layer import Layer\n-from keras.ops import operation_utils\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.backend.common.keras_tensor import KerasTensor\n+from keras.src.layers.layer import Layer\n+from keras.src.ops import operation_utils\n \n \n @keras_export(\"keras.layers.Reshape\")\n\n@@ -1,10 +1,10 @@\n import pytest\n from absl.testing import parameterized\n \n-from keras import backend\n-from keras import layers\n-from keras import testing\n-from keras.backend.common.keras_tensor import KerasTensor\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n+from keras.src.backend.common.keras_tensor import KerasTensor\n \n \n class ReshapeTest(testing.TestCase, parameterized.TestCase):\n\n@@ -1,7 +1,7 @@\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.layers.input_spec import InputSpec\n-from keras.layers.layer import Layer\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.layers.input_spec import InputSpec\n+from keras.src.layers.layer import Layer\n \n \n @keras_export(\"keras.layers.UpSampling1D\")\n\n@@ -1,9 +1,9 @@\n import numpy as np\n import pytest\n \n-from keras import layers\n-from keras import testing\n-from keras.backend.common.keras_tensor import KerasTensor\n+from keras.src import layers\n+from keras.src import testing\n+from keras.src.backend.common.keras_tensor import KerasTensor\n \n \n class UpSamplingTest(testing.TestCase):\n\n@@ -1,9 +1,9 @@\n-from keras import backend\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.layers.input_spec import InputSpec\n-from keras.layers.layer import Layer\n-from keras.utils import argument_validation\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.layers.input_spec import InputSpec\n+from keras.src.layers.layer import Layer\n+from keras.src.utils import argument_validation\n \n \n @keras_export(\"keras.layers.UpSampling2D\")\n\n@@ -3,9 +3,9 @@ import numpy as np\n import pytest\n from absl.testing import parameterized\n \n-from keras import backend\n-from keras import layers\n-from keras import testing\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n \n \n class UpSampling2dTest(testing.TestCase, parameterized.TestCase):\n\n@@ -1,9 +1,9 @@\n-from keras import backend\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.layers.input_spec import InputSpec\n-from keras.layers.layer import Layer\n-from keras.utils import argument_validation\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.layers.input_spec import InputSpec\n+from keras.src.layers.layer import Layer\n+from keras.src.utils import argument_validation\n \n \n @keras_export(\"keras.layers.UpSampling3D\")\n\n@@ -2,9 +2,9 @@ import numpy as np\n import pytest\n from absl.testing import parameterized\n \n-from keras import backend\n-from keras import layers\n-from keras import testing\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n \n \n class UpSampling3dTest(testing.TestCase, parameterized.TestCase):\n\n@@ -1,8 +1,8 @@\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.layers.input_spec import InputSpec\n-from keras.layers.layer import Layer\n-from keras.utils import argument_validation\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.layers.input_spec import InputSpec\n+from keras.src.layers.layer import Layer\n+from keras.src.utils import argument_validation\n \n \n @keras_export(\"keras.layers.ZeroPadding1D\")\n\n@@ -1,8 +1,8 @@\n import numpy as np\n from absl.testing import parameterized\n \n-from keras import layers\n-from keras import testing\n+from keras.src import layers\n+from keras.src import testing\n \n \n class ZeroPadding1DTest(testing.TestCase, parameterized.TestCase):\n\n@@ -1,9 +1,9 @@\n-from keras import backend\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.layers.input_spec import InputSpec\n-from keras.layers.layer import Layer\n-from keras.utils import argument_validation\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.layers.input_spec import InputSpec\n+from keras.src.layers.layer import Layer\n+from keras.src.utils import argument_validation\n \n \n @keras_export(\"keras.layers.ZeroPadding2D\")\n\n@@ -1,9 +1,9 @@\n import numpy as np\n from absl.testing import parameterized\n \n-from keras import backend\n-from keras import layers\n-from keras import testing\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n \n \n class ZeroPadding2DTest(testing.TestCase, parameterized.TestCase):\n\n@@ -1,9 +1,9 @@\n-from keras import backend\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.layers.input_spec import InputSpec\n-from keras.layers.layer import Layer\n-from keras.utils import argument_validation\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.layers.input_spec import InputSpec\n+from keras.src.layers.layer import Layer\n+from keras.src.utils import argument_validation\n \n \n @keras_export(\"keras.layers.ZeroPadding3D\")\n\n@@ -1,9 +1,9 @@\n import numpy as np\n from absl.testing import parameterized\n \n-from keras import backend\n-from keras import layers\n-from keras import testing\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n \n \n class ZeroPadding3DTest(testing.TestCase, parameterized.TestCase):\n\n\n@@ -1,11 +1,11 @@\n import copy\n \n-from keras import ops\n-from keras import utils\n-from keras.api_export import keras_export\n-from keras.layers.core.wrapper import Wrapper\n-from keras.layers.layer import Layer\n-from keras.saving import serialization_lib\n+from keras.src import ops\n+from keras.src import utils\n+from keras.src.api_export import keras_export\n+from keras.src.layers.core.wrapper import Wrapper\n+from keras.src.layers.layer import Layer\n+from keras.src.saving import serialization_lib\n \n \n @keras_export(\"keras.layers.Bidirectional\")\n\n@@ -1,9 +1,9 @@\n import numpy as np\n import pytest\n \n-from keras import initializers\n-from keras import layers\n-from keras import testing\n+from keras.src import initializers\n+from keras.src import layers\n+from keras.src import testing\n \n \n class SimpleRNNTest(testing.TestCase):\n\n@@ -1,16 +1,16 @@\n-from keras import activations\n-from keras import backend\n-from keras import constraints\n-from keras import initializers\n-from keras import ops\n-from keras import regularizers\n-from keras import tree\n-from keras.layers.input_spec import InputSpec\n-from keras.layers.layer import Layer\n-from keras.layers.rnn.dropout_rnn_cell import DropoutRNNCell\n-from keras.layers.rnn.rnn import RNN\n-from keras.ops import operation_utils\n-from keras.utils import argument_validation\n+from keras.src import activations\n+from keras.src import backend\n+from keras.src import constraints\n+from keras.src import initializers\n+from keras.src import ops\n+from keras.src import regularizers\n+from keras.src import tree\n+from keras.src.layers.input_spec import InputSpec\n+from keras.src.layers.layer import Layer\n+from keras.src.layers.rnn.dropout_rnn_cell import DropoutRNNCell\n+from keras.src.layers.rnn.rnn import RNN\n+from keras.src.ops import operation_utils\n+from keras.src.utils import argument_validation\n \n \n class ConvLSTMCell(Layer, DropoutRNNCell):\n\n@@ -1,5 +1,5 @@\n-from keras.api_export import keras_export\n-from keras.layers.rnn.conv_lstm import ConvLSTM\n+from keras.src.api_export import keras_export\n+from keras.src.layers.rnn.conv_lstm import ConvLSTM\n \n \n @keras_export(\"keras.layers.ConvLSTM1D\")\n\n@@ -1,10 +1,10 @@\n import numpy as np\n import pytest\n \n-from keras import backend\n-from keras import initializers\n-from keras import layers\n-from keras import testing\n+from keras.src import backend\n+from keras.src import initializers\n+from keras.src import layers\n+from keras.src import testing\n \n \n class ConvLSTM1DTest(testing.TestCase):\n\n@@ -1,5 +1,5 @@\n-from keras.api_export import keras_export\n-from keras.layers.rnn.conv_lstm import ConvLSTM\n+from keras.src.api_export import keras_export\n+from keras.src.layers.rnn.conv_lstm import ConvLSTM\n \n \n @keras_export(\"keras.layers.ConvLSTM2D\")\n\n@@ -1,10 +1,10 @@\n import numpy as np\n import pytest\n \n-from keras import backend\n-from keras import initializers\n-from keras import layers\n-from keras import testing\n+from keras.src import backend\n+from keras.src import initializers\n+from keras.src import layers\n+from keras.src import testing\n \n \n class ConvLSTM2DTest(testing.TestCase):\n\n@@ -1,5 +1,5 @@\n-from keras.api_export import keras_export\n-from keras.layers.rnn.conv_lstm import ConvLSTM\n+from keras.src.api_export import keras_export\n+from keras.src.layers.rnn.conv_lstm import ConvLSTM\n \n \n @keras_export(\"keras.layers.ConvLSTM3D\")\n\n@@ -1,10 +1,10 @@\n import numpy as np\n import pytest\n \n-from keras import backend\n-from keras import initializers\n-from keras import layers\n-from keras import testing\n+from keras.src import backend\n+from keras.src import initializers\n+from keras.src import layers\n+from keras.src import testing\n \n \n class ConvLSTM1DTest(testing.TestCase):\n\n@@ -1,10 +1,10 @@\n import numpy as np\n \n-from keras import backend\n-from keras import initializers\n-from keras import testing\n-from keras.layers.rnn.conv_lstm import ConvLSTM\n-from keras.layers.rnn.conv_lstm import ConvLSTMCell\n+from keras.src import backend\n+from keras.src import initializers\n+from keras.src import testing\n+from keras.src.layers.rnn.conv_lstm import ConvLSTM\n+from keras.src.layers.rnn.conv_lstm import ConvLSTMCell\n \n \n class ConvLSTMCellTest(testing.TestCase):\n\n@@ -1,5 +1,5 @@\n-from keras import backend\n-from keras import ops\n+from keras.src import backend\n+from keras.src import ops\n \n \n class DropoutRNNCell:\n\n@@ -1,10 +1,10 @@\n import pytest\n \n-from keras import backend\n-from keras import layers\n-from keras import ops\n-from keras import testing\n-from keras.layers.rnn.dropout_rnn_cell import DropoutRNNCell\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import ops\n+from keras.src import testing\n+from keras.src.layers.rnn.dropout_rnn_cell import DropoutRNNCell\n \n \n class RNNCellWithDropout(layers.Layer, DropoutRNNCell):\n\n@@ -1,15 +1,15 @@\n-from keras import activations\n-from keras import backend\n-from keras import constraints\n-from keras import initializers\n-from keras import ops\n-from keras import regularizers\n-from keras import tree\n-from keras.api_export import keras_export\n-from keras.layers.input_spec import InputSpec\n-from keras.layers.layer import Layer\n-from keras.layers.rnn.dropout_rnn_cell import DropoutRNNCell\n-from keras.layers.rnn.rnn import RNN\n+from keras.src import activations\n+from keras.src import backend\n+from keras.src import constraints\n+from keras.src import initializers\n+from keras.src import ops\n+from keras.src import regularizers\n+from keras.src import tree\n+from keras.src.api_export import keras_export\n+from keras.src.layers.input_spec import InputSpec\n+from keras.src.layers.layer import Layer\n+from keras.src.layers.rnn.dropout_rnn_cell import DropoutRNNCell\n+from keras.src.layers.rnn.rnn import RNN\n \n \n @keras_export(\"keras.layers.GRUCell\")\n\n@@ -2,9 +2,9 @@ import numpy as np\n import pytest\n from absl.testing import parameterized\n \n-from keras import initializers\n-from keras import layers\n-from keras import testing\n+from keras.src import initializers\n+from keras.src import layers\n+from keras.src import testing\n \n \n class GRUTest(testing.TestCase, parameterized.TestCase):\n\n@@ -1,15 +1,15 @@\n-from keras import activations\n-from keras import backend\n-from keras import constraints\n-from keras import initializers\n-from keras import ops\n-from keras import regularizers\n-from keras import tree\n-from keras.api_export import keras_export\n-from keras.layers.input_spec import InputSpec\n-from keras.layers.layer import Layer\n-from keras.layers.rnn.dropout_rnn_cell import DropoutRNNCell\n-from keras.layers.rnn.rnn import RNN\n+from keras.src import activations\n+from keras.src import backend\n+from keras.src import constraints\n+from keras.src import initializers\n+from keras.src import ops\n+from keras.src import regularizers\n+from keras.src import tree\n+from keras.src.api_export import keras_export\n+from keras.src.layers.input_spec import InputSpec\n+from keras.src.layers.layer import Layer\n+from keras.src.layers.rnn.dropout_rnn_cell import DropoutRNNCell\n+from keras.src.layers.rnn.rnn import RNN\n \n \n @keras_export(\"keras.layers.LSTMCell\")\n\n@@ -2,9 +2,9 @@ import numpy as np\n import pytest\n from absl.testing import parameterized\n \n-from keras import initializers\n-from keras import layers\n-from keras import testing\n+from keras.src import initializers\n+from keras.src import layers\n+from keras.src import testing\n \n \n class LSTMTest(testing.TestCase, parameterized.TestCase):\n\n@@ -1,12 +1,12 @@\n-from keras import backend\n-from keras import ops\n-from keras import tree\n-from keras.api_export import keras_export\n-from keras.layers.layer import Layer\n-from keras.layers.rnn.dropout_rnn_cell import DropoutRNNCell\n-from keras.layers.rnn.stacked_rnn_cells import StackedRNNCells\n-from keras.saving import serialization_lib\n-from keras.utils import tracking\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src import tree\n+from keras.src.api_export import keras_export\n+from keras.src.layers.layer import Layer\n+from keras.src.layers.rnn.dropout_rnn_cell import DropoutRNNCell\n+from keras.src.layers.rnn.stacked_rnn_cells import StackedRNNCells\n+from keras.src.saving import serialization_lib\n+from keras.src.utils import tracking\n \n \n @keras_export(\"keras.layers.RNN\")\n@@ -133,8 +133,8 @@ class RNN(Layer):\n     Examples:\n \n     ```python\n-    from keras.layers import RNN\n-    from keras import ops\n+    from keras.src.layers import RNN\n+    from keras.src import ops\n \n     # First, let's define a RNN Cell, as a layer subclass.\n     class MinimalRNNCell(keras.layers.Layer):\n\n@@ -1,9 +1,9 @@\n import numpy as np\n import pytest\n \n-from keras import layers\n-from keras import ops\n-from keras import testing\n+from keras.src import layers\n+from keras.src import ops\n+from keras.src import testing\n \n \n class OneStateRNNCell(layers.Layer):\n\n@@ -1,14 +1,14 @@\n-from keras import activations\n-from keras import backend\n-from keras import constraints\n-from keras import initializers\n-from keras import ops\n-from keras import regularizers\n-from keras.api_export import keras_export\n-from keras.layers.input_spec import InputSpec\n-from keras.layers.layer import Layer\n-from keras.layers.rnn.dropout_rnn_cell import DropoutRNNCell\n-from keras.layers.rnn.rnn import RNN\n+from keras.src import activations\n+from keras.src import backend\n+from keras.src import constraints\n+from keras.src import initializers\n+from keras.src import ops\n+from keras.src import regularizers\n+from keras.src.api_export import keras_export\n+from keras.src.layers.input_spec import InputSpec\n+from keras.src.layers.layer import Layer\n+from keras.src.layers.rnn.dropout_rnn_cell import DropoutRNNCell\n+from keras.src.layers.rnn.rnn import RNN\n \n \n @keras_export(\"keras.layers.SimpleRNNCell\")\n\n@@ -1,9 +1,9 @@\n import numpy as np\n import pytest\n \n-from keras import initializers\n-from keras import layers\n-from keras import testing\n+from keras.src import initializers\n+from keras.src import layers\n+from keras.src import testing\n \n \n class SimpleRNNTest(testing.TestCase):\n\n@@ -1,8 +1,8 @@\n-from keras import ops\n-from keras import tree\n-from keras.api_export import keras_export\n-from keras.layers.layer import Layer\n-from keras.saving import serialization_lib\n+from keras.src import ops\n+from keras.src import tree\n+from keras.src.api_export import keras_export\n+from keras.src.layers.layer import Layer\n+from keras.src.saving import serialization_lib\n \n \n @keras_export(\"keras.layers.StackedRNNCells\")\n\n@@ -1,10 +1,10 @@\n import numpy as np\n import pytest\n \n-from keras import layers\n-from keras import testing\n-from keras.layers.rnn.rnn_test import OneStateRNNCell\n-from keras.layers.rnn.rnn_test import TwoStatesRNNCell\n+from keras.src import layers\n+from keras.src import testing\n+from keras.src.layers.rnn.rnn_test import OneStateRNNCell\n+from keras.src.layers.rnn.rnn_test import TwoStatesRNNCell\n \n \n class StackedRNNTest(testing.TestCase):\n\n@@ -1,10 +1,10 @@\n \"\"\"Wrapper layer to apply every temporal slice of an input.\"\"\"\n \n-from keras import backend\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.layers.core.wrapper import Wrapper\n-from keras.layers.layer import Layer\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.layers.core.wrapper import Wrapper\n+from keras.src.layers.layer import Layer\n \n \n @keras_export(\"keras.layers.TimeDistributed\")\n\n@@ -1,11 +1,11 @@\n import numpy as np\n import pytest\n \n-from keras import backend\n-from keras import initializers\n-from keras import layers\n-from keras import ops\n-from keras import testing\n+from keras.src import backend\n+from keras.src import initializers\n+from keras.src import layers\n+from keras.src import ops\n+from keras.src import testing\n \n \n class TimeDistributedTest(testing.TestCase):\n\n\n@@ -4,9 +4,9 @@ import itertools\n \n import numpy as np\n \n-from keras import backend\n-from keras.api_export import keras_export\n-from keras.utils.module_utils import tensorflow as tf\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.utils.module_utils import tensorflow as tf\n \n py_any = any\n py_all = all\n\n@@ -6,10 +6,10 @@ RandomWidth\n ThresholdedReLU\n \"\"\"\n \n-from keras import backend\n-from keras.api_export import keras_export\n-from keras.layers.layer import Layer\n-from keras.utils.module_utils import tensorflow as tf\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.layers.layer import Layer\n+from keras.src.utils.module_utils import tensorflow as tf\n \n \n @keras_export(\"keras._legacy.layers.AlphaDropout\")\n\n@@ -1,4 +1,4 @@\n-from keras.api_export import keras_export\n+from keras.src.api_export import keras_export\n \n \n @keras_export(\"keras._legacy.losses.Reduction\")\n\n\n@@ -8,12 +8,12 @@ import warnings\n \n import numpy as np\n \n-from keras import backend\n-from keras.api_export import keras_export\n-from keras.trainers.data_adapters.py_dataset_adapter import PyDataset\n-from keras.utils import image_utils\n-from keras.utils import io_utils\n-from keras.utils.module_utils import scipy\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.trainers.data_adapters.py_dataset_adapter import PyDataset\n+from keras.src.utils import image_utils\n+from keras.src.utils import io_utils\n+from keras.src.utils.module_utils import scipy\n \n \n @keras_export(\"keras._legacy.preprocessing.image.Iterator\")\n\n@@ -5,8 +5,8 @@ import random\n \n import numpy as np\n \n-from keras.api_export import keras_export\n-from keras.trainers.data_adapters.py_dataset_adapter import PyDataset\n+from keras.src.api_export import keras_export\n+from keras.src.trainers.data_adapters.py_dataset_adapter import PyDataset\n \n \n @keras_export(\"keras._legacy.preprocessing.sequence.TimeseriesGenerator\")\n\n@@ -7,7 +7,7 @@ import warnings\n \n import numpy as np\n \n-from keras.api_export import keras_export\n+from keras.src.api_export import keras_export\n \n \n @keras_export(\"keras._legacy.preprocessing.text.text_to_word_sequence\")\n\n\n@@ -7,9 +7,9 @@ import json\n \n import numpy as np\n \n-from keras.legacy.saving import serialization\n-from keras.saving import serialization_lib\n-from keras.utils.module_utils import tensorflow as tf\n+from keras.src.legacy.saving import serialization\n+from keras.src.saving import serialization_lib\n+from keras.src.utils.module_utils import tensorflow as tf\n \n _EXTENSION_TYPE_SPEC = \"_EXTENSION_TYPE_SPEC\"\n \n\n@@ -2,9 +2,9 @@ import enum\n \n import pytest\n \n-from keras import backend\n-from keras import testing\n-from keras.legacy.saving import json_utils\n+from keras.src import backend\n+from keras.src import testing\n+from keras.src.legacy.saving import json_utils\n \n if backend.backend() == \"tensorflow\":\n     import tensorflow as tf\n\n@@ -5,14 +5,14 @@ import warnings\n import numpy as np\n from absl import logging\n \n-from keras import backend\n-from keras import optimizers\n-from keras.backend.common import global_state\n-from keras.legacy.saving import json_utils\n-from keras.legacy.saving import saving_options\n-from keras.legacy.saving import saving_utils\n-from keras.saving import object_registration\n-from keras.utils import io_utils\n+from keras.src import backend\n+from keras.src import optimizers\n+from keras.src.backend.common import global_state\n+from keras.src.legacy.saving import json_utils\n+from keras.src.legacy.saving import saving_options\n+from keras.src.legacy.saving import saving_utils\n+from keras.src.saving import object_registration\n+from keras.src.utils import io_utils\n \n try:\n     import h5py\n@@ -200,7 +200,7 @@ def save_weights_to_hdf5_group(f, model):\n         f: HDF5 group.\n         model: Model instance.\n     \"\"\"\n-    from keras import __version__ as keras_version\n+    from keras.src import __version__ as keras_version\n \n     save_attributes_to_hdf5_group(\n         f, \"layer_names\", [layer.name.encode(\"utf8\") for layer in model.layers]\n\n@@ -4,13 +4,13 @@ import numpy as np\n import pytest\n \n import keras\n-from keras import layers\n-from keras import models\n-from keras import ops\n-from keras import testing\n-from keras.legacy.saving import legacy_h5_format\n-from keras.saving import object_registration\n-from keras.saving import serialization_lib\n+from keras.src import layers\n+from keras.src import models\n+from keras.src import ops\n+from keras.src import testing\n+from keras.src.legacy.saving import legacy_h5_format\n+from keras.src.saving import object_registration\n+from keras.src.saving import serialization_lib\n \n # TODO: more thorough testing. Correctness depends\n # on exact weight ordering for each layer, so we need\n@@ -233,7 +233,7 @@ class LegacyH5WholeModelTest(testing.TestCase):\n         )\n         model = models.Sequential([layer])\n         with self.subTest(\"test_JSON\"):\n-            from keras.models.model import model_from_json\n+            from keras.src.models.model import model_from_json\n \n             model_json = model.to_json()\n             self.assertIn(\"Foo>RegisteredSubLayer\", model_json)\n\n@@ -1,6 +1,6 @@\n import contextlib\n \n-from keras.backend.common import global_state\n+from keras.src.backend.common import global_state\n \n \n @contextlib.contextmanager\n\n@@ -3,15 +3,15 @@ import threading\n \n from absl import logging\n \n-from keras import backend\n-from keras import layers\n-from keras import losses\n-from keras import metrics as metrics_module\n-from keras import models\n-from keras import optimizers\n-from keras import tree\n-from keras.legacy.saving import serialization\n-from keras.saving import object_registration\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import losses\n+from keras.src import metrics as metrics_module\n+from keras.src import models\n+from keras.src import optimizers\n+from keras.src import tree\n+from keras.src.legacy.saving import serialization\n+from keras.src.saving import object_registration\n \n MODULE_OBJECTS = threading.local()\n \n@@ -92,7 +92,7 @@ def model_from_config(config, custom_objects=None):\n \n def model_metadata(model, include_optimizer=True, require_config=True):\n     \"\"\"Returns a dictionary containing the model metadata.\"\"\"\n-    from keras import __version__ as keras_version\n+    from keras.src import __version__ as keras_version\n \n     model_config = {\"class_name\": model.__class__.__name__}\n     try:\n\n@@ -7,8 +7,8 @@ import threading\n import weakref\n \n # isort: off\n-from keras.api_export import keras_export\n-from keras.saving import object_registration\n+from keras.src.api_export import keras_export\n+from keras.src.saving import object_registration\n \n # Flag that determines whether to skip the NotImplementedError when calling\n # get_config in custom models and layers. This is only enabled when saving to\n\n@@ -1,48 +1,48 @@\n import inspect\n \n-from keras.api_export import keras_export\n-from keras.losses.loss import Loss\n-from keras.losses.losses import BinaryCrossentropy\n-from keras.losses.losses import BinaryFocalCrossentropy\n-from keras.losses.losses import CategoricalCrossentropy\n-from keras.losses.losses import CategoricalFocalCrossentropy\n-from keras.losses.losses import CategoricalHinge\n-from keras.losses.losses import CosineSimilarity\n-from keras.losses.losses import Dice\n-from keras.losses.losses import Hinge\n-from keras.losses.losses import Huber\n-from keras.losses.losses import KLDivergence\n-from keras.losses.losses import LogCosh\n-from keras.losses.losses import LossFunctionWrapper\n-from keras.losses.losses import MeanAbsoluteError\n-from keras.losses.losses import MeanAbsolutePercentageError\n-from keras.losses.losses import MeanSquaredError\n-from keras.losses.losses import MeanSquaredLogarithmicError\n-from keras.losses.losses import Poisson\n-from keras.losses.losses import SparseCategoricalCrossentropy\n-from keras.losses.losses import SquaredHinge\n-from keras.losses.losses import Tversky\n-from keras.losses.losses import binary_crossentropy\n-from keras.losses.losses import binary_focal_crossentropy\n-from keras.losses.losses import categorical_crossentropy\n-from keras.losses.losses import categorical_focal_crossentropy\n-from keras.losses.losses import categorical_hinge\n-from keras.losses.losses import cosine_similarity\n-from keras.losses.losses import ctc\n-from keras.losses.losses import dice\n-from keras.losses.losses import hinge\n-from keras.losses.losses import huber\n-from keras.losses.losses import kl_divergence\n-from keras.losses.losses import log_cosh\n-from keras.losses.losses import mean_absolute_error\n-from keras.losses.losses import mean_absolute_percentage_error\n-from keras.losses.losses import mean_squared_error\n-from keras.losses.losses import mean_squared_logarithmic_error\n-from keras.losses.losses import poisson\n-from keras.losses.losses import sparse_categorical_crossentropy\n-from keras.losses.losses import squared_hinge\n-from keras.losses.losses import tversky\n-from keras.saving import serialization_lib\n+from keras.src.api_export import keras_export\n+from keras.src.losses.loss import Loss\n+from keras.src.losses.losses import BinaryCrossentropy\n+from keras.src.losses.losses import BinaryFocalCrossentropy\n+from keras.src.losses.losses import CategoricalCrossentropy\n+from keras.src.losses.losses import CategoricalFocalCrossentropy\n+from keras.src.losses.losses import CategoricalHinge\n+from keras.src.losses.losses import CosineSimilarity\n+from keras.src.losses.losses import Dice\n+from keras.src.losses.losses import Hinge\n+from keras.src.losses.losses import Huber\n+from keras.src.losses.losses import KLDivergence\n+from keras.src.losses.losses import LogCosh\n+from keras.src.losses.losses import LossFunctionWrapper\n+from keras.src.losses.losses import MeanAbsoluteError\n+from keras.src.losses.losses import MeanAbsolutePercentageError\n+from keras.src.losses.losses import MeanSquaredError\n+from keras.src.losses.losses import MeanSquaredLogarithmicError\n+from keras.src.losses.losses import Poisson\n+from keras.src.losses.losses import SparseCategoricalCrossentropy\n+from keras.src.losses.losses import SquaredHinge\n+from keras.src.losses.losses import Tversky\n+from keras.src.losses.losses import binary_crossentropy\n+from keras.src.losses.losses import binary_focal_crossentropy\n+from keras.src.losses.losses import categorical_crossentropy\n+from keras.src.losses.losses import categorical_focal_crossentropy\n+from keras.src.losses.losses import categorical_hinge\n+from keras.src.losses.losses import cosine_similarity\n+from keras.src.losses.losses import ctc\n+from keras.src.losses.losses import dice\n+from keras.src.losses.losses import hinge\n+from keras.src.losses.losses import huber\n+from keras.src.losses.losses import kl_divergence\n+from keras.src.losses.losses import log_cosh\n+from keras.src.losses.losses import mean_absolute_error\n+from keras.src.losses.losses import mean_absolute_percentage_error\n+from keras.src.losses.losses import mean_squared_error\n+from keras.src.losses.losses import mean_squared_logarithmic_error\n+from keras.src.losses.losses import poisson\n+from keras.src.losses.losses import sparse_categorical_crossentropy\n+from keras.src.losses.losses import squared_hinge\n+from keras.src.losses.losses import tversky\n+from keras.src.saving import serialization_lib\n \n ALL_OBJECTS = {\n     # Base\n\n@@ -1,8 +1,8 @@\n-from keras import backend\n-from keras import ops\n-from keras import tree\n-from keras.api_export import keras_export\n-from keras.utils.naming import auto_name\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src import tree\n+from keras.src.api_export import keras_export\n+from keras.src.utils.naming import auto_name\n \n \n @keras_export([\"keras.Loss\", \"keras.losses.Loss\"])\n\n@@ -1,12 +1,12 @@\n import numpy as np\n import pytest\n \n-from keras import backend\n-from keras import losses as losses_module\n-from keras import ops\n-from keras import testing\n-from keras.losses.loss import Loss\n-from keras.losses.loss import squeeze_or_expand_to_same_rank\n+from keras.src import backend\n+from keras.src import losses as losses_module\n+from keras.src import ops\n+from keras.src import testing\n+from keras.src.losses.loss import Loss\n+from keras.src.losses.loss import squeeze_or_expand_to_same_rank\n \n \n class ExampleLoss(Loss):\n\n@@ -1,12 +1,12 @@\n import warnings\n \n-from keras import backend\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.losses.loss import Loss\n-from keras.losses.loss import squeeze_or_expand_to_same_rank\n-from keras.saving import serialization_lib\n-from keras.utils.numerical_utils import normalize\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.losses.loss import Loss\n+from keras.src.losses.loss import squeeze_or_expand_to_same_rank\n+from keras.src.saving import serialization_lib\n+from keras.src.utils.numerical_utils import normalize\n \n \n class LossFunctionWrapper(Loss):\n\n@@ -1,9 +1,9 @@\n import numpy as np\n import pytest\n \n-from keras import backend\n-from keras import testing\n-from keras.losses import losses\n+from keras.src import backend\n+from keras.src import testing\n+from keras.src.losses import losses\n \n \n class MeanSquaredErrorTest(testing.TestCase):\n\n@@ -1,52 +1,54 @@\n import inspect\n \n-from keras.api_export import keras_export\n-from keras.metrics.accuracy_metrics import Accuracy\n-from keras.metrics.accuracy_metrics import BinaryAccuracy\n-from keras.metrics.accuracy_metrics import CategoricalAccuracy\n-from keras.metrics.accuracy_metrics import SparseCategoricalAccuracy\n-from keras.metrics.accuracy_metrics import SparseTopKCategoricalAccuracy\n-from keras.metrics.accuracy_metrics import TopKCategoricalAccuracy\n-from keras.metrics.confusion_metrics import AUC\n-from keras.metrics.confusion_metrics import FalseNegatives\n-from keras.metrics.confusion_metrics import FalsePositives\n-from keras.metrics.confusion_metrics import Precision\n-from keras.metrics.confusion_metrics import PrecisionAtRecall\n-from keras.metrics.confusion_metrics import Recall\n-from keras.metrics.confusion_metrics import RecallAtPrecision\n-from keras.metrics.confusion_metrics import SensitivityAtSpecificity\n-from keras.metrics.confusion_metrics import SpecificityAtSensitivity\n-from keras.metrics.confusion_metrics import TrueNegatives\n-from keras.metrics.confusion_metrics import TruePositives\n-from keras.metrics.f_score_metrics import F1Score\n-from keras.metrics.f_score_metrics import FBetaScore\n-from keras.metrics.hinge_metrics import CategoricalHinge\n-from keras.metrics.hinge_metrics import Hinge\n-from keras.metrics.hinge_metrics import SquaredHinge\n-from keras.metrics.iou_metrics import BinaryIoU\n-from keras.metrics.iou_metrics import IoU\n-from keras.metrics.iou_metrics import MeanIoU\n-from keras.metrics.iou_metrics import OneHotIoU\n-from keras.metrics.iou_metrics import OneHotMeanIoU\n-from keras.metrics.metric import Metric\n-from keras.metrics.probabilistic_metrics import BinaryCrossentropy\n-from keras.metrics.probabilistic_metrics import CategoricalCrossentropy\n-from keras.metrics.probabilistic_metrics import KLDivergence\n-from keras.metrics.probabilistic_metrics import Poisson\n-from keras.metrics.probabilistic_metrics import SparseCategoricalCrossentropy\n-from keras.metrics.reduction_metrics import Mean\n-from keras.metrics.reduction_metrics import MeanMetricWrapper\n-from keras.metrics.reduction_metrics import Sum\n-from keras.metrics.regression_metrics import CosineSimilarity\n-from keras.metrics.regression_metrics import LogCoshError\n-from keras.metrics.regression_metrics import MeanAbsoluteError\n-from keras.metrics.regression_metrics import MeanAbsolutePercentageError\n-from keras.metrics.regression_metrics import MeanSquaredError\n-from keras.metrics.regression_metrics import MeanSquaredLogarithmicError\n-from keras.metrics.regression_metrics import R2Score\n-from keras.metrics.regression_metrics import RootMeanSquaredError\n-from keras.saving import serialization_lib\n-from keras.utils.naming import to_snake_case\n+from keras.src.api_export import keras_export\n+from keras.src.metrics.accuracy_metrics import Accuracy\n+from keras.src.metrics.accuracy_metrics import BinaryAccuracy\n+from keras.src.metrics.accuracy_metrics import CategoricalAccuracy\n+from keras.src.metrics.accuracy_metrics import SparseCategoricalAccuracy\n+from keras.src.metrics.accuracy_metrics import SparseTopKCategoricalAccuracy\n+from keras.src.metrics.accuracy_metrics import TopKCategoricalAccuracy\n+from keras.src.metrics.confusion_metrics import AUC\n+from keras.src.metrics.confusion_metrics import FalseNegatives\n+from keras.src.metrics.confusion_metrics import FalsePositives\n+from keras.src.metrics.confusion_metrics import Precision\n+from keras.src.metrics.confusion_metrics import PrecisionAtRecall\n+from keras.src.metrics.confusion_metrics import Recall\n+from keras.src.metrics.confusion_metrics import RecallAtPrecision\n+from keras.src.metrics.confusion_metrics import SensitivityAtSpecificity\n+from keras.src.metrics.confusion_metrics import SpecificityAtSensitivity\n+from keras.src.metrics.confusion_metrics import TrueNegatives\n+from keras.src.metrics.confusion_metrics import TruePositives\n+from keras.src.metrics.f_score_metrics import F1Score\n+from keras.src.metrics.f_score_metrics import FBetaScore\n+from keras.src.metrics.hinge_metrics import CategoricalHinge\n+from keras.src.metrics.hinge_metrics import Hinge\n+from keras.src.metrics.hinge_metrics import SquaredHinge\n+from keras.src.metrics.iou_metrics import BinaryIoU\n+from keras.src.metrics.iou_metrics import IoU\n+from keras.src.metrics.iou_metrics import MeanIoU\n+from keras.src.metrics.iou_metrics import OneHotIoU\n+from keras.src.metrics.iou_metrics import OneHotMeanIoU\n+from keras.src.metrics.metric import Metric\n+from keras.src.metrics.probabilistic_metrics import BinaryCrossentropy\n+from keras.src.metrics.probabilistic_metrics import CategoricalCrossentropy\n+from keras.src.metrics.probabilistic_metrics import KLDivergence\n+from keras.src.metrics.probabilistic_metrics import Poisson\n+from keras.src.metrics.probabilistic_metrics import (\n+    SparseCategoricalCrossentropy,\n+)\n+from keras.src.metrics.reduction_metrics import Mean\n+from keras.src.metrics.reduction_metrics import MeanMetricWrapper\n+from keras.src.metrics.reduction_metrics import Sum\n+from keras.src.metrics.regression_metrics import CosineSimilarity\n+from keras.src.metrics.regression_metrics import LogCoshError\n+from keras.src.metrics.regression_metrics import MeanAbsoluteError\n+from keras.src.metrics.regression_metrics import MeanAbsolutePercentageError\n+from keras.src.metrics.regression_metrics import MeanSquaredError\n+from keras.src.metrics.regression_metrics import MeanSquaredLogarithmicError\n+from keras.src.metrics.regression_metrics import R2Score\n+from keras.src.metrics.regression_metrics import RootMeanSquaredError\n+from keras.src.saving import serialization_lib\n+from keras.src.utils.naming import to_snake_case\n \n ALL_OBJECTS = {\n     # Base\n\n@@ -1,8 +1,8 @@\n-from keras import backend\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.losses.loss import squeeze_or_expand_to_same_rank\n-from keras.metrics import reduction_metrics\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.losses.loss import squeeze_or_expand_to_same_rank\n+from keras.src.metrics import reduction_metrics\n \n \n def accuracy(y_true, y_pred):\n\n@@ -2,8 +2,8 @@ import re\n \n import numpy as np\n \n-from keras import testing\n-from keras.metrics import accuracy_metrics\n+from keras.src import testing\n+from keras.src.metrics import accuracy_metrics\n \n \n class AccuracyTest(testing.TestCase):\n\n@@ -1,13 +1,13 @@\n import numpy as np\n \n-from keras import activations\n-from keras import backend\n-from keras import initializers\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.metrics import metrics_utils\n-from keras.metrics.metric import Metric\n-from keras.utils.python_utils import to_list\n+from keras.src import activations\n+from keras.src import backend\n+from keras.src import initializers\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.metrics import metrics_utils\n+from keras.src.metrics.metric import Metric\n+from keras.src.utils.python_utils import to_list\n \n \n class _ConfusionMatrixConditionCount(Metric):\n\n@@ -5,12 +5,12 @@ import pytest\n from absl import logging\n from absl.testing import parameterized\n \n-from keras import layers\n-from keras import metrics\n-from keras import models\n-from keras import ops\n-from keras import testing\n-from keras.metrics import metrics_utils\n+from keras.src import layers\n+from keras.src import metrics\n+from keras.src import models\n+from keras.src import ops\n+from keras.src import testing\n+from keras.src.metrics import metrics_utils\n \n \n class FalsePositivesTest(testing.TestCase):\n\n@@ -1,8 +1,8 @@\n-from keras import backend\n-from keras import initializers\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.metrics.metric import Metric\n+from keras.src import backend\n+from keras.src import initializers\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.metrics.metric import Metric\n \n \n @keras_export(\"keras.metrics.FBetaScore\")\n\n@@ -1,8 +1,8 @@\n import numpy as np\n from absl.testing import parameterized\n \n-from keras import testing\n-from keras.metrics import f_score_metrics\n+from keras.src import testing\n+from keras.src.metrics import f_score_metrics\n \n \n class FBetaScoreTest(parameterized.TestCase, testing.TestCase):\n\n@@ -1,8 +1,8 @@\n-from keras.api_export import keras_export\n-from keras.losses.losses import categorical_hinge\n-from keras.losses.losses import hinge\n-from keras.losses.losses import squared_hinge\n-from keras.metrics import reduction_metrics\n+from keras.src.api_export import keras_export\n+from keras.src.losses.losses import categorical_hinge\n+from keras.src.losses.losses import hinge\n+from keras.src.losses.losses import squared_hinge\n+from keras.src.metrics import reduction_metrics\n \n \n @keras_export(\"keras.metrics.Hinge\")\n\n@@ -1,7 +1,7 @@\n import numpy as np\n \n-from keras import testing\n-from keras.metrics import hinge_metrics\n+from keras.src import testing\n+from keras.src.metrics import hinge_metrics\n \n \n class HingeTest(testing.TestCase):\n\n@@ -1,9 +1,9 @@\n-from keras import backend\n-from keras import initializers\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.metrics.metric import Metric\n-from keras.metrics.metrics_utils import confusion_matrix\n+from keras.src import backend\n+from keras.src import initializers\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.metrics.metric import Metric\n+from keras.src.metrics.metrics_utils import confusion_matrix\n \n \n class _IoUBase(Metric):\n\n@@ -1,10 +1,10 @@\n import numpy as np\n import pytest\n \n-from keras import layers\n-from keras import models\n-from keras import testing\n-from keras.metrics import iou_metrics as metrics\n+from keras.src import layers\n+from keras.src import models\n+from keras.src import testing\n+from keras.src.metrics import iou_metrics as metrics\n \n \n class IoUTest(testing.TestCase):\n\n@@ -1,9 +1,9 @@\n-from keras import backend\n-from keras import initializers\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.utils.naming import auto_name\n-from keras.utils.tracking import Tracker\n+from keras.src import backend\n+from keras.src import initializers\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.utils.naming import auto_name\n+from keras.src.utils.tracking import Tracker\n \n \n @keras_export([\"keras.Metric\", \"keras.metrics.Metric\"])\n\n@@ -1,11 +1,11 @@\n import numpy as np\n \n-from keras import backend\n-from keras import initializers\n-from keras import metrics as metrics_module\n-from keras import ops\n-from keras import testing\n-from keras.metrics.metric import Metric\n+from keras.src import backend\n+from keras.src import initializers\n+from keras.src import metrics as metrics_module\n+from keras.src import ops\n+from keras.src import testing\n+from keras.src.metrics.metric import Metric\n \n \n class ExampleMetric(Metric):\n\n@@ -2,10 +2,10 @@ from enum import Enum\n \n import numpy as np\n \n-from keras import backend\n-from keras import ops\n-from keras.losses.loss import squeeze_or_expand_to_same_rank\n-from keras.utils.python_utils import to_list\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src.losses.loss import squeeze_or_expand_to_same_rank\n+from keras.src.utils.python_utils import to_list\n \n NEG_INF = -1e10\n \n\n@@ -1,10 +1,10 @@\n-from keras.api_export import keras_export\n-from keras.losses.losses import binary_crossentropy\n-from keras.losses.losses import categorical_crossentropy\n-from keras.losses.losses import kl_divergence\n-from keras.losses.losses import poisson\n-from keras.losses.losses import sparse_categorical_crossentropy\n-from keras.metrics import reduction_metrics\n+from keras.src.api_export import keras_export\n+from keras.src.losses.losses import binary_crossentropy\n+from keras.src.losses.losses import categorical_crossentropy\n+from keras.src.losses.losses import kl_divergence\n+from keras.src.losses.losses import poisson\n+from keras.src.losses.losses import sparse_categorical_crossentropy\n+from keras.src.metrics import reduction_metrics\n \n \n @keras_export(\"keras.metrics.KLDivergence\")\n\n@@ -1,7 +1,7 @@\n import numpy as np\n \n-from keras import metrics\n-from keras import testing\n+from keras.src import metrics\n+from keras.src import testing\n \n \n class KLDivergenceTest(testing.TestCase):\n\n@@ -1,10 +1,10 @@\n-from keras import backend\n-from keras import initializers\n-from keras import losses\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.metrics.metric import Metric\n-from keras.saving import serialization_lib\n+from keras.src import backend\n+from keras.src import initializers\n+from keras.src import losses\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.metrics.metric import Metric\n+from keras.src.saving import serialization_lib\n \n \n def reduce_to_samplewise_values(values, sample_weight, reduce_fn, dtype):\n\n@@ -1,8 +1,8 @@\n import numpy as np\n \n-from keras import testing\n-from keras.metrics import reduction_metrics\n-from keras.saving import register_keras_serializable\n+from keras.src import testing\n+from keras.src.metrics import reduction_metrics\n+from keras.src.saving import register_keras_serializable\n \n \n class SumTest(testing.TestCase):\n\n@@ -1,16 +1,16 @@\n import warnings\n \n-from keras import initializers\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.losses.loss import squeeze_or_expand_to_same_rank\n-from keras.losses.losses import log_cosh\n-from keras.losses.losses import mean_absolute_error\n-from keras.losses.losses import mean_absolute_percentage_error\n-from keras.losses.losses import mean_squared_error\n-from keras.losses.losses import mean_squared_logarithmic_error\n-from keras.metrics import reduction_metrics\n-from keras.utils.numerical_utils import normalize\n+from keras.src import initializers\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.losses.loss import squeeze_or_expand_to_same_rank\n+from keras.src.losses.losses import log_cosh\n+from keras.src.losses.losses import mean_absolute_error\n+from keras.src.losses.losses import mean_absolute_percentage_error\n+from keras.src.losses.losses import mean_squared_error\n+from keras.src.losses.losses import mean_squared_logarithmic_error\n+from keras.src.metrics import reduction_metrics\n+from keras.src.utils.numerical_utils import normalize\n \n \n @keras_export(\"keras.metrics.MeanSquaredError\")\n\n@@ -1,8 +1,8 @@\n import numpy as np\n from absl.testing import parameterized\n \n-from keras import testing\n-from keras.metrics import regression_metrics as metrics\n+from keras.src import testing\n+from keras.src.metrics import regression_metrics as metrics\n \n \n class MeanSquaredErrorTest(testing.TestCase):\n\n@@ -0,0 +1,3 @@\n+from keras.src.models.functional import Functional\n+from keras.src.models.model import Model\n+from keras.src.models.sequential import Sequential\n\n@@ -1,13 +1,13 @@\n-from keras import backend\n-from keras import tree\n-from keras import utils\n-from keras.api_export import keras_export\n-from keras.layers import Input\n-from keras.layers import InputLayer\n-from keras.models.functional import Functional\n-from keras.models.functional import functional_like_constructor\n-from keras.models.sequential import Sequential\n-from keras.saving import serialization_lib\n+from keras.src import backend\n+from keras.src import tree\n+from keras.src import utils\n+from keras.src.api_export import keras_export\n+from keras.src.layers import Input\n+from keras.src.layers import InputLayer\n+from keras.src.models.functional import Functional\n+from keras.src.models.functional import functional_like_constructor\n+from keras.src.models.sequential import Sequential\n+from keras.src.saving import serialization_lib\n \n \n @keras_export(\"keras.models.clone_model\")\n\n@@ -2,11 +2,11 @@ import numpy as np\n import pytest\n from absl.testing import parameterized\n \n-from keras import layers\n-from keras import models\n-from keras import testing\n-from keras import tree\n-from keras.models.cloning import clone_model\n+from keras.src import layers\n+from keras.src import models\n+from keras.src import testing\n+from keras.src import tree\n+from keras.src.models.cloning import clone_model\n \n \n def get_mlp_functional_model(shared_layers=False):\n\n@@ -3,24 +3,24 @@ import inspect\n import typing\n import warnings\n \n-from keras import backend\n-from keras import ops\n-from keras import tree\n-from keras.backend.common import global_state\n-from keras.layers.core.input_layer import Input\n-from keras.layers.core.input_layer import InputLayer\n-from keras.layers.input_spec import InputSpec\n-from keras.layers.layer import Layer\n-from keras.legacy.saving import saving_utils\n-from keras.legacy.saving import serialization as legacy_serialization\n-from keras.models.model import Model\n-from keras.ops.function import Function\n-from keras.ops.function import _build_map\n-from keras.ops.function import make_node_key\n-from keras.ops.node import KerasHistory\n-from keras.ops.node import Node\n-from keras.saving import serialization_lib\n-from keras.utils import tracking\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src import tree\n+from keras.src.backend.common import global_state\n+from keras.src.layers.core.input_layer import Input\n+from keras.src.layers.core.input_layer import InputLayer\n+from keras.src.layers.input_spec import InputSpec\n+from keras.src.layers.layer import Layer\n+from keras.src.legacy.saving import saving_utils\n+from keras.src.legacy.saving import serialization as legacy_serialization\n+from keras.src.models.model import Model\n+from keras.src.ops.function import Function\n+from keras.src.ops.function import _build_map\n+from keras.src.ops.function import make_node_key\n+from keras.src.ops.node import KerasHistory\n+from keras.src.ops.node import Node\n+from keras.src.saving import serialization_lib\n+from keras.src.utils import tracking\n \n \n class Functional(Function, Model):\n\n@@ -3,13 +3,13 @@ import warnings\n import numpy as np\n import pytest\n \n-from keras import backend\n-from keras import layers\n-from keras import testing\n-from keras.layers.core.input_layer import Input\n-from keras.layers.input_spec import InputSpec\n-from keras.models import Functional\n-from keras.models import Model\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n+from keras.src.layers.core.input_layer import Input\n+from keras.src.layers.input_spec import InputSpec\n+from keras.src.models import Functional\n+from keras.src.models import Model\n \n \n class FunctionalTest(testing.TestCase):\n\n@@ -3,24 +3,26 @@ import json\n import typing\n import warnings\n \n-from keras import backend\n-from keras import utils\n-from keras.api_export import keras_export\n-from keras.layers.layer import Layer\n-from keras.models.variable_mapping import map_trackable_variables\n-from keras.saving import saving_api\n-from keras.trainers import trainer as base_trainer\n-from keras.utils import summary_utils\n-from keras.utils import traceback_utils\n+from keras.src import backend\n+from keras.src import utils\n+from keras.src.api_export import keras_export\n+from keras.src.layers.layer import Layer\n+from keras.src.models.variable_mapping import map_trackable_variables\n+from keras.src.saving import saving_api\n+from keras.src.trainers import trainer as base_trainer\n+from keras.src.utils import summary_utils\n+from keras.src.utils import traceback_utils\n \n if backend.backend() == \"tensorflow\":\n-    from keras.backend.tensorflow.trainer import TensorFlowTrainer as Trainer\n+    from keras.src.backend.tensorflow.trainer import (\n+        TensorFlowTrainer as Trainer,\n+    )\n elif backend.backend() == \"jax\":\n-    from keras.backend.jax.trainer import JAXTrainer as Trainer\n+    from keras.src.backend.jax.trainer import JAXTrainer as Trainer\n elif backend.backend() == \"torch\":\n-    from keras.backend.torch.trainer import TorchTrainer as Trainer\n+    from keras.src.backend.torch.trainer import TorchTrainer as Trainer\n elif backend.backend() == \"numpy\":\n-    from keras.backend.numpy.trainer import NumpyTrainer as Trainer\n+    from keras.src.backend.numpy.trainer import NumpyTrainer as Trainer\n else:\n     raise RuntimeError(\n         f\"Backend '{backend.backend()}' must implement the Trainer class.\"\n@@ -136,14 +138,14 @@ class Model(Trainer, base_trainer.Trainer, Layer):\n     def __new__(cls, *args, **kwargs):\n         # Signature detection for usage of `Model` as a `Functional`\n         if functional_init_arguments(args, kwargs) and cls == Model:\n-            from keras.models import functional\n+            from keras.src.models import functional\n \n             return functional.Functional(*args, **kwargs)\n         return typing.cast(Model, super().__new__(cls))\n \n     def __init__(self, *args, **kwargs):\n         Trainer.__init__(self)\n-        from keras.models import functional\n+        from keras.src.models import functional\n \n         # Signature detection for usage of a `Model` subclass\n         # as a `Functional` subclass\n@@ -357,7 +359,7 @@ class Model(Trainer, base_trainer.Trainer, Layer):\n             mode: The mode of the quantization. Only 'int8' is supported at this\n                 time.\n         \"\"\"\n-        from keras.dtype_policies import QUANTIZATION_MODES\n+        from keras.src.dtype_policies import QUANTIZATION_MODES\n \n         if not self.built:\n             raise ValueError(\n@@ -442,7 +444,7 @@ class Model(Trainer, base_trainer.Trainer, Layer):\n         Returns:\n             A JSON string.\n         \"\"\"\n-        from keras.saving import serialization_lib\n+        from keras.src.saving import serialization_lib\n \n         model_config = serialization_lib.serialize_keras_object(self)\n         return json.dumps(model_config, **kwargs)\n@@ -481,13 +483,13 @@ class Model(Trainer, base_trainer.Trainer, Layer):\n         use the lower-level `keras.export.ExportArchive` class. The\n         `export()` method relies on `ExportArchive` internally.\n         \"\"\"\n-        from keras.export import export_lib\n+        from keras.src.export import export_lib\n \n         export_lib.export_model(self, filepath)\n \n     @classmethod\n     def from_config(cls, config, custom_objects=None):\n-        from keras.models.functional import Functional\n+        from keras.src.models.functional import Functional\n \n         functional_config_keys = [\n             \"name\",\n@@ -510,7 +512,7 @@ class Model(Trainer, base_trainer.Trainer, Layer):\n         if is_functional_config and revivable_as_functional:\n             # Revive Functional model\n             # (but not Functional subclasses with a custom __init__)\n-            from keras.models.functional import functional_from_config\n+            from keras.src.models.functional import functional_from_config\n \n             return functional_from_config(\n                 cls, config, custom_objects=custom_objects\n@@ -567,7 +569,7 @@ def model_from_json(json_string, custom_objects=None):\n     Returns:\n         A Keras model instance (uncompiled).\n     \"\"\"\n-    from keras.saving import serialization_lib\n+    from keras.src.saving import serialization_lib\n \n     model_config = json.loads(json_string)\n     return serialization_lib.deserialize_keras_object(\n@@ -585,7 +587,7 @@ def functional_init_arguments(args, kwargs):\n \n def inject_functional_model_class(cls):\n     \"\"\"Inject `Functional` into the hierarchy of this class if needed.\"\"\"\n-    from keras.models import functional\n+    from keras.src.models import functional\n \n     if cls == Model:\n         return functional.Functional\n\n@@ -2,13 +2,13 @@ import numpy as np\n import pytest\n from absl.testing import parameterized\n \n-from keras import backend\n-from keras import layers\n-from keras import testing\n-from keras.layers.core.input_layer import Input\n-from keras.models.functional import Functional\n-from keras.models.model import Model\n-from keras.models.model import model_from_json\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n+from keras.src.layers.core.input_layer import Input\n+from keras.src.models.functional import Functional\n+from keras.src.models.model import Model\n+from keras.src.models.model import model_from_json\n \n \n def _get_model():\n\n@@ -2,16 +2,16 @@ import copy\n import inspect\n import typing\n \n-from keras import tree\n-from keras.api_export import keras_export\n-from keras.backend.common import global_state\n-from keras.layers.core.input_layer import InputLayer\n-from keras.layers.layer import Layer\n-from keras.legacy.saving import saving_utils\n-from keras.legacy.saving import serialization as legacy_serialization\n-from keras.models.functional import Functional\n-from keras.models.model import Model\n-from keras.saving import serialization_lib\n+from keras.src import tree\n+from keras.src.api_export import keras_export\n+from keras.src.backend.common import global_state\n+from keras.src.layers.core.input_layer import InputLayer\n+from keras.src.layers.layer import Layer\n+from keras.src.legacy.saving import saving_utils\n+from keras.src.legacy.saving import serialization as legacy_serialization\n+from keras.src.models.functional import Functional\n+from keras.src.models.model import Model\n+from keras.src.saving import serialization_lib\n \n \n @keras_export([\"keras.Sequential\", \"keras.models.Sequential\"])\n\n@@ -1,12 +1,12 @@\n import numpy as np\n import pytest\n \n-from keras import backend\n-from keras import layers\n-from keras import testing\n-from keras.layers.core.input_layer import Input\n-from keras.models.functional import Functional\n-from keras.models.sequential import Sequential\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n+from keras.src.layers.core.input_layer import Input\n+from keras.src.models.functional import Functional\n+from keras.src.models.sequential import Sequential\n \n \n @pytest.mark.requires_trainable_backend\n\n@@ -1,7 +1,7 @@\n-from keras.layers.layer import Layer\n-from keras.metrics.metric import Metric\n-from keras.optimizers.optimizer import Optimizer\n-from keras.saving import saving_lib\n+from keras.src.layers.layer import Layer\n+from keras.src.metrics.metric import Metric\n+from keras.src.optimizers.optimizer import Optimizer\n+from keras.src.saving import saving_lib\n \n \n def map_trackable_variables(trackable, store, visited_trackables):\n\n@@ -1,7 +1,7 @@\n import numpy as np\n \n-from keras import testing\n-from keras.saving import saving_lib_test\n+from keras.src import testing\n+from keras.src.saving import saving_lib_test\n \n \n class VariableMappingTest(testing.TestCase):\n\n@@ -0,0 +1,16 @@\n+# from keras.src.ops.numpy import Matmul, matmul\n+# from keras.src.ops.numpy import Add, add\n+# from keras.src.ops.numpy import Multiply, multiply\n+\n+from keras.src.backend import cast\n+from keras.src.backend import cond\n+from keras.src.backend import is_tensor\n+from keras.src.backend import name_scope\n+from keras.src.backend import random\n+from keras.src.ops import image\n+from keras.src.ops import operation_utils\n+from keras.src.ops.core import *  # noqa: F403\n+from keras.src.ops.linalg import *  # noqa: F403\n+from keras.src.ops.math import *  # noqa: F403\n+from keras.src.ops.nn import *  # noqa: F403\n+from keras.src.ops.numpy import *  # noqa: F403\n\n@@ -16,13 +16,13 @@ custom_gradient\n \n import numpy as np\n \n-from keras import backend\n-from keras import tree\n-from keras.api_export import keras_export\n-from keras.backend import KerasTensor\n-from keras.backend import any_symbolic_tensors\n-from keras.ops.operation import Operation\n-from keras.utils import traceback_utils\n+from keras.src import backend\n+from keras.src import tree\n+from keras.src.api_export import keras_export\n+from keras.src.backend import KerasTensor\n+from keras.src.backend import any_symbolic_tensors\n+from keras.src.ops.operation import Operation\n+from keras.src.utils import traceback_utils\n \n \n class Scatter(Operation):\n\n@@ -5,17 +5,17 @@ import numpy as np\n import pytest\n from absl.testing import parameterized\n \n-from keras import backend\n-from keras import layers\n-from keras import losses\n-from keras import models\n-from keras import ops\n-from keras import optimizers\n-from keras import testing\n-from keras import tree\n-from keras.backend.common import dtypes\n-from keras.backend.common.keras_tensor import KerasTensor\n-from keras.ops import core\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import losses\n+from keras.src import models\n+from keras.src import ops\n+from keras.src import optimizers\n+from keras.src import testing\n+from keras.src import tree\n+from keras.src.backend.common import dtypes\n+from keras.src.backend.common.keras_tensor import KerasTensor\n+from keras.src.ops import core\n \n \n class CoreOpsStaticShapeTest(testing.TestCase):\n\n@@ -1,10 +1,10 @@\n import collections\n \n-from keras import tree\n-from keras.api_export import keras_export\n-from keras.backend import KerasTensor\n-from keras.backend.config import backend\n-from keras.ops.operation import Operation\n+from keras.src import tree\n+from keras.src.api_export import keras_export\n+from keras.src.backend import KerasTensor\n+from keras.src.backend.config import backend\n+from keras.src.ops.operation import Operation\n \n \n @keras_export(\"keras.Function\")\n\n@@ -2,13 +2,13 @@ import json\n \n import numpy as np\n \n-from keras import testing\n-from keras.backend.common import keras_tensor\n-from keras.layers import Dense\n-from keras.layers import Input\n-from keras.models import Model\n-from keras.ops import function\n-from keras.ops import numpy as knp\n+from keras.src import testing\n+from keras.src.backend.common import keras_tensor\n+from keras.src.layers import Dense\n+from keras.src.layers import Input\n+from keras.src.models import Model\n+from keras.src.ops import function\n+from keras.src.ops import numpy as knp\n \n \n class FunctionTest(testing.TestCase):\n\n@@ -1,10 +1,10 @@\n-from keras import backend\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.backend import KerasTensor\n-from keras.backend import any_symbolic_tensors\n-from keras.ops.operation import Operation\n-from keras.ops.operation_utils import compute_conv_output_shape\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.backend import KerasTensor\n+from keras.src.backend import any_symbolic_tensors\n+from keras.src.ops.operation import Operation\n+from keras.src.ops.operation_utils import compute_conv_output_shape\n \n \n class RGBToGrayscale(Operation):\n@@ -78,7 +78,7 @@ def rgb_to_grayscale(\n     Examples:\n \n     >>> import numpy as np\n-    >>> from keras import ops\n+    >>> from keras.src import ops\n     >>> x = np.random.random((2, 4, 4, 3))\n     >>> y = ops.image.rgb_to_grayscale(x)\n     >>> y.shape\n\n@@ -6,10 +6,10 @@ import scipy.ndimage\n import tensorflow as tf\n from absl.testing import parameterized\n \n-from keras import backend\n-from keras import testing\n-from keras.backend.common.keras_tensor import KerasTensor\n-from keras.ops import image as kimage\n+from keras.src import backend\n+from keras.src import testing\n+from keras.src.backend.common.keras_tensor import KerasTensor\n+from keras.src.ops import image as kimage\n \n \n class ImageOpsDynamicShapeTest(testing.TestCase):\n\n@@ -1,9 +1,9 @@\n-from keras import backend\n-from keras.api_export import keras_export\n-from keras.backend import KerasTensor\n-from keras.backend import any_symbolic_tensors\n-from keras.ops.operation import Operation\n-from keras.ops.operation_utils import reduce_shape\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.backend import KerasTensor\n+from keras.src.backend import any_symbolic_tensors\n+from keras.src.ops.operation import Operation\n+from keras.src.ops.operation_utils import reduce_shape\n \n \n class Cholesky(Operation):\n\n@@ -1,12 +1,12 @@\n import numpy as np\n from absl.testing import parameterized\n \n-from keras import backend\n-from keras import ops\n-from keras import testing\n-from keras.backend.common.keras_tensor import KerasTensor\n-from keras.ops import linalg\n-from keras.testing.test_utils import named_product\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src import testing\n+from keras.src.backend.common.keras_tensor import KerasTensor\n+from keras.src.ops import linalg\n+from keras.src.testing.test_utils import named_product\n \n \n class LinalgOpsDynamicShapeTest(testing.TestCase):\n\n@@ -1,11 +1,11 @@\n \"\"\"Commonly used math operations not included in NumPy.\"\"\"\n \n-from keras import backend\n-from keras.api_export import keras_export\n-from keras.backend import KerasTensor\n-from keras.backend import any_symbolic_tensors\n-from keras.ops.operation import Operation\n-from keras.ops.operation_utils import reduce_shape\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.backend import KerasTensor\n+from keras.src.backend import any_symbolic_tensors\n+from keras.src.ops.operation import Operation\n+from keras.src.ops.operation_utils import reduce_shape\n \n \n class SegmentSum(Operation):\n\n@@ -5,11 +5,11 @@ import pytest\n import scipy.signal\n from absl.testing import parameterized\n \n-from keras import backend\n-from keras import testing\n-from keras.backend.common import dtypes\n-from keras.backend.common.keras_tensor import KerasTensor\n-from keras.ops import math as kmath\n+from keras.src import backend\n+from keras.src import testing\n+from keras.src.backend.common import dtypes\n+from keras.src.backend.common.keras_tensor import KerasTensor\n+from keras.src.ops import math as kmath\n \n \n def _stft(\n\n@@ -2,17 +2,17 @@\n \n import warnings\n \n-from keras import backend\n-from keras.api_export import keras_export\n-from keras.backend import KerasTensor\n-from keras.backend import any_symbolic_tensors\n-from keras.backend import standardize_data_format\n-from keras.backend.common.backend_utils import (\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.backend import KerasTensor\n+from keras.src.backend import any_symbolic_tensors\n+from keras.src.backend import standardize_data_format\n+from keras.src.backend.common.backend_utils import (\n     compute_conv_transpose_output_shape,\n )\n-from keras.ops import operation_utils\n-from keras.ops.operation import Operation\n-from keras.ops.operation_utils import reduce_shape\n+from keras.src.ops import operation_utils\n+from keras.src.ops.operation import Operation\n+from keras.src.ops.operation_utils import reduce_shape\n \n \n class Relu(Operation):\n\n@@ -3,28 +3,34 @@ import pytest\n from absl.testing import parameterized\n \n import keras\n-from keras import backend\n-from keras import layers\n-from keras import losses\n-from keras import models\n-from keras import ops\n-from keras import testing\n-from keras.backend.common import dtypes\n-from keras.backend.common import standardize_dtype\n-from keras.backend.common.keras_tensor import KerasTensor\n-from keras.layers.convolutional.conv_test import np_conv1d\n-from keras.layers.convolutional.conv_test import np_conv2d\n-from keras.layers.convolutional.conv_test import np_conv3d\n-from keras.layers.convolutional.conv_transpose_test import np_conv1d_transpose\n-from keras.layers.convolutional.conv_transpose_test import np_conv2d_transpose\n-from keras.layers.convolutional.depthwise_conv_test import np_depthwise_conv2d\n-from keras.layers.pooling.average_pooling_test import np_avgpool1d\n-from keras.layers.pooling.average_pooling_test import np_avgpool2d\n-from keras.layers.pooling.max_pooling_test import np_maxpool1d\n-from keras.layers.pooling.max_pooling_test import np_maxpool2d\n-from keras.ops import nn as knn\n-from keras.ops import numpy as knp\n-from keras.testing.test_utils import named_product\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import losses\n+from keras.src import models\n+from keras.src import ops\n+from keras.src import testing\n+from keras.src.backend.common import dtypes\n+from keras.src.backend.common import standardize_dtype\n+from keras.src.backend.common.keras_tensor import KerasTensor\n+from keras.src.layers.convolutional.conv_test import np_conv1d\n+from keras.src.layers.convolutional.conv_test import np_conv2d\n+from keras.src.layers.convolutional.conv_test import np_conv3d\n+from keras.src.layers.convolutional.conv_transpose_test import (\n+    np_conv1d_transpose,\n+)\n+from keras.src.layers.convolutional.conv_transpose_test import (\n+    np_conv2d_transpose,\n+)\n+from keras.src.layers.convolutional.depthwise_conv_test import (\n+    np_depthwise_conv2d,\n+)\n+from keras.src.layers.pooling.average_pooling_test import np_avgpool1d\n+from keras.src.layers.pooling.average_pooling_test import np_avgpool2d\n+from keras.src.layers.pooling.max_pooling_test import np_maxpool1d\n+from keras.src.layers.pooling.max_pooling_test import np_maxpool2d\n+from keras.src.ops import nn as knn\n+from keras.src.ops import numpy as knp\n+from keras.src.testing.test_utils import named_product\n \n \n class NNOpsDynamicShapeTest(testing.TestCase, parameterized.TestCase):\n@@ -1809,7 +1815,7 @@ class NNOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         reason=\"synchronized=True only implemented for TF backend\",\n     )\n     def test_moments_sync_with_distribution_strategy(self, dtype):\n-        from keras.utils.module_utils import tensorflow as tf\n+        from keras.src.utils.module_utils import tensorflow as tf\n \n         # Config 2 CPUs for testing.\n         logical_cpus = tf.config.list_logical_devices(\"CPU\")\n\n@@ -1,8 +1,8 @@\n import collections\n \n-from keras import tree\n-from keras.backend import KerasTensor\n-from keras.ops.symbolic_arguments import SymbolicArguments\n+from keras.src import tree\n+from keras.src.backend import KerasTensor\n+from keras.src.ops.symbolic_arguments import SymbolicArguments\n \n \n class Node:\n\n@@ -1,9 +1,9 @@\n import numpy as np\n \n-from keras import Layer\n-from keras import testing\n-from keras.backend import KerasTensor\n-from keras.ops.node import Node\n+from keras.src import Layer\n+from keras.src import testing\n+from keras.src.backend import KerasTensor\n+from keras.src.ops.node import Node\n \n \n class DummyLayer(Layer):\n\n@@ -147,17 +147,17 @@ import re\n \n import numpy as np\n \n-from keras import backend\n-from keras.api_export import keras_export\n-from keras.backend import KerasTensor\n-from keras.backend import any_symbolic_tensors\n-from keras.backend.common import dtypes\n-from keras.backend.common.backend_utils import canonicalize_axis\n-from keras.backend.common.backend_utils import to_tuple_or_list\n-from keras.ops import operation_utils\n-from keras.ops.operation import Operation\n-from keras.ops.operation_utils import broadcast_shapes\n-from keras.ops.operation_utils import reduce_shape\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.backend import KerasTensor\n+from keras.src.backend import any_symbolic_tensors\n+from keras.src.backend.common import dtypes\n+from keras.src.backend.common.backend_utils import canonicalize_axis\n+from keras.src.backend.common.backend_utils import to_tuple_or_list\n+from keras.src.ops import operation_utils\n+from keras.src.ops.operation import Operation\n+from keras.src.ops.operation_utils import broadcast_shapes\n+from keras.src.ops.operation_utils import reduce_shape\n \n \n def shape_equal(shape1, shape2, axis=None, allow_none=True):\n@@ -1884,7 +1884,7 @@ def diag(x, k=0):\n         The extracted diagonal or constructed diagonal tensor.\n \n     Examples:\n-    >>> from keras import ops\n+    >>> from keras.src import ops\n     >>> x = ops.arange(9).reshape((3, 3))\n     >>> x\n     array([[0, 1, 2],\n@@ -1978,7 +1978,7 @@ def diagonal(x, offset=0, axis1=0, axis2=1):\n         Tensor of diagonals.\n \n     Examples:\n-    >>> from keras import ops\n+    >>> from keras.src import ops\n     >>> x = ops.arange(4).reshape((2, 2))\n     >>> x\n     array([[0, 1],\n@@ -2047,7 +2047,7 @@ def diff(a, n=1, axis=-1):\n         Tensor of diagonals.\n \n     Examples:\n-    >>> from keras import ops\n+    >>> from keras.src import ops\n     >>> x = ops.convert_to_tensor([1, 2, 4, 7, 0])\n     >>> ops.diff(x)\n     array([ 1,  2,  3, -7])\n@@ -2366,7 +2366,7 @@ def einsum(subscripts, *operands):\n         The calculation based on the Einstein summation convention.\n \n     Example:\n-    >>> from keras import ops\n+    >>> from keras.src import ops\n     >>> a = ops.arange(25).reshape(5, 5)\n     >>> b = ops.arange(5)\n     >>> c = ops.arange(6).reshape(2, 3)\n@@ -3748,7 +3748,7 @@ def meshgrid(*x, indexing=\"xy\"):\n         Sequence of N tensors.\n \n     Example:\n-    >>> from keras import ops\n+    >>> from keras.src import ops\n     >>> x = ops.array([1, 2, 3])\n     >>> y = ops.array([4, 5, 6])\n \n\n@@ -9,13 +9,13 @@ import pytest\n from absl.testing import parameterized\n \n import keras\n-from keras import backend\n-from keras import testing\n-from keras.backend.common import dtypes\n-from keras.backend.common import standardize_dtype\n-from keras.backend.common.keras_tensor import KerasTensor\n-from keras.ops import numpy as knp\n-from keras.testing.test_utils import named_product\n+from keras.src import backend\n+from keras.src import testing\n+from keras.src.backend.common import dtypes\n+from keras.src.backend.common import standardize_dtype\n+from keras.src.backend.common.keras_tensor import KerasTensor\n+from keras.src.ops import numpy as knp\n+from keras.src.testing.test_utils import named_product\n \n \n class NumpyTwoInputOpsDynamicShapeTest(testing.TestCase):\n\n@@ -1,15 +1,15 @@\n import inspect\n import textwrap\n \n-from keras import backend\n-from keras import dtype_policies\n-from keras import tree\n-from keras.api_export import keras_export\n-from keras.backend.common.keras_tensor import any_symbolic_tensors\n-from keras.ops.node import Node\n-from keras.utils import python_utils\n-from keras.utils import traceback_utils\n-from keras.utils.naming import auto_name\n+from keras.src import backend\n+from keras.src import dtype_policies\n+from keras.src import tree\n+from keras.src.api_export import keras_export\n+from keras.src.backend.common.keras_tensor import any_symbolic_tensors\n+from keras.src.ops.node import Node\n+from keras.src.utils import python_utils\n+from keras.src.utils import traceback_utils\n+from keras.src.utils.naming import auto_name\n \n \n @keras_export(\"keras.Operation\")\n@@ -120,7 +120,7 @@ class Operation:\n         try:\n             instance._lock = False\n             if auto_config:\n-                from keras.saving import serialization_lib\n+                from keras.src.saving import serialization_lib\n \n                 instance._auto_config = serialization_lib.SerializableDict(\n                     **kwargs\n\n@@ -1,10 +1,10 @@\n import numpy as np\n \n-from keras import backend\n-from keras import testing\n-from keras.backend.common import keras_tensor\n-from keras.ops import numpy as knp\n-from keras.ops import operation\n+from keras.src import backend\n+from keras.src import testing\n+from keras.src.backend.common import keras_tensor\n+from keras.src.ops import numpy as knp\n+from keras.src.ops import operation\n \n \n class OpWithMultipleInputs(operation.Operation):\n\n@@ -2,10 +2,10 @@ import math\n \n import numpy as np\n \n-from keras import tree\n-from keras.api_export import keras_export\n-from keras.backend.common.backend_utils import canonicalize_axis\n-from keras.backend.common.backend_utils import to_tuple_or_list\n+from keras.src import tree\n+from keras.src.api_export import keras_export\n+from keras.src.backend.common.backend_utils import canonicalize_axis\n+from keras.src.backend.common.backend_utils import to_tuple_or_list\n \n \n def broadcast_shapes(shape1, shape2):\n\n@@ -1,8 +1,8 @@\n-from keras import backend\n-from keras import ops\n-from keras import testing\n-from keras.layers.core import input_layer\n-from keras.ops import operation_utils\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src import testing\n+from keras.src.layers.core import input_layer\n+from keras.src.ops import operation_utils\n \n \n class OperationUtilsTest(testing.TestCase):\n\n@@ -1,5 +1,5 @@\n-from keras import tree\n-from keras.backend import KerasTensor\n+from keras.src import tree\n+from keras.src.backend import KerasTensor\n \n \n class SymbolicArguments:\n\n@@ -1,7 +1,7 @@\n-from keras import testing\n-from keras import tree\n-from keras.backend import KerasTensor\n-from keras.ops.symbolic_arguments import SymbolicArguments\n+from keras.src import testing\n+from keras.src import tree\n+from keras.src.backend import KerasTensor\n+from keras.src.ops.symbolic_arguments import SymbolicArguments\n \n \n class SymbolicArgumentsTest(testing.TestCase):\n\n@@ -1,18 +1,18 @@\n-from keras.api_export import keras_export\n-from keras.optimizers.adadelta import Adadelta\n-from keras.optimizers.adafactor import Adafactor\n-from keras.optimizers.adagrad import Adagrad\n-from keras.optimizers.adam import Adam\n-from keras.optimizers.adamax import Adamax\n-from keras.optimizers.adamw import AdamW\n-from keras.optimizers.ftrl import Ftrl\n-from keras.optimizers.lion import Lion\n-from keras.optimizers.loss_scale_optimizer import LossScaleOptimizer\n-from keras.optimizers.nadam import Nadam\n-from keras.optimizers.optimizer import Optimizer\n-from keras.optimizers.rmsprop import RMSprop\n-from keras.optimizers.sgd import SGD\n-from keras.saving import serialization_lib\n+from keras.src.api_export import keras_export\n+from keras.src.optimizers.adadelta import Adadelta\n+from keras.src.optimizers.adafactor import Adafactor\n+from keras.src.optimizers.adagrad import Adagrad\n+from keras.src.optimizers.adam import Adam\n+from keras.src.optimizers.adamax import Adamax\n+from keras.src.optimizers.adamw import AdamW\n+from keras.src.optimizers.ftrl import Ftrl\n+from keras.src.optimizers.lion import Lion\n+from keras.src.optimizers.loss_scale_optimizer import LossScaleOptimizer\n+from keras.src.optimizers.nadam import Nadam\n+from keras.src.optimizers.optimizer import Optimizer\n+from keras.src.optimizers.rmsprop import RMSprop\n+from keras.src.optimizers.sgd import SGD\n+from keras.src.saving import serialization_lib\n \n ALL_OBJECTS = {\n     Optimizer,\n\n@@ -1,6 +1,6 @@\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.optimizers import optimizer\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.optimizers import optimizer\n \n \n @keras_export([\"keras.optimizers.Adadelta\"])\n\n@@ -1,9 +1,9 @@\n import numpy as np\n \n-from keras import backend\n-from keras import ops\n-from keras import testing\n-from keras.optimizers.adadelta import Adadelta\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src import testing\n+from keras.src.optimizers.adadelta import Adadelta\n \n \n class AdadeltaTest(testing.TestCase):\n\n@@ -1,7 +1,7 @@\n-from keras import backend\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.optimizers import optimizer\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.optimizers import optimizer\n \n \n @keras_export([\"keras.optimizers.Adafactor\"])\n\n@@ -3,9 +3,9 @@\n \n import numpy as np\n \n-from keras import backend\n-from keras import testing\n-from keras.optimizers.adafactor import Adafactor\n+from keras.src import backend\n+from keras.src import testing\n+from keras.src.optimizers.adafactor import Adafactor\n \n \n class AdafactorTest(testing.TestCase):\n\n@@ -1,7 +1,7 @@\n-from keras import initializers\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.optimizers import optimizer\n+from keras.src import initializers\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.optimizers import optimizer\n \n \n @keras_export([\"keras.optimizers.Adagrad\"])\n\n@@ -3,10 +3,10 @@\n \n import numpy as np\n \n-from keras import backend\n-from keras import ops\n-from keras import testing\n-from keras.optimizers.adagrad import Adagrad\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src import testing\n+from keras.src.optimizers.adagrad import Adagrad\n \n \n class AdagradTest(testing.TestCase):\n\n@@ -1,6 +1,6 @@\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.optimizers import optimizer\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.optimizers import optimizer\n \n \n @keras_export([\"keras.optimizers.Adam\"])\n\n@@ -2,10 +2,10 @@ import numpy as np\n import pytest\n \n import keras\n-from keras import backend\n-from keras import ops\n-from keras import testing\n-from keras.optimizers.adam import Adam\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src import testing\n+from keras.src.optimizers.adam import Adam\n \n \n class AdamTest(testing.TestCase):\n\n@@ -1,6 +1,6 @@\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.optimizers import optimizer\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.optimizers import optimizer\n \n \n @keras_export([\"keras.optimizers.Adamax\"])\n\n@@ -3,10 +3,10 @@\n \n import numpy as np\n \n-from keras import backend\n-from keras import ops\n-from keras import testing\n-from keras.optimizers.adamax import Adamax\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src import testing\n+from keras.src.optimizers.adamax import Adamax\n \n \n class AdamaxTest(testing.TestCase):\n\n@@ -1,6 +1,6 @@\n-from keras.api_export import keras_export\n-from keras.optimizers import adam\n-from keras.optimizers import optimizer\n+from keras.src.api_export import keras_export\n+from keras.src.optimizers import adam\n+from keras.src.optimizers import optimizer\n \n \n @keras_export([\"keras.optimizers.AdamW\"])\n\n@@ -3,10 +3,10 @@\n \n import numpy as np\n \n-from keras import backend\n-from keras import ops\n-from keras import testing\n-from keras.optimizers.adamw import AdamW\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src import testing\n+from keras.src.optimizers.adamw import AdamW\n \n \n class AdamWTest(testing.TestCase):\n\n@@ -3,13 +3,13 @@ import warnings\n \n import numpy as np\n \n-from keras import backend\n-from keras import initializers\n-from keras import ops\n-from keras.optimizers.schedules import learning_rate_schedule\n-from keras.saving import serialization_lib\n-from keras.utils import tracking\n-from keras.utils.naming import auto_name\n+from keras.src import backend\n+from keras.src import initializers\n+from keras.src import ops\n+from keras.src.optimizers.schedules import learning_rate_schedule\n+from keras.src.saving import serialization_lib\n+from keras.src.utils import tracking\n+from keras.src.utils.naming import auto_name\n \n \n class BaseOptimizer:\n\n@@ -1,7 +1,7 @@\n-from keras import initializers\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.optimizers import optimizer\n+from keras.src import initializers\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.optimizers import optimizer\n \n \n @keras_export([\"keras.optimizers.Ftrl\"])\n\n@@ -3,9 +3,9 @@\n \n import numpy as np\n \n-from keras import backend\n-from keras import testing\n-from keras.optimizers.ftrl import Ftrl\n+from keras.src import backend\n+from keras.src import testing\n+from keras.src.optimizers.ftrl import Ftrl\n \n \n class FtrlTest(testing.TestCase):\n\n@@ -1,6 +1,6 @@\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.optimizers import optimizer\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.optimizers import optimizer\n \n \n @keras_export([\"keras.optimizers.Lion\"])\n\n@@ -2,10 +2,10 @@ import numpy as np\n import pytest\n \n import keras\n-from keras import backend\n-from keras import ops\n-from keras import testing\n-from keras.optimizers.lion import Lion\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src import testing\n+from keras.src.optimizers.lion import Lion\n \n \n class LionTest(testing.TestCase):\n\n@@ -1,10 +1,10 @@\n-from keras import backend\n-from keras import initializers\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.optimizers import optimizer\n-from keras.saving import serialization_lib\n-from keras.utils import tracking\n+from keras.src import backend\n+from keras.src import initializers\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.optimizers import optimizer\n+from keras.src.saving import serialization_lib\n+from keras.src.utils import tracking\n \n \n @keras_export(\n@@ -207,7 +207,7 @@ class LossScaleOptimizer(optimizer.Optimizer):\n \n     def _tf_apply(self, grads, trainable_variables=None):\n         \"\"\"Tensorflow specific logic for apply, which handles distribution.\"\"\"\n-        from keras.utils.module_utils import tensorflow as tf\n+        from keras.src.utils.module_utils import tensorflow as tf\n \n         if tf.distribute.in_cross_replica_context():\n             raise ValueError(\"apply() must be called in a replica context.\")\n\n@@ -1,11 +1,11 @@\n import numpy as np\n from absl.testing import parameterized\n \n-from keras import backend\n-from keras import ops\n-from keras import testing\n-from keras.optimizers.loss_scale_optimizer import LossScaleOptimizer\n-from keras.optimizers.sgd import SGD\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src import testing\n+from keras.src.optimizers.loss_scale_optimizer import LossScaleOptimizer\n+from keras.src.optimizers.sgd import SGD\n \n \n class LossScaleOptimizerTest(testing.TestCase, parameterized.TestCase):\n\n@@ -1,7 +1,7 @@\n-from keras import backend\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.optimizers import optimizer\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.optimizers import optimizer\n \n \n @keras_export([\"keras.optimizers.Nadam\"])\n\n@@ -3,10 +3,10 @@\n \n import numpy as np\n \n-from keras import backend\n-from keras import ops\n-from keras import testing\n-from keras.optimizers.nadam import Nadam\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src import testing\n+from keras.src.optimizers.nadam import Nadam\n \n \n class NadamTest(testing.TestCase):\n\n@@ -1,17 +1,17 @@\n-from keras import backend\n-from keras.api_export import keras_export\n-from keras.optimizers import base_optimizer\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.optimizers import base_optimizer\n \n if backend.backend() == \"tensorflow\":\n-    from keras.backend.tensorflow.optimizer import (\n+    from keras.src.backend.tensorflow.optimizer import (\n         TFOptimizer as BackendOptimizer,\n     )\n elif backend.backend() == \"torch\":\n-    from keras.backend.torch.optimizers import (\n+    from keras.src.backend.torch.optimizers import (\n         TorchOptimizer as BackendOptimizer,\n     )\n elif backend.backend() == \"jax\":\n-    from keras.backend.jax.optimizer import JaxOptimizer as BackendOptimizer\n+    from keras.src.backend.jax.optimizer import JaxOptimizer as BackendOptimizer\n else:\n \n     class BackendOptimizer(base_optimizer.BaseOptimizer):\n\n@@ -3,10 +3,10 @@ from unittest import mock\n import pytest\n from absl.testing import parameterized\n \n-from keras import backend\n-from keras import ops\n-from keras import optimizers\n-from keras import testing\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src import optimizers\n+from keras.src import testing\n \n \n class ScatterUpdateOptimizer(optimizers.Optimizer):\n\n@@ -3,12 +3,12 @@ import os\n import numpy as np\n import pytest\n \n-from keras import backend\n-from keras import constraints\n-from keras import layers\n-from keras import models\n-from keras import optimizers\n-from keras import testing\n+from keras.src import backend\n+from keras.src import constraints\n+from keras.src import layers\n+from keras.src import models\n+from keras.src import optimizers\n+from keras.src import testing\n \n \n class OptimizerTest(testing.TestCase):\n\n@@ -1,6 +1,6 @@\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.optimizers import optimizer\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.optimizers import optimizer\n \n \n @keras_export([\"keras.optimizers.RMSprop\"])\n\n@@ -1,9 +1,9 @@\n import numpy as np\n \n-from keras import backend\n-from keras import ops\n-from keras import testing\n-from keras.optimizers.rmsprop import RMSprop\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src import testing\n+from keras.src.optimizers.rmsprop import RMSprop\n \n \n class RMSpropTest(testing.TestCase):\n\n@@ -0,0 +1,16 @@\n+from keras.src.optimizers.schedules.learning_rate_schedule import CosineDecay\n+from keras.src.optimizers.schedules.learning_rate_schedule import (\n+    CosineDecayRestarts,\n+)\n+from keras.src.optimizers.schedules.learning_rate_schedule import (\n+    ExponentialDecay,\n+)\n+from keras.src.optimizers.schedules.learning_rate_schedule import (\n+    InverseTimeDecay,\n+)\n+from keras.src.optimizers.schedules.learning_rate_schedule import (\n+    PiecewiseConstantDecay,\n+)\n+from keras.src.optimizers.schedules.learning_rate_schedule import (\n+    PolynomialDecay,\n+)\n\n@@ -2,9 +2,9 @@\n \n import math\n \n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.saving import serialization_lib\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.saving import serialization_lib\n \n \n @keras_export(\"keras.optimizers.schedules.LearningRateSchedule\")\n\n@@ -5,12 +5,12 @@ import math\n import numpy as np\n import pytest\n \n-from keras import backend\n-from keras import layers\n-from keras import optimizers\n-from keras import testing\n-from keras.models import Sequential\n-from keras.optimizers import schedules\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import optimizers\n+from keras.src import testing\n+from keras.src.models import Sequential\n+from keras.src.optimizers import schedules\n \n \n class TestFitLRSchedulesFlow(testing.TestCase):\n\n@@ -1,6 +1,6 @@\n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.optimizers import optimizer\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.optimizers import optimizer\n \n \n @keras_export(\"keras.optimizers.SGD\")\n\n@@ -2,10 +2,10 @@\n \n import numpy as np\n \n-from keras import backend\n-from keras import ops\n-from keras import testing\n-from keras.optimizers.sgd import SGD\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src import testing\n+from keras.src.optimizers.sgd import SGD\n \n \n class SGDTest(testing.TestCase):\n\n@@ -1,14 +1,14 @@\n import inspect\n \n-from keras.api_export import keras_export\n-from keras.quantizers.quantizers import AbsMaxQuantizer\n-from keras.quantizers.quantizers import Quantizer\n-from keras.quantizers.quantizers import abs_max_quantize\n-from keras.quantizers.quantizers import compute_float8_amax_history\n-from keras.quantizers.quantizers import compute_float8_scale\n-from keras.quantizers.quantizers import quantize_and_dequantize\n-from keras.saving import serialization_lib\n-from keras.utils.naming import to_snake_case\n+from keras.src.api_export import keras_export\n+from keras.src.quantizers.quantizers import AbsMaxQuantizer\n+from keras.src.quantizers.quantizers import Quantizer\n+from keras.src.quantizers.quantizers import abs_max_quantize\n+from keras.src.quantizers.quantizers import compute_float8_amax_history\n+from keras.src.quantizers.quantizers import compute_float8_scale\n+from keras.src.quantizers.quantizers import quantize_and_dequantize\n+from keras.src.saving import serialization_lib\n+from keras.src.utils.naming import to_snake_case\n \n ALL_OBJECTS = {Quantizer, AbsMaxQuantizer}\n ALL_OBJECTS_DICT = {cls.__name__: cls for cls in ALL_OBJECTS}\n\n@@ -1,8 +1,8 @@\n import ml_dtypes\n \n-from keras import backend\n-from keras import ops\n-from keras.api_export import keras_export\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n \n \"\"\"Int8-related classes and methods\"\"\"\n \n\n@@ -1,7 +1,7 @@\n-from keras import ops\n-from keras import quantizers\n-from keras import random\n-from keras import testing\n+from keras.src import ops\n+from keras.src import quantizers\n+from keras.src import random\n+from keras.src import testing\n \n \n class QuantizersTest(testing.TestCase):\n\n@@ -0,0 +1,9 @@\n+from keras.src.random.random import categorical\n+from keras.src.random.random import dropout\n+from keras.src.random.random import gamma\n+from keras.src.random.random import normal\n+from keras.src.random.random import randint\n+from keras.src.random.random import shuffle\n+from keras.src.random.random import truncated_normal\n+from keras.src.random.random import uniform\n+from keras.src.random.seed_generator import SeedGenerator\n\n@@ -1,5 +1,5 @@\n-from keras import backend\n-from keras.api_export import keras_export\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n \n \n @keras_export(\"keras.random.normal\")\n\n@@ -3,15 +3,15 @@ import pytest\n from absl.testing import parameterized\n \n import keras\n-from keras import backend\n-from keras import ops\n-from keras import testing\n-from keras.backend.common import dtypes\n-from keras.backend.common import standardize_dtype\n-from keras.random import random\n-from keras.random import seed_generator\n-from keras.testing.test_utils import named_product\n-from keras.utils.rng_utils import set_random_seed\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src import testing\n+from keras.src.backend.common import dtypes\n+from keras.src.backend.common import standardize_dtype\n+from keras.src.random import random\n+from keras.src.random import seed_generator\n+from keras.src.testing.test_utils import named_product\n+from keras.src.utils.rng_utils import set_random_seed\n \n \n class RandomTest(testing.TestCase, parameterized.TestCase):\n@@ -129,7 +129,7 @@ class RandomTest(testing.TestCase, parameterized.TestCase):\n \n         @jax.jit\n         def train_step(x):\n-            with keras.backend.StatelessScope():\n+            with keras.src.backend.StatelessScope():\n                 x = keras.layers.Dropout(rate=0.1)(x, training=True)\n             return x\n \n\n@@ -2,11 +2,11 @@ import random as python_random\n \n import numpy as np\n \n-from keras import backend\n-from keras.api_export import keras_export\n-from keras.backend.common import global_state\n-from keras.utils import jax_utils\n-from keras.utils.naming import auto_name\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.backend.common import global_state\n+from keras.src.utils import jax_utils\n+from keras.src.utils.naming import auto_name\n \n \n @keras_export(\"keras.random.SeedGenerator\")\n@@ -132,7 +132,7 @@ def make_default_seed():\n \n \n def draw_seed(seed):\n-    from keras.backend import convert_to_tensor\n+    from keras.src.backend import convert_to_tensor\n \n     if isinstance(seed, SeedGenerator):\n         return seed.next()\n\n@@ -1,10 +1,10 @@\n import numpy as np\n import pytest\n \n-from keras import backend\n-from keras import ops\n-from keras import testing\n-from keras.random import seed_generator\n+from keras.src import backend\n+from keras.src import ops\n+from keras.src import testing\n+from keras.src.random import seed_generator\n \n \n class SeedGeneratorTest(testing.TestCase):\n\n@@ -1,13 +1,13 @@\n import inspect\n \n-from keras.api_export import keras_export\n-from keras.regularizers.regularizers import L1\n-from keras.regularizers.regularizers import L1L2\n-from keras.regularizers.regularizers import L2\n-from keras.regularizers.regularizers import OrthogonalRegularizer\n-from keras.regularizers.regularizers import Regularizer\n-from keras.saving import serialization_lib\n-from keras.utils.naming import to_snake_case\n+from keras.src.api_export import keras_export\n+from keras.src.regularizers.regularizers import L1\n+from keras.src.regularizers.regularizers import L1L2\n+from keras.src.regularizers.regularizers import L2\n+from keras.src.regularizers.regularizers import OrthogonalRegularizer\n+from keras.src.regularizers.regularizers import Regularizer\n+from keras.src.saving import serialization_lib\n+from keras.src.utils.naming import to_snake_case\n \n ALL_OBJECTS = {\n     Regularizer,\n\n@@ -1,8 +1,8 @@\n import math\n \n-from keras import ops\n-from keras.api_export import keras_export\n-from keras.utils.numerical_utils import normalize\n+from keras.src import ops\n+from keras.src.api_export import keras_export\n+from keras.src.utils.numerical_utils import normalize\n \n \n @keras_export([\"keras.Regularizer\", \"keras.regularizers.Regularizer\"])\n\n@@ -1,9 +1,9 @@\n import numpy as np\n \n-from keras import backend\n-from keras import regularizers\n-from keras import testing\n-from keras.regularizers.regularizers import validate_float_arg\n+from keras.src import backend\n+from keras.src import regularizers\n+from keras.src import testing\n+from keras.src.regularizers.regularizers import validate_float_arg\n \n \n class RegularizersTest(testing.TestCase):\n\n@@ -0,0 +1,9 @@\n+from keras.src.saving.object_registration import CustomObjectScope\n+from keras.src.saving.object_registration import custom_object_scope\n+from keras.src.saving.object_registration import get_custom_objects\n+from keras.src.saving.object_registration import get_registered_name\n+from keras.src.saving.object_registration import get_registered_object\n+from keras.src.saving.object_registration import register_keras_serializable\n+from keras.src.saving.saving_api import load_model\n+from keras.src.saving.serialization_lib import deserialize_keras_object\n+from keras.src.saving.serialization_lib import serialize_keras_object\n\n@@ -1,7 +1,7 @@\n import inspect\n \n-from keras.api_export import keras_export\n-from keras.backend.common import global_state\n+from keras.src.api_export import keras_export\n+from keras.src.backend.common import global_state\n \n GLOBAL_CUSTOM_OBJECTS = {}\n GLOBAL_CUSTOM_NAMES = {}\n\n@@ -1,7 +1,7 @@\n import keras\n-from keras import testing\n-from keras.saving import object_registration\n-from keras.saving import serialization_lib\n+from keras.src import testing\n+from keras.src.saving import object_registration\n+from keras.src.saving import serialization_lib\n \n \n class TestObjectRegistration(testing.TestCase):\n\n@@ -3,11 +3,11 @@ import zipfile\n \n from absl import logging\n \n-from keras.api_export import keras_export\n-from keras.legacy.saving import legacy_h5_format\n-from keras.saving import saving_lib\n-from keras.utils import file_utils\n-from keras.utils import io_utils\n+from keras.src.api_export import keras_export\n+from keras.src.legacy.saving import legacy_h5_format\n+from keras.src.saving import saving_lib\n+from keras.src.utils import file_utils\n+from keras.src.utils import io_utils\n \n try:\n     import h5py\n\n@@ -5,11 +5,11 @@ import numpy as np\n from absl import logging\n from absl.testing import parameterized\n \n-from keras import layers\n-from keras.models import Sequential\n-from keras.saving import saving_api\n-from keras.testing import test_case\n-from keras.testing.test_utils import named_product\n+from keras.src import layers\n+from keras.src.models import Sequential\n+from keras.src.saving import saving_api\n+from keras.src.testing import test_case\n+from keras.src.testing.test_utils import named_product\n \n \n class SaveModelTests(test_case.TestCase):\n\n@@ -10,19 +10,19 @@ import zipfile\n import ml_dtypes\n import numpy as np\n \n-from keras import backend\n-from keras.backend.common import global_state\n-from keras.layers.layer import Layer\n-from keras.losses.loss import Loss\n-from keras.metrics.metric import Metric\n-from keras.optimizers.optimizer import Optimizer\n-from keras.saving.serialization_lib import ObjectSharingScope\n-from keras.saving.serialization_lib import deserialize_keras_object\n-from keras.saving.serialization_lib import serialize_keras_object\n-from keras.trainers.compile_utils import CompileMetrics\n-from keras.utils import file_utils\n-from keras.utils import naming\n-from keras.version import __version__ as keras_version\n+from keras.src import backend\n+from keras.src.backend.common import global_state\n+from keras.src.layers.layer import Layer\n+from keras.src.losses.loss import Loss\n+from keras.src.metrics.metric import Metric\n+from keras.src.optimizers.optimizer import Optimizer\n+from keras.src.saving.serialization_lib import ObjectSharingScope\n+from keras.src.saving.serialization_lib import deserialize_keras_object\n+from keras.src.saving.serialization_lib import serialize_keras_object\n+from keras.src.trainers.compile_utils import CompileMetrics\n+from keras.src.utils import file_utils\n+from keras.src.utils import naming\n+from keras.src.version import __version__ as keras_version\n \n try:\n     import h5py\n@@ -319,8 +319,8 @@ def _name_key(name):\n \n \n def _walk_trackable(trackable):\n-    from keras.models import Functional\n-    from keras.models import Sequential\n+    from keras.src.models import Functional\n+    from keras.src.models import Sequential\n \n     if isinstance(trackable, Sequential):\n         obj_type = \"Sequential\"\n\n@@ -12,9 +12,9 @@ import numpy as np\n import pytest\n \n import keras\n-from keras import ops\n-from keras import testing\n-from keras.saving import saving_lib\n+from keras.src import ops\n+from keras.src import testing\n+from keras.src.saving import saving_lib\n \n \n @keras.saving.register_keras_serializable(package=\"my_custom_package\")\n@@ -614,7 +614,7 @@ class SavingTest(testing.TestCase):\n @pytest.mark.requires_trainable_backend\n class SavingAPITest(testing.TestCase):\n     def test_saving_api_errors(self):\n-        from keras.saving import saving_api\n+        from keras.src.saving import saving_api\n \n         model = _get_basic_functional_model()\n \n\n@@ -7,13 +7,13 @@ import warnings\n \n import numpy as np\n \n-from keras import api_export\n-from keras import backend\n-from keras.api_export import keras_export\n-from keras.backend.common import global_state\n-from keras.saving import object_registration\n-from keras.utils import python_utils\n-from keras.utils.module_utils import tensorflow as tf\n+from keras.src import api_export\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.backend.common import global_state\n+from keras.src.saving import object_registration\n+from keras.src.utils import python_utils\n+from keras.src.utils.module_utils import tensorflow as tf\n \n PLAIN_TYPES = (str, int, float, bool)\n \n\n@@ -6,9 +6,9 @@ import numpy as np\n import pytest\n \n import keras\n-from keras import ops\n-from keras import testing\n-from keras.saving import serialization_lib\n+from keras.src import ops\n+from keras.src import testing\n+from keras.src.saving import serialization_lib\n \n \n def custom_fn(x):\n\n@@ -0,0 +1,5 @@\n+from keras.src.testing.test_case import TestCase\n+from keras.src.testing.test_case import jax_uses_gpu\n+from keras.src.testing.test_case import tensorflow_uses_gpu\n+from keras.src.testing.test_case import torch_uses_gpu\n+from keras.src.testing.test_case import uses_gpu\n\n@@ -5,17 +5,17 @@ import unittest\n \n import numpy as np\n \n-from keras import backend\n-from keras import distribution\n-from keras import ops\n-from keras import tree\n-from keras import utils\n-from keras.backend.common import is_float_dtype\n-from keras.backend.common import standardize_dtype\n-from keras.backend.common.global_state import clear_session\n-from keras.backend.common.keras_tensor import KerasTensor\n-from keras.models import Model\n-from keras.utils import traceback_utils\n+from keras.src import backend\n+from keras.src import distribution\n+from keras.src import ops\n+from keras.src import tree\n+from keras.src import utils\n+from keras.src.backend.common import is_float_dtype\n+from keras.src.backend.common import standardize_dtype\n+from keras.src.backend.common.global_state import clear_session\n+from keras.src.backend.common.keras_tensor import KerasTensor\n+from keras.src.models import Model\n+from keras.src.utils import traceback_utils\n \n \n class TestCase(unittest.TestCase):\n@@ -100,9 +100,9 @@ class TestCase(unittest.TestCase):\n             )\n \n     def run_class_serialization_test(self, instance, custom_objects=None):\n-        from keras.saving import custom_object_scope\n-        from keras.saving import deserialize_keras_object\n-        from keras.saving import serialize_keras_object\n+        from keras.src.saving import custom_object_scope\n+        from keras.src.saving import deserialize_keras_object\n+        from keras.src.saving import serialize_keras_object\n \n         # get_config roundtrip\n         cls = instance.__class__\n@@ -599,7 +599,7 @@ def create_keras_tensors(input_shape, dtype, sparse):\n \n \n def create_eager_tensors(input_shape, dtype, sparse):\n-    from keras.backend import random\n+    from keras.src.backend import random\n \n     if set(tree.flatten(dtype)).difference(\n         [\"float16\", \"float32\", \"float64\", \"int16\", \"int32\", \"int64\"]\n\n\n@@ -1,8 +1,8 @@\n import numpy as np\n from absl.testing import parameterized\n \n-from keras.testing import test_case\n-from keras.testing import test_utils\n+from keras.src.testing import test_case\n+from keras.src.testing import test_utils\n \n \n class GetTestDataTest(test_case.TestCase):\n\n\n@@ -1,9 +1,9 @@\n-from keras import backend\n-from keras import losses as losses_module\n-from keras import metrics as metrics_module\n-from keras import ops\n-from keras import tree\n-from keras.utils.naming import get_object_name\n+from keras.src import backend\n+from keras.src import losses as losses_module\n+from keras.src import metrics as metrics_module\n+from keras.src import ops\n+from keras.src import tree\n+from keras.src.utils.naming import get_object_name\n \n \n class MetricsList(metrics_module.Metric):\n\n@@ -1,13 +1,13 @@\n import numpy as np\n from absl.testing import parameterized\n \n-from keras import backend\n-from keras import metrics as losses_module\n-from keras import metrics as metrics_module\n-from keras import ops\n-from keras import testing\n-from keras.trainers.compile_utils import CompileLoss\n-from keras.trainers.compile_utils import CompileMetrics\n+from keras.src import backend\n+from keras.src import metrics as losses_module\n+from keras.src import metrics as metrics_module\n+from keras.src import ops\n+from keras.src import testing\n+from keras.src.trainers.compile_utils import CompileLoss\n+from keras.src.trainers.compile_utils import CompileMetrics\n \n \n class TestCompileMetrics(testing.TestCase):\n\n@@ -1,15 +1,15 @@\n import types\n \n-from keras.distribution import distribution_lib\n-from keras.trainers.data_adapters import array_data_adapter\n-from keras.trainers.data_adapters import py_dataset_adapter\n-from keras.trainers.data_adapters.array_data_adapter import ArrayDataAdapter\n-from keras.trainers.data_adapters.generator_data_adapter import (\n+from keras.src.distribution import distribution_lib\n+from keras.src.trainers.data_adapters import array_data_adapter\n+from keras.src.trainers.data_adapters import py_dataset_adapter\n+from keras.src.trainers.data_adapters.array_data_adapter import ArrayDataAdapter\n+from keras.src.trainers.data_adapters.generator_data_adapter import (\n     GeneratorDataAdapter,\n )\n-from keras.trainers.data_adapters.py_dataset_adapter import PyDatasetAdapter\n-from keras.trainers.data_adapters.tf_dataset_adapter import TFDatasetAdapter\n-from keras.trainers.data_adapters.torch_data_loader_adapter import (\n+from keras.src.trainers.data_adapters.py_dataset_adapter import PyDatasetAdapter\n+from keras.src.trainers.data_adapters.tf_dataset_adapter import TFDatasetAdapter\n+from keras.src.trainers.data_adapters.torch_data_loader_adapter import (\n     TorchDataLoaderAdapter,\n )\n \n\n@@ -3,10 +3,10 @@ import math\n \n import numpy as np\n \n-from keras import tree\n-from keras.trainers.data_adapters import array_slicing\n-from keras.trainers.data_adapters import data_adapter_utils\n-from keras.trainers.data_adapters.data_adapter import DataAdapter\n+from keras.src import tree\n+from keras.src.trainers.data_adapters import array_slicing\n+from keras.src.trainers.data_adapters import data_adapter_utils\n+from keras.src.trainers.data_adapters.data_adapter import DataAdapter\n \n \n class ArrayDataAdapter(DataAdapter):\n@@ -103,7 +103,7 @@ class ArrayDataAdapter(DataAdapter):\n         return self._get_iterator(slice_and_convert_to_numpy, inputs)\n \n     def get_tf_dataset(self):\n-        from keras.utils.module_utils import tensorflow as tf\n+        from keras.src.utils.module_utils import tensorflow as tf\n \n         shuffle = self._shuffle\n         batch_size = self._batch_size\n@@ -243,7 +243,7 @@ class ArrayDataAdapter(DataAdapter):\n         return dataset.prefetch(tf.data.AUTOTUNE)\n \n     def get_jax_iterator(self):\n-        from keras.backend.jax.core import convert_to_tensor\n+        from keras.src.backend.jax.core import convert_to_tensor\n \n         inputs = array_slicing.convert_to_sliceable(\n             self._inputs, target_backend=\"jax\"\n@@ -260,7 +260,7 @@ class ArrayDataAdapter(DataAdapter):\n     def get_torch_dataloader(self):\n         import torch\n \n-        from keras.backend.torch.core import convert_to_tensor\n+        from keras.src.backend.torch.core import convert_to_tensor\n \n         class ArrayDataset(torch.utils.data.Dataset):\n             def __init__(self, array):\n\n@@ -7,10 +7,10 @@ import tensorflow as tf\n import torch\n from absl.testing import parameterized\n \n-from keras import backend\n-from keras import testing\n-from keras.testing.test_utils import named_product\n-from keras.trainers.data_adapters import array_data_adapter\n+from keras.src import backend\n+from keras.src import testing\n+from keras.src.testing.test_utils import named_product\n+from keras.src.trainers.data_adapters import array_data_adapter\n \n \n class TestArrayDataAdapter(testing.TestCase, parameterized.TestCase):\n\n@@ -3,9 +3,9 @@ import math\n \n import numpy as np\n \n-from keras import backend\n-from keras import tree\n-from keras.trainers.data_adapters import data_adapter_utils\n+from keras.src import backend\n+from keras.src import tree\n+from keras.src.trainers.data_adapters import data_adapter_utils\n \n try:\n     import pandas\n@@ -124,7 +124,7 @@ class NumpySliceable(Sliceable):\n \n class TensorflowSliceable(Sliceable):\n     def __getitem__(self, indices):\n-        from keras.utils.module_utils import tensorflow as tf\n+        from keras.src.utils.module_utils import tensorflow as tf\n \n         if isinstance(indices, slice):\n             return self.array[indices]\n@@ -133,13 +133,13 @@ class TensorflowSliceable(Sliceable):\n \n     @classmethod\n     def cast(cls, x, dtype):\n-        from keras.backend.tensorflow.core import cast\n+        from keras.src.backend.tensorflow.core import cast\n \n         return cast(x, dtype)\n \n     @classmethod\n     def convert_to_numpy(cls, x):\n-        from keras.backend.tensorflow.core import convert_to_numpy\n+        from keras.src.backend.tensorflow.core import convert_to_numpy\n \n         return convert_to_numpy(x)\n \n@@ -175,7 +175,7 @@ class TensorflowSparseSliceable(TensorflowSliceable):\n \n     @classmethod\n     def convert_to_torch_compatible(cls, x):\n-        from keras.backend.tensorflow import sparse as tf_sparse\n+        from keras.src.backend.tensorflow import sparse as tf_sparse\n \n         return tf_sparse.sparse_to_dense(x)\n \n@@ -186,7 +186,7 @@ class JaxSliceable(Sliceable):\n \n     @classmethod\n     def convert_to_numpy(cls, x):\n-        from keras.backend.jax.core import convert_to_numpy\n+        from keras.src.backend.jax.core import convert_to_numpy\n \n         return convert_to_numpy(x)\n \n@@ -206,13 +206,13 @@ class JaxSparseSliceable(JaxSliceable):\n class TorchSliceable(Sliceable):\n     @classmethod\n     def cast(cls, x, dtype):\n-        from keras.backend.torch.core import cast\n+        from keras.src.backend.torch.core import cast\n \n         return cast(x, dtype)\n \n     @classmethod\n     def convert_to_numpy(cls, x):\n-        from keras.backend.torch.core import convert_to_numpy\n+        from keras.src.backend.torch.core import convert_to_numpy\n \n         return convert_to_numpy(x)\n \n@@ -293,7 +293,7 @@ TensorflowSparseWrapper = collections.namedtuple(\n \n \n def to_tensorflow_sparse_wrapper(sparse):\n-    from keras.utils.module_utils import tensorflow as tf\n+    from keras.src.utils.module_utils import tensorflow as tf\n \n     row_ids = sparse.indices[:, 0]\n     row_splits = tf.experimental.RowPartition.from_value_rowids(\n@@ -308,7 +308,7 @@ def to_tensorflow_sparse_wrapper(sparse):\n \n \n def slice_tensorflow_sparse_wrapper(sparse_wrapper, indices):\n-    from keras.utils.module_utils import tensorflow as tf\n+    from keras.src.utils.module_utils import tensorflow as tf\n \n     if isinstance(indices, slice):\n         sparse_indices = sparse_wrapper.ragged_indices[indices]\n\n\n@@ -1,8 +1,8 @@\n import numpy as np\n \n-from keras import backend\n-from keras import tree\n-from keras.api_export import keras_export\n+from keras.src import backend\n+from keras.src import tree\n+from keras.src.api_export import keras_export\n \n NUM_BATCHES_FOR_TENSOR_SPEC = 2\n \n@@ -135,7 +135,7 @@ def get_tensor_spec(batches):\n             identical, but the shape at each leaf may be different.\n     Returns: the common tensor spec for all the batches.\n     \"\"\"\n-    from keras.utils.module_utils import tensorflow as tf\n+    from keras.src.utils.module_utils import tensorflow as tf\n \n     def get_single_tensor_spec(*tensors):\n         x = tensors[0]\n@@ -176,7 +176,7 @@ def get_tensor_spec(batches):\n \n \n def get_jax_iterator(iterable):\n-    from keras.backend.jax.core import convert_to_tensor\n+    from keras.src.backend.jax.core import convert_to_tensor\n \n     for batch in iterable:\n         yield tree.map_structure(convert_to_tensor, batch)\n@@ -201,7 +201,7 @@ def get_numpy_iterator(iterable):\n def get_torch_dataloader(iterable):\n     import torch.utils.data as torch_data\n \n-    from keras.backend.torch.core import convert_to_tensor\n+    from keras.src.backend.torch.core import convert_to_tensor\n \n     class ConverterIterableDataset(torch_data.IterableDataset):\n         def __init__(self, iterable):\n@@ -279,7 +279,7 @@ def is_scipy_sparse(x):\n \n \n def scipy_sparse_to_tf_sparse(x):\n-    from keras.utils.module_utils import tensorflow as tf\n+    from keras.src.utils.module_utils import tensorflow as tf\n \n     coo = x.tocoo()\n     indices = np.concatenate(\n@@ -303,6 +303,6 @@ def tf_sparse_to_jax_sparse(x):\n \n \n def jax_sparse_to_tf_sparse(x):\n-    from keras.utils.module_utils import tensorflow as tf\n+    from keras.src.utils.module_utils import tensorflow as tf\n \n     return tf.SparseTensor(x.indices, x.data, x.shape)\n\n@@ -1,8 +1,8 @@\n import itertools\n \n-from keras import tree\n-from keras.trainers.data_adapters import data_adapter_utils\n-from keras.trainers.data_adapters.data_adapter import DataAdapter\n+from keras.src import tree\n+from keras.src.trainers.data_adapters import data_adapter_utils\n+from keras.src.trainers.data_adapters.data_adapter import DataAdapter\n \n \n class GeneratorDataAdapter(DataAdapter):\n@@ -26,7 +26,7 @@ class GeneratorDataAdapter(DataAdapter):\n         return data_adapter_utils.get_numpy_iterator(self.generator)\n \n     def get_jax_iterator(self):\n-        from keras.backend.jax.core import convert_to_tensor\n+        from keras.src.backend.jax.core import convert_to_tensor\n \n         def convert_to_jax(x):\n             if data_adapter_utils.is_scipy_sparse(x):\n@@ -39,7 +39,7 @@ class GeneratorDataAdapter(DataAdapter):\n             yield tree.map_structure(convert_to_jax, batch)\n \n     def get_tf_dataset(self):\n-        from keras.utils.module_utils import tensorflow as tf\n+        from keras.src.utils.module_utils import tensorflow as tf\n \n         def convert_to_tf(x):\n             if data_adapter_utils.is_scipy_sparse(x):\n\n@@ -9,9 +9,9 @@ import torch\n from absl.testing import parameterized\n from jax import numpy as jnp\n \n-from keras import testing\n-from keras.testing.test_utils import named_product\n-from keras.trainers.data_adapters import generator_data_adapter\n+from keras.src import testing\n+from keras.src.testing.test_utils import named_product\n+from keras.src.trainers.data_adapters import generator_data_adapter\n \n \n def example_generator(x, y, sample_weight=None, batch_size=32):\n\n@@ -9,9 +9,9 @@ from contextlib import closing\n \n import numpy as np\n \n-from keras.api_export import keras_export\n-from keras.trainers.data_adapters import data_adapter_utils\n-from keras.trainers.data_adapters.data_adapter import DataAdapter\n+from keras.src.api_export import keras_export\n+from keras.src.trainers.data_adapters import data_adapter_utils\n+from keras.src.trainers.data_adapters.data_adapter import DataAdapter\n \n \n @keras_export([\"keras.utils.PyDataset\", \"keras.utils.Sequence\"])\n@@ -260,7 +260,7 @@ class PyDatasetAdapter(DataAdapter):\n         return data_adapter_utils.get_jax_iterator(self._get_iterator())\n \n     def get_tf_dataset(self):\n-        from keras.utils.module_utils import tensorflow as tf\n+        from keras.src.utils.module_utils import tensorflow as tf\n \n         if self._output_signature is None:\n             num_samples = min(\n\n@@ -7,10 +7,10 @@ import tensorflow as tf\n import torch\n from absl.testing import parameterized\n \n-from keras import testing\n-from keras.testing.test_utils import named_product\n-from keras.trainers.data_adapters import py_dataset_adapter\n-from keras.utils.rng_utils import set_random_seed\n+from keras.src import testing\n+from keras.src.testing.test_utils import named_product\n+from keras.src.trainers.data_adapters import py_dataset_adapter\n+from keras.src.utils.rng_utils import set_random_seed\n \n \n class ExamplePyDataset(py_dataset_adapter.PyDataset):\n\n@@ -1,6 +1,6 @@\n-from keras import tree\n-from keras.trainers.data_adapters import data_adapter_utils\n-from keras.trainers.data_adapters.data_adapter import DataAdapter\n+from keras.src import tree\n+from keras.src.trainers.data_adapters import data_adapter_utils\n+from keras.src.trainers.data_adapters.data_adapter import DataAdapter\n \n \n class TFDatasetAdapter(DataAdapter):\n@@ -17,7 +17,7 @@ class TFDatasetAdapter(DataAdapter):\n                 shard the input dataset into per worker/process dataset\n                 instance.\n         \"\"\"\n-        from keras.utils.module_utils import tensorflow as tf\n+        from keras.src.utils.module_utils import tensorflow as tf\n \n         if not isinstance(\n             dataset, (tf.data.Dataset, tf.distribute.DistributedDataset)\n@@ -35,7 +35,7 @@ class TFDatasetAdapter(DataAdapter):\n         self._dataset = dataset\n \n     def get_numpy_iterator(self):\n-        from keras.backend.tensorflow.core import convert_to_numpy\n+        from keras.src.backend.tensorflow.core import convert_to_numpy\n \n         for batch in self._dataset:\n             yield tree.map_structure(convert_to_numpy, batch)\n@@ -43,9 +43,9 @@ class TFDatasetAdapter(DataAdapter):\n     def get_jax_iterator(self):\n         import jax.experimental.sparse as jax_sparse\n \n-        from keras.backend.jax.core import convert_to_tensor\n-        from keras.backend.tensorflow.core import convert_to_numpy\n-        from keras.utils.module_utils import tensorflow as tf\n+        from keras.src.backend.jax.core import convert_to_tensor\n+        from keras.src.backend.tensorflow.core import convert_to_numpy\n+        from keras.src.utils.module_utils import tensorflow as tf\n \n         def convert_to_jax(x):\n             # We use numpy as an intermediary because the conversion\n@@ -107,7 +107,7 @@ def make_class_weight_map_fn(class_weight):\n         A function that can be used with `tf.data.Dataset.map` to apply class\n         weighting.\n     \"\"\"\n-    from keras.utils.module_utils import tensorflow as tf\n+    from keras.src.utils.module_utils import tensorflow as tf\n \n     class_weight_tensor = tf.convert_to_tensor(\n         [\n\n@@ -6,9 +6,9 @@ import tensorflow as tf\n import torch\n from absl.testing import parameterized\n \n-from keras import testing\n-from keras.testing.test_utils import named_product\n-from keras.trainers.data_adapters import tf_dataset_adapter\n+from keras.src import testing\n+from keras.src.testing.test_utils import named_product\n+from keras.src.trainers.data_adapters import tf_dataset_adapter\n \n \n class TestTFDatasetAdapter(testing.TestCase, parameterized.TestCase):\n\n@@ -2,9 +2,9 @@ import itertools\n \n import numpy as np\n \n-from keras import tree\n-from keras.trainers.data_adapters import data_adapter_utils\n-from keras.trainers.data_adapters.data_adapter import DataAdapter\n+from keras.src import tree\n+from keras.src.trainers.data_adapters import data_adapter_utils\n+from keras.src.trainers.data_adapters.data_adapter import DataAdapter\n \n \n class TorchDataLoaderAdapter(DataAdapter):\n@@ -44,7 +44,7 @@ class TorchDataLoaderAdapter(DataAdapter):\n         return data_adapter_utils.get_jax_iterator(self.get_numpy_iterator())\n \n     def get_tf_dataset(self):\n-        from keras.utils.module_utils import tensorflow as tf\n+        from keras.src.utils.module_utils import tensorflow as tf\n \n         if self._output_signature is None:\n             batches = list(\n\n@@ -6,9 +6,9 @@ import tensorflow as tf\n import torch\n from absl.testing import parameterized\n \n-from keras import testing\n-from keras.testing.test_utils import named_product\n-from keras.trainers.data_adapters.torch_data_loader_adapter import (\n+from keras.src import testing\n+from keras.src.testing.test_utils import named_product\n+from keras.src.trainers.data_adapters.torch_data_loader_adapter import (\n     TorchDataLoaderAdapter,\n )\n \n\n@@ -41,7 +41,7 @@ or until there is no data\n \n import warnings\n \n-from keras.trainers import data_adapters\n+from keras.src.trainers import data_adapters\n \n \n class EpochIterator:\n\n@@ -2,10 +2,10 @@ import numpy as np\n import pytest\n import tensorflow as tf\n \n-from keras import backend\n-from keras import testing\n-from keras.trainers import data_adapters\n-from keras.trainers import epoch_iterator\n+from keras.src import backend\n+from keras.src import testing\n+from keras.src.trainers import data_adapters\n+from keras.src.trainers import epoch_iterator\n \n \n class TestEpochIterator(testing.TestCase):\n\n@@ -1,18 +1,18 @@\n import platform\n import warnings\n \n-from keras import backend\n-from keras import metrics as metrics_module\n-from keras import ops\n-from keras import optimizers\n-from keras import tree\n-from keras.optimizers.loss_scale_optimizer import LossScaleOptimizer\n-from keras.saving import serialization_lib\n-from keras.trainers.compile_utils import CompileLoss\n-from keras.trainers.compile_utils import CompileMetrics\n-from keras.trainers.data_adapters import data_adapter_utils\n-from keras.utils import traceback_utils\n-from keras.utils import tracking\n+from keras.src import backend\n+from keras.src import metrics as metrics_module\n+from keras.src import ops\n+from keras.src import optimizers\n+from keras.src import tree\n+from keras.src.optimizers.loss_scale_optimizer import LossScaleOptimizer\n+from keras.src.saving import serialization_lib\n+from keras.src.trainers.compile_utils import CompileLoss\n+from keras.src.trainers.compile_utils import CompileMetrics\n+from keras.src.trainers.data_adapters import data_adapter_utils\n+from keras.src.utils import traceback_utils\n+from keras.src.utils import tracking\n \n \n class Trainer:\n@@ -995,7 +995,7 @@ def model_supports_jit(model):\n     # XLA not supported with TF on MacOS GPU\n     if platform.system() == \"Darwin\" and \"arm\" in platform.processor().lower():\n         if backend.backend() == \"tensorflow\":\n-            from keras.utils.module_utils import tensorflow as tf\n+            from keras.src.utils.module_utils import tensorflow as tf\n \n             if tf.config.list_physical_devices(\"GPU\"):\n                 return False\n\n@@ -5,27 +5,29 @@ import pytest\n from absl.testing import parameterized\n \n import keras\n-from keras import backend\n-from keras import initializers\n-from keras import layers\n-from keras import losses\n-from keras import metrics\n-from keras import models\n-from keras import ops\n-from keras import optimizers\n-from keras import testing\n-from keras.callbacks.callback import Callback\n-from keras.optimizers.rmsprop import RMSprop\n-from keras.testing.test_utils import named_product\n+from keras.src import backend\n+from keras.src import initializers\n+from keras.src import layers\n+from keras.src import losses\n+from keras.src import metrics\n+from keras.src import models\n+from keras.src import ops\n+from keras.src import optimizers\n+from keras.src import testing\n+from keras.src.callbacks.callback import Callback\n+from keras.src.optimizers.rmsprop import RMSprop\n+from keras.src.testing.test_utils import named_product\n \n if backend.backend() == \"jax\":\n-    from keras.backend.jax.trainer import JAXTrainer as Trainer\n+    from keras.src.backend.jax.trainer import JAXTrainer as Trainer\n elif backend.backend() == \"torch\":\n-    from keras.backend.torch.trainer import TorchTrainer as Trainer\n+    from keras.src.backend.torch.trainer import TorchTrainer as Trainer\n elif backend.backend() == \"tensorflow\":\n-    from keras.backend.tensorflow.trainer import TensorFlowTrainer as Trainer\n+    from keras.src.backend.tensorflow.trainer import (\n+        TensorFlowTrainer as Trainer,\n+    )\n elif backend.backend() == \"numpy\":\n-    from keras.backend.numpy.trainer import NumpyTrainer as Trainer\n+    from keras.src.backend.numpy.trainer import NumpyTrainer as Trainer\n else:\n     raise ImportError(f\"Invalid backend: {backend.backend()}\")\n \n@@ -966,7 +968,7 @@ class TestTrainer(testing.TestCase, parameterized.TestCase):\n     def get_functional(self):\n         ExampleLayer = self.get_layer()\n \n-        class ExampleFunctional(keras.Functional):\n+        class ExampleFunctional(keras.src.Functional):\n             def __init__(self, input_shape=(None,)):\n                 inputs = keras.Input(input_shape)\n                 outputs = ExampleLayer()(inputs)\n@@ -996,7 +998,7 @@ class TestTrainer(testing.TestCase, parameterized.TestCase):\n         reason=\"Only tensorflow supports raggeds\",\n     )\n     def test_trainer_with_raggeds(self, model_class):\n-        from keras.utils.module_utils import tensorflow as tf\n+        from keras.src.utils.module_utils import tensorflow as tf\n \n         def loss_fn(y, y_pred, sample_weight=None):\n             return 0\n\n@@ -0,0 +1,10 @@\n+from keras.src.tree.tree_api import assert_same_structure\n+from keras.src.tree.tree_api import flatten\n+from keras.src.tree.tree_api import is_nested\n+from keras.src.tree.tree_api import lists_to_tuples\n+from keras.src.tree.tree_api import map_shape_structure\n+from keras.src.tree.tree_api import map_structure\n+from keras.src.tree.tree_api import map_structure_up_to\n+from keras.src.tree.tree_api import pack_sequence_as\n+from keras.src.tree.tree_api import register_tree_node_class\n+from keras.src.tree.tree_api import traverse\n\n@@ -1,4 +1,4 @@\n-from keras.utils.module_utils import dmtree\n+from keras.src.utils.module_utils import dmtree\n \n \n def register_tree_node_class(cls):\n\n@@ -5,7 +5,7 @@ import types\n import optree\n import optree.utils\n \n-from keras.backend.config import backend\n+from keras.src.backend.config import backend\n \n \n def register_tree_node_class(cls):\n\n@@ -1,11 +1,11 @@\n-from keras.api_export import keras_export\n-from keras.utils.module_utils import dmtree\n-from keras.utils.module_utils import optree\n+from keras.src.api_export import keras_export\n+from keras.src.utils.module_utils import dmtree\n+from keras.src.utils.module_utils import optree\n \n if optree.available:\n-    from keras.tree import optree_impl as tree_impl\n+    from keras.src.tree import optree_impl as tree_impl\n elif dmtree.available:\n-    from keras.tree import dmtree_impl as tree_impl\n+    from keras.src.tree import dmtree_impl as tree_impl\n else:\n     raise ImportError(\n         \"To use Keras, you need to have `optree` installed. \"\n\n@@ -2,9 +2,9 @@ import collections\n \n import numpy as np\n \n-from keras import ops\n-from keras import testing\n-from keras import tree\n+from keras.src import ops\n+from keras.src import testing\n+from keras.src import tree\n \n STRUCTURE1 = (((1, 2), 3), 4, (5, 6))\n STRUCTURE2 = (((\"foo1\", \"foo2\"), \"foo3\"), \"foo4\", (\"foo5\", \"foo6\"))\n\n@@ -0,0 +1,26 @@\n+from keras.src.utils.audio_dataset_utils import audio_dataset_from_directory\n+from keras.src.utils.dataset_utils import split_dataset\n+from keras.src.utils.file_utils import get_file\n+from keras.src.utils.image_dataset_utils import image_dataset_from_directory\n+from keras.src.utils.image_utils import array_to_img\n+from keras.src.utils.image_utils import img_to_array\n+from keras.src.utils.image_utils import load_img\n+from keras.src.utils.image_utils import save_img\n+from keras.src.utils.io_utils import disable_interactive_logging\n+from keras.src.utils.io_utils import enable_interactive_logging\n+from keras.src.utils.io_utils import is_interactive_logging_enabled\n+from keras.src.utils.model_visualization import model_to_dot\n+from keras.src.utils.model_visualization import plot_model\n+from keras.src.utils.numerical_utils import normalize\n+from keras.src.utils.numerical_utils import to_categorical\n+from keras.src.utils.progbar import Progbar\n+from keras.src.utils.python_utils import default\n+from keras.src.utils.python_utils import is_default\n+from keras.src.utils.python_utils import removeprefix\n+from keras.src.utils.python_utils import removesuffix\n+from keras.src.utils.rng_utils import set_random_seed\n+from keras.src.utils.sequence_utils import pad_sequences\n+from keras.src.utils.text_dataset_utils import text_dataset_from_directory\n+from keras.src.utils.timeseries_dataset_utils import (\n+    timeseries_dataset_from_array,\n+)\n\n\n@@ -1,9 +1,9 @@\n import numpy as np\n \n-from keras.api_export import keras_export\n-from keras.utils import dataset_utils\n-from keras.utils.module_utils import tensorflow as tf\n-from keras.utils.module_utils import tensorflow_io as tfio\n+from keras.src.api_export import keras_export\n+from keras.src.utils import dataset_utils\n+from keras.src.utils.module_utils import tensorflow as tf\n+from keras.src.utils.module_utils import tensorflow_io as tfio\n \n ALLOWED_FORMATS = (\".wav\",)\n \n\n@@ -2,9 +2,9 @@ import os\n \n import numpy as np\n \n-from keras import testing\n-from keras.utils import audio_dataset_utils\n-from keras.utils.module_utils import tensorflow as tf\n+from keras.src import testing\n+from keras.src.utils import audio_dataset_utils\n+from keras.src.utils.module_utils import tensorflow as tf\n \n \n class AudioDatasetFromDirectoryTest(testing.TestCase):\n\n@@ -3,9 +3,9 @@ import importlib\n import os\n import sys\n \n-from keras import backend as backend_module\n-from keras.api_export import keras_export\n-from keras.backend.common import global_state\n+from keras.src import backend as backend_module\n+from keras.src.api_export import keras_export\n+from keras.src.backend.common import global_state\n \n \n def in_tf_graph():\n@@ -13,7 +13,7 @@ def in_tf_graph():\n         return True\n \n     if \"tensorflow\" in sys.modules:\n-        from keras.utils.module_utils import tensorflow as tf\n+        from keras.src.utils.module_utils import tensorflow as tf\n \n         return not tf.executing_eagerly()\n     return False\n@@ -67,23 +67,23 @@ class DynamicBackend:\n \n     def __getattr__(self, name):\n         if self._backend == \"tensorflow\":\n-            from keras.backend import tensorflow as tf_backend\n+            from keras.src.backend import tensorflow as tf_backend\n \n             return getattr(tf_backend, name)\n         if self._backend == \"jax\":\n-            from keras.backend import jax as jax_backend\n+            from keras.src.backend import jax as jax_backend\n \n             return getattr(jax_backend, name)\n         if self._backend == \"torch\":\n-            from keras.backend import torch as torch_backend\n+            from keras.src.backend import torch as torch_backend\n \n             return getattr(torch_backend, name)\n         if self._backend == \"numpy\":\n             # TODO (ariG23498):\n-            # The import `from keras.backend import numpy as numpy_backend`\n+            # The import `from keras.src.backend import numpy as numpy_backend`\n             # is not working. This is a temporary fix.\n             # The import is redirected to `keras.backend.numpy.numpy.py`\n-            from keras import backend as numpy_backend\n+            from keras.src import backend as numpy_backend\n \n             return getattr(numpy_backend, name)\n \n\n\n@@ -2,8 +2,8 @@ import os\n import sys\n from io import StringIO\n \n-from keras.testing import test_case\n-from keras.utils.code_stats import count_loc\n+from keras.src.testing import test_case\n+from keras.src.utils.code_stats import count_loc\n \n \n class TestCountLoc(test_case.TestCase):\n\n@@ -6,9 +6,9 @@ from multiprocessing.pool import ThreadPool\n \n import numpy as np\n \n-from keras.api_export import keras_export\n-from keras.utils import io_utils\n-from keras.utils.module_utils import tensorflow as tf\n+from keras.src.api_export import keras_export\n+from keras.src.utils import io_utils\n+from keras.src.utils.module_utils import tensorflow as tf\n \n \n @keras_export(\"keras.utils.split_dataset\")\n@@ -248,7 +248,9 @@ def _get_next_sample(\n     Yields:\n         data_sample: The next sample.\n     \"\"\"\n-    from keras.trainers.data_adapters.data_adapter_utils import is_torch_tensor\n+    from keras.src.trainers.data_adapters.data_adapter_utils import (\n+        is_torch_tensor,\n+    )\n \n     try:\n         dataset_iterator = iter(dataset_iterator)\n\n@@ -1,8 +1,8 @@\n import numpy as np\n \n-from keras.testing import test_case\n-from keras.utils.dataset_utils import split_dataset\n-from keras.utils.module_utils import tensorflow as tf\n+from keras.src.testing import test_case\n+from keras.src.utils.dataset_utils import split_dataset\n+from keras.src.utils.module_utils import tensorflow as tf\n \n \n class DatasetUtilsTest(test_case.TestCase):\n\n@@ -1,5 +1,5 @@\n-from keras import backend\n-from keras import ops\n+from keras.src import backend\n+from keras.src import ops\n \n DTYPE_TO_SIZE = {\n     **{f\"float{i}\": i for i in (16, 32, 64)},\n\n@@ -1,6 +1,6 @@\n-from keras.backend.common.keras_tensor import KerasTensor\n-from keras.testing import test_case\n-from keras.utils import dtype_utils\n+from keras.src.backend.common.keras_tensor import KerasTensor\n+from keras.src.testing import test_case\n+from keras.src.utils import dtype_utils\n \n \n class DtypeSizeTests(test_case.TestCase):\n\n@@ -9,11 +9,11 @@ import warnings\n import zipfile\n from urllib.request import urlretrieve\n \n-from keras.api_export import keras_export\n-from keras.backend import config\n-from keras.utils import io_utils\n-from keras.utils.module_utils import gfile\n-from keras.utils.progbar import Progbar\n+from keras.src.api_export import keras_export\n+from keras.src.backend import config\n+from keras.src.utils import io_utils\n+from keras.src.utils.module_utils import gfile\n+from keras.src.utils.progbar import Progbar\n \n \n def path_to_string(path):\n\n@@ -8,8 +8,8 @@ import urllib\n import zipfile\n from unittest.mock import patch\n \n-from keras.testing import test_case\n-from keras.utils import file_utils\n+from keras.src.testing import test_case\n+from keras.src.utils import file_utils\n \n \n class PathToStringTest(test_case.TestCase):\n\n@@ -1,10 +1,10 @@\n import numpy as np\n \n-from keras.api_export import keras_export\n-from keras.backend.config import standardize_data_format\n-from keras.utils import dataset_utils\n-from keras.utils import image_utils\n-from keras.utils.module_utils import tensorflow as tf\n+from keras.src.api_export import keras_export\n+from keras.src.backend.config import standardize_data_format\n+from keras.src.utils import dataset_utils\n+from keras.src.utils import image_utils\n+from keras.src.utils.module_utils import tensorflow as tf\n \n ALLOWLIST_FORMATS = (\".bmp\", \".gif\", \".jpeg\", \".jpg\", \".png\")\n \n@@ -415,7 +415,7 @@ def load_image(\n         )\n \n     if crop_to_aspect_ratio:\n-        from keras.backend import tensorflow as tf_backend\n+        from keras.src.backend import tensorflow as tf_backend\n \n         if data_format == \"channels_first\":\n             img = tf.transpose(img, (2, 0, 1))\n\n@@ -2,11 +2,11 @@ import os\n \n import numpy as np\n \n-from keras import backend\n-from keras import testing\n-from keras.utils import image_dataset_utils\n-from keras.utils import image_utils\n-from keras.utils.module_utils import tensorflow as tf\n+from keras.src import backend\n+from keras.src import testing\n+from keras.src.utils import image_dataset_utils\n+from keras.src.utils import image_utils\n+from keras.src.utils.module_utils import tensorflow as tf\n \n \n class ImageDatasetFromDirectoryTest(testing.TestCase):\n\n@@ -6,8 +6,8 @@ import warnings\n \n import numpy as np\n \n-from keras import backend\n-from keras.api_export import keras_export\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n \n try:\n     from PIL import Image as pil_image\n\n@@ -2,8 +2,8 @@ import sys\n \n from absl import logging\n \n-from keras.api_export import keras_export\n-from keras.backend.common import global_state\n+from keras.src.api_export import keras_export\n+from keras.src.backend.common import global_state\n \n \n @keras_export(\n\n@@ -1,7 +1,7 @@\n from unittest.mock import patch\n \n-from keras.testing import test_case\n-from keras.utils import io_utils\n+from keras.src.testing import test_case\n+from keras.src.utils import io_utils\n \n \n class TestIoUtils(test_case.TestCase):\n\n@@ -2,14 +2,14 @@ import inspect\n \n import numpy as np\n \n-from keras import backend\n-from keras import tree\n-from keras.api_export import keras_export\n-from keras.layers.layer import Layer\n-from keras.saving import serialization_lib\n-from keras.utils import jax_utils\n-from keras.utils import tracking\n-from keras.utils.module_utils import jax\n+from keras.src import backend\n+from keras.src import tree\n+from keras.src.api_export import keras_export\n+from keras.src.layers.layer import Layer\n+from keras.src.saving import serialization_lib\n+from keras.src.utils import jax_utils\n+from keras.src.utils import tracking\n+from keras.src.utils.module_utils import jax\n \n \n @keras_export(\"keras.layers.JaxLayer\")\n\n@@ -7,18 +7,18 @@ import pytest\n import tensorflow as tf\n from absl.testing import parameterized\n \n-from keras import backend\n-from keras import layers\n-from keras import metrics\n-from keras import models\n-from keras import saving\n-from keras import testing\n-from keras import tree\n-from keras import utils\n-from keras.export import export_lib\n-from keras.saving import object_registration\n-from keras.utils.jax_layer import FlaxLayer\n-from keras.utils.jax_layer import JaxLayer\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import metrics\n+from keras.src import models\n+from keras.src import saving\n+from keras.src import testing\n+from keras.src import tree\n+from keras.src import utils\n+from keras.src.export import export_lib\n+from keras.src.saving import object_registration\n+from keras.src.utils.jax_layer import FlaxLayer\n+from keras.src.utils.jax_layer import JaxLayer\n \n try:\n     import flax\n\n@@ -1,4 +1,4 @@\n-from keras import backend\n+from keras.src import backend\n \n \n def is_in_jax_tracing_scope(x=None):\n\n@@ -3,9 +3,9 @@\n import os\n import sys\n \n-from keras import tree\n-from keras.api_export import keras_export\n-from keras.utils import io_utils\n+from keras.src import tree\n+from keras.src.api_export import keras_export\n+from keras.src.utils import io_utils\n \n try:\n     # pydot-ng is a fork of pydot that is better maintained.\n@@ -202,7 +202,7 @@ def model_to_dot(\n         a `pydot.Cluster` instance representing nested model if\n         `subgraph=True`.\n     \"\"\"\n-    from keras.ops.function import make_node_key\n+    from keras.src.ops.function import make_node_key\n \n     if not model.built:\n         raise ValueError(\n@@ -211,10 +211,10 @@ def model_to_dot(\n             \"the model on a batch of data.\"\n         )\n \n-    from keras.models import functional\n-    from keras.models import sequential\n+    from keras.src.models import functional\n+    from keras.src.models import sequential\n \n-    # from keras.layers import Wrapper\n+    # from keras.src.layers import Wrapper\n \n     if not check_pydot():\n         raise ImportError(\n\n\n@@ -1,8 +1,8 @@\n import collections\n import re\n \n-from keras.api_export import keras_export\n-from keras.backend.common import global_state\n+from keras.src.api_export import keras_export\n+from keras.src.backend.common import global_state\n \n \n def auto_name(prefix):\n\n@@ -1,5 +1,5 @@\n-from keras.testing import test_case\n-from keras.utils import naming\n+from keras.src.testing import test_case\n+from keras.src.utils import naming\n \n \n class NamingUtilsTest(test_case.TestCase):\n\n@@ -1,7 +1,7 @@\n import numpy as np\n \n-from keras import backend\n-from keras.api_export import keras_export\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n \n \n @keras_export(\"keras.utils.normalize\")\n@@ -19,7 +19,7 @@ def normalize(x, axis=-1, order=2):\n     Returns:\n         A normalized copy of the array.\n     \"\"\"\n-    from keras import ops\n+    from keras.src import ops\n \n     if isinstance(x, np.ndarray):\n         # NumPy input\n\n@@ -1,9 +1,9 @@\n import numpy as np\n from absl.testing import parameterized\n \n-from keras import backend\n-from keras import testing\n-from keras.utils import numerical_utils\n+from keras.src import backend\n+from keras.src import testing\n+from keras.src.utils import numerical_utils\n \n NUM_CLASSES = 5\n \n\n@@ -3,9 +3,9 @@ import os\n import sys\n import time\n \n-from keras import backend\n-from keras.api_export import keras_export\n-from keras.utils import io_utils\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.utils import io_utils\n \n \n @keras_export(\"keras.utils.Progbar\")\n\n\n@@ -1,8 +1,8 @@\n import base64\n import marshal\n \n-from keras import testing\n-from keras.utils import python_utils\n+from keras.src import testing\n+from keras.src.utils import python_utils\n \n \n class PythonUtilsTest(testing.TestCase):\n\n@@ -2,9 +2,9 @@ import random\n \n import numpy as np\n \n-from keras import backend\n-from keras.api_export import keras_export\n-from keras.utils.module_utils import tensorflow as tf\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.utils.module_utils import tensorflow as tf\n \n \n @keras_export(\"keras.utils.set_random_seed\")\n\n@@ -3,9 +3,9 @@ import pytest\n import tensorflow as tf\n \n import keras\n-from keras import backend\n-from keras.testing import test_case\n-from keras.utils import rng_utils\n+from keras.src import backend\n+from keras.src.testing import test_case\n+from keras.src.utils import rng_utils\n \n \n class TestRandomSeedSetting(test_case.TestCase):\n\n@@ -1,6 +1,6 @@\n import numpy as np\n \n-from keras.api_export import keras_export\n+from keras.src.api_export import keras_export\n \n \n @keras_export(\n\n@@ -1,5 +1,5 @@\n-from keras import testing\n-from keras.utils import sequence_utils\n+from keras.src import testing\n+from keras.src.utils import sequence_utils\n \n \n class PadSequencesTest(testing.TestCase):\n\n@@ -10,10 +10,10 @@ import rich.markup\n # for below imports\n import rich.table\n \n-from keras import backend\n-from keras import tree\n-from keras.utils import dtype_utils\n-from keras.utils import io_utils\n+from keras.src import backend\n+from keras.src import tree\n+from keras.src.utils import dtype_utils\n+from keras.src.utils import io_utils\n \n \n def count_params(weights):\n@@ -131,8 +131,8 @@ def print_summary(\n             matches `layer_range[1]`. By default (`None`) all\n             layers in the model are included in the summary.\n     \"\"\"\n-    from keras.models import Functional\n-    from keras.models import Sequential\n+    from keras.src.models import Functional\n+    from keras.src.models import Sequential\n \n     if not print_fn and not io_utils.is_interactive_logging_enabled():\n         print_fn = io_utils.print_msg\n\n@@ -2,10 +2,10 @@ import numpy as np\n import pytest\n from absl.testing import parameterized\n \n-from keras import layers\n-from keras import models\n-from keras import testing\n-from keras.utils import summary_utils\n+from keras.src import layers\n+from keras.src import models\n+from keras.src import testing\n+from keras.src.utils import summary_utils\n \n \n class SummaryUtilsTest(testing.TestCase, parameterized.TestCase):\n\n@@ -1,8 +1,8 @@\n import numpy as np\n \n-from keras.api_export import keras_export\n-from keras.utils import dataset_utils\n-from keras.utils.module_utils import tensorflow as tf\n+from keras.src.api_export import keras_export\n+from keras.src.utils import dataset_utils\n+from keras.src.utils.module_utils import tensorflow as tf\n \n \n @keras_export(\n\n@@ -2,8 +2,8 @@ import os\n import random\n import string\n \n-from keras import testing\n-from keras.utils import text_dataset_utils\n+from keras.src import testing\n+from keras.src.utils import text_dataset_utils\n \n \n class TextDatasetFromDirectoryTest(testing.TestCase):\n\n@@ -1,4 +1,4 @@\n-from keras.utils.module_utils import tensorflow as tf\n+from keras.src.utils.module_utils import tensorflow as tf\n \n \n def expand_dims(inputs, axis):\n\n@@ -1,7 +1,7 @@\n import numpy as np\n \n-from keras.api_export import keras_export\n-from keras.utils.module_utils import tensorflow as tf\n+from keras.src.api_export import keras_export\n+from keras.src.utils.module_utils import tensorflow as tf\n \n \n @keras_export(\n\n@@ -1,7 +1,7 @@\n import numpy as np\n \n-from keras import testing\n-from keras.utils import timeseries_dataset_utils\n+from keras.src import testing\n+from keras.src.utils import timeseries_dataset_utils\n \n \n class TimeseriesDatasetTest(testing.TestCase):\n\n@@ -2,10 +2,10 @@ import io\n \n from packaging.version import parse\n \n-from keras.api_export import keras_export\n-from keras.layers import Layer\n-from keras.ops import convert_to_numpy\n-from keras.ops import convert_to_tensor\n+from keras.src.api_export import keras_export\n+from keras.src.layers import Layer\n+from keras.src.ops import convert_to_numpy\n+from keras.src.ops import convert_to_tensor\n \n \n @keras_export(\"keras.layers.TorchModuleWrapper\")\n@@ -33,7 +33,7 @@ class TorchModuleWrapper(Layer):\n     import torch.nn.functional as F\n \n     import keras\n-    from keras.layers import TorchModuleWrapper\n+    from keras.src.layers import TorchModuleWrapper\n \n     class Classifier(keras.Model):\n         def __init__(self, **kwargs):\n@@ -79,7 +79,7 @@ class TorchModuleWrapper(Layer):\n         super().__init__(name=name, **kwargs)\n         import torch.nn as nn\n \n-        from keras.backend.torch.core import get_device\n+        from keras.src.backend.torch.core import get_device\n \n         if (\n             isinstance(module, nn.modules.lazy.LazyModuleMixin)\n@@ -98,7 +98,7 @@ class TorchModuleWrapper(Layer):\n         return self.module.parameters(recurse=recurse)\n \n     def _track_module_parameters(self):\n-        from keras.backend.torch import Variable\n+        from keras.src.backend.torch import Variable\n \n         for param in self.module.parameters():\n             # The Variable will reuse the raw `param`\n\n@@ -5,12 +5,12 @@ import pytest\n import torch\n from absl.testing import parameterized\n \n-from keras import backend\n-from keras import layers\n-from keras import models\n-from keras import saving\n-from keras import testing\n-from keras.utils.torch_utils import TorchModuleWrapper\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import models\n+from keras.src import saving\n+from keras.src import testing\n+from keras.src.utils.torch_utils import TorchModuleWrapper\n \n \n class Classifier(models.Model):\n\n@@ -4,10 +4,10 @@ import traceback\n import types\n from functools import wraps\n \n-from keras import backend\n-from keras import tree\n-from keras.api_export import keras_export\n-from keras.backend.common import global_state\n+from keras.src import backend\n+from keras.src import tree\n+from keras.src.api_export import keras_export\n+from keras.src.backend.common import global_state\n \n _EXCLUDED_PATHS = (\n     os.path.abspath(os.path.join(__file__, \"..\", \"..\")),\n\n@@ -1,9 +1,9 @@\n from functools import wraps\n \n-from keras import tree\n-from keras.backend.common.global_state import get_global_attribute\n-from keras.backend.common.global_state import set_global_attribute\n-from keras.utils import python_utils\n+from keras.src import tree\n+from keras.src.backend.common.global_state import get_global_attribute\n+from keras.src.backend.common.global_state import set_global_attribute\n+from keras.src.utils import python_utils\n \n \n class DotNotTrackScope:\n@@ -234,7 +234,7 @@ class TrackedDict(dict):\n         super().clear()\n \n     def tree_flatten(self):\n-        from keras.utils.module_utils import optree\n+        from keras.src.utils.module_utils import optree\n \n         # For optree\n         keys, values = optree.utils.unzip2(\n@@ -244,7 +244,7 @@ class TrackedDict(dict):\n \n     @classmethod\n     def tree_unflatten(cls, keys, values):\n-        from keras.utils.module_utils import optree\n+        from keras.src.utils.module_utils import optree\n \n         # For optree\n         return cls(optree.utils.safe_zip(keys, values))\n\n@@ -1,8 +1,8 @@\n import collections\n \n-from keras import backend\n-from keras import testing\n-from keras.utils import tracking\n+from keras.src import backend\n+from keras.src import testing\n+from keras.src.utils import tracking\n \n \n class TrackingTest(testing.TestCase):\n\n@@ -1,4 +1,4 @@\n-from keras.api_export import keras_export\n+from keras.src.api_export import keras_export\n \n # Unique source of truth for the version number.\n __version__ = \"3.2.1\"\n\n@@ -1,5 +0,0 @@\n-from keras.testing.test_case import TestCase\n-from keras.testing.test_case import jax_uses_gpu\n-from keras.testing.test_case import tensorflow_uses_gpu\n-from keras.testing.test_case import torch_uses_gpu\n-from keras.testing.test_case import uses_gpu\n\n@@ -1,10 +0,0 @@\n-from keras.tree.tree_api import assert_same_structure\n-from keras.tree.tree_api import flatten\n-from keras.tree.tree_api import is_nested\n-from keras.tree.tree_api import lists_to_tuples\n-from keras.tree.tree_api import map_shape_structure\n-from keras.tree.tree_api import map_structure\n-from keras.tree.tree_api import map_structure_up_to\n-from keras.tree.tree_api import pack_sequence_as\n-from keras.tree.tree_api import register_tree_node_class\n-from keras.tree.tree_api import traverse\n\n@@ -1,24 +0,0 @@\n-from keras.utils.audio_dataset_utils import audio_dataset_from_directory\n-from keras.utils.dataset_utils import split_dataset\n-from keras.utils.file_utils import get_file\n-from keras.utils.image_dataset_utils import image_dataset_from_directory\n-from keras.utils.image_utils import array_to_img\n-from keras.utils.image_utils import img_to_array\n-from keras.utils.image_utils import load_img\n-from keras.utils.image_utils import save_img\n-from keras.utils.io_utils import disable_interactive_logging\n-from keras.utils.io_utils import enable_interactive_logging\n-from keras.utils.io_utils import is_interactive_logging_enabled\n-from keras.utils.model_visualization import model_to_dot\n-from keras.utils.model_visualization import plot_model\n-from keras.utils.numerical_utils import normalize\n-from keras.utils.numerical_utils import to_categorical\n-from keras.utils.progbar import Progbar\n-from keras.utils.python_utils import default\n-from keras.utils.python_utils import is_default\n-from keras.utils.python_utils import removeprefix\n-from keras.utils.python_utils import removesuffix\n-from keras.utils.rng_utils import set_random_seed\n-from keras.utils.sequence_utils import pad_sequences\n-from keras.utils.text_dataset_utils import text_dataset_from_directory\n-from keras.utils.timeseries_dataset_utils import timeseries_dataset_from_array\n\n@@ -20,10 +20,9 @@ import datetime\n import glob\n import os\n import pathlib\n+import re\n import shutil\n \n-import namex\n-\n # Needed because importing torch after TF causes the runtime to crash\n import torch  # noqa: F401\n \n@@ -33,112 +32,6 @@ dist_directory = \"dist\"\n to_copy = [\"setup.py\", \"README.md\"]\n \n \n-def ignore_files(_, filenames):\n-    return [f for f in filenames if f.endswith(\"_test.py\")]\n-\n-\n-def copy_source_to_build_directory(root_path):\n-    # Copy sources (`keras/` directory and setup files) to build\n-    # directory\n-    os.chdir(root_path)\n-    os.mkdir(build_directory)\n-    shutil.copytree(\n-        package, os.path.join(build_directory, package), ignore=ignore_files\n-    )\n-    for fname in to_copy:\n-        shutil.copy(fname, os.path.join(f\"{build_directory}\", fname))\n-    os.chdir(build_directory)\n-\n-\n-def run_namex_conversion():\n-    # Restructure the codebase so that source files live in `keras/src`\n-    namex.convert_codebase(package, code_directory=\"src\")\n-\n-    # Generate API __init__.py files in `keras/`\n-    namex.generate_api_files(package, code_directory=\"src\", verbose=True)\n-\n-\n-def create_legacy_directory():\n-    # Make keras/_tf_keras/ by copying keras/\n-    tf_keras_dirpath_parent = os.path.join(package, \"_tf_keras\")\n-    tf_keras_dirpath = os.path.join(tf_keras_dirpath_parent, \"keras\")\n-    os.makedirs(tf_keras_dirpath)\n-    with open(os.path.join(tf_keras_dirpath_parent, \"__init__.py\"), \"w\") as f:\n-        f.write(\"from keras._tf_keras import keras\\n\")\n-    with open(os.path.join(package, \"__init__.py\")) as f:\n-        init_file = f.read()\n-        init_file = init_file.replace(\n-            \"from keras import _legacy\",\n-            \"from keras import _tf_keras\",\n-        )\n-    with open(os.path.join(package, \"__init__.py\"), \"w\") as f:\n-        f.write(init_file)\n-    with open(os.path.join(tf_keras_dirpath, \"__init__.py\"), \"w\") as f:\n-        f.write(init_file)\n-    for dirname in os.listdir(package):\n-        dirpath = os.path.join(package, dirname)\n-        if os.path.isdir(dirpath) and dirname not in (\n-            \"_legacy\",\n-            \"_tf_keras\",\n-            \"src\",\n-        ):\n-            shutil.copytree(\n-                dirpath,\n-                os.path.join(tf_keras_dirpath, dirname),\n-                ignore=ignore_files,\n-            )\n-\n-    # Copy keras/_legacy/ file contents to keras/_tf_keras/keras\n-    legacy_submodules = [\n-        path[:-3]\n-        for path in os.listdir(os.path.join(package, \"src\", \"legacy\"))\n-        if path.endswith(\".py\")\n-    ]\n-    legacy_submodules += [\n-        path\n-        for path in os.listdir(os.path.join(package, \"src\", \"legacy\"))\n-        if os.path.isdir(os.path.join(package, \"src\", \"legacy\", path))\n-    ]\n-\n-    for root, _, fnames in os.walk(os.path.join(package, \"_legacy\")):\n-        for fname in fnames:\n-            if fname.endswith(\".py\"):\n-                legacy_fpath = os.path.join(root, fname)\n-                tf_keras_root = root.replace(\"/_legacy\", \"/_tf_keras/keras\")\n-                core_api_fpath = os.path.join(\n-                    root.replace(\"/_legacy\", \"\"), fname\n-                )\n-                if not os.path.exists(tf_keras_root):\n-                    os.makedirs(tf_keras_root)\n-                tf_keras_fpath = os.path.join(tf_keras_root, fname)\n-                with open(legacy_fpath) as f:\n-                    legacy_contents = f.read()\n-                    legacy_contents = legacy_contents.replace(\n-                        \"keras._legacy\", \"keras._tf_keras.keras\"\n-                    )\n-                if os.path.exists(core_api_fpath):\n-                    with open(core_api_fpath) as f:\n-                        core_api_contents = f.read()\n-                    core_api_contents = core_api_contents.replace(\n-                        \"from keras import _tf_keras\\n\", \"\"\n-                    )\n-                    for legacy_submodule in legacy_submodules:\n-                        core_api_contents = core_api_contents.replace(\n-                            f\"from keras import {legacy_submodule}\\n\",\n-                            \"\",\n-                        )\n-                        core_api_contents = core_api_contents.replace(\n-                            f\"keras.{legacy_submodule}\",\n-                            f\"keras._tf_keras.keras.{legacy_submodule}\",\n-                        )\n-                    legacy_contents = core_api_contents + \"\\n\" + legacy_contents\n-                with open(tf_keras_fpath, \"w\") as f:\n-                    f.write(legacy_contents)\n-\n-    # Delete keras/_legacy/\n-    shutil.rmtree(os.path.join(package, \"_legacy\"))\n-\n-\n def export_version_string(version, is_nightly=False, rc_index=None):\n     \"\"\"Export Version and Package Name.\"\"\"\n     if is_nightly:\n@@ -156,10 +49,15 @@ def export_version_string(version, is_nightly=False, rc_index=None):\n         version += \"rc\" + str(rc_index)\n \n     # Make sure to export the __version__ string\n-    with open(os.path.join(package, \"__init__.py\")) as f:\n+    with open(os.path.join(package, \"src\", \"version.py\")) as f:\n         init_contents = f.read()\n-    with open(os.path.join(package, \"__init__.py\"), \"w\") as f:\n-        f.write(init_contents + \"\\n\\n\" + f'__version__ = \"{version}\"\\n')\n+    with open(os.path.join(package, \"src\", \"version.py\"), \"w\") as f:\n+        init_contents = re.sub(\n+            \"\\n__version__ = .*\\n\",\n+            f'\\n__version__ = \"{version}\"\\n',\n+            init_contents,\n+        )\n+        f.write(init_contents)\n \n \n def build_and_save_output(root_path, __version__):\n@@ -188,20 +86,10 @@ def build_and_save_output(root_path, __version__):\n \n \n def build(root_path, is_nightly=False, rc_index=None):\n-    if os.path.exists(build_directory):\n-        raise ValueError(f\"Directory already exists: {build_directory}\")\n-\n-    try:\n-        copy_source_to_build_directory(root_path)\n-        run_namex_conversion()\n-        create_legacy_directory()\n     from keras.src.version import __version__  # noqa: E402\n \n     export_version_string(__version__, is_nightly, rc_index)\n     return build_and_save_output(root_path, __version__)\n-    finally:\n-        # Clean up: remove the build directory (no longer needed)\n-        shutil.rmtree(build_directory)\n \n \n def install_whl(whl_fpath):\n\n@@ -23,10 +23,7 @@ def get_version(rel_path):\n \n HERE = pathlib.Path(__file__).parent\n README = (HERE / \"README.md\").read_text()\n-if os.path.exists(\"keras/version.py\"):\n-    VERSION = get_version(\"keras/version.py\")\n-else:\n-    VERSION = get_version(\"keras/__init__.py\")\n+VERSION = get_version(\"keras/src/version.py\")\n \n setup(\n     name=\"keras\",\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
