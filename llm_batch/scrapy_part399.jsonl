{"custom_id": "scrapy#8c34e6d9a4994abda0059f76dbbdb64c2e8a9751", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 13 | Churn Cumulative: 613 | Contributors (this commit): 11 | Commits (past 90d): 3 | Contributors (cumulative): 17 | DMM Complexity: 0.0\n\nDIFF:\n@@ -36,6 +36,7 @@ curl_parser = CurlParser()\n curl_parser.add_argument(\"url\")\n curl_parser.add_argument(\"-H\", \"--header\", dest=\"headers\", action=\"append\")\n curl_parser.add_argument(\"-X\", \"--request\", dest=\"method\")\n+curl_parser.add_argument(\"-b\", \"--cookie\", dest=\"cookies\", action=\"append\")\n curl_parser.add_argument(\"-d\", \"--data\", \"--data-raw\", dest=\"data\", action=DataAction)\n curl_parser.add_argument(\"-u\", \"--user\", dest=\"auth\")\n \n@@ -68,6 +69,14 @@ def _parse_headers_and_cookies(\n         else:\n             headers.append((name, val))\n \n+    for cookie_param in parsed_args.cookies or ():\n+        # curl can treat this parameter as either \"key=value; key2=value2\" pairs, or a filename.\n+        # Scrapy will only support key-value pairs.\n+        if \"=\" not in cookie_param:\n+            continue\n+        for name, morsel in SimpleCookie(cookie_param).items():\n+            cookies[name] = morsel.value\n+\n     if parsed_args.auth:\n         user, password = parsed_args.auth.split(\":\", 1)\n         headers.append((\"Authorization\", basic_auth_header(user, password)))\n\n@@ -49,8 +49,8 @@ class CurlToRequestKwargsTest(unittest.TestCase):\n             \"ml,application/xhtml+xml,application/xml;q=0.9,image/webp,image/a\"\n             \"png,*/*;q=0.8' -H 'Referer: http://httpbin.org/' -H 'Cookie: _gau\"\n             \"ges_unique_year=1; _gauges_unique=1; _gauges_unique_month=1; _gau\"\n-            \"ges_unique_hour=1; _gauges_unique_day=1' -H 'Connection: keep-ali\"\n-            \"ve' --compressed\"\n+            \"ges_unique_hour=1' -H 'Connection: keep-alive' --compressed -b '_\"\n+            \"gauges_unique_day=1'\"\n         )\n         expected_result = {\n             \"method\": \"GET\",\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#c200458f24a2e55dece5df5c22f39a0d1b4ff341", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 1413 | Contributors (this commit): 15 | Commits (past 90d): 4 | Contributors (cumulative): 15 | DMM Complexity: None\n\nDIFF:\n@@ -227,7 +227,7 @@ class SpiderMiddlewareManager(MiddlewareManager):\n                         f\"Async iterable passed to {global_object_name(method)} was\"\n                         f\" downgraded to a non-async one. This is deprecated and will\"\n                         f\" stop working in a future version of Scrapy. Please see\"\n-                        f\" https://docs.scrapy.org/en/latest/topics/coroutines.html#mixing-synchronous-and-asynchronous-spider-middlewares\"\n+                        f\" https://docs.scrapy.org/en/latest/topics/coroutines.html#for-middleware-users\"\n                         f\" for more information.\"\n                     )\n                     assert isinstance(result, AsyncIterable)\n@@ -343,7 +343,7 @@ class SpiderMiddlewareManager(MiddlewareManager):\n                     f\" asynchronous spider output, this is deprecated and will stop\"\n                     f\" working in a future version of Scrapy. The middleware should\"\n                     f\" be updated to support it. Please see\"\n-                    f\" https://docs.scrapy.org/en/latest/topics/coroutines.html#mixing-synchronous-and-asynchronous-spider-middlewares\"\n+                    f\" https://docs.scrapy.org/en/latest/topics/coroutines.html#for-middleware-users\"\n                     f\" for more information.\"\n                 )\n             return normal_method\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#391af6afcca232aed82eda516b035dbbd39cdcb1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 107 | Lines Deleted: 7 | Files Changed: 2 | Hunks: 14 | Methods Changed: 9 | Complexity Δ (Sum/Max): 7/5 | Churn Δ: 114 | Churn Cumulative: 1708 | Contributors (this commit): 23 | Commits (past 90d): 3 | Contributors (cumulative): 36 | DMM Complexity: 1.0\n\nDIFF:\n@@ -111,6 +111,8 @@ class HttpCompressionMiddleware:\n                         f\"({len(decoded_body)} B) is larger than the \"\n                         f\"download warning size ({warn_size} B).\"\n                     )\n+                if content_encoding:\n+                    self._warn_unknown_encoding(response, content_encoding)\n                 response.headers[\"Content-Encoding\"] = content_encoding\n                 if self.stats:\n                     self.stats.inc_value(\n@@ -143,9 +145,11 @@ class HttpCompressionMiddleware:\n             body = self._decode(body, encoding, max_size)\n         return body, to_keep\n \n+    @staticmethod\n     def _split_encodings(\n-        self, content_encoding: list[bytes]\n+        content_encoding: list[bytes],\n     ) -> tuple[list[bytes], list[bytes]]:\n+        supported_encodings = {*ACCEPTED_ENCODINGS, b\"x-gzip\"}\n         to_keep: list[bytes] = [\n             encoding.strip().lower()\n             for encoding in chain.from_iterable(\n@@ -155,19 +159,35 @@ class HttpCompressionMiddleware:\n         to_decode: list[bytes] = []\n         while to_keep:\n             encoding = to_keep.pop()\n-            if encoding not in ACCEPTED_ENCODINGS:\n+            if encoding not in supported_encodings:\n                 to_keep.append(encoding)\n                 return to_decode, to_keep\n             to_decode.append(encoding)\n         return to_decode, to_keep\n \n-    def _decode(self, body: bytes, encoding: bytes, max_size: int) -> bytes:\n+    @staticmethod\n+    def _decode(body: bytes, encoding: bytes, max_size: int) -> bytes:\n         if encoding in {b\"gzip\", b\"x-gzip\"}:\n             return gunzip(body, max_size=max_size)\n         if encoding == b\"deflate\":\n             return _inflate(body, max_size=max_size)\n-        if encoding == b\"br\" and b\"br\" in ACCEPTED_ENCODINGS:\n+        if encoding == b\"br\":\n             return _unbrotli(body, max_size=max_size)\n-        if encoding == b\"zstd\" and b\"zstd\" in ACCEPTED_ENCODINGS:\n+        if encoding == b\"zstd\":\n             return _unzstd(body, max_size=max_size)\n-        return body\n+        # shouldn't be reached\n+        return body  # pragma: no cover\n+\n+    def _warn_unknown_encoding(\n+        self, response: Response, encodings: list[bytes]\n+    ) -> None:\n+        encodings_str = b\",\".join(encodings).decode()\n+        msg = (\n+            f\"{self.__class__.__name__} cannot decode the response for {response.url} \"\n+            f\"from unsupported encoding(s) '{encodings_str}'.\"\n+        )\n+        if b\"br\" in encodings:\n+            msg += \" You need to install brotli or brotlicffi to decode 'br'.\"\n+        if b\"zstd\" in encodings:\n+            msg += \" You need to install zstandard to decode 'zstd'.\"\n+        logger.warning(msg)\n\n@@ -23,7 +23,7 @@ SAMPLEDIR = Path(tests_datadir, \"compressed\")\n \n FORMAT = {\n     \"gzip\": (\"html-gzip.bin\", \"gzip\"),\n-    \"x-gzip\": (\"html-gzip.bin\", \"gzip\"),\n+    \"x-gzip\": (\"html-gzip.bin\", \"x-gzip\"),\n     \"rawdeflate\": (\"html-rawdeflate.bin\", \"deflate\"),\n     \"zlibdeflate\": (\"html-zlibdeflate.bin\", \"deflate\"),\n     \"gzip-deflate\": (\"html-gzip-deflate.bin\", \"gzip, deflate\"),\n@@ -145,6 +145,41 @@ class HttpCompressionTest(TestCase):\n         self.assertStatsEqual(\"httpcompression/response_count\", 1)\n         self.assertStatsEqual(\"httpcompression/response_bytes\", 74837)\n \n+    def test_process_response_br_unsupported(self):\n+        try:\n+            try:\n+                import brotli  # noqa: F401\n+\n+                raise SkipTest(\"Requires not having brotli support\")\n+            except ImportError:\n+                import brotlicffi  # noqa: F401\n+\n+                raise SkipTest(\"Requires not having brotli support\")\n+        except ImportError:\n+            pass\n+        response = self._getresponse(\"br\")\n+        request = response.request\n+        self.assertEqual(response.headers[\"Content-Encoding\"], b\"br\")\n+        with LogCapture(\n+            \"scrapy.downloadermiddlewares.httpcompression\",\n+            propagate=False,\n+            level=WARNING,\n+        ) as log:\n+            newresponse = self.mw.process_response(request, response, self.spider)\n+        log.check(\n+            (\n+                \"scrapy.downloadermiddlewares.httpcompression\",\n+                \"WARNING\",\n+                (\n+                    \"HttpCompressionMiddleware cannot decode the response for\"\n+                    \" http://scrapytest.org/ from unsupported encoding(s) 'br'.\"\n+                    \" You need to install brotli or brotlicffi to decode 'br'.\"\n+                ),\n+            ),\n+        )\n+        assert newresponse is not response\n+        self.assertEqual(newresponse.headers.getlist(\"Content-Encoding\"), [b\"br\"])\n+\n     def test_process_response_zstd(self):\n         try:\n             import zstandard  # noqa: F401\n@@ -166,6 +201,36 @@ class HttpCompressionTest(TestCase):\n             assert newresponse.body.startswith(b\"<!DOCTYPE\")\n             assert \"Content-Encoding\" not in newresponse.headers\n \n+    def test_process_response_zstd_unsupported(self):\n+        try:\n+            import zstandard  # noqa: F401\n+\n+            raise SkipTest(\"Requires not having zstandard support\")\n+        except ImportError:\n+            pass\n+        response = self._getresponse(\"zstd-static-content-size\")\n+        request = response.request\n+        self.assertEqual(response.headers[\"Content-Encoding\"], b\"zstd\")\n+        with LogCapture(\n+            \"scrapy.downloadermiddlewares.httpcompression\",\n+            propagate=False,\n+            level=WARNING,\n+        ) as log:\n+            newresponse = self.mw.process_response(request, response, self.spider)\n+        log.check(\n+            (\n+                \"scrapy.downloadermiddlewares.httpcompression\",\n+                \"WARNING\",\n+                (\n+                    \"HttpCompressionMiddleware cannot decode the response for\"\n+                    \" http://scrapytest.org/ from unsupported encoding(s) 'zstd'.\"\n+                    \" You need to install zstandard to decode 'zstd'.\"\n+                ),\n+            ),\n+        )\n+        assert newresponse is not response\n+        self.assertEqual(newresponse.headers.getlist(\"Content-Encoding\"), [b\"zstd\"])\n+\n     def test_process_response_rawdeflate(self):\n         response = self._getresponse(\"rawdeflate\")\n         request = response.request\n@@ -221,7 +286,22 @@ class HttpCompressionTest(TestCase):\n         response = self._getresponse(\"gzip-deflate\")\n         response.headers[\"Content-Encoding\"] = [b\"gzip, foo, deflate\"]\n         request = response.request\n+        with LogCapture(\n+            \"scrapy.downloadermiddlewares.httpcompression\",\n+            propagate=False,\n+            level=WARNING,\n+        ) as log:\n             newresponse = self.mw.process_response(request, response, self.spider)\n+        log.check(\n+            (\n+                \"scrapy.downloadermiddlewares.httpcompression\",\n+                \"WARNING\",\n+                (\n+                    \"HttpCompressionMiddleware cannot decode the response for\"\n+                    \" http://scrapytest.org/ from unsupported encoding(s) 'gzip,foo'.\"\n+                ),\n+            ),\n+        )\n         assert newresponse is not response\n         self.assertEqual(\n             newresponse.headers.getlist(\"Content-Encoding\"), [b\"gzip\", b\"foo\"]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#8d92c28a16c78a1ca7531679488fbd979f308661", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 469 | Lines Deleted: 379 | Files Changed: 45 | Hunks: 225 | Methods Changed: 144 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 848 | Churn Cumulative: 49753 | Contributors (this commit): 145 | Commits (past 90d): 138 | Contributors (cumulative): 668 | DMM Complexity: 1.0\n\nDIFF:\n@@ -185,9 +185,8 @@ class CrawlerTestCase(BaseCrawlerTest):\n \n     def test_get_downloader_middleware_not_crawling(self):\n         crawler = get_raw_crawler(settings_dict=BASE_SETTINGS)\n-        self.assertRaises(\n-            RuntimeError, crawler.get_downloader_middleware, DefaultSpider\n-        )\n+        with pytest.raises(RuntimeError):\n+            crawler.get_downloader_middleware(DefaultSpider)\n \n     @inlineCallbacks\n     def test_get_downloader_middleware_no_engine(self):\n@@ -266,7 +265,8 @@ class CrawlerTestCase(BaseCrawlerTest):\n \n     def test_get_extension_not_crawling(self):\n         crawler = get_raw_crawler(settings_dict=BASE_SETTINGS)\n-        self.assertRaises(RuntimeError, crawler.get_extension, DefaultSpider)\n+        with pytest.raises(RuntimeError):\n+            crawler.get_extension(DefaultSpider)\n \n     @inlineCallbacks\n     def test_get_extension_no_engine(self):\n@@ -345,7 +345,8 @@ class CrawlerTestCase(BaseCrawlerTest):\n \n     def test_get_item_pipeline_not_crawling(self):\n         crawler = get_raw_crawler(settings_dict=BASE_SETTINGS)\n-        self.assertRaises(RuntimeError, crawler.get_item_pipeline, DefaultSpider)\n+        with pytest.raises(RuntimeError):\n+            crawler.get_item_pipeline(DefaultSpider)\n \n     @inlineCallbacks\n     def test_get_item_pipeline_no_engine(self):\n@@ -424,7 +425,8 @@ class CrawlerTestCase(BaseCrawlerTest):\n \n     def test_get_spider_middleware_not_crawling(self):\n         crawler = get_raw_crawler(settings_dict=BASE_SETTINGS)\n-        self.assertRaises(RuntimeError, crawler.get_spider_middleware, DefaultSpider)\n+        with pytest.raises(RuntimeError):\n+            crawler.get_spider_middleware(DefaultSpider)\n \n     @inlineCallbacks\n     def test_get_spider_middleware_no_engine(self):\n@@ -537,7 +539,8 @@ class CrawlerRunnerTestCase(BaseCrawlerTest):\n                 \"SPIDER_LOADER_CLASS\": SpiderLoaderWithWrongInterface,\n             }\n         )\n-        self.assertRaises(MultipleInvalid, CrawlerRunner, settings)\n+        with pytest.raises(MultipleInvalid):\n+            CrawlerRunner(settings)\n \n     def test_crawler_runner_accepts_dict(self):\n         runner = CrawlerRunner({\"foo\": \"bar\"})\n@@ -630,13 +633,15 @@ class CrawlerRunnerHasSpider(unittest.TestCase):\n                 }\n             )\n         else:\n-            msg = r\"The installed reactor \\(.*?\\) does not match the requested one \\(.*?\\)\"\n-            with self.assertRaisesRegex(Exception, msg):\n             runner = CrawlerRunner(\n                 settings={\n                     \"TWISTED_REACTOR\": \"twisted.internet.asyncioreactor.AsyncioSelectorReactor\",\n                 }\n             )\n+            with pytest.raises(\n+                Exception,\n+                match=r\"The installed reactor \\(.*?\\) does not match the requested one \\(.*?\\)\",\n+            ):\n                 yield runner.crawl(NoRequestsSpider)\n \n \n\n@@ -248,5 +248,5 @@ class Https2ProxyTestCase(BaseTestClasses.Http11ProxyTestCase):\n \n     @defer.inlineCallbacks\n     def test_download_with_proxy_https_timeout(self):\n-        with self.assertRaises(NotImplementedError):\n+        with pytest.raises(NotImplementedError):\n             yield super().test_download_with_proxy_https_timeout()\n\n@@ -1,4 +1,5 @@\n import asyncio\n+from gzip import BadGzipFile\n from unittest import mock\n \n import pytest\n@@ -106,7 +107,8 @@ class DefaultsTest(ManagerTestCase):\n                 \"Location\": \"http://example.com/login\",\n             },\n         )\n-        self.assertRaises(OSError, self._download, request=req, response=resp)\n+        with pytest.raises(BadGzipFile):\n+            self._download(request=req, response=resp)\n \n \n class ResponseFromProcessRequestTest(ManagerTestCase):\n\n@@ -83,10 +83,9 @@ class CookiesMiddlewareTest(TestCase):\n         self.assertEqual(req2.headers.get(\"Cookie\"), b\"C1=value1\")\n \n     def test_setting_false_cookies_enabled(self):\n-        self.assertRaises(\n-            NotConfigured,\n-            CookiesMiddleware.from_crawler,\n-            get_crawler(settings_dict={\"COOKIES_ENABLED\": False}),\n+        with pytest.raises(NotConfigured):\n+            CookiesMiddleware.from_crawler(\n+                get_crawler(settings_dict={\"COOKIES_ENABLED\": False})\n             )\n \n     def test_setting_default_cookies_enabled(self):\n\n@@ -1,5 +1,6 @@\n import unittest\n \n+import pytest\n from w3lib.http import basic_auth_header\n \n from scrapy.downloadermiddlewares.httpauth import HttpAuthMiddleware\n@@ -29,8 +30,8 @@ class HttpAuthMiddlewareLegacyTest(unittest.TestCase):\n         self.spider = LegacySpider(\"foo\")\n \n     def test_auth(self):\n-        with self.assertRaises(AttributeError):\n         mw = HttpAuthMiddleware()\n+        with pytest.raises(AttributeError):\n             mw.spider_opened(self.spider)\n \n \n\n@@ -5,6 +5,8 @@ import time\n import unittest\n from contextlib import contextmanager\n \n+import pytest\n+\n from scrapy.downloadermiddlewares.httpcache import HttpCacheMiddleware\n from scrapy.exceptions import IgnoreRequest\n from scrapy.http import HtmlResponse, Request, Response\n@@ -192,9 +194,8 @@ class DummyPolicyTest(_BaseTest):\n \n     def test_middleware_ignore_missing(self):\n         with self._middleware(HTTPCACHE_IGNORE_MISSING=True) as mw:\n-            self.assertRaises(\n-                IgnoreRequest, mw.process_request, self.request, self.spider\n-            )\n+            with pytest.raises(IgnoreRequest):\n+                mw.process_request(self.request, self.spider)\n             mw.process_response(self.request, self.response, self.spider)\n             response = mw.process_request(self.request, self.spider)\n             assert isinstance(response, HtmlResponse)\n\n@@ -4,6 +4,7 @@ from logging import WARNING\n from pathlib import Path\n from unittest import SkipTest, TestCase\n \n+import pytest\n from testfixtures import LogCapture\n from w3lib.encoding import resolve_encoding\n \n@@ -87,10 +88,9 @@ class HttpCompressionTest(TestCase):\n         )\n \n     def test_setting_false_compression_enabled(self):\n-        self.assertRaises(\n-            NotConfigured,\n-            HttpCompressionMiddleware.from_crawler,\n-            get_crawler(settings_dict={\"COMPRESSION_ENABLED\": False}),\n+        with pytest.raises(NotConfigured):\n+            HttpCompressionMiddleware.from_crawler(\n+                get_crawler(settings_dict={\"COMPRESSION_ENABLED\": False})\n             )\n \n     def test_setting_default_compression_enabled(self):\n@@ -520,13 +520,8 @@ class HttpCompressionTest(TestCase):\n         mw.open_spider(spider)\n \n         response = self._getresponse(f\"bomb-{compression_id}\")\n-        self.assertRaises(\n-            IgnoreRequest,\n-            mw.process_response,\n-            response.request,\n-            response,\n-            spider,\n-        )\n+        with pytest.raises(IgnoreRequest):\n+            mw.process_response(response.request, response, spider)\n \n     def test_compression_bomb_setting_br(self):\n         try:\n@@ -561,13 +556,8 @@ class HttpCompressionTest(TestCase):\n         mw.open_spider(spider)\n \n         response = self._getresponse(f\"bomb-{compression_id}\")\n-        self.assertRaises(\n-            IgnoreRequest,\n-            mw.process_response,\n-            response.request,\n-            response,\n-            spider,\n-        )\n+        with pytest.raises(IgnoreRequest):\n+            mw.process_response(response.request, response, spider)\n \n     def test_compression_bomb_spider_attr_br(self):\n         try:\n@@ -600,13 +590,8 @@ class HttpCompressionTest(TestCase):\n \n         response = self._getresponse(f\"bomb-{compression_id}\")\n         response.meta[\"download_maxsize\"] = 10_000_000\n-        self.assertRaises(\n-            IgnoreRequest,\n-            mw.process_response,\n-            response.request,\n-            response,\n-            spider,\n-        )\n+        with pytest.raises(IgnoreRequest):\n+            mw.process_response(response.request, response, spider)\n \n     def test_compression_bomb_request_meta_br(self):\n         try:\n\n@@ -72,9 +72,8 @@ class Base:\n             assert isinstance(req, Request)\n             assert \"redirect_times\" in req.meta\n             self.assertEqual(req.meta[\"redirect_times\"], 1)\n-            self.assertRaises(\n-                IgnoreRequest, self.mw.process_response, req, rsp, self.spider\n-            )\n+            with pytest.raises(IgnoreRequest):\n+                self.mw.process_response(req, rsp, self.spider)\n \n         def test_ttl(self):\n             self.mw.max_redirect_times = 100\n@@ -83,9 +82,8 @@ class Base:\n \n             req = self.mw.process_response(req, rsp, self.spider)\n             assert isinstance(req, Request)\n-            self.assertRaises(\n-                IgnoreRequest, self.mw.process_response, req, rsp, self.spider\n-            )\n+            with pytest.raises(IgnoreRequest):\n+                self.mw.process_response(req, rsp, self.spider)\n \n         def test_redirect_urls(self):\n             req1 = Request(\"http://scrapytest.org/first\")\n\n@@ -1,6 +1,7 @@\n import logging\n import unittest\n \n+import pytest\n from testfixtures import LogCapture\n from twisted.internet import defer\n from twisted.internet.error import (\n@@ -407,7 +408,7 @@ class GetRetryRequestTest(unittest.TestCase):\n \n     def test_no_spider(self):\n         request = Request(\"https://example.com\")\n-        with self.assertRaises(TypeError):\n+        with pytest.raises(TypeError):\n             get_retry_request(request)  # pylint: disable=missing-kwoa\n \n     def test_max_retry_times_setting(self):\n\n@@ -1,5 +1,6 @@\n from unittest import mock\n \n+import pytest\n from twisted.internet import error, reactor\n from twisted.internet.defer import Deferred, DeferredList, maybeDeferred\n from twisted.python import failure\n@@ -26,7 +27,8 @@ class RobotsTxtMiddlewareTest(unittest.TestCase):\n     def test_robotstxt_settings(self):\n         self.crawler.settings = Settings()\n         self.crawler.settings.set(\"USER_AGENT\", \"CustomAgent\")\n-        self.assertRaises(NotConfigured, RobotsTxtMiddleware, self.crawler)\n+        with pytest.raises(NotConfigured):\n+            RobotsTxtMiddleware(self.crawler)\n \n     def _get_successful_crawler(self):\n         crawler = self.crawler\n\n@@ -10,6 +10,7 @@ from io import BytesIO\n from typing import Any\n \n import lxml.etree\n+import pytest\n from itemadapter import ItemAdapter\n \n from scrapy.exporters import (\n@@ -147,7 +148,7 @@ class PythonItemExporterTest(BaseItemExporterTest):\n         return PythonItemExporter(**kwargs)\n \n     def test_invalid_option(self):\n-        with self.assertRaisesRegex(TypeError, \"Unexpected options: invalid_option\"):\n+        with pytest.raises(TypeError, match=\"Unexpected options: invalid_option\"):\n             PythonItemExporter(invalid_option=\"something\")\n \n     def test_nested_item(self):\n@@ -388,7 +389,7 @@ class CsvItemExporterTest(BaseItemExporterTest):\n         )\n \n     def test_errors_default(self):\n-        with self.assertRaises(UnicodeEncodeError):\n+        with pytest.raises(UnicodeEncodeError):\n             self.assertExportResult(\n                 item={\"text\": \"W\\u0275\\u200brd\"},\n                 expected=None,\n@@ -549,7 +550,8 @@ class JsonLinesItemExporterTest(BaseItemExporterTest):\n         self.ie = self._get_exporter(sort_keys=True)\n         self.test_export_item()\n         self._check_output()\n-        self.assertRaises(TypeError, self._get_exporter, foo_unknown_keyword_bar=True)\n+        with pytest.raises(TypeError):\n+            self._get_exporter(foo_unknown_keyword_bar=True)\n \n     def test_nonstring_types_item(self):\n         item = self._get_nonstring_types_item()\n@@ -602,7 +604,8 @@ class JsonItemExporterTest(JsonLinesItemExporterTest):\n         i3 = MyItem(name=\"Jesus\", age=\"44\")\n         self.ie.start_exporting()\n         self.ie.export_item(i1)\n-        self.assertRaises(TypeError, self.ie.export_item, i2)\n+        with pytest.raises(TypeError):\n+            self.ie.export_item(i2)\n         self.ie.export_item(i3)\n         self.ie.finish_exporting()\n         exported = json.loads(to_unicode(self.output.getvalue()))\n@@ -657,7 +660,8 @@ class JsonItemExporterToBytesTest(BaseItemExporterTest):\n         i3 = MyItem(name=\"Jesus\", age=\"44\")\n         self.ie.start_exporting()\n         self.ie.export_item(i1)\n-        self.assertRaises(UnicodeEncodeError, self.ie.export_item, i2)\n+        with pytest.raises(UnicodeEncodeError):\n+            self.ie.export_item(i2)\n         self.ie.export_item(i3)\n         self.ie.finish_exporting()\n         exported = json.loads(to_unicode(self.output.getvalue(), encoding=\"latin\"))\n\n@@ -233,7 +233,8 @@ class BlockingFeedStorageTest(unittest.TestCase):\n         invalid_path = tests_path / \"invalid_path\"\n         spider = self.get_test_spider({\"FEED_TEMPDIR\": str(invalid_path)})\n \n-        self.assertRaises(OSError, b.open, spider=spider)\n+        with pytest.raises(OSError, match=\"Not a Directory:\"):\n+            b.open(spider=spider)\n \n \n @pytest.mark.requires_boto3\n@@ -2437,7 +2438,8 @@ class BatchDeliveriesTest(FeedExportTestBase):\n             \"FEED_EXPORT_BATCH_ITEM_COUNT\": 1,\n         }\n         crawler = get_crawler(settings_dict=settings)\n-        self.assertRaises(NotConfigured, FeedExporter, crawler)\n+        with pytest.raises(NotConfigured):\n+            FeedExporter(crawler)\n \n     @defer.inlineCallbacks\n     def test_export_no_items_not_store_empty(self):\n@@ -2758,7 +2760,7 @@ class FeedExportInitTest(unittest.TestCase):\n             },\n         }\n         crawler = get_crawler(settings_dict=settings)\n-        with self.assertRaises(NotConfigured):\n+        with pytest.raises(NotConfigured):\n             FeedExporter.from_crawler(crawler)\n \n     def test_unsupported_format(self):\n@@ -2770,7 +2772,7 @@ class FeedExportInitTest(unittest.TestCase):\n             },\n         }\n         crawler = get_crawler(settings_dict=settings)\n-        with self.assertRaises(NotConfigured):\n+        with pytest.raises(NotConfigured):\n             FeedExporter.from_crawler(crawler)\n \n     def test_absolute_pathlib_as_uri(self):\n@@ -2863,7 +2865,7 @@ class URIParamsTest:\n \n         with warnings.catch_warnings():\n             warnings.simplefilter(\"error\", ScrapyDeprecationWarning)\n-            with self.assertRaises(KeyError):\n+            with pytest.raises(KeyError):\n                 feed_exporter.open_spider(spider)\n \n     def test_params_as_is(self):\n\n@@ -12,6 +12,7 @@ from typing import TYPE_CHECKING\n from unittest import mock, skipIf\n from urllib.parse import urlencode\n \n+import pytest\n from twisted.internet import reactor\n from twisted.internet.defer import (\n     CancelledError,\n@@ -406,7 +407,7 @@ class Https2ClientProtocolTestCase(TestCase):\n             \"scrapy.core.http2.protocol.PROTOCOL_NAME\", return_value=b\"not-h2\"\n         ):\n             request = Request(url=self.get_url(\"/status?n=200\"))\n-            with self.assertRaises(ResponseFailed):\n+            with pytest.raises(ResponseFailed):\n                 yield self.make_request(request)\n \n     def test_cancel_request(self):\n@@ -560,7 +561,7 @@ class Https2ClientProtocolTestCase(TestCase):\n         return DeferredList(d_list, consumeErrors=True, fireOnOneErrback=True)\n \n     def test_invalid_request_type(self):\n-        with self.assertRaises(TypeError):\n+        with pytest.raises(TypeError):\n             self.make_request(\"https://InvalidDataTypePassed.com\")\n \n     def test_query_parameters(self):\n\n@@ -1,6 +1,8 @@\n import copy\n import unittest\n \n+import pytest\n+\n from scrapy.http import Headers\n \n \n@@ -13,7 +15,8 @@ class HeadersTest(unittest.TestCase):\n         assert h[\"Content-Type\"]\n         assert h[\"Content-Length\"]\n \n-        self.assertRaises(KeyError, h.__getitem__, \"Accept\")\n+        with pytest.raises(KeyError):\n+            h[\"Accept\"]\n         self.assertEqual(h.get(\"Accept\"), None)\n         self.assertEqual(h.getlist(\"Accept\"), [])\n \n@@ -152,15 +155,11 @@ class HeadersTest(unittest.TestCase):\n         self.assertEqual(h1.getlist(\"hey\"), [b\"5\"])\n \n     def test_invalid_value(self):\n-        self.assertRaisesRegex(\n-            TypeError, \"Unsupported value type\", Headers, {\"foo\": object()}\n-        )\n-        self.assertRaisesRegex(\n-            TypeError, \"Unsupported value type\", Headers().__setitem__, \"foo\", object()\n-        )\n-        self.assertRaisesRegex(\n-            TypeError, \"Unsupported value type\", Headers().setdefault, \"foo\", object()\n-        )\n-        self.assertRaisesRegex(\n-            TypeError, \"Unsupported value type\", Headers().setlist, \"foo\", [object()]\n-        )\n+        with pytest.raises(TypeError, match=\"Unsupported value type\"):\n+            Headers({\"foo\": object()})\n+        with pytest.raises(TypeError, match=\"Unsupported value type\"):\n+            Headers()[\"foo\"] = object()\n+        with pytest.raises(TypeError, match=\"Unsupported value type\"):\n+            Headers().setdefault(\"foo\", object())\n+        with pytest.raises(TypeError, match=\"Unsupported value type\"):\n+            Headers().setlist(\"foo\", [object()])\n\n@@ -7,6 +7,8 @@ from typing import Any\n from unittest import mock\n from urllib.parse import parse_qs, unquote_to_bytes\n \n+import pytest\n+\n from scrapy.http import (\n     FormRequest,\n     Headers,\n@@ -28,10 +30,12 @@ class RequestTest(unittest.TestCase):\n \n     def test_init(self):\n         # Request requires url in the __init__ method\n-        self.assertRaises(Exception, self.request_class)\n+        with pytest.raises(TypeError):\n+            self.request_class()\n \n         # url argument must be basestring\n-        self.assertRaises(TypeError, self.request_class, 123)\n+        with pytest.raises(TypeError):\n+            self.request_class(123)\n         r = self.request_class(\"http://www.example.com\")\n \n         r = self.request_class(\"http://www.example.com\")\n@@ -64,9 +68,13 @@ class RequestTest(unittest.TestCase):\n         self.request_class(\"data:,Hello%2C%20World!\")\n \n     def test_url_no_scheme(self):\n-        self.assertRaises(ValueError, self.request_class, \"foo\")\n-        self.assertRaises(ValueError, self.request_class, \"/foo/\")\n-        self.assertRaises(ValueError, self.request_class, \"/foo:bar\")\n+        msg = \"Missing scheme in request url:\"\n+        with pytest.raises(ValueError, match=msg):\n+            self.request_class(\"foo\")\n+        with pytest.raises(ValueError, match=msg):\n+            self.request_class(\"/foo/\")\n+        with pytest.raises(ValueError, match=msg):\n+            self.request_class(\"/foo:bar\")\n \n     def test_headers(self):\n         # Different ways of setting headers attribute\n@@ -273,8 +281,10 @@ class RequestTest(unittest.TestCase):\n \n     def test_immutable_attributes(self):\n         r = self.request_class(\"http://example.com\")\n-        self.assertRaises(AttributeError, setattr, r, \"url\", \"http://example2.com\")\n-        self.assertRaises(AttributeError, setattr, r, \"body\", \"xxx\")\n+        with pytest.raises(AttributeError):\n+            r.url = \"http://example2.com\"\n+        with pytest.raises(AttributeError):\n+            r.body = \"xxx\"\n \n     def test_callback_and_errback(self):\n         def a_function():\n@@ -309,11 +319,11 @@ class RequestTest(unittest.TestCase):\n         self.assertIs(r5.errback, NO_CALLBACK)\n \n     def test_callback_and_errback_type(self):\n-        with self.assertRaises(TypeError):\n+        with pytest.raises(TypeError):\n             self.request_class(\"http://example.com\", callback=\"a_function\")\n-        with self.assertRaises(TypeError):\n+        with pytest.raises(TypeError):\n             self.request_class(\"http://example.com\", errback=\"a_function\")\n-        with self.assertRaises(TypeError):\n+        with pytest.raises(TypeError):\n             self.request_class(\n                 url=\"http://example.com\",\n                 callback=\"a_function\",\n@@ -321,7 +331,7 @@ class RequestTest(unittest.TestCase):\n             )\n \n     def test_no_callback(self):\n-        with self.assertRaises(RuntimeError):\n+        with pytest.raises(RuntimeError):\n             NO_CALLBACK()\n \n     def test_from_curl(self):\n@@ -403,12 +413,10 @@ class RequestTest(unittest.TestCase):\n \n         # If `ignore_unknown_options` is set to `False` it raises an error with\n         # the unknown options: --foo and -z\n-        self.assertRaises(\n-            ValueError,\n-            lambda: self.request_class.from_curl(\n+        with pytest.raises(ValueError, match=\"Unrecognized options:\"):\n+            self.request_class.from_curl(\n                 'curl -X PATCH \"http://example.org\" --foo -z',\n                 ignore_unknown_options=False,\n-            ),\n             )\n \n \n@@ -428,7 +436,7 @@ class FormRequestTest(RequestTest):\n         data = ((\"a\", \"one\"), (\"a\", \"two\"), (\"b\", \"2\"))\n         url = self.request_class(\n             \"http://www.example.com/?a=0&b=1&c=3#fragment\", method=\"GET\", formdata=data\n-        ).url.split(\"#\")[0]\n+        ).url.split(\"#\", maxsplit=1)[0]\n         fs = _qs(self.request_class(url, method=\"GET\", formdata=data))\n         self.assertEqual(set(fs[b\"a\"]), {b\"one\", b\"two\"})\n         self.assertEqual(fs[b\"b\"], [b\"2\"])\n@@ -897,12 +905,11 @@ class FormRequestTest(RequestTest):\n             <input type=\"submit\" name=\"clickable2\" value=\"clicked2\">\n             </form>\"\"\"\n         )\n-        self.assertRaises(\n+        with pytest.raises(\n             ValueError,\n-            self.request_class.from_response,\n-            response,\n-            clickdata={\"type\": \"submit\"},\n-        )\n+            match=\"Multiple elements found .* matching the criteria in clickdata\",\n+        ):\n+            self.request_class.from_response(response, clickdata={\"type\": \"submit\"})\n \n     def test_from_response_non_matching_clickdata(self):\n         response = _buildresponse(\n@@ -910,11 +917,11 @@ class FormRequestTest(RequestTest):\n             <input type=\"submit\" name=\"clickable\" value=\"clicked\">\n             </form>\"\"\"\n         )\n-        self.assertRaises(\n-            ValueError,\n-            self.request_class.from_response,\n-            response,\n-            clickdata={\"nonexistent\": \"notme\"},\n+        with pytest.raises(\n+            ValueError, match=\"No clickable element matching clickdata:\"\n+        ):\n+            self.request_class.from_response(\n+                response, clickdata={\"nonexistent\": \"notme\"}\n             )\n \n     def test_from_response_nr_index_clickdata(self):\n@@ -937,13 +944,15 @@ class FormRequestTest(RequestTest):\n             </form>\n             \"\"\"\n         )\n-        self.assertRaises(\n-            ValueError, self.request_class.from_response, response, clickdata={\"nr\": 1}\n-        )\n+        with pytest.raises(\n+            ValueError, match=\"No clickable element matching clickdata:\"\n+        ):\n+            self.request_class.from_response(response, clickdata={\"nr\": 1})\n \n     def test_from_response_errors_noform(self):\n         response = _buildresponse(\"\"\"<html></html>\"\"\")\n-        self.assertRaises(ValueError, self.request_class.from_response, response)\n+        with pytest.raises(ValueError, match=\"No <form> element found in\"):\n+            self.request_class.from_response(response)\n \n     def test_from_response_invalid_html5(self):\n         response = _buildresponse(\n@@ -963,9 +972,8 @@ class FormRequestTest(RequestTest):\n             <input type=\"hidden\" name=\"test2\" value=\"xxx\">\n             </form>\"\"\"\n         )\n-        self.assertRaises(\n-            IndexError, self.request_class.from_response, response, formnumber=1\n-        )\n+        with pytest.raises(IndexError):\n+            self.request_class.from_response(response, formnumber=1)\n \n     def test_from_response_noformname(self):\n         response = _buildresponse(\n@@ -1021,13 +1029,8 @@ class FormRequestTest(RequestTest):\n             <input type=\"hidden\" name=\"two\" value=\"2\">\n             </form>\"\"\"\n         )\n-        self.assertRaises(\n-            IndexError,\n-            self.request_class.from_response,\n-            response,\n-            formname=\"form3\",\n-            formnumber=2,\n-        )\n+        with pytest.raises(IndexError):\n+            self.request_class.from_response(response, formname=\"form3\", formnumber=2)\n \n     def test_from_response_formid_exists(self):\n         response = _buildresponse(\n@@ -1086,13 +1089,8 @@ class FormRequestTest(RequestTest):\n             <input type=\"hidden\" name=\"two\" value=\"2\">\n             </form>\"\"\"\n         )\n-        self.assertRaises(\n-            IndexError,\n-            self.request_class.from_response,\n-            response,\n-            formid=\"form3\",\n-            formnumber=2,\n-        )\n+        with pytest.raises(IndexError):\n+            self.request_class.from_response(response, formid=\"form3\", formnumber=2)\n \n     def test_from_response_select(self):\n         res = _buildresponse(\n@@ -1245,11 +1243,9 @@ class FormRequestTest(RequestTest):\n         fs = _qs(r1)\n         self.assertEqual(fs[b\"three\"], [b\"3\"])\n \n-        self.assertRaises(\n-            ValueError,\n-            self.request_class.from_response,\n-            response,\n-            formxpath=\"//form/input[@name='abc']\",\n+        with pytest.raises(ValueError, match=\"No <form> element found with\"):\n+            self.request_class.from_response(\n+                response, formxpath=\"//form/input[@name='abc']\"\n             )\n \n     def test_from_response_unicode_xpath(self):\n@@ -1261,13 +1257,8 @@ class FormRequestTest(RequestTest):\n         self.assertEqual(fs, {})\n \n         xpath = \"//form[@name='\\u03b1']\"\n-        self.assertRaisesRegex(\n-            ValueError,\n-            re.escape(xpath),\n-            self.request_class.from_response,\n-            response,\n-            formxpath=xpath,\n-        )\n+        with pytest.raises(ValueError, match=re.escape(xpath)):\n+            self.request_class.from_response(response, formxpath=xpath)\n \n     def test_from_response_button_submit(self):\n         response = _buildresponse(\n@@ -1393,12 +1384,8 @@ class FormRequestTest(RequestTest):\n         fs = _qs(r1)\n         self.assertEqual(fs[b\"three\"], [b\"3\"])\n \n-        self.assertRaises(\n-            ValueError,\n-            self.request_class.from_response,\n-            response,\n-            formcss=\"input[name='abc']\",\n-        )\n+        with pytest.raises(ValueError, match=\"No <form> element found with\"):\n+            self.request_class.from_response(response, formcss=\"input[name='abc']\")\n \n     def test_from_response_valid_form_methods(self):\n         form_methods = [\n@@ -1424,13 +1411,11 @@ class FormRequestTest(RequestTest):\n             </form>\n             </body></html>\"\"\"\n         )\n-        with self.assertRaises(ValueError) as context:\n+        with pytest.raises(\n+            ValueError, match=\"formdata should be a dict or iterable of tuples\"\n+        ):\n             FormRequest.from_response(response, formdata=123)\n \n-        self.assertIn(\n-            \"formdata should be a dict or iterable of tuples\", str(context.exception)\n-        )\n-\n     def test_form_response_with_custom_invalid_formdata_value_error(self):\n         \"\"\"Test that a ValueError is raised for fault-inducing iterable formdata input\"\"\"\n         response = _buildresponse(\n@@ -1441,13 +1426,11 @@ class FormRequestTest(RequestTest):\n             </body></html>\"\"\"\n         )\n \n-        with self.assertRaises(ValueError) as context:\n+        with pytest.raises(\n+            ValueError, match=\"formdata should be a dict or iterable of tuples\"\n+        ):\n             FormRequest.from_response(response, formdata=(\"a\",))\n \n-        self.assertIn(\n-            \"formdata should be a dict or iterable of tuples\", str(context.exception)\n-        )\n-\n     def test_get_form_with_xpath_no_form_parent(self):\n         \"\"\"Test that _get_from raised a ValueError when an XPath selects an element\n         not nested within a <form> and no <form> parent is found\"\"\"\n@@ -1462,11 +1445,9 @@ class FormRequestTest(RequestTest):\n             </body></html>\"\"\"\n         )\n \n-        with self.assertRaises(ValueError) as context:\n+        with pytest.raises(ValueError, match=\"No <form> element found with\"):\n             FormRequest.from_response(response, formxpath='//div[@id=\"outside-form\"]/p')\n \n-        self.assertIn(\"No <form> element found with\", str(context.exception))\n-\n \n def _buildresponse(body, **kwargs):\n     kwargs.setdefault(\"body\", body)\n@@ -1507,8 +1488,10 @@ class XmlRpcRequestTest(RequestTest):\n         self._test_request(params=(\"response\",), methodresponse=\"login\")\n         self._test_request(params=(\"pas£\",), encoding=\"utf-8\")\n         self._test_request(params=(None,), allow_none=1)\n-        self.assertRaises(TypeError, self._test_request)\n-        self.assertRaises(TypeError, self._test_request, params=(None,))\n+        with pytest.raises(TypeError):\n+            self._test_request()\n+        with pytest.raises(TypeError):\n+            self._test_request(params=(None,))\n \n     def test_latin1(self):\n         self._test_request(params=(\"pas£\",), encoding=\"latin1\")\n\n@@ -27,14 +27,15 @@ class BaseResponseTest(unittest.TestCase):\n \n     def test_init(self):\n         # Response requires url in the constructor\n-        self.assertRaises(Exception, self.response_class)\n+        with pytest.raises(TypeError):\n+            self.response_class()\n         self.assertTrue(\n             isinstance(self.response_class(\"http://example.com/\"), self.response_class)\n         )\n-        self.assertRaises(TypeError, self.response_class, b\"http://example.com\")\n-        self.assertRaises(\n-            TypeError, self.response_class, url=\"http://example.com\", body={}\n-        )\n+        with pytest.raises(TypeError):\n+            self.response_class(b\"http://example.com\")\n+        with pytest.raises(TypeError):\n+            self.response_class(url=\"http://example.com\", body={})\n         # body can be str or None\n         self.assertTrue(\n             isinstance(\n@@ -77,12 +78,8 @@ class BaseResponseTest(unittest.TestCase):\n         self.assertEqual(r.status, 301)\n         r = self.response_class(\"http://www.example.com\", status=\"301\")\n         self.assertEqual(r.status, 301)\n-        self.assertRaises(\n-            ValueError,\n-            self.response_class,\n-            \"http://example.com\",\n-            status=\"lala200\",\n-        )\n+        with pytest.raises(ValueError, match=r\"invalid literal for int\\(\\)\"):\n+            self.response_class(\"http://example.com\", status=\"lala200\")\n \n     def test_copy(self):\n         \"\"\"Test Response copy\"\"\"\n@@ -122,14 +119,12 @@ class BaseResponseTest(unittest.TestCase):\n \n     def test_unavailable_meta(self):\n         r1 = self.response_class(\"http://www.example.com\", body=b\"Some body\")\n-        with self.assertRaisesRegex(AttributeError, r\"Response\\.meta not available\"):\n+        with pytest.raises(AttributeError, match=r\"Response\\.meta not available\"):\n             r1.meta\n \n     def test_unavailable_cb_kwargs(self):\n         r1 = self.response_class(\"http://www.example.com\", body=b\"Some body\")\n-        with self.assertRaisesRegex(\n-            AttributeError, r\"Response\\.cb_kwargs not available\"\n-        ):\n+        with pytest.raises(AttributeError, match=r\"Response\\.cb_kwargs not available\"):\n             r1.cb_kwargs\n \n     def test_copy_inherited_classes(self):\n@@ -179,8 +174,10 @@ class BaseResponseTest(unittest.TestCase):\n \n     def test_immutable_attributes(self):\n         r = self.response_class(\"http://example.com\")\n-        self.assertRaises(AttributeError, setattr, r, \"url\", \"http://example2.com\")\n-        self.assertRaises(AttributeError, setattr, r, \"body\", \"xxx\")\n+        with pytest.raises(AttributeError):\n+            r.url = \"http://example2.com\"\n+        with pytest.raises(AttributeError):\n+            r.body = \"xxx\"\n \n     def test_urljoin(self):\n         \"\"\"Test urljoin shortcut (only for existence, since behavior equals urljoin)\"\"\"\n@@ -192,10 +189,14 @@ class BaseResponseTest(unittest.TestCase):\n         r = self.response_class(\"http://example.com\", body=b\"hello\")\n         if self.response_class == Response:\n             msg = \"Response content isn't text\"\n-            self.assertRaisesRegex(AttributeError, msg, getattr, r, \"text\")\n-            self.assertRaisesRegex(NotSupported, msg, r.css, \"body\")\n-            self.assertRaisesRegex(NotSupported, msg, r.xpath, \"//body\")\n-            self.assertRaisesRegex(NotSupported, msg, r.jmespath, \"body\")\n+            with pytest.raises(AttributeError, match=msg):\n+                r.text\n+            with pytest.raises(NotSupported, match=msg):\n+                r.css(\"body\")\n+            with pytest.raises(NotSupported, match=msg):\n+                r.xpath(\"//body\")\n+            with pytest.raises(NotSupported, match=msg):\n+                r.jmespath(\"body\")\n         else:\n             r.text\n             r.css(\"body\")\n@@ -216,7 +217,8 @@ class BaseResponseTest(unittest.TestCase):\n \n     def test_follow_None_url(self):\n         r = self.response_class(\"http://example.com\")\n-        self.assertRaises(ValueError, r.follow, None)\n+        with pytest.raises(ValueError, match=\"url can't be None\"):\n+            r.follow(None)\n \n     @pytest.mark.xfail(\n         parse_version(w3lib_version) < parse_version(\"2.1.1\"),\n@@ -279,18 +281,20 @@ class BaseResponseTest(unittest.TestCase):\n     def test_follow_all_invalid(self):\n         r = self.response_class(\"http://example.com\")\n         if self.response_class == Response:\n-            with self.assertRaises(TypeError):\n+            with pytest.raises(TypeError):\n                 list(r.follow_all(urls=None))\n-            with self.assertRaises(TypeError):\n+            with pytest.raises(TypeError):\n                 list(r.follow_all(urls=12345))\n-            with self.assertRaises(ValueError):\n+            with pytest.raises(ValueError, match=\"url can't be None\"):\n                 list(r.follow_all(urls=[None]))\n         else:\n-            with self.assertRaises(ValueError):\n+            with pytest.raises(\n+                ValueError, match=\"Please supply exactly one of the following arguments\"\n+            ):\n                 list(r.follow_all(urls=None))\n-            with self.assertRaises(TypeError):\n+            with pytest.raises(TypeError):\n                 list(r.follow_all(urls=12345))\n-            with self.assertRaises(ValueError):\n+            with pytest.raises(ValueError, match=\"url can't be None\"):\n                 list(r.follow_all(urls=[None]))\n \n     def test_follow_all_whitespace(self):\n@@ -399,12 +403,8 @@ class TextResponseTest(BaseResponseTest):\n             \"\\u043a\\u0438\\u0440\\u0438\\u043b\\u043b\\u0438\\u0447\\u0435\\u0441\\u043a\\u0438\\u0439 \"\n             \"\\u0442\\u0435\\u043a\\u0441\\u0442\"\n         )\n-        self.assertRaises(\n-            TypeError,\n-            self.response_class,\n-            \"http://www.example.com\",\n-            body=\"unicode body\",\n-        )\n+        with pytest.raises(TypeError):\n+            self.response_class(\"http://www.example.com\", body=\"unicode body\")\n \n         original_string = unicode_string.encode(\"cp1251\")\n         r1 = self.response_class(\n@@ -483,12 +483,8 @@ class TextResponseTest(BaseResponseTest):\n         self._assert_response_values(r9, \"cp1252\", \"€\")\n \n         # TextResponse (and subclasses) must be passed a encoding when instantiating with unicode bodies\n-        self.assertRaises(\n-            TypeError,\n-            self.response_class,\n-            \"http://www.example.com\",\n-            body=\"\\xa3\",\n-        )\n+        with pytest.raises(TypeError):\n+            self.response_class(\"http://www.example.com\", body=\"\\xa3\")\n \n     def test_declared_encoding_invalid(self):\n         \"\"\"Check that unknown declared encodings are ignored\"\"\"\n@@ -679,20 +675,20 @@ class TextResponseTest(BaseResponseTest):\n                 self._assert_followed_url(sel, url, response=resp)\n \n         # non-a elements are not supported\n-        self.assertRaises(ValueError, resp.follow, resp.css(\"div\")[0])\n+        with pytest.raises(\n+            ValueError, match=\"Only <a> and <link> elements are supported\"\n+        ):\n+            resp.follow(resp.css(\"div\")[0])\n \n     def test_follow_selector_list(self):\n         resp = self._links_response()\n-        self.assertRaisesRegex(ValueError, \"SelectorList\", resp.follow, resp.css(\"a\"))\n+        with pytest.raises(ValueError, match=\"SelectorList\"):\n+            resp.follow(resp.css(\"a\"))\n \n     def test_follow_selector_invalid(self):\n         resp = self._links_response()\n-        self.assertRaisesRegex(\n-            ValueError,\n-            \"Unsupported\",\n-            resp.follow,\n-            resp.xpath(\"count(//div)\")[0],\n-        )\n+        with pytest.raises(ValueError, match=\"Unsupported\"):\n+            resp.follow(resp.xpath(\"count(//div)\")[0])\n \n     def test_follow_selector_attribute(self):\n         resp = self._links_response()\n@@ -704,7 +700,8 @@ class TextResponseTest(BaseResponseTest):\n             url=\"http://example.com\",\n             body=b\"<html><body><a name=123>click me</a></body></html>\",\n         )\n-        self.assertRaisesRegex(ValueError, \"no href\", resp.follow, resp.css(\"a\")[0])\n+        with pytest.raises(ValueError, match=\"no href\"):\n+            resp.follow(resp.css(\"a\")[0])\n \n     def test_follow_whitespace_selector(self):\n         resp = self.response_class(\n@@ -812,7 +809,9 @@ class TextResponseTest(BaseResponseTest):\n \n     def test_follow_all_too_many_arguments(self):\n         response = self._links_response()\n-        with self.assertRaises(ValueError):\n+        with pytest.raises(\n+            ValueError, match=\"Please supply exactly one of the following arguments\"\n+        ):\n             response.follow_all(\n                 css='a[href*=\"example.com\"]',\n                 xpath='//a[contains(@href, \"example.com\")]',\n@@ -825,7 +824,9 @@ class TextResponseTest(BaseResponseTest):\n \n         text_body = b\"\"\"<html><body>text</body></html>\"\"\"\n         text_response = self.response_class(\"http://www.example.com\", body=text_body)\n-        with self.assertRaises(ValueError):\n+        with pytest.raises(\n+            ValueError, match=\"(Expecting value|Unexpected '<'): line 1\"\n+        ):\n             text_response.json()\n \n     def test_cache_json_response(self):\n@@ -1023,10 +1024,8 @@ class CustomResponseTest(TextResponseTest):\n         self.assertEqual(r4.bar, \"bar\")\n         self.assertIsNone(r4.lost)\n \n-        with self.assertRaises(TypeError) as ctx:\n+        with pytest.raises(\n+            TypeError,\n+            match=r\"__init__\\(\\) got an unexpected keyword argument 'unknown'\",\n+        ):\n             r1.replace(unknown=\"unknown\")\n-        self.assertTrue(\n-            str(ctx.exception).endswith(\n-                \"__init__() got an unexpected keyword argument 'unknown'\"\n-            )\n-        )\n\n@@ -2,6 +2,8 @@ import unittest\n from abc import ABCMeta\n from unittest import mock\n \n+import pytest\n+\n from scrapy.item import Field, Item, ItemMeta\n \n \n@@ -22,7 +24,8 @@ class ItemTest(unittest.TestCase):\n             name = Field()\n \n         i = TestItem()\n-        self.assertRaises(KeyError, i.__getitem__, \"name\")\n+        with pytest.raises(KeyError):\n+            i[\"name\"]\n \n         i2 = TestItem(name=\"john doe\")\n         self.assertEqual(i2[\"name\"], \"john doe\")\n@@ -33,15 +36,18 @@ class ItemTest(unittest.TestCase):\n         i4 = TestItem(i3)\n         self.assertEqual(i4[\"name\"], \"john doe\")\n \n-        self.assertRaises(KeyError, TestItem, {\"name\": \"john doe\", \"other\": \"foo\"})\n+        with pytest.raises(KeyError):\n+            TestItem({\"name\": \"john doe\", \"other\": \"foo\"})\n \n     def test_invalid_field(self):\n         class TestItem(Item):\n             pass\n \n         i = TestItem()\n-        self.assertRaises(KeyError, i.__setitem__, \"field\", \"text\")\n-        self.assertRaises(KeyError, i.__getitem__, \"field\")\n+        with pytest.raises(KeyError):\n+            i[\"field\"] = \"text\"\n+        with pytest.raises(KeyError):\n+            i[\"field\"]\n \n     def test_repr(self):\n         class TestItem(Item):\n@@ -72,14 +78,16 @@ class ItemTest(unittest.TestCase):\n             name = Field()\n \n         i = TestItem()\n-        self.assertRaises(AttributeError, getattr, i, \"name\")\n+        with pytest.raises(AttributeError):\n+            i.name\n \n     def test_raise_setattr(self):\n         class TestItem(Item):\n             name = Field()\n \n         i = TestItem()\n-        self.assertRaises(AttributeError, setattr, i, \"name\", \"john\")\n+        with pytest.raises(AttributeError):\n+            i.name = \"john\"\n \n     def test_custom_methods(self):\n         class TestItem(Item):\n@@ -92,7 +100,8 @@ class ItemTest(unittest.TestCase):\n                 self[\"name\"] = name\n \n         i = TestItem()\n-        self.assertRaises(KeyError, i.get_name)\n+        with pytest.raises(KeyError):\n+            i.get_name()\n         i[\"name\"] = \"lala\"\n         self.assertEqual(i.get_name(), \"lala\")\n         i.change_name(\"other\")\n@@ -223,7 +232,8 @@ class ItemTest(unittest.TestCase):\n         class D(B, C):\n             pass\n \n-        self.assertRaises(KeyError, D, not_allowed=\"value\")\n+        with pytest.raises(KeyError):\n+            D(not_allowed=\"value\")\n         self.assertEqual(D(save=\"X\")[\"save\"], \"X\")\n         self.assertEqual(D.fields, {\"save\": {\"default\": \"A\"}, \"load\": {\"default\": \"A\"}})\n \n@@ -231,7 +241,8 @@ class ItemTest(unittest.TestCase):\n         class E(C, B):\n             pass\n \n-        self.assertRaises(KeyError, E, not_allowed=\"value\")\n+        with pytest.raises(KeyError):\n+            E(not_allowed=\"value\")\n         self.assertEqual(E(save=\"X\")[\"save\"], \"X\")\n         self.assertEqual(E.fields, {\"save\": {\"default\": \"A\"}, \"load\": {\"default\": \"A\"}})\n \n\n@@ -1,5 +1,7 @@\n import unittest\n \n+import pytest\n+\n from scrapy.link import Link\n \n \n@@ -53,5 +55,5 @@ class LinkTest(unittest.TestCase):\n         self._assert_same_links(l1, l2)\n \n     def test_bytes_url(self):\n-        with self.assertRaises(TypeError):\n+        with pytest.raises(TypeError):\n             Link(b\"http://www.example.com/\\xc2\\xa3\")\n\n@@ -4,6 +4,7 @@ import dataclasses\n import unittest\n \n import attr\n+import pytest\n from itemadapter import ItemAdapter\n from itemloaders.processors import Compose, Identity, MapCompose, TakeFirst\n \n@@ -69,7 +70,8 @@ def processor_with_args(value, other=None, loader_context=None):\n class BasicItemLoaderTest(unittest.TestCase):\n     def test_add_value_on_unknown_field(self):\n         il = ProcessorItemLoader()\n-        self.assertRaises(KeyError, il.add_value, \"wrong_field\", [\"lala\", \"lolo\"])\n+        with pytest.raises(KeyError):\n+            il.add_value(\"wrong_field\", [\"lala\", \"lolo\"])\n \n     def test_load_item_using_default_loader(self):\n         i = SummaryItem()\n@@ -294,12 +296,18 @@ class SelectortemLoaderTest(unittest.TestCase):\n \n     def test_init_method_errors(self):\n         l = ProcessorItemLoader()\n-        self.assertRaises(RuntimeError, l.add_xpath, \"url\", \"//a/@href\")\n-        self.assertRaises(RuntimeError, l.replace_xpath, \"url\", \"//a/@href\")\n-        self.assertRaises(RuntimeError, l.get_xpath, \"//a/@href\")\n-        self.assertRaises(RuntimeError, l.add_css, \"name\", \"#name::text\")\n-        self.assertRaises(RuntimeError, l.replace_css, \"name\", \"#name::text\")\n-        self.assertRaises(RuntimeError, l.get_css, \"#name::text\")\n+        with pytest.raises(RuntimeError):\n+            l.add_xpath(\"url\", \"//a/@href\")\n+        with pytest.raises(RuntimeError):\n+            l.replace_xpath(\"url\", \"//a/@href\")\n+        with pytest.raises(RuntimeError):\n+            l.get_xpath(\"//a/@href\")\n+        with pytest.raises(RuntimeError):\n+            l.add_css(\"name\", \"#name::text\")\n+        with pytest.raises(RuntimeError):\n+            l.replace_css(\"name\", \"#name::text\")\n+        with pytest.raises(RuntimeError):\n+            l.get_css(\"#name::text\")\n \n     def test_init_method_with_selector(self):\n         sel = Selector(text=\"<html><body><div>marta</div></body></html>\")\n\n@@ -6,6 +6,7 @@ Once we remove the references from scrapy, we can remove these tests.\n import unittest\n from functools import partial\n \n+import pytest\n from itemloaders.processors import (\n     Compose,\n     Identity,\n@@ -435,7 +436,13 @@ class BasicItemLoaderTest(unittest.TestCase):\n             name_in = MapCompose(float)\n \n         il = TestItemLoader()\n-        self.assertRaises(ValueError, il.add_value, \"name\", [\"marta\", \"other\"])\n+        with pytest.raises(\n+            ValueError,\n+            match=\"Error with input processor MapCompose: .* \"\n+            \"error='ValueError: Error in MapCompose .* \"\n+            \"error='ValueError: could not convert\",\n+        ):\n+            il.add_value(\"name\", [\"marta\", \"other\"])\n \n     def test_error_output_processor(self):\n         class TestItem(Item):\n@@ -447,7 +454,12 @@ class BasicItemLoaderTest(unittest.TestCase):\n \n         il = TestItemLoader()\n         il.add_value(\"name\", \"marta\")\n-        with self.assertRaises(ValueError):\n+        with pytest.raises(\n+            ValueError,\n+            match=\"Error with output processor: .* \"\n+            \"error='ValueError: Error in Compose .* \"\n+            \"error='ValueError: could not convert\",\n+        ):\n             il.load_item()\n \n     def test_error_processor_as_argument(self):\n@@ -458,9 +470,13 @@ class BasicItemLoaderTest(unittest.TestCase):\n             default_item_class = TestItem\n \n         il = TestItemLoader()\n-        self.assertRaises(\n-            ValueError, il.add_value, \"name\", [\"marta\", \"other\"], Compose(float)\n-        )\n+        with pytest.raises(\n+            ValueError,\n+            match=r\"Error with processor Compose .* \"\n+            r\"error='ValueError: Error in Compose .* \"\n+            r\"error='TypeError: float\\(\\) argument\",\n+        ):\n+            il.add_value(\"name\", [\"marta\", \"other\"], Compose(float))\n \n \n class InitializationFromDictTest(unittest.TestCase):\n@@ -630,7 +646,8 @@ class ProcessorsTest(unittest.TestCase):\n \n     def test_join(self):\n         proc = Join()\n-        self.assertRaises(TypeError, proc, [None, \"\", \"hello\", \"world\"])\n+        with pytest.raises(TypeError):\n+            proc([None, \"\", \"hello\", \"world\"])\n         self.assertEqual(proc([\"\", \"hello\", \"world\"]), \" hello world\")\n         self.assertEqual(proc([\"hello\", \"world\"]), \"hello world\")\n         self.assertIsInstance(proc([\"hello\", \"world\"]), str)\n@@ -641,9 +658,17 @@ class ProcessorsTest(unittest.TestCase):\n         proc = Compose(str.upper)\n         self.assertEqual(proc(None), None)\n         proc = Compose(str.upper, stop_on_none=False)\n-        self.assertRaises(ValueError, proc, None)\n+        with pytest.raises(\n+            ValueError,\n+            match=\"Error in Compose with .* error='TypeError: (descriptor 'upper'|'str' object expected)\",\n+        ):\n+            proc(None)\n         proc = Compose(str.upper, lambda x: x + 1)\n-        self.assertRaises(ValueError, proc, \"hello\")\n+        with pytest.raises(\n+            ValueError,\n+            match=\"Error in Compose with .* error='TypeError: (can only|unsupported operand)\",\n+        ):\n+            proc(\"hello\")\n \n     def test_mapcompose(self):\n         def filter_world(x):\n@@ -657,9 +682,17 @@ class ProcessorsTest(unittest.TestCase):\n         proc = MapCompose(filter_world, str.upper)\n         self.assertEqual(proc(None), [])\n         proc = MapCompose(filter_world, str.upper)\n-        self.assertRaises(ValueError, proc, [1])\n+        with pytest.raises(\n+            ValueError,\n+            match=\"Error in MapCompose with .* error='TypeError: (descriptor 'upper'|'str' object expected)\",\n+        ):\n+            proc([1])\n         proc = MapCompose(filter_world, lambda x: x + 1)\n-        self.assertRaises(ValueError, proc, \"hello\")\n+        with pytest.raises(\n+            ValueError,\n+            match=\"Error in MapCompose with .* error='TypeError: (can only|unsupported operand)\",\n+        ):\n+            proc(\"hello\")\n \n \n class SelectJmesTestCase(unittest.TestCase):\n\n@@ -1,6 +1,8 @@\n import unittest\n from datetime import datetime\n \n+import pytest\n+\n from scrapy.extensions.logstats import LogStats\n from scrapy.utils.test import get_crawler\n from tests.spiders import SimpleSpider\n@@ -18,8 +20,9 @@ class TestLogStats(unittest.TestCase):\n     def test_stats_calculations(self):\n         logstats = LogStats.from_crawler(self.crawler)\n \n-        with self.assertRaises(AttributeError):\n+        with pytest.raises(AttributeError):\n             logstats.pagesprev\n+        with pytest.raises(AttributeError):\n             logstats.itemsprev\n \n         logstats.spider_opened(self.spider)\n\n@@ -7,6 +7,7 @@ from shutil import rmtree\n from tempfile import mkdtemp\n \n import attr\n+import pytest\n from itemadapter import ItemAdapter\n from twisted.trial import unittest\n \n@@ -146,11 +147,11 @@ class ImagesPipelineTestCase(unittest.TestCase):\n         resp3 = Response(url=\"https://dev.mydeco.com/mydeco.gif\", body=buf3.getvalue())\n         req = Request(url=\"https://dev.mydeco.com/mydeco.gif\")\n \n-        with self.assertRaises(ImageException):\n+        with pytest.raises(ImageException):\n             next(self.pipeline.get_images(response=resp1, request=req, info=object()))\n-        with self.assertRaises(ImageException):\n+        with pytest.raises(ImageException):\n             next(self.pipeline.get_images(response=resp2, request=req, info=object()))\n-        with self.assertRaises(ImageException):\n+        with pytest.raises(ImageException):\n             next(self.pipeline.get_images(response=resp3, request=req, info=object()))\n \n     def test_get_images(self):\n\n@@ -1,6 +1,7 @@\n import tempfile\n import unittest\n \n+import pytest\n import queuelib\n \n from scrapy.http.request import Request\n@@ -40,9 +41,9 @@ class PriorityQueueTest(unittest.TestCase):\n             self.crawler, FifoMemoryQueue, temp_dir\n         )\n         queue.push(Request(\"https://example.org\"))\n-        with self.assertRaises(\n+        with pytest.raises(\n             NotImplementedError,\n-            msg=\"The underlying queue class does not implement 'peek'\",\n+            match=\"The underlying queue class does not implement 'peek'\",\n         ):\n             queue.peek()\n         queue.close()\n@@ -129,9 +130,9 @@ class DownloaderAwarePriorityQueueTest(unittest.TestCase):\n         if hasattr(queuelib.queue.FifoMemoryQueue, \"peek\"):\n             raise unittest.SkipTest(\"queuelib.queue.FifoMemoryQueue.peek is defined\")\n         self.queue.push(Request(\"https://example.org\"))\n-        with self.assertRaises(\n+        with pytest.raises(\n             NotImplementedError,\n-            msg=\"The underlying queue class does not implement 'peek'\",\n+            match=\"The underlying queue class does not implement 'peek'\",\n         ):\n             self.queue.peek()\n \n\n@@ -1,5 +1,7 @@\n import unittest\n \n+import pytest\n+\n from scrapy import Request, Spider\n from scrapy.http import FormRequest, JsonRequest\n from scrapy.utils.request import request_from_dict\n@@ -134,11 +136,15 @@ class RequestSerializationTest(unittest.TestCase):\n \n     def test_unserializable_callback1(self):\n         r = Request(\"http://www.example.com\", callback=lambda x: x)\n-        self.assertRaises(ValueError, r.to_dict, spider=self.spider)\n+        with pytest.raises(\n+            ValueError, match=\"is not an instance method in: <MethodsSpider\"\n+        ):\n+            r.to_dict(spider=self.spider)\n \n     def test_unserializable_callback2(self):\n         r = Request(\"http://www.example.com\", callback=self.spider.parse_item)\n-        self.assertRaises(ValueError, r.to_dict, spider=None)\n+        with pytest.raises(ValueError, match=\"is not an instance method in: None\"):\n+            r.to_dict(spider=None)\n \n     def test_unserializable_callback3(self):\n         \"\"\"Parser method is removed or replaced dynamically.\"\"\"\n@@ -152,14 +158,18 @@ class RequestSerializationTest(unittest.TestCase):\n         spider = MySpider()\n         r = Request(\"http://www.example.com\", callback=spider.parse)\n         spider.parse = None\n-        self.assertRaises(ValueError, r.to_dict, spider=spider)\n+        with pytest.raises(ValueError, match=\"is not an instance method in: <MySpider\"):\n+            r.to_dict(spider=spider)\n \n     def test_callback_not_available(self):\n         \"\"\"Callback method is not available in the spider passed to from_dict\"\"\"\n         spider = SpiderDelegation()\n         r = Request(\"http://www.example.com\", callback=spider.delegated_callback)\n         d = r.to_dict(spider=spider)\n-        self.assertRaises(ValueError, request_from_dict, d, spider=Spider(\"foo\"))\n+        with pytest.raises(\n+            ValueError, match=\"Method 'delegated_callback' not found in: <Spider\"\n+        ):\n+            request_from_dict(d, spider=Spider(\"foo\"))\n \n \n class SpiderMixin:\n\n@@ -5,6 +5,7 @@ import tempfile\n import unittest\n from typing import Any, NamedTuple\n \n+import pytest\n from twisted.internet import defer\n from twisted.trial.unittest import TestCase\n \n@@ -229,7 +230,10 @@ class TestMigration(unittest.TestCase):\n         next_scheduler_handler.create_scheduler()\n \n     def test_migration(self):\n-        with self.assertRaises(ValueError):\n+        with pytest.raises(\n+            ValueError,\n+            match=\"DownloaderAwarePriorityQueue accepts ``slot_startprios`` as a dict\",\n+        ):\n             self._migration(self.tmpdir)\n \n \n@@ -351,5 +355,7 @@ class TestIncompatibility(unittest.TestCase):\n         scheduler.open(spider)\n \n     def test_incompatibility(self):\n-        with self.assertRaises(ValueError):\n+        with pytest.raises(\n+            ValueError, match=\"does not support CONCURRENT_REQUESTS_PER_IP\"\n+        ):\n             self._incompatible()\n\n@@ -3,6 +3,7 @@ from __future__ import annotations\n from unittest import TestCase\n from urllib.parse import urljoin\n \n+import pytest\n from testfixtures import LogCapture\n from twisted.internet import defer\n from twisted.trial.unittest import TestCase as TwistedTestCase\n@@ -75,13 +76,12 @@ class BaseSchedulerTest(TestCase, InterfaceCheckMixin):\n     def test_methods(self):\n         self.assertIsNone(self.scheduler.open(Spider(\"foo\")))\n         self.assertIsNone(self.scheduler.close(\"finished\"))\n-        self.assertRaises(NotImplementedError, self.scheduler.has_pending_requests)\n-        self.assertRaises(\n-            NotImplementedError,\n-            self.scheduler.enqueue_request,\n-            Request(\"https://example.org\"),\n-        )\n-        self.assertRaises(NotImplementedError, self.scheduler.next_request)\n+        with pytest.raises(NotImplementedError):\n+            self.scheduler.has_pending_requests()\n+        with pytest.raises(NotImplementedError):\n+            self.scheduler.enqueue_request(Request(\"https://example.org\"))\n+        with pytest.raises(NotImplementedError):\n+            self.scheduler.next_request()\n \n \n class MinimalSchedulerTest(TestCase, InterfaceCheckMixin):\n@@ -89,15 +89,15 @@ class MinimalSchedulerTest(TestCase, InterfaceCheckMixin):\n         self.scheduler = MinimalScheduler()\n \n     def test_open_close(self):\n-        with self.assertRaises(AttributeError):\n+        with pytest.raises(AttributeError):\n             self.scheduler.open(Spider(\"foo\"))\n-        with self.assertRaises(AttributeError):\n+        with pytest.raises(AttributeError):\n             self.scheduler.close(\"finished\")\n \n     def test_len(self):\n-        with self.assertRaises(AttributeError):\n+        with pytest.raises(AttributeError):\n             self.scheduler.__len__()\n-        with self.assertRaises(TypeError):\n+        with pytest.raises(TypeError):\n             len(self.scheduler)\n \n     def test_enqueue_dequeue(self):\n\n@@ -112,7 +112,7 @@ class SelectorTestCase(unittest.TestCase):\n         )\n \n     def test_selector_bad_args(self):\n-        with self.assertRaisesRegex(ValueError, \"received both response and text\"):\n+        with pytest.raises(ValueError, match=\"received both response and text\"):\n             Selector(TextResponse(url=\"http://example.com\", body=b\"\"), text=\"\")\n \n \n\n@@ -235,9 +235,9 @@ class BaseSettingsTest(unittest.TestCase):\n         self.assertIn(\"key_highprio\", settings)\n         del settings[\"key_highprio\"]\n         self.assertNotIn(\"key_highprio\", settings)\n-        with self.assertRaises(KeyError):\n+        with pytest.raises(KeyError):\n             settings.delete(\"notkey\")\n-        with self.assertRaises(KeyError):\n+        with pytest.raises(KeyError):\n             del settings[\"notkey\"]\n \n     def test_get(self):\n@@ -303,9 +303,19 @@ class BaseSettingsTest(unittest.TestCase):\n         self.assertEqual(settings.getdict(\"TEST_DICT2\"), {\"key1\": \"val1\", \"ke2\": 3})\n         self.assertEqual(settings.getdict(\"TEST_DICT3\"), {})\n         self.assertEqual(settings.getdict(\"TEST_DICT3\", {\"key1\": 5}), {\"key1\": 5})\n-        self.assertRaises(ValueError, settings.getdict, \"TEST_LIST1\")\n-        self.assertRaises(ValueError, settings.getbool, \"TEST_ENABLED_WRONG\")\n-        self.assertRaises(ValueError, settings.getbool, \"TEST_DISABLED_WRONG\")\n+        with pytest.raises(\n+            ValueError,\n+            match=\"dictionary update sequence element #0 has length 3; 2 is required|sequence of pairs expected\",\n+        ):\n+            settings.getdict(\"TEST_LIST1\")\n+        with pytest.raises(\n+            ValueError, match=\"Supported values for boolean settings are\"\n+        ):\n+            settings.getbool(\"TEST_ENABLED_WRONG\")\n+        with pytest.raises(\n+            ValueError, match=\"Supported values for boolean settings are\"\n+        ):\n+            settings.getbool(\"TEST_DISABLED_WRONG\")\n \n     def test_getpriority(self):\n         settings = BaseSettings({\"key\": \"value\"}, priority=99)\n@@ -381,11 +391,10 @@ class BaseSettingsTest(unittest.TestCase):\n \n     def test_freeze(self):\n         self.settings.freeze()\n-        with self.assertRaises(TypeError) as cm:\n+        with pytest.raises(\n+            TypeError, match=\"Trying to modify an immutable Settings object\"\n+        ):\n             self.settings.set(\"TEST_BOOL\", False)\n-            self.assertEqual(\n-                str(cm.exception), \"Trying to modify an immutable Settings object\"\n-            )\n \n     def test_frozencopy(self):\n         frozencopy = self.settings.frozencopy()\n@@ -476,7 +485,7 @@ class SettingsTest(unittest.TestCase):\n     def test_pop_item_with_default_value(self):\n         settings = Settings()\n \n-        with self.assertRaises(KeyError):\n+        with pytest.raises(KeyError):\n             settings.pop(\"DUMMY_CONFIG\")\n \n         dummy_config_value = settings.pop(\"DUMMY_CONFIG\", \"dummy_value\")\n@@ -491,9 +500,7 @@ class SettingsTest(unittest.TestCase):\n \n         settings.freeze()\n \n-        with self.assertRaises(TypeError) as error:\n+        with pytest.raises(\n+            TypeError, match=\"Trying to modify an immutable Settings object\"\n+        ):\n             settings.pop(\"OTHER_DUMMY_CONFIG\")\n-\n-        self.assertEqual(\n-            str(error.exception), \"Trying to modify an immutable Settings object\"\n-        )\n\n@@ -7,6 +7,7 @@ from pathlib import Path\n from typing import Any\n from unittest import mock\n \n+import pytest\n from testfixtures import LogCapture\n from twisted.internet.defer import inlineCallbacks\n from twisted.trial import unittest\n@@ -57,8 +58,11 @@ class SpiderTest(unittest.TestCase):\n \n     def test_spider_without_name(self):\n         \"\"\"``__init__`` method arguments are assigned to spider attributes\"\"\"\n-        self.assertRaises(ValueError, self.spider_class)\n-        self.assertRaises(ValueError, self.spider_class, somearg=\"foo\")\n+        msg = \"must have a name\"\n+        with pytest.raises(ValueError, match=msg):\n+            self.spider_class()\n+        with pytest.raises(ValueError, match=msg):\n+            self.spider_class(somearg=\"foo\")\n \n     def test_from_crawler_crawler_and_settings_population(self):\n         crawler = get_crawler()\n@@ -475,7 +479,7 @@ class CrawlSpiderTest(SpiderTest):\n         spider = self.spider_class(\"example.com\")\n         spider.start_url = \"https://www.example.com\"\n \n-        with self.assertRaisesRegex(AttributeError, r\"^Crawling could not start.*$\"):\n+        with pytest.raises(AttributeError, match=r\"^Crawling could not start.*$\"):\n             list(spider.start_requests())\n \n \n@@ -825,5 +829,5 @@ class NoParseMethodSpiderTest(unittest.TestCase):\n         resp = TextResponse(url=\"http://www.example.com/random_url\", body=text)\n \n         exc_msg = \"Spider.parse callback is not defined\"\n-        with self.assertRaisesRegex(NotImplementedError, exc_msg):\n+        with pytest.raises(NotImplementedError, match=exc_msg):\n             spider.parse(resp)\n\n@@ -7,6 +7,7 @@ from pathlib import Path\n from tempfile import mkdtemp\n from unittest import mock\n \n+import pytest\n from twisted.trial import unittest\n from zope.interface.verify import verifyObject\n \n@@ -124,9 +125,8 @@ class SpiderLoaderTest(unittest.TestCase):\n             }\n         )\n \n-        self.assertRaisesRegex(\n-            KeyError, \"Spider not found\", runner.create_crawler, \"spider2\"\n-        )\n+        with pytest.raises(KeyError, match=\"Spider not found\"):\n+            runner.create_crawler(\"spider2\")\n \n         crawler = runner.create_crawler(\"spider1\")\n         self.assertTrue(issubclass(crawler.spidercls, scrapy.Spider))\n@@ -135,7 +135,8 @@ class SpiderLoaderTest(unittest.TestCase):\n     def test_bad_spider_modules_exception(self):\n         module = \"tests.test_spiderloader.test_spiders.doesnotexist\"\n         settings = Settings({\"SPIDER_MODULES\": [module]})\n-        self.assertRaises(ImportError, SpiderLoader.from_settings, settings)\n+        with pytest.raises(ImportError):\n+            SpiderLoader.from_settings(settings)\n \n     def test_bad_spider_modules_warning(self):\n         with warnings.catch_warnings(record=True) as w:\n@@ -159,7 +160,8 @@ class SpiderLoaderTest(unittest.TestCase):\n         with mock.patch.object(SpiderLoader, \"_load_spiders\") as m:\n             m.side_effect = SyntaxError\n             settings = Settings({\"SPIDER_MODULES\": [module]})\n-            self.assertRaises(SyntaxError, SpiderLoader.from_settings, settings)\n+            with pytest.raises(SyntaxError):\n+                SpiderLoader.from_settings(settings)\n \n     def test_syntax_error_warning(self):\n         with (\n\n@@ -3,6 +3,7 @@ from __future__ import annotations\n from collections.abc import AsyncIterator, Iterable\n from unittest import mock\n \n+import pytest\n from testfixtures import LogCapture\n from twisted.internet import defer\n from twisted.python.failure import Failure\n@@ -299,12 +300,9 @@ class ProcessSpiderOutputCoroutineMiddleware:\n class ProcessSpiderOutputInvalidResult(BaseAsyncSpiderMiddlewareTestCase):\n     @defer.inlineCallbacks\n     def test_non_iterable(self):\n-        with self.assertRaisesRegex(\n+        with pytest.raises(\n             _InvalidOutput,\n-            (\n-                r\"\\.process_spider_output must return an iterable, got <class \"\n-                r\"'NoneType'>\"\n-            ),\n+            match=r\"\\.process_spider_output must return an iterable, got <class 'NoneType'>\",\n         ):\n             yield self._get_middleware_result(\n                 ProcessSpiderOutputNonIterableMiddleware,\n@@ -312,9 +310,9 @@ class ProcessSpiderOutputInvalidResult(BaseAsyncSpiderMiddlewareTestCase):\n \n     @defer.inlineCallbacks\n     def test_coroutine(self):\n-        with self.assertRaisesRegex(\n+        with pytest.raises(\n             _InvalidOutput,\n-            r\"\\.process_spider_output must be an asynchronous generator\",\n+            match=r\"\\.process_spider_output must be an asynchronous generator\",\n         ):\n             yield self._get_middleware_result(\n                 ProcessSpiderOutputCoroutineMiddleware,\n@@ -518,8 +516,8 @@ class ProcessSpiderExceptionTest(BaseAsyncSpiderMiddlewareTestCase):\n \n     @defer.inlineCallbacks\n     def _test_asyncgen_nodowngrade(self, *mw_classes):\n-        with self.assertRaisesRegex(\n-            _InvalidOutput, \"Async iterable returned from .+ cannot be downgraded\"\n+        with pytest.raises(\n+            _InvalidOutput, match=\"Async iterable returned from .+ cannot be downgraded\"\n         ):\n             yield self._get_middleware_result(*mw_classes)\n \n\n@@ -1,6 +1,7 @@\n import logging\n from unittest import TestCase\n \n+import pytest\n from testfixtures import LogCapture\n from twisted.internet import defer\n from twisted.trial.unittest import TestCase as TrialTestCase\n@@ -68,9 +69,8 @@ class TestHttpErrorMiddleware(TestCase):\n \n     def test_process_spider_input(self):\n         self.assertIsNone(self.mw.process_spider_input(self.res200, self.spider))\n-        self.assertRaises(\n-            HttpError, self.mw.process_spider_input, self.res404, self.spider\n-        )\n+        with pytest.raises(HttpError):\n+            self.mw.process_spider_input(self.res404, self.spider)\n \n     def test_process_spider_exception(self):\n         self.assertEqual(\n@@ -105,9 +105,8 @@ class TestHttpErrorMiddlewareSettings(TestCase):\n \n     def test_process_spider_input(self):\n         self.assertIsNone(self.mw.process_spider_input(self.res200, self.spider))\n-        self.assertRaises(\n-            HttpError, self.mw.process_spider_input, self.res404, self.spider\n-        )\n+        with pytest.raises(HttpError):\n+            self.mw.process_spider_input(self.res404, self.spider)\n         self.assertIsNone(self.mw.process_spider_input(self.res402, self.spider))\n \n     def test_meta_overrides_settings(self):\n@@ -120,14 +119,14 @@ class TestHttpErrorMiddlewareSettings(TestCase):\n         res402.request = request\n \n         self.assertIsNone(self.mw.process_spider_input(res404, self.spider))\n-        self.assertRaises(HttpError, self.mw.process_spider_input, res402, self.spider)\n+        with pytest.raises(HttpError):\n+            self.mw.process_spider_input(res402, self.spider)\n \n     def test_spider_override_settings(self):\n         self.spider.handle_httpstatus_list = [404]\n         self.assertIsNone(self.mw.process_spider_input(self.res404, self.spider))\n-        self.assertRaises(\n-            HttpError, self.mw.process_spider_input, self.res402, self.spider\n-        )\n+        with pytest.raises(HttpError):\n+            self.mw.process_spider_input(self.res402, self.spider)\n \n \n class TestHttpErrorMiddlewareHandleAll(TestCase):\n@@ -151,7 +150,8 @@ class TestHttpErrorMiddlewareHandleAll(TestCase):\n         res402.request = request\n \n         self.assertIsNone(self.mw.process_spider_input(res404, self.spider))\n-        self.assertRaises(HttpError, self.mw.process_spider_input, res402, self.spider)\n+        with pytest.raises(HttpError):\n+            self.mw.process_spider_input(res402, self.spider)\n \n     def test_httperror_allow_all_false(self):\n         crawler = get_crawler(_HttpErrorSpider)\n@@ -167,7 +167,8 @@ class TestHttpErrorMiddlewareHandleAll(TestCase):\n         res402 = self.res402.copy()\n         res402.request = request_httpstatus_true\n \n-        self.assertRaises(HttpError, mw.process_spider_input, res404, self.spider)\n+        with pytest.raises(HttpError):\n+            mw.process_spider_input(res404, self.spider)\n         self.assertIsNone(mw.process_spider_input(res402, self.spider))\n \n \n\n@@ -5,6 +5,8 @@ from typing import Any\n from unittest import TestCase\n from urllib.parse import urlparse\n \n+import pytest\n+\n from scrapy.downloadermiddlewares.redirect import RedirectMiddleware\n from scrapy.http import Request, Response\n from scrapy.settings import Settings\n@@ -884,7 +886,7 @@ class TestSettingsPolicyByName(TestCase):\n \n     def test_invalid_name(self):\n         settings = Settings({\"REFERRER_POLICY\": \"some-custom-unknown-policy\"})\n-        with self.assertRaises(RuntimeError):\n+        with pytest.raises(RuntimeError):\n             RefererMiddleware(settings)\n \n     def test_multiple_policy_tokens(self):\n@@ -925,7 +927,7 @@ class TestSettingsPolicyByName(TestCase):\n                 )\n             }\n         )\n-        with self.assertRaises(RuntimeError):\n+        with pytest.raises(RuntimeError):\n             RefererMiddleware(settings)\n \n \n\n@@ -2,6 +2,7 @@ import shutil\n from datetime import datetime, timezone\n from tempfile import mkdtemp\n \n+import pytest\n from twisted.trial import unittest\n \n from scrapy.exceptions import NotConfigured\n@@ -42,4 +43,5 @@ class SpiderStateTest(unittest.TestCase):\n \n     def test_not_configured(self):\n         crawler = get_crawler(Spider)\n-        self.assertRaises(NotConfigured, SpiderState.from_crawler, crawler)\n+        with pytest.raises(NotConfigured):\n+            SpiderState.from_crawler(crawler)\n\n@@ -1,6 +1,7 @@\n import pickle\n import sys\n \n+import pytest\n from queuelib.tests import test_queue as t\n \n from scrapy.http import Request\n@@ -30,10 +31,17 @@ class MyLoader(ItemLoader):\n \n def nonserializable_object_test(self):\n     q = self.queue()\n-    self.assertRaises(ValueError, q.push, lambda x: x)\n+    with pytest.raises(\n+        ValueError,\n+        match=\"unmarshallable object|Can't (get|pickle) local object|Can't pickle .*: it's not found as\",\n+    ):\n+        q.push(lambda x: x)\n     # Selectors should fail (lxml.html.HtmlElement objects can't be pickled)\n     sel = Selector(text=\"<html><body><p>some text</p></body></html>\")\n-    self.assertRaises(ValueError, q.push, sel)\n+    with pytest.raises(\n+        ValueError, match=\"unmarshallable object|can't pickle Selector objects\"\n+    ):\n+        q.push(sel)\n \n \n class FifoDiskQueueTestMixin:\n\n@@ -6,6 +6,7 @@ import shutil\n import tempfile\n import unittest\n \n+import pytest\n import queuelib\n \n from scrapy.http import Request\n@@ -69,9 +70,9 @@ class RequestQueueTestMixin:\n         req = Request(\"http://www.example.com\")\n         q.push(req)\n         self.assertEqual(len(q), 1)\n-        with self.assertRaises(\n+        with pytest.raises(\n             NotImplementedError,\n-            msg=\"The underlying queue class does not implement 'peek'\",\n+            match=\"The underlying queue class does not implement 'peek'\",\n         ):\n             q.peek()\n         self.assertEqual(q.pop().url, req.url)\n@@ -120,9 +121,9 @@ class FifoQueueMixin(RequestQueueTestMixin):\n         q.push(req1)\n         q.push(req2)\n         q.push(req3)\n-        with self.assertRaises(\n+        with pytest.raises(\n             NotImplementedError,\n-            msg=\"The underlying queue class does not implement 'peek'\",\n+            match=\"The underlying queue class does not implement 'peek'\",\n         ):\n             q.peek()\n         self.assertEqual(len(q), 3)\n@@ -176,9 +177,9 @@ class LifoQueueMixin(RequestQueueTestMixin):\n         q.push(req1)\n         q.push(req2)\n         q.push(req3)\n-        with self.assertRaises(\n+        with pytest.raises(\n             NotImplementedError,\n-            msg=\"The underlying queue class does not implement 'peek'\",\n+            match=\"The underlying queue class does not implement 'peek'\",\n         ):\n             q.peek()\n         self.assertEqual(len(q), 3)\n\n@@ -1,5 +1,7 @@\n import unittest\n \n+import pytest\n+\n from scrapy.exceptions import UsageError\n from scrapy.settings import BaseSettings, Settings\n from scrapy.utils.conf import (\n@@ -32,7 +34,9 @@ class BuildComponentListTest(unittest.TestCase):\n         )\n         # Same priority raises ValueError\n         duplicate_bs.set(\"ONE\", duplicate_bs[\"ONE\"], priority=20)\n-        with self.assertRaises(ValueError):\n+        with pytest.raises(\n+            ValueError, match=\"Some paths in .* convert to the same object\"\n+        ):\n             build_component_list(duplicate_bs, convert=lambda x: x.lower())\n \n     def test_valid_numbers(self):\n@@ -58,21 +62,13 @@ class UtilsConfTestCase(unittest.TestCase):\n class FeedExportConfigTestCase(unittest.TestCase):\n     def test_feed_export_config_invalid_format(self):\n         settings = Settings()\n-        self.assertRaises(\n-            UsageError,\n-            feed_process_params_from_cli,\n-            settings,\n-            [\"items.dat\"],\n-        )\n+        with pytest.raises(UsageError):\n+            feed_process_params_from_cli(settings, [\"items.dat\"])\n \n     def test_feed_export_config_mismatch(self):\n         settings = Settings()\n-        self.assertRaises(\n-            UsageError,\n-            feed_process_params_from_cli,\n-            settings,\n-            [\"items1.dat\", \"items2.dat\"],\n-        )\n+        with pytest.raises(UsageError):\n+            feed_process_params_from_cli(settings, [\"items1.dat\", \"items2.dat\"])\n \n     def test_feed_export_config_explicit_formats(self):\n         settings = Settings()\n@@ -117,11 +113,9 @@ class FeedExportConfigTestCase(unittest.TestCase):\n         )\n \n     def test_output_and_overwrite_output(self):\n-        with self.assertRaises(UsageError):\n+        with pytest.raises(UsageError):\n             feed_process_params_from_cli(\n-                Settings(),\n-                [\"output1.json\"],\n-                overwrite_output=[\"output2.json\"],\n+                Settings(), [\"output1.json\"], overwrite_output=[\"output2.json\"]\n             )\n \n     def test_feed_complete_default_values_from_settings_empty(self):\n\n@@ -1,6 +1,7 @@\n import unittest\n import warnings\n \n+import pytest\n from w3lib.http import basic_auth_header\n \n from scrapy import Request\n@@ -205,11 +206,11 @@ class CurlToRequestKwargsTest(unittest.TestCase):\n         self.assertEqual(curl_to_request_kwargs(curl_command), expected_result)\n \n     def test_too_few_arguments_error(self):\n-        self.assertRaisesRegex(\n+        with pytest.raises(\n             ValueError,\n-            r\"too few arguments|the following arguments are required:\\s*url\",\n-            lambda: curl_to_request_kwargs(\"curl\"),\n-        )\n+            match=r\"too few arguments|the following arguments are required:\\s*url\",\n+        ):\n+            curl_to_request_kwargs(\"curl\")\n \n     def test_ignore_unknown_options(self):\n         # case 1: ignore_unknown_options=True:\n@@ -220,16 +221,11 @@ class CurlToRequestKwargsTest(unittest.TestCase):\n             self.assertEqual(curl_to_request_kwargs(curl_command), expected_result)\n \n         # case 2: ignore_unknown_options=False (raise exception):\n-        self.assertRaisesRegex(\n-            ValueError,\n-            \"Unrecognized options:.*--bar.*--baz\",\n-            lambda: curl_to_request_kwargs(\n+        with pytest.raises(ValueError, match=\"Unrecognized options:.*--bar.*--baz\"):\n+            curl_to_request_kwargs(\n                 \"curl --bar --baz http://www.example.com\", ignore_unknown_options=False\n-            ),\n             )\n \n     def test_must_start_with_curl_error(self):\n-        self.assertRaises(\n-            ValueError,\n-            lambda: curl_to_request_kwargs(\"carl -X POST http://example.org\"),\n-        )\n+        with pytest.raises(ValueError, match=\"A curl command must start\"):\n+            curl_to_request_kwargs(\"carl -X POST http://example.org\")\n\n@@ -87,8 +87,10 @@ class CaseInsensitiveDictMixin:\n     def test_delete(self):\n         d = self.dict_class({\"key_lower\": 1})\n         del d[\"key_LOWER\"]\n-        self.assertRaises(KeyError, d.__getitem__, \"key_LOWER\")\n-        self.assertRaises(KeyError, d.__getitem__, \"key_lower\")\n+        with pytest.raises(KeyError):\n+            d[\"key_LOWER\"]\n+        with pytest.raises(KeyError):\n+            d[\"key_lower\"]\n \n     @pytest.mark.filterwarnings(\"ignore::scrapy.exceptions.ScrapyDeprecationWarning\")\n     def test_getdefault(self):\n@@ -138,7 +140,8 @@ class CaseInsensitiveDictMixin:\n         d = self.dict_class()\n         d[\"a\"] = 1\n         self.assertEqual(d.pop(\"A\"), 1)\n-        self.assertRaises(KeyError, d.pop, \"A\")\n+        with pytest.raises(KeyError):\n+            d.pop(\"A\")\n \n     def test_normkey(self):\n         class MyDict(self.dict_class):\n@@ -279,8 +282,8 @@ class SequenceExcludeTest(unittest.TestCase):\n         self.assertIn(set(\"bar\"), d)\n \n         # supplied sequence is a set, so checking for list (non)inclusion fails\n-        self.assertRaises(TypeError, (0, 1, 2) in d)\n-        self.assertRaises(TypeError, d.__contains__, [\"a\", \"b\", \"c\"])\n+        with pytest.raises(TypeError):\n+            [\"a\", \"b\", \"c\"] in d  # noqa: B015\n \n         for v in [-3, \"test\", 1.1]:\n             self.assertNotIn(v, d)\n\n@@ -3,6 +3,8 @@ import unittest\n import warnings\n from unittest import mock\n \n+import pytest\n+\n from scrapy.exceptions import ScrapyDeprecationWarning\n from scrapy.utils.deprecate import create_deprecated_class, update_classpath\n \n@@ -181,7 +183,8 @@ class WarnWhenSubclassedTest(unittest.TestCase):\n         assert not issubclass(OutdatedUserClass1, OutdatedUserClass1a)\n         assert not issubclass(OutdatedUserClass1a, OutdatedUserClass1)\n \n-        self.assertRaises(TypeError, issubclass, object(), DeprecatedName)\n+        with pytest.raises(TypeError):\n+            issubclass(object(), DeprecatedName)\n \n     def test_isinstance(self):\n         with warnings.catch_warnings():\n\n@@ -1,6 +1,8 @@\n import unittest\n+from gzip import BadGzipFile\n from pathlib import Path\n \n+import pytest\n from w3lib.encoding import html_to_unicode\n \n from scrapy.http import Response\n@@ -27,9 +29,8 @@ class GunzipTest(unittest.TestCase):\n         assert text.endswith(b\"</html\")\n \n     def test_gunzip_no_gzip_file_raises(self):\n-        self.assertRaises(\n-            OSError, gunzip, (SAMPLEDIR / \"feed-sample1.xml\").read_bytes()\n-        )\n+        with pytest.raises(BadGzipFile):\n+            gunzip((SAMPLEDIR / \"feed-sample1.xml\").read_bytes())\n \n     def test_gunzip_truncated_short(self):\n         r1 = Response(\n\n@@ -215,7 +215,7 @@ class XmliterBaseTestCase:\n         \"\"\"\n         response = XmlResponse(url=\"http://mydummycompany.com\", body=body)\n         my_iter = self.xmliter(response, \"g:link_image\")\n-        with self.assertRaises(StopIteration):\n+        with pytest.raises(StopIteration):\n             next(my_iter)\n \n     @pytest.mark.filterwarnings(\"ignore::scrapy.exceptions.ScrapyDeprecationWarning\")\n@@ -228,13 +228,14 @@ class XmliterBaseTestCase:\n         iter = self.xmliter(body, \"product\")\n         next(iter)\n         next(iter)\n-\n-        self.assertRaises(StopIteration, next, iter)\n+        with pytest.raises(StopIteration):\n+            next(iter)\n \n     @pytest.mark.filterwarnings(\"ignore::scrapy.exceptions.ScrapyDeprecationWarning\")\n     def test_xmliter_objtype_exception(self):\n         i = self.xmliter(42, \"product\")\n-        self.assertRaises(TypeError, next, i)\n+        with pytest.raises(TypeError):\n+            next(i)\n \n     @pytest.mark.filterwarnings(\"ignore::scrapy.exceptions.ScrapyDeprecationWarning\")\n     def test_xmliter_encoding(self):\n@@ -344,7 +345,8 @@ class LxmlXmliterTestCase(XmliterBaseTestCase, unittest.TestCase):\n \n     def test_xmliter_objtype_exception(self):\n         i = self.xmliter(42, \"product\")\n-        self.assertRaises(TypeError, next, i)\n+        with pytest.raises(TypeError):\n+            next(i)\n \n \n class UtilsCsvTestCase(unittest.TestCase):\n@@ -491,8 +493,8 @@ class UtilsCsvTestCase(unittest.TestCase):\n         next(iter)\n         next(iter)\n         next(iter)\n-\n-        self.assertRaises(StopIteration, next, iter)\n+        with pytest.raises(StopIteration):\n+            next(iter)\n \n     def test_csviter_encoding(self):\n         body1 = get_testdata(\"feeds\", \"feed-sample4.csv\")\n\n@@ -32,9 +32,12 @@ class UtilsMiscTestCase(unittest.TestCase):\n         self.assertIs(obj, load_object)\n \n     def test_load_object_exceptions(self):\n-        self.assertRaises(ImportError, load_object, \"nomodule999.mod.function\")\n-        self.assertRaises(NameError, load_object, \"scrapy.utils.misc.load_object999\")\n-        self.assertRaises(TypeError, load_object, {})\n+        with pytest.raises(ImportError):\n+            load_object(\"nomodule999.mod.function\")\n+        with pytest.raises(NameError):\n+            load_object(\"scrapy.utils.misc.load_object999\")\n+        with pytest.raises(TypeError):\n+            load_object({})\n \n     def test_walk_modules(self):\n         mods = walk_modules(\"tests.test_utils_misc.test_walk_modules\")\n@@ -59,7 +62,8 @@ class UtilsMiscTestCase(unittest.TestCase):\n         ]\n         self.assertEqual({m.__name__ for m in mods}, set(expected))\n \n-        self.assertRaises(ImportError, walk_modules, \"nomodule999\")\n+        with pytest.raises(ImportError):\n+            walk_modules(\"nomodule999\")\n \n     def test_walk_modules_egg(self):\n         egg = str(Path(__file__).parent / \"test.egg\")\n@@ -148,11 +152,13 @@ class UtilsMiscTestCase(unittest.TestCase):\n         create_instance(m, None, crawler, *args, **kwargs)\n         m.from_settings.assert_called_once_with(crawler.settings, *args, **kwargs)\n \n-        with self.assertRaises(ValueError):\n+        with pytest.raises(\n+            ValueError, match=\"Specify at least one of settings and crawler\"\n+        ):\n             create_instance(m, None, None)\n \n         m.from_settings.return_value = None\n-        with self.assertRaises(TypeError):\n+        with pytest.raises(TypeError):\n             create_instance(m, settings, None)\n \n     def test_build_from_crawler(self):\n@@ -191,7 +197,7 @@ class UtilsMiscTestCase(unittest.TestCase):\n         # Check adoption of crawler\n         m = mock.MagicMock(spec_set=[\"__qualname__\", \"from_crawler\"])\n         m.from_crawler.return_value = None\n-        with self.assertRaises(TypeError):\n+        with pytest.raises(TypeError):\n             build_from_crawler(m, crawler, *args, **kwargs)\n \n     def test_set_environ(self):\n\n@@ -87,7 +87,8 @@ class ToUnicodeTest(unittest.TestCase):\n         self.assertEqual(to_unicode(\"\\xf1e\\xf1e\\xf1e\"), \"\\xf1e\\xf1e\\xf1e\")\n \n     def test_converting_a_strange_object_should_raise_TypeError(self):\n-        self.assertRaises(TypeError, to_unicode, 423)\n+        with pytest.raises(TypeError):\n+            to_unicode(423)\n \n     def test_errors_argument(self):\n         self.assertEqual(to_unicode(b\"a\\xedb\", \"utf-8\", errors=\"replace\"), \"a\\ufffdb\")\n@@ -104,7 +105,8 @@ class ToBytesTest(unittest.TestCase):\n         self.assertEqual(to_bytes(b\"lel\\xf1e\"), b\"lel\\xf1e\")\n \n     def test_converting_a_strange_object_should_raise_TypeError(self):\n-        self.assertRaises(TypeError, to_bytes, unittest)\n+        with pytest.raises(TypeError):\n+            to_bytes(pytest)\n \n     def test_errors_argument(self):\n         self.assertEqual(to_bytes(\"a\\ufffdb\", \"latin-1\", errors=\"replace\"), b\"a?b\")\n\n@@ -35,7 +35,8 @@ class ResponseUtilsTest(unittest.TestCase):\n         assert open_in_browser(response, _openfunc=browser_open), \"Browser not called\"\n \n         resp = Response(url, body=body)\n-        self.assertRaises(TypeError, open_in_browser, resp, debug=True)\n+        with pytest.raises(TypeError):\n+            open_in_browser(resp, debug=True)  # pylint: disable=unexpected-keyword-arg\n \n     def test_get_meta_refresh(self):\n         r1 = HtmlResponse(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
