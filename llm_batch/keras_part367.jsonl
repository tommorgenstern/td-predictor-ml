{"custom_id": "keras#0be7f4317123b07420cf17fbb8ef0335a02c7a74", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 25 | Lines Deleted: 50 | Files Changed: 2 | Hunks: 5 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/1 | Churn Δ: 75 | Churn Cumulative: 228 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -15,11 +15,15 @@\n \"\"\"InputSpec tests.\"\"\"\n \n import tensorflow.compat.v2 as tf\n+\n+from absl.testing import parameterized\n+from keras import keras_parameterized\n from keras import layers\n from keras.engine import keras_tensor\n+from keras.engine import training\n \n \n-class KerasTensorTest(tf.test.TestCase):\n+class KerasTensorTest(keras_parameterized.TestCase):\n \n   def test_repr_and_string(self):\n     kt = keras_tensor.KerasTensor(\n@@ -84,6 +88,26 @@ class KerasTensorTest(tf.test.TestCase):\n       self.assertEqual(expected_str, str(kts[i]))\n       self.assertEqual(expected_repr, repr(kts[i]))\n     \n+  @parameterized.parameters(\n+      {'property_name': 'values'},\n+      {'property_name': 'indices'},\n+      {'property_name': 'dense_shape'},\n+  )\n+  def test_sparse_instance_property(self, property_name):\n+    inp = layers.Input(shape=[3], sparse=True)\n+    out = getattr(inp, property_name)\n+    model = training.Model(inp, out)\n+\n+    x = tf.SparseTensor([[0, 0], [0, 1], [1, 1], [1, 2]], [1, 2, 3, 4], [2, 3])\n+    expected_property = getattr(x, property_name)\n+    self.assertAllEqual(model(x), expected_property)\n+\n+    # Test that it works with serialization and deserialization as well\n+    model_config = model.get_config()\n+    model2 = training.Model.from_config(model_config)\n+    self.assertAllEqual(model2(x), expected_property)\n+\n+\n if __name__ == \"__main__\":\n   tf.compat.v1.enable_eager_execution()\n   tf.compat.v1.enable_v2_tensorshape()\n\n@@ -1,49 +0,0 @@\n-# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n-#\n-# Licensed under the Apache License, Version 2.0 (the \"License\");\n-# you may not use this file except in compliance with the License.\n-# You may obtain a copy of the License at\n-#\n-#     http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing, software\n-# distributed under the License is distributed on an \"AS IS\" BASIS,\n-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-# See the License for the specific language governing permissions and\n-# limitations under the License.\n-# ==============================================================================\n-\"\"\"RaggedKerasTensor tests.\"\"\"\n-\n-import tensorflow.compat.v2 as tf\n-\n-from absl.testing import parameterized\n-from keras import keras_parameterized\n-from keras import layers\n-from keras.engine import training\n-\n-\n-class SparseKerasTensorTest(keras_parameterized.TestCase):\n-  @parameterized.parameters(\n-      {'property_name': 'values'},\n-      {'property_name': 'indices'},\n-      {'property_name': 'dense_shape'},\n-  )\n-  def test_instance_property(self, property_name):\n-    inp = layers.Input(shape=[3], sparse=True)\n-    out = getattr(inp, property_name)\n-    model = training.Model(inp, out)\n-\n-    x = tf.SparseTensor([[0, 0], [0, 1], [1, 1], [1, 2]], [1, 2, 3, 4], [2, 3])\n-    expected_property = getattr(x, property_name)\n-    self.assertAllEqual(model(x), expected_property)\n-\n-    # Test that it works with serialization and deserialization as well\n-    model_config = model.get_config()\n-    model2 = training.Model.from_config(model_config)\n-    self.assertAllEqual(model2(x), expected_property)\n-\n-\n-if __name__ == '__main__':\n-  tf.compat.v1.enable_eager_execution()\n-  tf.compat.v1.enable_v2_tensorshape()\n-  tf.test.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#001972c9397d541d85607c3d146f60cdbaa1469f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 24 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 24 | Churn Cumulative: 238 | Contributors (this commit): 4 | Commits (past 90d): 3 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -105,6 +105,30 @@ class ModelToDotFormatTest(tf.test.TestCase, parameterized.TestCase):\n     except ImportError:\n       pass\n   \n+  def test_plot_model_cnn_with_activations(self):\n+    model = keras.Sequential()\n+    model.add(keras.layers.Conv2D(\n+        filters=2,\n+        kernel_size=2,\n+        input_shape=(9, 9, 3),\n+        activation='relu'))\n+    model.add(keras.layers.Conv2D(\n+        filters=4,\n+        kernel_size=2,\n+        strides=(2, 2),\n+        activation='relu'))\n+    model.add(keras.layers.Flatten(name='flat'))\n+    model.add(keras.layers.Dense(5, name='head', activation='softmax'))\n+    dot_img_file = 'model_5.png'\n+    try:\n+      vis_utils.plot_model(\n+          model, to_file=dot_img_file, show_shapes=True,\n+          show_dtype=True, show_layer_activations=True)\n+      self.assertTrue(tf.io.gfile.exists(dot_img_file))\n+      tf.io.gfile.remove(dot_img_file)\n+    except ImportError:\n+      pass\n+\n   @parameterized.parameters(\n       {'layer_range': ['block1a_project_conv', 'block1a_activation']},\n       {'layer_range': ['block1a_activation', 'block1a_project_conv']},\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#372515ca4540d99eece842ab0b56d13eedf37b7c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 43 | Lines Deleted: 43 | Files Changed: 12 | Hunks: 38 | Methods Changed: 21 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 86 | Churn Cumulative: 13877 | Contributors (this commit): 12 | Commits (past 90d): 46 | Contributors (cumulative): 46 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1661,9 +1661,8 @@ def zeros_like(x, dtype=None, name=None):\n   Example:\n \n   ```python\n-  from tensorflow.keras import backend as K\n-  kvar = K.variable(np.random.random((2,3)))\n-  kvar_zeros = K.zeros_like(kvar)\n+  kvar = tf.keras.backend.variable(np.random.random((2,3)))\n+  kvar_zeros = tf.keras.backend.zeros_like(kvar)\n   K.eval(kvar_zeros)\n   # array([[ 0.,  0.,  0.], [ 0.,  0.,  0.]], dtype=float32)\n   ```\n\n@@ -20,7 +20,7 @@ import tensorflow.compat.v2 as tf\n \n import os\n import numpy as np\n-from keras import backend as K\n+from keras import backend\n from keras import callbacks\n from tensorflow.python.platform import tf_logging as logging\n from tensorflow.python.util.tf_export import keras_export\n@@ -160,9 +160,10 @@ class TensorBoard(callbacks.TensorBoard):\n       self.writer = tf.summary.create_file_writer(self.log_dir)\n       if not model.run_eagerly and self.write_graph:\n         with self.writer.as_default():\n-          tf.summary.graph(K.get_graph())\n+          tf.summary.graph(backend.get_graph())\n     elif self.write_graph:\n-      self.writer = tf.compat.v1.summary.FileWriter(self.log_dir, K.get_graph())\n+      self.writer = tf.compat.v1.summary.FileWriter(\n+          self.log_dir, backend.get_graph())\n     else:\n       self.writer = tf.compat.v1.summary.FileWriter(self.log_dir)\n \n@@ -176,27 +177,26 @@ class TensorBoard(callbacks.TensorBoard):\n           tf.compat.v1.summary.histogram(mapped_weight_name, weight)\n           if self.write_images:\n             w_img = tf.compat.v1.squeeze(weight)\n-            shape = K.int_shape(w_img)\n+            shape = tuple(w_img.shape)\n             if len(shape) == 2:  # dense layer kernel case\n               if shape[0] > shape[1]:\n                 w_img = tf.compat.v1.transpose(w_img)\n-                shape = K.int_shape(w_img)\n+                shape = tuple(w_img.shape)\n               w_img = tf.reshape(w_img, [1, shape[0], shape[1], 1])\n             elif len(shape) == 3:  # convnet case\n-              if K.image_data_format() == 'channels_last':\n+              if backend.image_data_format() == 'channels_last':\n                 # switch to channels_first to display\n                 # every kernel as a separate image\n                 w_img = tf.compat.v1.transpose(w_img, perm=[2, 0, 1])\n-                shape = K.int_shape(w_img)\n-              w_img = tf.reshape(w_img,\n-                                        [shape[0], shape[1], shape[2], 1])\n+                shape = tuple(w_img.shape)\n+              w_img = tf.reshape(w_img, [shape[0], shape[1], shape[2], 1])\n             elif len(shape) == 1:  # bias case\n               w_img = tf.reshape(w_img, [1, shape[0], 1, 1])\n             else:\n               # not possible to handle 3D convnets etc.\n               continue\n \n-            shape = K.int_shape(w_img)\n+            shape = tuple(w_img.shape)\n             assert len(shape) == 4 and shape[-1] in [1, 3, 4]\n             tf.compat.v1.summary.image(mapped_weight_name, w_img)\n \n@@ -421,7 +421,7 @@ class TensorBoard(callbacks.TensorBoard):\n         embeddings_data = self.embeddings_data\n         n_samples = embeddings_data[0].shape[0]\n         i = 0\n-        sess = K.get_session()\n+        sess = backend.get_session()\n         while i < n_samples:\n           step = min(self.batch_size, n_samples - i)\n           batch = slice(i, i + step)\n@@ -436,8 +436,8 @@ class TensorBoard(callbacks.TensorBoard):\n \n           feed_dict.update({self.batch_id: i, self.step: step})\n \n-          if not isinstance(K.learning_phase(), int):\n-            feed_dict[K.learning_phase()] = False\n+          if not isinstance(backend.learning_phase(), int):\n+            feed_dict[backend.learning_phase()] = False\n \n           sess.run(self.assign_embeddings, feed_dict=feed_dict)\n           self.saver.save(sess,\n\n@@ -16,7 +16,7 @@\n # pylint: disable=g-classes-have-attributes,g-direct-tensorflow-import\n \n from keras import activations\n-from keras import backend as K\n+from keras import backend\n from keras import constraints\n from keras import initializers\n from keras import regularizers\n@@ -128,7 +128,7 @@ class Dense(Layer):\n     self.supports_masking = True\n \n   def build(self, input_shape):\n-    dtype = tf.as_dtype(self.dtype or K.floatx())\n+    dtype = tf.as_dtype(self.dtype or backend.floatx())\n     if not (dtype.is_floating or dtype.is_complex):\n       raise TypeError('A Dense layer can only be built with a floating-point '\n                       f'dtype. Received: dtype={dtype}')\n\n@@ -15,7 +15,7 @@\n \"\"\"Contains the dropout layer.\"\"\"\n # pylint: disable=g-classes-have-attributes,g-direct-tensorflow-import\n \n-from keras import backend as K\n+from keras import backend\n from keras.engine.base_layer import Layer\n from keras.utils import control_flow_util\n import tensorflow.compat.v2 as tf\n@@ -110,7 +110,7 @@ class Dropout(Layer):\n \n   def call(self, inputs, training=None):\n     if training is None:\n-      training = K.learning_phase()\n+      training = backend.learning_phase()\n \n     def dropped_inputs():\n       return tf.nn.dropout(\n\n@@ -15,7 +15,6 @@\n \"\"\"Contains the Masking layer.\"\"\"\n # pylint: disable=g-classes-have-attributes,g-direct-tensorflow-import\n \n-from keras import backend as K\n from keras.engine.base_layer import Layer\n import tensorflow.compat.v2 as tf\n from tensorflow.python.util.tf_export import keras_export\n@@ -69,10 +68,10 @@ class Masking(Layer):\n     self._compute_output_and_mask_jointly = True\n \n   def compute_mask(self, inputs, mask=None):\n-    return K.any(tf.not_equal(inputs, self.mask_value), axis=-1)\n+    return tf.reduce_any(tf.not_equal(inputs, self.mask_value), axis=-1)\n \n   def call(self, inputs):\n-    boolean_mask = K.any(\n+    boolean_mask = tf.reduce_any(\n         tf.not_equal(inputs, self.mask_value), axis=-1, keepdims=True)\n     outputs = inputs * tf.cast(boolean_mask, inputs.dtype)\n     # Compute the mask and outputs simultaneously.\n\n@@ -15,7 +15,7 @@\n \"\"\"Contains the RepeatVector layer.\"\"\"\n # pylint: disable=g-classes-have-attributes,g-direct-tensorflow-import\n \n-from keras import backend as K\n+from keras import backend\n from keras.engine.base_layer import Layer\n from keras.engine.input_spec import InputSpec\n import tensorflow.compat.v2 as tf\n@@ -57,7 +57,7 @@ class RepeatVector(Layer):\n     return tf.TensorShape([input_shape[0], self.n, input_shape[1]])\n \n   def call(self, inputs):\n-    return K.repeat(inputs, self.n)\n+    return backend.repeat(inputs, self.n)\n \n   def get_config(self):\n     config = {'n': self.n}\n\n@@ -17,7 +17,7 @@\n import tensorflow.compat.v2 as tf\n # pylint: enable=g-bad-import-order\n \n-from keras import backend as K\n+from keras import backend\n from keras.engine import keras_tensor\n from keras.engine.base_layer import Layer\n \n@@ -48,7 +48,7 @@ class ClassMethod(Layer):\n         get_canonical_name_for_symbol(\n             self.cls_ref, api_name='keras', add_prefix_to_v1_names=True))\n     if 'name' not in kwargs:\n-      kwargs['name'] = K.unique_object_name(\n+      kwargs['name'] = backend.unique_object_name(\n           'tf.' + self.cls_symbol + '.' + self.method_name,\n           zero_based=True,\n           avoid_observed_names=True)\n@@ -134,7 +134,7 @@ class InstanceProperty(Layer):\n     self.attr_name = attr_name\n \n     if 'name' not in kwargs:\n-      kwargs['name'] = K.unique_object_name(\n+      kwargs['name'] = backend.unique_object_name(\n           'input.' + self.attr_name, zero_based=True, avoid_observed_names=True)\n     kwargs['autocast'] = False\n \n@@ -217,7 +217,7 @@ class TFOpLambda(Layer):\n         name = 'tf.' + self.symbol\n       else:\n         name = self.function.__name__\n-      kwargs['name'] = K.unique_object_name(\n+      kwargs['name'] = backend.unique_object_name(\n           name, zero_based=True, avoid_observed_names=True)\n     kwargs['autocast'] = False\n \n\n@@ -18,7 +18,7 @@ import tensorflow.compat.v2 as tf\n \n import os\n \n-from keras import backend as K\n+from keras import backend\n from keras.protobuf import saved_metadata_pb2\n from keras.protobuf import versions_pb2\n from keras.saving import saving_utils\n@@ -85,7 +85,7 @@ def save(model, filepath, overwrite, include_optimizer, signatures=None,\n   # already-set learning phase placeholder.\n   # This is needed for compatibility reasons until learning phase setting\n   # is removed from the public apis.\n-  with K.deprecated_internal_learning_phase_scope(0):\n+  with backend.deprecated_internal_learning_phase_scope(0):\n     with utils.keras_option_scope(save_traces):\n       saved_nodes, node_paths = save_lib.save_and_return_nodes(\n           model, filepath, signatures, options)\n\n@@ -22,7 +22,7 @@ import functools\n import threading\n import weakref\n \n-from keras import backend as K\n+from keras import backend\n from keras.engine import base_layer_utils\n from keras.engine import input_spec\n from keras.mixed_precision import autocast_variable\n@@ -355,7 +355,7 @@ def tracing_scope():\n     while _thread_local_data.trace_queue:\n       fn, args, kwargs, training = _thread_local_data.trace_queue.pop()\n       if training is not None:\n-        with K.deprecated_internal_learning_phase_scope(training):\n+        with backend.deprecated_internal_learning_phase_scope(training):\n           fn.get_concrete_function(*args, **kwargs)\n       else:\n         fn.get_concrete_function(*args, **kwargs)\n@@ -694,7 +694,7 @@ def _wrap_activity_regularizer(layer):\n       layer._activity_regularizer,\n       '{}_activity_regularizer'.format(layer.name),\n       input_signature=[\n-          tf.TensorSpec(None, layer._compute_dtype or K.floatx())\n+          tf.TensorSpec(None, layer._compute_dtype or backend.floatx())\n       ])\n   # pylint: enable=protected-access\n \n\n@@ -19,7 +19,7 @@ import tensorflow.compat.v2 as tf\n import itertools\n import threading\n import types\n-from keras import backend as K\n+from keras import backend\n from keras.engine import base_layer_utils\n from keras.utils import control_flow_util\n from keras.utils import tf_contextlib\n@@ -43,7 +43,7 @@ def use_wrapped_call(layer, call_fn, default_training_value=None,\n     call_fn: tf.function that takes layer inputs (and possibly a training arg),\n       and returns a tuple of (outputs, list of losses).\n     default_training_value: Default value of the training kwarg. If `None`, the\n-      default is `K.learning_phase()`.\n+      default is `tf.keras.backend.learning_phase()`.\n     return_method: Whether to return a method bound to the layer.\n \n   Returns:\n@@ -138,7 +138,8 @@ def maybe_add_training_arg(\n     wrapped_call: Wrapped call function.\n     expects_training_arg: Whether to include 'training' argument.\n     default_training_value: Default value of the training kwarg to include in\n-      the arg spec. If `None`, the default is `K.learning_phase()`.\n+      the arg spec. If `None`, the default is\n+      `tf.keras.backend.learning_phase()`.\n \n   Returns:\n     Tuple of (\n@@ -152,7 +153,7 @@ def maybe_add_training_arg(\n     training_arg_index = get_training_arg_index(original_call)\n     training = get_training_arg(training_arg_index, args, kwargs)\n     if training is None:\n-      training = default_training_value or K.learning_phase()\n+      training = default_training_value or backend.learning_phase()\n \n     args = list(args)\n     kwargs = kwargs.copy()\n\n@@ -19,7 +19,7 @@ import tensorflow.compat.v2 as tf\n \n import copy\n import os\n-from keras import backend as K\n+from keras import backend\n from keras import losses\n from keras import optimizer_v1\n from keras import optimizers\n@@ -149,7 +149,7 @@ def model_metadata(model, include_optimizer=True, require_config=True):\n \n   metadata = dict(\n       keras_version=str(keras_version),\n-      backend=K.backend(),\n+      backend=backend.backend(),\n       model_config=model_config)\n   if model.optimizer and include_optimizer:\n     if isinstance(model.optimizer, optimizer_v1.TFOptimizer):\n\n@@ -20,7 +20,7 @@ import collections\n import copy\n import numpy as np\n from tensorflow.python.framework import ops\n-from keras import backend as K\n+from keras import backend\n from keras.engine import keras_tensor\n from keras.utils import object_identity\n from keras.utils import tf_contextlib\n@@ -438,7 +438,7 @@ def maybe_init_scope(layer):\n def graph_context_for_symbolic_tensors(*args, **kwargs):\n   \"\"\"Returns graph context manager if any of the inputs is a symbolic tensor.\"\"\"\n   if any(is_symbolic_tensor(v) for v in list(args) + list(kwargs.values())):\n-    with K.get_graph().as_default():\n+    with backend.get_graph().as_default():\n       yield\n   else:\n     yield\n@@ -450,7 +450,8 @@ def dataset_is_infinite(dataset):\n     return tf.equal(\n         tf.data.experimental.cardinality(dataset), tf.data.experimental.INFINITE_CARDINALITY)\n   else:\n-    dataset_size = K.get_session().run(tf.data.experimental.cardinality(dataset))\n+    dataset_size = backend.get_session().run(\n+        tf.data.experimental.cardinality(dataset))\n     return dataset_size == tf.data.experimental.INFINITE_CARDINALITY\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f256a9c7ae08fbbea8404e6b2f0205c759732da0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 2 | Churn Cumulative: 2002 | Contributors (this commit): 9 | Commits (past 90d): 15 | Contributors (cumulative): 9 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1564,6 +1564,8 @@ def unpack_x_y_sample_weight(data):\n     The unpacked tuple, with `None`s for `y` and `sample_weight` if they are not\n     provided.\n   \"\"\"\n+  if isinstance(data, list):\n+    data = tuple(data)\n   if not isinstance(data, tuple):\n     return (data, None, None)\n   elif len(data) == 1:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#de730dbbd47b238e864766b5efb55bc044542678", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 3 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 20 | Churn Cumulative: 5265 | Contributors (this commit): 8 | Commits (past 90d): 17 | Contributors (cumulative): 12 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1110,6 +1110,19 @@ class ListsOfScalarsDataAdapterTest(DataAdapterTestBase):\n     self.assertFalse(self.adapter_cls.can_handle([]))\n \n \n+class TestDataAdapterUtils(DataAdapterTestBase):\n+\n+  def setUp(self):\n+    super(TestDataAdapterUtils, self).setUp()\n+\n+  def test_unpack_x_y_sample_weight_with_tuple_and_list(self):\n+    tuple_version = data_adapter.unpack_x_y_sample_weight(\n+        (self.tensor_input, self.tensor_target))\n+    list_version = data_adapter.unpack_x_y_sample_weight(\n+        [self.tensor_input, self.tensor_target])\n+    self.assertTrue(tuple_version==list_version)\n+        \n+\n if __name__ == '__main__':\n   tf.compat.v1.enable_eager_execution()\n   tf.test.main()\n\n@@ -322,6 +322,13 @@ class TrainingTest(keras_parameterized.TestCase):\n         epochs=2,\n         batch_size=5,\n         verbose=2)\n+    model.fit(\n+        [input_a_np, input_b_np], [output_d_np, output_e_np],\n+        validation_data=[[input_a_np, input_b_np], [output_d_np,\n+                                                    output_e_np]],\n+        epochs=2,\n+        batch_size=5,\n+        verbose=2)\n     # Test with validation split\n     model.fit(\n         [input_a_np, input_b_np], [output_d_np, output_e_np],\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e4815a1e6fe6f183762c9a70910d6150394033dc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 55 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 4/2 | Churn Δ: 56 | Churn Cumulative: 893 | Contributors (this commit): 3 | Commits (past 90d): 8 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -18,6 +18,7 @@ import tensorflow.compat.v2 as tf\n \n import collections\n import copy\n+import random\n import numpy as np\n from tensorflow.python.framework import ops\n from keras import backend\n@@ -27,6 +28,38 @@ from keras.utils import tf_contextlib\n from tensorflow.python.util.tf_export import keras_export\n \n \n+@keras_export('keras.utils.set_random_seed', v1=[])\n+def set_random_seed(seed):\n+  \"\"\"Sets all random seeds for the program (Python, NumPy, and TensorFlow).\n+\n+  You can use this utility to make almost any Keras program fully deterministic.\n+  Some limitations apply in cases where network communications are involved\n+  (e.g. parameter server distribution), which creates additional sources of\n+  randomness, or when certain non-deterministic cuDNN ops are involved.\n+\n+  Calling this utility is equivalent to the following:\n+\n+  ```python\n+  import random\n+  import numpy as np\n+  import tensorflow as tf\n+  random.seed(seed)\n+  np.random.seed(seed)\n+  tf.random.set_seed(seed)\n+  ```\n+\n+  Arguments:\n+    seed: Integer, the random seed to use.\n+  \"\"\"\n+  if not isinstance(seed, int):\n+    raise ValueError(\n+        'Expected `seed` argument to be an integer. '\n+        f'Received: seed={seed} (of type {type(seed)})')\n+  random.seed(seed)\n+  np.random.seed(seed)\n+  tf.random.set_seed(seed)\n+\n+\n def is_tensor_or_tensor_list(v):\n   v = tf.nest.flatten(v)\n   if v and isinstance(v[0], tf.Tensor):\n\n@@ -17,7 +17,7 @@\n import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n-\n+import numpy as np\n import keras\n from keras import combinations\n from keras.utils import tf_utils\n@@ -228,5 +228,26 @@ class TestIsExtensionType(tf.test.TestCase):\n     tensor = [1., 2., 3.]\n     self.assertFalse(tf_utils.is_extension_type(tensor))\n \n+\n+class TestRandomSeedSetting(tf.test.TestCase):\n+\n+  def test_seeds(self):\n+    def get_model_output():\n+      model = keras.Sequential([\n+          keras.layers.Dense(10),\n+          keras.layers.Dropout(0.5),\n+          keras.layers.Dense(10),\n+      ])\n+      x = np.random.random((32, 10)).astype('float32')\n+      ds = tf.data.Dataset.from_tensor_slices(x).shuffle(32).batch(16)\n+      return model.predict(ds)\n+\n+    tf_utils.set_random_seed(42)\n+    y1 = get_model_output()\n+    tf_utils.set_random_seed(42)\n+    y2 = get_model_output()\n+    self.assertAllClose(y1, y2, atol=1e-6)\n+\n+\n if __name__ == '__main__':\n   tf.test.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#db3fa5d40ed19cdf89fc295e8d0e317fb64480d4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 121 | Lines Deleted: 48 | Files Changed: 9 | Hunks: 45 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 169 | Churn Cumulative: 9769 | Contributors (this commit): 7 | Commits (past 90d): 85 | Contributors (cumulative): 48 | DMM Complexity: None\n\nDIFF:\n@@ -27,11 +27,14 @@ from tensorflow.python.util.tf_export import keras_export\n \n @keras_export('keras.layers.experimental.preprocessing.CategoryCrossing')\n class CategoryCrossing(base_layer.Layer):\n-  \"\"\"Category crossing layer.\n+  \"\"\"A preprocessing layer which crosses categorical features.\n \n   This layer concatenates multiple categorical inputs into a single categorical\n   output (similar to Cartesian product). The output dtype is string.\n \n+  For an overview and full list of preprocessing layers, see the preprocessing\n+  [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).\n+\n   Usage:\n   >>> inp_1 = ['a', 'b', 'c']\n   >>> inp_2 = ['d', 'e', 'f']\n\n@@ -35,13 +35,16 @@ COUNT = \"count\"\n @keras_export(\"keras.layers.CategoryEncoding\",\n               \"keras.layers.experimental.preprocessing.CategoryEncoding\")\n class CategoryEncoding(base_layer.Layer):\n-  \"\"\"Category encoding layer.\n+  \"\"\"A preprocessing layer which encodes integer features.\n \n   This layer provides options for condensing data into a categorical encoding\n   when the total number of tokens are known in advance. It accepts integer\n-  values as inputs, and it outputs a dense representation of those\n-  inputs. For integer inputs where the total number of tokens is not known,\n-  use instead `tf.keras.layers.IntegerLookup`.\n+  values as inputs, and it outputs a dense or sparse representation of those\n+  inputs. For integer inputs where the total number of tokens is not known, use\n+  `tf.keras.layers.IntegerLookup` instead.\n+\n+  For an overview and full list of preprocessing layers, see the preprocessing\n+  [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).\n \n   Examples:\n \n\n@@ -123,12 +123,15 @@ def get_bin_boundaries(summary, num_bins):\n @keras_export(\"keras.layers.Discretization\",\n               \"keras.layers.experimental.preprocessing.Discretization\")\n class Discretization(base_preprocessing_layer.PreprocessingLayer):\n-  \"\"\"Buckets data into discrete ranges.\n+  \"\"\"A preprocessing layer which buckets continuous features by ranges.\n \n   This layer will place each element of its input data into one of several\n   contiguous ranges and output an integer index indicating which range each\n   element was placed in.\n \n+  For an overview and full list of preprocessing layers, see the preprocessing\n+  [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).\n+\n   Input shape:\n     Any `tf.Tensor` or `tf.RaggedTensor` of dimension 2 or higher.\n \n\n@@ -27,10 +27,10 @@ from tensorflow.python.util.tf_export import keras_export\n @keras_export('keras.layers.Hashing',\n               'keras.layers.experimental.preprocessing.Hashing')\n class Hashing(base_layer.Layer):\n-  \"\"\"Implements categorical feature hashing, also known as \"hashing trick\".\n+  \"\"\"A preprocessing layer which hashes and bins categorical features.\n \n-  This layer transforms single or multiple categorical inputs to hashed output.\n-  It converts a sequence of int or string to a sequence of int. The stable hash\n+  This layer transforms categorical inputs to hashed output. It element-wise\n+  converts a ints or strings to ints in a fixed range. The stable hash\n   function uses `tensorflow::ops::Fingerprint` to produce the same output\n   consistently across all platforms.\n \n@@ -44,6 +44,9 @@ class Hashing(base_layer.Layer):\n   [SipHash64](https://github.com/google/highwayhash) hash function, with\n   the `salt` value serving as additional input to the hash function.\n \n+  For an overview and full list of preprocessing layers, see the preprocessing\n+  [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).\n+\n   **Example (FarmHash64)**\n \n   >>> layer = tf.keras.layers.Hashing(num_bins=3)\n\n@@ -55,10 +55,13 @@ def check_fill_mode_and_interpolation(fill_mode, interpolation):\n @keras_export('keras.layers.Resizing',\n               'keras.layers.experimental.preprocessing.Resizing')\n class Resizing(base_layer.Layer):\n-  \"\"\"Image resizing layer.\n+  \"\"\"A preprocessing layer which resizes images.\n \n-  Resize the batched image input to target height and width. The input should\n-  be a 4D (batched) or 3D (unbatched) tensor in `\"channels_last\"` format.\n+  This layer resizes an image input to a target height and width. The input\n+  should be a 4D (batched) or 3D (unbatched) tensor in `\"channels_last\"` format.\n+\n+  For an overview and full list of preprocessing layers, see the preprocessing\n+  [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).\n \n   Args:\n     height: Integer, the height of the output shape.\n@@ -121,7 +124,13 @@ class Resizing(base_layer.Layer):\n @keras_export('keras.layers.CenterCrop',\n               'keras.layers.experimental.preprocessing.CenterCrop')\n class CenterCrop(base_layer.Layer):\n-  \"\"\"Crop the central portion of the images to target height and width.\n+  \"\"\"A preprocessing layer which crops images.\n+\n+  This layers crops the central portion of the images to a target height and\n+  width.\n+\n+  For an overview and full list of preprocessing layers, see the preprocessing\n+  [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).\n \n   Input shape:\n     3D (unbatched) or 4D (batched) tensor with shape:\n@@ -194,7 +203,7 @@ class CenterCrop(base_layer.Layer):\n @keras_export('keras.layers.RandomCrop',\n               'keras.layers.experimental.preprocessing.RandomCrop')\n class RandomCrop(base_layer.Layer):\n-  \"\"\"Randomly crop the images to target height and width.\n+  \"\"\"A preprocessing layer which randomly crops images during training.\n \n   This layer will crop all the images in the same batch to the same cropping\n   location.\n@@ -203,6 +212,9 @@ class RandomCrop(base_layer.Layer):\n   center cropped. If you need to apply random cropping at inference time,\n   set `training` to True when calling the layer.\n \n+  For an overview and full list of preprocessing layers, see the preprocessing\n+  [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).\n+\n   Input shape:\n     3D (unbatched) or 4D (batched) tensor with shape:\n     `(..., height, width, channels)`, in `\"channels_last\"` format.\n@@ -313,7 +325,10 @@ class RandomCrop(base_layer.Layer):\n @keras_export('keras.layers.Rescaling',\n               'keras.layers.experimental.preprocessing.Rescaling')\n class Rescaling(base_layer.Layer):\n-  \"\"\"Multiply inputs by `scale` and adds `offset`.\n+  \"\"\"A preprocessing layer which rescales input values to a new range.\n+\n+  This layer rescales every value of an input (often an image) by multiplying by\n+  `scale` and adding `offset`.\n \n   For instance:\n \n@@ -325,6 +340,9 @@ class Rescaling(base_layer.Layer):\n \n   The rescaling is applied both during training and inference.\n \n+  For an overview and full list of preprocessing layers, see the preprocessing\n+  [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).\n+\n   Input shape:\n     Arbitrary.\n \n@@ -368,11 +386,14 @@ HORIZONTAL_AND_VERTICAL = 'horizontal_and_vertical'\n @keras_export('keras.layers.RandomFlip',\n               'keras.layers.experimental.preprocessing.RandomFlip')\n class RandomFlip(base_layer.Layer):\n-  \"\"\"Randomly flip each image horizontally and vertically.\n+  \"\"\"A preprocessing layer which randomly flips images during training.\n \n-  This layer will flip the images based on the `mode` attribute.\n-  During inference time, the output will be identical to input. Call the layer\n-  with `training=True` to flip the input.\n+  This layer will flip the images horizontally and or vertically based on the\n+  `mode` attribute. During inference time, the output will be identical to\n+  input. Call the layer with `training=True` to flip the input.\n+\n+  For an overview and full list of preprocessing layers, see the preprocessing\n+  [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).\n \n   Input shape:\n     3D (unbatched) or 4D (batched) tensor with shape:\n@@ -457,7 +478,13 @@ class RandomFlip(base_layer.Layer):\n @keras_export('keras.layers.RandomTranslation',\n               'keras.layers.experimental.preprocessing.RandomTranslation')\n class RandomTranslation(base_layer.Layer):\n-  \"\"\"Randomly translate each image during training.\n+  \"\"\"A preprocessing layer which randomly translates images during training.\n+\n+  This layer will apply random translations to each image during training,\n+  filling empty space according to `fill_mode`.\n+\n+  For an overview and full list of preprocessing layers, see the preprocessing\n+  [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).\n \n   Args:\n     height_factor: a float represented as fraction of value, or a tuple of size\n@@ -778,12 +805,18 @@ def get_rotation_matrix(angles, image_height, image_width, name=None):\n @keras_export('keras.layers.RandomRotation',\n               'keras.layers.experimental.preprocessing.RandomRotation')\n class RandomRotation(base_layer.Layer):\n-  \"\"\"Randomly rotate each image.\n+  \"\"\"A preprocessing layer which randomly rotates images during training.\n+\n+  This layer will apply random rotations to each image, filling empty space\n+  according to `fill_mode`.\n \n   By default, random rotations are only applied during training.\n   At inference time, the layer does nothing. If you need to apply random\n   rotations at inference time, set `training` to True when calling the layer.\n \n+  For an overview and full list of preprocessing layers, see the preprocessing\n+  [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).\n+\n   Input shape:\n     3D (unbatched) or 4D (batched) tensor with shape:\n     `(..., height, width, channels)`, in `\"channels_last\"` format\n@@ -899,7 +932,13 @@ class RandomRotation(base_layer.Layer):\n @keras_export('keras.layers.RandomZoom',\n               'keras.layers.experimental.preprocessing.RandomZoom')\n class RandomZoom(base_layer.Layer):\n-  \"\"\"Randomly zoom each image during training.\n+  \"\"\"A preprocessing layer which randomly zooms images during training.\n+\n+  This layer will randomly zoom in or out on each axis of an image\n+  independently, filling empty space according to `fill_mode`.\n+\n+  For an overview and full list of preprocessing layers, see the preprocessing\n+  [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).\n \n   Args:\n     height_factor: a float represented as fraction of value, or a tuple of size\n@@ -1100,15 +1139,19 @@ def get_zoom_matrix(zooms, image_height, image_width, name=None):\n @keras_export('keras.layers.RandomContrast',\n               'keras.layers.experimental.preprocessing.RandomContrast')\n class RandomContrast(base_layer.Layer):\n-  \"\"\"Adjust the contrast of an image or images by a random factor.\n+  \"\"\"A preprocessing layer which randomly adjusts contrast during training.\n \n-  Contrast is adjusted independently for each channel of each image during\n-  training.\n+  This layer will randomly adjust the contrast of an image or images by a random\n+  factor. Contrast is adjusted independently for each channel of each image\n+  during training.\n \n   For each channel, this layer computes the mean of the image pixels in the\n   channel and then adjusts each component `x` of each pixel to\n   `(x - mean) * contrast_factor + mean`.\n \n+  For an overview and full list of preprocessing layers, see the preprocessing\n+  [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).\n+\n   Input shape:\n     3D (unbatched) or 4D (batched) tensor with shape:\n     `(..., height, width, channels)`, in `\"channels_last\"` format.\n@@ -1175,14 +1218,17 @@ class RandomContrast(base_layer.Layer):\n @keras_export('keras.layers.RandomHeight',\n               'keras.layers.experimental.preprocessing.RandomHeight')\n class RandomHeight(base_layer.Layer):\n-  \"\"\"Randomly vary the height of a batch of images during training.\n+  \"\"\"A preprocessing layer which randomly varies image height during training.\n \n-  Adjusts the height of a batch of images by a random factor. The input\n-  should be a 3D (unbatched) or 4D (batched) tensor in the `\"channels_last\"`\n-  image data format.\n+  This layer adjusts the height of a batch of images by a random factor.\n+  The input should be a 3D (unbatched) or 4D (batched) tensor in the\n+  `\"channels_last\"` image data format.\n \n   By default, this layer is inactive during inference.\n \n+  For an overview and full list of preprocessing layers, see the preprocessing\n+  [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).\n+\n   Args:\n     factor: A positive float (fraction of original height), or a tuple of size 2\n       representing lower and upper bound for resizing vertically. When\n@@ -1275,16 +1321,19 @@ class RandomHeight(base_layer.Layer):\n @keras_export('keras.layers.RandomWidth',\n               'keras.layers.experimental.preprocessing.RandomWidth')\n class RandomWidth(base_layer.Layer):\n-  \"\"\"Randomly vary the width of a batch of images during training.\n+  \"\"\"A preprocessing layer which randomly varies image width during training.\n \n-  Adjusts the width of a batch of images by a random factor. The input\n-  should be a 3D (unbatched) or 4D (batched) tensor in the `\"channels_last\"`\n-  image data format.\n+  This layer will randomly adjusts the width of a batch of images of a\n+  batch of images by a random factor. The input should be a 3D (unbatched) or\n+  4D (batched) tensor in the `\"channels_last\"` image data format.\n \n   By default, this layer is inactive during inference.\n \n+  For an overview and full list of preprocessing layers, see the preprocessing\n+  [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).\n+\n   Args:\n-    factor: A positive float (fraction of original height), or a tuple of size 2\n+    factor: A positive float (fraction of original width), or a tuple of size 2\n       representing lower and upper bound for resizing vertically. When\n       represented as a single float, this value is used for both the upper and\n       lower bound. For instance, `factor=(0.2, 0.3)` results in an output with\n@@ -1303,7 +1352,7 @@ class RandomWidth(base_layer.Layer):\n \n   Output shape:\n     3D (unbatched) or 4D (batched) tensor with shape:\n-    `(..., random_height, width, channels)`.\n+    `(..., height, random_width, channels)`.\n   \"\"\"\n \n   def __init__(self,\n\n@@ -29,7 +29,7 @@ from tensorflow.python.util.tf_export import keras_export\n     \"keras.layers.experimental.preprocessing.IntegerLookup\",\n     v1=[])\n class IntegerLookup(index_lookup.IndexLookup):\n-  \"\"\"Reindex integer inputs to be in a contiguous range, via a dict lookup.\n+  \"\"\"A preprocessing layer which maps integer features to contiguous ranges.\n \n   This layer maps a set of arbitrary integer input tokens into indexed\n   integer output via a table-based vocabulary lookup. The layer's output indices\n@@ -60,6 +60,9 @@ class IntegerLookup(index_lookup.IndexLookup):\n   `\"multi_hot\"`, `\"count\"`, or `\"tf_idf\"` the vocabulary will begin with OOV\n   indices and instances of the mask token will be dropped.\n \n+  For an overview and full list of preprocessing layers, see the preprocessing\n+  [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).\n+\n   Args:\n     max_tokens: Maximum size of the vocabulary for this layer. This should only\n       be specified when adapting the vocabulary or when setting\n\n@@ -28,15 +28,19 @@ from tensorflow.python.util.tf_export import keras_export\n @keras_export('keras.layers.Normalization',\n               'keras.layers.experimental.preprocessing.Normalization')\n class Normalization(base_preprocessing_layer.PreprocessingLayer):\n-  \"\"\"Feature-wise normalization of the data.\n+  \"\"\"A preprocessing layer which normalizes continuous features.\n \n-  This layer will coerce its inputs into a distribution centered around\n+  This layer will shift and scale inputs into a distribution centered around\n   0 with standard deviation 1. It accomplishes this by precomputing the mean and\n   variance of the data, and calling `(input - mean) / sqrt(var)` at runtime.\n \n-  What happens in `adapt()`: Compute mean and variance of the data and store\n-  them as the layer's weights. `adapt()` should be called before `fit()`,\n-  `evaluate()`, or `predict()`.\n+  The mean and variance values for the layer must be either supplied on\n+  construction or learned via `adapt()`. `adapt()` will compute the mean and\n+  variance of the data and store them as the layer's weights. `adapt()` should\n+  be called before `fit()`, `evaluate()`, or `predict()`.\n+\n+  For an overview and full list of preprocessing layers, see the preprocessing\n+  [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).\n \n   Args:\n       axis: Integer, tuple of integers, or None. The axis or axes that should\n\n@@ -28,9 +28,9 @@ from tensorflow.python.util.tf_export import keras_export\n     \"keras.layers.experimental.preprocessing.StringLookup\",\n     v1=[])\n class StringLookup(index_lookup.IndexLookup):\n-  \"\"\"Maps strings from a vocabulary to integer indices.\n+  \"\"\"A preprocessing layer which maps string features to integer indices.\n \n-  This layer translates a set of arbitrary strings into an integer output via a\n+  This layer translates a set of arbitrary strings into  integer output via a\n   table-based vocabulary lookup.\n \n   The vocabulary for the layer must be either supplied on construction or\n@@ -56,6 +56,9 @@ class StringLookup(index_lookup.IndexLookup):\n   `\"multi_hot\"`, `\"count\"`, or `\"tf_idf\"` the vocabulary will begin with OOV\n   indices and instances of the mask token will be dropped.\n \n+  For an overview and full list of preprocessing layers, see the preprocessing\n+  [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).\n+\n   Args:\n     max_tokens: Maximum size of the vocabulary for this layer. This should only\n       be specified when adapting the vocabulary or when setting\n\n@@ -65,11 +65,11 @@ _ACCUMULATOR_NUM_DOCUMENTS = \"num_documents\"\n     \"keras.layers.experimental.preprocessing.TextVectorization\",\n     v1=[])\n class TextVectorization(base_preprocessing_layer.PreprocessingLayer):\n-  \"\"\"Text vectorization layer.\n+  \"\"\"A preprocessing layer which maps text features to integer sequences.\n \n-  This layer has basic options for managing text in a Keras model. It\n-  transforms a batch of strings (one example = one string) into either a list of\n-  token indices (one example = 1D tensor of integer token indices) or a dense\n+  This layer has basic options for managing text in a Keras model. It transforms\n+  a batch of strings (one example = one string) into either a list of token\n+  indices (one example = 1D tensor of integer token indices) or a dense\n   representation (one example = 1D tensor of float values representing data\n   about the example's tokens).\n \n@@ -109,6 +109,9 @@ class TextVectorization(base_preprocessing_layer.PreprocessingLayer):\n      \"split\"], [\"another\", \"string\", \"to\", \"split\"]]`. This makes the callable\n      site natively compatible with `tf.strings.split()`.\n \n+  For an overview and full list of preprocessing layers, see the preprocessing\n+  [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).\n+\n   Args:\n     max_tokens: Maximum size of the vocabulary for this layer. This should only\n       be specified when adapting a vocabulary or when setting\n@@ -231,7 +234,6 @@ class TextVectorization(base_preprocessing_layer.PreprocessingLayer):\n   ['', '[UNK]', 'earth', 'wind', 'and', 'fire']\n \n   \"\"\"\n-  # TODO(momernick): Add an examples section to the docstring.\n \n   def __init__(self,\n                max_tokens=None,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f1e1ba94f3fcb6ace6cf9ca6362e7ef12bdd753a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 5455 | Contributors (this commit): 7 | Commits (past 90d): 29 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -192,7 +192,7 @@ class IndexLookup(base_preprocessing_layer.PreprocessingLayer):\n                        f\"Received: output_mode={output_mode}\")\n \n     if sparse and output_mode == INT:\n-      raise ValueError(f\"`sparse` must not be true if `output_mode` is \"\n+      raise ValueError(f\"`sparse` may only be true if `output_mode` is \"\n                        f\"`'one_hot'`, `'multi_hot'`, `'count'` or `'tf_idf'`. \"\n                        f\"Received: sparse={sparse} and \"\n                        f\"output_mode={output_mode}\")\n\n@@ -1588,7 +1588,7 @@ class TextVectorizationErrorTest(keras_parameterized.TestCase,\n           ragged=True, output_mode=text_vectorization.MULTI_HOT)\n \n   def test_sparse_true_fails_if_output_mode_is_int(self):\n-    with self.assertRaisesRegex(ValueError, \"`sparse` must not be true if\"):\n+    with self.assertRaisesRegex(ValueError, \"`sparse` may only be true if\"):\n       _ = text_vectorization.TextVectorization(\n           sparse=True, output_mode=text_vectorization.INT)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2286cc56fb8badd62f0da560849af89bf9a786af", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 56 | Lines Deleted: 16 | Files Changed: 2 | Hunks: 14 | Methods Changed: 11 | Complexity Δ (Sum/Max): 7/7 | Churn Δ: 72 | Churn Cumulative: 18031 | Contributors (this commit): 133 | Commits (past 90d): 47 | Contributors (cumulative): 144 | DMM Complexity: 0.125\n\nDIFF:\n@@ -2510,7 +2510,9 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     weights += (self._trainable_weights + self._non_trainable_weights)\n     return weights\n \n-  def summary(self, line_length=None, positions=None, print_fn=None):\n+  def summary(self, line_length=None,\n+              positions=None, print_fn=None,\n+              expand_nested=False):\n     \"\"\"Prints a string summary of the network.\n \n     Args:\n@@ -2524,6 +2526,8 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n             It will be called on each line of the summary.\n             You can set it to a custom function\n             in order to capture the string summary.\n+        expand_nested: Whether to expand the nested models.\n+            If not provided, defaults to `False`.\n \n     Raises:\n         ValueError: if `summary()` is called before the model is built.\n@@ -2537,7 +2541,8 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     layer_utils.print_summary(self,\n                               line_length=line_length,\n                               positions=positions,\n-                              print_fn=print_fn)\n+                              print_fn=print_fn,\n+                              expand_nested=expand_nested)\n \n   @property\n   def layers(self):\n\n@@ -104,7 +104,8 @@ def count_params(weights):\n   return int(sum(np.prod(p) for p in standardized_weight_shapes))\n \n \n-def print_summary(model, line_length=None, positions=None, print_fn=None):\n+def print_summary(model, line_length=None, positions=None,\n+                  print_fn=None, expand_nested=False):\n   \"\"\"Prints a summary of a model.\n \n   Args:\n@@ -119,6 +120,8 @@ def print_summary(model, line_length=None, positions=None, print_fn=None):\n           You can set it to a custom function\n           in order to capture the string summary.\n           It defaults to `print` (prints to stdout).\n+      expand_nested: Whether to expand the nested models.\n+          If not provided, defaults to `False`.\n   \"\"\"\n   if print_fn is None:\n     print_fn = print\n@@ -174,7 +177,9 @@ def print_summary(model, line_length=None, positions=None, print_fn=None):\n     for v in model._nodes_by_depth.values():\n       relevant_nodes += v\n \n-  def print_row(fields, positions):\n+  def print_row(fields,\n+                positions,\n+                nested_level=0):\n     left_to_print = [str(x) for x in fields]\n     while any(left_to_print):\n       line = ''\n@@ -206,7 +211,11 @@ def print_summary(model, line_length=None, positions=None, print_fn=None):\n         left_to_print[col] = left_to_print[col][cutoff:]\n \n         # Pad out to the next position\n+        if nested_level:\n+          line += ' ' * (positions[col] - len(line) - (2 * nested_level) - 1)\n+        else:\n           line += ' ' * (positions[col] - len(line))\n+      line += '|' * nested_level\n       print_fn(line)\n \n   print_fn('Model: \"{}\"'.format(model.name))\n@@ -214,7 +223,8 @@ def print_summary(model, line_length=None, positions=None, print_fn=None):\n   print_row(to_display, positions)\n   print_fn('=' * line_length)\n \n-  def print_layer_summary(layer):\n+  def print_layer_summary(layer,\n+                          nested_level=0):\n     \"\"\"Prints a summary for a single layer.\n \n     Args:\n@@ -235,9 +245,10 @@ def print_summary(model, line_length=None, positions=None, print_fn=None):\n     else:\n       params = layer.count_params()\n     fields = [name + ' (' + cls_name + ')', output_shape, params]\n-    print_row(fields, positions)\n+    print_row(fields, positions, nested_level)\n \n-  def print_layer_summary_with_connections(layer):\n+  def print_layer_summary_with_connections(layer,\n+                                           nested_level=0):\n     \"\"\"Prints a summary for a single layer (including topological connections).\n \n     Args:\n@@ -263,18 +274,42 @@ def print_summary(model, line_length=None, positions=None, print_fn=None):\n         name + ' (' + cls_name + ')', output_shape,\n         layer.count_params(), connections\n     ]\n-    print_row(fields, positions)\n+    print_row(fields, positions, nested_level)\n+\n+  def print_layer(layer,\n+                  nested_level=0,\n+                  is_nested_last=False):\n+    if sequential_like:\n+      print_layer_summary(layer, nested_level)\n+    else:\n+      print_layer_summary_with_connections(layer, nested_level)\n+\n+    if expand_nested and isinstance(layer, type(model)) and layer.layers:\n+      print_fn('|' * (nested_level + 1) +\n+               '¯' * (line_length - 2 * nested_level - 2) +\n+               '|' * (nested_level + 1))\n+\n+      nested_layer = layer.layers\n+      is_nested_last = False\n+      for i in range(len(nested_layer)):\n+        if i == len(nested_layer)-1:\n+          is_nested_last = True\n+        print_fn('|' * (nested_level + 1), end=\" \")\n+        print_layer(nested_layer[i], nested_level + 1, is_nested_last)\n+\n+      print_fn('|' * nested_level +\n+               '¯' * (line_length - 2 * nested_level) +\n+               '|' * nested_level)\n+\n+    if not is_nested_last:\n+      print_fn('|' * nested_level +\n+               '_' * (line_length - 2 * nested_level) +\n+               '|' * nested_level)\n \n   layers = model.layers\n-  for i in range(len(layers)):\n-    if sequential_like:\n-      print_layer_summary(layers[i])\n-    else:\n-      print_layer_summary_with_connections(layers[i])\n-    if i == len(layers) - 1:\n+  for layer in layers:\n+    print_layer(layer)\n   print_fn('=' * line_length)\n-    else:\n-      print_fn('_' * line_length)\n \n   if hasattr(model, '_collected_trainable_weights'):\n     trainable_count = count_params(model._collected_trainable_weights)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
