{"custom_id": "keras#6939d91768543d953412a321983915eaf013ebd9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 15 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 6 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 22 | Churn Cumulative: 516 | Contributors (this commit): 14 | Commits (past 90d): 2 | Contributors (cumulative): 14 | DMM Complexity: None\n\nDIFF:\n@@ -35,8 +35,8 @@ from six.moves import range\n \n class CharacterTable(object):\n     \"\"\"Given a set of characters:\n-    + Encode them to a one hot integer representation\n-    + Decode the one hot integer representation to their character output\n+    + Encode them to a one-hot integer representation\n+    + Decode the one-hot or integer representation to their character output\n     + Decode a vector of probabilities to their character output\n     \"\"\"\n     def __init__(self, chars):\n@@ -50,10 +50,11 @@ class CharacterTable(object):\n         self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n \n     def encode(self, C, num_rows):\n-        \"\"\"One hot encode given string C.\n+        \"\"\"One-hot encode given string C.\n \n         # Arguments\n-            num_rows: Number of rows in the returned one hot encoding. This is\n+            C: string, to be encoded.\n+            num_rows: Number of rows in the returned one-hot encoding. This is\n                 used to keep the # of rows for each data the same.\n         \"\"\"\n         x = np.zeros((num_rows, len(self.chars)))\n@@ -62,6 +63,14 @@ class CharacterTable(object):\n         return x\n \n     def decode(self, x, calc_argmax=True):\n+        \"\"\"Decode the given vector or 2D array to their character output.\n+\n+        # Arguments\n+            x: A vector or a 2D array of probabilities or one-hot representations;\n+                or a vector of character indices (used with `calc_argmax=False`).\n+            calc_argmax: Whether to find the character index with maximum\n+                probability, defaults to `True`.\n+        \"\"\"\n         if calc_argmax:\n             x = x.argmax(axis=-1)\n         return ''.join(self.indices_char[x] for x in x)\n@@ -153,7 +162,7 @@ model = Sequential()\n # Note: In a situation where your input sequences have a variable length,\n # use input_shape=(None, num_feature).\n model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n-# As the decoder RNN's input, repeatedly provide with the last hidden state of\n+# As the decoder RNN's input, repeatedly provide with the last output of\n # RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n # length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n model.add(layers.RepeatVector(DIGITS + 1))\n@@ -167,8 +176,7 @@ for _ in range(LAYERS):\n \n # Apply a dense layer to the every temporal slice of an input. For each of step\n # of the output sequence, decide which character should be chosen.\n-model.add(layers.TimeDistributed(layers.Dense(len(chars))))\n-model.add(layers.Activation('softmax'))\n+model.add(layers.TimeDistributed(layers.Dense(len(chars), activation='softmax')))\n model.compile(loss='categorical_crossentropy',\n               optimizer='adam',\n               metrics=['accuracy'])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6e004306dfe70ab499afc04c31808fdac594ae08", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 3212 | Contributors (this commit): 79 | Commits (past 90d): 9 | Contributors (cumulative): 79 | DMM Complexity: 0.0\n\nDIFF:\n@@ -117,9 +117,10 @@ class CallbackList(object):\n         delta_t_median = np.median(self._delta_ts_batch_end)\n         if (self._delta_t_batch > 0. and\n            (delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1)):\n-            warnings.warn('Method on_batch_end() is slow compared '\n-                          'to the batch update (%f). Check your callbacks.'\n-                          % delta_t_median)\n+            warnings.warn('In your callbacks, method `on_batch_end()` '\n+                          'is slow compared to a model step '\n+                          '(%f vs %f). Check your callbacks.'\n+                          % (delta_t_median, self._delta_t_batch))\n \n     def on_train_begin(self, logs=None):\n         \"\"\"Called at the beginning of training.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#33902e53eb7312fbf2f17b7b700bdb7683441a24", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 39 | Lines Deleted: 39 | Files Changed: 2 | Hunks: 33 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 78 | Churn Cumulative: 9090 | Contributors (this commit): 93 | Commits (past 90d): 9 | Contributors (cumulative): 96 | DMM Complexity: None\n\nDIFF:\n@@ -971,9 +971,9 @@ class Model(Network):\n                 sample_weight=val_sample_weight,\n                 batch_size=batch_size)\n             if self._uses_dynamic_learning_phase():\n-                val_ins = val_x + val_y + val_sample_weights + [0.]\n+                val_inputs = val_x + val_y + val_sample_weights + [0.]\n             else:\n-                val_ins = val_x + val_y + val_sample_weights\n+                val_inputs = val_x + val_y + val_sample_weights\n \n         elif validation_split and 0. < validation_split < 1.:\n             if any(K.is_tensor(t) for t in x):\n@@ -993,45 +993,45 @@ class Model(Network):\n                 slice_arrays(sample_weights, 0, split_at),\n                 slice_arrays(sample_weights, split_at))\n             if self._uses_dynamic_learning_phase():\n-                val_ins = val_x + val_y + val_sample_weights + [0.]\n+                val_inputs = val_x + val_y + val_sample_weights + [0.]\n             else:\n-                val_ins = val_x + val_y + val_sample_weights\n+                val_inputs = val_x + val_y + val_sample_weights\n \n         elif validation_steps:\n             do_validation = True\n             if self._uses_dynamic_learning_phase():\n-                val_ins = [0.]\n+                val_inputs = [0.]\n \n         # Prepare input arrays and training function.\n         if self._uses_dynamic_learning_phase():\n-            ins = x + y + sample_weights + [1.]\n+            fit_inputs = x + y + sample_weights + [1.]\n         else:\n-            ins = x + y + sample_weights\n+            fit_inputs = x + y + sample_weights\n         self._make_train_function()\n-        f = self.train_function\n+        fit_function = self.train_function\n \n         # Prepare display labels.\n         out_labels = self.metrics_names\n \n         if do_validation:\n             self._make_test_function()\n-            val_f = self.test_function\n+            val_function = self.test_function\n             callback_metrics = copy.copy(out_labels) + [\n                 'val_' + n for n in out_labels]\n         else:\n             callback_metrics = copy.copy(out_labels)\n-            val_f = None\n-            val_ins = []\n+            val_function = None\n+            val_inputs = []\n \n         # Delegate logic to `fit_loop`.\n-        return training_arrays.fit_loop(self, f, ins,\n+        return training_arrays.fit_loop(self, fit_function, fit_inputs,\n                                         out_labels=out_labels,\n                                         batch_size=batch_size,\n                                         epochs=epochs,\n                                         verbose=verbose,\n                                         callbacks=callbacks,\n-                                        val_f=val_f,\n-                                        val_ins=val_ins,\n+                                        val_function=val_function,\n+                                        val_inputs=val_inputs,\n                                         shuffle=shuffle,\n                                         callback_metrics=callback_metrics,\n                                         initial_epoch=initial_epoch,\n\n@@ -18,40 +18,40 @@ from ..utils.generic_utils import to_list\n from ..utils.generic_utils import unpack_singleton\n \n \n-def fit_loop(model, f, ins,\n+def fit_loop(model, fit_function, fit_inputs,\n              out_labels=None,\n              batch_size=None,\n              epochs=100,\n              verbose=1,\n              callbacks=None,\n-             val_f=None,\n-             val_ins=None,\n+             val_function=None,\n+             val_inputs=None,\n              shuffle=True,\n              callback_metrics=None,\n              initial_epoch=0,\n              steps_per_epoch=None,\n              validation_steps=None):\n-    \"\"\"Abstract fit function for `f(ins)`.\n+    \"\"\"Abstract fit function for `fit_function(fit_inputs)`.\n \n-    Assumes that f returns a list, labeled by out_labels.\n+    Assumes that fit_function returns a list, labeled by out_labels.\n \n     # Arguments\n         model: Keras model instance.\n-        f: Keras function returning a list of tensors\n-        ins: List of tensors to be fed to `f`\n+        fit_function: Keras function returning a list of tensors\n+        fit_inputs: List of tensors to be fed to `fit_function`\n         out_labels: List of strings, display names of\n-            the outputs of `f`\n+            the outputs of `fit_function`\n         batch_size: Integer batch size or None if unknown.\n         epochs: Number of times to iterate over the data\n         verbose: Verbosity mode, 0, 1 or 2\n         callbacks: List of callbacks to be called during training\n-        val_f: Keras function to call for validation\n-        val_ins: List of tensors to be fed to `val_f`\n+        val_function: Keras function to call for validation\n+        val_inputs: List of tensors to be fed to `val_function`\n         shuffle: Whether to shuffle the data at the beginning of each epoch\n         callback_metrics: List of strings, the display names of the metrics\n             passed to the callbacks. They should be the\n             concatenation of list the display names of the outputs of\n-             `f` and the list of display names of the outputs of `f_val`.\n+             `fit_function` and the list of display names of the outputs of `fit_inputs`.\n         initial_epoch: Epoch at which to start training\n             (useful for resuming a previous training run)\n         steps_per_epoch: Total number of steps (batches of samples)\n@@ -65,12 +65,12 @@ def fit_loop(model, f, ins,\n         `History` object.\n     \"\"\"\n     do_validation = False\n-    if val_f and val_ins:\n+    if val_function and val_inputs:\n         do_validation = True\n-        if (verbose and ins and\n-           hasattr(ins[0], 'shape') and hasattr(val_ins[0], 'shape')):\n+        if (verbose and fit_inputs and\n+           hasattr(fit_inputs[0], 'shape') and hasattr(val_inputs[0], 'shape')):\n             print('Train on %d samples, validate on %d samples' %\n-                  (ins[0].shape[0], val_ins[0].shape[0]))\n+                  (fit_inputs[0].shape[0], val_inputs[0].shape[0]))\n     if validation_steps:\n         do_validation = True\n         if steps_per_epoch is None:\n@@ -84,7 +84,7 @@ def fit_loop(model, f, ins,\n                              'to perform validation '\n                              'when doing step-wise training.')\n \n-    num_train_samples = check_num_samples(ins,\n+    num_train_samples = check_num_samples(fit_inputs,\n                                           batch_size=batch_size,\n                                           steps=steps_per_epoch,\n                                           steps_name='steps_per_epoch')\n@@ -127,7 +127,7 @@ def fit_loop(model, f, ins,\n     callbacks.on_train_begin()\n     callback_model.stop_training = False\n     for cbk in callbacks:\n-        cbk.validation_data = val_ins\n+        cbk.validation_data = val_inputs\n \n     # To prevent a slowdown,\n     # we find beforehand the arrays that need conversion.\n@@ -136,7 +136,7 @@ def fit_loop(model, f, ins,\n             model._feed_sample_weights)\n     indices_for_conversion_to_dense = []\n     for i in range(len(feed)):\n-        if issparse(ins[i]) and not K.is_sparse(feed[i]):\n+        if issparse(fit_inputs[i]) and not K.is_sparse(feed[i]):\n             indices_for_conversion_to_dense.append(i)\n \n     for epoch in range(initial_epoch, epochs):\n@@ -151,7 +151,7 @@ def fit_loop(model, f, ins,\n                 batch_logs['batch'] = step_index\n                 batch_logs['size'] = 1\n                 callbacks.on_batch_begin(step_index, batch_logs)\n-                outs = f(ins)\n+                outs = fit_function(fit_inputs)\n \n                 outs = to_list(outs)\n                 for l, o in zip(out_labels, outs):\n@@ -162,7 +162,7 @@ def fit_loop(model, f, ins,\n                     break\n \n             if do_validation:\n-                val_outs = test_loop(model, val_f, val_ins,\n+                val_outs = test_loop(model, val_function, val_inputs,\n                                      steps=validation_steps,\n                                      verbose=0)\n                 val_outs = to_list(val_outs)\n@@ -179,12 +179,12 @@ def fit_loop(model, f, ins,\n             for batch_index, (batch_start, batch_end) in enumerate(batches):\n                 batch_ids = index_array[batch_start:batch_end]\n                 try:\n-                    if isinstance(ins[-1], float):\n+                    if isinstance(fit_inputs[-1], float):\n                         # Do not slice the training phase flag.\n                         ins_batch = slice_arrays(\n-                            ins[:-1], batch_ids) + [ins[-1]]\n+                            fit_inputs[:-1], batch_ids) + [fit_inputs[-1]]\n                     else:\n-                        ins_batch = slice_arrays(ins, batch_ids)\n+                        ins_batch = slice_arrays(fit_inputs, batch_ids)\n                 except TypeError:\n                     raise TypeError('TypeError while preparing batch. '\n                                     'If using HDF5 input data, '\n@@ -196,7 +196,7 @@ def fit_loop(model, f, ins,\n                 for i in indices_for_conversion_to_dense:\n                     ins_batch[i] = ins_batch[i].toarray()\n \n-                outs = f(ins_batch)\n+                outs = fit_function(ins_batch)\n                 outs = to_list(outs)\n                 for l, o in zip(out_labels, outs):\n                     batch_logs[l] = o\n@@ -207,7 +207,7 @@ def fit_loop(model, f, ins,\n \n                 if batch_index == len(batches) - 1:  # Last batch.\n                     if do_validation:\n-                        val_outs = test_loop(model, val_f, val_ins,\n+                        val_outs = test_loop(model, val_function, val_inputs,\n                                              batch_size=batch_size,\n                                              verbose=0)\n                         val_outs = to_list(val_outs)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f78b985087883a221aaae2c948eb0949cbabe3f7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 4 | Churn Cumulative: 343 | Contributors (this commit): 18 | Commits (past 90d): 4 | Contributors (cumulative): 18 | DMM Complexity: 0.0\n\nDIFF:\n@@ -25,9 +25,7 @@ def softmax(x, axis=-1):\n         ValueError: In case `dim(x) == 1`.\n     \"\"\"\n     ndim = K.ndim(x)\n-    if ndim == 1:\n-        raise ValueError('Cannot apply softmax to a tensor that is 1D')\n-    elif ndim == 2:\n+    if ndim == 2:\n         return K.softmax(x)\n     elif ndim > 2:\n         e = K.exp(x - K.max(x, axis=axis, keepdims=True))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#993a701498a4ac288b12dceb105f10b7fc60c14f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 503 | Contributors (this commit): 4 | Commits (past 90d): 4 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -51,7 +51,8 @@ def fit_loop(model, fit_function, fit_inputs,\n         callback_metrics: List of strings, the display names of the metrics\n             passed to the callbacks. They should be the\n             concatenation of list the display names of the outputs of\n-             `fit_function` and the list of display names of the outputs of `fit_inputs`.\n+             `fit_function` and the list of display names\n+             of the outputs of `fit_inputs`.\n         initial_epoch: Epoch at which to start training\n             (useful for resuming a previous training run)\n         steps_per_epoch: Total number of steps (batches of samples)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7875e856f8dc09372a83d8c5dc0af74a50d17d30", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 16 | Files Changed: 3 | Hunks: 6 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 32 | Churn Cumulative: 12681 | Contributors (this commit): 65 | Commits (past 90d): 13 | Contributors (cumulative): 79 | DMM Complexity: None\n\nDIFF:\n@@ -509,8 +509,8 @@ class ConvLSTM2DCell(Layer):\n         unit_forget_bias: Boolean.\n             If True, add 1 to the bias of the forget gate at initialization.\n             Use in combination with `bias_initializer=\"zeros\"`.\n-            This is recommended in [Jozefowicz et al.]\n-            (http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).\n+            This is recommended in [Jozefowicz et al. (2015)](\n+            http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).\n         kernel_regularizer: Regularizer function applied to\n             the `kernel` weights matrix\n             (see [regularizer](../regularizers.md)).\n@@ -835,8 +835,8 @@ class ConvLSTM2D(ConvRNN2D):\n         unit_forget_bias: Boolean.\n             If True, add 1 to the bias of the forget gate at initialization.\n             Use in combination with `bias_initializer=\"zeros\"`.\n-            This is recommended in [Jozefowicz et al.]\n-            (http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).\n+            This is recommended in [Jozefowicz et al. (2015)](\n+            http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).\n         kernel_regularizer: Regularizer function applied to\n             the `kernel` weights matrix\n             (see [regularizer](../regularizers.md)).\n\n@@ -338,8 +338,8 @@ class CuDNNLSTM(_CuDNNRNN):\n         unit_forget_bias: Boolean.\n             If True, add 1 to the bias of the forget gate at initialization.\n             Setting it to true will also force `bias_initializer=\"zeros\"`.\n-            This is recommended in [Jozefowicz et al.]\n-            (http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).\n+            This is recommended in [Jozefowicz et al. (2015)](\n+            http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).\n         recurrent_initializer: Initializer for the `recurrent_kernel`\n             weights matrix,\n             used for the linear transformation of the recurrent state.\n\n@@ -1782,8 +1782,8 @@ class LSTMCell(Layer):\n         unit_forget_bias: Boolean.\n             If True, add 1 to the bias of the forget gate at initialization.\n             Setting it to true will also force `bias_initializer=\"zeros\"`.\n-            This is recommended in [Jozefowicz et al.]\n-            (http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).\n+            This is recommended in [Jozefowicz et al. (2015)](\n+            http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).\n         kernel_regularizer: Regularizer function applied to\n             the `kernel` weights matrix\n             (see [regularizer](../regularizers.md)).\n@@ -2060,8 +2060,8 @@ class LSTM(RNN):\n         unit_forget_bias: Boolean.\n             If True, add 1 to the bias of the forget gate at initialization.\n             Setting it to true will also force `bias_initializer=\"zeros\"`.\n-            This is recommended in [Jozefowicz et al.]\n-            (http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).\n+            This is recommended in [Jozefowicz et al. (2015)](\n+            http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).\n         kernel_regularizer: Regularizer function applied to\n             the `kernel` weights matrix\n             (see [regularizer](../regularizers.md)).\n@@ -2111,12 +2111,12 @@ class LSTM(RNN):\n             Unrolling is only suitable for short sequences.\n \n     # References\n-        - [Long short-term memory]\n-          (http://www.bioinf.jku.at/publications/older/2604.pdf)\n-        - [Learning to forget: Continual prediction with LSTM]\n-          (http://www.mitpressjournals.org/doi/pdf/10.1162/089976600300015015)\n-        - [Supervised sequence labeling with recurrent neural networks]\n-          (http://www.cs.toronto.edu/~graves/preprint.pdf)\n+        - [Long short-term memory](\n+          http://www.bioinf.jku.at/publications/older/2604.pdf)\n+        - [Learning to forget: Continual prediction with LSTM](\n+          http://www.mitpressjournals.org/doi/pdf/10.1162/089976600300015015)\n+        - [Supervised sequence labeling with recurrent neural networks](\n+          http://www.cs.toronto.edu/~graves/preprint.pdf)\n         - [A Theoretically Grounded Application of Dropout in\n            Recurrent Neural Networks](https://arxiv.org/abs/1512.05287)\n     \"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d059890d0342955e968fdf97b5a90d19c9d68b4e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 9 | Files Changed: 1 | Hunks: 9 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 21 | Churn Cumulative: 119 | Contributors (this commit): 6 | Commits (past 90d): 4 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -59,7 +59,9 @@ def multi_gpu_model(model, gpus=None, cpu_merge=True, cpu_relocation=False):\n         A Keras `Model` instance which can be used just like the initial\n         `model` argument, but which distributes its workload on multiple GPUs.\n \n-    # Example 1 - Training models with weights merge on CPU\n+    # Examples\n+\n+    Example 1 - Training models with weights merge on CPU\n \n     ```python\n         import tensorflow as tf\n@@ -100,7 +102,7 @@ def multi_gpu_model(model, gpus=None, cpu_merge=True, cpu_relocation=False):\n         model.save('my_model.h5')\n     ```\n \n-    # Example 2 - Training models with weights merge on CPU using cpu_relocation\n+    Example 2 - Training models with weights merge on CPU using cpu_relocation\n \n     ```python\n          ..\n@@ -108,16 +110,16 @@ def multi_gpu_model(model, gpus=None, cpu_merge=True, cpu_relocation=False):\n          model = Xception(weights=None, ..)\n \n          try:\n-             model = multi_gpu_model(model, cpu_relocation=True)\n+             parallel_model = multi_gpu_model(model, cpu_relocation=True)\n              print(\"Training using multiple GPUs..\")\n-         except:\n+         except ValueError:\n+             parallel_model = model\n              print(\"Training using single GPU or CPU..\")\n-\n-         model.compile(..)\n+         parallel_model.compile(..)\n          ..\n     ```\n \n-    # Example 3 - Training models with weights merge on GPU (recommended for NV-link)\n+    Example 3 - Training models with weights merge on GPU (recommended for NV-link)\n \n     ```python\n          ..\n@@ -125,12 +127,13 @@ def multi_gpu_model(model, gpus=None, cpu_merge=True, cpu_relocation=False):\n          model = Xception(weights=None, ..)\n \n          try:\n-             model = multi_gpu_model(model, cpu_merge=False)\n+             parallel_model = multi_gpu_model(model, cpu_merge=False)\n              print(\"Training using multiple GPUs..\")\n          except:\n+             parallel_model = model\n              print(\"Training using single GPU or CPU..\")\n \n-         model.compile(..)\n+         parallel_model.compile(..)\n          ..\n     ```\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c7d04b70cd15dd47ae95dd2b1ccda64d293321c5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 18 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 18 | Churn Cumulative: 512 | Contributors (this commit): 17 | Commits (past 90d): 2 | Contributors (cumulative): 17 | DMM Complexity: None\n\nDIFF:\n@@ -21,7 +21,25 @@ def to_categorical(y, num_classes=None, dtype='float32'):\n     # Returns\n         A binary matrix representation of the input. The classes axis\n         is placed last.\n+\n+    # Example\n+\n+    ```python\n+    # Consider an array of 5 labels out of a set of 3 classes {0, 1, 2}:\n+    > labels\n+    array([0, 2, 1, 2, 0])\n+    # `to_categorical` converts this into a matrix with as many\n+    # columns as there are classes. The number of rows\n+    # stays the same.\n+    > to_categorical(labels)\n+    array([[ 1.,  0.,  0.],\n+           [ 0.,  0.,  1.],\n+           [ 0.,  1.,  0.],\n+           [ 0.,  0.,  1.],\n+           [ 1.,  0.,  0.]], dtype=float32)\n+    ```\n     \"\"\"\n+\n     y = np.array(y, dtype='int')\n     input_shape = y.shape\n     if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#38749e552bacf13a9fb4444ebb153255519ab871", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 678 | Contributors (this commit): 11 | Commits (past 90d): 3 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -217,10 +217,10 @@ if __name__ == '__main__':\n             aux_y = np.concatenate((label_batch, sampled_labels), axis=0)\n \n             # we don't want the discriminator to also maximize the classification\n-            # accuracy of the auxilary classifier on generated images, so we\n+            # accuracy of the auxiliary classifier on generated images, so we\n             # don't train discriminator to produce class labels for generated\n             # images (see https://openreview.net/forum?id=rJXTf9Bxg).\n-            # To preserve sum of sample weights for the auxilary classifier,\n+            # To preserve sum of sample weights for the auxiliary classifier,\n             # we assign sample weight of 2 to the real images.\n             disc_sample_weight = [np.ones(2 * len(image_batch)),\n                                   np.concatenate((np.ones(len(image_batch)) * 2,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#714ff6d7150fa7c41379024a660fe6e822742663", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 3214 | Contributors (this commit): 80 | Commits (past 90d): 9 | Contributors (cumulative): 80 | DMM Complexity: None\n\nDIFF:\n@@ -792,7 +792,7 @@ class TensorBoard(Callback):\n         if self.histogram_freq and self.merged is None:\n             for layer in self.model.layers:\n \n-                for weight in layer.weights:\n+                for weight in layer.trainable_weights:\n                     mapped_weight_name = weight.name.replace(':', '_')\n                     tf.summary.histogram(mapped_weight_name, weight)\n                     if self.write_grads:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#22f20b97386652a24bf2e8e363bfa38ca66cb209", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 3215 | Contributors (this commit): 80 | Commits (past 90d): 10 | Contributors (cumulative): 80 | DMM Complexity: None\n\nDIFF:\n@@ -13,7 +13,6 @@ import time\n import json\n import warnings\n import io\n-import sys\n \n from collections import deque\n from collections import OrderedDict\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5656e39f0fb9fea23376a297175fd4cfa58b36ef", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 6 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 13 | Churn Cumulative: 5254 | Contributors (this commit): 84 | Commits (past 90d): 21 | Contributors (cumulative): 111 | DMM Complexity: 1.0\n\nDIFF:\n@@ -790,8 +790,7 @@ class TensorBoard(Callback):\n             self.sess = K.get_session()\n         if self.histogram_freq and self.merged is None:\n             for layer in self.model.layers:\n-\n-                for weight in layer.trainable_weights:\n+                for weight in layer.weights:\n                     mapped_weight_name = weight.name.replace(':', '_')\n                     tf.summary.histogram(mapped_weight_name, weight)\n                     if self.write_grads:\n\n@@ -12,10 +12,11 @@ from keras import initializers\n from keras import callbacks\n from keras.models import Sequential, Model\n from keras.layers import Input, Dense, Dropout, add, dot, Lambda, Layer\n-from keras.layers.convolutional import Conv2D\n-from keras.layers.pooling import MaxPooling2D\n-from keras.layers.pooling import GlobalAveragePooling1D\n-from keras.layers.pooling import GlobalAveragePooling2D\n+from keras.layers import Conv2D\n+from keras.layers import MaxPooling2D\n+from keras.layers import GlobalAveragePooling1D\n+from keras.layers import GlobalAveragePooling2D\n+from keras.layers import BatchNormalization\n from keras.utils.test_utils import get_test_data\n from keras.utils.generic_utils import to_list\n from keras.utils.generic_utils import unpack_singleton\n@@ -575,6 +576,7 @@ def test_TensorBoard(tmpdir, update_freq):\n     inp = Input((input_dim,))\n     hidden = Dense(num_hidden, activation='relu')(inp)\n     hidden = Dropout(0.1)(hidden)\n+    hidden = BatchNormalization()(hidden)\n     output = Dense(num_classes, activation='softmax')(hidden)\n     model = Model(inputs=inp, outputs=output)\n     model.compile(loss='categorical_crossentropy',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c603874f98ffe86d4fdb492ba1ade3f8d99c04cd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 9 | Files Changed: 1 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 542 | Contributors (this commit): 6 | Commits (past 90d): 9 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -33,7 +33,6 @@ def fit_generator(model,\n                   shuffle=True,\n                   initial_epoch=0):\n     \"\"\"See docstring for `Model.fit_generator`.\"\"\"\n-    wait_time = 0.01  # in seconds\n     epoch = initial_epoch\n \n     do_validation = bool(validation_data)\n@@ -158,8 +157,7 @@ def fit_generator(model,\n             else:\n                 enqueuer = GeneratorEnqueuer(\n                     generator,\n-                    use_multiprocessing=use_multiprocessing,\n-                    wait_time=wait_time)\n+                    use_multiprocessing=use_multiprocessing)\n             enqueuer.start(workers=workers, max_queue_size=max_queue_size)\n             output_generator = enqueuer.get()\n         else:\n@@ -284,7 +282,6 @@ def evaluate_generator(model, generator,\n         stateful_metric_indices = []\n \n     steps_done = 0\n-    wait_time = 0.01\n     outs_per_batch = []\n     batch_sizes = []\n     is_sequence = isinstance(generator, Sequence)\n@@ -313,8 +310,7 @@ def evaluate_generator(model, generator,\n             else:\n                 enqueuer = GeneratorEnqueuer(\n                     generator,\n-                    use_multiprocessing=use_multiprocessing,\n-                    wait_time=wait_time)\n+                    use_multiprocessing=use_multiprocessing)\n             enqueuer.start(workers=workers, max_queue_size=max_queue_size)\n             output_generator = enqueuer.get()\n         else:\n@@ -390,7 +386,6 @@ def predict_generator(model, generator,\n     model._make_predict_function()\n \n     steps_done = 0\n-    wait_time = 0.01\n     all_outs = []\n     is_sequence = isinstance(generator, Sequence)\n     if not is_sequence and use_multiprocessing and workers > 1:\n@@ -418,8 +413,7 @@ def predict_generator(model, generator,\n             else:\n                 enqueuer = GeneratorEnqueuer(\n                     generator,\n-                    use_multiprocessing=use_multiprocessing,\n-                    wait_time=wait_time)\n+                    use_multiprocessing=use_multiprocessing)\n             enqueuer.start(workers=workers, max_queue_size=max_queue_size)\n             output_generator = enqueuer.get()\n         else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4fc8cf281e0d5fa248701708c03d5075f4914bcd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 30 | Lines Deleted: 20 | Files Changed: 4 | Hunks: 26 | Methods Changed: 11 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 50 | Churn Cumulative: 2489 | Contributors (this commit): 29 | Commits (past 90d): 22 | Contributors (cumulative): 46 | DMM Complexity: 0.8333333333333334\n\nDIFF:\n@@ -14,7 +14,7 @@ from six.moves import zip\n from .. import backend as K\n from .. import optimizers\n from ..utils.io_utils import ask_to_proceed_with_overwrite\n-from ..utils.io_utils import h5dict\n+from ..utils.io_utils import H5Dict\n from ..utils import conv_utils\n \n try:\n@@ -376,7 +376,7 @@ def save_model(model, filepath, overwrite=True, include_optimizer=True):\n     else:\n         opened_new_file = False\n \n-    f = h5dict(filepath, mode='w')\n+    f = H5Dict(filepath, mode='w')\n \n     try:\n         _serialize_model(model, f, include_optimizer)\n@@ -414,7 +414,7 @@ def load_model(filepath, custom_objects=None, compile=True):\n         raise ImportError('`load_model` requires h5py.')\n     model = None\n     opened_new_file = not isinstance(filepath, h5py.Group)\n-    f = h5dict(filepath, 'r')\n+    f = H5Dict(filepath, 'r')\n     try:\n         model = _deserialize_model(f, custom_objects, compile)\n     finally:\n@@ -425,13 +425,13 @@ def load_model(filepath, custom_objects=None, compile=True):\n \n def pickle_model(model):\n     d = {}\n-    f = h5dict(d)\n+    f = H5Dict(d)\n     _serialize_model(model, f)\n     return d\n \n \n def unpickle_model(state):\n-    f = h5dict(state, mode='r')\n+    f = H5Dict(state, mode='r')\n     return _deserialize_model(f)\n \n \n\n@@ -7,7 +7,7 @@ from . import conv_utils\n \n # Globally-importable utils.\n from .io_utils import HDF5Matrix\n-from .io_utils import h5dict\n+from .io_utils import H5Dict\n from .data_utils import get_file\n from .data_utils import Sequence\n from .data_utils import GeneratorEnqueuer\n\n@@ -176,13 +176,17 @@ class H5Dict(object):\n     There are lot of edge cases which have been hardcoded,\n     and makes sense only in the context of model serialization/\n     deserialization.\n+\n+    # Arguments\n+        path: Either a string (path on disk), a dict, or a HDF5 Group.\n+        mode: File open mode (one of `{\"a\", \"r\", \"w\"}`).\n     \"\"\"\n \n     def __init__(self, path, mode='a'):\n         if isinstance(path, h5py.Group):\n             self.data = path\n             self._is_file = False\n-        elif isinstance(path, str):\n+        elif isinstance(path, six.string_types):\n             self.data = h5py.File(path, mode=mode)\n             self._is_file = True\n         elif isinstance(path, dict):\n@@ -199,7 +203,7 @@ class H5Dict(object):\n \n     def __setitem__(self, attr, val):\n         if self.read_only:\n-            raise ValueError('Cannot set item in read only mode.')\n+            raise ValueError('Cannot set item in read-only mode.')\n         is_np = type(val).__module__ == np.__name__\n         if isinstance(self.data, dict):\n             if isinstance(attr, bytes):\n@@ -221,20 +225,21 @@ class H5Dict(object):\n                 dataset[()] = val\n             else:\n                 dataset[:] = val\n-        elif isinstance(val, list):\n+        elif isinstance(val, (list, tuple)):\n             # Check that no item in `data` is larger than `HDF5_OBJECT_HEADER_LIMIT`\n             # because in that case even chunking the array would not make the saving\n             # possible.\n             bad_attributes = [x for x in val if len(x) > HDF5_OBJECT_HEADER_LIMIT]\n \n             # Expecting this to never be true.\n-            if len(bad_attributes) > 0:\n+            if bad_attributes:\n                 raise RuntimeError('The following attributes cannot be saved to '\n                                    'HDF5 file because they are larger than '\n                                    '%d bytes: %s' % (HDF5_OBJECT_HEADER_LIMIT,\n                                                      ', '.join(bad_attributes)))\n \n-            if val and sys.version_info[0] == 3 and isinstance(val[0], str):\n+            if (val and sys.version_info[0] == 3 and isinstance(\n+                    val[0], six.string_types)):\n                 # convert to bytes\n                 val = [x.encode('utf-8') for x in val]\n \n@@ -270,7 +275,7 @@ class H5Dict(object):\n                 return val\n             else:\n                 if self.read_only:\n-                    raise ValueError('Cannot create group in read only mode.')\n+                    raise ValueError('Cannot create group in read-only mode.')\n                 val = {'_is_group': True}\n                 self.data[attr] = val\n                 return H5Dict(val)\n@@ -299,7 +304,7 @@ class H5Dict(object):\n                     chunk_attr = '%s%d' % (attr, chunk_id)\n             else:\n                 if self.read_only:\n-                    raise ValueError('Cannot create group in read only mode.')\n+                    raise ValueError('Cannot create group in read-only mode.')\n                 val = H5Dict(self.data.create_group(attr))\n         return val\n \n\n@@ -5,7 +5,7 @@ import pytest\n from keras.models import Sequential\n from keras.layers import Dense\n from keras.utils.io_utils import HDF5Matrix\n-from keras.utils.io_utils import h5dict\n+from keras.utils.io_utils import H5Dict\n from keras.utils.io_utils import ask_to_proceed_with_overwrite\n from numpy.testing import assert_allclose\n import numpy as np\n@@ -134,45 +134,50 @@ def test_ask_to_proceed_with_overwrite():\n         assert not ask_to_proceed_with_overwrite('/tmp/not_exists')\n \n \n-def test_h5dict_attrs():\n+def test_H5Dict_attrs():\n     _, h5_path = tempfile.mkstemp('.h5')\n \n     # test both HDF5 and dict implementations\n     paths = [h5_path, dict()]\n \n     for path in paths:\n-        f = h5dict(path, mode='w')\n+        f = H5Dict(path, mode='w')\n \n         # str\n         f['x'] = 'abcd'\n+        f['x2'] = u'abcd'\n \n         # list<bytes>\n         f['y'] = [b'efg', b'hij', b'klmn']\n+        f['y2'] = (b'asd', b'sdf', b'dfg')\n \n         # ndarray\n         array = np.random.random((4, 5, 512))\n         f['z'] = array\n \n         f.close()\n+        del f\n \n-        f = h5dict(path, mode='r')\n+        f = H5Dict(path, mode='r')\n \n         assert f['x'] == 'abcd'\n+        assert f['x2'] == u'abcd'\n         assert f['y'] == [b'efg', b'hij', b'klmn']\n+        assert list(f['y2']) == [b'asd', b'sdf', b'dfg']\n         assert_allclose(f['z'], array)\n \n         f.close()\n     os.remove(h5_path)\n \n \n-def test_h5dict_groups():\n+def test_H5Dict_groups():\n     _, h5_path = tempfile.mkstemp('.h5')\n \n     # test both HDF5 and dict implementations\n     paths = [h5_path, dict()]\n \n     for path in paths:\n-        f = h5dict(path, mode='w')\n+        f = H5Dict(path, mode='w')\n \n         group1 = f['group1']\n         group2 = group1['group2']\n@@ -188,7 +193,7 @@ def test_h5dict_groups():\n \n         f.close()\n \n-        f = h5dict(path, mode='r')\n+        f = H5Dict(path, mode='r')\n \n         assert 'group1' in f\n         group1 = f['group1']\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1608aeda408335232a62328fa95811488be4ddac", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 6 | Methods Changed: 5 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 14 | Churn Cumulative: 1988 | Contributors (this commit): 21 | Commits (past 90d): 7 | Contributors (cumulative): 21 | DMM Complexity: None\n\nDIFF:\n@@ -91,16 +91,16 @@ def _extract_archive(file_path, path='.', archive_format='auto'):\n     \"\"\"\n     if archive_format is None:\n         return False\n-    if archive_format is 'auto':\n+    if archive_format == 'auto':\n         archive_format = ['tar', 'zip']\n     if isinstance(archive_format, six.string_types):\n         archive_format = [archive_format]\n \n     for archive_type in archive_format:\n-        if archive_type is 'tar':\n+        if archive_type == 'tar':\n             open_fn = tarfile.open\n             is_match_fn = tarfile.is_tarfile\n-        if archive_type is 'zip':\n+        if archive_type == 'zip':\n             open_fn = zipfile.ZipFile\n             is_match_fn = zipfile.is_zipfile\n \n@@ -210,7 +210,7 @@ def get_file(fname,\n \n         def dl_progress(count, block_size, total_size):\n             if ProgressTracker.progbar is None:\n-                if total_size is -1:\n+                if total_size == -1:\n                     total_size = None\n                 ProgressTracker.progbar = Progbar(total_size)\n             else:\n@@ -261,7 +261,7 @@ def _hash_file(fpath, algorithm='sha256', chunk_size=65535):\n     # Returns\n         The file hash\n     \"\"\"\n-    if (algorithm is 'sha256') or (algorithm is 'auto' and len(hash) is 64):\n+    if (algorithm == 'sha256') or (algorithm == 'auto' and len(hash) == 64):\n         hasher = hashlib.sha256()\n     else:\n         hasher = hashlib.md5()\n@@ -287,8 +287,8 @@ def validate_file(fpath, file_hash, algorithm='auto', chunk_size=65535):\n     # Returns\n         Whether the file is valid\n     \"\"\"\n-    if ((algorithm is 'sha256') or\n-            (algorithm is 'auto' and len(file_hash) is 64)):\n+    if ((algorithm == 'sha256') or\n+            (algorithm == 'auto' and len(file_hash) == 64)):\n         hasher = 'sha256'\n     else:\n         hasher = 'md5'\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d7b04e6fc6ad57c58323f16687c366e19bdd0fd0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 657 | Contributors (this commit): 5 | Commits (past 90d): 4 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -201,7 +201,7 @@ def standardize_sample_weights(sample_weight, output_names):\n \n \n def check_array_length_consistency(inputs, targets, weights=None):\n-    \"\"\"Checks if batch axes are the same for numpy arrays.\n+    \"\"\"Checks if batch axes are the same for Numpy arrays.\n \n     # Arguments\n         inputs: list of Numpy arrays of inputs.\n@@ -443,7 +443,7 @@ def standardize_weights(y,\n             the targets (i.e. we are weighting timesteps, not samples).\n \n     # Returns\n-        A numpy array of target weights, one entry per sample to weight.\n+        A Numpy array of target weights, one entry per sample to weight.\n \n     # Raises\n         ValueError: In case of invalid user-provided arguments.\n@@ -550,9 +550,9 @@ def check_num_samples(ins,\n         exclusive.\n \n     # Returns\n-        When steps is `None`, returns the number of samples to be\n+        When `steps` is `None`, returns the number of samples to be\n         processed based on the size of the first dimension of the\n-        first input numpy array. When steps is not `None` and\n+        first input Numpy array. When `steps` is not `None` and\n         `batch_size` is `None`, returns `None`.\n \n     # Raises\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e06e8a96d5adef8610d682c758ee080a13011eca", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 1633 | Contributors (this commit): 11 | Commits (past 90d): 8 | Contributors (cumulative): 11 | DMM Complexity: 0.0\n\nDIFF:\n@@ -133,6 +133,7 @@ def _serialize_model(model, f, include_optimizer=True):\n                 },\n                 'loss': model.loss,\n                 'metrics': model.metrics,\n+                'weighted_metrics': model.weighted_metrics,\n                 'sample_weight_mode': model.sample_weight_mode,\n                 'loss_weights': model.loss_weights,\n             }, default=get_json_type).encode('utf8')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#43b66da6b596000a52162f6fc9e58a46c880172c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 10 | Files Changed: 1 | Hunks: 5 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 187 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -1,12 +1,8 @@\n import pytest\n-import os\n import sys\n-import tempfile\n import numpy as np\n from numpy.testing import assert_allclose\n-from numpy.testing import assert_raises\n \n-from keras import backend as K\n from keras.models import Model, Sequential\n from keras.layers import Dense, Lambda, RepeatVector, TimeDistributed\n from keras.layers import Input\n@@ -20,12 +16,6 @@ else:\n     import cPickle as pickle\n \n \n-skipif_no_tf_gpu = pytest.mark.skipif(\n-    (K.backend() != 'tensorflow') or\n-    (not K.tensorflow_backend._get_available_gpus()),\n-    reason='Requires TensorFlow backend and a GPU')\n-\n-\n def test_sequential_model_pickling():\n     model = Sequential()\n     model.add(Dense(2, input_shape=(3,)))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
