{"custom_id": "keras#ff4b3f6b318cd13b9ad881a2ddf37908b7de2d4a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 9 | Churn Cumulative: 439 | Contributors (this commit): 2 | Commits (past 90d): 5 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -123,7 +123,9 @@ def record_object_after_deserialization(obj, obj_id):\n     SHARED_OBJECTS.id_to_obj_map[obj_id] = obj\n \n \n-@keras_export(\"keras.utils.serialize_keras_object\")\n+@keras_export(\n+    \"keras.saving.serialize_keras_object\", \"keras.utils.serialize_keras_object\"\n+)\n def serialize_keras_object(obj):\n     \"\"\"Retrieve the config dict by serializing the Keras object.\n \n@@ -384,7 +386,10 @@ def serialize_dict(obj):\n     return {key: serialize_keras_object(value) for key, value in obj.items()}\n \n \n-@keras_export(\"keras.utils.deserialize_keras_object\")\n+@keras_export(\n+    \"keras.saving.deserialize_keras_object\",\n+    \"keras.utils.deserialize_keras_object\",\n+)\n def deserialize_keras_object(\n     config, custom_objects=None, safe_mode=True, **kwargs\n ):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1a8c6c16b74363fb80489132e760f6966494e3cd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 7 | Files Changed: 6 | Hunks: 7 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 14 | Churn Cumulative: 796 | Contributors (this commit): 6 | Commits (past 90d): 6 | Contributors (cumulative): 28 | DMM Complexity: None\n\nDIFF:\n@@ -22,7 +22,7 @@ from keras.layers.pooling.base_global_pooling1d import GlobalPooling1D\n from tensorflow.python.util.tf_export import keras_export\n \n \n-@keras_export(\"keras.layers.GlobalMaxPool1D\", \"keras.layers.GlobalMaxPooling1D\")\n+@keras_export(\"keras.layers.GlobalMaxPooling1D\", \"keras.layers.GlobalMaxPool1D\")\n class GlobalMaxPooling1D(GlobalPooling1D):\n     \"\"\"Global max pooling operation for 1D temporal data.\n \n\n@@ -22,7 +22,7 @@ from keras.layers.pooling.base_global_pooling2d import GlobalPooling2D\n from tensorflow.python.util.tf_export import keras_export\n \n \n-@keras_export(\"keras.layers.GlobalMaxPool2D\", \"keras.layers.GlobalMaxPooling2D\")\n+@keras_export(\"keras.layers.GlobalMaxPooling2D\", \"keras.layers.GlobalMaxPool2D\")\n class GlobalMaxPooling2D(GlobalPooling2D):\n     \"\"\"Global max pooling operation for spatial data.\n \n@@ -30,7 +30,7 @@ class GlobalMaxPooling2D(GlobalPooling2D):\n \n     >>> input_shape = (2, 4, 5, 3)\n     >>> x = tf.random.normal(input_shape)\n-    >>> y = tf.keras.layers.GlobalMaxPool2D()(x)\n+    >>> y = tf.keras.layers.GlobalMaxPooling2D()(x)\n     >>> print(y.shape)\n     (2, 3)\n \n\n@@ -22,7 +22,7 @@ from keras.layers.pooling.base_global_pooling3d import GlobalPooling3D\n from tensorflow.python.util.tf_export import keras_export\n \n \n-@keras_export(\"keras.layers.GlobalMaxPool3D\", \"keras.layers.GlobalMaxPooling3D\")\n+@keras_export(\"keras.layers.GlobalMaxPooling3D\", \"keras.layers.GlobalMaxPool3D\")\n class GlobalMaxPooling3D(GlobalPooling3D):\n     \"\"\"Global Max pooling operation for 3D data.\n \n\n@@ -24,7 +24,7 @@ from keras.layers.pooling.base_pooling1d import Pooling1D\n from tensorflow.python.util.tf_export import keras_export\n \n \n-@keras_export(\"keras.layers.MaxPool1D\", \"keras.layers.MaxPooling1D\")\n+@keras_export(\"keras.layers.MaxPooling1D\", \"keras.layers.MaxPool1D\")\n class MaxPooling1D(Pooling1D):\n     \"\"\"Max pooling operation for 1D temporal data.\n \n\n@@ -23,7 +23,7 @@ from keras.layers.pooling.base_pooling2d import Pooling2D\n from tensorflow.python.util.tf_export import keras_export\n \n \n-@keras_export(\"keras.layers.MaxPool2D\", \"keras.layers.MaxPooling2D\")\n+@keras_export(\"keras.layers.MaxPooling2D\", \"keras.layers.MaxPool2D\")\n class MaxPooling2D(Pooling2D):\n     \"\"\"Max pooling operation for 2D spatial data.\n \n\n@@ -23,7 +23,7 @@ from keras.layers.pooling.base_pooling3d import Pooling3D\n from tensorflow.python.util.tf_export import keras_export\n \n \n-@keras_export(\"keras.layers.MaxPool3D\", \"keras.layers.MaxPooling3D\")\n+@keras_export(\"keras.layers.MaxPooling3D\", \"keras.layers.MaxPool3D\")\n class MaxPooling3D(Pooling3D):\n     \"\"\"Max pooling operation for 3D data (spatial or spatio-temporal).\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#86e8daac7b480f075da05ce5e59c39a8fb88b548", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 15 | Lines Deleted: 44 | Files Changed: 5 | Hunks: 43 | Methods Changed: 3 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 59 | Churn Cumulative: 6654 | Contributors (this commit): 10 | Commits (past 90d): 10 | Contributors (cumulative): 37 | DMM Complexity: 1.0\n\nDIFF:\n@@ -33,7 +33,6 @@ from keras.utils import tf_contextlib\n # isort: off\n from tensorflow.python.ops import variable_scope as vs\n from tensorflow.python.util.tf_export import keras_export\n-from tensorflow.python.util.tf_export import tf_export\n \n _KERAS_STYLE_SCOPE = False\n \n@@ -41,7 +40,6 @@ _KERAS_STYLE_SCOPE = False\n @keras_export(\n     v1=[\"keras.__internal__.legacy.layers.experimental.keras_style_scope\"]\n )\n-@tf_export(v1=[\"layers.experimental.keras_style_scope\"])\n @tf_contextlib.contextmanager\n def keras_style_scope():\n     \"\"\"Use Keras-style variable management.\n@@ -113,7 +111,6 @@ def keras_style_scope():\n @keras_export(\n     v1=[\"keras.__internal__.legacy.layers.experimental.set_keras_style\"]\n )\n-@tf_export(v1=[\"layers.experimental.set_keras_style\"])\n def set_keras_style():\n     \"\"\"Use Keras-style variable management.\n \n@@ -157,7 +154,6 @@ def _is_in_keras_style_scope():\n \n \n @keras_export(v1=[\"keras.__internal__.legacy.layers.Layer\"])\n-@tf_export(v1=[\"layers.Layer\"])\n class Layer(base_layer.Layer):\n     \"\"\"Base layer class.\n \n\n@@ -27,11 +27,9 @@ from keras.legacy_tf_layers import base\n \n # isort: off\n from tensorflow.python.util.tf_export import keras_export\n-from tensorflow.python.util.tf_export import tf_export\n \n \n @keras_export(v1=[\"keras.__internal__.legacy.layers.Conv1D\"])\n-@tf_export(v1=[\"layers.Conv1D\"])\n class Conv1D(keras_layers.Conv1D, base.Layer):\n     \"\"\"1D convolution layer (e.g. temporal convolution).\n \n@@ -158,7 +156,6 @@ class Conv1D(keras_layers.Conv1D, base.Layer):\n \n \n @keras_export(v1=[\"keras.__internal__.legacy.layers.conv1d\"])\n-@tf_export(v1=[\"layers.conv1d\"])\n def conv1d(\n     inputs,\n     filters,\n@@ -306,7 +303,6 @@ def conv1d(\n \n \n @keras_export(v1=[\"keras.__internal__.legacy.layers.Conv2D\"])\n-@tf_export(v1=[\"layers.Conv2D\"])\n class Conv2D(keras_layers.Conv2D, base.Layer):\n     \"\"\"2D convolution layer (e.g. spatial convolution over images).\n \n@@ -441,7 +437,6 @@ class Conv2D(keras_layers.Conv2D, base.Layer):\n \n \n @keras_export(v1=[\"keras.__internal__.legacy.layers.conv2d\"])\n-@tf_export(v1=[\"layers.conv2d\"])\n def conv2d(\n     inputs,\n     filters,\n@@ -596,7 +591,6 @@ def conv2d(\n \n \n @keras_export(v1=[\"keras.__internal__.legacy.layers.Conv3D\"])\n-@tf_export(v1=[\"layers.Conv3D\"])\n class Conv3D(keras_layers.Conv3D, base.Layer):\n     \"\"\"3D convolution layer (e.g. spatial convolution over volumes).\n \n@@ -732,7 +726,6 @@ class Conv3D(keras_layers.Conv3D, base.Layer):\n \n \n @keras_export(v1=[\"keras.__internal__.legacy.layers.conv3d\"])\n-@tf_export(v1=[\"layers.conv3d\"])\n def conv3d(\n     inputs,\n     filters,\n@@ -888,7 +881,6 @@ def conv3d(\n \n \n @keras_export(v1=[\"keras.__internal__.legacy.layers.SeparableConv1D\"])\n-@tf_export(v1=[\"layers.SeparableConv1D\"])\n class SeparableConv1D(keras_layers.SeparableConv1D, base.Layer):\n     \"\"\"Depthwise separable 1D convolution.\n \n@@ -1037,7 +1029,6 @@ class SeparableConv1D(keras_layers.SeparableConv1D, base.Layer):\n \n \n @keras_export(v1=[\"keras.__internal__.legacy.layers.SeparableConv2D\"])\n-@tf_export(v1=[\"layers.SeparableConv2D\"])\n class SeparableConv2D(keras_layers.SeparableConv2D, base.Layer):\n     \"\"\"Depthwise separable 2D convolution.\n \n@@ -1190,7 +1181,6 @@ class SeparableConv2D(keras_layers.SeparableConv2D, base.Layer):\n \n \n @keras_export(v1=[\"keras.__internal__.legacy.layers.separable_conv1d\"])\n-@tf_export(v1=[\"layers.separable_conv1d\"])\n def separable_conv1d(\n     inputs,\n     filters,\n@@ -1358,7 +1348,6 @@ def separable_conv1d(\n \n \n @keras_export(v1=[\"keras.__internal__.legacy.layers.separable_conv2d\"])\n-@tf_export(v1=[\"layers.separable_conv2d\"])\n def separable_conv2d(\n     inputs,\n     filters,\n@@ -1530,7 +1519,6 @@ def separable_conv2d(\n \n \n @keras_export(v1=[\"keras.__internal__.legacy.layers.Conv2DTranspose\"])\n-@tf_export(v1=[\"layers.Conv2DTranspose\"])\n class Conv2DTranspose(keras_layers.Conv2DTranspose, base.Layer):\n     \"\"\"Transposed 2D convolution layer (sometimes called 2D Deconvolution).\n \n@@ -1654,7 +1642,6 @@ class Conv2DTranspose(keras_layers.Conv2DTranspose, base.Layer):\n \n \n @keras_export(v1=[\"keras.__internal__.legacy.layers.conv2d_transpose\"])\n-@tf_export(v1=[\"layers.conv2d_transpose\"])\n def conv2d_transpose(\n     inputs,\n     filters,\n@@ -1798,7 +1785,6 @@ def conv2d_transpose(\n \n \n @keras_export(v1=[\"keras.__internal__.legacy.layers.Conv3DTranspose\"])\n-@tf_export(v1=[\"layers.Conv3DTranspose\"])\n class Conv3DTranspose(keras_layers.Conv3DTranspose, base.Layer):\n     \"\"\"Transposed 3D convolution layer (sometimes called 3D Deconvolution).\n \n@@ -1918,7 +1904,6 @@ class Conv3DTranspose(keras_layers.Conv3DTranspose, base.Layer):\n \n \n @keras_export(v1=[\"keras.__internal__.legacy.layers.conv3d_transpose\"])\n-@tf_export(v1=[\"layers.conv3d_transpose\"])\n def conv3d_transpose(\n     inputs,\n     filters,\n\n@@ -30,11 +30,9 @@ from keras.legacy_tf_layers import base\n \n # isort: off\n from tensorflow.python.util.tf_export import keras_export\n-from tensorflow.python.util.tf_export import tf_export\n \n \n @keras_export(v1=[\"keras.__internal__.legacy.layers.Dense\"])\n-@tf_export(v1=[\"layers.Dense\"])\n class Dense(keras_layers.Dense, base.Layer):\n     \"\"\"Densely-connected layer class.\n \n@@ -153,7 +151,6 @@ class Dense(keras_layers.Dense, base.Layer):\n \n \n @keras_export(v1=[\"keras.__internal__.legacy.layers.dense\"])\n-@tf_export(v1=[\"layers.dense\"])\n def dense(\n     inputs,\n     units,\n@@ -275,7 +272,6 @@ def dense(\n \n \n @keras_export(v1=[\"keras.__internal__.legacy.layers.Dropout\"])\n-@tf_export(v1=[\"layers.Dropout\"])\n class Dropout(keras_layers.Dropout, base.Layer):\n     \"\"\"Applies Dropout to the input.\n \n@@ -348,7 +344,6 @@ class Dropout(keras_layers.Dropout, base.Layer):\n \n \n @keras_export(v1=[\"keras.__internal__.legacy.layers.dropout\"])\n-@tf_export(v1=[\"layers.dropout\"])\n def dropout(\n     inputs, rate=0.5, noise_shape=None, seed=None, training=False, name=None\n ):\n@@ -428,7 +423,6 @@ def dropout(\n \n \n @keras_export(v1=[\"keras.__internal__.legacy.layers.Flatten\"])\n-@tf_export(v1=[\"layers.Flatten\"])\n class Flatten(keras_layers.Flatten, base.Layer):\n     \"\"\"Flattens an input tensor while preserving the batch axis (axis 0).\n \n@@ -485,7 +479,6 @@ class Flatten(keras_layers.Flatten, base.Layer):\n \n \n @keras_export(v1=[\"keras.__internal__.legacy.layers.flatten\"])\n-@tf_export(v1=[\"layers.flatten\"])\n def flatten(inputs, name=None, data_format=\"channels_last\"):\n     \"\"\"Flattens an input tensor while preserving the batch axis (axis 0).\n \n\n@@ -25,11 +25,9 @@ from keras.legacy_tf_layers import base\n \n # isort: off\n from tensorflow.python.util.tf_export import keras_export\n-from tensorflow.python.util.tf_export import tf_export\n \n \n @keras_export(v1=[\"keras.__internal__.legacy.layers.AveragePooling1D\"])\n-@tf_export(v1=[\"layers.AveragePooling1D\"])\n class AveragePooling1D(keras_layers.AveragePooling1D, base.Layer):\n     \"\"\"Average Pooling layer for 1D inputs.\n \n@@ -101,7 +99,6 @@ class AveragePooling1D(keras_layers.AveragePooling1D, base.Layer):\n \n \n @keras_export(v1=[\"keras.__internal__.legacy.layers.average_pooling1d\"])\n-@tf_export(v1=[\"layers.average_pooling1d\"])\n def average_pooling1d(\n     inputs,\n     pool_size,\n@@ -186,7 +183,6 @@ def average_pooling1d(\n \n \n @keras_export(v1=[\"keras.__internal__.legacy.layers.MaxPooling1D\"])\n-@tf_export(v1=[\"layers.MaxPooling1D\"])\n class MaxPooling1D(keras_layers.MaxPooling1D, base.Layer):\n     \"\"\"Max Pooling layer for 1D inputs.\n \n@@ -258,7 +254,6 @@ class MaxPooling1D(keras_layers.MaxPooling1D, base.Layer):\n \n \n @keras_export(v1=[\"keras.__internal__.legacy.layers.max_pooling1d\"])\n-@tf_export(v1=[\"layers.max_pooling1d\"])\n def max_pooling1d(\n     inputs,\n     pool_size,\n@@ -343,7 +338,6 @@ def max_pooling1d(\n \n \n @keras_export(v1=[\"keras.__internal__.legacy.layers.AveragePooling2D\"])\n-@tf_export(v1=[\"layers.AveragePooling2D\"])\n class AveragePooling2D(keras_layers.AveragePooling2D, base.Layer):\n     \"\"\"Average pooling layer for 2D inputs (e.g. images).\n \n@@ -419,7 +413,6 @@ class AveragePooling2D(keras_layers.AveragePooling2D, base.Layer):\n \n \n @keras_export(v1=[\"keras.__internal__.legacy.layers.average_pooling2d\"])\n-@tf_export(v1=[\"layers.average_pooling2d\"])\n def average_pooling2d(\n     inputs,\n     pool_size,\n@@ -508,7 +501,6 @@ def average_pooling2d(\n \n \n @keras_export(v1=[\"keras.__internal__.legacy.layers.MaxPooling2D\"])\n-@tf_export(v1=[\"layers.MaxPooling2D\"])\n class MaxPooling2D(keras_layers.MaxPooling2D, base.Layer):\n     \"\"\"Max pooling layer for 2D inputs (e.g. images).\n \n@@ -584,7 +576,6 @@ class MaxPooling2D(keras_layers.MaxPooling2D, base.Layer):\n \n \n @keras_export(v1=[\"keras.__internal__.legacy.layers.max_pooling2d\"])\n-@tf_export(v1=[\"layers.max_pooling2d\"])\n def max_pooling2d(\n     inputs,\n     pool_size,\n@@ -673,7 +664,6 @@ def max_pooling2d(\n \n \n @keras_export(v1=[\"keras.__internal__.legacy.layers.AveragePooling3D\"])\n-@tf_export(v1=[\"layers.AveragePooling3D\"])\n class AveragePooling3D(keras_layers.AveragePooling3D, base.Layer):\n     \"\"\"Average pooling layer for 3D inputs (e.g. volumes).\n \n@@ -751,7 +741,6 @@ class AveragePooling3D(keras_layers.AveragePooling3D, base.Layer):\n \n \n @keras_export(v1=[\"keras.__internal__.legacy.layers.average_pooling3d\"])\n-@tf_export(v1=[\"layers.average_pooling3d\"])\n def average_pooling3d(\n     inputs,\n     pool_size,\n@@ -842,7 +831,6 @@ def average_pooling3d(\n \n \n @keras_export(v1=[\"keras.__internal__.legacy.layers.MaxPooling3D\"])\n-@tf_export(v1=[\"layers.MaxPooling3D\"])\n class MaxPooling3D(keras_layers.MaxPooling3D, base.Layer):\n     \"\"\"Max pooling layer for 3D inputs (e.g. volumes).\n \n@@ -920,7 +908,6 @@ class MaxPooling3D(keras_layers.MaxPooling3D, base.Layer):\n \n \n @keras_export(v1=[\"keras.__internal__.legacy.layers.max_pooling3d\"])\n-@tf_export(v1=[\"layers.max_pooling3d\"])\n def max_pooling3d(\n     inputs,\n     pool_size,\n\n@@ -191,17 +191,26 @@ def generate_keras_api_files(package_directory, src_directory):\n                         f\"[!] Could not inspect symbol '{name}' from {module}.\"\n                     )\n                 continue\n-            # If the symbol is a subclass of a non-registered symbol, skip it.\n+            # If the symbol is a non-registered subclass of\n+            # a registered symbol, skip it.\n             skip = False\n+\n+            def has_same_metadata(a, b):\n+                if (\n+                    hasattr(a, \"_keras_api_names\")\n+                    and hasattr(b, \"_keras_api_names\")\n+                    and a._keras_api_names == b._keras_api_names\n+                    and a._keras_api_names_v1 == b._keras_api_names_v1\n+                ):\n+                    return True\n+                return False\n+\n             try:\n                 classes = inspect.getmro(symbol)\n                 if len(classes) >= 2:\n                     parents = classes[1:]\n                     for p in parents:\n-                        if (\n-                            hasattr(p, \"_keras_api_names\")\n-                            and p._keras_api_names == symbol._keras_api_names\n-                        ):\n+                        if has_same_metadata(p, symbol):\n                             skip = True\n             except AttributeError:\n                 # getmro will error out on a non-class\n@@ -424,6 +433,7 @@ def test_wheel(wheel_path, expected_version, requirements_path):\n         f\"pip3 install -r {requirements_path}\\n\"\n         f\"pip3 install {wheel_path} --force-reinstall\\n\"\n         f\"python3 -c 'import keras;{checks};print(keras.__version__)'\\n\"\n+        f\"python3 -c 'import tensorflow as tf;tf.compat.v1.layers.Dense'\\n\"\n     )\n     try:\n         # Check version is correct\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b79087197678ac279469985aced90de34e0882b8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 14 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 14 | Churn Cumulative: 278 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -16,7 +16,6 @@\n \n import inspect\n import threading\n-import warnings\n \n # isort: off\n from tensorflow.python.util.tf_export import keras_export\n@@ -151,19 +150,6 @@ def register_keras_serializable(package=\"Custom\", name=None):\n                 \"get_config() method.\"\n             )\n \n-        if registered_name in _GLOBAL_CUSTOM_OBJECTS:\n-            warnings.warn(\n-                f\"{registered_name} has already been registered to \"\n-                f\"{_GLOBAL_CUSTOM_OBJECTS[registered_name]}. \"\n-                f\"Overwriting registration with {arg}.\"\n-            )\n-\n-        if arg in _GLOBAL_CUSTOM_NAMES:\n-            warnings.warn(\n-                f\"{arg} has already been registered to \"\n-                f\"{_GLOBAL_CUSTOM_NAMES[arg]}. \"\n-                f\"Overwriting registration with {registered_name}.\"\n-            )\n         _GLOBAL_CUSTOM_OBJECTS[registered_name] = arg\n         _GLOBAL_CUSTOM_NAMES[arg] = registered_name\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3c3da70cf9312131b70a86bed0664f3ec11408b4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 17 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 19 | Churn Cumulative: 282 | Contributors (this commit): 6 | Commits (past 90d): 1 | Contributors (cumulative): 6 | DMM Complexity: 0.0\n\nDIFF:\n@@ -21,6 +21,7 @@ from keras import backend\n from keras.engine.base_layer import Layer\n from keras.engine.input_spec import InputSpec\n from keras.utils import conv_utils\n+from keras.utils import image_utils\n \n # isort: off\n from tensorflow.python.util.tf_export import keras_export\n@@ -92,23 +93,7 @@ class UpSampling2D(Layer):\n         super().__init__(**kwargs)\n         self.data_format = conv_utils.normalize_data_format(data_format)\n         self.size = conv_utils.normalize_tuple(size, 2, \"size\")\n-        interpolations = {\n-            \"area\": tf.image.ResizeMethod.AREA,\n-            \"bicubic\": tf.image.ResizeMethod.BICUBIC,\n-            \"bilinear\": tf.image.ResizeMethod.BILINEAR,\n-            \"gaussian\": tf.image.ResizeMethod.GAUSSIAN,\n-            \"lanczos3\": tf.image.ResizeMethod.LANCZOS3,\n-            \"lanczos5\": tf.image.ResizeMethod.LANCZOS5,\n-            \"mitchellcubic\": tf.image.ResizeMethod.MITCHELLCUBIC,\n-            \"nearest\": tf.image.ResizeMethod.NEAREST_NEIGHBOR,\n-        }\n-        interploations_list = '\"' + '\", \"'.join(interpolations.keys()) + '\"'\n-        if interpolation not in interpolations:\n-            raise ValueError(\n-                \"`interpolation` argument should be one of: \"\n-                f'{interploations_list}. Received: \"{interpolation}\".'\n-            )\n-        self.interpolation = interpolation\n+        self.interpolation = image_utils.get_interpolation(interpolation)\n         self.input_spec = InputSpec(ndim=4)\n \n     def compute_output_shape(self, input_shape):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a2d5ea96d28a9efd97e2a582247d56ec58d2ca63", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 2 | Churn Cumulative: 2662 | Contributors (this commit): 20 | Commits (past 90d): 2 | Contributors (cumulative): 20 | DMM Complexity: None\n\nDIFF:\n@@ -73,7 +73,7 @@ def handle_partial_sample_weights(\n       describing the raw sample weights.\n     \"\"\"\n     if not isinstance(sample_weights, (list, tuple)):\n-        any_sample_weight = (sample_weights,) is not None and sample_weights is not None\n+        any_sample_weight = sample_weights is not None\n         partial_sample_weight = any_sample_weight and sample_weights is None\n     else:\n         any_sample_weight = sample_weights is not None and any(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0f89165b8b17a23cb165a2006b1370092c6eba95", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 18 | Churn Cumulative: 11041 | Contributors (this commit): 25 | Commits (past 90d): 11 | Contributors (cumulative): 25 | DMM Complexity: 0.0\n\nDIFF:\n@@ -5566,8 +5566,12 @@ def categorical_crossentropy(target, output, from_logits=False, axis=-1):\n             labels=target, logits=output, axis=axis\n         )\n \n-    # scale preds so that the class probas of each sample sum to 1\n+    # Adjust the predictions so that the probability of\n+    # each class for every sample adds up to 1\n+    # This is needed to ensure that the cross entropy is\n+    # computed correctly.\n     output = output / tf.reduce_sum(output, axis, True)\n+\n     # Compute cross entropy from probabilities.\n     epsilon_ = _constant_to_tensor(epsilon(), output.dtype.base_dtype)\n     output = tf.clip_by_value(output, epsilon_, 1.0 - epsilon_)\n@@ -5647,7 +5651,7 @@ def categorical_focal_crossentropy(\n     )\n \n     if from_logits:\n-        output = tf.nn.softmax(output, axis=axis)\n+        output = softmax(output, axis=axis)\n \n     # Adjust the predictions so that the probability of\n     # each class for every sample adds up to 1\n@@ -5858,14 +5862,14 @@ def binary_focal_crossentropy(\n     Returns:\n         A tensor.\n     \"\"\"\n-    sigmoidal = tf.__internal__.smart_cond.smart_cond(\n-        from_logits,\n-        lambda: sigmoid(output),\n-        lambda: output,\n-    )\n+\n+    sigmoidal = sigmoid(output) if from_logits else output\n+\n     p_t = target * sigmoidal + (1 - target) * (1 - sigmoidal)\n+\n     # Calculate focal factor\n     focal_factor = tf.pow(1.0 - p_t, gamma)\n+\n     # Binary crossentropy\n     bce = binary_crossentropy(\n         target=target,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3c193de4fee4779c63ec12ea0b55005b4ac57120", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 11046 | Contributors (this commit): 25 | Commits (past 90d): 12 | Contributors (cumulative): 25 | DMM Complexity: None\n\nDIFF:\n@@ -5857,7 +5857,8 @@ def binary_focal_crossentropy(\n         gamma: A focusing parameter, default is `2.0` as mentioned in the\n             reference.\n         from_logits: Whether `output` is expected to be a logits tensor. By\n-            default, we consider that `output` encodes a probability distribution.\n+            default, we consider that `output` encodes a probability\n+            distribution.\n \n     Returns:\n         A tensor.\n@@ -5897,7 +5898,7 @@ def sigmoid(x):\n     Returns:\n         A tensor.\n     \"\"\"\n-    return tf.sigmoid(x)\n+    return tf.math.sigmoid(x)\n \n \n @keras_export(\"keras.backend.hard_sigmoid\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8178687ace4e3458d4d516dedf1ebbd134654add", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 54 | Lines Deleted: 3 | Files Changed: 3 | Hunks: 10 | Methods Changed: 5 | Complexity Δ (Sum/Max): 8/5 | Churn Δ: 57 | Churn Cumulative: 1997 | Contributors (this commit): 13 | Commits (past 90d): 8 | Contributors (cumulative): 22 | DMM Complexity: 0.7837837837837838\n\nDIFF:\n@@ -401,6 +401,13 @@ def Input(\n             \"Keras `Input`.\"\n         )\n \n+    has_spec_name = (\n+        name is None and type_spec is not None and hasattr(type_spec, \"name\")\n+    )\n+\n+    if has_spec_name:\n+        name = type_spec.name\n+\n     input_layer_config = {\n         \"name\": name,\n         \"dtype\": dtype,\n@@ -448,6 +455,9 @@ def Input(\n     # Note that in this case train_output and test_output are the same pointer.\n     outputs = input_layer._inbound_nodes[0].outputs\n     if isinstance(outputs, list) and len(outputs) == 1:\n-        return outputs[0]\n+        output = outputs[0]\n     else:\n-        return outputs\n+        output = outputs\n+    if has_spec_name and hasattr(output, \"_name\"):\n+        output._name = input_layer.name\n+    return output\n\n@@ -14,15 +14,20 @@\n # ,============================================================================\n \"\"\"Tests for InputLayer construction.\"\"\"\n \n+\n import tensorflow.compat.v2 as tf\n \n+from keras import Sequential\n from keras import backend\n+from keras import models\n from keras.engine import functional\n from keras.engine import input_layer as input_layer_lib\n+from keras.layers import Dense\n from keras.layers import core\n from keras.saving.legacy import model_config\n from keras.saving.serialization_lib import SafeModeScope\n from keras.testing_infra import test_combinations\n+from keras.testing_infra import test_utils\n \n # isort: off\n from tensorflow.python.framework import type_spec\n@@ -420,6 +425,42 @@ class InputLayerTest(test_combinations.TestCase):\n         loaded = input_layer_lib.InputLayer.from_config(x.get_config())\n         self.assertIsNone(loaded._batch_input_shape)\n \n+    @test_utils.run_v2_only\n+    def test_typespec_naming_propagation(self):\n+        type_spec = tf.TensorSpec(name=\"test\", shape=(None, None, 2))\n+        input1 = input_layer_lib.Input(type_spec=type_spec)\n+        self.assertEqual(input1.name, \"test\")\n+\n+    @test_utils.run_v2_only\n+    def test_save_input_naming(self):\n+        x = input_layer_lib.Input(shape=(10,), name=\"features\")\n+        y = Dense(1)(x)\n+        model = functional.Functional(x, y)\n+        self.assertEqual(model.layers[0].name, \"features\")\n+        save_path = self.get_temp_dir() + \"/basic_model.keras\"\n+        model.save(save_path)\n+        reloaded_model = models.load_model(save_path)\n+        self.assertEqual(reloaded_model.layers[0].name, \"features\")\n+\n+    @test_utils.run_v2_only\n+    def test_export_input_naming(self):\n+        model = Sequential(\n+            layers=[\n+                input_layer_lib.Input(shape=(8,), name=\"features\"),\n+                Dense(1),\n+            ]\n+        )\n+        x = tf.random.normal((8, 8))\n+        model(x)\n+\n+        export_path = self.get_temp_dir() + \"test_model\"\n+        model.export(export_path)\n+        reloaded_artifact = tf.saved_model.load(export_path)\n+        self.assertEqual(\n+            reloaded_artifact.signatures._signatures[\"serve\"]._arg_keywords[-1],\n+            \"features\",\n+        )\n+\n \n if __name__ == \"__main__\":\n     tf.test.main()\n\n@@ -537,7 +537,7 @@ class ReloadedLayer(base_layer.Layer):\n \n \n def _make_tensor_spec(x):\n-    return tf.TensorSpec(x.shape, dtype=x.dtype)\n+    return tf.TensorSpec(x.shape, dtype=x.dtype, name=x.name)\n \n \n def _print_signature(fn, name):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#336f0ee6c45e36b30ebe04d79b53e79852f88c79", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 10 | Files Changed: 1 | Hunks: 7 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 20 | Churn Cumulative: 3197 | Contributors (this commit): 11 | Commits (past 90d): 11 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -124,7 +124,7 @@ BASE_DOCSTRING = \"\"\"Instantiates the {name} architecture.\n \n   Args:\n     include_top: Whether to include the fully-connected\n-      layer at the top of the network. Defaults to True.\n+      layer at the top of the network. Defaults to `True`.\n     weights: One of `None` (random initialization),\n       `\"imagenet\"` (pre-training on ImageNet-1k), or the path to the weights\n       file to be loaded. Defaults to `\"imagenet\"`.\n@@ -135,7 +135,7 @@ BASE_DOCSTRING = \"\"\"Instantiates the {name} architecture.\n       if `include_top` is False.\n       It should have exactly 3 inputs channels.\n     pooling: Optional pooling mode for feature extraction\n-      when `include_top` is `False`. Defaults to None.\n+      when `include_top` is `False`.\n       - `None` means that the output of the model will be\n         the 4D tensor output of the last convolutional layer.\n       - `avg` means that global average pooling\n@@ -144,16 +144,16 @@ BASE_DOCSTRING = \"\"\"Instantiates the {name} architecture.\n         the output of the model will be a 2D tensor.\n       - `max` means that global max pooling will\n         be applied.\n+      Defaults to `None`.\n     classes: Optional number of classes to classify images\n       into, only to be specified if `include_top` is True, and\n-      if no `weights` argument is specified. Defaults to 1000 (number of\n-      ImageNet classes).\n+      if no `weights` argument is specified. 1000 is how many\n+      ImageNet classes there are. Defaults to `1000`.\n     classifier_activation: A `str` or callable. The activation function to use\n       on the \"top\" layer. Ignored unless `include_top=True`. Set\n       `classifier_activation=None` to return the logits of the \"top\" layer.\n-      Defaults to `\"softmax\"`.\n       When loading pretrained weights, `classifier_activation` can only\n-      be `None` or `\"softmax\"`.\n+      be `None` or `\"softmax\"`. Defaults to `\"softmax\"`.\n \n   Returns:\n     A `keras.Model` instance.\n@@ -754,10 +754,10 @@ def preprocess_input(x, data_format=None):\n \n     Args:\n       x: A floating point `numpy.array` or a `tf.Tensor`.\n-      data_format: Optional data format of the image tensor/array. Defaults to\n-        None, in which case the global setting\n-        `tf.keras.backend.image_data_format()` is used (unless you changed it,\n-        it defaults to \"channels_last\").{mode}\n+      data_format: Optional data format of the image tensor/array. `None` means\n+        the global setting `tf.keras.backend.image_data_format()` is used\n+        (unless you changed it, it uses \"channels_last\").{mode}.\n+        Defaults to `None`.\n \n     Returns:\n       Unchanged `numpy.array` or `tf.Tensor`.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4107acf55a439c81ed3f732c0a6e73f8cd6af7a0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 4 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 16 | Churn Cumulative: 1543 | Contributors (this commit): 11 | Commits (past 90d): 2 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -192,7 +192,7 @@ BASE_DOCSTRING = \"\"\"Instantiates the {name} architecture.\n \n   Args:\n     include_top: Whether to include the fully-connected\n-        layer at the top of the network. Defaults to True.\n+        layer at the top of the network. Defaults to `True`.\n     weights: One of `None` (random initialization),\n           'imagenet' (pre-training on ImageNet),\n           or the path to the weights file to be loaded. Defaults to 'imagenet'.\n@@ -203,7 +203,7 @@ BASE_DOCSTRING = \"\"\"Instantiates the {name} architecture.\n         if `include_top` is False.\n         It should have exactly 3 inputs channels.\n     pooling: Optional pooling mode for feature extraction\n-        when `include_top` is `False`. Defaults to None.\n+        when `include_top` is `False`. Defaults to `None`.\n         - `None` means that the output of the model will be\n             the 4D tensor output of the\n             last convolutional layer.\n@@ -215,8 +215,8 @@ BASE_DOCSTRING = \"\"\"Instantiates the {name} architecture.\n             be applied.\n     classes: Optional number of classes to classify images\n         into, only to be specified if `include_top` is True, and\n-        if no `weights` argument is specified. Defaults to 1000 (number of\n-        ImageNet classes).\n+        if no `weights` argument is specified. 1000 is how many\n+        ImageNet classes there are. Defaults to `1000`.\n     classifier_activation: A `str` or callable. The activation function to use\n         on the \"top\" layer. Ignored unless `include_top=True`. Set\n         `classifier_activation=None` to return the logits of the \"top\" layer.\n@@ -852,10 +852,10 @@ def preprocess_input(x, data_format=None):\n \n     Args:\n       x: A floating point `numpy.array` or a `tf.Tensor`.\n-      data_format: Optional data format of the image tensor/array. Defaults to\n-        None, in which case the global setting\n-        `tf.keras.backend.image_data_format()` is used (unless you changed it,\n-        it defaults to \"channels_last\").{mode}\n+      data_format: Optional data format of the image tensor/array. `None` means\n+        the global setting `tf.keras.backend.image_data_format()` is used\n+        (unless you changed it, it uses \"channels_last\").{mode}.\n+        Defaults to `None`.\n \n     Returns:\n       Unchanged `numpy.array` or `tf.Tensor`.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f5d1c8e9cff614bd41872bef3f1c092144c450f4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 11 | Churn Cumulative: 1631 | Contributors (this commit): 19 | Commits (past 90d): 1 | Contributors (cumulative): 19 | DMM Complexity: None\n\nDIFF:\n@@ -56,10 +56,10 @@ PREPROCESS_INPUT_DOC = \"\"\"\n       The preprocessed data are written over the input data\n       if the data types are compatible. To avoid this\n       behaviour, `numpy.copy(x)` can be used.\n-    data_format: Optional data format of the image tensor/array. Defaults to\n-      None, in which case the global setting\n-      `tf.keras.backend.image_data_format()` is used (unless you changed it,\n-      it defaults to \"channels_last\").{mode}\n+    data_format: Optional data format of the image tensor/array. None, means\n+      the global setting `tf.keras.backend.image_data_format()` is used\n+      (unless you changed it, it uses \"channels_last\").{mode}\n+      Defaults to `None`.\n \n   Returns:\n       Preprocessed `numpy.array` or a `tf.Tensor` with type `float32`.\n@@ -70,7 +70,7 @@ PREPROCESS_INPUT_DOC = \"\"\"\n   \"\"\"\n \n PREPROCESS_INPUT_MODE_DOC = \"\"\"\n-    mode: One of \"caffe\", \"tf\" or \"torch\". Defaults to \"caffe\".\n+    mode: One of \"caffe\", \"tf\" or \"torch\".\n       - caffe: will convert the images from RGB to BGR,\n           then will zero-center each color channel with\n           respect to the ImageNet dataset,\n@@ -80,6 +80,7 @@ PREPROCESS_INPUT_MODE_DOC = \"\"\"\n       - torch: will scale pixels between 0 and 1 and then\n           will normalize each channel with respect to the\n           ImageNet dataset.\n+      Defaults to \"caffe\".\n   \"\"\"\n \n PREPROCESS_INPUT_DEFAULT_ERROR_DOC = \"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a29695fcf63f2b9536abba4b40eb9b8cf4fd2c6e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 4 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 1951 | Contributors (this commit): 16 | Commits (past 90d): 1 | Contributors (cumulative): 16 | DMM Complexity: None\n\nDIFF:\n@@ -82,13 +82,13 @@ def InceptionV3(\n \n     Args:\n       include_top: Boolean, whether to include the fully-connected\n-        layer at the top, as the last layer of the network. Default to `True`.\n+        layer at the top, as the last layer of the network. Defaults to `True`.\n       weights: One of `None` (random initialization),\n         `imagenet` (pre-training on ImageNet),\n-        or the path to the weights file to be loaded. Default to `imagenet`.\n+        or the path to the weights file to be loaded. Defaults to `imagenet`.\n       input_tensor: Optional Keras tensor (i.e. output of `layers.Input()`)\n         to use as image input for the model. `input_tensor` is useful for\n-        sharing inputs between multiple different networks. Default to None.\n+        sharing inputs between multiple different networks. Defaults to `None`.\n       input_shape: Optional shape tuple, only to be specified\n         if `include_top` is False (otherwise the input shape\n         has to be `(299, 299, 3)` (with `channels_last` data format)\n@@ -108,7 +108,7 @@ def InceptionV3(\n         - `max` means that global max pooling will be applied.\n       classes: optional number of classes to classify images\n         into, only to be specified if `include_top` is True, and\n-        if no `weights` argument is specified. Default to 1000.\n+        if no `weights` argument is specified. Defaults to 1000.\n       classifier_activation: A `str` or callable. The activation function to use\n         on the \"top\" layer. Ignored unless `include_top=True`. Set\n         `classifier_activation=None` to return the logits of the \"top\" layer.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b4757f49f5c80a81b790368379c3f1946c2b18ed", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 7 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 17 | Churn Cumulative: 2431 | Contributors (this commit): 19 | Commits (past 90d): 1 | Contributors (cumulative): 19 | DMM Complexity: None\n\nDIFF:\n@@ -124,25 +124,26 @@ def MobileNet(\n         `channels_last` data format) or (3, 224, 224) (with `channels_first`\n         data format). It should have exactly 3 inputs channels, and width and\n         height should be no smaller than 32. E.g. `(200, 200, 3)` would be one\n-        valid value. Default to `None`.\n+        valid value. Defaults to `None`.\n         `input_shape` will be ignored if the `input_tensor` is provided.\n       alpha: Controls the width of the network. This is known as the width\n         multiplier in the MobileNet paper. - If `alpha` < 1.0, proportionally\n         decreases the number of filters in each layer. - If `alpha` > 1.0,\n         proportionally increases the number of filters in each layer. - If\n         `alpha` = 1, default number of filters from the paper are used at each\n-        layer. Default to 1.0.\n+        layer. Defaults to `1.0`.\n       depth_multiplier: Depth multiplier for depthwise convolution. This is\n-        called the resolution multiplier in the MobileNet paper. Default to 1.0.\n-      dropout: Dropout rate. Default to 0.001.\n+        called the resolution multiplier in the MobileNet paper.\n+        Defaults to `1.0`.\n+      dropout: Dropout rate. Defaults to `0.001`.\n       include_top: Boolean, whether to include the fully-connected layer at the\n-        top of the network. Default to `True`.\n+        top of the network. Defaults to `True`.\n       weights: One of `None` (random initialization), 'imagenet' (pre-training\n-        on ImageNet), or the path to the weights file to be loaded. Default to\n+        on ImageNet), or the path to the weights file to be loaded. Defaults to\n         `imagenet`.\n       input_tensor: Optional Keras tensor (i.e. output of `layers.Input()`) to\n         use as image input for the model. `input_tensor` is useful for sharing\n-        inputs between multiple different networks. Default to None.\n+        inputs between multiple different networks. Defaults to `None`.\n       pooling: Optional pooling mode for feature extraction when `include_top`\n         is `False`.\n         - `None` (default) means that the output of the model will be\n@@ -154,7 +155,7 @@ def MobileNet(\n         - `max` means that global max pooling will be applied.\n       classes: Optional number of classes to classify images into, only to be\n         specified if `include_top` is True, and if no `weights` argument is\n-        specified. Defaults to 1000.\n+        specified. Defaults to `1000`.\n       classifier_activation: A `str` or callable. The activation function to use\n         on the \"top\" layer. Ignored unless `include_top=True`. Set\n         `classifier_activation=None` to return the logits of the \"top\" layer.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1dc165bdb610c17488ca6db5368aff0487a60e74", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 1236 | Contributors (this commit): 10 | Commits (past 90d): 1 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -679,10 +679,10 @@ def preprocess_input(x, data_format=None):\n \n     Args:\n       x: A floating point `numpy.array` or a `tf.Tensor`.\n-      data_format: Optional data format of the image tensor/array. Defaults to\n-        None, in which case the global setting\n-        `tf.keras.backend.image_data_format()` is used (unless you changed it,\n-        it defaults to \"channels_last\").{mode}\n+      data_format: Optional data format of the image tensor/array. `None` means\n+        the global setting `tf.keras.backend.image_data_format()` is used\n+        (unless you changed it, it uses \"channels_last\").{mode}.\n+        Defaults to `None`.\n \n     Returns:\n       Unchanged `numpy.array` or `tf.Tensor`.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0ef906cf0f0c5449830975f12f4523d897564f17", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 4 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 13 | Churn Cumulative: 11059 | Contributors (this commit): 25 | Commits (past 90d): 13 | Contributors (cumulative): 25 | DMM Complexity: None\n\nDIFF:\n@@ -1901,8 +1901,8 @@ class RandomGenerator(tf.__internal__.tracking.AutoTrackable):\n         When `rng_type` is \"legacy_stateful\", the seed will be passed down to\n         stateful random ops.\n       rng_type: Type of RNG to use, one of \"stateful\", \"stateless\",\n-        \"legacy_stateful\". It defaults to \"stateful\" if\n-        `enable_tf_random_generator` has been activated, or to\n+        \"legacy_stateful\". When `None` it uses \"stateful\" if\n+        `enable_tf_random_generator` has been activated, or\n         \"legacy_stateful\" otherwise.\n         - When using \"stateless\", the random ops outputs are constant (the same\n           inputs result in the same outputs).\n@@ -1913,6 +1913,7 @@ class RandomGenerator(tf.__internal__.tracking.AutoTrackable):\n         - \"legacy_stateful\" is backed by TF1 stateful RNG ops\n           (e.g. `tf.random.uniform`), while \"stateful\"\n           is backed by TF2 APIs (e.g. `tf.random.Generator.uniform`).\n+        Defaults to `None`.\n     \"\"\"\n \n     RNG_STATELESS = \"stateless\"\n@@ -6898,11 +6899,11 @@ def random_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n     Args:\n         shape: A tuple of integers, the shape of tensor to create.\n         mean: A float, the mean value of the normal distribution to draw\n-          samples. Default to 0.0.\n+          samples. Defaults to `0.0`.\n         stddev: A float, the standard deviation of the normal distribution\n-          to draw samples. Default to 1.0.\n-        dtype: `tf.dtypes.DType`, dtype of returned tensor. Default to use Keras\n-          backend dtype which is float32.\n+          to draw samples. Defaults to `1.0`.\n+        dtype: `tf.dtypes.DType`, dtype of returned tensor. None uses Keras\n+          backend dtype which is float32. Defaults to `None`.\n         seed: Integer, random seed. Will use a random numpy integer when not\n           specified.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4869fc251cb2d887ce31cb1ded764b8a1cca2db7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 4 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 847 | Contributors (this commit): 23 | Commits (past 90d): 1 | Contributors (cumulative): 23 | DMM Complexity: None\n\nDIFF:\n@@ -58,17 +58,17 @@ def load_data(\n           ranked by how often they occur (in the training set) and only\n           the `num_words` most frequent words are kept. Any less frequent word\n           will appear as `oov_char` value in the sequence data. If None,\n-          all words are kept. Defaults to None, so all words are kept.\n+          all words are kept. Defaults to `None`.\n       skip_top: skip the top N most frequently occurring words\n           (which may not be informative). These words will appear as\n-          `oov_char` value in the dataset. Defaults to 0, so no words are\n-          skipped.\n+          `oov_char` value in the dataset. When 0, no words are\n+          skipped. Defaults to `0`.\n       maxlen: int or None. Maximum sequence length.\n-          Any longer sequence will be truncated. Defaults to None, which\n-          means no truncation.\n+          Any longer sequence will be truncated. None, means no truncation.\n+          Defaults to `None`.\n       seed: int. Seed for reproducible data shuffling.\n       start_char: int. The start of a sequence will be marked with this\n-          character. Defaults to 1 because 0 is usually the padding character.\n+          character. 0 is usually the padding character. Defaults to `1`.\n       oov_char: int. The out-of-vocabulary character.\n           Words that were cut out because of the `num_words` or\n           `skip_top` limits will be replaced with this character.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
