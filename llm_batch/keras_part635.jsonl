{"custom_id": "keras#2a6d247f7827fe86f0efe1d1a5836632cf06101c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 229 | Lines Deleted: 0 | Files Changed: 4 | Hunks: 3 | Methods Changed: 9 | Complexity Δ (Sum/Max): 13/5 | Churn Δ: 229 | Churn Cumulative: 229 | Contributors (this commit): 1 | Commits (past 90d): 4 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n\n@@ -0,0 +1,36 @@\n+import time\n+\n+import numpy as np\n+import torch\n+\n+\n+def train_loop(model, train_loader, num_epochs, optimizer, loss_fn, framework):\n+    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n+    model.to(device)\n+    start = None\n+    average_batch_time_per_epoch = []\n+    for _ in range(num_epochs):\n+        running_loss = 0.0\n+        for batch_idx, (inputs, targets) in enumerate(train_loader):\n+            if batch_idx == 1:\n+                start = time.time()\n+            inputs = inputs.to(device)\n+            targets = targets.to(device)\n+            # Forward pass\n+            outputs = model(inputs)\n+            loss = loss_fn(outputs, targets)\n+\n+            # Backward and optimize\n+            optimizer.zero_grad()\n+            loss.backward()\n+            optimizer.step()\n+\n+            running_loss += loss.item()\n+\n+        end = time.time()\n+        average_batch_time_per_epoch.append(\n+            (end - start) / (len(train_loader) - 1)\n+        )\n+    average_time = np.mean(average_batch_time_per_epoch)\n+\n+    print(f\"Time per batch in {framework}: {average_time:.2f}\")\n\n@@ -0,0 +1,97 @@\n+\"\"\"Benchmark Keras performance with torch custom training loop.\n+\n+In this file we use a convolution model. Training loop is written in the\n+vanilla torch way, and we compare the performance between building model with\n+Keras and torch.\n+\"\"\"\n+import numpy as np\n+import torch\n+import torch.nn as nn\n+import torch.optim as optim\n+\n+import keras_core\n+from benchmarks.torch_ctl_benchmark.benchmark_utils import train_loop\n+from keras_core import layers\n+\n+num_classes = 2\n+input_shape = (3, 256, 256)\n+batch_size = 128\n+num_batches = 20\n+num_epochs = 1\n+\n+x_train = np.random.normal(\n+    size=(num_batches * batch_size, *input_shape)\n+).astype(np.float32)\n+y_train = np.random.randint(0, num_classes, size=(num_batches * batch_size,))\n+\n+# Create a TensorDataset\n+dataset = torch.utils.data.TensorDataset(\n+    torch.from_numpy(x_train), torch.from_numpy(y_train)\n+)\n+# Create a DataLoader\n+train_loader = torch.utils.data.DataLoader(\n+    dataset, batch_size=batch_size, shuffle=False\n+)\n+\n+\n+class TorchModel(torch.nn.Module):\n+    def __init__(self):\n+        super().__init__()\n+\n+        self.conv = torch.nn.Conv2d(3, 32, kernel_size=(3, 3))\n+        self.activation = torch.nn.ReLU()\n+        self.max_pool = torch.nn.MaxPool2d((2, 2))\n+        self.flatten = torch.nn.Flatten()\n+        self.dense = torch.nn.LazyLinear(num_classes)\n+        self.softmax = torch.nn.Softmax(dim=1)\n+\n+    def forward(self, x):\n+        x = self.conv(x)\n+        x = self.activation(x)\n+        x = self.max_pool(x)\n+        x = self.flatten(x)\n+        x = self.dense(x)\n+        x = self.softmax(x)\n+        return x\n+\n+\n+def run_keras_core_custom_training_loop():\n+    keras_model = keras_core.Sequential(\n+        [\n+            layers.Input(shape=input_shape),\n+            layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n+            layers.MaxPooling2D(pool_size=(2, 2)),\n+            layers.Flatten(),\n+            layers.Dense(num_classes),\n+            layers.Softmax(),\n+        ]\n+    )\n+    optimizer = optim.Adam(keras_model.parameters(), lr=0.001)\n+    loss_fn = nn.CrossEntropyLoss()\n+    train_loop(\n+        keras_model,\n+        train_loader,\n+        num_epochs=num_epochs,\n+        optimizer=optimizer,\n+        loss_fn=loss_fn,\n+        framework=\"keras_core\",\n+    )\n+\n+\n+def run_torch_custom_training_loop():\n+    torch_model = TorchModel()\n+    optimizer = optim.Adam(torch_model.parameters(), lr=0.001)\n+    loss_fn = nn.CrossEntropyLoss()\n+    train_loop(\n+        torch_model,\n+        train_loader,\n+        num_epochs=num_epochs,\n+        optimizer=optimizer,\n+        loss_fn=loss_fn,\n+        framework=\"torch\",\n+    )\n+\n+\n+if __name__ == \"__main__\":\n+    run_keras_core_custom_training_loop()\n+    run_torch_custom_training_loop()\n\n@@ -0,0 +1,96 @@\n+\"\"\"Benchmark Keras performance with torch custom training loop.\n+\n+In this file we use a model with 3 dense layers. Training loop is written in the\n+vanilla torch way, and we compare the performance between building model with\n+Keras and torch.\n+\"\"\"\n+import numpy as np\n+import torch\n+import torch.nn as nn\n+import torch.optim as optim\n+\n+import keras_core\n+from benchmarks.torch_ctl_benchmark.benchmark_utils import train_loop\n+from keras_core import layers\n+\n+num_classes = 2\n+input_shape = (8192,)\n+batch_size = 4096\n+num_batches = 20\n+num_epochs = 1\n+\n+x_train = np.random.normal(\n+    size=(num_batches * batch_size, *input_shape)\n+).astype(np.float32)\n+y_train = np.random.randint(0, num_classes, size=(num_batches * batch_size,))\n+\n+# Create a TensorDataset\n+dataset = torch.utils.data.TensorDataset(\n+    torch.from_numpy(x_train), torch.from_numpy(y_train)\n+)\n+# Create a DataLoader\n+train_loader = torch.utils.data.DataLoader(\n+    dataset, batch_size=batch_size, shuffle=False\n+)\n+\n+\n+class TorchModel(torch.nn.Module):\n+    def __init__(self):\n+        super().__init__()\n+\n+        self.dense1 = torch.nn.Linear(8192, 64)\n+        self.activation1 = torch.nn.ReLU()\n+        self.dense2 = torch.nn.Linear(64, 8)\n+        self.activation2 = torch.nn.ReLU()\n+        self.dense3 = torch.nn.Linear(8, num_classes)\n+        self.softmax = torch.nn.Softmax(dim=1)\n+\n+    def forward(self, x):\n+        x = self.dense1(x)\n+        x = self.activation1(x)\n+        x = self.dense2(x)\n+        x = self.activation2(x)\n+        x = self.dense3(x)\n+        x = self.softmax(x)\n+        return x\n+\n+\n+def run_keras_core_custom_training_loop():\n+    keras_model = keras_core.Sequential(\n+        [\n+            layers.Input(shape=input_shape),\n+            layers.Dense(64, activation=\"relu\"),\n+            layers.Dense(8, activation=\"relu\"),\n+            layers.Dense(num_classes),\n+            layers.Softmax(),\n+        ]\n+    )\n+    optimizer = optim.Adam(keras_model.parameters(), lr=0.001)\n+    loss_fn = nn.CrossEntropyLoss()\n+    train_loop(\n+        keras_model,\n+        train_loader,\n+        num_epochs=num_epochs,\n+        optimizer=optimizer,\n+        loss_fn=loss_fn,\n+        framework=\"keras_core\",\n+    )\n+\n+\n+def run_torch_custom_training_loop():\n+    torch_model = TorchModel()\n+    optimizer = optim.Adam(torch_model.parameters(), lr=0.001)\n+    loss_fn = nn.CrossEntropyLoss()\n+    train_loop(\n+        torch_model,\n+        train_loader,\n+        num_epochs=num_epochs,\n+        optimizer=optimizer,\n+        loss_fn=loss_fn,\n+        framework=\"torch\",\n+    )\n+\n+\n+if __name__ == \"__main__\":\n+    run_keras_core_custom_training_loop()\n+    run_torch_custom_training_loop()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#594b8087ba0cae8ec40ae63522842c93e7f1dad2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 26 | Lines Deleted: 5 | Files Changed: 4 | Hunks: 9 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 31 | Churn Cumulative: 928 | Contributors (this commit): 5 | Commits (past 90d): 18 | Contributors (cumulative): 12 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1,3 +1,22 @@\n+from keras_core.utils.dataset_utils import audio_dataset_from_directory\n+from keras_core.utils.dataset_utils import image_dataset_from_directory\n+from keras_core.utils.dataset_utils import split_dataset\n+from keras_core.utils.dataset_utils import text_dataset_from_directory\n+from keras_core.utils.dataset_utils import timeseries_dataset_from_array\n+from keras_core.utils.file_utils import get_file\n+from keras_core.utils.image_utils import array_to_img\n+from keras_core.utils.image_utils import img_to_array\n+from keras_core.utils.image_utils import load_img\n+from keras_core.utils.image_utils import save_img\n+from keras_core.utils.io_utils import disable_interactive_logging\n+from keras_core.utils.io_utils import enable_interactive_logging\n+from keras_core.utils.io_utils import is_interactive_logging_enabled\n+from keras_core.utils.model_visualization import model_to_dot\n+from keras_core.utils.model_visualization import plot_model\n+from keras_core.utils.numerical_utils import normalize\n+from keras_core.utils.numerical_utils import to_categorical\n+from keras_core.utils.progbar import Progbar\n from keras_core.utils.python_utils import default\n from keras_core.utils.python_utils import is_default\n from keras_core.utils.rng_utils import set_random_seed\n+from keras_core.utils.sequence_utils import pad_sequences\n\n@@ -4,7 +4,6 @@ import os\n import sys\n \n from keras_core.api_export import keras_core_export\n-from keras_core.operations.function import make_node_key\n from keras_core.utils import io_utils\n \n try:\n@@ -202,6 +201,7 @@ def model_to_dot(\n         a `pydot.Cluster` instance representing nested model if\n         `subgraph=True`.\n     \"\"\"\n+    from keras_core.operations.function import make_node_key\n \n     if not model.built:\n         raise ValueError(\n\n@@ -1,7 +1,6 @@\n import numpy as np\n \n from keras_core import backend\n-from keras_core import operations as ops\n from keras_core.api_export import keras_core_export\n \n \n@@ -20,6 +19,8 @@ def normalize(x, axis=-1, order=2):\n     Returns:\n         A normalized copy of the array.\n     \"\"\"\n+    from keras_core import operations as ops\n+\n     if not isinstance(order, int) or not order >= 1:\n         raise ValueError(\n             \"Argument `order` must be an int >= 1. \" f\"Received: order={order}\"\n\n@@ -3,7 +3,8 @@ import os\n import sys\n import time\n \n-from keras_core import operations as ops\n+import numpy as np\n+\n from keras_core.api_export import keras_core_export\n from keras_core.utils import io_utils\n \n@@ -158,7 +159,7 @@ class Progbar:\n             for k in self._values_order:\n                 info += f\" - {k}:\"\n                 if isinstance(self._values[k], list):\n-                    avg = ops.mean(\n+                    avg = np.mean(\n                         self._values[k][0] / max(1, self._values[k][1])\n                     )\n                     if abs(avg) > 1e-3:\n@@ -187,7 +188,7 @@ class Progbar:\n                 info += \" -\" + self._format_time(time_per_unit, self.unit_name)\n                 for k in self._values_order:\n                     info += f\" - {k}:\"\n-                    avg = ops.mean(\n+                    avg = np.mean(\n                         self._values[k][0] / max(1, self._values[k][1])\n                     )\n                     if avg > 1e-3:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#90baabee5ddd808fc95060dce1b40f1b586ce2f9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 75 | Lines Deleted: 1 | Files Changed: 9 | Hunks: 10 | Methods Changed: 11 | Complexity Δ (Sum/Max): 10/4 | Churn Δ: 76 | Churn Cumulative: 4040 | Contributors (this commit): 12 | Commits (past 90d): 192 | Contributors (cumulative): 58 | DMM Complexity: 1.0\n\nDIFF:\n@@ -15,6 +15,7 @@ from keras_core.backend.jax.core import is_tensor\n from keras_core.backend.jax.core import name_scope\n from keras_core.backend.jax.core import scatter\n from keras_core.backend.jax.core import shape\n+from keras_core.backend.jax.core import stop_gradient\n from keras_core.backend.jax.core import vectorized_map\n from keras_core.backend.jax.rnn import gru\n from keras_core.backend.jax.rnn import lstm\n\n@@ -242,3 +242,7 @@ def while_loop(\n     if maximum_iterations is not None:\n         outputs = outputs[:-1]\n     return outputs\n+\n+\n+def stop_gradient(variable):\n+    return jax.lax.stop_gradient(variable)\n\n@@ -16,6 +16,7 @@ from keras_core.backend.tensorflow.core import is_tensor\n from keras_core.backend.tensorflow.core import name_scope\n from keras_core.backend.tensorflow.core import scatter\n from keras_core.backend.tensorflow.core import shape\n+from keras_core.backend.tensorflow.core import stop_gradient\n from keras_core.backend.tensorflow.core import vectorized_map\n from keras_core.backend.tensorflow.rnn import gru\n from keras_core.backend.tensorflow.rnn import lstm\n\n@@ -157,3 +157,7 @@ def while_loop(\n         loop_vars,\n         maximum_iterations=maximum_iterations,\n     )\n+\n+\n+def stop_gradient(variable):\n+    return tf.stop_gradient(variable)\n\n@@ -15,6 +15,7 @@ from keras_core.backend.torch.core import is_tensor\n from keras_core.backend.torch.core import name_scope\n from keras_core.backend.torch.core import scatter\n from keras_core.backend.torch.core import shape\n+from keras_core.backend.torch.core import stop_gradient\n from keras_core.backend.torch.core import to_torch_dtype\n from keras_core.backend.torch.core import vectorized_map\n from keras_core.backend.torch.rnn import gru\n\n@@ -274,3 +274,7 @@ def while_loop(\n         loop_vars = tuple(loop_vars)\n         current_iter += 1\n     return loop_vars\n+\n+\n+def stop_gradient(variable):\n+    return variable.requires_grad_(False)\n\n@@ -189,3 +189,36 @@ def while_loop(\n         loop_vars,\n         maximum_iterations=maximum_iterations,\n     )\n+\n+\n+class StopGradient(Operation):\n+    def __init__(self):\n+        super().__init__()\n+\n+    def call(self, variable):\n+        return backend.core.stop_gradient(variable)\n+\n+    def compute_output_spec(self, variable):\n+        return KerasTensor(variable.shape, dtype=variable.dtype)\n+\n+\n+@keras_core_export(\"keras_core.operations.stop_gradient\")\n+def stop_gradient(variable):\n+    \"\"\"Stops gradient computation.\n+\n+    Args:\n+        variable: A tensor variable for which the gradient\n+            computation is to be disabled.\n+\n+    Returns:\n+        The variable with gradient computation disabled.\n+\n+    Examples:\n+\n+    >>> var = keras_core.backend.convert_to_tensor(\n+    ...     [1., 2., 3.],\n+    ...     dtype=\"float32\"\n+    ... )\n+    >>> var = keras_core.operations.stop_gradient(var)\n+    \"\"\"\n+    return backend.core.stop_gradient(variable)\n\n@@ -1,5 +1,10 @@\n import numpy as np\n \n+from keras_core import layers\n+from keras_core import losses\n+from keras_core import models\n+from keras_core import operations as ops\n+from keras_core import optimizers\n from keras_core import testing\n from keras_core.backend.common.keras_tensor import KerasTensor\n from keras_core.operations import core\n@@ -158,3 +163,24 @@ class CoreOpsCorrectnessTest(testing.TestCase):\n         x, y = core.while_loop(cond, body, (x, y), maximum_iterations=5)\n         self.assertAllClose(x, np.ones((2, 3)) * 6)\n         self.assertAllClose(y, np.ones((3, 2)) * 6)\n+\n+    def test_stop_gradient(self):\n+        class ExampleLayer(layers.Layer):\n+            def __init__(self):\n+                super().__init__()\n+                self.w = self.add_weight(shape=(1,), initializer=\"zeros\")\n+                self.b = self.add_weight(shape=(1,), initializer=\"zeros\")\n+\n+            def call(self, x, training=False):\n+                return x * ops.stop_gradient(self.w.value) + self.b\n+\n+        model = models.Sequential([ExampleLayer()])\n+        model.compile(\n+            optimizer=optimizers.SGD(), loss=losses.MeanSquaredError()\n+        )\n+        rng = np.random.default_rng(0)\n+        x = np.ones((2, 4), dtype=np.float32)\n+        y = rng.standard_normal((2, 4), dtype=np.float32)\n+        model.fit(x, y, epochs=1, batch_size=2)\n+        self.assertEqual(model.layers[0].w.numpy(), 0.0)\n+        self.assertNotEqual(model.layers[0].b.numpy(), 0.0)\n\n@@ -22,7 +22,7 @@ class Resize(Operation):\n     def call(self, image):\n         return backend.image.resize(\n             image,\n-            self.shape,\n+            self.size,\n             method=self.method,\n             antialias=self.antialias,\n             data_format=self.data_format,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f7dccb740a3f40cbecb2609f9e303aa4689c8c56", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 349 | Contributors (this commit): 3 | Commits (past 90d): 5 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -49,7 +49,7 @@ class BatchNormalizationDTensorTest(test_util.DTensorBaseTest):\n         self.mesh = self.configTestMesh(mesh_dict)\n \n     def test_strategy_backed_by_dtensor(self):\n-        strategy = dtensor_mirrored_strategy.MirroredStrategy(self.mesh)\n+        strategy = dtensor_mirrored_strategy.MirroredStrategy(mesh=self.mesh)\n \n         with strategy.scope():\n             self.assertTrue(utils.running_with_dtensor_strategy())\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b061f40b1d9911fc6b0958868de6213b38ed37ec", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 239/239 | Churn Δ: 2 | Churn Cumulative: 8042 | Contributors (this commit): 15 | Commits (past 90d): 2 | Contributors (cumulative): 15 | DMM Complexity: None\n\nDIFF:\n@@ -2415,7 +2415,7 @@ class TestCTC(tf.test.TestCase):\n         log_prob_pred = backend.eval(log_prob_pred_tf)\n         for i in range(top_paths):\n             self.assertTrue(\n-                np.alltrue(decode_truth[i] == backend.eval(decode_pred_tf[i]))\n+                np.all(decode_truth[i] == backend.eval(decode_pred_tf[i]))\n             )\n         self.assertAllClose(log_prob_truth, log_prob_pred)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#01598234b4131cb46fabe5a2e9c71673355d4a49", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 32 | Lines Deleted: 6 | Files Changed: 3 | Hunks: 6 | Methods Changed: 5 | Complexity Δ (Sum/Max): 3/2 | Churn Δ: 38 | Churn Cumulative: 421 | Contributors (this commit): 2 | Commits (past 90d): 12 | Contributors (cumulative): 4 | DMM Complexity: 0.8666666666666667\n\nDIFF:\n@@ -18,12 +18,13 @@ class MyDense(layers.Layer):\n \n     def build(self, input_shape):\n         input_dim = input_shape[-1]\n-        w_shape = (input_dim, self.units)\n-        w_value = initializers.GlorotUniform()(w_shape)\n-        # State must be stored in backend.Variable objects.\n-        self.w = backend.Variable(w_value, name=\"kernel\", trainable=True)\n+        self.w = self.add_weight(\n+            shape=(input_dim, self.units),\n+            initializer=initializers.GlorotNormal(),\n+            name=\"kernel\",\n+            trainable=True,\n+        )\n \n-        # You can also use add_weight\n         self.b = self.add_weight(\n             shape=(self.units,),\n             initializer=initializers.Zeros(),\n\n@@ -43,13 +43,35 @@ model = keras_core.Sequential(\n ######## Writing a torch training loop for a Keras model ########\n #################################################################\n \n+def get_keras_model():\n+    pass\n+\n+model = get_keras_model()\n+\n # Instantiate the torch optimizer\n-print(\"Num params:\", len(list(model.parameters())))\n optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n \n # Instantiate the torch loss function\n loss_fn = nn.CrossEntropyLoss()\n \n+def train_step(data):\n+    x, y = data\n+    y_pred = model(x)\n+    loss = loss_fn(y_pred, y)\n+    optimizer.zero_grad()\n+    loss.backward()\n+    optimizer.step()\n+    return loss\n+\n+# Create a TensorDataset\n+dataset = torch.utils.data.TensorDataset(\n+    torch.from_numpy(x_train), torch.from_numpy(y_train)\n+)\n+\n+for data in dataset:\n+    loss = train_step(data)\n+    print(\"Loss:\", float(loss))\n+\n \n def train(model, train_loader, num_epochs, optimizer, loss_fn):\n     for epoch in range(num_epochs):\n\n@@ -142,6 +142,9 @@ def inject_argument_info_in_traceback(fn, object_name=None):\n     \"\"\"\n \n     def error_handler(*args, **kwargs):\n+        if not is_traceback_filtering_enabled():\n+            return fn(*args, **kwargs)\n+\n         signature = None\n         bound_signature = None\n         try:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a4070caf47e9e6c35fae199fed5014b22e421f08", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 413 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 12 | Complexity Δ (Sum/Max): 13/13 | Churn Δ: 413 | Churn Cumulative: 413 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,413 @@\n+\"\"\"\n+Title: Image similarity estimation using a Siamese Network with a triplet loss\n+Authors: [Hazem Essam](https://twitter.com/hazemessamm) and [Santiago L. Valdarrama](https://twitter.com/svpino)\n+Date created: 2021/03/25\n+Last modified: 2021/03/25\n+Description: Training a Siamese Network to compare the similarity of images using a triplet loss function.\n+Accelerator: GPU\n+\"\"\"\n+\n+\"\"\"\n+## Introduction\n+\n+A [Siamese Network](https://en.wikipedia.org/wiki/Siamese_neural_network) is a type of network architecture that\n+contains two or more identical subnetworks used to generate feature vectors for each input and compare them.\n+\n+Siamese Networks can be applied to different use cases, like detecting duplicates, finding anomalies, and face recognition.\n+\n+This example uses a Siamese Network with three identical subnetworks. We will provide three images to the model, where\n+two of them will be similar (_anchor_ and _positive_ samples), and the third will be unrelated (a _negative_ example.)\n+Our goal is for the model to learn to estimate the similarity between images.\n+\n+For the network to learn, we use a triplet loss function. You can find an introduction to triplet loss in the\n+[FaceNet paper](https://arxiv.org/pdf/1503.03832.pdf) by Schroff et al,. 2015. In this example, we define the triplet\n+loss function as follows:\n+\n+`L(A, P, N) = max(‖f(A) - f(P)‖² - ‖f(A) - f(N)‖² + margin, 0)`\n+\n+This example uses the [Totally Looks Like dataset](https://sites.google.com/view/totally-looks-like-dataset)\n+by [Rosenfeld et al., 2018](https://arxiv.org/pdf/1803.01485v3.pdf).\n+\"\"\"\n+\n+\"\"\"\n+## Setup\n+\"\"\"\n+\n+import matplotlib.pyplot as plt\n+import numpy as np\n+import os\n+import tensorflow as tf\n+from pathlib import Path\n+from keras_core import layers\n+from keras_core import optimizers\n+from keras_core import metrics\n+from keras_core import Model\n+from keras_core.applications import resnet\n+\n+\n+target_shape = (200, 200)\n+\n+\n+\"\"\"\n+## Load the dataset\n+\n+We are going to load the *Totally Looks Like* dataset and unzip it inside the `~/.keras` directory\n+in the local environment.\n+\n+The dataset consists of two separate files:\n+\n+* `left.zip` contains the images that we will use as the anchor.\n+* `right.zip` contains the images that we will use as the positive sample (an image that looks like the anchor).\n+\"\"\"\n+\n+cache_dir = Path(Path.home()) / \".keras\"\n+anchor_images_path = cache_dir / \"left\"\n+positive_images_path = cache_dir / \"right\"\n+\n+\"\"\"shell\n+gdown --id 1jvkbTr_giSP3Ru8OwGNCg6B4PvVbcO34\n+gdown --id 1EzBZUb_mh_Dp_FKD0P4XiYYSd0QBH5zW\n+unzip -oq left.zip -d $cache_dir\n+unzip -oq right.zip -d $cache_dir\n+\"\"\"\n+\n+\"\"\"\n+## Preparing the data\n+\n+We are going to use a `tf.data` pipeline to load the data and generate the triplets that we\n+need to train the Siamese network.\n+\n+We'll set up the pipeline using a zipped list with anchor, positive, and negative filenames as\n+the source. The pipeline will load and preprocess the corresponding images.\n+\"\"\"\n+\n+\n+def preprocess_image(filename):\n+    \"\"\"\n+    Load the specified file as a JPEG image, preprocess it and\n+    resize it to the target shape.\n+    \"\"\"\n+\n+    image_string = tf.io.read_file(filename)\n+    image = tf.image.decode_jpeg(image_string, channels=3)\n+    image = tf.image.convert_image_dtype(image, tf.float32)\n+    image = tf.image.resize(image, target_shape)\n+    return image\n+\n+\n+def preprocess_triplets(anchor, positive, negative):\n+    \"\"\"\n+    Given the filenames corresponding to the three images, load and\n+    preprocess them.\n+    \"\"\"\n+\n+    return (\n+        preprocess_image(anchor),\n+        preprocess_image(positive),\n+        preprocess_image(negative),\n+    )\n+\n+\n+\"\"\"\n+Let's setup our data pipeline using a zipped list with an anchor, positive,\n+and negative image filename as the source. The output of the pipeline\n+contains the same triplet with every image loaded and preprocessed.\n+\"\"\"\n+\n+# We need to make sure both the anchor and positive images are loaded in\n+# sorted order so we can match them together.\n+anchor_images = sorted(\n+    [str(anchor_images_path / f) for f in os.listdir(anchor_images_path)]\n+)\n+\n+positive_images = sorted(\n+    [str(positive_images_path / f) for f in os.listdir(positive_images_path)]\n+)\n+\n+image_count = len(anchor_images)\n+\n+anchor_dataset = tf.data.Dataset.from_tensor_slices(anchor_images)\n+positive_dataset = tf.data.Dataset.from_tensor_slices(positive_images)\n+\n+# To generate the list of negative images, let's randomize the list of\n+# available images and concatenate them together.\n+rng = np.random.RandomState(seed=42)\n+rng.shuffle(anchor_images)\n+rng.shuffle(positive_images)\n+\n+negative_images = anchor_images + positive_images\n+np.random.RandomState(seed=32).shuffle(negative_images)\n+\n+negative_dataset = tf.data.Dataset.from_tensor_slices(negative_images)\n+negative_dataset = negative_dataset.shuffle(buffer_size=4096)\n+\n+dataset = tf.data.Dataset.zip((anchor_dataset, positive_dataset, negative_dataset))\n+dataset = dataset.shuffle(buffer_size=1024)\n+dataset = dataset.map(preprocess_triplets)\n+\n+# Let's now split our dataset in train and validation.\n+train_dataset = dataset.take(round(image_count * 0.8))\n+val_dataset = dataset.skip(round(image_count * 0.8))\n+\n+train_dataset = train_dataset.batch(32, drop_remainder=False)\n+train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n+\n+val_dataset = val_dataset.batch(32, drop_remainder=False)\n+val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)\n+\n+\n+\"\"\"\n+Let's take a look at a few examples of triplets. Notice how the first two images\n+look alike while the third one is always different.\n+\"\"\"\n+\n+\n+def visualize(anchor, positive, negative):\n+    \"\"\"Visualize a few triplets from the supplied batches.\"\"\"\n+\n+    def show(ax, image):\n+        ax.imshow(image)\n+        ax.get_xaxis().set_visible(False)\n+        ax.get_yaxis().set_visible(False)\n+\n+    fig = plt.figure(figsize=(9, 9))\n+\n+    axs = fig.subplots(3, 3)\n+    for i in range(3):\n+        show(axs[i, 0], anchor[i])\n+        show(axs[i, 1], positive[i])\n+        show(axs[i, 2], negative[i])\n+\n+\n+visualize(*list(train_dataset.take(1).as_numpy_iterator())[0])\n+\n+\"\"\"\n+## Setting up the embedding generator model\n+\n+Our Siamese Network will generate embeddings for each of the images of the\n+triplet. To do this, we will use a ResNet50 model pretrained on ImageNet and\n+connect a few `Dense` layers to it so we can learn to separate these\n+embeddings.\n+\n+We will freeze the weights of all the layers of the model up until the layer `conv5_block1_out`.\n+This is important to avoid affecting the weights that the model has already learned.\n+We are going to leave the bottom few layers trainable, so that we can fine-tune their weights\n+during training.\n+\"\"\"\n+\n+base_cnn = resnet.ResNet50(\n+    weights=\"imagenet\", input_shape=target_shape + (3,), include_top=False\n+)\n+\n+flatten = layers.Flatten()(base_cnn.output)\n+dense1 = layers.Dense(512, activation=\"relu\")(flatten)\n+dense1 = layers.BatchNormalization()(dense1)\n+dense2 = layers.Dense(256, activation=\"relu\")(dense1)\n+dense2 = layers.BatchNormalization()(dense2)\n+output = layers.Dense(256)(dense2)\n+\n+embedding = Model(base_cnn.input, output, name=\"Embedding\")\n+\n+trainable = False\n+for layer in base_cnn.layers:\n+    if layer.name == \"conv5_block1_out\":\n+        trainable = True\n+    layer.trainable = trainable\n+\n+\"\"\"\n+## Setting up the Siamese Network model\n+\n+The Siamese network will receive each of the triplet images as an input,\n+generate the embeddings, and output the distance between the anchor and the\n+positive embedding, as well as the distance between the anchor and the negative\n+embedding.\n+\n+To compute the distance, we can use a custom layer `DistanceLayer` that\n+returns both values as a tuple.\n+\"\"\"\n+\n+\n+class DistanceLayer(layers.Layer):\n+    \"\"\"\n+    This layer is responsible for computing the distance between the anchor\n+    embedding and the positive embedding, and the anchor embedding and the\n+    negative embedding.\n+    \"\"\"\n+\n+    def __init__(self, **kwargs):\n+        super().__init__(**kwargs)\n+\n+    def call(self, anchor, positive, negative):\n+        ap_distance = tf.reduce_sum(tf.square(anchor - positive), -1)\n+        an_distance = tf.reduce_sum(tf.square(anchor - negative), -1)\n+        return (ap_distance, an_distance)\n+\n+\n+anchor_input = layers.Input(name=\"anchor\", shape=target_shape + (3,))\n+positive_input = layers.Input(name=\"positive\", shape=target_shape + (3,))\n+negative_input = layers.Input(name=\"negative\", shape=target_shape + (3,))\n+\n+distances = DistanceLayer()(\n+    embedding(resnet.preprocess_input(anchor_input)),\n+    embedding(resnet.preprocess_input(positive_input)),\n+    embedding(resnet.preprocess_input(negative_input)),\n+)\n+\n+siamese_network = Model(\n+    inputs=[anchor_input, positive_input, negative_input], outputs=distances\n+)\n+\n+\"\"\"\n+## Putting everything together\n+\n+We now need to implement a model with custom training loop so we can compute\n+the triplet loss using the three embeddings produced by the Siamese network.\n+\n+Let's create a `Mean` metric instance to track the loss of the training process.\n+\"\"\"\n+\n+\n+class SiameseModel(Model):\n+    \"\"\"The Siamese Network model with a custom training and testing loops.\n+\n+    Computes the triplet loss using the three embeddings produced by the\n+    Siamese Network.\n+\n+    The triplet loss is defined as:\n+       L(A, P, N) = max(‖f(A) - f(P)‖² - ‖f(A) - f(N)‖² + margin, 0)\n+    \"\"\"\n+\n+    def __init__(self, siamese_network, margin=0.5):\n+        super().__init__()\n+        self.siamese_network = siamese_network\n+        self.margin = margin\n+        self.loss_tracker = metrics.Mean(name=\"loss\")\n+\n+    def call(self, inputs):\n+        return self.siamese_network(inputs)\n+\n+    def train_step(self, data):\n+        # GradientTape is a context manager that records every operation that\n+        # you do inside. We are using it here to compute the loss so we can get\n+        # the gradients and apply them using the optimizer specified in\n+        # `compile()`.\n+        with tf.GradientTape() as tape:\n+            loss = self._compute_loss(data)\n+\n+        # Storing the gradients of the loss function with respect to the\n+        # weights/parameters.\n+        gradients = tape.gradient(loss, self.siamese_network.trainable_weights)\n+\n+        # Applying the gradients on the model using the specified optimizer\n+        self.optimizer.apply_gradients(\n+            zip(gradients, self.siamese_network.trainable_weights)\n+        )\n+\n+        # Let's update and return the training loss metric.\n+        self.loss_tracker.update_state(loss)\n+        return {\"loss\": self.loss_tracker.result()}\n+\n+    def test_step(self, data):\n+        loss = self._compute_loss(data)\n+\n+        # Let's update and return the loss metric.\n+        self.loss_tracker.update_state(loss)\n+        return {\"loss\": self.loss_tracker.result()}\n+\n+    def _compute_loss(self, data):\n+        # The output of the network is a tuple containing the distances\n+        # between the anchor and the positive example, and the anchor and\n+        # the negative example.\n+        ap_distance, an_distance = self.siamese_network(data)\n+\n+        # Computing the Triplet Loss by subtracting both distances and\n+        # making sure we don't get a negative value.\n+        loss = ap_distance - an_distance\n+        loss = tf.maximum(loss + self.margin, 0.0)\n+        return loss\n+\n+    @property\n+    def metrics(self):\n+        # We need to list our metrics here so the `reset_states()` can be\n+        # called automatically.\n+        return [self.loss_tracker]\n+\n+\n+\"\"\"\n+## Training\n+\n+We are now ready to train our model.\n+\"\"\"\n+\n+siamese_model = SiameseModel(siamese_network)\n+siamese_model.compile(optimizer=optimizers.Adam(0.0001))\n+siamese_model.fit(train_dataset, epochs=10, validation_data=val_dataset)\n+\n+\"\"\"\n+## Inspecting what the network has learned\n+\n+At this point, we can check how the network learned to separate the embeddings\n+depending on whether they belong to similar images.\n+\n+We can use [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity) to measure the\n+similarity between embeddings.\n+\n+Let's pick a sample from the dataset to check the similarity between the\n+embeddings generated for each image.\n+\"\"\"\n+sample = next(iter(train_dataset))\n+visualize(*sample)\n+\n+anchor, positive, negative = sample\n+anchor_embedding, positive_embedding, negative_embedding = (\n+    embedding(resnet.preprocess_input(anchor)),\n+    embedding(resnet.preprocess_input(positive)),\n+    embedding(resnet.preprocess_input(negative)),\n+)\n+\n+\"\"\"\n+Finally, we can compute the cosine similarity between the anchor and positive\n+images and compare it with the similarity between the anchor and the negative\n+images.\n+\n+We should expect the similarity between the anchor and positive images to be\n+larger than the similarity between the anchor and the negative images.\n+\"\"\"\n+\n+cosine_similarity = metrics.CosineSimilarity()\n+\n+positive_similarity = cosine_similarity(anchor_embedding, positive_embedding)\n+print(\"Positive similarity:\", positive_similarity.numpy())\n+\n+negative_similarity = cosine_similarity(anchor_embedding, negative_embedding)\n+print(\"Negative similarity\", negative_similarity.numpy())\n+\n+\n+\"\"\"\n+## Summary\n+\n+1. The `tf.data` API enables you to build efficient input pipelines for your model. It is\n+particularly useful if you have a large dataset. You can learn more about `tf.data`\n+pipelines in [tf.data: Build TensorFlow input pipelines](https://www.tensorflow.org/guide/data).\n+\n+2. In this example, we use a pre-trained ResNet50 as part of the subnetwork that generates\n+the feature embeddings. By using [transfer learning](https://www.tensorflow.org/guide/keras/transfer_learning?hl=en),\n+we can significantly reduce the training time and size of the dataset.\n+\n+3. Notice how we are [fine-tuning](https://www.tensorflow.org/guide/keras/transfer_learning?hl=en#fine-tuning)\n+the weights of the final layers of the ResNet50 network but keeping the rest of the layers untouched.\n+Using the name assigned to each layer, we can freeze the weights to a certain point and keep the last few layers open.\n+\n+4. We can create custom layers by creating a class that inherits from `tf.keras.layers.Layer`,\n+as we did in the `DistanceLayer` class.\n+\n+5. We used a cosine similarity metric to measure how to 2 output embeddings are similar to each other.\n+\n+6. You can implement a custom training loop by overriding the `train_step()` method. `train_step()` uses\n+[`tf.GradientTape`](https://www.tensorflow.org/api_docs/python/tf/GradientTape),\n+which records every operation that you perform inside it. In this example, we use it to access the\n+gradients passed to the optimizer to update the model weights at every step. For more details, check out the\n+[Intro to Keras for researchers](https://keras.io/getting_started/intro_to_keras_for_researchers/)\n+and [Writing a training loop from scratch](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch?hl=en).\n+\n+\"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#abfd47bfa580ce86f951e4a033110bacaad75b7d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 198 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 9 | Complexity Δ (Sum/Max): 12/12 | Churn Δ: 198 | Churn Cumulative: 198 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,198 @@\n+import os\n+import torch\n+import torch.nn as nn\n+import torch.optim as optim\n+from keras_core import layers\n+import keras_core\n+import numpy as np\n+\n+import torch.multiprocessing as mp\n+import torch.distributed as dist\n+from torch.nn.parallel import DistributedDataParallel as DDP\n+from torch.utils.data import DataLoader, Dataset\n+from torch.utils.data.distributed import DistributedSampler\n+\n+# Model / data parameters\n+num_classes = 10\n+input_shape = (28, 28, 1)\n+learning_rate = 0.01\n+batch_size = 128\n+num_epochs = 1\n+\n+def get_data():\n+    # Load the data and split it between train and test sets\n+    (x_train, y_train), (x_test, y_test) = keras_core.datasets.mnist.load_data()\n+\n+    # Scale images to the [0, 1] range\n+    x_train = x_train.astype(\"float32\") / 255\n+    x_test = x_test.astype(\"float32\") / 255\n+    # Make sure images have shape (28, 28, 1)\n+    x_train = np.expand_dims(x_train, -1)\n+    x_test = np.expand_dims(x_test, -1)\n+    print(\"x_train shape:\", x_train.shape)\n+    print(x_train.shape[0], \"train samples\")\n+    print(x_test.shape[0], \"test samples\")\n+\n+    # Create a TensorDataset\n+    dataset = torch.utils.data.TensorDataset(\n+        torch.from_numpy(x_train), torch.from_numpy(y_train)\n+    )\n+    return dataset\n+\n+def get_model():\n+    # Create the Keras model\n+    model = keras_core.Sequential(\n+        [\n+            layers.Input(shape=(28, 28, 1)),\n+            layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n+            layers.MaxPooling2D(pool_size=(2, 2)),\n+            layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n+            layers.MaxPooling2D(pool_size=(2, 2)),\n+            layers.Flatten(),\n+            layers.Dropout(0.5),\n+            layers.Dense(num_classes),\n+        ]\n+    )\n+    return model\n+\n+\n+class MyModel(nn.Module):\n+    def __init__(self):\n+        super().__init__()\n+        self.model = keras_core.Sequential(\n+            [\n+                layers.Input(shape=(28, 28, 1)),\n+                layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n+                layers.MaxPooling2D(pool_size=(2, 2)),\n+                layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n+                layers.MaxPooling2D(pool_size=(2, 2)),\n+                layers.Flatten(),\n+                layers.Dropout(0.5),\n+                layers.Dense(num_classes),\n+            ]\n+        )\n+\n+    def forward(self, x):\n+        return self.model(x)\n+\n+\n+def train(model, train_loader, num_epochs, optimizer, loss_fn):\n+    for epoch in range(num_epochs):\n+        running_loss = 0.0\n+        for batch_idx, (inputs, targets) in enumerate(train_loader):\n+            inputs = inputs.cuda(non_blocking=True)\n+            targets = targets.cuda(non_blocking=True)\n+\n+            # Forward pass\n+            outputs = model(inputs)\n+            loss = loss_fn(outputs, targets)\n+\n+            # Backward and optimize\n+            optimizer.zero_grad()\n+            loss.backward()\n+            optimizer.step()\n+\n+            running_loss += loss.item()\n+\n+            # Print loss statistics\n+            if (batch_idx + 1) % 10 == 0:\n+                print(\n+                    f\"Epoch [{epoch+1}/{num_epochs}], \"\n+                    f\"Batch [{batch_idx+1}/{len(train_loader)}], \"\n+                    f\"Loss: {running_loss / 10}\"\n+                )\n+                running_loss = 0.0\n+\n+def setup(current_gpu_index, num_gpu):\n+    # Device setup\n+    os.environ['MASTER_ADDR'] = 'keras-core-torch'\n+    os.environ['MASTER_PORT'] = '56492'\n+    device = torch.device(\"cuda:{}\".format(current_gpu_index))\n+    dist.init_process_group(\n+        backend='nccl',\n+        init_method='env://',\n+        world_size=num_gpu,\n+        rank=current_gpu_index\n+    )\n+    torch.cuda.set_device(device)\n+\n+\n+def prepare(dataset, current_gpu_index, num_gpu, batch_size):\n+    sampler = DistributedSampler(\n+        dataset,\n+        num_replicas=num_gpu,\n+        rank=current_gpu_index,\n+        shuffle=False,\n+    )\n+\n+    # Create a DataLoader\n+    train_loader = DataLoader(\n+        dataset,\n+        sampler=sampler,\n+        batch_size=batch_size,\n+        shuffle=False,\n+    )\n+\n+    return train_loader\n+\n+def cleanup():\n+    # Cleanup\n+    dist.destroy_process_group()\n+\n+\n+def main(current_gpu_index, num_gpu):\n+    # setup the process groups\n+    setup(current_gpu_index, num_gpu)\n+\n+    #################################################################\n+    ######## Writing a torch training loop for a Keras model ########\n+    #################################################################\n+\n+    dataset = get_data()\n+    model = get_model()\n+\n+    # prepare the dataloader\n+    dataloader = prepare(dataset, current_gpu_index, num_gpu, batch_size)\n+\n+    # Instantiate the torch optimizer\n+    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n+\n+    # Instantiate the torch loss function\n+    loss_fn = nn.CrossEntropyLoss()\n+\n+    # Put model on device\n+    model = model.to(current_gpu_index)\n+    ddp_model = DDP(model, device_ids=[current_gpu_index], output_device=current_gpu_index)\n+\n+    train(ddp_model, dataloader, num_epochs, optimizer, loss_fn)\n+\n+    ################################################################\n+    ######## Using a Keras model or layer in a torch Module ########\n+    ################################################################\n+\n+    torch_module = MyModel().to(current_gpu_index)\n+    ddp_torch_module = DDP(torch_module, device_ids=[current_gpu_index], output_device=current_gpu_index)\n+\n+    # Instantiate the torch optimizer\n+    optimizer = optim.Adam(torch_module.parameters(), lr=learning_rate)\n+\n+    # Instantiate the torch loss function\n+    loss_fn = nn.CrossEntropyLoss()\n+\n+    train(ddp_torch_module, dataloader, num_epochs, optimizer, loss_fn)\n+\n+    cleanup()\n+\n+\n+if __name__ == \"__main__\":\n+    # GPU parameters\n+    num_gpu = torch.cuda.device_count()\n+    \n+    print(f\"Running on {num_gpu} GPUs\")\n+\n+    torch.multiprocessing.spawn(\n+        main,\n+        args=(num_gpu, ),\n+        nprocs=num_gpu,\n+        join=True,\n+    )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3d0af7a0d153238c219d0e6715bd6a63bb66788a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 46 | Lines Deleted: 30 | Files Changed: 2 | Hunks: 6 | Methods Changed: 7 | Complexity Δ (Sum/Max): 6/5 | Churn Δ: 76 | Churn Cumulative: 2372 | Contributors (this commit): 8 | Commits (past 90d): 45 | Contributors (cumulative): 11 | DMM Complexity: 1.0\n\nDIFF:\n@@ -333,28 +333,25 @@ class Functional(Function, Model):\n         config[\"layers\"] = layer_configs\n \n         # Gather info about inputs and outputs.\n-        model_inputs = []\n-        for tensor in self._inputs:\n+        def get_tensor_config(tensor):\n             operation = tensor._keras_history[0]\n             node_index = tensor._keras_history[1]\n             tensor_index = tensor._keras_history[2]\n             node_key = make_node_key(operation, node_index)\n-            if node_key not in self._nodes:\n-                continue\n+            assert node_key in self._nodes\n             new_node_index = node_reindexing_map[node_key]\n-            model_inputs.append([operation.name, new_node_index, tensor_index])\n-        config[\"input_layers\"] = model_inputs\n-        model_outputs = []\n-        for tensor in self._outputs:\n-            operation = tensor._keras_history[0]\n-            node_index = tensor._keras_history[1]\n-            tensor_index = tensor._keras_history[2]\n-            node_key = make_node_key(operation, node_index)\n-            if node_key not in self._nodes:\n-                continue\n-            new_node_index = node_reindexing_map[node_key]\n-            model_outputs.append([operation.name, new_node_index, tensor_index])\n-        config[\"output_layers\"] = model_outputs\n+            return [operation.name, new_node_index, tensor_index]\n+\n+        def map_tensors(tensors):\n+            if isinstance(tensors, dict):\n+                return {k: get_tensor_config(v) for k, v in tensors.items()}\n+            if isinstance(tensors, (list, tuple)):\n+                return [get_tensor_config(v) for v in tensors]\n+            else:\n+                return [get_tensor_config(tensors)]\n+\n+        config[\"input_layers\"] = map_tensors(self._inputs_struct)\n+        config[\"output_layers\"] = map_tensors(self._outputs_struct)\n         return copy.deepcopy(config)\n \n     @classmethod\n@@ -507,24 +504,23 @@ class Functional(Function, Model):\n         # Create lits of input and output tensors and return new class\n         name = config.get(\"name\")\n         trainable = config.get(\"trainable\")\n-        input_tensors = []\n-        output_tensors = []\n-        for layer_data in config[\"input_layers\"]:\n-            layer_name, node_index, tensor_index = layer_data\n+\n+        def get_tensor(layer_name, node_index, tensor_index):\n             assert layer_name in created_layers\n             layer = created_layers[layer_name]\n             layer_output_tensors = layer._inbound_nodes[\n                 node_index\n             ].output_tensors\n-            input_tensors.append(layer_output_tensors[tensor_index])\n-        for layer_data in config[\"output_layers\"]:\n-            layer_name, node_index, tensor_index = layer_data\n-            assert layer_name in created_layers\n-            layer = created_layers[layer_name]\n-            layer_output_tensors = layer._inbound_nodes[\n-                node_index\n-            ].output_tensors\n-            output_tensors.append(layer_output_tensors[tensor_index])\n+            return layer_output_tensors[tensor_index]\n+\n+        def map_tensors(tensors):\n+            if isinstance(tensors, dict):\n+                return {k: get_tensor(*v) for k, v in tensors.items()}\n+            else:\n+                return [get_tensor(*v) for v in tensors]\n+\n+        input_tensors = map_tensors(config[\"input_layers\"])\n+        output_tensors = map_tensors(config[\"output_layers\"])\n         return cls(\n             inputs=input_tensors,\n             outputs=output_tensors,\n\n@@ -188,6 +188,26 @@ class SerializationLibTest(testing.TestCase):\n     #     y2 = new_lmbda(x)\n     #     self.assertAllClose(y1, y2, atol=1e-5)\n \n+    def test_dict_inputs_outputs(self):\n+        input_foo = keras_core.Input((2,), name=\"foo\")\n+        input_bar = keras_core.Input((2,), name=\"bar\")\n+        dense = keras_core.layers.Dense(1)\n+        output_foo = dense(input_foo)\n+        output_bar = dense(input_bar)\n+        model = keras_core.Model(\n+            {\"foo\": input_foo, \"bar\": input_bar},\n+            {\"foo\": output_foo, \"bar\": output_bar},\n+        )\n+        _, new_model, _ = self.roundtrip(model)\n+        original_output = model(\n+            {\"foo\": np.zeros((2, 2)), \"bar\": np.zeros((2, 2))}\n+        )\n+        restored_output = model(\n+            {\"foo\": np.zeros((2, 2)), \"bar\": np.zeros((2, 2))}\n+        )\n+        self.assertAllClose(original_output[\"foo\"], restored_output[\"foo\"])\n+        self.assertAllClose(original_output[\"bar\"], restored_output[\"bar\"])\n+\n     def shared_inner_layer(self):\n         input_1 = keras_core.Input((2,))\n         input_2 = keras_core.Input((2,))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
