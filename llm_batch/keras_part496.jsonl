{"custom_id": "keras#600d47860539833c04d8043723522e51ae4b1d81", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 63 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 4 | Methods Changed: 8 | Complexity Δ (Sum/Max): 8/8 | Churn Δ: 63 | Churn Cumulative: 1073 | Contributors (this commit): 8 | Commits (past 90d): 19 | Contributors (cumulative): 8 | DMM Complexity: 1.0\n\nDIFF:\n@@ -33,6 +33,8 @@ from keras.testing_infra import test_utils\n from keras.utils import io_utils\n \n train_step_message = \"This is my training step\"\n+assets_data = \"These are my assets\"\n+variables_data = np.random.random((10,))\n \n \n @keras.utils.register_keras_serializable(package=\"my_custom_package\")\n@@ -68,6 +70,29 @@ class MyDense(keras.layers.Dense):\n         return 2\n \n \n+@keras.utils.register_keras_serializable(package=\"my_custom_package\")\n+class LayerWithCustomSaving(MyDense):\n+    def build(self, input_shape):\n+        self.assets = assets_data\n+        self.stored_variables = variables_data\n+        return super().build(input_shape)\n+\n+    def _save_assets(self, inner_path):\n+        with open(os.path.join(inner_path, \"assets.txt\"), \"w\") as f:\n+            f.write(self.assets)\n+\n+    def _save_own_variables(self, store):\n+        store[\"variables\"] = self.stored_variables\n+\n+    def _load_assets(self, inner_path):\n+        with open(os.path.join(inner_path, \"assets.txt\"), \"r\") as f:\n+            text = f.read()\n+        self.assets = text\n+\n+    def _load_own_variables(self, store):\n+        self.stored_variables = np.array(store[\"variables\"])\n+\n+\n @keras.utils.register_keras_serializable(package=\"my_custom_package\")\n class CustomModelX(keras.Model):\n     def __init__(self, *args, **kwargs):\n@@ -96,6 +121,16 @@ class CustomModelX(keras.Model):\n         return 1\n \n \n+@keras.utils.register_keras_serializable(package=\"my_custom_package\")\n+class ModelWithCustomSaving(keras.Model):\n+    def __init__(self, *args, **kwargs):\n+        super().__init__(*args, **kwargs)\n+        self.custom_dense = LayerWithCustomSaving(1)\n+\n+    def call(self, inputs):\n+        return self.custom_dense(inputs)\n+\n+\n @keras.utils.register_keras_serializable(package=\"my_custom_package\")\n class CompileOverridingModel(keras.Model):\n     def __init__(self, *args, **kwargs):\n@@ -429,6 +464,34 @@ class SavingV3Test(tf.test.TestCase, parameterized.TestCase):\n         ):\n             np.testing.assert_allclose(original_weights, loaded_weights)\n \n+    def test_saving_custom_assets_and_variables(self):\n+        temp_filepath = os.path.join(self.get_temp_dir(), \"my_model.keras\")\n+        model = ModelWithCustomSaving()\n+        model.compile(\n+            optimizer=adam.Adam(),\n+            loss=[\n+                \"mse\",\n+                keras.losses.mean_squared_error,\n+                keras.losses.MeanSquaredError(),\n+                my_mean_squared_error,\n+            ],\n+        )\n+        x = np.random.random((100, 32))\n+        y = np.random.random((100, 1))\n+        model.fit(x, y, epochs=1)\n+\n+        # Assert that the archive has not been saved.\n+        self.assertFalse(os.path.exists(temp_filepath))\n+\n+        model._save_experimental(temp_filepath)\n+\n+        loaded_model = saving_lib.load_model(temp_filepath)\n+        self.assertEqual(loaded_model.custom_dense.assets, assets_data)\n+        self.assertEqual(\n+            loaded_model.custom_dense.stored_variables.tolist(),\n+            variables_data.tolist(),\n+        )\n+\n     @tf.__internal__.distribute.combinations.generate(\n         tf.__internal__.test.combinations.combine(\n             model_type=[\"subclassed\", \"sequential\"],\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cf9450c16508a8f8c189b0386414e56deb8167fc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 15 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): -1/1 | Churn Δ: 23 | Churn Cumulative: 3376 | Contributors (this commit): 17 | Commits (past 90d): 7 | Contributors (cumulative): 24 | DMM Complexity: 1.0\n\nDIFF:\n@@ -743,21 +743,6 @@ class Functional(training_lib.Model):\n             if keras_history is not None:  # Restore keras history.\n                 tensor._keras_history = keras_history\n \n-            # Add shape hints to Tensors that may have None shape dims but have\n-            # shapes defined by the `keras.Input` (not applicable in eager\n-            # mode).\n-            if not tf.executing_eagerly():\n-                try:\n-                    tensor.set_shape(tensor.shape.merge_with(ref_input.shape))\n-                except ValueError:\n-                    logging.warning(\n-                        \"Model was constructed with shape {} for input {}, \"\n-                        \"but it was called on an input with incompatible \"\n-                        \"shape {}.\".format(\n-                            ref_input.shape, ref_input, tensor.shape\n-                        )\n-                    )\n-\n             # Dtype casting.\n             tensor = tf.cast(tensor, dtype=ref_input.dtype)\n         elif tf_utils.is_extension_type(tensor):\n\n@@ -174,6 +174,14 @@ class InputLayerTest(test_combinations.TestCase):\n \n         self.assertAllEqual(run_model(tf.ones((10, 8))), tf.ones((10, 8)) * 2.0)\n \n+    @test_combinations.run_all_keras_modes\n+    def testBasicOutputShapeWithBatchSizeAndNoneDimensionsPlaceholder(self):\n+        x = input_layer_lib.Input((2, 3), batch_size=4, dtype=tf.float32)\n+        model = functional.Functional(x, x * 2.0)\n+        output = model(backend.placeholder(shape=[None, None, 3]))\n+        # batch size and dimension defined in Input should not be applied\n+        self.assertAllEqual(output.shape.as_list(), [None, None, 3])\n+\n     @test_combinations.generate(\n         test_combinations.combine(mode=[\"graph\", \"eager\"])\n     )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e27b2b333808fcde9b553d0748af80c3111c8f6b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 15 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 20 | Churn Cumulative: 166 | Contributors (this commit): 3 | Commits (past 90d): 1 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -18,24 +18,14 @@ import tensorflow.compat.v2 as tf\n from absl.testing import parameterized\n \n # isort: off\n-from tensorflow.python.distribute import (\n-    combinations as ds_combinations,\n-)\n-from tensorflow.python.distribute import (\n-    strategy_combinations,\n-)\n-from tensorflow.python.framework import (\n-    test_combinations as combinations,\n-)\n-from tensorflow.python.keras.utils import kpl_test_utils\n+from tensorflow.compat.v2.__internal__.distribute import combinations\n+from keras.utils import kpl_test_utils\n \n \n # TODO(b/182278926): Combine this test with other strategies.\n-@ds_combinations.generate(\n-    combinations.combine(\n-        distribution=[\n-            strategy_combinations.central_storage_strategy_with_gpu_and_cpu,\n-        ],\n+@combinations.generate(\n+    tf.__internal__.test.combinations.combine(\n+        distribution=[combinations.central_storage_strategy_with_gpu_and_cpu],\n         mode=[\"eager\"],\n     )\n )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6dd604d0fbefeadd862a17b01b24b4ff3cdf7e9a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 146 | Lines Deleted: 124 | Files Changed: 5 | Hunks: 23 | Methods Changed: 18 | Complexity Δ (Sum/Max): 7/3 | Churn Δ: 270 | Churn Cumulative: 4735 | Contributors (this commit): 14 | Commits (past 90d): 22 | Contributors (cumulative): 38 | DMM Complexity: 0.8181818181818182\n\nDIFF:\n@@ -65,7 +65,7 @@ def get_model(sync_batchnorm=False):\n         )\n     )\n     if sync_batchnorm:\n-        model.add(keras.layers.SyncBatchNormalization())\n+        model.add(keras.layers.BatchNormalization(synchronized=True))\n     else:\n         model.add(keras.layers.BatchNormalization())\n     model.add(keras.layers.Dense(10, activation=\"relu\"))\n\n@@ -28,6 +28,7 @@ from keras.testing_infra import test_utils\n     \"float64, the test sometimes fails with TensorFloat-32 enabled for unknown \"\n     \"reasons\"\n )\n+@test_utils.run_v2_only()\n class DistributionStrategyCnnCorrectnessTest(\n     keras_correctness_test_base.TestDistributionStrategyCorrectnessBase\n ):\n@@ -48,8 +49,12 @@ class DistributionStrategyCnnCorrectnessTest(\n                 c1 = keras.layers.BatchNormalization(name=\"bn1\")(c1)\n             elif self.with_batch_norm == \"sync\":\n                 # Test with parallel batch norms to verify all-reduce works OK.\n-                bn1 = keras.layers.SyncBatchNormalization(name=\"bn1\")(c1)\n-                bn2 = keras.layers.SyncBatchNormalization(name=\"bn2\")(c1)\n+                bn1 = keras.layers.BatchNormalization(\n+                    name=\"bn1\", synchronized=True\n+                )(c1)\n+                bn2 = keras.layers.BatchNormalization(\n+                    name=\"bn2\", synchronized=True\n+                )(c1)\n                 c1 = keras.layers.Add()([bn1, bn2])\n             c1 = keras.layers.MaxPooling2D(pool_size=(2, 2))(c1)\n             logits = keras.layers.Dense(10, activation=\"softmax\", name=\"pred\")(\n@@ -133,8 +138,9 @@ class DistributionStrategyCnnCorrectnessTest(\n         self, distribution, use_numpy, use_validation_data\n     ):\n         if not tf.executing_eagerly():\n-            self.skipTest(\"SyncBatchNorm is not enabled in graph mode.\")\n-\n+            self.skipTest(\n+                \"BatchNorm with `synchronized` is not enabled in graph mode.\"\n+            )\n         self.run_correctness_test(\n             distribution, use_numpy, use_validation_data, with_batch_norm=\"sync\"\n         )\n\n@@ -31,6 +31,7 @@ from tensorflow.python.ops.control_flow_ops import (\n     get_enclosing_xla_context,\n )\n from tensorflow.python.platform import tf_logging as logging\n+from tensorflow.python.util import deprecation\n from tensorflow.python.util.tf_export import keras_export\n \n \n@@ -131,6 +132,11 @@ class BatchNormalizationBase(Layer):\n               across all examples), and finally apply gamma and/or beta. If\n               `None`, no adjustment is applied. Cannot be specified if\n               virtual_batch_size is specified.\n+      synchronized: If True, synchronizes the global batch statistics (mean and\n+        variance) for the layer across all devices at each training step in a\n+        distributed training strategy. If False, each replica uses its own\n+        local batch statistics. Only relevant when used inside a\n+        `tf.distribute` strategy.\n \n     Call arguments:\n       inputs: Input tensor (of any rank).\n@@ -178,6 +184,7 @@ class BatchNormalizationBase(Layer):\n         virtual_batch_size=None,\n         adjustment=None,\n         name=None,\n+        synchronized=False,\n         **kwargs,\n     ):\n         super().__init__(name=name, **kwargs)\n@@ -190,6 +197,14 @@ class BatchNormalizationBase(Layer):\n                 \"Expected an int or a list/tuple of ints for the \"\n                 \"argument 'axis', but received: %r\" % axis\n             )\n+        if synchronized and fused:\n+            raise ValueError(\n+                \"`fused=True` is not supported when `synchronized=True`.\"\n+            )\n+        self.synchronized = synchronized\n+        if self.synchronized:\n+            fused = False\n+\n         self.momentum = momentum\n         self.epsilon = epsilon\n         self.center = center\n@@ -788,6 +803,10 @@ class BatchNormalizationBase(Layer):\n         return (r, d, out_mean, out_variance)\n \n     def _calculate_mean_and_var(self, inputs, reduction_axes, keep_dims):\n+        if self.synchronized:\n+            return self._sync_calculate_mean_and_var(\n+                inputs, reduction_axes, keep_dims\n+            )\n         return tf.nn.moments(inputs, reduction_axes, keepdims=keep_dims)\n \n     def _moments(self, inputs, reduction_axes, keep_dims):\n@@ -1099,119 +1118,7 @@ class BatchNormalizationBase(Layer):\n         base_config = super().get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n \n-\n-@keras_export(\"keras.layers.experimental.SyncBatchNormalization\", v1=[])\n-class SyncBatchNormalization(BatchNormalizationBase):\n-    r\"\"\"Normalize and scale inputs or activations synchronously across replicas.\n-\n-    Applies batch normalization to activations of the previous layer at each\n-    batch by synchronizing the global batch statistics across all devices that\n-    are training the model. For specific details about batch normalization\n-    please refer to the `tf.keras.layers.BatchNormalization` layer docs.\n-\n-    If this layer is used when using tf.distribute strategy to train models\n-    across devices/workers, there will be an allreduce call to aggregate batch\n-    statistics across all replicas at every training step. Without tf.distribute\n-    strategy, this layer behaves as a regular\n-    `tf.keras.layers.BatchNormalization` layer.\n-\n-    Example usage:\n-\n-    ```python\n-    strategy = tf.distribute.MirroredStrategy()\n-\n-    with strategy.scope():\n-      model = tf.keras.Sequential()\n-      model.add(tf.keras.layers.Dense(16))\n-      model.add(tf.keras.layers.experimental.SyncBatchNormalization())\n-    ```\n-\n-    Args:\n-      axis: Integer, the axis that should be normalized\n-        (typically the features axis).\n-        For instance, after a `Conv2D` layer with\n-        `data_format=\"channels_first\"`,\n-        set `axis=1` in `BatchNormalization`.\n-      momentum: Momentum for the moving average.\n-      epsilon: Small float added to variance to avoid dividing by zero.\n-      center: If True, add offset of `beta` to normalized tensor.\n-        If False, `beta` is ignored.\n-      scale: If True, multiply by `gamma`.\n-        If False, `gamma` is not used.\n-        When the next layer is linear (also e.g. `nn.relu`),\n-        this can be disabled since the scaling\n-        will be done by the next layer.\n-      beta_initializer: Initializer for the beta weight.\n-      gamma_initializer: Initializer for the gamma weight.\n-      moving_mean_initializer: Initializer for the moving mean.\n-      moving_variance_initializer: Initializer for the moving variance.\n-      beta_regularizer: Optional regularizer for the beta weight.\n-      gamma_regularizer: Optional regularizer for the gamma weight.\n-      beta_constraint: Optional constraint for the beta weight.\n-      gamma_constraint: Optional constraint for the gamma weight.\n-\n-    Call arguments:\n-      inputs: Input tensor (of any rank).\n-      training: Python boolean indicating whether the layer should behave in\n-        training mode or in inference mode.\n-        - `training=True`: The layer will normalize its inputs using the\n-          mean and variance of the current batch of inputs.\n-        - `training=False`: The layer will normalize its inputs using the\n-          mean and variance of its moving statistics, learned during training.\n-\n-    Input shape:\n-      Arbitrary. Use the keyword argument `input_shape`\n-      (tuple of integers, does not include the samples axis)\n-      when using this layer as the first layer in a model.\n-\n-    Output shape:\n-      Same shape as input.\n-\n-    \"\"\"\n-\n-    def __init__(\n-        self,\n-        axis=-1,\n-        momentum=0.99,\n-        epsilon=1e-3,\n-        center=True,\n-        scale=True,\n-        beta_initializer=\"zeros\",\n-        gamma_initializer=\"ones\",\n-        moving_mean_initializer=\"zeros\",\n-        moving_variance_initializer=\"ones\",\n-        beta_regularizer=None,\n-        gamma_regularizer=None,\n-        beta_constraint=None,\n-        gamma_constraint=None,\n-        **kwargs,\n-    ):\n-        if kwargs.pop(\"fused\", None):\n-            raise ValueError(\n-                \"`fused` argument cannot be True for SyncBatchNormalization.\"\n-            )\n-\n-        # Currently we only support aggregating over the global batch size.\n-        super().__init__(\n-            axis=axis,\n-            momentum=momentum,\n-            epsilon=epsilon,\n-            center=center,\n-            scale=scale,\n-            beta_initializer=beta_initializer,\n-            gamma_initializer=gamma_initializer,\n-            moving_mean_initializer=moving_mean_initializer,\n-            moving_variance_initializer=moving_variance_initializer,\n-            beta_regularizer=beta_regularizer,\n-            gamma_regularizer=gamma_regularizer,\n-            beta_constraint=beta_constraint,\n-            gamma_constraint=gamma_constraint,\n-            fused=False,\n-            **kwargs,\n-        )\n-\n-    def _calculate_mean_and_var(self, x, axes, keep_dims):\n-\n+    def _sync_calculate_mean_and_var(self, x, axes, keep_dims):\n         with backend.name_scope(\"moments\"):\n             # The dynamic range of fp16 is too limited to support the collection\n             # of sufficient statistics. As a workaround we simply perform the\n@@ -1315,6 +1222,23 @@ class BatchNormalization(BatchNormalizationBase):\n     *after having been trained on data that has similar statistics as the\n     inference data*.\n \n+    When `synchronized=True` is set and if this layer is used within a\n+    `tf.distribute` strategy, there will be an `allreduce` call\n+    to aggregate batch statistics across all replicas at every\n+    training step. Setting `synchronized` has no impact when the model is\n+    trained without specifying any distribution strategy.\n+\n+    Example usage:\n+\n+    ```python\n+    strategy = tf.distribute.MirroredStrategy()\n+\n+    with strategy.scope():\n+      model = tf.keras.Sequential()\n+      model.add(tf.keras.layers.Dense(16))\n+      model.add(tf.keras.layers.BatchNormalization(synchronized=True))\n+    ```\n+\n     Args:\n       axis: Integer, the axis that should be normalized (typically the features\n         axis). For instance, after a `Conv2D` layer with\n@@ -1334,6 +1258,11 @@ class BatchNormalization(BatchNormalizationBase):\n       gamma_regularizer: Optional regularizer for the gamma weight.\n       beta_constraint: Optional constraint for the beta weight.\n       gamma_constraint: Optional constraint for the gamma weight.\n+      synchronized: If True, synchronizes the global batch statistics (mean and\n+        variance) for the layer across all devices at each training step in a\n+        distributed training strategy. If False, each replica uses its own\n+        local batch statistics. Only relevant when used inside a\n+        `tf.distribute` strategy.\n \n     Call arguments:\n       inputs: Input tensor (of any rank).\n@@ -1404,8 +1333,10 @@ class BatchNormalization(BatchNormalizationBase):\n         gamma_regularizer=None,\n         beta_constraint=None,\n         gamma_constraint=None,\n+        synchronized=False,\n         **kwargs,\n     ):\n+        # Currently we only support aggregating over the global batch size.\n         super().__init__(\n             axis=axis,\n             momentum=momentum,\n@@ -1420,5 +1351,61 @@ class BatchNormalization(BatchNormalizationBase):\n             gamma_regularizer=gamma_regularizer,\n             beta_constraint=beta_constraint,\n             gamma_constraint=gamma_constraint,\n+            synchronized=synchronized,\n+            **kwargs,\n+        )\n+\n+\n+@keras_export(\"keras.layers.experimental.SyncBatchNormalization\", v1=[])\n+@deprecation.deprecated_endpoints(\n+    \"keras.layers.experimental.SyncBatchNormalization\"\n+)\n+class SyncBatchNormalization(BatchNormalizationBase):\n+    \"\"\"Deprecated. Please use `tf.keras.layers.BatchNormalization` instead.\n+\n+    Caution: `tf.keras.layers.experimental.SyncBatchNormalization` endpoint is\n+      deprecated and will be removed in a future release. Please use\n+      `tf.keras.layers.BatchNormalization` with parameter `synchronized`\n+      set to True\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        axis=-1,\n+        momentum=0.99,\n+        epsilon=1e-3,\n+        center=True,\n+        scale=True,\n+        beta_initializer=\"zeros\",\n+        gamma_initializer=\"ones\",\n+        moving_mean_initializer=\"zeros\",\n+        moving_variance_initializer=\"ones\",\n+        beta_regularizer=None,\n+        gamma_regularizer=None,\n+        beta_constraint=None,\n+        gamma_constraint=None,\n+        **kwargs,\n+    ):\n+        logging.warning(\n+            \"`tf.keras.layers.experimental.SyncBatchNormalization` endpoint is \"\n+            \"deprecated and will be removed in a future release. Please use \"\n+            \"`tf.keras.layers.BatchNormalization` with parameter \"\n+            \"`synchronized` set to True.\"\n+        )\n+        super().__init__(\n+            axis=axis,\n+            momentum=momentum,\n+            epsilon=epsilon,\n+            center=center,\n+            scale=scale,\n+            beta_initializer=beta_initializer,\n+            gamma_initializer=gamma_initializer,\n+            moving_mean_initializer=moving_mean_initializer,\n+            moving_variance_initializer=moving_variance_initializer,\n+            beta_regularizer=beta_regularizer,\n+            gamma_regularizer=gamma_regularizer,\n+            beta_constraint=beta_constraint,\n+            gamma_constraint=gamma_constraint,\n+            synchronized=True,\n             **kwargs,\n         )\n\n@@ -95,13 +95,22 @@ class BatchNormalizationTest(test_combinations.TestCase):\n         self.assertEqual(layer.gamma.constraint, max_norm)\n         self.assertEqual(layer.beta.constraint, max_norm)\n \n-    @test_combinations.run_all_keras_modes\n-    def test_batchnorm_convnet(self):\n+    @test_combinations.run_all_keras_modes(always_skip_v1=True)\n+    def test_batchnorm_sync_fused_error(self):\n+        with self.assertRaises(ValueError):\n+            _ = batch_normalization.BatchNormalization(\n+                synchronized=True, fused=True\n+            )\n+\n+    def _test_batchnorm_convnet(self, synchronized=False):\n         if tf.test.is_gpu_available(cuda_only=True):\n             with self.session():\n                 model = keras.models.Sequential()\n                 norm = keras.layers.BatchNormalization(\n-                    axis=1, input_shape=(3, 4, 4), momentum=0.8\n+                    axis=1,\n+                    input_shape=(3, 4, 4),\n+                    momentum=0.8,\n+                    synchronized=synchronized,\n                 )\n                 model.add(norm)\n                 model.compile(\n@@ -124,6 +133,14 @@ class BatchNormalizationTest(test_combinations.TestCase):\n                     np.std(out, axis=(0, 2, 3)), 1.0, atol=1e-1\n                 )\n \n+    @test_combinations.run_all_keras_modes\n+    def test_batchnorm_convnet(self):\n+        self._test_batchnorm_convnet(synchronized=False)\n+\n+    @test_combinations.run_all_keras_modes\n+    def test_batchnorm_convnet_synchronized(self):\n+        self._test_batchnorm_convnet(synchronized=True)\n+\n     @test_combinations.run_all_keras_modes\n     def test_batchnorm_convnet_channel_last(self):\n         model = keras.models.Sequential()\n@@ -155,6 +172,11 @@ class BatchNormalizationTest(test_combinations.TestCase):\n         _run_batchnorm_correctness_test(\n             batch_normalization.BatchNormalization, dtype=\"float32\"\n         )\n+        _run_batchnorm_correctness_test(\n+            batch_normalization.BatchNormalization,\n+            dtype=\"float32\",\n+            synchronized=True,\n+        )\n \n     @test_combinations.run_all_keras_modes\n     def test_batchnorm_float16(self):\n@@ -451,10 +473,12 @@ class BatchNormalizationV2Test(test_combinations.TestCase):\n         self.assertAllEqual(layer.beta, tape_vars[1])\n \n \n-def _run_batchnorm_correctness_test(layer, dtype=\"float32\", fused=False):\n+def _run_batchnorm_correctness_test(\n+    layer, dtype=\"float32\", fused=False, synchronized=False\n+):\n     model = keras.models.Sequential()\n     model.add(keras.Input(shape=(2, 2, 2), dtype=dtype))\n-    norm = layer(momentum=0.8, fused=fused)\n+    norm = layer(momentum=0.8, fused=fused, synchronized=synchronized)\n     model.add(norm)\n     if dtype == \"float16\":\n         # Keras models require float32 losses.\n@@ -558,7 +582,7 @@ class NormalizationLayersGraphModeOnlyTest(\n             self.assertAllClose(x1, x2, atol=1e-7)\n \n     def test_batchnorm_trainable(self, layer):\n-        \"\"\"Tests that BN layer is trainable when learning phase is enabled.\n+        \"\"\"Tests that batchnorm layer is trainable when learning phase is enabled.\n \n         Computes mean and std for current inputs then\n         applies batch normalization using them.\n\n@@ -24,3 +24,8 @@ from tensorflow.python.util.tf_export import keras_export\n @keras_export(v1=[\"keras.layers.BatchNormalization\"])\n class BatchNormalization(batch_normalization.BatchNormalizationBase):\n     _USE_V2_BEHAVIOR = False\n+\n+    def __init__(self, *args, **kwargs):\n+        # synchronized not implemented in V1\n+        kwargs.pop(\"synchronized\", None)\n+        super().__init__(*args, **kwargs)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c9068087d9142bab573e0c300bf9874a957accff", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 730 | Lines Deleted: 291 | Files Changed: 10 | Hunks: 79 | Methods Changed: 54 | Complexity Δ (Sum/Max): 41/38 | Churn Δ: 1021 | Churn Cumulative: 35979 | Contributors (this commit): 164 | Commits (past 90d): 106 | Contributors (cumulative): 222 | DMM Complexity: 0.5138888888888888\n\nDIFF:\n@@ -480,7 +480,7 @@ class Sequential(functional.Functional):\n             )\n             model.add(layer)\n \n-        if getattr(saving_lib._SAVING_V3_ENABLED, \"value\", False):\n+        if saving_lib.saving_v3_enabled():\n             compile_config = config.get(\"compile_config\", None)\n             if compile_config is not None:\n                 model._compile_from_config(\n\n@@ -17,7 +17,6 @@\n import copy\n import itertools\n import json\n-import os\n import warnings\n import weakref\n \n@@ -40,10 +39,8 @@ from keras.optimizers.optimizer_experimental import (\n     optimizer as optimizer_experimental,\n )\n from keras.saving import pickle_utils\n+from keras.saving import saving_api\n from keras.saving.experimental import saving_lib\n-from keras.saving.legacy import hdf5_format\n-from keras.saving.legacy import save\n-from keras.saving.legacy import saving_utils\n from keras.saving.legacy import serialization\n from keras.saving.legacy.saved_model import json_utils\n from keras.saving.legacy.saved_model import model_serialization\n@@ -69,7 +66,7 @@ except ImportError:\n \n @keras_export(\"keras.Model\", \"keras.models.Model\")\n class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n-    \"\"\"`Model` groups layers into an object with training and inference features.\n+    \"\"\"A model grouping layers into an object with training/inference features.\n \n     Args:\n         inputs: The input(s) of the model: a `keras.Input` object or a\n@@ -804,7 +801,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n \n     @property\n     def metrics(self):\n-        \"\"\"Returns the model's metrics added using `compile()`, `add_metric()` APIs.\n+        \"\"\"Return metrics added using `compile()` or `add_metric()`.\n \n         Note: Metrics passed to `compile()` are available only after a\n         `keras.Model` has been trained/evaluated on actual data.\n@@ -1349,7 +1346,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n         workers=1,\n         use_multiprocessing=False,\n     ):\n-        \"\"\"Trains the model for a fixed number of epochs (iterations on a dataset).\n+        \"\"\"Trains the model for a fixed number of epochs (dataset iterations).\n \n         Args:\n             x: Input data. It could be:\n@@ -2764,69 +2761,65 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n             return super().get_weights()\n \n     @traceback_utils.filter_traceback\n-    def save(\n-        self,\n-        filepath,\n-        overwrite=True,\n-        include_optimizer=True,\n-        save_format=None,\n-        signatures=None,\n-        options=None,\n-        save_traces=True,\n-    ):\n+    def save(self, filepath, overwrite=True, save_format=None, **kwargs):\n+        \"\"\"Saves a model as a TensorFlow SavedModel or HDF5 file.\n \n-        \"\"\"Saves the model to Tensorflow SavedModel or a single HDF5 file.\n-\n-        Please see `tf.keras.models.save_model` or the\n-        [Serialization and Saving guide](\n-        https://keras.io/guides/serialization_and_saving/)\n-        for details.\n+        See the [Serialization and Saving guide](\n+            https://keras.io/guides/serialization_and_saving/) for details.\n \n         Args:\n-            filepath: String, PathLike, path to SavedModel or H5 file to save\n-                the model.\n-            overwrite: Whether to silently overwrite any existing file at the\n-                target location, or provide the user with a manual prompt.\n-            include_optimizer: If True, save optimizer's state together.\n-            save_format: Either `'tf'` or `'h5'`, indicating whether to save the\n-                model to Tensorflow SavedModel or HDF5. Defaults to 'tf' in TF\n-                2.X, and 'h5' in TF 1.X.\n-            signatures: Signatures to save with the SavedModel. Applicable to\n-                the 'tf' format only. Please see the `signatures` argument in\n+            model: Keras model instance to be saved.\n+            filepath: `str` or `pathlib.Path` object. Path where to save the\n+                model.\n+            overwrite: Whether we should overwrite any existing model at the\n+                target location, or instead ask the user via an interactive\n+                prompt.\n+            save_format: Either `\"keras\"`, `\"tf\"`, `\"h5\"`,\n+                indicating whether to save the model\n+                in the native Keras format (`.keras`),\n+                in the TensorFlow SavedModel format\n+                (referred to as \"SavedModel\" below),\n+                or in the legacy HDF5 format (`.h5`).\n+                Defaults to `\"tf\"` in TF 2.X, and `\"h5\"` in TF 1.X.\n+\n+        SavedModel format arguments:\n+            include_optimizer: Only applied to SavedModel and legacy HDF5\n+                formats. If False, do not save the optimizer state.\n+                Defaults to True.\n+            signatures: Only applies to SavedModel format. Signatures to save\n+                with the SavedModel. See the `signatures` argument in\n                 `tf.saved_model.save` for details.\n-            options: (only applies to SavedModel format)\n-                `tf.saved_model.SaveOptions` object that specifies options for\n-                saving to SavedModel.\n-            save_traces: (only applies to SavedModel format) When enabled, the\n+            options: Only applies to SavedModel format.\n+                `tf.saved_model.SaveOptions` object that specifies SavedModel\n+                saving options.\n+            save_traces: Only applies to SavedModel format. When enabled, the\n                 SavedModel will store the function traces for each layer. This\n                 can be disabled, so that only the configs of each layer are\n-                stored.  Defaults to `True`. Disabling this will decrease\n-                serialization time and reduce file size, but it requires that\n-                all custom layers/models implement a `get_config()` method.\n+                stored. Defaults to `True`.\n+                Disabling this will decrease serialization time\n+                and reduce file size, but it requires that all custom\n+                layers/models implement a `get_config()` method.\n \n         Example:\n \n         ```python\n-        from keras.models import load_model\n-\n-        model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n-        del model  # deletes the existing model\n-\n-        # returns a compiled model\n-        # identical to the previous one\n-        model = load_model('my_model.h5')\n+        model = tf.keras.Sequential([\n+            tf.keras.layers.Dense(5, input_shape=(3,)),\n+            tf.keras.layers.Softmax()])\n+        model.save(\"model.keras\")\n+        loaded_model = tf.keras.models.load_model(\"model.keras\")\n+        x = tf.random.uniform((10, 3))\n+        assert np.allclose(model.predict(x), loaded_model.predict(x))\n         ```\n-        \"\"\"\n \n-        save.save_model(\n+        Note that `model.save()` is an alias for `tf.keras.models.save_model()`.\n+        \"\"\"\n+        saving_api.save_model(\n             self,\n-            filepath,\n-            overwrite,\n-            include_optimizer,\n-            save_format,\n-            signatures,\n-            options,\n-            save_traces,\n+            filepath=filepath,\n+            overwrite=overwrite,\n+            save_format=save_format,\n+            **kwargs,\n         )\n \n     @traceback_utils.filter_traceback\n@@ -2893,69 +2886,19 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n             ImportError: If `h5py` is not available when attempting to save in\n                 HDF5 format.\n         \"\"\"\n-        self._assert_weights_created()\n-        filepath = io_utils.path_to_string(filepath)\n-        filepath_is_h5 = saving_utils.is_hdf5_filepath(filepath)\n-        if save_format is None:\n-            if filepath_is_h5:\n-                save_format = \"h5\"\n-            else:\n-                save_format = \"tf\"\n-        else:\n-            user_format = save_format.lower().strip()\n-            if user_format in (\"tensorflow\", \"tf\"):\n-                save_format = \"tf\"\n-            elif user_format in (\"hdf5\", \"h5\", \"keras\"):\n-                save_format = \"h5\"\n-            else:\n-                raise ValueError(\n-                    f\"Unknown format. Received: `save_format`={save_format}. \"\n-                    'Was expecting one of {\"tf\", \"h5\"}.'\n-                )\n-        if save_format == \"tf\" and filepath_is_h5:\n-            raise ValueError(\n-                'save_weights got save_format=\"tf\"/\"tensorflow\", but the '\n-                f\"filepath ({filepath}) looks like an HDF5 file. \"\n-                'Omit the \".h5\"/\".keras\" when saving in TensorFlow format.'\n-            )\n-\n-        if save_format == \"h5\" and h5py is None:\n-            raise ImportError(\n-                \"`save_weights` requires h5py when saving in hdf5, but h5py is \"\n-                \"not available. Try installing h5py package.\"\n-            )\n-        if save_format == \"tf\":\n-            check_filepath = filepath + \".index\"\n-        else:\n-            check_filepath = filepath\n-        # If file exists and should not be overwritten:\n-        if not overwrite and os.path.isfile(check_filepath):\n-            proceed = io_utils.ask_to_proceed_with_overwrite(check_filepath)\n-            if not proceed:\n-                return\n-        if save_format == \"h5\":\n-            with h5py.File(filepath, \"w\") as f:\n-                hdf5_format.save_weights_to_hdf5_group(f, self)\n-        else:\n-            if not tf.executing_eagerly():\n-                # Call `get_session` to initialize any uninitialized variables.\n-                backend.get_session()\n-            self._checkpoint.write(filepath, options=options)\n-\n-            # Record this checkpoint so it's visible from\n-            # tf.train.latest_checkpoint.\n-            tf.__internal__.train.update_checkpoint_state(\n-                save_dir=os.path.dirname(filepath),\n-                model_checkpoint_path=filepath,\n-                save_relative_paths=True,\n-                all_model_checkpoint_paths=[filepath],\n+        saving_api.save_weights(\n+            self,\n+            filepath=filepath,\n+            overwrite=overwrite,\n+            save_format=save_format,\n+            options=options,\n         )\n \n     @traceback_utils.filter_traceback\n     def load_weights(\n         self, filepath, by_name=False, skip_mismatch=False, options=None\n     ):\n-        \"\"\"Loads all layer weights, either from a TensorFlow or an HDF5 weight file.\n+        \"\"\"Loads all layer weights, either from a SavedModel or H5 weights file.\n \n         If `by_name` is False weights are loaded based on the network's\n         topology. This means the architecture should be the same as when the\n@@ -3004,67 +2947,13 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n             ValueError: If `skip_mismatch` is set to `True` when `by_name` is\n               `False`.\n         \"\"\"\n-        if backend.is_tpu_strategy(self._distribution_strategy):\n-            if self._distribution_strategy.extended.steps_per_run > 1 and (\n-                not saving_utils.is_hdf5_filepath(filepath)\n-            ):\n-                spr = self._distribution_strategy.extended.steps_per_run\n-                raise ValueError(\n-                    \"Load weights is not implemented with TPUStrategy \"\n-                    \"with `steps_per_run` greater than 1. The \"\n-                    f\"`steps_per_run` is {spr}\"\n+        return saving_api.load_weights(\n+            self,\n+            filepath=filepath,\n+            by_name=by_name,\n+            skip_mismatch=skip_mismatch,\n+            options=options,\n         )\n-        if skip_mismatch and not by_name:\n-            raise ValueError(\n-                \"When calling model.load_weights, skip_mismatch can only be \"\n-                \"set to True when by_name is True.\"\n-            )\n-\n-        filepath, save_format = _detect_save_format(filepath)\n-        if save_format == \"tf\":\n-            status = self._checkpoint.read(filepath, options)\n-            if by_name:\n-                raise NotImplementedError(\n-                    \"Weights may only be loaded based on topology into Models \"\n-                    \"when loading TensorFlow-formatted weights \"\n-                    \"(got by_name=True to load_weights).\"\n-                )\n-            if not tf.executing_eagerly():\n-                session = backend.get_session()\n-                # Restore existing variables (if any) immediately, and set up a\n-                # streaming restore for any variables created in the future.\n-                tf.__internal__.tracking.streaming_restore(\n-                    status=status, session=session\n-                )\n-            status.assert_nontrivial_match()\n-        else:\n-            status = None\n-            if h5py is None:\n-                raise ImportError(\n-                    \"`load_weights` requires h5py package when loading weights \"\n-                    \"from HDF5. Try installing h5py.\"\n-                )\n-            if not self._is_graph_network and not self.built:\n-                raise ValueError(\n-                    \"Unable to load weights saved in HDF5 format into a \"\n-                    \"subclassed Model which has not created its variables yet. \"\n-                    \"Call the Model first, then load the weights.\"\n-                )\n-            self._assert_weights_created()\n-            with h5py.File(filepath, \"r\") as f:\n-                if \"layer_names\" not in f.attrs and \"model_weights\" in f:\n-                    f = f[\"model_weights\"]\n-                if by_name:\n-                    hdf5_format.load_weights_from_hdf5_group_by_name(\n-                        f, self, skip_mismatch\n-                    )\n-                else:\n-                    hdf5_format.load_weights_from_hdf5_group(f, self)\n-\n-        # Perform any layer defined finalization of the layer state.\n-        for layer in self.layers:\n-            layer.finalize_state()\n-        return status\n \n     def _updated_config(self):\n         \"\"\"Util shared between different serialization methods.\n@@ -3111,7 +3000,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n         # don't override `from_config()`, which would use `cls(**config)`\n         # as a result.\n         config = {}\n-        if getattr(saving_lib._SAVING_V3_ENABLED, \"value\", False):\n+        if saving_lib.saving_v3_enabled():\n             if self._is_compiled and hasattr(self, \"_compile_config\"):\n                 config[\"compile_config\"] = self._compile_config.serialize()\n             if self.built:\n@@ -3166,7 +3055,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n                         f\"Error encountered during deserialization:\\n{e}\"\n                     )\n \n-            if getattr(saving_lib._SAVING_V3_ENABLED, \"value\", False):\n+            if saving_lib.saving_v3_enabled():\n                 if build_input_shape:\n                     model.build(build_input_shape)\n                 if compile_config is not None:\n@@ -3459,7 +3348,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n \n     @tf.__internal__.tracking.no_automatic_dependency_tracking\n     def _set_save_spec(self, inputs, args=None, kwargs=None):\n-        \"\"\"Defines the save spec so that serialization is able to trace model call.\n+        \"\"\"Defines the save spec so that serialization can trace `call()`.\n \n         The TensorSpecs of the call function `inputs`, `args`, and `kwargs` are\n         saved into a tuple of `([inputs] + args, kwargs)`. The input\n@@ -3500,7 +3389,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n             )\n \n     def save_spec(self, dynamic_batch=True):\n-        \"\"\"Returns the `tf.TensorSpec` of call inputs as a tuple `(args, kwargs)`.\n+        \"\"\"Returns the `tf.TensorSpec` of call args as a tuple `(args, kwargs)`.\n \n         This value is automatically defined after calling the model for the\n         first time. Afterwards, you can use it when exporting the model for\n@@ -3684,7 +3573,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     def _maybe_load_initial_counters_from_ckpt(\n         self, steps_per_epoch, initial_epoch\n     ):\n-        \"\"\"Maybe load initial epoch from ckpt considering possible worker recovery.\n+        \"\"\"Maybe load initial epoch from ckpt, considering worker recovery.\n \n         Refer to tensorflow/python/keras/distribute/worker_training_state.py\n         for more information.\n@@ -4097,49 +3986,6 @@ def _disallow_inside_tf_function(method_name):\n         raise RuntimeError(error_msg)\n \n \n-def _detect_save_format(filepath):\n-    \"\"\"Returns path to weights file and save format.\"\"\"\n-\n-    filepath = io_utils.path_to_string(filepath)\n-    if saving_utils.is_hdf5_filepath(filepath):\n-        return filepath, \"h5\"\n-\n-    # Filepath could be a TensorFlow checkpoint file prefix or SavedModel\n-    # directory. It's possible for filepath to be both a prefix and directory.\n-    # Prioritize checkpoint over SavedModel.\n-    if _is_readable_tf_checkpoint(filepath):\n-        save_format = \"tf\"\n-    elif tf.saved_model.contains_saved_model(filepath):\n-        ckpt_path = os.path.join(\n-            filepath,\n-            tf.saved_model.VARIABLES_DIRECTORY,\n-            tf.saved_model.VARIABLES_FILENAME,\n-        )\n-        if _is_readable_tf_checkpoint(ckpt_path):\n-            filepath = ckpt_path\n-            save_format = \"tf\"\n-        else:\n-            raise ValueError(\n-                \"Unable to load weights. filepath {} appears to be a \"\n-                \"SavedModel directory, but checkpoint either doesn't \"\n-                \"exist, or is incorrectly formatted.\".format(filepath)\n-            )\n-    else:\n-        # Not a TensorFlow checkpoint. This filepath is likely an H5 file that\n-        # doesn't have the hdf5/keras extensions.\n-        save_format = \"h5\"\n-    return filepath, save_format\n-\n-\n-def _is_readable_tf_checkpoint(filepath):\n-    try:\n-        tf.compat.v1.train.NewCheckpointReader(filepath)\n-        return True\n-    except tf.errors.DataLossError:\n-        # The checkpoint is not readable in TensorFlow format.\n-        return False\n-\n-\n def flatten_metrics_in_order(logs, metrics_names):\n     \"\"\"Turns the `logs` dict into a list as per key order of `metrics_names`.\"\"\"\n     results = []\n\n@@ -444,7 +444,7 @@ class NormalizationAdaptTest(\n \n         # Save the model to disk.\n         output_path = os.path.join(self.get_temp_dir(), \"tf_keras_saved_model\")\n-        model.save(output_path, save_format=format)\n+        model.save(output_path, save_format=save_format)\n         loaded_model = keras.models.load_model(\n             output_path, custom_objects={\"Normalization\": cls}\n         )\n\n@@ -277,7 +277,7 @@ class LossFunctionWrapper(Loss):\n                 backend.eval(v) if tf_utils.is_tensor_or_variable(v) else v\n             )\n \n-        if getattr(saving_lib._SAVING_V3_ENABLED, \"value\", False):\n+        if saving_lib.saving_v3_enabled():\n             from keras.utils import get_registered_name\n \n             config[\"fn\"] = get_registered_name(self.fn)\n@@ -295,7 +295,7 @@ class LossFunctionWrapper(Loss):\n         Returns:\n             A `keras.losses.Loss` instance.\n         \"\"\"\n-        if getattr(saving_lib._SAVING_V3_ENABLED, \"value\", False):\n+        if saving_lib.saving_v3_enabled():\n             fn_name = config.pop(\"fn\", None)\n             if fn_name and cls is LossFunctionWrapper:\n                 config[\"fn\"] = get(fn_name)\n\n@@ -32,5 +32,5 @@ from keras.models.sharpness_aware_minimization import SharpnessAwareMinimization\n from keras.saving.legacy.model_config import model_from_config\n from keras.saving.legacy.model_config import model_from_json\n from keras.saving.legacy.model_config import model_from_yaml\n-from keras.saving.legacy.save import load_model\n-from keras.saving.legacy.save import save_model\n+from keras.saving.saving_api import load_model\n+from keras.saving.saving_api import save_model\n\n@@ -99,7 +99,7 @@ def save_model(model, filepath, weights_format=\"h5\"):\n     \"\"\"\n     if not filepath.endswith(\".keras\"):\n         raise ValueError(\n-            \"Invalid filename: expected a `.keras` extension. \"\n+            \"Invalid `filepath` argument: expected a `.keras` extension. \"\n             f\"Received: filepath={filepath}\"\n         )\n     if weights_format == \"h5\" and h5py is None:\n@@ -142,16 +142,17 @@ def save_model(model, filepath, weights_format=\"h5\"):\n                 )\n             else:\n                 raise ValueError(\n-                    \"Unknown weights_format. Expected 'h5' or 'npz'. \"\n-                    f\"Received: {weights_format}\"\n+                    \"Unknown `weights_format` argument. \"\n+                    \"Expected 'h5' or 'npz'. \"\n+                    f\"Received: weights_format={weights_format}\"\n                 )\n \n             asset_store = DiskIOStore(_ASSETS_DIRNAME, archive=zf, mode=\"w\")\n \n             _save_state(\n                 model,\n-                weights_handler=weights_store,\n-                assets_handler=asset_store,\n+                weights_store=weights_store,\n+                assets_store=asset_store,\n                 inner_path=\"\",\n                 visited_trackables=set(),\n             )\n@@ -164,7 +165,7 @@ def save_model(model, filepath, weights_format=\"h5\"):\n         _SAVING_V3_ENABLED.value = saving_v3_enabled_value\n \n \n-def load_model(filepath, custom_objects=None):\n+def load_model(filepath, custom_objects=None, compile=True):\n     \"\"\"Load a zip archive representing a Keras model.\"\"\"\n     if not filepath.endswith(\".keras\"):\n         raise ValueError(\n@@ -184,6 +185,9 @@ def load_model(filepath, custom_objects=None):\n             # Note: we should NOT use a custom JSON decoder. Anything that\n             # needs custom decoding must be handled in deserialize_keras_object.\n             config_dict = json.loads(config_json)\n+            if not compile:\n+                # Disable compilation\n+                config_dict[\"config\"][\"compile_config\"] = None\n             # Construct the model from the configuration file in the archive.\n             model = deserialize_keras_object(config_dict, custom_objects)\n \n@@ -208,8 +212,8 @@ def load_model(filepath, custom_objects=None):\n \n             _load_state(\n                 model,\n-                weights_handler=weights_store,\n-                assets_handler=asset_store,\n+                weights_store=weights_store,\n+                assets_store=asset_store,\n                 inner_path=\"\",\n                 visited_trackables=set(),\n             )\n@@ -234,18 +238,18 @@ def save_weights_only(model, filepath):\n     # then upload it\n     if not filepath.endswith(\".weights.h5\"):\n         raise ValueError(\n-            \"Invalid filename: expected a `.weights.h5` extension. \"\n+            \"Invalid `filepath` argument: expected a `.weights.h5` extension. \"\n             f\"Received: filepath={filepath}\"\n         )\n-    weights_handler = H5IOStore(filepath, mode=\"w\")\n+    weights_store = H5IOStore(filepath, mode=\"w\")\n     _save_state(\n         model,\n-        weights_handler=weights_handler,\n-        assets_handler=None,\n+        weights_store=weights_store,\n+        assets_store=None,\n         inner_path=\"\",\n         visited_trackables=set(),\n     )\n-    weights_handler.close()\n+    weights_store.close()\n \n \n def load_weights_only(model, filepath):\n@@ -266,8 +270,8 @@ def load_weights_only(model, filepath):\n \n     _load_state(\n         model,\n-        weights_handler=weights_store,\n-        assets_handler=None,\n+        weights_store=weights_store,\n+        assets_store=None,\n         inner_path=\"\",\n         visited_trackables=set(),\n     )\n@@ -291,17 +295,17 @@ def _write_to_zip_recursively(zipfile_to_save, system_path, zip_path):\n \n \n def _save_state(\n-    trackable, weights_handler, assets_handler, inner_path, visited_trackables\n+    trackable, weights_store, assets_store, inner_path, visited_trackables\n ):\n     # If the trackable has already been saved, skip it.\n     if id(trackable) in visited_trackables:\n         return\n \n     # TODO(fchollet): better name?\n-    if hasattr(trackable, \"_save_own_variables\") and weights_handler:\n-        trackable._save_own_variables(weights_handler.make(inner_path))\n-    if hasattr(trackable, \"_save_assets\") and assets_handler:\n-        trackable._save_assets(assets_handler.make(inner_path))\n+    if hasattr(trackable, \"_save_own_variables\") and weights_store:\n+        trackable._save_own_variables(weights_store.make(inner_path))\n+    if hasattr(trackable, \"_save_assets\") and assets_store:\n+        trackable._save_assets(assets_store.make(inner_path))\n \n     visited_trackables.add(id(trackable))\n \n@@ -317,31 +321,31 @@ def _save_state(\n         if _is_keras_trackable(child_obj):\n             _save_state(\n                 child_obj,\n-                weights_handler,\n-                assets_handler,\n+                weights_store,\n+                assets_store,\n                 inner_path=tf.io.gfile.join(inner_path, child_attr),\n                 visited_trackables=visited_trackables,\n             )\n         elif isinstance(child_obj, (list, dict, tuple)):\n             _save_container_state(\n                 child_obj,\n-                weights_handler,\n-                assets_handler,\n+                weights_store,\n+                assets_store,\n                 inner_path=tf.io.gfile.join(inner_path, child_attr),\n                 visited_trackables=visited_trackables,\n             )\n \n \n def _load_state(\n-    trackable, weights_handler, assets_handler, inner_path, visited_trackables\n+    trackable, weights_store, assets_store, inner_path, visited_trackables\n ):\n     if id(trackable) in visited_trackables:\n         return\n \n-    if hasattr(trackable, \"_load_own_variables\") and weights_handler:\n-        trackable._load_own_variables(weights_handler.get(inner_path))\n-    if hasattr(trackable, \"_load_assets\") and assets_handler:\n-        trackable._load_assets(assets_handler.get(inner_path))\n+    if hasattr(trackable, \"_load_own_variables\") and weights_store:\n+        trackable._load_own_variables(weights_store.get(inner_path))\n+    if hasattr(trackable, \"_load_assets\") and assets_store:\n+        trackable._load_assets(assets_store.get(inner_path))\n \n     visited_trackables.add(id(trackable))\n \n@@ -357,23 +361,23 @@ def _load_state(\n         if _is_keras_trackable(child_obj):\n             _load_state(\n                 child_obj,\n-                weights_handler,\n-                assets_handler,\n+                weights_store,\n+                assets_store,\n                 inner_path=tf.io.gfile.join(inner_path, child_attr),\n                 visited_trackables=visited_trackables,\n             )\n         elif isinstance(child_obj, (list, dict, tuple)):\n             _load_container_state(\n                 child_obj,\n-                weights_handler,\n-                assets_handler,\n+                weights_store,\n+                assets_store,\n                 inner_path=tf.io.gfile.join(inner_path, child_attr),\n                 visited_trackables=visited_trackables,\n             )\n \n \n def _save_container_state(\n-    container, weights_handler, assets_handler, inner_path, visited_trackables\n+    container, weights_store, assets_store, inner_path, visited_trackables\n ):\n     used_names = {}\n     for trackable in container:\n@@ -389,15 +393,15 @@ def _save_container_state(\n                 used_names[name] = 0\n             _save_state(\n                 trackable,\n-                weights_handler,\n-                assets_handler,\n+                weights_store,\n+                assets_store,\n                 inner_path=tf.io.gfile.join(inner_path, name),\n                 visited_trackables=visited_trackables,\n             )\n \n \n def _load_container_state(\n-    container, weights_handler, assets_handler, inner_path, visited_trackables\n+    container, weights_store, assets_store, inner_path, visited_trackables\n ):\n     used_names = {}\n     for trackable in container:\n@@ -410,8 +414,8 @@ def _load_container_state(\n                 used_names[name] = 0\n             _load_state(\n                 trackable,\n-                weights_handler,\n-                assets_handler,\n+                weights_store,\n+                assets_store,\n                 inner_path=tf.io.gfile.join(inner_path, name),\n                 visited_trackables=visited_trackables,\n             )\n@@ -584,6 +588,10 @@ def _is_keras_trackable(obj):\n     )\n \n \n+def saving_v3_enabled():\n+    return getattr(_SAVING_V3_ENABLED, \"value\", False)\n+\n+\n # Some debugging utilities.\n \n \n\n@@ -97,13 +97,11 @@ class LayerWithCustomSaving(MyDense):\n class CustomModelX(keras.Model):\n     def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n-        self.embedding = keras.layers.Embedding(4, 1)\n         self.dense1 = MyDense(1)\n         self.dense2 = MyDense(1)\n \n     def call(self, inputs):\n-        out = self.embedding(inputs)\n-        out = self.dense1(out)\n+        out = self.dense1(inputs)\n         return self.dense2(out)\n \n     def train_step(self, data):\n@@ -176,9 +174,7 @@ class SavingV3Test(tf.test.TestCase, parameterized.TestCase):\n         return subclassed_model\n \n     def _get_sequential_model(self):\n-        sequential_model = keras.Sequential(\n-            [keras.layers.Embedding(4, 1), MyDense(1), MyDense(1)]\n-        )\n+        sequential_model = keras.Sequential([MyDense(1), MyDense(1)])\n         sequential_model.compile(\n             optimizer=\"adam\", loss=[\"mse\", keras.losses.mean_squared_error]\n         )\n@@ -186,9 +182,8 @@ class SavingV3Test(tf.test.TestCase, parameterized.TestCase):\n \n     def _get_functional_model(self):\n         inputs = keras.Input(shape=(32,))\n-        inputs = keras.layers.Embedding(4, 1)(inputs)\n-        inputs = MyDense(1, name=\"first_dense\")(inputs)\n-        outputs = MyDense(1, name=\"second_dense\")(inputs)\n+        x = MyDense(1, name=\"first_dense\")(inputs)\n+        outputs = MyDense(1, name=\"second_dense\")(x)\n         functional_model = keras.Model(inputs, outputs)\n         functional_model.compile(\n             optimizer=\"adam\", loss=[\"mse\", keras.losses.mean_squared_error]\n@@ -532,6 +527,15 @@ class SavingV3Test(tf.test.TestCase, parameterized.TestCase):\n         self.assertIn(\"keras_version\", metadata)\n         self.assertIn(\"date_saved\", metadata)\n \n+    def test_load_model_api_endpoint(self):\n+        temp_filepath = os.path.join(self.get_temp_dir(), \"mymodel.keras\")\n+        model = self._get_functional_model()\n+        ref_input = np.random.random((10, 32))\n+        ref_output = model.predict(ref_input)\n+        model.save(temp_filepath, save_format=\"keras_v3\")\n+        model = keras.models.load_model(temp_filepath)\n+        self.assertAllClose(model.predict(ref_input), ref_output, atol=1e-6)\n+\n     def test_save_load_weights_only(self):\n         temp_filepath = os.path.join(self.get_temp_dir(), \"mymodel.weights.h5\")\n         model = self._get_functional_model()\n@@ -541,8 +545,13 @@ class SavingV3Test(tf.test.TestCase, parameterized.TestCase):\n         model = self._get_functional_model()\n         saving_lib.load_weights_only(model, temp_filepath)\n         self.assertAllClose(model.predict(ref_input), ref_output, atol=1e-6)\n+        # Test with Model method\n+        model = self._get_functional_model()\n+        model.load_weights(temp_filepath)\n+        self.assertAllClose(model.predict(ref_input), ref_output, atol=1e-6)\n \n     def test_load_weights_only_with_keras_file(self):\n+        # Test loading weights from whole saved model\n         temp_filepath = os.path.join(self.get_temp_dir(), \"mymodel.keras\")\n         model = self._get_functional_model()\n         ref_input = np.random.random((10, 32))\n@@ -551,6 +560,51 @@ class SavingV3Test(tf.test.TestCase, parameterized.TestCase):\n         model = self._get_functional_model()\n         saving_lib.load_weights_only(model, temp_filepath)\n         self.assertAllClose(model.predict(ref_input), ref_output, atol=1e-6)\n+        # Test with Model method\n+        model = self._get_functional_model()\n+        model.load_weights(temp_filepath)\n+        self.assertAllClose(model.predict(ref_input), ref_output, atol=1e-6)\n+\n+    def test_compile_arg(self):\n+        temp_filepath = os.path.join(self.get_temp_dir(), \"mymodel.keras\")\n+        model = self._get_functional_model()\n+        model.compile(\"rmsprop\", \"mse\")\n+        model.fit(np.random.random((10, 32)), np.random.random((10, 1)))\n+        saving_lib.save_model(model, temp_filepath)\n+\n+        model = saving_lib.load_model(temp_filepath)\n+        self.assertEqual(model._is_compiled, True)\n+        model = saving_lib.load_model(temp_filepath, compile=False)\n+        self.assertEqual(model._is_compiled, False)\n+\n+    def test_overwrite(self):\n+        temp_filepath = os.path.join(self.get_temp_dir(), \"mymodel.keras\")\n+        model = self._get_functional_model()\n+        model.save(temp_filepath, save_format=\"keras_v3\")\n+        model.save(temp_filepath, save_format=\"keras_v3\", overwrite=True)\n+        with self.assertRaises(EOFError):\n+            model.save(temp_filepath, save_format=\"keras_v3\", overwrite=False)\n+\n+        temp_filepath = os.path.join(self.get_temp_dir(), \"mymodel.weights.h5\")\n+        model = self._get_functional_model()\n+        model.save_weights(temp_filepath)\n+        model.save_weights(temp_filepath, overwrite=True)\n+        with self.assertRaises(EOFError):\n+            model.save_weights(temp_filepath, overwrite=False)\n+\n+    def test_api_errors(self):\n+        temp_filepath = os.path.join(self.get_temp_dir(), \"mymodel.notkeras\")\n+        model = self._get_functional_model()\n+        with self.assertRaisesRegex(ValueError, \"Unknown `save_format`\"):\n+            model.save(temp_filepath, save_format=\"invalid\")\n+        with self.assertRaisesRegex(ValueError, \"Invalid `filepath` argument\"):\n+            model.save(temp_filepath, save_format=\"keras_v3\")\n+\n+        temp_filepath = os.path.join(self.get_temp_dir(), \"mymodel.keras\")\n+        with self.assertRaisesRegex(ValueError, \"not supported\"):\n+            model.save(\n+                temp_filepath, include_optimizer=False, save_format=\"keras_v3\"\n+            )\n \n \n if __name__ == \"__main__\":\n\n@@ -14,8 +14,11 @@\n # ==============================================================================\n \"\"\"Keras model saving code.\"\"\"\n \n+import os\n+\n import tensorflow.compat.v2 as tf\n \n+from keras import backend\n from keras.saving import object_registration\n from keras.saving.legacy import hdf5_format\n from keras.saving.legacy import saving_utils\n@@ -23,12 +26,8 @@ from keras.saving.legacy import serialization\n from keras.saving.legacy.saved_model import load as saved_model_load\n from keras.saving.legacy.saved_model import load_context\n from keras.saving.legacy.saved_model import save as saved_model_save\n+from keras.utils import io_utils\n from keras.utils import traceback_utils\n-from keras.utils.io_utils import path_to_string\n-\n-# isort: off\n-from tensorflow.python.util.tf_export import keras_export\n-\n \n try:\n     import h5py\n@@ -36,7 +35,6 @@ except ImportError:\n     h5py = None\n \n \n-@keras_export(\"keras.models.save_model\")\n @traceback_utils.filter_traceback\n def save_model(\n     model,\n@@ -48,7 +46,6 @@ def save_model(\n     options=None,\n     save_traces=True,\n ):\n-\n     \"\"\"Saves a model as a TensorFlow SavedModel or HDF5 file.\n \n     See the [Serialization and Saving\n@@ -135,7 +132,7 @@ def save_model(\n     default_format = \"tf\" if tf.__internal__.tf2.enabled() else \"h5\"\n     save_format = save_format or default_format\n \n-    filepath = path_to_string(filepath)\n+    filepath = io_utils.path_to_string(filepath)\n \n     # If the user has not already called fit or built the underlying metrics, we\n     # should do that before saving to ensure the metric names have all\n@@ -175,7 +172,6 @@ def save_model(\n             )\n \n \n-@keras_export(\"keras.models.load_model\")\n @traceback_utils.filter_traceback\n def load_model(filepath, custom_objects=None, compile=True, options=None):\n     \"\"\"Loads a model saved via `model.save()`.\n@@ -221,7 +217,7 @@ def load_model(filepath, custom_objects=None, compile=True, options=None):\n     with serialization.SharedObjectLoadingScope():\n         with object_registration.CustomObjectScope(custom_objects or {}):\n             with load_context.load_context(options):\n-                filepath_str = path_to_string(filepath)\n+                filepath_str = io_utils.path_to_string(filepath)\n                 if isinstance(filepath_str, str):\n                     if not tf.io.gfile.exists(filepath_str):\n                         raise IOError(\n@@ -255,6 +251,286 @@ def load_model(filepath, custom_objects=None, compile=True, options=None):\n     )\n \n \n+def save_weights(\n+    model, filepath, overwrite=True, save_format=None, options=None\n+):\n+    \"\"\"Saves all layer weights.\n+\n+    Either saves in HDF5 or in TensorFlow format based on the `save_format`\n+    argument.\n+\n+    When saving in HDF5 format, the weight file has:\n+        - `layer_names` (attribute), a list of strings\n+            (ordered names of model layers).\n+        - For every layer, a `group` named `layer.name`\n+            - For every such layer group, a group attribute `weight_names`,\n+                a list of strings\n+                (ordered names of weights tensor of the layer).\n+            - For every weight in the layer, a dataset\n+                storing the weight value, named after the weight tensor.\n+\n+    When saving in TensorFlow format, all objects referenced by the network\n+    are saved in the same format as `tf.train.Checkpoint`, including any\n+    `Layer` instances or `Optimizer` instances assigned to object\n+    attributes. For networks constructed from inputs and outputs using\n+    `tf.keras.Model(inputs, outputs)`, `Layer` instances used by the network\n+    are tracked/saved automatically. For user-defined classes which inherit\n+    from `tf.keras.Model`, `Layer` instances must be assigned to object\n+    attributes, typically in the constructor. See the documentation of\n+    `tf.train.Checkpoint` and `tf.keras.Model` for details.\n+\n+    While the formats are the same, do not mix `save_weights` and\n+    `tf.train.Checkpoint`. Checkpoints saved by `Model.save_weights` should\n+    be loaded using `Model.load_weights`. Checkpoints saved using\n+    `tf.train.Checkpoint.save` should be restored using the corresponding\n+    `tf.train.Checkpoint.restore`. Prefer `tf.train.Checkpoint` over\n+    `save_weights` for training checkpoints.\n+\n+    The TensorFlow format matches objects and variables by starting at a\n+    root object, `self` for `save_weights`, and greedily matching attribute\n+    names. For `Model.save` this is the `Model`, and for `Checkpoint.save`\n+    this is the `Checkpoint` even if the `Checkpoint` has a model attached.\n+    This means saving a `tf.keras.Model` using `save_weights` and loading\n+    into a `tf.train.Checkpoint` with a `Model` attached (or vice versa)\n+    will not match the `Model`'s variables. See the\n+    [guide to training checkpoints](\n+    https://www.tensorflow.org/guide/checkpoint) for details on\n+    the TensorFlow format.\n+\n+    Args:\n+        filepath: String or PathLike, path to the file to save the weights\n+            to. When saving in TensorFlow format, this is the prefix used\n+            for checkpoint files (multiple files are generated). Note that\n+            the '.h5' suffix causes weights to be saved in HDF5 format.\n+        overwrite: Whether to silently overwrite any existing file at the\n+            target location, or provide the user with a manual prompt.\n+        save_format: Either 'tf' or 'h5'. A `filepath` ending in '.h5' or\n+            '.keras' will default to HDF5 if `save_format` is `None`.\n+            Otherwise `None` defaults to 'tf'.\n+        options: Optional `tf.train.CheckpointOptions` object that specifies\n+            options for saving weights.\n+\n+    Raises:\n+        ImportError: If `h5py` is not available when attempting to save in\n+            HDF5 format.\n+    \"\"\"\n+    model._assert_weights_created()\n+    filepath = io_utils.path_to_string(filepath)\n+    filepath_is_h5 = saving_utils.is_hdf5_filepath(filepath)\n+    if save_format is None:\n+        if filepath_is_h5:\n+            save_format = \"h5\"\n+        else:\n+            save_format = \"tf\"\n+    else:\n+        user_format = save_format.lower().strip()\n+        if user_format in (\"tensorflow\", \"tf\"):\n+            save_format = \"tf\"\n+        elif user_format in (\"hdf5\", \"h5\", \"keras\"):\n+            save_format = \"h5\"\n+        else:\n+            raise ValueError(\n+                f\"Unknown format. Received: `save_format`={save_format}. \"\n+                'Was expecting one of {\"tf\", \"h5\"}.'\n+            )\n+    if save_format == \"tf\" and filepath_is_h5:\n+        raise ValueError(\n+            'save_weights got save_format=\"tf\"/\"tensorflow\", but the '\n+            f\"filepath ({filepath}) looks like an HDF5 file. \"\n+            'Omit the \".h5\"/\".keras\" when saving in TensorFlow format.'\n+        )\n+\n+    if save_format == \"h5\" and h5py is None:\n+        raise ImportError(\n+            \"`save_weights` requires h5py when saving in hdf5, but h5py is \"\n+            \"not available. Try installing h5py package.\"\n+        )\n+    if save_format == \"tf\":\n+        check_filepath = filepath + \".index\"\n+    else:\n+        check_filepath = filepath\n+    # If file exists and should not be overwritten:\n+    if not overwrite and os.path.isfile(check_filepath):\n+        proceed = io_utils.ask_to_proceed_with_overwrite(check_filepath)\n+        if not proceed:\n+            return\n+    if save_format == \"h5\":\n+        with h5py.File(filepath, \"w\") as f:\n+            hdf5_format.save_weights_to_hdf5_group(f, model)\n+    else:\n+        if not tf.executing_eagerly():\n+            # Call `get_session` to initialize any uninitialized variables.\n+            backend.get_session()\n+        model._checkpoint.write(filepath, options=options)\n+\n+        # Record this checkpoint so it's visible from\n+        # tf.train.latest_checkpoint.\n+        tf.__internal__.train.update_checkpoint_state(\n+            save_dir=os.path.dirname(filepath),\n+            model_checkpoint_path=filepath,\n+            save_relative_paths=True,\n+            all_model_checkpoint_paths=[filepath],\n+        )\n+\n+\n+def load_weights(\n+    model, filepath, by_name=False, skip_mismatch=False, options=None\n+):\n+    \"\"\"Loads all layer weights, either from a SavedModel or H5 weights file.\n+\n+    If `by_name` is False weights are loaded based on the network's\n+    topology. This means the architecture should be the same as when the\n+    weights were saved.  Note that layers that don't have weights are not\n+    taken into account in the topological ordering, so adding or removing\n+    layers is fine as long as they don't have weights.\n+\n+    If `by_name` is True, weights are loaded into layers only if they share\n+    the same name. This is useful for fine-tuning or transfer-learning\n+    models where some of the layers have changed.\n+\n+    Only topological loading (`by_name=False`) is supported when loading\n+    weights from the TensorFlow format. Note that topological loading\n+    differs slightly between TensorFlow and HDF5 formats for user-defined\n+    classes inheriting from `tf.keras.Model`: HDF5 loads based on a\n+    flattened list of weights, while the TensorFlow format loads based on\n+    the object-local names of attributes to which layers are assigned in the\n+    `Model`'s constructor.\n+\n+    Args:\n+        filepath: String, path to the weights file to load. For weight files\n+            in TensorFlow format, this is the file prefix (the same as was\n+            passed to `save_weights`). This can also be a path to a\n+            SavedModel saved from `model.save`.\n+        by_name: Boolean, whether to load weights by name or by topological\n+            order. Only topological loading is supported for weight files in\n+            TensorFlow format.\n+        skip_mismatch: Boolean, whether to skip loading of layers where\n+            there is a mismatch in the number of weights, or a mismatch in\n+            the shape of the weight (only valid when `by_name=True`).\n+        options: Optional `tf.train.CheckpointOptions` object that specifies\n+            options for loading weights.\n+\n+    Returns:\n+        When loading a weight file in TensorFlow format, returns the same\n+        status object as `tf.train.Checkpoint.restore`. When graph building,\n+        restore ops are run automatically as soon as the network is built\n+        (on first call for user-defined classes inheriting from `Model`,\n+        immediately if it is already built).\n+\n+        When loading weights in HDF5 format, returns `None`.\n+\n+    Raises:\n+        ImportError: If `h5py` is not available and the weight file is in\n+            HDF5 format.\n+        ValueError: If `skip_mismatch` is set to `True` when `by_name` is\n+            `False`.\n+    \"\"\"\n+    if backend.is_tpu_strategy(model._distribution_strategy):\n+        if model._distribution_strategy.extended.steps_per_run > 1 and (\n+            not saving_utils.is_hdf5_filepath(filepath)\n+        ):\n+            spr = model._distribution_strategy.extended.steps_per_run\n+            raise ValueError(\n+                \"Load weights is not implemented with TPUStrategy \"\n+                \"with `steps_per_run` greater than 1. The \"\n+                f\"`steps_per_run` is {spr}\"\n+            )\n+    if skip_mismatch and not by_name:\n+        raise ValueError(\n+            \"When calling model.load_weights, skip_mismatch can only be \"\n+            \"set to True when by_name is True.\"\n+        )\n+\n+    filepath, save_format = _detect_save_format(filepath)\n+    if save_format == \"tf\":\n+        status = model._checkpoint.read(filepath, options)\n+        if by_name:\n+            raise NotImplementedError(\n+                \"Weights may only be loaded based on topology into Models \"\n+                \"when loading TensorFlow-formatted weights \"\n+                \"(got by_name=True to load_weights).\"\n+            )\n+        if not tf.executing_eagerly():\n+            session = backend.get_session()\n+            # Restore existing variables (if any) immediately, and set up a\n+            # streaming restore for any variables created in the future.\n+            tf.__internal__.tracking.streaming_restore(\n+                status=status, session=session\n+            )\n+        status.assert_nontrivial_match()\n+    else:\n+        status = None\n+        if h5py is None:\n+            raise ImportError(\n+                \"`load_weights` requires h5py package when loading weights \"\n+                \"from HDF5. Try installing h5py.\"\n+            )\n+        if not model._is_graph_network and not model.built:\n+            raise ValueError(\n+                \"Unable to load weights saved in HDF5 format into a \"\n+                \"subclassed Model which has not created its variables yet. \"\n+                \"Call the Model first, then load the weights.\"\n+            )\n+        model._assert_weights_created()\n+        with h5py.File(filepath, \"r\") as f:\n+            if \"layer_names\" not in f.attrs and \"model_weights\" in f:\n+                f = f[\"model_weights\"]\n+            if by_name:\n+                hdf5_format.load_weights_from_hdf5_group_by_name(\n+                    f, model, skip_mismatch\n+                )\n+            else:\n+                hdf5_format.load_weights_from_hdf5_group(f, model)\n+\n+    # Perform any layer defined finalization of the layer state.\n+    for layer in model.layers:\n+        layer.finalize_state()\n+    return status\n+\n+\n+def _detect_save_format(filepath):\n+    \"\"\"Returns path to weights file and save format.\"\"\"\n+\n+    filepath = io_utils.path_to_string(filepath)\n+    if saving_utils.is_hdf5_filepath(filepath):\n+        return filepath, \"h5\"\n+\n+    # Filepath could be a TensorFlow checkpoint file prefix or SavedModel\n+    # directory. It's possible for filepath to be both a prefix and directory.\n+    # Prioritize checkpoint over SavedModel.\n+    if _is_readable_tf_checkpoint(filepath):\n+        save_format = \"tf\"\n+    elif tf.saved_model.contains_saved_model(filepath):\n+        ckpt_path = os.path.join(\n+            filepath,\n+            tf.saved_model.VARIABLES_DIRECTORY,\n+            tf.saved_model.VARIABLES_FILENAME,\n+        )\n+        if _is_readable_tf_checkpoint(ckpt_path):\n+            filepath = ckpt_path\n+            save_format = \"tf\"\n+        else:\n+            raise ValueError(\n+                \"Unable to load weights. filepath {} appears to be a \"\n+                \"SavedModel directory, but checkpoint either doesn't \"\n+                \"exist, or is incorrectly formatted.\".format(filepath)\n+            )\n+    else:\n+        # Not a TensorFlow checkpoint. This filepath is likely an H5 file that\n+        # doesn't have the hdf5/keras extensions.\n+        save_format = \"h5\"\n+    return filepath, save_format\n+\n+\n+def _is_readable_tf_checkpoint(filepath):\n+    try:\n+        tf.compat.v1.train.NewCheckpointReader(filepath)\n+        return True\n+    except tf.errors.DataLossError:\n+        # The checkpoint is not readable in TensorFlow format.\n+        return False\n+\n+\n # Inject the load_model function to keras_deps to remove the dependency\n # from TFLite to Keras.\n tf.__internal__.register_load_model_function(load_model)\n\n@@ -12,7 +12,7 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n # ==============================================================================\n-\"\"\"Keras SavedModel serialization.\"\"\"\n+\"\"\"Keras legacy SavedModel saving.\"\"\"\n \n import os\n \n@@ -20,10 +20,10 @@ import tensorflow.compat.v2 as tf\n from absl import logging\n \n from keras import backend\n-from keras.layers import serialization\n from keras.protobuf import saved_metadata_pb2\n from keras.protobuf import versions_pb2\n from keras.saving.legacy import saving_utils\n+from keras.saving.legacy import serialization\n from keras.saving.legacy.saved_model import constants\n from keras.saving.legacy.saved_model import save_impl\n from keras.saving.legacy.saved_model import utils\n@@ -92,6 +92,7 @@ def save(\n     # already-set learning phase placeholder.\n     # This is needed for compatibility reasons until learning phase setting\n     # is removed from the public apis.\n+    with serialization.SharedObjectSavingScope():\n         with backend.deprecated_internal_learning_phase_scope(0):\n             with utils.keras_option_scope(save_traces):\n                 saved_nodes, node_paths = save_lib.save_and_return_nodes(\n@@ -111,8 +112,7 @@ def save(\n \n \n def generate_keras_metadata(saved_nodes, node_paths):\n-    \"\"\"Constructs a KerasMetadata proto with the metadata of each keras\n-    object.\"\"\"\n+    \"\"\"Constructs a KerasMetadata proto with the metadata of each object.\"\"\"\n     metadata = saved_metadata_pb2.SavedMetadata()\n     for node_id, node in enumerate(saved_nodes):\n         if isinstance(node, base_layer.Layer):\n@@ -135,7 +135,9 @@ def generate_keras_metadata(saved_nodes, node_paths):\n             # Log warning if the node's class name conflicts with a Keras\n             # built-in object.\n             class_name = node.__class__.__name__\n-            builtin_layer = serialization.get_builtin_layer(class_name)\n+            from keras.layers import serialization as layers_serialization\n+\n+            builtin_layer = layers_serialization.get_builtin_layer(class_name)\n             if builtin_layer:\n                 if not isinstance(node, builtin_layer):\n                     logging.warning(\n\n@@ -0,0 +1,253 @@\n+# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Public API surface for saving APIs.\"\"\"\n+\n+import os\n+import zipfile\n+\n+import tensorflow.compat.v2 as tf\n+from tensorflow.python.util.tf_export import keras_export\n+\n+from keras.saving.experimental import saving_lib\n+from keras.saving.legacy import save as legacy_sm_saving_lib\n+from keras.utils import io_utils\n+\n+try:\n+    import h5py\n+except ImportError:\n+    h5py = None\n+\n+\n+@keras_export(\"keras.models.save_model\")\n+def save_model(model, filepath, overwrite=True, save_format=None, **kwargs):\n+    \"\"\"Saves a model as a TensorFlow SavedModel or HDF5 file.\n+\n+    See the [Serialization and Saving guide](\n+        https://keras.io/guides/serialization_and_saving/) for details.\n+\n+    Args:\n+        model: Keras model instance to be saved.\n+        filepath: `str` or `pathlib.Path` object. Path where to save the model.\n+        overwrite: Whether we should overwrite any existing model at the target\n+            location, or instead ask the user via an interactive prompt.\n+        save_format: Either `\"keras\"`, `\"tf\"`, `\"h5\"`,\n+            indicating whether to save the model\n+            in the native Keras format (`.keras`),\n+            in the TensorFlow SavedModel format (referred to as \"SavedModel\"\n+            below), or in the legacy HDF5 format (`.h5`).\n+            Defaults to `\"tf\"` in TF 2.X, and `\"h5\"` in TF 1.X.\n+\n+    SavedModel format arguments:\n+        include_optimizer: Only applied to SavedModel and legacy HDF5 formats.\n+            If False, do not save the optimizer state. Defaults to True.\n+        signatures: Only applies to SavedModel format. Signatures to save\n+            with the SavedModel. See the `signatures` argument in\n+            `tf.saved_model.save` for details.\n+        options: Only applies to SavedModel format.\n+            `tf.saved_model.SaveOptions` object that specifies SavedModel\n+            saving options.\n+        save_traces: Only applies to SavedModel format. When enabled, the\n+            SavedModel will store the function traces for each layer. This\n+            can be disabled, so that only the configs of each layer are stored.\n+            Defaults to `True`. Disabling this will decrease serialization time\n+            and reduce file size, but it requires that all custom layers/models\n+            implement a `get_config()` method.\n+\n+    Example:\n+\n+    ```python\n+    model = tf.keras.Sequential([\n+        tf.keras.layers.Dense(5, input_shape=(3,)),\n+        tf.keras.layers.Softmax()])\n+    model.save(\"model.keras\")\n+    loaded_model = tf.keras.models.load_model(\"model.keras\")\n+    x = tf.random.uniform((10, 3))\n+    assert np.allclose(model.predict(x), loaded_model.predict(x))\n+    ```\n+\n+    Note that `model.save()` is an alias for `tf.keras.models.save_model()`.\n+\n+    The SavedModel or HDF5 file contains:\n+\n+    - The model's configuration (architecture)\n+    - The model's weights\n+    - The model's optimizer's state (if any)\n+\n+    Thus models can be reinstantiated in the exact same state, without any of\n+    the code used for model definition or training.\n+\n+    Note that the model weights may have different scoped names after being\n+    loaded. Scoped names include the model/layer names, such as\n+    `\"dense_1/kernel:0\"`. It is recommended that you use the layer properties to\n+    access specific variables, e.g. `model.get_layer(\"dense_1\").kernel`.\n+\n+    __SavedModel serialization format__\n+\n+    With `save_format=\"tf\"`, the model and all trackable objects attached\n+    to the it (e.g. layers and variables) are saved as a TensorFlow SavedModel.\n+    The model config, weights, and optimizer are included in the SavedModel.\n+    Additionally, for every Keras layer attached to the model, the SavedModel\n+    stores:\n+\n+    * The config and metadata -- e.g. name, dtype, trainable status\n+    * Traced call and loss functions, which are stored as TensorFlow\n+      subgraphs.\n+\n+    The traced functions allow the SavedModel format to save and load custom\n+    layers without the original class definition.\n+\n+    You can choose to not save the traced functions by disabling the\n+    `save_traces` option. This will decrease the time it takes to save the model\n+    and the amount of disk space occupied by the output SavedModel. If you\n+    enable this option, then you _must_ provide all custom class definitions\n+    when loading the model. See the `custom_objects` argument in\n+    `tf.keras.models.load_model`.\n+    \"\"\"\n+    save_format = get_save_format(filepath, save_format)\n+    if save_format not in (\"keras\", \"tf\", \"h5\", \"keras_v3\"):\n+        raise ValueError(\n+            \"Unknown `save_format` argument. Expected one of \"\n+            \"'keras', 'tf', or 'h5'. \"\n+            f\"Received: save_format{save_format}\"\n+        )\n+    if save_format == \"keras_v3\" or (\n+        saving_lib.saving_v3_enabled() and save_format == \"keras\"\n+    ):\n+        # If file exists and should not be overwritten.\n+        try:\n+            exists = os.path.exists(filepath)\n+        except TypeError:\n+            exists = False\n+        if exists and not overwrite:\n+            proceed = io_utils.ask_to_proceed_with_overwrite(filepath)\n+            if not proceed:\n+                return\n+        if kwargs:\n+            raise ValueError(\n+                \"The following argument(s) are not supported \"\n+                f\"with the native Keras format: {list(kwargs.keys())}\"\n+            )\n+        saving_lib.save_model(model, filepath)\n+    else:\n+        # Legacy case\n+        return legacy_sm_saving_lib.save_model(\n+            model,\n+            filepath,\n+            overwrite=overwrite,\n+            save_format=save_format,\n+            **kwargs,\n+        )\n+\n+\n+@keras_export(\"keras.models.load_model\")\n+def load_model(filepath, custom_objects=None, compile=True, **kwargs):\n+    \"\"\"Loads a model saved via `model.save()`.\n+\n+    Args:\n+        filepath: `str` or `pathlib.Path` object, path to the saved model file.\n+        custom_objects: Optional dictionary mapping names\n+            (strings) to custom classes or functions to be\n+            considered during deserialization.\n+        compile: Boolean, whether to compile the model after loading.\n+\n+    SavedModel format arguments:\n+        options: Only applies to SavedModel format.\n+            Optional `tf.saved_model.LoadOptions` object that specifies\n+            SavedModel loading options.\n+\n+    Returns:\n+        A Keras model instance. If the original model was compiled,\n+        and the argument `compile=True` is set, then the returned model\n+        will be compiled. Otherwise, the model will be left uncompiled.\n+\n+    Example:\n+\n+    ```python\n+    model = tf.keras.Sequential([\n+        tf.keras.layers.Dense(5, input_shape=(3,)),\n+        tf.keras.layers.Softmax()])\n+    model.save(\"model.keras\")\n+    loaded_model = tf.keras.models.load_model(\"model.keras\")\n+    x = tf.random.uniform((10, 3))\n+    assert np.allclose(model.predict(x), loaded_model.predict(x))\n+    ```\n+\n+    Note that the model variables may have different name values\n+    (`var.name` property, e.g. `\"dense_1/kernel:0\"`) after being reloaded.\n+    It is recommended that you use layer attributes to\n+    access specific variables, e.g. `model.get_layer(\"dense_1\").kernel`.\n+    \"\"\"\n+    if str(filepath).endswith(\".keras\") and zipfile.is_zipfile(filepath):\n+        if kwargs:\n+            raise ValueError(\n+                \"The following argument(s) are not supported \"\n+                f\"with the native Keras format: {list(kwargs.keys())}\"\n+            )\n+        return saving_lib.load_model(\n+            filepath, custom_objects=custom_objects, compile=compile\n+        )\n+\n+    # Legacy case.\n+    return legacy_sm_saving_lib.load_model(\n+        filepath, custom_objects=custom_objects, compile=compile, **kwargs\n+    )\n+\n+\n+def save_weights(model, filepath, overwrite=True, **kwargs):\n+    if str(filepath).endswith(\".weights.h5\"):\n+        # If file exists and should not be overwritten.\n+        try:\n+            exists = os.path.exists(filepath)\n+        except TypeError:\n+            exists = False\n+        if exists and not overwrite:\n+            proceed = io_utils.ask_to_proceed_with_overwrite(filepath)\n+            if not proceed:\n+                return\n+        saving_lib.save_weights_only(model, filepath)\n+    else:\n+        legacy_sm_saving_lib.save_weights(\n+            model, filepath, overwrite=overwrite, **kwargs\n+        )\n+\n+\n+def load_weights(model, filepath, **kwargs):\n+    if str(filepath).endswith(\".keras\") and zipfile.is_zipfile(filepath):\n+        saving_lib.load_weights_only(model, filepath)\n+    elif str(filepath).endswith(\".weights.h5\"):\n+        saving_lib.load_weights_only(model, filepath)\n+    else:\n+        return legacy_sm_saving_lib.load_weights(model, filepath, **kwargs)\n+\n+\n+def get_save_format(filepath, save_format):\n+    if saving_lib.saving_v3_enabled():\n+        default_format = \"keras\"\n+    elif tf.__internal__.tf2.enabled():\n+        default_format = \"tf\"\n+    else:\n+        default_format = \"h5\"\n+\n+    if (h5py is not None and isinstance(filepath, h5py.File)) or str(\n+        filepath\n+    ).endswith((\".h5\", \".hdf5\")):\n+        if save_format and save_format != \"h5\":\n+            raise ValueError(\n+                \"Provided `save_format` is inconsistent with `filepath`. \"\n+                f\"Received: save_format='{save_format}', filepath='{filepath}'\"\n+            )\n+        save_format = \"h5\"\n+\n+    return save_format or default_format\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
