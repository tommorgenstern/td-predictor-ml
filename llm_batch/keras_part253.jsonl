{"custom_id": "keras#3d7f5f0905ff8933e54366ac38edc3a3c4e4139b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 194 | Lines Deleted: 24 | Files Changed: 4 | Hunks: 38 | Methods Changed: 10 | Complexity Δ (Sum/Max): 14/6 | Churn Δ: 218 | Churn Cumulative: 12587 | Contributors (this commit): 64 | Commits (past 90d): 18 | Contributors (cumulative): 80 | DMM Complexity: 0.0\n\nDIFF:\n@@ -649,6 +649,14 @@ class Conv2DTranspose(Conv2D):\n             Specifying any stride value != 1 is incompatible with specifying\n             any `dilation_rate` value != 1.\n         padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n+        output_padding: An integer or tuple/list of 2 integers,\n+            specifying the amount of padding along the height and width\n+            of the output tensor.\n+            Can be a single integer to specify the same value for all\n+            spatial dimensions.\n+            The amount of output padding along a given dimension must be\n+            lower than the stride along that same dimension.\n+            If set to `None` (default), the output shape is inferred.\n         data_format: A string,\n             one of `\"channels_last\"` or `\"channels_first\"`.\n             The ordering of the dimensions in the inputs.\n@@ -703,6 +711,12 @@ class Conv2DTranspose(Conv2D):\n         `(batch, new_rows, new_cols, filters)`\n         if `data_format` is `\"channels_last\"`.\n         `rows` and `cols` values might have changed due to padding.\n+        If `output_padding` is specified:\n+\n+        ```\n+        new_rows = (rows - 1) * strides[0] + kernel_size[0] - 2 * padding[0] + output_padding[0]\n+        new_cols = (cols - 1) * strides[1] + kernel_size[1] - 2 * padding[1] + output_padding[1]\n+        ```\n \n     # References\n         - [A guide to convolution arithmetic for deep learning](https://arxiv.org/abs/1603.07285v1)\n@@ -714,6 +728,7 @@ class Conv2DTranspose(Conv2D):\n                  kernel_size,\n                  strides=(1, 1),\n                  padding='valid',\n+                 output_padding=None,\n                  data_format=None,\n                  activation=None,\n                  use_bias=True,\n@@ -743,6 +758,16 @@ class Conv2DTranspose(Conv2D):\n             **kwargs)\n         self.input_spec = InputSpec(ndim=4)\n \n+        self.output_padding = output_padding\n+        if self.output_padding is not None:\n+            self.output_padding = conv_utils.normalize_tuple(\n+                self.output_padding, 2, 'output_padding')\n+            for stride, out_pad in zip(self.strides, self.output_padding):\n+                if out_pad >= stride:\n+                    raise ValueError('Stride ' + str(self.strides) + ' must be '\n+                                     'greater than output padding ' +\n+                                     str(self.output_padding))\n+\n     def build(self, input_shape):\n         if len(input_shape) != 4:\n             raise ValueError('Inputs should have rank ' +\n@@ -786,14 +811,20 @@ class Conv2DTranspose(Conv2D):\n         height, width = input_shape[h_axis], input_shape[w_axis]\n         kernel_h, kernel_w = self.kernel_size\n         stride_h, stride_w = self.strides\n+        if self.output_padding is None:\n+            out_pad_h = out_pad_w = None\n+        else:\n+            out_pad_h, out_pad_w = self.output_padding\n \n         # Infer the dynamic output shape:\n         out_height = conv_utils.deconv_length(height,\n                                               stride_h, kernel_h,\n-                                              self.padding)\n+                                              self.padding,\n+                                              out_pad_h)\n         out_width = conv_utils.deconv_length(width,\n                                              stride_w, kernel_w,\n-                                             self.padding)\n+                                             self.padding,\n+                                             out_pad_w)\n         if self.data_format == 'channels_first':\n             output_shape = (batch_size, self.filters, out_height, out_width)\n         else:\n@@ -826,17 +857,28 @@ class Conv2DTranspose(Conv2D):\n \n         kernel_h, kernel_w = self.kernel_size\n         stride_h, stride_w = self.strides\n+        if self.output_padding is None:\n+            out_pad_h = out_pad_w = None\n+        else:\n+            out_pad_h, out_pad_w = self.output_padding\n \n         output_shape[c_axis] = self.filters\n-        output_shape[h_axis] = conv_utils.deconv_length(\n-            output_shape[h_axis], stride_h, kernel_h, self.padding)\n-        output_shape[w_axis] = conv_utils.deconv_length(\n-            output_shape[w_axis], stride_w, kernel_w, self.padding)\n+        output_shape[h_axis] = conv_utils.deconv_length(output_shape[h_axis],\n+                                                        stride_h,\n+                                                        kernel_h,\n+                                                        self.padding,\n+                                                        out_pad_h)\n+        output_shape[w_axis] = conv_utils.deconv_length(output_shape[w_axis],\n+                                                        stride_w,\n+                                                        kernel_w,\n+                                                        self.padding,\n+                                                        out_pad_w)\n         return tuple(output_shape)\n \n     def get_config(self):\n         config = super(Conv2DTranspose, self).get_config()\n         config.pop('dilation_rate')\n+        config['output_padding'] = self.output_padding\n         return config\n \n \n@@ -871,6 +913,14 @@ class Conv3DTranspose(Conv3D):\n             Specifying any stride value != 1 is incompatible with specifying\n             any `dilation_rate` value != 1.\n         padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n+        output_padding: An integer or tuple/list of 3 integers,\n+            specifying the amount of padding along the depth, height, and\n+            width.\n+            Can be a single integer to specify the same value for all\n+            spatial dimensions.\n+            The amount of output padding along a given dimension must be\n+            lower than the stride along that same dimension.\n+            If set to `None` (default), the output shape is inferred.\n         data_format: A string,\n             one of `\"channels_last\"` or `\"channels_first\"`.\n             The ordering of the dimensions in the inputs.\n@@ -925,6 +975,13 @@ class Conv3DTranspose(Conv3D):\n         `(batch, new_depth, new_rows, new_cols, filters)`\n         if `data_format` is `\"channels_last\"`.\n         `depth` and `rows` and `cols` values might have changed due to padding.\n+        If `output_padding` is specified::\n+\n+        ```\n+        new_depth = (depth - 1) * strides[0] + kernel_size[0] - 2 * padding[0] + output_padding[0]\n+        new_rows = (rows - 1) * strides[1] + kernel_size[1] - 2 * padding[1] + output_padding[1]\n+        new_cols = (cols - 1) * strides[2] + kernel_size[2] - 2 * padding[2] + output_padding[2]\n+        ```\n \n     # References\n         - [A guide to convolution arithmetic for deep learning](https://arxiv.org/abs/1603.07285v1)\n@@ -935,6 +992,7 @@ class Conv3DTranspose(Conv3D):\n                  kernel_size,\n                  strides=(1, 1, 1),\n                  padding='valid',\n+                 output_padding=None,\n                  data_format=None,\n                  activation=None,\n                  use_bias=True,\n@@ -963,6 +1021,15 @@ class Conv3DTranspose(Conv3D):\n             bias_constraint=bias_constraint,\n             **kwargs)\n         self.input_spec = InputSpec(ndim=5)\n+        self.output_padding = output_padding\n+        if self.output_padding is not None:\n+            self.output_padding = conv_utils.normalize_tuple(\n+                self.output_padding, 3, 'output_padding')\n+            for stride, out_pad in zip(self.strides, self.output_padding):\n+                if out_pad >= stride:\n+                    raise ValueError('Stride ' + str(self.strides) + ' must be '\n+                                     'greater than output padding ' +\n+                                     str(self.output_padding))\n \n     def build(self, input_shape):\n         if len(input_shape) != 5:\n@@ -1010,17 +1077,24 @@ class Conv3DTranspose(Conv3D):\n \n         kernel_d, kernel_h, kernel_w = self.kernel_size\n         stride_d, stride_h, stride_w = self.strides\n+        if self.output_padding is None:\n+            out_pad_d = out_pad_h = out_pad_w = None\n+        else:\n+            out_pad_d, out_pad_h, out_pad_w = self.output_padding\n \n         # Infer the dynamic output shape:\n         out_depth = conv_utils.deconv_length(depth,\n                                              stride_d, kernel_d,\n-                                             self.padding)\n+                                             self.padding,\n+                                             out_pad_d)\n         out_height = conv_utils.deconv_length(height,\n                                               stride_h, kernel_h,\n-                                              self.padding)\n+                                              self.padding,\n+                                              out_pad_h)\n         out_width = conv_utils.deconv_length(width,\n                                              stride_w, kernel_w,\n-                                             self.padding)\n+                                             self.padding,\n+                                             out_pad_w)\n \n         if self.data_format == 'channels_first':\n             output_shape = (batch_size, self.filters, out_depth, out_height, out_width)\n@@ -1053,26 +1127,34 @@ class Conv3DTranspose(Conv3D):\n \n         kernel_d, kernel_h, kernel_w = self.kernel_size\n         stride_d, stride_h, stride_w = self.strides\n+        if self.output_padding is None:\n+            out_pad_d = out_pad_h = out_pad_w = None\n+        else:\n+            out_pad_d, out_pad_h, out_pad_w = self.output_padding\n \n         output_shape[c_axis] = self.filters\n         output_shape[d_axis] = conv_utils.deconv_length(output_shape[d_axis],\n                                                         stride_d,\n                                                         kernel_d,\n-                                                        self.padding)\n+                                                        self.padding,\n+                                                        out_pad_d)\n         output_shape[h_axis] = conv_utils.deconv_length(output_shape[h_axis],\n                                                         stride_h,\n                                                         kernel_h,\n-                                                        self.padding)\n+                                                        self.padding,\n+                                                        out_pad_h)\n         output_shape[w_axis] = conv_utils.deconv_length(output_shape[w_axis],\n                                                         stride_w,\n                                                         kernel_w,\n-                                                        self.padding)\n+                                                        self.padding,\n+                                                        out_pad_w)\n \n         return tuple(output_shape)\n \n     def get_config(self):\n         config = super(Conv3DTranspose, self).get_config()\n         config.pop('dilation_rate')\n+        config['output_padding'] = self.output_padding\n         return config\n \n \n\n@@ -146,13 +146,42 @@ def conv_input_length(output_length, filter_size, padding, stride):\n     return (output_length - 1) * stride - 2 * pad + filter_size\n \n \n-def deconv_length(dim_size, stride_size, kernel_size, padding):\n+def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):\n+    \"\"\"Determines output length of a transposed convolution given input length.\n+\n+    # Arguments\n+        dim_size: Integer, the input length.\n+        stride_size: Integer, the stride along the dimension of `dim_size`.\n+        kernel_size: Integer, the kernel size along the dimension of\n+            `dim_size`.\n+        padding: One of `\"same\"`, `\"valid\"`, `\"full\"`.\n+        output_padding: Integer, amount of padding along the output dimension,\n+            Can be set to `None` in which case the output length is inferred.\n+\n+    # Returns\n+        The output length (integer).\n+    \"\"\"\n+    assert padding in {'same', 'valid', 'full'}\n     if dim_size is None:\n         return None\n+\n+    # Infer length if output padding is None, else compute the exact length\n+    if output_padding is None:\n         if padding == 'valid':\n             dim_size = dim_size * stride_size + max(kernel_size - stride_size, 0)\n         elif padding == 'full':\n             dim_size = dim_size * stride_size - (stride_size + kernel_size - 2)\n         elif padding == 'same':\n             dim_size = dim_size * stride_size\n+    else:\n+        if padding == 'same':\n+            pad = kernel_size // 2\n+        elif padding == 'valid':\n+            pad = 0\n+        elif padding == 'full':\n+            pad = kernel_size - 1\n+\n+        dim_size = ((dim_size - 1) * stride_size + kernel_size - 2 * pad +\n+                    output_padding)\n+\n     return dim_size\n\n@@ -194,19 +194,23 @@ def test_conv2d_transpose():\n     num_col = 6\n \n     for padding in _convolution_paddings:\n+        for out_padding in [None, (0, 0), (1, 1)]:\n             for strides in [(1, 1), (2, 2)]:\n                 if padding == 'same' and strides != (1, 1):\n                     continue\n-            layer_test(convolutional.Deconvolution2D,\n+                if strides == (1, 1) and out_padding == (1, 1):\n+                    continue\n+                layer_test(convolutional.Conv2DTranspose,\n                            kwargs={'filters': filters,\n                                    'kernel_size': 3,\n                                    'padding': padding,\n+                                   'output_padding': out_padding,\n                                    'strides': strides,\n                                    'data_format': 'channels_last'},\n                            input_shape=(num_samples, num_row, num_col, stack_size),\n                            fixed_batch_size=True)\n \n-    layer_test(convolutional.Deconvolution2D,\n+    layer_test(convolutional.Conv2DTranspose,\n                kwargs={'filters': filters,\n                        'kernel_size': 3,\n                        'padding': padding,\n@@ -223,12 +227,33 @@ def test_conv2d_transpose():\n \n     # Test invalid use case\n     with pytest.raises(ValueError):\n-        model = Sequential([convolutional.Conv2DTranspose(filters=filters,\n+        model = Sequential([convolutional.Conv2DTranspose(\n+            filters=filters,\n             kernel_size=3,\n             padding=padding,\n             use_bias=True,\n             batch_input_shape=(None, None, 5, None))])\n \n+    # Test invalid output padding for given stride. Output padding equal\n+    # to stride\n+    with pytest.raises(ValueError):\n+        model = Sequential([convolutional.Conv2DTranspose(\n+            filters=filters,\n+            kernel_size=3,\n+            padding=padding,\n+            output_padding=(0, 3),\n+            strides=(1, 3),\n+            batch_input_shape=(None, num_row, num_col, stack_size))])\n+    # Output padding greater than stride\n+    with pytest.raises(ValueError):\n+        model = Sequential([convolutional.Conv2DTranspose(\n+            filters=filters,\n+            kernel_size=3,\n+            padding=padding,\n+            output_padding=(2, 2),\n+            strides=(1, 3),\n+            batch_input_shape=(None, num_row, num_col, stack_size))])\n+\n \n @keras_test\n def test_separable_conv_1d():\n@@ -500,14 +525,18 @@ def test_conv3d_transpose():\n     num_col = 6\n \n     for padding in _convolution_paddings:\n+        for out_padding in [None, (0, 0, 0), (1, 1, 1)]:\n             for strides in [(1, 1, 1), (2, 2, 2)]:\n                 for data_format in ['channels_first', 'channels_last']:\n                     if padding == 'same' and strides != (1, 1, 1):\n                         continue\n+                    if strides == (1, 1, 1) and out_padding == (1, 1, 1):\n+                        continue\n                     layer_test(convolutional.Conv3DTranspose,\n                                kwargs={'filters': filters,\n                                        'kernel_size': 3,\n                                        'padding': padding,\n+                                       'output_padding': out_padding,\n                                        'strides': strides,\n                                        'data_format': data_format},\n                                input_shape=(None, num_depth, num_row, num_col, stack_size),\n@@ -531,11 +560,32 @@ def test_conv3d_transpose():\n \n     # Test invalid use case\n     with pytest.raises(ValueError):\n-        model = Sequential([convolutional.Conv3DTranspose(filters=filters,\n+        model = Sequential([convolutional.Conv3DTranspose(\n+            filters=filters,\n             kernel_size=3,\n             padding=padding,\n             batch_input_shape=(None, None, 5, None, None))])\n \n+    # Test invalid output padding for given stride. Output padding equal\n+    # to stride\n+    with pytest.raises(ValueError):\n+        model = Sequential([convolutional.Conv3DTranspose(\n+            filters=filters,\n+            kernel_size=3,\n+            padding=padding,\n+            output_padding=(0, 3, 3),\n+            strides=(1, 3, 4),\n+            batch_input_shape=(None, num_depth, num_row, num_col, stack_size))])\n+    # Output padding greater than stride\n+    with pytest.raises(ValueError):\n+        model = Sequential([convolutional.Conv3DTranspose(\n+            filters=filters,\n+            kernel_size=3,\n+            padding=padding,\n+            output_padding=(2, 2, 3),\n+            strides=(1, 3, 4),\n+            batch_input_shape=(None, num_depth, num_row, num_col, stack_size))])\n+\n \n @keras_test\n def test_maxpooling_3d():\n\n@@ -59,13 +59,22 @@ def test_conv_input_length():\n \n \n def test_deconv_length():\n-    assert conv_utils.deconv_length(None, 1, 7, 'same') is None\n-    assert conv_utils.deconv_length(224, 1, 7, 'same') == 224\n-    assert conv_utils.deconv_length(224, 2, 7, 'same') == 448\n-    assert conv_utils.deconv_length(32, 1, 5, 'valid') == 36\n-    assert conv_utils.deconv_length(32, 2, 5, 'valid') == 67\n-    assert conv_utils.deconv_length(32, 1, 5, 'full') == 28\n-    assert conv_utils.deconv_length(32, 2, 5, 'full') == 59\n+    assert conv_utils.deconv_length(None, 1, 7, 'same', None) is None\n+    assert conv_utils.deconv_length(224, 1, 7, 'same', None) == 224\n+    assert conv_utils.deconv_length(224, 2, 7, 'same', None) == 448\n+    assert conv_utils.deconv_length(32, 1, 5, 'valid', None) == 36\n+    assert conv_utils.deconv_length(32, 2, 5, 'valid', None) == 67\n+    assert conv_utils.deconv_length(32, 1, 5, 'full', None) == 28\n+    assert conv_utils.deconv_length(32, 2, 5, 'full', None) == 59\n+    assert conv_utils.deconv_length(224, 1, 7, 'same', 0) == 224\n+    assert conv_utils.deconv_length(224, 2, 7, 'same', 0) == 447\n+    assert conv_utils.deconv_length(224, 2, 7, 'same', 1) == 448\n+    assert conv_utils.deconv_length(32, 1, 5, 'valid', 0) == 36\n+    assert conv_utils.deconv_length(32, 2, 5, 'valid', 0) == 67\n+    assert conv_utils.deconv_length(32, 2, 5, 'valid', 1) == 68\n+    assert conv_utils.deconv_length(6, 1, 3, 'full', 0) == 4\n+    assert conv_utils.deconv_length(6, 2, 3, 'full', 1) == 10\n+    assert conv_utils.deconv_length(6, 2, 3, 'full', 2) == 11\n \n \n if __name__ == '__main__':\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#34e5936c24db033d8991a4abc433c4e9f3b6614b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 332 | Contributors (this commit): 17 | Commits (past 90d): 8 | Contributors (cumulative): 17 | DMM Complexity: None\n\nDIFF:\n@@ -20,7 +20,7 @@ For a detailed overview of what makes Keras special, see:\n https://keras.io/why-use-keras/\n \n Keras is compatible with Python 2.7-3.6\n-and is distributed under the MIT liense.\n+and is distributed under the MIT license.\n '''\n \n setup(name='Keras',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ba4aac6abeca84c8a0a8787850a9fcf90613b0bc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 12360 | Contributors (this commit): 76 | Commits (past 90d): 6 | Contributors (cumulative): 76 | DMM Complexity: None\n\nDIFF:\n@@ -486,7 +486,7 @@ class Flatten(Layer):\n     ```python\n         model = Sequential()\n         model.add(Conv2D(64, 3, 3,\n-                         border_mode='same',\n+                         padding='same',\n                          input_shape=(3, 32, 32)))\n         # now: model.output_shape == (None, 64, 32, 32)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#37b16451be92f71c9ed05fb0e2d751ef3d037150", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2746 | Contributors (this commit): 12 | Commits (past 90d): 8 | Contributors (cumulative): 14 | DMM Complexity: None\n\nDIFF:\n@@ -4,6 +4,7 @@ from __future__ import print_function\n \n from keras_applications import mobilenet\n \n+relu6 = mobilenet.relu6\n MobileNet = mobilenet.MobileNet\n decode_predictions = mobilenet.decode_predictions\n preprocess_input = mobilenet.preprocess_input\n\n@@ -4,6 +4,7 @@ from __future__ import print_function\n \n from keras_applications import mobilenet_v2\n \n+relu6 = mobilenet_v2.relu6\n MobileNetV2 = mobilenet_v2.MobileNetV2\n decode_predictions = mobilenet_v2.decode_predictions\n preprocess_input = mobilenet_v2.preprocess_input\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d954aef2a2e33532f8725f58183cf605f5c54656", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 2 | Churn Cumulative: 1170 | Contributors (this commit): 12 | Commits (past 90d): 8 | Contributors (cumulative): 12 | DMM Complexity: 0.0\n\nDIFF:\n@@ -323,6 +323,8 @@ def test_separable_conv_2d():\n                         continue\n                     if dilation_rate != (1, 1) and strides != (1, 1):\n                         continue\n+                    if dilation_rate != (1, 1) and multiplier == dilation_rate[0]:\n+                        continue\n                     if dilation_rate != (1, 1) and K.backend() == 'cntk':\n                         continue\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#17772aff6d5acaa3af9ce610f23b0cc52835a98d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 233 | Contributors (this commit): 14 | Commits (past 90d): 3 | Contributors (cumulative): 14 | DMM Complexity: None\n\nDIFF:\n@@ -73,6 +73,7 @@ if not os.path.exists(_config_path):\n # Set backend based on KERAS_BACKEND flag, if applicable.\n if 'KERAS_BACKEND' in os.environ:\n     _backend = os.environ['KERAS_BACKEND']\n+    if _backend:\n         _BACKEND = _backend\n \n # Import backend functions.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d1b40b169f3d70afe4db539d140d6ed374dab21e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 29 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 30 | Churn Cumulative: 1037 | Contributors (this commit): 16 | Commits (past 90d): 5 | Contributors (cumulative): 16 | DMM Complexity: 1.0\n\nDIFF:\n@@ -296,7 +296,6 @@ def test_loading_weights_by_name_and_reshape():\n         model.load_weights(fname, by_name=False, reshape=False)\n     model.load_weights(fname, by_name=False, reshape=True)\n     model.load_weights(fname, by_name=True, reshape=True)\n-    os.remove(fname)\n \n     out2 = model.predict(x)\n     assert_allclose(np.squeeze(out), np.squeeze(out2), atol=1e-05)\n@@ -307,6 +306,35 @@ def test_loading_weights_by_name_and_reshape():\n             if old_weights[i]:\n                 assert_allclose(old_weights[i][j], new_weights[j], atol=1e-05)\n \n+    # delete and recreate model with `use_bias=False`\n+    del(model)\n+    model = Sequential()\n+    model.add(Conv2D(2, (1, 1), input_shape=(1, 1, 1), use_bias=False, name='rick'))\n+    model.add(Flatten())\n+    model.add(Dense(3, name='morty'))\n+    with pytest.raises(ValueError,\n+                       match=r'.* expects [0-9]+ .* but the saved .* [0-9]+ .*'):\n+        model.load_weights(fname)\n+    with pytest.raises(ValueError,\n+                       match=r'.* expects [0-9]+ .* but the saved .* [0-9]+ .*'):\n+        model.load_weights(fname, by_name=True)\n+    with pytest.warns(UserWarning,\n+                      match=r'Skipping loading .* due to mismatch .*'):\n+        model.load_weights(fname, by_name=True, skip_mismatch=True)\n+\n+    # delete and recreate model with `filters=10`\n+    del(model)\n+    model = Sequential()\n+    model.add(Conv2D(10, (1, 1), input_shape=(1, 1, 1), name='rick'))\n+    with pytest.raises(ValueError,\n+                       match=r'.* has shape .* but the saved .* shape .*'):\n+        model.load_weights(fname, by_name=True)\n+    with pytest.raises(ValueError,\n+                       match=r'.* load .* [0-9]+ layers into .* [0-9]+ layers.'):\n+        model.load_weights(fname)\n+\n+    os.remove(fname)\n+\n \n @keras_test\n def test_loading_weights_by_name_2():\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#86a683540504c6f6ecd44d03941ba4d0a97ad08c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 12362 | Contributors (this commit): 77 | Commits (past 90d): 6 | Contributors (cumulative): 77 | DMM Complexity: None\n\nDIFF:\n@@ -884,7 +884,7 @@ class Dense(Layer):\n     def call(self, inputs):\n         output = K.dot(inputs, self.kernel)\n         if self.use_bias:\n-            output = K.bias_add(output, self.bias)\n+            output = K.bias_add(output, self.bias, data_format='channels_last')\n         if self.activation is not None:\n             output = self.activation(output)\n         return output\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5a7a789ee9766b6a594bd4be8b9edb34e71d6500", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 38 | Lines Deleted: 2 | Files Changed: 4 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 40 | Churn Cumulative: 2842 | Contributors (this commit): 50 | Commits (past 90d): 9 | Contributors (cumulative): 56 | DMM Complexity: None\n\nDIFF:\n@@ -171,6 +171,17 @@ def deserialize(name, custom_objects=None):\n \n \n def get(identifier):\n+    \"\"\"Get the `identifier` activation function.\n+\n+    # Arguments\n+        identifier: None or str, name of the function.\n+\n+    # Returns\n+        The activation function, `linear` if `identifier` is None.\n+\n+    # Raises\n+        ValueError if unknown identifier\n+    \"\"\"\n     if identifier is None:\n         return linear\n     if isinstance(identifier, six.string_types):\n\n@@ -115,6 +115,17 @@ def deserialize(name, custom_objects=None):\n \n \n def get(identifier):\n+    \"\"\"Get the `identifier` loss function.\n+\n+    # Arguments\n+        identifier: None or str, name of the function.\n+\n+    # Returns\n+        The loss function or None if `identifier` is None.\n+\n+    # Raises\n+        ValueError if unknown identifier.\n+    \"\"\"\n     if identifier is None:\n         return None\n     if isinstance(identifier, six.string_types):\n\n@@ -18,6 +18,17 @@ if K.backend() == 'tensorflow':\n \n \n def clip_norm(g, c, n):\n+    \"\"\"Clip the gradient `g` if the L2 norm `n` exceeds `c`.\n+\n+    # Arguments\n+        g: Tensor, the gradient tensor\n+        c: float >= 0. Gradients will be clipped\n+            when their L2 norm exceeds this value.\n+        n: Tensor, actual norm of `g`.\n+\n+    # Returns\n+        Tensor, the gradient clipped if required.\n+    \"\"\"\n     if c <= 0:  # if clipnorm == 0 no need to add ops to the graph\n         return g\n \n\n@@ -6,8 +6,11 @@ from itertools import compress\n \n import pytest\n \n-modules = ['keras.layers', 'keras.models', 'keras', 'keras.backend.tensorflow_backend', 'keras.preprocessing.image',\n-           'keras.preprocessing.text']\n+modules = ['keras.layers', 'keras.models', 'keras',\n+           'keras.backend.tensorflow_backend', 'keras.engine',\n+           'keras.wrappers', 'keras.utils',\n+           'keras.callbacks', 'keras.activations',\n+           'keras.losses', 'keras.models', 'keras.optimizers']\n accepted_name = ['from_config']\n accepted_module = ['keras.legacy.layers', 'keras.utils.generic_utils']\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#354bd35ff47aab7834c3576829dab5d3802fd41a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 803 | Contributors (this commit): 15 | Commits (past 90d): 2 | Contributors (cumulative): 24 | DMM Complexity: None\n\nDIFF:\n@@ -103,7 +103,7 @@ def load_data(path='imdb.npz', num_words=None, skip_top=0,\n \n \n def get_word_index(path='imdb_word_index.json'):\n-    \"\"\"Retrieves the dictionary mapping word indices back to words.\n+    \"\"\"Retrieves the dictionary mapping words to word indices.\n \n     # Arguments\n         path: where to cache the data (relative to `~/.keras/dataset`).\n\n@@ -89,7 +89,7 @@ def load_data(path='reuters.npz', num_words=None, skip_top=0,\n \n \n def get_word_index(path='reuters_word_index.json'):\n-    \"\"\"Retrieves the dictionary mapping word indices back to words.\n+    \"\"\"Retrieves the dictionary mapping words to word indices.\n \n     # Arguments\n         path: where to cache the data (relative to `~/.keras/dataset`).\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#468f080c98f06780c950e5a78c9eeeaf9fff002e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2748 | Contributors (this commit): 12 | Commits (past 90d): 10 | Contributors (cumulative): 14 | DMM Complexity: None\n\nDIFF:\n@@ -4,7 +4,6 @@ from __future__ import print_function\n \n from keras_applications import mobilenet\n \n-relu6 = mobilenet.relu6\n MobileNet = mobilenet.MobileNet\n decode_predictions = mobilenet.decode_predictions\n preprocess_input = mobilenet.preprocess_input\n\n@@ -4,7 +4,6 @@ from __future__ import print_function\n \n from keras_applications import mobilenet_v2\n \n-relu6 = mobilenet_v2.relu6\n MobileNetV2 = mobilenet_v2.MobileNetV2\n decode_predictions = mobilenet_v2.decode_predictions\n preprocess_input = mobilenet_v2.preprocess_input\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8a8a19ba1eb74feb5da22399a44e81b734c2b2d8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 4 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 3601 | Contributors (this commit): 6 | Commits (past 90d): 12 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -33,7 +33,6 @@ class Layer(object):\n             ill-defined (e.g. a shared layer with multiple input\n             shapes), in which case requesting `input_shape` will raise\n             an Exception. Prefer using\n-            `layer.get_input_shape_for(input_shape)`, or\n             `layer.get_input_shape_at(node_index)`.\n         input_spec: List of InputSpec class instances\n             each entry describes one required input:\n\n@@ -159,7 +159,7 @@ class Network(Layer):\n             if not hasattr(x, '_keras_history'):\n                 cls_name = self.__class__.__name__\n                 raise ValueError('Input tensors to a ' + cls_name + ' ' +\n-                                 'must come from `tf.layers.Input`. '\n+                                 'must come from `keras.layers.Input`. '\n                                  'Received: ' + str(x) +\n                                  ' (missing previous layer metadata).')\n             # Check that x is an input tensor.\n@@ -169,7 +169,7 @@ class Network(Layer):\n                      layer._inbound_nodes[0].inbound_layers)):\n                 cls_name = self.__class__.__name__\n                 warnings.warn(cls_name + ' inputs must come from '\n-                              '`tf.layers.Input` '\n+                              '`keras.layers.Input` '\n                               '(thus holding past layer metadata), '\n                               'they cannot be the output of '\n                               'a previous non-Input layer. '\n@@ -180,7 +180,7 @@ class Network(Layer):\n                               layer.name + '.\\n'\n                               'Note that input tensors are '\n                               'instantiated via '\n-                              '`tensor = tf.layers.Input(shape)`.\\n'\n+                              '`tensor = keras.layers.Input(shape)`.\\n'\n                               'The tensor that caused the issue was: ' +\n                               str(x.name))\n         for x in self.outputs:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a9a68bc9deac5d72170ac48c15c41b0defc9753e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 23 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 28 | Churn Cumulative: 489 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -102,7 +102,27 @@ def fit_generator(model,\n     val_enqueuer = None\n \n     try:\n-        if do_validation and not val_gen:\n+        if do_validation:\n+            if val_gen and workers > 0:\n+                # Create an Enqueuer that can be reused\n+                val_data = validation_data\n+                if isinstance(val_data, Sequence):\n+                    val_enqueuer = OrderedEnqueuer(val_data,\n+                                                   use_multiprocessing=use_multiprocessing)\n+                    validation_steps = len(val_data)\n+                else:\n+                    val_enqueuer = GeneratorEnqueuer(val_data,\n+                                                     use_multiprocessing=use_multiprocessing)\n+                val_enqueuer.start(workers=workers,\n+                                   max_queue_size=max_queue_size)\n+                val_enqueuer_gen = val_enqueuer.get()\n+            elif val_gen:\n+                val_data = validation_data\n+                if isinstance(val_data, Sequence):\n+                    val_enqueuer_gen = iter(val_data)\n+                else:\n+                    val_enqueuer_gen = val_data\n+            else:\n                 # Prepare data for validation\n                 if len(validation_data) == 2:\n                     val_x, val_y = validation_data\n@@ -204,11 +224,9 @@ def fit_generator(model,\n                 if steps_done >= steps_per_epoch and do_validation:\n                     if val_gen:\n                         val_outs = model.evaluate_generator(\n-                            validation_data,\n+                            val_enqueuer_gen,\n                             validation_steps,\n-                            workers=workers,\n-                            use_multiprocessing=use_multiprocessing,\n-                            max_queue_size=max_queue_size)\n+                            workers=0)\n                     else:\n                         # No need for try/except because\n                         # data has already been validated.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6eb0c7bdbb68d7de0ef507102c757c7ccbf582a0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 35 | Lines Deleted: 17 | Files Changed: 2 | Hunks: 13 | Methods Changed: 7 | Complexity Δ (Sum/Max): 6/4 | Churn Δ: 52 | Churn Cumulative: 7571 | Contributors (this commit): 40 | Commits (past 90d): 28 | Contributors (cumulative): 51 | DMM Complexity: 1.0\n\nDIFF:\n@@ -369,27 +369,21 @@ def constant(value, dtype=None, shape=None, name=None):\n \n \n def random_binomial(shape, p=0.0, dtype=None, seed=None):\n-    # use numpy workaround now\n     if seed is None:\n         # ensure that randomness is conditioned by the Numpy RNG\n         seed = np.random.randint(10e7)\n-        np.random.seed(seed)\n     if dtype is None:\n         dtype = np.float32\n     else:\n         dtype = _convert_string_dtype(dtype)\n \n-    size = 1\n     for _ in shape:\n         if _ is None:\n             raise ValueError('CNTK Backend: randomness op with '\n                              'dynamic shape is not supported now. '\n                              'Please provide fixed dimension '\n                              'instead of `None`.')\n-        size *= _\n-\n-    binomial = np.random.binomial(1, p, size).astype(dtype).reshape(shape)\n-    return variable(value=binomial, dtype=dtype)\n+    return C.random.bernoulli(shape=shape, dtype=dtype, mean=p, seed=seed)\n \n \n def random_uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None):\n@@ -400,7 +394,10 @@ def random_uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None):\n                              'Please provide fixed dimension '\n                              'instead of `None`.')\n \n-    return random_uniform_variable(shape, minval, maxval, dtype, seed)\n+    if seed is None:\n+        # ensure that randomness is conditioned by the Numpy RNG\n+        seed = np.random.randint(10e3)\n+    return C.random.uniform(shape=shape, dtype=dtype, low=minval, high=maxval, seed=seed)\n \n \n def random_uniform_variable(shape, low, high,\n@@ -450,13 +447,14 @@ def random_normal_variable(\n     if name is None:\n         name = ''\n \n-    return C.parameter(\n+    p = C.parameter(\n         shape=shape,\n         init=C.initializer.normal(\n             scale=scale,\n             seed=seed),\n         dtype=dtype,\n         name=name)\n+    return variable(value=p.value + mean)\n \n \n def random_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n@@ -468,8 +466,10 @@ def random_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n                              'dynamic shape is not supported now. '\n                              'Please provide fixed dimension '\n                              'instead of `None`.')\n-    # how to apply mean and stddev\n-    return random_normal_variable(shape=shape, mean=mean, scale=1.0, seed=seed)\n+    if seed is None:\n+        # ensure that randomness is conditioned by the Numpy RNG\n+        seed = np.random.randint(10e3)\n+    return C.random.normal(shape=shape, mean=mean, scale=stddev, seed=seed, dtype=dtype)\n \n \n def truncated_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n\n@@ -1162,13 +1162,19 @@ class TestBackend(object):\n                                       strides=(1, 1, 1), padding='same', pool_mode='avg')\n \n     def test_random_normal(self):\n-        mean = 0.\n-        std = 1.\n+        # test standard normal as well as a normal with a different set of parameters\n         for k in BACKENDS:\n+            for mean, std in [(0., 1.), (-10., 5.)]:\n                 rand = k.eval(k.random_normal((300, 200), mean=mean, stddev=std, seed=1337))\n                 assert rand.shape == (300, 200)\n-            assert np.abs(np.mean(rand) - mean) < 0.015\n-            assert np.abs(np.std(rand) - std) < 0.015\n+                assert np.abs(np.mean(rand) - mean) < std * 0.015\n+                assert np.abs(np.std(rand) - std) < std * 0.015\n+\n+                # test that random_normal also generates different values when used within a function\n+                r = k.random_normal((1,), mean=mean, stddev=std, seed=1337)\n+                samples = [k.eval(r) for _ in range(60000)]\n+                assert np.abs(np.mean(samples) - mean) < std * 0.015\n+                assert np.abs(np.std(samples) - std) < std * 0.015\n \n     def test_random_uniform(self):\n         min_val = -1.\n@@ -1177,8 +1183,14 @@ class TestBackend(object):\n             rand = k.eval(k.random_uniform((200, 100), min_val, max_val))\n             assert rand.shape == (200, 100)\n             assert np.abs(np.mean(rand)) < 0.015\n-            assert np.max(rand) <= max_val\n-            assert np.min(rand) >= min_val\n+            assert max_val - 0.015 < np.max(rand) <= max_val\n+            assert min_val + 0.015 > np.min(rand) >= min_val\n+\n+            r = k.random_uniform((1,), minval=min_val, maxval=max_val)\n+            samples = [k.eval(r) for _ in range(20000)]\n+            assert np.abs(np.mean(samples)) < 0.015\n+            assert max_val - 0.015 < np.max(samples) <= max_val\n+            assert min_val + 0.015 > np.min(samples) >= min_val\n \n     def test_random_binomial(self):\n         p = 0.5\n@@ -1189,6 +1201,12 @@ class TestBackend(object):\n             assert np.max(rand) == 1\n             assert np.min(rand) == 0\n \n+            r = k.random_binomial((1,), p)\n+            samples = [k.eval(r) for _ in range(20000)]\n+            assert np.abs(np.mean(samples) - p) < 0.015\n+            assert np.max(samples) == 1\n+            assert np.min(samples) == 0\n+\n     def test_truncated_normal(self):\n         mean = 0.\n         std = 1.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b1b3002e11e22287b46865a906f897251745d3df", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 3066 | Contributors (this commit): 74 | Commits (past 90d): 10 | Contributors (cumulative): 74 | DMM Complexity: None\n\nDIFF:\n@@ -634,7 +634,7 @@ class LearningRateScheduler(Callback):\n                              'should be float.')\n         K.set_value(self.model.optimizer.lr, lr)\n         if self.verbose > 0:\n-            print('\\nEpoch %05d: LearningRateScheduler reducing learning '\n+            print('\\nEpoch %05d: LearningRateScheduler setting learning '\n                   'rate to %s.' % (epoch + 1, lr))\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c469e72984ac9d9050ed46e2be4802e7e91861f7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 237 | Contributors (this commit): 11 | Commits (past 90d): 1 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -22,6 +22,7 @@ from keras.utils import to_categorical\n from keras.layers import Dense, Input, GlobalMaxPooling1D\n from keras.layers import Conv1D, MaxPooling1D, Embedding\n from keras.models import Model\n+from keras.initializers import Constant\n \n \n BASE_DIR = ''\n@@ -115,7 +116,7 @@ for word, i in word_index.items():\n # note that we set trainable = False so as to keep the embeddings fixed\n embedding_layer = Embedding(num_words,\n                             EMBEDDING_DIM,\n-                            weights=[embedding_matrix],\n+                            embeddings_initializer=Constant(embedding_matrix),\n                             input_length=MAX_SEQUENCE_LENGTH,\n                             trainable=False)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b3cb261b22a73d195a527592b49ca57e8c9ac9f5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 1611 | Contributors (this commit): 13 | Commits (past 90d): 2 | Contributors (cumulative): 13 | DMM Complexity: None\n\nDIFF:\n@@ -121,7 +121,6 @@ class _Pooling2D(Layer):\n     def __init__(self, pool_size=(2, 2), strides=None, padding='valid',\n                  data_format=None, **kwargs):\n         super(_Pooling2D, self).__init__(**kwargs)\n-        data_format = conv_utils.normalize_data_format(data_format)\n         if strides is None:\n             strides = pool_size\n         self.pool_size = conv_utils.normalize_tuple(pool_size, 2, 'pool_size')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#da5a6ac579dfc80cbb220bf092cd151eca7ffb2d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 7 | Files Changed: 3 | Hunks: 7 | Methods Changed: 5 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 27 | Churn Cumulative: 12976 | Contributors (this commit): 81 | Commits (past 90d): 9 | Contributors (cumulative): 91 | DMM Complexity: 1.0\n\nDIFF:\n@@ -624,7 +624,7 @@ class Lambda(Layer):\n \n     # Output shape\n         Specified by `output_shape` argument\n-        (or auto-inferred when using TensorFlow).\n+        (or auto-inferred when using TensorFlow or CNTK).\n     \"\"\"\n \n     @interfaces.legacy_lambda_support\n@@ -649,8 +649,8 @@ class Lambda(Layer):\n \n     def compute_output_shape(self, input_shape):\n         if self._output_shape is None:\n-            # With TensorFlow, we can infer the output shape directly:\n-            if K.backend() == 'tensorflow':\n+            # With TensorFlow or CNTK, we can infer the output shape directly:\n+            if K.backend() in ('tensorflow', 'cntk'):\n                 if isinstance(input_shape, list):\n                     xs = [K.placeholder(shape=shape) for shape in input_shape]\n                     x = self.call(xs)\n\n@@ -280,6 +280,16 @@ def test_lambda():\n     ld = deserialize_layer({'class_name': 'Lambda', 'config': config})\n \n \n+@keras_test\n+@pytest.mark.skipif((K.backend() == 'theano'),\n+                    reason=\"theano cannot compute \"\n+                           \"the output shape automatically.\")\n+def test_lambda_output_shape():\n+    layer_test(layers.Lambda,\n+               kwargs={'function': lambda x: K.mean(x, axis=-1)},\n+               input_shape=(3, 2, 4))\n+\n+\n @keras_test\n def test_dense():\n     layer_test(layers.Dense,\n\n@@ -65,12 +65,16 @@ def _test_optimizer(optimizer, target=0.75):\n \n \n @keras_test\n-def _test_no_grad(optimizer):\n+@pytest.mark.skipif((K.backend() != 'tensorflow'),\n+                    reason=\"Only Tensorflow raises a \"\n+                           \"ValueError if the gradient is null.\")\n+def test_no_grad():\n     inp = Input([3])\n     x = Dense(10)(inp)\n-    x = Lambda(lambda l: 1.0 * K.reshape(K.cast(K.argmax(l), 'float32'), [-1, 1]))(x)\n+    x = Lambda(lambda l: 1.0 * K.reshape(K.cast(K.argmax(l), 'float32'), [-1, 1]),\n+               output_shape=lambda x: [x[0], 1])(x)\n     mod = Model(inp, x)\n-    mod.compile(optimizer, 'mse')\n+    mod.compile('sgd', 'mse')\n     with pytest.raises(ValueError):\n         mod.fit(np.zeros([10, 3]), np.zeros([10, 1], np.float32), batch_size=10, epochs=10)\n \n@@ -79,7 +83,6 @@ def _test_no_grad(optimizer):\n def test_sgd():\n     sgd = optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)\n     _test_optimizer(sgd)\n-    _test_no_grad(sgd)\n \n \n @keras_test\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
