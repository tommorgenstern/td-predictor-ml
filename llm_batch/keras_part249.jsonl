{"custom_id": "keras#91c701e282592865b453ca25e572ac48fe6a3672", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 8483 | Contributors (this commit): 87 | Commits (past 90d): 15 | Contributors (cumulative): 87 | DMM Complexity: None\n\nDIFF:\n@@ -1340,7 +1340,7 @@ class Model(Network):\n                 List of callbacks to apply during training.\n                 See [callbacks](/callbacks).\n             validation_data: This can be either\n-                - a generator for the validation data\n+                - a generator or a `Sequence` object for the validation data\n                 - tuple `(x_val, y_val)`\n                 - tuple `(x_val, y_val, val_sample_weights)`\n                 on which to evaluate\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4f1ea9affa135121ee2336cd2be541aa2ffa150e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 820 | Contributors (this commit): 6 | Commits (past 90d): 6 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -89,7 +89,7 @@ def NASNet(input_shape=None,\n         input_shape: Optional shape tuple, the input shape\n             is by default `(331, 331, 3)` for NASNetLarge and\n             `(224, 224, 3)` for NASNetMobile.\n-            It should have exactly 3 inputs channels,\n+            It should have exactly 3 input channels,\n             and width and height should be no smaller than 32.\n             E.g. `(224, 224, 3)` would be one valid value.\n         penultimate_filters: Number of filters in the penultimate layer.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b8ac7e07b97c82f4870758fd5ee28ea64af4ee6b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 73 | Contributors (this commit): 2 | Commits (past 90d): 4 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -184,7 +184,7 @@ def multi_gpu_model(model, gpus=None, cpu_merge=True, cpu_relocation=False):\n         batch_size = shape[:1]\n         input_shape = shape[1:]\n         step = batch_size // parts\n-        if i == num_gpus - 1:\n+        if i == parts - 1:\n             size = batch_size - step * i\n         else:\n             size = step\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#14ff5175181e680d75b8d4ad6fe0d7d4dd35beff", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 29 | Lines Deleted: 30 | Files Changed: 1 | Hunks: 11 | Methods Changed: 3 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 59 | Churn Cumulative: 879 | Contributors (this commit): 6 | Commits (past 90d): 7 | Contributors (cumulative): 6 | DMM Complexity: 0.0\n\nDIFF:\n@@ -60,10 +60,10 @@ from ..applications.inception_v3 import preprocess_input\n from ..applications.imagenet_utils import decode_predictions\n from .. import backend as K\n \n-NASNET_MOBILE_WEIGHT_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.8/NASNet-mobile.h5'\n-NASNET_MOBILE_WEIGHT_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.8/NASNet-mobile-no-top.h5'\n-NASNET_LARGE_WEIGHT_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.8/NASNet-large.h5'\n-NASNET_LARGE_WEIGHT_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.8/NASNet-large-no-top.h5'\n+NASNET_MOBILE_WEIGHT_PATH = 'https://github.com/titu1994/Keras-NASNet/releases/download/v1.2/NASNet-mobile.h5'\n+NASNET_MOBILE_WEIGHT_PATH_NO_TOP = 'https://github.com/titu1994/Keras-NASNet/releases/download/v1.2/NASNet-mobile-no-top.h5'\n+NASNET_LARGE_WEIGHT_PATH = 'https://github.com/titu1994/Keras-NASNet/releases/download/v1.2/NASNet-large.h5'\n+NASNET_LARGE_WEIGHT_PATH_NO_TOP = 'https://github.com/titu1994/Keras-NASNet/releases/download/v1.2/NASNet-large-no-top.h5'\n \n \n def NASNet(input_shape=None,\n@@ -102,7 +102,7 @@ def NASNet(input_shape=None,\n                 -   P is the number of penultimate filters\n         stem_block_filters: Number of filters in the initial stem block\n         skip_reduction: Whether to skip the reduction step at the tail\n-            end of the network. Set to `False` for CIFAR models.\n+            end of the network.\n         filter_multiplier: Controls the width of the network.\n             - If `filter_multiplier` < 1.0, proportionally decreases the number\n                 of filters in each layer.\n@@ -210,20 +210,14 @@ def NASNet(input_shape=None,\n     channel_dim = 1 if K.image_data_format() == 'channels_first' else -1\n     filters = penultimate_filters // 24\n \n-    if not skip_reduction:\n     x = Conv2D(stem_block_filters, (3, 3), strides=(2, 2), padding='valid',\n                use_bias=False, name='stem_conv1',\n                kernel_initializer='he_normal')(img_input)\n-    else:\n-        x = Conv2D(stem_block_filters, (3, 3), strides=(1, 1), padding='same',\n-                   use_bias=False, name='stem_conv1',\n-                   kernel_initializer='he_normal')(img_input)\n \n     x = BatchNormalization(axis=channel_dim, momentum=0.9997,\n                            epsilon=1e-3, name='stem_bn1')(x)\n \n     p = None\n-    if not skip_reduction:  # imagenet / mobile mode\n     x, p = _reduction_a_cell(x, p, filters // (filter_multiplier ** 2),\n                              block_id='stem_1')\n     x, p = _reduction_a_cell(x, p, filters // filter_multiplier,\n@@ -274,27 +268,32 @@ def NASNet(input_shape=None,\n     if weights == 'imagenet':\n         if default_size == 224:  # mobile version\n             if include_top:\n-                weight_path = NASNET_MOBILE_WEIGHT_PATH\n-                model_name = 'nasnet_mobile.h5'\n+                weights_path = get_file(\n+                    'nasnet_mobile.h5',\n+                    NASNET_MOBILE_WEIGHT_PATH,\n+                    cache_subdir='models',\n+                    file_hash='020fb642bf7360b370c678b08e0adf61')\n             else:\n-                weight_path = NASNET_MOBILE_WEIGHT_PATH_NO_TOP\n-                model_name = 'nasnet_mobile_no_top.h5'\n-\n-            weights_file = get_file(model_name, weight_path,\n-                                    cache_subdir='models')\n-            model.load_weights(weights_file)\n-\n+                weights_path = get_file(\n+                    'nasnet_mobile_no_top.h5',\n+                    NASNET_MOBILE_WEIGHT_PATH_NO_TOP,\n+                    cache_subdir='models',\n+                    file_hash='1ed92395b5b598bdda52abe5c0dbfd63')\n+            model.load_weights(weights_path)\n         elif default_size == 331:  # large version\n             if include_top:\n-                weight_path = NASNET_LARGE_WEIGHT_PATH\n-                model_name = 'nasnet_large.h5'\n+                weights_path = get_file(\n+                    'nasnet_large.h5',\n+                    NASNET_LARGE_WEIGHT_PATH,\n+                    cache_subdir='models',\n+                    file_hash='11577c9a518f0070763c2b964a382f17')\n             else:\n-                weight_path = NASNET_LARGE_WEIGHT_PATH_NO_TOP\n-                model_name = 'nasnet_large_no_top.h5'\n-\n-            weights_file = get_file(model_name, weight_path,\n-                                    cache_subdir='models')\n-            model.load_weights(weights_file)\n+                weights_path = get_file(\n+                    'nasnet_large_no_top.h5',\n+                    NASNET_LARGE_WEIGHT_PATH_NO_TOP,\n+                    cache_subdir='models',\n+                    file_hash='d81d89dc07e6e56530c4e77faddd61b5')\n+            model.load_weights(weights_path)\n         else:\n             raise ValueError(\n                 'ImageNet weights can only be loaded with NASNetLarge'\n@@ -364,7 +363,7 @@ def NASNetLarge(input_shape=None,\n                   penultimate_filters=4032,\n                   num_blocks=6,\n                   stem_block_filters=96,\n-                  skip_reduction=False,\n+                  skip_reduction=True,\n                   filter_multiplier=2,\n                   include_top=include_top,\n                   weights=weights,\n@@ -630,7 +629,7 @@ def _reduction_a_cell(ip, p, filters, block_id=None):\n             x1_1 = _separable_conv_block(h, filters, (5, 5), strides=(2, 2),\n                                          block_id='reduction_left1_%s' % block_id)\n             x1_2 = _separable_conv_block(p, filters, (7, 7), strides=(2, 2),\n-                                         block_id='reduction_1_%s' % block_id)\n+                                         block_id='reduction_right1_%s' % block_id)\n             x1 = add([x1_1, x1_2], name='reduction_add_1_%s' % block_id)\n \n         with K.name_scope('block_2'):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bf1378f39d02b7d0b53ece5458f9275ac8208046", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 77 | Contributors (this commit): 2 | Commits (past 90d): 5 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -210,6 +210,10 @@ def multi_gpu_model(model, gpus=None, cpu_merge=True, cpu_relocation=False):\n                 inputs = []\n                 # Retrieve a slice of the input.\n                 for x in model.inputs:\n+                    # In-place input splitting which is not only\n+                    # 5% ~ 12% faster but also less GPU memory\n+                    # duplication.\n+                    with tf.device(x.device):\n                         input_shape = K.int_shape(x)[1:]\n                         slice_i = Lambda(get_slice,\n                                          output_shape=input_shape,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2eed2a5d688e8720740f30d281a18fb2c13a15fd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 28 | Lines Deleted: 15 | Files Changed: 1 | Hunks: 6 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 43 | Churn Cumulative: 4289 | Contributors (this commit): 25 | Commits (past 90d): 21 | Contributors (cumulative): 25 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1195,33 +1195,46 @@ class TestBackend(object):\n             assert np.abs(np.std(rand) - std * 0.87962) < 0.015\n \n     def test_conv_invalid_use(self):\n-        with pytest.raises(ValueError):\n-            K.conv1d(K.variable(np.ones((4, 8, 2))),\n-                     K.variable(np.ones((3, 2, 3))),\n-                     data_format='channels_middle')\n+        dummy_x_1d = K.variable(np.ones((4, 8, 2)))\n+        dummy_w_1d = K.variable(np.ones((3, 2, 3)))\n+        dummy_x_2d = K.variable(np.ones((2, 3, 4, 5)))\n+        dummy_w_2d = K.variable(np.ones((2, 2, 3, 4)))\n+        dummy_x_3d = K.variable(np.ones((2, 3, 4, 5, 4)))\n+        dummy_w_3d = K.variable(np.ones((2, 2, 2, 3, 4)))\n+        dummy_w1x1_2d = K.variable(np.ones((1, 1, 12, 7)))\n \n         with pytest.raises(ValueError):\n-            K.conv2d(K.variable(np.ones((2, 3, 4, 5))),\n-                     K.variable(np.ones((2, 2, 3, 4))),\n-                     data_format='channels_middle')\n+            K.conv1d(dummy_x_1d, dummy_w_1d, data_format='channels_middle')\n \n         with pytest.raises(ValueError):\n-            K.conv3d(K.variable(np.ones((2, 3, 4, 5, 4))),\n-                     K.variable(np.ones((2, 2, 2, 3, 4))),\n-                     data_format='channels_middle')\n+            K.conv2d(dummy_x_2d, dummy_w_2d, data_format='channels_middle')\n+\n+        with pytest.raises(ValueError):\n+            K.conv3d(dummy_x_3d, dummy_w_3d, data_format='channels_middle')\n \n         if K.backend() != 'theano':\n             with pytest.raises(ValueError):\n-                K.separable_conv2d(K.variable(np.ones((2, 3, 4, 5))),\n-                                   K.variable(np.ones((2, 2, 3, 4))),\n-                                   K.variable(np.ones((1, 1, 12, 7))),\n+                K.separable_conv2d(dummy_x_2d, dummy_w_2d, dummy_w1x1_2d,\n                                    data_format='channels_middle')\n \n         with pytest.raises(ValueError):\n-            K.depthwise_conv2d(K.variable(np.ones((2, 3, 4, 5))),\n-                               K.variable(np.ones((2, 2, 3, 4))),\n+            K.depthwise_conv2d(dummy_x_2d, dummy_w_2d,\n                                data_format='channels_middle')\n \n+        if K.backend() == 'cntk':\n+            with pytest.raises(ValueError):\n+                K.separable_conv2d(dummy_x_2d, dummy_w_2d, dummy_w1x1_2d,\n+                                   dilation_rate=(1, 2))\n+            with pytest.raises(ValueError):\n+                K.separable_conv2d(dummy_x_2d, dummy_w_2d, dummy_w1x1_2d,\n+                                   strides=(2, 2), dilation_rate=(1, 2))\n+            with pytest.raises(ValueError):\n+                K.depthwise_conv2d(dummy_x_2d, dummy_w_2d,\n+                                   dilation_rate=(1, 2))\n+            with pytest.raises(ValueError):\n+                K.depthwise_conv2d(dummy_x_2d, dummy_w_2d,\n+                                   strides=(2, 2), dilation_rate=(1, 2))\n+\n     def test_pooling_invalid_use(self):\n         for (input_shape, pool_size) in zip([(5, 10, 12, 3), (5, 10, 12, 6, 3)], [(2, 2), (2, 2, 2)]):\n             x = K.variable(np.random.random(input_shape))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#abd029405c97733de24102695cb4b6cef1f47bff", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 115 | Contributors (this commit): 8 | Commits (past 90d): 3 | Contributors (cumulative): 8 | DMM Complexity: 1.0\n\nDIFF:\n@@ -61,7 +61,6 @@ def model_to_dot(model,\n     if isinstance(model, Sequential):\n         if not model.built:\n             model.build()\n-        model = model.model\n     layers = model.layers\n \n     # Create graph nodes.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#25a8973dfce5251c0bd527ffa16ce17174b94218", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 24 | Lines Deleted: 82 | Files Changed: 1 | Hunks: 4 | Methods Changed: 4 | Complexity Δ (Sum/Max): -6/0 | Churn Δ: 106 | Churn Cumulative: 3169 | Contributors (this commit): 20 | Commits (past 90d): 15 | Contributors (cumulative): 20 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2025,20 +2025,8 @@ def function(inputs, outputs, updates=[], **kwargs):\n def temporal_padding(x, padding=(1, 1)):\n     assert len(padding) == 2\n     num_dynamic_axis = _get_dynamic_axis_num(x)\n-    base_shape = x.shape\n-    if num_dynamic_axis > 0:\n-        assert len(base_shape) == 2\n-        if hasattr(C, 'pad'):\n-            x = C.pad(x, pattern=[padding, (0, 0)])\n-        else:\n-            x = _padding(x, padding, 0)\n-    else:\n-        assert len(base_shape) == 3\n-        if hasattr(C, 'pad'):\n-            x = C.pad(x, pattern=[(0, 0), padding, (0, 0)])\n-        else:\n-            x = _padding(x, padding, 1)\n-    return x\n+    assert len(x.shape) == 3 - (1 if num_dynamic_axis > 0 else 0)\n+    return pad(x, [padding], 'channels_last', num_dynamic_axis)\n \n \n def _padding(x, pattern, axis):\n@@ -2062,6 +2050,24 @@ def _padding(x, pattern, axis):\n     return x\n \n \n+def pad(x, pad_info, data_format, num_dynamic_axis):\n+    if hasattr(C, 'pad'):\n+        pattern = [list(p) for p in pad_info]\n+        if data_format == 'channels_first':\n+            pattern = [[0, 0]] + pattern\n+        else:\n+            pattern = pattern + [[0, 0]]\n+        if num_dynamic_axis == 0:\n+            pattern = [[0, 0]] + pattern\n+        return C.pad(x, pattern=pattern)\n+    else:\n+        for (a, p) in enumerate(pad_info):\n+            x = _padding(x, p,\n+                         a + (1 if num_dynamic_axis == 0 else 0) +\n+                         (1 if data_format == 'channels_first' else 0))\n+        return x\n+\n+\n def spatial_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None):\n     assert len(padding) == 2\n     assert len(padding[0]) == 2\n@@ -2072,38 +2078,8 @@ def spatial_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None):\n         raise ValueError('Unknown data_format ' + str(data_format))\n \n     num_dynamic_axis = _get_dynamic_axis_num(x)\n-    base_shape = x.shape\n-    if data_format == 'channels_first':\n-        if num_dynamic_axis > 0:\n-            assert len(base_shape) == 3\n-            if hasattr(C, 'pad'):\n-                x = C.pad(x, pattern=[[0, 0], list(padding[0]), list(padding[1])])\n-            else:\n-                x = _padding(x, padding[0], 1)\n-                x = _padding(x, padding[1], 2)\n-        else:\n-            assert len(base_shape) == 4\n-            if hasattr(C, 'pad'):\n-                x = C.pad(x, pattern=[[0, 0], [0, 0], list(padding[0]), list(padding[1])])\n-            else:\n-                x = _padding(x, padding[0], 2)\n-                x = _padding(x, padding[1], 3)\n-    else:\n-        if num_dynamic_axis > 0:\n-            assert len(base_shape) == 3\n-            if hasattr(C, 'pad'):\n-                x = C.pad(x, pattern=[list(padding[0]), list(padding[1]), [0, 0]])\n-            else:\n-                x = _padding(x, padding[0], 0)\n-                x = _padding(x, padding[1], 1)\n-        else:\n-            assert len(base_shape) == 4\n-            if hasattr(C, 'pad'):\n-                x = C.pad(x, pattern=[[0, 0], list(padding[0]), list(padding[1]), [0, 0]])\n-            else:\n-                x = _padding(x, padding[0], 1)\n-                x = _padding(x, padding[1], 2)\n-    return x\n+    assert len(x.shape) == 4 - (1 if num_dynamic_axis > 0 else 0)\n+    return pad(x, padding, data_format, num_dynamic_axis)\n \n \n def spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None):\n@@ -2117,42 +2093,8 @@ def spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None):\n         raise ValueError('Unknown data_format ' + str(data_format))\n \n     num_dynamic_axis = _get_dynamic_axis_num(x)\n-    base_shape = x.shape\n-    if data_format == 'channels_first':\n-        if num_dynamic_axis > 0:\n-            assert len(base_shape) == 4\n-            if hasattr(C, 'pad'):\n-                x = C.pad(x, pattern=[[0, 0], list(padding[0]), list(padding[1]), list(padding[2])])\n-            else:\n-                x = _padding(x, padding[0], 1)\n-                x = _padding(x, padding[1], 2)\n-                x = _padding(x, padding[2], 3)\n-        else:\n-            assert len(base_shape) == 5\n-            if hasattr(C, 'pad'):\n-                x = C.pad(x, pattern=[[0, 0], [0, 0], list(padding[0]), list(padding[1]), list(padding[2])])\n-            else:\n-                x = _padding(x, padding[0], 2)\n-                x = _padding(x, padding[1], 3)\n-                x = _padding(x, padding[2], 4)\n-    else:\n-        if num_dynamic_axis > 0:\n-            assert len(base_shape) == 4\n-            if hasattr(C, 'pad'):\n-                x = C.pad(x, pattern=[list(padding[0]), list(padding[1]), list(padding[2]), [0, 0]])\n-            else:\n-                x = _padding(x, padding[0], 0)\n-                x = _padding(x, padding[1], 1)\n-                x = _padding(x, padding[2], 2)\n-        else:\n-            assert len(base_shape) == 5\n-            if hasattr(C, 'pad'):\n-                x = C.pad(x, pattern=[[0, 0], list(padding[0]), list(padding[1]), list(padding[2]), [0, 0]])\n-            else:\n-                x = _padding(x, padding[0], 1)\n-                x = _padding(x, padding[1], 2)\n-                x = _padding(x, padding[2], 3)\n-    return x\n+    assert len(x.shape) == 5 - (1 if num_dynamic_axis > 0 else 0)\n+    return pad(x, padding, data_format, num_dynamic_axis)\n \n \n def one_hot(indices, num_classes):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#08c873669f39b37743014db99fcd2d308f8ea5ea", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 262 | Lines Deleted: 98 | Files Changed: 2 | Hunks: 40 | Methods Changed: 17 | Complexity Δ (Sum/Max): 6/5 | Churn Δ: 360 | Churn Cumulative: 4723 | Contributors (this commit): 57 | Commits (past 90d): 22 | Contributors (cumulative): 69 | DMM Complexity: 0.6813186813186813\n\nDIFF:\n@@ -62,14 +62,9 @@ def random_rotation(x, rg, row_axis=1, col_axis=2, channel_axis=0,\n     # Returns\n         Rotated Numpy image tensor.\n     \"\"\"\n-    theta = np.deg2rad(np.random.uniform(-rg, rg))\n-    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n-                                [np.sin(theta), np.cos(theta), 0],\n-                                [0, 0, 1]])\n-\n-    h, w = x.shape[row_axis], x.shape[col_axis]\n-    transform_matrix = transform_matrix_offset_center(rotation_matrix, h, w)\n-    x = apply_transform(x, transform_matrix, channel_axis, fill_mode, cval)\n+    theta = np.random.uniform(-rg, rg)\n+    x = apply_affine_transform(x, theta=theta, channel_axis=channel_axis,\n+                               fill_mode=fill_mode, cval=cval)\n     return x\n \n \n@@ -96,12 +91,8 @@ def random_shift(x, wrg, hrg, row_axis=1, col_axis=2, channel_axis=0,\n     h, w = x.shape[row_axis], x.shape[col_axis]\n     tx = np.random.uniform(-hrg, hrg) * h\n     ty = np.random.uniform(-wrg, wrg) * w\n-    translation_matrix = np.array([[1, 0, tx],\n-                                   [0, 1, ty],\n-                                   [0, 0, 1]])\n-\n-    transform_matrix = translation_matrix  # no need to do offset\n-    x = apply_transform(x, transform_matrix, channel_axis, fill_mode, cval)\n+    x = apply_affine_transform(x, tx=tx, ty=ty, channel_axis=channel_axis,\n+                               fill_mode=fill_mode, cval=cval)\n     return x\n \n \n@@ -124,14 +115,9 @@ def random_shear(x, intensity, row_axis=1, col_axis=2, channel_axis=0,\n     # Returns\n         Sheared Numpy image tensor.\n     \"\"\"\n-    shear = np.deg2rad(np.random.uniform(-intensity, intensity))\n-    shear_matrix = np.array([[1, -np.sin(shear), 0],\n-                             [0, np.cos(shear), 0],\n-                             [0, 0, 1]])\n-\n-    h, w = x.shape[row_axis], x.shape[col_axis]\n-    transform_matrix = transform_matrix_offset_center(shear_matrix, h, w)\n-    x = apply_transform(x, transform_matrix, channel_axis, fill_mode, cval)\n+    shear = np.random.uniform(-intensity, intensity)\n+    x = apply_affine_transform(x, shear=shear, channel_axis=channel_axis,\n+                               fill_mode=fill_mode, cval=cval)\n     return x\n \n \n@@ -165,18 +151,13 @@ def random_zoom(x, zoom_range, row_axis=1, col_axis=2, channel_axis=0,\n         zx, zy = 1, 1\n     else:\n         zx, zy = np.random.uniform(zoom_range[0], zoom_range[1], 2)\n-    zoom_matrix = np.array([[zx, 0, 0],\n-                            [0, zy, 0],\n-                            [0, 0, 1]])\n-\n-    h, w = x.shape[row_axis], x.shape[col_axis]\n-    transform_matrix = transform_matrix_offset_center(zoom_matrix, h, w)\n-    x = apply_transform(x, transform_matrix, channel_axis, fill_mode, cval)\n+    x = apply_affine_transform(x, zx=zx, zy=zy, channel_axis=channel_axis,\n+                               fill_mode=fill_mode, cval=cval)\n     return x\n \n \n-def random_channel_shift(x, intensity, channel_axis=0):\n-    \"\"\"Performs a random channel shift.\n+def apply_channel_shift(x, intensity, channel_axis=0):\n+    \"\"\"Performs a channel shift.\n \n     # Arguments\n         x: Input tensor. Must be 3D.\n@@ -190,7 +171,7 @@ def random_channel_shift(x, intensity, channel_axis=0):\n     x = np.rollaxis(x, channel_axis, 0)\n     min_x, max_x = np.min(x), np.max(x)\n     channel_images = [\n-        np.clip(x_channel + np.random.uniform(-intensity, intensity),\n+        np.clip(x_channel + intensity,\n                 min_x,\n                 max_x)\n         for x_channel in x]\n@@ -199,6 +180,42 @@ def random_channel_shift(x, intensity, channel_axis=0):\n     return x\n \n \n+def random_channel_shift(x, intensity_range, channel_axis=0):\n+    \"\"\"Performs a random channel shift.\n+\n+    # Arguments\n+        x: Input tensor. Must be 3D.\n+        intensity_range: Transformation intensity.\n+        channel_axis: Index of axis for channels in the input tensor.\n+\n+    # Returns\n+        Numpy image tensor.\n+    \"\"\"\n+    intensity = np.random.uniform(-intensity_range, intensity_range)\n+    return apply_channel_shift(x, intensity, channel_axis=channel_axis)\n+\n+\n+def apply_brightness_shift(x, brightness):\n+    \"\"\"Performs a brightness shift.\n+\n+    # Arguments\n+        x: Input tensor. Must be 3D.\n+        brightness: Float. The new brightness value.\n+        channel_axis: Index of axis for channels in the input tensor.\n+\n+    # Returns\n+        Numpy image tensor.\n+\n+    # Raises\n+        ValueError if `brightness_range` isn't a tuple.\n+    \"\"\"\n+    x = array_to_img(x)\n+    x = imgenhancer_Brightness = ImageEnhance.Brightness(x)\n+    x = imgenhancer_Brightness.enhance(brightness)\n+    x = img_to_array(x)\n+    return x\n+\n+\n def random_brightness(x, brightness_range):\n     \"\"\"Performs a random brightness shift.\n \n@@ -212,19 +229,14 @@ def random_brightness(x, brightness_range):\n \n     # Raises\n         ValueError if `brightness_range` isn't a tuple.\n-\n     \"\"\"\n     if len(brightness_range) != 2:\n         raise ValueError(\n             '`brightness_range should be tuple or list of two floats. '\n             'Received: %s' % brightness_range)\n \n-    x = array_to_img(x)\n-    x = imgenhancer_Brightness = ImageEnhance.Brightness(x)\n     u = np.random.uniform(brightness_range[0], brightness_range[1])\n-    x = imgenhancer_Brightness.enhance(u)\n-    x = img_to_array(x)\n-    return x\n+    return apply_brightness_shift(x, u)\n \n \n def transform_matrix_offset_center(matrix, x, y):\n@@ -236,17 +248,22 @@ def transform_matrix_offset_center(matrix, x, y):\n     return transform_matrix\n \n \n-def apply_transform(x,\n-                    transform_matrix,\n-                    channel_axis=0,\n-                    fill_mode='nearest',\n-                    cval=0.):\n-    \"\"\"Applies the image transformation specified by a matrix.\n+def apply_affine_transform(x, theta=0, tx=0, ty=0, shear=0, zx=1, zy=1,\n+                           row_axis=0, col_axis=1, channel_axis=2,\n+                           fill_mode='nearest', cval=0.):\n+    \"\"\"Applies an affine transformation specified by the parameters given.\n \n     # Arguments\n         x: 2D numpy array, single image.\n-        transform_matrix: Numpy array specifying the geometric transformation.\n-        channel_axis: Index of axis for channels in the input tensor.\n+        theta: Rotation angle in degrees.\n+        tx: Width shift.\n+        ty: Heigh shift.\n+        shear: Shear angle in degrees.\n+        zx: Zoom in x direction.\n+        zy: Zoom in y direction\n+        row_axis: Index of axis for rows in the input image.\n+        col_axis: Index of axis for columns in the input image.\n+        channel_axis: Index of axis for channels in the input image.\n         fill_mode: Points outside the boundaries of the input\n             are filled according to the given mode\n             (one of `{'constant', 'nearest', 'reflect', 'wrap'}`).\n@@ -256,9 +273,41 @@ def apply_transform(x,\n     # Returns\n         The transformed version of the input.\n     \"\"\"\n+    transform_matrix = None\n+    if theta != 0:\n+        theta = np.deg2rad(theta)\n+        rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n+                                    [np.sin(theta), np.cos(theta), 0],\n+                                    [0, 0, 1]])\n+        transform_matrix = rotation_matrix\n+\n+    if tx != 0 or ty != 0:\n+        shift_matrix = np.array([[1, 0, tx],\n+                                 [0, 1, ty],\n+                                 [0, 0, 1]])\n+        transform_matrix = shift_matrix if transform_matrix is None else np.dot(transform_matrix, shift_matrix)\n+\n+    if shear != 0:\n+        shear = np.deg2rad(shear)\n+        shear_matrix = np.array([[1, -np.sin(shear), 0],\n+                                 [0, np.cos(shear), 0],\n+                                 [0, 0, 1]])\n+        transform_matrix = shear_matrix if transform_matrix is None else np.dot(transform_matrix, shear_matrix)\n+\n+    if zx != 1 or zy != 1:\n+        zoom_matrix = np.array([[zx, 0, 0],\n+                                [0, zy, 0],\n+                                [0, 0, 1]])\n+        transform_matrix = zoom_matrix if transform_matrix is None else np.dot(transform_matrix, zoom_matrix)\n+\n+    if transform_matrix is not None:\n+        h, w = x.shape[row_axis], x.shape[col_axis]\n+        transform_matrix = transform_matrix_offset_center(\n+            transform_matrix, h, w)\n         x = np.rollaxis(x, channel_axis, 0)\n         final_affine_matrix = transform_matrix[:2, :2]\n         final_offset = transform_matrix[:2, 2]\n+\n         channel_images = [ndi.interpolation.affine_transform(\n             x_channel,\n             final_affine_matrix,\n@@ -920,30 +969,27 @@ class ImageDataGenerator(object):\n                               'first by calling `.fit(numpy_data)`.')\n         return x\n \n-    def random_transform(self, x, seed=None):\n-        \"\"\"Randomly augments a single image tensor.\n+    def get_random_transform(self, img_shape, seed=None):\n+        \"\"\"Generates random parameters for a transformation.\n \n         # Arguments\n-            x: 3D tensor, single image.\n             seed: Random seed.\n+            img_shape: Tuple of integers. Shape of the image that is transformed.\n \n         # Returns\n-            A randomly transformed version of the input (same shape).\n+            A dictionary containing randomly chosen parameters describing the\n+            transformation.\n         \"\"\"\n-        # x is a single image, so it doesn't have image number at index 0\n         img_row_axis = self.row_axis - 1\n         img_col_axis = self.col_axis - 1\n-        img_channel_axis = self.channel_axis - 1\n \n         if seed is not None:\n             np.random.seed(seed)\n \n-        # Use composition of homographies\n-        # to generate final transform that needs to be applied\n         if self.rotation_range:\n-            theta = np.deg2rad(np.random.uniform(\n+            theta = np.random.uniform(\n                 -self.rotation_range,\n-                self.rotation_range))\n+                self.rotation_range)\n         else:\n             theta = 0\n \n@@ -955,7 +1001,7 @@ class ImageDataGenerator(object):\n                 tx = np.random.uniform(-self.height_shift_range,\n                                        self.height_shift_range)\n             if np.max(self.height_shift_range) < 1:\n-                tx *= x.shape[img_row_axis]\n+                tx *= img_shape[img_row_axis]\n         else:\n             tx = 0\n \n@@ -967,14 +1013,14 @@ class ImageDataGenerator(object):\n                 ty = np.random.uniform(-self.width_shift_range,\n                                        self.width_shift_range)\n             if np.max(self.width_shift_range) < 1:\n-                ty *= x.shape[img_col_axis]\n+                ty *= img_shape[img_col_axis]\n         else:\n             ty = 0\n \n         if self.shear_range:\n-            shear = np.deg2rad(np.random.uniform(\n+            shear = np.random.uniform(\n                 -self.shear_range,\n-                self.shear_range))\n+                self.shear_range)\n         else:\n             shear = 0\n \n@@ -985,55 +1031,103 @@ class ImageDataGenerator(object):\n                 self.zoom_range[0],\n                 self.zoom_range[1],\n                 2)\n-        transform_matrix = None\n-        if theta != 0:\n-            rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n-                                        [np.sin(theta), np.cos(theta), 0],\n-                                        [0, 0, 1]])\n-            transform_matrix = rotation_matrix\n \n-        if tx != 0 or ty != 0:\n-            shift_matrix = np.array([[1, 0, tx],\n-                                     [0, 1, ty],\n-                                     [0, 0, 1]])\n-            transform_matrix = shift_matrix if transform_matrix is None else np.dot(transform_matrix, shift_matrix)\n+        flip_horizontal = (np.random.random() < 0.5) * self.horizontal_flip\n+        flip_vertical = (np.random.random() < 0.5) * self.vertical_flip\n \n-        if shear != 0:\n-            shear_matrix = np.array([[1, -np.sin(shear), 0],\n-                                    [0, np.cos(shear), 0],\n-                                    [0, 0, 1]])\n-            transform_matrix = shear_matrix if transform_matrix is None else np.dot(transform_matrix, shear_matrix)\n+        channel_shift_intensity = None\n+        if self.channel_shift_range != 0:\n+            channel_shift_intensity = np.random.uniform(-self.channel_shift_range,\n+                                                        self.channel_shift_range)\n \n-        if zx != 1 or zy != 1:\n-            zoom_matrix = np.array([[zx, 0, 0],\n-                                    [0, zy, 0],\n-                                    [0, 0, 1]])\n-            transform_matrix = zoom_matrix if transform_matrix is None else np.dot(transform_matrix, zoom_matrix)\n+        brightness = None\n+        if self.brightness_range is not None:\n+            if len(self.brightness_range) != 2:\n+                raise ValueError(\n+                    '`brightness_range should be tuple or list of two floats. '\n+                    'Received: %s' % brightness_range)\n+            brightness = np.random.uniform(self.brightness_range[0],\n+                                           self.brightness_range[1])\n \n-        if transform_matrix is not None:\n-            h, w = x.shape[img_row_axis], x.shape[img_col_axis]\n-            transform_matrix = transform_matrix_offset_center(\n-                transform_matrix, h, w)\n-            x = apply_transform(x, transform_matrix, img_channel_axis,\n+        transform_parameters = {'theta': theta,\n+                                'tx': tx,\n+                                'ty': ty,\n+                                'shear': shear,\n+                                'zx': zx,\n+                                'zy': zy,\n+                                'flip_horizontal': flip_horizontal,\n+                                'flip_vertical': flip_vertical,\n+                                'channel_shift_intensity': channel_shift_intensity,\n+                                'brightness': brightness}\n+\n+        return transform_parameters\n+\n+    def apply_transform(self, x, transform_parameters):\n+        \"\"\"Applies a transformation to an image according to given parameters.\n+\n+        # Arguments\n+            x: 3D tensor, single image.\n+            transform_parameters: Dictionary with string - parameter pairs\n+              describing the transformation. Currently, the following parameters\n+              from the dictionary are used:\n+              - `'theta'`: Float. Rotation angle in degrees.\n+              - `'tx'`: Float. Shift in the x direction.\n+              - `'ty'`: Float. Shift in the y direction.\n+              - `'shear'`: Float. Shear angle in degrees.\n+              - `'zx'`: Float. Zoom in the x direction.\n+              - `'zy'`: Float. Zoom in the y direction.\n+              - `'flip_horizontal'`: Boolean. Horizontal flip.\n+              - `'flip_vertical'`: Boolean. Vertical flip.\n+              - `'channel_shift_intencity'`: Float. Channel shift intensity.\n+              - `'brightness'`: Float. Brightness shift intensity.\n+\n+        # Returns\n+            A ransformed version of the input (same shape).\n+        \"\"\"\n+        # x is a single image, so it doesn't have image number at index 0\n+        img_row_axis = self.row_axis - 1\n+        img_col_axis = self.col_axis - 1\n+        img_channel_axis = self.channel_axis - 1\n+\n+        x = apply_affine_transform(x, transform_parameters.get('theta', 0),\n+                                   transform_parameters.get('tx', 0),\n+                                   transform_parameters.get('ty', 0),\n+                                   transform_parameters.get('shear', 0),\n+                                   transform_parameters.get('zx', 1),\n+                                   transform_parameters.get('zy', 1),\n+                                   row_axis=img_row_axis, col_axis=img_col_axis,\n+                                   channel_axis=img_channel_axis,\n                                    fill_mode=self.fill_mode, cval=self.cval)\n \n-        if self.channel_shift_range != 0:\n-            x = random_channel_shift(x,\n-                                     self.channel_shift_range,\n+        if transform_parameters.get('channel_shift_intensity') is not None:\n+            x = apply_channel_shift(x,\n+                                    transform_parameters['channel_shift_intensity'],\n                                     img_channel_axis)\n-        if self.horizontal_flip:\n-            if np.random.random() < 0.5:\n+\n+        if transform_parameters.get('flip_horizontal', False):\n             x = flip_axis(x, img_col_axis)\n \n-        if self.vertical_flip:\n-            if np.random.random() < 0.5:\n+        if transform_parameters.get('flip_vertical', False):\n             x = flip_axis(x, img_row_axis)\n \n-        if self.brightness_range is not None:\n-            x = random_brightness(x, self.brightness_range)\n+        if transform_parameters.get('brightness') is not None:\n+            x = apply_brightness_shift(x, transform_parameters['brightness'])\n \n         return x\n \n+    def random_transform(self, x, seed=None):\n+        \"\"\"Applies a random transformation to an image.\n+\n+        # Arguments\n+            x: 3D tensor, single image.\n+            seed: Random seed.\n+\n+        # Returns\n+            A randomly transformed version of the input (same shape).\n+        \"\"\"\n+        params = self.get_random_transform(x.shape, seed)\n+        return self.apply_transform(x, params)\n+\n     def fit(self, x,\n             augment=False,\n             rounds=1,\n@@ -1314,8 +1408,9 @@ class NumpyArrayIterator(Iterator):\n                            dtype=K.floatx())\n         for i, j in enumerate(index_array):\n             x = self.x[j]\n-            x = self.image_data_generator.random_transform(\n-                x.astype(K.floatx()))\n+            params = self.image_data_generator.get_random_transform(x.shape)\n+            x = self.image_data_generator.apply_transform(\n+                x.astype(K.floatx()), params)\n             x = self.image_data_generator.standardize(x)\n             batch_x[i] = x\n \n@@ -1621,7 +1716,8 @@ class DirectoryIterator(Iterator):\n                            target_size=self.target_size,\n                            interpolation=self.interpolation)\n             x = img_to_array(img, data_format=self.data_format)\n-            x = self.image_data_generator.random_transform(x)\n+            params = self.image_data_generator.get_random_transform(x.shape)\n+            x = self.image_data_generator.apply_transform(x, params)\n             x = self.image_data_generator.standardize(x)\n             batch_x[i] = x\n         # optionally save augmented images to disk for debugging purposes\n\n@@ -452,6 +452,74 @@ class TestImage(object):\n         assert image.random_zoom(x, (5, 5)).shape == (2, 28, 28)\n         assert image.random_channel_shift(x, 20).shape == (2, 28, 28)\n \n+        # Test get_random_transform with predefined seed\n+        seed = 1\n+        generator = image.ImageDataGenerator(\n+            rotation_range=90.,\n+            width_shift_range=0.1,\n+            height_shift_range=0.1,\n+            shear_range=0.5,\n+            zoom_range=0.2,\n+            channel_shift_range=0.1,\n+            brightness_range=(1, 5),\n+            horizontal_flip=True,\n+            vertical_flip=True)\n+        transform_dict = generator.get_random_transform(x.shape, seed)\n+        transform_dict2 = generator.get_random_transform(x.shape, seed * 2)\n+        assert transform_dict['theta'] != 0\n+        assert transform_dict['theta'] != transform_dict2['theta']\n+        assert transform_dict['tx'] != 0\n+        assert transform_dict['tx'] != transform_dict2['tx']\n+        assert transform_dict['ty'] != 0\n+        assert transform_dict['ty'] != transform_dict2['ty']\n+        assert transform_dict['shear'] != 0\n+        assert transform_dict['shear'] != transform_dict2['shear']\n+        assert transform_dict['zx'] != 0\n+        assert transform_dict['zx'] != transform_dict2['zx']\n+        assert transform_dict['zy'] != 0\n+        assert transform_dict['zy'] != transform_dict2['zy']\n+        assert transform_dict['channel_shift_intensity'] != 0\n+        assert transform_dict['channel_shift_intensity'] != transform_dict2['channel_shift_intensity']\n+        assert transform_dict['brightness'] != 0\n+        assert transform_dict['brightness'] != transform_dict2['brightness']\n+\n+        # Test get_random_transform without any randomness\n+        generator = image.ImageDataGenerator()\n+        transform_dict = generator.get_random_transform(x.shape, seed)\n+        assert transform_dict['theta'] == 0\n+        assert transform_dict['tx'] == 0\n+        assert transform_dict['ty'] == 0\n+        assert transform_dict['shear'] == 0\n+        assert transform_dict['zx'] == 1\n+        assert transform_dict['zy'] == 1\n+        assert transform_dict['channel_shift_intensity'] is None\n+        assert transform_dict['brightness'] is None\n+\n+    def test_deterministic_transform(self):\n+        x = np.ones((32, 32, 3))\n+        generator = image.ImageDataGenerator(\n+            rotation_range=90,\n+            fill_mode='constant')\n+        x = np.random.random((32, 32, 3))\n+        assert np.allclose(generator.apply_transform(x, {'flip_vertical': True}),\n+                           x[::-1, :, :])\n+        assert np.allclose(generator.apply_transform(x, {'flip_horizontal': True}),\n+                           x[:, ::-1, :])\n+        x = np.ones((3, 3, 3))\n+        x_rotated = np.array([[[0., 0., 0.],\n+                               [0., 0., 0.],\n+                               [1., 1., 1.]],\n+                              [[0., 0., 0.],\n+                               [1., 1., 1.],\n+                               [1., 1., 1.]],\n+                              [[0., 0., 0.],\n+                               [0., 0., 0.],\n+                               [1., 1., 1.]]])\n+        assert np.allclose(generator.apply_transform(x, {'theta': 45}),\n+                           x_rotated)\n+        assert np.allclose(image.apply_affine_transform(x, theta=45, channel_axis=2,\n+                                                        fill_mode='constant'), x_rotated)\n+\n     def test_batch_standardize(self):\n         # ImageDataGenerator.standardize should work on batches\n         for test_images in self.all_test_images:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c77267af5fff5642951ae4a2c9bb09fb6d698c30", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 3 | Churn Cumulative: 1092 | Contributors (this commit): 4 | Commits (past 90d): 7 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -292,9 +292,6 @@ def load_model(filepath, custom_objects=None, compile=True):\n             # Set optimizer weights.\n             if 'optimizer_weights' in f:\n                 # Build train function (to get weight updates).\n-                if model.__class__.__name__ == 'Sequential':\n-                    model.model._make_train_function()\n-                else:\n                 model._make_train_function()\n                 optimizer_weights_group = f['optimizer_weights']\n                 optimizer_weight_names = [\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#20644772372738708660cd3f9404f1760fb7e9fe", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 298 | Contributors (this commit): 15 | Commits (past 90d): 3 | Contributors (cumulative): 15 | DMM Complexity: None\n\nDIFF:\n@@ -89,7 +89,7 @@ def softplus(x):\n         x: Input tensor.\n \n     # Returns\n-        The softplus activation: `log(exp(x) + 1`.\n+        The softplus activation: `log(exp(x) + 1)`.\n     \"\"\"\n     return K.softplus(x)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5a48df22f0d9dd5b365ed5afc9923424d2e8c2c9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 850 | Contributors (this commit): 14 | Commits (past 90d): 2 | Contributors (cumulative): 14 | DMM Complexity: None\n\nDIFF:\n@@ -408,7 +408,7 @@ class Concatenate(_Merge):\n class Dot(_Merge):\n     \"\"\"Layer that computes a dot product between samples in two tensors.\n \n-    E.g. if applied to two tensors `a` and `b` of shape `(batch_size, n)`,\n+    E.g. if applied to a list of two tensors `a` and `b` of shape `(batch_size, n)`,\n     the output will be a tensor of shape `(batch_size, 1)`\n     where each entry `i` will be the dot product between\n     `a[i]` and `b[i]`.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d476ecc7eb23509350b60c8cd917808ee4c61d29", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 3 | Churn Cumulative: 1122 | Contributors (this commit): 23 | Commits (past 90d): 2 | Contributors (cumulative): 23 | DMM Complexity: 1.0\n\nDIFF:\n@@ -175,8 +175,7 @@ def print_summary(model, line_length=None, positions=None, print_fn=None):\n     else:\n         trainable_count = count_params(model.trainable_weights)\n \n-    non_trainable_count = int(\n-        np.sum([K.count_params(p) for p in set(model.non_trainable_weights)]))\n+    non_trainable_count = count_params(model.non_trainable_weights)\n \n     print_fn(\n         'Total params: {:,}'.format(trainable_count + non_trainable_count))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5eecd55a6f1d6d149b42f9b76aa53d4c5ab8d3eb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 1104 | Contributors (this commit): 5 | Commits (past 90d): 8 | Contributors (cumulative): 5 | DMM Complexity: 0.0\n\nDIFF:\n@@ -987,15 +987,23 @@ def load_weights_from_hdf5_group_by_name(f, layers, skip_mismatch=False,\n                                      ' element(s).')\n             # Set values.\n             for i in range(len(weight_values)):\n-                if skip_mismatch:\n                 if K.int_shape(symbolic_weights[i]) != weight_values[i].shape:\n+                    if skip_mismatch:\n                         warnings.warn('Skipping loading of weights for layer {}'.format(layer.name) +\n                                       ' due to mismatch in shape' +\n                                       ' ({} vs {}).'.format(\n                                           symbolic_weights[i].shape,\n                                           weight_values[i].shape))\n                         continue\n-\n+                    else:\n+                        raise ValueError('Layer #' + str(k) +\n+                                         ' (named \"' + layer.name +\n+                                         '\"), weight ' +\n+                                         str(symbolic_weights[i]) +\n+                                         ' has shape {}'.format(K.int_shape(symbolic_weights[i])) +\n+                                         ', but the saved weight has shape ' +\n+                                         str(weight_values[i].shape) + '.')\n+                else:\n                     weight_value_tuples.append((symbolic_weights[i],\n                                                 weight_values[i]))\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
