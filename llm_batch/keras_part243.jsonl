{"custom_id": "keras#14113279768e0511d6adb7b2ffad21863a7c969d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 24 | Lines Deleted: 56 | Files Changed: 1 | Hunks: 14 | Methods Changed: 2 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 80 | Churn Cumulative: 5649 | Contributors (this commit): 81 | Commits (past 90d): 8 | Contributors (cumulative): 81 | DMM Complexity: 1.0\n\nDIFF:\n@@ -277,7 +277,7 @@ def int_shape(x):\n     if hasattr(x, '_keras_shape'):\n         return x._keras_shape\n     else:\n-        raise TypeError('Not a Keras tensor:', x)\n+        return None\n \n \n def ndim(x):\n@@ -1845,10 +1845,7 @@ def conv1d(x, kernel, strides=1, padding='valid',\n     if data_format not in {'channels_first', 'channels_last'}:\n         raise ValueError('Unknown data_format ', data_format)\n \n-    if hasattr(kernel, '_keras_shape'):\n-        kernel_shape = kernel._keras_shape\n-    else:\n-        kernel_shape = None\n+    kernel_shape = int_shape(kernel)\n     if padding == 'causal':\n         # causal (dilated) convolution:\n         if not kernel_shape:\n@@ -1856,10 +1853,7 @@ def conv1d(x, kernel, strides=1, padding='valid',\n         left_pad = dilation_rate * (kernel_shape[0] - 1)\n         x = temporal_padding(x, (left_pad, 0))\n         padding = 'valid'\n-    if hasattr(x, '_keras_shape'):\n-        shape = x._keras_shape\n-    else:\n-        shape = None\n+    shape = int_shape(x)\n     if data_format == 'channels_last':\n         # original shape: (batch, length, input_dim)\n         # add dim to x to have (batch, length, 1, input_dim)\n@@ -1908,15 +1902,10 @@ def conv2d(x, kernel, strides=(1, 1), padding='valid',\n     if data_format not in {'channels_first', 'channels_last'}:\n         raise ValueError('Unknown data_format ', data_format)\n \n-    if hasattr(x, '_keras_shape'):\n     image_shape = _preprocess_conv2d_image_shape(int_shape(x), data_format)\n-    else:\n-        image_shape = None\n-    if hasattr(kernel, '_keras_shape'):\n-        kernel_shape = kernel._keras_shape\n-    else:\n-        # Will only work if `kernel` is a shared variable.\n-        kernel_shape = kernel.eval().shape\n+    kernel_shape = int_shape(kernel)\n+    if kernel_shape is None:\n+        kernel_shape = kernel.eval().shape  # in case of a shared variable\n     kernel_shape = _preprocess_conv2d_filter_shape(kernel_shape, data_format)\n \n     x = _preprocess_conv2d_input(x, data_format)\n@@ -1962,11 +1951,9 @@ def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n                         output_shape[1],\n                         output_shape[2])\n \n-    if hasattr(kernel, '_keras_shape'):\n-        kernel_shape = kernel._keras_shape\n-    else:\n-        # Will only work if `kernel` is a shared variable.\n-        kernel_shape = kernel.eval().shape\n+    kernel_shape = int_shape(kernel)\n+    if kernel_shape is None:\n+        kernel_shape = kernel.eval().shape  # in case of a shared variable\n \n     if padding == 'same' and kernel_shape[0] % 2 == 0:\n         raise ValueError('In `Conv2DTranspose`, with padding mode `same`, '\n@@ -2020,21 +2007,14 @@ def separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1),\n     if data_format not in {'channels_first', 'channels_last'}:\n         raise ValueError('Unknown data_format ', data_format)\n \n-    if hasattr(x, '_keras_shape'):\n     image_shape = _preprocess_conv2d_image_shape(int_shape(x), data_format)\n-    else:\n-        image_shape = None\n-    if hasattr(depthwise_kernel, '_keras_shape'):\n-        depthwise_kernel_shape = depthwise_kernel._keras_shape\n-    else:\n-        # Will only work if `depthwise_kernel` is a shared variable.\n-        depthwise_kernel_shape = depthwise_kernel.eval().shape\n+    depthwise_kernel_shape = int_shape(depthwise_kernel)\n+    if depthwise_kernel_shape is None:\n+        depthwise_kernel_shape = depthwise_kernel.eval().shape  # in case of a shared variable\n     depthwise_kernel_shape = _preprocess_conv2d_filter_shape(depthwise_kernel_shape, data_format)\n-    if hasattr(pointwise_kernel, '_keras_shape'):\n-        pointwise_kernel_shape = pointwise_kernel._keras_shape\n-    else:\n-        # Will only work if `pointwise_kernel` is a shared variable.\n-        pointwise_kernel_shape = pointwise_kernel.eval().shape\n+    pointwise_kernel_shape = int_shape(pointwise_kernel)\n+    if pointwise_kernel_shape is None:\n+        pointwise_kernel_shape = pointwise_kernel.eval().shape  # in case of a shared variable\n     pointwise_kernel_shape = _preprocess_conv2d_filter_shape(pointwise_kernel_shape, data_format)\n \n     x = _preprocess_conv2d_input(x, data_format)\n@@ -2092,15 +2072,10 @@ def depthwise_conv2d(x, depthwise_kernel, strides=(1, 1), padding='valid',\n     if data_format not in {'channels_first', 'channels_last'}:\n         raise ValueError('Unknown data_format ', data_format)\n \n-    if hasattr(x, '_keras_shape'):\n     image_shape = _preprocess_conv2d_image_shape(int_shape(x), data_format)\n-    else:\n-        image_shape = None\n-    if hasattr(depthwise_kernel, '_keras_shape'):\n-        depthwise_kernel_shape = depthwise_kernel._keras_shape\n-    else:\n-        # Will only work if `kernel` is a shared variable.\n-        depthwise_kernel_shape = depthwise_kernel.eval().shape\n+    depthwise_kernel_shape = int_shape(depthwise_kernel)\n+    if depthwise_kernel_shape is None:\n+        depthwise_kernel_shape = depthwise_kernel.eval().shape  # in case of a shared variable\n     depthwise_kernel_shape = _preprocess_conv2d_filter_shape(depthwise_kernel_shape, data_format)\n \n     x = _preprocess_conv2d_input(x, data_format)\n@@ -2144,15 +2119,10 @@ def conv3d(x, kernel, strides=(1, 1, 1),\n     if data_format not in {'channels_first', 'channels_last'}:\n         raise ValueError('Unknown data_format:', data_format)\n \n-    if hasattr(x, '_keras_shape'):\n     volume_shape = _preprocess_conv3d_volume_shape(int_shape(x), data_format)\n-    else:\n-        volume_shape = None\n-    if hasattr(kernel, '_keras_shape'):\n-        kernel_shape = kernel._keras_shape\n-    else:\n-        # Will only work if `kernel` is a shared variable.\n-        kernel_shape = kernel.eval().shape\n+    kernel_shape = int_shape(kernel)\n+    if kernel_shape is None:\n+        kernel_shape = kernel.eval().shape  # in case of a shared variable\n     kernel_shape = _preprocess_conv3d_filter_shape(kernel_shape, data_format)\n \n     x = _preprocess_conv3d_input(x, data_format)\n@@ -2199,11 +2169,9 @@ def conv3d_transpose(x, kernel, output_shape, strides=(1, 1, 1),\n                         output_shape[2],\n                         output_shape[3])\n \n-    if hasattr(kernel, '_keras_shape'):\n-        kernel_shape = kernel._keras_shape\n-    else:\n-        # Will only work if `kernel` is a shared variable.\n-        kernel_shape = kernel.eval().shape\n+    kernel_shape = int_shape(kernel)\n+    if kernel_shape is None:\n+        kernel_shape = kernel.eval().shape  # in case of a shared variable\n \n     if padding == 'same' and kernel_shape[0] % 2 == 0:\n         raise ValueError('In `Conv3DTranspose`, with padding mode `same`, '\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#918c5991faa21cbb48de07566124c57cf16c0cf0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 5 | Methods Changed: 3 | Complexity Δ (Sum/Max): 6/2 | Churn Δ: 14 | Churn Cumulative: 18037 | Contributors (this commit): 139 | Commits (past 90d): 34 | Contributors (cumulative): 211 | DMM Complexity: 0.0\n\nDIFF:\n@@ -545,6 +545,10 @@ def batch_dot(x, y, axes=None):\n     if axes is None:\n         # behaves like tf.batch_matmul as default\n         axes = [len(x_shape) - 1, len(y_shape) - 2]\n+    if b_any([isinstance(a, (list, tuple)) for a in axes]):\n+        raise ValueError('Multiple target dimensions are not supported. ' +\n+                         'Expected: None, int, (int, int), ' +\n+                         'Provided: ' + str(axes))\n \n     if len(x_shape) == 2 and len(y_shape) == 2:\n         if axes[0] == axes[1]:\n\n@@ -25,6 +25,7 @@ from .common import set_image_dim_ordering\n from .common import image_dim_ordering\n \n py_all = all\n+py_any = any\n py_sum = sum\n \n # INTERNAL UTILS\n@@ -1135,6 +1136,10 @@ def batch_dot(x, y, axes=None):\n     if axes is None:\n         # behaves like tf.batch_matmul as default\n         axes = [x_ndim - 1, y_ndim - 2]\n+    if py_any([isinstance(a, (list, tuple)) for a in axes]):\n+        raise ValueError('Multiple target dimensions are not supported. ' +\n+                         'Expected: None, int, (int, int), ' +\n+                         'Provided: ' + str(axes))\n     if x_ndim > y_ndim:\n         diff = x_ndim - y_ndim\n         y = tf.reshape(y, tf.concat([tf.shape(y), [1] * (diff)], axis=0))\n\n@@ -26,6 +26,7 @@ from ..utils.generic_utils import has_arg\n from .common import set_image_dim_ordering, image_dim_ordering\n \n py_all = all\n+py_any = any\n py_sum = sum\n \n \n@@ -451,6 +452,10 @@ def batch_dot(x, y, axes=None):\n     if axes is None:\n         # behaves like tf.batch_matmul as default\n         axes = [x.ndim - 1, y.ndim - 2]\n+    if py_any([isinstance(a, (list, tuple)) for a in axes]):\n+        raise ValueError('Multiple target dimensions are not supported. ' +\n+                         'Expected: None, int, (int, int), ' +\n+                         'Provided: ' + str(axes))\n     if isinstance(axes, tuple):\n         axes = list(axes)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#24daab1c7b3ceebf04a19d3df3fdcdef11fe773b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 12 | Files Changed: 2 | Hunks: 6 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 17 | Churn Cumulative: 1984 | Contributors (this commit): 11 | Commits (past 90d): 6 | Contributors (cumulative): 15 | DMM Complexity: 1.0\n\nDIFF:\n@@ -9,9 +9,6 @@ the VGG16 and ResNet models (299x299 instead of 224x224),\n and that the input preprocessing function\n is also different (same as Inception V3).\n \n-Also do note that this model is only available for the TensorFlow backend,\n-due to its reliance on `SeparableConvolution` layers.\n-\n # Reference\n \n - [Xception: Deep Learning with Depthwise Separable Convolutions](https://arxiv.org/abs/1610.02357)\n@@ -37,6 +34,7 @@ from ..layers import GlobalAveragePooling2D\n from ..layers import GlobalMaxPooling2D\n from ..engine import get_source_inputs\n from ..utils.data_utils import get_file\n+from ..utils import layer_utils\n from .. import backend as K\n from . import imagenet_utils\n from .imagenet_utils import decode_predictions\n@@ -53,10 +51,8 @@ def Xception(include_top=True, weights='imagenet',\n              classes=1000):\n     \"\"\"Instantiates the Xception architecture.\n \n-    Optionally loads weights pre-trained\n-    on ImageNet. This model is available for TensorFlow only,\n-    and can only be used with inputs following the TensorFlow\n-    data format `(width, height, channels)`.\n+    Optionally loads weights pre-trained on ImageNet. This model can\n+    only be used with the data format `(width, height, channels)`.\n     You should set `image_data_format='channels_last'` in your Keras config\n     located at ~/.keras/keras.json.\n \n@@ -110,9 +106,6 @@ def Xception(include_top=True, weights='imagenet',\n         raise ValueError('If using `weights` as imagenet with `include_top`'\n                          ' as true, `classes` should be 1000')\n \n-    if K.backend() != 'tensorflow':\n-        raise RuntimeError('The Xception model is only available with '\n-                           'the TensorFlow backend.')\n     if K.image_data_format() != 'channels_last':\n         warnings.warn('The Xception model is only available for the '\n                       'input data format \"channels_last\" '\n@@ -261,6 +254,8 @@ def Xception(include_top=True, weights='imagenet',\n                                     cache_subdir='models',\n                                     file_hash='b0042744bf5b25fce3cb969f33bebb97')\n         model.load_weights(weights_path)\n+        if K.backend() == 'theano':\n+            layer_utils.convert_all_kernels_in_model(model)\n     elif weights is not None:\n         model.load_weights(weights)\n \n\n@@ -108,8 +108,6 @@ def test_vgg():\n     _test_app_pooling(app, last_dim)\n \n \n-@pytest.mark.skipif((K.backend() != 'tensorflow'),\n-                    reason='Requires TensorFlow backend')\n def test_xception():\n     app = applications.Xception\n     last_dim = 2048\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a1d544f4a156373b1c9e72d3af0bf87e4d81d90c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 97 | Lines Deleted: 9 | Files Changed: 2 | Hunks: 11 | Methods Changed: 4 | Complexity Δ (Sum/Max): 15/10 | Churn Δ: 106 | Churn Cumulative: 3869 | Contributors (this commit): 55 | Commits (past 90d): 23 | Contributors (cumulative): 66 | DMM Complexity: 0.0\n\nDIFF:\n@@ -672,9 +672,14 @@ class ImageDataGenerator(object):\n             augmented/normalized data.\n \n         # Arguments\n-               x: data. Should have rank 4.\n-                In case of grayscale data,\n-                the channels axis should have value 1, and in case\n+               x: data. Numpy array of rank 4 or a tuple. If tuple, the first element\n+                should contain the images and the second element another numpy array\n+                or a list of numpy arrays of miscellaneous data that gets passed to the output\n+                without any modifications. Can be used to feed the model miscellaneous data\n+                along with the images.\n+\n+                In case of grayscale data, the channels axis of the image array\n+                should have value 1, and in case\n                 of RGB data, it should have value 3.\n                y: labels.\n                batch_size: int (default: 32).\n@@ -691,8 +696,9 @@ class ImageDataGenerator(object):\n                 `validation_split` is set in `ImageDataGenerator`.\n \n         # Returns\n-            An Iterator yielding tuples of `(x, y)` where `x` is a numpy array of image data and\n-             `y` is a numpy array of corresponding labels.\"\"\"\n+            An Iterator yielding tuples of `(x, y)` where `x` is a numpy array of image data\n+             (in the case of a single image input) or a list of numpy arrays (in the case with\n+             additional inputs) and `y` is a numpy array of corresponding labels.\"\"\"\n         return NumpyArrayIterator(\n             x, y, self,\n             batch_size=batch_size,\n@@ -1084,7 +1090,9 @@ class NumpyArrayIterator(Iterator):\n     \"\"\"Iterator yielding data from a Numpy array.\n \n     # Arguments\n-        x: Numpy array of input data.\n+        x: Numpy array of input data or tuple. If tuple, the second elements is either\n+            another numpy array or a list of numpy arrays, each of which gets passed\n+            through as an output without any modifications.\n         y: Numpy array of targets data.\n         image_data_generator: Instance of `ImageDataGenerator`\n             to use for random transformations and normalization.\n@@ -1109,6 +1117,20 @@ class NumpyArrayIterator(Iterator):\n                  data_format=None,\n                  save_to_dir=None, save_prefix='', save_format='png',\n                  subset=None):\n+        if (type(x) is tuple) or (type(x) is list):\n+            if type(x[1]) is not list:\n+                x_misc = [np.asarray(x[1])]\n+            else:\n+                x_misc = [np.asarray(xx) for xx in x[1]]\n+            x = x[0]\n+            for xx in x_misc:\n+                if len(x) != len(xx):\n+                    raise ValueError('All of the arrays in `x` should have the same length. '\n+                                     'Found a pair with: len(x[0]) = %s, len(x[?]) = %s' %\n+                                     (len(x), len(xx)))\n+        else:\n+            x_misc = []\n+\n         if y is not None and len(x) != len(y):\n             raise ValueError('`x` (images tensor) and `y` (labels) '\n                              'should have the same length. '\n@@ -1121,15 +1143,18 @@ class NumpyArrayIterator(Iterator):\n             split_idx = int(len(x) * image_data_generator._validation_split)\n             if subset == 'validation':\n                 x = x[:split_idx]\n+                x_misc = [np.asarray(xx[:split_idx]) for xx in x_misc]\n                 if y is not None:\n                     y = y[:split_idx]\n             else:\n                 x = x[split_idx:]\n+                x_misc = [np.asarray(xx[split_idx:]) for xx in x_misc]\n                 if y is not None:\n                     y = y[split_idx:]\n         if data_format is None:\n             data_format = K.image_data_format()\n         self.x = np.asarray(x, dtype=K.floatx())\n+        self.x_misc = x_misc\n         if self.x.ndim != 4:\n             raise ValueError('Input data in `NumpyArrayIterator` '\n                              'should have rank 4. You passed an array '\n@@ -1161,6 +1186,7 @@ class NumpyArrayIterator(Iterator):\n             x = self.image_data_generator.random_transform(x.astype(K.floatx()))\n             x = self.image_data_generator.standardize(x)\n             batch_x[i] = x\n+\n         if self.save_to_dir:\n             for i, j in enumerate(index_array):\n                 img = array_to_img(batch_x[i], self.data_format, scale=True)\n@@ -1169,10 +1195,12 @@ class NumpyArrayIterator(Iterator):\n                                                                   hash=np.random.randint(1e4),\n                                                                   format=self.save_format)\n                 img.save(os.path.join(self.save_to_dir, fname))\n+        batch_x_miscs = [xx[index_array] for xx in self.x_misc]\n+        output = (batch_x if batch_x_miscs == [] else [batch_x] + batch_x_miscs,)\n         if self.y is None:\n-            return batch_x\n-        batch_y = self.y[index_array]\n-        return batch_x, batch_y\n+            return output[0]\n+        output += (self.y[index_array],)\n+        return output\n \n     def next(self):\n         \"\"\"For python 2.x.\n\n@@ -71,6 +71,66 @@ class TestImage(object):\n                 assert list(y) != [0, 1, 2]\n                 break\n \n+            # Test without y\n+            for x in generator.flow(images, None,\n+                                    shuffle=True, save_to_dir=str(tmpdir),\n+                                    batch_size=3):\n+                assert type(x) is np.ndarray\n+                assert x.shape == images[:3].shape\n+                # Check that the sequence is shuffled.\n+                break\n+\n+            # Test with a single miscellaneous input data array\n+            dsize = images.shape[0]\n+            x_misc1 = np.random.random(dsize)\n+\n+            for i, (x, y) in enumerate(generator.flow((images, x_misc1),\n+                                                      np.arange(dsize),\n+                                                      shuffle=False, batch_size=2)):\n+                assert x[0].shape == images[:2].shape\n+                assert (x[1] == x_misc1[(i * 2):((i + 1) * 2)]).all()\n+                if i == 2:\n+                    break\n+\n+            # Test with two miscellaneous inputs\n+            x_misc2 = np.random.random((dsize, 3, 3))\n+\n+            for i, (x, y) in enumerate(generator.flow((images, [x_misc1, x_misc2]),\n+                                                      np.arange(dsize),\n+                                                      shuffle=False, batch_size=2)):\n+                assert x[0].shape == images[:2].shape\n+                assert (x[1] == x_misc1[(i * 2):((i + 1) * 2)]).all()\n+                assert (x[2] == x_misc2[(i * 2):((i + 1) * 2)]).all()\n+                if i == 2:\n+                    break\n+\n+            # Test cases with `y = None`\n+            x = generator.flow(images, None, batch_size=3).next()\n+            assert type(x) is np.ndarray\n+            assert x.shape == images[:3].shape\n+            x = generator.flow((images, x_misc1), None,\n+                               batch_size=3, shuffle=False).next()\n+            assert type(x) is list\n+            assert x[0].shape == images[:3].shape\n+            assert (x[1] == x_misc1[:3]).all()\n+            x = generator.flow((images, [x_misc1, x_misc2]), None,\n+                               batch_size=3, shuffle=False).next()\n+            assert type(x) is list\n+            assert x[0].shape == images[:3].shape\n+            assert (x[1] == x_misc1[:3]).all()\n+            assert (x[2] == x_misc2[:3]).all()\n+\n+            # Test some failure cases:\n+            x_misc_err = np.random.random((dsize + 1, 3, 3))\n+\n+            with pytest.raises(ValueError) as e_info:\n+                generator.flow((images, x_misc_err), np.arange(dsize), batch_size=3)\n+            assert str(e_info.value).find('All of the arrays in') != -1\n+\n+            with pytest.raises(ValueError) as e_info:\n+                generator.flow((images, x_misc1), np.arange(dsize + 1), batch_size=3)\n+            assert str(e_info.value).find('`x` (images tensor) and `y` (labels) ') != -1\n+\n             # Test `flow` behavior as Sequence\n             seq = generator.flow(images, np.arange(images.shape[0]),\n                                  shuffle=False, save_to_dir=str(tmpdir),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5959d34aca8d6605b3e4b3f9c905b030cae600e3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 22 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 22 | Churn Cumulative: 320 | Contributors (this commit): 16 | Commits (past 90d): 6 | Contributors (cumulative): 16 | DMM Complexity: None\n\nDIFF:\n@@ -1,10 +1,32 @@\n from setuptools import setup\n from setuptools import find_packages\n \n+long_description = '''\n+Keras is a high-level neural networks API,\n+written in Python and capable of running on top of\n+TensorFlow, CNTK, or Theano.\n+\n+Use Keras if you need a deep learning library that:\n+\n+- Allows for easy and fast prototyping\n+  (through user friendliness, modularity, and extensibility).\n+- Supports both convolutional networks and recurrent networks,\n+  as well as combinations of the two.\n+- Runs seamlessly on CPU and GPU.\n+\n+Read the documentation at: https://keras.io/\n+\n+For a detailed overview of what makes Keras special, see:\n+https://keras.io/why-use-keras/\n+\n+Keras is compatible with Python 2.7-3.6\n+and is distributed under the MIT liense.\n+'''\n \n setup(name='Keras',\n       version='2.1.6',\n       description='Deep Learning for humans',\n+      long_description=long_description,\n       author='Francois Chollet',\n       author_email='francois.chollet@gmail.com',\n       url='https://github.com/keras-team/keras',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ece9a009deb0202f4344881607426d651d89da38", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 9409 | Contributors (this commit): 110 | Commits (past 90d): 12 | Contributors (cumulative): 110 | DMM Complexity: None\n\nDIFF:\n@@ -9,7 +9,6 @@ from tensorflow.python.ops import tensor_array_ops\n from tensorflow.python.ops import control_flow_ops\n from tensorflow.python.ops import functional_ops\n from tensorflow.python.ops import ctc_ops as ctc\n-from tensorflow.python.ops import variables as tf_variables\n from tensorflow.python.client import device_lib\n \n from collections import defaultdict\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a637960fab61b66848a36e6a5caf0204c155af01", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 124 | Lines Deleted: 2037 | Files Changed: 8 | Hunks: 56 | Methods Changed: 73 | Complexity Δ (Sum/Max): -218/0 | Churn Δ: 2161 | Churn Cumulative: 11548 | Contributors (this commit): 36 | Commits (past 90d): 18 | Contributors (cumulative): 50 | DMM Complexity: 0.4263636363636364\n\nDIFF:\n@@ -14,7 +14,6 @@ from six.moves import zip\n from .. import backend as K\n from .. import optimizers\n from ..utils.io_utils import ask_to_proceed_with_overwrite\n-from ..legacy import models as legacy_models\n from ..utils import conv_utils\n \n try:\n@@ -119,9 +118,6 @@ def save_model(model, filepath, overwrite=True, include_optimizer=True):\n         }, default=get_json_type).encode('utf8')\n \n         model_weights_group = f.create_group('model_weights')\n-        if legacy_models.needs_legacy_support(model):\n-            model_layers = legacy_models.legacy_sequential_layers(model)\n-        else:\n         model_layers = model.layers\n         save_weights_to_hdf5_group(model_weights_group, model_layers)\n \n\n@@ -6,21 +6,14 @@ from __future__ import print_function\n \n import warnings\n import copy\n-import os\n \n-from . import base_layer\n from . import network\n-from . import saving\n from .training import Model\n from .base_layer import Layer\n from .input_layer import Input\n from .input_layer import InputLayer\n from .. import backend as K\n from .. import layers as layer_module\n-from ..utils.io_utils import ask_to_proceed_with_overwrite\n-from ..legacy import layers as legacy_layers\n-from ..legacy import models as legacy_models\n-from ..legacy import interfaces\n \n try:\n     import h5py\n@@ -34,63 +27,90 @@ class Sequential(Model):\n     # Arguments\n         layers: list of layers to add to the model.\n \n-    # Note\n-        The first layer passed to a Sequential model\n-        should have a defined input shape. What that\n-        means is that it should have received an `input_shape`\n-        or `batch_input_shape` argument,\n-        or for some type of layers (recurrent, Dense...)\n-        an `input_dim` argument.\n-\n     # Example\n \n     ```python\n+    # Optionally, the first layer can receive an `input_shape` argument:\n     model = Sequential()\n-            # first layer must have a defined input shape\n-            model.add(Dense(32, input_dim=500))\n-            # afterwards, Keras does automatic shape inference\n+    model.add(Dense(32, input_shape=(500,)))\n+\n+    # Afterwards, we do automatic shape inference:\n     model.add(Dense(32))\n \n-            # also possible (equivalent to the above):\n+    # This is identical to the following:\n+    model = Sequential()\n+    model.add(Dense(32, input_dim=500))\n+\n+    # And to the following:\n+    model = Sequential()\n+    model.add(Dense(32, batch_input_shape=(None, 500)))\n+\n+    # Note that you can also omit the `input_shape` argument:\n+    # In that case the model gets built the first time you call `fit` (or other\n+    # training and evaluation methods).\n+    model = Sequential()\n+    model.add(Dense(32))\n+    model.add(Dense(32))\n+    model.compile(optimizer=optimizer, loss=loss)\n+\n+    # This builds the model for the first time:\n+    model.fit(x, y, batch_size=32, epochs=10)\n+\n+    # Note that when using this delayed-build pattern\n+    # (no input shape specified),\n+    # the model doesn't have any weights until the first call\n+    # to a training/evaluation method (since it isn't yet built):\n+    model = Sequential()\n+    model.add(Dense(32))\n+    model.add(Dense(32))\n+    model.weights  # returns []\n+\n+    # Whereas if you specify the input shape, the model gets built continuously\n+    # as you are adding layers:\n     model = Sequential()\n     model.add(Dense(32, input_shape=(500,)))\n     model.add(Dense(32))\n+    model.weights  # returns list of length 4\n \n-            # also possible (equivalent to the above):\n+    # When using the delayed-build pattern (no input shape specified), you can\n+    # choose to manually build your model by calling\n+    # `build(batch_input_shape)`:\n     model = Sequential()\n-            # here the batch dimension is None,\n-            # which means any batch size will be accepted by the model.\n-            model.add(Dense(32, batch_input_shape=(None, 500)))\n     model.add(Dense(32))\n+    model.add(Dense(32))\n+    model.build((None, 500))\n+    model.weights  # returns list of length 4\n     ```\n     \"\"\"\n \n     def __init__(self, layers=None, name=None):\n-        self._layers = []  # Stack of layers.\n-        self.model = None  # Internal Model instance.\n-        self.inputs = []  # List of input tensors\n-        self.outputs = []  # List of length 1: the output tensor (unique).\n-        self._trainable = True\n-        self._initial_weights = None\n-        self._is_graph_network = True\n-\n-        # Model attributes.\n-        self._inbound_nodes = []\n-        self._outbound_nodes = []\n-        self.built = False\n-        self.optimizer = None\n-\n-        # Set model name.\n-        if not name:\n-            prefix = 'sequential_'\n-            name = prefix + str(K.get_uid(prefix))\n-        self.name = name\n+        super(Sequential, self).__init__(name=name)\n \n         # Add to the model any layers passed to the constructor.\n         if layers:\n             for layer in layers:\n                 self.add(layer)\n \n+    @property\n+    def layers(self):\n+        # Historically, `sequential.layers` only returns layers that were added\n+        # via `add`, and omits the auto-generated `InputLayer`\n+        # that comes at the bottom of the stack.\n+        if self._layers and isinstance(self._layers[0], InputLayer):\n+            return self._layers[1:]\n+        return self._layers\n+\n+    @property\n+    def model(self):\n+        # Historically, `Sequential` was once\n+        # implemented as a wrapper for `Model` which maintained\n+        # its underlying `Model` as the `model` property.\n+        # We keep it for compatibility reasons.\n+        warnings.warn('`Sequential.model` is deprecated. '\n+                      '`Sequential` is a subclass of `Model`, you can '\n+                      'just use your `Sequential` instance directly.')\n+        return self\n+\n     def add(self, layer):\n         \"\"\"Adds a layer instance on top of the layer stack.\n \n@@ -109,11 +129,14 @@ class Sequential(Model):\n             raise TypeError('The added layer must be '\n                             'an instance of class Layer. '\n                             'Found: ' + str(layer))\n-        if not self.outputs:\n+        self.built = False\n+        if not self._layers:\n+            set_inputs = False\n             # First layer in model: check that it is an input layer.\n-            if not isinstance(layer, (InputLayer, legacy_layers.Merge)):\n-                # Create an input layer.\n-                # First, we need to infer its expected input shape and dtype.\n+            if not isinstance(layer, InputLayer):\n+                # Create an input tensor and call `layer` on the input tensor.\n+                # First, we need to infer the expected input shape and dtype.\n+                first_layer = layer\n                 if isinstance(layer, (Model, Sequential)):\n                     # We were passed a model as first layer.\n                     # This requires a specific way to figure out the\n@@ -128,48 +151,39 @@ class Sequential(Model):\n                         first_layer = first_layer.layers[0]\n                     batch_shape = first_layer.batch_input_shape\n                     dtype = first_layer.dtype\n-                else:\n-                    # We were passed a regular layer, and it should\n-                    # know about its input shape. Otherwise, that's an error.\n-                    if not hasattr(layer, 'batch_input_shape'):\n-                        raise ValueError('The first layer in a '\n-                                         'Sequential model must '\n-                                         'get an `input_shape` or '\n-                                         '`batch_input_shape` argument.')\n-                    batch_shape = layer.batch_input_shape\n-                    dtype = layer.dtype\n+\n+                if hasattr(first_layer, 'batch_input_shape'):\n+                    batch_shape = first_layer.batch_input_shape\n+                    dtype = first_layer.dtype\n                     # Instantiate the input layer.\n-                x = Input(batch_shape=batch_shape,\n+                    x = Input(\n+                        batch_shape=batch_shape,\n                         dtype=dtype,\n                         name=layer.name + '_input')\n                     # This will build the current layer\n                     # and create the node connecting the current layer\n                     # to the input layer we just created.\n                     layer(x)\n+                    set_inputs = True\n+                else:\n+                    # The layer doesn't know about its expected shape.\n+                    # We will have to\n+                    # build the model lazily on `fit`/etc.\n+                    batch_shape = None\n+            else:\n+                # Corner case where the user passes an InputLayer via `add`.\n+                assert len(layer._inbound_nodes[-1].output_tensors) == 1\n+                set_inputs = True\n \n+            if set_inputs:\n                 if len(layer._inbound_nodes[-1].output_tensors) != 1:\n                     raise ValueError('All layers in a Sequential model '\n                                      'should have a single output tensor. '\n                                      'For multi-output layers, '\n                                      'use the functional API.')\n-\n                 self.outputs = [layer._inbound_nodes[-1].output_tensors[0]]\n                 self.inputs = network.get_source_inputs(self.outputs[0])\n-\n-            # We create an input node, which we will keep updated\n-            # as we add more layers\n-            base_layer.Node(outbound_layer=self,\n-                            inbound_layers=[],\n-                            node_indices=[],\n-                            tensor_indices=[],\n-                            input_tensors=self.inputs,\n-                            output_tensors=self.outputs,\n-                            # no model-level masking for now\n-                            input_masks=[None for _ in self.inputs],\n-                            output_masks=[None],\n-                            input_shapes=[x._keras_shape for x in self.inputs],\n-                            output_shapes=[self.outputs[0]._keras_shape])\n-        else:\n+        elif self.outputs:\n             output_tensor = layer(self.outputs[0])\n             if isinstance(output_tensor, list):\n                 raise TypeError('All layers in a Sequential model '\n@@ -177,13 +191,10 @@ class Sequential(Model):\n                                 'For multi-output layers, '\n                                 'use the functional API.')\n             self.outputs = [output_tensor]\n-            # update self._inbound_nodes\n-            self._inbound_nodes[0].output_tensors = self.outputs\n-            self._inbound_nodes[0].output_shapes = [\n-                self.outputs[0]._keras_shape]\n-\n-        self.layers.append(layer)\n-        self.built = False\n+        if self.inputs:\n+            self.build()\n+        else:\n+            self._layers.append(layer)\n \n     def pop(self):\n         \"\"\"Removes the last layer in the model.\n@@ -194,594 +205,35 @@ class Sequential(Model):\n         if not self.layers:\n             raise TypeError('There are no layers in the model.')\n \n-        self.layers.pop()\n+        self._layers.pop()\n+        self.built = False\n         if not self.layers:\n-            self.outputs = []\n-            self._inbound_nodes = []\n-            self._outbound_nodes = []\n-        else:\n+            self.outputs = None\n+            self.inputs = None\n+        elif self.outputs:\n             self.layers[-1]._outbound_nodes = []\n             self.outputs = [self.layers[-1].output]\n-            # update self._inbound_nodes\n-            self._inbound_nodes[0].output_tensors = self.outputs\n-            self._inbound_nodes[0].output_shapes = [\n-                self.outputs[0]._keras_shape]\n-        self.built = False\n-\n-    def get_layer(self, name=None, index=None):\n-        \"\"\"Retrieve a layer that is part of the model.\n-\n-        Returns a layer based on either its name (unique)\n-        or its index in the graph. Indices are based on\n-        order of horizontal graph traversal (bottom-up).\n-\n-        # Arguments\n-            name: string, name of layer.\n-            index: integer, index of layer.\n-\n-        # Returns\n-            A layer instance.\n-        \"\"\"\n-        if not self.built:\n             self.build()\n-        return self.model.get_layer(name, index)\n-\n-    def call(self, inputs, mask=None):\n-        if not self.built:\n-            self.build()\n-        return self.model.call(inputs, mask)\n \n     def build(self, input_shape=None):\n-        if not self.inputs or not self.outputs:\n-            raise TypeError('Sequential model cannot be built: model is empty.'\n-                            ' Add some layers first.')\n-        # actually create the model\n-        self.model = Model(self.inputs, self.outputs[0],\n-                           name=self.name + '_model')\n-        self.model.trainable = self.trainable\n+        if input_shape and not self.inputs:\n+            batch_shape = tuple(input_shape)\n+            dtype = K.floatx()\n+            x = Input(batch_shape=batch_shape,\n+                      dtype=dtype,\n+                      name=self.name + '_input')\n+            self.inputs = [x]\n+            for layer in self._layers:\n+                x = layer(x)\n+            self.outputs = [x]\n \n-        # mirror model attributes\n-        self.supports_masking = self.model.supports_masking\n-        self._output_mask_cache = self.model._output_mask_cache\n-        self._output_tensor_cache = self.model._output_tensor_cache\n-        self._output_shape_cache = self.model._output_shape_cache\n-        self._input_layers = self.model._input_layers\n-        self._input_coordinates = self.model._input_coordinates\n-        self._output_layers = self.model._output_layers\n-        self._output_coordinates = self.model._output_coordinates\n-        self._nodes_by_depth = self.model._nodes_by_depth\n-        self.output_names = self.model.output_names\n-        self.input_names = self.model.input_names\n-        self._feed_input_names = self.model._feed_input_names\n-        self._feed_inputs = self.model._feed_inputs\n-        self._network_nodes = self.model._network_nodes\n-\n-        # Make sure child model callbacks\n-        # will call the parent Sequential model.\n-        self.model.callback_model = self\n+        if self.inputs:\n+            self._init_graph_network(self.inputs,\n+                                     self.outputs,\n+                                     name=self.name)\n             self.built = True\n \n-    @property\n-    def uses_learning_phase(self):\n-        if not self.built:\n-            self.build()\n-        return self.model.uses_learning_phase\n-\n-    @property\n-    def _flattened_layers(self):\n-        layers = []\n-        if self.layers:\n-            # Support for legacy models\n-            if isinstance(self.layers[0], legacy_layers.Merge):\n-                merge = self.layers[0]\n-                for layer in merge.layers:\n-                    if hasattr(layer, '_flattened_layers'):\n-                        for sublayer in layer._flattened_layers:\n-                            if sublayer not in layers:\n-                                layers.append(sublayer)\n-                    elif hasattr(layer, 'layers'):\n-                        for sublayer in layer.layers:\n-                            if sublayer not in layers:\n-                                layers.append(sublayer)\n-                    else:\n-                        if layer not in layers:\n-                            layers.append(layer)\n-            else:\n-                if self.layers[0] not in layers:\n-                    layers.append(self.layers[0])\n-            for layer in self.layers[1:]:\n-                if layer not in layers:\n-                    layers.append(layer)\n-        return layers\n-\n-    def _gather_list_attr(self, attr):\n-        all_attrs = []\n-        for layer in self._flattened_layers:\n-            all_attrs += getattr(layer, attr, [])\n-        return all_attrs\n-\n-    @property\n-    def trainable(self):\n-        return self._trainable\n-\n-    @trainable.setter\n-    def trainable(self, value):\n-        if self.built:\n-            self.model.trainable = value\n-        self._trainable = value\n-\n-    @property\n-    def trainable_weights(self):\n-        if not self.trainable:\n-            return []\n-        # Support for legacy behavior\n-        return self._gather_list_attr('trainable_weights')\n-\n-    @property\n-    def non_trainable_weights(self):\n-        # Support for legacy behavior\n-        weights = self._gather_list_attr('non_trainable_weights')\n-        if not self.trainable:\n-            trainable_weights = self._gather_list_attr('trainable_weights')\n-            return trainable_weights + weights\n-        return weights\n-\n-    @property\n-    def updates(self):\n-        if not self.built:\n-            self.build()\n-        return self.model.updates\n-\n-    @property\n-    def state_updates(self):\n-        if not self.built:\n-            self.build()\n-        return self.model.state_updates\n-\n-    def get_updates_for(self, inputs):\n-        if not self.built:\n-            self.build()\n-        return self.model.get_updates_for(inputs)\n-\n-    @property\n-    def losses(self):\n-        if not self.built:\n-            self.build()\n-        return self.model.losses\n-\n-    def get_losses_for(self, inputs):\n-        if not self.built:\n-            self.build()\n-        return self.model.get_losses_for(inputs)\n-\n-    @property\n-    def regularizers(self):\n-        if not self.built:\n-            self.build()\n-        return self.model.regularizers\n-\n-    def get_weights(self):\n-        \"\"\"Retrieves the weights of the model.\n-\n-        # Returns\n-            A flat list of Numpy arrays\n-            (one array per model weight).\n-        \"\"\"\n-        # Legacy support\n-        if legacy_models.needs_legacy_support(self):\n-            layers = legacy_models.legacy_sequential_layers(self)\n-            weights = []\n-            for layer in layers:\n-                weights.append(layer.get_weights())\n-            return weights\n-\n-        if not self.built:\n-            self.build()\n-        return self.model.get_weights()\n-\n-    def set_weights(self, weights):\n-        \"\"\"Sets the weights of the model.\n-\n-        # Arguments\n-            weights: Should be a list\n-                of Numpy arrays with shapes and types matching\n-                the output of `model.get_weights()`.\n-        \"\"\"\n-        # Legacy support\n-        if legacy_models.needs_legacy_support(self):\n-            layers = legacy_models.legacy_sequential_layers(self)\n-            for layer in layers:\n-                nb_param = len(layer.weights)\n-                layer.set_weights(weights[:nb_param])\n-                weights = weights[nb_param:]\n-\n-        if not self.built:\n-            self.build()\n-        self.model.set_weights(weights)\n-\n-    def load_weights(self, filepath, by_name=False, skip_mismatch=False, reshape=False):\n-        if h5py is None:\n-            raise ImportError('`load_weights` requires h5py.')\n-        with h5py.File(filepath, mode='r') as f:\n-            if 'layer_names' not in f.attrs and 'model_weights' in f:\n-                f = f['model_weights']\n-\n-            # Legacy support\n-            if legacy_models.needs_legacy_support(self):\n-                layers = legacy_models.legacy_sequential_layers(self)\n-            else:\n-                layers = self.layers\n-            if by_name:\n-                saving.load_weights_from_hdf5_group_by_name(f, layers,\n-                                                            skip_mismatch=skip_mismatch,\n-                                                            reshape=reshape)\n-            else:\n-                saving.load_weights_from_hdf5_group(f, layers, reshape=reshape)\n-\n-    def save_weights(self, filepath, overwrite=True):\n-        \"\"\"Saves the weights of a model.\n-\n-        Note: Please also see\n-        [How can I install HDF5 or h5py to save my models in Keras?](\n-        /getting-started/faq/\n-        #how-can-i-install-HDF5-or-h5py-to-save-my-models-in-Keras)\n-        in the FAQ for instructions on how to install `h5py`.\n-        \"\"\"\n-\n-        if h5py is None:\n-            raise ImportError('`save_weights` requires h5py.')\n-        # If file exists and should not be overwritten:\n-        if not overwrite and os.path.isfile(filepath):\n-            proceed = ask_to_proceed_with_overwrite(filepath)\n-            if not proceed:\n-                return\n-        # Legacy support\n-        if legacy_models.needs_legacy_support(self):\n-            layers = legacy_models.legacy_sequential_layers(self)\n-        else:\n-            layers = self.layers\n-\n-        with h5py.File(filepath, 'w') as f:\n-            saving.save_weights_to_hdf5_group(f, layers)\n-            f.flush()\n-\n-    def compile(self, optimizer, loss,\n-                metrics=None,\n-                sample_weight_mode=None,\n-                weighted_metrics=None,\n-                target_tensors=None,\n-                **kwargs):\n-        \"\"\"Configures the model for training.\n-\n-        # Arguments\n-            optimizer: String (name of optimizer) or optimizer object.\n-                See [optimizers](/optimizers).\n-            loss: String (name of objective function) or objective function.\n-                See [losses](/losses).\n-                If the model has multiple outputs, you can use a different loss\n-                on each output by passing a dictionary or a list of losses.\n-                The loss value that will be minimized by the model\n-                will then be the sum of all individual losses.\n-            metrics: List of metrics to be evaluated by the model\n-                during training and testing.\n-                Typically you will use `metrics=['accuracy']`.\n-                To specify different metrics for different outputs of a\n-                multi-output model, you could also pass a dictionary,\n-                such as `metrics={'output_a': 'accuracy'}`.\n-            sample_weight_mode: If you need to do timestep-wise\n-                sample weighting (2D weights), set this to `\"temporal\"`.\n-                `None` defaults to sample-wise weights (1D).\n-                If the model has multiple outputs, you can use a different\n-                `sample_weight_mode` on each output by passing a\n-                dictionary or a list of modes.\n-            weighted_metrics: List of metrics to be evaluated and weighted\n-                by sample_weight or class_weight during training and testing.\n-            target_tensors: By default, Keras will create a placeholder for the\n-                model's target, which will be fed with the target data during\n-                training. If instead you would like to use your own\n-                target tensor (in turn, Keras will not expect external\n-                Numpy data for these targets at training time), you\n-                can specify them via the `target_tensors` argument.\n-                It should be a single tensor\n-                (for a single-output `Sequential` model).\n-            **kwargs: When using the Theano/CNTK backends, these arguments\n-                are passed into `K.function`.\n-                When using the TensorFlow backend,\n-                these arguments are passed into `tf.Session.run`.\n-\n-        # Raises\n-            ValueError: In case of invalid arguments for\n-                `optimizer`, `loss`, `metrics` or `sample_weight_mode`.\n-\n-        # Example\n-            ```python\n-                model = Sequential()\n-                model.add(Dense(32, input_shape=(500,)))\n-                model.add(Dense(10, activation='softmax'))\n-                model.compile(optimizer='rmsprop',\n-                              loss='categorical_crossentropy',\n-                              metrics=['accuracy'])\n-            ```\n-        \"\"\"\n-        # create the underlying model\n-        self.build()\n-        # call compile method of Model class\n-        self.model.compile(optimizer, loss,\n-                           metrics=metrics,\n-                           sample_weight_mode=sample_weight_mode,\n-                           weighted_metrics=weighted_metrics,\n-                           target_tensors=target_tensors,\n-                           **kwargs)\n-        self.optimizer = self.model.optimizer\n-        self.loss = self.model.loss\n-        self.metrics = self.model.metrics\n-        self.loss_weights = self.model.loss_weights\n-        self.sample_weight_mode = self.model.sample_weight_mode\n-        self.weighted_metrics = self.model.weighted_metrics\n-        self.targets = self.model.targets\n-        self.metrics_tensors = self.model.metrics_tensors\n-        self.metrics_names = self.model.metrics_names\n-        self.sample_weights = self.model.sample_weights\n-        self.total_loss = self.model.total_loss\n-\n-    def fit(self,\n-            x=None,\n-            y=None,\n-            batch_size=None,\n-            epochs=1,\n-            verbose=1,\n-            callbacks=None,\n-            validation_split=0.,\n-            validation_data=None,\n-            shuffle=True,\n-            class_weight=None,\n-            sample_weight=None,\n-            initial_epoch=0,\n-            steps_per_epoch=None,\n-            validation_steps=None,\n-            **kwargs):\n-        \"\"\"Trains the model for a fixed number of epochs (iterations on a dataset).\n-\n-        # Arguments\n-            x: Numpy array of training data.\n-                If the input layer in the model is named, you can also pass a\n-                dictionary mapping the input name to a Numpy array.\n-                `x` can be `None` (default) if feeding from\n-                framework-native tensors (e.g. TensorFlow data tensors).\n-            y: Numpy array of target (label) data.\n-                If the output layer in the model is named, you can also pass a\n-                dictionary mapping the output name to a Numpy array.\n-                `y` can be `None` (default) if feeding from\n-                framework-native tensors (e.g. TensorFlow data tensors).\n-            batch_size: Integer or `None`.\n-                Number of samples per gradient update.\n-                If unspecified, it will default to 32.\n-            epochs: Integer. Number of epochs to train the model.\n-                An epoch is an iteration over the entire `x` and `y`\n-                data provided.\n-                Note that in conjunction with `initial_epoch`,\n-                `epochs` is to be understood as \"final epoch\".\n-                The model is not trained for a number of iterations\n-                given by `epochs`, but merely until the epoch\n-                of index `epochs` is reached.\n-            verbose: 0, 1, or 2. Verbosity mode.\n-                0 = silent, 1 = progress bar, 2 = one line per epoch.\n-            callbacks: List of `keras.callbacks.Callback` instances.\n-                List of callbacks to apply during training.\n-                See [callbacks](/callbacks).\n-            validation_split: Float between 0 and 1.\n-                Fraction of the training data to be used as validation data.\n-                The model will set apart this fraction of the training data,\n-                will not train on it, and will evaluate\n-                the loss and any model metrics\n-                on this data at the end of each epoch.\n-                The validation data is selected from the last samples\n-                in the `x` and `y` data provided, before shuffling.\n-            validation_data: tuple `(x_val, y_val)` or tuple\n-                `(x_val, y_val, val_sample_weights)` on which to evaluate\n-                the loss and any model metrics at the end of each epoch.\n-                The model will not be trained on this data.\n-                This will override `validation_split`.\n-            shuffle: Boolean (whether to shuffle the training data\n-                before each epoch) or str (for 'batch').\n-                'batch' is a special option for dealing with the\n-                limitations of HDF5 data; it shuffles in batch-sized chunks.\n-                Has no effect when `steps_per_epoch` is not `None`.\n-            class_weight: Optional dictionary mapping class indices (integers)\n-                to a weight (float) value, used for weighting the loss function\n-                (during training only).\n-                This can be useful to tell the model to\n-                \"pay more attention\" to samples from\n-                an under-represented class.\n-            sample_weight: Optional Numpy array of weights for\n-                the training samples, used for weighting the loss function\n-                (during training only). You can either pass a flat (1D)\n-                Numpy array with the same length as the input samples\n-                (1:1 mapping between weights and samples),\n-                or in the case of temporal data,\n-                you can pass a 2D array with shape\n-                `(samples, sequence_length)`,\n-                to apply a different weight to every timestep of every sample.\n-                In this case you should make sure to specify\n-                `sample_weight_mode=\"temporal\"` in `compile()`.\n-            initial_epoch: Epoch at which to start training\n-                (useful for resuming a previous training run).\n-            steps_per_epoch: Total number of steps (batches of samples)\n-                before declaring one epoch finished and starting the\n-                next epoch. When training with input tensors such as\n-                TensorFlow data tensors, the default `None` is equal to\n-                the number of samples in your dataset divided by\n-                the batch size, or 1 if that cannot be determined.\n-            validation_steps: Only relevant if `steps_per_epoch`\n-                is specified. Total number of steps (batches of samples)\n-                to validate before stopping.\n-\n-        # Returns\n-            A `History` object. Its `History.history` attribute is\n-            a record of training loss values and metrics values\n-            at successive epochs, as well as validation loss values\n-            and validation metrics values (if applicable).\n-\n-        # Raises\n-            RuntimeError: If the model was never compiled.\n-            ValueError: In case of mismatch between the provided input data\n-                and what the model expects.\n-        \"\"\"\n-        # Legacy support\n-        if 'nb_epoch' in kwargs:\n-            warnings.warn('The `nb_epoch` argument in `fit` '\n-                          'has been renamed `epochs`.')\n-            epochs = kwargs.pop('nb_epoch')\n-        if kwargs:\n-            raise TypeError('Unrecognized keyword arguments: ' + str(kwargs))\n-\n-        if not self.built:\n-            raise RuntimeError('The model needs to be compiled '\n-                               'before being used.')\n-        return self.model.fit(x, y,\n-                              batch_size=batch_size,\n-                              epochs=epochs,\n-                              verbose=verbose,\n-                              callbacks=callbacks,\n-                              validation_split=validation_split,\n-                              validation_data=validation_data,\n-                              shuffle=shuffle,\n-                              class_weight=class_weight,\n-                              sample_weight=sample_weight,\n-                              initial_epoch=initial_epoch,\n-                              steps_per_epoch=steps_per_epoch,\n-                              validation_steps=validation_steps)\n-\n-    def evaluate(self, x=None, y=None,\n-                 batch_size=None,\n-                 verbose=1,\n-                 sample_weight=None,\n-                 steps=None):\n-        \"\"\"Computes the loss on some input data, batch by batch.\n-\n-        # Arguments\n-            x: input data, as a Numpy array or list of Numpy arrays\n-                (if the model has multiple inputs).\n-                `x` can be `None` (default) if feeding from\n-                framework-native tensors (e.g. TensorFlow data tensors).\n-            y: labels, as a Numpy array.\n-                `y` can be `None` (default) if feeding from\n-                framework-native tensors (e.g. TensorFlow data tensors).\n-            batch_size: Integer. If unspecified, it will default to 32.\n-            verbose: verbosity mode, 0 or 1.\n-            sample_weight: sample weights, as a Numpy array.\n-            steps: Integer or `None`.\n-                Total number of steps (batches of samples)\n-                before declaring the evaluation round finished.\n-                Ignored with the default value of `None`.\n-\n-        # Returns\n-            Scalar test loss (if the model has no metrics)\n-            or list of scalars (if the model computes other metrics).\n-            The attribute `model.metrics_names` will give you\n-            the display labels for the scalar outputs.\n-\n-        # Raises\n-            RuntimeError: if the model was never compiled.\n-        \"\"\"\n-        if not self.built:\n-            raise RuntimeError('The model needs to be compiled '\n-                               'before being used.')\n-        return self.model.evaluate(x, y,\n-                                   batch_size=batch_size,\n-                                   verbose=verbose,\n-                                   sample_weight=sample_weight,\n-                                   steps=steps)\n-\n-    def predict(self, x, batch_size=None, verbose=0, steps=None):\n-        \"\"\"Generates output predictions for the input samples.\n-\n-        The input samples are processed batch by batch.\n-\n-        # Arguments\n-            x: the input data, as a Numpy array.\n-            batch_size: Integer. If unspecified, it will default to 32.\n-            verbose: verbosity mode, 0 or 1.\n-            steps: Total number of steps (batches of samples)\n-                before declaring the prediction round finished.\n-                Ignored with the default value of `None`.\n-\n-        # Returns\n-            A Numpy array of predictions.\n-        \"\"\"\n-        if not self.built:\n-            self.build()\n-        return self.model.predict(x, batch_size=batch_size, verbose=verbose,\n-                                  steps=steps)\n-\n-    def predict_on_batch(self, x):\n-        \"\"\"Returns predictions for a single batch of samples.\n-\n-        # Arguments\n-            x: input data, as a Numpy array or list of Numpy arrays\n-                (if the model has multiple inputs).\n-\n-        # Returns\n-            A Numpy array of predictions.\n-        \"\"\"\n-        if not self.built:\n-            self.build()\n-        return self.model.predict_on_batch(x)\n-\n-    def train_on_batch(self, x, y, class_weight=None,\n-                       sample_weight=None):\n-        \"\"\"Single gradient update over one batch of samples.\n-\n-        # Arguments\n-            x: input data, as a Numpy array or list of Numpy arrays\n-                (if the model has multiple inputs).\n-            y: labels, as a Numpy array.\n-            class_weight: dictionary mapping classes to a weight value,\n-                used for scaling the loss function (during training only).\n-            sample_weight: sample weights, as a Numpy array.\n-\n-        # Returns\n-            Scalar training loss (if the model has no metrics)\n-            or list of scalars (if the model computes other metrics).\n-            The attribute `model.metrics_names` will give you\n-            the display labels for the scalar outputs.\n-\n-        # Raises\n-            RuntimeError: if the model was never compiled.\n-        \"\"\"\n-        if not self.built:\n-            raise RuntimeError('The model needs to be compiled '\n-                               'before being used.')\n-        return self.model.train_on_batch(x, y,\n-                                         sample_weight=sample_weight,\n-                                         class_weight=class_weight)\n-\n-    def test_on_batch(self, x, y,\n-                      sample_weight=None):\n-        \"\"\"Evaluates the model over a single batch of samples.\n-\n-        # Arguments\n-            x: input data, as a Numpy array or list of Numpy arrays\n-                (if the model has multiple inputs).\n-            y: labels, as a Numpy array.\n-            sample_weight: sample weights, as a Numpy array.\n-\n-        # Returns\n-            Scalar test loss (if the model has no metrics)\n-            or list of scalars (if the model computes other metrics).\n-            The attribute `model.metrics_names` will give you\n-            the display labels for the scalar outputs.\n-\n-        # Raises\n-            RuntimeError: if the model was never compiled.\n-        \"\"\"\n-        if not self.built:\n-            raise RuntimeError('The model needs to be compiled '\n-                               'before being used.')\n-        return self.model.test_on_batch(x, y,\n-                                        sample_weight=sample_weight)\n-\n-    def predict_proba(self, x, batch_size=None, verbose=0, steps=None):\n+    def predict_proba(self, x, batch_size=32, verbose=0):\n         \"\"\"Generates class probability predictions for the input samples.\n \n         The input samples are processed batch by batch.\n@@ -789,17 +241,13 @@ class Sequential(Model):\n         # Arguments\n             x: input data, as a Numpy array or list of Numpy arrays\n                 (if the model has multiple inputs).\n-            batch_size: Integer. If unspecified, it will default to 32.\n+            batch_size: integer.\n             verbose: verbosity mode, 0 or 1.\n-            steps: Total number of steps (batches of samples)\n-                before declaring the prediction round finished.\n-                Ignored with the default value of `None`.\n-\n \n         # Returns\n             A Numpy array of probability predictions.\n         \"\"\"\n-        preds = self.predict(x, batch_size, verbose, steps=steps)\n+        preds = self.predict(x, batch_size, verbose)\n         if preds.min() < 0. or preds.max() > 1.:\n             warnings.warn('Network returning invalid probability values. '\n                           'The last layer might not normalize predictions '\n@@ -807,7 +255,7 @@ class Sequential(Model):\n                           '(like softmax or sigmoid would).')\n         return preds\n \n-    def predict_classes(self, x, batch_size=None, verbose=0, steps=None):\n+    def predict_classes(self, x, batch_size=32, verbose=0):\n         \"\"\"Generate class predictions for the input samples.\n \n         The input samples are processed batch by batch.\n@@ -815,330 +263,32 @@ class Sequential(Model):\n         # Arguments\n             x: input data, as a Numpy array or list of Numpy arrays\n                 (if the model has multiple inputs).\n-            batch_size: Integer. If unspecified, it will default to 32.\n+            batch_size: integer.\n             verbose: verbosity mode, 0 or 1.\n-            steps: Total number of steps (batches of samples)\n-                before declaring the prediction round finished.\n-                Ignored with the default value of `None`.\n \n-        # Returns\n+        # Returns:\n             A numpy array of class predictions.\n         \"\"\"\n-        proba = self.predict(x, batch_size=batch_size, verbose=verbose,\n-                             steps=steps)\n+        proba = self.predict(x, batch_size=batch_size, verbose=verbose)\n         if proba.shape[-1] > 1:\n             return proba.argmax(axis=-1)\n         else:\n             return (proba > 0.5).astype('int32')\n \n-    @interfaces.legacy_generator_methods_support\n-    def fit_generator(self,\n-                      generator,\n-                      steps_per_epoch=None,\n-                      epochs=1,\n-                      verbose=1,\n-                      callbacks=None,\n-                      validation_data=None,\n-                      validation_steps=None,\n-                      class_weight=None,\n-                      max_queue_size=10,\n-                      workers=1,\n-                      use_multiprocessing=False,\n-                      shuffle=True,\n-                      initial_epoch=0):\n-        \"\"\"Fits the model on data generated batch-by-batch by a Python generator.\n-\n-        The generator is run in parallel to the model, for efficiency.\n-        For instance, this allows you to do real-time data augmentation\n-        on images on CPU in parallel to training your model on GPU.\n-\n-        The use of `keras.utils.Sequence` guarantees the ordering\n-        and guarantees the single use of every input per epoch when\n-        using `use_multiprocessing=True`.\n-\n-        # Arguments\n-            generator: A generator or an instance of `Sequence`\n-                (`keras.utils.Sequence`) object in order to avoid duplicate data\n-                    when using multiprocessing.\n-                The output of the generator must be either\n-                - a tuple `(inputs, targets)`\n-                - a tuple `(inputs, targets, sample_weights)`.\n-                This tuple (a single output of the generator) makes a single\n-                batch. Therefore, all arrays in this tuple must have the same\n-                length (equal to the size of this batch). Different batches may\n-                have different sizes. For example, the last batch of the epoch\n-                is commonly smaller than the others, if the size of the dataset\n-                is not divisible by the batch size.\n-                The generator is expected to loop over its data\n-                indefinitely. An epoch finishes when `steps_per_epoch`\n-                batches have been seen by the model.\n-            steps_per_epoch: Total number of steps (batches of samples)\n-                to yield from `generator` before declaring one epoch\n-                finished and starting the next epoch. It should typically\n-                be equal to the number of samples of your dataset\n-                divided by the batch size.\n-                Optional for `Sequence`: if unspecified, will use\n-                the `len(generator)` as a number of steps.\n-            epochs: Integer, total number of iterations on the data.\n-                Note that in conjunction with initial_epoch, the parameter\n-                epochs is to be understood as \"final epoch\". The model is\n-                not trained for n steps given by epochs, but until the\n-                epoch epochs is reached.\n-            verbose: Integer. 0, 1, or 2. Verbosity mode.\n-                0 = silent, 1 = progress bar, 2 = one line per epoch.\n-            callbacks: List of `keras.callbacks.Callback` instances.\n-                List of callbacks to apply during training.\n-                See [callbacks](/callbacks).\n-            validation_data: This can be either\n-                - a generator for the validation data\n-                - a tuple `(inputs, targets)`\n-                - a tuple `(inputs, targets, sample_weights)`.\n-            validation_steps: Only relevant if `validation_data`\n-                is a generator. Total number of steps (batches of samples)\n-                to yield from `validation_data` generator before stopping\n-                at the end of every epoch. It should typically\n-                be equal to the number of samples of your\n-                validation dataset divided by the batch size.\n-                Optional for `Sequence`: if unspecified, will use\n-                the `len(validation_data)` as a number of steps.\n-            class_weight: Optional dictionary mapping class indices (integers)\n-                to a weight (float) value, used for weighting the loss function\n-                (during training only). This can be useful to tell the model to\n-                \"pay more attention\" to samples from an under-represented class.\n-            max_queue_size: Integer. Maximum size for the generator queue.\n-                If unspecified, `max_queue_size` will default to 10.\n-            workers: Integer. Maximum number of processes to spin up\n-                when using process-based threading.\n-                If unspecified, `workers` will default to 1. If 0, will\n-                execute the generator on the main thread.\n-            use_multiprocessing: Boolean.\n-                If `True`, use process-based threading.\n-                If unspecified, `use_multiprocessing` will default to `False`.\n-                Note that because this implementation relies on multiprocessing,\n-                you should not pass non-picklable arguments to the generator\n-                as they can't be passed easily to children processes.\n-            shuffle: Boolean (whether to shuffle the order of the batches at\n-                the beginning of each epoch. Only used with instances\n-                of `Sequence` (`keras.utils.Sequence`).\n-                Has no effect when `steps_per_epoch` is not `None`.\n-            initial_epoch: Integer.\n-                Epoch at which to start training\n-                (useful for resuming a previous training run).\n-\n-        # Returns\n-            A `History` object.\n-\n-        # Raises\n-            RuntimeError: if the model was never compiled.\n-            ValueError: In case the generator yields data in an invalid format.\n-\n-        # Example\n-\n-        ```python\n-            def generate_arrays_from_file(path):\n-                while True:\n-                    with open(path) as f:\n-                        for line in f:\n-                            # create Numpy arrays of input data\n-                            # and labels, from each line in the file\n-                            x, y = process_line(line)\n-                            yield (x, y)\n-\n-            model.fit_generator(generate_arrays_from_file('/my_file.txt'),\n-                                steps_per_epoch=1000, epochs=10)\n-        ```\n-        \"\"\"\n-        if not self.built:\n-            raise RuntimeError('The model needs to be compiled '\n-                               'before being used.')\n-        return self.model.fit_generator(generator,\n-                                        steps_per_epoch,\n-                                        epochs,\n-                                        verbose=verbose,\n-                                        callbacks=callbacks,\n-                                        validation_data=validation_data,\n-                                        validation_steps=validation_steps,\n-                                        class_weight=class_weight,\n-                                        max_queue_size=max_queue_size,\n-                                        workers=workers,\n-                                        use_multiprocessing=use_multiprocessing,\n-                                        shuffle=shuffle,\n-                                        initial_epoch=initial_epoch)\n-\n-    @interfaces.legacy_generator_methods_support\n-    def evaluate_generator(self, generator, steps=None,\n-                           max_queue_size=10, workers=1,\n-                           use_multiprocessing=False):\n-        \"\"\"Evaluates the model on a data generator.\n-\n-        The generator should return the same kind of data\n-        as accepted by `test_on_batch`.\n-\n-        # Arguments\n-            generator: Generator yielding tuples (inputs, targets)\n-                or (inputs, targets, sample_weights)\n-            steps: Total number of steps (batches of samples)\n-                to yield from `generator` before stopping.\n-                Optional for `Sequence`: if unspecified, will use\n-                the `len(generator)` as a number of steps.\n-            max_queue_size: maximum size for the generator queue\n-            workers: maximum number of processes to spin up\n-            use_multiprocessing: if True, use process based threading.\n-                Note that because this implementation\n-                relies on multiprocessing, you should not pass\n-                non picklable arguments to the generator\n-                as they can't be passed easily to children processes.\n-\n-        # Returns\n-            Scalar test loss (if the model has no metrics)\n-            or list of scalars (if the model computes other metrics).\n-            The attribute `model.metrics_names` will give you\n-            the display labels for the scalar outputs.\n-\n-        # Raises\n-            RuntimeError: if the model was never compiled.\n-        \"\"\"\n-        if not self.built:\n-            raise RuntimeError('The model needs to be compiled '\n-                               'before being used.')\n-        return self.model.evaluate_generator(generator,\n-                                             steps,\n-                                             max_queue_size=max_queue_size,\n-                                             workers=workers,\n-                                             use_multiprocessing=use_multiprocessing)\n-\n-    @interfaces.legacy_generator_methods_support\n-    def predict_generator(self, generator, steps=None,\n-                          max_queue_size=10, workers=1,\n-                          use_multiprocessing=False, verbose=0):\n-        \"\"\"Generates predictions for the input samples from a data generator.\n-\n-        The generator should return the same kind of data as accepted by\n-        `predict_on_batch`.\n-\n-        # Arguments\n-            generator: generator yielding batches of input samples.\n-            steps: Total number of steps (batches of samples)\n-                to yield from `generator` before stopping.\n-                Optional for `Sequence`: if unspecified, will use\n-                the `len(generator)` as a number of steps.\n-            max_queue_size: maximum size for the generator queue\n-            workers: maximum number of processes to spin up\n-            use_multiprocessing: if True, use process based threading.\n-                Note that because this implementation\n-                relies on multiprocessing, you should not pass\n-                non picklable arguments to the generator\n-                as they can't be passed easily to children processes.\n-            verbose: verbosity mode, 0 or 1.\n-\n-        # Returns\n-            A Numpy array of predictions.\n-        \"\"\"\n-        if not self.built:\n-            self.build()\n-        return self.model.predict_generator(generator, steps,\n-                                            max_queue_size=max_queue_size,\n-                                            workers=workers,\n-                                            use_multiprocessing=use_multiprocessing,\n-                                            verbose=verbose)\n-\n     def get_config(self):\n-        if isinstance(self.layers[0], legacy_layers.Merge):\n-            return self.legacy_get_config()\n-\n         config = []\n         for layer in self.layers:\n-            config.append({'class_name': layer.__class__.__name__,\n-                           'config': layer.get_config()})\n+            config.append({\n+                'class_name': layer.__class__.__name__,\n+                'config': layer.get_config()\n+            })\n         return copy.deepcopy(config)\n \n     @classmethod\n     def from_config(cls, config, custom_objects=None):\n-        if 'class_name' not in config[0] or config[0]['class_name'] == 'Merge':\n-            return cls.legacy_from_config(config)\n-\n         model = cls()\n         for conf in config:\n-            layer = layer_module.deserialize(conf, custom_objects=custom_objects)\n-            model.add(layer)\n-        return model\n-\n-    def legacy_get_config(self):\n-        \"\"\"Retrieves the model configuration as a Python list.\n-\n-        # Returns\n-            A list of dicts (each dict is a layer config).\n-        \"\"\"\n-        config = []\n-        if isinstance(self.layers[0], legacy_layers.Merge):\n-            assert hasattr(self.layers[0], 'layers')\n-            layers = []\n-            for layer in self.layers[0].layers:\n-                layer_config = {'class_name': layer.__class__.__name__,\n-                                'config': layer.get_config()}\n-                layers.append(layer_config)\n-            merge_config = self.layers[0].get_config()\n-            merge_config['layers'] = layers\n-            config.append({'class_name': 'Merge', 'config': merge_config})\n-        else:\n-            config.append({'class_name': self.layers[0].__class__.__name__,\n-                           'config': self.layers[0].get_config()})\n-        for layer in self.layers[1:]:\n-            config.append({'class_name': layer.__class__.__name__,\n-                           'config': layer.get_config()})\n-        return copy.deepcopy(config)\n-\n-    @classmethod\n-    def legacy_from_config(cls, config, layer_cache=None):\n-        \"\"\"Load a model from a legacy configuration.\n-\n-        # Arguments\n-            config: dictionary with configuration.\n-            layer_cache: cache to draw pre-existing layer.\n-\n-        # Returns\n-            The loaded Model.\n-        \"\"\"\n-        if not layer_cache:\n-            layer_cache = {}\n-\n-        def normalize_legacy_config(conf):\n-            if 'class_name' not in conf:\n-                class_name = conf['name']\n-                name = conf.get('custom_name')\n-                conf['name'] = name\n-                return {'class_name': class_name,\n-                        'config': conf}\n-            return conf\n-\n-        # the model we will return\n-        model = cls()\n-\n-        def get_or_create_layer(layer_data):\n-            name = layer_data['config'].get('name')\n-            if name in layer_cache:\n-                return layer_cache[name]\n-            layer = layer_module.deserialize(layer_data)\n-            layer_cache[name] = layer\n-            return layer\n-\n-        first_layer = config[0]\n-        first_layer = normalize_legacy_config(first_layer)\n-        if first_layer['class_name'] == 'Merge':\n-            merge_inputs = []\n-            first_layer_config = first_layer['config']\n-            for merge_input_config in first_layer_config.pop('layers'):\n-                merge_input = layer_module.deserialize(merge_input_config)\n-                merge_inputs.append(merge_input)\n-            first_layer_config['layers'] = merge_inputs\n-            merge = legacy_layers.Merge.from_config(first_layer_config)\n-            model.add(merge)\n-        else:\n-            layer = get_or_create_layer(first_layer)\n-            model.add(layer)\n-\n-        for conf in config[1:]:\n-            conf = normalize_legacy_config(conf)\n-            layer = get_or_create_layer(conf)\n+            layer = layer_module.deserialize(conf,\n+                                             custom_objects=custom_objects)\n             model.add(layer)\n         return model\n\n@@ -3,12 +3,10 @@ from __future__ import division\n from __future__ import print_function\n \n import numpy as np\n-import types as python_types\n import warnings\n \n from ..engine import Layer, InputSpec\n from .. import backend as K\n-from ..utils.generic_utils import func_dump, func_load, has_arg\n from ..utils import conv_utils\n from .. import regularizers\n from .. import constraints\n@@ -16,465 +14,6 @@ from .. import activations\n from .. import initializers\n \n \n-class Merge(Layer):\n-    \"\"\"A `Merge` layer can be used to merge a list of tensors\n-    into a single tensor, following some merge `mode`.\n-    # Example\n-    ```python\n-    model1 = Sequential()\n-    model1.add(Dense(32, input_dim=32))\n-    model2 = Sequential()\n-    model2.add(Dense(32, input_dim=32))\n-    merged_model = Sequential()\n-    merged_model.add(Merge([model1, model2], mode='concat', concat_axis=1))\n-    ```\n-    # Arguments\n-        layers: Can be a list of Keras tensors or\n-            a list of layer instances. Must be more\n-            than one layer/tensor.\n-        mode: String or lambda/function. If string, must be one\n-            of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'.\n-            If lambda/function, it should take as input a list of tensors\n-            and return a single tensor.\n-        concat_axis: Integer, axis to use in mode `concat`.\n-        dot_axes: Integer or tuple of integers,\n-            axes to use in mode `dot` or `cos`.\n-        output_shape: Either a shape tuple (tuple of integers),\n-            or a lambda/function\n-            to compute `output_shape`\n-            (only if merge mode is a lambda/function).\n-            If the argument is a tuple,\n-            it should be expected output shape, *not* including the batch size\n-            (same convention as the `input_shape` argument in layers).\n-            If the argument is callable,\n-            it should take as input a list of shape tuples\n-            (1:1 mapping to input tensors)\n-            and return a single shape tuple, including the\n-            batch size (same convention as the\n-            `compute_output_shape` method of layers).\n-        node_indices: Optional list of integers containing\n-            the output node index for each input layer\n-            (in case some input layers have multiple output nodes).\n-            will default to an array of 0s if not provided.\n-        tensor_indices: Optional list of indices of output tensors\n-            to consider for merging\n-            (in case some input layer node returns multiple tensors).\n-        output_mask: Mask or lambda/function to compute the output mask (only\n-            if merge mode is a lambda/function). If the latter case, it should\n-            take as input a list of masks and return a single mask.\n-    \"\"\"\n-\n-    def __init__(self, layers=None, mode='sum', concat_axis=-1,\n-                 dot_axes=-1, output_shape=None, output_mask=None,\n-                 arguments=None, node_indices=None, tensor_indices=None,\n-                 name=None):\n-        warnings.warn('The `Merge` layer is deprecated '\n-                      'and will be removed after 08/2017. '\n-                      'Use instead layers from `keras.layers.merge`, '\n-                      'e.g. `add`, `concatenate`, etc.', stacklevel=2)\n-        self.layers = layers\n-        self.mode = mode\n-        self.concat_axis = concat_axis\n-        self.dot_axes = dot_axes\n-        self._output_shape = output_shape\n-        self.node_indices = node_indices\n-        self._output_mask = output_mask\n-        self.arguments = arguments if arguments else {}\n-        self._initial_weights = None\n-        self._updates = []\n-        self._losses = []\n-        self._per_input_updates = {}\n-        self._per_input_losses = {}\n-\n-        # Layer parameters.\n-        self._inbound_nodes = []\n-        self._outbound_nodes = []\n-        self.constraints = {}\n-        self._trainable_weights = []\n-        self._non_trainable_weights = []\n-        self.supports_masking = True\n-        self.uses_learning_phase = False\n-        self.input_spec = None  # Compatible with anything.\n-        self.stateful = False\n-        self.trainable = True\n-        if not name:\n-            prefix = self.__class__.__name__.lower()\n-            name = prefix + '_' + str(K.get_uid(prefix))\n-        self.name = name\n-\n-        if layers:\n-            # This exists for backwards compatibility.\n-            # equivalent to:\n-            # merge = Merge(layers=None)\n-            # output = merge([input_tensor_1, input_tensor_2])\n-            if not node_indices:\n-                # By default we connect to\n-                # the 1st output stream in the input layer.\n-                node_indices = [0 for _ in range(len(layers))]\n-            if not tensor_indices:\n-                tensor_indices = [0 for _ in range(len(layers))]\n-            self._arguments_validation(layers, mode,\n-                                       concat_axis, dot_axes,\n-                                       node_indices, tensor_indices)\n-            self.built = True\n-            input_tensors = []\n-            input_masks = []\n-            for i, layer in enumerate(layers):\n-                node_index = node_indices[i]\n-                tensor_index = tensor_indices[i]\n-                inbound_node = layer._inbound_nodes[node_index]\n-                input_tensors.append(inbound_node.output_tensors[tensor_index])\n-                input_masks.append(inbound_node.output_masks[tensor_index])\n-            self(input_tensors, mask=input_masks)\n-        else:\n-            self.built = False\n-\n-    def _arguments_validation(self, layers, mode, concat_axis, dot_axes,\n-                              node_indices, tensor_indices):\n-        \"\"\"Validates user-passed arguments and raises exceptions\n-        as appropriate.\n-        \"\"\"\n-        if not callable(mode):\n-            if mode not in {'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'}:\n-                raise ValueError('Invalid merge mode: ' + str(mode))\n-        if not isinstance(layers, (list, tuple)) or len(layers) < 2:\n-            raise TypeError('A Merge should only be applied to a list of '\n-                            'layers with at least 2 elements. Found: ' +\n-                            str(layers))\n-\n-        if tensor_indices is None:\n-            tensor_indices = [None for _ in range(len(layers))]\n-\n-        input_shapes = []\n-        for i, layer in enumerate(layers):\n-            layer_output_shape = layer.get_output_shape_at(node_indices[i])\n-            if isinstance(layer_output_shape, list):\n-                # Case: the layer has multiple output tensors\n-                # and we only need a specific one.\n-                layer_output_shape = layer_output_shape[tensor_indices[i]]\n-            input_shapes.append(layer_output_shape)\n-\n-        if mode in {'sum', 'mul', 'ave', 'cos', 'max'}:\n-            input_shapes_set = set(input_shapes)\n-            if len(input_shapes_set) > 1:\n-                raise ValueError('Only layers of same output shape can '\n-                                 'be merged using ' + mode + ' mode. ' +\n-                                 'Layer shapes: %s' % input_shapes)\n-        if mode in {'cos', 'dot'}:\n-            if len(layers) > 2:\n-                raise ValueError(mode + ' merge takes exactly 2 layers')\n-            shape1 = input_shapes[0]\n-            shape2 = input_shapes[1]\n-            n1 = len(shape1)\n-            n2 = len(shape2)\n-            if isinstance(dot_axes, int):\n-                if dot_axes < 0:\n-                    self.dot_axes = [dot_axes % n1, dot_axes % n2]\n-                else:\n-                    self.dot_axes = [dot_axes, ] * 2\n-            if not isinstance(self.dot_axes, (list, tuple)):\n-                raise TypeError('Invalid type for dot_axes - '\n-                                'should be a list.')\n-            if len(self.dot_axes) != 2:\n-                raise ValueError('Invalid format for dot_axes - '\n-                                 'should contain two elements.')\n-            if not isinstance(self.dot_axes[0], int) or not isinstance(self.dot_axes[1], int):\n-                raise ValueError('Invalid format for dot_axes - '\n-                                 'list elements should be \"int\".')\n-            if shape1[self.dot_axes[0]] != shape2[self.dot_axes[1]]:\n-                raise ValueError('Dimension incompatibility using dot mode: '\n-                                 '%s != %s. ' % (shape1[self.dot_axes[0]], shape2[self.dot_axes[1]]) +\n-                                 'Layer shapes: %s, %s' % (shape1, shape2))\n-        elif mode == 'concat':\n-            reduced_inputs_shapes = [list(shape) for shape in input_shapes]\n-            shape_set = set()\n-            for i in range(len(reduced_inputs_shapes)):\n-                del reduced_inputs_shapes[i][self.concat_axis]\n-                shape_set.add(tuple(reduced_inputs_shapes[i]))\n-            if len(shape_set) > 1:\n-                raise ValueError('\"concat\" mode can only merge '\n-                                 'layers with matching '\n-                                 'output shapes except for the concat axis. '\n-                                 'Layer shapes: %s' % (input_shapes))\n-\n-    def call(self, inputs, mask=None):\n-        if not isinstance(inputs, list) or len(inputs) <= 1:\n-            raise TypeError('Merge must be called on a list of tensors '\n-                            '(at least 2). Got: ' + str(inputs))\n-        # Case: \"mode\" is a lambda or function.\n-        if callable(self.mode):\n-            arguments = self.arguments\n-            if has_arg(self.mode, 'mask'):\n-                arguments['mask'] = mask\n-            return self.mode(inputs, **arguments)\n-\n-        if self.mode == 'sum' or self.mode == 'ave':\n-            s = inputs[0]\n-            for i in range(1, len(inputs)):\n-                s += inputs[i]\n-            if self.mode == 'ave':\n-                s /= len(inputs)\n-            return s\n-\n-        elif self.mode == 'concat':\n-            return K.concatenate(inputs, axis=self.concat_axis)\n-\n-        elif self.mode == 'mul':\n-            s = inputs[0]\n-            for i in range(1, len(inputs)):\n-                s *= inputs[i]\n-            return s\n-        elif self.mode == 'max':\n-            s = inputs[0]\n-            for i in range(1, len(inputs)):\n-                s = K.maximum(s, inputs[i])\n-            return s\n-        elif self.mode == 'dot':\n-            l1 = inputs[0]\n-            l2 = inputs[1]\n-            output = K.batch_dot(l1, l2, self.dot_axes)\n-            return output\n-\n-        elif self.mode == 'cos':\n-            l1 = inputs[0]\n-            l2 = inputs[1]\n-            denominator = K.sqrt(K.batch_dot(l1, l1, self.dot_axes) *\n-                                 K.batch_dot(l2, l2, self.dot_axes))\n-            denominator = K.maximum(denominator, K.epsilon())\n-            output = K.batch_dot(l1, l2, self.dot_axes) / denominator\n-            output = K.expand_dims(output, 1)\n-            return output\n-        else:\n-            raise ValueError('Unknown merge mode.')\n-\n-    def compute_output_shape(self, input_shape):\n-        # Must have multiple input shape tuples.\n-        assert isinstance(input_shape, list)\n-        # Case: callable self._output_shape.\n-        if callable(self.mode):\n-            if callable(self._output_shape):\n-                output_shape = self._output_shape(input_shape)\n-                return output_shape\n-            elif self._output_shape is not None:\n-                return (input_shape[0][0],) + tuple(self._output_shape)\n-            else:\n-                raise ValueError('The Merge layer ' + self.name +\n-                                 ' has a callable `mode` argument, '\n-                                 'and we cannot infer its output shape '\n-                                 'because no `output_shape` '\n-                                 'argument was provided. '\n-                                 'Make sure to pass a shape tuple '\n-                                 '(or callable) '\n-                                 '`output_shape` to Merge.')\n-        # Pre-defined merge modes.\n-        input_shapes = input_shape\n-        if self.mode in ['sum', 'mul', 'ave', 'max']:\n-            # All tuples in input_shapes should be the same.\n-            return input_shapes[0]\n-        elif self.mode == 'concat':\n-            output_shape = list(input_shapes[0])\n-            for shape in input_shapes[1:]:\n-                if output_shape[self.concat_axis] is None or shape[self.concat_axis] is None:\n-                    output_shape[self.concat_axis] = None\n-                    break\n-                output_shape[self.concat_axis] += shape[self.concat_axis]\n-            return tuple(output_shape)\n-        elif self.mode in ['dot', 'cos']:\n-            shape1 = list(input_shapes[0])\n-            shape2 = list(input_shapes[1])\n-            shape1.pop(self.dot_axes[0])\n-            shape2.pop(self.dot_axes[1])\n-            shape2.pop(0)\n-            output_shape = shape1 + shape2\n-            if len(output_shape) == 1:\n-                output_shape += [1]\n-            return tuple(output_shape)\n-\n-    def compute_mask(self, inputs, mask=None):\n-        if mask is None or all([m is None for m in mask]):\n-            return None\n-\n-        assert hasattr(mask, '__len__') and len(mask) == len(inputs)\n-\n-        if self.mode in ['sum', 'mul', 'ave', 'max']:\n-            masks = [K.expand_dims(m, 0) for m in mask if m is not None]\n-            return K.all(K.concatenate(masks, axis=0), axis=0, keepdims=False)\n-        elif self.mode == 'concat':\n-            # Make a list of masks while making sure\n-            # the dimensionality of each mask\n-            # is the same as the corresponding input.\n-            masks = []\n-            for input_i, mask_i in zip(inputs, mask):\n-                if mask_i is None:\n-                    # Input is unmasked. Append all 1s to masks,\n-                    masks.append(K.ones_like(input_i, dtype='bool'))\n-                elif K.ndim(mask_i) < K.ndim(input_i):\n-                    # Mask is smaller than the input, expand it\n-                    masks.append(K.expand_dims(mask_i))\n-                else:\n-                    masks.append(mask_i)\n-            concatenated = K.concatenate(masks, axis=self.concat_axis)\n-            return K.all(concatenated, axis=-1, keepdims=False)\n-        elif self.mode in ['cos', 'dot']:\n-            return None\n-        elif callable(self.mode):\n-            if callable(self._output_mask):\n-                return self._output_mask(mask)\n-            else:\n-                return self._output_mask\n-        else:\n-            # This should have been caught earlier.\n-            raise ValueError('Invalid merge mode: {}'.format(self.mode))\n-\n-    def get_config(self):\n-        if isinstance(self.mode, python_types.LambdaType):\n-            mode = func_dump(self.mode)\n-            mode_type = 'lambda'\n-        elif callable(self.mode):\n-            mode = self.mode.__name__\n-            mode_type = 'function'\n-        else:\n-            mode = self.mode\n-            mode_type = 'raw'\n-\n-        if isinstance(self._output_shape, python_types.LambdaType):\n-            output_shape = func_dump(self._output_shape)\n-            output_shape_type = 'lambda'\n-        elif callable(self._output_shape):\n-            output_shape = self._output_shape.__name__\n-            output_shape_type = 'function'\n-        else:\n-            output_shape = self._output_shape\n-            output_shape_type = 'raw'\n-\n-        if isinstance(self._output_mask, python_types.LambdaType):\n-            output_mask = func_dump(self._output_mask)\n-            output_mask_type = 'lambda'\n-        elif callable(self._output_mask):\n-            output_mask = self._output_mask.__name__\n-            output_mask_type = 'function'\n-        else:\n-            output_mask = self._output_mask\n-            output_mask_type = 'raw'\n-\n-        return {'name': self.name,\n-                'mode': mode,\n-                'mode_type': mode_type,\n-                'concat_axis': self.concat_axis,\n-                'dot_axes': self.dot_axes,\n-                'output_shape': output_shape,\n-                'output_shape_type': output_shape_type,\n-                'output_mask': output_mask,\n-                'output_mask_type': output_mask_type,\n-                'arguments': self.arguments}\n-\n-    @classmethod\n-    def from_config(cls, config):\n-        config = config.copy()\n-        mode_type = config.pop('mode_type')\n-        if mode_type == 'function':\n-            mode = globals()[config['mode']]\n-        elif mode_type == 'lambda':\n-            mode = func_load(config['mode'], globs=globals())\n-        else:\n-            mode = config['mode']\n-\n-        output_shape_type = config.pop('output_shape_type', None)\n-        if output_shape_type == 'function':\n-            output_shape = globals()[config['output_shape']]\n-        elif output_shape_type == 'lambda':\n-            output_shape = func_load(config['output_shape'],\n-                                     globs=globals())\n-        else:\n-            output_shape = config.get('output_shape')\n-\n-        output_mask_type = config.pop('output_mask_type', None)\n-        if output_mask_type == 'function':\n-            output_mask = globals()[config['output_mask']]\n-        elif output_mask_type == 'lambda':\n-            output_mask = func_load(config['output_mask'],\n-                                    globs=globals())\n-        else:\n-            output_mask = config.get('output_mask')\n-\n-        config['mode'] = mode\n-        config['output_shape'] = output_shape\n-        config['output_mask'] = output_mask\n-        return super(Merge, cls).from_config(config)\n-\n-\n-def merge(inputs, mode='sum', concat_axis=-1,\n-          dot_axes=-1, output_shape=None, output_mask=None,\n-          arguments=None, name=None):\n-    \"\"\"Functional merge, to apply to Keras tensors (NOT layers).\n-    Returns a Keras tensor.\n-    # Example\n-    ```python\n-    tensor_a = Input(shape=(32,))\n-    tensor_b = Input(shape=(32,))\n-    merged_tensor = merge([tensor_a, tensor_b], mode='concat', concat_axis=1)\n-    ```\n-    # Arguments\n-        mode: String or lambda/function. If string, must be one\n-            of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'.\n-            If lambda/function, it should take as input a list of tensors\n-            and return a single tensor.\n-        concat_axis: Integer, axis to use in mode `concat`.\n-        dot_axes: Integer or tuple of integers,\n-            axes to use in mode `dot` or `cos`.\n-        output_shape: Shape tuple (tuple of integers), or lambda/function\n-            to compute output_shape (only if merge mode is a lambda/function).\n-            If the latter case, it should take as input a list of shape tuples\n-            (1:1 mapping to input tensors) and return a single shape tuple,\n-            including the batch size\n-            (same convention as the `compute_output_shape` method of layers).\n-        node_indices: Optional list of integers containing\n-            the output node index for each input layer\n-            (in case some input layers have multiple output nodes).\n-            will default to an array of 0s if not provided.\n-        tensor_indices: Optional list of indices of output tensors\n-            to consider for merging\n-            (in case some input layer node returns multiple tensors).\n-    \"\"\"\n-    warnings.warn('The `merge` function is deprecated '\n-                  'and will be removed after 08/2017. '\n-                  'Use instead layers from `keras.layers.merge`, '\n-                  'e.g. `add`, `concatenate`, etc.', stacklevel=2)\n-    all_keras_tensors = True\n-    for x in inputs:\n-        if not hasattr(x, '_keras_history'):\n-            all_keras_tensors = False\n-            break\n-    if all_keras_tensors:\n-        input_layers = []\n-        node_indices = []\n-        tensor_indices = []\n-        for x in inputs:\n-            input_layer, node_index, tensor_index = x._keras_history\n-            input_layers.append(input_layer)\n-            node_indices.append(node_index)\n-            tensor_indices.append(tensor_index)\n-        merge_layer = Merge(input_layers, mode=mode,\n-                            concat_axis=concat_axis,\n-                            dot_axes=dot_axes,\n-                            output_shape=output_shape,\n-                            output_mask=output_mask,\n-                            arguments=arguments,\n-                            node_indices=node_indices,\n-                            tensor_indices=tensor_indices,\n-                            name=name)\n-        return merge_layer._inbound_nodes[0].output_tensors[0]\n-    else:\n-        merge_layer = Merge(mode=mode,\n-                            concat_axis=concat_axis,\n-                            dot_axes=dot_axes,\n-                            output_shape=output_shape,\n-                            output_mask=output_mask,\n-                            arguments=arguments,\n-                            name=name)\n-        return merge_layer(inputs)\n-\n-\n class MaxoutDense(Layer):\n     \"\"\"A dense maxout layer.\n     A `MaxoutDense` layer takes the element-wise maximum of\n\n@@ -1,31 +0,0 @@\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-from .layers import Merge\n-\n-\n-def needs_legacy_support(model):\n-    return isinstance(model.layers[0], Merge)\n-\n-\n-def legacy_sequential_layers(model):\n-    layers = []\n-    if model.layers:\n-        if isinstance(model.layers[0], Merge):\n-            merge = model.layers[0]\n-            for layer in merge.layers:\n-                if hasattr(layer, 'layers'):\n-                    for sublayer in layer.layers:\n-                        if sublayer not in layers:\n-                            layers.append(sublayer)\n-                else:\n-                    if layer not in layers:\n-                        layers.append(layer)\n-        else:\n-            if model.layers[0] not in layers:\n-                layers.append(model.layers[0])\n-        for layer in model.layers[1:]:\n-            if layer not in layers:\n-                layers.append(layer)\n-    return layers\n\n@@ -3,12 +3,8 @@ import pytest\n from keras.utils.test_utils import keras_test\n from keras.utils.test_utils import layer_test\n from keras.legacy import layers as legacy_layers\n-from keras import layers\n-from keras import models\n from keras import regularizers\n from keras import constraints\n-from keras import backend as K\n-import numpy as np\n \n \n @keras_test\n@@ -42,276 +38,5 @@ def test_maxout_dense():\n                input_shape=(3, 2))\n \n \n-@keras_test\n-def test_merge():\n-    # test modes: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot'.\n-    input_shapes = [(3, 2), (3, 2)]\n-    inputs = [np.random.random(shape) for shape in input_shapes]\n-\n-    # test functional API\n-    for mode in ['sum', 'mul', 'concat', 'ave', 'max']:\n-        print(mode)\n-        input_a = layers.Input(shape=input_shapes[0][1:])\n-        input_b = layers.Input(shape=input_shapes[1][1:])\n-        merged = legacy_layers.merge([input_a, input_b], mode=mode)\n-        model = models.Model([input_a, input_b], merged)\n-        model.compile('rmsprop', 'mse')\n-\n-        expected_output_shape = model.compute_output_shape(input_shapes)\n-        actual_output_shape = model.predict(inputs).shape\n-        assert expected_output_shape == actual_output_shape\n-\n-        config = model.get_config()\n-        model = models.Model.from_config(config)\n-        model.compile('rmsprop', 'mse')\n-\n-        # test Merge (#2460)\n-        merged = legacy_layers.Merge(mode=mode)([input_a, input_b])\n-        model = models.Model([input_a, input_b], merged)\n-        model.compile('rmsprop', 'mse')\n-\n-        expected_output_shape = model.compute_output_shape(input_shapes)\n-        actual_output_shape = model.predict(inputs).shape\n-        assert expected_output_shape == actual_output_shape\n-\n-    # test lambda with output_shape lambda\n-    input_a = layers.Input(shape=input_shapes[0][1:])\n-    input_b = layers.Input(shape=input_shapes[1][1:])\n-    merged = legacy_layers.merge(\n-        [input_a, input_b],\n-        mode=lambda tup: K.concatenate([tup[0], tup[1]]),\n-        output_shape=lambda tup: tup[0][:-1] + (tup[0][-1] + tup[1][-1],))\n-    model = models.Model([input_a, input_b], merged)\n-    expected_output_shape = model.compute_output_shape(input_shapes)\n-    actual_output_shape = model.predict(inputs).shape\n-    assert expected_output_shape == actual_output_shape\n-\n-    config = model.get_config()\n-    model = models.Model.from_config(config)\n-    model.compile('rmsprop', 'mse')\n-\n-    # test function with output_shape function\n-    def fn_mode(tup):\n-        x, y = tup\n-        return K.concatenate([x, y], axis=1)\n-\n-    def fn_output_shape(tup):\n-        s1, s2 = tup\n-        return (s1[0], s1[1] + s2[1]) + s1[2:]\n-\n-    input_a = layers.Input(shape=input_shapes[0][1:])\n-    input_b = layers.Input(shape=input_shapes[1][1:])\n-    merged = legacy_layers.merge([input_a, input_b],\n-                                 mode=fn_mode,\n-                                 output_shape=fn_output_shape)\n-    model = models.Model([input_a, input_b], merged)\n-    expected_output_shape = model.compute_output_shape(input_shapes)\n-    actual_output_shape = model.predict(inputs).shape\n-    assert expected_output_shape == actual_output_shape\n-\n-    config = model.get_config()\n-    model = models.Model.from_config(config)\n-    model.compile('rmsprop', 'mse')\n-\n-    # test function with output_mask function\n-    # time dimension is required for masking\n-    input_shapes = [(4, 3, 2), (4, 3, 2)]\n-    inputs = [np.random.random(shape) for shape in input_shapes]\n-\n-    def fn_output_mask(tup):\n-        x_mask, y_mask = tup\n-        return K.concatenate([x_mask, y_mask])\n-\n-    input_a = layers.Input(shape=input_shapes[0][1:])\n-    input_b = layers.Input(shape=input_shapes[1][1:])\n-    a = layers.Masking()(input_a)\n-    b = layers.Masking()(input_b)\n-    merged = legacy_layers.merge([a, b], mode=fn_mode, output_shape=fn_output_shape, output_mask=fn_output_mask)\n-    model = models.Model([input_a, input_b], merged)\n-    expected_output_shape = model.compute_output_shape(input_shapes)\n-    actual_output_shape = model.predict(inputs).shape\n-    assert expected_output_shape == actual_output_shape\n-\n-    config = model.get_config()\n-    model = models.Model.from_config(config)\n-    model.compile('rmsprop', 'mse')\n-\n-    mask_inputs = (np.zeros(input_shapes[0][:-1]), np.ones(input_shapes[1][:-1]))\n-    expected_mask_output = np.concatenate(mask_inputs, axis=-1)\n-    mask_input_placeholders = [K.placeholder(shape=input_shape[:-1]) for input_shape in input_shapes]\n-    mask_output = model.layers[-1]._output_mask(mask_input_placeholders)\n-    assert np.all(K.function(mask_input_placeholders, [mask_output])(mask_inputs)[0] == expected_mask_output)\n-\n-    # test lambda with output_mask lambda\n-    input_a = layers.Input(shape=input_shapes[0][1:])\n-    input_b = layers.Input(shape=input_shapes[1][1:])\n-    a = layers.Masking()(input_a)\n-    b = layers.Masking()(input_b)\n-    merged = legacy_layers.merge(\n-        [a, b], mode=lambda tup: K.concatenate([tup[0], tup[1]], axis=1),\n-        output_shape=lambda tup: (tup[0][0], tup[0][1] + tup[1][1]) + tup[0][2:],\n-        output_mask=lambda tup: K.concatenate([tup[0], tup[1]]))\n-    model = models.Model([input_a, input_b], merged)\n-    expected_output_shape = model.compute_output_shape(input_shapes)\n-    actual_output_shape = model.predict(inputs).shape\n-    assert expected_output_shape == actual_output_shape\n-\n-    config = model.get_config()\n-    model = models.Model.from_config(config)\n-    model.compile('rmsprop', 'mse')\n-\n-    mask_output = model.layers[-1]._output_mask(mask_input_placeholders)\n-    assert np.all(K.function(mask_input_placeholders, [mask_output])(mask_inputs)[0] == expected_mask_output)\n-\n-    # test with arguments\n-    input_shapes = [(3, 2), (3, 2)]\n-    inputs = [np.random.random(shape) for shape in input_shapes]\n-\n-    def fn_mode(tup, a, b):\n-        x, y = tup\n-        return x * a + y * b\n-\n-    input_a = layers.Input(shape=input_shapes[0][1:])\n-    input_b = layers.Input(shape=input_shapes[1][1:])\n-    merged = legacy_layers.merge([input_a, input_b], mode=fn_mode, output_shape=lambda s: s[0], arguments={'a': 0.7, 'b': 0.3})\n-    model = models.Model([input_a, input_b], merged)\n-    output = model.predict(inputs)\n-\n-    config = model.get_config()\n-    model = models.Model.from_config(config)\n-\n-    assert np.all(model.predict(inputs) == output)\n-\n-\n-@keras_test\n-def test_merge_mask_2d():\n-    rand = lambda *shape: np.asarray(np.random.random(shape) > 0.5, dtype='int32')\n-\n-    # inputs\n-    input_a = layers.Input(shape=(3,))\n-    input_b = layers.Input(shape=(3,))\n-\n-    # masks\n-    masked_a = layers.Masking(mask_value=0)(input_a)\n-    masked_b = layers.Masking(mask_value=0)(input_b)\n-\n-    # three different types of merging\n-    merged_sum = legacy_layers.merge([masked_a, masked_b], mode='sum')\n-    merged_concat = legacy_layers.merge([masked_a, masked_b], mode='concat', concat_axis=1)\n-    merged_concat_mixed = legacy_layers.merge([masked_a, input_b], mode='concat', concat_axis=1)\n-\n-    # test sum\n-    model_sum = models.Model([input_a, input_b], [merged_sum])\n-    model_sum.compile(loss='mse', optimizer='sgd')\n-    model_sum.fit([rand(2, 3), rand(2, 3)], [rand(2, 3)], epochs=1)\n-\n-    # test concatenation\n-    model_concat = models.Model([input_a, input_b], [merged_concat])\n-    model_concat.compile(loss='mse', optimizer='sgd')\n-    model_concat.fit([rand(2, 3), rand(2, 3)], [rand(2, 6)], epochs=1)\n-\n-    # test concatenation with masked and non-masked inputs\n-    model_concat = models.Model([input_a, input_b], [merged_concat_mixed])\n-    model_concat.compile(loss='mse', optimizer='sgd')\n-    model_concat.fit([rand(2, 3), rand(2, 3)], [rand(2, 6)], epochs=1)\n-\n-\n-@keras_test\n-def test_merge_mask_3d():\n-    rand = lambda *shape: np.asarray(np.random.random(shape) > 0.5, dtype='int32')\n-\n-    # embeddings\n-    input_a = layers.Input(shape=(3,), dtype='int32')\n-    input_b = layers.Input(shape=(3,), dtype='int32')\n-    embedding = layers.Embedding(3, 4, mask_zero=True)\n-    embedding_a = embedding(input_a)\n-    embedding_b = embedding(input_b)\n-\n-    # rnn\n-    rnn = layers.SimpleRNN(3, return_sequences=True)\n-    rnn_a = rnn(embedding_a)\n-    rnn_b = rnn(embedding_b)\n-\n-    # concatenation\n-    merged_concat = legacy_layers.merge([rnn_a, rnn_b], mode='concat', concat_axis=-1)\n-    model = models.Model([input_a, input_b], [merged_concat])\n-    model.compile(loss='mse', optimizer='sgd')\n-    model.fit([rand(2, 3), rand(2, 3)], [rand(2, 3, 6)])\n-\n-\n-@keras_test\n-def test_sequential_regression():\n-    # start with a basic example of using a Sequential model\n-    # inside the functional API\n-    seq = models.Sequential()\n-    seq.add(layers.Dense(10, input_shape=(10,)))\n-\n-    x = layers.Input(shape=(10,))\n-    y = seq(x)\n-    model = models.Model(x, y)\n-    model.compile('rmsprop', 'mse')\n-    weights = model.get_weights()\n-\n-    # test serialization\n-    config = model.get_config()\n-    model = models.Model.from_config(config)\n-    model.compile('rmsprop', 'mse')\n-    model.set_weights(weights)\n-\n-    # more advanced model with multiple branches\n-\n-    branch_1 = models.Sequential(name='branch_1')\n-    branch_1.add(layers.Embedding(input_dim=100,\n-                                  output_dim=10,\n-                                  input_length=2,\n-                                  name='embed_1'))\n-    branch_1.add(layers.LSTM(32, name='lstm_1'))\n-\n-    branch_2 = models.Sequential(name='branch_2')\n-    branch_2.add(layers.Dense(32, input_shape=(8,), name='dense_2'))\n-\n-    branch_3 = models.Sequential(name='branch_3')\n-    branch_3.add(layers.Dense(32, input_shape=(6,), name='dense_3'))\n-\n-    branch_1_2 = models.Sequential([legacy_layers.Merge([branch_1, branch_2], mode='concat')], name='branch_1_2')\n-    branch_1_2.add(layers.Dense(16, name='dense_1_2-0'))\n-    # test whether impromptu input_shape breaks the model\n-    branch_1_2.add(layers.Dense(16, input_shape=(16,), name='dense_1_2-1'))\n-\n-    model = models.Sequential([legacy_layers.Merge([branch_1_2, branch_3], mode='concat')], name='final')\n-    model.add(layers.Dense(16, name='dense_final'))\n-    model.compile(optimizer='rmsprop',\n-                  loss='categorical_crossentropy',\n-                  metrics=['accuracy'])\n-    model.summary()\n-\n-    x = (100 * np.random.random((100, 2))).astype('int32')\n-    y = np.random.random((100, 8))\n-    z = np.random.random((100, 6))\n-    labels = np.random.random((100, 16))\n-    model.fit([x, y, z], labels, epochs=1)\n-\n-    # test if Sequential can be called in the functional API\n-\n-    a = layers.Input(shape=(2,), dtype='int32')\n-    b = layers.Input(shape=(8,))\n-    c = layers.Input(shape=(6,))\n-    o = model([a, b, c])\n-\n-    outer_model = models.Model([a, b, c], o)\n-    outer_model.compile(optimizer='rmsprop',\n-                        loss='categorical_crossentropy',\n-                        metrics=['accuracy'])\n-    outer_model.fit([x, y, z], labels, epochs=1)\n-\n-    # test serialization\n-    config = outer_model.get_config()\n-    outer_model = models.Model.from_config(config)\n-    outer_model.compile(optimizer='rmsprop',\n-                        loss='categorical_crossentropy',\n-                        metrics=['accuracy'])\n-    outer_model.fit([x, y, z], labels, epochs=1)\n-\n-\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n@@ -1,290 +0,0 @@\n-from __future__ import absolute_import\n-from __future__ import print_function\n-import pytest\n-import os\n-import numpy as np\n-\n-from keras.models import Sequential\n-from keras.layers import Dense, Activation\n-from keras.legacy.layers import Merge\n-from keras.utils import np_utils\n-from keras.utils.test_utils import get_test_data, keras_test\n-from keras.models import model_from_json, model_from_yaml\n-\n-\n-input_dim = 16\n-num_hidden = 8\n-num_classes = 4\n-batch_size = 32\n-epochs = 1\n-\n-\n-@pytest.fixture\n-def in_tmpdir(tmpdir):\n-    \"\"\"Runs a function in a temporary directory.\n-\n-    Checks that the directory is empty afterwards.\n-    \"\"\"\n-    with tmpdir.as_cwd():\n-        yield None\n-    assert not tmpdir.listdir()\n-\n-\n-def _get_test_data():\n-    np.random.seed(1234)\n-\n-    train_samples = 100\n-    test_samples = 50\n-\n-    (x_train, y_train), (x_test, y_test) = get_test_data(num_train=train_samples,\n-                                                         num_test=test_samples,\n-                                                         input_shape=(input_dim,),\n-                                                         classification=True,\n-                                                         num_classes=num_classes)\n-    y_test = np_utils.to_categorical(y_test)\n-    y_train = np_utils.to_categorical(y_train)\n-    return (x_train, y_train), (x_test, y_test)\n-\n-\n-@keras_test\n-def test_merge_sum(in_tmpdir):\n-    (x_train, y_train), (x_test, y_test) = _get_test_data()\n-    left = Sequential()\n-    left.add(Dense(num_hidden, input_shape=(input_dim,)))\n-    left.add(Activation('relu'))\n-\n-    right = Sequential()\n-    right.add(Dense(num_hidden, input_shape=(input_dim,)))\n-    right.add(Activation('relu'))\n-\n-    model = Sequential()\n-    model.add(Merge([left, right], mode='sum'))\n-    model.add(Dense(num_classes))\n-    model.add(Activation('softmax'))\n-    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n-\n-    model.fit([x_train, x_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0, validation_data=([x_test, x_test], y_test))\n-    model.fit([x_train, x_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0, validation_split=0.1)\n-    model.fit([x_train, x_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0)\n-    model.fit([x_train, x_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0, shuffle=False)\n-\n-    loss = model.evaluate([x_test, x_test], y_test, verbose=0)\n-\n-    model.predict([x_test, x_test], verbose=0)\n-    model.predict_classes([x_test, x_test], verbose=0)\n-    model.predict_proba([x_test, x_test], verbose=0)\n-\n-    # test weight saving\n-    fname = 'test_merge_sum_temp.h5'\n-    model.save_weights(fname, overwrite=True)\n-    left = Sequential()\n-    left.add(Dense(num_hidden, input_shape=(input_dim,)))\n-    left.add(Activation('relu'))\n-    right = Sequential()\n-    right.add(Dense(num_hidden, input_shape=(input_dim,)))\n-    right.add(Activation('relu'))\n-    model = Sequential()\n-    model.add(Merge([left, right], mode='sum'))\n-    model.add(Dense(num_classes))\n-    model.add(Activation('softmax'))\n-    model.load_weights(fname)\n-    os.remove(fname)\n-    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n-\n-    nloss = model.evaluate([x_test, x_test], y_test, verbose=0)\n-    assert(loss == nloss)\n-\n-    # test serialization\n-    config = model.get_config()\n-    Sequential.from_config(config)\n-\n-    model.summary()\n-    json_str = model.to_json()\n-    model_from_json(json_str)\n-\n-    yaml_str = model.to_yaml()\n-    model_from_yaml(yaml_str)\n-\n-\n-@keras_test\n-def test_merge_dot():\n-    (x_train, y_train), (x_test, y_test) = _get_test_data()\n-\n-    left = Sequential()\n-    left.add(Dense(num_hidden, input_shape=(input_dim,)))\n-    left.add(Activation('relu'))\n-\n-    right = Sequential()\n-    right.add(Dense(num_hidden, input_shape=(input_dim,)))\n-    right.add(Activation('relu'))\n-\n-    model = Sequential()\n-    model.add(Merge([left, right], mode='dot', dot_axes=1))\n-    model.add(Dense(num_classes))\n-    model.add(Activation('softmax'))\n-\n-    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n-\n-    left = Sequential()\n-    left.add(Dense(num_hidden, input_shape=(input_dim,)))\n-    left.add(Activation('relu'))\n-\n-    right = Sequential()\n-    right.add(Dense(num_hidden, input_shape=(input_dim,)))\n-    right.add(Activation('relu'))\n-\n-    model = Sequential()\n-    model.add(Merge([left, right], mode='dot', dot_axes=[1, 1]))\n-    model.add(Dense(num_classes))\n-    model.add(Activation('softmax'))\n-\n-    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n-\n-\n-@keras_test\n-def test_merge_concat(in_tmpdir):\n-    (x_train, y_train), (x_test, y_test) = _get_test_data()\n-\n-    left = Sequential(name='branch_1')\n-    left.add(Dense(num_hidden, input_shape=(input_dim,), name='dense_1'))\n-    left.add(Activation('relu', name='relu_1'))\n-\n-    right = Sequential(name='branch_2')\n-    right.add(Dense(num_hidden, input_shape=(input_dim,), name='dense_2'))\n-    right.add(Activation('relu', name='relu_2'))\n-\n-    model = Sequential(name='merged_branches')\n-    model.add(Merge([left, right], mode='concat', name='merge'))\n-    model.add(Dense(num_classes, name='final_dense'))\n-    model.add(Activation('softmax', name='softmax'))\n-    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n-\n-    model.fit([x_train, x_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0, validation_data=([x_test, x_test], y_test))\n-    model.fit([x_train, x_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0, validation_split=0.1)\n-    model.fit([x_train, x_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0)\n-    model.fit([x_train, x_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0, shuffle=False)\n-\n-    loss = model.evaluate([x_test, x_test], y_test, verbose=0)\n-\n-    model.predict([x_test, x_test], verbose=0)\n-    model.predict_classes([x_test, x_test], verbose=0)\n-    model.predict_proba([x_test, x_test], verbose=0)\n-    model.get_config()\n-\n-    fname = 'test_merge_concat_temp.h5'\n-    model.save_weights(fname, overwrite=True)\n-    model.fit([x_train, x_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0)\n-    model.load_weights(fname)\n-    os.remove(fname)\n-\n-    nloss = model.evaluate([x_test, x_test], y_test, verbose=0)\n-    assert(loss == nloss)\n-\n-\n-@keras_test\n-def test_merge_recursivity(in_tmpdir):\n-    (x_train, y_train), (x_test, y_test) = _get_test_data()\n-    left = Sequential()\n-    left.add(Dense(num_hidden, input_shape=(input_dim,)))\n-    left.add(Activation('relu'))\n-\n-    right = Sequential()\n-    right.add(Dense(num_hidden, input_shape=(input_dim,)))\n-    right.add(Activation('relu'))\n-\n-    righter = Sequential()\n-    righter.add(Dense(num_hidden, input_shape=(input_dim,)))\n-    righter.add(Activation('relu'))\n-\n-    intermediate = Sequential()\n-    intermediate.add(Merge([left, right], mode='sum'))\n-    intermediate.add(Dense(num_hidden))\n-    intermediate.add(Activation('relu'))\n-\n-    model = Sequential()\n-    model.add(Merge([intermediate, righter], mode='sum'))\n-    model.add(Dense(num_classes))\n-    model.add(Activation('softmax'))\n-    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n-\n-    model.fit([x_train, x_train, x_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0, validation_data=([x_test, x_test, x_test], y_test))\n-    model.fit([x_train, x_train, x_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0, validation_split=0.1)\n-    model.fit([x_train, x_train, x_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0)\n-    model.fit([x_train, x_train, x_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0, shuffle=False)\n-\n-    loss = model.evaluate([x_test, x_test, x_test], y_test, verbose=0)\n-\n-    model.predict([x_test, x_test, x_test], verbose=0)\n-    model.predict_classes([x_test, x_test, x_test], verbose=0)\n-    model.predict_proba([x_test, x_test, x_test], verbose=0)\n-\n-    fname = 'test_merge_recursivity_temp.h5'\n-    model.save_weights(fname, overwrite=True)\n-    model.load_weights(fname)\n-    os.remove(fname)\n-\n-    nloss = model.evaluate([x_test, x_test, x_test], y_test, verbose=0)\n-    assert(loss == nloss)\n-\n-    # test serialization\n-    config = model.get_config()\n-    Sequential.from_config(config)\n-\n-    model.summary()\n-    json_str = model.to_json()\n-    model_from_json(json_str)\n-\n-    yaml_str = model.to_yaml()\n-    model_from_yaml(yaml_str)\n-\n-\n-@keras_test\n-def test_merge_overlap(in_tmpdir):\n-    (x_train, y_train), (x_test, y_test) = _get_test_data()\n-    left = Sequential()\n-    left.add(Dense(num_hidden, input_shape=(input_dim,)))\n-    left.add(Activation('relu'))\n-\n-    model = Sequential()\n-    model.add(Merge([left, left], mode='sum'))\n-    model.add(Dense(num_classes))\n-    model.add(Activation('softmax'))\n-    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n-\n-    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n-    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=2, validation_split=0.1)\n-    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=0)\n-    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, shuffle=False)\n-\n-    model.train_on_batch(x_train[:32], y_train[:32])\n-\n-    loss = model.evaluate(x_test, y_test, verbose=0)\n-    model.predict(x_test, verbose=0)\n-    model.predict_classes(x_test, verbose=0)\n-    model.predict_proba(x_test, verbose=0)\n-\n-    fname = 'test_merge_overlap_temp.h5'\n-    print(model.layers)\n-    model.save_weights(fname, overwrite=True)\n-    print(model.trainable_weights)\n-\n-    model.load_weights(fname)\n-    os.remove(fname)\n-\n-    nloss = model.evaluate(x_test, y_test, verbose=0)\n-    assert(loss == nloss)\n-\n-    # test serialization\n-    config = model.get_config()\n-    Sequential.from_config(config)\n-\n-    model.summary()\n-    json_str = model.to_json()\n-    model_from_json(json_str)\n-\n-    yaml_str = model.to_yaml()\n-    model_from_yaml(yaml_str)\n-\n-\n-if __name__ == '__main__':\n-    pytest.main([__file__])\n\n@@ -382,7 +382,6 @@ def test_sequential_update_disabling():\n \n     model.compile('sgd', 'mse')\n     assert not model.updates\n-    assert not model.model.updates\n \n     x1 = model.predict(val_a)\n     model.train_on_batch(val_a, val_out)\n@@ -392,7 +391,6 @@ def test_sequential_update_disabling():\n     model.trainable = True\n     model.compile('sgd', 'mse')\n     assert model.updates\n-    assert model.model.updates\n \n     model.train_on_batch(val_a, val_out)\n     x2 = model.predict(val_a)\n\n@@ -226,7 +226,7 @@ def test_saving_right_after_compilation():\n     model.add(Dense(2, input_shape=(3,)))\n     model.add(Dense(3))\n     model.compile(loss='mse', optimizer='sgd', metrics=['acc'])\n-    model.model._make_train_function()\n+    model._make_train_function()\n \n     _, fname = tempfile.mkstemp('.h5')\n     save_model(model, fname)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
