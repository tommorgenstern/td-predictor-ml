{"custom_id": "keras#f73f6ec19b3819e23fc732db8702bd839902427e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 40 | Lines Deleted: 58 | Files Changed: 2 | Hunks: 23 | Methods Changed: 13 | Complexity Δ (Sum/Max): -6/0 | Churn Δ: 98 | Churn Cumulative: 1737 | Contributors (this commit): 8 | Commits (past 90d): 8 | Contributors (cumulative): 12 | DMM Complexity: 1.0\n\nDIFF:\n@@ -242,7 +242,7 @@ class Attention(BaseDenseAttention):\n       Defaults to `False`.\n     dropout: Float between 0 and 1. Fraction of the units to drop for the\n       attention scores. Defaults to 0.0.\n-    score: One of {'dot', 'concat'}. 'dot' refers to dot multiplication\n+    score_type: One of {'dot', 'concat'}. 'dot' refers to dot product\n       of query and key. 'concat' refers to hyperbolic tangent of query and key.\n \n   Call Args:\n@@ -321,17 +321,19 @@ class Attention(BaseDenseAttention):\n   ```\n   \"\"\"\n \n-  def __init__(self, use_scale=False, score='dot', **kwargs):\n+  def __init__(self, use_scale=False, score_type='dot', **kwargs):\n     super(Attention, self).__init__(**kwargs)\n     self.use_scale = use_scale\n-    self.score_type= score\n+    self.score_type= score_type\n     if self.score_type not in ['dot', 'concat']:\n-      logging.warning(f'Score type {self.score_type} is unknown, '\n-                      'fallback to score_type dot.')\n-      self.score_type= 'dot'\n+      raise ValueError(\n+                \"Unknown score_type. Acceptable values \"\n+                \"are: ['dot', 'concat']\"\n+            )\n \n   def build(self, input_shape):\n-    \"\"\"Creates scale variable if use_scale==True.\"\"\"\n+    \"\"\"Creates scale variable if use_scale==True and\n+      v parameter if score_type==concat\"\"\"\n     if self.use_scale:\n       self.scale = self.add_weight(\n           name='scale',\n@@ -341,73 +343,49 @@ class Attention(BaseDenseAttention):\n           trainable=True)\n     else:\n       self.scale = None\n+    if self.score_type == 'concat':\n+      self.attention_v = self.add_weight(\n+          name='attention_v',\n+          shape=(),\n+          initializer='ones',\n+          dtype=self.dtype,\n+          trainable=True)\n     super(Attention, self).build(input_shape)\n \n-  def _calculate_scores(self, query, key, score_type):\n+  def _calculate_scores(self, query, key):\n     \"\"\"Calculates attention scores as a query-key dot product.\n \n     Args:\n       query: Query tensor of shape `[batch_size, Tq, dim]`.\n       key: Key tensor of shape `[batch_size, Tv, dim]`.\n-      score: One of {'dot', 'concat'}.\n     Returns:\n       Tensor of shape `[batch_size, Tq, Tv]`.\n     \"\"\"\n-    if score_type == 'dot':\n+    if self.score_type == 'dot':\n       scores = tf.matmul(query, key, transpose_b=True)\n-    elif score_type == 'concat':\n+      if self.scale is not None:\n+        scores *= self.scale\n+    elif self.score_type == 'concat':\n       # Reshape tensors to enable broadcasting.\n       # Reshape into [batch_size, Tq, 1, dim].\n       q_reshaped = tf.expand_dims(query, axis=-2)\n       # Reshape into [batch_size, 1, Tv, dim].\n       k_reshaped = tf.expand_dims(key, axis=-3)\n-      scores = tf.reduce_sum(\n+      if self.scale is not None:\n+        scores = self.attention_v * tf.reduce_sum(\n+         tf.tanh(self.scale * (q_reshaped + k_reshaped)), axis=-1)\n+      else:\n+        scores = self.attention_v * tf.reduce_sum(\n          tf.tanh(q_reshaped + k_reshaped), axis=-1)\n \n-    if self.scale is not None:\n-      scores *= self.scale\n     return scores\n \n   def get_config(self):\n-    config = {'use_scale': self.use_scale}\n+    config = {'use_scale': self.use_scale,\n+              'score_type': self.score_type}\n     base_config = super(Attention, self).get_config()\n     return dict(list(base_config.items()) + list(config.items()))\n \n-  def call(self,\n-           inputs,\n-           mask=None,\n-           training=None,\n-           return_attention_scores=False):\n-    self._validate_call_args(inputs=inputs, mask=mask)\n-    q = inputs[0]\n-    v = inputs[1]\n-    k = inputs[2] if len(inputs) > 2 else v\n-    q_mask = mask[0] if mask else None\n-    v_mask = mask[1] if mask else None\n-    scores = self._calculate_scores(\n-        query=q, key=k, score_type= self.score_type)\n-    if v_mask is not None:\n-      # Mask of shape [batch_size, 1, Tv].\n-      v_mask = tf.expand_dims(v_mask, axis=-2)\n-    if self.causal:\n-      scores_shape = tf.shape(scores)\n-      causal_mask_shape = tf.concat(\n-          [tf.ones_like(scores_shape[:-2]), scores_shape[-2:]],\n-          axis=0)\n-      causal_mask = _lower_triangular_mask(causal_mask_shape)\n-    else:\n-      causal_mask = None\n-    scores_mask = _merge_masks(v_mask, causal_mask)\n-    result, attention_scores = self._apply_scores(\n-        scores=scores, value=v, scores_mask=scores_mask, training=training)\n-    if q_mask is not None:\n-      # Mask of shape [batch_size, Tq, 1].\n-      q_mask = tf.expand_dims(q_mask, axis=-1)\n-      result *= tf.cast(q_mask, dtype=result.dtype)\n-    if return_attention_scores:\n-      return result, attention_scores\n-    return result\n-\n \n @keras_export('keras.layers.AdditiveAttention')\n class AdditiveAttention(BaseDenseAttention):\n\n@@ -175,7 +175,7 @@ class AttentionTest(tf.test.TestCase, parameterized.TestCase):\n     k = np.array([[[1.6]]], dtype=np.float32)\n     attention_layer = dense_attention.Attention()\n     attention_layer.build(input_shape=([1, 1, 1], [1, 1, 1]))\n-    actual = attention_layer._calculate_scores(query=q, key=k)\n+    actual = attention_layer._calculate_scores(query=q, key=k, score_type='dot')\n \n     # Expected tensor of shape [1, 1, 1].\n     # expected000 = 1.1*1.6 = 1.76\n@@ -191,7 +191,7 @@ class AttentionTest(tf.test.TestCase, parameterized.TestCase):\n         dtype=np.float32)\n     attention_layer = dense_attention.Attention()\n     attention_layer.build(input_shape=([1, 2, 4], [1, 3, 4]))\n-    actual = attention_layer._calculate_scores(query=q, key=k)\n+    actual = attention_layer._calculate_scores(query=q, key=k, score_type='dot')\n \n     # Expected tensor of shape [1, 2, 3].\n     # expected000 = 1.*1.5+1.1*1.6+1.2*1.7+1.3*1.8 = 7.64\n@@ -211,9 +211,10 @@ class AttentionTest(tf.test.TestCase, parameterized.TestCase):\n     k = np.array(\n         [[[1.5, 1.6, 1.7, 1.8], [2.5, 2.6, 2.7, 2.8], [3.5, 3.6, 3.7, 3.8]]],\n         dtype=np.float32)\n-    attention_layer = dense_attention.Attention()\n+    attention_layer = dense_attention.Attention(score_type='dot')\n     attention_layer.build(input_shape=([1, 2, 4], [1, 3, 4]))\n-    actual = attention_layer._calculate_scores(query=q, key=k, score_type='concat')\n+    actual = attention_layer._calculate_scores(query=q, key=k)\n+    attention_layer.attention_v = 1\n \n     # pylint:disable=line-too-long\n     # expected000 = tanh(1.+1.5) + tanh(1.1+1.6) + tanh(1.2+1.7) + tanh(1.3+1.8) = 3.96753427840\n@@ -264,14 +265,15 @@ class AttentionTest(tf.test.TestCase, parameterized.TestCase):\n     q = np.array([[[1.1]]], dtype=np.float32)\n     # Key tensor of shape [1, 1, 1]\n     k = np.array([[[1.6]]], dtype=np.float32)\n-    attention_layer = dense_attention.Attention(use_scale=True)\n+    attention_layer = dense_attention.Attention(use_scale=True, score_type='concat')\n     attention_layer.build(input_shape=([1, 1, 1], [1, 1, 1]))\n     attention_layer.scale = 2.\n     actual = attention_layer._calculate_scores(query=q, key=k)\n+    attention_layer.attention_v = 1\n \n     # Expected tensor of shape [1, 1, 1].\n-    # expected000 = 2 * tanh(1.1+1.6) = 1.982014907\n-    expected = np.array([[[1.98201491]]], dtype=np.float32)\n+    # expected000 = tanh(2*(1.1+1.6)) = 0.9999592018254402\n+    expected = np.array([[[0.999959202]]], dtype=np.float32)\n     self.assertAllClose(expected, actual)\n \n   def test_shape(self):\n@@ -298,7 +300,8 @@ class AttentionTest(tf.test.TestCase, parameterized.TestCase):\n         dtype=np.float32)\n     # Value mask tensor of shape [1, 3]\n     v_mask = np.array([[True, True, False]], dtype=np.bool_)\n-    attention_layer = dense_attention.Attention(score='concat')\n+    attention_layer = dense_attention.Attention(score_type='concat')\n+    attention_layer.attention_v = 1\n     actual = attention_layer([q, v], mask=[None, v_mask])\n \n     expected_shape = [1, 2, 4]\n@@ -337,6 +340,7 @@ class AttentionTest(tf.test.TestCase, parameterized.TestCase):\n     # Value mask tensor of shape [1, 3]\n     v_mask = np.array([[True, True, False]], dtype=np.bool_)\n     attention_layer = dense_attention.Attention(score='concat')\n+    attention_layer.attention_v = 1\n     actual = attention_layer([q, v, k], mask=[None, v_mask])\n \n     expected_shape = [1, 2, 4]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ca62313221e44d0fb9c4e34f3ef808fe9efc0cff", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 15 | Lines Deleted: 15 | Files Changed: 2 | Hunks: 14 | Methods Changed: 10 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 30 | Churn Cumulative: 1767 | Contributors (this commit): 8 | Commits (past 90d): 10 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -242,7 +242,7 @@ class Attention(BaseDenseAttention):\n       Defaults to `False`.\n     dropout: Float between 0 and 1. Fraction of the units to drop for the\n       attention scores. Defaults to 0.0.\n-    score_type: One of {'dot', 'concat'}. 'dot' refers to dot product\n+    score_mode: One of {'dot', 'concat'}. 'dot' refers to dot product\n       of query and key. 'concat' refers to hyperbolic tangent of query and key.\n \n   Call Args:\n@@ -321,19 +321,19 @@ class Attention(BaseDenseAttention):\n   ```\n   \"\"\"\n \n-  def __init__(self, use_scale=False, score_type='dot', **kwargs):\n+  def __init__(self, use_scale=False, score_mode='dot', **kwargs):\n     super(Attention, self).__init__(**kwargs)\n     self.use_scale = use_scale\n-    self.score_type= score_type\n-    if self.score_type not in ['dot', 'concat']:\n+    self.score_mode= score_mode\n+    if self.score_mode not in ['dot', 'concat']:\n       raise ValueError(\n-                \"Unknown score_type. Acceptable values \"\n+                \"Unknown score_mode. Acceptable values \"\n                 \"are: ['dot', 'concat']\"\n             )\n \n   def build(self, input_shape):\n     \"\"\"Creates scale variable if use_scale==True and\n-      v parameter if score_type==concat\"\"\"\n+      v parameter if score_mode==concat\"\"\"\n     if self.use_scale:\n       self.scale = self.add_weight(\n           name='scale',\n@@ -343,7 +343,7 @@ class Attention(BaseDenseAttention):\n           trainable=True)\n     else:\n       self.scale = None\n-    if self.score_type == 'concat':\n+    if self.score_mode == 'concat':\n       self.attention_v = self.add_weight(\n           name='attention_v',\n           shape=(),\n@@ -361,11 +361,11 @@ class Attention(BaseDenseAttention):\n     Returns:\n       Tensor of shape `[batch_size, Tq, Tv]`.\n     \"\"\"\n-    if self.score_type == 'dot':\n+    if self.score_mode == 'dot':\n       scores = tf.matmul(query, key, transpose_b=True)\n       if self.scale is not None:\n         scores *= self.scale\n-    elif self.score_type == 'concat':\n+    elif self.score_mode == 'concat':\n       # Reshape tensors to enable broadcasting.\n       # Reshape into [batch_size, Tq, 1, dim].\n       q_reshaped = tf.expand_dims(query, axis=-2)\n@@ -382,7 +382,7 @@ class Attention(BaseDenseAttention):\n \n   def get_config(self):\n     config = {'use_scale': self.use_scale,\n-              'score_type': self.score_type}\n+              'score_mode': self.score_mode}\n     base_config = super(Attention, self).get_config()\n     return dict(list(base_config.items()) + list(config.items()))\n \n\n@@ -175,7 +175,7 @@ class AttentionTest(tf.test.TestCase, parameterized.TestCase):\n     k = np.array([[[1.6]]], dtype=np.float32)\n     attention_layer = dense_attention.Attention()\n     attention_layer.build(input_shape=([1, 1, 1], [1, 1, 1]))\n-    actual = attention_layer._calculate_scores(query=q, key=k, score_type='dot')\n+    actual = attention_layer._calculate_scores(query=q, key=k)\n \n     # Expected tensor of shape [1, 1, 1].\n     # expected000 = 1.1*1.6 = 1.76\n@@ -191,7 +191,7 @@ class AttentionTest(tf.test.TestCase, parameterized.TestCase):\n         dtype=np.float32)\n     attention_layer = dense_attention.Attention()\n     attention_layer.build(input_shape=([1, 2, 4], [1, 3, 4]))\n-    actual = attention_layer._calculate_scores(query=q, key=k, score_type='dot')\n+    actual = attention_layer._calculate_scores(query=q, key=k)\n \n     # Expected tensor of shape [1, 2, 3].\n     # expected000 = 1.*1.5+1.1*1.6+1.2*1.7+1.3*1.8 = 7.64\n@@ -211,7 +211,7 @@ class AttentionTest(tf.test.TestCase, parameterized.TestCase):\n     k = np.array(\n         [[[1.5, 1.6, 1.7, 1.8], [2.5, 2.6, 2.7, 2.8], [3.5, 3.6, 3.7, 3.8]]],\n         dtype=np.float32)\n-    attention_layer = dense_attention.Attention(score_type='dot')\n+    attention_layer = dense_attention.Attention(score_mode='concat')\n     attention_layer.build(input_shape=([1, 2, 4], [1, 3, 4]))\n     actual = attention_layer._calculate_scores(query=q, key=k)\n     attention_layer.attention_v = 1\n@@ -265,7 +265,7 @@ class AttentionTest(tf.test.TestCase, parameterized.TestCase):\n     q = np.array([[[1.1]]], dtype=np.float32)\n     # Key tensor of shape [1, 1, 1]\n     k = np.array([[[1.6]]], dtype=np.float32)\n-    attention_layer = dense_attention.Attention(use_scale=True, score_type='concat')\n+    attention_layer = dense_attention.Attention(use_scale=True, score_mode='concat')\n     attention_layer.build(input_shape=([1, 1, 1], [1, 1, 1]))\n     attention_layer.scale = 2.\n     actual = attention_layer._calculate_scores(query=q, key=k)\n@@ -300,7 +300,7 @@ class AttentionTest(tf.test.TestCase, parameterized.TestCase):\n         dtype=np.float32)\n     # Value mask tensor of shape [1, 3]\n     v_mask = np.array([[True, True, False]], dtype=np.bool_)\n-    attention_layer = dense_attention.Attention(score_type='concat')\n+    attention_layer = dense_attention.Attention(score_mode='concat')\n     attention_layer.attention_v = 1\n     actual = attention_layer([q, v], mask=[None, v_mask])\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4e7b65df14cbc90f8ec23342d86e8bbe823a1e59", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 39 | Lines Deleted: 12 | Files Changed: 3 | Hunks: 7 | Methods Changed: 7 | Complexity Δ (Sum/Max): 3/2 | Churn Δ: 51 | Churn Cumulative: 21105 | Contributors (this commit): 124 | Commits (past 90d): 26 | Contributors (cumulative): 137 | DMM Complexity: 1.0\n\nDIFF:\n@@ -109,7 +109,7 @@ class DatasetCreatorModelFitParameterServerStrategyOnlyTest(\n     with self.assertRaisesRegex(ValueError,\n                                 \"`verbose=1` is not allowed with \"\n                                 \"`ParameterServerStrategy` for performance \"\n-                                \"reasons. Received: `verbose`=1\"):\n+                                \"reasons. Received: verbose=1\"):\n       self._model_fit(\n           strategy, use_dataset_creator=use_dataset_creator,\n           verbose=1)\n\n@@ -1304,15 +1304,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     self._check_call_args('fit')\n     _disallow_inside_tf_function('fit')\n \n-    if verbose == 'auto':\n-      if self.distribute_strategy._should_use_with_coordinator:  # pylint: disable=protected-access\n-        verbose = 2  # Default to epoch-level logging for PSStrategy.\n-      else:\n-        verbose = 1  # Default to batch-level logging otherwise.\n-    elif verbose == 1 and self.distribute_strategy._should_use_with_coordinator:  # pylint: disable=protected-access\n-      raise ValueError(\n-          '`verbose=1` is not allowed with `ParameterServerStrategy` for '\n-          f'performance reasons. Received: `verbose`={verbose}')\n+    verbose = _get_verbosity(verbose, self.distribute_strategy)\n \n     if validation_split:\n       # Create the validation data using the training data. Only supported for\n@@ -1576,7 +1568,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n                x=None,\n                y=None,\n                batch_size=None,\n-               verbose=1,\n+               verbose='auto',\n                sample_weight=None,\n                steps=None,\n                callbacks=None,\n@@ -1616,7 +1608,13 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n           specify the `batch_size` if your data is in the form of a dataset,\n           generators, or `keras.utils.Sequence` instances (since they generate\n           batches).\n-        verbose: 0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.\n+        verbose: `\"auto\"`, 0, 1, or 2. Verbosity mode.\n+            0 = silent, 1 = progress bar, 2 = one line per epoch.\n+            `\"auto\"` defaults to 1 for most cases, and to 2 when used with\n+            `ParameterServerStrategy`. Note that the progress bar is not\n+            particularly useful when logged to a file, so `verbose=2` is\n+            recommended when not running interactively (e.g. in a production\n+            environment).\n         sample_weight: Optional Numpy array of weights for the test samples,\n           used for weighting the loss function. You can either pass a flat (1D)\n           Numpy array with the same length as the input samples\n@@ -1675,6 +1673,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n       self._cluster_coordinator = tf.distribute.experimental.coordinator.ClusterCoordinator(\n           self.distribute_strategy)\n \n+    verbose = _get_verbosity(verbose, self.distribute_strategy)\n     with self.distribute_strategy.scope():\n       # Use cached evaluation data only when it's called in `Model.fit`\n       if (use_cached_eval_dataset\n@@ -3188,6 +3187,20 @@ def concat(tensors, axis=0):\n   return tf.concat(tensors, axis=axis)\n \n \n+def _get_verbosity(verbose, distribute_strategy):\n+  \"\"\"Find the right verbosity value for 'auto'.\"\"\"\n+  if verbose == 1 and distribute_strategy._should_use_with_coordinator:  # pylint: disable=protected-access\n+    raise ValueError(\n+        '`verbose=1` is not allowed with `ParameterServerStrategy` for '\n+        f'performance reasons. Received: verbose={verbose}')\n+  if verbose == 'auto':\n+    if distribute_strategy._should_use_with_coordinator:  # pylint: disable=protected-access\n+      return 2  # Default to epoch-level logging for PSStrategy.\n+    else:\n+      return 1  # Default to batch-level logging otherwise.\n+  return verbose\n+\n+\n def _is_tpu_multi_host(strategy):\n   return (backend.is_tpu_strategy(strategy) and\n           strategy.extended.num_hosts > 1)\n\n@@ -1856,6 +1856,20 @@ class TrainingTest(keras_parameterized.TestCase):\n     self.assertLen(history.history['loss'], 2)\n     self.assertAllClose(initial_value, model.trainable_variables[0])\n \n+  @keras_parameterized.run_all_keras_modes(always_skip_v1=True)\n+  def test_get_verbosity(self):\n+    class MyStrategy(tf.distribute.Strategy):\n+\n+      def __init__(self):\n+        self._should_use_with_coordinator = True\n+    with self.assertRaisesRegex(ValueError, '`verbose=1` is not allowed'):\n+      training_module._get_verbosity(1, MyStrategy())\n+    self.assertEqual(training_module._get_verbosity('auto', MyStrategy()), 2)\n+    self.assertEqual(training_module._get_verbosity(\n+        'auto', tf.distribute.MirroredStrategy()), 1)\n+    self.assertEqual(training_module._get_verbosity(\n+        2, tf.distribute.MirroredStrategy()), 2)\n+\n \n class TestExceptionsAndWarnings(keras_parameterized.TestCase):\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c717e7ff933fa6ea1aa7a12bdad4610ff86f6bed", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 854 | Contributors (this commit): 8 | Commits (past 90d): 8 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -242,8 +242,10 @@ class Attention(BaseDenseAttention):\n       Defaults to `False`.\n     dropout: Float between 0 and 1. Fraction of the units to drop for the\n       attention scores. Defaults to 0.0.\n-    score_mode: One of {'dot', 'concat'}. 'dot' refers to dot product\n-      of query and key. 'concat' refers to hyperbolic tangent of query and key.\n+    score_mode: Function to use to compute attention scores, one of \n+      `{\"dot\", \"concat\"}`. `\"dot\"` refers to the dot product between the query\n+      and key vectors. `\"concat\"` refers to the hyperbolic tangent of the \n+      concatenation of the query and key vectors.\n \n   Call Args:\n \n@@ -327,7 +329,7 @@ class Attention(BaseDenseAttention):\n     self.score_mode= score_mode\n     if self.score_mode not in ['dot', 'concat']:\n       raise ValueError(\n-                \"Unknown score_mode. Acceptable values \"\n+                f\"Received: score_mode={score_mode}. Acceptable values \"\n                 \"are: ['dot', 'concat']\"\n             )\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e70b70a6fd25054419db634d5c37b1de827d1bca", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 12 | Churn Cumulative: 16462 | Contributors (this commit): 120 | Commits (past 90d): 15 | Contributors (cumulative): 120 | DMM Complexity: 1.0\n\nDIFF:\n@@ -3071,7 +3071,8 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n   def _trackable_saved_model_saver(self):\n     return model_serialization.ModelSavedModelSaver(self)\n \n-  def _list_functions_for_serialization(self, serialization_cache):\n+  def _trackable_children(self, save_type='checkpoint', **kwargs):\n+    if save_type == 'savedmodel':\n       # SavedModel needs to ignore the execution functions.\n       train_function = self.train_function\n       test_function = self.test_function\n@@ -3081,13 +3082,16 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n       self.test_function = None\n       self.predict_function = None\n       self.train_tf_function = None\n-    functions = super(\n-        Model, self)._list_functions_for_serialization(serialization_cache)\n+\n+    children = super(Model, self)._trackable_children(save_type, **kwargs)\n+\n+    if save_type == 'savedmodel':\n       self.train_function = train_function\n       self.test_function = test_function\n       self.predict_function = predict_function\n       self.train_tf_function = train_tf_function\n-    return functions\n+\n+    return children\n \n   def _should_eval(self, epoch, validation_freq):\n     epoch = epoch + 1  # one-index the user-facing epoch.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5caa668b6a415675064a730f5eb46ecc08e40f65", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 192 | Lines Deleted: 102 | Files Changed: 5 | Hunks: 12 | Methods Changed: 11 | Complexity Δ (Sum/Max): 8/4 | Churn Δ: 294 | Churn Cumulative: 3462 | Contributors (this commit): 20 | Commits (past 90d): 12 | Contributors (cumulative): 40 | DMM Complexity: 0.7708333333333334\n\nDIFF:\n@@ -251,6 +251,7 @@ from keras.layers.rnn_cell_wrapper_v2 import ResidualWrapper\n # Serialization functions.\n from keras.layers import serialization\n from keras.layers.serialization import deserialize\n+from keras.layers.serialization import deserialize_from_json\n from keras.layers.serialization import serialize\n from keras.layers.serialization import get_builtin_layer\n \n\n@@ -52,6 +52,7 @@ from keras.layers.preprocessing import integer_lookup\n from keras.layers.preprocessing import normalization as preprocessing_normalization\n from keras.layers.preprocessing import string_lookup\n from keras.layers.preprocessing import text_vectorization\n+from keras.saving.saved_model import json_utils\n from keras.utils import generic_utils\n from keras.utils import tf_inspect as inspect\n from tensorflow.python.util.tf_export import keras_export\n@@ -217,3 +218,13 @@ def get_builtin_layer(class_name):\n   if not hasattr(LOCAL, 'ALL_OBJECTS'):\n     populate_deserializable_objects()\n   return LOCAL.ALL_OBJECTS.get(class_name)\n+\n+\n+def deserialize_from_json(json_string, custom_objects=None):\n+  \"\"\"Instantiates a layer from a JSON string.\"\"\"\n+  populate_deserializable_objects()\n+  config = json_utils.decode_and_deserialize(\n+      json_string,\n+      module_objects=LOCAL.ALL_OBJECTS,\n+      custom_objects=custom_objects)\n+  return deserialize(config, custom_objects)\n\n@@ -15,7 +15,6 @@\n # pylint: disable=protected-access\n \"\"\"Functions that save the model's config into different formats.\"\"\"\n \n-from keras.saving.saved_model import json_utils\n from tensorflow.python.util.tf_export import keras_export\n \n \n@@ -99,6 +98,5 @@ def model_from_json(json_string, custom_objects=None):\n   Returns:\n       A Keras model instance (uncompiled).\n   \"\"\"\n-  config = json_utils.decode(json_string)\n-  from keras.layers import deserialize  # pylint: disable=g-import-not-at-top\n-  return deserialize(config, custom_objects=custom_objects)\n+  from keras.layers import deserialize_from_json  # pylint: disable=g-import-not-at-top\n+  return deserialize_from_json(json_string, custom_objects=custom_objects)\n\n@@ -136,101 +136,6 @@ class TestSaveModel(tf.test.TestCase, parameterized.TestCase):\n     self.model.save_weights(path, save_format='h5')\n     self.model.load_weights(path)\n \n-  @combinations.generate(combinations.combine(mode=['graph', 'eager']))\n-  def test_saving_with_dense_features(self):\n-    cols = [\n-        tf.feature_column.numeric_column('a'),\n-        tf.feature_column.indicator_column(\n-            tf.feature_column.categorical_column_with_vocabulary_list(\n-                'b', ['one', 'two']))\n-    ]\n-    input_layers = {\n-        'a': keras.layers.Input(shape=(1,), name='a'),\n-        'b': keras.layers.Input(shape=(1,), name='b', dtype='string')\n-    }\n-\n-    fc_layer = dense_features.DenseFeatures(cols)(input_layers)\n-    output = keras.layers.Dense(10)(fc_layer)\n-\n-    model = keras.models.Model(input_layers, output)\n-\n-    model.compile(\n-        loss=keras.losses.MSE,\n-        optimizer='rmsprop',\n-        metrics=[keras.metrics.categorical_accuracy])\n-\n-    config = model.to_json()\n-    loaded_model = model_config.model_from_json(config)\n-\n-    inputs_a = np.arange(10).reshape(10, 1)\n-    inputs_b = np.arange(10).reshape(10, 1).astype('str')\n-\n-    with self.cached_session():\n-      # Initialize tables for V1 lookup.\n-      if not tf.executing_eagerly():\n-        self.evaluate(tf.compat.v1.tables_initializer())\n-\n-      self.assertLen(loaded_model.predict({'a': inputs_a, 'b': inputs_b}), 10)\n-\n-  @combinations.generate(combinations.combine(mode=['graph', 'eager']))\n-  def test_saving_with_sequence_features(self):\n-    cols = [\n-        tf.feature_column.sequence_numeric_column('a'),\n-        tf.feature_column.indicator_column(\n-            tf.feature_column.sequence_categorical_column_with_vocabulary_list(\n-                'b', ['one', 'two']))\n-    ]\n-    input_layers = {\n-        'a':\n-            keras.layers.Input(shape=(None, 1), sparse=True, name='a'),\n-        'b':\n-            keras.layers.Input(\n-                shape=(None, 1), sparse=True, name='b', dtype='string')\n-    }\n-\n-    fc_layer, _ = ksfc.SequenceFeatures(cols)(input_layers)\n-    # TODO(tibell): Figure out the right dtype and apply masking.\n-    # sequence_length_mask = array_ops.sequence_mask(sequence_length)\n-    # x = keras.layers.GRU(32)(fc_layer, mask=sequence_length_mask)\n-    x = keras.layers.GRU(32)(fc_layer)\n-    output = keras.layers.Dense(10)(x)\n-\n-    model = keras.models.Model(input_layers, output)\n-\n-    model.compile(\n-        loss=keras.losses.MSE,\n-        optimizer='rmsprop',\n-        metrics=[keras.metrics.categorical_accuracy])\n-\n-    config = model.to_json()\n-    loaded_model = model_config.model_from_json(config)\n-\n-    batch_size = 10\n-    timesteps = 1\n-\n-    values_a = np.arange(10, dtype=np.float32)\n-    indices_a = np.zeros((10, 3), dtype=np.int64)\n-    indices_a[:, 0] = np.arange(10)\n-    inputs_a = tf.SparseTensor(indices_a, values_a,\n-                                          (batch_size, timesteps, 1))\n-\n-    values_b = np.zeros(10, dtype=np.str)\n-    indices_b = np.zeros((10, 3), dtype=np.int64)\n-    indices_b[:, 0] = np.arange(10)\n-    inputs_b = tf.SparseTensor(indices_b, values_b,\n-                                          (batch_size, timesteps, 1))\n-\n-    with self.cached_session():\n-      # Initialize tables for V1 lookup.\n-      if not tf.executing_eagerly():\n-        self.evaluate(tf.compat.v1.tables_initializer())\n-\n-      self.assertLen(\n-          loaded_model.predict({\n-              'a': inputs_a,\n-              'b': inputs_b\n-          }, steps=1), batch_size)\n-\n   @combinations.generate(combinations.combine(mode=['graph', 'eager']))\n   def test_saving_h5_for_rnn_layers(self):\n     # See https://github.com/tensorflow/tensorflow/issues/35731 for details.\n@@ -364,6 +269,139 @@ class TestSaveModel(tf.test.TestCase, parameterized.TestCase):\n     self.assertEmpty(matched)\n \n \n+@generic_utils.register_keras_serializable(package='Foo')\n+class RegisteredSubLayer(keras.layers.Layer):\n+  pass\n+\n+\n+class TestJson(keras_parameterized.TestCase):\n+  \"\"\"Tests to_json()/from_json().\"\"\"\n+\n+  @combinations.generate(combinations.combine(mode=['graph', 'eager']))\n+  def test_saving_with_dense_features(self):\n+    cols = [\n+        tf.feature_column.numeric_column('a'),\n+        tf.feature_column.indicator_column(\n+            tf.feature_column.categorical_column_with_vocabulary_list(\n+                'b', ['one', 'two']))\n+    ]\n+    input_layers = {\n+        'a': keras.layers.Input(shape=(1,), name='a'),\n+        'b': keras.layers.Input(shape=(1,), name='b', dtype='string')\n+    }\n+\n+    fc_layer = dense_features.DenseFeatures(cols)(input_layers)\n+    output = keras.layers.Dense(10)(fc_layer)\n+\n+    model = keras.models.Model(input_layers, output)\n+\n+    model.compile(\n+        loss=keras.losses.MSE,\n+        optimizer='rmsprop',\n+        metrics=[keras.metrics.categorical_accuracy])\n+\n+    config = model.to_json()\n+    loaded_model = model_config.model_from_json(config)\n+\n+    inputs_a = np.arange(10).reshape(10, 1)\n+    inputs_b = np.arange(10).reshape(10, 1).astype('str')\n+\n+    with self.cached_session():\n+      # Initialize tables for V1 lookup.\n+      if not tf.executing_eagerly():\n+        self.evaluate(tf.compat.v1.tables_initializer())\n+\n+      self.assertLen(loaded_model.predict({'a': inputs_a, 'b': inputs_b}), 10)\n+\n+  @combinations.generate(combinations.combine(mode=['graph', 'eager']))\n+  def test_saving_with_sequence_features(self):\n+    cols = [\n+        tf.feature_column.sequence_numeric_column('a'),\n+        tf.feature_column.indicator_column(\n+            tf.feature_column.sequence_categorical_column_with_vocabulary_list(\n+                'b', ['one', 'two']))\n+    ]\n+    input_layers = {\n+        'a':\n+            keras.layers.Input(shape=(None, 1), sparse=True, name='a'),\n+        'b':\n+            keras.layers.Input(\n+                shape=(None, 1), sparse=True, name='b', dtype='string')\n+    }\n+\n+    fc_layer, _ = ksfc.SequenceFeatures(cols)(input_layers)\n+    # TODO(tibell): Figure out the right dtype and apply masking.\n+    # sequence_length_mask = array_ops.sequence_mask(sequence_length)\n+    # x = keras.layers.GRU(32)(fc_layer, mask=sequence_length_mask)\n+    x = keras.layers.GRU(32)(fc_layer)\n+    output = keras.layers.Dense(10)(x)\n+\n+    model = keras.models.Model(input_layers, output)\n+\n+    model.compile(\n+        loss=keras.losses.MSE,\n+        optimizer='rmsprop',\n+        metrics=[keras.metrics.categorical_accuracy])\n+\n+    config = model.to_json()\n+    loaded_model = model_config.model_from_json(config)\n+\n+    batch_size = 10\n+    timesteps = 1\n+\n+    values_a = np.arange(10, dtype=np.float32)\n+    indices_a = np.zeros((10, 3), dtype=np.int64)\n+    indices_a[:, 0] = np.arange(10)\n+    inputs_a = tf.SparseTensor(indices_a, values_a,\n+                               (batch_size, timesteps, 1))\n+\n+    values_b = np.zeros(10, dtype=np.str)\n+    indices_b = np.zeros((10, 3), dtype=np.int64)\n+    indices_b[:, 0] = np.arange(10)\n+    inputs_b = tf.SparseTensor(indices_b, values_b,\n+                               (batch_size, timesteps, 1))\n+\n+    with self.cached_session():\n+      # Initialize tables for V1 lookup.\n+      if not tf.executing_eagerly():\n+        self.evaluate(tf.compat.v1.tables_initializer())\n+\n+      self.assertLen(\n+          loaded_model.predict({\n+              'a': inputs_a,\n+              'b': inputs_b\n+          }, steps=1), batch_size)\n+\n+  @combinations.generate(combinations.combine(mode=['graph', 'eager']))\n+  def test_nested_layers(self):\n+\n+    class MyLayer(keras.layers.Layer):\n+\n+      def __init__(self, sublayers, **kwargs):\n+        super(MyLayer, self).__init__(**kwargs)\n+        self.sublayers = sublayers\n+\n+      def get_config(self):\n+        config = super(MyLayer, self).get_config()\n+        config['sublayers'] = self.sublayers\n+        return config\n+\n+    layer = MyLayer([keras.layers.Dense(2, name='MyDense'),\n+                     RegisteredSubLayer(name='MySubLayer')])\n+    model = keras.Sequential([keras.Input([None]), layer])\n+    model_json = model.to_json()\n+\n+    self.assertIn('Foo>RegisteredSubLayer', model_json)\n+\n+    loaded_model = model_config.model_from_json(\n+        model_json, custom_objects={'MyLayer': MyLayer})\n+    loaded_layer = loaded_model.layers[0]\n+    self.assertIsInstance(loaded_layer.sublayers[0], keras.layers.Dense)\n+    self.assertEqual(loaded_layer.sublayers[0].name, 'MyDense')\n+    self.assertIsInstance(loaded_layer.sublayers[1], RegisteredSubLayer)\n+    self.assertEqual(loaded_layer.sublayers[1].name, 'MySubLayer')\n+\n+\n @keras_parameterized.run_with_all_saved_model_formats\n class TestWholeModelSaving(keras_parameterized.TestCase):\n \n\n@@ -24,10 +24,15 @@ input if the given shape is a tuple.\n import tensorflow.compat.v2 as tf\n \n import collections\n+import functools\n import enum\n import json\n import numpy as np\n import wrapt\n+\n+from keras.utils import generic_utils\n+\n+# pylint: disable=g-direct-tensorflow-import\n from tensorflow.python.framework import type_spec\n \n \n@@ -61,8 +66,33 @@ def decode(json_string):\n   return json.loads(json_string, object_hook=_decode_helper)\n \n \n-def _decode_helper(obj):\n-  \"\"\"A decoding helper that is TF-object aware.\"\"\"\n+def decode_and_deserialize(json_string, module_objects=None,\n+                           custom_objects=None):\n+  \"\"\"Decodes the JSON and deserializes any Keras objects found in the dict.\"\"\"\n+  return json.loads(json_string,\n+                    object_hook=functools.partial(\n+                        _decode_helper,\n+                        deserialize=True,\n+                        module_objects=module_objects,\n+                        custom_objects=custom_objects))\n+\n+\n+def _decode_helper(obj, deserialize=False, module_objects=None,\n+                   custom_objects=None):\n+  \"\"\"A decoding helper that is TF-object aware.\n+\n+  Args:\n+    obj: A decoded dictionary that may represent an object.\n+    deserialize: Boolean, defaults to False. When True, deserializes any Keras\n+      objects found in `obj`.\n+    module_objects: A dictionary of built-in objects to look the name up in.\n+      Generally, `module_objects` is provided by midlevel library implementers.\n+    custom_objects: A dictionary of custom objects to look the name up in.\n+      Generally, `custom_objects` is provided by the end user.\n+\n+  Returns:\n+    The decoded object.\n+  \"\"\"\n   if isinstance(obj, dict) and 'class_name' in obj:\n     if obj['class_name'] == 'TensorShape':\n       return tf.TensorShape(obj['items'])\n@@ -73,6 +103,16 @@ def _decode_helper(obj):\n       return tuple(_decode_helper(i) for i in obj['items'])\n     elif obj['class_name'] == '__ellipsis__':\n       return Ellipsis\n+    elif deserialize and '__passive_serialization__' in obj:\n+      # __passive_serialization__ is added by the JSON encoder when encoding\n+      # an object that has a `get_config()` method.\n+      try:\n+        return generic_utils.deserialize_keras_object(\n+            obj,\n+            module_objects=module_objects,\n+            custom_objects=custom_objects)\n+      except ValueError:\n+        pass\n   return obj\n \n \n@@ -91,7 +131,9 @@ def get_json_type(obj):\n   # if obj is a serializable Keras class instance\n   # e.g. optimizer, layer\n   if hasattr(obj, 'get_config'):\n-    return {'class_name': obj.__class__.__name__, 'config': obj.get_config()}\n+    serialized = generic_utils.serialize_keras_object(obj)\n+    serialized['__passive_serialization__'] = True\n+    return serialized\n \n   # if obj is any numpy type\n   if type(obj).__module__ == np.__name__:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#30d7bdbd63b2a8559ebae635087bab90503c196f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 13 | Churn Cumulative: 16475 | Contributors (this commit): 120 | Commits (past 90d): 16 | Contributors (cumulative): 120 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1609,7 +1609,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n           generators, or `keras.utils.Sequence` instances (since they generate\n           batches).\n         verbose: `\"auto\"`, 0, 1, or 2. Verbosity mode.\n-            0 = silent, 1 = progress bar, 2 = one line per epoch.\n+            0 = silent, 1 = progress bar, 2 = single line.\n             `\"auto\"` defaults to 1 for most cases, and to 2 when used with\n             `ParameterServerStrategy`. Note that the progress bar is not\n             particularly useful when logged to a file, so `verbose=2` is\n@@ -1829,7 +1829,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n   def predict(self,\n               x,\n               batch_size=None,\n-              verbose=0,\n+              verbose='auto',\n               steps=None,\n               callbacks=None,\n               max_queue_size=10,\n@@ -1876,7 +1876,13 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n             Do not specify the `batch_size` if your data is in the\n             form of dataset, generators, or `keras.utils.Sequence` instances\n             (since they generate batches).\n-        verbose: Verbosity mode, 0 or 1.\n+        verbose: `\"auto\"`, 0, 1, or 2. Verbosity mode.\n+            0 = silent, 1 = progress bar, 2 = single line.\n+            `\"auto\"` defaults to 1 for most cases, and to 2 when used with\n+            `ParameterServerStrategy`. Note that the progress bar is not\n+            particularly useful when logged to a file, so `verbose=2` is\n+            recommended when not running interactively (e.g. in a production\n+            environment).\n         steps: Total number of steps (batches of samples)\n             before declaring the prediction round finished.\n             Ignored with the default value of `None`. If x is a `tf.data`\n@@ -1933,6 +1939,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     if self._cluster_coordinator:\n       self._cluster_coordinator = None\n \n+    verbose = _get_verbosity(verbose, self.distribute_strategy)\n     outputs = None\n     with self.distribute_strategy.scope():\n       # Creates a `tf.data.Dataset` and handles batch and epoch iteration.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ba6fddb32d20ccd0759c90d19978b02da6568fe7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 19 | Lines Deleted: 12 | Files Changed: 2 | Hunks: 14 | Methods Changed: 4 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 31 | Churn Cumulative: 20905 | Contributors (this commit): 123 | Commits (past 90d): 29 | Contributors (cumulative): 132 | DMM Complexity: 0.0\n\nDIFF:\n@@ -14,15 +14,13 @@\n # ==============================================================================\n \"\"\"Training-related part of the Keras engine.\"\"\"\n \n-import tensorflow.compat.v2 as tf\n-\n import copy\n import itertools\n import json\n import os\n import warnings\n import weakref\n-from tensorflow.python.eager import context\n+\n from keras import backend\n from keras import callbacks as callbacks_module\n from keras import optimizer_v1\n@@ -36,25 +34,26 @@ from keras.mixed_precision import loss_scale_optimizer as lso\n from keras.mixed_precision import policy\n from keras.optimizer_experimental import optimizer as optimizer_experimental\n from keras.saving import hdf5_format\n+from keras.saving import pickle_utils\n from keras.saving import save\n from keras.saving import saving_utils\n-from keras.saving import pickle_utils\n from keras.saving.saved_model import json_utils\n from keras.saving.saved_model import model_serialization\n from keras.utils import generic_utils\n+from keras.utils import io_utils\n from keras.utils import layer_utils\n from keras.utils import object_identity\n from keras.utils import tf_utils\n from keras.utils import traceback_utils\n from keras.utils import version_utils\n-from keras.utils.io_utils import ask_to_proceed_with_overwrite\n-from keras.utils.io_utils import path_to_string\n from keras.utils.mode_keys import ModeKeys\n+import tensorflow.compat.v2 as tf\n+\n+from tensorflow.python.eager import context\n from tensorflow.python.platform import tf_logging as logging\n from tensorflow.python.util.tf_export import keras_export\n from tensorflow.tools.docs import doc_controls\n \n-\n # pylint: disable=g-import-not-at-top\n try:\n   import h5py\n@@ -2460,7 +2459,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n             format.\n     \"\"\"\n     self._assert_weights_created()\n-    filepath = path_to_string(filepath)\n+    filepath = io_utils.path_to_string(filepath)\n     filepath_is_h5 = saving_utils.is_hdf5_filepath(filepath)\n     if save_format is None:\n       if filepath_is_h5:\n@@ -2493,7 +2492,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n       check_filepath = filepath\n     # If file exists and should not be overwritten:\n     if not overwrite and os.path.isfile(check_filepath):\n-      proceed = ask_to_proceed_with_overwrite(check_filepath)\n+      proceed = io_utils.ask_to_proceed_with_overwrite(check_filepath)\n       if not proceed:\n         return\n     if save_format == 'h5':\n@@ -3205,8 +3204,10 @@ def _get_verbosity(verbose, distribute_strategy):\n         '`verbose=1` is not allowed with `ParameterServerStrategy` for '\n         f'performance reasons. Received: verbose={verbose}')\n   if verbose == 'auto':\n-    if distribute_strategy._should_use_with_coordinator:  # pylint: disable=protected-access\n-      return 2  # Default to epoch-level logging for PSStrategy.\n+    if (distribute_strategy._should_use_with_coordinator or  # pylint: disable=protected-access\n+        not io_utils.is_interactive_logging_enabled()):\n+      # Default to epoch-level logging for PSStrategy or using absl logging.\n+      return 2\n     else:\n       return 1  # Default to batch-level logging otherwise.\n   return verbose\n@@ -3297,7 +3298,7 @@ def _disallow_inside_tf_function(method_name):\n def _detect_save_format(filepath):\n   \"\"\"Returns path to weights file and save format.\"\"\"\n \n-  filepath = path_to_string(filepath)\n+  filepath = io_utils.path_to_string(filepath)\n   if saving_utils.is_hdf5_filepath(filepath):\n     return filepath, 'h5'\n \n\n@@ -1864,12 +1864,18 @@ class TrainingTest(keras_parameterized.TestCase):\n         self._should_use_with_coordinator = True\n     with self.assertRaisesRegex(ValueError, '`verbose=1` is not allowed'):\n       training_module._get_verbosity(1, MyStrategy())\n+\n+    io_utils.enable_interactive_logging()\n     self.assertEqual(training_module._get_verbosity('auto', MyStrategy()), 2)\n     self.assertEqual(training_module._get_verbosity(\n         'auto', tf.distribute.MirroredStrategy()), 1)\n     self.assertEqual(training_module._get_verbosity(\n         2, tf.distribute.MirroredStrategy()), 2)\n \n+    io_utils.disable_interactive_logging()\n+    self.assertEqual(training_module._get_verbosity(\n+        'auto', tf.distribute.MirroredStrategy()), 2)\n+\n \n class TestExceptionsAndWarnings(keras_parameterized.TestCase):\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d936758eeec90dc71a56c4431a09ba831c7ef04c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 19 | Files Changed: 2 | Hunks: 14 | Methods Changed: 4 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 31 | Churn Cumulative: 20936 | Contributors (this commit): 123 | Commits (past 90d): 31 | Contributors (cumulative): 132 | DMM Complexity: 1.0\n\nDIFF:\n@@ -14,13 +14,15 @@\n # ==============================================================================\n \"\"\"Training-related part of the Keras engine.\"\"\"\n \n+import tensorflow.compat.v2 as tf\n+\n import copy\n import itertools\n import json\n import os\n import warnings\n import weakref\n-\n+from tensorflow.python.eager import context\n from keras import backend\n from keras import callbacks as callbacks_module\n from keras import optimizer_v1\n@@ -34,26 +36,25 @@ from keras.mixed_precision import loss_scale_optimizer as lso\n from keras.mixed_precision import policy\n from keras.optimizer_experimental import optimizer as optimizer_experimental\n from keras.saving import hdf5_format\n-from keras.saving import pickle_utils\n from keras.saving import save\n from keras.saving import saving_utils\n+from keras.saving import pickle_utils\n from keras.saving.saved_model import json_utils\n from keras.saving.saved_model import model_serialization\n from keras.utils import generic_utils\n-from keras.utils import io_utils\n from keras.utils import layer_utils\n from keras.utils import object_identity\n from keras.utils import tf_utils\n from keras.utils import traceback_utils\n from keras.utils import version_utils\n+from keras.utils.io_utils import ask_to_proceed_with_overwrite\n+from keras.utils.io_utils import path_to_string\n from keras.utils.mode_keys import ModeKeys\n-import tensorflow.compat.v2 as tf\n-\n-from tensorflow.python.eager import context\n from tensorflow.python.platform import tf_logging as logging\n from tensorflow.python.util.tf_export import keras_export\n from tensorflow.tools.docs import doc_controls\n \n+\n # pylint: disable=g-import-not-at-top\n try:\n   import h5py\n@@ -2459,7 +2460,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n             format.\n     \"\"\"\n     self._assert_weights_created()\n-    filepath = io_utils.path_to_string(filepath)\n+    filepath = path_to_string(filepath)\n     filepath_is_h5 = saving_utils.is_hdf5_filepath(filepath)\n     if save_format is None:\n       if filepath_is_h5:\n@@ -2492,7 +2493,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n       check_filepath = filepath\n     # If file exists and should not be overwritten:\n     if not overwrite and os.path.isfile(check_filepath):\n-      proceed = io_utils.ask_to_proceed_with_overwrite(check_filepath)\n+      proceed = ask_to_proceed_with_overwrite(check_filepath)\n       if not proceed:\n         return\n     if save_format == 'h5':\n@@ -3204,10 +3205,8 @@ def _get_verbosity(verbose, distribute_strategy):\n         '`verbose=1` is not allowed with `ParameterServerStrategy` for '\n         f'performance reasons. Received: verbose={verbose}')\n   if verbose == 'auto':\n-    if (distribute_strategy._should_use_with_coordinator or  # pylint: disable=protected-access\n-        not io_utils.is_interactive_logging_enabled()):\n-      # Default to epoch-level logging for PSStrategy or using absl logging.\n-      return 2\n+    if distribute_strategy._should_use_with_coordinator:  # pylint: disable=protected-access\n+      return 2  # Default to epoch-level logging for PSStrategy.\n     else:\n       return 1  # Default to batch-level logging otherwise.\n   return verbose\n@@ -3298,7 +3297,7 @@ def _disallow_inside_tf_function(method_name):\n def _detect_save_format(filepath):\n   \"\"\"Returns path to weights file and save format.\"\"\"\n \n-  filepath = io_utils.path_to_string(filepath)\n+  filepath = path_to_string(filepath)\n   if saving_utils.is_hdf5_filepath(filepath):\n     return filepath, 'h5'\n \n\n@@ -1864,18 +1864,12 @@ class TrainingTest(keras_parameterized.TestCase):\n         self._should_use_with_coordinator = True\n     with self.assertRaisesRegex(ValueError, '`verbose=1` is not allowed'):\n       training_module._get_verbosity(1, MyStrategy())\n-\n-    io_utils.enable_interactive_logging()\n     self.assertEqual(training_module._get_verbosity('auto', MyStrategy()), 2)\n     self.assertEqual(training_module._get_verbosity(\n         'auto', tf.distribute.MirroredStrategy()), 1)\n     self.assertEqual(training_module._get_verbosity(\n         2, tf.distribute.MirroredStrategy()), 2)\n \n-    io_utils.disable_interactive_logging()\n-    self.assertEqual(training_module._get_verbosity(\n-        'auto', tf.distribute.MirroredStrategy()), 2)\n-\n \n class TestExceptionsAndWarnings(keras_parameterized.TestCase):\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
