{"custom_id": "keras#672028a5f2712f8f65b4d97c617a25d81972775e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 1138 | Contributors (this commit): 15 | Commits (past 90d): 8 | Contributors (cumulative): 15 | DMM Complexity: None\n\nDIFF:\n@@ -387,7 +387,7 @@ def process_class_docstring(docstring):\n                        r'\\n    __\\1__\\n\\n',\n                        docstring)\n \n-    docstring = re.sub(r'    ([^\\s\\\\]+):(.*)\\n',\n+    docstring = re.sub(r'    ([^\\s\\\\\\(]+):(.*)\\n',\n                        r'    - __\\1__:\\2\\n',\n                        docstring)\n \n@@ -405,7 +405,7 @@ def process_function_docstring(docstring):\n                        r'\\n        __\\1__\\n\\n',\n                        docstring)\n \n-    docstring = re.sub(r'    ([^\\s\\\\]+):(.*)\\n',\n+    docstring = re.sub(r'    ([^\\s\\\\\\(]+):(.*)\\n',\n                        r'    - __\\1__:\\2\\n',\n                        docstring)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2766074d19a545acc53ae3b73d48510535397697", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 22 | Lines Deleted: 7 | Files Changed: 2 | Hunks: 5 | Methods Changed: 3 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 29 | Churn Cumulative: 1171 | Contributors (this commit): 8 | Commits (past 90d): 19 | Contributors (cumulative): 10 | DMM Complexity: 0.0\n\nDIFF:\n@@ -105,7 +105,8 @@ class ConvRecurrent2D(Recurrent):\n         self.return_sequences = return_sequences\n         self.go_backwards = go_backwards\n         self.stateful = stateful\n-        self.input_spec = InputSpec(ndim=5)\n+        self.input_spec = [InputSpec(ndim=5)]\n+        self.state_spec = None\n \n     def compute_output_shape(self, input_shape):\n         if self.data_format == 'channels_first':\n@@ -330,9 +331,10 @@ class ConvLSTM2D(ConvRecurrent2D):\n         self.recurrent_dropout = min(1., max(0., recurrent_dropout))\n \n     def build(self, input_shape):\n-        # TODO: better handling of input spec\n-        self.input_spec = InputSpec(shape=input_shape)\n-\n+        if isinstance(input_shape, list):\n+            input_shape = input_shape[0]\n+        batch_size = input_shape[0] if self.stateful else None\n+        self.input_spec[0] = InputSpec(shape=(batch_size,) + input_shape[1:])\n         if self.stateful:\n             self.reset_states()\n         else:\n@@ -413,7 +415,7 @@ class ConvLSTM2D(ConvRecurrent2D):\n     def reset_states(self):\n         if not self.stateful:\n             raise RuntimeError('Layer must be stateful.')\n-        input_shape = self.input_spec.shape\n+        input_shape = self.input_spec[0].shape\n         output_shape = self.compute_output_shape(input_shape)\n         if not input_shape[0]:\n             raise ValueError('If a RNN is stateful, a complete '\n\n@@ -3,8 +3,8 @@ import numpy as np\n from numpy.testing import assert_allclose\n \n from keras import backend as K\n-from keras.models import Sequential\n-from keras.layers import convolutional_recurrent\n+from keras.models import Sequential, Model\n+from keras.layers import convolutional_recurrent, Input\n from keras.utils.test_utils import layer_test\n from keras import regularizers\n \n@@ -116,5 +116,18 @@ def test_convolutional_recurrent():\n                                'recurrent_dropout': 0.1},\n                        input_shape=inputs.shape)\n \n+            # check state initialization\n+            layer = convolutional_recurrent.ConvLSTM2D(filters=filters,\n+                                                       kernel_size=(num_row, num_col),\n+                                                       data_format=data_format,\n+                                                       return_sequences=return_sequences)\n+            layer.build(inputs.shape)\n+            x = Input(batch_shape=inputs.shape)\n+            initial_state = layer.get_initial_state(x)\n+            y = layer(x, initial_state=initial_state)\n+            model = Model(x, y)\n+            assert model.predict(inputs).shape == layer.compute_output_shape(inputs.shape)\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6642d496e509e780f70c33d8cd1a802b94f6b587", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 4 | Churn Cumulative: 7728 | Contributors (this commit): 43 | Commits (past 90d): 49 | Contributors (cumulative): 48 | DMM Complexity: 0.0\n\nDIFF:\n@@ -334,7 +334,7 @@ class ConvLSTM2D(ConvRecurrent2D):\n         if isinstance(input_shape, list):\n             input_shape = input_shape[0]\n         batch_size = input_shape[0] if self.stateful else None\n-        self.input_spec[0] = InputSpec(shape=(batch_size,) + input_shape[1:])\n+        self.input_spec[0] = InputSpec(shape=(batch_size, None) + input_shape[2:])\n         if self.stateful:\n             self.reset_states()\n         else:\n\n@@ -256,6 +256,8 @@ class Recurrent(Layer):\n             # Compute the full input spec, including state\n             input_spec = self.input_spec\n             state_spec = self.state_spec\n+            if not isinstance(input_spec, list):\n+                input_spec = [input_spec]\n             if not isinstance(state_spec, list):\n                 state_spec = [state_spec]\n             self.input_spec = input_spec + state_spec\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#737ae88a02230e2af8f1517d71630550b9f7b68f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 436 | Contributors (this commit): 9 | Commits (past 90d): 4 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -11,6 +11,7 @@ import sys\n import numpy as np\n from six.moves import range\n from six.moves import zip\n+from collections import OrderedDict\n import warnings\n \n if sys.version_info < (3,):\n@@ -92,7 +93,7 @@ class Tokenizer(object):\n         if kwargs:\n             raise TypeError('Unrecognized keyword arguments: ' + str(kwargs))\n \n-        self.word_counts = {}\n+        self.word_counts = OrderedDict()\n         self.word_docs = {}\n         self.filters = filters\n         self.split = split\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#08aa6ae5553320d53c976536c7c294329ebafd7c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 8 | Methods Changed: 4 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 25 | Churn Cumulative: 3559 | Contributors (this commit): 47 | Commits (past 90d): 23 | Contributors (cumulative): 58 | DMM Complexity: 0.26666666666666666\n\nDIFF:\n@@ -592,6 +592,8 @@ class TensorBoard(Callback):\n             write_graph is set to True.\n         write_grads: whether to visualize gradient histograms in TensorBoard.\n             `histogram_freq` must be greater than 0.\n+        batch_size: size of batch of inputs to feed to the network\n+            for histograms computation.\n         write_images: whether to write model weights to visualize as\n             image in TensorBoard.\n         embeddings_freq: frequency (in epochs) at which selected embedding\n@@ -607,6 +609,7 @@ class TensorBoard(Callback):\n \n     def __init__(self, log_dir='./logs',\n                  histogram_freq=0,\n+                 batch_size=32,\n                  write_graph=True,\n                  write_grads=False,\n                  write_images=False,\n@@ -626,6 +629,7 @@ class TensorBoard(Callback):\n         self.embeddings_freq = embeddings_freq\n         self.embeddings_layer_names = embeddings_layer_names\n         self.embeddings_metadata = embeddings_metadata or {}\n+        self.batch_size = batch_size\n \n     def set_model(self, model):\n         self.model = model\n@@ -725,8 +729,6 @@ class TensorBoard(Callback):\n \n         if self.validation_data and self.histogram_freq:\n             if epoch % self.histogram_freq == 0:\n-                # TODO: implement batched calls to sess.run\n-                # (current call will likely go OOM on GPU)\n \n                 val_data = self.validation_data\n                 tensors = (self.model.inputs +\n@@ -737,10 +739,21 @@ class TensorBoard(Callback):\n                     tensors += [K.learning_phase()]\n \n                 assert len(val_data) == len(tensors)\n-                feed_dict = dict(zip(tensors, val_data))\n+                val_size = val_data[0].shape[0]\n+                i = 0\n+                while i < val_size:\n+                    step = min(self.batch_size, val_size - i)\n+                    batch_val = []\n+                    batch_val.append(val_data[0][i:i + step])\n+                    batch_val.append(val_data[1][i:i + step])\n+                    batch_val.append(val_data[2][i:i + step])\n+                    if self.model.uses_learning_phase:\n+                        batch_val.append(val_data[3])\n+                    feed_dict = dict(zip(tensors, batch_val))\n                     result = self.sess.run([self.merged], feed_dict=feed_dict)\n                     summary_str = result[0]\n                     self.writer.add_summary(summary_str, epoch)\n+                    i += self.batch_size\n \n         if self.embeddings_freq and self.embeddings_logs:\n             if epoch % self.embeddings_freq == 0:\n\n@@ -318,7 +318,8 @@ def test_TensorBoard():\n                   metrics=['accuracy'])\n \n     tsb = callbacks.TensorBoard(log_dir=filepath, histogram_freq=1,\n-                                write_images=True, write_grads=True)\n+                                write_images=True, write_grads=True,\n+                                batch_size=5)\n     cbks = [tsb]\n \n     # fit with validation data\n@@ -381,7 +382,8 @@ def test_TensorBoard_convnet():\n                   optimizer='rmsprop',\n                   metrics=['accuracy'])\n     tsb = callbacks.TensorBoard(log_dir=filepath, histogram_freq=1,\n-                                write_images=True, write_grads=True)\n+                                write_images=True, write_grads=True,\n+                                batch_size=16)\n     cbks = [tsb]\n     model.summary()\n     history = model.fit(x_train, y_train, epochs=2, batch_size=16,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#504bded884bbfa33d2c563154389752e6aef1676", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 46 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 4 | Methods Changed: 4 | Complexity Δ (Sum/Max): 9/6 | Churn Δ: 46 | Churn Cumulative: 7917 | Contributors (this commit): 85 | Commits (past 90d): 67 | Contributors (cumulative): 105 | DMM Complexity: 0.9411764705882353\n\nDIFF:\n@@ -227,6 +227,21 @@ class BaseLogger(Callback):\n                     logs[k] = self.totals[k] / self.seen\n \n \n+class TerminateOnNaN(Callback):\n+    \"\"\"Callback that terminates training when a NaN loss is encountered.\"\"\"\n+\n+    def __init__(self):\n+        super(TerminateOnNaN, self).__init__()\n+\n+    def on_batch_end(self, batch, logs=None):\n+        logs = logs or {}\n+        loss = logs.get('loss')\n+        if loss is not None:\n+            if np.isnan(loss) or np.isinf(loss):\n+                print('Batch %d: Invalid loss, terminating training' % (batch))\n+                self.model.stop_training = True\n+\n+\n class ProgbarLogger(Callback):\n     \"\"\"Callback that prints metrics to stdout.\n \n\n@@ -1159,6 +1159,8 @@ class Model(Container):\n                     batch_logs[l] = o\n \n                 callbacks.on_batch_end(batch_index, batch_logs)\n+                if callback_model.stop_training:\n+                    break\n \n                 if batch_index == len(batches) - 1:  # Last batch.\n                     if do_validation:\n\n@@ -6,6 +6,7 @@ import pytest\n from csv import Sniffer\n import shutil\n from keras import optimizers\n+from keras import initializers\n from keras import callbacks\n from keras.models import Sequential\n from keras.layers.core import Dense, Dropout\n@@ -24,6 +25,34 @@ train_samples = 20\n test_samples = 20\n \n \n+@keras_test\n+def test_TerminateOnNaN():\n+    np.random.seed(1337)\n+    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,\n+                                                         num_test=test_samples,\n+                                                         input_shape=(input_dim,),\n+                                                         classification=True,\n+                                                         num_classes=num_class)\n+\n+    y_test = np_utils.to_categorical(y_test)\n+    y_train = np_utils.to_categorical(y_train)\n+    cbks = [callbacks.TerminateOnNaN()]\n+    model = Sequential()\n+    initializer = initializers.Constant(value=1e5)\n+    for _ in range(5):\n+        model.add(Dense(num_hidden, input_dim=input_dim, activation='relu',\n+                        kernel_initializer=initializer))\n+    model.add(Dense(num_class, activation='linear'))\n+    model.compile(loss='mean_squared_error',\n+                  optimizer='rmsprop')\n+\n+    history = model.fit(X_train, y_train, batch_size=batch_size,\n+                        validation_data=(X_test, y_test), callbacks=cbks, epochs=20)\n+    loss = history.history['loss']\n+    assert len(loss) == 1\n+    assert loss[0] == np.inf\n+\n+\n @keras_test\n def test_ModelCheckpoint():\n     np.random.seed(1337)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#24db6bfaaf8a692059223e283c04d5c98aae8a41", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 42 | Lines Deleted: 8 | Files Changed: 2 | Hunks: 11 | Methods Changed: 2 | Complexity Δ (Sum/Max): 12/12 | Churn Δ: 50 | Churn Cumulative: 10572 | Contributors (this commit): 43 | Commits (past 90d): 41 | Contributors (cumulative): 47 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1430,15 +1430,15 @@ class ZeroPadding3D(Layer):\n     def compute_output_shape(self, input_shape):\n         if self.data_format == 'channels_first':\n             if input_shape[2] is not None:\n-                dim1 = input_shape[2] + 2 * self.padding[0][0]\n+                dim1 = input_shape[2] + self.padding[0][0] + self.padding[0][1]\n             else:\n                 dim1 = None\n             if input_shape[3] is not None:\n-                dim2 = input_shape[3] + 2 * self.padding[1][0]\n+                dim2 = input_shape[3] + self.padding[1][0] + self.padding[1][1]\n             else:\n                 dim2 = None\n             if input_shape[4] is not None:\n-                dim3 = input_shape[4] + 2 * self.padding[2][0]\n+                dim3 = input_shape[4] + self.padding[2][0] + self.padding[2][1]\n             else:\n                 dim3 = None\n             return (input_shape[0],\n@@ -1448,15 +1448,15 @@ class ZeroPadding3D(Layer):\n                     dim3)\n         elif self.data_format == 'channels_last':\n             if input_shape[1] is not None:\n-                dim1 = input_shape[1] + 2 * self.padding[0][1]\n+                dim1 = input_shape[1] + self.padding[0][0] + self.padding[0][1]\n             else:\n                 dim1 = None\n             if input_shape[2] is not None:\n-                dim2 = input_shape[2] + 2 * self.padding[1][1]\n+                dim2 = input_shape[2] + self.padding[1][0] + self.padding[1][1]\n             else:\n                 dim2 = None\n             if input_shape[3] is not None:\n-                dim3 = input_shape[3] + 2 * self.padding[2][1]\n+                dim3 = input_shape[3] + self.padding[2][0] + self.padding[2][1]\n             else:\n                 dim3 = None\n             return (input_shape[0],\n\n@@ -494,20 +494,54 @@ def test_zero_padding_3d():\n                      stack_size))\n \n     # basic test\n+    for data_format in ['channels_first', 'channels_last']:\n         layer_test(convolutional.ZeroPadding3D,\n-               kwargs={'padding': (2, 2, 2)},\n+                   kwargs={'padding': (2, 2, 2), 'data_format': data_format},\n+                   input_shape=inputs.shape)\n+        layer_test(convolutional.ZeroPadding3D,\n+                   kwargs={'padding': ((1, 2), (3, 4), (0, 2)), 'data_format': data_format},\n                    input_shape=inputs.shape)\n \n         # correctness test\n-    layer = convolutional.ZeroPadding3D(padding=(2, 2, 2))\n+        layer = convolutional.ZeroPadding3D(padding=(2, 2, 2),\n+                                            data_format=data_format)\n         layer.build(inputs.shape)\n         output = layer(K.variable(inputs))\n         np_output = K.eval(output)\n+        if data_format == 'channels_last':\n             for offset in [0, 1, -1, -2]:\n                 assert_allclose(np_output[:, offset, :, :, :], 0.)\n                 assert_allclose(np_output[:, :, offset, :, :], 0.)\n                 assert_allclose(np_output[:, :, :, offset, :], 0.)\n             assert_allclose(np_output[:, 2:-2, 2:-2, 2:-2, :], 1.)\n+        elif data_format == 'channels_first':\n+            for offset in [0, 1, -1, -2]:\n+                assert_allclose(np_output[:, :, offset, :, :], 0.)\n+                assert_allclose(np_output[:, :, :, offset, :], 0.)\n+                assert_allclose(np_output[:, :, :, :, offset], 0.)\n+            assert_allclose(np_output[:, :, 2:-2, 2:-2, 2:-2], 1.)\n+\n+        layer = convolutional.ZeroPadding3D(padding=((1, 2), (3, 4), (0, 2)),\n+                                            data_format=data_format)\n+        layer.build(inputs.shape)\n+        output = layer(K.variable(inputs))\n+        np_output = K.eval(output)\n+        if data_format == 'channels_last':\n+            for dim1_offset in [0, -1, -2]:\n+                assert_allclose(np_output[:, dim1_offset, :, :, :], 0.)\n+            for dim2_offset in [0, 1, 2, -1, -2, -3, -4]:\n+                assert_allclose(np_output[:, :, dim2_offset, :, :], 0.)\n+            for dim3_offset in [-1, -2]:\n+                assert_allclose(np_output[:, :, :, dim3_offset, :], 0.)\n+            assert_allclose(np_output[:, 1:-2, 3:-4, 0:-2, :], 1.)\n+        elif data_format == 'channels_first':\n+            for dim1_offset in [0, -1, -2]:\n+                assert_allclose(np_output[:, :, dim1_offset, :, :], 0.)\n+            for dim2_offset in [0, 1, 2, -1, -2, -3, -4]:\n+                assert_allclose(np_output[:, :, :, dim2_offset, :], 0.)\n+            for dim3_offset in [-1, -2]:\n+                assert_allclose(np_output[:, :, :, :, dim3_offset], 0.)\n+            assert_allclose(np_output[:, :, 1:-2, 3:-4, 0:-2], 1.)\n \n \n @keras_test\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5f4f234f9b4b2edd78153a289cd6388a6330993d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 2661 | Contributors (this commit): 49 | Commits (past 90d): 18 | Contributors (cumulative): 49 | DMM Complexity: 1.0\n\nDIFF:\n@@ -482,7 +482,9 @@ class EarlyStopping(Callback):\n             self.min_delta *= -1\n \n     def on_train_begin(self, logs=None):\n-        self.wait = 0  # Allow instances to be re-used\n+        # Allow instances to be re-used\n+        self.wait = 0\n+        self.stopped_epoch = 0\n         self.best = np.Inf if self.monitor_op == np.less else -np.Inf\n \n     def on_epoch_end(self, epoch, logs=None):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e1773974275d77d9861ce4b3988d563c3119e3e4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 445 | Contributors (this commit): 5 | Commits (past 90d): 3 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -196,8 +196,8 @@ x = mask_input\n for layer in image_model.layers[1:]:\r\n     name = 'mask_%s' % layer.name\r\n     if 'conv' in layer.name:\r\n-        x = AveragePooling2D((3, 3), strides=(\r\n-            1, 1), name=name, border_mode='same')(x)\r\n+        x = AveragePooling2D((3, 3), padding='same', strides=(\r\n+            1, 1), name=name)(x)\r\n     elif 'pool' in layer.name:\r\n         x = AveragePooling2D((2, 2), name=name)(x)\r\n mask_model = Model(mask_input, x)\r\n@@ -238,6 +238,7 @@ def region_style_loss(style_image, target_image, style_mask, target_mask):\n         masked_target = K.permute_dimensions(\r\n             target_image, (2, 0, 1)) * target_mask\r\n         num_channels = K.shape(style_image)[-1]\r\n+    num_channels = K.cast(num_channels, dtype='float32')\r\n     s = gram_matrix(masked_style) / K.mean(style_mask) / num_channels\r\n     c = gram_matrix(masked_target) / K.mean(target_mask) / num_channels\r\n     return K.mean(K.square(s - c))\r\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a2dde60a2fac35475df2aa5cbf8f3ba2cecb352b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 9 | Files Changed: 2 | Hunks: 7 | Methods Changed: 3 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 19 | Churn Cumulative: 3626 | Contributors (this commit): 49 | Commits (past 90d): 28 | Contributors (cumulative): 61 | DMM Complexity: 1.0\n\nDIFF:\n@@ -706,8 +706,6 @@ class TensorBoard(Callback):\n             self.writer = tf.summary.FileWriter(self.log_dir)\n \n         if self.embeddings_freq:\n-            self.saver = tf.train.Saver()\n-\n             embeddings_layer_names = self.embeddings_layer_names\n \n             if not embeddings_layer_names:\n@@ -718,6 +716,8 @@ class TensorBoard(Callback):\n                           for layer in self.model.layers\n                           if layer.name in embeddings_layer_names}\n \n+            self.saver = tf.train.Saver(list(embeddings.values()))\n+\n             embeddings_metadata = {}\n \n             if not isinstance(self.embeddings_metadata, str):\n@@ -727,15 +727,13 @@ class TensorBoard(Callback):\n                                        for layer_name in embeddings.keys()}\n \n             config = projector.ProjectorConfig()\n-            self.embeddings_logs = []\n+            self.embeddings_ckpt_path = os.path.join(self.log_dir,\n+                                                     'keras_embedding.ckpt')\n \n             for layer_name, tensor in embeddings.items():\n                 embedding = config.embeddings.add()\n                 embedding.tensor_name = tensor.name\n \n-                self.embeddings_logs.append(os.path.join(self.log_dir,\n-                                                         layer_name + '.ckpt'))\n-\n                 if layer_name in embeddings_metadata:\n                     embedding.metadata_path = embeddings_metadata[layer_name]\n \n@@ -772,10 +770,11 @@ class TensorBoard(Callback):\n                     self.writer.add_summary(summary_str, epoch)\n                     i += self.batch_size\n \n-        if self.embeddings_freq and self.embeddings_logs:\n+        if self.embeddings_freq and self.embeddings_ckpt_path:\n             if epoch % self.embeddings_freq == 0:\n-                for log in self.embeddings_logs:\n-                    self.saver.save(self.sess, log, epoch)\n+                self.saver.save(self.sess,\n+                                self.embeddings_ckpt_path,\n+                                epoch)\n \n         for name, value in logs.items():\n             if name in ['batch', 'size']:\n\n@@ -348,6 +348,8 @@ def test_TensorBoard():\n \n     tsb = callbacks.TensorBoard(log_dir=filepath, histogram_freq=1,\n                                 write_images=True, write_grads=True,\n+                                embeddings_freq=1,\n+                                embeddings_layer_names=['dense_1'],\n                                 batch_size=5)\n     cbks = [tsb]\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d67cf89759a8113a075fcb9428a9681a8a7b46ec", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 98 | Lines Deleted: 31 | Files Changed: 6 | Hunks: 8 | Methods Changed: 5 | Complexity Δ (Sum/Max): 7/3 | Churn Δ: 129 | Churn Cumulative: 21468 | Contributors (this commit): 122 | Commits (past 90d): 150 | Contributors (cumulative): 204 | DMM Complexity: 0.7037037037037037\n\nDIFF:\n@@ -10,7 +10,6 @@ from .common import set_floatx\n from .common import cast_to_floatx\n from .common import image_data_format\n from .common import set_image_data_format\n-from .common import is_keras_tensor\n \n # Obtain Keras base dir path: either ~/.keras or /tmp.\n _keras_base_dir = os.path.expanduser('~')\n\n@@ -145,35 +145,6 @@ def set_image_data_format(data_format):\n     _IMAGE_DATA_FORMAT = str(data_format)\n \n \n-def is_keras_tensor(x):\n-    \"\"\"Returns whether `x` is a Keras tensor.\n-\n-    # Arguments\n-        x: a potential tensor.\n-\n-    # Returns\n-        A boolean: whether the argument is a Keras tensor.\n-\n-    # Examples\n-    ```python\n-        >>> from keras import backend as K\n-        >>> np_var = numpy.array([1, 2])\n-        >>> K.is_keras_tensor(np_var)\n-        False\n-        >>> keras_var = K.variable(np_var)\n-        >>> K.is_keras_tensor(keras_var)  # A variable is not a Tensor.\n-        False\n-        >>> keras_placeholder = K.placeholder(shape=(2, 4, 5))\n-        >>> K.is_keras_tensor(keras_placeholder)  # A placeholder is a Tensor.\n-        True\n-    ```\n-    \"\"\"\n-    if hasattr(x, '_keras_shape'):\n-        return True\n-    else:\n-        return False\n-\n-\n # Legacy methods\n \n def set_image_dim_ordering(dim_ordering):\n\n@@ -4,6 +4,7 @@ from tensorflow.python.ops import tensor_array_ops\n from tensorflow.python.ops import control_flow_ops\n from tensorflow.python.ops import functional_ops\n from tensorflow.python.ops import ctc_ops as ctc\n+from tensorflow.python.ops import variables\n \n from collections import defaultdict\n import numpy as np\n@@ -354,6 +355,42 @@ def constant(value, dtype=None, shape=None, name=None):\n     return tf.constant(value, dtype=dtype, shape=shape, name=name)\n \n \n+def is_keras_tensor(x):\n+    \"\"\"Returns whether `x` is a Keras tensor.\n+\n+    # Arguments\n+        x: a potential tensor.\n+\n+    # Returns\n+        A boolean: whether the argument is a Keras tensor.\n+\n+    # Raises\n+        ValueError: in case `x` is not a symbolic tensor.\n+\n+    # Examples\n+    ```python\n+        >>> from keras import backend as K\n+        >>> np_var = numpy.array([1, 2])\n+        >>> K.is_keras_tensor(np_var) # A numpy array is not a symbolic yensor.\n+        ValueError\n+        >>> k_var = tf.placeholder('float32', shape=(1,1))\n+        >>> K.is_keras_tensor(k_var) # A variable created directly from tensorflow/theano is not a Keras tensor.\n+        False\n+        >>> keras_var = K.variable(np_var)\n+        >>> K.is_keras_tensor(keras_var)  # A variable created with the keras backend is a Keras tensor.\n+        True\n+        >>> keras_placeholder = K.placeholder(shape=(2, 4, 5))\n+        >>> K.is_keras_tensor(keras_placeholder)  # A placeholder is a Keras tensor.\n+        True\n+    ```\n+    \"\"\"\n+    if not isinstance(x, (tf.Tensor,\n+                          variables.Variable)):\n+        raise ValueError('Unexpectedly found an instance of type `' + str(type(x)) + '`. '\n+                         'Expected a symbolic tensor instance.')\n+    return hasattr(x, '_keras_history')\n+\n+\n def placeholder(shape=None, ndim=None, dtype=None, sparse=False, name=None):\n     \"\"\"Instantiates a placeholder tensor and returns it.\n \n\n@@ -164,6 +164,42 @@ def constant(value, dtype=None, shape=None, name=None):\n     return const\n \n \n+def is_keras_tensor(x):\n+    \"\"\"Returns whether `x` is a Keras tensor.\n+\n+    # Arguments\n+        x: a potential tensor.\n+\n+    # Returns\n+        A boolean: whether the argument is a Keras tensor.\n+\n+    # Raises\n+        ValueError: in case `x` is not a symbolic tensor.\n+\n+    # Examples\n+    ```python\n+        >>> from keras import backend as K\n+        >>> np_var = numpy.array([1, 2])\n+        >>> K.is_keras_tensor(np_var) # A numpy array is not a symbolic tensor.\n+        ValueError\n+        >>> k_var = theano.shared(value=np.array([1,2,3]))\n+        >>> K.is_keras_tensor(k_var) # A variable created directly from tensorflow/theano is not a Keras tensor.\n+        False\n+        >>> keras_var = K.variable(np_var)\n+        >>> K.is_keras_tensor(keras_var) # A variable created with the keras backend is a Keras tensor.\n+        True\n+        >>> keras_placeholder = K.placeholder(shape=(2, 4, 5))\n+        >>> K.is_keras_tensor(keras_placeholder)  # A placeholder is a Keras tensor.\n+        True\n+    ```\n+    \"\"\"\n+    if not isinstance(x, (T.TensorVariable,\n+                          T.sharedvar.TensorSharedVariable)):\n+        raise ValueError('Unexpectedly found an instance of type `' + str(type(x)) + '`. '\n+                         'Expected a symbolic tensor instance.')\n+    return hasattr(x, '_keras_history')\n+\n+\n def placeholder(shape=None, ndim=None, dtype=None, sparse=False, name=None):\n     \"\"\"Instantiate an input data placeholder variable.\n     \"\"\"\n\n@@ -413,13 +413,22 @@ class Layer(object):\n             ValueError: in case of mismatch between\n                 the provided inputs and the expectations of the layer.\n         \"\"\"\n+        inputs = _to_list(inputs)\n+        for x in inputs:\n+            try:\n+                K.is_keras_tensor(x)\n+            except ValueError:\n+                raise ValueError('Layer ' + self.name + ' expects '\n+                                 'an input of a symbolic tensor but '\n+                                 'it received an instance of ' +\n+                                 str(type(x)) + \".\")\n+\n         if not self.input_spec:\n             return\n         if not isinstance(self.input_spec, (list, tuple)):\n             input_spec = _to_list(self.input_spec)\n         else:\n             input_spec = self.input_spec\n-        inputs = _to_list(inputs)\n         if len(inputs) != len(input_spec):\n             raise ValueError('Layer ' + self.name + ' expects ' +\n                              str(len(input_spec)) + ' inputs, '\n\n@@ -77,6 +77,21 @@ def check_composed_tensor_operations(first_function_name, first_function_args,\n \n class TestBackend(object):\n \n+    def test_is_keras_tensor(self):\n+        for K in [KTH, KTF]:\n+            np_var = np.array([1, 2])\n+            try:\n+                K.is_keras_tensor(np_var)\n+                assert True is False\n+            except ValueError:\n+                # This is the expected behavior\n+                continue\n+\n+            keras_var = K.variable(np_var)\n+            assert K.is_keras_tensor(keras_var) is True\n+            keras_placeholder = K.placeholder(shape=(2, 4, 5))\n+            assert K.is_keras_tensor(keras_placeholder) is True\n+\n     def test_linear_operations(self):\n         check_two_tensor_operation('dot', (4, 2), (2, 4))\n         check_two_tensor_operation('dot', (4, 2), (5, 2, 3))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bc9dbc5de0fec911ab8b6cae9696641da9c13d5c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 7915 | Contributors (this commit): 35 | Commits (past 90d): 57 | Contributors (cumulative): 35 | DMM Complexity: 0.0\n\nDIFF:\n@@ -418,10 +418,12 @@ class Layer(object):\n             try:\n                 K.is_keras_tensor(x)\n             except ValueError:\n-                raise ValueError('Layer ' + self.name + ' expects '\n-                                 'an input of a symbolic tensor but '\n-                                 'it received an instance of ' +\n-                                 str(type(x)) + \".\")\n+                raise ValueError('Layer ' + self.name + ' was called with '\n+                                 'an input that isn\\'t a symbolic tensor. '\n+                                 'Received type: ' +\n+                                 str(type(x)) + '. Full input: ' +\n+                                 str(inputs) + '. All inputs to the layer '\n+                                 'should be tensors.')\n \n         if not self.input_spec:\n             return\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6220e35ccd2dbcd852bbd07d12511af9f5a09e99", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 65 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 65 | Churn Cumulative: 65 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,65 @@\n+'''Tests for functions in io_utils.py.\n+'''\n+import os\n+import pytest\n+from keras.models import Sequential\n+from keras.layers import Dense\n+from keras.utils.io_utils import HDF5Matrix\n+import numpy as np\n+import warnings\n+import h5py\n+\n+\n+def create_dataset(h5_path='test.h5'):\n+    X = np.random.randn(200, 10).astype('float32')\n+    y = np.random.randint(0, 2, size=(200, 1))\n+    f = h5py.File(h5_path, 'w')\n+    # Creating dataset to store features\n+    X_dset = f.create_dataset('my_data', (200, 10), dtype='f')\n+    X_dset[:] = X\n+    # Creating dataset to store labels\n+    y_dset = f.create_dataset('my_labels', (200, 1), dtype='i')\n+    y_dset[:] = y\n+    f.close()\n+\n+\n+def test_io_utils():\n+    '''Tests the HDF5Matrix code using the sample from @jfsantos at\n+    https://gist.github.com/jfsantos/e2ef822c744357a4ed16ec0c885100a3\n+    '''\n+    h5_path = 'test.h5'\n+    create_dataset(h5_path)\n+\n+    # Instantiating HDF5Matrix for the training set, which is a slice of the first 150 elements\n+    X_train = HDF5Matrix(h5_path, 'my_data', start=0, end=150)\n+    y_train = HDF5Matrix(h5_path, 'my_labels', start=0, end=150)\n+\n+    # Likewise for the test set\n+    X_test = HDF5Matrix(h5_path, 'my_data', start=150, end=200)\n+    y_test = HDF5Matrix(h5_path, 'my_labels', start=150, end=200)\n+\n+    # HDF5Matrix behave more or less like Numpy matrices with regards to indexing\n+    assert y_train.shape == (150, 1), 'HDF5Matrix shape should match input array'\n+    # But they do not support negative indices, so don't try print(X_train[-1])\n+\n+    model = Sequential()\n+    model.add(Dense(64, input_shape=(10,), activation='relu'))\n+    model.add(Dense(1, activation='sigmoid'))\n+\n+    model.compile(loss='binary_crossentropy', optimizer='sgd')\n+\n+    # Note: you have to use shuffle='batch' or False with HDF5Matrix\n+    model.fit(X_train, y_train, batch_size=32, shuffle='batch', verbose=False)\n+    # test that evalutation and prediction don't crash and return reasonable results\n+    out_pred = model.predict(X_test, batch_size=32, verbose=False)\n+    out_eval = model.evaluate(X_test, y_test, batch_size=32, verbose=False)\n+\n+    assert out_pred.shape == (50, 1), 'Prediction shape does not match'\n+    assert out_eval.shape == (), 'Shape of evaluation does not match'\n+    assert out_eval > 0, 'Evaluation value does not meet criteria: {}'.format(out_eval)\n+\n+    os.remove(h5_path)\n+\n+\n+if __name__ == '__main__':\n+    pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0d27d903c295f00d16efaed7f596b3b974e38764", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 7 | Churn Cumulative: 1041 | Contributors (this commit): 8 | Commits (past 90d): 16 | Contributors (cumulative): 8 | DMM Complexity: 0.0\n\nDIFF:\n@@ -109,6 +109,8 @@ class ConvRecurrent2D(Recurrent):\n         self.state_spec = None\n \n     def compute_output_shape(self, input_shape):\n+        if type(input_shape) is list:\n+            input_shape = input_shape[0]\n         if self.data_format == 'channels_first':\n             rows = input_shape[3]\n             cols = input_shape[4]\n@@ -329,6 +331,7 @@ class ConvLSTM2D(ConvRecurrent2D):\n \n         self.dropout = min(1., max(0., dropout))\n         self.recurrent_dropout = min(1., max(0., recurrent_dropout))\n+        self.state_spec = [InputSpec(ndim=4), InputSpec(ndim=4)]\n \n     def build(self, input_shape):\n         if isinstance(input_shape, list):\n@@ -349,6 +352,10 @@ class ConvLSTM2D(ConvRecurrent2D):\n             raise ValueError('The channel dimension of the inputs '\n                              'should be defined. Found `None`.')\n         input_dim = input_shape[channel_axis]\n+        state_shape = [None] * 4\n+        state_shape[channel_axis] = input_dim\n+        state_shape = tuple(state_shape)\n+        self.state_spec = [InputSpec(shape=state_shape), InputSpec(shape=state_shape)]\n         kernel_shape = self.kernel_size + (input_dim, self.filters * 4)\n         self.kernel_shape = kernel_shape\n         recurrent_kernel_shape = self.kernel_size + (self.filters, self.filters * 4)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#13303663ffea668cbf903a1ab83fc33596e5a213", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 4 | Methods Changed: 6 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 2150 | Contributors (this commit): 26 | Commits (past 90d): 9 | Contributors (cumulative): 26 | DMM Complexity: None\n\nDIFF:\n@@ -443,7 +443,7 @@ class ImageDataGenerator(object):\n                              'Received arg: ', zoom_range)\n \n     def flow(self, x, y=None, batch_size=32, shuffle=True, seed=None,\n-             save_to_dir=None, save_prefix='', save_format='jpeg'):\n+             save_to_dir=None, save_prefix='', save_format='png'):\n         return NumpyArrayIterator(\n             x, y, self,\n             batch_size=batch_size,\n@@ -460,7 +460,7 @@ class ImageDataGenerator(object):\n                             batch_size=32, shuffle=True, seed=None,\n                             save_to_dir=None,\n                             save_prefix='',\n-                            save_format='jpeg',\n+                            save_format='png',\n                             follow_links=False):\n         return DirectoryIterator(\n             directory, self,\n@@ -752,7 +752,7 @@ class NumpyArrayIterator(Iterator):\n     def __init__(self, x, y, image_data_generator,\n                  batch_size=32, shuffle=False, seed=None,\n                  data_format=None,\n-                 save_to_dir=None, save_prefix='', save_format='jpeg'):\n+                 save_to_dir=None, save_prefix='', save_format='png'):\n         if y is not None and len(x) != len(y):\n             raise ValueError('X (images tensor) and y (labels) '\n                              'should have the same length. '\n@@ -860,7 +860,7 @@ class DirectoryIterator(Iterator):\n                  classes=None, class_mode='categorical',\n                  batch_size=32, shuffle=True, seed=None,\n                  data_format=None,\n-                 save_to_dir=None, save_prefix='', save_format='jpeg',\n+                 save_to_dir=None, save_prefix='', save_format='png',\n                  follow_links=False):\n         if data_format is None:\n             data_format = K.image_data_format()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ed9e8d2ff0f6ebd4119eaa9c234d65b86114f139", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 2155 | Contributors (this commit): 26 | Commits (past 90d): 10 | Contributors (cumulative): 26 | DMM Complexity: 0.0\n\nDIFF:\n@@ -346,6 +346,7 @@ class ImageDataGenerator(object):\n         featurewise_std_normalization: divide inputs by std of the dataset.\n         samplewise_std_normalization: divide each input by its std.\n         zca_whitening: apply ZCA whitening.\n+        zca_epsilon: epsilon for ZCA whitening. Default is 1e-6.\n         rotation_range: degrees (0 to 180).\n         width_shift_range: fraction of total width.\n         height_shift_range: fraction of total height.\n@@ -382,6 +383,7 @@ class ImageDataGenerator(object):\n                  featurewise_std_normalization=False,\n                  samplewise_std_normalization=False,\n                  zca_whitening=False,\n+                 zca_epsilon=1e-6,\n                  rotation_range=0.,\n                  width_shift_range=0.,\n                  height_shift_range=0.,\n@@ -402,6 +404,7 @@ class ImageDataGenerator(object):\n         self.featurewise_std_normalization = featurewise_std_normalization\n         self.samplewise_std_normalization = samplewise_std_normalization\n         self.zca_whitening = zca_whitening\n+        self.zca_epsilon = zca_epsilon\n         self.rotation_range = rotation_range\n         self.width_shift_range = width_shift_range\n         self.height_shift_range = height_shift_range\n@@ -671,7 +674,7 @@ class ImageDataGenerator(object):\n             flat_x = np.reshape(x, (x.shape[0], x.shape[1] * x.shape[2] * x.shape[3]))\n             sigma = np.dot(flat_x.T, flat_x) / flat_x.shape[0]\n             u, s, _ = linalg.svd(sigma)\n-            self.principal_components = np.dot(np.dot(u, np.diag(1. / np.sqrt(s + 10e-7))), u.T)\n+            self.principal_components = np.dot(np.dot(u, np.diag(1. / np.sqrt(s + self.zca_epsilon))), u.T)\n \n \n class Iterator(object):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7a3190de3bc40611a7f2967f1604ce9d9bbd4b22", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 7722 | Contributors (this commit): 75 | Commits (past 90d): 37 | Contributors (cumulative): 75 | DMM Complexity: None\n\nDIFF:\n@@ -1937,7 +1937,7 @@ def batch_flatten(x):\n \n \n def expand_dims(x, axis=-1):\n-    \"\"\"Adds a 1-sized dimension at index \"dim\".\n+    \"\"\"Adds a 1-sized dimension at index \"axis\".\n \n     # Arguments\n         x: A tensor or variable.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3061fcce608677578d2db72203171f9a42badb2a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 7724 | Contributors (this commit): 76 | Commits (past 90d): 38 | Contributors (cumulative): 76 | DMM Complexity: None\n\nDIFF:\n@@ -1944,7 +1944,7 @@ def expand_dims(x, axis=-1):\n         axis: Position where to add a new axis.\n \n     # Returns\n-        A tensor with expended dimensions.\n+        A tensor with expanded dimensions.\n     \"\"\"\n     return tf.expand_dims(x, axis)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b5490b20d23ed1ffd45d535f0799804d54308b09", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 36 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 5/5 | Churn Δ: 40 | Churn Cumulative: 9280 | Contributors (this commit): 36 | Commits (past 90d): 58 | Contributors (cumulative): 40 | DMM Complexity: 0.9130434782608695\n\nDIFF:\n@@ -1690,6 +1690,15 @@ class Container(Layer):\n             # If the depth is not set, the node has no outbound nodes (depth 0).\n             depth = nodes_depths.setdefault(node, 0)\n \n+            # Update the depth of the corresponding layer\n+            previous_depth = layers_depths.get(node.outbound_layer, 0)\n+            # If we've seen this layer before at a higher depth, we should use that depth instead\n+            # of the node depth.  This is necessary for shared layers that have inputs at different\n+            # depth levels in the graph.\n+            depth = max(depth, previous_depth)\n+            layers_depths[node.outbound_layer] = depth\n+            nodes_depths[node] = depth\n+\n             # Update the depth of inbound nodes.\n             for i in range(len(node.inbound_layers)):\n                 inbound_layer = node.inbound_layers[i]\n@@ -1698,10 +1707,6 @@ class Container(Layer):\n                 previous_depth = nodes_depths.get(inbound_node, 0)\n                 nodes_depths[inbound_node] = max(depth + 1, previous_depth)\n \n-            # Update the depth of the corresponding layer\n-            previous_depth = layers_depths.get(node.outbound_layer, 0)\n-            layers_depths[node.outbound_layer] = max(depth, previous_depth)\n-\n         # Build a dict {depth: list of nodes with this depth}\n         nodes_by_depth = {}\n         for node, depth in nodes_depths.items():\n\n@@ -577,5 +577,32 @@ def test_recursion_with_bn_and_loss():\n     model2.fit(x, y, verbose=0, epochs=1)\n \n \n+def test_shared_layer_depth_is_correct():\n+    # Basic outline here: we have a shared embedding layer, and two inputs that go through\n+    # different depths of computation in the graph before the final output.  We need the computed\n+    # depth of the input layers to be the same, because they both pass through the embedding layer\n+    # before anything else happens.  That's what we're testing.\n+    from keras.layers import Embedding, Input, Dense, Concatenate\n+    from keras.models import Model\n+    input1 = Input(shape=(10,), name=\"input1\")\n+    input2 = Input(shape=(10,), name=\"input2\")\n+    embedding_layer = Embedding(name=\"embedding\", input_dim=5, output_dim=10)\n+    embedded_input1 = embedding_layer(input1)\n+    embedded_input2 = embedding_layer(input2)\n+    transformed_input2 = Dense(6)(Dense(5)(Dense(3)(embedded_input2)))\n+    final_output = Dense(2)(Concatenate()([embedded_input1, transformed_input2]))\n+    model = Model(inputs=[input1, input2], outputs=final_output)\n+    input1_depth = -1\n+    input2_depth = -1\n+    for depth, layers in model.layers_by_depth.items():\n+        for layer in layers:\n+            if layer.name == 'input1':\n+                input1_depth = depth\n+            if layer.name == 'input2':\n+                input2_depth = depth\n+    assert input1_depth != -1\n+    assert input1_depth == input2_depth\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
