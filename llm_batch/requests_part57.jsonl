{"custom_id": "requests#def20cdb0cf1d4fcc3aa4cd3164602d6c4029ac3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 8 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): -4/0 | Churn Δ: 8 | Churn Cumulative: 9831 | Contributors (this commit): 98 | Commits (past 90d): 71 | Contributors (cumulative): 113 | DMM Complexity: 0.0\n\nDIFF:\n@@ -558,11 +558,6 @@ class Response(object):\n         except ValueError:\n             return None\n \n-    def iter_json(self):\n-        for line in self.iter_lines():\n-            if line: # filter out keep-alive new lines\n-                yield json.loads(line)\n-\n     @property\n     def links(self):\n         \"\"\"Returns the parsed header links of the response, if any.\"\"\"\n\n@@ -182,9 +182,6 @@ class Session(SessionRedirectMixin):\n     def __exit__(self, *args):\n         self.close()\n \n-    def close(self):\n-        pass\n-\n     def request(self, method, url,\n         params=None,\n         data=None,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#a776e7cb3e57e56a2d9974b730e6f5e7776751a4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 38 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 5 | Methods Changed: 3 | Complexity Δ (Sum/Max): 10/10 | Churn Δ: 43 | Churn Cumulative: 9874 | Contributors (this commit): 98 | Commits (past 90d): 73 | Contributors (cumulative): 113 | DMM Complexity: 0.0\n\nDIFF:\n@@ -257,7 +257,7 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n             pass\n \n         # Support for unicode domain names and paths.\n-        scheme, netloc, path, params, query, fragment = urlparse(url)\n+        scheme, netloc, path, _params, query, fragment = urlparse(url)\n \n         if not scheme:\n             raise MissingSchema(\"Invalid URL %r: No schema supplied\" % url)\n@@ -278,8 +278,8 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n                 netloc = netloc.encode('utf-8')\n             if isinstance(path, str):\n                 path = path.encode('utf-8')\n-            if isinstance(params, str):\n-                params = params.encode('utf-8')\n+            if isinstance(_params, str):\n+                _params = _params.encode('utf-8')\n             if isinstance(query, str):\n                 query = query.encode('utf-8')\n             if isinstance(fragment, str):\n@@ -292,7 +292,7 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n             else:\n                 query = enc_params\n \n-        url = requote_uri(urlunparse([scheme, netloc, path, params, query, fragment]))\n+        url = requote_uri(urlunparse([scheme, netloc, path, _params, query, fragment]))\n         self.url = url\n \n     def prepare_headers(self, headers):\n\n@@ -186,7 +186,7 @@ class Session(SessionRedirectMixin):\n         params=None,\n         data=None,\n         headers=None,\n-        cookies=None,\n+        cookies=None or {},\n         files=None,\n         auth=None,\n         timeout=None,\n@@ -198,6 +198,39 @@ class Session(SessionRedirectMixin):\n         verify=None,\n         cert=None):\n \n+\n+        # merge session cookies into passed-in ones\n+        dead_cookies = None\n+        # passed-in cookies must become a CookieJar:\n+        if not isinstance(cookies, cookielib.CookieJar):\n+            cookies = cookiejar_from_dict(cookies)\n+            # support unsetting cookies that have been passed in with None values\n+            # this is only meaningful when `cookies` is a dict ---\n+            # for a real CookieJar, the client should use session.cookies.clear()\n+            if cookies is not None:\n+                dead_cookies = [name for name in cookies if cookies[name] is None]\n+        # merge the session's cookies into the passed-in cookies:\n+        for cookie in self.cookies:\n+            cookies.set_cookie(cookie)\n+        # remove the unset cookies from the jar we'll be using with the current request\n+        # (but not from the session's own store of cookies):\n+        if dead_cookies is not None:\n+            for name in dead_cookies:\n+                remove_cookie_by_name(cookies, name)\n+\n+        # Merge local kwargs with session kwargs.\n+        for attr in self.__attrs__:\n+            # we already merged cookies:\n+            if attr == 'cookies':\n+                continue\n+\n+            session_val = getattr(self, attr, None)\n+            local_val = locals().get(attr)\n+            locals()[attr] = merge_kwargs(local_val, session_val)\n+\n+\n+        headers = merge_kwargs(headers, self.headers)\n+\n         req = Request()\n         req.method = method\n         req.url = url\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#4bad1285b695771154eb9d17f42d49cfd6419538", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 24 | Lines Deleted: 45 | Files Changed: 3 | Hunks: 20 | Methods Changed: 8 | Complexity Δ (Sum/Max): -7/0 | Churn Δ: 69 | Churn Cumulative: 3257 | Contributors (this commit): 39 | Commits (past 90d): 41 | Contributors (cumulative): 57 | DMM Complexity: 0.42857142857142855\n\nDIFF:\n@@ -29,7 +29,6 @@ def request(method, url, **kwargs):\n     :param timeout: (optional) Float describing the timeout of the request.\n     :param allow_redirects: (optional) Boolean. Set to True if POST/PUT/DELETE redirect following is allowed.\n     :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.\n-    :param return_response: (optional) If False, an un-sent Request object will returned.\n     :param verify: (optional) if ``True``, the SSL cert will be verified. A CA_BUNDLE path can also be provided.\n     :param prefetch: (optional) if ``True``, the response content will be immediately downloaded.\n     :param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, ('cert', 'key') pair.\n\n@@ -41,18 +41,13 @@ class MockRequest(object):\n         return urlparse(self._r.url).netloc\n \n     def get_origin_req_host(self):\n-        if self._r.response.history:\n-            r = self._r.response.history[0]\n-            return urlparse(r.url).netloc\n-        else:\n         return self.get_host()\n \n     def get_full_url(self):\n         return self._r.url\n \n     def is_unverifiable(self):\n-        # unverifiable == redirected\n-        return bool(self._r.response.history)\n+        return True\n \n     def has_header(self, name):\n         return name in self._r.headers or name in self._new_headers\n\n@@ -70,10 +70,14 @@ class SessionRedirectMixin(object):\n         # ((resp.status_code is codes.see_other))\n         while (('location' in resp.headers and resp.status_code in REDIRECT_STATI)):\n \n+            # Persist cookies.\n+            for cookie in resp.cookies:\n+                self.cookies.set_cookie(cookie)\n+\n             resp.content  # Consume socket so it can be released\n \n             if i > self.max_redirects:\n-                raise TooManyRedirects()\n+                raise TooManyRedirects('Exceeded %s redirects.' % self.max_redirects)\n \n             # Release the connection back into the pool.\n             resp.close()\n@@ -186,51 +190,38 @@ class Session(SessionRedirectMixin):\n         params=None,\n         data=None,\n         headers=None,\n-        cookies=None or {},\n+        cookies=None,\n         files=None,\n         auth=None,\n         timeout=None,\n         allow_redirects=True,\n         proxies=None,\n         hooks=None,\n-        return_response=True,\n         prefetch=None,\n         verify=None,\n         cert=None):\n \n+        cookies = cookies or {}\n \n-        # merge session cookies into passed-in ones\n-        dead_cookies = None\n-        # passed-in cookies must become a CookieJar:\n+        # Bootstrap CookieJar.\n         if not isinstance(cookies, cookielib.CookieJar):\n             cookies = cookiejar_from_dict(cookies)\n-            # support unsetting cookies that have been passed in with None values\n-            # this is only meaningful when `cookies` is a dict ---\n-            # for a real CookieJar, the client should use session.cookies.clear()\n-            if cookies is not None:\n-                dead_cookies = [name for name in cookies if cookies[name] is None]\n-        # merge the session's cookies into the passed-in cookies:\n+\n+        # Bubble down session cookies.\n         for cookie in self.cookies:\n             cookies.set_cookie(cookie)\n-        # remove the unset cookies from the jar we'll be using with the current request\n-        # (but not from the session's own store of cookies):\n-        if dead_cookies is not None:\n-            for name in dead_cookies:\n-                remove_cookie_by_name(cookies, name)\n-\n-        # Merge local kwargs with session kwargs.\n-        for attr in self.__attrs__:\n-            # we already merged cookies:\n-            if attr == 'cookies':\n-                continue\n-\n-            session_val = getattr(self, attr, None)\n-            local_val = locals().get(attr)\n-            locals()[attr] = merge_kwargs(local_val, session_val)\n-\n \n+        # Merge all the kwargs.\n+        params = merge_kwargs(params, self.params)\n         headers = merge_kwargs(headers, self.headers)\n+        auth = merge_kwargs(auth, self.auth)\n+        proxies = merge_kwargs(proxies, self.proxies)\n+        hooks = merge_kwargs(hooks, self.hooks)\n+        prefetch = merge_kwargs(prefetch, self.prefetch)\n+        verify = merge_kwargs(verify, self.verify)\n+        cert = merge_kwargs(cert, self.cert)\n \n+        # Create the Request.\n         req = Request()\n         req.method = method\n         req.url = url\n@@ -240,15 +231,12 @@ class Session(SessionRedirectMixin):\n         req.params = params\n         req.auth = auth\n         req.cookies = cookies\n-        # TODO: move to attached\n-        # req.allow_redirects = allow_redirects\n-        # req.proxies = proxies\n         req.hooks = hooks\n \n+        # Prepare the Request.\n         prep = req.prepare()\n \n-        # TODO: prepare cookies.\n-\n+        # Send the request.\n         resp = self.send(prep, prefetch=prefetch, timeout=timeout, verify=verify, cert=cert)\n \n         # Redirect resolving generator.\n@@ -268,9 +256,6 @@ class Session(SessionRedirectMixin):\n \n         return resp\n \n-\n-\n-\n     def get(self, url, **kwargs):\n         \"\"\"Sends a GET request. Returns :class:`Response` object.\n \n@@ -340,10 +325,10 @@ class Session(SessionRedirectMixin):\n \n         return self.request('DELETE', url, **kwargs)\n \n-    def send(self, request, prefetch=True, timeout=None, verify=True, cert=None):\n+    def send(self, request, **kwargs):\n         \"\"\"Send a given PreparedRequest.\"\"\"\n         adapter = HTTPAdapter()\n-        r = adapter.send(request, prefetch, timeout, verify, cert)\n+        r = adapter.send(request, **kwargs)\n         return r\n \n     def __getstate__(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#42b029552190f6639642d0f62d27abcd1ceed51e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 1656 | Contributors (this commit): 23 | Commits (past 90d): 24 | Contributors (cumulative): 23 | DMM Complexity: None\n\nDIFF:\n@@ -134,10 +134,6 @@ class SessionRedirectMixin(object):\n class Session(SessionRedirectMixin):\n     \"\"\"A Requests session.\"\"\"\n \n-    __attrs__ = [\n-        'headers', 'cookies', 'auth', 'timeout', 'proxies', 'hooks',\n-        'params', 'verify', 'cert', 'prefetch']\n-\n     def __init__(self):\n \n         #: A case-insensitive dictionary of headers to be sent on each\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#899c9a9522e963be6153da78937babf85b07857f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 11 | Churn Cumulative: 1667 | Contributors (this commit): 23 | Commits (past 90d): 25 | Contributors (cumulative): 23 | DMM Complexity: 0.0\n\nDIFF:\n@@ -108,15 +108,16 @@ class SessionRedirectMixin(object):\n                 method = 'GET'\n \n             # Remove the cookie headers that were sent.\n-            # headers = req.headers\n-            # try:\n-            #     del headers['Cookie']\n-            # except KeyError:\n-            #     pass\n+            headers = req.headers\n+            try:\n+                del headers['Cookie']\n+            except KeyError:\n+                pass\n \n             resp = self.request(\n                     url=url,\n                     method=method,\n+                    headers=headers,\n                     params=req.params,\n                     auth=req.auth,\n                     cookies=req.cookies,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#a75ba04eed165da54416e4b32f26a6bb566d8203", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 605 | Contributors (this commit): 1 | Commits (past 90d): 3 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -30,7 +30,6 @@\n         :param timeout: (optional) Float describing the timeout of the request.\n         :param allow_redirects: (optional) Boolean. Set to True by default.\n         :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.\n-        :param return_response: (optional) If False, an un-sent Request object will returned.\n         :param config: (optional) A configuration dictionary. See ``request.defaults`` for allowed keys and their default values.\n         :param prefetch: (optional) whether to immediately download the response content. Defaults to ``True``.\n         :param verify: (optional) if ``True``, the SSL cert will be verified. A CA_BUNDLE path can also be provided.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#a197309e214ad060cd5f084ab47f6d04f09cf68b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 8 | Churn Cumulative: 8291 | Contributors (this commit): 90 | Commits (past 90d): 52 | Contributors (cumulative): 90 | DMM Complexity: 0.0\n\nDIFF:\n@@ -9,12 +9,13 @@ This module contains the primary objects that power Requests.\n \n # import os\n # import socket\n+\n import collections\n import logging\n \n # from datetime import datetime\n from io import BytesIO\n-\n+from types import GeneratorType\n from .hooks import dispatch_hook, default_hooks\n from .structures import CaseInsensitiveDict\n from .status_codes import codes\n@@ -305,7 +306,10 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n \n     def prepare_body(self, data, files):\n         \"\"\"Prepares the given HTTP body data.\"\"\"\n-        # if a generator is provided, error out.\n+\n+        # If a generator is provided, error out.\n+        if isinstance(data, types.GeneratorType)\n+            raise NotImplementedError('Generator bodies are not supported yet.')\n \n         # Nottin' on you.\n         body = None\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#ca0d08eedaa9d0c79ccd9c69fedae89ed7812c53", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 21 | Lines Deleted: 17 | Files Changed: 2 | Hunks: 12 | Methods Changed: 7 | Complexity Δ (Sum/Max): 4/3 | Churn Δ: 38 | Churn Cumulative: 8584 | Contributors (this commit): 90 | Commits (past 90d): 65 | Contributors (cumulative): 91 | DMM Complexity: 1.0\n\nDIFF:\n@@ -12,8 +12,10 @@ import os\n import socket\n \n from .models import Response\n+from .auth import HTTPProxyAuth\n from .packages.urllib3.poolmanager import PoolManager\n from .hooks import dispatch_hook\n+from .compat import urlparse\n from .utils import DEFAULT_CA_BUNDLE_PATH, get_encoding_from_headers\n from .structures import CaseInsensitiveDict\n from .packages.urllib3.exceptions import MaxRetryError\n@@ -119,6 +121,19 @@ class HTTPAdapter(BaseAdapter):\n         response = dispatch_hook('response', req.hooks, response)\n         return response\n \n+    def get_connection(self, url, proxies=None):\n+        proxies = proxies or {}\n+        proxy = proxies.get(urlparse(url).scheme)\n+\n+        if proxy:\n+            conn = poolmanager.proxy_from_url(proxy)\n+        else:\n+            conn = self.poolmanager.connection_from_url(url)\n+\n+        return conn\n+        # no_proxy = filter(lambda x: x.strip(), self.proxies.get('no', '').split(','))\n+\n+\n \n     def close(self):\n         \"\"\"Dispose of any internal state.\n@@ -128,10 +143,11 @@ class HTTPAdapter(BaseAdapter):\n         \"\"\"\n         self.poolmanager.clear()\n \n-    def send(self, request, prefetch=True, timeout=None, verify=True, cert=None):\n+    def send(self, request, prefetch=True, timeout=None, verify=True, cert=None, proxies=None):\n         \"\"\"Sends PreparedRequest object. Returns Response object.\"\"\"\n \n-        conn = self.poolmanager.connection_from_url(request.url)\n+        conn = self.get_connection(request.url, proxies)\n+\n         self.cert_verify(conn, request.url, verify, cert)\n \n         try:\n\n@@ -15,20 +15,13 @@ import logging\n \n # from datetime import datetime\n from io import BytesIO\n-from types import GeneratorType\n from .hooks import dispatch_hook, default_hooks\n from .structures import CaseInsensitiveDict\n from .status_codes import codes\n \n from .auth import HTTPBasicAuth, HTTPProxyAuth\n from .cookies import cookiejar_from_dict, extract_cookies_to_jar, get_cookie_header\n-# from .packages.urllib3.exceptions import MaxRetryError, LocationParseError\n-# from .packages.urllib3.exceptions import TimeoutError\n-# from .packages.urllib3.exceptions import SSLError as _SSLError\n-# from .packages.urllib3.exceptions import HTTPError as _HTTPError\n-# from .packages.urllib3 import connectionpool, poolmanager\n from .packages.urllib3.filepost import encode_multipart_formdata\n-\n from .exceptions import (\n     ConnectionError, HTTPError, RequestException, Timeout, TooManyRedirects,\n     URLRequired, SSLError, MissingSchema, InvalidSchema, InvalidURL)\n@@ -43,6 +36,7 @@ from .compat import (\n \n REDIRECT_STATI = (codes.moved, codes.found, codes.other, codes.temporary_moved)\n CONTENT_CHUNK_SIZE = 10 * 1024\n+ITER_CHUNK_SIZE = 10 * 1024\n \n log = logging.getLogger(__name__)\n \n@@ -57,12 +51,6 @@ class RequestEncodingMixin(object):\n \n         p = urlsplit(self.url)\n \n-        # Proxies use full URLs.\n-        # if p.scheme in self.proxies:\n-            # url_base, frag = urldefrag(self.url)\n-            # return url_base\n-\n-\n         path = p.path\n         if not path:\n             path = '/'\n@@ -308,7 +296,7 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n         \"\"\"Prepares the given HTTP body data.\"\"\"\n \n         # If a generator is provided, error out.\n-        if isinstance(data, types.GeneratorType)\n+        if isinstance(data, type(_ for _ in [])):\n             raise NotImplementedError('Generator bodies are not supported yet.')\n \n         # Nottin' on you.\n@@ -457,7 +445,7 @@ class Response(object):\n \n         return gen\n \n-    def iter_lines(self, chunk_size=10 * 1024, decode_unicode=None):\n+    def iter_lines(self, chunk_size=ITER_CHUNK_SIZE, decode_unicode=None):\n         \"\"\"Iterates over the response data, one line at a time.  This\n         avoids reading the content at once into memory for large\n         responses.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#bc4af7c7e1b8895ac58633448a733eba8550e8d5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 276 | Contributors (this commit): 1 | Commits (past 90d): 13 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -122,6 +122,7 @@ class HTTPAdapter(BaseAdapter):\n         return response\n \n     def get_connection(self, url, proxies=None):\n+        \"\"\"Returns a connection for the given URL.\"\"\"\n         proxies = proxies or {}\n         proxy = proxies.get(urlparse(url).scheme)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#5b5d8a81b7094a4131e40da1eaf127fec341bfa0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 278 | Contributors (this commit): 1 | Commits (past 90d): 14 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -132,8 +132,6 @@ class HTTPAdapter(BaseAdapter):\n             conn = self.poolmanager.connection_from_url(url)\n \n         return conn\n-        # no_proxy = filter(lambda x: x.strip(), self.proxies.get('no', '').split(','))\n-\n \n \n     def close(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#4c3b9df6091b65d8c72763222bd5fdefb7231149", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 16 | Files Changed: 4 | Hunks: 13 | Methods Changed: 10 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 29 | Churn Cumulative: 11345 | Contributors (this commit): 101 | Commits (past 90d): 103 | Contributors (cumulative): 138 | DMM Complexity: 0.0\n\nDIFF:\n@@ -142,7 +142,7 @@ class HTTPAdapter(BaseAdapter):\n         \"\"\"\n         self.poolmanager.clear()\n \n-    def send(self, request, prefetch=True, timeout=None, verify=True, cert=None, proxies=None):\n+    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):\n         \"\"\"Sends PreparedRequest object. Returns Response object.\"\"\"\n \n         conn = self.get_connection(request.url, proxies)\n@@ -180,7 +180,7 @@ class HTTPAdapter(BaseAdapter):\n \n         r = self.build_response(request, resp)\n \n-        if prefetch:\n+        if not stream:\n             r.content\n \n         return r\n\n@@ -30,7 +30,7 @@ def request(method, url, **kwargs):\n     :param allow_redirects: (optional) Boolean. Set to True if POST/PUT/DELETE redirect following is allowed.\n     :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.\n     :param verify: (optional) if ``True``, the SSL cert will be verified. A CA_BUNDLE path can also be provided.\n-    :param prefetch: (optional) if ``True``, the response content will be immediately downloaded.\n+    :param stream: (optional) if ``False``, the response content will be immediately downloaded.\n     :param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, ('cert', 'key') pair.\n     \"\"\"\n \n\n@@ -378,7 +378,7 @@ class Response(object):\n         self.headers = CaseInsensitiveDict()\n \n         #: File-like object representation of response (for advanced usage).\n-        #: Requires that ``prefetch=False` on the request.\n+        #: Requires that ``stream=True` on the request.\n         # This requirement does not apply for use internally to Requests.\n         self.raw = None\n \n@@ -393,8 +393,6 @@ class Response(object):\n         #: up here. The list is sorted from the oldest to the most recent request.\n         self.history = []\n \n-        #: The :class:`Request <Request>` that created the Response.\n-        # self.request = None\n \n         self.reason = None\n \n@@ -513,8 +511,7 @@ class Response(object):\n \n         # Fallback to auto-detected encoding.\n         if self.encoding is None:\n-            if chardet is not None:\n-                encoding = chardet.detect(self.content)['encoding']\n+            encoding = self.apparent_encoding\n \n         # Decode unicode from given encoding.\n         try:\n\n@@ -62,7 +62,7 @@ def merge_kwargs(local_kwarg, default_kwarg):\n \n class SessionRedirectMixin(object):\n \n-    def resolve_redirects(self, resp, req, prefetch=True, timeout=None, verify=True, cert=None):\n+    def resolve_redirects(self, resp, req, stream=False, timeout=None, verify=True, cert=None):\n         \"\"\"Receives a Response. Returns a generator of Responses.\"\"\"\n \n         i = 0\n@@ -122,7 +122,7 @@ class SessionRedirectMixin(object):\n                     auth=req.auth,\n                     cookies=req.cookies,\n                     allow_redirects=False,\n-                    prefetch=prefetch,\n+                    stream=stream,\n                     timeout=timeout,\n                     verify=verify,\n                     cert=cert\n@@ -159,8 +159,8 @@ class Session(SessionRedirectMixin):\n         #: representing multivalued query parameters.\n         self.params = {}\n \n-        #: Prefetch response content.\n-        self.prefetch = True\n+        #: Stream response content.\n+        self.stream = False\n \n         #: SSL Verification.\n         self.verify = True\n@@ -194,7 +194,7 @@ class Session(SessionRedirectMixin):\n         allow_redirects=True,\n         proxies=None,\n         hooks=None,\n-        prefetch=None,\n+        stream=None,\n         verify=None,\n         cert=None):\n \n@@ -214,7 +214,7 @@ class Session(SessionRedirectMixin):\n         auth = merge_kwargs(auth, self.auth)\n         proxies = merge_kwargs(proxies, self.proxies)\n         hooks = merge_kwargs(hooks, self.hooks)\n-        prefetch = merge_kwargs(prefetch, self.prefetch)\n+        stream = merge_kwargs(stream, self.stream)\n         verify = merge_kwargs(verify, self.verify)\n         cert = merge_kwargs(cert, self.cert)\n \n@@ -234,10 +234,10 @@ class Session(SessionRedirectMixin):\n         prep = req.prepare()\n \n         # Send the request.\n-        resp = self.send(prep, prefetch=prefetch, timeout=timeout, verify=verify, cert=cert)\n+        resp = self.send(prep, stream=stream, timeout=timeout, verify=verify, cert=cert)\n \n         # Redirect resolving generator.\n-        gen = self.resolve_redirects(resp, req, prefetch, timeout, verify, cert)\n+        gen = self.resolve_redirects(resp, req, stream, timeout, verify, cert)\n \n         # Resolve redirects if allowed.\n         history = [r for r in gen] if allow_redirects else []\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#bc34f33955d7f71c82da18d109f278470d083dab", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 5 | Churn Cumulative: 8321 | Contributors (this commit): 90 | Commits (past 90d): 55 | Contributors (cumulative): 90 | DMM Complexity: 1.0\n\nDIFF:\n@@ -418,6 +418,11 @@ class Response(object):\n             return False\n         return True\n \n+    @property\n+    def apparent_encoding(self):\n+        \"\"\"The apparent encoding, provided by the lovely Charade library.\"\"\"\n+        return chardet.detect(self.content)['encoding']\n+\n     def iter_content(self, chunk_size=1, decode_unicode=False):\n         \"\"\"Iterates over the response data.  This avoids reading the content\n         at once into memory for large responses.  The chunk size is the number\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#d11522b29e3d05017c1464f13dd3be70c3ffd1a4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 21 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 4 | Methods Changed: 4 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 23 | Churn Cumulative: 1706 | Contributors (this commit): 23 | Commits (past 90d): 27 | Contributors (cumulative): 23 | DMM Complexity: 1.0\n\nDIFF:\n@@ -14,7 +14,7 @@ from .cookies import cookiejar_from_dict, remove_cookie_by_name\n from .models import Request\n from .hooks import dispatch_hook, default_hooks\n from .utils import header_expand, from_key_val_list, default_headers\n-from .exceptions import TooManyRedirects\n+from .exceptions import TooManyRedirects, InvalidSchema\n \n from .compat import urlparse, urljoin\n from .adapters import HTTPAdapter\n@@ -177,6 +177,11 @@ class Session(SessionRedirectMixin):\n         # Set up a CookieJar to be used by default\n         self.cookies = cookiejar_from_dict({})\n \n+        # Default connection adapters.\n+        self.adapters = {}\n+        self.mount('http://', HTTPAdapter())\n+        self.mount('https://', HTTPAdapter())\n+\n     def __enter__(self):\n         return self\n \n@@ -324,10 +329,24 @@ class Session(SessionRedirectMixin):\n \n     def send(self, request, **kwargs):\n         \"\"\"Send a given PreparedRequest.\"\"\"\n-        adapter = HTTPAdapter()\n+        adapter = self.get_adapter(url=request.url)\n         r = adapter.send(request, **kwargs)\n         return r\n \n+    def get_adapter(self, url):\n+        \"\"\"Returns the appropriate connnection adapter for the given URL.\"\"\"\n+        for (prefix, adapter) in self.adapters.items():\n+\n+            if url.startswith(prefix):\n+                return adapter\n+\n+        # Nothing matches :-/\n+        raise InvalidSchema('No connection adapters were found for \\'%s\\'' % url)\n+\n+    def mount(self, prefix, adapter):\n+        \"\"\"Registers a connection adapter to a prefix.\"\"\"\n+        self.adapters[prefix] = adapter\n+\n     def __getstate__(self):\n         return dict((attr, getattr(self, attr, None)) for attr in self.__attrs__)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#c3431bb6f21bf7c88ff86d9a232ba4db54bb91a0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 60 | Files Changed: 3 | Hunks: 7 | Methods Changed: 3 | Complexity Δ (Sum/Max): -10/0 | Churn Δ: 63 | Churn Cumulative: 11725 | Contributors (this commit): 116 | Commits (past 90d): 97 | Contributors (cumulative): 150 | DMM Complexity: 0.9583333333333334\n\nDIFF:\n@@ -7,13 +7,9 @@ requests.models\n This module contains the primary objects that power Requests.\n \"\"\"\n \n-# import os\n-# import socket\n-\n import collections\n import logging\n \n-# from datetime import datetime\n from io import BytesIO\n from .hooks import dispatch_hook, default_hooks\n from .structures import CaseInsensitiveDict\n\n@@ -10,10 +10,10 @@ requests (cookies, auth, proxies).\n \"\"\"\n \n from .compat import cookielib\n-from .cookies import cookiejar_from_dict, remove_cookie_by_name\n+from .cookies import cookiejar_from_dict\n from .models import Request\n from .hooks import dispatch_hook, default_hooks\n-from .utils import header_expand, from_key_val_list, default_headers\n+from .utils import from_key_val_list, default_headers\n from .exceptions import TooManyRedirects, InvalidSchema\n \n from .compat import urlparse, urljoin\n@@ -354,8 +354,6 @@ class Session(SessionRedirectMixin):\n         for attr, value in state.items():\n             setattr(self, attr, value)\n \n-        self.init_poolmanager()\n-\n \n def session(**kwargs):\n     \"\"\"Returns a :class:`Session` for context-management.\"\"\"\n\n@@ -254,56 +254,6 @@ def unquote_header_value(value, is_filename=False):\n     return value\n \n \n-def header_expand(headers):\n-    \"\"\"Returns an HTTP Header value string from a dictionary.\n-\n-    Example expansion::\n-\n-        {'text/x-dvi': {'q': '.8', 'mxb': '100000', 'mxt': '5.0'}, 'text/x-c': {}}\n-        # Accept: text/x-dvi; q=.8; mxb=100000; mxt=5.0, text/x-c\n-\n-        (('text/x-dvi', {'q': '.8', 'mxb': '100000', 'mxt': '5.0'}), ('text/x-c', {}))\n-        # Accept: text/x-dvi; q=.8; mxb=100000; mxt=5.0, text/x-c\n-    \"\"\"\n-\n-    collector = []\n-\n-    if isinstance(headers, dict):\n-        headers = list(headers.items())\n-    elif isinstance(headers, basestring):\n-        return headers\n-    elif isinstance(headers, str):\n-        # As discussed in https://github.com/kennethreitz/requests/issues/400\n-        # latin-1 is the most conservative encoding used on the web. Anyone\n-        # who needs more can encode to a byte-string before calling\n-        return headers.encode(\"latin-1\")\n-    elif headers is None:\n-        return headers\n-\n-    for i, (value, params) in enumerate(headers):\n-\n-        _params = []\n-\n-        for (p_k, p_v) in list(params.items()):\n-\n-            _params.append('%s=%s' % (p_k, p_v))\n-\n-        collector.append(value)\n-        collector.append('; ')\n-\n-        if len(params):\n-\n-            collector.append('; '.join(_params))\n-\n-            if not len(headers) == i + 1:\n-                collector.append(', ')\n-\n-    # Remove trailing separators.\n-    if collector[-1] in (', ', '; '):\n-        del collector[-1]\n-\n-    return ''.join(collector)\n-\n \n def dict_from_cookiejar(cj):\n     \"\"\"Returns a key/value dictionary from a CookieJar.\n@@ -423,8 +373,7 @@ def get_unicode_from_response(r):\n \n \n def stream_decompress(iterator, mode='gzip'):\n-    \"\"\"\n-    Stream decodes an iterator over compressed data\n+    \"\"\"Stream decodes an iterator over compressed data\n \n     :param iterator: An iterator over compressed data\n     :param mode: 'gzip' or 'deflate'\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#a982b0d90346febf9c0b4df042fc80fc18cc93dd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 6 | Methods Changed: 2 | Complexity Δ (Sum/Max): 5/5 | Churn Δ: 19 | Churn Cumulative: 2013 | Contributors (this commit): 23 | Commits (past 90d): 45 | Contributors (cumulative): 24 | DMM Complexity: 0.0\n\nDIFF:\n@@ -127,7 +127,7 @@ class HTTPAdapter(BaseAdapter):\n         proxy = proxies.get(urlparse(url).scheme)\n \n         if proxy:\n-            conn = poolmanager.proxy_from_url(proxy)\n+            conn = self.poolmanager.ProxyManager(self.poolmanager.proxy_from_url(proxy))\n         else:\n             conn = self.poolmanager.connection_from_url(url)\n \n\n@@ -19,7 +19,7 @@ from .exceptions import TooManyRedirects, InvalidSchema\n from .compat import urlparse, urljoin\n from .adapters import HTTPAdapter\n \n-from .utils import requote_uri\n+from .utils import requote_uri, get_environ_proxies, get_netrc_auth\n \n from .status_codes import codes\n REDIRECT_STATI = (codes.moved, codes.found, codes.other, codes.temporary_moved)\n@@ -204,6 +204,7 @@ class Session(SessionRedirectMixin):\n         cert=None):\n \n         cookies = cookies or {}\n+        proxies = proxies or {}\n \n         # Bootstrap CookieJar.\n         if not isinstance(cookies, cookielib.CookieJar):\n@@ -213,6 +214,17 @@ class Session(SessionRedirectMixin):\n         for cookie in self.cookies:\n             cookies.set_cookie(cookie)\n \n+        # Gather clues from the surrounding environment.\n+        if self.trust_env:\n+            # Set environment's proxies.\n+            env_proxies = get_environ_proxies(url) or {}\n+            for (k, v) in env_proxies.items():\n+                proxies.setdefault(k, v)\n+\n+            # Set environment's basic authentication.\n+            if not auth:\n+                auth = get_netrc_auth(url)\n+\n         # Merge all the kwargs.\n         params = merge_kwargs(params, self.params)\n         headers = merge_kwargs(headers, self.headers)\n@@ -223,6 +235,7 @@ class Session(SessionRedirectMixin):\n         verify = merge_kwargs(verify, self.verify)\n         cert = merge_kwargs(cert, self.cert)\n \n+\n         # Create the Request.\n         req = Request()\n         req.method = method\n@@ -239,7 +252,7 @@ class Session(SessionRedirectMixin):\n         prep = req.prepare()\n \n         # Send the request.\n-        resp = self.send(prep, stream=stream, timeout=timeout, verify=verify, cert=cert)\n+        resp = self.send(prep, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)\n \n         # Redirect resolving generator.\n         gen = self.resolve_redirects(resp, req, stream, timeout, verify, cert)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#e4c4c80b82e14cf60e43653d6934a7d862f00fa5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1873 | Files Changed: 10 | Hunks: 10 | Methods Changed: 139 | Complexity Δ (Sum/Max): -213/0 | Churn Δ: 1873 | Churn Cumulative: 4001 | Contributors (this commit): 32 | Commits (past 90d): 40 | Contributors (cumulative): 57 | DMM Complexity: 0.022526934378060724\n\nDIFF:\n@@ -1,29 +0,0 @@\n-import requests\n-import unittest\n-\n-\n-class IterationTestCase(unittest.TestCase):\n-\n-    def test_assertion(self):\n-        assert 1\n-\n-    # def test_dzubia(self):\n-    #     s = requests.Session()\n-    #     r = requests.Request(method='GET', url='http://github.com/')\n-\n-    #     # r = s.send(r)\n-\n-    def test_prepared_request(self):\n-        s = requests.Session()\n-        r = requests.Request(method='GET', url='http://github.com/')\n-        r = r.prepare()\n-\n-        r = s.send(r)\n-        print r\n-\n-\n-\n-\n-\n-if __name__ == '__main__':\n-    unittest.main()\n\\ No newline at end of file\n\n@@ -1,46 +0,0 @@\n-import asyncore\r\n-import threading\r\n-import socket\r\n-\r\n-class HttpServer(threading.Thread):\r\n-    def __init__(self, port):\r\n-        threading.Thread.__init__(self)\r\n-        self.dispatcher = HttpServerDispatcher(port)\r\n-\r\n-    def run(self):\r\n-        asyncore.loop()\r\n-\r\n-    @property\r\n-    def connection_count(self):\r\n-        return self.dispatcher.connection_count\r\n-\r\n-    def close(self):\r\n-        asyncore.close_all()\r\n-\r\n-class HttpServerDispatcher(asyncore.dispatcher):\r\n-    def __init__(self, port):\r\n-        asyncore.dispatcher.__init__(self)\r\n-        self.connected = False\r\n-        self.create_socket(socket.AF_INET, socket.SOCK_STREAM)\r\n-        self.bind(('127.0.0.1', port))\r\n-        self.listen(1)\r\n-        self.connection_count = 0\r\n-\r\n-    def handle_accept(self):\r\n-        self.connection_count += 1\r\n-        self.handler = RequestHandler(self.accept()[0])\r\n-\r\n-    def handle_close(self):\r\n-        self.close()\r\n-\r\n-\r\n-class RequestHandler(asyncore.dispatcher_with_send):\r\n-    def __init__(self, sock):\r\n-        asyncore.dispatcher_with_send.__init__(self, sock)\r\n-        self.response = (\"HTTP/1.1 200 OK\\r\\n\"\r\n-                         \"Connection: keep-alive\\r\\n\"\r\n-                         \"Content-Length: 0\\r\\n\\r\\n\")\r\n-\r\n-    def handle_read(self):\r\n-        self.recv(1024)\r\n-        self.send(self.response)\r\n\n@@ -1,31 +0,0 @@\n-\"\"\"\n-This is an informal test originally written by Bluehorn;\n-it verifies that Requests does not leak connections when\n-the body of the request is not read.\n-\"\"\"\n-\n-import gc\n-import os\n-import requests\n-import subprocess\n-import sys\n-\n-\n-def main():\n-    gc.disable()\n-\n-    for x in range(20):\n-        requests.head(\"http://www.google.com/\")\n-\n-    print(\"Open sockets after 20 head requests:\")\n-    pid = os.getpid()\n-    subprocess.call(\"lsof -p%d -a -iTCP\" % (pid,), shell=True)\n-\n-    gcresult = gc.collect()\n-    print(\"Garbage collection result: %s\" % (gcresult,))\n-\n-    print(\"Open sockets after garbage collection:\")\n-    subprocess.call(\"lsof -p%d -a -iTCP\" % (pid,), shell=True)\n-\n-if __name__ == '__main__':\n-    sys.exit(main())\n\n@@ -1,244 +0,0 @@\n-#!/usr/bin/env python\n-# -*- coding: utf-8 -*-\n-\n-import sys\n-import json\n-import os\n-import tempfile\n-import unittest\n-\n-# Path hack.\n-sys.path.insert(0, os.path.abspath('..'))\n-import requests\n-from requests.compat import cookielib\n-\n-# More hacks\n-sys.path.append('.')\n-from test_requests import httpbin, TestBaseMixin\n-\n-\n-class CookieTests(TestBaseMixin, unittest.TestCase):\n-\n-    def test_cookies_from_response(self):\n-        \"\"\"Basic test that we correctly parse received cookies in the Response object.\"\"\"\n-        r = requests.get(httpbin('cookies', 'set', 'myname', 'myvalue'))\n-\n-        # test deprecated dictionary interface\n-        self.assertEqual(r.cookies['myname'], 'myvalue')\n-        self.assertEqual(r.cookies.get('myname'), 'myvalue')\n-        # test CookieJar interface\n-        jar = r.cookies\n-        self.assertEqual(len(jar), 1)\n-        cookie_from_jar = list(jar)[0]\n-        self.assertCookieHas(cookie_from_jar, name='myname', value='myvalue')\n-\n-        q = requests.get(httpbin('cookies'), cookies=jar)\n-        self.assertEqual(json.loads(q.text)['cookies'], {'myname': 'myvalue'})\n-\n-    def test_crossdomain_cookies(self):\n-        \"\"\"Cookies should not be sent to domains they didn't originate from.\"\"\"\n-        r = requests.get(\"http://github.com\")\n-        c = r.cookies\n-        # github should send us cookies\n-        self.assertTrue(len(c) >= 1)\n-\n-        # github cookies should not be sent to httpbin.org:\n-        r2 = requests.get(httpbin('cookies'), cookies=c)\n-        self.assertEqual(json.loads(r2.text)['cookies'], {})\n-\n-        # let's do this again using the session object\n-        s = requests.session()\n-        s.get(\"http://github.com\")\n-        self.assertTrue(len(s.cookies) >= 1)\n-        r = s.get(httpbin('cookies'))\n-        self.assertEqual(json.loads(r.text)['cookies'], {})\n-        # we can set a cookie and get exactly that same-domain cookie back:\n-        r = s.get(httpbin('cookies', 'set', 'myname', 'myvalue'))\n-        self.assertEqual(json.loads(r.text)['cookies'], {'myname': 'myvalue'})\n-\n-    def test_overwrite(self):\n-        \"\"\"Cookies should get overwritten when appropriate.\"\"\"\n-        r = requests.get(httpbin('cookies', 'set', 'shimon', 'yochai'))\n-        cookies = r.cookies\n-        requests.get(httpbin('cookies', 'set', 'elazar', 'shimon'), cookies=cookies)\n-        r = requests.get(httpbin('cookies'), cookies=cookies)\n-        self.assertEqual(json.loads(r.text)['cookies'],\n-                {'shimon': 'yochai', 'elazar': 'shimon'})\n-        # overwrite the value of 'shimon'\n-        r = requests.get(httpbin('cookies', 'set', 'shimon', 'gamaliel'), cookies=cookies)\n-        self.assertEqual(len(cookies), 2)\n-        r = requests.get(httpbin('cookies'), cookies=cookies)\n-        self.assertEqual(json.loads(r.text)['cookies'],\n-                {'shimon': 'gamaliel', 'elazar': 'shimon'})\n-\n-    def test_redirects(self):\n-        \"\"\"Test that cookies set by a 302 page are correctly processed.\"\"\"\n-        r = requests.get(httpbin('cookies', 'set', 'redirects', 'work'))\n-        self.assertEqual(r.history[0].status_code, 302)\n-        expected_cookies = {'redirects': 'work'}\n-        self.assertEqual(json.loads(r.text)['cookies'], expected_cookies)\n-\n-        r2 = requests.get(httpbin('cookies', 'set', 'very', 'well'), cookies=r.cookies)\n-        expected_cookies = {'redirects': 'work', 'very': 'well'}\n-        self.assertEqual(json.loads(r2.text)['cookies'], expected_cookies)\n-        self.assertTrue(r.cookies is r2.cookies)\n-\n-    def test_none_cookie(self):\n-        \"\"\"Regression test: don't send a Cookie header with a string value of 'None'!\"\"\"\n-        page = json.loads(requests.get(httpbin('headers')).text)\n-        self.assertTrue('Cookie' not in page['headers'])\n-\n-    def test_secure_cookies(self):\n-        \"\"\"Test that secure cookies can only be sent via https.\"\"\"\n-        header = \"Set-Cookie: ThisIsA=SecureCookie; Path=/; Secure; HttpOnly\"\n-        url = 'https://httpbin.org/response-headers?%s' % (requests.utils.quote(header),)\n-        cookies = requests.get(url, verify=False).cookies\n-        self.assertEqual(len(cookies), 1)\n-        self.assertEqual(list(cookies)[0].secure, True)\n-\n-        secure_resp = requests.get('https://httpbin.org/cookies', cookies=cookies, verify=False)\n-        secure_cookies_sent = json.loads(secure_resp.text)['cookies']\n-        self.assertEqual(secure_cookies_sent, {'ThisIsA': 'SecureCookie'})\n-\n-        insecure_resp = requests.get('http://httpbin.org/cookies', cookies=cookies)\n-        insecure_cookies_sent = json.loads(insecure_resp.text)['cookies']\n-        self.assertEqual(insecure_cookies_sent, {})\n-\n-    def test_jar_utility_functions(self):\n-        \"\"\"Test utility functions such as list_domains, list_paths, multiple_domains.\"\"\"\n-        r = requests.get(\"http://github.com\")\n-        c = r.cookies\n-        # github should send us cookies\n-        self.assertTrue(len(c) >= 1)\n-        self.assertEqual(len(c), len(r.cookies.keys()))\n-        self.assertEqual(len(c), len(r.cookies.values()))\n-        self.assertEqual(len(c), len(r.cookies.items()))\n-\n-        # domain and path utility functions\n-        domain = r.cookies.list_domains()[0]\n-        path = r.cookies.list_paths()[0]\n-        self.assertEqual(dict(r.cookies), r.cookies.get_dict(domain=domain, path=path))\n-        self.assertEqual(len(r.cookies.list_domains()), 1)\n-        self.assertEqual(len(r.cookies.list_paths()), 1)\n-        self.assertFalse(r.cookies.multiple_domains())\n-\n-    def test_convert_jar_to_dict(self):\n-        \"\"\"Test that keys, values, and items are defined and that we can convert\n-        cookie jars to plain old Python dicts.\"\"\"\n-        r = requests.get(httpbin('cookies', 'set', 'myname', 'myvalue'))\n-\n-        # test keys, values, and items\n-        self.assertEqual(r.cookies.keys(), ['myname'])\n-        self.assertEqual(r.cookies.values(), ['myvalue'])\n-        self.assertEqual(r.cookies.items(), [('myname', 'myvalue')])\n-\n-        # test if we can convert jar to dict\n-        dictOfCookies = dict(r.cookies)\n-        self.assertEqual(dictOfCookies, {'myname': 'myvalue'})\n-        self.assertEqual(dictOfCookies, r.cookies.get_dict())\n-\n-\n-class LWPCookieJarTest(TestBaseMixin, unittest.TestCase):\n-    \"\"\"Check store/load of cookies to FileCookieJar's, specifically LWPCookieJar's.\"\"\"\n-\n-    COOKIEJAR_CLASS = cookielib.LWPCookieJar\n-\n-    def setUp(self):\n-        # blank the file\n-        self.cookiejar_file = tempfile.NamedTemporaryFile()\n-        self.cookiejar_filename = self.cookiejar_file.name\n-        cookiejar = self.COOKIEJAR_CLASS(self.cookiejar_filename)\n-        cookiejar.save()\n-\n-    def tearDown(self):\n-        try:\n-            self.cookiejar_file.close()\n-        except OSError:\n-            pass\n-\n-    def test_cookiejar_persistence(self):\n-        \"\"\"Test that we can save cookies to a FileCookieJar.\"\"\"\n-        cookiejar = self.COOKIEJAR_CLASS(self.cookiejar_filename)\n-        cookiejar.load()\n-        # initially should be blank\n-        self.assertEqual(len(cookiejar), 0)\n-\n-        response = requests.get(httpbin('cookies', 'set', 'key', 'value'), cookies=cookiejar)\n-        self.assertEqual(len(cookiejar), 1)\n-        cookie = list(cookiejar)[0]\n-        self.assertEqual(json.loads(response.text)['cookies'], {'key': 'value'})\n-        self.assertCookieHas(cookie, name='key', value='value')\n-\n-        # save and reload the cookies from the file:\n-        cookiejar.save(ignore_discard=True)\n-        cookiejar_2 = self.COOKIEJAR_CLASS(self.cookiejar_filename)\n-        cookiejar_2.load(ignore_discard=True)\n-        self.assertEqual(len(cookiejar_2), 1)\n-        cookie_2 = list(cookiejar_2)[0]\n-        # this cookie should have been saved with the correct domain restriction:\n-        self.assertCookieHas(cookie_2, name='key', value='value',\n-                domain='httpbin.org', path='/')\n-\n-        # httpbin sets session cookies, so if we don't ignore the discard attribute,\n-        # there should be no cookie:\n-        cookiejar_3 = self.COOKIEJAR_CLASS(self.cookiejar_filename)\n-        cookiejar_3.load()\n-        self.assertEqual(len(cookiejar_3), 0)\n-\n-    def test_crossdomain(self):\n-        \"\"\"Test persistence of the domains associated with the cookies.\"\"\"\n-        cookiejar = self.COOKIEJAR_CLASS(self.cookiejar_filename)\n-        cookiejar.load()\n-        self.assertEqual(len(cookiejar), 0)\n-\n-        # github sets a cookie\n-        requests.get(\"http://github.com\", cookies=cookiejar)\n-        num_github_cookies = len(cookiejar)\n-        self.assertTrue(num_github_cookies >= 1)\n-        # httpbin sets another\n-        requests.get(httpbin('cookies', 'set', 'key', 'value'), cookies=cookiejar)\n-        num_total_cookies = len(cookiejar)\n-        self.assertTrue(num_total_cookies >= 2)\n-        self.assertTrue(num_total_cookies > num_github_cookies)\n-\n-        # save and load\n-        cookiejar.save(ignore_discard=True)\n-        cookiejar_2 = self.COOKIEJAR_CLASS(self.cookiejar_filename)\n-        cookiejar_2.load(ignore_discard=True)\n-        self.assertEqual(len(cookiejar_2), num_total_cookies)\n-        r = requests.get(httpbin('cookies'), cookies=cookiejar_2)\n-        self.assertEqual(json.loads(r.text)['cookies'], {'key': 'value'})\n-\n-    def test_persistent_cookies(self):\n-        \"\"\"Test that we correctly interpret persistent cookies.\"\"\"\n-        # httpbin's normal cookie methods don't send persistent cookies,\n-        # so cook up the appropriate header and force it to send\n-        header = \"Set-Cookie: Persistent=CookiesAreScary; expires=Sun, 04-May-2032 04:56:50 GMT; path=/\"\n-        url = httpbin('response-headers?%s' % (requests.utils.quote(header),))\n-        cookiejar = self.COOKIEJAR_CLASS(self.cookiejar_filename)\n-\n-        requests.get(url, cookies=cookiejar)\n-        self.assertEqual(len(cookiejar), 1)\n-        self.assertCookieHas(list(cookiejar)[0], name='Persistent', value='CookiesAreScary')\n-\n-        requests.get(httpbin('cookies', 'set', 'ThisCookieIs', 'SessionOnly'), cookies=cookiejar)\n-        self.assertEqual(len(cookiejar), 2)\n-        self.assertEqual(len([c for c in cookiejar if c.name == 'Persistent']), 1)\n-        self.assertEqual(len([c for c in cookiejar if c.name == 'ThisCookieIs']), 1)\n-\n-        # save and load\n-        cookiejar.save()\n-        cookiejar_2 = self.COOKIEJAR_CLASS(self.cookiejar_filename)\n-        cookiejar_2.load()\n-        # we should only load the persistent cookie\n-        self.assertEqual(len(cookiejar_2), 1)\n-        self.assertCookieHas(list(cookiejar_2)[0], name='Persistent', value='CookiesAreScary')\n-\n-\n-class MozCookieJarTest(LWPCookieJarTest):\n-    \"\"\"Same test, but substitute MozillaCookieJar.\"\"\"\n-\n-    COOKIEJAR_CLASS = cookielib.MozillaCookieJar\n-\n-if __name__ == '__main__':\n-    unittest.main()\n\n@@ -1,65 +0,0 @@\n-#!/usr/bin/env python\r\n-# -*- coding: utf-8 -*-\r\n-\r\n-import os\r\n-import sys\r\n-import unittest\r\n-\r\n-# Path hack.\r\n-sys.path.insert(0, os.path.abspath('..'))\r\n-import requests\r\n-import dummy_server\r\n-\r\n-class KeepAliveTests(unittest.TestCase):\r\n-    server_and_proxy_port = 1234\r\n-    request_count = 2\r\n-    url = 'http://localhost:{0}'.format(server_and_proxy_port)\r\n-    proxies={'http': url}\r\n-\r\n-    def setUp(self):\r\n-        self.session = requests.session()\r\n-        self.proxy_server = dummy_server.HttpServer(self.server_and_proxy_port)\r\n-        self.proxy_server.start()\r\n-\r\n-    def tearDown(self):\r\n-        self.proxy_server.close()\r\n-\r\n-    def test_keep_alive_with_direct_connection(self):\r\n-        self.make_requests()\r\n-        self.check_each_request_are_in_same_connection()\r\n-\r\n-    def test_no_keep_alive_with_direct_connection(self):\r\n-        self.disable_keep_alive_in_session()\r\n-        self.make_requests()\r\n-        self.check_each_request_are_in_different_connection()\r\n-\r\n-    def test_keep_alive_with_proxy_connection(self):\r\n-        self.make_proxy_requests()\r\n-        self.check_each_request_are_in_same_connection()\r\n-\r\n-    def test_no_keep_alive_with_proxy_connection(self):\r\n-        self.disable_keep_alive_in_session()\r\n-        self.make_proxy_requests()\r\n-        self.check_each_request_are_in_different_connection()\r\n-\r\n-    def make_proxy_requests(self):\r\n-        self.make_requests(self.proxies)\r\n-\r\n-    def make_requests(self, proxies=None):\r\n-        for _ in range(self.request_count):\n-            self.session.get(self.url, proxies=proxies).text\r\n-\r\n-    def check_each_request_are_in_same_connection(self):\r\n-        \"\"\"Keep-alive requests open a single connection to the server.\"\"\"\r\n-        self.assertEqual(self.proxy_server.connection_count, 1)\r\n-\r\n-    def check_each_request_are_in_different_connection(self):\r\n-        \"\"\"Keep-alive requests open a single connection to the server.\"\"\"\r\n-        self.assertEqual(self.proxy_server.connection_count, self.request_count)\r\n-\r\n-    def disable_keep_alive_in_session(self):\r\n-        self.session.config['keep_alive'] = False\r\n-\r\n-\r\n-if __name__ == '__main__':\r\n-    unittest.main()\r\n\n@@ -1,29 +0,0 @@\n-#!/usr/bin/env python\n-# -*- coding: utf-8 -*-\n-\n-import os\n-import sys\n-import unittest\n-\n-# Path hack.\n-sys.path.insert(0, os.path.abspath('..'))\n-import requests\n-\n-\n-class HTTPSProxyTest(unittest.TestCase):\n-    \"\"\"Smoke test for https functionality.\"\"\"\n-\n-    smoke_url = \"https://github.com\"\n-\n-    def test_empty_https_proxy(self):\n-        proxy = {\"https\": \"\"}\n-        result = requests.get(self.smoke_url, verify=False, proxies=proxy)\n-        self.assertEqual(result.status_code, 200)\n-\n-    def test_empty_http_proxy(self):\n-        proxy = {\"http\": \"\"}\n-        result = requests.get(self.smoke_url, proxies=proxy)\n-        self.assertEqual(result.status_code, 200)\n-\n-if __name__ == '__main__':\n-    unittest.main()\n\n@@ -1,1151 +0,0 @@\n-#!/usr/bin/env python\n-# -*- coding: utf-8 -*-\n-\n-# from __future__ import unicode_literals\n-\n-# Path hack.\n-import sys\n-import os\n-sys.path.insert(0, os.path.abspath('..'))\n-import json\n-import unittest\n-import pickle\n-import tempfile\n-import collections\n-\n-import requests\n-from requests.compat import str, StringIO\n-# import envoy\n-from requests import HTTPError\n-from requests import get, post, head, put\n-from requests.auth import HTTPBasicAuth, HTTPDigestAuth\n-from requests.exceptions import InvalidURL\n-\n-if 'HTTPBIN_URL' not in os.environ:\n-    os.environ['HTTPBIN_URL'] = 'http://httpbin.org/'\n-\n-HTTPBIN_URL = os.environ.get('HTTPBIN_URL')\n-\n-\n-def httpbin(*suffix):\n-    \"\"\"Returns url for HTTPBIN resource.\"\"\"\n-    return HTTPBIN_URL + '/'.join(suffix)\n-\n-\n-SERVICES = (httpbin, )\n-\n-_httpbin = False\n-\n-\n-class TestSetup(object):\n-    \"\"\"Requests test cases.\"\"\"\n-\n-    # It goes to eleven.\n-    _multiprocess_can_split_ = True\n-\n-    def setUp(self):\n-\n-        global _httpbin\n-\n-        if (not 'HTTPBIN_URL' in os.environ) and not _httpbin:\n-            # c = envoy.connect('httpbin %s' % (PORT))\n-            # time.sleep(1)\n-            _httpbin = True\n-\n-\n-class TestBaseMixin(object):\n-\n-    def assertCookieHas(self, cookie, **kwargs):\n-        \"\"\"Assert that a cookie has various specified properties.\"\"\"\n-        for attr, expected_value in kwargs.items():\n-            cookie_attr = getattr(cookie, attr)\n-            message = 'Failed comparison for %s: %s != %s' % (attr, cookie_attr, expected_value)\n-            self.assertEqual(cookie_attr, expected_value, message)\n-\n-\n-class RequestsTestSuite(TestSetup, TestBaseMixin, unittest.TestCase):\n-    \"\"\"Requests test cases.\"\"\"\n-\n-    def test_entry_points(self):\n-\n-        requests.session\n-        requests.session().get\n-        requests.session().head\n-        requests.get\n-        requests.head\n-        requests.put\n-        requests.patch\n-        requests.post\n-\n-    def test_invalid_url(self):\n-        self.assertRaises(ValueError, get, 'hiwpefhipowhefopw')\n-\n-    def test_path_is_not_double_encoded(self):\n-        request = requests.Request(\"http://0.0.0.0/get/test case\")\n-\n-        self.assertEqual(request.path_url, \"/get/test%20case\")\n-\n-    def test_params_are_added_before_fragment(self):\n-        request = requests.Request(\n-            \"http://example.com/path#fragment\", params={\"a\": \"b\"})\n-        self.assertEqual(request.full_url,\n-            \"http://example.com/path?a=b#fragment\")\n-        request = requests.Request(\n-            \"http://example.com/path?key=value#fragment\", params={\"a\": \"b\"})\n-        self.assertEqual(request.full_url,\n-            \"http://example.com/path?key=value&a=b#fragment\")\n-\n-    def test_params_accepts_kv_list(self):\n-        request = requests.Request('http://example.com/path',\n-                params=[('a', 'b')])\n-        self.assertEqual(request.full_url, 'http://example.com/path?a=b')\n-\n-    def test_HTTP_200_OK_GET(self):\n-        r = get(httpbin('get'))\n-        self.assertEqual(r.status_code, 200)\n-\n-    def test_response_sent(self):\n-        r = get(httpbin('get'))\n-\n-        self.assertTrue(r.request.sent)\n-\n-    def test_HTTP_302_ALLOW_REDIRECT_GET(self):\n-        r = get(httpbin('redirect', '1'))\n-        self.assertEqual(r.status_code, 200)\n-\n-    def test_HTTP_302_GET(self):\n-        r = get(httpbin('redirect', '1'), allow_redirects=False)\n-        self.assertEqual(r.status_code, 302)\n-\n-    def test_HTTP_200_OK_GET_WITH_PARAMS(self):\n-        heads = {'User-agent': 'Mozilla/5.0'}\n-\n-        r = get(httpbin('user-agent'), headers=heads)\n-\n-        self.assertTrue(heads['User-agent'] in r.text)\n-        self.assertEqual(r.status_code, 200)\n-\n-    def test_HTTP_200_OK_GET_WITH_MIXED_PARAMS(self):\n-        heads = {'User-agent': 'Mozilla/5.0'}\n-\n-        r = get(httpbin('get') + '?test=true', params={'q': 'test'}, headers=heads)\n-        self.assertEqual(r.status_code, 200)\n-\n-    # def test_unicode_headers(self):\n-    #     # Simply calling requests with a unicode instance should simply work\n-    #     # when the characters are all representable using latin-1:\n-    #     heads = { u'User-Agent': u'Requests Test Suite' }\n-    #     requests.get(url=httpbin('get'), headers=heads)\n-\n-    #     # Characters outside latin-1 should raise an exception:\n-    #     heads = { u'User-Agent': u'\\u30cd\\u30c3\\u30c8\\u30ef\\u30fc\\u30af' }\n-    #     self.assertRaises(UnicodeEncodeError, requests.get,\n-    #                       url=httpbin('get'), headers=heads)\n-\n-    # def test_session_with_escaped_url(self):\n-    #     # Test a URL that contains percent-escaped characters\n-    #     # This URL should not be modified (double-escaped)\n-    #     # Tests:\n-    #     # - Quoted illegal characters (\"%20\" (' '), \"%3C\" ('<'), \"%3E\" ('>'))\n-    #     # - Quoted reserved characters (\"%25\" ('%'), \"%23\" ('#'), \"%2F\" ('/'))\n-    #     # - Quoted non-ASCII characters (\"%C3%98\", \"%C3%A5\")\n-    #     path_fully_escaped = '%3Ca%25b%23c%2Fd%3E/%C3%98%20%C3%A5'\n-    #     url = httpbin('get/' + path_fully_escaped)\n-    #     response = get(url)\n-    #     self.assertEqual(response.url, httpbin('get/' + path_fully_escaped))\n-\n-    #     # Test that illegal characters in a path get properly percent-escaped\n-    #     # Tests:\n-    #     # - Bare illegal characters (space, '<')\n-    #     # - Bare non-ASCII characters ('\\u00d8')\n-    #     path = u'<a%25b%23c%2Fd%3E/\\u00d8 %C3%A5'\n-    #     url = httpbin('get/' + path)\n-    #     response = get(url)\n-    #     self.assertEqual(response.url, httpbin('get/' + path_fully_escaped))\n-\n-    #     # Test that reserved characters in a path do not get percent-escaped\n-    #     # Tests:\n-    #     # - All reserved characters (RFC 3986), except '?', '#', '[' and ']',\n-    #     #   which are not allowed in the path, and ';' which delimits\n-    #     #   parameters.\n-    #     #   All such characters must be allowed bare in path, and must not be\n-    #     #   encoded.\n-    #     # - Special unreserved characters (RFC 3986), which should not be\n-    #     #   encoded (even though it wouldn't hurt).\n-    #     path_reserved = '!$&\\'()*+,/:=@-._~'\n-    #     url = httpbin('get/' + path_reserved)\n-    #     response = get(url)\n-    #     self.assertEqual(response.url, httpbin('get/' + path_reserved))\n-\n-    #     # Test that percent-encoded unreserved characters in a path get\n-    #     # normalised to their un-encoded forms.\n-    #     path_unreserved = 'ABCDwxyz1234-._~'\n-    #     path_unreserved_escaped = '%41%42%43%44%77%78%79%7A%31%32%33%34%2D%2E%5F%7E'\n-    #     url = httpbin('get/' + path_unreserved_escaped)\n-    #     response = get(url)\n-    #     self.assertEqual(response.url, httpbin('get/' + path_unreserved))\n-\n-    #     # Re-run all of the same tests on the query part of the URI\n-    #     query_fully_escaped = '%3Ca%25b%23c%2Fd%3E=%C3%98%20%C3%A5'\n-    #     url = httpbin('get/?' + query_fully_escaped)\n-    #     response = get(url)\n-    #     self.assertEqual(response.url, httpbin('get/?' + query_fully_escaped))\n-\n-    #     query = u'<a%25b%23c%2Fd%3E=\\u00d8 %C3%A5'\n-    #     url = httpbin('get/?' + query)\n-    #     response = get(url)\n-    #     self.assertEqual(response.url, httpbin('get/?' + query_fully_escaped))\n-\n-    #     # The legal characters in query happens to be the same as in path\n-    #     query_reserved = '!$&\\'()*+,/:=@-._~'\n-    #     url = httpbin('get/?' + query_reserved)\n-    #     response = get(url)\n-    #     self.assertEqual(response.url, httpbin('get/?' + query_reserved))\n-\n-    #     query_unreserved = 'ABCDwxyz=1234-._~'\n-    #     query_unreserved_escaped = '%41%42%43%44%77%78%79%7A=%31%32%33%34%2D%2E%5F%7E'\n-    #     url = httpbin('get/?' + query_unreserved_escaped)\n-    #     response = get(url)\n-    #     self.assertEqual(response.url, httpbin('get/?' + query_unreserved))\n-\n-    def test_user_agent_transfers(self):\n-        \"\"\"Issue XX\"\"\"\n-\n-        heads = {\n-            'User-agent':\n-                'Mozilla/5.0 (github.com/kennethreitz/requests)'\n-        }\n-\n-        r = get(httpbin('user-agent'), headers=heads)\n-        self.assertTrue(heads['User-agent'] in r.text)\n-\n-        heads = {\n-            'user-agent':\n-                'Mozilla/5.0 (github.com/kennethreitz/requests)'\n-        }\n-\n-        r = get(httpbin('user-agent'), headers=heads)\n-        self.assertTrue(heads['user-agent'] in r.text)\n-\n-    def test_HTTP_200_OK_HEAD(self):\n-        r = head(httpbin('get'))\n-        self.assertEqual(r.status_code, 200)\n-\n-    def test_HTTP_200_OK_PUT(self):\n-        r = put(httpbin('put'))\n-        self.assertEqual(r.status_code, 200)\n-\n-    def test_BASICAUTH_TUPLE_HTTP_200_OK_GET(self):\n-\n-        for service in SERVICES:\n-\n-            auth = ('user', 'pass')\n-            url = service('basic-auth', 'user', 'pass')\n-\n-            r = get(url, auth=auth)\n-            self.assertEqual(r.status_code, 200)\n-\n-            r = get(url)\n-            self.assertEqual(r.status_code, 401)\n-\n-            s = requests.session(auth=auth)\n-            r = get(url, session=s)\n-            self.assertEqual(r.status_code, 200)\n-\n-    def test_BASICAUTH_HTTP_200_OK_GET(self):\n-\n-        for service in SERVICES:\n-\n-            auth = HTTPBasicAuth('user', 'pass')\n-            url = service('basic-auth', 'user', 'pass')\n-\n-            r = get(url, auth=auth)\n-            self.assertEqual(r.status_code, 200)\n-\n-            auth = ('user', 'pass')\n-            r = get(url, auth=auth)\n-            self.assertEqual(r.status_code, 200)\n-\n-            r = get(url)\n-            self.assertEqual(r.status_code, 401)\n-\n-            s = requests.session(auth=auth)\n-            r = get(url, session=s)\n-            self.assertEqual(r.status_code, 200)\n-\n-    def test_DIGESTAUTH_HTTP_200_OK_GET(self):\n-\n-        for service in SERVICES:\n-\n-            auth = HTTPDigestAuth('user', 'pass')\n-            url = service('digest-auth', 'auth', 'user', 'pass')\n-\n-            r = get(url, auth=auth)\n-            self.assertEqual(r.status_code, 200)\n-            self.assertEqual(len(r.history), 1)\n-\n-            r = get(url, auth=auth)\n-            self.assertEqual(r.status_code, 200)\n-            self.assertEqual(len(r.history), 0)\n-\n-            r = get(url)\n-            self.assertEqual(r.status_code, 401)\n-\n-            s = requests.session(auth=auth)\n-            r = get(url, session=s)\n-            self.assertEqual(r.status_code, 200)\n-\n-    def test_DIGESTAUTH_WRONG_HTTP_401_GET(self):\n-\n-        for service in SERVICES:\n-\n-            auth = HTTPDigestAuth('user', 'wrongpass')\n-            url = service('digest-auth', 'auth', 'user', 'pass')\n-\n-            r = get(url, auth=auth)\n-            self.assertEqual(r.status_code, 401)\n-\n-            s = requests.session(auth=auth)\n-            r = get(url, session=s)\n-            self.assertEqual(r.status_code, 401)\n-\n-    def test_POSTBIN_GET_POST_FILES(self):\n-\n-        for service in SERVICES:\n-\n-            url = service('post')\n-            post1 = post(url).raise_for_status()\n-\n-            post1 = post(url, data={'some': 'data'})\n-            self.assertEqual(post1.status_code, 200)\n-\n-            with open(__file__) as f:\n-                post2 = post(url, files={'some': f})\n-                post3 = post(url, files=[('some', f)])\n-            self.assertEqual(post2.status_code, 200)\n-            self.assertEqual(post3.status_code, 200)\n-\n-            post4 = post(url, data='[{\"some\": \"json\"}]')\n-            self.assertEqual(post4.status_code, 200)\n-\n-            try:\n-                post(url, files=['bad file data'])\n-            except ValueError:\n-                pass\n-\n-    def test_POSTBIN_GET_POST_FILES_WITH_PARAMS(self):\n-\n-        for service in SERVICES:\n-\n-            with open(__file__) as f:\n-                url = service('post')\n-                post1 = post(url, data={'some': 'data'}, files={'some': f})\n-                post2 = post(url, data={'some': 'data'}, files=[('some', f)])\n-                post3 = post(url, data=[('some', 'data')], files=[('some', f)])\n-\n-            self.assertEqual(post1.status_code, 200)\n-            self.assertEqual(post2.status_code, 200)\n-            self.assertEqual(post3.status_code, 200)\n-\n-    def test_POSTBIN_GET_POST_FILES_WITH_CJK_PARAMS(self):\n-\n-        for service in SERVICES:\n-\n-            with open(__file__) as f:\n-                url = service('post')\n-                post1 = post(url, data={'some': '中文'}, files={'some': f})\n-                post2 = post(url, data={'some': '日本語'}, files=[('some', f)])\n-                post3 = post(url, data=[('some', '한국의')], files=[('some', f)])\n-\n-            self.assertEqual(post1.status_code, 200)\n-            self.assertEqual(post2.status_code, 200)\n-            self.assertEqual(post3.status_code, 200)\n-\n-    def test_POSTBIN_GET_POST_FILES_WITH_HEADERS(self):\n-\n-        for service in SERVICES:\n-\n-            url = service('post')\n-\n-            with open(__file__) as f:\n-\n-                post2 = post(url,\n-                    files={'some': f},\n-                    headers={'User-Agent': 'requests-tests'})\n-\n-            self.assertEqual(post2.status_code, 200)\n-\n-    def test_POSTBIN_GET_POST_FILES_STRINGS(self):\n-\n-        for service in SERVICES:\n-\n-            url = service('post')\n-\n-            post1 = post(url, files={'fname.txt': 'fdata'})\n-            self.assertEqual(post1.status_code, 200)\n-\n-            post2 = post(url, files={'fname.txt': 'fdata',\n-                    'fname2.txt': 'more fdata'})\n-            self.assertEqual(post2.status_code, 200)\n-\n-            post3 = post(url, files={'fname.txt': 'fdata',\n-                    'fname2.txt': open(__file__, 'rb')})\n-            self.assertEqual(post3.status_code, 200)\n-\n-            post4 = post(url, files={'fname.txt': 'fdata'})\n-            self.assertEqual(post4.status_code, 200)\n-\n-            post5 = post(url, files={'file': ('file.txt', 'more fdata')})\n-            self.assertEqual(post5.status_code, 200)\n-\n-            # Dirty hack to tide us over until 3.3.\n-            # TODO: Remove this hack when Python 3.3 is released.\n-            if (sys.version_info[0] == 2):\n-                fdata = '\\xc3\\xa9'.decode('utf-8')\n-            else:\n-                fdata = '\\xe9'\n-\n-            post6 = post(url, files={'fname.txt': fdata})\n-            self.assertEqual(post6.status_code, 200)\n-\n-            post7 = post(url, files={'fname.txt': 'fdata to verify'})\n-            rbody = json.loads(post7.text)\n-            self.assertTrue(rbody.get('files', None))\n-            self.assertTrue(rbody['files'].get('fname.txt', None))\n-            self.assertEqual(rbody['files']['fname.txt'], 'fdata to verify')\n-\n-            post8 = post(url, files=[('fname.txt', 'fdata')])\n-            self.assertEqual(post8.status_code, 200)\n-            resp_body = post8.json\n-            self.assertTrue(resp_body.get('files', None))\n-            self.assertTrue(resp_body['files'].get('fname.txt', None))\n-            self.assertEqual(resp_body['files']['fname.txt'], 'fdata')\n-\n-            post9 = post(url, files=[('fname.txt', fdata)])\n-            self.assertEqual(post9.status_code, 200)\n-\n-            post10 = post(url, files=[('file',\n-                        ('file.txt', 'more file data'))])\n-            self.assertEqual(post10.status_code, 200)\n-\n-            post11 = post(url, files=[('fname.txt', 'fdata'),\n-                    ('fname2.txt', 'more fdata')])\n-            post12 = post(url, files=[('fname.txt', 'fdata'),\n-                    ('fname2.txt', open(__file__, 'rb'))])\n-            self.assertEqual(post11.status_code, 200)\n-            self.assertEqual(post12.status_code, 200)\n-\n-    def test_nonzero_evaluation(self):\n-\n-        for service in SERVICES:\n-\n-            r = get(service('status', '500'))\n-            self.assertEqual(bool(r), False)\n-\n-            r = get(service('/get'))\n-            self.assertEqual(bool(r), True)\n-\n-    def test_request_ok_set(self):\n-\n-        for service in SERVICES:\n-\n-            r = get(service('status', '404'))\n-            # print r.status_code\n-            # r.raise_for_status()\n-            self.assertEqual(r.ok, False)\n-\n-    def test_status_raising(self):\n-        r = get(httpbin('status', '404'))\n-        self.assertRaises(HTTPError, r.raise_for_status)\n-\n-        r = get(httpbin('status', '200'))\n-        self.assertFalse(r.error)\n-        r.raise_for_status()\n-\n-    def test_decompress_gzip(self):\n-\n-        r = get(httpbin('gzip'))\n-        r.content.decode('ascii')\n-\n-    def test_response_has_unicode_url(self):\n-\n-        for service in SERVICES:\n-\n-            url = service('get')\n-\n-            response = get(url)\n-\n-            self.assertTrue(isinstance(response.url, str))\n-\n-    def test_unicode_get(self):\n-\n-        for service in SERVICES:\n-\n-            url = service('/get')\n-\n-            get(url, params={'foo': 'føø'})\n-            get(url, params={'føø': 'føø'})\n-            get(url, params={'føø': 'føø'})\n-            get(url, params={'foo': 'foo'})\n-            get(service('ø'), params={'foo': 'foo'})\n-\n-    def test_httpauth_recursion(self):\n-\n-        http_auth = HTTPBasicAuth('user', 'BADpass')\n-\n-        for service in SERVICES:\n-            r = get(service('basic-auth', 'user', 'pass'), auth=http_auth)\n-            self.assertEqual(r.status_code, 401)\n-\n-    def test_urlencoded_post_data(self):\n-\n-        for service in SERVICES:\n-\n-            r = post(service('post'), data=dict(test='fooaowpeuf'))\n-\n-            self.assertEqual(r.status_code, 200)\n-            self.assertEqual(r.headers['content-type'], 'application/json')\n-            self.assertEqual(r.url, service('post'))\n-\n-            rbody = json.loads(r.text)\n-\n-            self.assertEqual(rbody.get('form'), dict(test='fooaowpeuf'))\n-            self.assertEqual(rbody.get('data'), '')\n-\n-    def test_nonurlencoded_post_data(self):\n-\n-        for service in SERVICES:\n-\n-            r = post(service('post'), data='fooaowpeuf')\n-\n-            self.assertEqual(r.status_code, 200)\n-            self.assertEqual(r.headers['content-type'], 'application/json')\n-            self.assertEqual(r.url, service('post'))\n-\n-            rbody = json.loads(r.text)\n-            # Body wasn't valid url encoded data, so the server returns None as\n-            # \"form\" and the raw body as \"data\".\n-\n-            self.assertTrue(rbody.get('form') in (None, {}))\n-            self.assertEqual(rbody.get('data'), 'fooaowpeuf')\n-\n-    def test_file_post_data(self):\n-\n-        filecontent = b\"fooaowpeufbarasjhf\"\n-        testfile = tempfile.NamedTemporaryFile(delete=False)\n-        testfile.write(filecontent)\n-        testfile.flush()\n-        testfile.close()\n-\n-        for service in SERVICES:\n-\n-            data = open(testfile.name, \"rb\")\n-            r = post(service('post'), data=data,\n-                    headers={\"content-type\": \"application/octet-stream\"})\n-\n-            data.close()\n-            self.assertEqual(r.status_code, 200)\n-            self.assertEqual(r.headers['content-type'], 'application/json')\n-            self.assertEqual(r.url, service('post'))\n-\n-            rbody = json.loads(r.text)\n-            self.assertTrue(rbody.get('form') in (None, {}))\n-            self.assertEqual(rbody.get('data'), filecontent.decode('ascii'))\n-        os.remove(testfile.name)\n-\n-    def test_urlencoded_post_querystring(self):\n-\n-        for service in SERVICES:\n-\n-            r = post(service('post'), params=dict(test='fooaowpeuf'))\n-\n-            self.assertEqual(r.status_code, 200)\n-            self.assertEqual(r.headers['content-type'], 'application/json')\n-            self.assertEqual(r.url, service('post?test=fooaowpeuf'))\n-\n-            rbody = json.loads(r.text)\n-            self.assertEqual(rbody.get('form'), {})  # No form supplied\n-            self.assertEqual(rbody.get('data'), '')\n-\n-    def test_urlencoded_post_query_and_data(self):\n-\n-        for service in SERVICES:\n-\n-            r = post(\n-                service('post'),\n-                params=dict(test='fooaowpeuf'),\n-                data=dict(test2=\"foobar\"))\n-\n-            self.assertEqual(r.status_code, 200)\n-            self.assertEqual(r.headers['content-type'], 'application/json')\n-            self.assertEqual(r.url, service('post?test=fooaowpeuf'))\n-\n-            rbody = json.loads(r.text)\n-            self.assertEqual(rbody.get('form'), dict(test2='foobar'))\n-            self.assertEqual(rbody.get('data'), '')\n-\n-    def test_nonurlencoded_postdata(self):\n-\n-        for service in SERVICES:\n-\n-            r = post(service('post'), data=\"foobar\")\n-\n-            self.assertEqual(r.status_code, 200)\n-            self.assertEqual(r.headers['content-type'], 'application/json')\n-\n-            rbody = json.loads(r.text)\n-\n-            self.assertTrue(rbody.get('form') in (None, {}))\n-            self.assertEqual(rbody.get('data'), 'foobar')\n-\n-    def test_urlencoded_get_query_multivalued_param(self):\n-\n-        for service in SERVICES:\n-\n-            r = get(service('get'), params=dict(test=['foo', 'baz']))\n-            self.assertEqual(r.status_code, 200)\n-            self.assertEqual(r.url, service('get?test=foo&test=baz'))\n-\n-    def test_urlencoded_post_querystring_multivalued(self):\n-\n-        for service in SERVICES:\n-\n-            r = post(service('post'), params=dict(test=['foo', 'baz']))\n-            self.assertEqual(r.status_code, 200)\n-            self.assertEqual(r.headers['content-type'], 'application/json')\n-            self.assertEqual(r.url, service('post?test=foo&test=baz'))\n-\n-            rbody = json.loads(r.text)\n-            self.assertEqual(rbody.get('form'), {})  # No form supplied\n-            self.assertEqual(rbody.get('data'), '')\n-\n-    def test_urlencoded_post_query_multivalued_and_data(self):\n-\n-        for service in SERVICES:\n-\n-            r = post(\n-                service('post'),\n-                params=dict(test=['foo', 'baz']),\n-                data=dict(test2=\"foobar\", test3=['foo', 'baz']))\n-\n-            self.assertEqual(r.status_code, 200)\n-            self.assertEqual(r.headers['content-type'], 'application/json')\n-            self.assertEqual(r.url, service('post?test=foo&test=baz'))\n-\n-            # print(r.text)\n-            # print('-----------------------')\n-\n-            rbody = json.loads(r.text)\n-            self.assertEqual(rbody.get('form'), dict(test2='foobar', test3=['foo', 'baz']))\n-            self.assertEqual(rbody.get('data'), '')\n-\n-    def test_multivalued_data_encoding(self):\n-        \"\"\"\n-        Make sure data encoding works on a value that is an iterable but not\n-        a list\n-        \"\"\"\n-        for service in SERVICES:\n-            # Can't have unicode literals in Python3, so avoid them.\n-            # TODO: fixup when moving to Python 3.3\n-            if (sys.version_info[0] == 2):\n-                nonascii = '\\xc3\\xa9'.decode('utf-8')\n-            else:\n-                nonascii = '\\xe9'\n-\n-            r = post(\n-                service('post'),\n-                data=dict(test=('foo', nonascii)))\n-\n-            self.assertEqual(r.status_code, 200)\n-            self.assertEqual(r.headers['content-type'], 'application/json')\n-\n-            rbody = json.loads(r.text)\n-            self.assertEqual(rbody.get('form'),\n-                             dict(test=['foo', nonascii]))\n-\n-    def test_GET_no_redirect(self):\n-\n-        for service in SERVICES:\n-\n-            r = get(service('redirect', '3'), allow_redirects=False)\n-            self.assertEqual(r.status_code, 302)\n-            self.assertEqual(len(r.history), 0)\n-\n-    def test_HEAD_no_redirect(self):\n-\n-        for service in SERVICES:\n-\n-            r = head(service('redirect', '3'), allow_redirects=False)\n-            self.assertEqual(r.status_code, 302)\n-            self.assertEqual(len(r.history), 0)\n-\n-    def test_redirect_history(self):\n-\n-        for service in SERVICES:\n-\n-            r = get(service('redirect', '3'))\n-            self.assertEqual(r.status_code, 200)\n-            self.assertEqual(len(r.history), 3)\n-\n-    def test_relative_redirect_history(self):\n-\n-        for service in SERVICES:\n-\n-            r = get(service('relative-redirect', '3'))\n-            self.assertEqual(r.status_code, 200)\n-            self.assertEqual(len(r.history), 3)\n-\n-    def test_session_HTTP_200_OK_GET(self):\n-\n-        s = requests.session()\n-        r = get(httpbin('get'), session=s)\n-        self.assertEqual(r.status_code, 200)\n-\n-    def test_session_persistent_headers(self):\n-\n-        heads = {'User-agent': 'Mozilla/5.0'}\n-\n-        s = requests.session()\n-        s.headers = heads\n-\n-        # Make 2 requests from Session object, should send header both times\n-        r1 = get(httpbin('user-agent'), session=s)\n-        self.assertTrue(heads['User-agent'] in r1.text)\n-\n-        r2 = get(httpbin('user-agent'), session=s)\n-        self.assertTrue(heads['User-agent'] in r2.text)\n-\n-        new_heads = {'User-agent': 'blah'}\n-        r3 = get(httpbin('user-agent'), headers=new_heads, session=s)\n-        self.assertTrue(new_heads['User-agent'] in r3.text)\n-\n-        self.assertEqual(r2.status_code, 200)\n-\n-    def test_single_hook(self):\n-\n-        def add_foo_header(args):\n-            if not args.get('headers'):\n-                args['headers'] = {}\n-\n-            args['headers'].update({\n-                'X-Foo': 'foo'\n-            })\n-\n-            return args\n-\n-        for service in SERVICES:\n-            url = service('headers')\n-            response = get(url=url, hooks={'args': add_foo_header})\n-\n-            self.assertTrue('foo' in response.text)\n-\n-    def test_multiple_hooks(self):\n-\n-        def add_foo_header(args):\n-            if not args.get('headers'):\n-                args['headers'] = {}\n-\n-            args['headers'].update({\n-                'X-Foo': 'foo'\n-            })\n-\n-            return args\n-\n-        def add_bar_header(args):\n-            if not args.get('headers'):\n-                args['headers'] = {}\n-\n-            args['headers'].update({\n-                'X-Bar': 'bar'\n-            })\n-\n-            return args\n-\n-        for service in SERVICES:\n-            url = service('headers')\n-\n-            response = get(url=url,\n-                hooks={\n-                    'args': [add_foo_header, add_bar_header]\n-                }\n-            )\n-\n-            for text in ('foo', 'bar'):\n-                self.assertTrue(text in response.text)\n-\n-    def test_allow_list_of_hooks_to_register_hook(self):\n-        \"\"\"Issue 785: https://github.com/kennethreitz/requests/issues/785\"\"\"\n-        def add_foo_header(args):\n-            if not args.get('headers'):\n-                args['headers'] = {}\n-\n-            args['headers'].update({\n-                'X-Foo': 'foo'\n-            })\n-\n-            return args\n-\n-        def add_bar_header(args):\n-            if not args.get('headers'):\n-                args['headers'] = {}\n-\n-            args['headers'].update({\n-                'X-Bar': 'bar'\n-            })\n-\n-            return args\n-\n-        def assert_hooks_are_callable(hooks):\n-            for h in hooks['args']:\n-                self.assertTrue(isinstance(h, collections.Callable))\n-\n-        hooks = [add_foo_header, add_bar_header]\n-        r = requests.models.Request()\n-        r.register_hook('args', hooks)\n-        assert_hooks_are_callable(r.hooks)\n-\n-        r = requests.models.Request(hooks={'args': hooks})\n-        assert_hooks_are_callable(r.hooks)\n-\n-        hooks.append('string that should not be registered')\n-        r = requests.models.Request(hooks={'args': hooks})\n-        assert_hooks_are_callable(r.hooks)\n-\n-    def test_session_persistent_cookies(self):\n-\n-        s = requests.session()\n-\n-        # Internally dispatched cookies are sent.\n-        _c = {'kenneth': 'reitz', 'bessie': 'monke'}\n-        r = get(httpbin('cookies'), cookies=_c, session=s)\n-        r = get(httpbin('cookies'), session=s)\n-\n-        # Those cookies persist transparently.\n-        c = json.loads(r.text).get('cookies')\n-        self.assertEqual(c, _c)\n-\n-        # Double check.\n-        r = get(httpbin('cookies'), cookies={}, session=s)\n-        c = json.loads(r.text).get('cookies')\n-        self.assertEqual(c, _c)\n-\n-        # Remove a cookie by setting it's value to None.\n-        r = get(httpbin('cookies'), cookies={'bessie': None}, session=s)\n-        c = json.loads(r.text).get('cookies')\n-        del _c['bessie']\n-        self.assertEqual(c, _c)\n-\n-        # Test session-level cookies.\n-        s = requests.session(cookies=_c)\n-        r = get(httpbin('cookies'), session=s)\n-        c = json.loads(r.text).get('cookies')\n-        self.assertEqual(c, _c)\n-\n-        # Have the server set a cookie.\n-        r = get(httpbin('cookies', 'set', 'k', 'v'), allow_redirects=True, session=s)\n-        c = json.loads(r.text).get('cookies')\n-\n-        self.assertTrue('k' in c)\n-\n-        # And server-set cookie persistience.\n-        r = get(httpbin('cookies'), session=s)\n-        c = json.loads(r.text).get('cookies')\n-\n-        self.assertTrue('k' in c)\n-\n-    def test_session_persistent_params(self):\n-\n-        params = {'a': 'a_test'}\n-\n-        s = requests.session()\n-        s.params = params\n-\n-        # Make 2 requests from Session object, should send header both times\n-        r1 = get(httpbin('get'), session=s)\n-        self.assertTrue(params['a'] in r1.text)\n-\n-        params2 = {'b': 'b_test'}\n-\n-        r2 = get(httpbin('get'), params=params2, session=s)\n-        for param in (params['a'], params2['b']):\n-            self.assertTrue(param in r2.text)\n-\n-        params3 = {'b': 'b_test', 'a': None, 'c': 'c_test'}\n-\n-        r3 = get(httpbin('get'), params=params3, session=s)\n-\n-        self.assertFalse(params['a'] in r3.text)\n-\n-        for param in (params3['b'], params3['c']):\n-            self.assertTrue(param in r3.text)\n-\n-    def test_session_cookies_with_return_response_false(self):\n-        s = requests.session()\n-        # return_response=False as it does requests.async.get\n-        rq = get(httpbin('cookies', 'set', 'k', 'v'), return_response=False,\n-                 allow_redirects=True, session=s)\n-        rq.send(prefetch=True)\n-        c = rq.response.json.get('cookies')\n-        self.assertTrue('k' in c)\n-        self.assertTrue('k' in s.cookies)\n-\n-    def test_session_pickling(self):\n-\n-        s = requests.session(\n-                headers={'header': 'value'},\n-                cookies={'a-cookie': 'cookie-value'},\n-                auth=('username', 'password'))\n-\n-        ds = pickle.loads(pickle.dumps(s))\n-\n-        self.assertEqual(s.headers, ds.headers)\n-        self.assertEqual(s.auth, ds.auth)\n-\n-        # Cookie doesn't have a good __eq__, so verify manually:\n-        self.assertEqual(len(ds.cookies), 1)\n-        for cookie in ds.cookies:\n-            self.assertCookieHas(cookie, name='a-cookie', value='cookie-value')\n-\n-    def test_unpickled_session_requests(self):\n-        s = requests.session()\n-        r = get(httpbin('cookies', 'set', 'k', 'v'), allow_redirects=True, session=s)\n-        c = json.loads(r.text).get('cookies')\n-        self.assertTrue('k' in c)\n-\n-        ds = pickle.loads(pickle.dumps(s))\n-        r = get(httpbin('cookies'), session=ds)\n-        c = json.loads(r.text).get('cookies')\n-        self.assertTrue('k' in c)\n-\n-        ds1 = pickle.loads(pickle.dumps(requests.session()))\n-        ds2 = pickle.loads(pickle.dumps(requests.session(prefetch=False)))\n-        self.assertTrue(ds1.prefetch)\n-        self.assertFalse(ds2.prefetch)\n-\n-    def test_connection_error(self):\n-        try:\n-            get('http://localhost:1/nope')\n-        except requests.ConnectionError:\n-            pass\n-        else:\n-            self.fail()\n-\n-    def test_cached_response(self):\n-\n-        r1 = get(httpbin('get'), prefetch=False)\n-        self.assertFalse(r1._content)\n-        self.assertTrue(r1.content)\n-        self.assertTrue(r1.text)\n-\n-        r2 = get(httpbin('get'), prefetch=True)\n-        self.assertTrue(r2._content)\n-        self.assertTrue(r2.content)\n-        self.assertTrue(r2.text)\n-\n-    def test_iter_lines(self):\n-\n-        lines = (0, 2, 10, 100)\n-\n-        for i in lines:\n-            r = get(httpbin('stream', str(i)), prefetch=False)\n-            lines = list(r.iter_lines())\n-            len_lines = len(lines)\n-\n-            self.assertEqual(i, len_lines)\n-\n-        # Tests that trailing whitespaces within lines do not get stripped.\n-        # Tests that a trailing non-terminated line does not get stripped.\n-        quote = (\n-            '''Agamemnon  \\n'''\n-            '''\\tWhy will he not upon our fair request\\r\\n'''\n-            '''\\tUntent his person and share the air with us?'''\n-        )\n-\n-        # Make a request and monkey-patch its contents\n-        r = get(httpbin('get'), prefetch=False)\n-        r.raw = StringIO(quote)\n-\n-        lines = list(r.iter_lines())\n-        len_lines = len(lines)\n-        self.assertEqual(len_lines, 3)\n-\n-        joined = lines[0] + '\\n' + lines[1] + '\\r\\n' + lines[2]\n-        self.assertEqual(joined, quote)\n-\n-    def test_permissive_iter_content(self):\n-        \"\"\"Test that iter_content and iter_lines work even after the body has been fetched.\"\"\"\n-        r = get(httpbin('stream', '10'), prefetch=True)\n-        self.assertTrue(r._content_consumed)\n-        # iter_lines should still work without crashing\n-        self.assertEqual(len(list(r.iter_lines())), 10)\n-\n-        # iter_content should return a one-item iterator over the whole content\n-        iter_content_list = list(r.iter_content(chunk_size=1))\n-        self.assertTrue(all(len(item) == 1 for item in iter_content_list))\n-        # when joined, it should be exactly the original content\n-        self.assertEqual(bytes().join(iter_content_list), r.content)\n-\n-        # test different chunk sizes:\n-        for chunk_size in range(2, 20):\n-            self.assertEqual(bytes().join(r.iter_content(chunk_size=chunk_size)), r.content)\n-\n-\n-    def test_upload_binary_data(self):\n-\n-        requests.get(httpbin('post'), auth=('a', 'b'), data='\\xff')\n-\n-    def test_useful_exception_for_invalid_port(self):\n-        # If we pass a legitimate URL with an invalid port, we should fail.\n-        self.assertRaises(\n-              ValueError,\n-              get,\n-              'http://google.com:banana')\n-\n-    def test_useful_exception_for_invalid_scheme(self):\n-\n-        # If we pass a legitimate URL with a scheme not supported\n-        # by requests, we should fail.\n-        self.assertRaises(\n-              ValueError,\n-              get,\n-              'ftp://ftp.kernel.org/pub/')\n-\n-    def test_can_have_none_in_header_values(self):\n-        try:\n-            # Don't choke on headers with none in the value.\n-            requests.get(httpbin('headers'), headers={'Foo': None})\n-        except TypeError:\n-            self.fail('Not able to have none in header values')\n-\n-\n-    def test_empty_response(self):\n-        r = requests.get(httpbin('status', '404'))\n-        r.text\n-\n-    def test_connection_keepalive_and_close(self):\n-        \"\"\"Test that we send 'Connection: close' when keep_alive is disabled.\"\"\"\n-        # keep-alive should be on by default\n-        r1 = requests.get(httpbin('get'))\n-        # XXX due to proxying issues, test the header sent back by httpbin, rather than\n-        # the header reported in its message body. See kennethreitz/httpbin#46\n-        self.assertEqual(r1.headers['Connection'].lower(), 'keep-alive')\n-\n-        # but when we disable it, we should send a 'Connection: close'\n-        # and get the same back:\n-        r2 = requests.get(httpbin('get'), config=dict(keep_alive=False))\n-        self.assertEqual(r2.headers['Connection'].lower(), 'close')\n-\n-    def test_head_content(self):\n-        \"\"\"Test that empty bodies are properly supported.\"\"\"\n-\n-        r = requests.head(httpbin('headers'))\n-        r.content\n-        r.text\n-\n-    def test_post_fields_with_multiple_values_and_files(self):\n-        \"\"\"Test that it is possible to POST using the files argument and a\n-        list for a value in the data argument.\"\"\"\n-\n-        data = {'field': ['a', 'b']}\n-        files = {'field': 'Garbled data'}\n-        r = post(httpbin('post'), data=data, files=files)\n-        t = json.loads(r.text)\n-        self.assertEqual(t.get('form'), {'field': ['a', 'b']})\n-        self.assertEqual(t.get('files'), files)\n-        r = post(httpbin('post'), data=data, files=files.items())\n-        self.assertEqual(t.get('files'), files)\n-\n-    def test_str_data_content_type(self):\n-        data = 'test string data'\n-        r = post(httpbin('post'), data=data)\n-        t = json.loads(r.text)\n-        self.assertEqual(t.get('headers').get('Content-Type'), '')\n-\n-    def test_prefetch_redirect_bug(self):\n-        \"\"\"Test that prefetch persists across redirections.\"\"\"\n-        res = get(httpbin('redirect/2'), prefetch=False)\n-        # prefetch should persist across the redirect;\n-        # the content should not have been consumed\n-        self.assertFalse(res._content_consumed)\n-        first_line = next(res.iter_lines())\n-        self.assertTrue(first_line.strip().decode('utf-8').startswith('{'))\n-\n-    def test_prefetch_return_response_interaction(self):\n-        \"\"\"Test that prefetch can be overridden as a kwarg to `send`.\"\"\"\n-        req = requests.get(httpbin('get'), return_response=False)\n-        req.send(prefetch=False)\n-        # content should not have been prefetched\n-        self.assertFalse(req.response._content_consumed)\n-        first_line = next(req.response.iter_lines())\n-        self.assertTrue(first_line.strip().decode('utf-8').startswith('{'))\n-\n-    def test_accept_objects_with_string_representations_as_urls(self):\n-        \"\"\"Test that URLs can be set to objects with string representations,\n-        e.g. for use with furl.\"\"\"\n-        class URL():\n-            def __unicode__(self):\n-                # Can't have unicode literals in Python3, so avoid them.\n-                # TODO: fixup when moving to Python 3.3\n-                if (sys.version_info[0] == 2):\n-                    return 'http://httpbin.org/get'.decode('utf-8')\n-                else:\n-                    return 'http://httpbin.org/get'\n-\n-            def __str__(self):\n-                return 'http://httpbin.org/get'\n-\n-        r = get(URL())\n-        self.assertEqual(r.status_code, 200)\n-\n-    def test_post_fields_with_multiple_values_and_files_as_tuples(self):\n-        \"\"\"Test that it is possible to POST multiple data and file fields\n-        with the same name.\n-        https://github.com/kennethreitz/requests/pull/746\n-        \"\"\"\n-\n-        fields = [\n-            ('__field__', '__value__'),\n-            ('__field__', '__value__'),\n-        ]\n-\n-        r = post(httpbin('post'), data=fields, files=fields)\n-        t = json.loads(r.text)\n-\n-        self.assertEqual(t.get('form'), {\n-            '__field__': [\n-                '__value__',\n-                '__value__',\n-            ]\n-        })\n-\n-        # It's not currently possible to test for multiple file fields with\n-        # the same name against httpbin so we need to inspect the encoded\n-        # body manually.\n-        request = r.request\n-        body, content_type = request._encode_files(request.files)\n-        file_field = (b'Content-Disposition: form-data;'\n-                      b' name=\"__field__\"; filename=\"__field__\"')\n-        self.assertEqual(body.count(b'__value__'), 4)\n-        self.assertEqual(body.count(file_field), 2)\n-\n-    def test_bytes_files(self):\n-        \"\"\"Test that `bytes` can be used as the values of `files`.\"\"\"\n-        post(httpbin('post'), files={'test': b'test'})\n-\n-    def test_invalid_urls_throw_requests_exception(self):\n-        \"\"\"Test that URLs with invalid labels throw\n-        Requests.exceptions.InvalidURL instead of UnicodeError.\"\"\"\n-        self.assertRaises(InvalidURL, get, 'http://.google.com/')\n-\n-    def test_none_vals_in_data_are_deleted(self):\n-        \"\"\"Test that keys with None as the value are removed instead of\n-        being posted.\"\"\"\n-        data = {'key1': 'value1', 'key2': None}\n-        r = post(httpbin('post'), data=data)\n-        vals = r.json['form']\n-        self.assertEqual(vals['key1'], 'value1')\n-        # The 'key2' key should not have been sent.\n-        self.assertTrue(vals.get('key2') is None)\n-\n-if __name__ == '__main__':\n-    unittest.main()\n\n@@ -1,124 +0,0 @@\n-#!/usr/bin/env python\n-# -*- coding: utf-8 -*-\n-\n-# Path hack.\n-import os\n-import sys\n-sys.path.insert(0, os.path.abspath('..'))\n-\n-import unittest\n-\n-import requests\n-from requests.compat import is_py2, is_py3\n-\n-try:\n-    import omnijson as json\n-except ImportError:\n-    import json\n-\n-\n-class RequestsTestSuite(unittest.TestCase):\n-    \"\"\"Requests test cases.\"\"\"\n-\n-    # It goes to eleven.\n-    _multiprocess_can_split_ = True\n-\n-    def test_addition(self):\n-        self.assertEqual(2, 1 + 1)\n-\n-    def test_ssl_hostname_ok(self):\n-        requests.get('https://github.com', verify=True)\n-\n-    def test_ssl_hostname_not_ok(self):\n-        requests.get('https://kennethreitz.com', verify=False)\n-\n-        self.assertRaises(requests.exceptions.SSLError, requests.get, 'https://kennethreitz.com')\n-\n-    def test_ssl_hostname_session_not_ok(self):\n-\n-        s = requests.session()\n-\n-        self.assertRaises(requests.exceptions.SSLError, s.get, 'https://kennethreitz.com')\n-\n-        s.get('https://kennethreitz.com', verify=False)\n-\n-    def test_binary_post(self):\n-        '''We need to be careful how we build the utf-8 string since\n-        unicode literals are a syntax error in python3\n-        '''\n-\n-        if is_py2:\n-            # Blasphemy!\n-            utf8_string = eval(\"u'Smörgås'.encode('utf-8')\")\n-        elif is_py3:\n-            utf8_string = 'Smörgås'.encode('utf-8')\n-        else:\n-            raise EnvironmentError('Flesh out this test for your environment.')\n-        requests.post('http://www.google.com/', data=utf8_string)\n-\n-    def test_unicode_error(self):\n-        url = 'http://blip.fm/~1abvfu'\n-        requests.get(url)\n-\n-    def test_chunked_head_redirect(self):\n-        url = \"http://t.co/NFrx0zLG\"\n-        r = requests.head(url, allow_redirects=True)\n-        self.assertEqual(r.status_code, 200)\n-\n-    def test_unicode_redirect(self):\n-        '''This url redirects to a location that has a nonstandard\n-        character in it, that breaks requests in python2.7\n-\n-        After some research, the cause was identified as an unintended\n-        sideeffect of overriding of str with unicode.\n-\n-        In the case that the redirected url is actually a malformed\n-        \"bytes\" object, i.e. a string with character c where\n-            ord(c) > 127,\n-        then unicode(url) breaks.\n-        '''\n-        r = requests.get('http://www.marketwire.com/mw/release.' +\n-                         'do?id=1628202&sourceType=3')\n-        self.assertTrue(r.ok)\n-\n-    def test_unicode_url_outright(self):\n-        '''This url visits in my browser'''\n-        r = requests.get('http://www.marketwire.com/press-release/' +\n-                         'jp-morgan-behauptet-sich-der-spitze-euro' +\n-                         'p%C3%A4ischer-anleihe-analysten-laut-umf' +\n-                         'rageergebnissen-1628202.htm')\n-        self.assertTrue(r.ok)\n-\n-    def test_redirect_encoding(self):\n-        '''This url redirects to\n-        http://www.dealipedia.com/deal_view_investment.php?r=20012'''\n-\n-        r = requests.get('http://feedproxy.google.com/~r/Dealipedia' +\n-                         'News/~3/BQtUJRJeZlo/deal_view_investment.' +\n-                         'php')\n-        self.assertTrue(r.ok)\n-\n-    def test_cookies_on_redirects(self):\n-        \"\"\"Test interaction between cookie handling and redirection.\"\"\"\n-        # get a cookie for tinyurl.com ONLY\n-        s = requests.session()\n-        s.get(url='http://tinyurl.com/preview.php?disable=1')\n-        # we should have set a cookie for tinyurl: preview=0\n-        self.assertTrue('preview' in s.cookies)\n-        self.assertEqual(s.cookies['preview'], '0')\n-        self.assertEqual(list(s.cookies)[0].name, 'preview')\n-        self.assertEqual(list(s.cookies)[0].domain, 'tinyurl.com')\n-\n-        # get cookies on another domain\n-        r2 = s.get(url='http://httpbin.org/cookies')\n-        # the cookie is not there\n-        self.assertTrue('preview' not in json.loads(r2.text)['cookies'])\n-\n-        # this redirects to another domain, httpbin.org\n-        # cookies of the first domain should NOT be sent to the next one\n-        r3 = s.get(url='http://tinyurl.com/7zp3jnr')\n-        self.assertEqual(r3.url, 'http://httpbin.org/cookies')\n-        self.assertTrue('preview' not in json.loads(r3.text)['cookies'])\n-\n-if __name__ == '__main__':\n-    unittest.main()\n\n@@ -1,32 +0,0 @@\n-#!/usr/bin/env python\n-# -*- coding: utf-8 -*-\n-\n-import os\n-import sys\n-import unittest\n-\n-# Path hack.\n-sys.path.insert(0, os.path.abspath('..'))\n-import requests\n-\n-\n-class HTTPSTest(unittest.TestCase):\n-    \"\"\"Smoke test for https functionality.\"\"\"\n-\n-    smoke_url = \"https://github.com\"\n-\n-    def perform_smoke_test(self, verify=False):\n-        result = requests.get(self.smoke_url, verify=verify)\n-        self.assertEqual(result.status_code, 200)\n-\n-    def test_smoke(self):\n-        \"\"\"Smoke test without verification.\"\"\"\n-        self.perform_smoke_test(verify=False)\n-\n-    def test_smoke_verified(self):\n-        \"\"\"Smoke test with SSL verification.\"\"\"\n-        self.perform_smoke_test(verify=True)\n-\n-\n-if __name__ == '__main__':\n-    unittest.main()\n\n@@ -1,122 +0,0 @@\n-#!/usr/bin/env python\n-# -*- coding: utf-8 -*-\n-\n-import codecs\n-import os\n-import sys\n-import unittest\n-import random\n-\n-# Path hack.\n-sys.path.insert(0, os.path.abspath('..'))\n-from requests.utils import get_environ_proxies\n-import requests.utils\n-from requests.compat import is_py3, bytes\n-\n-\n-if is_py3:\n-    unichr = chr\n-    byteschr = lambda c: bytes([c])\n-else:\n-    byteschr = chr\n-\n-\n-class UtilityTests(unittest.TestCase):\n-    \"\"\"Tests for the JSON UTF encoding guessing code.\"\"\"\n-\n-    codecs = (\n-        'utf-8', 'utf-8-sig',\n-        'utf-16', 'utf-16-le', 'utf-16-be',\n-        'utf-32', 'utf-32-le', 'utf-32-be'\n-    )\n-\n-    def test_guess_encoding(self):\n-        # Throw 4-character ASCII strings (encoded to a UTF encoding)\n-        # at the guess routine; it should correctly guess all codecs.\n-        guess = requests.utils.guess_json_utf\n-        for c in range(33, 127):  # printable only\n-            sample = unichr(c) * 4\n-            for codec in self.codecs:\n-                res = guess(sample.encode(codec))\n-                self.assertEqual(res, codec)\n-\n-    def test_smoke_encoding(self):\n-        # Throw random 4-byte strings at the guess function.\n-        # Any guess for a UTF encoding is verified, a decode exception\n-        # is a test failure.\n-        guess = requests.utils.guess_json_utf\n-        for i in range(1000):\n-            sample = bytes().join(\n-                [byteschr(random.randrange(256)) for _ in range(4)])\n-            res = guess(sample)\n-            if res is not None:\n-                # This should decode without errors if this is *really*\n-                # something in this encoding. However, UTF-8 is a lot\n-                # more picky, so we expect errors there. UTF-16 surrogate\n-                # pairs also fail\n-                try:\n-                    sample.decode(res)\n-                except UnicodeDecodeError as e:\n-                    self.assertEqual(e.args[0].replace('-', '').lower(),\n-                                     res.replace('-', '').lower())\n-                    if res == 'utf-8':\n-                        self.assertTrue(e.args[-1], (\n-                            'invalid continuation byte',\n-                            'invalid start byte'))\n-                        continue\n-                    if res == 'utf-16':\n-                        self.assertEqual(e.args[-1], 'unexpected end of data')\n-                        self.assertTrue(sample[:2] in (\n-                            codecs.BOM_UTF16_LE, codecs.BOM_UTF16_BE))\n-                        # the second two bytes are in the range \\ud800-\\udfff\n-                        # if someone wants to add tests for that as well. I don't\n-                        # see the need; we are not testing UTF decoding here.\n-                        continue\n-                    raise\n-\n-    def test_get_environ_proxies_respects_no_proxy(self):\n-        '''This test confirms that the no_proxy environment setting is\n-        respected by get_environ_proxies().'''\n-\n-        # Store the current environment settings.\n-        try:\n-            old_http_proxy = os.environ['http_proxy']\n-        except KeyError:\n-            old_http_proxy = None\n-\n-        try:\n-            old_no_proxy = os.environ['no_proxy']\n-        except KeyError:\n-            old_no_proxy = None\n-\n-        # Set up some example environment settings.\n-        os.environ['http_proxy'] = 'http://www.example.com/'\n-        os.environ['no_proxy'] = r'localhost,.0.0.1:8080'\n-\n-        # Set up expected proxy return values.\n-        proxy_yes = {'http': 'http://www.example.com/'}\n-        proxy_no = {}\n-\n-        # Check that we get the right things back.\n-        self.assertEqual(proxy_yes,\n-                         get_environ_proxies('http://www.google.com/'))\n-        self.assertEqual(proxy_no,\n-                         get_environ_proxies('http://localhost/test'))\n-        self.assertEqual(proxy_no,\n-                         get_environ_proxies('http://127.0.0.1:8080/'))\n-        self.assertEqual(proxy_yes,\n-                         get_environ_proxies('http://127.0.0.1:8081/'))\n-\n-        # Return the settings to what they were.\n-        if old_http_proxy:\n-            os.environ['http_proxy'] = old_http_proxy\n-        else:\n-            del os.environ['http_proxy']\n-\n-        if old_no_proxy:\n-            os.environ['no_proxy'] = old_no_proxy\n-        else:\n-            del os.environ['no_proxy']\n-\n-if __name__ == '__main__':\n-    unittest.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
