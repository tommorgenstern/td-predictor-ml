{"custom_id": "scrapy#104027d78d10592a395ffeb8f34ac9fc0ae1702f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 215 | Contributors (this commit): 6 | Commits (past 90d): 7 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -200,9 +200,9 @@ class MySpider(scrapy.Spider):\n         self.assertIn(\"File not found: some_non_existent_file\", log)\n \n     def test_runspider_unable_to_load(self):\n-        p = self.runspider(\"\", \"myspider.txt\")\n+        p = self.runspider('', 'myspider.txt')\n         log = to_native_str(p.stderr.read())\n-        self.assertIn(\"Unable to load\", log)\n+        self.assertIn('Unable to load', log)\n \n     def test_start_requests_errors(self):\n         p = self.runspider(\"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#30a27effa9b20eb5cf410e00840a56286a2e8d92", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 53 | Lines Deleted: 9 | Files Changed: 1 | Hunks: 5 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 62 | Churn Cumulative: 90 | Contributors (this commit): 3 | Commits (past 90d): 1 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,22 +1,48 @@\n from OpenSSL import SSL\n from twisted.internet.ssl import ClientContextFactory\n-try:\n-    # available since twisted 14.0\n-    from twisted.internet._sslverify import ClientTLSOptions\n-except ImportError:\n-    ClientTLSOptions = None\n+\n+from scrapy import twisted_version\n+\n+if twisted_version >= (14, 0, 0):\n+\n+    from twisted.web.client import BrowserLikePolicyForHTTPS\n+    from twisted.internet.ssl import optionsForClientTLS\n+\n+    class ScrapyClientContextFactory(BrowserLikePolicyForHTTPS):\n+        \"\"\"\n+        Using Twisted recommended context factory for twisted.web.client.Agent\n+\n+        Quoting:\n+        \"The default is to use a BrowserLikePolicyForHTTPS,\n+        so unless you have special requirements you can leave this as-is.\"\n+\n+        See http://twistedmatrix.com/documents/current/api/twisted.web.client.Agent.html\n+        \"\"\"\n \n \n-class ScrapyClientContextFactory(ClientContextFactory):\n+    class OpenSSLMethodContextFactory(ScrapyClientContextFactory):\n+\n+        openssl_method = SSL.SSLv23_METHOD\n+\n+        def creatorForNetloc(self, hostname, port):\n+            return optionsForClientTLS(hostname.decode(\"ascii\"),\n+                                       trustRoot=self._trustRoot,\n+                                       extraCertificateOptions={\n+                                            'method': self.openssl_method\n+                                       })\n+\n+\n+else:\n+\n+    class OpenSSLMethodContextFactory(ClientContextFactory):\n         \"A SSL context factory which is more permissive against SSL bugs.\"\n         # see https://github.com/scrapy/scrapy/issues/82\n         # and https://github.com/scrapy/scrapy/issues/26\n         # and https://github.com/scrapy/scrapy/issues/981\n+        openssl_method = SSL.SSLv23_METHOD\n \n         def __init__(self):\n-        # see this issue on why we use TLSv1_METHOD by default\n-        # https://github.com/scrapy/scrapy/issues/194\n-        self.method = SSL.TLSv1_METHOD\n+            self.method = self.openssl_method\n \n         def getContext(self, hostname=None, port=None):\n             ctx = ClientContextFactory.getContext(self)\n@@ -26,3 +52,21 @@ class ScrapyClientContextFactory(ClientContextFactory):\n             if hostname and ClientTLSOptions is not None: # workaround for TLS SNI\n                 ClientTLSOptions(hostname, ctx)\n             return ctx\n+\n+    ScrapyClientContextFactory = OpenSSLMethodContextFactory\n+\n+\n+class SSLv3ContextFactory(OpenSSLMethodContextFactory):\n+    openssl_method = SSL.SSLv3_METHOD\n+\n+\n+class TLSv1ContextFactory(OpenSSLMethodContextFactory):\n+    openssl_method = SSL.TLSv1_METHOD\n+\n+\n+class TLSv11ContextFactory(OpenSSLMethodContextFactory):\n+    openssl_method = SSL.TLSv1_1_METHOD\n+\n+\n+class TLSv12ContextFactory(OpenSSLMethodContextFactory):\n+    openssl_method = SSL.TLSv1_2_METHOD\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#45f972cb3f664705fefc932f34a1e88134819fb4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 4 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 95 | Contributors (this commit): 3 | Commits (past 90d): 2 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -5,9 +5,11 @@ from scrapy import twisted_version\n \n if twisted_version >= (14, 0, 0):\n \n-    from twisted.web.client import BrowserLikePolicyForHTTPS\n     from twisted.internet.ssl import optionsForClientTLS\n+    from twisted.web.client import BrowserLikePolicyForHTTPS\n+    from twisted.web.iweb import IPolicyForHTTPS\n \n+    @implementer(IPolicyForHTTPS)\n     class ScrapyClientContextFactory(BrowserLikePolicyForHTTPS):\n         \"\"\"\n         Using Twisted recommended context factory for twisted.web.client.Agent\n@@ -20,6 +22,7 @@ if twisted_version >= (14, 0, 0):\n         \"\"\"\n \n \n+    @implementer(IPolicyForHTTPS)\n     class OpenSSLMethodContextFactory(ScrapyClientContextFactory):\n \n         openssl_method = SSL.SSLv23_METHOD\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#406b9a06fe67db09b53041724a126d59f11cb519", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 105 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -5,6 +5,8 @@ from scrapy import twisted_version\n \n if twisted_version >= (14, 0, 0):\n \n+    from zope.interface.declarations import implementer\n+\n     from twisted.internet.ssl import optionsForClientTLS\n     from twisted.web.client import BrowserLikePolicyForHTTPS\n     from twisted.web.iweb import IPolicyForHTTPS\n@@ -65,11 +67,3 @@ class SSLv3ContextFactory(OpenSSLMethodContextFactory):\n \n class TLSv1ContextFactory(OpenSSLMethodContextFactory):\n     openssl_method = SSL.TLSv1_METHOD\n-\n-\n-class TLSv11ContextFactory(OpenSSLMethodContextFactory):\n-    openssl_method = SSL.TLSv1_1_METHOD\n-\n-\n-class TLSv12ContextFactory(OpenSSLMethodContextFactory):\n-    openssl_method = SSL.TLSv1_2_METHOD\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#18a381816d1e2e4a08e8c8655fa38f9bb0af312f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1483 | Contributors (this commit): 10 | Commits (past 90d): 3 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -87,7 +87,7 @@ class Crawler(object):\n                 yield self.engine.close()\n \n             if six.PY2:\n-                raise six.reraise(*exc_info)\n+                six.reraise(*exc_info)\n             raise\n \n     def _create_spider(self, *args, **kwargs):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#5f5374209f520edf80c5a414cc45033c3ed75a0f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): -4/0 | Churn Δ: 4 | Churn Cumulative: 398 | Contributors (this commit): 15 | Commits (past 90d): 1 | Contributors (cumulative): 15 | DMM Complexity: None\n\nDIFF:\n@@ -31,7 +31,7 @@ def arg_to_iter(arg):\n def load_object(path):\n     \"\"\"Load an object given its absolute object path, and return it.\n \n-    object can be a class, function, variable o instance.\n+    object can be a class, function, variable or an instance.\n     path ie: 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware'\n     \"\"\"\n \n@@ -52,7 +52,7 @@ def load_object(path):\n \n \n def walk_modules(path):\n-    \"\"\"Loads a module and all its submodules from a the given module path and\n+    \"\"\"Loads a module and all its submodules from the given module path and\n     returns them. If *any* module throws an exception while importing, that\n     exception is thrown back.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#523e98dabe01842b9103fdb750237f5a6275963b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 55 | Contributors (this commit): 3 | Commits (past 90d): 1 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -19,7 +19,7 @@ def listen_tcp(portrange, host, factory):\n \n class CallLaterOnce(object):\n     \"\"\"Schedule a function to be called in the next reactor loop, but only if\n-    it hasn't been already scheduled since the last time it run.\n+    it hasn't been already scheduled since the last time it ran.\n     \"\"\"\n \n     def __init__(self, func, *a, **kw):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#57990fba7a12a83517456487979df6461a347328", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 75 | Lines Deleted: 26 | Files Changed: 5 | Hunks: 22 | Methods Changed: 8 | Complexity Δ (Sum/Max): 5/4 | Churn Δ: 101 | Churn Cumulative: 2013 | Contributors (this commit): 32 | Commits (past 90d): 27 | Contributors (cumulative): 47 | DMM Complexity: 1.0\n\nDIFF:\n@@ -7,47 +7,79 @@ if twisted_version >= (14, 0, 0):\n \n     from zope.interface.declarations import implementer\n \n-    from twisted.internet.ssl import optionsForClientTLS\n+    from twisted.internet.ssl import optionsForClientTLS, CertificateOptions, platformTrust\n+    from twisted.internet._sslverify import ClientTLSOptions\n     from twisted.web.client import BrowserLikePolicyForHTTPS\n     from twisted.web.iweb import IPolicyForHTTPS\n \n     @implementer(IPolicyForHTTPS)\n     class ScrapyClientContextFactory(BrowserLikePolicyForHTTPS):\n         \"\"\"\n-        Using Twisted recommended context factory for twisted.web.client.Agent\n+        Non-peer-certificate verifying HTTPS context factory\n \n-        Quoting:\n-        \"The default is to use a BrowserLikePolicyForHTTPS,\n-        so unless you have special requirements you can leave this as-is.\"\n+        Default OpenSSL method is TLS_METHOD (also called SSLv23_METHOD)\n+        which allows TLS protocol negotiation\n \n-        See http://twistedmatrix.com/documents/current/api/twisted.web.client.Agent.html\n+        'A TLS/SSL connection established with [this method] may\n+         understand the SSLv3, TLSv1, TLSv1.1 and TLSv1.2 protocols.'\n         \"\"\"\n \n+        def __init__(self, method=SSL.SSLv23_METHOD, *args, **kwargs):\n+            super(BrowserLikePolicyForHTTPS, self).__init__(*args, **kwargs)\n+            self._ssl_method = method\n+\n+        def getCertificateOptions(self):\n+            # setting verify=True will require you to provide CAs\n+            # to verify against; in other words: it's not that simple\n+            return CertificateOptions(verify=False, method=self._ssl_method)\n+\n+        # kept for old-style HTTP/1.0 downloader context twisted calls,\n+        # e.g. connectSSL()\n+        def getContext(self, hostname=None, port=None):\n+            return self.getCertificateOptions().getContext()\n+\n+        def creatorForNetloc(self, hostname, port):\n+            return ClientTLSOptions(hostname.decode(\"ascii\"), self.getContext())\n+\n \n     @implementer(IPolicyForHTTPS)\n-    class OpenSSLMethodContextFactory(ScrapyClientContextFactory):\n+    class BrowserLikeContextFactory(ScrapyClientContextFactory):\n+        \"\"\"\n+        Twisted-recommended context factory for web clients.\n \n-        openssl_method = SSL.SSLv23_METHOD\n+        Quoting http://twistedmatrix.com/documents/current/api/twisted.web.client.Agent.html:\n+        \"The default is to use a BrowserLikePolicyForHTTPS,\n+        so unless you have special requirements you can leave this as-is.\"\n \n+        creatorForNetloc() is the same as BrowserLikePolicyForHTTPS\n+        except this context factory allows setting the TLS/SSL method to use.\n+\n+        Default OpenSSL method is TLS_METHOD (also called SSLv23_METHOD)\n+        which allows TLS protocol negotiation.\n+        \"\"\"\n         def creatorForNetloc(self, hostname, port):\n+\n+            # trustRoot set to platformTrust() will use the platform's root CAs.\n+            #\n+            # This means that a website like https://www.cacert.org will be rejected\n+            # by default, since CAcert.org CA certificate is seldom shipped.\n             return optionsForClientTLS(hostname.decode(\"ascii\"),\n-                                       trustRoot=self._trustRoot,\n+                                       trustRoot=platformTrust(),\n                                        extraCertificateOptions={\n-                                            'method': self.openssl_method\n+                                            'method': self._ssl_method,\n                                        })\n \n \n else:\n \n-    class OpenSSLMethodContextFactory(ClientContextFactory):\n+    class ScrapyClientContextFactory(ClientContextFactory):\n         \"A SSL context factory which is more permissive against SSL bugs.\"\n         # see https://github.com/scrapy/scrapy/issues/82\n         # and https://github.com/scrapy/scrapy/issues/26\n         # and https://github.com/scrapy/scrapy/issues/981\n-        openssl_method = SSL.SSLv23_METHOD\n \n-        def __init__(self):\n-            self.method = self.openssl_method\n+        def __init__(self, method=SSL.SSLv23_METHOD):\n+            self.method = method\n \n         def getContext(self, hostname=None, port=None):\n             ctx = ClientContextFactory.getContext(self)\n@@ -57,13 +89,3 @@ else:\n             if hostname and ClientTLSOptions is not None: # workaround for TLS SNI\n                 ClientTLSOptions(hostname, ctx)\n             return ctx\n-\n-    ScrapyClientContextFactory = OpenSSLMethodContextFactory\n-\n-\n-class SSLv3ContextFactory(OpenSSLMethodContextFactory):\n-    openssl_method = SSL.SSLv3_METHOD\n-\n-\n-class TLSv1ContextFactory(OpenSSLMethodContextFactory):\n-    openssl_method = SSL.TLSv1_METHOD\n\n@@ -18,6 +18,7 @@ from scrapy.xlib.tx import Agent, ProxyAgent, ResponseDone, \\\n from scrapy.http import Headers\n from scrapy.responsetypes import responsetypes\n from scrapy.core.downloader.webclient import _parse\n+from scrapy.core.downloader.tls import openssl_methods, METHOD_TLS\n from scrapy.utils.misc import load_object\n from scrapy.utils.python import to_bytes, to_unicode\n from scrapy import twisted_version\n@@ -31,8 +32,16 @@ class HTTP11DownloadHandler(object):\n         self._pool = HTTPConnectionPool(reactor, persistent=True)\n         self._pool.maxPersistentPerHost = settings.getint('CONCURRENT_REQUESTS_PER_DOMAIN')\n         self._pool._factory.noisy = False\n+\n+        self._sslMethod = openssl_methods[settings.get('DOWNLOADER_CLIENT_TLS_METHOD')]\n         self._contextFactoryClass = load_object(settings['DOWNLOADER_CLIENTCONTEXTFACTORY'])\n+        # try method-aware context factory\n+        try:\n+            self._contextFactory = self._contextFactoryClass(method=self._sslMethod)\n+        except TypeError:\n+            # use defaults\n             self._contextFactory = self._contextFactoryClass()\n+\n         self._default_maxsize = settings.getint('DOWNLOAD_MAXSIZE')\n         self._default_warnsize = settings.getint('DOWNLOAD_WARNSIZE')\n         self._disconnect_timeout = 1\n\n@@ -0,0 +1,16 @@\n+from OpenSSL import SSL\n+\n+\n+METHOD_SSLv3 = 'SSLv3'\n+METHOD_TLS = 'TLS'\n+METHOD_TLSv10 = 'TLSv1.0'\n+METHOD_TLSv11 = 'TLSv1.1'\n+METHOD_TLSv12 = 'TLSv1.2'\n+\n+openssl_methods = {\n+    METHOD_TLS: SSL.SSLv23_METHOD,                      # protocol negotiation (recommended)\n+    METHOD_SSLv3: SSL.SSLv3_METHOD,                     # SSL 3 (NOT recommended)\n+    METHOD_TLSv10: SSL.TLSv1_METHOD,                    # TLS 1.0 only\n+    METHOD_TLSv11: getattr(SSL, 'TLSv1_1_METHOD', 5),   # TLS 1.1 only\n+    METHOD_TLSv12: getattr(SSL, 'TLSv1_2_METHOD', 6),   # TLS 1.2 only\n+}\n\n@@ -83,6 +83,8 @@ DOWNLOADER = 'scrapy.core.downloader.Downloader'\n \n DOWNLOADER_HTTPCLIENTFACTORY = 'scrapy.core.downloader.webclient.ScrapyHTTPClientFactory'\n DOWNLOADER_CLIENTCONTEXTFACTORY = 'scrapy.core.downloader.contextfactory.ScrapyClientContextFactory'\n+DOWNLOADER_CLIENT_TLS_METHOD = 'TLS' # Use highest TLS/SSL protocol version supported by the platform,\n+                                     # also allowing negotiation\n \n DOWNLOADER_MIDDLEWARES = {}\n \n\n@@ -206,8 +206,8 @@ class MockServer():\n \n def ssl_context_factory():\n     return ssl.DefaultOpenSSLContextFactory(\n-         os.path.join(os.path.dirname(__file__), 'keys/cert.pem'),\n-         os.path.join(os.path.dirname(__file__), 'keys/cert.pem'),\n+         os.path.join(os.path.dirname(__file__), 'keys/server.pem'),\n+         os.path.join(os.path.dirname(__file__), 'keys/server.pem'),\n          )\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#49c757f208eb41e637171543b5b337f4a280387a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 9 | Files Changed: 2 | Hunks: 5 | Methods Changed: 2 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 14 | Churn Cumulative: 308 | Contributors (this commit): 6 | Commits (past 90d): 13 | Contributors (cumulative): 9 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1,12 +1,11 @@\n from OpenSSL import SSL\n from twisted.internet.ssl import ClientContextFactory\n \n-from scrapy import twisted_version\n-\n-if twisted_version >= (14, 0, 0):\n+try:\n \n     from zope.interface.declarations import implementer\n \n+    # the following should be available from Twisted 14.0.0\n     from twisted.internet.ssl import optionsForClientTLS, CertificateOptions, platformTrust\n     from twisted.internet._sslverify import ClientTLSOptions\n     from twisted.web.client import BrowserLikePolicyForHTTPS\n@@ -69,8 +68,7 @@ if twisted_version >= (14, 0, 0):\n                                             'method': self._ssl_method,\n                                        })\n \n-\n-else:\n+except ImportError:\n \n     class ScrapyClientContextFactory(ClientContextFactory):\n         \"A SSL context factory which is more permissive against SSL bugs.\"\n@@ -86,6 +84,4 @@ else:\n             # Enable all workarounds to SSL bugs as documented by\n             # http://www.openssl.org/docs/ssl/SSL_CTX_set_options.html\n             ctx.set_options(SSL.OP_ALL)\n-            if hostname and ClientTLSOptions is not None: # workaround for TLS SNI\n-                ClientTLSOptions(hostname, ctx)\n             return ctx\n\n@@ -206,8 +206,8 @@ class MockServer():\n \n def ssl_context_factory():\n     return ssl.DefaultOpenSSLContextFactory(\n-         os.path.join(os.path.dirname(__file__), 'keys/server.pem'),\n-         os.path.join(os.path.dirname(__file__), 'keys/server.pem'),\n+         os.path.join(os.path.dirname(__file__), 'keys/cert.pem'),\n+         os.path.join(os.path.dirname(__file__), 'keys/cert.pem'),\n          )\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#3f946b5278cb964ce1dab1b6e8a3a74e16d00fca", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 187 | Contributors (this commit): 3 | Commits (past 90d): 6 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -24,7 +24,7 @@ try:\n         \"\"\"\n \n         def __init__(self, method=SSL.SSLv23_METHOD, *args, **kwargs):\n-            super(BrowserLikePolicyForHTTPS, self).__init__(*args, **kwargs)\n+            super(ScrapyClientContextFactory, self).__init__(*args, **kwargs)\n             self._ssl_method = method\n \n         def getCertificateOptions(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#6174192564250d715ffa69b492bc58a901fba07f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 47 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 4 | Methods Changed: 5 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 48 | Churn Cumulative: 1820 | Contributors (this commit): 15 | Commits (past 90d): 38 | Contributors (cumulative): 20 | DMM Complexity: 1.0\n\nDIFF:\n@@ -209,7 +209,21 @@ class ScrapyAgent(object):\n         headers = TxHeaders(request.headers)\n         if isinstance(agent, self._TunnelingAgent):\n             headers.removeHeader(b'Proxy-Authorization')\n-        bodyproducer = _RequestBodyProducer(request.body) if request.body else None\n+        if request.body:\n+            bodyproducer = _RequestBodyProducer(request.body)\n+        else:\n+            bodyproducer = None\n+            # Setting Content-Length: 0 even for POST requests is not a\n+            # MUST per HTTP RFCs, but it's common behavior, and some\n+            # server require this otherwise returing HTTP 411\n+            #\n+            # RFC 7230#section-3.3.2:\n+            # \"a Content-Length header field is normally sent in a POST\n+            # request even when the value is 0 (indicating an empty payload body).\"\n+            #\n+            # Twisted Agent will not add \"Content-Length: 0\" by itself\n+            if method == b'POST':\n+                headers.addRawHeader(b'Content-Length', b'0')\n \n         start_time = time()\n         d = agent.request(\n\n@@ -105,6 +105,15 @@ class FileTestCase(unittest.TestCase):\n         return self.assertFailure(d, IOError)\n \n \n+class ContentLengthHeaderResource(resource.Resource):\n+    \"\"\"\n+    A testing resource which renders itself as the value of the Content-Length\n+    header from the request.\n+    \"\"\"\n+    def render(self, request):\n+        return request.requestHeaders.getRawHeaders(b\"content-length\")[0]\n+\n+\n class HttpTestCase(unittest.TestCase):\n \n     scheme = 'http'\n@@ -122,6 +131,7 @@ class HttpTestCase(unittest.TestCase):\n         r.putChild(b\"host\", HostHeaderResource())\n         r.putChild(b\"payload\", PayloadResource())\n         r.putChild(b\"broken\", BrokenDownloadResource())\n+        r.putChild(b\"contentlength\", ContentLengthHeaderResource())\n         self.site = server.Site(r, timeout=None)\n         self.wrapper = WrappingFactory(self.site)\n         self.host = 'localhost'\n@@ -209,6 +219,28 @@ class HttpTestCase(unittest.TestCase):\n         d.addCallback(self.assertEquals, b'example.com')\n         return d\n \n+    def test_content_length_zero_bodyless_post_request_headers(self):\n+        \"\"\"Tests if \"Content-Length: 0\" is sent for bodyless POST requests.\n+\n+        This is not strictly required by HTTP RFCs but can cause trouble\n+        for some web servers.\n+        See:\n+        https://github.com/scrapy/scrapy/issues/823\n+        https://issues.apache.org/jira/browse/TS-2902\n+        https://github.com/kennethreitz/requests/issues/405\n+        https://bugs.python.org/issue14721\n+        \"\"\"\n+        def _test(response):\n+            self.assertEquals(response.body, b'0')\n+\n+        request = Request(self.getURL('contentlength'), method='POST', headers={'Host': 'example.com'})\n+        return self.download_request(request, Spider('foo')).addCallback(_test)\n+\n+        d = self.download_request(request, Spider('foo'))\n+        d.addCallback(lambda r: r.body)\n+        d.addCallback(self.assertEquals, b'0')\n+        return d\n+\n     def test_payload(self):\n         body = b'1'*100 # PayloadResource requires body length to be 100\n         request = Request(self.getURL('payload'), method='POST', body=body)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#ac8f97c33bccc7647d80d9c3ccdf1eafc22636e3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1281 | Contributors (this commit): 12 | Commits (past 90d): 14 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -215,7 +215,7 @@ class ScrapyAgent(object):\n             bodyproducer = None\n             # Setting Content-Length: 0 even for POST requests is not a\n             # MUST per HTTP RFCs, but it's common behavior, and some\n-            # server require this otherwise returing HTTP 411\n+            # servers require this, otherwise returning HTTP 411 Length required\n             #\n             # RFC 7230#section-3.3.2:\n             # \"a Content-Length header field is normally sent in a POST\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#e9bd328936e1d0172fd89033f0b847c63045423a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 250 | Contributors (this commit): 9 | Commits (past 90d): 5 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -24,7 +24,7 @@ def skip_if_no_boto():\n     try:\n         is_botocore()\n     except NotConfigured as e:\n-        raise SkipTest(e.message)\n+        raise SkipTest(str(e))\n \n def get_s3_content_and_delete(bucket, path, with_key=False):\n     \"\"\" Get content from s3 key, and delete key afterwards.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#ad4c1169c49c0ac6becb070ef4fab1439a9eda6b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 252 | Contributors (this commit): 9 | Commits (past 90d): 6 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -24,7 +24,7 @@ def skip_if_no_boto():\n     try:\n         is_botocore()\n     except NotConfigured as e:\n-        raise SkipTest(str(e))\n+        raise SkipTest(e)\n \n def get_s3_content_and_delete(bucket, path, with_key=False):\n     \"\"\" Get content from s3 key, and delete key afterwards.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#35fb630c4ec6c996a90cc4f50085275525ec9105", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 8 | Churn Cumulative: 1289 | Contributors (this commit): 12 | Commits (past 90d): 15 | Contributors (cumulative): 12 | DMM Complexity: 1.0\n\nDIFF:\n@@ -92,9 +92,11 @@ class TunnelingTCP4ClientEndpoint(TCP4ClientEndpoint):\n \n     def requestTunnel(self, protocol):\n         \"\"\"Asks the proxy to open a tunnel.\"\"\"\n-        tunnelReq = to_bytes(\n-            'CONNECT %s:%s HTTP/1.1\\r\\n' % (\n-                self._tunneledHost, self._tunneledPort), encoding='ascii')\n+        tunnelReq = (\n+            b'CONNECT ' +\n+            to_bytes(self._tunneledHost, encoding='ascii') + b':' +\n+            to_bytes(str(self._tunneledPort)) +\n+            b' HTTP/1.1\\r\\n')\n         if self._proxyAuthHeader:\n             tunnelReq += \\\n                 b'Proxy-Authorization: ' + self._proxyAuthHeader + b'\\r\\n'\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#095495e99ce327d0fc6cf2064f8a6d871d2f7dd1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 13 | Churn Cumulative: 200 | Contributors (this commit): 3 | Commits (past 90d): 7 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -30,7 +30,18 @@ try:\n         def getCertificateOptions(self):\n             # setting verify=True will require you to provide CAs\n             # to verify against; in other words: it's not that simple\n-            return CertificateOptions(verify=False, method=self._ssl_method)\n+\n+            # backward-compatible SSL/TLS method:\n+            #\n+            # * this will respect `method` attribute in often recommended\n+            #   `ScrapyClientContextFactory` subclass\n+            #   (https://github.com/scrapy/scrapy/issues/1429#issuecomment-131782133)\n+            #\n+            # * getattr() for `_ssl_method` attribute for context factories\n+            #   not calling super(..., self).__init__\n+            return CertificateOptions(verify=False,\n+                        method=getattr(self, 'method',\n+                                       getattr(self, '_ssl_method', None)))\n \n         # kept for old-style HTTP/1.0 downloader context twisted calls,\n         # e.g. connectSSL()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#c9890d5f7662dc2673696ceb80870c5318746495", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 4 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 10 | Churn Cumulative: 1299 | Contributors (this commit): 12 | Commits (past 90d): 16 | Contributors (cumulative): 12 | DMM Complexity: 1.0\n\nDIFF:\n@@ -4,6 +4,7 @@ import re\n import logging\n from io import BytesIO\n from time import time\n+import warnings\n from six.moves.urllib.parse import urldefrag\n \n from zope.interface import implementer\n@@ -18,7 +19,7 @@ from scrapy.xlib.tx import Agent, ProxyAgent, ResponseDone, \\\n from scrapy.http import Headers\n from scrapy.responsetypes import responsetypes\n from scrapy.core.downloader.webclient import _parse\n-from scrapy.core.downloader.tls import openssl_methods, METHOD_TLS\n+from scrapy.core.downloader.tls import openssl_methods\n from scrapy.utils.misc import load_object\n from scrapy.utils.python import to_bytes, to_unicode\n from scrapy import twisted_version\n@@ -39,9 +40,12 @@ class HTTP11DownloadHandler(object):\n         try:\n             self._contextFactory = self._contextFactoryClass(method=self._sslMethod)\n         except TypeError:\n-            # use defaults\n+            # use context factory defaults\n             self._contextFactory = self._contextFactoryClass()\n-\n+            warnings.warn(\"\"\"\n+    You are using a context factory class that does not accept the `method` argument\n+    (type OpenSSL.SSL method, e.g. OpenSSL.SSL.SSLv23_METHOD).\n+    Please upgrade your context factory class to handle or ignore it.\"\"\")\n         self._default_maxsize = settings.getint('DOWNLOAD_MAXSIZE')\n         self._default_warnsize = settings.getint('DOWNLOAD_WARNSIZE')\n         self._disconnect_timeout = 1\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#164f300762297bb6069a25cfc1cbb819e1bff9ec", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 583 | Contributors (this commit): 26 | Commits (past 90d): 7 | Contributors (cumulative): 29 | DMM Complexity: 1.0\n\nDIFF:\n@@ -82,7 +82,8 @@ class S3FilesStore(object):\n     AWS_ACCESS_KEY_ID = None\n     AWS_SECRET_ACCESS_KEY = None\n \n-    POLICY = 'public-read'\n+    POLICY = 'private'  # Overriden from settings.S3_STORE_ACL in\n+                        # FilesPipeline.from_settings.\n     HEADERS = {\n         'Cache-Control': 'max-age=172800',\n     }\n@@ -232,6 +233,7 @@ class FilesPipeline(MediaPipeline):\n         s3store = cls.STORE_SCHEMES['s3']\n         s3store.AWS_ACCESS_KEY_ID = settings['AWS_ACCESS_KEY_ID']\n         s3store.AWS_SECRET_ACCESS_KEY = settings['AWS_SECRET_ACCESS_KEY']\n+        s3store.POLICY = settings['S3_STORE_ACL']\n \n         cls.FILES_URLS_FIELD = settings.get('FILES_URLS_FIELD', cls.DEFAULT_FILES_URLS_FIELD)\n         cls.FILES_RESULT_FIELD = settings.get('FILES_RESULT_FIELD', cls.DEFAULT_FILES_RESULT_FIELD)\n\n@@ -231,6 +231,8 @@ SCHEDULER = 'scrapy.core.scheduler.Scheduler'\n SCHEDULER_DISK_QUEUE = 'scrapy.squeues.PickleLifoDiskQueue'\n SCHEDULER_MEMORY_QUEUE = 'scrapy.squeues.LifoMemoryQueue'\n \n+S3_STORE_ACL = 'private'\n+\n SPIDER_LOADER_CLASS = 'scrapy.spiderloader.SpiderLoader'\n \n SPIDER_MIDDLEWARES = {}\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#6137dd96d9b52e1a4e4e28dd64924f877a63329f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 4 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 591 | Contributors (this commit): 26 | Commits (past 90d): 9 | Contributors (cumulative): 29 | DMM Complexity: None\n\nDIFF:\n@@ -82,7 +82,7 @@ class S3FilesStore(object):\n     AWS_ACCESS_KEY_ID = None\n     AWS_SECRET_ACCESS_KEY = None\n \n-    POLICY = 'private'  # Overriden from settings.S3_STORE_ACL in\n+    POLICY = 'private'  # Overriden from settings.FILES_STORE_S3_ACL in\n                         # FilesPipeline.from_settings.\n     HEADERS = {\n         'Cache-Control': 'max-age=172800',\n@@ -233,7 +233,7 @@ class FilesPipeline(MediaPipeline):\n         s3store = cls.STORE_SCHEMES['s3']\n         s3store.AWS_ACCESS_KEY_ID = settings['AWS_ACCESS_KEY_ID']\n         s3store.AWS_SECRET_ACCESS_KEY = settings['AWS_SECRET_ACCESS_KEY']\n-        s3store.POLICY = settings['S3_STORE_ACL']\n+        s3store.POLICY = settings['FILES_STORE_S3_ACL']\n \n         cls.FILES_URLS_FIELD = settings.get('FILES_URLS_FIELD', cls.DEFAULT_FILES_URLS_FIELD)\n         cls.FILES_RESULT_FIELD = settings.get('FILES_RESULT_FIELD', cls.DEFAULT_FILES_RESULT_FIELD)\n\n@@ -156,6 +156,8 @@ FEED_EXPORTERS_BASE = {\n     'pickle': 'scrapy.exporters.PickleItemExporter',\n }\n \n+FILES_STORE_S3_ACL = 'private'\n+\n HTTPCACHE_ENABLED = False\n HTTPCACHE_DIR = 'httpcache'\n HTTPCACHE_IGNORE_MISSING = False\n@@ -231,8 +233,6 @@ SCHEDULER = 'scrapy.core.scheduler.Scheduler'\n SCHEDULER_DISK_QUEUE = 'scrapy.squeues.PickleLifoDiskQueue'\n SCHEDULER_MEMORY_QUEUE = 'scrapy.squeues.LifoMemoryQueue'\n \n-S3_STORE_ACL = 'private'\n-\n SPIDER_LOADER_CLASS = 'scrapy.spiderloader.SpiderLoader'\n \n SPIDER_MIDDLEWARES = {}\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#c29a1b98b3b49a961c67ac64fa303e0265dab2d1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 1304 | Contributors (this commit): 12 | Commits (past 90d): 17 | Contributors (cumulative): 12 | DMM Complexity: 1.0\n\nDIFF:\n@@ -42,10 +42,11 @@ class HTTP11DownloadHandler(object):\n         except TypeError:\n             # use context factory defaults\n             self._contextFactory = self._contextFactoryClass()\n-            warnings.warn(\"\"\"\n+            msg = \"\"\"\n     You are using a context factory class that does not accept the `method` argument\n     (type OpenSSL.SSL method, e.g. OpenSSL.SSL.SSLv23_METHOD).\n-    Please upgrade your context factory class to handle or ignore it.\"\"\")\n+    Please upgrade your context factory class to handle or ignore it.\"\"\"\n+            warnings.warn(msg)\n         self._default_maxsize = settings.getint('DOWNLOAD_MAXSIZE')\n         self._default_warnsize = settings.getint('DOWNLOAD_WARNSIZE')\n         self._disconnect_timeout = 1\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#0336c2504af45a87d2aae4c1ed45039c0e0ea183", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 1311 | Contributors (this commit): 12 | Commits (past 90d): 18 | Contributors (cumulative): 12 | DMM Complexity: 1.0\n\nDIFF:\n@@ -43,9 +43,10 @@ class HTTP11DownloadHandler(object):\n             # use context factory defaults\n             self._contextFactory = self._contextFactoryClass()\n             msg = \"\"\"\n-    You are using a context factory class that does not accept the `method` argument\n-    (type OpenSSL.SSL method, e.g. OpenSSL.SSL.SSLv23_METHOD).\n-    Please upgrade your context factory class to handle or ignore it.\"\"\"\n+ '%s' does not accept `method` argument (type OpenSSL.SSL method,\\\n+ e.g. OpenSSL.SSL.SSLv23_METHOD).\\\n+ Please upgrade your context factory class to handle it or ignore it.\"\"\" % (\n+                settings['DOWNLOADER_CLIENTCONTEXTFACTORY'],)\n             warnings.warn(msg)\n         self._default_maxsize = settings.getint('DOWNLOAD_MAXSIZE')\n         self._default_warnsize = settings.getint('DOWNLOAD_WARNSIZE')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#ecddc093a4b9cb6057f229df82c5c5693fca9612", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 7 | Methods Changed: 6 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 22 | Churn Cumulative: 1874 | Contributors (this commit): 15 | Commits (past 90d): 45 | Contributors (cumulative): 20 | DMM Complexity: 0.75\n\nDIFF:\n@@ -193,6 +193,7 @@ class ScrapyAgent(object):\n         self._pool = pool\n         self._maxsize = maxsize\n         self._warnsize = warnsize\n+        self._txresponse = None\n \n     def _get_agent(self, request, timeout):\n         bindaddress = request.meta.get('bindaddress') or self._bindAddress\n@@ -259,6 +260,11 @@ class ScrapyAgent(object):\n         if self._timeout_cl.active():\n             self._timeout_cl.cancel()\n             return result\n+        # needed for HTTPS requests, otherwise _ResponseReader doesn't\n+        # receive connectionLost()\n+        if self._txresponse:\n+            self._txresponse._transport.stopProducing()\n+\n         raise TimeoutError(\"Getting %s took longer than %s seconds.\" % (url, timeout))\n \n     def _cb_latency(self, result, request, start_time):\n@@ -294,6 +300,10 @@ class ScrapyAgent(object):\n \n         d = defer.Deferred(_cancel)\n         txresponse.deliverBody(_ResponseReader(d, txresponse, request, maxsize, warnsize))\n+\n+        # save response for timeouts\n+        self._txresponse = txresponse\n+\n         return d\n \n     def _cb_bodydone(self, result, request, url):\n\n@@ -182,17 +182,19 @@ class HttpTestCase(unittest.TestCase):\n         return d\n \n     @defer.inlineCallbacks\n-    def test_timeout_download_from_spider(self):\n-        if self.scheme == 'https':\n-            raise unittest.SkipTest(\n-                'test_timeout_download_from_spider skipped under https')\n+    def test_timeout_download_from_spider_nodata_rcvd(self):\n+        # client connects but no data is received\n         spider = Spider('foo')\n         meta = {'download_timeout': 0.2}\n-        # client connects but no data is received\n         request = Request(self.getURL('wait'), meta=meta)\n         d = self.download_request(request, spider)\n         yield self.assertFailure(d, defer.TimeoutError, error.TimeoutError)\n+\n+    @defer.inlineCallbacks\n+    def test_timeout_download_from_spider_server_hangs(self):\n         # client connects, server send headers and some body bytes but hangs\n+        spider = Spider('foo')\n+        meta = {'download_timeout': 0.2}\n         request = Request(self.getURL('hang-after-headers'), meta=meta)\n         d = self.download_request(request, spider)\n         yield self.assertFailure(d, defer.TimeoutError, error.TimeoutError)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#c9e781357da20d8dbb9302e3c983a5dbcd2afb84", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 5 | Churn Cumulative: 331 | Contributors (this commit): 7 | Commits (past 90d): 9 | Contributors (cumulative): 7 | DMM Complexity: 1.0\n\nDIFF:\n@@ -83,6 +83,11 @@ class ScrapyHTTPPageGetter(HTTPClient):\n \n     def timeout(self):\n         self.transport.loseConnection()\n+\n+        # transport cleanup needed for HTTPS connections\n+        if self.factory.url.startswith(b'https'):\n+            self.transport.stopProducing()\n+\n         self.factory.noPage(\\\n                 defer.TimeoutError(\"Getting %s took longer than %s seconds.\" % \\\n                 (self.factory.url, self.factory.timeout)))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#1ce4c86c2b6677133d6bcafc9ed36ebbddfc2d2e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 9 | Churn Cumulative: 64 | Contributors (this commit): 2 | Commits (past 90d): 1 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -17,14 +17,17 @@ class SpiderLoader(object):\n     def __init__(self, settings):\n         self.spider_modules = settings.getlist('SPIDER_MODULES')\n         self._spiders = {}\n-        for name in self.spider_modules:\n-            for module in walk_modules(name):\n-                self._load_spiders(module)\n+        self._load_all_spiders()\n             \n     def _load_spiders(self, module):\n         for spcls in iter_spider_classes(module):\n             self._spiders[spcls.name] = spcls\n \n+    def _load_all_spiders(self):\n+        for name in self.spider_modules:\n+            for module in walk_modules(name):\n+                self._load_spiders(module)\n+\n     @classmethod\n     def from_settings(cls, settings):\n         return cls(settings)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#94e28adfb7049be8ec0e9ce00bab1ab3a0b25301", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 25 | Lines Deleted: 9 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 34 | Churn Cumulative: 1355 | Contributors (this commit): 13 | Commits (past 90d): 20 | Contributors (cumulative): 13 | DMM Complexity: 1.0\n\nDIFF:\n@@ -107,15 +107,8 @@ class TunnelingTCP4ClientEndpoint(TCP4ClientEndpoint):\n \n     def requestTunnel(self, protocol):\n         \"\"\"Asks the proxy to open a tunnel.\"\"\"\n-        tunnelReq = (\n-            b'CONNECT ' +\n-            to_bytes(self._tunneledHost, encoding='ascii') + b':' +\n-            to_bytes(str(self._tunneledPort)) +\n-            b' HTTP/1.1\\r\\n')\n-        if self._proxyAuthHeader:\n-            tunnelReq += \\\n-                b'Proxy-Authorization: ' + self._proxyAuthHeader + b'\\r\\n'\n-        tunnelReq += b'\\r\\n'\n+        tunnelReq = tunnel_request_data(self._tunneledHost, self._tunneledPort,\n+                                        self._proxyAuthHeader)\n         protocol.transport.write(tunnelReq)\n         self._protocolDataReceived = protocol.dataReceived\n         protocol.dataReceived = self.processProxyResponse\n@@ -149,6 +142,29 @@ class TunnelingTCP4ClientEndpoint(TCP4ClientEndpoint):\n         return self._tunnelReadyDeferred\n \n \n+def tunnel_request_data(host, port, proxy_auth_header=None):\n+    r\"\"\"\n+    Return binary content of a CONNECT request.\n+\n+    >>> from scrapy.utils.python import to_native_str as s\n+    >>> s(tunnel_request_data(\"example.com\", 8080))\n+    'CONNECT example.com:8080 HTTP/1.1\\r\\n\\r\\n'\n+    >>> s(tunnel_request_data(\"example.com\", 8080, b\"123\"))\n+    'CONNECT example.com:8080 HTTP/1.1\\r\\nProxy-Authorization: 123\\r\\n\\r\\n'\n+    >>> s(tunnel_request_data(b\"example.com\", \"8090\"))\n+    'CONNECT example.com:8090 HTTP/1.1\\r\\n\\r\\n'\n+    \"\"\"\n+    tunnel_req = (\n+        b'CONNECT ' +\n+        to_bytes(host, encoding='ascii') + b':' +\n+        to_bytes(str(port)) +\n+        b' HTTP/1.1\\r\\n')\n+    if proxy_auth_header:\n+        tunnel_req += b'Proxy-Authorization: ' + proxy_auth_header + b'\\r\\n'\n+    tunnel_req += b'\\r\\n'\n+    return tunnel_req\n+\n+\n class TunnelingAgent(Agent):\n     \"\"\"An agent that uses a L{TunnelingTCP4ClientEndpoint} to make HTTPS\n     downloads. It may look strange that we have chosen to subclass Agent and not\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#17d3bec699b0b851c02fdad40ab6056ef96c5877", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 412 | Contributors (this commit): 9 | Commits (past 90d): 1 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -32,6 +32,10 @@ setup(\n         'Programming Language :: Python',\n         'Programming Language :: Python :: 2',\n         'Programming Language :: Python :: 2.7',\n+        'Programming Language :: Python :: 3',\n+        'Programming Language :: Python :: 3.3',\n+        'Programming Language :: Python :: 3.4',\n+        'Programming Language :: Python :: 3.5',\n         'Topic :: Internet :: WWW/HTTP',\n         'Topic :: Software Development :: Libraries :: Application Frameworks',\n         'Topic :: Software Development :: Libraries :: Python Modules',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
