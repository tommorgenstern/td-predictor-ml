{"custom_id": "keras#30989dc997afcfe7097692e75ac5ff9e7ab06e55", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 13 | Methods Changed: 4 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 23 | Churn Cumulative: 1620 | Contributors (this commit): 2 | Commits (past 90d): 14 | Contributors (cumulative): 2 | DMM Complexity: 0.1111111111111111\n\nDIFF:\n@@ -1082,7 +1082,8 @@ class Model(Container):\n         return self._predict_loop(f, ins,\n                                   batch_size=batch_size, verbose=verbose)\n \n-    def train_on_batch(self, x, y, sample_weight=None, class_weight=None):\n+    def train_on_batch(self, x, y,\n+                       sample_weight=None, class_weight=None):\n         '''Runs a single gradient update on a single batch of data.\n \n         # Arguments\n@@ -1233,7 +1234,7 @@ class Model(Container):\n                                 samples_per_epoch=10000, nb_epoch=10)\n         ```\n         '''\n-        wait_time = 0.05  # in seconds\n+        wait_time = 0.01  # in seconds\n         epoch = 0\n \n         do_validation = bool(validation_data)\n@@ -1316,8 +1317,12 @@ class Model(Container):\n                     raise Exception('output of generator should be a tuple '\n                                     '(x, y, sample_weight) '\n                                     'or (x, y). Found: ' + str(generator_output))\n+                # build batch logs\n                 batch_logs = {}\n+                if type(x) is list:\n                     batch_size = len(x[0])\n+                else:\n+                    batch_size = len(x)\n                 batch_logs['batch'] = batch_index\n                 batch_logs['size'] = batch_size\n                 callbacks.on_batch_begin(batch_index, batch_logs)\n@@ -1359,7 +1364,7 @@ class Model(Container):\n                         val_outs = self.evaluate(val_x, val_y,\n                                                  sample_weight=val_sample_weights,\n                                                  verbose=0)\n-                    if type(val_outs) != list:\n+                    if type(val_outs) is not list:\n                         val_outs = [val_outs]\n                     # same labels assumed\n                     for l, o in zip(out_labels, val_outs):\n@@ -1395,7 +1400,7 @@ class Model(Container):\n         self._make_test_function()\n \n         processed_samples = 0\n-        wait_time = 0.05\n+        wait_time = 0.01\n         all_outs = []\n         weights = []\n         data_gen_queue, _stop = generator_queue(generator)\n@@ -1430,7 +1435,10 @@ class Model(Container):\n                 _stop.set()\n                 raise e\n \n+            if type(x) is list:\n                 nb_samples = len(x[0])\n+            else:\n+                nb_samples = len(x)\n             all_outs.append(outs)\n \n             processed_samples += nb_samples\n@@ -1463,7 +1471,7 @@ class Model(Container):\n         self._make_predict_function()\n \n         processed_samples = 0\n-        wait_time = 0.05\n+        wait_time = 0.01\n         all_outs = []\n         data_gen_queue, _stop = generator_queue(generator)\n \n@@ -1490,15 +1498,16 @@ class Model(Container):\n             else:\n                 x = generator_output\n \n-            x = standardize_input_data(x, self.input_names)\n-\n             try:\n                 outs = self.predict_on_batch(x)\n             except Exception as e:\n                 _stop.set()\n                 raise e\n \n+            if type(x) is list:\n                 nb_samples = len(x[0])\n+            else:\n+                nb_samples = len(x)\n \n             if type(outs) != list:\n                 outs = [outs]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cec7f73bca617ab4321a805f25499d75f13c2672", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 23 | Files Changed: 1 | Hunks: 5 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 26 | Churn Cumulative: 150 | Contributors (this commit): 3 | Commits (past 90d): 2 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -14,18 +14,15 @@ Reaches 0.93 train/test accuracy after 900 epochs\n '''\n \n from __future__ import print_function\n-import numpy as np\n-np.random.seed(1337)  # for reproducibility\n \n from keras.datasets import mnist\n from keras.models import Sequential\n from keras.layers.core import Dense, Activation\n from keras.initializations import normal, identity\n-from keras.layers.recurrent import SimpleRNN, LSTM\n+from keras.layers.recurrent import SimpleRNN\n from keras.optimizers import RMSprop\n from keras.utils import np_utils\n \n-\n batch_size = 32\n nb_classes = 10\n nb_epochs = 200\n@@ -54,8 +51,8 @@ Y_test = np_utils.to_categorical(y_test, nb_classes)\n print('Evaluate IRNN...')\n model = Sequential()\n model.add(SimpleRNN(output_dim=hidden_units,\n-                    init=lambda shape: normal(shape, scale=0.001),\n-                    inner_init=lambda shape: identity(shape, scale=1.0),\n+                    init=lambda shape, name: normal(shape, scale=0.001, name=name),\n+                    inner_init=lambda shape, name: identity(shape, scale=1.0, name=name),\n                     activation='relu',\n                     input_shape=X_train.shape[1:]))\n model.add(Dense(nb_classes))\n@@ -71,20 +68,3 @@ model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epochs,\n scores = model.evaluate(X_test, Y_test, verbose=0)\n print('IRNN test score:', scores[0])\n print('IRNN test accuracy:', scores[1])\n-\n-print('Compare to LSTM...')\n-model = Sequential()\n-model.add(LSTM(hidden_units, input_shape=X_train.shape[1:]))\n-model.add(Dense(nb_classes))\n-model.add(Activation('softmax'))\n-rmsprop = RMSprop(lr=learning_rate)\n-model.compile(loss='categorical_crossentropy',\n-              optimizer=rmsprop,\n-              metrics=['accuracy'])\n-\n-model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epochs,\n-          verbose=1, validation_data=(X_test, Y_test))\n-\n-scores = model.evaluate(X_test, Y_test, verbose=0)\n-print('LSTM test score:', scores[0])\n-print('LSTM test accuracy:', scores[1])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2e45022c955acc8197c57c67e7ce93be31bb4405", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 12 | Files Changed: 2 | Hunks: 6 | Methods Changed: 8 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 24 | Churn Cumulative: 3214 | Contributors (this commit): 23 | Commits (past 90d): 84 | Contributors (cumulative): 34 | DMM Complexity: None\n\nDIFF:\n@@ -734,26 +734,26 @@ def switch(condition, then_expression, else_expression):\n     return x\n \n \n-def in_train_phase(x, expression):\n-    '''Inserts an expression to be only applied at training time.\n-    Note that `expression` should have the *same shape* as `x`.\n+def in_train_phase(x, alt):\n+    '''Selects `x` in train phase, and `alt` otherwise.\n+    Note that `alt` should have the *same shape* as `x`.\n     '''\n     x_shape = copy.copy(x.get_shape())\n     x = tf.python.control_flow_ops.cond(tf.cast(_LEARNING_PHASE, 'bool'),\n                                         lambda: x,\n-                                        lambda: expression)\n+                                        lambda: alt)\n     x._uses_learning_phase = True\n     x.set_shape(x_shape)\n     return x\n \n \n-def in_test_phase(x, expression):\n-    '''Inserts an expression to be only applied at test time.\n-    Note that `expression` should have the *same shape* as `x`.\n+def in_test_phase(x, alt):\n+    '''Selects `x` in test phase, and `alt` otherwise.\n+    Note that `alt` should have the *same shape* as `x`.\n     '''\n     x_shape = copy.copy(x.get_shape())\n     x = tf.python.control_flow_ops.cond(tf.cast(_LEARNING_PHASE, 'bool'),\n-                                        lambda: expression,\n+                                        lambda: alt,\n                                         lambda: x)\n     x._uses_learning_phase = True\n     x.set_shape(x_shape)\n\n@@ -673,14 +673,14 @@ def switch(condition, then_expression, else_expression):\n     return T.switch(condition, then_expression, else_expression)\n \n \n-def in_train_phase(x, expression):\n-    x = T.switch(_LEARNING_PHASE, x, expression)\n+def in_train_phase(x, alt):\n+    x = T.switch(_LEARNING_PHASE, x, alt)\n     x._uses_learning_phase = True\n     return x\n \n \n-def in_test_phase(x, expression):\n-    x = T.switch(_LEARNING_PHASE, expression, x)\n+def in_test_phase(x, alt):\n+    x = T.switch(_LEARNING_PHASE, alt, x)\n     x._uses_learning_phase = True\n     return x\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ddec052dab091f3be579d5349d93a075819a7030", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1684 | Contributors (this commit): 20 | Commits (past 90d): 43 | Contributors (cumulative): 20 | DMM Complexity: None\n\nDIFF:\n@@ -790,8 +790,6 @@ def conv2d(x, kernel, strides=(1, 1), border_mode='valid', dim_ordering='th',\n     if border_mode == 'same':\n         th_border_mode = 'half'\n         np_kernel = kernel.eval()\n-        assert strides[0] <= np_kernel.shape[2], 'strides should be smaller than the convolution window.'\n-        assert strides[1] <= np_kernel.shape[3], 'strides should be smaller than the convolution window.'\n     elif border_mode == 'valid':\n         th_border_mode = 'valid'\n     else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#dc8b5509f3d554d67ffa02b2315a00965a492776", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 12 | Churn Cumulative: 2610 | Contributors (this commit): 5 | Commits (past 90d): 22 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1516,7 +1516,7 @@ class Container(Layer):\n             layer, node_index, tensor_index = x._keras_history\n             if len(layer.inbound_nodes) > 1 or (layer.inbound_nodes and layer.inbound_nodes[0].inbound_layers):\n                 cls_name = self.__class__.__name__\n-                raise Exception(cls_name + ' inputs must come from '\n+                warnings.warn(cls_name + ' inputs must come from '\n                               'a Keras Input layer, '\n                               'they cannot be the output of '\n                               'a previous non-Input layer. '\n@@ -2349,7 +2349,7 @@ class Container(Layer):\n         print_summary(flattened_layers, getattr(self, 'container_nodes', None))\n \n \n-def get_source_inputs(tensor, layer=None, node_index=None, tensor_index=None):\n+def get_source_inputs(tensor, layer=None, node_index=None):\n     '''Returns the list of input tensors\n     necessary to compute `tensor`.\n \n@@ -2361,12 +2361,12 @@ def get_source_inputs(tensor, layer=None, node_index=None, tensor_index=None):\n         layer: origin layer of the tensor. Will be\n             determined via tensor._keras_history if not provided.\n         node_index: origin node index of the tensor.\n-        tensor_index: origin tensor index of the tensor.\n     '''\n     if not hasattr(tensor, '_keras_history'):\n         raise Exception('Tensor must be a Keras tensor. Found: ' + str(tensor))\n \n-    layer, node_index, tensor_index = tensor._keras_history\n+    if layer is None or node_index:\n+        layer, node_index, _ = tensor._keras_history\n     if not layer.inbound_nodes:\n         return [tensor]\n     else:\n@@ -2380,11 +2380,9 @@ def get_source_inputs(tensor, layer=None, node_index=None, tensor_index=None):\n                 x = node.input_tensors[i]\n                 layer = node.inbound_layers[i]\n                 node_index = node.node_indices[i]\n-                tensor_index = node.tensor_indices[i]\n                 previous_sources = get_source_inputs(x,\n                                                      layer,\n-                                                     node_index,\n-                                                     tensor_index)\n+                                                     node_index)\n                 # avoid input redundancy\n                 for x in previous_sources:\n                     if x not in source_tensors:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c0eedfeca0e19a65e4484e63790319cf18433343", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 80 | Contributors (this commit): 3 | Commits (past 90d): 4 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -49,7 +49,7 @@ model.add(Activation('softmax'))\n model.summary()\n \n model.compile(loss='categorical_crossentropy',\n-              optimizer=Adam(),\n+              optimizer=RMSprop(),\n               metrics=['accuracy'])\n \n history = model.fit(X_train, Y_train,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d31fe1ac3495ff29251f65d00ab866bbf98893f2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 3998 | Contributors (this commit): 20 | Commits (past 90d): 30 | Contributors (cumulative): 20 | DMM Complexity: None\n\nDIFF:\n@@ -314,10 +314,10 @@ class SimpleRNN(Recurrent):\n             self.W_regularizer.set_param(self.W)\n             self.regularizers.append(self.W_regularizer)\n         if self.U_regularizer:\n-            self.W_regularizer.set_param(self.U)\n+            self.U_regularizer.set_param(self.U)\n             self.regularizers.append(self.U_regularizer)\n         if self.b_regularizer:\n-            self.W_regularizer.set_param(self.b)\n+            self.b_regularizer.set_param(self.b)\n             self.regularizers.append(self.b_regularizer)\n \n         self.trainable_weights = [self.W, self.U, self.b]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#41b97777462837bacf12f98d5b64a03a2e78a1db", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 34 | Lines Deleted: 33 | Files Changed: 1 | Hunks: 9 | Methods Changed: 4 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 67 | Churn Cumulative: 1687 | Contributors (this commit): 2 | Commits (past 90d): 15 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -601,39 +601,14 @@ class Model(Container):\n                     else:\n                         self.metrics_names.append(self.output_layers[i].name + '_' + metric_fn.__name__)\n \n-        # define symbolic outptus\n-        all_outputs = [total_loss] + self.metrics\n-\n         # prepare gradient updates and state updates\n         self.optimizer = optimizers.get(optimizer)\n-        # dedupe trainable weights\n-        trainable_weights_set = set()\n-        trainable_weights = []\n-        for w in self.trainable_weights:\n-            if w not in trainable_weights_set:\n-                trainable_weights_set.add(w)\n-                trainable_weights.append(w)\n-        # compute weight updates\n-        train_updates = self.optimizer.get_updates(trainable_weights,\n-                                                   self.constraints,\n-                                                   total_loss)\n-        train_updates += self.updates\n-\n-        # model inputs: add learning phase if necessary\n-        if self.uses_learning_phase:\n-            train_test_inputs = self.inputs + self.targets + sample_weights + [K.learning_phase()]\n-            predict_inputs = self.inputs + [K.learning_phase()]\n-        else:\n-            train_test_inputs = self.inputs + self.targets + sample_weights\n-            predict_inputs = self.inputs\n+        self.total_loss = total_loss\n+        self.sample_weights = sample_weights\n \n         # functions for train, test and predict will\n         # be compiled lazily when required.\n         # This saves time when the user is not using all functions.\n-        self._train_updates = train_updates\n-        self._train_test_inputs = train_test_inputs\n-        self._all_outputs = all_outputs\n-        self._predict_inputs = predict_inputs\n         self._function_kwargs = kwargs\n \n         self.train_function = None\n@@ -642,24 +617,50 @@ class Model(Container):\n \n     def _make_train_function(self):\n         if self.train_function is None:\n+            if self.uses_learning_phase:\n+                inputs = self.inputs + self.targets + self.sample_weights + [K.learning_phase()]\n+            else:\n+                inputs = self.inputs + self.targets + self.sample_weights\n+\n+            # dedupe trainable weights\n+            trainable_weights_set = set()\n+            trainable_weights = []\n+            for w in self.trainable_weights:\n+                if w not in trainable_weights_set:\n+                    trainable_weights_set.add(w)\n+                    trainable_weights.append(w)\n+\n+            training_updates = self.optimizer.get_updates(trainable_weights, self.constraints, self.total_loss)\n+            updates = self.state_updates + self.updates + training_updates\n+\n             # returns loss and metrics. Updates weights at each call.\n-            self.train_function = K.function(self._train_test_inputs,\n-                                             self._all_outputs,\n-                                             updates=self._train_updates,\n+            self.train_function = K.function(inputs,\n+                                             [self.total_loss] + self.metrics,\n+                                             updates=updates,\n                                              **self._function_kwargs)\n \n     def _make_test_function(self):\n         if self.test_function is None:\n+            if self.uses_learning_phase:\n+                inputs = self.inputs + self.targets + self.sample_weights + [K.learning_phase()]\n+            else:\n+                inputs = self.inputs + self.targets + self.sample_weights\n             # return loss and metrics, no gradient updates.\n-            self.test_function = K.function(self._train_test_inputs,\n-                                            self._all_outputs,\n+            # Does update the network states.\n+            self.test_function = K.function(inputs,\n+                                            [self.total_loss] + self.metrics,\n+                                            updates=self.state_updates,\n                                             **self._function_kwargs)\n \n     def _make_predict_function(self):\n         if self.predict_function is None:\n+            if self.uses_learning_phase:\n+                inputs = self.inputs + [K.learning_phase()]\n+            else:\n+                inputs = self.inputs\n             # returns network outputs. Does not update weights.\n             # Does update the network states.\n-            self.predict_function = K.function(self._predict_inputs,\n+            self.predict_function = K.function(inputs,\n                                                self.outputs,\n                                                updates=self.state_updates,\n                                                **self._function_kwargs)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5706d1d68807f0a7eb2c58b972a399d9b97b85d8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1689 | Contributors (this commit): 2 | Commits (past 90d): 16 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -631,7 +631,7 @@ class Model(Container):\n                     trainable_weights.append(w)\n \n             training_updates = self.optimizer.get_updates(trainable_weights, self.constraints, self.total_loss)\n-            updates = self.state_updates + self.updates + training_updates\n+            updates = self.updates + training_updates\n \n             # returns loss and metrics. Updates weights at each call.\n             self.train_function = K.function(inputs,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cadd3e4e2c578eb73b0bbedc95cceae577266adf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 3 | Churn Cumulative: 294 | Contributors (this commit): 1 | Commits (past 90d): 7 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -78,6 +78,9 @@ class TimeDistributed(Wrapper):\n     # Arguments\n         layer: a layer instance.\n     \"\"\"\n+    def __init__(self, layer, **kwargs):\n+        self.supports_masking = True\n+        super(TimeDistributed, self).__init__(layer, **kwargs)\n \n     def build(self, input_shape):\n         assert len(input_shape) >= 3\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0772210dea435e0c8d5cff9ce212b835b40c7a40", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 8 | Methods Changed: 8 | Complexity Δ (Sum/Max): 8/8 | Churn Δ: 17 | Churn Cumulative: 7533 | Contributors (this commit): 43 | Commits (past 90d): 39 | Contributors (cumulative): 43 | DMM Complexity: 0.0\n\nDIFF:\n@@ -375,6 +375,8 @@ class Sequential(Model):\n             at successive epochs, as well as validation loss values\n             and validation metrics values (if applicable).\n         '''\n+        if self.model is None:\n+            raise Exception('The model needs to be compiled before being used.')\n         if 'show_accuracy' in kwargs:\n             kwargs.pop('show_accuracy')\n             warnings.warn('The \"show_accuracy\" argument is deprecated, '\n@@ -414,6 +416,8 @@ class Sequential(Model):\n             The attribute `model.metrics_names` will give you\n             the display labels for the scalar outputs.\n         '''\n+        if self.model is None:\n+            raise Exception('The model needs to be compiled before being used.')\n         if 'show_accuracy' in kwargs:\n             kwargs.pop('show_accuracy')\n             warnings.warn('The \"show_accuracy\" argument is deprecated, '\n@@ -441,6 +445,8 @@ class Sequential(Model):\n         # Returns\n             A Numpy array of predictions.\n         '''\n+        if self.model is None:\n+            raise Exception('The model needs to be compiled before being used.')\n         return self.model.predict(x, batch_size=batch_size, verbose=verbose)\n \n     def predict_on_batch(self, x):\n@@ -522,6 +528,8 @@ class Sequential(Model):\n         # Returns\n             A Numpy array of probability predictions.\n         '''\n+        if self.model is None:\n+            raise Exception('The model needs to be compiled before being used.')\n         preds = self.predict(x, batch_size, verbose)\n         if preds.min() < 0. or preds.max() > 1.:\n             warnings.warn('Network returning invalid probability values. '\n@@ -543,6 +551,8 @@ class Sequential(Model):\n         # Returns\n             A numpy array of class predictions.\n         '''\n+        if self.model is None:\n+            raise Exception('The model needs to be compiled before being used.')\n         proba = self.predict(x, batch_size=batch_size, verbose=verbose)\n         if proba.shape[-1] > 1:\n             return proba.argmax(axis=-1)\n@@ -604,6 +614,8 @@ class Sequential(Model):\n                                 samples_per_epoch=10000, nb_epoch=10)\n         ```\n         '''\n+        if self.model is None:\n+            raise Exception('The model needs to be compiled before being used.')\n         if 'show_accuracy' in kwargs:\n             kwargs.pop('show_accuracy')\n             warnings.warn('The \"show_accuracy\" argument is deprecated, '\n@@ -644,6 +656,8 @@ class Sequential(Model):\n                 total number of samples to generate from `generator`\n                 before returning.\n         '''\n+        if self.model is None:\n+            raise Exception('The model needs to be compiled before being used.')\n         if 'show_accuracy' in kwargs:\n             kwargs.pop('show_accuracy')\n             warnings.warn('The \"show_accuracy\" argument is deprecated, '\n@@ -673,7 +687,8 @@ class Sequential(Model):\n         # Returns\n             A Numpy array of predictions.\n         '''\n-\n+        if self.model is None:\n+            raise Exception('The model needs to be compiled before being used.')\n         return self.model.predict_generator(generator, val_samples)\n \n     def get_config(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1db555a530ce433f39c9d8af0592e6e81468d6eb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 37 | Contributors (this commit): 4 | Commits (past 90d): 1 | Contributors (cumulative): 4 | DMM Complexity: 0.0\n\nDIFF:\n@@ -9,7 +9,6 @@ def to_categorical(y, nb_classes=None):\n     '''Convert class vector (integers from 0 to nb_classes)\n     to binary class matrix, for use with categorical_crossentropy.\n     '''\n-    y = np.asarray(y, dtype='int32')\n     if not nb_classes:\n         nb_classes = np.max(y)+1\n     Y = np.zeros((len(y), nb_classes))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6ea3188971a29405710563be48956da94ae26fa8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 7535 | Contributors (this commit): 43 | Commits (past 90d): 40 | Contributors (cumulative): 43 | DMM Complexity: None\n\nDIFF:\n@@ -312,7 +312,7 @@ class Sequential(Model):\n                 model.add(Dense(10, activation='softmax'))\n                 model.compile(optimizer='rmsprop',\n                               loss='categorical_crossentropy',\n-                              metrics=['acccuracy'])\n+                              metrics=['accuracy'])\n             ```\n         '''\n         # create the underlying model\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#30208ae08bffb51175abda85c372701388cb7d91", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 6 | Churn Cumulative: 573 | Contributors (this commit): 11 | Commits (past 90d): 12 | Contributors (cumulative): 11 | DMM Complexity: 1.0\n\nDIFF:\n@@ -77,7 +77,6 @@ class Embedding(Layer):\n         self.dropout = dropout\n \n         self.W_constraint = constraints.get(W_constraint)\n-        self.constraints = [self.W_constraint]\n \n         self.W_regularizer = regularizers.get(W_regularizer)\n         self.activity_regularizer = regularizers.get(activity_regularizer)\n@@ -93,6 +92,11 @@ class Embedding(Layer):\n         self.W = self.init((self.input_dim, self.output_dim),\n                            name='{}_W'.format(self.name))\n         self.trainable_weights = [self.W]\n+\n+        self.constraints = {}\n+        if self.W_constraint:\n+            self.constraints[self.W] = self.W_constraint\n+\n         self.regularizers = []\n         if self.W_regularizer:\n             self.W_regularizer.set_param(self.W)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#26714bc635f9f6b03679e739eb5e8512102a2027", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 4000 | Contributors (this commit): 21 | Commits (past 90d): 31 | Contributors (cumulative): 21 | DMM Complexity: None\n\nDIFF:\n@@ -196,7 +196,7 @@ class Recurrent(Layer):\n     def call(self, x, mask=None):\n         # input shape: (nb_samples, time (padded with zeros), input_dim)\n         # note that the .build() method of subclasses MUST define\n-        # self.input_sepc with a complete input shape.\n+        # self.input_spec with a complete input shape.\n         input_shape = self.input_spec[0].shape\n         if K._BACKEND == 'tensorflow':\n             if not input_shape[1]:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d50f469c09ba48cfb850556699390e6c50e4e651", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 5 | Churn Cumulative: 10302 | Contributors (this commit): 43 | Commits (past 90d): 45 | Contributors (cumulative): 43 | DMM Complexity: 1.0\n\nDIFF:\n@@ -76,9 +76,10 @@ class Dropout(Layer):\n         - [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf)\n     '''\n     def __init__(self, p, **kwargs):\n-        self.supports_masking = True\n-        self.uses_learning_phase = True\n         self.p = p\n+        if 0. < self.p < 1.:\n+            self.uses_learning_phase = True\n+        self.supports_masking = True\n         super(Dropout, self).__init__(**kwargs)\n \n     def call(self, x, mask=None):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fa1d6b478eaf2e457f42b09b41ffd557fcaf8b71", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 6 | Churn Cumulative: 1695 | Contributors (this commit): 2 | Commits (past 90d): 17 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1322,6 +1322,8 @@ class Model(Container):\n                 batch_logs = {}\n                 if type(x) is list:\n                     batch_size = len(x[0])\n+                elif type(x) is dict:\n+                    batch_size = len(list(x.values())[0])\n                 else:\n                     batch_size = len(x)\n                 batch_logs['batch'] = batch_index\n@@ -1438,6 +1440,8 @@ class Model(Container):\n \n             if type(x) is list:\n                 nb_samples = len(x[0])\n+            elif type(x) is dict:\n+                nb_samples = len(list(x.values())[0])\n             else:\n                 nb_samples = len(x)\n             all_outs.append(outs)\n@@ -1507,6 +1511,8 @@ class Model(Container):\n \n             if type(x) is list:\n                 nb_samples = len(x[0])\n+            elif type(x) is dict:\n+                nb_samples = len(list(x.values())[0])\n             else:\n                 nb_samples = len(x)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#80ebe801384ba9e6bf788df5aec5bb6b45ed9a5e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 1526 | Contributors (this commit): 14 | Commits (past 90d): 10 | Contributors (cumulative): 14 | DMM Complexity: 1.0\n\nDIFF:\n@@ -60,8 +60,7 @@ class CallbackList(object):\n             callback.on_batch_end(batch, logs)\n         self._delta_ts_batch_end.append(time.time() - t_before_callbacks)\n         delta_t_median = np.median(self._delta_ts_batch_end)\n-        if self._delta_t_batch > 0. and delta_t_median > 0.95 * \\\n-           self._delta_t_batch and delta_t_median > 0.1:\n+        if self._delta_t_batch > 0. and (delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1):\n             warnings.warn('Method on_batch_end() is slow compared '\n                           'to the batch update (%f). Check your callbacks.'\n                           % delta_t_median)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1206120d1084cbe45dc2876f002cb572a97e3844", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 22 | Lines Deleted: 8 | Files Changed: 2 | Hunks: 9 | Methods Changed: 3 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 30 | Churn Cumulative: 9260 | Contributors (this commit): 43 | Commits (past 90d): 59 | Contributors (cumulative): 45 | DMM Complexity: 0.125\n\nDIFF:\n@@ -692,8 +692,6 @@ class Model(Container):\n         # Returns\n             `History` object.\n         '''\n-        self.training_data = ins\n-        self.validation_data = val_ins\n         do_validation = False\n         if val_f and val_ins:\n             do_validation = True\n@@ -710,7 +708,14 @@ class Model(Container):\n             callbacks += [cbks.ProgbarLogger()]\n         callbacks = cbks.CallbackList(callbacks)\n \n-        callbacks._set_model(self)\n+        # it's possible to callback a different model than self\n+        # (used by Sequential models)\n+        if hasattr(self, 'callback_model') and self.callback_model:\n+            callback_model = self.callback_model\n+        else:\n+            callback_model = self\n+\n+        callbacks._set_model(callback_model)\n         callbacks._set_params({\n             'batch_size': batch_size,\n             'nb_epoch': nb_epoch,\n@@ -720,8 +725,9 @@ class Model(Container):\n             'metrics': callback_metrics,\n         })\n         callbacks.on_train_begin()\n+        callback_model.stop_training = False\n+        self.validation_data = val_ins\n \n-        self.stop_training = False\n         for epoch in range(nb_epoch):\n             callbacks.on_epoch_begin(epoch)\n             if shuffle == 'batch':\n@@ -768,7 +774,7 @@ class Model(Container):\n                         for l, o in zip(out_labels, val_outs):\n                             epoch_logs['val_' + l] = o\n             callbacks.on_epoch_end(epoch, epoch_logs)\n-            if self.stop_training:\n+            if callback_model.stop_training:\n                 break\n         callbacks.on_train_end()\n         return self.history\n@@ -1261,7 +1267,12 @@ class Model(Container):\n             callbacks += [cbks.ProgbarLogger()]\n         callbacks = cbks.CallbackList(callbacks)\n \n-        callbacks._set_model(self)\n+        # it's possible to callback a different model than self:\n+        if hasattr(self, 'callback_model') and self.callback_model:\n+            callback_model = self.callback_model\n+        else:\n+            callback_model = self\n+        callbacks._set_model(callback_model)\n         callbacks._set_params({\n             'nb_epoch': nb_epoch,\n             'nb_sample': samples_per_epoch,\n@@ -1289,7 +1300,7 @@ class Model(Container):\n         # start generator thread storing batches into a queue\n         data_gen_queue, _stop = generator_queue(generator)\n \n-        self.stop_training = False\n+        callback_model.stop_training = False\n         while epoch < nb_epoch:\n             callbacks.on_epoch_begin(epoch)\n             samples_seen = 0\n@@ -1375,7 +1386,7 @@ class Model(Container):\n \n             callbacks.on_epoch_end(epoch, epoch_logs)\n             epoch += 1\n-            if self.stop_training:\n+            if callback_model.stop_training:\n                 break\n \n         _stop.set()\n\n@@ -178,6 +178,9 @@ class Sequential(Model):\n         self.output_names = self.model.output_names\n         self.input_names = self.model.input_names\n \n+        # make sure child model callbacks will call the parent Sequential model:\n+        self.model.callback_model = self\n+\n         self.built = True\n \n     @property\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cb65139aa8857421e70920422844db8a2d6b0a87", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 66 | Lines Deleted: 25 | Files Changed: 2 | Hunks: 20 | Methods Changed: 12 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 91 | Churn Cumulative: 783 | Contributors (this commit): 11 | Commits (past 90d): 19 | Contributors (cumulative): 14 | DMM Complexity: 0.8974358974358975\n\nDIFF:\n@@ -16,42 +16,34 @@ from six.moves import range\n import threading\n \n \n-def random_rotation(x, rg, fill_mode='nearest', cval=0.):\n+def random_rotation(x, rg, fill_mode='nearest', cval=0., axes=(1,2)):\n     angle = np.random.uniform(-rg, rg)\n     x = ndimage.interpolation.rotate(x, angle,\n-                                     axes=(1, 2),\n+                                     axes=axes,\n                                      reshape=False,\n                                      mode=fill_mode,\n                                      cval=cval)\n     return x\n \n \n-def random_shift(x, wrg, hrg, fill_mode='nearest', cval=0.):\n+def random_shift(x, wrg, hrg, fill_mode='nearest', cval=0., row_index=1, col_index=2):\n     shift_x = shift_y = 0\n-\n     if wrg:\n-        shift_x = np.random.uniform(-wrg, wrg) * x.shape[2]\n+        shift_x = np.random.uniform(-wrg, wrg) * x.shape[col_index]\n     if hrg:\n-        shift_y = np.random.uniform(-hrg, hrg) * x.shape[1]\n+        shift_y = np.random.uniform(-hrg, hrg) * x.shape[row_index]\n     x = ndimage.interpolation.shift(x, (0, shift_y, shift_x),\n                                     order=0,\n                                     mode=fill_mode,\n                                     cval=cval)\n     return x\n \n-\n-def horizontal_flip(x):\n-    for i in range(x.shape[0]):\n-        x[i] = np.fliplr(x[i])\n+def flip_axis(x, axis):\n+    x = np.asarray(x).swapaxes(axis, 0)\n+    x = x[::-1,...]\n+    x = x.swapaxes(0, axis)\n     return x\n \n-\n-def vertical_flip(x):\n-    for i in range(x.shape[0]):\n-        x[i] = np.flipud(x[i])\n-    return x\n-\n-\n def random_barrel_transform(x, intensity):\n     # TODO\n     pass\n@@ -140,6 +132,8 @@ class ImageDataGenerator(object):\n         shear_range: shear intensity (shear angle in radians).\n         horizontal_flip: whether to randomly flip images horizontally.\n         vertical_flip: whether to randomly flip images vertically.\n+        dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension\n+            (the depth) is at index 1, in 'tf' mode it is at index 3.\n     '''\n     def __init__(self,\n                  featurewise_center=True,\n@@ -152,12 +146,25 @@ class ImageDataGenerator(object):\n                  height_shift_range=0.,\n                  shear_range=0.,\n                  horizontal_flip=False,\n-                 vertical_flip=False):\n+                 vertical_flip=False,\n+                 dim_ordering='th'):\n         self.__dict__.update(locals())\n         self.mean = None\n         self.std = None\n         self.principal_components = None\n         self.lock = threading.Lock()\n+        if dim_ordering not in {'tf', 'th'}:\n+            raise Exception('dim_ordering should be \"tf\" (channel after row and \\\n+            column) or \"th\" (channel before row and column). Received arg: ', dim_ordering)\n+        self.dim_ordering = dim_ordering\n+        if dim_ordering == \"th\":\n+            self.channel_index = 1\n+            self.row_index = 2\n+            self.col_index = 3\n+        if dim_ordering == \"tf\":\n+            self.channel_index = 3\n+            self.row_index = 1\n+            self.col_index = 2\n \n     def _flow_index(self, N, batch_size=32, shuffle=False, seed=None):\n         b = 0\n@@ -230,9 +237,9 @@ class ImageDataGenerator(object):\n \n     def standardize(self, x):\n         if self.samplewise_center:\n-            x -= np.mean(x, axis=1, keepdims=True)\n+            x -= np.mean(x, axis=self.channel_index, keepdims=True)\n         if self.samplewise_std_normalization:\n-            x /= (np.std(x, axis=1, keepdims=True) + 1e-7)\n+            x /= (np.std(x, axis=self.channel_index, keepdims=True) + 1e-7)\n \n         if self.featurewise_center:\n             x -= self.mean\n@@ -240,23 +247,29 @@ class ImageDataGenerator(object):\n             x /= (self.std + 1e-7)\n \n         if self.zca_whitening:\n-            flatx = np.reshape(x, (x.shape[0] * x.shape[1] * x.shape[2]))\n+            flatx = np.reshape(x, (x.size))\n             whitex = np.dot(flatx, self.principal_components)\n             x = np.reshape(whitex, (x.shape[0], x.shape[1], x.shape[2]))\n \n         return x\n \n     def random_transform(self, x):\n+        # x is a single image, so it doesn't have image number at index 0\n+        img_col_index = self.col_index - 1\n+        img_row_index = self.row_index - 1\n+\n         if self.rotation_range:\n-            x = random_rotation(x, self.rotation_range)\n+            x = random_rotation(x, self.rotation_range,\n+                                axes=(img_row_index, img_col_index))\n         if self.width_shift_range or self.height_shift_range:\n-            x = random_shift(x, self.width_shift_range, self.height_shift_range)\n+            x = random_shift(x, self.width_shift_range, self.height_shift_range,\n+                             row_index=img_row_index, col_index=img_col_index)\n         if self.horizontal_flip:\n             if np.random.random() < 0.5:\n-                x = horizontal_flip(x)\n+                x = flip_axis(x, img_col_index)\n         if self.vertical_flip:\n             if np.random.random() < 0.5:\n-                x = vertical_flip(x)\n+                x = flip_axis(x, img_row_index)\n         if self.shear_range:\n             x = random_shear(x, self.shear_range)\n         # TODO:\n\n@@ -55,5 +55,33 @@ def test_image_data_generator():\n             assert x.shape[1:] == images.shape[1:]\n             break\n \n+def test_img_flip():\n+    x = np.array(range(4)).reshape([1,1,2,2])\n+    assert (flip_axis(x, 0) == x).all()\n+    assert (flip_axis(x, 1) == x).all()\n+    assert (flip_axis(x, 2) == [[[[2, 3], [0, 1]]]]).all()\n+    assert (flip_axis(x, 3) == [[[[1, 0], [3, 2]]]]).all()\n+\n+    dim_ordering_and_col_index = (('tf', 2), ('th', 3))\n+    for dim_ordering, col_index in dim_ordering_and_col_index:\n+        image_generator_th = ImageDataGenerator(\n+            featurewise_center=False,\n+            samplewise_center=False,\n+            featurewise_std_normalization=False,\n+            samplewise_std_normalization=False,\n+            zca_whitening=False,\n+            rotation_range=0,\n+            width_shift_range=0,\n+            height_shift_range=0,\n+            shear_range=0,\n+            horizontal_flip=True,\n+            vertical_flip=False,\n+            dim_ordering=dim_ordering).flow(x, [1])\n+        for i in range(10):\n+            potentially_flipped_x, _ = next(image_generator_th)\n+            assert (potentially_flipped_x==x).all() or \\\n+                   (potentially_flipped_x==flip_axis(x, col_index)).all()\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3cbca7bdba93df45c6ac2a00683d8f7724301d5f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 16 | Churn Cumulative: 1738 | Contributors (this commit): 2 | Commits (past 90d): 19 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -956,14 +956,6 @@ class Model(Container):\n                                                            class_weight=class_weight,\n                                                            check_batch_dim=False,\n                                                            batch_size=batch_size)\n-        # prepare input arrays and training function\n-        if self.uses_learning_phase:\n-            ins = x + y + sample_weights + [1.]\n-        else:\n-            ins = x + y + sample_weights\n-        self._make_train_function()\n-        f = self.train_function\n-\n         # prepare validation data\n         if validation_data:\n             do_validation = True\n@@ -1002,6 +994,14 @@ class Model(Container):\n             val_f = None\n             val_ins = None\n \n+        # prepare input arrays and training function\n+        if self.uses_learning_phase:\n+            ins = x + y + sample_weights + [1.]\n+        else:\n+            ins = x + y + sample_weights\n+        self._make_train_function()\n+        f = self.train_function\n+\n         # prepare display labels\n         out_labels = self.metrics_names\n         if do_validation:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#05e1d8e5f4bc3eab549fe386f4db24641acffa7b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 7 | Churn Cumulative: 222 | Contributors (this commit): 3 | Commits (past 90d): 6 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -28,6 +28,11 @@ def euclidean_distance(vects):\n     return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n \n \n+def eucl_dist_output_shape(shapes):\n+    shape1, shape2 = shapes\n+    return shape1\n+\n+\n def contrastive_loss(y_true, y_pred):\n     '''Contrastive loss from Hadsell-et-al.'06\n     http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n@@ -103,7 +108,7 @@ input_b = Input(shape=(input_dim,))\n processed_a = base_network(input_a)\n processed_b = base_network(input_b)\n \n-distance = Lambda(euclidean_distance)([processed_a, processed_b])\n+distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n \n model = Model(input=[input_a, input_b], output=distance)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
