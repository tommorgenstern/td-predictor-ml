{"custom_id": "keras#904ee76e7962a2ea5e121752e82c744e603fa567", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 10 | Files Changed: 1 | Hunks: 3 | Methods Changed: 4 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 14 | Churn Cumulative: 624 | Contributors (this commit): 4 | Commits (past 90d): 5 | Contributors (cumulative): 4 | DMM Complexity: 0.0\n\nDIFF:\n@@ -49,18 +49,10 @@ class NestedCustomLayer(keras_core.layers.Layer):\n         }\n \n \n-class WrapperLayer(keras_core.layers.Layer):\n-    def __init__(self, layer, **kwargs):\n-        super().__init__(**kwargs)\n-        self.layer = layer\n-\n+class WrapperLayer(keras_core.layers.Wrapper):\n     def call(self, x):\n         return self.layer(x)\n \n-    def get_config(self):\n-        config = super().get_config()\n-        return {\"layer\": self.layer, **config}\n-\n \n class SerializationLibTest(testing.TestCase):\n     def roundtrip(self, obj, custom_objects=None, safe_mode=True):\n@@ -210,7 +202,9 @@ class SerializationLibTest(testing.TestCase):\n         self.assertAllClose(original_output[\"foo\"], restored_output[\"foo\"])\n         self.assertAllClose(original_output[\"bar\"], restored_output[\"bar\"])\n \n-    def shared_inner_layer(self):\n+    @pytest.mark.requires_trainable_backend\n+    def test_shared_inner_layer(self):\n+        with serialization_lib.ObjectSharingScope():\n             input_1 = keras_core.Input((2,))\n             input_2 = keras_core.Input((2,))\n             shared_layer = keras_core.layers.Dense(1)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a7ef7e8d240d35e8811cf0fa2dffb9abfb04c332", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 51 | Lines Deleted: 5 | Files Changed: 4 | Hunks: 8 | Methods Changed: 8 | Complexity Δ (Sum/Max): 9/5 | Churn Δ: 56 | Churn Cumulative: 2958 | Contributors (this commit): 18 | Commits (past 90d): 66 | Contributors (cumulative): 22 | DMM Complexity: 1.0\n\nDIFF:\n@@ -24,3 +24,17 @@ class TorchLayer(torch.nn.Module):\n \n     def forward(self, *args, **kwargs):\n         return Operation.__call__(self, *args, **kwargs)\n+\n+    def _setattr_hook(self, name, value):\n+        from keras_core.layers import Layer\n+\n+        if (\n+            isinstance(value, torch.nn.Module)\n+            and not isinstance(value, Layer)\n+            and not name == \"torch_params\"\n+        ):\n+            from keras_core.utils.torch_utils import TorchModuleWrapper\n+\n+            if not isinstance(self, TorchModuleWrapper):\n+                value = TorchModuleWrapper(value)\n+        return name, value\n\n@@ -361,10 +361,6 @@ class Layer(BackendLayer, Operation):\n             )\n         self.built = True\n \n-    def _post_build(self):\n-        \"\"\"Can be overridden for per backend post build actions.\"\"\"\n-        pass\n-\n     def _lock_state(self):\n         \"\"\"Prevent further state updates, called automatically in `build()`.\"\"\"\n         if not self._tracker.locked:\n@@ -1229,6 +1225,7 @@ class Layer(BackendLayer, Operation):\n \n     def __setattr__(self, name, value):\n         # Track Variables, Layers, Metrics, SeedGenerators.\n+        name, value = self._setattr_hook(name, value)\n         if hasattr(self, \"_tracker\"):\n             value = self._tracker.track(value)\n         elif name != \"_tracker\":\n\n@@ -256,3 +256,12 @@ class Operation:\n             return values[0]\n         else:\n             return values\n+\n+    # Hooks for backend layer classes\n+    def _post_build(self):\n+        \"\"\"Can be overridden for per backend post build actions.\"\"\"\n+        pass\n+\n+    def _setattr_hook(self, name, value):\n+        \"\"\"Can be overridden for per backend post build actions.\"\"\"\n+        return name, value\n\n@@ -3,6 +3,7 @@ import pytest\n import torch\n \n from keras_core import backend\n+from keras_core import layers\n from keras_core import models\n from keras_core import testing\n from keras_core.utils.torch_utils import TorchModuleWrapper\n@@ -17,10 +18,20 @@ class Classifier(models.Model):\n         return self.fc(x)\n \n \n+class ClassifierWithNoSpecialCasing(models.Model):\n+    def __init__(self, *args, **kwargs):\n+        super().__init__(*args, **kwargs)\n+        self.fc = torch.nn.Linear(2, 4)\n+        self.fc2 = layers.Dense(2)\n+\n+    def call(self, x):\n+        return self.fc(self.fc2(x))\n+\n+\n+class TorchUtilsTest(testing.TestCase):\n     @pytest.mark.skipif(\n         backend.backend() != \"torch\", reason=\"Requires torch backend\"\n     )\n-class TorchUtilsTest(testing.TestCase):\n     def test_basic_usage(self):\n         model = Classifier()\n         self.assertEqual(len(model.layers), 1)\n@@ -28,3 +39,18 @@ class TorchUtilsTest(testing.TestCase):\n         model(np.random.random((3, 2)))\n         model.compile(optimizer=\"sgd\", loss=\"mse\")\n         model.fit(np.random.random((3, 2)), np.random.random((3, 4)))\n+\n+    @pytest.mark.skipif(\n+        backend.backend() != \"torch\", reason=\"Requires torch backend\"\n+    )\n+    def test_module_autowrapping(self):\n+        model = ClassifierWithNoSpecialCasing()\n+        self.assertTrue(isinstance(model.fc, TorchModuleWrapper))\n+        self.assertFalse(isinstance(model.fc2, TorchModuleWrapper))\n+        self.assertEqual(len(model.fc.trainable_weights), 2)\n+        model(np.random.random((3, 2)))\n+        self.assertEqual(len(model._layers), 2)\n+        self.assertEqual(len(model.fc2.trainable_weights), 2)\n+        self.assertEqual(len(model.trainable_weights), 4)\n+        model.compile(optimizer=\"sgd\", loss=\"mse\")\n+        model.fit(np.random.random((3, 2)), np.random.random((3, 4)))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#86f9517df5aa182554da2ed795a33dd9072dc1ed", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 9 | Churn Cumulative: 9 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,9 @@\n+from keras_core import backend\n+\n+\n+def is_in_jax_tracing_scope():\n+    if backend.backend() == \"jax\":\n+        x = backend.numpy.ones(())\n+        if x.__class__.__name__ == \"DynamicJaxprTracer\":\n+            return True\n+    return False\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2eb99e7a49a18fa3bb91b297335a58884c5b69d5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 515 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 5 | Complexity Δ (Sum/Max): 6/6 | Churn Δ: 515 | Churn Cumulative: 515 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,515 @@\n+\"\"\"\n+Title: English-to-Spanish translation with KerasNLP\n+Author: [Abheesht Sharma](https://github.com/abheesht17/)\n+Date created: 2022/05/26\n+Last modified: 2022/12/21\n+Description: Use KerasNLP to train a sequence-to-sequence Transformer model on the machine translation task.\n+Accelerator: GPU\n+\"\"\"\n+\n+\"\"\"\n+## Introduction\n+\n+KerasNLP provides building blocks for NLP (model layers, tokenizers, metrics, etc.) and\n+makes it convenient to construct NLP pipelines.\n+\n+In this example, we'll use KerasNLP layers to build an encoder-decoder Transformer\n+model, and train it on the English-to-Spanish machine translation task.\n+\n+This example is based on the\n+[English-to-Spanish NMT\n+example](https://keras.io/examples/nlp/neural_machine_translation_with_transformer/)\n+by [fchollet](https://twitter.com/fchollet). The original example is more low-level\n+and implements layers from scratch, whereas this example uses KerasNLP to show\n+some more advanced approaches, such as subword tokenization and using metrics\n+to compute the quality of generated translations.\n+\n+You'll learn how to:\n+\n+- Tokenize text using `keras_nlp.tokenizers.WordPieceTokenizer`.\n+- Implement a sequence-to-sequence Transformer model using KerasNLP's\n+`keras_nlp.layers.TransformerEncoder`, `keras_nlp.layers.TransformerDecoder` and\n+`keras_nlp.layers.TokenAndPositionEmbedding` layers, and train it.\n+- Use `keras_nlp.samplers` to generate translations of unseen input sentences\n+ using the top-p decoding strategy!\n+\n+Don't worry if you aren't familiar with KerasNLP. This tutorial will start with\n+the basics. Let's dive right in!\n+\"\"\"\n+\n+\"\"\"\n+## Setup\n+\n+Before we start implementing the pipeline, let's import all the libraries we need.\n+\"\"\"\n+\n+\"\"\"shell\n+!pip install -q rouge-score\n+!pip install -q git+https://github.com/keras-team/keras-nlp.git --upgrade\n+\"\"\"\n+\n+import keras_nlp\n+import pathlib\n+import random\n+\n+import keras_core as keras\n+from keras_core import ops\n+\n+import tensorflow.data as tf_data\n+from tensorflow_text.tools.wordpiece_vocab import (\n+    bert_vocab_from_dataset as bert_vocab,\n+)\n+\n+\"\"\"\n+Let's also define our parameters/hyperparameters.\n+\"\"\"\n+\n+BATCH_SIZE = 64\n+EPOCHS = 1  # This should be at least 10 for convergence\n+MAX_SEQUENCE_LENGTH = 40\n+ENG_VOCAB_SIZE = 15000\n+SPA_VOCAB_SIZE = 15000\n+\n+EMBED_DIM = 256\n+INTERMEDIATE_DIM = 2048\n+NUM_HEADS = 8\n+\n+\"\"\"\n+## Downloading the data\n+\n+We'll be working with an English-to-Spanish translation dataset\n+provided by [Anki](https://www.manythings.org/anki/). Let's download it:\n+\"\"\"\n+\n+text_file = keras.utils.get_file(\n+    fname=\"spa-eng.zip\",\n+    origin=\"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\",\n+    extract=True,\n+)\n+text_file = pathlib.Path(text_file).parent / \"spa-eng\" / \"spa.txt\"\n+\n+\"\"\"\n+## Parsing the data\n+\n+Each line contains an English sentence and its corresponding Spanish sentence.\n+The English sentence is the *source sequence* and Spanish one is the *target sequence*.\n+Before adding the text to a list, we convert it to lowercase.\n+\"\"\"\n+\n+with open(text_file) as f:\n+    lines = f.read().split(\"\\n\")[:-1]\n+text_pairs = []\n+for line in lines:\n+    eng, spa = line.split(\"\\t\")\n+    eng = eng.lower()\n+    spa = spa.lower()\n+    text_pairs.append((eng, spa))\n+\n+\"\"\"\n+Here's what our sentence pairs look like:\n+\"\"\"\n+\n+for _ in range(5):\n+    print(random.choice(text_pairs))\n+\n+\"\"\"\n+Now, let's split the sentence pairs into a training set, a validation set,\n+and a test set.\n+\"\"\"\n+\n+random.shuffle(text_pairs)\n+num_val_samples = int(0.15 * len(text_pairs))\n+num_train_samples = len(text_pairs) - 2 * num_val_samples\n+train_pairs = text_pairs[:num_train_samples]\n+val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n+test_pairs = text_pairs[num_train_samples + num_val_samples :]\n+\n+print(f\"{len(text_pairs)} total pairs\")\n+print(f\"{len(train_pairs)} training pairs\")\n+print(f\"{len(val_pairs)} validation pairs\")\n+print(f\"{len(test_pairs)} test pairs\")\n+\n+\n+\"\"\"\n+## Tokenizing the data\n+\n+We'll define two tokenizers - one for the source language (English), and the other\n+for the target language (Spanish). We'll be using\n+`keras_nlp.tokenizers.WordPieceTokenizer` to tokenize the text.\n+`keras_nlp.tokenizers.WordPieceTokenizer` takes a WordPiece vocabulary\n+and has functions for tokenizing the text, and detokenizing sequences of tokens.\n+\n+Before we define the two tokenizers, we first need to train them on the dataset\n+we have. The WordPiece tokenization algorithm is a subword tokenization algorithm;\n+training it on a corpus gives us a vocabulary of subwords. A subword tokenizer\n+is a compromise between word tokenizers (word tokenizers need very large\n+vocabularies for good coverage of input words), and character tokenizers\n+(characters don't really encode meaning like words do). Luckily, KerasNLP\n+makes it very simple to train WordPiece on a corpus with the\n+`keras_nlp.tokenizers.compute_word_piece_vocabulary` utility.\n+\"\"\"\n+\n+\n+def train_word_piece(text_samples, vocab_size, reserved_tokens):\n+    word_piece_ds = tf_data.Dataset.from_tensor_slices(text_samples)\n+    vocab = keras_nlp.tokenizers.compute_word_piece_vocabulary(\n+        word_piece_ds.batch(1000).prefetch(2),\n+        vocabulary_size=vocab_size,\n+        reserved_tokens=reserved_tokens,\n+    )\n+    return vocab\n+\n+\n+\"\"\"\n+Every vocabulary has a few special, reserved tokens. We have four such tokens:\n+\n+- `\"[PAD]\"` - Padding token. Padding tokens are appended to the input sequence\n+length when the input sequence length is shorter than the maximum sequence length.\n+- `\"[UNK]\"` - Unknown token.\n+- `\"[START]\"` - Token that marks the start of the input sequence.\n+- `\"[END]\"` - Token that marks the end of the input sequence.\n+\"\"\"\n+\n+reserved_tokens = [\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"]\n+\n+eng_samples = [text_pair[0] for text_pair in train_pairs]\n+eng_vocab = train_word_piece(eng_samples, ENG_VOCAB_SIZE, reserved_tokens)\n+\n+spa_samples = [text_pair[1] for text_pair in train_pairs]\n+spa_vocab = train_word_piece(spa_samples, SPA_VOCAB_SIZE, reserved_tokens)\n+\n+\"\"\"\n+Let's see some tokens!\n+\"\"\"\n+\n+print(\"English Tokens: \", eng_vocab[100:110])\n+print(\"Spanish Tokens: \", spa_vocab[100:110])\n+\n+\"\"\"\n+Now, let's define the tokenizers. We will configure the tokenizers with the\n+the vocabularies trained above.\n+\"\"\"\n+\n+eng_tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n+    vocabulary=eng_vocab, lowercase=False\n+)\n+spa_tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n+    vocabulary=spa_vocab, lowercase=False\n+)\n+\n+\"\"\"\n+Let's try and tokenize a sample from our dataset! To verify whether the text has\n+been tokenized correctly, we can also detokenize the list of tokens back to the\n+original text.\n+\"\"\"\n+\n+eng_input_ex = text_pairs[0][0]\n+eng_tokens_ex = eng_tokenizer.tokenize(eng_input_ex)\n+print(\"English sentence: \", eng_input_ex)\n+print(\"Tokens: \", eng_tokens_ex)\n+print(\n+    \"Recovered text after detokenizing: \",\n+    eng_tokenizer.detokenize(eng_tokens_ex),\n+)\n+\n+print()\n+\n+spa_input_ex = text_pairs[0][1]\n+spa_tokens_ex = spa_tokenizer.tokenize(spa_input_ex)\n+print(\"Spanish sentence: \", spa_input_ex)\n+print(\"Tokens: \", spa_tokens_ex)\n+print(\n+    \"Recovered text after detokenizing: \",\n+    spa_tokenizer.detokenize(spa_tokens_ex),\n+)\n+\n+\"\"\"\n+## Format datasets\n+\n+Next, we'll format our datasets.\n+\n+At each training step, the model will seek to predict target words N+1 (and beyond)\n+using the source sentence and the target words 0 to N.\n+\n+As such, the training dataset will yield a tuple `(inputs, targets)`, where:\n+\n+- `inputs` is a dictionary with the keys `encoder_inputs` and `decoder_inputs`.\n+`encoder_inputs` is the tokenized source sentence and `decoder_inputs` is the target\n+sentence \"so far\",\n+that is to say, the words 0 to N used to predict word N+1 (and beyond) in the target\n+sentence.\n+- `target` is the target sentence offset by one step:\n+it provides the next words in the target sentence -- what the model will try to predict.\n+\n+We will add special tokens, `\"[START]\"` and `\"[END]\"`, to the input Spanish\n+sentence after tokenizing the text. We will also pad the input to a fixed length.\n+This can be easily done using `keras_nlp.layers.StartEndPacker`.\n+\"\"\"\n+\n+\n+def preprocess_batch(eng, spa):\n+    batch_size = ops.shape(spa)[0]\n+\n+    eng = eng_tokenizer(eng)\n+    spa = spa_tokenizer(spa)\n+\n+    # Pad `eng` to `MAX_SEQUENCE_LENGTH`.\n+    eng_start_end_packer = keras_nlp.layers.StartEndPacker(\n+        sequence_length=MAX_SEQUENCE_LENGTH,\n+        pad_value=eng_tokenizer.token_to_id(\"[PAD]\"),\n+    )\n+    eng = eng_start_end_packer(eng)\n+\n+    # Add special tokens (`\"[START]\"` and `\"[END]\"`) to `spa` and pad it as well.\n+    spa_start_end_packer = keras_nlp.layers.StartEndPacker(\n+        sequence_length=MAX_SEQUENCE_LENGTH + 1,\n+        start_value=spa_tokenizer.token_to_id(\"[START]\"),\n+        end_value=spa_tokenizer.token_to_id(\"[END]\"),\n+        pad_value=spa_tokenizer.token_to_id(\"[PAD]\"),\n+    )\n+    spa = spa_start_end_packer(spa)\n+\n+    return (\n+        {\n+            \"encoder_inputs\": eng,\n+            \"decoder_inputs\": spa[:, :-1],\n+        },\n+        spa[:, 1:],\n+    )\n+\n+\n+def make_dataset(pairs):\n+    eng_texts, spa_texts = zip(*pairs)\n+    eng_texts = list(eng_texts)\n+    spa_texts = list(spa_texts)\n+    dataset = tf_data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n+    dataset = dataset.batch(BATCH_SIZE)\n+    dataset = dataset.map(preprocess_batch, num_parallel_calls=tf_data.AUTOTUNE)\n+    return dataset.shuffle(2048).prefetch(16).cache()\n+\n+\n+train_ds = make_dataset(train_pairs)\n+val_ds = make_dataset(val_pairs)\n+\n+\"\"\"\n+Let's take a quick look at the sequence shapes\n+(we have batches of 64 pairs, and all sequences are 40 steps long):\n+\"\"\"\n+\n+for inputs, targets in train_ds.take(1):\n+    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n+    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n+    print(f\"targets.shape: {targets.shape}\")\n+\n+\n+\"\"\"\n+## Building the model\n+\n+Now, let's move on to the exciting part - defining our model!\n+We first need an embedding layer, i.e., a vector for every token in our input sequence.\n+This embedding layer can be initialised randomly. We also need a positional\n+embedding layer which encodes the word order in the sequence. The convention is\n+to add these two embeddings. KerasNLP has a `keras_nlp.layers.TokenAndPositionEmbedding `\n+layer which does all of the above steps for us.\n+\n+Our sequence-to-sequence Transformer consists of a `keras_nlp.layers.TransformerEncoder`\n+layer and a `keras_nlp.layers.TransformerDecoder` layer chained together.\n+\n+The source sequence will be passed to `keras_nlp.layers.TransformerEncoder`, which\n+will produce a new representation of it. This new representation will then be passed\n+to the `keras_nlp.layers.TransformerDecoder`, together with the target sequence\n+so far (target words 0 to N). The `keras_nlp.layers.TransformerDecoder` will\n+then seek to predict the next words in the target sequence (N+1 and beyond).\n+\n+A key detail that makes this possible is causal masking.\n+The `keras_nlp.layers.TransformerDecoder` sees the entire sequence at once, and\n+thus we must make sure that it only uses information from target tokens 0 to N\n+when predicting token N+1 (otherwise, it could use information from the future,\n+which would result in a model that cannot be used at inference time). Causal masking\n+is enabled by default in `keras_nlp.layers.TransformerDecoder`.\n+\n+We also need to mask the padding tokens (`\"[PAD]\"`). For this, we can set the\n+`mask_zero` argument of the `keras_nlp.layers.TokenAndPositionEmbedding` layer\n+to True. This will then be propagated to all subsequent layers.\n+\"\"\"\n+\n+# Encoder\n+encoder_inputs = keras.Input(\n+    shape=(None,), dtype=\"int64\", name=\"encoder_inputs\"\n+)\n+\n+x = keras_nlp.layers.TokenAndPositionEmbedding(\n+    vocabulary_size=ENG_VOCAB_SIZE,\n+    sequence_length=MAX_SEQUENCE_LENGTH,\n+    embedding_dim=EMBED_DIM,\n+)(encoder_inputs)\n+\n+encoder_outputs = keras_nlp.layers.TransformerEncoder(\n+    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n+)(inputs=x)\n+encoder = keras.Model(encoder_inputs, encoder_outputs)\n+\n+\n+# Decoder\n+decoder_inputs = keras.Input(\n+    shape=(None,), dtype=\"int64\", name=\"decoder_inputs\"\n+)\n+encoded_seq_inputs = keras.Input(\n+    shape=(None, EMBED_DIM), name=\"decoder_state_inputs\"\n+)\n+\n+x = keras_nlp.layers.TokenAndPositionEmbedding(\n+    vocabulary_size=SPA_VOCAB_SIZE,\n+    sequence_length=MAX_SEQUENCE_LENGTH,\n+    embedding_dim=EMBED_DIM,\n+)(decoder_inputs)\n+\n+x = keras_nlp.layers.TransformerDecoder(\n+    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n+)(decoder_sequence=x, encoder_sequence=encoded_seq_inputs)\n+x = keras.layers.Dropout(0.5)(x)\n+decoder_outputs = keras.layers.Dense(SPA_VOCAB_SIZE, activation=\"softmax\")(x)\n+decoder = keras.Model(\n+    [\n+        decoder_inputs,\n+        encoded_seq_inputs,\n+    ],\n+    decoder_outputs,\n+)\n+decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n+\n+transformer = keras.Model(\n+    [encoder_inputs, decoder_inputs],\n+    decoder_outputs,\n+    name=\"transformer\",\n+)\n+\n+\"\"\"\n+## Training our model\n+\n+We'll use accuracy as a quick way to monitor training progress on the validation data.\n+Note that machine translation typically uses BLEU scores as well as other metrics,\n+rather than accuracy. However, in order to use metrics like ROUGE, BLEU, etc. we\n+will have decode the probabilities and generate the text. Text generation is\n+computationally expensive, and performing this during training is not recommended.\n+\n+Here we only train for 1 epoch, but to get the model to actually converge\n+you should train for at least 10 epochs.\n+\"\"\"\n+\n+transformer.summary()\n+transformer.compile(\n+    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n+)\n+transformer.fit(train_ds, epochs=EPOCHS, validation_data=val_ds)\n+\n+\"\"\"\n+## Decoding test sentences (qualitative analysis)\n+\n+Finally, let's demonstrate how to translate brand new English sentences.\n+We simply feed into the model the tokenized English sentence\n+as well as the target token `\"[START]\"`. The model outputs probabilities of the\n+next token. We then we repeatedly generated the next token conditioned on the\n+tokens generated so far, until we hit the token `\"[END]\"`.\n+\n+For decoding, we will use the `keras_nlp.samplers` module from\n+KerasNLP. Greedy Decoding is a text decoding method which outputs the most\n+likely next token at each time step, i.e., the token with the highest probability.\n+\"\"\"\n+\n+\n+def decode_sequences(input_sentences):\n+    batch_size = 1\n+\n+    # Tokenize the encoder input.\n+    encoder_input_tokens = ops.convert_to_tensor(eng_tokenizer(input_sentences))\n+    if len(encoder_input_tokens[0]) < MAX_SEQUENCE_LENGTH:\n+        pads = ops.full(\n+            (1, MAX_SEQUENCE_LENGTH - len(encoder_input_tokens[0])), 0\n+        )\n+        encoder_input_tokens = ops.concatenate([encoder_input_tokens, pads], 1)\n+\n+    # Define a function that outputs the next token's probability given the\n+    # input sequence.\n+    def next(prompt, cache, index):\n+        logits = transformer([encoder_input_tokens, prompt])[:, index - 1, :]\n+        # Ignore hidden states for now; only needed for contrastive search.\n+        hidden_states = None\n+        return logits, hidden_states, cache\n+\n+    # Build a prompt of length 40 with a start token and padding tokens.\n+    length = 40\n+    start = ops.full((batch_size, 1), spa_tokenizer.token_to_id(\"[START]\"))\n+    pad = ops.full((batch_size, length - 1), spa_tokenizer.token_to_id(\"[PAD]\"))\n+    prompt = ops.concatenate((start, pad), axis=-1)\n+\n+    generated_tokens = keras_nlp.samplers.GreedySampler()(\n+        next,\n+        prompt,\n+        end_token_id=spa_tokenizer.token_to_id(\"[END]\"),\n+        index=1,  # Start sampling after start token.\n+    )\n+    generated_sentences = spa_tokenizer.detokenize(generated_tokens)\n+    return generated_sentences\n+\n+\n+test_eng_texts = [pair[0] for pair in test_pairs]\n+for i in range(2):\n+    input_sentence = random.choice(test_eng_texts)\n+    translated = decode_sequences([input_sentence])\n+    translated = translated.numpy()[0].decode(\"utf-8\")\n+    translated = (\n+        translated.replace(\"[PAD]\", \"\")\n+        .replace(\"[START]\", \"\")\n+        .replace(\"[END]\", \"\")\n+        .strip()\n+    )\n+    print(f\"** Example {i} **\")\n+    print(input_sentence)\n+    print(translated)\n+    print()\n+\n+\"\"\"\n+## Evaluating our model (quantitative analysis)\n+\n+There are many metrics which are used for text generation tasks. Here, to\n+evaluate translations generated by our model, let's compute the ROUGE-1 and\n+ROUGE-2 scores. Essentially, ROUGE-N is a score based on the number of common\n+n-grams between the reference text and the generated text. ROUGE-1 and ROUGE-2\n+use the number of common unigrams and bigrams, respectively.\n+\n+We will calculate the score over 30 test samples (since decoding is an\n+expensive process).\n+\"\"\"\n+\n+rouge_1 = keras_nlp.metrics.RougeN(order=1)\n+rouge_2 = keras_nlp.metrics.RougeN(order=2)\n+\n+for test_pair in test_pairs[:30]:\n+    input_sentence = test_pair[0]\n+    reference_sentence = test_pair[1]\n+\n+    translated_sentence = decode_sequences([input_sentence])\n+    translated_sentence = translated_sentence.numpy()[0].decode(\"utf-8\")\n+    translated_sentence = (\n+        translated_sentence.replace(\"[PAD]\", \"\")\n+        .replace(\"[START]\", \"\")\n+        .replace(\"[END]\", \"\")\n+        .strip()\n+    )\n+\n+    rouge_1(reference_sentence, translated_sentence)\n+    rouge_2(reference_sentence, translated_sentence)\n+\n+print(\"ROUGE-1 Score: \", rouge_1.result())\n+print(\"ROUGE-2 Score: \", rouge_2.result())\n+\n+\"\"\"\n+After 10 epochs, the scores are as follows:\n+\n+|               | **ROUGE-1** | **ROUGE-2** |\n+|:-------------:|:-----------:|:-----------:|\n+| **Precision** |    0.568    |    0.374    |\n+|   **Recall**  |    0.615    |    0.394    |\n+|  **F1 Score** |    0.579    |    0.381    |\n+\"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7bfc6df3955115b1b20ca50b9caec834c8dd2308", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 105 | Lines Deleted: 105 | Files Changed: 18 | Hunks: 81 | Methods Changed: 44 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 210 | Churn Cumulative: 6474 | Contributors (this commit): 22 | Commits (past 90d): 138 | Contributors (cumulative): 99 | DMM Complexity: None\n\nDIFF:\n@@ -15,19 +15,19 @@ class ComputeOutputSpecTest(testing.TestCase):\n         out = backend.compute_output_spec(\n             example_fn, backend.KerasTensor((2, 3))\n         )\n-        self.assertTrue(isinstance(out, backend.KerasTensor))\n+        self.assertIsInstance(out, backend.KerasTensor)\n         self.assertEqual(out.shape, (2, 3, 2))\n \n         out = backend.compute_output_spec(\n             example_fn, backend.KerasTensor((None, 3))\n         )\n-        self.assertTrue(isinstance(out, backend.KerasTensor))\n+        self.assertIsInstance(out, backend.KerasTensor)\n         self.assertEqual(out.shape, (None, 3, 2))\n \n         out = backend.compute_output_spec(\n             example_fn, backend.KerasTensor((2, None))\n         )\n-        self.assertTrue(isinstance(out, backend.KerasTensor))\n+        self.assertIsInstance(out, backend.KerasTensor)\n         self.assertEqual(out.shape, (2, None, 2))\n \n     @pytest.mark.skipif(\n@@ -51,7 +51,7 @@ class ComputeOutputSpecTest(testing.TestCase):\n         out = backend.compute_output_spec(\n             instance.example_meta_fn, backend.KerasTensor((2, 3))\n         )\n-        self.assertTrue(isinstance(out, backend.KerasTensor))\n+        self.assertIsInstance(out, backend.KerasTensor)\n         self.assertTrue(instance.canary)\n         self.assertEqual(out.shape, (2, 3, 2))\n \n@@ -59,6 +59,6 @@ class ComputeOutputSpecTest(testing.TestCase):\n         out = backend.compute_output_spec(\n             instance.example_meta_fn, backend.KerasTensor((2, None))\n         )\n-        self.assertTrue(isinstance(out, backend.KerasTensor))\n+        self.assertIsInstance(out, backend.KerasTensor)\n         self.assertTrue(instance.canary)\n         self.assertEqual(out.shape, (2, None, 2))\n\n@@ -36,7 +36,7 @@ class LayerTest(testing.TestCase):\n \n         layer = TestLayer()\n         out = layer.compute_output_spec(backend.KerasTensor((2, 3)))\n-        self.assertTrue(isinstance(out, tuple))\n+        self.assertIsInstance(out, tuple)\n         self.assertEqual(len(out), 2)\n         self.assertEqual(out[0].shape, (2, 3))\n         self.assertEqual(out[1].shape, (2, 3))\n@@ -51,7 +51,7 @@ class LayerTest(testing.TestCase):\n \n         layer = TestLayer()\n         out = layer.compute_output_spec(backend.KerasTensor((2, 3)))\n-        self.assertTrue(isinstance(out, list))\n+        self.assertIsInstance(out, list)\n         self.assertEqual(len(out), 2)\n         self.assertEqual(out[0].shape, (2, 3))\n         self.assertEqual(out[1].shape, (2, 3))\n@@ -66,7 +66,7 @@ class LayerTest(testing.TestCase):\n \n         layer = TestLayer()\n         out = layer.compute_output_spec(backend.KerasTensor((2, 3)))\n-        self.assertTrue(isinstance(out, dict))\n+        self.assertIsInstance(out, dict)\n         self.assertEqual(len(out), 2)\n         self.assertEqual(out[\"1\"].shape, (2, 3))\n         self.assertEqual(out[\"2\"].shape, (2, 3))\n@@ -85,14 +85,14 @@ class LayerTest(testing.TestCase):\n \n         layer = TestLayer()\n         out = layer.compute_output_spec(backend.KerasTensor((2, 3)))\n-        self.assertTrue(isinstance(out, tuple))\n+        self.assertIsInstance(out, tuple)\n         self.assertEqual(len(out), 3)\n         self.assertEqual(out[0].shape, (2, 3))\n-        self.assertTrue(isinstance(out[1], tuple))\n+        self.assertIsInstance(out[1], tuple)\n         self.assertEqual(len(out[1]), 2)\n         self.assertEqual(out[1][0].shape, (2, 3))\n         self.assertEqual(out[1][1].shape, (2, 3))\n-        self.assertTrue(isinstance(out[2], tuple))\n+        self.assertIsInstance(out[2], tuple)\n         self.assertEqual(len(out[2]), 2)\n         self.assertEqual(out[2][0].shape, (2, 3))\n         self.assertEqual(out[2][1].shape, (2, 3))\n@@ -110,10 +110,10 @@ class LayerTest(testing.TestCase):\n \n         layer = TestLayer()\n         out = layer.compute_output_spec(backend.KerasTensor((2, 3)))\n-        self.assertTrue(isinstance(out, dict))\n+        self.assertIsInstance(out, dict)\n         self.assertEqual(len(out), 2)\n         self.assertEqual(out[\"1\"].shape, (2, 3))\n-        self.assertTrue(isinstance(out[\"2\"], dict))\n+        self.assertIsInstance(out[\"2\"], dict)\n         self.assertEqual(len(out[\"2\"]), 2)\n         self.assertEqual(out[\"2\"][\"11\"].shape, (2, 3))\n         self.assertEqual(out[\"2\"][\"22\"].shape, (2, 3))\n\n@@ -156,13 +156,13 @@ class MetricTest(testing.TestCase):\n \n     def test_get_method(self):\n         metric = metrics_module.get(\"mse\")\n-        self.assertTrue(isinstance(metric, metrics_module.MeanSquaredError))\n+        self.assertIsInstance(metric, metrics_module.MeanSquaredError)\n \n         metric = metrics_module.get(\"mean_squared_error\")\n-        self.assertTrue(isinstance(metric, metrics_module.MeanSquaredError))\n+        self.assertIsInstance(metric, metrics_module.MeanSquaredError)\n \n         metric = metrics_module.get(\"categorical_accuracy\")\n-        self.assertTrue(isinstance(metric, metrics_module.CategoricalAccuracy))\n+        self.assertIsInstance(metric, metrics_module.CategoricalAccuracy)\n \n         metric = metrics_module.get(None)\n         self.assertEqual(metric, None)\n\n@@ -24,8 +24,8 @@ class FunctionalTest(testing.TestCase):\n         model.summary()\n \n         self.assertEqual(model.name, \"basic\")\n-        self.assertTrue(isinstance(model, Functional))\n-        self.assertTrue(isinstance(model, Model))\n+        self.assertIsInstance(model, Functional)\n+        self.assertIsInstance(model, Model)\n \n         # Eager call\n         in_val = [np.random.random((2, 3)), np.random.random((2, 3))]\n@@ -72,14 +72,14 @@ class FunctionalTest(testing.TestCase):\n         # Eager call\n         in_val = np.random.random((2, 3))\n         out_val = model(in_val)\n-        self.assertTrue(isinstance(out_val, list))\n+        self.assertIsInstance(out_val, list)\n         self.assertEqual(len(out_val), 2)\n         self.assertEqual(out_val[0].shape, (2, 4))\n         self.assertEqual(out_val[1].shape, (2, 5))\n \n         # Symbolic call\n         out_val = model(Input(shape=(3,), batch_size=2))\n-        self.assertTrue(isinstance(out_val, list))\n+        self.assertIsInstance(out_val, list)\n         self.assertEqual(len(out_val), 2)\n         self.assertEqual(out_val[0].shape, (2, 4))\n         self.assertEqual(out_val[1].shape, (2, 5))\n\n@@ -69,7 +69,7 @@ def _get_model_multi_outputs_dict():\n class ModelTest(testing.TestCase, parameterized.TestCase):\n     def test_functional_rerouting(self):\n         model = _get_model()\n-        self.assertTrue(isinstance(model, Functional))\n+        self.assertIsInstance(model, Functional)\n \n     def test_json_serialization(self):\n         model = _get_model()\n@@ -113,7 +113,7 @@ class ModelTest(testing.TestCase, parameterized.TestCase):\n         new_model = Model.from_config(\n             config, custom_objects={\"CustomDense\": CustomDense}\n         )\n-        self.assertTrue(isinstance(new_model, Functional))\n+        self.assertIsInstance(new_model, Functional)\n \n     @parameterized.named_parameters(\n         (\"single_output_1\", _get_model_single_output, None),\n@@ -131,7 +131,7 @@ class ModelTest(testing.TestCase, parameterized.TestCase):\n     )\n     def test_functional_single_output(self, model_fn, loss_type):\n         model = model_fn()\n-        self.assertTrue(isinstance(model, Functional))\n+        self.assertIsInstance(model, Functional)\n         loss = \"mean_squared_error\"\n         if loss_type == \"list\":\n             loss = [loss]\n@@ -172,7 +172,7 @@ class ModelTest(testing.TestCase, parameterized.TestCase):\n \n     def test_functional_list_outputs_list_losses(self):\n         model = _get_model_multi_outputs_list()\n-        self.assertTrue(isinstance(model, Functional))\n+        self.assertIsInstance(model, Functional)\n         x = np.random.rand(8, 3)\n         y1 = np.random.rand(8, 1)\n         y2 = np.random.randint(0, 2, (8, 1))\n@@ -203,7 +203,7 @@ class ModelTest(testing.TestCase, parameterized.TestCase):\n \n     def test_functional_list_outputs_list_losses_abbr(self):\n         model = _get_model_multi_outputs_list()\n-        self.assertTrue(isinstance(model, Functional))\n+        self.assertIsInstance(model, Functional)\n         x = np.random.rand(8, 3)\n         y1 = np.random.rand(8, 1)\n         y2 = np.random.randint(0, 2, (8, 1))\n@@ -236,7 +236,7 @@ class ModelTest(testing.TestCase, parameterized.TestCase):\n \n     def test_functional_list_outputs_nested_list_losses(self):\n         model = _get_model_multi_outputs_list()\n-        self.assertTrue(isinstance(model, Functional))\n+        self.assertIsInstance(model, Functional)\n         x = np.random.rand(8, 3)\n         y1 = np.random.rand(8, 1)\n         y2 = np.random.randint(0, 2, (8, 1))\n@@ -267,7 +267,7 @@ class ModelTest(testing.TestCase, parameterized.TestCase):\n \n     def test_functional_dict_outputs_dict_losses(self):\n         model = _get_model_multi_outputs_dict()\n-        self.assertTrue(isinstance(model, Functional))\n+        self.assertIsInstance(model, Functional)\n         x = np.random.rand(8, 3)\n         y1 = np.random.rand(8, 1)\n         y2 = np.random.randint(0, 2, (8, 1))\n@@ -313,7 +313,7 @@ class ModelTest(testing.TestCase, parameterized.TestCase):\n \n     def test_functional_list_outputs_dict_losses_metrics(self):\n         model = _get_model_multi_outputs_list()\n-        self.assertTrue(isinstance(model, Functional))\n+        self.assertIsInstance(model, Functional)\n         x = np.random.rand(8, 3)\n         y1 = np.random.rand(8, 1)\n         y2 = np.random.randint(0, 2, (8, 1))\n@@ -353,7 +353,7 @@ class ModelTest(testing.TestCase, parameterized.TestCase):\n \n     def test_functional_list_outputs_dict_losses_metrics_uniq_weighted(self):\n         model = _get_model_multi_outputs_list()\n-        self.assertTrue(isinstance(model, Functional))\n+        self.assertIsInstance(model, Functional)\n         x = np.random.rand(8, 3)\n         y1 = np.random.rand(8, 1)\n         y2 = np.random.randint(0, 2, (8, 1))\n@@ -394,7 +394,7 @@ class ModelTest(testing.TestCase, parameterized.TestCase):\n \n     def test_functional_list_outputs_dict_losses_partial_metrics(self):\n         model = _get_model_multi_outputs_list()\n-        self.assertTrue(isinstance(model, Functional))\n+        self.assertIsInstance(model, Functional)\n         x = np.random.rand(8, 3)\n         y1 = np.random.rand(8, 1)\n         y2 = np.random.randint(0, 2, (8, 1))\n@@ -425,7 +425,7 @@ class ModelTest(testing.TestCase, parameterized.TestCase):\n \n     def test_functional_list_outputs_dict_losses_invalid_keys(self):\n         model = _get_model_multi_outputs_list()\n-        self.assertTrue(isinstance(model, Functional))\n+        self.assertIsInstance(model, Functional)\n         x = np.random.rand(8, 3)\n         y1 = np.random.rand(8, 1)\n         y2 = np.random.randint(0, 2, (8, 1))\n@@ -446,7 +446,7 @@ class ModelTest(testing.TestCase, parameterized.TestCase):\n \n     def test_functional_list_outputs_dict_losses_no_output_names(self):\n         model = _get_model_multi_outputs_list_no_output_names()\n-        self.assertTrue(isinstance(model, Functional))\n+        self.assertIsInstance(model, Functional)\n         x = np.random.rand(8, 3)\n         y1 = np.random.rand(8, 1)\n         y2 = np.random.randint(0, 2, (8, 1))\n@@ -464,7 +464,7 @@ class ModelTest(testing.TestCase, parameterized.TestCase):\n \n     def test_functional_list_outputs_dict_metrics_invalid_keys(self):\n         model = _get_model_multi_outputs_list()\n-        self.assertTrue(isinstance(model, Functional))\n+        self.assertIsInstance(model, Functional)\n         x = np.random.rand(8, 3)\n         y1 = np.random.rand(8, 1)\n         y2 = np.random.randint(0, 2, (8, 1))\n@@ -488,7 +488,7 @@ class ModelTest(testing.TestCase, parameterized.TestCase):\n \n     def test_functional_dict_outputs_dict_losses_invalid_keys(self):\n         model = _get_model_multi_outputs_dict()\n-        self.assertTrue(isinstance(model, Functional))\n+        self.assertIsInstance(model, Functional)\n         x = np.random.rand(8, 3)\n         y1 = np.random.rand(8, 1)\n         y2 = np.random.randint(0, 2, (8, 1))\n@@ -509,7 +509,7 @@ class ModelTest(testing.TestCase, parameterized.TestCase):\n \n     def test_functional_dict_outputs_dict_metrics_invalid_keys(self):\n         model = _get_model_multi_outputs_dict()\n-        self.assertTrue(isinstance(model, Functional))\n+        self.assertIsInstance(model, Functional)\n         x = np.random.rand(8, 3)\n         y1 = np.random.rand(8, 1)\n         y2 = np.random.randint(0, 2, (8, 1))\n@@ -533,7 +533,7 @@ class ModelTest(testing.TestCase, parameterized.TestCase):\n \n     def test_functional_list_outputs_invalid_nested_list_losses(self):\n         model = _get_model_multi_outputs_list()\n-        self.assertTrue(isinstance(model, Functional))\n+        self.assertIsInstance(model, Functional)\n         x = np.random.rand(8, 3)\n         y1 = np.random.rand(8, 1)\n         y2 = np.random.randint(0, 2, (8, 1))\n\n@@ -17,9 +17,9 @@ class OptimizerTest(testing.TestCase):\n \n     def test_get_method(self):\n         obj = optimizers.get(\"sgd\")\n-        self.assertTrue(isinstance(obj, optimizers.SGD))\n+        self.assertIsInstance(obj, optimizers.SGD)\n         obj = optimizers.get(\"adamw\")\n-        self.assertTrue(isinstance(obj, optimizers.AdamW))\n+        self.assertIsInstance(obj, optimizers.AdamW)\n \n         obj = optimizers.get(None)\n         self.assertEqual(obj, None)\n\n@@ -130,7 +130,7 @@ class RandomTest(testing.TestCase, parameterized.TestCase):\n             return x\n \n         x = train_step(x)\n-        self.assertTrue(isinstance(x, jnp.ndarray))\n+        self.assertIsInstance(x, jnp.ndarray)\n \n     def test_dropout_noise_shape(self):\n         inputs = ops.ones((2, 3, 5, 7))\n@@ -152,7 +152,7 @@ class RandomTest(testing.TestCase, parameterized.TestCase):\n         self.assertEqual(rng.shape, (2,))\n         self.assertEqual(rng.dtype, jnp.uint32)\n         x = random.randint((3, 5), 0, 10, seed=rng)\n-        self.assertTrue(isinstance(x, jnp.ndarray))\n+        self.assertIsInstance(x, jnp.ndarray)\n \n     @pytest.mark.skipif(\n         keras_core.backend.backend() != \"jax\",\n\n@@ -236,7 +236,7 @@ class TestCase(unittest.TestCase):\n                         msg=\"Unexpected output shape\",\n                     )\n                 elif isinstance(expected_output_shape, dict):\n-                    self.assertTrue(isinstance(output, dict))\n+                    self.assertIsInstance(output, dict)\n                     self.assertEqual(\n                         set(output.keys()),\n                         set(expected_output_shape.keys()),\n@@ -251,7 +251,7 @@ class TestCase(unittest.TestCase):\n                         msg=\"Unexpected output shape\",\n                     )\n                 elif isinstance(expected_output_shape, list):\n-                    self.assertTrue(isinstance(output, list))\n+                    self.assertIsInstance(output, list)\n                     self.assertEqual(\n                         len(output),\n                         len(\n\n@@ -35,14 +35,14 @@ class TestCompileMetrics(testing.TestCase):\n             y_true, y_pred, sample_weight=sample_weight\n         )\n         result = compile_metrics.result()\n-        self.assertTrue(isinstance(result, dict))\n+        self.assertIsInstance(result, dict)\n         self.assertEqual(len(result), 2)\n         self.assertAllClose(result[\"mean_squared_error\"], 0.055833336)\n         self.assertAllClose(result[\"weighted_mean_squared_error\"], 0.0725)\n \n         compile_metrics.reset_state()\n         result = compile_metrics.result()\n-        self.assertTrue(isinstance(result, dict))\n+        self.assertIsInstance(result, dict)\n         self.assertEqual(len(result), 2)\n         self.assertAllClose(result[\"mean_squared_error\"], 0.0)\n         self.assertAllClose(result[\"weighted_mean_squared_error\"], 0.0)\n@@ -98,14 +98,14 @@ class TestCompileMetrics(testing.TestCase):\n             y_true, y_pred, sample_weight=sample_weight\n         )\n         result = compile_metrics.result()\n-        self.assertTrue(isinstance(result, dict))\n+        self.assertIsInstance(result, dict)\n         self.assertEqual(len(result), 8)\n         self.assertAllClose(result[\"mean_squared_error\"], 0.055833336)\n         self.assertAllClose(result[\"weighted_mean_squared_error\"], 0.0725)\n \n         compile_metrics.reset_state()\n         result = compile_metrics.result()\n-        self.assertTrue(isinstance(result, dict))\n+        self.assertIsInstance(result, dict)\n         self.assertEqual(len(result), 8)\n         self.assertAllClose(result[\"mean_squared_error\"], 0.0)\n         self.assertAllClose(result[\"weighted_mean_squared_error\"], 0.0)\n@@ -167,7 +167,7 @@ class TestCompileMetrics(testing.TestCase):\n             y_true, y_pred, sample_weight=sample_weight\n         )\n         result = compile_metrics.result()\n-        self.assertTrue(isinstance(result, dict))\n+        self.assertIsInstance(result, dict)\n         self.assertEqual(len(result), 8)\n         # Result values obtained from `tf.keras`\n         # m = tf.keras.metrics.MeanSquaredError()\n@@ -189,7 +189,7 @@ class TestCompileMetrics(testing.TestCase):\n \n         compile_metrics.reset_state()\n         result = compile_metrics.result()\n-        self.assertTrue(isinstance(result, dict))\n+        self.assertIsInstance(result, dict)\n         self.assertEqual(len(result), 8)\n         self.assertAllClose(result[\"output_1_mean_squared_error\"], 0.0)\n         self.assertAllClose(result[\"output_2_mean_squared_error\"], 0.0)\n@@ -206,7 +206,7 @@ class TestCompileMetrics(testing.TestCase):\n         compile_metrics.build(y_true, y_pred)\n         compile_metrics.update_state(y_true, y_pred, sample_weight=None)\n         result = compile_metrics.result()\n-        self.assertTrue(isinstance(result, dict))\n+        self.assertIsInstance(result, dict)\n         self.assertEqual(len(result), 3)\n         self.assertAllClose(result[\"acc\"], 0.333333)\n         self.assertAllClose(result[\"accuracy\"], 0.333333)\n\n@@ -51,8 +51,8 @@ class TestArrayDataAdapter(testing.TestCase, parameterized.TestCase):\n         for i, batch in enumerate(gen):\n             self.assertEqual(len(batch), 2)\n             bx, by = batch\n-            self.assertTrue(isinstance(bx, np.ndarray))\n-            self.assertTrue(isinstance(by, np.ndarray))\n+            self.assertIsInstance(bx, np.ndarray)\n+            self.assertIsInstance(by, np.ndarray)\n             self.assertEqual(bx.dtype, by.dtype)\n             self.assertEqual(bx.dtype, backend.floatx())\n             if i < 2:\n@@ -65,8 +65,8 @@ class TestArrayDataAdapter(testing.TestCase, parameterized.TestCase):\n         for i, batch in enumerate(ds):\n             self.assertEqual(len(batch), 2)\n             bx, by = batch\n-            self.assertTrue(isinstance(bx, tf.Tensor))\n-            self.assertTrue(isinstance(by, tf.Tensor))\n+            self.assertIsInstance(bx, tf.Tensor)\n+            self.assertIsInstance(by, tf.Tensor)\n             self.assertEqual(bx.dtype, by.dtype)\n             self.assertEqual(bx.dtype, backend.floatx())\n             if i < 2:\n@@ -94,18 +94,18 @@ class TestArrayDataAdapter(testing.TestCase, parameterized.TestCase):\n         for i, batch in enumerate(gen):\n             self.assertEqual(len(batch), 3)\n             bx, by, bw = batch\n-            self.assertTrue(isinstance(bx, dict))\n+            self.assertIsInstance(bx, dict)\n             # NOTE: the y list was converted to a tuple for tf.data\n             # compatibility.\n-            self.assertTrue(isinstance(by, tuple))\n-            self.assertTrue(isinstance(bw, tuple))\n+            self.assertIsInstance(by, tuple)\n+            self.assertIsInstance(bw, tuple)\n \n-            self.assertTrue(isinstance(bx[\"x1\"], np.ndarray))\n-            self.assertTrue(isinstance(bx[\"x2\"], np.ndarray))\n-            self.assertTrue(isinstance(by[0], np.ndarray))\n-            self.assertTrue(isinstance(by[1], np.ndarray))\n-            self.assertTrue(isinstance(bw[0], np.ndarray))\n-            self.assertTrue(isinstance(bw[1], np.ndarray))\n+            self.assertIsInstance(bx[\"x1\"], np.ndarray)\n+            self.assertIsInstance(bx[\"x2\"], np.ndarray)\n+            self.assertIsInstance(by[0], np.ndarray)\n+            self.assertIsInstance(by[1], np.ndarray)\n+            self.assertIsInstance(bw[0], np.ndarray)\n+            self.assertIsInstance(bw[1], np.ndarray)\n \n             self.assertEqual(bx[\"x1\"].dtype, by[0].dtype)\n             self.assertEqual(bx[\"x1\"].dtype, backend.floatx())\n@@ -125,18 +125,18 @@ class TestArrayDataAdapter(testing.TestCase, parameterized.TestCase):\n         for i, batch in enumerate(ds):\n             self.assertEqual(len(batch), 3)\n             bx, by, bw = batch\n-            self.assertTrue(isinstance(bx, dict))\n+            self.assertIsInstance(bx, dict)\n             # NOTE: the y list was converted to a tuple for tf.data\n             # compatibility.\n-            self.assertTrue(isinstance(by, tuple))\n-            self.assertTrue(isinstance(bw, tuple))\n+            self.assertIsInstance(by, tuple)\n+            self.assertIsInstance(bw, tuple)\n \n-            self.assertTrue(isinstance(bx[\"x1\"], tf.Tensor))\n-            self.assertTrue(isinstance(bx[\"x2\"], tf.Tensor))\n-            self.assertTrue(isinstance(by[0], tf.Tensor))\n-            self.assertTrue(isinstance(by[1], tf.Tensor))\n-            self.assertTrue(isinstance(bw[0], tf.Tensor))\n-            self.assertTrue(isinstance(bw[1], tf.Tensor))\n+            self.assertIsInstance(bx[\"x1\"], tf.Tensor)\n+            self.assertIsInstance(bx[\"x2\"], tf.Tensor)\n+            self.assertIsInstance(by[0], tf.Tensor)\n+            self.assertIsInstance(by[1], tf.Tensor)\n+            self.assertIsInstance(bw[0], tf.Tensor)\n+            self.assertIsInstance(bw[1], tf.Tensor)\n \n             self.assertEqual(bx[\"x1\"].dtype, by[0].dtype)\n             self.assertEqual(bx[\"x1\"].dtype, backend.floatx())\n\n@@ -55,13 +55,13 @@ class GeneratorDataAdapterTest(testing.TestCase, parameterized.TestCase):\n                 self.assertEqual(len(batch), 2)\n                 bx, by = batch\n \n-            self.assertTrue(isinstance(bx, np.ndarray))\n-            self.assertTrue(isinstance(by, np.ndarray))\n+            self.assertIsInstance(bx, np.ndarray)\n+            self.assertIsInstance(by, np.ndarray)\n             self.assertEqual(bx.dtype, by.dtype)\n             self.assertEqual(bx.shape, (16, 4))\n             self.assertEqual(by.shape, (16, 2))\n             if use_sample_weight:\n-                self.assertTrue(isinstance(bsw, np.ndarray))\n+                self.assertIsInstance(bsw, np.ndarray)\n             for i in range(by.shape[0]):\n                 sample_order.append(by[i, 0])\n         self.assertAllClose(sample_order, list(range(64)))\n@@ -78,13 +78,13 @@ class GeneratorDataAdapterTest(testing.TestCase, parameterized.TestCase):\n             else:\n                 self.assertEqual(len(batch), 2)\n                 bx, by = batch\n-            self.assertTrue(isinstance(bx, tf.Tensor))\n-            self.assertTrue(isinstance(by, tf.Tensor))\n+            self.assertIsInstance(bx, tf.Tensor)\n+            self.assertIsInstance(by, tf.Tensor)\n             self.assertEqual(bx.dtype, by.dtype)\n             self.assertEqual(tuple(bx.shape), (16, 4))\n             self.assertEqual(tuple(by.shape), (16, 2))\n             if use_sample_weight:\n-                self.assertTrue(isinstance(bsw, tf.Tensor))\n+                self.assertIsInstance(bsw, tf.Tensor)\n             for i in range(by.shape[0]):\n                 sample_order.append(by[i, 0])\n         self.assertAllClose(sample_order, list(range(64)))\n\n@@ -73,8 +73,8 @@ class PyDatasetAdapterTest(testing.TestCase, parameterized.TestCase):\n         for batch in gen:\n             self.assertEqual(len(batch), 2)\n             bx, by = batch\n-            self.assertTrue(isinstance(bx, np.ndarray))\n-            self.assertTrue(isinstance(by, np.ndarray))\n+            self.assertIsInstance(bx, np.ndarray)\n+            self.assertIsInstance(by, np.ndarray)\n             self.assertEqual(bx.dtype, by.dtype)\n             self.assertEqual(bx.shape, (16, 4))\n             self.assertEqual(by.shape, (16, 2))\n@@ -90,8 +90,8 @@ class PyDatasetAdapterTest(testing.TestCase, parameterized.TestCase):\n         for batch in ds:\n             self.assertEqual(len(batch), 2)\n             bx, by = batch\n-            self.assertTrue(isinstance(bx, tf.Tensor))\n-            self.assertTrue(isinstance(by, tf.Tensor))\n+            self.assertIsInstance(bx, tf.Tensor)\n+            self.assertIsInstance(by, tf.Tensor)\n             self.assertEqual(bx.dtype, by.dtype)\n             self.assertEqual(tuple(bx.shape), (16, 4))\n             self.assertEqual(tuple(by.shape), (16, 2))\n\n@@ -21,8 +21,8 @@ class TestTFDatasetAdapter(testing.TestCase):\n         for i, batch in enumerate(gen):\n             self.assertEqual(len(batch), 2)\n             bx, by = batch\n-            self.assertTrue(isinstance(bx, np.ndarray))\n-            self.assertTrue(isinstance(by, np.ndarray))\n+            self.assertIsInstance(bx, np.ndarray)\n+            self.assertIsInstance(by, np.ndarray)\n             self.assertEqual(bx.dtype, by.dtype)\n             self.assertEqual(bx.dtype, \"float32\")\n             if i < 2:\n@@ -35,8 +35,8 @@ class TestTFDatasetAdapter(testing.TestCase):\n         for i, batch in enumerate(ds):\n             self.assertEqual(len(batch), 2)\n             bx, by = batch\n-            self.assertTrue(isinstance(bx, tf.Tensor))\n-            self.assertTrue(isinstance(by, tf.Tensor))\n+            self.assertIsInstance(bx, tf.Tensor)\n+            self.assertIsInstance(by, tf.Tensor)\n             self.assertEqual(bx.dtype, by.dtype)\n             self.assertEqual(bx.dtype, \"float32\")\n             if i < 2:\n\n@@ -34,8 +34,8 @@ class TestTorchDataLoaderAdapter(testing.TestCase):\n         for i, batch in enumerate(gen):\n             self.assertEqual(len(batch), 2)\n             bx, by = batch\n-            self.assertTrue(isinstance(bx, np.ndarray))\n-            self.assertTrue(isinstance(by, np.ndarray))\n+            self.assertIsInstance(bx, np.ndarray)\n+            self.assertIsInstance(by, np.ndarray)\n             self.assertEqual(bx.dtype, by.dtype)\n             self.assertEqual(bx.dtype, \"float32\")\n             if i < 2:\n@@ -49,8 +49,8 @@ class TestTorchDataLoaderAdapter(testing.TestCase):\n         for i, batch in enumerate(ds):\n             self.assertEqual(len(batch), 2)\n             bx, by = batch\n-            self.assertTrue(isinstance(bx, torch.Tensor))\n-            self.assertTrue(isinstance(by, torch.Tensor))\n+            self.assertIsInstance(bx, torch.Tensor)\n+            self.assertIsInstance(by, torch.Tensor)\n             self.assertEqual(bx.dtype, by.dtype)\n             self.assertEqual(bx.dtype, torch.float32)\n             if i < 2:\n@@ -64,8 +64,8 @@ class TestTorchDataLoaderAdapter(testing.TestCase):\n         for i, batch in enumerate(ds):\n             self.assertEqual(len(batch), 2)\n             bx, by = batch\n-            self.assertTrue(isinstance(bx, tf.Tensor))\n-            self.assertTrue(isinstance(by, tf.Tensor))\n+            self.assertIsInstance(bx, tf.Tensor)\n+            self.assertIsInstance(by, tf.Tensor)\n             self.assertEqual(bx.dtype, by.dtype)\n             self.assertEqual(bx.dtype, tf.float32)\n             if i < 2:\n\n@@ -28,9 +28,9 @@ class TestEpochIterator(testing.TestCase):\n             steps_seen.append(step)\n             self.assertEqual(len(batch), 3)\n             if return_type == \"np\":\n-                self.assertTrue(isinstance(batch[0], np.ndarray))\n+                self.assertIsInstance(batch[0], np.ndarray)\n             else:\n-                self.assertTrue(isinstance(batch[0], tf.Tensor))\n+                self.assertIsInstance(batch[0], tf.Tensor)\n         self.assertEqual(steps_seen, [0, 1, 2, 3, 4, 5, 6])\n \n     def test_basic_flow_np(self):\n\n@@ -221,7 +221,7 @@ class TestTrainer(testing.TestCase, parameterized.TestCase):\n         output = model.evaluate(x, y, batch_size=batch_size)\n         self.assertAllClose(output, [16.0, 16.0])\n         output = model.evaluate(x, y, batch_size=batch_size, return_dict=True)\n-        self.assertTrue(isinstance(output, dict))\n+        self.assertIsInstance(output, dict)\n         self.assertIn(\"loss\", output)\n         self.assertIn(\"mean_squared_error\", output)\n         self.assertAllClose(output[\"mean_squared_error\"], 16.0)\n@@ -255,7 +255,7 @@ class TestTrainer(testing.TestCase, parameterized.TestCase):\n         }\n         batch_size = 16\n         outputs = model.predict(x, batch_size=batch_size)\n-        self.assertTrue(isinstance(outputs, dict))\n+        self.assertIsInstance(outputs, dict)\n         self.assertEqual(len(outputs), 2)\n         self.assertAllClose(outputs[\"y_one\"], 4 * np.ones((100, 3)))\n         self.assertAllClose(outputs[\"y_two\"], 4 * np.ones((100, 3)))\n@@ -366,27 +366,27 @@ class TestTrainer(testing.TestCase, parameterized.TestCase):\n             jit_compile=jit_compile,\n         )\n         logs = model.train_on_batch(x, y)\n-        self.assertTrue(isinstance(logs, list))\n+        self.assertIsInstance(logs, list)\n         self.assertEqual(len(logs), 2)\n         self.assertAlmostEqual(logs[0], 16.0)\n \n         logs = model.train_on_batch(x, y, return_dict=True)\n-        self.assertTrue(isinstance(logs, dict))\n+        self.assertIsInstance(logs, dict)\n         self.assertEqual(len(logs), 2)\n         self.assertAlmostEqual(logs[\"loss\"], 15.579)\n \n         logs = model.test_on_batch(x, y)\n-        self.assertTrue(isinstance(logs, list))\n+        self.assertIsInstance(logs, list)\n         self.assertEqual(len(logs), 2)\n         self.assertAlmostEqual(logs[0], 15.173)\n \n         logs = model.test_on_batch(x, y, return_dict=True)\n-        self.assertTrue(isinstance(logs, dict))\n+        self.assertIsInstance(logs, dict)\n         self.assertEqual(len(logs), 2)\n         self.assertAlmostEqual(logs[\"loss\"], 14.97)\n \n         output = model.predict_on_batch(x)\n-        self.assertTrue(isinstance(output, np.ndarray))\n+        self.assertIsInstance(output, np.ndarray)\n         self.assertAllClose(output[0], np.array([3.789511, 3.789511, 3.789511]))\n \n         # With sample weights\n@@ -420,16 +420,16 @@ class TestTrainer(testing.TestCase, parameterized.TestCase):\n             jit_compile=jit_compile,\n         )\n         output = model.predict_on_batch(x)\n-        self.assertTrue(isinstance(output, np.ndarray))\n+        self.assertIsInstance(output, np.ndarray)\n         self.assertAllClose(output[0], np.array([4.0, 4.0, 4.0]))\n \n         logs = model.test_on_batch(x, y)\n-        self.assertTrue(isinstance(logs, list))\n+        self.assertIsInstance(logs, list)\n         self.assertEqual(len(logs), 2)\n         self.assertAlmostEqual(logs[0], 16.0)\n \n         logs = model.test_on_batch(x, y, return_dict=True)\n-        self.assertTrue(isinstance(logs, dict))\n+        self.assertIsInstance(logs, dict)\n         self.assertEqual(len(logs), 2)\n         self.assertAlmostEqual(logs[\"loss\"], 16.0)\n \n\n@@ -65,7 +65,7 @@ class TestNumericalUtils(testing.TestCase, parameterized.TestCase):\n \n         # Test NumPy\n         out = numerical_utils.normalize(xnp, axis=-1, order=order)\n-        self.assertTrue(isinstance(out, np.ndarray))\n+        self.assertIsInstance(out, np.ndarray)\n         self.assertAllClose(out, expected)\n \n         # Test backend\n\n@@ -45,7 +45,7 @@ class TorchUtilsTest(testing.TestCase):\n     )\n     def test_module_autowrapping(self):\n         model = ClassifierWithNoSpecialCasing()\n-        self.assertTrue(isinstance(model.fc, TorchModuleWrapper))\n+        self.assertIsInstance(model.fc, TorchModuleWrapper)\n         self.assertFalse(isinstance(model.fc2, TorchModuleWrapper))\n         self.assertEqual(len(model.fc.trainable_weights), 2)\n         model(np.random.random((3, 2)))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
