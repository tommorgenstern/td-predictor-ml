{"custom_id": "scrapy#01ad8b31ab7fe86fd78a70b09a6dd61a497e0ccb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 31 | Lines Deleted: 34 | Files Changed: 2 | Hunks: 18 | Methods Changed: 9 | Complexity Δ (Sum/Max): -1/1 | Churn Δ: 65 | Churn Cumulative: 945 | Contributors (this commit): 1 | Commits (past 90d): 13 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -50,10 +50,7 @@ class H2ClientProtocol(Protocol):\n     def _stream_close_cb(self, stream_id: int):\n         \"\"\"Called when stream is closed completely\n         \"\"\"\n-        try:\n-            del self.streams[stream_id]\n-        except KeyError:\n-            pass\n+        self.streams.pop(stream_id, None)\n \n     def _new_stream(self, request: Request):\n         \"\"\"Instantiates a new Stream object\n@@ -66,7 +63,7 @@ class H2ClientProtocol(Protocol):\n             request=request,\n             connection=self.conn,\n             write_to_transport=self._write_to_transport,\n-            cb_close=lambda: self._stream_close_cb(stream_id)\n+            cb_close=self._stream_close_cb\n         )\n \n         self.streams[stream.stream_id] = stream\n@@ -124,10 +121,7 @@ class H2ClientProtocol(Protocol):\n         \"\"\"\n         # Pop all streams which were pending and were not yet started\n         for stream_id in list(self.streams):\n-            try:\n             self.streams[stream_id].lost_connection()\n-            except KeyError:\n-                pass\n \n         self.conn.close_connection()\n \n\n@@ -81,25 +81,27 @@ class Stream:\n         \"\"\"\n         return self._deferred_response\n \n-    def initiate_request(self):\n-        http2_request_headers = []\n-        for name, value in self._request.headers.items():\n-            http2_request_headers.append((name, value))\n-\n+    def _get_request_headers(self):\n         url = urlparse(self._request.url)\n-        http2_request_headers += [\n-            (\":method\", self._request.method),\n-            (\":authority\", url.netloc),\n \n-            # TODO: Check if scheme can be \"http\" for HTTP/2 ?\n-            (\":scheme\", \"https\"),\n-            (\":path\", url.path),\n+        # Make sure pseudo-headers comes before all the other headers\n+        headers = [\n+            (':method', self._request.method),\n+            (':authority', url.netloc),\n \n-            # TODO: Make sure 'Content-Type' and 'Content-Encoding' headers\n-            #  are sent for request having body\n+            # TODO: Check if scheme can be 'http' for HTTP/2 ?\n+            (':scheme', 'https'),\n+            (':path', url.path),\n         ]\n \n-        self._conn.send_headers(self.stream_id, http2_request_headers, end_stream=False)\n+        for name, value in self._request.headers.items():\n+            headers.append((name, value[0]))\n+\n+        return headers\n+\n+    def initiate_request(self):\n+        headers = self._get_request_headers()\n+        self._conn.send_headers(self.stream_id, headers, end_stream=False)\n         self._write_to_transport()\n \n         self.send_data()\n@@ -127,23 +129,24 @@ class Stream:\n \n         # We will send no more than the window size or the remaining file size\n         # of data in this call, whichever is smaller.\n-        bytes_to_send = min(window_size, self.remaining_content_length)\n+        bytes_to_send_size = min(window_size, self.remaining_content_length)\n \n         # We now need to send a number of data frames.\n-        while bytes_to_send > 0:\n-            chunk_size = min(bytes_to_send, max_frame_size)\n+        while bytes_to_send_size > 0:\n+            chunk_size = min(bytes_to_send_size, max_frame_size)\n \n-            data_chunk_start = self.content_length - self.remaining_content_length\n-            data_chunk = self._request_body[data_chunk_start:data_chunk_start + chunk_size]\n+            data_chunk_start_id = self.content_length - self.remaining_content_length\n+            data_chunk = self._request_body[data_chunk_start_id:data_chunk_start_id + chunk_size]\n \n             self._conn.send_data(self.stream_id, data_chunk, end_stream=False)\n-            self._write_to_transport()\n \n-            bytes_to_send = max(0, bytes_to_send - chunk_size)\n-            self.remaining_content_length = max(0, self.remaining_content_length - chunk_size)\n+            bytes_to_send_size = bytes_to_send_size - chunk_size\n+            self.remaining_content_length = self.remaining_content_length - chunk_size\n \n         # End the stream if no more data has to be send\n-        if self.remaining_content_length == 0:\n+        if self.remaining_content_length <= 0:\n+            self.remaining_content_length = 0\n+\n             self.stream_closed_local = True\n             self._conn.end_stream(self.stream_id)\n \n@@ -183,12 +186,12 @@ class Stream:\n         #  Q1. Do we need to send the request again?\n         #  Q2. What response should we send now?\n         self.stream_closed_server = True\n-        self._cb_close()\n+        self._cb_close(self.stream_id)\n \n     def lost_connection(self):\n         # TODO: Same as self.reset\n         self.stream_closed_server = True\n-        self._cb_close()\n+        self._cb_close(self.stream_id)\n \n     def end_stream(self):\n         \"\"\"Stream is ended by the server hence no further\n@@ -201,7 +204,7 @@ class Stream:\n         self.stream_closed_server = True\n \n         self._fire_response_deferred()\n-        self._cb_close()\n+        self._cb_close(self.stream_id)\n \n     def _fire_response_deferred(self):\n         # TODO:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#214da8e5235c9676bc4b0427c8bf58f328fe6570", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 814 | Contributors (this commit): 23 | Commits (past 90d): 2 | Contributors (cumulative): 23 | DMM Complexity: None\n\nDIFF:\n@@ -334,10 +334,10 @@ class MutableChain:\n     \"\"\"\n \n     def __init__(self, *args):\n-        self.data = chain(*args)\n+        self.data = chain.from_iterable(args)\n \n     def extend(self, *iterables):\n-        self.data = chain(self.data, *iterables)\n+        self.data = chain(self.data, chain.from_iterable(iterables))\n \n     def __iter__(self):\n         return self\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#3d027fb578532d504b3dbfaa77a06c3560f85d3c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 51 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 8 | Methods Changed: 6 | Complexity Δ (Sum/Max): -69/0 | Churn Δ: 53 | Churn Cumulative: 3110 | Contributors (this commit): 27 | Commits (past 90d): 28 | Contributors (cumulative): 45 | DMM Complexity: 0.8571428571428571\n\nDIFF:\n@@ -270,7 +270,9 @@ class FeedExporter:\n             if not slot.itemcount and not slot.store_empty:\n                 # We need to call slot.storage.store nonetheless to get the file\n                 # properly closed.\n-                return defer.maybeDeferred(slot.storage.store, slot.file)\n+                d = defer.maybeDeferred(slot.storage.store, slot.file)\n+                deferred_list.append(d)\n+                continue\n             slot.finish_exporting()\n             logfmt = \"%s %%(format)s feed (%%(itemcount)d items) in: %%(uri)s\"\n             log_args = {'format': slot.format,\n\n@@ -7,6 +7,7 @@ import string\n import tempfile\n import warnings\n from io import BytesIO\n+from logging import getLogger\n from pathlib import Path\n from string import ascii_letters, digits\n from unittest import mock\n@@ -14,9 +15,11 @@ from urllib.parse import urljoin, urlparse, quote\n from urllib.request import pathname2url\n \n import lxml.etree\n+from testfixtures import LogCapture\n from twisted.internet import defer\n from twisted.trial import unittest\n-from w3lib.url import path_to_file_uri\n+from w3lib.url import file_uri_to_path, path_to_file_uri\n+from zope.interface import implementer\n from zope.interface.verify import verifyObject\n \n import scrapy\n@@ -390,6 +393,25 @@ class FromCrawlerFileFeedStorage(FileFeedStorage, FromCrawlerMixin):\n     pass\n \n \n+@implementer(IFeedStorage)\n+class LogOnStoreFileStorage:\n+    \"\"\"\n+    This storage logs inside `store` method.\n+    It can be used to make sure `store` method is invoked.\n+    \"\"\"\n+\n+    def __init__(self, uri):\n+        self.path = file_uri_to_path(uri)\n+        self.logger = getLogger()\n+\n+    def open(self, spider):\n+        return tempfile.NamedTemporaryFile(prefix='feed-')\n+\n+    def store(self, file):\n+        self.logger.info('Storage.store is called')\n+        file.close()\n+\n+\n class FeedExportTest(unittest.TestCase):\n \n     class MyItem(scrapy.Item):\n@@ -426,11 +448,17 @@ class FeedExportTest(unittest.TestCase):\n                 yield runner.crawl(spider_cls)\n \n             for file_path, feed in FEEDS.items():\n+                if not os.path.exists(str(file_path)):\n+                    continue\n+\n                 with open(str(file_path), 'rb') as f:\n                     content[feed['format']] = f.read()\n \n         finally:\n             for file_path in FEEDS.keys():\n+                if not os.path.exists(str(file_path)):\n+                    continue\n+\n                 os.remove(str(file_path))\n \n         return content\n@@ -623,6 +651,25 @@ class FeedExportTest(unittest.TestCase):\n             data = yield self.exported_no_data(settings)\n             self.assertEqual(data[fmt], expctd)\n \n+    @defer.inlineCallbacks\n+    def test_export_no_items_multiple_feeds(self):\n+        \"\"\" Make sure that `storage.store` is called for every feed. \"\"\"\n+        settings = {\n+            'FEEDS': {\n+                self._random_temp_filename(): {'format': 'json'},\n+                self._random_temp_filename(): {'format': 'xml'},\n+                self._random_temp_filename(): {'format': 'csv'},\n+            },\n+            'FEED_STORAGES': {'file': 'tests.test_feedexport.LogOnStoreFileStorage'},\n+            'FEED_STORE_EMPTY': False\n+        }\n+\n+        with LogCapture() as log:\n+            yield self.exported_no_data(settings)\n+\n+        print(log)\n+        self.assertEqual(str(log).count('Storage.store is called'), 3)\n+\n     @defer.inlineCallbacks\n     def test_export_multiple_item_classes(self):\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#089dbc75e78a2da9c455f21bb3c7ebaaeb2e3582", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 9 | Files Changed: 2 | Hunks: 10 | Methods Changed: 6 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 20 | Churn Cumulative: 965 | Contributors (this commit): 1 | Commits (past 90d): 15 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1,4 +1,6 @@\n+import itertools\n import logging\n+from collections import deque\n \n from h2.config import H2Configuration\n from h2.connection import H2Connection\n@@ -35,7 +37,7 @@ class H2ClientProtocol(Protocol):\n         # ID of the next request stream\n         # Following the convention made by hyper-h2 each client ID\n         # will be odd.\n-        self.next_stream_id = 1\n+        self.stream_id_count = itertools.count(start=1, step=2)\n \n         # Streams are stored in a dictionary keyed off their stream IDs\n         self.streams = {}\n@@ -45,7 +47,7 @@ class H2ClientProtocol(Protocol):\n         # we keep all requests in a pool and send them as the connection\n         # is made\n         self.is_connection_made = False\n-        self._pending_request_stream_pool = []\n+        self._pending_request_stream_pool = deque()\n \n     def _stream_close_cb(self, stream_id: int):\n         \"\"\"Called when stream is closed completely\n@@ -55,8 +57,7 @@ class H2ClientProtocol(Protocol):\n     def _new_stream(self, request: Request):\n         \"\"\"Instantiates a new Stream object\n         \"\"\"\n-        stream_id = self.next_stream_id\n-        self.next_stream_id += 2\n+        stream_id = next(self.stream_id_count)\n \n         stream = Stream(\n             stream_id=stream_id,\n@@ -72,11 +73,10 @@ class H2ClientProtocol(Protocol):\n     def _send_pending_requests(self):\n         # TODO: handle MAX_CONCURRENT_STREAMS\n         # Initiate all pending requests\n-        for stream in self._pending_request_stream_pool:\n+        while len(self._pending_request_stream_pool):\n+            stream = self._pending_request_stream_pool.popleft()\n             stream.initiate_request()\n \n-        self._pending_request_stream_pool.clear()\n-\n     def _write_to_transport(self):\n         \"\"\" Write data to the underlying transport connection\n         from the HTTP2 connection instance if any\n@@ -108,6 +108,8 @@ class H2ClientProtocol(Protocol):\n         self._write_to_transport()\n         self.is_connection_made = True\n \n+        # Send off all the pending requests\n+        # as now we have established a proper HTTP/2 connection\n         self._send_pending_requests()\n \n     def dataReceived(self, data):\n\n@@ -132,7 +132,7 @@ class Stream:\n         bytes_to_send_size = min(window_size, self.remaining_content_length)\n \n         # We now need to send a number of data frames.\n-        while bytes_to_send_size > 0:\n+        while bytes_to_send_size:\n             chunk_size = min(bytes_to_send_size, max_frame_size)\n \n             data_chunk_start_id = self.content_length - self.remaining_content_length\n@@ -163,7 +163,7 @@ class Stream:\n         Arguments:\n             delta -- Window change delta\n         \"\"\"\n-        if self.remaining_content_length > 0 and not self.stream_closed_local:\n+        if self.stream_closed_local is False:\n             self.send_data()\n \n     def receive_data(self, data: bytes, flow_controlled_length: int):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#700df3eeb7c540892c8b2910db688f1cc5d1c845", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 140 | Lines Deleted: 2 | Files Changed: 3 | Hunks: 6 | Methods Changed: 5 | Complexity Δ (Sum/Max): 6/5 | Churn Δ: 142 | Churn Cumulative: 659 | Contributors (this commit): 24 | Commits (past 90d): 6 | Contributors (cumulative): 26 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,67 @@\n+# This is simple script to test\n+\n+import json\n+\n+from twisted.internet import reactor\n+from twisted.internet.endpoints import connectProtocol, SSL4ClientEndpoint\n+from twisted.internet.ssl import optionsForClientTLS\n+\n+from scrapy.core.http2.protocol import H2ClientProtocol\n+from scrapy.http import Request, Response, JsonRequest\n+\n+try:\n+    with open('data.json', 'r') as f:\n+        JSON_DATA = json.load(f)\n+except:\n+    JSON_DATA = {\n+        \"data\": \"To test for really large amount of data -- Add data.json with lots of data.\",\n+        \"why\": \"To test whether correct data is sent :)\"\n+    }\n+\n+# Use nghttp2 for testing whether basic setup works - for small response\n+HTTPBIN_AUTHORITY = u'nghttp2.org'\n+HTTPBIN_REQUEST_URLS = 1 * [\n+    Request(url='https://nghttp2.org/httpbin/get', method='GET'),\n+    Request(url='https://nghttp2.org/httpbin/post', method='POST'),\n+    JsonRequest(url='https://nghttp2.org/httpbin/anything', method='POST', data=JSON_DATA),\n+]\n+\n+# Use POKE_API for testing large responses\n+POKE_API_AUTHORITY = u'pokeapi.co'\n+POKE_API_REQUESTS = 15 * [\n+    Request(url='https://pokeapi.co/api/v2/pokemon/ditto', method='GET'),\n+    Request(url='https://pokeapi.co/api/v2/pokemon/charizard', method='GET'),\n+    Request(url='https://pokeapi.co/api/v2/pokemon/pikachu', method='GET'),\n+    Request(url='https://pokeapi.co/api/v2/pokemon/DoesNotExist', method='GET'),  # should give 404\n+]\n+\n+AUTHORITY = POKE_API_AUTHORITY\n+REQUEST_URLS = POKE_API_REQUESTS\n+\n+options = optionsForClientTLS(\n+    hostname=AUTHORITY,\n+    acceptableProtocols=[b'h2'],\n+)\n+\n+protocol = H2ClientProtocol()\n+\n+count_responses = 1\n+\n+\n+def print_response(response):\n+    global count_responses\n+    assert isinstance(response, Response)\n+    print('({})\\t{}: ReponseBodySize={}'.format(count_responses, response, len(response.body)))\n+    count_responses = count_responses + 1\n+\n+\n+for request in REQUEST_URLS:\n+    d = protocol.request(request)\n+    d.addCallback(print_response)\n+\n+connectProtocol(\n+    SSL4ClientEndpoint(reactor, AUTHORITY, 443, options),\n+    protocol\n+)\n+\n+reactor.run()\n\n@@ -1,8 +1,8 @@\n from os.path import dirname, join\n+\n from pkg_resources import parse_version\n from setuptools import setup, find_packages, __version__ as setuptools_version\n \n-\n with open(join(dirname(__file__), 'scrapy/VERSION'), 'rb') as f:\n     version = f.read().decode('ascii').strip()\n \n@@ -25,7 +25,6 @@ if has_environment_marker_platform_impl_support():\n         'PyPyDispatcher>=2.1.0',\n     ]\n \n-\n setup(\n     name='Scrapy',\n     version=version,\n@@ -69,6 +68,7 @@ setup(\n     python_requires='>=3.5',\n     install_requires=[\n         'Twisted>=17.9.0',\n+        'Twisted[http2]>=17.9.0'\n         'cryptography>=2.0',\n         'cssselect>=0.9.1',\n         'lxml>=3.5.0',\n\n@@ -0,0 +1,71 @@\n+import os\n+import shutil\n+\n+from twisted.internet import defer, reactor\n+from twisted.internet.endpoints import connectProtocol, SSL4ClientEndpoint\n+from twisted.internet.ssl import optionsForClientTLS\n+from twisted.protocols.policies import WrappingFactory\n+from twisted.python.filepath import FilePath\n+from twisted.trial import unittest\n+from twisted.web import static, server\n+\n+from scrapy.core.http2.protocol import H2ClientProtocol\n+from scrapy.http import Request\n+from tests.mockserver import ssl_context_factory\n+\n+\n+class Http2ClientProtocolTestCase(unittest.TestCase):\n+    scheme = 'https'\n+\n+    # only used for HTTPS tests\n+    file_key = 'keys/localhost.key'\n+    file_certificate = 'keys/localhost.crt'\n+\n+    def setUp(self):\n+        # Start server for testing\n+        self.path_temp = self.mktemp()\n+        os.mkdir(self.path_temp)\n+        FilePath(self.path_temp).child('file').setContent(b\"0123456789\")\n+        r = static.File(self.path_temp)\n+\n+        self.site = server.Site(r, timeout=None)\n+        self.wrapper = WrappingFactory(self.site)\n+        self.host = 'localhost'\n+        if self.scheme is 'https':\n+            self.port = reactor.listenSSL(\n+                0, self.wrapper,\n+                ssl_context_factory(self.file_key, self.file_certificate),\n+                interface=self.host\n+            )\n+        else:\n+            self.port = reactor.listenTCP(0, self.wrapper, interface=self.host)\n+\n+        self.port_number = self.port.getHost().port\n+\n+        # Connect to the server using the custom HTTP2ClientProtocol\n+        options = optionsForClientTLS(\n+            hostname=self.host,\n+            acceptableProtocols=[b'h2']\n+        )\n+\n+        self.protocol = H2ClientProtocol()\n+\n+        connectProtocol(\n+            endpoint=SSL4ClientEndpoint(reactor, self.host, self.port_number, options),\n+            protocol=self.protocol\n+        )\n+\n+    def getURL(self, path):\n+        return \"%s://%s:%d/%s\" % (self.scheme, self.host, self.port_number, path)\n+\n+    @defer.inlineCallbacks\n+    def tearDown(self):\n+        yield self.port.stopListening()\n+        shutil.rmtree(self.path_temp)\n+\n+    def test_download(self):\n+        request = Request(self.getURL('file'))\n+        d = self.protocol.request(request)\n+        d.addCallback(lambda response: response.body)\n+        d.addCallback(self.assertEqual, b\"0123456789\")\n+        return d\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#a4bfd5ab6fd75c4badac1c5d9b40706181c41bd9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 77 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 3 | Methods Changed: 5 | Complexity Δ (Sum/Max): 9/9 | Churn Δ: 82 | Churn Cumulative: 3192 | Contributors (this commit): 27 | Commits (past 90d): 34 | Contributors (cumulative): 45 | DMM Complexity: 1.0\n\nDIFF:\n@@ -279,11 +279,20 @@ class FeedExporter:\n                         'itemcount': slot.itemcount,\n                         'uri': slot.uri}\n             d = defer.maybeDeferred(slot.storage.store, slot.file)\n-            d.addCallback(lambda _: logger.info(logfmt % \"Stored\", log_args,\n-                                                extra={'spider': spider}))\n-            d.addErrback(lambda f: logger.error(logfmt % \"Error storing\", log_args,\n-                                                exc_info=failure_to_exc_info(f),\n-                                                extra={'spider': spider}))\n+\n+            # Use `largs=log_args` to copy log_args into function's scope\n+            # instead of using `log_args` from the outer scope\n+            d.addCallback(\n+                lambda _, largs=log_args: logger.info(\n+                    logfmt % \"Stored\", largs, extra={'spider': spider}\n+                )\n+            )\n+            d.addErrback(\n+                lambda f, largs=log_args: logger.error(\n+                    logfmt % \"Error storing\", largs,\n+                    exc_info=failure_to_exc_info(f), extra={'spider': spider}\n+                )\n+            )\n             deferred_list.append(d)\n         return defer.DeferredList(deferred_list) if deferred_list else None\n \n\n@@ -393,6 +393,27 @@ class FromCrawlerFileFeedStorage(FileFeedStorage, FromCrawlerMixin):\n     pass\n \n \n+class DummyBlockingFeedStorage(BlockingFeedStorage):\n+\n+    def __init__(self, uri):\n+        self.path = file_uri_to_path(uri)\n+\n+    def _store_in_thread(self, file):\n+        dirname = os.path.dirname(self.path)\n+        if dirname and not os.path.exists(dirname):\n+            os.makedirs(dirname)\n+        with open(self.path, 'ab') as output_file:\n+            output_file.write(file.read())\n+\n+        file.close()\n+\n+\n+class FailingBlockingFeedStorage(DummyBlockingFeedStorage):\n+\n+    def _store_in_thread(self, file):\n+        raise OSError('Cannot store')\n+\n+\n @implementer(IFeedStorage)\n class LogOnStoreFileStorage:\n     \"\"\"\n@@ -1025,3 +1046,45 @@ class FeedExportTest(unittest.TestCase):\n         }\n         data = yield self.exported_no_data(settings)\n         self.assertEqual(data['csv'], b'')\n+\n+    @defer.inlineCallbacks\n+    def test_multiple_feeds_success_logs_blocking_feed_storage(self):\n+        settings = {\n+            'FEEDS': {\n+                self._random_temp_filename(): {'format': 'json'},\n+                self._random_temp_filename(): {'format': 'xml'},\n+                self._random_temp_filename(): {'format': 'csv'},\n+            },\n+            'FEED_STORAGES': {'file': 'tests.test_feedexport.DummyBlockingFeedStorage'},\n+        }\n+        items = [\n+            {'foo': 'bar1', 'baz': ''},\n+            {'foo': 'bar2', 'baz': 'quux'},\n+        ]\n+        with LogCapture() as log:\n+            yield self.exported_data(items, settings)\n+\n+        print(log)\n+        for fmt in ['json', 'xml', 'csv']:\n+            self.assertIn('Stored %s feed (2 items)' % fmt, str(log))\n+\n+    @defer.inlineCallbacks\n+    def test_multiple_feeds_failing_logs_blocking_feed_storage(self):\n+        settings = {\n+            'FEEDS': {\n+                self._random_temp_filename(): {'format': 'json'},\n+                self._random_temp_filename(): {'format': 'xml'},\n+                self._random_temp_filename(): {'format': 'csv'},\n+            },\n+            'FEED_STORAGES': {'file': 'tests.test_feedexport.FailingBlockingFeedStorage'},\n+        }\n+        items = [\n+            {'foo': 'bar1', 'baz': ''},\n+            {'foo': 'bar2', 'baz': 'quux'},\n+        ]\n+        with LogCapture() as log:\n+            yield self.exported_data(items, settings)\n+\n+        print(log)\n+        for fmt in ['json', 'xml', 'csv']:\n+            self.assertIn('Error storing %s feed (2 items)' % fmt, str(log))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#303485a9b4fd86c5123c96c81a9401b5e323a91d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 131 | Lines Deleted: 54 | Files Changed: 2 | Hunks: 51 | Methods Changed: 26 | Complexity Δ (Sum/Max): 6/4 | Churn Δ: 185 | Churn Cumulative: 1150 | Contributors (this commit): 1 | Commits (past 90d): 17 | Contributors (cumulative): 2 | DMM Complexity: 0.17142857142857143\n\nDIFF:\n@@ -1,3 +1,4 @@\n+import ipaddress\n import itertools\n import logging\n from collections import deque\n@@ -5,7 +6,7 @@ from collections import deque\n from h2.config import H2Configuration\n from h2.connection import H2Connection\n from h2.events import (\n-    ConnectionTerminated, DataReceived, ResponseReceived,\n+    DataReceived, ResponseReceived, SettingsAcknowledged,\n     StreamEnded, StreamReset, WindowUpdated\n )\n from twisted.internet.protocol import connectionDone, Protocol\n@@ -49,6 +50,13 @@ class H2ClientProtocol(Protocol):\n         self.is_connection_made = False\n         self._pending_request_stream_pool = deque()\n \n+        # Some meta data of this connection\n+        # initialized when connection is successfully made\n+        self._metadata = {\n+            'certificate': None,\n+            'ip_address': None\n+        }\n+\n     def _stream_close_cb(self, stream_id: int):\n         \"\"\"Called when stream is closed completely\n         \"\"\"\n@@ -63,6 +71,7 @@ class H2ClientProtocol(Protocol):\n             stream_id=stream_id,\n             request=request,\n             connection=self.conn,\n+            metadata=self._metadata,\n             write_to_transport=self._write_to_transport,\n             cb_close=self._stream_close_cb\n         )\n@@ -73,7 +82,7 @@ class H2ClientProtocol(Protocol):\n     def _send_pending_requests(self):\n         # TODO: handle MAX_CONCURRENT_STREAMS\n         # Initiate all pending requests\n-        while len(self._pending_request_stream_pool):\n+        while self._pending_request_stream_pool:\n             stream = self._pending_request_stream_pool.popleft()\n             stream.initiate_request()\n \n@@ -84,6 +93,8 @@ class H2ClientProtocol(Protocol):\n         data = self.conn.data_to_send()\n         self.transport.write(data)\n \n+        LOGGER.debug(\"Sent {} bytes to {} via transport\".format(len(data), self._metadata['ip_address']))\n+\n     def request(self, _request: Request):\n         stream = self._new_stream(_request)\n         d = stream.get_response()\n@@ -101,17 +112,16 @@ class H2ClientProtocol(Protocol):\n         \"\"\"Called by Twisted when the connection is established. We can start\n         sending some data now: we should open with the connection preamble.\n         \"\"\"\n-        self.destination = self.transport.connector.getDestination()\n+        self.destination = self.transport.getPeer()\n         LOGGER.info('Connection made to {}'.format(self.destination))\n \n+        self._metadata['certificate'] = self.transport.getPeerCertificate()\n+        self._metadata['ip_address'] = ipaddress.ip_address(self.destination.host)\n+\n         self.conn.initiate_connection()\n         self._write_to_transport()\n         self.is_connection_made = True\n \n-        # Send off all the pending requests\n-        # as now we have established a proper HTTP/2 connection\n-        self._send_pending_requests()\n-\n     def dataReceived(self, data):\n         events = self.conn.receive_data(data)\n         self._handle_events(events)\n@@ -123,7 +133,7 @@ class H2ClientProtocol(Protocol):\n         \"\"\"\n         # Pop all streams which were pending and were not yet started\n         for stream_id in list(self.streams):\n-            self.streams[stream_id].lost_connection()\n+            self.streams[stream_id].close()\n \n         self.conn.close_connection()\n \n@@ -139,9 +149,7 @@ class H2ClientProtocol(Protocol):\n         \"\"\"\n         for event in events:\n             LOGGER.debug(event)\n-            if isinstance(event, ConnectionTerminated):\n-                self.connection_terminated(event)\n-            elif isinstance(event, DataReceived):\n+            if isinstance(event, DataReceived):\n                 self.data_received(event)\n             elif isinstance(event, ResponseReceived):\n                 self.response_received(event)\n@@ -151,13 +159,12 @@ class H2ClientProtocol(Protocol):\n                 self.stream_reset(event)\n             elif isinstance(event, WindowUpdated):\n                 self.window_updated(event)\n+            elif isinstance(event, SettingsAcknowledged):\n+                self.settings_acknowledged(event)\n             else:\n                 LOGGER.info(\"Received unhandled event {}\".format(event))\n \n     # Event handler functions starts here\n-    def connection_terminated(self, event: ConnectionTerminated):\n-        pass\n-\n     def data_received(self, event: DataReceived):\n         stream_id = event.stream_id\n         self.streams[stream_id].receive_data(event.data, event.flow_controlled_length)\n@@ -166,20 +173,26 @@ class H2ClientProtocol(Protocol):\n         stream_id = event.stream_id\n         self.streams[stream_id].receive_headers(event.headers)\n \n+    def settings_acknowledged(self, event: SettingsAcknowledged):\n+        # Send off all the pending requests\n+        # as now we have established a proper HTTP/2 connection\n+        self._send_pending_requests()\n+\n     def stream_ended(self, event: StreamEnded):\n         stream_id = event.stream_id\n-        self.streams[stream_id].end_stream()\n+        self.streams[stream_id].close()\n \n     def stream_reset(self, event: StreamReset):\n         # TODO: event.stream_id was abruptly closed\n         #  Q. What should be the response? (Failure/Partial/???)\n-        self.streams[event.stream_id].reset()\n+        self.streams[event.stream_id].close(event)\n \n     def window_updated(self, event: WindowUpdated):\n         stream_id = event.stream_id\n         if stream_id != 0:\n             self.streams[stream_id].receive_window_update(event.delta)\n         else:\n-            # TODO:\n-            #  Q. What to do when StreamID=0 ?\n-            pass\n+            # Send leftover data for all the streams\n+            for stream in self.streams.values():\n+                if stream.request_sent:\n+                    stream.send_data()\n\n@@ -1,11 +1,15 @@\n import logging\n+from typing import Dict\n from urllib.parse import urlparse\n \n from h2.connection import H2Connection\n+from h2.events import StreamEnded\n+from h2.exceptions import StreamClosedError\n from twisted.internet.defer import Deferred\n \n-from scrapy.http import Request, Response\n+from scrapy.http import Request\n from scrapy.http.headers import Headers\n+from scrapy.responsetypes import responsetypes\n \n LOGGER = logging.getLogger(__name__)\n \n@@ -26,6 +30,7 @@ class Stream:\n         stream_id: int,\n         request: Request,\n         connection: H2Connection,\n+        metadata: Dict,\n         write_to_transport,\n         cb_close\n     ):\n@@ -35,6 +40,7 @@ class Stream:\n                 uniquely identified by a single integer\n             request {Request} -- HTTP request\n             connection {H2Connection} -- HTTP/2 connection this stream belongs to.\n+            metadata {Dict} -- Reference to dictionary having metadata of HTTP/2 connection\n             write_to_transport {callable} -- Method used to write & send data to the server\n                 This method should be used whenever some frame is to be sent to the server.\n             cb_close {callable} -- Method called when this stream is closed\n@@ -43,12 +49,16 @@ class Stream:\n         self.stream_id = stream_id\n         self._request = request\n         self._conn = connection\n+        self._metadata = metadata\n         self._write_to_transport = write_to_transport\n         self._cb_close = cb_close\n \n         self._request_body = self._request.body\n         self.content_length = 0 if self._request_body is None else len(self._request_body)\n \n+        # Flag to keep track whether this stream has initiated the request\n+        self.request_sent = False\n+\n         # Each time we send a data frame, we will decrease value by the amount send.\n         self.remaining_content_length = self.content_length\n \n@@ -58,20 +68,30 @@ class Stream:\n         # Flag to keep track whether the server has closed the stream\n         self.stream_closed_server = False\n \n-        # Data received frame by frame from the server is appended\n-        # and passed to the response Deferred when completely received.\n-        self._response_data = b\"\"\n-\n         # The amount of data received that counts against the flow control\n         # window\n         self._response_flow_controlled_size = 0\n \n+        # Private variable used to build the response\n+        # this response is then converted to appropriate Response class\n+        # passed to the response deferred callback\n+        self._response = {\n+            # Data received frame by frame from the server is appended\n+            # and passed to the response Deferred when completely received.\n+            'body': b'',\n+\n             # Headers received after sending the request\n-        self._response_headers = Headers({})\n+            'headers': Headers({})\n+        }\n \n         # TODO: Add canceller for the Deferred below\n         self._deferred_response = Deferred()\n \n+    def __str__(self):\n+        return \"Stream(id={})\".format(self.stream_id)\n+\n+    __repr__ = __str__\n+\n     def get_response(self):\n         \"\"\"Simply return a Deferred which fires when response\n         from the asynchronous request is available\n@@ -104,6 +124,8 @@ class Stream:\n         self._conn.send_headers(self.stream_id, headers, end_stream=False)\n         self._write_to_transport()\n \n+        self.request_sent = True\n+\n         self.send_data()\n \n     def send_data(self):\n@@ -112,7 +134,18 @@ class Stream:\n \n          If the content length is 0 initially then we end the stream immediately and\n          wait for response data.\n+\n+         Warning: Only call this method when stream not closed from client side\n+            and has initiated request already by sending HEADER frame. If not then\n+            stream will be closed from client side with 499 response.\n+\n+            TODO: Q. Should we instead raise ProtocolError here with a proper message?\n          \"\"\"\n+        if self.stream_closed_local or self.stream_closed_server:\n+            raise StreamClosedError(self.stream_id)\n+        elif not self.request_sent:\n+            self.close()\n+            return\n \n         # TODO:\n         #  1. Add test for sending very large data\n@@ -132,7 +165,8 @@ class Stream:\n         bytes_to_send_size = min(window_size, self.remaining_content_length)\n \n         # We now need to send a number of data frames.\n-        while bytes_to_send_size:\n+        data_frames_sent = 0\n+        while bytes_to_send_size > 0:\n             chunk_size = min(bytes_to_send_size, max_frame_size)\n \n             data_chunk_start_id = self.content_length - self.remaining_content_length\n@@ -140,16 +174,24 @@ class Stream:\n \n             self._conn.send_data(self.stream_id, data_chunk, end_stream=False)\n \n+            data_frames_sent += 1\n             bytes_to_send_size = bytes_to_send_size - chunk_size\n             self.remaining_content_length = self.remaining_content_length - chunk_size\n \n-        # End the stream if no more data has to be send\n-        if self.remaining_content_length <= 0:\n-            self.remaining_content_length = 0\n+        self.remaining_content_length = max(0, self.remaining_content_length)\n+        LOGGER.debug(\"{} sending {}/{} data bytes ({} frames) to {}\".format(\n+            self,\n+            self.content_length - self.remaining_content_length, self.content_length,\n+            data_frames_sent,\n+            self._metadata['ip_address'])\n+        )\n \n+        # End the stream if no more data needs to be send\n+        if self.remaining_content_length == 0:\n             self.stream_closed_local = True\n             self._conn.end_stream(self.stream_id)\n \n+        # Write data to transport -- Empty the outstanding data\n         self._write_to_transport()\n \n         # Q. What about the rest of the data?\n@@ -163,11 +205,11 @@ class Stream:\n         Arguments:\n             delta -- Window change delta\n         \"\"\"\n-        if self.stream_closed_local is False:\n+        if self.remaining_content_length > 0 and not self.stream_closed_server:\n             self.send_data()\n \n     def receive_data(self, data: bytes, flow_controlled_length: int):\n-        self._response_data += data\n+        self._response['body'] += data\n         self._response_flow_controlled_size += flow_controlled_length\n \n         # Acknowledge the data received\n@@ -178,47 +220,69 @@ class Stream:\n \n     def receive_headers(self, headers):\n         for name, value in headers:\n-            self._response_headers[name] = value\n+            self._response['headers'][name] = value\n \n-    def reset(self):\n-        \"\"\"Received a RST_STREAM -- forcefully reset\"\"\"\n-        # TODO:\n-        #  Q1. Do we need to send the request again?\n-        #  Q2. What response should we send now?\n-        self.stream_closed_server = True\n-        self._cb_close(self.stream_id)\n+    def close(self, event=None):\n+        \"\"\"Based on the event sent we will handle each case.\n \n-    def lost_connection(self):\n-        # TODO: Same as self.reset\n-        self.stream_closed_server = True\n-        self._cb_close(self.stream_id)\n-\n-    def end_stream(self):\n-        \"\"\"Stream is ended by the server hence no further\n+        event: StreamEnded\n+        Stream is ended by the server hence no further\n         data or headers should be expected on this stream.\n-\n         We will call the response deferred callback passing\n         the response object\n+\n+        event: StreamReset\n+        Stream reset via RST_FRAME by the upstream hence forcefully close\n+        this stream and send TODO: ?\n+\n+        event: None\n+        No event is launched -- Hence we will simply close this stream\n         \"\"\"\n+        # TODO: In case of abruptly stream close\n+        #  Q1. Do we need to send the request again?\n+        #  Q2. What response should we send now?\n         assert self.stream_closed_server is False\n         self.stream_closed_server = True\n \n+        if not isinstance(event, StreamEnded):\n+            # TODO\n+            # Stream was abruptly ended here\n+            # Partial - Content-Length header not provided\n+            pass\n+\n         self._fire_response_deferred()\n         self._cb_close(self.stream_id)\n \n-    def _fire_response_deferred(self):\n+    def _fire_response_deferred(self, flags=None):\n+        \"\"\"Builds response from the self._response dict\n+        and fires the response deferred callback with the\n+        generated response instance\"\"\"\n         # TODO:\n         #  1. Set flags, certificate, ip_address in response\n         #  2. Should we fire this in case of\n         #   2.1 StreamReset in between when data is received partially\n         #   2.2 Forcefully closed the stream\n+        #  3. Update Client Side Status Codes here\n \n-        # NOTE: Presently on fired with successful response\n-        response = Response(\n+        response_cls = responsetypes.from_args(\n+            headers=self._response['headers'],\n             url=self._request.url,\n-            status=self._response_headers[\":status\"],\n-            headers=self._response_headers,\n-            body=self._response_data,\n-            request=self._request\n+            body=self._response['body']\n         )\n+\n+        # If there is :status in headers then\n+        # HTTP Status Code: 499 - Client Closed Request\n+        status = self._response['headers'].get(':status', '499')\n+\n+        response = response_cls(\n+            url=self._request.url,\n+            status=status,\n+            headers=self._response['headers'],\n+            body=self._response['body'],\n+            request=self._request,\n+            flags=flags,\n+            certificate=self._metadata['certificate'],\n+            ip_address=self._metadata['ip_address']\n+        )\n+\n         self._deferred_response.callback(response)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#c74ef660c7b28cd69825a4b9843230a383f702f4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 150 | Lines Deleted: 64 | Files Changed: 2 | Hunks: 40 | Methods Changed: 17 | Complexity Δ (Sum/Max): 16/17 | Churn Δ: 214 | Churn Cumulative: 1364 | Contributors (this commit): 1 | Commits (past 90d): 19 | Contributors (cumulative): 2 | DMM Complexity: 0.4090909090909091\n\nDIFF:\n@@ -11,7 +11,7 @@ from h2.events import (\n )\n from twisted.internet.protocol import connectionDone, Protocol\n \n-from scrapy.core.http2.stream import Stream\n+from scrapy.core.http2.stream import Stream, StreamCloseReason\n from scrapy.http import Request\n \n LOGGER = logging.getLogger(__name__)\n@@ -71,7 +71,7 @@ class H2ClientProtocol(Protocol):\n             stream_id=stream_id,\n             request=request,\n             connection=self.conn,\n-            metadata=self._metadata,\n+            conn_metadata=self._metadata,\n             write_to_transport=self._write_to_transport,\n             cb_close=self._stream_close_cb\n         )\n@@ -133,7 +133,7 @@ class H2ClientProtocol(Protocol):\n         \"\"\"\n         # Pop all streams which were pending and were not yet started\n         for stream_id in list(self.streams):\n-            self.streams[stream_id].close()\n+            self.streams[stream_id].close(StreamCloseReason.CONNECTION_LOST)\n \n         self.conn.close_connection()\n \n@@ -180,19 +180,18 @@ class H2ClientProtocol(Protocol):\n \n     def stream_ended(self, event: StreamEnded):\n         stream_id = event.stream_id\n-        self.streams[stream_id].close()\n+        self.streams[stream_id].close(StreamCloseReason.ENDED)\n \n     def stream_reset(self, event: StreamReset):\n         # TODO: event.stream_id was abruptly closed\n         #  Q. What should be the response? (Failure/Partial/???)\n-        self.streams[event.stream_id].close(event)\n+        self.streams[event.stream_id].close(StreamCloseReason.RESET)\n \n     def window_updated(self, event: WindowUpdated):\n         stream_id = event.stream_id\n         if stream_id != 0:\n-            self.streams[stream_id].receive_window_update(event.delta)\n+            self.streams[stream_id].receive_window_update()\n         else:\n             # Send leftover data for all the streams\n             for stream in self.streams.values():\n-                if stream.request_sent:\n-                    stream.send_data()\n+                stream.receive_window_update()\n\n@@ -1,11 +1,15 @@\n import logging\n+from enum import IntFlag, auto\n+from io import BytesIO\n from typing import Dict\n from urllib.parse import urlparse\n \n from h2.connection import H2Connection\n-from h2.events import StreamEnded\n+from h2.errors import ErrorCodes\n from h2.exceptions import StreamClosedError\n-from twisted.internet.defer import Deferred\n+from twisted.internet.defer import Deferred, CancelledError\n+from twisted.python.failure import Failure\n+from twisted.web.client import ResponseFailed\n \n from scrapy.http import Request\n from scrapy.http.headers import Headers\n@@ -14,6 +18,20 @@ from scrapy.responsetypes import responsetypes\n LOGGER = logging.getLogger(__name__)\n \n \n+class StreamCloseReason(IntFlag):\n+    # Received a StreamEnded event\n+    ENDED = auto()\n+\n+    # Received a StreamReset event -- ended abruptly\n+    RESET = auto()\n+\n+    # Transport connection was lost\n+    CONNECTION_LOST = auto()\n+\n+    # Expected response body size is more than allowed limit\n+    MAXSIZE_EXCEEDED = auto()\n+\n+\n class Stream:\n     \"\"\"Represents a single HTTP/2 Stream.\n \n@@ -30,9 +48,12 @@ class Stream:\n             stream_id: int,\n             request: Request,\n             connection: H2Connection,\n-        metadata: Dict,\n+            conn_metadata: Dict,\n             write_to_transport,\n-        cb_close\n+            cb_close,\n+            download_maxsize=0,\n+            download_warnsize=0,\n+            fail_on_data_loss=True\n     ):\n         \"\"\"\n         Arguments:\n@@ -40,7 +61,7 @@ class Stream:\n                 uniquely identified by a single integer\n             request {Request} -- HTTP request\n             connection {H2Connection} -- HTTP/2 connection this stream belongs to.\n-            metadata {Dict} -- Reference to dictionary having metadata of HTTP/2 connection\n+            conn_metadata {Dict} -- Reference to dictionary having metadata of HTTP/2 connection\n             write_to_transport {callable} -- Method used to write & send data to the server\n                 This method should be used whenever some frame is to be sent to the server.\n             cb_close {callable} -- Method called when this stream is closed\n@@ -49,16 +70,24 @@ class Stream:\n         self.stream_id = stream_id\n         self._request = request\n         self._conn = connection\n-        self._metadata = metadata\n+        self._conn_metadata = conn_metadata\n         self._write_to_transport = write_to_transport\n         self._cb_close = cb_close\n \n-        self._request_body = self._request.body\n-        self.content_length = 0 if self._request_body is None else len(self._request_body)\n+        self._download_maxsize = self._request.meta.get('download_maxsize', download_maxsize)\n+        self._download_warnsize = self._request.meta.get('download_warnsize', download_warnsize)\n+        self._fail_on_dataloss = self._request.meta.get('download_fail_on_dataloss', fail_on_data_loss)\n+\n+        self.request_start_time = None\n+\n+        self.content_length = 0 if self._request.body is None else len(self._request.body)\n \n         # Flag to keep track whether this stream has initiated the request\n         self.request_sent = False\n \n+        # Flag to track whether we have logged about exceeding download warnsize\n+        self._reached_warnsize = False\n+\n         # Each time we send a data frame, we will decrease value by the amount send.\n         self.remaining_content_length = self.content_length\n \n@@ -68,17 +97,17 @@ class Stream:\n         # Flag to keep track whether the server has closed the stream\n         self.stream_closed_server = False\n \n-        # The amount of data received that counts against the flow control\n-        # window\n-        self._response_flow_controlled_size = 0\n-\n         # Private variable used to build the response\n         # this response is then converted to appropriate Response class\n         # passed to the response deferred callback\n         self._response = {\n             # Data received frame by frame from the server is appended\n             # and passed to the response Deferred when completely received.\n-            'body': b'',\n+            'body': BytesIO(),\n+\n+            # The amount of data received that counts against the flow control\n+            # window\n+            'flow_controlled_size': 0,\n \n             # Headers received after sending the request\n             'headers': Headers({})\n@@ -137,16 +166,8 @@ class Stream:\n \n          Warning: Only call this method when stream not closed from client side\n             and has initiated request already by sending HEADER frame. If not then\n-            stream will be closed from client side with 499 response.\n-\n-            TODO: Q. Should we instead raise ProtocolError here with a proper message?\n+            stream will raise ProtocolError (raise by h2 state machine).\n          \"\"\"\n-        if self.stream_closed_local or self.stream_closed_server:\n-            raise StreamClosedError(self.stream_id)\n-        elif not self.request_sent:\n-            self.close()\n-            return\n-\n         # TODO:\n         #  1. Add test for sending very large data\n         #  2. Add test for small data\n@@ -154,6 +175,9 @@ class Stream:\n         #    3.1 Large number of request\n         #    3.2 Small number of requests\n \n+        if self.stream_closed_local:\n+            raise StreamClosedError(self.stream_id)\n+\n         # Firstly, check what the flow control window is for current stream.\n         window_size = self._conn.local_flow_control_window(stream_id=self.stream_id)\n \n@@ -170,7 +194,7 @@ class Stream:\n             chunk_size = min(bytes_to_send_size, max_frame_size)\n \n             data_chunk_start_id = self.content_length - self.remaining_content_length\n-            data_chunk = self._request_body[data_chunk_start_id:data_chunk_start_id + chunk_size]\n+            data_chunk = self._request.body[data_chunk_start_id:data_chunk_start_id + chunk_size]\n \n             self._conn.send_data(self.stream_id, data_chunk, end_stream=False)\n \n@@ -183,7 +207,7 @@ class Stream:\n             self,\n             self.content_length - self.remaining_content_length, self.content_length,\n             data_frames_sent,\n-            self._metadata['ip_address'])\n+            self._conn_metadata['ip_address'])\n         )\n \n         # End the stream if no more data needs to be send\n@@ -197,24 +221,40 @@ class Stream:\n         # Q. What about the rest of the data?\n         # Ans: Remaining Data frames will be sent when we get a WindowUpdate frame\n \n-    def receive_window_update(self, delta):\n+    def receive_window_update(self):\n         \"\"\"Flow control window size was changed.\n         Send data that earlier could not be sent as we were\n         blocked behind the flow control.\n-\n-        Arguments:\n-            delta -- Window change delta\n         \"\"\"\n-        if self.remaining_content_length > 0 and not self.stream_closed_server:\n+        if self.remaining_content_length and not self.stream_closed_server and self.request_sent:\n             self.send_data()\n \n     def receive_data(self, data: bytes, flow_controlled_length: int):\n-        self._response['body'] += data\n-        self._response_flow_controlled_size += flow_controlled_length\n+        self._response['body'].write(data)\n+        self._response['flow_controlled_size'] += flow_controlled_length\n+\n+        if self._download_maxsize and self._response['flow_controlled_size'] > self._download_maxsize:\n+            # Clear buffer earlier to avoid keeping data in memory for a long time\n+            self._response['body'].truncate(0)\n+            self.reset_stream(StreamCloseReason.MAXSIZE_EXCEEDED)\n+            return\n+\n+        if self._download_warnsize \\\n+                and self._response['flow_controlled_size'] > self._download_warnsize \\\n+                and not self._reached_warnsize:\n+            self._reached_warnsize = True\n+            warning_msg = ('Received more ({bytes}) bytes than download ',\n+                           'warn size ({warnsize}) in request {request}')\n+            warning_args = {\n+                'bytes': self._response['flow_controlled_size'],\n+                'warnsize': self._download_warnsize,\n+                'request': self._request\n+            }\n+            LOGGER.warning(warning_msg, warning_args)\n \n         # Acknowledge the data received\n         self._conn.acknowledge_received_data(\n-            self._response_flow_controlled_size,\n+            self._response['flow_controlled_size'],\n             self.stream_id\n         )\n \n@@ -222,35 +262,83 @@ class Stream:\n         for name, value in headers:\n             self._response['headers'][name] = value\n \n-    def close(self, event=None):\n-        \"\"\"Based on the event sent we will handle each case.\n+        # Check if we exceed the allowed max data size which can be received\n+        expected_size = int(self._response['headers'].get(b'Content-Length', -1))\n+        if self._download_maxsize and expected_size > self._download_maxsize:\n+            self.reset_stream(StreamCloseReason.MAXSIZE_EXCEEDED)\n+            return\n \n-        event: StreamEnded\n-        Stream is ended by the server hence no further\n-        data or headers should be expected on this stream.\n-        We will call the response deferred callback passing\n-        the response object\n+        if self._download_warnsize and expected_size > self._download_warnsize:\n+            warning_msg = (\"Expected response size ({size}) larger than \",\n+                           \"download warn size ({warnsize}) in request {request}.\")\n+            warning_args = {\n+                'size': expected_size, 'warnsize': self._download_warnsize,\n+                'request': self._request\n+            }\n+            LOGGER.warning(warning_msg, warning_args)\n \n-        event: StreamReset\n-        Stream reset via RST_FRAME by the upstream hence forcefully close\n-        this stream and send TODO: ?\n+    def reset_stream(self, reason=StreamCloseReason.RESET):\n+        \"\"\"Close this stream by sending a RST_FRAME to the remote peer\"\"\"\n+        # TODO: Q. REFUSED_STREAM or CANCEL ?\n+        if self.stream_closed_local:\n+            raise StreamClosedError(self.stream_id)\n \n-        event: None\n-        No event is launched -- Hence we will simply close this stream\n+        self.stream_closed_local = True\n+        self._conn.reset_stream(self.stream_id, ErrorCodes.REFUSED_STREAM)\n+        self._write_to_transport()\n+        self.close(reason)\n+\n+    def _is_data_lost(self) -> bool:\n+        assert self.stream_closed_server\n+\n+        expected_size = self._response['flow_controlled_size']\n+        received_body_size = int(self._response['headers'][b'Content-Length'])\n+\n+        return expected_size != received_body_size\n+\n+    def close(self, reason: StreamCloseReason):\n+        \"\"\"Based on the reason sent we will handle each case.\n         \"\"\"\n         # TODO: In case of abruptly stream close\n         #  Q1. Do we need to send the request again?\n         #  Q2. What response should we send now?\n-        assert self.stream_closed_server is False\n+        if self.stream_closed_server:\n+            raise StreamClosedError(self.stream_id)\n+\n         self.stream_closed_server = True\n \n-        if not isinstance(event, StreamEnded):\n-            # TODO\n-            # Stream was abruptly ended here\n-            # Partial - Content-Length header not provided\n-            pass\n+        flags = None\n+        if b'Content-Length' not in self._response['headers']:\n+            # Missing Content-Length - PotentialDataLoss\n+            flags = ['partial']\n+        elif self._is_data_lost():\n+            if self._fail_on_dataloss:\n+                self._deferred_response.errback(ResponseFailed([Failure()]))\n+                self._cb_close(self.stream_id)\n+                return\n+            else:\n+                flags = ['dataloss']\n+\n+        if reason is StreamCloseReason.ENDED:\n+            self._fire_response_deferred(flags)\n+\n+        elif reason in (StreamCloseReason.RESET | StreamCloseReason.CONNECTION_LOST):\n+            # Stream was abruptly ended here\n+            self._deferred_response.errback(ResponseFailed([Failure()]))\n+\n+        elif reason is StreamCloseReason.MAXSIZE_EXCEEDED:\n+            expected_size = int(self._response['headers'].get(b'Content-Length', -1))\n+            error_msg = (\"Cancelling download of {url}: expected response \"\n+                         \"size ({size}) larger than download max size ({maxsize}).\")\n+            error_args = {\n+                'url': self._request.url,\n+                'size': expected_size,\n+                'maxsize': self._download_maxsize\n+            }\n+\n+            LOGGER.error(error_msg, error_args)\n+            self._deferred_response.errback(CancelledError(error_msg.format(**error_args)))\n \n-        self._fire_response_deferred()\n         self._cb_close(self.stream_id)\n \n     def _fire_response_deferred(self, flags=None):\n@@ -258,7 +346,6 @@ class Stream:\n         and fires the response deferred callback with the\n         generated response instance\"\"\"\n         # TODO:\n-        #  1. Set flags, certificate, ip_address in response\n         #  2. Should we fire this in case of\n         #   2.1 StreamReset in between when data is received partially\n         #   2.2 Forcefully closed the stream\n@@ -270,7 +357,7 @@ class Stream:\n             body=self._response['body']\n         )\n \n-        # If there is :status in headers then\n+        # If there is no :status in headers then\n         # HTTP Status Code: 499 - Client Closed Request\n         status = self._response['headers'].get(':status', '499')\n \n@@ -278,11 +365,11 @@ class Stream:\n             url=self._request.url,\n             status=status,\n             headers=self._response['headers'],\n-            body=self._response['body'],\n+            body=self._response['body'].getvalue(),\n             request=self._request,\n             flags=flags,\n-            certificate=self._metadata['certificate'],\n-            ip_address=self._metadata['ip_address']\n+            certificate=self._conn_metadata['certificate'],\n+            ip_address=self._conn_metadata['ip_address']\n         )\n \n         self._deferred_response.callback(response)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
