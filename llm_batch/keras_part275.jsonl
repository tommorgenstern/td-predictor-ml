{"custom_id": "keras#2898da6cfcc893aafc0b9016f934ef08c196b9d4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 1811 | Contributors (this commit): 31 | Commits (past 90d): 7 | Contributors (cumulative): 31 | DMM Complexity: None\n\nDIFF:\n@@ -104,6 +104,7 @@ EXCLUDE = {\n     'normalize_data_format',\n     'image_dim_ordering',\n     'get_variable_shape',\n+    'Constraint'\n }\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3e772defb7781955be8c5490744532ccdfc1dd3f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 36 | Lines Deleted: 31 | Files Changed: 1 | Hunks: 25 | Methods Changed: 10 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 67 | Churn Cumulative: 1700 | Contributors (this commit): 12 | Commits (past 90d): 8 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -24,7 +24,7 @@ except ImportError:\n     h5py = None\n \n \n-def _serialize_model(model, f, include_optimizer=True):\n+def _serialize_model(model, h5dict, include_optimizer=True):\n     \"\"\"Model serialization logic.\n \n     This method is used for both writing to HDF5 file/group,\n@@ -34,7 +34,7 @@ def _serialize_model(model, f, include_optimizer=True):\n \n     # Arguments\n         model: Keras model instance to be serialized.\n-        f: keras.utils.io_utils.HD5Dict instance.\n+        h5dict: keras.utils.io_utils.HD5Dict instance.\n         include_optimizer: If True, serialize optimizer's state together.\n \n     \"\"\"\n@@ -75,17 +75,17 @@ def _serialize_model(model, f, include_optimizer=True):\n \n     from .. import __version__ as keras_version\n \n-    f['keras_version'] = str(keras_version).encode('utf8')\n-    f['backend'] = K.backend().encode('utf8')\n+    h5dict['keras_version'] = str(keras_version).encode('utf8')\n+    h5dict['backend'] = K.backend().encode('utf8')\n \n     model_config = {}\n     model_config['class_name'] = model.__class__.__name__\n     model_config['config'] = model.get_config()\n     model_config = json.dumps(model_config, default=get_json_type)\n     model_config = model_config.encode('utf-8')\n-    f['model_config'] = model_config\n+    h5dict['model_config'] = model_config\n \n-    model_weights_group = f['model_weights']\n+    model_weights_group = h5dict['model_weights']\n     model_layers = model.layers\n     model_weights_group['layer_names'] = [layer.name.encode('utf8')\n                                           for layer in model_layers]\n@@ -126,7 +126,7 @@ def _serialize_model(model, f, include_optimizer=True):\n                 'Prefer using a Keras optimizer instead '\n                 '(see keras.io/optimizers).')\n         else:\n-            f['training_config'] = json.dumps({\n+            h5dict['training_config'] = json.dumps({\n                 'optimizer_config': {\n                     'class_name': model.optimizer.__class__.__name__,\n                     'config': model.optimizer.get_config()\n@@ -139,7 +139,7 @@ def _serialize_model(model, f, include_optimizer=True):\n             }, default=get_json_type).encode('utf8')\n             symbolic_weights = getattr(model.optimizer, 'weights')\n             if symbolic_weights:\n-                optimizer_weights_group = f['optimizer_weights']\n+                optimizer_weights_group = h5dict['optimizer_weights']\n                 weight_values = K.batch_get_value(symbolic_weights)\n                 weight_names = []\n                 for i, (w, val) in enumerate(zip(symbolic_weights,\n@@ -172,11 +172,11 @@ def _serialize_model(model, f, include_optimizer=True):\n                     optimizer_weights_group[name] = val\n \n \n-def _deserialize_model(f, custom_objects=None, compile=True):\n+def _deserialize_model(h5dict, custom_objects=None, compile=True):\n     \"\"\"De-serializes a model serialized via _serialize_model\n \n     # Arguments\n-        f: `keras.utils.hdf5_utils.HFDict` instance.\n+        h5dict: `keras.utils.hdf5_utils.HFDict` instance.\n         custom_objects: Optional dictionary mapping names\n             (strings) to custom classes or functions to be\n             considered during deserialization.\n@@ -219,12 +219,12 @@ def _deserialize_model(f, custom_objects=None, compile=True):\n             return custom_objects[obj]\n         return obj\n \n-    model_config = f['model_config']\n+    model_config = h5dict['model_config']\n     if model_config is None:\n         raise ValueError('No model found in config.')\n     model_config = json.loads(model_config.decode('utf-8'))\n     model = model_from_config(model_config, custom_objects=custom_objects)\n-    model_weights_group = f['model_weights']\n+    model_weights_group = h5dict['model_weights']\n \n     if 'keras_version' in model_weights_group:\n         original_keras_version = model_weights_group['keras_version'].decode('utf8')\n@@ -288,7 +288,7 @@ def _deserialize_model(f, custom_objects=None, compile=True):\n     K.batch_set_value(weight_value_tuples)\n \n     if compile:\n-        training_config = f.get('training_config')\n+        training_config = h5dict.get('training_config')\n         if training_config is None:\n             warnings.warn('No training configuration found in save file: '\n                           'the model was *not* compiled. '\n@@ -313,10 +313,10 @@ def _deserialize_model(f, custom_objects=None, compile=True):\n                       sample_weight_mode=sample_weight_mode)\n \n         # Set optimizer weights.\n-        if 'optimizer_weights' in f:\n+        if 'optimizer_weights' in h5dict:\n             # Build train function (to get weight updates).\n             model._make_train_function()\n-            optimizer_weights_group = f['optimizer_weights']\n+            optimizer_weights_group = h5dict['optimizer_weights']\n             optimizer_weight_names = [\n                 n.decode('utf8') for n in\n                 optimizer_weights_group['weight_names']]\n@@ -377,13 +377,12 @@ def save_model(model, filepath, overwrite=True, include_optimizer=True):\n     else:\n         opened_new_file = False\n \n-    f = H5Dict(filepath, mode='w')\n-\n+    h5dict = H5Dict(filepath, mode='w')\n     try:\n-        _serialize_model(model, f, include_optimizer)\n+        _serialize_model(model, h5dict, include_optimizer)\n     finally:\n         if opened_new_file:\n-            f.close()\n+            h5dict.close()\n \n \n def load_model(filepath, custom_objects=None, compile=True):\n@@ -415,25 +414,25 @@ def load_model(filepath, custom_objects=None, compile=True):\n         raise ImportError('`load_model` requires h5py.')\n     model = None\n     opened_new_file = not isinstance(filepath, h5py.Group)\n-    f = H5Dict(filepath, 'r')\n+    h5dict = H5Dict(filepath, 'r')\n     try:\n-        model = _deserialize_model(f, custom_objects, compile)\n+        model = _deserialize_model(h5dict, custom_objects, compile)\n     finally:\n         if opened_new_file:\n-            f.close()\n+            h5dict.close()\n     return model\n \n \n def pickle_model(model):\n     d = {}\n-    f = H5Dict(d)\n-    _serialize_model(model, f)\n+    h5dict = H5Dict(d)\n+    _serialize_model(model, h5dict)\n     return d\n \n \n def unpickle_model(state):\n-    f = H5Dict(state, mode='r')\n-    return _deserialize_model(f)\n+    h5dict = H5Dict(state, mode='r')\n+    return _deserialize_model(h5dict)\n \n \n def model_from_config(config, custom_objects=None):\n@@ -559,16 +558,22 @@ def load_attributes_from_hdf5_group(group, name):\n     return data\n \n \n-def save_weights_to_hdf5_group(f, layers):\n+def save_weights_to_hdf5_group(group, layers):\n+    \"\"\"Saves weights into the HDF5 group.\n+\n+    # Arguments\n+        group: A pointer to a HDF5 group.\n+        layers: Layers to load.\n+    \"\"\"\n     from .. import __version__ as keras_version\n \n     save_attributes_to_hdf5_group(\n-        f, 'layer_names', [layer.name.encode('utf8') for layer in layers])\n-    f.attrs['backend'] = K.backend().encode('utf8')\n-    f.attrs['keras_version'] = str(keras_version).encode('utf8')\n+        group, 'layer_names', [layer.name.encode('utf8') for layer in layers])\n+    group.attrs['backend'] = K.backend().encode('utf8')\n+    group.attrs['keras_version'] = str(keras_version).encode('utf8')\n \n     for layer in layers:\n-        g = f.create_group(layer.name)\n+        g = group.create_group(layer.name)\n         symbolic_weights = layer.weights\n         weight_values = K.batch_get_value(symbolic_weights)\n         weight_names = []\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b7fad0752779177e0968f93832d8a5b302236a7d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 41 | Lines Deleted: 15 | Files Changed: 2 | Hunks: 6 | Methods Changed: 4 | Complexity Δ (Sum/Max): 5/5 | Churn Δ: 56 | Churn Cumulative: 6604 | Contributors (this commit): 33 | Commits (past 90d): 70 | Contributors (cumulative): 39 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1783,30 +1783,25 @@ class TestBackend(object):\n                   for t in range(max_time_steps)]\n \n         # change tensorflow order to keras backend order\n-        inputs = K.variable(np.asarray(inputs).transpose((1, 0, 2)))\n+        inputs = np.asarray(inputs).transpose((1, 0, 2))\n+\n         # batch_size length vector of sequence_lengths\n-        input_length = K.variable(np.array([seq_len_0, seq_len_1], dtype=np.int32))\n-\n-        # batch_size length vector of negative log probabilities\n-        log_prob_truth = np.array([\n-            np.sum(-np.log([1.0, 0.6, 0.6, 0.9])),\n-            np.sum(-np.log([0.9, 0.9, 0.9, 0.9, 0.9]))\n-        ], np.float32)[:, np.newaxis]\n-\n-        # keras output, unlike tensorflow, is a dense (not sparse) tensor\n-        decode_truth = np.array([[0, 1, -1], [1, 1, 0]])\n+        input_length = np.array([seq_len_0, seq_len_1], dtype=np.int32)\n \n+        decode_pred_np, log_prob_pred_np = KNP.ctc_decode(inputs,\n+                                                          input_length, greedy=True)\n+        inputs = K.variable(inputs)\n+        input_length = K.variable(input_length)\n         decode_pred_tf, log_prob_pred_tf = K.ctc_decode(inputs,\n-                                                        input_length,\n-                                                        greedy=True)\n+                                                        input_length, greedy=True)\n \n         assert len(decode_pred_tf) == 1\n \n         decode_pred = K.eval(decode_pred_tf[0])\n         log_prob_pred = K.eval(log_prob_pred_tf)\n \n-        assert np.alltrue(decode_truth == decode_pred)\n-        assert np.allclose(log_prob_truth, log_prob_pred)\n+        assert np.alltrue(decode_pred_np == decode_pred)\n+        assert np.allclose(log_prob_pred_np, log_prob_pred)\n \n     @pytest.mark.skipif(K.backend() != 'tensorflow',\n                         reason='Beam search is only implemented with '\n\n@@ -688,6 +688,37 @@ def resize_volumes(x, depth_factor, height_factor, width_factor, data_format):\n def one_hot(indices, num_classes):\n     return to_categorical(indices, num_classes)\n \n+\n+def ctc_decode(y_pred, input_length, greedy=True, beam_width=100, top_paths=1):\n+    num_samples = y_pred.shape[0]\n+    num_classes = y_pred.shape[-1]\n+    log_prob = np.zeros((num_samples, 1))\n+    decoded_dense = -np.ones_like(y_pred[..., 0])\n+    decoded_length = np.zeros((num_samples,), dtype=np.int)\n+    if greedy:\n+        for i in range(num_samples):\n+            prob = y_pred[i]\n+            length = input_length[i]\n+            decoded = np.argmax(prob[:length], axis=-1)\n+            log_prob[i] = -np.sum(np.log(prob[np.arange(length), decoded]))\n+            decoded = _remove_repeats(decoded)\n+            decoded = _remove_blanks(decoded, num_classes)\n+            decoded_length[i] = len(decoded)\n+            decoded_dense[i, :len(decoded)] = decoded\n+        return decoded_dense[:, :np.max(decoded_length)], log_prob\n+    else:\n+        raise \"not supported yet\"\n+\n+\n+def _remove_repeats(inds):\n+    is_not_repeat = np.insert(np.diff(inds).astype(np.bool), 0, True)\n+    return inds[is_not_repeat]\n+\n+\n+def _remove_blanks(inds, num_classes):\n+    return inds[inds < (num_classes - 1)]\n+\n+\n square = np.square\n abs = np.abs\n exp = np.exp\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e47a003ed160d829300f6782a2e3ec014c739144", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 21 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 22 | Churn Cumulative: 12445 | Contributors (this commit): 81 | Commits (past 90d): 3 | Contributors (cumulative): 81 | DMM Complexity: None\n\nDIFF:\n@@ -592,10 +592,30 @@ class Lambda(Layer):\n         model.add(Lambda(antirectifier,\n                          output_shape=antirectifier_output_shape))\n     ```\n+    ```python\n+        # add a layer that returns the hadamard product\n+        # and sum of it from two input tensors\n+\n+        def hadamard_product_sum(tensors):\n+            out1 = tensors[0] * tensors[1]\n+            out2 = K.sum(out1, axis=-1)\n+            return [out1, out2]\n+\n+        def hadamard_product_sum_output_shape(input_shapes):\n+            shape1 = list(input_shapes[0])\n+            shape2 = list(input_shapes[1])\n+            assert shape1 == shape2  # else hadamard product isn't possible\n+            return [tuple(shape1), tuple(shape2[:-1])]\n+\n+        x1 = Dense(32)(input_1)\n+        x2 = Dense(32)(input_2)\n+        layer = Lambda(hadamard_product_sum, hadamard_product_sum_output_shape)\n+        x_hadamard, x_sum = layer([x1, x2])\n+    ```\n \n     # Arguments\n         function: The function to be evaluated.\n-            Takes input tensor as first argument.\n+            Takes input tensor or list of tensors as first argument.\n         output_shape: Expected output shape from function.\n             Only relevant when using Theano.\n             Can be a tuple or function.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8ef5dcfd3dfa385e00e7d2654825f7f79d2dec57", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 49 | Lines Deleted: 1 | Files Changed: 4 | Hunks: 7 | Methods Changed: 5 | Complexity Δ (Sum/Max): 6/6 | Churn Δ: 50 | Churn Cumulative: 17991 | Contributors (this commit): 147 | Commits (past 90d): 73 | Contributors (cumulative): 186 | DMM Complexity: 1.0\n\nDIFF:\n@@ -80,6 +80,7 @@ from keras import models\n from keras import losses\n from keras import metrics\n from keras import backend\n+from keras.backend import numpy_backend\n from keras import constraints\n from keras import activations\n from keras import preprocessing\n@@ -575,6 +576,44 @@ def process_docstring(docstring):\n             '$CODE_BLOCK_%d' % i, code_block)\n     return docstring\n \n+\n+template_np_implementation = \"\"\"# Numpy implementation\n+\n+    ```python\n+{{code}}\n+    ```\n+\"\"\"\n+\n+template_hidden_np_implementation = \"\"\"# Numpy implementation\n+\n+    <details>\n+    <summary>Show the Numpy implementation</summary>\n+\n+    ```python\n+{{code}}\n+    ```\n+\n+    </details>\n+\"\"\"\n+\n+\n+def add_np_implementation(function, docstring):\n+    np_implementation = getattr(numpy_backend, function.__name__)\n+    code = inspect.getsource(np_implementation)\n+    code_lines = code.split('\\n')\n+    for i in range(len(code_lines)):\n+        if code_lines[i]:\n+            # if there is something on the line, add 8 spaces.\n+            code_lines[i] = '        ' + code_lines[i]\n+    code = '\\n'.join(code_lines[:-1])\n+\n+    if len(code_lines) < 10:\n+        section = template_np_implementation.replace('{{code}}', code)\n+    else:\n+        section = template_hidden_np_implementation.replace('{{code}}', code)\n+    return docstring.replace('{{np_implementation}}', section)\n+\n+\n print('Cleaning up existing sources directory.')\n if os.path.exists('sources'):\n     shutil.rmtree('sources')\n@@ -617,6 +656,9 @@ def render_function(function, method=True):\n     subblocks.append(code_snippet(signature))\n     docstring = function.__doc__\n     if docstring:\n+        if ('backend' in signature and\n+                '{{np_implementation}}' in docstring):\n+            docstring = add_np_implementation(function, docstring)\n         subblocks.append(process_docstring(docstring))\n     return '\\n\\n'.join(subblocks)\n \n\n\n@@ -1150,6 +1150,8 @@ def batch_dot(x, y, axes=None):\n         >>> K.int_shape(xy_batch_dot)\n         (32, 1, 30)\n     ```\n+\n+    {{np_implementation}}\n     \"\"\"\n     x_shape = int_shape(x)\n     y_shape = int_shape(y)\n@@ -1291,6 +1293,8 @@ def gather(reference, indices):\n \n     # Returns\n         A tensor of same type as `reference`.\n+\n+    {{np_implementation}}\n     \"\"\"\n     return tf.nn.embedding_lookup(reference, indices)\n \n@@ -2442,6 +2446,8 @@ def reverse(x, axes):\n \n     # Returns\n         A tensor.\n+\n+    {{np_implementation}}\n     \"\"\"\n     if isinstance(axes, int):\n         axes = [axes]\n\n@@ -7,7 +7,7 @@ import warnings\n from keras import backend as K\n from keras.backend import floatx, set_floatx, variable\n from keras.utils.conv_utils import convert_kernel\n-import reference_operations as KNP\n+from keras.backend import numpy_backend as KNP\n \n \n BACKENDS = []  # Holds a list of all available back-ends\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9e410e7839793d232276253a6a560153bcb6cce6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 2 | Churn Cumulative: 1200 | Contributors (this commit): 31 | Commits (past 90d): 4 | Contributors (cumulative): 31 | DMM Complexity: 0.0\n\nDIFF:\n@@ -120,6 +120,8 @@ def serialize_keras_object(instance):\n def deserialize_keras_object(identifier, module_objects=None,\n                              custom_objects=None,\n                              printable_module_name='object'):\n+    if identifier is None:\n+        return None\n     if isinstance(identifier, dict):\n         # In this case we are dealing with a Keras config dictionary.\n         config = identifier\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#90c90b69cf35c0457ae52e97e363b82562fe1920", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 809 | Contributors (this commit): 12 | Commits (past 90d): 2 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -83,8 +83,8 @@ layer_dict = dict([(layer.name, layer) for layer in model.layers])\n loss = K.variable(0.)\n for layer_name in settings['features']:\n     # Add the L2 norm of the features of a layer to the loss.\n-    assert (layer_name in layer_dict.keys(),\n-            'Layer ' + layer_name + ' not found in model.')\n+    if layer_name not in layer_dict:\n+        raise ValueError('Layer ' + layer_name + ' not found in model.')\n     coeff = settings['features'][layer_name]\n     x = layer_dict[layer_name].output\n     # We avoid border artifacts by only involving non-border pixels in the loss.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#384d3bc35db3359cb7c1f560e053f2a510d9381a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 230 | Files Changed: 1 | Hunks: 3 | Methods Changed: 12 | Complexity Δ (Sum/Max): -30/0 | Churn Δ: 230 | Churn Cumulative: 5969 | Contributors (this commit): 33 | Commits (past 90d): 47 | Contributors (cumulative): 33 | DMM Complexity: 0.39106145251396646\n\nDIFF:\n@@ -832,144 +832,6 @@ class TestBackend(object):\n         assert_allclose(last_y1, last_y2, atol=1e-05)\n         assert_allclose(y1, y2, atol=1e-05)\n \n-    def test_legacy_rnn(self):\n-        # implement a simple RNN\n-        num_samples = 4\n-        input_dim = 5\n-        output_dim = 3\n-        timesteps = 6\n-\n-        input_val = np.random.random(\n-            (num_samples, timesteps, input_dim)).astype(np.float32)\n-        init_state_val = np.random.random(\n-            (num_samples, output_dim)).astype(np.float32)\n-        W_i_val = np.random.random((input_dim, output_dim)).astype(np.float32)\n-        W_o_val = np.random.random((output_dim, output_dim)).astype(np.float32)\n-        np_mask = np.random.randint(2, size=(num_samples, timesteps))\n-\n-        def rnn_step_fn(k):\n-            W_i = k.variable(W_i_val)\n-            W_o = k.variable(W_o_val)\n-\n-            def step_function(x, states):\n-                assert len(states) == 1\n-                prev_output = states[0]\n-                output = k.dot(x, W_i) + k.dot(prev_output, W_o)\n-                return output, [output]\n-\n-            return step_function\n-\n-        # test default setup\n-        last_output_list = [[], [], [], [], [], []]\n-        outputs_list = [[], [], [], [], [], []]\n-        state_list = [[], [], [], [], [], []]\n-\n-        for k in BACKENDS:\n-            rnn_fn = rnn_step_fn(k)\n-            inputs = k.variable(input_val)\n-            initial_states = [k.variable(init_state_val)]\n-            mask = k.variable(np_mask)\n-\n-            kwargs_list = [\n-                {'go_backwards': False, 'mask': None},\n-                {'go_backwards': False, 'mask': None, 'unroll': True,\n-                 'input_length': timesteps},\n-                {'go_backwards': True, 'mask': None},\n-                {'go_backwards': True, 'mask': None, 'unroll': True,\n-                 'input_length': timesteps},\n-                {'go_backwards': False, 'mask': mask},\n-                {'go_backwards': False, 'mask': mask, 'unroll': True,\n-                 'input_length': timesteps},\n-            ]\n-\n-            for (i, kwargs) in enumerate(kwargs_list):\n-                last_output, outputs, new_states = k.rnn(rnn_fn, inputs,\n-                                                         initial_states,\n-                                                         **kwargs)\n-\n-                last_output_list[i].append(k.eval(last_output))\n-                outputs_list[i].append(k.eval(outputs))\n-                assert len(new_states) == 1\n-                state_list[i].append(k.eval(new_states[0]))\n-\n-        assert_list_pairwise(last_output_list[0], shape=False, atol=1e-04)\n-        assert_list_pairwise(outputs_list[0], shape=False, atol=1e-04)\n-        assert_list_pairwise(state_list[0], shape=False, atol=1e-04)\n-        assert_list_pairwise(last_output_list[2], shape=False, atol=1e-04)\n-        assert_list_pairwise(outputs_list[2], shape=False, atol=1e-04)\n-        assert_list_pairwise(state_list[2], shape=False, atol=1e-04)\n-\n-        for l, u_l in zip(last_output_list[0], last_output_list[1]):\n-            assert_allclose(l, u_l, atol=1e-04)\n-\n-        for o, u_o in zip(outputs_list[0], outputs_list[1]):\n-            assert_allclose(o, u_o, atol=1e-04)\n-\n-        for s, u_s in zip(state_list[0], state_list[1]):\n-            assert_allclose(s, u_s, atol=1e-04)\n-\n-        for b_l, b_u_l in zip(last_output_list[2], last_output_list[3]):\n-            assert_allclose(b_l, b_u_l, atol=1e-04)\n-\n-        for b_o, b_u_o in zip(outputs_list[2], outputs_list[3]):\n-            assert_allclose(b_o, b_u_o, atol=1e-04)\n-\n-        for b_s, b_u_s in zip(state_list[2], state_list[3]):\n-            assert_allclose(b_s, b_u_s, atol=1e-04)\n-\n-        for m_l, u_m_l, k in zip(last_output_list[4], last_output_list[5], BACKENDS):\n-            if k == KTF:\n-                m_l = m_l * np.expand_dims(np_mask[:, -1], -1)\n-                u_m_l = u_m_l * np.expand_dims(np_mask[:, -1], -1)\n-            assert_allclose(m_l, u_m_l, atol=1e-04)\n-\n-        for m_o, u_m_o, k in zip(outputs_list[4], outputs_list[5], BACKENDS):\n-            if k == KTF:\n-                m_o = m_o * np.expand_dims(np_mask, -1)\n-                u_m_o = u_m_o * np.expand_dims(np_mask, -1)\n-            assert_allclose(m_o, u_m_o, atol=1e-04)\n-\n-        for m_s, u_m_s, k in zip(state_list[4], state_list[5], BACKENDS):\n-            assert_allclose(m_s, u_m_s, atol=1e-04)\n-\n-    def test_legacy_rnn_no_states(self):\n-        # implement a simple RNN without states\n-        input_dim = 8\n-        output_dim = 4\n-        timesteps = 5\n-\n-        input_val = np.random.random((32, timesteps, input_dim))\n-        W_i_val = np.random.random((input_dim, output_dim))\n-\n-        def rnn_step_fn(k):\n-            W_i = k.variable(W_i_val)\n-\n-            def step_function(x, states):\n-                assert len(states) == 0\n-                output = k.dot(x, W_i)\n-                return output, []\n-\n-            return step_function\n-\n-        # test default setup\n-        last_output_list = []\n-        outputs_list = []\n-\n-        for k in BACKENDS:\n-            rnn_fn = rnn_step_fn(k)\n-            inputs = k.variable(input_val)\n-            initial_states = []\n-            last_output, outputs, new_states = k.rnn(rnn_fn, inputs,\n-                                                     initial_states,\n-                                                     go_backwards=False,\n-                                                     mask=None)\n-            last_output_list.append(k.eval(last_output))\n-            outputs_list.append(k.eval(outputs))\n-            assert len(new_states) == 0\n-\n-        assert_list_pairwise(last_output_list, shape=False)\n-        assert_list_pairwise(outputs_list, shape=False)\n-\n     @pytest.mark.parametrize('x_np,axis,keepdims', [\n         (np.array([1.1, 0.8, 0.9]), 0, False),\n         (np.array([[1.1, 0.8, 0.9]]), 0, False),\n@@ -1272,55 +1134,6 @@ class TestBackend(object):\n             padding=padding, data_format=data_format, pool_mode=pool_mode,\n             cntk_dynamicity=True)\n \n-    def test_legacy_conv1d(self):\n-        # channels_last input shape: (n, length, input_depth)\n-        input_shape = (4, 8, 2)\n-        kernel_shape = (3, 2, 3)\n-        for strides in [1, 2]:\n-            check_two_tensor_operation('conv1d', input_shape, kernel_shape,\n-                                       BACKENDS, cntk_dynamicity=True,\n-                                       strides=strides,\n-                                       data_format='channels_last')\n-\n-    def test_legacy_conv2d(self):\n-        # TF kernel shape: (rows, cols, input_depth, depth)\n-        # channels_first input shape: (n, input_depth, rows, cols)\n-        for (input_shape, kernel_shape, data_format) in [\n-            ((2, 3, 4, 5), (2, 2, 3, 4), 'channels_first'),\n-            ((2, 3, 5, 6), (4, 3, 3, 4), 'channels_first'),\n-            ((1, 6, 5, 3), (3, 3, 3, 2), 'channels_last')\n-        ]:\n-            check_two_tensor_operation('conv2d', input_shape, kernel_shape,\n-                                       BACKENDS, cntk_dynamicity=True,\n-                                       data_format=data_format)\n-\n-    def test_legacy_depthwise_conv_2d(self):\n-        # TF kernel shape: (rows, cols, input_depth, depth_multiplier)\n-        # channels_first input shape: (n, input_depth, rows, cols)\n-        for (input_shape, kernel_shape, data_format) in [\n-            ((2, 3, 4, 5), (2, 2, 3, 4), 'channels_first'),\n-            ((2, 3, 5, 6), (4, 3, 3, 4), 'channels_first'),\n-            ((1, 6, 5, 3), (3, 3, 3, 2), 'channels_last')\n-        ]:\n-            check_two_tensor_operation('depthwise_conv2d',\n-                                       input_shape, kernel_shape,\n-                                       BACKENDS, cntk_dynamicity=True,\n-                                       data_format=data_format)\n-\n-    def test_legacy_conv3d(self):\n-        # TH input shape: (samples, input_depth, conv_dim1, conv_dim2, conv_dim3)\n-        # TF input shape: (samples, conv_dim1, conv_dim2, conv_dim3, input_depth)\n-        # TH kernel shape: (depth, input_depth, x, y, z)\n-        # TF kernel shape: (x, y, z, input_depth, depth)\n-        for (input_shape, kernel_shape, data_format) in [\n-            ((2, 3, 4, 5, 4), (2, 2, 2, 3, 4), 'channels_first'),\n-            ((2, 3, 5, 4, 6), (3, 2, 4, 3, 4), 'channels_first'),\n-            ((1, 2, 2, 2, 1), (2, 2, 2, 1, 1), 'channels_last')\n-        ]:\n-            check_two_tensor_operation('conv3d', input_shape, kernel_shape,\n-                                       BACKENDS, cntk_dynamicity=True,\n-                                       data_format=data_format)\n-\n     @pytest.mark.parametrize(\n         'op,input_shape,kernel_shape,depth_multiplier,padding,data_format', [\n             ('separable_conv1d', (2, 8, 2), (3,), 1, 'same', 'channels_last'),\n@@ -1360,49 +1173,6 @@ class TestBackend(object):\n                 padding=padding, data_format=data_format))\n         assert_allclose(y1, y2, atol=1e-05)\n \n-    def legacy_test_pool2d(self):\n-        check_single_tensor_operation(\n-            'pool2d', (5, 10, 12, 3), BACKENDS, cntk_dynamicity=True,\n-            pool_size=(2, 2), strides=(1, 1), padding='valid')\n-\n-        check_single_tensor_operation(\n-            'pool2d', (5, 9, 11, 3), BACKENDS, cntk_dynamicity=True,\n-            pool_size=(2, 2), strides=(1, 1), padding='valid')\n-\n-        check_single_tensor_operation(\n-            'pool2d', (5, 9, 11, 3), BACKENDS, cntk_dynamicity=True,\n-            pool_size=(2, 2), strides=(1, 1), pool_mode='avg')\n-\n-        check_single_tensor_operation(\n-            'pool2d', (5, 9, 11, 3), BACKENDS, cntk_dynamicity=True,\n-            pool_size=(2, 3), strides=(1, 1), padding='valid')\n-\n-        check_single_tensor_operation(\n-            'pool2d', (2, 7, 7, 5), BACKENDS, cntk_dynamicity=True,\n-            pool_size=(3, 3), strides=(1, 1),\n-            padding='same', pool_mode='avg')\n-\n-    def legacy_test_pool3d(self):\n-        check_single_tensor_operation(\n-            'pool3d', (5, 10, 12, 5, 3), BACKENDS, cntk_dynamicity=True,\n-            pool_size=(2, 2, 2), strides=(1, 1, 1), padding='valid')\n-\n-        check_single_tensor_operation(\n-            'pool3d', (5, 9, 11, 5, 3), BACKENDS, cntk_dynamicity=True,\n-            pool_size=(2, 2, 2), strides=(1, 1, 1), padding='valid')\n-\n-        check_single_tensor_operation(\n-            'pool3d', (5, 9, 11, 5, 3), BACKENDS, cntk_dynamicity=True,\n-            pool_size=(2, 2, 2), strides=(1, 1, 1), pool_mode='avg')\n-\n-        check_single_tensor_operation(\n-            'pool3d', (5, 9, 11, 5, 3), BACKENDS, cntk_dynamicity=True,\n-            pool_size=(2, 3, 2), strides=(1, 1, 1), padding='valid')\n-\n-        check_single_tensor_operation(\n-            'pool3d', (2, 6, 6, 6, 3), [KTH, KTF],\n-            pool_size=(3, 3, 3), strides=(1, 1, 1), padding='same', pool_mode='avg')\n-\n     def test_random_normal(self):\n         # test standard normal as well as a normal with a different set of parameters\n         for mean, std in [(0., 1.), (-10., 5.)]:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#97bff7df815de472039d366728df8f610528d631", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 189/189 | Churn Δ: 8 | Churn Cumulative: 8 | Contributors (this commit): 1 | Commits (past 90d): 2 | Contributors (cumulative): 1 | DMM Complexity: 0.0\n\nDIFF:\n@@ -572,11 +572,9 @@ def transpose(x):\n \n \n def reverse(x, axes):\n-    if isinstance(axes, int):\n-        axes = [axes]\n-    for a in axes:\n-        x = np.flip(x, a)\n-    return x\n+    if isinstance(axes, list):\n+        axes = tuple(axes)\n+    return np.flip(x, axes)\n \n \n def variable(value, dtype=None, name=None, constraint=None):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6207edd1477696f4a8a1761993544d72d766bd8e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 5 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 5975 | Contributors (this commit): 33 | Commits (past 90d): 48 | Contributors (cumulative): 33 | DMM Complexity: None\n\nDIFF:\n@@ -10,25 +10,20 @@ from keras.utils.conv_utils import convert_kernel\n from keras.backend import numpy_backend as KNP\n \n \n-BACKENDS = []  # Holds a list of all available back-ends\n-\n try:\n     from keras.backend import cntk_backend as KC\n-    BACKENDS.append(KC)\n except ImportError:\n     KC = None\n     warnings.warn('Could not import the CNTK backend')\n \n try:\n     from keras.backend import tensorflow_backend as KTF\n-    BACKENDS.append(KTF)\n except ImportError:\n     KTF = None\n     warnings.warn('Could not import the TensorFlow backend.')\n \n try:\n     from keras.backend import theano_backend as KTH\n-    BACKENDS.append(KTH)\n except ImportError:\n     KTH = None\n     warnings.warn('Could not import the Theano backend')\n@@ -439,7 +434,6 @@ class TestBackend(object):\n         check_single_tensor_operation('std', (4, 2), WITH_NP)\n         check_single_tensor_operation('std', (4, 2), WITH_NP, axis=1, keepdims=True)\n         check_single_tensor_operation('std', (4, 2, 3), WITH_NP, axis=[1, -1])\n-        # check_single_tensor_operation('std', (4, 2, 3), BACKENDS, axis=[1, -1])\n \n         check_single_tensor_operation('logsumexp', (4, 2), WITH_NP)\n         check_single_tensor_operation('logsumexp', (4, 2),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#08a6dd04f9143a04ee77af1128eaedb3218c6147", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 10413 | Contributors (this commit): 121 | Commits (past 90d): 21 | Contributors (cumulative): 122 | DMM Complexity: 0.0\n\nDIFF:\n@@ -285,9 +285,7 @@ def sigmoid(x):\n \n def hard_sigmoid(x):\n     y = 0.2 * x + 0.5\n-    y = np.minimum(y, 1.)\n-    y = np.maximum(y, 0.)\n-    return y\n+    return np.clip(y, 0, 1)\n \n \n def tanh(x):\n\n@@ -3493,6 +3493,8 @@ def hard_sigmoid(x):\n \n     # Returns\n         A tensor.\n+\n+    {{np_implementation}}\n     \"\"\"\n     x = (0.2 * x) + 0.5\n     zero = _to_tensor(0., x.dtype.base_dtype)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1d10fe2d739c48f00404008fe5754d2807bb0fd6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 7 | Churn Cumulative: 508 | Contributors (this commit): 10 | Commits (past 90d): 5 | Contributors (cumulative): 10 | DMM Complexity: 1.0\n\nDIFF:\n@@ -71,13 +71,6 @@ def layer_test(layer_cls, kwargs={}, input_shape=None, input_dtype=None,\n     weights = layer.get_weights()\n     layer.set_weights(weights)\n \n-    # test and instantiation from weights\n-    # Checking for empty weights array to avoid a problem where some\n-    # legacy layers return bad values from get_weights()\n-    if has_arg(layer_cls.__init__, 'weights') and len(weights):\n-        kwargs['weights'] = weights\n-        layer = layer_cls(**kwargs)\n-\n     expected_output_shape = layer.compute_output_shape(input_shape)\n \n     def _layer_in_model_test(model):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#58432f2c78cd5bc1d9893c63b3cb8977dab31670", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 362 | Contributors (this commit): 19 | Commits (past 90d): 6 | Contributors (cumulative): 19 | DMM Complexity: None\n\nDIFF:\n@@ -45,7 +45,6 @@ setup(name='Keras',\n                     'pytest-pep8',\n                     'pytest-xdist',\n                     'pytest-cov',\n-                    'pytest-timeout',\n                     'pandas',\n                     'requests'],\n       },\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0354142fa447e343ff99eda1ed504c19d4474aeb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 10 | Methods Changed: 10 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 20 | Churn Cumulative: 10421 | Contributors (this commit): 121 | Commits (past 90d): 19 | Contributors (cumulative): 121 | DMM Complexity: None\n\nDIFF:\n@@ -593,6 +593,8 @@ def int_shape(x):\n         >>> K.int_shape(kvar)\n         (2, 2)\n     ```\n+\n+    {{np_implementation}}\n     \"\"\"\n     if hasattr(x, '_keras_shape'):\n         return x._keras_shape\n@@ -622,6 +624,8 @@ def ndim(x):\n         >>> K.ndim(kvar)\n         2\n     ```\n+\n+    {{np_implementation}}\n     \"\"\"\n     dims = x.get_shape()._dims\n     if dims is not None:\n@@ -1685,6 +1689,8 @@ def equal(x, y):\n \n     # Returns\n         A bool tensor.\n+\n+    {{np_implementation}}\n     \"\"\"\n     return tf.equal(x, y)\n \n@@ -1698,6 +1704,8 @@ def not_equal(x, y):\n \n     # Returns\n         A bool tensor.\n+\n+    {{np_implementation}}\n     \"\"\"\n     return tf.not_equal(x, y)\n \n@@ -1711,6 +1719,8 @@ def greater(x, y):\n \n     # Returns\n         A bool tensor.\n+\n+    {{np_implementation}}\n     \"\"\"\n     return tf.greater(x, y)\n \n@@ -1724,6 +1734,8 @@ def greater_equal(x, y):\n \n     # Returns\n         A bool tensor.\n+\n+    {{np_implementation}}\n     \"\"\"\n     return tf.greater_equal(x, y)\n \n@@ -1737,6 +1749,8 @@ def less(x, y):\n \n     # Returns\n         A bool tensor.\n+\n+    {{np_implementation}}\n     \"\"\"\n     return tf.less(x, y)\n \n@@ -1750,6 +1764,8 @@ def less_equal(x, y):\n \n     # Returns\n         A bool tensor.\n+\n+    {{np_implementation}}\n     \"\"\"\n     return tf.less_equal(x, y)\n \n@@ -1763,6 +1779,8 @@ def maximum(x, y):\n \n     # Returns\n         A tensor.\n+\n+    {{np_implementation}}\n     \"\"\"\n     return tf.maximum(x, y)\n \n@@ -1776,6 +1794,8 @@ def minimum(x, y):\n \n     # Returns\n         A tensor.\n+\n+    {{np_implementation}}\n     \"\"\"\n     return tf.minimum(x, y)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#351e7a992d8f948e373e321252a35824da77ac35", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 1 | Churn Cumulative: 8591 | Contributors (this commit): 93 | Commits (past 90d): 5 | Contributors (cumulative): 93 | DMM Complexity: 0.0\n\nDIFF:\n@@ -801,6 +801,7 @@ class Model(Network):\n                     feed_sample_weight_modes)\n             ]\n             # Check that all arrays have the same length.\n+            if check_array_lengths:\n                 check_array_length_consistency(x, y, sample_weights)\n             if self._is_graph_network:\n                 # Additional checks to avoid users mistakenly\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#622540176d0943fcc3e361153ddac2ae08eb7e70", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 30 | Lines Deleted: 21 | Files Changed: 1 | Hunks: 2 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 51 | Churn Cumulative: 6026 | Contributors (this commit): 33 | Commits (past 90d): 49 | Contributors (cumulative): 33 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1419,28 +1419,37 @@ class TestBackend(object):\n         with pytest.raises(ValueError):\n             K.bias_add(x, b, data_format='channels_middle')\n \n-    def test_batchnorm(self):\n-        shape = (2, 3)\n-        for data_format in ['channels_first', 'channels_last']:\n-            if data_format == 'channels_first':\n-                x_shape = (1, 4) + shape\n-            else:\n-                x_shape = (1,) + shape + (4,)\n+    @pytest.mark.skipif(K.backend() != 'theano',\n+                        reason='Specific to Theano.')\n+    @pytest.mark.parametrize('x_shape', [(1, 4, 2, 3), (1, 2, 3, 4)])\n+    def test_batchnorm_th(self, x_shape):\n         x_val = np.random.random(x_shape).astype(np.float32)\n-            xth = KTH.variable(x_val)\n-            xtf = KTF.variable(x_val)\n-            xc = KC.placeholder(x_shape)\n-            zth, _, _ = KTH.normalize_batch_in_training(\n-                xth, None, None, reduction_axes='per-activation')\n-            ztf, _, _ = KTF.normalize_batch_in_training(\n-                xtf, None, None, reduction_axes=[0, 1, 2, 3])\n-            zc, _, _ = KC.normalize_batch_in_training(\n-                xc, None, None, reduction_axes=[0, 1, 2, 3])\n-            zth = KTH.eval(zth)\n-            ztf = KTF.eval(ztf)\n-            zc = KC.function([xc], [zc])([x_val])[0]\n-            assert zth.shape == ztf.shape\n-            assert zth.shape == zc.shape\n+        x = K.variable(x_val)\n+        z, _, _ = K.normalize_batch_in_training(\n+            x, None, None, reduction_axes='per-activation')\n+        z = K.eval(z)\n+        assert z.shape == x_shape\n+\n+    @pytest.mark.skipif(K.backend() != 'tensorflow',\n+                        reason='Specific to Tensorflow.')\n+    @pytest.mark.parametrize('x_shape', [(1, 4, 2, 3), (1, 2, 3, 4)])\n+    def test_batchnorm_tf(self, x_shape):\n+        x_val = np.random.random(x_shape).astype(np.float32)\n+        x = K.variable(x_val)\n+        z, _, _ = K.normalize_batch_in_training(\n+            x, None, None, reduction_axes=[0, 1, 2, 3])\n+        z = K.eval(z)\n+        assert z.shape == x_shape\n+\n+    @pytest.mark.skipif(K.backend() != 'cntk', reason='Specific to CNTK.')\n+    @pytest.mark.parametrize('x_shape', [(1, 4, 2, 3), (1, 2, 3, 4)])\n+    def test_batchnorm_cntk(self, x_shape):\n+        x_val = np.random.random(x_shape).astype(np.float32)\n+        x = K.placeholder(x_shape)\n+        z, _, _ = K.normalize_batch_in_training(\n+            x, None, None, reduction_axes=[0, 1, 2, 3])\n+        z = K.function([x], [z])([x_val])[0]\n+        assert z.shape == x_shape\n \n     # the Theano and TensorFlow CTC code use different methods to ensure\n     # numerical stability.  The Theano code subtracts out the max\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#140605ee0f08b7996d69a61610782f48766776ad", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 14 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 26 | Churn Cumulative: 534 | Contributors (this commit): 10 | Commits (past 90d): 6 | Contributors (cumulative): 10 | DMM Complexity: 1.0\n\nDIFF:\n@@ -73,13 +73,24 @@ def layer_test(layer_cls, kwargs={}, input_shape=None, input_dtype=None,\n \n     expected_output_shape = layer.compute_output_shape(input_shape)\n \n-    def _layer_in_model_test(model):\n+    # test in functional API\n+    if fixed_batch_size:\n+        x = Input(batch_shape=input_shape, dtype=input_dtype)\n+    else:\n+        x = Input(shape=input_shape[1:], dtype=input_dtype)\n+    y = layer(x)\n+    assert K.dtype(y) == expected_output_dtype\n+\n+    # check with the functional API\n+    model = Model(x, y)\n+\n     actual_output = model.predict(input_data)\n     actual_output_shape = actual_output.shape\n     for expected_dim, actual_dim in zip(expected_output_shape,\n                                         actual_output_shape):\n         if expected_dim is not None:\n             assert expected_dim == actual_dim\n+\n     if expected_output is not None:\n         assert_allclose(actual_output, expected_output, rtol=1e-3)\n \n@@ -97,19 +108,6 @@ def layer_test(layer_cls, kwargs={}, input_shape=None, input_dtype=None,\n     if has_arg(layer.call, 'training'):\n         model.compile('rmsprop', 'mse')\n         model.train_on_batch(input_data, actual_output)\n-        return actual_output\n-\n-    # test in functional API\n-    if fixed_batch_size:\n-        x = Input(batch_shape=input_shape, dtype=input_dtype)\n-    else:\n-        x = Input(shape=input_shape[1:], dtype=input_dtype)\n-    y = layer(x)\n-    assert K.dtype(y) == expected_output_dtype\n-\n-    # check with the functional API\n-    model = Model(x, y)\n-    actual_output = _layer_in_model_test(model)\n \n     # test instantiation from layer config\n     layer_config = layer.get_config()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5a8f346e64cb432a445002230246ee042dbc278b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 321 | Lines Deleted: 59 | Files Changed: 6 | Hunks: 33 | Methods Changed: 24 | Complexity Δ (Sum/Max): 35/14 | Churn Δ: 380 | Churn Cumulative: 28389 | Contributors (this commit): 164 | Commits (past 90d): 102 | Contributors (cumulative): 300 | DMM Complexity: 0.7164179104477612\n\nDIFF:\n@@ -1490,6 +1490,12 @@ def rnn(step_function, inputs, initial_states,\n         go_backwards=False, mask=None, constants=None,\n         unroll=False, input_length=None):\n \n+    if not unroll and mask is not None:\n+        warnings.warn(\n+            'CNTK Backend only supports accurate masking if '\n+            '`output == new_states[0]` for '\n+            '`output, new_states = step_function(inputs, states)`')\n+\n     shape = int_shape(inputs)\n     dims = len(shape)\n \n\n@@ -2930,7 +2930,7 @@ def rnn(step_function, inputs, initial_states,\n         ValueError: If `mask` is provided (not `None`)\n             but states is not provided (`len(states)` == 0).\n     \"\"\"\n-    ndim = len(inputs.get_shape())\n+    ndim = len(inputs.shape)\n     if ndim < 3:\n         raise ValueError('Input should be at least 3D.')\n \n@@ -2942,9 +2942,22 @@ def rnn(step_function, inputs, initial_states,\n     if mask is not None:\n         if mask.dtype != tf.bool:\n             mask = tf.cast(mask, tf.bool)\n-        if len(mask.get_shape()) == ndim - 1:\n-            mask = expand_dims(mask)\n-        mask = tf.transpose(mask, axes)\n+        if len(mask.shape) != 2:\n+            raise ValueError(\n+                'mask should have `shape=(samples, time)`, '\n+                'got {}'.format(mask.shape))\n+        mask = tf.transpose(mask, [1, 0])\n+\n+        def get_matching_mask(mask_t, ref_tensor_t):\n+            # tf.where needs its condition tensor\n+            # to be the same shape as its two\n+            # result tensors\n+            ndim = len(ref_tensor_t.shape)\n+            for _ in range(ndim - 1):\n+                mask_t = expand_dims(mask_t)\n+            add_shape = tf.shape(ref_tensor_t)[1:]\n+            multiple = tf.concat([[1], add_shape], 0)\n+            return tf.tile(mask_t, multiple)\n \n     if constants is None:\n         constants = []\n@@ -2953,7 +2966,7 @@ def rnn(step_function, inputs, initial_states,\n     uses_learning_phase = False\n \n     if unroll:\n-        if not inputs.get_shape()[0]:\n+        if not inputs.shape[0]:\n             raise ValueError('Unrolling requires a '\n                              'fixed number of timesteps.')\n         states = initial_states\n@@ -2974,32 +2987,18 @@ def rnn(step_function, inputs, initial_states,\n                 if getattr(output, '_uses_learning_phase', False):\n                     uses_learning_phase = True\n \n-                # tf.where needs its condition tensor\n-                # to be the same shape as its two\n-                # result tensors, but in our case\n-                # the condition (mask) tensor is\n-                # (nsamples, 1), and A and B are (nsamples, ndimensions).\n-                # So we need to\n-                # broadcast the mask to match the shape of A and B.\n-                # That's what the tile call does,\n-                # it just repeats the mask along its second dimension\n-                # n times.\n-                tiled_mask_t = tf.tile(mask_t,\n-                                       tf.stack([1, tf.shape(output)[1]]))\n-\n                 if not successive_outputs:\n                     prev_output = zeros_like(output)\n                 else:\n                     prev_output = successive_outputs[-1]\n \n-                output = tf.where(tiled_mask_t, output, prev_output)\n+                output_mask_t = get_matching_mask(mask_t, output)\n+                output = tf.where(output_mask_t, output, prev_output)\n \n                 return_states = []\n                 for state, new_state in zip(states, new_states):\n-                    # (see earlier comment for tile explanation)\n-                    tiled_mask_t = tf.tile(mask_t,\n-                                           tf.stack([1, tf.shape(new_state)[1]]))\n-                    return_states.append(tf.where(tiled_mask_t,\n+                    state_mask_t = get_matching_mask(mask_t, new_state)\n+                    return_states.append(tf.where(state_mask_t,\n                                                   new_state,\n                                                   state))\n                 states = return_states\n@@ -3026,26 +3025,29 @@ def rnn(step_function, inputs, initial_states,\n         states = tuple(initial_states)\n \n         time_steps = tf.shape(inputs)[0]\n-        outputs, _ = step_function(inputs[0], initial_states + constants)\n+        output, _ = step_function(inputs[0], initial_states + constants)\n         output_ta = tensor_array_ops.TensorArray(\n-            dtype=outputs.dtype,\n+            dtype=output.dtype,\n             size=time_steps,\n             tensor_array_name='output_ta')\n+        initial_output = zeros_like(output)\n         input_ta = tensor_array_ops.TensorArray(\n             dtype=inputs.dtype,\n             size=time_steps,\n             tensor_array_name='input_ta')\n         input_ta = input_ta.unstack(inputs)\n         time = tf.constant(0, dtype='int32', name='time')\n+        while_loop_kwargs = {\n+            'cond': lambda time, *_: time < time_steps,\n+            'parallel_iterations': 32,\n+            'swap_memory': True,\n+            'maximum_iterations': input_length}\n \n         if mask is not None:\n             if not states:\n                 raise ValueError('No initial states provided! '\n                                  'When using masking in an RNN, you should '\n-                                 'provide initial states '\n-                                 '(and your step function should return '\n-                                 'as its first state at time `t` '\n-                                 'the output at time `t-1`).')\n+                                 'provide initial states')\n             if go_backwards:\n                 mask = reverse(mask, 0)\n \n@@ -3055,12 +3057,13 @@ def rnn(step_function, inputs, initial_states,\n                 tensor_array_name='mask_ta')\n             mask_ta = mask_ta.unstack(mask)\n \n-            def _step(time, output_ta_t, *states):\n+            def _step(time, output_ta_t, output_tm1, *states):\n                 \"\"\"RNN step function.\n \n                 # Arguments\n                     time: Current timestep value.\n                     output_ta_t: TensorArray.\n+                    output_tm1: output Tensor from previous timestep\n                     *states: List of states.\n \n                 # Returns\n@@ -3075,18 +3078,23 @@ def rnn(step_function, inputs, initial_states,\n                     global uses_learning_phase\n                     uses_learning_phase = True\n                 for state, new_state in zip(states, new_states):\n-                    new_state.set_shape(state.get_shape())\n-                tiled_mask_t = tf.tile(mask_t,\n-                                       tf.stack([1, tf.shape(output)[1]]))\n-                output = tf.where(tiled_mask_t, output, states[0])\n-                tmp = []\n-                for i in range(len(states)):\n-                    multiples = tf.stack([1, tf.shape(new_states[i])[1]])\n-                    tiled = tf.tile(mask_t, multiples)\n-                    tmp.append(tf.where(tiled, new_states[i], states[i]))\n-                new_states = tmp\n+                    new_state.set_shape(state.shape)\n+\n+                output_mask_t = get_matching_mask(mask_t, output)\n+                output = tf.where(output_mask_t, output, output_tm1)\n+\n+                new_states = [tf.where(get_matching_mask(mask_t, new_states[i]),\n+                                       new_states[i],\n+                                       states[i]) for i in range(len(states))]\n+\n                 output_ta_t = output_ta_t.write(time, output)\n-                return (time + 1, output_ta_t) + tuple(new_states)\n+                return (time + 1, output_ta_t, output) + tuple(new_states)\n+\n+            final_outputs = control_flow_ops.while_loop(\n+                body=_step,\n+                loop_vars=(time, output_ta, initial_output) + states,\n+                **while_loop_kwargs)\n+            new_states = final_outputs[3:]  # skip output_tm1\n         else:\n             def _step(time, output_ta_t, *states):\n                 \"\"\"RNN step function.\n@@ -3107,25 +3115,22 @@ def rnn(step_function, inputs, initial_states,\n                     global uses_learning_phase\n                     uses_learning_phase = True\n                 for state, new_state in zip(states, new_states):\n-                    new_state.set_shape(state.get_shape())\n+                    new_state.set_shape(state.shape)\n                 output_ta_t = output_ta_t.write(time, output)\n                 return (time + 1, output_ta_t) + tuple(new_states)\n \n             final_outputs = control_flow_ops.while_loop(\n-            cond=lambda time, *_: time < time_steps,\n                 body=_step,\n                 loop_vars=(time, output_ta) + states,\n-            parallel_iterations=32,\n-            swap_memory=True,\n-            maximum_iterations=input_length)\n-        last_time = final_outputs[0]\n-        output_ta = final_outputs[1]\n+                **while_loop_kwargs)\n             new_states = final_outputs[2:]\n \n+        last_time = final_outputs[0]\n+        output_ta = final_outputs[1]\n         outputs = output_ta.stack()\n         last_output = output_ta.read(last_time - 1)\n \n-    axes = [1, 0] + list(range(2, len(outputs.get_shape())))\n+    axes = [1, 0] + list(range(2, len(outputs.shape)))\n     outputs = tf.transpose(outputs, axes)\n     last_output._uses_learning_phase = uses_learning_phase\n     return last_output, outputs, new_states\n\n@@ -1503,10 +1503,22 @@ def rnn(step_function, inputs, initial_states,\n     uses_learning_phase = False\n \n     if mask is not None:\n-        if mask.ndim == ndim - 1:\n-            mask = expand_dims(mask)\n-        assert mask.ndim == ndim\n-        mask = mask.dimshuffle(axes)\n+        if mask.ndim != 2:\n+            raise ValueError(\n+                'mask should have `shape=(samples, time)`, '\n+                'got {}'.format(mask.shape))\n+        mask = mask.dimshuffle([1, 0])\n+\n+        def get_matching_mask(mask_t, ref_tensor_t):\n+            # tf.where needs its condition tensor\n+            # to be the same shape as its two\n+            # result tensors\n+            ndim = ref_tensor_t.ndim\n+            for _ in range(ndim - 1):\n+                mask_t = expand_dims(mask_t)\n+            add_shape = ref_tensor_t.shape[1:]\n+            reps = T.concatenate([[1], add_shape], 0)\n+            return T.tile(mask_t, reps, ndim=ndim)\n \n         if unroll:\n             indices = list(range(input_length))\n@@ -1526,10 +1538,12 @@ def rnn(step_function, inputs, initial_states,\n                 else:\n                     prev_output = successive_outputs[-1]\n \n-                output = T.switch(mask[i], output, prev_output)\n+                output_mask = get_matching_mask(mask[i], output)\n+                output = T.switch(output_mask, output, prev_output)\n                 kept_states = []\n                 for state, new_state in zip(states, new_states):\n-                    kept_states.append(T.switch(mask[i], new_state, state))\n+                    state_mask = get_matching_mask(mask[i], state)\n+                    kept_states.append(T.switch(state_mask, new_state, state))\n                 states = kept_states\n \n                 successive_outputs.append(output)\n@@ -1557,10 +1571,12 @@ def rnn(step_function, inputs, initial_states,\n                     global uses_learning_phase\n                     uses_learning_phase = True\n                 # output previous output if masked.\n-                outputs = T.switch(mask, outputs, output_tm1)\n+                output_mask = get_matching_mask(mask, outputs)\n+                outputs = T.switch(output_mask, outputs, output_tm1)\n                 return_states = []\n                 for state, new_state in zip(states, new_states):\n-                    return_states.append(T.switch(mask, new_state, state))\n+                    state_mask = get_matching_mask(mask, state)\n+                    return_states.append(T.switch(state_mask, new_state, state))\n                 return [outputs] + return_states\n \n             results, _ = theano.scan(\n\n@@ -826,6 +826,119 @@ class TestBackend(object):\n         assert_allclose(last_y1, last_y2, atol=1e-05)\n         assert_allclose(y1, y2, atol=1e-05)\n \n+    def test_rnn_output_and_state_masking_independent(self):\n+        num_samples = 2\n+        num_timesteps = 4\n+        state_and_io_size = 5\n+        mask_last_num_timesteps = 2  # for second sample only\n+\n+        # a step function that just outputs inputs,\n+        # but increments states +1 per timestep\n+        def step_function(inputs, states):\n+            return inputs, [s + 1 for s in states]\n+\n+        inputs_vals = np.random.random(\n+            (num_samples, num_timesteps, state_and_io_size))\n+        initial_state_vals = np.random.random((num_samples, state_and_io_size))\n+        # masking of two last timesteps for second sample only\n+        mask_vals = np.ones((num_samples, num_timesteps))\n+        mask_vals[1, -mask_last_num_timesteps:] = 0\n+\n+        # outputs expected to be same as inputs for the first sample\n+        expected_outputs = inputs_vals.copy()\n+        # but for the second sample all outputs in masked region should be the same\n+        # as last output before masked region\n+        expected_outputs[1, -mask_last_num_timesteps:] = \\\n+            expected_outputs[1, -(mask_last_num_timesteps + 1)]\n+\n+        expected_state = initial_state_vals.copy()\n+        # first state should be incremented for every timestep (no masking)\n+        expected_state[0] += num_timesteps\n+        # second state should not be incremented for last two timesteps\n+        expected_state[1] += (num_timesteps - mask_last_num_timesteps)\n+\n+        # verify same expected output for `unroll=true/false`\n+        inputs = K.variable(inputs_vals)\n+        initial_states = [K.variable(initial_state_vals)]\n+        mask = K.variable(mask_vals)\n+        for unroll in [True, False]:\n+            last_output, outputs, last_states = K.rnn(\n+                step_function,\n+                inputs,\n+                initial_states,\n+                mask=mask,\n+                unroll=unroll,\n+                input_length=num_timesteps if unroll else None)\n+\n+            assert_allclose(K.eval(outputs), expected_outputs)\n+            assert_allclose(K.eval(last_states[0]), expected_state)\n+\n+    @pytest.mark.skipif(K.backend() == 'cntk', reason='Not supported')\n+    def test_rnn_output_num_dim_larger_than_2_masking(self):\n+        num_samples = 3\n+        num_timesteps = 4\n+        num_features = 5\n+\n+        def step_function(inputs, states):\n+            outputs = K.tile(K.expand_dims(inputs), [1, 1, 2])\n+            return outputs, states\n+\n+        inputs_vals = np.random.random((num_samples, num_timesteps, num_features))\n+        initial_state_vals = np.random.random((num_samples, 6))\n+        mask_vals = np.ones((num_samples, num_timesteps))\n+        mask_vals[-1, -1] = 0  # final timestep masked for last sample\n+\n+        expected_outputs = np.repeat(inputs_vals[..., None], repeats=2, axis=-1)\n+        # for the last sample, the final timestep (in masked region) should be the\n+        # same as the second to final output (before masked region)\n+        expected_outputs[-1, -1] = expected_outputs[-1, -2]\n+\n+        inputs = K.variable(inputs_vals)\n+        initial_states = [K.variable(initial_state_vals)]\n+        mask = K.variable(mask_vals)\n+        for unroll in [True, False]:\n+            last_output, outputs, last_states = K.rnn(\n+                step_function,\n+                inputs,\n+                initial_states,\n+                mask=mask,\n+                unroll=unroll,\n+                input_length=num_timesteps if unroll else None)\n+\n+            assert_allclose(K.eval(outputs), expected_outputs)\n+\n+    @pytest.mark.skipif(K.backend() == 'cntk', reason='Not supported')\n+    def test_rnn_state_num_dim_larger_than_2_masking(self):\n+        num_samples = 3\n+        num_timesteps = 4\n+\n+        def step_function(inputs, states):\n+            return inputs, [s + 1 for s in states]\n+\n+        inputs_vals = np.random.random((num_samples, num_timesteps, 5))\n+        initial_state_vals = np.random.random((num_samples, 6, 7))\n+        mask_vals = np.ones((num_samples, num_timesteps))\n+        mask_vals[0, -2:] = 0  # final two timesteps masked for first sample\n+\n+        expected_last_state = initial_state_vals.copy()\n+        expected_last_state[0] += (num_timesteps - 2)\n+        expected_last_state[1:] += num_timesteps\n+\n+        inputs = K.variable(inputs_vals)\n+        initial_states = [K.variable(initial_state_vals)]\n+        mask = K.variable(mask_vals)\n+        for unroll in [True, False]:\n+            last_output, outputs, last_states = K.rnn(\n+                step_function,\n+                inputs,\n+                initial_states,\n+                mask=mask,\n+                unroll=unroll,\n+                input_length=num_timesteps if unroll else None)\n+\n+            # not updated last timestep:\n+            assert_allclose(K.eval(last_states[0]), expected_last_state)\n+\n     @pytest.mark.parametrize('x_np,axis,keepdims', [\n         (np.array([1.1, 0.8, 0.9]), 0, False),\n         (np.array([[1.1, 0.8, 0.9]]), 0, False),\n\n@@ -4,7 +4,7 @@ from numpy.testing import assert_allclose\n \n from keras import backend as K\n from keras.models import Sequential, Model\n-from keras.layers import convolutional_recurrent, Input\n+from keras.layers import convolutional_recurrent, Input, Masking, Lambda\n from keras.utils.test_utils import layer_test\n from keras import regularizers\n \n@@ -20,6 +20,11 @@ sequence_len = 2\n \n def test_convolutional_recurrent():\n \n+    class Masking5D(Masking):\n+        \"\"\"Regular masking layer returns wrong shape of mask for RNN\"\"\"\n+        def compute_mask(self, inputs, mask=None):\n+            return K.any(K.not_equal(inputs, 0.), axis=[2, 3, 4])\n+\n     for data_format in ['channels_first', 'channels_last']:\n \n         if data_format == 'channels_first':\n@@ -31,8 +36,8 @@ def test_convolutional_recurrent():\n                                     input_num_row, input_num_col,\n                                     input_channel)\n \n+        for use_mask in [False, True]:\n             for return_sequences in [True, False]:\n-\n                 # test for return state:\n                 x = Input(batch_shape=inputs.shape)\n                 kwargs = {'data_format': data_format,\n@@ -44,6 +49,9 @@ def test_convolutional_recurrent():\n                           'padding': 'valid'}\n                 layer = convolutional_recurrent.ConvLSTM2D(**kwargs)\n                 layer.build(inputs.shape)\n+                if use_mask:\n+                    outputs = layer(Masking5D()(x))\n+                else:\n                     outputs = layer(x)\n                 output, states = outputs[0], outputs[1:]\n                 assert len(states) == 2\n\n@@ -165,6 +165,120 @@ def test_masking_correctness(layer_class):\n     assert_allclose(out7, out6, atol=1e-5)\n \n \n+@pytest.mark.skipif(K.backend() == 'cntk', reason='Not supported.')\n+def test_masking_correctness_output_not_equal_to_first_state():\n+\n+    class Cell(keras.layers.Layer):\n+\n+        def __init__(self):\n+            self.state_size = None\n+            self.output_size = None\n+            super(Cell, self).__init__()\n+\n+        def build(self, input_shape):\n+            self.state_size = input_shape[-1]\n+            self.output_size = input_shape[-1]\n+\n+        def call(self, inputs, states):\n+            return inputs, [s + 1 for s in states]\n+\n+    num_samples = 5\n+    num_timesteps = 4\n+    state_size = input_size = 3  # also equal to `output_size`\n+\n+    # random inputs and state values\n+    x_vals = np.random.random((num_samples, num_timesteps, input_size))\n+    # last timestep masked for first sample (all zero inputs masked by Masking layer)\n+    x_vals[0, -1, :] = 0\n+    s_initial_vals = np.random.random((num_samples, state_size))\n+\n+    # final outputs equal to last inputs\n+    y_vals_expected = x_vals[:, -1].copy()\n+    # except for first sample, where it is equal to second to last value due to mask\n+    y_vals_expected[0] = x_vals[0, -2]\n+\n+    s_final_vals_expected = s_initial_vals.copy()\n+    # states are incremented `num_timesteps - 1` times for first sample\n+    s_final_vals_expected[0] += (num_timesteps - 1)\n+    # and `num_timesteps - 1` times for remaining samples\n+    s_final_vals_expected[1:] += num_timesteps\n+\n+    for unroll in [True, False]:\n+        x = Input((num_timesteps, input_size), name=\"x\")\n+        x_masked = Masking()(x)\n+        s_initial = Input((state_size,), name=\"s_initial\")\n+        y, s_final = recurrent.RNN(Cell(),\n+                                   return_state=True,\n+                                   unroll=unroll)(x_masked, initial_state=s_initial)\n+        model = Model([x, s_initial], [y, s_final])\n+        model.compile(optimizer='sgd', loss='mse')\n+\n+        y_vals, s_final_vals = model.predict([x_vals, s_initial_vals])\n+        assert_allclose(y_vals,\n+                        y_vals_expected,\n+                        err_msg=\"Unexpected output for unroll={}\".format(unroll))\n+        assert_allclose(s_final_vals,\n+                        s_final_vals_expected,\n+                        err_msg=\"Unexpected state for unroll={}\".format(unroll))\n+\n+\n+@pytest.mark.skipif(K.backend() == 'cntk', reason='Not supported.')\n+def test_masking_correctness_output_size_not_equal_to_first_state_size():\n+\n+    class Cell(keras.layers.Layer):\n+\n+        def __init__(self):\n+            self.state_size = None\n+            self.output_size = None\n+            super(Cell, self).__init__()\n+\n+        def build(self, input_shape):\n+            self.state_size = input_shape[-1]\n+            self.output_size = input_shape[-1] * 2\n+\n+        def call(self, inputs, states):\n+            return keras.layers.concatenate([inputs] * 2), [s + 1 for s in states]\n+\n+    num_samples = 5\n+    num_timesteps = 6\n+    input_size = state_size = 7\n+\n+    # random inputs and state values\n+    x_vals = np.random.random((num_samples, num_timesteps, input_size))\n+    # last timestep masked for first sample (all zero inputs masked by Masking layer)\n+    x_vals[0, -1, :] = 0\n+    s_initial_vals = np.random.random((num_samples, state_size))\n+\n+    # final outputs equal to last inputs concatenated\n+    y_vals_expected = np.concatenate([x_vals[:, -1]] * 2, axis=-1)\n+    # except for first sample, where it is equal to second to last value due to mask\n+    y_vals_expected[0] = np.concatenate([x_vals[0, -2]] * 2, axis=-1)\n+\n+    s_final_vals_expected = s_initial_vals.copy()\n+    # states are incremented `num_timesteps - 1` times for first sample\n+    s_final_vals_expected[0] += (num_timesteps - 1)\n+    # and `num_timesteps - 1` times for remaining samples\n+    s_final_vals_expected[1:] += num_timesteps\n+\n+    for unroll in [True, False]:\n+        x = Input((num_timesteps, input_size), name=\"x\")\n+        x_masked = Masking()(x)\n+        s_initial = Input((state_size,), name=\"s_initial\")\n+        y, s_final = recurrent.RNN(Cell(),\n+                                   return_state=True,\n+                                   unroll=unroll)(x_masked, initial_state=s_initial)\n+        model = Model([x, s_initial], [y, s_final])\n+        model.compile(optimizer='sgd', loss='mse')\n+\n+        y_vals, s_final_vals = model.predict([x_vals, s_initial_vals])\n+        assert_allclose(y_vals,\n+                        y_vals_expected,\n+                        err_msg=\"Unexpected output for unroll={}\".format(unroll))\n+        assert_allclose(s_final_vals,\n+                        s_final_vals_expected,\n+                        err_msg=\"Unexpected state for unroll={}\".format(unroll))\n+\n+\n @rnn_test\n def test_implementation_mode(layer_class):\n     for mode in [1, 2]:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
