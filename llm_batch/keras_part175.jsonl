{"custom_id": "keras#214a54d40e50681f8088ca2255a05b9dee89e685", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 70 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 5/4 | Churn Δ: 70 | Churn Cumulative: 11087 | Contributors (this commit): 39 | Commits (past 90d): 85 | Contributors (cumulative): 47 | DMM Complexity: 1.0\n\nDIFF:\n@@ -671,6 +671,7 @@ class Conv2DTranspose(Conv2D):\n         - [Deconvolutional Networks](http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf)\n     \"\"\"\n \n+    @interfaces.legacy_deconv2d_support\n     def __init__(self, filters,\n                  kernel_size,\n                  strides=(1, 1),\n\n@@ -283,6 +283,32 @@ legacy_separable_conv2d_support = generate_legacy_interface(\n     preprocessor=separable_conv2d_args_preprocessor)\n \n \n+def deconv2d_args_preprocessor(args, kwargs):\n+    if len(args) == 5:\n+        if isinstance(args[4], tuple):\n+            args = args[:-1]\n+    if 'output_shape' in kwargs:\n+        kwargs.pop('output_shape')\n+    return conv2d_args_preprocessor(args, kwargs)\n+\n+legacy_deconv2d_support = generate_legacy_interface(\n+    allowed_positional_args=['filters', 'kernel_size'],\n+    conversions=[('nb_filter', 'filters'),\n+                 ('subsample', 'strides'),\n+                 ('border_mode', 'padding'),\n+                 ('dim_ordering', 'data_format'),\n+                 ('init', 'kernel_initializer'),\n+                 ('W_regularizer', 'kernel_regularizer'),\n+                 ('b_regularizer', 'bias_regularizer'),\n+                 ('W_constraint', 'kernel_constraint'),\n+                 ('b_constraint', 'bias_constraint'),\n+                 ('bias', 'use_bias')],\n+    value_conversions={'dim_ordering': {'tf': 'channels_last',\n+                                        'th': 'channels_first',\n+                                        'default': None}},\n+    preprocessor=deconv2d_args_preprocessor)\n+\n+\n def conv3d_args_preprocessor(args, kwargs):\n     if len(args) > 5:\n         raise TypeError('Layer can receive at most 4 positional arguments.')\n\n@@ -430,6 +430,49 @@ def test_conv2d_legacy_interface():\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n \n \n+@keras_test\n+def test_deconv2d_legacy_interface():\n+    old_layer = keras.layers.Deconvolution2D(5, 3, 3, (6, 7, 5), name='deconv')\n+    new_layer = keras.layers.Conv2DTranspose(5, (3, 3), name='deconv')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.Deconvolution2D(5, 3, 3, output_shape=(6, 7, 5), name='deconv')\n+    new_layer = keras.layers.Conv2DTranspose(5, (3, 3), name='deconv')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.Deconvolution2D(5, 3, nb_col=3, output_shape=(6, 7, 5), name='deconv')\n+    new_layer = keras.layers.Conv2DTranspose(5, (3, 3), name='deconv')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.Deconvolution2D(5, nb_row=3, nb_col=3, output_shape=(6, 7, 5), name='deconv')\n+    new_layer = keras.layers.Conv2DTranspose(5, (3, 3), name='deconv')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.Deconvolution2D(5, 3, 3,\n+                                             output_shape=(6, 7, 5),\n+                                             init='normal',\n+                                             subsample=(2, 2),\n+                                             border_mode='valid',\n+                                             dim_ordering='th',\n+                                             W_regularizer='l1',\n+                                             b_regularizer='l2',\n+                                             W_constraint='maxnorm',\n+                                             b_constraint='unitnorm',\n+                                             name='conv')\n+    new_layer = keras.layers.Conv2DTranspose(\n+        5, (3, 3),\n+        kernel_initializer='normal',\n+        strides=(2, 2),\n+        padding='valid',\n+        kernel_regularizer='l1',\n+        bias_regularizer='l2',\n+        kernel_constraint='max_norm',\n+        bias_constraint='unit_norm',\n+        data_format='channels_first',\n+        name='conv')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+\n @keras_test\n def test_conv1d_legacy_interface():\n     old_layer = keras.layers.Convolution1D(5,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#21bf90cbf561250b256d7b30c7545da3bf092552", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1002 | Contributors (this commit): 5 | Commits (past 90d): 17 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -335,7 +335,7 @@ class ConvLSTM2D(ConvRecurrent2D):\n             self.reset_states()\n         else:\n             # initial states: 2 all-zero tensor of shape (filters)\n-            self.states = [None, None, None, None]\n+            self.states = [None, None]\n \n         if self.data_format == 'channels_first':\n             channel_axis = 1\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a783ceae2a970007668735419210fc67eb748db6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 136 | Lines Deleted: 4 | Files Changed: 6 | Hunks: 15 | Methods Changed: 6 | Complexity Δ (Sum/Max): 9/7 | Churn Δ: 140 | Churn Cumulative: 14685 | Contributors (this commit): 54 | Commits (past 90d): 135 | Contributors (cumulative): 75 | DMM Complexity: 1.0\n\nDIFF:\n@@ -19,8 +19,6 @@ from .pooling import MaxPooling1D\n from .pooling import MaxPooling2D\n from .pooling import MaxPooling3D\n \n-from ..legacy import interfaces\n-\n \n class _Conv(Layer):\n     \"\"\"Abstract nD convolution layer (private, used as implementation base).\n\n@@ -11,6 +11,7 @@ from .recurrent import Recurrent\n import numpy as np\n from ..engine import InputSpec\n from ..utils import conv_utils\n+from ..legacy import interfaces\n \n \n class ConvRecurrent2D(Recurrent):\n@@ -270,6 +271,7 @@ class ConvLSTM2D(ConvRecurrent2D):\n         cells output\n     \"\"\"\n \n+    @interfaces.legacy_convlstm2d_support\n     def __init__(self, filters,\n                  kernel_size,\n                  strides=(1, 1),\n\n@@ -9,6 +9,7 @@ from .. import constraints\n from ..engine import Layer\n from ..engine import InputSpec\n from ..utils import conv_utils\n+from ..legacy import interfaces\n \n \n class LocallyConnected1D(Layer):\n@@ -71,6 +72,7 @@ class LocallyConnected1D(Layer):\n         `steps` value might have changed due to padding or strides.\n     \"\"\"\n \n+    @interfaces.legacy_conv1d_support\n     def __init__(self, filters,\n                  kernel_size,\n                  strides=1,\n@@ -266,6 +268,7 @@ class LocallyConnected2D(Layer):\n         `rows` and `cols` values might have changed due to padding.\n     \"\"\"\n \n+    @interfaces.legacy_conv2d_support\n     def __init__(self, filters,\n                  kernel_size,\n                  strides=(1, 1),\n\n@@ -6,6 +6,7 @@ from .. import initializers\n from .. import regularizers\n from .. import constraints\n from .. import backend as K\n+from ..legacy import interfaces\n \n \n class BatchNormalization(Layer):\n@@ -51,6 +52,7 @@ class BatchNormalization(Layer):\n         - [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167)\n     \"\"\"\n \n+    @interfaces.legacy_batchnorm_support\n     def __init__(self,\n                  axis=-1,\n                  momentum=0.99,\n\n@@ -262,11 +262,14 @@ legacy_conv2d_support = generate_legacy_interface(\n \n \n def separable_conv2d_args_preprocessor(args, kwargs):\n+    converted = []\n     if 'init' in kwargs:\n         init = kwargs.pop('init')\n         kwargs['depthwise_initializer'] = init\n         kwargs['pointwise_initializer'] = init\n-    return conv2d_args_preprocessor(args, kwargs)\n+        converted.append(('init', 'depthwise_initializer/pointwise_initializer'))\n+    args, kwargs, _converted = conv2d_args_preprocessor(args, kwargs)\n+    return args, kwargs, converted + _converted\n \n legacy_separable_conv2d_support = generate_legacy_interface(\n     allowed_positional_args=['filters', 'kernel_size'],\n@@ -284,12 +287,16 @@ legacy_separable_conv2d_support = generate_legacy_interface(\n \n \n def deconv2d_args_preprocessor(args, kwargs):\n+    converted = []\n     if len(args) == 5:\n         if isinstance(args[4], tuple):\n             args = args[:-1]\n+            converted.append(('output_shape', None))\n     if 'output_shape' in kwargs:\n         kwargs.pop('output_shape')\n-    return conv2d_args_preprocessor(args, kwargs)\n+        converted.append(('output_shape', None))\n+    args, kwargs, _converted = conv2d_args_preprocessor(args, kwargs)\n+    return args, kwargs, converted + _converted\n \n legacy_deconv2d_support = generate_legacy_interface(\n     allowed_positional_args=['filters', 'kernel_size'],\n@@ -360,3 +367,62 @@ legacy_conv3d_support = generate_legacy_interface(\n                                         'th': 'channels_first',\n                                         'default': None}},\n     preprocessor=conv3d_args_preprocessor)\n+\n+\n+def batchnorm_args_preprocessor(args, kwargs):\n+    converted = []\n+    if len(args) > 1:\n+        raise TypeError('The `BatchNormalization` layer '\n+                        'does not accept positional arguments. '\n+                        'Use keyword arguments instead.')\n+    if 'mode' in kwargs:\n+        value = kwargs.pop('mode')\n+        if value != 0:\n+            raise TypeError('The `mode` argument of `BatchNormalization` '\n+                            'no longer exists. `mode=1` and `mode=2` '\n+                            'are no longer supported.')\n+        converted.append(('mode', None))\n+    return args, kwargs, converted\n+\n+\n+def convlstm2d_args_preprocessor(args, kwargs):\n+    converted = []\n+    if 'forget_bias_init' in kwargs:\n+        value = kwargs.pop('forget_bias_init')\n+        if value == 'one':\n+            kwargs['unit_forget_bias'] = True\n+            converted.append(('forget_bias_init', 'unit_forget_bias'))\n+        else:\n+            warnings.warn('The `forget_bias_init` argument '\n+                          'has been ignored. Use `unit_forget_bias=True` '\n+                          'instead to intialize with ones')\n+    args, kwargs, _converted = conv2d_args_preprocessor(args, kwargs)\n+    return args, kwargs, converted + _converted\n+\n+\n+legacy_convlstm2d_support = generate_legacy_interface(\n+    allowed_positional_args=['filters', 'kernel_size'],\n+    conversions=[('nb_filter', 'filters'),\n+                 ('subsample', 'strides'),\n+                 ('border_mode', 'padding'),\n+                 ('dim_ordering', 'data_format'),\n+                 ('init', 'kernel_initializer'),\n+                 ('inner_init', 'recurrent_initializer'),\n+                 ('W_regularizer', 'kernel_regularizer'),\n+                 ('U_regularizer', 'recurrent_regularizer'),\n+                 ('b_regularizer', 'bias_regularizer'),\n+                 ('inner_activation', 'recurrent_activation'),\n+                 ('dropout_W', 'dropout'),\n+                 ('dropout_U', 'recurrent_dropout'),\n+                 ('bias', 'use_bias')],\n+    value_conversions={'dim_ordering': {'tf': 'channels_last',\n+                                        'th': 'channels_first',\n+                                        'default': None}},\n+    preprocessor=convlstm2d_args_preprocessor)\n+\n+\n+legacy_batchnorm_support = generate_legacy_interface(\n+    allowed_positional_args=[],\n+    conversions=[('beta_init', 'beta_initializer'),\n+                 ('gamma_init', 'gamma_initializer')],\n+    preprocessor=batchnorm_args_preprocessor)\n\n@@ -592,5 +592,66 @@ def test_conv3d_legacy_interface():\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n \n \n+@keras_test\n+def test_convlstm2d_legacy_interface():\n+    old_layer = keras.layers.ConvLSTM2D(5, 3, 3, name='conv')\n+    new_layer = keras.layers.ConvLSTM2D(5, (3, 3), name='conv')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.ConvLSTM2D(5, 3, nb_col=3, name='conv')\n+    new_layer = keras.layers.ConvLSTM2D(5, (3, 3), name='conv')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.ConvLSTM2D(5, nb_row=3, nb_col=3, name='conv')\n+    new_layer = keras.layers.ConvLSTM2D(5, (3, 3), name='conv')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.ConvLSTM2D(5, 3, 3,\n+                                        init='normal',\n+                                        inner_init='uniform',\n+                                        forget_bias_init='one',\n+                                        inner_activation='relu',\n+                                        subsample=(2, 2),\n+                                        border_mode='valid',\n+                                        dim_ordering='th',\n+                                        W_regularizer='l1',\n+                                        U_regularizer='l2',\n+                                        b_regularizer='l2',\n+                                        dropout_W=0.2,\n+                                        dropout_U=0.1,\n+                                        name='conv')\n+    new_layer = keras.layers.ConvLSTM2D(5, (3, 3),\n+                                        kernel_initializer='normal',\n+                                        recurrent_initializer='uniform',\n+                                        unit_forget_bias=True,\n+                                        recurrent_activation='relu',\n+                                        strides=(2, 2),\n+                                        padding='valid',\n+                                        kernel_regularizer='l1',\n+                                        recurrent_regularizer='l2',\n+                                        bias_regularizer='l2',\n+                                        data_format='channels_first',\n+                                        dropout=0.2,\n+                                        recurrent_dropout=0.1,\n+                                        name='conv')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+\n+@keras_test\n+def test_batchnorm_legacy_interface():\n+    old_layer = keras.layers.BatchNormalization(mode=0, name='bn')\n+    new_layer = keras.layers.BatchNormalization(name='bn')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.BatchNormalization(mode=0,\n+                                                beta_init='one',\n+                                                gamma_init='uniform',\n+                                                name='bn')\n+    new_layer = keras.layers.BatchNormalization(beta_initializer='ones',\n+                                                gamma_initializer='uniform',\n+                                                name='bn')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fbc8697366de1e8bac0f76a00c6a65385dd11209", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 88 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 4 | Methods Changed: 4 | Complexity Δ (Sum/Max): 6/4 | Churn Δ: 88 | Churn Cumulative: 11196 | Contributors (this commit): 39 | Commits (past 90d): 69 | Contributors (cumulative): 43 | DMM Complexity: 1.0\n\nDIFF:\n@@ -19,6 +19,9 @@ from .pooling import MaxPooling1D\n from .pooling import MaxPooling2D\n from .pooling import MaxPooling3D\n \n+from ..legacy.layers import AtrousConvolution1D\n+from ..legacy.layers import AtrousConvolution2D\n+\n \n class _Conv(Layer):\n     \"\"\"Abstract nD convolution layer (private, used as implementation base).\n@@ -1830,3 +1833,7 @@ Convolution3D = Conv3D\n SeparableConvolution2D = SeparableConv2D\n Convolution2DTranspose = Conv2DTranspose\n Deconvolution2D = Deconv2D = Conv2DTranspose\n+\n+# Legacy aliases\n+AtrousConv1D = AtrousConvolution1D\n+AtrousConv2D = AtrousConvolution2D\n\n@@ -726,3 +726,31 @@ class Highway(Layer):\n                   'input_dim': self.input_dim}\n         base_config = super(Highway, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n+\n+\n+def AtrousConvolution1D(*args, **kwargs):\n+    from ..layers import Conv1D\n+    if 'atrous_rate' in kwargs:\n+        rate = kwargs.pop('atrous_rate')\n+    else:\n+        rate = 1\n+    kwargs['dilation_rate'] = rate\n+    warnings.warn('The `AtrousConvolution1D` layer '\n+                  ' has been deprecated. Use instead '\n+                  'the `Conv1D` layer with the `dilation_rate` '\n+                  'argument.')\n+    return Conv1D(*args, **kwargs)\n+\n+\n+def AtrousConvolution2D(*args, **kwargs):\n+    from ..layers import Conv2D\n+    if 'atrous_rate' in kwargs:\n+        rate = kwargs.pop('atrous_rate')\n+    else:\n+        rate = 1\n+    kwargs['dilation_rate'] = rate\n+    warnings.warn('The `AtrousConvolution2D` layer '\n+                  ' has been deprecated. Use instead '\n+                  'the `Conv2D` layer with the `dilation_rate` '\n+                  'argument.')\n+    return Conv2D(*args, **kwargs)\n\n@@ -653,5 +653,58 @@ def test_batchnorm_legacy_interface():\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n \n \n+@keras_test\n+def test_atrousconv1d_legacy_interface():\n+    old_layer = keras.layers.AtrousConvolution1D(5, 3,\n+                                                 init='normal',\n+                                                 subsample_length=2,\n+                                                 border_mode='valid',\n+                                                 W_regularizer='l1',\n+                                                 b_regularizer='l2',\n+                                                 W_constraint='maxnorm',\n+                                                 b_constraint='unitnorm',\n+                                                 atrous_rate=2,\n+                                                 name='conv')\n+    new_layer = keras.layers.Conv1D(5, 3,\n+                                    kernel_initializer='normal',\n+                                    strides=2,\n+                                    padding='valid',\n+                                    kernel_regularizer='l1',\n+                                    bias_regularizer='l2',\n+                                    kernel_constraint='max_norm',\n+                                    bias_constraint='unit_norm',\n+                                    dilation_rate=2,\n+                                    name='conv')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+\n+@keras_test\n+def test_atrousconv2d_legacy_interface():\n+    old_layer = keras.layers.AtrousConvolution2D(\n+        5, 3, 3,\n+        atrous_rate=(2, 2),\n+        init='normal',\n+        subsample=(2, 2),\n+        border_mode='valid',\n+        dim_ordering='th',\n+        W_regularizer='l1',\n+        b_regularizer='l2',\n+        W_constraint='maxnorm',\n+        b_constraint='unitnorm',\n+        name='conv')\n+    new_layer = keras.layers.Conv2D(5, (3, 3),\n+                                    kernel_initializer='normal',\n+                                    strides=(2, 2),\n+                                    padding='valid',\n+                                    kernel_regularizer='l1',\n+                                    bias_regularizer='l2',\n+                                    kernel_constraint='max_norm',\n+                                    bias_constraint='unit_norm',\n+                                    data_format='channels_first',\n+                                    dilation_rate=(2, 2),\n+                                    name='conv')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7696a139956577fd0f5b527698341d2c4d9e90eb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 10 | Methods Changed: 5 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 19 | Churn Cumulative: 867 | Contributors (this commit): 6 | Commits (past 90d): 27 | Contributors (cumulative): 6 | DMM Complexity: 0.2857142857142857\n\nDIFF:\n@@ -24,11 +24,11 @@ def generate_legacy_interface(allowed_positional_args=None,\n                 raise TypeError('Layer `' + layer_name +\n                                 '` can accept only ' +\n                                 str(len(allowed_positional_args)) +\n-                                ' positional arguments (' +\n-                                str(allowed_positional_args) + '), but '\n+                                ' positional arguments ' +\n+                                str(tuple(allowed_positional_args)) + ', but '\n                                 'you passed the following '\n                                 'positional arguments: ' +\n-                                str(args[1:]))\n+                                str(list(args[1:])))\n             for key in value_conversions:\n                 if key in kwargs:\n                     old_value = kwargs[key]\n@@ -43,11 +43,12 @@ def generate_legacy_interface(allowed_positional_args=None,\n                     converted.append((new_name, old_name))\n             if converted:\n                 signature = '`' + layer_name + '('\n-                for value in args[1:]:\n+                for i, value in enumerate(args[1:]):\n                     if isinstance(value, six.string_types):\n                         signature += '\"' + value + '\"'\n                     else:\n                         signature += str(value)\n+                    if i < len(args[1:]) - 1 or kwargs:\n                         signature += ', '\n                 for i, (name, value) in enumerate(kwargs.items()):\n                     signature += name + '='\n@@ -193,6 +194,7 @@ legacy_upsampling3d_support = generate_legacy_interface(\n \n \n def conv1d_args_preprocessor(args, kwargs):\n+    converted = []\n     if 'input_dim' in kwargs:\n         if 'input_length' in kwargs:\n             length = kwargs.pop('input_length')\n@@ -200,7 +202,8 @@ def conv1d_args_preprocessor(args, kwargs):\n             length = None\n         input_shape = (length, kwargs.pop('input_dim'))\n         kwargs['input_shape'] = input_shape\n-    return args, kwargs, [('input_shape', 'input_dim')]\n+        converted.append(('input_shape', 'input_dim'))\n+    return args, kwargs, converted\n \n legacy_conv1d_support = generate_legacy_interface(\n     allowed_positional_args=['filters', 'kernel_size'],\n@@ -218,6 +221,7 @@ legacy_conv1d_support = generate_legacy_interface(\n \n \n def conv2d_args_preprocessor(args, kwargs):\n+    converted = []\n     if len(args) > 4:\n         raise TypeError('Layer can receive at most 3 positional arguments.')\n     if len(args) == 4:\n@@ -233,15 +237,18 @@ def conv2d_args_preprocessor(args, kwargs):\n                         'as a keyword argument instead.')\n             kernel_size = (args[2], args[3])\n             args = [args[0], args[1], kernel_size]\n+            converted.append(('kernel_size', 'nb_row/nb_col'))\n     elif len(args) == 3 and isinstance(args[2], int):\n         if 'nb_col' in kwargs:\n             kernel_size = (args[2], kwargs.pop('nb_col'))\n             args = [args[0], args[1], kernel_size]\n+            converted.append(('kernel_size', 'nb_row/nb_col'))\n     elif len(args) == 2:\n         if 'nb_row' in kwargs and 'nb_col' in kwargs:\n             kernel_size = (kwargs.pop('nb_row'), kwargs.pop('nb_col'))\n             args = [args[0], args[1], kernel_size]\n-    return args, kwargs, [('kernel_size', 'nb_row/nb_col')]\n+            converted.append(('kernel_size', 'nb_row/nb_col'))\n+    return args, kwargs, converted\n \n legacy_conv2d_support = generate_legacy_interface(\n     allowed_positional_args=['filters', 'kernel_size'],\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#84711475f8db72ac573a2584cb85f8d6ff5facef", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 105 | Lines Deleted: 4 | Files Changed: 3 | Hunks: 9 | Methods Changed: 6 | Complexity Δ (Sum/Max): 11/7 | Churn Δ: 109 | Churn Cumulative: 11408 | Contributors (this commit): 39 | Commits (past 90d): 94 | Contributors (cumulative): 47 | DMM Complexity: 0.5535714285714286\n\nDIFF:\n@@ -1289,6 +1289,7 @@ class ZeroPadding2D(Layer):\n             `(batch, channels, padded_rows, padded_cols)`\n     \"\"\"\n \n+    @interfaces.legacy_zeropadding2d_support\n     def __init__(self,\n                  padding=(1, 1),\n                  data_format=None,\n@@ -1383,6 +1384,7 @@ class ZeroPadding3D(Layer):\n             `(batch, depth, first_padded_axis, second_padded_axis, third_axis_to_pad)`\n     \"\"\"\n \n+    @interfaces.legacy_zeropadding3d_support\n     def __init__(self, padding=(1, 1, 1), data_format=None, **kwargs):\n         super(ZeroPadding3D, self).__init__(**kwargs)\n         self.data_format = conv_utils.normalize_data_format(data_format)\n@@ -1542,6 +1544,7 @@ class Cropping2D(Layer):\n     ```\n     \"\"\"\n \n+    @interfaces.legacy_cropping2d_support\n     def __init__(self, cropping=((0, 0), (0, 0)),\n                  data_format=None, **kwargs):\n         super(Cropping2D, self).__init__(**kwargs)\n@@ -1669,6 +1672,7 @@ class Cropping3D(Layer):\n             `(batch, depth, first_cropped_axis, second_cropped_axis, third_cropped_axis)`\n     \"\"\"\n \n+    @interfaces.legacy_cropping3d_support\n     def __init__(self, cropping=((1, 1), (1, 1), (1, 1)),\n                  data_format=None, **kwargs):\n         super(Cropping3D, self).__init__(**kwargs)\n\n@@ -406,7 +406,6 @@ def convlstm2d_args_preprocessor(args, kwargs):\n     args, kwargs, _converted = conv2d_args_preprocessor(args, kwargs)\n     return args, kwargs, converted + _converted\n \n-\n legacy_convlstm2d_support = generate_legacy_interface(\n     allowed_positional_args=['filters', 'kernel_size'],\n     conversions=[('nb_filter', 'filters'),\n@@ -427,9 +426,64 @@ legacy_convlstm2d_support = generate_legacy_interface(\n                                         'default': None}},\n     preprocessor=convlstm2d_args_preprocessor)\n \n-\n legacy_batchnorm_support = generate_legacy_interface(\n     allowed_positional_args=[],\n     conversions=[('beta_init', 'beta_initializer'),\n                  ('gamma_init', 'gamma_initializer')],\n     preprocessor=batchnorm_args_preprocessor)\n+\n+\n+def zeropadding2d_preprocessor(args, kwargs):\n+    converted = []\n+    if 'padding' in kwargs and isinstance(kwargs['padding'], dict):\n+        if set(kwargs['padding'].keys()) <= {'top_pad', 'bottom_pad',\n+                                             'left_pad', 'right_pad'}:\n+            top_pad = kwargs['padding'].get('top_pad', 0)\n+            bottom_pad = kwargs['padding'].get('bottom_pad', 0)\n+            left_pad = kwargs['padding'].get('left_pad', 0)\n+            right_pad = kwargs['padding'].get('right_pad', 0)\n+            kwargs['padding'] = ((top_pad, bottom_pad), (left_pad, right_pad))\n+            warnings.warn('The `padding` argument in the Keras 2 API no longer'\n+                          'accepts dict types. You can now input argument as: '\n+                          '`padding`=(top_pad, bottom_pad, left_pad, right_pad)')\n+    elif len(args) == 2 and isinstance(args[1], dict):\n+        if set(args[1].keys()) <= {'top_pad', 'bottom_pad',\n+                                   'left_pad', 'right_pad'}:\n+            top_pad = args[1].get('top_pad', 0)\n+            bottom_pad = args[1].get('bottom_pad', 0)\n+            left_pad = args[1].get('left_pad', 0)\n+            right_pad = args[1].get('right_pad', 0)\n+            args = (args[0], ((top_pad, bottom_pad), (left_pad, right_pad)))\n+            warnings.warn('The `padding` argument in the Keras 2 API no longer'\n+                          'accepts dict types. You can now input argument as: '\n+                          '`padding`=((top_pad, bottom_pad), (left_pad, right_pad))')\n+    return args, kwargs, converted\n+\n+legacy_zeropadding2d_support = generate_legacy_interface(\n+    allowed_positional_args=['padding'],\n+    conversions=[('dim_ordering', 'data_format')],\n+    value_conversions={'dim_ordering': {'tf': 'channels_last',\n+                                        'th': 'channels_first',\n+                                        'default': None}},\n+    preprocessor=zeropadding2d_preprocessor)\n+\n+legacy_zeropadding3d_support = generate_legacy_interface(\n+    allowed_positional_args=['padding'],\n+    conversions=[('dim_ordering', 'data_format')],\n+    value_conversions={'dim_ordering': {'tf': 'channels_last',\n+                                        'th': 'channels_first',\n+                                        'default': None}})\n+\n+legacy_cropping2d_support = generate_legacy_interface(\n+    allowed_positional_args=['cropping'],\n+    conversions=[('dim_ordering', 'data_format')],\n+    value_conversions={'dim_ordering': {'tf': 'channels_last',\n+                                        'th': 'channels_first',\n+                                        'default': None}})\n+\n+legacy_cropping3d_support = generate_legacy_interface(\n+    allowed_positional_args=['cropping'],\n+    conversions=[('dim_ordering', 'data_format')],\n+    value_conversions={'dim_ordering': {'tf': 'channels_last',\n+                                        'th': 'channels_first',\n+                                        'default': None}})\n\n@@ -388,8 +388,12 @@ def test_upsampling2d_legacy_interface():\n \n @keras_test\n def test_upsampling3d_legacy_interface():\n-    old_layer = keras.layers.UpSampling3D((2, 2, 2), dim_ordering='tf', name='us3d')\n-    new_layer = keras.layers.UpSampling3D((2, 2, 2), data_format='channels_last', name='us3d')\n+    old_layer = keras.layers.UpSampling3D((2, 2, 2),\n+                                          dim_ordering='tf',\n+                                          name='us3d')\n+    new_layer = keras.layers.UpSampling3D((2, 2, 2),\n+                                          data_format='channels_last',\n+                                          name='us3d')\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n \n \n@@ -706,5 +710,44 @@ def test_atrousconv2d_legacy_interface():\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n \n \n+@keras_test\n+def test_zeropadding2d_legacy_interface():\n+    old_layer = keras.layers.ZeroPadding2D(padding={'right_pad': 4,\n+                                                    'bottom_pad': 2,\n+                                                    'top_pad': 1,\n+                                                    'left_pad': 3},\n+                                          dim_ordering='tf',\n+                                          name='zp2d')\n+    new_layer = keras.layers.ZeroPadding2D(((1, 2), (3, 4)),\n+                                           data_format='channels_last',\n+                                           name='zp2d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+\n+@keras_test\n+def test_zeropadding3d_legacy_interface():\n+    old_layer = keras.layers.ZeroPadding3D((2, 2, 2),\n+                                           dim_ordering='tf',\n+                                           name='zp3d')\n+    new_layer = keras.layers.ZeroPadding3D((2, 2, 2),\n+                                           data_format='channels_last',\n+                                           name='zp3d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+\n+@keras_test\n+def test_cropping2d_legacy_interface():\n+    old_layer = keras.layers.Cropping2D(dim_ordering='tf', name='c2d')\n+    new_layer = keras.layers.Cropping2D(data_format='channels_last', name='c2d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+\n+@keras_test\n+def test_cropping3d_legacy_interface():\n+    old_layer = keras.layers.Cropping3D(dim_ordering='tf', name='c3d')\n+    new_layer = keras.layers.Cropping3D(data_format='channels_last', name='c3d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#aa826d684d97c7871daa65cdbaf19eaac32955c2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 167 | Lines Deleted: 162 | Files Changed: 17 | Hunks: 103 | Methods Changed: 10 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 329 | Churn Cumulative: 4798 | Contributors (this commit): 44 | Commits (past 90d): 68 | Contributors (cumulative): 84 | DMM Complexity: 1.0\n\nDIFF:\n@@ -12,8 +12,8 @@ References:\n Reaches 98.6% accuracy on task 'single_supporting_fact_10k' after 120 epochs.\n Time per epoch: 3s on CPU (core i7).\n '''\n-\n from __future__ import print_function\n+\n from keras.models import Sequential\n from keras.layers.embeddings import Embedding\n from keras.layers import Activation, Dense, Merge, Permute, Dropout\n\n@@ -5,6 +5,7 @@ This script can run on CPU in a few minutes (with the TensorFlow backend).\n Results example: http://i.imgur.com/4nj4KjN.jpg\n '''\n from __future__ import print_function\n+\n from scipy.misc import imsave\n import numpy as np\n import time\n\n@@ -15,6 +15,7 @@ If running on CPU, prefer the TensorFlow backend (much faster).\n Example results: http://i.imgur.com/FX6ROg9.jpg\n '''\n from __future__ import print_function\n+\n from keras.preprocessing.image import load_img, img_to_array\n import numpy as np\n from scipy.misc import imsave\n@@ -57,21 +58,19 @@ saved_settings = {\n # the settings we will use in this experiment\n settings = saved_settings['dreamy']\n \n-# util function to open, resize and format pictures into appropriate tensors\n-\n \n def preprocess_image(image_path):\n+    # util function to open, resize and format pictures\n+    # into appropriate tensors\n     img = load_img(image_path, target_size=(img_height, img_width))\n     img = img_to_array(img)\n     img = np.expand_dims(img, axis=0)\n     img = vgg16.preprocess_input(img)\n     return img\n \n-# util function to convert a tensor into a valid image\n-\n \n def deprocess_image(x):\n-\n+    # util function to convert a tensor into a valid image\n     if K.image_data_format() == 'channels_first':\n         x = x.reshape((3, img_height, img_width))\n         x = x.transpose((1, 2, 0))\n@@ -102,10 +101,9 @@ print('Model loaded.')\n # get the symbolic outputs of each \"key\" layer (we gave them unique names).\n layer_dict = dict([(layer.name, layer) for layer in model.layers])\n \n-# continuity loss util function\n-\n \n def continuity_loss(x):\n+    # continuity loss util function\n     assert K.ndim(x) == 4\n     if K.image_data_format() == 'channels_first':\n         a = K.square(x[:, :, :img_height - 1, :img_width - 1] -\n@@ -162,15 +160,17 @@ def eval_loss_and_grads(x):\n         grad_values = np.array(outs[1:]).flatten().astype('float64')\n     return loss_value, grad_values\n \n-# this Evaluator class makes it possible\n-# to compute loss and gradients in one pass\n-# while retrieving them via two separate functions,\n-# \"loss\" and \"grads\". This is done because scipy.optimize\n-# requires separate functions for loss and gradients,\n-# but computing them separately would be inefficient.\n-\n \n class Evaluator(object):\n+    \"\"\"Loss and gradients evaluator.\n+\n+    This Evaluator class makes it possible\n+    to compute loss and gradients in one pass\n+    while retrieving them via two separate functions,\n+    \"loss\" and \"grads\". This is done because scipy.optimize\n+    requires separate functions for loss and gradients,\n+    but computing them separately would be inefficient.\n+    \"\"\"\n \n     def __init__(self):\n         self.loss_value = None\n@@ -192,22 +192,23 @@ class Evaluator(object):\n \n evaluator = Evaluator()\n \n-# run scipy-based optimization (L-BFGS) over the pixels of the generated image\n+# Run scipy-based optimization (L-BFGS) over the pixels of the generated image\n # so as to minimize the loss\n x = preprocess_image(base_image_path)\n for i in range(5):\n     print('Start of iteration', i)\n     start_time = time.time()\n \n-    # add a random jitter to the initial image. This will be reverted at decoding time\n+    # Add a random jitter to the initial image.\n+    # This will be reverted at decoding time\n     random_jitter = (settings['jitter'] * 2) * (np.random.random(img_size) - 0.5)\n     x += random_jitter\n \n-    # run L-BFGS for 7 steps\n+    # Run L-BFGS for 7 steps\n     x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n                                      fprime=evaluator.grads, maxfun=7)\n     print('Current loss value:', min_val)\n-    # decode the dream and save it\n+    # Decode the dream and save it\n     x = x.reshape(img_size)\n     x -= random_jitter\n     img = deprocess_image(np.copy(x))\n\n@@ -6,7 +6,6 @@ Time per epoch on CPU (Core i7): ~150s.\n \n from __future__ import print_function\n import numpy as np\n-np.random.seed(1337)  # for reproducibility\n \n from keras.preprocessing import sequence\n from keras.models import Sequential\n@@ -15,19 +14,21 @@ from keras.datasets import imdb\n \n \n max_features = 20000\n-maxlen = 100  # cut texts after this number of words (among top max_features most common words)\n+# cut texts after this number of words\n+# (among top max_features most common words)\n+maxlen = 100\n batch_size = 32\n \n print('Loading data...')\n-(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n-print(len(X_train), 'train sequences')\n-print(len(X_test), 'test sequences')\n+(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n+print(len(x_train), 'train sequences')\n+print(len(x_test), 'test sequences')\n \n print(\"Pad sequences (samples x time)\")\n-X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n-X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n-print('X_train shape:', X_train.shape)\n-print('X_test shape:', X_test.shape)\n+x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n+x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n+print('x_train shape:', x_train.shape)\n+print('x_test shape:', x_test.shape)\n y_train = np.array(y_train)\n y_test = np.array(y_test)\n \n@@ -41,7 +42,7 @@ model.add(Dense(1, activation='sigmoid'))\n model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n \n print('Train...')\n-model.fit(X_train, y_train,\n+model.fit(x_train, y_train,\n           batch_size=batch_size,\n           epochs=4,\n-          validation_data=[X_test, y_test])\n+          validation_data=[x_test, y_test])\n\n@@ -7,8 +7,6 @@ Gets to 0.89 test accuracy after 2 epochs.\n '''\n \n from __future__ import print_function\n-import numpy as np\n-np.random.seed(1337)  # for reproducibility\n \n from keras.preprocessing import sequence\n from keras.models import Sequential\n@@ -17,7 +15,6 @@ from keras.layers import Embedding\n from keras.layers import Conv1D, GlobalMaxPooling1D\n from keras.datasets import imdb\n \n-\n # set parameters:\n max_features = 5000\n maxlen = 400\n@@ -29,15 +26,15 @@ hidden_dims = 250\n epochs = 2\n \n print('Loading data...')\n-(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n-print(len(X_train), 'train sequences')\n-print(len(X_test), 'test sequences')\n+(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n+print(len(x_train), 'train sequences')\n+print(len(x_test), 'test sequences')\n \n print('Pad sequences (samples x time)')\n-X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n-X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n-print('X_train shape:', X_train.shape)\n-print('X_test shape:', X_test.shape)\n+x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n+x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n+print('x_train shape:', x_train.shape)\n+print('x_test shape:', x_test.shape)\n \n print('Build model...')\n model = Sequential()\n@@ -71,7 +68,7 @@ model.add(Activation('sigmoid'))\n model.compile(loss='binary_crossentropy',\n               optimizer='adam',\n               metrics=['accuracy'])\n-model.fit(X_train, y_train,\n+model.fit(x_train, y_train,\n           batch_size=batch_size,\n           epochs=epochs,\n-          validation_data=(X_test, y_test))\n+          validation_data=(x_test, y_test))\n\n@@ -4,8 +4,6 @@ classification task.\n Gets to 0.8498 test accuracy after 2 epochs. 41s/epoch on K520 GPU.\n '''\n from __future__ import print_function\n-import numpy as np\n-np.random.seed(1337)  # for reproducibility\n \n from keras.preprocessing import sequence\n from keras.models import Sequential\n@@ -15,7 +13,6 @@ from keras.layers import LSTM\n from keras.layers import Conv1D, MaxPooling1D\n from keras.datasets import imdb\n \n-\n # Embedding\n max_features = 20000\n maxlen = 100\n@@ -40,15 +37,15 @@ Only 2 epochs are needed as the dataset is very small.\n '''\n \n print('Loading data...')\n-(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n-print(len(X_train), 'train sequences')\n-print(len(X_test), 'test sequences')\n+(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n+print(len(x_train), 'train sequences')\n+print(len(x_test), 'test sequences')\n \n print('Pad sequences (samples x time)')\n-X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n-X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n-print('X_train shape:', X_train.shape)\n-print('X_test shape:', X_test.shape)\n+x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n+x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n+print('x_train shape:', x_train.shape)\n+print('x_test shape:', x_test.shape)\n \n print('Build model...')\n \n@@ -70,8 +67,8 @@ model.compile(loss='binary_crossentropy',\n               metrics=['accuracy'])\n \n print('Train...')\n-model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,\n-          validation_data=(X_test, y_test))\n-score, acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n+model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,\n+          validation_data=(x_test, y_test))\n+score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n print('Test score:', score)\n print('Test accuracy:', acc)\n\n@@ -7,12 +7,11 @@ https://arxiv.org/abs/1607.01759\n \n Results on IMDB datasets with uni and bi-gram embeddings:\n     Uni-gram: 0.8813 test accuracy after 5 epochs. 8s/epoch on i7 cpu.\n-    Bi-gram : 0.9056 test accuracy after 5 epochs. 2s/epoch on GTX 980M gpu.\n+    Bi-gram : 0.9056 test accuracy after 5 epochs. 2s/epoch on GTx 980M gpu.\n '''\n \n from __future__ import print_function\n import numpy as np\n-np.random.seed(1337)  # for reproducibility\n \n from keras.preprocessing import sequence\n from keras.models import Sequential\n@@ -73,17 +72,17 @@ embedding_dims = 50\n epochs = 5\n \n print('Loading data...')\n-(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n-print(len(X_train), 'train sequences')\n-print(len(X_test), 'test sequences')\n-print('Average train sequence length: {}'.format(np.mean(list(map(len, X_train)), dtype=int)))\n-print('Average test sequence length: {}'.format(np.mean(list(map(len, X_test)), dtype=int)))\n+(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n+print(len(x_train), 'train sequences')\n+print(len(x_test), 'test sequences')\n+print('Average train sequence length: {}'.format(np.mean(list(map(len, x_train)), dtype=int)))\n+print('Average test sequence length: {}'.format(np.mean(list(map(len, x_test)), dtype=int)))\n \n if ngram_range > 1:\n     print('Adding {}-gram features'.format(ngram_range))\n     # Create set of unique n-gram from the training set.\n     ngram_set = set()\n-    for input_list in X_train:\n+    for input_list in x_train:\n         for i in range(2, ngram_range + 1):\n             set_of_ngram = create_ngram_set(input_list, ngram_value=i)\n             ngram_set.update(set_of_ngram)\n@@ -98,17 +97,17 @@ if ngram_range > 1:\n     # max_features is the highest integer that could be found in the dataset.\n     max_features = np.max(list(indice_token.keys())) + 1\n \n-    # Augmenting X_train and X_test with n-grams features\n-    X_train = add_ngram(X_train, token_indice, ngram_range)\n-    X_test = add_ngram(X_test, token_indice, ngram_range)\n-    print('Average train sequence length: {}'.format(np.mean(list(map(len, X_train)), dtype=int)))\n-    print('Average test sequence length: {}'.format(np.mean(list(map(len, X_test)), dtype=int)))\n+    # Augmenting x_train and x_test with n-grams features\n+    x_train = add_ngram(x_train, token_indice, ngram_range)\n+    x_test = add_ngram(x_test, token_indice, ngram_range)\n+    print('Average train sequence length: {}'.format(np.mean(list(map(len, x_train)), dtype=int)))\n+    print('Average test sequence length: {}'.format(np.mean(list(map(len, x_test)), dtype=int)))\n \n print('Pad sequences (samples x time)')\n-X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n-X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n-print('X_train shape:', X_train.shape)\n-print('X_test shape:', X_test.shape)\n+x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n+x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n+print('x_train shape:', x_train.shape)\n+print('x_test shape:', x_test.shape)\n \n print('Build model...')\n model = Sequential()\n@@ -130,7 +129,7 @@ model.compile(loss='binary_crossentropy',\n               optimizer='adam',\n               metrics=['accuracy'])\n \n-model.fit(X_train, y_train,\n+model.fit(x_train, y_train,\n           batch_size=batch_size,\n           epochs=epochs,\n-          validation_data=(X_test, y_test))\n+          validation_data=(x_test, y_test))\n\n@@ -11,11 +11,10 @@ Some configurations won't converge.\n from what you see with CNNs/MLPs/etc.\n '''\n from __future__ import print_function\n-import numpy as np\n \n from keras.preprocessing import sequence\n from keras.models import Sequential\n-from keras.layers import Dense, Activation, Embedding\n+from keras.layers import Dense, Embedding\n from keras.layers import LSTM\n from keras.datasets import imdb\n \n\n@@ -43,9 +43,13 @@ for mode in modes:\n     print('Testing mode: implementation={}'.format(mode))\n \n     model = Sequential()\n-    model.add(Embedding(max_features, embedding_dim, input_length=max_length))\n+    model.add(Embedding(max_features, embedding_dim,\n+                        input_length=max_length))\n     model.add(Dropout(0.2))\n-    model.add(LSTM(embedding_dim, dropout=0.2, recurrent_dropout=0.2, implementation=mode))\n+    model.add(LSTM(embedding_dim,\n+                   dropout=0.2,\n+                   recurrent_dropout=0.2,\n+                   implementation=mode))\n     model.add(Dense(1, activation='sigmoid'))\n     model.compile(loss='binary_crossentropy',\n                   optimizer='adam',\n\n@@ -20,7 +20,7 @@ import numpy as np\n import random\n import sys\n \n-path = get_file('nietzsche.txt', origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\")\n+path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n text = open(path).read().lower()\n print('corpus length:', len(text))\n \n\n@@ -6,8 +6,8 @@ MNIST dataset. See https://arxiv.org/abs/1610.09585 for more details.\n \n You should start to see reasonable images after ~5 epochs, and good images\n by ~15 epochs. You should use a GPU, as the convolution-heavy operations are\n-very slow on the CPU. Prefer the TensorFlow backend if you plan on iterating, as\n-the compilation time can be a blocker using Theano.\n+very slow on the CPU. Prefer the TensorFlow backend if you plan on iterating,\n+as the compilation time can be a blocker using Theano.\n \n Timings:\n \n@@ -33,9 +33,10 @@ from six.moves import range\n \n import keras.backend as K\n from keras.datasets import mnist\n-from keras.layers import Input, Dense, Reshape, Flatten, Embedding, merge, Dropout\n+from keras import layers\n+from keras.layers import Input, Dense, Reshape, Flatten, Embedding, Dropout\n from keras.layers.advanced_activations import LeakyReLU\n-from keras.layers.convolutional import UpSampling2D, Convolution2D\n+from keras.layers.convolutional import UpSampling2D, Conv2D\n from keras.models import Sequential, Model\n from keras.optimizers import Adam\n from keras.utils.generic_utils import Progbar\n@@ -57,17 +58,20 @@ def build_generator(latent_size):\n \n     # upsample to (..., 14, 14)\n     cnn.add(UpSampling2D(size=(2, 2)))\n-    cnn.add(Convolution2D(256, 5, padding='same',\n-                          activation='relu', kernel_initializer='glorot_normal'))\n+    cnn.add(Conv2D(256, 5, padding='same',\n+                   activation='relu',\n+                   kernel_initializer='glorot_normal'))\n \n     # upsample to (..., 28, 28)\n     cnn.add(UpSampling2D(size=(2, 2)))\n-    cnn.add(Convolution2D(128, 5, padding='same',\n-                          activation='relu', kernel_initializer='glorot_normal'))\n+    cnn.add(Conv2D(128, 5, padding='same',\n+                   activation='relu',\n+                   kernel_initializer='glorot_normal'))\n \n     # take a channel axis reduction\n-    cnn.add(Convolution2D(1, 2, padding='same',\n-                          activation='tanh', kernel_initializer='glorot_normal'))\n+    cnn.add(Conv2D(1, 2, padding='same',\n+                   activation='tanh',\n+                   kernel_initializer='glorot_normal'))\n \n     # this is the z space commonly refered to in GAN papers\n     latent = Input(shape=(latent_size, ))\n@@ -80,7 +84,7 @@ def build_generator(latent_size):\n                               embeddings_initializer='glorot_normal')(image_class))\n \n     # hadamard product between z-space and a class conditional embedding\n-    h = merge([latent, cls], mode='mul')\n+    h = layers.multiply([latent, cls])\n \n     fake_image = cnn(h)\n \n@@ -92,20 +96,20 @@ def build_discriminator():\n     # the reference paper\n     cnn = Sequential()\n \n-    cnn.add(Convolution2D(32, 3, padding='same', strides=2,\n+    cnn.add(Conv2D(32, 3, padding='same', strides=2,\n                    input_shape=(1, 28, 28)))\n     cnn.add(LeakyReLU())\n     cnn.add(Dropout(0.3))\n \n-    cnn.add(Convolution2D(64, 3, padding='same', strides=2))\n+    cnn.add(Conv2D(64, 3, padding='same', strides=2))\n     cnn.add(LeakyReLU())\n     cnn.add(Dropout(0.3))\n \n-    cnn.add(Convolution2D(128, 3, padding='same', strides=2))\n+    cnn.add(Conv2D(128, 3, padding='same', strides=2))\n     cnn.add(LeakyReLU())\n     cnn.add(Dropout(0.3))\n \n-    cnn.add(Convolution2D(256, 3, padding='same', strides=1))\n+    cnn.add(Conv2D(256, 3, padding='same', strides=1))\n     cnn.add(LeakyReLU())\n     cnn.add(Dropout(0.3))\n \n@@ -224,7 +228,8 @@ if __name__ == '__main__':\n             trick = np.ones(2 * batch_size)\n \n             epoch_gen_loss.append(combined.train_on_batch(\n-                [noise, sampled_labels.reshape((-1, 1))], [trick, sampled_labels]))\n+                [noise, sampled_labels.reshape((-1, 1))],\n+                [trick, sampled_labels]))\n \n         print('\\nTesting for epoch {}:'.format(epoch + 1))\n \n\n@@ -56,8 +56,8 @@ print(x_train.shape[0], 'train samples')\n print(x_test.shape[0], 'test samples')\n \n # Converts class vectors to binary class matrices.\n-Y_train = keras.utils.to_categorical(y_train, num_classes)\n-Y_test = keras.utils.to_categorical(y_test, num_classes)\n+y_train = keras.utils.to_categorical(y_train, num_classes)\n+y_test = keras.utils.to_categorical(y_test, num_classes)\n \n row, col, pixel = x_train.shape[1:]\n \n@@ -78,10 +78,11 @@ model.compile(loss='categorical_crossentropy',\n               metrics=['accuracy'])\n \n # Training.\n-model.fit(x_train, Y_train, batch_size=batch_size, epochs=epochs,\n-          verbose=1, validation_data=(x_test, Y_test))\n+model.fit(x_train, y_train,\n+          batch_size=batch_size, epochs=epochs,\n+          verbose=1, validation_data=(x_test, y_test))\n \n # Evaluation.\n-scores = model.evaluate(x_test, Y_test, verbose=0)\n+scores = model.evaluate(x_test, y_test, verbose=0)\n print('Test loss:', scores[0])\n print('Test accuracy:', scores[1])\n\n@@ -13,7 +13,6 @@ Gets to 99.5% test accuracy after 20 epochs.\n from __future__ import absolute_import\n from __future__ import print_function\n import numpy as np\n-np.random.seed(1337)  # for reproducibility\n \n import random\n from keras.datasets import mnist\n@@ -38,7 +37,8 @@ def contrastive_loss(y_true, y_pred):\n     http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n     '''\n     margin = 1\n-    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n+    return K.mean(y_true * K.square(y_pred) +\n+                  (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n \n \n def create_pairs(x, digit_indices):\n@@ -108,7 +108,8 @@ input_b = Input(shape=(input_dim,))\n processed_a = base_network(input_a)\n processed_b = base_network(input_b)\n \n-distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n+distance = Lambda(euclidean_distance,\n+                  output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n \n model = Model([input_a, input_b], distance)\n \n\n@@ -9,7 +9,7 @@ import keras\n from keras.datasets import mnist\n from keras.models import Sequential\n from keras.layers import Dense, Dropout, Activation, Flatten\n-from keras.layers import Convolution2D, MaxPooling2D\n+from keras.layers import Conv2D, MaxPooling2D\n from keras.wrappers.scikit_learn import KerasClassifier\n from keras import backend as K\n from sklearn.grid_search import GridSearchCV\n@@ -53,11 +53,11 @@ def make_model(dense_layer_sizes, filters, kernel_size, pool_size):\n     '''\n \n     model = Sequential()\n-    model.add(Convolution2D(filters, kernel_size,\n+    model.add(Conv2D(filters, kernel_size,\n                      padding='valid',\n                      input_shape=input_shape))\n     model.add(Activation('relu'))\n-    model.add(Convolution2D(filters, kernel_size))\n+    model.add(Conv2D(filters, kernel_size))\n     model.add(Activation('relu'))\n     model.add(MaxPooling2D(pool_size=pool_size))\n     model.add(Dropout(0.25))\n\n@@ -2,21 +2,21 @@\n MNIST dataset.  It exemplifies two influential methods that have been developed\r\n in the past few years.\r\n \r\n-The first is the idea of properly \"unpooling.\" During any max pool, the\r\n-exact location (the \"where\") of the maximal value in a pooled receptive field\r\n+The first is the idea of properly 'unpooling.' During any max pool, the\r\n+exact location (the 'where') of the maximal value in a pooled receptive field\r\n is lost, however it can be very useful in the overall reconstruction of an\r\n-input image.  Therefore, if the \"where\" is handed from the encoder\r\n-to the corresponding decoder layer, features being decoded can be \"placed\" in\r\n+input image.  Therefore, if the 'where' is handed from the encoder\r\n+to the corresponding decoder layer, features being decoded can be 'placed' in\r\n the right location, allowing for reconstructions of much higher fidelity.\r\n \r\n References:\r\n [1]\r\n-\"Visualizing and Understanding Convolutional Networks\"\r\n+'Visualizing and Understanding Convolutional Networks'\r\n Matthew D Zeiler, Rob Fergus\r\n https://arxiv.org/abs/1311.2901v3\r\n \r\n [2]\r\n-\"Stacked What-Where Auto-encoders\"\r\n+'Stacked What-Where Auto-encoders'\r\n Junbo Zhao, Michael Mathieu, Ross Goroshin, Yann LeCun\r\n https://arxiv.org/abs/1506.02351v8\r\n \r\n@@ -34,42 +34,42 @@ applied as a bias because we know the MNIST digits are mapped to [0,1].\n \r\n References:\r\n [3]\r\n-\"Deep Residual Learning for Image Recognition\"\r\n-Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\r\n+'Deep Residual Learning for Image Recognition'\r\n+Kaiming He, xiangyu Zhang, Shaoqing Ren, Jian Sun\r\n https://arxiv.org/abs/1512.03385v1\r\n \r\n [4]\r\n-\"Identity Mappings in Deep Residual Networks\"\r\n-Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\r\n+'Identity Mappings in Deep Residual Networks'\r\n+Kaiming He, xiangyu Zhang, Shaoqing Ren, Jian Sun\r\n https://arxiv.org/abs/1603.05027v3\r\n \r\n '''\r\n from __future__ import print_function\r\n import numpy as np\r\n-np.random.seed(1337)  # for reproducibility\r\n \r\n from keras.datasets import mnist\r\n from keras.models import Model\r\n-from keras.layers import Activation, merge\r\n-from keras.layers import UpSampling2D, Convolution2D, MaxPooling2D\r\n+from keras.layers import Activation\r\n+from keras.layers import UpSampling2D, Conv2D, MaxPooling2D\r\n from keras.layers import Input, BatchNormalization\r\n import matplotlib.pyplot as plt\r\n import keras.backend as K\r\n+from keras import layers\r\n \r\n \r\n def convresblock(x, nfeats=8, ksize=3, nskipped=2):\r\n     ''' The proposed residual block from [4]'''\r\n-    y0 = Convolution2D(nfeats, ksize, ksize, border_mode='same')(x)\r\n+    y0 = Conv2D(nfeats, ksize, padding='same')(x)\r\n     y = y0\r\n     for i in range(nskipped):\r\n-        y = BatchNormalization(mode=0, axis=1)(y)\r\n+        y = BatchNormalization(axis=1)(y)\r\n         y = Activation('relu')(y)\r\n-        y = Convolution2D(nfeats, ksize, ksize, border_mode='same')(y)\r\n-    return merge([y0, y], mode='sum')\r\n+        y = Conv2D(nfeats, ksize, padding='same')(y)\r\n+    return layers.add([y0, y])\r\n \r\n \r\n def getwhere(x):\r\n-    ''' Calculate the \"where\" mask that contains switches indicating which\r\n+    ''' Calculate the 'where' mask that contains switches indicating which\r\n     index contained the max value when MaxPool2D was applied.  Using the\r\n     gradient of the sum is a nice trick to keep everything high level.'''\r\n     y_prepool, y_postpool = x\r\n@@ -89,17 +89,17 @@ K.set_image_data_format('channels_first')\n img_rows, img_cols = 28, 28\r\n \r\n # the data, shuffled and split between train and test sets\r\n-(X_train, _), (X_test, _) = mnist.load_data()\r\n+(x_train, _), (x_test, _) = mnist.load_data()\r\n \r\n-X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\r\n-X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\r\n-X_train = X_train.astype('float32')\r\n-X_test = X_test.astype('float32')\r\n-X_train /= 255\r\n-X_test /= 255\r\n-print('X_train shape:', X_train.shape)\r\n-print(X_train.shape[0], 'train samples')\r\n-print(X_test.shape[0], 'test samples')\r\n+x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\r\n+x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\r\n+x_train = x_train.astype('float32')\r\n+x_test = x_test.astype('float32')\r\n+x_train /= 255\r\n+x_test /= 255\r\n+print('x_train shape:', x_train.shape)\r\n+print(x_train.shape[0], 'train samples')\r\n+print(x_test.shape[0], 'test samples')\r\n \r\n # The size of the kernel used for the MaxPooling2D\r\n pool_size = 2\r\n@@ -116,41 +116,40 @@ batch_size = 128\n \r\n if pool_size == 2:\r\n     # if using a 5 layer net of pool_size = 2\r\n-    X_train = np.pad(X_train, [[0, 0], [0, 0], [2, 2], [2, 2]],\r\n+    x_train = np.pad(x_train, [[0, 0], [0, 0], [2, 2], [2, 2]],\r\n                      mode='constant')\r\n-    X_test = np.pad(X_test, [[0, 0], [0, 0], [2, 2], [2, 2]], mode='constant')\r\n+    x_test = np.pad(x_test, [[0, 0], [0, 0], [2, 2], [2, 2]], mode='constant')\r\n     nlayers = 5\r\n elif pool_size == 3:\r\n     # if using a 3 layer net of pool_size = 3\r\n-    X_train = X_train[:, :, :-1, :-1]\r\n-    X_test = X_test[:, :, :-1, :-1]\r\n+    x_train = x_train[:, :, :-1, :-1]\r\n+    x_test = x_test[:, :, :-1, :-1]\r\n     nlayers = 3\r\n else:\r\n     import sys\r\n-    sys.exit(\"Script supports pool_size of 2 and 3.\")\r\n+    sys.exit('Script supports pool_size of 2 and 3.')\r\n \r\n # Shape of input to train on (note that model is fully convolutional however)\r\n-input_shape = X_train.shape[1:]\r\n+input_shape = x_train.shape[1:]\r\n # The final list of the size of axis=1 for all layers, including input\r\n nfeats_all = [input_shape[0]] + nfeats\r\n \r\n-# First build the encoder, all the while keeping track of the \"where\" masks\r\n+# First build the encoder, all the while keeping track of the 'where' masks\r\n img_input = Input(shape=input_shape)\r\n \r\n-# We push the \"where\" masks to the following list\r\n+# We push the 'where' masks to the following list\r\n wheres = [None] * nlayers\r\n y = img_input\r\n for i in range(nlayers):\r\n     y_prepool = convresblock(y, nfeats=nfeats_all[i + 1], ksize=ksize)\r\n     y = MaxPooling2D(pool_size=(pool_sizes[i], pool_sizes[i]))(y_prepool)\r\n-    wheres[i] = merge([y_prepool, y], mode=getwhere,\r\n-                      output_shape=lambda x: x[0])\r\n+    wheres[i] = layers.Lambda(getwhere, output_shape=lambda x: x[0])([y_prepool, y])\r\n \r\n-# Now build the decoder, and use the stored \"where\" masks to place the features\r\n+# Now build the decoder, and use the stored 'where' masks to place the features\r\n for i in range(nlayers):\r\n     ind = nlayers - 1 - i\r\n     y = UpSampling2D(size=(pool_sizes[ind], pool_sizes[ind]))(y)\r\n-    y = merge([y, wheres[ind]], mode='mul')\r\n+    y = layers.multiply([y, wheres[ind]])\r\n     y = convresblock(y, nfeats=nfeats_all[ind], ksize=ksize)\r\n \r\n # Use hard_simgoid to clip range of reconstruction\r\n@@ -161,16 +160,16 @@ model = Model(img_input, y)\n model.compile('adam', 'mse')\r\n \r\n # Fit the model\r\n-model.fit(X_train, X_train, validation_data=(X_test, X_test),\r\n+model.fit(x_train, x_train, validation_data=(x_test, x_test),\r\n           batch_size=batch_size, epochs=epochs)\r\n \r\n # Plot\r\n-X_recon = model.predict(X_test[:25])\r\n-X_plot = np.concatenate((X_test[:25], X_recon), axis=1)\r\n-X_plot = X_plot.reshape((5, 10, input_shape[-2], input_shape[-1]))\r\n-X_plot = np.vstack([np.hstack(x) for x in X_plot])\r\n+x_recon = model.predict(x_test[:25])\r\n+x_plot = np.concatenate((x_test[:25], x_recon), axis=1)\r\n+x_plot = x_plot.reshape((5, 10, input_shape[-2], input_shape[-1]))\r\n+x_plot = np.vstack([np.hstack(x) for x in x_plot])\r\n plt.figure()\r\n plt.axis('off')\r\n plt.title('Test Samples: Originals/Reconstructions')\r\n-plt.imshow(X_plot, interpolation='none', cmap='gray')\r\n+plt.imshow(x_plot, interpolation='none', cmap='gray')\r\n plt.savefig('reconstructions.png')\r\n\n@@ -122,7 +122,7 @@ def kmeans(xs, k):\n     assert xs.ndim == 2\r\n     try:\r\n         from sklearn.cluster import k_means\r\n-        _, labels, _ = k_means(xs.astype(\"float64\"), k)\r\n+        _, labels, _ = k_means(xs.astype('float64'), k)\r\n     except ImportError:\r\n         from scipy.cluster.vq import kmeans2\r\n         _, labels = kmeans2(xs, k, missing='raise')\r\n@@ -179,8 +179,8 @@ images = K.concatenate([style_image, target_image, content_image], axis=0)\n \r\n # Create tensor variables for masks\r\n raw_style_mask, raw_target_mask = load_mask_labels()\r\n-style_mask = K.variable(raw_style_mask.astype(\"float32\"))\r\n-target_mask = K.variable(raw_target_mask.astype(\"float32\"))\r\n+style_mask = K.variable(raw_style_mask.astype('float32'))\r\n+target_mask = K.variable(raw_target_mask.astype('float32'))\r\n masks = K.concatenate([style_mask, target_mask], axis=0)\r\n \r\n # index constants for images and tasks variables\r\n@@ -191,13 +191,13 @@ STYLE, TARGET, CONTENT = 0, 1, 2\n image_model = vgg19.VGG19(include_top=False, input_tensor=images)\r\n \r\n # mask model as a series of pooling\r\n-mask_input = Input(tensor=masks, shape=(None, None, None), name=\"mask_input\")\r\n+mask_input = Input(tensor=masks, shape=(None, None, None), name='mask_input')\r\n x = mask_input\r\n for layer in image_model.layers[1:]:\r\n     name = 'mask_%s' % layer.name\r\n     if 'conv' in layer.name:\r\n         x = AveragePooling2D((3, 3), strides=(\r\n-            1, 1), name=name, border_mode=\"same\")(x)\r\n+            1, 1), name=name, border_mode='same')(x)\r\n     elif 'pool' in layer.name:\r\n         x = AveragePooling2D((2, 2), name=name)(x)\r\n mask_model = Model(mask_input, x)\r\n\n@@ -36,7 +36,7 @@ def gen_cosine_amp(amp=100, period=1000, x0=0, xn=50000, step=1, k=0.0001):\n     return cos\n \n \n-print('Generating Data')\n+print('Generating Data...')\n cos = gen_cosine_amp()\n print('Input shape:', cos.shape)\n \n@@ -44,13 +44,13 @@ expected_output = np.zeros((len(cos), 1))\n for i in range(len(cos) - lahead):\n     expected_output[i, 0] = np.mean(cos[i + 1:i + lahead + 1])\n \n-print('Output shape')\n-print(expected_output.shape)\n+print('Output shape:', expected_output.shape)\n \n-print('Creating Model')\n+print('Creating Model...')\n model = Sequential()\n model.add(LSTM(50,\n-               batch_input_shape=(batch_size, tsteps, 1),\n+               input_shape=(tsteps, 1),\n+               batch_size=batch_size,\n                return_sequences=True,\n                stateful=True))\n model.add(LSTM(50,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
