{"custom_id": "keras#e9d0e84281c9a06f06bb34b90982561e834cbd7a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 125 | Lines Deleted: 543 | Files Changed: 10 | Hunks: 33 | Methods Changed: 48 | Complexity Δ (Sum/Max): 19/16 | Churn Δ: 668 | Churn Cumulative: 5714 | Contributors (this commit): 14 | Commits (past 90d): 211 | Contributors (cumulative): 46 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1,291 +0,0 @@\n-\"\"\"\n-Title: Image classification with Vision Transformer\n-Author: [Khalid Salama](https://www.linkedin.com/in/khalid-salama-24403144/)\n-Date created: 2021/01/18\n-Last modified: 2021/01/18\n-Description: Implementing the Vision Transformer (ViT) model for image classification.\n-Accelerator: GPU\n-\"\"\"\n-\n-\"\"\"\n-## Introduction\n-\n-This example implements the [Vision Transformer (ViT)](https://arxiv.org/abs/2010.11929)\n-model by Alexey Dosovitskiy et al. for image classification,\n-and demonstrates it on the CIFAR-100 dataset.\n-The ViT model applies the Transformer architecture with self-attention to sequences of\n-image patches, without using convolution layers.\n-\n-\"\"\"\n-\n-\"\"\"\n-## Setup\n-\"\"\"\n-\n-import numpy as np\n-import tensorflow as tf\n-import keras_core as keras\n-from keras_core import layers\n-\n-\"\"\"\n-## Prepare the data\n-\"\"\"\n-\n-num_classes = 100\n-input_shape = (32, 32, 3)\n-\n-(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n-\n-print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n-print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")\n-\n-\n-\"\"\"\n-## Configure the hyperparameters\n-\"\"\"\n-\n-learning_rate = 0.001\n-weight_decay = 0.0001\n-batch_size = 256\n-num_epochs = 100\n-image_size = 72  # We'll resize input images to this size\n-patch_size = 6  # Size of the patches to be extract from the input images\n-num_patches = (image_size // patch_size) ** 2\n-projection_dim = 64\n-num_heads = 4\n-transformer_units = [\n-    projection_dim * 2,\n-    projection_dim,\n-]  # Size of the transformer layers\n-transformer_layers = 8\n-mlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier\n-\n-\n-\"\"\"\n-## Use data augmentation\n-\"\"\"\n-\n-data_augmentation = keras.Sequential(\n-    [\n-        layers.Normalization(),\n-        layers.Resizing(image_size, image_size),\n-        layers.RandomFlip(\"horizontal\"),\n-        layers.RandomRotation(factor=0.02),\n-        layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n-    ],\n-    name=\"data_augmentation\",\n-)\n-# Compute the mean and the variance of the training data for normalization.\n-data_augmentation.layers[0].adapt(x_train)\n-\n-\n-\"\"\"\n-## Implement multilayer perceptron (MLP)\n-\"\"\"\n-\n-\n-def mlp(x, hidden_units, dropout_rate):\n-    for units in hidden_units:\n-        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n-        x = layers.Dropout(dropout_rate)(x)\n-    return x\n-\n-\n-\"\"\"\n-## Implement patch creation as a layer\n-\"\"\"\n-\n-\n-class Patches(layers.Layer):\n-    def __init__(self, patch_size):\n-        super().__init__()\n-        self.patch_size = patch_size\n-\n-    def call(self, images):\n-        batch_size = tf.shape(images)[0]\n-        patches = tf.image.extract_patches(\n-            images=images,\n-            sizes=[1, self.patch_size, self.patch_size, 1],\n-            strides=[1, self.patch_size, self.patch_size, 1],\n-            rates=[1, 1, 1, 1],\n-            padding=\"VALID\",\n-        )\n-        patch_dims = patches.shape[-1]\n-        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n-        return patches\n-\n-\n-\"\"\"\n-Let's display patches for a sample image\n-\"\"\"\n-\n-import matplotlib.pyplot as plt\n-\n-plt.figure(figsize=(4, 4))\n-image = x_train[np.random.choice(range(x_train.shape[0]))]\n-plt.imshow(image.astype(\"uint8\"))\n-plt.axis(\"off\")\n-\n-resized_image = tf.image.resize(\n-    tf.convert_to_tensor([image]), size=(image_size, image_size)\n-)\n-patches = Patches(patch_size)(resized_image)\n-print(f\"Image size: {image_size} X {image_size}\")\n-print(f\"Patch size: {patch_size} X {patch_size}\")\n-print(f\"Patches per image: {patches.shape[1]}\")\n-print(f\"Elements per patch: {patches.shape[-1]}\")\n-\n-n = int(np.sqrt(patches.shape[1]))\n-plt.figure(figsize=(4, 4))\n-for i, patch in enumerate(patches[0]):\n-    ax = plt.subplot(n, n, i + 1)\n-    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n-    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n-    plt.axis(\"off\")\n-\n-\"\"\"\n-## Implement the patch encoding layer\n-\n-The `PatchEncoder` layer will linearly transform a patch by projecting it into a\n-vector of size `projection_dim`. In addition, it adds a learnable position\n-embedding to the projected vector.\n-\"\"\"\n-\n-\n-class PatchEncoder(layers.Layer):\n-    def __init__(self, num_patches, projection_dim):\n-        super().__init__()\n-        self.num_patches = num_patches\n-        self.projection = layers.Dense(units=projection_dim)\n-        self.position_embedding = layers.Embedding(\n-            input_dim=num_patches, output_dim=projection_dim\n-        )\n-\n-    def call(self, patch):\n-        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n-        encoded = self.projection(patch) + self.position_embedding(positions)\n-        return encoded\n-\n-\n-\"\"\"\n-## Build the ViT model\n-\n-The ViT model consists of multiple Transformer blocks,\n-which use the `layers.MultiHeadAttention` layer as a self-attention mechanism\n-applied to the sequence of patches. The Transformer blocks produce a\n-`[batch_size, num_patches, projection_dim]` tensor, which is processed via an\n-classifier head with softmax to produce the final class probabilities output.\n-\n-Unlike the technique described in the [paper](https://arxiv.org/abs/2010.11929),\n-which prepends a learnable embedding to the sequence of encoded patches to serve\n-as the image representation, all the outputs of the final Transformer block are\n-reshaped with `layers.Flatten()` and used as the image\n-representation input to the classifier head.\n-Note that the `layers.GlobalAveragePooling1D` layer\n-could also be used instead to aggregate the outputs of the Transformer block,\n-especially when the number of patches and the projection dimensions are large.\n-\"\"\"\n-\n-\n-def create_vit_classifier():\n-    inputs = layers.Input(shape=input_shape)\n-    # Augment data.\n-    augmented = data_augmentation(inputs)\n-    # Create patches.\n-    patches = Patches(patch_size)(augmented)\n-    # Encode patches.\n-    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n-\n-    # Create multiple layers of the Transformer block.\n-    for _ in range(transformer_layers):\n-        # Layer normalization 1.\n-        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n-        # Create a multi-head attention layer.\n-        attention_output = layers.MultiHeadAttention(\n-            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n-        )(x1, x1)\n-        # Skip connection 1.\n-        x2 = layers.Add()([attention_output, encoded_patches])\n-        # Layer normalization 2.\n-        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n-        # MLP.\n-        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n-        # Skip connection 2.\n-        encoded_patches = layers.Add()([x3, x2])\n-\n-    # Create a [batch_size, projection_dim] tensor.\n-    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n-    representation = layers.Flatten()(representation)\n-    representation = layers.Dropout(0.5)(representation)\n-    # Add MLP.\n-    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n-    # Classify outputs.\n-    logits = layers.Dense(num_classes)(features)\n-    # Create the Keras model.\n-    model = keras.Model(inputs=inputs, outputs=logits)\n-    return model\n-\n-\n-\"\"\"\n-## Compile, train, and evaluate the mode\n-\"\"\"\n-\n-\n-def run_experiment(model):\n-    optimizer = keras.optimizers.AdamW(\n-        learning_rate=learning_rate, weight_decay=weight_decay\n-    )\n-\n-    model.compile(\n-        optimizer=optimizer,\n-        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n-        metrics=[\n-            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n-            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n-        ],\n-    )\n-\n-    checkpoint_filepath = \"/tmp/checkpoint\"\n-    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n-        checkpoint_filepath,\n-        monitor=\"val_accuracy\",\n-        save_best_only=True,\n-        save_weights_only=True,\n-    )\n-\n-    history = model.fit(\n-        x=x_train,\n-        y=y_train,\n-        batch_size=batch_size,\n-        epochs=num_epochs,\n-        validation_split=0.1,\n-        callbacks=[checkpoint_callback],\n-    )\n-\n-    model.load_weights(checkpoint_filepath)\n-    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n-    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n-    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n-\n-    return history\n-\n-\n-vit_classifier = create_vit_classifier()\n-history = run_experiment(vit_classifier)\n-\n-\n-\"\"\"\n-After 100 epochs, the ViT model achieves around 55% accuracy and\n-82% top-5 accuracy on the test data. These are not competitive results on the CIFAR-100 dataset,\n-as a ResNet50V2 trained from scratch on the same data can achieve 67% accuracy.\n-\n-Note that the state of the art results reported in the\n-[paper](https://arxiv.org/abs/2010.11929) are achieved by pre-training the ViT model using\n-the JFT-300M dataset, then fine-tuning it on the target dataset. To improve the model quality\n-without pre-training, you can try to train the model for more epochs, use a larger number of\n-Transformer layers, resize the input images, change the patch size, or increase the projection dimensions. \n-Besides, as mentioned in the paper, the quality of the model is affected not only by architecture choices, \n-but also by parameters such as the learning rate schedule, optimizer, weight decay, etc.\n-In practice, it's recommended to fine-tune a ViT model\n-that was pre-trained using a large, high-resolution dataset.\n-\"\"\"\n\\ No newline at end of file\n\n@@ -1,229 +0,0 @@\n-\"\"\"\n-Title: MixUp augmentation for image classification\n-Author: [Sayak Paul](https://twitter.com/RisingSayak)\n-Date created: 2021/03/06\n-Last modified: 2021/03/06\n-Description: Data augmentation using the mixup technique for image classification.\n-Accelerator: GPU\n-\"\"\"\n-\"\"\"\n-## Introduction\n-\"\"\"\n-\n-\"\"\"\n-_mixup_ is a *domain-agnostic* data augmentation technique proposed in [mixup: Beyond Empirical Risk Minimization](https://arxiv.org/abs/1710.09412)\n-by Zhang et al. It's implemented with the following formulas:\n-\n-![](https://i.ibb.co/DRyHYww/image.png)\n-\n-(Note that the lambda values are values with the [0, 1] range and are sampled from the\n-[Beta distribution](https://en.wikipedia.org/wiki/Beta_distribution).)\n-\n-The technique is quite systematically named. We are literally mixing up the features and\n-their corresponding labels. Implementation-wise it's simple. Neural networks are prone\n-to [memorizing corrupt labels](https://arxiv.org/abs/1611.03530). mixup relaxes this by\n-combining different features with one another (same happens for the labels too) so that\n-a network does not get overconfident about the relationship between the features and\n-their labels.\n-\n-mixup is specifically useful when we are not sure about selecting a set of augmentation\n-transforms for a given dataset, medical imaging datasets, for example. mixup can be\n-extended to a variety of data modalities such as computer vision, naturallanguage\n-processing, speech, and so on.\n-\"\"\"\n-\n-\"\"\"\n-## Setup\n-\"\"\"\n-\n-import numpy as np\n-import tensorflow as tf\n-import matplotlib.pyplot as plt\n-from keras_core import layers\n-import keras_core as keras\n-\n-\"\"\"\n-## Prepare the dataset\n-\n-In this example, we will be using the [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist) dataset. But this same recipe can\n-be used for other classification datasets as well.\n-\"\"\"\n-\n-(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n-\n-x_train = x_train.astype(\"float32\") / 255.0\n-x_train = np.reshape(x_train, (-1, 28, 28, 1))\n-y_train = tf.one_hot(y_train, 10)\n-\n-x_test = x_test.astype(\"float32\") / 255.0\n-x_test = np.reshape(x_test, (-1, 28, 28, 1))\n-y_test = tf.one_hot(y_test, 10)\n-\n-\"\"\"\n-## Define hyperparameters\n-\"\"\"\n-\n-AUTO = tf.data.AUTOTUNE\n-BATCH_SIZE = 64\n-EPOCHS = 10\n-\n-\"\"\"\n-## Convert the data into TensorFlow `Dataset` objects\n-\"\"\"\n-\n-# Put aside a few samples to create our validation set\n-val_samples = 2000\n-x_val, y_val = x_train[:val_samples], y_train[:val_samples]\n-new_x_train, new_y_train = x_train[val_samples:], y_train[val_samples:]\n-\n-train_ds_one = (\n-    tf.data.Dataset.from_tensor_slices((new_x_train, new_y_train))\n-    .shuffle(BATCH_SIZE * 100)\n-    .batch(BATCH_SIZE)\n-)\n-train_ds_two = (\n-    tf.data.Dataset.from_tensor_slices((new_x_train, new_y_train))\n-    .shuffle(BATCH_SIZE * 100)\n-    .batch(BATCH_SIZE)\n-)\n-# Because we will be mixing up the images and their corresponding labels, we will be\n-# combining two shuffled datasets from the same training data.\n-train_ds = tf.data.Dataset.zip((train_ds_one, train_ds_two))\n-\n-val_ds = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(BATCH_SIZE)\n-\n-test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(BATCH_SIZE)\n-\n-\"\"\"\n-## Define the mixup technique function\n-\n-To perform the mixup routine, we create new virtual datasets using the training data from\n-the same dataset, and apply a lambda value within the [0, 1] range sampled from a [Beta distribution](https://en.wikipedia.org/wiki/Beta_distribution)\n-— such that, for example, `new_x = lambda * x1 + (1 - lambda) * x2` (where\n-`x1` and `x2` are images) and the same equation is applied to the labels as well.\n-\"\"\"\n-\n-\n-def sample_beta_distribution(size, concentration_0=0.2, concentration_1=0.2):\n-    gamma_1_sample = tf.random.gamma(shape=[size], alpha=concentration_1)\n-    gamma_2_sample = tf.random.gamma(shape=[size], alpha=concentration_0)\n-    return gamma_1_sample / (gamma_1_sample + gamma_2_sample)\n-\n-\n-def mix_up(ds_one, ds_two, alpha=0.2):\n-    # Unpack two datasets\n-    images_one, labels_one = ds_one\n-    images_two, labels_two = ds_two\n-    batch_size = tf.shape(images_one)[0]\n-\n-    # Sample lambda and reshape it to do the mixup\n-    l = sample_beta_distribution(batch_size, alpha, alpha)\n-    x_l = tf.reshape(l, (batch_size, 1, 1, 1))\n-    y_l = tf.reshape(l, (batch_size, 1))\n-\n-    # Perform mixup on both images and labels by combining a pair of images/labels\n-    # (one from each dataset) into one image/label\n-    images = images_one * x_l + images_two * (1 - x_l)\n-    labels = labels_one * y_l + labels_two * (1 - y_l)\n-    return (images, labels)\n-\n-\n-\"\"\"\n-**Note** that here , we are combining two images to create a single one. Theoretically,\n-we can combine as many we want but that comes at an increased computation cost. In\n-certain cases, it may not help improve the performance as well.\n-\"\"\"\n-\n-\"\"\"\n-## Visualize the new augmented dataset\n-\"\"\"\n-\n-# First create the new dataset using our `mix_up` utility\n-train_ds_mu = train_ds.map(\n-    lambda ds_one, ds_two: mix_up(ds_one, ds_two, alpha=0.2), num_parallel_calls=AUTO\n-)\n-\n-# Let's preview 9 samples from the dataset\n-sample_images, sample_labels = next(iter(train_ds_mu))\n-plt.figure(figsize=(10, 10))\n-for i, (image, label) in enumerate(zip(sample_images[:9], sample_labels[:9])):\n-    ax = plt.subplot(3, 3, i + 1)\n-    plt.imshow(image.numpy().squeeze())\n-    print(label.numpy().tolist())\n-    plt.axis(\"off\")\n-\n-\"\"\"\n-## Model building\n-\"\"\"\n-\n-\n-def get_training_model():\n-    model = keras.Sequential(\n-        [\n-            layers.Conv2D(16, (5, 5), activation=\"relu\", input_shape=(28, 28, 1)),\n-            layers.MaxPooling2D(pool_size=(2, 2)),\n-            layers.Conv2D(32, (5, 5), activation=\"relu\"),\n-            layers.MaxPooling2D(pool_size=(2, 2)),\n-            layers.Dropout(0.2),\n-            layers.GlobalAveragePooling2D(),\n-            layers.Dense(128, activation=\"relu\"),\n-            layers.Dense(10, activation=\"softmax\"),\n-        ]\n-    )\n-    return model\n-\n-\n-\"\"\"\n-For the sake of reproducibility, we serialize the initial random weights of our shallow\n-network.\n-\"\"\"\n-\n-initial_model = get_training_model()\n-initial_model.save_weights(\"initial_weights.weights.h5\")\n-\n-\"\"\"\n-## 1. Train the model with the mixed up dataset\n-\"\"\"\n-\n-model = get_training_model()\n-model.load_weights(\"initial_weights.weights.h5\")\n-model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n-model.fit(train_ds_mu, validation_data=val_ds, epochs=EPOCHS)\n-_, test_acc = model.evaluate(test_ds)\n-print(\"Test accuracy: {:.2f}%\".format(test_acc * 100))\n-\n-\"\"\"\n-## 2. Train the model *without* the mixed up dataset\n-\"\"\"\n-\n-model = get_training_model()\n-model.load_weights(\"initial_weights.weights.h5\")\n-model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n-# Notice that we are NOT using the mixed up dataset here\n-model.fit(train_ds_one, validation_data=val_ds, epochs=EPOCHS)\n-_, test_acc = model.evaluate(test_ds)\n-print(\"Test accuracy: {:.2f}%\".format(test_acc * 100))\n-\n-\"\"\"\n-Readers are encouraged to try out mixup on different datasets from different domains and\n-experiment with the lambda parameter. You are strongly advised to check out the\n-[original paper](https://arxiv.org/abs/1710.09412) as well - the authors present several ablation studies on mixup\n-showing how it can improve generalization, as well as show their results of combining\n-more than two images to create a single one.\n-\"\"\"\n-\n-\"\"\"\n-## Notes\n-\n-* With mixup, you can create synthetic examples — especially when you lack a large\n-dataset - without incurring high computational costs.\n-* [Label smoothing](https://www.pyimagesearch.com/2019/12/30/label-smoothing-with-keras-tensorflow-and-deep-learning/) and mixup usually do not work well together because label smoothing\n-already modifies the hard labels by some factor.\n-* mixup does not work well when you are using [Supervised Contrastive\n-Learning](https://arxiv.org/abs/2004.11362) (SCL) since SCL expects the true labels\n-during its pre-training phase.\n-* A few other benefits of mixup include (as described in the [paper](https://arxiv.org/abs/1710.09412)) robustness to\n-adversarial examples and stabilized GAN (Generative Adversarial Networks) training.\n-* There are a number of data augmentation techniques that extend mixup such as\n-[CutMix](https://arxiv.org/abs/1905.04899) and [AugMix](https://arxiv.org/abs/1912.02781).\n-\"\"\"\n\\ No newline at end of file\n\n@@ -30,9 +30,8 @@ def categorical(logits, num_samples, dtype=\"int32\", seed=None):\n     logits = convert_to_tensor(logits)\n     dtype = to_torch_dtype(dtype)\n     generator = torch_seed_generator(seed, device=get_device())\n-    probs = torch.softmax(logits, dim=-1)\n     return torch.multinomial(\n-        probs,\n+        logits,\n         num_samples,\n         replacement=True,\n         generator=generator,\n\n@@ -77,65 +77,81 @@ class CallbackList(Callback):\n             callback.set_model(model)\n \n     def on_batch_begin(self, batch, logs=None):\n+        logs = logs or {}\n         for callback in self.callbacks:\n             callback.on_batch_begin(batch, logs=logs)\n \n     def on_batch_end(self, batch, logs=None):\n+        logs = logs or {}\n         for callback in self.callbacks:\n             callback.on_batch_end(batch, logs=logs)\n \n     def on_epoch_begin(self, epoch, logs=None):\n+        logs = logs or {}\n         for callback in self.callbacks:\n             callback.on_epoch_begin(epoch, logs)\n \n     def on_epoch_end(self, epoch, logs=None):\n+        logs = logs or {}\n         for callback in self.callbacks:\n             callback.on_epoch_end(epoch, logs)\n \n     def on_train_batch_begin(self, batch, logs=None):\n+        logs = logs or {}\n         for callback in self.callbacks:\n             callback.on_train_batch_begin(batch, logs=logs)\n \n     def on_train_batch_end(self, batch, logs=None):\n+        logs = logs or {}\n         for callback in self.callbacks:\n             callback.on_train_batch_end(batch, logs=logs)\n \n     def on_test_batch_begin(self, batch, logs=None):\n+        logs = logs or {}\n         for callback in self.callbacks:\n             callback.on_test_batch_begin(batch, logs=logs)\n \n     def on_test_batch_end(self, batch, logs=None):\n+        logs = logs or {}\n         for callback in self.callbacks:\n             callback.on_test_batch_end(batch, logs=logs)\n \n     def on_predict_batch_begin(self, batch, logs=None):\n+        logs = logs or {}\n         for callback in self.callbacks:\n             callback.on_predict_batch_begin(batch, logs=logs)\n \n     def on_predict_batch_end(self, batch, logs=None):\n+        logs = logs or {}\n         for callback in self.callbacks:\n             callback.on_predict_batch_end(batch, logs=logs)\n \n     def on_train_begin(self, logs=None):\n+        logs = logs or {}\n         for callback in self.callbacks:\n             callback.on_train_begin(logs)\n \n     def on_train_end(self, logs=None):\n+        logs = logs or {}\n         for callback in self.callbacks:\n             callback.on_train_end(logs)\n \n     def on_test_begin(self, logs=None):\n+        logs = logs or {}\n         for callback in self.callbacks:\n             callback.on_test_begin(logs)\n \n     def on_test_end(self, logs=None):\n+        logs = logs or {}\n         for callback in self.callbacks:\n             callback.on_test_end(logs)\n \n     def on_predict_begin(self, logs=None):\n+        logs = logs or {}\n         for callback in self.callbacks:\n             callback.on_predict_begin(logs)\n \n     def on_predict_end(self, logs=None):\n+        logs = logs or {}\n         for callback in self.callbacks:\n             callback.on_predict_end(logs)\n\n@@ -82,6 +82,7 @@ class Dense(Layer):\n         self.bias_constraint = constraints.get(bias_constraint)\n \n         self.input_spec = InputSpec(min_ndim=2)\n+        self.supports_masking = True\n \n     def build(self, input_shape):\n         input_dim = input_shape[-1]\n\n@@ -248,6 +248,9 @@ class Layer(BackendLayer, Operation):\n         self._trainable = trainable\n         self._losses = []\n \n+        self._call_signature_parameters = [\n+            p.name for p in inspect.signature(self.call).parameters.values()\n+        ]\n         self._supports_masking = not utils.is_default(self.compute_mask)\n         # Whether to automatically convert (+ auto-cast) inputs to `call()`.\n         self._convert_input_args = True\n@@ -255,9 +258,6 @@ class Layer(BackendLayer, Operation):\n         self._allow_non_tensor_positional_args = False\n         # Dict of shapes that were used to call `build()`.\n         self._build_shapes_dict = None\n-        self._call_signature_parameters = [\n-            p.name for p in inspect.signature(self.call).parameters.values()\n-        ]\n         self._initializer_tracker()\n \n     @tracking.no_automatic_dependency_tracking\n@@ -606,7 +606,6 @@ class Layer(BackendLayer, Operation):\n \n         ##############################\n         # 6. Populate mask argument(s)\n-        if self.supports_masking:\n         if len(call_spec.tensor_arguments_dict) == 1:\n             if (\n                 \"mask\" in call_spec.argument_names\n@@ -623,10 +622,7 @@ class Layer(BackendLayer, Operation):\n             for k, v in call_spec.tensor_arguments_dict.items():\n                 expected_mask_arg_name = f\"{k}_mask\"\n                 if expected_mask_arg_name in call_spec.argument_names:\n-                        if (\n-                            call_spec.arguments_dict[expected_mask_arg_name]\n-                            is None\n-                        ):\n+                    if call_spec.arguments_dict[expected_mask_arg_name] is None:\n                         mask = nest.map_structure(\n                             lambda x: getattr(x, \"_keras_mask\", None), v\n                         )\n@@ -651,16 +647,22 @@ class Layer(BackendLayer, Operation):\n                         if backend.is_tensor(output):\n                             self.add_loss(self.activity_regularizer(output))\n \n-            if self.supports_masking:\n             # Set masks on outputs,\n             # provided only the first positional input arg and its mask.\n             # TODO: consider extending this to all args and kwargs.\n-                previous_mask = getattr(\n-                    call_spec.first_arg, \"_keras_mask\", None\n-                )\n+            previous_mask = getattr(call_spec.first_arg, \"_keras_mask\", None)\n+            if self.supports_masking:\n                 self._set_mask_metadata(\n                     call_spec.first_arg, outputs, previous_mask\n                 )\n+            elif previous_mask is not None:\n+                warnings.warn(\n+                    f\"Layer '{self.name}' (of type {self.__class__.__name__}) \"\n+                    \"was passed an input with a mask attached to it. \"\n+                    \"However, this layer does not support masking and will \"\n+                    \"therefore destroy the mask information. Downstream \"\n+                    \"layers will not see the mask.\"\n+                )\n         finally:\n             # Destroy call context if we created it\n             self._maybe_reset_call_context()\n\n@@ -11,8 +11,6 @@ convert_to_tensor\n convert_to_numpy\n \"\"\"\n \n-import numpy as np\n-\n from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.backend import KerasTensor\n@@ -298,7 +296,9 @@ def convert_to_tensor(x, dtype=None):\n def convert_to_numpy(x):\n     \"\"\"Convert a tensor to a NumPy array.\"\"\"\n     if any_symbolic_tensors((x,)):\n-        # This will raise a `ValueError` defined in the `KerasTensor` class. We\n-        # trigger it rather than duplicate it here.\n-        return np.array(x)\n+        raise ValueError(\n+            \"A symbolic tensor (usually the result of applying layers or \"\n+            \"operations to a `keras.Input`), cannot be converted to a numpy \"\n+            \"array. There is no concrete value for the input.\"\n+        )\n     return backend.convert_to_numpy(x)\n\n@@ -71,7 +71,8 @@ class Operation:\n                 f\"'{self.name}' (of type {self.__class__.__name__}). \"\n                 f\"Either the `{self.__class__.__name__}.call()` method \"\n                 f\"is incorrect, or you need to implement the \"\n-                f\"`{self.__class__.__name__}.compute_output_spec()` method. \"\n+                f\"`{self.__class__.__name__}.compute_output_spec() / \"\n+                \"compute_output_shape()` method. \"\n                 f\"Error encountered:\\n\\n{e}\"\n             )\n             raise new_e.with_traceback(e.__traceback__) from None\n\n@@ -48,9 +48,8 @@ class RandomTest(testing.TestCase, parameterized.TestCase):\n     )\n     def test_categorical(self, seed, num_samples, batch_size):\n         np.random.seed(seed)\n-        # Create logits that definitely favors the batch index after a softmax\n-        # is applied. Without a softmax, this would be close to random.\n-        logits = np.eye(batch_size) * 1e5 + 1e6\n+        # Definitively favor the batch index.\n+        logits = np.eye(batch_size) * 1e9\n         res = random.categorical(logits, num_samples, seed=seed)\n         # Outputs should have shape `(batch_size, num_samples)`, where each\n         # output index matches the batch index.\n\n@@ -347,3 +347,87 @@ class TestTrainer(testing.TestCase, parameterized.TestCase):\n         x1, x2 = np.random.rand(2, 3, 4)\n         out = model.predict({\"a\": x1, \"b\": x2})\n         self.assertEqual(out.shape, (3, 4))\n+\n+    def test_callback_methods_keys(self):\n+        class CustomCallback(Callback):\n+            def on_train_begin(self, logs=None):\n+                keys = sorted(list(logs.keys()))\n+                assert keys == []\n+\n+            def on_train_end(self, logs=None):\n+                keys = sorted(list(logs.keys()))\n+                assert keys == [\n+                    \"loss\",\n+                    \"mean_absolute_error\",\n+                    \"val_loss\",\n+                    \"val_mean_absolute_error\",\n+                ]\n+\n+            def on_epoch_begin(self, epoch, logs=None):\n+                keys = sorted(list(logs.keys()))\n+                assert keys == []\n+\n+            def on_epoch_end(self, epoch, logs=None):\n+                keys = sorted(list(logs.keys()))\n+                assert keys == [\n+                    \"loss\",\n+                    \"mean_absolute_error\",\n+                    \"val_loss\",\n+                    \"val_mean_absolute_error\",\n+                ]\n+\n+            def on_test_begin(self, logs=None):\n+                keys = sorted(list(logs.keys()))\n+                assert keys == []\n+\n+            def on_test_end(self, logs=None):\n+                keys = sorted(list(logs.keys()))\n+                assert keys == [\"loss\", \"mean_absolute_error\"]\n+\n+            def on_predict_begin(self, logs=None):\n+                keys = sorted(list(logs.keys()))\n+                assert keys == []\n+\n+            def on_predict_end(self, logs=None):\n+                keys = sorted(list(logs.keys()))\n+                assert keys == []\n+\n+            def on_train_batch_begin(self, batch, logs=None):\n+                keys = sorted(list(logs.keys()))\n+                assert keys == []\n+\n+            def on_train_batch_end(self, batch, logs=None):\n+                keys = sorted(list(logs.keys()))\n+                assert keys == [\"loss\", \"mean_absolute_error\"]\n+\n+            def on_test_batch_begin(self, batch, logs=None):\n+                keys = sorted(list(logs.keys()))\n+                assert keys == []\n+\n+            def on_test_batch_end(self, batch, logs=None):\n+                keys = sorted(list(logs.keys()))\n+                assert keys == [\"loss\", \"mean_absolute_error\"]\n+\n+            def on_predict_batch_begin(self, batch, logs=None):\n+                keys = sorted(list(logs.keys()))\n+                assert keys == []\n+\n+            def on_predict_batch_end(self, batch, logs=None):\n+                keys = sorted(list(logs.keys()))\n+                assert keys == [\"outputs\"]\n+\n+        model = ExampleModel(units=3)\n+        model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n+        x = np.ones((16, 4))\n+        y = np.zeros((16, 3))\n+        x_test = np.ones((16, 4))\n+        y_test = np.zeros((16, 3))\n+        model.fit(\n+            x,\n+            y,\n+            callbacks=[CustomCallback()],\n+            batch_size=4,\n+            validation_data=(x_test, y_test),\n+        )\n+        model.evaluate(x_test, y_test, batch_size=4)\n+        model.predict(x_test, batch_size=4)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#567e1aad53694913a04aad3ed1d6160b25b952f2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 530 | Lines Deleted: 8 | Files Changed: 5 | Hunks: 7 | Methods Changed: 13 | Complexity Δ (Sum/Max): 12/9 | Churn Δ: 538 | Churn Cumulative: 3260 | Contributors (this commit): 10 | Commits (past 90d): 59 | Contributors (cumulative): 20 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,291 @@\n+\"\"\"\n+Title: Image classification with Vision Transformer\n+Author: [Khalid Salama](https://www.linkedin.com/in/khalid-salama-24403144/)\n+Date created: 2021/01/18\n+Last modified: 2021/01/18\n+Description: Implementing the Vision Transformer (ViT) model for image classification.\n+Accelerator: GPU\n+\"\"\"\n+\n+\"\"\"\n+## Introduction\n+\n+This example implements the [Vision Transformer (ViT)](https://arxiv.org/abs/2010.11929)\n+model by Alexey Dosovitskiy et al. for image classification,\n+and demonstrates it on the CIFAR-100 dataset.\n+The ViT model applies the Transformer architecture with self-attention to sequences of\n+image patches, without using convolution layers.\n+\n+\"\"\"\n+\n+\"\"\"\n+## Setup\n+\"\"\"\n+\n+import numpy as np\n+import tensorflow as tf\n+import keras_core as keras\n+from keras_core import layers\n+\n+\"\"\"\n+## Prepare the data\n+\"\"\"\n+\n+num_classes = 100\n+input_shape = (32, 32, 3)\n+\n+(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n+\n+print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n+print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")\n+\n+\n+\"\"\"\n+## Configure the hyperparameters\n+\"\"\"\n+\n+learning_rate = 0.001\n+weight_decay = 0.0001\n+batch_size = 256\n+num_epochs = 100\n+image_size = 72  # We'll resize input images to this size\n+patch_size = 6  # Size of the patches to be extract from the input images\n+num_patches = (image_size // patch_size) ** 2\n+projection_dim = 64\n+num_heads = 4\n+transformer_units = [\n+    projection_dim * 2,\n+    projection_dim,\n+]  # Size of the transformer layers\n+transformer_layers = 8\n+mlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier\n+\n+\n+\"\"\"\n+## Use data augmentation\n+\"\"\"\n+\n+data_augmentation = keras.Sequential(\n+    [\n+        layers.Normalization(),\n+        layers.Resizing(image_size, image_size),\n+        layers.RandomFlip(\"horizontal\"),\n+        layers.RandomRotation(factor=0.02),\n+        layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n+    ],\n+    name=\"data_augmentation\",\n+)\n+# Compute the mean and the variance of the training data for normalization.\n+data_augmentation.layers[0].adapt(x_train)\n+\n+\n+\"\"\"\n+## Implement multilayer perceptron (MLP)\n+\"\"\"\n+\n+\n+def mlp(x, hidden_units, dropout_rate):\n+    for units in hidden_units:\n+        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n+        x = layers.Dropout(dropout_rate)(x)\n+    return x\n+\n+\n+\"\"\"\n+## Implement patch creation as a layer\n+\"\"\"\n+\n+\n+class Patches(layers.Layer):\n+    def __init__(self, patch_size):\n+        super().__init__()\n+        self.patch_size = patch_size\n+\n+    def call(self, images):\n+        batch_size = tf.shape(images)[0]\n+        patches = tf.image.extract_patches(\n+            images=images,\n+            sizes=[1, self.patch_size, self.patch_size, 1],\n+            strides=[1, self.patch_size, self.patch_size, 1],\n+            rates=[1, 1, 1, 1],\n+            padding=\"VALID\",\n+        )\n+        patch_dims = patches.shape[-1]\n+        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n+        return patches\n+\n+\n+\"\"\"\n+Let's display patches for a sample image\n+\"\"\"\n+\n+import matplotlib.pyplot as plt\n+\n+plt.figure(figsize=(4, 4))\n+image = x_train[np.random.choice(range(x_train.shape[0]))]\n+plt.imshow(image.astype(\"uint8\"))\n+plt.axis(\"off\")\n+\n+resized_image = tf.image.resize(\n+    tf.convert_to_tensor([image]), size=(image_size, image_size)\n+)\n+patches = Patches(patch_size)(resized_image)\n+print(f\"Image size: {image_size} X {image_size}\")\n+print(f\"Patch size: {patch_size} X {patch_size}\")\n+print(f\"Patches per image: {patches.shape[1]}\")\n+print(f\"Elements per patch: {patches.shape[-1]}\")\n+\n+n = int(np.sqrt(patches.shape[1]))\n+plt.figure(figsize=(4, 4))\n+for i, patch in enumerate(patches[0]):\n+    ax = plt.subplot(n, n, i + 1)\n+    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n+    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n+    plt.axis(\"off\")\n+\n+\"\"\"\n+## Implement the patch encoding layer\n+\n+The `PatchEncoder` layer will linearly transform a patch by projecting it into a\n+vector of size `projection_dim`. In addition, it adds a learnable position\n+embedding to the projected vector.\n+\"\"\"\n+\n+\n+class PatchEncoder(layers.Layer):\n+    def __init__(self, num_patches, projection_dim):\n+        super().__init__()\n+        self.num_patches = num_patches\n+        self.projection = layers.Dense(units=projection_dim)\n+        self.position_embedding = layers.Embedding(\n+            input_dim=num_patches, output_dim=projection_dim\n+        )\n+\n+    def call(self, patch):\n+        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n+        encoded = self.projection(patch) + self.position_embedding(positions)\n+        return encoded\n+\n+\n+\"\"\"\n+## Build the ViT model\n+\n+The ViT model consists of multiple Transformer blocks,\n+which use the `layers.MultiHeadAttention` layer as a self-attention mechanism\n+applied to the sequence of patches. The Transformer blocks produce a\n+`[batch_size, num_patches, projection_dim]` tensor, which is processed via an\n+classifier head with softmax to produce the final class probabilities output.\n+\n+Unlike the technique described in the [paper](https://arxiv.org/abs/2010.11929),\n+which prepends a learnable embedding to the sequence of encoded patches to serve\n+as the image representation, all the outputs of the final Transformer block are\n+reshaped with `layers.Flatten()` and used as the image\n+representation input to the classifier head.\n+Note that the `layers.GlobalAveragePooling1D` layer\n+could also be used instead to aggregate the outputs of the Transformer block,\n+especially when the number of patches and the projection dimensions are large.\n+\"\"\"\n+\n+\n+def create_vit_classifier():\n+    inputs = layers.Input(shape=input_shape)\n+    # Augment data.\n+    augmented = data_augmentation(inputs)\n+    # Create patches.\n+    patches = Patches(patch_size)(augmented)\n+    # Encode patches.\n+    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n+\n+    # Create multiple layers of the Transformer block.\n+    for _ in range(transformer_layers):\n+        # Layer normalization 1.\n+        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n+        # Create a multi-head attention layer.\n+        attention_output = layers.MultiHeadAttention(\n+            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n+        )(x1, x1)\n+        # Skip connection 1.\n+        x2 = layers.Add()([attention_output, encoded_patches])\n+        # Layer normalization 2.\n+        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n+        # MLP.\n+        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n+        # Skip connection 2.\n+        encoded_patches = layers.Add()([x3, x2])\n+\n+    # Create a [batch_size, projection_dim] tensor.\n+    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n+    representation = layers.Flatten()(representation)\n+    representation = layers.Dropout(0.5)(representation)\n+    # Add MLP.\n+    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n+    # Classify outputs.\n+    logits = layers.Dense(num_classes)(features)\n+    # Create the Keras model.\n+    model = keras.Model(inputs=inputs, outputs=logits)\n+    return model\n+\n+\n+\"\"\"\n+## Compile, train, and evaluate the mode\n+\"\"\"\n+\n+\n+def run_experiment(model):\n+    optimizer = keras.optimizers.AdamW(\n+        learning_rate=learning_rate, weight_decay=weight_decay\n+    )\n+\n+    model.compile(\n+        optimizer=optimizer,\n+        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n+        metrics=[\n+            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n+            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n+        ],\n+    )\n+\n+    checkpoint_filepath = \"/tmp/checkpoint\"\n+    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n+        checkpoint_filepath,\n+        monitor=\"val_accuracy\",\n+        save_best_only=True,\n+        save_weights_only=True,\n+    )\n+\n+    history = model.fit(\n+        x=x_train,\n+        y=y_train,\n+        batch_size=batch_size,\n+        epochs=num_epochs,\n+        validation_split=0.1,\n+        callbacks=[checkpoint_callback],\n+    )\n+\n+    model.load_weights(checkpoint_filepath)\n+    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n+    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n+    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n+\n+    return history\n+\n+\n+vit_classifier = create_vit_classifier()\n+history = run_experiment(vit_classifier)\n+\n+\n+\"\"\"\n+After 100 epochs, the ViT model achieves around 55% accuracy and\n+82% top-5 accuracy on the test data. These are not competitive results on the CIFAR-100 dataset,\n+as a ResNet50V2 trained from scratch on the same data can achieve 67% accuracy.\n+\n+Note that the state of the art results reported in the\n+[paper](https://arxiv.org/abs/2010.11929) are achieved by pre-training the ViT model using\n+the JFT-300M dataset, then fine-tuning it on the target dataset. To improve the model quality\n+without pre-training, you can try to train the model for more epochs, use a larger number of\n+Transformer layers, resize the input images, change the patch size, or increase the projection dimensions. \n+Besides, as mentioned in the paper, the quality of the model is affected not only by architecture choices, \n+but also by parameters such as the learning rate schedule, optimizer, weight decay, etc.\n+In practice, it's recommended to fine-tune a ViT model\n+that was pre-trained using a large, high-resolution dataset.\n+\"\"\"\n\\ No newline at end of file\n\n@@ -0,0 +1,229 @@\n+\"\"\"\n+Title: MixUp augmentation for image classification\n+Author: [Sayak Paul](https://twitter.com/RisingSayak)\n+Date created: 2021/03/06\n+Last modified: 2021/03/06\n+Description: Data augmentation using the mixup technique for image classification.\n+Accelerator: GPU\n+\"\"\"\n+\"\"\"\n+## Introduction\n+\"\"\"\n+\n+\"\"\"\n+_mixup_ is a *domain-agnostic* data augmentation technique proposed in [mixup: Beyond Empirical Risk Minimization](https://arxiv.org/abs/1710.09412)\n+by Zhang et al. It's implemented with the following formulas:\n+\n+![](https://i.ibb.co/DRyHYww/image.png)\n+\n+(Note that the lambda values are values with the [0, 1] range and are sampled from the\n+[Beta distribution](https://en.wikipedia.org/wiki/Beta_distribution).)\n+\n+The technique is quite systematically named. We are literally mixing up the features and\n+their corresponding labels. Implementation-wise it's simple. Neural networks are prone\n+to [memorizing corrupt labels](https://arxiv.org/abs/1611.03530). mixup relaxes this by\n+combining different features with one another (same happens for the labels too) so that\n+a network does not get overconfident about the relationship between the features and\n+their labels.\n+\n+mixup is specifically useful when we are not sure about selecting a set of augmentation\n+transforms for a given dataset, medical imaging datasets, for example. mixup can be\n+extended to a variety of data modalities such as computer vision, naturallanguage\n+processing, speech, and so on.\n+\"\"\"\n+\n+\"\"\"\n+## Setup\n+\"\"\"\n+\n+import numpy as np\n+import tensorflow as tf\n+import matplotlib.pyplot as plt\n+from keras_core import layers\n+import keras_core as keras\n+\n+\"\"\"\n+## Prepare the dataset\n+\n+In this example, we will be using the [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist) dataset. But this same recipe can\n+be used for other classification datasets as well.\n+\"\"\"\n+\n+(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n+\n+x_train = x_train.astype(\"float32\") / 255.0\n+x_train = np.reshape(x_train, (-1, 28, 28, 1))\n+y_train = tf.one_hot(y_train, 10)\n+\n+x_test = x_test.astype(\"float32\") / 255.0\n+x_test = np.reshape(x_test, (-1, 28, 28, 1))\n+y_test = tf.one_hot(y_test, 10)\n+\n+\"\"\"\n+## Define hyperparameters\n+\"\"\"\n+\n+AUTO = tf.data.AUTOTUNE\n+BATCH_SIZE = 64\n+EPOCHS = 10\n+\n+\"\"\"\n+## Convert the data into TensorFlow `Dataset` objects\n+\"\"\"\n+\n+# Put aside a few samples to create our validation set\n+val_samples = 2000\n+x_val, y_val = x_train[:val_samples], y_train[:val_samples]\n+new_x_train, new_y_train = x_train[val_samples:], y_train[val_samples:]\n+\n+train_ds_one = (\n+    tf.data.Dataset.from_tensor_slices((new_x_train, new_y_train))\n+    .shuffle(BATCH_SIZE * 100)\n+    .batch(BATCH_SIZE)\n+)\n+train_ds_two = (\n+    tf.data.Dataset.from_tensor_slices((new_x_train, new_y_train))\n+    .shuffle(BATCH_SIZE * 100)\n+    .batch(BATCH_SIZE)\n+)\n+# Because we will be mixing up the images and their corresponding labels, we will be\n+# combining two shuffled datasets from the same training data.\n+train_ds = tf.data.Dataset.zip((train_ds_one, train_ds_two))\n+\n+val_ds = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(BATCH_SIZE)\n+\n+test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(BATCH_SIZE)\n+\n+\"\"\"\n+## Define the mixup technique function\n+\n+To perform the mixup routine, we create new virtual datasets using the training data from\n+the same dataset, and apply a lambda value within the [0, 1] range sampled from a [Beta distribution](https://en.wikipedia.org/wiki/Beta_distribution)\n+— such that, for example, `new_x = lambda * x1 + (1 - lambda) * x2` (where\n+`x1` and `x2` are images) and the same equation is applied to the labels as well.\n+\"\"\"\n+\n+\n+def sample_beta_distribution(size, concentration_0=0.2, concentration_1=0.2):\n+    gamma_1_sample = tf.random.gamma(shape=[size], alpha=concentration_1)\n+    gamma_2_sample = tf.random.gamma(shape=[size], alpha=concentration_0)\n+    return gamma_1_sample / (gamma_1_sample + gamma_2_sample)\n+\n+\n+def mix_up(ds_one, ds_two, alpha=0.2):\n+    # Unpack two datasets\n+    images_one, labels_one = ds_one\n+    images_two, labels_two = ds_two\n+    batch_size = tf.shape(images_one)[0]\n+\n+    # Sample lambda and reshape it to do the mixup\n+    l = sample_beta_distribution(batch_size, alpha, alpha)\n+    x_l = tf.reshape(l, (batch_size, 1, 1, 1))\n+    y_l = tf.reshape(l, (batch_size, 1))\n+\n+    # Perform mixup on both images and labels by combining a pair of images/labels\n+    # (one from each dataset) into one image/label\n+    images = images_one * x_l + images_two * (1 - x_l)\n+    labels = labels_one * y_l + labels_two * (1 - y_l)\n+    return (images, labels)\n+\n+\n+\"\"\"\n+**Note** that here , we are combining two images to create a single one. Theoretically,\n+we can combine as many we want but that comes at an increased computation cost. In\n+certain cases, it may not help improve the performance as well.\n+\"\"\"\n+\n+\"\"\"\n+## Visualize the new augmented dataset\n+\"\"\"\n+\n+# First create the new dataset using our `mix_up` utility\n+train_ds_mu = train_ds.map(\n+    lambda ds_one, ds_two: mix_up(ds_one, ds_two, alpha=0.2), num_parallel_calls=AUTO\n+)\n+\n+# Let's preview 9 samples from the dataset\n+sample_images, sample_labels = next(iter(train_ds_mu))\n+plt.figure(figsize=(10, 10))\n+for i, (image, label) in enumerate(zip(sample_images[:9], sample_labels[:9])):\n+    ax = plt.subplot(3, 3, i + 1)\n+    plt.imshow(image.numpy().squeeze())\n+    print(label.numpy().tolist())\n+    plt.axis(\"off\")\n+\n+\"\"\"\n+## Model building\n+\"\"\"\n+\n+\n+def get_training_model():\n+    model = keras.Sequential(\n+        [\n+            layers.Conv2D(16, (5, 5), activation=\"relu\", input_shape=(28, 28, 1)),\n+            layers.MaxPooling2D(pool_size=(2, 2)),\n+            layers.Conv2D(32, (5, 5), activation=\"relu\"),\n+            layers.MaxPooling2D(pool_size=(2, 2)),\n+            layers.Dropout(0.2),\n+            layers.GlobalAveragePooling2D(),\n+            layers.Dense(128, activation=\"relu\"),\n+            layers.Dense(10, activation=\"softmax\"),\n+        ]\n+    )\n+    return model\n+\n+\n+\"\"\"\n+For the sake of reproducibility, we serialize the initial random weights of our shallow\n+network.\n+\"\"\"\n+\n+initial_model = get_training_model()\n+initial_model.save_weights(\"initial_weights.weights.h5\")\n+\n+\"\"\"\n+## 1. Train the model with the mixed up dataset\n+\"\"\"\n+\n+model = get_training_model()\n+model.load_weights(\"initial_weights.weights.h5\")\n+model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n+model.fit(train_ds_mu, validation_data=val_ds, epochs=EPOCHS)\n+_, test_acc = model.evaluate(test_ds)\n+print(\"Test accuracy: {:.2f}%\".format(test_acc * 100))\n+\n+\"\"\"\n+## 2. Train the model *without* the mixed up dataset\n+\"\"\"\n+\n+model = get_training_model()\n+model.load_weights(\"initial_weights.weights.h5\")\n+model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n+# Notice that we are NOT using the mixed up dataset here\n+model.fit(train_ds_one, validation_data=val_ds, epochs=EPOCHS)\n+_, test_acc = model.evaluate(test_ds)\n+print(\"Test accuracy: {:.2f}%\".format(test_acc * 100))\n+\n+\"\"\"\n+Readers are encouraged to try out mixup on different datasets from different domains and\n+experiment with the lambda parameter. You are strongly advised to check out the\n+[original paper](https://arxiv.org/abs/1710.09412) as well - the authors present several ablation studies on mixup\n+showing how it can improve generalization, as well as show their results of combining\n+more than two images to create a single one.\n+\"\"\"\n+\n+\"\"\"\n+## Notes\n+\n+* With mixup, you can create synthetic examples — especially when you lack a large\n+dataset - without incurring high computational costs.\n+* [Label smoothing](https://www.pyimagesearch.com/2019/12/30/label-smoothing-with-keras-tensorflow-and-deep-learning/) and mixup usually do not work well together because label smoothing\n+already modifies the hard labels by some factor.\n+* mixup does not work well when you are using [Supervised Contrastive\n+Learning](https://arxiv.org/abs/2004.11362) (SCL) since SCL expects the true labels\n+during its pre-training phase.\n+* A few other benefits of mixup include (as described in the [paper](https://arxiv.org/abs/1710.09412)) robustness to\n+adversarial examples and stabilized GAN (Generative Adversarial Networks) training.\n+* There are a number of data augmentation techniques that extend mixup such as\n+[CutMix](https://arxiv.org/abs/1905.04899) and [AugMix](https://arxiv.org/abs/1912.02781).\n+\"\"\"\n\\ No newline at end of file\n\n@@ -30,8 +30,9 @@ def categorical(logits, num_samples, dtype=\"int32\", seed=None):\n     logits = convert_to_tensor(logits)\n     dtype = to_torch_dtype(dtype)\n     generator = torch_seed_generator(seed, device=get_device())\n+    probs = torch.softmax(logits, dim=-1)\n     return torch.multinomial(\n-        logits,\n+        probs,\n         num_samples,\n         replacement=True,\n         generator=generator,\n\n@@ -11,6 +11,8 @@ convert_to_tensor\n convert_to_numpy\n \"\"\"\n \n+import numpy as np\n+\n from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.backend import KerasTensor\n@@ -296,9 +298,7 @@ def convert_to_tensor(x, dtype=None):\n def convert_to_numpy(x):\n     \"\"\"Convert a tensor to a NumPy array.\"\"\"\n     if any_symbolic_tensors((x,)):\n-        raise ValueError(\n-            \"A symbolic tensor (usually the result of applying layers or \"\n-            \"operations to a `keras.Input`), cannot be converted to a numpy \"\n-            \"array. There is no concrete value for the input.\"\n-        )\n+        # This will raise a `ValueError` defined in the `KerasTensor` class. We\n+        # trigger it rather than duplicate it here.\n+        return np.array(x)\n     return backend.convert_to_numpy(x)\n\n@@ -48,8 +48,9 @@ class RandomTest(testing.TestCase, parameterized.TestCase):\n     )\n     def test_categorical(self, seed, num_samples, batch_size):\n         np.random.seed(seed)\n-        # Definitively favor the batch index.\n-        logits = np.eye(batch_size) * 1e9\n+        # Create logits that definitely favors the batch index after a softmax\n+        # is applied. Without a softmax, this would be close to random.\n+        logits = np.eye(batch_size) * 1e5 + 1e6\n         res = random.categorical(logits, num_samples, seed=seed)\n         # Outputs should have shape `(batch_size, num_samples)`, where each\n         # output index matches the batch index.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
