{"custom_id": "scrapy#2ee38e8ddbac6841c8d2bb067ddc0ddba813151f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 10/10 | Churn Δ: 16 | Churn Cumulative: 1174 | Contributors (this commit): 18 | Commits (past 90d): 3 | Contributors (cumulative): 18 | DMM Complexity: 1.0\n\nDIFF:\n@@ -29,6 +29,8 @@ from scrapy.utils.test import assert_aws_environ, get_s3_content_and_delete, get\n from scrapy.utils.python import to_native_str\n from scrapy.utils.project import get_project_settings\n \n+from Pathlib import Path\n+\n \n class FileFeedStorageTest(unittest.TestCase):\n \n@@ -843,3 +845,17 @@ class FeedExportTest(unittest.TestCase):\n         yield self.exported_data({}, settings)\n         self.assertTrue(FromCrawlerCsvItemExporter.init_with_crawler)\n         self.assertTrue(FromCrawlerFileFeedStorage.init_with_crawler)\n+\n+    @defer.inlineCallbacks\n+    def test_pathlib_uri(self):\n+        tmpdir = tempfile.mkdtemp()\n+        feed_uri = Path(tmpdir) / 'res'\n+        settings = {\n+            'FEED_FORMAT': 'csv',\n+            'FEED_STORE_EMPTY': True,\n+            'FEED_URI': feed_uri,\n+        }\n+        \n+    data = yield self.exported_no_data(settings)\n+    self.assertEqual(data, b'')\n+    shutil.rmtree(tmpdir, ignore_errors=True)\n\\ No newline at end of file\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#a776554282aadc651f9e142aea9bc436f9f587a7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1176 | Contributors (this commit): 18 | Commits (past 90d): 4 | Contributors (cumulative): 18 | DMM Complexity: None\n\nDIFF:\n@@ -29,7 +29,7 @@ from scrapy.utils.test import assert_aws_environ, get_s3_content_and_delete, get\n from scrapy.utils.python import to_native_str\n from scrapy.utils.project import get_project_settings\n \n-from Pathlib import Path\n+from pathlib import Path\n \n \n class FileFeedStorageTest(unittest.TestCase):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#cd4c211f4b5c9d5716d0e49472a978c11d7351f8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1178 | Contributors (this commit): 18 | Commits (past 90d): 5 | Contributors (cumulative): 18 | DMM Complexity: None\n\nDIFF:\n@@ -29,7 +29,7 @@ from scrapy.utils.test import assert_aws_environ, get_s3_content_and_delete, get\n from scrapy.utils.python import to_native_str\n from scrapy.utils.project import get_project_settings\n \n-from pathlib import Path\n+from pathlib2 import Path\n \n \n class FileFeedStorageTest(unittest.TestCase):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#7031e3a12422ae977448e7b338457f6c09af9b0e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 1181 | Contributors (this commit): 18 | Commits (past 90d): 6 | Contributors (cumulative): 18 | DMM Complexity: 1.0\n\nDIFF:\n@@ -850,10 +850,11 @@ class FeedExportTest(unittest.TestCase):\n     def test_pathlib_uri(self):\n         tmpdir = tempfile.mkdtemp()\n         feed_uri = Path(tmpdir) / 'res'\n+        res_uri = urljoin('file:', pathname2url(feed_uri))\n         settings = {\n             'FEED_FORMAT': 'csv',\n             'FEED_STORE_EMPTY': True,\n-            'FEED_URI': feed_uri,\n+            'FEED_URI': res_uri,\n         }\n         \n         data = yield self.exported_no_data(settings)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#85f56a92f0c753dfa55012e647f425a6a3d23076", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 1182 | Contributors (this commit): 18 | Commits (past 90d): 7 | Contributors (cumulative): 18 | DMM Complexity: 1.0\n\nDIFF:\n@@ -850,6 +850,7 @@ class FeedExportTest(unittest.TestCase):\n     def test_pathlib_uri(self):\n         tmpdir = tempfile.mkdtemp()\n         feed_uri = Path(tmpdir) / 'res'\n+        feed_uri=str(feeduri)\n         res_uri = urljoin('file:', pathname2url(feed_uri))\n         settings = {\n             'FEED_FORMAT': 'csv',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#4184bac0687d55a442f599ebcfc913231a7c98e2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1184 | Contributors (this commit): 18 | Commits (past 90d): 8 | Contributors (cumulative): 18 | DMM Complexity: None\n\nDIFF:\n@@ -850,7 +850,7 @@ class FeedExportTest(unittest.TestCase):\n     def test_pathlib_uri(self):\n         tmpdir = tempfile.mkdtemp()\n         feed_uri = Path(tmpdir) / 'res'\n-        feed_uri=str(feeduri)\n+        feed_uri=str(feed_uri)\n         res_uri = urljoin('file:', pathname2url(feed_uri))\n         settings = {\n             'FEED_FORMAT': 'csv',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#d21e1034f046c7e8d778e698614c47ebd6875c87", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 469 | Contributors (this commit): 21 | Commits (past 90d): 3 | Contributors (cumulative): 21 | DMM Complexity: None\n\nDIFF:\n@@ -123,7 +123,7 @@ def rel_has_nofollow(rel):\n \n def create_instance(objcls, settings, crawler, *args, **kwargs):\n     \"\"\"Construct a class instance using its ``from_crawler`` or\n-    ``from_settings`` ``__init__`` method, if available.\n+    ``from_settings`` ``__init__`` methods, if available.\n \n     At least one of ``settings`` and ``crawler`` needs to be different from\n     ``None``. If ``settings `` is ``None``, ``crawler.settings`` will be used.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#1d5c270ce8caf954ce83c8db262e2a35707e0c5e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 6 | Churn Cumulative: 1475 | Contributors (this commit): 23 | Commits (past 90d): 16 | Contributors (cumulative): 37 | DMM Complexity: None\n\nDIFF:\n@@ -242,7 +242,9 @@ class FeedExporter(object):\n     def close_spider(self, spider):\n         slot = self.slot\n         if not slot.itemcount and not self.store_empty:\n-            return\n+            # We need to call slot.storage.store nonetheless to get the file\n+            # properly closed.\n+            return defer.maybeDeferred(slot.storage.store, slot.file)\n         if self._exporting:\n             slot.exporter.finish_exporting()\n             self._exporting = False\n\n@@ -417,7 +417,7 @@ class FeedExportTest(unittest.TestCase):\n                 content = f.read()\n \n         finally:\n-            shutil.rmtree(tmpdir, ignore_errors=True)\n+            shutil.rmtree(tmpdir)\n \n         defer.returnValue(content)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#d96b9f860b01256a84bda641b190b423eb4910b1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 7 | Methods Changed: 7 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 920 | Contributors (this commit): 10 | Commits (past 90d): 2 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -108,6 +108,7 @@ class BaseSettings(MutableMapping):\n         :type name: str\n \n         :param default: the value to return if no setting is found\n+        :type default: object\n         \"\"\"\n         return self[name] if self[name] is not None else default\n \n@@ -125,6 +126,7 @@ class BaseSettings(MutableMapping):\n         :type name: str\n \n         :param default: the value to return if no setting is found\n+        :type default: object\n         \"\"\"\n         got = self.get(name, default)\n         try:\n@@ -146,6 +148,7 @@ class BaseSettings(MutableMapping):\n         :type name: str\n \n         :param default: the value to return if no setting is found\n+        :type default: object\n         \"\"\"\n         return int(self.get(name, default))\n \n@@ -157,6 +160,7 @@ class BaseSettings(MutableMapping):\n         :type name: str\n \n         :param default: the value to return if no setting is found\n+        :type default: object\n         \"\"\"\n         return float(self.get(name, default))\n \n@@ -172,6 +176,7 @@ class BaseSettings(MutableMapping):\n         :type name: str\n \n         :param default: the value to return if no setting is found\n+        :type default: object\n         \"\"\"\n         value = self.get(name, default or [])\n         if isinstance(value, six.string_types):\n@@ -192,6 +197,7 @@ class BaseSettings(MutableMapping):\n         :type name: str\n \n         :param default: the value to return if no setting is found\n+        :type default: object\n         \"\"\"\n         value = self.get(name, default or {})\n         if isinstance(value, six.string_types):\n@@ -249,6 +255,7 @@ class BaseSettings(MutableMapping):\n         :type name: str\n \n         :param value: the value to associate with the setting\n+        :type default: object\n \n         :param priority: the priority of the setting. Should be a key of\n             :attr:`~scrapy.settings.SETTINGS_PRIORITIES` or an integer\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#7a84a4bdba45bab56cee0daed9d9c3a04d8d61c0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 8 | Files Changed: 2 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 16 | Churn Cumulative: 648 | Contributors (this commit): 22 | Commits (past 90d): 6 | Contributors (cumulative): 26 | DMM Complexity: None\n\nDIFF:\n@@ -123,14 +123,14 @@ def rel_has_nofollow(rel):\n \n def create_instance(objcls, settings, crawler, *args, **kwargs):\n     \"\"\"Construct a class instance using its ``from_crawler`` or\n-    ``from_settings`` ``__init__`` methods, if available.\n+    ``from_settings`` constructors, if available.\n \n     At least one of ``settings`` and ``crawler`` needs to be different from\n     ``None``. If ``settings `` is ``None``, ``crawler.settings`` will be used.\n-    If ``crawler`` is ``None``, only the ``from_settings`` ``__init__`` method will be\n+    If ``crawler`` is ``None``, only the ``from_settings`` constructor will be\n     tried.\n \n-    ``*args`` and ``**kwargs`` are forwarded to the ``__init__`` methods.\n+    ``*args`` and ``**kwargs`` are forwarded to the constructors.\n \n     Raises ``ValueError`` if both ``settings`` and ``crawler`` are ``None``.\n     \"\"\"\n\n@@ -109,11 +109,11 @@ class UtilsMiscTestCase(unittest.TestCase):\n             else:\n                 mock.assert_called_once_with(*args, **kwargs)\n \n-        # Check usage of correct __init__ method using four mocks:\n-        #   1. with no alternative __init__ methods\n-        #   2. with from_settings() __init__ method\n-        #   3. with from_crawler() __init__ method\n-        #   4. with from_settings() and from_crawler() __init__ method\n+        # Check usage of correct constructor using four mocks:\n+        #   1. with no alternative constructors\n+        #   2. with from_settings() constructor\n+        #   3. with from_crawler() constructor\n+        #   4. with from_settings() and from_crawler() constructor\n         spec_sets = ([], ['from_settings'], ['from_crawler'],\n                      ['from_settings', 'from_crawler'])\n         for specs in spec_sets:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#f701f5b0db10faef08e4ed9a21b98fd72f9cfc9a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 4 | Churn Cumulative: 1536 | Contributors (this commit): 23 | Commits (past 90d): 6 | Contributors (cumulative): 30 | DMM Complexity: 1.0\n\nDIFF:\n@@ -66,7 +66,7 @@ class Request(object_ref):\n         s = safe_url_string(url, self.encoding)\n         self._url = escape_ajax(s)\n \n-        if ':' not in self._url:\n+        if ('://' not in self._url) and (not self._url.startswith('data:')):\n             raise ValueError('Missing scheme in request url: %s' % self._url)\n \n     url = property(_get_url, obsolete_setter(_set_url, 'url'))\n\n@@ -52,6 +52,8 @@ class RequestTest(unittest.TestCase):\n \n     def test_url_no_scheme(self):\n         self.assertRaises(ValueError, self.request_class, 'foo')\n+        self.assertRaises(ValueError, self.request_class, '/foo/')\n+        self.assertRaises(ValueError, self.request_class, '/foo:bar')\n \n     def test_headers(self):\n         # Different ways of setting headers attribute\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#bf5c1a3dec02165b81dffb98fc560c43fb065f38", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 291 | Contributors (this commit): 19 | Commits (past 90d): 8 | Contributors (cumulative): 19 | DMM Complexity: None\n\nDIFF:\n@@ -106,7 +106,7 @@ class S3FeedStorage(BlockingFeedStorage):\n                 warnings.warn(\n                     \"Initialising `scrapy.extensions.feedexport.S3FeedStorage` \"\n                     \"without AWS keys is deprecated. Please supply credentials or \"\n-                    \"use the `from_crawler()` ``__init__`` method.\",\n+                    \"use the `from_crawler()` constructor.\",\n                     category=ScrapyDeprecationWarning,\n                     stacklevel=2\n                 )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#c623a16a223df31669d9f204b8af7d89062ee56c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 3 | Churn Cumulative: 810 | Contributors (this commit): 4 | Commits (past 90d): 1 | Contributors (cumulative): 4 | DMM Complexity: 0.0\n\nDIFF:\n@@ -86,9 +86,6 @@ class _SlotPriorityQueues(object):\n     def __len__(self):\n         return sum(len(x) for x in self.pqueues.values()) if self.pqueues else 0\n \n-    def __contains__(self, slot):\n-        return slot in self.pqueues\n-\n \n class ScrapyPriorityQueue(PriorityQueue):\n     \"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#3b6f7ac9f2f5b48b9f2f3ce106d1205599d2164f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 7/7 | Churn Δ: 7 | Churn Cumulative: 72 | Contributors (this commit): 3 | Commits (past 90d): 1 | Contributors (cumulative): 3 | DMM Complexity: 0.0\n\nDIFF:\n@@ -14,6 +14,9 @@ Author: dufferzafar\n \n import re\n \n+\n+def main():\n+\n     # Used for remembering the file (and its contents)\n     # so we don't have to open the same file again.\n     _filename = None\n@@ -61,3 +64,7 @@ for line in output_lines:\n         else:\n             # We don't understand what the current line means!\n             print(\"Not Understood: \" + line)\n+\n+\n+if __name__ == '__main__':\n+    main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#179dc916ff3e3518d8874f3fcd93948e11d5a259", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 497 | Contributors (this commit): 21 | Commits (past 90d): 5 | Contributors (cumulative): 21 | DMM Complexity: None\n\nDIFF:\n@@ -56,7 +56,7 @@ setup(\n         'Programming Language :: Python :: 3.5',\n         'Programming Language :: Python :: 3.6',\n         'Programming Language :: Python :: 3.7',\n-        'Programming Language :: Python :: 3.8',\n+        # 'Programming Language :: Python :: 3.8',  not supported yet\n         'Programming Language :: Python :: Implementation :: CPython',\n         'Programming Language :: Python :: Implementation :: PyPy',\n         'Topic :: Internet :: WWW/HTTP',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#4068797558f6d8d58f81e12930f487fc0f59f0a5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 141 | Contributors (this commit): 8 | Commits (past 90d): 1 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -154,6 +154,7 @@ class FilesystemStorageGzipTest(FilesystemStorageTest):\n         new_settings.setdefault('HTTPCACHE_GZIP', True)\n         return super(FilesystemStorageTest, self)._get_settings(**new_settings)\n \n+@pytest.mark.xfail(reason='leveldb not supported in python 3.8')\n class LeveldbStorageTest(DefaultStorageTest):\n \n     pytest.importorskip('leveldb')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#deacd34c8d2400b07e911dea9173b840cec7dece", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 143 | Contributors (this commit): 8 | Commits (past 90d): 2 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -104,6 +104,7 @@ class _BaseTest(unittest.TestCase):\n \n class DefaultStorageTest(_BaseTest):\n \n+    @pytest.mark.xfail(reason='leveldb not supported in python 3.8')\n     def test_storage(self):\n         with self._storage() as storage:\n             request2 = self.request.copy()\n@@ -154,7 +155,6 @@ class FilesystemStorageGzipTest(FilesystemStorageTest):\n         new_settings.setdefault('HTTPCACHE_GZIP', True)\n         return super(FilesystemStorageTest, self)._get_settings(**new_settings)\n \n-@pytest.mark.xfail(reason='leveldb not supported in python 3.8')\n class LeveldbStorageTest(DefaultStorageTest):\n \n     pytest.importorskip('leveldb')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#11942c436c78e998e3d58f0aad7cba490d74cc67", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 147 | Contributors (this commit): 8 | Commits (past 90d): 3 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -6,6 +6,7 @@ import unittest\n import email.utils\n from contextlib import contextmanager\n import pytest\n+import sys\n \n from scrapy.http import Response, HtmlResponse, Request\n from scrapy.spiders import Spider\n@@ -157,7 +158,10 @@ class FilesystemStorageGzipTest(FilesystemStorageTest):\n \n class LeveldbStorageTest(DefaultStorageTest):\n \n+    try:\n         pytest.importorskip('leveldb')\n+    except SystemError:\n+        pass\n     storage_class = 'scrapy.extensions.httpcache.LeveldbCacheStorage'\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#b3df0a84150f15ff00cdfaffc586f91b653baecd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 4 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 152 | Contributors (this commit): 8 | Commits (past 90d): 4 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -6,7 +6,6 @@ import unittest\n import email.utils\n from contextlib import contextmanager\n import pytest\n-import sys\n \n from scrapy.http import Response, HtmlResponse, Request\n from scrapy.spiders import Spider\n@@ -90,6 +89,7 @@ class _BaseTest(unittest.TestCase):\n         assert any(h in request2.headers for h in (b'If-None-Match', b'If-Modified-Since'))\n         self.assertEqual(request1.body, request2.body)\n \n+    @pytest.mark.xfail(reason='leveldb not supported in python 3.8')\n     def test_dont_cache(self):\n         with self._middleware() as mw:\n             self.request.meta['dont_cache'] = True\n@@ -119,6 +119,7 @@ class DefaultStorageTest(_BaseTest):\n             time.sleep(2)  # wait for cache to expire\n             assert storage.retrieve_response(self.spider, request2) is None\n \n+    @pytest.mark.xfail(reason='leveldb not supported in python 3.8')\n     def test_storage_never_expire(self):\n         with self._storage(HTTPCACHE_EXPIRATION_SECS=0) as storage:\n             assert storage.retrieve_response(self.spider, self.request) is None\n@@ -161,6 +162,8 @@ class LeveldbStorageTest(DefaultStorageTest):\n     try:\n         pytest.importorskip('leveldb')\n     except SystemError:\n+        # Happens in python 3.8\n+        # This will cause xfail in DefaultStorageTest to trigger\n         pass\n     storage_class = 'scrapy.extensions.httpcache.LeveldbCacheStorage'\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#70b2854590c1aa10324e6a4b50b6d74a5079c8e9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 4 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 159 | Contributors (this commit): 8 | Commits (past 90d): 5 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -6,6 +6,7 @@ import unittest\n import email.utils\n from contextlib import contextmanager\n import pytest\n+import sys\n \n from scrapy.http import Response, HtmlResponse, Request\n from scrapy.spiders import Spider\n@@ -89,7 +90,7 @@ class _BaseTest(unittest.TestCase):\n         assert any(h in request2.headers for h in (b'If-None-Match', b'If-Modified-Since'))\n         self.assertEqual(request1.body, request2.body)\n \n-    @pytest.mark.xfail(reason='leveldb not supported in python 3.8')\n+    @pytest.mark.xfail(sys.version_info >= (3, 8), raises=RuntimeError, reason='leveldb not supported in python 3.8')\n     def test_dont_cache(self):\n         with self._middleware() as mw:\n             self.request.meta['dont_cache'] = True\n@@ -105,7 +106,7 @@ class _BaseTest(unittest.TestCase):\n \n class DefaultStorageTest(_BaseTest):\n \n-    @pytest.mark.xfail(reason='leveldb not supported in python 3.8')\n+    @pytest.mark.xfail(sys.version_info >= (3, 8), raises=RuntimeError, reason='leveldb not supported in python 3.8')\n     def test_storage(self):\n         with self._storage() as storage:\n             request2 = self.request.copy()\n@@ -119,7 +120,7 @@ class DefaultStorageTest(_BaseTest):\n             time.sleep(2)  # wait for cache to expire\n             assert storage.retrieve_response(self.spider, request2) is None\n \n-    @pytest.mark.xfail(reason='leveldb not supported in python 3.8')\n+    @pytest.mark.xfail(sys.version_info >= (3, 8), raises=RuntimeError, reason='leveldb not supported in python 3.8')\n     def test_storage_never_expire(self):\n         with self._storage(HTTPCACHE_EXPIRATION_SECS=0) as storage:\n             assert storage.retrieve_response(self.spider, self.request) is None\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#20ea912513053aa2b2122ba5bb0387189bbc5467", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 165 | Contributors (this commit): 8 | Commits (past 90d): 6 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -90,7 +90,7 @@ class _BaseTest(unittest.TestCase):\n         assert any(h in request2.headers for h in (b'If-None-Match', b'If-Modified-Since'))\n         self.assertEqual(request1.body, request2.body)\n \n-    @pytest.mark.xfail(sys.version_info >= (3, 8), raises=RuntimeError, reason='leveldb not supported in python 3.8')\n+    @pytest.mark.xfail(sys.version_info >= (3, 8), raises=SystemError, reason='leveldb not supported in python 3.8')\n     def test_dont_cache(self):\n         with self._middleware() as mw:\n             self.request.meta['dont_cache'] = True\n@@ -106,7 +106,7 @@ class _BaseTest(unittest.TestCase):\n \n class DefaultStorageTest(_BaseTest):\n \n-    @pytest.mark.xfail(sys.version_info >= (3, 8), raises=RuntimeError, reason='leveldb not supported in python 3.8')\n+    @pytest.mark.xfail(sys.version_info >= (3, 8), raises=SystemError, reason='leveldb not supported in python 3.8')\n     def test_storage(self):\n         with self._storage() as storage:\n             request2 = self.request.copy()\n@@ -120,7 +120,7 @@ class DefaultStorageTest(_BaseTest):\n             time.sleep(2)  # wait for cache to expire\n             assert storage.retrieve_response(self.spider, request2) is None\n \n-    @pytest.mark.xfail(sys.version_info >= (3, 8), raises=RuntimeError, reason='leveldb not supported in python 3.8')\n+    @pytest.mark.xfail(sys.version_info >= (3, 8), raises=SystemError, reason='leveldb not supported in python 3.8')\n     def test_storage_never_expire(self):\n         with self._storage(HTTPCACHE_EXPIRATION_SECS=0) as storage:\n             assert storage.retrieve_response(self.spider, self.request) is None\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#7731814cc25c57fe31db9ba749450cd5a27eed39", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 236 | Lines Deleted: 58 | Files Changed: 2 | Hunks: 19 | Methods Changed: 24 | Complexity Δ (Sum/Max): 22/22 | Churn Δ: 294 | Churn Cumulative: 741 | Contributors (this commit): 13 | Commits (past 90d): 3 | Contributors (cumulative): 21 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,19 +1,19 @@\n-\"\"\"Item Loader\n+\"\"\"\n+Item Loader\n \n See documentation in docs/topics/loaders.rst\n-\n \"\"\"\n from collections import defaultdict\n+\n import six\n \n from scrapy.item import Item\n+from scrapy.loader.common import wrap_loader_context\n+from scrapy.loader.processors import Identity\n from scrapy.selector import Selector\n from scrapy.utils.misc import arg_to_iter, extract_regex\n from scrapy.utils.python import flatten\n \n-from .common import wrap_loader_context\n-from .processors import Identity\n-\n \n class ItemLoader(object):\n \n@@ -33,10 +33,9 @@ class ItemLoader(object):\n         self.parent = parent\n         self._local_item = context['item'] = item\n         self._local_values = defaultdict(list)\n-        # Preprocess values if item built from dict\n-        # Values need to be added to item._values if added them from dict (not with add_values)\n+        # values from initial item\n         for field_name, value in item.items():\n-            self._values[field_name] = self._process_input_value(field_name, value)\n+            self._values[field_name] += arg_to_iter(value)\n \n     @property\n     def _values(self):\n@@ -132,7 +131,7 @@ class ItemLoader(object):\n         try:\n             return proc(self._values[field_name])\n         except Exception as e:\n-            raise ValueError(\"Error with output processor: field=%r value=%r error='%s: %s'\" % \\\n+            raise ValueError(\"Error with output processor: field=%r value=%r error='%s: %s'\" %\n                              (field_name, self._values[field_name], type(e).__name__, str(e)))\n \n     def get_collected_values(self, field_name):\n@@ -141,14 +140,14 @@ class ItemLoader(object):\n     def get_input_processor(self, field_name):\n         proc = getattr(self, '%s_in' % field_name, None)\n         if not proc:\n-            proc = self._get_item_field_attr(field_name, 'input_processor', \\\n+            proc = self._get_item_field_attr(field_name, 'input_processor',\n                                              self.default_input_processor)\n         return proc\n \n     def get_output_processor(self, field_name):\n         proc = getattr(self, '%s_out' % field_name, None)\n         if not proc:\n-            proc = self._get_item_field_attr(field_name, 'output_processor', \\\n+            proc = self._get_item_field_attr(field_name, 'output_processor',\n                                              self.default_output_processor)\n         return proc\n \n\n@@ -1,13 +1,15 @@\n-import unittest\n-import six\n from functools import partial\n+import unittest\n+\n+import six\n \n-from scrapy.loader import ItemLoader\n-from scrapy.loader.processors import Join, Identity, TakeFirst, \\\n-    Compose, MapCompose, SelectJmes\n-from scrapy.item import Item, Field\n-from scrapy.selector import Selector\n from scrapy.http import HtmlResponse\n+from scrapy.item import Item, Field\n+from scrapy.loader import ItemLoader\n+from scrapy.loader.processors import (Compose, Identity, Join,\n+                                      MapCompose, SelectJmes, TakeFirst)\n+from scrapy.selector import Selector\n+\n \n # test items\n class NameItem(Item):\n@@ -61,7 +63,7 @@ class BasicItemLoaderTest(unittest.TestCase):\n         il.add_value('name', u'marta')\n         item = il.load_item()\n         assert item is i\n-        self.assertEqual(item['summary'], u'lala')\n+        self.assertEqual(item['summary'], [u'lala'])\n         self.assertEqual(item['name'], [u'marta'])\n \n     def test_load_item_using_custom_loader(self):\n@@ -419,43 +421,6 @@ class BasicItemLoaderTest(unittest.TestCase):\n         self.assertEqual(item['url'], u'rabbit.hole')\n         self.assertEqual(item['summary'], u'rabbithole')\n \n-    def test_create_item_from_dict(self):\n-        class TestItem(Item):\n-            title = Field()\n-\n-        class TestItemLoader(ItemLoader):\n-            default_item_class = TestItem\n-\n-        input_item = {'title': 'Test item title 1'}\n-        il = TestItemLoader(item=input_item)\n-        # Getting output value mustn't remove value from item\n-        self.assertEqual(il.load_item(), {\n-            'title': 'Test item title 1',\n-        })\n-        self.assertEqual(il.get_output_value('title'), 'Test item title 1')\n-        self.assertEqual(il.load_item(), {\n-            'title': 'Test item title 1',\n-        })\n-\n-        input_item = {'title': 'Test item title 2'}\n-        il = TestItemLoader(item=input_item)\n-        # Values from dict must be added to item _values\n-        self.assertEqual(il._values.get('title'), 'Test item title 2')\n-\n-        input_item = {'title': [u'Test item title 3', u'Test item 4']}\n-        il = TestItemLoader(item=input_item)\n-        # Same rules must work for lists\n-        self.assertEqual(il._values.get('title'),\n-                         [u'Test item title 3', u'Test item 4'])\n-        self.assertEqual(il.load_item(), {\n-            'title': [u'Test item title 3', u'Test item 4'],\n-        })\n-        self.assertEqual(il.get_output_value('title'),\n-                         [u'Test item title 3', u'Test item 4'])\n-        self.assertEqual(il.load_item(), {\n-            'title': [u'Test item title 3', u'Test item 4'],\n-        })\n-\n     def test_error_input_processor(self):\n         class TestItem(Item):\n             name = Field()\n@@ -493,6 +458,220 @@ class BasicItemLoaderTest(unittest.TestCase):\n                           [u'marta', u'other'], Compose(float))\n \n \n+class InitializationTestMixin(object):\n+\n+    item_class = None\n+\n+    def test_keep_single_value(self):\n+        \"\"\"Loaded item should contain values from the initial item\"\"\"\n+        input_item = self.item_class(name='foo')\n+        il = ItemLoader(item=input_item)\n+        loaded_item = il.load_item()\n+        self.assertIsInstance(loaded_item, self.item_class)\n+        self.assertEqual(dict(loaded_item), {'name': ['foo']})\n+\n+    def test_keep_list(self):\n+        \"\"\"Loaded item should contain values from the initial item\"\"\"\n+        input_item = self.item_class(name=['foo', 'bar'])\n+        il = ItemLoader(item=input_item)\n+        loaded_item = il.load_item()\n+        self.assertIsInstance(loaded_item, self.item_class)\n+        self.assertEqual(dict(loaded_item), {'name': ['foo', 'bar']})\n+\n+    def test_add_value_singlevalue_singlevalue(self):\n+        \"\"\"Values added after initialization should be appended\"\"\"\n+        input_item = self.item_class(name='foo')\n+        il = ItemLoader(item=input_item)\n+        il.add_value('name', 'bar')\n+        loaded_item = il.load_item()\n+        self.assertIsInstance(loaded_item, self.item_class)\n+        self.assertEqual(dict(loaded_item), {'name': ['foo', 'bar']})\n+\n+    def test_add_value_singlevalue_list(self):\n+        \"\"\"Values added after initialization should be appended\"\"\"\n+        input_item = self.item_class(name='foo')\n+        il = ItemLoader(item=input_item)\n+        il.add_value('name', ['item', 'loader'])\n+        loaded_item = il.load_item()\n+        self.assertIsInstance(loaded_item, self.item_class)\n+        self.assertEqual(dict(loaded_item), {'name': ['foo', 'item', 'loader']})\n+\n+    def test_add_value_list_singlevalue(self):\n+        \"\"\"Values added after initialization should be appended\"\"\"\n+        input_item = self.item_class(name=['foo', 'bar'])\n+        il = ItemLoader(item=input_item)\n+        il.add_value('name', 'qwerty')\n+        loaded_item = il.load_item()\n+        self.assertIsInstance(loaded_item, self.item_class)\n+        self.assertEqual(dict(loaded_item), {'name': ['foo', 'bar', 'qwerty']})\n+\n+    def test_add_value_list_list(self):\n+        \"\"\"Values added after initialization should be appended\"\"\"\n+        input_item = self.item_class(name=['foo', 'bar'])\n+        il = ItemLoader(item=input_item)\n+        il.add_value('name', ['item', 'loader'])\n+        loaded_item = il.load_item()\n+        self.assertIsInstance(loaded_item, self.item_class)\n+        self.assertEqual(dict(loaded_item), {'name': ['foo', 'bar', 'item', 'loader']})\n+\n+    def test_get_output_value_singlevalue(self):\n+        \"\"\"Getting output value must not remove value from item\"\"\"\n+        input_item = self.item_class(name='foo')\n+        il = ItemLoader(item=input_item)\n+        self.assertEqual(il.get_output_value('name'), ['foo'])\n+        loaded_item = il.load_item()\n+        self.assertIsInstance(loaded_item, self.item_class)\n+        self.assertEqual(loaded_item, dict({'name': ['foo']}))\n+\n+    def test_get_output_value_list(self):\n+        \"\"\"Getting output value must not remove value from item\"\"\"\n+        input_item = self.item_class(name=['foo', 'bar'])\n+        il = ItemLoader(item=input_item)\n+        self.assertEqual(il.get_output_value('name'), ['foo', 'bar'])\n+        loaded_item = il.load_item()\n+        self.assertIsInstance(loaded_item, self.item_class)\n+        self.assertEqual(loaded_item, dict({'name': ['foo', 'bar']}))\n+\n+    def test_values_single(self):\n+        \"\"\"Values from initial item must be added to loader._values\"\"\"\n+        input_item = self.item_class(name='foo')\n+        il = ItemLoader(item=input_item)\n+        self.assertEqual(il._values.get('name'), ['foo'])\n+\n+    def test_values_list(self):\n+        \"\"\"Values from initial item must be added to loader._values\"\"\"\n+        input_item = self.item_class(name=['foo', 'bar'])\n+        il = ItemLoader(item=input_item)\n+        self.assertEqual(il._values.get('name'), ['foo', 'bar'])\n+\n+\n+class InitializationFromDictTest(InitializationTestMixin, unittest.TestCase):\n+    item_class = dict\n+\n+\n+class InitializationFromItemTest(InitializationTestMixin, unittest.TestCase):\n+    item_class = NameItem\n+\n+\n+class BaseNoInputReprocessingLoader(ItemLoader):\n+    title_in = MapCompose(str.upper)\n+    title_out = TakeFirst()\n+\n+\n+class NoInputReprocessingDictLoader(BaseNoInputReprocessingLoader):\n+    default_item_class = dict\n+\n+\n+class NoInputReprocessingFromDictTest(unittest.TestCase):\n+    \"\"\"\n+    Loaders initialized from loaded items must not reprocess fields (dict instances)\n+    \"\"\"\n+    def test_avoid_reprocessing_with_initial_values_single(self):\n+        il = NoInputReprocessingDictLoader(item=dict(title='foo'))\n+        il_loaded = il.load_item()\n+        self.assertEqual(il_loaded, dict(title='foo'))\n+        self.assertEqual(NoInputReprocessingDictLoader(item=il_loaded).load_item(), dict(title='foo'))\n+\n+    def test_avoid_reprocessing_with_initial_values_list(self):\n+        il = NoInputReprocessingDictLoader(item=dict(title=['foo', 'bar']))\n+        il_loaded = il.load_item()\n+        self.assertEqual(il_loaded, dict(title='foo'))\n+        self.assertEqual(NoInputReprocessingDictLoader(item=il_loaded).load_item(), dict(title='foo'))\n+\n+    def test_avoid_reprocessing_without_initial_values_single(self):\n+        il = NoInputReprocessingDictLoader()\n+        il.add_value('title', 'foo')\n+        il_loaded = il.load_item()\n+        self.assertEqual(il_loaded, dict(title='FOO'))\n+        self.assertEqual(NoInputReprocessingDictLoader(item=il_loaded).load_item(), dict(title='FOO'))\n+\n+    def test_avoid_reprocessing_without_initial_values_list(self):\n+        il = NoInputReprocessingDictLoader()\n+        il.add_value('title', ['foo', 'bar'])\n+        il_loaded = il.load_item()\n+        self.assertEqual(il_loaded, dict(title='FOO'))\n+        self.assertEqual(NoInputReprocessingDictLoader(item=il_loaded).load_item(), dict(title='FOO'))\n+\n+\n+class NoInputReprocessingItem(Item):\n+    title = Field()\n+\n+\n+class NoInputReprocessingItemLoader(BaseNoInputReprocessingLoader):\n+    default_item_class = NoInputReprocessingItem\n+\n+\n+class NoInputReprocessingFromItemTest(unittest.TestCase):\n+    \"\"\"\n+    Loaders initialized from loaded items must not reprocess fields (BaseItem instances)\n+    \"\"\"\n+    def test_avoid_reprocessing_with_initial_values_single(self):\n+        il = NoInputReprocessingItemLoader(item=NoInputReprocessingItem(title='foo'))\n+        il_loaded = il.load_item()\n+        self.assertEqual(il_loaded, {'title': 'foo'})\n+        self.assertEqual(NoInputReprocessingItemLoader(item=il_loaded).load_item(), {'title': 'foo'})\n+\n+    def test_avoid_reprocessing_with_initial_values_list(self):\n+        il = NoInputReprocessingItemLoader(item=NoInputReprocessingItem(title=['foo', 'bar']))\n+        il_loaded = il.load_item()\n+        self.assertEqual(il_loaded, {'title': 'foo'})\n+        self.assertEqual(NoInputReprocessingItemLoader(item=il_loaded).load_item(), {'title': 'foo'})\n+\n+    def test_avoid_reprocessing_without_initial_values_single(self):\n+        il = NoInputReprocessingItemLoader()\n+        il.add_value('title', 'FOO')\n+        il_loaded = il.load_item()\n+        self.assertEqual(il_loaded, {'title': 'FOO'})\n+        self.assertEqual(NoInputReprocessingItemLoader(item=il_loaded).load_item(), {'title': 'FOO'})\n+\n+    def test_avoid_reprocessing_without_initial_values_list(self):\n+        il = NoInputReprocessingItemLoader()\n+        il.add_value('title', ['foo', 'bar'])\n+        il_loaded = il.load_item()\n+        self.assertEqual(il_loaded, {'title': 'FOO'})\n+        self.assertEqual(NoInputReprocessingItemLoader(item=il_loaded).load_item(), {'title': 'FOO'})\n+\n+\n+class TestOutputProcessorDict(unittest.TestCase):\n+    def test_output_processor(self):\n+\n+        class TempDict(dict):\n+            def __init__(self, *args, **kwargs):\n+                super(TempDict, self).__init__(self, *args, **kwargs)\n+                self.setdefault('temp', 0.3)\n+\n+        class TempLoader(ItemLoader):\n+            default_item_class = TempDict\n+            default_input_processor = Identity()\n+            default_output_processor = Compose(TakeFirst())\n+\n+        loader = TempLoader()\n+        item = loader.load_item()\n+        self.assertIsInstance(item, TempDict)\n+        self.assertEqual(dict(item), {'temp': 0.3})\n+\n+\n+class TestOutputProcessorItem(unittest.TestCase):\n+    def test_output_processor(self):\n+\n+        class TempItem(Item):\n+            temp = Field()\n+\n+            def __init__(self, *args, **kwargs):\n+                super(TempItem, self).__init__(self, *args, **kwargs)\n+                self.setdefault('temp', 0.3)\n+\n+        class TempLoader(ItemLoader):\n+            default_item_class = TempItem\n+            default_input_processor = Identity()\n+            default_output_processor = Compose(TakeFirst())\n+\n+        loader = TempLoader()\n+        item = loader.load_item()\n+        self.assertIsInstance(item, TempItem)\n+        self.assertEqual(dict(item), {'temp': 0.3})\n+\n+\n class ProcessorsTest(unittest.TestCase):\n \n     def test_take_first(self):\n@@ -523,7 +702,8 @@ class ProcessorsTest(unittest.TestCase):\n         self.assertRaises(ValueError, proc, 'hello')\n \n     def test_mapcompose(self):\n-        filter_world = lambda x: None if x == 'world' else x\n+        def filter_world(x):\n+            return None if x == 'world' else x\n         proc = MapCompose(filter_world, six.text_type.upper)\n         self.assertEqual(proc([u'hello', u'world', u'this', u'is', u'scrapy']),\n                          [u'HELLO', u'THIS', u'IS', u'SCRAPY'])\n@@ -535,7 +715,6 @@ class ProcessorsTest(unittest.TestCase):\n         self.assertRaises(ValueError, proc, 'hello')\n \n \n-\n class SelectortemLoaderTest(unittest.TestCase):\n     response = HtmlResponse(url=\"\", encoding='utf-8', body=b\"\"\"\n     <html>\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#3d0df419c4eeb0ccf7934c8f06a38707eae8d722", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 9 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 17 | Churn Cumulative: 196 | Contributors (this commit): 9 | Commits (past 90d): 1 | Contributors (cumulative): 9 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,19 +1,24 @@\n from __future__ import print_function\n-import os\n+\n import gzip\n import logging\n-from six.moves import cPickle as pickle\n+import os\n+from email.utils import mktime_tz, parsedate_tz\n from importlib import import_module\n from time import time\n+from warnings import warn\n from weakref import WeakKeyDictionary\n-from email.utils import mktime_tz, parsedate_tz\n+\n+from six.moves import cPickle as pickle\n from w3lib.http import headers_raw_to_dict, headers_dict_to_raw\n+\n+from scrapy.exceptions import ScrapyDeprecationWarning\n from scrapy.http import Headers, Response\n from scrapy.responsetypes import responsetypes\n-from scrapy.utils.request import request_fingerprint\n-from scrapy.utils.project import data_path\n from scrapy.utils.httpobj import urlparse_cached\n+from scrapy.utils.project import data_path\n from scrapy.utils.python import to_bytes, to_unicode, garbage_collect\n+from scrapy.utils.request import request_fingerprint\n \n \n logger = logging.getLogger(__name__)\n@@ -345,6 +350,8 @@ class FilesystemCacheStorage(object):\n class LeveldbCacheStorage(object):\n \n     def __init__(self, settings):\n+        warn(\"The LevelDB storage backend is deprecated.\",\n+             ScrapyDeprecationWarning, stacklevel=2)\n         import leveldb\n         self._leveldb = leveldb\n         self.cachedir = data_path(settings['HTTPCACHE_DIR'], createdir=True)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#16bb3ac20dae8b7c5fbccf4ab85b3a0393e7c55d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 4 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 9 | Churn Cumulative: 174 | Contributors (this commit): 8 | Commits (past 90d): 7 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -90,7 +90,6 @@ class _BaseTest(unittest.TestCase):\n         assert any(h in request2.headers for h in (b'If-None-Match', b'If-Modified-Since'))\n         self.assertEqual(request1.body, request2.body)\n \n-    @pytest.mark.xfail(sys.version_info >= (3, 8), raises=SystemError, reason='leveldb not supported in python 3.8')\n     def test_dont_cache(self):\n         with self._middleware() as mw:\n             self.request.meta['dont_cache'] = True\n@@ -106,7 +105,6 @@ class _BaseTest(unittest.TestCase):\n \n class DefaultStorageTest(_BaseTest):\n \n-    @pytest.mark.xfail(sys.version_info >= (3, 8), raises=SystemError, reason='leveldb not supported in python 3.8')\n     def test_storage(self):\n         with self._storage() as storage:\n             request2 = self.request.copy()\n@@ -120,7 +118,6 @@ class DefaultStorageTest(_BaseTest):\n             time.sleep(2)  # wait for cache to expire\n             assert storage.retrieve_response(self.spider, request2) is None\n \n-    @pytest.mark.xfail(sys.version_info >= (3, 8), raises=SystemError, reason='leveldb not supported in python 3.8')\n     def test_storage_never_expire(self):\n         with self._storage(HTTPCACHE_EXPIRATION_SECS=0) as storage:\n             assert storage.retrieve_response(self.spider, self.request) is None\n@@ -164,8 +161,10 @@ class LeveldbStorageTest(DefaultStorageTest):\n         pytest.importorskip('leveldb')\n     except SystemError:\n         # Happens in python 3.8\n-        # This will cause xfail in DefaultStorageTest to trigger\n-        pass\n+        pytest.mark.skipif(\n+            sys.version_info >= (3, 8),\n+            reason='leveldb not supported in python 3.8',\n+        )\n     storage_class = 'scrapy.extensions.httpcache.LeveldbCacheStorage'\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
