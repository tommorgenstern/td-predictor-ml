{"custom_id": "keras#7207c78e101a0620b8fe2891c74f94de181e15fc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 189 | Contributors (this commit): 3 | Commits (past 90d): 4 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -86,7 +86,7 @@ def legacy_dense_support(func):\n             ('bias', 'use_bias'),\n         ]\n         kwargs = convert_legacy_kwargs('Dense',\n-                                       args,\n+                                       args[1:],\n                                        kwargs,\n                                        conversions)\n         return func(*args, **kwargs)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6419d52543b8af2c50c9a7678e1dd42f96745961", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 308 | Contributors (this commit): 5 | Commits (past 90d): 7 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -77,7 +77,7 @@ class GaussianDropout(Layer):\n         if 0 < self.rate < 1:\n             def noised():\n                 stddev = np.sqrt(self.rate / (1.0 - self.rate))\n-                return inputs + K.random_normal(shape=K.shape(inputs),\n+                return inputs * K.random_normal(shape=K.shape(inputs),\n                                                 mean=1.0,\n                                                 stddev=stddev)\n             return K.in_train_phase(noised, inputs, training=training)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8f6d12f45754721b11c3ce9ac62d747b391808cd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 58 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 8/7 | Churn Δ: 58 | Churn Cumulative: 1856 | Contributors (this commit): 8 | Commits (past 90d): 21 | Contributors (cumulative): 13 | DMM Complexity: 0.3142857142857143\n\nDIFF:\n@@ -5,6 +5,7 @@ from .. import backend as K\n from ..engine import Layer\n from ..engine import InputSpec\n from ..utils import conv_utils\n+from ..legacy import interfaces\n \n \n class _Pooling1D(Layer):\n@@ -66,6 +67,7 @@ class MaxPooling1D(_Pooling1D):\n         3D tensor with shape: `(batch_size, downsampled_steps, features)`.\n     \"\"\"\n \n+    @interfaces.legacy_maxpooling1d_support\n     def __init__(self, pool_size=2, strides=None,\n                  padding='valid', **kwargs):\n         super(MaxPooling1D, self).__init__(pool_size, strides,\n\n@@ -133,3 +133,47 @@ def legacy_dropout_support(func):\n \n         return func(*args, **kwargs)\n     return wrapper\n+\n+\n+def legacy_maxpooling1d_support(func):\n+    \"\"\"Function wrapper to convert the `MaxPooling1D` constructor from Keras 1 to 2.\n+\n+    # Arguments\n+        func: `__init__` method of `MaxPooling1D`.\n+\n+    # Returns\n+        A constructor conversion wrapper.\n+    \"\"\"\n+    @six.wraps(func)\n+    def wrapper(*args, **kwargs):\n+        if len(args) > 2:\n+            # The first entry in `args` is `self`.\n+            raise TypeError('The `MaxPooling1D` layer can have at most '\n+                            'one positional argument (the `pool_size` argument).')\n+\n+        # make sure that only keyword argument 'pool_size'(or pool_length' in the legacy interface)\n+        # can be also used as positional argument, which is keyword argument originally.\n+        if 'pool_length' in kwargs:\n+            if len(args) > 1:\n+                raise TypeError('Got both a positional argument '\n+                                'and keyword argument for argument '\n+                                '`pool_size` '\n+                                '(`pool_length` in the legacy interface).')\n+\n+        elif 'pool_size' in kwargs:\n+            if len(args) > 1:\n+                raise TypeError('Got both a positional argument '\n+                                'and keyword argument for argument '\n+                                '`pool_size`. ')\n+\n+        # Remaining kwargs.\n+        conversions = [\n+            ('pool_length', 'pool_size'),\n+            ('border_mode', 'padding'),\n+        ]\n+        kwargs = convert_legacy_kwargs('MaxPooling1D',\n+                                       args[1:],\n+                                       kwargs,\n+                                       conversions)\n+        return func(*args, **kwargs)\n+    return wrapper\n\n@@ -36,5 +36,17 @@ def test_dropout_legacy_interface():\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer_1.get_config())\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer_2.get_config())\n \n+\n+@keras_test\n+def test_maxpooling1d_legacy_interface():\n+    old_layer = keras.layers.MaxPool1D(pool_length=2, border_mode='valid', name='maxpool1d')\n+    new_layer = keras.layers.MaxPool1D(pool_size=2, padding='valid', name='maxpool1d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.MaxPool1D(2, padding='valid', name='maxpool1d')\n+    new_layer = keras.layers.MaxPool1D(pool_size=2, padding='valid', name='maxpool1d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#46a3f9443d4c6741177e0ff970c6b60488c9398c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 35 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 6/4 | Churn Δ: 39 | Churn Cumulative: 4766 | Contributors (this commit): 57 | Commits (past 90d): 59 | Contributors (cumulative): 59 | DMM Complexity: 1.0\n\nDIFF:\n@@ -388,8 +388,11 @@ def gather(reference, indices):\n \n     Return: a tensor of same type as reference.\n     \"\"\"\n-    # TODO: `keras_shape` inference.\n-    return reference[indices]\n+    y = reference[indices]\n+    if hasattr(reference, '_keras_shape') and hasattr(indices, '_keras_shape'):\n+        l = indices._keras_shape[0]\n+        y._keras_shape = (l,) + reference._keras_shape[1:]\n+    return y\n \n \n # ELEMENT-WISE OPERATIONS\n@@ -778,8 +781,18 @@ def arange(start, stop=None, step=1, dtype='int32'):\n \n \n def tile(x, n):\n-    # TODO: `keras_shape` inference.\n-    return T.tile(x, n)\n+    y = T.tile(x, n)\n+    if hasattr(x, '_keras_shape'):\n+        xshape = np.asarray(x._keras_shape)\n+        n = np.asarray(n)\n+        diff = len(xshape) - len(n)\n+        if diff > 0:\n+            n = np.append([1] * diff, n)\n+        else:\n+            xshape = np.append([1] * -diff, xshape)\n+        y._keras_shape = tuple(xshape * n)\n+\n+    return y\n \n \n def flatten(x):\n\n@@ -167,6 +167,24 @@ class TestBackend(object):\n         if hasattr(th_z, '_keras_shape'):\n             assert th_z._keras_shape == th_rep.shape\n \n+    def test_gather(self):\n+        shape = (10, 2, 3)\n+        ref = np.arange(np.prod(shape)).reshape(shape)\n+        ref_th = KTH.variable(ref)\n+        ref_tf = KTF.variable(ref)\n+\n+        inds = [1, 3, 7, 9]\n+        inds_th = KTH.variable(inds, dtype='int32')\n+        inds_tf = KTF.variable(inds, dtype='int32')\n+        th_z = KTH.gather(ref_th, inds_th)\n+        th_result = KTH.eval(th_z)\n+        tf_result = KTF.eval(KTF.gather(ref_tf, inds_tf))\n+\n+        assert_allclose(tf_result, th_result, atol=1e-05)\n+\n+        if hasattr(th_z, '_keras_shape'):\n+            assert th_z._keras_shape == th_result.shape\n+\n     def test_value_manipulation(self):\n         val = np.random.random((4, 2))\n         xth = KTH.variable(val)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#42b18506c53f05b1c84e6a905e76afb6a534a853", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 18 | Lines Deleted: 6 | Files Changed: 3 | Hunks: 7 | Methods Changed: 5 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 24 | Churn Cumulative: 1880 | Contributors (this commit): 9 | Commits (past 90d): 24 | Contributors (cumulative): 16 | DMM Complexity: 1.0\n\nDIFF:\n@@ -67,7 +67,7 @@ class MaxPooling1D(_Pooling1D):\n         3D tensor with shape: `(batch_size, downsampled_steps, features)`.\n     \"\"\"\n \n-    @interfaces.legacy_maxpooling1d_support\n+    @interfaces.legacy_pooling1d_support\n     def __init__(self, pool_size=2, strides=None,\n                  padding='valid', **kwargs):\n         super(MaxPooling1D, self).__init__(pool_size, strides,\n@@ -97,6 +97,7 @@ class AveragePooling1D(_Pooling1D):\n         3D tensor with shape: `(batch_size, downsampled_steps, features)`.\n     \"\"\"\n \n+    @interfaces.legacy_pooling1d_support\n     def __init__(self, pool_size=2, strides=None,\n                  padding='valid', **kwargs):\n         super(AveragePooling1D, self).__init__(pool_size, strides,\n\n@@ -135,11 +135,11 @@ def legacy_dropout_support(func):\n     return wrapper\n \n \n-def legacy_maxpooling1d_support(func):\n-    \"\"\"Function wrapper to convert the `MaxPooling1D` constructor from Keras 1 to 2.\n+def legacy_pooling1d_support(func):\n+    \"\"\"Function wrapper to convert `MaxPooling1D` or `AvgPooling1D` constructor from Keras 1 to 2.\n \n     # Arguments\n-        func: `__init__` method of `MaxPooling1D`.\n+        func: `__init__` method of `MaxPooling1D` or `AvgPooling1D`.\n \n     # Returns\n         A constructor conversion wrapper.\n@@ -148,7 +148,7 @@ def legacy_maxpooling1d_support(func):\n     def wrapper(*args, **kwargs):\n         if len(args) > 2:\n             # The first entry in `args` is `self`.\n-            raise TypeError('The `MaxPooling1D` layer can have at most '\n+            raise TypeError(args[0].__name__ + ' layer can have at most '\n                             'one positional argument (the `pool_size` argument).')\n \n         # make sure that only keyword argument 'pool_size'(or pool_length' in the legacy interface)\n@@ -171,7 +171,7 @@ def legacy_maxpooling1d_support(func):\n             ('pool_length', 'pool_size'),\n             ('border_mode', 'padding'),\n         ]\n-        kwargs = convert_legacy_kwargs('MaxPooling1D',\n+        kwargs = convert_legacy_kwargs(args[0].__name__,\n                                        args[1:],\n                                        kwargs,\n                                        conversions)\n\n@@ -48,5 +48,16 @@ def test_maxpooling1d_legacy_interface():\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n \n \n+@keras_test\n+def test_avgpooling1d_legacy_interface():\n+    old_layer = keras.layers.AvgPool1D(pool_length=2, border_mode='valid', name='d')\n+    new_layer = keras.layers.AvgPool1D(pool_size=2, padding='valid', name='d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.AvgPool1D(2, padding='valid', name='d')\n+    new_layer = keras.layers.AvgPool1D(pool_size=2, padding='valid', name='d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#74cf6df1535d18b55f9a9bf0b98d1ae6c2cc1860", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 247 | Contributors (this commit): 4 | Commits (past 90d): 7 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -148,7 +148,7 @@ def legacy_pooling1d_support(func):\n     def wrapper(*args, **kwargs):\n         if len(args) > 2:\n             # The first entry in `args` is `self`.\n-            raise TypeError(args[0].__name__ + ' layer can have at most '\n+            raise TypeError(args[0].__class__.__name__ + ' layer can have at most '\n                             'one positional argument (the `pool_size` argument).')\n \n         # make sure that only keyword argument 'pool_size'(or pool_length' in the legacy interface)\n@@ -171,7 +171,7 @@ def legacy_pooling1d_support(func):\n             ('pool_length', 'pool_size'),\n             ('border_mode', 'padding'),\n         ]\n-        kwargs = convert_legacy_kwargs(args[0].__name__,\n+        kwargs = convert_legacy_kwargs(args[0].__class__.__name__,\n                                        args[1:],\n                                        kwargs,\n                                        conversions)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c6c93739546cc88d7bc0be5981d27c9127b65678", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 62 | Lines Deleted: 159 | Files Changed: 1 | Hunks: 5 | Methods Changed: 10 | Complexity Δ (Sum/Max): -17/0 | Churn Δ: 221 | Churn Cumulative: 468 | Contributors (this commit): 4 | Commits (past 90d): 8 | Contributors (cumulative): 4 | DMM Complexity: 0.5972222222222222\n\nDIFF:\n@@ -4,6 +4,56 @@ import six\n import warnings\n \n \n+def generate_legacy_interface(allowed_positional_args=None,\n+                              conversions=None):\n+    allowed_positional_args = allowed_positional_args or []\n+    conversions = conversions or []\n+\n+    def legacy_support(func):\n+        @six.wraps(func)\n+        def wrapper(*args, **kwargs):\n+            layer_name = args[0].__class__.__name__\n+            converted = []\n+            if len(args) > len(allowed_positional_args) + 1:\n+                raise TypeError('Layer `' + layer_name +\n+                                '` can accept only ' +\n+                                str(len(allowed_positional_args)) +\n+                                ' positional arguments (' +\n+                                str(allowed_positional_args) + '), but '\n+                                'you passed the following '\n+                                'positional arguments: ' +\n+                                str(args[1:]))\n+            for old_name, new_name in conversions:\n+                if old_name in kwargs:\n+                    value = kwargs.pop(old_name)\n+                    if new_name in kwargs:\n+                        raise_duplicate_arg_error(old_name, new_name)\n+                    kwargs[new_name] = value\n+                    converted.append((new_name, old_name))\n+            if converted:\n+                signature = '`' + layer_name + '('\n+                for value in args[1:]:\n+                    if isinstance(value, six.string_types):\n+                        signature += '\"' + value + '\"'\n+                    else:\n+                        signature += str(value)\n+                    signature += ', '\n+                for i, (name, value) in enumerate(kwargs.items()):\n+                    signature += name + '='\n+                    if isinstance(value, six.string_types):\n+                        signature += '\"' + value + '\"'\n+                    else:\n+                        signature += str(value)\n+                    if i < len(kwargs) - 1:\n+                        signature += ', '\n+                signature += ')`'\n+                warnings.warn('Update your `' + layer_name +\n+                              '` layer call to the Keras 2 API: ' + signature)\n+            return func(*args, **kwargs)\n+        return wrapper\n+    return legacy_support\n+\n+\n def raise_duplicate_arg_error(old_arg, new_arg):\n     raise TypeError('For the `' + new_arg + '` argument, '\n                     'the layer received both '\n@@ -11,169 +61,22 @@ def raise_duplicate_arg_error(old_arg, new_arg):\n                     '`' + old_arg + '` and the Keras 2 keyword argument '\n                     '`' + new_arg + '`. Stick with the latter!')\n \n-\n-def convert_legacy_kwargs(layer_name,\n-                          args,\n-                          kwargs,\n-                          conversions,\n-                          converted=None):\n-    converted = converted or []\n-    for old_arg, new_arg in conversions:\n-        if old_arg in kwargs:\n-            if new_arg in kwargs:\n-                raise_duplicate_arg_error(old_arg, new_arg)\n-            arg_value = kwargs.pop(old_arg)\n-            kwargs[new_arg] = arg_value\n-            converted.append((new_arg, arg_value))\n-\n-    if converted:\n-        signature = '`' + layer_name + '('\n-        for value in args:\n-            if isinstance(value, six.string_types):\n-                signature += '\"' + value + '\"'\n-            else:\n-                signature += str(value)\n-            signature += ', '\n-        for i, (name, value) in enumerate(converted):\n-            signature += name + '='\n-            if isinstance(value, six.string_types):\n-                signature += '\"' + value + '\"'\n-            else:\n-                signature += str(value)\n-            if i < len(converted) - 1:\n-                signature += ', '\n-        signature += ')`'\n-        warnings.warn('Update your `' + layer_name + '` layer call '\n-                      'to the Keras 2 API: ' + signature)\n-    return kwargs\n-\n-\n-def legacy_dense_support(func):\n-    \"\"\"Function wrapper to convert the `Dense` constructor from Keras 1 to 2.\n-\n-    # Arguments\n-        func: `__init__` method of `Dense`.\n-\n-    # Returns\n-        A constructor conversion wrapper.\n-    \"\"\"\n-    @six.wraps(func)\n-    def wrapper(*args, **kwargs):\n-        if len(args) > 2:\n-            # The first entry in `args` is `self`.\n-            raise TypeError('The `Dense` layer can have at most '\n-                            'one positional argument (the `units` argument).')\n-\n-        # output_dim\n-        if 'output_dim' in kwargs:\n-            if len(args) > 1:\n-                raise TypeError('Got both a positional argument '\n-                                'and keyword argument for argument '\n-                                '`units` '\n-                                '(`output_dim` in the legacy interface).')\n-            if 'units' in kwargs:\n-                raise_duplicate_arg_error('output_dim', 'units')\n-            output_dim = kwargs.pop('output_dim')\n-            args = (args[0], output_dim)\n-\n-        # Remaining kwargs.\n-        conversions = [\n+legacy_dense_support = generate_legacy_interface(\n+    allowed_positional_args=['units'],\n+    conversions=[('output_dim', 'units'),\n                  ('init', 'kernel_initializer'),\n                  ('W_regularizer', 'kernel_regularizer'),\n                  ('b_regularizer', 'bias_regularizer'),\n                  ('W_constraint', 'kernel_constraint'),\n                  ('b_constraint', 'bias_constraint'),\n-            ('bias', 'use_bias'),\n-        ]\n-        kwargs = convert_legacy_kwargs('Dense',\n-                                       args[1:],\n-                                       kwargs,\n-                                       conversions)\n-        return func(*args, **kwargs)\n-    return wrapper\n+                 ('bias', 'use_bias')])\n \n+legacy_dropout_support = generate_legacy_interface(\n+    allowed_positional_args=['rate', 'noise_shape', 'seed'],\n+    conversions=[('p', 'rate')])\n \n-def legacy_dropout_support(func):\n-    \"\"\"Function wrapper to convert the `Dropout` constructor from Keras 1 to 2.\n-\n-    # Arguments\n-        func: `__init__` method of `Dropout`.\n-\n-    # Returns\n-        A constructor conversion wrapper.\n-    \"\"\"\n-    @six.wraps(func)\n-    def wrapper(*args, **kwargs):\n-        if len(args) > 2:\n-            # The first entry in `args` is `self`.\n-            raise TypeError('The `Dropout` layer can have at most '\n-                            'one positional argument (the `rate` argument).')\n-\n-        # Convert `p` to `rate` if keyword arguement is used\n-        if 'p' in kwargs:\n-            if len(args) > 1:\n-                raise TypeError('Got both a positional argument '\n-                                'and keyword argument for argument '\n-                                '`rate` '\n-                                '(`p` in the legacy interface).')\n-            if 'rate' in kwargs:\n-                raise_duplicate_arg_error('p', 'rate')\n-            rate = kwargs.pop('p')\n-            args = (args[0], rate)\n-            signature = '`Dropout(' + str(args[1])\n-            for kwarg in kwargs:\n-                signature += ', ' + kwarg + '='\n-                if isinstance(kwargs[kwarg], six.string_types):\n-                    signature += ('\"' + kwargs[kwarg] + '\"')\n-                else:\n-                    signature += str(kwargs[kwarg])\n-            signature += ')`'\n-            warnings.warn('Update your `Dropout` layer call '\n-                          'to the Keras 2 API: ' + signature)\n-\n-        return func(*args, **kwargs)\n-    return wrapper\n-\n-\n-def legacy_pooling1d_support(func):\n-    \"\"\"Function wrapper to convert `MaxPooling1D` or `AvgPooling1D` constructor from Keras 1 to 2.\n-\n-    # Arguments\n-        func: `__init__` method of `MaxPooling1D` or `AvgPooling1D`.\n-\n-    # Returns\n-        A constructor conversion wrapper.\n-    \"\"\"\n-    @six.wraps(func)\n-    def wrapper(*args, **kwargs):\n-        if len(args) > 2:\n-            # The first entry in `args` is `self`.\n-            raise TypeError(args[0].__class__.__name__ + ' layer can have at most '\n-                            'one positional argument (the `pool_size` argument).')\n-\n-        # make sure that only keyword argument 'pool_size'(or pool_length' in the legacy interface)\n-        # can be also used as positional argument, which is keyword argument originally.\n-        if 'pool_length' in kwargs:\n-            if len(args) > 1:\n-                raise TypeError('Got both a positional argument '\n-                                'and keyword argument for argument '\n-                                '`pool_size` '\n-                                '(`pool_length` in the legacy interface).')\n-\n-        elif 'pool_size' in kwargs:\n-            if len(args) > 1:\n-                raise TypeError('Got both a positional argument '\n-                                'and keyword argument for argument '\n-                                '`pool_size`. ')\n-\n-        # Remaining kwargs.\n-        conversions = [\n-            ('pool_length', 'pool_size'),\n-            ('border_mode', 'padding'),\n-        ]\n-        kwargs = convert_legacy_kwargs(args[0].__class__.__name__,\n-                                       args[1:],\n-                                       kwargs,\n-                                       conversions)\n-        return func(*args, **kwargs)\n-    return wrapper\n+legacy_pooling1d_support = generate_legacy_interface(\n+    allowed_positional_args=['pool_size', 'strides', 'padding'],\n+    conversions=[('pool_length', 'pool_size'),\n+                 ('stride', 'strides'),\n+                 ('border_mode', 'padding')])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5374cec3c548fae888ee7b0cd541ab4d14b8dc97", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 18 | Lines Deleted: 7 | Files Changed: 3 | Hunks: 8 | Methods Changed: 7 | Complexity Δ (Sum/Max): -26/18 | Churn Δ: 25 | Churn Cumulative: 13457 | Contributors (this commit): 82 | Commits (past 90d): 126 | Contributors (cumulative): 140 | DMM Complexity: 1.0\n\nDIFF:\n@@ -3091,7 +3091,7 @@ def ctc_decode(y_pred, input_length, greedy=True, beam_width=100,\n \n # HIGH ORDER FUNCTIONS\n \n-def map_fn(fn, elems, name=None):\n+def map_fn(fn, elems, name=None, dtype=None):\n     \"\"\"Map the function fn over the elements elems and return the outputs.\n \n     # Arguments\n@@ -3103,7 +3103,7 @@ def map_fn(fn, elems, name=None):\n         Tensor with first dimension equal to the elems and second depending on\n         fn\n     \"\"\"\n-    return tf.map_fn(fn, elems, name=name)\n+    return tf.map_fn(fn, elems, name=name, dtype=dtype)\n \n \n def foldl(fn, elems, initializer=None, name=None):\n\n@@ -2061,7 +2061,7 @@ def ctc_batch_cost(y_true, y_pred, input_length, label_length):\n \n # HIGH ORDER FUNCTIONS\n \n-def map_fn(fn, elems, name=None):\n+def map_fn(fn, elems, name=None, dtype=None):\n     \"\"\"Map the function fn over the elements elems and return the outputs.\n \n     # Arguments\n\n@@ -908,15 +908,25 @@ class TestBackend(object):\n     def test_map(self):\n         x = np.random.rand(10, 3).astype(np.float32)\n         for K in [KTF, KTH]:\n-            kx = K.eval(K.map_fn(K.sum, x))\n+            vx = K.variable(x)\n+            kx = K.eval(K.map_fn(K.sum, vx))\n+            # make sure we can also walk the indexes in tensorflow which we\n+            # can't without specifying dtype\n+            kx2 = K.eval(K.map_fn(\n+                lambda i: K.sum(vx[i]),\n+                K.arange(10),\n+                dtype=K.floatx()\n+            ))\n \n             assert (10,) == kx.shape\n+            assert (10,) == kx2.shape\n             assert_allclose(x.sum(axis=1), kx, atol=1e-05)\n+            assert_allclose(kx, kx2, atol=1e-05)\n \n     def test_foldl(self):\n         x = np.random.rand(10, 3).astype(np.float32)\n         for K in [KTF, KTH]:\n-            kx = K.eval(K.foldl(lambda a, b: a + b, x))\n+            kx = K.eval(K.foldl(lambda a, b: a + b, K.variable(x)))\n \n             assert (3,) == kx.shape\n             assert_allclose(x.sum(axis=0), kx, atol=1e-05)\n@@ -928,8 +938,9 @@ class TestBackend(object):\n         # right to left we have no such problem and the result is larger\n         x = np.array([1e-20, 1e-20, 10, 10, 10], dtype=np.float32)\n         for K in [KTF, KTH]:\n-            p1 = K.eval(K.foldl(lambda a, b: a * b, x))\n-            p2 = K.eval(K.foldr(lambda a, b: a * b, x))\n+            vx = K.variable(x)\n+            p1 = K.eval(K.foldl(lambda a, b: a * b, vx))\n+            p2 = K.eval(K.foldr(lambda a, b: a * b, vx))\n \n             assert p1 < p2\n             assert 9e-38 < p2 <= 1e-37\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0744a2577800134a891a9cf26a25a46aee0922cb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 3 | Methods Changed: 4 | Complexity Δ (Sum/Max): 5/5 | Churn Δ: 9 | Churn Cumulative: 477 | Contributors (this commit): 5 | Commits (past 90d): 9 | Contributors (cumulative): 5 | DMM Complexity: 0.2857142857142857\n\nDIFF:\n@@ -5,9 +5,11 @@ import warnings\n \n \n def generate_legacy_interface(allowed_positional_args=None,\n-                              conversions=None):\n+                              conversions=None,\n+                              value_conversions=None):\n     allowed_positional_args = allowed_positional_args or []\n     conversions = conversions or []\n+    value_conversions = value_conversions or []\n \n     def legacy_support(func):\n         @six.wraps(func)\n@@ -23,6 +25,11 @@ def generate_legacy_interface(allowed_positional_args=None,\n                                 'you passed the following '\n                                 'positional arguments: ' +\n                                 str(args[1:]))\n+            for key in list(value_conversions.keys()):\n+                if key in kwargs:\n+                    for old_value, new_value in value_conversions[key]:\n+                        if kwargs[key] == old_value:\n+                            kwargs[key] = new_value\n             for old_name, new_name in conversions:\n                 if old_name in kwargs:\n                     value = kwargs.pop(old_name)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#080aa7a6ad9730e8e07b8d6fdc64550af1b53708", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 56 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 56 | Churn Cumulative: 2170 | Contributors (this commit): 10 | Commits (past 90d): 30 | Contributors (cumulative): 19 | DMM Complexity: 1.0\n\nDIFF:\n@@ -204,6 +204,7 @@ class MaxPooling2D(_Pooling2D):\n             `(batch_size, channels, pooled_rows, pooled_cols)`\n     \"\"\"\n \n+    @interfaces.legacy_pooling2d_support\n     def __init__(self, pool_size=(2, 2), strides=None, padding='valid',\n                  data_format=None, **kwargs):\n         super(MaxPooling2D, self).__init__(pool_size, strides, padding,\n@@ -258,6 +259,7 @@ class AveragePooling2D(_Pooling2D):\n             `(batch_size, channels, pooled_rows, pooled_cols)`\n     \"\"\"\n \n+    @interfaces.legacy_pooling2d_support\n     def __init__(self, pool_size=(2, 2), strides=None, padding='valid',\n                  data_format=None, **kwargs):\n         super(AveragePooling2D, self).__init__(pool_size, strides, padding,\n\n@@ -87,3 +87,11 @@ legacy_pooling1d_support = generate_legacy_interface(\n     conversions=[('pool_length', 'pool_size'),\n                  ('stride', 'strides'),\n                  ('border_mode', 'padding')])\n+\n+legacy_pooling2d_support = generate_legacy_interface(\n+    allowed_positional_args=['pool_size', 'strides', 'padding'],\n+    conversions=[('pool_length', 'pool_size'),\n+                 ('stride', 'strides'),\n+                 ('border_mode', 'padding'),\n+                 ('dim_ordering', 'data_format')],\n+    value_conversions={'dim_ordering': [('tf', 'channels_last'), ('th', 'channels_first'), ('default', None)]})\n\n@@ -59,5 +59,51 @@ def test_avgpooling1d_legacy_interface():\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n \n \n+@keras_test\n+def test_maxpooling2d_legacy_interface():\n+    old_layer = keras.layers.MaxPooling2D(pool_length=2, border_mode='valid', name='maxpool2d')\n+    new_layer = keras.layers.MaxPooling2D(pool_size=2, padding='valid', name='maxpool2dd')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.MaxPooling2D(2, padding='valid', name='maxpool2d')\n+    new_layer = keras.layers.MaxPooling2D(pool_size=2, padding='valid', name='maxpool2d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.MaxPooling2D(2, padding='valid', dim_ordering='tf', name='maxpool2d')\n+    new_layer = keras.layers.MaxPooling2D(pool_size=2, padding='valid', data_format='channels_last', name='maxpool2d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.MaxPooling2D(2, padding='valid', dim_ordering='th', name='maxpool2d')\n+    new_layer = keras.layers.MaxPooling2D(pool_size=2, padding='valid', data_format='channels_first', name='maxpool2d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.MaxPooling2D(2, padding='valid', dim_ordering='default', name='maxpool2d')\n+    new_layer = keras.layers.MaxPooling2D(pool_size=2, padding='valid', name='maxpool2d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+\n+@keras_test\n+def test_avgpooling2d_legacy_interface():\n+    old_layer = keras.layers.AveragePooling2D(pool_length=2, border_mode='valid', name='avgpooling2d')\n+    new_layer = keras.layers.AveragePooling2D(pool_size=2, padding='valid', name='avgpooling2d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.AveragePooling2D(2, padding='valid', name='avgpooling2d')\n+    new_layer = keras.layers.AveragePooling2D(pool_size=2, padding='valid', name='avgpooling2d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.AveragePooling2D(2, padding='valid', dim_ordering='tf', name='avgpooling2d')\n+    new_layer = keras.layers.AveragePooling2D(pool_size=2, padding='valid', data_format='channels_last', name='avgpooling2d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.AveragePooling2D(2, padding='valid', dim_ordering='th', name='avgpooling2d')\n+    new_layer = keras.layers.AveragePooling2D(pool_size=2, padding='valid', data_format='channels_first', name='avgpooling2d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.AveragePooling2D(2, padding='valid', dim_ordering='default', name='avgpooling2d')\n+    new_layer = keras.layers.AveragePooling2D(pool_size=2, padding='valid', name='avgpooling2d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#76b4db7767d3d593066e132f8f516dfcd211acf0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 489 | Contributors (this commit): 5 | Commits (past 90d): 11 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -27,7 +27,7 @@ def generate_legacy_interface(allowed_positional_args=None,\n                                 str(args[1:]))\n             for key in list(value_conversions.keys()):\n                 if key in kwargs:\n-                    for old_value, new_value in value_conversions[key]:\n+                    for old_value, new_value in value_conversions[key].items():\n                         if kwargs[key] == old_value:\n                             kwargs[key] = new_value\n             for old_name, new_name in conversions:\n@@ -94,4 +94,4 @@ legacy_pooling2d_support = generate_legacy_interface(\n                  ('stride', 'strides'),\n                  ('border_mode', 'padding'),\n                  ('dim_ordering', 'data_format')],\n-    value_conversions={'dim_ordering': [('tf', 'channels_last'), ('th', 'channels_first'), ('default', None)]})\n+    value_conversions={'dim_ordering': {'tf': 'channels_last', 'th': 'channels_first', 'default': None}})\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#78eedad77a2da3b7062fdcf8224c3baa173b2ec6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 4 | Methods Changed: 1 | Complexity Δ (Sum/Max): -6/0 | Churn Δ: 13 | Churn Cumulative: 1920 | Contributors (this commit): 20 | Commits (past 90d): 34 | Contributors (cumulative): 29 | DMM Complexity: 1.0\n\nDIFF:\n@@ -7,6 +7,7 @@ from .. import constraints\n from ..engine import Layer\n from ..engine import InputSpec\n from .. import backend as K\n+from ..legacy import interfaces\n \n \n class LeakyReLU(Layer):\n@@ -78,6 +79,7 @@ class PReLU(Layer):\n         - [Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification](https://arxiv.org/abs/1502.01852)\n     \"\"\"\n \n+    @interfaces.legacy_prelu_support\n     def __init__(self, alpha_initializer='zeros',\n                  alpha_regularizer=None,\n                  alpha_constraint=None,\n\n@@ -80,3 +80,7 @@ legacy_pooling1d_support = generate_legacy_interface(\n     conversions=[('pool_length', 'pool_size'),\n                  ('stride', 'strides'),\n                  ('border_mode', 'padding')])\n+\n+legacy_prelu_support = generate_legacy_interface(\n+    allowed_positional_args=['alpha_initializer'],\n+    conversions=[('init', 'alpha_initializer')])\n\n@@ -59,5 +59,12 @@ def test_avgpooling1d_legacy_interface():\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n \n \n+@keras_test\n+def test_prelu_legacy_interface():\n+    old_layer = keras.layers.PReLU(init='zero', name='p')\n+    new_layer = keras.layers.PReLU('zero', name='p')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4b754736907bd9834429717a96c44decf063c32f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 3 | Complexity Δ (Sum/Max): 5/5 | Churn Δ: 2 | Churn Cumulative: 495 | Contributors (this commit): 6 | Commits (past 90d): 13 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -25,7 +25,7 @@ def generate_legacy_interface(allowed_positional_args=None,\n                                 'you passed the following '\n                                 'positional arguments: ' +\n                                 str(args[1:]))\n-            for key in list(value_conversions.keys()):\n+            for key in value_conversions:\n                 if key in kwargs:\n                     for old_value, new_value in value_conversions[key].items():\n                         if kwargs[key] == old_value:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e645a18e83583189ea6216c91d4d77798fdbf611", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 4 | Methods Changed: 1 | Complexity Δ (Sum/Max): -4/1 | Churn Δ: 13 | Churn Cumulative: 932 | Contributors (this commit): 10 | Commits (past 90d): 29 | Contributors (cumulative): 18 | DMM Complexity: 1.0\n\nDIFF:\n@@ -4,6 +4,7 @@ from __future__ import absolute_import\n from ..engine import Layer\n from .. import backend as K\n import numpy as np\n+from ..legacy import interfaces\n \n \n class GaussianNoise(Layer):\n@@ -28,6 +29,7 @@ class GaussianNoise(Layer):\n         Same shape as input.\n     \"\"\"\n \n+    @interfaces.legacy_gaussiannoise_support\n     def __init__(self, stddev, **kwargs):\n         super(GaussianNoise, self).__init__(**kwargs)\n         self.supports_masking = True\n\n@@ -84,3 +84,7 @@ legacy_pooling1d_support = generate_legacy_interface(\n legacy_prelu_support = generate_legacy_interface(\n     allowed_positional_args=['alpha_initializer'],\n     conversions=[('init', 'alpha_initializer')])\n+\n+legacy_gaussiannoise_support = generate_legacy_interface(\n+    allowed_positional_args=['stddev'],\n+    conversions=[('sigma', 'stddev')])\n\n@@ -66,5 +66,12 @@ def test_prelu_legacy_interface():\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n \n \n+@keras_test\n+def test_gaussiannoise_legacy_interface():\n+    old_layer = keras.layers.GaussianNoise(sigma=0.5, name='gn')\n+    new_layer = keras.layers.GaussianNoise(stddev=0.5, name='gn')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6cc11224fb4c77a03b31bd8317e861eedb3b2d42", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 20 | Files Changed: 1 | Hunks: 10 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 40 | Churn Cumulative: 163 | Contributors (this commit): 6 | Commits (past 90d): 8 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -75,47 +75,47 @@ def test_gaussiannoise_legacy_interface():\n \n @keras_test\n def test_maxpooling2d_legacy_interface():\n-    old_layer = keras.layers.MaxPooling2D(pool_length=2, border_mode='valid', name='maxpool2d')\n-    new_layer = keras.layers.MaxPooling2D(pool_size=2, padding='valid', name='maxpool2dd')\n+    old_layer = keras.layers.MaxPool2D(pool_length=2, border_mode='valid', name='maxpool2d')\n+    new_layer = keras.layers.MaxPool2D(pool_size=2, padding='valid', name='maxpool2d')\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n \n-    old_layer = keras.layers.MaxPooling2D(2, padding='valid', name='maxpool2d')\n-    new_layer = keras.layers.MaxPooling2D(pool_size=2, padding='valid', name='maxpool2d')\n+    old_layer = keras.layers.MaxPool2D(2, padding='valid', name='maxpool2d')\n+    new_layer = keras.layers.MaxPool2D(pool_size=2, padding='valid', name='maxpool2d')\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n \n-    old_layer = keras.layers.MaxPooling2D(2, padding='valid', dim_ordering='tf', name='maxpool2d')\n-    new_layer = keras.layers.MaxPooling2D(pool_size=2, padding='valid', data_format='channels_last', name='maxpool2d')\n+    old_layer = keras.layers.MaxPool2D(2, padding='valid', dim_ordering='tf', name='maxpool2d')\n+    new_layer = keras.layers.MaxPool2D(pool_size=2, padding='valid', data_format='channels_last', name='maxpool2d')\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n \n-    old_layer = keras.layers.MaxPooling2D(2, padding='valid', dim_ordering='th', name='maxpool2d')\n-    new_layer = keras.layers.MaxPooling2D(pool_size=2, padding='valid', data_format='channels_first', name='maxpool2d')\n+    old_layer = keras.layers.MaxPool2D(2, padding='valid', dim_ordering='th', name='maxpool2d')\n+    new_layer = keras.layers.MaxPool2D(pool_size=2, padding='valid', data_format='channels_first', name='maxpool2d')\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n \n-    old_layer = keras.layers.MaxPooling2D(2, padding='valid', dim_ordering='default', name='maxpool2d')\n-    new_layer = keras.layers.MaxPooling2D(pool_size=2, padding='valid', name='maxpool2d')\n+    old_layer = keras.layers.MaxPool2D(2, padding='valid', dim_ordering='default', name='maxpool2d')\n+    new_layer = keras.layers.MaxPool2D(pool_size=2, padding='valid', name='maxpool2d')\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n \n \n @keras_test\n def test_avgpooling2d_legacy_interface():\n-    old_layer = keras.layers.AveragePooling2D(pool_length=2, border_mode='valid', name='avgpooling2d')\n-    new_layer = keras.layers.AveragePooling2D(pool_size=2, padding='valid', name='avgpooling2d')\n+    old_layer = keras.layers.AvgPool2D(pool_length=2, border_mode='valid', name='avgpooling2d')\n+    new_layer = keras.layers.AvgPool2D(pool_size=2, padding='valid', name='avgpooling2d')\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n \n-    old_layer = keras.layers.AveragePooling2D(2, padding='valid', name='avgpooling2d')\n-    new_layer = keras.layers.AveragePooling2D(pool_size=2, padding='valid', name='avgpooling2d')\n+    old_layer = keras.layers.AvgPool2D(2, padding='valid', name='avgpooling2d')\n+    new_layer = keras.layers.AvgPool2D(pool_size=2, padding='valid', name='avgpooling2d')\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n \n-    old_layer = keras.layers.AveragePooling2D(2, padding='valid', dim_ordering='tf', name='avgpooling2d')\n-    new_layer = keras.layers.AveragePooling2D(pool_size=2, padding='valid', data_format='channels_last', name='avgpooling2d')\n+    old_layer = keras.layers.AvgPool2D(2, padding='valid', dim_ordering='tf', name='avgpooling2d')\n+    new_layer = keras.layers.AvgPool2D(pool_size=2, padding='valid', data_format='channels_last', name='avgpooling2d')\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n \n-    old_layer = keras.layers.AveragePooling2D(2, padding='valid', dim_ordering='th', name='avgpooling2d')\n-    new_layer = keras.layers.AveragePooling2D(pool_size=2, padding='valid', data_format='channels_first', name='avgpooling2d')\n+    old_layer = keras.layers.AvgPool2D(2, padding='valid', dim_ordering='th', name='avgpooling2d')\n+    new_layer = keras.layers.AvgPool2D(pool_size=2, padding='valid', data_format='channels_first', name='avgpooling2d')\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n \n-    old_layer = keras.layers.AveragePooling2D(2, padding='valid', dim_ordering='default', name='avgpooling2d')\n-    new_layer = keras.layers.AveragePooling2D(pool_size=2, padding='valid', name='avgpooling2d')\n+    old_layer = keras.layers.AvgPool2D(2, padding='valid', dim_ordering='default', name='avgpooling2d')\n+    new_layer = keras.layers.AvgPool2D(pool_size=2, padding='valid', name='avgpooling2d')\n \n \n if __name__ == '__main__':\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2ad58e1dccf530826b9a8166577975d5f6a0d187", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 14 | Churn Cumulative: 986 | Contributors (this commit): 10 | Commits (past 90d): 33 | Contributors (cumulative): 18 | DMM Complexity: 1.0\n\nDIFF:\n@@ -70,6 +70,7 @@ class GaussianDropout(Layer):\n         - [Dropout: A Simple Way to Prevent Neural Networks from Overfitting Srivastava, Hinton, et al. 2014](http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf)\n     \"\"\"\n \n+    @interfaces.legacy_gaussiandropout_support\n     def __init__(self, rate, **kwargs):\n         super(GaussianDropout, self).__init__(**kwargs)\n         self.supports_masking = True\n\n@@ -88,3 +88,7 @@ legacy_prelu_support = generate_legacy_interface(\n legacy_gaussiannoise_support = generate_legacy_interface(\n     allowed_positional_args=['stddev'],\n     conversions=[('sigma', 'stddev')])\n+\n+legacy_gaussiandropout_support = generate_legacy_interface(\n+    allowed_positional_args=['rate'],\n+    conversions=[('p', 'rate')])\n\n@@ -73,5 +73,14 @@ def test_gaussiannoise_legacy_interface():\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n \n \n+@keras_test\n+def test_gaussiandropout_legacy_interface():\n+    old_layer = keras.layers.GaussianDropout(p=0.6, name='drop')\n+    new_layer_1 = keras.layers.GaussianDropout(rate=0.6, name='drop')\n+    new_layer_2 = keras.layers.GaussianDropout(0.6, name='drop')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer_1.get_config())\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer_2.get_config())\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b2a992e08f9a045fa51046d795d7004482a05140", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 12 | Files Changed: 4 | Hunks: 10 | Methods Changed: 5 | Complexity Δ (Sum/Max): -18/0 | Churn Δ: 26 | Churn Cumulative: 26285 | Contributors (this commit): 122 | Commits (past 90d): 129 | Contributors (cumulative): 161 | DMM Complexity: 0.0\n\nDIFF:\n@@ -3076,16 +3076,18 @@ def bias_add(x, bias, data_format=None):\n             x += reshape(bias, (1, 1, 1, 1, int_shape(bias)[0]))\n     elif ndim(x) == 4:\n         if data_format == 'channels_first':\n-            x += reshape(bias, (1, int_shape(bias)[0], 1, 1))\n+            x = tf.nn.bias_add(x, bias,\n+                               data_format='NCHW')\n         elif data_format == 'channels_last':\n-            x += reshape(bias, (1, 1, 1, int_shape(bias)[0]))\n+            x = tf.nn.bias_add(x, bias,\n+                               data_format='NHWC')\n     elif ndim(x) == 3:\n         if data_format == 'channels_first':\n             x += reshape(bias, (1, int_shape(bias)[0], 1))\n         elif data_format == 'channels_last':\n             x += reshape(bias, (1, 1, int_shape(bias)[0]))\n     else:\n-        x += bias\n+        x = tf.nn.bias_add(x, bias)\n     return x\n \n \n\n@@ -835,7 +835,7 @@ class Dense(Layer):\n     def call(self, inputs):\n         output = K.dot(inputs, self.kernel)\n         if self.use_bias:\n-            output += self.bias\n+            output = K.bias_add(output, self.bias)\n         if self.activation is not None:\n             output = self.activation(output)\n         return output\n\n@@ -48,7 +48,7 @@ def _time_distributed_dense(x, w, b=None, dropout=None,\n     x = K.reshape(x, (-1, input_dim))\n     x = K.dot(x, w)\n     if b is not None:\n-        x += b\n+        x = K.bias_add(x, b)\n     # reshape to 3D tensor\n     if K.backend() == 'tensorflow':\n         x = K.reshape(x, K.stack([-1, timesteps, output_dim]))\n@@ -432,7 +432,7 @@ class SimpleRNN(Recurrent):\n             else:\n                 h = K.dot(inputs, self.kernel)\n             if self.bias is not None:\n-                h += self.bias\n+                h = K.bias_add(h, self.bias)\n \n         prev_output = states[0]\n         if 0 < self.recurrent_dropout < 1:\n@@ -715,7 +715,7 @@ class GRU(Recurrent):\n         if self.implementation == 1:\n             matrix_x = K.dot(inputs * dp_mask[0], self.kernel)\n             if self.use_bias:\n-                matrix_x += self.bias\n+                matrix_x = K.bias_add(matrix_x, self.bias)\n             matrix_inner = K.dot(h_tm1 * rec_dp_mask[0],\n                                  self.recurrent_kernel[:, :2 * self.units])\n \n@@ -741,9 +741,9 @@ class GRU(Recurrent):\n                 x_r = K.dot(inputs * dp_mask[1], self.kernel_r)\n                 x_h = K.dot(inputs * dp_mask[2], self.kernel_h)\n                 if self.use_bias:\n-                    x_z += self.bias_z\n-                    x_r += self.bias_r\n-                    x_h += self.bias_h\n+                    x_z = K.bias_add(x_z, self.bias_z)\n+                    x_r = K.bias_add(self.bias_r)\n+                    x_h = K.bias_add(self.bias_h)\n             else:\n                 raise ValueError('Unknown `implementation` mode.')\n             z = self.recurrent_activation(x_z + K.dot(h_tm1 * rec_dp_mask[0],\n@@ -1018,7 +1018,7 @@ class LSTM(Recurrent):\n             z = K.dot(inputs * dp_mask[0], self.kernel)\n             z += K.dot(h_tm1 * rec_dp_mask[0], self.recurrent_kernel)\n             if self.use_bias:\n-                z += self.bias\n+                z = K.bias_add(z, self.bias)\n \n             z0 = z[:, :self.units]\n             z1 = z[:, self.units: 2 * self.units]\n\n@@ -59,7 +59,7 @@ def raise_duplicate_arg_error(old_arg, new_arg):\n                     'the layer received both '\n                     'the legacy keyword argument '\n                     '`' + old_arg + '` and the Keras 2 keyword argument '\n-                    '`' + new_arg + '`. Stick with the latter!')\n+                    '`' + new_arg + '`. Stick to the latter!')\n \n legacy_dense_support = generate_legacy_interface(\n     allowed_positional_args=['units'],\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
