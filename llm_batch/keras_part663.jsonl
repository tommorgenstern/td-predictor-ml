{"custom_id": "keras#cef6dfae9c896182352f3bc0acfa4a942a4dafbf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 380 | Lines Deleted: 6 | Files Changed: 5 | Hunks: 7 | Methods Changed: 9 | Complexity Δ (Sum/Max): 14/11 | Churn Δ: 386 | Churn Cumulative: 1913 | Contributors (this commit): 5 | Commits (past 90d): 35 | Contributors (cumulative): 10 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,357 @@\n+\"\"\"\n+Title: Customizing what happens in `fit()` with JAX\n+Author: [fchollet](https://twitter.com/fchollet)\n+Date created: 2023/06/27\n+Last modified: 2023/06/27\n+Description: Overriding the training step of the Model class with JAX.\n+Accelerator: GPU\n+\"\"\"\n+\n+\"\"\"\n+## Introduction\n+\n+When you're doing supervised learning, you can use `fit()` and everything works\n+smoothly.\n+\n+When you need to take control of every little detail, you can write your own training\n+loop entirely from scratch.\n+\n+But what if you need a custom training algorithm, but you still want to benefit from\n+the convenient features of `fit()`, such as callbacks, built-in distribution support,\n+or step fusing?\n+\n+A core principle of Keras is **progressive disclosure of complexity**. You should\n+always be able to get into lower-level workflows in a gradual way. You shouldn't fall\n+off a cliff if the high-level functionality doesn't exactly match your use case. You\n+should be able to gain more control over the small details while retaining a\n+commensurate amount of high-level convenience.\n+\n+When you need to customize what `fit()` does, you should **override the training step\n+function of the `Model` class**. This is the function that is called by `fit()` for\n+every batch of data. You will then be able to call `fit()` as usual -- and it will be\n+running your own learning algorithm.\n+\n+Note that this pattern does not prevent you from building models with the Functional\n+API. You can do this whether you're building `Sequential` models, Functional API\n+models, or subclassed models.\n+\n+Let's see how that works.\n+\"\"\"\n+\n+\"\"\"\n+## Setup\n+\"\"\"\n+\n+import os\n+\n+# This guide can only be run with the JAX backend.\n+os.environ[\"KERAS_BACKEND\"] = \"jax\"\n+\n+import jax\n+import keras_core as keras\n+import numpy as np\n+\n+\"\"\"\n+## A first simple example\n+\n+Let's start from a simple example:\n+\n+- We create a new class that subclasses `keras.Model`.\n+- We implement a fully-stateless `compute_loss_and_updates()` method\n+to compute the loss as well as the updated values for the non-trainable\n+variables of the model. Internally, it calls `stateless_call()` and\n+the built-in `compute_loss()`.\n+- We implement a fully-stateless `train_step()` method to compute current\n+metric values (including the loss) as well as updated values for the \n+trainable variables, the optimizer variables, and the metric variables.\n+\n+Note that you can also take into account the `sample_weight` argument by:\n+\n+- Unpacking the data as `x, y, sample_weight = data`\n+- Passing `sample_weight` to `compute_loss()`\n+- Passing `sample_weight` alongside `y` and `y_pred`\n+to metrics in `stateless_update_state()`\n+\"\"\"\n+\n+\n+class CustomModel(keras.Model):\n+    def compute_loss_and_updates(\n+        self,\n+        trainable_variables,\n+        non_trainable_variables,\n+        x,\n+        y,\n+        training=False,\n+    ):\n+        y_pred, non_trainable_variables = self.stateless_call(\n+            trainable_variables,\n+            non_trainable_variables,\n+            x,\n+            training=training,\n+        )\n+        loss = self.compute_loss(x, y, y_pred)\n+        return loss, (y_pred, non_trainable_variables)\n+\n+    def train_step(self, state, data):\n+        (\n+            trainable_variables,\n+            non_trainable_variables,\n+            optimizer_variables,\n+            metrics_variables,\n+        ) = state\n+        x, y = data\n+\n+        # Get the gradient function.\n+        grad_fn = jax.value_and_grad(\n+            self.compute_loss_and_updates, has_aux=True\n+        )\n+\n+        # Compute the gradients.\n+        (loss, (y_pred, non_trainable_variables)), grads = grad_fn(\n+            trainable_variables,\n+            non_trainable_variables,\n+            x,\n+            y,\n+            training=True,\n+        )\n+\n+        # Update trainable variables and optimizer variables.\n+        (\n+            trainable_variables,\n+            optimizer_variables,\n+        ) = self.optimizer.stateless_apply(\n+            optimizer_variables, grads, trainable_variables\n+        )\n+\n+        # Update metrics.\n+        new_metrics_vars = []\n+        for metric in self.metrics:\n+            this_metric_vars = metrics_variables[\n+                len(new_metrics_vars) : len(new_metrics_vars)\n+                + len(metric.variables)\n+            ]\n+            if metric.name == \"loss\":\n+                this_metric_vars = metric.stateless_update_state(\n+                    this_metric_vars, loss\n+                )\n+            else:\n+                this_metric_vars = metric.stateless_update_state(\n+                    this_metric_vars, y, y_pred\n+                )\n+            logs = metric.stateless_result(this_metric_vars)\n+            new_metrics_vars += this_metric_vars\n+\n+        # Return metric logs and updated state variables.\n+        state = (\n+            trainable_variables,\n+            non_trainable_variables,\n+            optimizer_variables,\n+            new_metrics_vars,\n+        )\n+        return logs, state\n+\n+\n+\"\"\"\n+Let's try this out:\n+\"\"\"\n+\n+# Construct and compile an instance of CustomModel\n+inputs = keras.Input(shape=(32,))\n+outputs = keras.layers.Dense(1)(inputs)\n+model = CustomModel(inputs, outputs)\n+model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n+\n+# Just use `fit` as usual\n+x = np.random.random((1000, 32))\n+y = np.random.random((1000, 1))\n+model.fit(x, y, epochs=3)\n+\n+\n+\"\"\"\n+## Going lower-level\n+\n+Naturally, you could just skip passing a loss function in `compile()`, and instead do\n+everything *manually* in `train_step`. Likewise for metrics.\n+\n+Here's a lower-level example, that only uses `compile()` to configure the optimizer:\n+\"\"\"\n+\n+\n+class CustomModel(keras.Model):\n+    def __init__(self, *args, **kwargs):\n+        super().__init__(*args, **kwargs)\n+        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n+        self.mae_metric = keras.metrics.MeanAbsoluteError(name=\"mae\")\n+        self.loss_fn = keras.losses.MeanSquaredError()\n+\n+    def compute_loss_and_updates(\n+        self,\n+        trainable_variables,\n+        non_trainable_variables,\n+        x,\n+        y,\n+        training=False,\n+    ):\n+        y_pred, non_trainable_variables = self.stateless_call(\n+            trainable_variables,\n+            non_trainable_variables,\n+            x,\n+            training=training,\n+        )\n+        loss = self.loss_fn(y, y_pred)\n+        return loss, (y_pred, non_trainable_variables)\n+\n+    def train_step(self, state, data):\n+        (\n+            trainable_variables,\n+            non_trainable_variables,\n+            optimizer_variables,\n+            metrics_variables,\n+        ) = state\n+        x, y = data\n+\n+        # Get the gradient function.\n+        grad_fn = jax.value_and_grad(\n+            self.compute_loss_and_updates, has_aux=True\n+        )\n+\n+        # Compute the gradients.\n+        (loss, (y_pred, non_trainable_variables)), grads = grad_fn(\n+            trainable_variables,\n+            non_trainable_variables,\n+            x,\n+            y,\n+            training=True,\n+        )\n+\n+        # Update trainable variables and optimizer variables.\n+        (\n+            trainable_variables,\n+            optimizer_variables,\n+        ) = self.optimizer.stateless_apply(\n+            optimizer_variables, grads, trainable_variables\n+        )\n+\n+        # Update metrics.\n+        loss_tracker_vars = metrics_variables[\n+            : len(self.loss_tracker.variables)\n+        ]\n+        mae_metric_vars = metrics_variables[len(self.loss_tracker.variables) :]\n+\n+        loss_tracker_vars = self.loss_tracker.stateless_update_state(\n+            loss_tracker_vars, loss\n+        )\n+        mae_metric_vars = self.mae_metric.stateless_update_state(\n+            mae_metric_vars, y, y_pred\n+        )\n+\n+        logs = {}\n+        logs[self.loss_tracker.name] = self.loss_tracker.stateless_result(\n+            loss_tracker_vars\n+        )\n+        logs[self.mae_metric.name] = self.mae_metric.stateless_result(\n+            mae_metric_vars\n+        )\n+\n+        new_metrics_vars = loss_tracker_vars + mae_metric_vars\n+\n+        # Return metric logs and updated state variables.\n+        state = (\n+            trainable_variables,\n+            non_trainable_variables,\n+            optimizer_variables,\n+            new_metrics_vars,\n+        )\n+        return logs, state\n+\n+    @property\n+    def metrics(self):\n+        # We list our `Metric` objects here so that `reset_states()` can be\n+        # called automatically at the start of each epoch\n+        # or at the start of `evaluate()`.\n+        return [self.loss_tracker, self.mae_metric]\n+\n+\n+# Construct an instance of CustomModel\n+inputs = keras.Input(shape=(32,))\n+outputs = keras.layers.Dense(1)(inputs)\n+model = CustomModel(inputs, outputs)\n+\n+# We don't passs a loss or metrics here.\n+model.compile(optimizer=\"adam\")\n+\n+# Just use `fit` as usual -- you can use callbacks, etc.\n+x = np.random.random((1000, 32))\n+y = np.random.random((1000, 1))\n+model.fit(x, y, epochs=5)\n+\n+\n+\"\"\"\n+## Providing your own evaluation step\n+\n+What if you want to do the same for calls to `model.evaluate()`? Then you would\n+override `test_step` in exactly the same way. Here's what it looks like:\n+\"\"\"\n+\n+\n+class CustomModel(keras.Model):\n+    def test_step(self, state, data):\n+        # Unpack the data.\n+        x, y = data\n+        (\n+            trainable_variables,\n+            non_trainable_variables,\n+            metrics_variables,\n+        ) = state\n+\n+        # Compute predictions and loss.\n+        y_pred, non_trainable_variables = self.stateless_call(\n+            trainable_variables,\n+            non_trainable_variables,\n+            x,\n+            training=False,\n+        )\n+        loss = self.compute_loss(x, y, y_pred)\n+\n+        # Update metrics.\n+        new_metrics_vars = []\n+        for metric in self.metrics:\n+            this_metric_vars = metrics_variables[\n+                len(new_metrics_vars) : len(new_metrics_vars)\n+                + len(metric.variables)\n+            ]\n+            if metric.name == \"loss\":\n+                this_metric_vars = metric.stateless_update_state(\n+                    this_metric_vars, loss\n+                )\n+            else:\n+                this_metric_vars = metric.stateless_update_state(\n+                    this_metric_vars, y, y_pred\n+                )\n+            logs = metric.stateless_result(this_metric_vars)\n+            new_metrics_vars += this_metric_vars\n+\n+        # Return metric logs and updated state variables.\n+        state = (\n+            trainable_variables,\n+            non_trainable_variables,\n+            new_metrics_vars,\n+        )\n+        return logs, state\n+\n+\n+# Construct an instance of CustomModel\n+inputs = keras.Input(shape=(32,))\n+outputs = keras.layers.Dense(1)(inputs)\n+model = CustomModel(inputs, outputs)\n+model.compile(loss=\"mse\", metrics=[\"mae\"])\n+\n+# Evaluate with our custom test_step\n+x = np.random.random((1000, 32))\n+y = np.random.random((1000, 1))\n+model.evaluate(x, y)\n+\n+\n+\"\"\"\n+That's it!\n+\"\"\"\n\n@@ -3,7 +3,7 @@ Title: Customizing what happens in `fit()` with TensorFlow\n Author: [fchollet](https://twitter.com/fchollet)\n Date created: 2020/04/15\n Last modified: 2023/06/27\n-Description: Complete guide to overriding the training step of the Model class with TensorFlow.\n+Description: Overriding the training step of the Model class with TensorFlow.\n Accelerator: GPU\n \"\"\"\n \n@@ -181,8 +181,6 @@ class CustomModel(keras.Model):\n         # We list our `Metric` objects here so that `reset_states()` can be\n         # called automatically at the start of each epoch\n         # or at the start of `evaluate()`.\n-        # If you don't implement this property, you have to call\n-        # `reset_states()` yourself at the time of your choosing.\n         return [self.loss_tracker, self.mae_metric]\n \n \n\n@@ -3,7 +3,7 @@ Title: Customizing what happens in `fit()` with PyTorch\n Author: [fchollet](https://twitter.com/fchollet)\n Date created: 2023/06/27\n Last modified: 2023/06/27\n-Description: Complete guide to overriding the training step of the Model class with PyTorch.\n+Description: Overriding the training step of the Model class with PyTorch.\n Accelerator: GPU\n \"\"\"\n \n@@ -196,8 +196,6 @@ class CustomModel(keras.Model):\n         # We list our `Metric` objects here so that `reset_states()` can be\n         # called automatically at the start of each epoch\n         # or at the start of `evaluate()`.\n-        # If you don't implement this property, you have to call\n-        # `reset_states()` yourself at the time of your choosing.\n         return [self.loss_tracker, self.mae_metric]\n \n \n\n@@ -142,6 +142,22 @@ class Metric:\n         \"\"\"\n         raise NotImplementedError\n \n+    def stateless_result(self, metric_variables):\n+        if len(metric_variables) != len(self.variables):\n+            raise ValueError(\n+                \"Argument `metric_variables` must be a list of tensors \"\n+                f\"corresponding 1:1 to {self.__class__.__name__}().variables. \"\n+                f\"Received list with length {len(metric_variables)}, but \"\n+                f\"expected {len(self.variables)} variables.\"\n+            )\n+        # Gather variable mapping\n+        mapping = list(zip(self.variables, metric_variables))\n+\n+        # Call in stateless scope\n+        with backend.StatelessScope(state_mapping=mapping) as scope:\n+            res = self.result()\n+        return res\n+\n     @property\n     def dtype(self):\n         return self._dtype\n\n@@ -102,6 +102,11 @@ class MetricTest(testing.TestCase):\n \n             update(metric_variables, y_true_batch, y_pred_batch)\n     \n+    def test_stateless_result(self):\n+        metric = ExampleMetric(name=\"mse\")\n+        res = metric.stateless_result([ops.ones(()) * 12, ops.ones(()) * 3])\n+        self.assertAllClose(res, 4.)\n+\n     def test_variable_tracking(self):\n         # In list\n         metric = ExampleMetric(name=\"mse\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4829ddfc5fdcb84efe19b5e571f4be8dda89a3e1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 3 | Files Changed: 3 | Hunks: 5 | Methods Changed: 6 | Complexity Δ (Sum/Max): 3/1 | Churn Δ: 15 | Churn Cumulative: 25002 | Contributors (this commit): 48 | Commits (past 90d): 20 | Contributors (cumulative): 79 | DMM Complexity: 1.0\n\nDIFF:\n@@ -3835,11 +3835,13 @@ class BaseRandomLayer(Layer):\n         children.update(super()._trackable_children(save_type, **kwargs))\n         return children\n \n-    def _lookup_dependency(self, name):\n+    def _lookup_dependency(self, name, cached_dependencies=None):\n         # When loading from a Keras SavedModel load, make sure that the loader\n         # can find the random generator, otherwise the loader will assume that\n         # it does not exist, and will try to create a new generator.\n         if name == \"_random_generator\":\n             return self._random_generator\n+        elif cached_dependencies is not None:\n+            return cached_dependencies.get(name)\n         else:\n             return super()._lookup_dependency(name)\n\n@@ -461,7 +461,11 @@ class Functional(training_lib.Model):\n         dependencies.update(super()._trackable_children(save_type, **kwargs))\n         return dependencies\n \n-    def _lookup_dependency(self, name):\n+    def _lookup_dependency(self, name, cached_dependencies=None):\n+        if cached_dependencies:\n+            return cached_dependencies.get(name)\n+        # Fall back to slow lookup (`layer_checkpoint_dependencies` does a\n+        # thorough check of all layer to see if they contain weights.)\n         layer_dependencies = self._layer_checkpoint_dependencies\n         if name in layer_dependencies:\n             return layer_dependencies[name]\n\n@@ -209,8 +209,11 @@ class _DynamicLossScaleState(tf.__internal__.tracking.Trackable):\n         weights.update(super()._trackable_children(save_type, **kwargs))\n         return weights\n \n-    def _lookup_dependency(self, name):\n+    def _lookup_dependency(self, name, cached_dependencies=None):\n         \"\"\"From Trackable. Find a weight in the current graph.\"\"\"\n+        if cached_dependencies is not None:\n+            unconditional = cached_dependencies.get(name)\n+        else:\n             unconditional = super()._lookup_dependency(name)\n         if unconditional is not None:\n             return unconditional\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5ddf84a0aba83ecfc67beddcc0a9de8f10d72e4f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 12 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 15 | Churn Cumulative: 999 | Contributors (this commit): 13 | Commits (past 90d): 5 | Contributors (cumulative): 13 | DMM Complexity: 1.0\n\nDIFF:\n@@ -298,20 +298,11 @@ def get(identifier, **kwargs):\n     ):\n         return identifier\n     elif isinstance(identifier, base_optimizer.Optimizer):\n-        if tf.__internal__.tf2.enabled() and not is_arm_mac():\n+        if tf.__internal__.tf2.enabled():\n             return identifier\n         else:\n-            # If TF2 is disabled or on a M1 mac, we convert to the legacy\n-            # optimizer. We observed a slowdown of optimizer on M1 Mac, so we\n-            # fall back to the legacy optimizer for now, see b/263339144\n-            # for more context.\n-            optimizer_name = identifier.__class__.__name__\n-            logging.warning(\n-                \"There is a known slowdown when using v2.11+ Keras optimizers \"\n-                \"on M1/M2 Macs. Falling back to the \"\n-                \"legacy Keras optimizer, i.e., \"\n-                f\"`tf.keras.optimizers.legacy.{optimizer_name}`.\"\n-            )\n+            # If TF2 is disabled, we convert to the legacy\n+            # optimizer.\n             return convert_to_legacy_optimizer(identifier)\n \n     # Wrap legacy TF optimizer instances\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#08da5649850352d1eece47c2136b6eb0820f1a84", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 437 | Lines Deleted: 677 | Files Changed: 169 | Hunks: 393 | Methods Changed: 31 | Complexity Δ (Sum/Max): 1581/759 | Churn Δ: 1114 | Churn Cumulative: 87411 | Contributors (this commit): 18 | Commits (past 90d): 1390 | Contributors (cumulative): 446 | DMM Complexity: None\n\nDIFF:\n@@ -11,7 +11,7 @@ from keras_core import Model\n from keras_core import backend\n from keras_core import initializers\n from keras_core import layers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import optimizers\n \n \n\n@@ -7,7 +7,7 @@ from keras_core import initializers\n from keras_core import layers\n from keras_core import losses\n from keras_core import metrics\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import optimizers\n \n \n\n@@ -11,7 +11,7 @@ from keras_core import Model\n from keras_core import backend\n from keras_core import initializers\n from keras_core import layers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import optimizers\n \n \n\n@@ -39,7 +39,7 @@ from zipfile import ZipFile\n \n import keras_core as keras\n from keras_core import layers\n-import keras_core.operations as ops\n+from keras_core import ops\n \"\"\"\n ## First, load the data and apply preprocessing\n \"\"\"\n\n@@ -56,7 +56,7 @@ by TensorFlow.\n import numpy as np\n import keras_core as keras\n from keras_core import layers\n-from keras_core import operations as ops\n+from keras_core import ops\n from tqdm import tqdm\n from matplotlib import pyplot as plt\n \n\n@@ -27,7 +27,7 @@ the class segmentation of the training inputs.\n import random\n import numpy as np\n import keras_core as keras\n-from keras_core import operations as ops\n+from keras_core import ops\n import matplotlib.pyplot as plt\n \n \"\"\"\n\n@@ -13,7 +13,7 @@ Accelerator: GPU\n import numpy as np\n import keras_core as keras\n from keras_core import layers\n-from keras_core import operations as ops\n+from keras_core import ops\n \n \"\"\"\n ## Introduction\n\n@@ -30,7 +30,7 @@ Let's dive in.\n \n import numpy as np\n import keras_core as keras\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import layers\n \n \"\"\"\n\n@@ -13,7 +13,7 @@ Accelerator: GPU\n \n import keras_core as keras\n from keras_core import layers\n-from keras_core import operations as ops\n+from keras_core import ops\n \n \"\"\"\n ## When to use a Sequential model\n\n@@ -19,7 +19,7 @@ import os\n import numpy as np\n import keras_core as keras\n from keras_core import layers\n-from keras_core import operations as ops\n+from keras_core import ops\n \n \"\"\"\n ## Introduction\n\n@@ -11,7 +11,7 @@ Accelerator: None\n \"\"\"\n import numpy as np\n import keras_core as keras\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import layers\n \n \"\"\"\n\n@@ -2,7 +2,7 @@ import numpy as np\n \n import keras_core\n from keras_core import layers\n-from keras_core import operations as ops\n+from keras_core import ops\n \n keras_core.utils.set_random_seed(1337)\n x = np.random.rand(100, 32, 32, 3)\n\n@@ -6,7 +6,7 @@ from keras_core import datasets\n from keras_core import initializers\n from keras_core import layers\n from keras_core import models\n-from keras_core import operations\n+from keras_core import ops\n from keras_core import optimizers\n from keras_core import regularizers\n from keras_core import utils\n\n@@ -1,5 +1,5 @@\n from keras_core import backend\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n \n \n\n@@ -4,14 +4,14 @@ from tensorflow.io import gfile\n from keras_core import backend\n from keras_core import initializers\n from keras_core import layers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import random\n from keras_core.api_export import keras_core_export\n from keras_core.applications import imagenet_utils\n from keras_core.layers.layer import Layer\n from keras_core.models import Functional\n from keras_core.models import Sequential\n-from keras_core.operations import operation_utils\n+from keras_core.ops import operation_utils\n from keras_core.utils import file_utils\n \n BASE_WEIGHTS_PATH = (\n\n@@ -5,7 +5,7 @@ from keras_core import layers\n from keras_core.api_export import keras_core_export\n from keras_core.applications import imagenet_utils\n from keras_core.models import Functional\n-from keras_core.operations import operation_utils\n+from keras_core.ops import operation_utils\n from keras_core.utils import file_utils\n \n BASE_WEIGHTS_PATH = (\n\n@@ -8,7 +8,7 @@ from keras_core import layers\n from keras_core.api_export import keras_core_export\n from keras_core.applications import imagenet_utils\n from keras_core.models import Functional\n-from keras_core.operations import operation_utils\n+from keras_core.ops import operation_utils\n from keras_core.utils import file_utils\n \n BASE_WEIGHTS_PATH = \"https://storage.googleapis.com/keras-applications/\"\n\n@@ -9,7 +9,7 @@ from keras_core import layers\n from keras_core.api_export import keras_core_export\n from keras_core.applications import imagenet_utils\n from keras_core.models import Functional\n-from keras_core.operations import operation_utils\n+from keras_core.ops import operation_utils\n from keras_core.utils import file_utils\n \n BASE_WEIGHTS_PATH = \"https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/\"  # noqa: E501\n\n@@ -5,7 +5,7 @@ import numpy as np\n \n from keras_core import activations\n from keras_core import backend\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.utils import file_utils\n \n\n@@ -6,7 +6,7 @@ from keras_core.api_export import keras_core_export\n from keras_core.applications import imagenet_utils\n from keras_core.layers.layer import Layer\n from keras_core.models import Functional\n-from keras_core.operations import operation_utils\n+from keras_core.ops import operation_utils\n from keras_core.utils import file_utils\n \n BASE_WEIGHT_URL = (\n\n@@ -5,7 +5,7 @@ from keras_core import layers\n from keras_core.api_export import keras_core_export\n from keras_core.applications import imagenet_utils\n from keras_core.models import Functional\n-from keras_core.operations import operation_utils\n+from keras_core.ops import operation_utils\n from keras_core.utils import file_utils\n \n WEIGHTS_PATH = (\n\n@@ -7,7 +7,7 @@ from keras_core import layers\n from keras_core.api_export import keras_core_export\n from keras_core.applications import imagenet_utils\n from keras_core.models import Functional\n-from keras_core.operations import operation_utils\n+from keras_core.ops import operation_utils\n from keras_core.utils import file_utils\n \n BASE_WEIGHT_PATH = (\n\n@@ -7,7 +7,7 @@ from keras_core import layers\n from keras_core.api_export import keras_core_export\n from keras_core.applications import imagenet_utils\n from keras_core.models import Functional\n-from keras_core.operations import operation_utils\n+from keras_core.ops import operation_utils\n from keras_core.utils import file_utils\n \n BASE_WEIGHT_PATH = (\n\n@@ -7,7 +7,7 @@ from keras_core import layers\n from keras_core.api_export import keras_core_export\n from keras_core.applications import imagenet_utils\n from keras_core.models import Functional\n-from keras_core.operations import operation_utils\n+from keras_core.ops import operation_utils\n from keras_core.utils import file_utils\n \n BASE_WEIGHT_PATH = (\n\n@@ -7,7 +7,7 @@ from keras_core import layers\n from keras_core.api_export import keras_core_export\n from keras_core.applications import imagenet_utils\n from keras_core.models import Functional\n-from keras_core.operations import operation_utils\n+from keras_core.ops import operation_utils\n from keras_core.utils import file_utils\n \n BASE_WEIGHTS_PATH = (\n\n@@ -5,7 +5,7 @@ from keras_core import layers\n from keras_core.api_export import keras_core_export\n from keras_core.applications import imagenet_utils\n from keras_core.models import Functional\n-from keras_core.operations import operation_utils\n+from keras_core.ops import operation_utils\n from keras_core.utils import file_utils\n \n BASE_WEIGHTS_PATH = (\n\n@@ -5,7 +5,7 @@ from keras_core import layers\n from keras_core.api_export import keras_core_export\n from keras_core.applications import imagenet_utils\n from keras_core.models import Functional\n-from keras_core.operations import operation_utils\n+from keras_core.ops import operation_utils\n from keras_core.utils import file_utils\n \n WEIGHTS_PATH = (\n\n@@ -5,7 +5,7 @@ from keras_core import layers\n from keras_core.api_export import keras_core_export\n from keras_core.applications import imagenet_utils\n from keras_core.models import Functional\n-from keras_core.operations import operation_utils\n+from keras_core.ops import operation_utils\n from keras_core.utils import file_utils\n \n WEIGHTS_PATH = (\n\n@@ -5,7 +5,7 @@ from keras_core import layers\n from keras_core.api_export import keras_core_export\n from keras_core.applications import imagenet_utils\n from keras_core.models import Functional\n-from keras_core.operations import operation_utils\n+from keras_core.ops import operation_utils\n from keras_core.utils import file_utils\n \n WEIGHTS_PATH = (\n\n@@ -45,14 +45,14 @@ class KerasTensor:\n         return len(self.shape)\n \n     def reshape(self, new_shape):\n-        from keras_core import operations\n+        from keras_core import ops\n \n-        return operations.Reshape(new_shape)(self)\n+        return ops.Reshape(new_shape)(self)\n \n     def squeeze(self, axis=None):\n-        from keras_core import operations\n+        from keras_core import ops\n \n-        return operations.Squeeze(axis)(self)\n+        return ops.Squeeze(axis)(self)\n \n     def __array__(self):\n         raise ValueError(\n@@ -122,89 +122,89 @@ class KerasTensor:\n         raise TypeError(\"A symbolic KerasTensor cannot be used as a boolean.\")\n \n     def __add__(self, other):\n-        from keras_core import operations\n+        from keras_core import ops\n \n-        return operations.Add().symbolic_call(self, other)\n+        return ops.Add().symbolic_call(self, other)\n \n     def __radd__(self, other):\n-        from keras_core import operations\n+        from keras_core import ops\n \n-        return operations.Add().symbolic_call(other, self)\n+        return ops.Add().symbolic_call(other, self)\n \n     def __sub__(self, other):\n-        from keras_core import operations\n+        from keras_core import ops\n \n-        return operations.Subtract().symbolic_call(self, other)\n+        return ops.Subtract().symbolic_call(self, other)\n \n     def __rsub__(self, other):\n-        from keras_core import operations\n+        from keras_core import ops\n \n-        return operations.Subtract().symbolic_call(other, self)\n+        return ops.Subtract().symbolic_call(other, self)\n \n     def __mul__(self, other):\n-        from keras_core import operations\n+        from keras_core import ops\n \n-        return operations.Multiply().symbolic_call(self, other)\n+        return ops.Multiply().symbolic_call(self, other)\n \n     def __rmul__(self, other):\n-        from keras_core import operations\n+        from keras_core import ops\n \n-        return operations.Multiply().symbolic_call(other, self)\n+        return ops.Multiply().symbolic_call(other, self)\n \n     def __matmul__(self, other):\n-        from keras_core import operations\n+        from keras_core import ops\n \n-        return operations.Matmul().symbolic_call(self, other)\n+        return ops.Matmul().symbolic_call(self, other)\n \n     def __rmatmul__(self, other):\n-        from keras_core import operations\n+        from keras_core import ops\n \n-        return operations.Matmul().symbolic_call(other, self)\n+        return ops.Matmul().symbolic_call(other, self)\n \n     def __div__(self, other):\n-        from keras_core import operations\n+        from keras_core import ops\n \n-        return operations.Divide().symbolic_call(self, other)\n+        return ops.Divide().symbolic_call(self, other)\n \n     def __rdiv__(self, other):\n-        from keras_core import operations\n+        from keras_core import ops\n \n-        return operations.Divide().symbolic_call(other, self)\n+        return ops.Divide().symbolic_call(other, self)\n \n     def __truediv__(self, other):\n-        from keras_core import operations\n+        from keras_core import ops\n \n-        return operations.TrueDivide().symbolic_call(self, other)\n+        return ops.TrueDivide().symbolic_call(self, other)\n \n     def __rtruediv__(self, other):\n-        from keras_core import operations\n+        from keras_core import ops\n \n-        return operations.TrueDivide().symbolic_call(other, self)\n+        return ops.TrueDivide().symbolic_call(other, self)\n \n     def __neg__(self):\n-        from keras_core import operations\n+        from keras_core import ops\n \n-        return operations.Negative().symbolic_call(self)\n+        return ops.Negative().symbolic_call(self)\n \n     def __abs__(self):\n-        from keras_core import operations\n+        from keras_core import ops\n \n-        return operations.Absolute().symbolic_call(self)\n+        return ops.Absolute().symbolic_call(self)\n \n     def __pow__(self, other):\n-        from keras_core import operations\n+        from keras_core import ops\n \n-        return operations.Power().symbolic_call(self, other)\n+        return ops.Power().symbolic_call(self, other)\n \n     def __rpow__(self, other):\n-        from keras_core import operations\n+        from keras_core import ops\n \n-        return operations.Power().symbolic_call(other, self)\n+        return ops.Power().symbolic_call(other, self)\n \n     def __getitem__(self, key):\n-        from keras_core import operations\n+        from keras_core import ops\n \n-        return operations.GetItem().symbolic_call(self, key)\n+        return ops.GetItem().symbolic_call(self, key)\n \n     # TODO\n     #   \"__floordiv__\",\n\n@@ -2,7 +2,7 @@ import numpy as np\n import tensorflow as tf\n from jax import numpy as jnp\n \n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import testing\n from keras_core.backend.common import keras_tensor\n \n\n@@ -1,7 +1,7 @@\n import numpy as np\n \n from keras_core import backend\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import testing\n from keras_core.backend.common.stateless_scope import StatelessScope\n \n\n@@ -4,7 +4,7 @@ import tensorflow as tf  # for nest\n \n from keras_core import backend\n from keras_core import callbacks as callbacks_module\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import optimizers as optimizers_module\n from keras_core.trainers import trainer as base_trainer\n from keras_core.trainers.data_adapters import data_adapter_utils\n\n@@ -505,7 +505,7 @@ def _do_gru_arguments_support_cudnn(\n     reset_after,\n ):\n     from keras_core import activations\n-    from keras_core import operations as ops\n+    from keras_core import ops\n \n     return (\n         activation in (activations.tanh, tf.tanh, ops.tanh)\n@@ -524,7 +524,7 @@ def _do_lstm_arguments_support_cudnn(\n     bias,\n ):\n     from keras_core import activations\n-    from keras_core import operations as ops\n+    from keras_core import ops\n \n     return (\n         activation in (activations.tanh, tf.tanh, ops.tanh)\n\n@@ -1,7 +1,7 @@\n import torch\n \n from keras_core.backend.common.stateless_scope import in_stateless_scope\n-from keras_core.operations.operation import Operation\n+from keras_core.ops.operation import Operation\n \n \n class TorchLayer(torch.nn.Module):\n\n@@ -659,7 +659,7 @@ def repeat(x, repeats, axis=None):\n         # TODO: Refactor the upper level modules to avoid these imports.\n         from keras_core.backend import KerasTensor\n         from keras_core.backend import standardize_dtype\n-        from keras_core.operations.numpy import repeat\n+        from keras_core.ops.numpy import repeat\n \n         x = KerasTensor(x.shape, standardize_dtype(x.dtype))\n         outputs = repeat(x, repeats, axis=axis)\n\n@@ -1,6 +1,6 @@\n import warnings\n \n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.callbacks.callback import Callback\n from keras_core.utils import io_utils\n\n@@ -10,7 +10,7 @@ from tensorflow.compat.v1 import SummaryMetadata\n from tensorflow.io import gfile\n \n from keras_core import backend\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.callbacks.callback import Callback\n from keras_core.layers import Embedding\n\n@@ -14,7 +14,7 @@ from keras_core import callbacks\n from keras_core import layers\n from keras_core import losses\n from keras_core import models\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import optimizers\n from keras_core import testing\n from keras_core.optimizers import schedules\n\n@@ -1,5 +1,5 @@\n from keras_core import backend\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n \n \n\n@@ -1,4 +1,4 @@\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.backend import standardize_dtype\n from keras_core.initializers.initializer import Initializer\n\n@@ -1,6 +1,6 @@\n import math\n \n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.backend import random\n from keras_core.initializers.initializer import Initializer\n\n@@ -1,4 +1,4 @@\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.layers.attention.attention import Attention\n \n\n@@ -1,5 +1,5 @@\n from keras_core import backend\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n \n\n@@ -6,7 +6,7 @@ import numpy as np\n \n from keras_core import constraints\n from keras_core import initializers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import regularizers\n from keras_core.api_export import keras_core_export\n from keras_core.layers.activations.softmax import Softmax\n\n@@ -3,12 +3,12 @@\n from keras_core import activations\n from keras_core import constraints\n from keras_core import initializers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import regularizers\n from keras_core.backend import standardize_data_format\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n-from keras_core.operations.operation_utils import compute_conv_output_shape\n+from keras_core.ops.operation_utils import compute_conv_output_shape\n from keras_core.utils.argument_validation import standardize_padding\n from keras_core.utils.argument_validation import standardize_tuple\n \n\n@@ -3,7 +3,7 @@\n from keras_core import activations\n from keras_core import constraints\n from keras_core import initializers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import regularizers\n from keras_core.backend import standardize_data_format\n from keras_core.backend.common.backend_utils import (\n\n@@ -3,12 +3,12 @@\n from keras_core import activations\n from keras_core import constraints\n from keras_core import initializers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import regularizers\n from keras_core.backend import standardize_data_format\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n-from keras_core.operations.operation_utils import compute_conv_output_shape\n+from keras_core.ops.operation_utils import compute_conv_output_shape\n from keras_core.utils.argument_validation import standardize_padding\n from keras_core.utils.argument_validation import standardize_tuple\n \n\n@@ -4,12 +4,12 @@\n from keras_core import activations\n from keras_core import constraints\n from keras_core import initializers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import regularizers\n from keras_core.backend import standardize_data_format\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n-from keras_core.operations.operation_utils import compute_conv_output_shape\n+from keras_core.ops.operation_utils import compute_conv_output_shape\n from keras_core.utils.argument_validation import standardize_padding\n from keras_core.utils.argument_validation import standardize_tuple\n \n\n@@ -1,4 +1,4 @@\n-import keras_core.operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.layers.convolutional.base_conv import BaseConv\n \n\n@@ -1,7 +1,7 @@\n from keras_core import activations\n from keras_core import constraints\n from keras_core import initializers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import regularizers\n from keras_core.api_export import keras_core_export\n from keras_core.layers.input_spec import InputSpec\n\n@@ -3,7 +3,7 @@ import re\n from keras_core import activations\n from keras_core import constraints\n from keras_core import initializers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import regularizers\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n\n@@ -1,6 +1,6 @@\n from keras_core import constraints\n from keras_core import initializers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import regularizers\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n\n@@ -3,7 +3,7 @@ import warnings\n from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n-from keras_core.operations.node import Node\n+from keras_core.ops.node import Node\n \n \n @keras_core_export(\"keras_core.layers.InputLayer\")\n\n@@ -1,7 +1,7 @@\n import numpy as np\n \n from keras_core import layers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import testing\n \n \n\n@@ -1,5 +1,5 @@\n from keras_core import backend\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n \n\n@@ -32,7 +32,7 @@ from keras_core.backend import KerasTensor\n from keras_core.backend.common import global_state\n from keras_core.layers import input_spec\n from keras_core.metrics.metric import Metric\n-from keras_core.operations.operation import Operation\n+from keras_core.ops.operation import Operation\n from keras_core.utils import python_utils\n from keras_core.utils import summary_utils\n from keras_core.utils import traceback_utils\n\n@@ -4,7 +4,7 @@ import pytest\n from keras_core import backend\n from keras_core import layers\n from keras_core import models\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import testing\n \n \n\n@@ -1,5 +1,5 @@\n from keras_core import backend\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.layers.layer import Layer\n \n \n\n@@ -1,4 +1,4 @@\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.layers.merging.base_merge import Merge\n \n\n@@ -1,4 +1,4 @@\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.layers.merging.base_merge import Merge\n from keras_core.utils.numerical_utils import normalize\n@@ -105,7 +105,7 @@ def batch_dot(x, y, axes=None):\n             \"Cannot perform batch_dot over axis 0. \"\n             \"If your inputs are not batched, \"\n             \"add a dummy batch dimension to your \"\n-            \"inputs using keras_core.operations.expand_dims(x, 0)\"\n+            \"inputs using keras_core.ops.expand_dims(x, 0)\"\n         )\n     a0, a1 = axes\n     d1 = x_shape[a0]\n\n@@ -1,4 +1,4 @@\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.layers.merging.base_merge import Merge\n \n\n@@ -4,7 +4,7 @@ import pytest\n from keras_core import backend\n from keras_core import layers\n from keras_core import models\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import testing\n \n \n\n@@ -1,4 +1,4 @@\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.layers.merging.base_merge import Merge\n \n\n@@ -1,6 +1,6 @@\n from keras_core import constraints\n from keras_core import initializers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import regularizers\n from keras_core.api_export import keras_core_export\n from keras_core.layers.input_spec import InputSpec\n\n@@ -1,6 +1,6 @@\n from keras_core import constraints\n from keras_core import initializers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import regularizers\n from keras_core.api_export import keras_core_export\n from keras_core.layers.input_spec import InputSpec\n\n@@ -1,6 +1,6 @@\n from keras_core import constraints\n from keras_core import initializers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import regularizers\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n\n@@ -1,7 +1,7 @@\n import numpy as np\n \n from keras_core import layers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import regularizers\n from keras_core import testing\n \n\n@@ -1,5 +1,5 @@\n from keras_core import initializers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.layers import Wrapper\n from keras_core.layers.input_spec import InputSpec\n\n@@ -1,4 +1,4 @@\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n \n\n@@ -1,8 +1,8 @@\n from keras_core import backend\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n-from keras_core.operations.operation_utils import compute_pooling_output_shape\n+from keras_core.ops.operation_utils import compute_pooling_output_shape\n from keras_core.utils import argument_validation\n \n \n\n@@ -1,5 +1,5 @@\n from keras_core import backend\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.layers.pooling.base_global_pooling import BaseGlobalPooling\n \n\n@@ -1,4 +1,4 @@\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.layers.pooling.base_global_pooling import BaseGlobalPooling\n \n\n@@ -1,4 +1,4 @@\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.layers.pooling.base_global_pooling import BaseGlobalPooling\n \n\n@@ -1,4 +1,4 @@\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.layers.pooling.base_global_pooling import BaseGlobalPooling\n \n\n@@ -1,4 +1,4 @@\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.layers.pooling.base_global_pooling import BaseGlobalPooling\n \n\n@@ -1,4 +1,4 @@\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.layers.pooling.base_global_pooling import BaseGlobalPooling\n \n\n@@ -3,7 +3,7 @@ from tensorflow import nest\n \n from keras_core import backend\n from keras_core import layers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n from keras_core.saving import saving_lib\n\n@@ -7,7 +7,7 @@ from tensorflow import nest\n from keras_core import backend\n from keras_core import layers\n from keras_core import models\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import testing\n from keras_core.layers.preprocessing import feature_space\n from keras_core.saving import saving_api\n\n@@ -4,7 +4,7 @@ import numpy as np\n import tensorflow as tf\n \n from keras_core import backend\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n \n\n@@ -2,7 +2,7 @@ import math\n \n from keras_core import backend\n from keras_core import layers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n \n \n\n@@ -1,6 +1,6 @@\n from keras_core import backend\n from keras_core import layers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n \n \n\n@@ -1,5 +1,5 @@\n from keras_core import backend\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.regularization.dropout import Dropout\n\n@@ -3,7 +3,7 @@ import pytest\n \n from keras_core import backend\n from keras_core import layers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import testing\n \n \n\n@@ -4,7 +4,7 @@ from absl.testing import parameterized\n \n from keras_core import backend\n from keras_core import layers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import testing\n \n \n\n@@ -4,7 +4,7 @@ from absl.testing import parameterized\n \n from keras_core import backend\n from keras_core import layers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import testing\n \n \n\n@@ -1,7 +1,7 @@\n import math\n \n from keras_core import backend\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n\n@@ -3,7 +3,7 @@ import pytest\n \n from keras_core import backend\n from keras_core import layers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import testing\n \n \n\n@@ -1,4 +1,4 @@\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n\n@@ -3,7 +3,7 @@ import pytest\n \n from keras_core import backend\n from keras_core import layers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import testing\n \n \n\n@@ -1,4 +1,4 @@\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n\n@@ -3,7 +3,7 @@ import pytest\n \n from keras_core import backend\n from keras_core import layers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import testing\n \n \n\n@@ -1,7 +1,7 @@\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n-from keras_core.operations import operation_utils\n+from keras_core.ops import operation_utils\n \n \n @keras_core_export(\"keras_core.layers.Reshape\")\n\n@@ -1,4 +1,4 @@\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n\n@@ -1,7 +1,7 @@\n import numpy as np\n \n from keras_core import backend\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n\n@@ -1,5 +1,5 @@\n from keras_core import backend\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n\n@@ -1,4 +1,4 @@\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n\n@@ -1,5 +1,5 @@\n from keras_core import backend\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n\n@@ -1,5 +1,5 @@\n from keras_core import backend\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n\n@@ -1,6 +1,6 @@\n import copy\n \n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import utils\n from keras_core.api_export import keras_core_export\n from keras_core.layers.core.wrapper import Wrapper\n\n@@ -4,13 +4,13 @@ from keras_core import activations\n from keras_core import backend\n from keras_core import constraints\n from keras_core import initializers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import regularizers\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n from keras_core.layers.rnn.dropout_rnn_cell import DropoutRNNCell\n from keras_core.layers.rnn.rnn import RNN\n-from keras_core.operations import operation_utils\n+from keras_core.ops import operation_utils\n from keras_core.utils import argument_validation\n \n \n\n@@ -1,5 +1,5 @@\n from keras_core import backend\n-from keras_core import operations as ops\n+from keras_core import ops\n \n \n class DropoutRNNCell:\n\n@@ -1,6 +1,6 @@\n from keras_core import backend\n from keras_core import layers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import testing\n from keras_core.layers.rnn.dropout_rnn_cell import DropoutRNNCell\n \n\n@@ -4,7 +4,7 @@ from keras_core import activations\n from keras_core import backend\n from keras_core import constraints\n from keras_core import initializers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import regularizers\n from keras_core.api_export import keras_core_export\n from keras_core.layers.input_spec import InputSpec\n\n@@ -4,7 +4,7 @@ from keras_core import activations\n from keras_core import backend\n from keras_core import constraints\n from keras_core import initializers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import regularizers\n from keras_core.api_export import keras_core_export\n from keras_core.layers.input_spec import InputSpec\n\n@@ -1,7 +1,7 @@\n from tensorflow import nest\n \n from keras_core import backend\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n from keras_core.layers.rnn.stacked_rnn_cells import StackedRNNCells\n@@ -138,7 +138,7 @@ class RNN(Layer):\n \n     ```python\n     from keras_core.layers import RNN\n-    from keras_core import operations as ops\n+    from keras_core import ops\n \n     # First, let's define a RNN Cell, as a layer subclass.\n     class MinimalRNNCell(keras_core.layers.Layer):\n\n@@ -3,7 +3,7 @@ import pytest\n \n from keras_core import backend\n from keras_core import layers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import testing\n \n \n\n@@ -2,7 +2,7 @@ from keras_core import activations\n from keras_core import backend\n from keras_core import constraints\n from keras_core import initializers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import regularizers\n from keras_core.api_export import keras_core_export\n from keras_core.layers.input_spec import InputSpec\n\n@@ -1,6 +1,6 @@\n from tensorflow import nest\n \n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n from keras_core.saving import serialization_lib\n\n@@ -1,7 +1,7 @@\n \"\"\"Wrapper layer to apply every temporal slice of an input.\"\"\"\n \n from keras_core import backend\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.layers.core.wrapper import Wrapper\n from keras_core.layers.layer import Layer\n\n@@ -2,7 +2,7 @@ import numpy as np\n \n from keras_core import initializers\n from keras_core import layers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import testing\n \n \n\n@@ -1,7 +1,7 @@\n from tensorflow import nest\n \n from keras_core import backend\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.utils import dtype_utils\n from keras_core.utils.naming import auto_name\n\n@@ -2,7 +2,7 @@ import numpy as np\n \n from keras_core import backend\n from keras_core import losses as losses_module\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import testing\n from keras_core.losses.loss import Loss\n \n\n@@ -1,7 +1,7 @@\n import warnings\n \n from keras_core import backend\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.losses.loss import Loss\n from keras_core.losses.loss import squeeze_to_same_rank\n\n@@ -1,5 +1,5 @@\n from keras_core import backend\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.losses.loss import squeeze_to_same_rank\n from keras_core.metrics import reduction_metrics\n\n@@ -3,7 +3,7 @@ import numpy as np\n from keras_core import activations\n from keras_core import backend\n from keras_core import initializers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.metrics import metrics_utils\n from keras_core.metrics.metric import Metric\n\n@@ -8,7 +8,7 @@ from tensorflow.python.ops.numpy_ops import np_config\n from keras_core import layers\n from keras_core import metrics\n from keras_core import models\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import testing\n from keras_core.metrics import metrics_utils\n \n\n@@ -1,6 +1,6 @@\n from keras_core import backend\n from keras_core import initializers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.metrics.metric import Metric\n \n\n@@ -1,6 +1,6 @@\n from keras_core import backend\n from keras_core import initializers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.metrics.metric import Metric\n from keras_core.metrics.metrics_utils import confusion_matrix\n\n@@ -1,6 +1,6 @@\n from keras_core import backend\n from keras_core import initializers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.utils.naming import auto_name\n from keras_core.utils.tracking import Tracker\n\n@@ -3,7 +3,7 @@ import numpy as np\n from keras_core import backend\n from keras_core import initializers\n from keras_core import metrics as metrics_module\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import testing\n from keras_core.metrics.metric import Metric\n \n@@ -105,7 +105,7 @@ class MetricTest(testing.TestCase):\n     def test_stateless_result(self):\n         metric = ExampleMetric(name=\"mse\")\n         res = metric.stateless_result([ops.ones(()) * 12, ops.ones(()) * 3])\n-        self.assertAllClose(res, 4.)\n+        self.assertAllClose(res, 4.0)\n \n     def test_variable_tracking(self):\n         # In list\n\n@@ -3,7 +3,7 @@ from enum import Enum\n import numpy as np\n \n from keras_core import backend\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.losses.loss import squeeze_to_same_rank\n from keras_core.utils.python_utils import to_list\n \n\n@@ -1,6 +1,6 @@\n from keras_core import backend\n from keras_core import initializers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.losses import loss\n from keras_core.metrics.metric import Metric\n\n@@ -1,7 +1,7 @@\n import warnings\n \n from keras_core import initializers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.losses.loss import squeeze_to_same_rank\n from keras_core.losses.losses import log_cosh\n\n@@ -5,12 +5,12 @@ import warnings\n from tensorflow import nest\n \n from keras_core import backend\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n from keras_core.models.model import Model\n-from keras_core.operations.function import Function\n-from keras_core.operations.function import make_node_key\n+from keras_core.ops.function import Function\n+from keras_core.ops.function import make_node_key\n from keras_core.saving import serialization_lib\n from keras_core.utils import tracking\n \n\n@@ -1,15 +0,0 @@\n-# from keras_core.operations.numpy import Matmul, matmul\n-# from keras_core.operations.numpy import Add, add\n-# from keras_core.operations.numpy import Multiply, multiply\n-\n-from keras_core.backend import cast\n-from keras_core.backend import cond\n-from keras_core.backend import is_tensor\n-from keras_core.backend import name_scope\n-from keras_core.backend import random\n-from keras_core.operations import image\n-from keras_core.operations import operation_utils\n-from keras_core.operations.core import *  # noqa: F403\n-from keras_core.operations.math import *  # noqa: F403\n-from keras_core.operations.nn import *  # noqa: F403\n-from keras_core.operations.numpy import *  # noqa: F403\n\n@@ -0,0 +1,15 @@\n+# from keras_core.ops.numpy import Matmul, matmul\n+# from keras_core.ops.numpy import Add, add\n+# from keras_core.ops.numpy import Multiply, multiply\n+\n+from keras_core.backend import cast\n+from keras_core.backend import cond\n+from keras_core.backend import is_tensor\n+from keras_core.backend import name_scope\n+from keras_core.backend import random\n+from keras_core.ops import image\n+from keras_core.ops import operation_utils\n+from keras_core.ops.core import *  # noqa: F403\n+from keras_core.ops.math import *  # noqa: F403\n+from keras_core.ops.nn import *  # noqa: F403\n+from keras_core.ops.numpy import *  # noqa: F403\n\n@@ -17,7 +17,7 @@ from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.backend import KerasTensor\n from keras_core.backend import any_symbolic_tensors\n-from keras_core.operations.operation import Operation\n+from keras_core.ops.operation import Operation\n \n \n class Scatter(Operation):\n@@ -28,7 +28,7 @@ class Scatter(Operation):\n         return KerasTensor(shape, dtype=values.dtype)\n \n \n-@keras_core_export(\"keras_core.operations.scatter\")\n+@keras_core_export(\"keras_core.ops.scatter\")\n def scatter(indices, values, shape):\n     if any_symbolic_tensors((indices, values, shape)):\n         return Scatter().symbolic_call(indices, values, shape)\n@@ -43,7 +43,7 @@ class ScatterUpdate(Operation):\n         return KerasTensor(inputs.shape, dtype=inputs.dtype)\n \n \n-@keras_core_export(\"keras_core.operations.scatter_update\")\n+@keras_core_export(\"keras_core.ops.scatter_update\")\n def scatter_update(inputs, indices, updates):\n     \"\"\"Update inputs via updates at scattered (sparse) indices.\n \n@@ -61,7 +61,7 @@ def scatter_update(inputs, indices, updates):\n     inputs = np.zeros((4, 4, 4))\n     indices = [[1, 2, 3], [0, 1, 3]]\n     updates = np.array([1., 1.])\n-    inputs = keras_core.operations.scatter_update(inputs, indices, updates)\n+    inputs = keras_core.ops.scatter_update(inputs, indices, updates)\n     ```\n \n     2 `indices` is a 2D tensor of shape `(num_updates, k)`, where `num_updates`\n@@ -77,7 +77,7 @@ def scatter_update(inputs, indices, updates):\n     inputs = np.zeros((4, 4, 4))\n     indices = [[1, 2], [2, 3]]\n     updates = np.array([[1., 1., 1, 1,], [1., 1., 1, 1,])\n-    inputs = keras_core.operations.scatter_update(inputs, indices, updates)\n+    inputs = keras_core.ops.scatter_update(inputs, indices, updates)\n     ```\n \n     Args:\n@@ -103,7 +103,7 @@ class Slice(Operation):\n         return KerasTensor(shape, dtype=inputs.dtype)\n \n \n-@keras_core_export(\"keras_core.operations.slice\")\n+@keras_core_export(\"keras_core.ops.slice\")\n def slice(inputs, start_indices, shape):\n     \"\"\"Return a slice of an input tensor.\n \n@@ -117,7 +117,7 @@ def slice(inputs, start_indices, shape):\n     inputs = np.zeros((5, 5))\n     start_indices = np.array([3, 3])\n     shape = np.array([2, 2])\n-    inputs = keras_core.operations.slice(inputs, start_indices, updates)\n+    inputs = keras_core.ops.slice(inputs, start_indices, updates)\n     ```\n \n     Args:\n@@ -142,7 +142,7 @@ class SliceUpdate(Operation):\n         return KerasTensor(inputs.shape, dtype=inputs.dtype)\n \n \n-@keras_core_export(\"keras_core.operations.slice_update\")\n+@keras_core_export(\"keras_core.ops.slice_update\")\n def slice_update(inputs, start_indices, updates):\n     \"\"\"Update an input by slicing in a tensor of updated values.\n \n@@ -160,7 +160,7 @@ def slice_update(inputs, start_indices, updates):\n     inputs = np.zeros((5, 5))\n     start_indices = [3, 3]\n     updates = np.ones((2, 2))\n-    inputs = keras_core.operations.slice_update(inputs, start_indices, updates)\n+    inputs = keras_core.ops.slice_update(inputs, start_indices, updates)\n     ```\n \n     Args:\n@@ -197,7 +197,7 @@ class WhileLoop(Operation):\n         return [KerasTensor(v.shape, dtype=v.dtype) for v in loop_vars]\n \n \n-@keras_core_export(\"keras_core.operations.while_loop\")\n+@keras_core_export(\"keras_core.ops.while_loop\")\n def while_loop(\n     cond,\n     body,\n@@ -226,7 +226,7 @@ def while_loop(\n     >>> i = 0\n     >>> cond = lambda i: i < 10\n     >>> body = lambda i: i + 1\n-    >>> keras_core.operations.while_loop(cond, body, [i])[0]\n+    >>> keras_core.ops.while_loop(cond, body, [i])[0]\n     10\n     \"\"\"\n \n@@ -249,7 +249,7 @@ class StopGradient(Operation):\n         return KerasTensor(variable.shape, dtype=variable.dtype)\n \n \n-@keras_core_export(\"keras_core.operations.stop_gradient\")\n+@keras_core_export(\"keras_core.ops.stop_gradient\")\n def stop_gradient(variable):\n     \"\"\"Stops gradient computation.\n \n@@ -266,12 +266,12 @@ def stop_gradient(variable):\n     ...     [1., 2., 3.],\n     ...     dtype=\"float32\"\n     ... )\n-    >>> var = keras_core.operations.stop_gradient(var)\n+    >>> var = keras_core.ops.stop_gradient(var)\n     \"\"\"\n     return backend.core.stop_gradient(variable)\n \n \n-@keras_core_export(\"keras_core.operations.shape\")\n+@keras_core_export(\"keras_core.ops.shape\")\n def shape(x):\n     \"\"\"Gets the shape of the tensor input.\"\"\"\n     if any_symbolic_tensors((x,)):\n@@ -279,7 +279,7 @@ def shape(x):\n     return backend.core.shape(x)\n \n \n-@keras_core_export(\"keras_core.operations.cast\")\n+@keras_core_export(\"keras_core.ops.cast\")\n def cast(x, dtype):\n     \"\"\"Cast a tensor to the desired dtype.\"\"\"\n     dtype = backend.standardize_dtype(dtype)\n@@ -288,13 +288,13 @@ def cast(x, dtype):\n     return backend.core.cast(x, dtype)\n \n \n-@keras_core_export(\"keras_core.operations.convert_to_tensor\")\n+@keras_core_export(\"keras_core.ops.convert_to_tensor\")\n def convert_to_tensor(x, dtype=None):\n     \"\"\"Convert a NumPy array to a tensor.\"\"\"\n     return backend.convert_to_tensor(x, dtype=dtype)\n \n \n-@keras_core_export(\"keras_core.operations.convert_to_numpy\")\n+@keras_core_export(\"keras_core.ops.convert_to_numpy\")\n def convert_to_numpy(x):\n     \"\"\"Convert a tensor to a NumPy array.\"\"\"\n     if any_symbolic_tensors((x,)):\n\n@@ -3,11 +3,11 @@ import numpy as np\n from keras_core import layers\n from keras_core import losses\n from keras_core import models\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import optimizers\n from keras_core import testing\n from keras_core.backend.common.keras_tensor import KerasTensor\n-from keras_core.operations import core\n+from keras_core.ops import core\n \n \n class CoreOpsStaticShapeTest(testing.TestCase):\n\n@@ -4,7 +4,7 @@ from tensorflow import nest\n \n from keras_core.api_export import keras_core_export\n from keras_core.backend import KerasTensor\n-from keras_core.operations.operation import Operation\n+from keras_core.ops.operation import Operation\n \n \n @keras_core_export(\"keras_core.Function\")\n@@ -25,7 +25,7 @@ class Function(Operation):\n     input_1 = keras_core.KerasTensor(shape=(None, 2, 3))\n     input_2 = keras_core.KerasTensor(shape=(None, 2, 3))\n     x = input_1 + input_2\n-    output = keras_core.operations.sigmoid(x)\n+    output = keras_core.ops.sigmoid(x)\n     fn = keras_core.Function(inputs=[input_1, input_2], outputs=output)\n \n     input_1_val = np.random.random((4, 2, 3))\n\n@@ -2,8 +2,8 @@ import numpy as np\n \n from keras_core import testing\n from keras_core.backend.common import keras_tensor\n-from keras_core.operations import function\n-from keras_core.operations import numpy as knp\n+from keras_core.ops import function\n+from keras_core.ops import numpy as knp\n \n \n class FunctionTest(testing.TestCase):\n\n@@ -2,7 +2,7 @@ from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.backend import KerasTensor\n from keras_core.backend import any_symbolic_tensors\n-from keras_core.operations.operation import Operation\n+from keras_core.ops.operation import Operation\n \n \n class Resize(Operation):\n@@ -51,7 +51,7 @@ class Resize(Operation):\n         )\n \n \n-@keras_core_export(\"keras_core.operations.image.resize\")\n+@keras_core_export(\"keras_core.ops.image.resize\")\n def resize(\n     image, size, method=\"bilinear\", antialias=False, data_format=\"channels_last\"\n ):\n\n@@ -5,7 +5,7 @@ from absl.testing import parameterized\n from keras_core import backend\n from keras_core import testing\n from keras_core.backend.common.keras_tensor import KerasTensor\n-from keras_core.operations import image as kimage\n+from keras_core.ops import image as kimage\n \n \n class ImageOpsDynamicShapeTest(testing.TestCase):\n\n@@ -9,8 +9,8 @@ from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.backend import KerasTensor\n from keras_core.backend import any_symbolic_tensors\n-from keras_core.operations.operation import Operation\n-from keras_core.operations.operation_utils import reduce_shape\n+from keras_core.ops.operation import Operation\n+from keras_core.ops.operation_utils import reduce_shape\n \n \n class SegmentSum(Operation):\n@@ -33,7 +33,7 @@ class SegmentSum(Operation):\n         )\n \n \n-@keras_core_export(\"keras_core.operations.segment_sum\")\n+@keras_core_export(\"keras_core.ops.segment_sum\")\n def segment_sum(data, segment_ids, num_segments=None, sorted=False):\n     if any_symbolic_tensors((data,)):\n         return SegmentSum(num_segments, sorted).symbolic_call(data, segment_ids)\n@@ -61,7 +61,7 @@ class TopK(Operation):\n         return backend.math.top_k(x, self.k, self.sorted)\n \n \n-@keras_core_export(\"keras_core.operations.top_k\")\n+@keras_core_export(\"keras_core.ops.top_k\")\n def top_k(x, k, sorted=True):\n     if any_symbolic_tensors((x,)):\n         return TopK(k, sorted).symbolic_call(x)\n@@ -80,7 +80,7 @@ class InTopK(Operation):\n         return backend.math.in_top_k(targets, predictions, self.k)\n \n \n-@keras_core_export(\"keras_core.operations.in_top_k\")\n+@keras_core_export(\"keras_core.ops.in_top_k\")\n def in_top_k(targets, predictions, k):\n     if any_symbolic_tensors((targets, predictions)):\n         return InTopK(k).symbolic_call(targets, predictions)\n@@ -101,7 +101,7 @@ class Logsumexp(Operation):\n         return backend.math.logsumexp(x, axis=self.axis, keepdims=self.keepdims)\n \n \n-@keras_core_export(\"keras_core.operations.logsumexp\")\n+@keras_core_export(\"keras_core.ops.logsumexp\")\n def logsumexp(x, axis=None, keepdims=False):\n     if any_symbolic_tensors((x,)):\n         return Logsumexp(axis, keepdims).symbolic_call(x)\n@@ -150,7 +150,7 @@ class Qr(Operation):\n         return backend.math.qr(x, mode=self.mode)\n \n \n-@keras_core_export(\"keras_core.operations.qr\")\n+@keras_core_export(\"keras_core.ops.qr\")\n def qr(x, mode=\"reduced\"):\n     if any_symbolic_tensors((x,)):\n         return Qr(mode=mode).symbolic_call(x)\n\n@@ -5,7 +5,7 @@ import tensorflow as tf\n from keras_core import backend\n from keras_core import testing\n from keras_core.backend.common.keras_tensor import KerasTensor\n-from keras_core.operations import math as kmath\n+from keras_core.ops import math as kmath\n \n \n class MathOpsDynamicShapeTest(testing.TestCase):\n\n@@ -37,8 +37,8 @@ from keras_core.backend import standardize_data_format\n from keras_core.backend.common.backend_utils import (\n     compute_conv_transpose_output_shape,\n )\n-from keras_core.operations import operation_utils\n-from keras_core.operations.operation import Operation\n+from keras_core.ops import operation_utils\n+from keras_core.ops.operation import Operation\n \n \n class Relu(Operation):\n@@ -49,9 +49,7 @@ class Relu(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.relu\", \"keras_core.operations.nn.relu\"]\n-)\n+@keras_core_export([\"keras_core.ops.relu\", \"keras_core.ops.nn.relu\"])\n def relu(x):\n     if any_symbolic_tensors((x,)):\n         return Relu().symbolic_call(x)\n@@ -66,9 +64,7 @@ class Relu6(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.relu6\", \"keras_core.operations.nn.relu6\"]\n-)\n+@keras_core_export([\"keras_core.ops.relu6\", \"keras_core.ops.nn.relu6\"])\n def relu6(x):\n     if any_symbolic_tensors((x,)):\n         return Relu6().symbolic_call(x)\n@@ -83,9 +79,7 @@ class Sigmoid(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.sigmoid\", \"keras_core.operations.nn.sigmoid\"]\n-)\n+@keras_core_export([\"keras_core.ops.sigmoid\", \"keras_core.ops.nn.sigmoid\"])\n def sigmoid(x):\n     if any_symbolic_tensors((x,)):\n         return Sigmoid().symbolic_call(x)\n@@ -100,9 +94,7 @@ class Tanh(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.tanh\", \"keras_core.operations.nn.tanh\"]\n-)\n+@keras_core_export([\"keras_core.ops.tanh\", \"keras_core.ops.nn.tanh\"])\n def tanh(x):\n     if any_symbolic_tensors((x,)):\n         return Tanh().symbolic_call(x)\n@@ -117,9 +109,7 @@ class Softplus(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.softplus\", \"keras_core.operations.nn.softplus\"]\n-)\n+@keras_core_export([\"keras_core.ops.softplus\", \"keras_core.ops.nn.softplus\"])\n def softplus(x):\n     if any_symbolic_tensors((x,)):\n         return Softplus().symbolic_call(x)\n@@ -134,9 +124,7 @@ class Softsign(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.softsign\", \"keras_core.operations.nn.softsign\"]\n-)\n+@keras_core_export([\"keras_core.ops.softsign\", \"keras_core.ops.nn.softsign\"])\n def softsign(x):\n     if any_symbolic_tensors((x,)):\n         return Softsign().symbolic_call(x)\n@@ -151,9 +139,7 @@ class Silu(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.silu\", \"keras_core.operations.nn.silu\"]\n-)\n+@keras_core_export([\"keras_core.ops.silu\", \"keras_core.ops.nn.silu\"])\n def silu(x):\n     if any_symbolic_tensors((x,)):\n         return Silu().symbolic_call(x)\n@@ -168,9 +154,7 @@ class Swish(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.swish\", \"keras_core.operations.nn.swish\"]\n-)\n+@keras_core_export([\"keras_core.ops.swish\", \"keras_core.ops.nn.swish\"])\n def swish(x):\n     if any_symbolic_tensors((x,)):\n         return Swish().symbolic_call(x)\n@@ -187,8 +171,8 @@ class LogSigmoid(Operation):\n \n @keras_core_export(\n     [\n-        \"keras_core.operations.log_sigmoid\",\n-        \"keras_core.operations.nn.log_sigmoid\",\n+        \"keras_core.ops.log_sigmoid\",\n+        \"keras_core.ops.nn.log_sigmoid\",\n     ]\n )\n def log_sigmoid(x):\n@@ -210,7 +194,7 @@ class LeakyRelu(Operation):\n \n \n @keras_core_export(\n-    [\"keras_core.operations.leaky_relu\", \"keras_core.operations.nn.leaky_relu\"]\n+    [\"keras_core.ops.leaky_relu\", \"keras_core.ops.nn.leaky_relu\"]\n )\n def leaky_relu(x, negative_slope=0.2):\n     if any_symbolic_tensors((x,)):\n@@ -228,8 +212,8 @@ class HardSigmoid(Operation):\n \n @keras_core_export(\n     [\n-        \"keras_core.operations.hard_sigmoid\",\n-        \"keras_core.operations.nn.hard_sigmoid\",\n+        \"keras_core.ops.hard_sigmoid\",\n+        \"keras_core.ops.nn.hard_sigmoid\",\n     ]\n )\n def hard_sigmoid(x):\n@@ -250,9 +234,7 @@ class Elu(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.elu\", \"keras_core.operations.nn.elu\"]\n-)\n+@keras_core_export([\"keras_core.ops.elu\", \"keras_core.ops.nn.elu\"])\n def elu(x, alpha=1.0):\n     if any_symbolic_tensors((x,)):\n         return Elu(alpha).symbolic_call(x)\n@@ -267,9 +249,7 @@ class Selu(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.selu\", \"keras_core.operations.nn.selu\"]\n-)\n+@keras_core_export([\"keras_core.ops.selu\", \"keras_core.ops.nn.selu\"])\n def selu(x):\n     if any_symbolic_tensors((x,)):\n         return Selu().symbolic_call(x)\n@@ -288,9 +268,7 @@ class Gelu(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.gelu\", \"keras_core.operations.nn.gelu\"]\n-)\n+@keras_core_export([\"keras_core.ops.gelu\", \"keras_core.ops.nn.gelu\"])\n def gelu(x, approximate=True):\n     if any_symbolic_tensors((x,)):\n         return Gelu(approximate).symbolic_call(x)\n@@ -309,9 +287,7 @@ class Softmax(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.softmax\", \"keras_core.operations.nn.softmax\"]\n-)\n+@keras_core_export([\"keras_core.ops.softmax\", \"keras_core.ops.nn.softmax\"])\n def softmax(x, axis=None):\n     if any_symbolic_tensors((x,)):\n         return Softmax(axis).symbolic_call(x)\n@@ -332,8 +308,8 @@ class LogSoftmax(Operation):\n \n @keras_core_export(\n     [\n-        \"keras_core.operations.log_softmax\",\n-        \"keras_core.operations.nn.log_softmax\",\n+        \"keras_core.ops.log_softmax\",\n+        \"keras_core.ops.nn.log_softmax\",\n     ]\n )\n def log_softmax(x, axis=None):\n@@ -376,9 +352,7 @@ class MaxPool(Operation):\n         return KerasTensor(output_shape, dtype=inputs.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.max_pool\", \"keras_core.operations.nn.max_pool\"]\n-)\n+@keras_core_export([\"keras_core.ops.max_pool\", \"keras_core.ops.nn.max_pool\"])\n def max_pool(\n     inputs,\n     pool_size,\n@@ -465,8 +439,8 @@ class AveragePool(Operation):\n \n @keras_core_export(\n     [\n-        \"keras_core.operations.average_pool\",\n-        \"keras_core.operations.nn.average_pool\",\n+        \"keras_core.ops.average_pool\",\n+        \"keras_core.ops.nn.average_pool\",\n     ]\n )\n def average_pool(\n@@ -558,9 +532,7 @@ class Conv(Operation):\n         return KerasTensor(output_shape, dtype=inputs.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.conv\", \"keras_core.operations.nn.conv\"]\n-)\n+@keras_core_export([\"keras_core.ops.conv\", \"keras_core.ops.nn.conv\"])\n def conv(\n     inputs,\n     kernel,\n@@ -655,8 +627,8 @@ class DepthwiseConv(Operation):\n \n @keras_core_export(\n     [\n-        \"keras_core.operations.depthwise_conv\",\n-        \"keras_core.operations.nn.depthwise_conv\",\n+        \"keras_core.ops.depthwise_conv\",\n+        \"keras_core.ops.nn.depthwise_conv\",\n     ]\n )\n def depthwise_conv(\n@@ -764,8 +736,8 @@ class SeparableConv(Operation):\n \n @keras_core_export(\n     [\n-        \"keras_core.operations.separable_conv\",\n-        \"keras_core.operations.nn.separable_conv\",\n+        \"keras_core.ops.separable_conv\",\n+        \"keras_core.ops.nn.separable_conv\",\n     ]\n )\n def separable_conv(\n@@ -886,8 +858,8 @@ class ConvTranspose(Operation):\n \n @keras_core_export(\n     [\n-        \"keras_core.operations.conv_transpose\",\n-        \"keras_core.operations.nn.conv_transpose\",\n+        \"keras_core.ops.conv_transpose\",\n+        \"keras_core.ops.nn.conv_transpose\",\n     ]\n )\n def conv_transpose(\n@@ -985,9 +957,7 @@ class OneHot(Operation):\n         return KerasTensor(x_shape, dtype=self.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.one_hot\", \"keras_core.operations.nn.one_hot\"]\n-)\n+@keras_core_export([\"keras_core.ops.one_hot\", \"keras_core.ops.nn.one_hot\"])\n def one_hot(x, num_classes, axis=-1, dtype=None):\n     if any_symbolic_tensors((x,)):\n         return OneHot(num_classes, axis=axis, dtype=dtype).symbolic_call(x)\n@@ -1018,8 +988,8 @@ class BinaryCrossentropy(Operation):\n \n @keras_core_export(\n     [\n-        \"keras_core.operations.binary_crossentropy\",\n-        \"keras_core.operations.nn.binary_crossentropy\",\n+        \"keras_core.ops.binary_crossentropy\",\n+        \"keras_core.ops.nn.binary_crossentropy\",\n     ]\n )\n def binary_crossentropy(target, output, from_logits=False):\n@@ -1061,8 +1031,8 @@ class CategoricalCrossentropy(Operation):\n \n @keras_core_export(\n     [\n-        \"keras_core.operations.categorical_crossentropy\",\n-        \"keras_core.operations.nn.categorical_crossentropy\",\n+        \"keras_core.ops.categorical_crossentropy\",\n+        \"keras_core.ops.nn.categorical_crossentropy\",\n     ]\n )\n def categorical_crossentropy(target, output, from_logits=False, axis=-1):\n@@ -1107,8 +1077,8 @@ class SparseCategoricalCrossentropy(Operation):\n \n @keras_core_export(\n     [\n-        \"keras_core.operations.sparse_categorical_crossentropy\",\n-        \"keras_core.operations.nn.sparse_categorical_crossentropy\",\n+        \"keras_core.ops.sparse_categorical_crossentropy\",\n+        \"keras_core.ops.nn.sparse_categorical_crossentropy\",\n     ]\n )\n def sparse_categorical_crossentropy(target, output, from_logits=False, axis=-1):\n\n@@ -6,7 +6,7 @@ from absl.testing import parameterized\n from keras_core import backend\n from keras_core import testing\n from keras_core.backend.common.keras_tensor import KerasTensor\n-from keras_core.operations import nn as knn\n+from keras_core.ops import nn as knn\n \n \n class NNOpsDynamicShapeTest(testing.TestCase, parameterized.TestCase):\n\n@@ -3,7 +3,7 @@ import collections\n from tensorflow import nest\n \n from keras_core.backend import KerasTensor\n-from keras_core.operations.symbolic_arguments import SymbolicArguments\n+from keras_core.ops.symbolic_arguments import SymbolicArguments\n \n \n class Node:\n\n@@ -140,9 +140,9 @@ from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.backend import KerasTensor\n from keras_core.backend import any_symbolic_tensors\n-from keras_core.operations import operation_utils\n-from keras_core.operations.operation import Operation\n-from keras_core.operations.operation_utils import reduce_shape\n+from keras_core.ops import operation_utils\n+from keras_core.ops.operation import Operation\n+from keras_core.ops.operation_utils import reduce_shape\n \n \n def broadcast_shapes(shape1, shape2):\n@@ -213,9 +213,7 @@ class Absolute(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.absolute\", \"keras_core.operations.numpy.absolute\"]\n-)\n+@keras_core_export([\"keras_core.ops.absolute\", \"keras_core.ops.numpy.absolute\"])\n def absolute(x):\n     if any_symbolic_tensors((x,)):\n         return Absolute().symbolic_call(x)\n@@ -226,9 +224,7 @@ class Abs(Absolute):\n     pass\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.abs\", \"keras_core.operations.numpy.abs\"]\n-)\n+@keras_core_export([\"keras_core.ops.abs\", \"keras_core.ops.numpy.abs\"])\n def abs(x):\n     return absolute(x)\n \n@@ -244,9 +240,7 @@ class Add(Operation):\n         return KerasTensor(output_shape, dtype=x1.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.add\", \"keras_core.operations.numpy.add\"]\n-)\n+@keras_core_export([\"keras_core.ops.add\", \"keras_core.ops.numpy.add\"])\n def add(x1, x2):\n     if any_symbolic_tensors((x1, x2)):\n         return Add().symbolic_call(x1, x2)\n@@ -280,9 +274,7 @@ class All(Operation):\n         )\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.all\", \"keras_core.operations.numpy.all\"]\n-)\n+@keras_core_export([\"keras_core.ops.all\", \"keras_core.ops.numpy.all\"])\n def all(x, axis=None, keepdims=False):\n     if any_symbolic_tensors((x,)):\n         return All(axis=axis, keepdims=keepdims).symbolic_call(x)\n@@ -316,9 +308,7 @@ class Any(Operation):\n         )\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.any\", \"keras_core.operations.numpy.any\"]\n-)\n+@keras_core_export([\"keras_core.ops.any\", \"keras_core.ops.numpy.any\"])\n def any(x, axis=None, keepdims=False):\n     if any_symbolic_tensors((x,)):\n         return Any(axis=axis, keepdims=keepdims).symbolic_call(x)\n@@ -347,9 +337,7 @@ class Amax(Operation):\n         )\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.amax\", \"keras_core.operations.numpy.amax\"]\n-)\n+@keras_core_export([\"keras_core.ops.amax\", \"keras_core.ops.numpy.amax\"])\n def amax(x, axis=None, keepdims=False):\n     if any_symbolic_tensors((x,)):\n         return All(axis=axis, keepdims=keepdims).symbolic_call(x)\n@@ -374,9 +362,7 @@ class Amin(Operation):\n         )\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.amin\", \"keras_core.operations.numpy.amin\"]\n-)\n+@keras_core_export([\"keras_core.ops.amin\", \"keras_core.ops.numpy.amin\"])\n def amin(x, axis=None, keepdims=False):\n     if any_symbolic_tensors((x,)):\n         return All(axis=axis, keepdims=keepdims).symbolic_call(x)\n@@ -413,9 +399,7 @@ class Append(Operation):\n         return KerasTensor(output_shape, dtype=x1.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.append\", \"keras_core.operations.numpy.append\"]\n-)\n+@keras_core_export([\"keras_core.ops.append\", \"keras_core.ops.numpy.append\"])\n def append(\n     x1,\n     x2,\n@@ -437,9 +421,7 @@ class Arange(Operation):\n         return KerasTensor(output_shape, dtype=dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.arange\", \"keras_core.operations.numpy.arange\"]\n-)\n+@keras_core_export([\"keras_core.ops.arange\", \"keras_core.ops.numpy.arange\"])\n def arange(start, stop=None, step=1, dtype=None):\n     return backend.numpy.arange(start, stop, step=step, dtype=dtype)\n \n@@ -452,9 +434,7 @@ class Arccos(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.arccos\", \"keras_core.operations.numpy.arccos\"]\n-)\n+@keras_core_export([\"keras_core.ops.arccos\", \"keras_core.ops.numpy.arccos\"])\n def arccos(x):\n     if any_symbolic_tensors((x,)):\n         return Arccos().symbolic_call(x)\n@@ -469,9 +449,7 @@ class Arcsin(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.arcsin\", \"keras_core.operations.numpy.arcsin\"]\n-)\n+@keras_core_export([\"keras_core.ops.arcsin\", \"keras_core.ops.numpy.arcsin\"])\n def arcsin(x):\n     if any_symbolic_tensors((x,)):\n         return Arcsin().symbolic_call(x)\n@@ -486,9 +464,7 @@ class Arctan(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.arctan\", \"keras_core.operations.numpy.arctan\"]\n-)\n+@keras_core_export([\"keras_core.ops.arctan\", \"keras_core.ops.numpy.arctan\"])\n def arctan(x):\n     if any_symbolic_tensors((x,)):\n         return Arctan().symbolic_call(x)\n@@ -506,9 +482,7 @@ class Arctan2(Operation):\n         return KerasTensor(outputs_shape, dtype=x1.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.arctan2\", \"keras_core.operations.numpy.arctan2\"]\n-)\n+@keras_core_export([\"keras_core.ops.arctan2\", \"keras_core.ops.numpy.arctan2\"])\n def arctan2(x1, x2):\n     if any_symbolic_tensors((x1, x2)):\n         return Arctan2().symbolic_call(x1, x2)\n@@ -531,9 +505,7 @@ class Argmax(Operation):\n         )\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.argmax\", \"keras_core.operations.numpy.argmax\"]\n-)\n+@keras_core_export([\"keras_core.ops.argmax\", \"keras_core.ops.numpy.argmax\"])\n def argmax(x, axis=None):\n     if any_symbolic_tensors((x,)):\n         return Argmax(axis=axis).symbolic_call(x)\n@@ -556,9 +528,7 @@ class Argmin(Operation):\n         )\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.argmin\", \"keras_core.operations.numpy.argmin\"]\n-)\n+@keras_core_export([\"keras_core.ops.argmin\", \"keras_core.ops.numpy.argmin\"])\n def argmin(x, axis=None):\n     if any_symbolic_tensors((x,)):\n         return Argmin(axis=axis).symbolic_call(x)\n@@ -579,9 +549,7 @@ class Argsort(Operation):\n         return KerasTensor(x.shape, dtype=\"int32\")\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.argsort\", \"keras_core.operations.numpy.argsort\"]\n-)\n+@keras_core_export([\"keras_core.ops.argsort\", \"keras_core.ops.numpy.argsort\"])\n def argsort(x, axis=-1):\n     if any_symbolic_tensors((x,)):\n         return Argsort(axis=axis).symbolic_call(x)\n@@ -596,9 +564,7 @@ class Array(Operation):\n         return KerasTensor(x.shape, dtype=dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.array\", \"keras_core.operations.numpy.array\"]\n-)\n+@keras_core_export([\"keras_core.ops.array\", \"keras_core.ops.numpy.array\"])\n def array(x, dtype=None):\n     if any_symbolic_tensors((x,)):\n         return Array().symbolic_call(x, dtype=dtype)\n@@ -651,9 +617,7 @@ class Average(Operation):\n             )\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.average\", \"keras_core.operations.numpy.average\"]\n-)\n+@keras_core_export([\"keras_core.ops.average\", \"keras_core.ops.numpy.average\"])\n def average(x, axis=None, weights=None):\n     if any_symbolic_tensors((x,)):\n         return Average(axis=axis).symbolic_call(x, weights=weights)\n@@ -676,9 +640,7 @@ class Bincount(Operation):\n         return KerasTensor(out_shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.bincount\", \"keras_core.operations.numpy.bincount\"]\n-)\n+@keras_core_export([\"keras_core.ops.bincount\", \"keras_core.ops.numpy.bincount\"])\n def bincount(x, weights=None, minlength=0):\n     if any_symbolic_tensors((x,)):\n         return Bincount(weights=weights, minlength=minlength).symbolic_call(x)\n@@ -701,8 +663,8 @@ class BroadcastTo(Operation):\n \n @keras_core_export(\n     [\n-        \"keras_core.operations.broadcast_to\",\n-        \"keras_core.operations.numpy.broadcast_to\",\n+        \"keras_core.ops.broadcast_to\",\n+        \"keras_core.ops.numpy.broadcast_to\",\n     ]\n )\n def broadcast_to(x, shape):\n@@ -719,9 +681,7 @@ class Ceil(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.ceil\", \"keras_core.operations.numpy.ceil\"]\n-)\n+@keras_core_export([\"keras_core.ops.ceil\", \"keras_core.ops.numpy.ceil\"])\n def ceil(x):\n     if any_symbolic_tensors((x,)):\n         return Ceil().symbolic_call(x)\n@@ -741,9 +701,7 @@ class Clip(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.clip\", \"keras_core.operations.numpy.clip\"]\n-)\n+@keras_core_export([\"keras_core.ops.clip\", \"keras_core.ops.numpy.clip\"])\n def clip(x, x_min, x_max):\n     if any_symbolic_tensors((x,)):\n         return Clip(x_min, x_max).symbolic_call(x)\n@@ -784,8 +742,8 @@ class Concatenate(Operation):\n \n @keras_core_export(\n     [\n-        \"keras_core.operations.concatenate\",\n-        \"keras_core.operations.numpy.concatenate\",\n+        \"keras_core.ops.concatenate\",\n+        \"keras_core.ops.numpy.concatenate\",\n     ]\n )\n def concatenate(xs, axis=0):\n@@ -803,7 +761,7 @@ class Conjugate(Operation):\n \n \n @keras_core_export(\n-    [\"keras_core.operations.conjugate\", \"keras_core.operations.numpy.conjugate\"]\n+    [\"keras_core.ops.conjugate\", \"keras_core.ops.numpy.conjugate\"]\n )\n def conjugate(x):\n     if any_symbolic_tensors((x,)):\n@@ -815,9 +773,7 @@ class Conj(Conjugate):\n     pass\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.conj\", \"keras_core.operations.numpy.conj\"]\n-)\n+@keras_core_export([\"keras_core.ops.conj\", \"keras_core.ops.numpy.conj\"])\n def conj(x):\n     return conjugate(x)\n \n@@ -830,9 +786,7 @@ class Copy(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.copy\", \"keras_core.operations.numpy.copy\"]\n-)\n+@keras_core_export([\"keras_core.ops.copy\", \"keras_core.ops.numpy.copy\"])\n def copy(x):\n     if any_symbolic_tensors((x,)):\n         return Copy().symbolic_call(x)\n@@ -847,9 +801,7 @@ class Cos(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.cos\", \"keras_core.operations.numpy.cos\"]\n-)\n+@keras_core_export([\"keras_core.ops.cos\", \"keras_core.ops.numpy.cos\"])\n def cos(x):\n     if any_symbolic_tensors((x,)):\n         return Cos().symbolic_call(x)\n@@ -876,8 +828,8 @@ class CountNonzero(Operation):\n \n @keras_core_export(\n     [\n-        \"keras_core.operations.count_nonzero\",\n-        \"keras_core.operations.numpy.count_nonzero\",\n+        \"keras_core.ops.count_nonzero\",\n+        \"keras_core.ops.numpy.count_nonzero\",\n     ]\n )\n def count_nonzero(x, axis=None):\n@@ -933,9 +885,7 @@ class Cross(Operation):\n         return KerasTensor(output_shape, dtype=x1.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.cross\", \"keras_core.operations.numpy.cross\"]\n-)\n+@keras_core_export([\"keras_core.ops.cross\", \"keras_core.ops.numpy.cross\"])\n def cross(x1, x2, axisa=-1, axisb=-1, axisc=-1, axis=None):\n     if any_symbolic_tensors((x1, x2)):\n         return Cross(\n@@ -969,9 +919,7 @@ class Cumprod(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.cumprod\", \"keras_core.operations.numpy.cumprod\"]\n-)\n+@keras_core_export([\"keras_core.ops.cumprod\", \"keras_core.ops.numpy.cumprod\"])\n def cumprod(x, axis=None):\n     if any_symbolic_tensors((x,)):\n         return Cumprod(axis=axis).symbolic_call(x)\n@@ -996,9 +944,7 @@ class Cumsum(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.cumsum\", \"keras_core.operations.numpy.cumsum\"]\n-)\n+@keras_core_export([\"keras_core.ops.cumsum\", \"keras_core.ops.numpy.cumsum\"])\n def cumsum(x, axis=None):\n     if any_symbolic_tensors((x,)):\n         return Cumsum(axis=axis).symbolic_call(x)\n@@ -1042,9 +988,7 @@ class Diag(Operation):\n         return KerasTensor(output_shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.diag\", \"keras_core.operations.numpy.diag\"]\n-)\n+@keras_core_export([\"keras_core.ops.diag\", \"keras_core.ops.numpy.diag\"])\n def diag(x, k=0):\n     if any_symbolic_tensors((x,)):\n         return Diag(k=k).symbolic_call(x)\n@@ -1093,9 +1037,7 @@ class Diagonal(Operation):\n         return KerasTensor(output_shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.diagonal\", \"keras_core.operations.numpy.diagonal\"]\n-)\n+@keras_core_export([\"keras_core.ops.diagonal\", \"keras_core.ops.numpy.diagonal\"])\n def diagonal(x, offset=0, axis1=0, axis2=1):\n     if any_symbolic_tensors((x,)):\n         return Diagonal(\n@@ -1147,9 +1089,7 @@ class Dot(Operation):\n         )\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.dot\", \"keras_core.operations.numpy.dot\"]\n-)\n+@keras_core_export([\"keras_core.ops.dot\", \"keras_core.ops.numpy.dot\"])\n def dot(x1, x2):\n     if any_symbolic_tensors((x1, x2)):\n         return Dot().symbolic_call(x1, x2)\n@@ -1329,9 +1269,7 @@ class Einsum(Operation):\n         return KerasTensor(output_shape, dtype=dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.einsum\", \"keras_core.operations.numpy.einsum\"]\n-)\n+@keras_core_export([\"keras_core.ops.einsum\", \"keras_core.ops.numpy.einsum\"])\n def einsum(subscripts, *operands):\n     if any_symbolic_tensors(operands):\n         return Einsum(subscripts).symbolic_call(*operands)\n@@ -1346,9 +1284,7 @@ class Empty(Operation):\n         return KerasTensor(shape, dtype=dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.empty\", \"keras_core.operations.numpy.empty\"]\n-)\n+@keras_core_export([\"keras_core.ops.empty\", \"keras_core.ops.numpy.empty\"])\n def empty(shape, dtype=\"float32\"):\n     return backend.numpy.empty(shape, dtype=dtype)\n \n@@ -1364,9 +1300,7 @@ class Equal(Operation):\n         return KerasTensor(output_shape, dtype=x1.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.equal\", \"keras_core.operations.numpy.equal\"]\n-)\n+@keras_core_export([\"keras_core.ops.equal\", \"keras_core.ops.numpy.equal\"])\n def equal(x1, x2):\n     if any_symbolic_tensors((x1, x2)):\n         return Equal().symbolic_call(x1, x2)\n@@ -1381,9 +1315,7 @@ class Exp(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.exp\", \"keras_core.operations.numpy.exp\"]\n-)\n+@keras_core_export([\"keras_core.ops.exp\", \"keras_core.ops.numpy.exp\"])\n def exp(x):\n     if any_symbolic_tensors((x,)):\n         return Exp().symbolic_call(x)\n@@ -1415,8 +1347,8 @@ class ExpandDims(Operation):\n \n @keras_core_export(\n     [\n-        \"keras_core.operations.expand_dims\",\n-        \"keras_core.operations.numpy.expand_dims\",\n+        \"keras_core.ops.expand_dims\",\n+        \"keras_core.ops.numpy.expand_dims\",\n     ]\n )\n def expand_dims(x, axis):\n@@ -1433,9 +1365,7 @@ class Expm1(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.expm1\", \"keras_core.operations.numpy.expm1\"]\n-)\n+@keras_core_export([\"keras_core.ops.expm1\", \"keras_core.ops.numpy.expm1\"])\n def expm1(x):\n     if any_symbolic_tensors((x,)):\n         return Expm1().symbolic_call(x)\n@@ -1454,9 +1384,7 @@ class Flip(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.flip\", \"keras_core.operations.numpy.flip\"]\n-)\n+@keras_core_export([\"keras_core.ops.flip\", \"keras_core.ops.numpy.flip\"])\n def flip(x, axis=None):\n     if any_symbolic_tensors((x,)):\n         return Flip(axis=axis).symbolic_call(x)\n@@ -1471,9 +1399,7 @@ class Floor(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.floor\", \"keras_core.operations.numpy.floor\"]\n-)\n+@keras_core_export([\"keras_core.ops.floor\", \"keras_core.ops.numpy.floor\"])\n def floor(x):\n     if any_symbolic_tensors((x,)):\n         return Floor().symbolic_call(x)\n@@ -1488,9 +1414,7 @@ class Full(Operation):\n         return KerasTensor(shape, dtype=dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.full\", \"keras_core.operations.numpy.full\"]\n-)\n+@keras_core_export([\"keras_core.ops.full\", \"keras_core.ops.numpy.full\"])\n def full(shape, fill_value, dtype=None):\n     return backend.numpy.full(shape, fill_value, dtype=dtype)\n \n@@ -1504,7 +1428,7 @@ class FullLike(Operation):\n \n \n @keras_core_export(\n-    [\"keras_core.operations.full_like\", \"keras_core.operations.numpy.full_like\"]\n+    [\"keras_core.ops.full_like\", \"keras_core.ops.numpy.full_like\"]\n )\n def full_like(x, fill_value, dtype=None):\n     if any_symbolic_tensors((x,)):\n@@ -1581,9 +1505,7 @@ class GetItem(Operation):\n         return KerasTensor(tuple(new_shape), dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.get_item\", \"keras_core.operations.numpy.get_item\"]\n-)\n+@keras_core_export([\"keras_core.ops.get_item\", \"keras_core.ops.numpy.get_item\"])\n def get_item(x, key):\n     if any_symbolic_tensors((x,)):\n         return GetItem().symbolic_call(x, key)\n@@ -1601,9 +1523,7 @@ class Greater(Operation):\n         return KerasTensor(output_shape, dtype=x1.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.greater\", \"keras_core.operations.numpy.greater\"]\n-)\n+@keras_core_export([\"keras_core.ops.greater\", \"keras_core.ops.numpy.greater\"])\n def greater(x1, x2):\n     if any_symbolic_tensors((x1, x2)):\n         return Greater().symbolic_call(x1, x2)\n@@ -1623,8 +1543,8 @@ class GreaterEqual(Operation):\n \n @keras_core_export(\n     [\n-        \"keras_core.operations.greater_equal\",\n-        \"keras_core.operations.numpy.greater_equal\",\n+        \"keras_core.ops.greater_equal\",\n+        \"keras_core.ops.numpy.greater_equal\",\n     ]\n )\n def greater_equal(x1, x2):\n@@ -1657,9 +1577,7 @@ class Hstack(Operation):\n         return KerasTensor(output_shape)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.hstack\", \"keras_core.operations.numpy.hstack\"]\n-)\n+@keras_core_export([\"keras_core.ops.hstack\", \"keras_core.ops.numpy.hstack\"])\n def hstack(xs):\n     if any_symbolic_tensors((xs,)):\n         return Hstack().symbolic_call(xs)\n@@ -1674,9 +1592,7 @@ class Identity(Operation):\n         return KerasTensor([n, n], dtype=dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.identity\", \"keras_core.operations.numpy.identity\"]\n-)\n+@keras_core_export([\"keras_core.ops.identity\", \"keras_core.ops.numpy.identity\"])\n def identity(n, dtype=\"float32\"):\n     return backend.numpy.identity(n, dtype=dtype)\n \n@@ -1689,9 +1605,7 @@ class Imag(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.imag\", \"keras_core.operations.numpy.imag\"]\n-)\n+@keras_core_export([\"keras_core.ops.imag\", \"keras_core.ops.numpy.imag\"])\n def imag(x):\n     if any_symbolic_tensors((x,)):\n         return Imag().symbolic_call(x)\n@@ -1709,9 +1623,7 @@ class Isclose(Operation):\n         return KerasTensor(output_shape, dtype=x1.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.isclose\", \"keras_core.operations.numpy.isclose\"]\n-)\n+@keras_core_export([\"keras_core.ops.isclose\", \"keras_core.ops.numpy.isclose\"])\n def isclose(x1, x2):\n     if any_symbolic_tensors((x1, x2)):\n         return Isclose().symbolic_call(x1, x2)\n@@ -1726,9 +1638,7 @@ class Isfinite(Operation):\n         return KerasTensor(x.shape, dtype=\"bool\")\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.isfinite\", \"keras_core.operations.numpy.isfinite\"]\n-)\n+@keras_core_export([\"keras_core.ops.isfinite\", \"keras_core.ops.numpy.isfinite\"])\n def isfinite(x):\n     if any_symbolic_tensors((x,)):\n         return Isfinite().symbolic_call(x)\n@@ -1743,9 +1653,7 @@ class Isinf(Operation):\n         return KerasTensor(x.shape, dtype=\"bool\")\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.isinf\", \"keras_core.operations.numpy.isinf\"]\n-)\n+@keras_core_export([\"keras_core.ops.isinf\", \"keras_core.ops.numpy.isinf\"])\n def isinf(x):\n     if any_symbolic_tensors((x,)):\n         return Isinf().symbolic_call(x)\n@@ -1760,9 +1668,7 @@ class Isnan(Operation):\n         return KerasTensor(x.shape, dtype=\"bool\")\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.isnan\", \"keras_core.operations.numpy.isnan\"]\n-)\n+@keras_core_export([\"keras_core.ops.isnan\", \"keras_core.ops.numpy.isnan\"])\n def isnan(x):\n     if any_symbolic_tensors((x,)):\n         return Isnan().symbolic_call(x)\n@@ -1780,9 +1686,7 @@ class Less(Operation):\n         return KerasTensor(output_shape, dtype=x1.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.less\", \"keras_core.operations.numpy.less\"]\n-)\n+@keras_core_export([\"keras_core.ops.less\", \"keras_core.ops.numpy.less\"])\n def less(x1, x2):\n     if any_symbolic_tensors((x1, x2)):\n         return Less().symbolic_call(x1, x2)\n@@ -1802,8 +1706,8 @@ class LessEqual(Operation):\n \n @keras_core_export(\n     [\n-        \"keras_core.operations.less_equal\",\n-        \"keras_core.operations.numpy.less_equal\",\n+        \"keras_core.ops.less_equal\",\n+        \"keras_core.ops.numpy.less_equal\",\n     ]\n )\n def less_equal(x1, x2):\n@@ -1859,9 +1763,7 @@ class Linspace(Operation):\n         return KerasTensor(output_shape, dtype=dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.linspace\", \"keras_core.operations.numpy.linspace\"]\n-)\n+@keras_core_export([\"keras_core.ops.linspace\", \"keras_core.ops.numpy.linspace\"])\n def linspace(\n     start, stop, num=50, endpoint=True, retstep=False, dtype=None, axis=0\n ):\n@@ -1886,9 +1788,7 @@ class Log(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.log\", \"keras_core.operations.numpy.log\"]\n-)\n+@keras_core_export([\"keras_core.ops.log\", \"keras_core.ops.numpy.log\"])\n def log(x):\n     if any_symbolic_tensors((x,)):\n         return Log().symbolic_call(x)\n@@ -1903,9 +1803,7 @@ class Log10(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.log10\", \"keras_core.operations.numpy.log10\"]\n-)\n+@keras_core_export([\"keras_core.ops.log10\", \"keras_core.ops.numpy.log10\"])\n def log10(x):\n     if any_symbolic_tensors((x,)):\n         return Log10().symbolic_call(x)\n@@ -1920,9 +1818,7 @@ class Log1p(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.log1p\", \"keras_core.operations.numpy.log1p\"]\n-)\n+@keras_core_export([\"keras_core.ops.log1p\", \"keras_core.ops.numpy.log1p\"])\n def log1p(x):\n     if any_symbolic_tensors((x,)):\n         return Log1p().symbolic_call(x)\n@@ -1937,9 +1833,7 @@ class Log2(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.log2\", \"keras_core.operations.numpy.log2\"]\n-)\n+@keras_core_export([\"keras_core.ops.log2\", \"keras_core.ops.numpy.log2\"])\n def log2(x):\n     if any_symbolic_tensors((x,)):\n         return Log2().symbolic_call(x)\n@@ -1958,7 +1852,7 @@ class Logaddexp(Operation):\n \n \n @keras_core_export(\n-    [\"keras_core.operations.logaddexp\", \"keras_core.operations.numpy.logaddexp\"]\n+    [\"keras_core.ops.logaddexp\", \"keras_core.ops.numpy.logaddexp\"]\n )\n def logaddexp(x1, x2):\n     if any_symbolic_tensors((x1, x2)):\n@@ -1979,8 +1873,8 @@ class LogicalAnd(Operation):\n \n @keras_core_export(\n     [\n-        \"keras_core.operations.logical_and\",\n-        \"keras_core.operations.numpy.logical_and\",\n+        \"keras_core.ops.logical_and\",\n+        \"keras_core.ops.numpy.logical_and\",\n     ]\n )\n def logical_and(x1, x2):\n@@ -1999,8 +1893,8 @@ class LogicalNot(Operation):\n \n @keras_core_export(\n     [\n-        \"keras_core.operations.logical_not\",\n-        \"keras_core.operations.numpy.logical_not\",\n+        \"keras_core.ops.logical_not\",\n+        \"keras_core.ops.numpy.logical_not\",\n     ]\n )\n def logical_not(x):\n@@ -2022,8 +1916,8 @@ class LogicalOr(Operation):\n \n @keras_core_export(\n     [\n-        \"keras_core.operations.logical_or\",\n-        \"keras_core.operations.numpy.logical_or\",\n+        \"keras_core.ops.logical_or\",\n+        \"keras_core.ops.numpy.logical_or\",\n     ]\n )\n def logical_or(x1, x2):\n@@ -2075,9 +1969,7 @@ class Logspace(Operation):\n         return KerasTensor(output_shape, dtype=dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.logspace\", \"keras_core.operations.numpy.logspace\"]\n-)\n+@keras_core_export([\"keras_core.ops.logspace\", \"keras_core.ops.numpy.logspace\"])\n def logspace(start, stop, num=50, endpoint=True, base=10, dtype=None, axis=0):\n     if any_symbolic_tensors((start, stop)):\n         return Logspace(num, endpoint, base, dtype, axis)(start, stop)\n@@ -2124,9 +2016,7 @@ class Matmul(Operation):\n         return KerasTensor(output_shape, dtype=x1.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.matmul\", \"keras_core.operations.numpy.matmul\"]\n-)\n+@keras_core_export([\"keras_core.ops.matmul\", \"keras_core.ops.numpy.matmul\"])\n def matmul(x1, x2):\n     if any_symbolic_tensors((x1, x2)):\n         return Matmul().symbolic_call(x1, x2)\n@@ -2158,9 +2048,7 @@ class Max(Operation):\n         )\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.max\", \"keras_core.operations.numpy.max\"]\n-)\n+@keras_core_export([\"keras_core.ops.max\", \"keras_core.ops.numpy.max\"])\n def max(x, axis=None, keepdims=False, initial=None):\n     if any_symbolic_tensors((x,)):\n         return Max(axis=axis, keepdims=keepdims, initial=initial).symbolic_call(\n@@ -2180,9 +2068,7 @@ class Maximum(Operation):\n         return KerasTensor(output_shape, dtype=x1.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.maximum\", \"keras_core.operations.numpy.maximum\"]\n-)\n+@keras_core_export([\"keras_core.ops.maximum\", \"keras_core.ops.numpy.maximum\"])\n def maximum(x1, x2):\n     if any_symbolic_tensors((x1, x2)):\n         return Maximum().symbolic_call(x1, x2)\n@@ -2221,9 +2107,7 @@ class Meshgrid(Operation):\n         return [KerasTensor(output_shape) for _ in range(len(x))]\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.meshgrid\", \"keras_core.operations.numpy.meshgrid\"]\n-)\n+@keras_core_export([\"keras_core.ops.meshgrid\", \"keras_core.ops.numpy.meshgrid\"])\n def meshgrid(*x, indexing=\"xy\"):\n     if any_symbolic_tensors(x):\n         return Meshgrid(indexing=indexing).symbolic_call(*x)\n@@ -2251,9 +2135,7 @@ class Min(Operation):\n         )\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.min\", \"keras_core.operations.numpy.min\"]\n-)\n+@keras_core_export([\"keras_core.ops.min\", \"keras_core.ops.numpy.min\"])\n def min(x, axis=None, keepdims=False, initial=None):\n     if any_symbolic_tensors((x,)):\n         return Min(axis=axis, keepdims=keepdims, initial=initial).symbolic_call(\n@@ -2273,9 +2155,7 @@ class Minimum(Operation):\n         return KerasTensor(output_shape, dtype=x1.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.minimum\", \"keras_core.operations.numpy.minimum\"]\n-)\n+@keras_core_export([\"keras_core.ops.minimum\", \"keras_core.ops.numpy.minimum\"])\n def minimum(x1, x2):\n     if any_symbolic_tensors((x1, x2)):\n         return Minimum().symbolic_call(x1, x2)\n@@ -2293,9 +2173,7 @@ class Mod(Operation):\n         return KerasTensor(output_shape, dtype=x1.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.mod\", \"keras_core.operations.numpy.mod\"]\n-)\n+@keras_core_export([\"keras_core.ops.mod\", \"keras_core.ops.numpy.mod\"])\n def mod(x1, x2):\n     if any_symbolic_tensors((x1, x2)):\n         return Mod().symbolic_call(x1, x2)\n@@ -2346,9 +2224,7 @@ class Moveaxis(Operation):\n         return KerasTensor(output_shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.moveaxis\", \"keras_core.operations.numpy.moveaxis\"]\n-)\n+@keras_core_export([\"keras_core.ops.moveaxis\", \"keras_core.ops.numpy.moveaxis\"])\n def moveaxis(x, source, destination):\n     if any_symbolic_tensors((x,)):\n         return Moveaxis(source, destination).symbolic_call(x)\n@@ -2362,8 +2238,8 @@ class NanToNum(Operation):\n \n @keras_core_export(\n     [\n-        \"keras_core.operations.nan_to_num\",\n-        \"keras_core.operations.numpy.nan_to_num\",\n+        \"keras_core.ops.nan_to_num\",\n+        \"keras_core.ops.numpy.nan_to_num\",\n     ]\n )\n def nan_to_num(x):\n@@ -2380,9 +2256,7 @@ class Ndim(Operation):\n         return KerasTensor([len(x.shape)])\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.ndim\", \"keras_core.operations.numpy.ndim\"]\n-)\n+@keras_core_export([\"keras_core.ops.ndim\", \"keras_core.ops.numpy.ndim\"])\n def ndim(x):\n     if any_symbolic_tensors((x,)):\n         return Ndim().symbolic_call(x)\n@@ -2394,9 +2268,7 @@ class Nonzero(Operation):\n         return backend.numpy.nonzero(x)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.nonzero\", \"keras_core.operations.numpy.nonzero\"]\n-)\n+@keras_core_export([\"keras_core.ops.nonzero\", \"keras_core.ops.numpy.nonzero\"])\n def nonzero(x):\n     return backend.numpy.nonzero(x)\n \n@@ -2413,7 +2285,7 @@ class NotEqual(Operation):\n \n \n @keras_core_export(\n-    [\"keras_core.operations.not_equal\", \"keras_core.operations.numpy.not_equal\"]\n+    [\"keras_core.ops.not_equal\", \"keras_core.ops.numpy.not_equal\"]\n )\n def not_equal(x1, x2):\n     if any_symbolic_tensors((x1, x2)):\n@@ -2432,7 +2304,7 @@ class OnesLike(Operation):\n \n \n @keras_core_export(\n-    [\"keras_core.operations.ones_like\", \"keras_core.operations.numpy.ones_like\"]\n+    [\"keras_core.ops.ones_like\", \"keras_core.ops.numpy.ones_like\"]\n )\n def ones_like(x, dtype=None):\n     if any_symbolic_tensors((x,)):\n@@ -2452,8 +2324,8 @@ class ZerosLike(Operation):\n \n @keras_core_export(\n     [\n-        \"keras_core.operations.zeros_like\",\n-        \"keras_core.operations.numpy.zeros_like\",\n+        \"keras_core.ops.zeros_like\",\n+        \"keras_core.ops.numpy.zeros_like\",\n     ]\n )\n def zeros_like(x, dtype=None):\n@@ -2481,9 +2353,7 @@ class Outer(Operation):\n         return KerasTensor(output_shape, dtype=x1.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.outer\", \"keras_core.operations.numpy.outer\"]\n-)\n+@keras_core_export([\"keras_core.ops.outer\", \"keras_core.ops.numpy.outer\"])\n def outer(x1, x2):\n     if any_symbolic_tensors((x1, x2)):\n         return Outer().symbolic_call(x1, x2)\n@@ -2537,9 +2407,7 @@ class Pad(Operation):\n         return KerasTensor(output_shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.pad\", \"keras_core.operations.numpy.pad\"]\n-)\n+@keras_core_export([\"keras_core.ops.pad\", \"keras_core.ops.numpy.pad\"])\n def pad(x, pad_width, mode=\"constant\"):\n     if any_symbolic_tensors((x,)):\n         return Pad(pad_width, mode=mode).symbolic_call(x)\n@@ -2571,9 +2439,7 @@ class Prod(Operation):\n         )\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.prod\", \"keras_core.operations.numpy.prod\"]\n-)\n+@keras_core_export([\"keras_core.ops.prod\", \"keras_core.ops.numpy.prod\"])\n def prod(x, axis=None, keepdims=False, dtype=None):\n     if any_symbolic_tensors((x,)):\n         return Prod(axis=axis, keepdims=keepdims, dtype=dtype).symbolic_call(x)\n@@ -2594,9 +2460,7 @@ class Ravel(Operation):\n         return KerasTensor(output_shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.ravel\", \"keras_core.operations.numpy.ravel\"]\n-)\n+@keras_core_export([\"keras_core.ops.ravel\", \"keras_core.ops.numpy.ravel\"])\n def ravel(x):\n     if any_symbolic_tensors((x,)):\n         return Ravel().symbolic_call(x)\n@@ -2611,9 +2475,7 @@ class Real(Operation):\n         return KerasTensor(x.shape)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.real\", \"keras_core.operations.numpy.real\"]\n-)\n+@keras_core_export([\"keras_core.ops.real\", \"keras_core.ops.numpy.real\"])\n def real(x):\n     if any_symbolic_tensors((x,)):\n         return Real().symbolic_call(x)\n@@ -2630,8 +2492,8 @@ class Reciprocal(Operation):\n \n @keras_core_export(\n     [\n-        \"keras_core.operations.reciprocal\",\n-        \"keras_core.operations.numpy.reciprocal\",\n+        \"keras_core.ops.reciprocal\",\n+        \"keras_core.ops.numpy.reciprocal\",\n     ]\n )\n def reciprocal(x):\n@@ -2674,9 +2536,7 @@ class Repeat(Operation):\n         return KerasTensor(output_shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.repeat\", \"keras_core.operations.numpy.repeat\"]\n-)\n+@keras_core_export([\"keras_core.ops.repeat\", \"keras_core.ops.numpy.repeat\"])\n def repeat(x, repeats, axis=None):\n     if any_symbolic_tensors((x,)):\n         return Repeat(repeats, axis=axis).symbolic_call(x)\n@@ -2698,9 +2558,7 @@ class Reshape(Operation):\n         return KerasTensor(output_shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.reshape\", \"keras_core.operations.numpy.reshape\"]\n-)\n+@keras_core_export([\"keras_core.ops.reshape\", \"keras_core.ops.numpy.reshape\"])\n def reshape(x, new_shape):\n     if any_symbolic_tensors((x,)):\n         return Reshape(new_shape).symbolic_call(x)\n@@ -2720,9 +2578,7 @@ class Roll(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.roll\", \"keras_core.operations.numpy.roll\"]\n-)\n+@keras_core_export([\"keras_core.ops.roll\", \"keras_core.ops.numpy.roll\"])\n def roll(x, shift, axis=None):\n     if any_symbolic_tensors((x,)):\n         return Roll(shift, axis=axis).symbolic_call(x)\n@@ -2741,9 +2597,7 @@ class Round(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.round\", \"keras_core.operations.numpy.round\"]\n-)\n+@keras_core_export([\"keras_core.ops.round\", \"keras_core.ops.numpy.round\"])\n def round(x, decimals=0):\n     if any_symbolic_tensors((x,)):\n         return Round(decimals).symbolic_call(x)\n@@ -2758,9 +2612,7 @@ class Sign(Operation):\n         return KerasTensor(x.shape, dtype=\"int32\")\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.sign\", \"keras_core.operations.numpy.sign\"]\n-)\n+@keras_core_export([\"keras_core.ops.sign\", \"keras_core.ops.numpy.sign\"])\n def sign(x):\n     if any_symbolic_tensors((x,)):\n         return Sign().symbolic_call(x)\n@@ -2775,9 +2627,7 @@ class Sin(Operation):\n         return KerasTensor(x.shape)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.sin\", \"keras_core.operations.numpy.sin\"]\n-)\n+@keras_core_export([\"keras_core.ops.sin\", \"keras_core.ops.numpy.sin\"])\n def sin(x):\n     if any_symbolic_tensors((x,)):\n         return Sin().symbolic_call(x)\n@@ -2792,9 +2642,7 @@ class Size(Operation):\n         return KerasTensor([], dtype=\"int32\")\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.size\", \"keras_core.operations.numpy.size\"]\n-)\n+@keras_core_export([\"keras_core.ops.size\", \"keras_core.ops.numpy.size\"])\n def size(x):\n     if any_symbolic_tensors((x,)):\n         return Size().symbolic_call(x)\n@@ -2813,9 +2661,7 @@ class Sort(Operation):\n         return KerasTensor(x.shape, x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.sort\", \"keras_core.operations.numpy.sort\"]\n-)\n+@keras_core_export([\"keras_core.ops.sort\", \"keras_core.ops.numpy.sort\"])\n def sort(x, axis=-1):\n     if any_symbolic_tensors((x,)):\n         return Sort(axis=axis).symbolic_call(x)\n@@ -2865,9 +2711,7 @@ class Split(Operation):\n         return outputs\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.split\", \"keras_core.operations.numpy.split\"]\n-)\n+@keras_core_export([\"keras_core.ops.split\", \"keras_core.ops.numpy.split\"])\n def split(x, indices_or_sections, axis=0):\n     if any_symbolic_tensors((x,)):\n         return Split(indices_or_sections, axis=axis).symbolic_call(x)\n@@ -2903,9 +2747,7 @@ class Stack(Operation):\n         return KerasTensor(output_shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.stack\", \"keras_core.operations.numpy.stack\"]\n-)\n+@keras_core_export([\"keras_core.ops.stack\", \"keras_core.ops.numpy.stack\"])\n def stack(x, axis=0):\n     if any_symbolic_tensors((x,)):\n         return Stack(axis=axis).symbolic_call(x)\n@@ -2930,9 +2772,7 @@ class Std(Operation):\n         )\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.std\", \"keras_core.operations.numpy.std\"]\n-)\n+@keras_core_export([\"keras_core.ops.std\", \"keras_core.ops.numpy.std\"])\n def std(x, axis=None, keepdims=False):\n     if any_symbolic_tensors((x,)):\n         return Std(axis=axis, keepdims=keepdims).symbolic_call(x)\n@@ -2957,9 +2797,7 @@ class Swapaxes(Operation):\n         return KerasTensor(x_shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.swapaxes\", \"keras_core.operations.numpy.swapaxes\"]\n-)\n+@keras_core_export([\"keras_core.ops.swapaxes\", \"keras_core.ops.numpy.swapaxes\"])\n def swapaxes(x, axis1, axis2):\n     if any_symbolic_tensors((x,)):\n         return Swapaxes(axis1, axis2).symbolic_call(x)\n@@ -2989,9 +2827,7 @@ class Take(Operation):\n         return KerasTensor(output_shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.take\", \"keras_core.operations.numpy.take\"]\n-)\n+@keras_core_export([\"keras_core.ops.take\", \"keras_core.ops.numpy.take\"])\n def take(x, indices, axis=None):\n     if any_symbolic_tensors((x, indices)):\n         return Take(axis=axis).symbolic_call(x, indices)\n@@ -3034,8 +2870,8 @@ class TakeAlongAxis(Operation):\n \n @keras_core_export(\n     [\n-        \"keras_core.operations.take_along_axis\",\n-        \"keras_core.operations.numpy.take_along_axis\",\n+        \"keras_core.ops.take_along_axis\",\n+        \"keras_core.ops.numpy.take_along_axis\",\n     ]\n )\n def take_along_axis(x, indices, axis=None):\n@@ -3052,9 +2888,7 @@ class Tan(Operation):\n         return KerasTensor(x.shape)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.tan\", \"keras_core.operations.numpy.tan\"]\n-)\n+@keras_core_export([\"keras_core.ops.tan\", \"keras_core.ops.numpy.tan\"])\n def tan(x):\n     if any_symbolic_tensors((x,)):\n         return Tan().symbolic_call(x)\n@@ -3103,7 +2937,7 @@ class Tensordot(Operation):\n \n \n @keras_core_export(\n-    [\"keras_core.operations.tensordot\", \"keras_core.operations.numpy.tensordot\"]\n+    [\"keras_core.ops.tensordot\", \"keras_core.ops.numpy.tensordot\"]\n )\n def tensordot(x1, x2, axes=2):\n     if any_symbolic_tensors((x1, x2)):\n@@ -3136,9 +2970,7 @@ class Tile(Operation):\n         return KerasTensor(output_shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.tile\", \"keras_core.operations.numpy.tile\"]\n-)\n+@keras_core_export([\"keras_core.ops.tile\", \"keras_core.ops.numpy.tile\"])\n def tile(x, repeats):\n     if any_symbolic_tensors((x,)):\n         return Tile(\n@@ -3167,9 +2999,7 @@ class Trace(Operation):\n         return KerasTensor(output_shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.trace\", \"keras_core.operations.numpy.trace\"]\n-)\n+@keras_core_export([\"keras_core.ops.trace\", \"keras_core.ops.numpy.trace\"])\n def trace(x, offset=0, axis1=0, axis2=1):\n     if any_symbolic_tensors((x,)):\n         return Trace(offset, axis1, axis2).symbolic_call(x)\n@@ -3186,9 +3016,7 @@ class Tri(Operation):\n         return KerasTensor((N, M), dtype=dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.tri\", \"keras_core.operations.numpy.tri\"]\n-)\n+@keras_core_export([\"keras_core.ops.tri\", \"keras_core.ops.numpy.tri\"])\n def tri(N, M=None, k=0, dtype=\"float32\"):\n     return backend.numpy.tri(N, M=M, k=k, dtype=dtype)\n \n@@ -3205,9 +3033,7 @@ class Tril(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.tril\", \"keras_core.operations.numpy.tril\"]\n-)\n+@keras_core_export([\"keras_core.ops.tril\", \"keras_core.ops.numpy.tril\"])\n def tril(x, k=0):\n     if any_symbolic_tensors((x,)):\n         return Tril(k=k).symbolic_call(x)\n@@ -3226,9 +3052,7 @@ class Triu(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.triu\", \"keras_core.operations.numpy.triu\"]\n-)\n+@keras_core_export([\"keras_core.ops.triu\", \"keras_core.ops.numpy.triu\"])\n def triu(x, k=0):\n     if any_symbolic_tensors((x,)):\n         return Triu(k=k).symbolic_call(x)\n@@ -3243,9 +3067,7 @@ class Vdot(Operation):\n         return KerasTensor([], dtype=x1.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.vdot\", \"keras_core.operations.numpy.vdot\"]\n-)\n+@keras_core_export([\"keras_core.ops.vdot\", \"keras_core.ops.numpy.vdot\"])\n def vdot(x1, x2):\n     if any_symbolic_tensors((x1, x2)):\n         return Vdot().symbolic_call(x1, x2)\n@@ -3276,9 +3098,7 @@ class Vstack(Operation):\n         return KerasTensor(output_shape)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.vstack\", \"keras_core.operations.numpy.vstack\"]\n-)\n+@keras_core_export([\"keras_core.ops.vstack\", \"keras_core.ops.numpy.vstack\"])\n def vstack(xs):\n     if any_symbolic_tensors((xs,)):\n         return Vstack().symbolic_call(xs)\n@@ -3298,9 +3118,7 @@ class Where(Operation):\n         return KerasTensor(output_shape, dtype=x1.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.where\", \"keras_core.operations.numpy.where\"]\n-)\n+@keras_core_export([\"keras_core.ops.where\", \"keras_core.ops.numpy.where\"])\n def where(condition, x1, x2):\n     if any_symbolic_tensors((condition, x1, x2)):\n         return Where().symbolic_call(condition, x1, x2)\n@@ -3318,9 +3136,7 @@ class Subtract(Operation):\n         return KerasTensor(output_shape, dtype=x1.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.subtract\", \"keras_core.operations.numpy.subtract\"]\n-)\n+@keras_core_export([\"keras_core.ops.subtract\", \"keras_core.ops.numpy.subtract\"])\n def subtract(x1, x2):\n     if any_symbolic_tensors((x1, x2)):\n         return Subtract().symbolic_call(x1, x2)\n@@ -3338,9 +3154,7 @@ class Multiply(Operation):\n         return KerasTensor(output_shape, dtype=x1.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.multiply\", \"keras_core.operations.numpy.multiply\"]\n-)\n+@keras_core_export([\"keras_core.ops.multiply\", \"keras_core.ops.numpy.multiply\"])\n def multiply(x1, x2):\n     if any_symbolic_tensors((x1, x2)):\n         return Multiply().symbolic_call(x1, x2)\n@@ -3358,9 +3172,7 @@ class Divide(Operation):\n         return KerasTensor(output_shape, dtype=x1.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.divide\", \"keras_core.operations.numpy.divide\"]\n-)\n+@keras_core_export([\"keras_core.ops.divide\", \"keras_core.ops.numpy.divide\"])\n def divide(x1, x2):\n     if any_symbolic_tensors((x1, x2)):\n         return Divide().symbolic_call(x1, x2)\n@@ -3380,8 +3192,8 @@ class TrueDivide(Operation):\n \n @keras_core_export(\n     [\n-        \"keras_core.operations.true_divide\",\n-        \"keras_core.operations.numpy.true_divide\",\n+        \"keras_core.ops.true_divide\",\n+        \"keras_core.ops.numpy.true_divide\",\n     ]\n )\n def true_divide(x1, x2):\n@@ -3401,9 +3213,7 @@ class Power(Operation):\n         return KerasTensor(output_shape, dtype=x1.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.power\", \"keras_core.operations.numpy.power\"]\n-)\n+@keras_core_export([\"keras_core.ops.power\", \"keras_core.ops.numpy.power\"])\n def power(x1, x2):\n     if any_symbolic_tensors((x1, x2)):\n         return Power().symbolic_call(x1, x2)\n@@ -3418,9 +3228,7 @@ class Negative(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.negative\", \"keras_core.operations.numpy.negative\"]\n-)\n+@keras_core_export([\"keras_core.ops.negative\", \"keras_core.ops.numpy.negative\"])\n def negative(x):\n     if any_symbolic_tensors((x,)):\n         return Negative().symbolic_call(x)\n@@ -3435,9 +3243,7 @@ class Square(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.square\", \"keras_core.operations.numpy.square\"]\n-)\n+@keras_core_export([\"keras_core.ops.square\", \"keras_core.ops.numpy.square\"])\n def square(x):\n     if any_symbolic_tensors((x,)):\n         return Square().symbolic_call(x)\n@@ -3453,9 +3259,7 @@ class Sqrt(Operation):\n         return KerasTensor(x.shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.sqrt\", \"keras_core.operations.numpy.sqrt\"]\n-)\n+@keras_core_export([\"keras_core.ops.sqrt\", \"keras_core.ops.numpy.sqrt\"])\n def sqrt(x):\n     if any_symbolic_tensors((x,)):\n         return Sqrt().symbolic_call(x)\n@@ -3486,9 +3290,7 @@ class Squeeze(Operation):\n             return KerasTensor(input_shape, dtype=x.dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.squeeze\", \"keras_core.operations.numpy.squeeze\"]\n-)\n+@keras_core_export([\"keras_core.ops.squeeze\", \"keras_core.ops.numpy.squeeze\"])\n def squeeze(x, axis=None):\n     if any_symbolic_tensors((x,)):\n         return Squeeze().symbolic_call(x, axis=axis)\n@@ -3520,7 +3322,7 @@ class Transpose(Operation):\n \n \n @keras_core_export(\n-    [\"keras_core.operations.transpose\", \"keras_core.operations.numpy.transpose\"]\n+    [\"keras_core.ops.transpose\", \"keras_core.ops.numpy.transpose\"]\n )\n def transpose(x, axes=None):\n     if any_symbolic_tensors((x,)):\n@@ -3546,9 +3348,7 @@ class Mean(Operation):\n         )\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.mean\", \"keras_core.operations.numpy.mean\"]\n-)\n+@keras_core_export([\"keras_core.ops.mean\", \"keras_core.ops.numpy.mean\"])\n def mean(x, axis=None, keepdims=False):\n     if any_symbolic_tensors((x,)):\n         return Mean(axis=axis, keepdims=keepdims).symbolic_call(x)\n@@ -3573,9 +3373,7 @@ class Var(Operation):\n         )\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.var\", \"keras_core.operations.numpy.var\"]\n-)\n+@keras_core_export([\"keras_core.ops.var\", \"keras_core.ops.numpy.var\"])\n def var(x, axis=None, keepdims=False):\n     if any_symbolic_tensors((x,)):\n         return Var(axis=axis, keepdims=keepdims).symbolic_call(x)\n@@ -3600,9 +3398,7 @@ class Sum(Operation):\n         )\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.sum\", \"keras_core.operations.numpy.sum\"]\n-)\n+@keras_core_export([\"keras_core.ops.sum\", \"keras_core.ops.numpy.sum\"])\n def sum(x, axis=None, keepdims=False):\n     if any_symbolic_tensors((x,)):\n         return Sum(axis=axis, keepdims=keepdims).symbolic_call(x)\n@@ -3617,9 +3413,7 @@ class Zeros(Operation):\n         return KerasTensor(shape, dtype=dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.zeros\", \"keras_core.operations.numpy.zeros\"]\n-)\n+@keras_core_export([\"keras_core.ops.zeros\", \"keras_core.ops.numpy.zeros\"])\n def zeros(shape, dtype=\"float32\"):\n     return backend.numpy.zeros(shape, dtype=dtype)\n \n@@ -3632,9 +3426,7 @@ class Ones(Operation):\n         return KerasTensor(shape, dtype=dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.ones\", \"keras_core.operations.numpy.ones\"]\n-)\n+@keras_core_export([\"keras_core.ops.ones\", \"keras_core.ops.numpy.ones\"])\n def ones(shape, dtype=\"float32\"):\n     return backend.numpy.ones(shape, dtype=dtype)\n \n@@ -3649,8 +3441,6 @@ class Eye(Operation):\n         return KerasTensor((N, M), dtype=dtype)\n \n \n-@keras_core_export(\n-    [\"keras_core.operations.eye\", \"keras_core.operations.numpy.eye\"]\n-)\n+@keras_core_export([\"keras_core.ops.eye\", \"keras_core.ops.numpy.eye\"])\n def eye(N, M=None, k=0, dtype=\"float32\"):\n     return backend.numpy.eye(N, M=M, k=k, dtype=dtype)\n\n@@ -4,7 +4,7 @@ from tensorflow.python.ops.numpy_ops import np_config\n from keras_core import backend\n from keras_core import testing\n from keras_core.backend.common.keras_tensor import KerasTensor\n-from keras_core.operations import numpy as knp\n+from keras_core.ops import numpy as knp\n \n # TODO: remove reliance on this (or alternatively, turn it on by default).\n np_config.enable_numpy_behavior()\n\n@@ -6,7 +6,7 @@ from tensorflow import nest\n from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.backend.common.keras_tensor import any_symbolic_tensors\n-from keras_core.operations.node import Node\n+from keras_core.ops.node import Node\n from keras_core.utils import python_utils\n from keras_core.utils import traceback_utils\n from keras_core.utils.naming import auto_name\n\n@@ -3,8 +3,8 @@ import numpy as np\n from keras_core import backend\n from keras_core import testing\n from keras_core.backend.common import keras_tensor\n-from keras_core.operations import numpy as knp\n-from keras_core.operations import operation\n+from keras_core.ops import numpy as knp\n+from keras_core.ops import operation\n \n \n class OpWithMultipleInputs(operation.Operation):\n\n\n@@ -1,7 +1,7 @@\n from keras_core import backend\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import testing\n-from keras_core.operations import operation_utils\n+from keras_core.ops import operation_utils\n \n \n class OperationUtilsTest(testing.TestCase):\n\n\n@@ -1,4 +1,4 @@\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.optimizers import optimizer\n \n\n@@ -1,5 +1,5 @@\n from keras_core import backend\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.optimizers import optimizer\n \n\n@@ -1,5 +1,5 @@\n from keras_core import initializers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.optimizers import optimizer\n \n\n@@ -1,4 +1,4 @@\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.optimizers import optimizer\n \n\n@@ -1,4 +1,4 @@\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.optimizers import optimizer\n \n\n@@ -1,4 +1,4 @@\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.optimizers import optimizer\n \n\n@@ -5,7 +5,7 @@ import numpy as np\n \n from keras_core import backend\n from keras_core import initializers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.optimizers.schedules import learning_rate_schedule\n from keras_core.saving import serialization_lib\n from keras_core.utils import tracking\n\n@@ -1,5 +1,5 @@\n from keras_core import initializers\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.optimizers import optimizer\n \n\n@@ -1,5 +1,5 @@\n from keras_core import backend\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.optimizers import optimizer\n \n\n@@ -1,4 +1,4 @@\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.optimizers import optimizer\n \n\n@@ -2,7 +2,7 @@\n \n import math\n \n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.saving import serialization_lib\n \n\n@@ -1,4 +1,4 @@\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.optimizers import optimizer\n \n\n@@ -3,7 +3,7 @@\n import numpy as np\n \n from keras_core import backend\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import testing\n from keras_core.optimizers.sgd import SGD\n \n\n@@ -5,7 +5,7 @@ from absl.testing import parameterized\n import keras_core\n from keras_core import backend\n from keras_core import testing\n-from keras_core.operations import numpy as knp\n+from keras_core.ops import numpy as knp\n from keras_core.random import random\n \n \n\n@@ -1,6 +1,6 @@\n import math\n \n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.utils.numerical_utils import normalize\n \n\n@@ -9,7 +9,7 @@ from unittest import mock\n import numpy as np\n \n import keras_core\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import testing\n from keras_core.saving import saving_lib\n \n\n@@ -5,7 +5,7 @@ import json\n import numpy as np\n \n import keras_core\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import testing\n from keras_core.saving import serialization_lib\n \n\n@@ -7,7 +7,7 @@ import numpy as np\n from tensorflow import nest\n \n from keras_core import backend\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import utils\n from keras_core.models import Model\n from keras_core.utils import traceback_utils\n\n@@ -3,7 +3,7 @@ from tensorflow import nest\n from keras_core import backend\n from keras_core import losses as losses_module\n from keras_core import metrics as metrics_module\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core.utils.naming import get_object_name\n \n \n\n@@ -3,7 +3,7 @@ import warnings\n \n from keras_core import backend\n from keras_core import metrics as metrics_module\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import optimizers\n from keras_core.saving import serialization_lib\n from keras_core.trainers.compile_utils import CompileLoss\n\n@@ -8,7 +8,7 @@ from keras_core import initializers\n from keras_core import layers\n from keras_core import losses\n from keras_core import metrics\n-from keras_core import operations as ops\n+from keras_core import ops\n from keras_core import optimizers\n from keras_core import testing\n from keras_core.callbacks.callback import Callback\n\n@@ -1,5 +1,5 @@\n from keras_core import backend\n-from keras_core import operations as ops\n+from keras_core import ops\n \n \n def dtype_size(dtype):\n\n@@ -201,7 +201,7 @@ def model_to_dot(\n         a `pydot.Cluster` instance representing nested model if\n         `subgraph=True`.\n     \"\"\"\n-    from keras_core.operations.function import make_node_key\n+    from keras_core.ops.function import make_node_key\n \n     if not model.built:\n         raise ValueError(\n\n@@ -19,7 +19,7 @@ def normalize(x, axis=-1, order=2):\n     Returns:\n         A normalized copy of the array.\n     \"\"\"\n-    from keras_core import operations as ops\n+    from keras_core import ops\n \n     if not isinstance(order, int) or not order >= 1:\n         raise ValueError(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
