{"custom_id": "keras#a4e85547b2f85283aab53f35f84c77d026ab2102", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 99 | Lines Deleted: 17 | Files Changed: 4 | Hunks: 14 | Methods Changed: 9 | Complexity Δ (Sum/Max): 9/6 | Churn Δ: 116 | Churn Cumulative: 160 | Contributors (this commit): 3 | Commits (past 90d): 9 | Contributors (cumulative): 9 | DMM Complexity: 1.0\n\nDIFF:\n@@ -9,10 +9,7 @@ def accuracy(y_true, y_pred):\n     y_pred = ops.convert_to_tensor(y_pred)\n     y_true = ops.convert_to_tensor(y_true, dtype=y_pred.dtype)\n     y_true, y_pred = squeeze_or_expand_to_same_rank(y_true, y_pred)\n-    return ops.mean(\n-        ops.cast(ops.equal(y_true, y_pred), dtype=backend.floatx()),\n-        axis=-1,\n-    )\n+    return ops.cast(ops.equal(y_true, y_pred), dtype=backend.floatx())\n \n \n @keras_export(\"keras.metrics.Accuracy\")\n@@ -69,10 +66,7 @@ def binary_accuracy(y_true, y_pred, threshold=0.5):\n     y_true, y_pred = squeeze_or_expand_to_same_rank(y_true, y_pred)\n     threshold = ops.cast(threshold, y_pred.dtype)\n     y_pred = ops.cast(y_pred > threshold, y_true.dtype)\n-    return ops.mean(\n-        ops.cast(ops.equal(y_true, y_pred), dtype=backend.floatx()),\n-        axis=-1,\n-    )\n+    return ops.cast(ops.equal(y_true, y_pred), dtype=backend.floatx())\n \n \n @keras_export(\"keras.metrics.BinaryAccuracy\")\n\n@@ -41,6 +41,33 @@ class AccuracyTest(testing.TestCase):\n         result = acc_obj.result()\n         self.assertAllClose(result, 0.5, atol=1e-3)\n \n+    def test_weighted_rank_1(self):\n+        acc_obj = accuracy_metrics.Accuracy(name=\"accuracy\", dtype=\"float32\")\n+        y_true = np.array([1, 2, 3, 4])\n+        y_pred = np.array([0, 2, 3, 4])\n+        sample_weight = np.array([1, 1, 0, 0])\n+        acc_obj.update_state(y_true, y_pred, sample_weight=sample_weight)\n+        result = acc_obj.result()\n+        self.assertAllClose(result, 0.5, atol=1e-3)\n+\n+    def test_weighted_nd_weights(self):\n+        acc_obj = accuracy_metrics.Accuracy(name=\"accuracy\", dtype=\"float32\")\n+        y_true = np.array([[1, 2], [3, 4]])\n+        y_pred = np.array([[0, 2], [3, 4]])\n+        sample_weight = np.array([[1, 0], [0, 1]])\n+        acc_obj.update_state(y_true, y_pred, sample_weight=sample_weight)\n+        result = acc_obj.result()\n+        self.assertAllClose(result, 0.5, atol=1e-3)\n+\n+    def test_weighted_nd_broadcast_weights(self):\n+        acc_obj = accuracy_metrics.Accuracy(name=\"accuracy\", dtype=\"float32\")\n+        y_true = np.array([[1, 2], [3, 4]])\n+        y_pred = np.array([[0, 2], [3, 4]])\n+        sample_weight = np.array([[1, 0]])\n+        acc_obj.update_state(y_true, y_pred, sample_weight=sample_weight)\n+        result = acc_obj.result()\n+        self.assertAllClose(result, 0.5, atol=1e-3)\n+\n \n class BinaryAccuracyTest(testing.TestCase):\n     def test_config(self):\n@@ -95,6 +122,39 @@ class BinaryAccuracyTest(testing.TestCase):\n         result = bin_acc_obj.result()\n         self.assertAllClose(result, 0.5, atol=1e-3)\n \n+    def test_weighted_rank_1(self):\n+        bin_acc_obj = accuracy_metrics.BinaryAccuracy(\n+            name=\"binary_accuracy\", dtype=\"float32\"\n+        )\n+        y_true = np.array([1, 1, 0, 0])\n+        y_pred = np.array([0.98, 1, 0, 0.6])\n+        sample_weight = np.array([1, 0, 0, 1])\n+        bin_acc_obj.update_state(y_true, y_pred, sample_weight=sample_weight)\n+        result = bin_acc_obj.result()\n+        self.assertAllClose(result, 0.5, atol=1e-3)\n+\n+    def test_weighted_nd_weights(self):\n+        bin_acc_obj = accuracy_metrics.BinaryAccuracy(\n+            name=\"binary_accuracy\", dtype=\"float32\"\n+        )\n+        y_true = np.array([[1, 1], [0, 0]])\n+        y_pred = np.array([[0.98, 1], [0, 0.6]])\n+        sample_weight = np.array([[1, 0], [0, 1]])\n+        bin_acc_obj.update_state(y_true, y_pred, sample_weight=sample_weight)\n+        result = bin_acc_obj.result()\n+        self.assertAllClose(result, 0.5, atol=1e-3)\n+\n+    def test_weighted_nd_broadcast_weights(self):\n+        bin_acc_obj = accuracy_metrics.BinaryAccuracy(\n+            name=\"binary_accuracy\", dtype=\"float32\"\n+        )\n+        y_true = np.array([[1, 1], [0, 0]])\n+        y_pred = np.array([[0.98, 1], [0, 0.6]])\n+        sample_weight = np.array([[1, 0]])\n+        bin_acc_obj.update_state(y_true, y_pred, sample_weight=sample_weight)\n+        result = bin_acc_obj.result()\n+        self.assertAllClose(result, 1.0, atol=1e-3)\n+\n     def test_threshold(self):\n         bin_acc_obj_1 = accuracy_metrics.BinaryAccuracy(\n             name=\"binary_accuracy\", dtype=\"float32\", threshold=0.3\n\n@@ -22,15 +22,18 @@ def reduce_to_samplewise_values(values, sample_weight, reduce_fn, dtype):\n         values, sample_weight = losses.loss.squeeze_or_expand_to_same_rank(\n             values, sample_weight\n         )\n-        # Reduce values to same ndim as weight array\n+        # Reduce values to same ndim as weight array.\n         weight_ndim = len(sample_weight.shape)\n         values_ndim = len(values.shape)\n         if values_ndim > weight_ndim:\n             values = reduce_fn(\n                 values, axis=list(range(weight_ndim, values_ndim))\n             )\n+        # Broadcast sample_weight. It doesn't change the multiplication below\n+        # but changes the sample_weight reduction applied later.\n+        sample_weight = ops.broadcast_to(sample_weight, values.shape)\n         values = values * sample_weight\n-        if values_ndim > 1:\n+        if weight_ndim > 1:\n             sample_weight = reduce_fn(\n                 sample_weight, axis=list(range(1, weight_ndim))\n             )\n@@ -39,7 +42,6 @@ def reduce_to_samplewise_values(values, sample_weight, reduce_fn, dtype):\n     if values_ndim > 1:\n         values = reduce_fn(values, axis=list(range(1, values_ndim)))\n     return values, sample_weight\n-    return values, sample_weight\n \n \n @keras_export(\"keras.metrics.Sum\")\n@@ -82,7 +84,7 @@ class Sum(Metric):\n         values, _ = reduce_to_samplewise_values(\n             values, sample_weight, reduce_fn=ops.sum, dtype=self.dtype\n         )\n-        self.total.assign(self.total + ops.sum(values))\n+        self.total.assign_add(ops.sum(values))\n \n     def reset_state(self):\n         self.total.assign(0.0)\n@@ -138,14 +140,14 @@ class Mean(Metric):\n         values, sample_weight = reduce_to_samplewise_values(\n             values, sample_weight, reduce_fn=ops.mean, dtype=self.dtype\n         )\n-        self.total.assign(self.total + ops.sum(values))\n-        if len(values.shape) >= 1:\n+        self.total.assign_add(ops.sum(values))\n+        if sample_weight is not None:\n+            num_samples = ops.sum(sample_weight)\n+        elif len(values.shape) >= 1:\n             num_samples = ops.shape(values)[0]\n         else:\n             num_samples = 1\n-        if sample_weight is not None:\n-            num_samples = ops.sum(sample_weight)\n-        self.count.assign(self.count + ops.cast(num_samples, dtype=self.dtype))\n+        self.count.assign_add(ops.cast(num_samples, dtype=self.dtype))\n \n     def reset_state(self):\n         self.total.assign(0.0)\n\n@@ -36,6 +36,12 @@ class SumTest(testing.TestCase):\n         result = sum_obj.result()\n         self.assertAllClose(result, 9.0, atol=1e-3)\n \n+    def test_weighted_nd_broadcast(self):\n+        sum_obj = reduction_metrics.Sum(name=\"sum\", dtype=\"float32\")\n+        sum_obj.update_state([[1, 3], [5, 7]], sample_weight=[[1, 0]])\n+        result = sum_obj.result()\n+        self.assertAllClose(result, 6.0, atol=1e-3)\n+\n \n class MeanTest(testing.TestCase):\n     def test_config(self):\n@@ -74,6 +80,12 @@ class MeanTest(testing.TestCase):\n         result = mean_obj.result()\n         self.assertAllClose(result, 3.0, atol=1e-3)\n \n+    def test_weighted_nd_broadcast(self):\n+        mean_obj = reduction_metrics.Mean(name=\"mean\", dtype=\"float32\")\n+        mean_obj.update_state([[1, 3], [5, 7]], sample_weight=[[1, 0]])\n+        result = mean_obj.result()\n+        self.assertAllClose(result, 3.0, atol=1e-3)\n+\n \n # How users would register a custom function or class to use with\n # MeanMetricWrapper.\n@@ -127,3 +139,17 @@ class MetricWrapperTest(testing.TestCase):\n         sample_weight = np.array([1.0, 1.5, 2.0, 2.5])\n         result = mse_obj(y_true, y_pred, sample_weight=sample_weight)\n         self.assertAllClose(0.54285, result, atol=1e-5)\n+\n+    def test_weighted_broadcast(self):\n+        mse_obj = reduction_metrics.MeanMetricWrapper(\n+            fn=mse, name=\"mse\", dtype=\"float32\"\n+        )\n+        y_true = np.array(\n+            [[0, 1, 0, 1, 0], [0, 0, 1, 1, 1], [1, 1, 1, 1, 0], [0, 0, 0, 0, 1]]\n+        )\n+        y_pred = np.array(\n+            [[0, 0, 1, 1, 0], [1, 1, 1, 1, 1], [0, 1, 0, 1, 0], [1, 1, 1, 1, 1]]\n+        )\n+        sample_weight = np.array([[1.0, 0.0, 0.5, 0.0, 1.0]])\n+        result = mse_obj(y_true, y_pred, sample_weight=sample_weight)\n+        self.assertAllClose(0.45, result, atol=1e-5)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#11be99a6b4ea050528ba1739cad8bf969e242d4c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 21 | Lines Deleted: 8 | Files Changed: 4 | Hunks: 9 | Methods Changed: 4 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 29 | Churn Cumulative: 382 | Contributors (this commit): 5 | Commits (past 90d): 25 | Contributors (cumulative): 11 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,3 +1,5 @@\n+import warnings\n+\n import numpy as np\n \n from keras.src import tree\n@@ -285,7 +287,21 @@ def unstack(x, num=None, axis=0):\n     return [x[i] for i in range(x.shape[0])]\n \n \n-def custom_gradient(fun):\n-    raise NotImplementedError(\n-        \"`custom_gradient` is not supported with numpy backend\"\n+class custom_gradient:\n+    \"\"\"Decorator for custom gradients.\n+\n+    Args:\n+        fun: Forward pass function.\n+    \"\"\"\n+\n+    def __init__(self, fun):\n+        warnings.warn(\n+            \"`custom_gradient` for the numpy backend acts as a pass-through to \"\n+            \"support the forward pass. No gradient computation or modification \"\n+            \"takes place.\"\n         )\n+        self.fun = fun\n+\n+    def __call__(self, *args, **kwargs):\n+        outputs, _ = self.fun(*args, **kwargs)\n+        return outputs\n\n@@ -65,6 +65,8 @@ def matmul(x1, x2):\n         dtype = \"int32\"\n     else:\n         dtype = dtypes.result_type(x1.dtype, x2.dtype)\n+    x1 = x1.astype(dtype)\n+    x2 = x2.astype(dtype)\n     return np.matmul(x1, x2).astype(dtype)\n \n \n\n@@ -334,7 +334,6 @@ class DenseTest(testing.TestCase, parameterized.TestCase):\n \n     # Test quantization-related (int8 and float8) methods\n \n-    @pytest.mark.requires_trainable_backend\n     def test_quantize_int8(self):\n         layer = layers.Dense(units=16)\n         layer.build((None, 8))\n@@ -764,7 +763,6 @@ class DenseTest(testing.TestCase, parameterized.TestCase):\n                 len(model.non_trainable_weights),\n             )\n \n-    @pytest.mark.requires_trainable_backend\n     def test_quantize_float8_inference(self):\n         config = dict(units=16)\n         layer = layers.Dense(**config)\n\n@@ -382,7 +382,6 @@ class EinsumDenseTest(testing.TestCase, parameterized.TestCase):\n \n     # Test quantization-related (int8 and float8) methods\n \n-    @pytest.mark.requires_trainable_backend\n     def test_quantize_int8(self):\n         layer = layers.EinsumDense(\n             equation=\"ab,bcd->acd\",\n@@ -471,7 +470,6 @@ class EinsumDenseTest(testing.TestCase, parameterized.TestCase):\n         (\"btd,ndh->btnh\", \"btd,ndh->btnh\", (None, 2, 8), (1, 2, 4)),\n         (\"btd,df->btf\", \"btd,df->btf\", (None, 4), (1, 2, 4)),\n     )\n-    @pytest.mark.requires_trainable_backend\n     def test_quantize_int8_with_specific_equations(\n         self, equation, output_shape, input_shape\n     ):\n@@ -903,7 +901,6 @@ class EinsumDenseTest(testing.TestCase, parameterized.TestCase):\n                 len(model.non_trainable_weights),\n             )\n \n-    @pytest.mark.requires_trainable_backend\n     def test_quantize_float8_inference(self):\n         config = dict(\n             equation=\"ab,bcd->acd\",\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#84b283e6200bcb051ed976782fbb2b123bf9b8fc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 82 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 2 | Methods Changed: 7 | Complexity Δ (Sum/Max): 15/15 | Churn Δ: 83 | Churn Cumulative: 238 | Contributors (this commit): 6 | Commits (past 90d): 15 | Contributors (cumulative): 11 | DMM Complexity: 1.0\n\nDIFF:\n@@ -507,7 +507,7 @@ class Layer(BackendLayer, Operation, KerasSaveable):\n             else:\n                 initializer = \"zeros\"\n         initializer = initializers.get(initializer)\n-        with self._open_name_scope():\n+        with backend.name_scope(self.name, caller=self):\n             variable = backend.Variable(\n                 initializer=initializer,\n                 shape=shape,\n\n@@ -993,3 +993,84 @@ class LayerTest(testing.TestCase):\n         layer = layers.Dense(2)\n         config = layer.get_config()\n         self.assertNotIn(\"activity_regularizer\", config)\n+\n+    def test_custom_layer_add_weight_in_init_name(self):\n+        class TrainingLayer(layers.Layer):\n+            def __init__(self):\n+                super().__init__()\n+                self.inner = InnerLayer()\n+\n+        class InnerLayer(layers.Layer):\n+            def __init__(self):\n+                super().__init__()\n+                self.var = self.add_weight(\n+                    shape=(1,),\n+                    name=\"inner\",\n+                )\n+                self.inner = InnerInnerLayer()\n+\n+        class InnerInnerLayer(layers.Layer):\n+            def __init__(self):\n+                super().__init__()\n+                self.var = self.add_weight(\n+                    shape=(1,),\n+                    name=\"inner\",\n+                )\n+\n+        layer = TrainingLayer()\n+        layer.build(None)\n+        self.assertEqual(len(layer.variables), 2)\n+        variable_paths = set(v.path for v in layer.variables)\n+        self.assertTrue(\"inner_layer/inner\" in variable_paths)\n+        self.assertTrue(\"inner_inner_layer/inner\" in variable_paths)\n+\n+    def test_custom_layer_add_weight_in_build_name(self):\n+        class TrainingLayer(layers.Layer):\n+            def __init__(self):\n+                super().__init__()\n+                self.inner = InnerLayer()\n+\n+            def call(self, input):\n+                return self.inner(input)\n+\n+        class InnerLayer(layers.Layer):\n+            def __init__(self):\n+                super().__init__()\n+                self.inner = InnerInnerLayer()\n+\n+            def build(self, _):\n+                self.var = self.add_weight(\n+                    shape=(1,),\n+                    name=\"inner\",\n+                )\n+\n+            def call(self, input):\n+                return self.var + self.inner(input)\n+\n+        class InnerInnerLayer(layers.Layer):\n+            def __init__(self):\n+                super().__init__()\n+\n+            def build(self, _):\n+                self.var = self.add_weight(\n+                    shape=(1,),\n+                    name=\"inner\",\n+                )\n+\n+            def call(self, input):\n+                return self.var + input\n+\n+        layer = TrainingLayer()\n+        output = layer(\n+            backend.KerasTensor(\n+                (4, 1),\n+            )\n+        )\n+        self.assertEqual(output.shape, (4, 1))\n+        self.assertEqual(len(layer.variables), 2)\n+        variable_paths = set(v.path for v in layer.variables)\n+        self.assertTrue(\"training_layer/inner_layer/inner\" in variable_paths)\n+        self.assertTrue(\n+            \"training_layer/inner_layer/inner_inner_layer/inner\"\n+            in variable_paths\n+        )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ec1e9bd10218aa42b2b7ad48f5dfb2e8969c8582", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 690 | Lines Deleted: 48 | Files Changed: 8 | Hunks: 42 | Methods Changed: 38 | Complexity Δ (Sum/Max): 70/16 | Churn Δ: 738 | Churn Cumulative: 3986 | Contributors (this commit): 4 | Commits (past 90d): 37 | Contributors (cumulative): 23 | DMM Complexity: 0.885593220338983\n\nDIFF:\n@@ -7,7 +7,9 @@ since your modifications would be overwritten.\n from keras.src.ops.image import affine_transform\n from keras.src.ops.image import crop_images\n from keras.src.ops.image import extract_patches\n+from keras.src.ops.image import hsv_to_rgb\n from keras.src.ops.image import map_coordinates\n from keras.src.ops.image import pad_images\n from keras.src.ops.image import resize\n from keras.src.ops.image import rgb_to_grayscale\n+from keras.src.ops.image import rgb_to_hsv\n\n@@ -7,7 +7,9 @@ since your modifications would be overwritten.\n from keras.src.ops.image import affine_transform\n from keras.src.ops.image import crop_images\n from keras.src.ops.image import extract_patches\n+from keras.src.ops.image import hsv_to_rgb\n from keras.src.ops.image import map_coordinates\n from keras.src.ops.image import pad_images\n from keras.src.ops.image import resize\n from keras.src.ops.image import rgb_to_grayscale\n+from keras.src.ops.image import rgb_to_hsv\n\n@@ -16,7 +16,6 @@ RESIZE_INTERPOLATIONS = (\n \n \n def rgb_to_grayscale(images, data_format=None):\n-    # return images\n     images = convert_to_tensor(images)\n     data_format = backend.standardize_data_format(data_format)\n     channels_axis = -1 if data_format == \"channels_last\" else -3\n@@ -29,7 +28,7 @@ def rgb_to_grayscale(images, data_format=None):\n     # Convert to floats\n     original_dtype = images.dtype\n     compute_dtype = backend.result_type(images.dtype, float)\n-    images = backend.cast(images, compute_dtype)\n+    images = images.astype(compute_dtype)\n \n     # Ref: tf.image.rgb_to_grayscale\n     rgb_weights = convert_to_tensor(\n@@ -37,7 +36,97 @@ def rgb_to_grayscale(images, data_format=None):\n     )\n     images = jnp.tensordot(images, rgb_weights, axes=(channels_axis, -1))\n     images = jnp.expand_dims(images, axis=channels_axis)\n-    return backend.cast(images, original_dtype)\n+    return images.astype(original_dtype)\n+\n+\n+def rgb_to_hsv(images, data_format=None):\n+    # Ref: dm_pix\n+    images = convert_to_tensor(images)\n+    dtype = images.dtype\n+    data_format = backend.standardize_data_format(data_format)\n+    channels_axis = -1 if data_format == \"channels_last\" else -3\n+    if len(images.shape) not in (3, 4):\n+        raise ValueError(\n+            \"Invalid images rank: expected rank 3 (single image) \"\n+            \"or rank 4 (batch of images). Received input with shape: \"\n+            f\"images.shape={images.shape}\"\n+        )\n+    if not backend.is_float_dtype(dtype):\n+        raise ValueError(\n+            \"Invalid images dtype: expected float dtype. \"\n+            f\"Received: images.dtype={backend.standardize_dtype(dtype)}\"\n+        )\n+    eps = jnp.finfo(dtype).eps\n+    images = jnp.where(jnp.abs(images) < eps, 0.0, images)\n+    red, green, blue = jnp.split(images, 3, channels_axis)\n+    red = jnp.squeeze(red, channels_axis)\n+    green = jnp.squeeze(green, channels_axis)\n+    blue = jnp.squeeze(blue, channels_axis)\n+\n+    def rgb_planes_to_hsv_planes(r, g, b):\n+        value = jnp.maximum(jnp.maximum(r, g), b)\n+        minimum = jnp.minimum(jnp.minimum(r, g), b)\n+        range_ = value - minimum\n+\n+        safe_value = jnp.where(value > 0, value, 1.0)\n+        safe_range = jnp.where(range_ > 0, range_, 1.0)\n+\n+        saturation = jnp.where(value > 0, range_ / safe_value, 0.0)\n+        norm = 1.0 / (6.0 * safe_range)\n+\n+        hue = jnp.where(\n+            value == g,\n+            norm * (b - r) + 2.0 / 6.0,\n+            norm * (r - g) + 4.0 / 6.0,\n+        )\n+        hue = jnp.where(value == r, norm * (g - b), hue)\n+        hue = jnp.where(range_ > 0, hue, 0.0) + (hue < 0.0).astype(hue.dtype)\n+        return hue, saturation, value\n+\n+    images = jnp.stack(\n+        rgb_planes_to_hsv_planes(red, green, blue), axis=channels_axis\n+    )\n+    return images\n+\n+\n+def hsv_to_rgb(images, data_format=None):\n+    # Ref: dm_pix\n+    images = convert_to_tensor(images)\n+    dtype = images.dtype\n+    data_format = backend.standardize_data_format(data_format)\n+    channels_axis = -1 if data_format == \"channels_last\" else -3\n+    if len(images.shape) not in (3, 4):\n+        raise ValueError(\n+            \"Invalid images rank: expected rank 3 (single image) \"\n+            \"or rank 4 (batch of images). Received input with shape: \"\n+            f\"images.shape={images.shape}\"\n+        )\n+    if not backend.is_float_dtype(dtype):\n+        raise ValueError(\n+            \"Invalid images dtype: expected float dtype. \"\n+            f\"Received: images.dtype={backend.standardize_dtype(dtype)}\"\n+        )\n+    hue, saturation, value = jnp.split(images, 3, channels_axis)\n+    hue = jnp.squeeze(hue, channels_axis)\n+    saturation = jnp.squeeze(saturation, channels_axis)\n+    value = jnp.squeeze(value, channels_axis)\n+\n+    def hsv_planes_to_rgb_planes(hue, saturation, value):\n+        dh = jnp.mod(hue, 1.0) * 6.0\n+        dr = jnp.clip(jnp.abs(dh - 3.0) - 1.0, 0.0, 1.0)\n+        dg = jnp.clip(2.0 - jnp.abs(dh - 2.0), 0.0, 1.0)\n+        db = jnp.clip(2.0 - jnp.abs(dh - 4.0), 0.0, 1.0)\n+        one_minus_s = 1.0 - saturation\n+\n+        red = value * (one_minus_s + saturation * dr)\n+        green = value * (one_minus_s + saturation * dg)\n+        blue = value * (one_minus_s + saturation * db)\n+        return red, green, blue\n+\n+    images = jnp.stack(\n+        hsv_planes_to_rgb_planes(hue, saturation, value), axis=channels_axis\n+    )\n+    return images\n \n \n def resize(\n\n@@ -36,6 +36,96 @@ def rgb_to_grayscale(images, data_format=None):\n     return grayscales.astype(original_dtype)\n \n \n+def rgb_to_hsv(images, data_format=None):\n+    # Ref: dm_pix\n+    images = convert_to_tensor(images)\n+    dtype = images.dtype\n+    data_format = backend.standardize_data_format(data_format)\n+    channels_axis = -1 if data_format == \"channels_last\" else -3\n+    if len(images.shape) not in (3, 4):\n+        raise ValueError(\n+            \"Invalid images rank: expected rank 3 (single image) \"\n+            \"or rank 4 (batch of images). Received input with shape: \"\n+            f\"images.shape={images.shape}\"\n+        )\n+    if not backend.is_float_dtype(dtype):\n+        raise ValueError(\n+            \"Invalid images dtype: expected float dtype. \"\n+            f\"Received: images.dtype={backend.standardize_dtype(dtype)}\"\n+        )\n+    eps = np.finfo(dtype).eps\n+    images = np.where(np.abs(images) < eps, 0.0, images)\n+    red, green, blue = np.split(images, 3, channels_axis)\n+    red = np.squeeze(red, channels_axis)\n+    green = np.squeeze(green, channels_axis)\n+    blue = np.squeeze(blue, channels_axis)\n+\n+    def rgb_planes_to_hsv_planes(r, g, b):\n+        value = np.maximum(np.maximum(r, g), b)\n+        minimum = np.minimum(np.minimum(r, g), b)\n+        range_ = value - minimum\n+\n+        safe_value = np.where(value > 0, value, 1.0)\n+        safe_range = np.where(range_ > 0, range_, 1.0)\n+\n+        saturation = np.where(value > 0, range_ / safe_value, 0.0)\n+        norm = 1.0 / (6.0 * safe_range)\n+\n+        hue = np.where(\n+            value == g,\n+            norm * (b - r) + 2.0 / 6.0,\n+            norm * (r - g) + 4.0 / 6.0,\n+        )\n+        hue = np.where(value == r, norm * (g - b), hue)\n+        hue = np.where(range_ > 0, hue, 0.0) + (hue < 0.0).astype(hue.dtype)\n+        return hue, saturation, value\n+\n+    images = np.stack(\n+        rgb_planes_to_hsv_planes(red, green, blue), axis=channels_axis\n+    )\n+    return images.astype(dtype)\n+\n+\n+def hsv_to_rgb(images, data_format=None):\n+    # Ref: dm_pix\n+    images = convert_to_tensor(images)\n+    dtype = images.dtype\n+    data_format = backend.standardize_data_format(data_format)\n+    channels_axis = -1 if data_format == \"channels_last\" else -3\n+    if len(images.shape) not in (3, 4):\n+        raise ValueError(\n+            \"Invalid images rank: expected rank 3 (single image) \"\n+            \"or rank 4 (batch of images). Received input with shape: \"\n+            f\"images.shape={images.shape}\"\n+        )\n+    if not backend.is_float_dtype(dtype):\n+        raise ValueError(\n+            \"Invalid images dtype: expected float dtype. \"\n+            f\"Received: images.dtype={backend.standardize_dtype(dtype)}\"\n+        )\n+    hue, saturation, value = np.split(images, 3, channels_axis)\n+    hue = np.squeeze(hue, channels_axis)\n+    saturation = np.squeeze(saturation, channels_axis)\n+    value = np.squeeze(value, channels_axis)\n+\n+    def hsv_planes_to_rgb_planes(hue, saturation, value):\n+        dh = np.mod(hue, 1.0) * 6.0\n+        dr = np.clip(np.abs(dh - 3.0) - 1.0, 0.0, 1.0)\n+        dg = np.clip(2.0 - np.abs(dh - 2.0), 0.0, 1.0)\n+        db = np.clip(2.0 - np.abs(dh - 4.0), 0.0, 1.0)\n+        one_minus_s = 1.0 - saturation\n+\n+        red = value * (one_minus_s + saturation * dr)\n+        green = value * (one_minus_s + saturation * dg)\n+        blue = value * (one_minus_s + saturation * db)\n+        return red, green, blue\n+\n+    images = np.stack(\n+        hsv_planes_to_rgb_planes(hue, saturation, value), axis=channels_axis\n+    )\n+    return images.astype(dtype)\n+\n+\n def resize(\n     images,\n     size,\n\n@@ -29,7 +29,7 @@ def rgb_to_grayscale(images, data_format=None):\n     # Convert to floats\n     original_dtype = images.dtype\n     compute_dtype = backend.result_type(images.dtype, float)\n-    images = backend.cast(images, compute_dtype)\n+    images = tf.cast(images, compute_dtype)\n \n     # Ref: tf.image.rgb_to_grayscale\n     rgb_weights = convert_to_tensor(\n@@ -40,6 +40,64 @@ def rgb_to_grayscale(images, data_format=None):\n     return tf.cast(images, original_dtype)\n \n \n+def rgb_to_hsv(images, data_format=None):\n+    images = convert_to_tensor(images)\n+    dtype = images.dtype\n+    data_format = backend.standardize_data_format(data_format)\n+    if len(images.shape) not in (3, 4):\n+        raise ValueError(\n+            \"Invalid images rank: expected rank 3 (single image) \"\n+            \"or rank 4 (batch of images). Received input with shape: \"\n+            f\"images.shape={images.shape}\"\n+        )\n+    if not backend.is_float_dtype(dtype):\n+        raise ValueError(\n+            \"Invalid images dtype: expected float dtype. \"\n+            f\"Received: images.dtype={backend.standardize_dtype(dtype)}\"\n+        )\n+    if data_format == \"channels_first\":\n+        if len(images.shape) == 4:\n+            images = tf.transpose(images, (0, 2, 3, 1))\n+        else:\n+            images = tf.transpose(images, (1, 2, 0))\n+    images = tf.image.rgb_to_hsv(images)\n+    if data_format == \"channels_first\":\n+        if len(images.shape) == 4:\n+            images = tf.transpose(images, (0, 3, 1, 2))\n+        elif len(images.shape) == 3:\n+            images = tf.transpose(images, (2, 0, 1))\n+    return images\n+\n+\n+def hsv_to_rgb(images, data_format=None):\n+    images = convert_to_tensor(images)\n+    dtype = images.dtype\n+    data_format = backend.standardize_data_format(data_format)\n+    if len(images.shape) not in (3, 4):\n+        raise ValueError(\n+            \"Invalid images rank: expected rank 3 (single image) \"\n+            \"or rank 4 (batch of images). Received input with shape: \"\n+            f\"images.shape={images.shape}\"\n+        )\n+    if not backend.is_float_dtype(dtype):\n+        raise ValueError(\n+            \"Invalid images dtype: expected float dtype. \"\n+            f\"Received: images.dtype={backend.standardize_dtype(dtype)}\"\n+        )\n+    if data_format == \"channels_first\":\n+        if len(images.shape) == 4:\n+            images = tf.transpose(images, (0, 2, 3, 1))\n+        else:\n+            images = tf.transpose(images, (1, 2, 0))\n+    images = tf.image.hsv_to_rgb(images)\n+    if data_format == \"channels_first\":\n+        if len(images.shape) == 4:\n+            images = tf.transpose(images, (0, 3, 1, 2))\n+        elif len(images.shape) == 3:\n+            images = tf.transpose(images, (2, 0, 1))\n+    return images\n+\n+\n def resize(\n     images,\n     size,\n\n@@ -39,6 +39,96 @@ def rgb_to_grayscale(images, data_format=None):\n     return images\n \n \n+def rgb_to_hsv(images, data_format=None):\n+    # Ref: dm_pix\n+    images = convert_to_tensor(images)\n+    dtype = images.dtype\n+    data_format = backend.standardize_data_format(data_format)\n+    channels_axis = -1 if data_format == \"channels_last\" else -3\n+    if len(images.shape) not in (3, 4):\n+        raise ValueError(\n+            \"Invalid images rank: expected rank 3 (single image) \"\n+            \"or rank 4 (batch of images). Received input with shape: \"\n+            f\"images.shape={images.shape}\"\n+        )\n+    if not backend.is_float_dtype(dtype):\n+        raise ValueError(\n+            \"Invalid images dtype: expected float dtype. \"\n+            f\"Received: images.dtype={backend.standardize_dtype(dtype)}\"\n+        )\n+    eps = torch.finfo(dtype).eps\n+    images = torch.where(torch.abs(images) < eps, 0.0, images)\n+    red, green, blue = torch.split(images, [1, 1, 1], channels_axis)\n+    red = torch.squeeze(red, channels_axis)\n+    green = torch.squeeze(green, channels_axis)\n+    blue = torch.squeeze(blue, channels_axis)\n+\n+    def rgb_planes_to_hsv_planes(r, g, b):\n+        value = torch.maximum(torch.maximum(r, g), b)\n+        minimum = torch.minimum(torch.minimum(r, g), b)\n+        range_ = value - minimum\n+\n+        safe_value = torch.where(value > 0, value, 1.0)\n+        safe_range = torch.where(range_ > 0, range_, 1.0)\n+\n+        saturation = torch.where(value > 0, range_ / safe_value, 0.0)\n+        norm = 1.0 / (6.0 * safe_range)\n+\n+        hue = torch.where(\n+            value == g,\n+            norm * (b - r) + 2.0 / 6.0,\n+            norm * (r - g) + 4.0 / 6.0,\n+        )\n+        hue = torch.where(value == r, norm * (g - b), hue)\n+        hue = torch.where(range_ > 0, hue, 0.0) + (hue < 0.0).to(hue.dtype)\n+        return hue, saturation, value\n+\n+    images = torch.stack(\n+        rgb_planes_to_hsv_planes(red, green, blue), axis=channels_axis\n+    )\n+    return images\n+\n+\n+def hsv_to_rgb(images, data_format=None):\n+    # Ref: dm_pix\n+    images = convert_to_tensor(images)\n+    dtype = images.dtype\n+    data_format = backend.standardize_data_format(data_format)\n+    channels_axis = -1 if data_format == \"channels_last\" else -3\n+    if len(images.shape) not in (3, 4):\n+        raise ValueError(\n+            \"Invalid images rank: expected rank 3 (single image) \"\n+            \"or rank 4 (batch of images). Received input with shape: \"\n+            f\"images.shape={images.shape}\"\n+        )\n+    if not backend.is_float_dtype(dtype):\n+        raise ValueError(\n+            \"Invalid images dtype: expected float dtype. \"\n+            f\"Received: images.dtype={backend.standardize_dtype(dtype)}\"\n+        )\n+    hue, saturation, value = torch.split(images, [1, 1, 1], channels_axis)\n+    hue = torch.squeeze(hue, channels_axis)\n+    saturation = torch.squeeze(saturation, channels_axis)\n+    value = torch.squeeze(value, channels_axis)\n+\n+    def hsv_planes_to_rgb_planes(hue, saturation, value):\n+        dh = torch.remainder(hue, 1.0) * 6.0\n+        dr = torch.clip(torch.abs(dh - 3.0) - 1.0, 0.0, 1.0)\n+        dg = torch.clip(2.0 - torch.abs(dh - 2.0), 0.0, 1.0)\n+        db = torch.clip(2.0 - torch.abs(dh - 4.0), 0.0, 1.0)\n+        one_minus_s = 1.0 - saturation\n+\n+        red = value * (one_minus_s + saturation * dr)\n+        green = value * (one_minus_s + saturation * dg)\n+        blue = value * (one_minus_s + saturation * db)\n+        return red, green, blue\n+\n+    images = torch.stack(\n+        hsv_planes_to_rgb_planes(hue, saturation, value), axis=channels_axis\n+    )\n+    return images\n+\n+\n def resize(\n     images,\n     size,\n\n@@ -37,7 +37,7 @@ def rgb_to_grayscale(images, data_format=None):\n     \"\"\"Convert RGB images to grayscale.\n \n     This function converts RGB images to grayscale images. It supports both\n-    3D and 4D tensors, where the last dimension represents channels.\n+    3D and 4D tensors.\n \n     Args:\n         images: Input image or batch of images. Must be 3D or 4D.\n@@ -46,8 +46,8 @@ def rgb_to_grayscale(images, data_format=None):\n             `\"channels_last\"` corresponds to inputs with shape\n             `(batch, height, width, channels)`, while `\"channels_first\"`\n             corresponds to inputs with shape `(batch, channels, height, width)`.\n-            If not specified, the value will be interpreted by\n-            `keras.config.image_data_format`. Defaults to `None`.\n+            If not specified, the value will default to\n+            `keras.config.image_data_format`.\n \n     Returns:\n         Grayscale image or batch of grayscale images.\n@@ -55,7 +55,7 @@ def rgb_to_grayscale(images, data_format=None):\n     Examples:\n \n     >>> import numpy as np\n-    >>> from keras.src import ops\n+    >>> from keras import ops\n     >>> x = np.random.random((2, 4, 4, 3))\n     >>> y = ops.image.rgb_to_grayscale(x)\n     >>> y.shape\n@@ -76,6 +76,147 @@ def rgb_to_grayscale(images, data_format=None):\n     return backend.image.rgb_to_grayscale(images, data_format=data_format)\n \n \n+class RGBToHSV(Operation):\n+    def __init__(self, data_format=None):\n+        super().__init__()\n+        self.data_format = backend.standardize_data_format(data_format)\n+\n+    def call(self, images):\n+        return backend.image.rgb_to_hsv(images, data_format=self.data_format)\n+\n+    def compute_output_spec(self, images):\n+        images_shape = list(images.shape)\n+        dtype = images.dtype\n+        if len(images_shape) not in (3, 4):\n+            raise ValueError(\n+                \"Invalid images rank: expected rank 3 (single image) \"\n+                \"or rank 4 (batch of images). \"\n+                f\"Received: images.shape={images_shape}\"\n+            )\n+        if not backend.is_float_dtype(dtype):\n+            raise ValueError(\n+                \"Invalid images dtype: expected float dtype. \"\n+                f\"Received: images.dtype={dtype}\"\n+            )\n+        return KerasTensor(shape=images_shape, dtype=images.dtype)\n+\n+\n+@keras_export(\"keras.ops.image.rgb_to_hsv\")\n+def rgb_to_hsv(images, data_format=None):\n+    \"\"\"Convert RGB images to HSV.\n+\n+    `images` must be of float dtype, and the output is only well defined if the\n+    values in `images` are in `[0, 1]`.\n+\n+    All HSV values are in `[0, 1]`. A hue of `0` corresponds to pure red, `1/3`\n+    is pure green, and `2/3` is pure blue.\n+\n+    Args:\n+        images: Input image or batch of images. Must be 3D or 4D.\n+        data_format: A string specifying the data format of the input tensor.\n+            It can be either `\"channels_last\"` or `\"channels_first\"`.\n+            `\"channels_last\"` corresponds to inputs with shape\n+            `(batch, height, width, channels)`, while `\"channels_first\"`\n+            corresponds to inputs with shape `(batch, channels, height, width)`.\n+            If not specified, the value will default to\n+            `keras.config.image_data_format`.\n+\n+    Returns:\n+        HSV image or batch of HSV images.\n+\n+    Examples:\n+\n+    >>> import numpy as np\n+    >>> from keras import ops\n+    >>> x = np.random.random((2, 4, 4, 3))\n+    >>> y = ops.image.rgb_to_hsv(x)\n+    >>> y.shape\n+    (2, 4, 4, 3)\n+\n+    >>> x = np.random.random((4, 4, 3)) # Single RGB image\n+    >>> y = ops.image.rgb_to_hsv(x)\n+    >>> y.shape\n+    (4, 4, 3)\n+\n+    >>> x = np.random.random((2, 3, 4, 4))\n+    >>> y = ops.image.rgb_to_hsv(x, data_format=\"channels_first\")\n+    >>> y.shape\n+    (2, 3, 4, 4)\n+    \"\"\"\n+    if any_symbolic_tensors((images,)):\n+        return RGBToHSV(data_format=data_format).symbolic_call(images)\n+    return backend.image.rgb_to_hsv(images, data_format=data_format)\n+\n+\n+class HSVToRGB(Operation):\n+    def __init__(self, data_format=None):\n+        super().__init__()\n+        self.data_format = backend.standardize_data_format(data_format)\n+\n+    def call(self, images):\n+        return backend.image.hsv_to_rgb(images, data_format=self.data_format)\n+\n+    def compute_output_spec(self, images):\n+        images_shape = list(images.shape)\n+        dtype = images.dtype\n+        if len(images_shape) not in (3, 4):\n+            raise ValueError(\n+                \"Invalid images rank: expected rank 3 (single image) \"\n+                \"or rank 4 (batch of images). \"\n+                f\"Received: images.shape={images_shape}\"\n+            )\n+        if not backend.is_float_dtype(dtype):\n+            raise ValueError(\n+                \"Invalid images dtype: expected float dtype. \"\n+                f\"Received: images.dtype={dtype}\"\n+            )\n+        return KerasTensor(shape=images_shape, dtype=images.dtype)\n+\n+\n+@keras_export(\"keras.ops.image.hsv_to_rgb\")\n+def hsv_to_rgb(images, data_format=None):\n+    \"\"\"Convert HSV images to RGB.\n+\n+    `images` must be of float dtype, and the output is only well defined if the\n+    values in `images` are in `[0, 1]`.\n+\n+    Args:\n+        images: Input image or batch of images. Must be 3D or 4D.\n+        data_format: A string specifying the data format of the input tensor.\n+            It can be either `\"channels_last\"` or `\"channels_first\"`.\n+            `\"channels_last\"` corresponds to inputs with shape\n+            `(batch, height, width, channels)`, while `\"channels_first\"`\n+            corresponds to inputs with shape `(batch, channels, height, width)`.\n+            If not specified, the value will default to\n+            `keras.config.image_data_format`.\n+\n+    Returns:\n+        RGB image or batch of RGB images.\n+\n+    Examples:\n+\n+    >>> import numpy as np\n+    >>> from keras import ops\n+    >>> x = np.random.random((2, 4, 4, 3))\n+    >>> y = ops.image.hsv_to_rgb(x)\n+    >>> y.shape\n+    (2, 4, 4, 3)\n+\n+    >>> x = np.random.random((4, 4, 3)) # Single HSV image\n+    >>> y = ops.image.hsv_to_rgb(x)\n+    >>> y.shape\n+    (4, 4, 3)\n+\n+    >>> x = np.random.random((2, 3, 4, 4))\n+    >>> y = ops.image.hsv_to_rgb(x, data_format=\"channels_first\")\n+    >>> y.shape\n+    (2, 3, 4, 4)\n+    \"\"\"\n+    if any_symbolic_tensors((images,)):\n+        return HSVToRGB(data_format=data_format).symbolic_call(images)\n+    return backend.image.hsv_to_rgb(images, data_format=data_format)\n+\n+\n class Resize(Operation):\n     def __init__(\n         self,\n@@ -170,8 +311,8 @@ def resize(\n             `\"channels_last\"` corresponds to inputs with shape\n             `(batch, height, width, channels)`, while `\"channels_first\"`\n             corresponds to inputs with shape `(batch, channels, height, width)`.\n-            If not specified, the value will be interpreted by\n-            `keras.config.image_data_format`. Defaults to `None`.\n+            If not specified, the value will default to\n+            `keras.config.image_data_format`.\n \n     Returns:\n         Resized image or batch of images.\n@@ -320,8 +461,8 @@ def affine_transform(\n             `\"channels_last\"` corresponds to inputs with shape\n             `(batch, height, width, channels)`, while `\"channels_first\"`\n             corresponds to inputs with shape `(batch, channels, height, width)`.\n-            If not specified, the value will be interpreted by\n-            `keras.config.image_data_format`. Defaults to `None`.\n+            If not specified, the value will default to\n+            `keras.config.image_data_format`.\n \n     Returns:\n         Applied affine transform image or batch of images.\n@@ -455,8 +596,8 @@ def extract_patches(\n             `\"channels_last\"` corresponds to inputs with shape\n             `(batch, height, width, channels)`, while `\"channels_first\"`\n             corresponds to inputs with shape `(batch, channels, height, width)`.\n-            If not specified, the value will be interpreted by\n-            `keras.config.image_data_format`. Defaults to `None`.\n+            If not specified, the value will default to\n+            `keras.config.image_data_format`.\n \n     Returns:\n         Extracted patches 3D (if not batched) or 4D (if batched)\n@@ -701,8 +842,8 @@ def pad_images(\n             `\"channels_last\"` corresponds to inputs with shape\n             `(batch, height, width, channels)`, while `\"channels_first\"`\n             corresponds to inputs with shape `(batch, channels, height, width)`.\n-            If not specified, the value will be interpreted by\n-            `keras.config.image_data_format`. Defaults to `None`.\n+            If not specified, the value will default to\n+            `keras.config.image_data_format`.\n \n     Returns:\n         Padded image or batch of images.\n@@ -927,8 +1068,8 @@ def crop_images(\n             `\"channels_last\"` corresponds to inputs with shape\n             `(batch, height, width, channels)`, while `\"channels_first\"`\n             corresponds to inputs with shape `(batch, channels, height, width)`.\n-            If not specified, the value will be interpreted by\n-            `keras.config.image_data_format`. Defaults to `None`.\n+            If not specified, the value will default to\n+            `keras.config.image_data_format`.\n \n     Returns:\n         Cropped image or batch of images.\n\n@@ -36,6 +36,30 @@ class ImageOpsDynamicShapeTest(testing.TestCase):\n         out = kimage.rgb_to_grayscale(x)\n         self.assertEqual(out.shape, (None, 1, 20, 20))\n \n+    def test_rgb_to_hsv(self):\n+        # Test channels_last\n+        x = KerasTensor([None, 20, 20, 3])\n+        out = kimage.rgb_to_hsv(x)\n+        self.assertEqual(out.shape, (None, 20, 20, 3))\n+\n+        # Test channels_first\n+        backend.set_image_data_format(\"channels_first\")\n+        x = KerasTensor([None, 3, 20, 20])\n+        out = kimage.rgb_to_hsv(x)\n+        self.assertEqual(out.shape, (None, 3, 20, 20))\n+\n+    def test_hsv_to_rgb(self):\n+        # Test channels_last\n+        x = KerasTensor([None, 20, 20, 3])\n+        out = kimage.hsv_to_rgb(x)\n+        self.assertEqual(out.shape, (None, 20, 20, 3))\n+\n+        # Test channels_first\n+        backend.set_image_data_format(\"channels_first\")\n+        x = KerasTensor([None, 3, 20, 20])\n+        out = kimage.hsv_to_rgb(x)\n+        self.assertEqual(out.shape, (None, 3, 20, 20))\n+\n     def test_resize(self):\n         # Test channels_last\n         x = KerasTensor([None, 20, 20, 3])\n@@ -163,6 +187,30 @@ class ImageOpsStaticShapeTest(testing.TestCase):\n         out = kimage.rgb_to_grayscale(x)\n         self.assertEqual(out.shape, (1, 20, 20))\n \n+    def test_rgb_to_hsv(self):\n+        # Test channels_last\n+        x = KerasTensor([20, 20, 3])\n+        out = kimage.rgb_to_hsv(x)\n+        self.assertEqual(out.shape, (20, 20, 3))\n+\n+        # Test channels_first\n+        backend.set_image_data_format(\"channels_first\")\n+        x = KerasTensor([3, 20, 20])\n+        out = kimage.rgb_to_hsv(x)\n+        self.assertEqual(out.shape, (3, 20, 20))\n+\n+    def test_hsv_to_rgb(self):\n+        # Test channels_last\n+        x = KerasTensor([20, 20, 3])\n+        out = kimage.hsv_to_rgb(x)\n+        self.assertEqual(out.shape, (20, 20, 3))\n+\n+        # Test channels_first\n+        backend.set_image_data_format(\"channels_first\")\n+        x = KerasTensor([3, 20, 20])\n+        out = kimage.hsv_to_rgb(x)\n+        self.assertEqual(out.shape, (3, 20, 20))\n+\n     def test_resize(self):\n         # Test channels_last\n         x = KerasTensor([20, 20, 3])\n@@ -358,13 +406,13 @@ class ImageOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         out = kimage.rgb_to_grayscale(x)\n         ref_out = tf.image.rgb_to_grayscale(x)\n         self.assertEqual(tuple(out.shape), tuple(ref_out.shape))\n-        self.assertAllClose(ref_out, out, atol=0.3)\n+        self.assertAllClose(ref_out, out)\n \n         x = np.random.random((2, 50, 50, 3)).astype(\"float32\") * 255\n         out = kimage.rgb_to_grayscale(x)\n         ref_out = tf.image.rgb_to_grayscale(x)\n         self.assertEqual(tuple(out.shape), tuple(ref_out.shape))\n-        self.assertAllClose(ref_out, out, atol=0.3)\n+        self.assertAllClose(ref_out, out)\n \n         # Test channels_first\n         backend.set_image_data_format(\"channels_first\")\n@@ -373,18 +421,86 @@ class ImageOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         ref_out = tf.image.rgb_to_grayscale(np.transpose(x, [1, 2, 0]))\n         ref_out = tf.transpose(ref_out, [2, 0, 1])\n         self.assertEqual(tuple(out.shape), tuple(ref_out.shape))\n-        self.assertAllClose(ref_out, out, atol=0.3)\n+        self.assertAllClose(ref_out, out)\n \n         x = np.random.random((2, 3, 50, 50)).astype(\"float32\") * 255\n         out = kimage.rgb_to_grayscale(x)\n         ref_out = tf.image.rgb_to_grayscale(np.transpose(x, [0, 2, 3, 1]))\n         ref_out = tf.transpose(ref_out, [0, 3, 1, 2])\n         self.assertEqual(tuple(out.shape), tuple(ref_out.shape))\n-        self.assertAllClose(ref_out, out, atol=0.3)\n+        self.assertAllClose(ref_out, out)\n \n         # Test class\n         out = kimage.RGBToGrayscale()(x)\n-        self.assertAllClose(ref_out, out, atol=0.3)\n+        self.assertAllClose(ref_out, out)\n+\n+    def test_rgb_to_hsv(self):\n+        # Test channels_last\n+        x = np.random.random((50, 50, 3)).astype(\"float32\")\n+        out = kimage.rgb_to_hsv(x)\n+        ref_out = tf.image.rgb_to_hsv(x)\n+        self.assertEqual(tuple(out.shape), tuple(ref_out.shape))\n+        self.assertAllClose(ref_out, out)\n+\n+        x = np.random.random((2, 50, 50, 3)).astype(\"float32\")\n+        out = kimage.rgb_to_hsv(x)\n+        ref_out = tf.image.rgb_to_hsv(x)\n+        self.assertEqual(tuple(out.shape), tuple(ref_out.shape))\n+        self.assertAllClose(ref_out, out)\n+\n+        # Test channels_first\n+        backend.set_image_data_format(\"channels_first\")\n+        x = np.random.random((3, 50, 50)).astype(\"float32\")\n+        out = kimage.rgb_to_hsv(x)\n+        ref_out = tf.image.rgb_to_hsv(np.transpose(x, [1, 2, 0]))\n+        ref_out = tf.transpose(ref_out, [2, 0, 1])\n+        self.assertEqual(tuple(out.shape), tuple(ref_out.shape))\n+        self.assertAllClose(ref_out, out)\n+\n+        x = np.random.random((2, 3, 50, 50)).astype(\"float32\")\n+        out = kimage.rgb_to_hsv(x)\n+        ref_out = tf.image.rgb_to_hsv(np.transpose(x, [0, 2, 3, 1]))\n+        ref_out = tf.transpose(ref_out, [0, 3, 1, 2])\n+        self.assertEqual(tuple(out.shape), tuple(ref_out.shape))\n+        self.assertAllClose(ref_out, out)\n+\n+        # Test class\n+        out = kimage.RGBToHSV()(x)\n+        self.assertAllClose(ref_out, out)\n+\n+    def test_hsv_to_rgb(self):\n+        # Test channels_last\n+        x = np.random.random((50, 50, 3)).astype(\"float32\")\n+        out = kimage.hsv_to_rgb(x)\n+        ref_out = tf.image.hsv_to_rgb(x)\n+        self.assertEqual(tuple(out.shape), tuple(ref_out.shape))\n+        self.assertAllClose(ref_out, out)\n+\n+        x = np.random.random((2, 50, 50, 3)).astype(\"float32\")\n+        out = kimage.hsv_to_rgb(x)\n+        ref_out = tf.image.hsv_to_rgb(x)\n+        self.assertEqual(tuple(out.shape), tuple(ref_out.shape))\n+        self.assertAllClose(ref_out, out)\n+\n+        # Test channels_first\n+        backend.set_image_data_format(\"channels_first\")\n+        x = np.random.random((3, 50, 50)).astype(\"float32\")\n+        out = kimage.hsv_to_rgb(x)\n+        ref_out = tf.image.hsv_to_rgb(np.transpose(x, [1, 2, 0]))\n+        ref_out = tf.transpose(ref_out, [2, 0, 1])\n+        self.assertEqual(tuple(out.shape), tuple(ref_out.shape))\n+        self.assertAllClose(ref_out, out)\n+\n+        x = np.random.random((2, 3, 50, 50)).astype(\"float32\")\n+        out = kimage.hsv_to_rgb(x)\n+        ref_out = tf.image.hsv_to_rgb(np.transpose(x, [0, 2, 3, 1]))\n+        ref_out = tf.transpose(ref_out, [0, 3, 1, 2])\n+        self.assertEqual(tuple(out.shape), tuple(ref_out.shape))\n+        self.assertAllClose(ref_out, out)\n+\n+        # Test class\n+        out = kimage.HSVToRGB()(x)\n+        self.assertAllClose(ref_out, out)\n \n     @parameterized.named_parameters(\n         named_product(\n@@ -429,7 +545,7 @@ class ImageOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             antialias=antialias,\n         )\n         self.assertEqual(tuple(out.shape), tuple(ref_out.shape))\n-        self.assertAllClose(ref_out, out, atol=0.3)\n+        self.assertAllClose(ref_out, out, atol=1e-4)\n \n         x = np.random.random((2, 30, 30, 3)).astype(\"float32\") * 255\n         out = kimage.resize(\n@@ -445,7 +561,7 @@ class ImageOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             antialias=antialias,\n         )\n         self.assertEqual(tuple(out.shape), tuple(ref_out.shape))\n-        self.assertAllClose(ref_out, out, atol=0.3)\n+        self.assertAllClose(ref_out, out, atol=1e-4)\n \n         # Test channels_first\n         backend.set_image_data_format(\"channels_first\")\n@@ -464,7 +580,7 @@ class ImageOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         )\n         ref_out = tf.transpose(ref_out, [2, 0, 1])\n         self.assertEqual(tuple(out.shape), tuple(ref_out.shape))\n-        self.assertAllClose(ref_out, out, atol=0.3)\n+        self.assertAllClose(ref_out, out, atol=1e-4)\n \n         x = np.random.random((2, 3, 30, 30)).astype(\"float32\") * 255\n         out = kimage.resize(\n@@ -481,7 +597,7 @@ class ImageOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         )\n         ref_out = tf.transpose(ref_out, [0, 3, 1, 2])\n         self.assertEqual(tuple(out.shape), tuple(ref_out.shape))\n-        self.assertAllClose(ref_out, out, atol=0.3)\n+        self.assertAllClose(ref_out, out, atol=1e-4)\n \n         # Test class\n         out = kimage.Resize(\n@@ -489,7 +605,7 @@ class ImageOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             interpolation=interpolation,\n             antialias=antialias,\n         )(x)\n-        self.assertAllClose(ref_out, out, atol=0.3)\n+        self.assertAllClose(ref_out, out, atol=1e-4)\n \n     def test_resize_with_crop(self):\n         # Test channels_last\n@@ -708,7 +824,7 @@ class ImageOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             padding=padding.upper(),\n         )\n         self.assertEqual(tuple(patches_out.shape), tuple(patches_ref.shape))\n-        self.assertAllClose(patches_ref, patches_out, atol=0.3)\n+        self.assertAllClose(patches_ref, patches_out, atol=1e-2)\n \n         # Test channels_first\n         if backend.backend() == \"tensorflow\":\n@@ -733,7 +849,7 @@ class ImageOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         )\n         patches_ref = tf.transpose(patches_ref, [0, 3, 1, 2])\n         self.assertEqual(tuple(patches_out.shape), tuple(patches_ref.shape))\n-        self.assertAllClose(patches_ref, patches_out, atol=0.3)\n+        self.assertAllClose(patches_ref, patches_out, atol=1e-2)\n \n         # Test class\n         patches_out = kimage.ExtractPatches(\n@@ -742,7 +858,7 @@ class ImageOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             dilation_rate=dilation_rate,\n             padding=padding,\n         )(image)\n-        self.assertAllClose(patches_ref, patches_out, atol=0.3)\n+        self.assertAllClose(patches_ref, patches_out, atol=1e-2)\n \n     @parameterized.named_parameters(\n         named_product(\n@@ -941,7 +1057,7 @@ class ImageOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         self.assertAllClose(ref_cropped_image, cropped_image)\n \n \n-class ImageOpsBehaviorTests(testing.TestCase):\n+class ImageOpsBehaviorTests(testing.TestCase, parameterized.TestCase):\n     def setUp(self):\n         # Defaults to channels_last\n         self.data_format = backend.image_data_format()\n@@ -952,9 +1068,10 @@ class ImageOpsBehaviorTests(testing.TestCase):\n         backend.set_image_data_format(self.data_format)\n         return super().tearDown()\n \n-    def test_rgb_to_grayscale_invalid_rank(self):\n-        # Test rank=2\n-        invalid_image = np.random.uniform(size=(10, 10))\n+    @parameterized.named_parameters(named_product(rank=[2, 5]))\n+    def test_rgb_to_grayscale_invalid_rank(self, rank):\n+        shape = [3] * rank\n+        invalid_image = np.random.uniform(size=shape)\n         with self.assertRaisesRegex(\n             ValueError,\n             \"Invalid images rank: expected rank 3\",\n@@ -965,27 +1082,80 @@ class ImageOpsBehaviorTests(testing.TestCase):\n             \"Invalid images rank: expected rank 3\",\n         ):\n             kimage.RGBToGrayscale()(invalid_image)\n-\n-        # Test rank=5\n-        invalid_image = np.random.uniform(size=(2, 3, 10, 10, 3))\n+        invalid_image = KerasTensor(shape=shape)\n         with self.assertRaisesRegex(\n             ValueError,\n             \"Invalid images rank: expected rank 3\",\n         ):\n             kimage.rgb_to_grayscale(invalid_image)\n-        with self.assertRaisesRegex(\n-            ValueError,\n-            \"Invalid images rank: expected rank 3\",\n-        ):\n-            kimage.RGBToGrayscale()(invalid_image)\n \n-        # Test rank=2, symbolic tensor\n-        invalid_image = KerasTensor(shape=(10, 10))\n+    @parameterized.named_parameters(named_product(rank=[2, 5]))\n+    def test_rgb_to_hsv_invalid_rank(self, rank):\n+        shape = [3] * rank\n+        invalid_image = np.random.uniform(size=shape)\n         with self.assertRaisesRegex(\n-            ValueError,\n-            \"Invalid images rank: expected rank 3\",\n+            ValueError, \"Invalid images rank: expected rank 3\"\n         ):\n-            kimage.rgb_to_grayscale(invalid_image)\n+            kimage.rgb_to_hsv(invalid_image)\n+        with self.assertRaisesRegex(\n+            ValueError, \"Invalid images rank: expected rank 3\"\n+        ):\n+            kimage.RGBToHSV()(invalid_image)\n+        invalid_image = KerasTensor(shape=shape)\n+        with self.assertRaisesRegex(\n+            ValueError, \"Invalid images rank: expected rank 3\"\n+        ):\n+            kimage.rgb_to_hsv(invalid_image)\n+\n+    def test_rgb_to_hsv_invalid_dtype(self):\n+        invalid_image = np.random.uniform(size=(10, 10, 3)).astype(\"int32\")\n+        with self.assertRaisesRegex(\n+            ValueError, \"Invalid images dtype: expected float dtype.\"\n+        ):\n+            kimage.rgb_to_hsv(invalid_image)\n+        with self.assertRaisesRegex(\n+            ValueError, \"Invalid images dtype: expected float dtype.\"\n+        ):\n+            kimage.RGBToHSV()(invalid_image)\n+        invalid_image = KerasTensor(shape=(10, 10, 3), dtype=\"int32\")\n+        with self.assertRaisesRegex(\n+            ValueError, \"Invalid images dtype: expected float dtype.\"\n+        ):\n+            kimage.rgb_to_hsv(invalid_image)\n+\n+    @parameterized.named_parameters(named_product(rank=[2, 5]))\n+    def test_hsv_to_rgb_invalid_rank(self, rank):\n+        shape = [3] * rank\n+        invalid_image = np.random.uniform(size=shape)\n+        with self.assertRaisesRegex(\n+            ValueError, \"Invalid images rank: expected rank 3\"\n+        ):\n+            kimage.hsv_to_rgb(invalid_image)\n+        with self.assertRaisesRegex(\n+            ValueError, \"Invalid images rank: expected rank 3\"\n+        ):\n+            kimage.HSVToRGB()(invalid_image)\n+        invalid_image = KerasTensor(shape=shape)\n+        with self.assertRaisesRegex(\n+            ValueError, \"Invalid images rank: expected rank 3\"\n+        ):\n+            kimage.hsv_to_rgb(invalid_image)\n+\n+    def test_hsv_to_rgb_invalid_dtype(self):\n+        invalid_image = np.random.uniform(size=(10, 10, 3)).astype(\"int32\")\n+        with self.assertRaisesRegex(\n+            ValueError, \"Invalid images dtype: expected float dtype.\"\n+        ):\n+            kimage.hsv_to_rgb(invalid_image)\n+        with self.assertRaisesRegex(\n+            ValueError, \"Invalid images dtype: expected float dtype.\"\n+        ):\n+            kimage.HSVToRGB()(invalid_image)\n+        invalid_image = KerasTensor(shape=(10, 10, 3), dtype=\"int32\")\n+        with self.assertRaisesRegex(\n+            ValueError, \"Invalid images dtype: expected float dtype.\"\n+        ):\n+            kimage.hsv_to_rgb(invalid_image)\n \n     def test_resize_invalid_rank(self):\n         # Test rank=2\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
