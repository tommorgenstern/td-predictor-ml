{"custom_id": "keras#12ea236fc8c1fbc38a848f369e613f0625ccf956", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 15 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 16 | Churn Cumulative: 2626 | Contributors (this commit): 41 | Commits (past 90d): 14 | Contributors (cumulative): 41 | DMM Complexity: 1.0\n\nDIFF:\n@@ -717,7 +717,10 @@ class ImageDataGenerator(object):\n \n \n class Iterator(Sequence):\n-    \"\"\"Abstract base class for image data iterators.\n+    \"\"\"Base class for image data iterators.\n+\n+    Every `Iterator` must implement the `_get_batches_of_transformed_samples`\n+    method.\n \n     # Arguments\n         n: Integer, total number of samples in the dataset to loop over.\n@@ -792,6 +795,17 @@ class Iterator(Sequence):\n     def __next__(self, *args, **kwargs):\n         return self.next(*args, **kwargs)\n \n+    def _get_batches_of_transformed_samples(self, index_array):\n+        \"\"\"Gets a batch of transformed samples.\n+\n+        # Arguments\n+            index_array: array of sample indices to include in batch.\n+\n+        # Returns\n+            A batch of transformed samples.\n+        \"\"\"\n+        raise NotImplementedError\n+\n \n class NumpyArrayIterator(Iterator):\n     \"\"\"Iterator yielding data from a Numpy array.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7610c55bdc046ff0b0d6300af5ea9dcfd0a427cb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 21 | Files Changed: 2 | Hunks: 5 | Methods Changed: 3 | Complexity Δ (Sum/Max): -2/3 | Churn Δ: 28 | Churn Cumulative: 11011 | Contributors (this commit): 53 | Commits (past 90d): 4 | Contributors (cumulative): 59 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1217,7 +1217,8 @@ class SeparableConv2D(Conv2D):\n             self.pointwise_kernel,\n             data_format=self.data_format,\n             strides=self.strides,\n-            padding=self.padding)\n+            padding=self.padding,\n+            dilation_rate=self.dilation_rate)\n \n         if self.bias:\n             outputs = K.bias_add(\n@@ -1229,25 +1230,6 @@ class SeparableConv2D(Conv2D):\n             return self.activation(outputs)\n         return outputs\n \n-    def compute_output_shape(self, input_shape):\n-        if self.data_format == 'channels_first':\n-            rows = input_shape[2]\n-            cols = input_shape[3]\n-        elif self.data_format == 'channels_last':\n-            rows = input_shape[1]\n-            cols = input_shape[2]\n-\n-        rows = conv_utils.conv_output_length(rows, self.kernel_size[0],\n-                                             self.padding,\n-                                             self.strides[0])\n-        cols = conv_utils.conv_output_length(cols, self.kernel_size[1],\n-                                             self.padding,\n-                                             self.strides[1])\n-        if self.data_format == 'channels_first':\n-            return (input_shape[0], self.filters, rows, cols)\n-        elif self.data_format == 'channels_last':\n-            return (input_shape[0], rows, cols, self.filters)\n-\n     def get_config(self):\n         config = super(SeparableConv2D, self).get_config()\n         config.pop('kernel_initializer')\n\n@@ -241,15 +241,19 @@ def test_separable_conv_2d():\n     for padding in _convolution_paddings:\n         for strides in [(1, 1), (2, 2)]:\n             for multiplier in [1, 2]:\n+                for dilation_rate in [(1, 1), (2, 2), (2, 1), (1, 2)]:\n                     if padding == 'same' and strides != (1, 1):\n                         continue\n+                    if dilation_rate != (1, 1) and strides != (1, 1):\n+                        continue\n \n                     layer_test(convolutional.SeparableConv2D,\n                                kwargs={'filters': filters,\n                                        'kernel_size': (3, 3),\n                                        'padding': padding,\n                                        'strides': strides,\n-                                   'depth_multiplier': multiplier},\n+                                       'depth_multiplier': multiplier,\n+                                       'dilation_rate': dilation_rate},\n                                input_shape=(num_samples, num_row, num_col, stack_size))\n \n     layer_test(convolutional.SeparableConv2D,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f940d227a480de9be227498ad3b3950d3fc56f5d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 45 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 5 | Methods Changed: 7 | Complexity Δ (Sum/Max): 11/8 | Churn Δ: 46 | Churn Cumulative: 1375 | Contributors (this commit): 11 | Commits (past 90d): 11 | Contributors (cumulative): 15 | DMM Complexity: 0.21875\n\nDIFF:\n@@ -537,10 +537,13 @@ class OrderedEnqueuer(SequenceEnqueuer):\n class GeneratorEnqueuer(SequenceEnqueuer):\n     \"\"\"Builds a queue out of a data generator.\n \n+    The provided generator can be finite in which case the class will throw\n+    a `StopIteration` exception.\n+\n     Used in `fit_generator`, `evaluate_generator`, `predict_generator`.\n \n     # Arguments\n-        generator: a generator function which endlessly yields data\n+        generator: a generator function which yields data\n         use_multiprocessing: use multiprocessing if True, otherwise threading\n         wait_time: time to sleep in-between calls to `put()`\n         random_seed: Initial seed for workers,\n@@ -576,6 +579,8 @@ class GeneratorEnqueuer(SequenceEnqueuer):\n                         self.queue.put(generator_output)\n                     else:\n                         time.sleep(self.wait_time)\n+                except StopIteration:\n+                    break\n                 except Exception:\n                     self._stop_event.set()\n                     raise\n@@ -647,5 +652,9 @@ class GeneratorEnqueuer(SequenceEnqueuer):\n                 inputs = self.queue.get()\n                 if inputs is not None:\n                     yield inputs\n+            else:\n+                all_finished = all([not thread.is_alive() for thread in self._threads])\n+                if all_finished:\n+                    raise StopIteration()\n                 else:\n                     time.sleep(self.wait_time)\n\n@@ -245,5 +245,40 @@ def test_ordered_enqueuer_fail_processes():\n         next(gen_output)\n \n \n+@threadsafe_generator\n+def create_finite_generator_from_sequence_threads(ds):\n+    for i in range(len(ds)):\n+        yield ds[i]\n+\n+\n+def create_finite_generator_from_sequence_pcs(ds):\n+    for i in range(len(ds)):\n+        yield ds[i]\n+\n+\n+def test_finite_generator_enqueuer_threads():\n+    enqueuer = GeneratorEnqueuer(create_finite_generator_from_sequence_threads(\n+        TestSequence([3, 200, 200, 3])), use_multiprocessing=False)\n+    enqueuer.start(3, 10)\n+    gen_output = enqueuer.get()\n+    acc = []\n+    for output in gen_output:\n+        acc.append(int(output[0, 0, 0, 0]))\n+    assert len(set(acc) - set(range(100))) == 0, \"Output is not the same\"\n+    enqueuer.stop()\n+\n+\n+def test_finite_generator_enqueuer_processes():\n+    enqueuer = GeneratorEnqueuer(create_finite_generator_from_sequence_pcs(\n+        TestSequence([3, 200, 200, 3])), use_multiprocessing=True)\n+    enqueuer.start(3, 10)\n+    gen_output = enqueuer.get()\n+    acc = []\n+    for output in gen_output:\n+        acc.append(int(output[0, 0, 0, 0]))\n+    assert acc != list(range(100)), \"Order was keep in GeneratorEnqueuer with processes\"\n+    enqueuer.stop()\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f569c75b7dfd3d7ccc3510a8717fb4f63a603a7b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 31 | Lines Deleted: 26 | Files Changed: 1 | Hunks: 18 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 57 | Churn Cumulative: 565 | Contributors (this commit): 6 | Commits (past 90d): 3 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -29,12 +29,12 @@ Experiments\n - Net2WiderNet experiment:\n   + Student model has a wider Conv2D layer and a wider FC layer.\n   + Comparison of 'random-padding' vs 'net2wider' weight initialization.\n-  + With both methods, student model should immediately perform as well as\n+  + With both methods, after 1 epoch, student model should perform as well as\n     teacher model, but 'net2wider' is slightly better.\n - Net2DeeperNet experiment:\n   + Student model has an extra Conv2D layer and an extra FC layer.\n   + Comparison of 'random-init' vs 'net2deeper' weight initialization.\n-  + Starting performance of 'net2deeper' is better than 'random-init'.\n+  + After 1 epoch, performance of 'net2deeper' is better than 'random-init'.\n - Hyper-parameters:\n   + SGD with momentum=0.9 is used for training teacher and student models.\n   + Learning rate adjustment: it's suggested to reduce learning rate\n@@ -44,14 +44,19 @@ Experiments\n     when a Dropout layer is used.\n \n Results\n-- Tested with 'Theano' backend and 'channels_first' image_data_format.\n-- Running on GPU GeForce GTX 980M\n+- Tested with TF backend and 'channels_last' image_data_format.\n+- Running on GPU GeForce GTX Titan X Maxwell\n - Performance Comparisons - validation loss values during first 3 epochs:\n-(1) teacher_model:             0.075    0.041    0.041\n-(2) wider_random_pad:          0.036    0.034    0.032\n-(3) wider_net2wider:           0.032    0.030    0.030\n-(4) deeper_random_init:        0.061    0.043    0.041\n-(5) deeper_net2deeper:         0.032    0.031    0.029\n+\n+Experiment of Net2WiderNet ...\n+(1) teacher_model:             0.0537   0.0354   0.0356\n+(2) wider_random_pad:          0.0320   0.0317   0.0289\n+(3) wider_net2wider:           0.0271   0.0274   0.0270\n+\n+Experiment of Net2DeeperNet ...\n+(4) teacher_model:             0.0522   0.0386   0.0358\n+(5) deeper_random_init:        0.0682   0.0506   0.0468\n+(4) deeper_net2deeper:         0.0292   0.0294   0.0286\n '''\n \n from __future__ import print_function\n@@ -104,35 +109,35 @@ def wider2net_conv2d(teacher_w1, teacher_b1, teacher_w2, new_width, init):\n     '''\n     assert teacher_w1.shape[0] == teacher_w2.shape[1], (\n         'successive layers from teacher model should have compatible shapes')\n-    assert teacher_w1.shape[0] == teacher_b1.shape[0], (\n+    assert teacher_w1.shape[3] == teacher_b1.shape[0], (\n         'weight and bias from same layer should have compatible shapes')\n-    assert new_width > teacher_w1.shape[0], (\n+    assert new_width > teacher_w1.shape[3], (\n         'new width (filters) should be bigger than the existing one')\n \n-    n = new_width - teacher_w1.shape[0]\n+    n = new_width - teacher_w1.shape[3]\n     if init == 'random-pad':\n-        new_w1 = np.random.normal(0, 0.1, size=(n, ) + teacher_w1.shape[1:])\n+        new_w1 = np.random.normal(0, 0.1, size=teacher_w1.shape[:3] + (n,))\n         new_b1 = np.ones(n) * 0.1\n-        new_w2 = np.random.normal(0, 0.1, size=(\n-            teacher_w2.shape[0], n) + teacher_w2.shape[2:])\n+        new_w2 = np.random.normal(0, 0.1,\n+                                  size=teacher_w2.shape[:2] + (n, teacher_w2.shape[3]))\n     elif init == 'net2wider':\n-        index = np.random.randint(teacher_w1.shape[0], size=n)\n+        index = np.random.randint(teacher_w1.shape[3], size=n)\n         factors = np.bincount(index)[index] + 1.\n-        new_w1 = teacher_w1[index, :, :, :]\n+        new_w1 = teacher_w1[:, :, :, index]\n         new_b1 = teacher_b1[index]\n-        new_w2 = teacher_w2[:, index, :, :] / factors.reshape((1, -1, 1, 1))\n+        new_w2 = teacher_w2[:, :, index, :] / factors.reshape((1, 1, -1, 1))\n     else:\n         raise ValueError('Unsupported weight initializer: %s' % init)\n \n-    student_w1 = np.concatenate((teacher_w1, new_w1), axis=0)\n+    student_w1 = np.concatenate((teacher_w1, new_w1), axis=3)\n     if init == 'random-pad':\n-        student_w2 = np.concatenate((teacher_w2, new_w2), axis=1)\n+        student_w2 = np.concatenate((teacher_w2, new_w2), axis=2)\n     elif init == 'net2wider':\n         # add small noise to break symmetry, so that student model will have\n         # full capacity later\n         noise = np.random.normal(0, 5e-2 * new_w2.std(), size=new_w2.shape)\n-        student_w2 = np.concatenate((teacher_w2, new_w2 + noise), axis=1)\n-        student_w2[:, index, :, :] = new_w2\n+        student_w2 = np.concatenate((teacher_w2, new_w2 + noise), axis=2)\n+        student_w2[:, :, index, :] = new_w2\n     student_b1 = np.concatenate((teacher_b1, new_b1), axis=0)\n \n     return student_w1, student_b1, student_w2\n@@ -193,12 +198,12 @@ def deeper2net_conv2d(teacher_w):\n \n     # Arguments\n         teacher_w: `weight` of previous conv2d layer,\n-          of shape (filters, num_channel, kh, kw)\n+          of shape (kh, kw, num_channel, filters)\n     '''\n-    filters, num_channel, kh, kw = teacher_w.shape\n-    student_w = np.zeros((filters, filters, kh, kw))\n+    kh, kw, num_channel, filters = teacher_w.shape\n+    student_w = np.zeros_like(teacher_w)\n     for i in range(filters):\n-        student_w[i, i, (kh - 1) / 2, (kw - 1) / 2] = 1.\n+        student_w[(kh - 1) / 2, (kw - 1) / 2, i, i] = 1.\n     student_b = np.zeros(filters)\n     return student_w, student_b\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f2501c4db6a7699e6199316da27dc7407dacf4bd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 12 | Files Changed: 2 | Hunks: 7 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 24 | Churn Cumulative: 4191 | Contributors (this commit): 64 | Commits (past 90d): 18 | Contributors (cumulative): 81 | DMM Complexity: None\n\nDIFF:\n@@ -394,7 +394,7 @@ class ModelCheckpoint(Callback):\n         self.epochs_since_last_save += 1\n         if self.epochs_since_last_save >= self.period:\n             self.epochs_since_last_save = 0\n-            filepath = self.filepath.format(epoch=epoch, **logs)\n+            filepath = self.filepath.format(epoch=epoch + 1, **logs)\n             if self.save_best_only:\n                 current = logs.get(self.monitor)\n                 if current is None:\n@@ -405,7 +405,7 @@ class ModelCheckpoint(Callback):\n                         if self.verbose > 0:\n                             print('Epoch %05d: %s improved from %0.5f to %0.5f,'\n                                   ' saving model to %s'\n-                                  % (epoch, self.monitor, self.best,\n+                                  % (epoch + 1, self.monitor, self.best,\n                                      current, filepath))\n                         self.best = current\n                         if self.save_weights_only:\n@@ -415,10 +415,10 @@ class ModelCheckpoint(Callback):\n                     else:\n                         if self.verbose > 0:\n                             print('Epoch %05d: %s did not improve' %\n-                                  (epoch, self.monitor))\n+                                  (epoch + 1, self.monitor))\n             else:\n                 if self.verbose > 0:\n-                    print('Epoch %05d: saving model to %s' % (epoch, filepath))\n+                    print('Epoch %05d: saving model to %s' % (epoch + 1, filepath))\n                 if self.save_weights_only:\n                     self.model.save_weights(filepath, overwrite=True)\n                 else:\n@@ -504,7 +504,7 @@ class EarlyStopping(Callback):\n \n     def on_train_end(self, logs=None):\n         if self.stopped_epoch > 0 and self.verbose > 0:\n-            print('Epoch %05d: early stopping' % (self.stopped_epoch))\n+            print('Epoch %05d: early stopping' % (self.stopped_epoch + 1))\n \n \n class RemoteMonitor(Callback):\n@@ -905,7 +905,7 @@ class ReduceLROnPlateau(Callback):\n                         new_lr = max(new_lr, self.min_lr)\n                         K.set_value(self.model.optimizer.lr, new_lr)\n                         if self.verbose > 0:\n-                            print('\\nEpoch %05d: reducing learning rate to %s.' % (epoch, new_lr))\n+                            print('\\nEpoch %05d: reducing learning rate to %s.' % (epoch + 1, new_lr))\n                         self.cooldown_counter = self.cooldown\n                         self.wait = 0\n                 self.wait += 1\n\n@@ -193,12 +193,12 @@ def test_ModelCheckpoint(tmpdir):\n                                       period=period)]\n     model.fit(X_train, y_train, batch_size=batch_size,\n               validation_data=(X_test, y_test), callbacks=cbks, epochs=4)\n-    assert os.path.isfile(filepath.format(epoch=1))\n-    assert os.path.isfile(filepath.format(epoch=3))\n-    assert not os.path.exists(filepath.format(epoch=0))\n-    assert not os.path.exists(filepath.format(epoch=2))\n-    os.remove(filepath.format(epoch=1))\n-    os.remove(filepath.format(epoch=3))\n+    assert os.path.isfile(filepath.format(epoch=2))\n+    assert os.path.isfile(filepath.format(epoch=4))\n+    assert not os.path.exists(filepath.format(epoch=1))\n+    assert not os.path.exists(filepath.format(epoch=3))\n+    os.remove(filepath.format(epoch=2))\n+    os.remove(filepath.format(epoch=4))\n     assert not tmpdir.listdir()\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9a37c3da5e01893ed9cc5f97473e550d26bc03ce", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 3 | Churn Cumulative: 835 | Contributors (this commit): 21 | Commits (past 90d): 7 | Contributors (cumulative): 21 | DMM Complexity: 0.0\n\nDIFF:\n@@ -296,8 +296,11 @@ class Progbar(object):\n                 return\n \n             prev_total_width = self.total_width\n+            if sys.stdout.isatty():\n                 sys.stdout.write('\\b' * prev_total_width)\n                 sys.stdout.write('\\r')\n+            else:\n+                sys.stdout.write('\\n')\n \n             if self.target is not None:\n                 numdigits = int(np.floor(np.log10(self.target))) + 1\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1b5d54839daa5d0cb1efcf4d6c376655b81ddad6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 151 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -47,6 +47,8 @@ def multi_gpu_model(model, gpus):\n     ```python\n         import tensorflow as tf\n         from keras.applications import Xception\n+        from keras.utils import multi_gpu_model\n+        import numpy as np\n \n         num_samples = 1000\n         height = 224\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e93b85462e3d9ada8b70aa766ff13c50cade23ad", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 8 | Churn Cumulative: 8935 | Contributors (this commit): 92 | Commits (past 90d): 29 | Contributors (cumulative): 92 | DMM Complexity: 1.0\n\nDIFF:\n@@ -3117,7 +3117,15 @@ def conv1d(x, kernel, strides=1, padding='valid',\n \n     # Returns\n         A tensor, result of 1D convolution.\n+\n+    # Raises\n+        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n     \"\"\"\n+    if data_format is None:\n+        data_format = image_data_format()\n+    if data_format not in {'channels_first', 'channels_last'}:\n+        raise ValueError('Unknown data_format ' + str(data_format))\n+\n     kernel_shape = kernel.get_shape().as_list()\n     if padding == 'causal':\n         # causal (dilated) convolution:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9c79e01a61b371820d04e9cc52487fc0eb5d0312", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 4 | Churn Cumulative: 1379 | Contributors (this commit): 11 | Commits (past 90d): 11 | Contributors (cumulative): 15 | DMM Complexity: None\n\nDIFF:\n@@ -654,7 +654,7 @@ class GeneratorEnqueuer(SequenceEnqueuer):\n                     yield inputs\n             else:\n                 all_finished = all([not thread.is_alive() for thread in self._threads])\n-                if all_finished:\n+                if all_finished and self.queue.empty():\n                     raise StopIteration()\n                 else:\n                     time.sleep(self.wait_time)\n\n@@ -264,7 +264,7 @@ def test_finite_generator_enqueuer_threads():\n     acc = []\n     for output in gen_output:\n         acc.append(int(output[0, 0, 0, 0]))\n-    assert len(set(acc) - set(range(100))) == 0, \"Output is not the same\"\n+    assert set(acc) == set(range(100)), \"Output is not the same\"\n     enqueuer.stop()\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ab30f73a90b8a38593f20bda1b09e459a660d506", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 9 | Churn Cumulative: 475 | Contributors (this commit): 8 | Commits (past 90d): 2 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -182,8 +182,8 @@ if __name__ == '__main__':\n     train_history = defaultdict(list)\n     test_history = defaultdict(list)\n \n-    for epoch in range(epochs):\n-        print('Epoch {} of {}'.format(epoch + 1, epochs))\n+    for epoch in range(1, epochs + 1):\n+        print('Epoch {} of {}'.format(epoch, epochs))\n \n         num_batches = int(X_train.shape[0] / batch_size)\n         progress_bar = Progbar(target=num_batches)\n@@ -192,7 +192,6 @@ if __name__ == '__main__':\n         epoch_disc_loss = []\n \n         for index in range(num_batches):\n-            progress_bar.update(index)\n             # generate a new batch of noise\n             noise = np.random.uniform(-1, 1, (batch_size, latent_size))\n \n@@ -232,7 +231,9 @@ if __name__ == '__main__':\n                 [noise, sampled_labels.reshape((-1, 1))],\n                 [trick, sampled_labels]))\n \n-        print('\\nTesting for epoch {}:'.format(epoch + 1))\n+            progress_bar.update(index + 1)\n+\n+        print('Testing for epoch {}:'.format(epoch))\n \n         # evaluate the testing loss here\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7b35041e470e3254393f70e9cddcfa25f0be31f6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 5 | Churn Cumulative: 358 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -122,18 +122,18 @@ def test_cudnn_rnn_canonical_to_params_gru():\n \n \n @keras_test\n+@pytest.mark.parametrize('rnn_type', ['lstm', 'gru'], ids=['LSTM', 'GRU'])\n @pytest.mark.skipif((keras.backend.backend() != 'tensorflow'),\n                     reason='Requires TensorFlow backend')\n @pytest.mark.skipif(not keras.backend.tensorflow_backend._get_available_gpus(),\n                     reason='Requires GPU')\n-def test_cudnn_rnn_timing():\n+def test_cudnn_rnn_timing(rnn_type):\n     input_size = 1000\n     timesteps = 60\n     units = 256\n     num_samples = 10000\n \n     times = []\n-    for rnn_type in ['lstm', 'gru']:\n     for use_cudnn in [True, False]:\n         start_time = time.time()\n         inputs = keras.layers.Input(shape=(None, input_size))\n@@ -161,7 +161,6 @@ def test_cudnn_rnn_timing():\n     speedup = times[1] / times[0]\n     print(rnn_type, 'speedup', speedup)\n     assert speedup > 3\n-        keras.backend.clear_session()\n \n \n @keras_test\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a91b81ba299deecfec41f1264fa4f4368745772d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 1163 | Contributors (this commit): 8 | Commits (past 90d): 2 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -1,3 +1,4 @@\n+import numpy as np\n import types as python_types\n import warnings\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0ff700abccc71ceb0794ddc8e77945e178f10599", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 23 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 34 | Churn Cumulative: 639 | Contributors (this commit): 7 | Commits (past 90d): 1 | Contributors (cumulative): 7 | DMM Complexity: 0.0\n\nDIFF:\n@@ -82,21 +82,15 @@ def get_stories(f, only_supporting=False, max_length=None):\n     return data\n \n \n-def vectorize_stories(data, word_idx, story_maxlen, query_maxlen):\n-    X = []\n-    Xq = []\n-    Y = []\n+def vectorize_stories(data):\n+    inputs, queries, answers = [], [], []\n     for story, query, answer in data:\n-        x = [word_idx[w] for w in story]\n-        xq = [word_idx[w] for w in query]\n-        # let's not forget that index 0 is reserved\n-        y = np.zeros(len(word_idx) + 1)\n-        y[word_idx[answer]] = 1\n-        X.append(x)\n-        Xq.append(xq)\n-        Y.append(y)\n-    return (pad_sequences(X, maxlen=story_maxlen),\n-            pad_sequences(Xq, maxlen=query_maxlen), np.array(Y))\n+        inputs.append([word_idx[w] for w in story])\n+        queries.append([word_idx[w] for w in query])\n+        answers.append(word_idx[answer])\n+    return (pad_sequences(inputs, maxlen=story_maxlen),\n+            pad_sequences(queries, maxlen=query_maxlen),\n+            np.array(answers))\n \n try:\n     path = get_file('babi-tasks-v1-2.tar.gz', origin='https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz')\n@@ -143,14 +137,8 @@ print('-')\n print('Vectorizing the word sequences...')\n \n word_idx = dict((c, i + 1) for i, c in enumerate(vocab))\n-inputs_train, queries_train, answers_train = vectorize_stories(train_stories,\n-                                                               word_idx,\n-                                                               story_maxlen,\n-                                                               query_maxlen)\n-inputs_test, queries_test, answers_test = vectorize_stories(test_stories,\n-                                                            word_idx,\n-                                                            story_maxlen,\n-                                                            query_maxlen)\n+inputs_train, queries_train, answers_train = vectorize_stories(train_stories)\n+inputs_test, queries_test, answers_test = vectorize_stories(test_stories)\n \n print('-')\n print('inputs: integer tensor of shape (samples, max_length)')\n@@ -225,7 +213,7 @@ answer = Activation('softmax')(answer)\n \n # build the final model\n model = Model([input_sequence, question], answer)\n-model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n+model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy',\n               metrics=['accuracy'])\n \n # train\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#035c814b13b6fa64ae9eb7f0264ce8a0ac84264f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 15 | Lines Deleted: 15 | Files Changed: 2 | Hunks: 12 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 30 | Churn Cumulative: 739 | Contributors (this commit): 14 | Commits (past 90d): 4 | Contributors (cumulative): 17 | DMM Complexity: None\n\nDIFF:\n@@ -40,11 +40,11 @@ for i in range(0, len(text) - maxlen, step):\n print('nb sequences:', len(sentences))\n \n print('Vectorization...')\n-X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n+x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n for i, sentence in enumerate(sentences):\n     for t, char in enumerate(sentence):\n-        X[i, t, char_indices[char]] = 1\n+        x[i, t, char_indices[char]] = 1\n     y[i, char_indices[next_chars[i]]] = 1\n \n \n@@ -73,7 +73,7 @@ for iteration in range(1, 60):\n     print()\n     print('-' * 50)\n     print('Iteration', iteration)\n-    model.fit(X, y,\n+    model.fit(x, y,\n               batch_size=128,\n               epochs=1)\n \n\n@@ -170,14 +170,14 @@ if __name__ == '__main__':\n \n     # get our mnist data, and force it to be of shape (..., 1, 28, 28) with\n     # range [-1, 1]\n-    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n-    X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n-    X_train = np.expand_dims(X_train, axis=1)\n+    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n+    x_train = (x_train.astype(np.float32) - 127.5) / 127.5\n+    x_train = np.expand_dims(x_train, axis=1)\n \n-    X_test = (X_test.astype(np.float32) - 127.5) / 127.5\n-    X_test = np.expand_dims(X_test, axis=1)\n+    x_test = (x_test.astype(np.float32) - 127.5) / 127.5\n+    x_test = np.expand_dims(x_test, axis=1)\n \n-    num_train, num_test = X_train.shape[0], X_test.shape[0]\n+    num_train, num_test = x_train.shape[0], x_test.shape[0]\n \n     train_history = defaultdict(list)\n     test_history = defaultdict(list)\n@@ -185,7 +185,7 @@ if __name__ == '__main__':\n     for epoch in range(1, epochs + 1):\n         print('Epoch {} of {}'.format(epoch, epochs))\n \n-        num_batches = int(X_train.shape[0] / batch_size)\n+        num_batches = int(x_train.shape[0] / batch_size)\n         progress_bar = Progbar(target=num_batches)\n \n         epoch_gen_loss = []\n@@ -196,7 +196,7 @@ if __name__ == '__main__':\n             noise = np.random.uniform(-1, 1, (batch_size, latent_size))\n \n             # get a batch of real images\n-            image_batch = X_train[index * batch_size:(index + 1) * batch_size]\n+            image_batch = x_train[index * batch_size:(index + 1) * batch_size]\n             label_batch = y_train[index * batch_size:(index + 1) * batch_size]\n \n             # sample some labels from p_c\n@@ -209,12 +209,12 @@ if __name__ == '__main__':\n             generated_images = generator.predict(\n                 [noise, sampled_labels.reshape((-1, 1))], verbose=0)\n \n-            X = np.concatenate((image_batch, generated_images))\n+            x = np.concatenate((image_batch, generated_images))\n             y = np.array([1] * batch_size + [0] * batch_size)\n             aux_y = np.concatenate((label_batch, sampled_labels), axis=0)\n \n             # see if the discriminator can figure itself out...\n-            epoch_disc_loss.append(discriminator.train_on_batch(X, [y, aux_y]))\n+            epoch_disc_loss.append(discriminator.train_on_batch(x, [y, aux_y]))\n \n             # make new noise. we generate 2 * batch size here such that we have\n             # the generator optimize over an identical number of images as the\n@@ -245,13 +245,13 @@ if __name__ == '__main__':\n         generated_images = generator.predict(\n             [noise, sampled_labels.reshape((-1, 1))], verbose=False)\n \n-        X = np.concatenate((X_test, generated_images))\n+        x = np.concatenate((x_test, generated_images))\n         y = np.array([1] * num_test + [0] * num_test)\n         aux_y = np.concatenate((y_test, sampled_labels), axis=0)\n \n         # see if the discriminator can figure itself out...\n         discriminator_test_loss = discriminator.evaluate(\n-            X, [y, aux_y], verbose=False)\n+            x, [y, aux_y], verbose=False)\n \n         discriminator_train_loss = np.mean(np.array(epoch_disc_loss), axis=0)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#eee1a0ed2293be17bfe671a698d60da399317ba3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 257 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -113,7 +113,7 @@ for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n     for t, char in enumerate(input_text):\n         encoder_input_data[i, t, input_token_index[char]] = 1.\n     for t, char in enumerate(target_text):\n-        # decoder_target_data is ahead of decoder_target_data by one timestep\n+        # decoder_target_data is ahead of decoder_input_data by one timestep\n         decoder_input_data[i, t, target_token_index[char]] = 1.\n         if t > 0:\n             # decoder_target_data will be ahead by one timestep\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#62d097c4ff6fa694a4dbc670e9c7eb9e2bc27c74", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 501 | Contributors (this commit): 8 | Commits (past 90d): 4 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -183,7 +183,7 @@ if __name__ == '__main__':\n     test_history = defaultdict(list)\n \n     for epoch in range(1, epochs + 1):\n-        print('Epoch {} of {}'.format(epoch, epochs))\n+        print('Epoch {}/{}'.format(epoch, epochs))\n \n         num_batches = int(x_train.shape[0] / batch_size)\n         progress_bar = Progbar(target=num_batches)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fd3ac2a93ea2584d0679e27a10ebeff0508d7a37", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 246 | Contributors (this commit): 10 | Commits (past 90d): 2 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -90,11 +90,11 @@ for iteration in range(1, 60):\n         sys.stdout.write(generated)\n \n         for i in range(400):\n-            x = np.zeros((1, maxlen, len(chars)))\n+            x_pred = np.zeros((1, maxlen, len(chars)))\n             for t, char in enumerate(sentence):\n-                x[0, t, char_indices[char]] = 1.\n+                x_pred[0, t, char_indices[char]] = 1.\n \n-            preds = model.predict(x, verbose=0)[0]\n+            preds = model.predict(x_pred, verbose=0)[0]\n             next_index = sample(preds, diversity)\n             next_char = indices_char[next_index]\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f11b422541cb68857d6f62ab667d7778f3f3e3a2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 8 | Files Changed: 2 | Hunks: 7 | Methods Changed: 3 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 16 | Churn Cumulative: 11712 | Contributors (this commit): 94 | Commits (past 90d): 47 | Contributors (cumulative): 105 | DMM Complexity: 0.0\n\nDIFF:\n@@ -493,13 +493,13 @@ def ones_like(x, name=None):\n \n \n def count_params(x):\n-    for _ in x.shape:\n+    for _ in get_variable_shape(x):\n         if _ == C.InferredDimension or _ == C.FreeDimension:\n             raise ValueError('CNTK backend: `count_params` with dynamic '\n                              'shape is not supported. Please provide '\n                              'fixed dimension instead of `None`.')\n \n-    return np.prod([x.shape[i] for i in range(len(x.shape))])\n+    return np.prod(get_variable_shape(x))\n \n \n def cast(x, dtype):\n\n@@ -541,7 +541,7 @@ def shape(x):\n \n \n def int_shape(x):\n-    \"\"\"Returns the shape tensor or variable as a tuple of int or None entries.\n+    \"\"\"Returns the shape of tensor or variable as a tuple of int or None entries.\n \n     # Arguments\n         x: Tensor or variable.\n@@ -865,13 +865,14 @@ def random_normal_variable(shape, mean, scale, dtype=None,\n \n \n def count_params(x):\n-    \"\"\"Returns the number of scalars in a Keras variable.\n+    \"\"\"Returns the static number of elements in a Keras variable or tensor.\n \n     # Arguments\n-        x: Keras variable.\n+        x: Keras variable or tensor.\n \n     # Returns\n-        Integer, the number of scalars in `x`.\n+        Integer, the number of elements in `x`, i.e., the product of the\n+        array's static dimensions.\n \n     # Example\n     ```python\n@@ -883,8 +884,7 @@ def count_params(x):\n                [ 0.,  0.,  0.]], dtype=float32)\n     ```\n     \"\"\"\n-    shape = x.get_shape()\n-    return np.prod([shape[i]._value for i in range(len(shape))])\n+    return np.prod(get_variable_shape(x))\n \n \n def cast(x, dtype):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ce406b773b9f36be5718a4369ad07fea4f9ebdba", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 7 | Files Changed: 2 | Hunks: 5 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 13 | Churn Cumulative: 473 | Contributors (this commit): 9 | Commits (past 90d): 7 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -59,7 +59,7 @@ epochs = 100  # Number of epochs to train for.\n latent_dim = 256  # Latent dimensionality of the encoding space.\n num_samples = 10000  # Number of samples to train on.\n # Path to the data txt file on disk.\n-data_path = '/Users/fchollet/Downloads/fra-eng/fra.txt'\n+data_path = 'fra-eng/fra.txt'\n \n # Vectorize the data.\n input_texts = []\n\n@@ -19,14 +19,14 @@ import numpy as np\n from keras.preprocessing.text import Tokenizer\n from keras.preprocessing.sequence import pad_sequences\n from keras.utils import to_categorical\n-from keras.layers import Dense, Input, Flatten\n+from keras.layers import Dense, Input, GlobalMaxPooling1D\n from keras.layers import Conv1D, MaxPooling1D, Embedding\n from keras.models import Model\n \n \n BASE_DIR = ''\n-GLOVE_DIR = BASE_DIR + '/glove.6B/'\n-TEXT_DATA_DIR = BASE_DIR + '/20_newsgroup/'\n+GLOVE_DIR = os.path.join(BASE_DIR, 'glove.6B')\n+TEXT_DATA_DIR = os.path.join(BASE_DIR, '20_newsgroup')\n MAX_SEQUENCE_LENGTH = 1000\n MAX_NB_WORDS = 20000\n EMBEDDING_DIM = 100\n@@ -106,7 +106,7 @@ print('Preparing embedding matrix.')\n \n # prepare embedding matrix\n num_words = min(MAX_NB_WORDS, len(word_index))\n-embedding_matrix = np.zeros((num_words + 1, EMBEDDING_DIM))\n+embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n for word, i in word_index.items():\n     if i >= MAX_NB_WORDS:\n         continue\n@@ -133,8 +133,7 @@ x = MaxPooling1D(5)(x)\n x = Conv1D(128, 5, activation='relu')(x)\n x = MaxPooling1D(5)(x)\n x = Conv1D(128, 5, activation='relu')(x)\n-x = MaxPooling1D(35)(x)\n-x = Flatten()(x)\n+x = GlobalMaxPooling1D()(x)\n x = Dense(128, activation='relu')(x)\n preds = Dense(len(labels_index), activation='softmax')(x)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d08e28921452ae2c7db32f8c1a51d7fc04939848", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 6 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 14974 | Contributors (this commit): 123 | Commits (past 90d): 25 | Contributors (cumulative): 143 | DMM Complexity: None\n\nDIFF:\n@@ -1894,9 +1894,9 @@ class Model(Container):\n                 non picklable arguments to the generator\n                 as they can't be passed\n                 easily to children processes.\n-            shuffle: Whether to shuffle the data at the beginning of each\n-                epoch. Only used with instances of `Sequence` (\n-                keras.utils.Sequence).\n+            shuffle: Whether to shuffle the order of the batches at \n+                the beginning of each epoch. Only used with instances \n+                of `Sequence` (keras.utils.Sequence).\n             initial_epoch: Epoch at which to start training\n                 (useful for resuming a previous training run)\n \n\n@@ -1087,9 +1087,9 @@ class Sequential(Model):\n                 non picklable arguments to the generator\n                 as they can't be passed\n                 easily to children processes.\n-            shuffle: Whether to shuffle the data at the beginning of each\n-                epoch. Only used with instances of `Sequence` (\n-                keras.utils.Sequence).\n+            shuffle: Whether to shuffle the order of the batches at \n+                the beginning of each epoch. Only used with instances \n+                of `Sequence` (keras.utils.Sequence).\n             initial_epoch: Epoch at which to start training\n                 (useful for resuming a previous training run).\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c173b764c768a686139636da24c54b30734f5c83", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 25 | Lines Deleted: 1 | Files Changed: 3 | Hunks: 13 | Methods Changed: 2 | Complexity Δ (Sum/Max): 5/5 | Churn Δ: 26 | Churn Cumulative: 6886 | Contributors (this commit): 78 | Commits (past 90d): 33 | Contributors (cumulative): 92 | DMM Complexity: 0.6190476190476191\n\nDIFF:\n@@ -60,6 +60,9 @@ def _standardize_input_data(data, names, shapes=None,\n     if data is None:\n         return [None for _ in range(len(names))]\n     if isinstance(data, dict):\n+        for key, value in data.items():\n+            if value.__class__.__name__ == 'DataFrame':\n+                data[key] = value.values\n         arrays = []\n         for name in names:\n             if name not in data:\n@@ -68,6 +71,9 @@ def _standardize_input_data(data, names, shapes=None,\n                                  str(names))\n             arrays.append(data[name])\n     elif isinstance(data, list):\n+        for key, value in enumerate(data):\n+            if value.__class__.__name__ == 'DataFrame':\n+                data[key] = value.values\n         if len(data) != len(names):\n             if data and hasattr(data[0], 'shape'):\n                 raise ValueError('Error when checking model ' +\n@@ -95,6 +101,9 @@ def _standardize_input_data(data, names, shapes=None,\n                         'The list you passed was: ' +\n                         str(data)[:200])\n         arrays = data\n+    elif data.__class__.__name__ == 'DataFrame':\n+        # test if data is a DataFrame, without pandas installed\n+        data = data.values\n     else:\n         if not hasattr(data, 'shape'):\n             raise TypeError('Error when checking model ' +\n\n@@ -20,7 +20,8 @@ setup(name='Keras',\n           'tests': ['pytest',\n                     'pytest-pep8',\n                     'pytest-xdist',\n-                    'pytest-cov'],\n+                    'pytest-cov',\n+                    'pandas'],\n       },\n       classifiers=[\n           'Development Status :: 5 - Production/Stable',\n\n@@ -1,5 +1,6 @@\n import pytest\n import numpy as np\n+import pandas as pd\n from numpy.testing import assert_allclose\n import sys\n import scipy.sparse as sparse\n@@ -106,9 +107,13 @@ def test_model_methods():\n \n     input_a_np = np.random.random((10, 3))\n     input_b_np = np.random.random((10, 3))\n+    input_a_df = pd.DataFrame(input_a_np)\n+    input_b_df = pd.DataFrame(input_b_np)\n \n     output_a_np = np.random.random((10, 4))\n     output_b_np = np.random.random((10, 3))\n+    output_a_df = pd.DataFrame(output_a_np)\n+    output_b_df = pd.DataFrame(output_b_np)\n \n     # training/testing doesn't work before compiling.\n     with pytest.raises(RuntimeError):\n@@ -124,6 +129,8 @@ def test_model_methods():\n                                [output_a_np, output_b_np])\n     out = model.train_on_batch({'input_a': input_a_np, 'input_b': input_b_np},\n                                {'dense_1': output_a_np, 'dropout': output_b_np})\n+    out = model.train_on_batch([input_a_df, input_b_df],\n+                               [output_a_df, output_b_df])\n \n     # test fit\n     out = model.fit([input_a_np, input_b_np],\n@@ -133,6 +140,8 @@ def test_model_methods():\n     out = model.fit({'input_a': input_a_np, 'input_b': input_b_np},\n                     {'dense_1': output_a_np, 'dropout': output_b_np},\n                     epochs=1, batch_size=4)\n+    out = model.fit([input_a_df, input_b_df],\n+                    [output_a_df, output_b_df], epochs=1, batch_size=4)\n \n     # test validation_split\n     out = model.fit([input_a_np, input_b_np],\n@@ -165,10 +174,13 @@ def test_model_methods():\n                               [output_a_np, output_b_np])\n     out = model.test_on_batch({'input_a': input_a_np, 'input_b': input_b_np},\n                               {'dense_1': output_a_np, 'dropout': output_b_np})\n+    out = model.test_on_batch([input_a_df, input_b_df],\n+                              [output_a_df, output_b_df])\n \n     # predict_on_batch\n     out = model.predict_on_batch([input_a_np, input_b_np])\n     out = model.predict_on_batch({'input_a': input_a_np, 'input_b': input_b_np})\n+    out = model.predict_on_batch([input_a_df, input_b_df])\n \n     # predict, evaluate\n     input_a_np = np.random.random((10, 3))\n@@ -178,7 +190,9 @@ def test_model_methods():\n     output_b_np = np.random.random((10, 3))\n \n     out = model.evaluate([input_a_np, input_b_np], [output_a_np, output_b_np], batch_size=4)\n+    out = model.evaluate([input_a_df, input_b_df], [output_a_df, output_b_df], batch_size=4)\n     out = model.predict([input_a_np, input_b_np], batch_size=4)\n+    out = model.predict([input_a_df, input_b_df], batch_size=4)\n \n     # with sample_weight\n     input_a_np = np.random.random((10, 3))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
