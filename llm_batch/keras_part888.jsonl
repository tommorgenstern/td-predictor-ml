{"custom_id": "keras#8a7955f239e53a7c60465eac7bde6cb99465e8f8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 65 | Contributors (this commit): 6 | Commits (past 90d): 3 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -28,11 +28,12 @@ def setup_package():\n     whl_path = re.findall(\n         r\"[^\\s]*\\.whl\",\n         build_process.stdout,\n-    )[-1]\n+    )\n     if not whl_path:\n+        print(build_process.stdout)\n         print(build_process.stderr)\n         raise ValueError(\"Installing Keras package unsuccessful. \")\n-    return whl_path\n+    return whl_path[-1]\n \n \n def create_virtualenv():\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#04ebf724f2467338534998981638950329175e0c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 3 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 2985 | Contributors (this commit): 9 | Commits (past 90d): 21 | Contributors (cumulative): 22 | DMM Complexity: None\n\nDIFF:\n@@ -465,7 +465,7 @@ def affine_transform(\n     # transform the indices\n     coordinates = jnp.einsum(\"Bhwij, Bjk -> Bhwik\", indices, transform)\n     coordinates = jnp.moveaxis(coordinates, source=-1, destination=1)\n-    coordinates += jnp.reshape(a=offset, shape=(*offset.shape, 1, 1, 1))\n+    coordinates += jnp.reshape(offset, shape=(*offset.shape, 1, 1, 1))\n \n     # apply affine transformation\n     _map_coordinates = functools.partial(\n\n@@ -600,7 +600,7 @@ def affine_transform(\n     # transform the indices\n     coordinates = np.einsum(\"Bhwij, Bjk -> Bhwik\", indices, transform)\n     coordinates = np.moveaxis(coordinates, source=-1, destination=1)\n-    coordinates += np.reshape(a=offset, newshape=(*offset.shape, 1, 1, 1))\n+    coordinates += np.reshape(offset, newshape=(*offset.shape, 1, 1, 1))\n \n     # apply affine transformation\n     affined = np.stack(\n\n@@ -424,7 +424,7 @@ def affine_transform(\n     # transform the indices\n     coordinates = torch.einsum(\"Bhwij, Bjk -> Bhwik\", indices, transform)\n     coordinates = torch.moveaxis(coordinates, source=-1, destination=1)\n-    coordinates += torch.reshape(a=offset, shape=(*offset.shape, 1, 1, 1))\n+    coordinates += torch.reshape(offset, shape=(*offset.shape, 1, 1, 1))\n \n     # Note: torch.stack is faster than torch.vmap when the batch size is small.\n     affined = torch.stack(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b539552e9ae63687eeca9ef15b4d08a7401b1d35", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 26 | Lines Deleted: 6 | Files Changed: 6 | Hunks: 18 | Methods Changed: 11 | Complexity Δ (Sum/Max): 16/4 | Churn Δ: 32 | Churn Cumulative: 4865 | Contributors (this commit): 19 | Commits (past 90d): 40 | Contributors (cumulative): 67 | DMM Complexity: 1.0\n\nDIFF:\n@@ -439,6 +439,7 @@ def bitwise_xor(x, y):\n \n def bitwise_left_shift(x, y):\n     x = convert_to_tensor(x)\n+    if not isinstance(y, int):\n         y = convert_to_tensor(y)\n     return jnp.left_shift(x, y)\n \n@@ -449,6 +450,7 @@ def left_shift(x, y):\n \n def bitwise_right_shift(x, y):\n     x = convert_to_tensor(x)\n+    if not isinstance(y, int):\n         y = convert_to_tensor(y)\n     return jnp.right_shift(x, y)\n \n\n@@ -355,6 +355,7 @@ def bitwise_xor(x, y):\n \n def bitwise_left_shift(x, y):\n     x = convert_to_tensor(x)\n+    if not isinstance(y, int):\n         y = convert_to_tensor(y)\n     return np.left_shift(x, y)\n \n@@ -365,6 +366,7 @@ def left_shift(x, y):\n \n def bitwise_right_shift(x, y):\n     x = convert_to_tensor(x)\n+    if not isinstance(y, int):\n         y = convert_to_tensor(y)\n     return np.right_shift(x, y)\n \n\n@@ -1007,6 +1007,7 @@ def bitwise_xor(x, y):\n \n def bitwise_left_shift(x, y):\n     x = convert_to_tensor(x)\n+    if not isinstance(y, int):\n         y = convert_to_tensor(y)\n         dtype = dtypes.result_type(x.dtype, y.dtype)\n         x = tf.cast(x, dtype)\n@@ -1020,6 +1021,7 @@ def left_shift(x, y):\n \n def bitwise_right_shift(x, y):\n     x = convert_to_tensor(x)\n+    if not isinstance(y, int):\n         y = convert_to_tensor(y)\n         dtype = dtypes.result_type(x.dtype, y.dtype)\n         x = tf.cast(x, dtype)\n\n@@ -479,6 +479,7 @@ def bitwise_xor(x, y):\n \n def bitwise_left_shift(x, y):\n     x = convert_to_tensor(x)\n+    if not isinstance(y, int):\n         y = convert_to_tensor(y)\n     return torch.bitwise_left_shift(x, y)\n \n@@ -489,6 +490,7 @@ def left_shift(x, y):\n \n def bitwise_right_shift(x, y):\n     x = convert_to_tensor(x)\n+    if not isinstance(y, int):\n         y = convert_to_tensor(y)\n     return torch.bitwise_right_shift(x, y)\n \n\n@@ -1417,6 +1417,9 @@ class BitwiseLeftShift(Operation):\n         return backend.numpy.bitwise_left_shift(x, y)\n \n     def compute_output_spec(self, x, y):\n+        if isinstance(y, int):\n+            dtype = x.dtype\n+        else:\n             dtype = dtypes.result_type(x.dtype, y.dtype)\n         return KerasTensor(x.shape, dtype=dtype)\n \n@@ -1451,6 +1454,9 @@ class LeftShift(Operation):\n         return backend.numpy.left_shift(x, y)\n \n     def compute_output_spec(self, x, y):\n+        if isinstance(y, int):\n+            dtype = x.dtype\n+        else:\n             dtype = dtypes.result_type(x.dtype, y.dtype)\n         return KerasTensor(x.shape, dtype=dtype)\n \n@@ -1483,6 +1489,9 @@ class BitwiseRightShift(Operation):\n         return backend.numpy.bitwise_right_shift(x, y)\n \n     def compute_output_spec(self, x, y):\n+        if isinstance(y, int):\n+            dtype = x.dtype\n+        else:\n             dtype = dtypes.result_type(x.dtype, y.dtype)\n         return KerasTensor(x.shape, dtype=dtype)\n \n@@ -1517,6 +1526,9 @@ class RightShift(Operation):\n         return backend.numpy.right_shift(x, y)\n \n     def compute_output_spec(self, x, y):\n+        if isinstance(y, int):\n+            dtype = x.dtype\n+        else:\n             dtype = dtypes.result_type(x.dtype, y.dtype)\n         return KerasTensor(x.shape, dtype=dtype)\n \n\n@@ -6229,16 +6229,16 @@ class NumpyDtypeTest(testing.TestCase):\n         self.assertDType(knp.BitwiseXor().symbolic_call(x1, x2), expected_dtype)\n \n     @parameterized.named_parameters(\n-        named_product(dtypes=itertools.combinations(INT_DTYPES, 2))\n+        named_product(dtypes=itertools.product(INT_DTYPES, INT_DTYPES + [None]))\n     )\n     def test_bitwise_left_shift(self, dtypes):\n         import jax.numpy as jnp\n \n         dtype1, dtype2 = dtypes\n         x1 = knp.ones((1,), dtype=dtype1)\n-        x2 = knp.ones((1,), dtype=dtype2)\n+        x2 = knp.ones((1,), dtype=dtype2) if dtype2 else 1\n         x1_jax = jnp.ones((1,), dtype=dtype1)\n-        x2_jax = jnp.ones((1,), dtype=dtype2)\n+        x2_jax = jnp.ones((1,), dtype=dtype2) if dtype2 else 1\n         expected_dtype = standardize_dtype(jnp.left_shift(x1_jax, x2_jax).dtype)\n \n         self.assertDType(knp.bitwise_left_shift(x1, x2), expected_dtype)\n@@ -6249,16 +6249,16 @@ class NumpyDtypeTest(testing.TestCase):\n     # left_shift is same as bitwise_left_shift\n \n     @parameterized.named_parameters(\n-        named_product(dtypes=itertools.combinations(INT_DTYPES, 2))\n+        named_product(dtypes=itertools.product(INT_DTYPES, INT_DTYPES + [None]))\n     )\n     def test_bitwise_right_shift(self, dtypes):\n         import jax.numpy as jnp\n \n         dtype1, dtype2 = dtypes\n         x1 = knp.ones((1,), dtype=dtype1)\n-        x2 = knp.ones((1,), dtype=dtype2)\n+        x2 = knp.ones((1,), dtype=dtype2) if dtype2 else 1\n         x1_jax = jnp.ones((1,), dtype=dtype1)\n-        x2_jax = jnp.ones((1,), dtype=dtype2)\n+        x2_jax = jnp.ones((1,), dtype=dtype2) if dtype2 else 1\n         expected_dtype = standardize_dtype(\n             jnp.right_shift(x1_jax, x2_jax).dtype\n         )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6e688ab104942db088816a1b8ef315ebabb1c682", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 16 | Churn Cumulative: 1187 | Contributors (this commit): 10 | Commits (past 90d): 1 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -2363,11 +2363,23 @@ def binary_focal_crossentropy(\n \n     >>> y_true = [[0, 1], [0, 0]]\n     >>> y_pred = [[0.6, 0.4], [0.4, 0.6]]\n-    >>> loss = keras.losses.binary_focal_crossentropy(\n+    >>> # In this instance, the first sample in the second batch is the\n+    >>> # 'easier' example.\n+    >>> focal_loss = keras.losses.binary_focal_crossentropy(\n     ...        y_true, y_pred, gamma=2)\n     >>> assert loss.shape == (2,)\n-    >>> loss\n+    >>> focal_loss\n     array([0.330, 0.206], dtype=float32)\n+    >>> # Compare with binary_crossentropy\n+    >>> bce_loss = keras.losses.binary_focal_crossentropy(\n+    ...        y_true, y_pred)\n+    >>> bce_loss\n+    array([0.916, 0.714], dtype=float32)\n+    >>> # Binary focal crossentropy loss attributes more importance to the\n+    >>> # harder example which results in a higher loss for the first batch\n+    >>> # when normalized by binary cross entropy loss\n+    >>> focal_loss/bce_loss\n+    array([0.360, 0.289]\n     \"\"\"\n     y_pred = ops.convert_to_tensor(y_pred)\n     y_true = ops.cast(y_true, y_pred.dtype)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#dac30fac60a53fb446146187b806529707a91033", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 325 | Contributors (this commit): 5 | Commits (past 90d): 1 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -13,6 +13,7 @@ if backend() == \"tensorflow\":\n     from tensorflow.python.trackable.data_structures import ListWrapper\n     from tensorflow.python.trackable.data_structures import _DictWrapper\n \n+    try:\n         optree.register_pytree_node(\n             ListWrapper,\n             lambda x: (x, None),\n@@ -33,6 +34,8 @@ if backend() == \"tensorflow\":\n             ),\n             namespace=\"keras\",\n         )\n+    except ValueError:\n+        pass  # We may have already registered if we are reiporting keras.\n \n \n def is_nested(structure):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1ba20128226cfd8b277869420aba19b80ba38a8b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 14 | Contributors (this commit): 3 | Commits (past 90d): 1 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -9,13 +9,13 @@ class Lion(optimizer.Optimizer):\n \n     The Lion optimizer is a stochastic-gradient-descent method that uses the\n     sign operator to control the magnitude of the update, unlike other adaptive\n-    optimizers such as Adam that rely on second-order moments. This make\n+    optimizers such as Adam that rely on second-order moments. This makes\n     Lion more memory-efficient as it only keeps track of the momentum. According\n     to the authors (see reference), its performance gain over Adam grows with\n     the batch size. Because the update of Lion is produced through the sign\n     operation, resulting in a larger norm, a suitable learning rate for Lion is\n     typically 3-10x smaller than that for AdamW. The weight decay for Lion\n-    should be in turn 3-10x larger than that for AdamW to maintain a\n+    should in turn be 3-10x larger than that for AdamW to maintain a\n     similar strength (lr * wd).\n \n     Args:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#33d97b02449e4422a7aac880d771eb816d373629", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 13 | Churn Cumulative: 393 | Contributors (this commit): 13 | Commits (past 90d): 4 | Contributors (cumulative): 16 | DMM Complexity: 0.6666666666666666\n\nDIFF:\n@@ -89,3 +89,13 @@ class DeviceTest(testing.TestCase):\n     def test_invalid_torch_device(self):\n         with self.assertRaisesRegex(ValueError, \"Received: device_name='123'\"):\n             backend.device(123).__enter__()\n+\n+    @pytest.mark.skipif(backend.backend() != \"torch\", reason=\"torch only\")\n+    def test_torch_meta_device(self):\n+        import torch\n+\n+        with torch.device(\"meta\"):\n+            x = torch.ones(5)\n+\n+        t = backend.convert_to_tensor(x)\n+        self.assertEqual(t.device, torch.device(\"cpu\"))\n\n@@ -199,6 +199,9 @@ def convert_to_tensor(x, dtype=None, sparse=None, ragged=None):\n     if is_tensor(x):\n         device = get_device()\n         if x.device != device:\n+            if x.is_meta:\n+                x = torch.empty_like(x, device=device)\n+            else:\n                 x = x.to(device)\n         if dtype is None:\n             return x\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#624c00b587110884e04f9c4023da2c307d5622f9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 340 | Lines Deleted: 0 | Files Changed: 4 | Hunks: 7 | Methods Changed: 9 | Complexity Δ (Sum/Max): 10/6 | Churn Δ: 340 | Churn Cumulative: 2035 | Contributors (this commit): 12 | Commits (past 90d): 5 | Contributors (cumulative): 26 | DMM Complexity: 1.0\n\nDIFF:\n@@ -14,6 +14,7 @@ from keras.src.losses.losses import BinaryCrossentropy\n from keras.src.losses.losses import BinaryFocalCrossentropy\n from keras.src.losses.losses import CategoricalCrossentropy\n from keras.src.losses.losses import CategoricalFocalCrossentropy\n+from keras.src.losses.losses import CategoricalGeneralizedCrossEntropy\n from keras.src.losses.losses import CategoricalHinge\n from keras.src.losses.losses import Circle\n from keras.src.losses.losses import CosineSimilarity\n@@ -34,6 +35,7 @@ from keras.src.losses.losses import binary_crossentropy\n from keras.src.losses.losses import binary_focal_crossentropy\n from keras.src.losses.losses import categorical_crossentropy\n from keras.src.losses.losses import categorical_focal_crossentropy\n+from keras.src.losses.losses import categorical_generalized_cross_entropy\n from keras.src.losses.losses import categorical_hinge\n from keras.src.losses.losses import circle\n from keras.src.losses.losses import cosine_similarity\n\n@@ -13,6 +13,7 @@ from keras.src.losses.losses import BinaryCrossentropy\n from keras.src.losses.losses import BinaryFocalCrossentropy\n from keras.src.losses.losses import CategoricalCrossentropy\n from keras.src.losses.losses import CategoricalFocalCrossentropy\n+from keras.src.losses.losses import CategoricalGeneralizedCrossEntropy\n from keras.src.losses.losses import CategoricalHinge\n from keras.src.losses.losses import Circle\n from keras.src.losses.losses import CosineSimilarity\n@@ -33,6 +34,7 @@ from keras.src.losses.losses import binary_crossentropy\n from keras.src.losses.losses import binary_focal_crossentropy\n from keras.src.losses.losses import categorical_crossentropy\n from keras.src.losses.losses import categorical_focal_crossentropy\n+from keras.src.losses.losses import categorical_generalized_cross_entropy\n from keras.src.losses.losses import categorical_hinge\n from keras.src.losses.losses import circle\n from keras.src.losses.losses import cosine_similarity\n\n@@ -1504,6 +1504,86 @@ class Circle(LossFunctionWrapper):\n         return config\n \n \n+@keras_export(\"keras.losses.CategoricalGeneralizedCrossEntropy\")\n+class CategoricalGeneralizedCrossEntropy(LossFunctionWrapper):\n+    \"\"\"Computes the Generalized Cross Entropy loss between `y_true` & `y_pred`.\n+\n+    Generalized Cross Entropy (GCE) is a noise-robust loss function\n+    that provides better robustness against noisy labels than\n+    standard cross entropy.\n+    It generalizes both cross entropy and mean absolute error through\n+    the parameter q, where values closer to 1 make the loss more robust\n+    to noisy labels.\n+\n+    Formula:\n+    ```python\n+    loss = (1 - p**q) / q\n+    ```\n+    where `p` is the predicted probability for the true class and `q`\n+    is the noise parameter.\n+\n+    Args:\n+        q: Float in range `(0, 1)`. It is the noise parameter.\n+           Controls the behavior of the loss:\n+            - As `q` approaches 0: Behaves more like cross entropy\n+            - As `q` approaches 1: Behaves more like mean absolute error\n+           Defaults to `0.5`\n+        reduction: Type of reduction to apply to the loss. In almost all cases\n+            this should be `\"sum_over_batch_size\"`. Supported options are\n+            `\"sum\"`, `\"sum_over_batch_size\"`, `\"mean\"`,\n+            `\"mean_with_sample_weight\"` or `None`. `\"sum\"` sums the loss,\n+            `\"sum_over_batch_size\"` and `\"mean\"` sum the loss and divide by the\n+            sample size, and `\"mean_with_sample_weight\"` sums the loss and\n+            divides by the sum of the sample weights. `\"none\"` and `None`\n+            perform no aggregation. Defaults to `\"sum_over_batch_size\"`.\n+        name: Optional name for the loss instance.\n+        dtype: The dtype of the loss's computations. Defaults to `None`, which\n+            means using `keras.backend.floatx()`. `keras.backend.floatx()` is a\n+            `\"float32\"` unless set to different value\n+            (via `keras.backend.set_floatx()`). If a `keras.DTypePolicy` is\n+            provided, then the `compute_dtype` will be utilized.\n+\n+    Example:\n+    ```python\n+    y_true = np.array([0, 1, 0, 1])\n+    y_pred = np.array([[0.7, 0.3], [0.2, 0.8], [0.6, 0.4], [0.4, 0.6]])\n+    keras.losses.CategoricalGeneralizedCrossEntropy()(y_true, y_pred)\n+    ```\n+\n+    References:\n+        - [Zhang, Sabuncu, 2018](https://arxiv.org/abs/1805.07836)\n+          (\"Generalized Cross Entropy Loss for Training\n+            Deep Neural Networks with Noisy Labels\")\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        q=0.5,\n+        reduction=\"sum_over_batch_size\",\n+        name=\"categorical_generalized_cross_entropy\",\n+        dtype=None,\n+    ):\n+        if not 0 < q < 1:\n+            raise ValueError(\"q must be in the interval (0, 1)\")\n+        super().__init__(\n+            categorical_generalized_cross_entropy,\n+            name=name,\n+            reduction=reduction,\n+            dtype=dtype,\n+            q=q,\n+        )\n+        self.q = q\n+\n+    def get_config(self):\n+        config = Loss.get_config(self)\n+        config.update(\n+            {\n+                \"q\": self.q,\n+            }\n+        )\n+        return config\n+\n+\n def convert_binary_labels_to_hinge(y_true):\n     \"\"\"Converts binary labels into -1/1 for hinge loss/metric calculation.\"\"\"\n     are_zeros = ops.equal(y_true, 0)\n@@ -2609,3 +2689,54 @@ def circle(\n     circle_loss = ops.softplus(p_loss + n_loss)\n     backend.set_keras_mask(circle_loss, circle_loss > 0)\n     return circle_loss\n+\n+\n+@keras_export(\"keras.losses.categorical_generalized_cross_entropy\")\n+def categorical_generalized_cross_entropy(y_true, y_pred, q):\n+    \"\"\"Computes the Generalized Cross Entropy loss.\n+\n+    Generalized Cross Entropy (GCE) is a noise-robust loss function that\n+    provides better robustness against noisy labels than standard cross entropy.\n+    It generalizes both cross entropy and mean absolute error through\n+    the parameter q, where values closer to 1 make the loss more robust\n+    to noisy labels.\n+\n+    Formula:\n+    ```python\n+    loss = (1 - p**q) / q\n+    ```\n+    where `p` is the predicted probability for the true class and `q`\n+    is the noise parameter.\n+\n+    Args:\n+        y_true: Ground truth labels. Expected to contain *integer class indices*\n+            with shape `[batch_size]` or `[batch_size, 1]`.\n+        y_pred: The predicted class probabilities, with shape\n+            `[batch_size, num_classes]`.\n+        q: Float in range `(0, 1)`. It is the noise parameter.\n+           Controls the behavior of the loss:\n+            - As `q` approaches 0: Behaves more like cross entropy\n+            - As `q` approaches 1: Behaves more like mean absolute error\n+\n+    Returns:\n+        GCE loss values with shape `[batch_size]`.\n+    ```\n+\n+    References:\n+        - [Zhang, Sabuncu, 2018](https://arxiv.org/abs/1805.07836)\n+          (\"Generalized Cross Entropy Loss for Training\n+            Deep Neural Networks with Noisy Labels\")\n+    \"\"\"\n+\n+    # Convert y_true to integer type and one-hot encode\n+    y_true_one_hot = ops.one_hot(\n+        ops.cast(y_true, \"int\"), num_classes=ops.shape(y_pred)[-1]\n+    )\n+    y_true_one_hot = ops.cast(y_true_one_hot, y_pred.dtype)\n+    # Calculate the probability of the true class\n+    p = ops.sum(y_pred * y_true_one_hot, axis=-1)\n+\n+    # Compute the GCE loss for q in (0,1)\n+    gce_loss = (1 - ops.power(p, q)) / q\n+\n+    return gce_loss\n\n@@ -1763,3 +1763,208 @@ class CircleTest(testing.TestCase):\n         circle_loss = losses.Circle(dtype=\"bfloat16\")\n         loss = circle_loss(self.y_true, self.y_pred)\n         self.assertDType(loss, \"bfloat16\")\n+\n+\n+class CategoricalGeneralizedCrossEntropyTest(testing.TestCase):\n+    def test_config(self):\n+        self.run_class_serialization_test(\n+            losses.CategoricalGeneralizedCrossEntropy(name=\"gce\")\n+        )\n+        self.run_class_serialization_test(\n+            losses.CategoricalGeneralizedCrossEntropy(q=0.1, name=\"gce\")\n+        )\n+\n+    def test_basic_correctness_for_binary(self):\n+        y_true = np.array([0, 1, 0, 1])\n+        y_pred = np.array([[0.7, 0.3], [0.2, 0.8], [0.6, 0.4], [0.4, 0.6]])\n+        # Calculate expected GCE loss manually\n+        # For q=0.5:\n+        # First sample (class 0): gce = (1 - 0.7^0.5) / 0.5\n+        # Second sample (class 1): gce = (1 - 0.8^0.5) / 0.5\n+        # Third sample (class 0): gce = (1 - 0.6^0.5) / 0.5\n+        # Fourth sample (class 1): gce = (1 - 0.6^0.5) / 0.5\n+        expected = np.array(\n+            [\n+                (1 - np.power(0.7, 0.5)) / 0.5,\n+                (1 - np.power(0.8, 0.5)) / 0.5,\n+                (1 - np.power(0.6, 0.5)) / 0.5,\n+                (1 - np.power(0.6, 0.5)) / 0.5,\n+            ]\n+        )\n+        output = losses.CategoricalGeneralizedCrossEntropy()(y_true, y_pred)\n+        self.assertAllClose(output, expected.sum() / len(expected))\n+\n+        expected_q_08 = np.array(\n+            [\n+                (1 - np.power(0.7, 0.8)) / 0.8,\n+                (1 - np.power(0.8, 0.8)) / 0.8,\n+                (1 - np.power(0.6, 0.8)) / 0.8,\n+                (1 - np.power(0.6, 0.8)) / 0.8,\n+            ]\n+        )\n+        output = losses.CategoricalGeneralizedCrossEntropy(q=0.8)(\n+            y_true, y_pred\n+        )\n+        self.assertAllClose(output, expected_q_08.sum() / len(expected_q_08))\n+\n+    def test_basic_correctness_for_multi_class(self):\n+        y_true = np.array([0, 1, 0, 1])\n+        y_pred = np.array(\n+            [[0.7, 0.3, 0.0], [0.2, 0.2, 0.6], [0.6, 0.4, 0.0], [0.2, 0.2, 0.6]]\n+        )\n+        # Calculate expected GCE loss manually\n+        # For q=0.5:\n+        # First sample (class 0): gce = (1 - 0.7^0.5) / 0.5\n+        # Second sample (class 1): gce = (1 - 0^0.5) / 0.5\n+        # Third sample (class 0): gce = (1 - 0.6^0.5) / 0.5\n+        # Fourth sample (class 1): gce = (1 - 0.0^0.5) / 0.5\n+        expected = np.array(\n+            [\n+                (1 - np.power(0.7, 0.5)) / 0.5,\n+                (1 - np.power(0.2, 0.5)) / 0.5,\n+                (1 - np.power(0.6, 0.5)) / 0.5,\n+                (1 - np.power(0.2, 0.5)) / 0.5,\n+            ]\n+        )\n+        output = losses.CategoricalGeneralizedCrossEntropy()(y_true, y_pred)\n+        self.assertAllClose(output, expected.sum() / len(expected))\n+\n+        expected_q_08 = np.array(\n+            [\n+                (1 - np.power(0.7, 0.8)) / 0.8,\n+                (1 - np.power(0.2, 0.8)) / 0.8,\n+                (1 - np.power(0.6, 0.8)) / 0.8,\n+                (1 - np.power(0.2, 0.8)) / 0.8,\n+            ]\n+        )\n+        output = losses.CategoricalGeneralizedCrossEntropy(q=0.8)(\n+            y_true, y_pred\n+        )\n+        self.assertAllClose(output, expected_q_08.sum() / len(expected_q_08))\n+\n+    def test_binary_segmentation(self):\n+        y_true = np.array(\n+            [[0, 1, 1, 0], [1, 0, 1, 0], [0, 0, 1, 1], [1, 1, 0, 1]]\n+        )\n+        y_pred = np.array(\n+            [\n+                [[1.0, 0.0], [0.0, 1.0], [0.0, 1.0], [1.0, 0.0]],\n+                [[0.0, 1.0], [1.0, 0.0], [0.0, 1.0], [1.0, 0.0]],\n+                [[1.0, 0.0], [1.0, 0.0], [0.0, 1.0], [0.0, 1.0]],\n+                [[0.0, 1.0], [0.0, 1.0], [1.0, 0.0], [0.0, 1.0]],\n+            ]\n+        )\n+        output = losses.CategoricalGeneralizedCrossEntropy(q=0.5)(\n+            y_true, y_pred\n+        )\n+        self.assertAllClose(output, 0.0)\n+\n+        y_true = np.array(\n+            [[0, 1, 1, 0], [1, 0, 1, 0], [0, 0, 1, 1], [1, 1, 0, 1]]\n+        )\n+        y_pred = np.array(\n+            [\n+                [[1.0, 0.0], [0.0, 1.0], [0.0, 1.0], [0.2, 0.8]],\n+                [[0.0, 1.0], [1.0, 0.0], [0.0, 1.0], [1.0, 0.0]],\n+                [[1.0, 0.0], [1.0, 0.0], [0.0, 1.0], [0.0, 1.0]],\n+                [[0.0, 1.0], [0.0, 1.0], [1.0, 0.0], [0.6, 0.4]],\n+            ]\n+        )\n+        expected = np.array(\n+            [\n+                (1 - np.power(0.2, 0.5)) / 0.5,\n+                (1 - np.power(0.4, 0.5)) / 0.5,\n+            ]\n+        )\n+        output = losses.CategoricalGeneralizedCrossEntropy(q=0.5)(\n+            y_true, y_pred\n+        )\n+        self.assertAllClose(output, expected.sum() / 16.0)  # 16 pixels\n+\n+    def test_multi_class_segmentation(self):\n+        y_true = np.array(\n+            [[0, 1, 2, 0], [1, 0, 1, 0], [0, 0, 1, 1], [1, 1, 0, 1]]\n+        )\n+        y_pred = np.array(\n+            [\n+                [\n+                    [1.0, 0.0, 0.0],\n+                    [0.0, 1.0, 0.0],\n+                    [0.0, 0.0, 1.0],\n+                    [1.0, 0.0, 0.0],\n+                ],\n+                [\n+                    [0.0, 1.0, 0.0],\n+                    [1.0, 0.0, 0.0],\n+                    [0.0, 1.0, 0.0],\n+                    [1.0, 0.0, 0.0],\n+                ],\n+                [\n+                    [1.0, 0.0, 0.0],\n+                    [1.0, 0.0, 0.0],\n+                    [0.0, 1.0, 0.0],\n+                    [0.0, 1.0, 0.0],\n+                ],\n+                [\n+                    [0.0, 1.0, 0.0],\n+                    [0.0, 1.0, 0.0],\n+                    [1.0, 0.0, 0.0],\n+                    [0.0, 1.0, 0.0],\n+                ],\n+            ]\n+        )\n+        output = losses.CategoricalGeneralizedCrossEntropy(q=0.5)(\n+            y_true, y_pred\n+        )\n+        self.assertAllClose(output, 0.0)\n+\n+        y_true = np.array(\n+            [[0, 1, 2, 0], [1, 0, 1, 0], [0, 0, 1, 1], [1, 1, 0, 1]]\n+        )\n+        y_pred = np.array(\n+            [\n+                [\n+                    [1.0, 0.0, 0.0],\n+                    [0.0, 1.0, 0.0],\n+                    [0.0, 0.0, 1.0],\n+                    [0.2, 0.0, 0.8],\n+                ],\n+                [\n+                    [1.0, 0.0, 0.0],\n+                    [1.0, 0.0, 0.0],\n+                    [0.0, 1.0, 0.0],\n+                    [1.0, 0.0, 0.0],\n+                ],\n+                [\n+                    [1.0, 0.0, 0.0],\n+                    [1.0, 0.0, 0.0],\n+                    [0.0, 1.0, 0.0],\n+                    [0.0, 1.0, 0.0],\n+                ],\n+                [\n+                    [0.0, 1.0, 0.0],\n+                    [0.0, 1.0, 0.0],\n+                    [0.5, 0.5, 0.0],\n+                    [0.0, 1.0, 0.0],\n+                ],\n+            ]\n+        )\n+        expected = np.array(\n+            [\n+                (1 - np.power(0.2, 0.5)) / 0.5,\n+                (1 - np.power(0.0, 0.5)) / 0.5,\n+                (1 - np.power(0.5, 0.5)) / 0.5,\n+            ]\n+        )\n+        output = losses.CategoricalGeneralizedCrossEntropy(q=0.5)(\n+            y_true, y_pred\n+        )\n+        self.assertAllClose(output, expected.sum() / 16.0)  # 16 pixels\n+\n+    def test_dtype_arg(self):\n+        y_true = np.array([0, 1, 0, 1])\n+        y_pred = np.array([[0.7, 0.3], [0.2, 0.8], [0.6, 0.4], [0.4, 0.6]])\n+        output = losses.CategoricalGeneralizedCrossEntropy(dtype=\"bfloat16\")(\n+            y_true, y_pred\n+        )\n+        self.assertDType(output, \"bfloat16\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#56fb8bb6ab00aefbdc9bc353272c9d9aa825de9c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 11 | Churn Cumulative: 70 | Contributors (this commit): 5 | Commits (past 90d): 2 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -66,9 +66,6 @@ class DeviceTest(testing.TestCase):\n     def test_torch_device_scope(self):\n         import torch\n \n-        if not torch.cuda.device_count():\n-            self.skipTest(\"Need at least one GPU for testing\")\n-\n         with backend.device(\"cpu:0\"):\n             t = backend.numpy.ones((2, 1))\n             self.assertEqual(t.device, torch.device(\"cpu\"))\n@@ -76,6 +73,10 @@ class DeviceTest(testing.TestCase):\n             t = backend.numpy.ones((2, 1))\n             self.assertEqual(t.device, torch.device(\"cpu\"))\n \n+        # Need at least one GPU for the following testing.\n+        if not torch.cuda.is_available():\n+            return\n+\n         # When leaving the scope, the device should be back with gpu:0\n         t = backend.numpy.ones((2, 1))\n         self.assertEqual(t.device, torch.device(\"cuda\", 0))\n@@ -98,4 +99,8 @@ class DeviceTest(testing.TestCase):\n             x = torch.ones(5)\n \n         t = backend.convert_to_tensor(x)\n+\n+        if not torch.cuda.is_available():\n             self.assertEqual(t.device, torch.device(\"cpu\"))\n+        else:\n+            self.assertEqual(t.device, torch.device(\"cuda\", 0))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d865f5f0f2b7862afb96a4bf3dabdd0d464e5da9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 673 | Lines Deleted: 106 | Files Changed: 5 | Hunks: 62 | Methods Changed: 39 | Complexity Δ (Sum/Max): 55/39 | Churn Δ: 779 | Churn Cumulative: 2521 | Contributors (this commit): 16 | Commits (past 90d): 9 | Contributors (cumulative): 32 | DMM Complexity: 0.7513227513227513\n\nDIFF:\n@@ -270,6 +270,16 @@ class Model(Trainer, base_trainer.Trainer, Layer):\n     def save(self, filepath, overwrite=True, zipped=None, **kwargs):\n         \"\"\"Saves a model as a `.keras` file.\n \n+        Note that `model.save()` is an alias for `keras.saving.save_model()`.\n+\n+        The saved `.keras` file contains:\n+\n+        - The model's configuration (architecture)\n+        - The model's weights\n+        - The model's optimizer's state (if any)\n+\n+        Thus models can be reinstantiated in the exact same state.\n+\n         Args:\n             filepath: `str` or `pathlib.Path` object.\n                 The path where to save the model. Must end in `.keras`\n@@ -297,63 +307,117 @@ class Model(Trainer, base_trainer.Trainer, Layer):\n         x = keras.random.uniform((10, 3))\n         assert np.allclose(model.predict(x), loaded_model.predict(x))\n         ```\n-\n-        Note that `model.save()` is an alias for `keras.saving.save_model()`.\n-\n-        The saved `.keras` file contains:\n-\n-        - The model's configuration (architecture)\n-        - The model's weights\n-        - The model's optimizer's state (if any)\n-\n-        Thus models can be reinstantiated in the exact same state.\n         \"\"\"\n         return saving_api.save_model(\n             self, filepath, overwrite=overwrite, zipped=zipped, **kwargs\n         )\n \n     @traceback_utils.filter_traceback\n-    def save_weights(self, filepath, overwrite=True):\n-        \"\"\"Saves all layer weights to a `.weights.h5` file.\n+    def save_weights(self, filepath, overwrite=True, max_shard_size=None):\n+        \"\"\"Saves all weights to a single file or sharded files.\n+\n+        By default, the weights will be saved in a single `.weights.h5` file.\n+        If sharding is enabled (`max_shard_size` is not `None`), the weights\n+        will be saved in multiple files, each with a size at most\n+        `max_shard_size` (in GB). Additionally, a configuration file\n+        `.weights.json` will contain the metadata for the sharded files.\n+\n+        The saved sharded files contain:\n+\n+        - `*.weights.json`: The configuration file containing 'metadata' and\n+            'weight_map'.\n+        - `*_xxxxxx.weights.h5`: The sharded files containing only the\n+            weights.\n \n         Args:\n-            filepath: `str` or `pathlib.Path` object.\n-                Path where to save the model. Must end in `.weights.h5`.\n-            overwrite: Whether we should overwrite any existing model\n-                at the target location, or instead ask the user\n-                via an interactive prompt.\n+            filepath: `str` or `pathlib.Path` object. Path where the weights\n+                will be saved.  When sharding, the filepath must end in\n+                `.weights.json`. If `.weights.h5` is provided, it will be\n+                overridden.\n+            overwrite: Whether to overwrite any existing weights at the target\n+                location or instead ask the user via an interactive prompt.\n+            max_shard_size: `int` or `float`. Maximum size in GB for each\n+                sharded file. If `None`, no sharding will be done. Defaults to\n+                `None`.\n+\n+        Example:\n+\n+        ```python\n+        # Instantiate a EfficientNetV2L model with about 454MB of weights.\n+        model = keras.applications.EfficientNetV2L(weights=None)\n+\n+        # Save the weights in a single file.\n+        model.save_weights(\"model.weights.h5\")\n+\n+        # Save the weights in sharded files. Use `max_shard_size=0.25` means\n+        # each sharded file will be at most ~250MB.\n+        model.save_weights(\"model.weights.json\", max_shard_size=0.25)\n+\n+        # Load the weights in a new model with the same architecture.\n+        loaded_model = keras.applications.EfficientNetV2L(weights=None)\n+        loaded_model.load_weights(\"model.weights.h5\")\n+        x = keras.random.uniform((1, 480, 480, 3))\n+        assert np.allclose(model.predict(x), loaded_model.predict(x))\n+\n+        # Load the sharded weights in a new model with the same architecture.\n+        loaded_model = keras.applications.EfficientNetV2L(weights=None)\n+        loaded_model.load_weights(\"model.weights.json\")\n+        x = keras.random.uniform((1, 480, 480, 3))\n+        assert np.allclose(model.predict(x), loaded_model.predict(x))\n+        ```\n         \"\"\"\n-        return saving_api.save_weights(self, filepath, overwrite=overwrite)\n+        return saving_api.save_weights(\n+            self, filepath, overwrite=overwrite, max_shard_size=max_shard_size\n+        )\n \n     @traceback_utils.filter_traceback\n     def load_weights(self, filepath, skip_mismatch=False, **kwargs):\n-        \"\"\"Load weights from a file saved via `save_weights()`.\n+        \"\"\"Load the weights from a single file or sharded files.\n \n-        Weights are loaded based on the network's\n-        topology. This means the architecture should be the same as when the\n-        weights were saved. Note that layers that don't have weights are not\n-        taken into account in the topological ordering, so adding or removing\n-        layers is fine as long as they don't have weights.\n+        Weights are loaded based on the network's topology. This means the\n+        architecture should be the same as when the weights were saved. Note\n+        that layers that don't have weights are not taken into account in the\n+        topological ordering, so adding or removing layers is fine as long as\n+        they don't have weights.\n \n         **Partial weight loading**\n \n         If you have modified your model, for instance by adding a new layer\n-        (with weights) or by changing the shape of the weights of a layer,\n-        you can choose to ignore errors and continue loading\n-        by setting `skip_mismatch=True`. In this case any layer with\n-        mismatching weights will be skipped. A warning will be displayed\n-        for each skipped layer.\n+        (with weights) or by changing the shape of the weights of a layer, you\n+        can choose to ignore errors and continue loading by setting\n+        `skip_mismatch=True`. In this case any layer with mismatching weights\n+        will be skipped. A warning will be displayed for each skipped layer.\n+\n+        **Sharding**\n+\n+        When loading sharded weights, it is important to specify `filepath` that\n+        ends with `*.weights.json` which is used as the configuration file.\n+        Additionally, the sharded files `*_xxxxx.weights.h5` must be in the same\n+        directory as the configuration file.\n \n         Args:\n-            filepath: String, path to the weights file to load.\n-                It can either be a `.weights.h5` file\n-                or a legacy `.h5` weights file.\n+            filepath: `str` or `pathlib.Path` object. Path where the weights\n+                will be saved.  When sharding, the filepath must end in\n+                `.weights.json`.\n             skip_mismatch: Boolean, whether to skip loading of layers where\n                 there is a mismatch in the number of weights, or a mismatch in\n                 the shape of the weights.\n+\n+        Example:\n+\n+        ```python\n+        # Load the weights in a single file.\n+        model.load_weights(\"model.weights.h5\")\n+\n+        # Load the weights in sharded files.\n+        model.load_weights(\"model.weights.json\")\n+        ```\n         \"\"\"\n         saving_api.load_weights(\n-            self, filepath, skip_mismatch=skip_mismatch, **kwargs\n+            self,\n+            filepath,\n+            skip_mismatch=skip_mismatch,\n+            **kwargs,\n         )\n \n     def quantize(self, mode, **kwargs):\n\n@@ -219,32 +219,45 @@ def load_model(filepath, custom_objects=None, compile=True, safe_mode=True):\n \n \n @keras_export(\"keras.saving.save_weights\")\n-def save_weights(model, filepath, overwrite=True, **kwargs):\n-    if not str(filepath).endswith(\".weights.h5\"):\n+def save_weights(\n+    model, filepath, overwrite=True, max_shard_size=None, **kwargs\n+):\n+    filepath_str = str(filepath)\n+    if max_shard_size is None and not filepath_str.endswith(\".weights.h5\"):\n         raise ValueError(\n             \"The filename must end in `.weights.h5`. \"\n-            f\"Received: filepath={filepath}\"\n+            f\"Received: filepath={filepath_str}\"\n+        )\n+    elif max_shard_size is not None and not filepath_str.endswith(\n+        (\"weights.h5\", \"weights.json\")\n+    ):\n+        raise ValueError(\n+            \"The filename must end in `.weights.json` when `max_shard_size` is \"\n+            f\"specified. Received: filepath={filepath_str}\"\n         )\n     try:\n         exists = os.path.exists(filepath)\n     except TypeError:\n         exists = False\n     if exists and not overwrite:\n-        proceed = io_utils.ask_to_proceed_with_overwrite(filepath)\n+        proceed = io_utils.ask_to_proceed_with_overwrite(filepath_str)\n         if not proceed:\n             return\n-    saving_lib.save_weights_only(model, filepath, **kwargs)\n+    saving_lib.save_weights_only(model, filepath, max_shard_size, **kwargs)\n \n \n @keras_export(\"keras.saving.load_weights\")\n def load_weights(model, filepath, skip_mismatch=False, **kwargs):\n-    if str(filepath).endswith(\".keras\"):\n+    filepath_str = str(filepath)\n+    if filepath_str.endswith(\".keras\"):\n         if kwargs:\n             raise ValueError(f\"Invalid keyword arguments: {kwargs}\")\n         saving_lib.load_weights_only(\n             model, filepath, skip_mismatch=skip_mismatch\n         )\n-    elif str(filepath).endswith(\".weights.h5\"):\n+    elif filepath_str.endswith(\".weights.h5\") or filepath_str.endswith(\n+        \".weights.json\"\n+    ):\n         objects_to_skip = kwargs.pop(\"objects_to_skip\", None)\n         if kwargs:\n             raise ValueError(f\"Invalid keyword arguments: {kwargs}\")\n@@ -254,7 +267,7 @@ def load_weights(model, filepath, skip_mismatch=False, **kwargs):\n             skip_mismatch=skip_mismatch,\n             objects_to_skip=objects_to_skip,\n         )\n-    elif str(filepath).endswith(\".h5\") or str(filepath).endswith(\".hdf5\"):\n+    elif filepath_str.endswith(\".h5\") or filepath_str.endswith(\".hdf5\"):\n         by_name = kwargs.pop(\"by_name\", False)\n         if kwargs:\n             raise ValueError(f\"Invalid keyword arguments: {kwargs}\")\n\n@@ -1,4 +1,5 @@\n import os\n+import pathlib\n import unittest.mock as mock\n \n import numpy as np\n@@ -237,6 +238,20 @@ class LoadWeightsTests(test_case.TestCase):\n         with self.assertRaisesRegex(ValueError, \"File format not supported\"):\n             model.load_weights(\"invalid_extension.pkl\")\n \n+    def test_load_sharded_weights(self):\n+        src_model = self.get_model()\n+        temp_filepath = pathlib.Path(\n+            os.path.join(self.get_temp_dir(), \"test_weights.weights.json\")\n+        )\n+        src_model.save_weights(temp_filepath, max_shard_size=1)\n+        self.assertLen(os.listdir(temp_filepath.parent), 2)\n+        src_weights = src_model.get_weights()\n+        dest_model = self.get_model()\n+        dest_model.load_weights(temp_filepath)\n+        dest_weights = dest_model.get_weights()\n+        for orig, loaded in zip(src_weights, dest_weights):\n+            self.assertAllClose(orig, loaded)\n+\n \n class SaveModelTestsWarning(test_case.TestCase):\n     def get_model(self):\n\n@@ -3,6 +3,7 @@\n import datetime\n import io\n import json\n+import math\n import os\n import pathlib\n import shutil\n@@ -23,11 +24,13 @@ from keras.src.saving.serialization_lib import ObjectSharingScope\n from keras.src.saving.serialization_lib import deserialize_keras_object\n from keras.src.saving.serialization_lib import serialize_keras_object\n from keras.src.trainers.compile_utils import CompileMetrics\n+from keras.src.utils import dtype_utils\n from keras.src.utils import file_utils\n from keras.src.utils import io_utils\n from keras.src.utils import naming\n from keras.src.utils import plot_model\n from keras.src.utils.model_visualization import check_pydot\n+from keras.src.utils.summary_utils import readable_memory_size\n from keras.src.utils.summary_utils import weight_memory_size\n from keras.src.version import __version__ as keras_version\n \n@@ -510,7 +513,9 @@ def _load_model_from_fileobj(fileobj, custom_objects, compile, safe_mode):\n     return model\n \n \n-def save_weights_only(model, filepath, objects_to_skip=None):\n+def save_weights_only(\n+    model, filepath, max_shard_size=None, objects_to_skip=None\n+):\n     \"\"\"Save only the weights of a model to a target filepath.\n \n     Supports both `.weights.h5` and `.keras`.\n@@ -522,13 +527,20 @@ def save_weights_only(model, filepath, objects_to_skip=None):\n             \"by using `build()`.\"\n         )\n \n-    filepath = str(filepath)\n+    filepath_str = str(filepath)\n     tmp_dir = None\n     remote_filepath = None\n-    if not filepath.endswith(\".weights.h5\"):\n+    if max_shard_size is None and not filepath_str.endswith(\".weights.h5\"):\n         raise ValueError(\n-            \"Invalid `filepath` argument: expected a `.weights.h5` extension. \"\n-            f\"Received: filepath={filepath}\"\n+            \"The filename must end in `.weights.h5`. \"\n+            f\"Received: filepath={filepath_str}\"\n+        )\n+    elif max_shard_size is not None and not filepath_str.endswith(\n+        (\"weights.h5\", \"weights.json\")\n+    ):\n+        raise ValueError(\n+            \"The filename must end in `.weights.json` when `max_shard_size` is \"\n+            f\"specified. Received: filepath={filepath_str}\"\n         )\n     try:\n         if file_utils.is_remote_path(filepath):\n@@ -537,6 +549,9 @@ def save_weights_only(model, filepath, objects_to_skip=None):\n             remote_filepath = filepath\n             filepath = local_filepath\n \n+        if max_shard_size is not None:\n+            weights_store = ShardedH5IOStore(filepath, max_shard_size, mode=\"w\")\n+        else:\n             weights_store = H5IOStore(filepath, mode=\"w\")\n         if objects_to_skip is not None:\n             visited_saveables = set(id(o) for o in objects_to_skip)\n@@ -572,18 +587,22 @@ def load_weights_only(\n \n     archive = None\n     tmp_dir = None\n-    filepath = str(filepath)\n+    filepath_str = str(filepath)\n \n     try:\n-        if file_utils.is_remote_path(filepath):\n+        if file_utils.is_remote_path(filepath_str):\n             tmp_dir = get_temp_dir()\n-            local_filepath = os.path.join(tmp_dir, os.path.basename(filepath))\n-            file_utils.copy(filepath, local_filepath)\n-            filepath = local_filepath\n+            local_filepath = os.path.join(\n+                tmp_dir, os.path.basename(filepath_str)\n+            )\n+            file_utils.copy(filepath_str, local_filepath)\n+            filepath_str = filepath = local_filepath\n \n-        if filepath.endswith(\".weights.h5\"):\n+        if filepath_str.endswith(\"weights.h5\"):\n             weights_store = H5IOStore(filepath, mode=\"r\")\n-        elif filepath.endswith(\".keras\"):\n+        elif filepath_str.endswith(\"weights.json\"):\n+            weights_store = ShardedH5IOStore(filepath, mode=\"r\")\n+        elif filepath_str.endswith(\".keras\"):\n             archive = zipfile.ZipFile(filepath, \"r\")\n             weights_store = H5IOStore(_VARS_FNAME_H5, archive=archive, mode=\"r\")\n \n@@ -693,6 +712,19 @@ def _save_state(\n ):\n     from keras.src.saving.keras_saveable import KerasSaveable\n \n+    if not isinstance(weights_store, (H5IOStore, ShardedH5IOStore, NpzIOStore)):\n+        raise ValueError(\n+            \"Expected `weights_store` to be an instance of \"\n+            \"`H5IOStore`, `ShardedH5IOStore` or `NpzIOStore`. \"\n+            f\"Received: {weights_store} of type {type(weights_store)}\"\n+        )\n+    if not isinstance(assets_store, (DiskIOStore, type(None))):\n+        raise ValueError(\n+            \"Expected `assets_store` to be an instance of \"\n+            \"`DiskIOStore` or `None`. \"\n+            f\"Received: {assets_store} of type {type(assets_store)}\"\n+        )\n+\n     # If the saveable has already been saved, skip it.\n     if id(saveable) in visited_saveables:\n         return\n@@ -746,6 +778,19 @@ def _load_state(\n ):\n     from keras.src.saving.keras_saveable import KerasSaveable\n \n+    if not isinstance(weights_store, (H5IOStore, ShardedH5IOStore, NpzIOStore)):\n+        raise ValueError(\n+            \"Expected `weights_store` to be an instance of \"\n+            \"`H5IOStore`, `ShardedH5IOStore` or `NpzIOStore`. \"\n+            f\"Received: {weights_store} of type {type(weights_store)}\"\n+        )\n+    if not isinstance(assets_store, (DiskIOStore, type(None))):\n+        raise ValueError(\n+            \"Expected `assets_store` to be an instance of \"\n+            \"`DiskIOStore` or `None`. \"\n+            f\"Received: {assets_store} of type {type(assets_store)}\"\n+        )\n+\n     if visited_saveables and id(saveable) in visited_saveables:\n         return\n \n@@ -945,71 +990,106 @@ class DiskIOStore:\n \n \n class H5IOStore:\n-    def __init__(self, root_path, archive=None, mode=\"r\"):\n     \"\"\"Numerical variable store backed by HDF5.\n \n-        If `archive` is specified, then `root_path` refers to the filename\n-        inside the archive.\n-\n-        If `archive` is not specified, then `root_path` refers to the path of\n-        the h5 file on disk.\n+    Args:\n+        path_or_io: `str`, `pathlib.Path` or `io.BytesIO` object. The path where\n+            to save the model.\n+        archive: Optional `zipfile.ZipFile` object. If specified, the h5 file\n+            will be saved inside the archive and `path_or_io` will be used as\n+            the filename.\n+        mode: `str`. One of {`\"r\"`, `\"w\"`}. The mode to open the h5 file.\n+            Defaults to `\"r\"`.\n     \"\"\"\n-        self.root_path = root_path\n+\n+    def __init__(self, path_or_io, archive=None, mode=\"r\"):\n+        if mode not in (\"w\", \"r\"):\n+            raise ValueError(\n+                f\"`mode` should be either 'w' or 'r'. Received: {mode}\"\n+            )\n+        if isinstance(path_or_io, (str, pathlib.Path)):\n+            self.path_or_io = pathlib.Path(path_or_io)\n+        elif isinstance(path_or_io, io.BytesIO):\n+            if archive is not None:\n+                raise ValueError(\n+                    \"When `path_or_io` is an `io.BytesIO` object, `archive` \"\n+                    \"should be `None`.\"\n+                )\n+            self.path_or_io = path_or_io\n+        else:\n+            raise TypeError(\n+                \"`path_or_io` should be a `str`, `pathlib.Path` or \"\n+                f\"`io.BytesIO` object. Received: path_or_io={path_or_io} of \"\n+                f\"type {type(path_or_io)}.\"\n+            )\n         self.mode = mode\n         self.archive = archive\n         self.io_file = None\n \n+        # Init H5 file.\n+        self.h5_file = self._get_h5_file(self.path_or_io)\n+\n+        # Init H5 entry group.\n+        self._h5_entry_path = None\n+        self._h5_entry_group = {}\n+\n+    def __bool__(self):\n+        # Delegate `__bool__` to the underlying `h5_file`. Otherwise, Python\n+        # will mistakenly using `__len__` to determine the value.\n+        return self.h5_file.__bool__()\n+\n+    def _get_h5_file(self, path_or_io):\n         if self.archive:\n             if self.mode == \"w\":\n                 self.io_file = io.BytesIO()\n             else:\n-                self.io_file = self.archive.open(self.root_path, \"r\")\n-            self.h5_file = h5py.File(self.io_file, mode=self.mode)\n+                self.io_file = self.archive.open(str(path_or_io), \"r\")\n+            return h5py.File(self.io_file, mode=self.mode)\n         else:\n-            self.h5_file = h5py.File(root_path, mode=self.mode)\n+            return h5py.File(path_or_io, mode=self.mode)\n \n     def make(self, path, metadata=None):\n-        return H5Entry(self.h5_file, path, mode=\"w\", metadata=metadata)\n+        self._h5_entry_path = path\n+        self.make_entry(path, metadata=metadata)\n+        return self\n \n     def get(self, path):\n-        return H5Entry(self.h5_file, path, mode=\"r\")\n+        self._h5_entry_path = path\n+        self.make_entry(path)\n+        return self\n \n     def close(self):\n         self.h5_file.close()\n         if self.mode == \"w\" and self.archive:\n-            self.archive.writestr(self.root_path, self.io_file.getvalue())\n+            self.archive.writestr(str(self.path_or_io), self.io_file.getvalue())\n         if self.io_file:\n             self.io_file.close()\n \n+    # H5 entry level methods.\n \n-class H5Entry:\n-    \"\"\"Leaf entry in a H5IOStore.\"\"\"\n-\n-    def __init__(self, h5_file, path, mode, metadata=None):\n-        self.h5_file = h5_file\n-        self.path = path\n-        self.mode = mode\n-        self.metadata = metadata\n-\n-        if mode == \"w\":\n-            if not path:\n-                self.group = self.h5_file.create_group(\"vars\")\n-            else:\n-                self.group = self.h5_file.create_group(self.path).create_group(\n-                    \"vars\"\n+    def make_entry(self, path, metadata=None):\n+        if not isinstance(metadata, (dict, type(None))):\n+            raise ValueError(\n+                f\"`metadata` should be a dict or `None`. Received: {metadata}\"\n             )\n-            if self.metadata:\n-                for k, v in self.metadata.items():\n-                    self.group.attrs[k] = v\n+\n+        if self.mode == \"w\":\n+            if not path:\n+                self._h5_entry_group = self.h5_file.create_group(\"vars\")\n             else:\n-            found = False\n+                self._h5_entry_group = self.h5_file.create_group(\n+                    path\n+                ).create_group(\"vars\")\n+            if metadata:\n+                for k, v in metadata.items():\n+                    self._h5_entry_group.attrs[k] = v\n+        else:\n+            self._h5_entry_group = {}  # Defaults to an empty dict if not found.\n             if not path:\n                 if \"vars\" in self.h5_file:\n-                    self.group = self.h5_file[\"vars\"]\n-                    found = True\n+                    self._h5_entry_group = self.h5_file[\"vars\"]\n             elif path in self.h5_file and \"vars\" in self.h5_file[path]:\n-                self.group = self.h5_file[path][\"vars\"]\n-                found = True\n+                self._h5_entry_group = self.h5_file[path][\"vars\"]\n             else:\n                 # No hit.\n                 # Fix for 2.13 compatibility\n@@ -1017,40 +1097,201 @@ class H5Entry:\n                     path = path.replace(\n                         \"layers\", \"_layer_checkpoint_dependencies\"\n                     )\n-                    self.path = path\n                     if path in self.h5_file and \"vars\" in self.h5_file[path]:\n-                        self.group = self.h5_file[path][\"vars\"]\n-                        found = True\n-            if not found:\n-                self.group = {}\n+                        self._h5_entry_group = self.h5_file[path][\"vars\"]\n \n     def __len__(self):\n-        return self.group.__len__()\n+        return self._h5_entry_group.__len__()\n \n     def keys(self):\n-        return self.group.keys()\n+        return self._h5_entry_group.keys()\n \n     def items(self):\n-        return self.group.items()\n+        return self._h5_entry_group.items()\n \n     def values(self):\n-        return self.group.values()\n+        return self._h5_entry_group.values()\n+\n+    def __getitem__(self, key):\n+        value = self._h5_entry_group[key]\n+        if (\n+            hasattr(value, \"attrs\")\n+            and \"dtype\" in value.attrs\n+            and value.attrs[\"dtype\"] == \"bfloat16\"\n+        ):\n+            value = np.array(value, dtype=ml_dtypes.bfloat16)\n+        return value\n \n     def __setitem__(self, key, value):\n         if self.mode != \"w\":\n             raise ValueError(\"Setting a value is only allowed in write mode.\")\n         value = backend.convert_to_numpy(value)\n         if backend.standardize_dtype(value.dtype) == \"bfloat16\":\n-            ds = self.group.create_dataset(key, data=value)\n+            ds = self._h5_entry_group.create_dataset(key, data=value)\n             ds.attrs[\"dtype\"] = \"bfloat16\"\n         else:\n-            self.group[key] = value\n+            self._h5_entry_group[key] = value\n \n-    def __getitem__(self, name):\n-        value = self.group[name]\n-        if \"dtype\" in value.attrs and value.attrs[\"dtype\"] == \"bfloat16\":\n-            value = np.array(value, dtype=ml_dtypes.bfloat16)\n-        return value\n+    def __delitem__(self, key):\n+        if self.mode != \"w\":\n+            raise ValueError(\"Deleting a value is only allowed in write mode.\")\n+        del self._h5_entry_group[key]\n+\n+    def __contains__(self, item):\n+        return item in self._h5_entry_group\n+\n+\n+class ShardedH5IOStore(H5IOStore):\n+    \"\"\"Sharded numerical variable store backed by HDF5.\n+\n+    Args:\n+        path_or_io: `str` or `pathlib.Path` object. The path where to save the\n+            model.\n+        max_shard_size: `int` or `float`. Maximum size in GB for each sharded\n+            file. If `None`, no sharding will be done. Defaults to `None`.\n+        archive: Optional `zipfile.ZipFile` object. If specified, the h5 file\n+            will be saved inside the archive and `path_or_io` will be used as\n+            the filename.\n+        mode: `str`. One of {'r', 'w'}. The mode to open the h5 file. Defaults\n+            to `\"r\"`.\n+    \"\"\"\n+\n+    def __init__(self, path_or_io, max_shard_size=5, archive=None, mode=\"r\"):\n+        if mode not in (\"w\", \"r\"):\n+            raise ValueError(\n+                f\"`mode` should be either 'w' or 'r'. Received: {mode}\"\n+            )\n+        if not isinstance(path_or_io, (str, pathlib.Path)):\n+            raise TypeError(\n+                \"`path_or_io` should be a `str`, `pathlib.Path` object. \"\n+                f\"Received: path_or_io={path_or_io} of type {type(path_or_io)}.\"\n+            )\n+        self.path = pathlib.Path(path_or_io)\n+        self.mode = mode\n+        self.archive = archive\n+        self.io_file = None\n+\n+        self.max_shard_size = float(max_shard_size)\n+        self.base_name = self.path.stem.replace(\".weights\", \"\")\n+\n+        if self.path.suffix != \".json\":\n+            method = \"Saving\" if self.mode == \"w\" else \"Loading\"\n+            new_path = self.path.with_suffix(\".json\")\n+            warnings.warn(\n+                f\"{method} sharded weights requires `*.json` as the \"\n+                f\"extension. The original path: {str(self.path)} will be \"\n+                f\"renamed to {str(new_path)}.\"\n+            )\n+            self.path = new_path\n+\n+        # Init H5 entry group.\n+        self._h5_entry_path = None\n+        self._h5_entry_group = {}\n+\n+        # Init shard parameters.\n+        self.current_shard_index = 0\n+        self.current_shard_size = 0\n+        self.total_shard_size = 0  # In bytes.\n+        self.current_shard_path = None\n+        if self.mode == \"w\":\n+            self.sharding_config = {\n+                \"metadata\": {\n+                    \"total_size\": 0,\n+                },\n+                \"weight_map\": {},\n+            }\n+        else:\n+            if self.archive:\n+                self.sharding_config = json.loads(\n+                    self.archive.open(str(self.path), \"r\").read()\n+                )\n+            else:\n+                with open(self.path, \"r\") as map_file:\n+                    self.sharding_config = json.load(map_file)\n+        self.h5_file = self._create_new_shard_file()\n+\n+    def make(self, path, metadata=None):\n+        h5_entry = super().make(path, metadata=metadata)\n+        self.sharding_config[\"weight_map\"][self._h5_entry_group.name] = (\n+            self.current_shard_path.name\n+        )\n+        return h5_entry\n+\n+    def get(self, path):\n+        if not path:\n+            parsed_path = \"/vars\"\n+        else:\n+            parsed_path = path\n+\n+        # If not found, check shard map and switch files.\n+        filename = self.sharding_config[\"weight_map\"].get(\n+            parsed_path\n+        ) or self.sharding_config[\"weight_map\"].get(\"/\" + parsed_path + \"/vars\")\n+\n+        if filename != self.current_shard_path.name:\n+            self.close()\n+            self.h5_file = self._get_h5_file(self.path.with_name(filename))\n+        return super().get(path)\n+\n+    def close(self):\n+        self.h5_file.close()\n+        if self.mode == \"w\":\n+            self.sharding_config[\"metadata\"][\"total_size\"] = (\n+                self.total_shard_size\n+            )\n+            json_str = json.dumps(self.sharding_config, indent=4)\n+            if self.archive:\n+                self.archive.writestr(str(self.path), json_str)\n+                self.archive.writestr(\n+                    str(self.current_shard_path), self.io_file.getvalue()\n+                )\n+            else:\n+                with open(self.path, \"w\") as f:\n+                    f.write(json_str)\n+        if self.io_file:\n+            self.io_file.close()\n+\n+    # Shard-specific methods.\n+\n+    def _create_new_shard_file(self):\n+        new_shard_path = (\n+            f\"{self.base_name}_{self.current_shard_index:05}.weights.h5\"\n+        )\n+        self.current_shard_index += 1\n+        self.current_shard_path = self.path.with_name(new_shard_path)\n+        return self._get_h5_file(self.current_shard_path)\n+\n+    # H5 entry level methods.\n+\n+    def __setitem__(self, key, value):\n+        # Accumulate `current_shard_size`.\n+        value = backend.convert_to_numpy(value)\n+        dtype = backend.standardize_dtype(value.dtype)\n+        weight_counts = math.prod(value.shape)\n+        per_param_size = dtype_utils.dtype_size(dtype)\n+        value_size = weight_counts * per_param_size / (8.0 * 1024**3)  # To GB.\n+        self.total_shard_size += weight_counts * per_param_size / 8  # In bytes.\n+        if value_size > self.max_shard_size:\n+            value_size_str = readable_memory_size(value_size * 1024**3)\n+            max_shard_size_str = readable_memory_size(\n+                self.max_shard_size * 1024**3\n+            )\n+            raise ValueError(\n+                f\"The size of {key} is {value_size_str} which \"\n+                f\"exceeds the maximum shard size {max_shard_size_str}. You \"\n+                \"can increase the `max_shard_size` parameter to accommodate \"\n+                \"the size.\"\n+            )\n+\n+        # Create a new shard if the current shard is full.\n+        self.current_shard_size += value_size\n+        if self.current_shard_size > self.max_shard_size:\n+            self.close()\n+            self.h5_file = self._create_new_shard_file()\n+            self.make(self._h5_entry_path)\n+            self.current_shard_size = value_size\n+\n+        super().__setitem__(key, value)\n \n \n class NpzIOStore:\n\n@@ -762,8 +762,51 @@ class SavingTest(testing.TestCase):\n         self.assertLen(model.layers, 3)  # Input + 2 Dense layers\n         self._test_inference_after_instantiation(model)\n \n+    @parameterized.named_parameters(\n+        (\"efficientnet_b0_512\", \"efficientnet_b0\", 1),  # Only 1 sharded file.\n+        (\"efficientnet_b0_10\", \"efficientnet_b0\", 0.01),\n+    )\n+    def test_weights_sharding(self, model_name, max_shard_size):\n+        from keras.src.applications import efficientnet\n+\n+        if backend.image_data_format() == \"channels_last\":\n+            shape = (224, 224, 3)\n+        else:\n+            shape = (3, 224, 224)\n+\n+        if model_name == \"efficientnet_b0\":\n+            model_fn = efficientnet.EfficientNetB0\n+\n+        temp_filepath = Path(\n+            os.path.join(self.get_temp_dir(), \"mymodel.weights.json\")\n+        )\n+        model = model_fn(weights=None, input_shape=shape)\n+        ref_input = np.random.random((1, *shape)).astype(\"float32\")\n+        ref_output = model.predict(ref_input)\n+\n+        # Save the sharded files.\n+        saving_lib.save_weights_only(\n+            model, temp_filepath, max_shard_size=max_shard_size\n+        )\n+        self.assertIn(\"mymodel.weights.json\", os.listdir(temp_filepath.parent))\n+        if max_shard_size == 512:\n+            # 1 sharded file + 1 config file = 2.\n+            self.assertLen(os.listdir(temp_filepath.parent), 2)\n+        elif max_shard_size == 10:\n+            # 3 sharded file + 1 config file = 4.\n+            self.assertLen(os.listdir(temp_filepath.parent), 4)\n+\n+        with open(temp_filepath, \"r\") as f:\n+            sharding_config = json.load(f)\n+        self.assertIn(\"metadata\", sharding_config)\n+        self.assertIn(\"weight_map\", sharding_config)\n+\n+        # Instantiate new model and load the sharded files.\n+        model = model_fn(weights=None, input_shape=shape)\n+        saving_lib.load_weights_only(model, temp_filepath)\n+        self.assertAllClose(model.predict(ref_input), ref_output, atol=1e-6)\n+\n \n-@pytest.mark.requires_trainable_backend\n class SavingAPITest(testing.TestCase):\n     def test_saving_api_errors(self):\n         from keras.src.saving import saving_api\n@@ -1101,3 +1144,194 @@ class SavingBattleTest(testing.TestCase):\n             model = _get_basic_functional_model()\n             model.save_weights(temp_filepath)\n             model.load_weights(temp_filepath)\n+\n+\n+class SavingH5IOStoreTest(testing.TestCase):\n+    def test_h5_io_store_basics(self):\n+        temp_filepath = Path(os.path.join(self.get_temp_dir(), \"store.h5\"))\n+\n+        # Pre-defined data.\n+        a = np.random.random((2, 4)).astype(\"float32\")\n+        b = np.random.random((4, 8)).astype(\"int32\")\n+\n+        # Set.\n+        store = saving_lib.H5IOStore(temp_filepath, mode=\"w\")\n+        vars_store = store.make(\"vars\")\n+        vars_store[\"a\"] = a\n+        vars_store[\"b\"] = b\n+        vars_store[\"c\"] = 42\n+        self.assertAllClose(vars_store[\"a\"], a)\n+        self.assertAllClose(vars_store[\"b\"], b)\n+        self.assertEqual(int(vars_store[\"c\"][()]), 42)\n+\n+        # Delete.\n+        del vars_store[\"c\"]\n+\n+        # Contain.\n+        self.assertNotIn(\"c\", vars_store)\n+\n+        store.close()\n+        self.assertTrue(os.path.exists(temp_filepath))\n+\n+        # Get.\n+        store = saving_lib.H5IOStore(temp_filepath, mode=\"r\")\n+        vars_store = store.get(\"vars\")\n+        self.assertAllClose(vars_store[\"a\"], a)\n+        self.assertAllClose(vars_store[\"b\"], b)\n+        self.assertNotIn(\"c\", vars_store)\n+\n+    def test_h5_io_store_lora(self):\n+        # For `keras_hub.models.backbone.save_lora_weights` and\n+        # `keras_hub.models.backbone.load_lora_weights`\n+        temp_filepath = Path(os.path.join(self.get_temp_dir(), \"layer.lora.h5\"))\n+        layer = keras.layers.Dense(units=16)\n+        layer.build((None, 8))\n+        layer.enable_lora(4)\n+\n+        ref_input = np.random.random((1, 8)).astype(\"float32\")\n+        ref_output = layer(ref_input)\n+\n+        # Save the LoRA weights.\n+        store = saving_lib.H5IOStore(temp_filepath, mode=\"w\")\n+        lora_store = store.make(\"lora\")\n+        lora_store[\"rank\"] = layer.lora_rank\n+        inner_store = store.make(\"lora/0\")\n+        inner_store[\"lora_kernel_a\"] = layer.lora_kernel_a\n+        inner_store[\"lora_kernel_b\"] = layer.lora_kernel_b\n+        store.close()\n+\n+        # Load the LoRA weights.\n+        revived_layer = keras.layers.Dense(units=16)\n+        revived_layer.build((None, 8))\n+        store = saving_lib.H5IOStore(temp_filepath, mode=\"r\")\n+        lora_store = store.get(\"lora\")\n+        revived_layer.enable_lora(int(lora_store[\"rank\"][()]))\n+        lora_kernel_a = store.get(\"lora/0\")[\"lora_kernel_a\"]\n+        lora_kernel_b = store.get(\"lora/0\")[\"lora_kernel_b\"]\n+        revived_layer._kernel.assign(layer._kernel)\n+        revived_layer.bias.assign(layer.bias)\n+        revived_layer.lora_kernel_a.assign(lora_kernel_a)\n+        revived_layer.lora_kernel_b.assign(lora_kernel_b)\n+        self.assertAllClose(revived_layer(ref_input), ref_output, atol=1e-6)\n+\n+    def test_h5_io_store_exception_raised(self):\n+        temp_filepath = Path(os.path.join(self.get_temp_dir(), \"store.h5\"))\n+\n+        # Bad `path_or_io`.\n+        with self.assertRaisesRegex(\n+            TypeError,\n+            (\n+                r\"`path_or_io` should be a `str`, `pathlib.Path` or \"\n+                r\"`io.BytesIO` object.\"\n+            ),\n+        ):\n+            saving_lib.H5IOStore(None, mode=\"w\")\n+\n+        # Bad `mode`.\n+        with self.assertRaisesRegex(\n+            ValueError, r\"`mode` should be either 'w' or 'r'.\"\n+        ):\n+            saving_lib.H5IOStore(temp_filepath, mode=\"x\")\n+\n+        # No archive when using `io.BytesIO` as `path_or_io`.\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            (\n+                r\"When `path_or_io` is an `io.BytesIO` object, `archive` \"\n+                r\"should be `None`.\"\n+            ),\n+        ):\n+            saving_lib.H5IOStore(BytesIO(), archive=\"archive\", mode=\"w\")\n+\n+        store = saving_lib.H5IOStore(temp_filepath, mode=\"w\")\n+\n+        # Bad `metadata`.\n+        with self.assertRaisesRegex(\n+            ValueError, r\"`metadata` should be a dict or `None`.\"\n+        ):\n+            store.make(\"vars\", metadata=\"metadata\")\n+\n+        store.close()\n+\n+        store = saving_lib.H5IOStore(temp_filepath, mode=\"r\")\n+        vars_store = store.get(\"vars\")\n+\n+        # Set in read mode.\n+        with self.assertRaisesRegex(\n+            ValueError, r\"Setting a value is only allowed in write mode.\"\n+        ):\n+            vars_store[\"weights\"] = np.random.random((2, 4)).astype(\"float32\")\n+\n+        # Delete in read mode.\n+        with self.assertRaisesRegex(\n+            ValueError, r\"Deleting a value is only allowed in write mode.\"\n+        ):\n+            del vars_store[\"weights\"]\n+\n+    def test_sharded_h5_io_store_basics(self):\n+        name = \"sharded_store\"\n+        temp_filepath = Path(os.path.join(self.get_temp_dir(), f\"{name}.json\"))\n+\n+        # Pre-defined data.\n+        a = np.random.random((2, 4)).astype(\"float32\")\n+        b = np.random.random((4, 8)).astype(\"int32\")\n+\n+        # Set.\n+        store = saving_lib.ShardedH5IOStore(temp_filepath, mode=\"w\")\n+        vars_store = store.make(\"vars\")\n+        vars_store[\"a\"] = a\n+        vars_store[\"b\"] = b\n+        vars_store[\"c\"] = 42\n+        self.assertAllClose(vars_store[\"a\"], a)\n+        self.assertAllClose(vars_store[\"b\"], b)\n+        self.assertEqual(int(vars_store[\"c\"][()]), 42)\n+\n+        # Delete.\n+        del vars_store[\"c\"]\n+\n+        # Contain.\n+        self.assertNotIn(\"c\", vars_store)\n+\n+        store.close()\n+        self.assertTrue(os.path.exists(temp_filepath))\n+        self.assertTrue(\n+            os.path.exists(temp_filepath.with_name(f\"{name}_00000.weights.h5\"))\n+        )\n+\n+        # Get.\n+        store = saving_lib.ShardedH5IOStore(temp_filepath, mode=\"r\")\n+        vars_store = store.get(\"vars\")\n+        self.assertAllClose(vars_store[\"a\"], a)\n+        self.assertAllClose(vars_store[\"b\"], b)\n+        self.assertNotIn(\"c\", vars_store)\n+\n+    def test_sharded_h5_io_store_exception_raised(self):\n+        temp_filepath = Path(os.path.join(self.get_temp_dir(), \"store.h5\"))\n+\n+        # Bad `path_or_io`.\n+        with self.assertRaisesRegex(\n+            TypeError,\n+            r\"`path_or_io` should be a `str`, `pathlib.Path` object. \",\n+        ):\n+            saving_lib.ShardedH5IOStore(None, mode=\"w\")\n+\n+        # Bad `mode`.\n+        with self.assertRaisesRegex(\n+            ValueError, r\"`mode` should be either 'w' or 'r'.\"\n+        ):\n+            saving_lib.ShardedH5IOStore(temp_filepath, mode=\"x\")\n+\n+        store = saving_lib.ShardedH5IOStore(\n+            temp_filepath, max_shard_size=0.00001, mode=\"w\"\n+        )\n+        vars_store = store.make(\"vars\")\n+\n+        # Too large data.\n+        with self.assertRaisesRegex(\n+            ValueError, r\"exceeds the maximum shard size\"\n+        ):\n+            vars_store[\"weights\"] = np.random.random((100, 100)).astype(\n+                \"float32\"\n+            )\n+\n+        store.close()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
