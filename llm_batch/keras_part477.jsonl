{"custom_id": "keras#2180f3c82a76519f8abbcfe5ff1f7b7da9866bf6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 19733 | Contributors (this commit): 132 | Commits (past 90d): 32 | Contributors (cumulative): 132 | DMM Complexity: None\n\nDIFF:\n@@ -3820,7 +3820,7 @@ def reduce_per_replica(values, strategy, reduction=\"first\"):\n             return tf.reduce_sum(values)\n         else:\n             raise ValueError(\n-                '`reduction` must be \"first\" or \"concat\" or \"sum\". Received: '\n+                '`reduction` must be \"first\", \"concat\", or \"sum\". Received: '\n                 f\"reduction={reduction}.\"\n             )\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1c9240f6ef9ce4805329eeacfa33f4feb5262869", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 46 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 4 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 46 | Churn Cumulative: 8351 | Contributors (this commit): 18 | Commits (past 90d): 12 | Contributors (cumulative): 18 | DMM Complexity: 1.0\n\nDIFF:\n@@ -145,6 +145,52 @@ class TrainingTest(test_combinations.TestCase):\n         model.evaluate(x, y)\n         model.predict(x)\n \n+    @test_combinations.run_all_keras_modes(always_skip_v1=True)\n+    def test_distribution_reduction_method_sum(self):\n+\n+        strategy = tf.distribute.MirroredStrategy([\"/cpu:1\", \"/cpu:2\"])\n+        BATCH_SIZE = 10\n+\n+        class MyModel(training_module.Model):\n+            @staticmethod\n+            def reduce_loss(loss_value, global_batch_size):\n+                REDUCTION_AXES = range(1, backend.ndim(loss_value))\n+                loss_value = tf.reduce_mean(loss_value, axis=REDUCTION_AXES)\n+                return tf.nn.compute_average_loss(\n+                    loss_value, global_batch_size=global_batch_size\n+                )\n+\n+            def train_step(self, data):\n+                loss_value = tf.ones_like(data[0])\n+                return {\n+                    \"loss\": MyModel.reduce_loss(\n+                        loss_value, global_batch_size=BATCH_SIZE\n+                    )\n+                }\n+\n+            def test_step(self, data):\n+                loss_value = tf.ones_like(data[0])\n+                return {\n+                    \"metric\": MyModel.reduce_loss(\n+                        loss_value, global_batch_size=BATCH_SIZE\n+                    )\n+                }\n+\n+        with strategy.scope():\n+            inputs = layers_module.Input(shape=(1,), name=\"my_input\")\n+            outputs = layers_module.Dense(1)(inputs)\n+            model = MyModel(inputs, outputs)\n+\n+        model.distribute_reduction_method = \"sum\"\n+        model.compile()\n+\n+        x, y = np.ones((40, 1)), np.ones((40, 1))\n+        history = model.fit(x, y, epochs=2, batch_size=BATCH_SIZE)\n+        self.assertAllClose(history.history[\"loss\"][-1], 1.0)\n+\n+        eval_output = model.evaluate(x, y, batch_size=BATCH_SIZE)\n+        self.assertAllClose(eval_output, 1.0)\n+\n     @test_combinations.run_all_keras_modes(always_skip_v1=True)\n     def test_verify_xla_compile_with_jit_compile(self):\n         vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cd1e5ca34d124a9bfcb0b4981ed88dfe8b7cbf8b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 8357 | Contributors (this commit): 18 | Commits (past 90d): 14 | Contributors (cumulative): 18 | DMM Complexity: 1.0\n\nDIFF:\n@@ -148,7 +148,9 @@ class TrainingTest(test_combinations.TestCase):\n     @test_combinations.run_all_keras_modes(always_skip_v1=True)\n     def test_distribution_reduction_method_sum(self):\n \n-        strategy = tf.distribute.MirroredStrategy([\"/cpu:1\", \"/cpu:2\", \"/cpu:3\", \"/cpu:4\"])\n+        strategy = tf.distribute.MirroredStrategy(\n+            [\"/cpu:1\", \"/cpu:2\", \"/cpu:3\", \"/cpu:4\"]\n+        )\n         BATCH_SIZE = 10\n \n         class MyModel(training_module.Model):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bffa98320579106d90c264fb7f1f456b9949eb45", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 16 | Files Changed: 5 | Hunks: 9 | Methods Changed: 7 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 25 | Churn Cumulative: 3232 | Contributors (this commit): 13 | Commits (past 90d): 39 | Contributors (cumulative): 36 | DMM Complexity: 1.0\n\nDIFF:\n@@ -193,5 +193,5 @@ def get(identifier):\n         return deserialize(config)\n     else:\n         raise ValueError(\n-            \"Could not interpret optimizer identifier: {}\".format(identifier)\n+            f\"Could not interpret optimizer identifier: {identifier}\"\n         )\n\n@@ -49,7 +49,7 @@ class Optimizer:\n             # checks that clipnorm >= 0 and clipvalue >= 0\n             if kwargs[k] < 0:\n                 raise ValueError(\n-                    \"Expected {} >= 0, received: {}\".format(k, kwargs[k])\n+                    f\"Expected {k} >= 0, received: {kwargs[k]}\"\n                 )\n         self.__dict__.update(kwargs)\n         self.updates = []\n\n@@ -375,7 +375,7 @@ class OptimizerV2(tf.__internal__.tracking.Trackable):\n             # checks that all keyword arguments are non-negative.\n             if kwargs[k] is not None and kwargs[k] < 0:\n                 raise ValueError(\n-                    \"Expected {} >= 0, received: {}\".format(k, kwargs[k])\n+                    f\"Expected {k} >= 0, received: {kwargs[k]}\"\n                 )\n             if k == \"lr\":\n                 warnings.warn(\n@@ -404,8 +404,7 @@ class OptimizerV2(tf.__internal__.tracking.Trackable):\n         decay = kwargs.pop(\"decay\", 0.0)\n         if decay < 0.0:\n             raise ValueError(\n-                \"decay cannot be less than 0. \"\n-                \"Received: decay={}.\".format(decay)\n+                f\"decay cannot be less than 0. Received: decay={decay}.\"\n             )\n         self._initial_decay = decay\n \n@@ -1051,11 +1050,7 @@ class OptimizerV2(tf.__internal__.tracking.Trackable):\n \n                 with strategy.extended.colocate_vars_with(var):\n                     weight = tf.Variable(\n-                        name=\"%s/%s\"\n-                        % (\n-                            var._shared_name,\n-                            slot_name,\n-                        ),\n+                        name=f\"{var._shared_name}/{slot_name}\",\n                         dtype=var.dtype,\n                         trainable=False,\n                         initial_value=initial_value,\n\n@@ -1230,9 +1230,7 @@ def topological_sort(graph):\n     # Check correctness.\n     if len(result) != len(graph_ops):\n         raise ValueError(\n-            \"Sort result has {} ops, source graph has {}.\".format(\n-                len(result), len(graph_ops)\n-            )\n+            f\"Sort result has {len(result)} ops, source graph has {len(graph_ops)}.\"\n         )\n \n     sort_check_seen = set()\n@@ -1318,7 +1316,7 @@ def identify_redundant_ops(graph):\n         num_duplicates += len(op_defs)\n         traceback = []\n         for level in op_defs[0].traceback:\n-            traceback.append(\"  {} {}:{}\".format(level[0], level[2], level[1]))\n+            traceback.append(f\"  {level[0]} {level[2]}:{level[1]}\")\n \n         duplicate_types.append(\n             \"# Example name: {}\\n# Op creation stack:\\n{}\\n{}\".format(\n\n@@ -802,11 +802,11 @@ class SlotColocationTest(tf.test.TestCase, parameterized.TestCase):\n         # Validate updated params, All variables should have decreased.\n         self.assertTrue(\n             all(v < 0.0 for v in self.evaluate(var0)),\n-            msg=\"updated variables: %s\" % self.evaluate(var0),\n+            msg=f\"updated variables: {self.evaluate(var0)}\",\n         )\n         self.assertTrue(\n             all(v < 2.0 for v in self.evaluate(var1)),\n-            msg=\"updated variables: %s\" % self.evaluate(var1),\n+            msg=f\"updated variables: {self.evaluate(var1)}\",\n         )\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#27aa44c7fa6c8dd617cc1ddeb5b7ccc8090a8976", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 32 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 4 | Complexity Δ (Sum/Max): 5/3 | Churn Δ: 32 | Churn Cumulative: 13252 | Contributors (this commit): 32 | Commits (past 90d): 26 | Contributors (cumulative): 42 | DMM Complexity: 1.0\n\nDIFF:\n@@ -3662,3 +3662,12 @@ class BaseRandomLayer(Layer):\n             children = {}\n         children.update(super()._trackable_children(save_type, **kwargs))\n         return children\n+\n+    def _lookup_dependency(self, name):\n+        # When loading from a Keras SavedModel load, make sure that the loader\n+        # can find the random generator, otherwise the loader will assume that\n+        # it does not exist, and will try to create a new generator.\n+        if name == \"_random_generator\":\n+            return self._random_generator\n+        else:\n+            return super()._lookup_dependency(name)\n\n@@ -1234,6 +1234,29 @@ class TestSavedModelFormat(tf.test.TestCase):\n         ):\n             keras_load.load(saved_model_dir)\n \n+    def test_random_generator_custom_layer(self):\n+        class CustomDropout(keras.layers.Layer):\n+            def __init__(self, dropout_rate=0.1, **kwargs):\n+                super().__init__(**kwargs)\n+                self.dropout_rate = dropout_rate\n+                self.dropout = keras.layers.Dropout(\n+                    dropout_rate, rng_type=\"stateful\"\n+                )\n+\n+            def call(self, inputs, training=False):\n+                return self.dropout(inputs, training=training)\n+\n+        root = keras.models.Sequential(\n+            [keras.layers.Input(shape=(3,)), CustomDropout()]\n+        )\n+        saved_model_dir = self._save_model_dir()\n+        root.save(saved_model_dir, save_format=\"tf\")\n+\n+        loaded = keras_load.load(saved_model_dir)\n+\n+        output = loaded(tf.random.uniform([1, 3]), training=True)\n+        self.assertAllEqual([1, 3], output.shape)\n+\n \n class TestLayerCallTracing(tf.test.TestCase, parameterized.TestCase):\n     def test_functions_have_same_trace(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#de088f8ddbec63ac3f21a5d0ac3d5717f8e3517f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 1974 | Contributors (this commit): 15 | Commits (past 90d): 9 | Contributors (cumulative): 15 | DMM Complexity: 0.25\n\nDIFF:\n@@ -255,6 +255,7 @@ class TextVectorization(base_preprocessing_layer.PreprocessingLayer):\n         idf_weights=None,\n         sparse=False,\n         ragged=False,\n+        encoding=None,\n         **kwargs,\n     ):\n \n@@ -365,6 +366,7 @@ class TextVectorization(base_preprocessing_layer.PreprocessingLayer):\n \n         self._output_mode = output_mode\n         self._output_sequence_length = output_sequence_length\n+        self._encoding = encoding\n \n         # VocabularySavedModelSaver will clear the config vocabulary to restore\n         # the lookup table ops directly. We persist this hidden option to\n@@ -391,6 +393,7 @@ class TextVectorization(base_preprocessing_layer.PreprocessingLayer):\n             output_mode=output_mode if output_mode is not None else INT,\n             sparse=sparse,\n             has_input_vocabulary=self._has_input_vocabulary,\n+            encoding=encoding,\n         )\n \n     def compute_output_shape(self, input_shape):\n@@ -510,6 +513,7 @@ class TextVectorization(base_preprocessing_layer.PreprocessingLayer):\n             \"ragged\": self._ragged,\n             \"vocabulary\": utils.listify_tensors(vocab),\n             \"idf_weights\": utils.listify_tensors(idf_weights),\n+            \"encoding\": self._encoding,\n         }\n         base_config = super().get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ba8c1a14f3154ad134e10ee3058a1a6dd1a95027", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 2 | Churn Cumulative: 10703 | Contributors (this commit): 19 | Commits (past 90d): 15 | Contributors (cumulative): 19 | DMM Complexity: None\n\nDIFF:\n@@ -1370,7 +1370,7 @@ def placeholder(\n         ragged: Boolean, whether the placeholder should have a ragged type.\n             In this case, values of 'None' in the 'shape' argument represent\n             ragged dimensions. For more information about RaggedTensors, see\n-            this [guide](https://www.tensorflow.org/guide/ragged_tensors).\n+            this [guide](https://www.tensorflow.org/guide/ragged_tensor).\n \n     Raises:\n         ValueError: If called with sparse = True and ragged = True.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#92cf82d82d8da7927491dabcd8fb27fb526a2368", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 16 | Files Changed: 1 | Hunks: 8 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 32 | Churn Cumulative: 350 | Contributors (this commit): 5 | Commits (past 90d): 7 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -95,22 +95,22 @@ class DepthwiseConv1D(DepthwiseConv):\n         `keras.constraints`).\n \n     Input shape:\n-      4D tensor with shape: `[batch_size, channels, rows, cols]` if\n-        data_format='channels_first'\n-      or 4D tensor with shape: `[batch_size, rows, cols, channels]` if\n+      3D tensor with shape: `[batch_size, channels, input_dims]` if\n+        data_format='channels_first'.\n+      or 3D tensor with shape: `[batch_size, input_dims, channels]` if\n         data_format='channels_last'.\n \n     Output shape:\n-      4D tensor with shape: `[batch_size, channels * depth_multiplier, new_rows,\n-        new_cols]` if `data_format='channels_first'`\n-        or 4D tensor with shape: `[batch_size,\n-        new_rows, new_cols, channels * depth_multiplier]` if\n-        `data_format='channels_last'`. `rows` and `cols` values might have\n+      3D tensor with shape: `[batch_size, channels * depth_multiplier, new_dims]`\n+        if `data_format='channels_first'`\n+        or 3D tensor with shape: `[batch_size,\n+        new_dims, channels * depth_multiplier]` if\n+        `data_format='channels_last'`. `new_dims` values might have\n         changed due to padding.\n \n     Returns:\n-      A tensor of rank 4 representing\n-      `activation(depthwiseconv2d(inputs, kernel) + bias)`.\n+      A tensor of rank 3 representing\n+      `activation(depthwiseconv1d(inputs, kernel) + bias)`.\n \n     Raises:\n       ValueError: if `padding` is \"causal\".\n@@ -197,20 +197,20 @@ class DepthwiseConv1D(DepthwiseConv):\n     @tf_utils.shape_type_conversion\n     def compute_output_shape(self, input_shape):\n         if self.data_format == \"channels_first\":\n-            rows = input_shape[2]\n+            input_dims = input_shape[2]\n             out_filters = input_shape[1] * self.depth_multiplier\n         elif self.data_format == \"channels_last\":\n-            rows = input_shape[1]\n+            input_dims = input_shape[1]\n             out_filters = input_shape[2] * self.depth_multiplier\n \n-        rows = conv_utils.conv_output_length(\n-            rows,\n+        input_dims = conv_utils.conv_output_length(\n+            input_dims,\n             self.kernel_size[0],\n             self.padding,\n             self.strides[0],\n             self.dilation_rate[0],\n         )\n         if self.data_format == \"channels_first\":\n-            return (input_shape[0], out_filters, rows)\n+            return (input_shape[0], out_filters, input_dims)\n         elif self.data_format == \"channels_last\":\n-            return (input_shape[0], rows, out_filters)\n+            return (input_shape[0], input_dims, out_filters)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d047f98b64a408779888aaa8d8713004553c9e1b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 352 | Contributors (this commit): 5 | Commits (past 90d): 8 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -96,7 +96,7 @@ class DepthwiseConv1D(DepthwiseConv):\n \n     Input shape:\n       3D tensor with shape: `[batch_size, channels, input_dims]` if\n-        data_format='channels_first'.\n+        data_format='channels_first'\n       or 3D tensor with shape: `[batch_size, input_dims, channels]` if\n         data_format='channels_last'.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#feb5969cd1b50e7bd25ce5458547b47023974c8c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 10763 | Contributors (this commit): 19 | Commits (past 90d): 24 | Contributors (cumulative): 24 | DMM Complexity: None\n\nDIFF:\n@@ -1815,7 +1815,7 @@ def identity(x, name=None):\n # tf.random.Generator to generate random numbers.\n # The legacy behavior is to use TF's legacy stateful RNG ops like\n # tf.random.uniform.\n-_USE_GENERATOR_FOR_RNG = False\n+_USE_GENERATOR_FOR_RNG = True\n \n # The global generator to create the seed when initializing the\n # tf.random.Genrator used by RandomGenerator. When tf.random.Generator becomes\n\n@@ -43,7 +43,7 @@ class Dropout(base_layer.BaseRandomLayer):\n     `trainable` does not affect the layer's behavior, as Dropout does\n     not have any variables/weights that can be frozen during training.)\n \n-    >>> tf.random.set_seed(0)\n+    >>> tf.keras.utils.set_random_seed(0)\n     >>> layer = tf.keras.layers.Dropout(.2, input_shape=(2,))\n     >>> data = np.arange(10).reshape(5, 2).astype(np.float32)\n     >>> print(data)\n@@ -56,7 +56,7 @@ class Dropout(base_layer.BaseRandomLayer):\n     >>> print(outputs)\n     tf.Tensor(\n     [[ 0.    1.25]\n-     [ 2.5   3.75]\n+     [ 0.    3.75]\n      [ 5.    6.25]\n      [ 7.5   8.75]\n      [10.    0.  ]], shape=(5, 2), dtype=float32)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#81277c072a7d77811450eeeeeb7092f069188977", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 9 | Files Changed: 1 | Hunks: 8 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 19 | Churn Cumulative: 371 | Contributors (this commit): 6 | Commits (past 90d): 9 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -95,13 +95,14 @@ class DepthwiseConv1D(DepthwiseConv):\n         `keras.constraints`).\n \n     Input shape:\n-      3D tensor with shape: `[batch_size, channels, input_dims]` if\n+      3D tensor with shape: `[batch_size, channels, input_dim]` if\n         data_format='channels_first'\n-      or 3D tensor with shape: `[batch_size, input_dims, channels]` if\n+      or 3D tensor with shape: `[batch_size, input_dim, channels]` if\n         data_format='channels_last'.\n \n     Output shape:\n-      3D tensor with shape: `[batch_size, channels * depth_multiplier, new_dims]`\n+      3D tensor with shape:\n+       `[batch_size, channels * depth_multiplier, new_dims]`\n         if `data_format='channels_first'`\n         or 3D tensor with shape: `[batch_size,\n         new_dims, channels * depth_multiplier]` if\n@@ -197,20 +198,20 @@ class DepthwiseConv1D(DepthwiseConv):\n     @tf_utils.shape_type_conversion\n     def compute_output_shape(self, input_shape):\n         if self.data_format == \"channels_first\":\n-            input_dims = input_shape[2]\n+            input_dim = input_shape[2]\n             out_filters = input_shape[1] * self.depth_multiplier\n         elif self.data_format == \"channels_last\":\n-            input_dims = input_shape[1]\n+            input_dim = input_shape[1]\n             out_filters = input_shape[2] * self.depth_multiplier\n \n-        input_dims = conv_utils.conv_output_length(\n-            input_dims,\n+        input_dim = conv_utils.conv_output_length(\n+            input_dim,\n             self.kernel_size[0],\n             self.padding,\n             self.strides[0],\n             self.dilation_rate[0],\n         )\n         if self.data_format == \"channels_first\":\n-            return (input_shape[0], out_filters, input_dims)\n+            return (input_shape[0], out_filters, input_dim)\n         elif self.data_format == \"channels_last\":\n-            return (input_shape[0], input_dims, out_filters)\n+            return (input_shape[0], input_dim, out_filters)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#78b7824353308d73a8fe04c5bd0bd94577aeefdc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 10769 | Contributors (this commit): 19 | Commits (past 90d): 26 | Contributors (cumulative): 24 | DMM Complexity: None\n\nDIFF:\n@@ -1815,7 +1815,7 @@ def identity(x, name=None):\n # tf.random.Generator to generate random numbers.\n # The legacy behavior is to use TF's legacy stateful RNG ops like\n # tf.random.uniform.\n-_USE_GENERATOR_FOR_RNG = True\n+_USE_GENERATOR_FOR_RNG = False\n \n # The global generator to create the seed when initializing the\n # tf.random.Genrator used by RandomGenerator. When tf.random.Generator becomes\n\n@@ -43,7 +43,7 @@ class Dropout(base_layer.BaseRandomLayer):\n     `trainable` does not affect the layer's behavior, as Dropout does\n     not have any variables/weights that can be frozen during training.)\n \n-    >>> tf.keras.utils.set_random_seed(0)\n+    >>> tf.random.set_seed(0)\n     >>> layer = tf.keras.layers.Dropout(.2, input_shape=(2,))\n     >>> data = np.arange(10).reshape(5, 2).astype(np.float32)\n     >>> print(data)\n@@ -56,7 +56,7 @@ class Dropout(base_layer.BaseRandomLayer):\n     >>> print(outputs)\n     tf.Tensor(\n     [[ 0.    1.25]\n-     [ 0.    3.75]\n+     [ 2.5   3.75]\n      [ 5.    6.25]\n      [ 7.5   8.75]\n      [10.    0.  ]], shape=(5, 2), dtype=float32)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bf836aa4d897a192b0b354a83aae6322c8cb1825", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 10 | Files Changed: 3 | Hunks: 6 | Methods Changed: 9 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 17 | Churn Cumulative: 2468 | Contributors (this commit): 11 | Commits (past 90d): 28 | Contributors (cumulative): 25 | DMM Complexity: 0.3333333333333333\n\nDIFF:\n@@ -48,9 +48,7 @@ class Optimizer:\n                 )\n             # checks that clipnorm >= 0 and clipvalue >= 0\n             if kwargs[k] < 0:\n-                raise ValueError(\n-                    f\"Expected {k} >= 0, received: {kwargs[k]}\"\n-                )\n+                raise ValueError(f\"Expected {k} >= 0, received: {kwargs[k]}\")\n         self.__dict__.update(kwargs)\n         self.updates = []\n         self.weights = []\n@@ -521,7 +519,7 @@ class Adam(Optimizer):\n         epsilon=None,\n         decay=0.0,\n         amsgrad=False,\n-        **kwargs\n+        **kwargs,\n     ):\n         super().__init__(**kwargs)\n         with backend.name_scope(self.__class__.__name__):\n@@ -637,7 +635,7 @@ class Adamax(Optimizer):\n         beta_2=0.999,\n         epsilon=None,\n         decay=0.0,\n-        **kwargs\n+        **kwargs,\n     ):\n         super().__init__(**kwargs)\n         with backend.name_scope(self.__class__.__name__):\n@@ -739,7 +737,7 @@ class Nadam(Optimizer):\n         beta_2=0.999,\n         epsilon=None,\n         schedule_decay=0.004,\n-        **kwargs\n+        **kwargs,\n     ):\n         super().__init__(**kwargs)\n         with backend.name_scope(self.__class__.__name__):\n\n@@ -374,9 +374,7 @@ class OptimizerV2(tf.__internal__.tracking.Trackable):\n                 )\n             # checks that all keyword arguments are non-negative.\n             if kwargs[k] is not None and kwargs[k] < 0:\n-                raise ValueError(\n-                    f\"Expected {k} >= 0, received: {kwargs[k]}\"\n-                )\n+                raise ValueError(f\"Expected {k} >= 0, received: {kwargs[k]}\")\n             if k == \"lr\":\n                 warnings.warn(\n                     \"The `lr` argument is deprecated, \"\n\n@@ -1230,7 +1230,8 @@ def topological_sort(graph):\n     # Check correctness.\n     if len(result) != len(graph_ops):\n         raise ValueError(\n-            f\"Sort result has {len(result)} ops, source graph has {len(graph_ops)}.\"\n+            f\"Sort result has {len(result)} ops, \"\n+            f\"source graph has {len(graph_ops)}.\"\n         )\n \n     sort_check_seen = set()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e46ca53e175ec800f1f2267f5d769dc38e9d31be", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 34 | Contributors (this commit): 5 | Commits (past 90d): 2 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -14,9 +14,9 @@\n # ==============================================================================\n \"\"\"Learning rate schedule API.\"\"\"\n \n-from keras.optimizers.schedules.learning_rate_schedules import ExponentialDecay\n-from keras.optimizers.schedules.learning_rate_schedules import InverseTimeDecay\n-from keras.optimizers.schedules.learning_rate_schedules import (\n+from keras.optimizers.schedules.learning_rate_schedule import ExponentialDecay\n+from keras.optimizers.schedules.learning_rate_schedule import InverseTimeDecay\n+from keras.optimizers.schedules.learning_rate_schedule import (\n     PiecewiseConstantDecay,\n )\n-from keras.optimizers.schedules.learning_rate_schedules import PolynomialDecay\n+from keras.optimizers.schedules.learning_rate_schedule import PolynomialDecay\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#55a712dbc99304a5a0a08e08289944704e338d59", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 12/12 | Churn Δ: 4 | Churn Cumulative: 2904 | Contributors (this commit): 39 | Commits (past 90d): 13 | Contributors (cumulative): 39 | DMM Complexity: None\n\nDIFF:\n@@ -169,8 +169,8 @@ def get_layer_index_bound_by_layer_name(model, layer_range=None):\n \n     if not lower_index or not upper_index:\n         raise ValueError(\n-            \"Passed layer_names does not match the layer names in the model. \"\n-            f\"Recieved: {layer_range}\"\n+            \"Passed layer_names do not match the layer names in the model. \"\n+            f\"Received: {layer_range}\"\n         )\n \n     if min(lower_index) > max(upper_index):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d32ff6ce318d53fa16a4acd52ac8a28d1c291f30", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 3098 | Contributors (this commit): 13 | Commits (past 90d): 6 | Contributors (cumulative): 13 | DMM Complexity: None\n\nDIFF:\n@@ -188,7 +188,7 @@ def NASNet(\n         default_size=default_size,\n         min_size=32,\n         data_format=backend.image_data_format(),\n-        require_flatten=True,\n+        require_flatten=include_top,\n         weights=weights,\n     )\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4edc0d7e240f2468d0de1d368a27f01c2ba17e04", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 3121 | Contributors (this commit): 17 | Commits (past 90d): 18 | Contributors (cumulative): 27 | DMM Complexity: None\n\nDIFF:\n@@ -123,6 +123,7 @@ class StringLookup(index_lookup.IndexLookup):\n       sparse: Boolean. Only applicable when `output_mode` is `\"multi_hot\"`,\n         `\"count\"`, or `\"tf_idf\"`. If True, returns a `SparseTensor` instead of a\n         dense `Tensor`. Defaults to False.\n+      encoding: Optional. A string representing the encoding to use. Defaults to `\"utf-8\"`.\n \n     Examples:\n \n\n@@ -174,6 +174,7 @@ class TextVectorization(base_preprocessing_layer.PreprocessingLayer):\n       sparse: Boolean. Only applicable to `\"multi_hot\"`, `\"count\"`, and\n         `\"tf_idf\"` output modes. If True, returns a `SparseTensor` instead of a\n         dense `Tensor`. Defaults to False.\n+      encoding: Optional. A string representing the encoding to use. Defaults to `\"utf-8\"`.\n \n     Example:\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ee1ada0bac06442ed81bdff1f98b364b985956e7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 3 | Methods Changed: 4 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 7 | Churn Cumulative: 3128 | Contributors (this commit): 17 | Commits (past 90d): 20 | Contributors (cumulative): 27 | DMM Complexity: 0.0\n\nDIFF:\n@@ -313,7 +313,7 @@ class StringLookup(index_lookup.IndexLookup):\n         oov_token=\"[UNK]\",\n         vocabulary=None,\n         idf_weights=None,\n-        encoding=None,\n+        encoding=\"utf-8\",\n         invert=False,\n         output_mode=\"int\",\n         sparse=False,\n@@ -327,9 +327,6 @@ class StringLookup(index_lookup.IndexLookup):\n         ):\n             del kwargs[\"dtype\"]\n \n-        if encoding is None:\n-            encoding = \"utf-8\"\n-\n         self.encoding = encoding\n \n         super().__init__(\n\n@@ -256,7 +256,7 @@ class TextVectorization(base_preprocessing_layer.PreprocessingLayer):\n         idf_weights=None,\n         sparse=False,\n         ragged=False,\n-        encoding=None,\n+        encoding=\"utf-8\",\n         **kwargs,\n     ):\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6e17a412f43b7182f53d1ca4966f2d24e6c19af2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 3134 | Contributors (this commit): 17 | Commits (past 90d): 22 | Contributors (cumulative): 27 | DMM Complexity: None\n\nDIFF:\n@@ -123,7 +123,8 @@ class StringLookup(index_lookup.IndexLookup):\n       sparse: Boolean. Only applicable when `output_mode` is `\"multi_hot\"`,\n         `\"count\"`, or `\"tf_idf\"`. If True, returns a `SparseTensor` instead of a\n         dense `Tensor`. Defaults to False.\n-      encoding: Optional. A string representing the encoding to use. Defaults to `\"utf-8\"`.\n+      encoding: Optional. A string representing the encoding to use. Defaults to \n+        `\"utf-8\"`.\n \n     Examples:\n \n\n@@ -174,7 +174,8 @@ class TextVectorization(base_preprocessing_layer.PreprocessingLayer):\n       sparse: Boolean. Only applicable to `\"multi_hot\"`, `\"count\"`, and\n         `\"tf_idf\"` output modes. If True, returns a `SparseTensor` instead of a\n         dense `Tensor`. Defaults to False.\n-      encoding: Optional. A string representing the encoding to use. Defaults to `\"utf-8\"`.\n+      encoding: Optional. A string representing the encoding to use. Defaults to \n+        `\"utf-8\"`.\n \n     Example:\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4a89bb6ced975a2cf339725af721268cecd94c22", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 518 | Contributors (this commit): 8 | Commits (past 90d): 8 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -32,7 +32,7 @@ class AdamW(optimizer.Optimizer):\n \n     AdamW optimization is a stochastic gradient descent method that is based on\n     adaptive estimation of first-order and second-order moments with an added\n-    method to decay weights per the techniques discussed in the paeper,\n+    method to decay weights per the techniques discussed in the paper,\n     'Decoupled Weight Decay Regularization' by\n     [Loshchilov, Hutter et al., 2019](https://arxiv.org/abs/1711.05101).\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e7b31f4409b73d3153c07494f7dc8e03f48fb1a7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 10 | Churn Cumulative: 406 | Contributors (this commit): 9 | Commits (past 90d): 6 | Contributors (cumulative): 9 | DMM Complexity: 1.0\n\nDIFF:\n@@ -176,6 +176,16 @@ class ApplicationsTest(tf.test.TestCase, parameterized.TestCase):\n             self.assertShapeEqual(output_shape, (None, None, None, last_dim))\n         backend.clear_session()\n \n+    @parameterized.parameters(*MODEL_LIST)\n+    def test_application_notop_custom_input_shape(self, app, last_dim):\n+        output_shape = _get_output_shape(\n+            lambda: app(\n+                weights=None, include_top=False, input_shape=(224, 224, 3)\n+            )\n+        )\n+\n+        self.assertEqual(output_shape[-1], last_dim)\n+\n     @parameterized.parameters(MODEL_LIST)\n     def test_application_pooling(self, app, last_dim):\n         output_shape = _get_output_shape(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#90700cef91c88a000d150e286821205fceef5ff1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 74 | Lines Deleted: 38 | Files Changed: 7 | Hunks: 27 | Methods Changed: 14 | Complexity Δ (Sum/Max): -6/4 | Churn Δ: 112 | Churn Cumulative: 31116 | Contributors (this commit): 137 | Commits (past 90d): 79 | Contributors (cumulative): 187 | DMM Complexity: 0.5714285714285714\n\nDIFF:\n@@ -19,6 +19,9 @@ import tensorflow.compat.v2 as tf\n # isort: off\n from tensorflow.python.platform import tf_logging as logging\n from tensorflow.python.util import deprecation\n+from keras.optimizers.optimizer_experimental import (\n+    optimizer as optimizer_experimental,\n+)\n from tensorflow.python.util.tf_export import keras_export\n \n _PRINT_EVAL_STEP_EVERY_SEC = 60.0\n@@ -201,11 +204,15 @@ class SidecarEvaluator:\n \n     def start(self):\n         \"\"\"Starts the evaluation loop.\"\"\"\n+        if self.model.optimizer and isinstance(\n+            self.model.optimizer, optimizer_experimental.Optimizer\n+        ):\n+            checkpoint = tf.train.Checkpoint(model=self.model)\n+        else:\n             optimizer_checkpoint = tf.train.Checkpoint(iter=self._iterations)\n             checkpoint = tf.train.Checkpoint(\n                 model=self.model, optimizer=optimizer_checkpoint\n             )\n-\n         for latest_checkpoint in tf.train.checkpoints_iterator(\n             self.checkpoint_dir,\n             timeout=_CHECKPOINT_TIMEOUT_SEC,\n@@ -230,7 +237,12 @@ class SidecarEvaluator:\n                 # The model checkpoint might not include optimizer in cases,\n                 # e.g.  using a custom training loop. Directly assign the\n                 # iterations property to be used in callbacks.\n-                if self.model.optimizer:\n+                if self.model.optimizer and not isinstance(\n+                    self.model.optimizer,\n+                    optimizer_experimental.Optimizer,\n+                ):\n+                    # experimental optimizer automatically restores the\n+                    # iteration value.\n                     self.model.optimizer.iterations.assign(self._iterations)\n             except (tf.errors.OpError,) as e:\n                 # A couple errors can happen here with the coordinator racing to\n@@ -247,8 +259,13 @@ class SidecarEvaluator:\n                     f\"Error: {e.__class__.__name__}: {e}\"\n                 )\n                 continue\n-\n-            if self._iterations.numpy() == _ITERATIONS_UNINITIALIZED:\n+            if (\n+                self._iterations.numpy() == _ITERATIONS_UNINITIALIZED\n+                and not isinstance(\n+                    self.model.optimizer,\n+                    optimizer_experimental.Optimizer,\n+                )\n+            ):\n                 raise RuntimeError(\n                     \"Variable `iterations` cannot be loaded from the \"\n                     f\"checkpoint file at {self.checkpoint_dir}. \"\n@@ -260,7 +277,6 @@ class SidecarEvaluator:\n                 \"Evaluation starts: Model weights loaded from latest \"\n                 f\"checkpoint file {latest_checkpoint}\"\n             )\n-\n             self.model.evaluate(\n                 self.data, steps=self.steps, callbacks=self.callbacks, verbose=2\n             )\n\n@@ -25,7 +25,7 @@ from absl.testing import parameterized\n \n import keras\n from keras.distribute import sidecar_evaluator as sidecar_evaluator_lib\n-from keras.optimizers.optimizer_v2 import gradient_descent\n+from keras.optimizers.optimizer_experimental import sgd\n from keras.testing_infra import test_utils\n \n # isort: off\n@@ -62,7 +62,7 @@ def _test_model_builder(model_type: ModelType, compile_model, build_model):\n \n     if compile_model:\n         model.compile(\n-            gradient_descent.SGD(),\n+            sgd.SGD(),\n             loss=\"mse\",\n             metrics=[keras.metrics.CategoricalAccuracy(), DictMetric()],\n         )\n@@ -288,7 +288,9 @@ class SidecarEvaluatorTest(tf.test.TestCase, parameterized.TestCase):\n         self.assertModelsSameVariables(model, eval_model)\n \n         # check the iterations is restored.\n-        self.assertEqual(sidecar_evaluator._iterations.numpy(), _BATCH_SIZE)\n+        self.assertEqual(\n+            sidecar_evaluator.model.optimizer.iterations.numpy(), _BATCH_SIZE\n+        )\n \n         self.assertSummaryEventsWritten(os.path.join(log_dir, \"validation\"))\n \n\n@@ -104,12 +104,14 @@ class Optimizer(optimizer_lib._BaseOptimizer):\n                     self._mesh, rank=initial_value.shape.rank\n                 ),\n             )\n-        return dtensor.DVariable(\n+        variable = dtensor.DVariable(\n             initial_value=initial_value,\n             name=f\"{variable_name}/{model_variable._shared_name}\",\n             dtype=model_variable.dtype,\n             trainable=False,\n         )\n+        self._variables.append(variable)\n+        return variable\n \n     @doc_controls.do_not_generate_docs\n     def aggregate_gradients(self, grads_and_vars):\n\n@@ -3168,10 +3168,6 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n         self._assert_weights_created()\n         weights = []\n         for layer in self._self_tracked_trackables:\n-            if isinstance(layer, optimizer_experimental.Optimizer):\n-                # Optimizer has to use variables() method.\n-                weights += layer.variables()\n-            else:\n             weights += layer.variables\n         weights += self._trainable_weights + self._non_trainable_weights\n         return weights\n\n@@ -37,6 +37,7 @@ from keras.engine import training_utils_v1\n from keras.layers.preprocessing import string_lookup\n from keras.mixed_precision import policy\n from keras.optimizers import optimizer_v2\n+from keras.optimizers.optimizer_experimental import rmsprop\n from keras.optimizers.optimizer_experimental import sgd as sgd_experimental\n from keras.testing_infra import test_combinations\n from keras.testing_infra import test_utils\n@@ -1413,7 +1414,7 @@ class TrainingTest(test_combinations.TestCase):\n         )\n         reference_model.compile(\n             loss=\"categorical_crossentropy\",\n-            optimizer=RMSPropOptimizer(learning_rate=0.001),\n+            optimizer=rmsprop.RMSprop(learning_rate=0.001),\n             run_eagerly=True,\n         )\n         fixed_weights = reference_model.get_weights()\n\n@@ -32,7 +32,7 @@ from tensorflow.python.util.tf_export import keras_export\n from tensorflow.tools.docs import doc_controls\n \n \n-class _BaseOptimizer(tf.Module):\n+class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):\n     \"\"\"Optimizer base class, which only supports non-distribute use case.\"\"\"\n \n     def __init__(\n@@ -47,7 +47,7 @@ class _BaseOptimizer(tf.Module):\n         jit_compile=True,\n         **kwargs,\n     ):\n-        self._name = name\n+        self.name = name\n         self.clipnorm = clipnorm\n         self.global_clipnorm = global_clipnorm\n         self.clipvalue = clipvalue\n@@ -85,6 +85,7 @@ class _BaseOptimizer(tf.Module):\n \n         self._create_iteration_variable()\n         self._process_kwargs(kwargs)\n+        self._variables = []\n \n     def _create_iteration_variable(self):\n         \"\"\"Create the iterations counter variable.\"\"\"\n@@ -405,9 +406,11 @@ class _BaseOptimizer(tf.Module):\n             dtype = backend.floatx()\n         if shape is None:\n             shape = []\n-        return tf.Variable(\n+        variable = tf.Variable(\n             initial_value=initializer(shape, dtype), name=name, trainable=False\n         )\n+        self._variables.append(variable)\n+        return variable\n \n     def add_variable_from_reference(\n         self, model_variable, variable_name, shape=None, initial_value=None\n@@ -441,12 +444,14 @@ class _BaseOptimizer(tf.Module):\n                 )\n             else:\n                 initial_value = tf.zeros(shape, dtype=model_variable.dtype)\n-        return tf.Variable(\n+        variable = tf.Variable(\n             initial_value=initial_value,\n             name=f\"{variable_name}/{model_variable._shared_name}\",\n             dtype=model_variable.dtype,\n             trainable=False,\n         )\n+        self._variables.append(variable)\n+        return variable\n \n     def minimize(self, loss, var_list, tape=None):\n         \"\"\"Minimize `loss` by updating `var_list`.\n@@ -486,16 +491,24 @@ class _BaseOptimizer(tf.Module):\n         ):\n             # Compute the current learning rate at the beginning of variable\n             # update.\n+            if hasattr(self, \"_current_learning_rate\"):\n                 self._current_learning_rate.assign(\n                     self._learning_rate(self.iterations)\n                 )\n+            else:\n+                self._current_learning_rate = tf.Variable(\n+                    self._learning_rate(self.iterations),\n+                    name=\"learning_rate\",\n+                    dtype=tf.float32,\n+                    trainable=False,\n+                )\n         grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)\n         if len(list(grads_and_vars)) == 0:\n             # It is possible that the grad is empty. In this case,\n             # `apply_gradients` is a no-op.\n             return\n         grads, trainable_variables = zip(*grads_and_vars)\n-        scope_name = self._name or \"optimizer\"\n+        scope_name = self.name or \"optimizer\"\n         with tf.name_scope(scope_name):\n             with tf.init_scope():\n                 # Lift variable creation to init scope to avoid environment\n@@ -632,22 +645,7 @@ class _BaseOptimizer(tf.Module):\n         sake of backward compatibility with `optimizer_v2.Optimizer`'s\n         `variable()` method.\n         \"\"\"\n-\n-        def predicate(obj):\n-            if not isinstance(obj, tf.Variable):\n-                return False\n-            # Exclude `iteration` and `learning_rate` to keep backward\n-            # compatibilty with `optimizer_v2.Optimizer`.\n-            return (\n-                \"iteration\" not in obj.name and \"learning_rate\" not in obj.name\n-            )\n-\n-        return tuple(\n-            self._flatten(\n-                predicate=predicate,\n-                expand_composites=True,\n-            )\n-        )\n+        return self._variables\n \n \n base_optimizer_keyword_args = \"\"\"name: String. The name to use\n\n@@ -336,11 +336,32 @@ class OptimizerFuntionalityTest(tf.test.TestCase, parameterized.TestCase):\n             self.evaluate(optimizer_2._iterations),\n         )\n \n+    def testCheckpointOptimizerWithModel(self):\n+        inputs = keras.layers.Input(shape=(1,))\n+        outputs = keras.layers.Dense(1)(inputs)\n+        model = keras.Model(inputs=inputs, outputs=outputs)\n+        optimizer = adamax_new_fn()\n+        x = tf.expand_dims(tf.convert_to_tensor([1, 1, 1, 0, 0, 0]), axis=1)\n+        y = tf.expand_dims(tf.convert_to_tensor([1, 1, 1, 0, 0, 0]), axis=1)\n+        model.compile(loss=\"mse\", optimizer=optimizer)\n+        path = os.path.join(self.get_temp_dir(), \"ckpt\")\n+        checkpoint_callback = keras.callbacks.ModelCheckpoint(path)\n+        model.fit(x, y, callbacks=[checkpoint_callback])\n+\n+        new_model = keras.Model(inputs=inputs, outputs=outputs)\n+        new_optimizer = adamax_new_fn()\n+        new_model.compile(loss=\"mse\", optimizer=new_optimizer)\n+        new_model.load_weights(path)\n+        self.assertEqual(\n+            new_model.optimizer.iterations.numpy(),\n+            model.optimizer.iterations.numpy(),\n+        )\n+\n     @parameterized.product(optimizer_fn=OPTIMIZER_FN)\n     def testSaveAndLoadOptimizerWithModel(self, optimizer_fn):\n-        model = keras.Sequential(\n-            [keras.layers.Input(shape=(1,)), keras.layers.Dense(1)]\n-        )\n+        inputs = keras.layers.Input(shape=(1,))\n+        outputs = keras.layers.Dense(1)(inputs)\n+        model = keras.Model(inputs=inputs, outputs=outputs)\n         optimizer = optimizer_fn()\n         optimizer.clipnorm = 0.1\n         x = tf.expand_dims(tf.convert_to_tensor([1, 1, 1, 0, 0, 0]), axis=1)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
