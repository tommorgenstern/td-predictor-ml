{"custom_id": "keras#b4a7f36e8eee2ecc803b810d36e6594871340952", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 241 | Lines Deleted: 5 | Files Changed: 5 | Hunks: 8 | Methods Changed: 15 | Complexity Δ (Sum/Max): 20/8 | Churn Δ: 246 | Churn Cumulative: 1368 | Contributors (this commit): 6 | Commits (past 90d): 46 | Contributors (cumulative): 23 | DMM Complexity: 1.0\n\nDIFF:\n@@ -188,3 +188,20 @@ def scatter(indices, values, shape):\n     zeros = jnp.zeros(shape, values.dtype)\n     key = tuple(jnp.moveaxis(indices, -1, 0))\n     return zeros.at[key].add(values)\n+\n+\n+def scatter_update(inputs, indices, updates):\n+    indices = jnp.array(indices)\n+    indices = jnp.transpose(indices)\n+    inputs[tuple(indices)] = updates\n+    return inputs\n+\n+\n+def block_update(inputs, start_indices, updates):\n+    update_shape = updates.shape\n+    slices = [\n+        slice(start_index, start_index + update_length)\n+        for start_index, update_length in zip(start_indices, update_shape)\n+    ]\n+    inputs[tuple(slices)] = updates\n+    return inputs\n\n@@ -1,4 +1,5 @@\n import tensorflow as tf\n+from tensorflow.compiler.tf2xla.python.xla import dynamic_update_slice\n \n from keras_core.backend.common import KerasVariable\n from keras_core.backend.common import standardize_dtype\n@@ -102,3 +103,11 @@ def vectorized_map(function, elements):\n \n def scatter(indices, values, shape):\n     return tf.scatter_nd(indices, values, shape)\n+\n+\n+def scatter_update(inputs, indices, updates):\n+    return tf.tensor_scatter_nd_update(inputs, indices, updates)\n+\n+\n+def block_update(inputs, start_indices, updates):\n+    return dynamic_update_slice(inputs, updates, start_indices)\n\n@@ -104,3 +104,27 @@ def scatter(indices, values, shape):\n         index = indices[i]\n         zeros[tuple(index)] += values[i]\n     return zeros\n+\n+\n+def scatter_update(inputs, indices, updates):\n+    inputs = convert_to_tensor(inputs)\n+    indices = convert_to_tensor(indices, dtype=\"int64\")\n+    updates = convert_to_tensor(updates)\n+    indices = torch.transpose(indices, 0, 1)\n+\n+    inputs[tuple(indices)] = updates\n+    return inputs\n+\n+\n+def block_update(inputs, start_indices, updates):\n+    inputs = convert_to_tensor(inputs)\n+    start_indices = convert_to_tensor(start_indices, dtype=\"int64\")\n+    updates = convert_to_tensor(updates)\n+\n+    update_shape = updates.shape\n+    slices = [\n+        slice(start_index, start_index + update_length)\n+        for start_index, update_length in zip(start_indices, update_shape)\n+    ]\n+    inputs[slices] = updates\n+    return inputs\n\n@@ -22,3 +22,106 @@ def scatter(indices, values, shape):\n     if any_symbolic_tensors((indices, values, shape)):\n         return Scatter().symbolic_call(indices, values, shape)\n     return backend.core.scatter(indices, values, shape)\n+\n+\n+class ScatterUpdate(Operation):\n+    def call(self, inputs, indices, updates):\n+        return backend.core.scatter_update(inputs, indices, updates)\n+\n+    def compute_output_spec(self, inputs, indices, updates):\n+        return KerasTensor(inputs.shape, dtype=inputs.dtype)\n+\n+\n+@keras_core_export(\"keras_core.operations.scatter_update\")\n+def scatter_update(inputs, indices, updates):\n+    \"\"\"Update inputs by scattering updates at indices.\n+\n+    At a high level, this operation does `inputs[indices]=updates`. In details,\n+    assume `inputs` is a tensor of shape `[D0, D1, ..., Dn]`, there are 2 main\n+    usages of `scatter_update`.\n+\n+    - `indices` is a 2D tensor of shape `[num_updates, n]`, where `num_updates`\n+        is the number of updates to perform, and `updates` is a 1D tensor of\n+        shape `[num_updates]`. For example, if `inputs = np.zeros([4, 4, 4])`,\n+        and we want to update `inputs[1, 2, 3]` and `inputs[0, 1, 3]` as 1, then\n+        we can use\n+\n+        ```\n+        inputs = np.zeros([4, 4, 4])\n+        indices = [[1, 2, 3], [0, 1, 3]]\n+        updates = np.array([1., 1.])\n+        inputs = keras_core.operations.scatter_update(inputs, indices, updates)\n+        ```\n+    - `indices` is a 2D tensor of shape `[num_updates, k]`, where `num_updates`\n+        is the number of updates to perform, and `k` (`k < n`) is the size of\n+        each index in `indices`. `updates` is a `n-k`-D tensor of shape\n+        `[num_updates, inputs.shape[k:]]`. For example, if\n+        `inputs = np.zeros([4, 4, 4])`, and we want to update `inputs[1, 2, :]`\n+        and `inputs[2, 3, :]` as `[1, 1, 1, 1]`, then `indices` would have shape\n+        `[num_updates, 2]` (`k=2`), and `updates` would have shape\n+        `[num_updates, 4]` (`inputs.shape[2:]=4`). See the code below:\n+\n+        ```\n+        inputs = np.zeros([4, 4, 4])\n+        indices = [[1, 2], [2, 3]]\n+        updates = np.array([[1., 1., 1, 1,], [1., 1., 1, 1,])\n+        inputs = keras_core.operations.scatter_update(inputs, indices, updates)\n+        ```\n+\n+    Args:\n+        inputs: A tensor, the tensor to be updated.\n+        indices: A tensor or list/tuple of shape `[N, inputs.ndims]`, specifying\n+            indices to update. `N` is the number of indices to update, must be\n+            equal to the first dimension of `updates`.\n+        updates: A tensor, the new values to be put to `inputs` at `indices`.\n+\n+    Returns:\n+        A tensor, has the same shape and dtype as `inputs`.\n+    \"\"\"\n+    if any_symbolic_tensors((inputs, indices, updates)):\n+        return ScatterUpdate().symbolic_call(inputs, indices, updates)\n+    return backend.core.scatter_update(inputs, indices, updates)\n+\n+\n+class BlockUpdate(Operation):\n+    def call(self, inputs, start_indices, updates):\n+        return backend.core.block_update(inputs, start_indices, updates)\n+\n+    def compute_output_spec(self, inputs, start_indices, updates):\n+        return KerasTensor(inputs.shape, dtype=inputs.dtype)\n+\n+\n+@keras_core_export(\"keras_core.operations.block_update\")\n+def block_update(inputs, start_indices, updates):\n+    \"\"\"Update inputs block.\n+\n+    At a high level, this operation does\n+    `inputs[start_indices: start_indices + updates.shape] = updates`. In\n+    details, assume inputs is a tensor of shape `[D0, D1, ..., Dn]`,\n+    `start_indices` must be a list/tuple of n integers, specifying the starting\n+    indices. `updates` must have the same rank as `inputs`, and the size of each\n+    dim must not exceed `Di - start_indices[i]`. For example, if we have 2D\n+    inputs `inputs=np.zeros([5, 5])`, and we want to update the intersection of\n+    last 2 rows and last 2 columns as 1, i.e.,\n+    `inputs[3:, 3:] = np.ones([2, 2])`, then we can use the code below:\n+\n+    ```\n+    inputs = np.zeros([5, 5])\n+    start_indices = [3, 3]\n+    updates = np.ones([2, 2])\n+    inputs = keras_core.operations.block_update(inputs, start_indices, updates)\n+    ```\n+\n+    Args:\n+        inputs: A tensor, the tensor to be updated.\n+        start_indices: A list/tuple of shape `[inputs.ndims]`, specifying\n+            the starting indices for updating.\n+        updates: A tensor, the new values to be put to `inputs` at `indices`.\n+            `updates` must have the same rank as `inputs`.\n+\n+    Returns:\n+        A tensor, has the same shape and dtype as `inputs`.\n+    \"\"\"\n+    if any_symbolic_tensors((inputs, start_indices, updates)):\n+        return BlockUpdate().symbolic_call(inputs, start_indices, updates)\n+    return backend.core.block_update(inputs, start_indices, updates)\n\n@@ -1,16 +1,46 @@\n import numpy as np\n \n from keras_core import testing\n+from keras_core.backend.common.keras_tensor import KerasTensor\n from keras_core.operations import core\n \n \n class CoreOpsStaticShapeTest(testing.TestCase):\n     def test_scatter(self):\n-        # Requires dtype\n-        indices = np.array([[0]], dtype=\"int32\")\n-        values = np.array([0], dtype=\"int32\")\n-        shape = (8,)\n-        self.assertEqual(core.scatter(indices, values, shape).shape, (8,))\n+        indices = KerasTensor((5, 2))\n+        values = KerasTensor((5,))\n+        shape = (4, 4)\n+        self.assertEqual(core.scatter(indices, values, shape).shape, (4, 4))\n+\n+    def test_scatter_update(self):\n+        inputs = KerasTensor((4, 4))\n+        indices = KerasTensor((5, 2))\n+        updates = KerasTensor((5,))\n+        self.assertEqual(\n+            core.scatter_update(inputs, indices, updates).shape, (4, 4)\n+        )\n+\n+        inputs = KerasTensor((4, 4, 4))\n+        indices = KerasTensor((5, 2))\n+        updates = KerasTensor((5, 4))\n+        self.assertEqual(\n+            core.scatter_update(inputs, indices, updates).shape, (4, 4, 4)\n+        )\n+\n+    def test_block_update(self):\n+        inputs = KerasTensor((4, 4))\n+        start_indices = KerasTensor((2,))\n+        updates = KerasTensor((2, 2))\n+        self.assertEqual(\n+            core.block_update(inputs, start_indices, updates).shape, (4, 4)\n+        )\n+\n+        inputs = KerasTensor((4, 4, 4))\n+        start_indices = KerasTensor((3,))\n+        updates = KerasTensor((2, 2, 2))\n+        self.assertEqual(\n+            core.block_update(inputs, start_indices, updates).shape, (4, 4, 4)\n+        )\n \n \n class CoreOpsCorrectnessTest(testing.TestCase):\n@@ -56,3 +86,56 @@ class CoreOpsCorrectnessTest(testing.TestCase):\n         indices = np.array([[0], [0]])\n         values = np.array([1, 1])\n         self.assertAllClose(core.scatter(indices, values, (1,)), [2])\n+\n+    def test_scatter_update(self):\n+        # Test 1D.\n+        inputs = np.array([0, 0, 0, 0, 0, 0, 0, 0])\n+        indices = [[1], [3], [4], [7]]\n+        updates = np.array([9, 10, 11, 12])\n+        self.assertAllClose(\n+            core.scatter_update(inputs, indices, updates),\n+            [0, 9, 0, 10, 11, 0, 0, 12],\n+        )\n+\n+        # Test 2D.\n+        inputs = np.array([[1, 1], [1, 1], [1, 1]])\n+        indices = [[0, 1], [2, 0]]\n+        updates = np.array([5, 10])\n+        self.assertAllClose(\n+            core.scatter_update(inputs, indices, updates),\n+            [[1, 5], [1, 1], [10, 1]],\n+        )\n+\n+        # Test updates has multiple dimension.\n+        inputs = np.ones([4, 4, 4])\n+        indices = [[1, 1], [2, 2]]\n+        updates = np.array([[0, 1, 2, 3], [3, 2, 1, 0]], dtype=np.float64)\n+        outputs = core.scatter_update(inputs, indices, updates)\n+        self.assertAllClose(outputs[1, 1, :], [0, 1, 2, 3])\n+        self.assertAllClose(outputs[2, 2, :], [3, 2, 1, 0])\n+\n+    def test_block_update(self):\n+        # Test 1D.\n+        inputs = np.array([0, 0, 0, 0, 0, 0, 0, 0])\n+        start_indices = [1]\n+        updates = np.array([9, 10, 11, 12])\n+        self.assertAllClose(\n+            core.block_update(inputs, start_indices, updates),\n+            [0, 9, 10, 11, 12, 0, 0, 0],\n+        )\n+\n+        # Test 2D.\n+        inputs = np.array([[1, 1], [1, 1], [1, 1]])\n+        start_indices = [1, 0]\n+        updates = np.array([[2, 2], [2, 2]])\n+        self.assertAllClose(\n+            core.block_update(inputs, start_indices, updates),\n+            [[1, 1], [2, 2], [2, 2]],\n+        )\n+\n+        # Test N-D.\n+        inputs = np.ones([4, 4, 4, 4])\n+        start_indices = [1, 1, 2, 2]\n+        updates = np.zeros([2, 2, 2, 2])\n+        outputs = core.block_update(inputs, start_indices, updates)\n+        self.assertAllClose(outputs[1:3, 1:3, 2:4, 2:4], np.zeros([2, 2, 2, 2]))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b10843ded67b13c6173ace6b7ae532ebc634d746", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 26 | Lines Deleted: 25 | Files Changed: 1 | Hunks: 16 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 51 | Churn Cumulative: 266 | Contributors (this commit): 5 | Commits (past 90d): 8 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -34,35 +34,36 @@ class ScatterUpdate(Operation):\n \n @keras_core_export(\"keras_core.operations.scatter_update\")\n def scatter_update(inputs, indices, updates):\n-    \"\"\"Update inputs by scattering updates at indices.\n+    \"\"\"Update inputs via updates at scattered (sparse) indices.\n \n-    At a high level, this operation does `inputs[indices]=updates`. In details,\n-    assume `inputs` is a tensor of shape `[D0, D1, ..., Dn]`, there are 2 main\n+    At a high level, this operation does `inputs[indices] = updates`.\n+    Assume `inputs` is a tensor of shape `(D0, D1, ..., Dn)`, there are 2 main\n     usages of `scatter_update`.\n \n-    - `indices` is a 2D tensor of shape `[num_updates, n]`, where `num_updates`\n+    1. `indices` is a 2D tensor of shape `(num_updates, n)`, where `num_updates`\n         is the number of updates to perform, and `updates` is a 1D tensor of\n-        shape `[num_updates]`. For example, if `inputs = np.zeros([4, 4, 4])`,\n+        shape `(num_updates,)`. For example, if `inputs` is `zeros((4, 4, 4))`,\n         and we want to update `inputs[1, 2, 3]` and `inputs[0, 1, 3]` as 1, then\n-        we can use\n+        we can use:\n \n-        ```\n-        inputs = np.zeros([4, 4, 4])\n+    ```python\n+    inputs = np.zeros((4, 4, 4))\n     indices = [[1, 2, 3], [0, 1, 3]]\n     updates = np.array([1., 1.])\n     inputs = keras_core.operations.scatter_update(inputs, indices, updates)\n     ```\n-    - `indices` is a 2D tensor of shape `[num_updates, k]`, where `num_updates`\n+\n+    2 `indices` is a 2D tensor of shape `(num_updates, k)`, where `num_updates`\n         is the number of updates to perform, and `k` (`k < n`) is the size of\n         each index in `indices`. `updates` is a `n - k`-D tensor of shape\n-        `[num_updates, inputs.shape[k:]]`. For example, if\n-        `inputs = np.zeros([4, 4, 4])`, and we want to update `inputs[1, 2, :]`\n+        `(num_updates, inputs.shape[k:])`. For example, if\n+        `inputs = np.zeros((4, 4, 4))`, and we want to update `inputs[1, 2, :]`\n         and `inputs[2, 3, :]` as `[1, 1, 1, 1]`, then `indices` would have shape\n-        `[num_updates, 2]` (`k=2`), and `updates` would have shape\n-        `[num_updates, 4]` (`inputs.shape[2:]=4`). See the code below:\n+        `(num_updates, 2)` (`k = 2`), and `updates` would have shape\n+        `(num_updates, 4)` (`inputs.shape[2:] = 4`). See the code below:\n \n-        ```\n-        inputs = np.zeros([4, 4, 4])\n+    ```python\n+    inputs = np.zeros((4, 4, 4))\n     indices = [[1, 2], [2, 3]]\n     updates = np.array([[1., 1., 1, 1,], [1., 1., 1, 1,])\n     inputs = keras_core.operations.scatter_update(inputs, indices, updates)\n@@ -70,7 +71,7 @@ def scatter_update(inputs, indices, updates):\n \n     Args:\n         inputs: A tensor, the tensor to be updated.\n-        indices: A tensor or list/tuple of shape `[N, inputs.ndims]`, specifying\n+        indices: A tensor or list/tuple of shape `(N, inputs.ndim)`, specifying\n             indices to update. `N` is the number of indices to update, must be\n             equal to the first dimension of `updates`.\n         updates: A tensor, the new values to be put to `inputs` at `indices`.\n@@ -96,25 +97,25 @@ def block_update(inputs, start_indices, updates):\n     \"\"\"Update inputs block.\n \n     At a high level, this operation does\n-    `inputs[start_indices: start_indices + updates.shape] = updates`. In\n-    details, assume inputs is a tensor of shape `[D0, D1, ..., Dn]`,\n+    `inputs[start_indices: start_indices + updates.shape] = updates`.\n+    Assume inputs is a tensor of shape `(D0, D1, ..., Dn)`,\n     `start_indices` must be a list/tuple of n integers, specifying the starting\n     indices. `updates` must have the same rank as `inputs`, and the size of each\n     dim must not exceed `Di - start_indices[i]`. For example, if we have 2D\n-    inputs `inputs=np.zeros([5, 5])`, and we want to update the intersection of\n-    last 2 rows and last 2 columns as 1, i.e.,\n-    `inputs[3:, 3:] = np.ones([2, 2])`, then we can use the code below:\n+    inputs `inputs = np.zeros((5, 5))`, and we want to update the intersection\n+    of last 2 rows and last 2 columns as 1, i.e.,\n+    `inputs[3:, 3:] = np.ones((2, 2))`, then we can use the code below:\n \n-    ```\n-    inputs = np.zeros([5, 5])\n+    ```python\n+    inputs = np.zeros((5, 5))\n     start_indices = [3, 3]\n-    updates = np.ones([2, 2])\n+    updates = np.ones((2, 2))\n     inputs = keras_core.operations.block_update(inputs, start_indices, updates)\n     ```\n \n     Args:\n         inputs: A tensor, the tensor to be updated.\n-        start_indices: A list/tuple of shape `[inputs.ndims]`, specifying\n+        start_indices: A list/tuple of shape `(inputs.ndim,)`, specifying\n             the starting indices for updating.\n         updates: A tensor, the new values to be put to `inputs` at `indices`.\n             `updates` must have the same rank as `inputs`.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#57fa12951cc093ff8bccccfbaa214a78d0f6b456", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 59 | Lines Deleted: 1 | Files Changed: 4 | Hunks: 7 | Methods Changed: 4 | Complexity Δ (Sum/Max): 6/3 | Churn Δ: 60 | Churn Cumulative: 2324 | Contributors (this commit): 9 | Commits (past 90d): 111 | Contributors (cumulative): 18 | DMM Complexity: 0.0\n\nDIFF:\n@@ -17,6 +17,7 @@ And some more magic:\n \"\"\"\n import collections\n import inspect\n+import warnings\n \n import numpy as np\n from tensorflow import nest\n@@ -200,10 +201,30 @@ class Layer(Operation):\n         dtype=None,\n         autocast=True,\n         name=None,\n+        **kwargs,\n     ):\n         self._lock = False\n         super().__init__(name=name)\n         self.activity_regularizer = regularizers.get(activity_regularizer)\n+        input_dim_arg = kwargs.pop(\"input_dim\", None)\n+        if input_dim_arg is not None:\n+            input_shape_arg = (input_dim_arg,)\n+        else:\n+            input_shape_arg = kwargs.pop(\"input_shape\", None)\n+        if input_shape_arg is not None:\n+            warnings.warn(\n+                \"Do not pass an `input_shape`/`input_dim` argument to \"\n+                \"a layer. When using Sequential models, \"\n+                \"prefer using an `Input(shape)` object as the \"\n+                \"first layer in the model instead.\",\n+                stacklevel=2,\n+            )\n+            self._input_shape_arg = input_shape_arg\n+        if kwargs:\n+            raise ValueError(\n+                \"Unrecognized keyword arguments \"\n+                f\"passed to {self.__class__.__name__}: {kwargs}\"\n+            )\n \n         self.built = False\n         self.dtype_policy = mixed_precision.resolve_policy(dtype)\n\n@@ -68,6 +68,12 @@ class Sequential(Model):\n             self._maybe_rebuild()\n \n     def add(self, layer, rebuild=True):\n+        # Legacy case: if the first layer has an input_shape arg,\n+        # use it to build an InputLayer.\n+        if not self._layers:\n+            if getattr(layer, \"_input_shape_arg\", None) is not None:\n+                self.add(InputLayer(shape=layer._input_shape_arg))\n+\n         # If we are passed a Keras tensor created by keras.Input(), we\n         # extract the input layer from its keras history and use that.\n         if hasattr(layer, \"_keras_history\"):\n\n@@ -58,6 +58,36 @@ class SequentialTest(testing.TestCase):\n         y = model(x)\n         self.assertEqual(y.shape, (3, 4))\n \n+    def test_legacy_flow_with_input_shape(self):\n+        model = Sequential(name=\"seq\")\n+        model.add(layers.Dense(4, input_shape=(2,)))\n+        model.add(layers.Dense(5))\n+\n+        self.assertEqual(len(model.layers), 2)\n+        self.assertTrue(model.built)\n+        self.assertEqual(len(model.weights), 4)\n+        self.assertEqual(type(model._functional), Functional)\n+\n+        # Input_dim works too\n+        model = Sequential(name=\"seq\")\n+        model.add(layers.Dense(4, input_dim=2))\n+        model.add(layers.Dense(5))\n+\n+        self.assertEqual(len(model.layers), 2)\n+        self.assertTrue(model.built)\n+        self.assertEqual(len(model.weights), 4)\n+        self.assertEqual(type(model._functional), Functional)\n+\n+        # Subsequent input_shapes are ignored\n+        model = Sequential(name=\"seq\")\n+        model.add(layers.Dense(4, input_shape=(2,)))\n+        model.add(layers.Dense(5, input_shape=(3, 4)))\n+\n+        self.assertEqual(len(model.layers), 2)\n+        self.assertTrue(model.built)\n+        self.assertEqual(len(model.weights), 4)\n+        self.assertEqual(type(model._functional), Functional)\n+\n     def test_basic_flow_deferred(self):\n         model = Sequential(name=\"seq\")\n         model.add(layers.Dense(4))\n\n@@ -65,10 +65,11 @@ def get(identifier):\n     if isinstance(identifier, Optimizer):\n         return identifier\n     elif isinstance(identifier, dict):\n-        return deserialize(identifier)\n+        opt = deserialize(identifier)\n     elif isinstance(identifier, str):\n         config = {\"class_name\": identifier, \"config\": {}}\n         opt = deserialize(config)\n+\n     if isinstance(opt, Optimizer):\n         return opt\n     raise ValueError(f\"Could not interpret optimizer identifier: {identifier}\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#784139e69c332c29db69c43b521df1a13e5e2997", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 61 | Lines Deleted: 9 | Files Changed: 7 | Hunks: 13 | Methods Changed: 7 | Complexity Δ (Sum/Max): 15/12 | Churn Δ: 70 | Churn Cumulative: 12277 | Contributors (this commit): 11 | Commits (past 90d): 129 | Contributors (cumulative): 35 | DMM Complexity: 0.0\n\nDIFF:\n@@ -496,18 +496,25 @@ def categorical_crossentropy(target, output, from_logits=False, axis=-1):\n     target = tf.convert_to_tensor(target)\n     output = tf.convert_to_tensor(output)\n \n-    if target.shape != output.shape:\n-        raise ValueError(\n-            \"Arguments `target` and `output` must have the same shape. \"\n-            \"Received: \"\n-            f\"target.shape={target.shape}, output.shape={output.shape}\"\n-        )\n     if len(target.shape) < 1:\n         raise ValueError(\n             \"Arguments `target` and `output` must be at least rank 1. \"\n             \"Received: \"\n             f\"target.shape={target.shape}, output.shape={output.shape}\"\n         )\n+    if len(target.shape) != len(output.shape):\n+        raise ValueError(\n+            \"Arguments `target` and `output` must have the same rank \"\n+            \"(ndim). Received: \"\n+            f\"target.shape={target.shape}, output.shape={output.shape}\"\n+        )\n+    for e1, e2 in zip(target.shape, output.shape):\n+        if e1 is not None and e2 is not None and e1 != e2:\n+            raise ValueError(\n+                \"Arguments `target` and `output` must have the same shape. \"\n+                \"Received: \"\n+                f\"target.shape={target.shape}, output.shape={output.shape}\"\n+            )\n \n     output, from_logits = _get_logits(\n         output, from_logits, \"Softmax\", \"categorical_crossentropy\"\n@@ -562,7 +569,14 @@ def sparse_categorical_crossentropy(target, output, from_logits=False, axis=-1):\n             \"Received: \"\n             f\"output.shape={output.shape}\"\n         )\n-    if target.shape != output.shape[:-1]:\n+    if len(target.shape) != len(output.shape[:-1]):\n+        raise ValueError(\n+            \"Argument `output` must have rank (ndim) `target.ndim - 1`. \"\n+            \"Received: \"\n+            f\"target.shape={target.shape}, output.shape={output.shape}\"\n+        )\n+    for e1, e2 in zip(target.shape, output.shape[:-1]):\n+        if e1 is not None and e2 is not None and e1 != e2:\n             raise ValueError(\n                 \"Arguments `target` and `output` must have the same shape \"\n                 \"up until the last dimension: \"\n@@ -598,7 +612,14 @@ def binary_crossentropy(target, output, from_logits=False):\n     target = tf.convert_to_tensor(target)\n     output = tf.convert_to_tensor(output)\n \n-    if target.shape != output.shape:\n+    if len(target.shape) != len(output.shape):\n+        raise ValueError(\n+            \"Arguments `target` and `output` must have the same rank \"\n+            \"(ndim). Received: \"\n+            f\"target.shape={target.shape}, output.shape={output.shape}\"\n+        )\n+    for e1, e2 in zip(target.shape, output.shape):\n+        if e1 is not None and e2 is not None and e1 != e2:\n             raise ValueError(\n                 \"Arguments `target` and `output` must have the same shape. \"\n                 \"Received: \"\n\n@@ -328,6 +328,7 @@ class GRUCell(Layer, DropoutRNNCell):\n         ]\n \n \n+@keras_core_export(\"keras_core.layers.GRU\")\n class GRU(RNN):\n     \"\"\"Gated Recurrent Unit - Cho et al. 2014.\n \n\n@@ -316,6 +316,7 @@ class LSTMCell(Layer, DropoutRNNCell):\n         ]\n \n \n+@keras_core_export(\"keras_core.layers.LSTM\")\n class LSTM(RNN):\n     \"\"\"Long Short-Term Memory layer - Hochreiter 1997.\n \n\n@@ -269,7 +269,7 @@ class RNN(Layer):\n \n     def build(self, sequences_shape, initial_state_shape=None):\n         # Build cell (if layer).\n-        step_input_shape = (sequences_shape[0],) + sequences_shape[2:]\n+        step_input_shape = (sequences_shape[0],) + tuple(sequences_shape[2:])\n         if isinstance(self.cell, Layer) and not self.cell.built:\n             self.cell.build(step_input_shape)\n             self.cell.built = True\n\n@@ -258,6 +258,17 @@ class Functional(Function, Model):\n         flat_inputs = self._flatten_to_reference_inputs(inputs)\n         return self._adjust_input_rank(flat_inputs)\n \n+    @property\n+    def input(self):\n+        # For backwards compatibility,\n+        # override `input` to retrieve the used-provided\n+        # constructor inputs\n+        return self._inputs_struct\n+\n+    @property\n+    def output(self):\n+        return self._outputs_struct\n+\n     def add_loss(self, loss):\n         # Symbolic only. TODO\n         raise NotImplementedError\n\n@@ -1,6 +1,14 @@\n from keras_core.api_export import keras_core_export\n+from keras_core.optimizers.adadelta import Adadelta\n+from keras_core.optimizers.adafactor import Adafactor\n+from keras_core.optimizers.adagrad import Adagrad\n from keras_core.optimizers.adam import Adam\n+from keras_core.optimizers.adamax import Adamax\n+from keras_core.optimizers.adamw import AdamW\n+from keras_core.optimizers.ftrl import Ftrl\n+from keras_core.optimizers.nadam import Nadam\n from keras_core.optimizers.optimizer import Optimizer\n+from keras_core.optimizers.rmsprop import RMSprop\n from keras_core.optimizers.sgd import SGD\n from keras_core.saving import serialization_lib\n \n@@ -8,6 +16,14 @@ ALL_OBJECTS = {\n     Optimizer,\n     Adam,\n     SGD,\n+    RMSprop,\n+    Adadelta,\n+    AdamW,\n+    Adagrad,\n+    Adamax,\n+    Adafactor,\n+    Nadam,\n+    Ftrl,\n }\n ALL_OBJECTS_DICT = {cls.__name__.lower(): cls for cls in ALL_OBJECTS}\n \n\n@@ -188,6 +188,8 @@ class EpochIterator:\n \n     @property\n     def num_batches(self):\n+        if self.steps_per_epoch:\n+            return self.steps_per_epoch\n         # Either copied from the data_adapter, or\n         # inferred at the end of an iteration.\n         return self._num_batches\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1c615b12ea1664dcb8482d56d6fe07cf2af8dcfc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 871 | Lines Deleted: 6 | Files Changed: 6 | Hunks: 9 | Methods Changed: 5 | Complexity Δ (Sum/Max): 11/4 | Churn Δ: 877 | Churn Cumulative: 993 | Contributors (this commit): 1 | Commits (past 90d): 11 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -7,10 +7,9 @@ from keras_core import metrics\n from keras_core import optimizers\n \n inputs = layers.Input((100,))\n-x = layers.Dense(256, activation=\"relu\")(inputs)\n+x = layers.Dense(128, activation=\"relu\")(inputs)\n residual = x\n-x = layers.Dense(256, activation=\"relu\")(x)\n-x = layers.Dense(256, activation=\"relu\")(x)\n+x = layers.Dense(128, activation=\"relu\")(x)\n x += residual\n outputs = layers.Dense(16)(x)\n model = Model(inputs, outputs)\n@@ -25,7 +24,10 @@ epochs = 5\n model.compile(\n     optimizer=optimizers.Adam(learning_rate=0.001),\n     loss=losses.MeanSquaredError(),\n-    metrics=[metrics.CategoricalAccuracy(name=\"acc\"), metrics.MeanSquaredError(name=\"mse\")],\n+    metrics=[\n+        metrics.CategoricalAccuracy(name=\"acc\"),\n+        metrics.MeanSquaredError(name=\"mse\"),\n+    ],\n )\n \n print(\"\\nTrain model\")\n\n@@ -43,9 +43,13 @@ model = keras_core.Sequential(\n \n model.summary()\n \n-model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n+model.compile(\n+    loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n+)\n \n-model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n+model.fit(\n+    x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1\n+)\n \n score = model.evaluate(x_test, y_test, verbose=0)\n print(\"Test loss:\", score[0])\n\n@@ -0,0 +1,169 @@\n+\"\"\"\n+Title: Convolutional autoencoder for image denoising\n+Author: [Santiago L. Valdarrama](https://twitter.com/svpino)\n+Date created: 2021/03/01\n+Last modified: 2021/03/01\n+Description: How to train a deep convolutional autoencoder for image denoising.\n+Accelerator: GPU\n+\"\"\"\n+\n+\"\"\"\n+## Introduction\n+\n+This example demonstrates how to implement a deep convolutional autoencoder\n+for image denoising, mapping noisy digits images from the MNIST dataset to\n+clean digits images. This implementation is based on an original blog post\n+titled [Building Autoencoders in Keras](https://blog.keras.io/building-autoencoders-in-keras.html)\n+by [François Chollet](https://twitter.com/fchollet).\n+\"\"\"\n+\n+\"\"\"\n+## Setup\n+\"\"\"\n+\n+import numpy as np\n+import matplotlib.pyplot as plt\n+\n+from keras_core import layers\n+from keras_core.datasets import mnist\n+from keras_core.models import Model\n+\n+\n+def preprocess(array):\n+    \"\"\"Normalizes the supplied array and reshapes it.\"\"\"\n+    array = array.astype(\"float32\") / 255.0\n+    array = np.reshape(array, (len(array), 28, 28, 1))\n+    return array\n+\n+\n+def noise(array):\n+    \"\"\"Adds random noise to each image in the supplied array.\"\"\"\n+    noise_factor = 0.4\n+    noisy_array = array + noise_factor * np.random.normal(\n+        loc=0.0, scale=1.0, size=array.shape\n+    )\n+\n+    return np.clip(noisy_array, 0.0, 1.0)\n+\n+\n+def display(array1, array2):\n+    \"\"\"Displays ten random images from each array.\"\"\"\n+    n = 10\n+    indices = np.random.randint(len(array1), size=n)\n+    images1 = array1[indices, :]\n+    images2 = array2[indices, :]\n+\n+    plt.figure(figsize=(20, 4))\n+    for i, (image1, image2) in enumerate(zip(images1, images2)):\n+        ax = plt.subplot(2, n, i + 1)\n+        plt.imshow(image1.reshape(28, 28))\n+        plt.gray()\n+        ax.get_xaxis().set_visible(False)\n+        ax.get_yaxis().set_visible(False)\n+\n+        ax = plt.subplot(2, n, i + 1 + n)\n+        plt.imshow(image2.reshape(28, 28))\n+        plt.gray()\n+        ax.get_xaxis().set_visible(False)\n+        ax.get_yaxis().set_visible(False)\n+\n+    plt.show()\n+\n+\n+\"\"\"\n+## Prepare the data\n+\"\"\"\n+\n+# Since we only need images from the dataset to encode and decode, we\n+# won't use the labels.\n+(train_data, _), (test_data, _) = mnist.load_data()\n+\n+# Normalize and reshape the data\n+train_data = preprocess(train_data)\n+test_data = preprocess(test_data)\n+\n+# Create a copy of the data with added noise\n+noisy_train_data = noise(train_data)\n+noisy_test_data = noise(test_data)\n+\n+# Display the train data and a version of it with added noise\n+display(train_data, noisy_train_data)\n+\n+\"\"\"\n+## Build the autoencoder\n+\n+We are going to use the Functional API to build our convolutional autoencoder.\n+\"\"\"\n+\n+input = layers.Input(shape=(28, 28, 1))\n+\n+# Encoder\n+x = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(input)\n+x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n+x = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n+x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n+\n+# Decoder\n+x = layers.Conv2DTranspose(\n+    32, (3, 3), strides=2, activation=\"relu\", padding=\"same\"\n+)(x)\n+x = layers.Conv2DTranspose(\n+    32, (3, 3), strides=2, activation=\"relu\", padding=\"same\"\n+)(x)\n+x = layers.Conv2D(1, (3, 3), activation=\"sigmoid\", padding=\"same\")(x)\n+\n+# Autoencoder\n+autoencoder = Model(input, x)\n+autoencoder.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n+autoencoder.summary()\n+\n+\"\"\"\n+Now we can train our autoencoder using `train_data` as both our input data\n+and target. Notice we are setting up the validation data using the same\n+format.\n+\"\"\"\n+\n+autoencoder.fit(\n+    x=train_data,\n+    y=train_data,\n+    epochs=50,\n+    batch_size=128,\n+    shuffle=True,\n+    validation_data=(test_data, test_data),\n+)\n+\n+\"\"\"\n+Let's predict on our test dataset and display the original image together with\n+the prediction from our autoencoder.\n+\n+Notice how the predictions are pretty close to the original images, although\n+not quite the same.\n+\"\"\"\n+\n+predictions = autoencoder.predict(test_data)\n+display(test_data, predictions)\n+\n+\"\"\"\n+Now that we know that our autoencoder works, let's retrain it using the noisy\n+data as our input and the clean data as our target. We want our autoencoder to\n+learn how to denoise the images.\n+\"\"\"\n+\n+autoencoder.fit(\n+    x=noisy_train_data,\n+    y=train_data,\n+    epochs=100,\n+    batch_size=128,\n+    shuffle=True,\n+    validation_data=(noisy_test_data, test_data),\n+)\n+\n+\"\"\"\n+Let's now predict on the noisy data and display the results of our autoencoder.\n+\n+Notice how the autoencoder does an amazing job at removing the noise from the\n+input images.\n+\"\"\"\n+\n+predictions = autoencoder.predict(noisy_test_data)\n+display(noisy_test_data, predictions)\n\n@@ -0,0 +1,318 @@\n+\"\"\"\n+Title: Image classification from scratch\n+Author: [fchollet](https://twitter.com/fchollet)\n+Date created: 2020/04/27\n+Last modified: 2022/11/10\n+Description: Training an image classifier from scratch on the Kaggle Cats vs Dogs dataset.\n+Accelerator: GPU\n+\"\"\"\n+\"\"\"\n+## Introduction\n+\n+This example shows how to do image classification from scratch, starting from JPEG\n+image files on disk, without leveraging pre-trained weights or a pre-made Keras\n+Application model. We demonstrate the workflow on the Kaggle Cats vs Dogs binary\n+ classification dataset.\n+\n+We use the `image_dataset_from_directory` utility to generate the datasets, and\n+we use Keras image preprocessing layers for image standardization and data augmentation.\n+\"\"\"\n+\n+\"\"\"\n+## Setup\n+\"\"\"\n+\n+import tensorflow as tf\n+import keras_core as keras\n+from keras_core import layers\n+import os\n+from pathlib import Path\n+import matplotlib.pyplot as plt\n+\n+\"\"\"\n+## Load the data: the Cats vs Dogs dataset\n+\n+### Raw data download\n+\n+First, let's download the 786M ZIP archive of the raw data:\n+\"\"\"\n+\n+fpath = keras.utils.get_file(\n+    origin=\"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\"\n+)\n+dirpath = Path(fpath).parent.absolute()\n+os.system(f\"unzip -q {fpath} -d {dirpath}\")\n+\n+\"\"\"\n+Now we have a `PetImages` folder which contain two subfolders, `Cat` and `Dog`. Each\n+subfolder contains image files for each category.\n+\"\"\"\n+\n+os.system(f\"ls {dirpath}/PetImages/\")\n+\n+\"\"\"\n+### Filter out corrupted images\n+\n+When working with lots of real-world image data, corrupted images are a common\n+occurence. Let's filter out badly-encoded images that do not feature the string \"JFIF\"\n+in their header.\n+\"\"\"\n+\n+import os\n+\n+num_skipped = 0\n+for folder_name in (\"Cat\", \"Dog\"):\n+    folder_path = os.path.join(dirpath, \"PetImages\", folder_name)\n+    for fname in os.listdir(folder_path):\n+        fpath = os.path.join(folder_path, fname)\n+        try:\n+            fobj = open(fpath, \"rb\")\n+            is_jfif = tf.compat.as_bytes(\"JFIF\") in fobj.peek(10)\n+        finally:\n+            fobj.close()\n+\n+        if not is_jfif:\n+            num_skipped += 1\n+            # Delete corrupted image\n+            os.remove(fpath)\n+\n+print(f\"Deleted {num_skipped} images\")\n+\n+\"\"\"\n+## Generate a `Dataset`\n+\"\"\"\n+\n+image_size = (180, 180)\n+batch_size = 128\n+\n+train_ds, val_ds = keras.utils.image_dataset_from_directory(\n+    os.path.join(dirpath, \"PetImages\"),\n+    validation_split=0.2,\n+    subset=\"both\",\n+    seed=1337,\n+    image_size=image_size,\n+    batch_size=batch_size,\n+)\n+\n+\"\"\"\n+## Visualize the data\n+\n+Here are the first 9 images in the training dataset. As you can see, label 1 is \"dog\"\n+and label 0 is \"cat\".\n+\"\"\"\n+\n+plt.figure(figsize=(10, 10))\n+for images, labels in train_ds.take(1):\n+    for i in range(9):\n+        ax = plt.subplot(3, 3, i + 1)\n+        plt.imshow(images[i].numpy().astype(\"uint8\"))\n+        plt.title(int(labels[i]))\n+        plt.axis(\"off\")\n+\n+\"\"\"\n+## Using image data augmentation\n+\n+When you don't have a large image dataset, it's a good practice to artificially\n+introduce sample diversity by applying random yet realistic transformations to the\n+training images, such as random horizontal flipping or small random rotations. This\n+helps expose the model to different aspects of the training data while slowing down\n+overfitting.\n+\"\"\"\n+\n+data_augmentation = keras.Sequential(\n+    [\n+        layers.RandomFlip(\"horizontal\"),\n+        layers.RandomRotation(0.1),\n+    ]\n+)\n+\n+\"\"\"\n+Let's visualize what the augmented samples look like, by applying `data_augmentation`\n+repeatedly to the first image in the dataset:\n+\"\"\"\n+\n+plt.figure(figsize=(10, 10))\n+for images, _ in train_ds.take(1):\n+    for i in range(9):\n+        augmented_images = data_augmentation(images)\n+        ax = plt.subplot(3, 3, i + 1)\n+        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n+        plt.axis(\"off\")\n+\n+\"\"\"\n+## Standardizing the data\n+\n+Our image are already in a standard size (180x180), as they are being yielded as\n+contiguous `float32` batches by our dataset. However, their RGB channel values are in\n+the `[0, 255]` range. This is not ideal for a neural network;\n+in general you should seek to make your input values small. Here, we will\n+standardize values to be in the `[0, 1]` by using a `Rescaling` layer at the start of\n+our model.\n+\"\"\"\n+\n+\"\"\"\n+## Two options to preprocess the data\n+\n+There are two ways you could be using the `data_augmentation` preprocessor:\n+\n+**Option 1: Make it part of the model**, like this:\n+\n+```python\n+inputs = keras.Input(shape=input_shape)\n+x = data_augmentation(inputs)\n+x = layers.Rescaling(1./255)(x)\n+...  # Rest of the model\n+```\n+\n+With this option, your data augmentation will happen *on device*, synchronously\n+with the rest of the model execution, meaning that it will benefit from GPU\n+acceleration.\n+\n+Note that data augmentation is inactive at test time, so the input samples will only be\n+augmented during `fit()`, not when calling `evaluate()` or `predict()`.\n+\n+If you're training on GPU, this may be a good option.\n+\n+**Option 2: apply it to the dataset**, so as to obtain a dataset that yields batches of\n+augmented images, like this:\n+\n+```python\n+augmented_train_ds = train_ds.map(\n+    lambda x, y: (data_augmentation(x, training=True), y))\n+```\n+\n+With this option, your data augmentation will happen **on CPU**, asynchronously, and will\n+be buffered before going into the model.\n+\n+If you're training on CPU, this is the better option, since it makes data augmentation\n+asynchronous and non-blocking.\n+\n+In our case, we'll go with the second option. If you're not sure\n+which one to pick, this second option (asynchronous preprocessing) is always a solid choice.\n+\"\"\"\n+\n+\"\"\"\n+## Configure the dataset for performance\n+\n+Let's apply data augmentation to our training dataset,\n+and let's make sure to use buffered prefetching so we can yield data from disk without\n+having I/O becoming blocking:\n+\"\"\"\n+\n+print(\"Make datasets\")\n+# Apply `data_augmentation` to the training images.\n+train_ds = train_ds.map(\n+    lambda img, label: (data_augmentation(img), label),\n+    num_parallel_calls=tf.data.AUTOTUNE,\n+)\n+# Prefetching samples in GPU memory helps maximize GPU utilization.\n+train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n+val_ds = val_ds.prefetch(tf.data.AUTOTUNE)\n+\n+\"\"\"\n+## Build a model\n+\n+We'll build a small version of the Xception network. We haven't particularly tried to\n+optimize the architecture; if you want to do a systematic search for the best model\n+configuration, consider using\n+[KerasTuner](https://github.com/keras-team/keras-tuner).\n+\n+Note that:\n+\n+- We start the model with the `data_augmentation` preprocessor, followed by a\n+ `Rescaling` layer.\n+- We include a `Dropout` layer before the final classification layer.\n+\"\"\"\n+\n+\n+def make_model(input_shape, num_classes):\n+    inputs = keras.Input(shape=input_shape)\n+\n+    # Entry block\n+    x = layers.Rescaling(1.0 / 255)(inputs)\n+    x = layers.Conv2D(128, 3, strides=2, padding=\"same\")(x)\n+    x = layers.BatchNormalization()(x)\n+    x = layers.Activation(\"relu\")(x)\n+\n+    previous_block_activation = x  # Set aside residual\n+\n+    for size in [256, 512, 728]:\n+        x = layers.Activation(\"relu\")(x)\n+        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n+        x = layers.BatchNormalization()(x)\n+\n+        x = layers.Activation(\"relu\")(x)\n+        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n+        x = layers.BatchNormalization()(x)\n+\n+        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n+\n+        # Project residual\n+        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n+            previous_block_activation\n+        )\n+        x = layers.add([x, residual])  # Add back residual\n+        previous_block_activation = x  # Set aside next residual\n+\n+    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n+    x = layers.BatchNormalization()(x)\n+    x = layers.Activation(\"relu\")(x)\n+\n+    x = layers.GlobalAveragePooling2D()(x)\n+    if num_classes == 2:\n+        activation = \"sigmoid\"\n+        units = 1\n+    else:\n+        activation = \"softmax\"\n+        units = num_classes\n+\n+    x = layers.Dropout(0.5)(x)\n+    outputs = layers.Dense(units, activation=activation)(x)\n+    return keras.Model(inputs, outputs)\n+\n+\n+model = make_model(input_shape=image_size + (3,), num_classes=2)\n+keras.utils.plot_model(model, show_shapes=True)\n+\n+\"\"\"\n+## Train the model\n+\"\"\"\n+\n+epochs = 25\n+\n+callbacks = [\n+    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.keras\"),\n+]\n+\n+model.compile(\n+    optimizer=keras.optimizers.Adam(1e-3),\n+    loss=\"binary_crossentropy\",\n+    metrics=[\"accuracy\"],\n+)\n+model.fit(\n+    train_ds,\n+    epochs=epochs,\n+    callbacks=callbacks,\n+    validation_data=val_ds,\n+)\n+\n+\"\"\"\n+We get to >90% validation accuracy after training for 25 epochs on the full dataset\n+(in practice, you can train for 50+ epochs before validation performance starts degrading).\n+\"\"\"\n+\n+\"\"\"\n+## Run inference on new data\n+\n+Note that data augmentation and dropout are inactive at inference time.\n+\"\"\"\n+\n+img = keras.utils.load_img(\n+    f\"{dirpath}/PetImages/Cat/6779.jpg\", target_size=image_size\n+)\n+img_array = keras.utils.img_to_array(img)\n+img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n+\n+predictions = model.predict(img_array)\n+score = float(predictions[0])\n+print(f\"This image is {100 * (1 - score):.2f}% cat and {100 * score:.2f}% dog.\")\n\n@@ -0,0 +1,288 @@\n+\"\"\"\n+Title: Character-level recurrent sequence-to-sequence model\n+Author: [fchollet](https://twitter.com/fchollet)\n+Date created: 2017/09/29\n+Last modified: 2020/04/26\n+Description: Character-level recurrent sequence-to-sequence model.\n+Accelerator: GPU\n+\"\"\"\n+\"\"\"\n+## Introduction\n+\n+This example demonstrates how to implement a basic character-level\n+recurrent sequence-to-sequence model. We apply it to translating\n+short English sentences into short French sentences,\n+character-by-character. Note that it is fairly unusual to\n+do character-level machine translation, as word-level\n+models are more common in this domain.\n+\n+**Summary of the algorithm**\n+\n+- We start with input sequences from a domain (e.g. English sentences)\n+    and corresponding target sequences from another domain\n+    (e.g. French sentences).\n+- An encoder LSTM turns input sequences to 2 state vectors\n+    (we keep the last LSTM state and discard the outputs).\n+- A decoder LSTM is trained to turn the target sequences into\n+    the same sequence but offset by one timestep in the future,\n+    a training process called \"teacher forcing\" in this context.\n+    It uses as initial state the state vectors from the encoder.\n+    Effectively, the decoder learns to generate `targets[t+1...]`\n+    given `targets[...t]`, conditioned on the input sequence.\n+- In inference mode, when we want to decode unknown input sequences, we:\n+    - Encode the input sequence into state vectors\n+    - Start with a target sequence of size 1\n+        (just the start-of-sequence character)\n+    - Feed the state vectors and 1-char target sequence\n+        to the decoder to produce predictions for the next character\n+    - Sample the next character using these predictions\n+        (we simply use argmax).\n+    - Append the sampled character to the target sequence\n+    - Repeat until we generate the end-of-sequence character or we\n+        hit the character limit.\n+\"\"\"\n+\n+\"\"\"\n+## Setup\n+\"\"\"\n+\n+import numpy as np\n+import keras_core as keras\n+import os\n+from pathlib import Path\n+\n+\"\"\"\n+## Download the data\n+\"\"\"\n+\n+fpath = keras.utils.get_file(\n+    origin=\"http://www.manythings.org/anki/fra-eng.zip\"\n+)\n+dirpath = Path(fpath).parent.absolute()\n+os.system(f\"unzip -q {fpath} -d {dirpath}\")\n+\n+\"\"\"\n+## Configuration\n+\"\"\"\n+\n+batch_size = 64  # Batch size for training.\n+epochs = 100  # Number of epochs to train for.\n+latent_dim = 256  # Latent dimensionality of the encoding space.\n+num_samples = 10000  # Number of samples to train on.\n+# Path to the data txt file on disk.\n+data_path = os.path.join(dirpath, \"fra.txt\")\n+\n+\"\"\"\n+## Prepare the data\n+\"\"\"\n+\n+# Vectorize the data.\n+input_texts = []\n+target_texts = []\n+input_characters = set()\n+target_characters = set()\n+with open(data_path, \"r\", encoding=\"utf-8\") as f:\n+    lines = f.read().split(\"\\n\")\n+for line in lines[: min(num_samples, len(lines) - 1)]:\n+    input_text, target_text, _ = line.split(\"\\t\")\n+    # We use \"tab\" as the \"start sequence\" character\n+    # for the targets, and \"\\n\" as \"end sequence\" character.\n+    target_text = \"\\t\" + target_text + \"\\n\"\n+    input_texts.append(input_text)\n+    target_texts.append(target_text)\n+    for char in input_text:\n+        if char not in input_characters:\n+            input_characters.add(char)\n+    for char in target_text:\n+        if char not in target_characters:\n+            target_characters.add(char)\n+\n+input_characters = sorted(list(input_characters))\n+target_characters = sorted(list(target_characters))\n+num_encoder_tokens = len(input_characters)\n+num_decoder_tokens = len(target_characters)\n+max_encoder_seq_length = max([len(txt) for txt in input_texts])\n+max_decoder_seq_length = max([len(txt) for txt in target_texts])\n+\n+print(\"Number of samples:\", len(input_texts))\n+print(\"Number of unique input tokens:\", num_encoder_tokens)\n+print(\"Number of unique output tokens:\", num_decoder_tokens)\n+print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n+print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n+\n+input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n+target_token_index = dict(\n+    [(char, i) for i, char in enumerate(target_characters)]\n+)\n+\n+encoder_input_data = np.zeros(\n+    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n+    dtype=\"float32\",\n+)\n+decoder_input_data = np.zeros(\n+    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n+    dtype=\"float32\",\n+)\n+decoder_target_data = np.zeros(\n+    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n+    dtype=\"float32\",\n+)\n+\n+for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n+    for t, char in enumerate(input_text):\n+        encoder_input_data[i, t, input_token_index[char]] = 1.0\n+    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n+    for t, char in enumerate(target_text):\n+        # decoder_target_data is ahead of decoder_input_data by one timestep\n+        decoder_input_data[i, t, target_token_index[char]] = 1.0\n+        if t > 0:\n+            # decoder_target_data will be ahead by one timestep\n+            # and will not include the start character.\n+            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n+    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n+    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n+\n+\"\"\"\n+## Build the model\n+\"\"\"\n+\n+# Define an input sequence and process it.\n+encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n+encoder = keras.layers.LSTM(latent_dim, return_state=True)\n+encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n+\n+# We discard `encoder_outputs` and only keep the states.\n+encoder_states = [state_h, state_c]\n+\n+# Set up the decoder, using `encoder_states` as initial state.\n+decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n+\n+# We set up our decoder to return full output sequences,\n+# and to return internal states as well. We don't use the\n+# return states in the training model, but we will use them in inference.\n+decoder_lstm = keras.layers.LSTM(\n+    latent_dim, return_sequences=True, return_state=True\n+)\n+decoder_outputs, _, _ = decoder_lstm(\n+    decoder_inputs, initial_state=encoder_states\n+)\n+decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n+decoder_outputs = decoder_dense(decoder_outputs)\n+\n+# Define the model that will turn\n+# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n+model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n+\n+\"\"\"\n+## Train the model\n+\"\"\"\n+\n+model.compile(\n+    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n+)\n+model.fit(\n+    [encoder_input_data, decoder_input_data],\n+    decoder_target_data,\n+    batch_size=batch_size,\n+    epochs=epochs,\n+    validation_split=0.2,\n+)\n+# Save model\n+model.save(\"s2s_model.keras\")\n+\n+\"\"\"\n+## Run inference (sampling)\n+\n+1. encode input and retrieve initial decoder state\n+2. run one step of decoder with this initial state\n+and a \"start of sequence\" token as target.\n+Output will be the next target token.\n+3. Repeat with the current target token and current states\n+\"\"\"\n+\n+# Define sampling models\n+# Restore the model and construct the encoder and decoder.\n+model = keras.models.load_model(\"s2s_model.keras\")\n+\n+encoder_inputs = model.input[0]  # input_1\n+encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # lstm_1\n+encoder_states = [state_h_enc, state_c_enc]\n+encoder_model = keras.Model(encoder_inputs, encoder_states)\n+\n+decoder_inputs = model.input[1]  # input_2\n+decoder_state_input_h = keras.Input(shape=(latent_dim,))\n+decoder_state_input_c = keras.Input(shape=(latent_dim,))\n+decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n+decoder_lstm = model.layers[3]\n+decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n+    decoder_inputs, initial_state=decoder_states_inputs\n+)\n+decoder_states = [state_h_dec, state_c_dec]\n+decoder_dense = model.layers[4]\n+decoder_outputs = decoder_dense(decoder_outputs)\n+decoder_model = keras.Model(\n+    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n+)\n+\n+# Reverse-lookup token index to decode sequences back to\n+# something readable.\n+reverse_input_char_index = dict(\n+    (i, char) for char, i in input_token_index.items()\n+)\n+reverse_target_char_index = dict(\n+    (i, char) for char, i in target_token_index.items()\n+)\n+\n+\n+def decode_sequence(input_seq):\n+    # Encode the input as state vectors.\n+    states_value = encoder_model.predict(input_seq, verbose=0)\n+\n+    # Generate empty target sequence of length 1.\n+    target_seq = np.zeros((1, 1, num_decoder_tokens))\n+    # Populate the first character of target sequence with the start character.\n+    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n+\n+    # Sampling loop for a batch of sequences\n+    # (to simplify, here we assume a batch of size 1).\n+    stop_condition = False\n+    decoded_sentence = \"\"\n+    while not stop_condition:\n+        output_tokens, h, c = decoder_model.predict(\n+            [target_seq] + states_value, verbose=0\n+        )\n+\n+        # Sample a token\n+        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n+        sampled_char = reverse_target_char_index[sampled_token_index]\n+        decoded_sentence += sampled_char\n+\n+        # Exit condition: either hit max length\n+        # or find stop character.\n+        if (\n+            sampled_char == \"\\n\"\n+            or len(decoded_sentence) > max_decoder_seq_length\n+        ):\n+            stop_condition = True\n+\n+        # Update the target sequence (of length 1).\n+        target_seq = np.zeros((1, 1, num_decoder_tokens))\n+        target_seq[0, 0, sampled_token_index] = 1.0\n+\n+        # Update states\n+        states_value = [h, c]\n+    return decoded_sentence\n+\n+\n+\"\"\"\n+You can now generate decoded sentences as such:\n+\"\"\"\n+\n+for seq_index in range(20):\n+    # Take one sequence (part of the training set)\n+    # for trying out decoding.\n+    input_seq = encoder_input_data[seq_index : seq_index + 1]\n+    decoded_sentence = decode_sequence(input_seq)\n+    print(\"-\")\n+    print(\"Input sentence:\", input_texts[seq_index])\n+    print(\"Decoded sentence:\", decoded_sentence)\n\n@@ -0,0 +1,84 @@\n+\"\"\"\n+Title: Simple MNIST convnet\n+Author: [fchollet](https://twitter.com/fchollet)\n+Date created: 2015/06/19\n+Last modified: 2020/04/21\n+Description: A simple convnet that achieves ~99% test accuracy on MNIST.\n+Accelerator: GPU\n+\"\"\"\n+\n+\"\"\"\n+## Setup\n+\"\"\"\n+\n+import numpy as np\n+import keras_core as keras\n+from keras_core import layers\n+\n+\"\"\"\n+## Prepare the data\n+\"\"\"\n+\n+# Model / data parameters\n+num_classes = 10\n+input_shape = (28, 28, 1)\n+\n+# Load the data and split it between train and test sets\n+(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n+\n+# Scale images to the [0, 1] range\n+x_train = x_train.astype(\"float32\") / 255\n+x_test = x_test.astype(\"float32\") / 255\n+# Make sure images have shape (28, 28, 1)\n+x_train = np.expand_dims(x_train, -1)\n+x_test = np.expand_dims(x_test, -1)\n+print(\"x_train shape:\", x_train.shape)\n+print(x_train.shape[0], \"train samples\")\n+print(x_test.shape[0], \"test samples\")\n+\n+\n+# convert class vectors to binary class matrices\n+y_train = keras.utils.to_categorical(y_train, num_classes)\n+y_test = keras.utils.to_categorical(y_test, num_classes)\n+\n+\"\"\"\n+## Build the model\n+\"\"\"\n+\n+model = keras.Sequential(\n+    [\n+        keras.Input(shape=input_shape),\n+        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n+        layers.MaxPooling2D(pool_size=(2, 2)),\n+        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n+        layers.MaxPooling2D(pool_size=(2, 2)),\n+        layers.Flatten(),\n+        layers.Dropout(0.5),\n+        layers.Dense(num_classes, activation=\"softmax\"),\n+    ]\n+)\n+\n+model.summary()\n+\n+\"\"\"\n+## Train the model\n+\"\"\"\n+\n+batch_size = 128\n+epochs = 15\n+\n+model.compile(\n+    loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n+)\n+\n+model.fit(\n+    x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1\n+)\n+\n+\"\"\"\n+## Evaluate the trained model\n+\"\"\"\n+\n+score = model.evaluate(x_test, y_test, verbose=0)\n+print(\"Test loss:\", score[0])\n+print(\"Test accuracy:\", score[1])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
