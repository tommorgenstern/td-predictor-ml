{"custom_id": "keras#e5351f331b10235da567340b46043247432d5ef6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 50 | Lines Deleted: 16 | Files Changed: 3 | Hunks: 16 | Methods Changed: 7 | Complexity Δ (Sum/Max): 4/3 | Churn Δ: 66 | Churn Cumulative: 1384 | Contributors (this commit): 13 | Commits (past 90d): 12 | Contributors (cumulative): 22 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,4 +1,5 @@\n import jax\n+import ml_dtypes\n import numpy as np\n \n from keras.src import backend\n@@ -39,7 +40,7 @@ def rgb_to_grayscale(images, data_format=None):\n def rgb_to_hsv(images, data_format=None):\n     # Ref: dm_pix\n     images = convert_to_tensor(images)\n-    dtype = images.dtype\n+    dtype = backend.standardize_dtype(images.dtype)\n     data_format = backend.standardize_data_format(data_format)\n     channels_axis = -1 if data_format == \"channels_last\" else -3\n     if len(images.shape) not in (3, 4):\n@@ -51,9 +52,9 @@ def rgb_to_hsv(images, data_format=None):\n     if not backend.is_float_dtype(dtype):\n         raise ValueError(\n             \"Invalid images dtype: expected float dtype. \"\n-            f\"Received: images.dtype={backend.standardize_dtype(dtype)}\"\n+            f\"Received: images.dtype={dtype}\"\n         )\n-    eps = np.finfo(dtype).eps\n+    eps = ml_dtypes.finfo(dtype).eps\n     images = np.where(np.abs(images) < eps, 0.0, images)\n     red, green, blue = np.split(images, 3, channels_axis)\n     red = np.squeeze(red, channels_axis)\n\n@@ -1,3 +1,4 @@\n+import ml_dtypes\n import numpy as np\n \n from keras.src import backend\n@@ -870,10 +871,23 @@ def saturate_cast(x, dtype):\n \n def _saturate_cast(x, dtype, backend_module=None):\n     backend_module = backend_module or backend\n+\n+    def get_dtype_min_max(dtype):\n+        if \"bool\" == dtype:\n+            dtype_min = 0\n+            dtype_max = 1\n+        elif \"int\" in dtype:\n+            dtype_min = ml_dtypes.iinfo(dtype).min\n+            dtype_max = ml_dtypes.iinfo(dtype).max\n+        else:\n+            dtype_min = ml_dtypes.finfo(dtype).min\n+            dtype_max = ml_dtypes.finfo(dtype).max\n+        return dtype_min, dtype_max\n+\n     dtype = backend.standardize_dtype(dtype)\n     in_dtype = backend.standardize_dtype(x.dtype)\n-    in_info = np.iinfo(in_dtype) if \"int\" in in_dtype else np.finfo(in_dtype)\n-    out_info = np.iinfo(dtype) if \"int\" in dtype else np.finfo(dtype)\n+    in_min, in_max = get_dtype_min_max(in_dtype)\n+    out_min, out_max = get_dtype_min_max(dtype)\n \n     # The output min/max may not actually be representable in the\n     # in_dtype (e.g. casting float32 to uint32).  This can lead to undefined\n@@ -882,11 +896,11 @@ def _saturate_cast(x, dtype, backend_module=None):\n     # the valid output range. The catch is that we may actually saturate\n     # to a value less than the true saturation limit, but this is the best we\n     # can do in order to avoid UB without backend op.\n-    min_limit = np.maximum(in_info.min, out_info.min).astype(in_dtype)\n-    if min_limit < out_info.min:\n+    min_limit = np.maximum(in_min, out_min).astype(in_dtype)\n+    if min_limit < out_min:\n         min_limit = np.nextafter(min_limit, 0, dtype=in_dtype)\n-    max_limit = np.minimum(in_info.max, out_info.max).astype(in_dtype)\n-    if max_limit > out_info.max:\n+    max_limit = np.minimum(in_max, out_max).astype(in_dtype)\n+    if max_limit > out_max:\n         max_limit = np.nextafter(max_limit, 0, dtype=in_dtype)\n \n     # Unconditionally apply `clip` to fix `inf` behavior.\n\n@@ -17,6 +17,7 @@ from keras.src import tree\n from keras.src.backend.common import dtypes\n from keras.src.backend.common.keras_tensor import KerasTensor\n from keras.src.ops import core\n+from keras.src.testing.test_utils import named_product\n \n \n class CoreOpsStaticShapeTest(testing.TestCase):\n@@ -863,8 +864,6 @@ class CoreOpsCorrectnessTest(testing.TestCase):\n \n \n class CoreOpsDtypeTest(testing.TestCase):\n-    import jax  # enable bfloat16 for numpy\n-\n     # TODO: Using uint64 will lead to weak type promotion (`float`),\n     # resulting in different behavior between JAX and Keras. Currently, we\n     # are skipping the test for uint64\n@@ -873,15 +872,31 @@ class CoreOpsDtypeTest(testing.TestCase):\n         for x in dtypes.ALLOWED_DTYPES\n         if x not in [\"string\", \"uint64\", \"complex64\", \"complex128\"]\n     ] + [None]\n+    INT_DTYPES = [x for x in dtypes.INT_TYPES if x != \"uint64\"]\n+    FLOAT_DTYPES = dtypes.FLOAT_TYPES\n \n     if backend.backend() == \"torch\":\n         # TODO: torch doesn't support uint16, uint32 and uint64\n         ALL_DTYPES = [\n             x for x in ALL_DTYPES if x not in [\"uint16\", \"uint32\", \"uint64\"]\n         ]\n+        INT_DTYPES = [\n+            x for x in INT_DTYPES if x not in [\"uint16\", \"uint32\", \"uint64\"]\n+        ]\n     # Remove float8 dtypes for the following tests\n     ALL_DTYPES = [x for x in ALL_DTYPES if x not in dtypes.FLOAT8_TYPES]\n \n+    def setUp(self):\n+        from jax.experimental import enable_x64\n+\n+        self.jax_enable_x64 = enable_x64()\n+        self.jax_enable_x64.__enter__()\n+        return super().setUp()\n+\n+    def tearDown(self) -> None:\n+        self.jax_enable_x64.__exit__(None, None, None)\n+        return super().tearDown()\n+\n     @parameterized.parameters(\n         ((), None, backend.floatx()),\n         ([], None, backend.floatx()),\n@@ -922,13 +937,17 @@ class CoreOpsDtypeTest(testing.TestCase):\n             jax_disable_x64 = contextlib.nullcontext()\n \n         with jax_disable_x64:\n-            self.assertEqual(\n-                backend.standardize_dtype(\n-                    ops.convert_to_tensor(x, dtype=dtype).dtype\n-                ),\n-                expected_dtype,\n+            self.assertDType(\n+                ops.convert_to_tensor(x, dtype=dtype), expected_dtype\n             )\n \n+    @parameterized.named_parameters(named_product(dtype=ALL_DTYPES))\n+    def test_saturate_cast(self, dtype):\n+        x = np.ones((1,))\n+\n+        self.assertDType(core.saturate_cast(x, dtype), dtype)\n+        self.assertDType(core.SaturateCast(dtype).symbolic_call(x), dtype)\n+\n \n class CoreOpsCallsTests(testing.TestCase):\n     def test_map_basic_call(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a93828a94f105909f9398c00d2cddf4ac43197ac", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 42 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 4 | Methods Changed: 5 | Complexity Δ (Sum/Max): 4/2 | Churn Δ: 43 | Churn Cumulative: 1120 | Contributors (this commit): 8 | Commits (past 90d): 11 | Contributors (cumulative): 11 | DMM Complexity: 0.6666666666666666\n\nDIFF:\n@@ -515,6 +515,13 @@ def save_weights_only(model, filepath, objects_to_skip=None):\n \n     Supports both `.weights.h5` and `.keras`.\n     \"\"\"\n+    if not model.built:\n+        raise ValueError(\n+            \"You are saving a model that has not yet been built. \"\n+            \"Try building the model first by calling it on some data or \"\n+            \"by using `build()`.\"\n+        )\n+\n     filepath = str(filepath)\n     tmp_dir = None\n     remote_filepath = None\n@@ -556,6 +563,13 @@ def load_weights_only(\n \n     Note: only supports h5 for now.\n     \"\"\"\n+    if not model.built:\n+        raise ValueError(\n+            \"You are loading weights into a model that has not yet been built. \"\n+            \"Try building the model first by calling it on some data or \"\n+            \"by using `build()`.\"\n+        )\n+\n     archive = None\n     tmp_dir = None\n     filepath = str(filepath)\n\n@@ -469,6 +469,33 @@ class SavingTest(testing.TestCase):\n         model.load_weights(temp_filepath)\n         self.assertAllClose(model.predict(ref_input), ref_output, atol=1e-6)\n \n+    def test_save_weights_only_with_unbuilt_model(self):\n+        temp_filepath = Path(\n+            os.path.join(self.get_temp_dir(), \"mymodel.weights.h5\")\n+        )\n+        model = _get_subclassed_model()\n+        with self.assertRaisesRegex(\n+            ValueError, \"You are saving a model that has not yet been built.\"\n+        ):\n+            saving_lib.save_weights_only(model, temp_filepath)\n+\n+    def test_load_weights_only_with_unbuilt_model(self):\n+        temp_filepath = Path(\n+            os.path.join(self.get_temp_dir(), \"mymodel.weights.h5\")\n+        )\n+        model = _get_subclassed_model()\n+        x = np.random.random((100, 32))\n+        _ = model.predict(x)  # Build the model by calling it on some data\n+        saving_lib.save_weights_only(model, temp_filepath)\n+        saving_lib.load_weights_only(model, temp_filepath)\n+\n+        new_model = _get_subclassed_model()\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"You are loading weights into a model that has not yet been built.\",\n+        ):\n+            saving_lib.load_weights_only(new_model, temp_filepath)\n+\n     def test_load_weights_only_with_keras_file(self):\n         # Test loading weights from whole saved model\n         temp_filepath = Path(os.path.join(self.get_temp_dir(), \"mymodel.keras\"))\n@@ -1071,6 +1098,6 @@ class SavingBattleTest(testing.TestCase):\n         with mock.patch(\n             \"keras.src.utils.file_utils.is_remote_path\", is_remote_path\n         ):\n-            model = _get_subclassed_model()\n+            model = _get_basic_functional_model()\n             model.save_weights(temp_filepath)\n             model.load_weights(temp_filepath)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4e2e6e10400af2661fb7338d053d82b7a34fb596", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 10 | Files Changed: 2 | Hunks: 6 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 21 | Churn Cumulative: 44 | Contributors (this commit): 3 | Commits (past 90d): 2 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -136,14 +136,12 @@ class EarlyStopping(Callback):\n             )\n         if self.monitor_op == ops.less:\n             self.min_delta *= -1\n-        self.best = (\n-            float(\"inf\") if self.monitor_op == ops.less else -float(\"inf\")\n-        )\n \n     def on_train_begin(self, logs=None):\n         # Allow instances to be re-used\n         self.wait = 0\n         self.stopped_epoch = 0\n+        self.best = None\n         self.best_weights = None\n         self.best_epoch = 0\n \n@@ -210,4 +208,6 @@ class EarlyStopping(Callback):\n         return monitor_value\n \n     def _is_improvement(self, monitor_value, reference_value):\n+        if reference_value is None:\n+            return True\n         return self.monitor_op(monitor_value - self.min_delta, reference_value)\n\n@@ -114,16 +114,17 @@ class EarlyStoppingTest(testing.TestCase):\n             loss=\"mae\",\n             metrics=[\"mse\"],\n         )\n-        weights = model.get_weights()\n-\n-        # This should allow training to go for at least `patience` epochs\n-        model.set_weights(weights)\n-\n         stopper = callbacks.EarlyStopping(monitor=\"mse\", patience=patience)\n-        hist = model.fit(\n+\n+        history1 = model.fit(\n             data, labels, callbacks=[stopper], verbose=0, epochs=20\n         )\n-        assert len(hist.epoch) >= patience\n+        self.assertGreaterEqual(len(history1.epoch), patience)\n+\n+        history2 = model.fit(\n+            data, labels, callbacks=[stopper], verbose=0, epochs=20\n+        )\n+        self.assertGreaterEqual(len(history2.epoch), patience)\n \n     @pytest.mark.requires_trainable_backend\n     def test_early_stopping_with_baseline(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9ac3ee5957b4eca883ebfb6c0a7f8a622d6414be", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 236 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 7 | Methods Changed: 6 | Complexity Δ (Sum/Max): 9/5 | Churn Δ: 237 | Churn Cumulative: 354 | Contributors (this commit): 4 | Commits (past 90d): 6 | Contributors (cumulative): 6 | DMM Complexity: 0.9939393939393939\n\nDIFF:\n@@ -3,7 +3,14 @@ from keras.src.api_export import keras_export\n from keras.src.layers.preprocessing.image_preprocessing.base_image_preprocessing_layer import (  # noqa: E501\n     BaseImagePreprocessingLayer,\n )\n+from keras.src.layers.preprocessing.image_preprocessing.bounding_boxes.converters import (  # noqa: E501\n+    clip_to_image_size,\n+)\n+from keras.src.layers.preprocessing.image_preprocessing.bounding_boxes.converters import (  # noqa: E501\n+    convert_format,\n+)\n from keras.src.random.seed_generator import SeedGenerator\n+from keras.src.utils import backend_utils\n \n \n @keras_export(\"keras.layers.RandomZoom\")\n@@ -175,13 +182,121 @@ class RandomZoom(BaseImagePreprocessingLayer):\n     def transform_labels(self, labels, transformation, training=True):\n         return labels\n \n+    def get_transformed_x_y(self, x, y, transform):\n+        a0, a1, a2, b0, b1, b2, c0, c1 = self.backend.numpy.split(\n+            transform, 8, axis=-1\n+        )\n+\n+        k = c0 * x + c1 * y + 1\n+        x_transformed = (a0 * x + a1 * y + a2) / k\n+        y_transformed = (b0 * x + b1 * y + b2) / k\n+        return x_transformed, y_transformed\n+\n+    def get_clipped_bbox(self, bounding_boxes, h_end, h_start, w_end, w_start):\n+        bboxes = bounding_boxes[\"boxes\"]\n+        x1, y1, x2, y2 = self.backend.numpy.split(bboxes, 4, axis=-1)\n+\n+        if len(bboxes.shape) == 3:\n+            h_end = self.backend.numpy.expand_dims(h_end, -1)\n+            h_start = self.backend.numpy.expand_dims(h_start, -1)\n+            w_end = self.backend.numpy.expand_dims(w_end, -1)\n+            w_start = self.backend.numpy.expand_dims(w_start, -1)\n+\n+        x1 = self.backend.numpy.clip(x1, w_start, w_end) - w_start\n+        y1 = self.backend.numpy.clip(y1, h_start, h_end) - h_start\n+        x2 = self.backend.numpy.clip(x2, w_start, w_end) - w_start\n+        y2 = self.backend.numpy.clip(y2, h_start, h_end) - h_start\n+        bounding_boxes[\"boxes\"] = self.backend.numpy.concatenate(\n+            [x1, y1, x2, y2], axis=-1\n+        )\n+        return bounding_boxes\n+\n     def transform_bounding_boxes(\n         self,\n         bounding_boxes,\n         transformation,\n         training=True,\n     ):\n-        raise NotImplementedError\n+        if backend_utils.in_tf_graph():\n+            self.backend.set_backend(\"tensorflow\")\n+\n+        width_zoom = transformation[\"width_zoom\"]\n+        height_zoom = transformation[\"height_zoom\"]\n+        inputs_shape = transformation[\"input_shape\"]\n+\n+        if self.data_format == \"channels_first\":\n+            height = inputs_shape[-2]\n+            width = inputs_shape[-1]\n+        else:\n+            height = inputs_shape[-3]\n+            width = inputs_shape[-2]\n+\n+        bounding_boxes = convert_format(\n+            bounding_boxes,\n+            source=self.bounding_box_format,\n+            target=\"xyxy\",\n+            height=height,\n+            width=width,\n+        )\n+\n+        zooms = self.backend.cast(\n+            self.backend.numpy.concatenate([width_zoom, height_zoom], axis=1),\n+            dtype=\"float32\",\n+        )\n+        transform = self._get_zoom_matrix(zooms, height, width)\n+\n+        w_start, h_start = self.get_transformed_x_y(\n+            0,\n+            0,\n+            transform,\n+        )\n+\n+        w_end, h_end = self.get_transformed_x_y(\n+            width,\n+            height,\n+            transform,\n+        )\n+\n+        bounding_boxes = self.get_clipped_bbox(\n+            bounding_boxes, h_end, h_start, w_end, w_start\n+        )\n+\n+        height_transformed = h_end - h_start\n+        width_transformed = w_end - w_start\n+\n+        height_transformed = self.backend.numpy.expand_dims(\n+            height_transformed, -1\n+        )\n+        width_transformed = self.backend.numpy.expand_dims(\n+            width_transformed, -1\n+        )\n+\n+        bounding_boxes = convert_format(\n+            bounding_boxes,\n+            source=\"xyxy\",\n+            target=\"rel_xyxy\",\n+            height=height_transformed,\n+            width=width_transformed,\n+        )\n+\n+        bounding_boxes = clip_to_image_size(\n+            bounding_boxes=bounding_boxes,\n+            height=height_transformed,\n+            width=width_transformed,\n+            format=\"rel_xyxy\",\n+        )\n+\n+        bounding_boxes = convert_format(\n+            bounding_boxes,\n+            source=\"rel_xyxy\",\n+            target=self.bounding_box_format,\n+            height=height,\n+            width=width,\n+        )\n+\n+        self.backend.reset()\n+\n+        return bounding_boxes\n \n     def transform_segmentation_masks(\n         self, segmentation_masks, transformation, training=True\n@@ -229,6 +344,7 @@ class RandomZoom(BaseImagePreprocessingLayer):\n         return {\n             \"height_zoom\": height_zoom,\n             \"width_zoom\": width_zoom,\n+            \"input_shape\": images_shape,\n         }\n \n     def _zoom_inputs(self, inputs, transformation):\n\n@@ -7,6 +7,7 @@ from keras.src import backend\n from keras.src import layers\n from keras.src import models\n from keras.src import testing\n+from keras.src.utils import backend_utils\n \n \n class RandomZoomTest(testing.TestCase):\n@@ -148,3 +149,121 @@ class RandomZoomTest(testing.TestCase):\n \n         model.compile(loss=\"mse\")\n         model.fit(np.random.random((2, 2, 2, 1)), y=np.random.random((2,)))\n+\n+    @parameterized.named_parameters(\n+        (\n+            \"with_zoom_in\",\n+            [[[0.1]], [[0.1]]],\n+            [[[0.0, 0.0, 8.0, 0.0], [8.0, 0.0, 8.0, 10.0]]],\n+        ),\n+        (\n+            \"with_zoom_out\",\n+            [[[1.9]], [[1.9]]],\n+            [\n+                [\n+                    [2.710526, 2.657895, 3.763158, 3.710526],\n+                    [4.815789, 4.236842, 5.868421, 5.289474],\n+                ]\n+            ],\n+        ),\n+    )\n+    def test_random_flip_bounding_boxes(self, zoom, expected_boxes):\n+        data_format = backend.config.image_data_format()\n+        if data_format == \"channels_last\":\n+            image_shape = (10, 8, 3)\n+        else:\n+            image_shape = (3, 10, 8)\n+        input_image = np.random.random(image_shape)\n+        bounding_boxes = {\n+            \"boxes\": np.array(\n+                [\n+                    [2, 1, 4, 3],\n+                    [6, 4, 8, 6],\n+                ]\n+            ),\n+            \"labels\": np.array([[1, 2]]),\n+        }\n+        input_data = {\"images\": input_image, \"bounding_boxes\": bounding_boxes}\n+        random_zoom_layer = layers.RandomZoom(\n+            height_factor=(0.5, 0.5),\n+            data_format=data_format,\n+            seed=42,\n+            bounding_box_format=\"xyxy\",\n+        )\n+\n+        transformation = {\n+            \"height_zoom\": backend_utils.convert_tf_tensor(np.array(zoom[0])),\n+            \"width_zoom\": backend_utils.convert_tf_tensor(np.array(zoom[1])),\n+            \"input_shape\": image_shape,\n+        }\n+        output = random_zoom_layer.transform_bounding_boxes(\n+            input_data[\"bounding_boxes\"],\n+            transformation=transformation,\n+            training=True,\n+        )\n+\n+        self.assertAllClose(output[\"boxes\"], expected_boxes)\n+\n+    @parameterized.named_parameters(\n+        (\n+            \"with_zoom_in\",\n+            [[[0.1]], [[0.1]]],\n+            [[[0.0, 0.0, 8.0, 0.0], [8.0, 0.0, 8.0, 10.0]]],\n+        ),\n+        (\n+            \"with_zoom_out\",\n+            [[[1.9]], [[1.9]]],\n+            [\n+                [\n+                    [2.710526, 2.657895, 3.763158, 3.710526],\n+                    [4.815789, 4.236842, 5.868421, 5.289474],\n+                ]\n+            ],\n+        ),\n+    )\n+    def test_random_flip_tf_data_bounding_boxes(self, zoom, expected_boxes):\n+        data_format = backend.config.image_data_format()\n+        if backend.config.image_data_format() == \"channels_last\":\n+            image_shape = (1, 10, 8, 3)\n+        else:\n+            image_shape = (1, 3, 10, 8)\n+        input_image = np.random.random(image_shape)\n+        bounding_boxes = {\n+            \"boxes\": np.array(\n+                [\n+                    [\n+                        [2, 1, 4, 3],\n+                        [6, 4, 8, 6],\n+                    ]\n+                ]\n+            ),\n+            \"labels\": np.array([[1, 2]]),\n+        }\n+\n+        input_data = {\"images\": input_image, \"bounding_boxes\": bounding_boxes}\n+\n+        ds = tf_data.Dataset.from_tensor_slices(input_data)\n+        random_zoom_layer = layers.RandomZoom(\n+            height_factor=0.5,\n+            data_format=data_format,\n+            seed=42,\n+            bounding_box_format=\"xyxy\",\n+        )\n+\n+        transformation = {\n+            \"height_zoom\": backend_utils.convert_tf_tensor(np.array(zoom[0])),\n+            \"width_zoom\": backend_utils.convert_tf_tensor(np.array(zoom[1])),\n+            \"input_shape\": image_shape,\n+        }\n+\n+        ds = ds.map(\n+            lambda x: random_zoom_layer.transform_bounding_boxes(\n+                x[\"bounding_boxes\"],\n+                transformation=transformation,\n+                training=True,\n+            )\n+        )\n+\n+        output = next(iter(ds))\n+        expected_boxes = np.array(expected_boxes)\n+        self.assertAllClose(output[\"boxes\"], expected_boxes)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5d36ee1f219bb650dd108c35b257c783cd034ffd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 27 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 3/2 | Churn Δ: 28 | Churn Cumulative: 367 | Contributors (this commit): 7 | Commits (past 90d): 8 | Contributors (cumulative): 12 | DMM Complexity: 0.0\n\nDIFF:\n@@ -672,7 +672,7 @@ class BaseOptimizer(KerasSaveable):\n         \"\"\"\n         # Shortcut for `tf.Variable` because it doesn't have a\n         # `overwrite_with_gradient` attr\n-        if not hasattr(vars[0], \"overwrite_with_gradient\"):\n+        if any(not hasattr(v, \"overwrite_with_gradient\") for v in vars):\n             return grads, vars\n \n         # Shallow copies\n@@ -723,7 +723,11 @@ class BaseOptimizer(KerasSaveable):\n             if filtered_grads[i] is None:\n                 filtered_grads.pop(i)\n                 v = filtered_vars.pop(i)\n+                try:\n                     missing_grad_vars.append(v.path)\n+                except AttributeError:\n+                    # `tf.Variable` doesn't have `path` attr.\n+                    missing_grad_vars.append(v.name)\n \n         if not filtered_grads:\n             raise ValueError(\"No gradients provided for any variable.\")\n\n@@ -401,3 +401,25 @@ class OptimizerTest(testing.TestCase):\n         reloaded = pickle.loads(pickle.dumps(optimizer))\n \n         self.assertEqual(optimizer.get_config(), reloaded.get_config())\n+\n+    @pytest.mark.skipif(\n+        backend.backend() != \"tensorflow\",\n+        reason=\"The tf.Variable test can only run with TensorFlow backend.\",\n+    )\n+    def test_mixed_with_tf_variables(self):\n+        import tensorflow as tf\n+\n+        v = backend.Variable([[1.0, 2.0], [3.0, 4.0]])\n+        grads = backend.convert_to_tensor([[1.0, 1.0], [1.0, 1.0]])\n+        tf_v = tf.Variable([[1.0, 2.0], [3.0, 4.0]])\n+        tf_grads = backend.convert_to_tensor([[1.0, 1.0], [1.0, 1.0]])\n+        optimizer = optimizers.Adam(learning_rate=1.0)\n+        optimizer.apply_gradients([(grads, v), (tf_grads, tf_v)])\n+        self.assertAllClose(optimizer.iterations, 1)\n+\n+        # Test with no grads\n+        with self.assertWarnsRegex(\n+            UserWarning, \"Gradients do not exist for variables\"\n+        ):\n+            optimizer.apply_gradients([(grads, v), (None, tf_v)])\n+            self.assertAllClose(optimizer.iterations, 2)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ceabd61f89572a4b83c0348a96c5a8fd8af25b87", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 51 | Lines Deleted: 7 | Files Changed: 2 | Hunks: 7 | Methods Changed: 6 | Complexity Δ (Sum/Max): 8/7 | Churn Δ: 58 | Churn Cumulative: 1092 | Contributors (this commit): 12 | Commits (past 90d): 13 | Contributors (cumulative): 19 | DMM Complexity: 1.0\n\nDIFF:\n@@ -909,26 +909,47 @@ def _saturate_cast(x, dtype, backend_module=None):\n     return backend_module.cast(x, dtype)\n \n \n+class ConvertToTensor(Operation):\n+    def __init__(self, dtype, sparse):\n+        super().__init__()\n+        self.dtype = backend.standardize_dtype(dtype)\n+        self.sparse = sparse\n+\n+    def call(self, x):\n+        return backend.core.convert_to_tensor(\n+            x, dtype=self.dtype, sparse=self.sparse\n+        )\n+\n+    def compute_output_spec(self, x):\n+        dtype = x.dtype if self.dtype is None else self.dtype\n+        sparse = (\n+            False if self.sparse is not None and not self.sparse else x.sparse\n+        )\n+        return backend.KerasTensor(shape=x.shape, dtype=dtype, sparse=sparse)\n+\n+\n @keras_export(\"keras.ops.convert_to_tensor\")\n def convert_to_tensor(x, dtype=None, sparse=None):\n     \"\"\"Convert a NumPy array to a tensor.\n \n     Args:\n-        x: A NumPy array.\n-        dtype: The target type.\n+        x: A NumPy array, Python array (can be nested) or a backend tensor.\n+        dtype: The target type. If `None`, the type of `x` is used.\n         sparse: Whether to keep sparse tensors. `False` will cause sparse\n             tensors to be densified. The default value of `None` means that\n             sparse tensors are kept only if the backend supports them.\n \n     Returns:\n-        A tensor of the specified `dtype`.\n+        A backend tensor of the specified `dtype` and sparseness.\n \n     Example:\n \n     >>> x = np.array([1, 2, 3])\n     >>> y = keras.ops.convert_to_tensor(x)\n     \"\"\"\n-    return backend.convert_to_tensor(x, dtype=dtype, sparse=sparse)\n+    if any_symbolic_tensors((x,)):\n+        return ConvertToTensor(dtype=dtype, sparse=sparse)(x)\n+    return backend.core.convert_to_tensor(x, dtype=dtype, sparse=sparse)\n \n \n @keras_export(\"keras.ops.convert_to_numpy\")\n\n@@ -144,6 +144,29 @@ class CoreOpsStaticShapeTest(testing.TestCase):\n         ):\n             core.unstack(x, axis=axis)\n \n+    def test_convert_to_tensor(self):\n+        x = KerasTensor((2, 3))\n+        out = core.convert_to_tensor(x)\n+        self.assertEqual(out.shape, x.shape)\n+        self.assertEqual(out.dtype, x.dtype)\n+        self.assertFalse(out.sparse)\n+\n+        out = core.convert_to_tensor(x, dtype=\"int32\")\n+        self.assertEqual(out.dtype, \"int32\")\n+\n+        out = core.convert_to_tensor(x, sparse=True)\n+        self.assertFalse(out.sparse)\n+\n+        x = KerasTensor((2, 3), sparse=True)\n+        out = core.convert_to_tensor(x)\n+        self.assertTrue(out.sparse)\n+\n+        out = core.convert_to_tensor(x, sparse=True)\n+        self.assertTrue(out.sparse)\n+\n+        out = core.convert_to_tensor(x, sparse=False)\n+        self.assertFalse(out.sparse)\n+\n \n class CoreOpsCorrectnessTest(testing.TestCase):\n     def test_map(self):\n@@ -651,9 +674,6 @@ class CoreOpsCorrectnessTest(testing.TestCase):\n         x = ops.convert_to_tensor((1, ops.array(2), 3))\n         self.assertAllEqual(x, (1, 2, 3))\n \n-        with self.assertRaises(ValueError):\n-            ops.convert_to_numpy(KerasTensor((2,)))\n-\n     @pytest.mark.skipif(\n         not backend.SUPPORTS_SPARSE_TENSORS,\n         reason=\"Backend does not support sparse tensors.\",\n@@ -1262,6 +1282,9 @@ class CoreOpsBehaviorTests(testing.TestCase):\n         # Test assignment -- should not fail.\n         y[0] = 1.0\n \n+        with self.assertRaises(ValueError):\n+            ops.convert_to_numpy(KerasTensor((2,)))\n+\n     def test_scan_invalid_arguments(self):\n         def cumsum(carry, xs):\n             carry = carry + xs\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5bec656bf00bce3272516fc60136be4caa8aa7bd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 210 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 7 | Methods Changed: 6 | Complexity Δ (Sum/Max): 9/5 | Churn Δ: 212 | Churn Cumulative: 308 | Contributors (this commit): 4 | Commits (past 90d): 6 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2,7 +2,14 @@ from keras.src.api_export import keras_export\n from keras.src.layers.preprocessing.image_preprocessing.base_image_preprocessing_layer import (  # noqa: E501\n     BaseImagePreprocessingLayer,\n )\n+from keras.src.layers.preprocessing.image_preprocessing.bounding_boxes.converters import (  # noqa: E501\n+    clip_to_image_size,\n+)\n+from keras.src.layers.preprocessing.image_preprocessing.bounding_boxes.converters import (  # noqa: E501\n+    convert_format,\n+)\n from keras.src.random.seed_generator import SeedGenerator\n+from keras.src.utils import backend_utils\n \n \n @keras_export(\"keras.layers.RandomTranslation\")\n@@ -166,13 +173,99 @@ class RandomTranslation(BaseImagePreprocessingLayer):\n     def transform_labels(self, labels, transformation, training=True):\n         return labels\n \n+    def get_transformed_x_y(self, x, y, transform):\n+        a0, a1, a2, b0, b1, b2, c0, c1 = self.backend.numpy.split(\n+            transform, 8, axis=-1\n+        )\n+\n+        k = c0 * x + c1 * y + 1\n+        x_transformed = (a0 * x + a1 * y + a2) / k\n+        y_transformed = (b0 * x + b1 * y + b2) / k\n+        return x_transformed, y_transformed\n+\n+    def get_shifted_bbox(self, bounding_boxes, w_shift_factor, h_shift_factor):\n+        bboxes = bounding_boxes[\"boxes\"]\n+        x1, x2, x3, x4 = self.backend.numpy.split(bboxes, 4, axis=-1)\n+\n+        w_shift_factor = self.backend.convert_to_tensor(\n+            w_shift_factor, dtype=x1.dtype\n+        )\n+        h_shift_factor = self.backend.convert_to_tensor(\n+            h_shift_factor, dtype=x1.dtype\n+        )\n+\n+        if len(bboxes.shape) == 3:\n+            w_shift_factor = self.backend.numpy.expand_dims(w_shift_factor, -1)\n+            h_shift_factor = self.backend.numpy.expand_dims(h_shift_factor, -1)\n+\n+        bounding_boxes[\"boxes\"] = self.backend.numpy.concatenate(\n+            [\n+                x1 - w_shift_factor,\n+                x2 - h_shift_factor,\n+                x3 - w_shift_factor,\n+                x4 - h_shift_factor,\n+            ],\n+            axis=-1,\n+        )\n+        return bounding_boxes\n+\n     def transform_bounding_boxes(\n         self,\n         bounding_boxes,\n         transformation,\n         training=True,\n     ):\n-        raise NotImplementedError\n+        if backend_utils.in_tf_graph():\n+            self.backend.set_backend(\"tensorflow\")\n+\n+        if self.data_format == \"channels_first\":\n+            height_axis = -2\n+            width_axis = -1\n+        else:\n+            height_axis = -3\n+            width_axis = -2\n+\n+        input_height, input_width = (\n+            transformation[\"input_shape\"][height_axis],\n+            transformation[\"input_shape\"][width_axis],\n+        )\n+\n+        bounding_boxes = convert_format(\n+            bounding_boxes,\n+            source=self.bounding_box_format,\n+            target=\"xyxy\",\n+            height=input_height,\n+            width=input_width,\n+        )\n+\n+        translations = transformation[\"translations\"]\n+        transform = self._get_translation_matrix(translations)\n+\n+        w_shift_factor, h_shift_factor = self.get_transformed_x_y(\n+            0, 0, transform\n+        )\n+        bounding_boxes = self.get_shifted_bbox(\n+            bounding_boxes, w_shift_factor, h_shift_factor\n+        )\n+\n+        bounding_boxes = clip_to_image_size(\n+            bounding_boxes=bounding_boxes,\n+            height=input_height,\n+            width=input_width,\n+            format=\"xyxy\",\n+        )\n+\n+        bounding_boxes = convert_format(\n+            bounding_boxes,\n+            source=\"xyxy\",\n+            target=self.bounding_box_format,\n+            height=input_height,\n+            width=input_width,\n+        )\n+\n+        self.backend.reset()\n+\n+        return bounding_boxes\n \n     def transform_segmentation_masks(\n         self, segmentation_masks, transformation, training=True\n@@ -227,7 +320,7 @@ class RandomTranslation(BaseImagePreprocessingLayer):\n             ),\n             dtype=\"float32\",\n         )\n-        return {\"translations\": translations}\n+        return {\"translations\": translations, \"input_shape\": images_shape}\n \n     def _translate_inputs(self, inputs, transformation):\n         if transformation is None:\n\n@@ -5,6 +5,7 @@ from tensorflow import data as tf_data\n from keras.src import backend\n from keras.src import layers\n from keras.src import testing\n+from keras.src.utils import backend_utils\n \n \n class RandomTranslationTest(testing.TestCase):\n@@ -328,3 +329,117 @@ class RandomTranslationTest(testing.TestCase):\n         input_data = np.random.random((1, 4, 4, 3))\n         ds = tf_data.Dataset.from_tensor_slices(input_data).batch(1).map(layer)\n         next(iter(ds)).numpy()\n+\n+    @parameterized.named_parameters(\n+        (\n+            \"with_positive_shift\",\n+            [[1.0, 2.0]],\n+            [[3.0, 3.0, 5.0, 5.0], [7.0, 6.0, 8.0, 8.0]],\n+        ),\n+        (\n+            \"with_negative_shift\",\n+            [[-1.0, -2.0]],\n+            [[1.0, 0.0, 3.0, 1.0], [5.0, 2.0, 7.0, 4.0]],\n+        ),\n+    )\n+    def test_random_flip_bounding_boxes(self, translation, expected_boxes):\n+        data_format = backend.config.image_data_format()\n+        if data_format == \"channels_last\":\n+            image_shape = (10, 8, 3)\n+        else:\n+            image_shape = (3, 10, 8)\n+        input_image = np.random.random(image_shape)\n+        bounding_boxes = {\n+            \"boxes\": np.array(\n+                [\n+                    [2, 1, 4, 3],\n+                    [6, 4, 8, 6],\n+                ]\n+            ),\n+            \"labels\": np.array([[1, 2]]),\n+        }\n+        input_data = {\"images\": input_image, \"bounding_boxes\": bounding_boxes}\n+        random_translation_layer = layers.RandomTranslation(\n+            height_factor=0.5,\n+            width_factor=0.5,\n+            data_format=data_format,\n+            seed=42,\n+            bounding_box_format=\"xyxy\",\n+        )\n+\n+        transformation = {\n+            \"translations\": backend_utils.convert_tf_tensor(\n+                np.array(translation)\n+            ),\n+            \"input_shape\": image_shape,\n+        }\n+        output = random_translation_layer.transform_bounding_boxes(\n+            input_data[\"bounding_boxes\"],\n+            transformation=transformation,\n+            training=True,\n+        )\n+\n+        self.assertAllClose(output[\"boxes\"], expected_boxes)\n+\n+    @parameterized.named_parameters(\n+        (\n+            \"with_positive_shift\",\n+            [[1.0, 2.0]],\n+            [[3.0, 3.0, 5.0, 5.0], [7.0, 6.0, 8.0, 8.0]],\n+        ),\n+        (\n+            \"with_negative_shift\",\n+            [[-1.0, -2.0]],\n+            [[1.0, 0.0, 3.0, 1.0], [5.0, 2.0, 7.0, 4.0]],\n+        ),\n+    )\n+    def test_random_flip_tf_data_bounding_boxes(\n+        self, translation, expected_boxes\n+    ):\n+        data_format = backend.config.image_data_format()\n+        if backend.config.image_data_format() == \"channels_last\":\n+            image_shape = (1, 10, 8, 3)\n+        else:\n+            image_shape = (1, 3, 10, 8)\n+        input_image = np.random.random(image_shape)\n+        bounding_boxes = {\n+            \"boxes\": np.array(\n+                [\n+                    [\n+                        [2, 1, 4, 3],\n+                        [6, 4, 8, 6],\n+                    ]\n+                ]\n+            ),\n+            \"labels\": np.array([[1, 2]]),\n+        }\n+\n+        input_data = {\"images\": input_image, \"bounding_boxes\": bounding_boxes}\n+\n+        ds = tf_data.Dataset.from_tensor_slices(input_data)\n+        random_translation_layer = layers.RandomTranslation(\n+            height_factor=0.5,\n+            width_factor=0.5,\n+            data_format=data_format,\n+            seed=42,\n+            bounding_box_format=\"xyxy\",\n+        )\n+\n+        transformation = {\n+            \"translations\": backend_utils.convert_tf_tensor(\n+                np.array(translation)\n+            ),\n+            \"input_shape\": image_shape,\n+        }\n+\n+        ds = ds.map(\n+            lambda x: random_translation_layer.transform_bounding_boxes(\n+                x[\"bounding_boxes\"],\n+                transformation=transformation,\n+                training=True,\n+            )\n+        )\n+\n+        output = next(iter(ds))\n+        expected_boxes = np.array(expected_boxes)\n+        self.assertAllClose(output[\"boxes\"], expected_boxes)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#28d39c0cc766767f4db54edc8b8ce68d3a05d4b4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 32 | Lines Deleted: 3 | Files Changed: 4 | Hunks: 8 | Methods Changed: 6 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 35 | Churn Cumulative: 649 | Contributors (this commit): 12 | Commits (past 90d): 9 | Contributors (cumulative): 20 | DMM Complexity: 1.0\n\nDIFF:\n@@ -95,10 +95,10 @@ class KerasVariable:\n                 \"cannot contain character `/`. \"\n                 f\"Received: name={name}\"\n             )\n-        if aggregation not in (\"mean\", \"sum\", \"only_first_replica\"):\n+        if aggregation not in (\"none\", \"mean\", \"sum\", \"only_first_replica\"):\n             raise ValueError(\n                 \"Invalid valid for argument `aggregation`. Expected \"\n-                \"one of {'mean', 'sum', 'only_first_replica'}. \"\n+                \"one of {'none', 'mean', 'sum', 'only_first_replica'}. \"\n                 f\"Received: aggregation={aggregation}\"\n             )\n         self.name = name\n\n@@ -36,7 +36,11 @@ class Variable(\n \n     def _initialize(self, value):\n         self._value = tf.Variable(\n-            value, dtype=self._dtype, trainable=self.trainable, name=self.name\n+            value,\n+            dtype=self._dtype,\n+            trainable=self.trainable,\n+            name=self.name,\n+            aggregation=self._map_aggregation(self.aggregation),\n         )\n \n     def _initialize_with_initializer(self, initializer):\n@@ -45,6 +49,7 @@ class Variable(\n             dtype=self._dtype,\n             trainable=self.trainable,\n             name=self.name,\n+            aggregation=self._map_aggregation(self.aggregation),\n         )\n \n     def _deferred_initialize(self):\n@@ -113,6 +118,15 @@ class Variable(\n     def _write_object_proto(self, proto, options):\n         return self.value._write_object_proto(proto, options)\n \n+    def _map_aggregation(self, aggregation):\n+        mapping = {\n+            \"none\": tf.VariableAggregation.NONE,\n+            \"sum\": tf.VariableAggregation.SUM,\n+            \"mean\": tf.VariableAggregation.MEAN,\n+            \"only_first_replica\": tf.VariableAggregation.ONLY_FIRST_REPLICA,\n+        }\n+        return mapping[aggregation]\n+\n \n def convert_to_tensor(x, dtype=None, sparse=None):\n     if isinstance(x, tf.SparseTensor) and sparse is not None and not sparse:\n\n@@ -122,3 +122,16 @@ class DistributeTest(testing.TestCase):\n                 self.assertEqual(y.values[0].shape, [2, 4])\n                 self.assertEqual(sample_weight.values[0].shape, [2])\n         self.assertEqual(steps_seen, [0, 1, 2, 3, 4, 5, 6])\n+\n+    def test_variable_aggregation(self):\n+        strategy = tf.distribute.MirroredStrategy([\"CPU:0\", \"CPU:1\"])\n+\n+        with strategy.scope():\n+            x = np.random.random((4, 4))\n+            v1 = backend.Variable(x, dtype=\"float32\")\n+            self.assertEqual(v1.aggregation, \"mean\")\n+            self.assertEqual(v1.value.aggregation, tf.VariableAggregation.MEAN)\n+\n+            v2 = backend.Variable(x, dtype=\"float32\", aggregation=\"sum\")\n+            self.assertEqual(v2.aggregation, \"sum\")\n+            self.assertEqual(v2.value.aggregation, tf.VariableAggregation.SUM)\n\n@@ -67,12 +67,14 @@ class LossScaleOptimizer(optimizer.Optimizer):\n             shape=(),\n             dtype=\"int\",\n             initializer=initializers.Zeros(),\n+            aggregation=\"none\",\n             name=\"step_counter\",\n         )\n         self.dynamic_scale = self.add_variable(\n             shape=(),\n             dtype=\"float32\",\n             initializer=initializers.Constant(self.initial_scale),\n+            aggregation=\"none\",\n             name=\"dynamic_scale\",\n         )\n         self.inner_optimizer.build(var_list)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a503a162fc5b4120a96a1f7203a1de841f0601e2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 252 | Contributors (this commit): 3 | Commits (past 90d): 8 | Contributors (cumulative): 6 | DMM Complexity: 0.0\n\nDIFF:\n@@ -426,9 +426,7 @@ class RandomTranslationTest(testing.TestCase):\n         )\n \n         transformation = {\n-            \"translations\": backend_utils.convert_tf_tensor(\n-                np.array(translation)\n-            ),\n+            \"translations\": np.array(translation),\n             \"input_shape\": image_shape,\n         }\n \n\n@@ -251,8 +251,8 @@ class RandomZoomTest(testing.TestCase):\n         )\n \n         transformation = {\n-            \"height_zoom\": backend_utils.convert_tf_tensor(np.array(zoom[0])),\n-            \"width_zoom\": backend_utils.convert_tf_tensor(np.array(zoom[1])),\n+            \"height_zoom\": np.array(zoom[0]),\n+            \"width_zoom\": np.array(zoom[1]),\n             \"input_shape\": image_shape,\n         }\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0078f24ca94bb10063fe7478a70dbaef701f176a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 126 | Lines Deleted: 0 | Files Changed: 10 | Hunks: 13 | Methods Changed: 9 | Complexity Δ (Sum/Max): 14/4 | Churn Δ: 126 | Churn Cumulative: 4471 | Contributors (this commit): 21 | Commits (past 90d): 85 | Contributors (cumulative): 92 | DMM Complexity: 1.0\n\nDIFF:\n@@ -172,6 +172,7 @@ from keras.src.ops.numpy import histogram\n from keras.src.ops.numpy import hstack\n from keras.src.ops.numpy import identity\n from keras.src.ops.numpy import imag\n+from keras.src.ops.numpy import inner\n from keras.src.ops.numpy import isclose\n from keras.src.ops.numpy import isfinite\n from keras.src.ops.numpy import isinf\n\n@@ -75,6 +75,7 @@ from keras.src.ops.numpy import histogram\n from keras.src.ops.numpy import hstack\n from keras.src.ops.numpy import identity\n from keras.src.ops.numpy import imag\n+from keras.src.ops.numpy import inner\n from keras.src.ops.numpy import isclose\n from keras.src.ops.numpy import isfinite\n from keras.src.ops.numpy import isinf\n\n@@ -172,6 +172,7 @@ from keras.src.ops.numpy import histogram\n from keras.src.ops.numpy import hstack\n from keras.src.ops.numpy import identity\n from keras.src.ops.numpy import imag\n+from keras.src.ops.numpy import inner\n from keras.src.ops.numpy import isclose\n from keras.src.ops.numpy import isfinite\n from keras.src.ops.numpy import isinf\n\n@@ -75,6 +75,7 @@ from keras.src.ops.numpy import histogram\n from keras.src.ops.numpy import hstack\n from keras.src.ops.numpy import identity\n from keras.src.ops.numpy import imag\n+from keras.src.ops.numpy import inner\n from keras.src.ops.numpy import isclose\n from keras.src.ops.numpy import isfinite\n from keras.src.ops.numpy import isinf\n\n@@ -1102,6 +1102,12 @@ def vdot(x1, x2):\n     return jnp.vdot(x1, x2)\n \n \n+def inner(x1, x2):\n+    x1 = convert_to_tensor(x1)\n+    x2 = convert_to_tensor(x2)\n+    return jnp.inner(x1, x2)\n+\n+\n def vstack(xs):\n     return jnp.vstack(xs)\n \n\n@@ -1006,6 +1006,15 @@ def vdot(x1, x2):\n     return np.vdot(x1, x2)\n \n \n+def inner(x1, x2):\n+    x1 = convert_to_tensor(x1)\n+    x2 = convert_to_tensor(x2)\n+    dtype = dtypes.result_type(x1.dtype, x2.dtype)\n+    x1 = x1.astype(dtype)\n+    x2 = x2.astype(dtype)\n+    return np.inner(x1, x2)\n+\n+\n def vstack(xs):\n     dtype_set = set([getattr(x, \"dtype\", type(x)) for x in xs])\n     if len(dtype_set) > 1:\n\n@@ -2285,6 +2285,24 @@ def vdot(x1, x2):\n     return tf.cast(dot(x1, x2), result_dtype)\n \n \n+def inner(x1, x2):\n+    x1 = convert_to_tensor(x1)\n+    x2 = convert_to_tensor(x2)\n+    result_dtype = dtypes.result_type(x1.dtype, x2.dtype)\n+    compute_dtype = dtypes.result_type(result_dtype, float)\n+    x1 = tf.cast(x1, compute_dtype)\n+    x2 = tf.cast(x2, compute_dtype)\n+    x = tf.cond(\n+        tf.math.logical_or(\n+            tf.math.equal(tf.rank(x1), 0),\n+            tf.math.equal(tf.rank(x2), 0),\n+        ),\n+        lambda: x1 * x2,\n+        lambda: tf.tensordot(x1, x2, axes=[[-1], [-1]]),\n+    )\n+    return tf.cast(x, result_dtype)\n+\n+\n def vstack(xs):\n     dtype_set = set([getattr(x, \"dtype\", type(x)) for x in xs])\n     if len(dtype_set) > 1:\n\n@@ -1487,6 +1487,20 @@ def vdot(x1, x2):\n     return cast(torch.vdot(x1, x2), result_dtype)\n \n \n+def inner(x1, x2):\n+    x1 = convert_to_tensor(x1)\n+    x2 = convert_to_tensor(x2)\n+    result_dtype = dtypes.result_type(x1.dtype, x2.dtype)\n+    compute_dtype = dtypes.result_type(result_dtype, float)\n+\n+    if get_device() == \"cpu\" and compute_dtype == \"float16\":\n+        compute_dtype = \"float32\"\n+\n+    x1 = cast(x1, compute_dtype)\n+    x2 = cast(x2, compute_dtype)\n+    return cast(torch.inner(x1, x2), result_dtype)\n+\n+\n def vstack(xs):\n     xs = [convert_to_tensor(x) for x in xs]\n     return torch.vstack(xs)\n\n@@ -5678,6 +5678,45 @@ def vdot(x1, x2):\n     return backend.numpy.vdot(x1, x2)\n \n \n+class Inner(Operation):\n+    def call(self, x1, x2):\n+        return backend.numpy.inner(x1, x2)\n+\n+    def compute_output_spec(self, x1, x2):\n+        dtype = dtypes.result_type(\n+            getattr(x1, \"dtype\", type(x1)),\n+            getattr(x2, \"dtype\", type(x2)),\n+        )\n+        return KerasTensor([], dtype=dtype)\n+\n+\n+@keras_export([\"keras.ops.inner\", \"keras.ops.numpy.inner\"])\n+def inner(x1, x2):\n+    \"\"\"Return the inner product of two tensors.\n+\n+    Ordinary inner product of vectors for 1-D tensors\n+    (without complex conjugation), in higher dimensions\n+    a sum product over the last axes.\n+\n+    Multidimensional arrays are treated as vectors by flattening\n+    all but their last axes. The resulting dot product is performed\n+    over their last axes.\n+\n+    Args:\n+        x1: First input tensor.\n+        x2: Second input tensor. The last dimension of `x1` and `x2`\n+            must match.\n+\n+    Returns:\n+        Output tensor. The shape of the output is determined by\n+        broadcasting the shapes of `x1` and `x2` after removing\n+        their last axes.\n+    \"\"\"\n+    if any_symbolic_tensors((x1, x2)):\n+        return Inner().symbolic_call(x1, x2)\n+    return backend.numpy.inner(x1, x2)\n+\n+\n @keras_export([\"keras.ops.vectorize\", \"keras.ops.numpy.vectorize\"])\n def vectorize(pyfunc, *, excluded=None, signature=None):\n     \"\"\"Turn a function into a vectorized function.\n\n@@ -299,6 +299,11 @@ class NumpyTwoInputOpsDynamicShapeTest(testing.TestCase):\n         y = KerasTensor((None, 3, 3))\n         self.assertEqual(knp.vdot(x, y).shape, ())\n \n+    def test_inner(self):\n+        x = KerasTensor((None,))\n+        y = KerasTensor((3,))\n+        self.assertEqual(knp.inner(x, y).shape, ())\n+\n     def test_where(self):\n         condition = KerasTensor((2, None, 1))\n         x = KerasTensor((None, 1))\n@@ -875,6 +880,11 @@ class NumpyTwoInputOpsStaticShapeTest(testing.TestCase):\n         y = KerasTensor((2, 3))\n         self.assertEqual(knp.vdot(x, y).shape, ())\n \n+    def test_inner(self):\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((2, 3))\n+        self.assertEqual(knp.inner(x, y).shape, ())\n+\n     def test_where(self):\n         condition = KerasTensor((2, 3))\n         x = KerasTensor((2, 3))\n@@ -2975,6 +2985,12 @@ class NumpyTwoInputOpsCorrectnessTest(testing.TestCase):\n         self.assertAllClose(knp.vdot(x, y), np.vdot(x, y))\n         self.assertAllClose(knp.Vdot()(x, y), np.vdot(x, y))\n \n+    def test_inner(self):\n+        x = np.array([1.0, 2.0, 3.0])\n+        y = np.array([4.0, 5.0, 6.0])\n+        self.assertAllClose(knp.inner(x, y), np.inner(x, y))\n+        self.assertAllClose(knp.Inner()(x, y), np.inner(x, y))\n+\n     def test_where(self):\n         x = np.array([1, 2, 3])\n         y = np.array([4, 5, 6])\n@@ -8249,6 +8265,26 @@ class NumpyDtypeTest(testing.TestCase):\n         )\n         self.assertEqual(knp.Vdot().symbolic_call(x1, x2).dtype, expected_dtype)\n \n+    @parameterized.named_parameters(\n+        named_product(dtypes=itertools.combinations(ALL_DTYPES, 2))\n+    )\n+    def test_inner(self, dtypes):\n+        import jax.numpy as jnp\n+\n+        dtype1, dtype2 = dtypes\n+        x1 = knp.ones((1,), dtype=dtype1)\n+        x2 = knp.ones((1,), dtype=dtype2)\n+        x1_jax = jnp.ones((1,), dtype=dtype1)\n+        x2_jax = jnp.ones((1,), dtype=dtype2)\n+        expected_dtype = standardize_dtype(jnp.inner(x1_jax, x2_jax).dtype)\n+\n+        self.assertEqual(\n+            standardize_dtype(knp.inner(x1, x2).dtype), expected_dtype\n+        )\n+        self.assertEqual(\n+            knp.Inner().symbolic_call(x1, x2).dtype, expected_dtype\n+        )\n+\n     @parameterized.named_parameters(\n         named_product(dtypes=itertools.combinations(ALL_DTYPES, 2))\n     )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
