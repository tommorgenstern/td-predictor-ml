{"custom_id": "keras#366d4ac23bae7dc327e94366d33c2dee507c59b7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 17 | Files Changed: 3 | Hunks: 4 | Methods Changed: 4 | Complexity Δ (Sum/Max): -3/0 | Churn Δ: 19 | Churn Cumulative: 16503 | Contributors (this commit): 115 | Commits (past 90d): 49 | Contributors (cumulative): 122 | DMM Complexity: 0.42857142857142855\n\nDIFF:\n@@ -105,15 +105,6 @@ class DatasetCreatorModelFitParameterServerStrategyOnlyTest(\n     files = tf.compat.v1.gfile.ListDirectory(log_dir)\n     self.assertGreaterEqual(len(files), 1)\n \n-  def testModelFitVerbose1(self, strategy, use_dataset_creator):\n-    with self.assertRaisesRegex(ValueError,\n-                                \"`verbose=1` is not allowed with \"\n-                                \"`ParameterServerStrategy` for performance \"\n-                                \"reasons. Received: `verbose`=1\"):\n-      self._model_fit(\n-          strategy, use_dataset_creator=use_dataset_creator,\n-          verbose=1)\n-\n   def testModelEvaluateErrorOnBatchLevelCallbacks(self, strategy,\n                                                   use_dataset_creator):\n \n\n@@ -119,8 +119,7 @@ class DatasetCreatorModelFitTestBase(tf.test.TestCase, parameterized.TestCase):\n                  with_normalization_layer=False,\n                  callbacks=None,\n                  use_lookup_layer=False,\n-                 use_dataset_creator=True,\n-                 verbose=\"auto\"):\n+                 use_dataset_creator=True):\n     if callbacks is None:\n       callbacks = []\n \n@@ -154,8 +153,7 @@ class DatasetCreatorModelFitTestBase(tf.test.TestCase, parameterized.TestCase):\n         steps_per_epoch=steps_per_epoch,\n         callbacks=callbacks,\n         validation_data=validation_data,\n-        validation_steps=steps_per_epoch,\n-        verbose=verbose)\n+        validation_steps=steps_per_epoch)\n     return model\n \n   def _model_evaluate(self,\n\n@@ -1109,10 +1109,6 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n         verbose = 2  # Default to epoch-level logging for PSStrategy.\n       else:\n         verbose = 1  # Default to batch-level logging otherwise.\n-    elif verbose == 1 and self.distribute_strategy._should_use_with_coordinator:  # pylint: disable=protected-access\n-      raise ValueError(\n-          '`verbose=1` is not allowed with `ParameterServerStrategy` for '\n-          f'performance reasons. Received: `verbose`={verbose}')\n \n     if validation_split:\n       # Create the validation data using the training data. Only supported for\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#df97de0a0d2646b718540bb568b7d70b423bf536", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 2 | Files Changed: 3 | Hunks: 4 | Methods Changed: 4 | Complexity Δ (Sum/Max): 3/2 | Churn Δ: 19 | Churn Cumulative: 16522 | Contributors (this commit): 115 | Commits (past 90d): 52 | Contributors (cumulative): 122 | DMM Complexity: 0.5714285714285714\n\nDIFF:\n@@ -105,6 +105,15 @@ class DatasetCreatorModelFitParameterServerStrategyOnlyTest(\n     files = tf.compat.v1.gfile.ListDirectory(log_dir)\n     self.assertGreaterEqual(len(files), 1)\n \n+  def testModelFitVerbose1(self, strategy, use_dataset_creator):\n+    with self.assertRaisesRegex(ValueError,\n+                                \"`verbose=1` is not allowed with \"\n+                                \"`ParameterServerStrategy` for performance \"\n+                                \"reasons. Received: `verbose`=1\"):\n+      self._model_fit(\n+          strategy, use_dataset_creator=use_dataset_creator,\n+          verbose=1)\n+\n   def testModelEvaluateErrorOnBatchLevelCallbacks(self, strategy,\n                                                   use_dataset_creator):\n \n\n@@ -119,7 +119,8 @@ class DatasetCreatorModelFitTestBase(tf.test.TestCase, parameterized.TestCase):\n                  with_normalization_layer=False,\n                  callbacks=None,\n                  use_lookup_layer=False,\n-                 use_dataset_creator=True):\n+                 use_dataset_creator=True,\n+                 verbose=\"auto\"):\n     if callbacks is None:\n       callbacks = []\n \n@@ -153,7 +154,8 @@ class DatasetCreatorModelFitTestBase(tf.test.TestCase, parameterized.TestCase):\n         steps_per_epoch=steps_per_epoch,\n         callbacks=callbacks,\n         validation_data=validation_data,\n-        validation_steps=steps_per_epoch)\n+        validation_steps=steps_per_epoch,\n+        verbose=verbose)\n     return model\n \n   def _model_evaluate(self,\n\n@@ -1109,6 +1109,10 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n         verbose = 2  # Default to epoch-level logging for PSStrategy.\n       else:\n         verbose = 1  # Default to batch-level logging otherwise.\n+    elif verbose == 1 and self.distribute_strategy._should_use_with_coordinator:  # pylint: disable=protected-access\n+      raise ValueError(\n+          '`verbose=1` is not allowed with `ParameterServerStrategy` for '\n+          f'performance reasons. Received: `verbose`={verbose}')\n \n     if validation_split:\n       # Create the validation data using the training data. Only supported for\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9e4bd34ae93c48fb6f6f704e3444ebb6b7ec2547", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 10 | Files Changed: 2 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): -3/0 | Churn Δ: 14 | Churn Cumulative: 906 | Contributors (this commit): 5 | Commits (past 90d): 5 | Contributors (cumulative): 8 | DMM Complexity: 0.0\n\nDIFF:\n@@ -48,8 +48,8 @@ MODEL_LIST_NO_NASNET = [\n     (inception_resnet_v2.InceptionResNetV2, 1536),\n     (mobilenet.MobileNet, 1024),\n     (mobilenet_v2.MobileNetV2, 1280),\n-    (mobilenet_v3.MobileNetV3Small, 1024),\n-    (mobilenet_v3.MobileNetV3Large, 1280),\n+    (mobilenet_v3.MobileNetV3Small, 576),\n+    (mobilenet_v3.MobileNetV3Large, 960),\n     (densenet.DenseNet121, 1024),\n     (densenet.DenseNet169, 1664),\n     (densenet.DenseNet201, 1920),\n@@ -93,7 +93,7 @@ class ApplicationsTest(tf.test.TestCase, parameterized.TestCase):\n \n   @parameterized.parameters(*MODEL_LIST)\n   def test_application_notop(self, app, last_dim):\n-    if 'NASNet' or 'MobileNetV3' in app.__name__:\n+    if 'NASNet' in app.__name__:\n       only_check_last_dim = True\n     else:\n       only_check_last_dim = False\n@@ -119,9 +119,6 @@ class ApplicationsTest(tf.test.TestCase, parameterized.TestCase):\n       input_shape = (None, None, 1)\n     output_shape = _get_output_shape(\n         lambda: app(weights=None, include_top=False, input_shape=input_shape))\n-    if 'MobileNetV3' in app.__name__:\n-      self.assertShapeEqual(output_shape, (None, 1, 1, last_dim))\n-    else:\n     self.assertShapeEqual(output_shape, (None, None, None, last_dim))\n     backend.clear_session()\n \n@@ -131,9 +128,6 @@ class ApplicationsTest(tf.test.TestCase, parameterized.TestCase):\n       input_shape = (None, None, 4)\n     output_shape = _get_output_shape(\n         lambda: app(weights=None, include_top=False, input_shape=input_shape))\n-    if 'MobileNetV3' in app.__name__:\n-      self.assertShapeEqual(output_shape, (None, 1, 1, last_dim))\n-    else:\n     self.assertShapeEqual(output_shape, (None, None, None, last_dim))\n     backend.clear_session()\n \n\n@@ -310,6 +310,7 @@ def MobileNetV3(stack_fn,\n       axis=channel_axis, epsilon=1e-3,\n       momentum=0.999, name='Conv_1/BatchNorm')(x)\n   x = activation(x)\n+  if include_top:\n     x = layers.GlobalAveragePooling2D(keepdims=True)(x)\n     x = layers.Conv2D(\n         last_point_ch,\n@@ -319,7 +320,6 @@ def MobileNetV3(stack_fn,\n         name='Conv_2')(x)\n     x = activation(x)\n \n-  if include_top:\n     if dropout_rate > 0:\n       x = layers.Dropout(dropout_rate)(x)\n     x = layers.Conv2D(classes, kernel_size=1, padding='same', name='Logits')(x)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#90887569b979a687e6af4249ce12be1a70f75179", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 27 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 5/5 | Churn Δ: 31 | Churn Cumulative: 10524 | Contributors (this commit): 97 | Commits (past 90d): 23 | Contributors (cumulative): 104 | DMM Complexity: 1.0\n\nDIFF:\n@@ -251,14 +251,14 @@ class CallbackList:\n       elif isinstance(cb, History):\n         self._history = cb\n \n-    if self._progbar is None and add_progbar:\n-      self._progbar = ProgbarLogger(count_mode='steps')\n-      self.callbacks.insert(0, self._progbar)\n-\n     if self._history is None and add_history:\n       self._history = History()\n       self.callbacks.append(self._history)\n \n+    if self._progbar is None and add_progbar:\n+      self._progbar = ProgbarLogger(count_mode='steps')\n+      self.callbacks.append(self._progbar)\n+\n   def _process_logs(self, logs, is_batch_hook=False):\n     \"\"\"Turns tensors into numpy arrays or Python scalars if necessary.\"\"\"\n     if logs is None:\n\n@@ -26,6 +26,7 @@ import sys\n import threading\n import time\n import unittest\n+from unittest import mock\n \n from absl.testing import parameterized\n import numpy as np\n@@ -2041,6 +2042,28 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n     model.fit(x, y, batch_size=2, callbacks=[my_cb])\n     self.assertEqual(my_cb.batch_counter, 3)\n \n+  @keras_parameterized.run_all_keras_modes(always_skip_v1=True)\n+  def test_built_in_callback_order(self):\n+\n+    class CustomCallback(keras.callbacks.Callback):\n+      pass\n+\n+    class TestingCallbackList(keras.callbacks.CallbackList):\n+\n+      def __init__(self, *args, **kwargs):\n+        super(TestingCallbackList, self).__init__(*args, **kwargs)\n+        if ((not isinstance(self.callbacks[0], CustomCallback)) or\n+            (not isinstance(self.callbacks[1], keras.callbacks.History)) or\n+            (not isinstance(self.callbacks[2], keras.callbacks.ProgbarLogger))):\n+          raise AssertionError(f'Callback order unexpected: {self.callbacks}')\n+\n+    with mock.patch.object(\n+        keras.callbacks, 'CallbackList', TestingCallbackList):\n+      model = keras.Sequential([keras.layers.Dense(1)])\n+      model.compile('sgd', 'mse')\n+      custom_callback = CustomCallback()\n+      model.fit(np.ones((10, 10)), np.ones((10, 1)), epochs=5,\n+                callbacks=[custom_callback])\n \n # A summary that was emitted during a test. Fields:\n #   logdir: str. The logdir of the FileWriter to which the summary was\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#070feb661be99d5db5509b833eb693a811f764fe", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 63 | Lines Deleted: 3 | Files Changed: 3 | Hunks: 10 | Methods Changed: 6 | Complexity Δ (Sum/Max): 12/8 | Churn Δ: 66 | Churn Cumulative: 2089 | Contributors (this commit): 9 | Commits (past 90d): 9 | Contributors (cumulative): 15 | DMM Complexity: 0.32558139534883723\n\nDIFF:\n@@ -209,3 +209,10 @@ def deserialize(config, custom_objects=None):\n       module_objects=LOCAL.ALL_OBJECTS,\n       custom_objects=custom_objects,\n       printable_module_name='layer')\n+\n+\n+def get_builtin_layer(class_name):\n+  \"\"\"Returns class if `class_name` is registered, else returns None.\"\"\"\n+  if not hasattr(LOCAL, 'ALL_OBJECTS'):\n+    populate_deserializable_objects()\n+  return LOCAL.ALL_OBJECTS.get(class_name)\n\n@@ -38,6 +38,7 @@ from keras.engine import sequential\n from keras.feature_column import dense_features\n from keras.feature_column import sequence_feature_column as ksfc\n from keras.layers import core\n+from keras.premade.linear import LinearModel\n from keras.saving import model_config\n from keras.saving import save\n from keras.utils import generic_utils\n@@ -325,6 +326,42 @@ class TestSaveModel(tf.test.TestCase, parameterized.TestCase):\n       # Make sure the model can be correctly load back.\n       _ = save.load_model(filepath, compile=True)\n \n+  def test_saving_model_with_name_conflict(self):\n+\n+    class Sequential(keras.Model):\n+\n+      def __init__(self):\n+        super(Sequential, self).__init__()\n+        self.layer = keras.layers.Dense(1)\n+\n+      def call(self, x):\n+        return self.layer(x)\n+\n+    model = Sequential()\n+    model(tf.ones((10, 10)))\n+    temp_dir = self.get_temp_dir()\n+    filepath = os.path.join(temp_dir, 'Sequential')\n+\n+    with self.assertLogs() as logs:\n+      model.save(filepath, save_format='tf')\n+\n+    expected_substring = 'has the same name \\'Sequential\\' as a built-in Keras'\n+    matched = [log for log in logs.output if expected_substring in log]\n+    self.assertNotEmpty(matched)\n+\n+  def test_saving_built_in_model(self):\n+    model = LinearModel()\n+    model(tf.constant([[5.]]))\n+    temp_dir = self.get_temp_dir()\n+    filepath = os.path.join(temp_dir, 'LinearModel')\n+    with self.assertLogs() as logs:\n+      model.save(filepath, save_format='tf')\n+\n+    expected_substring = 'has the same name \\'LinearModel\\' as a built-in Keras'\n+    matched = [log for log in logs.output if expected_substring in log]\n+    # Check that a warning is *not* logged for a premade model.\n+    self.assertEmpty(matched)\n+\n \n @keras_parameterized.run_with_all_saved_model_formats\n class TestWholeModelSaving(keras_parameterized.TestCase):\n\n@@ -14,11 +14,11 @@\n # ==============================================================================\n \"\"\"Keras SavedModel serialization.\"\"\"\n \n-import tensorflow.compat.v2 as tf\n-\n import os\n+from absl import logging\n \n from keras import backend\n+from keras.layers import serialization\n from keras.protobuf import saved_metadata_pb2\n from keras.protobuf import versions_pb2\n from keras.saving import saving_utils\n@@ -27,8 +27,11 @@ from keras.saving.saved_model import save_impl\n from keras.saving.saved_model import utils\n from keras.utils.generic_utils import LazyLoader\n from keras.utils.io_utils import ask_to_proceed_with_overwrite\n+import tensorflow.compat.v2 as tf\n+\n from tensorflow.python.saved_model import save as save_lib\n \n+\n # To avoid circular dependencies between keras/engine and keras/saving,\n # code in keras/saving must delay imports.\n \n@@ -104,7 +107,6 @@ def save(model, filepath, overwrite, include_optimizer, signatures=None,\n def generate_keras_metadata(saved_nodes, node_paths):\n   \"\"\"Constructs a KerasMetadata proto with the metadata of each keras object.\"\"\"\n   metadata = saved_metadata_pb2.SavedMetadata()\n-\n   for node_id, node in enumerate(saved_nodes):\n     if isinstance(node, base_layer.Layer):\n       path = node_paths[node]\n@@ -122,4 +124,18 @@ def generate_keras_metadata(saved_nodes, node_paths):\n           identifier=node._object_identifier,  # pylint: disable=protected-access\n           metadata=node._tracking_metadata)  # pylint: disable=protected-access\n \n+      # Log warning if the node's class name conflicts with a Keras built-in\n+      # object.\n+      class_name = node.__class__.__name__\n+      builtin_layer = serialization.get_builtin_layer(class_name)\n+      if builtin_layer:\n+        if not isinstance(node, builtin_layer):\n+          logging.warning(\n+              \"%s has the same name '%s' as a built-in Keras \"\n+              \"object. Consider renaming %s to avoid naming \"\n+              \"conflicts when loading with \"\n+              \"`tf.keras.models.load_model`. If renaming is not possible, pass \"\n+              \"the object in the `custom_objects` parameter of the load \"\n+              \"function.\", node, class_name, node.__class__)\n+\n   return metadata\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cd36f9d9721f66355a95f0c77ea6893bdfaa4963", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 42 | Lines Deleted: 1 | Files Changed: 3 | Hunks: 5 | Methods Changed: 3 | Complexity Δ (Sum/Max): 4/2 | Churn Δ: 43 | Churn Cumulative: 2868 | Contributors (this commit): 17 | Commits (past 90d): 17 | Contributors (cumulative): 26 | DMM Complexity: 0.5384615384615384\n\nDIFF:\n@@ -251,6 +251,7 @@ from keras.layers.rnn_cell_wrapper_v2 import ResidualWrapper\n from keras.layers import serialization\n from keras.layers.serialization import deserialize\n from keras.layers.serialization import serialize\n+from keras.layers.serialization import get_builtin_layer\n \n \n class VersionAwareLayers:\n\n@@ -523,6 +523,21 @@ class KerasObjectLoader:\n       obj = layers_module.deserialize(\n           generic_utils.serialize_keras_class_and_config(\n               class_name, config, shared_object_id=shared_object_id))\n+    except (TypeError, KeyError) as e:\n+      # A name conflict has occured. The `class_name` is in the Keras native\n+      # framework; however, the value in the framework is different from the\n+      # user's class definition which confuses the KerasObjectLoader.\n+      builtin_layer = layers_module.get_builtin_layer(class_name)\n+      if builtin_layer:\n+        raise RuntimeError(\n+            f'Unable to restore object of class \\'{class_name}\\' likely due to '\n+            f'name conflict with built-in Keras class \\'{builtin_layer}\\'. To '\n+            'override the built-in Keras definition of the object, decorate '\n+            'your class with `@keras.utils.register_keras_serializable` and '\n+            'include that file in your program, or pass your class in a '\n+            '`keras.utils.CustomObjectScope` that wraps this load call.') from e\n+      else:\n+        raise\n     except ValueError:\n       if must_restore_from_config:\n         raise RuntimeError(\n\n@@ -193,6 +193,12 @@ class FunctionalSubclassModelWrongConfig(FunctionalSubclassModel):\n     return {}\n \n \n+# The WideDeepModel, whose name conflicts with a Keras built-in model, is\n+# registered in these tests.\n+class WideDeepModel(SubclassedModelWithConfig):\n+  pass\n+\n+\n class ReviveTestBase(keras_parameterized.TestCase):\n \n   def setUp(self):\n@@ -409,6 +415,24 @@ class TestModelRevive(ReviveTestBase):\n         model._get_save_spec(dynamic_batch=False),\n         revived._get_save_spec(dynamic_batch=False))\n \n+  def test_load_model_with_name_conflict_raises_error(self):\n+\n+    class LinearModel(SubclassedModelWithConfig):\n+      pass\n+\n+    model = LinearModel(2, 3)\n+    model(np.random.random((5, 10)).astype(np.float32))\n+    model.save(self.path, save_format='tf')\n+    with self.assertRaisesRegex(\n+        RuntimeError, 'Unable to restore object of class \\'LinearModel\\''):\n+      keras_load.load(self.path, compile=True)\n+\n+  def test_load_model_with_name_conflict_registered_works(self):\n+    model = WideDeepModel(2, 3)\n+    model(np.random.random((5, 10)).astype(np.float32))\n+    model.save(self.path, save_format='tf')\n+    keras_load.load(self.path, compile=True)\n+\n \n if __name__ == '__main__':\n   tf.compat.v1.enable_eager_execution()\n@@ -418,6 +442,7 @@ if __name__ == '__main__':\n       'CustomNetworkWithConfigName': CustomNetworkWithConfigName,\n       'SubclassedModelWithConfig': SubclassedModelWithConfig,\n       'FunctionalSubclassModel': FunctionalSubclassModel,\n-      'FunctionalSubclassModelWrongConfig': FunctionalSubclassModelWrongConfig\n+      'FunctionalSubclassModelWrongConfig': FunctionalSubclassModelWrongConfig,\n+      'WideDeepModel': WideDeepModel\n   }):\n     tf.test.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a0bf205a3dd1530db7514d38835eb3070183f687", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 32 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 8 | Methods Changed: 8 | Complexity Δ (Sum/Max): 5/3 | Churn Δ: 36 | Churn Cumulative: 347 | Contributors (this commit): 5 | Commits (past 90d): 5 | Contributors (cumulative): 7 | DMM Complexity: 0.0\n\nDIFF:\n@@ -131,8 +131,10 @@ class KPLTest(tf.test.TestCase, parameterized.TestCase):\n \n   @tf.__internal__.distribute.combinations.generate(\n       tf.__internal__.test.combinations.combine(\n-          mode=[\"eager\"], use_adapt=[True, False]))\n-  def testTrainAndServe(self, use_adapt):\n+          mode=[\"eager\"],\n+          use_adapt=[True, False],\n+          load_under_strategy=[True, False]))\n+  def testTrainAndServe(self, use_adapt, load_under_strategy):\n \n     with self.coordinator.strategy.scope():\n \n@@ -231,7 +233,22 @@ class KPLTest(tf.test.TestCase, parameterized.TestCase):\n     saved_model_dir = tempfile.mkdtemp(dir=self.get_temp_dir())\n     model.save(saved_model_dir, signatures={\"serving_default\": serving_fn})\n \n-    # Test the saved_model.\n+    if load_under_strategy:\n+      with self.coordinator.strategy.scope():\n+\n+        loaded_serving_fn = tf.keras.models.load_model(\n+            saved_model_dir).signatures[\"serving_default\"]\n+\n+      outputs = []\n+      for _ in range(7):\n+        outputs.append(\n+            self.coordinator.schedule(\n+                loaded_serving_fn,\n+                args=(tf.constant([\"avenger\", \"ironman\", \"avenger\"]),)))\n+      self.coordinator.join()\n+      for prediction0 in outputs:\n+        self.assertIn(prediction0._get_values()[\"output_0\"], (\"yes\", \"no\"))\n+    else:\n       loaded_serving_fn = tf.keras.models.load_model(\n           saved_model_dir).signatures[\"serving_default\"]\n \n\n@@ -23,17 +23,23 @@ class LoadContext(threading.local):\n \n   def __init__(self):\n     super(LoadContext, self).__init__()\n+    self._entered_load_context = []\n     self._load_options = None\n \n   def set_load_options(self, load_options):\n     self._load_options = load_options\n+    self._entered_load_context.append(True)\n \n   def clear_load_options(self):\n     self._load_options = None\n+    self._entered_load_context.pop()\n \n   def load_options(self):\n     return self._load_options\n \n+  def in_load_context(self):\n+    return self._entered_load_context\n+\n \n _load_context = LoadContext()\n \n@@ -48,5 +54,10 @@ def load_context(load_options):\n \n \n def get_load_options():\n-  \"\"\"Returns whether under a load context.\"\"\"\n+  \"\"\"Returns the load options under a load context.\"\"\"\n   return _load_context.load_options()\n+\n+\n+def in_load_context():\n+  \"\"\"Returns whether under a load context.\"\"\"\n+  return _load_context.in_load_context\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#14ebecdc89f542794d309b45bcd40f7f5a67ce4b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 43 | Lines Deleted: 63 | Files Changed: 6 | Hunks: 27 | Methods Changed: 14 | Complexity Δ (Sum/Max): -11/1 | Churn Δ: 106 | Churn Cumulative: 33895 | Contributors (this commit): 114 | Commits (past 90d): 47 | Contributors (cumulative): 165 | DMM Complexity: 0.0\n\nDIFF:\n@@ -136,13 +136,13 @@ class Conv(Layer):\n                        f'Was expecting a positive value. Received {filters}.')\n     self.filters = filters\n     self.groups = groups or 1\n-    self.kernel_size = conv_utils.normalize_positive_tuple(\n-        kernel_size, rank, 'kernel_size')\n-    self.strides = conv_utils.normalize_tuple(strides, rank, 'strides')\n+    self.kernel_size = conv_utils.normalize_tuple(\n+        kernel_size, rank, 'kernel_size', lambda x: x <= 0)\n+    self.strides = conv_utils.normalize_tuple(strides, rank, 'strides', lambda x: x < 0)\n     self.padding = conv_utils.normalize_padding(padding)\n     self.data_format = conv_utils.normalize_data_format(data_format)\n     self.dilation_rate = conv_utils.normalize_tuple(\n-        dilation_rate, rank, 'dilation_rate')\n+        dilation_rate, rank, 'dilation_rate', lambda x: x <= 0)\n \n     self.activation = activations.get(activation)\n     self.use_bias = use_bias\n@@ -953,7 +953,7 @@ class Conv1DTranspose(Conv1D):\n     self.output_padding = output_padding\n     if self.output_padding is not None:\n       self.output_padding = conv_utils.normalize_tuple(\n-          self.output_padding, 1, 'output_padding')\n+          self.output_padding, 1, 'output_padding', lambda x: x < 0)\n       for stride, out_pad in zip(self.strides, self.output_padding):\n         if out_pad >= stride:\n           raise ValueError('Strides must be greater than output padding. '\n@@ -1227,7 +1227,7 @@ class Conv2DTranspose(Conv2D):\n     self.output_padding = output_padding\n     if self.output_padding is not None:\n       self.output_padding = conv_utils.normalize_tuple(\n-          self.output_padding, 2, 'output_padding')\n+          self.output_padding, 2, 'output_padding', lambda x: x < 0)\n       for stride, out_pad in zip(self.strides, self.output_padding):\n         if out_pad >= stride:\n           raise ValueError('Strides must be greater than output padding. '\n@@ -1540,7 +1540,7 @@ class Conv3DTranspose(Conv3D):\n     self.output_padding = output_padding\n     if self.output_padding is not None:\n       self.output_padding = conv_utils.normalize_tuple(\n-          self.output_padding, 3, 'output_padding')\n+          self.output_padding, 3, 'output_padding', lambda x: x < 0)\n       for stride, out_pad in zip(self.strides, self.output_padding):\n         if out_pad >= stride:\n           raise ValueError('Strides must be greater than output padding. '\n@@ -3081,7 +3081,7 @@ class ZeroPadding1D(Layer):\n \n   def __init__(self, padding=1, **kwargs):\n     super(ZeroPadding1D, self).__init__(**kwargs)\n-    self.padding = conv_utils.normalize_tuple(padding, 2, 'padding')\n+    self.padding = conv_utils.normalize_tuple(padding, 2, 'padding', lambda x: x < 0)\n     self.input_spec = InputSpec(ndim=3)\n \n   def compute_output_shape(self, input_shape):\n@@ -3177,9 +3177,9 @@ class ZeroPadding2D(Layer):\n         raise ValueError('`padding` should have two elements. '\n                          f'Received: {padding}.')\n       height_padding = conv_utils.normalize_tuple(padding[0], 2,\n-                                                  '1st entry of padding')\n+                                                  '1st entry of padding', lambda x: x < 0)\n       width_padding = conv_utils.normalize_tuple(padding[1], 2,\n-                                                 '2nd entry of padding')\n+                                                 '2nd entry of padding', lambda x: x < 0)\n       self.padding = (height_padding, width_padding)\n     else:\n       raise ValueError('`padding` should be either an int, '\n@@ -3290,11 +3290,11 @@ class ZeroPadding3D(Layer):\n         raise ValueError('`padding` should have 3 elements. '\n                          f'Received: {padding}.')\n       dim1_padding = conv_utils.normalize_tuple(padding[0], 2,\n-                                                '1st entry of padding')\n+                                                '1st entry of padding', lambda x: x < 0)\n       dim2_padding = conv_utils.normalize_tuple(padding[1], 2,\n-                                                '2nd entry of padding')\n+                                                '2nd entry of padding', lambda x: x < 0)\n       dim3_padding = conv_utils.normalize_tuple(padding[2], 2,\n-                                                '3rd entry of padding')\n+                                                '3rd entry of padding', lambda x: x < 0)\n       self.padding = (dim1_padding, dim2_padding, dim3_padding)\n     else:\n       raise ValueError(\n\n@@ -487,13 +487,13 @@ class ConvLSTMCell(DropoutRNNCellMixin, Layer):\n       raise ValueError(f'Rank {rank} convolutions are not currently '\n                        f'implemented. Received: rank={rank}')\n     self.filters = filters\n-    self.kernel_size = conv_utils.normalize_positive_tuple(kernel_size, self.rank,\n-                                                  'kernel_size')\n-    self.strides = conv_utils.normalize_tuple(strides, self.rank, 'strides')\n+    self.kernel_size = conv_utils.normalize_tuple(kernel_size, self.rank,\n+                                                  'kernel_size', lambda x: x <= 0)\n+    self.strides = conv_utils.normalize_tuple(strides, self.rank, 'strides', lambda x: x < 0)\n     self.padding = conv_utils.normalize_padding(padding)\n     self.data_format = conv_utils.normalize_data_format(data_format)\n     self.dilation_rate = conv_utils.normalize_tuple(dilation_rate, self.rank,\n-                                                    'dilation_rate')\n+                                                    'dilation_rate', lambda x: x <= 0)\n     self.activation = activations.get(activation)\n     self.recurrent_activation = activations.get(recurrent_activation)\n     self.use_bias = use_bias\n\n@@ -132,7 +132,7 @@ class LocallyConnected1D(Layer):\n                **kwargs):\n     super(LocallyConnected1D, self).__init__(**kwargs)\n     self.filters = filters\n-    self.kernel_size = conv_utils.normalize_positive_tuple(kernel_size, 1, 'kernel_size')\n+    self.kernel_size = conv_utils.normalize_tuple(kernel_size, 1, 'kernel_size', lambda x: x <= 0)\n     self.strides = conv_utils.normalize_tuple(strides, 1, 'strides')\n     self.padding = conv_utils.normalize_padding(padding)\n     if self.padding != 'valid' and implementation == 1:\n@@ -439,7 +439,7 @@ class LocallyConnected2D(Layer):\n                **kwargs):\n     super(LocallyConnected2D, self).__init__(**kwargs)\n     self.filters = filters\n-    self.kernel_size = conv_utils.normalize_positive_tuple(kernel_size, 2, 'kernel_size')\n+    self.kernel_size = conv_utils.normalize_tuple(kernel_size, 2, 'kernel_size', lambda x: x <= 0)\n     self.strides = conv_utils.normalize_tuple(strides, 2, 'strides')\n     self.padding = conv_utils.normalize_padding(padding)\n     if self.padding != 'valid' and implementation == 1:\n\n@@ -56,7 +56,7 @@ class Pooling1D(Layer):\n     if strides is None:\n       strides = pool_size\n     self.pool_function = pool_function\n-    self.pool_size = conv_utils.normalize_positive_tuple(pool_size, 1, 'pool_size')\n+    self.pool_size = conv_utils.normalize_tuple(pool_size, 1, 'pool_size', lambda x: x <= 0)\n     self.strides = conv_utils.normalize_tuple(strides, 1, 'strides')\n     self.padding = conv_utils.normalize_padding(padding)\n     self.data_format = conv_utils.normalize_data_format(data_format)\n@@ -339,7 +339,7 @@ class Pooling2D(Layer):\n     if strides is None:\n       strides = pool_size\n     self.pool_function = pool_function\n-    self.pool_size = conv_utils.normalize_positive_tuple(pool_size, 2, 'pool_size')\n+    self.pool_size = conv_utils.normalize_tuple(pool_size, 2, 'pool_size', lambda x: x <= 0)\n     self.strides = conv_utils.normalize_tuple(strides, 2, 'strides')\n     self.padding = conv_utils.normalize_padding(padding)\n     self.data_format = conv_utils.normalize_data_format(data_format)\n@@ -677,7 +677,7 @@ class Pooling3D(Layer):\n     if strides is None:\n       strides = pool_size\n     self.pool_function = pool_function\n-    self.pool_size = conv_utils.normalize_positive_tuple(pool_size, 3, 'pool_size')\n+    self.pool_size = conv_utils.normalize_tuple(pool_size, 3, 'pool_size', lambda x: x <= 0)\n     self.strides = conv_utils.normalize_tuple(strides, 3, 'strides')\n     self.padding = conv_utils.normalize_padding(padding)\n     self.data_format = conv_utils.normalize_data_format(data_format)\n\n@@ -49,32 +49,7 @@ def convert_data_format(data_format, ndim):\n         'Expected values are [\"channels_first\", \"channels_last\"]')\n \n \n-def normalize_positive_tuple(value, n, name):\n-  \"\"\"Transforms a single positive integer or iterable of positive integers into an\n-    integer tuple.\n-\n-  Args:\n-    value: The value to validate and convert. Could a positive int, or any iterable\n-      of positive ints.\n-    n: The size of the tuple to be returned.\n-    name: The name of the argument being validated, e.g. \"pool_size\" or \"kernel_size\".\n-    This is only used for format error messages.\n-\n-  Returns:\n-    A tuple of n positive integers.\n-\n-  Raises:\n-    ValueError: If something else than an postive int/long or iterable thereof was passed.\n-  \"\"\"\n-  value_tuple = normalize_tuple(value, n, name)\n-  for value in value_tuple:\n-    if value <= 0:\n-      raise ValueError(f'The `{name}` argument must be a positive int or a tuple of positive integers. '\n-                       f'Received: {value}.')\n-  return value_tuple\n-\n-\n-def normalize_tuple(value, n, name):\n+def normalize_tuple(value, n, name, cmp=None):\n   \"\"\"Transforms a single integer or iterable of integers into an integer tuple.\n \n   Args:\n@@ -83,7 +58,7 @@ def normalize_tuple(value, n, name):\n     n: The size of the tuple to be returned.\n     name: The name of the argument being validated, e.g. \"strides\" or\n       \"kernel_size\". This is only used to format error messages.\n-\n+    cmp: the function used to filter out unqualified values.\n   Returns:\n     A tuple of n integers.\n \n@@ -110,6 +85,11 @@ def normalize_tuple(value, n, name):\n         error_msg += (f'including element {single_value} of '\n                       f'type {type(single_value)}')\n         raise ValueError(error_msg)\n+\n+    unqualified_values = [v for v in value_tuple if cmp is not None and cmp(v)]\n+    if len(unqualified_values) > 0:\n+      error_msg += f' that does not satisfy the requirement.'\n+      raise ValueError(error_msg)\n     return value_tuple\n \n \n\n@@ -67,27 +67,27 @@ class TestBasicConvUtilsTest(tf.test.TestCase):\n \n   def test_normalize_tuple(self):\n     self.assertEqual((2, 2, 2),\n-                     conv_utils.normalize_tuple(2, n=3, name='strides'))\n+                     conv_utils.normalize_tuple(2, n=3, name='strides', cmp=lambda x: x < 0))\n     self.assertEqual((2, 1, 2),\n-                     conv_utils.normalize_tuple((2, 1, 2), n=3, name='strides'))\n-\n-    with self.assertRaises(ValueError):\n-      conv_utils.normalize_tuple((2, 1), n=3, name='strides')\n-\n-    with self.assertRaises(ValueError):\n-      conv_utils.normalize_tuple(None, n=3, name='strides')\n-\n-  def test_normalize_positive_tuple(self):\n+                     conv_utils.normalize_tuple((2, 1, 2), n=3, name='strides', cmp=lambda x: x < 0))\n     self.assertEqual((1, 2, 3,),\n-                     conv_utils.normalize_positive_tuple((1, 2, 3), n=3, name='pool_size'))\n+                     conv_utils.normalize_tuple((1, 2, 3), n=3, name='pool_size', cmp=lambda x: x <= 0))\n     self.assertEqual((3, 3, 3),\n-                     conv_utils.normalize_positive_tuple(3, n=3, name='pool_size'))\n+                     conv_utils.normalize_tuple(3, n=3, name='pool_size', cmp=lambda x: x <= 0))\n+    self.assertEqual((3, -1, 3),\n+                     conv_utils.normalize_tuple((3, -1, 3), n=3, name='negative_size'))\n \n     with self.assertRaises(ValueError):\n-      conv_utils.normalize_positive_tuple(-4, n=3, name='pool_size')\n+      conv_utils.normalize_tuple((2, 1), n=3, name='strides', cmp=lambda x: x < 0)\n \n     with self.assertRaises(ValueError):\n-      conv_utils.normalize_positive_tuple((0, 1, 2), n=3, name='pool_size')\n+      conv_utils.normalize_tuple(None, n=3, name='strides', cmp=lambda x: x < 0)\n+\n+    with self.assertRaises(ValueError):\n+      conv_utils.normalize_tuple(-4, n=3, name='pool_size', cmp=lambda x: x <= 0)\n+\n+    with self.assertRaises(ValueError):\n+      conv_utils.normalize_tuple((0, 1, 2), n=3, name='pool_size', cmp=lambda x: x <= 0)\n \n   def test_normalize_data_format(self):\n     self.assertEqual('channels_last',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ce8b3d398f84eb88959fb188e8e0c90dcef65ec0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 7 | Files Changed: 2 | Hunks: 7 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 19 | Churn Cumulative: 1543 | Contributors (this commit): 17 | Commits (past 90d): 8 | Contributors (cumulative): 20 | DMM Complexity: 0.8\n\nDIFF:\n@@ -88,7 +88,8 @@ def normalize_tuple(value, n, name, cmp=None):\n \n     unqualified_values = [v for v in value_tuple if cmp is not None and cmp(v)]\n     if len(unqualified_values) > 0:\n-      error_msg += f' that does not satisfy the requirement.'\n+      error_msg += (f' including {unqualified_values}'\n+                    f' that does not satisfy the requirement.')\n       raise ValueError(error_msg)\n     return value_tuple\n \n\n@@ -77,17 +77,21 @@ class TestBasicConvUtilsTest(tf.test.TestCase):\n     self.assertEqual((3, -1, 3),\n                      conv_utils.normalize_tuple((3, -1, 3), n=3, name='negative_size'))\n \n-    with self.assertRaises(ValueError):\n+    with self.assertRaises(ValueError) as ctx:\n       conv_utils.normalize_tuple((2, 1), n=3, name='strides', cmp=lambda x: x < 0)\n+      self.assertTrue('The `strides` argument must be a tuple of 3' in str(ctx.exception))\n \n-    with self.assertRaises(ValueError):\n-      conv_utils.normalize_tuple(None, n=3, name='strides', cmp=lambda x: x < 0)\n+    with self.assertRaises(ValueError) as ctx:\n+      conv_utils.normalize_tuple(None, n=3, name='kernel_size', cmp=lambda x: x <= 0)\n+      self.assertTrue('The `kernel_size` argument must be a tuple of 3' in str(ctx.exception))\n \n-    with self.assertRaises(ValueError):\n-      conv_utils.normalize_tuple(-4, n=3, name='pool_size', cmp=lambda x: x <= 0)\n+    with self.assertRaises(ValueError) as ctx:\n+      conv_utils.normalize_tuple(-4, n=3, name='strides', cmp=lambda x: x < 0)\n+      self.assertTrue('that does not satisfy the requirement' in str(ctx.exception))\n \n-    with self.assertRaises(ValueError):\n+    with self.assertRaises(ValueError) as ctx:\n       conv_utils.normalize_tuple((0, 1, 2), n=3, name='pool_size', cmp=lambda x: x <= 0)\n+      self.assertTrue('that does not satisfy the requirement' in str(ctx.exception))\n \n   def test_normalize_data_format(self):\n     self.assertEqual('channels_last',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#eafe8cdc5aaf13d5d3ca2411a236765b7af7351c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1138 | Contributors (this commit): 17 | Commits (past 90d): 6 | Contributors (cumulative): 17 | DMM Complexity: None\n\nDIFF:\n@@ -86,7 +86,7 @@ def normalize_tuple(value, n, name, cmp=None):\n                       f'type {type(single_value)}')\n         raise ValueError(error_msg)\n \n-    unqualified_values = [v for v in value_tuple if cmp is not None and cmp(v)]\n+    unqualified_values = [v for v in value_tuple if cmp and cmp(v)]\n     if len(unqualified_values) > 0:\n       error_msg += (f' including {unqualified_values}'\n                     f' that does not satisfy the requirement.')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bd6f444339074d1fe338c29d6f2bae15a5e91b69", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 4 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 9 | Churn Cumulative: 1147 | Contributors (this commit): 17 | Commits (past 90d): 7 | Contributors (cumulative): 17 | DMM Complexity: 0.0\n\nDIFF:\n@@ -66,12 +66,12 @@ def normalize_tuple(value, n, name, cmp=None):\n     ValueError: If something else than an int/long or iterable thereof was\n       passed.\n   \"\"\"\n-  if isinstance(value, int):\n-    return (value,) * n\n-  else:\n   error_msg = (f'The `{name}` argument must be a tuple of {n} '\n                f'integers. Received: {value}')\n \n+  if isinstance(value, int):\n+    value_tuple = (value,) * n\n+  else:\n     try:\n       value_tuple = tuple(value)\n     except TypeError:\n@@ -87,10 +87,13 @@ def normalize_tuple(value, n, name, cmp=None):\n         raise ValueError(error_msg)\n \n   unqualified_values = [v for v in value_tuple if cmp and cmp(v)]\n+  print(unqualified_values, value_tuple)\n+\n   if len(unqualified_values) > 0:\n     error_msg += (f' including {unqualified_values}'\n                   f' that does not satisfy the requirement.')\n     raise ValueError(error_msg)\n+\n   return value_tuple\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a21a165150a4bdea810ebc474a74faf344b49266", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 1148 | Contributors (this commit): 17 | Commits (past 90d): 8 | Contributors (cumulative): 17 | DMM Complexity: 1.0\n\nDIFF:\n@@ -87,7 +87,6 @@ def normalize_tuple(value, n, name, cmp=None):\n         raise ValueError(error_msg)\n \n   unqualified_values = [v for v in value_tuple if cmp and cmp(v)]\n-  print(unqualified_values, value_tuple)\n \n   if len(unqualified_values) > 0:\n     error_msg += (f' including {unqualified_values}'\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#52380ed4437749467912e34a3b485a928160828f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 62 | Lines Deleted: 47 | Files Changed: 6 | Hunks: 38 | Methods Changed: 15 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 109 | Churn Cumulative: 34035 | Contributors (this commit): 114 | Commits (past 90d): 58 | Contributors (cumulative): 165 | DMM Complexity: 1.0\n\nDIFF:\n@@ -137,12 +137,13 @@ class Conv(Layer):\n     self.filters = filters\n     self.groups = groups or 1\n     self.kernel_size = conv_utils.normalize_tuple(\n-        kernel_size, rank, 'kernel_size', lambda x: x <= 0)\n-    self.strides = conv_utils.normalize_tuple(strides, rank, 'strides', lambda x: x < 0)\n+        kernel_size, rank, 'kernel_size')\n+    self.strides = conv_utils.normalize_tuple(\n+        strides, rank, 'strides', lambda x: x >= 0, '>=0')\n     self.padding = conv_utils.normalize_padding(padding)\n     self.data_format = conv_utils.normalize_data_format(data_format)\n     self.dilation_rate = conv_utils.normalize_tuple(\n-        dilation_rate, rank, 'dilation_rate', lambda x: x <= 0)\n+        dilation_rate, rank, 'dilation_rate')\n \n     self.activation = activations.get(activation)\n     self.use_bias = use_bias\n@@ -953,7 +954,7 @@ class Conv1DTranspose(Conv1D):\n     self.output_padding = output_padding\n     if self.output_padding is not None:\n       self.output_padding = conv_utils.normalize_tuple(\n-          self.output_padding, 1, 'output_padding', lambda x: x < 0)\n+          self.output_padding, 1, 'output_padding', lambda x: x >= 0, '>=0')\n       for stride, out_pad in zip(self.strides, self.output_padding):\n         if out_pad >= stride:\n           raise ValueError('Strides must be greater than output padding. '\n@@ -1227,7 +1228,7 @@ class Conv2DTranspose(Conv2D):\n     self.output_padding = output_padding\n     if self.output_padding is not None:\n       self.output_padding = conv_utils.normalize_tuple(\n-          self.output_padding, 2, 'output_padding', lambda x: x < 0)\n+          self.output_padding, 2, 'output_padding', lambda x: x >= 0, '>=0')\n       for stride, out_pad in zip(self.strides, self.output_padding):\n         if out_pad >= stride:\n           raise ValueError('Strides must be greater than output padding. '\n@@ -1540,7 +1541,7 @@ class Conv3DTranspose(Conv3D):\n     self.output_padding = output_padding\n     if self.output_padding is not None:\n       self.output_padding = conv_utils.normalize_tuple(\n-          self.output_padding, 3, 'output_padding', lambda x: x < 0)\n+          self.output_padding, 3, 'output_padding', lambda x: x >= 0, '>=0')\n       for stride, out_pad in zip(self.strides, self.output_padding):\n         if out_pad >= stride:\n           raise ValueError('Strides must be greater than output padding. '\n@@ -3081,7 +3082,7 @@ class ZeroPadding1D(Layer):\n \n   def __init__(self, padding=1, **kwargs):\n     super(ZeroPadding1D, self).__init__(**kwargs)\n-    self.padding = conv_utils.normalize_tuple(padding, 2, 'padding', lambda x: x < 0)\n+    self.padding = conv_utils.normalize_tuple(padding, 2, 'padding', lambda x: x >= 0, '>=0')\n     self.input_spec = InputSpec(ndim=3)\n \n   def compute_output_shape(self, input_shape):\n@@ -3177,9 +3178,9 @@ class ZeroPadding2D(Layer):\n         raise ValueError('`padding` should have two elements. '\n                          f'Received: {padding}.')\n       height_padding = conv_utils.normalize_tuple(padding[0], 2,\n-                                                  '1st entry of padding', lambda x: x < 0)\n+                                                  '1st entry of padding', lambda x: x >= 0, '>=0')\n       width_padding = conv_utils.normalize_tuple(padding[1], 2,\n-                                                 '2nd entry of padding', lambda x: x < 0)\n+                                                 '2nd entry of padding', lambda x: x >= 0, '>=0')\n       self.padding = (height_padding, width_padding)\n     else:\n       raise ValueError('`padding` should be either an int, '\n@@ -3290,11 +3291,14 @@ class ZeroPadding3D(Layer):\n         raise ValueError('`padding` should have 3 elements. '\n                          f'Received: {padding}.')\n       dim1_padding = conv_utils.normalize_tuple(padding[0], 2,\n-                                                '1st entry of padding', lambda x: x < 0)\n+                                                '1st entry of padding',\n+                                                lambda x: x >= 0, '>=0')\n       dim2_padding = conv_utils.normalize_tuple(padding[1], 2,\n-                                                '2nd entry of padding', lambda x: x < 0)\n+                                                '2nd entry of padding',\n+                                                lambda x: x >= 0, '>=0')\n       dim3_padding = conv_utils.normalize_tuple(padding[2], 2,\n-                                                '3rd entry of padding', lambda x: x < 0)\n+                                                '3rd entry of padding',\n+                                                lambda x: x >= 0, '>=0')\n       self.padding = (dim1_padding, dim2_padding, dim3_padding)\n     else:\n       raise ValueError(\n@@ -3389,7 +3393,8 @@ class Cropping1D(Layer):\n \n   def __init__(self, cropping=(1, 1), **kwargs):\n     super(Cropping1D, self).__init__(**kwargs)\n-    self.cropping = conv_utils.normalize_tuple(cropping, 2, 'cropping')\n+    self.cropping = conv_utils.normalize_tuple(\n+        cropping, 2, 'cropping', lambda x: x >= 0, '>=0')\n     self.input_spec = InputSpec(ndim=3)\n \n   def compute_output_shape(self, input_shape):\n@@ -3477,9 +3482,11 @@ class Cropping2D(Layer):\n         raise ValueError('`cropping` should have two elements. '\n                          f'Received: {cropping}.')\n       height_cropping = conv_utils.normalize_tuple(cropping[0], 2,\n-                                                   '1st entry of cropping')\n+                                                   '1st entry of cropping',\n+                                                   lambda x: x >= 0, '>=0')\n       width_cropping = conv_utils.normalize_tuple(cropping[1], 2,\n-                                                  '2nd entry of cropping')\n+                                                  '2nd entry of cropping',\n+                                                  lambda x: x >= 0, '>=0')\n       self.cropping = (height_cropping, width_cropping)\n     else:\n       raise ValueError('`cropping` should be either an int, '\n@@ -3609,11 +3616,14 @@ class Cropping3D(Layer):\n         raise ValueError('`cropping` should have 3 elements. '\n                          f'Received: {cropping}.')\n       dim1_cropping = conv_utils.normalize_tuple(cropping[0], 2,\n-                                                 '1st entry of cropping')\n+                                                 '1st entry of cropping',\n+                                                 lambda x: x >= 0, '>=0')\n       dim2_cropping = conv_utils.normalize_tuple(cropping[1], 2,\n-                                                 '2nd entry of cropping')\n+                                                 '2nd entry of cropping',\n+                                                 lambda x: x >= 0, '>=0')\n       dim3_cropping = conv_utils.normalize_tuple(cropping[2], 2,\n-                                                 '3rd entry of cropping')\n+                                                 '3rd entry of cropping',\n+                                                 lambda x: x >= 0, '>=0')\n       self.cropping = (dim1_cropping, dim2_cropping, dim3_cropping)\n     else:\n       raise ValueError(\n\n@@ -487,13 +487,14 @@ class ConvLSTMCell(DropoutRNNCellMixin, Layer):\n       raise ValueError(f'Rank {rank} convolutions are not currently '\n                        f'implemented. Received: rank={rank}')\n     self.filters = filters\n-    self.kernel_size = conv_utils.normalize_tuple(kernel_size, self.rank,\n-                                                  'kernel_size', lambda x: x <= 0)\n-    self.strides = conv_utils.normalize_tuple(strides, self.rank, 'strides', lambda x: x < 0)\n+    self.kernel_size = conv_utils.normalize_tuple(\n+        kernel_size, self.rank, 'kernel_size')\n+    self.strides = conv_utils.normalize_tuple(\n+        strides, self.rank, 'strides', lambda x: x >= 0, '>=0')\n     self.padding = conv_utils.normalize_padding(padding)\n     self.data_format = conv_utils.normalize_data_format(data_format)\n-    self.dilation_rate = conv_utils.normalize_tuple(dilation_rate, self.rank,\n-                                                    'dilation_rate', lambda x: x <= 0)\n+    self.dilation_rate = conv_utils.normalize_tuple(\n+        dilation_rate, self.rank, 'dilation_rate')\n     self.activation = activations.get(activation)\n     self.recurrent_activation = activations.get(recurrent_activation)\n     self.use_bias = use_bias\n@@ -644,7 +645,7 @@ class ConvLSTMCell(DropoutRNNCellMixin, Layer):\n     return conv_out\n \n   def recurrent_conv(self, x, w):\n-    strides = conv_utils.normalize_tuple(1, self.rank, 'strides')\n+    strides = conv_utils.normalize_tuple(1, self.rank, 'strides', lambda s: s >= 0, '>=0')\n     conv_out = self._conv_func(\n         x, w, strides=strides, padding='same', data_format=self.data_format)\n     return conv_out\n\n@@ -132,8 +132,8 @@ class LocallyConnected1D(Layer):\n                **kwargs):\n     super(LocallyConnected1D, self).__init__(**kwargs)\n     self.filters = filters\n-    self.kernel_size = conv_utils.normalize_tuple(kernel_size, 1, 'kernel_size', lambda x: x <= 0)\n-    self.strides = conv_utils.normalize_tuple(strides, 1, 'strides')\n+    self.kernel_size = conv_utils.normalize_tuple(kernel_size, 1, 'kernel_size')\n+    self.strides = conv_utils.normalize_tuple(strides, 1, 'strides', lambda x: x >= 0, '>=0')\n     self.padding = conv_utils.normalize_padding(padding)\n     if self.padding != 'valid' and implementation == 1:\n       raise ValueError('Invalid border mode for LocallyConnected1D '\n@@ -439,8 +439,8 @@ class LocallyConnected2D(Layer):\n                **kwargs):\n     super(LocallyConnected2D, self).__init__(**kwargs)\n     self.filters = filters\n-    self.kernel_size = conv_utils.normalize_tuple(kernel_size, 2, 'kernel_size', lambda x: x <= 0)\n-    self.strides = conv_utils.normalize_tuple(strides, 2, 'strides')\n+    self.kernel_size = conv_utils.normalize_tuple(kernel_size, 2, 'kernel_size')\n+    self.strides = conv_utils.normalize_tuple(strides, 2, 'strides', lambda x: x >= 0, '>=0')\n     self.padding = conv_utils.normalize_padding(padding)\n     if self.padding != 'valid' and implementation == 1:\n       raise ValueError('Invalid border mode for LocallyConnected2D '\n\n@@ -56,8 +56,8 @@ class Pooling1D(Layer):\n     if strides is None:\n       strides = pool_size\n     self.pool_function = pool_function\n-    self.pool_size = conv_utils.normalize_tuple(pool_size, 1, 'pool_size', lambda x: x <= 0)\n-    self.strides = conv_utils.normalize_tuple(strides, 1, 'strides')\n+    self.pool_size = conv_utils.normalize_tuple(pool_size, 1, 'pool_size')\n+    self.strides = conv_utils.normalize_tuple(strides, 1, 'strides', lambda x: x >= 0, '>=0')\n     self.padding = conv_utils.normalize_padding(padding)\n     self.data_format = conv_utils.normalize_data_format(data_format)\n     self.input_spec = InputSpec(ndim=3)\n@@ -339,8 +339,8 @@ class Pooling2D(Layer):\n     if strides is None:\n       strides = pool_size\n     self.pool_function = pool_function\n-    self.pool_size = conv_utils.normalize_tuple(pool_size, 2, 'pool_size', lambda x: x <= 0)\n-    self.strides = conv_utils.normalize_tuple(strides, 2, 'strides')\n+    self.pool_size = conv_utils.normalize_tuple(pool_size, 2, 'pool_size')\n+    self.strides = conv_utils.normalize_tuple(strides, 2, 'strides', lambda x: x >= 0, '>=0')\n     self.padding = conv_utils.normalize_padding(padding)\n     self.data_format = conv_utils.normalize_data_format(data_format)\n     self.input_spec = InputSpec(ndim=4)\n@@ -677,8 +677,8 @@ class Pooling3D(Layer):\n     if strides is None:\n       strides = pool_size\n     self.pool_function = pool_function\n-    self.pool_size = conv_utils.normalize_tuple(pool_size, 3, 'pool_size', lambda x: x <= 0)\n-    self.strides = conv_utils.normalize_tuple(strides, 3, 'strides')\n+    self.pool_size = conv_utils.normalize_tuple(pool_size, 3, 'pool_size')\n+    self.strides = conv_utils.normalize_tuple(strides, 3, 'strides', lambda x: x >= 0, '>=0')\n     self.padding = conv_utils.normalize_padding(padding)\n     self.data_format = conv_utils.normalize_data_format(data_format)\n     self.input_spec = InputSpec(ndim=5)\n\n@@ -49,7 +49,7 @@ def convert_data_format(data_format, ndim):\n         'Expected values are [\"channels_first\", \"channels_last\"]')\n \n \n-def normalize_tuple(value, n, name, cmp=None):\n+def normalize_tuple(value, n, name, validation_fn=lambda x: x > 0, fn_alt='>0'):\n   \"\"\"Transforms a single integer or iterable of integers into an integer tuple.\n \n   Args:\n@@ -58,7 +58,8 @@ def normalize_tuple(value, n, name, cmp=None):\n     n: The size of the tuple to be returned.\n     name: The name of the argument being validated, e.g. \"strides\" or\n       \"kernel_size\". This is only used to format error messages.\n-    cmp: the function used to filter out unqualified values.\n+    validation_fn: the function used to filter out unqualified values.\n+    fn_alt: alternative text for validation_fn.\n   Returns:\n     A tuple of n integers.\n \n@@ -86,11 +87,11 @@ def normalize_tuple(value, n, name, cmp=None):\n                       f'type {type(single_value)}')\n         raise ValueError(error_msg)\n \n-  unqualified_values = [v for v in value_tuple if cmp and cmp(v)]\n+  unqualified_values = [v for v in value_tuple if validation_fn and (not validation_fn(v))]\n \n   if len(unqualified_values) > 0:\n     error_msg += (f' including {unqualified_values}'\n-                  f' that does not satisfy the requirement.')\n+                  f' that does not satisfy the requirement {fn_alt}.')\n     raise ValueError(error_msg)\n \n   return value_tuple\n\n@@ -67,30 +67,33 @@ class TestBasicConvUtilsTest(tf.test.TestCase):\n \n   def test_normalize_tuple(self):\n     self.assertEqual((2, 2, 2),\n-                     conv_utils.normalize_tuple(2, n=3, name='strides', cmp=lambda x: x < 0))\n+                     conv_utils.normalize_tuple(2,\n+                                                n=3, name='strides', validation_fn=lambda x: x >= 0, fn_alt='>=0'))\n     self.assertEqual((2, 1, 2),\n-                     conv_utils.normalize_tuple((2, 1, 2), n=3, name='strides', cmp=lambda x: x < 0))\n+                     conv_utils.normalize_tuple((2, 1, 2),\n+                                                n=3, name='strides', validation_fn=lambda x: x >= 0, fn_alt='>=0'))\n     self.assertEqual((1, 2, 3,),\n-                     conv_utils.normalize_tuple((1, 2, 3), n=3, name='pool_size', cmp=lambda x: x <= 0))\n+                     conv_utils.normalize_tuple((1, 2, 3), n=3, name='pool_size'))\n     self.assertEqual((3, 3, 3),\n-                     conv_utils.normalize_tuple(3, n=3, name='pool_size', cmp=lambda x: x <= 0))\n+                     conv_utils.normalize_tuple(3, n=3, name='pool_size'))\n     self.assertEqual((3, -1, 3),\n-                     conv_utils.normalize_tuple((3, -1, 3), n=3, name='negative_size'))\n+                     conv_utils.normalize_tuple((3, -1, 3),\n+                                                n=3, name='negative_size', validation_fn=None, fn_alt=None))\n \n     with self.assertRaises(ValueError) as ctx:\n-      conv_utils.normalize_tuple((2, 1), n=3, name='strides', cmp=lambda x: x < 0)\n+      conv_utils.normalize_tuple((2, 1), n=3, name='strides', validation_fn=lambda x: x >= 0, fn_alt='>=0')\n     self.assertTrue('The `strides` argument must be a tuple of 3' in str(ctx.exception))\n \n     with self.assertRaises(ValueError) as ctx:\n-      conv_utils.normalize_tuple(None, n=3, name='kernel_size', cmp=lambda x: x <= 0)\n+      conv_utils.normalize_tuple(None, n=3, name='kernel_size')\n     self.assertTrue('The `kernel_size` argument must be a tuple of 3' in str(ctx.exception))\n \n     with self.assertRaises(ValueError) as ctx:\n-      conv_utils.normalize_tuple(-4, n=3, name='strides', cmp=lambda x: x < 0)\n+      conv_utils.normalize_tuple(-4, n=3, name='strides', validation_fn=lambda x: x >= 0, fn_alt='>=0')\n     self.assertTrue('that does not satisfy the requirement' in str(ctx.exception))\n \n     with self.assertRaises(ValueError) as ctx:\n-      conv_utils.normalize_tuple((0, 1, 2), n=3, name='pool_size', cmp=lambda x: x <= 0)\n+      conv_utils.normalize_tuple((0, 1, 2), n=3, name='pool_size')\n     self.assertTrue('that does not satisfy the requirement' in str(ctx.exception))\n \n   def test_normalize_data_format(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
