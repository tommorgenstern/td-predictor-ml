{"custom_id": "keras#151b5f9778b4c2d2d75a46bcc438349b7659e743", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 135 | Lines Deleted: 89 | Files Changed: 7 | Hunks: 27 | Methods Changed: 13 | Complexity Δ (Sum/Max): -73/5 | Churn Δ: 224 | Churn Cumulative: 34609 | Contributors (this commit): 158 | Commits (past 90d): 277 | Contributors (cumulative): 250 | DMM Complexity: 1.0\n\nDIFF:\n@@ -125,8 +125,7 @@ def image_data_format():\n \n \n def set_image_data_format(data_format):\n-    \"\"\"Sets the value of the image dimension\n-    ordering convention ('channels_first' or 'channels_last').\n+    \"\"\"Sets the value of the data format convention.\n \n     # Arguments\n         data_format: string. `'channels_first'` or `'channels_last'`.\n@@ -174,3 +173,40 @@ def is_keras_tensor(x):\n         return True\n     else:\n         return False\n+\n+\n+# Legacy methods\n+\n+def set_image_dim_ordering(dim_ordering):\n+    \"\"\"Sets the value of the image data format.\n+\n+    # Arguments\n+        data_format: string. `'channels_first'` or `'channels_last'`.\n+\n+    # Example\n+    ```python\n+        >>> from keras import backend as K\n+        >>> K.image_data_format()\n+        'channels_first'\n+        >>> K.set_image_data_format('channels_last')\n+        >>> K.image_data_format()\n+        'channels_last'\n+    ```\n+    \"\"\"\n+    global _IMAGE_DATA_FORMAT\n+    if dim_ordering not in {'tf', 'th'}:\n+        raise ValueError('Unknown dim_ordering:', dim_ordering)\n+    if dim_ordering == 'th':\n+        data_format = 'channels_first'\n+    else:\n+        data_format = 'channels_last'\n+    _IMAGE_DATA_FORMAT = data_format\n+\n+\n+def image_dim_ordering():\n+    \"\"\"Legacy getter for data format.\n+    \"\"\"\n+    if _IMAGE_DATA_FORMAT == 'channels_first':\n+        return 'th'\n+    else:\n+        return 'tf'\n\n@@ -13,6 +13,9 @@ import warnings\n from .common import floatx\n from .common import _EPSILON\n from .common import image_data_format\n+# Legacy functions\n+from .common import set_image_dim_ordering, image_dim_ordering\n+\n py_all = all\n py_sum = sum\n \n\n@@ -16,6 +16,9 @@ except ImportError:\n import inspect\n import numpy as np\n from .common import _FLOATX, floatx, _EPSILON, image_data_format\n+# Legacy functions\n+from .common import set_image_dim_ordering, image_dim_ordering\n+\n py_all = all\n py_sum = sum\n \n\n@@ -18,6 +18,7 @@ from .. import initializers\n from ..utils.io_utils import ask_to_proceed_with_overwrite\n from ..utils.layer_utils import print_summary as print_layer_summary\n from ..utils import conv_utils\n+from ..legacy import interfaces\n \n try:\n     import h5py\n@@ -1418,6 +1419,7 @@ class Container(Layer):\n         from_config\n     \"\"\"\n \n+    @interfaces.legacy_model_constructor_support\n     def __init__(self, inputs, outputs, name=None):\n         # Handle `name` argument.\n         if not name:\n\n@@ -1317,6 +1317,7 @@ class Model(Container):\n                                  str(x[0].shape[0]) + ' samples')\n         return x, y, sample_weights\n \n+    @interfaces.legacy_fit_support\n     def fit(self, x=None,\n             y=None,\n             batch_size=32,\n\n@@ -2,12 +2,19 @@\n \"\"\"\n import six\n import warnings\n+import functools\n+import numpy as np\n \n \n def generate_legacy_interface(allowed_positional_args=None,\n                               conversions=None,\n                               preprocessor=None,\n-                              value_conversions=None):\n+                              value_conversions=None,\n+                              object_type='class'):\n+    if allowed_positional_args is None:\n+        check_positional_args = False\n+    else:\n+        check_positional_args = True\n     allowed_positional_args = allowed_positional_args or []\n     conversions = conversions or []\n     value_conversions = value_conversions or []\n@@ -15,18 +22,22 @@ def generate_legacy_interface(allowed_positional_args=None,\n     def legacy_support(func):\n         @six.wraps(func)\n         def wrapper(*args, **kwargs):\n-            layer_name = args[0].__class__.__name__\n+            if object_type == 'class':\n+                object_name = args[0].__class__.__name__\n+            else:\n+                object_name = func.__name__\n             if preprocessor:\n                 args, kwargs, converted = preprocessor(args, kwargs)\n             else:\n                 converted = []\n+            if check_positional_args:\n                 if len(args) > len(allowed_positional_args) + 1:\n-                raise TypeError('Layer `' + layer_name +\n+                    raise TypeError('`' + object_name +\n                                     '` can accept only ' +\n                                     str(len(allowed_positional_args)) +\n                                     ' positional arguments ' +\n-                                str(tuple(allowed_positional_args)) + ', but '\n-                                'you passed the following '\n+                                    str(tuple(allowed_positional_args)) +\n+                                    ', but you passed the following '\n                                     'positional arguments: ' +\n                                     str(list(args[1:])))\n             for key in value_conversions:\n@@ -42,12 +53,18 @@ def generate_legacy_interface(allowed_positional_args=None,\n                     kwargs[new_name] = value\n                     converted.append((new_name, old_name))\n             if converted:\n-                signature = '`' + layer_name + '('\n+                signature = '`' + object_name + '('\n                 for i, value in enumerate(args[1:]):\n                     if isinstance(value, six.string_types):\n                         signature += '\"' + value + '\"'\n                     else:\n-                        signature += str(value)\n+                        if isinstance(value, np.ndarray):\n+                            str_val = 'array'\n+                        else:\n+                            str_val = str(value)\n+                        if len(str_val) > 10:\n+                            str_val = str_val[:10] + '...'\n+                        signature += str_val\n                     if i < len(args[1:]) - 1 or kwargs:\n                         signature += ', '\n                 for i, (name, value) in enumerate(kwargs.items()):\n@@ -55,80 +72,25 @@ def generate_legacy_interface(allowed_positional_args=None,\n                     if isinstance(value, six.string_types):\n                         signature += '\"' + value + '\"'\n                     else:\n-                        signature += str(value)\n+                        if isinstance(value, np.ndarray):\n+                            str_val = 'array'\n+                        else:\n+                            str_val = str(value)\n+                        if len(str_val) > 10:\n+                            str_val = str_val[:10] + '...'\n+                        signature += str_val\n                     if i < len(kwargs) - 1:\n                         signature += ', '\n                 signature += ')`'\n-                warnings.warn('Update your `' + layer_name +\n-                              '` layer call to the Keras 2 API: ' + signature)\n+                warnings.warn('Update your `' + object_name +\n+                              '` call to the Keras 2 API: ' + signature)\n             return func(*args, **kwargs)\n         return wrapper\n     return legacy_support\n \n \n-def generate_legacy_method_interface(allowed_positional_args=None,\n-                                     conversions=None,\n-                                     preprocessor=None,\n-                                     value_conversions=None):\n-    allowed_positional_args = allowed_positional_args or []\n-    conversions = conversions or []\n-    value_conversions = value_conversions or []\n-\n-    def legacy_support(func):\n-        @six.wraps(func)\n-        def wrapper(*args, **kwargs):\n-            method_name = func.__name__\n-            if preprocessor:\n-                args, kwargs, converted = preprocessor(args, kwargs)\n-            else:\n-                converted = []\n-            if len(args) > len(allowed_positional_args) + 1:\n-                raise TypeError('The function `' + method_name +\n-                                '` can accept only ' +\n-                                str(len(allowed_positional_args)) +\n-                                ' positional arguments (' +\n-                                str(allowed_positional_args) + '), but '\n-                                'you passed the following '\n-                                'positional arguments: ' +\n-                                str(args[1:]))\n-            for key in value_conversions:\n-                if key in kwargs:\n-                    old_value = kwargs[key]\n-                    if old_value in value_conversions[key]:\n-                        kwargs[key] = value_conversions[key][old_value]\n-            for old_name, new_name in conversions:\n-                if old_name in kwargs:\n-                    value = kwargs.pop(old_name)\n-                    if new_name in kwargs:\n-                        raise_duplicate_arg_error(old_name, new_name)\n-                    kwargs[new_name] = value\n-                    converted.append((new_name, old_name))\n-            if converted:\n-                signature = '`' + method_name + '('\n-                for value in args[1:]:\n-                    if isinstance(value, six.string_types):\n-                        signature += '\"' + value + '\"'\n-                    elif hasattr(value, '__name__'):\n-                        signature += value.__name__ + '()'\n-                    else:\n-                        signature += str(value)\n-                    signature += ', '\n-                for i, (name, value) in enumerate(kwargs.items()):\n-                    signature += name + '='\n-                    if isinstance(value, six.string_types):\n-                        signature += '\"' + value + '\"'\n-                    elif hasattr(value, '__name__'):\n-                        signature += value.__name__ + '()'\n-                    else:\n-                        signature += str(value)\n-                    if i < len(kwargs) - 1:\n-                        signature += ', '\n-                signature += ')`'\n-                warnings.warn('Update your `' + method_name +\n-                              '` function call to the Keras 2 API: ' + signature)\n-            return func(*args, **kwargs)\n-        return wrapper\n-    return legacy_support\n+generate_legacy_method_interface = functools.partial(generate_legacy_interface,\n+                                                     object_type='method')\n \n \n def raise_duplicate_arg_error(old_arg, new_arg):\n@@ -507,7 +469,7 @@ legacy_batchnorm_support = generate_legacy_interface(\n     preprocessor=batchnorm_args_preprocessor)\n \n \n-def zeropadding2d_preprocessor(args, kwargs):\n+def zeropadding2d_args_preprocessor(args, kwargs):\n     converted = []\n     if 'padding' in kwargs and isinstance(kwargs['padding'], dict):\n         if set(kwargs['padding'].keys()) <= {'top_pad', 'bottom_pad',\n@@ -539,7 +501,7 @@ legacy_zeropadding2d_support = generate_legacy_interface(\n     value_conversions={'dim_ordering': {'tf': 'channels_last',\n                                         'th': 'channels_first',\n                                         'default': None}},\n-    preprocessor=zeropadding2d_preprocessor)\n+    preprocessor=zeropadding2d_args_preprocessor)\n \n legacy_zeropadding3d_support = generate_legacy_interface(\n     allowed_positional_args=['padding'],\n@@ -562,18 +524,6 @@ legacy_cropping3d_support = generate_legacy_interface(\n                                         'th': 'channels_first',\n                                         'default': None}})\n \n-legacy_generator_methods_support = generate_legacy_method_interface(\n-    allowed_positional_args=['generator', 'steps_per_epoch',\n-                             'epochs', 'verbose', 'callbacks',\n-                             'validation_data', 'validation_steps',\n-                             'class_weight', 'max_q_size', 'workers',\n-                             'pickle_safe', 'initial_epoch'],\n-    conversions=[('samples_per_epoch', 'steps_per_epoch'),\n-                 ('val_samples', 'steps'),\n-                 ('nb_epoch', 'epochs'),\n-                 ('nb_val_samples', 'validation_steps'),\n-                 ('nb_worker', 'workers')])\n-\n legacy_spatialdropout1d_support = generate_legacy_interface(\n     allowed_positional_args=['rate'],\n     conversions=[('p', 'rate')])\n@@ -588,3 +538,49 @@ legacy_spatialdropoutNd_support = generate_legacy_interface(\n \n legacy_lambda_support = generate_legacy_interface(\n     allowed_positional_args=['function', 'output_shape'])\n+\n+\n+# Model methods\n+\n+def generator_methods_args_preprocessor(args, kwargs):\n+    converted = []\n+    if len(args) < 3:\n+        if 'samples_per_epoch' in kwargs:\n+            samples_per_epoch = kwargs.pop('samples_per_epoch')\n+            if len(args) > 1:\n+                generator = args[1]\n+            else:\n+                generator = kwargs['generator']\n+            if hasattr(generator, 'batch_size'):\n+                kwargs['steps_per_epoch'] = samples_per_epoch // generator.batch_size\n+            else:\n+                warnings.warn('The semantics of the Keras 2 argument '\n+                              ' `steps_per_epoch` is not the same as the '\n+                              'Keras 1 argument `samples_per_epoch`. '\n+                              '`steps_per_epoch` is the number of batches '\n+                              'to draw from the generator at each epoch. '\n+                              'Update your method calls accordingly.')\n+                kwargs['steps_per_epoch'] = samples_per_epoch\n+            converted.append(('samples_per_epoch', 'steps_per_epoch'))\n+    return args, kwargs, converted\n+\n+\n+legacy_generator_methods_support = generate_legacy_method_interface(\n+    allowed_positional_args=['generator', 'steps_per_epoch', 'epochs'],\n+    conversions=[('samples_per_epoch', 'steps_per_epoch'),\n+                 ('val_samples', 'steps'),\n+                 ('nb_epoch', 'epochs'),\n+                 ('nb_val_samples', 'validation_steps'),\n+                 ('nb_worker', 'workers')],\n+    preprocessor=generator_methods_args_preprocessor)\n+\n+\n+legacy_fit_support = generate_legacy_method_interface(\n+    allowed_positional_args=None,\n+    conversions=[('nb_epoch', 'epochs')])\n+\n+\n+legacy_model_constructor_support = generate_legacy_interface(\n+    allowed_positional_args=None,\n+    conversions=[('input', 'inputs'),\n+                 ('output', 'outputs')])\n\n@@ -19,6 +19,7 @@ from .engine.topology import Layer\n from .engine.topology import Input\n from .legacy import layers as legacy_layers\n from .legacy import models as legacy_models\n+from .legacy import interfaces\n \n try:\n     import h5py\n@@ -771,6 +772,7 @@ class Sequential(Model):\n         self.metrics_names = self.model.metrics_names\n         self.sample_weight_mode = self.model.sample_weight_mode\n \n+    @interfaces.legacy_fit_support\n     def fit(self, x, y, batch_size=32, epochs=10, verbose=1, callbacks=None,\n             validation_split=0., validation_data=None, shuffle=True,\n             class_weight=None, sample_weight=None, initial_epoch=0):\n@@ -990,6 +992,7 @@ class Sequential(Model):\n         else:\n             return (proba > 0.5).astype('int32')\n \n+    @interfaces.legacy_generator_methods_support\n     def fit_generator(self, generator,\n                       steps_per_epoch,\n                       epochs=1,\n@@ -1086,6 +1089,7 @@ class Sequential(Model):\n                                         pickle_safe=pickle_safe,\n                                         initial_epoch=initial_epoch)\n \n+    @interfaces.legacy_generator_methods_support\n     def evaluate_generator(self, generator, steps,\n                            max_q_size=10, workers=1,\n                            pickle_safe=False):\n@@ -1125,6 +1129,7 @@ class Sequential(Model):\n                                              workers=workers,\n                                              pickle_safe=pickle_safe)\n \n+    @interfaces.legacy_generator_methods_support\n     def predict_generator(self, generator, steps,\n                           max_q_size=10, workers=1, pickle_safe=False):\n         \"\"\"Generates predictions for the input samples from a data generator.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d704bea3b2f6230a3a0945b305857da07ced8570", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 31 | Lines Deleted: 9 | Files Changed: 3 | Hunks: 9 | Methods Changed: 6 | Complexity Δ (Sum/Max): 11/7 | Churn Δ: 40 | Churn Cumulative: 14450 | Contributors (this commit): 85 | Commits (past 90d): 101 | Contributors (cumulative): 96 | DMM Complexity: 0.24\n\nDIFF:\n@@ -1317,7 +1317,6 @@ class Model(Container):\n                                  str(x[0].shape[0]) + ' samples')\n         return x, y, sample_weights\n \n-    @interfaces.legacy_fit_support\n     def fit(self, x=None,\n             y=None,\n             batch_size=32,\n@@ -1329,7 +1328,8 @@ class Model(Container):\n             shuffle=True,\n             class_weight=None,\n             sample_weight=None,\n-            initial_epoch=0):\n+            initial_epoch=0,\n+            **kwargs):\n         \"\"\"Trains the model for a fixed number of epochs (iterations on a dataset).\n \n         # Arguments\n@@ -1388,6 +1388,14 @@ class Model(Container):\n             ValueError: In case of mismatch between the provided input data\n                 and what the model expects.\n         \"\"\"\n+        # Legacy support\n+        if 'nb_epoch' in kwargs:\n+            warnings.warn('The `nb_epoch` argument in `fit` '\n+                          'has been renamed `epochs`.')\n+            epochs = kwargs.pop('nb_epoch')\n+        if kwargs:\n+            raise TypeError('Unrecognized keyword arguments: ' + str(kwargs))\n+\n         # validate user data\n         x, y, sample_weights = self._standardize_user_data(\n             x, y,\n\n@@ -279,6 +279,11 @@ def conv2d_args_preprocessor(args, kwargs):\n             kernel_size = (kwargs.pop('nb_row'), kwargs.pop('nb_col'))\n             args = [args[0], args[1], kernel_size]\n             converted.append(('kernel_size', 'nb_row/nb_col'))\n+    elif len(args) == 1:\n+        if 'nb_row' in kwargs and 'nb_col' in kwargs:\n+            kernel_size = (kwargs.pop('nb_row'), kwargs.pop('nb_col'))\n+            kwargs['kernel_size'] = kernel_size\n+            converted.append(('kernel_size', 'nb_row/nb_col'))\n     return args, kwargs, converted\n \n legacy_conv2d_support = generate_legacy_interface(\n@@ -392,6 +397,13 @@ def conv3d_args_preprocessor(args, kwargs):\n                            kwargs.pop('kernel_dim3'))\n             args = [args[0], args[1], kernel_size]\n             converted.append(('kernel_size', 'kernel_dim*'))\n+    elif len(args) == 1:\n+        if 'kernel_dim1' in kwargs and 'kernel_dim2' in kwargs and 'kernel_dim3' in kwargs:\n+            kernel_size = (kwargs.pop('kernel_dim1'),\n+                           kwargs.pop('kernel_dim2'),\n+                           kwargs.pop('kernel_dim3'))\n+            kwargs['kernel_size'] = kernel_size\n+            converted.append(('kernel_size', 'nb_row/nb_col'))\n     return args, kwargs, converted\n \n legacy_conv3d_support = generate_legacy_interface(\n@@ -575,11 +587,6 @@ legacy_generator_methods_support = generate_legacy_method_interface(\n     preprocessor=generator_methods_args_preprocessor)\n \n \n-legacy_fit_support = generate_legacy_method_interface(\n-    allowed_positional_args=None,\n-    conversions=[('nb_epoch', 'epochs')])\n-\n-\n legacy_model_constructor_support = generate_legacy_interface(\n     allowed_positional_args=None,\n     conversions=[('input', 'inputs'),\n\n@@ -772,10 +772,9 @@ class Sequential(Model):\n         self.metrics_names = self.model.metrics_names\n         self.sample_weight_mode = self.model.sample_weight_mode\n \n-    @interfaces.legacy_fit_support\n     def fit(self, x, y, batch_size=32, epochs=10, verbose=1, callbacks=None,\n             validation_split=0., validation_data=None, shuffle=True,\n-            class_weight=None, sample_weight=None, initial_epoch=0):\n+            class_weight=None, sample_weight=None, initial_epoch=0, **kwargs):\n         \"\"\"Trains the model for a fixed number of epochs.\n \n         # Arguments\n@@ -822,6 +821,14 @@ class Sequential(Model):\n         # Raises\n             RuntimeError: if the model was never compiled.\n         \"\"\"\n+        # Legacy support\n+        if 'nb_epoch' in kwargs:\n+            warnings.warn('The `nb_epoch` argument in `fit` '\n+                          'has been renamed `epochs`.')\n+            epochs = kwargs.pop('nb_epoch')\n+        if kwargs:\n+            raise TypeError('Unrecognized keyword arguments: ' + str(kwargs))\n+\n         if self.model is None:\n             raise RuntimeError('The model needs to be compiled '\n                                'before being used.')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ac1afb3e5f6f608ca4303f0c142a86d65b05cb45", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 6 | Methods Changed: 4 | Complexity Δ (Sum/Max): 4/2 | Churn Δ: 22 | Churn Cumulative: 650 | Contributors (this commit): 7 | Commits (past 90d): 17 | Contributors (cumulative): 10 | DMM Complexity: 0.0\n\nDIFF:\n@@ -3,11 +3,12 @@ from ..utils.data_utils import get_file\n from six.moves import zip\n import numpy as np\n import json\n+import warnings\n \n \n def load_data(path='imdb.npz', num_words=None, skip_top=0,\n               maxlen=None, seed=113,\n-              start_char=1, oov_char=2, index_from=3):\n+              start_char=1, oov_char=2, index_from=3, **kwargs):\n     \"\"\"Loads the IMDB dataset.\n \n     # Arguments\n@@ -38,6 +39,14 @@ def load_data(path='imdb.npz', num_words=None, skip_top=0,\n     Words that were not seen in the training set but are in the test set\n     have simply been skipped.\n     \"\"\"\n+    # Legacy support\n+    if 'nb_words' in kwargs:\n+        warnings.warn('The `nb_words` argument in `load_data` '\n+                      'has been renamed `num_words`.')\n+        num_words = kwargs.pop('nb_words')\n+    if kwargs:\n+        raise TypeError('Unrecognized keyword arguments: ' + str(kwargs))\n+\n     path = get_file(path,\n                     origin='https://s3.amazonaws.com/text-datasets/imdb.npz')\n     f = np.load(path)\n\n@@ -4,11 +4,12 @@ from ..utils.data_utils import get_file\n from six.moves import zip\n import numpy as np\n import json\n+import warnings\n \n \n def load_data(path='reuters.npz', num_words=None, skip_top=0,\n               maxlen=None, test_split=0.2, seed=113,\n-              start_char=1, oov_char=2, index_from=3):\n+              start_char=1, oov_char=2, index_from=3, **kwargs):\n     \"\"\"Loads the Reuters newswire classification dataset.\n \n     # Arguments\n@@ -36,6 +37,14 @@ def load_data(path='reuters.npz', num_words=None, skip_top=0,\n     Words that were not seen in the training set but are in the test set\n     have simply been skipped.\n     \"\"\"\n+    # Legacy support\n+    if 'nb_words' in kwargs:\n+        warnings.warn('The `nb_words` argument in `load_data` '\n+                      'has been renamed `num_words`.')\n+        num_words = kwargs.pop('nb_words')\n+    if kwargs:\n+        raise TypeError('Unrecognized keyword arguments: ' + str(kwargs))\n+\n     path = get_file(path, origin='https://s3.amazonaws.com/text-datasets/reuters.npz')\n     npzfile = np.load(path)\n     xs = npzfile['x']\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#96554939784f96b0bb15d069979a7a00f2716ba7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 3/2 | Churn Δ: 16 | Churn Cumulative: 1614 | Contributors (this commit): 17 | Commits (past 90d): 20 | Contributors (cumulative): 18 | DMM Complexity: 0.7777777777777778\n\nDIFF:\n@@ -11,6 +11,7 @@ import sys\n import numpy as np\n from six.moves import range\n from six.moves import zip\n+import warnings\n \n if sys.version_info < (3,):\n     maketrans = string.maketrans\n@@ -81,7 +82,16 @@ class Tokenizer(object):\n                  filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n                  lower=True,\n                  split=' ',\n-                 char_level=False):\n+                 char_level=False,\n+                 **kwargs):\n+        # Legacy support\n+        if 'nb_words' in kwargs:\n+            warnings.warn('The `nb_words` argument in `Tokenizer` '\n+                          'has been renamed `num_words`.')\n+            num_words = kwargs.pop('nb_words')\n+        if kwargs:\n+            raise TypeError('Unrecognized keyword arguments: ' + str(kwargs))\n+\n         self.word_counts = {}\n         self.word_docs = {}\n         self.filters = filters\n\n@@ -82,7 +82,9 @@ class BaseWrapper(object):\n \n         for params_name in params:\n             if params_name not in legal_params:\n-                raise ValueError('{} is not a legal parameter'.format(params_name))\n+                if params_name != 'nb_epoch':\n+                    raise ValueError(\n+                        '{} is not a legal parameter'.format(params_name))\n \n     def get_params(self, **params):\n         \"\"\"Gets parameters for this estimator.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#53c0faa5535c4fb782271d21ca1bbb2191c5f19c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 1225 | Contributors (this commit): 6 | Commits (past 90d): 35 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -159,7 +159,7 @@ def lstm_args_preprocessor(args, kwargs):\n             kwargs.pop('forget_bias_init')\n             warnings.warn('The `forget_bias_init` argument '\n                           'has been ignored. Use `unit_forget_bias=True` '\n-                          'instead to intialize with ones')\n+                          'instead to intialize with ones.')\n     return args, kwargs, converted\n \n legacy_recurrent_support = generate_legacy_interface(\n@@ -450,7 +450,7 @@ def convlstm2d_args_preprocessor(args, kwargs):\n         else:\n             warnings.warn('The `forget_bias_init` argument '\n                           'has been ignored. Use `unit_forget_bias=True` '\n-                          'instead to intialize with ones')\n+                          'instead to intialize with ones.')\n     args, kwargs, _converted = conv2d_args_preprocessor(args, kwargs)\n     return args, kwargs, converted + _converted\n \n@@ -493,7 +493,7 @@ def zeropadding2d_args_preprocessor(args, kwargs):\n             kwargs['padding'] = ((top_pad, bottom_pad), (left_pad, right_pad))\n             warnings.warn('The `padding` argument in the Keras 2 API no longer'\n                           'accepts dict types. You can now input argument as: '\n-                          '`padding`=(top_pad, bottom_pad, left_pad, right_pad)')\n+                          '`padding=(top_pad, bottom_pad, left_pad, right_pad)`.')\n     elif len(args) == 2 and isinstance(args[1], dict):\n         if set(args[1].keys()) <= {'top_pad', 'bottom_pad',\n                                    'left_pad', 'right_pad'}:\n@@ -504,7 +504,7 @@ def zeropadding2d_args_preprocessor(args, kwargs):\n             args = (args[0], ((top_pad, bottom_pad), (left_pad, right_pad)))\n             warnings.warn('The `padding` argument in the Keras 2 API no longer'\n                           'accepts dict types. You can now input argument as: '\n-                          '`padding`=((top_pad, bottom_pad), (left_pad, right_pad))')\n+                          '`padding=((top_pad, bottom_pad), (left_pad, right_pad))`')\n     return args, kwargs, converted\n \n legacy_zeropadding2d_support = generate_legacy_interface(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e9222523ba8f3de04e5fd0a64176f5c3457cc00b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 47 | Lines Deleted: 57 | Files Changed: 1 | Hunks: 8 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 104 | Churn Cumulative: 1055 | Contributors (this commit): 11 | Commits (past 90d): 4 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -39,7 +39,7 @@ Index\n     Text preprocessing\n     Sequence preprocessing\n \n-Objectives\n+Losses\n Metrics\n Optimizers\n Activations\n@@ -65,7 +65,10 @@ if sys.version[0] == '2':\n     reload(sys)\n     sys.setdefaultencoding('utf8')\n \n-from keras.layers import convolutional\n+import keras\n+from keras import utils\n+from keras import layers\n+from keras import initializers\n from keras.layers import pooling\n from keras.layers import local\n from keras.layers import recurrent\n@@ -79,7 +82,7 @@ from keras import optimizers\n from keras import callbacks\n from keras import models\n from keras.engine import topology\n-from keras import objectives\n+from keras import losses\n from keras import metrics\n from keras import backend\n from keras import constraints\n@@ -137,40 +140,35 @@ PAGES = [\n     {\n         'page': 'layers/core.md',\n         'classes': [\n-            core.Dense,\n-            core.Activation,\n-            core.Dropout,\n-            core.Flatten,\n-            core.Reshape,\n-            core.Permute,\n-            core.RepeatVector,\n-            topology.Merge,\n-            core.Lambda,\n-            core.ActivityRegularization,\n-            core.Masking,\n-            core.Highway,\n-            core.MaxoutDense,\n+            layers.Dense,\n+            layers.Activation,\n+            layers.Dropout,\n+            layers.Flatten,\n+            layers.Reshape,\n+            layers.Permute,\n+            layers.RepeatVector,\n+            layers.Lambda,\n+            layers.ActivityRegularization,\n+            layers.Masking,\n         ],\n     },\n     {\n         'page': 'layers/convolutional.md',\n         'classes': [\n-            convolutional.Convolution1D,\n-            convolutional.AtrousConvolution1D,\n-            convolutional.Convolution2D,\n-            convolutional.AtrousConvolution2D,\n-            convolutional.SeparableConvolution2D,\n-            convolutional.Deconvolution2D,\n-            convolutional.Convolution3D,\n-            convolutional.Cropping1D,\n-            convolutional.Cropping2D,\n-            convolutional.Cropping3D,\n-            convolutional.UpSampling1D,\n-            convolutional.UpSampling2D,\n-            convolutional.UpSampling3D,\n-            convolutional.ZeroPadding1D,\n-            convolutional.ZeroPadding2D,\n-            convolutional.ZeroPadding3D,\n+            layers.Conv1D,\n+            layers.Conv2D,\n+            layers.SeparableConv2D,\n+            layers.Conv2DTranspose,\n+            layers.Conv3D,\n+            layers.Cropping1D,\n+            layers.Cropping2D,\n+            layers.Cropping3D,\n+            layers.UpSampling1D,\n+            layers.UpSampling2D,\n+            layers.UpSampling3D,\n+            layers.ZeroPadding1D,\n+            layers.ZeroPadding2D,\n+            layers.ZeroPadding3D,\n         ],\n     },\n     {\n@@ -224,6 +222,10 @@ PAGES = [\n         'page': 'layers/noise.md',\n         'all_module_classes': [noise],\n     },\n+    {\n+        'page': 'layers/merge.md',\n+        'all_module_classes': [keras.merge],\n+    },\n     {\n         'page': 'layers/wrappers.md',\n         'all_module_classes': [wrappers],\n@@ -232,6 +234,15 @@ PAGES = [\n         'page': 'metrics.md',\n         'all_module_functions': [metrics],\n     },\n+    {\n+        'page': 'losses.md',\n+        'all_module_functions': [losses],\n+    },\n+    {\n+        'page': 'initializers.md',\n+        'all_module_functions': [initializers],\n+        'all_module_classes': [initializers],\n+    },\n     {\n         'page': 'optimizers.md',\n         'all_module_classes': [optimizers],\n@@ -245,31 +256,10 @@ PAGES = [\n         'all_module_functions': [backend],\n     },\n     {\n-        'page': 'utils/data_utils.md',\n-        'functions': [\n-            data_utils.get_file,\n-        ]\n-    },\n-    {\n-        'page': 'utils/io_utils.md',\n-        'classes': [\n-            io_utils.HDF5Matrix\n-        ],\n-    },\n-    {\n-        'page': 'utils/layer_utils.md',\n-        'functions': [\n-            layer_utils.layer_from_config,\n-        ]\n-    },\n-    {\n-        'page': 'utils/np_utils.md',\n-        'all_module_functions': [np_utils]\n-    },\n-    {\n-        'page': 'utils/generic_utils.md',\n-        'all_module_functions': [generic_utils],\n-        'classes': [generic_utils.CustomObjectScope]\n+        'page': 'utils.md',\n+        'all_module_functions': [utils],\n+        'classes': [utils.CustomObjectScope,\n+                    utils.HDF5Matrix]\n     },\n ]\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3916e626669c11c094a48c3f0b9def00a30171ea", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 1058 | Contributors (this commit): 12 | Commits (past 90d): 5 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -78,6 +78,7 @@ from keras.layers import normalization\n from keras.layers import advanced_activations\n from keras.layers import embeddings\n from keras.layers import wrappers\n+from keras.layers import merge\n from keras import optimizers\n from keras import callbacks\n from keras import models\n@@ -224,7 +225,7 @@ PAGES = [\n     },\n     {\n         'page': 'layers/merge.md',\n-        'all_module_classes': [keras.merge],\n+        'all_module_classes': [merge],\n     },\n     {\n         'page': 'layers/wrappers.md',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b377edf9748e3d89613db49fee54462b891719e9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 4 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 11 | Churn Cumulative: 12174 | Contributors (this commit): 83 | Commits (past 90d): 118 | Contributors (cumulative): 121 | DMM Complexity: None\n\nDIFF:\n@@ -1874,16 +1874,17 @@ def spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None):\n     return tf.pad(x, pattern)\n \n \n-def stack(x):\n+def stack(x, axis=0):\n     \"\"\"Stacks a list of rank `R` tensors into a rank `R+1` tensor.\n \n     # Arguments\n-        x: Tensor or variable.\n+        x: List of tensors.\n+        axis: Axis along which to perform stacking.\n \n     # Returns\n         A tensor.\n     \"\"\"\n-    return tf.stack(x)\n+    return tf.stack(x, axis=axis)\n \n \n def one_hot(indices, num_classes):\n\n@@ -985,8 +985,8 @@ def spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None):\n     return T.set_subtensor(output[indices], x)\n \n \n-def stack(x):\n-    return T.stack(*x)\n+def stack(x, axis=0):\n+    return T.stack(x, axis=axis)\n \n \n def one_hot(indices, num_classes):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#859ffebfcca389f15b92cc5185548640e2401edf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 1065 | Contributors (this commit): 12 | Commits (past 90d): 6 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -102,6 +102,9 @@ EXCLUDE = {\n     'get_session',\n     'set_session',\n     'CallbackList',\n+    'serialize',\n+    'deserialize',\n+    'get',\n }\n \n PAGES = [\n@@ -252,6 +255,10 @@ PAGES = [\n         'page': 'callbacks.md',\n         'all_module_classes': [callbacks],\n     },\n+    {\n+        'page': 'activations.md',\n+        'all_module_functions': [activations],\n+    },\n     {\n         'page': 'backend.md',\n         'all_module_functions': [backend],\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1b0c05697553cfdefbe14faf0d33b1a19416adb0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 7625 | Contributors (this commit): 28 | Commits (past 90d): 52 | Contributors (cumulative): 28 | DMM Complexity: None\n\nDIFF:\n@@ -2716,6 +2716,18 @@ def save_weights_to_hdf5_group(f, layers):\n def preprocess_weights_for_loading(layer, weights,\n                                    original_keras_version=None,\n                                    original_backend=None):\n+    \"\"\"Converts layers weights from Keras 1 format to Keras 2.\n+\n+    # Arguments\n+        layer: Layer instance.\n+        weights: List of weights values (Numpy arrays).\n+        original_keras_version: Keras version for the weights, as a string.\n+        original_backend: Keras backend the weights were trained with,\n+            as a string.\n+\n+    # Returns\n+        A list of weights values (Numpy arrays).\n+    \"\"\"\n     if original_keras_version == '1':\n         if layer.__class__.__name__ == 'Conv1D':\n             shape = weights[0].shape\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#966ec311d18c8dd7ec4194d53488487691e7b296", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 5 | Methods Changed: 5 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 4187 | Contributors (this commit): 36 | Commits (past 90d): 38 | Contributors (cumulative): 36 | DMM Complexity: None\n\nDIFF:\n@@ -1518,7 +1518,7 @@ class Model(Container):\n             check_batch_axis=False,\n             batch_size=batch_size)\n         # prepare inputs, delegate logic to _test_loop\n-        if self.uses_learning_phase and not isinstance(K.learning_phase, int):\n+        if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n             ins = x + y + sample_weights + [0.]\n         else:\n             ins = x + y + sample_weights\n@@ -1562,7 +1562,7 @@ class Model(Container):\n                                  'Batch size: ' + str(batch_size) + '.')\n \n         # prepare inputs, delegate logic to _predict_loop\n-        if self.uses_learning_phase and not isinstance(K.learning_phase, int):\n+        if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n             ins = x + [0.]\n         else:\n             ins = x\n@@ -1612,7 +1612,7 @@ class Model(Container):\n             sample_weight=sample_weight,\n             class_weight=class_weight,\n             check_batch_axis=True)\n-        if self.uses_learning_phase and not isinstance(K.learning_phase, int):\n+        if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n             ins = x + y + sample_weights + [1.]\n         else:\n             ins = x + y + sample_weights\n@@ -1654,7 +1654,7 @@ class Model(Container):\n             x, y,\n             sample_weight=sample_weight,\n             check_batch_axis=True)\n-        if self.uses_learning_phase and not isinstance(K.learning_phase, int):\n+        if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n             ins = x + y + sample_weights + [0.]\n         else:\n             ins = x + y + sample_weights\n@@ -1675,7 +1675,7 @@ class Model(Container):\n         \"\"\"\n         x = _standardize_input_data(x, self._feed_input_names,\n                                     self._feed_input_shapes)\n-        if self.uses_learning_phase and not isinstance(K.learning_phase, int):\n+        if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n             ins = x + [0.]\n         else:\n             ins = x\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7f58b6fbe702c1936e88a878002ee6e9c469bc77", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 34 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 5 | Methods Changed: 0 | Complexity Δ (Sum/Max): -13/0 | Churn Δ: 36 | Churn Cumulative: 1474 | Contributors (this commit): 21 | Commits (past 90d): 12 | Contributors (cumulative): 22 | DMM Complexity: None\n\nDIFF:\n@@ -78,7 +78,6 @@ from keras.layers import normalization\n from keras.layers import advanced_activations\n from keras.layers import embeddings\n from keras.layers import wrappers\n-from keras.layers import merge\n from keras import optimizers\n from keras import callbacks\n from keras import models\n@@ -228,7 +227,22 @@ PAGES = [\n     },\n     {\n         'page': 'layers/merge.md',\n-        'all_module_classes': [merge],\n+        'classes': [\n+            layers.Add,\n+            layers.Multiply,\n+            layers.Average,\n+            layers.Maximum,\n+            layers.Concatenate,\n+            layers.Dot,\n+        ],\n+        'functions': [\n+            layers.add,\n+            layers.multiply,\n+            layers.average,\n+            layers.maximum,\n+            layers.concatenate,\n+            layers.dot,\n+        ]\n     },\n     {\n         'page': 'layers/wrappers.md',\n@@ -408,6 +422,14 @@ for subdir, dirs, fnames in os.walk('templates'):\n             new_fpath = fpath.replace('templates', 'sources')\n             shutil.copy(fpath, new_fpath)\n \n+# Take care of index page.\n+readme = open('../README.md').read()\n+index = open('templates/index.md').read()\n+index = index.replace('{{autogenerated}}', readme[readme.find('##'):])\n+f = open('sources/index.md', 'w')\n+f.write(index)\n+f.close()\n+\n print('Starting autogeneration.')\n for page_data in PAGES:\n     blocks = []\n@@ -463,6 +485,10 @@ for page_data in PAGES:\n             subblocks.append(process_function_docstring(docstring))\n         blocks.append('\\n\\n'.join(subblocks))\n \n+    if not blocks:\n+        raise RuntimeError('Found no content for page ' +\n+                           page_data['page'])\n+\n     mkdown = '\\n----\\n\\n'.join(blocks)\n     # save module page.\n     # Either insert content into existing page,\n\n@@ -0,0 +1,6 @@\n+\"\"\"Legacy objectives module.\n+\n+Only kept for backwards API compatibility.\n+\"\"\"\n+from __future__ import absolute_import\n+from .losses import *\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a18f9f57559c6e91c8f22abd7e05dbcc5603ca24", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 7633 | Contributors (this commit): 29 | Commits (past 90d): 52 | Contributors (cumulative): 29 | DMM Complexity: None\n\nDIFF:\n@@ -2839,11 +2839,11 @@ def load_weights_from_hdf5_group(f, layers):\n             and weights file.\n     \"\"\"\n     if 'keras_version' in f.attrs:\n-        original_keras_version = f.attrs['keras_version']\n+        original_keras_version = f.attrs['keras_version'].decode('utf8')\n     else:\n         original_keras_version = '1'\n     if 'backend' in f.attrs:\n-        original_backend = f.attrs['backend']\n+        original_backend = f.attrs['backend'].decode('utf8')\n     else:\n         original_backend = None\n \n@@ -2911,11 +2911,11 @@ def load_weights_from_hdf5_group_by_name(f, layers):\n             and weights file.\n     \"\"\"\n     if 'keras_version' in f.attrs:\n-        original_keras_version = f.attrs['keras_version']\n+        original_keras_version = f.attrs['keras_version'].decode('utf8')\n     else:\n         original_keras_version = '1'\n     if 'backend' in f.attrs:\n-        original_backend = f.attrs['backend']\n+        original_backend = f.attrs['backend'].decode('utf8')\n     else:\n         original_backend = None\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f78d417f948cdfaaca22fabf90e01a76db126237", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 191 | Contributors (this commit): 8 | Commits (past 90d): 7 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -15,10 +15,7 @@ setup(name='Keras',\n           'h5py': ['h5py'],\n           'visualize': ['pydot-ng'],\n           'tests': ['pytest',\n-                    'pytest-cov',\n                     'pytest-pep8',\n-                    'pytest-xdist',\n-                    'python-coveralls',\n-                    'coverage==3.7.1'],\n+                    'pytest-xdist'],\n       },\n       packages=find_packages())\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#69a6b1a028781ec3dc4ff00dffc863406d23e86a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 2474 | Contributors (this commit): 41 | Commits (past 90d): 18 | Contributors (cumulative): 41 | DMM Complexity: None\n\nDIFF:\n@@ -581,13 +581,15 @@ class TensorBoard(Callback):\n \n     # Arguments\n         log_dir: the path of the directory where to save the log\n-            files to be parsed by Tensorboard\n+            files to be parsed by Tensorboard.\n         histogram_freq: frequency (in epochs) at which to compute activation\n             histograms for the layers of the model. If set to 0,\n             histograms won't be computed.\n         write_graph: whether to visualize the graph in Tensorboard.\n             The log file can become quite large when\n             write_graph is set to True.\n+        write_images: whether to write model weights to visualize as\n+            image in Tensorboard.\n     \"\"\"\n \n     def __init__(self, log_dir='./logs',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3f7b0ff954188fe64b54ad6ab3a18f1e4418ad9e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 768 | Contributors (this commit): 3 | Commits (past 90d): 6 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -66,7 +66,7 @@ class Merge(Layer):\n         warnings.warn('The `Merge` layer is deprecated '\n                       'and will be removed after 08/2017. '\n                       'Use instead layers from `keras.layers.merge`, '\n-                      'e.g. `add`, `concatenate`, etc.')\n+                      'e.g. `add`, `concatenate`, etc.', stacklevel=2)\n         self.layers = layers\n         self.mode = mode\n         self.concat_axis = concat_axis\n@@ -429,7 +429,7 @@ def merge(inputs, mode='sum', concat_axis=-1,\n     warnings.warn('The `merge` function is deprecated '\n                   'and will be removed after 08/2017. '\n                   'Use instead layers from `keras.layers.merge`, '\n-                  'e.g. `sum`, `concatenate`, etc.')\n+                  'e.g. `sum`, `concatenate`, etc.', stacklevel=2)\n     all_keras_tensors = True\n     for x in inputs:\n         if not hasattr(x, '_keras_history'):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
