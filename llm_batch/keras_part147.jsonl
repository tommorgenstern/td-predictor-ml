{"custom_id": "keras#8ef4a3da52530a86463b2aa015567cbdd6eb2d5a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 46 | Lines Deleted: 39 | Files Changed: 1 | Hunks: 25 | Methods Changed: 8 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 85 | Churn Cumulative: 624 | Contributors (this commit): 5 | Commits (past 90d): 7 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -3,6 +3,8 @@ from .. import backend as K\n \n \n class Wrapper(Layer):\n+    \"\"\"Abstract wrapper base class.\n+    \"\"\"\n \n     def __init__(self, layer, **kwargs):\n         self.layer = layer\n@@ -10,10 +12,8 @@ class Wrapper(Layer):\n         super(Wrapper, self).__init__(**kwargs)\n \n     def build(self, input_shape=None):\n-        \"\"\"Assumes that self.layer is already set.\n-        Should be called at the end of .build() in the\n-        children classes.\n-        \"\"\"\n+        # Assumes that self.layer is already set.\n+        # Should be called at the end of .build() in the children classes.\n         self.trainable_weights = getattr(self.layer, 'trainable_weights', [])\n         self.non_trainable_weights = getattr(self.layer, 'non_trainable_weights', [])\n         self.updates = getattr(self.layer, 'updates', [])\n@@ -41,18 +41,19 @@ class Wrapper(Layer):\n \n \n class TimeDistributed(Wrapper):\n-    \"\"\"This wrapper allows to apply a layer to every\n-    temporal slice of an input.\n+    \"\"\"This wrapper allows to apply a layer to every temporal slice of an input.\n \n-    The input should be at least 3D,\n-    and the dimension of index one will be considered to be\n-    the temporal dimension.\n+    The input should be at least 3D, and the dimension of index one\n+    will be considered to be the temporal dimension.\n \n-    Consider a batch of 32 samples, where each sample is a sequence of 10\n-    vectors of 16 dimensions. The batch input shape of the layer is then `(32, 10, 16)`\n-    (and the `input_shape`, not including the samples dimension, is `(10, 16)`).\n+    Consider a batch of 32 samples,\n+    where each sample is a sequence of 10 vectors of 16 dimensions.\n+    The batch input shape of the layer is then `(32, 10, 16)`,\n+    and the `input_shape`, not including the samples dimension, is `(10, 16)`.\n+\n+    You can then use `TimeDistributed` to apply a `Dense` layer\n+    to each of the 10 timesteps, independently:\n \n-    You can then use `TimeDistributed` to apply a `Dense` layer to each of the 10 timesteps, independently:\n     ```python\n         # as the first layer in a model\n         model = Sequential()\n@@ -66,14 +67,16 @@ class TimeDistributed(Wrapper):\n \n     The output will then have shape `(32, 10, 8)`.\n \n-    Note this is strictly equivalent to using `layers.core.TimeDistributedDense`.\n+    Note this is strictly equivalent to\n+    using `layers.core.TimeDistributedDense`.\n     However what is different about `TimeDistributed`\n     is that it can be used with arbitrary layers, not just `Dense`,\n     for instance with a `Convolution2D` layer:\n \n     ```python\n         model = Sequential()\n-        model.add(TimeDistributed(Convolution2D(64, 3, 3), input_shape=(10, 3, 299, 299)))\n+        model.add(TimeDistributed(Convolution2D(64, 3, 3),\n+                                  input_shape=(10, 3, 299, 299)))\n     ```\n \n     # Arguments\n@@ -99,15 +102,15 @@ class TimeDistributed(Wrapper):\n         timesteps = input_shape[1]\n         return (child_output_shape[0], timesteps) + child_output_shape[1:]\n \n-    def call(self, X, mask=None):\n-        input_shape = K.int_shape(X)\n+    def call(self, inputs, mask=None):\n+        input_shape = K.int_shape(inputs)\n         if input_shape[0]:\n             # batch size matters, use rnn-based implementation\n-            def step(x, states):\n+            def step(x, _):\n                 output = self.layer.call(x)\n                 return output, []\n \n-            _, outputs, _ = K.rnn(step, X,\n+            _, outputs, _ = K.rnn(step, inputs,\n                                   initial_states=[],\n                                   input_length=input_shape[1],\n                                   unroll=False)\n@@ -118,17 +121,19 @@ class TimeDistributed(Wrapper):\n             # we can go with reshape-based implementation for performance\n             input_length = input_shape[1]\n             if not input_length:\n-                input_length = K.shape(X)[1]\n-            X = K.reshape(X, (-1,) + input_shape[2:])  # (nb_samples * timesteps, ...)\n-            y = self.layer.call(X)  # (nb_samples * timesteps, ...)\n+                input_length = K.shape(inputs)[1]\n+            # (nb_samples * timesteps, ...)\n+            inputs = K.reshape(inputs, (-1,) + input_shape[2:])\n+            y = self.layer.call(inputs)  # (nb_samples * timesteps, ...)\n             # (nb_samples, timesteps, ...)\n             output_shape = self.get_output_shape_for(input_shape)\n             y = K.reshape(y, (-1, input_length) + output_shape[2:])\n \n         # Apply activity regularizer if any:\n-        if hasattr(self.layer, 'activity_regularizer') and self.layer.activity_regularizer is not None:\n+        if (hasattr(self.layer, 'activity_regularizer') and\n+           self.layer.activity_regularizer is not None):\n             regularization_loss = self.layer.activity_regularizer(y)\n-            self.add_loss(regularization_loss, X)\n+            self.add_loss(regularization_loss, inputs)\n         return y\n \n \n@@ -194,21 +199,21 @@ class Bidirectional(Wrapper):\n         elif self.merge_mode is None:\n             return [self.forward_layer.get_output_shape_for(input_shape)] * 2\n \n-    def call(self, X, mask=None):\n-        Y = self.forward_layer.call(X, mask)\n-        Y_rev = self.backward_layer.call(X, mask)\n+    def call(self, inputs, mask=None):\n+        y = self.forward_layer.call(inputs, mask)\n+        y_rev = self.backward_layer.call(inputs, mask)\n         if self.return_sequences:\n-            Y_rev = K.reverse(Y_rev, 1)\n+            y_rev = K.reverse(y_rev, 1)\n         if self.merge_mode == 'concat':\n-            return K.concatenate([Y, Y_rev])\n+            return K.concatenate([y, y_rev])\n         elif self.merge_mode == 'sum':\n-            return Y + Y_rev\n+            return y + y_rev\n         elif self.merge_mode == 'ave':\n-            return (Y + Y_rev) / 2\n+            return (y + y_rev) / 2\n         elif self.merge_mode == 'mul':\n-            return Y * Y_rev\n+            return y * y_rev\n         elif self.merge_mode is None:\n-            return [Y, Y_rev]\n+            return [y, y_rev]\n \n     def reset_states(self):\n         self.forward_layer.reset_states()\n@@ -230,13 +235,15 @@ class Bidirectional(Wrapper):\n     @property\n     def trainable_weights(self):\n         if hasattr(self.forward_layer, 'trainable_weights'):\n-            return self.forward_layer.trainable_weights + self.backward_layer.trainable_weights\n+            return (self.forward_layer.trainable_weights +\n+                    self.backward_layer.trainable_weights)\n         return []\n \n     @property\n     def non_trainable_weights(self):\n         if hasattr(self.forward_layer, 'non_trainable_weights'):\n-            return self.forward_layer.non_trainable_weights + self.backward_layer.non_trainable_weights\n+            return (self.forward_layer.non_trainable_weights +\n+                    self.backward_layer.non_trainable_weights)\n         return []\n \n     @property\n@@ -253,11 +260,11 @@ class Bidirectional(Wrapper):\n \n     @property\n     def constraints(self):\n-        _constraints = {}\n+        constraints = {}\n         if hasattr(self.forward_layer, 'constraints'):\n-            _constraints.update(self.forward_layer.constraints)\n-            _constraints.update(self.backward_layer.constraints)\n-        return _constraints\n+            constraints.update(self.forward_layer.constraints)\n+            constraints.update(self.backward_layer.constraints)\n+        return constraints\n \n     def get_config(self):\n         config = {\"merge_mode\": self.merge_mode}\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3a7cd05b488e327c1adccaaff10c78390d53b5a8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 61 | Lines Deleted: 13 | Files Changed: 6 | Hunks: 24 | Methods Changed: 12 | Complexity Δ (Sum/Max): 18/3 | Churn Δ: 74 | Churn Cumulative: 1624 | Contributors (this commit): 4 | Commits (past 90d): 37 | Contributors (cumulative): 18 | DMM Complexity: 0.0\n\nDIFF:\n@@ -61,7 +61,8 @@ def conv2d_bn(x, nb_filter, nb_row, nb_col,\n \n \n def InceptionV3(include_top=True, weights='imagenet',\n-                input_tensor=None, input_shape=None):\n+                input_tensor=None, input_shape=None,\n+                classes=1000):\n     \"\"\"Instantiate the Inception v3 architecture,\n     optionally loading weights pre-trained\n     on ImageNet. Note that when using TensorFlow,\n@@ -90,6 +91,9 @@ def InceptionV3(include_top=True, weights='imagenet',\n             It should have exactly 3 inputs channels,\n             and width and height should be no smaller than 139.\n             E.g. `(150, 150, 3)` would be one valid value.\n+        classes: optional number of classes to classify images\n+            into, only to be specified if `include_top` is True, and\n+            if no `weights` argument is specified.\n \n     # Returns\n         A Keras model instance.\n@@ -98,6 +102,11 @@ def InceptionV3(include_top=True, weights='imagenet',\n         raise ValueError('The `weights` argument should be either '\n                          '`None` (random initialization) or `imagenet` '\n                          '(pre-training on ImageNet).')\n+\n+    if weights == 'imagenet' and include_top and classes != 1000:\n+        raise ValueError('If using `weights` as imagenet with `include_top`'\n+                         ' as true, `classes` should be 1000')\n+\n     # Determine proper input shape\n     input_shape = _obtain_input_shape(input_shape,\n                                       default_size=299,\n@@ -262,7 +271,7 @@ def InceptionV3(include_top=True, weights='imagenet',\n         # Classification block\n         x = AveragePooling2D((8, 8), strides=(8, 8), name='avg_pool')(x)\n         x = Flatten(name='flatten')(x)\n-        x = Dense(1000, activation='softmax', name='predictions')(x)\n+        x = Dense(classes, activation='softmax', name='predictions')(x)\n \n     # Ensure that the model takes into account\n     # any potential predecessors of `input_tensor`.\n\n@@ -28,7 +28,7 @@ TF_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/dow\n \n \n def MusicTaggerCRNN(weights='msd', input_tensor=None,\n-                    include_top=True):\n+                    include_top=True, classes=50):\n     \"\"\"Instantiate the MusicTaggerCRNN architecture,\n     optionally loading weights pre-trained\n     on Million Song Dataset. Note that when using TensorFlow,\n@@ -54,7 +54,9 @@ def MusicTaggerCRNN(weights='msd', input_tensor=None,\n         include_top: whether to include the 1 fully-connected\n             layer (output layer) at the top of the network.\n             If False, the network outputs 32-dim features.\n-\n+        classes: optional number of classes to classify images\n+            into, only to be specified if `include_top` is True, and\n+            if no `weights` argument is specified.\n \n     # Returns\n         A Keras model instance.\n@@ -64,6 +66,9 @@ def MusicTaggerCRNN(weights='msd', input_tensor=None,\n                          '`None` (random initialization) or `msd` '\n                          '(pre-training on Million Song Dataset).')\n \n+    if weights == 'msd' and include_top and classes != 50:\n+        raise ValueError('If using `weights` as msd with `include_top`'\n+                         ' as true, `classes` should be 50')\n     # Determine proper input shape\n     if K.image_dim_ordering() == 'th':\n         input_shape = (1, 96, 1366)\n@@ -126,7 +131,7 @@ def MusicTaggerCRNN(weights='msd', input_tensor=None,\n     x = GRU(32, return_sequences=False, name='gru2')(x)\n \n     if include_top:\n-        x = Dense(50, activation='sigmoid', name='output')(x)\n+        x = Dense(classes, activation='sigmoid', name='output')(x)\n \n     # Ensure that the model takes into account\n     # any potential predecessors of `input_tensor`.\n\n@@ -109,7 +109,8 @@ def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2))\n \n \n def ResNet50(include_top=True, weights='imagenet',\n-             input_tensor=None, input_shape=None):\n+             input_tensor=None, input_shape=None,\n+             classes=1000):\n     \"\"\"Instantiate the ResNet50 architecture,\n     optionally loading weights pre-trained\n     on ImageNet. Note that when using TensorFlow,\n@@ -136,6 +137,9 @@ def ResNet50(include_top=True, weights='imagenet',\n             It should have exactly 3 inputs channels,\n             and width and height should be no smaller than 197.\n             E.g. `(200, 200, 3)` would be one valid value.\n+        classes: optional number of classes to classify images\n+            into, only to be specified if `include_top` is True, and\n+            if no `weights` argument is specified.\n \n     # Returns\n         A Keras model instance.\n@@ -144,6 +148,11 @@ def ResNet50(include_top=True, weights='imagenet',\n         raise ValueError('The `weights` argument should be either '\n                          '`None` (random initialization) or `imagenet` '\n                          '(pre-training on ImageNet).')\n+\n+    if weights == 'imagenet' and include_top and classes != 1000:\n+        raise ValueError('If using `weights` as imagenet with `include_top`'\n+                         ' as true, `classes` should be 1000')\n+\n     # Determine proper input shape\n     input_shape = _obtain_input_shape(input_shape,\n                                       default_size=224,\n@@ -193,7 +202,7 @@ def ResNet50(include_top=True, weights='imagenet',\n \n     if include_top:\n         x = Flatten()(x)\n-        x = Dense(1000, activation='softmax', name='fc1000')(x)\n+        x = Dense(classes, activation='softmax', name='fc1000')(x)\n \n     # Ensure that the model takes into account\n     # any potential predecessors of `input_tensor`.\n\n@@ -28,7 +28,8 @@ TF_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/relea\n \n \n def VGG16(include_top=True, weights='imagenet',\n-          input_tensor=None, input_shape=None):\n+          input_tensor=None, input_shape=None,\n+          classes=1000):\n     \"\"\"Instantiate the VGG16 architecture,\n     optionally loading weights pre-trained\n     on ImageNet. Note that when using TensorFlow,\n@@ -55,6 +56,9 @@ def VGG16(include_top=True, weights='imagenet',\n             It should have exactly 3 inputs channels,\n             and width and height should be no smaller than 48.\n             E.g. `(200, 200, 3)` would be one valid value.\n+        classes: optional number of classes to classify images\n+            into, only to be specified if `include_top` is True, and\n+            if no `weights` argument is specified.\n \n     # Returns\n         A Keras model instance.\n@@ -63,6 +67,10 @@ def VGG16(include_top=True, weights='imagenet',\n         raise ValueError('The `weights` argument should be either '\n                          '`None` (random initialization) or `imagenet` '\n                          '(pre-training on ImageNet).')\n+\n+    if weights == 'imagenet' and include_top and classes != 1000:\n+        raise ValueError('If using `weights` as imagenet with `include_top`'\n+                         ' as true, `classes` should be 1000')\n     # Determine proper input shape\n     input_shape = _obtain_input_shape(input_shape,\n                                       default_size=224,\n@@ -110,7 +118,7 @@ def VGG16(include_top=True, weights='imagenet',\n         x = Flatten(name='flatten')(x)\n         x = Dense(4096, activation='relu', name='fc1')(x)\n         x = Dense(4096, activation='relu', name='fc2')(x)\n-        x = Dense(1000, activation='softmax', name='predictions')(x)\n+        x = Dense(classes, activation='softmax', name='predictions')(x)\n \n     # Ensure that the model takes into account\n     # any potential predecessors of `input_tensor`.\n\n@@ -28,7 +28,8 @@ TF_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/relea\n \n \n def VGG19(include_top=True, weights='imagenet',\n-          input_tensor=None, input_shape=None):\n+          input_tensor=None, input_shape=None,\n+          classes=1000):\n     \"\"\"Instantiate the VGG19 architecture,\n     optionally loading weights pre-trained\n     on ImageNet. Note that when using TensorFlow,\n@@ -55,6 +56,9 @@ def VGG19(include_top=True, weights='imagenet',\n             It should have exactly 3 inputs channels,\n             and width and height should be no smaller than 48.\n             E.g. `(200, 200, 3)` would be one valid value.\n+        classes: optional number of classes to classify images\n+            into, only to be specified if `include_top` is True, and\n+            if no `weights` argument is specified.\n \n     # Returns\n         A Keras model instance.\n@@ -63,6 +67,10 @@ def VGG19(include_top=True, weights='imagenet',\n         raise ValueError('The `weights` argument should be either '\n                          '`None` (random initialization) or `imagenet` '\n                          '(pre-training on ImageNet).')\n+\n+    if weights == 'imagenet' and include_top and classes != 1000:\n+        raise ValueError('If using `weights` as imagenet with `include_top`'\n+                         ' as true, `classes` should be 1000')\n     # Determine proper input shape\n     input_shape = _obtain_input_shape(input_shape,\n                                       default_size=224,\n@@ -113,7 +121,7 @@ def VGG19(include_top=True, weights='imagenet',\n         x = Flatten(name='flatten')(x)\n         x = Dense(4096, activation='relu', name='fc1')(x)\n         x = Dense(4096, activation='relu', name='fc2')(x)\n-        x = Dense(1000, activation='softmax', name='predictions')(x)\n+        x = Dense(classes, activation='softmax', name='predictions')(x)\n \n     # Ensure that the model takes into account\n     # any potential predecessors of `input_tensor`.\n\n@@ -36,7 +36,8 @@ TF_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/relea\n \n \n def Xception(include_top=True, weights='imagenet',\n-             input_tensor=None, input_shape=None):\n+             input_tensor=None, input_shape=None,\n+             classes=1000):\n     \"\"\"Instantiate the Xception architecture,\n     optionally loading weights pre-trained\n     on ImageNet. This model is available for TensorFlow only,\n@@ -60,6 +61,9 @@ def Xception(include_top=True, weights='imagenet',\n             It should have exactly 3 inputs channels,\n             and width and height should be no smaller than 71.\n             E.g. `(150, 150, 3)` would be one valid value.\n+        classes: optional number of classes to classify images\n+            into, only to be specified if `include_top` is True, and\n+            if no `weights` argument is specified.\n \n     # Returns\n         A Keras model instance.\n@@ -68,6 +72,11 @@ def Xception(include_top=True, weights='imagenet',\n         raise ValueError('The `weights` argument should be either '\n                          '`None` (random initialization) or `imagenet` '\n                          '(pre-training on ImageNet).')\n+\n+    if weights == 'imagenet' and include_top and classes != 1000:\n+        raise ValueError('If using `weights` as imagenet with `include_top`'\n+                         ' as true, `classes` should be 1000')\n+\n     if K.backend() != 'tensorflow':\n         raise RuntimeError('The Xception model is only available with '\n                            'the TensorFlow backend.')\n@@ -189,7 +198,7 @@ def Xception(include_top=True, weights='imagenet',\n \n     if include_top:\n         x = GlobalAveragePooling2D(name='avg_pool')(x)\n-        x = Dense(1000, activation='softmax', name='predictions')(x)\n+        x = Dense(classes, activation='softmax', name='predictions')(x)\n \n     # Ensure that the model takes into account\n     # any potential predecessors of `input_tensor`.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3d176e926f848c5aacd036d6095ab015a2f8cc83", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 55 | Lines Deleted: 26 | Files Changed: 8 | Hunks: 16 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 81 | Churn Cumulative: 24257 | Contributors (this commit): 101 | Commits (past 90d): 90 | Contributors (cumulative): 146 | DMM Complexity: None\n\nDIFF:\n@@ -3,13 +3,22 @@ from __future__ import absolute_import\n import functools\n \n from .. import backend as K\n-from .. import activations, initializations, regularizers, constraints\n-from ..engine import Layer, InputSpec\n-from ..utils.np_utils import conv_output_length, conv_input_length\n+from .. import activations\n+from .. import initializations\n+from .. import regularizers\n+from .. import constraints\n+from ..engine import Layer\n+from ..engine import InputSpec\n+from ..utils.np_utils import conv_output_length\n+from ..utils.np_utils import conv_input_length\n \n # imports for backwards namespace compatibility\n-from .pooling import AveragePooling1D, AveragePooling2D, AveragePooling3D\n-from .pooling import MaxPooling1D, MaxPooling2D, MaxPooling3D\n+from .pooling import AveragePooling1D\n+from .pooling import AveragePooling2D\n+from .pooling import AveragePooling3D\n+from .pooling import MaxPooling1D\n+from .pooling import MaxPooling2D\n+from .pooling import MaxPooling3D\n \n \n class Convolution1D(Layer):\n\n@@ -1,8 +1,11 @@\n from .. import backend as K\n-from .. import activations, initializations, regularizers\n+from .. import activations\n+from .. import initializations\n+from .. import regularizers\n \n import numpy as np\n-from ..engine import Layer, InputSpec\n+from ..engine import Layer\n+from ..engine import InputSpec\n from ..utils.np_utils import conv_output_length\n import warnings\n \n\n@@ -10,10 +10,15 @@ import types as python_types\n import warnings\n \n from .. import backend as K\n-from .. import activations, initializations, regularizers, constraints\n-from ..engine import InputSpec, Layer, Merge\n-from ..regularizers import ActivityRegularizer\n-from ..utils.generic_utils import func_dump, func_load\n+from .. import activations\n+from .. import initializations\n+from .. import regularizers\n+from .. import constraints\n+from ..engine import InputSpec\n+from ..engine import Layer\n+from ..engine import Merge\n+from ..utils.generic_utils import func_dump\n+from ..utils.generic_utils import func_load\n \n \n class Masking(Layer):\n@@ -49,8 +54,8 @@ class Masking(Layer):\n         self.mask_value = mask_value\n         super(Masking, self).__init__(**kwargs)\n \n-    def compute_mask(self, input, input_mask=None):\n-        return K.any(K.not_equal(input, self.mask_value), axis=-1)\n+    def compute_mask(self, x, input_mask=None):\n+        return K.any(K.not_equal(x, self.mask_value), axis=-1)\n \n     def call(self, x, mask=None):\n         boolean_mask = K.any(K.not_equal(x, self.mask_value),\n@@ -317,15 +322,13 @@ class Reshape(Layer):\n         self.target_shape = tuple(target_shape)\n \n     def _fix_unknown_dimension(self, input_shape, output_shape):\n-        \"\"\"Find and replace a single missing dimension in an output shape\n-        given an input shape.\n+        \"\"\"Find and replace a missing dimension in an output shape.\n \n-        A near direct port of the internal Numpy function\n-        _fix_unknown_dimension in numpy/core/src/multiarray/shape.c\n+        This is a near direct port of the internal Numpy function\n+        `_fix_unknown_dimension` in `numpy/core/src/multiarray/shape.c`\n \n         # Arguments\n             input_shape: shape of array being reshaped\n-\n             output_shape: desired shape of the array with at most\n                 a single -1 which indicates a dimension that should be\n                 derived from the input shape.\n@@ -336,6 +339,10 @@ class Reshape(Layer):\n             Raises a ValueError if the total array size of the output_shape is\n             different then the input_shape, or more then one unknown dimension\n             is specified.\n+\n+        # Raises\n+            ValueError: in case of invalid values\n+                for `input_shape` or `input_shape`.\n         \"\"\"\n         output_shape = list(output_shape)\n \n@@ -347,7 +354,7 @@ class Reshape(Layer):\n                 if unknown is None:\n                     unknown = index\n                 else:\n-                    raise ValueError('can only specify one unknown dimension')\n+                    raise ValueError('Can only specify one unknown dimension.')\n             else:\n                 known *= dim\n \n\n@@ -2,8 +2,12 @@\n from __future__ import absolute_import\n \n from keras import backend as K\n-from keras.layers import activations, initializations, regularizers, constraints\n-from keras.engine import Layer, InputSpec\n+from keras.layers import activations\n+from keras.layers import initializations\n+from keras.layers import regularizers\n+from keras.layers import constraints\n+from keras.engine import Layer\n+from keras.engine import InputSpec\n from ..utils.np_utils import conv_output_length\n \n \n\n@@ -2,7 +2,8 @@\n from __future__ import absolute_import\n \n from .. import backend as K\n-from ..engine import Layer, InputSpec\n+from ..engine import Layer\n+from ..engine import InputSpec\n from ..utils.np_utils import conv_output_length\n \n \n\n@@ -3,8 +3,11 @@ from __future__ import absolute_import\n import numpy as np\n \n from .. import backend as K\n-from .. import activations, initializations, regularizers\n-from ..engine import Layer, InputSpec\n+from .. import activations\n+from .. import initializations\n+from .. import regularizers\n+from ..engine import Layer\n+from ..engine import InputSpec\n \n \n def time_distributed_dense(x, w, b=None, dropout=None,\n\n@@ -1,4 +1,5 @@\n-from ..engine import Layer, InputSpec\n+from ..engine import Layer\n+from ..engine import InputSpec\n from .. import backend as K\n \n \n\n@@ -5,7 +5,8 @@ import inspect\n import six\n \n from ..engine import Model, Input\n-from ..models import Sequential, model_from_json\n+from ..models import Sequential\n+from ..models import model_from_json\n from .. import backend as K\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5adce5266f43f89dcf7f14758e5d895fbf6791ef", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 998 | Lines Deleted: 998 | Files Changed: 40 | Hunks: 739 | Methods Changed: 197 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1996 | Churn Cumulative: 42681 | Contributors (this commit): 171 | Commits (past 90d): 300 | Contributors (cumulative): 391 | DMM Complexity: None\n\nDIFF:\n@@ -34,7 +34,7 @@ def deprocess_image(x):\n \n     # convert to RGB array\n     x *= 255\n-    if K.image_dim_ordering() == 'th':\n+    if K.image_data_format() == 'channels_first':\n         x = x.transpose((1, 2, 0))\n     x = np.clip(x, 0, 255).astype('uint8')\n     return x\n@@ -67,7 +67,7 @@ for filter_index in range(0, 200):\n     # we build a loss function that maximizes the activation\n     # of the nth filter of the layer considered\n     layer_output = layer_dict[layer_name].output\n-    if K.image_dim_ordering() == 'th':\n+    if K.image_data_format() == 'channels_first':\n         loss = K.mean(layer_output[:, filter_index, :, :])\n     else:\n         loss = K.mean(layer_output[:, :, :, filter_index])\n@@ -85,7 +85,7 @@ for filter_index in range(0, 200):\n     step = 1.\n \n     # we start from a gray image with some random noise\n-    if K.image_dim_ordering() == 'th':\n+    if K.image_data_format() == 'channels_first':\n         input_img_data = np.random.random((1, 3, img_width, img_height))\n     else:\n         input_img_data = np.random.random((1, img_width, img_height, 3))\n\n@@ -33,7 +33,7 @@ seq.add(BatchNormalization())\n \n seq.add(Convolution3D(nb_filter=1, kernel_dim1=1, kernel_dim2=3,\n                       kernel_dim3=3, activation='sigmoid',\n-                      border_mode='same', dim_ordering='tf'))\n+                      border_mode='same', data_format='channels_last'))\n \n seq.compile(loss='binary_crossentropy', optimizer='adadelta')\n \n\n@@ -74,7 +74,7 @@ def preprocess_image(image_path):\n \n \n def deprocess_image(x):\n-    if K.image_dim_ordering() == 'th':\n+    if K.image_data_format() == 'channels_first':\n         x = x.reshape((3, img_width, img_height))\n         x = x.transpose((1, 2, 0))\n     else:\n@@ -88,7 +88,7 @@ def deprocess_image(x):\n     x = np.clip(x, 0, 255).astype('uint8')\n     return x\n \n-if K.image_dim_ordering() == 'th':\n+if K.image_data_format() == 'channels_first':\n     img_size = (3, img_width, img_height)\n else:\n     img_size = (img_width, img_height, 3)\n@@ -109,7 +109,7 @@ layer_dict = dict([(layer.name, layer) for layer in model.layers])\n \n def continuity_loss(x):\n     assert K.ndim(x) == 4\n-    if K.image_dim_ordering() == 'th':\n+    if K.image_data_format() == 'channels_first':\n         a = K.square(x[:, :, :img_width - 1, :img_height - 1] -\n                      x[:, :, 1:, :img_height - 1])\n         b = K.square(x[:, :, :img_width - 1, :img_height - 1] -\n@@ -130,7 +130,7 @@ for layer_name in settings['features']:\n     x = layer_dict[layer_name].output\n     shape = layer_dict[layer_name].output_shape\n     # we avoid border artifacts by only involving non-border pixels in the loss\n-    if K.image_dim_ordering() == 'th':\n+    if K.image_data_format() == 'channels_first':\n         loss -= coeff * K.sum(K.square(x[:, :, 2: shape[2] - 2, 2: shape[3] - 2])) / np.prod(shape[1:])\n     else:\n         loss -= coeff * K.sum(K.square(x[:, 2: shape[1] - 2, 2: shape[2] - 2, :])) / np.prod(shape[1:])\n\n@@ -235,7 +235,7 @@ class TextImageGenerator(keras.callbacks.Callback):\n     def get_batch(self, index, size, train):\n         # width and height are backwards from typical Keras convention\n         # because width is the time dimension when it gets fed into the RNN\n-        if K.image_dim_ordering() == 'th':\n+        if K.image_data_format() == 'channels_first':\n             X_data = np.ones([size, 1, self.img_w, self.img_h])\n         else:\n             X_data = np.ones([size, self.img_w, self.img_h, 1])\n@@ -248,7 +248,7 @@ class TextImageGenerator(keras.callbacks.Callback):\n             # Mix in some blank inputs.  This seems to be important for\n             # achieving translational invariance\n             if train and i > size - 4:\n-                if K.image_dim_ordering() == 'th':\n+                if K.image_data_format() == 'channels_first':\n                     X_data[i, 0, 0:self.img_w, :] = self.paint_func('')[0, :, :].T\n                 else:\n                     X_data[i, 0:self.img_w, :, 0] = self.paint_func('',)[0, :, :].T\n@@ -257,7 +257,7 @@ class TextImageGenerator(keras.callbacks.Callback):\n                 label_length[i] = 1\n                 source_str.append('')\n             else:\n-                if K.image_dim_ordering() == 'th':\n+                if K.image_data_format() == 'channels_first':\n                     X_data[i, 0, 0:self.img_w, :] = self.paint_func(self.X_text[index + i])[0, :, :].T\n                 else:\n                     X_data[i, 0:self.img_w, :, 0] = self.paint_func(self.X_text[index + i])[0, :, :].T\n@@ -383,7 +383,7 @@ class VizCallback(keras.callbacks.Callback):\n             cols = 1\n         for i in range(self.num_display_words):\n             pylab.subplot(self.num_display_words // cols, cols, i + 1)\n-            if K.image_dim_ordering() == 'th':\n+            if K.image_data_format() == 'channels_first':\n                 the_input = word_batch['the_input'][i, 0, :, :]\n             else:\n                 the_input = word_batch['the_input'][i, :, :, 0]\n@@ -409,7 +409,7 @@ def train(run_name, start_epoch, stop_epoch, img_w):\n     time_dense_size = 32\n     rnn_size = 512\n \n-    if K.image_dim_ordering() == 'th':\n+    if K.image_data_format() == 'channels_first':\n         input_shape = (1, img_w, img_h)\n     else:\n         input_shape = (img_w, img_h, 1)\n\n@@ -43,7 +43,7 @@ import numpy as np\n \n np.random.seed(1337)\n \n-K.set_image_dim_ordering('th')\n+K.set_image_data_format('channels_first')\n \n \n def build_generator(latent_size):\n\n@@ -32,7 +32,7 @@ kernel_size = (3, 3)\n # the data, shuffled and split between train and test sets\n (X_train, y_train), (X_test, y_test) = mnist.load_data()\n \n-if K.image_dim_ordering() == 'th':\n+if K.image_data_format() == 'channels_first':\n     X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n     X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n     input_shape = (1, img_rows, img_cols)\n\n@@ -44,7 +44,7 @@ Experiments\n     when a Dropout layer is used.\n \n Results\n-- Tested with 'Theano' backend and 'th' image_dim_ordering.\n+- Tested with 'Theano' backend and 'channels_first' image_data_format.\n - Running on GPU GeForce GTX 980M\n - Performance Comparisons - validation loss values during first 3 epochs:\n (1) teacher_model:             0.075    0.041    0.041\n\n@@ -82,8 +82,8 @@ if K.backend() == 'tensorflow':\n                        'of a gradient, which isn\\'t '\r\n                        'supported for all TF ops.')\r\n \r\n-# This example assume 'th' dim ordering.\r\n-K.set_image_dim_ordering('th')\r\n+# This example assume 'channels_first' data format.\r\n+K.set_image_data_format('channels_first')\r\n \r\n # input image dimensions\r\n img_rows, img_cols = 28, 28\r\n\n@@ -39,7 +39,7 @@ pool_size = 2\n # convolution kernel size\n kernel_size = 3\n \n-if K.image_dim_ordering() == 'th':\n+if K.image_data_format() == 'channels_first':\n     input_shape = (1, img_rows, img_cols)\n else:\n     input_shape = (img_rows, img_cols, 1)\n\n@@ -103,7 +103,7 @@ def preprocess_image(image_path):\n \r\n \r\n def deprocess_image(x):\r\n-    if K.image_dim_ordering() == 'th':\r\n+    if K.image_data_format() == 'channels_first':\r\n         x = x.reshape((3, img_nrows, img_ncols))\r\n         x = x.transpose((1, 2, 0))\r\n     else:\r\n@@ -132,7 +132,7 @@ def kmeans(xs, k):\n def load_mask_labels():\r\n     '''Load both target and style masks.\r\n     A mask image (nr x nc) with m labels/colors will be loaded\r\n-    as a 4D boolean tensor: (1, m, nr, nc) for 'th' or (1, nr, nc, m) for 'tf'\r\n+    as a 4D boolean tensor: (1, m, nr, nc) for 'channels_first' or (1, nr, nc, m) for 'channels_last'\r\n     '''\r\n     target_mask_img = load_img(target_mask_path,\r\n                                target_size=(img_nrows, img_ncols))\r\n@@ -140,7 +140,7 @@ def load_mask_labels():\n     style_mask_img = load_img(style_mask_path,\r\n                               target_size=(img_nrows, img_ncols))\r\n     style_mask_img = img_to_array(style_mask_img)\r\n-    if K.image_dim_ordering() == 'th':\r\n+    if K.image_data_format() == 'channels_first':\r\n         mask_vecs = np.vstack([style_mask_img.reshape((3, -1)).T,\r\n                                target_mask_img.reshape((3, -1)).T])\r\n     else:\r\n@@ -153,7 +153,7 @@ def load_mask_labels():\n     target_mask_label = labels[img_nrows *\r\n                                img_ncols:].reshape((img_nrows, img_ncols))\r\n \r\n-    stack_axis = 0 if K.image_dim_ordering() == 'th' else -1\r\n+    stack_axis = 0 if K.image_data_format() == 'channels_first' else -1\r\n     style_mask = np.stack([style_mask_label == r for r in xrange(nb_labels)],\r\n                           axis=stack_axis)\r\n     target_mask = np.stack([target_mask_label == r for r in xrange(nb_labels)],\r\n@@ -163,7 +163,7 @@ def load_mask_labels():\n             np.expand_dims(target_mask, axis=0))\r\n \r\n # Create tensor variables for images\r\n-if K.image_dim_ordering() == 'th':\r\n+if K.image_data_format() == 'channels_first':\r\n     shape = (1, nb_colors, img_nrows, img_ncols)\r\n else:\r\n     shape = (1, img_nrows, img_ncols, nb_colors)\r\n@@ -228,7 +228,7 @@ def region_style_loss(style_image, target_image, style_mask, target_mask):\n     '''\r\n     assert 3 == K.ndim(style_image) == K.ndim(target_image)\r\n     assert 2 == K.ndim(style_mask) == K.ndim(target_mask)\r\n-    if K.image_dim_ordering() == 'th':\r\n+    if K.image_data_format() == 'channels_first':\r\n         masked_style = style_image * style_mask\r\n         masked_target = target_image * target_mask\r\n         nb_channels = K.shape(style_image)[0]\r\n@@ -251,7 +251,7 @@ def style_loss(style_image, target_image, style_masks, target_masks):\n     assert 3 == K.ndim(style_masks) == K.ndim(target_masks)\r\n     loss = K.variable(0)\r\n     for i in xrange(nb_labels):\r\n-        if K.image_dim_ordering() == 'th':\r\n+        if K.image_data_format() == 'channels_first':\r\n             style_mask = style_masks[i, :, :]\r\n             target_mask = target_masks[i, :, :]\r\n         else:\r\n@@ -268,7 +268,7 @@ def content_loss(content_image, target_image):\n \r\n def total_variation_loss(x):\r\n     assert 4 == K.ndim(x)\r\n-    if K.image_dim_ordering() == 'th':\r\n+    if K.image_data_format() == 'channels_first':\r\n         a = K.square(x[:, :, :img_nrows - 1, :img_ncols - 1] -\r\n                      x[:, :, 1:, :img_ncols - 1])\r\n         b = K.square(x[:, :, :img_nrows - 1, :img_ncols - 1] -\r\n@@ -310,7 +310,7 @@ f_outputs = K.function([target_image], outputs)\n \r\n \r\n def eval_loss_and_grads(x):\r\n-    if K.image_dim_ordering() == 'th':\r\n+    if K.image_data_format() == 'channels_first':\r\n         x = x.reshape((1, 3, img_nrows, img_ncols))\r\n     else:\r\n         x = x.reshape((1, img_nrows, img_ncols, 3))\r\n@@ -346,7 +346,7 @@ class Evaluator(object):\n evaluator = Evaluator()\r\n \r\n # Generate images by iterative optimization\r\n-if K.image_dim_ordering() == 'th':\r\n+if K.image_data_format() == 'channels_first':\r\n     x = np.random.uniform(0, 255, (1, 3, img_nrows, img_ncols)) - 128.\r\n else:\r\n     x = np.random.uniform(0, 255, (1, img_nrows, img_ncols, 3)) - 128.\r\n\n@@ -106,7 +106,7 @@ def preprocess_image(image_path):\n \n \n def deprocess_image(x):\n-    if K.image_dim_ordering() == 'th':\n+    if K.image_data_format() == 'channels_first':\n         x = x.reshape((3, img_nrows, img_ncols))\n         x = x.transpose((1, 2, 0))\n     else:\n@@ -125,7 +125,7 @@ base_image = K.variable(preprocess_image(base_image_path))\n style_reference_image = K.variable(preprocess_image(style_reference_image_path))\n \n # this will contain our generated image\n-if K.image_dim_ordering() == 'th':\n+if K.image_data_format() == 'channels_first':\n     combination_image = K.placeholder((1, 3, img_nrows, img_ncols))\n else:\n     combination_image = K.placeholder((1, img_nrows, img_ncols, 3))\n@@ -152,7 +152,7 @@ outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n \n def gram_matrix(x):\n     assert K.ndim(x) == 3\n-    if K.image_dim_ordering() == 'th':\n+    if K.image_data_format() == 'channels_first':\n         features = K.batch_flatten(x)\n     else:\n         features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n@@ -189,7 +189,7 @@ def content_loss(base, combination):\n \n def total_variation_loss(x):\n     assert K.ndim(x) == 4\n-    if K.image_dim_ordering() == 'th':\n+    if K.image_data_format() == 'channels_first':\n         a = K.square(x[:, :, :img_nrows - 1, :img_ncols - 1] - x[:, :, 1:, :img_ncols - 1])\n         b = K.square(x[:, :, :img_nrows - 1, :img_ncols - 1] - x[:, :, :img_nrows - 1, 1:])\n     else:\n@@ -229,7 +229,7 @@ f_outputs = K.function([combination_image], outputs)\n \n \n def eval_loss_and_grads(x):\n-    if K.image_dim_ordering() == 'th':\n+    if K.image_data_format() == 'channels_first':\n         x = x.reshape((1, 3, img_nrows, img_ncols))\n     else:\n         x = x.reshape((1, img_nrows, img_ncols, 3))\n@@ -273,7 +273,7 @@ evaluator = Evaluator()\n \n # run scipy-based optimization (L-BFGS) over the pixels of the generated image\n # so as to minimize the neural style loss\n-if K.image_dim_ordering() == 'th':\n+if K.image_data_format() == 'channels_first':\n     x = np.random.uniform(0, 255, (1, 3, img_nrows, img_ncols)) - 128.\n else:\n     x = np.random.uniform(0, 255, (1, img_nrows, img_ncols, 3)) - 128.\n\n@@ -22,7 +22,7 @@ nb_filters = 64\n nb_conv = 3\n \n batch_size = 100\n-if K.image_dim_ordering() == 'th':\n+if K.image_data_format() == 'channels_first':\n     original_img_size = (img_chns, img_rows, img_cols)\n else:\n     original_img_size = (img_rows, img_cols, img_chns)\n@@ -63,7 +63,7 @@ z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n decoder_hid = Dense(intermediate_dim, activation='relu')\n decoder_upsample = Dense(nb_filters * 14 * 14, activation='relu')\n \n-if K.image_dim_ordering() == 'th':\n+if K.image_data_format() == 'channels_first':\n     output_shape = (batch_size, nb_filters, 14, 14)\n else:\n     output_shape = (batch_size, 14, 14, nb_filters)\n@@ -79,7 +79,7 @@ decoder_deconv_2 = Deconvolution2D(nb_filters, nb_conv, nb_conv,\n                                    border_mode='same',\n                                    subsample=(1, 1),\n                                    activation='relu')\n-if K.image_dim_ordering() == 'th':\n+if K.image_data_format() == 'channels_first':\n     output_shape = (batch_size, nb_filters, 29, 29)\n else:\n     output_shape = (batch_size, 29, 29, nb_filters)\n\n@@ -20,12 +20,12 @@ TAGS = ['rock', 'pop', 'alternative', 'indie', 'electronic',\n         'sad', 'House', 'happy']\n \n \n-def preprocess_input(audio_path, dim_ordering='default'):\n+def preprocess_input(audio_path, data_format='default'):\n     \"\"\"Reads an audio file and outputs a Mel-spectrogram.\n \n     # Arguments\n         audio_path: path to the target audio file.\n-        dim_ordering: data format for the output spectrogram image.\n+        data_format: data format for the output spectrogram image.\n \n     # Returns\n         3D Numpy tensor encoding the Mel-spectrogram.\n@@ -33,9 +33,9 @@ def preprocess_input(audio_path, dim_ordering='default'):\n     # Raises\n         ImportError: if librosa is not available.\n     \"\"\"\n-    if dim_ordering == 'default':\n-        dim_ordering = K.image_dim_ordering()\n-    assert dim_ordering in {'tf', 'th'}\n+    if data_format == 'default':\n+        data_format = K.image_data_format()\n+    assert data_format in {'channels_last', 'channels_first'}\n \n     if librosa is None:\n         raise ImportError('Librosa is required to process audio files. '\n@@ -66,9 +66,9 @@ def preprocess_input(audio_path, dim_ordering='default'):\n                       n_fft=n_fft, n_mels=n_mels) ** 2,\n               ref_power=1.0)\n \n-    if dim_ordering == 'th':\n+    if data_format == 'channels_first':\n         x = np.expand_dims(x, axis=0)\n-    elif dim_ordering == 'tf':\n+    elif data_format == 'channels_last':\n         x = np.expand_dims(x, axis=3)\n     return x\n \n\n@@ -8,21 +8,21 @@ CLASS_INDEX = None\n CLASS_INDEX_PATH = 'https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json'\n \n \n-def preprocess_input(x, dim_ordering='default'):\n+def preprocess_input(x, data_format='default'):\n     \"\"\"Preprocesses a tensor encoding a batch of images.\n \n     # Arguments\n         x: input Numpy tensor, 4D.\n-        dim_ordering: data format of the image tensor.\n+        data_format: data format of the image tensor.\n \n     # Returns\n         Preprocessed tensor.\n     \"\"\"\n-    if dim_ordering == 'default':\n-        dim_ordering = K.image_dim_ordering()\n-    assert dim_ordering in {'tf', 'th'}\n+    if data_format == 'default':\n+        data_format = K.image_data_format()\n+    assert data_format in {'channels_last', 'channels_first'}\n \n-    if dim_ordering == 'th':\n+    if data_format == 'channels_first':\n         # 'RGB'->'BGR'\n         x = x[:, ::-1, :, :]\n         # Zero-center by mean pixel\n@@ -78,7 +78,7 @@ def decode_predictions(preds, top=5):\n def _obtain_input_shape(input_shape,\n                         default_size,\n                         min_size,\n-                        dim_ordering,\n+                        data_format,\n                         include_top):\n     \"\"\"Internal utility to compute/validate an ImageNet model's input shape.\n \n@@ -87,7 +87,7 @@ def _obtain_input_shape(input_shape,\n             or a user-provided shape to be validated.\n         default_size: default input width/height for the model.\n         min_size: minimum input width/height accepted by the model.\n-        dim_ordering: image data format to use.\n+        data_format: image data format to use.\n         include_top: whether the model is expected to\n             be linked to a classifier via a Flatten layer.\n \n@@ -97,7 +97,7 @@ def _obtain_input_shape(input_shape,\n     # Raises\n         ValueError: in case of invalid argument values.\n     \"\"\"\n-    if dim_ordering == 'th':\n+    if data_format == 'channels_first':\n         default_shape = (3, default_size, default_size)\n     else:\n         default_shape = (default_size, default_size, 3)\n@@ -108,7 +108,7 @@ def _obtain_input_shape(input_shape,\n                                  '`input_shape` should be ' + str(default_shape) + '.')\n         input_shape = default_shape\n     else:\n-        if dim_ordering == 'th':\n+        if data_format == 'channels_first':\n             if input_shape is not None:\n                 if len(input_shape) != 3:\n                     raise ValueError('`input_shape` must be a tuple of three integers.')\n\n@@ -47,7 +47,7 @@ def conv2d_bn(x, nb_filter, nb_row, nb_col,\n     else:\n         bn_name = None\n         conv_name = None\n-    if K.image_dim_ordering() == 'th':\n+    if K.image_data_format() == 'channels_first':\n         bn_axis = 1\n     else:\n         bn_axis = 3\n@@ -67,11 +67,11 @@ def InceptionV3(include_top=True, weights='imagenet',\n     optionally loading weights pre-trained\n     on ImageNet. Note that when using TensorFlow,\n     for best performance you should set\n-    `image_dim_ordering=\"tf\"` in your Keras config\n+    `image_data_format=\"channels_last\"` in your Keras config\n     at ~/.keras/keras.json.\n \n     The model and the weights are compatible with both\n-    TensorFlow and Theano. The dimension ordering\n+    TensorFlow and Theano. The data format\n     convention used by the model is the one\n     specified in your Keras config file.\n \n@@ -86,8 +86,8 @@ def InceptionV3(include_top=True, weights='imagenet',\n             to use as image input for the model.\n         input_shape: optional shape tuple, only to be specified\n             if `include_top` is False (otherwise the input shape\n-            has to be `(299, 299, 3)` (with `tf` dim ordering)\n-            or `(3, 299, 299)` (with `th` dim ordering).\n+            has to be `(299, 299, 3)` (with `channels_last` data format)\n+            or `(3, 299, 299)` (with `channels_first` data format).\n             It should have exactly 3 inputs channels,\n             and width and height should be no smaller than 139.\n             E.g. `(150, 150, 3)` would be one valid value.\n@@ -111,7 +111,7 @@ def InceptionV3(include_top=True, weights='imagenet',\n     input_shape = _obtain_input_shape(input_shape,\n                                       default_size=299,\n                                       min_size=139,\n-                                      dim_ordering=K.image_dim_ordering(),\n+                                      data_format=K.image_data_format(),\n                                       include_top=include_top)\n \n     if input_tensor is None:\n@@ -122,7 +122,7 @@ def InceptionV3(include_top=True, weights='imagenet',\n         else:\n             img_input = input_tensor\n \n-    if K.image_dim_ordering() == 'th':\n+    if K.image_data_format() == 'channels_first':\n         channel_axis = 1\n     else:\n         channel_axis = 3\n@@ -284,7 +284,7 @@ def InceptionV3(include_top=True, weights='imagenet',\n \n     # load weights\n     if weights == 'imagenet':\n-        if K.image_dim_ordering() == 'th':\n+        if K.image_data_format() == 'channels_first':\n             if include_top:\n                 weights_path = get_file('inception_v3_weights_th_dim_ordering_th_kernels.h5',\n                                         TH_WEIGHTS_PATH,\n@@ -299,10 +299,10 @@ def InceptionV3(include_top=True, weights='imagenet',\n             if K.backend() == 'tensorflow':\n                 warnings.warn('You are using the TensorFlow backend, yet you '\n                               'are using the Theano '\n-                              'image dimension ordering convention '\n-                              '(`image_dim_ordering=\"th\"`). '\n+                              'image data format convention '\n+                              '(`image_data_format=\"channels_first\"`). '\n                               'For best performance, set '\n-                              '`image_dim_ordering=\"tf\"` in '\n+                              '`image_data_format=\"channels_last\"` in '\n                               'your Keras config '\n                               'at ~/.keras/keras.json.')\n                 convert_all_kernels_in_model(model)\n\n@@ -23,8 +23,8 @@ from ..utils.data_utils import get_file\n from ..utils.layer_utils import convert_all_kernels_in_model\n from .audio_conv_utils import decode_predictions, preprocess_input\n \n-TH_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.3/music_tagger_crnn_weights_tf_kernels_th_dim_ordering.h5'\n-TF_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.3/music_tagger_crnn_weights_tf_kernels_tf_dim_ordering.h5'\n+TH_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.3/music_tagger_crnn_weights_tf_kernels_th_data_format.h5'\n+TF_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.3/music_tagger_crnn_weights_tf_kernels_tf_data_format.h5'\n \n \n def MusicTaggerCRNN(weights='msd', input_tensor=None,\n@@ -33,11 +33,11 @@ def MusicTaggerCRNN(weights='msd', input_tensor=None,\n     optionally loading weights pre-trained\n     on Million Song Dataset. Note that when using TensorFlow,\n     for best performance you should set\n-    `image_dim_ordering=\"tf\"` in your Keras config\n+    `image_data_format=\"channels_last\"` in your Keras config\n     at ~/.keras/keras.json.\n \n     The model and the weights are compatible with both\n-    TensorFlow and Theano. The dimension ordering\n+    TensorFlow and Theano. The data format\n     convention used by the model is the one\n     specified in your Keras config file.\n \n@@ -70,7 +70,7 @@ def MusicTaggerCRNN(weights='msd', input_tensor=None,\n         raise ValueError('If using `weights` as msd with `include_top`'\n                          ' as true, `classes` should be 50')\n     # Determine proper input shape\n-    if K.image_dim_ordering() == 'th':\n+    if K.image_data_format() == 'channels_first':\n         input_shape = (1, 96, 1366)\n     else:\n         input_shape = (96, 1366, 1)\n@@ -84,7 +84,7 @@ def MusicTaggerCRNN(weights='msd', input_tensor=None,\n             melgram_input = input_tensor\n \n     # Determine input axis\n-    if K.image_dim_ordering() == 'th':\n+    if K.image_data_format() == 'channels_first':\n         channel_axis = 1\n         freq_axis = 2\n         time_axis = 3\n@@ -122,7 +122,7 @@ def MusicTaggerCRNN(weights='msd', input_tensor=None,\n     x = MaxPooling2D(pool_size=(4, 4), strides=(4, 4), name='pool4')(x)\n \n     # reshaping\n-    if K.image_dim_ordering() == 'th':\n+    if K.image_data_format() == 'channels_first':\n         x = Permute((3, 1, 2))(x)\n     x = Reshape((15, 128))(x)\n \n@@ -146,12 +146,12 @@ def MusicTaggerCRNN(weights='msd', input_tensor=None,\n         return model\n     else:\n         # Load weights\n-        if K.image_dim_ordering() == 'tf':\n-            weights_path = get_file('music_tagger_crnn_weights_tf_kernels_tf_dim_ordering.h5',\n+        if K.image_data_format() == 'channels_last':\n+            weights_path = get_file('music_tagger_crnn_weights_tf_kernels_tf_data_format.h5',\n                                     TF_WEIGHTS_PATH,\n                                     cache_subdir='models')\n         else:\n-            weights_path = get_file('music_tagger_crnn_weights_tf_kernels_th_dim_ordering.h5',\n+            weights_path = get_file('music_tagger_crnn_weights_tf_kernels_th_data_format.h5',\n                                     TH_WEIGHTS_PATH,\n                                     cache_subdir='models')\n         model.load_weights(weights_path, by_name=True)\n\n@@ -41,7 +41,7 @@ def identity_block(input_tensor, kernel_size, filters, stage, block):\n         block: 'a','b'..., current block label, used for generating layer names\n     \"\"\"\n     nb_filter1, nb_filter2, nb_filter3 = filters\n-    if K.image_dim_ordering() == 'tf':\n+    if K.image_data_format() == 'channels_last':\n         bn_axis = 3\n     else:\n         bn_axis = 1\n@@ -79,7 +79,7 @@ def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2))\n     And the shortcut should have subsample=(2,2) as well\n     \"\"\"\n     nb_filter1, nb_filter2, nb_filter3 = filters\n-    if K.image_dim_ordering() == 'tf':\n+    if K.image_data_format() == 'channels_last':\n         bn_axis = 3\n     else:\n         bn_axis = 1\n@@ -115,11 +115,11 @@ def ResNet50(include_top=True, weights='imagenet',\n     optionally loading weights pre-trained\n     on ImageNet. Note that when using TensorFlow,\n     for best performance you should set\n-    `image_dim_ordering=\"tf\"` in your Keras config\n+    `image_data_format=\"channels_last\"` in your Keras config\n     at ~/.keras/keras.json.\n \n     The model and the weights are compatible with both\n-    TensorFlow and Theano. The dimension ordering\n+    TensorFlow and Theano. The data format\n     convention used by the model is the one\n     specified in your Keras config file.\n \n@@ -132,8 +132,8 @@ def ResNet50(include_top=True, weights='imagenet',\n             to use as image input for the model.\n         input_shape: optional shape tuple, only to be specified\n             if `include_top` is False (otherwise the input shape\n-            has to be `(224, 224, 3)` (with `tf` dim ordering)\n-            or `(3, 224, 244)` (with `th` dim ordering).\n+            has to be `(224, 224, 3)` (with `channels_last` data format)\n+            or `(3, 224, 244)` (with `channels_first` data format).\n             It should have exactly 3 inputs channels,\n             and width and height should be no smaller than 197.\n             E.g. `(200, 200, 3)` would be one valid value.\n@@ -157,7 +157,7 @@ def ResNet50(include_top=True, weights='imagenet',\n     input_shape = _obtain_input_shape(input_shape,\n                                       default_size=224,\n                                       min_size=197,\n-                                      dim_ordering=K.image_dim_ordering(),\n+                                      data_format=K.image_data_format(),\n                                       include_top=include_top)\n \n     if input_tensor is None:\n@@ -167,7 +167,7 @@ def ResNet50(include_top=True, weights='imagenet',\n             img_input = Input(tensor=input_tensor, shape=input_shape)\n         else:\n             img_input = input_tensor\n-    if K.image_dim_ordering() == 'tf':\n+    if K.image_data_format() == 'channels_last':\n         bn_axis = 3\n     else:\n         bn_axis = 1\n@@ -215,7 +215,7 @@ def ResNet50(include_top=True, weights='imagenet',\n \n     # load weights\n     if weights == 'imagenet':\n-        if K.image_dim_ordering() == 'th':\n+        if K.image_data_format() == 'channels_first':\n             if include_top:\n                 weights_path = get_file('resnet50_weights_th_dim_ordering_th_kernels.h5',\n                                         TH_WEIGHTS_PATH,\n@@ -230,10 +230,10 @@ def ResNet50(include_top=True, weights='imagenet',\n             if K.backend() == 'tensorflow':\n                 warnings.warn('You are using the TensorFlow backend, yet you '\n                               'are using the Theano '\n-                              'image dimension ordering convention '\n-                              '(`image_dim_ordering=\"th\"`). '\n+                              'image data format convention '\n+                              '(`image_data_format=\"channels_first\"`). '\n                               'For best performance, set '\n-                              '`image_dim_ordering=\"tf\"` in '\n+                              '`image_data_format=\"channels_last\"` in '\n                               'your Keras config '\n                               'at ~/.keras/keras.json.')\n                 convert_all_kernels_in_model(model)\n\n@@ -34,11 +34,11 @@ def VGG16(include_top=True, weights='imagenet',\n     optionally loading weights pre-trained\n     on ImageNet. Note that when using TensorFlow,\n     for best performance you should set\n-    `image_dim_ordering=\"tf\"` in your Keras config\n+    `image_data_format=\"channels_last\"` in your Keras config\n     at ~/.keras/keras.json.\n \n     The model and the weights are compatible with both\n-    TensorFlow and Theano. The dimension ordering\n+    TensorFlow and Theano. The data format\n     convention used by the model is the one\n     specified in your Keras config file.\n \n@@ -51,8 +51,8 @@ def VGG16(include_top=True, weights='imagenet',\n             to use as image input for the model.\n         input_shape: optional shape tuple, only to be specified\n             if `include_top` is False (otherwise the input shape\n-            has to be `(224, 224, 3)` (with `tf` dim ordering)\n-            or `(3, 224, 244)` (with `th` dim ordering).\n+            has to be `(224, 224, 3)` (with `channels_last` data format)\n+            or `(3, 224, 244)` (with `channels_first` data format).\n             It should have exactly 3 inputs channels,\n             and width and height should be no smaller than 48.\n             E.g. `(200, 200, 3)` would be one valid value.\n@@ -75,7 +75,7 @@ def VGG16(include_top=True, weights='imagenet',\n     input_shape = _obtain_input_shape(input_shape,\n                                       default_size=224,\n                                       min_size=48,\n-                                      dim_ordering=K.image_dim_ordering(),\n+                                      data_format=K.image_data_format(),\n                                       include_top=include_top)\n \n     if input_tensor is None:\n@@ -131,7 +131,7 @@ def VGG16(include_top=True, weights='imagenet',\n \n     # load weights\n     if weights == 'imagenet':\n-        if K.image_dim_ordering() == 'th':\n+        if K.image_data_format() == 'channels_first':\n             if include_top:\n                 weights_path = get_file('vgg16_weights_th_dim_ordering_th_kernels.h5',\n                                         TH_WEIGHTS_PATH,\n@@ -144,10 +144,10 @@ def VGG16(include_top=True, weights='imagenet',\n             if K.backend() == 'tensorflow':\n                 warnings.warn('You are using the TensorFlow backend, yet you '\n                               'are using the Theano '\n-                              'image dimension ordering convention '\n-                              '(`image_dim_ordering=\"th\"`). '\n+                              'image data format convention '\n+                              '(`image_data_format=\"channels_first\"`). '\n                               'For best performance, set '\n-                              '`image_dim_ordering=\"tf\"` in '\n+                              '`image_data_format=\"channels_last\"` in '\n                               'your Keras config '\n                               'at ~/.keras/keras.json.')\n                 convert_all_kernels_in_model(model)\n\n@@ -34,11 +34,11 @@ def VGG19(include_top=True, weights='imagenet',\n     optionally loading weights pre-trained\n     on ImageNet. Note that when using TensorFlow,\n     for best performance you should set\n-    `image_dim_ordering=\"tf\"` in your Keras config\n+    `image_data_format=\"channels_last\"` in your Keras config\n     at ~/.keras/keras.json.\n \n     The model and the weights are compatible with both\n-    TensorFlow and Theano. The dimension ordering\n+    TensorFlow and Theano. The data format\n     convention used by the model is the one\n     specified in your Keras config file.\n \n@@ -51,8 +51,8 @@ def VGG19(include_top=True, weights='imagenet',\n             to use as image input for the model.\n         input_shape: optional shape tuple, only to be specified\n             if `include_top` is False (otherwise the input shape\n-            has to be `(224, 224, 3)` (with `tf` dim ordering)\n-            or `(3, 224, 244)` (with `th` dim ordering).\n+            has to be `(224, 224, 3)` (with `channels_last` data format)\n+            or `(3, 224, 244)` (with `channels_first` data format).\n             It should have exactly 3 inputs channels,\n             and width and height should be no smaller than 48.\n             E.g. `(200, 200, 3)` would be one valid value.\n@@ -75,7 +75,7 @@ def VGG19(include_top=True, weights='imagenet',\n     input_shape = _obtain_input_shape(input_shape,\n                                       default_size=224,\n                                       min_size=48,\n-                                      dim_ordering=K.image_dim_ordering(),\n+                                      data_format=K.image_data_format(),\n                                       include_top=include_top)\n \n     if input_tensor is None:\n@@ -134,7 +134,7 @@ def VGG19(include_top=True, weights='imagenet',\n \n     # load weights\n     if weights == 'imagenet':\n-        if K.image_dim_ordering() == 'th':\n+        if K.image_data_format() == 'channels_first':\n             if include_top:\n                 weights_path = get_file('vgg19_weights_th_dim_ordering_th_kernels.h5',\n                                         TH_WEIGHTS_PATH,\n@@ -147,10 +147,10 @@ def VGG19(include_top=True, weights='imagenet',\n             if K.backend() == 'tensorflow':\n                 warnings.warn('You are using the TensorFlow backend, yet you '\n                               'are using the Theano '\n-                              'image dimension ordering convention '\n-                              '(`image_dim_ordering=\"th\"`). '\n+                              'image data format convention '\n+                              '(`image_data_format=\"channels_first\"`). '\n                               'For best performance, set '\n-                              '`image_dim_ordering=\"tf\"` in '\n+                              '`image_data_format=\"channels_last\"` in '\n                               'your Keras config '\n                               'at ~/.keras/keras.json.')\n                 convert_all_kernels_in_model(model)\n\n@@ -42,8 +42,8 @@ def Xception(include_top=True, weights='imagenet',\n     optionally loading weights pre-trained\n     on ImageNet. This model is available for TensorFlow only,\n     and can only be used with inputs following the TensorFlow\n-    dimension ordering `(width, height, channels)`.\n-    You should set `image_dim_ordering=\"tf\"` in your Keras config\n+    data format `(width, height, channels)`.\n+    You should set `image_data_format=\"channels_last\"` in your Keras config\n     located at ~/.keras/keras.json.\n \n     Note that the default input image size for this model is 299x299.\n@@ -80,26 +80,26 @@ def Xception(include_top=True, weights='imagenet',\n     if K.backend() != 'tensorflow':\n         raise RuntimeError('The Xception model is only available with '\n                            'the TensorFlow backend.')\n-    if K.image_dim_ordering() != 'tf':\n+    if K.image_data_format() != 'channels_last':\n         warnings.warn('The Xception model is only available for the '\n-                      'input dimension ordering \"tf\" '\n+                      'input data format \"channels_last\" '\n                       '(width, height, channels). '\n                       'However your settings specify the default '\n-                      'dimension ordering \"th\" (channels, width, height). '\n-                      'You should set `image_dim_ordering=\"tf\"` in your Keras '\n+                      'data format \"channels_first\" (channels, width, height). '\n+                      'You should set `image_data_format=\"channels_last\"` in your Keras '\n                       'config located at ~/.keras/keras.json. '\n                       'The model being returned right now will expect inputs '\n-                      'to follow the \"tf\" dimension ordering.')\n-        K.set_image_dim_ordering('tf')\n-        old_dim_ordering = 'th'\n+                      'to follow the \"channels_last\" data format.')\n+        K.set_image_data_format('channels_last')\n+        old_data_format = 'channels_first'\n     else:\n-        old_dim_ordering = None\n+        old_data_format = None\n \n     # Determine proper input shape\n     input_shape = _obtain_input_shape(input_shape,\n                                       default_size=299,\n                                       min_size=71,\n-                                      dim_ordering=K.image_dim_ordering(),\n+                                      data_format=K.image_data_format(),\n                                       include_top=include_top)\n \n     if input_tensor is None:\n@@ -221,8 +221,8 @@ def Xception(include_top=True, weights='imagenet',\n                                     cache_subdir='models')\n         model.load_weights(weights_path)\n \n-    if old_dim_ordering:\n-        K.set_image_dim_ordering(old_dim_ordering)\n+    if old_data_format:\n+        K.set_image_data_format(old_data_format)\n     return model\n \n \n\n@@ -9,8 +9,8 @@ from .common import set_epsilon\n from .common import set_floatx\n from .common import get_uid\n from .common import cast_to_floatx\n-from .common import image_dim_ordering\n-from .common import set_image_dim_ordering\n+from .common import image_data_format\n+from .common import set_image_data_format\n from .common import is_keras_tensor\n from .common import legacy_weight_ordering\n from .common import set_legacy_weight_ordering\n@@ -35,13 +35,13 @@ if os.path.exists(_config_path):\n     assert isinstance(_epsilon, float)\n     _backend = _config.get('backend', _BACKEND)\n     assert _backend in {'theano', 'tensorflow'}\n-    _image_dim_ordering = _config.get('image_dim_ordering',\n-                                      image_dim_ordering())\n-    assert _image_dim_ordering in {'tf', 'th'}\n+    _image_data_format = _config.get('image_data_format',\n+                                      image_data_format())\n+    assert _image_data_format in {'channels_last', 'channels_first'}\n \n     set_floatx(_floatx)\n     set_epsilon(_epsilon)\n-    set_image_dim_ordering(_image_dim_ordering)\n+    set_image_data_format(_image_data_format)\n     _BACKEND = _backend\n \n # save config file\n@@ -49,7 +49,7 @@ if not os.path.exists(_config_path):\n     _config = {'floatx': floatx(),\n                'epsilon': epsilon(),\n                'backend': _BACKEND,\n-               'image_dim_ordering': image_dim_ordering()}\n+               'image_data_format': image_data_format()}\n     with open(_config_path, 'w') as f:\n         f.write(json.dumps(_config, indent=4))\n \n\n@@ -6,7 +6,7 @@ from collections import defaultdict\n _FLOATX = 'float32'\n _EPSILON = 10e-8\n _UID_PREFIXES = defaultdict(int)\n-_IMAGE_DIM_ORDERING = 'tf'\n+_IMAGE_DATA_FORMAT = 'channels_last'\n _LEGACY_WEIGHT_ORDERING = False\n \n \n@@ -112,43 +112,43 @@ def cast_to_floatx(x):\n     return np.asarray(x, dtype=_FLOATX)\n \n \n-def image_dim_ordering():\n-    \"\"\"Returns the default image dimension ordering\n-    convention ('th' or 'tf').\n+def image_data_format():\n+    \"\"\"Returns the default image data format\n+    convention ('channels_first' or 'channels_last').\n \n     # Returns\n-        A string, either `'th'` or `'tf'`\n+        A string, either `'channels_first'` or `'channels_last'`\n \n     # Example\n     ```python\n-        >>> keras.backend.image_dim_ordering()\n-        'th'\n+        >>> keras.backend.image_data_format()\n+        'channels_first'\n     ```\n     \"\"\"\n-    return _IMAGE_DIM_ORDERING\n+    return _IMAGE_DATA_FORMAT\n \n \n-def set_image_dim_ordering(dim_ordering):\n+def set_image_data_format(data_format):\n     \"\"\"Sets the value of the image dimension\n-    ordering convention ('th' or 'tf').\n+    ordering convention ('channels_first' or 'channels_last').\n \n     # Arguments\n-        dim_ordering: string. `'th'` or `'tf'`.\n+        data_format: string. `'channels_first'` or `'channels_last'`.\n \n     # Example\n     ```python\n         >>> from keras import backend as K\n-        >>> K.image_dim_ordering()\n-        'th'\n-        >>> K.set_image_dim_ordering('tf')\n-        >>> K.image_dim_ordering()\n-        'tf'\n+        >>> K.image_data_format()\n+        'channels_first'\n+        >>> K.set_image_data_format('channels_last')\n+        >>> K.image_data_format()\n+        'channels_last'\n     ```\n     \"\"\"\n-    global _IMAGE_DIM_ORDERING\n-    if dim_ordering not in {'tf', 'th'}:\n-        raise ValueError('Unknown dim_ordering:', dim_ordering)\n-    _IMAGE_DIM_ORDERING = str(dim_ordering)\n+    global _IMAGE_DATA_FORMAT\n+    if data_format not in {'channels_last', 'channels_first'}:\n+        raise ValueError('Unknown data_format:', data_format)\n+    _IMAGE_DATA_FORMAT = str(data_format)\n \n \n def get_uid(prefix=''):\n\n@@ -11,7 +11,7 @@ except ImportError:\n import numpy as np\n import os\n import warnings\n-from .common import floatx, _EPSILON, image_dim_ordering, reset_uids\n+from .common import floatx, _EPSILON, image_data_format, reset_uids\n py_all = all\n \n # INTERNAL UTILS\n@@ -1439,17 +1439,17 @@ def permute_dimensions(x, pattern):\n     return tf.transpose(x, perm=pattern)\n \n \n-def resize_images(X, height_factor, width_factor, dim_ordering):\n+def resize_images(X, height_factor, width_factor, data_format):\n     \"\"\"Resizes the images contained in a 4D tensor of shape\n-    - `[batch, channels, height, width]` (for 'th' dim_ordering)\n-    - `[batch, height, width, channels]` (for 'tf' dim_ordering)\n+    - `[batch, channels, height, width]` (for 'channels_first' data_format)\n+    - `[batch, height, width, channels]` (for 'channels_last' data_format)\n     by a factor of `(height_factor, width_factor)`. Both factors should be\n     positive integers.\n \n     # Returns\n         A tensor.\n     \"\"\"\n-    if dim_ordering == 'th':\n+    if data_format == 'channels_first':\n         original_shape = int_shape(X)\n         new_shape = tf.shape(X)[2:]\n         new_shape *= tf.constant(np.array([height_factor, width_factor]).astype('int32'))\n@@ -1459,7 +1459,7 @@ def resize_images(X, height_factor, width_factor, dim_ordering):\n         X.set_shape((None, None, original_shape[2] * height_factor if original_shape[2] is not None else None,\n                      original_shape[3] * width_factor if original_shape[3] is not None else None))\n         return X\n-    elif dim_ordering == 'tf':\n+    elif data_format == 'channels_last':\n         original_shape = int_shape(X)\n         new_shape = tf.shape(X)[1:3]\n         new_shape *= tf.constant(np.array([height_factor, width_factor]).astype('int32'))\n@@ -1468,31 +1468,31 @@ def resize_images(X, height_factor, width_factor, dim_ordering):\n                      original_shape[2] * width_factor if original_shape[2] is not None else None, None))\n         return X\n     else:\n-        raise ValueError('Invalid dim_ordering:', dim_ordering)\n+        raise ValueError('Invalid data_format:', data_format)\n \n \n-def resize_volumes(X, depth_factor, height_factor, width_factor, dim_ordering):\n+def resize_volumes(X, depth_factor, height_factor, width_factor, data_format):\n     \"\"\"Resizes the volume contained in a 5D tensor of shape\n-    - `[batch, channels, depth, height, width]` (for 'th' dim_ordering)\n-    - `[batch, depth, height, width, channels]` (for 'tf' dim_ordering)\n+    - `[batch, channels, depth, height, width]` (for 'channels_first' data_format)\n+    - `[batch, depth, height, width, channels]` (for 'channels_last' data_format)\n     by a factor of `(depth_factor, height_factor, width_factor)`.\n     All three factors should be positive integers.\n \n     # Returns\n         A tensor.\n     \"\"\"\n-    if dim_ordering == 'th':\n+    if data_format == 'channels_first':\n         output = repeat_elements(X, depth_factor, axis=2)\n         output = repeat_elements(output, height_factor, axis=3)\n         output = repeat_elements(output, width_factor, axis=4)\n         return output\n-    elif dim_ordering == 'tf':\n+    elif data_format == 'channels_last':\n         output = repeat_elements(X, depth_factor, axis=1)\n         output = repeat_elements(output, height_factor, axis=2)\n         output = repeat_elements(output, width_factor, axis=3)\n         return output\n     else:\n-        raise ValueError('Invalid dim_ordering:', dim_ordering)\n+        raise ValueError('Invalid data_format:', data_format)\n \n \n def repeat_elements(x, rep, axis):\n@@ -1627,19 +1627,19 @@ def asymmetric_temporal_padding(x, left_pad=1, right_pad=1):\n     return tf.pad(x, pattern)\n \n \n-def spatial_2d_padding(x, padding=(1, 1), dim_ordering='default'):\n+def spatial_2d_padding(x, padding=(1, 1), data_format='default'):\n     \"\"\"Pads the 2nd and 3rd dimensions of a 4D tensor\n     with \"padding[0]\" and \"padding[1]\" (resp.) zeros left and right.\n \n     # Returns\n         A padded 4D tensor.\n     \"\"\"\n-    if dim_ordering == 'default':\n-        dim_ordering = image_dim_ordering()\n-    if dim_ordering not in {'th', 'tf'}:\n-        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))\n+    if data_format == 'default':\n+        data_format = image_data_format()\n+    if data_format not in {'channels_first', 'channels_last'}:\n+        raise ValueError('Unknown data_format ' + str(data_format))\n \n-    if dim_ordering == 'th':\n+    if data_format == 'channels_first':\n         pattern = [[0, 0], [0, 0],\n                    [padding[0], padding[0]], [padding[1], padding[1]]]\n     else:\n@@ -1651,7 +1651,7 @@ def spatial_2d_padding(x, padding=(1, 1), dim_ordering='default'):\n \n def asymmetric_spatial_2d_padding(x, top_pad=1, bottom_pad=1,\n                                   left_pad=1, right_pad=1,\n-                                  dim_ordering='default'):\n+                                  data_format='default'):\n     \"\"\"Pad the rows and columns of a 4D tensor\n     with \"top_pad\", \"bottom_pad\", \"left_pad\", \"right_pad\" (resp.) zeros\n     rows on top, bottom; cols on left, right.\n@@ -1659,12 +1659,12 @@ def asymmetric_spatial_2d_padding(x, top_pad=1, bottom_pad=1,\n     # Returns\n         A padded 4D tensor.\n     \"\"\"\n-    if dim_ordering == 'default':\n-        dim_ordering = image_dim_ordering()\n-    if dim_ordering not in {'th', 'tf'}:\n-        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))\n+    if data_format == 'default':\n+        data_format = image_data_format()\n+    if data_format not in {'channels_first', 'channels_last'}:\n+        raise ValueError('Unknown data_format ' + str(data_format))\n \n-    if dim_ordering == 'th':\n+    if data_format == 'channels_first':\n         pattern = [[0, 0],\n                    [0, 0],\n                    [top_pad, bottom_pad],\n@@ -1677,22 +1677,22 @@ def asymmetric_spatial_2d_padding(x, top_pad=1, bottom_pad=1,\n     return tf.pad(x, pattern)\n \n \n-def spatial_3d_padding(x, padding=(1, 1, 1), dim_ordering='default'):\n+def spatial_3d_padding(x, padding=(1, 1, 1), data_format='default'):\n     \"\"\"Pads 5D tensor with zeros for the depth, height, width dimension with\n     \"padding[0]\", \"padding[1]\" and \"padding[2]\" (resp.) zeros left and right\n \n-    For 'tf' dim_ordering, the 2nd, 3rd and 4th dimension will be padded.\n-    For 'th' dim_ordering, the 3rd, 4th and 5th dimension will be padded.\n+    For 'channels_last' data_format, the 2nd, 3rd and 4th dimension will be padded.\n+    For 'channels_first' data_format, the 3rd, 4th and 5th dimension will be padded.\n \n     # Returns\n         A padded 5D tensor.\n     \"\"\"\n-    if dim_ordering == 'default':\n-        dim_ordering = image_dim_ordering()\n-    if dim_ordering not in {'th', 'tf'}:\n-        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))\n+    if data_format == 'default':\n+        data_format = image_data_format()\n+    if data_format not in {'channels_first', 'channels_last'}:\n+        raise ValueError('Unknown data_format ' + str(data_format))\n \n-    if dim_ordering == 'th':\n+    if data_format == 'channels_first':\n         pattern = [\n             [0, 0],\n             [0, 0],\n@@ -2463,8 +2463,8 @@ def in_top_k(predictions, targets, k):\n \n # CONVOLUTIONS\n \n-def _preprocess_deconv_output_shape(x, shape, dim_ordering):\n-    if dim_ordering == 'th':\n+def _preprocess_deconv_output_shape(x, shape, data_format):\n+    if data_format == 'channels_first':\n         shape = (shape[0], shape[2], shape[3], shape[1])\n \n     if shape[0] is None:\n@@ -2472,10 +2472,10 @@ def _preprocess_deconv_output_shape(x, shape, dim_ordering):\n     return shape\n \n \n-def _preprocess_conv2d_input(x, dim_ordering):\n+def _preprocess_conv2d_input(x, data_format):\n     if dtype(x) == 'float64':\n         x = tf.cast(x, 'float32')\n-    if dim_ordering == 'th':\n+    if data_format == 'channels_first':\n         # TF uses the last dimension as channel dimension,\n         # instead of the 2nd one.\n         # TH input shape: (samples, input_depth, rows, cols)\n@@ -2484,10 +2484,10 @@ def _preprocess_conv2d_input(x, dim_ordering):\n     return x\n \n \n-def _preprocess_conv3d_input(x, dim_ordering):\n+def _preprocess_conv3d_input(x, data_format):\n     if dtype(x) == 'float64':\n         x = tf.cast(x, 'float32')\n-    if dim_ordering == 'th':\n+    if data_format == 'channels_first':\n         # TF uses the last dimension as channel dimension,\n         # instead of the 2nd one.\n         # TH input shape: (samples, input_depth, conv_dim1, conv_dim2, conv_dim3)\n@@ -2496,10 +2496,10 @@ def _preprocess_conv3d_input(x, dim_ordering):\n     return x\n \n \n-def _preprocess_conv2d_kernel(kernel, dim_ordering):\n+def _preprocess_conv2d_kernel(kernel, data_format):\n     if dtype(kernel) == 'float64':\n         kernel = tf.cast(kernel, 'float32')\n-    if dim_ordering == 'th':\n+    if data_format == 'channels_first':\n         # TF uses the last dimension as channel dimension,\n         # instead of the 2nd one.\n         # TH kernel shape: (depth, input_depth, rows, cols)\n@@ -2508,10 +2508,10 @@ def _preprocess_conv2d_kernel(kernel, dim_ordering):\n     return kernel\n \n \n-def _preprocess_conv3d_kernel(kernel, dim_ordering):\n+def _preprocess_conv3d_kernel(kernel, data_format):\n     if dtype(kernel) == 'float64':\n         kernel = tf.cast(kernel, 'float32')\n-    if dim_ordering == 'th':\n+    if data_format == 'channels_first':\n         # TF uses the last dimension as channel dimension,\n         # instead of the 2nd one.\n         # TH kernel shape: (out_depth, input_depth, kernel_dim1, kernel_dim2, kernel_dim3)\n@@ -2530,8 +2530,8 @@ def _preprocess_border_mode(border_mode):\n     return padding\n \n \n-def _postprocess_conv2d_output(x, dim_ordering):\n-    if dim_ordering == 'th':\n+def _postprocess_conv2d_output(x, data_format):\n+    if data_format == 'channels_first':\n         x = tf.transpose(x, (0, 3, 1, 2))\n \n     if floatx() == 'float64':\n@@ -2539,8 +2539,8 @@ def _postprocess_conv2d_output(x, dim_ordering):\n     return x\n \n \n-def _postprocess_conv3d_output(x, dim_ordering):\n-    if dim_ordering == 'th':\n+def _postprocess_conv3d_output(x, data_format):\n+    if data_format == 'channels_first':\n         x = tf.transpose(x, (0, 4, 1, 2, 3))\n \n     if floatx() == 'float64':\n@@ -2574,7 +2574,7 @@ def conv1d(x, kernel, stride=1, border_mode='valid',\n \n \n def conv2d(x, kernel, strides=(1, 1), border_mode='valid',\n-           dim_ordering='default',\n+           data_format='default',\n            image_shape=None, filter_shape=None, filter_dilation=(1, 1)):\n     \"\"\"2D convolution.\n \n@@ -2582,20 +2582,20 @@ def conv2d(x, kernel, strides=(1, 1), border_mode='valid',\n         kernel: kernel tensor.\n         strides: strides tuple.\n         border_mode: string, `\"same\"` or `\"valid\"`.\n-        dim_ordering: `\"tf\"` or `\"th\"`.\n-            Whether to use Theano or TensorFlow dimension ordering\n+        data_format: `\"channels_last\"` or `\"channels_first\"`.\n+            Whether to use Theano or TensorFlow data format\n             for inputs/kernels/ouputs.\n \n     # Returns\n         A tensor, result of 2D convolution.\n     \"\"\"\n-    if dim_ordering == 'default':\n-        dim_ordering = image_dim_ordering()\n-    if dim_ordering not in {'th', 'tf'}:\n-        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))\n+    if data_format == 'default':\n+        data_format = image_data_format()\n+    if data_format not in {'channels_first', 'channels_last'}:\n+        raise ValueError('Unknown data_format ' + str(data_format))\n \n-    x = _preprocess_conv2d_input(x, dim_ordering)\n-    kernel = _preprocess_conv2d_kernel(kernel, dim_ordering)\n+    x = _preprocess_conv2d_input(x, data_format)\n+    kernel = _preprocess_conv2d_kernel(kernel, data_format)\n     padding = _preprocess_border_mode(border_mode)\n     if filter_dilation == (1, 1):\n         strides = (1,) + strides + (1,)\n@@ -2604,12 +2604,12 @@ def conv2d(x, kernel, strides=(1, 1), border_mode='valid',\n         assert filter_dilation[0] == filter_dilation[1]\n         assert strides == (1, 1), 'Invalid strides for dilated convolution'\n         x = tf.nn.atrous_conv2d(x, kernel, filter_dilation[0], padding=padding)\n-    return _postprocess_conv2d_output(x, dim_ordering)\n+    return _postprocess_conv2d_output(x, data_format)\n \n \n def deconv2d(x, kernel, output_shape, strides=(1, 1),\n              border_mode='valid',\n-             dim_ordering='default',\n+             data_format='default',\n              image_shape=None, filter_shape=None):\n     \"\"\"2D deconvolution (i.e. transposed convolution).\n \n@@ -2619,33 +2619,33 @@ def deconv2d(x, kernel, output_shape, strides=(1, 1),\n         output_shape: 1D int tensor for the output shape.\n         strides: strides tuple.\n         border_mode: string, `\"same\"` or `\"valid\"`.\n-        dim_ordering: `\"tf\"` or `\"th\"`.\n-            Whether to use Theano or TensorFlow dimension ordering\n+        data_format: `\"channels_last\"` or `\"channels_first\"`.\n+            Whether to use Theano or TensorFlow data format\n             for inputs/kernels/ouputs.\n \n     # Returns\n         A tensor, result of transposed 2D convolution.\n     \"\"\"\n-    if dim_ordering == 'default':\n-        dim_ordering = image_dim_ordering()\n-    if dim_ordering not in {'th', 'tf'}:\n-        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))\n+    if data_format == 'default':\n+        data_format = image_data_format()\n+    if data_format not in {'channels_first', 'channels_last'}:\n+        raise ValueError('Unknown data_format ' + str(data_format))\n \n-    x = _preprocess_conv2d_input(x, dim_ordering)\n-    output_shape = _preprocess_deconv_output_shape(x, output_shape, dim_ordering)\n-    kernel = _preprocess_conv2d_kernel(kernel, dim_ordering)\n+    x = _preprocess_conv2d_input(x, data_format)\n+    output_shape = _preprocess_deconv_output_shape(x, output_shape, data_format)\n+    kernel = _preprocess_conv2d_kernel(kernel, data_format)\n     kernel = tf.transpose(kernel, (0, 1, 3, 2))\n     padding = _preprocess_border_mode(border_mode)\n     strides = (1,) + strides + (1,)\n \n     x = tf.nn.conv2d_transpose(x, kernel, output_shape, strides,\n                                padding=padding)\n-    return _postprocess_conv2d_output(x, dim_ordering)\n+    return _postprocess_conv2d_output(x, data_format)\n \n \n def atrous_conv2d(x, kernel, rate=1,\n                   border_mode='valid',\n-                  dim_ordering='default',\n+                  data_format='default',\n                   image_shape=None, filter_shape=None):\n     \"\"\"Atrous 2D convolution. Also as known as dilated convolution.\n \n@@ -2656,53 +2656,53 @@ def atrous_conv2d(x, kernel, rate=1,\n         output_shape: 1D int tensor for the output shape.\n         strides: strides tuple.\n         border_mode: string, `\"same\"` or `\"valid\"`.\n-        dim_ordering: `\"tf\"` or `\"th\"`.\n-            Whether to use Theano or TensorFlow dimension ordering\n+        data_format: `\"channels_last\"` or `\"channels_first\"`.\n+            Whether to use Theano or TensorFlow data format\n             for inputs/kernels/ouputs.\n \n     # Returns\n         A tensor, result of atrous transposed 2D convolution.\n     \"\"\"\n-    if dim_ordering == 'default':\n-        dim_ordering = image_dim_ordering()\n-    if dim_ordering not in {'th', 'tf'}:\n-        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))\n+    if data_format == 'default':\n+        data_format = image_data_format()\n+    if data_format not in {'channels_first', 'channels_last'}:\n+        raise ValueError('Unknown data_format ' + str(data_format))\n     if rate == 1:\n         return conv2d(x, kernel, strides=(1, 1), border_mode=border_mode,\n-                      dim_ordering=dim_ordering)\n+                      data_format=data_format)\n \n-    x = _preprocess_conv2d_input(x, dim_ordering)\n-    kernel = _preprocess_conv2d_kernel(kernel, dim_ordering)\n+    x = _preprocess_conv2d_input(x, data_format)\n+    kernel = _preprocess_conv2d_kernel(kernel, data_format)\n     padding = _preprocess_border_mode(border_mode)\n \n     x = tf.nn.atrous_conv2d(x, kernel, rate, padding)\n-    return _postprocess_conv2d_output(x, dim_ordering)\n+    return _postprocess_conv2d_output(x, data_format)\n \n \n def separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1),\n-                     border_mode='valid', dim_ordering='default'):\n+                     border_mode='valid', data_format='default'):\n     \"\"\"2-D convolution with separable filters.\n     \"\"\"\n-    if dim_ordering == 'default':\n-        dim_ordering = image_dim_ordering()\n-    if dim_ordering not in {'th', 'tf'}:\n-        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))\n+    if data_format == 'default':\n+        data_format = image_data_format()\n+    if data_format not in {'channels_first', 'channels_last'}:\n+        raise ValueError('Unknown data_format ' + str(data_format))\n \n-    x = _preprocess_conv2d_input(x, dim_ordering)\n+    x = _preprocess_conv2d_input(x, data_format)\n     depthwise_kernel = _preprocess_conv2d_kernel(depthwise_kernel,\n-                                                 dim_ordering)\n+                                                 data_format)\n     pointwise_kernel = _preprocess_conv2d_kernel(pointwise_kernel,\n-                                                 dim_ordering)\n+                                                 data_format)\n     padding = _preprocess_border_mode(border_mode)\n     strides = (1,) + strides + (1,)\n \n     x = tf.nn.separable_conv2d(x, depthwise_kernel, pointwise_kernel,\n                                strides, padding)\n-    return _postprocess_conv2d_output(x, dim_ordering)\n+    return _postprocess_conv2d_output(x, data_format)\n \n \n def conv3d(x, kernel, strides=(1, 1, 1),\n-           border_mode='valid', dim_ordering='default',\n+           border_mode='valid', data_format='default',\n            volume_shape=None, filter_shape=None):\n     \"\"\"3D convolution.\n \n@@ -2710,29 +2710,29 @@ def conv3d(x, kernel, strides=(1, 1, 1),\n         kernel: kernel tensor.\n         strides: strides tuple.\n         border_mode: string, `\"same\"` or `\"valid\"`.\n-        dim_ordering: `\"tf\"` or `\"th\"`.\n-            Whether to use Theano or TensorFlow dimension ordering\n+        data_format: `\"channels_last\"` or `\"channels_first\"`.\n+            Whether to use Theano or TensorFlow data format\n             for inputs/kernels/ouputs.\n \n     # Returns\n         A tensor, result of 3D convolution.\n     \"\"\"\n-    if dim_ordering == 'default':\n-        dim_ordering = image_dim_ordering()\n-    if dim_ordering not in {'th', 'tf'}:\n-        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))\n+    if data_format == 'default':\n+        data_format = image_data_format()\n+    if data_format not in {'channels_first', 'channels_last'}:\n+        raise ValueError('Unknown data_format ' + str(data_format))\n \n-    x = _preprocess_conv3d_input(x, dim_ordering)\n-    kernel = _preprocess_conv3d_kernel(kernel, dim_ordering)\n+    x = _preprocess_conv3d_input(x, data_format)\n+    kernel = _preprocess_conv3d_kernel(kernel, data_format)\n     padding = _preprocess_border_mode(border_mode)\n     strides = (1,) + strides + (1,)\n \n     x = tf.nn.conv3d(x, kernel, strides, padding)\n-    return _postprocess_conv3d_output(x, dim_ordering)\n+    return _postprocess_conv3d_output(x, data_format)\n \n \n def pool2d(x, pool_size, strides=(1, 1),\n-           border_mode='valid', dim_ordering='default',\n+           border_mode='valid', data_format='default',\n            pool_mode='max'):\n     \"\"\"2D Pooling.\n \n@@ -2740,22 +2740,22 @@ def pool2d(x, pool_size, strides=(1, 1),\n         pool_size: tuple of 2 integers.\n         strides: tuple of 2 integers.\n         border_mode: one of `\"valid\"`, `\"same\"`.\n-        dim_ordering: one of `\"th\"`, `\"tf\"`.\n+        data_format: one of `\"channels_first\"`, `\"channels_last\"`.\n         pool_mode: one of `\"max\"`, `\"avg\"`.\n \n     # Returns\n         A tensor, result of 2D pooling.\n     \"\"\"\n-    if dim_ordering == 'default':\n-        dim_ordering = image_dim_ordering()\n-    if dim_ordering not in {'th', 'tf'}:\n-        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))\n+    if data_format == 'default':\n+        data_format = image_data_format()\n+    if data_format not in {'channels_first', 'channels_last'}:\n+        raise ValueError('Unknown data_format ' + str(data_format))\n \n     padding = _preprocess_border_mode(border_mode)\n     strides = (1,) + strides + (1,)\n     pool_size = (1,) + pool_size + (1,)\n \n-    x = _preprocess_conv2d_input(x, dim_ordering)\n+    x = _preprocess_conv2d_input(x, data_format)\n \n     if pool_mode == 'max':\n         x = tf.nn.max_pool(x, pool_size, strides, padding=padding)\n@@ -2764,33 +2764,33 @@ def pool2d(x, pool_size, strides=(1, 1),\n     else:\n         raise ValueError('Invalid pooling mode:', pool_mode)\n \n-    return _postprocess_conv2d_output(x, dim_ordering)\n+    return _postprocess_conv2d_output(x, data_format)\n \n \n def pool3d(x, pool_size, strides=(1, 1, 1), border_mode='valid',\n-           dim_ordering='default', pool_mode='max'):\n+           data_format='default', pool_mode='max'):\n     \"\"\"3D Pooling.\n \n     # Arguments\n         pool_size: tuple of 3 integers.\n         strides: tuple of 3 integers.\n         border_mode: one of `\"valid\"`, `\"same\"`.\n-        dim_ordering: one of `\"th\"`, `\"tf\"`.\n+        data_format: one of `\"channels_first\"`, `\"channels_last\"`.\n         pool_mode: one of `\"max\"`, `\"avg\"`.\n \n     # Returns\n         A tensor, result of 3D pooling.\n     \"\"\"\n-    if dim_ordering == 'default':\n-        dim_ordering = image_dim_ordering()\n-    if dim_ordering not in {'th', 'tf'}:\n-        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))\n+    if data_format == 'default':\n+        data_format = image_data_format()\n+    if data_format not in {'channels_first', 'channels_last'}:\n+        raise ValueError('Unknown data_format ' + str(data_format))\n \n     padding = _preprocess_border_mode(border_mode)\n     strides = (1,) + strides + (1,)\n     pool_size = (1,) + pool_size + (1,)\n \n-    x = _preprocess_conv3d_input(x, dim_ordering)\n+    x = _preprocess_conv3d_input(x, data_format)\n \n     if pool_mode == 'max':\n         x = tf.nn.max_pool3d(x, pool_size, strides, padding=padding)\n@@ -2799,7 +2799,7 @@ def pool3d(x, pool_size, strides=(1, 1, 1), border_mode='valid',\n     else:\n         raise ValueError('Invalid pooling mode:', pool_mode)\n \n-    return _postprocess_conv3d_output(x, dim_ordering)\n+    return _postprocess_conv3d_output(x, data_format)\n \n \n # RANDOMNESS\n\n@@ -14,7 +14,7 @@ except ImportError:\n     from theano.sandbox.softsign import softsign as T_softsign\n import inspect\n import numpy as np\n-from .common import _FLOATX, floatx, _EPSILON, image_dim_ordering\n+from .common import _FLOATX, floatx, _EPSILON, image_data_format\n py_all = all\n \n \n@@ -615,46 +615,46 @@ def repeat_elements(x, rep, axis):\n     return T.repeat(x, rep, axis=axis)\n \n \n-def resize_images(X, height_factor, width_factor, dim_ordering):\n+def resize_images(X, height_factor, width_factor, data_format):\n     \"\"\"Resize the images contained in a 4D tensor of shape\n-    - [batch, channels, height, width] (for 'th' dim_ordering)\n-    - [batch, height, width, channels] (for 'tf' dim_ordering)\n+    - [batch, channels, height, width] (for 'channels_first' data_format)\n+    - [batch, height, width, channels] (for 'channels_last' data_format)\n     by a factor of (height_factor, width_factor). Both factors should be\n     positive integers.\n     \"\"\"\n     # TODO: `keras_shape` inference.\n-    if dim_ordering == 'th':\n+    if data_format == 'channels_first':\n         output = repeat_elements(X, height_factor, axis=2)\n         output = repeat_elements(output, width_factor, axis=3)\n         return output\n-    elif dim_ordering == 'tf':\n+    elif data_format == 'channels_last':\n         output = repeat_elements(X, height_factor, axis=1)\n         output = repeat_elements(output, width_factor, axis=2)\n         return output\n     else:\n-        raise ValueError('Invalid dim_ordering:', dim_ordering)\n+        raise ValueError('Invalid data_format:', data_format)\n \n \n-def resize_volumes(X, depth_factor, height_factor, width_factor, dim_ordering):\n+def resize_volumes(X, depth_factor, height_factor, width_factor, data_format):\n     \"\"\"Resize the volume contained in a 5D tensor of shape\n-    - [batch, channels, depth, height, width] (for 'th' dim_ordering)\n-    - [batch, depth, height, width, channels] (for 'tf' dim_ordering)\n+    - [batch, channels, depth, height, width] (for 'channels_first' data_format)\n+    - [batch, depth, height, width, channels] (for 'channels_last' data_format)\n     by a factor of (depth_factor, height_factor, width_factor).\n     Both factors should be positive integers.\n     \"\"\"\n     # TODO: `keras_shape` inference.\n-    if dim_ordering == 'th':\n+    if data_format == 'channels_first':\n         output = repeat_elements(X, depth_factor, axis=2)\n         output = repeat_elements(output, height_factor, axis=3)\n         output = repeat_elements(output, width_factor, axis=4)\n         return output\n-    elif dim_ordering == 'tf':\n+    elif data_format == 'channels_last':\n         output = repeat_elements(X, depth_factor, axis=1)\n         output = repeat_elements(output, height_factor, axis=2)\n         output = repeat_elements(output, width_factor, axis=3)\n         return output\n     else:\n-        raise ValueError('Invalid dim_ordering:', dim_ordering)\n+        raise ValueError('Invalid data_format:', data_format)\n \n \n def repeat(x, n):\n@@ -756,18 +756,18 @@ def asymmetric_temporal_padding(x, left_pad=1, right_pad=1):\n     return T.set_subtensor(output[:, left_pad:x.shape[1] + left_pad, :], x)\n \n \n-def spatial_2d_padding(x, padding=(1, 1), dim_ordering='default'):\n+def spatial_2d_padding(x, padding=(1, 1), data_format='default'):\n     \"\"\"Pad the 2nd and 3rd dimensions of a 4D tensor\n     with \"padding[0]\" and \"padding[1]\" (resp.) zeros left and right.\n     \"\"\"\n     # TODO: `keras_shape` inference.\n-    if dim_ordering == 'default':\n-        dim_ordering = image_dim_ordering()\n-    if dim_ordering not in {'th', 'tf'}:\n-        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))\n+    if data_format == 'default':\n+        data_format = image_data_format()\n+    if data_format not in {'channels_first', 'channels_last'}:\n+        raise ValueError('Unknown data_format ' + str(data_format))\n \n     input_shape = x.shape\n-    if dim_ordering == 'th':\n+    if data_format == 'channels_first':\n         output_shape = (input_shape[0],\n                         input_shape[1],\n                         input_shape[2] + 2 * padding[0],\n@@ -778,7 +778,7 @@ def spatial_2d_padding(x, padding=(1, 1), dim_ordering='default'):\n                    slice(padding[0], input_shape[2] + padding[0]),\n                    slice(padding[1], input_shape[3] + padding[1]))\n \n-    elif dim_ordering == 'tf':\n+    elif data_format == 'channels_last':\n         output_shape = (input_shape[0],\n                         input_shape[1] + 2 * padding[0],\n                         input_shape[2] + 2 * padding[1],\n@@ -789,24 +789,24 @@ def spatial_2d_padding(x, padding=(1, 1), dim_ordering='default'):\n                    slice(padding[1], input_shape[2] + padding[1]),\n                    slice(None))\n     else:\n-        raise ValueError('Invalid dim_ordering:', dim_ordering)\n+        raise ValueError('Invalid data_format:', data_format)\n     return T.set_subtensor(output[indices], x)\n \n \n def asymmetric_spatial_2d_padding(x, top_pad=1, bottom_pad=1,\n                                   left_pad=1, right_pad=1,\n-                                  dim_ordering='default'):\n+                                  data_format='default'):\n     \"\"\"Pad the rows and columns of a 4D tensor\n     with \"top_pad\", \"bottom_pad\", \"left_pad\", \"right_pad\" (resp.) zeros\n     rows on top, bottom; cols on left, right.\n     \"\"\"\n-    if dim_ordering == 'default':\n-        dim_ordering = image_dim_ordering()\n-    if dim_ordering not in {'th', 'tf'}:\n-        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))\n+    if data_format == 'default':\n+        data_format = image_data_format()\n+    if data_format not in {'channels_first', 'channels_last'}:\n+        raise ValueError('Unknown data_format ' + str(data_format))\n \n     input_shape = x.shape\n-    if dim_ordering == 'th':\n+    if data_format == 'channels_first':\n         output_shape = (input_shape[0],\n                         input_shape[1],\n                         input_shape[2] + top_pad + bottom_pad,\n@@ -817,7 +817,7 @@ def asymmetric_spatial_2d_padding(x, top_pad=1, bottom_pad=1,\n                    slice(top_pad, input_shape[2] + top_pad),\n                    slice(left_pad, input_shape[3] + left_pad))\n \n-    elif dim_ordering == 'tf':\n+    elif data_format == 'channels_last':\n         output_shape = (input_shape[0],\n                         input_shape[1] + top_pad + bottom_pad,\n                         input_shape[2] + left_pad + right_pad,\n@@ -829,21 +829,21 @@ def asymmetric_spatial_2d_padding(x, top_pad=1, bottom_pad=1,\n                    slice(left_pad, input_shape[2] + left_pad),\n                    slice(None))\n     else:\n-        raise ValueError('Invalid dim_ordering:', dim_ordering)\n+        raise ValueError('Invalid data_format:', data_format)\n     return T.set_subtensor(output[indices], x)\n \n \n-def spatial_3d_padding(x, padding=(1, 1, 1), dim_ordering='default'):\n+def spatial_3d_padding(x, padding=(1, 1, 1), data_format='default'):\n     \"\"\"Pad the 2nd, 3rd and 4th dimensions of a 5D tensor\n     with \"padding[0]\", \"padding[1]\" and \"padding[2]\" (resp.) zeros left and right.\n     \"\"\"\n-    if dim_ordering == 'default':\n-        dim_ordering = image_dim_ordering()\n-    if dim_ordering not in {'th', 'tf'}:\n-        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))\n+    if data_format == 'default':\n+        data_format = image_data_format()\n+    if data_format not in {'channels_first', 'channels_last'}:\n+        raise ValueError('Unknown data_format ' + str(data_format))\n \n     input_shape = x.shape\n-    if dim_ordering == 'th':\n+    if data_format == 'channels_first':\n         output_shape = (input_shape[0],\n                         input_shape[1],\n                         input_shape[2] + 2 * padding[0],\n@@ -856,7 +856,7 @@ def spatial_3d_padding(x, padding=(1, 1, 1), dim_ordering='default'):\n                    slice(padding[1], input_shape[3] + padding[1]),\n                    slice(padding[2], input_shape[4] + padding[2]))\n \n-    elif dim_ordering == 'tf':\n+    elif data_format == 'channels_last':\n         output_shape = (input_shape[0],\n                         input_shape[1] + 2 * padding[0],\n                         input_shape[2] + 2 * padding[1],\n@@ -869,7 +869,7 @@ def spatial_3d_padding(x, padding=(1, 1, 1), dim_ordering='default'):\n                    slice(padding[2], input_shape[3] + padding[2]),\n                    slice(None))\n     else:\n-        raise ValueError('Invalid dim_ordering:', dim_ordering)\n+        raise ValueError('Invalid data_format:', data_format)\n     return T.set_subtensor(output[indices], x)\n \n \n@@ -1322,8 +1322,8 @@ def in_top_k(predictions, targets, k):\n \n # CONVOLUTIONS\n \n-def _preprocess_conv2d_input(x, dim_ordering):\n-    if dim_ordering == 'tf':\n+def _preprocess_conv2d_input(x, data_format):\n+    if data_format == 'channels_last':\n         # TF uses the last dimension as channel dimension,\n         # instead of the 2nd one.\n         # TH input shape: (samples, input_depth, rows, cols)\n@@ -1332,8 +1332,8 @@ def _preprocess_conv2d_input(x, dim_ordering):\n     return x\n \n \n-def _preprocess_conv3d_input(x, dim_ordering):\n-    if dim_ordering == 'tf':\n+def _preprocess_conv3d_input(x, data_format):\n+    if data_format == 'channels_last':\n         # TF uses the last dimension as channel dimension,\n         # instead of the 2nd one.\n         # TH input shape: (samples, input_depth, rows, cols, slices)\n@@ -1342,8 +1342,8 @@ def _preprocess_conv3d_input(x, dim_ordering):\n     return x\n \n \n-def _preprocess_conv2d_kernel(kernel, dim_ordering):\n-    if dim_ordering == 'tf':\n+def _preprocess_conv2d_kernel(kernel, data_format):\n+    if data_format == 'channels_last':\n         # TF uses the last dimension as channel dimension,\n         # instead of the 2nd one.\n         # TH kernel shape: (depth, input_depth, rows, cols)\n@@ -1352,8 +1352,8 @@ def _preprocess_conv2d_kernel(kernel, dim_ordering):\n     return kernel\n \n \n-def _preprocess_conv3d_kernel(kernel, dim_ordering):\n-    if dim_ordering == 'tf':\n+def _preprocess_conv3d_kernel(kernel, data_format):\n+    if data_format == 'channels_last':\n         # TF uses the last dimension as channel dimension,\n         # instead of the 2nd one.\n         # TH kernel shape: (depth, input_depth, rows, cols, slices)\n@@ -1374,14 +1374,14 @@ def _preprocess_border_mode(border_mode):\n     return th_border_mode\n \n \n-def _preprocess_conv2d_image_shape(dim_ordering, image_shape):\n+def _preprocess_conv2d_image_shape(data_format, image_shape):\n     # Theano might not accept long type\n     def int_or_none(value):\n         try:\n             return int(value)\n         except TypeError:\n             return None\n-    if dim_ordering == 'tf':\n+    if data_format == 'channels_last':\n         if image_shape:\n             image_shape = (image_shape[0], image_shape[3],\n                            image_shape[1], image_shape[2])\n@@ -1390,14 +1390,14 @@ def _preprocess_conv2d_image_shape(dim_ordering, image_shape):\n     return image_shape\n \n \n-def _preprocess_conv3d_volume_shape(dim_ordering, volume_shape):\n+def _preprocess_conv3d_volume_shape(data_format, volume_shape):\n     # Theano might not accept long type\n     def int_or_none(value):\n         try:\n             return int(value)\n         except TypeError:\n             return None\n-    if dim_ordering == 'tf':\n+    if data_format == 'channels_last':\n         if volume_shape:\n             volume_shape = (volume_shape[0], volume_shape[4],\n                             volume_shape[1], volume_shape[2], volume_shape[3])\n@@ -1406,14 +1406,14 @@ def _preprocess_conv3d_volume_shape(dim_ordering, volume_shape):\n     return volume_shape\n \n \n-def _preprocess_conv2d_filter_shape(dim_ordering, filter_shape):\n+def _preprocess_conv2d_filter_shape(data_format, filter_shape):\n     # Theano might not accept long type\n     def int_or_none(value):\n         try:\n             return int(value)\n         except TypeError:\n             return None\n-    if dim_ordering == 'tf':\n+    if data_format == 'channels_last':\n         if filter_shape:\n             filter_shape = (filter_shape[3], filter_shape[2],\n                             filter_shape[0], filter_shape[1])\n@@ -1422,14 +1422,14 @@ def _preprocess_conv2d_filter_shape(dim_ordering, filter_shape):\n     return filter_shape\n \n \n-def _preprocess_conv3d_filter_shape(dim_ordering, filter_shape):\n+def _preprocess_conv3d_filter_shape(data_format, filter_shape):\n     # Theano might not accept long type\n     def int_or_none(value):\n         try:\n             return int(value)\n         except TypeError:\n             return None\n-    if dim_ordering == 'tf':\n+    if data_format == 'channels_last':\n         if filter_shape:\n             filter_shape = (filter_shape[4], filter_shape[3],\n                             filter_shape[0], filter_shape[1], filter_shape[2])\n@@ -1438,18 +1438,18 @@ def _preprocess_conv3d_filter_shape(dim_ordering, filter_shape):\n     return filter_shape\n \n \n-def _postprocess_conv2d_output(conv_out, x, border_mode, np_kernel, strides, dim_ordering):\n+def _postprocess_conv2d_output(conv_out, x, border_mode, np_kernel, strides, data_format):\n     if border_mode == 'same':\n         if np_kernel.shape[2] % 2 == 0:\n             conv_out = conv_out[:, :, :(x.shape[2] + strides[0] - 1) // strides[0], :]\n         if np_kernel.shape[3] % 2 == 0:\n             conv_out = conv_out[:, :, :, :(x.shape[3] + strides[1] - 1) // strides[1]]\n-    if dim_ordering == 'tf':\n+    if data_format == 'channels_last':\n         conv_out = conv_out.dimshuffle((0, 2, 3, 1))\n     return conv_out\n \n \n-def _postprocess_conv3d_output(conv_out, x, border_mode, np_kernel, strides, dim_ordering):\n+def _postprocess_conv3d_output(conv_out, x, border_mode, np_kernel, strides, data_format):\n     if border_mode == 'same':\n         if np_kernel.shape[2] % 2 == 0:\n             conv_out = conv_out[:, :, :(x.shape[2] + strides[0] - 1) // strides[0], :, :]\n@@ -1457,7 +1457,7 @@ def _postprocess_conv3d_output(conv_out, x, border_mode, np_kernel, strides, dim\n             conv_out = conv_out[:, :, :, :(x.shape[3] + strides[1] - 1) // strides[1], :]\n         if np_kernel.shape[4] % 2 == 0:\n             conv_out = conv_out[:, :, :, :, :(x.shape[4] + strides[2] - 1) // strides[2]]\n-    if dim_ordering == 'tf':\n+    if data_format == 'channels_last':\n         conv_out = conv_out.dimshuffle((0, 2, 3, 4, 1))\n     return conv_out\n \n@@ -1475,7 +1475,7 @@ def conv1d(x, kernel, stride=1, border_mode='valid',\n \n \n def conv2d(x, kernel, strides=(1, 1), border_mode='valid',\n-           dim_ordering='default', image_shape=None,\n+           data_format='default', image_shape=None,\n            filter_shape=None, filter_dilation=(1, 1)):\n     \"\"\"2D convolution.\n \n@@ -1483,21 +1483,21 @@ def conv2d(x, kernel, strides=(1, 1), border_mode='valid',\n         kernel: kernel tensor.\n         strides: strides tuple.\n         border_mode: string, \"same\" or \"valid\".\n-        dim_ordering: \"tf\" or \"th\".\n-            Whether to use Theano or TensorFlow dimension ordering\n+        data_format: \"channels_last\" or \"channels_first\".\n+            Whether to use Theano or TensorFlow data format\n         in inputs/kernels/ouputs.\n     \"\"\"\n-    if dim_ordering == 'default':\n-        dim_ordering = image_dim_ordering()\n-    if dim_ordering not in {'th', 'tf'}:\n-        raise ValueError('Unknown dim_ordering ', dim_ordering)\n+    if data_format == 'default':\n+        data_format = image_data_format()\n+    if data_format not in {'channels_first', 'channels_last'}:\n+        raise ValueError('Unknown data_format ', data_format)\n \n-    x = _preprocess_conv2d_input(x, dim_ordering)\n-    kernel = _preprocess_conv2d_kernel(kernel, dim_ordering)\n+    x = _preprocess_conv2d_input(x, data_format)\n+    kernel = _preprocess_conv2d_kernel(kernel, data_format)\n     th_border_mode = _preprocess_border_mode(border_mode)\n     np_kernel = kernel.eval()\n-    image_shape = _preprocess_conv2d_image_shape(dim_ordering, image_shape)\n-    filter_shape = _preprocess_conv2d_filter_shape(dim_ordering, filter_shape)\n+    image_shape = _preprocess_conv2d_image_shape(data_format, image_shape)\n+    filter_shape = _preprocess_conv2d_filter_shape(data_format, filter_shape)\n \n     # TODO: remove the if statement when theano with no filter dilation is deprecated.\n     if filter_dilation == (1, 1):\n@@ -1515,13 +1515,13 @@ def conv2d(x, kernel, strides=(1, 1), border_mode='valid',\n                                  filter_dilation=filter_dilation)\n \n     conv_out = _postprocess_conv2d_output(conv_out, x, border_mode, np_kernel,\n-                                          strides, dim_ordering)\n+                                          strides, data_format)\n     return conv_out\n \n \n def deconv2d(x, kernel, output_shape, strides=(1, 1),\n              border_mode='valid',\n-             dim_ordering='default',\n+             data_format='default',\n              image_shape=None, filter_shape=None):\n     \"\"\"2D deconvolution (transposed convolution).\n \n@@ -1530,22 +1530,22 @@ def deconv2d(x, kernel, output_shape, strides=(1, 1),\n         output_shape: desired dimensions of output.\n         strides: strides tuple.\n         border_mode: string, \"same\" or \"valid\".\n-        dim_ordering: \"tf\" or \"th\".\n-            Whether to use Theano or TensorFlow dimension ordering\n+        data_format: \"channels_last\" or \"channels_first\".\n+            Whether to use Theano or TensorFlow data format\n         in inputs/kernels/ouputs.\n     \"\"\"\n     flip_filters = False\n-    if dim_ordering == 'default':\n-        dim_ordering = image_dim_ordering()\n-    if dim_ordering not in {'th', 'tf'}:\n-        raise ValueError('Unknown dim_ordering ' + dim_ordering)\n+    if data_format == 'default':\n+        data_format = image_data_format()\n+    if data_format not in {'channels_first', 'channels_last'}:\n+        raise ValueError('Unknown data_format ' + data_format)\n \n-    x = _preprocess_conv2d_input(x, dim_ordering)\n-    kernel = _preprocess_conv2d_kernel(kernel, dim_ordering)\n+    x = _preprocess_conv2d_input(x, data_format)\n+    kernel = _preprocess_conv2d_kernel(kernel, data_format)\n     kernel = kernel.dimshuffle((1, 0, 2, 3))\n     th_border_mode = _preprocess_border_mode(border_mode)\n     np_kernel = kernel.eval()\n-    filter_shape = _preprocess_conv2d_filter_shape(dim_ordering, filter_shape)\n+    filter_shape = _preprocess_conv2d_filter_shape(data_format, filter_shape)\n     filter_shape = tuple(filter_shape[i] for i in (1, 0, 2, 3))\n \n     op = T.nnet.abstract_conv.AbstractConv2d_gradInputs(imshp=output_shape,\n@@ -1556,24 +1556,24 @@ def deconv2d(x, kernel, output_shape, strides=(1, 1),\n     conv_out = op(kernel, x, output_shape[2:])\n \n     conv_out = _postprocess_conv2d_output(conv_out, x, border_mode, np_kernel,\n-                                          strides, dim_ordering)\n+                                          strides, data_format)\n     return conv_out\n \n \n def atrous_conv2d(x, kernel, rate=1,\n                   border_mode='valid',\n-                  dim_ordering='default',\n+                  data_format='default',\n                   image_shape=None, filter_shape=None):\n     raise NotImplementedError\n \n \n def separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1),\n-                     border_mode='valid', dim_ordering='default'):\n+                     border_mode='valid', data_format='default'):\n     raise NotImplementedError\n \n \n def conv3d(x, kernel, strides=(1, 1, 1),\n-           border_mode='valid', dim_ordering='default',\n+           border_mode='valid', data_format='default',\n            volume_shape=None, filter_shape=None,\n            filter_dilation=(1, 1, 1)):\n     \"\"\"3D convolution.\n@@ -1582,14 +1582,14 @@ def conv3d(x, kernel, strides=(1, 1, 1),\n         kernel: kernel tensor.\n         strides: strides tuple.\n         border_mode: string, \"same\" or \"valid\".\n-        dim_ordering: \"tf\" or \"th\".\n-            Whether to use Theano or TensorFlow dimension ordering\n+        data_format: \"channels_last\" or \"channels_first\".\n+            Whether to use Theano or TensorFlow data format\n         in inputs/kernels/ouputs.\n     \"\"\"\n-    if dim_ordering == 'default':\n-        dim_ordering = image_dim_ordering()\n-    if dim_ordering not in {'th', 'tf'}:\n-        raise ValueError('Unknown dim_ordering:', dim_ordering)\n+    if data_format == 'default':\n+        data_format = image_data_format()\n+    if data_format not in {'channels_first', 'channels_last'}:\n+        raise ValueError('Unknown data_format:', data_format)\n \n     # TODO: remove this if statement when Theano without AbstractConv3d is deprecated\n     if not hasattr(T.nnet, 'conv3d'):\n@@ -1598,14 +1598,14 @@ def conv3d(x, kernel, strides=(1, 1, 1),\n                              '0.9.0dev3 or newer.')\n \n         return _old_theano_conv3d(x, kernel, strides, border_mode,\n-                                  dim_ordering, volume_shape, filter_shape)\n+                                  data_format, volume_shape, filter_shape)\n \n-    x = _preprocess_conv3d_input(x, dim_ordering)\n-    kernel = _preprocess_conv3d_kernel(kernel, dim_ordering)\n+    x = _preprocess_conv3d_input(x, data_format)\n+    kernel = _preprocess_conv3d_kernel(kernel, data_format)\n     th_border_mode = _preprocess_border_mode(border_mode)\n     np_kernel = kernel.eval()\n-    volume_shape = _preprocess_conv3d_volume_shape(dim_ordering, volume_shape)\n-    filter_shape = _preprocess_conv3d_filter_shape(dim_ordering, filter_shape)\n+    volume_shape = _preprocess_conv3d_volume_shape(data_format, volume_shape)\n+    filter_shape = _preprocess_conv3d_filter_shape(data_format, filter_shape)\n \n     conv_out = T.nnet.conv3d(x, kernel,\n                              border_mode=th_border_mode,\n@@ -1615,26 +1615,26 @@ def conv3d(x, kernel, strides=(1, 1, 1),\n                              filter_dilation=filter_dilation)\n \n     conv_out = _postprocess_conv3d_output(conv_out, x, border_mode, np_kernel,\n-                                          strides, dim_ordering)\n+                                          strides, data_format)\n     return conv_out\n \n \n # TODO: remove this function when theano without AbstractConv3d is deprecated\n def _old_theano_conv3d(x, kernel, strides=(1, 1, 1),\n-                       border_mode='valid', dim_ordering='default',\n+                       border_mode='valid', data_format='default',\n                        volume_shape=None, filter_shape=None):\n     \"\"\"\n     Run on cuDNN if available.\n     border_mode: string, \"same\" or \"valid\".\n     \"\"\"\n-    if dim_ordering == 'default':\n-        dim_ordering = image_dim_ordering()\n-    if dim_ordering not in {'th', 'tf'}:\n-        raise ValueError('Unknown dim_ordering:', dim_ordering)\n+    if data_format == 'default':\n+        data_format = image_data_format()\n+    if data_format not in {'channels_first', 'channels_last'}:\n+        raise ValueError('Unknown data_format:', data_format)\n     if border_mode not in {'same', 'valid'}:\n         raise ValueError('Invalid border mode:', border_mode)\n \n-    if dim_ordering == 'tf':\n+    if data_format == 'channels_last':\n         # TF uses the last dimension as channel dimension,\n         # instead of the 2nd one.\n         # TH input shape: (samples, input_depth, conv_dim1, conv_dim2, conv_dim3)\n@@ -1677,18 +1677,18 @@ def _old_theano_conv3d(x, kernel, strides=(1, 1, 1),\n     if strides != (1, 1, 1):\n         conv_out = conv_out[:, :, ::strides[0], ::strides[1], ::strides[2]]\n \n-    if dim_ordering == 'tf':\n+    if data_format == 'channels_last':\n         conv_out = conv_out.dimshuffle((0, 2, 3, 4, 1))\n \n     return conv_out\n \n \n def pool2d(x, pool_size, strides=(1, 1), border_mode='valid',\n-           dim_ordering='default', pool_mode='max'):\n-    if dim_ordering == 'default':\n-        dim_ordering = image_dim_ordering()\n-    if dim_ordering not in {'th', 'tf'}:\n-        raise ValueError('Unknown dim_ordering:', dim_ordering)\n+           data_format='default', pool_mode='max'):\n+    if data_format == 'default':\n+        data_format = image_data_format()\n+    if data_format not in {'channels_first', 'channels_last'}:\n+        raise ValueError('Unknown data_format:', data_format)\n \n     assert pool_size[0] >= 1 and pool_size[1] >= 1\n \n@@ -1701,10 +1701,10 @@ def pool2d(x, pool_size, strides=(1, 1), border_mode='valid',\n     else:\n         raise ValueError('Invalid border mode:', border_mode)\n \n-    if dim_ordering not in {'th', 'tf'}:\n-        raise ValueError('Unknown dim_ordering:', dim_ordering)\n+    if data_format not in {'channels_first', 'channels_last'}:\n+        raise ValueError('Unknown data_format:', data_format)\n \n-    if dim_ordering == 'tf':\n+    if data_format == 'channels_last':\n         x = x.dimshuffle((0, 3, 1, 2))\n \n     if pool_mode == 'max':\n@@ -1746,23 +1746,23 @@ def pool2d(x, pool_size, strides=(1, 1), border_mode='valid',\n                             : expected_width,\n                             : expected_height]\n \n-    if dim_ordering == 'tf':\n+    if data_format == 'channels_last':\n         pool_out = pool_out.dimshuffle((0, 2, 3, 1))\n     return pool_out\n \n \n def pool3d(x, pool_size, strides=(1, 1, 1), border_mode='valid',\n-           dim_ordering='default', pool_mode='max'):\n-    if dim_ordering == 'default':\n-        dim_ordering = image_dim_ordering()\n-    if dim_ordering not in {'th', 'tf'}:\n-        raise ValueError('Unknown dim_ordering:', dim_ordering)\n+           data_format='default', pool_mode='max'):\n+    if data_format == 'default':\n+        data_format = image_data_format()\n+    if data_format not in {'channels_first', 'channels_last'}:\n+        raise ValueError('Unknown data_format:', data_format)\n \n     # TODO: remove this if statement when Theano without pool_3d is deprecated\n     #       (pool_3d was introduced after 0.9.0dev3)\n     if not hasattr(T.signal.pool, 'pool_3d'):\n         return _old_theano_pool3d(x, pool_size, strides, border_mode,\n-                                  dim_ordering, pool_mode)\n+                                  data_format, pool_mode)\n \n     if border_mode == 'same':\n         w_pad = pool_size[0] - 2 if pool_size[0] % 2 == 1 else pool_size[0] - 1\n@@ -1773,10 +1773,10 @@ def pool3d(x, pool_size, strides=(1, 1, 1), border_mode='valid',\n         padding = (0, 0, 0)\n     else:\n         raise ValueError('Invalid border mode:', border_mode)\n-    if dim_ordering not in {'th', 'tf'}:\n-        raise ValueError('Unknown dim_ordering:', dim_ordering)\n+    if data_format not in {'channels_first', 'channels_last'}:\n+        raise ValueError('Unknown data_format:', data_format)\n \n-    if dim_ordering == 'tf':\n+    if data_format == 'channels_last':\n         x = x.dimshuffle((0, 4, 1, 2, 3))\n \n     if pool_mode == 'max':\n@@ -1820,7 +1820,7 @@ def pool3d(x, pool_size, strides=(1, 1, 1), border_mode='valid',\n                             : expected_height,\n                             : expected_depth]\n \n-    if dim_ordering == 'tf':\n+    if data_format == 'channels_last':\n         pool_out = pool_out.dimshuffle((0, 2, 3, 4, 1))\n     return pool_out\n \n@@ -1828,11 +1828,11 @@ def pool3d(x, pool_size, strides=(1, 1, 1), border_mode='valid',\n # TODO: remove this function when Theano without pool_3d is deprecated\n #       (pool_3d was introduced after 0.9.0dev3)\n def _old_theano_pool3d(x, pool_size, strides=(1, 1, 1), border_mode='valid',\n-                       dim_ordering='default', pool_mode='max'):\n-    if dim_ordering == 'default':\n-        dim_ordering = image_dim_ordering()\n-    if dim_ordering not in {'th', 'tf'}:\n-        raise ValueError('Unknown dim_ordering:', dim_ordering)\n+                       data_format='default', pool_mode='max'):\n+    if data_format == 'default':\n+        data_format = image_data_format()\n+    if data_format not in {'channels_first', 'channels_last'}:\n+        raise ValueError('Unknown data_format:', data_format)\n \n     if border_mode == 'same':\n         # TODO: add implementation for border_mode=\"same\"\n@@ -1843,10 +1843,10 @@ def _old_theano_pool3d(x, pool_size, strides=(1, 1, 1), border_mode='valid',\n     else:\n         raise ValueError('Invalid border mode:', border_mode)\n \n-    if dim_ordering not in {'th', 'tf'}:\n-        raise ValueError('Unknown dim_ordering:', dim_ordering)\n+    if data_format not in {'channels_first', 'channels_last'}:\n+        raise ValueError('Unknown data_format:', data_format)\n \n-    if dim_ordering == 'tf':\n+    if data_format == 'channels_last':\n         x = x.dimshuffle((0, 4, 1, 2, 3))\n \n     if pool_mode == 'max':\n@@ -1885,7 +1885,7 @@ def _old_theano_pool3d(x, pool_size, strides=(1, 1, 1), border_mode='valid',\n     else:\n         raise ValueError('Invalid pooling mode:', pool_mode)\n \n-    if dim_ordering == 'tf':\n+    if data_format == 'channels_last':\n         pool_out = pool_out.dimshuffle((0, 2, 3, 4, 1))\n     return pool_out\n \n\n@@ -25,7 +25,7 @@ class MaxNorm(Constraint):\n             has shape `(input_dim, output_dim)`,\n             set `axis` to `0` to constrain each weight vector\n             of length `(input_dim,)`.\n-            In a `Convolution2D` layer with `dim_ordering=\"tf\"`,\n+            In a `Convolution2D` layer with `data_format=\"channels_last\"`,\n             the weight tensor has shape\n             `(rows, cols, input_depth, output_depth)`,\n             set `axis` to `[0, 1, 2]`\n@@ -70,7 +70,7 @@ class UnitNorm(Constraint):\n             has shape `(input_dim, output_dim)`,\n             set `axis` to `0` to constrain each weight vector\n             of length `(input_dim,)`.\n-            In a `Convolution2D` layer with `dim_ordering=\"tf\"`,\n+            In a `Convolution2D` layer with `data_format=\"channels_last\"`,\n             the weight tensor has shape\n             `(rows, cols, input_depth, output_depth)`,\n             set `axis` to `[0, 1, 2]`\n\n@@ -33,7 +33,7 @@ def load_data():\n     y_train = np.reshape(y_train, (len(y_train), 1))\n     y_test = np.reshape(y_test, (len(y_test), 1))\n \n-    if K.image_dim_ordering() == 'tf':\n+    if K.image_data_format() == 'channels_last':\n         x_train = x_train.transpose(0, 2, 3, 1)\n         x_test = x_test.transpose(0, 2, 3, 1)\n \n\n@@ -34,7 +34,7 @@ def load_data(label_mode='fine'):\n     y_train = np.reshape(y_train, (len(y_train), 1))\n     y_test = np.reshape(y_test, (len(y_test), 1))\n \n-    if K.image_dim_ordering() == 'tf':\n+    if K.image_data_format() == 'channels_last':\n         x_train = x_train.transpose(0, 2, 3, 1)\n         x_test = x_test.transpose(0, 2, 3, 1)\n \n\n@@ -4,7 +4,7 @@ from . import backend as K\n from .utils.generic_utils import get_from_module\n \n \n-def get_fans(shape, dim_ordering='th'):\n+def get_fans(shape, data_format='channels_first'):\n     if len(shape) == 2:\n         fan_in = shape[0]\n         fan_out = shape[1]\n@@ -12,16 +12,16 @@ def get_fans(shape, dim_ordering='th'):\n         # Assuming convolution kernels (2D or 3D).\n         # TH kernel shape: (depth, input_depth, ...)\n         # TF kernel shape: (..., input_depth, depth)\n-        if dim_ordering == 'th':\n+        if data_format == 'channels_first':\n             receptive_field_size = np.prod(shape[2:])\n             fan_in = shape[1] * receptive_field_size\n             fan_out = shape[0] * receptive_field_size\n-        elif dim_ordering == 'tf':\n+        elif data_format == 'channels_last':\n             receptive_field_size = np.prod(shape[:2])\n             fan_in = shape[-2] * receptive_field_size\n             fan_out = shape[-1] * receptive_field_size\n         else:\n-            raise ValueError('Invalid dim_ordering: ' + dim_ordering)\n+            raise ValueError('Invalid data_format: ' + data_format)\n     else:\n         # No specific assumptions.\n         fan_in = np.sqrt(np.prod(shape))\n@@ -29,63 +29,63 @@ def get_fans(shape, dim_ordering='th'):\n     return fan_in, fan_out\n \n \n-def uniform(shape, scale=0.05, name=None, dim_ordering='th'):\n+def uniform(shape, scale=0.05, name=None, data_format='channels_first'):\n     return K.random_uniform_variable(shape, -scale, scale, name=name)\n \n \n-def normal(shape, scale=0.05, name=None, dim_ordering='th'):\n+def normal(shape, scale=0.05, name=None, data_format='channels_first'):\n     return K.random_normal_variable(shape, 0.0, scale, name=name)\n \n \n-def lecun_uniform(shape, name=None, dim_ordering='th'):\n+def lecun_uniform(shape, name=None, data_format='channels_first'):\n     \"\"\"LeCun uniform variance scaling initializer.\n \n     # References\n         LeCun 98, Efficient Backprop,\n         http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf\n     \"\"\"\n-    fan_in, fan_out = get_fans(shape, dim_ordering=dim_ordering)\n+    fan_in, fan_out = get_fans(shape, data_format=data_format)\n     scale = np.sqrt(3. / fan_in)\n     return uniform(shape, scale, name=name)\n \n \n-def glorot_normal(shape, name=None, dim_ordering='th'):\n+def glorot_normal(shape, name=None, data_format='channels_first'):\n     \"\"\"Glorot normal variance scaling initializer.\n \n     # References\n         Glorot & Bengio, AISTATS 2010\n     \"\"\"\n-    fan_in, fan_out = get_fans(shape, dim_ordering=dim_ordering)\n+    fan_in, fan_out = get_fans(shape, data_format=data_format)\n     s = np.sqrt(2. / (fan_in + fan_out))\n     return normal(shape, s, name=name)\n \n \n-def glorot_uniform(shape, name=None, dim_ordering='th'):\n-    fan_in, fan_out = get_fans(shape, dim_ordering=dim_ordering)\n+def glorot_uniform(shape, name=None, data_format='channels_first'):\n+    fan_in, fan_out = get_fans(shape, data_format=data_format)\n     s = np.sqrt(6. / (fan_in + fan_out))\n     return uniform(shape, s, name=name)\n \n \n-def he_normal(shape, name=None, dim_ordering='th'):\n+def he_normal(shape, name=None, data_format='channels_first'):\n     \"\"\"He normal variance scaling initializer.\n \n     # References\n         He et al., http://arxiv.org/abs/1502.01852\n     \"\"\"\n-    fan_in, fan_out = get_fans(shape, dim_ordering=dim_ordering)\n+    fan_in, fan_out = get_fans(shape, data_format=data_format)\n     s = np.sqrt(2. / fan_in)\n     return normal(shape, s, name=name)\n \n \n-def he_uniform(shape, name=None, dim_ordering='th'):\n+def he_uniform(shape, name=None, data_format='channels_first'):\n     \"\"\"He uniform variance scaling initializer.\n     \"\"\"\n-    fan_in, fan_out = get_fans(shape, dim_ordering=dim_ordering)\n+    fan_in, fan_out = get_fans(shape, data_format=data_format)\n     s = np.sqrt(6. / fan_in)\n     return uniform(shape, s, name=name)\n \n \n-def orthogonal(shape, scale=1.1, name=None, dim_ordering='th'):\n+def orthogonal(shape, scale=1.1, name=None, data_format='channels_first'):\n     \"\"\"Orthogonal initializer.\n \n     # References\n@@ -100,7 +100,7 @@ def orthogonal(shape, scale=1.1, name=None, dim_ordering='th'):\n     return K.variable(scale * q[:shape[0], :shape[1]], name=name)\n \n \n-def identity(shape, scale=1, name=None, dim_ordering='th'):\n+def identity(shape, scale=1, name=None, data_format='channels_first'):\n     if len(shape) != 2 or shape[0] != shape[1]:\n         raise ValueError('Identity matrix initialization can only be used '\n                          'for 2D square matrices.')\n@@ -108,11 +108,11 @@ def identity(shape, scale=1, name=None, dim_ordering='th'):\n         return K.variable(scale * np.identity(shape[0]), name=name)\n \n \n-def zero(shape, name=None, dim_ordering='th'):\n+def zero(shape, name=None, data_format='channels_first'):\n     return K.zeros(shape, name=name)\n \n \n-def one(shape, name=None, dim_ordering='th'):\n+def one(shape, name=None, data_format='channels_first'):\n     return K.ones(shape, name=name)\n \n \n\n@@ -131,7 +131,7 @@ class Convolution1D(Layer):\n \n         self.W = self.add_weight(self.W_shape,\n                                  initializer=functools.partial(self.init,\n-                                                               dim_ordering='th'),\n+                                                               data_format='channels_first'),\n                                  name='{}_W'.format(self.name),\n                                  regularizer=self.W_regularizer,\n                                  constraint=self.W_constraint)\n@@ -160,7 +160,7 @@ class Convolution1D(Layer):\n         x = K.expand_dims(x, 2)  # add a dummy dimension\n         output = K.conv2d(x, self.W, strides=self.subsample,\n                           border_mode=self.border_mode,\n-                          dim_ordering='tf')\n+                          data_format='channels_last')\n         output = K.squeeze(output, 2)  # remove the dummy dimension\n         if self.bias:\n             output += K.reshape(self.b, (1, 1, self.nb_filter))\n@@ -297,7 +297,7 @@ class AtrousConvolution1D(Convolution1D):\n         x = K.expand_dims(x, 2)  # add a dummy dimension\n         output = K.conv2d(x, self.W, strides=self.subsample,\n                           border_mode=self.border_mode,\n-                          dim_ordering='tf',\n+                          data_format='channels_last',\n                           filter_dilation=(self.atrous_rate, self.atrous_rate))\n         output = K.squeeze(output, 2)  # remove the dummy dimension\n         if self.bias:\n@@ -363,37 +363,37 @@ class Convolution2D(Layer):\n             (eg. maxnorm, nonneg), applied to the main weights matrix.\n         b_constraint: instance of the [constraints](../constraints.md) module,\n             applied to the bias.\n-        dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension\n-            (the depth) is at index 1, in 'tf' mode is it at index 3.\n-            It defaults to the `image_dim_ordering` value found in your\n+        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension\n+            (the depth) is at index 1, in 'channels_last' mode is it at index 3.\n+            It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"tf\".\n+            If you never set it, then it will be \"channels_last\".\n         bias: whether to include a bias\n             (i.e. make the layer affine rather than linear).\n \n     # Input shape\n         4D tensor with shape:\n-        `(samples, channels, rows, cols)` if dim_ordering='th'\n+        `(samples, channels, rows, cols)` if data_format='channels_first'\n         or 4D tensor with shape:\n-        `(samples, rows, cols, channels)` if dim_ordering='tf'.\n+        `(samples, rows, cols, channels)` if data_format='channels_last'.\n \n     # Output shape\n         4D tensor with shape:\n-        `(samples, nb_filter, new_rows, new_cols)` if dim_ordering='th'\n+        `(samples, nb_filter, new_rows, new_cols)` if data_format='channels_first'\n         or 4D tensor with shape:\n-        `(samples, new_rows, new_cols, nb_filter)` if dim_ordering='tf'.\n+        `(samples, new_rows, new_cols, nb_filter)` if data_format='channels_last'.\n         `rows` and `cols` values might have changed due to padding.\n     \"\"\"\n \n     def __init__(self, nb_filter, nb_row, nb_col,\n                  init='glorot_uniform', activation=None, weights=None,\n-                 border_mode='valid', subsample=(1, 1), dim_ordering='default',\n+                 border_mode='valid', subsample=(1, 1), data_format='default',\n                  W_regularizer=None, b_regularizer=None,\n                  activity_regularizer=None,\n                  W_constraint=None, b_constraint=None,\n                  bias=True, **kwargs):\n-        if dim_ordering == 'default':\n-            dim_ordering = K.image_dim_ordering()\n+        if data_format == 'default':\n+            data_format = K.image_data_format()\n         if border_mode not in {'valid', 'same', 'full'}:\n             raise ValueError('Invalid border mode for Convolution2D:', border_mode)\n         self.nb_filter = nb_filter\n@@ -403,9 +403,9 @@ class Convolution2D(Layer):\n         self.activation = activations.get(activation)\n         self.border_mode = border_mode\n         self.subsample = tuple(subsample)\n-        if dim_ordering not in {'tf', 'th'}:\n-            raise ValueError('dim_ordering must be in {tf, th}.')\n-        self.dim_ordering = dim_ordering\n+        if data_format not in {'channels_last', 'channels_first'}:\n+            raise ValueError('data_format must be in {\"channels_last\", \"channels_first\"}.')\n+        self.data_format = data_format\n \n         self.W_regularizer = regularizers.get(W_regularizer)\n         self.b_regularizer = regularizers.get(b_regularizer)\n@@ -420,17 +420,17 @@ class Convolution2D(Layer):\n         super(Convolution2D, self).__init__(**kwargs)\n \n     def build(self, input_shape):\n-        if self.dim_ordering == 'th':\n+        if self.data_format == 'channels_first':\n             stack_size = input_shape[1]\n             self.W_shape = (self.nb_filter, stack_size, self.nb_row, self.nb_col)\n-        elif self.dim_ordering == 'tf':\n+        elif self.data_format == 'channels_last':\n             stack_size = input_shape[3]\n             self.W_shape = (self.nb_row, self.nb_col, stack_size, self.nb_filter)\n         else:\n-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n+            raise ValueError('Invalid data_format:', self.data_format)\n         self.W = self.add_weight(self.W_shape,\n                                  initializer=functools.partial(self.init,\n-                                                               dim_ordering=self.dim_ordering),\n+                                                               data_format=self.data_format),\n                                  name='{}_W'.format(self.name),\n                                  regularizer=self.W_regularizer,\n                                  constraint=self.W_constraint)\n@@ -449,37 +449,37 @@ class Convolution2D(Layer):\n         self.built = True\n \n     def get_output_shape_for(self, input_shape):\n-        if self.dim_ordering == 'th':\n+        if self.data_format == 'channels_first':\n             rows = input_shape[2]\n             cols = input_shape[3]\n-        elif self.dim_ordering == 'tf':\n+        elif self.data_format == 'channels_last':\n             rows = input_shape[1]\n             cols = input_shape[2]\n         else:\n-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n+            raise ValueError('Invalid data_format:', self.data_format)\n \n         rows = conv_output_length(rows, self.nb_row,\n                                   self.border_mode, self.subsample[0])\n         cols = conv_output_length(cols, self.nb_col,\n                                   self.border_mode, self.subsample[1])\n \n-        if self.dim_ordering == 'th':\n+        if self.data_format == 'channels_first':\n             return (input_shape[0], self.nb_filter, rows, cols)\n-        elif self.dim_ordering == 'tf':\n+        elif self.data_format == 'channels_last':\n             return (input_shape[0], rows, cols, self.nb_filter)\n \n     def call(self, x, mask=None):\n         output = K.conv2d(x, self.W, strides=self.subsample,\n                           border_mode=self.border_mode,\n-                          dim_ordering=self.dim_ordering,\n+                          data_format=self.data_format,\n                           filter_shape=self.W_shape)\n         if self.bias:\n-            if self.dim_ordering == 'th':\n+            if self.data_format == 'channels_first':\n                 output += K.reshape(self.b, (1, self.nb_filter, 1, 1))\n-            elif self.dim_ordering == 'tf':\n+            elif self.data_format == 'channels_last':\n                 output += K.reshape(self.b, (1, 1, 1, self.nb_filter))\n             else:\n-                raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n+                raise ValueError('Invalid data_format:', self.data_format)\n         output = self.activation(output)\n         return output\n \n@@ -491,7 +491,7 @@ class Convolution2D(Layer):\n                   'activation': self.activation.__name__,\n                   'border_mode': self.border_mode,\n                   'subsample': self.subsample,\n-                  'dim_ordering': self.dim_ordering,\n+                  'data_format': self.data_format,\n                   'W_regularizer': self.W_regularizer.get_config() if self.W_regularizer else None,\n                   'b_regularizer': self.b_regularizer.get_config() if self.b_regularizer else None,\n                   'activity_regularizer': self.activity_regularizer.get_config() if self.activity_regularizer else None,\n@@ -595,25 +595,25 @@ class Deconvolution2D(Convolution2D):\n             (eg. maxnorm, nonneg), applied to the main weights matrix.\n         b_constraint: instance of the [constraints](../constraints.md) module,\n             applied to the bias.\n-        dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension\n-            (the depth) is at index 1, in 'tf' mode is it at index 3.\n-            It defaults to the `image_dim_ordering` value found in your\n+        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension\n+            (the depth) is at index 1, in 'channels_last' mode is it at index 3.\n+            It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"tf\".\n+            If you never set it, then it will be \"channels_last\".\n         bias: whether to include a bias\n             (i.e. make the layer affine rather than linear).\n \n     # Input shape\n         4D tensor with shape:\n-        `(samples, channels, rows, cols)` if dim_ordering='th'\n+        `(samples, channels, rows, cols)` if data_format='channels_first'\n         or 4D tensor with shape:\n-        `(samples, rows, cols, channels)` if dim_ordering='tf'.\n+        `(samples, rows, cols, channels)` if data_format='channels_last'.\n \n     # Output shape\n         4D tensor with shape:\n-        `(samples, nb_filter, new_rows, new_cols)` if dim_ordering='th'\n+        `(samples, nb_filter, new_rows, new_cols)` if data_format='channels_first'\n         or 4D tensor with shape:\n-        `(samples, new_rows, new_cols, nb_filter)` if dim_ordering='tf'.\n+        `(samples, new_rows, new_cols, nb_filter)` if data_format='channels_last'.\n         `rows` and `cols` values might have changed due to padding.\n \n     # References\n@@ -625,12 +625,12 @@ class Deconvolution2D(Convolution2D):\n     def __init__(self, nb_filter, nb_row, nb_col, output_shape,\n                  init='glorot_uniform', activation=None, weights=None,\n                  border_mode='valid', subsample=(1, 1),\n-                 dim_ordering='default',\n+                 data_format='default',\n                  W_regularizer=None, b_regularizer=None, activity_regularizer=None,\n                  W_constraint=None, b_constraint=None,\n                  bias=True, **kwargs):\n-        if dim_ordering == 'default':\n-            dim_ordering = K.image_dim_ordering()\n+        if data_format == 'default':\n+            data_format = K.image_data_format()\n         if border_mode not in {'valid', 'same', 'full'}:\n             raise ValueError('Invalid border mode for Deconvolution2D:', border_mode)\n \n@@ -642,7 +642,7 @@ class Deconvolution2D(Convolution2D):\n                                               weights=weights,\n                                               border_mode=border_mode,\n                                               subsample=subsample,\n-                                              dim_ordering=dim_ordering,\n+                                              data_format=data_format,\n                                               W_regularizer=W_regularizer,\n                                               b_regularizer=b_regularizer,\n                                               activity_regularizer=activity_regularizer,\n@@ -652,33 +652,33 @@ class Deconvolution2D(Convolution2D):\n                                               **kwargs)\n \n     def get_output_shape_for(self, input_shape):\n-        if self.dim_ordering == 'th':\n+        if self.data_format == 'channels_first':\n             rows = self.output_shape_[2]\n             cols = self.output_shape_[3]\n-        elif self.dim_ordering == 'tf':\n+        elif self.data_format == 'channels_last':\n             rows = self.output_shape_[1]\n             cols = self.output_shape_[2]\n         else:\n-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n+            raise ValueError('Invalid data_format:', self.data_format)\n \n-        if self.dim_ordering == 'th':\n+        if self.data_format == 'channels_first':\n             return (input_shape[0], self.nb_filter, rows, cols)\n-        elif self.dim_ordering == 'tf':\n+        elif self.data_format == 'channels_last':\n             return (input_shape[0], rows, cols, self.nb_filter)\n \n     def call(self, x, mask=None):\n         output = K.deconv2d(x, self.W, self.output_shape_,\n                             strides=self.subsample,\n                             border_mode=self.border_mode,\n-                            dim_ordering=self.dim_ordering,\n+                            data_format=self.data_format,\n                             filter_shape=self.W_shape)\n         if self.bias:\n-            if self.dim_ordering == 'th':\n+            if self.data_format == 'channels_first':\n                 output += K.reshape(self.b, (1, self.nb_filter, 1, 1))\n-            elif self.dim_ordering == 'tf':\n+            elif self.data_format == 'channels_last':\n                 output += K.reshape(self.b, (1, 1, 1, self.nb_filter))\n             else:\n-                raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n+                raise ValueError('Invalid data_format:', self.data_format)\n         output = self.activation(output)\n         return output\n \n@@ -742,25 +742,25 @@ class AtrousConvolution2D(Convolution2D):\n             (eg. maxnorm, nonneg), applied to the main weights matrix.\n         b_constraint: instance of the [constraints](../constraints.md) module,\n             applied to the bias.\n-        dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension\n-            (the depth) is at index 1, in 'tf' mode is it at index 3.\n-            It defaults to the `image_dim_ordering` value found in your\n+        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension\n+            (the depth) is at index 1, in 'channels_last' mode is it at index 3.\n+            It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"tf\".\n+            If you never set it, then it will be \"channels_last\".\n         bias: whether to include a bias\n             (i.e. make the layer affine rather than linear).\n \n     # Input shape\n         4D tensor with shape:\n-        `(samples, channels, rows, cols)` if dim_ordering='th'\n+        `(samples, channels, rows, cols)` if data_format='channels_first'\n         or 4D tensor with shape:\n-        `(samples, rows, cols, channels)` if dim_ordering='tf'.\n+        `(samples, rows, cols, channels)` if data_format='channels_last'.\n \n     # Output shape\n         4D tensor with shape:\n-        `(samples, nb_filter, new_rows, new_cols)` if dim_ordering='th'\n+        `(samples, nb_filter, new_rows, new_cols)` if data_format='channels_first'\n         or 4D tensor with shape:\n-        `(samples, new_rows, new_cols, nb_filter)` if dim_ordering='tf'.\n+        `(samples, new_rows, new_cols, nb_filter)` if data_format='channels_last'.\n         `rows` and `cols` values might have changed due to padding.\n \n     # References\n@@ -770,13 +770,13 @@ class AtrousConvolution2D(Convolution2D):\n     def __init__(self, nb_filter, nb_row, nb_col,\n                  init='glorot_uniform', activation=None, weights=None,\n                  border_mode='valid', subsample=(1, 1),\n-                 atrous_rate=(1, 1), dim_ordering='default',\n+                 atrous_rate=(1, 1), data_format='default',\n                  W_regularizer=None, b_regularizer=None,\n                  activity_regularizer=None,\n                  W_constraint=None, b_constraint=None,\n                  bias=True, **kwargs):\n-        if dim_ordering == 'default':\n-            dim_ordering = K.image_dim_ordering()\n+        if data_format == 'default':\n+            data_format = K.image_data_format()\n \n         if border_mode not in {'valid', 'same', 'full'}:\n             raise ValueError('Invalid border mode for AtrousConv2D:', border_mode)\n@@ -789,7 +789,7 @@ class AtrousConvolution2D(Convolution2D):\n                                                   weights=weights,\n                                                   border_mode=border_mode,\n                                                   subsample=subsample,\n-                                                  dim_ordering=dim_ordering,\n+                                                  data_format=data_format,\n                                                   W_regularizer=W_regularizer,\n                                                   b_regularizer=b_regularizer,\n                                                   activity_regularizer=activity_regularizer,\n@@ -799,14 +799,14 @@ class AtrousConvolution2D(Convolution2D):\n                                                   **kwargs)\n \n     def get_output_shape_for(self, input_shape):\n-        if self.dim_ordering == 'th':\n+        if self.data_format == 'channels_first':\n             rows = input_shape[2]\n             cols = input_shape[3]\n-        elif self.dim_ordering == 'tf':\n+        elif self.data_format == 'channels_last':\n             rows = input_shape[1]\n             cols = input_shape[2]\n         else:\n-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n+            raise ValueError('Invalid data_format:', self.data_format)\n \n         rows = conv_output_length(rows, self.nb_row, self.border_mode,\n                                   self.subsample[0],\n@@ -815,24 +815,24 @@ class AtrousConvolution2D(Convolution2D):\n                                   self.subsample[1],\n                                   dilation=self.atrous_rate[1])\n \n-        if self.dim_ordering == 'th':\n+        if self.data_format == 'channels_first':\n             return (input_shape[0], self.nb_filter, rows, cols)\n-        elif self.dim_ordering == 'tf':\n+        elif self.data_format == 'channels_last':\n             return (input_shape[0], rows, cols, self.nb_filter)\n \n     def call(self, x, mask=None):\n         output = K.conv2d(x, self.W, strides=self.subsample,\n                           border_mode=self.border_mode,\n-                          dim_ordering=self.dim_ordering,\n+                          data_format=self.data_format,\n                           filter_shape=self.W_shape,\n                           filter_dilation=self.atrous_rate)\n         if self.bias:\n-            if self.dim_ordering == 'th':\n+            if self.data_format == 'channels_first':\n                 output += K.reshape(self.b, (1, self.nb_filter, 1, 1))\n-            elif self.dim_ordering == 'tf':\n+            elif self.data_format == 'channels_last':\n                 output += K.reshape(self.b, (1, 1, 1, self.nb_filter))\n             else:\n-                raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n+                raise ValueError('Invalid data_format:', self.data_format)\n         output = self.activation(output)\n         return output\n \n@@ -900,32 +900,32 @@ class SeparableConvolution2D(Layer):\n             (eg. maxnorm, nonneg), applied to the pointwise weights matrix.\n         b_constraint: instance of the [constraints](../constraints.md) module,\n             applied to the bias.\n-        dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension\n-            (the depth) is at index 1, in 'tf' mode is it at index 3.\n-            It defaults to the `image_dim_ordering` value found in your\n+        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension\n+            (the depth) is at index 1, in 'channels_last' mode is it at index 3.\n+            It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"tf\".\n+            If you never set it, then it will be \"channels_last\".\n         bias: whether to include a bias\n             (i.e. make the layer affine rather than linear).\n \n     # Input shape\n         4D tensor with shape:\n-        `(samples, channels, rows, cols)` if dim_ordering='th'\n+        `(samples, channels, rows, cols)` if data_format='channels_first'\n         or 4D tensor with shape:\n-        `(samples, rows, cols, channels)` if dim_ordering='tf'.\n+        `(samples, rows, cols, channels)` if data_format='channels_last'.\n \n     # Output shape\n         4D tensor with shape:\n-        `(samples, nb_filter, new_rows, new_cols)` if dim_ordering='th'\n+        `(samples, nb_filter, new_rows, new_cols)` if data_format='channels_first'\n         or 4D tensor with shape:\n-        `(samples, new_rows, new_cols, nb_filter)` if dim_ordering='tf'.\n+        `(samples, new_rows, new_cols, nb_filter)` if data_format='channels_last'.\n         `rows` and `cols` values might have changed due to padding.\n     \"\"\"\n \n     def __init__(self, nb_filter, nb_row, nb_col,\n                  init='glorot_uniform', activation=None, weights=None,\n                  border_mode='valid', subsample=(1, 1),\n-                 depth_multiplier=1, dim_ordering='default',\n+                 depth_multiplier=1, data_format='default',\n                  depthwise_regularizer=None, pointwise_regularizer=None,\n                  b_regularizer=None, activity_regularizer=None,\n                  depthwise_constraint=None, pointwise_constraint=None,\n@@ -936,8 +936,8 @@ class SeparableConvolution2D(Layer):\n             raise RuntimeError('SeparableConv2D is only available '\n                                'with TensorFlow for the time being.')\n \n-        if dim_ordering == 'default':\n-            dim_ordering = K.image_dim_ordering()\n+        if data_format == 'default':\n+            data_format = K.image_data_format()\n \n         if border_mode not in {'valid', 'same'}:\n             raise ValueError('Invalid border mode for SeparableConv2D:', border_mode)\n@@ -954,9 +954,9 @@ class SeparableConvolution2D(Layer):\n         self.border_mode = border_mode\n         self.subsample = tuple(subsample)\n         self.depth_multiplier = depth_multiplier\n-        if dim_ordering not in {'tf', 'th'}:\n-            raise ValueError('dim_ordering must be in {tf, th}.')\n-        self.dim_ordering = dim_ordering\n+        if data_format not in {'channels_last', 'channels_first'}:\n+            raise ValueError('data_format must be in {\"channels_last\", \"channels_first\"}.')\n+        self.data_format = data_format\n \n         self.depthwise_regularizer = regularizers.get(depthwise_regularizer)\n         self.pointwise_regularizer = regularizers.get(pointwise_regularizer)\n@@ -973,26 +973,26 @@ class SeparableConvolution2D(Layer):\n         super(SeparableConvolution2D, self).__init__(**kwargs)\n \n     def build(self, input_shape):\n-        if self.dim_ordering == 'th':\n+        if self.data_format == 'channels_first':\n             stack_size = input_shape[1]\n             depthwise_shape = (self.depth_multiplier, stack_size, self.nb_row, self.nb_col)\n             pointwise_shape = (self.nb_filter, self.depth_multiplier * stack_size, 1, 1)\n-        elif self.dim_ordering == 'tf':\n+        elif self.data_format == 'channels_last':\n             stack_size = input_shape[3]\n             depthwise_shape = (self.nb_row, self.nb_col, stack_size, self.depth_multiplier)\n             pointwise_shape = (1, 1, self.depth_multiplier * stack_size, self.nb_filter)\n         else:\n-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n+            raise ValueError('Invalid data_format:', self.data_format)\n \n         self.depthwise_kernel = self.add_weight(depthwise_shape,\n                                                 initializer=functools.partial(self.init,\n-                                                                              dim_ordering=self.dim_ordering),\n+                                                                              data_format=self.data_format),\n                                                 regularizer=self.depthwise_regularizer,\n                                                 constraint=self.depthwise_constraint,\n                                                 name='{}_depthwise_kernel'.format(self.name))\n         self.pointwise_kernel = self.add_weight(pointwise_shape,\n                                                 initializer=functools.partial(self.init,\n-                                                                              dim_ordering=self.dim_ordering),\n+                                                                              data_format=self.data_format),\n                                                 regularizer=self.pointwise_regularizer,\n                                                 constraint=self.pointwise_constraint,\n                                                 name='{}_pointwise_kernel'.format(self.name))\n@@ -1011,40 +1011,40 @@ class SeparableConvolution2D(Layer):\n         self.built = True\n \n     def get_output_shape_for(self, input_shape):\n-        if self.dim_ordering == 'th':\n+        if self.data_format == 'channels_first':\n             rows = input_shape[2]\n             cols = input_shape[3]\n-        elif self.dim_ordering == 'tf':\n+        elif self.data_format == 'channels_last':\n             rows = input_shape[1]\n             cols = input_shape[2]\n         else:\n-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n+            raise ValueError('Invalid data_format:', self.data_format)\n \n         rows = conv_output_length(rows, self.nb_row,\n                                   self.border_mode, self.subsample[0])\n         cols = conv_output_length(cols, self.nb_col,\n                                   self.border_mode, self.subsample[1])\n \n-        if self.dim_ordering == 'th':\n+        if self.data_format == 'channels_first':\n             return (input_shape[0], self.nb_filter, rows, cols)\n-        elif self.dim_ordering == 'tf':\n+        elif self.data_format == 'channels_last':\n             return (input_shape[0], rows, cols, self.nb_filter)\n         else:\n-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n+            raise ValueError('Invalid data_format:', self.data_format)\n \n     def call(self, x, mask=None):\n         output = K.separable_conv2d(x, self.depthwise_kernel,\n                                     self.pointwise_kernel,\n                                     strides=self.subsample,\n                                     border_mode=self.border_mode,\n-                                    dim_ordering=self.dim_ordering)\n+                                    data_format=self.data_format)\n         if self.bias:\n-            if self.dim_ordering == 'th':\n+            if self.data_format == 'channels_first':\n                 output += K.reshape(self.b, (1, self.nb_filter, 1, 1))\n-            elif self.dim_ordering == 'tf':\n+            elif self.data_format == 'channels_last':\n                 output += K.reshape(self.b, (1, 1, 1, self.nb_filter))\n             else:\n-                raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n+                raise ValueError('Invalid data_format:', self.data_format)\n         output = self.activation(output)\n         return output\n \n@@ -1057,7 +1057,7 @@ class SeparableConvolution2D(Layer):\n                   'border_mode': self.border_mode,\n                   'subsample': self.subsample,\n                   'depth_multiplier': self.depth_multiplier,\n-                  'dim_ordering': self.dim_ordering,\n+                  'data_format': self.data_format,\n                   'depthwise_regularizer': self.depthwise_regularizer.get_config() if self.depthwise_regularizer else None,\n                   'pointwise_regularizer': self.depthwise_regularizer.get_config() if self.depthwise_regularizer else None,\n                   'b_regularizer': self.b_regularizer.get_config() if self.b_regularizer else None,\n@@ -1110,36 +1110,36 @@ class Convolution3D(Layer):\n             (eg. maxnorm, nonneg), applied to the main weights matrix.\n         b_constraint: instance of the [constraints](../constraints.md) module,\n             applied to the bias.\n-        dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension\n-            (the depth) is at index 1, in 'tf' mode is it at index 4.\n-            It defaults to the `image_dim_ordering` value found in your\n+        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension\n+            (the depth) is at index 1, in 'channels_last' mode is it at index 4.\n+            It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"tf\".\n+            If you never set it, then it will be \"channels_last\".\n         bias: whether to include a bias\n             (i.e. make the layer affine rather than linear).\n \n     # Input shape\n         5D tensor with shape:\n-        `(samples, channels, conv_dim1, conv_dim2, conv_dim3)` if dim_ordering='th'\n+        `(samples, channels, conv_dim1, conv_dim2, conv_dim3)` if data_format='channels_first'\n         or 5D tensor with shape:\n-        `(samples, conv_dim1, conv_dim2, conv_dim3, channels)` if dim_ordering='tf'.\n+        `(samples, conv_dim1, conv_dim2, conv_dim3, channels)` if data_format='channels_last'.\n \n     # Output shape\n         5D tensor with shape:\n-        `(samples, nb_filter, new_conv_dim1, new_conv_dim2, new_conv_dim3)` if dim_ordering='th'\n+        `(samples, nb_filter, new_conv_dim1, new_conv_dim2, new_conv_dim3)` if data_format='channels_first'\n         or 5D tensor with shape:\n-        `(samples, new_conv_dim1, new_conv_dim2, new_conv_dim3, nb_filter)` if dim_ordering='tf'.\n+        `(samples, new_conv_dim1, new_conv_dim2, new_conv_dim3, nb_filter)` if data_format='channels_last'.\n         `new_conv_dim1`, `new_conv_dim2` and `new_conv_dim3` values might have changed due to padding.\n     \"\"\"\n \n     def __init__(self, nb_filter, kernel_dim1, kernel_dim2, kernel_dim3,\n                  init='glorot_uniform', activation=None, weights=None,\n-                 border_mode='valid', subsample=(1, 1, 1), dim_ordering='default',\n+                 border_mode='valid', subsample=(1, 1, 1), data_format='default',\n                  W_regularizer=None, b_regularizer=None, activity_regularizer=None,\n                  W_constraint=None, b_constraint=None,\n                  bias=True, **kwargs):\n-        if dim_ordering == 'default':\n-            dim_ordering = K.image_dim_ordering()\n+        if data_format == 'default':\n+            data_format = K.image_data_format()\n \n         if border_mode not in {'valid', 'same', 'full'}:\n             raise ValueError('Invalid border mode for Convolution3D:', border_mode)\n@@ -1151,9 +1151,9 @@ class Convolution3D(Layer):\n         self.activation = activations.get(activation)\n         self.border_mode = border_mode\n         self.subsample = tuple(subsample)\n-        if dim_ordering not in {'tf', 'th'}:\n-            raise ValueError('dim_ordering must be in {tf, th}.')\n-        self.dim_ordering = dim_ordering\n+        if data_format not in {'channels_last', 'channels_first'}:\n+            raise ValueError('data_format must be in {\"channels_last\", \"channels_first\"}.')\n+        self.data_format = data_format\n \n         self.W_regularizer = regularizers.get(W_regularizer)\n         self.b_regularizer = regularizers.get(b_regularizer)\n@@ -1171,20 +1171,20 @@ class Convolution3D(Layer):\n         assert len(input_shape) == 5\n         self.input_spec = [InputSpec(shape=input_shape)]\n \n-        if self.dim_ordering == 'th':\n+        if self.data_format == 'channels_first':\n             stack_size = input_shape[1]\n             self.W_shape = (self.nb_filter, stack_size,\n                             self.kernel_dim1, self.kernel_dim2, self.kernel_dim3)\n-        elif self.dim_ordering == 'tf':\n+        elif self.data_format == 'channels_last':\n             stack_size = input_shape[4]\n             self.W_shape = (self.kernel_dim1, self.kernel_dim2, self.kernel_dim3,\n                             stack_size, self.nb_filter)\n         else:\n-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n+            raise ValueError('Invalid data_format:', self.data_format)\n \n         self.W = self.add_weight(self.W_shape,\n                                  initializer=functools.partial(self.init,\n-                                                               dim_ordering=self.dim_ordering),\n+                                                               data_format=self.data_format),\n                                  name='{}_W'.format(self.name),\n                                  regularizer=self.W_regularizer,\n                                  constraint=self.W_constraint)\n@@ -1203,16 +1203,16 @@ class Convolution3D(Layer):\n         self.built = True\n \n     def get_output_shape_for(self, input_shape):\n-        if self.dim_ordering == 'th':\n+        if self.data_format == 'channels_first':\n             conv_dim1 = input_shape[2]\n             conv_dim2 = input_shape[3]\n             conv_dim3 = input_shape[4]\n-        elif self.dim_ordering == 'tf':\n+        elif self.data_format == 'channels_last':\n             conv_dim1 = input_shape[1]\n             conv_dim2 = input_shape[2]\n             conv_dim3 = input_shape[3]\n         else:\n-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n+            raise ValueError('Invalid data_format:', self.data_format)\n \n         conv_dim1 = conv_output_length(conv_dim1, self.kernel_dim1,\n                                        self.border_mode, self.subsample[0])\n@@ -1221,27 +1221,27 @@ class Convolution3D(Layer):\n         conv_dim3 = conv_output_length(conv_dim3, self.kernel_dim3,\n                                        self.border_mode, self.subsample[2])\n \n-        if self.dim_ordering == 'th':\n+        if self.data_format == 'channels_first':\n             return (input_shape[0], self.nb_filter, conv_dim1, conv_dim2, conv_dim3)\n-        elif self.dim_ordering == 'tf':\n+        elif self.data_format == 'channels_last':\n             return (input_shape[0], conv_dim1, conv_dim2, conv_dim3, self.nb_filter)\n         else:\n-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n+            raise ValueError('Invalid data_format:', self.data_format)\n \n     def call(self, x, mask=None):\n         input_shape = self.input_spec[0].shape\n         output = K.conv3d(x, self.W, strides=self.subsample,\n                           border_mode=self.border_mode,\n-                          dim_ordering=self.dim_ordering,\n+                          data_format=self.data_format,\n                           volume_shape=input_shape,\n                           filter_shape=self.W_shape)\n         if self.bias:\n-            if self.dim_ordering == 'th':\n+            if self.data_format == 'channels_first':\n                 output += K.reshape(self.b, (1, self.nb_filter, 1, 1, 1))\n-            elif self.dim_ordering == 'tf':\n+            elif self.data_format == 'channels_last':\n                 output += K.reshape(self.b, (1, 1, 1, 1, self.nb_filter))\n             else:\n-                raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n+                raise ValueError('Invalid data_format:', self.data_format)\n         output = self.activation(output)\n         return output\n \n@@ -1250,7 +1250,7 @@ class Convolution3D(Layer):\n                   'kernel_dim1': self.kernel_dim1,\n                   'kernel_dim2': self.kernel_dim2,\n                   'kernel_dim3': self.kernel_dim3,\n-                  'dim_ordering': self.dim_ordering,\n+                  'data_format': self.data_format,\n                   'init': self.init.__name__,\n                   'activation': self.activation.__name__,\n                   'border_mode': self.border_mode,\n@@ -1307,45 +1307,45 @@ class UpSampling2D(Layer):\n \n     # Arguments\n         size: tuple of 2 integers. The upsampling factors for rows and columns.\n-        dim_ordering: 'th' or 'tf'.\n-            In 'th' mode, the channels dimension (the depth)\n-            is at index 1, in 'tf' mode is it at index 3.\n-            It defaults to the `image_dim_ordering` value found in your\n+        data_format: 'channels_first' or 'channels_last'.\n+            In 'channels_first' mode, the channels dimension (the depth)\n+            is at index 1, in 'channels_last' mode is it at index 3.\n+            It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"tf\".\n+            If you never set it, then it will be \"channels_last\".\n \n     # Input shape\n         4D tensor with shape:\n-        `(samples, channels, rows, cols)` if dim_ordering='th'\n+        `(samples, channels, rows, cols)` if data_format='channels_first'\n         or 4D tensor with shape:\n-        `(samples, rows, cols, channels)` if dim_ordering='tf'.\n+        `(samples, rows, cols, channels)` if data_format='channels_last'.\n \n     # Output shape\n         4D tensor with shape:\n-        `(samples, channels, upsampled_rows, upsampled_cols)` if dim_ordering='th'\n+        `(samples, channels, upsampled_rows, upsampled_cols)` if data_format='channels_first'\n         or 4D tensor with shape:\n-        `(samples, upsampled_rows, upsampled_cols, channels)` if dim_ordering='tf'.\n+        `(samples, upsampled_rows, upsampled_cols, channels)` if data_format='channels_last'.\n     \"\"\"\n \n-    def __init__(self, size=(2, 2), dim_ordering='default', **kwargs):\n-        if dim_ordering == 'default':\n-            dim_ordering = K.image_dim_ordering()\n+    def __init__(self, size=(2, 2), data_format='default', **kwargs):\n+        if data_format == 'default':\n+            data_format = K.image_data_format()\n         self.size = tuple(size)\n-        if dim_ordering not in {'tf', 'th'}:\n-            raise ValueError('dim_ordering must be in {tf, th}.')\n-        self.dim_ordering = dim_ordering\n+        if data_format not in {'channels_last', 'channels_first'}:\n+            raise ValueError('data_format must be in {\"channels_last\", \"channels_first\"}.')\n+        self.data_format = data_format\n         self.input_spec = [InputSpec(ndim=4)]\n         super(UpSampling2D, self).__init__(**kwargs)\n \n     def get_output_shape_for(self, input_shape):\n-        if self.dim_ordering == 'th':\n+        if self.data_format == 'channels_first':\n             width = self.size[0] * input_shape[2] if input_shape[2] is not None else None\n             height = self.size[1] * input_shape[3] if input_shape[3] is not None else None\n             return (input_shape[0],\n                     input_shape[1],\n                     width,\n                     height)\n-        elif self.dim_ordering == 'tf':\n+        elif self.data_format == 'channels_last':\n             width = self.size[0] * input_shape[1] if input_shape[1] is not None else None\n             height = self.size[1] * input_shape[2] if input_shape[2] is not None else None\n             return (input_shape[0],\n@@ -1353,11 +1353,11 @@ class UpSampling2D(Layer):\n                     height,\n                     input_shape[3])\n         else:\n-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n+            raise ValueError('Invalid data_format:', self.data_format)\n \n     def call(self, x, mask=None):\n         return K.resize_images(x, self.size[0], self.size[1],\n-                               self.dim_ordering)\n+                               self.data_format)\n \n     def get_config(self):\n         config = {'size': self.size}\n@@ -1373,38 +1373,38 @@ class UpSampling3D(Layer):\n \n     # Arguments\n         size: tuple of 3 integers. The upsampling factors for dim1, dim2 and dim3.\n-        dim_ordering: 'th' or 'tf'.\n-            In 'th' mode, the channels dimension (the depth)\n-            is at index 1, in 'tf' mode is it at index 4.\n-            It defaults to the `image_dim_ordering` value found in your\n+        data_format: 'channels_first' or 'channels_last'.\n+            In 'channels_first' mode, the channels dimension (the depth)\n+            is at index 1, in 'channels_last' mode is it at index 4.\n+            It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"tf\".\n+            If you never set it, then it will be \"channels_last\".\n \n     # Input shape\n         5D tensor with shape:\n-        `(samples, channels, dim1, dim2, dim3)` if dim_ordering='th'\n+        `(samples, channels, dim1, dim2, dim3)` if data_format='channels_first'\n         or 5D tensor with shape:\n-        `(samples, dim1, dim2, dim3, channels)` if dim_ordering='tf'.\n+        `(samples, dim1, dim2, dim3, channels)` if data_format='channels_last'.\n \n     # Output shape\n         5D tensor with shape:\n-        `(samples, channels, upsampled_dim1, upsampled_dim2, upsampled_dim3)` if dim_ordering='th'\n+        `(samples, channels, upsampled_dim1, upsampled_dim2, upsampled_dim3)` if data_format='channels_first'\n         or 5D tensor with shape:\n-        `(samples, upsampled_dim1, upsampled_dim2, upsampled_dim3, channels)` if dim_ordering='tf'.\n+        `(samples, upsampled_dim1, upsampled_dim2, upsampled_dim3, channels)` if data_format='channels_last'.\n     \"\"\"\n \n-    def __init__(self, size=(2, 2, 2), dim_ordering='default', **kwargs):\n-        if dim_ordering == 'default':\n-            dim_ordering = K.image_dim_ordering()\n+    def __init__(self, size=(2, 2, 2), data_format='default', **kwargs):\n+        if data_format == 'default':\n+            data_format = K.image_data_format()\n         self.size = tuple(size)\n-        if dim_ordering not in {'tf', 'th'}:\n-            raise ValueError('dim_ordering must be in {tf, th}.')\n-        self.dim_ordering = dim_ordering\n+        if data_format not in {'channels_last', 'channels_first'}:\n+            raise ValueError('data_format must be in {\"channels_last\", \"channels_first\"}.')\n+        self.data_format = data_format\n         self.input_spec = [InputSpec(ndim=5)]\n         super(UpSampling3D, self).__init__(**kwargs)\n \n     def get_output_shape_for(self, input_shape):\n-        if self.dim_ordering == 'th':\n+        if self.data_format == 'channels_first':\n             dim1 = self.size[0] * input_shape[2] if input_shape[2] is not None else None\n             dim2 = self.size[1] * input_shape[3] if input_shape[3] is not None else None\n             dim3 = self.size[2] * input_shape[4] if input_shape[4] is not None else None\n@@ -1413,7 +1413,7 @@ class UpSampling3D(Layer):\n                     dim1,\n                     dim2,\n                     dim3)\n-        elif self.dim_ordering == 'tf':\n+        elif self.data_format == 'channels_last':\n             dim1 = self.size[0] * input_shape[1] if input_shape[1] is not None else None\n             dim2 = self.size[1] * input_shape[2] if input_shape[2] is not None else None\n             dim3 = self.size[2] * input_shape[3] if input_shape[3] is not None else None\n@@ -1423,11 +1423,11 @@ class UpSampling3D(Layer):\n                     dim3,\n                     input_shape[4])\n         else:\n-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n+            raise ValueError('Invalid data_format:', self.data_format)\n \n     def call(self, x, mask=None):\n         return K.resize_volumes(x, self.size[0], self.size[1], self.size[2],\n-                                self.dim_ordering)\n+                                self.data_format)\n \n     def get_config(self):\n         config = {'size': self.size}\n@@ -1513,33 +1513,33 @@ class ZeroPadding2D(Layer):\n             - If dictionary: should contain the keys\n             {'top_pad', 'bottom_pad', 'left_pad', 'right_pad'}.\n             If any key is missing, default value of 0 will be used for the missing key.\n-        dim_ordering: 'th' or 'tf'.\n-            In 'th' mode, the channels dimension (the depth)\n-            is at index 1, in 'tf' mode is it at index 3.\n-            It defaults to the `image_dim_ordering` value found in your\n+        data_format: 'channels_first' or 'channels_last'.\n+            In 'channels_first' mode, the channels dimension (the depth)\n+            is at index 1, in 'channels_last' mode is it at index 3.\n+            It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"tf\".\n+            If you never set it, then it will be \"channels_last\".\n \n     # Input shape\n         4D tensor with shape:\n-        `(samples, channels, rows, cols)` if dim_ordering='th'\n+        `(samples, channels, rows, cols)` if data_format='channels_first'\n         or 4D tensor with shape:\n-        `(samples, rows, cols, channels)` if dim_ordering='tf'.\n+        `(samples, rows, cols, channels)` if data_format='channels_last'.\n \n     # Output shape\n         4D tensor with shape:\n-        `(samples, channels, padded_rows, padded_cols)` if dim_ordering='th'\n+        `(samples, channels, padded_rows, padded_cols)` if data_format='channels_first'\n         or 4D tensor with shape:\n-        `(samples, padded_rows, padded_cols, channels)` if dim_ordering='tf'.\n+        `(samples, padded_rows, padded_cols, channels)` if data_format='channels_last'.\n     \"\"\"\n \n     def __init__(self,\n                  padding=(1, 1),\n-                 dim_ordering='default',\n+                 data_format='default',\n                  **kwargs):\n         super(ZeroPadding2D, self).__init__(**kwargs)\n-        if dim_ordering == 'default':\n-            dim_ordering = K.image_dim_ordering()\n+        if data_format == 'default':\n+            data_format = K.image_data_format()\n \n         self.padding = padding\n         if isinstance(padding, dict):\n@@ -1570,20 +1570,20 @@ class ZeroPadding2D(Layer):\n                                 'of length 2 or 4, or dict. '\n                                 'Found: ' + str(padding))\n \n-        if dim_ordering not in {'tf', 'th'}:\n-            raise ValueError('dim_ordering must be in {tf, th}.')\n-        self.dim_ordering = dim_ordering\n+        if data_format not in {'channels_last', 'channels_first'}:\n+            raise ValueError('data_format must be in {\"channels_last\", \"channels_first\"}.')\n+        self.data_format = data_format\n         self.input_spec = [InputSpec(ndim=4)]\n \n     def get_output_shape_for(self, input_shape):\n-        if self.dim_ordering == 'th':\n+        if self.data_format == 'channels_first':\n             rows = input_shape[2] + self.top_pad + self.bottom_pad if input_shape[2] is not None else None\n             cols = input_shape[3] + self.left_pad + self.right_pad if input_shape[3] is not None else None\n             return (input_shape[0],\n                     input_shape[1],\n                     rows,\n                     cols)\n-        elif self.dim_ordering == 'tf':\n+        elif self.data_format == 'channels_last':\n             rows = input_shape[1] + self.top_pad + self.bottom_pad if input_shape[1] is not None else None\n             cols = input_shape[2] + self.left_pad + self.right_pad if input_shape[2] is not None else None\n             return (input_shape[0],\n@@ -1591,7 +1591,7 @@ class ZeroPadding2D(Layer):\n                     cols,\n                     input_shape[3])\n         else:\n-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n+            raise ValueError('Invalid data_format:', self.data_format)\n \n     def call(self, x, mask=None):\n         return K.asymmetric_spatial_2d_padding(x,\n@@ -1599,7 +1599,7 @@ class ZeroPadding2D(Layer):\n                                                bottom_pad=self.bottom_pad,\n                                                left_pad=self.left_pad,\n                                                right_pad=self.right_pad,\n-                                               dim_ordering=self.dim_ordering)\n+                                               data_format=self.data_format)\n \n     def get_config(self):\n         config = {'padding': self.padding}\n@@ -1615,12 +1615,12 @@ class ZeroPadding3D(Layer):\n             How many zeros to add at the beginning and end of\n             the 3 padding dimensions (axis 3, 4 and 5).\n             Currently only symmetric padding is supported.\n-        dim_ordering: 'th' or 'tf'.\n-            In 'th' mode, the channels dimension (the depth)\n-            is at index 1, in 'tf' mode is it at index 4.\n-            It defaults to the `image_dim_ordering` value found in your\n+        data_format: 'channels_first' or 'channels_last'.\n+            In 'channels_first' mode, the channels dimension (the depth)\n+            is at index 1, in 'channels_last' mode is it at index 4.\n+            It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"tf\".\n+            If you never set it, then it will be \"channels_last\".\n \n     # Input shape\n         5D tensor with shape:\n@@ -1631,18 +1631,18 @@ class ZeroPadding3D(Layer):\n         `(samples, depth, first_padded_axis, second_padded_axis, third_axis_to_pad)`\n     \"\"\"\n \n-    def __init__(self, padding=(1, 1, 1), dim_ordering='default', **kwargs):\n+    def __init__(self, padding=(1, 1, 1), data_format='default', **kwargs):\n         super(ZeroPadding3D, self).__init__(**kwargs)\n-        if dim_ordering == 'default':\n-            dim_ordering = K.image_dim_ordering()\n+        if data_format == 'default':\n+            data_format = K.image_data_format()\n         self.padding = tuple(padding)\n-        if dim_ordering not in {'tf', 'th'}:\n-            raise ValueError('dim_ordering must be in {tf, th}.')\n-        self.dim_ordering = dim_ordering\n+        if data_format not in {'channels_last', 'channels_first'}:\n+            raise ValueError('data_format must be in {\"channels_last\", \"channels_first\"}.')\n+        self.data_format = data_format\n         self.input_spec = [InputSpec(ndim=5)]\n \n     def get_output_shape_for(self, input_shape):\n-        if self.dim_ordering == 'th':\n+        if self.data_format == 'channels_first':\n             dim1 = input_shape[2] + 2 * self.padding[0] if input_shape[2] is not None else None\n             dim2 = input_shape[3] + 2 * self.padding[1] if input_shape[3] is not None else None\n             dim3 = input_shape[4] + 2 * self.padding[2] if input_shape[4] is not None else None\n@@ -1651,7 +1651,7 @@ class ZeroPadding3D(Layer):\n                     dim1,\n                     dim2,\n                     dim3)\n-        elif self.dim_ordering == 'tf':\n+        elif self.data_format == 'channels_last':\n             dim1 = input_shape[1] + 2 * self.padding[0] if input_shape[1] is not None else None\n             dim2 = input_shape[2] + 2 * self.padding[1] if input_shape[2] is not None else None\n             dim3 = input_shape[3] + 2 * self.padding[2] if input_shape[3] is not None else None\n@@ -1661,11 +1661,11 @@ class ZeroPadding3D(Layer):\n                     dim3,\n                     input_shape[4])\n         else:\n-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n+            raise ValueError('Invalid data_format:', self.data_format)\n \n     def call(self, x, mask=None):\n         return K.spatial_3d_padding(x, padding=self.padding,\n-                                    dim_ordering=self.dim_ordering)\n+                                    data_format=self.data_format)\n \n     def get_config(self):\n         config = {'padding': self.padding}\n@@ -1731,12 +1731,12 @@ class Cropping2D(Layer):\n         cropping: tuple of tuple of int (length 2)\n             How many units should be trimmed off at the beginning and end of\n             the 2 cropping dimensions (width, height).\n-        dim_ordering: 'th' or 'tf'.\n-            In 'th' mode, the channels dimension (the depth)\n-            is at index 1, in 'tf' mode is it at index 3.\n-            It defaults to the `image_dim_ordering` value found in your\n+        data_format: 'channels_first' or 'channels_last'.\n+            In 'channels_first' mode, the channels dimension (the depth)\n+            is at index 1, in 'channels_last' mode is it at index 3.\n+            It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"tf\".\n+            If you never set it, then it will be \"channels_last\".\n \n     # Input shape\n         4D tensor with shape:\n@@ -1760,10 +1760,10 @@ class Cropping2D(Layer):\n     ```\n     \"\"\"\n \n-    def __init__(self, cropping=((0, 0), (0, 0)), dim_ordering='default', **kwargs):\n+    def __init__(self, cropping=((0, 0), (0, 0)), data_format='default', **kwargs):\n         super(Cropping2D, self).__init__(**kwargs)\n-        if dim_ordering == 'default':\n-            dim_ordering = K.image_dim_ordering()\n+        if data_format == 'default':\n+            data_format = K.image_data_format()\n         self.cropping = tuple(cropping)\n         if len(self.cropping) != 2:\n             raise ValueError('`cropping` must be a tuple length of 2.')\n@@ -1771,9 +1771,9 @@ class Cropping2D(Layer):\n             raise ValueError('`cropping[0]` must be a tuple length of 2.')\n         if len(self.cropping[1]) != 2:\n             raise ValueError('`cropping[1]` must be a tuple length of 2.')\n-        if dim_ordering not in {'tf', 'th'}:\n-            raise ValueError('dim_ordering must be in {tf, th}.')\n-        self.dim_ordering = dim_ordering\n+        if data_format not in {'channels_last', 'channels_first'}:\n+            raise ValueError('data_format must be in {\"channels_last\", \"channels_first\"}.')\n+        self.data_format = data_format\n         self.input_spec = [InputSpec(ndim=4)]\n \n     def build(self, input_shape):\n@@ -1781,21 +1781,21 @@ class Cropping2D(Layer):\n         self.built = True\n \n     def get_output_shape_for(self, input_shape):\n-        if self.dim_ordering == 'th':\n+        if self.data_format == 'channels_first':\n             return (input_shape[0],\n                     input_shape[1],\n                     input_shape[2] - self.cropping[0][0] - self.cropping[0][1],\n                     input_shape[3] - self.cropping[1][0] - self.cropping[1][1])\n-        elif self.dim_ordering == 'tf':\n+        elif self.data_format == 'channels_last':\n             return (input_shape[0],\n                     input_shape[1] - self.cropping[0][0] - self.cropping[0][1],\n                     input_shape[2] - self.cropping[1][0] - self.cropping[1][1],\n                     input_shape[3])\n         else:\n-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n+            raise ValueError('Invalid data_format:', self.data_format)\n \n     def call(self, x, mask=None):\n-        if self.dim_ordering == 'th':\n+        if self.data_format == 'channels_first':\n             if self.cropping[0][1] == self.cropping[1][1] == 0:\n                 return x[:,\n                          :,\n@@ -1815,7 +1815,7 @@ class Cropping2D(Layer):\n                      :,\n                      self.cropping[0][0]:-self.cropping[0][1],\n                      self.cropping[1][0]:-self.cropping[1][1]]\n-        elif self.dim_ordering == 'tf':\n+        elif self.data_format == 'channels_last':\n             if self.cropping[0][1] == self.cropping[1][1] == 0:\n                 return x[:,\n                          self.cropping[0][0]:,\n@@ -1849,12 +1849,12 @@ class Cropping3D(Layer):\n         cropping: tuple of tuple of int (length 3)\n             How many units should be trimmed off at the beginning and end of\n             the 3 cropping dimensions (kernel_dim1, kernel_dim2, kernerl_dim3).\n-        dim_ordering: 'th' or 'tf'.\n-            In 'th' mode, the channels dimension (the depth)\n-            is at index 1, in 'tf' mode is it at index 4.\n-            It defaults to the `image_dim_ordering` value found in your\n+        data_format: 'channels_first' or 'channels_last'.\n+            In 'channels_first' mode, the channels dimension (the depth)\n+            is at index 1, in 'channels_last' mode is it at index 4.\n+            It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"tf\".\n+            If you never set it, then it will be \"channels_last\".\n \n     # Input shape\n         5D tensor with shape:\n@@ -1867,10 +1867,10 @@ class Cropping3D(Layer):\n     \"\"\"\n \n     def __init__(self, cropping=((1, 1), (1, 1), (1, 1)),\n-                 dim_ordering='default', **kwargs):\n+                 data_format='default', **kwargs):\n         super(Cropping3D, self).__init__(**kwargs)\n-        if dim_ordering == 'default':\n-            dim_ordering = K.image_dim_ordering()\n+        if data_format == 'default':\n+            data_format = K.image_data_format()\n         self.cropping = tuple(cropping)\n         if len(self.cropping) != 3:\n             raise ValueError('`cropping` must be a tuple length of 3.')\n@@ -1880,9 +1880,9 @@ class Cropping3D(Layer):\n             raise ValueError('`cropping[1]` must be a tuple length of 2.')\n         if len(self.cropping[2]) != 2:\n             raise ValueError('`cropping[2]` must be a tuple length of 2.')\n-        if dim_ordering not in {'tf', 'th'}:\n-            raise ValueError('dim_ordering must be in {tf, th}.')\n-        self.dim_ordering = dim_ordering\n+        if data_format not in {'channels_last', 'channels_first'}:\n+            raise ValueError('data_format must be in {\"channels_last\", \"channels_first\"}.')\n+        self.data_format = data_format\n         self.input_spec = [InputSpec(ndim=5)]\n \n     def build(self, input_shape):\n@@ -1890,7 +1890,7 @@ class Cropping3D(Layer):\n         self.built = True\n \n     def get_output_shape_for(self, input_shape):\n-        if self.dim_ordering == 'th':\n+        if self.data_format == 'channels_first':\n             dim1 = input_shape[2] - self.cropping[0][0] - self.cropping[0][1] if input_shape[2] is not None else None\n             dim2 = input_shape[3] - self.cropping[1][0] - self.cropping[1][1] if input_shape[3] is not None else None\n             dim3 = input_shape[4] - self.cropping[2][0] - self.cropping[2][1] if input_shape[4] is not None else None\n@@ -1899,7 +1899,7 @@ class Cropping3D(Layer):\n                     dim1,\n                     dim2,\n                     dim3)\n-        elif self.dim_ordering == 'tf':\n+        elif self.data_format == 'channels_last':\n             dim1 = input_shape[1] - self.cropping[0][0] - self.cropping[0][1] if input_shape[1] is not None else None\n             dim2 = input_shape[2] - self.cropping[1][0] - self.cropping[1][1] if input_shape[2] is not None else None\n             dim3 = input_shape[3] - self.cropping[2][0] - self.cropping[2][1] if input_shape[3] is not None else None\n@@ -1909,10 +1909,10 @@ class Cropping3D(Layer):\n                     dim3,\n                     input_shape[4])\n         else:\n-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n+            raise ValueError('Invalid data_format:', self.data_format)\n \n     def call(self, x, mask=None):\n-        if self.dim_ordering == 'th':\n+        if self.data_format == 'channels_first':\n             if self.cropping[0][1] == self.cropping[1][1] == self.cropping[2][1] == 0:\n                 return x[:,\n                          :,\n@@ -1960,7 +1960,7 @@ class Cropping3D(Layer):\n                      self.cropping[0][0]:-self.cropping[0][1],\n                      self.cropping[1][0]:-self.cropping[1][1],\n                      self.cropping[2][0]:-self.cropping[2][1]]\n-        elif self.dim_ordering == 'tf':\n+        elif self.data_format == 'channels_last':\n             if self.cropping[0][1] == self.cropping[1][1] == self.cropping[2][1] == 0:\n                 return x[:,\n                          self.cropping[0][0]:,\n\n@@ -81,7 +81,7 @@ class ConvRecurrent2D(Layer):\n \n     def __init__(self, weights=None, nb_row=None, nb_col=None, nb_filter=None,\n                  return_sequences=False, go_backwards=False, stateful=False,\n-                 dim_ordering=None, **kwargs):\n+                 data_format=None, **kwargs):\n         self.return_sequences = return_sequences\n         self.go_backwards = go_backwards\n         self.stateful = stateful\n@@ -89,7 +89,7 @@ class ConvRecurrent2D(Layer):\n         self.nb_row = nb_row\n         self.nb_col = nb_col\n         self.nb_filter = nb_filter\n-        self.dim_ordering = dim_ordering\n+        self.data_format = data_format\n         self.input_spec = [InputSpec(ndim=5)]\n \n         super(ConvRecurrent2D, self).__init__(**kwargs)\n@@ -102,14 +102,14 @@ class ConvRecurrent2D(Layer):\n \n     def get_output_shape_for(self, input_shape):\n \n-        if self.dim_ordering == 'th':\n+        if self.data_format == 'channels_first':\n             rows = input_shape[3]\n             cols = input_shape[4]\n-        elif self.dim_ordering == 'tf':\n+        elif self.data_format == 'channels_last':\n             rows = input_shape[2]\n             cols = input_shape[3]\n         else:\n-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n+            raise ValueError('Invalid data_format:', self.data_format)\n \n         rows = conv_output_length(rows, self.nb_row,\n                                   self.border_mode, self.subsample[0])\n@@ -117,16 +117,16 @@ class ConvRecurrent2D(Layer):\n                                   self.border_mode, self.subsample[1])\n \n         if self.return_sequences:\n-            if self.dim_ordering == 'th':\n+            if self.data_format == 'channels_first':\n                 return (input_shape[0], input_shape[1],\n                         self.nb_filter, rows, cols)\n-            elif self.dim_ordering == 'tf':\n+            elif self.data_format == 'channels_last':\n                 return (input_shape[0], input_shape[1],\n                         rows, cols, self.nb_filter)\n         else:\n-            if self.dim_ordering == 'th':\n+            if self.data_format == 'channels_first':\n                 return (input_shape[0], self.nb_filter, rows, cols)\n-            elif self.dim_ordering == 'tf':\n+            elif self.data_format == 'channels_last':\n                 return (input_shape[0], rows, cols, self.nb_filter)\n \n     def step(self, x, states):\n@@ -194,26 +194,26 @@ class ConvLSTM2D(ConvRecurrent2D):\n     \"\"\"Convolutional LSTM.\n \n     # Input shape\n-        - if dim_ordering='th'\n+        - if data_format='channels_first'\n             5D tensor with shape:\n             `(samples,time, channels, rows, cols)`\n-        - if dim_ordering='tf'\n+        - if data_format='channels_last'\n             5D tensor with shape:\n             `(samples,time, rows, cols, channels)`\n \n      # Output shape\n         - if `return_sequences`\n-             - if dim_ordering='th'\n+             - if data_format='channels_first'\n                 5D tensor with shape:\n                 `(samples, time, nb_filter, output_row, output_col)`\n-             - if dim_ordering='tf'\n+             - if data_format='channels_last'\n                 5D tensor with shape:\n                 `(samples, time, output_row, output_col, nb_filter)`\n         - else\n-            - if dim_ordering ='th'\n+            - if data_format ='channels_first'\n                 4D tensor with shape:\n                 `(samples, nb_filter, output_row, output_col)`\n-            - if dim_ordering='tf'\n+            - if data_format='channels_last'\n                 4D tensor with shape:\n                 `(samples, output_row, output_col, nb_filter)`\n \n@@ -227,7 +227,7 @@ class ConvLSTM2D(ConvRecurrent2D):\n             border_mode: 'valid' or 'same'.\n             subsample: tuple of length 2. Factor by which to subsample output.\n                 Also called strides elsewhere.\n-            dim_ordering: 'tf' if the feature are at the last dimension or 'th'\n+            data_format: 'channels_last' if the feature are at the last dimension or 'channels_first'\n             stateful : Boolean (default False). If True, the last state\n                 for each sample at index i in a batch will be used as initial\n                 state for the sample of index i in the following batch.\n@@ -256,15 +256,15 @@ class ConvLSTM2D(ConvRecurrent2D):\n                  init='glorot_uniform', inner_init='orthogonal',\n                  forget_bias_init='one', activation='tanh',\n                  inner_activation='hard_sigmoid',\n-                 dim_ordering='default',\n+                 data_format='default',\n                  border_mode='valid', subsample=(1, 1),\n                  W_regularizer=None, U_regularizer=None, b_regularizer=None,\n                  dropout_W=0., dropout_U=0., **kwargs):\n \n-        if dim_ordering == 'default':\n-            dim_ordering = K.image_dim_ordering()\n-        if dim_ordering not in {'tf', 'th'}:\n-            raise ValueError('dim_ordering must be in {tf,th}', dim_ordering)\n+        if data_format == 'default':\n+            data_format = K.image_data_format()\n+        if data_format not in {'channels_last', 'channels_first'}:\n+            raise ValueError('data_format must be in {tf,th}', data_format)\n         self.nb_filter = nb_filter\n         self.nb_row = nb_row\n         self.nb_col = nb_col\n@@ -276,19 +276,19 @@ class ConvLSTM2D(ConvRecurrent2D):\n         self.border_mode = border_mode\n         self.subsample = subsample\n \n-        if dim_ordering == 'th':\n+        if data_format == 'channels_first':\n             warnings.warn('Be carefull if used with convolution3D layers:\\n'\n                           'th in convolution 3D corresponds to '\n                           '(samples, channels, conv_dim1, conv_dim2,'\n                           'conv_dim3)\\n'\n                           'while for this network it corresponds to: '\n                           '(samples, time, channels, rows, cols)')\n-        self.dim_ordering = dim_ordering\n+        self.data_format = data_format\n \n         kwargs['nb_filter'] = nb_filter\n         kwargs['nb_row'] = nb_row\n         kwargs['nb_col'] = nb_col\n-        kwargs['dim_ordering'] = dim_ordering\n+        kwargs['data_format'] = data_format\n \n         self.W_regularizer = regularizers.get(W_regularizer)\n         self.U_regularizer = regularizers.get(U_regularizer)\n@@ -302,21 +302,21 @@ class ConvLSTM2D(ConvRecurrent2D):\n     def build(self, input_shape):\n         self.input_spec = [InputSpec(shape=input_shape)]\n \n-        if self.dim_ordering == 'th':\n+        if self.data_format == 'channels_first':\n             stack_size = input_shape[2]\n             self.W_shape = (self.nb_filter, stack_size,\n                             self.nb_row, self.nb_col)\n-        elif self.dim_ordering == 'tf':\n+        elif self.data_format == 'channels_last':\n             stack_size = input_shape[4]\n             self.W_shape = (self.nb_row, self.nb_col,\n                             stack_size, self.nb_filter)\n         else:\n-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n+            raise ValueError('Invalid data_format:', self.data_format)\n \n-        if self.dim_ordering == 'th':\n+        if self.data_format == 'channels_first':\n             self.W_shape1 = (self.nb_filter, self.nb_filter,\n                              self.nb_row, self.nb_col)\n-        elif self.dim_ordering == 'tf':\n+        elif self.data_format == 'channels_last':\n             self.W_shape1 = (self.nb_row, self.nb_col,\n                              self.nb_filter, self.nb_filter)\n \n@@ -404,19 +404,19 @@ class ConvLSTM2D(ConvRecurrent2D):\n \n         conv_out = K.conv2d(x, W, strides=self.subsample,\n                             border_mode=border_mode,\n-                            dim_ordering=self.dim_ordering,\n+                            data_format=self.data_format,\n                             image_shape=(input_shape[0],\n                                          input_shape[2],\n                                          input_shape[3],\n                                          input_shape[4]),\n                             filter_shape=self.W_shape)\n         if b:\n-            if self.dim_ordering == 'th':\n+            if self.data_format == 'channels_first':\n                 conv_out = conv_out + K.reshape(b, (1, self.nb_filter, 1, 1))\n-            elif self.dim_ordering == 'tf':\n+            elif self.data_format == 'channels_last':\n                 conv_out = conv_out + K.reshape(b, (1, 1, 1, self.nb_filter))\n             else:\n-                raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n+                raise ValueError('Invalid data_format:', self.data_format)\n \n         return conv_out\n \n@@ -432,7 +432,7 @@ class ConvLSTM2D(ConvRecurrent2D):\n \n         conv_out = K.conv2d(x, W, strides=(1, 1),\n                             border_mode=border_mode,\n-                            dim_ordering=self.dim_ordering,\n+                            data_format=self.data_format,\n                             image_shape=(input_shape[0],\n                                          out_row, out_col,\n                                          out_filter),\n@@ -508,7 +508,7 @@ class ConvLSTM2D(ConvRecurrent2D):\n                   'inner_init': self.inner_init.__name__,\n                   'forget_bias_init': self.forget_bias_init.__name__,\n                   'activation': self.activation.__name__,\n-                  'dim_ordering': self.dim_ordering,\n+                  'data_format': self.data_format,\n                   'border_mode': self.border_mode,\n                   'inner_activation': self.inner_activation.__name__}\n         base_config = super(ConvLSTM2D, self).get_config()\n\n@@ -163,17 +163,17 @@ class SpatialDropout2D(Dropout):\n \n     # Arguments\n         p: float between 0 and 1. Fraction of the input units to drop.\n-        dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension\n-            (the depth) is at index 1, in 'tf' mode is it at index 3.\n-            It defaults to the `image_dim_ordering` value found in your\n+        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension\n+            (the depth) is at index 1, in 'channels_last' mode is it at index 3.\n+            It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"tf\".\n+            If you never set it, then it will be \"channels_last\".\n \n     # Input shape\n         4D tensor with shape:\n-        `(samples, channels, rows, cols)` if dim_ordering='th'\n+        `(samples, channels, rows, cols)` if data_format='channels_first'\n         or 4D tensor with shape:\n-        `(samples, rows, cols, channels)` if dim_ordering='tf'.\n+        `(samples, rows, cols, channels)` if data_format='channels_last'.\n \n     # Output shape\n         Same as input\n@@ -182,21 +182,21 @@ class SpatialDropout2D(Dropout):\n         - [Efficient Object Localization Using Convolutional Networks](https://arxiv.org/abs/1411.4280)\n     \"\"\"\n \n-    def __init__(self, p, dim_ordering='default', **kwargs):\n-        if dim_ordering == 'default':\n-            dim_ordering = K.image_dim_ordering()\n-        assert dim_ordering in {'tf', 'th'}, 'dim_ordering must be in {tf, th}'\n-        self.dim_ordering = dim_ordering\n+    def __init__(self, p, data_format='default', **kwargs):\n+        if data_format == 'default':\n+            data_format = K.image_data_format()\n+        assert data_format in {'channels_last', 'channels_first'}, 'data_format must be in {\"channels_last\", \"channels_first\"}'\n+        self.data_format = data_format\n         super(SpatialDropout2D, self).__init__(p, **kwargs)\n \n     def _get_noise_shape(self, x):\n         input_shape = K.shape(x)\n-        if self.dim_ordering == 'th':\n+        if self.data_format == 'channels_first':\n             noise_shape = (input_shape[0], input_shape[1], 1, 1)\n-        elif self.dim_ordering == 'tf':\n+        elif self.data_format == 'channels_last':\n             noise_shape = (input_shape[0], 1, 1, input_shape[3])\n         else:\n-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n+            raise ValueError('Invalid data_format:', self.data_format)\n         return noise_shape\n \n \n@@ -213,18 +213,18 @@ class SpatialDropout3D(Dropout):\n \n     # Arguments\n         p: float between 0 and 1. Fraction of the input units to drop.\n-        dim_ordering: 'th' or 'tf'.\n-            In 'th' mode, the channels dimension (the depth)\n-            is at index 1, in 'tf' mode is it at index 4.\n-            It defaults to the `image_dim_ordering` value found in your\n+        data_format: 'channels_first' or 'channels_last'.\n+            In 'channels_first' mode, the channels dimension (the depth)\n+            is at index 1, in 'channels_last' mode is it at index 4.\n+            It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"tf\".\n+            If you never set it, then it will be \"channels_last\".\n \n     # Input shape\n         5D tensor with shape:\n-        `(samples, channels, dim1, dim2, dim3)` if dim_ordering='th'\n+        `(samples, channels, dim1, dim2, dim3)` if data_format='channels_first'\n         or 5D tensor with shape:\n-        `(samples, dim1, dim2, dim3, channels)` if dim_ordering='tf'.\n+        `(samples, dim1, dim2, dim3, channels)` if data_format='channels_last'.\n \n     # Output shape\n         Same as input\n@@ -233,21 +233,21 @@ class SpatialDropout3D(Dropout):\n         - [Efficient Object Localization Using Convolutional Networks](https://arxiv.org/abs/1411.4280)\n     \"\"\"\n \n-    def __init__(self, p, dim_ordering='default', **kwargs):\n-        if dim_ordering == 'default':\n-            dim_ordering = K.image_dim_ordering()\n-        assert dim_ordering in {'tf', 'th'}, 'dim_ordering must be in {tf, th}'\n-        self.dim_ordering = dim_ordering\n+    def __init__(self, p, data_format='default', **kwargs):\n+        if data_format == 'default':\n+            data_format = K.image_data_format()\n+        assert data_format in {'channels_last', 'channels_first'}, 'data_format must be in {\"channels_last\", \"channels_first\"}'\n+        self.data_format = data_format\n         super(SpatialDropout3D, self).__init__(p, **kwargs)\n \n     def _get_noise_shape(self, x):\n         input_shape = K.shape(x)\n-        if self.dim_ordering == 'th':\n+        if self.data_format == 'channels_first':\n             noise_shape = (input_shape[0], input_shape[1], 1, 1, 1)\n-        elif self.dim_ordering == 'tf':\n+        elif self.data_format == 'channels_last':\n             noise_shape = (input_shape[0], 1, 1, 1, input_shape[4])\n         else:\n-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n+            raise ValueError('Invalid data_format:', self.data_format)\n         return noise_shape\n \n \n\n@@ -92,7 +92,7 @@ class LocallyConnected1D(Layer):\n                              '(only \"valid\" is supported):', border_mode)\n         self.nb_filter = nb_filter\n         self.filter_length = filter_length\n-        self.init = initializations.get(init, dim_ordering='th')\n+        self.init = initializations.get(init, data_format='channels_first')\n         self.activation = activations.get(activation)\n \n         self.border_mode = border_mode\n@@ -240,47 +240,47 @@ class LocallyConnected2D(Layer):\n             (eg. maxnorm, nonneg), applied to the main weights matrix.\n         b_constraint: instance of the [constraints](../constraints.md) module,\n             applied to the bias.\n-        dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension\n-            (the depth) is at index 1, in 'tf' mode is it at index 3.\n+        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension\n+            (the depth) is at index 1, in 'channels_last' mode is it at index 3.\n         bias: whether to include a bias (i.e. make the layer affine rather than linear).\n \n     # Input shape\n         4D tensor with shape:\n-        `(samples, channels, rows, cols)` if dim_ordering='th'\n+        `(samples, channels, rows, cols)` if data_format='channels_first'\n         or 4D tensor with shape:\n-        `(samples, rows, cols, channels)` if dim_ordering='tf'.\n+        `(samples, rows, cols, channels)` if data_format='channels_last'.\n \n     # Output shape\n         4D tensor with shape:\n-        `(samples, nb_filter, new_rows, new_cols)` if dim_ordering='th'\n+        `(samples, nb_filter, new_rows, new_cols)` if data_format='channels_first'\n         or 4D tensor with shape:\n-        `(samples, new_rows, new_cols, nb_filter)` if dim_ordering='tf'.\n+        `(samples, new_rows, new_cols, nb_filter)` if data_format='channels_last'.\n         `rows` and `cols` values might have changed due to padding.\n     \"\"\"\n \n     def __init__(self, nb_filter, nb_row, nb_col,\n                  init='glorot_uniform', activation=None, weights=None,\n                  border_mode='valid', subsample=(1, 1),\n-                 dim_ordering='default',\n+                 data_format='default',\n                  W_regularizer=None, b_regularizer=None, activity_regularizer=None,\n                  W_constraint=None, b_constraint=None,\n                  bias=True, **kwargs):\n-        if dim_ordering == 'default':\n-            dim_ordering = K.image_dim_ordering()\n+        if data_format == 'default':\n+            data_format = K.image_data_format()\n         if border_mode != 'valid':\n             raise ValueError('Invalid border mode for LocallyConnected2D '\n                              '(only \"valid\" is supported):', border_mode)\n         self.nb_filter = nb_filter\n         self.nb_row = nb_row\n         self.nb_col = nb_col\n-        self.init = initializations.get(init, dim_ordering=dim_ordering)\n+        self.init = initializations.get(init, data_format=data_format)\n         self.activation = activations.get(activation)\n \n         self.border_mode = border_mode\n         self.subsample = tuple(subsample)\n-        if dim_ordering not in {'tf', 'th'}:\n-            raise ValueError('`dim_ordering` must be in {tf, th}.')\n-        self.dim_ordering = dim_ordering\n+        if data_format not in {'channels_last', 'channels_first'}:\n+            raise ValueError('`data_format` must be in {\"channels_last\", \"channels_first\"}.')\n+        self.data_format = data_format\n \n         self.W_regularizer = regularizers.get(W_regularizer)\n         self.b_regularizer = regularizers.get(b_regularizer)\n@@ -296,14 +296,14 @@ class LocallyConnected2D(Layer):\n \n     def build(self, input_shape):\n         output_shape = self.get_output_shape_for(input_shape)\n-        if self.dim_ordering == 'th':\n+        if self.data_format == 'channels_first':\n             _, nb_filter, output_row, output_col = output_shape\n             input_filter = input_shape[1]\n-        elif self.dim_ordering == 'tf':\n+        elif self.data_format == 'channels_last':\n             _, output_row, output_col, nb_filter = output_shape\n             input_filter = input_shape[3]\n         else:\n-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n+            raise ValueError('Invalid data_format:', self.data_format)\n \n         self.output_row = output_row\n         self.output_col = output_col\n@@ -330,30 +330,30 @@ class LocallyConnected2D(Layer):\n         self.built = True\n \n     def get_output_shape_for(self, input_shape):\n-        if self.dim_ordering == 'th':\n+        if self.data_format == 'channels_first':\n             rows = input_shape[2]\n             cols = input_shape[3]\n-        elif self.dim_ordering == 'tf':\n+        elif self.data_format == 'channels_last':\n             rows = input_shape[1]\n             cols = input_shape[2]\n         else:\n-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n+            raise ValueError('Invalid data_format:', self.data_format)\n \n         rows = conv_output_length(rows, self.nb_row,\n                                   self.border_mode, self.subsample[0])\n         cols = conv_output_length(cols, self.nb_col,\n                                   self.border_mode, self.subsample[1])\n \n-        if self.dim_ordering == 'th':\n+        if self.data_format == 'channels_first':\n             return (input_shape[0], self.nb_filter, rows, cols)\n-        elif self.dim_ordering == 'tf':\n+        elif self.data_format == 'channels_last':\n             return (input_shape[0], rows, cols, self.nb_filter)\n \n     def call(self, x, mask=None):\n         stride_row, stride_col = self.subsample\n         _, feature_dim, nb_filter = self.W_shape\n \n-        if self.dim_ordering == 'th':\n+        if self.data_format == 'channels_first':\n             if K.backend() == 'theano':\n                 output = []\n                 for i in range(self.output_row):\n@@ -378,7 +378,7 @@ class LocallyConnected2D(Layer):\n                 output = K.batch_dot(x_aggregate, self.W)\n             output = K.reshape(output, (self.output_row, self.output_col, -1, nb_filter))\n             output = K.permute_dimensions(output, (2, 3, 0, 1))\n-        elif self.dim_ordering == 'tf':\n+        elif self.data_format == 'channels_last':\n             xs = []\n             for i in range(self.output_row):\n                 for j in range(self.output_col):\n@@ -392,12 +392,12 @@ class LocallyConnected2D(Layer):\n             output = K.reshape(output, (self.output_row, self.output_col, -1, nb_filter))\n             output = K.permute_dimensions(output, (2, 0, 1, 3))\n         else:\n-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n+            raise ValueError('Invalid data_format:', self.data_format)\n \n         if self.bias:\n-            if self.dim_ordering == 'th':\n+            if self.data_format == 'channels_first':\n                 output += K.reshape(self.b, (1, nb_filter, self.output_row, self.output_col))\n-            elif self.dim_ordering == 'tf':\n+            elif self.data_format == 'channels_last':\n                 output += K.reshape(self.b, (1, self.output_row, self.output_col, nb_filter))\n \n         output = self.activation(output)\n@@ -411,7 +411,7 @@ class LocallyConnected2D(Layer):\n                   'activation': self.activation.__name__,\n                   'border_mode': self.border_mode,\n                   'subsample': self.subsample,\n-                  'dim_ordering': self.dim_ordering,\n+                  'data_format': self.data_format,\n                   'W_regularizer': self.W_regularizer.get_config() if self.W_regularizer else None,\n                   'b_regularizer': self.b_regularizer.get_config() if self.b_regularizer else None,\n                   'activity_regularizer': self.activity_regularizer.get_config() if self.activity_regularizer else None,\n\n@@ -31,7 +31,7 @@ class _Pooling1D(Layer):\n         return (input_shape[0], length, input_shape[2])\n \n     def _pooling_function(self, inputs, pool_size, strides,\n-                          border_mode, dim_ordering):\n+                          border_mode, data_format):\n         raise NotImplementedError\n \n     def call(self, x, mask=None):\n@@ -39,7 +39,7 @@ class _Pooling1D(Layer):\n         output = self._pooling_function(inputs=x, pool_size=self.pool_size,\n                                         strides=self.st,\n                                         border_mode=self.border_mode,\n-                                        dim_ordering='tf')\n+                                        data_format='channels_last')\n         return K.squeeze(output, 2)  # remove dummy last dimension\n \n     def get_config(self):\n@@ -73,9 +73,9 @@ class MaxPooling1D(_Pooling1D):\n                                            border_mode, **kwargs)\n \n     def _pooling_function(self, inputs, pool_size, strides,\n-                          border_mode, dim_ordering):\n+                          border_mode, data_format):\n         output = K.pool2d(inputs, pool_size, strides,\n-                          border_mode, dim_ordering, pool_mode='max')\n+                          border_mode, data_format, pool_mode='max')\n         return output\n \n \n@@ -101,9 +101,9 @@ class AveragePooling1D(_Pooling1D):\n                                                border_mode, **kwargs)\n \n     def _pooling_function(self, inputs, pool_size, strides,\n-                          border_mode, dim_ordering):\n+                          border_mode, data_format):\n         output = K.pool2d(inputs, pool_size, strides,\n-                          border_mode, dim_ordering, pool_mode='avg')\n+                          border_mode, data_format, pool_mode='avg')\n         return output\n \n \n@@ -112,10 +112,10 @@ class _Pooling2D(Layer):\n     \"\"\"\n \n     def __init__(self, pool_size=(2, 2), strides=None, border_mode='valid',\n-                 dim_ordering='default', **kwargs):\n+                 data_format='default', **kwargs):\n         super(_Pooling2D, self).__init__(**kwargs)\n-        if dim_ordering == 'default':\n-            dim_ordering = K.image_dim_ordering()\n+        if data_format == 'default':\n+            data_format = K.image_data_format()\n         self.pool_size = tuple(pool_size)\n         if strides is None:\n             strides = self.pool_size\n@@ -123,33 +123,33 @@ class _Pooling2D(Layer):\n         if border_mode not in {'valid', 'same'}:\n             raise ValueError('`border_mode` must be in {valid, same}.')\n         self.border_mode = border_mode\n-        if dim_ordering not in {'tf', 'th'}:\n-            raise ValueError('`dim_ordering` must be in {tf, th}.')\n-        self.dim_ordering = dim_ordering\n+        if data_format not in {'channels_last', 'channels_first'}:\n+            raise ValueError('`data_format` must be in {\"channels_last\", \"channels_first\"}.')\n+        self.data_format = data_format\n         self.input_spec = [InputSpec(ndim=4)]\n \n     def get_output_shape_for(self, input_shape):\n-        if self.dim_ordering == 'th':\n+        if self.data_format == 'channels_first':\n             rows = input_shape[2]\n             cols = input_shape[3]\n-        elif self.dim_ordering == 'tf':\n+        elif self.data_format == 'channels_last':\n             rows = input_shape[1]\n             cols = input_shape[2]\n         else:\n-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n+            raise ValueError('Invalid data_format:', self.data_format)\n \n         rows = conv_output_length(rows, self.pool_size[0],\n                                   self.border_mode, self.strides[0])\n         cols = conv_output_length(cols, self.pool_size[1],\n                                   self.border_mode, self.strides[1])\n \n-        if self.dim_ordering == 'th':\n+        if self.data_format == 'channels_first':\n             return (input_shape[0], input_shape[1], rows, cols)\n-        elif self.dim_ordering == 'tf':\n+        elif self.data_format == 'channels_last':\n             return (input_shape[0], rows, cols, input_shape[3])\n \n     def _pooling_function(self, inputs, pool_size, strides,\n-                          border_mode, dim_ordering):\n+                          border_mode, data_format):\n         raise NotImplementedError\n \n     def call(self, x, mask=None):\n@@ -157,14 +157,14 @@ class _Pooling2D(Layer):\n                                         pool_size=self.pool_size,\n                                         strides=self.strides,\n                                         border_mode=self.border_mode,\n-                                        dim_ordering=self.dim_ordering)\n+                                        data_format=self.data_format)\n         return output\n \n     def get_config(self):\n         config = {'pool_size': self.pool_size,\n                   'border_mode': self.border_mode,\n                   'strides': self.strides,\n-                  'dim_ordering': self.dim_ordering}\n+                  'data_format': self.data_format}\n         base_config = super(_Pooling2D, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n \n@@ -179,34 +179,34 @@ class MaxPooling2D(_Pooling2D):\n         strides: tuple of 2 integers, or None. Strides values.\n             If None, it will default to `pool_size`.\n         border_mode: 'valid' or 'same'.\n-        dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension\n-            (the depth) is at index 1, in 'tf' mode is it at index 3.\n-            It defaults to the `image_dim_ordering` value found in your\n+        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension\n+            (the depth) is at index 1, in 'channels_last' mode is it at index 3.\n+            It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"tf\".\n+            If you never set it, then it will be \"channels_last\".\n \n     # Input shape\n         4D tensor with shape:\n-        `(samples, channels, rows, cols)` if dim_ordering='th'\n+        `(samples, channels, rows, cols)` if data_format='channels_first'\n         or 4D tensor with shape:\n-        `(samples, rows, cols, channels)` if dim_ordering='tf'.\n+        `(samples, rows, cols, channels)` if data_format='channels_last'.\n \n     # Output shape\n         4D tensor with shape:\n-        `(nb_samples, channels, pooled_rows, pooled_cols)` if dim_ordering='th'\n+        `(nb_samples, channels, pooled_rows, pooled_cols)` if data_format='channels_first'\n         or 4D tensor with shape:\n-        `(samples, pooled_rows, pooled_cols, channels)` if dim_ordering='tf'.\n+        `(samples, pooled_rows, pooled_cols, channels)` if data_format='channels_last'.\n     \"\"\"\n \n     def __init__(self, pool_size=(2, 2), strides=None, border_mode='valid',\n-                 dim_ordering='default', **kwargs):\n+                 data_format='default', **kwargs):\n         super(MaxPooling2D, self).__init__(pool_size, strides, border_mode,\n-                                           dim_ordering, **kwargs)\n+                                           data_format, **kwargs)\n \n     def _pooling_function(self, inputs, pool_size, strides,\n-                          border_mode, dim_ordering):\n+                          border_mode, data_format):\n         output = K.pool2d(inputs, pool_size, strides,\n-                          border_mode, dim_ordering,\n+                          border_mode, data_format,\n                           pool_mode='max')\n         return output\n \n@@ -221,34 +221,34 @@ class AveragePooling2D(_Pooling2D):\n         strides: tuple of 2 integers, or None. Strides values.\n             If None, it will default to `pool_size`.\n         border_mode: 'valid' or 'same'.\n-        dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension\n-            (the depth) is at index 1, in 'tf' mode is it at index 3.\n-            It defaults to the `image_dim_ordering` value found in your\n+        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension\n+            (the depth) is at index 1, in 'channels_last' mode is it at index 3.\n+            It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"tf\".\n+            If you never set it, then it will be \"channels_last\".\n \n     # Input shape\n         4D tensor with shape:\n-        `(samples, channels, rows, cols)` if dim_ordering='th'\n+        `(samples, channels, rows, cols)` if data_format='channels_first'\n         or 4D tensor with shape:\n-        `(samples, rows, cols, channels)` if dim_ordering='tf'.\n+        `(samples, rows, cols, channels)` if data_format='channels_last'.\n \n     # Output shape\n         4D tensor with shape:\n-        `(nb_samples, channels, pooled_rows, pooled_cols)` if dim_ordering='th'\n+        `(nb_samples, channels, pooled_rows, pooled_cols)` if data_format='channels_first'\n         or 4D tensor with shape:\n-        `(samples, pooled_rows, pooled_cols, channels)` if dim_ordering='tf'.\n+        `(samples, pooled_rows, pooled_cols, channels)` if data_format='channels_last'.\n     \"\"\"\n \n     def __init__(self, pool_size=(2, 2), strides=None, border_mode='valid',\n-                 dim_ordering='default', **kwargs):\n+                 data_format='default', **kwargs):\n         super(AveragePooling2D, self).__init__(pool_size, strides, border_mode,\n-                                               dim_ordering, **kwargs)\n+                                               data_format, **kwargs)\n \n     def _pooling_function(self, inputs, pool_size, strides,\n-                          border_mode, dim_ordering):\n+                          border_mode, data_format):\n         output = K.pool2d(inputs, pool_size, strides,\n-                          border_mode, dim_ordering, pool_mode='avg')\n+                          border_mode, data_format, pool_mode='avg')\n         return output\n \n \n@@ -257,10 +257,10 @@ class _Pooling3D(Layer):\n     \"\"\"\n \n     def __init__(self, pool_size=(2, 2, 2), strides=None, border_mode='valid',\n-                 dim_ordering='default', **kwargs):\n+                 data_format='default', **kwargs):\n         super(_Pooling3D, self).__init__(**kwargs)\n-        if dim_ordering == 'default':\n-            dim_ordering = K.image_dim_ordering()\n+        if data_format == 'default':\n+            data_format = K.image_data_format()\n         self.pool_size = tuple(pool_size)\n         if strides is None:\n             strides = self.pool_size\n@@ -268,22 +268,22 @@ class _Pooling3D(Layer):\n         if border_mode not in {'valid', 'same'}:\n             raise ValueError('`border_mode` must be in {valid, same}.')\n         self.border_mode = border_mode\n-        if dim_ordering not in {'tf', 'th'}:\n-            raise ValueError('`dim_ordering` must be in {tf, th}.')\n-        self.dim_ordering = dim_ordering\n+        if data_format not in {'channels_last', 'channels_first'}:\n+            raise ValueError('`data_format` must be in {\"channels_last\", \"channels_first\"}.')\n+        self.data_format = data_format\n         self.input_spec = [InputSpec(ndim=5)]\n \n     def get_output_shape_for(self, input_shape):\n-        if self.dim_ordering == 'th':\n+        if self.data_format == 'channels_first':\n             len_dim1 = input_shape[2]\n             len_dim2 = input_shape[3]\n             len_dim3 = input_shape[4]\n-        elif self.dim_ordering == 'tf':\n+        elif self.data_format == 'channels_last':\n             len_dim1 = input_shape[1]\n             len_dim2 = input_shape[2]\n             len_dim3 = input_shape[3]\n         else:\n-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n+            raise ValueError('Invalid data_format:', self.data_format)\n \n         len_dim1 = conv_output_length(len_dim1, self.pool_size[0],\n                                       self.border_mode, self.strides[0])\n@@ -291,31 +291,31 @@ class _Pooling3D(Layer):\n                                       self.border_mode, self.strides[1])\n         len_dim3 = conv_output_length(len_dim3, self.pool_size[2],\n                                       self.border_mode, self.strides[2])\n-        if self.dim_ordering == 'th':\n+        if self.data_format == 'channels_first':\n             return (input_shape[0],\n                     input_shape[1],\n                     len_dim1, len_dim2, len_dim3)\n-        elif self.dim_ordering == 'tf':\n+        elif self.data_format == 'channels_last':\n             return (input_shape[0],\n                     len_dim1, len_dim2, len_dim3,\n                     input_shape[4])\n \n     def _pooling_function(self, inputs, pool_size, strides,\n-                          border_mode, dim_ordering):\n+                          border_mode, data_format):\n         raise NotImplementedError\n \n     def call(self, x, mask=None):\n         output = self._pooling_function(inputs=x, pool_size=self.pool_size,\n                                         strides=self.strides,\n                                         border_mode=self.border_mode,\n-                                        dim_ordering=self.dim_ordering)\n+                                        data_format=self.data_format)\n         return output\n \n     def get_config(self):\n         config = {'pool_size': self.pool_size,\n                   'border_mode': self.border_mode,\n                   'strides': self.strides,\n-                  'dim_ordering': self.dim_ordering}\n+                  'data_format': self.data_format}\n         base_config = super(_Pooling3D, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n \n@@ -329,34 +329,34 @@ class MaxPooling3D(_Pooling3D):\n             (2, 2, 2) will halve the size of the 3D input in each dimension.\n         strides: tuple of 3 integers, or None. Strides values.\n         border_mode: 'valid' or 'same'.\n-        dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension\n-            (the depth) is at index 1, in 'tf' mode is it at index 4.\n-            It defaults to the `image_dim_ordering` value found in your\n+        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension\n+            (the depth) is at index 1, in 'channels_last' mode is it at index 4.\n+            It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"tf\".\n+            If you never set it, then it will be \"channels_last\".\n \n     # Input shape\n         5D tensor with shape:\n-        `(samples, channels, len_pool_dim1, len_pool_dim2, len_pool_dim3)` if dim_ordering='th'\n+        `(samples, channels, len_pool_dim1, len_pool_dim2, len_pool_dim3)` if data_format='channels_first'\n         or 5D tensor with shape:\n-        `(samples, len_pool_dim1, len_pool_dim2, len_pool_dim3, channels)` if dim_ordering='tf'.\n+        `(samples, len_pool_dim1, len_pool_dim2, len_pool_dim3, channels)` if data_format='channels_last'.\n \n     # Output shape\n         5D tensor with shape:\n-        `(nb_samples, channels, pooled_dim1, pooled_dim2, pooled_dim3)` if dim_ordering='th'\n+        `(nb_samples, channels, pooled_dim1, pooled_dim2, pooled_dim3)` if data_format='channels_first'\n         or 5D tensor with shape:\n-        `(samples, pooled_dim1, pooled_dim2, pooled_dim3, channels)` if dim_ordering='tf'.\n+        `(samples, pooled_dim1, pooled_dim2, pooled_dim3, channels)` if data_format='channels_last'.\n     \"\"\"\n \n     def __init__(self, pool_size=(2, 2, 2), strides=None, border_mode='valid',\n-                 dim_ordering='default', **kwargs):\n+                 data_format='default', **kwargs):\n         super(MaxPooling3D, self).__init__(pool_size, strides, border_mode,\n-                                           dim_ordering, **kwargs)\n+                                           data_format, **kwargs)\n \n     def _pooling_function(self, inputs, pool_size, strides,\n-                          border_mode, dim_ordering):\n+                          border_mode, data_format):\n         output = K.pool3d(inputs, pool_size, strides,\n-                          border_mode, dim_ordering, pool_mode='max')\n+                          border_mode, data_format, pool_mode='max')\n         return output\n \n \n@@ -369,34 +369,34 @@ class AveragePooling3D(_Pooling3D):\n             (2, 2, 2) will halve the size of the 3D input in each dimension.\n         strides: tuple of 3 integers, or None. Strides values.\n         border_mode: 'valid' or 'same'.\n-        dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension\n-            (the depth) is at index 1, in 'tf' mode is it at index 4.\n-            It defaults to the `image_dim_ordering` value found in your\n+        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension\n+            (the depth) is at index 1, in 'channels_last' mode is it at index 4.\n+            It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"tf\".\n+            If you never set it, then it will be \"channels_last\".\n \n     # Input shape\n         5D tensor with shape:\n-        `(samples, channels, len_pool_dim1, len_pool_dim2, len_pool_dim3)` if dim_ordering='th'\n+        `(samples, channels, len_pool_dim1, len_pool_dim2, len_pool_dim3)` if data_format='channels_first'\n         or 5D tensor with shape:\n-        `(samples, len_pool_dim1, len_pool_dim2, len_pool_dim3, channels)` if dim_ordering='tf'.\n+        `(samples, len_pool_dim1, len_pool_dim2, len_pool_dim3, channels)` if data_format='channels_last'.\n \n     # Output shape\n         5D tensor with shape:\n-        `(nb_samples, channels, pooled_dim1, pooled_dim2, pooled_dim3)` if dim_ordering='th'\n+        `(nb_samples, channels, pooled_dim1, pooled_dim2, pooled_dim3)` if data_format='channels_first'\n         or 5D tensor with shape:\n-        `(samples, pooled_dim1, pooled_dim2, pooled_dim3, channels)` if dim_ordering='tf'.\n+        `(samples, pooled_dim1, pooled_dim2, pooled_dim3, channels)` if data_format='channels_last'.\n     \"\"\"\n \n     def __init__(self, pool_size=(2, 2, 2), strides=None, border_mode='valid',\n-                 dim_ordering='default', **kwargs):\n+                 data_format='default', **kwargs):\n         super(AveragePooling3D, self).__init__(pool_size, strides, border_mode,\n-                                               dim_ordering, **kwargs)\n+                                               data_format, **kwargs)\n \n     def _pooling_function(self, inputs, pool_size, strides,\n-                          border_mode, dim_ordering):\n+                          border_mode, data_format):\n         output = K.pool3d(inputs, pool_size, strides,\n-                          border_mode, dim_ordering,\n+                          border_mode, data_format,\n                           pool_mode='avg')\n         return output\n \n@@ -448,15 +448,15 @@ class _GlobalPooling2D(Layer):\n     \"\"\"Abstract class for different global pooling 2D layers.\n     \"\"\"\n \n-    def __init__(self, dim_ordering='default', **kwargs):\n+    def __init__(self, data_format='default', **kwargs):\n         super(_GlobalPooling2D, self).__init__(**kwargs)\n-        if dim_ordering == 'default':\n-            dim_ordering = K.image_dim_ordering()\n-        self.dim_ordering = dim_ordering\n+        if data_format == 'default':\n+            data_format = K.image_data_format()\n+        self.data_format = data_format\n         self.input_spec = [InputSpec(ndim=4)]\n \n     def get_output_shape_for(self, input_shape):\n-        if self.dim_ordering == 'tf':\n+        if self.data_format == 'channels_last':\n             return (input_shape[0], input_shape[3])\n         else:\n             return (input_shape[0], input_shape[1])\n@@ -465,7 +465,7 @@ class _GlobalPooling2D(Layer):\n         raise NotImplementedError\n \n     def get_config(self):\n-        config = {'dim_ordering': self.dim_ordering}\n+        config = {'data_format': self.data_format}\n         base_config = super(_GlobalPooling2D, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n \n@@ -474,17 +474,17 @@ class GlobalAveragePooling2D(_GlobalPooling2D):\n     \"\"\"Global average pooling operation for spatial data.\n \n     # Arguments\n-        dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension\n-            (the depth) is at index 1, in 'tf' mode is it at index 3.\n-            It defaults to the `image_dim_ordering` value found in your\n+        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension\n+            (the depth) is at index 1, in 'channels_last' mode is it at index 3.\n+            It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"tf\".\n+            If you never set it, then it will be \"channels_last\".\n \n     # Input shape\n         4D tensor with shape:\n-        `(samples, channels, rows, cols)` if dim_ordering='th'\n+        `(samples, channels, rows, cols)` if data_format='channels_first'\n         or 4D tensor with shape:\n-        `(samples, rows, cols, channels)` if dim_ordering='tf'.\n+        `(samples, rows, cols, channels)` if data_format='channels_last'.\n \n     # Output shape\n         2D tensor with shape:\n@@ -492,7 +492,7 @@ class GlobalAveragePooling2D(_GlobalPooling2D):\n     \"\"\"\n \n     def call(self, x, mask=None):\n-        if self.dim_ordering == 'tf':\n+        if self.data_format == 'channels_last':\n             return K.mean(x, axis=[1, 2])\n         else:\n             return K.mean(x, axis=[2, 3])\n@@ -502,17 +502,17 @@ class GlobalMaxPooling2D(_GlobalPooling2D):\n     \"\"\"Global max pooling operation for spatial data.\n \n     # Arguments\n-        dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension\n-            (the depth) is at index 1, in 'tf' mode is it at index 3.\n-            It defaults to the `image_dim_ordering` value found in your\n+        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension\n+            (the depth) is at index 1, in 'channels_last' mode is it at index 3.\n+            It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"tf\".\n+            If you never set it, then it will be \"channels_last\".\n \n     # Input shape\n         4D tensor with shape:\n-        `(samples, channels, rows, cols)` if dim_ordering='th'\n+        `(samples, channels, rows, cols)` if data_format='channels_first'\n         or 4D tensor with shape:\n-        `(samples, rows, cols, channels)` if dim_ordering='tf'.\n+        `(samples, rows, cols, channels)` if data_format='channels_last'.\n \n     # Output shape\n         2D tensor with shape:\n@@ -520,7 +520,7 @@ class GlobalMaxPooling2D(_GlobalPooling2D):\n     \"\"\"\n \n     def call(self, x, mask=None):\n-        if self.dim_ordering == 'tf':\n+        if self.data_format == 'channels_last':\n             return K.max(x, axis=[1, 2])\n         else:\n             return K.max(x, axis=[2, 3])\n@@ -530,15 +530,15 @@ class _GlobalPooling3D(Layer):\n     \"\"\"Abstract class for different global pooling 3D layers.\n     \"\"\"\n \n-    def __init__(self, dim_ordering='default', **kwargs):\n+    def __init__(self, data_format='default', **kwargs):\n         super(_GlobalPooling3D, self).__init__(**kwargs)\n-        if dim_ordering == 'default':\n-            dim_ordering = K.image_dim_ordering()\n-        self.dim_ordering = dim_ordering\n+        if data_format == 'default':\n+            data_format = K.image_data_format()\n+        self.data_format = data_format\n         self.input_spec = [InputSpec(ndim=5)]\n \n     def get_output_shape_for(self, input_shape):\n-        if self.dim_ordering == 'tf':\n+        if self.data_format == 'channels_last':\n             return (input_shape[0], input_shape[4])\n         else:\n             return (input_shape[0], input_shape[1])\n@@ -547,7 +547,7 @@ class _GlobalPooling3D(Layer):\n         raise NotImplementedError\n \n     def get_config(self):\n-        config = {'dim_ordering': self.dim_ordering}\n+        config = {'data_format': self.data_format}\n         base_config = super(_GlobalPooling3D, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n \n@@ -556,17 +556,17 @@ class GlobalAveragePooling3D(_GlobalPooling3D):\n     \"\"\"Global Average pooling operation for 3D data.\n \n     # Arguments\n-        dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension\n-            (the depth) is at index 1, in 'tf' mode is it at index 4.\n-            It defaults to the `image_dim_ordering` value found in your\n+        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension\n+            (the depth) is at index 1, in 'channels_last' mode is it at index 4.\n+            It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"tf\".\n+            If you never set it, then it will be \"channels_last\".\n \n     # Input shape\n         5D tensor with shape:\n-        `(samples, channels, len_pool_dim1, len_pool_dim2, len_pool_dim3)` if dim_ordering='th'\n+        `(samples, channels, len_pool_dim1, len_pool_dim2, len_pool_dim3)` if data_format='channels_first'\n         or 5D tensor with shape:\n-        `(samples, len_pool_dim1, len_pool_dim2, len_pool_dim3, channels)` if dim_ordering='tf'.\n+        `(samples, len_pool_dim1, len_pool_dim2, len_pool_dim3, channels)` if data_format='channels_last'.\n \n     # Output shape\n         2D tensor with shape:\n@@ -574,7 +574,7 @@ class GlobalAveragePooling3D(_GlobalPooling3D):\n     \"\"\"\n \n     def call(self, x, mask=None):\n-        if self.dim_ordering == 'tf':\n+        if self.data_format == 'channels_last':\n             return K.mean(x, axis=[1, 2, 3])\n         else:\n             return K.mean(x, axis=[2, 3, 4])\n@@ -584,17 +584,17 @@ class GlobalMaxPooling3D(_GlobalPooling3D):\n     \"\"\"Global Max pooling operation for 3D data.\n \n     # Arguments\n-        dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension\n-            (the depth) is at index 1, in 'tf' mode is it at index 4.\n-            It defaults to the `image_dim_ordering` value found in your\n+        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension\n+            (the depth) is at index 1, in 'channels_last' mode is it at index 4.\n+            It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"tf\".\n+            If you never set it, then it will be \"channels_last\".\n \n     # Input shape\n         5D tensor with shape:\n-        `(samples, channels, len_pool_dim1, len_pool_dim2, len_pool_dim3)` if dim_ordering='th'\n+        `(samples, channels, len_pool_dim1, len_pool_dim2, len_pool_dim3)` if data_format='channels_first'\n         or 5D tensor with shape:\n-        `(samples, len_pool_dim1, len_pool_dim2, len_pool_dim3, channels)` if dim_ordering='tf'.\n+        `(samples, len_pool_dim1, len_pool_dim2, len_pool_dim3, channels)` if data_format='channels_last'.\n \n     # Output shape\n         2D tensor with shape:\n@@ -602,7 +602,7 @@ class GlobalMaxPooling3D(_GlobalPooling3D):\n     \"\"\"\n \n     def call(self, x, mask=None):\n-        if self.dim_ordering == 'tf':\n+        if self.data_format == 'channels_last':\n             return K.max(x, axis=[1, 2, 3])\n         else:\n             return K.max(x, axis=[2, 3, 4])\n\n@@ -191,12 +191,12 @@ def flip_axis(x, axis):\n     return x\n \n \n-def array_to_img(x, dim_ordering='default', scale=True):\n+def array_to_img(x, data_format='default', scale=True):\n     \"\"\"Converts a 3D Numpy array to a PIL Image instance.\n \n     # Arguments\n         x: Input Numpy array.\n-        dim_ordering: Image data format.\n+        data_format: Image data format.\n         scale: Whether to rescale image values\n             to be within [0, 255].\n \n@@ -205,7 +205,7 @@ def array_to_img(x, dim_ordering='default', scale=True):\n \n     # Raises\n         ImportError: if PIL is not available.\n-        ValueError: if invalid `x` or `dim_ordering` is passed.\n+        ValueError: if invalid `x` or `data_format` is passed.\n     \"\"\"\n     if pil_image is None:\n         raise ImportError('Could not import PIL.Image. '\n@@ -215,15 +215,15 @@ def array_to_img(x, dim_ordering='default', scale=True):\n         raise ValueError('Expected image array to have rank 3 (single image). '\n                          'Got array with shape:', x.shape)\n \n-    if dim_ordering == 'default':\n-        dim_ordering = K.image_dim_ordering()\n-    if dim_ordering not in {'th', 'tf'}:\n-        raise ValueError('Invalid dim_ordering:', dim_ordering)\n+    if data_format == 'default':\n+        data_format = K.image_data_format()\n+    if data_format not in {'channels_first', 'channels_last'}:\n+        raise ValueError('Invalid data_format:', data_format)\n \n     # Original Numpy array x has format (height, width, channel)\n     # or (channel, height, width)\n     # but target PIL image has format (width, height, channel)\n-    if dim_ordering == 'th':\n+    if data_format == 'channels_first':\n         x = x.transpose(1, 2, 0)\n     if scale:\n         x += max(-np.min(x), 0)\n@@ -241,32 +241,32 @@ def array_to_img(x, dim_ordering='default', scale=True):\n         raise ValueError('Unsupported channel number: ', x.shape[2])\n \n \n-def img_to_array(img, dim_ordering='default'):\n+def img_to_array(img, data_format='default'):\n     \"\"\"Converts a PIL Image instance to a Numpy array.\n \n     # Arguments\n         img: PIL Image instance.\n-        dim_ordering: Image data format.\n+        data_format: Image data format.\n \n     # Returns\n         A 3D Numpy array (float32).\n \n     # Raises\n-        ValueError: if invalid `img` or `dim_ordering` is passed.\n+        ValueError: if invalid `img` or `data_format` is passed.\n     \"\"\"\n-    if dim_ordering == 'default':\n-        dim_ordering = K.image_dim_ordering()\n-    if dim_ordering not in {'th', 'tf'}:\n-        raise ValueError('Unknown dim_ordering: ', dim_ordering)\n+    if data_format == 'default':\n+        data_format = K.image_data_format()\n+    if data_format not in {'channels_first', 'channels_last'}:\n+        raise ValueError('Unknown data_format: ', data_format)\n     # Numpy array x has format (height, width, channel)\n     # or (channel, height, width)\n     # but original PIL image has format (width, height, channel)\n     x = np.asarray(img, dtype='float32')\n     if len(x.shape) == 3:\n-        if dim_ordering == 'th':\n+        if data_format == 'channels_first':\n             x = x.transpose(2, 0, 1)\n     elif len(x.shape) == 2:\n-        if dim_ordering == 'th':\n+        if data_format == 'channels_first':\n             x = x.reshape((1, x.shape[0], x.shape[1]))\n         else:\n             x = x.reshape((x.shape[0], x.shape[1], 1))\n@@ -341,11 +341,11 @@ class ImageDataGenerator(object):\n             The function should take one argument:\n             one image (Numpy tensor with rank 3),\n             and should output a Numpy tensor with the same shape.\n-        dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension\n-            (the depth) is at index 1, in 'tf' mode it is at index 3.\n-            It defaults to the `image_dim_ordering` value found in your\n+        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension\n+            (the depth) is at index 1, in 'channels_last' mode it is at index 3.\n+            It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"tf\".\n+            If you never set it, then it will be \"channels_last\".\n     \"\"\"\n \n     def __init__(self,\n@@ -366,9 +366,9 @@ class ImageDataGenerator(object):\n                  vertical_flip=False,\n                  rescale=None,\n                  preprocessing_function=None,\n-                 dim_ordering='default'):\n-        if dim_ordering == 'default':\n-            dim_ordering = K.image_dim_ordering()\n+                 data_format='default'):\n+        if data_format == 'default':\n+            data_format = K.image_data_format()\n         self.featurewise_center = featurewise_center\n         self.samplewise_center = samplewise_center\n         self.featurewise_std_normalization = featurewise_std_normalization\n@@ -387,16 +387,16 @@ class ImageDataGenerator(object):\n         self.rescale = rescale\n         self.preprocessing_function = preprocessing_function\n \n-        if dim_ordering not in {'tf', 'th'}:\n-            raise ValueError('dim_ordering should be \"tf\" (channel after row and '\n-                             'column) or \"th\" (channel before row and column). '\n-                             'Received arg: ', dim_ordering)\n-        self.dim_ordering = dim_ordering\n-        if dim_ordering == 'th':\n+        if data_format not in {'channels_last', 'channels_first'}:\n+            raise ValueError('data_format should be \"channels_last\" (channel after row and '\n+                             'column) or \"channels_first\" (channel before row and column). '\n+                             'Received arg: ', data_format)\n+        self.data_format = data_format\n+        if data_format == 'channels_first':\n             self.channel_axis = 1\n             self.row_axis = 2\n             self.col_axis = 3\n-        if dim_ordering == 'tf':\n+        if data_format == 'channels_last':\n             self.channel_axis = 3\n             self.row_axis = 1\n             self.col_axis = 2\n@@ -421,7 +421,7 @@ class ImageDataGenerator(object):\n             batch_size=batch_size,\n             shuffle=shuffle,\n             seed=seed,\n-            dim_ordering=self.dim_ordering,\n+            data_format=self.data_format,\n             save_to_dir=save_to_dir,\n             save_prefix=save_prefix,\n             save_format=save_format)\n@@ -438,7 +438,7 @@ class ImageDataGenerator(object):\n             directory, self,\n             target_size=target_size, color_mode=color_mode,\n             classes=classes, class_mode=class_mode,\n-            dim_ordering=self.dim_ordering,\n+            data_format=self.data_format,\n             batch_size=batch_size, shuffle=shuffle, seed=seed,\n             save_to_dir=save_to_dir,\n             save_prefix=save_prefix,\n@@ -579,7 +579,7 @@ class ImageDataGenerator(object):\n         if x.shape[self.channel_axis] not in {1, 3, 4}:\n             raise ValueError(\n                 'Expected input to be images (as Numpy array) '\n-                'following the dimension ordering convention \"' + self.dim_ordering + '\" '\n+                'following the data format convention \"' + self.data_format + '\" '\n                 '(channels on axis ' + str(self.channel_axis) + '), i.e. expected '\n                 'either 1, 3 or 4 channels on axis ' + str(self.channel_axis) + '. '\n                 'However, it was passed an array with shape ' + str(x.shape) +\n@@ -666,24 +666,24 @@ class NumpyArrayIterator(Iterator):\n \n     def __init__(self, x, y, image_data_generator,\n                  batch_size=32, shuffle=False, seed=None,\n-                 dim_ordering='default',\n+                 data_format='default',\n                  save_to_dir=None, save_prefix='', save_format='jpeg'):\n         if y is not None and len(x) != len(y):\n             raise ValueError('X (images tensor) and y (labels) '\n                              'should have the same length. '\n                              'Found: X.shape = %s, y.shape = %s' %\n                              (np.asarray(x).shape, np.asarray(y).shape))\n-        if dim_ordering == 'default':\n-            dim_ordering = K.image_dim_ordering()\n+        if data_format == 'default':\n+            data_format = K.image_data_format()\n         self.x = np.asarray(x)\n         if self.x.ndim != 4:\n             raise ValueError('Input data in `NumpyArrayIterator` '\n                              'should have rank 4. You passed an array '\n                              'with shape', self.x.shape)\n-        channels_axis = 3 if dim_ordering == 'tf' else 1\n+        channels_axis = 3 if data_format == 'channels_last' else 1\n         if self.x.shape[channels_axis] not in {1, 3, 4}:\n             raise ValueError('NumpyArrayIterator is set to use the '\n-                             'dimension ordering convention \"' + dim_ordering + '\" '\n+                             'data format convention \"' + data_format + '\" '\n                              '(channels on axis ' + str(channels_axis) + '), i.e. expected '\n                              'either 1, 3 or 4 channels on axis ' + str(channels_axis) + '. '\n                              'However, it was passed an array with shape ' + str(self.x.shape) +\n@@ -693,7 +693,7 @@ class NumpyArrayIterator(Iterator):\n         else:\n             self.y = None\n         self.image_data_generator = image_data_generator\n-        self.dim_ordering = dim_ordering\n+        self.data_format = data_format\n         self.save_to_dir = save_to_dir\n         self.save_prefix = save_prefix\n         self.save_format = save_format\n@@ -716,7 +716,7 @@ class NumpyArrayIterator(Iterator):\n             batch_x[i] = x\n         if self.save_to_dir:\n             for i in range(current_batch_size):\n-                img = array_to_img(batch_x[i], self.dim_ordering, scale=True)\n+                img = array_to_img(batch_x[i], self.data_format, scale=True)\n                 fname = '{prefix}_{index}_{hash}.{format}'.format(prefix=self.save_prefix,\n                                                                   index=current_index + i,\n                                                                   hash=np.random.randint(1e4),\n@@ -732,13 +732,13 @@ class DirectoryIterator(Iterator):\n \n     def __init__(self, directory, image_data_generator,\n                  target_size=(256, 256), color_mode='rgb',\n-                 dim_ordering='default',\n+                 data_format='default',\n                  classes=None, class_mode='categorical',\n                  batch_size=32, shuffle=True, seed=None,\n                  save_to_dir=None, save_prefix='', save_format='jpeg',\n                  follow_links=False):\n-        if dim_ordering == 'default':\n-            dim_ordering = K.image_dim_ordering()\n+        if data_format == 'default':\n+            data_format = K.image_data_format()\n         self.directory = directory\n         self.image_data_generator = image_data_generator\n         self.target_size = tuple(target_size)\n@@ -746,14 +746,14 @@ class DirectoryIterator(Iterator):\n             raise ValueError('Invalid color mode:', color_mode,\n                              '; expected \"rgb\" or \"grayscale\".')\n         self.color_mode = color_mode\n-        self.dim_ordering = dim_ordering\n+        self.data_format = data_format\n         if self.color_mode == 'rgb':\n-            if self.dim_ordering == 'tf':\n+            if self.data_format == 'channels_last':\n                 self.image_shape = self.target_size + (3,)\n             else:\n                 self.image_shape = (3,) + self.target_size\n         else:\n-            if self.dim_ordering == 'tf':\n+            if self.data_format == 'channels_last':\n                 self.image_shape = self.target_size + (1,)\n             else:\n                 self.image_shape = (1,) + self.target_size\n@@ -830,14 +830,14 @@ class DirectoryIterator(Iterator):\n             img = load_img(os.path.join(self.directory, fname),\n                            grayscale=grayscale,\n                            target_size=self.target_size)\n-            x = img_to_array(img, dim_ordering=self.dim_ordering)\n+            x = img_to_array(img, data_format=self.data_format)\n             x = self.image_data_generator.random_transform(x)\n             x = self.image_data_generator.standardize(x)\n             batch_x[i] = x\n         # optionally save augmented images to disk for debugging purposes\n         if self.save_to_dir:\n             for i in range(current_batch_size):\n-                img = array_to_img(batch_x[i], self.dim_ordering, scale=True)\n+                img = array_to_img(batch_x[i], self.data_format, scale=True)\n                 fname = '{prefix}_{index}_{hash}.{format}'.format(prefix=self.save_prefix,\n                                                                   index=current_index + i,\n                                                                   hash=np.random.randint(1e4),\n\n@@ -64,34 +64,34 @@ def categorical_probas_to_classes(p):\n     return np.argmax(p, axis=1)\n \n \n-def convert_kernel(kernel, dim_ordering=None):\n+def convert_kernel(kernel, data_format=None):\n     \"\"\"Converts a Numpy kernel matrix from Theano format to TensorFlow format.\n \n     Also works reciprocally, since the transformation is its own inverse.\n \n     # Arguments\n         kernel: Numpy array (4D or 5D).\n-        dim_ordering: the data format.\n+        data_format: the data format.\n \n     # Returns\n         The converted kernel.\n \n     # Raises\n-        ValueError: in case of invalid kernel shape or invalid dim_ordering.\n+        ValueError: in case of invalid kernel shape or invalid data_format.\n     \"\"\"\n-    if dim_ordering is None:\n-        dim_ordering = K.image_dim_ordering()\n+    if data_format is None:\n+        data_format = K.image_data_format()\n     if not 4 <= kernel.ndim <= 5:\n         raise ValueError('Invalid kernel shape:', kernel.shape)\n \n     slices = [slice(None, None, -1) for _ in range(kernel.ndim)]\n     no_flip = (slice(None, None), slice(None, None))\n-    if dim_ordering == 'th':  # (out_depth, input_depth, ...)\n+    if data_format == 'channels_first':  # (out_depth, input_depth, ...)\n         slices[:2] = no_flip\n-    elif dim_ordering == 'tf':  # (..., input_depth, out_depth)\n+    elif data_format == 'channels_last':  # (..., input_depth, out_depth)\n         slices[-2:] = no_flip\n     else:\n-        raise ValueError('Invalid dim_ordering:', dim_ordering)\n+        raise ValueError('Invalid data_format:', data_format)\n \n     return np.copy(kernel[slices])\n \n\n@@ -536,11 +536,11 @@ class TestBackend(object):\n \n                 kernel_val = np.random.random(kernel_shape) - 0.5\n \n-                kernel_th = KTH.variable(convert_kernel(kernel_val, dim_ordering='th'))\n+                kernel_th = KTH.variable(convert_kernel(kernel_val, data_format='channels_first'))\n                 kernel_tf = KTF.variable(kernel_val)\n \n-                zth = KTH.eval(KTH.conv2d(xth, kernel_th, dim_ordering='th'))\n-                ztf = KTF.eval(KTF.conv2d(xtf, kernel_tf, dim_ordering='th'))\n+                zth = KTH.eval(KTH.conv2d(xth, kernel_th, data_format='channels_first'))\n+                ztf = KTF.eval(KTF.conv2d(xtf, kernel_tf, data_format='channels_first'))\n \n                 assert zth.shape == ztf.shape\n                 assert_allclose(zth, ztf, atol=1e-05)\n@@ -555,11 +555,11 @@ class TestBackend(object):\n \n         kernel_val = np.random.random(kernel_shape) - 0.5\n \n-        kernel_th = KTH.variable(convert_kernel(kernel_val, dim_ordering='tf'))\n+        kernel_th = KTH.variable(convert_kernel(kernel_val, data_format='channels_last'))\n         kernel_tf = KTF.variable(kernel_val)\n \n-        zth = KTH.eval(KTH.conv2d(xth, kernel_th, dim_ordering='tf'))\n-        ztf = KTF.eval(KTF.conv2d(xtf, kernel_tf, dim_ordering='tf'))\n+        zth = KTH.eval(KTH.conv2d(xth, kernel_th, data_format='channels_last'))\n+        ztf = KTF.eval(KTF.conv2d(xtf, kernel_tf, data_format='channels_last'))\n \n         assert zth.shape == ztf.shape\n         assert_allclose(zth, ztf, atol=1e-05)\n@@ -570,7 +570,7 @@ class TestBackend(object):\n         # TH kernel shape: (depth, input_depth, x, y, z)\n         # TF kernel shape: (x, y, z, input_depth, depth)\n \n-        # test in dim_ordering = th\n+        # test in data_format = th\n         for input_shape in [(2, 3, 4, 5, 4), (2, 3, 5, 4, 6)]:\n             for kernel_shape in [(4, 3, 2, 2, 2), (4, 3, 3, 2, 4)]:\n                 xval = np.random.random(input_shape)\n@@ -580,16 +580,16 @@ class TestBackend(object):\n \n                 kernel_val = np.random.random(kernel_shape) - 0.5\n \n-                kernel_th = KTH.variable(convert_kernel(kernel_val, dim_ordering='th'))\n+                kernel_th = KTH.variable(convert_kernel(kernel_val, data_format='channels_first'))\n                 kernel_tf = KTF.variable(kernel_val)\n \n-                zth = KTH.eval(KTH.conv3d(xth, kernel_th, dim_ordering='th'))\n-                ztf = KTF.eval(KTF.conv3d(xtf, kernel_tf, dim_ordering='th'))\n+                zth = KTH.eval(KTH.conv3d(xth, kernel_th, data_format='channels_first'))\n+                ztf = KTF.eval(KTF.conv3d(xtf, kernel_tf, data_format='channels_first'))\n \n                 assert zth.shape == ztf.shape\n                 assert_allclose(zth, ztf, atol=1e-05)\n \n-        # test in dim_ordering = tf\n+        # test in data_format = tf\n         input_shape = (1, 2, 2, 2, 1)\n         kernel_shape = (2, 2, 2, 1, 1)\n \n@@ -600,11 +600,11 @@ class TestBackend(object):\n \n         kernel_val = np.random.random(kernel_shape) - 0.5\n \n-        kernel_th = KTH.variable(convert_kernel(kernel_val, dim_ordering='tf'))\n+        kernel_th = KTH.variable(convert_kernel(kernel_val, data_format='channels_last'))\n         kernel_tf = KTF.variable(kernel_val)\n \n-        zth = KTH.eval(KTH.conv3d(xth, kernel_th, dim_ordering='tf'))\n-        ztf = KTF.eval(KTF.conv3d(xtf, kernel_tf, dim_ordering='tf'))\n+        zth = KTH.eval(KTH.conv3d(xth, kernel_th, data_format='channels_last'))\n+        ztf = KTF.eval(KTF.conv3d(xtf, kernel_tf, data_format='channels_last'))\n \n         assert zth.shape == ztf.shape\n         assert_allclose(zth, ztf, atol=1e-05)\n\n@@ -157,7 +157,7 @@ def test_deconvolution_2d():\n                                    'output_shape': (batch_size, nb_filter, rows, cols),\n                                    'border_mode': border_mode,\n                                    'subsample': subsample,\n-                                   'dim_ordering': 'th'},\n+                                   'data_format': 'channels_first'},\n                            input_shape=(nb_samples, stack_size, nb_row, nb_col),\n                            fixed_batch_size=True)\n \n@@ -167,7 +167,7 @@ def test_deconvolution_2d():\n                                    'nb_col': 3,\n                                    'output_shape': (batch_size, nb_filter, rows, cols),\n                                    'border_mode': border_mode,\n-                                   'dim_ordering': 'th',\n+                                   'data_format': 'channels_first',\n                                    'W_regularizer': 'l2',\n                                    'b_regularizer': 'l2',\n                                    'activity_regularizer': 'activity_l2',\n@@ -265,32 +265,32 @@ def test_globalpooling_1d():\n @keras_test\n def test_globalpooling_2d():\n     layer_test(pooling.GlobalMaxPooling2D,\n-               kwargs={'dim_ordering': 'th'},\n+               kwargs={'data_format': 'channels_first'},\n                input_shape=(3, 4, 5, 6))\n     layer_test(pooling.GlobalMaxPooling2D,\n-               kwargs={'dim_ordering': 'tf'},\n+               kwargs={'data_format': 'channels_last'},\n                input_shape=(3, 5, 6, 4))\n     layer_test(pooling.GlobalAveragePooling2D,\n-               kwargs={'dim_ordering': 'th'},\n+               kwargs={'data_format': 'channels_first'},\n                input_shape=(3, 4, 5, 6))\n     layer_test(pooling.GlobalAveragePooling2D,\n-               kwargs={'dim_ordering': 'tf'},\n+               kwargs={'data_format': 'channels_last'},\n                input_shape=(3, 5, 6, 4))\n \n \n @keras_test\n def test_globalpooling_3d():\n     layer_test(pooling.GlobalMaxPooling3D,\n-               kwargs={'dim_ordering': 'th'},\n+               kwargs={'data_format': 'channels_first'},\n                input_shape=(3, 4, 3, 4, 3))\n     layer_test(pooling.GlobalMaxPooling3D,\n-               kwargs={'dim_ordering': 'tf'},\n+               kwargs={'data_format': 'channels_last'},\n                input_shape=(3, 4, 3, 4, 3))\n     layer_test(pooling.GlobalAveragePooling3D,\n-               kwargs={'dim_ordering': 'th'},\n+               kwargs={'data_format': 'channels_first'},\n                input_shape=(3, 4, 3, 4, 3))\n     layer_test(pooling.GlobalAveragePooling3D,\n-               kwargs={'dim_ordering': 'tf'},\n+               kwargs={'data_format': 'channels_last'},\n                input_shape=(3, 4, 3, 4, 3))\n \n \n@@ -432,12 +432,12 @@ def test_zero_padding_2d():\n     stack_size = 2\n     input_nb_row = 4\n     input_nb_col = 5\n-    dim_ordering = K.image_dim_ordering()\n-    assert dim_ordering in {'tf', 'th'}, 'dim_ordering must be in {tf, th}'\n+    data_format = K.image_data_format()\n+    assert data_format in {'channels_last', 'channels_first'}, 'data_format must be in {\"channels_last\", \"channels_first\"}'\n \n-    if dim_ordering == 'tf':\n+    if data_format == 'channels_last':\n         input = np.ones((nb_samples, input_nb_row, input_nb_col, stack_size))\n-    elif dim_ordering == 'th':\n+    elif data_format == 'channels_first':\n         input = np.ones((nb_samples, stack_size, input_nb_row, input_nb_col))\n \n     # basic test\n@@ -456,12 +456,12 @@ def test_zero_padding_2d():\n     layer.build(input.shape)\n     output = layer(K.variable(input))\n     np_output = K.eval(output)\n-    if dim_ordering == 'tf':\n+    if data_format == 'channels_last':\n         for offset in [0, 1, -1, -2]:\n             assert_allclose(np_output[:, offset, :, :], 0.)\n             assert_allclose(np_output[:, :, offset, :], 0.)\n         assert_allclose(np_output[:, 2:-2, 2:-2, :], 1.)\n-    elif dim_ordering == 'th':\n+    elif data_format == 'channels_first':\n         for offset in [0, 1, -1, -2]:\n             assert_allclose(np_output[:, :, offset, :], 0.)\n             assert_allclose(np_output[:, :, :, offset], 0.)\n@@ -471,7 +471,7 @@ def test_zero_padding_2d():\n     layer.build(input.shape)\n     output = layer(K.variable(input))\n     np_output = K.eval(output)\n-    if dim_ordering == 'tf':\n+    if data_format == 'channels_last':\n         for top_offset in [0]:\n             assert_allclose(np_output[:, top_offset, :, :], 0.)\n         for bottom_offset in [-1, -2]:\n@@ -481,7 +481,7 @@ def test_zero_padding_2d():\n         for right_offset in [-1, -2, -3, -4]:\n             assert_allclose(np_output[:, :, right_offset, :], 0.)\n         assert_allclose(np_output[:, 1:-2, 3:-4, :], 1.)\n-    elif dim_ordering == 'th':\n+    elif data_format == 'channels_first':\n         for top_offset in [0]:\n             assert_allclose(np_output[:, :, top_offset, :], 0.)\n         for bottom_offset in [-1, -2]:\n@@ -537,8 +537,8 @@ def test_upsampling_2d():\n     input_nb_row = 11\n     input_nb_col = 12\n \n-    for dim_ordering in ['th', 'tf']:\n-        if dim_ordering == 'th':\n+    for data_format in ['channels_first', 'channels_last']:\n+        if data_format == 'channels_first':\n             input = np.random.rand(nb_samples, stack_size, input_nb_row,\n                                    input_nb_col)\n         else:  # tf\n@@ -549,11 +549,11 @@ def test_upsampling_2d():\n             for length_col in [2, 3, 9]:\n                 layer = convolutional.UpSampling2D(\n                     size=(length_row, length_col),\n-                    dim_ordering=dim_ordering)\n+                    data_format=data_format)\n                 layer.build(input.shape)\n                 output = layer(K.variable(input))\n                 np_output = K.eval(output)\n-                if dim_ordering == 'th':\n+                if data_format == 'channels_first':\n                     assert np_output.shape[2] == length_row * input_nb_row\n                     assert np_output.shape[3] == length_col * input_nb_col\n                 else:  # tf\n@@ -561,7 +561,7 @@ def test_upsampling_2d():\n                     assert np_output.shape[2] == length_col * input_nb_col\n \n                 # compare with numpy\n-                if dim_ordering == 'th':\n+                if data_format == 'channels_first':\n                     expected_out = np.repeat(input, length_row, axis=2)\n                     expected_out = np.repeat(expected_out, length_col, axis=3)\n                 else:  # tf\n@@ -578,8 +578,8 @@ def test_upsampling_3d():\n     input_len_dim2 = 11\n     input_len_dim3 = 12\n \n-    for dim_ordering in ['th', 'tf']:\n-        if dim_ordering == 'th':\n+    for data_format in ['channels_first', 'channels_last']:\n+        if data_format == 'channels_first':\n             input = np.random.rand(nb_samples, stack_size, input_len_dim1, input_len_dim2,\n                                    input_len_dim3)\n         else:  # tf\n@@ -590,11 +590,11 @@ def test_upsampling_3d():\n                 for length_dim3 in [2, 3, 9]:\n                     layer = convolutional.UpSampling3D(\n                         size=(length_dim1, length_dim2, length_dim3),\n-                        dim_ordering=dim_ordering)\n+                        data_format=data_format)\n                     layer.build(input.shape)\n                     output = layer(K.variable(input))\n                     np_output = K.eval(output)\n-                    if dim_ordering == 'th':\n+                    if data_format == 'channels_first':\n                         assert np_output.shape[2] == length_dim1 * input_len_dim1\n                         assert np_output.shape[3] == length_dim2 * input_len_dim2\n                         assert np_output.shape[4] == length_dim3 * input_len_dim3\n@@ -604,7 +604,7 @@ def test_upsampling_3d():\n                         assert np_output.shape[3] == length_dim3 * input_len_dim3\n \n                     # compare with numpy\n-                    if dim_ordering == 'th':\n+                    if data_format == 'channels_first':\n                         expected_out = np.repeat(input, length_dim1, axis=2)\n                         expected_out = np.repeat(expected_out, length_dim2, axis=3)\n                         expected_out = np.repeat(expected_out, length_dim3, axis=4)\n@@ -634,9 +634,9 @@ def test_cropping_2d():\n     input_len_dim1 = 8\n     input_len_dim2 = 8\n     cropping = ((2, 2), (3, 3))\n-    dim_ordering = K.image_dim_ordering()\n+    data_format = K.image_data_format()\n \n-    if dim_ordering == 'th':\n+    if data_format == 'channels_first':\n         input = np.random.rand(nb_samples, stack_size,\n                                input_len_dim1, input_len_dim2)\n     else:\n@@ -646,16 +646,16 @@ def test_cropping_2d():\n     # basic test\n     layer_test(convolutional.Cropping2D,\n                kwargs={'cropping': cropping,\n-                       'dim_ordering': dim_ordering},\n+                       'data_format': data_format},\n                input_shape=input.shape)\n     # correctness test\n     layer = convolutional.Cropping2D(cropping=cropping,\n-                                     dim_ordering=dim_ordering)\n+                                     data_format=data_format)\n     layer.build(input.shape)\n     output = layer(K.variable(input))\n     np_output = K.eval(output)\n     # compare with numpy\n-    if dim_ordering == 'th':\n+    if data_format == 'channels_first':\n         expected_out = input[:,\n                              :,\n                              cropping[0][0]: -cropping[0][1],\n@@ -669,7 +669,7 @@ def test_cropping_2d():\n     # another correctness test (no cropping)\n     cropping = ((0, 0), (0, 0))\n     layer = convolutional.Cropping2D(cropping=cropping,\n-                                     dim_ordering=dim_ordering)\n+                                     data_format=data_format)\n     layer.build(input.shape)\n     output = layer(K.variable(input))\n     np_output = K.eval(output)\n@@ -684,9 +684,9 @@ def test_cropping_3d():\n     input_len_dim2 = 8\n     input_len_dim3 = 8\n     cropping = ((2, 2), (3, 3), (2, 3))\n-    dim_ordering = K.image_dim_ordering()\n+    data_format = K.image_data_format()\n \n-    if dim_ordering == 'th':\n+    if data_format == 'channels_first':\n         input = np.random.rand(nb_samples, stack_size,\n                                input_len_dim1, input_len_dim2, input_len_dim3)\n     else:\n@@ -696,16 +696,16 @@ def test_cropping_3d():\n     # basic test\n     layer_test(convolutional.Cropping3D,\n                kwargs={'cropping': cropping,\n-                       'dim_ordering': dim_ordering},\n+                       'data_format': data_format},\n                input_shape=input.shape)\n     # correctness test\n     layer = convolutional.Cropping3D(cropping=cropping,\n-                                     dim_ordering=dim_ordering)\n+                                     data_format=data_format)\n     layer.build(input.shape)\n     output = layer(K.variable(input))\n     np_output = K.eval(output)\n     # compare with numpy\n-    if dim_ordering == 'th':\n+    if data_format == 'channels_first':\n         expected_out = input[:,\n                              :,\n                              cropping[0][0]: -cropping[0][1],\n@@ -721,7 +721,7 @@ def test_cropping_3d():\n     # another correctness test (no cropping)\n     cropping = ((0, 0), (0, 0), (0, 0))\n     layer = convolutional.Cropping3D(cropping=cropping,\n-                                     dim_ordering=dim_ordering)\n+                                     data_format=data_format)\n     layer.build(input.shape)\n     output = layer(K.variable(input))\n     np_output = K.eval(output)\n\n@@ -18,9 +18,9 @@ def test_recurrent_convolutional():\n     input_nb_row = 5\n     input_nb_col = 5\n     sequence_len = 2\n-    for dim_ordering in ['th', 'tf']:\n+    for data_format in ['channels_first', 'channels_last']:\n \n-        if dim_ordering == 'th':\n+        if data_format == 'channels_first':\n             input = np.random.rand(nb_samples, sequence_len,\n                                    input_channel,\n                                    input_nb_row, input_nb_col)\n@@ -32,7 +32,7 @@ def test_recurrent_convolutional():\n         for return_sequences in [True, False]:\n             # test for ouptput shape:\n             output = layer_test(convolutional_recurrent.ConvLSTM2D,\n-                                kwargs={'dim_ordering': dim_ordering,\n+                                kwargs={'data_format': data_format,\n                                         'return_sequences': return_sequences,\n                                         'nb_filter': nb_filter,\n                                         'nb_row': nb_row,\n@@ -42,7 +42,7 @@ def test_recurrent_convolutional():\n \n             output_shape = [nb_samples, input_nb_row, input_nb_col]\n \n-            if dim_ordering == 'th':\n+            if data_format == 'channels_first':\n                 output_shape.insert(1, nb_filter)\n             else:\n                 output_shape.insert(3, nb_filter)\n@@ -53,12 +53,12 @@ def test_recurrent_convolutional():\n             assert output.shape == tuple(output_shape)\n \n             # No need to check statefulness for both\n-            if dim_ordering == 'th' or return_sequences:\n+            if data_format == 'channels_first' or return_sequences:\n                 continue\n \n             # Tests for statefulness\n             model = Sequential()\n-            kwargs = {'dim_ordering': dim_ordering,\n+            kwargs = {'data_format': data_format,\n                       'return_sequences': return_sequences,\n                       'nb_filter': nb_filter,\n                       'nb_row': nb_row,\n@@ -97,7 +97,7 @@ def test_recurrent_convolutional():\n             assert(out4.max() != out5.max())\n \n             # check regularizers\n-            kwargs = {'dim_ordering': dim_ordering,\n+            kwargs = {'data_format': data_format,\n                       'return_sequences': return_sequences,\n                       'nb_filter': nb_filter,\n                       'nb_row': nb_row,\n@@ -116,7 +116,7 @@ def test_recurrent_convolutional():\n \n             # check dropout\n             layer_test(convolutional_recurrent.ConvLSTM2D,\n-                       kwargs={'dim_ordering': dim_ordering,\n+                       kwargs={'data_format': data_format,\n                                'return_sequences': return_sequences,\n                                'nb_filter': nb_filter,\n                                'nb_row': nb_row,\n\n@@ -56,7 +56,7 @@ def test_locallyconnected_2d():\n                                'b_regularizer': 'l2',\n                                'activity_regularizer': 'activity_l2',\n                                'subsample': subsample,\n-                               'dim_ordering': 'tf'},\n+                               'data_format': 'channels_last'},\n                        input_shape=(nb_samples, nb_row, nb_col, stack_size))\n \n             layer_test(local.LocallyConnected2D,\n@@ -68,7 +68,7 @@ def test_locallyconnected_2d():\n                                'b_regularizer': 'l2',\n                                'activity_regularizer': 'activity_l2',\n                                'subsample': subsample,\n-                               'dim_ordering': 'th'},\n+                               'data_format': 'channels_first'},\n                        input_shape=(nb_samples, stack_size, nb_row, nb_col))\n \n \n\n@@ -68,7 +68,7 @@ class TestImage:\n             featurewise_std_normalization=True,\n             samplewise_std_normalization=True,\n             zca_whitening=True,\n-            dim_ordering='tf')\n+            data_format='channels_last')\n         # Test fit with invalid data\n         with pytest.raises(ValueError):\n             x = np.random.random((3, 10, 10))\n@@ -97,7 +97,7 @@ class TestImage:\n             featurewise_std_normalization=True,\n             samplewise_std_normalization=True,\n             zca_whitening=True,\n-            dim_ordering='tf')\n+            data_format='channels_last')\n         # Test grayscale\n         x = np.random.random((32, 10, 10, 1))\n         generator.fit(x)\n@@ -110,7 +110,7 @@ class TestImage:\n             featurewise_std_normalization=True,\n             samplewise_std_normalization=True,\n             zca_whitening=True,\n-            dim_ordering='th')\n+            data_format='channels_first')\n         # Test grayscale\n         x = np.random.random((32, 1, 10, 10))\n         generator.fit(x)\n@@ -163,30 +163,30 @@ class TestImage:\n     def test_img_utils(self):\n         height, width = 10, 8\n \n-        # Test th dim ordering\n+        # Test th data format\n         x = np.random.random((3, height, width))\n-        img = image.array_to_img(x, dim_ordering='th')\n+        img = image.array_to_img(x, data_format='channels_first')\n         assert img.size == (width, height)\n-        x = image.img_to_array(img, dim_ordering='th')\n+        x = image.img_to_array(img, data_format='channels_first')\n         assert x.shape == (3, height, width)\n         # Test 2D\n         x = np.random.random((1, height, width))\n-        img = image.array_to_img(x, dim_ordering='th')\n+        img = image.array_to_img(x, data_format='channels_first')\n         assert img.size == (width, height)\n-        x = image.img_to_array(img, dim_ordering='th')\n+        x = image.img_to_array(img, data_format='channels_first')\n         assert x.shape == (1, height, width)\n \n-        # Test tf dim ordering\n+        # Test tf data format\n         x = np.random.random((height, width, 3))\n-        img = image.array_to_img(x, dim_ordering='tf')\n+        img = image.array_to_img(x, data_format='channels_last')\n         assert img.size == (width, height)\n-        x = image.img_to_array(img, dim_ordering='tf')\n+        x = image.img_to_array(img, data_format='channels_last')\n         assert x.shape == (height, width, 3)\n         # Test 2D\n         x = np.random.random((height, width, 1))\n-        img = image.array_to_img(x, dim_ordering='tf')\n+        img = image.array_to_img(x, data_format='channels_last')\n         assert img.size == (width, height)\n-        x = image.img_to_array(img, dim_ordering='tf')\n+        x = image.img_to_array(img, data_format='channels_last')\n         assert x.shape == (height, width, 1)\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
