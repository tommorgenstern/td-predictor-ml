{"custom_id": "keras#d138e315d5e1ba30ca3fc7ea6610b72cfc226b83", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 49 | Contributors (this commit): 2 | Commits (past 90d): 5 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -183,7 +183,6 @@ def compute_output_spec(fn, *args, **kwargs):\n             with StatelessScope():\n                 return fn(*rec_args, **kwargs, **static_kwargs)\n \n-        output_spec = None\n         if has_none:\n             ms_args_1, ms_kwargs_1 = tree.map_structure(\n                 lambda x: convert_keras_tensor_to_jax(x, fill_value=83),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7412791b70c23ccf334d33e7c5521e0229792b3f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 68 | Lines Deleted: 34 | Files Changed: 8 | Hunks: 25 | Methods Changed: 18 | Complexity Δ (Sum/Max): 7/4 | Churn Δ: 102 | Churn Cumulative: 458 | Contributors (this commit): 5 | Commits (past 90d): 22 | Contributors (cumulative): 20 | DMM Complexity: 0.8214285714285714\n\nDIFF:\n@@ -16,6 +16,7 @@ class InputLayer(Layer):\n         sparse=None,\n         batch_shape=None,\n         input_tensor=None,\n+        optional=False,\n         name=None,\n         **kwargs,\n     ):\n@@ -69,6 +70,7 @@ class InputLayer(Layer):\n         self._input_tensor = input_tensor\n         Node(operation=self, call_args=(), call_kwargs={}, outputs=input_tensor)\n         self.built = True\n+        self.optional = optional\n \n     def call(self):\n         return\n@@ -95,6 +97,7 @@ def Input(\n     batch_shape=None,\n     name=None,\n     tensor=None,\n+    optional=False,\n ):\n     \"\"\"Used to instantiate a Keras tensor.\n \n@@ -127,6 +130,8 @@ def Input(\n         tensor: Optional existing tensor to wrap into the `Input` layer.\n             If set, the layer will use this tensor rather\n             than creating a new placeholder tensor.\n+        optional: Boolean, whether the input is optional or not.\n+            An optional input can accept `None` values.\n \n     Returns:\n       A Keras tensor.\n@@ -148,5 +153,6 @@ def Input(\n         batch_shape=batch_shape,\n         name=name,\n         input_tensor=tensor,\n+        optional=optional,\n     )\n     return layer.output\n\n@@ -30,6 +30,8 @@ class InputSpec:\n             as long as the last axis of the spec is 1.\n         name: Expected key corresponding to this input when passing data as\n             a dictionary.\n+        optional: Boolean, whether the input is optional or not.\n+            An optional input can accept `None` values.\n \n     Example:\n \n@@ -56,6 +58,7 @@ class InputSpec:\n         axes=None,\n         allow_last_axis_squeeze=False,\n         name=None,\n+        optional=False,\n     ):\n         self.dtype = (\n             backend.standardize_dtype(dtype) if dtype is not None else None\n@@ -69,6 +72,7 @@ class InputSpec:\n         self.max_ndim = max_ndim\n         self.min_ndim = min_ndim\n         self.name = name\n+        self.optional = optional\n         self.allow_last_axis_squeeze = allow_last_axis_squeeze\n         try:\n             axes = axes or {}\n@@ -152,22 +156,6 @@ def assert_input_compatibility(input_spec, inputs, layer_name):\n             inputs = list_inputs\n \n     inputs = tree.flatten(inputs)\n-    if len(input_spec) != len(inputs):\n-        raise ValueError(\n-            f\"Layer '{layer_name}' expected {len(input_spec)} input(s). \"\n-            f\"Received {len(inputs)} instead.\"\n-        )\n-    for x in inputs:\n-        # Having a shape/dtype is the only commonality of the various\n-        # tensor-like objects that may be passed. The most common kind of\n-        # invalid type we are guarding for is a Layer instance (Functional API),\n-        # which does not have a `shape` attribute.\n-        if not hasattr(x, \"shape\"):\n-            raise ValueError(\n-                f\"Inputs to a layer should be tensors. Got '{x}' \"\n-                f\"(of type {type(x)}) as input for layer '{layer_name}'.\"\n-            )\n-\n     if len(inputs) != len(input_spec):\n         raise ValueError(\n             f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n@@ -177,6 +165,18 @@ def assert_input_compatibility(input_spec, inputs, layer_name):\n     for input_index, (x, spec) in enumerate(zip(inputs, input_spec)):\n         if spec is None:\n             continue\n+        if x is None and spec.optional:\n+            continue\n+\n+        # Having a shape/dtype is the only commonality of the various\n+        # tensor-like objects that may be passed. The most common kind of\n+        # invalid type we are guarding for is a Layer instance (Functional API),\n+        # which does not have a `shape` attribute.\n+        if not hasattr(x, \"shape\"):\n+            raise ValueError(\n+                f\"Inputs to a layer should be tensors. Got '{x}' \"\n+                f\"(of type {type(x)}) as input for layer '{layer_name}'.\"\n+            )\n \n         shape = backend.standardize_shape(x.shape)\n         ndim = len(shape)\n\n@@ -747,8 +747,10 @@ class Layer(BackendLayer, Operation, KerasSaveable):\n         # 2. Enforce that only tensors can be passed positionally.\n         if not self._allow_non_tensor_positional_args:\n             for arg in tree.flatten(args):\n-                if not isinstance(arg, KerasTensor) and not backend.is_tensor(\n-                    arg\n+                if (\n+                    not isinstance(arg, KerasTensor)\n+                    and not backend.is_tensor(arg)\n+                    and arg is not None\n                 ):\n                     raise ValueError(\n                         \"Only input tensors may be passed as \"\n\n@@ -207,8 +207,13 @@ class Functional(Function, Model):\n     def _convert_inputs_to_tensors(self, flat_inputs):\n         converted = []\n         for x, input in zip(flat_inputs, self._inputs):\n+            if x is None:  # TODO: check if optional\n+                converted.append(x)\n+            else:\n                 converted.append(\n-                ops.convert_to_tensor(x, dtype=input.dtype, sparse=input.sparse)\n+                    ops.convert_to_tensor(\n+                        x, dtype=input.dtype, sparse=input.sparse\n+                    )\n                 )\n         return converted\n \n@@ -216,6 +221,9 @@ class Functional(Function, Model):\n         flat_ref_shapes = [x.shape for x in self._inputs]\n         adjusted = []\n         for x, ref_shape in zip(flat_inputs, flat_ref_shapes):\n+            if x is None:\n+                adjusted.append(x)\n+                continue\n             x_rank = len(x.shape)\n             ref_rank = len(ref_shape)\n             if x_rank == ref_rank:\n@@ -273,10 +281,15 @@ class Functional(Function, Model):\n             return tuple(x)\n \n         def make_spec_for_tensor(x):\n+            optional = False\n+            if isinstance(x._keras_history[0], InputLayer):\n+                if x._keras_history[0].optional:\n+                    optional = True\n             return InputSpec(\n                 shape=shape_with_no_batch_size(x.shape),\n                 allow_last_axis_squeeze=True,\n                 name=x._keras_history[0].name,\n+                optional=optional,\n             )\n \n         if isinstance(self._inputs_struct, dict):\n\n@@ -304,7 +304,7 @@ class FunctionalTest(testing.TestCase):\n             ValueError, r\"expected shape=\\(None, 4\\), found shape=\\(2, 3\\)\"\n         ):\n             model(np.zeros((2, 3)))\n-        with self.assertRaisesRegex(ValueError, \"expected 1 input\"):\n+        with self.assertRaisesRegex(ValueError, \"expects 1 input\"):\n             model([np.zeros((2, 4)), np.zeros((2, 4))])\n \n         # List input\n@@ -313,7 +313,7 @@ class FunctionalTest(testing.TestCase):\n         x = input_a + input_b\n         outputs = layers.Dense(2)(x)\n         model = Functional([input_a, input_b], outputs)\n-        with self.assertRaisesRegex(ValueError, \"expected 2 input\"):\n+        with self.assertRaisesRegex(ValueError, \"expects 2 input\"):\n             model(np.zeros((2, 3)))\n         with self.assertRaisesRegex(\n             ValueError, r\"expected shape=\\(None, 4\\), found shape=\\(2, 3\\)\"\n@@ -322,7 +322,7 @@ class FunctionalTest(testing.TestCase):\n \n         # Dict input\n         model = Functional({\"a\": input_a, \"b\": input_b}, outputs)\n-        with self.assertRaisesRegex(ValueError, \"expected 2 input\"):\n+        with self.assertRaisesRegex(ValueError, \"expects 2 input\"):\n             model(np.zeros((2, 3)))\n         with self.assertRaisesRegex(\n             ValueError, r\"expected shape=\\(None, 4\\), found shape=\\(2, 3\\)\"\n@@ -432,6 +432,26 @@ class FunctionalTest(testing.TestCase):\n             out_eager[\"others\"][\"3\"], new_out_eager[\"others\"][\"3\"]\n         )\n \n+    def test_optional_inputs(self):\n+        class OptionalInputLayer(layers.Layer):\n+            def call(self, x, y=None):\n+                if y is not None:\n+                    return x + y\n+                return x\n+\n+            def compute_output_shape(self, x_shape):\n+                return x_shape\n+\n+        i1 = Input((2,))\n+        i2 = Input((2,), optional=True)\n+        outputs = OptionalInputLayer()(i1, i2)\n+        model = Model([i1, i2], outputs)\n+\n+        # Eager test\n+        out = model([np.ones((2, 2)), None])\n+        self.assertAllClose(out, np.ones((2, 2)))\n+        # Note: it's not intended to work in symbolic mode (yet).\n+\n     def test_add_loss(self):\n         # TODO\n         pass\n\n@@ -79,10 +79,7 @@ class Operation:\n         try:\n             return backend.compute_output_spec(self.call, *args, **kwargs)\n         except Exception as e:\n-            if isinstance(e, TypeError):\n-                raise e\n-            else:\n-                new_e = RuntimeError(\n+            new_e = e.__class__(\n                 \"Could not automatically infer the output shape / dtype of \"\n                 f\"'{self.name}' (of type {self.__class__.__name__}). \"\n                 f\"Either the `{self.__class__.__name__}.call()` method \"\n\n@@ -40,9 +40,7 @@ class SymbolicArguments:\n \n         def switch_fn(x):\n             if isinstance(x, KerasTensor):\n-                val = tensor_dict.get(id(x), None)\n-                if val is not None:\n-                    return val\n+                return tensor_dict.get(id(x), None)\n             return x\n \n         return self.convert(switch_fn)\n\n@@ -99,8 +99,7 @@ class SymbolicArgumentsTest(testing.TestCase):\n \n         # Call the method to be tested\n         result, _ = sym_args.fill_in(tensor_dict)\n-\n-        self.assertEqual(result, ((a, 2),))\n+        self.assertEqual(result, ((None, 2),))\n \n     # Testing fill in function for args and kwargs\n     def test_fill_in(self):\n@@ -115,9 +114,8 @@ class SymbolicArgumentsTest(testing.TestCase):\n                 a,\n                 b,\n             ),\n-            {1: c},\n+            {\"1\": c},\n         )\n \n         (values, _) = sym_args.fill_in(dictionary)\n-\n-        self.assertEqual(values, ((3, b), {1: 2}))\n+        self.assertEqual(values, ((3, None), {\"1\": 2}))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f12a205015f1611bc99021870613cb7e2b916522", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 3 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 9 | Churn Cumulative: 79 | Contributors (this commit): 5 | Commits (past 90d): 6 | Contributors (cumulative): 5 | DMM Complexity: 0.4\n\nDIFF:\n@@ -1450,7 +1450,9 @@ class Layer(BackendLayer, Operation, KerasSaveable):\n         return backend.name_scope(self.name, caller=self)\n \n \n-def is_backend_tensor_or_symbolic(x):\n+def is_backend_tensor_or_symbolic(x, allow_none=False):\n+    if allow_none and x is None:\n+        return True\n     return backend.is_tensor(x) or isinstance(x, backend.KerasTensor)\n \n \n@@ -1485,7 +1487,10 @@ class CallSpec:\n                 tensor_arg_dict[name] = value\n             elif tree.is_nested(value) and len(value) > 0:\n                 flat_values = tree.flatten(value)\n-                if all(is_backend_tensor_or_symbolic(x) for x in flat_values):\n+                if all(\n+                    is_backend_tensor_or_symbolic(x, allow_none=True)\n+                    for x in flat_values\n+                ):\n                     tensor_args.append(value)\n                     tensor_arg_names.append(name)\n                     tensor_arg_dict[name] = value\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7b4697e02767a216cf7723da75a665b65f3f5bd8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 62 | Lines Deleted: 18 | Files Changed: 4 | Hunks: 20 | Methods Changed: 20 | Complexity Δ (Sum/Max): 4/1 | Churn Δ: 80 | Churn Cumulative: 339 | Contributors (this commit): 2 | Commits (past 90d): 18 | Contributors (cumulative): 8 | DMM Complexity: 1.0\n\nDIFF:\n@@ -146,7 +146,7 @@ class Dense(Layer):\n             )\n         return self._kernel\n \n-    def call(self, inputs):\n+    def call(self, inputs, training=None):\n         x = ops.matmul(inputs, self.kernel)\n         if self.bias is not None:\n             x = ops.add(x, self.bias)\n@@ -310,7 +310,7 @@ class Dense(Layer):\n                 f\"Expected: {[v.name for v in all_vars]}\"\n             )\n \n-    \"\"\"Quantization-related (int8 and float8) methods\"\"\"\n+    # Quantization-related (int8 and float8) methods\n \n     QUANTIZATION_MODE_ERROR_TEMPLATE = (\n         f\"Invalid quantization mode. Expected one of \"\n@@ -402,11 +402,11 @@ class Dense(Layer):\n         self.outputs_grad_amax_history.overwrite_with_gradient = True\n         self._is_quantized = True\n \n-    def quantized_call(self, inputs):\n+    def quantized_call(self, inputs, training=None):\n         if self.dtype_policy.quantization_mode == \"int8\":\n             return self._int8_call(inputs)\n         elif self.dtype_policy.quantization_mode == \"float8\":\n-            return self._float8_call(inputs)\n+            return self._float8_call(inputs, training=training)\n         else:\n             mode = self.dtype_policy.quantization_mode\n             raise NotImplementedError(\n@@ -448,7 +448,7 @@ class Dense(Layer):\n             x = self.activation(x)\n         return x\n \n-    def _float8_call(self, inputs):\n+    def _float8_call(self, inputs, training=None):\n         if self.lora_enabled:\n             raise NotImplementedError(\n                 \"Currently, `_float8_call` doesn't support LoRA\"\n@@ -456,6 +456,7 @@ class Dense(Layer):\n \n         @ops.custom_gradient\n         def quantized_dequantize_inputs(inputs, scale, amax_history):\n+            if training:\n                 new_scale = quantizers.compute_float8_scale(\n                     ops.max(amax_history, axis=0),\n                     scale,\n@@ -463,12 +464,15 @@ class Dense(Layer):\n                         float(ml_dtypes.finfo(\"float8_e4m3fn\").max), \"float32\"\n                     ),\n                 )\n-            qdq_inputs = quantizers.quantize_and_dequantize(\n-                inputs, scale, \"float8_e4m3fn\", self.compute_dtype\n-            )\n                 new_amax_history = quantizers.compute_float8_amax_history(\n                     inputs, amax_history\n                 )\n+            else:\n+                new_scale = None\n+                new_amax_history = None\n+            qdq_inputs = quantizers.quantize_and_dequantize(\n+                inputs, scale, \"float8_e4m3fn\", self.compute_dtype\n+            )\n \n             def grad(*args, upstream=None, variables=None):\n                 if upstream is None:\n\n@@ -597,7 +597,9 @@ class DenseTest(testing.TestCase, parameterized.TestCase):\n             import jax\n \n             def stateless_loss_fn(trainable_variables, x, dy):\n-                y = layer.stateless_call(trainable_variables, [], x)[0]\n+                y = layer.stateless_call(\n+                    trainable_variables, [], x, training=True\n+                )[0]\n                 loss = y * ops.cast(dy, y.dtype)\n                 return ops.sum(loss)\n \n@@ -732,3 +734,17 @@ class DenseTest(testing.TestCase, parameterized.TestCase):\n                 reloaded_layer.non_trainable_weights,\n                 len(model.non_trainable_weights),\n             )\n+\n+    @pytest.mark.requires_trainable_backend\n+    def test_quantize_float8_inference(self):\n+        config = dict(units=16)\n+        layer = layers.Dense(**config)\n+        layer.build((None, 8))\n+        layer.quantize(\"float8\")\n+\n+        # Try calling with `training=False` and the result must match\n+        # `training=True` because there is no update.\n+        x = np.random.random((64, 8))\n+        y_inference = layer(x, training=False)\n+        y_training = layer(x, training=True)\n+        self.assertAllClose(y_inference, y_training)\n\n@@ -206,7 +206,7 @@ class EinsumDense(Layer):\n     def compute_output_shape(self, _):\n         return self.full_output_shape\n \n-    def call(self, inputs):\n+    def call(self, inputs, training=None):\n         x = ops.einsum(self.equation, inputs, self.kernel)\n         if self.bias is not None:\n             x += self.bias\n@@ -369,7 +369,7 @@ class EinsumDense(Layer):\n                 f\"Expected: {[v.name for v in all_vars]}\"\n             )\n \n-    \"\"\"Quantization-related (int8 and float8) methods\"\"\"\n+    # Quantization-related (int8 and float8) methods\n \n     QUANTIZATION_MODE_ERROR_TEMPLATE = (\n         f\"Invalid quantization mode. Expected one of \"\n@@ -488,11 +488,11 @@ class EinsumDense(Layer):\n         self.outputs_grad_amax_history.overwrite_with_gradient = True\n         self._is_quantized = True\n \n-    def quantized_call(self, inputs):\n+    def quantized_call(self, inputs, training=None):\n         if self.dtype_policy.quantization_mode == \"int8\":\n             return self._int8_call(inputs)\n         elif self.dtype_policy.quantization_mode == \"float8\":\n-            return self._float8_call(inputs)\n+            return self._float8_call(inputs, training=training)\n         else:\n             mode = self.dtype_policy.quantization_mode\n             raise NotImplementedError(\n@@ -562,7 +562,7 @@ class EinsumDense(Layer):\n             x = self.activation(x)\n         return x\n \n-    def _float8_call(self, inputs):\n+    def _float8_call(self, inputs, training=None):\n         if self.lora_enabled:\n             raise NotImplementedError(\n                 \"Currently, `_float8_call` doesn't support LoRA\"\n@@ -570,6 +570,7 @@ class EinsumDense(Layer):\n \n         @ops.custom_gradient\n         def quantized_dequantize_inputs(inputs, scale, amax_history):\n+            if training:\n                 new_scale = quantizers.compute_float8_scale(\n                     ops.max(amax_history, axis=0),\n                     scale,\n@@ -577,12 +578,15 @@ class EinsumDense(Layer):\n                         float(ml_dtypes.finfo(\"float8_e4m3fn\").max), \"float32\"\n                     ),\n                 )\n-            qdq_inputs = quantizers.quantize_and_dequantize(\n-                inputs, scale, \"float8_e4m3fn\", self.compute_dtype\n-            )\n                 new_amax_history = quantizers.compute_float8_amax_history(\n                     inputs, amax_history\n                 )\n+            else:\n+                new_scale = None\n+                new_amax_history = None\n+            qdq_inputs = quantizers.quantize_and_dequantize(\n+                inputs, scale, \"float8_e4m3fn\", self.compute_dtype\n+            )\n \n             def grad(*args, upstream=None, variables=None):\n                 if upstream is None:\n\n@@ -731,7 +731,9 @@ class EinsumDenseTest(testing.TestCase, parameterized.TestCase):\n             import jax\n \n             def stateless_loss_fn(trainable_variables, x, dy):\n-                y = layer.stateless_call(trainable_variables, [], x)[0]\n+                y = layer.stateless_call(\n+                    trainable_variables, [], x, training=True\n+                )[0]\n                 loss = y * ops.cast(dy, y.dtype)\n                 return ops.sum(loss)\n \n@@ -870,3 +872,21 @@ class EinsumDenseTest(testing.TestCase, parameterized.TestCase):\n                 reloaded_layer.non_trainable_weights,\n                 len(model.non_trainable_weights),\n             )\n+\n+    @pytest.mark.requires_trainable_backend\n+    def test_quantize_float8_inference(self):\n+        config = dict(\n+            equation=\"ab,bcd->acd\",\n+            output_shape=(8, 32),\n+            bias_axes=\"d\",\n+        )\n+        layer = layers.EinsumDense(**config)\n+        layer.build((None, 3))\n+        layer.quantize(\"float8\")\n+\n+        # Try calling with `training=False` and the result must match\n+        # `training=True` because there is no update.\n+        x = np.random.random((64, 3))\n+        y_inference = layer(x, training=False)\n+        y_training = layer(x, training=True)\n+        self.assertAllClose(y_inference, y_training)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1353b11f343f06da7e8739369668de86d4875f23", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 32 | Lines Deleted: 0 | Files Changed: 16 | Hunks: 32 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 32 | Churn Cumulative: 98 | Contributors (this commit): 2 | Commits (past 90d): 32 | Contributors (cumulative): 32 | DMM Complexity: None\n\nDIFF:\n@@ -63,12 +63,14 @@ class Conv1D(BaseConv):\n             bias after being updated by an `Optimizer`.\n \n     Input shape:\n+\n     - If `data_format=\"channels_last\"`:\n         A 3D tensor with shape: `(batch_shape, steps, channels)`\n     - If `data_format=\"channels_first\"`:\n         A 3D tensor with shape: `(batch_shape, channels, steps)`\n \n     Output shape:\n+    \n     - If `data_format=\"channels_last\"`:\n         A 3D tensor with shape: `(batch_shape, new_steps, filters)`\n     - If `data_format=\"channels_first\"`:\n\n@@ -57,12 +57,14 @@ class Conv1DTranspose(BaseConvTranspose):\n             bias after being updated by an `Optimizer`.\n \n     Input shape:\n+\n     - If `data_format=\"channels_last\"`:\n         A 3D tensor with shape: `(batch_shape, steps, channels)`\n     - If `data_format=\"channels_first\"`:\n         A 3D tensor with shape: `(batch_shape, channels, steps)`\n \n     Output shape:\n+    \n     - If `data_format=\"channels_last\"`:\n         A 3D tensor with shape: `(batch_shape, new_steps, filters)`\n     - If `data_format=\"channels_first\"`:\n\n@@ -59,12 +59,14 @@ class Conv2D(BaseConv):\n             bias after being updated by an `Optimizer`.\n \n     Input shape:\n+\n     - If `data_format=\"channels_last\"`:\n         A 4D tensor with shape: `(batch_size, height, width, channels)`\n     - If `data_format=\"channels_first\"`:\n         A 4D tensor with shape: `(batch_size, channels, height, width)`\n \n     Output shape:\n+    \n     - If `data_format=\"channels_last\"`:\n         A 4D tensor with shape: `(batch_size, new_height, new_width, filters)`\n     - If `data_format=\"channels_first\"`:\n\n@@ -59,12 +59,14 @@ class Conv2DTranspose(BaseConvTranspose):\n             bias after being updated by an `Optimizer`.\n \n     Input shape:\n+\n     - If `data_format=\"channels_last\"`:\n         A 4D tensor with shape: `(batch_size, height, width, channels)`\n     - If `data_format=\"channels_first\"`:\n         A 4D tensor with shape: `(batch_size, channels, height, width)`\n \n     Output shape:\n+    \n     - If `data_format=\"channels_last\"`:\n         A 4D tensor with shape: `(batch_size, new_height, new_width, filters)`\n     - If `data_format=\"channels_first\"`:\n\n@@ -59,6 +59,7 @@ class Conv3D(BaseConv):\n             bias after being updated by an `Optimizer`.\n \n     Input shape:\n+\n     - If `data_format=\"channels_last\"`:\n         5D tensor with shape:\n         `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n@@ -67,6 +68,7 @@ class Conv3D(BaseConv):\n         `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n \n     Output shape:\n+    \n     - If `data_format=\"channels_last\"`:\n         5D tensor with shape:\n         `(batch_size, new_spatial_dim1, new_spatial_dim2, new_spatial_dim3,\n\n@@ -59,6 +59,7 @@ class Conv3DTranspose(BaseConvTranspose):\n             bias after being updated by an `Optimizer`.\n \n     Input shape:\n+\n     - If `data_format=\"channels_last\"`:\n         5D tensor with shape:\n         `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n@@ -67,6 +68,7 @@ class Conv3DTranspose(BaseConvTranspose):\n         `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n \n     Output shape:\n+    \n     - If `data_format=\"channels_last\"`:\n         5D tensor with shape:\n         `(batch_size, new_spatial_dim1, new_spatial_dim2, new_spatial_dim3,\n\n@@ -67,12 +67,14 @@ class DepthwiseConv1D(BaseDepthwiseConv):\n             bias after being updated by an `Optimizer`.\n \n     Input shape:\n+\n     - If `data_format=\"channels_last\"`:\n         A 3D tensor with shape: `(batch_shape, steps, channels)`\n     - If `data_format=\"channels_first\"`:\n         A 3D tensor with shape: `(batch_shape, channels, steps)`\n \n     Output shape:\n+    \n     - If `data_format=\"channels_last\"`:\n         A 3D tensor with shape:\n         `(batch_shape, new_steps, channels * depth_multiplier)`\n\n@@ -68,12 +68,14 @@ class DepthwiseConv2D(BaseDepthwiseConv):\n             bias after being updated by an `Optimizer`.\n \n     Input shape:\n+\n     - If `data_format=\"channels_last\"`:\n         A 4D tensor with shape: `(batch_size, height, width, channels)`\n     - If `data_format=\"channels_first\"`:\n         A 4D tensor with shape: `(batch_size, channels, height, width)`\n \n     Output shape:\n+    \n     - If `data_format=\"channels_last\"`:\n         A 4D tensor with shape:\n         `(batch_size, new_height, new_width, channels * depth_multiplier)`\n\n@@ -70,12 +70,14 @@ class SeparableConv1D(BaseSeparableConv):\n             bias after being updated by an `Optimizer`.\n \n     Input shape:\n+\n     - If `data_format=\"channels_last\"`:\n         A 3D tensor with shape: `(batch_shape, steps, channels)`\n     - If `data_format=\"channels_first\"`:\n         A 3D tensor with shape: `(batch_shape, channels, steps)`\n \n     Output shape:\n+    \n     - If `data_format=\"channels_last\"`:\n         A 3D tensor with shape: `(batch_shape, new_steps, filters)`\n     - If `data_format=\"channels_first\"`:\n\n@@ -71,12 +71,14 @@ class SeparableConv2D(BaseSeparableConv):\n             bias after being updated by an `Optimizer`.\n \n     Input shape:\n+\n     - If `data_format=\"channels_last\"`:\n         A 4D tensor with shape: `(batch_size, height, width, channels)`\n     - If `data_format=\"channels_first\"`:\n         A 4D tensor with shape: `(batch_size, channels, height, width)`\n \n     Output shape:\n+    \n     - If `data_format=\"channels_last\"`:\n         A 4D tensor with shape: `(batch_size, new_height, new_width, filters)`\n     - If `data_format=\"channels_first\"`:\n\n@@ -31,12 +31,14 @@ class AveragePooling1D(BasePooling):\n             If you never set it, then it will be `\"channels_last\"`.\n \n     Input shape:\n+\n     - If `data_format=\"channels_last\"`:\n         3D tensor with shape `(batch_size, steps, features)`.\n     - If `data_format=\"channels_first\"`:\n         3D tensor with shape `(batch_size, features, steps)`.\n \n     Output shape:\n+    \n     - If `data_format=\"channels_last\"`:\n         3D tensor with shape `(batch_size, downsampled_steps, features)`.\n     - If `data_format=\"channels_first\"`:\n\n@@ -40,12 +40,14 @@ class AveragePooling2D(BasePooling):\n             `\"channels_last\"`.\n \n     Input shape:\n+\n     - If `data_format=\"channels_last\"`:\n         4D tensor with shape `(batch_size, height, width, channels)`.\n     - If `data_format=\"channels_first\"`:\n         4D tensor with shape `(batch_size, channels, height, width)`.\n \n     Output shape:\n+    \n     - If `data_format=\"channels_last\"`:\n         4D tensor with shape\n         `(batch_size, pooled_height, pooled_width, channels)`.\n\n@@ -33,6 +33,7 @@ class AveragePooling3D(BasePooling):\n             will be `\"channels_last\"`.\n \n     Input shape:\n+\n     - If `data_format=\"channels_last\"`:\n         5D tensor with shape:\n         `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n@@ -41,6 +42,7 @@ class AveragePooling3D(BasePooling):\n         `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n \n     Output shape:\n+    \n     - If `data_format=\"channels_last\"`:\n         5D tensor with shape:\n         `(batch_size, pooled_dim1, pooled_dim2, pooled_dim3, channels)`\n\n@@ -32,12 +32,14 @@ class MaxPooling1D(BasePooling):\n             If you never set it, then it will be `\"channels_last\"`.\n \n     Input shape:\n+\n     - If `data_format=\"channels_last\"`:\n         3D tensor with shape `(batch_size, steps, features)`.\n     - If `data_format=\"channels_first\"`:\n         3D tensor with shape `(batch_size, features, steps)`.\n \n     Output shape:\n+    \n     - If `data_format=\"channels_last\"`:\n         3D tensor with shape `(batch_size, downsampled_steps, features)`.\n     - If `data_format=\"channels_first\"`:\n\n@@ -40,12 +40,14 @@ class MaxPooling2D(BasePooling):\n             `\"channels_last\"`.\n \n     Input shape:\n+\n     - If `data_format=\"channels_last\"`:\n         4D tensor with shape `(batch_size, height, width, channels)`.\n     - If `data_format=\"channels_first\"`:\n         4D tensor with shape `(batch_size, channels, height, width)`.\n \n     Output shape:\n+    \n     - If `data_format=\"channels_last\"`:\n         4D tensor with shape\n         `(batch_size, pooled_height, pooled_width, channels)`.\n\n@@ -33,6 +33,7 @@ class MaxPooling3D(BasePooling):\n             will be `\"channels_last\"`.\n \n     Input shape:\n+\n     - If `data_format=\"channels_last\"`:\n         5D tensor with shape:\n         `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n@@ -41,6 +42,7 @@ class MaxPooling3D(BasePooling):\n         `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n \n     Output shape:\n+    \n     - If `data_format=\"channels_last\"`:\n         5D tensor with shape:\n         `(batch_size, pooled_dim1, pooled_dim2, pooled_dim3, channels)`\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#603db8003caee499b3f0e98fc08716dd93076734", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 188 | Lines Deleted: 22 | Files Changed: 7 | Hunks: 14 | Methods Changed: 15 | Complexity Δ (Sum/Max): 21/8 | Churn Δ: 210 | Churn Cumulative: 329 | Contributors (this commit): 5 | Commits (past 90d): 19 | Contributors (cumulative): 17 | DMM Complexity: 0.5793650793650794\n\nDIFF:\n@@ -870,12 +870,14 @@ class Layer(BackendLayer, Operation, KerasSaveable):\n             # Set masks on outputs,\n             # provided only the first positional input arg and its mask.\n             # TODO: consider extending this to all args and kwargs.\n-            previous_mask = getattr(call_spec.first_arg, \"_keras_mask\", None)\n+            previous_mask = tree.map_structure(\n+                lambda x: getattr(x, \"_keras_mask\", None), call_spec.first_arg\n+            )\n             if self.supports_masking:\n                 self._set_mask_metadata(\n                     call_spec.first_arg, outputs, previous_mask\n                 )\n-            elif previous_mask is not None:\n+            elif any(m is not None for m in tree.flatten(previous_mask)):\n                 warnings.warn(\n                     f\"Layer '{self.name}' (of type {self.__class__.__name__}) \"\n                     \"was passed an input with a mask attached to it. \"\n\n@@ -20,6 +20,43 @@ class Merge(Layer):\n     def _merge_function(self, inputs):\n         raise NotImplementedError\n \n+    def _apply_merge_op_and_or_mask(self, op_fn, inputs):\n+        \"\"\"Merge a set of inputs by applying `op_fn` and ORing the masks.\n+\n+        We use this for `Minimum` and `Maximum` as it handles the fact that\n+        there is no identity element. If applicable, the mask obtained by ORing\n+        all masks is set on the output.\n+\n+        Args:\n+            op_fn: binary operation to apply to tensor pair.\n+            inputs: array of tensors to apply operation on.\n+        \"\"\"\n+        output = None\n+        output_mask = None\n+\n+        for x in inputs:\n+            mask = getattr(x, \"_keras_mask\", None)\n+            if mask is not None:\n+                mask = ops.broadcast_to(ops.expand_dims(mask, -1), ops.shape(x))\n+            if output is None:\n+                output = x\n+                output_mask = mask\n+                continue\n+            if mask is not None:\n+                x = ops.where(mask, x, output)\n+            if output_mask is not None:\n+                output = ops.where(output_mask, output, x)\n+            if mask is not None and output_mask is not None:\n+                output_mask = ops.logical_or(output_mask, mask)\n+            else:\n+                output_mask = None\n+            output = op_fn(output, x)\n+\n+        if output_mask is not None:\n+            output_mask = ops.any(output_mask, axis=-1, keepdims=False)\n+            output._keras_mask = output_mask\n+        return output\n+\n     def _compute_elemwise_op_output_shape(self, shape1, shape2):\n         \"\"\"Computes the shape of the resultant of an elementwise operation.\n \n@@ -231,10 +268,14 @@ class Merge(Layer):\n                 f\"Received: inputs={inputs} of length {len(inputs)}, and \"\n                 f\"mask={mask} of length {len(mask)}\"\n             )\n-        if all(m is None for m in mask):\n+        # Default implementation does an OR between the masks, which works\n+        # for `Add`, `Subtract`, `Average`, `Maximum`, `Minimum`, `Multiply`.\n+        if any(m is None for m in mask):\n             return None\n-        masks = [ops.expand_dims(m, axis=0) for m in mask if m is not None]\n-        return ops.all(ops.concatenate(masks, axis=0), axis=0, keepdims=False)\n+        output_mask = mask[0]\n+        for m in mask[1:]:\n+            output_mask = ops.logical_or(output_mask, m)\n+        return output_mask\n \n     def get_config(self):\n         return super().get_config()\n\n@@ -145,11 +145,15 @@ class Concatenate(Merge):\n                 masks.append(ops.ones_like(input_i, dtype=\"bool\"))\n             elif mask_i.ndim < input_i.ndim:\n                 # Mask is smaller than the input, expand it\n-                masks.append(ops.expand_dims(mask_i, axis=-1))\n+                masks.append(\n+                    ops.broadcast_to(\n+                        ops.expand_dims(mask_i, axis=-1), ops.shape(input_i)\n+                    )\n+                )\n             else:\n                 masks.append(mask_i)\n         concatenated = ops.concatenate(masks, axis=self.axis)\n-        return ops.all(concatenated, axis=-1, keepdims=False)\n+        return ops.any(concatenated, axis=-1, keepdims=False)\n \n     def get_config(self):\n         config = {\"axis\": self.axis}\n\n@@ -31,10 +31,7 @@ class Maximum(Merge):\n     \"\"\"\n \n     def _merge_function(self, inputs):\n-        output = inputs[0]\n-        for i in range(1, len(inputs)):\n-            output = ops.maximum(output, inputs[i])\n-        return output\n+        return self._apply_merge_op_and_or_mask(ops.maximum, inputs)\n \n \n @keras_export(\"keras.layers.maximum\")\n\n@@ -125,14 +125,14 @@ class MergingLayersTest(testing.TestCase, parameterized.TestCase):\n         self.assertEqual(res.shape, expected_output_shape)\n         self.assertAllClose(res, x3, atol=1e-4)\n         self.assertIsNone(layer.compute_mask([input_1, input_2], [None, None]))\n+        self.assertIsNone(layer.compute_mask([x1, x2], [None, None]))\n         if not skip_mask_test:\n+            mask1 = np.ones(input_shape[:-1], dtype=np.bool_)\n+            mask2 = np.ones(input_shape[:-1], dtype=np.bool_)\n             self.assertTrue(\n                 np.all(\n                     backend.convert_to_numpy(\n-                        layer.compute_mask(\n-                            [input_1, input_2],\n-                            [backend.Variable(x1), backend.Variable(x2)],\n-                        )\n+                        layer.compute_mask([x1, x2], [mask1, mask2])\n                     )\n                 )\n             )\n@@ -234,6 +234,111 @@ class MergingLayersTest(testing.TestCase, parameterized.TestCase):\n         c = layers.Dot(axes=(-2, -1))([a, b])\n         self.assertEqual(backend.standardize_shape(c.shape), (1, 2, 1, 2))\n \n+    def test_add_with_mask(self):\n+        mask = layers.Masking()\n+        x1 = mask(backend.convert_to_tensor([[[0, 0], [1, 2], [0, 0], [3, 4]]]))\n+        x2 = backend.convert_to_tensor([[[0, 0], [0, 0], [1, 2], [3, 4]]])\n+\n+        output = layers.Add()([x1, x2])\n+        self.assertAllClose(output, [[[0, 0], [1, 2], [1, 2], [6, 8]]])\n+        self.assertIsNone(getattr(output, \"_keras_mask\", None))\n+\n+        x2 = mask(x2)\n+        output = layers.Add()([x1, x2])\n+        self.assertAllClose(output, [[[0, 0], [1, 2], [1, 2], [6, 8]]])\n+        self.assertAllClose(output._keras_mask, [[0, 1, 1, 1]])\n+\n+    def test_subtract_with_mask(self):\n+        mask = layers.Masking()\n+        x1 = mask(backend.convert_to_tensor([[[0, 0], [1, 2], [0, 0], [3, 4]]]))\n+        x2 = backend.convert_to_tensor([[[0, 0], [0, 0], [1, 2], [3, 4]]])\n+\n+        output = layers.Subtract()([x1, x2])\n+        self.assertAllClose(output, [[[0, 0], [1, 2], [-1, -2], [0, 0]]])\n+        self.assertIsNone(getattr(output, \"_keras_mask\", None))\n+\n+        x2 = mask(x2)\n+        output = layers.Subtract()([x1, x2])\n+        self.assertAllClose(output, [[[0, 0], [1, 2], [-1, -2], [0, 0]]])\n+        self.assertAllClose(output._keras_mask, [[0, 1, 1, 1]])\n+\n+    def test_average_with_mask(self):\n+        mask = layers.Masking()\n+        x1 = mask(backend.convert_to_tensor([[[0, 0], [1, 2], [0, 0], [3, 4]]]))\n+        x2 = backend.convert_to_tensor([[[0, 0], [0, 0], [1, 2], [3, 4]]])\n+\n+        output = layers.Average()([x1, x2])\n+        self.assertAllClose(output, [[[0, 0], [0.5, 1], [0.5, 1], [3, 4]]])\n+        self.assertIsNone(getattr(output, \"_keras_mask\", None))\n+\n+        x2 = mask(x2)\n+        output = layers.Average()([x1, x2])\n+        self.assertAllClose(output, [[[0, 0], [0.5, 1], [0.5, 1], [3, 4]]])\n+        self.assertAllClose(output._keras_mask, [[0, 1, 1, 1]])\n+\n+    def test_multiply_with_mask(self):\n+        mask = layers.Masking()\n+        x1 = mask(backend.convert_to_tensor([[[0, 0], [1, 2], [0, 0], [3, 4]]]))\n+        x2 = backend.convert_to_tensor([[[0, 0], [0, 0], [1, 2], [3, 4]]])\n+\n+        output = layers.Multiply()([x1, x2])\n+        self.assertAllClose(output, [[[0, 0], [0, 0], [1, 2], [9, 16]]])\n+        self.assertIsNone(getattr(output, \"_keras_mask\", None))\n+\n+        x2 = mask(x2)\n+        output = layers.Multiply()([x1, x2])\n+        self.assertAllClose(output, [[[0, 0], [1, 2], [1, 2], [9, 16]]])\n+        self.assertAllClose(output._keras_mask, [[0, 1, 1, 1]])\n+\n+    def test_maximum_with_mask(self):\n+        mask = layers.Masking()\n+        x1 = mask(\n+            backend.convert_to_tensor([[[0, 0], [-1, -2], [0, 0], [-3, -4]]])\n+        )\n+        x2 = backend.convert_to_tensor([[[0, 0], [0, 0], [-1, -2], [-3, -4]]])\n+\n+        output = layers.Maximum()([x1, x2])\n+        self.assertAllClose(output, [[[0, 0], [0, 0], [-1, -2], [-3, -4]]])\n+        self.assertIsNone(getattr(output, \"_keras_mask\", None))\n+\n+        x2 = mask(x2)\n+        output = layers.Maximum()([x1, x2])\n+        self.assertAllClose(output, [[[0, 0], [-1, -2], [-1, -2], [-3, -4]]])\n+        self.assertAllClose(output._keras_mask, [[0, 1, 1, 1]])\n+\n+    def test_minimum_with_mask(self):\n+        mask = layers.Masking()\n+        x1 = mask(backend.convert_to_tensor([[[0, 0], [1, 2], [0, 0], [3, 4]]]))\n+        x2 = backend.convert_to_tensor([[[0, 0], [0, 0], [1, 2], [3, 4]]])\n+\n+        output = layers.Minimum()([x1, x2])\n+        self.assertAllClose(output, [[[0, 0], [0, 0], [1, 2], [3, 4]]])\n+        self.assertIsNone(getattr(output, \"_keras_mask\", None))\n+\n+        x2 = mask(x2)\n+        output = layers.Minimum()([x1, x2])\n+        self.assertAllClose(output, [[[0, 0], [1, 2], [1, 2], [3, 4]]])\n+        self.assertAllClose(output._keras_mask, [[0, 1, 1, 1]])\n+\n+    def test_concatenate_with_mask(self):\n+        mask = layers.Masking()\n+        x1 = mask(backend.convert_to_tensor([[[0, 0], [1, 2], [0, 0], [3, 4]]]))\n+        x2 = backend.convert_to_tensor([[[0, 0], [0, 0], [1, 2], [3, 4]]])\n+\n+        output = layers.Concatenate(axis=1)([x1, x2])\n+        self.assertAllClose(\n+            output,\n+            [[[0, 0], [1, 2], [0, 0], [3, 4], [0, 0], [0, 0], [1, 2], [3, 4]]],\n+        )\n+        self.assertAllClose(output._keras_mask, [[0, 1, 0, 1, 1, 1, 1, 1]])\n+\n+        output = layers.Concatenate(axis=2)([x1, x2])\n+        self.assertAllClose(\n+            output,\n+            [[[0, 0, 0, 0], [1, 2, 0, 0], [0, 0, 1, 2], [3, 4, 3, 4]]],\n+        )\n+        self.assertAllClose(output._keras_mask, [[1, 1, 1, 1]])\n+\n     @parameterized.named_parameters(TEST_PARAMETERS)\n     @pytest.mark.skipif(\n         not backend.SUPPORTS_SPARSE_TENSORS,\n\n@@ -31,10 +31,7 @@ class Minimum(Merge):\n     \"\"\"\n \n     def _merge_function(self, inputs):\n-        output = inputs[0]\n-        for i in range(1, len(inputs)):\n-            output = ops.minimum(output, inputs[i])\n-        return output\n+        return self._apply_merge_op_and_or_mask(ops.minimum, inputs)\n \n \n @keras_export(\"keras.layers.minimum\")\n\n@@ -31,9 +31,29 @@ class Multiply(Merge):\n     \"\"\"\n \n     def _merge_function(self, inputs):\n-        output = inputs[0]\n-        for i in range(1, len(inputs)):\n-            output = ops.multiply(output, inputs[i])\n+        masks = [getattr(x, \"_keras_mask\", None) for x in inputs]\n+        has_output_mask = all(mask is not None for mask in masks)\n+        output = None\n+        output_mask = None\n+\n+        for x, mask in zip(inputs, masks):\n+            if mask is not None:\n+                mask = ops.broadcast_to(ops.expand_dims(mask, -1), ops.shape(x))\n+                # Replace 0s with 1s outside of mask.\n+                x = ops.where(mask, x, ops.cast(1, x.dtype))\n+                if has_output_mask:\n+                    output_mask = (\n+                        mask\n+                        if output_mask is None\n+                        else ops.logical_or(output_mask, mask)\n+                    )\n+            output = x if output is None else ops.multiply(output, x)\n+\n+        if has_output_mask:\n+            # Replace 1s with 0s outside of mask per standard masking rules.\n+            output = ops.where(output_mask, output, ops.cast(0, output.dtype))\n+            output_mask = ops.any(output_mask, axis=-1, keepdims=False)\n+            output._keras_mask = output_mask\n         return output\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#10c27c0e9b4fd8157deaf2824da1fca32be07c1f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 23 | Lines Deleted: 9 | Files Changed: 4 | Hunks: 7 | Methods Changed: 4 | Complexity Δ (Sum/Max): 6/6 | Churn Δ: 32 | Churn Cumulative: 1120 | Contributors (this commit): 8 | Commits (past 90d): 39 | Contributors (cumulative): 17 | DMM Complexity: 0.2\n\nDIFF:\n@@ -273,9 +273,11 @@ def conv(\n             f\"kernel in_channels {kernel_in_channels}. \"\n         )\n     feature_group_count = channels // kernel_in_channels\n+    kernel = convert_to_tensor(kernel)\n+    inputs = convert_to_tensor(inputs, dtype=kernel.dtype)\n     return jax.lax.conv_general_dilated(\n-        convert_to_tensor(inputs),\n-        convert_to_tensor(kernel),\n+        inputs,\n+        kernel,\n         strides,\n         padding,\n         rhs_dilation=dilation_rate,\n\n@@ -1251,8 +1251,8 @@ def split(x, indices_or_sections, axis=0):\n         dim=axis,\n     )\n     if dim == 0 and isinstance(indices_or_sections, int):\n-        out = tuple(out[0].clone() for _ in range(indices_or_sections))\n-    return out\n+        out = [out[0].clone() for _ in range(indices_or_sections)]\n+    return list(out)\n \n \n def stack(x, axis=0):\n\n@@ -1076,15 +1076,26 @@ def _crop_images(\n             f\"Received: target_width={target_width}\"\n         )\n \n+    if isinstance(top_cropping, int) and isinstance(left_cropping, int):\n+        start_indices = [0, top_cropping, left_cropping, 0]\n+    else:\n+        start_indices = backend.numpy.stack([0, top_cropping, left_cropping, 0])\n+    if (\n+        isinstance(batch, int)\n+        and isinstance(target_height, int)\n+        and isinstance(target_width, int)\n+        and isinstance(depth, int)\n+    ):\n+        shape = [batch, target_height, target_width, depth]\n+    else:\n+        shape = backend.numpy.stack([batch, target_height, target_width, depth])\n     cropped = ops.slice(\n         images,\n-        backend.numpy.stack([0, top_cropping, left_cropping, 0]),\n-        backend.numpy.stack([batch, target_height, target_width, depth]),\n+        start_indices,\n+        shape,\n     )\n \n-    cropped_shape = [batch, target_height, target_width, depth]\n-    cropped = backend.numpy.reshape(cropped, cropped_shape)\n-\n+    cropped = backend.numpy.reshape(cropped, shape)\n     if not is_batch:\n         cropped = backend.numpy.squeeze(cropped, axis=[0])\n     return cropped\n\n@@ -3974,6 +3974,7 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n \n     def test_split(self):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n+        self.assertIsInstance(knp.split(x, 2), list)\n         self.assertAllClose(knp.split(x, 2), np.split(x, 2))\n         self.assertAllClose(knp.Split(2)(x), np.split(x, 2))\n         self.assertAllClose(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#43e515558b041a3875e5ca26c4172cc17218fbdf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 465 | Lines Deleted: 7 | Files Changed: 8 | Hunks: 13 | Methods Changed: 27 | Complexity Δ (Sum/Max): 106/39 | Churn Δ: 472 | Churn Cumulative: 1087 | Contributors (this commit): 8 | Commits (past 90d): 39 | Contributors (cumulative): 30 | DMM Complexity: 0.45110410094637227\n\nDIFF:\n@@ -15,6 +15,7 @@ from keras.src.ops.core import convert_to_tensor\n from keras.src.ops.core import custom_gradient\n from keras.src.ops.core import fori_loop\n from keras.src.ops.core import is_tensor\n+from keras.src.ops.core import scan\n from keras.src.ops.core import scatter\n from keras.src.ops.core import scatter_update\n from keras.src.ops.core import shape\n\n@@ -15,6 +15,7 @@ from keras.src.ops.core import convert_to_tensor\n from keras.src.ops.core import custom_gradient\n from keras.src.ops.core import fori_loop\n from keras.src.ops.core import is_tensor\n+from keras.src.ops.core import scan\n from keras.src.ops.core import scatter\n from keras.src.ops.core import scatter_update\n from keras.src.ops.core import shape\n\n@@ -253,6 +253,18 @@ def vectorized_map(function, elements):\n     return jax.vmap(function)(elements)\n \n \n+def scan(f, init, xs=None, length=None, reverse=False, unroll=1):\n+    if not isinstance(unroll, bool):\n+        if not isinstance(unroll, int) or unroll < 1:\n+            raise ValueError(\n+                \"`unroll` must be an positive integer or boolean. \"\n+                f\"Received: unroll={unroll}\"\n+            )\n+    return jax.lax.scan(\n+        f, init=init, xs=xs, length=length, reverse=reverse, unroll=unroll\n+    )\n+\n+\n def scatter(indices, values, shape):\n     zeros = jnp.zeros(shape, values.dtype)\n     key = tuple(jnp.moveaxis(indices, -1, 0))\n\n@@ -140,6 +140,55 @@ def compute_output_spec(fn, *args, **kwargs):\n     return output_spec\n \n \n+def scan(f, init, xs=None, length=None, reverse=False, unroll=1):\n+    # Ref: jax.lax.scan\n+    if not callable(f):\n+        raise TypeError(f\"`f` should be a callable. Received: f={f}\")\n+    if not isinstance(unroll, bool):\n+        if not isinstance(unroll, int) or unroll < 1:\n+            raise ValueError(\n+                \"`unroll` must be an positive integer or boolean. \"\n+                f\"Received: unroll={unroll}\"\n+            )\n+    if xs is None and length is None:\n+        raise ValueError(\"Got no `xs` to scan over and `length` not provided.\")\n+\n+    input_is_sequence = tree.is_nested(xs)\n+    output_is_sequence = tree.is_nested(init)\n+\n+    def pack_input(x):\n+        return tree.pack_sequence_as(xs, x) if input_is_sequence else x[0]\n+\n+    def pack_output(x):\n+        return tree.pack_sequence_as(init, x) if output_is_sequence else x[0]\n+\n+    if xs is None:\n+        xs_flat = []\n+        n = int(length)\n+    else:\n+        xs_flat = tree.flatten(xs)\n+        xs_flat = [convert_to_tensor(elem) for elem in xs_flat]\n+        n = int(length) if length is not None else shape(xs_flat[0])[0]\n+\n+    init_flat = tree.flatten(init)\n+    init_flat = [convert_to_tensor(init) for init in init_flat]\n+    init = pack_output(init_flat)\n+    dummy_y = [np.zeros_like(init) for init in init_flat]\n+\n+    carry = init\n+    ys = []\n+    maybe_reversed = reversed if reverse else lambda x: x\n+    for i in maybe_reversed(range(n)):\n+        xs_slice = [x[i] for x in xs_flat]\n+        packed_xs = pack_input(xs_slice) if len(xs_slice) > 0 else None\n+        carry, y = f(carry, packed_xs)\n+        ys.append(y if y is not None else dummy_y)\n+    stacked_y = tree.map_structure(\n+        lambda *ys: np.stack(ys), *maybe_reversed(ys)\n+    )\n+    return carry, stacked_y\n+\n+\n def scatter(indices, values, shape):\n     indices = convert_to_tensor(indices)\n     values = convert_to_tensor(values)\n\n@@ -210,6 +210,127 @@ def vectorized_map(function, elements):\n     return tf.vectorized_map(function, elements)\n \n \n+def scan(f, init, xs=None, length=None, reverse=False, unroll=1):\n+    # We have reimplemented `scan` to match the behavior of `jax.lax.scan`\n+    # Ref: tf.scan, jax.lax.scan\n+    if not callable(f):\n+        raise TypeError(f\"`f` should be a callable. Received: f={f}\")\n+    if not isinstance(unroll, bool):\n+        if not isinstance(unroll, int) or unroll < 1:\n+            raise ValueError(\n+                \"`unroll` must be an positive integer or boolean. \"\n+                f\"Received: unroll={unroll}\"\n+            )\n+    if xs is None and length is None:\n+        raise ValueError(\"Got no `xs` to scan over and `length` not provided.\")\n+\n+    input_is_sequence = tree.is_nested(xs)\n+    output_is_sequence = tree.is_nested(init)\n+\n+    def pack_input(x):\n+        return tree.pack_sequence_as(xs, x) if input_is_sequence else x[0]\n+\n+    def pack_output(x):\n+        return tree.pack_sequence_as(init, x) if output_is_sequence else x[0]\n+\n+    if xs is None:\n+        xs_flat = []\n+        n = int(length)\n+    else:\n+        # xs_flat = flatten_input(xs)\n+        xs_flat = tree.flatten(xs)\n+        xs_flat = [tf.convert_to_tensor(elem) for elem in xs_flat]\n+        n = int(length) if length is not None else tf.shape(xs_flat[0])[0]\n+\n+    # TensorArrays are always flat\n+    xs_array = [\n+        tf.TensorArray(\n+            dtype=x.dtype,\n+            size=n,\n+            dynamic_size=False,\n+            element_shape=x.shape[1:],\n+            infer_shape=True,\n+        )\n+        for x in xs_flat\n+    ]\n+    xs_array = [x_a.unstack(x) for x_a, x in zip(xs_array, xs_flat)]\n+\n+    init_flat = tree.flatten(init)\n+    carry_flat = [tf.convert_to_tensor(init) for init in init_flat]\n+\n+    # Store the intermediate values\n+    # Note: there is a constraint that the output of `f` must have the same\n+    # shape and dtype as carry (`init`).\n+    ys_array = [\n+        tf.TensorArray(\n+            dtype=carry.dtype,\n+            size=n,\n+            dynamic_size=False,\n+            element_shape=carry.shape,\n+            infer_shape=True,\n+        )\n+        for carry in carry_flat\n+    ]\n+    carry_array = [\n+        tf.TensorArray(\n+            dtype=carry.dtype,\n+            size=1,\n+            dynamic_size=False,\n+            clear_after_read=False,\n+            element_shape=carry.shape,\n+            infer_shape=True,\n+        )\n+        for carry in carry_flat\n+    ]\n+    carry_array = [\n+        carry.write(0, c) for (carry, c) in zip(carry_array, carry_flat)\n+    ]\n+\n+    def loop_body(i, carry_array, ys_array):\n+        packed_xs = (\n+            pack_input([xs.read(i) for xs in xs_array])\n+            if len(xs_array) > 0\n+            else None\n+        )\n+        packed_carry = pack_output([carry.read(0) for carry in carry_array])\n+\n+        carry, ys = f(packed_carry, packed_xs)\n+\n+        if ys is not None:\n+            flat_ys = tree.flatten(ys)\n+            ys_array = [ys.write(i, v) for (ys, v) in zip(ys_array, flat_ys)]\n+        if carry is not None:\n+            flat_carry = tree.flatten(carry)\n+            carry_array = [\n+                carry.write(0, v) for (carry, v) in zip(carry_array, flat_carry)\n+            ]\n+        next_i = i + 1 if not reverse else i - 1\n+        return (next_i, carry_array, ys_array)\n+\n+    if isinstance(unroll, bool):\n+        unroll = max(n, 1) if unroll else 1\n+\n+    _, carry_array, ys_array = tf.while_loop(\n+        lambda i, _1, _2: i >= 0 if reverse else i < n,\n+        loop_body,\n+        (n - 1 if reverse else 0, carry_array, ys_array),\n+        parallel_iterations=unroll,\n+    )\n+\n+    ys_flat = [ys.stack() for ys in ys_array]\n+    carry_flat = [carry.read(0) for carry in carry_array]\n+    if xs is not None:\n+        n_static = xs_flat[0].get_shape().with_rank_at_least(1)[0]\n+        if not isinstance(n_static, int):\n+            for x in xs_flat[1:]:\n+                n_static.assert_is_compatible_with(\n+                    x.get_shape().with_rank_at_least(1)[0]\n+                )\n+        for r in ys_flat:\n+            r.set_shape(tf.TensorShape(n_static).concatenate(r.get_shape()[1:]))\n+    return pack_output(carry_flat), pack_output(ys_flat)\n+\n+\n def scatter(indices, values, shape):\n     return tf.scatter_nd(indices, values, shape)\n \n\n@@ -340,6 +340,55 @@ def vectorized_map(function, elements):\n     return torch.vmap(function)(elements)\n \n \n+def scan(f, init, xs=None, length=None, reverse=False, unroll=1):\n+    # Ref: jax.lax.scan\n+    if not callable(f):\n+        raise TypeError(f\"`f` should be a callable. Received: f={f}\")\n+    if not isinstance(unroll, bool):\n+        if not isinstance(unroll, int) or unroll < 1:\n+            raise ValueError(\n+                \"`unroll` must be an positive integer or boolean. \"\n+                f\"Received: unroll={unroll}\"\n+            )\n+    if xs is None and length is None:\n+        raise ValueError(\"Got no `xs` to scan over and `length` not provided.\")\n+\n+    input_is_sequence = tree.is_nested(xs)\n+    output_is_sequence = tree.is_nested(init)\n+\n+    def pack_input(x):\n+        return tree.pack_sequence_as(xs, x) if input_is_sequence else x[0]\n+\n+    def pack_output(x):\n+        return tree.pack_sequence_as(init, x) if output_is_sequence else x[0]\n+\n+    if xs is None:\n+        xs_flat = []\n+        n = int(length)\n+    else:\n+        xs_flat = tree.flatten(xs)\n+        xs_flat = [convert_to_tensor(elem) for elem in xs_flat]\n+        n = int(length) if length is not None else shape(xs_flat[0])[0]\n+\n+    init_flat = tree.flatten(init)\n+    init_flat = [convert_to_tensor(init) for init in init_flat]\n+    init = pack_output(init_flat)\n+    dummy_y = [torch.zeros_like(init) for init in init_flat]\n+\n+    carry = init\n+    ys = []\n+    maybe_reversed = reversed if reverse else lambda x: x\n+    for i in maybe_reversed(range(n)):\n+        xs_slice = [x[i] for x in xs_flat]\n+        packed_xs = pack_input(xs_slice) if len(xs_slice) > 0 else None\n+        carry, y = f(carry, packed_xs)\n+        ys.append(y if y is not None else dummy_y)\n+    stacked_y = tree.map_structure(\n+        lambda *ys: torch.stack(ys), *maybe_reversed(ys)\n+    )\n+    return carry, stacked_y\n+\n+\n def scatter(indices, values, shape):\n     indices = convert_to_tensor(indices)\n     values = convert_to_tensor(values)\n\n@@ -1,4 +1,5 @@\n \"\"\"\n+scan\n scatter\n scatter_update\n slice\n@@ -25,6 +26,113 @@ from keras.src.ops.operation import Operation\n from keras.src.utils import traceback_utils\n \n \n+class Scan(Operation):\n+    def __init__(self, reverse=False, unroll=1):\n+        super().__init__()\n+        self.reverse = reverse\n+        self.unroll = unroll\n+\n+    def call(self, f, init, xs, length):\n+        return backend.core.scan(\n+            f, init, xs, length, reverse=self.reverse, unroll=self.unroll\n+        )\n+\n+    def compute_output_spec(self, f, init, xs, length):\n+        if xs is None:\n+            n = int(length)\n+            x = None\n+        else:\n+            n = (\n+                int(length)\n+                if length is not None\n+                else tree.flatten(xs)[0].shape[0]\n+            )\n+            x = xs[0]\n+\n+        carry_spec, y_spec = backend.compute_output_spec(f, init, x)\n+        y_spec.shape = (n,) + y_spec.shape\n+        return carry_spec, y_spec\n+\n+\n+@keras_export(\"keras.ops.scan\")\n+def scan(f, init, xs=None, length=None, reverse=False, unroll=1):\n+    \"\"\"Scan a function over leading array axes while carrying along state.\n+\n+    When the type of `xs` is an array type or `None`, and the type of `ys` is an\n+    array type, the semantics of `scan()` are given roughly by this Python\n+    implementation:\n+\n+    ```python\n+    def scan(f, init, xs, length=None):\n+        if xs is None:\n+            xs = [None] * length\n+        carry = init\n+        ys = []\n+        for x in xs:\n+            carry, y = f(carry, x)\n+            ys.append(y)\n+        return carry, np.stack(ys)\n+    ```\n+\n+    The loop-carried value `carry` (`init`) must hold a fixed shape and dtype\n+    across all iterations.\n+\n+    In TensorFlow, `y` must match `carry` in shape and dtype. This is not\n+    required in other backends.\n+\n+    Args:\n+        f: Callable defines the logic for each loop iteration. This accepts two\n+            arguments where the first is a value of the loop carry and the\n+            second is a slice of `xs` along its leading axis.\n+            This callable returns a pair where the first represents a new value\n+            for the loop carry and the second represents a slice of the output.\n+        init: The initial loop carry value. This can be a scalar, tensor, or any\n+            nested structure. It must match the structure of the first element\n+            returned by `f`.\n+        xs: Optional value to scan along its leading axis. This can be a tensor\n+            or any nested structure. If `xs` is not provided, you must specify\n+            `length` to define the number of loop iterations.\n+            Defaults to `None`.\n+        length: Optional integer specifying the number of loop iterations.\n+            If `length` is not provided, it defaults to the sizes of leading\n+            axis of the arrays in `xs`. Defaults to `None`.\n+        reverse: Optional boolean specifying whether to run the scan iteration\n+            forward or in reverse, equivalent to reversing the leading axes of\n+            the arrays in both `xs` and in `ys`.\n+        unroll: Optional positive integer or boolean specifying how many scan\n+            iterations to unroll within a single iteration of a loop. If an\n+            integer is provided, it determines how many unrolled loop iterations\n+            to run within a single rolled iteration of the loop. If a boolean is\n+            provided, it will determine if the loop is completely unrolled\n+            (`unroll=True`) or left completely unrolled (`unroll=False`).\n+            Note that unrolling is only supported by JAX and TensorFlow\n+            backends.\n+\n+    Returns:\n+        A pair where the first element represents the final loop carry value and\n+        the second element represents the stacked outputs of `f` when scanned\n+        over the leading axis of the inputs.\n+\n+    Examples:\n+\n+    >>> sum_fn = lambda c, x: (c + x, c + x)\n+    >>> init = keras.ops.array(0)\n+    >>> xs = keras.ops.array([1, 2, 3, 4, 5])\n+    >>> carry, result = ops.scan(sum_fn, init, xs)\n+    >>> carry\n+    15\n+    >>> result\n+    [1, 3, 6, 10, 15]\n+    \"\"\"\n+    if any_symbolic_tensors((init, xs)):\n+        return Scan(reverse=reverse, unroll=unroll).symbolic_call(\n+            f, init, xs, length\n+        )\n+    return backend.core.scan(\n+        f, init, xs, length, reverse=reverse, unroll=unroll\n+    )\n+\n+\n class Scatter(Operation):\n     def call(self, indices, values, shape):\n         return backend.core.scatter(indices, values, shape)\n\n@@ -19,6 +19,24 @@ from keras.src.ops import core\n \n \n class CoreOpsStaticShapeTest(testing.TestCase):\n+    def test_scan(self):\n+        def f(carry, xs):\n+            xs = xs + carry\n+            return carry, carry\n+\n+        init = KerasTensor(())\n+        xs = KerasTensor((6,))\n+        carry, result = core.scan(f, init, xs)\n+        self.assertEqual(carry.shape, ())\n+        self.assertEqual(result.shape, (6,))\n+\n+        def f2(carry, _):\n+            return carry, carry\n+\n+        carry, result = core.scan(f2, init, xs=None, length=3)\n+        self.assertEqual(carry.shape, ())\n+        self.assertEqual(result.shape, (3,))\n+\n     def test_scatter(self):\n         indices = KerasTensor((5, 2))\n         values = KerasTensor((5,))\n@@ -85,6 +103,69 @@ class CoreOpsStaticShapeTest(testing.TestCase):\n \n \n class CoreOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n+    def test_scan(self):\n+        # Test cumsum\n+        def cumsum(carry, xs):\n+            carry = carry + xs\n+            return carry, carry\n+\n+        init = np.array(0, dtype=\"float32\")\n+        xs = np.array([1, 2, 3, 4, 10, 20], dtype=\"float32\")\n+        carry, result = core.scan(cumsum, init, xs)\n+        self.assertAllClose(carry, 40.0)\n+        self.assertAllClose(result, ops.cumsum(xs))\n+\n+        # Test reverse=True\n+        carry, result = core.scan(cumsum, init, xs, reverse=True)\n+        self.assertAllClose(carry, 40.0)\n+        self.assertAllClose(result, [40, 39, 37, 34, 30, 20])\n+\n+        # Test unroll\n+        for unroll in (True, False, 2):\n+            carry, result = core.scan(cumsum, init, xs, unroll=unroll)\n+            self.assertAllClose(carry, 40.0)\n+            self.assertAllClose(result, ops.cumsum(xs))\n+\n+        # Test xs is None\n+        def fibonaccis(carry, _):\n+            return (carry[1], carry[0] + carry[1]), None\n+\n+        init = (np.array(0, dtype=\"float32\"), np.array(1, dtype=\"float32\"))\n+        carry, _ = core.scan(fibonaccis, init, length=6)\n+        self.assertAllClose(carry, [8, 13])\n+\n+        # Test nested init\n+        if backend.backend() != \"tensorflow\":\n+            # tensorflow doesn't support arbitrary shape/dtype of the output of\n+            # `f`. It must be the same as `init`.\n+            def multiply_two(carry, _):\n+                value1 = carry[\"value1\"]\n+                value2 = carry[\"value2\"]\n+                return (\n+                    {\"value1\": value1 * 2, \"value2\": value2 * 2},\n+                    value1 * 2 + value2 * 2,\n+                )\n+\n+            init = {\"value1\": 2.0, \"value2\": 3.0}\n+            carry, result = core.scan(multiply_two, init, length=3)\n+            self.assertAllClose(carry[\"value1\"], 16)\n+            self.assertAllClose(carry[\"value2\"], 24)\n+            self.assertAllClose(result, [10, 20, 40])\n+\n+        # Test nested xs\n+        def reduce_add(carry, xs):\n+            value1 = xs[\"value1\"]\n+            value2 = xs[\"value2\"]\n+            return carry, value1 + value2\n+\n+        init = np.array(0, dtype=\"float32\")\n+        xs = {\n+            \"value1\": np.array([1, 2, 3], dtype=\"float32\"),\n+            \"value2\": np.array([10, 20, 30], dtype=\"float32\"),\n+        }\n+        _, result = core.scan(reduce_add, init, xs)\n+        self.assertAllClose(result, [11, 22, 33])\n+\n     def test_scatter(self):\n         # Test 1D\n         indices = np.array([[1], [3], [4], [7]])\n@@ -633,15 +714,20 @@ class CoreOpsDtypeTest(testing.TestCase, parameterized.TestCase):\n                 expected_dtype,\n             )\n \n-    def test_convert_to_numpy(self):\n-        x = ops.array([1, 2, 3], dtype=\"float32\")\n-        y = ops.convert_to_numpy(x)\n-        self.assertIsInstance(y, np.ndarray)\n-        # Test assignment -- should not fail.\n-        y[0] = 1.0\n-\n \n class CoreOpsCallsTests(testing.TestCase):\n+    def test_scan_basic_call(self):\n+        def cumsum(carry, xs):\n+            carry = carry + xs\n+            return carry, carry\n+\n+        init = np.array(0, dtype=\"float32\")\n+        xs = np.array([1, 2, 3, 4, 10, 20], dtype=\"float32\")\n+        scan_op = core.Scan()\n+        carry, result = scan_op.call(cumsum, init, xs, None)\n+        self.assertAllClose(carry, 40.0)\n+        self.assertAllClose(result, ops.cumsum(xs))\n+\n     def test_scatter_basic_call(self):\n         indices = np.array([[1, 0], [0, 1]])\n         values = np.array([10, 20])\n@@ -884,3 +970,34 @@ class CoreOpsCallsTests(testing.TestCase):\n                 (mock_spec,), (mock_spec, mock_spec_different)\n             )\n         )\n+\n+\n+class CoreOpsBehaviorTests(testing.TestCase):\n+    def test_convert_to_numpy(self):\n+        x = ops.array([1, 2, 3], dtype=\"float32\")\n+        y = ops.convert_to_numpy(x)\n+        self.assertIsInstance(y, np.ndarray)\n+        # Test assignment -- should not fail.\n+        y[0] = 1.0\n+\n+    def test_scan_invalid_arguments(self):\n+        def cumsum(carry, xs):\n+            carry = carry + xs\n+            return carry, carry\n+\n+        init = np.array(0, dtype=\"float32\")\n+        xs = np.array([1, 2, 3, 4, 10, 20], dtype=\"float32\")\n+\n+        # Test non-callable\n+        with self.assertRaisesRegex(TypeError, \"should be a callable.\"):\n+            core.scan(123, init, xs)\n+\n+        # Test bad unroll\n+        with self.assertRaisesRegex(\n+            ValueError, \"must be an positive integer or boolean.\"\n+        ):\n+            core.scan(cumsum, init, xs, unroll=-1)\n+\n+        # Test both xs and length are None\n+        with self.assertRaisesRegex(ValueError, \"to scan over and\"):\n+            core.scan(cumsum, init, xs=None, length=None)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
