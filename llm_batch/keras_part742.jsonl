{"custom_id": "keras#fb9c5e859d5bdb1300927c3fccc253c512a097b5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 10 | Files Changed: 2 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 20 | Churn Cumulative: 188 | Contributors (this commit): 2 | Commits (past 90d): 6 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -939,7 +939,7 @@ class Erf(Operation):\n         return backend.math.erf(x)\n \n \n-@keras_core_export(\"keras_core.ops.erf\")\n+@keras_export(\"keras_core.ops.erf\")\n def erf(x):\n     \"\"\"Computes the error function of x element-wise.\n \n\n@@ -841,9 +841,9 @@ class MathOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         sample_values = np.array([-3.0, -2.0, -1.0, 0.0, 1.0, 2.0, 3.0])\n \n         # Expected output using numpy's approximation of the error function\n-        expected_output = (2 / np.sqrt(np.pi)) * np.vectorize(math.erf)(\n-            sample_values\n-        )\n+        expected_output = (2 / np.sqrt(np.pi)) * np.vectorize(\n+            scipy.special.erf\n+        )(sample_values)\n \n         # Output from the erf operation in keras_core\n         output_from_erf_op = kmath.erf(sample_values)\n@@ -857,18 +857,18 @@ class MathOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             sample_values = np.array(\n                 [-3.0, -2.0, -1.0, 0.0, 1.0, 2.0, 3.0], dtype=dtype\n             )\n-            expected_output = (2 / np.sqrt(np.pi)) * np.vectorize(math.erf)(\n-                sample_values\n-            )\n+            expected_output = (2 / np.sqrt(np.pi)) * np.vectorize(\n+                scipy.special.erf\n+            )(sample_values)\n             output_from_erf_op = kmath.erf(sample_values)\n             self.assertAllClose(expected_output, output_from_erf_op, atol=1e-4)\n \n     def test_erf_operation_edge_cases(self):\n         # Test for edge cases\n         edge_values = np.array([1e5, -1e5, 1e-5, -1e-5], dtype=np.float64)\n-        expected_edge_output = (2 / np.sqrt(np.pi)) * np.vectorize(math.erf)(\n-            edge_values\n-        )\n+        expected_edge_output = (2 / np.sqrt(np.pi)) * np.vectorize(\n+            scipy.special.erf\n+        )(edge_values)\n         output_from_edge_erf_op = kmath.erf(edge_values)\n         self.assertAllClose(\n             expected_edge_output, output_from_edge_erf_op, atol=1e-4\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7fe6672f0111f09db7c7250ce0da1ea640d4a46b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 126 | Contributors (this commit): 3 | Commits (past 90d): 4 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -939,7 +939,7 @@ class Erf(Operation):\n         return backend.math.erf(x)\n \n \n-@keras_export(\"keras_core.ops.erf\")\n+@keras_export(\"keras.ops.erf\")\n def erf(x):\n     \"\"\"Computes the error function of x element-wise.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#893f8e6a4c6e0554bea2a9d046abd9dc7e9db5cc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 29 | Lines Deleted: 44 | Files Changed: 2 | Hunks: 12 | Methods Changed: 5 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 73 | Churn Cumulative: 263 | Contributors (this commit): 3 | Commits (past 90d): 9 | Contributors (cumulative): 5 | DMM Complexity: 0.0\n\nDIFF:\n@@ -900,21 +900,6 @@ def istft(\n \n \n class Rsqrt(Operation):\n-    \"\"\"Computes reciprocal of square root of x element-wise.\n-\n-    Args:\n-        x: input tensor\n-\n-    Returns:\n-        A tensor with the same type as `x`.\n-\n-    Example:\n-\n-    >>> data = keras.ops.convert_to_tensor([1.0, 10.0, 100.0])\n-    >>> keras.ops.rsqrt(data)\n-    array([1.0, 0.31622776, 0.1], dtype=float32)\n-    \"\"\"\n-\n     def call(self, x):\n         x = backend.convert_to_tensor(x)\n         return backend.math.rsqrt(x)\n@@ -925,6 +910,20 @@ class Rsqrt(Operation):\n \n @keras_export(\"keras.ops.rsqrt\")\n def rsqrt(x):\n+    \"\"\"Computes reciprocal of square root of x element-wise.\n+\n+    Args:\n+        x: input tensor\n+\n+    Returns:\n+        A tensor with the same dtype as `x`.\n+\n+    Example:\n+\n+    >>> x = keras.ops.convert_to_tensor([1.0, 10.0, 100.0])\n+    >>> keras.ops.rsqrt(x)\n+    array([1.0, 0.31622776, 0.1], dtype=float32)\n+    \"\"\"\n     if any_symbolic_tensors((x,)):\n         return Rsqrt().symbolic_call(x)\n     x = backend.convert_to_tensor(x)\n@@ -941,27 +940,21 @@ class Erf(Operation):\n \n @keras_export(\"keras.ops.erf\")\n def erf(x):\n-    \"\"\"Computes the error function of x element-wise.\n+    \"\"\"Computes the error function of `x`, element-wise.\n \n     Args:\n-        x: input tensor\n+        x: Input tensor.\n \n     Returns:\n-        A tensor with the same type as `x`.\n+        A tensor with the same dtype as `x`.\n \n-    Examples:\n+    Example:\n \n-    Basic usage\n-    >>> x = np.array([-3.0, -2.0, -1.0, 0.0, 1.0, 2.0, 3.0])\n-    >>> y = Erf()(x)\n-\n-    Using `float32` data type\n-    >>> x_float32 = np.array([-3.0, -2.0], dtype=np.float32)\n-    >>> y_float32 = Erf()(x_float32)\n-\n-    Using large values\n-    >>> x_large = np.array([1e10, -1e10])\n-    >>> y_large = Erf()(x_large)\n+    >>> x = np.array([-3.0, -2.0, -1.0, 0.0, 1.0])\n+    >>> keras.ops.erf(x)\n+    array([-0.99998 , -0.99532, -0.842701,  0.,  0.842701], dtype=float32)\n     \"\"\"\n-\n-    return Erf()(x)\n+    if any_symbolic_tensors((x,)):\n+        return Erf().symbolic_call(x)\n+    x = backend.convert_to_tensor(x)\n+    return backend.math.erf(x)\n\n@@ -841,9 +841,7 @@ class MathOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         sample_values = np.array([-3.0, -2.0, -1.0, 0.0, 1.0, 2.0, 3.0])\n \n         # Expected output using numpy's approximation of the error function\n-        expected_output = (2 / np.sqrt(np.pi)) * np.vectorize(\n-            scipy.special.erf\n-        )(sample_values)\n+        expected_output = scipy.special.erf(sample_values)\n \n         # Output from the erf operation in keras_core\n         output_from_erf_op = kmath.erf(sample_values)\n@@ -857,19 +855,13 @@ class MathOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             sample_values = np.array(\n                 [-3.0, -2.0, -1.0, 0.0, 1.0, 2.0, 3.0], dtype=dtype\n             )\n-            expected_output = (2 / np.sqrt(np.pi)) * np.vectorize(\n-                scipy.special.erf\n-            )(sample_values)\n+            expected_output = scipy.special.erf(sample_values)\n             output_from_erf_op = kmath.erf(sample_values)\n             self.assertAllClose(expected_output, output_from_erf_op, atol=1e-4)\n \n     def test_erf_operation_edge_cases(self):\n         # Test for edge cases\n         edge_values = np.array([1e5, -1e5, 1e-5, -1e-5], dtype=np.float64)\n-        expected_edge_output = (2 / np.sqrt(np.pi)) * np.vectorize(\n-            scipy.special.erf\n-        )(edge_values)\n+        expected_output = scipy.special.erf(edge_values)\n         output_from_edge_erf_op = kmath.erf(edge_values)\n-        self.assertAllClose(\n-            expected_edge_output, output_from_edge_erf_op, atol=1e-4\n-        )\n+        self.assertAllClose(expected_output, output_from_edge_erf_op, atol=1e-4)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2de5d4d3a5fb848f28e20b956a32dd300784f209", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 343 | Lines Deleted: 4 | Files Changed: 3 | Hunks: 6 | Methods Changed: 43 | Complexity Δ (Sum/Max): 39/21 | Churn Δ: 347 | Churn Cumulative: 491 | Contributors (this commit): 2 | Commits (past 90d): 7 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -208,12 +208,12 @@ class KerasTensor:\n     def __floordiv__(self, other):\n         from keras import ops\n \n-        return ops.FloorDiv().symbolic_call(self, other)\n+        return ops.FloorDivide().symbolic_call(self, other)\n \n     def __rfloordiv__(self, other):\n         from keras import ops\n \n-        return ops.FloorDiv().symbolic_call(other, self)\n+        return ops.FloorDivide().symbolic_call(other, self)\n \n     def __mod__(self, other):\n         from keras import ops\n@@ -270,10 +270,10 @@ class KerasTensor:\n \n         return ops.LogicalOr().symbolic_call(other, self)\n \n-    def __invert__(self, other):\n+    def __invert__(self):\n         from keras import ops\n \n-        return ops.LogicalNot().symbolic_call(other, self)\n+        return ops.LogicalNot().symbolic_call(self)\n \n     def __xor__(self, other):\n         from keras import ops\n\n@@ -153,3 +153,235 @@ class KerasTensorTest(testing.TestCase):\n         result = operator(x, other)\n         mock_method.assert_called_once_with(x, other)\n         self.assertEqual(result, mock_tensor)\n+\n+    @patch(\"keras.ops.Add.symbolic_call\")\n+    def test_radd_method(self, mock_symbolic_call):\n+        \"\"\"Test __radd__ method\"\"\"\n+        mock_tensor = Mock()\n+        mock_symbolic_call.return_value = mock_tensor\n+        x = keras_tensor.KerasTensor(shape=(3, 4), dtype=\"float32\")\n+        y = Mock()\n+        result = y + x\n+        mock_symbolic_call.assert_called_once_with(y, x)\n+        self.assertEqual(result, mock_tensor)\n+\n+    @patch(\"keras.ops.Subtract.symbolic_call\")\n+    def test_rsub_method(self, mock_symbolic_call):\n+        \"\"\"Test __rsub__ method\"\"\"\n+        mock_tensor = Mock()\n+        mock_symbolic_call.return_value = mock_tensor\n+        x = keras_tensor.KerasTensor(shape=(3, 4), dtype=\"float32\")\n+        y = Mock()\n+        result = y - x\n+        mock_symbolic_call.assert_called_once_with(y, x)\n+        self.assertEqual(result, mock_tensor)\n+\n+    @patch(\"keras.ops.Multiply.symbolic_call\")\n+    def test_rmul_method(self, mock_symbolic_call):\n+        \"\"\"Test __rmul__ method\"\"\"\n+        mock_tensor = Mock()\n+        mock_symbolic_call.return_value = mock_tensor\n+        x = keras_tensor.KerasTensor(shape=(3, 4), dtype=\"float32\")\n+        y = Mock()\n+        result = y * x\n+        mock_symbolic_call.assert_called_once_with(y, x)\n+        self.assertEqual(result, mock_tensor)\n+\n+    @patch(\"keras.ops.Matmul.symbolic_call\")\n+    def test_rmatmul_method(self, mock_symbolic_call):\n+        \"\"\"Test __rmatmul__ method\"\"\"\n+        mock_tensor = Mock()\n+        mock_symbolic_call.return_value = mock_tensor\n+        x = keras_tensor.KerasTensor(shape=(3, 4), dtype=\"float32\")\n+        y = Mock()\n+        result = y @ x\n+        mock_symbolic_call.assert_called_once_with(y, x)\n+        self.assertEqual(result, mock_tensor)\n+\n+    @patch(\"keras.ops.Power.symbolic_call\")\n+    def test_rpow_method(self, mock_symbolic_call):\n+        \"\"\"Test __rpow__ method\"\"\"\n+        mock_tensor = Mock()\n+        mock_symbolic_call.return_value = mock_tensor\n+        x = keras_tensor.KerasTensor(shape=(3, 4), dtype=\"float32\")\n+        y = Mock()\n+        result = y**x\n+        mock_symbolic_call.assert_called_once_with(y, x)\n+        self.assertEqual(result, mock_tensor)\n+\n+    @patch(\"keras.ops.FloorDivide.symbolic_call\")\n+    def test_floordiv_method(self, mock_symbolic_call):\n+        \"\"\"Test __floordiv__ method\"\"\"\n+        mock_tensor = Mock()\n+        mock_symbolic_call.return_value = mock_tensor\n+        x = keras_tensor.KerasTensor(shape=(3, 4), dtype=\"float32\")\n+        y = Mock()\n+        result = x // y\n+        mock_symbolic_call.assert_called_once_with(x, y)\n+        self.assertEqual(result, mock_tensor)\n+\n+    @patch(\"keras.ops.FloorDivide.symbolic_call\")\n+    def test_rfloordiv_method(self, mock_symbolic_call):\n+        \"\"\"Test __rfloordiv__ method\"\"\"\n+        mock_tensor = Mock()\n+        mock_symbolic_call.return_value = mock_tensor\n+        x = keras_tensor.KerasTensor(shape=(3, 4), dtype=\"float32\")\n+        y = Mock()\n+        result = y // x\n+        mock_symbolic_call.assert_called_once_with(y, x)\n+        self.assertEqual(result, mock_tensor)\n+\n+    @patch(\"keras.ops.Mod.symbolic_call\")\n+    def test_rmod_method(self, mock_symbolic_call):\n+        \"\"\"Test __rmod__ method\"\"\"\n+        mock_tensor = Mock()\n+        mock_symbolic_call.return_value = mock_tensor\n+        x = keras_tensor.KerasTensor(shape=(3, 4), dtype=\"float32\")\n+        y = Mock()\n+        result = y % x\n+        mock_symbolic_call.assert_called_once_with(y, x)\n+        self.assertEqual(result, mock_tensor)\n+\n+    @patch(\"keras.ops.LessEqual.symbolic_call\")\n+    def test_le_method(self, mock_symbolic_call):\n+        \"\"\"Test __le__ method\"\"\"\n+        mock_tensor = Mock()\n+        mock_symbolic_call.return_value = mock_tensor\n+        x = keras_tensor.KerasTensor(shape=(3, 4), dtype=\"float32\")\n+        y = Mock()\n+        result = x <= y\n+        mock_symbolic_call.assert_called_once_with(x, y)\n+        self.assertEqual(result, mock_tensor)\n+\n+    @patch(\"keras.ops.Greater.symbolic_call\")\n+    def test_gt_method(self, mock_symbolic_call):\n+        \"\"\"Test __gt__ method\"\"\"\n+        mock_tensor = Mock()\n+        mock_symbolic_call.return_value = mock_tensor\n+        x = keras_tensor.KerasTensor(shape=(3, 4), dtype=\"float32\")\n+        y = Mock()\n+        result = x > y\n+        mock_symbolic_call.assert_called_once_with(x, y)\n+        self.assertEqual(result, mock_tensor)\n+\n+    @patch(\"keras.ops.GreaterEqual.symbolic_call\")\n+    def test_ge_method(self, mock_symbolic_call):\n+        \"\"\"Test __ge__ method\"\"\"\n+        mock_tensor = Mock()\n+        mock_symbolic_call.return_value = mock_tensor\n+        x = keras_tensor.KerasTensor(shape=(3, 4), dtype=\"float32\")\n+        y = Mock()\n+        result = x >= y\n+        mock_symbolic_call.assert_called_once_with(x, y)\n+        self.assertEqual(result, mock_tensor)\n+\n+    @patch(\"keras.ops.NotEqual.symbolic_call\")\n+    def test_ne_method(self, mock_symbolic_call):\n+        \"\"\"Test __ne__ method\"\"\"\n+        mock_tensor = Mock()\n+        mock_symbolic_call.return_value = mock_tensor\n+        x = keras_tensor.KerasTensor(shape=(3, 4), dtype=\"float32\")\n+        y = Mock()\n+        result = x != y\n+        mock_symbolic_call.assert_called_once_with(x, y)\n+        self.assertEqual(result, mock_tensor)\n+\n+    @patch(\"keras.ops.LogicalAnd.symbolic_call\")\n+    def test_rand_method(self, mock_symbolic_call):\n+        \"\"\"Test __rand__ method\"\"\"\n+        mock_tensor = Mock()\n+        mock_symbolic_call.return_value = mock_tensor\n+        x = keras_tensor.KerasTensor(shape=(3, 4), dtype=\"bool\")\n+        y = Mock()\n+        result = y & x\n+        mock_symbolic_call.assert_called_once_with(y, x)\n+        self.assertEqual(result, mock_tensor)\n+\n+    @patch(\"keras.ops.LogicalOr.symbolic_call\")\n+    def test_ror_method(self, mock_symbolic_call):\n+        \"\"\"Test __ror__ method\"\"\"\n+        mock_tensor = Mock()\n+        mock_symbolic_call.return_value = mock_tensor\n+        x = keras_tensor.KerasTensor(shape=(3, 4), dtype=\"bool\")\n+        y = Mock()\n+        result = y | x\n+        mock_symbolic_call.assert_called_once_with(y, x)\n+        self.assertEqual(result, mock_tensor)\n+\n+    @patch(\"keras.ops.LogicalNot.symbolic_call\")\n+    def test_invert_method(self, mock_symbolic_call):\n+        \"\"\"Test __invert__ method\"\"\"\n+        mock_tensor = Mock()\n+        mock_symbolic_call.return_value = mock_tensor\n+        x = keras_tensor.KerasTensor(shape=(3, 4), dtype=\"bool\")\n+        result = ~x\n+        mock_symbolic_call.assert_called_once_with(x)\n+        self.assertEqual(result, mock_tensor)\n+\n+    @patch(\"keras.ops.LogicalXor.symbolic_call\")\n+    def test_xor_method(self, mock_symbolic_call):\n+        \"\"\"Test __xor__ method\"\"\"\n+        mock_tensor = Mock()\n+        mock_symbolic_call.return_value = mock_tensor\n+        x = keras_tensor.KerasTensor(shape=(3, 4), dtype=\"bool\")\n+        y = Mock()\n+        result = x ^ y\n+        mock_symbolic_call.assert_called_once_with(x, y)\n+        self.assertEqual(result, mock_tensor)\n+\n+    @patch(\"keras.ops.LogicalXor.symbolic_call\")\n+    def test_rxor_method(self, mock_symbolic_call):\n+        \"\"\"Test __rxor__ method\"\"\"\n+        mock_tensor = Mock()\n+        mock_symbolic_call.return_value = mock_tensor\n+        x = keras_tensor.KerasTensor(shape=(3, 4), dtype=\"bool\")\n+        y = Mock()\n+        result = y ^ x\n+        mock_symbolic_call.assert_called_once_with(y, x)\n+        self.assertEqual(result, mock_tensor)\n+\n+    @patch(\"keras.ops.TrueDivide.symbolic_call\")\n+    def test_truediv_method(self, mock_symbolic_call):\n+        \"\"\"Test __truediv__ method\"\"\"\n+        mock_tensor = Mock()\n+        mock_symbolic_call.return_value = mock_tensor\n+        x = keras_tensor.KerasTensor(shape=(3, 4), dtype=\"float32\")\n+        y = Mock()\n+        result = x / y\n+        mock_symbolic_call.assert_called_once_with(x, y)\n+        self.assertEqual(result, mock_tensor)\n+\n+    @patch(\"keras.ops.TrueDivide.symbolic_call\")\n+    def test_rtruediv_method(self, mock_symbolic_call):\n+        \"\"\"Test __rtruediv__ method\"\"\"\n+        mock_tensor = Mock()\n+        mock_symbolic_call.return_value = mock_tensor\n+        x = keras_tensor.KerasTensor(shape=(3, 4), dtype=\"float32\")\n+        y = Mock()\n+        result = y / x\n+        mock_symbolic_call.assert_called_once_with(y, x)\n+        self.assertEqual(result, mock_tensor)\n+\n+    @patch(\"keras.ops.Divide.symbolic_call\")\n+    def test_div_method(self, mock_symbolic_call):\n+        \"\"\"Test __div__ method\"\"\"\n+        mock_tensor = Mock()\n+        mock_symbolic_call.return_value = mock_tensor\n+        x = keras_tensor.KerasTensor(shape=(3, 4), dtype=\"float32\")\n+        y = keras_tensor.KerasTensor(shape=(3, 4), dtype=\"float32\")\n+        # to ensure compatibility across Python versions.\n+        result = x.__div__(y)\n+        mock_symbolic_call.assert_called_once_with(x, y)\n+        self.assertEqual(result, mock_tensor)\n+\n+    @patch(\"keras.ops.Divide.symbolic_call\")\n+    def test_rdiv_method(self, mock_symbolic_call):\n+        \"\"\"Test __rdiv__ method\"\"\"\n+        mock_tensor = Mock()\n+        mock_symbolic_call.return_value = mock_tensor\n+        x = keras_tensor.KerasTensor(shape=(3, 4), dtype=\"float32\")\n+        y = keras_tensor.KerasTensor(shape=(3, 4), dtype=\"float32\")\n+        # to ensure compatibility across Python versions.\n+        result = x.__rdiv__(y)\n+        mock_symbolic_call.assert_called_once_with(y, x)\n+        self.assertEqual(result, mock_tensor)\n\n@@ -125,3 +125,110 @@ class VariablesTest(test_case.TestCase):\n             \"`AutocastScope` can only be used with a floating-point\",\n         ):\n             _ = AutocastScope(\"int32\")\n+\n+    def test_variable_initialization_with_non_callable(self):\n+        v = backend.Variable(initializer=np.ones((2, 2)))\n+        self.assertAllClose(v.value, np.ones((2, 2)))\n+\n+    def test_variable_path_creation(self):\n+        v = backend.Variable(initializer=np.ones((2, 2)), name=\"test_var\")\n+        self.assertEqual(v.path, \"test_var\")\n+\n+    def test_variable_initialization_with_non_trainable(self):\n+        v = backend.Variable(initializer=np.ones((2, 2)), trainable=False)\n+        self.assertFalse(v.trainable)\n+\n+    def test_variable_initialization_with_dtype(self):\n+        v = backend.Variable(initializer=np.ones((2, 2)), dtype=\"int32\")\n+        self.assertEqual(v.dtype, \"int32\")\n+        self.assertEqual(backend.standardize_dtype(v.value.dtype), \"int32\")\n+\n+    def test_variable_initialization_without_shape(self):\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"When creating a Variable from an initializer, the `shape` \",\n+        ):\n+            backend.Variable(initializer=initializers.RandomNormal())\n+\n+    def test_deferred_initialize_already_initialized(self):\n+        v = backend.Variable(initializer=np.ones((2, 2)))\n+        with self.assertRaisesRegex(\n+            ValueError, f\"Variable {v.path} is already initialized.\"\n+        ):\n+            v._deferred_initialize()\n+\n+    def test_deferred_initialize_within_stateless_scope(self):\n+        with backend.StatelessScope():\n+            v = backend.Variable(\n+                initializer=initializers.RandomNormal(), shape=(2, 2)\n+            )\n+            with self.assertRaisesRegex(\n+                ValueError,\n+                \"You are attempting to initialize a variable \"\n+                \"while in a stateless scope. This is disallowed.\",\n+            ):\n+                v._deferred_initialize()\n+\n+    def test_variable_as_boolean(self):\n+        v = backend.Variable(initializer=np.ones((2, 2)))\n+        with self.assertRaises(TypeError):\n+            bool(v)\n+\n+    def test_variable_negation(self):\n+        v = backend.Variable(initializer=np.array([-1, 2]))\n+        neg_v = -v\n+        self.assertAllClose(neg_v, np.array([1, -2]))\n+\n+    def test_variable_pos(self):\n+        v = backend.Variable(initializer=np.array([-1, 2]))\n+        pos_v = v\n+        self.assertAllClose(pos_v, np.array([-1, 2]))\n+\n+    def test_variable_abs(self):\n+        v = backend.Variable(initializer=np.array([-1, 2]))\n+        abs_v = abs(v)\n+        self.assertAllClose(abs_v, np.array([1, 2]))\n+\n+    def test_variable_invert(self):\n+        v = backend.Variable(initializer=np.array([0, -1]), dtype=\"int32\")\n+        inv_v = ~v\n+        self.assertAllClose(inv_v, np.array([-1, 0]))\n+\n+    def test_variable_lt_numpy_array(self):\n+        v = backend.Variable(initializer=np.array([1, 2, 3]))\n+        arr = np.array([2, 2, 2])\n+\n+        lt_result = v < arr\n+        self.assertAllClose(lt_result.numpy(), np.array([True, False, False]))\n+\n+    def test_variable_div_numpy_array(self):\n+        v = backend.Variable(initializer=np.array([2, 4, 8]))\n+        arr = np.array([2, 8, 16])\n+\n+        div_result = arr / v\n+        self.assertAllClose(div_result, np.array([1, 2, 2]))\n+\n+    def test_variable_rdiv_numpy_array(self):\n+        v = backend.Variable(initializer=np.array([2, 4, 8]))\n+        arr = np.array([16, 32, 64])\n+\n+        rdiv_result = arr / v\n+        self.assertAllClose(rdiv_result, np.array([8, 8, 8]))\n+\n+    def test_variable_rsub_numpy_array(self):\n+        v = backend.Variable(initializer=np.array([1, 2, 3]))\n+        arr = np.array([2, 2, 2])\n+\n+        rsub_result = arr - v\n+        self.assertAllClose(rsub_result, np.array([1, 0, -1]))\n+\n+    def test_variable_rfloordiv(self):\n+        v = backend.Variable(initializer=np.array([3, 4, 6]))\n+        result = np.array([9, 12, 18]) // v\n+        self.assertAllClose(result, np.array([3, 3, 3]))\n+\n+    def test_variable_rmatmul(self):\n+        v = backend.Variable(initializer=np.array([[2, 3], [4, 5]]))\n+        other = np.array([[1, 2], [3, 4]])\n+        rmatmul_result = other @ v\n+        self.assertAllClose(rmatmul_result, np.array([[10, 13], [22, 29]]))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4619d6f303d34cea56340081fdc0f7fbb601ecbd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 7 | Churn Cumulative: 128 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -194,13 +194,6 @@ class VariablesTest(test_case.TestCase):\n         inv_v = ~v\n         self.assertAllClose(inv_v, np.array([-1, 0]))\n \n-    def test_variable_lt_numpy_array(self):\n-        v = backend.Variable(initializer=np.array([1, 2, 3]))\n-        arr = np.array([2, 2, 2])\n-\n-        lt_result = v < arr\n-        self.assertAllClose(lt_result.numpy(), np.array([True, False, False]))\n-\n     def test_variable_div_numpy_array(self):\n         v = backend.Variable(initializer=np.array([2, 4, 8]))\n         arr = np.array([2, 8, 16])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#775ca7969ee2a4b5ca300755344025b07919cef6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 10 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 10 | Churn Cumulative: 138 | Contributors (this commit): 2 | Commits (past 90d): 4 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -138,11 +138,6 @@ class VariablesTest(test_case.TestCase):\n         v = backend.Variable(initializer=np.ones((2, 2)), trainable=False)\n         self.assertFalse(v.trainable)\n \n-    def test_variable_initialization_with_dtype(self):\n-        v = backend.Variable(initializer=np.ones((2, 2)), dtype=\"int32\")\n-        self.assertEqual(v.dtype, \"int32\")\n-        self.assertEqual(backend.standardize_dtype(v.value.dtype), \"int32\")\n-\n     def test_variable_initialization_without_shape(self):\n         with self.assertRaisesRegex(\n             ValueError,\n@@ -189,11 +184,6 @@ class VariablesTest(test_case.TestCase):\n         abs_v = abs(v)\n         self.assertAllClose(abs_v, np.array([1, 2]))\n \n-    def test_variable_invert(self):\n-        v = backend.Variable(initializer=np.array([0, -1]), dtype=\"int32\")\n-        inv_v = ~v\n-        self.assertAllClose(inv_v, np.array([-1, 0]))\n-\n     def test_variable_div_numpy_array(self):\n         v = backend.Variable(initializer=np.array([2, 4, 8]))\n         arr = np.array([2, 8, 16])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#266c19d00cd255646a6200957a95694c209c2808", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 90 | Files Changed: 1 | Hunks: 1 | Methods Changed: 15 | Complexity Δ (Sum/Max): -15/0 | Churn Δ: 90 | Churn Cumulative: 228 | Contributors (this commit): 2 | Commits (past 90d): 5 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -125,93 +125,3 @@ class VariablesTest(test_case.TestCase):\n             \"`AutocastScope` can only be used with a floating-point\",\n         ):\n             _ = AutocastScope(\"int32\")\n-\n-    def test_variable_initialization_with_non_callable(self):\n-        v = backend.Variable(initializer=np.ones((2, 2)))\n-        self.assertAllClose(v.value, np.ones((2, 2)))\n-\n-    def test_variable_path_creation(self):\n-        v = backend.Variable(initializer=np.ones((2, 2)), name=\"test_var\")\n-        self.assertEqual(v.path, \"test_var\")\n-\n-    def test_variable_initialization_with_non_trainable(self):\n-        v = backend.Variable(initializer=np.ones((2, 2)), trainable=False)\n-        self.assertFalse(v.trainable)\n-\n-    def test_variable_initialization_without_shape(self):\n-        with self.assertRaisesRegex(\n-            ValueError,\n-            \"When creating a Variable from an initializer, the `shape` \",\n-        ):\n-            backend.Variable(initializer=initializers.RandomNormal())\n-\n-    def test_deferred_initialize_already_initialized(self):\n-        v = backend.Variable(initializer=np.ones((2, 2)))\n-        with self.assertRaisesRegex(\n-            ValueError, f\"Variable {v.path} is already initialized.\"\n-        ):\n-            v._deferred_initialize()\n-\n-    def test_deferred_initialize_within_stateless_scope(self):\n-        with backend.StatelessScope():\n-            v = backend.Variable(\n-                initializer=initializers.RandomNormal(), shape=(2, 2)\n-            )\n-            with self.assertRaisesRegex(\n-                ValueError,\n-                \"You are attempting to initialize a variable \"\n-                \"while in a stateless scope. This is disallowed.\",\n-            ):\n-                v._deferred_initialize()\n-\n-    def test_variable_as_boolean(self):\n-        v = backend.Variable(initializer=np.ones((2, 2)))\n-        with self.assertRaises(TypeError):\n-            bool(v)\n-\n-    def test_variable_negation(self):\n-        v = backend.Variable(initializer=np.array([-1, 2]))\n-        neg_v = -v\n-        self.assertAllClose(neg_v, np.array([1, -2]))\n-\n-    def test_variable_pos(self):\n-        v = backend.Variable(initializer=np.array([-1, 2]))\n-        pos_v = v\n-        self.assertAllClose(pos_v, np.array([-1, 2]))\n-\n-    def test_variable_abs(self):\n-        v = backend.Variable(initializer=np.array([-1, 2]))\n-        abs_v = abs(v)\n-        self.assertAllClose(abs_v, np.array([1, 2]))\n-\n-    def test_variable_div_numpy_array(self):\n-        v = backend.Variable(initializer=np.array([2, 4, 8]))\n-        arr = np.array([2, 8, 16])\n-\n-        div_result = arr / v\n-        self.assertAllClose(div_result, np.array([1, 2, 2]))\n-\n-    def test_variable_rdiv_numpy_array(self):\n-        v = backend.Variable(initializer=np.array([2, 4, 8]))\n-        arr = np.array([16, 32, 64])\n-\n-        rdiv_result = arr / v\n-        self.assertAllClose(rdiv_result, np.array([8, 8, 8]))\n-\n-    def test_variable_rsub_numpy_array(self):\n-        v = backend.Variable(initializer=np.array([1, 2, 3]))\n-        arr = np.array([2, 2, 2])\n-\n-        rsub_result = arr - v\n-        self.assertAllClose(rsub_result, np.array([1, 0, -1]))\n-\n-    def test_variable_rfloordiv(self):\n-        v = backend.Variable(initializer=np.array([3, 4, 6]))\n-        result = np.array([9, 12, 18]) // v\n-        self.assertAllClose(result, np.array([3, 3, 3]))\n-\n-    def test_variable_rmatmul(self):\n-        v = backend.Variable(initializer=np.array([[2, 3], [4, 5]]))\n-        other = np.array([[1, 2], [3, 4]])\n-        rmatmul_result = other @ v\n-        self.assertAllClose(rmatmul_result, np.array([[10, 13], [22, 29]]))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#063e80e176e1676a5bfc5184db2d65af7624982c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 264 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -381,7 +381,7 @@ class KerasTensorTest(testing.TestCase):\n         mock_symbolic_call.return_value = mock_tensor\n         x = keras_tensor.KerasTensor(shape=(3, 4), dtype=\"float32\")\n         y = keras_tensor.KerasTensor(shape=(3, 4), dtype=\"float32\")\n-        # to ensure compatibility across Python versions.\n+        # to ensure compatibility across Python versions\n         result = x.__rdiv__(y)\n         mock_symbolic_call.assert_called_once_with(y, x)\n         self.assertEqual(result, mock_tensor)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e28e933cba913116bedf1ae7a0d9480021fcac96", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 266 | Contributors (this commit): 2 | Commits (past 90d): 4 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -369,7 +369,7 @@ class KerasTensorTest(testing.TestCase):\n         mock_symbolic_call.return_value = mock_tensor\n         x = keras_tensor.KerasTensor(shape=(3, 4), dtype=\"float32\")\n         y = keras_tensor.KerasTensor(shape=(3, 4), dtype=\"float32\")\n-        # to ensure compatibility across Python versions.\n+        # to ensure compatibility across Python versions\n         result = x.__div__(y)\n         mock_symbolic_call.assert_called_once_with(x, y)\n         self.assertEqual(result, mock_tensor)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0b781e00446ab4684f862d2946acb1a79e3e50a3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 268 | Contributors (this commit): 2 | Commits (past 90d): 5 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -369,7 +369,7 @@ class KerasTensorTest(testing.TestCase):\n         mock_symbolic_call.return_value = mock_tensor\n         x = keras_tensor.KerasTensor(shape=(3, 4), dtype=\"float32\")\n         y = keras_tensor.KerasTensor(shape=(3, 4), dtype=\"float32\")\n-        # to ensure compatibility across Python versions\n+        # to ensure compatibility across Python versions.\n         result = x.__div__(y)\n         mock_symbolic_call.assert_called_once_with(x, y)\n         self.assertEqual(result, mock_tensor)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#29a954a83671e6e79ac6dca94ebcb3c2eb371c5f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 270 | Contributors (this commit): 2 | Commits (past 90d): 6 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -369,7 +369,7 @@ class KerasTensorTest(testing.TestCase):\n         mock_symbolic_call.return_value = mock_tensor\n         x = keras_tensor.KerasTensor(shape=(3, 4), dtype=\"float32\")\n         y = keras_tensor.KerasTensor(shape=(3, 4), dtype=\"float32\")\n-        # to ensure compatibility across Python versions.\n+        # to ensure compatibility across Python versions\n         result = x.__div__(y)\n         mock_symbolic_call.assert_called_once_with(x, y)\n         self.assertEqual(result, mock_tensor)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e80b0f27d503ce671c961413790bf71b445f3484", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 1340 | Contributors (this commit): 6 | Commits (past 90d): 8 | Contributors (cumulative): 6 | DMM Complexity: 0.0\n\nDIFF:\n@@ -58,8 +58,11 @@ def run_namex_conversion():\n \n def create_legacy_directory():\n     # Make keras/_tf_keras/ by copying keras/\n-    tf_keras_dirpath = os.path.join(package, \"_tf_keras\")\n+    tf_keras_dirpath_parent = os.path.join(package, \"_tf_keras\")\n+    tf_keras_dirpath = os.path.join(tf_keras_dirpath_parent, \"keras\")\n     os.makedirs(tf_keras_dirpath)\n+    with open(os.path.join(tf_keras_dirpath_parent, \"__init__.py\"), \"w\") as f:\n+        f.write(\"\")\n     with open(os.path.join(package, \"__init__.py\")) as f:\n         init_file = f.read()\n         init_file = init_file.replace(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#180e1f82d09bd077c36194b18e045c41e750ff89", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 7 | Churn Cumulative: 11 | Contributors (this commit): 1 | Commits (past 90d): 2 | Contributors (cumulative): 1 | DMM Complexity: 0.0\n\nDIFF:\n@@ -80,6 +80,13 @@ class TFOptimizer(base_optimizer.BaseOptimizer):\n     ):\n         \"\"\"`apply_gradients` using a `DistributionStrategy`.\"\"\"\n \n+        unwrapped_grads_and_vars = []\n+        for g, v in grads_and_vars:\n+            if isinstance(v, backend.Variable):\n+                v = v.value\n+            unwrapped_grads_and_vars.append((g, v))\n+        grads_and_vars = unwrapped_grads_and_vars\n+\n         def apply_grad_to_update_var(var, grad):\n             learning_rate = self._get_current_learning_rate()\n             grad = tf.convert_to_tensor(grad)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f23d482c7a889f2ef30d6a5118232567c51e2360", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 4 | Methods Changed: 5 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 12 | Churn Cumulative: 29 | Contributors (this commit): 2 | Commits (past 90d): 5 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -58,6 +58,8 @@ class TFOptimizer(base_optimizer.BaseOptimizer):\n                     variable.assign(variable - variable * wd * lr)\n \n             for variable in variables:\n+                if isinstance(variable, backend.Variable):\n+                    variable = variable.value  # Convert to tf.Variable\n                 distribution.extended.update(\n                     variable, weight_decay_fn, group=False\n                 )\n\n@@ -46,7 +46,7 @@ class OptimizerDistributeTest(testing.TestCase):\n                 momentum=0.06,\n             )\n             grads = tf.constant([1.0, 6.0, 7.0, 2.0])\n-            vars = backend.Variable([1.0, 2.0, 3.0, 4.0]).value\n+            vars = backend.Variable([1.0, 2.0, 3.0, 4.0])\n \n             self.strategy.run(\n                 lambda: optimizer.apply_gradients(zip([grads], [vars]))\n@@ -59,9 +59,9 @@ class OptimizerDistributeTest(testing.TestCase):\n         with self.strategy.scope():\n             grads, var1, var2, var3 = (\n                 tf.zeros(()),\n-                backend.Variable(2.0).value,\n-                backend.Variable(3.0, name=\"exclude\").value,\n-                backend.Variable(4.0).value,\n+                backend.Variable(2.0),\n+                backend.Variable(3.0, name=\"exclude\"),\n+                backend.Variable(4.0),\n             )\n             optimizer_1 = SGD(learning_rate=1.0, weight_decay=0.004)\n             self.strategy.run(\n@@ -92,7 +92,7 @@ class OptimizerDistributeTest(testing.TestCase):\n         with self.strategy.scope():\n             optimizer = SGD(nesterov=True)\n \n-            x = backend.Variable(np.ones([10])).value\n+            x = backend.Variable(np.ones([10]))\n             grads = np.arange(0.1, 1.1, 0.1)\n             first_grads = np.full((10,), 0.01)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cb2f5168ec568e459eb50499848ff9292356ef6f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 5 | Methods Changed: 3 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 20 | Churn Cumulative: 32 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -46,7 +46,6 @@ from keras.trainers.data_adapters import generator_data_adapter\n from keras.trainers.data_adapters import py_dataset_adapter\n from keras.trainers.data_adapters import tf_dataset_adapter\n from keras.trainers.data_adapters import torch_data_adapter\n-from keras.utils.module_utils import tensorflow as tf\n \n \n class EpochIterator:\n@@ -76,7 +75,7 @@ class EpochIterator:\n                 batch_size=batch_size,\n                 steps=steps_per_epoch,\n             )\n-        elif tf.available and isinstance(x, tf.data.Dataset):\n+        elif is_tf_dataset(x):\n             self.data_adapter = tf_dataset_adapter.TFDatasetAdapter(\n                 x, class_weight=class_weight\n             )\n@@ -170,18 +169,13 @@ class EpochIterator:\n                 if self._insufficient_data:\n                     break\n \n-                if tf.available:\n-                    errors = (StopIteration, tf.errors.OutOfRangeError)\n-                else:\n-                    errors = (StopIteration,)\n-\n                 try:\n                     data = next(self._current_iterator)\n                     buffer.append(data)\n                     if len(buffer) == self.steps_per_execution:\n                         yield step - len(buffer) + 1, buffer\n                         buffer = []\n-                except errors:\n+                except (StopIteration,):\n                     warnings.warn(\n                         \"Your input ran out of data; interrupting epoch. \"\n                         \"Make sure that your dataset or generator can generate \"\n@@ -225,6 +219,16 @@ def raise_unsupported_arg(arg_name, arg_description, input_type):\n     )\n \n \n+def is_tf_dataset(x):\n+    if hasattr(x, \"__class__\"):\n+        for parent in x.__class__.__mro__:\n+            if parent.__name__ == \"DatasetV2\" and str(\n+                parent.__module__\n+            ).startswith(\"tensorflow.python.types.data\"):\n+                return True\n+    return False\n+\n+\n def is_torch_dataloader(x):\n     if hasattr(x, \"__class__\"):\n         for parent in x.__class__.__mro__:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6e536f68dc1c57368d9a843d7df59ef5eb6acc33", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 31 | Lines Deleted: 8 | Files Changed: 3 | Hunks: 7 | Methods Changed: 7 | Complexity Δ (Sum/Max): -1/1 | Churn Δ: 39 | Churn Cumulative: 78 | Contributors (this commit): 2 | Commits (past 90d): 9 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -31,6 +31,13 @@ class TFOptimizer(base_optimizer.BaseOptimizer):\n                 reference_variable, name=name\n             )\n \n+    def stateless_apply(self, optimizer_variables, grads, trainable_variables):\n+        # This is mainly due to the interaction with tf.distribute.Strategy,\n+        # which requires tf.Variable as the inputs for most of its APIs.\n+        raise ValueError(\n+            \"stateless_apply is not supported by the TF based \" \"optimizer. \"\n+        )\n+\n     def _var_key(self, variable):\n         if isinstance(variable, backend.Variable):\n             variable = variable.value  # Convert to tf.Variable\n\n@@ -130,3 +130,11 @@ class OptimizerDistributeTest(testing.TestCase):\n             grad = [np.array([100.0, 100.0])]\n             clipped_grad = optimizer._clip_gradients(grad)\n             self.assertAllClose(clipped_grad[0], [1.0, 1.0])\n+\n+    def test_stateless_not_supported(self):\n+        optimizer = SGD(learning_rate=0.5)\n+        grads = [np.array([1.0, 6.0, 7.0, 2.0])]\n+        vars = [backend.Variable([1.0, 2.0, 3.0, 4.0])]\n+        optimizer.build(vars)\n+        with self.assertRaisesRegex(ValueError, \"not supported\"):\n+            optimizer.stateless_apply(optimizer.variables, grads, vars)\n\n@@ -9,6 +9,14 @@ from keras.optimizers.sgd import SGD\n \n \n class LossScaleOptimizerTest(testing.TestCase, parameterized.TestCase):\n+    def _skip_test_for_stateless(self, stateless):\n+        if not stateless and backend.backend() == \"jax\":\n+            self.skipTest(\"LossScaleOptimizer must use stateless_apply on jax.\")\n+        if stateless and backend.backend() == \"tensorflow\":\n+            self.skipTest(\n+                \"stateless_apply is not supported by the tf based optimizer\"\n+            )\n+\n     def test_config(self):\n         inner_optimizer = SGD(\n             learning_rate=0.5,\n@@ -21,8 +29,8 @@ class LossScaleOptimizerTest(testing.TestCase, parameterized.TestCase):\n \n     @parameterized.named_parameters((\"stateless\", True), (\"stateful\", False))\n     def test_finite_step(self, stateless):\n-        if not stateless and backend.backend() == \"jax\":\n-            self.skipTest(\"LossScaleOptimizer must use stateless_apply on jax.\")\n+        self._skip_test_for_stateless(stateless)\n+\n         inner_optimizer = SGD(learning_rate=0.5)\n         optimizer = LossScaleOptimizer(inner_optimizer)\n         grads = [ops.array([1.0, 6.0, 7.0, 2.0]) * optimizer.initial_scale]\n@@ -40,8 +48,8 @@ class LossScaleOptimizerTest(testing.TestCase, parameterized.TestCase):\n \n     @parameterized.named_parameters((\"stateless\", True), (\"stateful\", False))\n     def test_infinite_step(self, stateless):\n-        if not stateless and backend.backend() == \"jax\":\n-            self.skipTest(\"LossScaleOptimizer must use stateless_apply on jax.\")\n+        self._skip_test_for_stateless(stateless)\n+\n         inner_optimizer = SGD(learning_rate=0.5)\n         optimizer = LossScaleOptimizer(inner_optimizer)\n         grads = [ops.array([np.inf, np.inf, np.inf, np.inf])]\n@@ -57,8 +65,8 @@ class LossScaleOptimizerTest(testing.TestCase, parameterized.TestCase):\n \n     @parameterized.named_parameters((\"stateless\", True), (\"stateful\", False))\n     def test_downscaling(self, stateless):\n-        if not stateless and backend.backend() == \"jax\":\n-            self.skipTest(\"LossScaleOptimizer must use stateless_apply on jax.\")\n+        self._skip_test_for_stateless(stateless)\n+\n         inner_optimizer = SGD(learning_rate=0.5)\n         optimizer = LossScaleOptimizer(inner_optimizer, initial_scale=400.0)\n         vars = [backend.Variable([1.0, 2.0, 3.0, 4.0])]\n@@ -76,8 +84,8 @@ class LossScaleOptimizerTest(testing.TestCase, parameterized.TestCase):\n \n     @parameterized.named_parameters((\"stateless\", True), (\"stateful\", False))\n     def test_upscaling(self, stateless):\n-        if not stateless and backend.backend() == \"jax\":\n-            self.skipTest(\"LossScaleOptimizer must use stateless_apply on jax.\")\n+        self._skip_test_for_stateless(stateless)\n+\n         inner_optimizer = SGD(learning_rate=0.5)\n         optimizer = LossScaleOptimizer(\n             inner_optimizer,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ece41771c764538f13043252f9056690777b912a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 22 | Contributors (this commit): 2 | Commits (past 90d): 5 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -35,7 +35,7 @@ class TFOptimizer(base_optimizer.BaseOptimizer):\n         # This is mainly due to the interaction with tf.distribute.Strategy,\n         # which requires tf.Variable as the inputs for most of its APIs.\n         raise ValueError(\n-            \"stateless_apply is not supported by the TF based \" \"optimizer. \"\n+            \"stateless_apply is not supported by the TF based optimizer.\"\n         )\n \n     def _var_key(self, variable):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#06d8b95a7e34b3d1c8c72e42c4b263c982e7ad81", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 329 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 7 | Complexity Δ (Sum/Max): 12/12 | Churn Δ: 329 | Churn Cumulative: 329 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,329 @@\n+\"\"\"\n+Title: Image classification with ConvMixer\n+Author: [Sayak Paul](https://twitter.com/RisingSayak)\n+Converted to Keras Core: [Md Awsafur Rahman](https://awsaf49.github.io)\n+Date created: 2021/10/12\n+Last modified: 2021/10/12\n+Description: An all-convolutional network applied to patches of images.\n+\"\"\"\n+\"\"\"\n+## Introduction\n+\n+Vision Transformers (ViT; [Dosovitskiy et al.](https://arxiv.org/abs/1612.00593)) extract\n+small patches from the input images, linearly project them, and then apply the\n+Transformer ([Vaswani et al.](https://arxiv.org/abs/1706.03762)) blocks. The application\n+of ViTs to image recognition tasks is quickly becoming a promising area of research,\n+because ViTs eliminate the need to have strong inductive biases (such as convolutions) for\n+modeling locality. This presents them as a general computation primititive capable of\n+learning just from the training data with as minimal inductive priors as possible. ViTs\n+yield great downstream performance when trained with proper regularization, data\n+augmentation, and relatively large datasets.\n+\n+In the [Patches Are All You Need](https://openreview.net/pdf?id=TVHS5Y4dNvM) paper (note:\n+at\n+the time of writing, it is a submission to the ICLR 2022 conference), the authors extend\n+the idea of using patches to train an all-convolutional network and demonstrate\n+competitive results. Their architecture namely **ConvMixer** uses recipes from the recent\n+isotrophic architectures like ViT, MLP-Mixer\n+([Tolstikhin et al.](https://arxiv.org/abs/2105.01601)), such as using the same\n+depth and resolution across different layers in the network, residual connections,\n+and so on.\n+\n+In this example, we will implement the ConvMixer model and demonstrate its performance on\n+the CIFAR-10 dataset.\n+\"\"\"\n+\n+\"\"\"shell\n+pip install -qU keras_core\n+\"\"\"\n+\n+\"\"\"\n+## Imports\n+\"\"\"\n+\n+import os\n+\n+os.environ[\"KERAS_BACKEND\"] = \"jax\"\n+\n+import keras_core as keras\n+from keras_core import layers\n+\n+import matplotlib.pyplot as plt\n+import tensorflow as tf\n+import numpy as np\n+\n+\"\"\"\n+## Hyperparameters\n+\n+To keep run time short, we will train the model for only 10 epochs. To focus on\n+the core ideas of ConvMixer, we will not use other training-specific elements like\n+RandAugment ([Cubuk et al.](https://arxiv.org/abs/1909.13719)). If you are interested in\n+learning more about those details, please refer to the\n+[original paper](https://openreview.net/pdf?id=TVHS5Y4dNvM).\n+\"\"\"\n+\n+learning_rate = 0.001\n+weight_decay = 0.0001\n+batch_size = 128\n+num_epochs = 10\n+\n+\"\"\"\n+## Load the CIFAR-10 dataset\n+\"\"\"\n+\n+(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n+val_split = 0.1\n+\n+val_indices = int(len(x_train) * val_split)\n+new_x_train, new_y_train = x_train[val_indices:], y_train[val_indices:]\n+x_val, y_val = x_train[:val_indices], y_train[:val_indices]\n+\n+print(f\"Training data samples: {len(new_x_train)}\")\n+print(f\"Validation data samples: {len(x_val)}\")\n+print(f\"Test data samples: {len(x_test)}\")\n+\n+\"\"\"\n+## Prepare `tf.data.Dataset` objects\n+\n+Our data augmentation pipeline is different from what the authors used for the CIFAR-10\n+dataset, which is fine for the purpose of the example.\n+Note that, it's ok to use **TF APIs for data I/O and preprocessing** with other backends\n+(jax, torch) as it is feature-complete framework when it comes to data preprocessing.\n+\"\"\"\n+\n+image_size = 32\n+auto = tf.data.AUTOTUNE\n+\n+data_augmentation = tf.keras.Sequential(\n+    [\n+        tf.keras.layers.RandomCrop(image_size, image_size),\n+        tf.keras.layers.RandomFlip(\"horizontal\"),\n+    ],\n+    name=\"data_augmentation\",\n+)\n+\n+\n+def make_datasets(images, labels, is_train=False):\n+    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n+    if is_train:\n+        dataset = dataset.shuffle(batch_size * 10)\n+    dataset = dataset.batch(batch_size)\n+    if is_train:\n+        dataset = dataset.map(\n+            lambda x, y: (data_augmentation(x), y), num_parallel_calls=auto\n+        )\n+    return dataset.prefetch(auto)\n+\n+\n+train_dataset = make_datasets(new_x_train, new_y_train, is_train=True)\n+val_dataset = make_datasets(x_val, y_val)\n+test_dataset = make_datasets(x_test, y_test)\n+\n+\"\"\"\n+## ConvMixer utilities\n+\n+The following figure (taken from the original paper) depicts the ConvMixer model:\n+\n+![](https://i.imgur.com/yF8actg.png)\n+\n+ConvMixer is very similar to the MLP-Mixer, model with the following key\n+differences:\n+\n+* Instead of using fully-connected layers, it uses standard convolution layers.\n+* Instead of LayerNorm (which is typical for ViTs and MLP-Mixers), it uses BatchNorm.\n+\n+Two types of convolution layers are used in ConvMixer. **(1)**: Depthwise convolutions,\n+for mixing spatial locations of the images, **(2)**: Pointwise convolutions (which follow\n+the depthwise convolutions), for mixing channel-wise information across the patches.\n+Another keypoint is the use of *larger kernel sizes* to allow a larger receptive field.\n+\"\"\"\n+\n+\n+def activation_block(x):\n+    x = layers.Activation(\"gelu\")(x)\n+    return layers.BatchNormalization()(x)\n+\n+\n+def conv_stem(x, filters: int, patch_size: int):\n+    x = layers.Conv2D(filters, kernel_size=patch_size, strides=patch_size)(x)\n+    return activation_block(x)\n+\n+\n+def conv_mixer_block(x, filters: int, kernel_size: int):\n+    # Depthwise convolution.\n+    x0 = x\n+    x = layers.DepthwiseConv2D(kernel_size=kernel_size, padding=\"same\")(x)\n+    x = layers.Add()([activation_block(x), x0])  # Residual.\n+\n+    # Pointwise convolution.\n+    x = layers.Conv2D(filters, kernel_size=1)(x)\n+    x = activation_block(x)\n+\n+    return x\n+\n+\n+def get_conv_mixer_256_8(\n+    image_size=32, filters=256, depth=8, kernel_size=5, patch_size=2, num_classes=10\n+):\n+    \"\"\"ConvMixer-256/8: https://openreview.net/pdf?id=TVHS5Y4dNvM.\n+    The hyperparameter values are taken from the paper.\n+    \"\"\"\n+    inputs = keras.Input((image_size, image_size, 3))\n+    x = layers.Rescaling(scale=1.0 / 255)(inputs)\n+\n+    # Extract patch embeddings.\n+    x = conv_stem(x, filters, patch_size)\n+\n+    # ConvMixer blocks.\n+    for _ in range(depth):\n+        x = conv_mixer_block(x, filters, kernel_size)\n+\n+    # Classification block.\n+    x = layers.GlobalAvgPool2D()(x)\n+    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n+\n+    return keras.Model(inputs, outputs)\n+\n+\n+\"\"\"\n+The model used in this experiment is termed as **ConvMixer-256/8** where 256 denotes the\n+number of channels and 8 denotes the depth. The resulting model only has 0.8 million\n+parameters.\n+\"\"\"\n+\n+\"\"\"\n+## Model training and evaluation utility\n+\"\"\"\n+\n+# Code reference:\n+# https://keras.io/examples/vision/image_classification_with_vision_transformer/.\n+\n+\n+def run_experiment(model):\n+    optimizer = keras.optimizers.AdamW(\n+        learning_rate=learning_rate, weight_decay=weight_decay\n+    )\n+\n+    model.compile(\n+        optimizer=optimizer,\n+        loss=\"sparse_categorical_crossentropy\",\n+        metrics=[\"accuracy\"],\n+    )\n+\n+    checkpoint_filepath = \"/tmp/checkpoint.keras\"\n+    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n+        checkpoint_filepath,\n+        monitor=\"val_accuracy\",\n+        save_best_only=True,\n+        save_weights_only=False,\n+    )\n+\n+    history = model.fit(\n+        train_dataset,\n+        validation_data=val_dataset,\n+        epochs=num_epochs,\n+        callbacks=[checkpoint_callback],\n+    )\n+\n+    model.load_weights(checkpoint_filepath)\n+    _, accuracy = model.evaluate(test_dataset)\n+    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n+\n+    return history, model\n+\n+\n+\"\"\"\n+## Train and evaluate model\n+\"\"\"\n+\n+conv_mixer_model = get_conv_mixer_256_8()\n+history, conv_mixer_model = run_experiment(conv_mixer_model)\n+\n+\"\"\"\n+The gap in training and validation performance can be mitigated by using additional\n+regularization techniques. Nevertheless, being able to get to ~83% accuracy within 10\n+epochs with 0.8 million parameters is a strong result.\n+\"\"\"\n+\n+\"\"\"\n+## Visualizing the internals of ConvMixer\n+\n+We can visualize the patch embeddings and the learned convolution filters. Recall\n+that each patch embedding and intermediate feature map have the same number of channels\n+(256 in this case). This will make our visualization utility easier to implement.\n+\"\"\"\n+\n+# Code reference: https://bit.ly/3awIRbP.\n+\n+\n+def visualization_plot(weights, idx=1):\n+    # First, apply min-max normalization to the\n+    # given weights to avoid isotrophic scaling.\n+    p_min, p_max = weights.min(), weights.max()\n+    weights = (weights - p_min) / (p_max - p_min)\n+\n+    # Visualize all the filters.\n+    num_filters = 256\n+    plt.figure(figsize=(8, 8))\n+\n+    for i in range(num_filters):\n+        current_weight = weights[:, :, :, i]\n+        if current_weight.shape[-1] == 1:\n+            current_weight = current_weight.squeeze()\n+        ax = plt.subplot(16, 16, idx)\n+        ax.set_xticks([])\n+        ax.set_yticks([])\n+        plt.imshow(current_weight)\n+        idx += 1\n+\n+\n+# We first visualize the learned patch embeddings.\n+patch_embeddings = conv_mixer_model.layers[2].get_weights()[0]\n+visualization_plot(patch_embeddings)\n+\n+\"\"\"\n+Even though we did not train the network to convergence, we can notice that different\n+patches show different patterns. Some share similarity with others while some are very\n+different. These visualizations are more salient with larger image sizes.\n+\n+Similarly, we can visualize the raw convolution kernels. This can help us understand\n+the patterns to which a given kernel is receptive.\n+\"\"\"\n+\n+# First, print the indices of the convolution layers that are not\n+# pointwise convolutions.\n+for i, layer in enumerate(conv_mixer_model.layers):\n+    if isinstance(layer, layers.DepthwiseConv2D):\n+        if layer.get_config()[\"kernel_size\"] == (5, 5):\n+            print(i, layer)\n+\n+idx = 26  # Taking a kernel from the middle of the network.\n+\n+kernel = conv_mixer_model.layers[idx].get_weights()[0]\n+kernel = np.expand_dims(kernel.squeeze(), axis=2)\n+visualization_plot(kernel)\n+\n+\"\"\"\n+We see that different filters in the kernel have different locality spans, and this\n+pattern\n+is likely to evolve with more training.\n+\"\"\"\n+\n+\"\"\"\n+## Final notes\n+\n+There's been a recent trend on fusing convolutions with other data-agnostic operations\n+like self-attention. Following works are along this line of research:\n+\n+* ConViT ([d'Ascoli et al.](https://arxiv.org/abs/2103.10697))\n+* CCT ([Hassani et al.](https://arxiv.org/abs/2104.05704))\n+* CoAtNet ([Dai et al.](https://arxiv.org/abs/2106.04803))\n+\n+| Trained Model | Demo |\n+| :--: | :--: |\n+| [![Generic\n+badge](https://img.shields.io/badge/🤗%20Model-ConvMixer-black.svg)](https://huggingface.co\n+/keras-io/conv_Mixer) | [![Generic\n+badge](https://img.shields.io/badge/🤗%20Spaces-ConvMixer-black.svg)](https://huggingface.c\n+o/spaces/keras-io/conv_Mixer) |\n+\"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
