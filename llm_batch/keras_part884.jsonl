{"custom_id": "keras#da07901124c1af67e9f3aa9df9ac6d21b95ad5f8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 199 | Lines Deleted: 119 | Files Changed: 3 | Hunks: 48 | Methods Changed: 16 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 318 | Churn Cumulative: 1422 | Contributors (this commit): 6 | Commits (past 90d): 7 | Contributors (cumulative): 9 | DMM Complexity: 0.9791666666666666\n\nDIFF:\n@@ -546,7 +546,8 @@ def perspective_transform(\n \n     batch_size, height, width, channels = images.shape\n     transforms = compute_homography_matrix(\n-        jnp.asarray(start_points), jnp.asarray(end_points)\n+        jnp.asarray(start_points, dtype=\"float32\"),\n+        jnp.asarray(end_points, dtype=\"float32\"),\n     )\n \n     x, y = jnp.meshgrid(jnp.arange(width), jnp.arange(height), indexing=\"xy\")\n\n@@ -49,7 +49,7 @@ class RandomPerspective(BaseImagePreprocessingLayer):\n     def __init__(\n         self,\n         factor=1.0,\n-        scale=0.3,\n+        scale=1.0,\n         interpolation=\"bilinear\",\n         fill_value=0.0,\n         seed=None,\n@@ -103,6 +103,10 @@ class RandomPerspective(BaseImagePreprocessingLayer):\n             batch_size = 1\n         else:\n             batch_size = images_shape[0]\n+        height, width = (\n+            images.shape[self.height_axis],\n+            images.shape[self.width_axis],\n+        )\n \n         seed = seed or self._get_seed_generator(self.backend._backend)\n \n@@ -122,32 +126,42 @@ class RandomPerspective(BaseImagePreprocessingLayer):\n         apply_perspective = random_threshold < transformation_probability\n \n         perspective_factor = self.backend.random.uniform(\n-            minval=-self.scale,\n-            maxval=self.scale,\n-            shape=[batch_size, 4],\n+            shape=(batch_size, 4, 2),\n+            minval=-0.5 * self.scale,\n+            maxval=0.5 * self.scale,\n             seed=seed,\n             dtype=self.compute_dtype,\n         )\n \n+        start_points = self.backend.convert_to_tensor(\n+            [\n+                [\n+                    [0.0, 0.0],\n+                    [width - 1, 0.0],\n+                    [0.0, height - 1],\n+                    [width - 1, height - 1],\n+                ]\n+            ],\n+            dtype=self.compute_dtype,\n+        )\n+\n+        start_points = self.backend.numpy.repeat(\n+            start_points, batch_size, axis=0\n+        )\n+        end_points = start_points + start_points * perspective_factor\n+\n         return {\n             \"apply_perspective\": apply_perspective,\n-            \"perspective_factor\": perspective_factor,\n+            \"start_points\": start_points,\n+            \"end_points\": end_points,\n             \"input_shape\": images_shape,\n         }\n \n     def transform_images(self, images, transformation, training=True):\n         images = self.backend.cast(images, self.compute_dtype)\n         if training and transformation is not None:\n-            apply_perspective = transformation[\"apply_perspective\"]\n-            perspective_images = self._perspective_inputs(\n-                images, transformation\n-            )\n-\n-            images = self.backend.numpy.where(\n-                apply_perspective[:, None, None, None],\n-                perspective_images,\n-                images,\n-            )\n+            images = self._perspective_inputs(images, transformation)\n+            images = self.backend.cast(images, self.compute_dtype)\n         return images\n \n     def _perspective_inputs(self, inputs, transformation):\n@@ -159,63 +173,36 @@ class RandomPerspective(BaseImagePreprocessingLayer):\n         if unbatched:\n             inputs = self.backend.numpy.expand_dims(inputs, axis=0)\n \n-        perspective_factor = self.backend.core.convert_to_tensor(\n-            transformation[\"perspective_factor\"], dtype=self.compute_dtype\n-        )\n-        outputs = self.backend.image.affine_transform(\n+        start_points = transformation[\"start_points\"]\n+        end_points = transformation[\"end_points\"]\n+\n+        outputs = self.backend.image.perspective_transform(\n             inputs,\n-            transform=self._get_perspective_matrix(perspective_factor),\n+            start_points,\n+            end_points,\n             interpolation=self.interpolation,\n-            fill_mode=\"constant\",\n             fill_value=self.fill_value,\n             data_format=self.data_format,\n         )\n \n+        apply_perspective = transformation[\"apply_perspective\"]\n+        outputs = self.backend.numpy.where(\n+            apply_perspective[:, None, None, None],\n+            outputs,\n+            inputs,\n+        )\n+\n         if unbatched:\n             outputs = self.backend.numpy.squeeze(outputs, axis=0)\n         return outputs\n \n-    def _get_perspective_matrix(self, perspectives):\n-        perspectives = self.backend.core.convert_to_tensor(\n-            perspectives, dtype=self.compute_dtype\n-        )\n-        num_perspectives = self.backend.shape(perspectives)[0]\n-        return self.backend.numpy.concatenate(\n-            [\n-                self.backend.numpy.ones(\n-                    (num_perspectives, 1), dtype=self.compute_dtype\n-                )\n-                + perspectives[:, :1],\n-                perspectives[:, :1],\n-                perspectives[:, 2:3],\n-                perspectives[:, 1:2],\n-                self.backend.numpy.ones(\n-                    (num_perspectives, 1), dtype=self.compute_dtype\n-                )\n-                + perspectives[:, 1:2],\n-                perspectives[:, 3:4],\n-                self.backend.numpy.zeros((num_perspectives, 2)),\n-            ],\n-            axis=1,\n-        )\n-\n-    def _get_transformed_coordinates(self, x, y, transform):\n-        a0, a1, a2, b0, b1, b2, c0, c1 = self.backend.numpy.split(\n-            transform, 8, axis=-1\n-        )\n-\n-        x_transformed = (a1 * (y - b2) - b1 * (x - a2)) / (a1 * b0 - a0 * b1)\n-        y_transformed = (b0 * (x - a2) - a0 * (y - b2)) / (a1 * b0 - a0 * b1)\n-\n-        return x_transformed, y_transformed\n-\n     def transform_bounding_boxes(\n         self,\n         bounding_boxes,\n         transformation,\n         training=True,\n     ):\n-        if training:\n+        if training and transformation is not None:\n             if backend_utils.in_tf_graph():\n                 self.backend.set_backend(\"tensorflow\")\n \n@@ -233,26 +220,33 @@ class RandomPerspective(BaseImagePreprocessingLayer):\n             )\n \n             boxes = bounding_boxes[\"boxes\"]\n-\n             x0, y0, x1, y1 = self.backend.numpy.split(boxes, 4, axis=-1)\n \n-            perspective_factor = transformation[\"perspective_factor\"]\n-            transform = self._get_perspective_matrix(perspective_factor)\n+            start_points = transformation[\"start_points\"]\n+            end_points = transformation[\"end_points\"]\n+            transform = self.backend.image.compute_homography_matrix(\n+                start_points, end_points\n+            )\n             transform = self.backend.numpy.expand_dims(transform, axis=1)\n             transform = self.backend.cast(transform, dtype=self.compute_dtype)\n \n-            x_1, y_1 = self._get_transformed_coordinates(x0, y0, transform)\n-            x_2, y_2 = self._get_transformed_coordinates(x1, y1, transform)\n-            x_3, y_3 = self._get_transformed_coordinates(x0, y1, transform)\n-            x_4, y_4 = self._get_transformed_coordinates(x1, y0, transform)\n+            corners = [\n+                self._get_transformed_coordinates(x, y, transform)\n+                for x, y in [(x0, y0), (x1, y1), (x0, y1), (x1, y0)]\n+            ]\n+            x_corners, y_corners = zip(*corners)\n \n-            xs = self.backend.numpy.concatenate([x_1, x_2, x_3, x_4], axis=-1)\n-            ys = self.backend.numpy.concatenate([y_1, y_2, y_3, y_4], axis=-1)\n+            xs = self.backend.numpy.stack(x_corners, axis=-1)\n+            ys = self.backend.numpy.stack(y_corners, axis=-1)\n \n-            min_x = self.backend.numpy.min(xs, axis=-1)\n-            max_x = self.backend.numpy.max(xs, axis=-1)\n-            min_y = self.backend.numpy.min(ys, axis=-1)\n-            max_y = self.backend.numpy.max(ys, axis=-1)\n+            min_x, max_x = (\n+                self.backend.numpy.min(xs, axis=-1),\n+                self.backend.numpy.max(xs, axis=-1),\n+            )\n+            min_y, max_y = (\n+                self.backend.numpy.min(ys, axis=-1),\n+                self.backend.numpy.max(ys, axis=-1),\n+            )\n \n             min_x = self.backend.numpy.expand_dims(min_x, axis=-1)\n             max_x = self.backend.numpy.expand_dims(max_x, axis=-1)\n@@ -280,8 +274,43 @@ class RandomPerspective(BaseImagePreprocessingLayer):\n                 bounding_box_format=\"xyxy\",\n             )\n \n+            self.backend.reset()\n+\n         return bounding_boxes\n \n+    def _get_transformed_coordinates(\n+        self, x_coords, y_coords, transformation_matrix\n+    ):\n+        backend = self.backend\n+\n+        batch_size = backend.shape(transformation_matrix)[0]\n+\n+        homogeneous_transform = backend.numpy.concatenate(\n+            [transformation_matrix, backend.numpy.ones((batch_size, 1, 1))],\n+            axis=-1,\n+        )\n+        homogeneous_transform = backend.numpy.reshape(\n+            homogeneous_transform, (batch_size, 3, 3)\n+        )\n+\n+        inverse_transform = backend.linalg.inv(homogeneous_transform)\n+\n+        ones_column = backend.numpy.ones_like(x_coords)\n+        homogeneous_coords = backend.numpy.concatenate(\n+            [x_coords, y_coords, ones_column], axis=-1\n+        )\n+\n+        homogeneous_coords = backend.numpy.moveaxis(homogeneous_coords, -1, -2)\n+        transformed_coords = backend.numpy.matmul(\n+            inverse_transform, homogeneous_coords\n+        )\n+        transformed_coords = backend.numpy.moveaxis(transformed_coords, -1, -2)\n+\n+        x_transformed = transformed_coords[..., 0] / transformed_coords[..., 2]\n+        y_transformed = transformed_coords[..., 1] / transformed_coords[..., 2]\n+\n+        return x_transformed, y_transformed\n+\n     def transform_labels(self, labels, transformation, training=True):\n         return labels\n \n\n@@ -43,38 +43,44 @@ class RandomPerspectiveTest(testing.TestCase):\n         output = layer(inputs)\n         self.assertAllClose(inputs, output)\n \n-        layer = layers.RandomPerspective(scale=0)\n-\n-        np.random.seed(seed)\n-        inputs = np.random.randint(0, 255, size=(224, 224, 3))\n-        output = layer(inputs)\n-        self.assertAllClose(inputs, output)\n-\n     def test_random_perspective_basic(self):\n         data_format = backend.config.image_data_format()\n         if data_format == \"channels_last\":\n-            inputs = np.ones((2, 2, 1))\n-            expected_output = np.array(\n-                [[[[1.0], [0.89476013]], [[0.84097195], [0.6412543]]]]\n+            inputs = np.ones((4, 4, 1))\n+            expected_output = np.asarray(\n+                [\n+                    [[1.0], [1.0], [0.0], [0.0]],\n+                    [[1.0], [1.0], [0.0], [0.0]],\n+                    [[0.0], [0.0], [0.0], [0.0]],\n+                    [[0.0], [0.0], [0.0], [0.0]],\n+                ],\n             )\n \n         else:\n-            inputs = np.ones((1, 2, 2))\n-            expected_output = np.array([[[[1.0000, 0.8948], [0.8410, 0.6413]]]])\n+            inputs = np.ones((1, 4, 4))\n+            expected_output = np.array(\n+                [\n+                    [\n+                        [1.0, 1.0, 0.0, 0.0],\n+                        [1.0, 1.0, 0.0, 0.0],\n+                        [0.0, 0.0, 0.0, 0.0],\n+                        [0.0, 0.0, 0.0, 0.0],\n+                    ]\n+                ]\n+            )\n \n         layer = layers.RandomPerspective(data_format=data_format)\n \n         transformation = {\n-            \"apply_perspective\": np.asarray([True]),\n-            \"perspective_factor\": np.asarray(\n-                [[0.05261999, 0.07951406, 0.05261999, 0.07951406]]\n+            \"apply_perspective\": np.array([True]),\n+            \"start_points\": np.array(\n+                [[[0.0, 0.0], [3.0, 0.0], [0.0, 3.0], [3.0, 3.0]]]\n             ),\n+            \"end_points\": np.array([[[0.0, 0.0], [1, 0.0], [0.0, 1], [1, 1]]]),\n+            \"input_shape\": np.array((4, 4, 1)),\n         }\n-\n         output = layer.transform_images(inputs, transformation)\n \n-        print(output)\n-\n         self.assertAllClose(expected_output, output, atol=1e-4, rtol=1e-4)\n \n     def test_tf_data_compatibility(self):\n@@ -91,27 +97,43 @@ class RandomPerspectiveTest(testing.TestCase):\n \n     @parameterized.named_parameters(\n         (\n-            \"with_negative_shift\",\n-            [[-0.5, -0.1, -0.3, -0.2]],\n+            \"with_large_scale\",\n             [\n                 [\n-                    [6.6750007, 2.0750003, 8.0, 5.0750003],\n-                    [8.0, 6.8250003, 8.0, 9.825],\n+                    [0.0, 0.0],\n+                    [8.151311, 0.0],\n+                    [0.0, 12.695701],\n+                    [9.2712054, 10.524198],\n+                ]\n+            ],\n+            [\n+                [\n+                    [2.6490488, 1.1149256, 5.2026834, 3.6187303],\n+                    [7.5547166, 4.2492595, 8.0, 6.869391],\n                 ]\n             ],\n         ),\n         (\n-            \"with_positive_shift\",\n-            [[0.5, 0.1, 0.3, 0.2]],\n+            \"with_small_scale\",\n             [\n                 [\n-                    [0.29375008, 0.51874995, 2.2937498, 2.5187497],\n-                    [2.1062498, 3.0812497, 4.10625, 5.08125],\n+                    [0.0, 0.0],\n+                    [4.151311, 0.0],\n+                    [0.0, 6.695701],\n+                    [4.2712054, 7.524198],\n+                ]\n+            ],\n+            [\n+                [\n+                    [1.095408, 0.7504317, 2.2761598, 2.3389952],\n+                    [3.5416048, 3.2349987, 4.920989, 5.0568376],\n                 ]\n             ],\n         ),\n     )\n-    def test_random_perspective_bounding_boxes(self, factor, expected_boxes):\n+    def test_random_perspective_bounding_boxes(\n+        self, end_points, expected_boxes\n+    ):\n         data_format = backend.config.image_data_format()\n         if data_format == \"channels_last\":\n             image_shape = (10, 8, 3)\n@@ -120,58 +142,79 @@ class RandomPerspectiveTest(testing.TestCase):\n         input_image = np.random.random(image_shape)\n         bounding_boxes = {\n             \"boxes\": np.array(\n+                [\n                     [\n                         [2, 1, 4, 3],\n                         [6, 4, 8, 6],\n                     ]\n+                ]\n             ),\n             \"labels\": np.array([[1, 2]]),\n         }\n         input_data = {\"images\": input_image, \"bounding_boxes\": bounding_boxes}\n         layer = layers.RandomPerspective(\n-            data_format=data_format,\n+            # data_format=data_format,\n             seed=42,\n             bounding_box_format=\"xyxy\",\n         )\n \n         transformation = {\n-            \"apply_perspective\": np.asarray([True]),\n-            \"perspective_factor\": np.asarray(factor),\n-            \"input_shape\": image_shape,\n+            \"apply_perspective\": np.array([True]),\n+            \"end_points\": np.array(end_points),\n+            \"input_shape\": np.array(image_shape),\n+            \"start_points\": np.array(\n+                [[[0.0, 0.0], [7.0, 0.0], [0.0, 9.0], [7.0, 9.0]]]\n+            ),\n         }\n+\n         output = layer.transform_bounding_boxes(\n             input_data[\"bounding_boxes\"],\n-            transformation=transformation,\n-            training=True,\n+            transformation,\n         )\n \n-        print(output)\n-\n-        self.assertAllClose(output[\"boxes\"], expected_boxes)\n+        self.assertAllClose(\n+            output[\"boxes\"], expected_boxes, atol=1e-3, rtol=1e-3\n+        )\n \n     @parameterized.named_parameters(\n         (\n-            \"with_negative_shift\",\n-            [[-0.5, -0.1, -0.3, -0.2]],\n+            \"with_large_scale\",\n             [\n                 [\n-                    [6.6750007, 2.0750003, 8.0, 5.0750003],\n-                    [8.0, 6.8250003, 8.0, 9.825],\n+                    [0.0, 0.0],\n+                    [8.151311, 0.0],\n+                    [0.0, 12.695701],\n+                    [9.2712054, 10.524198],\n+                ]\n+            ],\n+            [\n+                [\n+                    [2.6490488, 1.1149256, 5.2026834, 3.6187303],\n+                    [7.5547166, 4.2492595, 8.0, 6.869391],\n                 ]\n             ],\n         ),\n         (\n-            \"with_positive_shift\",\n-            [[0.5, 0.1, 0.3, 0.2]],\n+            \"with_small_scale\",\n             [\n                 [\n-                    [0.29375008, 0.51874995, 2.2937498, 2.5187497],\n-                    [2.1062498, 3.0812497, 4.10625, 5.08125],\n+                    [0.0, 0.0],\n+                    [4.151311, 0.0],\n+                    [0.0, 6.695701],\n+                    [4.2712054, 7.524198],\n+                ]\n+            ],\n+            [\n+                [\n+                    [1.095408, 0.7504317, 2.2761598, 2.3389952],\n+                    [3.5416048, 3.2349987, 4.920989, 5.0568376],\n                 ]\n             ],\n         ),\n     )\n-    def test_random_flip_tf_data_bounding_boxes(self, factor, expected_boxes):\n+    def test_random_flip_tf_data_bounding_boxes(\n+        self, end_points, expected_boxes\n+    ):\n         data_format = backend.config.image_data_format()\n         if backend.config.image_data_format() == \"channels_last\":\n             image_shape = (1, 10, 8, 3)\n@@ -180,12 +223,14 @@ class RandomPerspectiveTest(testing.TestCase):\n         input_image = np.random.random(image_shape)\n         bounding_boxes = {\n             \"boxes\": np.array(\n+                [\n                     [\n                         [\n                             [2, 1, 4, 3],\n                             [6, 4, 8, 6],\n                         ]\n                     ]\n+                ]\n             ),\n             \"labels\": np.array([[1, 2]]),\n         }\n@@ -200,9 +245,12 @@ class RandomPerspectiveTest(testing.TestCase):\n         )\n \n         transformation = {\n-            \"apply_perspective\": np.asarray([True]),\n-            \"perspective_factor\": np.asarray(factor),\n-            \"input_shape\": image_shape,\n+            \"apply_perspective\": np.array([True]),\n+            \"end_points\": np.array(end_points),\n+            \"input_shape\": np.array(image_shape),\n+            \"start_points\": np.array(\n+                [[[0.0, 0.0], [7.0, 0.0], [0.0, 9.0], [7.0, 9.0]]]\n+            ),\n         }\n \n         ds = ds.map(\n@@ -215,4 +263,6 @@ class RandomPerspectiveTest(testing.TestCase):\n \n         output = next(iter(ds))\n         expected_boxes = np.array(expected_boxes)\n-        self.assertAllClose(output[\"boxes\"], expected_boxes)\n+        self.assertAllClose(\n+            output[\"boxes\"], expected_boxes, atol=1e-3, rtol=1e-3\n+        )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#996bc9d0d57693dd9db8e4d66dcc47fe157ae41a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 2 | Churn Cumulative: 87 | Contributors (this commit): 7 | Commits (past 90d): 3 | Contributors (cumulative): 7 | DMM Complexity: 0.0\n\nDIFF:\n@@ -25,6 +25,8 @@ def pytest_configure(config):\n \n \n def pytest_collection_modifyitems(config, items):\n+    openvino_skipped_tests = []\n+    if backend() == \"openvino\":\n         with open(\n             \"keras/src/backend/openvino/excluded_concrete_tests.txt\", \"r\"\n         ) as file:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#76703050e9036606f7ba30c50a48e8f8033cc701", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 35 | Contributors (this commit): 4 | Commits (past 90d): 2 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,3 +1,5 @@\n+import os\n+\n import numpy as np\n import pytest\n \n@@ -75,6 +77,7 @@ class MaskingTest(testing.TestCase):\n             ]\n         )\n         model(x)\n-        model.save(\"model.keras\")\n-        reload_model = load_model(\"model.keras\")\n+        temp_filepath = os.path.join(self.get_temp_dir(), \"model.keras\")\n+        model.save(temp_filepath)\n+        reload_model = load_model(temp_filepath)\n         reload_model(x)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#39e39cdcb4aa853eca68a6bfc1ab7aecca093259", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 18 | Churn Cumulative: 176 | Contributors (this commit): 7 | Commits (past 90d): 2 | Contributors (cumulative): 12 | DMM Complexity: 1.0\n\nDIFF:\n@@ -414,7 +414,8 @@ def is_remote_path(filepath):\n     Determines if a given filepath indicates a remote location.\n \n     This function checks if the filepath represents a known remote pattern\n-    such as GCS (`/gcs`), CNS (`/cns`), CFS (`/cfs`), HDFS (`/hdfs`)\n+    such as GCS (`/gcs`), CNS (`/cns`), CFS (`/cfs`), HDFS (`/hdfs`), Placer\n+    (`/placer`), or a URL (`.*://`).\n \n     Args:\n         filepath (str): The path to be checked.\n@@ -422,7 +423,9 @@ def is_remote_path(filepath):\n     Returns:\n         bool: True if the filepath is a recognized remote path, otherwise False\n     \"\"\"\n-    if re.match(r\"^(/cns|/cfs|/gcs|/hdfs|/readahead|.*://).*$\", str(filepath)):\n+    if re.match(\n+        r\"^(/cns|/cfs|/gcs|/hdfs|/readahead|/placer|.*://).*$\", str(filepath)\n+    ):\n         return True\n     return False\n \n\n@@ -715,6 +715,17 @@ class IsRemotePathTest(test_case.TestCase):\n     def test_cns_remote_path(self):\n         self.assertTrue(file_utils.is_remote_path(\"/cns/some/path\"))\n \n+    def test_placer_remote_path(self):\n+        self.assertTrue(\n+            file_utils.is_remote_path(\"/placer/prod/home/some/path\")\n+        )\n+        self.assertTrue(\n+            file_utils.is_remote_path(\"/placer/test/home/some/path\")\n+        )\n+        self.assertTrue(\n+            file_utils.is_remote_path(\"/placer/prod/scratch/home/some/path\")\n+        )\n+\n     def test_cfs_remote_path(self):\n         self.assertTrue(file_utils.is_remote_path(\"/cfs/some/path\"))\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a4b0f642b255e3137b2485d5913983fd5899acd2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 40 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 42 | Churn Cumulative: 1170 | Contributors (this commit): 4 | Commits (past 90d): 7 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -243,10 +243,48 @@ def arctan(x):\n \n \n def arctan2(x1, x2):\n-    raise NotImplementedError(\n-        \"`arctan2` is not supported with openvino backend\"\n+    x1 = get_ov_output(x1)\n+    x2 = get_ov_output(x2)\n+    x1_type = x1.get_element_type()\n+    x2_type = x2.get_element_type()\n+\n+    if x1_type.is_integral():\n+        ov_type = OPENVINO_DTYPES[config.floatx()]\n+        x1 = ov_opset.convert(x1, ov_type)\n+    if x2_type.is_integral():\n+        ov_type = OPENVINO_DTYPES[config.floatx()]\n+        x2 = ov_opset.convert(x2, ov_type)\n+\n+    x = ov_opset.divide(x1, x2)\n+    y = ov_opset.atan(x)\n+\n+    ov_type = x1.get_element_type()\n+    pi = ov_opset.constant(float(np.pi), ov_type)\n+    half_pi = ov_opset.constant(float(np.pi / 2), ov_type)\n+    neg_half_pi = ov_opset.constant(-float(np.pi / 2), ov_type)\n+    zero_const = ov_opset.constant(0.0, ov_type)\n+\n+    cond_x2_gt0 = ov_opset.greater(x2, zero_const).output(0)\n+    cond_x2_lt0 = ov_opset.less(x2, zero_const).output(0)\n+\n+    cond_x1_ge0 = ov_opset.greater_equal(x1, zero_const).output(0)\n+    cond_x1_gt0 = ov_opset.greater(x1, zero_const).output(0)\n+    cond_x1_eq0 = ov_opset.equal(x1, zero_const).output(0)\n+\n+    out_x2_lt0 = ov_opset.select(\n+        cond_x1_ge0,\n+        ov_opset.add(y, pi),\n+        ov_opset.subtract(y, pi),\n     )\n \n+    out_x1_zero = ov_opset.select(cond_x1_eq0, zero_const, neg_half_pi)\n+    out_x2_zero = ov_opset.select(cond_x1_gt0, half_pi, out_x1_zero)\n+\n+    out_not_pos = ov_opset.select(cond_x2_lt0, out_x2_lt0, out_x2_zero)\n+\n+    final_out = ov_opset.select(cond_x2_gt0, y, out_not_pos)\n+    return OpenVINOKerasTensor(final_out.output(0))\n+\n \n def arctanh(x):\n     x = get_ov_output(x)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1eee1133bee114077938e9a390c527b80acdf4c3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 12 | Churn Cumulative: 664 | Contributors (this commit): 8 | Commits (past 90d): 3 | Contributors (cumulative): 8 | DMM Complexity: 0.0\n\nDIFF:\n@@ -215,7 +215,7 @@ class LayerTest(testing.TestCase):\n             mock_remat.assert_called()\n \n     def test_functional_model_with_remat(self):\n-        if backend.backend() in (\"openvino\", \"numpy\") or testing.jax_uses_gpu():\n+        if backend.backend() in (\"openvino\", \"numpy\"):\n             self.skipTest(\n                 \"remat is not supported in openvino and numpy backends.\"\n             )\n@@ -226,11 +226,9 @@ class LayerTest(testing.TestCase):\n             inputs = Input(shape=(32, 32, 3))\n \n             # just one layer in remat scope\n-            with RematScope(mode=\"full\"):\n-                layer = layers.Conv2D(\n-                    64, (3, 3), activation=\"relu\", data_format=\"channels_last\"\n-                )\n-                output = layer(inputs)\n+            with RematScope(mode=\"activations\"):\n+                layer = layers.Dense(64, activation=\"relu\")\n+                output = layer(layers.Flatten()(inputs))\n \n             # Build the functional model\n             model = Model(inputs=inputs, outputs=output)\n@@ -240,7 +238,7 @@ class LayerTest(testing.TestCase):\n \n             # Generate dummy data for testing\n             x_train = np.random.random((10, 32, 32, 3)).astype(np.float32)\n-            y_train = np.random.random((10, 30, 30, 64)).astype(np.float32)\n+            y_train = np.random.random((10, 64)).astype(np.float32)\n \n             # Run training to ensure `RematScope` is applied correctly\n             model.fit(x_train, y_train, epochs=1, batch_size=2)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#12a41b10585f90e9887f3c75e7d73166b4d0d1ef", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 106 | Lines Deleted: 0 | Files Changed: 6 | Hunks: 8 | Methods Changed: 8 | Complexity Δ (Sum/Max): 9/6 | Churn Δ: 106 | Churn Cumulative: 2803 | Contributors (this commit): 21 | Commits (past 90d): 36 | Contributors (cumulative): 67 | DMM Complexity: 1.0\n\nDIFF:\n@@ -87,6 +87,7 @@ from keras.src.ops.nn import moments\n from keras.src.ops.nn import multi_hot\n from keras.src.ops.nn import normalize\n from keras.src.ops.nn import one_hot\n+from keras.src.ops.nn import polar\n from keras.src.ops.nn import psnr\n from keras.src.ops.nn import relu\n from keras.src.ops.nn import relu6\n\n@@ -31,6 +31,7 @@ from keras.src.ops.nn import moments\n from keras.src.ops.nn import multi_hot\n from keras.src.ops.nn import normalize\n from keras.src.ops.nn import one_hot\n+from keras.src.ops.nn import polar\n from keras.src.ops.nn import psnr\n from keras.src.ops.nn import relu\n from keras.src.ops.nn import relu6\n\n@@ -87,6 +87,7 @@ from keras.src.ops.nn import moments\n from keras.src.ops.nn import multi_hot\n from keras.src.ops.nn import normalize\n from keras.src.ops.nn import one_hot\n+from keras.src.ops.nn import polar\n from keras.src.ops.nn import psnr\n from keras.src.ops.nn import relu\n from keras.src.ops.nn import relu6\n\n@@ -31,6 +31,7 @@ from keras.src.ops.nn import moments\n from keras.src.ops.nn import multi_hot\n from keras.src.ops.nn import normalize\n from keras.src.ops.nn import one_hot\n+from keras.src.ops.nn import polar\n from keras.src.ops.nn import psnr\n from keras.src.ops.nn import relu\n from keras.src.ops.nn import relu6\n\n@@ -2651,3 +2651,73 @@ def dot_product_attention(\n         is_causal=is_causal,\n         flash_attention=flash_attention,\n     )\n+\n+\n+class Polar(Operation):\n+    def __init__(self):\n+        super().__init__()\n+\n+    def compute_output_spec(self, abs_, angle):\n+        return KerasTensor(shape=abs_.shape)\n+\n+    def call(self, x):\n+        return _polar(x)\n+\n+\n+@keras_export([\"keras.ops.polar\", \"keras.ops.nn.polar\"])\n+def polar(abs_, angle):\n+    \"\"\"Constructs a complex tensor whose elements are Cartesian\n+    coordinates corresponding to the polar coordinates\n+    with absolute value `abs` and angle `angle`.\n+\n+    The operation is numerically equivalent to `torch.polar()`.\n+    It is not equivalent to `scipy.lingalg.polar()` which performs\n+    Singular Value Decomposition.\n+\n+    Given the magnitude (`abs_`) and angle (`angle`), this function computes the\n+    corresponding complex number in the form of `real + imaginary * 1j`, where:\n+    - `real = abs_ * cos(angle)`\n+    - `imaginary = abs_ * sin(angle)`\n+\n+    Args:\n+        abs_: The magnitude (absolute value) of the complex number.\n+        angle: The angle (in radians) of the complex number.\n+\n+    Returns:\n+        A complex number (or array of complex numbers) with the same shape as\n+        `abs_` and `angle`.\n+\n+    Example:\n+\n+    >>> abs_ = keras.random.normal((1, 2))\n+    >>> angle = keras.random.normal((1, 2))\n+    >>> keras.ops.nn.polar(abs_, angle).shape\n+    (1, 2)\n+    >>> keras.ops.nn.polar(abs_, angle)\n+    Array([[0.63185346-0.59370506j, 0.48960376-0.31677645j]], dtype=complex64)\n+    \"\"\"\n+    if any_symbolic_tensors((abs_, angle)):\n+        return Polar().symbolic_call(abs_, angle)\n+    return _polar(abs_, angle)\n+\n+\n+def _polar(abs_, angle):\n+    \"\"\"Internal implementation of the polar function.\n+\n+    Args:\n+        abs_: The magnitude (absolute value) of the complex number.\n+        angle: The angle (in radians) of the complex number.\n+\n+    Returns:\n+        A complex number (or array of complex numbers) with the same shape as\n+        `abs_` and `angle`.\n+    \"\"\"\n+    abs_ = backend.convert_to_tensor(abs_)\n+    angle = backend.convert_to_tensor(angle)\n+\n+    real = abs_ * backend.numpy.cos(angle)\n+    imaginary = abs_ * backend.numpy.sin(angle)\n+\n+    result = backend.math._get_complex_tensor_from_tuple((real, imaginary))\n+\n+    return result\n\n@@ -1284,6 +1284,12 @@ class NNOpsStaticShapeTest(testing.TestCase):\n         out = knn.dot_product_attention(query, key, value)\n         self.assertEqual(out.shape, query.shape)\n \n+    def test_polar(self):\n+        abs_ = KerasTensor([1, 2])\n+        angle = KerasTensor([3, 4])\n+        out = knn.polar(abs_, angle)\n+        self.assertEqual(out.shape, abs_.shape)\n+\n \n class NNOpsCorrectnessTest(testing.TestCase):\n     def test_relu(self):\n@@ -1510,6 +1516,14 @@ class NNOpsCorrectnessTest(testing.TestCase):\n             )\n             self.assertAllClose(normalized_sum_by_axis, 1.0)\n \n+    def test_polar_corectness(self):\n+        abs_ = np.array([1, 2], dtype=\"float32\")\n+        angle = np.array([2, 3], dtype=\"float32\")\n+        out = knn.polar(abs_, angle)\n+        self.assertAllClose(\n+            out, [-0.41614684 + 0.9092974j, -1.979985 + 0.28224j], atol=1e-3\n+        )\n+\n     def test_sparsemax(self):\n         x = np.array([-0.5, 0, 1, 2, 3], dtype=np.float32)\n         self.assertAllClose(\n@@ -2941,6 +2955,24 @@ class NNOpsDtypeTest(testing.TestCase):\n             expected_dtype,\n         )\n \n+    @parameterized.named_parameters(named_product(dtype=FLOAT_DTYPES))\n+    def test_polar(self, dtype):\n+        import jax.nn as jnn\n+        import jax.numpy as jnp\n+\n+        x = knp.ones((), dtype=dtype)\n+        x_jax = jnp.ones((), dtype=dtype)\n+        expected_dtype = standardize_dtype(jnn.hard_tanh(x_jax).dtype)\n+\n+        self.assertEqual(\n+            standardize_dtype(knn.hard_tanh(x).dtype),\n+            expected_dtype,\n+        )\n+        self.assertEqual(\n+            standardize_dtype(knn.HardTanh().symbolic_call(x).dtype),\n+            expected_dtype,\n+        )\n+\n     @parameterized.named_parameters(named_product(dtype=FLOAT_DTYPES))\n     def test_ctc_loss(self, dtype):\n         labels = knp.array([[1, 2, 1]], dtype=\"int32\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7146c5765f2accd0cbda1582375174f371e9b94e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 29 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 10/10 | Churn Δ: 32 | Churn Cumulative: 1202 | Contributors (this commit): 5 | Commits (past 90d): 8 | Contributors (cumulative): 5 | DMM Complexity: 0.0\n\nDIFF:\n@@ -316,9 +316,35 @@ def array(x, dtype=None):\n \n \n def average(x, axis=None, weights=None):\n-    raise NotImplementedError(\n-        \"`average` is not supported with openvino backend\"\n-    )\n+    x = get_ov_output(x)\n+    if weights is not None:\n+        weights = get_ov_output(weights)\n+    if axis is None:\n+        flatten_shape = ov_opset.constant([-1], Type.i32).output(0)\n+        x = ov_opset.reshape(x, flatten_shape, False).output(0)\n+        if weights is not None:\n+            weights = ov_opset.reshape(weights, flatten_shape, False).output(0)\n+        axis = 0\n+\n+    if weights is not None:\n+        x_type = x.get_element_type()\n+        weights_type = weights.get_element_type()\n+        if (weights_type.is_integral() or weights_type == Type.boolean) and (\n+            x_type.is_integral() or x_type == Type.boolean\n+        ):\n+            x = ov_opset.convert(x, Type.f32).output(0)\n+            weights = ov_opset.convert(weights, Type.f32).output(0)\n+        x, weights = _align_operand_types(x, weights, \"multiply()\")\n+        x = ov_opset.multiply(x, weights)\n+\n+    if isinstance(axis, tuple):\n+        axis = list(axis)\n+    if axis == []:\n+        return OpenVINOKerasTensor(x)\n+\n+    axis_const = ov_opset.constant(axis, dtype=Type.i32).output(0)\n+    mean_ops = ov_opset.reduce_mean(x, axis_const, False)\n+    return OpenVINOKerasTensor(mean_ops.output(0))\n \n \n def bincount(x, weights=None, minlength=0, sparse=False):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c03ae353f0702387bff1d9a899115c1b9daeca37", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 34 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 8 | Methods Changed: 7 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 41 | Churn Cumulative: 1243 | Contributors (this commit): 5 | Commits (past 90d): 9 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -4,6 +4,7 @@ from openvino import Type\n \n from keras.src.backend import config\n from keras.src.backend.common import dtypes\n+from keras.src.backend.common.variables import standardize_dtype\n from keras.src.backend.openvino.core import OPENVINO_DTYPES\n from keras.src.backend.openvino.core import OpenVINOKerasTensor\n from keras.src.backend.openvino.core import (\n@@ -92,7 +93,7 @@ def max(x, axis=None, keepdims=False, initial=None):\n \n \n def ones(shape, dtype=None):\n-    dtype = dtype or config.floatx()\n+    dtype = standardize_dtype(dtype) or config.floatx()\n     ov_type = OPENVINO_DTYPES[dtype]\n     const_one = ov_opset.constant(1, ov_type).output(0)\n     if isinstance(shape, tuple):\n@@ -105,7 +106,7 @@ def ones(shape, dtype=None):\n \n \n def zeros(shape, dtype=None):\n-    dtype = dtype or config.floatx()\n+    dtype = standardize_dtype(dtype) or config.floatx()\n     ov_type = OPENVINO_DTYPES[dtype]\n     const_zero = ov_opset.constant(0, dtype=ov_type).output(0)\n     if isinstance(shape, tuple):\n@@ -194,7 +195,33 @@ def append(x1, x2, axis=None):\n \n \n def arange(start, stop=None, step=None, dtype=None):\n-    raise NotImplementedError(\"`arange` is not supported with openvino backend\")\n+    if stop is None:\n+        start, stop = get_ov_output(0), get_ov_output(start)\n+    else:\n+        start, stop = get_ov_output(start), get_ov_output(stop)\n+\n+    step = get_ov_output(1) if step is None else get_ov_output(step)\n+\n+    ov_type = None\n+    if dtype is not None:\n+        ov_type = OPENVINO_DTYPES[standardize_dtype(dtype)]\n+    else:\n+        ov_type = OPENVINO_DTYPES[\n+            dtypes.result_type(\n+                ov_to_keras_type(start.get_element_type()),\n+                ov_to_keras_type(stop.get_element_type()),\n+                ov_to_keras_type(step.get_element_type()),\n+                \"int32\",\n+            )\n+        ]\n+\n+    start_node = ov_opset.convert(start, ov_type)\n+    stop_node = ov_opset.convert(stop, ov_type)\n+    step_node = ov_opset.convert(step, ov_type)\n+\n+    return OpenVINOKerasTensor(\n+        ov_opset.range(start_node, stop_node, step_node, ov_type).output(0)\n+    )\n \n \n def arccos(x):\n@@ -437,7 +464,7 @@ def cumprod(x, axis=None, dtype=None):\n def cumsum(x, axis=None, dtype=None):\n     x = get_ov_output(x)\n     if dtype is not None:\n-        ov_type = OPENVINO_DTYPES[dtype]\n+        ov_type = OPENVINO_DTYPES[standardize_dtype(dtype)]\n         x = ov_opset.convert(x, ov_type).output(0)\n     if axis is None:\n         flatten_shape = ov_opset.constant([-1], Type.i32).output(0)\n@@ -515,7 +542,7 @@ def floor(x):\n \n \n def full(shape, fill_value, dtype=None):\n-    dtype = dtype or config.floatx()\n+    dtype = standardize_dtype(dtype) or config.floatx()\n     ov_type = OPENVINO_DTYPES[dtype]\n     fill_value = get_ov_output(fill_value, ov_type)\n     if isinstance(shape, tuple):\n@@ -747,7 +774,7 @@ def zeros_like(x, dtype=None):\n     x = get_ov_output(x)\n     shape_x = ov_opset.shape_of(x)\n     if dtype is not None:\n-        ov_type = OPENVINO_DTYPES[dtype]\n+        ov_type = OPENVINO_DTYPES[standardize_dtype(dtype)]\n         const_zero = ov_opset.constant(0, ov_type).output(0)\n     else:\n         const_zero = ov_opset.constant(0, x.get_element_type()).output(0)\n@@ -759,7 +786,7 @@ def ones_like(x, dtype=None):\n     x = get_ov_output(x)\n     shape_x = ov_opset.shape_of(x)\n     if dtype is not None:\n-        ov_type = OPENVINO_DTYPES[dtype]\n+        ov_type = OPENVINO_DTYPES[standardize_dtype(dtype)]\n         const_one = ov_opset.constant(1, ov_type).output(0)\n     else:\n         const_one = ov_opset.constant(1, x.get_element_type()).output(0)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1510e70ee9c9503b30fb039f2cb024a8b7b38356", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 53 | Contributors (this commit): 7 | Commits (past 90d): 2 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -2,6 +2,7 @@ from keras.src import backend\n from keras.src import initializers\n from keras.src import losses\n from keras.src import ops\n+from keras.src import tree\n from keras.src.api_export import keras_export\n from keras.src.metrics.metric import Metric\n from keras.src.saving import serialization_lib\n@@ -199,8 +200,8 @@ class MeanMetricWrapper(Mean):\n             self._direction = \"down\"\n \n     def update_state(self, y_true, y_pred, sample_weight=None):\n-        y_true = backend.cast(y_true, self.dtype)\n-        y_pred = backend.cast(y_pred, self.dtype)\n+        y_true = tree.map_structure(lambda x: ops.cast(x, self.dtype), y_true)\n+        y_pred = tree.map_structure(lambda x: ops.cast(x, self.dtype), y_pred)\n \n         mask = backend.get_keras_mask(y_pred)\n         values = self._fn(y_true, y_pred, **self._fn_kwargs)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#31047f6774a49becf64c5f5be9ffbf997ba11c11", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 18 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 20 | Churn Cumulative: 1205 | Contributors (this commit): 13 | Commits (past 90d): 9 | Contributors (cumulative): 13 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2404,8 +2404,16 @@ def tril(x, k=0):\n         mask = i >= j - k\n         return tf.where(tf.broadcast_to(mask, shape), x, tf.zeros_like(x))\n \n+    if isinstance(k, int):\n+        if k >= 0:\n+            return tf.linalg.band_part(x, -1, k)\n+        return _negative_k_branch()\n+\n+    # when `k` is a tensor\n     return tf.cond(\n-        k >= 0, lambda: tf.linalg.band_part(x, -1, k), _negative_k_branch\n+        tf.greater_equal(k, 0),\n+        lambda: tf.linalg.band_part(x, -1, k),\n+        _negative_k_branch,\n     )\n \n \n@@ -2419,8 +2427,16 @@ def triu(x, k=0):\n         mask = i <= j - k\n         return tf.where(tf.broadcast_to(mask, shape), x, tf.zeros_like(x))\n \n+    if isinstance(k, int):\n+        if k <= 0:\n+            return tf.linalg.band_part(x, -k, -1)\n+        return _positive_k_branch()\n+\n+    # when `k` is a tensor\n     return tf.cond(\n-        k <= 0, lambda: tf.linalg.band_part(x, -k, -1), _positive_k_branch\n+        tf.less_equal(k, 0),\n+        lambda: tf.linalg.band_part(x, -k, -1),\n+        _positive_k_branch,\n     )\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#44dfa9f4a456917a9b5af654b16220781ca2754c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 7 | Files Changed: 2 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 182 | Contributors (this commit): 9 | Commits (past 90d): 4 | Contributors (cumulative): 12 | DMM Complexity: 0.0\n\nDIFF:\n@@ -62,10 +62,10 @@ class Accuracy(reduction_metrics.MeanMetricWrapper):\n @keras_export(\"keras.metrics.binary_accuracy\")\n def binary_accuracy(y_true, y_pred, threshold=0.5):\n     y_pred = ops.convert_to_tensor(y_pred)\n-    y_true = ops.convert_to_tensor(y_true, dtype=y_pred.dtype)\n+    y_true = ops.convert_to_tensor(y_true)\n+    threshold = ops.convert_to_tensor(threshold)\n     y_true, y_pred = squeeze_or_expand_to_same_rank(y_true, y_pred)\n-    threshold = ops.cast(threshold, y_pred.dtype)\n-    y_pred = ops.cast(y_pred > threshold, y_true.dtype)\n+    y_pred = ops.cast(ops.greater(y_pred, threshold), y_true.dtype)\n     return ops.cast(ops.equal(y_true, y_pred), dtype=backend.floatx())\n \n \n\n@@ -2,7 +2,6 @@ from keras.src import backend\n from keras.src import initializers\n from keras.src import losses\n from keras.src import ops\n-from keras.src import tree\n from keras.src.api_export import keras_export\n from keras.src.metrics.metric import Metric\n from keras.src.saving import serialization_lib\n@@ -200,9 +199,6 @@ class MeanMetricWrapper(Mean):\n             self._direction = \"down\"\n \n     def update_state(self, y_true, y_pred, sample_weight=None):\n-        y_true = tree.map_structure(lambda x: ops.cast(x, self.dtype), y_true)\n-        y_pred = tree.map_structure(lambda x: ops.cast(x, self.dtype), y_pred)\n-\n         mask = backend.get_keras_mask(y_pred)\n         values = self._fn(y_true, y_pred, **self._fn_kwargs)\n         if sample_weight is not None and mask is not None:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#419764581adaddf828837f545a8d7d5886316650", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 568 | Lines Deleted: 0 | Files Changed: 8 | Hunks: 12 | Methods Changed: 26 | Complexity Δ (Sum/Max): 61/16 | Churn Δ: 568 | Churn Cumulative: 6670 | Contributors (this commit): 13 | Commits (past 90d): 25 | Contributors (cumulative): 47 | DMM Complexity: 0.5583333333333333\n\nDIFF:\n@@ -7,6 +7,7 @@ since your modifications would be overwritten.\n from keras.src.ops.image import affine_transform\n from keras.src.ops.image import crop_images\n from keras.src.ops.image import extract_patches\n+from keras.src.ops.image import gaussian_blur\n from keras.src.ops.image import hsv_to_rgb\n from keras.src.ops.image import map_coordinates\n from keras.src.ops.image import pad_images\n\n@@ -7,6 +7,7 @@ since your modifications would be overwritten.\n from keras.src.ops.image import affine_transform\n from keras.src.ops.image import crop_images\n from keras.src.ops.image import extract_patches\n+from keras.src.ops.image import gaussian_blur\n from keras.src.ops.image import hsv_to_rgb\n from keras.src.ops.image import map_coordinates\n from keras.src.ops.image import pad_images\n\n@@ -668,3 +668,65 @@ def map_coordinates(\n     return jax.scipy.ndimage.map_coordinates(\n         inputs, coordinates, order, fill_mode, fill_value\n     )\n+\n+\n+def gaussian_blur(\n+    images, kernel_size=(3, 3), sigma=(1.0, 1.0), data_format=None\n+):\n+    def _create_gaussian_kernel(kernel_size, sigma, dtype):\n+        def _get_gaussian_kernel1d(size, sigma):\n+            x = jnp.arange(size, dtype=dtype) - (size - 1) / 2\n+            kernel1d = jnp.exp(-0.5 * (x / sigma) ** 2)\n+            return kernel1d / jnp.sum(kernel1d)\n+\n+        def _get_gaussian_kernel2d(size, sigma):\n+            size = size.astype(dtype)\n+            kernel1d_x = _get_gaussian_kernel1d(size[0], sigma[0])\n+            kernel1d_y = _get_gaussian_kernel1d(size[1], sigma[1])\n+            return jnp.outer(kernel1d_y, kernel1d_x)\n+\n+        kernel = _get_gaussian_kernel2d(kernel_size, sigma)\n+        kernel = kernel[jnp.newaxis, jnp.newaxis, :, :]\n+        return kernel\n+\n+    images = convert_to_tensor(images)\n+    kernel_size = convert_to_tensor(kernel_size)\n+    sigma = convert_to_tensor(sigma)\n+    dtype = images.dtype\n+\n+    if len(images.shape) not in (3, 4):\n+        raise ValueError(\n+            \"Invalid images rank: expected rank 3 (single image) \"\n+            \"or rank 4 (batch of images). Received input with shape: \"\n+            f\"images.shape={images.shape}\"\n+        )\n+\n+    need_squeeze = False\n+    if images.ndim == 3:\n+        images = images[jnp.newaxis, ...]\n+        need_squeeze = True\n+\n+    if data_format == \"channels_last\":\n+        images = jnp.transpose(images, (0, 3, 1, 2))\n+\n+    num_channels = images.shape[1]\n+    kernel = _create_gaussian_kernel(kernel_size, sigma, dtype)\n+\n+    kernel = jnp.tile(kernel, (num_channels, 1, 1, 1))\n+\n+    blurred_images = jax.lax.conv_general_dilated(\n+        images,\n+        kernel,\n+        window_strides=(1, 1),\n+        padding=\"SAME\",\n+        dimension_numbers=(\"NCHW\", \"OIHW\", \"NCHW\"),\n+        feature_group_count=num_channels,\n+    )\n+\n+    if data_format == \"channels_last\":\n+        blurred_images = jnp.transpose(blurred_images, (0, 2, 3, 1))\n+\n+    if need_squeeze:\n+        blurred_images = blurred_images.squeeze(axis=0)\n+\n+    return blurred_images\n\n@@ -808,3 +808,83 @@ def map_coordinates(\n         padded, shifted_coords, order=order, mode=fill_mode, cval=fill_value\n     )\n     return result\n+\n+\n+def gaussian_blur(\n+    images, kernel_size=(3, 3), sigma=(1.0, 1.0), data_format=None\n+):\n+    def _create_gaussian_kernel(kernel_size, sigma, num_channels, dtype):\n+        def _get_gaussian_kernel1d(size, sigma):\n+            x = np.arange(size, dtype=dtype) - (size - 1) / 2\n+            kernel1d = np.exp(-0.5 * (x / sigma) ** 2)\n+            return kernel1d / np.sum(kernel1d)\n+\n+        def _get_gaussian_kernel2d(size, sigma):\n+            size = np.asarray(size, dtype)\n+            kernel1d_x = _get_gaussian_kernel1d(size[0], sigma[0])\n+            kernel1d_y = _get_gaussian_kernel1d(size[1], sigma[1])\n+            return np.outer(kernel1d_y, kernel1d_x)\n+\n+        kernel = _get_gaussian_kernel2d(kernel_size, sigma)\n+        kernel = kernel[:, :, np.newaxis]\n+        kernel = np.tile(kernel, (1, 1, num_channels))\n+        return kernel.astype(dtype)\n+\n+    images = convert_to_tensor(images)\n+    kernel_size = convert_to_tensor(kernel_size)\n+    sigma = convert_to_tensor(sigma)\n+    input_dtype = images.dtype\n+\n+    if len(images.shape) not in (3, 4):\n+        raise ValueError(\n+            \"Invalid images rank: expected rank 3 (single image) \"\n+            \"or rank 4 (batch of images). Received input with shape: \"\n+            f\"images.shape={images.shape}\"\n+        )\n+\n+    need_squeeze = False\n+    if len(images.shape) == 3:\n+        images = np.expand_dims(images, axis=0)\n+        need_squeeze = True\n+\n+    if data_format == \"channels_first\":\n+        images = np.transpose(images, (0, 2, 3, 1))\n+\n+    num_channels = images.shape[-1]\n+    kernel = _create_gaussian_kernel(\n+        kernel_size, sigma, num_channels, input_dtype\n+    )\n+    batch_size, height, width, _ = images.shape\n+    padded_images = np.pad(\n+        images,\n+        (\n+            (0, 0),\n+            (kernel_size[0] // 2, kernel_size[0] // 2),\n+            (kernel_size[1] // 2, kernel_size[1] // 2),\n+            (0, 0),\n+        ),\n+        mode=\"constant\",\n+    )\n+\n+    blurred_images = np.zeros_like(images)\n+    kernel_reshaped = kernel.reshape(\n+        (1, kernel.shape[0], kernel.shape[1], num_channels)\n+    )\n+\n+    for b in range(batch_size):\n+        image_patch = padded_images[b : b + 1, :, :, :]\n+        for i in range(height):\n+            for j in range(width):\n+                patch = image_patch[\n+                    :, i : i + kernel_size[0], j : j + kernel_size[1], :\n+                ]\n+                blurred_images[b, i, j, :] = np.sum(\n+                    patch * kernel_reshaped, axis=(1, 2)\n+                )\n+\n+    if data_format == \"channels_first\":\n+        blurred_images = np.transpose(blurred_images, (0, 3, 1, 2))\n+    if need_squeeze:\n+        blurred_images = np.squeeze(blurred_images, axis=0)\n+\n+    return blurred_images\n\n@@ -720,3 +720,59 @@ def map_coordinates(\n     if input_arr.dtype.is_integer:\n         result = tf.round(result)\n     return tf.cast(result, input_arr.dtype)\n+\n+\n+def gaussian_blur(\n+    images, kernel_size=(3, 3), sigma=(1.0, 1.0), data_format=None\n+):\n+    def _create_gaussian_kernel(kernel_size, sigma, num_channels, dtype):\n+        def _get_gaussian_kernel1d(size, sigma):\n+            x = tf.range(size, dtype=dtype) - (size - 1) / 2\n+            kernel1d = tf.exp(-0.5 * (x / sigma) ** 2)\n+            return kernel1d / tf.reduce_sum(kernel1d)\n+\n+        def _get_gaussian_kernel2d(size, sigma):\n+            size = tf.cast(size, dtype)\n+            kernel1d_x = _get_gaussian_kernel1d(size[0], sigma[0])\n+            kernel1d_y = _get_gaussian_kernel1d(size[1], sigma[1])\n+            return tf.tensordot(kernel1d_y, kernel1d_x, axes=0)\n+\n+        kernel = _get_gaussian_kernel2d(kernel_size, sigma)\n+        kernel = tf.reshape(kernel, (kernel_size[0], kernel_size[1], 1, 1))\n+        kernel = tf.tile(kernel, [1, 1, num_channels, 1])\n+        kernel = tf.cast(kernel, dtype)\n+        return kernel\n+\n+    images = convert_to_tensor(images)\n+    kernel_size = convert_to_tensor(kernel_size)\n+    sigma = convert_to_tensor(sigma)\n+    dtype = images.dtype\n+\n+    if len(images.shape) not in (3, 4):\n+        raise ValueError(\n+            \"Invalid images rank: expected rank 3 (single image) \"\n+            \"or rank 4 (batch of images). Received input with shape: \"\n+            f\"images.shape={images.shape}\"\n+        )\n+\n+    need_squeeze = False\n+    if len(images.shape) == 3:\n+        images = tf.expand_dims(images, axis=0)\n+        need_squeeze = True\n+\n+    if data_format == \"channels_first\":\n+        images = tf.transpose(images, (0, 2, 3, 1))\n+\n+    num_channels = tf.shape(images)[-1]\n+    kernel = _create_gaussian_kernel(kernel_size, sigma, num_channels, dtype)\n+\n+    blurred_images = tf.nn.depthwise_conv2d(\n+        images, kernel, strides=[1, 1, 1, 1], padding=\"SAME\"\n+    )\n+\n+    if data_format == \"channels_first\":\n+        blurred_images = tf.transpose(blurred_images, (0, 3, 1, 2))\n+    if need_squeeze:\n+        blurred_images = tf.squeeze(blurred_images, axis=0)\n+\n+    return blurred_images\n\n@@ -818,3 +818,70 @@ def map_coordinates(\n     if _is_integer(input_arr):\n         result = result if _is_integer(result) else torch.round(result)\n     return result.to(input_arr.dtype)\n+\n+\n+def gaussian_blur(\n+    images, kernel_size=(3, 3), sigma=(1.0, 1.0), data_format=None\n+):\n+    def _create_gaussian_kernel(kernel_size, sigma, dtype):\n+        def _get_gaussian_kernel1d(size, sigma):\n+            x = (\n+                torch.arange(size, dtype=dtype, device=sigma.device)\n+                - (size - 1) / 2\n+            )\n+            kernel1d = torch.exp(-0.5 * (x / sigma) ** 2)\n+            return kernel1d / torch.sum(kernel1d)\n+\n+        def _get_gaussian_kernel2d(size, sigma):\n+            size = torch.tensor(size, dtype=dtype)\n+            kernel1d_x = _get_gaussian_kernel1d(size[0], sigma[0])\n+            kernel1d_y = _get_gaussian_kernel1d(size[1], sigma[1])\n+            return torch.outer(kernel1d_y, kernel1d_x)\n+\n+        kernel = _get_gaussian_kernel2d(kernel_size, sigma)\n+\n+        kernel = kernel.view(1, 1, kernel_size[0], kernel_size[1])\n+        return kernel\n+\n+    images = convert_to_tensor(images)\n+    kernel_size = convert_to_tensor(kernel_size)\n+    sigma = convert_to_tensor(sigma)\n+    dtype = images.dtype\n+\n+    if len(images.shape) not in (3, 4):\n+        raise ValueError(\n+            \"Invalid images rank: expected rank 3 (single image) \"\n+            \"or rank 4 (batch of images). Received input with shape: \"\n+            f\"images.shape={images.shape}\"\n+        )\n+\n+    need_squeeze = False\n+    if images.ndim == 3:\n+        images = images.unsqueeze(dim=0)\n+        need_squeeze = True\n+\n+    if data_format == \"channels_last\":\n+        images = images.permute(0, 3, 1, 2)\n+\n+    num_channels = images.shape[1]\n+    kernel = _create_gaussian_kernel(kernel_size, sigma, dtype)\n+\n+    kernel = kernel.expand(num_channels, 1, kernel_size[0], kernel_size[1])\n+\n+    print(kernel_size[0] // 2)\n+\n+    blurred_images = torch.nn.functional.conv2d(\n+        images,\n+        kernel,\n+        stride=1,\n+        padding=int(kernel_size[0] // 2),\n+        groups=num_channels,\n+    )\n+\n+    if data_format == \"channels_last\":\n+        blurred_images = blurred_images.permute(0, 2, 3, 1)\n+\n+    if need_squeeze:\n+        blurred_images = blurred_images.squeeze(dim=0)\n+\n+    return blurred_images\n\n@@ -1373,3 +1373,88 @@ def perspective_transform(\n         fill_value=fill_value,\n         data_format=data_format,\n     )\n+\n+\n+class GaussianBlur(Operation):\n+    def __init__(\n+        self,\n+        kernel_size=(3, 3),\n+        sigma=(1.0, 1.0),\n+        data_format=None,\n+    ):\n+        super().__init__()\n+        self.kernel_size = kernel_size\n+        self.sigma = sigma\n+        self.data_format = backend.standardize_data_format(data_format)\n+\n+    def call(self, images):\n+        return backend.image.gaussian_blur(\n+            images,\n+            kernel_size=self.kernel_size,\n+            sigma=self.sigma,\n+            data_format=self.data_format,\n+        )\n+\n+    def compute_output_spec(self, images):\n+        if len(images.shape) not in (3, 4):\n+            raise ValueError(\n+                \"Invalid images rank: expected rank 3 (single image) \"\n+                \"or rank 4 (batch of images). Received input with shape: \"\n+                f\"images.shape={images.shape}\"\n+            )\n+        return KerasTensor(images.shape, dtype=images.dtype)\n+\n+\n+@keras_export(\"keras.ops.image.gaussian_blur\")\n+def gaussian_blur(\n+    images, kernel_size=(3, 3), sigma=(1.0, 1.0), data_format=None\n+):\n+    \"\"\"Applies a Gaussian blur to the image(s).\n+\n+    Args:\n+        images: Input image or batch of images. Must be 3D or 4D.\n+        kernel_size: A tuple of two integers, specifying the height and width\n+            of the Gaussian kernel.\n+        sigma: A tuple of two floats, specifying the standard deviation of\n+            the Gaussian kernel along height and width.\n+        data_format: A string specifying the data format of the input tensor.\n+            It can be either `\"channels_last\"` or `\"channels_first\"`.\n+            `\"channels_last\"` corresponds to inputs with shape\n+            `(batch, height, width, channels)`, while `\"channels_first\"`\n+            corresponds to inputs with shape `(batch, channels, height, width)`.\n+            If not specified, the value will default to\n+            `keras.config.image_data_format`.\n+\n+    Returns:\n+        Blurred image or batch of images.\n+\n+    Examples:\n+\n+    >>> x = np.random.random((2, 64, 80, 3))  # batch of 2 RGB images\n+    >>> y = keras.ops.image.gaussian_blur(x)\n+    >>> y.shape\n+    (2, 64, 80, 3)\n+\n+    >>> x = np.random.random((64, 80, 3))  # single RGB image\n+    >>> y = keras.ops.image.gaussian_blur(x)\n+    >>> y.shape\n+    (64, 80, 3)\n+\n+    >>> x = np.random.random((2, 3, 64, 80))  # batch of 2 RGB images\n+    >>> y = keras.ops.image.gaussian_blur(\n+    ...     x, data_format=\"channels_first\")\n+    >>> y.shape\n+    (2, 3, 64, 80)\n+    \"\"\"\n+    if any_symbolic_tensors((images,)):\n+        return GaussianBlur(\n+            kernel_size=kernel_size,\n+            sigma=sigma,\n+            data_format=data_format,\n+        ).symbolic_call(images)\n+    return backend.image.gaussian_blur(\n+        images,\n+        kernel_size=kernel_size,\n+        sigma=sigma,\n+        data_format=data_format,\n+    )\n\n@@ -179,6 +179,18 @@ class ImageOpsDynamicShapeTest(testing.TestCase):\n         out = kimage.perspective_transform(x, start_points, end_points)\n         self.assertEqual(out.shape, (None, 3, 20, 20))\n \n+    def test_gaussian_blur(self):\n+        # Test channels_last\n+        x = KerasTensor([None, 20, 20, 3])\n+        out = kimage.gaussian_blur(x)\n+        self.assertEqual(out.shape, (None, 20, 20, 3))\n+\n+        # Test channels_first\n+        backend.set_image_data_format(\"channels_first\")\n+        x = KerasTensor([None, 3, 20, 20])\n+        out = kimage.gaussian_blur(x)\n+        self.assertEqual(out.shape, (None, 3, 20, 20))\n+\n \n class ImageOpsStaticShapeTest(testing.TestCase):\n     def setUp(self):\n@@ -394,6 +406,38 @@ class ImageOpsStaticShapeTest(testing.TestCase):\n         out = kimage.perspective_transform(x, start_points, end_points)\n         self.assertEqual(out.shape, (3, 20, 20))\n \n+    def test_gaussian_blur(self):\n+        # Test channels_last\n+        x = KerasTensor([20, 20, 3])\n+        kernel_size = KerasTensor(\n+            [\n+                2,\n+            ]\n+        )\n+        sigma = KerasTensor(\n+            [\n+                2,\n+            ]\n+        )\n+        out = kimage.gaussian_blur(x, kernel_size, sigma)\n+        self.assertEqual(out.shape, (20, 20, 3))\n+\n+        # Test channels_first\n+        backend.set_image_data_format(\"channels_first\")\n+        x = KerasTensor([3, 20, 20])\n+        kernel_size = KerasTensor(\n+            [\n+                2,\n+            ]\n+        )\n+        sigma = KerasTensor(\n+            [\n+                2,\n+            ]\n+        )\n+        out = kimage.gaussian_blur(x, kernel_size, sigma)\n+        self.assertEqual(out.shape, (3, 20, 20))\n+\n \n AFFINE_TRANSFORM_INTERPOLATIONS = {  # map to order\n     \"nearest\": 0,\n@@ -544,6 +588,88 @@ def _perspective_transform_numpy(\n     return output\n \n \n+def gaussian_blur_np(\n+    images,\n+    kernel_size,\n+    sigma,\n+    data_format=None,\n+):\n+    def _create_gaussian_kernel(kernel_size, sigma, num_channels, dtype):\n+        def _get_gaussian_kernel1d(size, sigma):\n+            x = np.arange(size, dtype=dtype) - (size - 1) / 2\n+            kernel1d = np.exp(-0.5 * (x / sigma) ** 2)\n+            return kernel1d / np.sum(kernel1d)\n+\n+        def _get_gaussian_kernel2d(size, sigma):\n+            kernel1d_x = _get_gaussian_kernel1d(size[0], sigma[0])\n+            kernel1d_y = _get_gaussian_kernel1d(size[1], sigma[1])\n+            return np.outer(kernel1d_y, kernel1d_x)\n+\n+        kernel = _get_gaussian_kernel2d(kernel_size, sigma)\n+        kernel = kernel[:, :, np.newaxis]\n+        kernel = np.tile(kernel, (1, 1, num_channels))\n+        return kernel.astype(dtype)\n+\n+    images = np.asarray(images)\n+    input_dtype = images.dtype\n+    kernel_size = np.asarray(kernel_size)\n+\n+    if len(images.shape) not in (3, 4):\n+        raise ValueError(\n+            \"Invalid images rank: expected rank 3 (single image) \"\n+            \"or rank 4 (batch of images). Received input with shape: \"\n+            f\"images.shape={images.shape}\"\n+        )\n+\n+    need_squeeze = False\n+    if len(images.shape) == 3:\n+        images = np.expand_dims(images, axis=0)\n+        need_squeeze = True\n+\n+    if data_format == \"channels_first\":\n+        images = np.transpose(images, (0, 2, 3, 1))\n+\n+    num_channels = images.shape[-1]\n+    kernel = _create_gaussian_kernel(\n+        kernel_size, sigma, num_channels, input_dtype\n+    )\n+    batch_size, height, width, _ = images.shape\n+    padded_images = np.pad(\n+        images,\n+        (\n+            (0, 0),\n+            (kernel_size[0] // 2, kernel_size[0] // 2),\n+            (kernel_size[1] // 2, kernel_size[1] // 2),\n+            (0, 0),\n+        ),\n+        mode=\"constant\",\n+    )\n+\n+    blurred_images = np.zeros_like(images)\n+    kernel_reshaped = kernel.reshape(\n+        (1, kernel.shape[0], kernel.shape[1], num_channels)\n+    )\n+\n+    for b in range(batch_size):\n+        image_patch = padded_images[b : b + 1, :, :, :]\n+\n+    for i in range(height):\n+        for j in range(width):\n+            patch = image_patch[\n+                :, i : i + kernel_size[0], j : j + kernel_size[1], :\n+            ]\n+            blurred_images[b, i, j, :] = np.sum(\n+                patch * kernel_reshaped, axis=(1, 2)\n+            )\n+\n+    if data_format == \"channels_first\":\n+        blurred_images = np.transpose(blurred_images, (0, 3, 1, 2))\n+    if need_squeeze:\n+        blurred_images = np.squeeze(blurred_images, axis=0)\n+\n+    return blurred_images\n+\n+\n def _compute_homography_matrix(start_points, end_points):\n     start_x1, start_y1 = start_points[:, 0, 0], start_points[:, 0, 1]\n     start_x2, start_y2 = start_points[:, 1, 0], start_points[:, 1, 1]\n@@ -1502,6 +1628,54 @@ class ImageOpsCorrectnessTest(testing.TestCase):\n         self.assertEqual(tuple(out.shape), tuple(ref_out.shape))\n         self.assertAllClose(ref_out, out, atol=1e-2, rtol=1e-2)\n \n+    def test_gaussian_blur(self):\n+        # Test channels_last\n+        backend.set_image_data_format(\"channels_last\")\n+        np.random.seed(42)\n+        x = np.random.uniform(size=(50, 50, 3)).astype(\"float32\")\n+        kernel_size = np.array([3, 3])\n+        sigma = np.random.uniform(size=(2,)).astype(\"float32\")\n+\n+        out = kimage.gaussian_blur(\n+            x,\n+            kernel_size,\n+            sigma,\n+            data_format=\"channels_last\",\n+        )\n+\n+        ref_out = gaussian_blur_np(\n+            x,\n+            kernel_size,\n+            sigma,\n+            data_format=\"channels_last\",\n+        )\n+\n+        self.assertEqual(tuple(out.shape), tuple(ref_out.shape))\n+        self.assertAllClose(ref_out, out, atol=1e-2, rtol=1e-2)\n+\n+        # Test channels_first\n+        backend.set_image_data_format(\"channels_first\")\n+        x = np.random.uniform(size=(3, 50, 50)).astype(\"float32\")\n+        kernel_size = np.array([3, 3])\n+        sigma = np.random.uniform(size=(2,)).astype(\"float32\")\n+\n+        out = kimage.gaussian_blur(\n+            x,\n+            kernel_size,\n+            sigma,\n+            data_format=\"channels_first\",\n+        )\n+\n+        ref_out = gaussian_blur_np(\n+            x,\n+            kernel_size,\n+            sigma,\n+            data_format=\"channels_first\",\n+        )\n+\n+        self.assertEqual(tuple(out.shape), tuple(ref_out.shape))\n+        self.assertAllClose(ref_out, out, atol=1e-2, rtol=1e-2)\n+\n \n class ImageOpsBehaviorTests(testing.TestCase):\n     def setUp(self):\n@@ -1815,3 +1989,45 @@ class ImageOpsBehaviorTests(testing.TestCase):\n             ValueError, \"Invalid start_points shape: expected\"\n         ):\n             kimage.perspective_transform(images, start_points, end_points)\n+\n+    def test_gaussian_blur_invalid_images_rank(self):\n+        # Test rank=2\n+        invalid_image = np.random.uniform(size=(10, 10))\n+        kernel_size = (3, 3)\n+        sigma = (0.1, 0.1)\n+        with self.assertRaisesRegex(\n+            ValueError, \"Invalid images rank: expected rank 3\"\n+        ):\n+            kimage.gaussian_blur(\n+                invalid_image, kernel_size=kernel_size, sigma=sigma\n+            )\n+        with self.assertRaisesRegex(\n+            ValueError, \"Invalid images rank: expected rank 3\"\n+        ):\n+            kimage.GaussianBlur(kernel_size=kernel_size, sigma=sigma)(\n+                invalid_image\n+            )\n+\n+        # Test rank=5\n+        invalid_image = np.random.uniform(size=(2, 10, 10, 3, 1))\n+        with self.assertRaisesRegex(\n+            ValueError, \"Invalid images rank: expected rank 3\"\n+        ):\n+            kimage.gaussian_blur(\n+                invalid_image, kernel_size=kernel_size, sigma=sigma\n+            )\n+        with self.assertRaisesRegex(\n+            ValueError, \"Invalid images rank: expected rank 3\"\n+        ):\n+            kimage.GaussianBlur(kernel_size=kernel_size, sigma=sigma)(\n+                invalid_image\n+            )\n+\n+        # Test rank=2, symbolic tensor\n+        invalid_image = KerasTensor(shape=(10, 10))\n+        with self.assertRaisesRegex(\n+            ValueError, \"Invalid images rank: expected rank 3\"\n+        ):\n+            kimage.gaussian_blur(\n+                invalid_image, kernel_size=kernel_size, sigma=sigma\n+            )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
