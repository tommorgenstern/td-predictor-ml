{"custom_id": "keras#a689e6ee16dd2e3fe4a516602b4f3f943ee8547f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 53/53 | Churn Δ: 5 | Churn Cumulative: 1719 | Contributors (this commit): 9 | Commits (past 90d): 5 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -405,8 +405,9 @@ class PolynomialDecay(LearningRateSchedule):\n           end_learning_rate: A scalar `float32` or `float64` `Tensor` or a\n             Python number.  The minimal end learning rate.\n           power: A scalar `float32` or `float64` `Tensor` or a\n-            Python number. The power of the polynomial. Defaults to linear, 1.0.\n-          cycle: A boolean, whether or not it should cycle beyond decay_steps.\n+            Python number. The power of the polynomial. Linear default.\n+            Defaults to `1.0`.\n+          cycle: A boolean, whether it should cycle beyond decay_steps.\n           name: String.  Optional name of the operation. Defaults to\n             'PolynomialDecay'.\n         \"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d7486bf76eb62131498a5a981b87d072983f16c2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 9 | Files Changed: 2 | Hunks: 6 | Methods Changed: 2 | Complexity Δ (Sum/Max): 346/270 | Churn Δ: 18 | Churn Cumulative: 18189 | Contributors (this commit): 84 | Commits (past 90d): 4 | Contributors (cumulative): 97 | DMM Complexity: None\n\nDIFF:\n@@ -1225,9 +1225,9 @@ class ImageDataGenerator:\n           `fill_mode = \"constant\"`.\n         horizontal_flip: Boolean. Randomly flip inputs horizontally.\n         vertical_flip: Boolean. Randomly flip inputs vertically.\n-        rescale: rescaling factor. Defaults to None. If None or 0, no rescaling\n+        rescale: rescaling factor. If None or 0, no rescaling\n           is applied, otherwise we multiply the data by the value provided\n-          (after applying all other transformations).\n+          (after applying all other transformations). Defaults to `None`.\n         preprocessing_function: function that will be applied on each input. The\n           function will run after the image is resized and augmented.\n             The function should take one argument: one image (Numpy tensor with\n@@ -1236,9 +1236,9 @@ class ImageDataGenerator:\n           \"channels_last\". \"channels_last\" mode means that the images should\n           have shape `(samples, height, width, channels)`, \"channels_first\" mode\n           means that the images should have shape `(samples, channels, height,\n-          width)`.  It defaults to the `image_data_format` value found in your\n-          Keras config file at `~/.keras/keras.json`. If you never set it, then\n-          it will be \"channels_last\".\n+          width)`. When unspecified, uses `image_data_format` value found in\n+          your Keras config file at `~/.keras/keras.json` (if exists) else\n+          'channels_last'. Defaults to \"channels_last\".\n         validation_split: Float. Fraction of images reserved for validation\n           (strictly between 0 and 1).\n         dtype: Dtype to use for the generated arrays.\n@@ -1586,8 +1586,8 @@ class ImageDataGenerator:\n               in the generator. See [this script](\n               https://gist.github.com/fchollet/0830affa1f7f19fd47b06d4cf89ed44d)\n               for more details.\n-            target_size: Tuple of integers `(height, width)`, defaults to `(256,\n-              256)`. The dimensions to which all images found will be resized.\n+            target_size: Tuple of integers `(height, width)`. The dimensions to\n+             which all images found will be resized. Defaults to `(256,256)`.\n             color_mode: One of \"grayscale\", \"rgb\", \"rgba\". Default: \"rgb\".\n               Whether the images will be converted to have 1, 3, or 4 channels.\n             classes: Optional list of class subdirectories (e.g. `['dogs',\n\n@@ -154,11 +154,11 @@ def hashing_trick(\n     Args:\n         text: Input text (string).\n         n: Dimension of the hashing space.\n-        hash_function: defaults to python `hash` function, can be 'md5' or\n+        hash_function: when None uses a python `hash` function, can be 'md5' or\n             any function that takes in input a string and returns a int.\n             Note that 'hash' is not a stable hashing function, so\n             it is not consistent across different runs, while 'md5'\n-            is a stable hashing function.\n+            is a stable hashing function. Defaults to `None`.\n         filters: list (or concatenation) of characters to filter out, such as\n             punctuation. Default: ``!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\\\t\\\\n``,\n             includes basic punctuation, tabs, and newlines.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1e5557396fb08f8635912e102d61c0875134c196", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 61/47 | Churn Δ: 10 | Churn Cumulative: 445 | Contributors (this commit): 5 | Commits (past 90d): 6 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -95,8 +95,8 @@ def _decode_helper(\n \n     Args:\n       obj: A decoded dictionary that may represent an object.\n-      deserialize: Boolean, defaults to False. When True, deserializes any Keras\n-        objects found in `obj`.\n+      deserialize: Boolean. When True, deserializes any Keras\n+        objects found in `obj`. Defaults to `False`.\n       module_objects: A dictionary of built-in objects to look the name up in.\n         Generally, `module_objects` is provided by midlevel library\n         implementers.\n\n@@ -64,9 +64,9 @@ def save(\n       save_traces: (only applies to SavedModel format) When enabled, the\n         SavedModel will store the function traces for each layer. This\n         can be disabled, so that only the configs of each layer are stored.\n-        Defaults to `True`. Disabling this will decrease serialization time\n-        and reduce file size, but it requires that all custom layers/models\n-        implement a `get_config()` method.\n+        Disabling this will decrease serialization time and filesize, but\n+        it requires that all custom layers/models implement a\n+        `get_config()` method. Defaults to `True`.\n \n     Raises:\n       ValueError: if the model's inputs have not been defined.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5c24834eeff0582290f38ef4d18bb5069ae3f1f3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 9 | Files Changed: 2 | Hunks: 6 | Methods Changed: 4 | Complexity Δ (Sum/Max): 242/181 | Churn Δ: 20 | Churn Cumulative: 2714 | Contributors (this commit): 10 | Commits (past 90d): 4 | Contributors (cumulative): 18 | DMM Complexity: None\n\nDIFF:\n@@ -112,7 +112,7 @@ def run_with_all_saved_model_formats(test_or_class=None, exclude_formats=None):\n         test or class.\n       exclude_formats: A collection of Keras saved model formats to not run.\n         (May also be a single format not wrapped in a collection).\n-        Defaults to None.\n+        Defaults to `None`.\n \n     Returns:\n       Returns a decorator that will run the decorated test method multiple\n@@ -258,7 +258,7 @@ def run_with_all_model_types(test_or_class=None, exclude_models=None):\n         test or class.\n       exclude_models: A collection of Keras model types to not run.\n         (May also be a single model type not wrapped in a collection).\n-        Defaults to None.\n+        Defaults to `None`.\n \n     Returns:\n       Returns a decorator that will run the decorated test method multiple\n@@ -497,12 +497,13 @@ def keras_mode_combinations(mode=None, run_eagerly=None):\n \n     Args:\n       mode: List of modes to run the tests. The valid options are 'graph' and\n-        'eager'. Default to ['graph', 'eager'] if not specified. If a empty list\n-        is provide, then the test will run under the context based on tf's\n-        version, eg graph for v1 and eager for v2.\n+        'eager'. If None, uses ['graph', 'eager']. If an empty\n+        list is provided, then the test will run under the context based on\n+        tensorflow's version, e.g., graph for v1 and eager for v2. Defaults to\n+        `None`.\n       run_eagerly: List of `run_eagerly` value to be run with the tests.\n-        Default to [True, False] if not specified. Note that for `graph` mode,\n-        run_eagerly value will only be False.\n+        When None, uses [True, False]. Note that for `graph` mode,\n+        run_eagerly value will only be False. Defaults to `None`.\n \n     Returns:\n       A list contains all the combinations to be used to generate test cases.\n\n@@ -880,10 +880,11 @@ def get_multi_io_model(\n       shared_input_branch: An optional sequence of layers to apply to a single\n         input, before applying both branches to that intermediate result. If\n         set, the model will take only one input instead of two. Defaults to\n-        None.\n+        `None`.\n       shared_output_branch: An optional sequence of layers to merge the\n         intermediate results produced by branch a and branch b. If set,\n-        the model will produce only one output instead of two. Defaults to None.\n+        the model will produce only one output instead of two.\n+        Defaults to `None`.\n \n     Returns:\n       A multi-io model of the type specified by `get_model_type`, specified\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6893bd59cfa3da16b835b8d9d69e9fc4879f7a9d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 50 | Lines Deleted: 47 | Files Changed: 12 | Hunks: 32 | Methods Changed: 16 | Complexity Δ (Sum/Max): 937/175 | Churn Δ: 97 | Churn Cumulative: 31552 | Contributors (this commit): 129 | Commits (past 90d): 41 | Contributors (cumulative): 250 | DMM Complexity: None\n\nDIFF:\n@@ -103,7 +103,7 @@ def audio_dataset_from_directory(\n       subset: Subset of the data to return. One of \"training\", \"validation\" or\n         \"both\". Only used if `validation_split` is set.\n       follow_links: Whether to visits subdirectories pointed to by symlinks.\n-        Defaults to False.\n+        Defaults to `False`.\n \n     Returns:\n       A `tf.data.Dataset` object.\n\n@@ -63,8 +63,8 @@ def normalize_tuple(value, n, name, allow_zero=False):\n       n: The size of the tuple to be returned.\n       name: The name of the argument being validated, e.g. \"strides\" or\n         \"kernel_size\". This is only used to format error messages.\n-      allow_zero: Default to False. A ValueError will raised if zero is received\n-        and this param is False.\n+      allow_zero: A ValueError will be raised if zero is received\n+        and this param is False. Defaults to `False`.\n \n     Returns:\n       A tuple of n integers.\n\n@@ -247,7 +247,7 @@ def get_file(\n             The default `'auto'` corresponds to `['tar', 'zip']`.\n             None or an empty list will return no matches found.\n         cache_dir: Location to store cached files, when None it\n-            defaults to the default directory `~/.keras/`.\n+            defaults to `~/.keras/`.\n \n     Returns:\n         Path to the downloaded file.\n@@ -1063,14 +1063,16 @@ def pad_sequences(\n         maxlen: Optional Int, maximum length of all sequences. If not provided,\n             sequences will be padded to the length of the longest individual\n             sequence.\n-        dtype: (Optional, defaults to `\"int32\"`). Type of the output sequences.\n+        dtype: (Optional). Type of the output sequences.\n             To pad sequences with variable length strings, you can use `object`.\n-        padding: String, \"pre\" or \"post\" (optional, defaults to `\"pre\"`):\n-            pad either before or after each sequence.\n-        truncating: String, \"pre\" or \"post\" (optional, defaults to `\"pre\"`):\n+            Defaults to `\"int32\"`.\n+        padding: String, \"pre\" or \"post\" (optional):\n+            pad either before or after each sequence. Defaults to `\"pre\"`.\n+        truncating: String, \"pre\" or \"post\" (optional):\n             remove values from sequences larger than\n             `maxlen`, either at the beginning or at the end of the sequences.\n-        value: Float or String, padding value. (Optional, defaults to 0.)\n+            Defaults to `\"pre\"`.\n+        value: Float or String, padding value. (Optional). Defaults to `0.`.\n \n     Returns:\n         Numpy array with shape `(len(sequences), maxlen)`\n\n@@ -41,11 +41,11 @@ def split_dataset(\n         left_size: If float (in the range `[0, 1]`), it signifies\n           the fraction of the data to pack in the left dataset. If integer, it\n           signifies the number of samples to pack in the left dataset. If\n-          `None`, it defaults to the complement to `right_size`.\n+          `None`, it uses the complement to `right_size`. Defaults to `None`.\n         right_size: If float (in the range `[0, 1]`), it signifies\n           the fraction of the data to pack in the right dataset. If integer, it\n           signifies the number of samples to pack in the right dataset. If\n-          `None`, it defaults to the complement to `left_size`.\n+          `None`, it uses the complement to `left_size`. Defaults to `None`.\n         shuffle: Boolean, whether to shuffle the data before splitting it.\n         seed: A random seed for shuffling.\n \n@@ -130,10 +130,10 @@ def _convert_dataset_to_list(\n         dataset_type_spec : the type of the dataset\n         data_size_warning_flag (bool, optional): If set to True, a warning will\n           be issued if the dataset takes longer than 10 seconds to iterate.\n-          Defaults to True.\n+          Defaults to `True`.\n         ensure_shape_similarity (bool, optional): If set to True, the shape of\n           the first sample will be used to validate the shape of rest of the\n-          samples. Defaults to True.\n+          samples. Defaults to `True`.\n \n     Returns:\n         List: A list of tuples/NumPy arrays.\n@@ -254,10 +254,10 @@ def _get_next_sample(\n         dataset_iterator : An `iterator` object.\n         ensure_shape_similarity (bool, optional): If set to True, the shape of\n           the first sample will be used to validate the shape of rest of the\n-          samples. Defaults to True.\n+          samples. Defaults to `True`.\n         data_size_warning_flag (bool, optional): If set to True, a warning will\n           be issued if the dataset takes longer than 10 seconds to iterate.\n-          Defaults to True.\n+          Defaults to `True`.\n         start_time (float): the start time of the dataset iteration. this is\n           used only if `data_size_warning_flag` is set to true.\n \n\n@@ -105,12 +105,12 @@ class FeatureSpace(base_layer.Layer):\n             \"crossed\" by hashing their combined value into\n             a fixed-length vector.\n         crossing_dim: Default vector size for hashing crossed features.\n-            Defaults to 32.\n+            Defaults to `32`.\n         hashing_dim: Default vector size for hashing features of type\n-            `\"integer_hashed\"` and `\"string_hashed\"`. Defaults to 32.\n+            `\"integer_hashed\"` and `\"string_hashed\"`. Defaults to `32`.\n         num_discretization_bins: Default number of bins to be used for\n             discretizing features of type `\"float_discretized\"`.\n-            Defaults to 32.\n+            Defaults to `32`.\n \n     **Available feature types:**\n \n\n@@ -187,7 +187,7 @@ class Progbar:\n               as-is. Else, an average of the metric over time will be\n               displayed.\n             finalize: Whether this is the last update for the progress bar. If\n-              `None`, defaults to `current >= self.target`.\n+              `None`, uses `current >= self.target`. Defaults to `None`.\n         \"\"\"\n         if finalize is None:\n             if self.target is None:\n\n@@ -118,10 +118,10 @@ def image_dataset_from_directory(\n           When `subset=\"both\"`, the utility returns a tuple of two datasets\n           (the training and validation datasets respectively).\n       interpolation: String, the interpolation method used when resizing images.\n-        Defaults to `bilinear`. Supports `bilinear`, `nearest`, `bicubic`,\n-        `area`, `lanczos3`, `lanczos5`, `gaussian`, `mitchellcubic`.\n+        Supports `bilinear`, `nearest`, `bicubic`, `area`, `lanczos3`,\n+        `lanczos5`, `gaussian`, `mitchellcubic`. Defaults to `bilinear`.\n       follow_links: Whether to visit subdirectories pointed to by symlinks.\n-          Defaults to False.\n+          Defaults to `False`.\n       crop_to_aspect_ratio: If True, resize the images without aspect\n         ratio distortion. When the original aspect ratio differs from the target\n         aspect ratio, the output image will be cropped so as to return the\n\n@@ -120,9 +120,9 @@ def smart_resize(x, size, interpolation=\"bilinear\"):\n         format `(height, width, channels)` or `(batch_size, height, width,\n         channels)`.\n       size: Tuple of `(height, width)` integer. Target size.\n-      interpolation: String, interpolation to use for resizing. Defaults to\n-        `'bilinear'`. Supports `bilinear`, `nearest`, `bicubic`, `area`,\n-        `lanczos3`, `lanczos5`, `gaussian`, `mitchellcubic`.\n+      interpolation: String, interpolation to use for resizing. Supports\n+        `bilinear`, `nearest`, `bicubic`, `area`, `lanczos3`, `lanczos5`,\n+        `gaussian`, `mitchellcubic`. Defaults to `'bilinear'`.\n \n     Returns:\n       Array with shape `(size[0], size[1], channels)`. If the input image was a\n@@ -216,14 +216,14 @@ def array_to_img(x, data_format=None, scale=True, dtype=None):\n     Args:\n         x: Input data, in any form that can be converted to a Numpy array.\n         data_format: Image data format, can be either `\"channels_first\"` or\n-          `\"channels_last\"`. Defaults to `None`, in which case the global\n+          `\"channels_last\"`. None means the global\n           setting `tf.keras.backend.image_data_format()` is used (unless you\n-          changed it, it defaults to `\"channels_last\"`).\n+          changed it, it uses `\"channels_last\"`). Defaults to `None`.\n         scale: Whether to rescale the image such that minimum and maximum values\n           are 0 and 255 respectively. Defaults to `True`.\n-        dtype: Dtype to use. Default to `None`, in which case the global setting\n-          `tf.keras.backend.floatx()` is used (unless you changed it, it\n-          defaults to `\"float32\"`)\n+        dtype: Dtype to use. None makes the global setting\n+          `tf.keras.backend.floatx()` to be used (unless you changed it, it\n+          uses `\"float32\"`). Defaults to `None`.\n \n     Returns:\n         A PIL Image instance.\n@@ -298,12 +298,12 @@ def img_to_array(img, data_format=None, dtype=None):\n     Args:\n         img: Input PIL Image instance.\n         data_format: Image data format, can be either `\"channels_first\"` or\n-          `\"channels_last\"`. Defaults to `None`, in which case the global\n+          `\"channels_last\"`. None means the global\n           setting `tf.keras.backend.image_data_format()` is used (unless you\n-          changed it, it defaults to `\"channels_last\"`).\n-        dtype: Dtype to use. Default to `None`, in which case the global setting\n-          `tf.keras.backend.floatx()` is used (unless you changed it, it\n-          defaults to `\"float32\"`).\n+          changed it, it uses `\"channels_last\"`). Defaults to `None`.\n+        dtype: Dtype to use. None makes the global setting\n+          `tf.keras.backend.floatx()` to be used (unless you changed it, it\n+          uses `\"float32\"`). Defaults to `None`.\n \n     Returns:\n         A 3D Numpy array.\n\n@@ -335,11 +335,12 @@ def print_summary(\n             It will be called on each line of the summary.\n             You can set it to a custom function\n             in order to capture the string summary.\n-            It defaults to `print` (prints to stdout).\n+            When `None`, uses `print` (prints to stdout).\n+            Defaults to `None`.\n         expand_nested: Whether to expand the nested models.\n-            If not provided, defaults to `False`.\n+            Defaults to `False`.\n         show_trainable: Whether to show if a layer is trainable.\n-            If not provided, defaults to `False`.\n+            Defaults to `False`.\n         layer_range: List or tuple containing two strings,\n             the starting layer name and ending layer name (both inclusive),\n             indicating the range of layers to be printed in the summary. The\n@@ -1042,9 +1043,9 @@ def warmstart_embedding_matrix(\n           embedding matrix.\n         new_embeddings_initializer: Initializer for embedding vectors for\n           previously unseen terms to be added to the new embedding matrix (see\n-          `keras.initializers`). Defaults to \"uniform\". new_embedding matrix\n+          `keras.initializers`). new_embedding matrix\n           needs to be specified with \"constant\" initializer.\n-          matrix. Default value is None.\n+          matrix. None means \"uniform\". Default value is None.\n \n     Returns:\n       tf.tensor of remapped embedding layer matrix\n\n@@ -32,11 +32,11 @@ class ReductionV2:\n     Contains the following values:\n \n     * `AUTO`: Indicates that the reduction option will be determined by the\n-      usage context. For almost all cases this defaults to\n-      `SUM_OVER_BATCH_SIZE`. When used with `tf.distribute.Strategy`, outside of\n-      built-in training loops such as `tf.keras` `compile` and `fit`, we expect\n-      reduction value to be `SUM` or `NONE`. Using `AUTO` in that case will\n-      raise an error.\n+      usage context. For almost all cases this uses `SUM_OVER_BATCH_SIZE`.\n+      When used with `tf.distribute.Strategy`, outside of built-in training\n+      loops such as `tf.keras` `compile` and `fit`, we expect reduction\n+      value to be `SUM` or `NONE`. Using `AUTO` in that case will raise an\n+      error.\n     * `NONE`: No **additional** reduction is applied to the output of the\n       wrapped loss function. When non-scalar losses are returned to Keras\n       functions like `fit`/`evaluate`, the unreduced vector loss is passed to\n\n@@ -979,7 +979,7 @@ def sparse_top_k_categorical_matches(y_true, y_pred, k=5):\n       y_true: tensor of true targets.\n       y_pred: tensor of predicted targets.\n       k: (Optional) Number of top elements to look at for computing accuracy.\n-        Defaults to 5.\n+        Defaults to `5`.\n \n     Returns:\n       Match tensor: 1.0 for label-prediction match, 0.0 for mismatch.\n\n@@ -104,7 +104,7 @@ def text_dataset_from_directory(\n             When `subset=\"both\"`, the utility returns a tuple of two datasets\n             (the training and validation datasets respectively).\n         follow_links: Whether to visits subdirectories pointed to by symlinks.\n-            Defaults to False.\n+            Defaults to `False`.\n \n     Returns:\n         A `tf.data.Dataset` object.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#242f984013dc329b9805733d2c62659443dcb23a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1041 | Lines Deleted: 197 | Files Changed: 3 | Hunks: 75 | Methods Changed: 85 | Complexity Δ (Sum/Max): 161/121 | Churn Δ: 1238 | Churn Cumulative: 3847 | Contributors (this commit): 3 | Commits (past 90d): 19 | Contributors (cumulative): 7 | DMM Complexity: 0.9202037351443124\n\nDIFF:\n@@ -12,12 +12,11 @@ arange\n arccos\n arcsin\n arctan\n-arctanh\n+arctan2\n argmax\n argmin\n argsort\n array\n-array_equal\n average\n broadcast_to\n ceil\n@@ -28,7 +27,6 @@ conjugate\n copy\n cos\n count_nonzero\n-cov\n cross\n cumprod\n cumsum\n@@ -202,15 +200,32 @@ def reduce_shape(shape, axis=None, keepdims=False):\n         return output_shape\n \n \n-def shape_equal(shape1, shape2, axis=None):\n+def shape_equal(shape1, shape2, axis=None, allow_none=True):\n+    \"\"\"Check if two shapes are equal.\n+\n+    Args:\n+        shape1: A tuple or list of integers.\n+        shape2: A tuple or list of integers.\n+        axis: int or list/tuple of ints, defaults to None. If specified, the\n+            shape check will ignore the axes specified by `axis`.\n+        allow_none: bool, defaults to True. If True, None in the shape will\n+            match any value.\n+    \"\"\"\n     if len(shape1) != len(shape2):\n         return False\n-    if axis is not None:\n     shape1 = list(shape1)\n     shape2 = list(shape2)\n+    if axis is not None:\n         for ax in axis:\n             shape1[ax] = -1\n             shape2[ax] = -1\n+    if allow_none:\n+        for i in range(len(shape1)):\n+            if shape1[i] is None:\n+                shape1[i] = -1\n+            if shape2[i] is None:\n+                shape2[i] = -1\n+\n     return shape1 == shape2\n \n \n@@ -241,7 +256,9 @@ class Add(Operation):\n         return backend.execute(\"add\", x1, x2)\n \n     def compute_output_spec(self, x1, x2):\n-        output_shape = broadcast_shapes(x1.shape, x2.shape)\n+        x1_shape = getattr(x1, \"shape\", [])\n+        x2_shape = getattr(x2, \"shape\", [])\n+        output_shape = broadcast_shapes(x1_shape, x2_shape)\n         return KerasTensor(output_shape, dtype=x1.dtype)\n \n \n@@ -380,13 +397,444 @@ def append(\n     return backend.execute(\"append\", x1, x2, axis=axis)\n \n \n+class Arange(Operation):\n+    def call(self, start, stop=None, step=None, dtype=None):\n+        if stop is None:\n+            start, stop = 0, start\n+        if step is None:\n+            step = 1\n+        return backend.execute(\"arange\", start, stop, step=step, dtype=dtype)\n+\n+    def compute_output_spec(self, start, stop=None, step=None, dtype=None):\n+        if stop is None:\n+            start, stop = 0, start\n+        if step is None:\n+            step = 1\n+        output_shape = [np.ceil((stop - start) / step).astype(int)]\n+        return KerasTensor(output_shape, dtype=dtype)\n+\n+\n+def arange(start, stop=None, step=None, dtype=None):\n+    if stop is None:\n+        start, stop = 0, start\n+    if step is None:\n+        step = 1\n+    return backend.execute(\"arange\", start, stop, step=step, dtype=dtype)\n+\n+\n+class Arccos(Operation):\n+    def call(self, x):\n+        return backend.execute(\"arccos\", x)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=x.dtype)\n+\n+\n+def arccos(x):\n+    if any_symbolic_tensors((x,)):\n+        return Arccos().symbolic_call(x)\n+    return backend.execute(\"arccos\", x)\n+\n+\n+class Arcsin(Operation):\n+    def call(self, x):\n+        return backend.execute(\"arcsin\", x)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=x.dtype)\n+\n+\n+def arcsin(x):\n+    if any_symbolic_tensors((x,)):\n+        return Arcsin().symbolic_call(x)\n+    return backend.execute(\"arcsin\", x)\n+\n+\n+class Arctan(Operation):\n+    def call(self, x):\n+        return backend.execute(\"arctan\", x)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=x.dtype)\n+\n+\n+def arctan(x):\n+    if any_symbolic_tensors((x,)):\n+        return Arctan().symbolic_call(x)\n+    return backend.execute(\"arctan\", x)\n+\n+\n+class Arctan2(Operation):\n+    def call(self, x1, x2):\n+        return backend.execute(\"arctan2\", x1, x2)\n+\n+    def compute_output_spec(self, x1, x2):\n+        x1_shape = getattr(x1, \"shape\", [])\n+        x2_shape = getattr(x2, \"shape\", [])\n+        outputs_shape = broadcast_shapes(x1_shape, x2_shape)\n+        return KerasTensor(outputs_shape, dtype=x1.dtype)\n+\n+\n+def arctan2(x1, x2):\n+    if any_symbolic_tensors((x1, x2)):\n+        return Arctan2().symbolic_call(x1, x2)\n+    return backend.execute(\"arctan2\", x1, x2)\n+\n+\n+class Argmax(Operation):\n+    def __init__(self, axis=None):\n+        super().__init__()\n+        self.axis = axis\n+\n+    def call(self, x):\n+        return backend.execute(\"argmax\", x, axis=self.axis)\n+\n+    def compute_output_spec(self, x):\n+        if self.axis is None:\n+            return KerasTensor([], dtype=\"int32\")\n+        return KerasTensor(\n+            reduce_shape(x.shape, axis=[self.axis]), dtype=\"int32\"\n+        )\n+\n+\n+def argmax(x, axis=None):\n+    if any_symbolic_tensors((x,)):\n+        return Argmax(axis=axis).symbolic_call(x)\n+    return backend.execute(\"argmax\", x, axis=axis)\n+\n+\n+class Argmin(Operation):\n+    def __init__(self, axis=None):\n+        super().__init__()\n+        self.axis = axis\n+\n+    def call(self, x):\n+        return backend.execute(\"argmin\", x, axis=self.axis)\n+\n+    def compute_output_spec(self, x):\n+        if self.axis is None:\n+            return KerasTensor([], dtype=\"int32\")\n+        return KerasTensor(\n+            reduce_shape(x.shape, axis=[self.axis]), dtype=\"int32\"\n+        )\n+\n+\n+def argmin(x, axis=None):\n+    if any_symbolic_tensors((x,)):\n+        return Argmin(axis=axis).symbolic_call(x)\n+    return backend.execute(\"argmin\", x, axis=axis)\n+\n+\n+class Argsort(Operation):\n+    def __init__(self, axis=-1):\n+        super().__init__()\n+        self.axis = axis\n+\n+    def call(self, x):\n+        return backend.execute(\"argsort\", x, axis=self.axis)\n+\n+    def compute_output_spec(self, x):\n+        if self.axis is None:\n+            return KerasTensor([int(np.prod(x.shape))], dtype=\"int32\")\n+        return KerasTensor(x.shape, dtype=\"int32\")\n+\n+\n+def argsort(x, axis=-1):\n+    if any_symbolic_tensors((x,)):\n+        return Argsort(axis=axis).symbolic_call(x)\n+    return backend.execute(\"argsort\", x, axis=axis)\n+\n+\n+class Array(Operation):\n+    def call(self, x, dtype=None):\n+        return backend.execute(\"array\", x, dtype=dtype)\n+\n+    def compute_output_spec(self, x, dtype=None):\n+        return KerasTensor(x.shape, dtype=dtype)\n+\n+\n+def array(x, dtype=None):\n+    if any_symbolic_tensors((x,)):\n+        return Array().symbolic_call(x, dtype=dtype)\n+    return backend.execute(\"array\", x, dtype=dtype)\n+\n+\n+class Average(Operation):\n+    def __init__(self, axis=None):\n+        super().__init__()\n+        # np.average() does not support axis as tuple as declared by the\n+        # docstring, it only supports int or None.\n+        self.axis = axis\n+\n+    def call(self, x, weights=None):\n+        return backend.execute(\"average\", x, weights=weights, axis=self.axis)\n+\n+    def compute_output_spec(self, x, weights=None):\n+        if weights is not None:\n+            shape_match = shape_equal(x.shape, weights.shape, allow_none=True)\n+            if self.axis is not None:\n+                shape_match_on_axis = shape_equal(\n+                    [x.shape[self.axis]], weights.shape, allow_none=True\n+                )\n+        if self.axis is None:\n+            if weights is None or shape_match:\n+                return KerasTensor(\n+                    [],\n+                    dtype=x.dtype,\n+                )\n+            else:\n+                raise ValueError(\n+                    \"`weights` must have the same shape as `x` when \"\n+                    f\"`axis=None`, but received `weights.shape={weights.shape}`\"\n+                    f\" and `x.shape={x.shape}`.\"\n+                )\n+\n+        if weights is None or shape_match_on_axis or shape_match:\n+            return KerasTensor(\n+                reduce_shape(x.shape, axis=[self.axis]),\n+                dtype=x.dtype,\n+            )\n+        else:\n+            # `weights` can either be a 1D array of length `x.shape[axis]` or\n+            # of the same shape as `x`.\n+            raise ValueError(\n+                \"`weights` must have the same size as `x` at \"\n+                f\"`axis={self.axis}` but received \"\n+                f\"`weights.shape={weights.shape}` while x.shape at \"\n+                f\"`{self.axis}` is `{x.shape[self.axis]}`.\"\n+            )\n+\n+\n+def average(x, axis=None, weights=None):\n+    if any_symbolic_tensors((x,)):\n+        return Average(axis=axis).symbolic_call(x, weights=weights)\n+    return backend.execute(\"average\", x, weights=weights, axis=axis)\n+\n+\n+class BroadcastTo(Operation):\n+    def __init__(self, shape):\n+        super().__init__()\n+        self.shape = shape\n+\n+    def call(self, x):\n+        return backend.execute(\"broadcast_to\", x, self.shape)\n+\n+    def compute_output_spec(self, x):\n+        # Catch broadcasting errors for clear error messages.\n+        broadcast_shapes(x.shape, self.shape)\n+        return KerasTensor(self.shape, dtype=x.dtype)\n+\n+\n+def broadcast_to(x, shape):\n+    if any_symbolic_tensors((x,)):\n+        return BroadcastTo(shape=shape).symbolic_call(x)\n+    return backend.execute(\"broadcast_to\", x, shape)\n+\n+\n+class Ceil(Operation):\n+    def call(self, x):\n+        return backend.execute(\"ceil\", x)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=x.dtype)\n+\n+\n+def ceil(x):\n+    if any_symbolic_tensors((x,)):\n+        return Ceil().symbolic_call(x)\n+    return backend.execute(\"ceil\", x)\n+\n+\n+class Clip(Operation):\n+    def __init__(self, x_min, x_max):\n+        super().__init__()\n+        self.x_min = x_min\n+        self.x_max = x_max\n+\n+    def call(self, x):\n+        return backend.execute(\"clip\", x, self.x_min, self.x_max)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=x.dtype)\n+\n+\n+def clip(x, x_min, x_max):\n+    if any_symbolic_tensors((x,)):\n+        return Clip(x_min, x_max).symbolic_call(x)\n+    return backend.execute(\"clip\", x, x_min, x_max)\n+\n+\n+class Concatenate(Operation):\n+    def __init__(self, axis=0):\n+        super().__init__()\n+        if axis is None:\n+            raise ValueError(\"`axis` cannot be None for `concatenate`.\")\n+        self.axis = axis\n+\n+    def call(self, xs):\n+        return backend.execute(\"concatenate\", xs, axis=self.axis)\n+\n+    def compute_output_spec(self, xs):\n+        first_shape = xs[0].shape\n+        total_size_on_axis = 0\n+        for x in xs:\n+            if not shape_equal(\n+                x.shape, first_shape, axis=[self.axis], allow_none=True\n+            ):\n+                raise ValueError(\n+                    \"Every value in `xs` must have the same shape except on \"\n+                    f\"the `axis` dim. But found element of shape {x.shape}, \"\n+                    f\"which is different from the first element's \"\n+                    f\"shape {first_shape}.\"\n+                )\n+            if total_size_on_axis is None or x.shape[self.axis] is None:\n+                total_size_on_axis = None\n+            else:\n+                total_size_on_axis += x.shape[self.axis]\n+        output_shape = list(first_shape)\n+        output_shape[self.axis] = total_size_on_axis\n+        return KerasTensor(output_shape, dtype=x.dtype)\n+\n+\n+def concatenate(xs, axis=0):\n+    if any_symbolic_tensors(xs):\n+        return Concatenate(axis=axis).symbolic_call(xs)\n+    return backend.execute(\"concatenate\", xs, axis=axis)\n+\n+\n+class Conjugate(Operation):\n+    def call(self, x):\n+        return backend.execute(\"conjugate\", x)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=x.dtype)\n+\n+\n+def conjugate(x):\n+    if any_symbolic_tensors((x,)):\n+        return Conjugate().symbolic_call(x)\n+    return backend.execute(\"conjugate\", x)\n+\n+\n+class Conj(Conjugate):\n+    pass\n+\n+\n+def conj(x):\n+    return conjugate(x)\n+\n+\n+class Copy(Operation):\n+    def call(self, x):\n+        return backend.execute(\"copy\", x)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=x.dtype)\n+\n+\n+def copy(x):\n+    if any_symbolic_tensors((x,)):\n+        return Copy().symbolic_call(x)\n+    return backend.execute(\"copy\", x)\n+\n+\n+class Cos(Operation):\n+    def call(self, x):\n+        return backend.execute(\"cos\", x)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=x.dtype)\n+\n+\n+def cos(x):\n+    if any_symbolic_tensors((x,)):\n+        return Cos().symbolic_call(x)\n+    return backend.execute(\"cos\", x)\n+\n+\n+class CountNonzero(Operation):\n+    def __init__(self, axis=None):\n+        super().__init__()\n+        if isinstance(axis, int):\n+            self.axis = [axis]\n+        else:\n+            self.axis = axis\n+\n+    def call(self, x):\n+        return backend.execute(\n+            \"count_nonzero\",\n+            x,\n+            axis=self.axis,\n+        )\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(\n+            reduce_shape(x.shape, axis=self.axis),\n+            dtype=\"int32\",\n+        )\n+\n+\n+def count_nonzero(x, axis=None):\n+    if any_symbolic_tensors((x,)):\n+        return CountNonzero(axis=axis).symbolic_call(x)\n+    return backend.execute(\"count_nonzero\", x, axis=axis)\n+\n+\n+class Cumprod(Operation):\n+    def __init__(self, axis=None):\n+        super().__init__()\n+        self.axis = axis\n+\n+    def call(self, x):\n+        return backend.execute(\"cumprod\", x, axis=self.axis)\n+\n+    def compute_output_spec(self, x):\n+        if self.axis is None:\n+            if None in x.shape:\n+                output_shape = (None,)\n+            else:\n+                output_shape = (int(np.prod(x.shape)),)\n+            return KerasTensor(output_shape, dtype=\"int32\")\n+        return KerasTensor(x.shape, dtype=x.dtype)\n+\n+\n+def cumprod(x, axis=None):\n+    if any_symbolic_tensors((x,)):\n+        return Cumprod(axis=axis).symbolic_call(x)\n+    return backend.execute(\"cumprod\", x, axis=axis)\n+\n+\n+class Cumsum(Operation):\n+    def __init__(self, axis=None):\n+        super().__init__()\n+        self.axis = axis\n+\n+    def call(self, x):\n+        return backend.execute(\"cumsum\", x, axis=self.axis)\n+\n+    def compute_output_spec(self, x):\n+        if self.axis is None:\n+            if None in x.shape:\n+                output_shape = (None,)\n+            else:\n+                output_shape = (int(np.prod(x.shape)),)\n+            return KerasTensor(output_shape, dtype=\"int32\")\n+        return KerasTensor(x.shape, dtype=x.dtype)\n+\n+\n+def cumsum(x, axis=None):\n+    if any_symbolic_tensors((x,)):\n+        return Cumsum(axis=axis).symbolic_call(x)\n+    return backend.execute(\"cumsum\", x, axis=axis)\n+\n+\n class Matmul(Operation):\n     def call(self, x1, x2):\n         return backend.execute(\"matmul\", x1, x2)\n \n     def compute_output_spec(self, x1, x2):\n-        x1_shape = x1.shape\n-        x2_shape = x2.shape\n+        x1_shape = getattr(x1, \"shape\", [])\n+        x2_shape = getattr(x2, \"shape\", [])\n         if len(x1_shape) == 1:\n             x1_shape = (1, x1_shape[0])\n         if len(x2_shape) == 1:\n@@ -426,7 +874,9 @@ class Subtract(Operation):\n         return backend.execute(\"subtract\", x1, x2)\n \n     def compute_output_spec(self, x1, x2):\n-        output_shape = broadcast_shapes(x1.shape, x2.shape)\n+        x1_shape = getattr(x1, \"shape\", [])\n+        x2_shape = getattr(x2, \"shape\", [])\n+        output_shape = broadcast_shapes(x1_shape, x2_shape)\n         return KerasTensor(output_shape, dtype=x1.dtype)\n \n \n@@ -441,7 +891,9 @@ class Multiply(Operation):\n         return backend.execute(\"multiply\", x1, x2)\n \n     def compute_output_spec(self, x1, x2):\n-        output_shape = broadcast_shapes(x1.shape, x2.shape)\n+        x1_shape = getattr(x1, \"shape\", [])\n+        x2_shape = getattr(x2, \"shape\", [])\n+        output_shape = broadcast_shapes(x1_shape, x2_shape)\n         return KerasTensor(output_shape, dtype=x1.dtype)\n \n \n@@ -456,7 +908,9 @@ class Divide(Operation):\n         return backend.execute(\"divide\", x1, x2)\n \n     def compute_output_spec(self, x1, x2):\n-        output_shape = broadcast_shapes(x1.shape, x2.shape)\n+        x1_shape = getattr(x1, \"shape\", [])\n+        x2_shape = getattr(x2, \"shape\", [])\n+        output_shape = broadcast_shapes(x1_shape, x2_shape)\n         return KerasTensor(output_shape, dtype=x1.dtype)\n \n \n@@ -471,7 +925,9 @@ class TrueDivide(Operation):\n         return backend.execute(\"true_divide\", x1, x2)\n \n     def compute_output_spec(self, x1, x2):\n-        output_shape = broadcast_shapes(x1.shape, x2.shape)\n+        x1_shape = getattr(x1, \"shape\", [])\n+        x2_shape = getattr(x2, \"shape\", [])\n+        output_shape = broadcast_shapes(x1_shape, x2_shape)\n         return KerasTensor(output_shape, dtype=x1.dtype)\n \n \n@@ -486,7 +942,9 @@ class Power(Operation):\n         return backend.execute(\"power\", x1, x2)\n \n     def compute_output_spec(self, x1, x2):\n-        output_shape = broadcast_shapes(x1.shape, x2.shape)\n+        x1_shape = getattr(x1, \"shape\", [])\n+        x2_shape = getattr(x2, \"shape\", [])\n+        output_shape = broadcast_shapes(x1_shape, x2_shape)\n         return KerasTensor(output_shape, dtype=x1.dtype)\n \n \n\n@@ -1,4 +1,5 @@\n import numpy as np\n+from tensorflow.python.ops.numpy_ops import np_config\n \n from keras_core import backend\n from keras_core import testing\n@@ -6,6 +7,8 @@ from keras_core.backend.keras_tensor import KerasTensor\n from keras_core.operations import numpy as knp\n from keras_core.operations import operation\n \n+np_config.enable_numpy_behavior()\n+\n \n class NumpyTwoInputOpsShapeTest(testing.TestCase):\n     def test_add(self):\n@@ -17,6 +20,9 @@ class NumpyTwoInputOpsShapeTest(testing.TestCase):\n         y = KerasTensor((2, None))\n         self.assertEqual(knp.add(x, y).shape, (2, 3))\n \n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.add(x, 2).shape, (2, 3))\n+\n         with self.assertRaises(ValueError):\n             x = KerasTensor([2, 3])\n             y = KerasTensor([2, 3, 4])\n@@ -31,6 +37,9 @@ class NumpyTwoInputOpsShapeTest(testing.TestCase):\n         y = KerasTensor([2, None])\n         self.assertEqual(knp.subtract(x, y).shape, (2, 3))\n \n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.subtract(x, 2).shape, (2, 3))\n+\n         with self.assertRaises(ValueError):\n             x = KerasTensor([2, 3])\n             y = KerasTensor([2, 3, 4])\n@@ -45,6 +54,9 @@ class NumpyTwoInputOpsShapeTest(testing.TestCase):\n         y = KerasTensor([2, None])\n         self.assertEqual(knp.multiply(x, y).shape, (2, 3))\n \n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.multiply(x, 2).shape, (2, 3))\n+\n         with self.assertRaises(ValueError):\n             x = KerasTensor([2, 3])\n             y = KerasTensor([2, 3, 4])\n@@ -73,6 +85,9 @@ class NumpyTwoInputOpsShapeTest(testing.TestCase):\n         y = KerasTensor([2, None])\n         self.assertEqual(knp.power(x, y).shape, (2, 3))\n \n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.power(x, 2).shape, (2, 3))\n+\n         with self.assertRaises(ValueError):\n             x = KerasTensor([2, 3])\n             y = KerasTensor([2, 3, 4])\n@@ -87,6 +102,9 @@ class NumpyTwoInputOpsShapeTest(testing.TestCase):\n         y = KerasTensor([2, None])\n         self.assertEqual(knp.divide(x, y).shape, (2, 3))\n \n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.divide(x, 2).shape, (2, 3))\n+\n         with self.assertRaises(ValueError):\n             x = KerasTensor([2, 3])\n             y = KerasTensor([2, 3, 4])\n@@ -101,6 +119,9 @@ class NumpyTwoInputOpsShapeTest(testing.TestCase):\n         y = KerasTensor([2, None])\n         self.assertEqual(knp.true_divide(x, y).shape, (2, 3))\n \n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.true_divide(x, 2).shape, (2, 3))\n+\n         with self.assertRaises(ValueError):\n             x = KerasTensor([2, 3])\n             y = KerasTensor([2, 3, 4])\n@@ -124,6 +145,23 @@ class NumpyTwoInputOpsShapeTest(testing.TestCase):\n             y = KerasTensor([2, 3, 4])\n             knp.append(x, y, axis=2)\n \n+    def test_arctan2(self):\n+        x = KerasTensor([2, 3])\n+        y = KerasTensor([2, 3])\n+        self.assertEqual(knp.arctan2(x, y).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        y = KerasTensor([2, None])\n+        self.assertEqual(knp.arctan2(x, y).shape, (2, 3))\n+\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.arctan2(x, 2).shape, (2, 3))\n+\n+        with self.assertRaises(ValueError):\n+            x = KerasTensor([2, 3])\n+            y = KerasTensor([2, 3, 4])\n+            knp.arctan2(x, y)\n+\n \n class NumpyOneInputOpsShapeTest(testing.TestCase):\n     def test_mean(self):\n@@ -242,119 +280,269 @@ class NumpyOneInputOpsShapeTest(testing.TestCase):\n         x = KerasTensor([None, 3, 3])\n         self.assertEqual(knp.transpose(x, (2, 0, 1)).shape, (3, None, 3))\n \n+    def test_arccos(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.arccos(x).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.arccos(x).shape, (None, 3))\n+\n+    def test_arcsin(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.arcsin(x).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.arcsin(x).shape, (None, 3))\n+\n+    def test_arctan(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.arctan(x).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.arctan(x).shape, (None, 3))\n+\n+    def test_argmax(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.argmax(x).shape, ())\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.argmax(x).shape, ())\n+\n+        x = KerasTensor([None, 3, 3])\n+        self.assertEqual(knp.argmax(x, axis=1).shape, (None, 3))\n+\n+    def test_argmin(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.argmin(x).shape, ())\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.argmin(x).shape, ())\n+\n+        x = KerasTensor([None, 3, 3])\n+        self.assertEqual(knp.argmin(x, axis=1).shape, (None, 3))\n+\n+    def test_argsort(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.argsort(x).shape, (2, 3))\n+        self.assertEqual(knp.argsort(x, axis=None).shape, (6,))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.argsort(x).shape, (None, 3))\n+\n+        x = KerasTensor([None, 3, 3])\n+        self.assertEqual(knp.argsort(x, axis=1).shape, (None, 3, 3))\n+\n+    def test_array(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.array(x).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.array(x).shape, (None, 3))\n+\n+    def test_average(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.average(x).shape, ())\n+\n+        x = KerasTensor([None, 3])\n+        weights = KerasTensor([None, 3])\n+        self.assertEqual(knp.average(x, weights=weights).shape, ())\n+\n+        x = KerasTensor([None, 3])\n+        weights = KerasTensor([3])\n+        self.assertEqual(knp.average(x, axis=1, weights=weights).shape, (None,))\n+\n+        x = KerasTensor([None, 3, 3])\n+        self.assertEqual(knp.average(x, axis=1).shape, (None, 3))\n+\n+        with self.assertRaises(ValueError):\n+            x = KerasTensor([None, 3, 3])\n+            weights = KerasTensor([None, 4])\n+            knp.average(x, weights=weights)\n+\n+    def test_broadcast_to(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.broadcast_to(x, (2, 2, 3)).shape, (2, 2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.broadcast_to(x, (2, 3, 3)).shape, (2, 3, 3))\n+\n+        with self.assertRaises(ValueError):\n+            x = KerasTensor([3, 3])\n+            knp.broadcast_to(x, (2, 2, 3))\n+\n+    def test_ceil(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.ceil(x).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.ceil(x).shape, (None, 3))\n+\n+    def test_clip(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.clip(x, 1, 2).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.clip(x, 1, 2).shape, (None, 3))\n+\n+    def test_concatenate(self):\n+        x = KerasTensor([2, 3])\n+        y = KerasTensor([2, 3])\n+        self.assertEqual(knp.concatenate([x, y]).shape, (4, 3))\n+        self.assertEqual(knp.concatenate([x, y], axis=1).shape, (2, 6))\n+\n+        x = KerasTensor([None, 3])\n+        y = KerasTensor([None, 3])\n+        self.assertEqual(\n+            knp.concatenate(\n+                [x, y],\n+            ).shape,\n+            (None, 3),\n+        )\n+        self.assertEqual(knp.concatenate([x, y], axis=1).shape, (None, 6))\n+\n+        with self.assertRaises(ValueError):\n+            self.assertEqual(knp.concatenate([x, y], axis=None).shape, (None,))\n+\n+        with self.assertRaises(ValueError):\n+            x = KerasTensor([None, 3, 5])\n+            y = KerasTensor([None, 4, 6])\n+            knp.concatenate([x, y], axis=1)\n+\n+    def test_conjugate(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.conjugate(x).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.conjugate(x).shape, (None, 3))\n+\n+    def test_conj(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.conj(x).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.conj(x).shape, (None, 3))\n+\n+    def test_copy(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.copy(x).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.copy(x).shape, (None, 3))\n+\n+    def test_cos(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.cos(x).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.cos(x).shape, (None, 3))\n+\n+    def test_count_nonzero(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.count_nonzero(x).shape, ())\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.count_nonzero(x).shape, ())\n+\n+        x = KerasTensor([None, 3, 3])\n+        self.assertEqual(knp.count_nonzero(x, axis=1).shape, (None, 3))\n+\n+    def test_cumprod(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.cumprod(x).shape, (6,))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.cumprod(x).shape, (None,))\n+\n+        x = KerasTensor([None, 3, 3])\n+        self.assertEqual(knp.cumprod(x, axis=1).shape, (None, 3, 3))\n+\n+    def test_cumsum(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.cumsum(x).shape, (6,))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.cumsum(x).shape, (None,))\n+\n+        x = KerasTensor([None, 3, 3])\n+        self.assertEqual(knp.cumsum(x, axis=1).shape, (None, 3, 3))\n+\n \n class NumpyTwoInputOpsCorretnessTest(testing.TestCase):\n     def test_add(self):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n         y = np.array([[4, 5, 6], [3, 2, 1]])\n         z = np.array([[[1, 2, 3], [3, 2, 1]]])\n-        np.testing.assert_array_equal(np.array(knp.add(x, y)), np.add(x, y))\n-        np.testing.assert_array_equal(np.array(knp.add(x, z)), np.add(x, z))\n+        self.assertAllClose(np.array(knp.add(x, y)), np.add(x, y))\n+        self.assertAllClose(np.array(knp.add(x, z)), np.add(x, z))\n \n-        np.testing.assert_array_equal(np.array(knp.Add()(x, y)), np.add(x, y))\n-        np.testing.assert_array_equal(np.array(knp.Add()(x, z)), np.add(x, z))\n+        self.assertAllClose(np.array(knp.Add()(x, y)), np.add(x, y))\n+        self.assertAllClose(np.array(knp.Add()(x, z)), np.add(x, z))\n \n     def test_subtract(self):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n         y = np.array([[4, 5, 6], [3, 2, 1]])\n         z = np.array([[[1, 2, 3], [3, 2, 1]]])\n-        np.testing.assert_array_equal(\n-            np.array(knp.subtract(x, y)), np.subtract(x, y)\n-        )\n-        np.testing.assert_array_equal(\n-            np.array(knp.subtract(x, z)), np.subtract(x, z)\n-        )\n+        self.assertAllClose(np.array(knp.subtract(x, y)), np.subtract(x, y))\n+        self.assertAllClose(np.array(knp.subtract(x, z)), np.subtract(x, z))\n \n-        np.testing.assert_array_equal(\n-            np.array(knp.Subtract()(x, y)), np.subtract(x, y)\n-        )\n-        np.testing.assert_array_equal(\n-            np.array(knp.Subtract()(x, z)), np.subtract(x, z)\n-        )\n+        self.assertAllClose(np.array(knp.Subtract()(x, y)), np.subtract(x, y))\n+        self.assertAllClose(np.array(knp.Subtract()(x, z)), np.subtract(x, z))\n \n     def test_multiply(self):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n         y = np.array([[4, 5, 6], [3, 2, 1]])\n         z = np.array([[[1, 2, 3], [3, 2, 1]]])\n-        np.testing.assert_array_equal(\n-            np.array(knp.multiply(x, y)), np.multiply(x, y)\n-        )\n-        np.testing.assert_array_equal(\n-            np.array(knp.multiply(x, z)), np.multiply(x, z)\n-        )\n+        self.assertAllClose(np.array(knp.multiply(x, y)), np.multiply(x, y))\n+        self.assertAllClose(np.array(knp.multiply(x, z)), np.multiply(x, z))\n \n-        np.testing.assert_array_equal(\n-            np.array(knp.Multiply()(x, y)), np.multiply(x, y)\n-        )\n-        np.testing.assert_array_equal(\n-            np.array(knp.Multiply()(x, z)), np.multiply(x, z)\n-        )\n+        self.assertAllClose(np.array(knp.Multiply()(x, y)), np.multiply(x, y))\n+        self.assertAllClose(np.array(knp.Multiply()(x, z)), np.multiply(x, z))\n \n     def test_matmul(self):\n         x = np.ones([2, 3, 4, 5])\n         y = np.ones([2, 3, 5, 6])\n         z = np.ones([5, 6])\n-        np.testing.assert_array_equal(\n-            np.array(knp.matmul(x, y)), np.matmul(x, y)\n-        )\n-        np.testing.assert_array_equal(\n-            np.array(knp.matmul(x, z)), np.matmul(x, z)\n-        )\n+        self.assertAllClose(np.array(knp.matmul(x, y)), np.matmul(x, y))\n+        self.assertAllClose(np.array(knp.matmul(x, z)), np.matmul(x, z))\n \n-        np.testing.assert_array_equal(\n-            np.array(knp.Matmul()(x, y)), np.matmul(x, y)\n-        )\n-        np.testing.assert_array_equal(\n-            np.array(knp.Matmul()(x, z)), np.matmul(x, z)\n-        )\n+        self.assertAllClose(np.array(knp.Matmul()(x, y)), np.matmul(x, y))\n+        self.assertAllClose(np.array(knp.Matmul()(x, z)), np.matmul(x, z))\n \n     def test_power(self):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n         y = np.array([[4, 5, 6], [3, 2, 1]])\n         z = np.array([[[1, 2, 3], [3, 2, 1]]])\n-        np.testing.assert_array_equal(np.array(knp.power(x, y)), np.power(x, y))\n-        np.testing.assert_array_equal(np.array(knp.power(x, z)), np.power(x, z))\n+        self.assertAllClose(np.array(knp.power(x, y)), np.power(x, y))\n+        self.assertAllClose(np.array(knp.power(x, z)), np.power(x, z))\n \n-        np.testing.assert_array_equal(\n-            np.array(knp.Power()(x, y)), np.power(x, y)\n-        )\n-        np.testing.assert_array_equal(\n-            np.array(knp.Power()(x, z)), np.power(x, z)\n-        )\n+        self.assertAllClose(np.array(knp.Power()(x, y)), np.power(x, y))\n+        self.assertAllClose(np.array(knp.Power()(x, z)), np.power(x, z))\n \n     def test_divide(self):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n         y = np.array([[4, 5, 6], [3, 2, 1]])\n         z = np.array([[[1, 2, 3], [3, 2, 1]]])\n-        np.testing.assert_array_equal(\n-            np.array(knp.divide(x, y)), np.divide(x, y)\n-        )\n-        np.testing.assert_array_equal(\n-            np.array(knp.divide(x, z)), np.divide(x, z)\n-        )\n+        self.assertAllClose(np.array(knp.divide(x, y)), np.divide(x, y))\n+        self.assertAllClose(np.array(knp.divide(x, z)), np.divide(x, z))\n \n-        np.testing.assert_array_equal(\n-            np.array(knp.Divide()(x, y)), np.divide(x, y)\n-        )\n-        np.testing.assert_array_equal(\n-            np.array(knp.Divide()(x, z)), np.divide(x, z)\n-        )\n+        self.assertAllClose(np.array(knp.Divide()(x, y)), np.divide(x, y))\n+        self.assertAllClose(np.array(knp.Divide()(x, z)), np.divide(x, z))\n \n     def test_true_divide(self):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n         y = np.array([[4, 5, 6], [3, 2, 1]])\n         z = np.array([[[1, 2, 3], [3, 2, 1]]])\n-        np.testing.assert_array_equal(\n+        self.assertAllClose(\n             np.array(knp.true_divide(x, y)), np.true_divide(x, y)\n         )\n-        np.testing.assert_array_equal(\n+        self.assertAllClose(\n             np.array(knp.true_divide(x, z)), np.true_divide(x, z)\n         )\n \n-        np.testing.assert_array_equal(\n+        self.assertAllClose(\n             np.array(knp.TrueDivide()(x, y)), np.true_divide(x, y)\n         )\n-        np.testing.assert_array_equal(\n+        self.assertAllClose(\n             np.array(knp.TrueDivide()(x, z)), np.true_divide(x, z)\n         )\n \n@@ -362,233 +550,424 @@ class NumpyTwoInputOpsCorretnessTest(testing.TestCase):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n         y = np.array([[4, 5, 6], [3, 2, 1]])\n         z = np.array([[[1, 2, 3], [3, 2, 1]], [[4, 5, 6], [3, 2, 1]]])\n-        np.testing.assert_array_equal(\n-            np.array(knp.append(x, y)), np.append(x, y)\n-        )\n-        np.testing.assert_array_equal(\n+        self.assertAllClose(np.array(knp.append(x, y)), np.append(x, y))\n+        self.assertAllClose(\n             np.array(knp.append(x, y, axis=1)), np.append(x, y, axis=1)\n         )\n-        np.testing.assert_array_equal(\n-            np.array(knp.append(x, z)), np.append(x, z)\n-        )\n+        self.assertAllClose(np.array(knp.append(x, z)), np.append(x, z))\n \n-        np.testing.assert_array_equal(\n-            np.array(knp.Append()(x, y)), np.append(x, y)\n-        )\n-        np.testing.assert_array_equal(\n+        self.assertAllClose(np.array(knp.Append()(x, y)), np.append(x, y))\n+        self.assertAllClose(\n             np.array(knp.Append(axis=1)(x, y)), np.append(x, y, axis=1)\n         )\n-        np.testing.assert_array_equal(\n-            np.array(knp.Append()(x, z)), np.append(x, z)\n-        )\n+        self.assertAllClose(np.array(knp.Append()(x, z)), np.append(x, z))\n+\n+    def test_arctan2(self):\n+        x = np.array([[1.0, 2.0, 3.0], [3.0, 2.0, 1.0]])\n+        y = np.array([[4.0, 5.0, 6.0], [3.0, 2.0, 1.0]])\n+        self.assertAllClose(np.array(knp.arctan2(x, y)), np.arctan2(x, y))\n+\n+        self.assertAllClose(np.array(knp.Arctan2()(x, y)), np.arctan2(x, y))\n \n \n class NumpyOneInputOpsCorrectnessTest(testing.TestCase):\n     def test_mean(self):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n-        np.testing.assert_array_equal(np.array(knp.mean(x)), np.mean(x))\n-        np.testing.assert_array_equal(\n-            np.array(knp.mean(x, axis=1)), np.mean(x, axis=1)\n-        )\n-        np.testing.assert_array_equal(\n+        self.assertAllClose(np.array(knp.mean(x)), np.mean(x))\n+        self.assertAllClose(np.array(knp.mean(x, axis=1)), np.mean(x, axis=1))\n+        self.assertAllClose(\n             np.array(knp.mean(x, axis=1, keepdims=True)),\n             np.mean(x, axis=1, keepdims=True),\n         )\n \n-        np.testing.assert_array_equal(np.array(knp.Mean()(x)), np.mean(x))\n-        np.testing.assert_array_equal(\n-            np.array(knp.Mean(axis=1)(x)), np.mean(x, axis=1)\n-        )\n-        np.testing.assert_array_equal(\n+        self.assertAllClose(np.array(knp.Mean()(x)), np.mean(x))\n+        self.assertAllClose(np.array(knp.Mean(axis=1)(x)), np.mean(x, axis=1))\n+        self.assertAllClose(\n             np.array(knp.Mean(axis=1, keepdims=True)(x)),\n             np.mean(x, axis=1, keepdims=True),\n         )\n \n     def test_all(self):\n         x = np.array([[True, False, True], [True, True, True]])\n-        np.testing.assert_array_equal(np.array(knp.all(x)), np.all(x))\n-        np.testing.assert_array_equal(\n-            np.array(knp.all(x, axis=1)), np.all(x, axis=1)\n-        )\n-        np.testing.assert_array_equal(\n+        self.assertAllClose(np.array(knp.all(x)), np.all(x))\n+        self.assertAllClose(np.array(knp.all(x, axis=1)), np.all(x, axis=1))\n+        self.assertAllClose(\n             np.array(knp.all(x, axis=1, keepdims=True)),\n             np.all(x, axis=1, keepdims=True),\n         )\n \n-        np.testing.assert_array_equal(np.array(knp.All()(x)), np.all(x))\n-        np.testing.assert_array_equal(\n-            np.array(knp.All(axis=1)(x)), np.all(x, axis=1)\n-        )\n-        np.testing.assert_array_equal(\n+        self.assertAllClose(np.array(knp.All()(x)), np.all(x))\n+        self.assertAllClose(np.array(knp.All(axis=1)(x)), np.all(x, axis=1))\n+        self.assertAllClose(\n             np.array(knp.All(axis=1, keepdims=True)(x)),\n             np.all(x, axis=1, keepdims=True),\n         )\n \n     def test_var(self):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n-        np.testing.assert_array_equal(np.array(knp.var(x)), np.var(x))\n-        np.testing.assert_array_equal(\n-            np.array(knp.var(x, axis=1)), np.var(x, axis=1)\n-        )\n-        np.testing.assert_array_equal(\n+        self.assertAllClose(np.array(knp.var(x)), np.var(x))\n+        self.assertAllClose(np.array(knp.var(x, axis=1)), np.var(x, axis=1))\n+        self.assertAllClose(\n             np.array(knp.var(x, axis=1, keepdims=True)),\n             np.var(x, axis=1, keepdims=True),\n         )\n \n-        np.testing.assert_array_equal(np.array(knp.Var()(x)), np.var(x))\n-        np.testing.assert_array_equal(\n-            np.array(knp.Var(axis=1)(x)), np.var(x, axis=1)\n-        )\n-        np.testing.assert_array_equal(\n+        self.assertAllClose(np.array(knp.Var()(x)), np.var(x))\n+        self.assertAllClose(np.array(knp.Var(axis=1)(x)), np.var(x, axis=1))\n+        self.assertAllClose(\n             np.array(knp.Var(axis=1, keepdims=True)(x)),\n             np.var(x, axis=1, keepdims=True),\n         )\n \n     def test_sum(self):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n-        np.testing.assert_array_equal(np.array(knp.sum(x)), np.sum(x))\n-        np.testing.assert_array_equal(\n-            np.array(knp.sum(x, axis=1)), np.sum(x, axis=1)\n-        )\n-        np.testing.assert_array_equal(\n+        self.assertAllClose(np.array(knp.sum(x)), np.sum(x))\n+        self.assertAllClose(np.array(knp.sum(x, axis=1)), np.sum(x, axis=1))\n+        self.assertAllClose(\n             np.array(knp.sum(x, axis=1, keepdims=True)),\n             np.sum(x, axis=1, keepdims=True),\n         )\n \n-        np.testing.assert_array_equal(np.array(knp.Sum()(x)), np.sum(x))\n-        np.testing.assert_array_equal(\n-            np.array(knp.Sum(axis=1)(x)), np.sum(x, axis=1)\n-        )\n-        np.testing.assert_array_equal(\n+        self.assertAllClose(np.array(knp.Sum()(x)), np.sum(x))\n+        self.assertAllClose(np.array(knp.Sum(axis=1)(x)), np.sum(x, axis=1))\n+        self.assertAllClose(\n             np.array(knp.Sum(axis=1, keepdims=True)(x)),\n             np.sum(x, axis=1, keepdims=True),\n         )\n \n     def test_amax(self):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n-        np.testing.assert_array_equal(np.array(knp.amax(x)), np.amax(x))\n-        np.testing.assert_array_equal(\n-            np.array(knp.amax(x, axis=1)), np.amax(x, axis=1)\n-        )\n-        np.testing.assert_array_equal(\n+        self.assertAllClose(np.array(knp.amax(x)), np.amax(x))\n+        self.assertAllClose(np.array(knp.amax(x, axis=1)), np.amax(x, axis=1))\n+        self.assertAllClose(\n             np.array(knp.amax(x, axis=1, keepdims=True)),\n             np.amax(x, axis=1, keepdims=True),\n         )\n \n-        np.testing.assert_array_equal(np.array(knp.Amax()(x)), np.amax(x))\n-        np.testing.assert_array_equal(\n-            np.array(knp.Amax(axis=1)(x)), np.amax(x, axis=1)\n-        )\n-        np.testing.assert_array_equal(\n+        self.assertAllClose(np.array(knp.Amax()(x)), np.amax(x))\n+        self.assertAllClose(np.array(knp.Amax(axis=1)(x)), np.amax(x, axis=1))\n+        self.assertAllClose(\n             np.array(knp.Amax(axis=1, keepdims=True)(x)),\n             np.amax(x, axis=1, keepdims=True),\n         )\n \n     def test_amin(self):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n-        np.testing.assert_array_equal(np.array(knp.amin(x)), np.amin(x))\n-        np.testing.assert_array_equal(\n-            np.array(knp.amin(x, axis=1)), np.amin(x, axis=1)\n-        )\n-        np.testing.assert_array_equal(\n+        self.assertAllClose(np.array(knp.amin(x)), np.amin(x))\n+        self.assertAllClose(np.array(knp.amin(x, axis=1)), np.amin(x, axis=1))\n+        self.assertAllClose(\n             np.array(knp.amin(x, axis=1, keepdims=True)),\n             np.amin(x, axis=1, keepdims=True),\n         )\n \n-        np.testing.assert_array_equal(np.array(knp.Amin()(x)), np.amin(x))\n-        np.testing.assert_array_equal(\n-            np.array(knp.Amin(axis=1)(x)), np.amin(x, axis=1)\n-        )\n-        np.testing.assert_array_equal(\n+        self.assertAllClose(np.array(knp.Amin()(x)), np.amin(x))\n+        self.assertAllClose(np.array(knp.Amin(axis=1)(x)), np.amin(x, axis=1))\n+        self.assertAllClose(\n             np.array(knp.Amin(axis=1, keepdims=True)(x)),\n             np.amin(x, axis=1, keepdims=True),\n         )\n \n     def test_square(self):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n-        np.testing.assert_array_equal(np.array(knp.square(x)), np.square(x))\n+        self.assertAllClose(np.array(knp.square(x)), np.square(x))\n \n-        np.testing.assert_array_equal(np.array(knp.Square()(x)), np.square(x))\n+        self.assertAllClose(np.array(knp.Square()(x)), np.square(x))\n \n     def test_negative(self):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n-        np.testing.assert_array_equal(np.array(knp.negative(x)), np.negative(x))\n+        self.assertAllClose(np.array(knp.negative(x)), np.negative(x))\n \n-        np.testing.assert_array_equal(\n-            np.array(knp.Negative()(x)), np.negative(x)\n-        )\n+        self.assertAllClose(np.array(knp.Negative()(x)), np.negative(x))\n \n     def test_abs(self):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n-        np.testing.assert_array_equal(np.array(knp.abs(x)), np.abs(x))\n+        self.assertAllClose(np.array(knp.abs(x)), np.abs(x))\n \n-        np.testing.assert_array_equal(np.array(knp.Abs()(x)), np.abs(x))\n+        self.assertAllClose(np.array(knp.Abs()(x)), np.abs(x))\n \n     def test_absolute(self):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n-        np.testing.assert_array_equal(np.array(knp.absolute(x)), np.absolute(x))\n+        self.assertAllClose(np.array(knp.absolute(x)), np.absolute(x))\n \n-        np.testing.assert_array_equal(\n-            np.array(knp.Absolute()(x)), np.absolute(x)\n-        )\n+        self.assertAllClose(np.array(knp.Absolute()(x)), np.absolute(x))\n \n     def test_squeeze(self):\n         x = np.ones([1, 2, 3, 4, 5])\n-        np.testing.assert_array_equal(np.array(knp.squeeze(x)), np.squeeze(x))\n-        np.testing.assert_array_equal(\n+        self.assertAllClose(np.array(knp.squeeze(x)), np.squeeze(x))\n+        self.assertAllClose(\n             np.array(knp.squeeze(x, axis=0)), np.squeeze(x, axis=0)\n         )\n \n-        np.testing.assert_array_equal(np.array(knp.Squeeze()(x)), np.squeeze(x))\n-        np.testing.assert_array_equal(\n+        self.assertAllClose(np.array(knp.Squeeze()(x)), np.squeeze(x))\n+        self.assertAllClose(\n             np.array(knp.Squeeze(axis=0)(x)), np.squeeze(x, axis=0)\n         )\n \n     def test_transpose(self):\n         x = np.ones([1, 2, 3, 4, 5])\n-        np.testing.assert_array_equal(\n-            np.array(knp.transpose(x)), np.transpose(x)\n-        )\n-        np.testing.assert_array_equal(\n+        self.assertAllClose(np.array(knp.transpose(x)), np.transpose(x))\n+        self.assertAllClose(\n             np.array(knp.transpose(x, axes=(1, 0, 3, 2, 4))),\n             np.transpose(x, axes=(1, 0, 3, 2, 4)),\n         )\n \n-        np.testing.assert_array_equal(\n-            np.array(knp.Transpose()(x)), np.transpose(x)\n-        )\n-        np.testing.assert_array_equal(\n+        self.assertAllClose(np.array(knp.Transpose()(x)), np.transpose(x))\n+        self.assertAllClose(\n             np.array(knp.Transpose(axes=(1, 0, 3, 2, 4))(x)),\n             np.transpose(x, axes=(1, 0, 3, 2, 4)),\n         )\n \n+    def test_arcos(self):\n+        x = np.array([[1, 0.5, -0.7], [0.9, 0.2, -1]])\n+        self.assertAllClose(np.array(knp.arccos(x)), np.arccos(x))\n+\n+        self.assertAllClose(np.array(knp.Arccos()(x)), np.arccos(x))\n+\n+    def test_arcsin(self):\n+        x = np.array([[1, 0.5, -0.7], [0.9, 0.2, -1]])\n+        self.assertAllClose(np.array(knp.arcsin(x)), np.arcsin(x))\n+\n+        self.assertAllClose(np.array(knp.Arcsin()(x)), np.arcsin(x))\n+\n+    def test_argmax(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        self.assertAllClose(np.array(knp.argmax(x)), np.argmax(x))\n+        self.assertAllClose(\n+            np.array(knp.argmax(x, axis=1)), np.argmax(x, axis=1)\n+        )\n+\n+        self.assertAllClose(np.array(knp.Argmax()(x)), np.argmax(x))\n+        self.assertAllClose(\n+            np.array(knp.Argmax(axis=1)(x)), np.argmax(x, axis=1)\n+        )\n+\n+    def test_argmin(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        self.assertAllClose(np.array(knp.argmin(x)), np.argmin(x))\n+        self.assertAllClose(\n+            np.array(knp.argmin(x, axis=1)), np.argmin(x, axis=1)\n+        )\n+\n+        self.assertAllClose(np.array(knp.Argmin()(x)), np.argmin(x))\n+        self.assertAllClose(\n+            np.array(knp.Argmin(axis=1)(x)), np.argmin(x, axis=1)\n+        )\n+\n+    def test_argsort(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        self.assertAllClose(np.array(knp.argsort(x)), np.argsort(x))\n+        self.assertAllClose(\n+            np.array(knp.argsort(x, axis=1)), np.argsort(x, axis=1)\n+        )\n+        self.assertAllClose(\n+            np.array(knp.argsort(x, axis=None)),\n+            np.argsort(x, axis=None),\n+        )\n+\n+        self.assertAllClose(np.array(knp.Argsort()(x)), np.argsort(x))\n+        self.assertAllClose(\n+            np.array(knp.Argsort(axis=1)(x)), np.argsort(x, axis=1)\n+        )\n+        self.assertAllClose(\n+            np.array(knp.Argsort(axis=None)(x)),\n+            np.argsort(x, axis=None),\n+        )\n+\n+    def test_array(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        self.assertAllClose(np.array(knp.array(x)), np.array(x))\n+        self.assertAllClose(np.array(knp.Array()(x)), np.array(x))\n+\n+    def test_average(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        weights = np.ones([2, 3])\n+        weights_1d = np.ones([3])\n+        self.assertAllClose(np.array(knp.average(x)), np.average(x))\n+        self.assertAllClose(\n+            np.array(knp.average(x, axis=1)), np.average(x, axis=1)\n+        )\n+        self.assertAllClose(\n+            np.array(knp.average(x, axis=1, weights=weights)),\n+            np.average(x, axis=1, weights=weights),\n+        )\n+        self.assertAllClose(\n+            np.array(knp.average(x, axis=1, weights=weights_1d)),\n+            np.average(x, axis=1, weights=weights_1d),\n+        )\n+\n+        self.assertAllClose(np.array(knp.Average()(x)), np.average(x))\n+        self.assertAllClose(\n+            np.array(knp.Average(axis=1)(x)), np.average(x, axis=1)\n+        )\n+        self.assertAllClose(\n+            np.array(knp.Average(axis=1)(x, weights=weights)),\n+            np.average(x, axis=1, weights=weights),\n+        )\n+        self.assertAllClose(\n+            np.array(knp.Average(axis=1)(x, weights=weights_1d)),\n+            np.average(x, axis=1, weights=weights_1d),\n+        )\n+\n+    def test_broadcast_to(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        self.assertAllClose(\n+            np.array(knp.broadcast_to(x, [2, 2, 3])),\n+            np.broadcast_to(x, [2, 2, 3]),\n+        )\n+\n+        self.assertAllClose(\n+            np.array(knp.BroadcastTo([2, 2, 3])(x)),\n+            np.broadcast_to(x, [2, 2, 3]),\n+        )\n+\n+    def test_ceil(self):\n+        x = np.array([[1.2, 2.1, -2.5], [2.4, -11.9, -5.5]])\n+        self.assertAllClose(np.array(knp.ceil(x)), np.ceil(x))\n+        self.assertAllClose(np.array(knp.Ceil()(x)), np.ceil(x))\n+\n+    def test_clip(self):\n+        x = np.array([[1.2, 2.1, -2.5], [2.4, -11.9, -5.5]])\n+        self.assertAllClose(np.array(knp.clip(x, -2, 2)), np.clip(x, -2, 2))\n+        self.assertAllClose(np.array(knp.clip(x, -2, 2)), np.clip(x, -2, 2))\n+\n+        self.assertAllClose(np.array(knp.Clip(0, 1)(x)), np.clip(x, 0, 1))\n+        self.assertAllClose(np.array(knp.Clip(0, 1)(x)), np.clip(x, 0, 1))\n+\n+    def test_concatenate(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        y = np.array([[4, 5, 6], [6, 5, 4]])\n+        z = np.array([[7, 8, 9], [9, 8, 7]])\n+        self.assertAllClose(\n+            np.array(knp.concatenate([x, y], axis=0)),\n+            np.concatenate([x, y], axis=0),\n+        )\n+        self.assertAllClose(\n+            np.array(knp.concatenate([x, y, z], axis=0)),\n+            np.concatenate([x, y, z], axis=0),\n+        )\n+        self.assertAllClose(\n+            np.array(knp.concatenate([x, y], axis=1)),\n+            np.concatenate([x, y], axis=1),\n+        )\n+\n+        self.assertAllClose(\n+            np.array(knp.Concatenate(axis=0)([x, y])),\n+            np.concatenate([x, y], axis=0),\n+        )\n+        self.assertAllClose(\n+            np.array(knp.Concatenate(axis=0)([x, y, z])),\n+            np.concatenate([x, y, z], axis=0),\n+        )\n+        self.assertAllClose(\n+            np.array(knp.Concatenate(axis=1)([x, y])),\n+            np.concatenate([x, y], axis=1),\n+        )\n+\n+    def test_conjugate(self):\n+        x = np.array([[1 + 2j, 2 + 3j], [3 + 4j, 4 + 5j]])\n+        self.assertAllClose(np.array(knp.conjugate(x)), np.conjugate(x))\n+        self.assertAllClose(np.array(knp.Conjugate()(x)), np.conjugate(x))\n+\n+    def test_conj(self):\n+        x = np.array([[1 + 2j, 2 + 3j], [3 + 4j, 4 + 5j]])\n+        self.assertAllClose(np.array(knp.conj(x)), np.conj(x))\n+        self.assertAllClose(np.array(knp.Conj()(x)), np.conj(x))\n+\n+    def test_copy(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        self.assertAllClose(np.array(knp.copy(x)), np.copy(x))\n+        self.assertAllClose(np.array(knp.Copy()(x)), np.copy(x))\n+\n+    def test_cos(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        self.assertAllClose(np.array(knp.cos(x)), np.cos(x))\n+        self.assertAllClose(np.array(knp.Cos()(x)), np.cos(x))\n+\n+    def test_count_nonzero(self):\n+        x = np.array([[0, 2, 3], [3, 2, 0]])\n+        self.assertAllClose(np.array(knp.count_nonzero(x)), np.count_nonzero(x))\n+        self.assertAllClose(\n+            np.array(knp.count_nonzero(x, axis=1)),\n+            np.count_nonzero(x, axis=1),\n+        )\n+\n+        self.assertAllClose(\n+            np.array(knp.CountNonzero()(x)),\n+            np.count_nonzero(x),\n+        )\n+        self.assertAllClose(\n+            np.array(knp.CountNonzero(axis=1)(x)),\n+            np.count_nonzero(x, axis=1),\n+        )\n+\n+    def test_cumprod(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        self.assertAllClose(np.array(knp.cumprod(x)), np.cumprod(x))\n+        self.assertAllClose(\n+            np.array(knp.cumprod(x, axis=0)),\n+            np.cumprod(x, axis=0),\n+        )\n+        self.assertAllClose(\n+            np.array(knp.cumprod(x, axis=None)),\n+            np.cumprod(x, axis=None),\n+        )\n+\n+        self.assertAllClose(np.array(knp.Cumprod()(x)), np.cumprod(x))\n+        self.assertAllClose(\n+            np.array(knp.Cumprod(axis=0)(x)),\n+            np.cumprod(x, axis=0),\n+        )\n+        self.assertAllClose(\n+            np.array(knp.Cumprod(axis=None)(x)),\n+            np.cumprod(x, axis=None),\n+        )\n+\n+    def test_cumsum(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        self.assertAllClose(np.array(knp.cumsum(x)), np.cumsum(x))\n+        self.assertAllClose(\n+            np.array(knp.cumsum(x, axis=0)),\n+            np.cumsum(x, axis=0),\n+        )\n+        self.assertAllClose(\n+            np.array(knp.cumsum(x, axis=1)),\n+            np.cumsum(x, axis=1),\n+        )\n+\n+        self.assertAllClose(np.array(knp.Cumsum()(x)), np.cumsum(x))\n+        self.assertAllClose(\n+            np.array(knp.Cumsum(axis=0)(x)),\n+            np.cumsum(x, axis=0),\n+        )\n+        self.assertAllClose(\n+            np.array(knp.Cumsum(axis=1)(x)),\n+            np.cumsum(x, axis=1),\n+        )\n+\n \n class NumpyArrayCreateOpsCorrectnessTest(testing.TestCase):\n     def test_ones(self):\n-        np.testing.assert_array_equal(\n-            np.array(knp.ones([2, 3])), np.ones([2, 3])\n-        )\n-        np.testing.assert_array_equal(\n-            np.array(knp.Ones()([2, 3])), np.ones([2, 3])\n-        )\n+        self.assertAllClose(np.array(knp.ones([2, 3])), np.ones([2, 3]))\n+        self.assertAllClose(np.array(knp.Ones()([2, 3])), np.ones([2, 3]))\n \n     def test_zeros(self):\n-        np.testing.assert_array_equal(\n-            np.array(knp.zeros([2, 3])), np.zeros([2, 3])\n-        )\n-        np.testing.assert_array_equal(\n-            np.array(knp.Zeros()([2, 3])), np.zeros([2, 3])\n-        )\n+        self.assertAllClose(np.array(knp.zeros([2, 3])), np.zeros([2, 3]))\n+        self.assertAllClose(np.array(knp.Zeros()([2, 3])), np.zeros([2, 3]))\n \n     def test_eye(self):\n-        np.testing.assert_array_equal(np.array(knp.eye(3)), np.eye(3))\n-        np.testing.assert_array_equal(np.array(knp.eye(3, 4)), np.eye(3, 4))\n-        np.testing.assert_array_equal(\n-            np.array(knp.eye(3, 4, 1)), np.eye(3, 4, 1)\n-        )\n+        self.assertAllClose(np.array(knp.eye(3)), np.eye(3))\n+        self.assertAllClose(np.array(knp.eye(3, 4)), np.eye(3, 4))\n+        self.assertAllClose(np.array(knp.eye(3, 4, 1)), np.eye(3, 4, 1))\n \n-        np.testing.assert_array_equal(np.array(knp.Eye()(3)), np.eye(3))\n-        np.testing.assert_array_equal(np.array(knp.Eye()(3, 4)), np.eye(3, 4))\n-        np.testing.assert_array_equal(\n-            np.array(knp.Eye()(3, 4, 1)), np.eye(3, 4, 1)\n-        )\n+        self.assertAllClose(np.array(knp.Eye()(3)), np.eye(3))\n+        self.assertAllClose(np.array(knp.Eye()(3, 4)), np.eye(3, 4))\n+        self.assertAllClose(np.array(knp.Eye()(3, 4, 1)), np.eye(3, 4, 1))\n+\n+    def test_arange(self):\n+        self.assertAllClose(np.array(knp.arange(3)), np.arange(3))\n+        self.assertAllClose(np.array(knp.arange(3, 7)), np.arange(3, 7))\n+        self.assertAllClose(np.array(knp.arange(3, 7, 2)), np.arange(3, 7, 2))\n+\n+        self.assertAllClose(np.array(knp.Arange()(3)), np.arange(3))\n+        self.assertAllClose(np.array(knp.Arange()(3, 7)), np.arange(3, 7))\n+        self.assertAllClose(np.array(knp.Arange()(3, 7, 2)), np.arange(3, 7, 2))\n\n@@ -9,6 +9,13 @@ from keras_core.utils import dtype_utils\n from keras_core.utils import io_utils\n from keras_core.utils import text_rendering\n \n+from tensorflow import nest\n+\n+from keras_core import backend\n+from keras_core.utils import dtype_utils\n+from keras_core.utils import io_utils\n+from keras_core.utils import text_rendering\n+\n \n def count_params(weights):\n     shapes = [v.shape for v in weights]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
