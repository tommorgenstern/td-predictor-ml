{"custom_id": "keras#60d1b047184bf1de869b98f4337b49fafac78d36", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 5 | Churn Cumulative: 686 | Contributors (this commit): 4 | Commits (past 90d): 7 | Contributors (cumulative): 4 | DMM Complexity: 0.0\n\nDIFF:\n@@ -419,10 +419,13 @@ def conv_transpose(\n     kernel_spatial_shape = kernel.shape[2:]\n     padding_arg = []\n     output_padding_arg = []\n+    if isinstance(dilation_rate, int):\n+        dilation_rate = [dilation_rate] * len(kernel_spatial_shape)\n     for i, value in enumerate(padding_values):\n         total_padding = value[0] + value[1]\n         padding_arg.append(\n-            dilation_rate * (kernel_spatial_shape[i] - 1) - total_padding // 2\n+            dilation_rate[i] * (kernel_spatial_shape[i] - 1)\n+            - total_padding // 2\n         )\n         if total_padding % 2 == 0:\n             output_padding_arg.append(0)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3b442816aaa861289c0e851e5966bdddf61b54b7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 28 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 28 | Methods Changed: 14 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 28 | Churn Cumulative: 747 | Contributors (this commit): 2 | Commits (past 90d): 5 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -45,12 +45,14 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n+                backend.convert_to_numpy(\n                     add_layer.compute_mask(\n                         [input_1, input_2],\n                         [backend.Variable(x1), backend.Variable(x2)],\n                     )\n                 )\n             )\n+        )\n \n     def test_add_correctness_static(self):\n         batch_size = 2\n@@ -73,12 +75,14 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n+                backend.convert_to_numpy(\n                     add_layer.compute_mask(\n                         [input_1, input_2],\n                         [backend.Variable(x1), backend.Variable(x2)],\n                     )\n                 )\n             )\n+        )\n \n     def test_add_errors(self):\n         batch_size = 2\n@@ -136,12 +140,14 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n+                backend.convert_to_numpy(\n                     subtract_layer.compute_mask(\n                         [input_1, input_2],\n                         [backend.Variable(x1), backend.Variable(x2)],\n                     )\n                 )\n             )\n+        )\n \n     def test_subtract_correctness_static(self):\n         batch_size = 2\n@@ -164,12 +170,14 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n+                backend.convert_to_numpy(\n                     subtract_layer.compute_mask(\n                         [input_1, input_2],\n                         [backend.Variable(x1), backend.Variable(x2)],\n                     )\n                 )\n             )\n+        )\n \n     def test_subtract_errors(self):\n         batch_size = 2\n@@ -236,12 +244,14 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n+                backend.convert_to_numpy(\n                     merge_layer.compute_mask(\n                         [input_1, input_2],\n                         [backend.Variable(x1), backend.Variable(x2)],\n                     )\n                 )\n             )\n+        )\n \n     def test_minimum_correctness_static(self):\n         batch_size = 2\n@@ -264,12 +274,14 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n+                backend.convert_to_numpy(\n                     merge_layer.compute_mask(\n                         [input_1, input_2],\n                         [backend.Variable(x1), backend.Variable(x2)],\n                     )\n                 )\n             )\n+        )\n \n     def test_minimum_errors(self):\n         batch_size = 2\n@@ -327,12 +339,14 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n+                backend.convert_to_numpy(\n                     merge_layer.compute_mask(\n                         [input_1, input_2],\n                         [backend.Variable(x1), backend.Variable(x2)],\n                     )\n                 )\n             )\n+        )\n \n     def test_maximum_correctness_static(self):\n         batch_size = 2\n@@ -355,12 +369,14 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n+                backend.convert_to_numpy(\n                     merge_layer.compute_mask(\n                         [input_1, input_2],\n                         [backend.Variable(x1), backend.Variable(x2)],\n                     )\n                 )\n             )\n+        )\n \n     def test_maximum_errors(self):\n         batch_size = 2\n@@ -418,12 +434,14 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n+                backend.convert_to_numpy(\n                     merge_layer.compute_mask(\n                         [input_1, input_2],\n                         [backend.Variable(x1), backend.Variable(x2)],\n                     )\n                 )\n             )\n+        )\n \n     def test_multiply_correctness_static(self):\n         batch_size = 2\n@@ -446,12 +464,14 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n+                backend.convert_to_numpy(\n                     merge_layer.compute_mask(\n                         [input_1, input_2],\n                         [backend.Variable(x1), backend.Variable(x2)],\n                     )\n                 )\n             )\n+        )\n \n     def test_multiply_errors(self):\n         batch_size = 2\n@@ -509,12 +529,14 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n+                backend.convert_to_numpy(\n                     merge_layer.compute_mask(\n                         [input_1, input_2],\n                         [backend.Variable(x1), backend.Variable(x2)],\n                     )\n                 )\n             )\n+        )\n \n     def test_average_correctness_static(self):\n         batch_size = 2\n@@ -537,12 +559,14 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n+                backend.convert_to_numpy(\n                     merge_layer.compute_mask(\n                         [input_1, input_2],\n                         [backend.Variable(x1), backend.Variable(x2)],\n                     )\n                 )\n             )\n+        )\n \n     def test_average_errors(self):\n         batch_size = 2\n@@ -602,12 +626,14 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n+                backend.convert_to_numpy(\n                     merge_layer.compute_mask(\n                         [input_1, input_2],\n                         [backend.Variable(x1), backend.Variable(x2)],\n                     )\n                 )\n             )\n+        )\n \n     def test_concatenate_correctness_static(self):\n         batch_size = 2\n@@ -631,12 +657,14 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n+                backend.convert_to_numpy(\n                     merge_layer.compute_mask(\n                         [input_1, input_2],\n                         [x1, x2],\n                     )\n                 )\n             )\n+        )\n \n     def test_concatenate_errors(self):\n         batch_size = 2\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#09614a78146ba9d1c2009aca53a5ff40b31b8ab6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 16 | Churn Cumulative: 1168 | Contributors (this commit): 3 | Commits (past 90d): 9 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -171,6 +171,10 @@ class GroupNormalization(Layer):\n \n         if mask is None:\n             mask = tf.ones_like(inputs)\n+        else:\n+            # We broadcast before we group in case the mask does not have the\n+            # same shape as the input.\n+            mask = tf.broadcast_to(mask, input_shape)\n \n         reshaped_inputs = self._reshape_into_groups(inputs)\n         reshaped_mask = self._reshape_into_groups(mask)\n\n@@ -266,6 +266,18 @@ class GroupNormalizationTest(test_combinations.TestCase):\n             atol=1e-3,\n         )\n \n+    @test_combinations.run_all_keras_modes\n+    def test_mask_broadcasting(self):\n+        images = tf.ones((1, 2, 4, 3))  # NHWC\n+        mask = tf.random.uniform((1, 2, 4, 1)) < 0.5  # NHWC\n+\n+        norm = GroupNormalization(\n+            groups=3, axis=-1, input_shape=(2, 4, 9), scale=False, center=False\n+        )\n+        output = norm(images, mask=mask)\n+\n+        self.assertEqual(output.shape, (1, 2, 4, 3))\n+\n     @test_combinations.run_all_keras_modes\n     def test_correctness_instance_norm(self):\n         instance_norm_layer = GroupNormalization(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9e55bf4a767142d8834446cc7d2bafeddf7289d0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 122 | Lines Deleted: 39 | Files Changed: 15 | Hunks: 55 | Methods Changed: 33 | Complexity Δ (Sum/Max): 26/4 | Churn Δ: 161 | Churn Cumulative: 3366 | Contributors (this commit): 4 | Commits (past 90d): 55 | Contributors (cumulative): 21 | DMM Complexity: 1.0\n\nDIFF:\n@@ -45,14 +45,12 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n-                backend.convert_to_numpy(\n                 add_layer.compute_mask(\n                     [input_1, input_2],\n                     [backend.Variable(x1), backend.Variable(x2)],\n                 )\n             )\n         )\n-        )\n \n     def test_add_correctness_static(self):\n         batch_size = 2\n@@ -75,14 +73,12 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n-                backend.convert_to_numpy(\n                 add_layer.compute_mask(\n                     [input_1, input_2],\n                     [backend.Variable(x1), backend.Variable(x2)],\n                 )\n             )\n         )\n-        )\n \n     def test_add_errors(self):\n         batch_size = 2\n@@ -140,14 +136,12 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n-                backend.convert_to_numpy(\n                 subtract_layer.compute_mask(\n                     [input_1, input_2],\n                     [backend.Variable(x1), backend.Variable(x2)],\n                 )\n             )\n         )\n-        )\n \n     def test_subtract_correctness_static(self):\n         batch_size = 2\n@@ -170,14 +164,12 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n-                backend.convert_to_numpy(\n                 subtract_layer.compute_mask(\n                     [input_1, input_2],\n                     [backend.Variable(x1), backend.Variable(x2)],\n                 )\n             )\n         )\n-        )\n \n     def test_subtract_errors(self):\n         batch_size = 2\n@@ -244,14 +236,12 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n-                backend.convert_to_numpy(\n                 merge_layer.compute_mask(\n                     [input_1, input_2],\n                     [backend.Variable(x1), backend.Variable(x2)],\n                 )\n             )\n         )\n-        )\n \n     def test_minimum_correctness_static(self):\n         batch_size = 2\n@@ -274,14 +264,12 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n-                backend.convert_to_numpy(\n                 merge_layer.compute_mask(\n                     [input_1, input_2],\n                     [backend.Variable(x1), backend.Variable(x2)],\n                 )\n             )\n         )\n-        )\n \n     def test_minimum_errors(self):\n         batch_size = 2\n@@ -339,14 +327,12 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n-                backend.convert_to_numpy(\n                 merge_layer.compute_mask(\n                     [input_1, input_2],\n                     [backend.Variable(x1), backend.Variable(x2)],\n                 )\n             )\n         )\n-        )\n \n     def test_maximum_correctness_static(self):\n         batch_size = 2\n@@ -369,14 +355,12 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n-                backend.convert_to_numpy(\n                 merge_layer.compute_mask(\n                     [input_1, input_2],\n                     [backend.Variable(x1), backend.Variable(x2)],\n                 )\n             )\n         )\n-        )\n \n     def test_maximum_errors(self):\n         batch_size = 2\n@@ -434,14 +418,12 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n-                backend.convert_to_numpy(\n                 merge_layer.compute_mask(\n                     [input_1, input_2],\n                     [backend.Variable(x1), backend.Variable(x2)],\n                 )\n             )\n         )\n-        )\n \n     def test_multiply_correctness_static(self):\n         batch_size = 2\n@@ -464,14 +446,12 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n-                backend.convert_to_numpy(\n                 merge_layer.compute_mask(\n                     [input_1, input_2],\n                     [backend.Variable(x1), backend.Variable(x2)],\n                 )\n             )\n         )\n-        )\n \n     def test_multiply_errors(self):\n         batch_size = 2\n@@ -529,14 +509,12 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n-                backend.convert_to_numpy(\n                 merge_layer.compute_mask(\n                     [input_1, input_2],\n                     [backend.Variable(x1), backend.Variable(x2)],\n                 )\n             )\n         )\n-        )\n \n     def test_average_correctness_static(self):\n         batch_size = 2\n@@ -559,14 +537,12 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n-                backend.convert_to_numpy(\n                 merge_layer.compute_mask(\n                     [input_1, input_2],\n                     [backend.Variable(x1), backend.Variable(x2)],\n                 )\n             )\n         )\n-        )\n \n     def test_average_errors(self):\n         batch_size = 2\n@@ -626,14 +602,12 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n-                backend.convert_to_numpy(\n                 merge_layer.compute_mask(\n                     [input_1, input_2],\n                     [backend.Variable(x1), backend.Variable(x2)],\n                 )\n             )\n         )\n-        )\n \n     def test_concatenate_correctness_static(self):\n         batch_size = 2\n@@ -657,14 +631,12 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n-                backend.convert_to_numpy(\n                 merge_layer.compute_mask(\n                     [input_1, input_2],\n                     [x1, x2],\n                 )\n             )\n         )\n-        )\n \n     def test_concatenate_errors(self):\n         batch_size = 2\n\n@@ -118,6 +118,11 @@ class Discretization(Layer):\n         self.bin_boundaries = (\n             bin_boundaries if bin_boundaries is not None else []\n         )\n+        if self.bin_boundaries:\n+            self.built = True\n+        self._convert_input_args = False\n+        self._allow_non_tensor_positional_args = True\n+\n         self.num_bins = num_bins\n         self.epsilon = epsilon\n         self.output_mode = output_mode\n@@ -178,11 +183,16 @@ class Discretization(Layer):\n     def compute_output_shape(self, input_shape):\n         return input_shape\n \n-    def call(self, inputs):\n-        if not isinstance(inputs, (tf.Tensor, np.ndarray)):\n+    def __call__(self, inputs):\n+        if not isinstance(inputs, (tf.Tensor, np.ndarray, backend.KerasTensor)):\n             inputs = tf.convert_to_tensor(np.array(inputs))\n+        if not self.built:\n+            self.build(inputs.shape)\n+        return super().__call__(inputs)\n+\n+    def call(self, inputs):\n         outputs = self.layer.call(inputs)\n-        if backend.backend() != \"tensorflow\":\n+        if backend.backend() != \"tensorflow\" and tf.executing_eagerly():\n             outputs = backend.convert_to_tensor(outputs)\n         return outputs\n \n\n@@ -1,4 +1,5 @@\n import numpy as np\n+import tensorflow as tf\n \n from keras_core import backend\n from keras_core import layers\n@@ -36,3 +37,22 @@ class DicretizationTest(testing.TestCase):\n         output = layer(np.array([[0.0, 0.1, 0.8]]))\n         self.assertTrue(backend.is_tensor(output))\n         self.assertAllClose(output, np.array([[1, 1, 2]]))\n+\n+    def test_tf_data_compatibility(self):\n+        layer = layers.Discretization(bin_boundaries=[0.0, 0.5, 1.0])\n+        x = np.array([[0.0, 0.1, 0.8]])\n+        ds = tf.data.Dataset.from_tensor_slices(x).batch(1).map(layer)\n+        for output in ds.take(1):\n+            output = output.numpy()\n+        self.assertAllClose(output, np.array([[1, 1, 2]]))\n+\n+        # With adapt flow\n+        layer = layers.Discretization(num_bins=4)\n+        layer.adapt(\n+            np.random.random((32, 3)),\n+            batch_size=8,\n+        )\n+        x = np.array([[0.0, 0.1, 0.3]])\n+        ds = tf.data.Dataset.from_tensor_slices(x).batch(1).map(layer)\n+        for output in ds.take(1):\n+            output.numpy()\n\n@@ -175,7 +175,7 @@ class Hashing(Layer):\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n             inputs = tf.convert_to_tensor(np.array(inputs))\n         outputs = self.layer.call(inputs)\n-        if backend.backend() != \"tensorflow\":\n+        if backend.backend() != \"tensorflow\" and tf.executing_eagerly():\n             outputs = backend.convert_to_tensor(outputs)\n         return outputs\n \n\n@@ -1,4 +1,5 @@\n import numpy as np\n+import tensorflow as tf\n \n from keras_core import backend\n from keras_core import layers\n@@ -37,3 +38,11 @@ class TextVectorizationTest(testing.TestCase):\n         output = layer(inp)\n         self.assertTrue(backend.is_tensor(output))\n         self.assertAllClose(output, np.array([[0], [0], [2], [1], [0]]))\n+\n+    def test_tf_data_compatibility(self):\n+        layer = layers.Hashing(num_bins=3)\n+        inp = [[\"A\"], [\"B\"], [\"C\"], [\"D\"], [\"E\"]]\n+        ds = tf.data.Dataset.from_tensor_slices(inp).batch(5).map(layer)\n+        for output in ds.take(1):\n+            output = output.numpy()\n+        self.assertAllClose(output, np.array([[1], [0], [1], [1], [2]]))\n\n@@ -327,6 +327,7 @@ class IntegerLookup(Layer):\n             name=name,\n             **kwargs,\n         )\n+        self._convert_input_args = False\n         self._allow_non_tensor_positional_args = True\n         self.supports_jit = False\n \n@@ -440,7 +441,7 @@ class IntegerLookup(Layer):\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n             inputs = tf.convert_to_tensor(np.array(inputs))\n         outputs = self.layer.call(inputs)\n-        if backend.backend() != \"tensorflow\":\n+        if backend.backend() != \"tensorflow\" and tf.executing_eagerly():\n             outputs = backend.convert_to_tensor(outputs)\n         return outputs\n \n\n@@ -1,4 +1,5 @@\n import numpy as np\n+import tensorflow as tf\n \n from keras_core import backend\n from keras_core import layers\n@@ -44,3 +45,14 @@ class IntegerLookupTest(testing.TestCase):\n         output = layer(input_data)\n         self.assertTrue(backend.is_tensor(output))\n         self.assertAllClose(output, np.array([2, 3, 4, 0]))\n+\n+    def test_tf_data_compatibility(self):\n+        layer = layers.IntegerLookup(\n+            output_mode=\"int\",\n+            vocabulary=[1, 2, 3, 4],\n+        )\n+        input_data = [2, 3, 4, 5]\n+        ds = tf.data.Dataset.from_tensor_slices(input_data).batch(4).map(layer)\n+        for output in ds.take(1):\n+            output = output.numpy()\n+        self.assertAllClose(output, np.array([2, 3, 4, 0]))\n\n@@ -94,12 +94,14 @@ class RandomRotation(Layer):\n             **kwargs,\n         )\n         self.supports_jit = False\n+        self._convert_input_args = False\n+        self._allow_non_tensor_positional_args = True\n \n     def call(self, inputs, training=True):\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n             inputs = tf.convert_to_tensor(np.array(inputs))\n-        outputs = self.layer.call(inputs)\n-        if backend.backend() != \"tensorflow\":\n+        outputs = self.layer.call(inputs, training=training)\n+        if backend.backend() != \"tensorflow\" and tf.executing_eagerly():\n             outputs = backend.convert_to_tensor(outputs)\n         return outputs\n \n\n@@ -1,4 +1,5 @@\n import numpy as np\n+import tensorflow as tf\n from absl.testing import parameterized\n \n from keras_core import backend\n@@ -49,3 +50,10 @@ class RandomRotationTest(testing.TestCase, parameterized.TestCase):\n             supports_masking=False,\n             run_training_check=False,\n         )\n+\n+    def test_tf_data_compatibility(self):\n+        layer = layers.RandomRotation(0.2)\n+        input_data = np.random.random((1, 4, 4, 3))\n+        ds = tf.data.Dataset.from_tensor_slices(input_data).batch(1).map(layer)\n+        for output in ds.take(1):\n+            output.numpy()\n\n@@ -84,12 +84,14 @@ class RandomTranslation(Layer):\n             **kwargs,\n         )\n         self.supports_jit = False\n+        self._convert_input_args = False\n+        self._allow_non_tensor_positional_args = True\n \n     def call(self, inputs, training=True):\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n             inputs = tf.convert_to_tensor(np.array(inputs))\n-        outputs = self.layer.call(inputs)\n-        if backend.backend() != \"tensorflow\":\n+        outputs = self.layer.call(inputs, training=training)\n+        if backend.backend() != \"tensorflow\" and tf.executing_eagerly():\n             outputs = backend.convert_to_tensor(outputs)\n         return outputs\n \n\n@@ -1,4 +1,5 @@\n import numpy as np\n+import tensorflow as tf\n from absl.testing import parameterized\n \n from keras_core import backend\n@@ -229,3 +230,10 @@ class RandomTranslationTest(testing.TestCase, parameterized.TestCase):\n             supports_masking=False,\n             run_training_check=False,\n         )\n+\n+    def test_tf_data_compatibility(self):\n+        layer = layers.RandomTranslation(0.2, 0.1)\n+        input_data = np.random.random((1, 4, 4, 3))\n+        ds = tf.data.Dataset.from_tensor_slices(input_data).batch(1).map(layer)\n+        for output in ds.take(1):\n+            output.numpy()\n\n@@ -435,7 +435,7 @@ class StringLookup(Layer):\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n             inputs = tf.convert_to_tensor(np.array(inputs))\n         outputs = self.layer.call(inputs)\n-        if backend.backend() != \"tensorflow\":\n+        if backend.backend() != \"tensorflow\" and tf.executing_eagerly():\n             outputs = backend.convert_to_tensor(outputs)\n         return outputs\n \n\n@@ -1,4 +1,5 @@\n import numpy as np\n+import tensorflow as tf\n \n from keras_core import backend\n from keras_core import layers\n@@ -44,3 +45,14 @@ class StringLookupTest(testing.TestCase):\n         output = layer(input_data)\n         self.assertTrue(backend.is_tensor(output))\n         self.assertAllClose(output, np.array([2, 3, 0]))\n+\n+    def test_tf_data_compatibility(self):\n+        layer = layers.StringLookup(\n+            output_mode=\"int\",\n+            vocabulary=[\"a\", \"b\", \"c\"],\n+        )\n+        input_data = [\"b\", \"c\", \"d\"]\n+        ds = tf.data.Dataset.from_tensor_slices(input_data).batch(3).map(layer)\n+        for output in ds.take(1):\n+            output = output.numpy()\n+        self.assertAllClose(output, np.array([2, 3, 0]))\n\n@@ -358,7 +358,7 @@ class TextVectorization(Layer):\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n             inputs = tf.convert_to_tensor(np.array(inputs))\n         outputs = self.layer.call(inputs)\n-        if backend.backend() != \"tensorflow\":\n+        if backend.backend() != \"tensorflow\" and tf.executing_eagerly():\n             outputs = backend.convert_to_tensor(outputs)\n         return outputs\n \n\n@@ -1,4 +1,5 @@\n import numpy as np\n+import tensorflow as tf\n \n from keras_core import backend\n from keras_core import layers\n@@ -55,3 +56,29 @@ class TextVectorizationTest(testing.TestCase):\n         output = layer(input_data)\n         self.assertTrue(backend.is_tensor(output))\n         self.assertAllClose(output, np.array([[4, 1, 3, 0], [1, 2, 0, 0]]))\n+\n+    def test_tf_data_compatibility(self):\n+        max_tokens = 5000\n+        max_len = 4\n+        layer = layers.TextVectorization(\n+            max_tokens=max_tokens,\n+            output_mode=\"int\",\n+            output_sequence_length=max_len,\n+            vocabulary=[\"baz\", \"bar\", \"foo\"],\n+        )\n+        input_data = [[\"foo qux bar\"], [\"qux baz\"]]\n+        ds = tf.data.Dataset.from_tensor_slices(input_data).batch(2).map(layer)\n+        for output in ds.take(1):\n+            output = output.numpy()\n+        self.assertAllClose(output, np.array([[4, 1, 3, 0], [1, 2, 0, 0]]))\n+\n+        # Test adapt flow\n+        layer = layers.TextVectorization(\n+            max_tokens=max_tokens,\n+            output_mode=\"int\",\n+            output_sequence_length=max_len,\n+        )\n+        layer.adapt(input_data)\n+        ds = tf.data.Dataset.from_tensor_slices(input_data).batch(2).map(layer)\n+        for output in ds.take(1):\n+            output.numpy()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7d5b06ec43e18e911c6d1437b6d6ee4ef8a5c283", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 28 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 28 | Methods Changed: 14 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 28 | Churn Cumulative: 803 | Contributors (this commit): 3 | Commits (past 90d): 7 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -45,12 +45,14 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n+                backend.convert_to_numpy(\n                     add_layer.compute_mask(\n                         [input_1, input_2],\n                         [backend.Variable(x1), backend.Variable(x2)],\n                     )\n                 )\n             )\n+        )\n \n     def test_add_correctness_static(self):\n         batch_size = 2\n@@ -73,12 +75,14 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n+                backend.convert_to_numpy(\n                     add_layer.compute_mask(\n                         [input_1, input_2],\n                         [backend.Variable(x1), backend.Variable(x2)],\n                     )\n                 )\n             )\n+        )\n \n     def test_add_errors(self):\n         batch_size = 2\n@@ -136,12 +140,14 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n+                backend.convert_to_numpy(\n                     subtract_layer.compute_mask(\n                         [input_1, input_2],\n                         [backend.Variable(x1), backend.Variable(x2)],\n                     )\n                 )\n             )\n+        )\n \n     def test_subtract_correctness_static(self):\n         batch_size = 2\n@@ -164,12 +170,14 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n+                backend.convert_to_numpy(\n                     subtract_layer.compute_mask(\n                         [input_1, input_2],\n                         [backend.Variable(x1), backend.Variable(x2)],\n                     )\n                 )\n             )\n+        )\n \n     def test_subtract_errors(self):\n         batch_size = 2\n@@ -236,12 +244,14 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n+                backend.convert_to_numpy(\n                     merge_layer.compute_mask(\n                         [input_1, input_2],\n                         [backend.Variable(x1), backend.Variable(x2)],\n                     )\n                 )\n             )\n+        )\n \n     def test_minimum_correctness_static(self):\n         batch_size = 2\n@@ -264,12 +274,14 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n+                backend.convert_to_numpy(\n                     merge_layer.compute_mask(\n                         [input_1, input_2],\n                         [backend.Variable(x1), backend.Variable(x2)],\n                     )\n                 )\n             )\n+        )\n \n     def test_minimum_errors(self):\n         batch_size = 2\n@@ -327,12 +339,14 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n+                backend.convert_to_numpy(\n                     merge_layer.compute_mask(\n                         [input_1, input_2],\n                         [backend.Variable(x1), backend.Variable(x2)],\n                     )\n                 )\n             )\n+        )\n \n     def test_maximum_correctness_static(self):\n         batch_size = 2\n@@ -355,12 +369,14 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n+                backend.convert_to_numpy(\n                     merge_layer.compute_mask(\n                         [input_1, input_2],\n                         [backend.Variable(x1), backend.Variable(x2)],\n                     )\n                 )\n             )\n+        )\n \n     def test_maximum_errors(self):\n         batch_size = 2\n@@ -418,12 +434,14 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n+                backend.convert_to_numpy(\n                     merge_layer.compute_mask(\n                         [input_1, input_2],\n                         [backend.Variable(x1), backend.Variable(x2)],\n                     )\n                 )\n             )\n+        )\n \n     def test_multiply_correctness_static(self):\n         batch_size = 2\n@@ -446,12 +464,14 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n+                backend.convert_to_numpy(\n                     merge_layer.compute_mask(\n                         [input_1, input_2],\n                         [backend.Variable(x1), backend.Variable(x2)],\n                     )\n                 )\n             )\n+        )\n \n     def test_multiply_errors(self):\n         batch_size = 2\n@@ -509,12 +529,14 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n+                backend.convert_to_numpy(\n                     merge_layer.compute_mask(\n                         [input_1, input_2],\n                         [backend.Variable(x1), backend.Variable(x2)],\n                     )\n                 )\n             )\n+        )\n \n     def test_average_correctness_static(self):\n         batch_size = 2\n@@ -537,12 +559,14 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n+                backend.convert_to_numpy(\n                     merge_layer.compute_mask(\n                         [input_1, input_2],\n                         [backend.Variable(x1), backend.Variable(x2)],\n                     )\n                 )\n             )\n+        )\n \n     def test_average_errors(self):\n         batch_size = 2\n@@ -602,12 +626,14 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n+                backend.convert_to_numpy(\n                     merge_layer.compute_mask(\n                         [input_1, input_2],\n                         [backend.Variable(x1), backend.Variable(x2)],\n                     )\n                 )\n             )\n+        )\n \n     def test_concatenate_correctness_static(self):\n         batch_size = 2\n@@ -631,12 +657,14 @@ class MergingLayersTest(testing.TestCase):\n         )\n         self.assertTrue(\n             np.all(\n+                backend.convert_to_numpy(\n                     merge_layer.compute_mask(\n                         [input_1, input_2],\n                         [x1, x2],\n                     )\n                 )\n             )\n+        )\n \n     def test_concatenate_errors(self):\n         batch_size = 2\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b00a8e0e333cb9bd9aa26c645ee6f90d5b5b0d18", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 39 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 7 | Methods Changed: 6 | Complexity Δ (Sum/Max): 7/6 | Churn Δ: 41 | Churn Cumulative: 13774 | Contributors (this commit): 118 | Commits (past 90d): 14 | Contributors (cumulative): 123 | DMM Complexity: 0.56\n\nDIFF:\n@@ -1519,9 +1519,12 @@ class ModelCheckpoint(Callback):\n             self.epochs_since_last_save = 0\n             filepath = self._get_file_path(epoch, batch, logs)\n \n-            # Create host directory if it doesn't exist.\n             dirname = os.path.dirname(filepath)\n-            if dirname and not tf.io.gfile.exists(dirname):\n+            if (\n+                dirname\n+                and not dirname.startswith(\"gs://\")\n+                and not tf.io.gfile.exists(dirname)\n+            ):\n                 tf.io.gfile.makedirs(dirname)\n \n             try:\n\n@@ -30,6 +30,21 @@ try:\n except ImportError:\n     h5py = None\n \n+is_oss = True\n+\n+\n+def _support_gcs_uri(filepath, save_format, is_oss):\n+    \"\"\"Supports GCS URIs through bigstore via a temporary file.\"\"\"\n+    gs_filepath = None\n+    if str(filepath).startswith(\"gs://\") and save_format != \"tf\":\n+        gs_filepath = filepath\n+        if not is_oss:\n+            gs_filepath = filepath.replace(\"gs://\", \"/bigstore/\")\n+        filepath = os.path.join(\n+            saving_lib.get_temp_dir(), os.path.basename(gs_filepath)\n+        )\n+    return gs_filepath, filepath\n+\n \n @keras_export(\"keras.saving.save_model\", \"keras.models.save_model\")\n def save_model(model, filepath, overwrite=True, save_format=None, **kwargs):\n@@ -118,6 +133,9 @@ def save_model(model, filepath, overwrite=True, save_format=None, **kwargs):\n     \"\"\"\n     save_format = get_save_format(filepath, save_format)\n \n+    # Supports GCS URIs through bigstore via a temporary file\n+    gs_filepath, filepath = _support_gcs_uri(filepath, save_format, is_oss)\n+\n     # Deprecation warnings\n     if save_format == \"h5\":\n         warnings.warn(\n@@ -199,6 +217,12 @@ def load_model(\n     It is recommended that you use layer attributes to\n     access specific variables, e.g. `model.get_layer(\"dense_1\").kernel`.\n     \"\"\"\n+    # Supports GCS URIs by copying data to temporary file\n+    save_format = get_save_format(filepath, save_format=None)\n+    gs_filepath, filepath = _support_gcs_uri(filepath, save_format, is_oss)\n+    if gs_filepath is not None:\n+        tf.io.gfile.copy(gs_filepath, filepath, overwrite=True)\n+\n     is_keras_zip = str(filepath).endswith(\".keras\") and zipfile.is_zipfile(\n         filepath\n     )\n@@ -241,6 +265,10 @@ def load_model(\n \n \n def save_weights(model, filepath, overwrite=True, **kwargs):\n+    # Supports GCS URIs through bigstore via a temporary file\n+    save_format = get_save_format(filepath, save_format=None)\n+    gs_filepath, filepath = _support_gcs_uri(filepath, save_format, is_oss)\n+\n     if str(filepath).endswith(\".weights.h5\"):\n         # If file exists and should not be overwritten.\n         try:\n@@ -259,6 +287,12 @@ def save_weights(model, filepath, overwrite=True, **kwargs):\n \n \n def load_weights(model, filepath, skip_mismatch=False, **kwargs):\n+    # Supports GCS URIs by copying data to temporary file\n+    save_format = get_save_format(filepath, save_format=None)\n+    gs_filepath, filepath = _support_gcs_uri(filepath, save_format, is_oss)\n+    if gs_filepath is not None:\n+        tf.io.gfile.copy(gs_filepath, filepath, overwrite=True)\n+\n     if str(filepath).endswith(\".keras\") and zipfile.is_zipfile(filepath):\n         saving_lib.load_weights_only(\n             model, filepath, skip_mismatch=skip_mismatch\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#af3c9a52ae692fa7e50742a58eca3db69d34d92c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1539 | Contributors (this commit): 10 | Commits (past 90d): 77 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -59,7 +59,7 @@ class Layer(BackendLayer, Operation):\n     in the `call()` method, and a *state* (weight variables). State can be\n     created:\n \n-    * in `__init__()`, for instancce via `self.add_weight()`;\n+    * in `__init__()`, for instance via `self.add_weight()`;\n     * in the optional `build()` method, which is invoked by the first\n       `__call__()` to the layer, and supplies the shape(s) of the input(s),\n       which may not have been known at initialization time.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7e2df478384175c45d956daaa4531b0fdb9c414b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 373 | Lines Deleted: 86 | Files Changed: 28 | Hunks: 118 | Methods Changed: 43 | Complexity Δ (Sum/Max): 38/10 | Churn Δ: 459 | Churn Cumulative: 5345 | Contributors (this commit): 5 | Commits (past 90d): 112 | Contributors (cumulative): 50 | DMM Complexity: 0.9404761904761905\n\nDIFF:\n@@ -1,10 +1,10 @@\n from keras_core import operations as ops\n from keras_core.api_export import keras_core_export\n-from keras_core.layers.layer import Layer\n+from keras_core.layers.preprocessing.tf_data_layer import TFDataLayer\n \n \n @keras_core_export(\"keras_core.layers.CategoryEncoding\")\n-class CategoryEncoding(Layer):\n+class CategoryEncoding(TFDataLayer):\n     \"\"\"A preprocessing layer which encodes integer features.\n \n     This layer provides options for condensing data into a categorical encoding\n@@ -13,6 +13,9 @@ class CategoryEncoding(Layer):\n     inputs. For integer inputs where the total number of tokens is not known,\n     use `keras_core.layers.IntegerLookup` instead.\n \n+    **Note:** This layer is safe to use inside a `tf.data` pipeline\n+    (independently of which backend you're using).\n+\n     Examples:\n \n     **One-hot encoding data**\n@@ -130,23 +133,32 @@ class CategoryEncoding(Layer):\n             if self.output_mode != \"count\":\n                 raise ValueError(\n                     \"`count_weights` is not used when `output_mode` is not \"\n-                    \"`'count'`. Received `count_weights={count_weights}`.\"\n+                    f\"`'count'`. Received `count_weights={count_weights}`.\"\n                 )\n-            count_weights = ops.cast(count_weights, self.compute_dtype)\n+            count_weights = self.backend.cast(count_weights, self.compute_dtype)\n \n         depth = self.num_tokens\n \n-        max_value = ops.amax(inputs)\n-        min_value = ops.amin(inputs)\n-        condition = ops.logical_and(\n-            ops.greater(ops.cast(depth, max_value.dtype), max_value),\n-            ops.greater_equal(min_value, ops.cast(0, min_value.dtype)),\n+        max_value = self.backend.numpy.amax(inputs)\n+        min_value = self.backend.numpy.amin(inputs)\n+        condition = self.backend.numpy.logical_and(\n+            self.backend.numpy.greater(\n+                self.backend.cast(depth, max_value.dtype), max_value\n+            ),\n+            self.backend.numpy.greater_equal(\n+                min_value, self.backend.cast(0, min_value.dtype)\n+            ),\n         )\n+        try:\n+            # Check value range in eager mode only.\n+            condition = bool(condition.__array__())\n             if not condition:\n                 raise ValueError(\n                     \"Input values must be in the range 0 <= values < num_tokens\"\n                     f\" with num_tokens={depth}\"\n                 )\n+        except:\n+            pass\n \n         return self._encode_categorical_inputs(\n             inputs,\n@@ -164,12 +176,12 @@ class CategoryEncoding(Layer):\n     ):\n         # In all cases, we should uprank scalar input to a single sample.\n         if len(inputs.shape) == 0:\n-            inputs = ops.expand_dims(inputs, -1)\n+            inputs = self.backend.numpy.expand_dims(inputs, -1)\n         # One hot will uprank only if the final output dimension\n         # is not already 1.\n         if output_mode == \"one_hot\":\n             if len(inputs.shape) > 1 and inputs.shape[-1] != 1:\n-                inputs = ops.expand_dims(inputs, -1)\n+                inputs = self.backend.numpy.expand_dims(inputs, -1)\n \n         # TODO(b/190445202): remove output rank restriction.\n         if len(inputs.shape) > 2:\n@@ -181,15 +193,14 @@ class CategoryEncoding(Layer):\n             )\n \n         binary_output = output_mode in (\"multi_hot\", \"one_hot\")\n-        inputs = ops.cast(inputs, \"int32\")\n+        inputs = self.backend.cast(inputs, \"int32\")\n \n         if binary_output:\n-            bincounts = ops.one_hot(inputs, num_classes=depth)\n+            bincounts = self.backend.nn.one_hot(inputs, num_classes=depth)\n             if output_mode == \"multi_hot\":\n-                bincounts = ops.sum(bincounts, axis=0)\n+                bincounts = self.backend.numpy.sum(bincounts, axis=0)\n         else:\n-            bincounts = ops.bincount(\n+            bincounts = self.backend.numpy.bincount(\n                 inputs, minlength=depth, weights=count_weights\n             )\n-\n         return bincounts\n\n@@ -1,4 +1,5 @@\n import numpy as np\n+import tensorflow as tf\n \n from keras_core import layers\n from keras_core import testing\n@@ -51,3 +52,19 @@ class CategoryEncodingTest(testing.TestCase):\n         output_data = layer(input_data)\n         self.assertAllClose(expected_output, output_data)\n         self.assertEqual(expected_output_shape, output_data.shape)\n+\n+    def test_tf_data_compatibility(self):\n+        layer = layers.CategoryEncoding(num_tokens=4, output_mode=\"one_hot\")\n+        input_data = np.array([3, 2, 0, 1])\n+        expected_output = np.array(\n+            [\n+                [0, 0, 0, 1],\n+                [0, 0, 1, 0],\n+                [1, 0, 0, 0],\n+                [0, 1, 0, 0],\n+            ]\n+        )\n+        ds = tf.data.Dataset.from_tensor_slices(input_data).batch(4).map(layer)\n+        for output in ds.take(1):\n+            output = output.numpy()\n+        self.assertAllClose(output, expected_output)\n\n@@ -1,11 +1,11 @@\n from keras_core import backend\n from keras_core.api_export import keras_core_export\n-from keras_core.layers.layer import Layer\n+from keras_core.layers.preprocessing.tf_data_layer import TFDataLayer\n from keras_core.utils import image_utils\n \n \n @keras_core_export(\"keras_core.layers.CenterCrop\")\n-class CenterCrop(Layer):\n+class CenterCrop(TFDataLayer):\n     \"\"\"A preprocessing layer which crops images.\n \n     This layers crops the central portion of the images to a target size. If an\n@@ -29,6 +29,9 @@ class CenterCrop(Layer):\n     If the input height/width is even and the target height/width is odd (or\n     inversely), the input image is left-padded by 1 pixel.\n \n+    **Note:** This layer is safe to use inside a `tf.data` pipeline\n+    (independently of which backend you're using).\n+\n     Args:\n         height: Integer, the height of the output shape.\n         width: Integer, the width of the output shape.\n@@ -99,7 +102,10 @@ class CenterCrop(Layer):\n                 ]\n \n         return image_utils.smart_resize(\n-            inputs, [self.height, self.width], data_format=self.data_format\n+            inputs,\n+            [self.height, self.width],\n+            data_format=self.data_format,\n+            backend_module=self.backend,\n         )\n \n     def compute_output_shape(self, input_shape):\n\n@@ -94,3 +94,11 @@ class CenterCropTest(testing.TestCase, parameterized.TestCase):\n                 size[1],\n             )(img)\n         self.assertAllClose(ref_out, out)\n+\n+    def test_tf_data_compatibility(self):\n+        layer = layers.CenterCrop(8, 9)\n+        input_data = np.random.random((2, 10, 12, 3))\n+        ds = tf.data.Dataset.from_tensor_slices(input_data).batch(2).map(layer)\n+        for output in ds.take(1):\n+            output = output.numpy()\n+        self.assertEqual(list(output.shape), [2, 8, 9, 3])\n\n@@ -4,6 +4,7 @@ import tensorflow as tf\n from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n+from keras_core.utils import backend_utils\n \n \n @keras_core_export(\"keras_core.layers.Discretization\")\n@@ -22,6 +23,9 @@ class Discretization(Layer):\n     with any backend (outside the model itself), which is how we recommend\n     to use this layer.\n \n+    **Note:** This layer is safe to use inside a `tf.data` pipeline\n+    (independently of which backend you're using).\n+\n     Input shape:\n         Any array of dimension 2 or higher.\n \n@@ -192,7 +196,10 @@ class Discretization(Layer):\n \n     def call(self, inputs):\n         outputs = self.layer.call(inputs)\n-        if backend.backend() != \"tensorflow\" and tf.executing_eagerly():\n+        if (\n+            backend.backend() != \"tensorflow\"\n+            and not backend_utils.in_tf_graph()\n+        ):\n             outputs = backend.convert_to_tensor(outputs)\n         return outputs\n \n\n@@ -3,6 +3,7 @@ import tensorflow as tf\n from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n+from keras_core.utils import backend_utils\n \n \n @keras_core_export(\"keras_core.layers.HashedCrossing\")\n@@ -25,6 +26,9 @@ class HashedCrossing(Layer):\n     with any backend (outside the model itself), which is how we recommend\n     to use this layer.\n \n+    **Note:** This layer is safe to use inside a `tf.data` pipeline\n+    (independently of which backend you're using).\n+\n     Args:\n         num_bins: Number of hash bins.\n         output_mode: Specification for the output of the layer. Values can be\n@@ -100,7 +104,10 @@ class HashedCrossing(Layer):\n \n     def call(self, inputs):\n         outputs = self.layer.call(inputs)\n-        if backend.backend() != \"tensorflow\" and tf.executing_eagerly():\n+        if (\n+            backend.backend() != \"tensorflow\"\n+            and not backend_utils.in_tf_graph()\n+        ):\n             outputs = backend.convert_to_tensor(outputs)\n         return outputs\n \n\n@@ -4,6 +4,7 @@ import tensorflow as tf\n from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n+from keras_core.utils import backend_utils\n \n \n @keras_core_export(\"keras_core.layers.Hashing\")\n@@ -33,6 +34,9 @@ class Hashing(Layer):\n     with any backend (outside the model itself), which is how we recommend\n     to use this layer.\n \n+    **Note:** This layer is safe to use inside a `tf.data` pipeline\n+    (independently of which backend you're using).\n+\n     **Example (FarmHash64)**\n \n     >>> layer = keras_core.layers.Hashing(num_bins=3)\n@@ -175,7 +179,10 @@ class Hashing(Layer):\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n             inputs = tf.convert_to_tensor(np.array(inputs))\n         outputs = self.layer.call(inputs)\n-        if backend.backend() != \"tensorflow\" and tf.executing_eagerly():\n+        if (\n+            backend.backend() != \"tensorflow\"\n+            and not backend_utils.in_tf_graph()\n+        ):\n             outputs = backend.convert_to_tensor(outputs)\n         return outputs\n \n\n@@ -4,6 +4,7 @@ import tensorflow as tf\n from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n+from keras_core.utils import backend_utils\n \n \n @keras_core_export(\"keras_core.layers.IntegerLookup\")\n@@ -47,6 +48,9 @@ class IntegerLookup(Layer):\n     with any backend (outside the model itself), which is how we recommend\n     to use this layer.\n \n+    **Note:** This layer is safe to use inside a `tf.data` pipeline\n+    (independently of which backend you're using).\n+\n     Args:\n         max_tokens: Maximum size of the vocabulary for this layer. This should\n             only be specified when adapting the vocabulary or when setting\n@@ -441,7 +445,10 @@ class IntegerLookup(Layer):\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n             inputs = tf.convert_to_tensor(np.array(inputs))\n         outputs = self.layer.call(inputs)\n-        if backend.backend() != \"tensorflow\" and tf.executing_eagerly():\n+        if (\n+            backend.backend() != \"tensorflow\"\n+            and not backend_utils.in_tf_graph()\n+        ):\n             outputs = backend.convert_to_tensor(outputs)\n         return outputs\n \n\n@@ -1,17 +1,19 @@\n-from keras_core import operations as ops\n+from keras_core import backend\n from keras_core.api_export import keras_core_export\n-from keras_core.backend import random\n-from keras_core.layers.layer import Layer\n+from keras_core.layers.preprocessing.tf_data_layer import TFDataLayer\n \n \n @keras_core_export(\"keras_core.layers.RandomBrightness\")\n-class RandomBrightness(Layer):\n+class RandomBrightness(TFDataLayer):\n     \"\"\"A preprocessing layer which randomly adjusts brightness during training.\n \n     This layer will randomly increase/reduce the brightness for the input RGB\n     images. At inference time, the output will be identical to the input.\n     Call the layer with `training=True` to adjust the brightness of the input.\n \n+    **Note:** This layer is safe to use inside a `tf.data` pipeline\n+    (independently of which backend you're using).\n+\n     Args:\n         factor: Float or a list/tuple of 2 floats between -1.0 and 1.0. The\n             factor is used to determine the lower bound and upper bound of the\n@@ -72,21 +74,21 @@ class RandomBrightness(Layer):\n         super().__init__(**kwargs)\n         self._set_factor(factor)\n         self._set_value_range(value_range)\n-        self._seed = seed\n-        self._generator = random.SeedGenerator(seed)\n+        self.seed = seed\n+        self.generator = backend.random.SeedGenerator(seed)\n \n     def _set_value_range(self, value_range):\n         if not isinstance(value_range, (tuple, list)):\n             raise ValueError(\n-                self._VALUE_RANGE_VALIDATION_ERROR\n+                self.value_range_VALIDATION_ERROR\n                 + f\"Received: value_range={value_range}\"\n             )\n         if len(value_range) != 2:\n             raise ValueError(\n-                self._VALUE_RANGE_VALIDATION_ERROR\n+                self.value_range_VALIDATION_ERROR\n                 + f\"Received: value_range={value_range}\"\n             )\n-        self._value_range = sorted(value_range)\n+        self.value_range = sorted(value_range)\n \n     def _set_factor(self, factor):\n         if isinstance(factor, (tuple, list)):\n@@ -114,7 +116,7 @@ class RandomBrightness(Layer):\n             )\n \n     def call(self, inputs, training=True):\n-        inputs = ops.cast(inputs, self.compute_dtype)\n+        inputs = self.backend.cast(inputs, self.compute_dtype)\n         if training:\n             return self._brightness_adjust(inputs)\n         else:\n@@ -127,23 +129,30 @@ class RandomBrightness(Layer):\n         elif rank == 4:\n             # Keep only the batch dim. This will ensure to have same adjustment\n             # with in one image, but different across the images.\n-            rgb_delta_shape = [images.shape[0], 1, 1, 1]\n+            rgb_delta_shape = [self.backend.shape(images)[0], 1, 1, 1]\n         else:\n             raise ValueError(\n                 \"Expected the input image to be rank 3 or 4. Received \"\n                 f\"inputs.shape={images.shape}\"\n             )\n \n-        rgb_delta = ops.random.uniform(\n+        if backend.backend() != self.backend._backend:\n+            seed_generator = self.backend.random.SeedGenerator(self.seed)\n+        else:\n+            seed_generator = self.generator\n+\n+        rgb_delta = self.backend.random.uniform(\n             minval=self._factor[0],\n             maxval=self._factor[1],\n             shape=rgb_delta_shape,\n-            seed=self._generator,\n+            seed=seed_generator,\n         )\n-        rgb_delta = rgb_delta * (self._value_range[1] - self._value_range[0])\n-        rgb_delta = ops.cast(rgb_delta, images.dtype)\n+        rgb_delta = rgb_delta * (self.value_range[1] - self.value_range[0])\n+        rgb_delta = self.backend.cast(rgb_delta, images.dtype)\n         images += rgb_delta\n-        return ops.clip(images, self._value_range[0], self._value_range[1])\n+        return self.backend.numpy.clip(\n+            images, self.value_range[0], self.value_range[1]\n+        )\n \n     def compute_output_shape(self, input_shape):\n         return input_shape\n@@ -151,8 +160,8 @@ class RandomBrightness(Layer):\n     def get_config(self):\n         config = {\n             \"factor\": self._factor,\n-            \"value_range\": self._value_range,\n-            \"seed\": self._seed,\n+            \"value_range\": self.value_range,\n+            \"seed\": self.seed,\n         }\n         base_config = super().get_config()\n         return {**base_config, **config}\n\n@@ -1,4 +1,5 @@\n import numpy as np\n+import tensorflow as tf\n \n from keras_core import layers\n from keras_core import testing\n@@ -46,3 +47,10 @@ class RandomBrightnessTest(testing.TestCase):\n         diff = output - inputs\n         self.assertTrue(np.amax(diff) <= 0)\n         self.assertTrue(np.mean(diff) < 0)\n+\n+    def test_tf_data_compatibility(self):\n+        layer = layers.RandomBrightness(factor=0.5, seed=1337)\n+        input_data = np.random.random((2, 8, 8, 3))\n+        ds = tf.data.Dataset.from_tensor_slices(input_data).batch(2).map(layer)\n+        for output in ds.take(1):\n+            output.numpy()\n\n@@ -1,11 +1,10 @@\n-from keras_core import operations as ops\n+from keras_core import backend\n from keras_core.api_export import keras_core_export\n-from keras_core.backend import random\n-from keras_core.layers.layer import Layer\n+from keras_core.layers.preprocessing.tf_data_layer import TFDataLayer\n \n \n @keras_core_export(\"keras_core.layers.RandomContrast\")\n-class RandomContrast(Layer):\n+class RandomContrast(TFDataLayer):\n     \"\"\"A preprocessing layer which randomly adjusts contrast during training.\n \n     This layer will randomly adjust the contrast of an image or images\n@@ -20,6 +19,9 @@ class RandomContrast(Layer):\n     in integer or floating point dtype.\n     By default, the layer will output floats.\n \n+    **Note:** This layer is safe to use inside a `tf.data` pipeline\n+    (independently of which backend you're using).\n+\n     Input shape:\n         3D (unbatched) or 4D (batched) tensor with shape:\n         `(..., height, width, channels)`, in `\"channels_last\"` format.\n@@ -54,30 +56,34 @@ class RandomContrast(Layer):\n                 f\"Received: factor={factor}\"\n             )\n         self.seed = seed\n-        self.generator = random.SeedGenerator(seed)\n+        self.generator = backend.random.SeedGenerator(seed)\n \n     def call(self, inputs, training=True):\n-        inputs = ops.cast(inputs, self.compute_dtype)\n+        inputs = self.backend.cast(inputs, self.compute_dtype)\n         if training:\n-            factor = ops.random.uniform(\n+            if backend.backend() != self.backend._backend:\n+                seed_generator = self.backend.random.SeedGenerator(self.seed)\n+            else:\n+                seed_generator = self.generator\n+            factor = self.backend.random.uniform(\n                 shape=(),\n                 minval=1.0 - self.lower,\n                 maxval=1.0 + self.upper,\n-                seed=self.generator,\n+                seed=seed_generator,\n             )\n \n             outputs = self._adjust_constrast(inputs, factor)\n-            outputs = ops.clip(outputs, 0, 255)\n-            ops.reshape(outputs, inputs.shape)\n+            outputs = self.backend.numpy.clip(outputs, 0, 255)\n+            self.backend.numpy.reshape(outputs, self.backend.shape(inputs))\n             return outputs\n         else:\n             return inputs\n \n     def _adjust_constrast(self, inputs, contrast_factor):\n         # reduce mean on height\n-        inp_mean = ops.mean(inputs, axis=-3, keepdims=True)\n+        inp_mean = self.backend.numpy.mean(inputs, axis=-3, keepdims=True)\n         # reduce mean on width\n-        inp_mean = ops.mean(inp_mean, axis=-2, keepdims=True)\n+        inp_mean = self.backend.numpy.mean(inp_mean, axis=-2, keepdims=True)\n \n         outputs = (inputs - inp_mean) * contrast_factor + inp_mean\n         return outputs\n\n@@ -1,4 +1,5 @@\n import numpy as np\n+import tensorflow as tf\n \n from keras_core import layers\n from keras_core import testing\n@@ -33,3 +34,10 @@ class RandomContrastTest(testing.TestCase):\n         actual_outputs = np.clip(outputs, 0, 255)\n \n         self.assertAllClose(outputs, actual_outputs)\n+\n+    def test_tf_data_compatibility(self):\n+        layer = layers.RandomContrast(factor=0.5, seed=1337)\n+        input_data = np.random.random((2, 8, 8, 3))\n+        ds = tf.data.Dataset.from_tensor_slices(input_data).batch(2).map(layer)\n+        for output in ds.take(1):\n+            output.numpy()\n\n@@ -4,6 +4,7 @@ import tensorflow as tf\n from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n+from keras_core.utils import backend_utils\n \n \n @keras_core_export(\"keras_core.layers.RandomCrop\")\n@@ -32,6 +33,9 @@ class RandomCrop(Layer):\n     with any backend (outside the model itself), which is how we recommend\n     to use this layer.\n \n+    **Note:** This layer is safe to use inside a `tf.data` pipeline\n+    (independently of which backend you're using).\n+\n     Input shape:\n         3D (unbatched) or 4D (batched) tensor with shape:\n         `(..., height, width, channels)`, in `\"channels_last\"` format.\n@@ -59,12 +63,17 @@ class RandomCrop(Layer):\n         )\n         self.supports_masking = False\n         self.supports_jit = False\n+        self._convert_input_args = False\n+        self._allow_non_tensor_positional_args = True\n \n     def call(self, inputs, training=True):\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n             inputs = tf.convert_to_tensor(np.array(inputs))\n-        outputs = self.layer.call(inputs)\n-        if backend.backend() != \"tensorflow\":\n+        outputs = self.layer.call(inputs, training=training)\n+        if (\n+            backend.backend() != \"tensorflow\"\n+            and not backend_utils.in_tf_graph()\n+        ):\n             outputs = backend.convert_to_tensor(outputs)\n         return outputs\n \n\n@@ -1,4 +1,5 @@\n import numpy as np\n+import tensorflow as tf\n \n from keras_core import layers\n from keras_core import testing\n@@ -63,3 +64,11 @@ class RandomCropTest(testing.TestCase):\n             supports_masking=False,\n             run_training_check=False,\n         )\n+\n+    def test_tf_data_compatibility(self):\n+        layer = layers.RandomCrop(8, 9)\n+        input_data = np.random.random((2, 10, 12, 3))\n+        ds = tf.data.Dataset.from_tensor_slices(input_data).batch(2).map(layer)\n+        for output in ds.take(1):\n+            output = output.numpy()\n+        self.assertEqual(list(output.shape), [2, 8, 9, 3])\n\n@@ -4,6 +4,7 @@ import tensorflow as tf\n from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n+from keras_core.utils import backend_utils\n \n HORIZONTAL = \"horizontal\"\n VERTICAL = \"vertical\"\n@@ -21,6 +22,9 @@ class RandomFlip(Layer):\n     of integer or floating point dtype.\n     By default, the layer will output floats.\n \n+    **Note:** This layer is safe to use inside a `tf.data` pipeline\n+    (independently of which backend you're using).\n+\n     Input shape:\n         3D (unbatched) or 4D (batched) tensor with shape:\n         `(..., height, width, channels)`, in `\"channels_last\"` format.\n@@ -51,12 +55,17 @@ class RandomFlip(Layer):\n             **kwargs,\n         )\n         self.supports_jit = False\n+        self._convert_input_args = False\n+        self._allow_non_tensor_positional_args = True\n \n     def call(self, inputs, training=True):\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n             inputs = tf.convert_to_tensor(np.array(inputs))\n-        outputs = self.layer.call(inputs)\n-        if backend.backend() != \"tensorflow\":\n+        outputs = self.layer.call(inputs, training=training)\n+        if (\n+            backend.backend() != \"tensorflow\"\n+            and not backend_utils.in_tf_graph()\n+        ):\n             outputs = backend.convert_to_tensor(outputs)\n         return outputs\n \n\n@@ -1,4 +1,5 @@\n import numpy as np\n+import tensorflow as tf\n from absl.testing import parameterized\n \n from keras_core import backend\n@@ -54,3 +55,12 @@ class RandomFlipTest(testing.TestCase, parameterized.TestCase):\n             supports_masking=False,\n             run_training_check=False,\n         )\n+\n+    def test_tf_data_compatibility(self):\n+        layer = layers.RandomFlip(\"vertical\", seed=42)\n+        input_data = np.array([[[2, 3, 4]], [[5, 6, 7]]])\n+        expected_output = np.array([[[5, 6, 7]], [[2, 3, 4]]])\n+        ds = tf.data.Dataset.from_tensor_slices(input_data).batch(2).map(layer)\n+        for output in ds.take(1):\n+            output = output.numpy()\n+        self.assertAllClose(output, expected_output)\n\n@@ -4,6 +4,7 @@ import tensorflow as tf\n from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n+from keras_core.utils import backend_utils\n \n \n @keras_core_export(\"keras_core.layers.RandomRotation\")\n@@ -29,6 +30,9 @@ class RandomRotation(Layer):\n     with any backend (outside the model itself), which is how we recommend\n     to use this layer.\n \n+    **Note:** This layer is safe to use inside a `tf.data` pipeline\n+    (independently of which backend you're using).\n+\n     Input shape:\n         3D (unbatched) or 4D (batched) tensor with shape:\n         `(..., height, width, channels)`, in `\"channels_last\"` format\n@@ -101,7 +105,10 @@ class RandomRotation(Layer):\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n             inputs = tf.convert_to_tensor(np.array(inputs))\n         outputs = self.layer.call(inputs, training=training)\n-        if backend.backend() != \"tensorflow\" and tf.executing_eagerly():\n+        if (\n+            backend.backend() != \"tensorflow\"\n+            and not backend_utils.in_tf_graph()\n+        ):\n             outputs = backend.convert_to_tensor(outputs)\n         return outputs\n \n\n@@ -4,6 +4,7 @@ import tensorflow as tf\n from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n+from keras_core.utils import backend_utils\n \n \n @keras_core_export(\"keras_core.layers.RandomTranslation\")\n@@ -17,6 +18,9 @@ class RandomTranslation(Layer):\n     of integer or floating point dtype. By default, the layer will output\n     floats.\n \n+    **Note:** This layer is safe to use inside a `tf.data` pipeline\n+    (independently of which backend you're using).\n+\n     Args:\n       height_factor: a float represented as fraction of value, or a tuple of\n           size 2 representing lower and upper bound for shifting vertically. A\n@@ -91,7 +95,10 @@ class RandomTranslation(Layer):\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n             inputs = tf.convert_to_tensor(np.array(inputs))\n         outputs = self.layer.call(inputs, training=training)\n-        if backend.backend() != \"tensorflow\" and tf.executing_eagerly():\n+        if (\n+            backend.backend() != \"tensorflow\"\n+            and not backend_utils.in_tf_graph()\n+        ):\n             outputs = backend.convert_to_tensor(outputs)\n         return outputs\n \n\n@@ -4,6 +4,7 @@ import tensorflow as tf\n from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n+from keras_core.utils import backend_utils\n \n \n @keras_core_export(\"keras_core.layers.RandomZoom\")\n@@ -25,6 +26,9 @@ class RandomZoom(Layer):\n     with any backend (outside the model itself), which is how we recommend\n     to use this layer.\n \n+    **Note:** This layer is safe to use inside a `tf.data` pipeline\n+    (independently of which backend you're using).\n+\n     Args:\n         height_factor: a float represented as fraction of value,\n             or a tuple of size 2 representing lower and upper bound\n@@ -114,7 +118,10 @@ class RandomZoom(Layer):\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n             inputs = tf.convert_to_tensor(np.array(inputs))\n         outputs = self.layer.call(inputs, training=training)\n-        if backend.backend() != \"tensorflow\" and tf.executing_eagerly():\n+        if (\n+            backend.backend() != \"tensorflow\"\n+            and not backend_utils.in_tf_graph()\n+        ):\n             outputs = backend.convert_to_tensor(outputs)\n         return outputs\n \n\n@@ -1,10 +1,9 @@\n-from keras_core import operations as ops\n from keras_core.api_export import keras_core_export\n-from keras_core.layers.layer import Layer\n+from keras_core.layers.preprocessing.tf_data_layer import TFDataLayer\n \n \n @keras_core_export(\"keras_core.layers.Rescaling\")\n-class Rescaling(Layer):\n+class Rescaling(TFDataLayer):\n     \"\"\"A preprocessing layer which rescales input values to a new range.\n \n     This layer rescales every value of an input (often an image) by multiplying\n@@ -22,6 +21,9 @@ class Rescaling(Layer):\n     of integer or floating point dtype, and by default the layer will output\n     floats.\n \n+    **Note:** This layer is safe to use inside a `tf.data` pipeline\n+    (independently of which backend you're using).\n+\n     Args:\n         scale: Float, the scale to apply to the inputs.\n         offset: Float, the offset to apply to the inputs.\n@@ -36,9 +38,9 @@ class Rescaling(Layer):\n \n     def call(self, inputs):\n         dtype = self.compute_dtype\n-        scale = ops.cast(self.scale, dtype)\n-        offset = ops.cast(self.offset, dtype)\n-        return ops.cast(inputs, dtype) * scale + offset\n+        scale = self.backend.cast(self.scale, dtype)\n+        offset = self.backend.cast(self.offset, dtype)\n+        return self.backend.cast(inputs, dtype) * scale + offset\n \n     def compute_output_shape(self, input_shape):\n         return input_shape\n\n@@ -1,4 +1,5 @@\n import numpy as np\n+import tensorflow as tf\n \n from keras_core import layers\n from keras_core import testing\n@@ -62,3 +63,10 @@ class RescalingTest(testing.TestCase):\n         x = np.random.random((3, 10, 10, 3)) * 255\n         out = layer(x)\n         self.assertAllClose(out, x / 255 + 0.5)\n+\n+    def test_tf_data_compatibility(self):\n+        layer = layers.Rescaling(scale=1.0 / 255, offset=0.5)\n+        x = np.random.random((3, 10, 10, 3)) * 255\n+        ds = tf.data.Dataset.from_tensor_slices(x).batch(3).map(layer)\n+        for output in ds.take(1):\n+            output.numpy()\n\n@@ -1,12 +1,11 @@\n from keras_core import backend\n-from keras_core import operations as ops\n from keras_core.api_export import keras_core_export\n-from keras_core.layers.layer import Layer\n+from keras_core.layers.preprocessing.tf_data_layer import TFDataLayer\n from keras_core.utils import image_utils\n \n \n @keras_core_export(\"keras_core.layers.Resizing\")\n-class Resizing(Layer):\n+class Resizing(TFDataLayer):\n     \"\"\"A preprocessing layer which resizes images.\n \n     This layer resizes an image input to a target height and width. The input\n@@ -25,6 +24,9 @@ class Resizing(Layer):\n         or `(..., channels, target_height, target_width)`,\n         in `\"channels_first\"` format.\n \n+    **Note:** This layer is safe to use inside a `tf.data` pipeline\n+    (independently of which backend you're using).\n+\n     Args:\n         height: Integer, the height of the output shape.\n         width: Integer, the width of the output shape.\n@@ -73,9 +75,10 @@ class Resizing(Layer):\n                 size=size,\n                 interpolation=self.interpolation,\n                 data_format=self.data_format,\n+                backend_module=self.backend,\n             )\n         else:\n-            outputs = ops.image.resize(\n+            outputs = self.backend.image.resize(\n                 inputs,\n                 size=size,\n                 method=self.interpolation,\n\n@@ -142,3 +142,11 @@ class ResizingTest(testing.TestCase, parameterized.TestCase):\n                 size[0], size[1], crop_to_aspect_ratio=crop_to_aspect_ratio\n             )(img)\n         self.assertAllClose(ref_out, out)\n+\n+    def test_tf_data_compatibility(self):\n+        layer = layers.Resizing(8, 9)\n+        input_data = np.random.random((2, 10, 12, 3))\n+        ds = tf.data.Dataset.from_tensor_slices(input_data).batch(2).map(layer)\n+        for output in ds.take(1):\n+            output = output.numpy()\n+        self.assertEqual(list(output.shape), [2, 8, 9, 3])\n\n@@ -4,6 +4,7 @@ import tensorflow as tf\n from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n+from keras_core.utils import backend_utils\n \n \n @keras_core_export(\"keras_core.layers.StringLookup\")\n@@ -46,6 +47,9 @@ class StringLookup(Layer):\n     with any backend (outside the model itself), which is how we recommend\n     to use this layer.\n \n+    **Note:** This layer is safe to use inside a `tf.data` pipeline\n+    (independently of which backend you're using).\n+\n     Args:\n         max_tokens: Maximum size of the vocabulary for this layer. This should\n             only be specified when adapting the vocabulary or when setting\n@@ -435,7 +439,10 @@ class StringLookup(Layer):\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n             inputs = tf.convert_to_tensor(np.array(inputs))\n         outputs = self.layer.call(inputs)\n-        if backend.backend() != \"tensorflow\" and tf.executing_eagerly():\n+        if (\n+            backend.backend() != \"tensorflow\"\n+            and not backend_utils.in_tf_graph()\n+        ):\n             outputs = backend.convert_to_tensor(outputs)\n         return outputs\n \n\n@@ -5,6 +5,7 @@ from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n from keras_core.saving import serialization_lib\n+from keras_core.utils import backend_utils\n \n \n @keras_core_export(\"keras_core.layers.TextVectorization\")\n@@ -63,6 +64,9 @@ class TextVectorization(Layer):\n     with any backend (outside the model itself), which is how we recommend\n     to use this layer.\n \n+    **Note:** This layer is safe to use inside a `tf.data` pipeline\n+    (independently of which backend you're using).\n+\n     Args:\n         max_tokens: Maximum size of the vocabulary for this layer. This should\n             only be specified when adapting a vocabulary or when setting\n@@ -358,7 +362,10 @@ class TextVectorization(Layer):\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n             inputs = tf.convert_to_tensor(np.array(inputs))\n         outputs = self.layer.call(inputs)\n-        if backend.backend() != \"tensorflow\" and tf.executing_eagerly():\n+        if (\n+            backend.backend() != \"tensorflow\"\n+            and not backend_utils.in_tf_graph()\n+        ):\n             outputs = backend.convert_to_tensor(outputs)\n         return outputs\n \n\n@@ -0,0 +1,36 @@\n+from keras_core.layers.layer import Layer\n+from keras_core.utils import backend_utils\n+\n+\n+class TFDataLayer(Layer):\n+    \"\"\"Layer that can safely used in a tf.data pipeline.\n+\n+    The `call()` method must solely rely on `self.backend` ops.\n+\n+    Only supports a single input tensor argument.\n+    \"\"\"\n+\n+    def __init__(self, **kwargs):\n+        super().__init__(**kwargs)\n+        self.backend = backend_utils.DynamicBackend()\n+        self._allow_non_tensor_positional_args = True\n+\n+    def __call__(self, inputs, **kwargs):\n+        if backend_utils.in_tf_graph():\n+            # We're in a TF graph, e.g. a tf.data pipeline.\n+            self.backend.set_backend(\"tensorflow\")\n+            inputs = self.backend.convert_to_tensor(\n+                inputs, dtype=self.compute_dtype\n+            )\n+            switch_convert_input_args = False\n+            if self._convert_input_args:\n+                self._convert_input_args = False\n+                switch_convert_input_args = True\n+            try:\n+                outputs = super().__call__(inputs, **kwargs)\n+            finally:\n+                self.backend.reset()\n+                if switch_convert_input_args:\n+                    self._convert_input_args = True\n+            return outputs\n+        return super().__call__(inputs, **kwargs)\n\n@@ -0,0 +1,48 @@\n+import sys\n+\n+from keras_core import backend as backend_module\n+from keras_core.backend import jax as jax_backend\n+from keras_core.backend import tensorflow as tf_backend\n+from keras_core.backend import torch as torch_backend\n+\n+\n+def in_tf_graph():\n+    if \"tensorflow\" in sys.modules:\n+        import tensorflow as tf\n+\n+        return not tf.executing_eagerly()\n+    return False\n+\n+\n+class DynamicBackend:\n+    \"\"\"A class that can be used to switch from one backend to another.\n+\n+    Usage:\n+\n+    ```python\n+    backend = DynamicBackend(\"tensorflow\")\n+    y = backend.square(tf.constant(...))\n+    backend.set_backend(\"jax\")\n+    y = backend.square(jax.numpy.array(...))\n+    ```\n+\n+    Args:\n+        backend: Initial backend to use (string).\n+    \"\"\"\n+\n+    def __init__(self, backend=None):\n+        self._backend = backend or backend_module.backend()\n+\n+    def set_backend(self, backend):\n+        self._backend = backend\n+\n+    def reset(self):\n+        self._backend = backend_module.backend()\n+\n+    def __getattr__(self, name):\n+        if self._backend == \"tensorflow\":\n+            return getattr(tf_backend, name)\n+        if self._backend == \"jax\":\n+            return getattr(jax_backend, name)\n+        if self._backend == \"torch\":\n+            return getattr(torch_backend, name)\n\n@@ -299,7 +299,11 @@ def load_img(\n \n \n def smart_resize(\n-    x, size, interpolation=\"bilinear\", data_format=\"channels_last\"\n+    x,\n+    size,\n+    interpolation=\"bilinear\",\n+    data_format=\"channels_last\",\n+    backend_module=None,\n ):\n     \"\"\"Resize images to a target size without aspect ratio distortion.\n \n@@ -354,6 +358,8 @@ def smart_resize(\n             Supports `bilinear`, `nearest`, `bicubic`,\n             `lanczos3`, `lanczos5`.\n         data_format: `\"channels_last\"` or `\"channels_first\"`.\n+        backend_module: Backend module to use (if different from the default\n+            backend).\n \n     Returns:\n         Array with shape `(size[0], size[1], channels)`.\n@@ -361,11 +367,12 @@ def smart_resize(\n         and if it was a backend-native tensor,\n         the output is a backend-native tensor.\n     \"\"\"\n+    backend_module = backend_module or backend\n     if len(size) != 2:\n         raise ValueError(\n             f\"Expected `size` to be a tuple of 2 integers, but got: {size}.\"\n         )\n-    img = backend.convert_to_tensor(x)\n+    img = backend_module.convert_to_tensor(x)\n     if len(img.shape) is not None:\n         if len(img.shape) < 3 or len(img.shape) > 4:\n             raise ValueError(\n@@ -373,30 +380,32 @@ def smart_resize(\n                 \"channels)`, or `(batch_size, height, width, channels)`, but \"\n                 f\"got input with incorrect rank, of shape {img.shape}.\"\n             )\n-    shape = ops.shape(img)\n+    shape = backend_module.shape(img)\n     if data_format == \"channels_last\":\n         height, width = shape[-3], shape[-2]\n     else:\n         height, width = shape[-2], shape[-1]\n     target_height, target_width = size\n \n-    crop_height = ops.cast(\n-        ops.cast(width * target_height, \"float32\") / target_width, \"int32\"\n+    crop_height = backend_module.cast(\n+        backend_module.cast(width * target_height, \"float32\") / target_width,\n+        \"int32\",\n     )\n-    crop_width = ops.cast(\n-        ops.cast(height * target_width, \"float32\") / target_height, \"int32\"\n+    crop_width = backend_module.cast(\n+        backend_module.cast(height * target_width, \"float32\") / target_height,\n+        \"int32\",\n     )\n \n     # Set back to input height / width if crop_height / crop_width is not\n     # smaller.\n-    crop_height = ops.minimum(height, crop_height)\n-    crop_width = ops.minimum(width, crop_width)\n+    crop_height = backend_module.numpy.minimum(height, crop_height)\n+    crop_width = backend_module.numpy.minimum(width, crop_width)\n \n-    crop_box_hstart = ops.cast(\n-        ops.cast(height - crop_height, \"float32\") / 2, \"int32\"\n+    crop_box_hstart = backend_module.cast(\n+        backend_module.cast(height - crop_height, \"float32\") / 2, \"int32\"\n     )\n-    crop_box_wstart = ops.cast(\n-        ops.cast(width - crop_width, \"float32\") / 2, \"int32\"\n+    crop_box_wstart = backend_module.cast(\n+        backend_module.cast(width - crop_width, \"float32\") / 2, \"int32\"\n     )\n \n     if data_format == \"channels_last\":\n@@ -428,7 +437,7 @@ def smart_resize(\n                 crop_box_wstart : crop_box_wstart + crop_width,\n             ]\n \n-    img = ops.image.resize(\n+    img = backend_module.image.resize(\n         img, size=size, method=interpolation, data_format=data_format\n     )\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
