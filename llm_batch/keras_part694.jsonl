{"custom_id": "keras#bc3d06d6312c53ef62db9eb77083127cce22b276", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1071 | Lines Deleted: 36 | Files Changed: 7 | Hunks: 35 | Methods Changed: 21 | Complexity Δ (Sum/Max): 149/43 | Churn Δ: 1107 | Churn Cumulative: 3789 | Contributors (this commit): 3 | Commits (past 90d): 24 | Contributors (cumulative): 9 | DMM Complexity: 0.017114914425427872\n\nDIFF:\n@@ -48,8 +48,8 @@ def Xception(\n     The default input image size for this model is 299x299.\n \n     Note: each Keras Application expects a specific kind of input preprocessing.\n-    For Xception, call `tf.keras.applications.xception.preprocess_input` on your\n-    inputs before passing them to the model.\n+    For Xception, call `keras_core.applications.xception.preprocess_input`\n+    on your inputs before passing them to the model.\n     `xception.preprocess_input` will scale input pixels between -1 and 1.\n \n     Args:\n\n@@ -1,5 +1,11 @@\n+import numpy as np\n+\n from keras_core.api_export import keras_core_export\n+from keras_core.utils import dataset_utils\n from keras_core.utils.module_utils import tensorflow as tf\n+from keras_core.utils.module_utils import tensorflow_io as tfio\n+\n+ALLOWED_FORMATS = (\".wav\",)\n \n \n @keras_core_export(\"keras_core.utils.audio_dataset_from_directory\")\n@@ -106,19 +112,307 @@ def audio_dataset_from_directory(\n       of shape `(batch_size, num_classes)`, representing a one-hot\n       encoding of the class index.\n     \"\"\"\n-    # TODO: long-term, port implementation.\n-    return tf.keras.utils.audio_dataset_from_directory(\n+    if labels not in (\"inferred\", None):\n+        if not isinstance(labels, (list, tuple)):\n+            raise ValueError(\n+                \"The `labels` argument should be a list/tuple of integer \"\n+                \"labels, of the same size as the number of audio files in \"\n+                \"the target directory. If you wish to infer the labels from \"\n+                \"the subdirectory names in the target directory,\"\n+                ' pass `labels=\"inferred\"`. '\n+                \"If you wish to get a dataset that only contains audio samples \"\n+                f\"(no labels), pass `labels=None`. Received: labels={labels}\"\n+            )\n+        if class_names:\n+            raise ValueError(\n+                \"You can only pass `class_names` if \"\n+                f'`labels=\"inferred\"`. Received: labels={labels}, and '\n+                f\"class_names={class_names}\"\n+            )\n+    if label_mode not in {\"int\", \"categorical\", \"binary\", None}:\n+        raise ValueError(\n+            '`label_mode` argument must be one of \"int\", \"categorical\", '\n+            '\"binary\", '\n+            f\"or None. Received: label_mode={label_mode}\"\n+        )\n+\n+    if ragged and output_sequence_length is not None:\n+        raise ValueError(\n+            \"Cannot set both `ragged` and `output_sequence_length`\"\n+        )\n+\n+    if sampling_rate is not None:\n+        if not isinstance(sampling_rate, int):\n+            raise ValueError(\n+                \"`sampling_rate` should have an integer value. \"\n+                f\"Received: sampling_rate={sampling_rate}\"\n+            )\n+\n+        if sampling_rate <= 0:\n+            raise ValueError(\n+                \"`sampling_rate` should be higher than 0. \"\n+                f\"Received: sampling_rate={sampling_rate}\"\n+            )\n+\n+        if not tfio.available:\n+            raise ImportError(\n+                \"To use the argument `sampling_rate`, you should install \"\n+                \"tensorflow_io. You can install it via `pip install \"\n+                \"tensorflow-io`.\"\n+            )\n+\n+    if labels is None or label_mode is None:\n+        labels = None\n+        label_mode = None\n+\n+    dataset_utils.check_validation_split_arg(\n+        validation_split, subset, shuffle, seed\n+    )\n+\n+    if seed is None:\n+        seed = np.random.randint(1e6)\n+\n+    file_paths, labels, class_names = dataset_utils.index_directory(\n         directory,\n+        labels,\n+        formats=ALLOWED_FORMATS,\n+        class_names=class_names,\n+        shuffle=shuffle,\n+        seed=seed,\n+        follow_links=follow_links,\n+    )\n+\n+    if label_mode == \"binary\" and len(class_names) != 2:\n+        raise ValueError(\n+            'When passing `label_mode=\"binary\"`, there must be exactly 2 '\n+            f\"class_names. Received: class_names={class_names}\"\n+        )\n+\n+    if subset == \"both\":\n+        train_dataset, val_dataset = get_training_and_validation_dataset(\n+            file_paths=file_paths,\n             labels=labels,\n+            validation_split=validation_split,\n+            directory=directory,\n             label_mode=label_mode,\n             class_names=class_names,\n-        batch_size=batch_size,\n             sampling_rate=sampling_rate,\n             output_sequence_length=output_sequence_length,\n             ragged=ragged,\n+        )\n+\n+        train_dataset = prepare_dataset(\n+            dataset=train_dataset,\n+            batch_size=batch_size,\n             shuffle=shuffle,\n             seed=seed,\n+            class_names=class_names,\n+            output_sequence_length=output_sequence_length,\n+            ragged=ragged,\n+        )\n+        val_dataset = prepare_dataset(\n+            dataset=val_dataset,\n+            batch_size=batch_size,\n+            shuffle=False,\n+            seed=seed,\n+            class_names=class_names,\n+            output_sequence_length=output_sequence_length,\n+            ragged=ragged,\n+        )\n+        return train_dataset, val_dataset\n+\n+    else:\n+        dataset = get_dataset(\n+            file_paths=file_paths,\n+            labels=labels,\n+            directory=directory,\n             validation_split=validation_split,\n             subset=subset,\n-        follow_links=follow_links,\n+            label_mode=label_mode,\n+            class_names=class_names,\n+            sampling_rate=sampling_rate,\n+            output_sequence_length=output_sequence_length,\n+            ragged=ragged,\n         )\n+\n+        dataset = prepare_dataset(\n+            dataset=dataset,\n+            batch_size=batch_size,\n+            shuffle=shuffle,\n+            seed=seed,\n+            class_names=class_names,\n+            output_sequence_length=output_sequence_length,\n+            ragged=ragged,\n+        )\n+        return dataset\n+\n+\n+def prepare_dataset(\n+    dataset,\n+    batch_size,\n+    shuffle,\n+    seed,\n+    class_names,\n+    output_sequence_length,\n+    ragged,\n+):\n+    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n+    if batch_size is not None:\n+        if shuffle:\n+            dataset = dataset.shuffle(buffer_size=batch_size * 8, seed=seed)\n+\n+        if output_sequence_length is None and not ragged:\n+            dataset = dataset.padded_batch(\n+                batch_size, padded_shapes=([None, None], [])\n+            )\n+        else:\n+            dataset = dataset.batch(batch_size)\n+    else:\n+        if shuffle:\n+            dataset = dataset.shuffle(buffer_size=1024, seed=seed)\n+\n+    # Users may need to reference `class_names`.\n+    dataset.class_names = class_names\n+    return dataset\n+\n+\n+def get_training_and_validation_dataset(\n+    file_paths,\n+    labels,\n+    validation_split,\n+    directory,\n+    label_mode,\n+    class_names,\n+    sampling_rate,\n+    output_sequence_length,\n+    ragged,\n+):\n+    (\n+        file_paths_train,\n+        labels_train,\n+    ) = dataset_utils.get_training_or_validation_split(\n+        file_paths, labels, validation_split, \"training\"\n+    )\n+    if not file_paths_train:\n+        raise ValueError(\n+            f\"No training audio files found in directory {directory}. \"\n+            f\"Allowed format(s): {ALLOWED_FORMATS}\"\n+        )\n+\n+    file_paths_val, labels_val = dataset_utils.get_training_or_validation_split(\n+        file_paths, labels, validation_split, \"validation\"\n+    )\n+    if not file_paths_val:\n+        raise ValueError(\n+            f\"No validation audio files found in directory {directory}. \"\n+            f\"Allowed format(s): {ALLOWED_FORMATS}\"\n+        )\n+\n+    train_dataset = paths_and_labels_to_dataset(\n+        file_paths=file_paths_train,\n+        labels=labels_train,\n+        label_mode=label_mode,\n+        num_classes=len(class_names),\n+        sampling_rate=sampling_rate,\n+        output_sequence_length=output_sequence_length,\n+        ragged=ragged,\n+    )\n+\n+    val_dataset = paths_and_labels_to_dataset(\n+        file_paths=file_paths_val,\n+        labels=labels_val,\n+        label_mode=label_mode,\n+        num_classes=len(class_names),\n+        sampling_rate=sampling_rate,\n+        output_sequence_length=output_sequence_length,\n+        ragged=ragged,\n+    )\n+\n+    return train_dataset, val_dataset\n+\n+\n+def get_dataset(\n+    file_paths,\n+    labels,\n+    directory,\n+    validation_split,\n+    subset,\n+    label_mode,\n+    class_names,\n+    sampling_rate,\n+    output_sequence_length,\n+    ragged,\n+):\n+    file_paths, labels = dataset_utils.get_training_or_validation_split(\n+        file_paths, labels, validation_split, subset\n+    )\n+    if not file_paths:\n+        raise ValueError(\n+            f\"No audio files found in directory {directory}. \"\n+            f\"Allowed format(s): {ALLOWED_FORMATS}\"\n+        )\n+\n+    dataset = paths_and_labels_to_dataset(\n+        file_paths=file_paths,\n+        labels=labels,\n+        label_mode=label_mode,\n+        num_classes=len(class_names),\n+        sampling_rate=sampling_rate,\n+        output_sequence_length=output_sequence_length,\n+        ragged=ragged,\n+    )\n+\n+    return dataset\n+\n+\n+def read_and_decode_audio(\n+    path, sampling_rate=None, output_sequence_length=None\n+):\n+    \"\"\"Reads and decodes audio file.\"\"\"\n+    audio = tf.io.read_file(path)\n+\n+    if output_sequence_length is None:\n+        output_sequence_length = -1\n+\n+    audio, default_audio_rate = tf.audio.decode_wav(\n+        contents=audio, desired_samples=output_sequence_length\n+    )\n+    if sampling_rate is not None:\n+        # default_audio_rate should have dtype=int64\n+        default_audio_rate = tf.cast(default_audio_rate, tf.int64)\n+        audio = tfio.audio.resample(\n+            input=audio, rate_in=default_audio_rate, rate_out=sampling_rate\n+        )\n+    return audio\n+\n+\n+def paths_and_labels_to_dataset(\n+    file_paths,\n+    labels,\n+    label_mode,\n+    num_classes,\n+    sampling_rate,\n+    output_sequence_length,\n+    ragged,\n+):\n+    \"\"\"Constructs a fixed-size dataset of audio and labels.\"\"\"\n+    path_ds = tf.data.Dataset.from_tensor_slices(file_paths)\n+    audio_ds = path_ds.map(\n+        lambda x: read_and_decode_audio(\n+            x, sampling_rate, output_sequence_length\n+        ),\n+        num_parallel_calls=tf.data.AUTOTUNE,\n+    )\n+\n+    if ragged:\n+        audio_ds = audio_ds.map(\n+            lambda x: tf.RaggedTensor.from_tensor(x),\n+            num_parallel_calls=tf.data.AUTOTUNE,\n+        )\n+\n+    if label_mode:\n+        label_ds = dataset_utils.labels_to_dataset(\n+            labels, label_mode, num_classes\n+        )\n+        audio_ds = tf.data.Dataset.zip((audio_ds, label_ds))\n+    return audio_ds\n\n@@ -1,3 +1,5 @@\n+import multiprocessing\n+import os\n import random\n import time\n import warnings\n@@ -5,6 +7,7 @@ import warnings\n import numpy as np\n \n from keras_core.api_export import keras_core_export\n+from keras_core.utils import io_utils\n from keras_core.utils.module_utils import tensorflow as tf\n \n \n@@ -490,3 +493,262 @@ def _get_type_spec(dataset):\n         return torchDataset\n     else:\n         return None\n+\n+\n+def index_directory(\n+    directory,\n+    labels,\n+    formats,\n+    class_names=None,\n+    shuffle=True,\n+    seed=None,\n+    follow_links=False,\n+):\n+    \"\"\"List all files in `directory`, with their labels.\n+\n+    Args:\n+        directory: Directory where the data is located.\n+            If `labels` is `\"inferred\"`, it should contain\n+            subdirectories, each containing files for a class.\n+            Otherwise, the directory structure is ignored.\n+        labels: Either `\"inferred\"`\n+            (labels are generated from the directory structure),\n+            None (no labels),\n+            or a list/tuple of integer labels of the same size as the number\n+            of valid files found in the directory.\n+            Labels should be sorted according\n+            to the alphanumeric order of the image file paths\n+            (obtained via `os.walk(directory)` in Python).\n+        formats: Allowlist of file extensions to index (e.g. \".jpg\", \".txt\").\n+        class_names: Only valid if \"labels\" is \"inferred\". This is the explicit\n+            list of class names (must match names of subdirectories). Used\n+            to control the order of the classes\n+            (otherwise alphanumerical order is used).\n+        shuffle: Whether to shuffle the data. Default: True.\n+            If set to False, sorts the data in alphanumeric order.\n+        seed: Optional random seed for shuffling.\n+        follow_links: Whether to visits subdirectories pointed to by symlinks.\n+\n+    Returns:\n+        tuple (file_paths, labels, class_names).\n+        - file_paths: list of file paths (strings).\n+        - labels: list of matching integer labels (same length as file_paths)\n+        - class_names: names of the classes corresponding to these labels, in\n+        order.\n+    \"\"\"\n+    if labels != \"inferred\":\n+        # in the explicit/no-label cases, index from the parent directory down.\n+        subdirs = [\"\"]\n+        class_names = subdirs\n+    else:\n+        subdirs = []\n+        for subdir in sorted(tf.io.gfile.listdir(directory)):\n+            if tf.io.gfile.isdir(tf.io.gfile.join(directory, subdir)):\n+                if not subdir.startswith(\".\"):\n+                    if subdir.endswith(\"/\"):\n+                        subdir = subdir[:-1]\n+                    subdirs.append(subdir)\n+        if not class_names:\n+            class_names = subdirs\n+        else:\n+            if set(class_names) != set(subdirs):\n+                raise ValueError(\n+                    \"The `class_names` passed did not match the \"\n+                    \"names of the subdirectories of the target directory. \"\n+                    f\"Expected: {subdirs}, but received: {class_names}\"\n+                )\n+    class_indices = dict(zip(class_names, range(len(class_names))))\n+\n+    # Build an index of the files\n+    # in the different class subfolders.\n+    pool = multiprocessing.pool.ThreadPool()\n+    results = []\n+    filenames = []\n+\n+    for dirpath in (tf.io.gfile.join(directory, subdir) for subdir in subdirs):\n+        results.append(\n+            pool.apply_async(\n+                index_subdirectory,\n+                (dirpath, class_indices, follow_links, formats),\n+            )\n+        )\n+    labels_list = []\n+    for res in results:\n+        partial_filenames, partial_labels = res.get()\n+        labels_list.append(partial_labels)\n+        filenames += partial_filenames\n+    if labels not in (\"inferred\", None):\n+        if len(labels) != len(filenames):\n+            raise ValueError(\n+                \"Expected the lengths of `labels` to match the number \"\n+                \"of files in the target directory. len(labels) is \"\n+                f\"{len(labels)} while we found {len(filenames)} files \"\n+                f\"in directory {directory}.\"\n+            )\n+        class_names = sorted(set(labels))\n+    else:\n+        i = 0\n+        labels = np.zeros((len(filenames),), dtype=\"int32\")\n+        for partial_labels in labels_list:\n+            labels[i : i + len(partial_labels)] = partial_labels\n+            i += len(partial_labels)\n+\n+    if labels is None:\n+        io_utils.print_msg(f\"Found {len(filenames)} files.\")\n+    else:\n+        io_utils.print_msg(\n+            f\"Found {len(filenames)} files belonging \"\n+            f\"to {len(class_names)} classes.\"\n+        )\n+    pool.close()\n+    pool.join()\n+    file_paths = [tf.io.gfile.join(directory, fname) for fname in filenames]\n+\n+    if shuffle:\n+        # Shuffle globally to erase macro-structure\n+        if seed is None:\n+            seed = np.random.randint(1e6)\n+        rng = np.random.RandomState(seed)\n+        rng.shuffle(file_paths)\n+        rng = np.random.RandomState(seed)\n+        rng.shuffle(labels)\n+    return file_paths, labels, class_names\n+\n+\n+def iter_valid_files(directory, follow_links, formats):\n+    if not follow_links:\n+        walk = tf.io.gfile.walk(directory)\n+    else:\n+        walk = os.walk(directory, followlinks=follow_links)\n+    for root, _, files in sorted(walk, key=lambda x: x[0]):\n+        for fname in sorted(files):\n+            if fname.lower().endswith(formats):\n+                yield root, fname\n+\n+\n+def index_subdirectory(directory, class_indices, follow_links, formats):\n+    \"\"\"Recursively walks directory and list image paths and their class index.\n+\n+    Args:\n+        directory: string, target directory.\n+        class_indices: dict mapping class names to their index.\n+        follow_links: boolean, whether to recursively follow subdirectories\n+            (if False, we only list top-level images in `directory`).\n+        formats: Allowlist of file extensions to index (e.g. \".jpg\", \".txt\").\n+\n+    Returns:\n+        tuple `(filenames, labels)`. `filenames` is a list of relative file\n+            paths, and `labels` is a list of integer labels corresponding\n+            to these files.\n+    \"\"\"\n+    dirname = os.path.basename(directory)\n+    valid_files = iter_valid_files(directory, follow_links, formats)\n+    labels = []\n+    filenames = []\n+    for root, fname in valid_files:\n+        labels.append(class_indices[dirname])\n+        absolute_path = tf.io.gfile.join(root, fname)\n+        relative_path = tf.io.gfile.join(\n+            dirname, os.path.relpath(absolute_path, directory)\n+        )\n+        filenames.append(relative_path)\n+    return filenames, labels\n+\n+\n+def get_training_or_validation_split(samples, labels, validation_split, subset):\n+    \"\"\"Potentially restict samples & labels to a training or validation split.\n+\n+    Args:\n+        samples: List of elements.\n+        labels: List of corresponding labels.\n+        validation_split: Float, fraction of data to reserve for validation.\n+        subset: Subset of the data to return.\n+            Either `\"training\"`, `\"validation\"`, or `None`.\n+            If `None`, we return all of the data.\n+\n+    Returns:\n+        tuple (samples, labels), potentially restricted to the specified subset.\n+    \"\"\"\n+    if not validation_split:\n+        return samples, labels\n+\n+    num_val_samples = int(validation_split * len(samples))\n+    if subset == \"training\":\n+        io_utils.print_msg(\n+            f\"Using {len(samples) - num_val_samples} \" f\"files for training.\"\n+        )\n+        samples = samples[:-num_val_samples]\n+        labels = labels[:-num_val_samples]\n+    elif subset == \"validation\":\n+        io_utils.print_msg(f\"Using {num_val_samples} files for validation.\")\n+        samples = samples[-num_val_samples:]\n+        labels = labels[-num_val_samples:]\n+    else:\n+        raise ValueError(\n+            '`subset` must be either \"training\" '\n+            f'or \"validation\", received: {subset}'\n+        )\n+    return samples, labels\n+\n+\n+def labels_to_dataset(labels, label_mode, num_classes):\n+    \"\"\"Create a `tf.data.Dataset` from the list/tuple of labels.\n+\n+    Args:\n+        labels: list/tuple of labels to be converted into a `tf.data.Dataset`.\n+        label_mode: String describing the encoding of `labels`. Options are:\n+        - `\"binary\"` indicates that the labels (there can be only 2) are encoded\n+            as `float32` scalars with values 0 or 1\n+            (e.g. for `binary_crossentropy`).\n+        - `\"categorical\"` means that the labels are mapped into a categorical\n+            vector.  (e.g. for `categorical_crossentropy` loss).\n+        num_classes: number of classes of labels.\n+\n+    Returns:\n+        A `tf.data.Dataset` instance.\n+    \"\"\"\n+    label_ds = tf.data.Dataset.from_tensor_slices(labels)\n+    if label_mode == \"binary\":\n+        label_ds = label_ds.map(\n+            lambda x: tf.expand_dims(tf.cast(x, \"float32\"), axis=-1),\n+            num_parallel_calls=tf.data.AUTOTUNE,\n+        )\n+    elif label_mode == \"categorical\":\n+        label_ds = label_ds.map(\n+            lambda x: tf.one_hot(x, num_classes),\n+            num_parallel_calls=tf.data.AUTOTUNE,\n+        )\n+    return label_ds\n+\n+\n+def check_validation_split_arg(validation_split, subset, shuffle, seed):\n+    \"\"\"Raise errors in case of invalid argument values.\n+\n+    Args:\n+        validation_split: float between 0 and 1, fraction of data to reserve for\n+            validation.\n+        subset: One of `\"training\"`, `\"validation\"`, or `\"both\"`. Only used if\n+            `validation_split` is set.\n+        shuffle: Whether to shuffle the data. Either `True` or `False`.\n+        seed: random seed for shuffling and transformations.\n+    \"\"\"\n+    if validation_split and not 0 < validation_split < 1:\n+        raise ValueError(\n+            \"`validation_split` must be between 0 and 1, \"\n+            f\"received: {validation_split}\"\n+        )\n+    if (validation_split or subset) and not (validation_split and subset):\n+        raise ValueError(\n+            \"If `subset` is set, `validation_split` must be set, and inversely.\"\n+        )\n+    if subset not in (\"training\", \"validation\", \"both\", None):\n+        raise ValueError(\n+            '`subset` must be either \"training\", '\n+            f'\"validation\" or \"both\", received: {subset}'\n+        )\n+    if validation_split and shuffle and seed is None:\n+        raise ValueError(\n+            \"If using `validation_split` and shuffling the data, you must \"\n+            \"provide a `seed` argument, to make sure that there is no \"\n+            \"overlap between the training and validation subset.\"\n+        )\n\n@@ -1,6 +1,12 @@\n+import numpy as np\n+\n from keras_core.api_export import keras_core_export\n+from keras_core.utils import dataset_utils\n+from keras_core.utils import image_utils\n from keras_core.utils.module_utils import tensorflow as tf\n \n+ALLOWLIST_FORMATS = (\".bmp\", \".gif\", \".jpeg\", \".jpg\", \".png\")\n+\n \n @keras_core_export(\n     [\n@@ -136,20 +142,231 @@ def image_dataset_from_directory(\n     - if `color_mode` is `\"rgba\"`,\n         there are 4 channels in the image tensors.\n     \"\"\"\n-    # TODO: long-term, port implementation.\n-    return tf.keras.utils.image_dataset_from_directory(\n+    if labels not in (\"inferred\", None):\n+        if not isinstance(labels, (list, tuple)):\n+            raise ValueError(\n+                \"`labels` argument should be a list/tuple of integer labels, \"\n+                \"of the same size as the number of image files in the target \"\n+                \"directory. If you wish to infer the labels from the \"\n+                \"subdirectory \"\n+                'names in the target directory, pass `labels=\"inferred\"`. '\n+                \"If you wish to get a dataset that only contains images \"\n+                f\"(no labels), pass `labels=None`. Received: labels={labels}\"\n+            )\n+        if class_names:\n+            raise ValueError(\n+                \"You can only pass `class_names` if \"\n+                f'`labels=\"inferred\"`. Received: labels={labels}, and '\n+                f\"class_names={class_names}\"\n+            )\n+    if label_mode not in {\"int\", \"categorical\", \"binary\", None}:\n+        raise ValueError(\n+            '`label_mode` argument must be one of \"int\", '\n+            '\"categorical\", \"binary\", '\n+            f\"or None. Received: label_mode={label_mode}\"\n+        )\n+    if labels is None or label_mode is None:\n+        labels = None\n+        label_mode = None\n+    if color_mode == \"rgb\":\n+        num_channels = 3\n+    elif color_mode == \"rgba\":\n+        num_channels = 4\n+    elif color_mode == \"grayscale\":\n+        num_channels = 1\n+    else:\n+        raise ValueError(\n+            '`color_mode` must be one of {\"rgb\", \"rgba\", \"grayscale\"}. '\n+            f\"Received: color_mode={color_mode}\"\n+        )\n+\n+    interpolation = interpolation.lower()\n+    supported_interpolations = (\n+        \"bilinear\",\n+        \"nearest\",\n+        \"bicubic\",\n+        \"area\",\n+        \"lanczos3\",\n+        \"lanczos5\",\n+        \"gaussian\",\n+        \"mitchellcubic\",\n+    )\n+    if interpolation not in supported_interpolations:\n+        raise ValueError(\n+            \"Argument `interpolation` should be one of \"\n+            f\"{supported_interpolations}. \"\n+            f\"Received: interpolation={interpolation}\"\n+        )\n+\n+    dataset_utils.check_validation_split_arg(\n+        validation_split, subset, shuffle, seed\n+    )\n+\n+    if seed is None:\n+        seed = np.random.randint(1e6)\n+    image_paths, labels, class_names = dataset_utils.index_directory(\n         directory,\n-        labels=labels,\n-        label_mode=label_mode,\n+        labels,\n+        formats=ALLOWLIST_FORMATS,\n         class_names=class_names,\n-        color_mode=color_mode,\n-        batch_size=batch_size,\n-        image_size=image_size,\n         shuffle=shuffle,\n         seed=seed,\n-        validation_split=validation_split,\n-        subset=subset,\n-        interpolation=interpolation,\n         follow_links=follow_links,\n+    )\n+\n+    if label_mode == \"binary\" and len(class_names) != 2:\n+        raise ValueError(\n+            'When passing `label_mode=\"binary\"`, there must be exactly 2 '\n+            f\"class_names. Received: class_names={class_names}\"\n+        )\n+\n+    if subset == \"both\":\n+        (\n+            image_paths_train,\n+            labels_train,\n+        ) = dataset_utils.get_training_or_validation_split(\n+            image_paths, labels, validation_split, \"training\"\n+        )\n+        (\n+            image_paths_val,\n+            labels_val,\n+        ) = dataset_utils.get_training_or_validation_split(\n+            image_paths, labels, validation_split, \"validation\"\n+        )\n+        if not image_paths_train:\n+            raise ValueError(\n+                f\"No training images found in directory {directory}. \"\n+                f\"Allowed formats: {ALLOWLIST_FORMATS}\"\n+            )\n+        if not image_paths_val:\n+            raise ValueError(\n+                f\"No validation images found in directory {directory}. \"\n+                f\"Allowed formats: {ALLOWLIST_FORMATS}\"\n+            )\n+        train_dataset = paths_and_labels_to_dataset(\n+            image_paths=image_paths_train,\n+            image_size=image_size,\n+            num_channels=num_channels,\n+            labels=labels_train,\n+            label_mode=label_mode,\n+            num_classes=len(class_names),\n+            interpolation=interpolation,\n             crop_to_aspect_ratio=crop_to_aspect_ratio,\n         )\n+        val_dataset = paths_and_labels_to_dataset(\n+            image_paths=image_paths_val,\n+            image_size=image_size,\n+            num_channels=num_channels,\n+            labels=labels_val,\n+            label_mode=label_mode,\n+            num_classes=len(class_names),\n+            interpolation=interpolation,\n+            crop_to_aspect_ratio=crop_to_aspect_ratio,\n+        )\n+\n+        if batch_size is not None:\n+            if shuffle:\n+                # Shuffle locally at each iteration\n+                train_dataset = train_dataset.shuffle(\n+                    buffer_size=batch_size * 8, seed=seed\n+                )\n+            train_dataset = train_dataset.batch(batch_size)\n+            val_dataset = val_dataset.batch(batch_size)\n+        else:\n+            if shuffle:\n+                train_dataset = train_dataset.shuffle(\n+                    buffer_size=1024, seed=seed\n+                )\n+\n+        train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n+        val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)\n+\n+        # Users may need to reference `class_names`.\n+        train_dataset.class_names = class_names\n+        val_dataset.class_names = class_names\n+\n+        # Include file paths for images as attribute.\n+        train_dataset.file_paths = image_paths_train\n+        val_dataset.file_paths = image_paths_val\n+        dataset = [train_dataset, val_dataset]\n+    else:\n+        image_paths, labels = dataset_utils.get_training_or_validation_split(\n+            image_paths, labels, validation_split, subset\n+        )\n+        if not image_paths:\n+            raise ValueError(\n+                f\"No images found in directory {directory}. \"\n+                f\"Allowed formats: {ALLOWLIST_FORMATS}\"\n+            )\n+\n+        dataset = paths_and_labels_to_dataset(\n+            image_paths=image_paths,\n+            image_size=image_size,\n+            num_channels=num_channels,\n+            labels=labels,\n+            label_mode=label_mode,\n+            num_classes=len(class_names),\n+            interpolation=interpolation,\n+            crop_to_aspect_ratio=crop_to_aspect_ratio,\n+        )\n+\n+        if batch_size is not None:\n+            if shuffle:\n+                # Shuffle locally at each iteration\n+                dataset = dataset.shuffle(buffer_size=batch_size * 8, seed=seed)\n+            dataset = dataset.batch(batch_size)\n+        else:\n+            if shuffle:\n+                dataset = dataset.shuffle(buffer_size=1024, seed=seed)\n+\n+        dataset = dataset.prefetch(tf.data.AUTOTUNE)\n+\n+        # Users may need to reference `class_names`.\n+        dataset.class_names = class_names\n+\n+        # Include file paths for images as attribute.\n+        dataset.file_paths = image_paths\n+    return dataset\n+\n+\n+def paths_and_labels_to_dataset(\n+    image_paths,\n+    image_size,\n+    num_channels,\n+    labels,\n+    label_mode,\n+    num_classes,\n+    interpolation,\n+    crop_to_aspect_ratio=False,\n+):\n+    \"\"\"Constructs a dataset of images and labels.\"\"\"\n+    # TODO(fchollet): consider making num_parallel_calls settable\n+    path_ds = tf.data.Dataset.from_tensor_slices(image_paths)\n+    args = (image_size, num_channels, interpolation, crop_to_aspect_ratio)\n+    img_ds = path_ds.map(\n+        lambda x: load_image(x, *args), num_parallel_calls=tf.data.AUTOTUNE\n+    )\n+    if label_mode:\n+        label_ds = dataset_utils.labels_to_dataset(\n+            labels, label_mode, num_classes\n+        )\n+        img_ds = tf.data.Dataset.zip((img_ds, label_ds))\n+    return img_ds\n+\n+\n+def load_image(\n+    path, image_size, num_channels, interpolation, crop_to_aspect_ratio=False\n+):\n+    \"\"\"Load an image from a path and resize it.\"\"\"\n+    img = tf.io.read_file(path)\n+    img = tf.image.decode_image(\n+        img, channels=num_channels, expand_animations=False\n+    )\n+    if crop_to_aspect_ratio:\n+        img = image_utils.smart_resize(\n+            img, image_size, interpolation=interpolation\n+        )\n+    else:\n+        img = tf.image.resize(img, image_size, method=interpolation)\n+    img.set_shape((image_size[0], image_size[1], num_channels))\n+    return img\n\n@@ -36,3 +36,4 @@ class LazyModule:\n \n tensorflow = LazyModule(\"tensorflow\")\n gfile = LazyModule(\"tensorflow.io.gfile\", pip_name=\"tensorflow\")\n+tensorflow_io = LazyModule(\"tensorflow_io\")\n\n@@ -1,4 +1,7 @@\n+import numpy as np\n+\n from keras_core.api_export import keras_core_export\n+from keras_core.utils import dataset_utils\n from keras_core.utils.module_utils import tensorflow as tf\n \n \n@@ -106,17 +109,160 @@ def text_dataset_from_directory(\n         of shape `(batch_size, num_classes)`, representing a one-hot\n         encoding of the class index.\n     \"\"\"\n-    # TODO: long-term, port implementation.\n-    return tf.keras.utils.text_dataset_from_directory(\n+    if labels not in (\"inferred\", None):\n+        if not isinstance(labels, (list, tuple)):\n+            raise ValueError(\n+                \"`labels` argument should be a list/tuple of integer labels, \"\n+                \"of the same size as the number of text files in the target \"\n+                \"directory. If you wish to infer the labels from the \"\n+                \"subdirectory names in the target directory, \"\n+                'pass `labels=\"inferred\"`. '\n+                \"If you wish to get a dataset that only contains text samples \"\n+                f\"(no labels), pass `labels=None`. Received: labels={labels}\"\n+            )\n+        if class_names:\n+            raise ValueError(\n+                \"You can only pass `class_names` if \"\n+                f'`labels=\"inferred\"`. Received: labels={labels}, and '\n+                f\"class_names={class_names}\"\n+            )\n+    if label_mode not in {\"int\", \"categorical\", \"binary\", None}:\n+        raise ValueError(\n+            '`label_mode` argument must be one of \"int\", '\n+            '\"categorical\", \"binary\", '\n+            f\"or None. Received: label_mode={label_mode}\"\n+        )\n+    if labels is None or label_mode is None:\n+        labels = None\n+        label_mode = None\n+    dataset_utils.check_validation_split_arg(\n+        validation_split, subset, shuffle, seed\n+    )\n+\n+    if seed is None:\n+        seed = np.random.randint(1e6)\n+    file_paths, labels, class_names = dataset_utils.index_directory(\n         directory,\n-        labels=labels,\n-        label_mode=label_mode,\n+        labels,\n+        formats=(\".txt\",),\n         class_names=class_names,\n-        batch_size=batch_size,\n-        max_length=max_length,\n         shuffle=shuffle,\n         seed=seed,\n-        validation_split=validation_split,\n-        subset=subset,\n         follow_links=follow_links,\n     )\n+\n+    if label_mode == \"binary\" and len(class_names) != 2:\n+        raise ValueError(\n+            'When passing `label_mode=\"binary\"`, there must be exactly 2 '\n+            f\"class_names. Received: class_names={class_names}\"\n+        )\n+\n+    if subset == \"both\":\n+        (\n+            file_paths_train,\n+            labels_train,\n+        ) = dataset_utils.get_training_or_validation_split(\n+            file_paths, labels, validation_split, \"training\"\n+        )\n+        (\n+            file_paths_val,\n+            labels_val,\n+        ) = dataset_utils.get_training_or_validation_split(\n+            file_paths, labels, validation_split, \"validation\"\n+        )\n+        if not file_paths_train:\n+            raise ValueError(\n+                f\"No training text files found in directory {directory}. \"\n+                \"Allowed format: .txt\"\n+            )\n+        if not file_paths_val:\n+            raise ValueError(\n+                f\"No validation text files found in directory {directory}. \"\n+                \"Allowed format: .txt\"\n+            )\n+        train_dataset = paths_and_labels_to_dataset(\n+            file_paths=file_paths_train,\n+            labels=labels_train,\n+            label_mode=label_mode,\n+            num_classes=len(class_names),\n+            max_length=max_length,\n+        )\n+        val_dataset = paths_and_labels_to_dataset(\n+            file_paths=file_paths_val,\n+            labels=labels_val,\n+            label_mode=label_mode,\n+            num_classes=len(class_names),\n+            max_length=max_length,\n+        )\n+\n+        train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n+        val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)\n+        if batch_size is not None:\n+            if shuffle:\n+                # Shuffle locally at each iteration\n+                train_dataset = train_dataset.shuffle(\n+                    buffer_size=batch_size * 8, seed=seed\n+                )\n+            train_dataset = train_dataset.batch(batch_size)\n+            val_dataset = val_dataset.batch(batch_size)\n+        else:\n+            if shuffle:\n+                train_dataset = train_dataset.shuffle(\n+                    buffer_size=1024, seed=seed\n+                )\n+        # Users may need to reference `class_names`.\n+        train_dataset.class_names = class_names\n+        val_dataset.class_names = class_names\n+        dataset = [train_dataset, val_dataset]\n+    else:\n+        file_paths, labels = dataset_utils.get_training_or_validation_split(\n+            file_paths, labels, validation_split, subset\n+        )\n+        if not file_paths:\n+            raise ValueError(\n+                f\"No text files found in directory {directory}. \"\n+                \"Allowed format: .txt\"\n+            )\n+        dataset = paths_and_labels_to_dataset(\n+            file_paths=file_paths,\n+            labels=labels,\n+            label_mode=label_mode,\n+            num_classes=len(class_names),\n+            max_length=max_length,\n+        )\n+        dataset = dataset.prefetch(tf.data.AUTOTUNE)\n+        if batch_size is not None:\n+            if shuffle:\n+                # Shuffle locally at each iteration\n+                dataset = dataset.shuffle(buffer_size=batch_size * 8, seed=seed)\n+            dataset = dataset.batch(batch_size)\n+        else:\n+            if shuffle:\n+                dataset = dataset.shuffle(buffer_size=1024, seed=seed)\n+        # Users may need to reference `class_names`.\n+        dataset.class_names = class_names\n+    return dataset\n+\n+\n+def paths_and_labels_to_dataset(\n+    file_paths, labels, label_mode, num_classes, max_length\n+):\n+    \"\"\"Constructs a dataset of text strings and labels.\"\"\"\n+    path_ds = tf.data.Dataset.from_tensor_slices(file_paths)\n+    string_ds = path_ds.map(\n+        lambda x: path_to_string_content(x, max_length),\n+        num_parallel_calls=tf.data.AUTOTUNE,\n+    )\n+    if label_mode:\n+        label_ds = dataset_utils.labels_to_dataset(\n+            labels, label_mode, num_classes\n+        )\n+        string_ds = tf.data.Dataset.zip((string_ds, label_ds))\n+    return string_ds\n+\n+\n+def path_to_string_content(path, max_length):\n+    txt = tf.io.read_file(path)\n+    if max_length is not None:\n+        txt = tf.strings.substr(txt, 0, max_length)\n+    return txt\n\n@@ -1,3 +1,5 @@\n+import numpy as np\n+\n from keras_core.api_export import keras_core_export\n from keras_core.utils.module_utils import tensorflow as tf\n \n@@ -131,16 +133,129 @@ def timeseries_dataset_from_array(\n         break\n     ```\n     \"\"\"\n-    # TODO: long-term, port implementation.\n-    return tf.keras.utils.timeseries_dataset_from_array(\n-        data,\n-        targets,\n-        sequence_length,\n-        sequence_stride=sequence_stride,\n-        sampling_rate=sampling_rate,\n-        batch_size=batch_size,\n-        shuffle=shuffle,\n-        seed=seed,\n-        start_index=start_index,\n-        end_index=end_index,\n+    if start_index:\n+        if start_index < 0:\n+            raise ValueError(\n+                \"`start_index` must be 0 or greater. Received: \"\n+                f\"start_index={start_index}\"\n             )\n+        if start_index >= len(data):\n+            raise ValueError(\n+                \"`start_index` must be lower than the length of the \"\n+                f\"data. Received: start_index={start_index}, for data \"\n+                f\"of length {len(data)}\"\n+            )\n+    if end_index:\n+        if start_index and end_index <= start_index:\n+            raise ValueError(\n+                \"`end_index` must be higher than `start_index`. \"\n+                f\"Received: start_index={start_index}, and \"\n+                f\"end_index={end_index} \"\n+            )\n+        if end_index >= len(data):\n+            raise ValueError(\n+                \"`end_index` must be lower than the length of the \"\n+                f\"data. Received: end_index={end_index}, for data of \"\n+                f\"length {len(data)}\"\n+            )\n+        if end_index <= 0:\n+            raise ValueError(\n+                \"`end_index` must be higher than 0. \"\n+                f\"Received: end_index={end_index}\"\n+            )\n+\n+    # Validate strides\n+    if sampling_rate <= 0:\n+        raise ValueError(\n+            \"`sampling_rate` must be higher than 0. Received: \"\n+            f\"sampling_rate={sampling_rate}\"\n+        )\n+    if sampling_rate >= len(data):\n+        raise ValueError(\n+            \"`sampling_rate` must be lower than the length of the \"\n+            f\"data. Received: sampling_rate={sampling_rate}, for data \"\n+            f\"of length {len(data)}\"\n+        )\n+    if sequence_stride <= 0:\n+        raise ValueError(\n+            \"`sequence_stride` must be higher than 0. Received: \"\n+            f\"sequence_stride={sequence_stride}\"\n+        )\n+    if sequence_stride >= len(data):\n+        raise ValueError(\n+            \"`sequence_stride` must be lower than the length of the \"\n+            f\"data. Received: sequence_stride={sequence_stride}, for \"\n+            f\"data of length {len(data)}\"\n+        )\n+\n+    if start_index is None:\n+        start_index = 0\n+    if end_index is None:\n+        end_index = len(data)\n+\n+    # Determine the lowest dtype to store start positions (to lower memory\n+    # usage).\n+    num_seqs = end_index - start_index - (sequence_length - 1) * sampling_rate\n+    if targets is not None:\n+        num_seqs = min(num_seqs, len(targets))\n+    if num_seqs < 2147483647:\n+        index_dtype = \"int32\"\n+    else:\n+        index_dtype = \"int64\"\n+\n+    # Generate start positions\n+    start_positions = np.arange(0, num_seqs, sequence_stride, dtype=index_dtype)\n+    if shuffle:\n+        if seed is None:\n+            seed = np.random.randint(1e6)\n+        rng = np.random.RandomState(seed)\n+        rng.shuffle(start_positions)\n+\n+    sequence_length = tf.cast(sequence_length, dtype=index_dtype)\n+    sampling_rate = tf.cast(sampling_rate, dtype=index_dtype)\n+\n+    positions_ds = tf.data.Dataset.from_tensors(start_positions).repeat()\n+\n+    # For each initial window position, generates indices of the window elements\n+    indices = tf.data.Dataset.zip(\n+        (tf.data.Dataset.range(len(start_positions)), positions_ds)\n+    ).map(\n+        lambda i, positions: tf.range(\n+            positions[i],\n+            positions[i] + sequence_length * sampling_rate,\n+            sampling_rate,\n+        ),\n+        num_parallel_calls=tf.data.AUTOTUNE,\n+    )\n+\n+    dataset = sequences_from_indices(data, indices, start_index, end_index)\n+    if targets is not None:\n+        indices = tf.data.Dataset.zip(\n+            (tf.data.Dataset.range(len(start_positions)), positions_ds)\n+        ).map(\n+            lambda i, positions: positions[i],\n+            num_parallel_calls=tf.data.AUTOTUNE,\n+        )\n+        target_ds = sequences_from_indices(\n+            targets, indices, start_index, end_index\n+        )\n+        dataset = tf.data.Dataset.zip((dataset, target_ds))\n+    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n+    if batch_size is not None:\n+        if shuffle:\n+            # Shuffle locally at each iteration\n+            dataset = dataset.shuffle(buffer_size=batch_size * 8, seed=seed)\n+        dataset = dataset.batch(batch_size)\n+    else:\n+        if shuffle:\n+            dataset = dataset.shuffle(buffer_size=1024, seed=seed)\n+    return dataset\n+\n+\n+def sequences_from_indices(array, indices_ds, start_index, end_index):\n+    dataset = tf.data.Dataset.from_tensors(array[start_index:end_index])\n+    dataset = tf.data.Dataset.zip((dataset.repeat(), indices_ds)).map(\n+        lambda steps, inds: tf.gather(steps, inds),\n+        num_parallel_calls=tf.data.AUTOTUNE,\n+    )\n+    return dataset\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b7d65eb4325d8a4ed09180072a3a4de2483ccad3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 399 | Contributors (this commit): 1 | Commits (past 90d): 3 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -363,8 +363,13 @@ def load_image(\n         img, channels=num_channels, expand_animations=False\n     )\n     if crop_to_aspect_ratio:\n+        from keras_core.backend import tensorflow as tf_backend\n+\n         img = image_utils.smart_resize(\n-            img, image_size, interpolation=interpolation\n+            img,\n+            image_size,\n+            interpolation=interpolation,\n+            backend_module=tf_backend,\n         )\n     else:\n         img = tf.image.resize(img, image_size, method=interpolation)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#143cd2ae93ee8ac3d335fcd8c237b6a95533e256", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 353 | Lines Deleted: 26 | Files Changed: 9 | Hunks: 61 | Methods Changed: 49 | Complexity Δ (Sum/Max): 63/24 | Churn Δ: 379 | Churn Cumulative: 7796 | Contributors (this commit): 17 | Commits (past 90d): 129 | Contributors (cumulative): 54 | DMM Complexity: 1.0\n\nDIFF:\n@@ -58,9 +58,9 @@ def get_model():\n     # Make a simple convnet with batch normalization and dropout.\n     inputs = keras.Input(shape=(28, 28, 1))\n     x = keras.layers.Rescaling(1.0 / 255.0)(inputs)\n-    x = keras.layers.Conv2D(filters=12, kernel_size=3, padding=\"same\", use_bias=False)(\n-        x\n-    )\n+    x = keras.layers.Conv2D(\n+        filters=12, kernel_size=3, padding=\"same\", use_bias=False\n+    )(x)\n     x = keras.layers.BatchNormalization(scale=False, center=True)(x)\n     x = keras.layers.ReLU()(x)\n     x = keras.layers.Conv2D(\n@@ -187,7 +187,11 @@ compute_gradients = jax.value_and_grad(compute_loss, has_aux=True)\n # Training step, Keras provides a pure functional optimizer.stateless_apply\n @jax.jit\n def train_step(train_state, x, y):\n-    trainable_variables, non_trainable_variables, optimizer_variables = train_state\n+    (\n+        trainable_variables,\n+        non_trainable_variables,\n+        optimizer_variables,\n+    ) = train_state\n     (loss_value, non_trainable_variables), grads = compute_gradients(\n         trainable_variables, non_trainable_variables, x, y\n     )\n@@ -211,7 +215,9 @@ def get_replicated_train_state(devices):\n     var_replication = NamedSharding(var_mesh, P())\n \n     # Apply the distribution settings to the model variables\n-    trainable_variables = jax.device_put(model.trainable_variables, var_replication)\n+    trainable_variables = jax.device_put(\n+        model.trainable_variables, var_replication\n+    )\n     non_trainable_variables = jax.device_put(\n         model.non_trainable_variables, var_replication\n     )\n@@ -255,7 +261,9 @@ for epoch in range(num_epochs):\n trainable_variables, non_trainable_variables, optimizer_variables = train_state\n for variable, value in zip(model.trainable_variables, trainable_variables):\n     variable.assign(value)\n-for variable, value in zip(model.non_trainable_variables, non_trainable_variables):\n+for variable, value in zip(\n+    model.non_trainable_variables, non_trainable_variables\n+):\n     variable.assign(value)\n \n \"\"\"\n\n@@ -53,9 +53,9 @@ def get_model():\n     # Make a simple convnet with batch normalization and dropout.\n     inputs = keras.Input(shape=(28, 28, 1))\n     x = keras.layers.Rescaling(1.0 / 255.0)(inputs)\n-    x = keras.layers.Conv2D(filters=12, kernel_size=3, padding=\"same\", use_bias=False)(\n-        x\n-    )\n+    x = keras.layers.Conv2D(\n+        filters=12, kernel_size=3, padding=\"same\", use_bias=False\n+    )(x)\n     x = keras.layers.BatchNormalization(scale=False, center=True)(x)\n     x = keras.layers.ReLU()(x)\n     x = keras.layers.Conv2D(\n@@ -231,7 +231,9 @@ def per_device_launch_fn(current_gpu_index, num_gpu):\n     model = get_model()\n \n     # prepare the dataloader\n-    dataloader = prepare_dataloader(dataset, current_gpu_index, num_gpu, batch_size)\n+    dataloader = prepare_dataloader(\n+        dataset, current_gpu_index, num_gpu, batch_size\n+    )\n \n     # Instantiate the torch optimizer\n     optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n@@ -107,10 +107,18 @@ def arccos(x):\n     return jnp.arccos(x)\n \n \n+def arccosh(x):\n+    return jnp.arccosh(x)\n+\n+\n def arcsin(x):\n     return jnp.arcsin(x)\n \n \n+def arcsinh(x):\n+    return jnp.arcsinh(x)\n+\n+\n def arctan(x):\n     return jnp.arctan(x)\n \n@@ -119,6 +127,10 @@ def arctan2(x1, x2):\n     return jnp.arctan2(x1, x2)\n \n \n+def arctanh(x):\n+    return jnp.arctanh(x)\n+\n+\n def argmax(x, axis=None):\n     return jnp.argmax(x, axis=axis)\n \n@@ -171,6 +183,10 @@ def cos(x):\n     return jnp.cos(x)\n \n \n+def cosh(x):\n+    return jnp.cosh(x)\n+\n+\n def count_nonzero(x, axis=None):\n     return jnp.count_nonzero(x, axis=axis)\n \n@@ -441,6 +457,10 @@ def sin(x):\n     return jnp.sin(x)\n \n \n+def sinh(x):\n+    return jnp.sinh(x)\n+\n+\n def size(x):\n     return jnp.size(x)\n \n@@ -479,6 +499,10 @@ def tan(x):\n     return jnp.tan(x)\n \n \n+def tanh(x):\n+    return jnp.tanh(x)\n+\n+\n def tensordot(x1, x2, axes=2):\n     x1 = convert_to_tensor(x1)\n     x2 = convert_to_tensor(x2)\n\n@@ -84,10 +84,18 @@ def arccos(x):\n     return np.arccos(x)\n \n \n+def arccosh(x):\n+    return np.arccosh(x)\n+\n+\n def arcsin(x):\n     return np.arcsin(x)\n \n \n+def arcsinh(x):\n+    return np.arcsinh(x)\n+\n+\n def arctan(x):\n     return np.arctan(x)\n \n@@ -96,6 +104,10 @@ def arctan2(x1, x2):\n     return np.arctan2(x1, x2)\n \n \n+def arctanh(x):\n+    return np.arctanh(x)\n+\n+\n def argmax(x, axis=None):\n     axis = tuple(axis) if isinstance(axis, list) else axis\n     return np.argmax(x, axis=axis)\n@@ -157,6 +169,10 @@ def cos(x):\n     return np.cos(x)\n \n \n+def cosh(x):\n+    return np.cosh(x)\n+\n+\n def count_nonzero(x, axis=None):\n     axis = tuple(axis) if isinstance(axis, list) else axis\n     return np.count_nonzero(x, axis=axis)\n@@ -438,6 +454,10 @@ def sin(x):\n     return np.sin(x)\n \n \n+def sinh(x):\n+    return np.sinh(x)\n+\n+\n def size(x):\n     return np.size(x)\n \n@@ -480,6 +500,10 @@ def tan(x):\n     return np.tan(x)\n \n \n+def tanh(x):\n+    return np.tanh(x)\n+\n+\n def tensordot(x1, x2, axes=2):\n     axes = tuple(axes) if isinstance(axes, list) else axes\n     return np.tensordot(x1, x2, axes=axes)\n\n@@ -105,10 +105,18 @@ def arccos(x):\n     return tfnp.arccos(x)\n \n \n+def arccosh(x):\n+    return tfnp.arccosh(x)\n+\n+\n def arcsin(x):\n     return tfnp.arcsin(x)\n \n \n+def arcsinh(x):\n+    return tfnp.arcsinh(x)\n+\n+\n def arctan(x):\n     return tfnp.arctan(x)\n \n@@ -117,6 +125,10 @@ def arctan2(x1, x2):\n     return tfnp.arctan2(x1, x2)\n \n \n+def arctanh(x):\n+    return tfnp.arctanh(x)\n+\n+\n def argmax(x, axis=None):\n     return tfnp.argmax(x, axis=axis)\n \n@@ -174,6 +186,10 @@ def cos(x):\n     return tfnp.cos(x)\n \n \n+def cosh(x):\n+    return tfnp.cosh(x)\n+\n+\n def count_nonzero(x, axis=None):\n     return tfnp.count_nonzero(x, axis=axis)\n \n@@ -472,6 +488,10 @@ def sin(x):\n     return tfnp.sin(x)\n \n \n+def sinh(x):\n+    return tfnp.sinh(x)\n+\n+\n def size(x):\n     return tfnp.size(x)\n \n@@ -508,6 +528,10 @@ def tan(x):\n     return tfnp.tan(x)\n \n \n+def tanh(x):\n+    return tfnp.tanh(x)\n+\n+\n def tensordot(x1, x2, axes=2):\n     return tfnp.tensordot(x1, x2, axes=axes)\n \n\n@@ -173,11 +173,21 @@ def arccos(x):\n     return torch.arccos(x)\n \n \n+def arccosh(x):\n+    x = convert_to_tensor(x)\n+    return torch.arccosh(x)\n+\n+\n def arcsin(x):\n     x = convert_to_tensor(x)\n     return torch.arcsin(x)\n \n \n+def arcsinh(x):\n+    x = convert_to_tensor(x)\n+    return torch.arcsinh(x)\n+\n+\n def arctan(x):\n     x = convert_to_tensor(x)\n     return torch.arctan(x)\n@@ -188,6 +198,11 @@ def arctan2(x1, x2):\n     return torch.arctan2(x1, x2)\n \n \n+def arctanh(x):\n+    x = convert_to_tensor(x)\n+    return torch.arctanh(x)\n+\n+\n def argmax(x, axis=None):\n     x = convert_to_tensor(x)\n     return torch.argmax(x, dim=axis)\n@@ -277,6 +292,11 @@ def cos(x):\n     return torch.cos(x)\n \n \n+def cosh(x):\n+    x = convert_to_tensor(x)\n+    return torch.cosh(x)\n+\n+\n def count_nonzero(x, axis=None):\n     x = convert_to_tensor(x)\n     if axis == () or axis == []:\n@@ -729,6 +749,11 @@ def sin(x):\n     return torch.sin(x)\n \n \n+def sinh(x):\n+    x = convert_to_tensor(x)\n+    return torch.sinh(x)\n+\n+\n def size(x):\n     x_shape = convert_to_tensor(tuple(x.shape))\n     return torch.prod(x_shape)\n@@ -806,6 +831,11 @@ def tan(x):\n     return torch.tan(x)\n \n \n+def tanh(x):\n+    x = convert_to_tensor(x)\n+    return torch.tanh(x)\n+\n+\n def tensordot(x1, x2, axes=2):\n     x1, x2 = convert_to_tensor(x1), convert_to_tensor(x2)\n     # Conversion to long necessary for `torch.tensordot`\n\n@@ -57,21 +57,6 @@ def sigmoid(x):\n     return backend.nn.sigmoid(x)\n \n \n-class Tanh(Operation):\n-    def call(self, x):\n-        return backend.nn.tanh(x)\n-\n-    def compute_output_spec(self, x):\n-        return KerasTensor(x.shape, dtype=x.dtype)\n-\n-\n-@keras_core_export([\"keras_core.ops.tanh\", \"keras_core.ops.nn.tanh\"])\n-def tanh(x):\n-    if any_symbolic_tensors((x,)):\n-        return Tanh().symbolic_call(x)\n-    return backend.nn.tanh(x)\n-\n-\n class Softplus(Operation):\n     def call(self, x):\n         return backend.nn.softplus(x)\n\n@@ -10,9 +10,12 @@ amin\n append\n arange\n arccos\n+arccosh\n arcsin\n+arcsinh\n arctan\n arctan2\n+arctanh\n argmax\n argmin\n argsort\n@@ -27,6 +30,7 @@ conj\n conjugate\n copy\n cos\n+cosh\n count_nonzero\n cross\n cumprod\n@@ -102,6 +106,7 @@ roll\n round\n sign\n sin\n+sinh\n size\n sort\n split\n@@ -116,6 +121,7 @@ swapaxes\n take\n take_along_axis\n tan\n+tanh\n tensordot\n tile\n trace\n@@ -713,6 +719,28 @@ def arccos(x):\n     return backend.numpy.arccos(x)\n \n \n+class Arccosh(Operation):\n+    def call(self, x):\n+        return backend.numpy.arccosh(x)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=x.dtype)\n+\n+\n+def arccosh(x):\n+    \"\"\"Inverse hyperbolic cosine, element-wise.\n+\n+    Arguments:\n+        x: Input tensor.\n+\n+    Returns:\n+        Output tensor of same shape as x.\n+    \"\"\"\n+    if any_symbolic_tensors((x,)):\n+        return Arccosh().symbolic_call(x)\n+    return backend.numpy.arccosh(x)\n+\n+\n class Arcsin(Operation):\n     def call(self, x):\n         return backend.numpy.arcsin(x)\n@@ -742,6 +770,29 @@ def arcsin(x):\n     return backend.numpy.arcsin(x)\n \n \n+class Arcsinh(Operation):\n+    def call(self, x):\n+        return backend.numpy.arcsinh(x)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=x.dtype)\n+\n+\n+@keras_core_export([\"keras_core.ops.arcsinh\", \"keras_core.ops.numpy.arcsinh\"])\n+def arcsinh(x):\n+    \"\"\"Inverse hyperbolic sine, element-wise.\n+\n+    Arguments:\n+        x: Input tensor.\n+\n+    Returns:\n+        Output tensor of same shape as x.\n+    \"\"\"\n+    if any_symbolic_tensors((x,)):\n+        return Arcsinh().symbolic_call(x)\n+    return backend.numpy.arcsinh(x)\n+\n+\n class Arctan(Operation):\n     def call(self, x):\n         return backend.numpy.arctan(x)\n@@ -826,6 +877,29 @@ def arctan2(x1, x2):\n     return backend.numpy.arctan2(x1, x2)\n \n \n+class Arctanh(Operation):\n+    def call(self, x):\n+        return backend.numpy.arctanh(x)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=x.dtype)\n+\n+\n+@keras_core_export([\"keras_core.ops.arctanh\", \"keras_core.ops.numpy.arctanh\"])\n+def arctanh(x):\n+    \"\"\"Inverse hyperbolic tangent, element-wise.\n+\n+    Arguments:\n+        x: Input tensor.\n+\n+    Returns:\n+        Output tensor of same shape as x.\n+    \"\"\"\n+    if any_symbolic_tensors((x,)):\n+        return Arctanh().symbolic_call(x)\n+    return backend.numpy.arctanh(x)\n+\n+\n class Argmax(Operation):\n     def __init__(self, axis=None):\n         super().__init__()\n@@ -1289,6 +1363,29 @@ def cos(x):\n     return backend.numpy.cos(x)\n \n \n+class Cosh(Operation):\n+    def call(self, x):\n+        return backend.numpy.cosh(x)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=x.dtype)\n+\n+\n+@keras_core_export([\"keras_core.ops.cosh\", \"keras_core.ops.numpy.cosh\"])\n+def cosh(x):\n+    \"\"\"Hyperbolic cosine, element-wise.\n+\n+    Arguments:\n+        x: Input tensor.\n+\n+    Returns:\n+        Output tensor of same shape as x.\n+    \"\"\"\n+    if any_symbolic_tensors((x,)):\n+        return Cosh().symbolic_call(x)\n+    return backend.numpy.cosh(x)\n+\n+\n class CountNonzero(Operation):\n     def __init__(self, axis=None):\n         super().__init__()\n@@ -3115,6 +3212,29 @@ def sin(x):\n     return backend.numpy.sin(x)\n \n \n+class Sinh(Operation):\n+    def call(self, x):\n+        return backend.numpy.sinh(x)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=x.dtype)\n+\n+\n+@keras_core_export([\"keras_core.ops.sinh\", \"keras_core.ops.numpy.sinh\"])\n+def sinh(x):\n+    \"\"\"Hyperbolic sine, element-wise.\n+\n+    Arguments:\n+        x: Input tensor.\n+\n+    Returns:\n+        Output tensor of same shape as x.\n+    \"\"\"\n+    if any_symbolic_tensors((x,)):\n+        return Sinh().symbolic_call(x)\n+    return backend.numpy.sinh(x)\n+\n+\n class Size(Operation):\n     def call(self, x):\n         return backend.numpy.size(x)\n@@ -3376,6 +3496,29 @@ def tan(x):\n     return backend.numpy.tan(x)\n \n \n+class Tanh(Operation):\n+    def call(self, x):\n+        return backend.numpy.tanh(x)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=x.dtype)\n+\n+\n+@keras_core_export([\"keras_core.ops.tanh\", \"keras_core.ops.numpy.tanh\"])\n+def tanh(x):\n+    \"\"\"Hyperbolic tangent, element-wise.\n+\n+    Arguments:\n+        x: Input tensor.\n+\n+    Returns:\n+        Output tensor of same shape as x.\n+    \"\"\"\n+    if any_symbolic_tensors((x,)):\n+        return Tanh().symbolic_call(x)\n+    return backend.numpy.tanh(x)\n+\n+\n class Tensordot(Operation):\n     def __init__(self, axes=2):\n         super().__init__()\n\n@@ -754,14 +754,26 @@ class NumpyOneInputOpsDynamicShapeTest(testing.TestCase):\n         x = KerasTensor([None, 3])\n         self.assertEqual(knp.arccos(x).shape, (None, 3))\n \n+    def test_arccosh(self):\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.arccosh(x).shape, (None, 3))\n+\n     def test_arcsin(self):\n         x = KerasTensor([None, 3])\n         self.assertEqual(knp.arcsin(x).shape, (None, 3))\n \n+    def test_arcsinh(self):\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.arcsinh(x).shape, (None, 3))\n+\n     def test_arctan(self):\n         x = KerasTensor([None, 3])\n         self.assertEqual(knp.arctan(x).shape, (None, 3))\n \n+    def test_arctanh(self):\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.arctanh(x).shape, (None, 3))\n+\n     def test_argmax(self):\n         x = KerasTensor([None, 3])\n         self.assertEqual(knp.argmax(x).shape, ())\n@@ -855,6 +867,10 @@ class NumpyOneInputOpsDynamicShapeTest(testing.TestCase):\n         x = KerasTensor([None, 3])\n         self.assertEqual(knp.cos(x).shape, (None, 3))\n \n+    def test_cosh(self):\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.cosh(x).shape, (None, 3))\n+\n     def test_count_nonzero(self):\n         x = KerasTensor([None, 3])\n         self.assertEqual(knp.count_nonzero(x).shape, ())\n@@ -1095,6 +1111,10 @@ class NumpyOneInputOpsDynamicShapeTest(testing.TestCase):\n         x = KerasTensor([None, 3])\n         self.assertEqual(knp.sin(x).shape, (None, 3))\n \n+    def test_sinh(self):\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.sinh(x).shape, (None, 3))\n+\n     def test_size(self):\n         x = KerasTensor([None, 3])\n         self.assertEqual(knp.size(x).shape, ())\n@@ -1137,6 +1157,10 @@ class NumpyOneInputOpsDynamicShapeTest(testing.TestCase):\n         x = KerasTensor([None, 3])\n         self.assertEqual(knp.tan(x).shape, (None, 3))\n \n+    def test_tanh(self):\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.tanh(x).shape, (None, 3))\n+\n     def test_tile(self):\n         x = KerasTensor([None, 3])\n         self.assertEqual(knp.tile(x, [2]).shape, (None, 6))\n@@ -1227,14 +1251,26 @@ class NumpyOneInputOpsStaticShapeTest(testing.TestCase):\n         x = KerasTensor([2, 3])\n         self.assertEqual(knp.arccos(x).shape, (2, 3))\n \n+    def test_arccosh(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.arccosh(x).shape, (2, 3))\n+\n     def test_arcsin(self):\n         x = KerasTensor([2, 3])\n         self.assertEqual(knp.arcsin(x).shape, (2, 3))\n \n+    def test_arcsinh(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.arcsinh(x).shape, (2, 3))\n+\n     def test_arctan(self):\n         x = KerasTensor([2, 3])\n         self.assertEqual(knp.arctan(x).shape, (2, 3))\n \n+    def test_arctanh(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.arctanh(x).shape, (2, 3))\n+\n     def test_argmax(self):\n         x = KerasTensor([2, 3])\n         self.assertEqual(knp.argmax(x).shape, ())\n@@ -1297,6 +1333,10 @@ class NumpyOneInputOpsStaticShapeTest(testing.TestCase):\n         x = KerasTensor([2, 3])\n         self.assertEqual(knp.cos(x).shape, (2, 3))\n \n+    def test_cosh(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.cosh(x).shape, (2, 3))\n+\n     def test_count_nonzero(self):\n         x = KerasTensor([2, 3])\n         self.assertEqual(knp.count_nonzero(x).shape, ())\n@@ -1532,6 +1572,10 @@ class NumpyOneInputOpsStaticShapeTest(testing.TestCase):\n         x = KerasTensor([2, 3])\n         self.assertEqual(knp.sin(x).shape, (2, 3))\n \n+    def test_sinh(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.sinh(x).shape, (2, 3))\n+\n     def test_size(self):\n         x = KerasTensor([2, 3])\n         self.assertEqual(knp.size(x).shape, ())\n@@ -1579,6 +1623,10 @@ class NumpyOneInputOpsStaticShapeTest(testing.TestCase):\n         x = KerasTensor([2, 3])\n         self.assertEqual(knp.tan(x).shape, (2, 3))\n \n+    def test_tanh(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.tanh(x).shape, (2, 3))\n+\n     def test_tile(self):\n         x = KerasTensor([2, 3])\n         self.assertEqual(knp.tile(x, [2]).shape, (2, 6))\n@@ -2266,18 +2314,42 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase):\n             np.transpose(x, axes=(1, 0, 3, 2, 4)),\n         )\n \n-    def test_arcos(self):\n+    def test_arccos(self):\n         x = np.array([[1, 0.5, -0.7], [0.9, 0.2, -1]])\n         self.assertAllClose(knp.arccos(x), np.arccos(x))\n \n         self.assertAllClose(knp.Arccos()(x), np.arccos(x))\n \n+    def test_arccosh(self):\n+        x = np.array([[1, 0.5, -0.7], [0.9, 0.2, -1]])\n+        self.assertAllClose(knp.arccosh(x), np.arccosh(x))\n+\n+        self.assertAllClose(knp.Arccosh()(x), np.arccosh(x))\n+\n     def test_arcsin(self):\n         x = np.array([[1, 0.5, -0.7], [0.9, 0.2, -1]])\n         self.assertAllClose(knp.arcsin(x), np.arcsin(x))\n \n         self.assertAllClose(knp.Arcsin()(x), np.arcsin(x))\n \n+    def test_arcsinh(self):\n+        x = np.array([[1, 0.5, -0.7], [0.9, 0.2, -1]])\n+        self.assertAllClose(knp.arcsinh(x), np.arcsinh(x))\n+\n+        self.assertAllClose(knp.Arcsinh()(x), np.arcsinh(x))\n+\n+    def test_arctan(self):\n+        x = np.array([[1, 0.5, -0.7], [0.9, 0.2, -1]])\n+        self.assertAllClose(knp.arctan(x), np.arctan(x))\n+\n+        self.assertAllClose(knp.Arctan()(x), np.arctan(x))\n+\n+    def test_arctanh(self):\n+        x = np.array([[1, 0.5, -0.7], [0.9, 0.2, -1]])\n+        self.assertAllClose(knp.arctanh(x), np.arctanh(x))\n+\n+        self.assertAllClose(knp.Arctanh()(x), np.arctanh(x))\n+\n     def test_argmax(self):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n         self.assertAllClose(knp.argmax(x), np.argmax(x))\n@@ -2433,6 +2505,11 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase):\n         self.assertAllClose(knp.cos(x), np.cos(x))\n         self.assertAllClose(knp.Cos()(x), np.cos(x))\n \n+    def test_cosh(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        self.assertAllClose(knp.cosh(x), np.cosh(x))\n+        self.assertAllClose(knp.Cosh()(x), np.cosh(x))\n+\n     def test_count_nonzero(self):\n         x = np.array([[0, 2, 3], [3, 2, 0]])\n         self.assertAllClose(knp.count_nonzero(x), np.count_nonzero(x))\n@@ -2899,6 +2976,11 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase):\n         self.assertAllClose(knp.sin(x), np.sin(x))\n         self.assertAllClose(knp.Sin()(x), np.sin(x))\n \n+    def test_sinh(self):\n+        x = np.array([[1, -2, 3], [-3, 2, -1]])\n+        self.assertAllClose(knp.sinh(x), np.sinh(x))\n+        self.assertAllClose(knp.Sinh()(x), np.sinh(x))\n+\n     def test_size(self):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n         self.assertAllClose(knp.size(x), np.size(x))\n@@ -2993,6 +3075,11 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase):\n         self.assertAllClose(knp.tan(x), np.tan(x))\n         self.assertAllClose(knp.Tan()(x), np.tan(x))\n \n+    def test_tanh(self):\n+        x = np.array([[1, -2, 3], [-3, 2, -1]])\n+        self.assertAllClose(knp.tanh(x), np.tanh(x))\n+        self.assertAllClose(knp.Tanh()(x), np.tanh(x))\n+\n     def test_tile(self):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n         self.assertAllClose(knp.tile(x, [2, 3]), np.tile(x, [2, 3]))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
