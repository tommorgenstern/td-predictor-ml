{"custom_id": "keras#4ba641806b4afcf95bece96c3b15e646fc092161", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 13 | Files Changed: 3 | Hunks: 12 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 26 | Churn Cumulative: 13648 | Contributors (this commit): 72 | Commits (past 90d): 17 | Contributors (cumulative): 85 | DMM Complexity: None\n\nDIFF:\n@@ -1680,7 +1680,7 @@ class DepthwiseConv2D(Conv2D):\n             all spatial dimensions.\n             Specifying any stride value != 1 is incompatible with specifying\n             any `dilation_rate` value != 1.\n-        padding: one of `'valid'` or `'same'` (case-insensitive).\n+        padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n         depth_multiplier: The number of depthwise convolution output channels\n             for each input channel.\n             The total number of depthwise convolution output\n\n@@ -483,10 +483,10 @@ class ConvLSTM2DCell(Layer):\n             any `dilation_rate` value != 1.\n         padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n         data_format: A string,\n-            one of `channels_last` (default) or `channels_first`.\n+            one of `\"channels_last\"` (default) or `\"channels_first\"`.\n             It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"channels_last\".\n+            If you never set it, then it will be `\"channels_last\"`.\n         dilation_rate: An integer or tuple/list of n integers, specifying\n             the dilation rate to use for dilated convolution.\n             Currently, specifying any `dilation_rate` value != 1 is\n@@ -793,15 +793,15 @@ class ConvLSTM2D(ConvRNN2D):\n             any `dilation_rate` value != 1.\n         padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n         data_format: A string,\n-            one of `channels_last` (default) or `channels_first`.\n+            one of `\"channels_last\"` (default) or `\"channels_first\"`.\n             The ordering of the dimensions in the inputs.\n-            `channels_last` corresponds to inputs with shape\n+            `\"channels_last\"` corresponds to inputs with shape\n             `(batch, time, ..., channels)`\n-            while `channels_first` corresponds to\n+            while `\"channels_first\"` corresponds to\n             inputs with shape `(batch, time, channels, ...)`.\n             It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"channels_last\".\n+            If you never set it, then it will be `\"channels_last\"`.\n         dilation_rate: An integer or tuple/list of n integers, specifying\n             the dilation rate to use for dilated convolution.\n             Currently, specifying any `dilation_rate` value != 1 is\n\n@@ -13,11 +13,11 @@ def normalize_tuple(value, n, name):\n     \"\"\"Transforms a single int or iterable of ints into an int tuple.\n \n     # Arguments\n-        value: The value to validate and convert. Could an int, or any iterable\n+        value: The value to validate and convert. Could be an int, or any iterable\n           of ints.\n         n: The size of the tuple to be returned.\n-        name: The name of the argument being validated, e.g. \"strides\" or\n-          \"kernel_size\". This is only used to format error messages.\n+        name: The name of the argument being validated, e.g. `strides` or\n+          `kernel_size`. This is only used to format error messages.\n \n     # Returns\n         A tuple of n integers.\n@@ -54,7 +54,7 @@ def normalize_padding(value):\n     if K.backend() == 'theano':\n         allowed.add('full')\n     if padding not in allowed:\n-        raise ValueError('The `padding` argument must be one of \"valid\", \"same\" (or \"causal\" for Conv1D). '\n+        raise ValueError('The `padding` argument must be one of `\"valid\"`, `\"same\"` (or `\"causal\"` for Conv1D). '\n                          'Received: ' + str(padding))\n     return padding\n \n@@ -89,7 +89,7 @@ def conv_output_length(input_length, filter_size,\n     # Arguments\n         input_length: integer.\n         filter_size: integer.\n-        padding: one of \"same\", \"valid\", \"full\".\n+        padding: one of `\"same\"`, `\"valid\"`, `\"full\"`.\n         stride: integer.\n         dilation: dilation rate, integer.\n \n@@ -117,7 +117,7 @@ def conv_input_length(output_length, filter_size, padding, stride):\n     # Arguments\n         output_length: integer.\n         filter_size: integer.\n-        padding: one of \"same\", \"valid\", \"full\".\n+        padding: one of `\"same\"`, `\"valid\"`, `\"full\"`.\n         stride: integer.\n \n     # Returns\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e77a4cf3f85b45ad4275dfd661073ace1cc06e5a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 17 | Files Changed: 2 | Hunks: 13 | Methods Changed: 7 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 37 | Churn Cumulative: 1687 | Contributors (this commit): 26 | Commits (past 90d): 6 | Contributors (cumulative): 29 | DMM Complexity: 0.0\n\nDIFF:\n@@ -43,8 +43,8 @@ def normalize_tuple(value, n, name):\n             except ValueError:\n                 raise ValueError('The `' + name + '` argument must be a tuple of ' +\n                                  str(n) + ' integers. Received: ' + str(value) + ' '\n-                                 'including element ' + str(single_value) + ' of type' +\n-                                 ' ' + str(type(single_value)))\n+                                 'including element ' + str(single_value) + ' of '\n+                                 'type ' + str(type(single_value)))\n     return value_tuple\n \n \n@@ -54,8 +54,8 @@ def normalize_padding(value):\n     if K.backend() == 'theano':\n         allowed.add('full')\n     if padding not in allowed:\n-        raise ValueError('The `padding` argument must be one of `\"valid\"`, `\"same\"` (or `\"causal\"` for Conv1D). '\n-                         'Received: ' + str(padding))\n+        raise ValueError('The `padding` argument must be one of \"valid\", \"same\" '\n+                         '(or \"causal\" for Conv1D). Received: ' + str(padding))\n     return padding\n \n \n\n@@ -4,7 +4,7 @@ from __future__ import division\n from __future__ import print_function\n \n import hashlib\n-import multiprocessing\n+import multiprocessing as mp\n import os\n import random\n import shutil\n@@ -168,7 +168,7 @@ def get_file(fname,\n \n     # Returns\n         Path to the downloaded file\n-    \"\"\"\n+    \"\"\"  # noqa\n     if cache_dir is None:\n         cache_dir = os.path.join(os.path.expanduser('~'), '.keras')\n     if md5_hash is not None and file_hash is None:\n@@ -303,13 +303,14 @@ class Sequence(object):\n     \"\"\"Base object for fitting to a sequence of data, such as a dataset.\n \n     Every `Sequence` must implement the `__getitem__` and the `__len__` methods.\n-    If you want to modify your dataset between epochs you may implement `on_epoch_end`.\n-    The method `__getitem__` should return a complete batch.\n+    If you want to modify your dataset between epochs you may implement\n+    `on_epoch_end`. The method `__getitem__` should return a complete batch.\n \n     # Notes\n \n-    `Sequence` are a safer way to do multiprocessing. This structure guarantees that the network will only train once\n-     on each sample per epoch which is not the case with generators.\n+    `Sequence` are a safer way to do multiprocessing. This structure guarantees\n+    that the network will only train once on each sample per epoch which is not\n+    the case with generators.\n \n     # Examples\n \n@@ -482,7 +483,7 @@ class OrderedEnqueuer(SequenceEnqueuer):\n         global _SEQUENCE_COUNTER\n         if _SEQUENCE_COUNTER is None:\n             try:\n-                _SEQUENCE_COUNTER = multiprocessing.Value('i', 0)\n+                _SEQUENCE_COUNTER = mp.Value('i', 0)\n             except OSError:\n                 # In this case the OS does not allow us to use\n                 # multiprocessing. We resort to an int\n@@ -517,7 +518,7 @@ class OrderedEnqueuer(SequenceEnqueuer):\n                 (when full, workers could block on `put()`)\n         \"\"\"\n         if self.use_multiprocessing:\n-            self.executor_fn = lambda seqs: multiprocessing.Pool(workers,\n+            self.executor_fn = lambda seqs: mp.Pool(workers,\n                                                     initializer=init_pool,\n                                                     initargs=(seqs,))\n         else:\n@@ -663,7 +664,8 @@ class GeneratorEnqueuer(SequenceEnqueuer):\n                         break\n                     except Exception as e:\n                         # Can't pickle tracebacks.\n-                        # As a compromise, print the traceback and pickle None instead.\n+                        # As a compromise, print the traceback and\n+                        # pickle None instead.\n                         if not hasattr(e, '__traceback__'):\n                             setattr(e, '__traceback__', sys.exc_info()[2])\n                         self.queue.put((False, e))\n@@ -700,9 +702,9 @@ class GeneratorEnqueuer(SequenceEnqueuer):\n         try:\n             self.max_queue_size = max_queue_size\n             if self._use_multiprocessing:\n-                self._manager = multiprocessing.Manager()\n+                self._manager = mp.Manager()\n                 self.queue = self._manager.Queue(maxsize=max_queue_size)\n-                self._stop_event = multiprocessing.Event()\n+                self._stop_event = mp.Event()\n             else:\n                 # On all OSes, avoid **SYSTEMATIC** error in multithreading mode:\n                 # `ValueError: generator already executing`\n@@ -716,7 +718,7 @@ class GeneratorEnqueuer(SequenceEnqueuer):\n                     # Reset random seed else all children processes\n                     # share the same seed\n                     np.random.seed(self.seed)\n-                    thread = multiprocessing.Process(target=self._data_generator_task)\n+                    thread = mp.Process(target=self._data_generator_task)\n                     thread.daemon = True\n                     if self.seed is not None:\n                         self.seed += 1\n@@ -780,7 +782,8 @@ class GeneratorEnqueuer(SequenceEnqueuer):\n                 if value is not None:\n                     yield value\n             else:\n-                all_finished = all([not thread.is_alive() for thread in self._threads])\n+                all_finished = all([not thread.is_alive()\n+                                    for thread in self._threads])\n                 if all_finished and self.queue.empty():\n                     raise StopIteration()\n                 else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f6fad22671db9506acee34b9fd33361de78ab148", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 43 | Lines Deleted: 4 | Files Changed: 3 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 4/2 | Churn Δ: 47 | Churn Cumulative: 11090 | Contributors (this commit): 70 | Commits (past 90d): 7 | Contributors (cumulative): 78 | DMM Complexity: 0.36666666666666664\n\nDIFF:\n@@ -551,6 +551,14 @@ class RNN(Layer):\n         # note that the .build() method of subclasses MUST define\n         # self.input_spec and self.state_spec with complete input shapes.\n         if isinstance(inputs, list):\n+            # get initial_state from full input spec\n+            # as they could be copied to multiple GPU.\n+            if self._num_constants is None:\n+                initial_state = inputs[1:]\n+            else:\n+                initial_state = inputs[1:-self._num_constants]\n+            if len(initial_state) == 0:\n+                initial_state = None\n             inputs = inputs[0]\n         if initial_state is not None:\n             pass\n\n@@ -496,10 +496,27 @@ class Bidirectional(Wrapper):\n             kwargs['constants'] = constants\n \n         if initial_state is not None and has_arg(self.layer.call, 'initial_state'):\n-            forward_state = initial_state[:len(initial_state) // 2]\n-            backward_state = initial_state[len(initial_state) // 2:]\n-            y = self.forward_layer.call(inputs, initial_state=forward_state, **kwargs)\n-            y_rev = self.backward_layer.call(inputs, initial_state=backward_state, **kwargs)\n+            forward_inputs = [inputs[0]]\n+            backward_inputs = [inputs[0]]\n+            pivot = len(initial_state) // 2 + 1\n+            # add forward initial state\n+            forward_state = inputs[1:pivot]\n+            forward_inputs += forward_state\n+            if self._num_constants is None:\n+                # add backward initial state\n+                backward_state = inputs[pivot:]\n+                backward_inputs += backward_state\n+            else:\n+                # add backward initial state\n+                backward_state = inputs[pivot:-self._num_constants]\n+                backward_inputs += backward_state\n+                # add constants for forward and backward layers\n+                forward_inputs += inputs[-self._num_constants:]\n+                backward_inputs += inputs[-self._num_constants:]\n+            y = self.forward_layer.call(forward_inputs,\n+                                        initial_state=forward_state, **kwargs)\n+            y_rev = self.backward_layer.call(backward_inputs,\n+                                             initial_state=backward_state, **kwargs)\n         else:\n             y = self.forward_layer.call(inputs, **kwargs)\n             y_rev = self.backward_layer.call(inputs, **kwargs)\n\n@@ -272,5 +272,19 @@ def multi_gpu_application_folder_generator_benchmark():\n         print('%d gpus training:' % i, total_time)\n \n \n+@keras_test\n+def test_multi_gpu_with_multi_input_layers():\n+    inputs = keras.Input((4, 3))\n+    init_state = keras.Input((3,))\n+    outputs = keras.layers.SimpleRNN(\n+        3, return_sequences=True)(inputs, initial_state=init_state)\n+    x = [np.random.randn(2, 4, 3), np.random.randn(2, 3)]\n+    y = np.random.randn(2, 4, 3)\n+    model = keras.models.Model([inputs, init_state], outputs)\n+    parallel_model = multi_gpu_model(model, 2)\n+    parallel_model.compile(loss='mean_squared_error', optimizer='adam')\n+    parallel_model.train_on_batch(x, y)\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1068e173eafd15e5aa9f40b9f73590a7f5be4a84", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 66 | Lines Deleted: 28 | Files Changed: 5 | Hunks: 15 | Methods Changed: 4 | Complexity Δ (Sum/Max): -1/5 | Churn Δ: 94 | Churn Cumulative: 22691 | Contributors (this commit): 175 | Commits (past 90d): 40 | Contributors (cumulative): 274 | DMM Complexity: 1.0\n\nDIFF:\n@@ -8,6 +8,7 @@ from .common import floatx\n from .common import epsilon\n from .common import image_data_format\n from .common import normalize_data_format\n+from ..utils.generic_utils import transpose_shape\n from collections import defaultdict\n from contextlib import contextmanager\n import warnings\n@@ -1684,12 +1685,8 @@ def conv3d_transpose(x, kernel, output_shape, strides=(1, 1, 1),\n     output_shape = output_shape[1:]\n     # in keras2, need handle output shape in different format\n     if data_format == 'channels_last':\n-        shape = list(output_shape)\n-        shape[0] = output_shape[3]\n-        shape[1] = output_shape[0]\n-        shape[2] = output_shape[1]\n-        shape[3] = output_shape[2]\n-        output_shape = tuple(shape)\n+        output_shape = transpose_shape(output_shape, 'channels_first',\n+                                       spatial_axes=(0, 1, 2))\n \n     x = C.convolution_transpose(\n         kernel,\n@@ -2201,11 +2198,8 @@ def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n     output_shape = output_shape[1:]\n     # in keras2, need handle output shape in different format\n     if data_format == 'channels_last':\n-        shape = list(output_shape)\n-        shape[0] = output_shape[2]\n-        shape[1] = output_shape[0]\n-        shape[2] = output_shape[1]\n-        output_shape = tuple(shape)\n+        output_shape = transpose_shape(output_shape, 'channels_first',\n+                                       spatial_axes=(0, 1))\n \n     x = C.convolution_transpose(\n         kernel,\n\n@@ -20,6 +20,7 @@ import os\n from .common import floatx\n from .common import epsilon\n from .common import normalize_data_format\n+from ..utils.generic_utils import transpose_shape\n from ..utils.generic_utils import has_arg\n \n # Legacy functions\n@@ -2238,15 +2239,11 @@ def spatial_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None):\n     assert len(padding[1]) == 2\n     data_format = normalize_data_format(data_format)\n \n-    if data_format == 'channels_first':\n     pattern = [[0, 0],\n-                   [0, 0],\n                list(padding[0]),\n-                   list(padding[1])]\n-    else:\n-        pattern = [[0, 0],\n-                   list(padding[0]), list(padding[1]),\n+               list(padding[1]),\n                [0, 0]]\n+    pattern = transpose_shape(pattern, data_format, spatial_axes=(1, 2))\n     return tf.pad(x, pattern)\n \n \n\n@@ -23,6 +23,7 @@ import numpy as np\n from .common import floatx\n from .common import epsilon\n from .common import normalize_data_format\n+from ..utils.generic_utils import transpose_shape\n from ..utils.generic_utils import has_arg\n # Legacy functions\n from .common import set_image_dim_ordering, image_dim_ordering\n@@ -1823,8 +1824,8 @@ def _preprocess_conv2d_image_shape(image_shape, data_format):\n             return None\n     if data_format == 'channels_last':\n         if image_shape:\n-            image_shape = (image_shape[0], image_shape[3],\n-                           image_shape[1], image_shape[2])\n+            image_shape = transpose_shape(image_shape, 'channels_first',\n+                                          spatial_axes=(1, 2))\n     if image_shape is not None:\n         image_shape = tuple(int_or_none(v) for v in image_shape)\n     return image_shape\n\n@@ -21,6 +21,7 @@ from ..legacy import interfaces\n from ..legacy.layers import Recurrent, ConvRecurrent2D\n from .recurrent import RNN\n from ..utils.generic_utils import has_arg\n+from ..utils.generic_utils import transpose_shape\n \n \n class ConvRNN2D(RNN):\n@@ -169,22 +170,18 @@ class ConvRNN2D(RNN):\n                                              stride=cell.strides[1],\n                                              dilation=cell.dilation_rate[1])\n \n-        if cell.data_format == 'channels_first':\n-            output_shape = input_shape[:2] + (cell.filters, rows, cols)\n-        elif cell.data_format == 'channels_last':\n         output_shape = input_shape[:2] + (rows, cols, cell.filters)\n+        output_shape = transpose_shape(output_shape, cell.data_format,\n+                                       spatial_axes=(2, 3))\n \n         if not self.return_sequences:\n             output_shape = output_shape[:1] + output_shape[2:]\n \n         if self.return_state:\n             output_shape = [output_shape]\n-            if cell.data_format == 'channels_first':\n-                output_shape += [(input_shape[0], cell.filters, rows, cols)\n-                                 for _ in range(2)]\n-            elif cell.data_format == 'channels_last':\n-                output_shape += [(input_shape[0], rows, cols, cell.filters)\n-                                 for _ in range(2)]\n+            base = (input_shape[0], rows, cols, cell.filters)\n+            base = transpose_shape(base, cell.data_format, spatial_axes=(1, 2))\n+            output_shape += [base[:] for _ in range(2)]\n         return output_shape\n \n     def build(self, input_shape):\n\n@@ -532,3 +532,52 @@ def slice_arrays(arrays, start=None, stop=None):\n             return arrays[start:stop]\n         else:\n             return [None]\n+\n+\n+def transpose_shape(shape, target_format, spatial_axes):\n+    \"\"\"Converts a tuple or a list to the correct `data_format`.\n+\n+    It does so by switching the positions of its elements.\n+\n+    # Arguments\n+        shape: Tuple or list, often representing shape,\n+            corresponding to `'channels_last'`.\n+        target_format: A string, either `'channels_first'` or `'channels_last'`.\n+        spatial_axes: A tuple of integers.\n+            Correspond to the indexes of the spatial axes.\n+            For example, if you pass a shape\n+            representing (batch_size, timesteps, rows, cols, channels),\n+            then `spatial_axes=(2, 3)`.\n+\n+    # Returns\n+        A tuple or list, with the elements permuted according\n+        to `target_format`.\n+\n+    # Example\n+    ```python\n+        >>> from keras.utils.generic_utils import transpose_shape\n+        >>> transpose_shape((16, 128, 128, 32),'channels_first', spatial_axes=(1, 2))\n+        (16, 32, 128, 128)\n+        >>> transpose_shape((16, 128, 128, 32), 'channels_last', spatial_axes=(1, 2))\n+        (16, 128, 128, 32)\n+        >>> transpose_shape((128, 128, 32), 'channels_first', spatial_axes=(0, 1))\n+        (32, 128, 128)\n+    ```\n+\n+    # Raises\n+        ValueError: if `value` or the global `data_format` invalid.\n+    \"\"\"\n+    if target_format == 'channels_first':\n+        new_values = shape[:spatial_axes[0]]\n+        new_values += (shape[-1],)\n+        new_values += tuple(shape[x] for x in spatial_axes)\n+\n+        if isinstance(shape, list):\n+            return list(new_values)\n+        return new_values\n+    elif target_format == 'channels_last':\n+        return shape\n+    else:\n+        raise ValueError('The `data_format` argument must be one of '\n+                         '\"channels_first\", \"channels_last\". Received: ' +\n+                         str(target_format))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7205d903fbc079bb99fbae0e3c02e6d2b4d227f0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 6 | Files Changed: 3 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 5009 | Contributors (this commit): 10 | Commits (past 90d): 17 | Contributors (cumulative): 14 | DMM Complexity: 1.0\n\nDIFF:\n@@ -729,6 +729,8 @@ class Network(Layer):\n                             else:\n                                 output_masks = to_list(output_masks)\n                             computed_tensors = [computed_tensor]\n+\n+                            # computed_masks might be used in the future.\n                             computed_masks = [computed_mask]\n                         else:\n                             computed_tensors = [x[0] for x in computed_data]\n\n@@ -163,11 +163,6 @@ class Sequential(Model):\n                     # to the input layer we just created.\n                     layer(x)\n                     set_inputs = True\n-                else:\n-                    # The layer doesn't know about its expected shape.\n-                    # We will have to\n-                    # build the model lazily on `fit`/etc.\n-                    batch_shape = None\n             else:\n                 # Corner case where the user passes an InputLayer via `add`.\n                 assert len(layer._inbound_nodes[-1].output_tensors) == 1\n\n@@ -270,7 +270,6 @@ def evaluate_generator(model, generator,\n     \"\"\"See docstring for `Model.evaluate_generator`.\"\"\"\n     model._make_test_function()\n \n-    stateful_metric_indices = []\n     if hasattr(model, 'metrics'):\n         for m in model.stateful_metric_functions:\n             m.reset_states()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#63e204693b782b5f068240568853cdd637c29030", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 494 | Contributors (this commit): 16 | Commits (past 90d): 2 | Contributors (cumulative): 16 | DMM Complexity: None\n\nDIFF:\n@@ -6,7 +6,7 @@ from __future__ import print_function\n import numpy as np\n \n \n-def to_categorical(y, num_classes=None):\n+def to_categorical(y, num_classes=None, dtype='float32'):\n     \"\"\"Converts a class vector (integers) to binary class matrix.\n \n     E.g. for use with categorical_crossentropy.\n@@ -15,6 +15,8 @@ def to_categorical(y, num_classes=None):\n         y: class vector to be converted into a matrix\n             (integers from 0 to num_classes).\n         num_classes: total number of classes.\n+        dtype: The data type expected by the input, as a string\n+            (`float32`, `float64`, `int32`...)\n \n     # Returns\n         A binary matrix representation of the input. The classes axis\n@@ -28,7 +30,7 @@ def to_categorical(y, num_classes=None):\n     if not num_classes:\n         num_classes = np.max(y) + 1\n     n = y.shape[0]\n-    categorical = np.zeros((n, num_classes), dtype=np.float32)\n+    categorical = np.zeros((n, num_classes), dtype=dtype)\n     categorical[np.arange(n), y] = 1\n     output_shape = input_shape + (num_classes,)\n     categorical = np.reshape(categorical, output_shape)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e94e2cc5761e1a516f70e1706498b85cf9287297", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 141 | Files Changed: 1 | Hunks: 5 | Methods Changed: 2 | Complexity Δ (Sum/Max): -22/0 | Churn Δ: 161 | Churn Cumulative: 11309 | Contributors (this commit): 62 | Commits (past 90d): 10 | Contributors (cumulative): 62 | DMM Complexity: 1.0\n\nDIFF:\n@@ -13,6 +13,7 @@ from .. import constraints\n from ..engine.base_layer import Layer\n from ..engine.base_layer import InputSpec\n from ..utils import conv_utils\n+from ..utils.generic_utils import transpose_shape\n from ..legacy import interfaces\n \n # imports for backwards namespace compatibility\n@@ -2343,10 +2344,7 @@ class Cropping1D(Layer):\n                 input_shape[2])\n \n     def call(self, inputs):\n-        if self.cropping[1] == 0:\n-            return inputs[:, self.cropping[0]:, :]\n-        else:\n-            return inputs[:, self.cropping[0]: -self.cropping[1], :]\n+        return _call_cropping(inputs, 'channels_last', (self.cropping,))\n \n     def get_config(self):\n         config = {'cropping': self.cropping}\n@@ -2449,46 +2447,7 @@ class Cropping2D(Layer):\n                     input_shape[3])\n \n     def call(self, inputs):\n-        if self.data_format == 'channels_first':\n-            if self.cropping[0][1] == self.cropping[1][1] == 0:\n-                return inputs[:,\n-                              :,\n-                              self.cropping[0][0]:,\n-                              self.cropping[1][0]:]\n-            elif self.cropping[0][1] == 0:\n-                return inputs[:,\n-                              :,\n-                              self.cropping[0][0]:,\n-                              self.cropping[1][0]: -self.cropping[1][1]]\n-            elif self.cropping[1][1] == 0:\n-                return inputs[:,\n-                              :,\n-                              self.cropping[0][0]: -self.cropping[0][1],\n-                              self.cropping[1][0]:]\n-            return inputs[:,\n-                          :,\n-                          self.cropping[0][0]: -self.cropping[0][1],\n-                          self.cropping[1][0]: -self.cropping[1][1]]\n-        elif self.data_format == 'channels_last':\n-            if self.cropping[0][1] == self.cropping[1][1] == 0:\n-                return inputs[:,\n-                              self.cropping[0][0]:,\n-                              self.cropping[1][0]:,\n-                              :]\n-            elif self.cropping[0][1] == 0:\n-                return inputs[:,\n-                              self.cropping[0][0]:,\n-                              self.cropping[1][0]: -self.cropping[1][1],\n-                              :]\n-            elif self.cropping[1][1] == 0:\n-                return inputs[:,\n-                              self.cropping[0][0]: -self.cropping[0][1],\n-                              self.cropping[1][0]:,\n-                              :]\n-            return inputs[:,\n-                          self.cropping[0][0]: -self.cropping[0][1],\n-                          self.cropping[1][0]: -self.cropping[1][1],\n-                          :]\n+        return _call_cropping(inputs, self.data_format, self.cropping)\n \n     def get_config(self):\n         config = {'cropping': self.cropping,\n@@ -2607,103 +2566,7 @@ class Cropping3D(Layer):\n                     input_shape[4])\n \n     def call(self, inputs):\n-        if self.data_format == 'channels_first':\n-            if self.cropping[0][1] == self.cropping[1][1] == self.cropping[2][1] == 0:\n-                return inputs[:,\n-                              :,\n-                              self.cropping[0][0]:,\n-                              self.cropping[1][0]:,\n-                              self.cropping[2][0]:]\n-            elif self.cropping[0][1] == self.cropping[1][1] == 0:\n-                return inputs[:,\n-                              :,\n-                              self.cropping[0][0]:,\n-                              self.cropping[1][0]:,\n-                              self.cropping[2][0]: -self.cropping[2][1]]\n-            elif self.cropping[1][1] == self.cropping[2][1] == 0:\n-                return inputs[:,\n-                              :,\n-                              self.cropping[0][0]: -self.cropping[0][1],\n-                              self.cropping[1][0]:,\n-                              self.cropping[2][0]:]\n-            elif self.cropping[0][1] == self.cropping[2][1] == 0:\n-                return inputs[:,\n-                              :,\n-                              self.cropping[0][0]:,\n-                              self.cropping[1][0]: -self.cropping[1][1],\n-                              self.cropping[2][0]:]\n-            elif self.cropping[0][1] == 0:\n-                return inputs[:,\n-                              :,\n-                              self.cropping[0][0]:,\n-                              self.cropping[1][0]: -self.cropping[1][1],\n-                              self.cropping[2][0]: -self.cropping[2][1]]\n-            elif self.cropping[1][1] == 0:\n-                return inputs[:,\n-                              :,\n-                              self.cropping[0][0]: -self.cropping[0][1],\n-                              self.cropping[1][0]:,\n-                              self.cropping[2][0]: -self.cropping[2][1]]\n-            elif self.cropping[2][1] == 0:\n-                return inputs[:,\n-                              :,\n-                              self.cropping[0][0]: -self.cropping[0][1],\n-                              self.cropping[1][0]: -self.cropping[1][1],\n-                              self.cropping[2][0]:]\n-            return inputs[:,\n-                          :,\n-                          self.cropping[0][0]: -self.cropping[0][1],\n-                          self.cropping[1][0]: -self.cropping[1][1],\n-                          self.cropping[2][0]: -self.cropping[2][1]]\n-\n-        elif self.data_format == 'channels_last':\n-            if self.cropping[0][1] == self.cropping[1][1] == self.cropping[2][1] == 0:\n-                return inputs[:,\n-                              self.cropping[0][0]:,\n-                              self.cropping[1][0]:,\n-                              self.cropping[2][0]:,\n-                              :]\n-            elif self.cropping[0][1] == self.cropping[1][1] == 0:\n-                return inputs[:,\n-                              self.cropping[0][0]:,\n-                              self.cropping[1][0]:,\n-                              self.cropping[2][0]: -self.cropping[2][1],\n-                              :]\n-            elif self.cropping[1][1] == self.cropping[2][1] == 0:\n-                return inputs[:,\n-                              self.cropping[0][0]: -self.cropping[0][1],\n-                              self.cropping[1][0]:,\n-                              self.cropping[2][0]:,\n-                              :]\n-            elif self.cropping[0][1] == self.cropping[2][1] == 0:\n-                return inputs[:,\n-                              self.cropping[0][0]:,\n-                              self.cropping[1][0]:-self.cropping[1][1],\n-                              self.cropping[2][0]:,\n-                              :]\n-            elif self.cropping[0][1] == 0:\n-                return inputs[:,\n-                              self.cropping[0][0]:,\n-                              self.cropping[1][0]: -self.cropping[1][1],\n-                              self.cropping[2][0]: -self.cropping[2][1],\n-                              :]\n-            elif self.cropping[1][1] == 0:\n-                return inputs[:,\n-                              self.cropping[0][0]: -self.cropping[0][1],\n-                              self.cropping[1][0]:,\n-                              self.cropping[2][0]: -self.cropping[2][1],\n-                              :]\n-            elif self.cropping[2][1] == 0:\n-                return inputs[:,\n-                              self.cropping[0][0]: -self.cropping[0][1],\n-                              self.cropping[1][0]: -self.cropping[1][1],\n-                              self.cropping[2][0]:,\n-                              :]\n-            return inputs[:,\n-                          self.cropping[0][0]: -self.cropping[0][1],\n-                          self.cropping[1][0]: -self.cropping[1][1],\n-                          self.cropping[2][0]: -self.cropping[2][1],\n-                          :]\n+        return _call_cropping(inputs, self.data_format, self.cropping)\n \n     def get_config(self):\n         config = {'cropping': self.cropping,\n@@ -2712,6 +2575,22 @@ class Cropping3D(Layer):\n         return dict(list(base_config.items()) + list(config.items()))\n \n \n+def _call_cropping(inputs, data_format, cropping):\n+    slices_dims = []\n+    for start, end in cropping:\n+        if end == 0:\n+            end = None\n+        else:\n+            end = -end\n+        slices_dims.append(slice(start, end))\n+\n+    slices = [slice(None)] + slices_dims + [slice(None)]\n+    slices = tuple(slices)\n+    spatial_axes = list(range(1, 1 + len(cropping)))\n+    slices = transpose_shape(slices, data_format, spatial_axes)\n+    return inputs[slices]\n+\n+\n # Aliases\n \n Convolution1D = Conv1D\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8f4e4f2a0b543f3d74327cb04113f65cd5d11c62", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 21 | Lines Deleted: 53 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): -12/0 | Churn Δ: 74 | Churn Cumulative: 11383 | Contributors (this commit): 62 | Commits (past 90d): 11 | Contributors (cumulative): 62 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2335,13 +2335,9 @@ class Cropping1D(Layer):\n         self.input_spec = InputSpec(ndim=3)\n \n     def compute_output_shape(self, input_shape):\n-        if input_shape[1] is not None:\n-            length = input_shape[1] - self.cropping[0] - self.cropping[1]\n-        else:\n-            length = None\n-        return (input_shape[0],\n-                length,\n-                input_shape[2])\n+        return _compute_output_shape_cropping(input_shape,\n+                                              'channels_last',\n+                                              (self.cropping,))\n \n     def call(self, inputs):\n         return _call_cropping(inputs, 'channels_last', (self.cropping,))\n@@ -2435,16 +2431,9 @@ class Cropping2D(Layer):\n         self.input_spec = InputSpec(ndim=4)\n \n     def compute_output_shape(self, input_shape):\n-        if self.data_format == 'channels_first':\n-            return (input_shape[0],\n-                    input_shape[1],\n-                    input_shape[2] - self.cropping[0][0] - self.cropping[0][1] if input_shape[2] else None,\n-                    input_shape[3] - self.cropping[1][0] - self.cropping[1][1] if input_shape[3] else None)\n-        elif self.data_format == 'channels_last':\n-            return (input_shape[0],\n-                    input_shape[1] - self.cropping[0][0] - self.cropping[0][1] if input_shape[1] else None,\n-                    input_shape[2] - self.cropping[1][0] - self.cropping[1][1] if input_shape[2] else None,\n-                    input_shape[3])\n+        return _compute_output_shape_cropping(input_shape,\n+                                              self.data_format,\n+                                              self.cropping)\n \n     def call(self, inputs):\n         return _call_cropping(inputs, self.data_format, self.cropping)\n@@ -2528,42 +2517,9 @@ class Cropping3D(Layer):\n         self.input_spec = InputSpec(ndim=5)\n \n     def compute_output_shape(self, input_shape):\n-        if self.data_format == 'channels_first':\n-            if input_shape[2] is not None:\n-                dim1 = input_shape[2] - self.cropping[0][0] - self.cropping[0][1]\n-            else:\n-                dim1 = None\n-            if input_shape[3] is not None:\n-                dim2 = input_shape[3] - self.cropping[1][0] - self.cropping[1][1]\n-            else:\n-                dim2 = None\n-            if input_shape[4] is not None:\n-                dim3 = input_shape[4] - self.cropping[2][0] - self.cropping[2][1]\n-            else:\n-                dim3 = None\n-            return (input_shape[0],\n-                    input_shape[1],\n-                    dim1,\n-                    dim2,\n-                    dim3)\n-        elif self.data_format == 'channels_last':\n-            if input_shape[1] is not None:\n-                dim1 = input_shape[1] - self.cropping[0][0] - self.cropping[0][1]\n-            else:\n-                dim1 = None\n-            if input_shape[2] is not None:\n-                dim2 = input_shape[2] - self.cropping[1][0] - self.cropping[1][1]\n-            else:\n-                dim2 = None\n-            if input_shape[3] is not None:\n-                dim3 = input_shape[3] - self.cropping[2][0] - self.cropping[2][1]\n-            else:\n-                dim3 = None\n-            return (input_shape[0],\n-                    dim1,\n-                    dim2,\n-                    dim3,\n-                    input_shape[4])\n+        return _compute_output_shape_cropping(input_shape,\n+                                              self.data_format,\n+                                              self.cropping)\n \n     def call(self, inputs):\n         return _call_cropping(inputs, self.data_format, self.cropping)\n@@ -2591,6 +2547,18 @@ def _call_cropping(inputs, data_format, cropping):\n     return inputs[slices]\n \n \n+def _compute_output_shape_cropping(input_shape, data_format, cropping):\n+    cropping_all_dims = ((0, 0),) + cropping + ((0, 0),)\n+    spatial_axes = list(range(1, 1 + len(cropping)))\n+    cropping_all_dims = transpose_shape(cropping_all_dims, data_format, spatial_axes)\n+\n+    output_shape = list(input_shape)\n+    for dim in range(len(output_shape)):\n+        if output_shape[dim] is not None:\n+            output_shape[dim] -= sum(cropping_all_dims[dim])\n+    return tuple(output_shape)\n+\n+\n # Aliases\n \n Convolution1D = Conv1D\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9aed521e6650384533f69d7b46c0210b45ae9391", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 9 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 11 | Churn Cumulative: 9881 | Contributors (this commit): 117 | Commits (past 90d): 12 | Contributors (cumulative): 117 | DMM Complexity: 0.0\n\nDIFF:\n@@ -2276,15 +2276,6 @@ def spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None):\n     assert len(padding[2]) == 2\n     data_format = normalize_data_format(data_format)\n \n-    if data_format == 'channels_first':\n-        pattern = [\n-            [0, 0],\n-            [0, 0],\n-            [padding[0][0], padding[0][1]],\n-            [padding[1][0], padding[1][1]],\n-            [padding[2][0], padding[2][1]]\n-        ]\n-    else:\n     pattern = [\n         [0, 0],\n         [padding[0][0], padding[0][1]],\n@@ -2292,6 +2283,8 @@ def spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None):\n         [padding[2][0], padding[2][1]],\n         [0, 0]\n     ]\n+    pattern = transpose_shape(pattern, data_format, spatial_axes=(1, 2, 3))\n+\n     return tf.pad(x, pattern)\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#359e7627b46e850688c95cf6d1de48b77f9df901", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): -3/0 | Churn Δ: 12 | Churn Cumulative: 9893 | Contributors (this commit): 117 | Commits (past 90d): 13 | Contributors (cumulative): 117 | DMM Complexity: 1.0\n\nDIFF:\n@@ -3950,16 +3950,12 @@ def bias_add(x, bias, data_format=None):\n         raise ValueError('Unexpected bias dimensions %d, expect to be 1 or %d dimensions'\n                          % (len(bias_shape), ndim(x)))\n     if ndim(x) == 5:\n-        if data_format == 'channels_first':\n         if len(bias_shape) == 1:\n-                x += reshape(bias, (1, bias_shape[0], 1, 1, 1))\n+            new_shape = (1, 1, 1, 1, bias_shape[0])\n         else:\n-                x += reshape(bias, (1, bias_shape[3]) + bias_shape[:3])\n-        elif data_format == 'channels_last':\n-            if len(bias_shape) == 1:\n-                x += reshape(bias, (1, 1, 1, bias_shape[0]))\n-            else:\n-                x += reshape(bias, (1,) + bias_shape)\n+            new_shape = (1,) + bias_shape\n+        new_shape = transpose_shape(new_shape, data_format, spatial_axes=(1, 2, 3))\n+        x += reshape(bias, new_shape)\n     elif ndim(x) == 4:\n         if data_format == 'channels_first':\n             if len(bias_shape) == 1:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#672a873ffb344dfa030103cad69bdbc948184e8e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): -3/0 | Churn Δ: 12 | Churn Cumulative: 9905 | Contributors (this commit): 117 | Commits (past 90d): 14 | Contributors (cumulative): 117 | DMM Complexity: 1.0\n\nDIFF:\n@@ -3973,16 +3973,12 @@ def bias_add(x, bias, data_format=None):\n             else:\n                 x += reshape(bias, (1,) + bias_shape)\n     elif ndim(x) == 3:\n-        if data_format == 'channels_first':\n         if len(bias_shape) == 1:\n-                x += reshape(bias, (1, bias_shape[0], 1))\n+            new_shape = (1, 1, bias_shape[0])\n         else:\n-                x += reshape(bias, (1, bias_shape[1], bias_shape[0]))\n-        elif data_format == 'channels_last':\n-            if len(bias_shape) == 1:\n-                x += reshape(bias, (1, 1, bias_shape[0]))\n-            else:\n-                x += reshape(bias, (1, ) + bias_shape)\n+            new_shape = (1,) + bias_shape\n+        new_shape = transpose_shape(new_shape, data_format, spatial_axes=(1,))\n+        x += reshape(bias, new_shape)\n     else:\n         x = tf.nn.bias_add(x, bias)\n     return x\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#aa8d7f76a047b24a97614524d29fb5070cf549c7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 1425 | Contributors (this commit): 21 | Commits (past 90d): 3 | Contributors (cumulative): 21 | DMM Complexity: None\n\nDIFF:\n@@ -220,10 +220,10 @@ def get_file(fname,\n         try:\n             try:\n                 urlretrieve(origin, fpath, dl_progress)\n-            except URLError as e:\n-                raise Exception(error_msg.format(origin, e.errno, e.reason))\n             except HTTPError as e:\n                 raise Exception(error_msg.format(origin, e.code, e.msg))\n+            except URLError as e:\n+                raise Exception(error_msg.format(origin, e.errno, e.reason))\n         except (Exception, KeyboardInterrupt):\n             if os.path.exists(fpath):\n                 os.remove(fpath)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f99f633725815635a1cf24aa2dd70bdb094ed7aa", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 67 | Lines Deleted: 28 | Files Changed: 2 | Hunks: 21 | Methods Changed: 9 | Complexity Δ (Sum/Max): 8/4 | Churn Δ: 95 | Churn Cumulative: 10494 | Contributors (this commit): 98 | Commits (past 90d): 15 | Contributors (cumulative): 116 | DMM Complexity: 0.6153846153846154\n\nDIFF:\n@@ -1144,7 +1144,18 @@ def spatial_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None):\n                    py_slice(left_pad, input_shape[2] + left_pad),\n                    py_slice(None))\n     y = T.set_subtensor(output[indices], x)\n-    y._keras_shape = output_shape\n+    if hasattr(x, '_keras_shape'):\n+        if data_format == 'channels_first':\n+            output_keras_shape = (x._keras_shape[0],\n+                                  x._keras_shape[1],\n+                                  x._keras_shape[2] + top_pad + bottom_pad,\n+                                  x._keras_shape[3] + left_pad + right_pad)\n+        else:\n+            output_keras_shape = (x._keras_shape[0],\n+                                  x._keras_shape[1] + top_pad + bottom_pad,\n+                                  x._keras_shape[2] + left_pad + right_pad,\n+                                  x._keras_shape[3])\n+        y._keras_shape = output_keras_shape\n     return y\n \n \n@@ -1180,7 +1191,22 @@ def spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None):\n                    py_slice(padding[1][0], input_shape[2] + padding[1][0]),\n                    py_slice(padding[2][0], input_shape[3] + padding[2][0]),\n                    py_slice(None))\n-    return T.set_subtensor(output[indices], x)\n+    y = T.set_subtensor(output[indices], x)\n+    if hasattr(x, '_keras_shape'):\n+        if data_format == 'channels_first':\n+            output_keras_shape = (x._keras_shape[0],\n+                                  x._keras_shape[1],\n+                                  x._keras_shape[2] + padding[0][0] + padding[0][1],\n+                                  x._keras_shape[3] + padding[1][0] + padding[1][1],\n+                                  x._keras_shape[4] + padding[2][0] + padding[2][1])\n+        else:\n+            output_keras_shape = (x._keras_shape[0],\n+                                  x._keras_shape[1] + padding[0][0] + padding[0][1],\n+                                  x._keras_shape[2] + padding[1][0] + padding[1][1],\n+                                  x._keras_shape[3] + padding[2][0] + padding[2][1],\n+                                  x._keras_shape[4])\n+        y._keras_shape = output_keras_shape\n+    return y\n \n \n def stack(x, axis=0):\n\n@@ -45,19 +45,19 @@ def check_dtype(var, dtype):\n def cntk_func_single_tensor(function_name, x_shape, **kwargs):\n     xc = KC.placeholder(x_shape)\n     output_cntk = getattr(KC, function_name)(xc, **kwargs)\n-    return KC.function([xc], [output_cntk])\n+    return output_cntk, KC.function([xc], [output_cntk])\n \n \n def cntk_func_two_tensor(function_name, x_shape, y, **kwargs):\n     if isinstance(y, (np.generic, np.ndarray)):\n         xc = KC.placeholder(x_shape)\n         output_cntk = getattr(KC, function_name)(xc, KC.variable(y), **kwargs)\n-        return KC.function([xc], [output_cntk])\n+        return output_cntk, KC.function([xc], [output_cntk])\n     else:\n         xc = KC.placeholder(ndim=len(x_shape))\n         yc = KC.placeholder(y)\n         output_cntk = getattr(KC, function_name)(xc, yc, **kwargs)\n-        return KC.function([xc, yc], [output_cntk])\n+        return output_cntk, KC.function([xc, yc], [output_cntk])\n \n \n def cntk_func_three_tensor(function_name, x_shape, y, z, **kwargs):\n@@ -89,10 +89,12 @@ def assert_list_with_ref(z_list, ref):\n         assert_allclose(z, ref, atol=1e-05)\n \n \n-def assert_list_keras_shape(z_list):\n-    for z in z_list:\n-        if hasattr(z, '_keras_shape'):\n-            assert z._keras_shape == z.shape\n+def assert_list_keras_shape(t_list, z_list):\n+    for t, z in zip(t_list, z_list):\n+        if hasattr(t, '_keras_shape') and len(t._keras_shape) > 1:\n+            for i, s in enumerate(t._keras_shape):\n+                if s:\n+                    assert t._keras_shape[i] == z.shape[i]\n \n \n @keras_test\n@@ -106,16 +108,20 @@ def check_single_tensor_operation(function_name, x_shape_or_val, backend_list, *\n     if shape_or_val:\n         x_shape, x_val = parse_shape_or_val(x_shape_or_val)\n \n+    t_list = []\n     z_list = []\n     for k in backend_list:\n         if shape_or_val:\n             if (k == KC) & (cntk_dynamicity):\n-                z = cntk_func_single_tensor(function_name, x_shape,\n-                                            **kwargs)([x_val])[0]\n+                t, f = cntk_func_single_tensor(function_name, x_shape, **kwargs)\n+                z = f([x_val])[0]\n             else:\n-                z = k.eval(getattr(k, function_name)(k.variable(x_val), **kwargs))\n+                t = getattr(k, function_name)(k.variable(x_val), **kwargs)\n+                z = k.eval(t)\n         else:\n-            z = k.eval(getattr(k, function_name)(x_shape_or_val, **kwargs))\n+            t = getattr(k, function_name)(x_shape_or_val, **kwargs)\n+            z = k.eval(t)\n+        t_list += [t]\n         z_list += [z]\n \n     if return_results:\n@@ -128,7 +134,7 @@ def check_single_tensor_operation(function_name, x_shape_or_val, backend_list, *\n         assert_list_with_ref(z_list, assert_value_with_ref)\n     else:\n         assert_list_pairwise(z_list, allclose=assert_value_equality)\n-    assert_list_keras_shape(z_list)\n+    assert_list_keras_shape(t_list, z_list)\n \n \n @keras_test\n@@ -144,27 +150,32 @@ def check_two_tensor_operation(function_name, x_shape_or_val,\n         x_shape, x_val = parse_shape_or_val(x_shape_or_val)\n         y_shape, y_val = parse_shape_or_val(y_shape_or_val)\n \n+    t_list = []\n     z_list = []\n     for k in backend_list:\n         if shape_or_val:\n             if (k == KC) & (cntk_dynamicity):\n-                z = cntk_func_two_tensor(function_name, x_shape,\n-                                         y=y_val, **kwargs)([x_val])[0]\n+                t, f = cntk_func_two_tensor(function_name, x_shape, y=y_val, **kwargs)\n+                z = f([x_val])[0]\n             elif (k == KC) & (cntk_two_dynamicity):\n-                z = cntk_func_two_tensor(function_name, x_shape,\n-                                         y=y_shape, **kwargs)([x_val, y_val])[0]\n+                t, f = cntk_func_two_tensor(function_name, x_shape, y=y_shape, **kwargs)\n+                z = f([x_val, y_val])[0]\n             elif (k == KTH) & (function_name[:4] == 'conv'):\n-                z = k.eval(getattr(k, function_name)(\n-                    k.variable(x_val), k.variable(convert_kernel(y_val)), **kwargs))\n+                t = getattr(k, function_name)(\n+                    k.variable(x_val), k.variable(convert_kernel(y_val)), **kwargs)\n+                z = k.eval(t)\n             elif concat_args:\n-                z = k.eval(getattr(k, function_name)(\n-                    [k.variable(x_val), k.variable(y_val)], **kwargs))\n+                t = getattr(k, function_name)(\n+                    [k.variable(x_val), k.variable(y_val)], **kwargs)\n+                z = k.eval(t)\n             else:\n-                z = k.eval(getattr(k, function_name)(\n-                    k.variable(x_val), k.variable(y_val), **kwargs))\n+                t = getattr(k, function_name)(\n+                    k.variable(x_val), k.variable(y_val), **kwargs)\n+                z = k.eval(t)\n         else:\n-            z = k.eval(getattr(k, function_name)(\n-                x_shape_or_val, y_shape_or_val, **kwargs))\n+            t = getattr(k, function_name)(x_shape_or_val, y_shape_or_val, **kwargs)\n+            z = k.eval(t)\n+        t_list += [t]\n         z_list += [z]\n \n     if return_results:\n@@ -174,7 +185,7 @@ def check_two_tensor_operation(function_name, x_shape_or_val,\n             return z_list[0]\n \n     assert_list_pairwise(z_list)\n-    assert_list_keras_shape(z_list)\n+    assert_list_keras_shape(t_list, z_list)\n \n \n @keras_test\n@@ -333,11 +344,13 @@ class TestBackend(object):\n         shape = (10, 2, 3)\n         ref = np.arange(np.prod(shape)).reshape(shape)\n         inds = [1, 3, 7, 9]\n+        t_list = [k.gather(k.variable(ref), k.variable(inds, dtype='int32'))\n+                  for k in BACKENDS]\n         z_list = [k.eval(k.gather(k.variable(ref), k.variable(inds, dtype='int32')))\n                   for k in BACKENDS]\n \n         assert_list_pairwise(z_list)\n-        assert_list_keras_shape(z_list)\n+        assert_list_keras_shape(t_list, z_list)\n \n         # test theano shape inference when\n         # input shape has None entries\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
