{"custom_id": "keras#bfe6b7dde49f1f59906612f4aee0bd2a4e47001c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 147 | Contributors (this commit): 3 | Commits (past 90d): 4 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -436,6 +436,7 @@ class DenseTest(testing.TestCase, parameterized.TestCase):\n         (\"int8\", \"int8_from_float32\", 3),\n         (\"float8\", \"float8_from_float32\", 8),\n     )\n+    @pytest.mark.skipif(testing.tensorflow_uses_gpu(), reason=\"Segfault\")\n     def test_quantize_by_setting_dtype_policy(\n         self, policy, expected_num_variables\n     ):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#492e0792762fef0deba50a9730f2d95252789fa1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 20 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): -4/0 | Churn Δ: 20 | Churn Cumulative: 114 | Contributors (this commit): 4 | Commits (past 90d): 4 | Contributors (cumulative): 7 | DMM Complexity: 0.0\n\nDIFF:\n@@ -110,12 +110,6 @@ class BinaryAccuracy(reduction_metrics.MeanMetricWrapper):\n     \"\"\"\n \n     def __init__(self, name=\"binary_accuracy\", dtype=None, threshold=0.5):\n-        if threshold is not None and (threshold <= 0 or threshold >= 1):\n-            raise ValueError(\n-                \"Invalid value for argument `threshold`. \"\n-                \"Expected a value in interval (0, 1). \"\n-                f\"Received: threshold={threshold}\"\n-            )\n         super().__init__(\n             fn=binary_accuracy, name=name, dtype=dtype, threshold=threshold\n         )\n\n@@ -1,5 +1,3 @@\n-import re\n-\n import numpy as np\n \n from keras.src import testing\n@@ -174,18 +172,6 @@ class BinaryAccuracyTest(testing.TestCase):\n         self.assertAllClose(result_1, 1.0)\n         self.assertAllClose(result_2, 0.75)\n \n-    def test_invalid_threshold(self):\n-        self.assertRaisesRegex(\n-            ValueError,\n-            re.compile(r\"Invalid value for argument `threshold`\"),\n-            lambda: accuracy_metrics.BinaryAccuracy(threshold=-0.5),\n-        )\n-        self.assertRaisesRegex(\n-            ValueError,\n-            re.compile(r\"Invalid value for argument `threshold`\"),\n-            lambda: accuracy_metrics.BinaryAccuracy(threshold=1.5),\n-        )\n-\n \n class CategoricalAccuracyTest(testing.TestCase):\n     def test_config(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#755d85f40ec77ce4f2f440e04fc8c21ec1ad99b2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 106 | Contributors (this commit): 7 | Commits (past 90d): 5 | Contributors (cumulative): 7 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1062,7 +1062,8 @@ def divide(x1, x2):\n def divide_no_nan(x1, x2):\n     x1 = convert_to_tensor(x1)\n     x2 = convert_to_tensor(x2)\n-    return jnp.where(x2 == 0, 0, jnp.divide(x1, x2))\n+    safe_x2 = jnp.where(x2 == 0, 1, x2)\n+    return jnp.where(x2 == 0, 0, jnp.divide(x1, safe_x2))\n \n \n def true_divide(x1, x2):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#01381abb4addf785b9329ad7b26aa68d541ddd0a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 60 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 6 | Complexity Δ (Sum/Max): 9/7 | Churn Δ: 60 | Churn Cumulative: 446 | Contributors (this commit): 7 | Commits (past 90d): 9 | Contributors (cumulative): 8 | DMM Complexity: 1.0\n\nDIFF:\n@@ -238,6 +238,11 @@ def map(f, xs):\n         out = f(x)\n         return tree.map_structure(tf.TensorSpec.from_tensor, out)\n \n+    if tree.is_nested(xs):\n+        input = tree.pack_sequence_as(xs, [x[0] for x in tree.flatten(xs)])\n+        fn_output_signature = get_fn_output_signature(input)\n+        return tf.map_fn(f, xs, fn_output_signature=fn_output_signature)\n+    else:\n         fn_output_signature = get_fn_output_signature(xs[0])\n         return tf.map_fn(f, xs, fn_output_signature=fn_output_signature)\n \n\n@@ -0,0 +1,55 @@\n+import numpy as np\n+import pytest\n+import tensorflow as tf\n+\n+import keras\n+from keras.src import backend\n+from keras.src import testing\n+\n+\n+@pytest.mark.skipif(\n+    backend.backend() != \"tensorflow\",\n+    reason=\"The nestedstructure test can only run with TF backend.\",\n+)\n+def dict_input_fn(inputs):\n+    x = inputs[\"x\"][:, 0]\n+    y = inputs[\"y\"] + 1\n+    return {\"x\": x, \"y\": y}\n+\n+\n+def list_input_fn(inputs):\n+    return [x**2 for x in inputs]\n+\n+\n+class NestedTest(testing.TestCase):\n+    def setUp(self):\n+        self.xs = {\n+            \"x\": tf.convert_to_tensor(\n+                np.random.rand(4, 100, 3), dtype=tf.float32\n+            ),\n+            \"y\": tf.convert_to_tensor(\n+                np.random.randint(0, 10, size=(4, 1)), dtype=tf.int32\n+            ),\n+        }\n+        self.xs1 = [\n+            tf.convert_to_tensor(np.random.rand(4, 100, 3), dtype=tf.float32),\n+            tf.convert_to_tensor(\n+                np.random.randint(0, 10, size=(4, 1)), dtype=tf.int32\n+            ),\n+        ]\n+\n+    def test_dict_input_fn_outputs(self):\n+        ys = keras.ops.map(dict_input_fn, self.xs)\n+        self.assertEqual(ys[\"x\"].shape, (4, 100))\n+        self.assertEqual(\n+            keras.ops.convert_to_numpy(ys[\"y\"]).all(),\n+            keras.ops.convert_to_numpy(self.xs[\"y\"] + 1).all(),\n+        )\n+\n+    def test_list_input_fn_outputs(self):\n+        ys = keras.ops.map(list_input_fn, self.xs1)\n+        for i, (x, y) in enumerate(zip(self.xs1, ys)):\n+            self.assertEqual(\n+                (keras.ops.convert_to_numpy(y)).all(),\n+                (keras.ops.convert_to_numpy(x) ** 2).all(),\n+            )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4b3a65a63e06d754f38645f667ecb0e89251908a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 36 | Lines Deleted: 55 | Files Changed: 2 | Hunks: 2 | Methods Changed: 8 | Complexity Δ (Sum/Max): -3/4 | Churn Δ: 91 | Churn Cumulative: 503 | Contributors (this commit): 6 | Commits (past 90d): 6 | Contributors (cumulative): 7 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1,55 +0,0 @@\n-import numpy as np\n-import pytest\n-import tensorflow as tf\n-\n-import keras\n-from keras.src import backend\n-from keras.src import testing\n-\n-\n-@pytest.mark.skipif(\n-    backend.backend() != \"tensorflow\",\n-    reason=\"The nestedstructure test can only run with TF backend.\",\n-)\n-def dict_input_fn(inputs):\n-    x = inputs[\"x\"][:, 0]\n-    y = inputs[\"y\"] + 1\n-    return {\"x\": x, \"y\": y}\n-\n-\n-def list_input_fn(inputs):\n-    return [x**2 for x in inputs]\n-\n-\n-class NestedTest(testing.TestCase):\n-    def setUp(self):\n-        self.xs = {\n-            \"x\": tf.convert_to_tensor(\n-                np.random.rand(4, 100, 3), dtype=tf.float32\n-            ),\n-            \"y\": tf.convert_to_tensor(\n-                np.random.randint(0, 10, size=(4, 1)), dtype=tf.int32\n-            ),\n-        }\n-        self.xs1 = [\n-            tf.convert_to_tensor(np.random.rand(4, 100, 3), dtype=tf.float32),\n-            tf.convert_to_tensor(\n-                np.random.randint(0, 10, size=(4, 1)), dtype=tf.int32\n-            ),\n-        ]\n-\n-    def test_dict_input_fn_outputs(self):\n-        ys = keras.ops.map(dict_input_fn, self.xs)\n-        self.assertEqual(ys[\"x\"].shape, (4, 100))\n-        self.assertEqual(\n-            keras.ops.convert_to_numpy(ys[\"y\"]).all(),\n-            keras.ops.convert_to_numpy(self.xs[\"y\"] + 1).all(),\n-        )\n-\n-    def test_list_input_fn_outputs(self):\n-        ys = keras.ops.map(list_input_fn, self.xs1)\n-        for i, (x, y) in enumerate(zip(self.xs1, ys)):\n-            self.assertEqual(\n-                (keras.ops.convert_to_numpy(y)).all(),\n-                (keras.ops.convert_to_numpy(x) ** 2).all(),\n-            )\n\n@@ -161,6 +161,42 @@ class CoreOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         self.assertAllClose(outputs[\"a\"], xs**2)\n         self.assertAllClose(outputs[\"b\"], xs * 10)\n \n+        # Test with nested structures\n+        def dict_input_fn(inputs):\n+            x = inputs[\"x\"][:, 0]\n+            y = inputs[\"y\"] + 1\n+            return {\"x\": x, \"y\": y}\n+\n+        def list_input_fn(inputs):\n+            return [x**2 for x in inputs]\n+\n+        xs = {\n+            \"x\": ops.convert_to_tensor(\n+                np.random.rand(4, 100, 3), dtype=\"float32\"\n+            ),\n+            \"y\": ops.convert_to_tensor(\n+                np.random.randint(0, 10, size=(4, 1)), dtype=\"int32\"\n+            ),\n+        }\n+        xs1 = [\n+            ops.convert_to_tensor(np.random.rand(4, 100, 3), dtype=\"float32\"),\n+            ops.convert_to_tensor(\n+                np.random.randint(0, 10, size=(4, 1)), dtype=\"int32\"\n+            ),\n+        ]\n+        ys = ops.map(dict_input_fn, xs)\n+        self.assertEqual(ys[\"x\"].shape, (4, 100))\n+        self.assertEqual(\n+            ops.convert_to_numpy(ys[\"y\"]).all(),\n+            ops.convert_to_numpy(xs[\"y\"] + 1).all(),\n+        )\n+        ys = ops.map(list_input_fn, xs1)\n+        for x, y in zip(xs1, ys):\n+            self.assertEqual(\n+                (ops.convert_to_numpy(y)).all(),\n+                (ops.convert_to_numpy(x) ** 2).all(),\n+            )\n+\n     def test_scan(self):\n         # Test cumsum\n         def cumsum(carry, xs):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5a333ec8bf74f7c529eba0b699bf44f0a05d6f99", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 41 | Files Changed: 4 | Hunks: 21 | Methods Changed: 8 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 61 | Churn Cumulative: 1338 | Contributors (this commit): 12 | Commits (past 90d): 35 | Contributors (cumulative): 27 | DMM Complexity: None\n\nDIFF:\n@@ -3,7 +3,6 @@ import functools\n import warnings\n \n import numpy as np\n-import optree\n \n from keras.src import tree\n from keras.src.backend.common import KerasVariable\n@@ -210,16 +209,16 @@ def associative_scan(f, elems, reverse=False, axis=0):\n     # Ref: jax.lax.associative_scan\n     if not callable(f):\n         raise TypeError(f\"`f` should be a callable. Received: f={f}\")\n-    elems_flat, tree = optree.tree_flatten(elems)\n+    elems_flat = tree.flatten(elems)\n     elems_flat = [convert_to_tensor(elem) for elem in elems_flat]\n     if reverse:\n         elems_flat = [np.flip(elem, (axis,)) for elem in elems_flat]\n \n     def _combine(a_flat, b_flat):\n-        a = optree.tree_unflatten(tree, a_flat)\n-        b = optree.tree_unflatten(tree, b_flat)\n+        a = tree.pack_sequence_as(elems, a_flat)\n+        b = tree.pack_sequence_as(elems, b_flat)\n         c = f(a, b)\n-        c_flat, _ = optree.tree_flatten(c)\n+        c_flat = tree.flatten(c)\n         return c_flat\n \n     num_elems = int(elems_flat[0].shape[axis])\n@@ -313,7 +312,7 @@ def associative_scan(f, elems, reverse=False, axis=0):\n     if reverse:\n         scans = [np.flip(scanned, (axis,)) for scanned in scans]\n \n-    return optree.tree_unflatten(tree, scans)\n+    return tree.pack_sequence_as(elems, scans)\n \n \n def scatter(indices, values, shape):\n\n@@ -1,7 +1,6 @@\n import builtins\n \n import numpy as np\n-import optree\n import tensorflow as tf\n from tensorflow.compiler.tf2xla.python.xla import dynamic_update_slice\n \n@@ -373,16 +372,16 @@ def associative_scan(f, elems, reverse=False, axis=0):\n     # with additional checks to ensure similar behavior with jax\n     if not callable(f):\n         raise TypeError(f\"`f` should be a callable. Received: f={f}\")\n-    elems_flat, treespec = optree.tree_flatten(elems)\n+    elems_flat = tree.flatten(elems)\n     elems_flat = [tf.convert_to_tensor(elem) for elem in elems_flat]\n     if reverse:\n         elems_flat = [tf.reverse(elem, [axis]) for elem in elems_flat]\n \n     def _combine(a_flat, b_flat):\n-        a = optree.tree_unflatten(treespec, a_flat)\n-        b = optree.tree_unflatten(treespec, b_flat)\n+        a = tree.pack_sequence_as(elems, a_flat)\n+        b = tree.pack_sequence_as(elems, b_flat)\n         c = f(a, b)\n-        c_flat, _ = optree.tree_flatten(c)\n+        c_flat = tree.flatten(c)\n         return c_flat\n \n     def _get_dim(x):\n@@ -544,7 +543,7 @@ def associative_scan(f, elems, reverse=False, axis=0):\n     if reverse:\n         scans = [tf.reverse(scanned, [axis]) for scanned in scans]\n \n-    return optree.tree_unflatten(treespec, scans)\n+    return tree.pack_sequence_as(elems, scans)\n \n \n def scatter(indices, values, shape):\n\n@@ -4,7 +4,6 @@ import functools\n \n import ml_dtypes\n import numpy as np\n-import optree\n import torch\n \n from keras.src import tree\n@@ -437,7 +436,7 @@ def associative_scan(f, elems, reverse=False, axis=0):\n     # Ref: jax.lax.associative_scan\n     if not callable(f):\n         raise TypeError(f\"`f` should be a callable. Received: f={f}\")\n-    elems_flat, tree = optree.tree_flatten(elems)\n+    elems_flat = tree.flatten(elems)\n     elems_flat = [convert_to_tensor(elem) for elem in elems_flat]\n     if reverse:\n         elems_flat = [torch.flip(elem, (axis,)) for elem in elems_flat]\n@@ -446,10 +445,10 @@ def associative_scan(f, elems, reverse=False, axis=0):\n         a_flat = [convert_to_tensor(a) for a in a_flat]\n         b_flat = [convert_to_tensor(b) for b in b_flat]\n \n-        a = optree.tree_unflatten(tree, a_flat)\n-        b = optree.tree_unflatten(tree, b_flat)\n+        a = tree.pack_sequence_as(elems, a_flat)\n+        b = tree.pack_sequence_as(elems, b_flat)\n         c = f(a, b)\n-        c_flat, _ = optree.tree_flatten(c)\n+        c_flat = tree.flatten(c)\n         return c_flat\n \n     num_elems = int(elems_flat[0].shape[axis])\n@@ -484,12 +483,12 @@ def associative_scan(f, elems, reverse=False, axis=0):\n         a_pad = [[0, 0] for _ in range(a.dim())]\n         a_pad[axis][-1] = 1 if a.shape[axis] == b.shape[axis] else 0\n         a_pad = a_pad[::-1]\n-        a_pad, _ = optree.tree_flatten(a_pad)\n+        a_pad = tree.flatten(a_pad)\n \n         b_pad = [[0, 0] for _ in range(b.dim())]\n         b_pad[axis] = [1, 0] if a.shape[axis] == b.shape[axis] else [1, 1]\n         b_pad = b_pad[::-1]\n-        b_pad, _ = optree.tree_flatten(b_pad)\n+        b_pad = tree.flatten(b_pad)\n \n         op = torch.bitwise_or if a.dtype == torch.bool else torch.add\n         return op(\n@@ -548,7 +547,7 @@ def associative_scan(f, elems, reverse=False, axis=0):\n     if reverse:\n         scans = [torch.flip(scanned, (axis,)) for scanned in scans]\n \n-    return optree.tree_unflatten(tree, scans)\n+    return tree.pack_sequence_as(elems, scans)\n \n \n def scatter(indices, values, shape):\n\n@@ -1,22 +1,4 @@\n-\"\"\"\n-scan\n-scatter\n-scatter_update\n-slice\n-slice_update\n-while_loop\n-stop_gradient\n-shape\n-cast\n-convert_to_tensor\n-convert_to_numpy\n-cond\n-is_tensor\n-custom_gradient\n-\"\"\"\n-\n import numpy as np\n-import optree\n \n from keras.src import backend\n from keras.src import tree\n@@ -212,7 +194,7 @@ class AssociativeScan(Operation):\n         )\n \n     def compute_output_spec(self, f, elems, axis):\n-        elems_flat, tree_ = optree.tree_flatten(elems)\n+        elems_flat = tree.flatten(elems)\n         lens = [elem.shape[axis] for elem in elems_flat]\n         if len(set(lens)) != 1:\n             raise ValueError(\n@@ -222,8 +204,8 @@ class AssociativeScan(Operation):\n                 )\n             )\n \n-        x = optree.tree_unflatten(\n-            tree_, [slice_along_axis(x, 0, 1, axis=axis) for x in elems_flat]\n+        x = tree.pack_sequence_as(\n+            elems, [slice_along_axis(x, 0, 1, axis=axis) for x in elems_flat]\n         )\n         y_spec = backend.compute_output_spec(f, x, x)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#378bb38e9b5cf57f9f728c055c7d35641ada5e8f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 150 | Contributors (this commit): 3 | Commits (past 90d): 5 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -482,6 +482,7 @@ class DenseTest(testing.TestCase, parameterized.TestCase):\n         (\"float8\", \"float8_from_mixed_bfloat16\", 8, 0),\n     )\n     @pytest.mark.requires_trainable_backend\n+    @pytest.mark.skipif(testing.tensorflow_uses_gpu(), reason=\"Segfault\")\n     def test_quantize_dtype_argument(\n         self, dtype, num_trainable_weights, num_non_trainable_weights\n     ):\n@@ -498,6 +499,7 @@ class DenseTest(testing.TestCase, parameterized.TestCase):\n         )\n \n     @pytest.mark.requires_trainable_backend\n+    @pytest.mark.skipif(testing.tensorflow_uses_gpu(), reason=\"Segfault\")\n     def test_quantize_int8_when_lora_enabled(self):\n         # Note that saving and loading with lora_enabled and quantized are\n         # lossy, so we use a weak correctness test for model outputs (atol=0.5).\n@@ -579,6 +581,7 @@ class DenseTest(testing.TestCase, parameterized.TestCase):\n             )\n \n     @pytest.mark.requires_trainable_backend\n+    @pytest.mark.skipif(testing.tensorflow_uses_gpu(), reason=\"Segfault\")\n     def test_quantize_float8(self):\n         import ml_dtypes\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fa834a767bfab5d8e4180ada03fd0b7a597d6d55", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 16 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -1,7 +1,7 @@\n from keras.src.api_export import keras_export\n \n # Unique source of truth for the version number.\n-__version__ = \"3.4.1\"\n+__version__ = \"3.5.0\"\n \n \n @keras_export(\"keras.version\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#816d219c04b2bdb7de81081fa14eac63000dac30", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 5 | Churn Cumulative: 21 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -403,7 +403,7 @@ def is_remote_path(filepath):\n     Returns:\n         bool: True if the filepath is a recognized remote path, otherwise False\n     \"\"\"\n-    if re.match(r\"^(/cns|/cfs|/gcs|/hdfs|.*://).*$\", str(filepath)):\n+    if re.match(r\"^(/cns|/cfs|/gcs|/hdfs|/readahead|.*://).*$\", str(filepath)):\n         return True\n     return False\n \n\n@@ -721,6 +721,9 @@ class IsRemotePathTest(test_case.TestCase):\n     def test_cfs_remote_path(self):\n         self.assertTrue(file_utils.is_remote_path(\"/cfs/some/path\"))\n \n+    def test_readahead_remote_path(self):\n+        self.assertTrue(file_utils.is_remote_path(\"/readahead/some/path\"))\n+\n     def test_non_remote_paths(self):\n         self.assertFalse(file_utils.is_remote_path(\"/local/path/to/file.txt\"))\n         self.assertFalse(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#64059df74712829d4aec2097b3dff8a37657532d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 3/2 | Churn Δ: 17 | Churn Cumulative: 812 | Contributors (this commit): 8 | Commits (past 90d): 15 | Contributors (cumulative): 14 | DMM Complexity: 1.0\n\nDIFF:\n@@ -223,7 +223,11 @@ def compute_output_spec(fn, *args, **kwargs):\n \n \n def cond(pred, true_fn, false_fn):\n+    if isinstance(pred, tf.Variable):\n         return tf.cond(pred, true_fn=true_fn, false_fn=false_fn)\n+    return tf.__internal__.smart_cond.smart_cond(\n+        pred, true_fn=true_fn, false_fn=false_fn\n+    )\n \n \n def vectorized_map(function, elements):\n\n@@ -703,6 +703,19 @@ class CoreOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n                 lambda: ops.zeros((4,)),\n             )\n \n+    def test_cond_raw_bool_compile(self):\n+        class ExampleLayer(layers.Layer):\n+            def call(self, x, training=False):\n+                return ops.cond(training, lambda: x, lambda: x * 2.0)\n+\n+        model = models.Sequential([ExampleLayer()])\n+        model.compile(\n+            optimizer=optimizers.SGD(), loss=losses.MeanSquaredError()\n+        )\n+        x = np.ones((2, 4), dtype=np.float32)\n+        y = np.zeros((2, 4), dtype=np.float32)\n+        model.evaluate(x, y, batch_size=2)\n+\n     def test_unstack(self):\n         rng = np.random.default_rng(0)\n         x = rng.uniform(size=(2, 3, 4))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6fd4873a367d20624105967c5be0d451f72f946d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 3 | Files Changed: 3 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 10 | Churn Cumulative: 190 | Contributors (this commit): 4 | Commits (past 90d): 4 | Contributors (cumulative): 10 | DMM Complexity: 1.0\n\nDIFF:\n@@ -185,6 +185,8 @@ def solve_triangular(a, b, lower=False):\n \n \n def svd(x, full_matrices=True, compute_uv=True):\n+    if compute_uv is False:\n+        return tf.linalg.svd(x, full_matrices=full_matrices, compute_uv=False)\n     s, u, v = tf.linalg.svd(\n         x, full_matrices=full_matrices, compute_uv=compute_uv\n     )\n\n@@ -68,9 +68,7 @@ def solve_triangular(a, b, lower=False):\n \n def svd(x, full_matrices=True, compute_uv=True):\n     if not compute_uv:\n-        raise NotImplementedError(\n-            \"`compute_uv=False` is not supported for torch backend.\"\n-        )\n+        return torch.linalg.svdvals(x)\n     return torch.linalg.svd(x, full_matrices=full_matrices)\n \n \n\n@@ -534,6 +534,10 @@ class LinalgOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         # High tolerance due to numerical instability\n         self.assertAllClose(x_reconstructed, x, atol=1e-3)\n \n+        # Test `compute_uv=False`\n+        s_no_uv = linalg.svd(x, compute_uv=False)\n+        self.assertAllClose(s_no_uv, s)\n+\n     @parameterized.named_parameters(\n         (\"b_rank_1\", 1, None),\n         (\"b_rank_2\", 2, None),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b421e1fa1a2bfeb61425e6c1a4e1af73f9f38c63", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 30 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 4/2 | Churn Δ: 31 | Churn Cumulative: 363 | Contributors (this commit): 5 | Commits (past 90d): 7 | Contributors (cumulative): 9 | DMM Complexity: 0.8888888888888888\n\nDIFF:\n@@ -532,6 +532,8 @@ def functional_from_config(cls, config, custom_objects=None):\n             return get_tensor(*tensors)\n         if isinstance(tensors, dict):\n             return {k: map_tensors(v) for k, v in tensors.items()}\n+        if isinstance(tensors, tuple):\n+            return tuple([map_tensors(v) for v in tensors])\n         return [map_tensors(v) for v in tensors]\n \n     input_tensors = map_tensors(config[\"input_layers\"])\n\n@@ -3,6 +3,7 @@ import warnings\n \n import numpy as np\n import pytest\n+from absl.testing import parameterized\n \n from keras.src import applications\n from keras.src import backend\n@@ -16,7 +17,7 @@ from keras.src.models import Model\n from keras.src.models import Sequential\n \n \n-class FunctionalTest(testing.TestCase):\n+class FunctionalTest(testing.TestCase, parameterized.TestCase):\n     @pytest.mark.requires_trainable_backend\n     def test_basic_flow_multi_input(self):\n         input_a = Input(shape=(3,), batch_size=2, name=\"input_a\")\n@@ -180,6 +181,32 @@ class FunctionalTest(testing.TestCase):\n             out_val = model(in_val)\n             self.assertEqual(out_val.shape, (2, 3))\n \n+    @parameterized.named_parameters(\n+        (\"list\", list),\n+        (\"tuple\", tuple),\n+        (\"dict\", dict),\n+    )\n+    def test_restored_multi_output_type(self, out_type):\n+        inputs = Input(shape=(3,), batch_size=2, name=\"input\")\n+        x = layers.Dense(5)(inputs)\n+        output_a = layers.Dense(4)(x)\n+        output_b = layers.Dense(5)(x)\n+        if dict == out_type:\n+            outputs = {\"a\": output_a, \"b\": output_b}\n+        else:\n+            outputs = out_type([output_a, output_b])\n+        model = Functional(inputs, outputs)\n+        model_restored = Functional.from_config(model.get_config())\n+\n+        # Eager call\n+        in_val = np.random.random((2, 3))\n+        out_val = model_restored(in_val)\n+        self.assertIsInstance(out_val, out_type)\n+\n+        # Symbolic call\n+        out_val = model_restored(Input(shape=(3,), batch_size=2))\n+        self.assertIsInstance(out_val, out_type)\n+\n     @pytest.mark.requires_trainable_backend\n     def test_layer_getters(self):\n         # Test mixing ops and layers\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4cef3327bce371e093badc56e866408fbbafb0d1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 11 | Churn Cumulative: 834 | Contributors (this commit): 9 | Commits (past 90d): 16 | Contributors (cumulative): 14 | DMM Complexity: 1.0\n\nDIFF:\n@@ -609,6 +609,8 @@ def stop_gradient(variable):\n     ... )\n     >>> var = keras.ops.stop_gradient(var)\n     \"\"\"\n+    if any_symbolic_tensors((variable,)):\n+        return StopGradient().symbolic_call(variable)\n     return backend.core.stop_gradient(variable)\n \n \n\n@@ -583,6 +583,15 @@ class CoreOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         y = ops.stop_gradient(x)\n         self.assertAllClose(x, y)\n \n+    def test_stop_gradient_functional(self):\n+        a = layers.Input(shape=(2,))\n+        b = layers.Dense(4, kernel_initializer=\"ones\", use_bias=False)(a)\n+        c = layers.Dense(4, kernel_initializer=\"ones\", use_bias=False)(b)\n+        d = ops.stop_gradient(b) + c\n+        model = models.Model(inputs=a, outputs=d)\n+        output = model(ops.convert_to_tensor([[1.0, 2.0]]))\n+        self.assertAllClose(ops.convert_to_numpy(output), 15.0)\n+\n     def test_shape(self):\n         x = ops.ones((2, 3, 7, 1))\n         self.assertEqual(core.shape(x).__class__, tuple)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d72a0ea4feb7e42040117b000626611cd9786326", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 747 | Lines Deleted: 0 | Files Changed: 10 | Hunks: 24 | Methods Changed: 62 | Complexity Δ (Sum/Max): 105/45 | Churn Δ: 747 | Churn Cumulative: 3708 | Contributors (this commit): 12 | Commits (past 90d): 55 | Contributors (cumulative): 65 | DMM Complexity: 1.0\n\nDIFF:\n@@ -113,6 +113,13 @@ from keras.src.ops.numpy import argsort\n from keras.src.ops.numpy import array\n from keras.src.ops.numpy import average\n from keras.src.ops.numpy import bincount\n+from keras.src.ops.numpy import bitwise_and\n+from keras.src.ops.numpy import bitwise_invert\n+from keras.src.ops.numpy import bitwise_left_shift\n+from keras.src.ops.numpy import bitwise_not\n+from keras.src.ops.numpy import bitwise_or\n+from keras.src.ops.numpy import bitwise_right_shift\n+from keras.src.ops.numpy import bitwise_xor\n from keras.src.ops.numpy import broadcast_to\n from keras.src.ops.numpy import ceil\n from keras.src.ops.numpy import clip\n@@ -156,6 +163,7 @@ from keras.src.ops.numpy import isclose\n from keras.src.ops.numpy import isfinite\n from keras.src.ops.numpy import isinf\n from keras.src.ops.numpy import isnan\n+from keras.src.ops.numpy import left_shift\n from keras.src.ops.numpy import less\n from keras.src.ops.numpy import less_equal\n from keras.src.ops.numpy import linspace\n@@ -197,6 +205,7 @@ from keras.src.ops.numpy import real\n from keras.src.ops.numpy import reciprocal\n from keras.src.ops.numpy import repeat\n from keras.src.ops.numpy import reshape\n+from keras.src.ops.numpy import right_shift\n from keras.src.ops.numpy import roll\n from keras.src.ops.numpy import round\n from keras.src.ops.numpy import searchsorted\n\n@@ -27,6 +27,13 @@ from keras.src.ops.numpy import argsort\n from keras.src.ops.numpy import array\n from keras.src.ops.numpy import average\n from keras.src.ops.numpy import bincount\n+from keras.src.ops.numpy import bitwise_and\n+from keras.src.ops.numpy import bitwise_invert\n+from keras.src.ops.numpy import bitwise_left_shift\n+from keras.src.ops.numpy import bitwise_not\n+from keras.src.ops.numpy import bitwise_or\n+from keras.src.ops.numpy import bitwise_right_shift\n+from keras.src.ops.numpy import bitwise_xor\n from keras.src.ops.numpy import broadcast_to\n from keras.src.ops.numpy import ceil\n from keras.src.ops.numpy import clip\n@@ -70,6 +77,7 @@ from keras.src.ops.numpy import isclose\n from keras.src.ops.numpy import isfinite\n from keras.src.ops.numpy import isinf\n from keras.src.ops.numpy import isnan\n+from keras.src.ops.numpy import left_shift\n from keras.src.ops.numpy import less\n from keras.src.ops.numpy import less_equal\n from keras.src.ops.numpy import linspace\n@@ -111,6 +119,7 @@ from keras.src.ops.numpy import real\n from keras.src.ops.numpy import reciprocal\n from keras.src.ops.numpy import repeat\n from keras.src.ops.numpy import reshape\n+from keras.src.ops.numpy import right_shift\n from keras.src.ops.numpy import roll\n from keras.src.ops.numpy import round\n from keras.src.ops.numpy import select\n\n@@ -113,6 +113,13 @@ from keras.src.ops.numpy import argsort\n from keras.src.ops.numpy import array\n from keras.src.ops.numpy import average\n from keras.src.ops.numpy import bincount\n+from keras.src.ops.numpy import bitwise_and\n+from keras.src.ops.numpy import bitwise_invert\n+from keras.src.ops.numpy import bitwise_left_shift\n+from keras.src.ops.numpy import bitwise_not\n+from keras.src.ops.numpy import bitwise_or\n+from keras.src.ops.numpy import bitwise_right_shift\n+from keras.src.ops.numpy import bitwise_xor\n from keras.src.ops.numpy import broadcast_to\n from keras.src.ops.numpy import ceil\n from keras.src.ops.numpy import clip\n@@ -156,6 +163,7 @@ from keras.src.ops.numpy import isclose\n from keras.src.ops.numpy import isfinite\n from keras.src.ops.numpy import isinf\n from keras.src.ops.numpy import isnan\n+from keras.src.ops.numpy import left_shift\n from keras.src.ops.numpy import less\n from keras.src.ops.numpy import less_equal\n from keras.src.ops.numpy import linspace\n@@ -197,6 +205,7 @@ from keras.src.ops.numpy import real\n from keras.src.ops.numpy import reciprocal\n from keras.src.ops.numpy import repeat\n from keras.src.ops.numpy import reshape\n+from keras.src.ops.numpy import right_shift\n from keras.src.ops.numpy import roll\n from keras.src.ops.numpy import round\n from keras.src.ops.numpy import searchsorted\n\n@@ -27,6 +27,13 @@ from keras.src.ops.numpy import argsort\n from keras.src.ops.numpy import array\n from keras.src.ops.numpy import average\n from keras.src.ops.numpy import bincount\n+from keras.src.ops.numpy import bitwise_and\n+from keras.src.ops.numpy import bitwise_invert\n+from keras.src.ops.numpy import bitwise_left_shift\n+from keras.src.ops.numpy import bitwise_not\n+from keras.src.ops.numpy import bitwise_or\n+from keras.src.ops.numpy import bitwise_right_shift\n+from keras.src.ops.numpy import bitwise_xor\n from keras.src.ops.numpy import broadcast_to\n from keras.src.ops.numpy import ceil\n from keras.src.ops.numpy import clip\n@@ -70,6 +77,7 @@ from keras.src.ops.numpy import isclose\n from keras.src.ops.numpy import isfinite\n from keras.src.ops.numpy import isinf\n from keras.src.ops.numpy import isnan\n+from keras.src.ops.numpy import left_shift\n from keras.src.ops.numpy import less\n from keras.src.ops.numpy import less_equal\n from keras.src.ops.numpy import linspace\n@@ -111,6 +119,7 @@ from keras.src.ops.numpy import real\n from keras.src.ops.numpy import reciprocal\n from keras.src.ops.numpy import repeat\n from keras.src.ops.numpy import reshape\n+from keras.src.ops.numpy import right_shift\n from keras.src.ops.numpy import roll\n from keras.src.ops.numpy import round\n from keras.src.ops.numpy import select\n\n@@ -369,6 +369,53 @@ def average(x, axis=None, weights=None):\n     return jnp.average(x, weights=weights, axis=axis)\n \n \n+def bitwise_and(x, y):\n+    x = convert_to_tensor(x)\n+    y = convert_to_tensor(y)\n+    return jnp.bitwise_and(x, y)\n+\n+\n+def bitwise_invert(x):\n+    x = convert_to_tensor(x)\n+    return jnp.bitwise_invert(x)\n+\n+\n+def bitwise_not(x):\n+    return bitwise_invert(x)\n+\n+\n+def bitwise_or(x, y):\n+    x = convert_to_tensor(x)\n+    y = convert_to_tensor(y)\n+    return jnp.bitwise_or(x, y)\n+\n+\n+def bitwise_xor(x, y):\n+    x = convert_to_tensor(x)\n+    y = convert_to_tensor(y)\n+    return jnp.bitwise_xor(x, y)\n+\n+\n+def bitwise_left_shift(x, y):\n+    x = convert_to_tensor(x)\n+    y = convert_to_tensor(y)\n+    return jnp.bitwise_left_shift(x, y)\n+\n+\n+def left_shift(x, y):\n+    return bitwise_left_shift(x, y)\n+\n+\n+def bitwise_right_shift(x, y):\n+    x = convert_to_tensor(x)\n+    y = convert_to_tensor(y)\n+    return jnp.bitwise_right_shift(x, y)\n+\n+\n+def right_shift(x, y):\n+    return bitwise_right_shift(x, y)\n+\n+\n def broadcast_to(x, shape):\n     x = convert_to_tensor(x)\n     return jnp.broadcast_to(x, shape)\n\n@@ -293,6 +293,53 @@ def bincount(x, weights=None, minlength=0, sparse=False):\n     return np.bincount(x, weights, minlength).astype(dtype)\n \n \n+def bitwise_and(x, y):\n+    x = convert_to_tensor(x)\n+    y = convert_to_tensor(y)\n+    return np.bitwise_and(x, y)\n+\n+\n+def bitwise_invert(x):\n+    x = convert_to_tensor(x)\n+    return np.bitwise_not(x)\n+\n+\n+def bitwise_not(x):\n+    return bitwise_invert(x)\n+\n+\n+def bitwise_or(x, y):\n+    x = convert_to_tensor(x)\n+    y = convert_to_tensor(y)\n+    return np.bitwise_or(x, y)\n+\n+\n+def bitwise_xor(x, y):\n+    x = convert_to_tensor(x)\n+    y = convert_to_tensor(y)\n+    return np.bitwise_xor(x, y)\n+\n+\n+def bitwise_left_shift(x, y):\n+    x = convert_to_tensor(x)\n+    y = convert_to_tensor(y)\n+    return np.left_shift(x, y)\n+\n+\n+def left_shift(x, y):\n+    return bitwise_left_shift(x, y)\n+\n+\n+def bitwise_right_shift(x, y):\n+    x = convert_to_tensor(x)\n+    y = convert_to_tensor(y)\n+    return np.right_shift(x, y)\n+\n+\n+def right_shift(x, y):\n+    return bitwise_right_shift(x, y)\n+\n+\n def broadcast_to(x, shape):\n     return np.broadcast_to(x, shape)\n \n\n@@ -836,6 +836,68 @@ def average(x, axis=None, weights=None):\n     return avg\n \n \n+def bitwise_and(x, y):\n+    x = convert_to_tensor(x)\n+    y = convert_to_tensor(y)\n+    dtype = dtypes.result_type(x.dtype, y.dtype)\n+    x = tf.cast(x, dtype)\n+    y = tf.cast(y, dtype)\n+    return tf.bitwise.bitwise_and(x, y)\n+\n+\n+def bitwise_invert(x):\n+    x = convert_to_tensor(x)\n+    return tf.bitwise.invert(x)\n+\n+\n+def bitwise_not(x):\n+    return bitwise_invert(x)\n+\n+\n+def bitwise_or(x, y):\n+    x = convert_to_tensor(x)\n+    y = convert_to_tensor(y)\n+    dtype = dtypes.result_type(x.dtype, y.dtype)\n+    x = tf.cast(x, dtype)\n+    y = tf.cast(y, dtype)\n+    return tf.bitwise.bitwise_or(x, y)\n+\n+\n+def bitwise_xor(x, y):\n+    x = convert_to_tensor(x)\n+    y = convert_to_tensor(y)\n+    dtype = dtypes.result_type(x.dtype, y.dtype)\n+    x = tf.cast(x, dtype)\n+    y = tf.cast(y, dtype)\n+    return tf.bitwise.bitwise_xor(x, y)\n+\n+\n+def bitwise_left_shift(x, y):\n+    x = convert_to_tensor(x)\n+    y = convert_to_tensor(y)\n+    dtype = dtypes.result_type(x.dtype, y.dtype)\n+    x = tf.cast(x, dtype)\n+    y = tf.cast(y, dtype)\n+    return tf.bitwise.left_shift(x, y)\n+\n+\n+def left_shift(x, y):\n+    return bitwise_left_shift(x, y)\n+\n+\n+def bitwise_right_shift(x, y):\n+    x = convert_to_tensor(x)\n+    y = convert_to_tensor(y)\n+    dtype = dtypes.result_type(x.dtype, y.dtype)\n+    x = tf.cast(x, dtype)\n+    y = tf.cast(y, dtype)\n+    return tf.bitwise.right_shift(x, y)\n+\n+\n+def right_shift(x, y):\n+    return bitwise_right_shift(x, y)\n+\n+\n def broadcast_to(x, shape):\n     return tf.broadcast_to(x, shape)\n \n\n@@ -411,6 +411,53 @@ def bincount(x, weights=None, minlength=0, sparse=False):\n     return cast(torch.bincount(x, weights, minlength), dtype)\n \n \n+def bitwise_and(x, y):\n+    x = convert_to_tensor(x)\n+    y = convert_to_tensor(y)\n+    return torch.bitwise_and(x, y)\n+\n+\n+def bitwise_invert(x):\n+    x = convert_to_tensor(x)\n+    return torch.bitwise_not(x)\n+\n+\n+def bitwise_not(x):\n+    return bitwise_invert(x)\n+\n+\n+def bitwise_or(x, y):\n+    x = convert_to_tensor(x)\n+    y = convert_to_tensor(y)\n+    return torch.bitwise_or(x, y)\n+\n+\n+def bitwise_xor(x, y):\n+    x = convert_to_tensor(x)\n+    y = convert_to_tensor(y)\n+    return torch.bitwise_xor(x, y)\n+\n+\n+def bitwise_left_shift(x, y):\n+    x = convert_to_tensor(x)\n+    y = convert_to_tensor(y)\n+    return torch.bitwise_left_shift(x, y)\n+\n+\n+def left_shift(x, y):\n+    return bitwise_left_shift(x, y)\n+\n+\n+def bitwise_right_shift(x, y):\n+    x = convert_to_tensor(x)\n+    y = convert_to_tensor(y)\n+    return torch.bitwise_right_shift(x, y)\n+\n+\n+def right_shift(x, y):\n+    return bitwise_right_shift(x, y)\n+\n+\n def broadcast_to(x, shape):\n     x = convert_to_tensor(x)\n     return torch.broadcast_to(x, shape)\n\n@@ -1184,6 +1184,294 @@ def bincount(x, weights=None, minlength=0, sparse=False):\n     )\n \n \n+class BitwiseAnd(Operation):\n+    def __init__(self):\n+        super().__init__()\n+\n+    def call(self, x, y):\n+        return backend.numpy.bitwise_and(x, y)\n+\n+    def compute_output_spec(self, x, y):\n+        dtype = dtypes.result_type(x.dtype, y.dtype)\n+        return KerasTensor(x.shape, dtype=dtype)\n+\n+\n+@keras_export([\"keras.ops.bitwise_and\", \"keras.ops.numpy.bitwise_and\"])\n+def bitwise_and(x, y):\n+    \"\"\"Compute the bit-wise AND of two arrays element-wise.\n+\n+    Computes the bit-wise AND of the underlying binary representation of the\n+    integers in the input arrays. This ufunc implements the C/Python operator\n+    `&`.\n+\n+    Args:\n+        x: Input integer tensor.\n+        y: Input integer tensor.\n+\n+    Returns:\n+        Result tensor.\n+    \"\"\"\n+    if any_symbolic_tensors((x, y)):\n+        return BitwiseAnd().symbolic_call(x, y)\n+    return backend.numpy.bitwise_and(x, y)\n+\n+\n+class BitwiseInvert(Operation):\n+    def __init__(self):\n+        super().__init__()\n+\n+    def call(self, x):\n+        return backend.numpy.bitwise_invert(x)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=x.dtype)\n+\n+\n+@keras_export([\"keras.ops.bitwise_invert\", \"keras.ops.numpy.bitwise_invert\"])\n+def bitwise_invert(x):\n+    \"\"\"Compute bit-wise inversion, or bit-wise NOT, element-wise.\n+\n+    Computes the bit-wise NOT of the underlying binary representation of the\n+    integers in the input arrays. This ufunc implements the C/Python operator\n+    `~`.\n+\n+    Args:\n+        x: Input integer tensor.\n+\n+    Returns:\n+        Result tensor.\n+    \"\"\"\n+    if any_symbolic_tensors((x,)):\n+        return BitwiseInvert().symbolic_call(x)\n+    return backend.numpy.bitwise_invert(x)\n+\n+\n+class BitwiseNot(Operation):\n+    def __init__(self):\n+        super().__init__()\n+\n+    def call(self, x):\n+        return backend.numpy.bitwise_not(x)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=x.dtype)\n+\n+\n+@keras_export([\"keras.ops.bitwise_not\", \"keras.ops.numpy.bitwise_not\"])\n+def bitwise_not(x):\n+    \"\"\"Compute bit-wise inversion, or bit-wise NOT, element-wise.\n+\n+    Computes the bit-wise NOT of the underlying binary representation of the\n+    integers in the input arrays. This ufunc implements the C/Python operator\n+    `~`.\n+\n+    Args:\n+        x: Input integer tensor.\n+\n+    Returns:\n+        Result tensor.\n+    \"\"\"\n+    if any_symbolic_tensors((x,)):\n+        return BitwiseNot().symbolic_call(x)\n+    return backend.numpy.bitwise_not(x)\n+\n+\n+class BitwiseOr(Operation):\n+    def __init__(self):\n+        super().__init__()\n+\n+    def call(self, x, y):\n+        return backend.numpy.bitwise_or(x, y)\n+\n+    def compute_output_spec(self, x, y):\n+        dtype = dtypes.result_type(x.dtype, y.dtype)\n+        return KerasTensor(x.shape, dtype=dtype)\n+\n+\n+@keras_export([\"keras.ops.bitwise_or\", \"keras.ops.numpy.bitwise_or\"])\n+def bitwise_or(x, y):\n+    \"\"\"Compute the bit-wise OR of two arrays element-wise.\n+\n+    Computes the bit-wise OR of the underlying binary representation of the\n+    integers in the input arrays. This ufunc implements the C/Python operator\n+    `|`.\n+\n+    Args:\n+        x: Input integer tensor.\n+        y: Input integer tensor.\n+\n+    Returns:\n+        Result tensor.\n+    \"\"\"\n+    if any_symbolic_tensors((x, y)):\n+        return BitwiseOr().symbolic_call(x, y)\n+    return backend.numpy.bitwise_or(x, y)\n+\n+\n+class BitwiseXor(Operation):\n+    def __init__(self):\n+        super().__init__()\n+\n+    def call(self, x, y):\n+        return backend.numpy.bitwise_xor(x, y)\n+\n+    def compute_output_spec(self, x, y):\n+        dtype = dtypes.result_type(x.dtype, y.dtype)\n+        return KerasTensor(x.shape, dtype=dtype)\n+\n+\n+@keras_export([\"keras.ops.bitwise_xor\", \"keras.ops.numpy.bitwise_xor\"])\n+def bitwise_xor(x, y):\n+    \"\"\"Compute the bit-wise XOR of two arrays element-wise.\n+\n+    Computes the bit-wise XOR of the underlying binary representation of the\n+    integers in the input arrays. This ufunc implements the C/Python operator\n+    `^`.\n+\n+    Args:\n+        x: Input integer tensor.\n+        y: Input integer tensor.\n+\n+    Returns:\n+        Result tensor.\n+    \"\"\"\n+    if any_symbolic_tensors((x, y)):\n+        return BitwiseXor().symbolic_call(x, y)\n+    return backend.numpy.bitwise_xor(x, y)\n+\n+\n+class BitwiseLeftShift(Operation):\n+    def __init__(self):\n+        super().__init__()\n+\n+    def call(self, x, y):\n+        return backend.numpy.bitwise_left_shift(x, y)\n+\n+    def compute_output_spec(self, x, y):\n+        dtype = dtypes.result_type(x.dtype, y.dtype)\n+        return KerasTensor(x.shape, dtype=dtype)\n+\n+\n+@keras_export(\n+    [\"keras.ops.bitwise_left_shift\", \"keras.ops.numpy.bitwise_left_shift\"]\n+)\n+def bitwise_left_shift(x, y):\n+    \"\"\"Shift the bits of an integer to the left.\n+\n+    Bits are shifted to the left by appending `y` 0s at the right of `x`.\n+    Since the internal representation of numbers is in binary format, this\n+    operation is equivalent to multiplying `x` by `2**y`.\n+\n+    Args:\n+        x: Input integer tensor.\n+        y: Input integer tensor.\n+\n+    Returns:\n+        Result tensor.\n+    \"\"\"\n+    if any_symbolic_tensors((x, y)):\n+        return BitwiseLeftShift().symbolic_call(x, y)\n+    return backend.numpy.bitwise_left_shift(x, y)\n+\n+\n+class LeftShift(Operation):\n+    def __init__(self):\n+        super().__init__()\n+\n+    def call(self, x, y):\n+        return backend.numpy.left_shift(x, y)\n+\n+    def compute_output_spec(self, x, y):\n+        dtype = dtypes.result_type(x.dtype, y.dtype)\n+        return KerasTensor(x.shape, dtype=dtype)\n+\n+\n+@keras_export([\"keras.ops.left_shift\", \"keras.ops.numpy.left_shift\"])\n+def left_shift(x, y):\n+    \"\"\"Shift the bits of an integer to the left.\n+\n+    Bits are shifted to the left by appending `y` 0s at the right of `x`.\n+    Since the internal representation of numbers is in binary format, this\n+    operation is equivalent to multiplying `x` by `2**y`.\n+\n+    Args:\n+        x: Input integer tensor.\n+        y: Input integer tensor.\n+\n+    Returns:\n+        Result tensor.\n+    \"\"\"\n+    if any_symbolic_tensors((x, y)):\n+        return LeftShift().symbolic_call(x, y)\n+    return backend.numpy.left_shift(x, y)\n+\n+\n+class BitwiseRightShift(Operation):\n+    def __init__(self):\n+        super().__init__()\n+\n+    def call(self, x, y):\n+        return backend.numpy.bitwise_right_shift(x, y)\n+\n+    def compute_output_spec(self, x, y):\n+        dtype = dtypes.result_type(x.dtype, y.dtype)\n+        return KerasTensor(x.shape, dtype=dtype)\n+\n+\n+@keras_export(\n+    [\"keras.ops.bitwise_right_shift\", \"keras.ops.numpy.bitwise_right_shift\"]\n+)\n+def bitwise_right_shift(x, y):\n+    \"\"\"Shift the bits of an integer to the right.\n+\n+    Bits are shifted to the right `y`. Because the internal representation of\n+    numbers is in binary format, this operation is equivalent to dividing `x` by\n+    `2**y`.\n+\n+    Args:\n+        x: Input integer tensor.\n+        y: Input integer tensor.\n+\n+    Returns:\n+        Result tensor.\n+    \"\"\"\n+    if any_symbolic_tensors((x, y)):\n+        return BitwiseRightShift().symbolic_call(x, y)\n+    return backend.numpy.bitwise_right_shift(x, y)\n+\n+\n+class RightShift(Operation):\n+    def __init__(self):\n+        super().__init__()\n+\n+    def call(self, x, y):\n+        return backend.numpy.right_shift(x, y)\n+\n+    def compute_output_spec(self, x, y):\n+        dtype = dtypes.result_type(x.dtype, y.dtype)\n+        return KerasTensor(x.shape, dtype=dtype)\n+\n+\n+@keras_export([\"keras.ops.right_shift\", \"keras.ops.numpy.right_shift\"])\n+def right_shift(x, y):\n+    \"\"\"Shift the bits of an integer to the right.\n+\n+    Bits are shifted to the right `y`. Because the internal representation of\n+    numbers is in binary format, this operation is equivalent to dividing `x` by\n+    `2**y`.\n+\n+    Args:\n+        x: Input integer tensor.\n+        y: Input integer tensor.\n+\n+    Returns:\n+        Result tensor.\n+    \"\"\"\n+    if any_symbolic_tensors((x, y)):\n+        return RightShift().symbolic_call(x, y)\n+    return backend.numpy.right_shift(x, y)\n+\n+\n class BroadcastTo(Operation):\n     def __init__(self, shape):\n         super().__init__()\n\n@@ -70,6 +70,35 @@ class NumpyTwoInputOpsDynamicShapeTest(testing.TestCase):\n         y = KerasTensor((2, None))\n         self.assertEqual(knp.arctan2(x, y).shape, (2, 3))\n \n+    def test_bitwise_and(self):\n+        x = KerasTensor((None, 3))\n+        y = KerasTensor((None, 3))\n+        self.assertEqual(knp.bitwise_and(x, y).shape, (None, 3))\n+\n+    def test_bitwise_or(self):\n+        x = KerasTensor((None, 3))\n+        y = KerasTensor((None, 3))\n+        self.assertEqual(knp.bitwise_or(x, y).shape, (None, 3))\n+\n+    def test_bitwise_xor(self):\n+        x = KerasTensor((None, 3))\n+        y = KerasTensor((None, 3))\n+        self.assertEqual(knp.bitwise_xor(x, y).shape, (None, 3))\n+\n+    def test_bitwise_left_shift(self):\n+        x = KerasTensor((None, 3))\n+        y = KerasTensor((None, 3))\n+        self.assertEqual(knp.bitwise_left_shift(x, y).shape, (None, 3))\n+\n+    # left_shift is same as bitwise_left_shift\n+\n+    def test_bitwise_right_shift(self):\n+        x = KerasTensor((None, 3))\n+        y = KerasTensor((None, 3))\n+        self.assertEqual(knp.bitwise_right_shift(x, y).shape, (None, 3))\n+\n+    # right_shift is same as bitwise_right_shift\n+\n     def test_cross(self):\n         x1 = KerasTensor((2, 3, 3))\n         x2 = KerasTensor((1, 3, 2))\n@@ -531,6 +560,35 @@ class NumpyTwoInputOpsStaticShapeTest(testing.TestCase):\n             y = KerasTensor((2, 3, 4))\n             knp.arctan2(x, y)\n \n+    def test_bitwise_and(self):\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((2, 3))\n+        self.assertEqual(knp.bitwise_and(x, y).shape, (2, 3))\n+\n+    def test_bitwise_or(self):\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((2, 3))\n+        self.assertEqual(knp.bitwise_or(x, y).shape, (2, 3))\n+\n+    def test_bitwise_xor(self):\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((2, 3))\n+        self.assertEqual(knp.bitwise_xor(x, y).shape, (2, 3))\n+\n+    def test_bitwise_left_shift(self):\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((2, 3))\n+        self.assertEqual(knp.bitwise_left_shift(x, y).shape, (2, 3))\n+\n+    # left_shift is same as bitwise_left_shift\n+\n+    def test_bitwise_right_shift(self):\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((2, 3))\n+        self.assertEqual(knp.bitwise_right_shift(x, y).shape, (2, 3))\n+\n+    # right_shift is same as bitwise_right_shift\n+\n     def test_cross(self):\n         x1 = KerasTensor((2, 3, 3))\n         x2 = KerasTensor((1, 3, 2))\n@@ -1055,6 +1113,12 @@ class NumpyOneInputOpsDynamicShapeTest(testing.TestCase):\n             weights = KerasTensor((None, 4))\n             knp.average(x, weights=weights)\n \n+    def test_bitwise_invert(self):\n+        x = KerasTensor((None, 3))\n+        self.assertEqual(knp.bitwise_invert(x).shape, (None, 3))\n+\n+    # bitwise_not is same as bitwise_invert\n+\n     def test_broadcast_to(self):\n         x = KerasTensor((None, 3))\n         self.assertEqual(knp.broadcast_to(x, (2, 3, 3)).shape, (2, 3, 3))\n@@ -1612,6 +1676,12 @@ class NumpyOneInputOpsStaticShapeTest(testing.TestCase):\n         x = KerasTensor((2, 3))\n         self.assertEqual(knp.average(x).shape, ())\n \n+    def test_bitwise_invert(self):\n+        x = KerasTensor((2, 3))\n+        self.assertEqual(knp.bitwise_invert(x).shape, (2, 3))\n+\n+    # bitwise_not is same as bitwise_invert\n+\n     def test_broadcast_to(self):\n         x = KerasTensor((2, 3))\n         self.assertEqual(knp.broadcast_to(x, (2, 2, 3)).shape, (2, 2, 3))\n@@ -2185,6 +2255,40 @@ class NumpyTwoInputOpsCorretnessTest(testing.TestCase, parameterized.TestCase):\n \n         self.assertAllClose(knp.Arctan2()(x, y), np.arctan2(x, y))\n \n+    def test_bitwise_and(self):\n+        x = np.array([2, 5, 255])\n+        y = np.array([3, 14, 16])\n+        self.assertAllClose(knp.bitwise_and(x, y), np.bitwise_and(x, y))\n+        self.assertAllClose(knp.BitwiseAnd()(x, y), np.bitwise_and(x, y))\n+\n+    def test_bitwise_or(self):\n+        x = np.array([2, 5, 255])\n+        y = np.array([3, 14, 16])\n+        self.assertAllClose(knp.bitwise_or(x, y), np.bitwise_or(x, y))\n+        self.assertAllClose(knp.BitwiseOr()(x, y), np.bitwise_or(x, y))\n+\n+    def test_bitwise_xor(self):\n+        x = np.array([2, 5, 255])\n+        y = np.array([3, 14, 16])\n+        self.assertAllClose(knp.bitwise_xor(x, y), np.bitwise_xor(x, y))\n+        self.assertAllClose(knp.BitwiseXor()(x, y), np.bitwise_xor(x, y))\n+\n+    def test_bitwise_left_shift(self):\n+        x = np.array([50, 60, 70])\n+        y = np.array([1, 2, 3])\n+        self.assertAllClose(knp.bitwise_left_shift(x, y), np.left_shift(x, y))\n+        self.assertAllClose(knp.BitwiseLeftShift()(x, y), np.left_shift(x, y))\n+\n+    # left_shift is same as bitwise_left_shift\n+\n+    def test_bitwise_right_shift(self):\n+        x = np.array([5, 6, 7])\n+        y = np.array([1, 2, 3])\n+        self.assertAllClose(knp.bitwise_right_shift(x, y), np.right_shift(x, y))\n+        self.assertAllClose(knp.BitwiseRightShift()(x, y), np.right_shift(x, y))\n+\n+    # right_shift is same as bitwise_right_shift\n+\n     def test_cross(self):\n         x1 = np.ones([2, 1, 4, 3])\n         x2 = np.ones([2, 1, 4, 2])\n@@ -3286,6 +3390,13 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         self.assertAllClose(output, expected_output)\n         self.assertSparse(output, sparse_input or sparse_arg)\n \n+    def test_bitwise_invert(self):\n+        x = np.array([2, 5, 255])\n+        self.assertAllClose(knp.bitwise_invert(x), np.bitwise_not(x))\n+        self.assertAllClose(knp.BitwiseInvert()(x), np.bitwise_not(x))\n+\n+    # bitwise_not is same as bitwise_invert\n+\n     def test_broadcast_to(self):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n         self.assertAllClose(\n@@ -5775,6 +5886,115 @@ class NumpyDtypeTest(testing.TestCase, parameterized.TestCase):\n             knp.Average().symbolic_call(x1, weights=x2).dtype, expected_dtype\n         )\n \n+    @parameterized.named_parameters(\n+        named_product(dtypes=itertools.combinations(INT_DTYPES, 2))\n+    )\n+    def test_bitwise_and(self, dtypes):\n+        import jax.numpy as jnp\n+\n+        dtype1, dtype2 = dtypes\n+        x1 = knp.ones((1,), dtype=dtype1)\n+        x2 = knp.ones((1,), dtype=dtype2)\n+        x1_jax = jnp.ones((1,), dtype=dtype1)\n+        x2_jax = jnp.ones((1,), dtype=dtype2)\n+        expected_dtype = standardize_dtype(\n+            jnp.bitwise_and(x1_jax, x2_jax).dtype\n+        )\n+\n+        self.assertDType(knp.bitwise_and(x1, x2), expected_dtype)\n+        self.assertDType(knp.BitwiseAnd().symbolic_call(x1, x2), expected_dtype)\n+\n+    @parameterized.named_parameters(named_product(dtype=INT_DTYPES))\n+    def test_bitwise_invert(self, dtype):\n+        import jax.numpy as jnp\n+\n+        x = knp.ones((1,), dtype=dtype)\n+        x_jax = jnp.ones((1,), dtype=dtype)\n+        expected_dtype = standardize_dtype(jnp.bitwise_invert(x_jax).dtype)\n+\n+        self.assertDType(knp.bitwise_invert(x), expected_dtype)\n+        self.assertDType(knp.BitwiseInvert().symbolic_call(x), expected_dtype)\n+\n+    # bitwise_not is same as bitwise_invert\n+\n+    @parameterized.named_parameters(\n+        named_product(dtypes=itertools.combinations(INT_DTYPES, 2))\n+    )\n+    def test_bitwise_or(self, dtypes):\n+        import jax.numpy as jnp\n+\n+        dtype1, dtype2 = dtypes\n+        x1 = knp.ones((1,), dtype=dtype1)\n+        x2 = knp.ones((1,), dtype=dtype2)\n+        x1_jax = jnp.ones((1,), dtype=dtype1)\n+        x2_jax = jnp.ones((1,), dtype=dtype2)\n+        expected_dtype = standardize_dtype(jnp.bitwise_or(x1_jax, x2_jax).dtype)\n+\n+        self.assertDType(knp.bitwise_or(x1, x2), expected_dtype)\n+        self.assertDType(knp.BitwiseOr().symbolic_call(x1, x2), expected_dtype)\n+\n+    @parameterized.named_parameters(\n+        named_product(dtypes=itertools.combinations(INT_DTYPES, 2))\n+    )\n+    def test_bitwise_xor(self, dtypes):\n+        import jax.numpy as jnp\n+\n+        dtype1, dtype2 = dtypes\n+        x1 = knp.ones((1,), dtype=dtype1)\n+        x2 = knp.ones((1,), dtype=dtype2)\n+        x1_jax = jnp.ones((1,), dtype=dtype1)\n+        x2_jax = jnp.ones((1,), dtype=dtype2)\n+        expected_dtype = standardize_dtype(\n+            jnp.bitwise_xor(x1_jax, x2_jax).dtype\n+        )\n+\n+        self.assertDType(knp.bitwise_xor(x1, x2), expected_dtype)\n+        self.assertDType(knp.BitwiseXor().symbolic_call(x1, x2), expected_dtype)\n+\n+    @parameterized.named_parameters(\n+        named_product(dtypes=itertools.combinations(INT_DTYPES, 2))\n+    )\n+    def test_bitwise_left_shift(self, dtypes):\n+        import jax.numpy as jnp\n+\n+        dtype1, dtype2 = dtypes\n+        x1 = knp.ones((1,), dtype=dtype1)\n+        x2 = knp.ones((1,), dtype=dtype2)\n+        x1_jax = jnp.ones((1,), dtype=dtype1)\n+        x2_jax = jnp.ones((1,), dtype=dtype2)\n+        expected_dtype = standardize_dtype(\n+            jnp.bitwise_left_shift(x1_jax, x2_jax).dtype\n+        )\n+\n+        self.assertDType(knp.bitwise_left_shift(x1, x2), expected_dtype)\n+        self.assertDType(\n+            knp.BitwiseLeftShift().symbolic_call(x1, x2), expected_dtype\n+        )\n+\n+    # left_shift is same as bitwise_left_shift\n+\n+    @parameterized.named_parameters(\n+        named_product(dtypes=itertools.combinations(INT_DTYPES, 2))\n+    )\n+    def test_bitwise_right_shift(self, dtypes):\n+        import jax.numpy as jnp\n+\n+        dtype1, dtype2 = dtypes\n+        x1 = knp.ones((1,), dtype=dtype1)\n+        x2 = knp.ones((1,), dtype=dtype2)\n+        x1_jax = jnp.ones((1,), dtype=dtype1)\n+        x2_jax = jnp.ones((1,), dtype=dtype2)\n+        expected_dtype = standardize_dtype(\n+            jnp.bitwise_right_shift(x1_jax, x2_jax).dtype\n+        )\n+\n+        self.assertDType(knp.bitwise_right_shift(x1, x2), expected_dtype)\n+        self.assertDType(\n+            knp.BitwiseRightShift().symbolic_call(x1, x2), expected_dtype\n+        )\n+\n+    # right_shift is same as bitwise_right_shift\n+\n     @parameterized.named_parameters(named_product(dtype=ALL_DTYPES))\n     def test_broadcast_to(self, dtype):\n         import jax.numpy as jnp\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
