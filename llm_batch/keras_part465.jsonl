{"custom_id": "keras#f0fc6f798937a7a5fdab469c0f16bdde7cfc4ccd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 73 | Lines Deleted: 65 | Files Changed: 3 | Hunks: 27 | Methods Changed: 12 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 138 | Churn Cumulative: 1140 | Contributors (this commit): 6 | Commits (past 90d): 17 | Contributors (cumulative): 14 | DMM Complexity: 0.0\n\nDIFF:\n@@ -141,11 +141,11 @@ def _clone_functional_model(model, input_tensors=None, layer_fn=_clone_layer):\n             to build the model upon. If not provided,\n             placeholders will be created.\n         layer_fn: callable to be applied on non-input layers in the model. By\n-            default it clones the layer. Another example is to preserve the layer\n-            to share the weights. This is required when we create a per-replica\n-            copy of the model with distribution strategy; we want the weights to\n-            be shared but still feed inputs separately so we create new input\n-            layers.\n+            default it clones the layer. Another example is to preserve the\n+            layer to share the weights. This is required when we create a\n+            per-replica copy of the model with distribution strategy; we want\n+            the weights to be shared but still feed inputs separately so we\n+            create new input layers.\n \n     Returns:\n         An instance of `Model` reproducing the behavior\n@@ -181,8 +181,8 @@ def _clone_functional_model(model, input_tensors=None, layer_fn=_clone_layer):\n         for i, input_tensor in enumerate(input_tensors):\n             original_input_layer = model._input_layers[i]\n \n-            # Cache input layer. Create a new layer if the tensor is originally not\n-            # from a Keras layer.\n+            # Cache input layer. Create a new layer if the tensor is originally\n+            # not from a Keras layer.\n             if not backend.is_keras_tensor(input_tensor):\n                 name = original_input_layer.name\n                 input_tensor = Input(\n@@ -248,7 +248,8 @@ def _clone_layers_and_model_config(model, input_layers, layer_fn):\n \n     Args:\n       model: A Functional model.\n-      input_layers: Dictionary mapping input layers in `model` to new input layers\n+      input_layers: Dictionary mapping input layers in `model` to new input\n+        layers.\n       layer_fn: Function used to clone all non-input layers.\n \n     Returns:\n@@ -285,8 +286,8 @@ def _remove_ancillary_layers(model, layer_map, layers):\n       layers: A list of all layers.\n \n     Returns:\n-      Two lists of layers: (1) `layers` with the ancillary layers removed, and (2)\n-      the ancillary layers.\n+      Two lists of layers: (1) `layers` with the ancillary layers removed, and\n+      (2) the ancillary layers.\n     \"\"\"\n     ancillary_layers = []  # Additional layers for computing losses and metrics.\n     if not model._is_graph_network:\n@@ -315,11 +316,11 @@ def _clone_sequential_model(model, input_tensors=None, layer_fn=_clone_layer):\n             to build the model upon. If not provided,\n             placeholders will be created.\n         layer_fn: callable to be applied on non-input layers in the model. By\n-            default it clones the layer. Another example is to preserve the layer\n-            to share the weights. This is required when we create a per-replica\n-            copy of the model with distribution strategy; we want the weights to\n-            be shared but still feed inputs separately so we create new input\n-            layers.\n+            default it clones the layer. Another example is to preserve the\n+            layer to share the weights. This is required when we create a\n+            per-replica copy of the model with distribution strategy; we want\n+            the weights to be shared but still feed inputs separately so we\n+            create new input layers.\n \n     Returns:\n         An instance of `Sequential` reproducing the behavior\n@@ -368,8 +369,8 @@ def _clone_sequential_model(model, input_tensors=None, layer_fn=_clone_layer):\n         cloned_model = Sequential(layers=layers, name=model.name)\n     elif len(generic_utils.to_list(input_tensors)) != 1:\n         raise ValueError(\n-            \"To clone a `Sequential` model, we expect at most one tensor as part \"\n-            f\"of `input_tensors`. Received: input_tensors={input_tensors}\"\n+            \"To clone a `Sequential` model, we expect at most one tensor as \"\n+            f\"part of `input_tensors`. Received: input_tensors={input_tensors}\"\n         )\n     else:\n         # Overwrite the original model's input layer.\n@@ -405,8 +406,8 @@ def _clone_sequential_model(model, input_tensors=None, layer_fn=_clone_layer):\n     tensor_map = {}  # Maps tensors from `model` to those in `cloned_model`.\n     for depth, cloned_nodes in cloned_model._nodes_by_depth.items():\n         nodes = model._nodes_by_depth[depth]\n-        # This should be safe in a Sequential model. In an arbitrary network, you\n-        # need to sort using the outbound layer of the node as a key.\n+        # This should be safe in a Sequential model. In an arbitrary network,\n+        # you need to sort using the outbound layer of the node as a key.\n         for cloned_node, node in zip(cloned_nodes, nodes):\n             if isinstance(cloned_node.output_tensors, list):\n                 for j, output_tensor in enumerate(cloned_node.output_tensors):\n@@ -450,14 +451,14 @@ def clone_model(model, input_tensors=None, clone_function=None):\n             to build the model upon. If not provided,\n             new `Input` objects will be created.\n         clone_function: Callable to be used to clone each layer in the target\n-            model (except `InputLayer` instances). It takes as argument the layer\n-            instance to be cloned, and returns the corresponding layer instance to\n-            be used in the model copy. If unspecified, this callable defaults to\n-            the following serialization/deserialization function:\n+            model (except `InputLayer` instances). It takes as argument the\n+            layer instance to be cloned, and returns the corresponding layer\n+            instance to be used in the model copy. If unspecified, this callable\n+            defaults to the following serialization/deserialization function:\n             `lambda layer: layer.__class__.from_config(layer.get_config())`.\n             By passing a custom callable, you can customize your copy of the\n-            model, e.g. by wrapping certain layers of interest (you might want to\n-            replace all `LSTM` instances with equivalent\n+            model, e.g. by wrapping certain layers of interest (you might want\n+            to replace all `LSTM` instances with equivalent\n             `Bidirectional(LSTM(...))` instances, for example).\n \n     Returns:\n@@ -508,9 +509,9 @@ def clone_model(model, input_tensors=None, clone_function=None):\n def _in_place_subclassed_model_reset(model):\n     \"\"\"Substitute for model cloning that works for subclassed models.\n \n-    Subclassed models cannot be cloned because their topology is not serializable.\n-    To \"instantiate\" an identical model in a new TF graph, we reuse the original\n-    model object, but we clear its state.\n+    Subclassed models cannot be cloned because their topology is not\n+    serializable. To \"instantiate\" an identical model in a new TF graph, we\n+    reuse the original model object, but we clear its state.\n \n     After calling this function on a model instance, you can use the model\n     instance as if it were a model clone (in particular you can use it in a new\n@@ -563,7 +564,8 @@ def _in_place_subclassed_model_reset(model):\n             \"_compile_metric_functions\",\n             \"_output_loss_metrics\",\n         ):\n-            # Handle case: list/tuple of layers (also tracked by the Network API).\n+            # Handle case: list/tuple of layers (also tracked by the Network\n+            # API).\n             if value and all(isinstance(val, Layer) for val in value):\n                 raise ValueError(\n                     \"We do not support the use of list-of-layers \"\n@@ -583,8 +585,8 @@ def _in_place_subclassed_model_reset(model):\n     for layer in original_layers:  # We preserve layer order.\n         config = layer.get_config()\n         # This will not work for nested subclassed models used as layers.\n-        # This would be theoretically possible to support, but would add complexity.\n-        # Only do it if users complain.\n+        # This would be theoretically possible to support, but would add\n+        # complexity. Only do it if users complain.\n         if isinstance(layer, training.Model) and not layer._is_graph_network:\n             raise ValueError(\n                 \"We do not support the use of nested subclassed models \"\n@@ -654,8 +656,8 @@ def _reset_build_compile_trackers(model):\n def in_place_subclassed_model_state_restoration(model):\n     \"\"\"Restores the original state of a model after it was \"reset\".\n \n-    This undoes this action of `_in_place_subclassed_model_reset`, which is called\n-    in `clone_and_build_model` if `in_place_reset` is set to True.\n+    This undoes this action of `_in_place_subclassed_model_reset`, which is\n+    called in `clone_and_build_model` if `in_place_reset` is set to True.\n \n     Args:\n       model: Instance of a Keras model created via subclassing, on which\n@@ -667,10 +669,10 @@ def in_place_subclassed_model_state_restoration(model):\n         hasattr(model, \"_original_attributes_cache\")\n         and model._original_attributes_cache is not None\n     ):\n-        # Models have sticky attribute assignment, so we want to be careful to add\n-        # back the previous attributes and track Layers by their original names\n-        # without adding dependencies on \"utility\" attributes which Models exempt\n-        # when they're constructed.\n+        # Models have sticky attribute assignment, so we want to be careful to\n+        # add back the previous attributes and track Layers by their original\n+        # names without adding dependencies on \"utility\" attributes which Models\n+        # exempt when they're constructed.\n         setattr_tracking = model._setattr_tracking\n         model._setattr_tracking = False\n         model._self_tracked_trackables = []\n@@ -701,16 +703,16 @@ def clone_and_build_model(\n     This function can be run in the same graph or in a separate graph from the\n     model. When using a separate graph, `in_place_reset` must be `False`.\n \n-    Note that, currently, the clone produced from this function may not work with\n-    TPU DistributionStrategy. Try at your own risk.\n+    Note that, currently, the clone produced from this function may not work\n+    with TPU DistributionStrategy. Try at your own risk.\n \n     Args:\n       model: `tf.keras.Model` object. Can be Functional, Sequential, or\n         sub-classed.\n       input_tensors: Optional list or dictionary of input tensors to build the\n         model upon. If not provided, placeholders will be created.\n-      target_tensors: Optional list of target tensors for compiling the model. If\n-        not provided, placeholders will be created.\n+      target_tensors: Optional list of target tensors for compiling the model.\n+        If not provided, placeholders will be created.\n       custom_objects: Optional dictionary mapping string names to custom classes\n         or functions.\n       compile_clone: Boolean, whether to compile model clone (default `True`).\n@@ -719,10 +721,10 @@ def clone_and_build_model(\n         this argument must be set to `True` (default `False`). To restore the\n         original model, use the function\n         `in_place_subclassed_model_state_restoration(model)`.\n-      optimizer_iterations: An iterations variable that will be incremented by the\n-        optimizer if the clone is compiled. This argument is used when a Keras\n-        model is cloned into an Estimator model function, because Estimators\n-        create their own global step variable.\n+      optimizer_iterations: An iterations variable that will be incremented by\n+        the optimizer if the clone is compiled. This argument is used when a\n+        Keras model is cloned into an Estimator model function, because\n+        Estimators create their own global step variable.\n       optimizer_config: Optimizer config dictionary or list of dictionary\n         returned from `get_config()`. This argument should be defined if\n         `clone_and_build_model` is called in a different graph or session from\n@@ -741,8 +743,8 @@ def clone_and_build_model(\n     orig_optimizer = model.optimizer\n     if compile_clone and not orig_optimizer:\n         raise ValueError(\n-            \"Error when cloning model: `compile_clone` was set to True, but the \"\n-            f\"original model has not been compiled. Received: model={model}\"\n+            \"Error when cloning model: `compile_clone` was set to True, but \"\n+            f\"the original model has not been compiled. Received: model={model}\"\n         )\n \n     if compile_clone:\n@@ -772,8 +774,8 @@ def clone_and_build_model(\n                     )\n         else:\n             try:\n-                # Prefer cloning the model if serial/deserial logic is implemented for\n-                # subclassed model.\n+                # Prefer cloning the model if serial/deserial logic is\n+                # implemented for subclassed model.\n                 clone = model.__class__.from_config(model.get_config())\n             except NotImplementedError:\n                 logging.warning(\n@@ -784,11 +786,13 @@ def clone_and_build_model(\n                 if not in_place_reset:\n                     raise ValueError(\n                         f\"This model ({model}) is a subclassed model. \"\n-                        \"Such a model cannot be cloned, but there is a workaround where \"\n-                        \"the model is reset in-place. To use this, please set the \"\n-                        \"argument `in_place_reset` to `True`. This will reset the \"\n-                        \"attributes in the original model. To restore the attributes, \"\n-                        \"call `in_place_subclassed_model_state_restoration(model)`.\"\n+                        \"Such a model cannot be cloned, but there is a \"\n+                        \"workaround where the model is reset in-place. \"\n+                        \"To use this, please set the \"\n+                        \"argument `in_place_reset` to `True`. This will reset \"\n+                        \"the attributes in the original model. \"\n+                        \"To restore the attributes, call \"\n+                        \"`in_place_subclassed_model_state_restoration(model)`.\"\n                     )\n                 clone = model\n                 _in_place_subclassed_model_reset(clone)\n@@ -819,7 +823,8 @@ def clone_and_build_model(\n                     orig_optimizer[0].__class__.from_config(optimizer_config)\n                 ]\n             else:\n-                # optimizer config is list of dict, same order as orig_optimizer.\n+                # optimizer config is list of dict, same order as\n+                # orig_optimizer.\n                 optimizer = [\n                     opt.__class__.from_config(opt_config)\n                     for (opt, opt_config) in zip(\n\n@@ -34,7 +34,8 @@ class TestModel(keras.Model):\n     \"\"\"A model subclass.\"\"\"\n \n     def __init__(self, n_outputs=4, trainable=True):\n-        \"\"\"A test class with one dense layer and number of outputs as a variable.\"\"\"\n+        \"\"\"A test class with one dense layer and number of outputs as a\n+        variable.\"\"\"\n         super().__init__()\n         self.layer1 = keras.layers.Dense(n_outputs)\n         self.n_outputs = tf.Variable(n_outputs, trainable=trainable)\n@@ -157,7 +158,8 @@ class TestModelCloning(test_combinations.TestCase):\n             )[0],\n             keras.layers.InputLayer,\n         )\n-        # The new models inputs should have the properties of the new input tensor\n+        # The new models inputs should have the properties of the new input\n+        # tensor\n         if tf.__internal__.tf2.enabled():\n             # In TF1, the new model will be a:0\n             self.assertEqual(new_model.input_names[0], input_a.name)\n@@ -167,8 +169,8 @@ class TestModelCloning(test_combinations.TestCase):\n         # On top of new, non-Keras tensor  -- clone model should always have an\n         # InputLayer.\n         if not tf.executing_eagerly():\n-            # TODO(b/121277734):Skip Eager contexts, as Input() layers raise an error\n-            # saying they should not be used with EagerTensors\n+            # TODO(b/121277734):Skip Eager contexts, as Input() layers raise an\n+            # error saying they should not be used with EagerTensors\n             input_a = keras.backend.variable(val_a)\n             new_model = clone_fn(model, input_tensors=input_a)\n             self.assertIsInstance(\n@@ -250,8 +252,8 @@ class TestModelCloning(test_combinations.TestCase):\n \n         # On top of new, non-Keras tensors\n         if not tf.executing_eagerly():\n-            # TODO(b/121277734):Skip Eager contexts, as Input() layers raise an error\n-            # saying they should not be used with EagerTensors\n+            # TODO(b/121277734):Skip Eager contexts, as Input() layers raise an\n+            # error saying they should not be used with EagerTensors\n             input_a = keras.backend.variable(val_a)\n             input_b = keras.backend.variable(val_b)\n             new_model = clone_fn(model, input_tensors=[input_a, input_b])\n\n@@ -33,9 +33,9 @@ class SharpnessAwareMinimization(Model):\n     \"\"\"Sharpness aware minimization (SAM) training flow.\n \n     Sharpness-aware minimization (SAM) is a technique that improves the model\n-    generalization and provides robustness to label noise. Mini-batch splitting is\n-    proven to improve the SAM's performance, so users can control how mini batches\n-    are split via setting the `num_batch_splits` argument.\n+    generalization and provides robustness to label noise. Mini-batch splitting\n+    is proven to improve the SAM's performance, so users can control how mini\n+    batches are split via setting the `num_batch_splits` argument.\n \n     Args:\n       model: `tf.keras.Model` instance. The inner model that does the\n@@ -111,7 +111,8 @@ class SharpnessAwareMinimization(Model):\n             for (variable, epsilon_w) in zip(\n                 trainable_variables, epsilon_w_cache\n             ):\n-                # Restore the variable to its original value before `apply_gradients()`.\n+                # Restore the variable to its original value before\n+                # `apply_gradients()`.\n                 self._distributed_apply_epsilon_w(\n                     variable, -epsilon_w, tf.distribute.get_strategy()\n                 )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bb7edcbc84c11b22aa9b885f910d949dd5e10891", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 19435 | Contributors (this commit): 131 | Commits (past 90d): 26 | Contributors (cumulative): 131 | DMM Complexity: None\n\nDIFF:\n@@ -966,7 +966,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n \n         This method can be overridden to support custom training logic.\n         For concrete examples of how to override this method see\n-        [Customizing what happends in fit](\n+        [Customizing what happens in fit](\n         https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit).\n         This method is called by `Model.make_train_function`.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ee4e6ec720941958833f022cddec708902f78c2d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 15 | Lines Deleted: 12 | Files Changed: 2 | Hunks: 8 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 27 | Churn Cumulative: 185 | Contributors (this commit): 6 | Commits (past 90d): 11 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -80,14 +80,15 @@ class LinearModel(training.Model):\n           units: Positive integer, output dimension without the batch size.\n           activation: Activation function to use.\n             If you don't specify anything, no activation is applied.\n-          use_bias: whether to calculate the bias/intercept for this model. If set\n-            to False, no bias/intercept will be used in calculations, e.g., the data\n-            is already centered.\n+          use_bias: whether to calculate the bias/intercept for this model. If\n+            set to False, no bias/intercept will be used in calculations, e.g.,\n+            the data is already centered.\n           kernel_initializer: Initializer for the `kernel` weights matrices.\n           bias_initializer: Initializer for the bias vector.\n           kernel_regularizer: regularizer for kernel vectors.\n           bias_regularizer: regularizer for bias vector.\n-          **kwargs: The keyword arguments that are passed on to BaseLayer.__init__.\n+          **kwargs: The keyword arguments that are passed on to\n+            BaseLayer.__init__.\n         \"\"\"\n \n         self.units = units\n\n@@ -44,7 +44,8 @@ class WideDeepModel(keras_training.Model):\n     dnn_model = keras.Sequential([keras.layers.Dense(units=64),\n                                  keras.layers.Dense(units=1)])\n     combined_model = WideDeepModel(linear_model, dnn_model)\n-    combined_model.compile(optimizer=['sgd', 'adam'], loss='mse', metrics=['mse'])\n+    combined_model.compile(optimizer=['sgd', 'adam'],\n+                           loss='mse', metrics=['mse'])\n     # define dnn_inputs and linear_inputs as separate numpy arrays or\n     # a single numpy array if dnn_inputs is same as linear_inputs.\n     combined_model.fit([linear_inputs, dnn_inputs], y, epochs)\n@@ -66,7 +67,8 @@ class WideDeepModel(keras_training.Model):\n     dnn_model.compile('rmsprop', 'mse')\n     dnn_model.fit(dnn_inputs, y, epochs)\n     combined_model = WideDeepModel(linear_model, dnn_model)\n-    combined_model.compile(optimizer=['sgd', 'adam'], loss='mse', metrics=['mse'])\n+    combined_model.compile(optimizer=['sgd', 'adam'],\n+                           loss='mse', metrics=['mse'])\n     combined_model.fit([linear_inputs, dnn_inputs], y, epochs)\n     ```\n \n@@ -76,14 +78,14 @@ class WideDeepModel(keras_training.Model):\n         \"\"\"Create a Wide & Deep Model.\n \n         Args:\n-          linear_model: a premade LinearModel, its output must match the output of\n-            the dnn model.\n+          linear_model: a premade LinearModel, its output must match the output\n+            of the dnn model.\n           dnn_model: a `tf.keras.Model`, its output must match the output of the\n             linear model.\n           activation: Activation function. Set it to None to maintain a linear\n             activation.\n-          **kwargs: The keyword arguments that are passed on to BaseLayer.__init__.\n-            Allowed keyword arguments include `name`.\n+          **kwargs: The keyword arguments that are passed on to\n+            BaseLayer.__init__. Allowed keyword arguments include `name`.\n         \"\"\"\n         super().__init__(**kwargs)\n         base_layer.keras_premade_model_gauge.get_cell(\"WideDeep\").set(True)\n@@ -171,12 +173,12 @@ class WideDeepModel(keras_training.Model):\n                     # Training updates\n                     updates = []\n                     linear_updates = linear_optimizer.get_updates(\n-                        params=self.linear_model.trainable_weights,  # pylint: disable=protected-access\n+                        params=self.linear_model.trainable_weights,\n                         loss=self.total_loss,\n                     )\n                     updates += linear_updates\n                     dnn_updates = dnn_optimizer.get_updates(\n-                        params=self.dnn_model.trainable_weights,  # pylint: disable=protected-access\n+                        params=self.dnn_model.trainable_weights,\n                         loss=self.total_loss,\n                     )\n                     updates += dnn_updates\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7b5629dcf8d770e9e9fdc77ced3f87c8df0990a1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 188 | Lines Deleted: 170 | Files Changed: 5 | Hunks: 49 | Methods Changed: 20 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 358 | Churn Cumulative: 20455 | Contributors (this commit): 81 | Commits (past 90d): 27 | Contributors (cumulative): 111 | DMM Complexity: 1.0\n\nDIFF:\n@@ -295,15 +295,15 @@ class BatchFromFilesMixin:\n                 (if `save_to_dir` is set).\n             subset: Subset of data (`\"training\"` or `\"validation\"`) if\n                 validation_split is set in ImageDataGenerator.\n-            interpolation: Interpolation method used to resample the image if the\n-                target size is different from that of the loaded image.\n-                Supported methods are \"nearest\", \"bilinear\", and \"bicubic\".\n-                If PIL version 1.1.3 or newer is installed, \"lanczos\" is also\n+            interpolation: Interpolation method used to resample the image if\n+                the target size is different from that of the loaded image.\n+                Supported methods are \"nearest\", \"bilinear\", and \"bicubic\". If\n+                PIL version 1.1.3 or newer is installed, \"lanczos\" is also\n                 supported. If PIL version 3.4.0 or newer is installed, \"box\" and\n                 \"hamming\" are also supported. By default, \"nearest\" is used.\n-            keep_aspect_ratio: Boolean, whether to resize images to a target size\n-                without aspect ratio distortion. The image is cropped in the center\n-                with target aspect ratio before resizing.\n+            keep_aspect_ratio: Boolean, whether to resize images to a target\n+                size without aspect ratio distortion. The image is cropped in\n+                the center with target aspect ratio before resizing.\n         \"\"\"\n         self.image_data_generator = image_data_generator\n         self.target_size = tuple(target_size)\n@@ -426,9 +426,8 @@ class BatchFromFilesMixin:\n     def filepaths(self):\n         \"\"\"List of absolute paths to image files.\"\"\"\n         raise NotImplementedError(\n-            \"`filepaths` property method has not been implemented in {}.\".format(\n-                type(self).__name__\n-            )\n+            \"`filepaths` property method has not \"\n+            \"been implemented in {}.\".format(type(self).__name__)\n         )\n \n     @property\n@@ -443,9 +442,8 @@ class BatchFromFilesMixin:\n     @property\n     def sample_weight(self):\n         raise NotImplementedError(\n-            \"`sample_weight` property method has not been implemented in {}.\".format(\n-                type(self).__name__\n-            )\n+            \"`sample_weight` property method has not \"\n+            \"been implemented in {}.\".format(type(self).__name__)\n         )\n \n \n@@ -465,10 +463,10 @@ class DirectoryIterator(BatchFromFilesMixin, Iterator):\n     https://www.tensorflow.org/guide/keras/preprocessing_layers).\n \n     Args:\n-        directory: Path to the directory to read images from. Each subdirectory in\n-          this directory will be considered to contain images from one class, or\n-          alternatively you could specify class subdirectories via the `classes`\n-          argument.\n+        directory: Path to the directory to read images from. Each subdirectory\n+          in this directory will be considered to contain images from one class,\n+          or alternatively you could specify class subdirectories via the\n+          `classes` argument.\n         image_data_generator: Instance of `ImageDataGenerator` to use for random\n           transformations and normalization.\n         target_size: tuple of integers, dimensions to resize input images to.\n@@ -481,16 +479,16 @@ class DirectoryIterator(BatchFromFilesMixin, Iterator):\n             - `\"binary\"`: binary targets (if there are only two classes),\n             - `\"categorical\"`: categorical targets,\n             - `\"sparse\"`: integer targets,\n-            - `\"input\"`: targets are images identical to input images (mainly used\n-              to work with autoencoders),\n+            - `\"input\"`: targets are images identical to input images (mainly\n+              used to work with autoencoders),\n             - `None`: no targets get yielded (only input images are yielded).\n         batch_size: Integer, size of a batch.\n         shuffle: Boolean, whether to shuffle the data between epochs.\n         seed: Random seed for data shuffling.\n         data_format: String, one of `channels_first`, `channels_last`.\n-        save_to_dir: Optional directory where to save the pictures being yielded,\n-          in a viewable format. This is useful for visualizing the random\n-          transformations being applied, for debugging purposes.\n+        save_to_dir: Optional directory where to save the pictures being\n+          yielded, in a viewable format. This is useful for visualizing the\n+          random transformations being applied, for debugging purposes.\n         save_prefix: String prefix to use for saving sample images (if\n           `save_to_dir` is set).\n         save_format: Format to use for saving sample images (if `save_to_dir` is\n@@ -500,9 +498,9 @@ class DirectoryIterator(BatchFromFilesMixin, Iterator):\n         interpolation: Interpolation method used to resample the image if the\n           target size is different from that of the loaded image. Supported\n           methods are \"nearest\", \"bilinear\", and \"bicubic\". If PIL version 1.1.3\n-          or newer is installed, \"lanczos\" is also supported. If PIL version 3.4.0\n-          or newer is installed, \"box\" and \"hamming\" are also supported. By\n-          default, \"nearest\" is used.\n+          or newer is installed, \"lanczos\" is also supported. If PIL version\n+          3.4.0 or newer is installed, \"box\" and \"hamming\" are also supported.\n+          By default, \"nearest\" is used.\n         keep_aspect_ratio: Boolean, whether to resize images to a target size\n             without aspect ratio distortion. The image is cropped in the center\n             with target aspect ratio before resizing.\n@@ -642,8 +640,8 @@ class NumpyArrayIterator(Iterator):\n \n     Args:\n         x: Numpy array of input data or tuple. If tuple, the second elements is\n-          either another numpy array or a list of numpy arrays, each of which gets\n-          passed through as an output without any modifications.\n+          either another numpy array or a list of numpy arrays, each of which\n+          gets passed through as an output without any modifications.\n         y: Numpy array of targets data.\n         image_data_generator: Instance of `ImageDataGenerator` to use for random\n           transformations and normalization.\n@@ -652,9 +650,9 @@ class NumpyArrayIterator(Iterator):\n         sample_weight: Numpy array of sample weights.\n         seed: Random seed for data shuffling.\n         data_format: String, one of `channels_first`, `channels_last`.\n-        save_to_dir: Optional directory where to save the pictures being yielded,\n-          in a viewable format. This is useful for visualizing the random\n-          transformations being applied, for debugging purposes.\n+        save_to_dir: Optional directory where to save the pictures being\n+          yielded, in a viewable format. This is useful for visualizing the\n+          random transformations being applied, for debugging purposes.\n         save_prefix: String prefix to use for saving sample images (if\n           `save_to_dir` is set).\n         save_format: Format to use for saving sample images (if `save_to_dir` is\n@@ -848,16 +846,17 @@ class DataFrameIterator(BatchFromFilesMixin, Iterator):\n \n     Args:\n         dataframe: Pandas dataframe containing the filepaths relative to\n-          `directory` (or absolute paths if `directory` is None) of the images in\n-          a string column. It should include other column/s depending on the\n+          `directory` (or absolute paths if `directory` is None) of the images\n+          in a string column. It should include other column/s depending on the\n           `class_mode`: - if `class_mode` is `\"categorical\"` (default value) it\n           must include the `y_col` column with the class/es of each image.\n           Values in column can be string/list/tuple if a single class or\n-            list/tuple if multiple classes. - if `class_mode` is `\"binary\"` or\n-            `\"sparse\"` it must include the given `y_col` column with class values\n-            as strings. - if `class_mode` is `\"raw\"` or `\"multi_output\"` it should\n-            contain the columns specified in `y_col`. - if `class_mode` is\n-            `\"input\"` or `None` no extra column is needed.\n+          list/tuple if multiple classes.\n+            - if `class_mode` is `\"binary\"` or `\"sparse\"` it must include the\n+              given `y_col` column with class values as strings.\n+            - if `class_mode` is `\"raw\"` or `\"multi_output\"` it should contain\n+              the columns specified in `y_col`.\n+            - if `class_mode` is `\"input\"` or `None` no extra column is needed.\n         directory: string, path to the directory to read images from. If `None`,\n           data in `x_col` column should be absolute paths.\n         image_data_generator: Instance of `ImageDataGenerator` to use for random\n@@ -877,8 +876,8 @@ class DataFrameIterator(BatchFromFilesMixin, Iterator):\n           \"raw\", \"sparse\" or None. Default: \"categorical\".\n           Mode for yielding the targets:\n             - `\"binary\"`: 1D numpy array of binary labels,\n-            - `\"categorical\"`: 2D numpy array of one-hot encoded labels. Supports\n-              multi-label output.\n+            - `\"categorical\"`: 2D numpy array of one-hot encoded labels.\n+              Supports multi-label output.\n             - `\"input\"`: images identical to input images (mainly used to work\n               with autoencoders),\n             - `\"multi_output\"`: list with the values of the different columns,\n@@ -890,9 +889,9 @@ class DataFrameIterator(BatchFromFilesMixin, Iterator):\n         shuffle: Boolean, whether to shuffle the data between epochs.\n         seed: Random seed for data shuffling.\n         data_format: String, one of `channels_first`, `channels_last`.\n-        save_to_dir: Optional directory where to save the pictures being yielded,\n-          in a viewable format. This is useful for visualizing the random\n-          transformations being applied, for debugging purposes.\n+        save_to_dir: Optional directory where to save the pictures being\n+          yielded, in a viewable format. This is useful for visualizing the\n+          random transformations being applied, for debugging purposes.\n         save_prefix: String prefix to use for saving sample images (if\n           `save_to_dir` is set).\n         save_format: Format to use for saving sample images (if `save_to_dir` is\n@@ -902,17 +901,17 @@ class DataFrameIterator(BatchFromFilesMixin, Iterator):\n         interpolation: Interpolation method used to resample the image if the\n           target size is different from that of the loaded image. Supported\n           methods are \"nearest\", \"bilinear\", and \"bicubic\". If PIL version 1.1.3\n-          or newer is installed, \"lanczos\" is also supported. If PIL version 3.4.0\n-          or newer is installed, \"box\" and \"hamming\" are also supported. By\n-          default, \"nearest\" is used.\n+          or newer is installed, \"lanczos\" is also supported. If PIL version\n+          3.4.0 or newer is installed, \"box\" and \"hamming\" are also supported.\n+          By default, \"nearest\" is used.\n         keep_aspect_ratio: Boolean, whether to resize images to a target size\n           without aspect ratio distortion. The image is cropped in the center\n           with target aspect ratio before resizing.\n         dtype: Dtype to use for the generated arrays.\n         validate_filenames: Boolean, whether to validate image filenames in\n           `x_col`. If `True`, invalid images will be ignored. Disabling this\n-          option can lead to speed-up in the instantiation of this class. Default:\n-          `True`.\n+          option can lead to speed-up in the instantiation of this class.\n+          Default: `True`.\n     \"\"\"\n \n     allowed_class_modes = {\n@@ -1017,7 +1016,8 @@ class DataFrameIterator(BatchFromFilesMixin, Iterator):\n                     self.class_mode, self.allowed_class_modes\n                 )\n             )\n-        # check that y_col has several column names if class_mode is multi_output\n+        # check that y_col has several column names if class_mode is\n+        # multi_output\n         if (self.class_mode == \"multi_output\") and not isinstance(y_col, list):\n             raise TypeError(\n                 'If class_mode=\"{}\", y_col must be a list. Received {}.'.format(\n@@ -1099,9 +1099,8 @@ class DataFrameIterator(BatchFromFilesMixin, Iterator):\n                 return labels if labels in classes else None\n             else:\n                 raise TypeError(\n-                    \"Expect string, list or tuple but found {} in {} column \".format(\n-                        type(labels), y_col\n-                    )\n+                    \"Expect string, list or tuple \"\n+                    \"but found {} in {} column \".format(type(labels), y_col)\n                 )\n \n         if classes:\n@@ -1123,7 +1122,8 @@ class DataFrameIterator(BatchFromFilesMixin, Iterator):\n \n         Args:\n             df: Pandas dataframe containing filenames in a column\n-            x_col: string, column in `df` that contains the filenames or filepaths\n+            x_col: string, column in `df` that contains the filenames or\n+                filepaths\n         Returns:\n             absolute paths to image files\n         \"\"\"\n@@ -1196,17 +1196,18 @@ class ImageDataGenerator:\n             - 1-D array-like: random elements from the array.\n             - int: integer number of pixels from interval `(-width_shift_range,\n               +width_shift_range)` - With `width_shift_range=2` possible values\n-              are integers `[-1, 0, +1]`, same as with `width_shift_range=[-1, 0,\n-              +1]`, while with `width_shift_range=1.0` possible values are floats\n-              in the interval [-1.0, +1.0).\n+              are integers `[-1, 0, +1]`, same as with `width_shift_range=[-1,\n+              0, +1]`, while with `width_shift_range=1.0` possible values are\n+              floats in the interval [-1.0, +1.0).\n         height_shift_range: Float, 1-D array-like or int\n             - float: fraction of total height, if < 1, or pixels if >= 1.\n             - 1-D array-like: random elements from the array.\n             - int: integer number of pixels from interval `(-height_shift_range,\n-              +height_shift_range)` - With `height_shift_range=2` possible values\n-              are integers `[-1, 0, +1]`, same as with `height_shift_range=[-1, 0,\n-              +1]`, while with `height_shift_range=1.0` possible values are floats\n-              in the interval [-1.0, +1.0).\n+              +height_shift_range)` - With `height_shift_range=2` possible\n+              values are integers `[-1, 0, +1]`, same as with\n+              `height_shift_range=[-1, 0, +1]`, while with\n+              `height_shift_range=1.0` possible values are floats in the\n+              interval [-1.0, +1.0).\n         brightness_range: Tuple or list of two floats. Range for picking a\n           brightness shift value from.\n         shear_range: Float. Shear Intensity (Shear angle in counter-clockwise\n@@ -1214,8 +1215,8 @@ class ImageDataGenerator:\n         zoom_range: Float or [lower, upper]. Range for random zoom. If a float,\n           `[lower, upper] = [1-zoom_range, 1+zoom_range]`.\n         channel_shift_range: Float. Range for random channel shifts.\n-        fill_mode: One of {\"constant\", \"nearest\", \"reflect\" or \"wrap\"}. Default is\n-          'nearest'. Points outside the boundaries of the input are filled\n+        fill_mode: One of {\"constant\", \"nearest\", \"reflect\" or \"wrap\"}. Default\n+          is 'nearest'. Points outside the boundaries of the input are filled\n           according to the given mode:\n             - 'constant': kkkkkkkk|abcd|kkkkkkkk (cval=k)\n             - 'nearest':  aaaaaaaa|abcd|dddddddd\n@@ -1225,20 +1226,20 @@ class ImageDataGenerator:\n           `fill_mode = \"constant\"`.\n         horizontal_flip: Boolean. Randomly flip inputs horizontally.\n         vertical_flip: Boolean. Randomly flip inputs vertically.\n-        rescale: rescaling factor. Defaults to None. If None or 0, no rescaling is\n-          applied, otherwise we multiply the data by the value provided (after\n-          applying all other transformations).\n+        rescale: rescaling factor. Defaults to None. If None or 0, no rescaling\n+          is applied, otherwise we multiply the data by the value provided\n+          (after applying all other transformations).\n         preprocessing_function: function that will be applied on each input. The\n           function will run after the image is resized and augmented.\n             The function should take one argument: one image (Numpy tensor with\n               rank 3), and should output a Numpy tensor with the same shape.\n         data_format: Image data format, either \"channels_first\" or\n-          \"channels_last\". \"channels_last\" mode means that the images should have\n-          shape `(samples, height, width, channels)`, \"channels_first\" mode means\n-          that the images should have shape `(samples, channels, height, width)`.\n-          It defaults to the `image_data_format` value found in your Keras config\n-          file at `~/.keras/keras.json`. If you never set it, then it will be\n-          \"channels_last\".\n+          \"channels_last\". \"channels_last\" mode means that the images should\n+          have shape `(samples, height, width, channels)`, \"channels_first\" mode\n+          means that the images should have shape `(samples, channels, height,\n+          width)`.  It defaults to the `image_data_format` value found in your\n+          Keras config file at `~/.keras/keras.json`. If you never set it, then\n+          it will be \"channels_last\".\n         validation_split: Float. Fraction of images reserved for validation\n           (strictly between 0 and 1).\n         dtype: Dtype to use for the generated arrays.\n@@ -1501,24 +1502,27 @@ class ImageDataGenerator:\n \n         Args:\n             x: Input data. Numpy array of rank 4 or a tuple. If tuple, the first\n-              element should contain the images and the second element another numpy\n-              array or a list of numpy arrays that gets passed to the output without\n-              any modifications. Can be used to feed the model miscellaneous data\n-              along with the images. In case of grayscale data, the channels axis of\n-              the image array should have value 1, in case of RGB data, it should\n-              have value 3, and in case of RGBA data, it should have value 4.\n+              element should contain the images and the second element another\n+              numpy array or a list of numpy arrays that gets passed to the\n+              output without any modifications. Can be used to feed the model\n+              miscellaneous data along with the images. In case of grayscale\n+              data, the channels axis of the image array should have value 1, in\n+              case of RGB data, it should have value 3, and in case of RGBA\n+              data, it should have value 4.\n             y: Labels.\n             batch_size: Int (default: 32).\n             shuffle: Boolean (default: True).\n             sample_weight: Sample weights.\n             seed: Int (default: None).\n-            save_to_dir: None or str (default: None). This allows you to optionally\n-              specify a directory to which to save the augmented pictures being\n-              generated (useful for visualizing what you are doing).\n-            save_prefix: Str (default: `''`). Prefix to use for filenames of saved\n-              pictures (only relevant if `save_to_dir` is set).\n-            save_format: one of \"png\", \"jpeg\", \"bmp\", \"pdf\", \"ppm\", \"gif\", \"tif\",\n-              \"jpg\" (only relevant if `save_to_dir` is set). Default: \"png\".\n+            save_to_dir: None or str (default: None). This allows you to\n+              optionally specify a directory to which to save the augmented\n+              pictures being generated (useful for visualizing what you are\n+              doing).\n+            save_prefix: Str (default: `''`). Prefix to use for filenames of\n+              saved pictures (only relevant if `save_to_dir` is set).\n+            save_format: one of \"png\", \"jpeg\", \"bmp\", \"pdf\", \"ppm\", \"gif\",\n+              \"tif\", \"jpg\" (only relevant if `save_to_dir` is set). Default:\n+              \"png\".\n             ignore_class_split: Boolean (default: False), ignore difference\n               in number of classes in labels across train and validation\n               split (useful for non-classification tasks)\n@@ -1577,19 +1581,19 @@ class ImageDataGenerator:\n         \"\"\"Takes the path to a directory & generates batches of augmented data.\n \n         Args:\n-            directory: string, path to the target directory. It should contain one\n-              subdirectory per class. Any PNG, JPG, BMP, PPM or TIF images inside\n-              each of the subdirectories directory tree will be included in the\n-              generator. See [this script](\n+            directory: string, path to the target directory. It should contain\n+              one subdirectory per class. Any PNG, JPG, BMP, PPM or TIF images\n+              inside each of the subdirectories directory tree will be included\n+              in the generator. See [this script](\n               https://gist.github.com/fchollet/0830affa1f7f19fd47b06d4cf89ed44d)\n               for more details.\n             target_size: Tuple of integers `(height, width)`, defaults to `(256,\n               256)`. The dimensions to which all images found will be resized.\n-            color_mode: One of \"grayscale\", \"rgb\", \"rgba\". Default: \"rgb\". Whether\n-              the images will be converted to have 1, 3, or 4 channels.\n-            classes: Optional list of class subdirectories\n-                (e.g. `['dogs', 'cats']`). Default: None. If not provided, the list\n-                  of classes will be automatically inferred from the subdirectory\n+            color_mode: One of \"grayscale\", \"rgb\", \"rgba\". Default: \"rgb\".\n+              Whether the images will be converted to have 1, 3, or 4 channels.\n+            classes: Optional list of class subdirectories (e.g. `['dogs',\n+              'cats']`). Default: None. If not provided, the list of classes\n+              will be automatically inferred from the subdirectory\n               names/structure under `directory`, where each subdirectory will be\n               treated as a different class (and the order of the classes, which\n               will map to the label indices, will be alphanumeric). The\n@@ -1610,27 +1614,28 @@ class ImageDataGenerator:\n                   the data still needs to reside in a subdirectory\n                   of `directory` for it to work correctly.\n             batch_size: Size of the batches of data (default: 32).\n-            shuffle: Whether to shuffle the data (default: True) If set to False,\n-              sorts the data in alphanumeric order.\n+            shuffle: Whether to shuffle the data (default: True) If set to\n+              False, sorts the data in alphanumeric order.\n             seed: Optional random seed for shuffling and transformations.\n-            save_to_dir: None or str (default: None). This allows you to optionally\n-              specify a directory to which to save the augmented pictures being\n-              generated (useful for visualizing what you are doing).\n-            save_prefix: Str. Prefix to use for filenames of saved pictures (only\n-              relevant if `save_to_dir` is set).\n-            save_format: one of \"png\", \"jpeg\", \"bmp\", \"pdf\", \"ppm\", \"gif\", \"tif\",\n-              \"jpg\"\n-                (only relevant if `save_to_dir` is set). Default: \"png\".\n+            save_to_dir: None or str (default: None). This allows you to\n+              optionally specify a directory to which to save the augmented\n+              pictures being generated (useful for visualizing what you are\n+              doing).\n+            save_prefix: Str. Prefix to use for filenames of saved pictures\n+              (only relevant if `save_to_dir` is set).\n+            save_format: one of \"png\", \"jpeg\", \"bmp\", \"pdf\", \"ppm\", \"gif\",\n+              \"tif\", \"jpg\" (only relevant if `save_to_dir` is set). Default:\n+              \"png\".\n             follow_links: Whether to follow symlinks inside\n                 class subdirectories (default: False).\n             subset: Subset of data (`\"training\"` or `\"validation\"`) if\n               `validation_split` is set in `ImageDataGenerator`.\n-            interpolation: Interpolation method used to resample the image if the\n-              target size is different from that of the loaded image. Supported\n-              methods are `\"nearest\"`, `\"bilinear\"`, and `\"bicubic\"`. If PIL version\n-              1.1.3 or newer is installed, `\"lanczos\"` is also supported. If PIL\n-              version 3.4.0 or newer is installed, `\"box\"` and `\"hamming\"` are also\n-              supported. By default, `\"nearest\"` is used.\n+            interpolation: Interpolation method used to resample the image if\n+              the target size is different from that of the loaded image.\n+              Supported methods are `\"nearest\"`, `\"bilinear\"`, and `\"bicubic\"`.\n+              If PIL version 1.1.3 or newer is installed, `\"lanczos\"` is also\n+              supported. If PIL version 3.4.0 or newer is installed, `\"box\"` and\n+              `\"hamming\"` are also supported. By default, `\"nearest\"` is used.\n             keep_aspect_ratio: Boolean, whether to resize images to a target\n               size without aspect ratio distortion. The image is cropped in\n               the center with target aspect ratio before resizing.\n@@ -1702,57 +1707,64 @@ class ImageDataGenerator:\n                     or list/tuple if multiple classes.\n                 - if `class_mode` is `\"binary\"` or `\"sparse\"` it must include\n                     the given `y_col` column with class values as strings.\n-                - if `class_mode` is `\"raw\"` or `\"multi_output\"` it should contain\n-                the columns specified in `y_col`.\n-                - if `class_mode` is `\"input\"` or `None` no extra column is needed.\n-            directory: string, path to the directory to read images from. If `None`,\n-              data in `x_col` column should be absolute paths.\n+                - if `class_mode` is `\"raw\"` or `\"multi_output\"` it should\n+                    contain the columns specified in `y_col`.\n+                - if `class_mode` is `\"input\"` or `None` no extra column is\n+                    needed.\n+            directory: string, path to the directory to read images from. If\n+              `None`, data in `x_col` column should be absolute paths.\n             x_col: string, column in `dataframe` that contains the filenames (or\n               absolute paths if `directory` is `None`).\n-            y_col: string or list, column/s in `dataframe` that has the target data.\n+            y_col: string or list, column/s in `dataframe` that has the target\n+              data.\n             weight_col: string, column in `dataframe` that contains the sample\n                 weights. Default: `None`.\n-            target_size: tuple of integers `(height, width)`, default: `(256, 256)`.\n-              The dimensions to which all images found will be resized.\n-            color_mode: one of \"grayscale\", \"rgb\", \"rgba\". Default: \"rgb\". Whether\n-              the images will be converted to have 1 or 3 color channels.\n-            classes: optional list of classes (e.g. `['dogs', 'cats']`). Default is\n-              None. If not provided, the list of classes will be automatically\n-              inferred from the `y_col`, which will map to the label indices, will\n-              be alphanumeric). The dictionary containing the mapping from class\n-              names to class indices can be obtained via the attribute\n-              `class_indices`.\n+            target_size: tuple of integers `(height, width)`, default: `(256,\n+              256)`. The dimensions to which all images found will be resized.\n+            color_mode: one of \"grayscale\", \"rgb\", \"rgba\". Default: \"rgb\".\n+              Whether the images will be converted to have 1 or 3 color\n+              channels.\n+            classes: optional list of classes (e.g. `['dogs', 'cats']`). Default\n+              is None. If not provided, the list of classes will be\n+              automatically inferred from the `y_col`, which will map to the\n+              label indices, will be alphanumeric). The dictionary containing\n+              the mapping from class names to class indices can be obtained via\n+              the attribute `class_indices`.\n             class_mode: one of \"binary\", \"categorical\", \"input\", \"multi_output\",\n                 \"raw\", sparse\" or None. Default: \"categorical\".\n                 Mode for yielding the targets:\n                 - `\"binary\"`: 1D numpy array of binary labels,\n                 - `\"categorical\"`: 2D numpy array of one-hot encoded labels.\n                   Supports multi-label output.\n-                - `\"input\"`: images identical to input images (mainly used to work\n-                  with autoencoders),\n-                - `\"multi_output\"`: list with the values of the different columns,\n+                - `\"input\"`: images identical to input images (mainly used to\n+                  work with autoencoders),\n+                - `\"multi_output\"`: list with the values of the different\n+                  columns,\n                 - `\"raw\"`: numpy array of values in `y_col` column(s),\n-                - `\"sparse\"`: 1D numpy array of integer labels, - `None`, no targets\n-                  are returned (the generator will only yield batches of image data,\n-                  which is useful to use in `model.predict()`).\n+                - `\"sparse\"`: 1D numpy array of integer labels,\n+                - `None`, no targets are returned (the generator will only yield\n+                  batches of image data, which is useful to use in\n+                  `model.predict()`).\n             batch_size: size of the batches of data (default: 32).\n             shuffle: whether to shuffle the data (default: True)\n             seed: optional random seed for shuffling and transformations.\n-            save_to_dir: None or str (default: None). This allows you to optionally\n-              specify a directory to which to save the augmented pictures being\n-              generated (useful for visualizing what you are doing).\n-            save_prefix: str. Prefix to use for filenames of saved pictures (only\n-              relevant if `save_to_dir` is set).\n-            save_format: one of \"png\", \"jpeg\", \"bmp\", \"pdf\", \"ppm\", \"gif\", \"tif\",\n-              \"jpg\" (only relevant if `save_to_dir` is set). Default: \"png\".\n+            save_to_dir: None or str (default: None). This allows you to\n+              optionally specify a directory to which to save the augmented\n+              pictures being generated (useful for visualizing what you are\n+              doing).\n+            save_prefix: str. Prefix to use for filenames of saved pictures\n+              (only relevant if `save_to_dir` is set).\n+            save_format: one of \"png\", \"jpeg\", \"bmp\", \"pdf\", \"ppm\", \"gif\",\n+              \"tif\", \"jpg\" (only relevant if `save_to_dir` is set). Default:\n+              \"png\".\n             subset: Subset of data (`\"training\"` or `\"validation\"`) if\n               `validation_split` is set in `ImageDataGenerator`.\n-            interpolation: Interpolation method used to resample the image if the\n-              target size is different from that of the loaded image. Supported\n-              methods are `\"nearest\"`, `\"bilinear\"`, and `\"bicubic\"`. If PIL version\n-              1.1.3 or newer is installed, `\"lanczos\"` is also supported. If PIL\n-              version 3.4.0 or newer is installed, `\"box\"` and `\"hamming\"` are also\n-              supported. By default, `\"nearest\"` is used.\n+            interpolation: Interpolation method used to resample the image if\n+              the target size is different from that of the loaded image.\n+              Supported methods are `\"nearest\"`, `\"bilinear\"`, and `\"bicubic\"`.\n+              If PIL version 1.1.3 or newer is installed, `\"lanczos\"` is also\n+              supported. If PIL version 3.4.0 or newer is installed, `\"box\"` and\n+              `\"hamming\"` are also supported. By default, `\"nearest\"` is used.\n             validate_filenames: Boolean, whether to validate image filenames in\n               `x_col`. If `True`, invalid images will be ignored. Disabling this\n               option can lead to speed-up in the execution of this function.\n@@ -1817,7 +1829,8 @@ class ImageDataGenerator:\n         )\n \n     def standardize(self, x):\n-        \"\"\"Applies the normalization configuration in-place to a batch of inputs.\n+        \"\"\"Applies the normalization configuration in-place to a batch of\n+        inputs.\n \n         `x` is changed in-place since the function is mainly used internally\n         to standardize images and feed them to your network. If a copy of `x`\n@@ -2147,10 +2160,10 @@ def random_rotation(\n ):\n     \"\"\"Performs a random rotation of a Numpy image tensor.\n \n-    Deprecated: `tf.keras.preprocessing.image.random_rotation` does not operate on\n-    tensors and is not recommended for new code. Prefer\n-    `tf.keras.layers.RandomRotation` which provides equivalent functionality as a\n-    preprocessing layer. For more information, see the tutorial for\n+    Deprecated: `tf.keras.preprocessing.image.random_rotation` does not operate\n+    on tensors and is not recommended for new code. Prefer\n+    `tf.keras.layers.RandomRotation` which provides equivalent functionality as\n+    a preprocessing layer. For more information, see the tutorial for\n     [augmenting images](\n     https://www.tensorflow.org/tutorials/images/data_augmentation), as well as\n     the [preprocessing layer guide](\n@@ -2203,8 +2216,8 @@ def random_shift(\n \n     Deprecated: `tf.keras.preprocessing.image.random_shift` does not operate on\n     tensors and is not recommended for new code. Prefer\n-    `tf.keras.layers.RandomTranslation` which provides equivalent functionality as\n-    a preprocessing layer. For more information, see the tutorial for\n+    `tf.keras.layers.RandomTranslation` which provides equivalent functionality\n+    as a preprocessing layer. For more information, see the tutorial for\n     [augmenting images](\n     https://www.tensorflow.org/tutorials/images/data_augmentation), as well as\n     the [preprocessing layer guide](\n@@ -2428,10 +2441,10 @@ def apply_brightness_shift(x, brightness, scale=True):\n def random_brightness(x, brightness_range, scale=True):\n     \"\"\"Performs a random brightness shift.\n \n-    Deprecated: `tf.keras.preprocessing.image.random_brightness` does not operate\n-    on tensors and is not recommended for new code. Prefer\n-    `tf.keras.layers.RandomBrightness` which provides equivalent functionality as\n-    a preprocessing layer. For more information, see the tutorial for\n+    Deprecated: `tf.keras.preprocessing.image.random_brightness` does not\n+    operate on tensors and is not recommended for new code. Prefer\n+    `tf.keras.layers.RandomBrightness` which provides equivalent functionality\n+    as a preprocessing layer. For more information, see the tutorial for\n     [augmenting images](\n     https://www.tensorflow.org/tutorials/images/data_augmentation), as well as\n     the [preprocessing layer guide](\n@@ -2599,7 +2612,7 @@ def apply_affine_transform(\n         final_offset = transform_matrix[:2, 2]\n \n         channel_images = [\n-            ndimage.interpolation.affine_transform(  # pylint: disable=g-complex-comprehension\n+            ndimage.interpolation.affine_transform(\n                 x_channel,\n                 final_affine_matrix,\n                 final_offset,\n\n@@ -1648,7 +1648,8 @@ class TestImageDataGenerator(test_combinations.TestCase):\n             # number of classes, because labels are sorted\n             with self.assertRaisesRegex(\n                 ValueError,\n-                \"Training and validation subsets have different number of classes\",\n+                \"Training and validation subsets have \"\n+                \"different number of classes\",\n             ):\n                 generator.flow(\n                     images,\n\n@@ -182,7 +182,8 @@ class TestSequence(tf.test.TestCase):\n             self.assertEqual(expected, actual)\n \n             if len(g) > 0:  # pylint: disable=g-explicit-length-test\n-                # All elements in range(length, 10) should be used as current step\n+                # All elements in range(length, 10) should be used as current\n+                # step\n                 expected = np.arange(length, 10).reshape(-1, 1)\n \n                 y = np.concatenate([g[ix][1] for ix in range(len(g))], axis=0)\n\n@@ -92,12 +92,13 @@ def one_hot(\n ):\n     r\"\"\"One-hot encodes a text into a list of word indexes of size `n`.\n \n-    Deprecated: `tf.keras.text.preprocessing.one_hot` does not operate on tensors\n-    and is not recommended for new code. Prefer `tf.keras.layers.Hashing` with\n-    `output_mode='one_hot'` which provides equivalent functionality through a\n-    layer which accepts `tf.Tensor` input. See the [preprocessing layer guide]\n-    (https://www.tensorflow.org/guide/keras/preprocessing_layers)\n-    for an overview of preprocessing layers.\n+    Deprecated: `tf.keras.text.preprocessing.one_hot` does not operate on\n+    tensors and is not recommended for new code. Prefer\n+    `tf.keras.layers.Hashing` with `output_mode='one_hot'` which provides\n+    equivalent functionality through a layer which accepts `tf.Tensor` input.\n+    See the [preprocessing layer guide]\n+    (https://www.tensorflow.org/guide/keras/preprocessing_layers) for an\n+    overview of preprocessing layers.\n \n     This function receives as input a string of text and returns a\n     list of encoded integers each corresponding to a word (or token)\n@@ -144,11 +145,11 @@ def hashing_trick(\n     r\"\"\"Converts a text to a sequence of indexes in a fixed-size hashing space.\n \n     Deprecated: `tf.keras.text.preprocessing.hashing_trick` does not operate on\n-    tensors and is not recommended for new code. Prefer `tf.keras.layers.Hashing`\n-    which provides equivalent functionality through a layer which accepts\n-    `tf.Tensor` input. See the [preprocessing layer guide]\n-    (https://www.tensorflow.org/guide/keras/preprocessing_layers)\n-    for an overview of preprocessing layers.\n+    tensors and is not recommended for new code. Prefer\n+    `tf.keras.layers.Hashing` which provides equivalent functionality through a\n+    layer which accepts `tf.Tensor` input. See the [preprocessing layer guide](\n+    https://www.tensorflow.org/guide/keras/preprocessing_layers) for an\n+    overview of preprocessing layers.\n \n     Args:\n         text: Input text (string).\n\n@@ -90,9 +90,11 @@ class TestText(tf.test.TestCase):\n \n     def test_tokenizer_serde_fitting(self):\n         sample_texts = [\n-            \"There was a time that the pieces fit, but I watched them fall away\",\n+            \"There was a time that the pieces fit, but I watched \"\n+            \"them fall away\",\n             \"Mildewed and smoldering, strangled by our coveting\",\n-            \"I've done the math enough to know the dangers of our second guessing\",\n+            \"I've done the math enough to know the dangers of our second \"\n+            \"guessing\",\n         ]\n         tokenizer = text.Tokenizer(num_words=100)\n         tokenizer.fit_on_texts(sample_texts)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
