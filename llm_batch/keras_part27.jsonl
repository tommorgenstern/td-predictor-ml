{"custom_id": "keras#896880f84dcf6615fe33123dd1e6fe24bc1a7896", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 45 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 45 | Churn Cumulative: 45 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -0,0 +1,45 @@\n+from __future__ import absolute_import\n+from __future__ import print_function\n+from keras.models import Sequential, Graph\n+from keras.layers.core import Layer, Activation, Dense, Flatten, Reshape, Merge\n+from keras.layers.convolutional import Convolution2D, MaxPooling2D\n+import keras.utils.model_utils as model_utils\n+\n+print('-- Sequential model')\n+left = Sequential()\n+left.add(Convolution2D(32, 1, 3, 3, border_mode='valid'))\n+left.add(MaxPooling2D(poolsize=(2, 2)))\n+left.add(Flatten())\n+left.add(Dense(32 * 13 * 13, 50))\n+left.add(Activation('relu'))\n+\n+right = Sequential()\n+right.add(Dense(784, 30))\n+right.add(Activation('relu'))\n+\n+model = Sequential()\n+model.add(Merge([left, right], mode='concat'))\n+\n+model.add(Dense(80, 10))\n+model.add(Activation('softmax'))\n+\n+model_utils.print_model_layer_shapes(model, [(1, 1, 28, 28), (1, 784)])\n+\n+print('-- Graph model')\n+graph = Graph()\n+graph.add_input(name='input1', ndim=2)\n+graph.add_input(name='input2', ndim=4)\n+graph.add_node(Dense(32, 16), name='dense1', input='input1')\n+graph.add_node(Dense(16, 4), name='dense3', input='dense1')\n+\n+graph.add_node(Convolution2D(32, 1, 3, 3), name='conv1', input='input2')\n+graph.add_node(Flatten(), name='flatten1', input='conv1')\n+graph.add_node(Dense(32 * 13 * 13, 10), name='dense4', input='flatten1')\n+\n+graph.add_output(name='output1', inputs=['dense1', 'dense3'], merge_mode='sum')\n+graph.add_output(name='output2', inputs=['dense1', 'dense4'], merge_mode='concat')\n+\n+model_utils.print_graph_layer_shapes(graph,\n+    {'input1':(1, 32), 'input2':(1, 1, 28, 28)})\n+\n+print('Test script complete')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#570c37762304b37a73801dee9460ee0f664cfdd8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 73 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -32,7 +32,7 @@ def text_to_word_sequence(text, filters=base_filter(), lower=True, split=\" \"):\n \n \n def one_hot(text, n, filters=base_filter(), lower=True, split=\" \"):\n-    seq = text_to_word_sequence(text)\n+    seq = text_to_word_sequence(text, filters=filters, lower=lower, split=split)\n     return [(abs(hash(w))%(n-1)+1) for w in seq]\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#347e6d01ffa324b6a2c548c171eaae1569cbb6ea", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 40 | Lines Deleted: 28 | Files Changed: 1 | Hunks: 22 | Methods Changed: 9 | Complexity Δ (Sum/Max): 5/5 | Churn Δ: 68 | Churn Cumulative: 558 | Contributors (this commit): 7 | Commits (past 90d): 17 | Contributors (cumulative): 7 | DMM Complexity: 1.0\n\nDIFF:\n@@ -3,7 +3,7 @@ import theano\n import theano.tensor as T\n import numpy as np\n \n-from .utils.theano_utils import shared_zeros, shared_scalar\n+from .utils.theano_utils import shared_zeros, shared_scalar, floatX\n from six.moves import zip\n \n \n@@ -18,6 +18,18 @@ def kl_divergence(p, p_hat):\n \n \n class Optimizer(object):\n+    def __init__(self, **kwargs):\n+        self.__dict__.update(kwargs)\n+        self.update = []\n+\n+    def get_state(self):\n+        return [u[0].get_value() for u in self.update]\n+\n+    def set_state(self, value_list):\n+        assert len(self.update) == len(value_list)\n+        for u, v in zip(self.update, value_list):\n+            u[0].set_value(floatX(v))\n+\n     def get_updates(self, params, constraints, loss):\n         raise NotImplementedError\n \n@@ -38,27 +50,27 @@ class Optimizer(object):\n class SGD(Optimizer):\n \n     def __init__(self, lr=0.01, momentum=0., decay=0., nesterov=False, *args, **kwargs):\n-        self.__dict__.update(kwargs)\n+        super(SGD, self).__init__(**kwargs)\n         self.__dict__.update(locals())\n         self.iterations = shared_scalar(0)\n \n     def get_updates(self, params, constraints, loss):\n         grads = self.get_gradients(loss, params)\n         lr = self.lr * (1.0 / (1.0 + self.decay * self.iterations))\n-        updates = [(self.iterations, self.iterations + 1.)]\n+        self.updates = [(self.iterations, self.iterations + 1.)]\n \n         for p, g, c in zip(params, grads, constraints):\n             m = shared_zeros(p.get_value().shape) # momentum\n             v = self.momentum * m - lr * g # velocity\n-            updates.append((m, v))\n+            self.updates.append((m, v))\n \n             if self.nesterov:\n                 new_p = p + self.momentum * v - lr * g\n             else:\n                 new_p = p + v\n \n-            updates.append((p, c(new_p))) # apply constraints\n-        return updates\n+            self.updates.append((p, c(new_p))) # apply constraints\n+        return self.updates\n \n     def get_config(self):\n         return {\"name\": self.__class__.__name__,\n@@ -70,21 +82,21 @@ class SGD(Optimizer):\n \n class RMSprop(Optimizer):\n     def __init__(self, lr=0.001, rho=0.9, epsilon=1e-6, *args, **kwargs):\n-        self.__dict__.update(kwargs)\n+        super(RMSprop, self).__init__(**kwargs)\n         self.__dict__.update(locals())\n \n     def get_updates(self, params, constraints, loss):\n         grads = self.get_gradients(loss, params)\n         accumulators = [shared_zeros(p.get_value().shape) for p in params]\n-        updates = []\n+        self.updates = []\n \n         for p, g, a, c in zip(params, grads, accumulators, constraints):\n             new_a = self.rho * a + (1 - self.rho) * g ** 2 # update accumulator\n-            updates.append((a, new_a))\n+            self.updates.append((a, new_a))\n \n             new_p = p - self.lr * g / T.sqrt(new_a + self.epsilon)\n-            updates.append((p, c(new_p))) # apply constraints\n-        return updates\n+            self.updates.append((p, c(new_p))) # apply constraints\n+        return self.updates\n \n     def get_config(self):\n         return {\"name\": self.__class__.__name__,\n@@ -95,20 +107,20 @@ class RMSprop(Optimizer):\n \n class Adagrad(Optimizer):\n     def __init__(self, lr=0.01, epsilon=1e-6, *args, **kwargs):\n-        self.__dict__.update(kwargs)\n+        super(Adagrad, self).__init__(**kwargs)\n         self.__dict__.update(locals())\n \n     def get_updates(self, params, constraints, loss):\n         grads = self.get_gradients(loss, params)\n         accumulators = [shared_zeros(p.get_value().shape) for p in params]\n-        updates = []\n+        self.updates = []\n \n         for p, g, a, c in zip(params, grads, accumulators, constraints):\n             new_a = a + g ** 2 # update accumulator\n-            updates.append((a, new_a))\n+            self.updates.append((a, new_a))\n             new_p = p - self.lr * g / T.sqrt(new_a + self.epsilon)\n-            updates.append((p, c(new_p))) # apply constraints\n-        return updates\n+            self.updates.append((p, c(new_p))) # apply constraints\n+        return self.updates\n \n     def get_config(self):\n         return {\"name\": self.__class__.__name__,\n@@ -121,29 +133,29 @@ class Adadelta(Optimizer):\n         Reference: http://arxiv.org/abs/1212.5701\n     '''\n     def __init__(self, lr=1.0, rho=0.95, epsilon=1e-6, *args, **kwargs):\n-        self.__dict__.update(kwargs)\n+        super(Adadelta, self).__init__(**kwargs)\n         self.__dict__.update(locals())\n \n     def get_updates(self, params, constraints, loss):\n         grads = self.get_gradients(loss, params)\n         accumulators = [shared_zeros(p.get_value().shape) for p in params]\n         delta_accumulators = [shared_zeros(p.get_value().shape) for p in params]\n-        updates = []\n+        self.updates = []\n \n         for p, g, a, d_a, c in zip(params, grads, accumulators, delta_accumulators, constraints):\n             new_a = self.rho * a + (1 - self.rho) * g ** 2 # update accumulator\n-            updates.append((a, new_a))\n+            self.updates.append((a, new_a))\n \n             # use the new accumulator and the *old* delta_accumulator\n             update = g * T.sqrt(d_a + self.epsilon) / T.sqrt(new_a + self.epsilon)\n \n             new_p = p - self.lr * update\n-            updates.append((p, c(new_p))) # apply constraints\n+            self.updates.append((p, c(new_p))) # apply constraints\n \n             # update delta_accumulator\n             new_d_a = self.rho * d_a + (1 - self.rho) * update ** 2\n-            updates.append((d_a, new_d_a))\n-        return updates\n+            self.updates.append((d_a, new_d_a))\n+        return self.updates\n \n     def get_config(self):\n         return {\"name\": self.__class__.__name__,\n@@ -161,13 +173,13 @@ class Adam(Optimizer):\n         lambda is renamed kappa.\n     '''\n     def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, kappa=1-1e-8, *args, **kwargs):\n-        self.__dict__.update(kwargs)\n+        super(Adam, self).__init__(**kwargs)\n         self.__dict__.update(locals())\n         self.iterations = shared_scalar(0)\n \n     def get_updates(self, params, constraints, loss):\n         grads = self.get_gradients(loss, params)\n-        updates = [(self.iterations, self.iterations+1.)]\n+        self.updates = [(self.iterations, self.iterations+1.)]\n \n         i = self.iterations\n         beta_1_t = self.beta_1 * (self.kappa**i)\n@@ -187,10 +199,10 @@ class Adam(Optimizer):\n \n             p_t = p - self.lr * m_b_t / (T.sqrt(v_b_t) + self.epsilon)\n \n-            updates.append((m, m_t))\n-            updates.append((v, v_t))\n-            updates.append((p, c(p_t))) # apply constraints\n-        return updates\n+            self.updates.append((m, m_t))\n+            self.updates.append((v, v_t))\n+            self.updates.append((p, c(p_t))) # apply constraints\n+        return self.updates\n \n     def get_config(self):\n         return {\"name\": self.__class__.__name__,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e975f8a691f76a87e3f00dacfa8235cac7282660", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 9 | Files Changed: 2 | Hunks: 2 | Methods Changed: 3 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 10 | Churn Cumulative: 2647 | Contributors (this commit): 20 | Commits (past 90d): 93 | Contributors (cumulative): 21 | DMM Complexity: 0.0\n\nDIFF:\n@@ -359,14 +359,6 @@ class Sequential(Model, containers.Sequential):\n         self._test_with_acc = theano.function(test_ins, [test_loss, test_accuracy],\n             allow_input_downcast=True, mode=theano_mode)\n \n-    def train(self, X, y, accuracy=False, class_weight=None, sample_weight=None):\n-        warnings.warn('The \"train\" method is deprecated, use \"train_on_batch\" instead.')\n-        return self.train_on_batch(X, y, accuracy, class_weight, sample_weight)\n-\n-    def test(self, X, y, accuracy=False):\n-        warnings.warn('The \"test\" method is deprecated, use \"test_on_batch\" instead.')\n-        return self.test_on_batch(X, y, accuracy)\n-\n     def train_on_batch(self, X, y, accuracy=False, class_weight=None, sample_weight=None):\n         X = standardize_X(X)\n         y = standardize_y(y)\n\n@@ -86,7 +86,7 @@ class TestRegularizers(unittest.TestCase):\n         model.add(GRU(X_train.shape[-1], y_train.shape[-1]))\n         model.compile(loss='hinge', optimizer='adam')\n         history = model.fit(X_train, y_train, nb_epoch=12, batch_size=16, validation_data=(X_test, y_test), verbose=2)\n-        self.assertTrue(history.history['val_loss'][-1] < 0.75)\n+        self.assertTrue(history.history['val_loss'][-1] < 0.8)\n \n     def test_seq_to_seq(self):\n         print('sequence to sequence data:')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3a28da9e54ba8bb5b2aee2266c9bca3b0a975ca7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 28 | Lines Deleted: 51 | Files Changed: 2 | Hunks: 9 | Methods Changed: 3 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 79 | Churn Cumulative: 199 | Contributors (this commit): 2 | Commits (past 90d): 6 | Contributors (cumulative): 4 | DMM Complexity: 0.0\n\nDIFF:\n@@ -2,62 +2,39 @@ from __future__ import print_function\n import numpy as np\n import theano\n \n-def print_graph_layer_shapes(graph, input_shapes):\n+\n+def print_layer_shapes(model, input_shapes):\n     \"\"\"\n-    Utility function to print the shape of the output at each layer of a Graph\n+    Utility function to print the shape of the output at each layer of a Model\n \n     Arguments:\n-        graph: An instance of models.Graph\n-        input_shapes: A dict that gives a shape for each input to the Graph\n+        model: instance of Model / Merge\n+        input_shapes: dict (Graph), list of tuples (Merge) or tuple (Sequential)\n     \"\"\"\n-    input_vars = [graph.inputs[name].input\n-                  for name in graph.input_order]\n-    output_vars = [graph.outputs[name].get_output()\n-                   for name in graph.output_order]\n-    input_dummy = [np.zeros(input_shapes[name], dtype=np.float32)\n-                   for name in graph.input_order]\n-\n-    print(\"input shapes : \", input_shapes)\n-    for name, l in graph.nodes.items():\n-        shape_f = theano.function(input_vars,\n-                                  l.get_output(train=False).shape,\n-                                  on_unused_input='ignore')\n-        out_shape = shape_f(*input_dummy)\n-        print('shape after', l.get_config()['name'], \"(\", name, \") :\", out_shape)\n-\n-def print_model_layer_shapes(model, input_shapes):\n-    \"\"\"\n-    Utility function that prints the shape of the output at each layer.\n-\n-    Arguments:\n-        model: An instance of models.Model\n-        input_shape: The shape of the input you will provide to the model.\n-                     Either a tuple (for a single input) or a list of tuple\n-    \"\"\"\n-    # This is to handle the case where a model has been connected to a previous\n-    # layer (and therefore get_input would recurse into previous layer's\n-    # output).\n-    if hasattr(model.layers[0], 'previous'):\n-        # TODO: If the model is used as a part of another model, get_input will\n-        # return the input of the whole model and this won't work. So this is\n-        # not handled yet\n-        raise Exception(\"This function doesn't work on model used as subparts \"\n-                        \" for other models\")\n-\n-    # We allow the shortcut input_shapes=(1, 1, 28) instead of\n-    # input_shapes=[(1, 1, 28)].\n+    if model.__class__.__name__ in ['Sequential', 'Merge']:\n+        # in this case input_shapes is a tuple, or a list [shape1, shape2]\n         if not isinstance(input_shapes[0], tuple):\n             input_shapes = [input_shapes]\n-    input_vars = model.get_input(train=False)\n-    # theano.function excepts a list of variables\n-    if not isinstance(input_vars, list):\n-        input_vars = [input_vars]\n+\n+        inputs = model.get_input(train=False)\n+        if not isinstance(inputs, list):\n+            inputs = [inputs]\n         input_dummy = [np.zeros(shape, dtype=np.float32)\n                        for shape in input_shapes]\n+        layers = model.layers\n+\n+    elif model.__class__.__name__ == 'Graph':\n+        # in this case input_shapes is a dictionary\n+        inputs = [model.inputs[name].input\n+                  for name in model.input_order]\n+        input_dummy = [np.zeros(input_shapes[name], dtype=np.float32)\n+                       for name in model.input_order]\n+        layers = [model.nodes[c['name']] for c in model.node_config]\n \n     print(\"input shapes : \", input_shapes)\n-    for l in model.layers:\n-        shape_f = theano.function(input_vars,\n-                                  l.get_output(train=False).shape)\n-        out_shape = shape_f(*input_dummy)\n-        print('shape after', l.get_config()['name'], \":\", out_shape)\n+    for l in layers:\n+        shape_f = theano.function(inputs, l.get_output(train=False).shape,\n+                                  on_unused_input='ignore')\n+        out_shape = tuple(shape_f(*input_dummy))\n+        config = l.get_config()\n+        print('shape after %s: %s' % (config['name'], out_shape))\n\n@@ -23,7 +23,7 @@ model.add(Merge([left, right], mode='concat'))\n model.add(Dense(80, 10))\n model.add(Activation('softmax'))\n \n-model_utils.print_model_layer_shapes(model, [(1, 1, 28, 28), (1, 784)])\n+model_utils.print_layer_shapes(model, [(1, 1, 28, 28), (1, 784)])\n \n print('-- Graph model')\n graph = Graph()\n@@ -39,7 +39,7 @@ graph.add_node(Dense(32 * 13 * 13, 10), name='dense4', input='flatten1')\n graph.add_output(name='output1', inputs=['dense1', 'dense3'], merge_mode='sum')\n graph.add_output(name='output2', inputs=['dense1', 'dense4'], merge_mode='concat')\n \n-model_utils.print_graph_layer_shapes(graph,\n+model_utils.print_layer_shapes(graph,\n     {'input1':(1, 32), 'input2':(1, 1, 28, 28)})\n \n print('Test script complete')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d1387c1e871e726e6b75050f39809fd54fdacb81", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 42 | Lines Deleted: 44 | Files Changed: 3 | Hunks: 7 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/10 | Churn Δ: 86 | Churn Cumulative: 413 | Contributors (this commit): 3 | Commits (past 90d): 13 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -1,5 +1,7 @@\n+from __future__ import print_function\n import inspect\n import numpy as np\n+import theano\n \n from ..layers.advanced_activations import LeakyReLU, PReLU\n from ..layers.core import Dense, Merge, Dropout, Activation, Reshape, Flatten, RepeatVector, Layer\n@@ -83,6 +85,43 @@ def container_from_config(layer_dict):\n         return base_layer\n \n \n+def print_layer_shapes(model, input_shapes):\n+    \"\"\"\n+    Utility function to print the shape of the output at each layer of a Model\n+\n+    Arguments:\n+        model: instance of Model / Merge\n+        input_shapes: dict (Graph), list of tuples (Merge) or tuple (Sequential)\n+    \"\"\"\n+    if model.__class__.__name__ in ['Sequential', 'Merge']:\n+        # in this case input_shapes is a tuple, or a list [shape1, shape2]\n+        if not isinstance(input_shapes[0], tuple):\n+            input_shapes = [input_shapes]\n+\n+        inputs = model.get_input(train=False)\n+        if not isinstance(inputs, list):\n+            inputs = [inputs]\n+        input_dummy = [np.zeros(shape, dtype=np.float32)\n+                       for shape in input_shapes]\n+        layers = model.layers\n+\n+    elif model.__class__.__name__ == 'Graph':\n+        # in this case input_shapes is a dictionary\n+        inputs = [model.inputs[name].input\n+                  for name in model.input_order]\n+        input_dummy = [np.zeros(input_shapes[name], dtype=np.float32)\n+                       for name in model.input_order]\n+        layers = [model.nodes[c['name']] for c in model.node_config]\n+\n+    print(\"input shapes : \", input_shapes)\n+    for l in layers:\n+        shape_f = theano.function(inputs, l.get_output(train=False).shape,\n+                                  on_unused_input='ignore')\n+        out_shape = tuple(shape_f(*input_dummy))\n+        config = l.get_config()\n+        print('shape after %s: %s' % (config['name'], out_shape))\n+\n+\n from .generic_utils import get_from_module\n def get_layer(identifier, kwargs=None):\n     return get_from_module(identifier, globals(), 'layer', instantiate=True, kwargs=kwargs)\n\n@@ -1,40 +0,0 @@\n-from __future__ import print_function\n-import numpy as np\n-import theano\n-\n-\n-def print_layer_shapes(model, input_shapes):\n-    \"\"\"\n-    Utility function to print the shape of the output at each layer of a Model\n-\n-    Arguments:\n-        model: instance of Model / Merge\n-        input_shapes: dict (Graph), list of tuples (Merge) or tuple (Sequential)\n-    \"\"\"\n-    if model.__class__.__name__ in ['Sequential', 'Merge']:\n-        # in this case input_shapes is a tuple, or a list [shape1, shape2]\n-        if not isinstance(input_shapes[0], tuple):\n-            input_shapes = [input_shapes]\n-\n-        inputs = model.get_input(train=False)\n-        if not isinstance(inputs, list):\n-            inputs = [inputs]\n-        input_dummy = [np.zeros(shape, dtype=np.float32)\n-                       for shape in input_shapes]\n-        layers = model.layers\n-\n-    elif model.__class__.__name__ == 'Graph':\n-        # in this case input_shapes is a dictionary\n-        inputs = [model.inputs[name].input\n-                  for name in model.input_order]\n-        input_dummy = [np.zeros(input_shapes[name], dtype=np.float32)\n-                       for name in model.input_order]\n-        layers = [model.nodes[c['name']] for c in model.node_config]\n-\n-    print(\"input shapes : \", input_shapes)\n-    for l in layers:\n-        shape_f = theano.function(inputs, l.get_output(train=False).shape,\n-                                  on_unused_input='ignore')\n-        out_shape = tuple(shape_f(*input_dummy))\n-        config = l.get_config()\n-        print('shape after %s: %s' % (config['name'], out_shape))\n\n@@ -3,7 +3,7 @@ from __future__ import print_function\n from keras.models import Sequential, Graph\n from keras.layers.core import Layer, Activation, Dense, Flatten, Reshape, Merge\n from keras.layers.convolutional import Convolution2D, MaxPooling2D\n-import keras.utils.model_utils as model_utils\n+import keras.utils.layer_utils as layer_utils\n \n print('-- Sequential model')\n left = Sequential()\n@@ -23,7 +23,7 @@ model.add(Merge([left, right], mode='concat'))\n model.add(Dense(80, 10))\n model.add(Activation('softmax'))\n \n-model_utils.print_layer_shapes(model, [(1, 1, 28, 28), (1, 784)])\n+layer_utils.print_layer_shapes(model, [(1, 1, 28, 28), (1, 784)])\n \n print('-- Graph model')\n graph = Graph()\n@@ -39,7 +39,6 @@ graph.add_node(Dense(32 * 13 * 13, 10), name='dense4', input='flatten1')\n graph.add_output(name='output1', inputs=['dense1', 'dense3'], merge_mode='sum')\n graph.add_output(name='output2', inputs=['dense1', 'dense4'], merge_mode='concat')\n \n-model_utils.print_layer_shapes(graph,\n-    {'input1':(1, 32), 'input2':(1, 1, 28, 28)})\n+layer_utils.print_layer_shapes(graph, {'input1': (1, 32), 'input2': (1, 1, 28, 28)})\n \n print('Test script complete')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b6aaeb35ee6b27b026e0495f1c04e830fe8c5db9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 6 | Contributors (this commit): 1 | Commits (past 90d): 5 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -19,7 +19,7 @@ class TestEmbedding(unittest.TestCase):\n         lookup.add(Dense(2, 1))\n         lookup.add(Activation('sigmoid'))\n         lookup.compile(loss='binary_crossentropy', optimizer='sgd', class_mode='binary')\n-        lookup.train(self.X1, np.array([[1], [0]], dtype='int32'))\n+        lookup.train_on_batch(self.X1, np.array([[1], [0]], dtype='int32'))\n         norm = np.linalg.norm(lookup.params[0].get_value(), axis=1)\n         self.assertTrue(np.allclose(norm, np.ones_like(norm).astype('float32')))\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e06f9df8782b6859cca4aeccb63ef3ca661a49df", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 40 | Lines Deleted: 34 | Files Changed: 1 | Hunks: 11 | Methods Changed: 7 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 74 | Churn Cumulative: 2536 | Contributors (this commit): 20 | Commits (past 90d): 88 | Contributors (cumulative): 20 | DMM Complexity: 1.0\n\nDIFF:\n@@ -96,25 +96,35 @@ def model_from_yaml(yaml_string):\n         which is either created by hand or from to_yaml method of Sequential or Graph\n     '''\n     import yaml\n-    model_params = yaml.load(yaml_string)\n-    model_name = model_params.get('name')\n+    config = yaml.load(yaml_string)\n+    return model_from_config(config)\n+\n+\n+def model_from_json(json_string):\n+    import json\n+    config.json.loads(json_string)\n+    return model_from_config(config)\n+\n+\n+def model_from_config(config):\n+    model_name = config.get('name')\n     if model_name not in {'Graph', 'Sequential'}:\n         raise Exception('Unrecognized model:', model_name)\n \n     # Create a container then set class to appropriate model\n-    model = container_from_config(model_params)\n+    model = container_from_config(config)\n     if model_name == 'Graph':\n         model.__class__ = Graph\n     elif model_name == 'Sequential':\n         model.__class__ = Sequential\n \n-    if 'optimizer' in model_params:\n+    if 'optimizer' in config:\n         # if it has an optimizer, the model is assumed to be compiled\n-        loss = objectives.get(model_params.get('loss'))\n-        class_mode = model_params.get('class_mode')\n-        theano_mode = model_params.get('theano_mode')\n+        loss = objectives.get(config.get('loss'))\n+        class_mode = config.get('class_mode')\n+        theano_mode = config.get('theano_mode')\n \n-        optimizer_params = model_params.get('optimizer')\n+        optimizer_params = config.get('optimizer')\n         optimizer_name = optimizer_params.pop('name')\n         optimizer = optimizers.get(optimizer_name, optimizer_params)\n \n@@ -277,11 +287,29 @@ class Model(object):\n \n     def get_config(self, verbose=0):\n         config = super(Model, self).get_config()\n+        for p in ['class_mode', 'theano_mode', 'loss']:\n+            if hasattr(self, p):\n+                config[p] = getattr(self, p)\n+        if hasattr(self, 'optimizer'):\n+            config['optimizer'] = self.optimizer.get_config()\n+\n         if verbose:\n             pp = pprint.PrettyPrinter(indent=4)\n             pp.pprint(config)\n         return config\n \n+    def to_yaml(self):\n+        # dump model configuration to yaml string\n+        import yaml\n+        config = self.get_config()\n+        return yaml.dump(config)\n+\n+    def to_json(self):\n+        # dump model configuration to json string\n+        import json\n+        config = self.get_config()\n+        return json.dump(config)\n+\n \n class Sequential(Model, containers.Sequential):\n     '''\n@@ -301,8 +329,8 @@ class Sequential(Model, containers.Sequential):\n     def compile(self, optimizer, loss, class_mode=\"categorical\", theano_mode=None):\n         self.optimizer = optimizers.get(optimizer)\n \n-        self.unweighted_loss = objectives.get(loss)\n-        self.loss = weighted_objective(objectives.get(loss))\n+        self.loss = objectives.get(loss)\n+        weighted_loss = weighted_objective(objectives.get(loss))\n \n         # input of model\n         self.X_train = self.get_input(train=True)\n@@ -316,8 +344,8 @@ class Sequential(Model, containers.Sequential):\n \n         self.weights = T.ones_like(self.y_train)\n \n-        train_loss = self.loss(self.y, self.y_train, self.weights)\n-        test_loss = self.loss(self.y, self.y_test, self.weights)\n+        train_loss = weighted_loss(self.y, self.y_train, self.weights)\n+        test_loss = weighted_loss(self.y, self.y_test, self.weights)\n \n         train_loss.name = 'train_loss'\n         test_loss.name = 'test_loss'\n@@ -501,18 +529,6 @@ class Sequential(Model, containers.Sequential):\n             self.layers[k].set_weights(weights)\n         f.close()\n \n-    def to_yaml(self):\n-        # dump model configuration to yaml string\n-        import yaml\n-        model_params = self.get_config()\n-        if hasattr(self, 'optimizer'):\n-            model_params['class_mode'] = self.class_mode\n-            model_params['theano_mode'] = self.theano_mode\n-            model_params['loss'] = self.unweighted_loss.__name__\n-            model_params['optimizer'] = self.optimizer.get_config()\n-\n-        return yaml.dump(model_params)\n-\n \n class Graph(Model, containers.Graph):\n     def compile(self, optimizer, loss, theano_mode=None):\n@@ -652,13 +668,3 @@ class Graph(Model, containers.Graph):\n         weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n         self.set_weights(weights)\n         f.close()\n-\n-    def to_yaml(self):\n-        # dump model configuration to yaml string\n-        import yaml\n-        model_params = self.get_config()\n-        if hasattr(self, 'optimizer'):\n-            model_params['theano_mode'] = self.theano_mode\n-            model_params['loss'] = self.loss\n-            model_params['optimizer'] = self.optimizer.get_config()\n-        return yaml.dump(model_params)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7c3bf9d02fb58a65394185ba65c192e5bbfa12ef", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 48 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 4 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 48 | Churn Cumulative: 48 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,48 @@\n+from __future__ import print_function\n+import unittest\n+from keras.datasets import cifar10, cifar100, reuters, imdb, mnist\n+\n+\n+class TestDatasets(unittest.TestCase):\n+    def test_cifar(self):\n+        print('cifar10')\n+        (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n+        print(X_train.shape)\n+        print(X_test.shape)\n+        print(y_train.shape)\n+        print(y_test.shape)\n+\n+        print('cifar100 fine')\n+        (X_train, y_train), (X_test, y_test) = cifar100.load_data('fine')\n+        print(X_train.shape)\n+        print(X_test.shape)\n+        print(y_train.shape)\n+        print(y_test.shape)\n+\n+        print('cifar100 coarse')\n+        (X_train, y_train), (X_test, y_test) = cifar100.load_data('coarse')\n+        print(X_train.shape)\n+        print(X_test.shape)\n+        print(y_train.shape)\n+        print(y_test.shape)\n+\n+    def test_reuters(self):\n+        print('reuters')\n+        (X_train, y_train), (X_test, y_test) = reuters.load_data()\n+\n+    def test_mnist(self):\n+        print('mnist')\n+        (X_train, y_train), (X_test, y_test) = mnist.load_data()\n+        print(X_train.shape)\n+        print(X_test.shape)\n+        print(y_train.shape)\n+        print(y_test.shape)\n+\n+    def test_imdb(self):\n+        print('imdb')\n+        (X_train, y_train), (X_test, y_test) = imdb.load_data()\n+\n+\n+if __name__ == '__main__':\n+    print('Test datasets')\n+    unittest.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4f6b1a4dae7701cc79a523e96fe812efaa54745b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 59 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 7 | Complexity Δ (Sum/Max): 7/7 | Churn Δ: 59 | Churn Cumulative: 59 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,59 @@\n+from __future__ import print_function\n+import numpy as np\n+np.random.seed(1337)\n+\n+from keras.utils.test_utils import get_test_data\n+from keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam\n+from keras.models import Sequential\n+from keras.layers.core import Dense, Activation\n+from keras.utils.np_utils import to_categorical\n+import unittest\n+\n+\n+(X_train, y_train), (X_test, y_test) = get_test_data(nb_train=1000, nb_test=200, input_shape=(10,),\n+                                                     classification=True, nb_class=2)\n+y_train = to_categorical(y_train)\n+y_test = to_categorical(y_test)\n+\n+\n+def get_model(input_dim, nb_hidden, output_dim):\n+    model = Sequential()\n+    model.add(Dense(input_dim, nb_hidden))\n+    model.add(Activation('relu'))\n+    model.add(Dense(nb_hidden, output_dim))\n+    model.add(Activation('softmax'))\n+    return model\n+\n+\n+def test_optimizer(optimizer, target=0.9):\n+    model = get_model(X_train.shape[1], 10, y_train.shape[1])\n+    model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n+    history = model.fit(X_train, y_train, nb_epoch=12, batch_size=16, validation_data=(X_test, y_test), show_accuracy=True, verbose=2)\n+    return history.history['val_acc'][-1] > target\n+\n+\n+class TestOptimizers(unittest.TestCase):\n+    def test_sgd(self):\n+        print('test SGD')\n+        sgd = SGD(lr=0.01, momentum=0.9, nesterov=True)\n+        self.assertTrue(test_optimizer(sgd))\n+\n+    def test_rmsprop(self):\n+        print('test RMSprop')\n+        self.assertTrue(test_optimizer(RMSprop()))\n+\n+    def test_adagrad(self):\n+        print('test Adagrad')\n+        self.assertTrue(test_optimizer(Adagrad()))\n+\n+    def test_adadelta(self):\n+        print('test Adadelta')\n+        self.assertTrue(test_optimizer(Adadelta()))\n+\n+    def test_adam(self):\n+        print('test Adam')\n+        self.assertTrue(test_optimizer(Adam()))\n+\n+if __name__ == '__main__':\n+    print('Test optimizers')\n+    unittest.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f1d60121ed6c300dc20d214ec4b810ee1cfdd584", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 6 | Methods Changed: 7 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 71 | Contributors (this commit): 1 | Commits (past 90d): 2 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -25,7 +25,7 @@ def get_model(input_dim, nb_hidden, output_dim):\n     return model\n \n \n-def test_optimizer(optimizer, target=0.9):\n+def _test_optimizer(optimizer, target=0.9):\n     model = get_model(X_train.shape[1], 10, y_train.shape[1])\n     model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n     history = model.fit(X_train, y_train, nb_epoch=12, batch_size=16, validation_data=(X_test, y_test), show_accuracy=True, verbose=2)\n@@ -36,23 +36,23 @@ class TestOptimizers(unittest.TestCase):\n     def test_sgd(self):\n         print('test SGD')\n         sgd = SGD(lr=0.01, momentum=0.9, nesterov=True)\n-        self.assertTrue(test_optimizer(sgd))\n+        self.assertTrue(_test_optimizer(sgd))\n \n     def test_rmsprop(self):\n         print('test RMSprop')\n-        self.assertTrue(test_optimizer(RMSprop()))\n+        self.assertTrue(_test_optimizer(RMSprop()))\n \n     def test_adagrad(self):\n         print('test Adagrad')\n-        self.assertTrue(test_optimizer(Adagrad()))\n+        self.assertTrue(_test_optimizer(Adagrad()))\n \n     def test_adadelta(self):\n         print('test Adadelta')\n-        self.assertTrue(test_optimizer(Adadelta()))\n+        self.assertTrue(_test_optimizer(Adadelta()))\n \n     def test_adam(self):\n         print('test Adam')\n-        self.assertTrue(test_optimizer(Adam()))\n+        self.assertTrue(_test_optimizer(Adam()))\n \n if __name__ == '__main__':\n     print('Test optimizers')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a4def20848c511e309e84062236646df12073a72", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 7 | Methods Changed: 3 | Complexity Δ (Sum/Max): 5/5 | Churn Δ: 20 | Churn Cumulative: 2556 | Contributors (this commit): 20 | Commits (past 90d): 89 | Contributors (cumulative): 20 | DMM Complexity: 0.0\n\nDIFF:\n@@ -4,17 +4,17 @@ import theano\n import theano.tensor as T\n import numpy as np\n import warnings, time, copy, pprint\n+from six.moves import range\n+import six\n \n from . import optimizers\n from . import objectives\n from . import regularizers\n from . import constraints\n from . import callbacks as cbks\n-\n from .utils.layer_utils import container_from_config\n from .utils.generic_utils import Progbar, printv\n from .layers import containers\n-from six.moves import range\n \n \n def standardize_y(y):\n@@ -120,7 +120,7 @@ def model_from_config(config):\n \n     if 'optimizer' in config:\n         # if it has an optimizer, the model is assumed to be compiled\n-        loss = objectives.get(config.get('loss'))\n+        loss = config.get('loss')\n         class_mode = config.get('class_mode')\n         theano_mode = config.get('theano_mode')\n \n@@ -136,6 +136,13 @@ def model_from_config(config):\n     return model\n \n \n+def get_function_name(o):\n+    if isinstance(o, six.string_types):\n+        return o\n+    else:\n+        return o.__name__\n+\n+\n class Model(object):\n     def _fit(self, f, ins, out_labels=[], batch_size=128, nb_epoch=100, verbose=1, callbacks=[],\n              validation_split=0., val_f=None, val_ins=None, shuffle=True, metrics=[]):\n@@ -287,11 +294,16 @@ class Model(object):\n \n     def get_config(self, verbose=0):\n         config = super(Model, self).get_config()\n-        for p in ['class_mode', 'theano_mode', 'loss']:\n+        for p in ['class_mode', 'theano_mode']:\n             if hasattr(self, p):\n                 config[p] = getattr(self, p)\n         if hasattr(self, 'optimizer'):\n             config['optimizer'] = self.optimizer.get_config()\n+        if hasattr(self, 'loss'):\n+            if type(self.loss) == dict:\n+                config['loss'] = dict([(k, get_function_name(v)) for k, v in self.loss.items()])\n+            else:\n+                config['loss'] = get_function_name(self.loss)\n \n         if verbose:\n             pp = pprint.PrettyPrinter(indent=4)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1e18983cfb3497cd35afe1794b3e951f3fd91b8d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 566 | Contributors (this commit): 7 | Commits (past 90d): 18 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -20,14 +20,14 @@ def kl_divergence(p, p_hat):\n class Optimizer(object):\n     def __init__(self, **kwargs):\n         self.__dict__.update(kwargs)\n-        self.update = []\n+        self.updates = []\n \n     def get_state(self):\n-        return [u[0].get_value() for u in self.update]\n+        return [u[0].get_value() for u in self.updates]\n \n     def set_state(self, value_list):\n-        assert len(self.update) == len(value_list)\n-        for u, v in zip(self.update, value_list):\n+        assert len(self.updates) == len(value_list)\n+        for u, v in zip(self.updates, value_list):\n             u[0].set_value(floatX(v))\n \n     def get_updates(self, params, constraints, loss):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3a62cad7f50e9748787cf7783e32e9874bfad918", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2558 | Contributors (this commit): 20 | Commits (past 90d): 90 | Contributors (cumulative): 20 | DMM Complexity: None\n\nDIFF:\n@@ -102,7 +102,7 @@ def model_from_yaml(yaml_string):\n \n def model_from_json(json_string):\n     import json\n-    config.json.loads(json_string)\n+    config = json.loads(json_string)\n     return model_from_config(config)\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b64217cdef51e8ec21675ad6736f6e4f5359acc0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 19 | Lines Deleted: 17 | Files Changed: 7 | Hunks: 19 | Methods Changed: 5 | Complexity Δ (Sum/Max): -5/0 | Churn Δ: 36 | Churn Cumulative: 1732 | Contributors (this commit): 11 | Commits (past 90d): 55 | Contributors (cumulative): 20 | DMM Complexity: 1.0\n\nDIFF:\n@@ -106,7 +106,7 @@ class BaseLogger(Callback):\n     def on_epoch_begin(self, epoch, logs={}):\n         if self.verbose:\n             print('Epoch %d' % epoch)\n-            self.progbar = Progbar(target=self.params['nb_sample'], \\\n+            self.progbar = Progbar(target=self.params['nb_sample'],\n                                    verbose=self.verbose)\n         self.seen = 0\n         self.totals = {}\n\n@@ -4,6 +4,7 @@ from .data_utils import get_file\n import numpy as np\n import os\n \n+\n def load_data():\n     dirname = \"cifar-10-batches-py\"\n     origin = \"http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n\n@@ -4,6 +4,7 @@ from .data_utils import get_file\n import numpy as np\n import os\n \n+\n def load_data(label_mode='fine'):\n     if label_mode not in ['fine', 'coarse']:\n         raise Exception('label_mode must be one of \"fine\" \"coarse\".')\n\n@@ -6,6 +6,7 @@ import random\n from six.moves import zip\n import numpy as np\n \n+\n def load_data(path=\"imdb.pkl\", nb_words=None, skip_top=0, maxlen=None, test_split=0.2, seed=113,\n               start_char=1, oov_char=2, index_from=3):\n \n@@ -63,4 +64,3 @@ def load_data(path=\"imdb.pkl\", nb_words=None, skip_top=0, maxlen=None, test_spli\n     y_test = labels[int(len(X)*(1-test_split)):]\n \n     return (X_train, y_train), (X_test, y_test)\n-\n\n@@ -4,6 +4,7 @@ from .data_utils import get_file\n import six.moves.cPickle\n import sys\n \n+\n def load_data(path=\"mnist.pkl.gz\"):\n     path = get_file(path, origin=\"https://s3.amazonaws.com/img-datasets/mnist.pkl.gz\")\n \n\n@@ -9,6 +9,7 @@ import six.moves.cPickle\n from six.moves import zip\n import numpy as np\n \n+\n def make_reuters_dataset(path=os.path.join('datasets', 'temp', 'reuters21578'), min_samples_per_topic=15):\n     import re\n     from ..preprocessing.text import Tokenizer\n@@ -24,8 +25,7 @@ def make_reuters_dataset(path=os.path.join('datasets', 'temp', 'reuters21578'),\n             while tag in s:\n                 s = s[s.find(tag)+len(tag):]\n                 topics = s[:s.find('</')]\n-                \n-                if topics and not '</D><D>' in topics:\n+                if topics and '</D><D>' not in topics:\n                     topic = topics.replace('<D>', '').replace('</D>', '')\n                     wire_topics.append(topic)\n                     topic_counts[topic] = topic_counts.get(topic, 0) + 1\n@@ -82,7 +82,6 @@ def make_reuters_dataset(path=os.path.join('datasets', 'temp', 'reuters21578'),\n     six.moves.cPickle.dump(tokenizer.word_index, open(os.path.join('datasets', 'data', 'reuters_word_index.pkl'), 'w'))\n \n \n-\n def load_data(path=\"reuters.pkl\", nb_words=None, skip_top=0, maxlen=None, test_split=0.2, seed=113,\n               start_char=1, oov_char=2, index_from=3):\n \n\n@@ -3,7 +3,6 @@ from __future__ import absolute_import\n \n import theano\n import theano.tensor as T\n-from theano.tensor.signal import downsample\n \n from .. import activations, initializations, regularizers, constraints\n from ..utils.theano_utils import shared_zeros\n@@ -14,7 +13,8 @@ class Convolution1D(Layer):\n     def __init__(self, input_dim, nb_filter, filter_length,\n                  init='uniform', activation='linear', weights=None,\n                  border_mode='valid', subsample_length=1,\n-        W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None):\n+                 W_regularizer=None, b_regularizer=None, activity_regularizer=None,\n+                 W_constraint=None, b_constraint=None):\n \n         if border_mode not in {'valid', 'full'}:\n             raise Exception('Invalid border mode for Convolution1D:', border_mode)\n@@ -62,10 +62,10 @@ class Convolution1D(Layer):\n \n     def get_output(self, train):\n         X = self.get_input(train)\n-        X = theano.tensor.reshape(X, (X.shape[0], X.shape[1], X.shape[2], 1)).dimshuffle(0, 2, 1, 3)\n-        conv_out = theano.tensor.nnet.conv.conv2d(X, self.W, border_mode=self.border_mode, subsample=self.subsample)\n+        X = T.reshape(X, (X.shape[0], X.shape[1], X.shape[2], 1)).dimshuffle(0, 2, 1, 3)\n+        conv_out = T.nnet.conv.conv2d(X, self.W, border_mode=self.border_mode, subsample=self.subsample)\n         output = self.activation(conv_out + self.b.dimshuffle('x', 0, 'x', 'x'))\n-        return theano.tensor.reshape(output, (output.shape[0], output.shape[1], output.shape[2])).dimshuffle(0, 2, 1)\n+        return T.reshape(output, (output.shape[0], output.shape[1], output.shape[2])).dimshuffle(0, 2, 1)\n \n     def get_config(self):\n         return {\"name\": self.__class__.__name__,\n@@ -99,10 +99,10 @@ class MaxPooling1D(Layer):\n \n     def get_output(self, train):\n         X = self.get_input(train)\n-        X = theano.tensor.reshape(X, (X.shape[0], X.shape[1], X.shape[2], 1)).dimshuffle(0, 1, 3, 2)\n-        output = downsample.max_pool_2d(X, ds=self.poolsize, st=self.st, ignore_border=self.ignore_border)\n+        X = T.reshape(X, (X.shape[0], X.shape[1], X.shape[2], 1)).dimshuffle(0, 1, 3, 2)\n+        output = T.signal.downsample.max_pool_2d(X, ds=self.poolsize, st=self.st, ignore_border=self.ignore_border)\n         output = output.dimshuffle(0, 1, 3, 2)\n-        return theano.tensor.reshape(output, (output.shape[0], output.shape[1], output.shape[2]))\n+        return T.reshape(output, (output.shape[0], output.shape[1], output.shape[2]))\n \n     def get_config(self):\n         return {\"name\": self.__class__.__name__,\n@@ -112,12 +112,12 @@ class MaxPooling1D(Layer):\n                 \"subsample_length\": self.subsample_length}\n \n \n-\n class Convolution2D(Layer):\n     def __init__(self, nb_filter, stack_size, nb_row, nb_col,\n                  init='glorot_uniform', activation='linear', weights=None,\n                  border_mode='valid', subsample=(1, 1),\n-        W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None):\n+                 W_regularizer=None, b_regularizer=None, activity_regularizer=None,\n+                 W_constraint=None, b_constraint=None):\n \n         if border_mode not in {'valid', 'full', 'same'}:\n             raise Exception('Invalid border mode for Convolution2D:', border_mode)\n@@ -170,7 +170,7 @@ class Convolution2D(Layer):\n         if border_mode == 'same':\n             border_mode = 'full'\n \n-        conv_out = theano.tensor.nnet.conv.conv2d(X, self.W,\n+        conv_out = T.nnet.conv.conv2d(X, self.W,\n             border_mode=border_mode, subsample=self.subsample)\n \n         if self.border_mode == 'same':\n@@ -207,7 +207,7 @@ class MaxPooling2D(Layer):\n \n     def get_output(self, train):\n         X = self.get_input(train)\n-        output = downsample.max_pool_2d(X, ds=self.poolsize, st=self.stride, ignore_border=self.ignore_border)\n+        output = T.signal.downsample.max_pool_2d(X, ds=self.poolsize, st=self.stride, ignore_border=self.ignore_border)\n         return output\n \n     def get_config(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
