{"custom_id": "keras#c0293ded9abe8ac7719cceb0095fa9dff807d2fe", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 135 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 10 | Methods Changed: 9 | Complexity Δ (Sum/Max): 15/12 | Churn Δ: 137 | Churn Cumulative: 819 | Contributors (this commit): 8 | Commits (past 90d): 17 | Contributors (cumulative): 14 | DMM Complexity: 0.6216216216216216\n\nDIFF:\n@@ -197,6 +197,8 @@ class MultiHeadAttention(Layer):\n       activity_regularizer: Regularizer for dense layer activity.\n       kernel_constraint: Constraint for dense layer kernels.\n       bias_constraint: Constraint for dense layer kernels.\n+      causal: Boolean, whether to apply a causal mask to prevent tokens from\n+      attending to future tokens (e.g., used in a decoder Transformer).\n \n     Call arguments:\n       query: Query `Tensor` of shape `(B, T, dim)`.\n@@ -241,9 +243,11 @@ class MultiHeadAttention(Layer):\n         activity_regularizer=None,\n         kernel_constraint=None,\n         bias_constraint=None,\n+        causal=False,\n         **kwargs\n     ):\n         super().__init__(**kwargs)\n+        self.supports_masking = True\n         self._num_heads = num_heads\n         self._key_dim = key_dim\n         self._value_dim = value_dim if value_dim else key_dim\n@@ -257,6 +261,7 @@ class MultiHeadAttention(Layer):\n         self._activity_regularizer = regularizers.get(activity_regularizer)\n         self._kernel_constraint = constraints.get(kernel_constraint)\n         self._bias_constraint = constraints.get(bias_constraint)\n+        self._causal = causal\n         if attention_axes is not None and not isinstance(\n             attention_axes, collections.abc.Sized\n         ):\n@@ -288,6 +293,7 @@ class MultiHeadAttention(Layer):\n             ),\n             \"kernel_constraint\": constraints.serialize(self._kernel_constraint),\n             \"bias_constraint\": constraints.serialize(self._bias_constraint),\n+            \"causal\": self._causal,\n             \"query_shape\": self._query_shape,\n             \"key_shape\": self._key_shape,\n             \"value_shape\": self._value_shape,\n@@ -449,7 +455,7 @@ class MultiHeadAttention(Layer):\n         \"\"\"Builds multi-head dot-product attention computations.\n \n         This function builds attributes necessary for `_compute_attention` to\n-        costomize attention computation to replace the default dot-product\n+        customize attention computation to replace the default dot-product\n         attention.\n \n         Args:\n@@ -502,7 +508,8 @@ class MultiHeadAttention(Layer):\n           key: Projected key `Tensor` of shape `(B, T, N, key_dim)`.\n           value: Projected value `Tensor` of shape `(B, T, N, value_dim)`.\n           attention_mask: a boolean mask of shape `(B, T, S)`, that prevents\n-            attention to certain positions.\n+            attention to certain positions. It is generally not needed if the\n+            `query` and `value` (and/or `key`) are masked.\n           training: Python boolean indicating whether the layer should behave in\n             training mode (adding dropout) or in inference mode (doing nothing).\n \n@@ -544,6 +551,10 @@ class MultiHeadAttention(Layer):\n         return_attention_scores=False,\n         training=None,\n     ):\n+        attention_mask = self._compute_attention_mask(\n+            query, value, key, attention_mask\n+        )\n+\n         if not self._built_from_signature:\n             self._build_from_signature(query=query, value=value, key=key)\n         if key is None:\n@@ -592,3 +603,84 @@ class MultiHeadAttention(Layer):\n         if return_attention_scores:\n             return attention_output, attention_scores\n         return attention_output\n+\n+    def _compute_attention_mask(\n+        self, query, value, key=None, attention_mask=None\n+    ):\n+        \"\"\"Computes the attention mask, using the Keras masks of the inputs.\n+\n+        * The `query`'s mask is reshaped from [B, T] to [B, T, 1].\n+        * The `value`'s mask is reshaped from [B, S] to [B, 1, S].\n+        * The `key`'s mask is reshaped from [B, S] to [B, 1, S]. The `key`'s\n+          mask is ignored if `key` is `None` or if `key is value`.\n+        * If the layer was created with `causal=True`, then the causal mask is\n+          computed. Its shape is [1, T, S].\n+\n+        All defined masks are merged using a logical AND operation (`&`).\n+\n+        In general, if the `query` and `value` are masked, then there is no need\n+        to define the `attention_mask`.\n+\n+        Args:\n+          query: Projected query `Tensor` of shape `(B, T, N, key_dim)`.\n+          key: Projected key `Tensor` of shape `(B, T, N, key_dim)`.\n+          value: Projected value `Tensor` of shape `(B, T, N, value_dim)`.\n+          attention_mask: a boolean mask of shape `(B, T, S)`, that prevents\n+            attention to certain positions.\n+        Returns:\n+          attention_mask: a boolean mask of shape `(B, T, S)`, that prevents\n+            attention to certain positions, based on the Keras masks of the\n+            `query`, `key`, `value`, and `attention_mask` tensors, and the\n+            causal mask if the layer was created with `causal=True`.\n+        \"\"\"\n+        query_mask = getattr(query, \"_keras_mask\", None)\n+        value_mask = getattr(value, \"_keras_mask\", None)\n+        key_mask = getattr(key, \"_keras_mask\", None)\n+        auto_mask = None\n+        if query_mask is not None:\n+            # B = batch size, T = max query length\n+            auto_mask = query_mask[:, :, tf.newaxis]  # shape is [B, T, 1]\n+        if value_mask is not None:\n+            # B = batch size, S == max value length\n+            mask = value_mask[:, tf.newaxis, :]  # shape is [B, 1, S]\n+            auto_mask = mask if auto_mask is None else auto_mask & mask\n+        if key_mask is not None:\n+            # B == batch size, S == max key length == max value length\n+            mask = key_mask[:, tf.newaxis, :]  # shape is [B, 1, S]\n+            auto_mask = mask if auto_mask is None else auto_mask & mask\n+        if self._causal:\n+            # the shape of the causal mask is [1, T, S]\n+            mask = self._compute_causal_mask(query, value)\n+            auto_mask = mask if auto_mask is None else auto_mask & mask\n+        if auto_mask is not None:\n+            # merge attention_mask & automatic mask, to shape [B, T, S]\n+            attention_mask = (\n+                auto_mask\n+                if attention_mask is None\n+                else attention_mask & auto_mask\n+            )\n+        return attention_mask\n+\n+    def _compute_causal_mask(self, query, value=None):\n+        \"\"\"Computes a causal mask (e.g., for masked self-attention layers).\n+\n+        For example, if query and value both contain sequences of length 4,\n+        this function returns:\n+        [[True,  False, False, False],\n+         [True,  True,  False, False],\n+         [True,  True,  True,  False],\n+         [True,  True,  True,  True]]\n+\n+        Args:\n+          query: query `Tensor` of shape `(B, T, ...)`.\n+          value: value `Tensor` of shape `(B, S, ...)` (optional, defaults to\n+          query).\n+        Returns:\n+          mask: an array of shape [1, T, S] containing a lower triangular matrix\n+          of shape [T, S].\n+        \"\"\"\n+        q_seq_length = tf.shape(query)[1]\n+        v_seq_length = q_seq_length if value is None else tf.shape(value)[1]\n+        return tf.linalg.band_part(  # creates a lower triangular matrix\n+            tf.ones((1, q_seq_length, v_seq_length), tf.bool), -1, 0\n+        )\n\n@@ -328,6 +328,47 @@ class MultiHeadAttentionTest(test_combinations.TestCase):\n         results = test_layer(query, value, key)\n         self.assertAllEqual(results.shape.as_list(), query.shape.as_list())\n \n+    def test_query_mask_progagation(self):\n+        \"\"\"Test automatic propagation of the query's mask.\"\"\"\n+        test_layer = keras.layers.MultiHeadAttention(num_heads=2, key_dim=2)\n+        self.assertTrue(test_layer.supports_masking)\n+        query = np.array([[1, 2, 3, 0, 0], [3, 3, 1, 1, 2], [1, 0, 0, 0, 0]])\n+        masked_query = keras.layers.Embedding(4, 8, mask_zero=True)(query)\n+        value = np.random.random((3, 3, 8))\n+        output = test_layer(query=masked_query, value=value)\n+        self.assertTrue(hasattr(output, \"_keras_mask\"))\n+        self.assertAllEqual(masked_query._keras_mask, output._keras_mask)\n+\n+    @parameterized.named_parameters((\"causal\", True), (\"not_causal\", False))\n+    def test_value_mask(self, causal):\n+        \"\"\"Test that the value and causal masks are taken into account.\"\"\"\n+        test_layer = keras.layers.MultiHeadAttention(\n+            num_heads=2, key_dim=2, causal=causal\n+        )\n+        query = np.array([[1, 2, 3, 0, 0], [3, 3, 1, 1, 2], [1, 0, 0, 0, 0]])\n+        masked_query = keras.layers.Embedding(4, 8, mask_zero=True)(query)\n+        value = np.array([[5, 4, 0], [3, 0, 0], [2, 1, 1]])\n+        masked_value = keras.layers.Embedding(6, 8, mask_zero=True)(value)\n+        output = test_layer(query=masked_query, value=masked_value)\n+        mask = np.array(\n+            [[[True, True, False]] * 3 + [[False, False, False]] * 2]\n+            + [[[True, False, False]] * 5]\n+            + [[[True, True, True]] + [[False, False, False]] * 4]\n+        )\n+        if causal:\n+            mask = mask & np.array(\n+                [\n+                    [[True, False, False], [True, True, False]]\n+                    + [[True, True, True]] * 3\n+                ]\n+            )\n+        del masked_query._keras_mask\n+        del masked_value._keras_mask\n+        output_with_manual_mask = test_layer(\n+            query=masked_query, value=masked_value, attention_mask=mask\n+        )\n+        self.assertAllClose(output, output_with_manual_mask)\n+\n \n class SubclassAttention(keras.layers.MultiHeadAttention):\n     def _build_attention(self, qkv_rank):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#015625fb981212a97c282b71a0479b6e7cada6b3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 19 | Lines Deleted: 17 | Files Changed: 2 | Hunks: 16 | Methods Changed: 8 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 36 | Churn Cumulative: 855 | Contributors (this commit): 8 | Commits (past 90d): 19 | Contributors (cumulative): 14 | DMM Complexity: 0.0\n\nDIFF:\n@@ -197,8 +197,6 @@ class MultiHeadAttention(Layer):\n       activity_regularizer: Regularizer for dense layer activity.\n       kernel_constraint: Constraint for dense layer kernels.\n       bias_constraint: Constraint for dense layer kernels.\n-      causal: Boolean, whether to apply a causal mask to prevent tokens from\n-      attending to future tokens (e.g., used in a decoder Transformer).\n \n     Call arguments:\n       query: Query `Tensor` of shape `(B, T, dim)`.\n@@ -217,6 +215,9 @@ class MultiHeadAttention(Layer):\n         training mode (adding dropout) or in inference mode (no dropout).\n         Defaults to either using the training mode of the parent layer/model,\n         or False (inference) if there is no parent layer.\n+      use_causal_mask: A boolean to indicate whether to apply a causal mask to\n+      prevent tokens from attending to future tokens (e.g., used in a decoder\n+      Transformer).\n \n     Returns:\n       attention_output: The result of the computation, of shape `(B, T, E)`,\n@@ -243,7 +244,6 @@ class MultiHeadAttention(Layer):\n         activity_regularizer=None,\n         kernel_constraint=None,\n         bias_constraint=None,\n-        causal=False,\n         **kwargs\n     ):\n         super().__init__(**kwargs)\n@@ -261,7 +261,6 @@ class MultiHeadAttention(Layer):\n         self._activity_regularizer = regularizers.get(activity_regularizer)\n         self._kernel_constraint = constraints.get(kernel_constraint)\n         self._bias_constraint = constraints.get(bias_constraint)\n-        self._causal = causal\n         if attention_axes is not None and not isinstance(\n             attention_axes, collections.abc.Sized\n         ):\n@@ -293,7 +292,6 @@ class MultiHeadAttention(Layer):\n             ),\n             \"kernel_constraint\": constraints.serialize(self._kernel_constraint),\n             \"bias_constraint\": constraints.serialize(self._bias_constraint),\n-            \"causal\": self._causal,\n             \"query_shape\": self._query_shape,\n             \"key_shape\": self._key_shape,\n             \"value_shape\": self._value_shape,\n@@ -550,9 +548,11 @@ class MultiHeadAttention(Layer):\n         attention_mask=None,\n         return_attention_scores=False,\n         training=None,\n+        use_causal_mask=False\n     ):\n         attention_mask = self._compute_attention_mask(\n-            query, value, key, attention_mask\n+            query, value, key=key, attention_mask=attention_mask,\n+            use_causal_mask=use_causal_mask\n         )\n \n         if not self._built_from_signature:\n@@ -605,7 +605,7 @@ class MultiHeadAttention(Layer):\n         return attention_output\n \n     def _compute_attention_mask(\n-        self, query, value, key=None, attention_mask=None\n+        self, query, value, key=None, attention_mask=None, use_causal_mask=False\n     ):\n         \"\"\"Computes the attention mask, using the Keras masks of the inputs.\n \n@@ -613,8 +613,8 @@ class MultiHeadAttention(Layer):\n         * The `value`'s mask is reshaped from [B, S] to [B, 1, S].\n         * The `key`'s mask is reshaped from [B, S] to [B, 1, S]. The `key`'s\n           mask is ignored if `key` is `None` or if `key is value`.\n-        * If the layer was created with `causal=True`, then the causal mask is\n-          computed. Its shape is [1, T, S].\n+        * If `use_causal_mask=True`, then the causal mask is computed. Its shape\n+          is [1, T, S].\n \n         All defined masks are merged using a logical AND operation (`&`).\n \n@@ -627,11 +627,14 @@ class MultiHeadAttention(Layer):\n           value: Projected value `Tensor` of shape `(B, T, N, value_dim)`.\n           attention_mask: a boolean mask of shape `(B, T, S)`, that prevents\n             attention to certain positions.\n+          use_causal_mask: A boolean to indicate whether to apply a causal mask\n+            to prevent tokens from attending to future tokens (e.g., used in a\n+            decoder Transformer).\n         Returns:\n           attention_mask: a boolean mask of shape `(B, T, S)`, that prevents\n             attention to certain positions, based on the Keras masks of the\n             `query`, `key`, `value`, and `attention_mask` tensors, and the\n-            causal mask if the layer was created with `causal=True`.\n+            causal mask if `use_causal_mask=True`.\n         \"\"\"\n         query_mask = getattr(query, \"_keras_mask\", None)\n         value_mask = getattr(value, \"_keras_mask\", None)\n@@ -648,7 +651,7 @@ class MultiHeadAttention(Layer):\n             # B == batch size, S == max key length == max value length\n             mask = key_mask[:, tf.newaxis, :]  # shape is [B, 1, S]\n             auto_mask = mask if auto_mask is None else auto_mask & mask\n-        if self._causal:\n+        if use_causal_mask:\n             # the shape of the causal mask is [1, T, S]\n             mask = self._compute_causal_mask(query, value)\n             auto_mask = mask if auto_mask is None else auto_mask & mask\n\n@@ -340,22 +340,21 @@ class MultiHeadAttentionTest(test_combinations.TestCase):\n         self.assertAllEqual(masked_query._keras_mask, output._keras_mask)\n \n     @parameterized.named_parameters((\"causal\", True), (\"not_causal\", False))\n-    def test_value_mask(self, causal):\n+    def test_value_mask(self, use_causal_mask):\n         \"\"\"Test that the value and causal masks are taken into account.\"\"\"\n-        test_layer = keras.layers.MultiHeadAttention(\n-            num_heads=2, key_dim=2, causal=causal\n-        )\n+        test_layer = keras.layers.MultiHeadAttention(num_heads=2, key_dim=2)\n         query = np.array([[1, 2, 3, 0, 0], [3, 3, 1, 1, 2], [1, 0, 0, 0, 0]])\n         masked_query = keras.layers.Embedding(4, 8, mask_zero=True)(query)\n         value = np.array([[5, 4, 0], [3, 0, 0], [2, 1, 1]])\n         masked_value = keras.layers.Embedding(6, 8, mask_zero=True)(value)\n-        output = test_layer(query=masked_query, value=masked_value)\n+        output = test_layer(query=masked_query, value=masked_value,\n+                            use_causal_mask=use_causal_mask)\n         mask = np.array(\n             [[[True, True, False]] * 3 + [[False, False, False]] * 2]\n             + [[[True, False, False]] * 5]\n             + [[[True, True, True]] + [[False, False, False]] * 4]\n         )\n-        if causal:\n+        if use_causal_mask:\n             mask = mask & np.array(\n                 [\n                     [[True, False, False], [True, True, False]]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ebf46bf42166a36068017d12d999d0ecd6e55d69", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 10 | Files Changed: 2 | Hunks: 6 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 26 | Churn Cumulative: 881 | Contributors (this commit): 8 | Commits (past 90d): 21 | Contributors (cumulative): 14 | DMM Complexity: 0.5\n\nDIFF:\n@@ -548,11 +548,14 @@ class MultiHeadAttention(Layer):\n         attention_mask=None,\n         return_attention_scores=False,\n         training=None,\n-        use_causal_mask=False\n+        use_causal_mask=False,\n     ):\n         attention_mask = self._compute_attention_mask(\n-            query, value, key=key, attention_mask=attention_mask,\n-            use_causal_mask=use_causal_mask\n+            query,\n+            value,\n+            key=key,\n+            attention_mask=attention_mask,\n+            use_causal_mask=use_causal_mask,\n         )\n \n         if not self._built_from_signature:\n@@ -668,19 +671,19 @@ class MultiHeadAttention(Layer):\n         \"\"\"Computes a causal mask (e.g., for masked self-attention layers).\n \n         For example, if query and value both contain sequences of length 4,\n-        this function returns:\n-        [[True,  False, False, False],\n+        this function returns a boolean `Tensor` equal to:\n+        [[[True,  False, False, False],\n           [True,  True,  False, False],\n           [True,  True,  True,  False],\n-         [True,  True,  True,  True]]\n+          [True,  True,  True,  True]]]\n \n         Args:\n           query: query `Tensor` of shape `(B, T, ...)`.\n           value: value `Tensor` of shape `(B, S, ...)` (optional, defaults to\n           query).\n         Returns:\n-          mask: an array of shape [1, T, S] containing a lower triangular matrix\n-          of shape [T, S].\n+          mask: a boolean `Tensor` of shape [1, T, S] containing a lower\n+                triangular matrix of shape [T, S].\n         \"\"\"\n         q_seq_length = tf.shape(query)[1]\n         v_seq_length = q_seq_length if value is None else tf.shape(value)[1]\n\n@@ -347,8 +347,11 @@ class MultiHeadAttentionTest(test_combinations.TestCase):\n         masked_query = keras.layers.Embedding(4, 8, mask_zero=True)(query)\n         value = np.array([[5, 4, 0], [3, 0, 0], [2, 1, 1]])\n         masked_value = keras.layers.Embedding(6, 8, mask_zero=True)(value)\n-        output = test_layer(query=masked_query, value=masked_value,\n-                            use_causal_mask=use_causal_mask)\n+        output = test_layer(\n+            query=masked_query,\n+            value=masked_value,\n+            use_causal_mask=use_causal_mask,\n+        )\n         mask = np.array(\n             [[[True, True, False]] * 3 + [[False, False, False]] * 2]\n             + [[[True, False, False]] * 5]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9ec97ba141354c8b34b7735942ffb207766b2d96", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 3 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 480 | Contributors (this commit): 7 | Commits (past 90d): 13 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -548,7 +548,7 @@ class MultiHeadAttention(Layer):\n         attention_mask=None,\n         return_attention_scores=False,\n         training=None,\n-        use_causal_mask=False,\n+        use_causal_mask=False\n     ):\n         attention_mask = self._compute_attention_mask(\n             query,\n@@ -633,6 +633,7 @@ class MultiHeadAttention(Layer):\n           use_causal_mask: A boolean to indicate whether to apply a causal mask\n             to prevent tokens from attending to future tokens (e.g., used in a\n             decoder Transformer).\n+\n         Returns:\n           attention_mask: a boolean mask of shape `(B, T, S)`, that prevents\n             attention to certain positions, based on the Keras masks of the\n@@ -681,6 +682,7 @@ class MultiHeadAttention(Layer):\n           query: query `Tensor` of shape `(B, T, ...)`.\n           value: value `Tensor` of shape `(B, S, ...)` (optional, defaults to\n           query).\n+\n         Returns:\n           mask: a boolean `Tensor` of shape [1, T, S] containing a lower\n                 triangular matrix of shape [T, S].\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f3c5262cd9db4aa2a1699b7bd8a533a5d35da6d2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 12 | Files Changed: 5 | Hunks: 10 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 21 | Churn Cumulative: 8381 | Contributors (this commit): 45 | Commits (past 90d): 38 | Contributors (cumulative): 64 | DMM Complexity: 0.0\n\nDIFF:\n@@ -17,15 +17,16 @@\n import numpy as np\n import tensorflow.compat.v2 as tf\n \n-# TODO(scottzhu): Fix the layout map test with keras/dtensor/test_util\n-from keras.dtensor.tests import test_util\n-\n from keras import backend\n from keras import layers\n from keras.dtensor import dtensor_api as dtensor\n from keras.dtensor import layout_map as layout_map_lib\n from keras.utils import tf_utils\n \n+# isort: off\n+# TODO(scottzhu): Fix the layout map test with keras/dtensor/test_util\n+from keras.dtensor.tests import test_util\n+\n \n class LayoutMapTest(test_util.DTensorBaseTest):\n     def setUp(self):\n\n@@ -24,10 +24,10 @@ from absl.testing import parameterized\n from keras import optimizers\n from keras.mixed_precision import loss_scale_optimizer\n from keras.mixed_precision import test_util as mp_test_util\n+from keras.optimizers.optimizer_experimental import adam as adam_experimental\n from keras.optimizers.optimizer_experimental import (\n     optimizer as optimizer_experimental,\n )\n-from keras.optimizers.optimizer_experimental import adam as adam_experimental\n from keras.optimizers.optimizer_experimental import sgd as sgd_experimental\n from keras.optimizers.optimizer_v2 import adam\n from keras.optimizers.optimizer_v2 import gradient_descent\n@@ -620,8 +620,7 @@ class LossScaleOptimizerTest(tf.test.TestCase, parameterized.TestCase):\n \n     @test_combinations.run_all_keras_modes(always_skip_v1=True)\n     def testHyperParametersExposedLSOV3(self):\n-        opt = adam_experimental.Adam(\n-            learning_rate=1.0, beta_1=0.5, beta_2=0.9)\n+        opt = adam_experimental.Adam(learning_rate=1.0, beta_1=0.5, beta_2=0.9)\n         lso = loss_scale_optimizer.BaseLossScaleOptimizer(opt)\n         lso.learning_rate = tf.Variable(0.005)\n         self.assertAllClose(self.evaluate(lso.learning_rate), 0.005)\n\n@@ -28,7 +28,7 @@ from keras.utils import np_utils\n \n # isort: off\n from tensorflow.python.training.adam import AdamOptimizer\n-from tensorflow.python.training.experimental.loss_scale_optimizer import (\n+from tensorflow.python.training.experimental.loss_scale_optimizer import (  # noqa: E501\n     MixedPrecisionLossScaleOptimizer,\n )\n \n\n@@ -37,13 +37,13 @@ import numpy as np\n import tensorflow.compat.v2 as tf\n from six.moves.urllib.parse import urlsplit\n \n-from six.moves.urllib.request import urlopen\n from keras.utils import io_utils\n from keras.utils import tf_inspect\n from keras.utils.generic_utils import Progbar\n \n # isort: off\n from tensorflow.python.util.tf_export import keras_export\n+from six.moves.urllib.request import urlopen\n \n # Required to support google internal urlretrieve\n if True:  # This gets transformed to `if sys.version_info[0] == 2:` in OSS.\n\n@@ -15,9 +15,6 @@\n \"\"\"Keras model mode constants.\"\"\"\n \n # isort: off\n-# pylint: disable=unused-import\n-from tensorflow.python.saved_model.model_utils.mode_keys import (\n+from tensorflow.python.saved_model.model_utils.mode_keys import (  # noqa: E501\n     KerasModeKeys as ModeKeys,\n )\n-\n-# pylint: enable=unused-import\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#896c8d1a2bfb9351611a86282acf0b2257c54a55", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 275 | Lines Deleted: 49 | Files Changed: 5 | Hunks: 44 | Methods Changed: 32 | Complexity Δ (Sum/Max): 34/22 | Churn Δ: 324 | Churn Cumulative: 38075 | Contributors (this commit): 221 | Commits (past 90d): 79 | Contributors (cumulative): 281 | DMM Complexity: 0.5478723404255319\n\nDIFF:\n@@ -1789,9 +1789,13 @@ class BackupAndRestore(Callback):\n           cannot be reused elsewhere to store other files, e.g. by\n           BackupAndRestore callback of another training, or by another callback\n           (ModelCheckpoint) of the same training.\n+        save_freq: `'epoch'` or integer. When set to `'epoch'`\n+          the callback saves the checkpoint at the end of each epoch.\n+          When set to an integer, the callback saves the checkpoint every\n+          `save_freq` batches.\n     \"\"\"\n \n-    def __init__(self, backup_dir):\n+    def __init__(self, backup_dir, save_freq=\"epoch\"):\n         super().__init__()\n         self.backup_dir = backup_dir\n         self._supports_tf_logs = True\n@@ -1802,6 +1806,9 @@ class BackupAndRestore(Callback):\n             tf.distribute.TPUStrategy,\n             tf.distribute.experimental.ParameterServerStrategy,\n         )\n+        self._save_freq = save_freq\n+        self._batches_count = 0\n+        self._current_epoch = 0\n \n         if not tf.executing_eagerly():\n             if tf.inside_function():\n@@ -1837,24 +1844,39 @@ class BackupAndRestore(Callback):\n                 \"MirroredStrategy, MultiWorkerMirroredStrategy and TPUStrategy.\"\n             )\n         self.model._training_state = worker_training_state.WorkerTrainingState(\n-            self.model, self.backup_dir\n+            self.model, self.backup_dir, self._save_freq\n         )\n         self._training_state = self.model._training_state\n         self._training_state.restore()\n \n+    def on_train_batch_end(self, batch, logs=None):\n+        if self._save_freq != \"epoch\":\n+            self._batches_count += 1\n+            if self._batches_count >= self._save_freq:\n+                self._batches_count = 0\n+                self._training_state.back_up(\n+                    epoch=self._current_epoch, batch=batch\n+                )\n+\n+    def _implements_train_batch_hooks(self):\n+        return self._save_freq != \"epoch\"\n+\n     def on_train_end(self, logs=None):\n         # pylint: disable=protected-access\n         # On exit of training, delete the training state backup file that was\n         # saved for the purpose of worker recovery.\n         self._training_state.delete_backup()\n-\n         # Clean up the training state.\n         del self._training_state\n         del self.model._training_state\n \n+    def on_epoch_begin(self, epoch, logs=None):\n+        self._current_epoch = epoch\n+\n     def on_epoch_end(self, epoch, logs=None):\n         # Back up the model and current epoch for possible future recovery.\n-        self._training_state.back_up(epoch)\n+        if self._save_freq == \"epoch\":\n+            self._training_state.back_up(epoch=epoch)\n \n \n @keras_export(\"keras.callbacks.experimental.BackupAndRestore\", v1=[])\n\n@@ -33,6 +33,7 @@ from absl.testing import parameterized\n \n import keras\n from keras.callbacks import BackupAndRestore\n+from keras.callbacks import Callback\n from keras.callbacks import BackupAndRestoreExperimental\n from keras.engine import sequential\n from keras.layers import Activation\n@@ -370,7 +371,8 @@ class KerasCallbacksTest(test_combinations.TestCase):\n     def test_backup_restore_train_counter(self):\n         if not tf.compat.v1.executing_eagerly():\n             self.skipTest(\n-                \"BackupAndRestore only available when execution is enabled\"\n+                \"BackupAndRestore only available when eager execution is \"\n+                \"enabled\"\n             )\n         model = keras.Sequential([keras.layers.Dense(1)])\n         model.compile(\"sgd\", \"mse\")\n@@ -450,6 +452,103 @@ class KerasCallbacksTest(test_combinations.TestCase):\n                 callbacks=[backup_callback],\n             )\n \n+    def _test_backup_and_restore_callback_at_steps(\n+        self, cls, epoch_int, steps_int, mode\n+    ):\n+        if not tf.compat.v1.executing_eagerly():\n+            self.skipTest(\n+                \"BackupAndRestore only available when eager execution is \"\n+                \"enabled\"\n+            )\n+\n+        class InterruptingCallback(keras.callbacks.Callback):\n+            \"\"\"A callback to intentionally introduce interruption to training.\"\"\"\n+\n+            batch_count = 0\n+\n+            def on_epoch_end(self, epoch, log=None):\n+                if epoch == epoch_int:\n+                    raise RuntimeError(\"EpochInterruption\")\n+\n+            def on_batch_end(self, batch, logs=None):\n+                self.batch_count += 1\n+                if self.batch_count == steps_int:\n+                    raise RuntimeError(\"StepsInterruption\")\n+\n+        class VerifyRestore(Callback):\n+            \"\"\"Verify if the training restored to the correct epoch and step.\"\"\"\n+\n+            def __init__(self, initial_epoch, initial_step):\n+                super(VerifyRestore, self).__init__()\n+                self.initial_epoch = initial_epoch\n+                self.initial_step = initial_step\n+                self._current_epoch = 0\n+\n+            def on_epoch_begin(self, epoch, logs=None):\n+                self._current_epoch = epoch\n+                if epoch < self.initial_epoch:\n+                    raise ValueError(\n+                        \"Training did not restore at epoch (%d) and step (%d)\"\n+                        % (self.initial_epoch, self.initial_step)\n+                    )\n+\n+            def on_batch_begin(self, batch, logs=None):\n+                if (\n+                    batch <= self.initial_step\n+                    and self._current_epoch < self.initial_epoch\n+                ):\n+                    raise ValueError(\n+                        \"Training did not restore at Epoch (%d) and step (%d)\"\n+                        % (self.initial_epoch, self.initial_step)\n+                    )\n+\n+        model = keras.Sequential([keras.layers.Dense(10)])\n+        optimizer = gradient_descent.SGD()\n+        model.compile(optimizer, loss=\"mse\")\n+\n+        x = tf.random.uniform((24, 10))\n+        y = tf.random.uniform((24,))\n+        dataset = tf.data.Dataset.from_tensor_slices((x, y)).repeat().batch(2)\n+        save_freq_arg = \"epoch\" if mode == \"epoch\" else 7\n+        backup_callback = cls(\n+            backup_dir=self.get_temp_dir(), save_freq=save_freq_arg\n+        )\n+        # epoch where the restore should resume from\n+        init_epoch = (\n+            epoch_int\n+            if save_freq_arg == \"epoch\"\n+            else int(((steps_int // 7) * 7) // 5)\n+        )\n+        # step from where the restore should resume from\n+        init_step = (\n+            0\n+            if save_freq_arg == \"epoch\"\n+            else int((((steps_int // 7) * 7) % 5) - 1)\n+        )\n+        # callback to verify accurate training state restore\n+        verify_restore_callback = VerifyRestore(\n+            initial_epoch=init_epoch, initial_step=init_step\n+        )\n+        try:\n+            model.fit(\n+                dataset,\n+                epochs=20,\n+                steps_per_epoch=5,\n+                callbacks=[backup_callback, InterruptingCallback()],\n+            )\n+        except RuntimeError as e:\n+            if str(e) == \"EpochInterruption\":\n+                logging.warning(\"***Handling interruption at epoch***\")\n+            elif str(e) == \"StepsInterruption\":\n+                logging.warning(\"***Handling interruption at Nth step***\")\n+            # This continues at the epoch and step where it left off.\n+            model.fit(\n+                dataset,\n+                epochs=20,\n+                steps_per_epoch=5,\n+                callbacks=[backup_callback, verify_restore_callback],\n+            )\n+\n     def test_experimental_backup_and_restore(self):\n         \"\"\"Ensure the legacy endpoint of `BackupAndRestore` gives warning.\"\"\"\n \n@@ -490,6 +589,66 @@ class KerasCallbacksTest(test_combinations.TestCase):\n         warning_msg = \"***Handling interruption***\"\n         self.assertIn(warning_msg, \"\\n\".join(warning_messages))\n \n+    def test_backup_and_restore_steps(self):\n+        \"\"\"Ensure the public endpoint of `BackupAndRestore` is working.\"\"\"\n+\n+        warning_messages = []\n+\n+        def warning(msg):\n+            warning_messages.append(msg)\n+\n+        with tf.compat.v1.test.mock.patch.object(logging, \"warning\", warning):\n+            # interrupt at steps before 1 epoch\n+            self._test_backup_and_restore_callback_at_steps(\n+                BackupAndRestore, epoch_int=20, steps_int=3, mode=\"batch\"\n+            )\n+        warning_msg = (\n+            \"`tf.keras.callbacks.experimental.BackupAndRestore` \"\n+            \"endpoint is deprecated\"\n+        )\n+        self.assertNotIn(warning_msg, \"\\n\".join(warning_messages))\n+        warning_msg = \"***Handling interruption at Nth step***\"\n+        self.assertIn(warning_msg, \"\\n\".join(warning_messages))\n+\n+        # interrupt at steps after 1 epoch\n+        warning_messages = []\n+        with tf.compat.v1.test.mock.patch.object(logging, \"warning\", warning):\n+            self._test_backup_and_restore_callback_at_steps(\n+                BackupAndRestore, epoch_int=20, steps_int=8, mode=\"batch\"\n+            )\n+        warning_msg = \"***Handling interruption at Nth step***\"\n+        self.assertIn(warning_msg, \"\\n\".join(warning_messages))\n+\n+        # interrupt at epoch before steps\n+        warning_messages = []\n+        with tf.compat.v1.test.mock.patch.object(logging, \"warning\", warning):\n+            self._test_backup_and_restore_callback_at_steps(\n+                BackupAndRestore, epoch_int=1, steps_int=12, mode=\"epoch\"\n+            )\n+        warning_msg = \"***Handling interruption at epoch***\"\n+        self.assertIn(warning_msg, \"\\n\".join(warning_messages))\n+\n+    def test_backup_and_restore_steps_last_batch(self):\n+        \"\"\"Ensure the public endpoint of `BackupAndRestore` is working.\"\"\"\n+\n+        warning_messages = []\n+\n+        def warning(msg):\n+            warning_messages.append(msg)\n+\n+        with tf.compat.v1.test.mock.patch.object(logging, \"warning\", warning):\n+            # interrupt at last step in 7th epoch\n+            self._test_backup_and_restore_callback_at_steps(\n+                BackupAndRestore, epoch_int=20, steps_int=35, mode=\"batch\"\n+            )\n+        warning_msg = (\n+            \"`tf.keras.callbacks.experimental.BackupAndRestore` \"\n+            \"endpoint is deprecated\"\n+        )\n+        self.assertNotIn(warning_msg, \"\\n\".join(warning_messages))\n+        warning_msg = \"***Handling interruption at Nth step***\"\n+        self.assertIn(warning_msg, \"\\n\".join(warning_messages))\n+\n     @test_combinations.run_all_keras_modes\n     def test_callback_warning(self):\n         class SleepCallback(keras.callbacks.Callback):\n@@ -2472,13 +2631,13 @@ class KerasCallbacksTest(test_combinations.TestCase):\n         model.compile(\"sgd\", \"mse\")\n \n         x, y = np.ones((10, 10)), np.ones((10, 1))\n-        with self.assertRaisesRegexp(ValueError, \"New function \"):\n+        with self.assertRaisesRegex(ValueError, \"New function \"):\n             model.fit(\n                 x, y, batch_size=2, epochs=2, callbacks=[ChangeFunctions()]\n             )\n-        with self.assertRaisesRegexp(ValueError, \"New function \"):\n+        with self.assertRaisesRegex(ValueError, \"New function \"):\n             model.evaluate(x, y, batch_size=2)\n-        with self.assertRaisesRegexp(ValueError, \"New function \"):\n+        with self.assertRaisesRegex(ValueError, \"New function \"):\n             model.predict(x, batch_size=2)\n \n     @test_combinations.run_all_keras_modes(always_skip_v1=True)\n@@ -3532,7 +3691,7 @@ class MostRecentlyModifiedFileMatchingPatternTest(tf.test.TestCase):\n         file_name = \"f.batch02.h5\"\n         test_dir = self.get_temp_dir()\n         file_path = os.path.join(test_dir, file_name)\n-        self.assertLen(os.listdir(test_dir), 0)\n+        self.assertEmpty(os.listdir(test_dir))\n         self.assertEqual(\n             keras.callbacks.ModelCheckpoint(\n                 None\n\n@@ -22,41 +22,52 @@ from keras import backend\n from keras.distribute import distributed_file_utils\n from keras.utils import mode_keys\n \n-# Constant for `tf.keras.Model` attribute to store the epoch at which the most\n-# recently saved checkpoint was saved.\n-CKPT_SAVED_EPOCH = \"_ckpt_saved_epoch\"\n-\n-CKPT_SAVED_EPOCH_UNUSED_VALUE = -1\n-\n \n class WorkerTrainingState:\n     \"\"\"Training state management class.\n \n     This class provides apis for backing up and restoring the training state.\n-    This allows model and epoch information to be saved periodically and restore\n-    for fault-tolerance, also known as preemption-recovery purpose.\n+    This allows model and epoch and batch information to be saved periodically\n+    and restore for fault-tolerance, also known as preemption-recovery purpose.\n     \"\"\"\n \n-    def __init__(self, model, checkpoint_dir):\n-        self._model = model\n+    # Constant for `tf.keras.Model` attribute to store the epoch and batch\n+    # at which the most recently saved checkpoint was saved.\n+    CKPT_SAVED_EPOCH_UNUSED_VALUE = -1\n \n-        # The epoch at which the checkpoint is saved. Used for fault-tolerance.\n-        # GPU device only has int64 dtype registered VarHandleOp.\n+    CKPT_SAVED_BATCH_UNUSED_VALUE = -1\n+\n+    def __init__(self, model, checkpoint_dir, save_freq=\"epoch\"):\n+        self._model = model\n+        self._save_freq = save_freq\n+        # The batch and epoch at which the checkpoint is saved. Used for\n+        # fault-tolerance. GPU device only has int64 dtype registered\n+        # VarHandleOp.\n         self._ckpt_saved_epoch = tf.Variable(\n             initial_value=tf.constant(\n-                CKPT_SAVED_EPOCH_UNUSED_VALUE, dtype=tf.int64\n+                self.CKPT_SAVED_EPOCH_UNUSED_VALUE, dtype=tf.int64\n             ),\n             name=\"ckpt_saved_epoch\",\n         )\n-\n+        self._ckpt_saved_batch = tf.Variable(\n+            initial_value=tf.constant(\n+                self.CKPT_SAVED_BATCH_UNUSED_VALUE, dtype=tf.int64\n+            ),\n+            name=\"ckpt_saved_batch\",\n+        )\n         # Variable initialization.\n-        backend.set_value(self._ckpt_saved_epoch, CKPT_SAVED_EPOCH_UNUSED_VALUE)\n-\n-        # _ckpt_saved_epoch gets tracked and is included in the checkpoint file\n-        # when backing up.\n+        backend.set_value(\n+            self._ckpt_saved_epoch, self.CKPT_SAVED_EPOCH_UNUSED_VALUE\n+        )\n+        backend.set_value(\n+            self._ckpt_saved_batch, self.CKPT_SAVED_BATCH_UNUSED_VALUE\n+        )\n+        # _ckpt_saved_epoch  and _ckpt_saved_batch gets tracked and is included in\n+        # the checkpoint file when backing up.\n         checkpoint = tf.train.Checkpoint(\n             model=self._model,\n             ckpt_saved_epoch=self._ckpt_saved_epoch,\n+            ckpt_saved_batch=self._ckpt_saved_batch,\n             train_counter=self._model._train_counter,\n         )\n \n@@ -86,14 +97,17 @@ class WorkerTrainingState:\n                 checkpoint, directory=write_checkpoint_dir, max_to_keep=1\n             )\n \n-    def back_up(self, epoch):\n+    def back_up(self, epoch, batch=0):\n         \"\"\"Back up the current state of training into a checkpoint file.\n \n         Args:\n           epoch: The current epoch information to be saved.\n+          batch: The current batch(step) information to be saved.\n         \"\"\"\n+        # Save the model plus CKPT_SAVED_EPOCH and CKPT_SAVED_BATCH variable.\n         backend.set_value(self._ckpt_saved_epoch, epoch)\n-        # Save the model plus CKPT_SAVED_EPOCH variable.\n+        backend.set_value(self._ckpt_saved_batch, batch)\n+\n         if self.write_checkpoint_manager.save():\n             distributed_file_utils.remove_temp_dirpath(\n                 self.write_checkpoint_manager.directory,\n@@ -122,7 +136,9 @@ class WorkerTrainingState:\n             except tf.errors.NotFoundError:\n                 pass\n \n-    def maybe_load_initial_epoch_from_ckpt(self, initial_epoch, mode):\n+    def maybe_load_initial_counters_from_ckpt(\n+        self, steps_per_epoch, initial_epoch, mode\n+    ):\n         \"\"\"Maybe load initial epoch from ckpt considering possible worker recovery.\n \n         When `_ckpt_saved_epoch` attribute exists and is not\n@@ -132,19 +148,36 @@ class WorkerTrainingState:\n         continue previous unfinished training from certain epoch.\n \n         Args:\n+          steps_per_epoch: The number of steps per epoch value.\n           initial_epoch: The original initial_epoch user passes in in `fit()`.\n           mode: The mode for running `model.fit()`.\n \n         Returns:\n           If the training is recovering from previous failure under multi-worker\n-          training setting, return the epoch the training is supposed to\n-          continue at. Otherwise, return the `initial_epoch` the user passes in.\n+          training setting, return the (epoch, step) the training is supposed to\n+          continue at. Otherwise, return the `initial_epoch, initial_step` the user\n+          passes in.\n         \"\"\"\n \n+        initial_step = 0\n         epoch = backend.eval(self._ckpt_saved_epoch)\n-        if mode == mode_keys.ModeKeys.TRAIN and epoch >= 0:\n+        batch = backend.eval(self._ckpt_saved_batch)\n+        if mode == mode_keys.ModeKeys.TRAIN:\n+            if self._save_freq == \"epoch\":\n+                if epoch >= 0:\n                     # The most recently saved epoch is one epoch prior to the epoch it\n-            # failed at, so return the value of 'self._ckpt_saved_epoch' plus\n-            # one.\n-            return epoch + 1\n-        return initial_epoch\n+                    # failed at, so return the value of 'self._ckpt_saved_epoch' plus one.\n+                    initial_epoch = epoch + 1\n+            else:\n+                if batch >= 0 and epoch >= 0:\n+                    # If the checkpoint was last saved at last batch of the epoch, return\n+                    # the next epoch number and batch=0\n+                    if batch == steps_per_epoch - 1:\n+                        initial_epoch = epoch + 1\n+                        initial_step = 0\n+                    else:\n+                        # If the checkpoint was not last saved at last batch of the epoch,\n+                        # return the same epoch and next batch number\n+                        initial_epoch = epoch\n+                        initial_step = batch + 1\n+        return (initial_epoch, initial_step)\n\n@@ -1365,6 +1365,7 @@ class DataHandler:\n     def steps(self):\n         \"\"\"Yields steps for the current epoch.\"\"\"\n         self._current_step = self._initial_step\n+        self._initial_step = 0\n         # `self._inferred_steps` can be changed by `catch_stop_iteration`.\n         while (\n             self._inferred_steps is None\n\n@@ -899,7 +899,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n           Boolean, whether the model should run eagerly.\n         \"\"\"\n         if (\n-            self.dynamic and self._run_eagerly is False\n+            self.dynamic and self._run_eagerly == False\n         ):  # pylint:disable=g-bool-id-comparison\n             # TODO(fchollet): consider using py_func to enable this.\n             raise ValueError(\n@@ -1541,15 +1541,21 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n             # Handle fault-tolerance for multi-worker.\n             # TODO(omalleyt): Fix the ordering issues that mean this has to\n             # happen after `callbacks.on_train_begin`.\n-            data_handler._initial_epoch = (  # pylint: disable=protected-access\n-                self._maybe_load_initial_epoch_from_ckpt(initial_epoch)\n+            steps_per_epoch_inferred = (\n+                steps_per_epoch or data_handler.inferred_steps\n+            )\n+            (\n+                data_handler._initial_epoch,\n+                data_handler._initial_step,\n+            ) = self._maybe_load_initial_counters_from_ckpt(  # pylint: disable=protected-access\n+                steps_per_epoch_inferred, initial_epoch\n             )\n             logs = None\n             for epoch, iterator in data_handler.enumerate_epochs():\n                 self.reset_metrics()\n                 callbacks.on_epoch_begin(epoch)\n                 with data_handler.catch_stop_iteration():\n-                    data_handler._initial_step = (\n+                    data_handler._initial_step = data_handler._initial_step or (\n                         self._maybe_load_initial_step_from_ckpt()\n                     )  # pylint: disable=protected-access\n                     for step in data_handler.steps():\n@@ -3501,26 +3507,31 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n                         \"distribution strategy scope.\"\n                     )\n \n-    def _maybe_load_initial_epoch_from_ckpt(self, initial_epoch):\n+    def _maybe_load_initial_counters_from_ckpt(\n+        self, steps_per_epoch, initial_epoch\n+    ):\n         \"\"\"Maybe load initial epoch from ckpt considering possible worker recovery.\n \n         Refer to tensorflow/python/keras/distribute/worker_training_state.py\n         for more information.\n \n         Args:\n-          initial_epoch: The original initial_epoch user passes in in `fit()`.\n+          steps_per_epoch: The number of step per epoch.\n+          initial_epoch: The original initial_epoch user passes in `fit()`.\n+          mode: The mode for running `model.fit()`.\n \n         Returns:\n           If the training is recovering from previous failure under multi-worker\n-          training setting, return the epoch the training is supposed to\n-          continue at. Otherwise, return the `initial_epoch` the user passes in.\n+          training setting, return the (epoch, step) the training is supposed to\n+          continue at. Otherwise, return the `initial_epoch, initial_step` the user\n+          passes in.\n         \"\"\"\n+        initial_step = 0\n         if self._training_state is not None:\n-            return self._training_state.maybe_load_initial_epoch_from_ckpt(\n-                initial_epoch, mode=ModeKeys.TRAIN\n+            return self._training_state.maybe_load_initial_counters_from_ckpt(\n+                steps_per_epoch, initial_epoch, mode=ModeKeys.TRAIN\n             )\n-\n-        return initial_epoch\n+        return (initial_epoch, initial_step)\n \n     def _maybe_load_initial_step_from_ckpt(self):\n         if getattr(self, \"_callback_step\", 0) > 0:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#53825c7d49c151b0c65c1be1286034c51c60a912", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 15 | Lines Deleted: 24 | Files Changed: 11 | Hunks: 12 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 39 | Churn Cumulative: 48469 | Contributors (this commit): 147 | Commits (past 90d): 102 | Contributors (cumulative): 232 | DMM Complexity: None\n\nDIFF:\n@@ -23,7 +23,7 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n-import keras  # pylint: disable=unused-import\n+import keras  # noqa: F401\n \n # isort: off\n from tensorflow.python.tools.api.generator import (\n\n@@ -45,7 +45,6 @@ from keras.utils import tf_inspect\n from tensorflow.core.protobuf import config_pb2\n from tensorflow.python.eager import context\n from tensorflow.python.eager.context import get_config\n-from tensorflow.python.framework import config\n from tensorflow.python.platform import tf_logging as logging\n from tensorflow.python.util.tf_export import keras_export\n from tensorflow.tools.docs import doc_controls\n\n@@ -51,12 +51,8 @@ from keras.utils import traceback_utils\n from keras.utils import version_utils\n \n # A module that only depends on `keras.layers` import these from here.\n-from keras.utils.generic_utils import (\n-    to_snake_case,  # pylint: disable=unused-import\n-)\n-from keras.utils.tf_utils import (\n-    is_tensor_or_tensor_list,  # pylint: disable=unused-import\n-)\n+from keras.utils.generic_utils import to_snake_case  # noqa: F401\n+from keras.utils.tf_utils import is_tensor_or_tensor_list  # noqa: F401\n \n # isort: off\n from google.protobuf import json_format\n\n@@ -41,12 +41,8 @@ from keras.utils import tf_inspect\n from keras.utils import tf_utils\n \n # A module that only depends on `keras.layers` import these from here.\n-from keras.utils.generic_utils import (\n-    to_snake_case,  # pylint: disable=unused-import\n-)\n-from keras.utils.tf_utils import (\n-    is_tensor_or_tensor_list,  # pylint: disable=unused-import\n-)\n+from keras.utils.generic_utils import to_snake_case  # noqa: F401\n+from keras.utils.tf_utils import is_tensor_or_tensor_list  # noqa: F401\n \n # isort: off\n from tensorflow.python.platform import tf_logging\n\n@@ -18,4 +18,4 @@\n Everything has been moved to keras/saving/. This file will be deleted soon.\n \"\"\"\n \n-from keras.saving import *  # pylint: disable=wildcard-import\n+from keras.saving import *  # noqa: F401\n\n@@ -15,8 +15,12 @@\n \"\"\"Layers that operate regularization via the addition of noise.\"\"\"\n # pylint: disable=g-bad-import-order,unused-import\n \n-from keras.layers.regularization.alpha_dropout import AlphaDropout\n+from keras.layers.regularization.alpha_dropout import AlphaDropout  # noqa: F401\n \n # Regularization layers imported for backwards namespace compatibility\n-from keras.layers.regularization.gaussian_dropout import GaussianDropout\n-from keras.layers.regularization.gaussian_noise import GaussianNoise\n+from keras.layers.regularization.gaussian_dropout import (  # noqa: F401,E501\n+    GaussianDropout,\n+)\n+from keras.layers.regularization.gaussian_noise import (  # noqa: F401,E501\n+    GaussianNoise,\n+)\n\n@@ -27,7 +27,6 @@ from keras.layers import convolutional\n from keras.layers import core\n from keras.layers import locally_connected\n from keras.layers import merging\n-from keras.layers import noise\n from keras.layers import pooling\n from keras.layers import regularization\n from keras.layers import reshaping\n\n@@ -46,8 +46,8 @@ from tensorflow.python.util.tf_export import keras_export\n \n try:\n     import scipy\n-    from scipy import linalg  # pylint: disable=unused-import\n-    from scipy import ndimage  # pylint: disable=unused-import\n+    from scipy import linalg  # noqa: F401\n+    from scipy import ndimage  # noqa: F401\n except ImportError:\n     pass\n try:\n\n@@ -16,7 +16,6 @@\n implementations.\"\"\"\n \n import copy\n-import inspect as _inspect\n import itertools\n import threading\n import types\n\n@@ -3,7 +3,6 @@\n import numpy as np\n import tensorflow.compat.v2 as tf\n \n-from keras.datasets import mnist\n from keras.testing_infra import test_utils\n from keras.utils import dataset_utils\n \n\n@@ -23,7 +23,6 @@ import numpy as np\n import tensorflow.compat.v2 as tf\n \n from keras.utils import io_utils\n-from keras.utils import tf_inspect\n \n # isort: off\n from tensorflow.python.util.tf_export import keras_export\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
