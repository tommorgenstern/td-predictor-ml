{"custom_id": "keras#a6d9edd838802fc2347a02ce645948f8a4c09eac", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 83 | Files Changed: 4 | Hunks: 14 | Methods Changed: 13 | Complexity Δ (Sum/Max): -21/0 | Churn Δ: 103 | Churn Cumulative: 1173 | Contributors (this commit): 11 | Commits (past 90d): 30 | Contributors (cumulative): 24 | DMM Complexity: 0.7636363636363637\n\nDIFF:\n@@ -1,12 +1,9 @@\n-import types\n-\n import jax\n import jax.experimental.sparse as jax_sparse\n import jax.numpy as jnp\n import ml_dtypes\n import numpy as np\n import tree\n-from jax.tree_util import Partial\n \n from keras.backend.common import KerasVariable\n from keras.backend.common import global_state\n@@ -139,16 +136,6 @@ def compute_output_spec(fn, *args, **kwargs):\n                             shape[i] = fill_value\n                 jax_tensor = jax.ShapeDtypeStruct(shape, dtype=x.dtype)\n                 return jax_tensor\n-            if isinstance(x, types.FunctionType):\n-\n-                def _fn(*args, **kwargs):\n-                    out = x(*args, **kwargs)\n-                    out = convert_keras_tensor_to_jax(\n-                        out, fill_value=fill_value\n-                    )\n-                    return out\n-\n-                return Partial(_fn)\n             if isinstance(x, dict):\n                 return {\n                     k: convert_keras_tensor_to_jax(v, fill_value=fill_value)\n\n@@ -1,5 +1,3 @@\n-import types\n-\n import numpy as np\n import tensorflow as tf\n from tensorflow.compiler.tf2xla.python.xla import dynamic_update_slice\n@@ -176,14 +174,6 @@ def compute_output_spec(fn, *args, **kwargs):\n                         return tf.compat.v1.placeholder(\n                             shape=x.shape, dtype=x.dtype\n                         )\n-                if isinstance(x, types.FunctionType):\n-\n-                    def _fn(*x_args, **x_kwargs):\n-                        out = x(*x_args, **x_kwargs)\n-                        out = convert_keras_tensor_to_tf(out)\n-                        return out\n-\n-                    return _fn\n                 return x\n \n             args, kwargs = tf.nest.map_structure(\n\n@@ -14,6 +14,7 @@ is_tensor\n \"\"\"\n \n import numpy as np\n+import tree\n \n from keras import backend\n from keras.api_export import keras_export\n@@ -514,13 +515,10 @@ class Cond(Operation):\n     @traceback_utils.filter_traceback\n     def __call__(self, *args, **kwargs):\n         def call_fn(*args, **kwargs):\n-            if not any_symbolic_tensors(args, kwargs):\n-                try:\n-                    return self.call(*args, **kwargs)\n-                except (TypeError, ValueError):\n-                    # fallback on symbolic case\n-                    pass\n+            if any_symbolic_tensors(args, kwargs):\n                 return self.symbolic_call(*args, **kwargs)\n+            else:\n+                return self.call(*args, **kwargs)\n \n         if traceback_utils.is_traceback_filtering_enabled():\n             # Wrap self.call to provide helpful info in case of exception\n@@ -537,11 +535,8 @@ class Cond(Operation):\n         return backend.core.cond(pred, true_fn, false_fn)\n \n     def compute_output_spec(self, pred, true_fn, false_fn):\n-        def call_fn(fn):\n-            return fn()\n-\n-        true_fn_spec = backend.compute_output_spec(call_fn, true_fn)\n-        false_fn_spec = backend.compute_output_spec(call_fn, false_fn)\n+        true_fn_spec = backend.compute_output_spec(true_fn)\n+        false_fn_spec = backend.compute_output_spec(false_fn)\n         if not self._check_output_spec(true_fn_spec, false_fn_spec):\n             raise ValueError(\n                 \"`true_fn` and `false_fn` should return outputs \"\n@@ -551,45 +546,18 @@ class Cond(Operation):\n         return true_fn_spec\n \n     def _check_output_spec(self, true_fn_spec, false_fn_spec):\n-        if true_fn_spec is None or false_fn_spec is None:\n-            return true_fn_spec is None and false_fn_spec is None\n-        elif isinstance(true_fn_spec, dict):\n-            if not isinstance(false_fn_spec, dict):\n-                return False\n-            if true_fn_spec.keys() != false_fn_spec.keys():\n-                return False\n-            if any(\n-                (not self._check_output_spec(true_fn_spec[k], false_fn_spec[k]))\n-                for k in true_fn_spec.keys()\n-            ):\n-                return False\n-        elif isinstance(true_fn_spec, list):\n-            if not isinstance(false_fn_spec, list):\n-                return False\n-            if len(true_fn_spec) != len(false_fn_spec):\n-                return False\n-            if any(\n-                (not self._check_output_spec(ti, fi))\n-                for ti, fi in zip(true_fn_spec, false_fn_spec)\n-            ):\n-                return False\n-        elif isinstance(true_fn_spec, tuple):\n-            if not isinstance(false_fn_spec, tuple):\n-                return False\n-            if len(true_fn_spec) != len(false_fn_spec):\n-                return False\n-            if any(\n-                (not self._check_output_spec(ti, fi))\n-                for ti, fi in zip(true_fn_spec, false_fn_spec)\n-            ):\n-                return False\n-        else:\n-            if true_fn_spec.dtype != false_fn_spec.dtype:\n-                return False\n-            if true_fn_spec.shape != false_fn_spec.shape:\n+        try:\n+            tree.assert_same_structure(true_fn_spec, false_fn_spec)\n+        except:\n             return False\n \n-        return True\n+        def check_leaf(t_spec, f_spec):\n+            if t_spec is None or f_spec is None:\n+                return t_spec is None and f_spec is None\n+            return t_spec.shape == f_spec.shape and t_spec.dtype == f_spec.dtype\n+\n+        same = tree.map_structure(check_leaf, true_fn_spec, false_fn_spec)\n+        return all(tree.flatten(same))\n \n \n @keras_export(\"keras.ops.cond\")\n\n@@ -423,14 +423,6 @@ class CoreOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         f = ops.cond(False, lambda: None, lambda: None)\n         self.assertEqual(f, None)\n \n-        for val in [True, False]:\n-            out = ops.cond(\n-                val,\n-                lambda: KerasTensor((16, 3)),\n-                lambda: KerasTensor((16, 3)),\n-            )\n-            self.assertEqual((16, 3), out.shape)\n-\n         out = ops.cond(\n             KerasTensor((), dtype=\"bool\"),\n             lambda: ops.ones((1, 3)),\n@@ -440,16 +432,16 @@ class CoreOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n \n         out = ops.cond(\n             KerasTensor((), dtype=\"bool\"),\n-            lambda: KerasTensor((3,)),\n-            lambda: KerasTensor((3,)),\n+            lambda: ops.ones((3,)),\n+            lambda: ops.zeros((3,)),\n         )\n         self.assertEqual((3,), out.shape)\n \n         with self.assertRaises(ValueError):\n             ops.cond(\n                 KerasTensor((), dtype=\"bool\"),\n-                lambda: KerasTensor((3,)),\n-                lambda: KerasTensor((4,)),\n+                lambda: ops.ones((3,)),\n+                lambda: ops.zeros((4,)),\n             )\n \n     def test_unstack(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9259a5a4848b2bf3e61f64a1c6f485d47302bae6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 474 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 3 | Methods Changed: 12 | Complexity Δ (Sum/Max): 23/17 | Churn Δ: 474 | Churn Cumulative: 2410 | Contributors (this commit): 24 | Commits (past 90d): 4 | Contributors (cumulative): 26 | DMM Complexity: 1.0\n\nDIFF:\n@@ -64,6 +64,7 @@ from keras.layers.pooling.global_max_pooling3d import GlobalMaxPooling3D\n from keras.layers.pooling.max_pooling1d import MaxPooling1D\n from keras.layers.pooling.max_pooling2d import MaxPooling2D\n from keras.layers.pooling.max_pooling3d import MaxPooling3D\n+from keras.layers.preprocessing.audio_preprocessing import MelSpectrogram\n from keras.layers.preprocessing.category_encoding import CategoryEncoding\n from keras.layers.preprocessing.center_crop import CenterCrop\n from keras.layers.preprocessing.discretization import Discretization\n\n@@ -0,0 +1,370 @@\n+from keras.api_export import keras_export\n+from keras.layers.preprocessing.tf_data_layer import TFDataLayer\n+\n+# mel spectrum constants.\n+_MEL_BREAK_FREQUENCY_HERTZ = 700.0\n+_MEL_HIGH_FREQUENCY_Q = 1127.0\n+\n+\n+@keras_export(\"keras.layers.MelSpectrogram\")\n+class MelSpectrogram(TFDataLayer):\n+    \"\"\"A preprocessing layer to convert raw audio signals to Mel spectrograms.\n+\n+    This layer takes `float32`/`float64` single or batched audio signal as\n+    inputs and computes the Mel spectrogram using Short-Time Fourier Transform\n+    and Mel scaling. The input should be a 1D (unbatched) or 2D (batched) tensor\n+    representing audio signals. The output will be a 2D or 3D tensor\n+    representing Mel spectrograms.\n+\n+    A spectrogram is an image-like representation that shows the frequency\n+    spectrum of a signal over time. It uses x-axis to represent time, y-axis to\n+    represent frequency, and each pixel to represent intensity.\n+    Mel spectrograms are a special type of spectrogram that use the mel scale,\n+    which approximates how humans perceive sound. They are commonly used in\n+    speech and music processing tasks like speech recognition, speaker\n+    identification, and music genre classification.\n+\n+    References:\n+    - [Spectrogram](https://en.wikipedia.org/wiki/Spectrogram),\n+    - [Mel scale](https://en.wikipedia.org/wiki/Mel_scale).\n+\n+    Examples:\n+\n+    **Unbatched audio signal**\n+\n+    >>> layer = keras.layers.MelSpectrogram(num_mel_bins=64,\n+    ...                                     sampling_rate=8000,\n+    ...                                     sequence_stride=256,\n+    ...                                     fft_length=2048)\n+    >>> layer(keras.random.uniform(shape=(16000,))).shape\n+    (64, 63)\n+\n+    **Batched audio signal**\n+\n+    >>> layer = keras.layers.MelSpectrogram(num_mel_bins=80,\n+    ...                                     sampling_rate=8000,\n+    ...                                     sequence_stride=128,\n+    ...                                     fft_length=2048)\n+    >>> layer(keras.random.uniform(shape=(2, 16000))).shape\n+    (2, 80, 125)\n+\n+    Input shape:\n+        1D (unbatched) or 2D (batched) tensor with shape:`(..., samples)`.\n+\n+    Output shape:\n+        2D (unbatched) or 3D (batched) tensor with\n+        shape:`(..., num_mel_bins, time)`.\n+\n+    Args:\n+        fft_length: Integer, size of the FFT window.\n+        sequence_stride: Integer, number of samples between successive STFT\n+            columns.\n+        sequence_length: Integer, size of the window used for applying\n+            `window` to each audio frame. If `None`, defaults to `fft_length`.\n+        window: String, name of the window function to use. Available values\n+            are `\"hann\"` and `\"hamming\"`. If `window` is a tensor, it will be\n+            used directly as the window and its length must be\n+            `sequence_length`. If `window` is `None`, no windowing is\n+            used. Defaults to `\"hann\"`.\n+        sampling_rate: Integer, sample rate of the input signal.\n+        num_mel_bins: Integer, number of mel bins to generate.\n+        min_freq: Float, minimum frequency of the mel bins.\n+        max_freq: Float, maximum frequency of the mel bins.\n+            If `None`, defaults to `sampling_rate / 2`.\n+        power_to_db: If True, convert the power spectrogram to decibels.\n+        top_db: Float, minimum negative cut-off `max(10 * log10(S)) - top_db`.\n+        mag_exp: Float, exponent for the magnitude spectrogram.\n+            1 for magnitude, 2 for power, etc. Default is 2.\n+        ref_power: Float, the power is scaled relative to it\n+            `10 * log10(S / ref_power)`.\n+        min_power: Float, minimum value for power and `ref_power`.\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        fft_length=2048,\n+        sequence_stride=512,\n+        sequence_length=None,\n+        window=\"hann\",\n+        sampling_rate=16000,\n+        num_mel_bins=128,\n+        min_freq=20.0,\n+        max_freq=None,\n+        power_to_db=True,\n+        top_db=80.0,\n+        mag_exp=2.0,\n+        min_power=1e-10,\n+        ref_power=1.0,\n+        **kwargs,\n+    ):\n+        self.fft_length = fft_length\n+        self.sequence_stride = sequence_stride\n+        self.sequence_length = sequence_length or fft_length\n+        self.window = window\n+        self.sampling_rate = sampling_rate\n+        self.num_mel_bins = num_mel_bins\n+        self.min_freq = min_freq\n+        self.max_freq = max_freq or int(sampling_rate / 2)\n+        self.power_to_db = power_to_db\n+        self.top_db = top_db\n+        self.mag_exp = mag_exp\n+        self.min_power = min_power\n+        self.ref_power = ref_power\n+        super().__init__(**kwargs)\n+\n+    def call(self, inputs):\n+        dtype = (\n+            \"float32\"\n+            if self.compute_dtype not in [\"float32\", \"float64\"]\n+            else self.compute_dtype\n+        )  # jax, tf supports only \"float32\" and \"float64\" in stft\n+        inputs = self.backend.convert_to_tensor(inputs, dtype=dtype)\n+        outputs = self._spectrogram(inputs)\n+        outputs = self._melscale(outputs)\n+        if self.power_to_db:\n+            outputs = self._dbscale(outputs)\n+        # swap time & freq axis to have shape of (..., num_mel_bins, time)\n+        outputs = self.backend.numpy.swapaxes(outputs, -1, -2)\n+        outputs = self.backend.cast(outputs, self.compute_dtype)\n+        return outputs\n+\n+    def _spectrogram(self, inputs):\n+        real, imag = self.backend.math.stft(\n+            inputs,\n+            sequence_length=self.sequence_length,\n+            sequence_stride=self.sequence_stride,\n+            fft_length=self.fft_length,\n+            window=self.window,\n+            center=True,\n+        )\n+        # abs of complex  = sqrt(real^2 + imag^2)\n+        spec = self.backend.numpy.sqrt(\n+            self.backend.numpy.add(\n+                self.backend.numpy.square(real), self.backend.numpy.square(imag)\n+            )\n+        )\n+        spec = self.backend.numpy.power(spec, self.mag_exp)\n+        return spec\n+\n+    def _melscale(self, inputs):\n+        matrix = self.linear_to_mel_weight_matrix(\n+            num_mel_bins=self.num_mel_bins,\n+            num_spectrogram_bins=self.backend.shape(inputs)[-1],\n+            sampling_rate=self.sampling_rate,\n+            lower_edge_hertz=self.min_freq,\n+            upper_edge_hertz=self.max_freq,\n+        )\n+        return self.backend.numpy.tensordot(inputs, matrix, axes=1)\n+\n+    def _dbscale(self, inputs):\n+        log_spec = 10.0 * (\n+            self.backend.numpy.log10(\n+                self.backend.numpy.maximum(inputs, self.min_power)\n+            )\n+        )\n+        ref_value = self.backend.numpy.abs(\n+            self.backend.convert_to_tensor(self.ref_power)\n+        )\n+        log_spec -= 10.0 * self.backend.numpy.log10(\n+            self.backend.numpy.maximum(ref_value, self.min_power)\n+        )\n+        log_spec = self.backend.numpy.maximum(\n+            log_spec, self.backend.numpy.max(log_spec) - self.top_db\n+        )\n+        return log_spec\n+\n+    def _hertz_to_mel(self, frequencies_hertz):\n+        \"\"\"Converts frequencies in `frequencies_hertz` in Hertz to the\n+            mel scale.\n+\n+        Args:\n+            frequencies_hertz: A tensor of frequencies in Hertz.\n+            name: An optional name for the operation.\n+\n+        Returns:\n+            A tensor of the same shape and type of `frequencies_hertz`\n+            containing frequencies in the mel scale.\n+        \"\"\"\n+        return _MEL_HIGH_FREQUENCY_Q * self.backend.numpy.log(\n+            1.0 + (frequencies_hertz / _MEL_BREAK_FREQUENCY_HERTZ)\n+        )\n+\n+    def linear_to_mel_weight_matrix(\n+        self,\n+        num_mel_bins=20,\n+        num_spectrogram_bins=129,\n+        sampling_rate=8000,\n+        lower_edge_hertz=125.0,\n+        upper_edge_hertz=3800.0,\n+        dtype=\"float32\",\n+    ):\n+        \"\"\"Returns a matrix to warp linear scale spectrograms to the mel scale.\n+\n+        Returns a weight matrix that can be used to re-weight a tensor\n+        containing `num_spectrogram_bins` linearly sampled frequency information\n+        from `[0, sampling_rate / 2]` into `num_mel_bins` frequency information\n+        from `[lower_edge_hertz, upper_edge_hertz]` on the mel scale.\n+\n+        This function follows the [Hidden Markov Model Toolkit (HTK)](\n+        http://htk.eng.cam.ac.uk/) convention, defining the mel scale in\n+        terms of a frequency in hertz according to the following formula:\n+\n+        ```mel(f) = 2595 * log10( 1 + f/700)```\n+\n+        In the returned matrix, all the triangles (filterbanks) have a peak\n+        value of 1.0.\n+\n+        For example, the returned matrix `A` can be used to right-multiply a\n+        spectrogram `S` of shape `[frames, num_spectrogram_bins]` of linear\n+        scale spectrum values (e.g. STFT magnitudes) to generate a\n+        \"mel spectrogram\" `M` of shape `[frames, num_mel_bins]`.\n+\n+        ```\n+        # `S` has shape [frames, num_spectrogram_bins]\n+        # `M` has shape [frames, num_mel_bins]\n+        M = keras.ops.matmul(S, A)\n+        ```\n+\n+        The matrix can be used with `keras.ops.tensordot` to convert an\n+        arbitrary rank `Tensor` of linear-scale spectral bins into the\n+        mel scale.\n+\n+        ```\n+        # S has shape [..., num_spectrogram_bins].\n+        # M has shape [..., num_mel_bins].\n+        M = keras.ops.tensordot(S, A, 1)\n+        ```\n+\n+        References:\n+        - [Mel scale (Wikipedia)](https://en.wikipedia.org/wiki/Mel_scale)\n+\n+        Args:\n+            num_mel_bins: Python int. How many bands in the resulting\n+                mel spectrum.\n+            num_spectrogram_bins: An integer `Tensor`. How many bins there are\n+                in the source spectrogram data, which is understood to be\n+                `fft_size // 2 + 1`, i.e. the spectrogram only contains the\n+                nonredundant FFT bins.\n+            sampling_rate: An integer or float `Tensor`. Samples per second of\n+                the input signal used to create the spectrogram. Used to figure\n+                out the frequencies corresponding to each spectrogram bin,\n+                which dictates how they are mapped into the mel scale.\n+            lower_edge_hertz: Python float. Lower bound on the frequencies to be\n+                included in the mel spectrum. This corresponds to the lower\n+                edge of the lowest triangular band.\n+            upper_edge_hertz: Python float. The desired top edge of the highest\n+                frequency band.\n+            dtype: The `DType` of the result matrix. Must be a floating point\n+                type.\n+\n+        Returns:\n+            A tensor of shape `[num_spectrogram_bins, num_mel_bins]`.\n+        \"\"\"\n+\n+        # This function can be constant folded by graph optimization since\n+        # there are no Tensor inputs.\n+        sampling_rate = self.backend.cast(sampling_rate, dtype)\n+        lower_edge_hertz = self.backend.convert_to_tensor(\n+            lower_edge_hertz,\n+            dtype,\n+        )\n+        upper_edge_hertz = self.backend.convert_to_tensor(\n+            upper_edge_hertz,\n+            dtype,\n+        )\n+        zero = self.backend.convert_to_tensor(0.0, dtype)\n+\n+        # HTK excludes the spectrogram DC bin.\n+        bands_to_zero = 1\n+        nyquist_hertz = sampling_rate / 2.0\n+        linear_frequencies = self.backend.numpy.linspace(\n+            zero, nyquist_hertz, num_spectrogram_bins\n+        )[bands_to_zero:]\n+        spectrogram_bins_mel = self.backend.numpy.expand_dims(\n+            self._hertz_to_mel(linear_frequencies), 1\n+        )\n+\n+        # Compute num_mel_bins triples of (lower_edge, center, upper_edge). The\n+        # center of each band is the lower and upper edge of the adjacent bands.\n+        # Accordingly, we divide [lower_edge_hertz, upper_edge_hertz] into\n+        # num_mel_bins + 2 pieces.\n+        band_edges_mel = self.backend.math.extract_sequences(\n+            self.backend.numpy.linspace(\n+                self._hertz_to_mel(lower_edge_hertz),\n+                self._hertz_to_mel(upper_edge_hertz),\n+                num_mel_bins + 2,\n+            ),\n+            sequence_length=3,\n+            sequence_stride=1,\n+        )\n+\n+        # Split the triples up and reshape them into [1, num_mel_bins] tensors.\n+        lower_edge_mel, center_mel, upper_edge_mel = tuple(\n+            self.backend.numpy.reshape(t, [1, num_mel_bins])\n+            for t in self.backend.numpy.split(band_edges_mel, 3, axis=1)\n+        )\n+\n+        # Calculate lower and upper slopes for every spectrogram bin.\n+        # Line segments are linear in the mel domain, not Hertz.\n+        lower_slopes = (spectrogram_bins_mel - lower_edge_mel) / (\n+            center_mel - lower_edge_mel\n+        )\n+        upper_slopes = (upper_edge_mel - spectrogram_bins_mel) / (\n+            upper_edge_mel - center_mel\n+        )\n+\n+        # Intersect the line segments with each other and zero.\n+        mel_weights_matrix = self.backend.numpy.maximum(\n+            zero, self.backend.numpy.minimum(lower_slopes, upper_slopes)\n+        )\n+\n+        # Re-add the zeroed lower bins we sliced out above.\n+        return self.backend.numpy.pad(\n+            mel_weights_matrix,\n+            [[bands_to_zero, 0], [0, 0]],\n+        )\n+\n+    def compute_output_shape(self, input_shape):\n+        if len(input_shape) == 1:\n+            output_shape = [\n+                self.num_mel_bins,\n+                (\n+                    (input_shape[0] + self.sequence_stride + 1)\n+                    // self.sequence_stride\n+                    if input_shape[0] is not None\n+                    else None\n+                ),\n+            ]\n+        else:\n+            output_shape = [\n+                input_shape[0],\n+                self.num_mel_bins,\n+                (\n+                    (input_shape[1] + self.sequence_stride + 1)\n+                    // self.sequence_stride\n+                    if input_shape[1] is not None\n+                    else None\n+                ),\n+            ]\n+        return output_shape\n+\n+    def get_config(self):\n+        config = super().get_config()\n+        config.update(\n+            {\n+                \"fft_length\": self.fft_length,\n+                \"sequence_stride\": self.sequence_stride,\n+                \"sequence_length\": self.sequence_length,\n+                \"window\": self.window,\n+                \"sampling_rate\": self.sampling_rate,\n+                \"num_mel_bins\": self.num_mel_bins,\n+                \"min_freq\": self.min_freq,\n+                \"max_freq\": self.max_freq,\n+                \"power_to_db\": self.power_to_db,\n+                \"top_db\": self.top_db,\n+                \"mag_exp\": self.mag_exp,\n+                \"min_power\": self.min_power,\n+                \"ref_power\": self.ref_power,\n+            }\n+        )\n+        return config\n\n@@ -0,0 +1,103 @@\n+import numpy as np\n+import pytest\n+from absl.testing import parameterized\n+from tensorflow import data as tf_data\n+\n+from keras import layers\n+from keras import testing\n+\n+\n+class MelSpectrogramTest(testing.TestCase, parameterized.TestCase):\n+    @pytest.mark.requires_trainable_backend\n+    def test_mel_spectrogram_basics(self):\n+        self.run_layer_test(\n+            layers.MelSpectrogram,\n+            init_kwargs={\n+                \"num_mel_bins\": 80,\n+                \"sampling_rate\": 8000,\n+                \"sequence_stride\": 128,\n+                \"fft_length\": 2048,\n+            },\n+            input_shape=(2, 16000),\n+            expected_output_shape=(2, 80, 126),\n+            expected_num_trainable_weights=0,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_seed_generators=0,\n+            expected_num_losses=0,\n+            supports_masking=False,\n+        )\n+        self.run_layer_test(\n+            layers.MelSpectrogram,\n+            init_kwargs={\n+                \"num_mel_bins\": 80,\n+                \"sampling_rate\": 8000,\n+                \"sequence_stride\": 128,\n+                \"fft_length\": 2048,\n+            },\n+            input_shape=(16000,),\n+            expected_output_shape=(80, 126),\n+            expected_num_trainable_weights=0,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_seed_generators=0,\n+            expected_num_losses=0,\n+            supports_masking=False,\n+        )\n+\n+    @parameterized.parameters(\n+        [\n+            ((2, 16000), 80, 128, 2048, 8000, False),\n+            ((16000,), 80, 128, 2048, 8000, False),\n+            ((2, 16001), 80, 128, 2048, 16000, False),\n+            ((16001,), 80, 128, 2048, 8000, False),\n+            ((2, 8000), 128, 64, 512, 32000, False),\n+            ((8000,), 128, 64, 512, 32000, False),\n+            ((2, 8000), 128, 64, 512, 32000, True),\n+            ((8000,), 128, 64, 512, 32000, True),\n+        ]\n+    )\n+    def test_output_shape(\n+        self,\n+        input_shape,\n+        num_mel_bins,\n+        sequence_stride,\n+        fft_length,\n+        sampling_rate,\n+        all_zero,\n+    ):\n+        if all_zero:\n+            audios = np.zeros(input_shape)\n+        else:\n+            audios = np.random.random(input_shape)\n+        out = layers.MelSpectrogram(\n+            num_mel_bins=num_mel_bins,\n+            sequence_stride=sequence_stride,\n+            fft_length=fft_length,\n+            sampling_rate=sampling_rate,\n+        )(audios)\n+        if len(input_shape) == 1:\n+            ref_shape = (\n+                num_mel_bins,\n+                (input_shape[0] + sequence_stride + 1) // sequence_stride,\n+            )\n+        else:\n+            ref_shape = (\n+                input_shape[0],\n+                num_mel_bins,\n+                (input_shape[1] + sequence_stride + 1) // sequence_stride,\n+            )\n+        self.assertEqual(tuple(out.shape), ref_shape)\n+\n+    def test_tf_data_compatibility(self):\n+        input_shape = (2, 16000)\n+        output_shape = (2, 80, 126)\n+        layer = layers.MelSpectrogram(\n+            num_mel_bins=80,\n+            sampling_rate=8000,\n+            sequence_stride=128,\n+            fft_length=2048,\n+        )\n+        input_data = np.random.random(input_shape)\n+        ds = tf_data.Dataset.from_tensor_slices(input_data).batch(2).map(layer)\n+        for output in ds.take(1):\n+            output = output.numpy()\n+        self.assertEqual(tuple(output.shape), output_shape)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4a0c829ee6815d80a1cb0737c3fe49dc9c530c7d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 421 | Contributors (this commit): 4 | Commits (past 90d): 1 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -9,6 +9,10 @@ from keras import testing\n \n class SpectralNormalizationTest(testing.TestCase):\n     @pytest.mark.requires_trainable_backend\n+    @pytest.mark.skipif(\n+        backend.backend() == \"tensorflow\",\n+        reason=\"TODO: test fails on GPU. XLA related.\",\n+    )\n     def test_basic_spectralnorm(self):\n         self.run_layer_test(\n             layers.SpectralNormalization,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1137074a9a1c237473f2fe57ab277c697892c6f1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 26 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 4/3 | Churn Δ: 26 | Churn Cumulative: 76 | Contributors (this commit): 1 | Commits (past 90d): 5 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -160,6 +160,21 @@ class Metric:\n             res = self.result()\n         return res\n \n+    def stateless_reset_state(self):\n+        # Call in stateless scope\n+        with backend.StatelessScope() as scope:\n+            self.reset_state()\n+\n+        # Gather updated variables\n+        metric_variables = []\n+        for v in self.variables:\n+            new_v = scope.get_current_value(v)\n+            if new_v is not None:\n+                metric_variables.append(new_v)\n+            else:\n+                metric_variables.append(v)\n+        return metric_variables\n+\n     @property\n     def dtype(self):\n         return self._dtype\n\n@@ -107,6 +107,17 @@ class MetricTest(testing.TestCase):\n         res = metric.stateless_result([ops.ones(()) * 12, ops.ones(()) * 3])\n         self.assertAllClose(res, 4.0)\n \n+    def test_stateless_reset_state(self):\n+        metric = ExampleMetric(name=\"mse\")\n+        num_samples = 20\n+        y_true = np.random.random((num_samples, 3))\n+        y_pred = np.random.random((num_samples, 3))\n+        metric.update_state(y_true, y_pred)\n+        vars = metric.stateless_reset_state()\n+        self.assertLen(vars, 2)\n+        self.assertEqual(vars[0], 0)\n+        self.assertEqual(vars[1], 0)\n+\n     def test_variable_tracking(self):\n         # In list\n         metric = ExampleMetric(name=\"mse\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#065e3c8c8a921978ac817dce5497f70c78bbcf5c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 9 | Churn Cumulative: 2787 | Contributors (this commit): 19 | Commits (past 90d): 3 | Contributors (cumulative): 22 | DMM Complexity: 0.0\n\nDIFF:\n@@ -503,6 +503,7 @@ def index_directory(\n     shuffle=True,\n     seed=None,\n     follow_links=False,\n+    verbose=True,\n ):\n     \"\"\"List all files in `directory`, with their labels.\n \n@@ -529,6 +530,8 @@ def index_directory(\n             If set to False, sorts the data in alphanumeric order.\n         seed: Optional random seed for shuffling.\n         follow_links: Whether to visits subdirectories pointed to by symlinks.\n+        verbose: Whether the function prints number of files found and classes.\n+            Default: True\n \n     Returns:\n         tuple (file_paths, labels, class_names).\n@@ -610,7 +613,7 @@ def index_directory(\n                 f\"in directory {directory}.\"\n             )\n         class_names = [str(label) for label in sorted(set(labels))]\n-\n+    if verbose:\n         if labels is None:\n             io_utils.print_msg(f\"Found {len(filenames)} files.\")\n         else:\n\n@@ -31,6 +31,7 @@ def image_dataset_from_directory(\n     follow_links=False,\n     crop_to_aspect_ratio=False,\n     data_format=None,\n+    verbose=True,\n ):\n     \"\"\"Generates a `tf.data.Dataset` from image files in a directory.\n \n@@ -115,6 +116,8 @@ def image_dataset_from_directory(\n             preserved.\n         data_format: If None uses keras.config.image_data_format()\n             otherwise either 'channel_last' or 'channel_first'.\n+        verbose: Whether the function prints number of files found and classes.\n+            Default: True\n \n     Returns:\n \n@@ -217,6 +220,7 @@ def image_dataset_from_directory(\n         shuffle=shuffle,\n         seed=seed,\n         follow_links=follow_links,\n+        verbose=verbose,\n     )\n \n     if label_mode == \"binary\" and len(class_names) != 2:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#dfa157319c0e6fa41162efd416ce10cd7a76b861", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 4 | Files Changed: 4 | Hunks: 9 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 16 | Churn Cumulative: 2839 | Contributors (this commit): 19 | Commits (past 90d): 7 | Contributors (cumulative): 24 | DMM Complexity: 0.0\n\nDIFF:\n@@ -23,6 +23,7 @@ def audio_dataset_from_directory(\n     validation_split=None,\n     subset=None,\n     follow_links=False,\n+    verbose=True,\n ):\n     \"\"\"Generates a `tf.data.Dataset` from audio files in a directory.\n \n@@ -90,6 +91,8 @@ def audio_dataset_from_directory(\n             `\"validation\"` or `\"both\"`. Only used if `validation_split` is set.\n         follow_links: Whether to visits subdirectories pointed to by symlinks.\n             Defaults to `False`.\n+        verbose: Whether to display number information on classes and\n+            number of files found. Defaults to `True`.\n \n     Returns:\n \n@@ -180,6 +183,7 @@ def audio_dataset_from_directory(\n         shuffle=shuffle,\n         seed=seed,\n         follow_links=follow_links,\n+        verbose=verbose,\n     )\n \n     if label_mode == \"binary\" and len(class_names) != 2:\n\n@@ -526,12 +526,12 @@ def index_directory(\n             list of class names (must match names of subdirectories). Used\n             to control the order of the classes\n             (otherwise alphanumerical order is used).\n-        shuffle: Whether to shuffle the data. Default: True.\n+        shuffle: Whether to shuffle the data. Defaults to `True`.\n             If set to False, sorts the data in alphanumeric order.\n         seed: Optional random seed for shuffling.\n         follow_links: Whether to visits subdirectories pointed to by symlinks.\n         verbose: Whether the function prints number of files found and classes.\n-            Default: True\n+            Defaults to `True`.\n \n     Returns:\n         tuple (file_paths, labels, class_names).\n\n@@ -116,8 +116,8 @@ def image_dataset_from_directory(\n             preserved.\n         data_format: If None uses keras.config.image_data_format()\n             otherwise either 'channel_last' or 'channel_first'.\n-        verbose: Whether the function prints number of files found and classes.\n-            Default: True\n+        verbose: Whether to display number information on classes and\n+            number of files found. Defaults to `True`.\n \n     Returns:\n \n\n@@ -23,6 +23,7 @@ def text_dataset_from_directory(\n     validation_split=None,\n     subset=None,\n     follow_links=False,\n+    verbose=True,\n ):\n     \"\"\"Generates a `tf.data.Dataset` from text files in a directory.\n \n@@ -88,6 +89,8 @@ def text_dataset_from_directory(\n             (the training and validation datasets respectively).\n         follow_links: Whether to visits subdirectories pointed to by symlinks.\n             Defaults to `False`.\n+        verbose: Whether to display number information on classes and\n+            number of files found. Defaults to `True`.\n \n     Returns:\n \n@@ -149,6 +152,7 @@ def text_dataset_from_directory(\n         shuffle=shuffle,\n         seed=seed,\n         follow_links=follow_links,\n+        verbose=verbose,\n     )\n \n     if label_mode == \"binary\" and len(class_names) != 2:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#94f062d4c5bcfa78e8cb56c17e7e0d7a39871f06", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 553 | Contributors (this commit): 4 | Commits (past 90d): 1 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -38,7 +38,8 @@ class CustomObjectScope:\n     ```\n \n     Args:\n-        custom_objects: Dictionary of `{name: object}` pairs.\n+        custom_objects: Dictionary of `{str: object}` pairs.\n+            Where the `str` key is the object name.\n     \"\"\"\n \n     def __init__(self, custom_objects):\n@@ -73,7 +74,7 @@ custom_object_scope = CustomObjectScope\n def get_custom_objects():\n     \"\"\"Retrieves a live reference to the global dictionary of custom objects.\n \n-    Custom objects set using using `custom_object_scope()` are not added to the\n+    Custom objects set using `custom_object_scope()` are not added to the\n     global dictionary of custom objects, and will not appear in the returned\n     dictionary.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0dcac0e7ce3ba2f2451f6effd6a94d125d4401b8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 557 | Contributors (this commit): 4 | Commits (past 90d): 2 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -38,8 +38,8 @@ class CustomObjectScope:\n     ```\n \n     Args:\n-        custom_objects: Dictionary of `{str: object}` pairs.\n-            Where the `str` key is the object name.\n+        custom_objects: Dictionary of `{str: object}` pairs,\n+            where the `str` key is the object name.\n     \"\"\"\n \n     def __init__(self, custom_objects):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ab1f4047fcb237ca70c2394e644b2d69cdddba37", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 87 | Lines Deleted: 41 | Files Changed: 4 | Hunks: 18 | Methods Changed: 4 | Complexity Δ (Sum/Max): 19/14 | Churn Δ: 128 | Churn Cumulative: 1828 | Contributors (this commit): 6 | Commits (past 90d): 8 | Contributors (cumulative): 11 | DMM Complexity: 0.0\n\nDIFF:\n@@ -40,30 +40,31 @@ def norm(x, ord=None, axis=None, keepdims=False):\n         axis = tuple(range(ndim))\n     elif isinstance(axis, int):\n         axis = (axis,)\n-\n+    if any(a < -ndim or a >= ndim for a in axis):\n+        raise ValueError(\n+            \"All `axis` values must be in the range [-ndim, ndim). \"\n+            f\"Received inputs with ndim={ndim}, while axis={axis}\"\n+        )\n     axis = axis[0] if len(axis) == 1 else axis\n     num_axes = 1 if isinstance(axis, int) else len(axis)\n \n-    if num_axes == 1 and ord is None:\n-        ord = \"euclidean\"\n-    elif num_axes == 2 and ord is None:\n-        ord = \"fro\"\n-\n     if standardize_dtype(x.dtype) == \"int64\":\n         dtype = config.floatx()\n     else:\n         dtype = dtypes.result_type(x.dtype, float)\n     x = cast(x, dtype)\n \n-    # Fast path to utilze `tf.linalg.norm`\n-    if (num_axes == 1 and ord in (\"euclidean\", 1, 2, float(\"inf\"))) or (\n-        num_axes == 2 and ord in (\"euclidean\", \"fro\", 1, 2, float(\"inf\"))\n-    ):\n-        return tf.linalg.norm(x, ord=ord, axis=axis, keepdims=keepdims)\n-\n     # Ref: jax.numpy.linalg.norm\n-    if num_axes == 1 and ord not in (\"fro\", \"nuc\"):\n-        if ord == float(\"-inf\"):\n+    if num_axes == 1:\n+        if ord is None or ord == 2:\n+            return tf.sqrt(\n+                tf.reduce_sum(x * tf.math.conj(x), axis=axis, keepdims=keepdims)\n+            )\n+        elif ord == float(\"inf\"):\n+            return tf.math.reduce_max(\n+                tf.math.abs(x), axis=axis, keepdims=keepdims\n+            )\n+        elif ord == float(\"-inf\"):\n             return tf.math.reduce_min(\n                 tf.math.abs(x), axis=axis, keepdims=keepdims\n             )\n@@ -73,22 +74,30 @@ def norm(x, ord=None, axis=None, keepdims=False):\n                 axis=axis,\n                 keepdims=keepdims,\n             )\n+        elif isinstance(ord, str):\n+            raise ValueError(\n+                f\"Invalid `ord` argument for vector norm. Received: ord={ord}\"\n+            )\n         else:\n             ord = convert_to_tensor(ord, dtype=x.dtype)\n             out = tf.math.reduce_sum(\n                 tf.pow(tf.math.abs(x), ord), axis=axis, keepdims=keepdims\n             )\n             return tf.pow(out, 1.0 / ord)\n-    elif num_axes == 2 and ord in (\"nuc\", float(\"-inf\"), -2, -1):\n+    elif num_axes == 2:\n         row_axis, col_axis = axis[0], axis[1]\n         row_axis = row_axis + ndim if row_axis < 0 else row_axis\n         col_axis = col_axis + ndim if col_axis < 0 else col_axis\n-        if ord == float(\"-inf\"):\n-            if not keepdims and row_axis > col_axis:\n-                row_axis -= 1\n-            x = tf.math.reduce_min(\n-                tf.reduce_sum(tf.math.abs(x), axis=col_axis, keepdims=keepdims),\n-                axis=row_axis,\n+        if ord is None or ord == \"fro\":\n+            return tf.sqrt(\n+                tf.reduce_sum(x * tf.math.conj(x), axis=axis, keepdims=keepdims)\n+            )\n+        elif ord == 1:\n+            if not keepdims and col_axis > row_axis:\n+                col_axis -= 1\n+            x = tf.math.reduce_max(\n+                tf.reduce_sum(tf.math.abs(x), axis=row_axis, keepdims=keepdims),\n+                axis=col_axis,\n                 keepdims=keepdims,\n             )\n         elif ord == -1:\n@@ -99,12 +108,32 @@ def norm(x, ord=None, axis=None, keepdims=False):\n                 axis=col_axis,\n                 keepdims=keepdims,\n             )\n-        else:\n+        elif ord == float(\"inf\"):\n+            if not keepdims and row_axis > col_axis:\n+                row_axis -= 1\n+            x = tf.math.reduce_max(\n+                tf.reduce_sum(tf.math.abs(x), axis=col_axis, keepdims=keepdims),\n+                axis=row_axis,\n+                keepdims=keepdims,\n+            )\n+        elif ord == float(\"-inf\"):\n+            if not keepdims and row_axis > col_axis:\n+                row_axis -= 1\n+            x = tf.math.reduce_min(\n+                tf.reduce_sum(tf.math.abs(x), axis=col_axis, keepdims=keepdims),\n+                axis=row_axis,\n+                keepdims=keepdims,\n+            )\n+        elif ord in (\"nuc\", 2, -2):\n             x = tfnp.moveaxis(x, axis, (-2, -1))\n             if ord == -2:\n                 x = tf.math.reduce_min(\n                     tf.linalg.svd(x, compute_uv=False), axis=-1\n                 )\n+            elif ord == 2:\n+                x = tf.math.reduce_max(\n+                    tf.linalg.svd(x, compute_uv=False), axis=-1\n+                )\n             else:\n                 x = tf.math.reduce_sum(\n                     tf.linalg.svd(x, compute_uv=False), axis=-1\n@@ -112,16 +141,11 @@ def norm(x, ord=None, axis=None, keepdims=False):\n             if keepdims:\n                 x = tf.expand_dims(x, axis[0])\n                 x = tf.expand_dims(x, axis[1])\n-        return x\n-\n-    if num_axes == 1:\n-        raise ValueError(\n-            f\"Invalid `ord` argument for vector norm. Received: ord={ord}\"\n-        )\n-    elif num_axes == 2:\n+        else:\n             raise ValueError(\n                 f\"Invalid `ord` argument for matrix norm. Received: ord={ord}\"\n             )\n+        return x\n     else:\n         raise ValueError(f\"Invalid axis values. Received: axis={axis}\")\n \n\n@@ -9,10 +9,6 @@ from keras import testing\n \n class SpectralNormalizationTest(testing.TestCase):\n     @pytest.mark.requires_trainable_backend\n-    @pytest.mark.skipif(\n-        backend.backend() == \"tensorflow\",\n-        reason=\"TODO: test fails on GPU. XLA related.\",\n-    )\n     def test_basic_spectralnorm(self):\n         self.run_layer_test(\n             layers.SpectralNormalization,\n\n@@ -294,7 +294,7 @@ def norm(x, ord=None, axis=None, keepdims=False):\n         - For matrices:\n             - `ord=None`: Frobenius norm\n             - `ord=\"fro\"`: Frobenius norm\n-            - `ord=nuc`: nuclear norm\n+            - `ord=\"nuc\"`: nuclear norm\n             - `ord=np.inf`: `max(sum(abs(x), axis=1))`\n             - `ord=-np.inf`: `min(sum(abs(x), axis=1))`\n             - `ord=0`: not supported\n@@ -306,7 +306,7 @@ def norm(x, ord=None, axis=None, keepdims=False):\n         - For vectors:\n             - `ord=None`: 2-norm\n             - `ord=\"fro\"`: not supported\n-            - `ord=nuc`: not supported\n+            - `ord=\"nuc\"`: not supported\n             - `ord=np.inf`: `max(abs(x))`\n             - `ord=-np.inf`: `min(abs(x))`\n             - `ord=0`: `sum(x != 0)`\n\n@@ -398,19 +398,45 @@ class LinalgOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n \n     @parameterized.named_parameters(\n         named_product(\n+            ndim=[1, 2],\n             ord=[None, \"fro\", \"nuc\", -np.inf, -2, -1, 0, 1, 2, np.inf, 3],\n-            axis=[None, 1, -1],\n+            axis=[None, 1, -1, (0, 1)],\n             keepdims=[False, True],\n         )\n     )\n-    def test_norm_vectors(self, ord, axis, keepdims):\n-        if axis is None:\n+    def test_norm(self, ndim, ord, axis, keepdims):\n+        if ndim == 1:\n             x = np.random.random((5,))\n         else:\n             x = np.random.random((5, 6))\n-        if ord in (\"fro\", \"nuc\"):\n-            error = RuntimeError if backend.backend() == \"torch\" else ValueError\n-            with self.assertRaises(error):\n+\n+        vector_norm = (ndim == 1) or isinstance(axis, int)\n+\n+        axis_out_of_bounds = ndim == 1 and (\n+            axis == 1 or isinstance(axis, tuple)\n+        )\n+        expected_error = None\n+        # when an out of bounds axis triggers an IndexError on torch is complex\n+        if (\n+            axis_out_of_bounds\n+            and (not isinstance(axis, tuple) or ord is None)\n+            and ord not in (\"fro\", \"nuc\")\n+        ):\n+            expected_error = IndexError\n+        elif (\n+            axis_out_of_bounds\n+            or (vector_norm and isinstance(axis, tuple))  # inv. axis for vector\n+            or (vector_norm and ord in (\"fro\", \"nuc\"))  # invalid ord for vector\n+            or (not vector_norm and ord in (0, 3))  # invalid ord for matrix\n+        ):\n+            expected_error = RuntimeError\n+\n+        if expected_error is not None:\n+            # Non-torch backends always throw a ValueError\n+            expected_error = (\n+                expected_error if backend.backend() == \"torch\" else ValueError\n+            )\n+            with self.assertRaises(expected_error):\n                 linalg.norm(x, ord=ord, axis=axis, keepdims=keepdims)\n             return\n         output = linalg.norm(x, ord=ord, axis=axis, keepdims=keepdims)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#93ce335a942e92681568e37d7ea008bec6ebb947", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 176 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -233,6 +233,7 @@ def gamma(shape, alpha, dtype=None, seed=None):\n     return backend.random.gamma(shape, alpha=alpha, dtype=dtype, seed=seed)\n \n \n+@keras_export(\"keras.random.binomial\")\n def binomial(shape, counts, probabilities, dtype=None, seed=None):\n     \"\"\"Draw samples from a Binomial distribution.\n \n@@ -268,6 +269,7 @@ def binomial(shape, counts, probabilities, dtype=None, seed=None):\n     )\n \n \n+@keras_export(\"keras.random.beta\")\n def beta(shape, alpha, beta, dtype=None, seed=None):\n     \"\"\"Draw samples from a Beta distribution.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9d58974a94964aba4deb5b16f1bec2cde3330135", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 6 | Churn Cumulative: 817 | Contributors (this commit): 4 | Commits (past 90d): 4 | Contributors (cumulative): 4 | DMM Complexity: 0.0\n\nDIFF:\n@@ -582,6 +582,12 @@ class TFSMLayer(Layer):\n         name=None,\n         dtype=None,\n     ):\n+        if backend.backend() != \"tensorflow\":\n+            raise NotImplementedError(\n+                \"The TFSMLayer is only currently supported with the \"\n+                \"TensorFlow backend.\"\n+            )\n+\n         # Initialize an empty layer, then add_weight() etc. as needed.\n         super().__init__(trainable=trainable, name=name, dtype=dtype)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
