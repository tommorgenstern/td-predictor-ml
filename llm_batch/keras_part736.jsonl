{"custom_id": "keras#f05c58619fd93b214887ae3d9b754c1bb320ac23", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 103 | Files Changed: 2 | Hunks: 3 | Methods Changed: 4 | Complexity Δ (Sum/Max): -14/0 | Churn Δ: 105 | Churn Cumulative: 1903 | Contributors (this commit): 9 | Commits (past 90d): 23 | Contributors (cumulative): 11 | DMM Complexity: 0.5783132530120482\n\nDIFF:\n@@ -266,10 +266,11 @@ def encode_categorical_inputs(\n     count_weights=None,\n ):\n     from keras_core import ops\n+    from keras_core import backend\n \n     \"\"\"Encodes categoical inputs according to output_mode.\"\"\"\n     if output_mode == \"int\":\n-        return ops.identity(ops.cast(inputs, dtype))\n+        return backend.convert_to_tensor(inputs, dtype=dtype)\n \n     original_shape = inputs.shape\n     # In all cases, we should uprank scalar input to a single sample.\n\n@@ -9,108 +9,6 @@ def expand_dims(inputs, axis):\n         return tf.expand_dims(inputs, axis)\n \n \n-def sparse_bincount(inputs, depth, binary_output, dtype, count_weights=None):\n-    \"\"\"Apply binary or count encoding to an input and return a sparse tensor.\"\"\"\n-    result = tf.sparse.bincount(\n-        inputs,\n-        weights=count_weights,\n-        minlength=depth,\n-        maxlength=depth,\n-        axis=-1,\n-        binary_output=binary_output,\n-    )\n-    result = tf.cast(result, dtype)\n-    if inputs.shape.rank == 1:\n-        output_shape = (depth,)\n-    else:\n-        batch_size = tf.shape(result)[0]\n-        output_shape = (batch_size, depth)\n-    result = tf.SparseTensor(\n-        indices=result.indices, values=result.values, dense_shape=output_shape\n-    )\n-    return result\n-\n-\n-def dense_bincount(inputs, depth, binary_output, dtype, count_weights=None):\n-    \"\"\"Apply binary or count encoding to an input.\"\"\"\n-    result = tf.math.bincount(\n-        inputs,\n-        weights=count_weights,\n-        minlength=depth,\n-        maxlength=depth,\n-        dtype=dtype,\n-        axis=-1,\n-        binary_output=binary_output,\n-    )\n-    if inputs.shape.rank == 1:\n-        result.set_shape(tf.TensorShape((depth,)))\n-    else:\n-        batch_size = inputs.shape.as_list()[0]\n-        result.set_shape(tf.TensorShape((batch_size, depth)))\n-    return result\n-\n-\n-def encode_categorical_inputs(\n-    inputs,\n-    output_mode,\n-    depth,\n-    dtype=\"float32\",\n-    sparse=False,\n-    count_weights=None,\n-    idf_weights=None,\n-):\n-    \"\"\"Encodes categoical inputs according to output_mode.\"\"\"\n-    if output_mode == \"int\":\n-        return tf.identity(tf.cast(inputs, dtype))\n-\n-    original_shape = inputs.shape\n-    # In all cases, we should uprank scalar input to a single sample.\n-    if inputs.shape.rank == 0:\n-        inputs = expand_dims(inputs, -1)\n-    # One hot will unprank only if the final output dimension is not already 1.\n-    if output_mode == \"one_hot\":\n-        if inputs.shape[-1] != 1:\n-            inputs = expand_dims(inputs, -1)\n-\n-    # TODO(b/190445202): remove output rank restriction.\n-    if inputs.shape.rank > 2:\n-        raise ValueError(\n-            \"When output_mode is not `'int'`, maximum supported output rank \"\n-            f\"is 2. Received output_mode {output_mode} and input shape \"\n-            f\"{original_shape}, \"\n-            f\"which would result in output rank {inputs.shape.rank}.\"\n-        )\n-\n-    binary_output = output_mode in (\"multi_hot\", \"one_hot\")\n-    if sparse:\n-        bincounts = sparse_bincount(\n-            inputs, depth, binary_output, dtype, count_weights\n-        )\n-    else:\n-        bincounts = dense_bincount(\n-            inputs, depth, binary_output, dtype, count_weights\n-        )\n-\n-    if output_mode != \"tf_idf\":\n-        return bincounts\n-\n-    if idf_weights is None:\n-        raise ValueError(\n-            \"When output mode is `'tf_idf'`, idf_weights must be provided. \"\n-            f\"Received: output_mode={output_mode} and idf_weights={idf_weights}\"\n-        )\n-\n-    if sparse:\n-        value_weights = tf.gather(idf_weights, bincounts.indices[:, -1])\n-        return tf.SparseTensor(\n-            bincounts.indices,\n-            value_weights * bincounts.values,\n-            bincounts.dense_shape,\n-        )\n-    else:\n-        return tf.multiply(tf.cast(bincounts, idf_weights.dtype), idf_weights)\n-\n-\n def get_tensor_spec(t, dynamic_batch=False, name=None):\n     \"\"\"Returns a `TensorSpec` given a single `Tensor` or `TensorSpec`.\"\"\"\n     if isinstance(t, tf.TypeSpec):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#61717d2ba94a54683edd60866b50b0f31671b352", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1653 | Contributors (this commit): 7 | Commits (past 90d): 15 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -265,8 +265,8 @@ def encode_categorical_inputs(\n     sparse=False,\n     count_weights=None,\n ):\n-    from keras_core import ops\n     from keras_core import backend\n+    from keras_core import ops\n \n     \"\"\"Encodes categoical inputs according to output_mode.\"\"\"\n     if output_mode == \"int\":\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cee60be6206fcaba203dead918b889e19b522e9a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1655 | Contributors (this commit): 7 | Commits (past 90d): 16 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -270,7 +270,7 @@ def encode_categorical_inputs(\n \n     \"\"\"Encodes categoical inputs according to output_mode.\"\"\"\n     if output_mode == \"int\":\n-        return backend.convert_to_tensor(inputs, dtype=dtype)\n+        return ops.cast(inputs, dtype=dtype)\n \n     original_shape = inputs.shape\n     # In all cases, we should uprank scalar input to a single sample.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ef045183310877ff47fb5cdb972a0033162c64ad", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 6 | Files Changed: 2 | Hunks: 6 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 1823 | Contributors (this commit): 8 | Commits (past 90d): 24 | Contributors (cumulative): 11 | DMM Complexity: 0.2\n\nDIFF:\n@@ -265,7 +265,6 @@ def encode_categorical_inputs(\n     sparse=False,\n     count_weights=None,\n ):\n-    from keras_core import backend\n     from keras_core import ops\n \n     \"\"\"Encodes categoical inputs according to output_mode.\"\"\"\n\n@@ -3,7 +3,6 @@ import os\n import numpy as np\n from tensorflow import data as tf_data\n \n-from keras_core import backend\n from keras_core import layers\n from keras_core import models\n from keras_core import testing\n@@ -41,7 +40,6 @@ class DicretizationTest(testing.TestCase):\n             bin_boundaries=[0.0, 0.5, 1.0], output_mode=\"int\"\n         )\n         output = layer(np.array([[-1.0, 0.0, 0.1, 0.8, 1.2]]))\n-        self.assertTrue(backend.is_tensor(output))\n         self.assertAllClose(output, np.array([[0, 1, 1, 2, 3]]))\n \n         # one_hot mode\n@@ -49,7 +47,6 @@ class DicretizationTest(testing.TestCase):\n             bin_boundaries=[0.0, 0.5, 1.0], output_mode=\"one_hot\"\n         )\n         output = layer(np.array([0.1, 0.8]))\n-        self.assertTrue(backend.is_tensor(output))\n         self.assertAllClose(output, np.array([[0, 1, 0, 0], [0, 0, 1, 0]]))\n \n         # multi_hot mode\n@@ -57,7 +54,6 @@ class DicretizationTest(testing.TestCase):\n             bin_boundaries=[0.0, 0.5, 1.0], output_mode=\"multi_hot\"\n         )\n         output = layer(np.array([[0.1, 0.8]]))\n-        self.assertTrue(backend.is_tensor(output))\n         self.assertAllClose(output, np.array([[0, 1, 1, 0]]))\n \n         # count mode\n@@ -65,7 +61,6 @@ class DicretizationTest(testing.TestCase):\n             bin_boundaries=[0.0, 0.5, 1.0], output_mode=\"count\"\n         )\n         output = layer(np.array([[0.1, 0.8, 0.9]]))\n-        self.assertTrue(backend.is_tensor(output))\n         self.assertAllClose(output, np.array([[0, 1, 2, 0]]))\n \n     def test_tf_data_compatibility(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a400bd6b19c7dc8d3b0785411a09ed2d14797b72", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 117 | Lines Deleted: 60 | Files Changed: 8 | Hunks: 31 | Methods Changed: 10 | Complexity Δ (Sum/Max): 1/5 | Churn Δ: 177 | Churn Cumulative: 5568 | Contributors (this commit): 20 | Commits (past 90d): 73 | Contributors (cumulative): 54 | DMM Complexity: 1.0\n\nDIFF:\n@@ -255,48 +255,3 @@ def compute_conv_transpose_output_shape(\n     else:\n         output_shape = [input_shape[0], filters] + output_shape\n     return output_shape\n-\n-\n-def encode_categorical_inputs(\n-    inputs,\n-    output_mode,\n-    depth,\n-    dtype=\"float32\",\n-    sparse=False,\n-    count_weights=None,\n-):\n-    from keras_core import ops\n-\n-    \"\"\"Encodes categoical inputs according to output_mode.\"\"\"\n-    if output_mode == \"int\":\n-        return ops.cast(inputs, dtype=dtype)\n-\n-    original_shape = inputs.shape\n-    # In all cases, we should uprank scalar input to a single sample.\n-    if len(ops.shape(inputs)) == 0:\n-        inputs = ops.expand_dims(inputs, -1)\n-    # One hot will unprank only if the final output dimension is not already 1.\n-    if output_mode == \"one_hot\":\n-        if ops.shape(inputs)[-1] != 1:\n-            inputs = ops.expand_dims(inputs, -1)\n-\n-    if len(ops.shape(inputs)) > 2:\n-        raise ValueError(\n-            \"When output_mode is not `'int'`, maximum supported output rank \"\n-            f\"is 2. Received output_mode {output_mode} and input shape \"\n-            f\"{original_shape}, \"\n-            f\"which would result in output rank {inputs.shape.rank}.\"\n-        )\n-\n-    binary_output = output_mode in (\"multi_hot\", \"one_hot\")\n-    bincounts = ops.bincount(\n-        inputs,\n-        weights=count_weights,\n-        minlength=depth,\n-    )\n-    if binary_output:\n-        one_hot_input = ops.one_hot(inputs, depth)\n-        bincounts = ops.where(ops.any(one_hot_input, axis=-2), 1, 0)\n-    bincounts = ops.cast(bincounts, dtype)\n-\n-    return bincounts\n\n@@ -1,8 +1,10 @@\n+import contextlib\n+\n import tree\n from jax import lax\n from jax import numpy as jnp\n \n-from keras_core.backend.common.stateless_scope import StatelessScope\n+from keras_core.backend.common import stateless_scope\n from keras_core.utils.nest import pack_sequence_as\n \n \n@@ -181,7 +183,12 @@ def rnn(\n \n             scan_xs = inputs\n \n-        with StatelessScope():\n+        if stateless_scope.in_stateless_scope():\n+            # Reuse the existing parent stateless scope.\n+            scope = contextlib.nullcontext()\n+        else:\n+            scope = stateless_scope.StatelessScope()\n+        with scope:\n             # We must use a stateless scope because `scan` will involve\n             # JAX tracing -- any variable update at this stage would\n             # be a leak.\n\n@@ -121,9 +121,12 @@ from keras_core.layers.rnn.conv_lstm1d import ConvLSTM1D\n from keras_core.layers.rnn.conv_lstm2d import ConvLSTM2D\n from keras_core.layers.rnn.conv_lstm3d import ConvLSTM3D\n from keras_core.layers.rnn.gru import GRU\n+from keras_core.layers.rnn.gru import GRUCell\n from keras_core.layers.rnn.lstm import LSTM\n+from keras_core.layers.rnn.lstm import LSTMCell\n from keras_core.layers.rnn.rnn import RNN\n from keras_core.layers.rnn.simple_rnn import SimpleRNN\n+from keras_core.layers.rnn.simple_rnn import SimpleRNNCell\n from keras_core.layers.rnn.stacked_rnn_cells import StackedRNNCells\n from keras_core.layers.rnn.time_distributed import TimeDistributed\n from keras_core.saving import serialization_lib\n\n@@ -1,23 +1,30 @@\n import numpy as np\n \n from keras_core import backend\n-from keras_core import ops\n from keras_core.api_export import keras_core_export\n-from keras_core.backend.common.backend_utils import encode_categorical_inputs\n-from keras_core.layers.preprocessing.tf_data_layer import TFDataLayer\n+from keras_core.layers.layer import Layer\n from keras_core.utils import argument_validation\n from keras_core.utils import backend_utils\n+from keras_core.utils import tf_utils\n from keras_core.utils.module_utils import tensorflow as tf\n \n \n @keras_core_export(\"keras_core.layers.Discretization\")\n-class Discretization(TFDataLayer):\n+class Discretization(Layer):\n     \"\"\"A preprocessing layer which buckets continuous features by ranges.\n \n     This layer will place each element of its input data into one of several\n     contiguous ranges and output an integer index indicating which range each\n     element was placed in.\n \n+    **Note:** This layer uses TensorFlow internally. It cannot\n+    be used as part of the compiled computation graph of a model with\n+    any backend other than TensorFlow.\n+    It can however be used with any backend when running eagerly.\n+    It can also always be used as part of an input preprocessing pipeline\n+    with any backend (outside the model itself), which is how we recommend\n+    to use this layer.\n+\n     **Note:** This layer is safe to use inside a `tf.data` pipeline\n     (independently of which backend you're using).\n \n@@ -71,14 +78,14 @@ class Discretization(TFDataLayer):\n \n     Examples:\n \n-    Discretize float values based on provided buckets.\n+    Bucketize float values based on provided buckets.\n     >>> input = np.array([[-1.5, 1.0, 3.4, .5], [0.0, 3.0, 1.3, 0.0]])\n     >>> layer = Discretization(bin_boundaries=[0., 1., 2.])\n     >>> layer(input)\n     array([[0, 2, 3, 1],\n            [1, 3, 2, 1]])\n \n-    Discretize float values based on a number of buckets to compute.\n+    Bucketize float values based on a number of buckets to compute.\n     >>> input = np.array([[-1.5, 1.0, 3.4, .5], [0.0, 3.0, 1.3, 0.0]])\n     >>> layer = Discretization(num_bins=4, epsilon=0.01)\n     >>> layer.adapt(input)\n@@ -234,18 +241,26 @@ class Discretization(TFDataLayer):\n         if not isinstance(\n             inputs,\n             (\n+                tf.Tensor,\n+                tf.SparseTensor,\n+                tf.RaggedTensor,\n                 np.ndarray,\n                 backend.KerasTensor,\n             ),\n         ):\n-            self._convert_input_args = True\n+            inputs = tf.convert_to_tensor(\n+                backend.convert_to_numpy(inputs), dtype=self.input_dtype\n+            )\n \n-        indices = ops.digitize(inputs, self.bin_boundaries)\n+        from keras_core.backend.tensorflow.numpy import digitize\n \n-        outputs = encode_categorical_inputs(\n+        indices = digitize(inputs, self.bin_boundaries)\n+\n+        outputs = tf_utils.encode_categorical_inputs(\n             indices,\n             output_mode=self.output_mode,\n             depth=len(self.bin_boundaries) + 1,\n+            sparse=self.sparse,\n             dtype=self.compute_dtype,\n         )\n         if (\n@@ -355,3 +370,7 @@ def compress_summary(summary, epsilon):\n     )\n     summary = np.stack((new_bins, new_weights))\n     return summary.astype(\"float32\")\n+\n+\n+def bucketize(inputs, boundaries):\n+    return tf.raw_ops.Bucketize(input=inputs, boundaries=boundaries)\n\n@@ -3,6 +3,7 @@ import os\n import numpy as np\n from tensorflow import data as tf_data\n \n+from keras_core import backend\n from keras_core import layers\n from keras_core import models\n from keras_core import testing\n@@ -40,6 +41,7 @@ class DicretizationTest(testing.TestCase):\n             bin_boundaries=[0.0, 0.5, 1.0], output_mode=\"int\"\n         )\n         output = layer(np.array([[-1.0, 0.0, 0.1, 0.8, 1.2]]))\n+        self.assertTrue(backend.is_tensor(output))\n         self.assertAllClose(output, np.array([[0, 1, 1, 2, 3]]))\n \n         # one_hot mode\n@@ -47,6 +49,7 @@ class DicretizationTest(testing.TestCase):\n             bin_boundaries=[0.0, 0.5, 1.0], output_mode=\"one_hot\"\n         )\n         output = layer(np.array([0.1, 0.8]))\n+        self.assertTrue(backend.is_tensor(output))\n         self.assertAllClose(output, np.array([[0, 1, 0, 0], [0, 0, 1, 0]]))\n \n         # multi_hot mode\n@@ -54,6 +57,7 @@ class DicretizationTest(testing.TestCase):\n             bin_boundaries=[0.0, 0.5, 1.0], output_mode=\"multi_hot\"\n         )\n         output = layer(np.array([[0.1, 0.8]]))\n+        self.assertTrue(backend.is_tensor(output))\n         self.assertAllClose(output, np.array([[0, 1, 1, 0]]))\n \n         # count mode\n@@ -61,13 +65,12 @@ class DicretizationTest(testing.TestCase):\n             bin_boundaries=[0.0, 0.5, 1.0], output_mode=\"count\"\n         )\n         output = layer(np.array([[0.1, 0.8, 0.9]]))\n+        self.assertTrue(backend.is_tensor(output))\n         self.assertAllClose(output, np.array([[0, 1, 2, 0]]))\n \n     def test_tf_data_compatibility(self):\n         # With fixed bins\n-        layer = layers.Discretization(\n-            bin_boundaries=[0.0, 0.35, 0.5, 1.0], dtype=\"float32\"\n-        )\n+        layer = layers.Discretization(bin_boundaries=[0.0, 0.35, 0.5, 1.0])\n         x = np.array([[-1.0, 0.0, 0.1, 0.2, 0.4, 0.5, 1.0, 1.2, 0.98]])\n         self.assertAllClose(layer(x), np.array([[0, 1, 1, 1, 2, 3, 4, 4, 3]]))\n         ds = tf_data.Dataset.from_tensor_slices(x).batch(1).map(layer)\n\n@@ -390,6 +390,10 @@ class RNN(Layer):\n             initial_state,\n         )\n \n+        # Prepopulate the dropout state so that the inner_loop is stateless\n+        # this is particularly important for JAX backend.\n+        self._maybe_config_dropout_masks(self.cell, sequences, initial_state)\n+\n         last_output, outputs, states = self.inner_loop(\n             sequences=sequences,\n             initial_state=initial_state,\n@@ -421,6 +425,20 @@ class RNN(Layer):\n             return output, *states\n         return output\n \n+    def _maybe_config_dropout_masks(self, cell, input_sequence, input_state):\n+        step_input = input_sequence[:, 0, :]\n+        state = (\n+            input_state[0]\n+            if isinstance(input_state, (list, tuple))\n+            else input_state\n+        )\n+        if isinstance(cell, DropoutRNNCell):\n+            cell.get_dropout_mask(step_input)\n+            cell.get_recurrent_dropout_mask(state)\n+        if isinstance(cell, StackedRNNCells):\n+            for c, s in zip(cell.cells, input_state):\n+                self._maybe_config_dropout_masks(c, input_sequence, s)\n+\n     def _maybe_reset_dropout_masks(self, cell):\n         if isinstance(cell, DropoutRNNCell):\n             cell.reset_dropout_mask()\n\n@@ -89,6 +89,7 @@ class StackedRNNCells(Layer):\n         # Call the cells in order and store the returned states.\n         new_states = []\n         for cell, states in zip(self.cells, states):\n+            state_is_list = tree.is_nested(states)\n             states = list(states) if tree.is_nested(states) else [states]\n             if isinstance(cell, Layer) and cell._call_has_training_arg:\n                 kwargs[\"training\"] = training\n@@ -96,7 +97,7 @@ class StackedRNNCells(Layer):\n                 kwargs.pop(\"training\", None)\n             cell_call_fn = cell.__call__ if callable(cell) else cell.call\n             inputs, states = cell_call_fn(inputs, states, **kwargs)\n-            if len(states) == 1:\n+            if len(states) == 1 and not state_is_list:\n                 states = states[0]\n             new_states.append(states)\n \n\n@@ -81,6 +81,57 @@ class StackedRNNTest(testing.TestCase):\n             supports_masking=True,\n             custom_objects={\"TwoStatesRNNCell\": TwoStatesRNNCell},\n         )\n+        self.run_layer_test(\n+            layers.RNN,\n+            init_kwargs={\n+                \"cell\": [\n+                    layers.SimpleRNNCell(3, dropout=0.1, recurrent_dropout=0.1),\n+                    layers.SimpleRNNCell(4, dropout=0.1, recurrent_dropout=0.1),\n+                    layers.SimpleRNNCell(5, dropout=0.1, recurrent_dropout=0.1),\n+                ],\n+                \"return_sequences\": True,\n+            },\n+            input_shape=(2, 3, 4),\n+            expected_output_shape=(2, 3, 5),\n+            expected_num_trainable_weights=9,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_seed_generators=0,\n+            supports_masking=True,\n+        )\n+        self.run_layer_test(\n+            layers.RNN,\n+            init_kwargs={\n+                \"cell\": [\n+                    layers.GRUCell(3, dropout=0.1, recurrent_dropout=0.1),\n+                    layers.GRUCell(4, dropout=0.1, recurrent_dropout=0.1),\n+                    layers.GRUCell(5, dropout=0.1, recurrent_dropout=0.1),\n+                ],\n+                \"return_sequences\": True,\n+            },\n+            input_shape=(2, 3, 4),\n+            expected_output_shape=(2, 3, 5),\n+            expected_num_trainable_weights=9,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_seed_generators=0,\n+            supports_masking=True,\n+        )\n+        self.run_layer_test(\n+            layers.RNN,\n+            init_kwargs={\n+                \"cell\": [\n+                    layers.LSTMCell(3, dropout=0.1, recurrent_dropout=0.1),\n+                    layers.LSTMCell(4, dropout=0.1, recurrent_dropout=0.1),\n+                    layers.LSTMCell(5, dropout=0.1, recurrent_dropout=0.1),\n+                ],\n+                \"return_sequences\": True,\n+            },\n+            input_shape=(2, 3, 4),\n+            expected_output_shape=(2, 3, 5),\n+            expected_num_trainable_weights=9,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_seed_generators=0,\n+            supports_masking=True,\n+        )\n \n     def test_correctness_single_state_stack(self):\n         sequence = np.arange(24).reshape((2, 3, 4)).astype(\"float32\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fa2bc17381792a603f39a7ffca605aed65ea2e0a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 24 | Files Changed: 4 | Hunks: 15 | Methods Changed: 8 | Complexity Δ (Sum/Max): 0/1 | Churn Δ: 44 | Churn Cumulative: 2233 | Contributors (this commit): 18 | Commits (past 90d): 34 | Contributors (cumulative): 28 | DMM Complexity: 1.0\n\nDIFF:\n@@ -576,8 +576,6 @@ def vstack(xs):\n \n \n def where(condition, x1, x2):\n-    x1 = convert_to_tensor(x1)\n-    x2 = convert_to_tensor(x2)\n     return jnp.where(condition, x1, x2)\n \n \n\n@@ -25,20 +25,20 @@ class Loss:\n     ```\n     \"\"\"\n \n-    def __init__(self, name=None, reduction=\"sum_over_batch_size\"):\n+    def __init__(self, name=None, reduction=\"sum_over_batch_size\", dtype=None):\n         self.name = name or auto_name(self.__class__.__name__)\n         self.reduction = standardize_reduction(reduction)\n+        self.dtype = dtype or backend.floatx()\n \n     def __call__(self, y_true, y_pred, sample_weight=None):\n         in_mask = getattr(y_pred, \"_keras_mask\", None)\n \n         with ops.name_scope(self.name):\n-            dtype = backend.floatx()\n             y_pred = tree.map_structure(\n-                lambda x: ops.convert_to_tensor(x, dtype=dtype), y_pred\n+                lambda x: ops.convert_to_tensor(x, dtype=self.dtype), y_pred\n             )\n             y_true = tree.map_structure(\n-                lambda x: ops.convert_to_tensor(x, dtype=dtype), y_true\n+                lambda x: ops.convert_to_tensor(x, dtype=self.dtype), y_true\n             )\n \n             losses = self.call(y_true, y_pred)\n@@ -58,6 +58,7 @@ class Loss:\n                 sample_weight=sample_weight,\n                 mask=mask,\n                 reduction=self.reduction,\n+                dtype=self.dtype,\n             )\n \n     def call(self, y_true, y_pred):\n@@ -119,30 +120,21 @@ def reduce_weighted_values(\n     sample_weight=None,\n     mask=None,\n     reduction=\"sum_over_batch_size\",\n+    dtype=None,\n ):\n     reduction = standardize_reduction(reduction)\n \n-    values = ops.convert_to_tensor(values)\n+    values = ops.convert_to_tensor(values, dtype=dtype)\n     if sample_weight is not None:\n-        sample_weight = ops.convert_to_tensor(sample_weight, dtype=values.dtype)\n+        sample_weight = ops.convert_to_tensor(sample_weight, dtype=dtype)\n     if mask is not None:\n-        mask = ops.convert_to_tensor(mask, dtype=values.dtype)\n+        mask = ops.convert_to_tensor(mask, dtype=dtype)\n \n     # Merge mask and sample weight into sample weight.\n     sample_weight = apply_mask(\n         sample_weight, mask, dtype=values.dtype, reduction=reduction\n     )\n \n-    # Convert any non float dtypes to floats, to avoid loss of precision\n-    # for dtype like int or bool.\n-    dtype = backend.standardize_dtype(values.dtype)\n-    if not dtype_utils.is_float(dtype):\n-        input_dtype = values.dtype\n-        values = ops.cast(values, \"float32\")\n-        input_casted = True\n-    else:\n-        input_casted = False\n-\n     if sample_weight is not None:\n         sample_weight = ops.cast(sample_weight, values.dtype)\n         # Update dimensions of `sample_weight` to match `losses`.\n@@ -151,10 +143,6 @@ def reduce_weighted_values(\n \n     # Apply reduction function to the individual weighted losses.\n     loss = reduce_values(values, reduction)\n-\n-    if input_casted:\n-        # Convert the result back to the input type.\n-        loss = ops.cast(loss, input_dtype)\n     return loss\n \n \n\n@@ -209,3 +209,13 @@ class LossTest(testing.TestCase):\n \n         with self.assertRaises(ValueError):\n             losses_module.get(\"typo\")\n+\n+    def test_dtype_arg(self):\n+        y_true = np.array([1.0, 0.0, 1.0, 0.0], dtype=\"float32\")\n+        y_pred = np.array([0.1, 0.2, 0.3, 0.4], dtype=\"float32\")\n+\n+        # Note: we use float16 and not float64 to test this because\n+        # JAX will map float64 to float32.\n+        loss_fn = ExampleLoss(dtype=\"float16\")\n+        loss = loss_fn(y_true, y_pred)\n+        self.assertEqual(backend.standardize_dtype(loss.dtype), \"float16\")\n\n@@ -329,7 +329,7 @@ class ImageOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         if data_format == \"channels_first\":\n             ref_out = np.transpose(ref_out, (0, 3, 1, 2))\n         self.assertEqual(tuple(out.shape), tuple(ref_out.shape))\n-        self.assertAllClose(ref_out, out, atol=0.3)\n+        self.assertAllClose(ref_out, out, atol=1e-3, rtol=1e-3)\n \n     @parameterized.parameters(\n         [\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#321534c775363229bc85452cd025b4764f19f133", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 83 | Lines Deleted: 173 | Files Changed: 14 | Hunks: 47 | Methods Changed: 20 | Complexity Δ (Sum/Max): -5/7 | Churn Δ: 256 | Churn Cumulative: 9603 | Contributors (this commit): 26 | Commits (past 90d): 131 | Contributors (cumulative): 94 | DMM Complexity: 0.0\n\nDIFF:\n@@ -255,3 +255,48 @@ def compute_conv_transpose_output_shape(\n     else:\n         output_shape = [input_shape[0], filters] + output_shape\n     return output_shape\n+\n+\n+def encode_categorical_inputs(\n+    inputs,\n+    output_mode,\n+    depth,\n+    dtype=\"float32\",\n+    sparse=False,\n+    count_weights=None,\n+):\n+    from keras_core import ops\n+\n+    \"\"\"Encodes categoical inputs according to output_mode.\"\"\"\n+    if output_mode == \"int\":\n+        return ops.cast(inputs, dtype=dtype)\n+\n+    original_shape = inputs.shape\n+    # In all cases, we should uprank scalar input to a single sample.\n+    if len(ops.shape(inputs)) == 0:\n+        inputs = ops.expand_dims(inputs, -1)\n+    # One hot will unprank only if the final output dimension is not already 1.\n+    if output_mode == \"one_hot\":\n+        if ops.shape(inputs)[-1] != 1:\n+            inputs = ops.expand_dims(inputs, -1)\n+\n+    if len(ops.shape(inputs)) > 2:\n+        raise ValueError(\n+            \"When output_mode is not `'int'`, maximum supported output rank \"\n+            f\"is 2. Received output_mode {output_mode} and input shape \"\n+            f\"{original_shape}, \"\n+            f\"which would result in output rank {inputs.shape.rank}.\"\n+        )\n+\n+    binary_output = output_mode in (\"multi_hot\", \"one_hot\")\n+    bincounts = ops.bincount(\n+        inputs,\n+        weights=count_weights,\n+        minlength=depth,\n+    )\n+    if binary_output:\n+        one_hot_input = ops.one_hot(inputs, depth)\n+        bincounts = ops.where(ops.any(one_hot_input, axis=-2), 1, 0)\n+    bincounts = ops.cast(bincounts, dtype)\n+\n+    return bincounts\n\n@@ -576,6 +576,8 @@ def vstack(xs):\n \n \n def where(condition, x1, x2):\n+    x1 = convert_to_tensor(x1)\n+    x2 = convert_to_tensor(x2)\n     return jnp.where(condition, x1, x2)\n \n \n\n@@ -1,10 +1,8 @@\n-import contextlib\n-\n import tree\n from jax import lax\n from jax import numpy as jnp\n \n-from keras_core.backend.common import stateless_scope\n+from keras_core.backend.common.stateless_scope import StatelessScope\n from keras_core.utils.nest import pack_sequence_as\n \n \n@@ -183,12 +181,7 @@ def rnn(\n \n             scan_xs = inputs\n \n-        if stateless_scope.in_stateless_scope():\n-            # Reuse the existing parent stateless scope.\n-            scope = contextlib.nullcontext()\n-        else:\n-            scope = stateless_scope.StatelessScope()\n-        with scope:\n+        with StatelessScope():\n             # We must use a stateless scope because `scan` will involve\n             # JAX tracing -- any variable update at this stage would\n             # be a leak.\n\n@@ -91,16 +91,6 @@ class ExportArchive:\n                 \"The export API is only compatible with JAX and TF backends.\"\n             )\n \n-        # TODO(nkovela): Make JAX version checking programatic.\n-        if backend.backend() == \"jax\":\n-            from jax import __version__ as jax_v\n-\n-            if jax_v > \"0.4.15\":\n-                raise ValueError(\n-                    \"The export API is only compatible with JAX version 0.4.15 \"\n-                    f\"and prior. Your JAX version: {jax_v}\"\n-                )\n-\n     @property\n     def variables(self):\n         return self._tf_trackable.variables\n\n@@ -1,6 +1,5 @@\n \"\"\"Tests for inference-only model/layer exporting utilities.\"\"\"\n import os\n-import sys\n \n import numpy as np\n import pytest\n@@ -29,10 +28,6 @@ def get_model():\n     backend.backend() not in (\"tensorflow\", \"jax\"),\n     reason=\"Export only currently supports the TF and JAX backends.\",\n )\n-@pytest.mark.skipif(\n-    backend.backend() == \"jax\" and sys.modules[\"jax\"].__version__ > \"0.4.15\",\n-    reason=\"The export API is only compatible with JAX version <= 0.4.15.\",\n-)\n class ExportArchiveTest(testing.TestCase):\n     def test_standard_model_export(self):\n         temp_filepath = os.path.join(self.get_temp_dir(), \"exported_model\")\n@@ -542,18 +537,6 @@ class ExportArchiveTest(testing.TestCase):\n         )\n \n \n-@pytest.mark.skipif(\n-    backend.backend() != \"jax\" or sys.modules[\"jax\"].__version__ <= \"0.4.15\",\n-    reason=\"This test is for invalid JAX versions, i.e. versions > 0.4.15.\",\n-)\n-class VersionTest(testing.TestCase):\n-    def test_invalid_jax_version(self):\n-        with self.assertRaisesRegex(\n-            ValueError, \"only compatible with JAX version\"\n-        ):\n-            _ = export_lib.ExportArchive()\n-\n-\n @pytest.mark.skipif(\n     backend.backend() != \"tensorflow\",\n     reason=\"TFSM Layer reloading is only for the TF backend.\",\n\n@@ -121,12 +121,9 @@ from keras_core.layers.rnn.conv_lstm1d import ConvLSTM1D\n from keras_core.layers.rnn.conv_lstm2d import ConvLSTM2D\n from keras_core.layers.rnn.conv_lstm3d import ConvLSTM3D\n from keras_core.layers.rnn.gru import GRU\n-from keras_core.layers.rnn.gru import GRUCell\n from keras_core.layers.rnn.lstm import LSTM\n-from keras_core.layers.rnn.lstm import LSTMCell\n from keras_core.layers.rnn.rnn import RNN\n from keras_core.layers.rnn.simple_rnn import SimpleRNN\n-from keras_core.layers.rnn.simple_rnn import SimpleRNNCell\n from keras_core.layers.rnn.stacked_rnn_cells import StackedRNNCells\n from keras_core.layers.rnn.time_distributed import TimeDistributed\n from keras_core.saving import serialization_lib\n\n@@ -1,30 +1,23 @@\n import numpy as np\n \n from keras_core import backend\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n-from keras_core.layers.layer import Layer\n+from keras_core.backend.common.backend_utils import encode_categorical_inputs\n+from keras_core.layers.preprocessing.tf_data_layer import TFDataLayer\n from keras_core.utils import argument_validation\n from keras_core.utils import backend_utils\n-from keras_core.utils import tf_utils\n from keras_core.utils.module_utils import tensorflow as tf\n \n \n @keras_core_export(\"keras_core.layers.Discretization\")\n-class Discretization(Layer):\n+class Discretization(TFDataLayer):\n     \"\"\"A preprocessing layer which buckets continuous features by ranges.\n \n     This layer will place each element of its input data into one of several\n     contiguous ranges and output an integer index indicating which range each\n     element was placed in.\n \n-    **Note:** This layer uses TensorFlow internally. It cannot\n-    be used as part of the compiled computation graph of a model with\n-    any backend other than TensorFlow.\n-    It can however be used with any backend when running eagerly.\n-    It can also always be used as part of an input preprocessing pipeline\n-    with any backend (outside the model itself), which is how we recommend\n-    to use this layer.\n-\n     **Note:** This layer is safe to use inside a `tf.data` pipeline\n     (independently of which backend you're using).\n \n@@ -78,14 +71,14 @@ class Discretization(Layer):\n \n     Examples:\n \n-    Bucketize float values based on provided buckets.\n+    Discretize float values based on provided buckets.\n     >>> input = np.array([[-1.5, 1.0, 3.4, .5], [0.0, 3.0, 1.3, 0.0]])\n     >>> layer = Discretization(bin_boundaries=[0., 1., 2.])\n     >>> layer(input)\n     array([[0, 2, 3, 1],\n            [1, 3, 2, 1]])\n \n-    Bucketize float values based on a number of buckets to compute.\n+    Discretize float values based on a number of buckets to compute.\n     >>> input = np.array([[-1.5, 1.0, 3.4, .5], [0.0, 3.0, 1.3, 0.0]])\n     >>> layer = Discretization(num_bins=4, epsilon=0.01)\n     >>> layer.adapt(input)\n@@ -238,29 +231,11 @@ class Discretization(Layer):\n         return\n \n     def call(self, inputs):\n-        if not isinstance(\n-            inputs,\n-            (\n-                tf.Tensor,\n-                tf.SparseTensor,\n-                tf.RaggedTensor,\n-                np.ndarray,\n-                backend.KerasTensor,\n-            ),\n-        ):\n-            inputs = tf.convert_to_tensor(\n-                backend.convert_to_numpy(inputs), dtype=self.input_dtype\n-            )\n-\n-        from keras_core.backend.tensorflow.numpy import digitize\n-\n-        indices = digitize(inputs, self.bin_boundaries)\n-\n-        outputs = tf_utils.encode_categorical_inputs(\n+        indices = ops.digitize(inputs, self.bin_boundaries)\n+        outputs = encode_categorical_inputs(\n             indices,\n             output_mode=self.output_mode,\n             depth=len(self.bin_boundaries) + 1,\n-            sparse=self.sparse,\n             dtype=self.compute_dtype,\n         )\n         if (\n@@ -370,7 +345,3 @@ def compress_summary(summary, epsilon):\n     )\n     summary = np.stack((new_bins, new_weights))\n     return summary.astype(\"float32\")\n-\n-\n-def bucketize(inputs, boundaries):\n-    return tf.raw_ops.Bucketize(input=inputs, boundaries=boundaries)\n\n@@ -3,7 +3,6 @@ import os\n import numpy as np\n from tensorflow import data as tf_data\n \n-from keras_core import backend\n from keras_core import layers\n from keras_core import models\n from keras_core import testing\n@@ -41,7 +40,6 @@ class DicretizationTest(testing.TestCase):\n             bin_boundaries=[0.0, 0.5, 1.0], output_mode=\"int\"\n         )\n         output = layer(np.array([[-1.0, 0.0, 0.1, 0.8, 1.2]]))\n-        self.assertTrue(backend.is_tensor(output))\n         self.assertAllClose(output, np.array([[0, 1, 1, 2, 3]]))\n \n         # one_hot mode\n@@ -49,7 +47,6 @@ class DicretizationTest(testing.TestCase):\n             bin_boundaries=[0.0, 0.5, 1.0], output_mode=\"one_hot\"\n         )\n         output = layer(np.array([0.1, 0.8]))\n-        self.assertTrue(backend.is_tensor(output))\n         self.assertAllClose(output, np.array([[0, 1, 0, 0], [0, 0, 1, 0]]))\n \n         # multi_hot mode\n@@ -57,7 +54,6 @@ class DicretizationTest(testing.TestCase):\n             bin_boundaries=[0.0, 0.5, 1.0], output_mode=\"multi_hot\"\n         )\n         output = layer(np.array([[0.1, 0.8]]))\n-        self.assertTrue(backend.is_tensor(output))\n         self.assertAllClose(output, np.array([[0, 1, 1, 0]]))\n \n         # count mode\n@@ -65,12 +61,13 @@ class DicretizationTest(testing.TestCase):\n             bin_boundaries=[0.0, 0.5, 1.0], output_mode=\"count\"\n         )\n         output = layer(np.array([[0.1, 0.8, 0.9]]))\n-        self.assertTrue(backend.is_tensor(output))\n         self.assertAllClose(output, np.array([[0, 1, 2, 0]]))\n \n     def test_tf_data_compatibility(self):\n         # With fixed bins\n-        layer = layers.Discretization(bin_boundaries=[0.0, 0.35, 0.5, 1.0])\n+        layer = layers.Discretization(\n+            bin_boundaries=[0.0, 0.35, 0.5, 1.0], dtype=\"float32\"\n+        )\n         x = np.array([[-1.0, 0.0, 0.1, 0.2, 0.4, 0.5, 1.0, 1.2, 0.98]])\n         self.assertAllClose(layer(x), np.array([[0, 1, 1, 1, 2, 3, 4, 4, 3]]))\n         ds = tf_data.Dataset.from_tensor_slices(x).batch(1).map(layer)\n\n@@ -390,10 +390,6 @@ class RNN(Layer):\n             initial_state,\n         )\n \n-        # Prepopulate the dropout state so that the inner_loop is stateless\n-        # this is particularly important for JAX backend.\n-        self._maybe_config_dropout_masks(self.cell, sequences, initial_state)\n-\n         last_output, outputs, states = self.inner_loop(\n             sequences=sequences,\n             initial_state=initial_state,\n@@ -425,20 +421,6 @@ class RNN(Layer):\n             return output, *states\n         return output\n \n-    def _maybe_config_dropout_masks(self, cell, input_sequence, input_state):\n-        step_input = input_sequence[:, 0, :]\n-        state = (\n-            input_state[0]\n-            if isinstance(input_state, (list, tuple))\n-            else input_state\n-        )\n-        if isinstance(cell, DropoutRNNCell):\n-            cell.get_dropout_mask(step_input)\n-            cell.get_recurrent_dropout_mask(state)\n-        if isinstance(cell, StackedRNNCells):\n-            for c, s in zip(cell.cells, input_state):\n-                self._maybe_config_dropout_masks(c, input_sequence, s)\n-\n     def _maybe_reset_dropout_masks(self, cell):\n         if isinstance(cell, DropoutRNNCell):\n             cell.reset_dropout_mask()\n\n@@ -89,7 +89,6 @@ class StackedRNNCells(Layer):\n         # Call the cells in order and store the returned states.\n         new_states = []\n         for cell, states in zip(self.cells, states):\n-            state_is_list = tree.is_nested(states)\n             states = list(states) if tree.is_nested(states) else [states]\n             if isinstance(cell, Layer) and cell._call_has_training_arg:\n                 kwargs[\"training\"] = training\n@@ -97,7 +96,7 @@ class StackedRNNCells(Layer):\n                 kwargs.pop(\"training\", None)\n             cell_call_fn = cell.__call__ if callable(cell) else cell.call\n             inputs, states = cell_call_fn(inputs, states, **kwargs)\n-            if len(states) == 1 and not state_is_list:\n+            if len(states) == 1:\n                 states = states[0]\n             new_states.append(states)\n \n\n@@ -81,57 +81,6 @@ class StackedRNNTest(testing.TestCase):\n             supports_masking=True,\n             custom_objects={\"TwoStatesRNNCell\": TwoStatesRNNCell},\n         )\n-        self.run_layer_test(\n-            layers.RNN,\n-            init_kwargs={\n-                \"cell\": [\n-                    layers.SimpleRNNCell(3, dropout=0.1, recurrent_dropout=0.1),\n-                    layers.SimpleRNNCell(4, dropout=0.1, recurrent_dropout=0.1),\n-                    layers.SimpleRNNCell(5, dropout=0.1, recurrent_dropout=0.1),\n-                ],\n-                \"return_sequences\": True,\n-            },\n-            input_shape=(2, 3, 4),\n-            expected_output_shape=(2, 3, 5),\n-            expected_num_trainable_weights=9,\n-            expected_num_non_trainable_weights=0,\n-            expected_num_seed_generators=0,\n-            supports_masking=True,\n-        )\n-        self.run_layer_test(\n-            layers.RNN,\n-            init_kwargs={\n-                \"cell\": [\n-                    layers.GRUCell(3, dropout=0.1, recurrent_dropout=0.1),\n-                    layers.GRUCell(4, dropout=0.1, recurrent_dropout=0.1),\n-                    layers.GRUCell(5, dropout=0.1, recurrent_dropout=0.1),\n-                ],\n-                \"return_sequences\": True,\n-            },\n-            input_shape=(2, 3, 4),\n-            expected_output_shape=(2, 3, 5),\n-            expected_num_trainable_weights=9,\n-            expected_num_non_trainable_weights=0,\n-            expected_num_seed_generators=0,\n-            supports_masking=True,\n-        )\n-        self.run_layer_test(\n-            layers.RNN,\n-            init_kwargs={\n-                \"cell\": [\n-                    layers.LSTMCell(3, dropout=0.1, recurrent_dropout=0.1),\n-                    layers.LSTMCell(4, dropout=0.1, recurrent_dropout=0.1),\n-                    layers.LSTMCell(5, dropout=0.1, recurrent_dropout=0.1),\n-                ],\n-                \"return_sequences\": True,\n-            },\n-            input_shape=(2, 3, 4),\n-            expected_output_shape=(2, 3, 5),\n-            expected_num_trainable_weights=9,\n-            expected_num_non_trainable_weights=0,\n-            expected_num_seed_generators=0,\n-            supports_masking=True,\n-        )\n \n     def test_correctness_single_state_stack(self):\n         sequence = np.arange(24).reshape((2, 3, 4)).astype(\"float32\")\n\n@@ -25,20 +25,20 @@ class Loss:\n     ```\n     \"\"\"\n \n-    def __init__(self, name=None, reduction=\"sum_over_batch_size\", dtype=None):\n+    def __init__(self, name=None, reduction=\"sum_over_batch_size\"):\n         self.name = name or auto_name(self.__class__.__name__)\n         self.reduction = standardize_reduction(reduction)\n-        self.dtype = dtype or backend.floatx()\n \n     def __call__(self, y_true, y_pred, sample_weight=None):\n         in_mask = getattr(y_pred, \"_keras_mask\", None)\n \n         with ops.name_scope(self.name):\n+            dtype = backend.floatx()\n             y_pred = tree.map_structure(\n-                lambda x: ops.convert_to_tensor(x, dtype=self.dtype), y_pred\n+                lambda x: ops.convert_to_tensor(x, dtype=dtype), y_pred\n             )\n             y_true = tree.map_structure(\n-                lambda x: ops.convert_to_tensor(x, dtype=self.dtype), y_true\n+                lambda x: ops.convert_to_tensor(x, dtype=dtype), y_true\n             )\n \n             losses = self.call(y_true, y_pred)\n@@ -58,7 +58,6 @@ class Loss:\n                 sample_weight=sample_weight,\n                 mask=mask,\n                 reduction=self.reduction,\n-                dtype=self.dtype,\n             )\n \n     def call(self, y_true, y_pred):\n@@ -120,21 +119,30 @@ def reduce_weighted_values(\n     sample_weight=None,\n     mask=None,\n     reduction=\"sum_over_batch_size\",\n-    dtype=None,\n ):\n     reduction = standardize_reduction(reduction)\n \n-    values = ops.convert_to_tensor(values, dtype=dtype)\n+    values = ops.convert_to_tensor(values)\n     if sample_weight is not None:\n-        sample_weight = ops.convert_to_tensor(sample_weight, dtype=dtype)\n+        sample_weight = ops.convert_to_tensor(sample_weight, dtype=values.dtype)\n     if mask is not None:\n-        mask = ops.convert_to_tensor(mask, dtype=dtype)\n+        mask = ops.convert_to_tensor(mask, dtype=values.dtype)\n \n     # Merge mask and sample weight into sample weight.\n     sample_weight = apply_mask(\n         sample_weight, mask, dtype=values.dtype, reduction=reduction\n     )\n \n+    # Convert any non float dtypes to floats, to avoid loss of precision\n+    # for dtype like int or bool.\n+    dtype = backend.standardize_dtype(values.dtype)\n+    if not dtype_utils.is_float(dtype):\n+        input_dtype = values.dtype\n+        values = ops.cast(values, \"float32\")\n+        input_casted = True\n+    else:\n+        input_casted = False\n+\n     if sample_weight is not None:\n         sample_weight = ops.cast(sample_weight, values.dtype)\n         # Update dimensions of `sample_weight` to match `losses`.\n@@ -143,6 +151,10 @@ def reduce_weighted_values(\n \n     # Apply reduction function to the individual weighted losses.\n     loss = reduce_values(values, reduction)\n+\n+    if input_casted:\n+        # Convert the result back to the input type.\n+        loss = ops.cast(loss, input_dtype)\n     return loss\n \n \n\n@@ -209,13 +209,3 @@ class LossTest(testing.TestCase):\n \n         with self.assertRaises(ValueError):\n             losses_module.get(\"typo\")\n-\n-    def test_dtype_arg(self):\n-        y_true = np.array([1.0, 0.0, 1.0, 0.0], dtype=\"float32\")\n-        y_pred = np.array([0.1, 0.2, 0.3, 0.4], dtype=\"float32\")\n-\n-        # Note: we use float16 and not float64 to test this because\n-        # JAX will map float64 to float32.\n-        loss_fn = ExampleLoss(dtype=\"float16\")\n-        loss = loss_fn(y_true, y_pred)\n-        self.assertEqual(backend.standardize_dtype(loss.dtype), \"float16\")\n\n@@ -329,7 +329,7 @@ class ImageOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         if data_format == \"channels_first\":\n             ref_out = np.transpose(ref_out, (0, 3, 1, 2))\n         self.assertEqual(tuple(out.shape), tuple(ref_out.shape))\n-        self.assertAllClose(ref_out, out, atol=1e-3, rtol=1e-3)\n+        self.assertAllClose(ref_out, out, atol=0.3)\n \n     @parameterized.parameters(\n         [\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#779496272da6caf169a71cba186bdc23d8b41bab", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 56 | Lines Deleted: 43 | Files Changed: 3 | Hunks: 17 | Methods Changed: 5 | Complexity Δ (Sum/Max): 5/7 | Churn Δ: 99 | Churn Cumulative: 3110 | Contributors (this commit): 10 | Commits (past 90d): 51 | Contributors (cumulative): 21 | DMM Complexity: 0.0\n\nDIFF:\n@@ -255,3 +255,48 @@ def compute_conv_transpose_output_shape(\n     else:\n         output_shape = [input_shape[0], filters] + output_shape\n     return output_shape\n+\n+\n+def encode_categorical_inputs(\n+    inputs,\n+    output_mode,\n+    depth,\n+    dtype=\"float32\",\n+    sparse=False,\n+    count_weights=None,\n+):\n+    from keras_core import ops\n+\n+    \"\"\"Encodes categoical inputs according to output_mode.\"\"\"\n+    if output_mode == \"int\":\n+        return ops.cast(inputs, dtype=dtype)\n+\n+    original_shape = inputs.shape\n+    # In all cases, we should uprank scalar input to a single sample.\n+    if len(ops.shape(inputs)) == 0:\n+        inputs = ops.expand_dims(inputs, -1)\n+    # One hot will unprank only if the final output dimension is not already 1.\n+    if output_mode == \"one_hot\":\n+        if ops.shape(inputs)[-1] != 1:\n+            inputs = ops.expand_dims(inputs, -1)\n+\n+    if len(ops.shape(inputs)) > 2:\n+        raise ValueError(\n+            \"When output_mode is not `'int'`, maximum supported output rank \"\n+            f\"is 2. Received output_mode {output_mode} and input shape \"\n+            f\"{original_shape}, \"\n+            f\"which would result in output rank {inputs.shape.rank}.\"\n+        )\n+\n+    binary_output = output_mode in (\"multi_hot\", \"one_hot\")\n+    bincounts = ops.bincount(\n+        inputs,\n+        weights=count_weights,\n+        minlength=depth,\n+    )\n+    if binary_output:\n+        one_hot_input = ops.one_hot(inputs, depth)\n+        bincounts = ops.where(ops.any(one_hot_input, axis=-2), 1, 0)\n+    bincounts = ops.cast(bincounts, dtype)\n+\n+    return bincounts\n\n@@ -1,30 +1,23 @@\n import numpy as np\n \n from keras_core import backend\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n-from keras_core.layers.layer import Layer\n+from keras_core.backend.common.backend_utils import encode_categorical_inputs\n+from keras_core.layers.preprocessing.tf_data_layer import TFDataLayer\n from keras_core.utils import argument_validation\n from keras_core.utils import backend_utils\n-from keras_core.utils import tf_utils\n from keras_core.utils.module_utils import tensorflow as tf\n \n \n @keras_core_export(\"keras_core.layers.Discretization\")\n-class Discretization(Layer):\n+class Discretization(TFDataLayer):\n     \"\"\"A preprocessing layer which buckets continuous features by ranges.\n \n     This layer will place each element of its input data into one of several\n     contiguous ranges and output an integer index indicating which range each\n     element was placed in.\n \n-    **Note:** This layer uses TensorFlow internally. It cannot\n-    be used as part of the compiled computation graph of a model with\n-    any backend other than TensorFlow.\n-    It can however be used with any backend when running eagerly.\n-    It can also always be used as part of an input preprocessing pipeline\n-    with any backend (outside the model itself), which is how we recommend\n-    to use this layer.\n-\n     **Note:** This layer is safe to use inside a `tf.data` pipeline\n     (independently of which backend you're using).\n \n@@ -78,14 +71,14 @@ class Discretization(Layer):\n \n     Examples:\n \n-    Bucketize float values based on provided buckets.\n+    Discretize float values based on provided buckets.\n     >>> input = np.array([[-1.5, 1.0, 3.4, .5], [0.0, 3.0, 1.3, 0.0]])\n     >>> layer = Discretization(bin_boundaries=[0., 1., 2.])\n     >>> layer(input)\n     array([[0, 2, 3, 1],\n            [1, 3, 2, 1]])\n \n-    Bucketize float values based on a number of buckets to compute.\n+    Discretize float values based on a number of buckets to compute.\n     >>> input = np.array([[-1.5, 1.0, 3.4, .5], [0.0, 3.0, 1.3, 0.0]])\n     >>> layer = Discretization(num_bins=4, epsilon=0.01)\n     >>> layer.adapt(input)\n@@ -238,29 +231,11 @@ class Discretization(Layer):\n         return\n \n     def call(self, inputs):\n-        if not isinstance(\n-            inputs,\n-            (\n-                tf.Tensor,\n-                tf.SparseTensor,\n-                tf.RaggedTensor,\n-                np.ndarray,\n-                backend.KerasTensor,\n-            ),\n-        ):\n-            inputs = tf.convert_to_tensor(\n-                backend.convert_to_numpy(inputs), dtype=self.input_dtype\n-            )\n-\n-        from keras_core.backend.tensorflow.numpy import digitize\n-\n-        indices = digitize(inputs, self.bin_boundaries)\n-\n-        outputs = tf_utils.encode_categorical_inputs(\n+        indices = ops.digitize(inputs, self.bin_boundaries)\n+        outputs = encode_categorical_inputs(\n             indices,\n             output_mode=self.output_mode,\n             depth=len(self.bin_boundaries) + 1,\n-            sparse=self.sparse,\n             dtype=self.compute_dtype,\n         )\n         if (\n@@ -370,7 +345,3 @@ def compress_summary(summary, epsilon):\n     )\n     summary = np.stack((new_bins, new_weights))\n     return summary.astype(\"float32\")\n-\n-\n-def bucketize(inputs, boundaries):\n-    return tf.raw_ops.Bucketize(input=inputs, boundaries=boundaries)\n\n@@ -3,7 +3,6 @@ import os\n import numpy as np\n from tensorflow import data as tf_data\n \n-from keras_core import backend\n from keras_core import layers\n from keras_core import models\n from keras_core import testing\n@@ -41,7 +40,6 @@ class DicretizationTest(testing.TestCase):\n             bin_boundaries=[0.0, 0.5, 1.0], output_mode=\"int\"\n         )\n         output = layer(np.array([[-1.0, 0.0, 0.1, 0.8, 1.2]]))\n-        self.assertTrue(backend.is_tensor(output))\n         self.assertAllClose(output, np.array([[0, 1, 1, 2, 3]]))\n \n         # one_hot mode\n@@ -49,7 +47,6 @@ class DicretizationTest(testing.TestCase):\n             bin_boundaries=[0.0, 0.5, 1.0], output_mode=\"one_hot\"\n         )\n         output = layer(np.array([0.1, 0.8]))\n-        self.assertTrue(backend.is_tensor(output))\n         self.assertAllClose(output, np.array([[0, 1, 0, 0], [0, 0, 1, 0]]))\n \n         # multi_hot mode\n@@ -57,7 +54,6 @@ class DicretizationTest(testing.TestCase):\n             bin_boundaries=[0.0, 0.5, 1.0], output_mode=\"multi_hot\"\n         )\n         output = layer(np.array([[0.1, 0.8]]))\n-        self.assertTrue(backend.is_tensor(output))\n         self.assertAllClose(output, np.array([[0, 1, 1, 0]]))\n \n         # count mode\n@@ -65,12 +61,13 @@ class DicretizationTest(testing.TestCase):\n             bin_boundaries=[0.0, 0.5, 1.0], output_mode=\"count\"\n         )\n         output = layer(np.array([[0.1, 0.8, 0.9]]))\n-        self.assertTrue(backend.is_tensor(output))\n         self.assertAllClose(output, np.array([[0, 1, 2, 0]]))\n \n     def test_tf_data_compatibility(self):\n         # With fixed bins\n-        layer = layers.Discretization(bin_boundaries=[0.0, 0.35, 0.5, 1.0])\n+        layer = layers.Discretization(\n+            bin_boundaries=[0.0, 0.35, 0.5, 1.0], dtype=\"float32\"\n+        )\n         x = np.array([[-1.0, 0.0, 0.1, 0.2, 0.4, 0.5, 1.0, 1.2, 0.98]])\n         self.assertAllClose(layer(x), np.array([[0, 1, 1, 1, 2, 3, 4, 4, 3]]))\n         ds = tf_data.Dataset.from_tensor_slices(x).batch(1).map(layer)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
