{"custom_id": "keras#e43af6c89cd6c4adecc21ad5fc05b21e7fa9477b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 1569 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 3 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1078,8 +1078,6 @@ class RandomRotationTest(keras_parameterized.TestCase):\n \n   def test_distribution_strategy(self):\n     \"\"\"Tests that RandomRotation can be created within distribution strategies.\n-\n-    And that replicas got the same random result.\n     \"\"\"\n     input_images = np.random.random((2, 5, 8, 3)).astype(np.float32)\n     with testing_utils.use_gpu():\n@@ -1089,7 +1087,6 @@ class RandomRotationTest(keras_parameterized.TestCase):\n         output = strat.run(lambda: layer(input_images, training=True))\n       values = output.values\n       self.assertAllEqual(2, len(values))\n-      self.assertAllClose(values[0], values[1], rtol=1e-5)\n \n   @testing_utils.run_v2_only\n   def test_config_with_custom_name(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d5289f16dc21afcf13023b42bb45f4edc1dcbee0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 188 | Lines Deleted: 208 | Files Changed: 18 | Hunks: 62 | Methods Changed: 37 | Complexity Δ (Sum/Max): -4/9 | Churn Δ: 396 | Churn Cumulative: 38869 | Contributors (this commit): 134 | Commits (past 90d): 57 | Contributors (cumulative): 191 | DMM Complexity: 1.0\n\nDIFF:\n@@ -262,7 +262,7 @@ def MobileNetV3(stack_fn,\n     se_ratio = 0.25\n \n   x = img_input\n-  x = layers.Rescaling(1. / 255.)(x)\n+  x = layers.Rescaling(scale=1. / 127.5, offset=-1.)(x)\n   x = layers.Conv2D(\n       16,\n       kernel_size=3,\n\n@@ -58,7 +58,6 @@ from keras.utils import version_utils\n # A module that only depends on `keras.layers` import these from here.\n from keras.utils.generic_utils import to_snake_case  # pylint: disable=unused-import\n from keras.utils.tf_utils import is_tensor_or_tensor_list  # pylint: disable=unused-import\n-from tensorflow.python.ops import resource_variable_ops\n from tensorflow.python.platform import tf_logging\n from tensorflow.python.training.tracking import base as trackable\n from tensorflow.python.training.tracking import data_structures\n@@ -2856,12 +2855,8 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n     # TODO(b/125122625): This won't pick up on any variables added to a\n     # list/dict after creation.\n     for val in tf.nest.flatten(value, expand_composites=True):\n-      # TODO(b/126450014): Remove `_UnreadVariable` check here when assign ops\n-      # no longer return True for isinstance Variable checks.\n       if not isinstance(val, tf.Variable):\n         continue\n-      if isinstance(val, resource_variable_ops._UnreadVariable):  # pylint: disable=protected-access\n-        continue\n \n       # Users may add extra weights/variables\n       # simply by assigning them to attributes (invalid for graph networks)\n\n@@ -1119,19 +1119,6 @@ class NestedTrackingTest(tf.test.TestCase):\n     del l.a\n     self.assertEqual([], l._self_tracked_trackables)\n \n-  def test_assign_op_not_tracked_as_variable(self):\n-\n-    class LayerWithAssignAttr(base_layer.Layer):\n-\n-      def build(self, input_shape):\n-        self.v = tf.Variable(1.)\n-        self.v_assign = self.v.assign_add(2.)\n-\n-    layer = LayerWithAssignAttr()\n-    layer.build((10, 10))\n-\n-    self.assertEqual([layer.v], layer.variables)\n-\n   def test_layer_class_not_tracked_as_sublayer(self):\n     # See https://github.com/tensorflow/tensorflow/issues/27431 for details.\n \n\n@@ -51,7 +51,6 @@ from keras.utils import tf_utils\n # A module that only depends on `keras.layers` import these from here.\n from keras.utils.generic_utils import to_snake_case  # pylint: disable=unused-import\n from keras.utils.tf_utils import is_tensor_or_tensor_list  # pylint: disable=unused-import\n-from tensorflow.python.ops import resource_variable_ops\n from tensorflow.python.platform import tf_logging\n from tensorflow.python.training.tracking import base as trackable\n from tensorflow.python.training.tracking import data_structures\n@@ -2226,12 +2225,8 @@ class Layer(base_layer.Layer):\n     # TODO(b/125122625): This won't pick up on any variables added to a\n     # list/dict after creation.\n     for val in tf.nest.flatten(value):\n-      # TODO(b/126450014): Remove `_UnreadVariable` check here when assign ops\n-      # no longer return True for isinstance Variable checks.\n       if not isinstance(val, tf.Variable):\n         continue\n-      if isinstance(val, resource_variable_ops._UnreadVariable):  # pylint: disable=protected-access\n-        continue\n \n       # Users may add extra weights/variables\n       # simply by assigning them to attributes (invalid for graph networks)\n\n@@ -2138,16 +2138,6 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n         session = None\n       else:\n         session = backend.get_session()\n-      optimizer = getattr(self, 'optimizer', None)\n-      if (optimizer\n-          and not isinstance(optimizer, tf.__internal__.tracking.Trackable)):\n-        logging.warning(\n-            ('This model was compiled with a Keras optimizer (%s) but is being '\n-             'saved in TensorFlow format with `save_weights`. The model\\'s '\n-             'weights will be saved, but unlike with TensorFlow optimizers in '\n-             'the TensorFlow format the optimizer\\'s state will not be '\n-             'saved.\\n\\nConsider using a TensorFlow optimizer from `tf.train`.')\n-            % (optimizer,))\n       self._trackable_saver.save(filepath, session=session, options=options)\n       # Record this checkpoint so it's visible from tf.train.latest_checkpoint.\n       checkpoint_management.update_checkpoint_state_internal(\n\n@@ -373,6 +373,20 @@ class MergeLayersTestNoExecution(tf.test.TestCase):\n     mask = layer.output_mask\n     self.assertListEqual(mask.shape.as_list(), [None, 4])\n \n+  def test_merge_concatenate_sparse_shape(self):\n+    i1 = keras.layers.Input(shape=(1,), batch_size=2, sparse=True)\n+    i2 = keras.layers.Input(shape=(2,), batch_size=2, sparse=True)\n+    layer = keras.layers.Concatenate(axis=1)\n+    o = layer([i1, i2])\n+    self.assertListEqual(o.shape.as_list(), [2, 3])\n+\n+    # Make sure it also respect None as the batch size\n+    i1 = keras.layers.Input(shape=(1,), sparse=True)\n+    i2 = keras.layers.Input(shape=(2,), sparse=True)\n+    layer = keras.layers.Concatenate(axis=1)\n+    o = layer([i1, i2])\n+    self.assertListEqual(o.shape.as_list(), [None, 3])\n+\n   def test_user_changes_to_input_structure(self):\n     a = keras.layers.Input(shape=(4, 5))\n     struct = [a, a]\n\n@@ -34,6 +34,7 @@ from keras.layers import advanced_activations\n from keras.layers import core\n from keras.layers import einsum_dense\n from keras.utils import tf_utils\n+from tensorflow.python.platform import tf_logging as logging\n from tensorflow.python.util.tf_export import keras_export\n \n \n@@ -242,6 +243,7 @@ class MultiHeadAttention(Layer):\n     else:\n       self._attention_axes = attention_axes\n     self._built_from_signature = False\n+    self._query_shape, self._key_shape, self._value_shape = None, None, None\n \n   def get_config(self):\n     config = {\n@@ -272,11 +274,32 @@ class MultiHeadAttention(Layer):\n         \"kernel_constraint\":\n             constraints.serialize(self._kernel_constraint),\n         \"bias_constraint\":\n-            constraints.serialize(self._bias_constraint)\n+            constraints.serialize(self._bias_constraint),\n+        \"query_shape\": self._query_shape,\n+        \"key_shape\": self._key_shape,\n+        \"value_shape\": self._value_shape,\n     }\n     base_config = super(MultiHeadAttention, self).get_config()\n     return dict(list(base_config.items()) + list(config.items()))\n \n+  @classmethod\n+  def from_config(cls, config):\n+    # If the layer has a different build() function from the Keras default,\n+    # we need to trigger the customized build to create weights.\n+    query_shape = config.pop(\"query_shape\")\n+    key_shape = config.pop(\"key_shape\")\n+    value_shape = config.pop(\"value_shape\")\n+    layer = cls(**config)\n+    if None in [query_shape, key_shape, value_shape]:\n+      logging.warning(\n+          \"One of the input shape is missing. They should be \"\n+          \"memorized when the layer was serialized. \"\n+          \"%s is created without weights.\",\n+          str(cls))\n+    else:\n+      layer._build_from_signature(query_shape, value_shape, key_shape)  # pylint: disable=protected-access\n+    return layer\n+\n   def _build_from_signature(self, query, value, key=None):\n     \"\"\"Builds layers and variables.\n \n@@ -289,19 +312,19 @@ class MultiHeadAttention(Layer):\n     \"\"\"\n     self._built_from_signature = True\n     if hasattr(query, \"shape\"):\n-      query_shape = tf.TensorShape(query.shape)\n+      self._query_shape = tf.TensorShape(query.shape)\n     else:\n-      query_shape = query\n+      self._query_shape = tf.TensorShape(query)\n     if hasattr(value, \"shape\"):\n-      value_shape = tf.TensorShape(value.shape)\n+      self._value_shape = tf.TensorShape(value.shape)\n     else:\n-      value_shape = value\n+      self._value_shape = tf.TensorShape(value)\n     if key is None:\n-      key_shape = value_shape\n+      self._key_shape = self._value_shape\n     elif hasattr(key, \"shape\"):\n-      key_shape = tf.TensorShape(key.shape)\n+      self._key_shape = tf.TensorShape(key.shape)\n     else:\n-      key_shape = key\n+      self._key_shape = tf.TensorShape(key)\n \n     common_kwargs = dict(\n         kernel_initializer=self._kernel_initializer,\n@@ -315,7 +338,7 @@ class MultiHeadAttention(Layer):\n     # to avoid creating symbolic Tensors that will later pollute any eager\n     # operations.\n     with tf_utils.maybe_init_scope(self):\n-      free_dims = query_shape.rank - 1\n+      free_dims = self._query_shape.rank - 1\n       einsum_equation, bias_axes, output_rank = _build_proj_equation(\n           free_dims, bound_dims=1, output_dims=2)\n       self._query_dense = einsum_dense.EinsumDense(\n@@ -326,7 +349,7 @@ class MultiHeadAttention(Layer):\n           name=\"query\",\n           **common_kwargs)\n       einsum_equation, bias_axes, output_rank = _build_proj_equation(\n-          key_shape.rank - 1, bound_dims=1, output_dims=2)\n+          self._key_shape.rank - 1, bound_dims=1, output_dims=2)\n       self._key_dense = einsum_dense.EinsumDense(\n           einsum_equation,\n           output_shape=_get_output_shape(output_rank - 1,\n@@ -335,7 +358,7 @@ class MultiHeadAttention(Layer):\n           name=\"key\",\n           **common_kwargs)\n       einsum_equation, bias_axes, output_rank = _build_proj_equation(\n-          value_shape.rank - 1, bound_dims=1, output_dims=2)\n+          self._value_shape.rank - 1, bound_dims=1, output_dims=2)\n       self._value_dense = einsum_dense.EinsumDense(\n           einsum_equation,\n           output_shape=_get_output_shape(output_rank - 1,\n@@ -354,7 +377,7 @@ class MultiHeadAttention(Layer):\n         else:\n           output_shape = self._output_shape\n       else:\n-        output_shape = [query_shape[-1]]\n+        output_shape = [self._query_shape[-1]]\n       einsum_equation, bias_axes, output_rank = _build_proj_equation(\n           free_dims, bound_dims=2, output_dims=len(output_shape))\n       self._output_dense = einsum_dense.EinsumDense(\n\n@@ -269,5 +269,71 @@ class AttentionSubclassTest(keras_parameterized.TestCase):\n     self.assertEqual(output.shape.as_list(), [None, 40, 80])\n \n \n+class TestModel(keras.Model):\n+\n+  def __init__(self):\n+    super(TestModel, self).__init__()\n+    self.attention = multi_head_attention.MultiHeadAttention(\n+        num_heads=3,\n+        key_dim=4,\n+        value_dim=4,\n+        use_bias=True,\n+        dropout=0.0,\n+        output_shape=[12])\n+\n+  @classmethod\n+  def from_config(cls, config):\n+    return cls(**config)\n+\n+  def get_config(self):\n+    return {}\n+\n+  def call(self, x, training=False):\n+    return self.attention(x, x, training=training)\n+\n+\n+@keras_parameterized.run_all_keras_modes(always_skip_v1=True)\n+class KerasModelSavingTest(keras_parameterized.TestCase):\n+\n+  def test_keras_saving_subclass(self):\n+    model = TestModel()\n+    query = keras.Input(shape=(40, 80))\n+    _ = model(query)\n+    model_path = self.get_temp_dir() + \"/tmp_model\"\n+    keras.models.save_model(model, model_path, save_format=\"tf\")\n+    reloaded_model = keras.models.load_model(model_path)\n+    self.assertEqual(\n+        len(model.trainable_variables), len(reloaded_model.trainable_variables))\n+    for src_v, loaded_v in zip(model.trainable_variables,\n+                               reloaded_model.trainable_variables):\n+      self.assertAllEqual(src_v, loaded_v)\n+\n+  @parameterized.parameters(\"h5\", \"tf\")\n+  def test_keras_saving_functional(self, save_format):\n+    model = TestModel()\n+    query = keras.Input(shape=(40, 80))\n+    output = multi_head_attention.MultiHeadAttention(\n+        num_heads=3,\n+        key_dim=4,\n+        value_dim=4,\n+        use_bias=True,\n+        dropout=0.0)(query, query)\n+    model = keras.Model(inputs=query, outputs=output)\n+    model_path = self.get_temp_dir() + \"/tmp_model\"\n+    keras.models.save_model(model, model_path, save_format=save_format)\n+    reloaded_model = keras.models.load_model(model_path)\n+    self.assertEqual(\n+        len(model.trainable_variables), len(reloaded_model.trainable_variables))\n+    for src_v, loaded_v in zip(model.trainable_variables,\n+                               reloaded_model.trainable_variables):\n+      self.assertAllEqual(src_v, loaded_v)\n+\n+  def test_create_without_build(self):\n+    not_intialized_layer = multi_head_attention.MultiHeadAttention(\n+        num_heads=3, key_dim=4, value_dim=4)\n+    multi_head_attention.MultiHeadAttention.from_config(\n+        not_intialized_layer.get_config())\n+\n+\n if __name__ == \"__main__\":\n   tf.test.main()\n\n@@ -1344,44 +1344,20 @@ class RandomWidth(PreprocessingLayer):\n     return dict(list(base_config.items()) + list(config.items()))\n \n \n-# TODO(b/147877541, b/158339556): This class is added to temporarily enable\n-# creating generators within distribution strategies. Remove it when the proper\n-# API is in place.\n-class _RandomGenerator(tf.random.Generator):\n-  \"\"\"A subclass that allows creation inside distribution strategies.\n-\n-  This is a temporary solution to allow creating tf.random.Generator inside\n-  distribution strategies. It will be removed when proper API is in place.\n-\n-  All replicas will have the same RNG state and generate the same random\n-  numbers.\n-  \"\"\"\n-\n-  # TODO(b/157995497): Temporarily use primary variable handle inside cross\n-  # replica context.\n-  @property\n-  def state(self):\n-    \"\"\"The internal state of the RNG.\"\"\"\n-    state_var = self._state_var\n-    try:\n-      _ = getattr(state_var, 'handle')\n-      return state_var\n-    except ValueError:\n-      return state_var.values[0]\n-\n-  def _create_variable(self, *args, **kwargs):\n-    # This function does the same thing as the base class's namesake, except\n-    # that it skips the distribution-strategy check. When we are inside a\n-    # distribution-strategy scope, variables.Variable will pick a proper\n-    # variable class (e.g. MirroredVariable).\n-    return tf.Variable(*args, **kwargs)\n-\n-\n def make_generator(seed=None):\n+  \"\"\"Creates a random generator.\n+\n+  Args:\n+    seed: the seed to initialize the generator. If None, the generator will be\n+      initialized non-deterministically.\n+\n+  Returns:\n+    A generator object.\n+  \"\"\"\n   if seed:\n-    return _RandomGenerator.from_seed(seed)\n+    return tf.random.Generator.from_seed(seed)\n   else:\n-    return _RandomGenerator.from_non_deterministic_state()\n+    return tf.random.Generator.from_non_deterministic_state()\n \n \n def get_interpolation(interpolation):\n\n@@ -38,6 +38,8 @@ class ImagePreprocessingDistributionTest(\n     preprocessing_test_utils.PreprocessingLayerTest):\n \n   def test_distribution(self, distribution):\n+    if \"CentralStorage\" in type(distribution).__name__:\n+      self.skipTest(\"Does not work with CentralStorageStrategy yet.\")\n     # TODO(b/159738418): large image input causes OOM in ubuntu multi gpu.\n     np_images = np.random.random((32, 32, 32, 3)).astype(np.float32)\n     image_dataset = tf.data.Dataset.from_tensor_slices(np_images).batch(\n\n@@ -60,7 +60,7 @@ class LearningRateSchedule(object):\n class ExponentialDecay(LearningRateSchedule):\n   \"\"\"A LearningRateSchedule that uses an exponential decay schedule.\n \n-  When training a model, it is often recommended to lower the learning rate as\n+  When training a model, it is often useful to lower the learning rate as\n   the training progresses. This schedule applies an exponential decay function\n   to an optimizer step, given a provided initial learning rate.\n \n@@ -411,7 +411,7 @@ class PolynomialDecay(LearningRateSchedule):\n class InverseTimeDecay(LearningRateSchedule):\n   \"\"\"A LearningRateSchedule that uses an inverse time decay schedule.\n \n-  When training a model, it is often recommended to lower the learning rate as\n+  When training a model, it is often useful to lower the learning rate as\n   the training progresses. This schedule applies the inverse decay function\n   to an optimizer step, given a provided initial learning rate.\n   It requires a `step` value to compute the decayed learning rate. You can\n@@ -513,14 +513,15 @@ class InverseTimeDecay(LearningRateSchedule):\n     }\n \n \n-@keras_export(\"keras.experimental.CosineDecay\")\n+@keras_export(\"keras.optimizers.schedules.CosineDecay\",\n+              \"keras.experimental.CosineDecay\")\n class CosineDecay(LearningRateSchedule):\n   \"\"\"A LearningRateSchedule that uses a cosine decay schedule.\n \n-  See [Loshchilov & Hutter, ICLR2016], SGDR: Stochastic Gradient Descent\n-  with Warm Restarts. https://arxiv.org/abs/1608.03983\n+  See [Loshchilov & Hutter, ICLR2016](https://arxiv.org/abs/1608.03983),\n+  SGDR: Stochastic Gradient Descent with Warm Restarts.\n \n-  When training a model, it is often recommended to lower the learning rate as\n+  When training a model, it is often useful to lower the learning rate as\n   the training progresses. This schedule applies a cosine decay function\n   to an optimizer step, given a provided initial learning rate.\n   It requires a `step` value to compute the decayed learning rate. You can\n@@ -542,7 +543,7 @@ class CosineDecay(LearningRateSchedule):\n   Example usage:\n   ```python\n   decay_steps = 1000\n-  lr_decayed_fn = tf.keras.experimental.CosineDecay(\n+  lr_decayed_fn = tf.keras.optimizers.schedules.CosineDecay(\n       initial_learning_rate, decay_steps)\n   ```\n \n@@ -606,14 +607,15 @@ class CosineDecay(LearningRateSchedule):\n     }\n \n \n-@keras_export(\"keras.experimental.CosineDecayRestarts\")\n+@keras_export(\"keras.optimizers.schedules.CosineDecayRestarts\",\n+              \"keras.experimental.CosineDecayRestarts\")\n class CosineDecayRestarts(LearningRateSchedule):\n   \"\"\"A LearningRateSchedule that uses a cosine decay schedule with restarts.\n \n-  See [Loshchilov & Hutter, ICLR2016], SGDR: Stochastic Gradient Descent\n-  with Warm Restarts. https://arxiv.org/abs/1608.03983\n+  See [Loshchilov & Hutter, ICLR2016](https://arxiv.org/abs/1608.03983),\n+  SGDR: Stochastic Gradient Descent with Warm Restarts.\n \n-  When training a model, it is often recommended to lower the learning rate as\n+  When training a model, it is often useful to lower the learning rate as\n   the training progresses. This schedule applies a cosine decay function with\n   restarts to an optimizer step, given a provided initial learning rate.\n   It requires a `step` value to compute the decayed learning rate. You can\n@@ -632,7 +634,7 @@ class CosineDecayRestarts(LearningRateSchedule):\n   ```python\n   first_decay_steps = 1000\n   lr_decayed_fn = (\n-    tf.keras.experimental.CosineDecayRestarts(\n+    tf.keras.optimizers.schedules.CosineDecayRestarts(\n         initial_learning_rate,\n         first_decay_steps))\n   ```\n@@ -732,7 +734,7 @@ class CosineDecayRestarts(LearningRateSchedule):\n     }\n \n \n-@keras_export(\"keras.experimental.LinearCosineDecay\")\n+# Note: this code is still used by V1 APIs.\n class LinearCosineDecay(LearningRateSchedule):\n   \"\"\"A LearningRateSchedule that uses a linear cosine decay schedule.\n \n@@ -850,7 +852,7 @@ class LinearCosineDecay(LearningRateSchedule):\n     }\n \n \n-@keras_export(\"keras.experimental.NoisyLinearCosineDecay\")\n+# Note: this code is still used by V1 APIs.\n class NoisyLinearCosineDecay(LearningRateSchedule):\n   \"\"\"A LearningRateSchedule that uses a noisy linear cosine decay schedule.\n \n\n@@ -426,81 +426,5 @@ class CosineDecayRestartsTestV2(tf.test.TestCase,\n       self.assertAllClose(self.evaluate(decayed_lr(step)), expected, 1e-6)\n \n \n-@combinations.generate(combinations.combine(serialize=[False, True],\n-                                            mode=[\"graph\", \"eager\"]))\n-class LinearCosineDecayTestV2(tf.test.TestCase,\n-                              parameterized.TestCase):\n-\n-  def np_linear_cosine_decay(self,\n-                             step,\n-                             decay_steps,\n-                             alpha=0.0,\n-                             beta=0.001,\n-                             num_periods=0.5):\n-    step = min(step, decay_steps)\n-    linear_decayed = float(decay_steps - step) / decay_steps\n-    fraction = 2.0 * num_periods * step / float(decay_steps)\n-    cosine_decayed = 0.5 * (1.0 + math.cos(math.pi * fraction))\n-    return (alpha + linear_decayed) * cosine_decayed + beta\n-\n-  def testDefaultDecay(self, serialize):\n-    num_training_steps = 1000\n-    initial_lr = 1.0\n-    for step in range(0, 1500, 250):\n-      decayed_lr = learning_rate_schedule.LinearCosineDecay(\n-          initial_lr, num_training_steps)\n-      decayed_lr = _maybe_serialized(decayed_lr, serialize)\n-      expected = self.np_linear_cosine_decay(step, num_training_steps)\n-      self.assertAllClose(self.evaluate(decayed_lr(step)), expected, 1e-6)\n-\n-  def testNonDefaultDecay(self, serialize):\n-    num_training_steps = 1000\n-    initial_lr = 1.0\n-    for step in range(0, 1500, 250):\n-      decayed_lr = learning_rate_schedule.LinearCosineDecay(\n-          initial_lr,\n-          num_training_steps,\n-          alpha=0.1,\n-          beta=1e-4,\n-          num_periods=5)\n-      decayed_lr = _maybe_serialized(decayed_lr, serialize)\n-      expected = self.np_linear_cosine_decay(\n-          step, num_training_steps, alpha=0.1, beta=1e-4, num_periods=5)\n-      self.assertAllClose(self.evaluate(decayed_lr(step)), expected, 1e-6)\n-\n-\n-@combinations.generate(combinations.combine(serialize=[False, True],\n-                                            mode=[\"graph\", \"eager\"]))\n-class NoisyLinearCosineDecayTestV2(tf.test.TestCase,\n-                                   parameterized.TestCase):\n-\n-  def testDefaultNoisyLinearCosine(self, serialize):\n-    num_training_steps = 1000\n-    initial_lr = 1.0\n-    for step in range(0, 1500, 250):\n-      # No numerical check because of noise\n-      decayed_lr = learning_rate_schedule.NoisyLinearCosineDecay(\n-          initial_lr, num_training_steps)\n-      decayed_lr = _maybe_serialized(decayed_lr, serialize)\n-      # Cannot be deterministically tested\n-      self.evaluate(decayed_lr(step))\n-\n-  def testNonDefaultNoisyLinearCosine(self, serialize):\n-    num_training_steps = 1000\n-    initial_lr = 1.0\n-    for step in range(0, 1500, 250):\n-      # No numerical check because of noise\n-      decayed_lr = learning_rate_schedule.NoisyLinearCosineDecay(\n-          initial_lr,\n-          num_training_steps,\n-          initial_variance=0.5,\n-          variance_decay=0.1,\n-          alpha=0.1,\n-          beta=1e-4,\n-          num_periods=5)\n-      decayed_lr = _maybe_serialized(decayed_lr, serialize)\n-      # Cannot be deterministically tested\n-      self.evaluate(decayed_lr(step))\n-\n if __name__ == \"__main__\":\n   tf.test.main()\n\n@@ -23,6 +23,7 @@ import tensorflow as tf\n import numpy as np\n from keras.layers.preprocessing import image_preprocessing\n from keras.preprocessing import dataset_utils\n+from keras.preprocessing import image as keras_image_ops\n from tensorflow.python.util.tf_export import keras_export\n \n \n@@ -42,7 +43,8 @@ def image_dataset_from_directory(directory,\n                                  validation_split=None,\n                                  subset=None,\n                                  interpolation='bilinear',\n-                                 follow_links=False):\n+                                 follow_links=False,\n+                                 smart_resize=False):\n   \"\"\"Generates a `tf.data.Dataset` from image files in a directory.\n \n   If your directory structure is:\n@@ -111,6 +113,11 @@ def image_dataset_from_directory(directory,\n       `area`, `lanczos3`, `lanczos5`, `gaussian`, `mitchellcubic`.\n     follow_links: Whether to visits subdirectories pointed to by symlinks.\n         Defaults to False.\n+    smart_resize: If True, the resizing function used will be\n+      `tf.keras.preprocessing.image.smart_resize`, which preserves the aspect\n+      ratio of the original image by using a mixture of resizing and cropping.\n+      If False (default), the resizing function is `tf.image.resize`, which\n+      does not preserve aspect ratio.\n \n   Returns:\n     A `tf.data.Dataset` object.\n@@ -200,7 +207,8 @@ def image_dataset_from_directory(directory,\n       labels=labels,\n       label_mode=label_mode,\n       num_classes=len(class_names),\n-      interpolation=interpolation)\n+      interpolation=interpolation,\n+      smart_resize=smart_resize)\n   if shuffle:\n     # Shuffle locally at each iteration\n     dataset = dataset.shuffle(buffer_size=batch_size * 8, seed=seed)\n@@ -218,22 +226,30 @@ def paths_and_labels_to_dataset(image_paths,\n                                 labels,\n                                 label_mode,\n                                 num_classes,\n-                                interpolation):\n+                                interpolation,\n+                                smart_resize=False):\n   \"\"\"Constructs a dataset of images and labels.\"\"\"\n   # TODO(fchollet): consider making num_parallel_calls settable\n   path_ds = tf.data.Dataset.from_tensor_slices(image_paths)\n+  args = (image_size, num_channels, interpolation, smart_resize)\n   img_ds = path_ds.map(\n-      lambda x: path_to_image(x, image_size, num_channels, interpolation))\n+      lambda x: load_image(x, *args))\n   if label_mode:\n     label_ds = dataset_utils.labels_to_dataset(labels, label_mode, num_classes)\n     img_ds = tf.data.Dataset.zip((img_ds, label_ds))\n   return img_ds\n \n \n-def path_to_image(path, image_size, num_channels, interpolation):\n+def load_image(path, image_size, num_channels, interpolation,\n+               smart_resize=False):\n+  \"\"\"Load an image from a path and resize it.\"\"\"\n   img = tf.io.read_file(path)\n   img = tf.image.decode_image(\n       img, channels=num_channels, expand_animations=False)\n+  if smart_resize:\n+    img = keras_image_ops.smart_resize(img, image_size,\n+                                       interpolation=interpolation)\n+  else:\n     img = tf.image.resize(img, image_size, method=interpolation)\n   img.set_shape((image_size[0], image_size[1], num_channels))\n   return img\n\n@@ -282,6 +282,17 @@ class ImageDatasetFromDirectoryTest(keras_parameterized.TestCase):\n     with self.assertRaisesRegex(ValueError, 'No images found.'):\n       _ = image_dataset.image_dataset_from_directory(directory)\n \n+  def test_image_dataset_from_directory_smart_resize(self):\n+    if PIL is None:\n+      return  # Skip test if PIL is not available.\n+\n+    directory = self._prepare_directory(num_classes=2, count=5)\n+    dataset = image_dataset.image_dataset_from_directory(\n+        directory, batch_size=5, image_size=(18, 18), smart_resize=True)\n+    batch = next(iter(dataset))\n+    self.assertLen(batch, 2)\n+    self.assertEqual(batch[0].shape, (5, 18, 18, 3))\n+\n   def test_image_dataset_from_directory_errors(self):\n     if PIL is None:\n       return  # Skip test if PIL is not available.\n\n@@ -34,7 +34,6 @@ from keras import optimizer_v1\n from keras import testing_utils\n from keras.engine import training\n from keras.saving import hdf5_format\n-from tensorflow.python.platform import tf_logging as logging\n \n try:\n   import h5py  # pylint:disable=g-import-not-at-top\n@@ -393,21 +392,6 @@ class SubclassedModel(training.Model):\n \n class TestWeightSavingAndLoadingTFFormat(tf.test.TestCase, parameterized.TestCase):\n \n-  def test_keras_optimizer_warning(self):\n-    graph = tf.Graph()\n-    with graph.as_default(), self.session(graph):\n-      model = keras.models.Sequential()\n-      model.add(keras.layers.Dense(2, input_shape=(3,)))\n-      model.add(keras.layers.Dense(3))\n-      model.compile(loss='mse', optimizer=optimizer_v1.Adam(), metrics=['acc'])\n-      if not tf.compat.v1.executing_eagerly_outside_functions():\n-        model._make_train_function()\n-      temp_dir = self.get_temp_dir()\n-      prefix = os.path.join(temp_dir, 'ckpt')\n-      with tf.compat.v1.test.mock.patch.object(logging, 'warning') as mock_log:\n-        model.save_weights(prefix)\n-        self.assertRegex(str(mock_log.call_args), 'Keras optimizer')\n-\n   @combinations.generate(combinations.combine(mode=['graph', 'eager']))\n   def test_tensorflow_format_overwrite(self):\n     with self.cached_session() as session:\n\n@@ -447,20 +447,20 @@ class KerasObjectLoader(object):\n \n   def _revive_graph_network(self, metadata, node_id):\n     \"\"\"Revives a graph network from config.\"\"\"\n-    class_name = tf.compat.as_str(metadata['class_name'])\n-    config = metadata.get('config')\n-\n     # Determine whether the metadata contains information for reviving a\n     # functional or Sequential model.\n+    config = metadata.get('config')\n+    if not generic_utils.validate_config(config):\n+      return None\n+\n+    class_name = tf.compat.as_str(metadata['class_name'])\n+    if generic_utils.get_registered_object(class_name) is not None:\n+      return None\n     model_is_functional_or_sequential = (\n         metadata.get('is_graph_network', False) or\n-        metadata['class_name'] == 'Sequential' or\n-        metadata['class_name'] == 'Functional')\n-    if not (generic_utils.validate_config(config) and\n-            model_is_functional_or_sequential\n-           ) or generic_utils.get_registered_object(class_name) is not None:\n-      # Model should not be revived as a graph network. Try reviving directly\n-      # from config or as a custom model.\n+        class_name == 'Sequential' or\n+        class_name == 'Functional')\n+    if not model_is_functional_or_sequential:\n       return None\n \n     # Revive functional and sequential models as blank model objects for now (\n\n@@ -45,7 +45,6 @@ from six.moves.urllib.request import urlopen\n from keras.utils import tf_inspect\n from keras.utils.generic_utils import Progbar\n from keras.utils.io_utils import path_to_string\n-from tensorflow.python.platform import tf_logging as logging\n from tensorflow.python.util.tf_export import keras_export\n \n \n@@ -529,10 +528,6 @@ def get_pool_class(use_multiprocessing):\n   global _FORCE_THREADPOOL\n   if not use_multiprocessing or _FORCE_THREADPOOL:\n     return multiprocessing.dummy.Pool  # ThreadPool\n-  logging.warning(\n-      'multiprocessing can interact badly with TensorFlow, causing '\n-      'nondeterministic deadlocks. For high performance data pipelines tf.data '\n-      'is recommended.')\n   return multiprocessing.Pool\n \n \n\n@@ -114,7 +114,7 @@ class BaseWrapper(object):\n     Returns:\n         Dictionary of parameter names mapped to their values.\n     \"\"\"\n-    res = copy.deepcopy(self.sk_params)\n+    res = self.sk_params.copy()\n     res.update({'build_fn': self.build_fn})\n     return res\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7d818d66a243aaf5d4e0f58e257087b0957a1086", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 150 | Lines Deleted: 52 | Files Changed: 14 | Hunks: 44 | Methods Changed: 19 | Complexity Δ (Sum/Max): 19/5 | Churn Δ: 202 | Churn Cumulative: 27222 | Contributors (this commit): 159 | Commits (past 90d): 51 | Contributors (cumulative): 202 | DMM Complexity: 0.8478260869565217\n\nDIFF:\n@@ -1680,7 +1680,10 @@ class EarlyStopping(Callback):\n     restore_best_weights: Whether to restore model weights from\n         the epoch with the best value of the monitored quantity.\n         If False, the model weights obtained at the last step of\n-        training are used.\n+        training are used. An epoch will be restored regardless\n+        of the performance relative to the `baseline`. If no epoch\n+        improves on `baseline`, training will run for `patience`\n+        epochs and restore weights from the best epoch in that set.\n \n   Example:\n \n@@ -1740,9 +1743,6 @@ class EarlyStopping(Callback):\n     # Allow instances to be re-used\n     self.wait = 0\n     self.stopped_epoch = 0\n-    if self.baseline is not None:\n-      self.best = self.baseline\n-    else:\n     self.best = np.Inf if self.monitor_op == np.less else -np.Inf\n     self.best_weights = None\n \n@@ -1750,17 +1750,23 @@ class EarlyStopping(Callback):\n     current = self.get_monitor_value(logs)\n     if current is None:\n       return\n-    if self.monitor_op(current - self.min_delta, self.best):\n+    if self.restore_best_weights and self.best_weights is None:\n+      # Restore the weights after first epoch if no progress is ever made.\n+      self.best_weights = self.model.get_weights()\n+\n+    self.wait += 1\n+    if self._is_improvement(current, self.best):\n       self.best = current\n-      self.wait = 0\n       if self.restore_best_weights:\n         self.best_weights = self.model.get_weights()\n-    else:\n-      self.wait += 1\n+      # Only restart wait if we beat both the baseline and our previous best.\n+      if self.baseline is None or self._is_improvement(current, self.baseline):\n+        self.wait = 0\n+\n     if self.wait >= self.patience:\n       self.stopped_epoch = epoch\n       self.model.stop_training = True\n-        if self.restore_best_weights:\n+      if self.restore_best_weights and self.best_weights is not None:\n         if self.verbose > 0:\n           print('Restoring model weights from the end of the best epoch.')\n         self.model.set_weights(self.best_weights)\n@@ -1778,6 +1784,9 @@ class EarlyStopping(Callback):\n                       self.monitor, ','.join(list(logs.keys())))\n     return monitor_value\n \n+  def _is_improvement(self, monitor_value, reference_value):\n+    return self.monitor_op(monitor_value - self.min_delta, reference_value)\n+\n \n @keras_export('keras.callbacks.RemoteMonitor')\n class RemoteMonitor(Callback):\n\n@@ -1108,6 +1108,25 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n     # so we end up at the epoch with the best weights, i.e. epoch 2\n     self.assertEqual(early_stop.model.get_weights(), 2)\n \n+    # Check early stopping when no model beats the baseline.\n+    early_stop = keras.callbacks.EarlyStopping(\n+        monitor='val_loss', patience=5, baseline=0.5, restore_best_weights=True)\n+    early_stop.model = DummyModel()\n+    losses = [0.9, 0.8, 0.7, 0.71, 0.72, 0.73]\n+    # The best configuration is in the epoch 2 (loss = 0.7000).\n+    epochs_trained = 0\n+    early_stop.on_train_begin()\n+    for epoch in range(len(losses)):\n+      epochs_trained += 1\n+      early_stop.model.set_weight_to_epoch(epoch=epoch)\n+      early_stop.on_epoch_end(epoch, logs={'val_loss': losses[epoch]})\n+      if early_stop.model.stop_training:\n+        break\n+    # No epoch improves on the baseline, so we should train for only 5 epochs,\n+    # and restore the second model.\n+    self.assertEqual(epochs_trained, 5)\n+    self.assertEqual(early_stop.model.get_weights(), 2)\n+\n   def test_RemoteMonitor(self):\n     if requests is None:\n       self.skipTest('`requests` required to run this test')\n\n@@ -307,7 +307,8 @@ class Softmax(Layer):\n       normalization is applied.\n   Call arguments:\n     inputs: The inputs, or logits to the softmax layer.\n-    mask: A boolean mask of the same shape as `inputs`. Defaults to `None`.\n+    mask: A boolean mask of the same shape as `inputs`. Defaults to `None`. The\n+      mask specifies 1 to keep and 0 to mask.\n \n   Returns:\n     softmaxed output with the same shape as `inputs`.\n@@ -320,7 +321,7 @@ class Softmax(Layer):\n \n   def call(self, inputs, mask=None):\n     if mask is not None:\n-      # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n+      # Since mask is 1.0 for positions we want to keep and 0.0 for\n       # masked positions, this operation will create a tensor which is 0.0 for\n       # positions we want to attend and -1e.9 for masked positions.\n       adder = (1.0 - tf.cast(mask, inputs.dtype)) * (\n\n@@ -28,7 +28,6 @@ from keras import backend as K\n from keras import combinations\n from keras import keras_parameterized\n from keras import testing_utils\n-from tensorflow.python.ops.ragged import ragged_tensor\n \n \n @keras_parameterized.run_all_keras_modes\n@@ -242,8 +241,7 @@ class MergeLayersTest(keras_parameterized.TestCase):\n     out = keras.layers.Add()([input1, input2])\n     model = keras.models.Model(inputs=[input1, input2], outputs=out)\n     out_ragged = model.predict([ragged_data, ragged_data], steps=1)\n-    out_ragged = ragged_tensor.convert_to_tensor_or_ragged_tensor(\n-        out_ragged).to_tensor()\n+    out_ragged = convert_ragged_tensor_value(out_ragged).to_tensor()\n \n     input1 = keras.Input(shape=(None,))\n     input2 = keras.Input(shape=(None,))\n@@ -404,5 +402,15 @@ class MergeLayersTestNoExecution(tf.test.TestCase):\n     keras.Model(a, c)  # Ensure model can be built.\n \n \n+def convert_ragged_tensor_value(inputs):\n+  if isinstance(inputs, tf.compat.v1.ragged.RaggedTensorValue):\n+    flat_values = tf.convert_to_tensor(\n+        value=inputs.flat_values,\n+        name='flat_values')\n+    return tf.RaggedTensor.from_nested_row_splits(\n+        flat_values, inputs.nested_row_splits, validate=False)\n+  return inputs\n+\n+\n if __name__ == '__main__':\n   tf.test.main()\n\n@@ -190,7 +190,10 @@ class MultiHeadAttention(Layer):\n     key: Optional key `Tensor` of shape `[B, S, dim]`. If not given, will use\n       `value` for both `key` and `value`, which is the most common case.\n     attention_mask: a boolean mask of shape `[B, T, S]`, that prevents\n-      attention to certain positions.\n+      attention to certain positions. The boolean mask specifies which query\n+      elements can attend to which key elements, 1 indicates attention and 0\n+      indicates no attention. Broadcasting can happen for the missing batch\n+      dimensions and the head dimension.\n     return_attention_scores: A boolean to indicate whether the output should\n       be attention output if True, or (attention_output, attention_scores) if\n       False. Defaults to False.\n\n@@ -114,8 +114,9 @@ class IndexLookup(base_preprocessing_layer.CombinerPreprocessingLayer):\n                        \"You passed %s\" % (max_tokens,))\n \n     if num_oov_indices < 0:\n-      raise ValueError(\"`num_oov_indices` must be greater than 0. You passed \"\n-                       \"%s\" % (num_oov_indices,))\n+      raise ValueError(\n+          \"num_oov_indices must be greater than or equal to 0. You passed %s\" %\n+          (num_oov_indices,))\n \n     if invert and num_oov_indices != 1:\n       raise ValueError(\"`num_oov_tokens` must be 1 when `invert` is True.\")\n\n@@ -64,9 +64,8 @@ class IntegerLookup(index_lookup.IndexLookup):\n     invert: If true, this layer will map indices to vocabulary items instead\n       of mapping vocabulary items to indices.\n     output_mode: Specification for the output of the layer. Only applicable\n-      when `invert` is False.\n-      Defaults to \"int\". Values can\n-      be \"int\", \"binary\", or \"count\", configuring the layer as follows:\n+      when `invert` is False. Defaults to \"int\". Values can be \"int\", \"binary\",\n+      or \"count\", configuring the layer as follows:\n         \"int\": Return the raw integer indices of the input values.\n         \"binary\": Outputs a single int array per batch, of either vocab_size or\n           max_tokens size, containing 1s in all elements where the token mapped\n@@ -217,7 +216,8 @@ class IntegerLookup(index_lookup.IndexLookup):\n                        \"You passed %s\" % (max_values,))\n \n     if num_oov_indices < 0:\n-      raise ValueError(\"num_oov_indices must be greater than 0. You passed %s\" %\n+      raise ValueError(\n+          \"num_oov_indices must be greater than or equal to 0. You passed %s\" %\n           (num_oov_indices,))\n \n     if vocabulary is not None:\n\n@@ -65,9 +65,8 @@ class StringLookup(index_lookup.IndexLookup):\n     invert: If true, this layer will map indices to vocabulary items instead\n       of mapping vocabulary items to indices.\n     output_mode: Specification for the output of the layer. Only applicable\n-      when `invert` is False.\n-      Defaults to \"int\". Values can\n-      be \"int\", \"binary\", or \"count\", configuring the layer as follows:\n+      when `invert` is False. Defaults to \"int\". Values can be \"int\", \"binary\",\n+      or \"count\", configuring the layer as follows:\n         \"int\": Return the raw integer indices of the input values.\n         \"binary\": Outputs a single int array per batch, of either vocab_size or\n           max_tokens size, containing 1s in all elements where the token mapped\n\n@@ -24,7 +24,6 @@ import os\n import numpy as np\n from keras import backend as K\n from keras.utils import tf_utils\n-from tensorflow.python.ops.ragged import ragged_tensor\n \n \n class TableHandler(object):\n@@ -124,13 +123,17 @@ class TableHandler(object):\n         inputs, (tf.SparseTensor, tf.compat.v1.SparseTensorValue)):\n       return self._sparse_lookup(inputs)\n \n-    # Try to convert lists/arrays to tensors or RaggedTensors.\n-    inputs = ragged_tensor.convert_to_tensor_or_ragged_tensor(inputs)\n-\n-    # Run the lookup operation on the converted tensor.\n     if tf_utils.is_ragged(inputs):\n+      if isinstance(inputs, tf.compat.v1.ragged.RaggedTensorValue):\n+        flat_values = tf.convert_to_tensor(\n+            value=inputs.flat_values,\n+            name=\"flat_values\")\n+        inputs = tf.RaggedTensor.from_nested_row_splits(\n+            flat_values, inputs.nested_row_splits, validate=False)\n       return self._ragged_lookup(inputs)\n-    else:\n+\n+    # For normal tensor inputs\n+    inputs = tf.convert_to_tensor(inputs)\n     return self._tensor_lookup(inputs)\n \n   def _eval(self, tensor):\n\n@@ -34,7 +34,6 @@ from keras.engine import base_layer_utils\n from keras.layers import core\n from keras.layers.rnn_cell_wrapper_v2 import ResidualWrapper\n from keras.utils import generic_utils\n-from tensorflow.python.ops.ragged import ragged_tensor\n from tensorflow.python.training.tracking import util as trackable_util\n \n \n@@ -425,8 +424,7 @@ class TimeDistributedTest(keras_parameterized.TestCase):\n     model_2._run_eagerly = testing_utils.should_run_eagerly()\n     output_dense = model_2.predict(dense_data, steps=1)\n \n-    output_ragged = ragged_tensor.convert_to_tensor_or_ragged_tensor(\n-        output_ragged, name='tensor')\n+    output_ragged = convert_ragged_tensor_value(output_ragged)\n     self.assertAllEqual(output_ragged.to_tensor(), output_dense)\n \n   @keras_parameterized.run_all_keras_modes\n@@ -454,8 +452,7 @@ class TimeDistributedTest(keras_parameterized.TestCase):\n     dense_data = ragged_data.to_tensor()\n     output_dense = model_2.predict(dense_data, steps=1)\n \n-    output_ragged = ragged_tensor.convert_to_tensor_or_ragged_tensor(\n-        output_ragged, name='tensor')\n+    output_ragged = convert_ragged_tensor_value(output_ragged)\n     self.assertAllEqual(output_ragged.to_tensor(), output_dense)\n \n   def test_TimeDistributed_set_static_shape(self):\n@@ -1309,10 +1306,10 @@ class BidirectionalTest(tf.test.TestCase, parameterized.TestCase):\n \n       y_merged = f_merged(x)\n       y_expected = merge_func(\n-          ragged_tensor.convert_to_tensor_or_ragged_tensor(f_forward(x)),\n-          ragged_tensor.convert_to_tensor_or_ragged_tensor(f_backward(x)))\n+          convert_ragged_tensor_value(f_forward(x)),\n+          convert_ragged_tensor_value(f_backward(x)))\n \n-      y_merged = ragged_tensor.convert_to_tensor_or_ragged_tensor(y_merged)\n+      y_merged = convert_ragged_tensor_value(y_merged)\n       self.assertAllClose(y_merged.flat_values, y_expected.flat_values)\n \n   def test_full_input_spec(self):\n@@ -1365,5 +1362,15 @@ def _to_list(ls):\n     return [ls]\n \n \n+def convert_ragged_tensor_value(inputs):\n+  if isinstance(inputs, tf.compat.v1.ragged.RaggedTensorValue):\n+    flat_values = tf.convert_to_tensor(\n+        value=inputs.flat_values,\n+        name='flat_values')\n+    return tf.RaggedTensor.from_nested_row_splits(\n+        flat_values, inputs.nested_row_splits, validate=False)\n+  return inputs\n+\n+\n if __name__ == '__main__':\n   tf.test.main()\n\n@@ -520,12 +520,20 @@ class Layer(base_layer.Layer):\n         # rather than initializing to None we check for an AttributeError.\n         scope_context_manager = self._always_reuse_variable_scope\n       except AttributeError:\n+        scope_context_manager = None\n+\n+      if scope_context_manager is None:\n         # From this point we will always set reuse=True, so create a \"final\"\n         # variable scope with this setting. We avoid re-creating variable scopes\n         # after this point as an optimization.\n-        self._always_reuse_variable_scope = tf.compat.v1.variable_scope(\n+        scope_context_manager = tf.compat.v1.variable_scope(\n             self._scope, reuse=True, auxiliary_name_scope=False)\n-        scope_context_manager = self._always_reuse_variable_scope\n+\n+        # Do not cache variable scopes if Eager mode is enabled. If Eager mode\n+        # is enabled then we don't want to reuse scopes because the cached scope\n+        # might be from a FuncGraph or Eager scope we are no longer in.\n+        if not tf.compat.v1.executing_eagerly_outside_functions():\n+          self._always_reuse_variable_scope = scope_context_manager\n     else:\n       scope_context_manager = tf.compat.v1.variable_scope(\n           self._scope, reuse=self._reuse, auxiliary_name_scope=False)\n\n@@ -652,6 +652,12 @@ class ImageDataGenerator(image.ImageDataGenerator):\n           (strictly between 0 and 1).\n       dtype: Dtype to use for the generated arrays.\n       \n+  Raises:\n+    ValueError: If the value of the argument, `data_format` is other than\n+          `\"channels_last\"` or `\"channels_first\"`.\n+    ValueError: If the value of the argument, `validation_split` > 1\n+          or `validation_split` < 0.\n+    \n   Examples: \n \n   Example of using `.flow(x, y)`:\n@@ -666,12 +672,16 @@ class ImageDataGenerator(image.ImageDataGenerator):\n       rotation_range=20,\n       width_shift_range=0.2,\n       height_shift_range=0.2,\n-      horizontal_flip=True)\n+      horizontal_flip=True,\n+      validation_split=0.2)\n   # compute quantities required for featurewise normalization\n   # (std, mean, and principal components if ZCA whitening is applied)\n   datagen.fit(x_train)\n   # fits the model on batches with real-time data augmentation:\n-  model.fit(datagen.flow(x_train, y_train, batch_size=32),\n+  model.fit(datagen.flow(x_train, y_train, batch_size=32, \n+           subset='training'), \n+           validation_data=datagen.flow(x_train, y_train, \n+           batch_size=8, subset='validation'),\n            steps_per_epoch=len(x_train) / 32, epochs=epochs)\n   # here's a more \"manual\" example\n   for e in range(epochs):\n@@ -832,7 +842,8 @@ class ImageDataGenerator(image.ImageDataGenerator):\n           generated (useful for visualizing what you are doing).\n         save_prefix: Str (default: `''`). Prefix to use for filenames of saved\n           pictures (only relevant if `save_to_dir` is set).\n-        save_format: one of \"png\", \"jpeg\"\n+        save_format: one of \"png\", \"jpeg\", \"bmp\", \"pdf\", \"ppm\", \"gif\", \n+            \"tif\", \"jpg\"\n             (only relevant if `save_to_dir` is set). Default: \"png\".\n         subset: Subset of data (`\"training\"` or `\"validation\"`) if\n           `validation_split` is set in `ImageDataGenerator`.\n@@ -846,6 +857,10 @@ class ImageDataGenerator(image.ImageDataGenerator):\n             of corresponding labels. If 'sample_weight' is not None,\n             the yielded tuples are of the form `(x, y, sample_weight)`.\n             If `y` is None, only the numpy array `x` is returned.\n+    Raises:\n+      ValueError: If the Value of the argument, `subset` is other than \n+            \"training\" or \"validation\".\n+\n     \"\"\"\n     return NumpyArrayIterator(\n         x,\n@@ -917,7 +932,8 @@ class ImageDataGenerator(image.ImageDataGenerator):\n           generated (useful for visualizing what you are doing).\n         save_prefix: Str. Prefix to use for filenames of saved pictures (only\n           relevant if `save_to_dir` is set).\n-        save_format: One of \"png\", \"jpeg\"\n+        save_format: one of \"png\", \"jpeg\", \"bmp\", \"pdf\", \"ppm\", \"gif\", \n+            \"tif\", \"jpg\" \n             (only relevant if `save_to_dir` is set). Default: \"png\".\n         follow_links: Whether to follow symlinks inside\n             class subdirectories (default: False).\n@@ -1032,7 +1048,8 @@ class ImageDataGenerator(image.ImageDataGenerator):\n           generated (useful for visualizing what you are doing).\n         save_prefix: str. Prefix to use for filenames of saved pictures (only\n           relevant if `save_to_dir` is set).\n-        save_format: one of \"png\", \"jpeg\"\n+        save_format: one of \"png\", \"jpeg\", \"bmp\", \"pdf\", \"ppm\", \"gif\", \n+            \"tif\", \"jpg\" \n             (only relevant if `save_to_dir` is set). Default: \"png\".\n         subset: Subset of data (`\"training\"` or `\"validation\"`) if\n           `validation_split` is set in `ImageDataGenerator`.\n\n@@ -197,13 +197,9 @@ def _generate_object_paths(object_graph_def):\n   \"\"\"Traverses through an ObjectGraphDef and builds a map of all node paths.\"\"\"\n   paths = {0: 'root'}\n   nodes_to_visit = [0]\n-  visited_nodes = set([])\n \n   while nodes_to_visit:\n     current_node = nodes_to_visit.pop()\n-    # if current_node in visited_nodes:\n-    #   continue\n-    visited_nodes.add(current_node)\n     current_path = paths[current_node]\n     for reference in object_graph_def.nodes[current_node].children:\n       if reference.node_id in paths:\n\n@@ -29,7 +29,6 @@ from keras.utils import losses_utils\n from keras.utils import tf_utils\n from keras.utils.generic_utils import to_list\n from tensorflow.python.ops import control_flow_ops\n-from tensorflow.python.ops.ragged import ragged_util\n from tensorflow.python.tpu import tpu\n \n NEG_INF = -1e10\n@@ -503,11 +502,11 @@ def ragged_assert_compatible_and_get_flat_values(values, mask=None):\n     # tf.TensorShape `assert_is_compatible_with`\n     # check if both dynamic dimensions are equal and then use the flat_values.\n     nested_row_split_list = [rt.nested_row_splits for rt in values]\n-    assertion_list = ragged_util.assert_splits_match(nested_row_split_list)\n+    assertion_list = _assert_splits_match(nested_row_split_list)\n \n     # if both are ragged sample_weights also should be ragged with same dims.\n     if isinstance(mask, tf.RaggedTensor):\n-      assertion_list_for_mask = ragged_util.assert_splits_match(\n+      assertion_list_for_mask = _assert_splits_match(\n           [nested_row_split_list[0], mask.nested_row_splits])\n       tmp = control_flow_ops.with_dependencies(assertion_list_for_mask,\n                                                mask.flat_values)\n@@ -529,3 +528,31 @@ def ragged_assert_compatible_and_get_flat_values(values, mask=None):\n     raise TypeError('Ragged mask is not allowed with non-ragged inputs.')\n \n   return values, mask\n+\n+\n+def _assert_splits_match(nested_splits_lists):\n+  \"\"\"Checks that the given splits lists are identical.\n+\n+  Performs static tests to ensure that the given splits lists are identical,\n+  and returns a list of control dependency op tensors that check that they are\n+  fully identical.\n+\n+  Args:\n+    nested_splits_lists: A list of nested_splits_lists, where each split_list is\n+      a list of `splits` tensors from a `RaggedTensor`, ordered from outermost\n+      ragged dimension to innermost ragged dimension.\n+\n+  Returns:\n+    A list of control dependency op tensors.\n+  Raises:\n+    ValueError: If the splits are not identical.\n+  \"\"\"\n+  error_msg = 'Inputs must have identical ragged splits'\n+  for splits_list in nested_splits_lists:\n+    if len(splits_list) != len(nested_splits_lists[0]):\n+      raise ValueError(error_msg)\n+  return [\n+      tf.compat.v1.assert_equal(s1, s2, message=error_msg)  # pylint: disable=g-complex-comprehension\n+      for splits_list in nested_splits_lists[1:]\n+      for (s1, s2) in zip(nested_splits_lists[0], splits_list)\n+  ]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
