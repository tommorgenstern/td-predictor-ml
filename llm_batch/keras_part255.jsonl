{"custom_id": "keras#75114feeac5ee6aa7679802ce7e5172c63565e2c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 3 | Files Changed: 3 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 4828 | Contributors (this commit): 43 | Commits (past 90d): 18 | Contributors (cumulative): 53 | DMM Complexity: 1.0\n\nDIFF:\n@@ -270,7 +270,7 @@ def placeholder(\n         raise ValueError('CNTK backend: creating placeholder with '\n                          '%d dimension is not supported, at least '\n                          '%d dimensions are needed.'\n-                         % (len(cntk_shape, dynamic_axis_num)))\n+                         % (len(cntk_shape), dynamic_axis_num))\n \n     if name is None:\n         name = ''\n\n@@ -224,7 +224,7 @@ def get_file(fname,\n                 raise Exception(error_msg.format(origin, e.errno, e.reason))\n             except HTTPError as e:\n                 raise Exception(error_msg.format(origin, e.code, e.msg))\n-        except (Exception, KeyboardInterrupt) as e:\n+        except (Exception, KeyboardInterrupt):\n             if os.path.exists(fpath):\n                 os.remove(fpath)\n             raise\n\n@@ -108,7 +108,6 @@ def model_to_dot(model,\n             if node_key in model._network_nodes:\n                 for inbound_layer in node.inbound_layers:\n                     inbound_layer_id = str(id(inbound_layer))\n-                    layer_id = str(id(layer))\n                     dot.add_edge(pydot.Edge(inbound_layer_id, layer_id))\n     return dot\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b88bbbab2695dd0e24905417006d2240c6595481", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 19 | Churn Cumulative: 2179 | Contributors (this commit): 21 | Commits (past 90d): 18 | Contributors (cumulative): 24 | DMM Complexity: 1.0\n\nDIFF:\n@@ -79,8 +79,7 @@ def save_model(model, filepath, overwrite=True, include_optimizer=True):\n         # if obj is any numpy type\n         if type(obj).__module__ == np.__name__:\n             if isinstance(obj, np.ndarray):\n-                return {'type': type(obj),\n-                        'value': obj.tolist()}\n+                return obj.tolist()\n             else:\n                 return obj.item()\n \n\n@@ -12,6 +12,7 @@ from keras.models import Model, Sequential\n from keras.layers import Dense, Lambda, RepeatVector, TimeDistributed, Bidirectional, GRU, LSTM, CuDNNGRU, CuDNNLSTM\n from keras.layers import Conv2D, Flatten\n from keras.layers import Input, InputLayer\n+from keras.initializers import Constant\n from keras import optimizers\n from keras import losses\n from keras import metrics\n@@ -641,6 +642,21 @@ def test_saving_recurrent_layer_without_bias():\n     os.remove(fname)\n \n \n+@keras_test\n+def test_saving_constant_initializer_with_numpy():\n+    \"\"\"Test saving and loading model of constant initializer with numpy ndarray as input.\n+    \"\"\"\n+    model = Sequential()\n+    model.add(Dense(2, input_shape=(3,), kernel_initializer=Constant(np.ones((3, 2)))))\n+    model.add(Dense(3))\n+    model.compile(loss='mse', optimizer='sgd', metrics=['acc'])\n+\n+    _, fname = tempfile.mkstemp('.h5')\n+    save_model(model, fname)\n+    model = load_model(fname)\n+    os.remove(fname)\n+\n+\n @keras_test\n @pytest.mark.parametrize('implementation', [1, 2], ids=['impl1', 'impl2'])\n @pytest.mark.parametrize('bidirectional', [False, True], ids=['single', 'bidirectional'])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#aab55e649c34f8a24f00ee63922d049d3417c979", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 10 | Files Changed: 1 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 18 | Churn Cumulative: 1777 | Contributors (this commit): 29 | Commits (past 90d): 10 | Contributors (cumulative): 29 | DMM Complexity: 0.4\n\nDIFF:\n@@ -115,7 +115,7 @@ EXCLUDE = {\n PAGES = [\n     {\n         'page': 'models/sequential.md',\n-        'functions': [\n+        'methods': [\n             models.Sequential.compile,\n             models.Sequential.fit,\n             models.Sequential.evaluate,\n@@ -131,7 +131,7 @@ PAGES = [\n     },\n     {\n         'page': 'models/model.md',\n-        'functions': [\n+        'methods': [\n             models.Model.compile,\n             models.Model.fit,\n             models.Model.evaluate,\n@@ -370,10 +370,6 @@ def get_function_signature(function, method=True):\n         signature = st[:-2] + ')'\n     else:\n         signature = st + ')'\n-\n-    if not method:\n-        # Prepend the module name.\n-        signature = clean_module_name(function.__module__) + '.' + signature\n     return post_process_signature(signature)\n \n \n@@ -597,9 +593,6 @@ def render_function(function, method=True):\n     if method:\n         signature = signature.replace(\n             clean_module_name(function.__module__) + '.', '')\n-    else:\n-        signature = signature.replace(\n-            clean_module_name(function.__module__) + '.', '', 1)\n     subblocks.append('### ' + function.__name__ + '\\n')\n     subblocks.append(code_snippet(signature))\n     docstring = function.__doc__\n@@ -609,7 +602,7 @@ def render_function(function, method=True):\n \n \n def read_page_data(page_data, type):\n-    assert type in ['classes', 'functions']\n+    assert type in ['classes', 'functions', 'methods']\n     data = page_data.get(type, [])\n     for module in page_data.get('all_module_{}'.format(type), []):\n         module_data = []\n@@ -664,6 +657,11 @@ if __name__ == '__main__':\n                     [render_function(method, method=True) for method in methods]))\n             blocks.append('\\n'.join(subblocks))\n \n+        methods = read_page_data(page_data, 'methods')\n+\n+        for method in methods:\n+            blocks.append(render_function(method, method=True))\n+\n         functions = read_page_data(page_data, 'functions')\n \n         for function in functions:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#749413a5d5b94f4335fe5704a107d8b2dd84c7f1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 18 | Lines Deleted: 18 | Files Changed: 1 | Hunks: 18 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 36 | Churn Cumulative: 11146 | Contributors (this commit): 62 | Commits (past 90d): 11 | Contributors (cumulative): 62 | DMM Complexity: None\n\nDIFF:\n@@ -271,10 +271,10 @@ class Conv1D(_Conv):\n             one of `\"channels_last\"` (default) or `\"channels_first\"`.\n             The ordering of the dimensions in the inputs.\n             `\"channels_last\"` corresponds to inputs with shape\n-            `(batch, length, channels)`\n+            `(batch, steps, channels)`\n             (default format for temporal data in Keras)\n             while `\"channels_first\"` corresponds to inputs\n-            with shape `(batch, channels, length)`.\n+            with shape `(batch, channels, steps)`.\n         dilation_rate: an integer or tuple/list of a single integer, specifying\n             the dilation rate to use for dilated convolution.\n             Currently, specifying any `dilation_rate` value != 1 is\n@@ -302,10 +302,10 @@ class Conv1D(_Conv):\n             (see [constraints](../constraints.md)).\n \n     # Input shape\n-        3D tensor with shape: `(batch_size, steps, input_dim)`\n+        3D tensor with shape: `(batch, steps, channels)`\n \n     # Output shape\n-        3D tensor with shape: `(batch_size, new_steps, filters)`\n+        3D tensor with shape: `(batch, new_steps, filters)`\n         `steps` value might have changed due to padding or strides.\n     \"\"\"\n \n@@ -429,18 +429,18 @@ class Conv2D(_Conv):\n \n     # Input shape\n         4D tensor with shape:\n-        `(samples, channels, rows, cols)`\n+        `(batch, channels, rows, cols)`\n         if `data_format` is `\"channels_first\"`\n         or 4D tensor with shape:\n-        `(samples, rows, cols, channels)`\n+        `(batch, rows, cols, channels)`\n         if `data_format` is `\"channels_last\"`.\n \n     # Output shape\n         4D tensor with shape:\n-        `(samples, filters, new_rows, new_cols)`\n+        `(batch, filters, new_rows, new_cols)`\n         if `data_format` is `\"channels_first\"`\n         or 4D tensor with shape:\n-        `(samples, new_rows, new_cols, filters)`\n+        `(batch, new_rows, new_cols, filters)`\n         if `data_format` is `\"channels_last\"`.\n         `rows` and `cols` values might have changed due to padding.\n     \"\"\"\n@@ -557,18 +557,18 @@ class Conv3D(_Conv):\n \n     # Input shape\n         5D tensor with shape:\n-        `(samples, channels, conv_dim1, conv_dim2, conv_dim3)`\n+        `(batch, channels, conv_dim1, conv_dim2, conv_dim3)`\n         if `data_format` is `\"channels_first\"`\n         or 5D tensor with shape:\n-        `(samples, conv_dim1, conv_dim2, conv_dim3, channels)`\n+        `(batch, conv_dim1, conv_dim2, conv_dim3, channels)`\n         if `data_format` is `\"channels_last\"`.\n \n     # Output shape\n         5D tensor with shape:\n-        `(samples, filters, new_conv_dim1, new_conv_dim2, new_conv_dim3)`\n+        `(batch, filters, new_conv_dim1, new_conv_dim2, new_conv_dim3)`\n         if `data_format` is `\"channels_first\"`\n         or 5D tensor with shape:\n-        `(samples, new_conv_dim1, new_conv_dim2, new_conv_dim3, filters)`\n+        `(batch, new_conv_dim1, new_conv_dim2, new_conv_dim3, filters)`\n         if `data_format` is `\"channels_last\"`.\n         `new_conv_dim1`, `new_conv_dim2` and `new_conv_dim3` values might have changed due to padding.\n     \"\"\"\n@@ -1411,9 +1411,9 @@ class SeparableConv1D(_SeparableConv):\n             one of `\"channels_last\"` or `\"channels_first\"`.\n             The ordering of the dimensions in the inputs.\n             `\"channels_last\"` corresponds to inputs with shape\n-            `(batch, height, width, channels)` while `\"channels_first\"`\n+            `(batch, steps, channels)` while `\"channels_first\"`\n             corresponds to inputs with shape\n-            `(batch, channels, height, width)`.\n+            `(batch, channels, steps)`.\n             It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n             If you never set it, then it will be \"channels_last\".\n@@ -1720,18 +1720,18 @@ class DepthwiseConv2D(Conv2D):\n \n     # Input shape\n         4D tensor with shape:\n-        `[batch, channels, rows, cols]`\n+        `(batch, channels, rows, cols)`\n         if `data_format` is `\"channels_first\"`\n         or 4D tensor with shape:\n-        `[batch, rows, cols, channels]`\n+        `(batch, rows, cols, channels)`\n         if `data_format` is `\"channels_last\"`.\n \n     # Output shape\n         4D tensor with shape:\n-        `[batch, filters, new_rows, new_cols]`\n+        `(batch, filters, new_rows, new_cols)`\n         if `data_format` is `\"channels_first\"`\n         or 4D tensor with shape:\n-        `[batch, new_rows, new_cols, filters]`\n+        `(batch, new_rows, new_cols, filters)`\n         if `data_format` is `\"channels_last\"`.\n         `rows` and `cols` values might have changed due to padding.\n     \"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d4c1f69693ec476b33add0d540631021eea36a0c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 4 | Churn Cumulative: 9861 | Contributors (this commit): 117 | Commits (past 90d): 20 | Contributors (cumulative): 117 | DMM Complexity: None\n\nDIFF:\n@@ -1872,9 +1872,9 @@ def batch_normalization(x, mean, var, beta, gamma, axis=-1, epsilon=1e-3):\n     \"\"\"\n     if ndim(x) == 4:\n         # The CPU implementation of FusedBatchNorm only support NHWC\n-        if axis == 1:\n+        if axis == 1 or axis == -3:\n             tf_data_format = 'NCHW'\n-        elif axis == 3:\n+        elif axis == 3 or axis == -1:\n             tf_data_format = 'NHWC'\n         else:\n             tf_data_format = None\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1c4bb1ed8286b723d99b419a6a5e63286353b149", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 18 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 4 | Methods Changed: 4 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 20 | Churn Cumulative: 459 | Contributors (this commit): 18 | Commits (past 90d): 4 | Contributors (cumulative): 23 | DMM Complexity: 1.0\n\nDIFF:\n@@ -58,6 +58,12 @@ class HDF5Matrix(object):\n         else:\n             self.end = end\n         self.normalizer = normalizer\n+        if self.normalizer is not None:\n+            first_val = self.normalizer(self.data[0:1])\n+        else:\n+            first_val = self.data[0:1]\n+        self._base_shape = first_val.shape[1:]\n+        self._base_dtype = first_val.dtype\n \n     def __len__(self):\n         return self.end - self.start\n@@ -101,7 +107,7 @@ class HDF5Matrix(object):\n         # Returns\n             A numpy-style shape tuple.\n         \"\"\"\n-        return (self.end - self.start,) + self.data.shape[1:]\n+        return (self.end - self.start,) + self._base_shape\n \n     @property\n     def dtype(self):\n@@ -110,7 +116,7 @@ class HDF5Matrix(object):\n         # Returns\n             A numpy dtype string.\n         \"\"\"\n-        return self.data.dtype\n+        return self._base_dtype\n \n     @property\n     def ndim(self):\n\n@@ -104,6 +104,16 @@ def test_io_utils(in_tmpdir):\n     normalized_X_train = HDF5Matrix(h5_path, 'my_data', start=0, end=150, normalizer=normalizer)\n     assert np.isclose(normalized_X_train[0][0], X_train[0][0] + 1)\n \n+    # test resizing normalizer\n+    normalizer_rs = lambda x: x[:, ::2]\n+    normalized_rs_X_train = HDF5Matrix(h5_path, 'my_data', start=0, end=150, normalizer=normalizer_rs)\n+    assert (normalized_rs_X_train.shape[1] == 5)\n+\n+    # test dtype changing normalizer\n+    normalizer_dtype = lambda x: x.astype(np.uint8)\n+    normalized_dtype_X_train = HDF5Matrix(h5_path, 'my_data', start=0, end=150, normalizer=normalizer_dtype)\n+    assert (normalized_dtype_X_train.dtype == np.uint8)\n+\n     os.remove(h5_path)\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#da9ce7d8f2e4212cebdacc80f6252b4ae1e68773", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 4 | Methods Changed: 5 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 19 | Churn Cumulative: 2086 | Contributors (this commit): 29 | Commits (past 90d): 8 | Contributors (cumulative): 32 | DMM Complexity: 1.0\n\nDIFF:\n@@ -375,7 +375,7 @@ def evaluate_generator(model, generator,\n             averages.append(np.average([out[i] for out in outs_per_batch],\n                                        weights=batch_sizes))\n         else:\n-            averages.append(float(outs_per_batch[-1][i]))\n+            averages.append(np.float64(outs_per_batch[-1][i]))\n     return unpack_singleton(averages)\n \n \n\n@@ -10,7 +10,7 @@ from keras import optimizers\n from keras import initializers\n from keras import callbacks\n from keras.models import Sequential, Model\n-from keras.layers import Input, Dense, Dropout, add, dot, Lambda\n+from keras.layers import Input, Dense, Dropout, add, dot, Lambda, Layer\n from keras.layers.convolutional import Conv2D\n from keras.layers.pooling import MaxPooling2D, GlobalAveragePooling1D, GlobalAveragePooling2D\n from keras.utils.test_utils import get_test_data\n@@ -500,6 +500,19 @@ def test_TensorBoard(tmpdir):\n             i += 1\n             i = i % max_batch_index\n \n+    class DummyStatefulMetric(Layer):\n+\n+        def __init__(self, name='dummy_stateful_metric', **kwargs):\n+            super(DummyStatefulMetric, self).__init__(name=name, **kwargs)\n+            self.stateful = True\n+            self.state = K.variable(value=0, dtype='int32')\n+\n+        def reset_states(self):\n+            pass\n+\n+        def __call__(self, y_true, y_pred):\n+            return self.state\n+\n     inp = Input((input_dim,))\n     hidden = Dense(num_hidden, activation='relu')(inp)\n     hidden = Dropout(0.1)(hidden)\n@@ -507,7 +520,7 @@ def test_TensorBoard(tmpdir):\n     model = Model(inputs=inp, outputs=output)\n     model.compile(loss='categorical_crossentropy',\n                   optimizer='sgd',\n-                  metrics=['accuracy'])\n+                  metrics=['accuracy', DummyStatefulMetric()])\n \n     # we must generate new callbacks for each test, as they aren't stateless\n     def callbacks_factory(histogram_freq, embeddings_freq=1):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b2979c25d3d7d55a6579de0b2906c66e8fd2e172", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 18 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 18 | Churn Cumulative: 4100 | Contributors (this commit): 18 | Commits (past 90d): 12 | Contributors (cumulative): 21 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1193,6 +1193,9 @@ class Network(Layer):\n         def get_json_type(obj):\n             # If obj is any numpy type\n             if type(obj).__module__ == np.__name__:\n+                if isinstance(obj, np.ndarray):\n+                    return obj.tolist()\n+                else:\n                     return obj.item()\n \n             # If obj is a python 'type'\n\n@@ -9,6 +9,7 @@ from keras.models import Model, Sequential\n from keras import backend as K\n from keras.models import model_from_json, model_from_yaml\n from keras.utils.test_utils import keras_test\n+from keras.initializers import Constant\n \n \n skipif_no_tf_gpu = pytest.mark.skipif(\n@@ -797,5 +798,19 @@ def test_multi_output_mask():\n     assert K.int_shape(z)[1:] == (16, 16, 3)\n \n \n+@keras_test\n+def test_constant_initializer_with_numpy():\n+    model = Sequential()\n+    model.add(Dense(2, input_shape=(3,), kernel_initializer=Constant(np.ones((3, 2)))))\n+    model.add(Dense(3))\n+    model.compile(loss='mse', optimizer='sgd', metrics=['acc'])\n+\n+    json_str = model.to_json()\n+    model_from_json(json_str).summary()\n+\n+    yaml_str = model.to_yaml()\n+    model_from_yaml(yaml_str).summary()\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#dd07a4c41efed22afb5780cd584555cbff141c74", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 22 | Lines Deleted: 32 | Files Changed: 7 | Hunks: 21 | Methods Changed: 10 | Complexity Δ (Sum/Max): -16/0 | Churn Δ: 54 | Churn Cumulative: 13362 | Contributors (this commit): 109 | Commits (past 90d): 24 | Contributors (cumulative): 134 | DMM Complexity: 1.0\n\nDIFF:\n@@ -25,6 +25,7 @@ from .. import optimizers\n from .. import losses\n from .. import metrics as metrics_module\n from ..utils.generic_utils import slice_arrays\n+from ..utils.generic_utils import to_list\n from ..utils.generic_utils import unpack_singleton\n from ..legacy import interfaces\n \n@@ -155,8 +156,7 @@ class Model(Network):\n         masks = self.compute_mask(self.inputs, mask=None)\n         if masks is None:\n             masks = [None for _ in self.outputs]\n-        if not isinstance(masks, list):\n-            masks = [masks]\n+        masks = to_list(masks)\n \n         # Prepare loss weights.\n         if loss_weights is None:\n\n@@ -14,6 +14,7 @@ from .. import backend as K\n from .. import callbacks as cbks\n from ..utils.generic_utils import Progbar\n from ..utils.generic_utils import slice_arrays\n+from ..utils.generic_utils import to_list\n from ..utils.generic_utils import unpack_singleton\n \n \n@@ -152,8 +153,7 @@ def fit_loop(model, f, ins,\n                 callbacks.on_batch_begin(step_index, batch_logs)\n                 outs = f(ins)\n \n-                if not isinstance(outs, list):\n-                    outs = [outs]\n+                outs = to_list(outs)\n                 for l, o in zip(out_labels, outs):\n                     batch_logs[l] = o\n \n@@ -165,8 +165,7 @@ def fit_loop(model, f, ins,\n                 val_outs = test_loop(model, val_f, val_ins,\n                                      steps=validation_steps,\n                                      verbose=0)\n-                if not isinstance(val_outs, list):\n-                    val_outs = [val_outs]\n+                val_outs = to_list(val_outs)\n                 # Same labels assumed.\n                 for l, o in zip(out_labels, val_outs):\n                     epoch_logs['val_' + l] = o\n@@ -198,8 +197,7 @@ def fit_loop(model, f, ins,\n                     ins_batch[i] = ins_batch[i].toarray()\n \n                 outs = f(ins_batch)\n-                if not isinstance(outs, list):\n-                    outs = [outs]\n+                outs = to_list(outs)\n                 for l, o in zip(out_labels, outs):\n                     batch_logs[l] = o\n \n@@ -212,8 +210,7 @@ def fit_loop(model, f, ins,\n                         val_outs = test_loop(model, val_f, val_ins,\n                                              batch_size=batch_size,\n                                              verbose=0)\n-                        if not isinstance(val_outs, list):\n-                            val_outs = [val_outs]\n+                        val_outs = to_list(val_outs)\n                         # Same labels assumed.\n                         for l, o in zip(out_labels, val_outs):\n                             epoch_logs['val_' + l] = o\n@@ -267,8 +264,7 @@ def predict_loop(model, f, ins, batch_size=32, verbose=0, steps=None):\n         unconcatenated_outs = []\n         for step in range(steps):\n             batch_outs = f(ins)\n-            if not isinstance(batch_outs, list):\n-                batch_outs = [batch_outs]\n+            batch_outs = to_list(batch_outs)\n             if step == 0:\n                 for batch_out in batch_outs:\n                     unconcatenated_outs.append([])\n@@ -296,8 +292,7 @@ def predict_loop(model, f, ins, batch_size=32, verbose=0, steps=None):\n                 ins_batch[i] = ins_batch[i].toarray()\n \n             batch_outs = f(ins_batch)\n-            if not isinstance(batch_outs, list):\n-                batch_outs = [batch_outs]\n+            batch_outs = to_list(batch_outs)\n             if batch_index == 0:\n                 # Pre-allocate the results arrays.\n                 for batch_out in batch_outs:\n\n@@ -12,6 +12,7 @@ from ..utils.data_utils import Sequence\n from ..utils.data_utils import GeneratorEnqueuer\n from ..utils.data_utils import OrderedEnqueuer\n from ..utils.generic_utils import Progbar\n+from ..utils.generic_utils import to_list\n from ..utils.generic_utils import unpack_singleton\n from .. import callbacks as cbks\n \n@@ -211,8 +212,7 @@ def fit_generator(model,\n                                             sample_weight=sample_weight,\n                                             class_weight=class_weight)\n \n-                if not isinstance(outs, list):\n-                    outs = [outs]\n+                outs = to_list(outs)\n                 for l, o in zip(out_labels, outs):\n                     batch_logs[l] = o\n \n@@ -236,8 +236,7 @@ def fit_generator(model,\n                             batch_size=batch_size,\n                             sample_weight=val_sample_weights,\n                             verbose=0)\n-                    if not isinstance(val_outs, list):\n-                        val_outs = [val_outs]\n+                    val_outs = to_list(val_outs)\n                     # Same labels assumed.\n                     for l, o in zip(out_labels, val_outs):\n                         epoch_logs['val_' + l] = o\n@@ -342,8 +341,7 @@ def evaluate_generator(model, generator,\n                                  'or (x, y). Found: ' +\n                                  str(generator_output))\n             outs = model.test_on_batch(x, y, sample_weight=sample_weight)\n-            if not isinstance(outs, list):\n-                outs = [outs]\n+            outs = to_list(outs)\n             outs_per_batch.append(outs)\n \n             if x is None or len(x) == 0:\n@@ -450,8 +448,7 @@ def predict_generator(model, generator,\n                 x = generator_output\n \n             outs = model.predict_on_batch(x)\n-            if not isinstance(outs, list):\n-                outs = [outs]\n+            outs = to_list(outs)\n \n             if not all_outs:\n                 for out in outs:\n\n@@ -9,6 +9,7 @@ import numpy as np\n \n from .. import backend as K\n from .. import losses\n+from ..utils.generic_utils import to_list\n \n \n def standardize_single_array(x):\n@@ -321,8 +322,7 @@ def collect_metrics(metrics, output_names):\n         nested_metrics = []\n         for name in output_names:\n             output_metrics = metrics.get(name, [])\n-            if not isinstance(output_metrics, list):\n-                output_metrics = [output_metrics]\n+            output_metrics = to_list(output_metrics)\n             nested_metrics.append(output_metrics)\n         return nested_metrics\n     else:\n\n@@ -8,6 +8,7 @@ import warnings\n from ..engine import Layer, InputSpec\n from .. import backend as K\n from ..utils import conv_utils\n+from ..utils.generic_utils import to_list\n from .. import regularizers\n from .. import constraints\n from .. import activations\n@@ -521,10 +522,8 @@ class Recurrent(Layer):\n             # Compute the full input spec, including state\n             input_spec = self.input_spec\n             state_spec = self.state_spec\n-            if not isinstance(input_spec, list):\n-                input_spec = [input_spec]\n-            if not isinstance(state_spec, list):\n-                state_spec = [state_spec]\n+            input_spec = to_list(input_spec)\n+            state_spec = to_list(state_spec)\n             self.input_spec = input_spec + state_spec\n \n             # Compute the full inputs, including state\n\n@@ -224,8 +224,7 @@ def multi_gpu_model(model, gpus=None, cpu_merge=True, cpu_relocation=False):\n                 # Apply model on slice\n                 # (creating a model replica on the target device).\n                 outputs = model(inputs)\n-                if not isinstance(outputs, list):\n-                    outputs = [outputs]\n+                outputs = to_list(outputs)\n \n                 # Save the outputs for merging back together later.\n                 for o in range(len(outputs)):\n\n@@ -11,6 +11,7 @@ import numpy as np\n \n from ..utils.np_utils import to_categorical\n from ..utils.generic_utils import has_arg\n+from ..utils.generic_utils import to_list\n from ..models import Sequential\n \n \n@@ -291,8 +292,7 @@ class KerasClassifier(BaseWrapper):\n             y = to_categorical(y)\n \n         outputs = self.model.evaluate(x, y, **kwargs)\n-        if not isinstance(outputs, list):\n-            outputs = [outputs]\n+        outputs = to_list(outputs)\n         for name, output in zip(self.model.metrics_names, outputs):\n             if name == 'acc':\n                 return output\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#eb2c1fdc2d5f841e328993e3bd0e1a3de268fe20", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 6 | Files Changed: 3 | Hunks: 5 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 11 | Churn Cumulative: 522 | Contributors (this commit): 23 | Commits (past 90d): 11 | Contributors (cumulative): 26 | DMM Complexity: None\n\nDIFF:\n@@ -23,4 +23,4 @@ from .layers import Input\n from .models import Model\r\n from .models import Sequential\r\n \r\n-__version__ = '2.2.0'\r\n+__version__ = '2.2.1'\r\n\n@@ -12,7 +12,6 @@ import keras_applications\n \n keras_applications.set_keras_submodules(\n     backend=backend,\n-    engine=engine,\n     layers=layers,\n     models=models,\n     utils=utils)\n\n@@ -24,21 +24,21 @@ and is distributed under the MIT license.\n '''\n \n setup(name='Keras',\n-      version='2.2.0',\n+      version='2.2.1',\n       description='Deep Learning for humans',\n       long_description=long_description,\n       author='Francois Chollet',\n       author_email='francois.chollet@gmail.com',\n       url='https://github.com/keras-team/keras',\n-      download_url='https://github.com/keras-team/keras/tarball/2.2.0',\n+      download_url='https://github.com/keras-team/keras/tarball/2.2.1',\n       license='MIT',\n       install_requires=['numpy>=1.9.1',\n                         'scipy>=0.14',\n                         'six>=1.9.0',\n                         'pyyaml',\n                         'h5py',\n-                        'keras_applications==1.0.2',\n-                        'keras_preprocessing==1.0.1'],\n+                        'keras_applications==1.0.4',\n+                        'keras_preprocessing==1.0.2'],\n       extras_require={\n           'visualize': ['pydot>=1.2.4'],\n           'tests': ['pytest',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#be28fd9e06cb16d28730c87f5c5a2b790c1abbcc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 81 | Contributors (this commit): 4 | Commits (past 90d): 5 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -9,6 +9,7 @@ from .. import backend as K\n from ..layers.core import Lambda\n from ..engine.training import Model\n from ..models import clone_model\n+from ..utils.generic_utils import to_list\n \n \n def _get_available_devices():\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#54386efa549f850dff13f79fc3af67799a4e5d4f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 496 | Contributors (this commit): 20 | Commits (past 90d): 10 | Contributors (cumulative): 21 | DMM Complexity: None\n\nDIFF:\n@@ -23,4 +23,4 @@ from .layers import Input\n from .models import Model\r\n from .models import Sequential\r\n \r\n-__version__ = '2.2.1'\r\n+__version__ = '2.2.2'\r\n\n@@ -24,13 +24,13 @@ and is distributed under the MIT license.\n '''\n \n setup(name='Keras',\n-      version='2.2.1',\n+      version='2.2.2',\n       description='Deep Learning for humans',\n       long_description=long_description,\n       author='Francois Chollet',\n       author_email='francois.chollet@gmail.com',\n       url='https://github.com/keras-team/keras',\n-      download_url='https://github.com/keras-team/keras/tarball/2.2.1',\n+      download_url='https://github.com/keras-team/keras/tarball/2.2.2',\n       license='MIT',\n       install_requires=['numpy>=1.9.1',\n                         'scipy>=0.14',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ee02d256611b17d11e37b86bd4f618d7f2a37d84", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 27 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 27 | Churn Cumulative: 605 | Contributors (this commit): 7 | Commits (past 90d): 4 | Contributors (cumulative): 10 | DMM Complexity: 0.9523809523809523\n\nDIFF:\n@@ -42,6 +42,7 @@ class InputLayer(Layer):\n         self.trainable = False\n         self.built = True\n         self.sparse = sparse\n+        self.supports_masking = True\n \n         if input_shape and batch_input_shape:\n             raise ValueError('Only provide the input_shape OR '\n\n@@ -5,6 +5,7 @@ from numpy.testing import assert_allclose\n from keras import backend as K\n from keras import layers\n from keras.models import Model\n+from keras.models import Sequential\n from keras.utils.test_utils import layer_test\n from keras.utils.test_utils import keras_test\n from keras import regularizers\n@@ -343,5 +344,30 @@ def test_activity_regularization():\n     model.compile('rmsprop', 'mse')\n \n \n+@keras_test\n+def test_sequential_as_downstream_of_masking_layer():\n+\n+    inputs = layers.Input(shape=(3, 4))\n+    x = layers.Masking(mask_value=0., input_shape=(3, 4))(inputs)\n+    s = Sequential()\n+    s.add(layers.Dense(5, input_shape=(4,)))\n+    s.add(layers.Activation('relu'))\n+    x = layers.wrappers.TimeDistributed(s)(x)\n+    model = Model(inputs=inputs, outputs=x)\n+    model.compile(optimizer='rmsprop', loss='mse')\n+    model_input = np.random.randint(low=1, high=5, size=(10, 3, 4))\n+    for i in range(4):\n+        model_input[i, i:, :] = 0.\n+    model.fit(model_input,\n+              np.random.random((10, 3, 5)), epochs=1, batch_size=6)\n+\n+    mask_outputs = [model.layers[1].compute_mask(model.layers[1].input)]\n+    mask_outputs += [model.layers[2].compute_mask(model.layers[2].input, mask_outputs[-1])]\n+    func = K.function([model.input], mask_outputs)\n+    mask_outputs_val = func([model_input])\n+    assert np.array_equal(mask_outputs_val[0], np.any(model_input, axis=-1))\n+    assert np.array_equal(mask_outputs_val[1], np.any(model_input, axis=-1))\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#20384818e1c95ce8b575c32a6800d3adf7f25a92", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 3324 | Contributors (this commit): 25 | Commits (past 90d): 12 | Contributors (cumulative): 25 | DMM Complexity: None\n\nDIFF:\n@@ -2031,7 +2031,7 @@ def temporal_padding(x, padding=(1, 1)):\n     return pad(x, [padding], 'channels_last', num_dynamic_axis)\n \n \n-def _padding(x, pattern, axis):\n+def _padding(x, pattern, axis):  # pragma: no cover\n     base_shape = x.shape\n     if b_any([dim < 0 for dim in base_shape]):\n         raise ValueError('CNTK Backend: padding input tensor with '\n@@ -2062,7 +2062,7 @@ def pad(x, pad_info, data_format, num_dynamic_axis):\n         if num_dynamic_axis == 0:\n             pattern = [[0, 0]] + pattern\n         return C.pad(x, pattern=pattern)\n-    else:\n+    else:  # pragma: no cover\n         for (a, p) in enumerate(pad_info):\n             x = _padding(x, p,\n                          a + (1 if num_dynamic_axis == 0 else 0) +\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#93cd2400ef005cca2048e1c78a84f24cb429e0f5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 6061 | Contributors (this commit): 87 | Commits (past 90d): 13 | Contributors (cumulative): 87 | DMM Complexity: 0.0\n\nDIFF:\n@@ -782,8 +782,8 @@ def batch_normalization(x, mean, var, beta, gamma, axis=-1, epsilon=1e-3):\n \n # TODO remove this function when Theano without\n # T.nnet.bn.batch_normalization_train is deprecated\n-def _old_normalize_batch_in_training(x, gamma, beta,\n-                                     reduction_axes, epsilon=1e-3):\n+def _old_normalize_batch_in_training(x, gamma, beta, reduction_axes,\n+                                     epsilon=1e-3):  # pragma: no cover\n     \"\"\"Computes mean and std for batch then apply batch_normalization on batch.\n     \"\"\"\n     if gamma is None:\n@@ -830,7 +830,8 @@ def _old_normalize_batch_in_training(x, gamma, beta,\n \n # TODO remove this if statement when Theano without\n # T.nnet.bn.batch_normalization_test is deprecated\n-def _old_batch_normalization(x, mean, var, beta, gamma, epsilon=1e-3):\n+def _old_batch_normalization(x, mean, var, beta, gamma,\n+                             epsilon=1e-3):  # pragma: no cover\n     \"\"\"Apply batch normalization on x given mean, var, beta and gamma.\n     \"\"\"\n     if gamma is None:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4db04d8701a64ee249dfe6ce09ebd89063bfb99c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 104 | Lines Deleted: 58 | Files Changed: 8 | Hunks: 51 | Methods Changed: 25 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 162 | Churn Cumulative: 1854 | Contributors (this commit): 41 | Commits (past 90d): 12 | Contributors (cumulative): 60 | DMM Complexity: 0.9142857142857143\n\nDIFF:\n@@ -55,7 +55,8 @@ class TestImage(object):\n                 vertical_flip=True)\n             generator.fit(images, augment=True)\n \n-            for x, y in generator.flow(images, np.arange(images.shape[0]),\n+            num_samples = images.shape[0]\n+            for x, y in generator.flow(images, np.arange(num_samples),\n                                        shuffle=False, save_to_dir=str(tmpdir),\n                                        batch_size=3):\n                 assert x.shape == images[:3].shape\n@@ -63,9 +64,9 @@ class TestImage(object):\n                 break\n \n             # Test with sample weights\n-            for x, y, w in generator.flow(images, np.arange(images.shape[0]),\n+            for x, y, w in generator.flow(images, np.arange(num_samples),\n                                           shuffle=False,\n-                                          sample_weight=np.arange(images.shape[0]) + 1,\n+                                          sample_weight=np.arange(num_samples) + 1,\n                                           save_to_dir=str(tmpdir),\n                                           batch_size=3):\n                 assert x.shape == images[:3].shape\n@@ -74,7 +75,7 @@ class TestImage(object):\n                 break\n \n             # Test with `shuffle=True`\n-            for x, y in generator.flow(images, np.arange(images.shape[0]),\n+            for x, y in generator.flow(images, np.arange(num_samples),\n                                        shuffle=True, save_to_dir=str(tmpdir),\n                                        batch_size=3):\n                 assert x.shape == images[:3].shape\n@@ -136,11 +137,13 @@ class TestImage(object):\n \n             with pytest.raises(ValueError) as e_info:\n                 generator.flow((images, x_misc_err), np.arange(dsize), batch_size=3)\n-            assert str(e_info.value).find('All of the arrays in') != -1\n+            assert 'All of the arrays in' in str(e_info.value)\n \n             with pytest.raises(ValueError) as e_info:\n-                generator.flow((images, x_misc1), np.arange(dsize + 1), batch_size=3)\n-            assert str(e_info.value).find('`x` (images tensor) and `y` (labels) ') != -1\n+                generator.flow((images, x_misc1),\n+                               np.arange(dsize + 1),\n+                               batch_size=3)\n+            assert '`x` (images tensor) and `y` (labels) ' in str(e_info.value)\n \n             # Test `flow` behavior as Sequence\n             seq = generator.flow(images, np.arange(images.shape[0]),\n@@ -271,7 +274,8 @@ class TestImage(object):\n                 im_class = count % num_classes\n                 # rotate subfolders\n                 classpaths = paths[im_class]\n-                filename = os.path.join(classpaths[count % len(classpaths)], 'image-{}.jpg'.format(count))\n+                filename = os.path.join(classpaths[count % len(classpaths)],\n+                                        'image-{}.jpg'.format(count))\n                 filenames.append(filename)\n                 im.save(str(tmpdir / filename))\n                 count += 1\n@@ -302,7 +306,8 @@ class TestImage(object):\n             return np.zeros_like(x)\n \n         # Test usage as Sequence\n-        generator = image.ImageDataGenerator(preprocessing_function=preprocessing_function)\n+        generator = image.ImageDataGenerator(\n+            preprocessing_function=preprocessing_function)\n         dir_seq = generator.flow_from_directory(str(tmpdir),\n                                                 target_size=(26, 26),\n                                                 color_mode='rgb',\n@@ -331,7 +336,8 @@ class TestImage(object):\n \n         # create iterator\n         generator = image.ImageDataGenerator()\n-        dir_iterator = generator.flow_from_directory(str(tmpdir), class_mode='input')\n+        dir_iterator = generator.flow_from_directory(str(tmpdir),\n+                                                     class_mode='input')\n         batch = next(dir_iterator)\n \n         # check if input and output have the same shape\n@@ -347,7 +353,8 @@ class TestImage(object):\n         (0.40, 10),\n         (0.50, 8),\n     ])\n-    def test_directory_iterator_with_validation_split(self, validation_split, num_training):\n+    def test_directory_iterator_with_validation_split(self, validation_split,\n+                                                      num_training):\n         num_classes = 2\n         tmp_folder = tempfile.mkdtemp(prefix='test_images')\n \n@@ -374,7 +381,8 @@ class TestImage(object):\n                 im_class = count % num_classes\n                 # rotate subfolders\n                 classpaths = paths[im_class]\n-                filename = os.path.join(classpaths[count % len(classpaths)], 'image-{}.jpg'.format(count))\n+                filename = os.path.join(classpaths[count % len(classpaths)],\n+                                        'image-{}.jpg'.format(count))\n                 filenames.append(filename)\n                 im.save(os.path.join(tmp_folder, filename))\n                 count += 1\n@@ -385,10 +393,12 @@ class TestImage(object):\n         with pytest.raises(ValueError):\n             generator.flow_from_directory(tmp_folder, subset='foo')\n \n-        train_iterator = generator.flow_from_directory(tmp_folder, subset='training')\n+        train_iterator = generator.flow_from_directory(tmp_folder,\n+                                                       subset='training')\n         assert train_iterator.samples == num_training\n \n-        valid_iterator = generator.flow_from_directory(tmp_folder, subset='validation')\n+        valid_iterator = generator.flow_from_directory(tmp_folder,\n+                                                       subset='validation')\n         assert valid_iterator.samples == count - num_training\n \n         # check number of classes and images\n@@ -431,17 +441,17 @@ class TestImage(object):\n         with pytest.raises(ValueError):\n             x = np.random.random((height, width))  # not 3D\n             img = image.array_to_img(x, data_format='channels_first')\n-        with pytest.raises(ValueError):\n+        with pytest.raises(ValueError):  # unknown data_format\n             x = np.random.random((height, width, 3))\n-            img = image.array_to_img(x, data_format='channels')  # unknown data_format\n-        with pytest.raises(ValueError):\n-            x = np.random.random((height, width, 5))  # neither RGB nor gray-scale\n+            img = image.array_to_img(x, data_format='channels')\n+        with pytest.raises(ValueError):  # neither RGB nor gray-scale\n+            x = np.random.random((height, width, 5))\n             img = image.array_to_img(x, data_format='channels_last')\n-        with pytest.raises(ValueError):\n+        with pytest.raises(ValueError):  # unknown data_format\n             x = np.random.random((height, width, 3))\n-            img = image.img_to_array(x, data_format='channels')  # unknown data_format\n-        with pytest.raises(ValueError):\n-            x = np.random.random((height, width, 5, 3))  # neither RGB nor gray-scale\n+            img = image.img_to_array(x, data_format='channels')\n+        with pytest.raises(ValueError):  # neither RGB nor gray-scale\n+            x = np.random.random((height, width, 5, 3))\n             img = image.img_to_array(x, data_format='channels_last')\n \n     def test_random_transforms(self):\n@@ -479,7 +489,8 @@ class TestImage(object):\n         assert transform_dict['zy'] != 0\n         assert transform_dict['zy'] != transform_dict2['zy']\n         assert transform_dict['channel_shift_intensity'] != 0\n-        assert transform_dict['channel_shift_intensity'] != transform_dict2['channel_shift_intensity']\n+        assert (transform_dict['channel_shift_intensity'] !=\n+                transform_dict2['channel_shift_intensity'])\n         assert transform_dict['brightness'] != 0\n         assert transform_dict['brightness'] != transform_dict2['brightness']\n \n@@ -517,8 +528,8 @@ class TestImage(object):\n                                [1., 1., 1.]]])\n         assert np.allclose(generator.apply_transform(x, {'theta': 45}),\n                            x_rotated)\n-        assert np.allclose(image.apply_affine_transform(x, theta=45, channel_axis=2,\n-                                                        fill_mode='constant'), x_rotated)\n+        assert np.allclose(image.apply_affine_transform(\n+            x, theta=45, channel_axis=2, fill_mode='constant'), x_rotated)\n \n     def test_batch_standardize(self):\n         # ImageDataGenerator.standardize should work on batches\n\n@@ -3,7 +3,10 @@\n import numpy as np\n import pytest\n \n-from keras.preprocessing.text import Tokenizer, one_hot, hashing_trick, text_to_word_sequence\n+from keras.preprocessing.text import Tokenizer\n+from keras.preprocessing.text import one_hot\n+from keras.preprocessing.text import hashing_trick\n+from keras.preprocessing.text import text_to_word_sequence\n \n \n def test_one_hot():\n@@ -80,16 +83,19 @@ def test_text_to_word_sequence_multichar_split():\n \n def test_text_to_word_sequence_unicode():\n     text = u'ali! veli? kırk dokuz elli'\n-    assert text_to_word_sequence(text) == [u'ali', u'veli', u'kırk', u'dokuz', u'elli']\n+    assert (text_to_word_sequence(text) ==\n+            [u'ali', u'veli', u'kırk', u'dokuz', u'elli'])\n \n \n def test_text_to_word_sequence_unicode_multichar_split():\n     text = u'ali!stopveli?stopkırkstopdokuzstopelli'\n-    assert text_to_word_sequence(text, split='stop') == [u'ali', u'veli', u'kırk', u'dokuz', u'elli']\n+    assert (text_to_word_sequence(text, split='stop') ==\n+            [u'ali', u'veli', u'kırk', u'dokuz', u'elli'])\n \n \n def test_tokenizer_unicode():\n-    texts = [u'ali veli kırk dokuz elli', u'ali veli kırk dokuz elli veli kırk dokuz']\n+    texts = [u'ali veli kırk dokuz elli',\n+             u'ali veli kırk dokuz elli veli kırk dokuz']\n     tokenizer = Tokenizer(num_words=5)\n     tokenizer.fit_on_texts(texts)\n \n\n@@ -173,7 +173,8 @@ def test_generator_enqueuer_threads():\n \n     \"\"\"\n      Not comparing the order since it is not guaranteed.\n-     It may get ordered, but not a lot, one thread can take the GIL before he was supposed to.\n+     It may get ordered, but not a lot, one thread can take\n+     the GIL before he was supposed to.\n     \"\"\"\n     assert len(set(acc) - set(range(100))) == 0, \"Output is not the same\"\n     enqueuer.stop()\n@@ -187,7 +188,8 @@ def test_generator_enqueuer_processes():\n     acc = []\n     for i in range(100):\n         acc.append(int(next(gen_output)[0, 0, 0, 0]))\n-    assert acc != list(range(100)), \"Order was keep in GeneratorEnqueuer with processes\"\n+    assert acc != list(range(100)), ('Order was keep in GeneratorEnqueuer '\n+                                     'with processes')\n     enqueuer.stop()\n \n \n@@ -210,13 +212,15 @@ def test_generator_enqueuer_fail_processes():\n \n \n def test_ordered_enqueuer_threads():\n-    enqueuer = OrderedEnqueuer(DummySequence([3, 200, 200, 3]), use_multiprocessing=False)\n+    enqueuer = OrderedEnqueuer(DummySequence([3, 200, 200, 3]),\n+                               use_multiprocessing=False)\n     enqueuer.start(3, 10)\n     gen_output = enqueuer.get()\n     acc = []\n     for i in range(100):\n         acc.append(next(gen_output)[0, 0, 0, 0])\n-    assert acc == list(range(100)), \"Order was not keep in GeneratorEnqueuer with threads\"\n+    assert acc == list(range(100)), ('Order was not keep in GeneratorEnqueuer '\n+                                     'with threads')\n     enqueuer.stop()\n \n \n@@ -229,19 +233,22 @@ def test_ordered_enqueuer_threads_not_ordered():\n     acc = []\n     for i in range(100):\n         acc.append(next(gen_output)[0, 0, 0, 0])\n-    assert acc != list(range(100)), \"Order was not keep in GeneratorEnqueuer with threads\"\n+    assert acc != list(range(100)), ('Order was not keep in GeneratorEnqueuer '\n+                                     'with threads')\n     enqueuer.stop()\n \n \n @use_spawn\n def test_ordered_enqueuer_processes():\n-    enqueuer = OrderedEnqueuer(DummySequence([3, 200, 200, 3]), use_multiprocessing=True)\n+    enqueuer = OrderedEnqueuer(DummySequence([3, 200, 200, 3]),\n+                               use_multiprocessing=True)\n     enqueuer.start(3, 10)\n     gen_output = enqueuer.get()\n     acc = []\n     for i in range(100):\n         acc.append(next(gen_output)[0, 0, 0, 0])\n-    assert acc == list(range(100)), \"Order was not keep in GeneratorEnqueuer with processes\"\n+    assert acc == list(range(100)), ('Order was not keep in GeneratorEnqueuer '\n+                                     'with processes')\n     enqueuer.stop()\n \n \n@@ -255,20 +262,24 @@ def test_ordered_enqueuer_fail_threads():\n \n @use_spawn\n def test_on_epoch_end_processes():\n-    enqueuer = OrderedEnqueuer(DummySequence([3, 200, 200, 3]), use_multiprocessing=True)\n+    enqueuer = OrderedEnqueuer(DummySequence([3, 200, 200, 3]),\n+                               use_multiprocessing=True)\n     enqueuer.start(3, 10)\n     gen_output = enqueuer.get()\n     acc = []\n     for i in range(200):\n         acc.append(next(gen_output)[0, 0, 0, 0])\n-    assert acc[100:] == list([k * 5 for k in range(100)]), \"Order was not keep in GeneratorEnqueuer with processes\"\n+    assert acc[100:] == list([k * 5 for k in range(100)]), (\n+        'Order was not keep in GeneratorEnqueuer with processes')\n     enqueuer.stop()\n \n \n @use_spawn\n def test_context_switch():\n-    enqueuer = OrderedEnqueuer(DummySequence([3, 200, 200, 3]), use_multiprocessing=True)\n-    enqueuer2 = OrderedEnqueuer(DummySequence([3, 200, 200, 3], value=15), use_multiprocessing=True)\n+    enqueuer = OrderedEnqueuer(DummySequence([3, 200, 200, 3]),\n+                               use_multiprocessing=True)\n+    enqueuer2 = OrderedEnqueuer(DummySequence([3, 200, 200, 3], value=15),\n+                                use_multiprocessing=True)\n     enqueuer.start(3, 10)\n     enqueuer2.start(3, 10)\n     gen_output = enqueuer.get()\n@@ -297,7 +308,8 @@ def test_context_switch():\n \n \n def test_on_epoch_end_threads():\n-    enqueuer = OrderedEnqueuer(DummySequence([3, 200, 200, 3]), use_multiprocessing=False)\n+    enqueuer = OrderedEnqueuer(DummySequence([3, 200, 200, 3]),\n+                               use_multiprocessing=False)\n     enqueuer.start(3, 10)\n     gen_output = enqueuer.get()\n     acc = []\n@@ -306,7 +318,8 @@ def test_on_epoch_end_threads():\n     acc = []\n     for i in range(100):\n         acc.append(next(gen_output)[0, 0, 0, 0])\n-    assert acc == list([k * 5 for k in range(100)]), \"Order was not keep in GeneratorEnqueuer with processes\"\n+    assert acc == list([k * 5 for k in range(100)]), (\n+        'Order was not keep in GeneratorEnqueuer with processes')\n     enqueuer.stop()\n \n \n@@ -350,7 +363,8 @@ def test_finite_generator_enqueuer_processes():\n     acc = []\n     for output in gen_output:\n         acc.append(int(output[0, 0, 0, 0]))\n-    assert acc != list(range(100)), \"Order was keep in GeneratorEnqueuer with processes\"\n+    assert acc != list(range(100)), ('Order was keep in GeneratorEnqueuer '\n+                                     'with processes')\n     enqueuer.stop()\n \n \n\n@@ -70,7 +70,8 @@ def test_has_arg(fn, name, accept_all, expected):\n             if sys.version_info >= (3,):\n                 raise\n             pytest.skip('Function is not compatible with Python 2')\n-        context.pop('__builtins__', None)  # Sometimes exec adds builtins to the context\n+        # Sometimes exec adds builtins to the context\n+        context.pop('__builtins__', None)\n         fn, = context.values()\n \n     assert has_arg(fn, name, accept_all) is expected\n@@ -125,7 +126,8 @@ def test_func_dump_and_load_backwards_compat(test_func):\n     # this test ensures that models serialized prior to version 2.1.2 can still be\n     # deserialized\n \n-    # see https://github.com/evhub/keras/blob/2.1.1/keras/utils/generic_utils.py#L166\n+    # see:\n+    # https://github.com/evhub/keras/blob/2.1.1/keras/utils/generic_utils.py#L166\n     serialized = marshal.dumps(test_func.__code__).decode('raw_unicode_escape')\n \n     deserialized = func_load(serialized, defaults=test_func.__defaults__)\n\n@@ -47,7 +47,8 @@ def test_io_utils(in_tmpdir):\n     h5_path = 'test.h5'\n     create_dataset(h5_path)\n \n-    # Instantiating HDF5Matrix for the training set, which is a slice of the first 150 elements\n+    # Instantiating HDF5Matrix for the training set,\n+    # which is a slice of the first 150 elements\n     X_train = HDF5Matrix(h5_path, 'my_data', start=0, end=150)\n     y_train = HDF5Matrix(h5_path, 'my_labels', start=0, end=150)\n \n@@ -59,7 +60,8 @@ def test_io_utils(in_tmpdir):\n     assert y_train.shape == (150, 1), 'HDF5Matrix shape should match input array'\n     # But they do not support negative indices, so don't try print(X_train[-1])\n \n-    assert y_train.dtype == np.dtype('i'), 'HDF5Matrix dtype should match input array'\n+    assert y_train.dtype == np.dtype('i'), (\n+        'HDF5Matrix dtype should match input array')\n     assert y_train.ndim == 2, 'HDF5Matrix ndim should match input array'\n     assert y_train.size == 150, 'HDF5Matrix ndim should match input array'\n \n@@ -71,13 +73,15 @@ def test_io_utils(in_tmpdir):\n \n     # Note: you have to use shuffle='batch' or False with HDF5Matrix\n     model.fit(X_train, y_train, batch_size=32, shuffle='batch', verbose=False)\n-    # test that evalutation and prediction don't crash and return reasonable results\n+    # test that evalutation and prediction don't crash and\n+    # return reasonable results\n     out_pred = model.predict(X_test, batch_size=32, verbose=False)\n     out_eval = model.evaluate(X_test, y_test, batch_size=32, verbose=False)\n \n     assert out_pred.shape == (50, 1), 'Prediction shape does not match'\n     assert out_eval.shape == (), 'Shape of evaluation does not match'\n-    assert out_eval > 0, 'Evaluation value does not meet criteria: {}'.format(out_eval)\n+    assert out_eval > 0, (\n+        'Evaluation value does not meet criteria: {}'.format(out_eval))\n \n     # test slicing for shortened array\n     assert len(X_train[0:]) == len(X_train), 'Incorrect shape for sliced data'\n@@ -101,17 +105,20 @@ def test_io_utils(in_tmpdir):\n \n     # test normalizer\n     normalizer = lambda x: x + 1\n-    normalized_X_train = HDF5Matrix(h5_path, 'my_data', start=0, end=150, normalizer=normalizer)\n+    normalized_X_train = HDF5Matrix(h5_path, 'my_data', start=0, end=150,\n+                                    normalizer=normalizer)\n     assert np.isclose(normalized_X_train[0][0], X_train[0][0] + 1)\n \n     # test resizing normalizer\n     normalizer_rs = lambda x: x[:, ::2]\n-    normalized_rs_X_train = HDF5Matrix(h5_path, 'my_data', start=0, end=150, normalizer=normalizer_rs)\n+    normalized_rs_X_train = HDF5Matrix(h5_path, 'my_data', start=0, end=150,\n+                                       normalizer=normalizer_rs)\n     assert (normalized_rs_X_train.shape[1] == 5)\n \n     # test dtype changing normalizer\n     normalizer_dtype = lambda x: x.astype(np.uint8)\n-    normalized_dtype_X_train = HDF5Matrix(h5_path, 'my_data', start=0, end=150, normalizer=normalizer_dtype)\n+    normalized_dtype_X_train = HDF5Matrix(h5_path, 'my_data', start=0, end=150,\n+                                          normalizer=normalizer_dtype)\n     assert (normalized_dtype_X_train.dtype == np.uint8)\n \n     os.remove(h5_path)\n\n@@ -53,7 +53,8 @@ def test_convert_weights():\n \n         # Test equivalence of convert_dense_weights_data_format\n         out1 = model1.predict(x)\n-        layer_utils.convert_dense_weights_data_format(model1.layers[2], prev_shape, target_data_format)\n+        layer_utils.convert_dense_weights_data_format(\n+            model1.layers[2], prev_shape, target_data_format)\n         for (src, dst) in zip(model1.layers, model2.layers):\n             dst.set_weights(src.get_weights())\n         out2 = model2.predict(transpose(x))\n\n@@ -13,7 +13,7 @@ from keras.utils import vis_utils\n \n def test_plot_model():\n     model = Sequential()\n-    model.add(Conv2D(filters=2, kernel_size=(2, 3), input_shape=(3, 5, 5), name='conv'))\n+    model.add(Conv2D(2, kernel_size=(2, 3), input_shape=(3, 5, 5), name='conv'))\n     model.add(Flatten(name='flat'))\n     model.add(Dense(5, name='dense1'))\n     vis_utils.plot_model(model, to_file='model1.png', show_layer_names=False)\n\n@@ -75,7 +75,8 @@ def test_classify_inherit_class_build_fn():\n \n \n def assert_classification_works(clf):\n-    clf.fit(X_train, y_train, sample_weight=np.ones(X_train.shape[0]), batch_size=batch_size, epochs=epochs)\n+    clf.fit(X_train, y_train, sample_weight=np.ones(X_train.shape[0]),\n+            batch_size=batch_size, epochs=epochs)\n \n     score = clf.score(X_train, y_train, batch_size=batch_size)\n     assert np.isscalar(score) and np.isfinite(score)\n@@ -171,11 +172,15 @@ if __name__ == '__main__':\n \n # Usage of sklearn's grid_search\n # from sklearn import grid_search\n-# parameters = dict(hidden_dims = [20, 30], batch_size=[64, 128], epochs=[2], verbose=[0])\n+# parameters = dict(hidden_dims = [20, 30], batch_size=[64, 128],\n+#                   epochs=[2], verbose=[0])\n # classifier = Inherit_class_build_fn_clf()\n # clf = grid_search.GridSearchCV(classifier, parameters)\n # clf.fit(X_train, y_train)\n-# parameters = dict(hidden_dims = [20, 30], batch_size=[64, 128], epochs=[2], verbose=[0])\n+# parameters = dict(hidden_dims = [20, 30], batch_size=[64, 128],\n+#                   epochs=[2], verbose=[0])\n # regressor = Inherit_class_build_fn_reg()\n-# reg = grid_search.GridSearchCV(regressor, parameters, scoring='mean_squared_error', n_jobs=1, cv=2, verbose=2)\n+# reg = grid_search.GridSearchCV(regressor, parameters,\n+#                                scoring='mean_squared_error',\n+#                                n_jobs=1, cv=2, verbose=2)\n # reg.fit(X_train_reg, y_train_reg)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
