{"custom_id": "scrapy#9c9e1a318d83b8e55125fdf7a7fb9482cb4951f8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 5 | Churn Cumulative: 2280 | Contributors (this commit): 30 | Commits (past 90d): 4 | Contributors (cumulative): 30 | DMM Complexity: 0.0\n\nDIFF:\n@@ -361,10 +361,9 @@ class ScrapyAgent:\n     @staticmethod\n     def _headers_from_twisted_response(response):\n         headers = Headers()\n-        if response.length is not None:\n+        if response.length != UNKNOWN_LENGTH:\n             headers[b'Content-Length'] = str(response.length).encode()\n-        for key, value in response.headers.getAllRawHeaders():\n-            headers[key] = value\n+        headers.update(response.headers.getAllRawHeaders())\n         return headers\n \n     def _cb_bodyready(self, txresponse, request):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#0596f2bf6e7fc404333345d1cece01e31fabed8e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 1194 | Contributors (this commit): 24 | Commits (past 90d): 2 | Contributors (cumulative): 24 | DMM Complexity: None\n\nDIFF:\n@@ -16,7 +16,6 @@ from scrapy.utils.defer import (\n     aiter_errback,\n     defer_fail,\n     defer_succeed,\n-    deferred_from_coro,\n     iter_errback,\n     parallel,\n     parallel_async,\n@@ -191,8 +190,8 @@ class Scraper:\n             return defer_succeed(None)\n         if isinstance(result, collections.abc.AsyncIterable):\n             it = aiter_errback(result, self.handle_spider_error, request, response, spider)\n-            dfd = deferred_from_coro(parallel_async(it, self.concurrent_items, self._process_spidermw_output,\n-                                     request, response, spider))\n+            dfd = parallel_async(it, self.concurrent_items, self._process_spidermw_output,\n+                                 request, response, spider)\n         else:\n             it = iter_errback(result, self.handle_spider_error, request, response, spider)\n             dfd = parallel(it, self.concurrent_items, self._process_spidermw_output,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#f422861ef49e8d0e0c2aa4de937fb77b95e063ca", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 188 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 4 | Methods Changed: 19 | Complexity Δ (Sum/Max): 37/37 | Churn Δ: 188 | Churn Cumulative: 1399 | Contributors (this commit): 3 | Commits (past 90d): 1 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,11 +1,15 @@\n+import collections.abc\n from unittest import mock\n \n+from twisted.internet import defer\n from twisted.trial.unittest import TestCase\n from twisted.python.failure import Failure\n \n from scrapy.spiders import Spider\n from scrapy.http import Request, Response\n from scrapy.exceptions import _InvalidOutput\n+from scrapy.utils.asyncgen import _process_iterable_universal, as_async_generator, collect_asyncgen\n+from scrapy.utils.defer import deferred_from_coro\n from scrapy.utils.test import get_crawler\n from scrapy.core.spidermw import SpiderMiddlewareManager\n \n@@ -101,3 +105,187 @@ class ProcessSpiderExceptionReRaise(SpiderMiddlewareTestCase):\n         result = self._scrape_response()\n         self.assertIsInstance(result, Failure)\n         self.assertIsInstance(result.value, ZeroDivisionError)\n+\n+\n+class BaseAsyncSpiderMiddlewareTestCase(SpiderMiddlewareTestCase):\n+    \"\"\" Helpers for testing sync, async and mixed middlewares.\n+\n+    Should work for process_spider_output and, when it's supported, process_start_requests.\n+    \"\"\"\n+\n+    RESULT_COUNT = 3  # to simplify checks, let everything return 3 objects\n+\n+    @defer.inlineCallbacks\n+    def _get_middleware_result(self, *mw_classes):\n+        for mw_cls in mw_classes:\n+            self.mwman._add_middleware(mw_cls())\n+        result = yield self.mwman.scrape_response(self._scrape_func, self.response, self.request, self.spider)\n+        return result\n+\n+    def assertAsyncGeneratorNotIterable(self, o):\n+        with self.assertRaisesRegex(TypeError,\n+                                    \"'(async_generator|MutableAsyncChain)' object is not iterable\"):\n+            list(o)\n+\n+    @defer.inlineCallbacks\n+    def _test_simple_base(self, *mw_classes):\n+        result = yield self._get_middleware_result(*mw_classes)\n+        self.assertIsInstance(result, collections.abc.Iterable)\n+        result_list = list(result)\n+        self.assertEqual(len(result_list), self.RESULT_COUNT)\n+        self.assertIsInstance(result_list[0], self.ITEM_TYPE)\n+\n+    @defer.inlineCallbacks\n+    def _test_asyncgen_base(self, *mw_classes):\n+        result = yield self._get_middleware_result(*mw_classes)\n+        self.assertIsInstance(result, collections.abc.AsyncIterator)\n+        result_list = yield deferred_from_coro(collect_asyncgen(result))\n+        self.assertEqual(len(result_list), self.RESULT_COUNT)\n+        self.assertIsInstance(result_list[0], self.ITEM_TYPE)\n+\n+    @defer.inlineCallbacks\n+    def _test_asyncgen_fail(self, *mw_classes):\n+        result = yield self._get_middleware_result(*mw_classes)\n+        self.assertIsInstance(result, collections.abc.Iterable)\n+        self.assertAsyncGeneratorNotIterable(result)\n+\n+\n+class ProcessSpiderOutputSimpleMiddleware:\n+    def process_spider_output(self, response, result, spider):\n+        for r in result:\n+            yield r\n+\n+\n+class ProcessSpiderOutputAsyncGenMiddleware:\n+    async def process_spider_output(self, response, result, spider):\n+        async for r in as_async_generator(result):\n+            yield r\n+\n+\n+class ProcessSpiderOutputUniversalMiddleware:\n+    def process_spider_output(self, response, result, spider):\n+        @_process_iterable_universal\n+        async def process(result):\n+            async for r in result:\n+                yield r\n+        return process(result)\n+\n+\n+class ProcessSpiderOutputSimple(BaseAsyncSpiderMiddlewareTestCase):\n+    \"\"\" process_spider_output tests for simple callbacks\"\"\"\n+\n+    ITEM_TYPE = dict\n+    MW_SIMPLE = ProcessSpiderOutputSimpleMiddleware\n+    MW_ASYNCGEN = ProcessSpiderOutputAsyncGenMiddleware\n+    MW_UNIVERSAL = ProcessSpiderOutputUniversalMiddleware\n+\n+    def _scrape_func(self, *args, **kwargs):\n+        yield {'foo': 1}\n+        yield {'foo': 2}\n+        yield {'foo': 3}\n+\n+    def test_simple(self):\n+        \"\"\" Simple mw \"\"\"\n+        return self._test_simple_base(self.MW_SIMPLE)\n+\n+    def test_asyncgen(self):\n+        \"\"\" Asyncgen mw \"\"\"\n+        return self._test_asyncgen_base(self.MW_ASYNCGEN)\n+\n+    def test_simple_asyncgen(self):\n+        \"\"\" Simple mw -> asyncgen mw \"\"\"\n+        return self._test_asyncgen_base(self.MW_ASYNCGEN,\n+                                        self.MW_SIMPLE)\n+\n+    def test_asyncgen_simple(self):\n+        \"\"\" Asyncgen mw -> simple mw; cannot work \"\"\"\n+        return self._test_asyncgen_fail(self.MW_SIMPLE,\n+                                        self.MW_ASYNCGEN)\n+\n+    def test_universal(self):\n+        \"\"\" Universal mw \"\"\"\n+        return self._test_simple_base(self.MW_UNIVERSAL)\n+\n+    def test_universal_simple(self):\n+        \"\"\" Universal mw -> simple mw \"\"\"\n+        return self._test_simple_base(self.MW_SIMPLE,\n+                                      self.MW_UNIVERSAL)\n+\n+    def test_simple_universal(self):\n+        \"\"\" Simple mw -> universal mw \"\"\"\n+        return self._test_simple_base(self.MW_UNIVERSAL,\n+                                      self.MW_SIMPLE)\n+\n+    def test_universal_asyncgen(self):\n+        \"\"\" Universal mw -> asyncgen mw \"\"\"\n+        return self._test_asyncgen_base(self.MW_ASYNCGEN,\n+                                        self.MW_UNIVERSAL)\n+\n+    def test_asyncgen_universal(self):\n+        \"\"\" Asyncgen mw -> universal mw \"\"\"\n+        return self._test_asyncgen_base(self.MW_UNIVERSAL,\n+                                        self.MW_ASYNCGEN)\n+\n+\n+class ProcessSpiderOutputAsyncGen(ProcessSpiderOutputSimple):\n+    \"\"\" process_spider_output tests for async generator callbacks \"\"\"\n+\n+    async def _scrape_func(self, *args, **kwargs):\n+        for item in super()._scrape_func():\n+            yield item\n+\n+    def test_simple(self):\n+        \"\"\" Simple mw; cannot work \"\"\"\n+        return self._test_asyncgen_fail(self.MW_SIMPLE)\n+\n+    @defer.inlineCallbacks\n+    def test_simple_asyncgen(self):\n+        \"\"\" Simple mw -> asyncgen mw; cannot work \"\"\"\n+        result = yield self._get_middleware_result(\n+            self.MW_ASYNCGEN,\n+            self.MW_SIMPLE)\n+        self.assertIsInstance(result, collections.abc.AsyncIterable)\n+        self.assertAsyncGeneratorNotIterable(result)\n+\n+    def test_universal(self):\n+        \"\"\" Universal mw \"\"\"\n+        return self._test_asyncgen_base(self.MW_UNIVERSAL)\n+\n+    def test_universal_simple(self):\n+        \"\"\" Universal mw -> simple mw; cannot work \"\"\"\n+        return self._test_asyncgen_fail(self.MW_SIMPLE,\n+                                        self.MW_UNIVERSAL)\n+\n+    def test_simple_universal(self):\n+        \"\"\" Simple mw -> universal mw; cannot work \"\"\"\n+        return self._test_asyncgen_fail(self.MW_UNIVERSAL,\n+                                        self.MW_SIMPLE)\n+\n+\n+class ProcessStartRequestsSimpleMiddleware:\n+    def process_start_requests(self, start_requests, spider):\n+        for r in start_requests:\n+            yield r\n+\n+\n+class ProcessStartRequestsSimple(BaseAsyncSpiderMiddlewareTestCase):\n+    \"\"\" process_start_requests tests for simple start_requests\"\"\"\n+\n+    ITEM_TYPE = Request\n+    MW_SIMPLE = ProcessStartRequestsSimpleMiddleware\n+\n+    def _start_requests(self):\n+        for i in range(3):\n+            yield Request(f'https://example.com/{i}', dont_filter=True)\n+\n+    @defer.inlineCallbacks\n+    def _get_middleware_result(self, *mw_classes):\n+        for mw_cls in mw_classes:\n+            self.mwman._add_middleware(mw_cls())\n+        start_requests = iter(self._start_requests())\n+        results = yield self.mwman.process_start_requests(start_requests, self.spider)\n+        return results\n+\n+    def test_simple(self):\n+        \"\"\" Simple mw \"\"\"\n+        self._test_simple_base(self.MW_SIMPLE)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#0638d6f01c41f12311b21f06fee5c71f5d08569f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 11 | Files Changed: 1 | Hunks: 7 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 28 | Churn Cumulative: 659 | Contributors (this commit): 9 | Commits (past 90d): 5 | Contributors (cumulative): 9 | DMM Complexity: 0.6\n\nDIFF:\n@@ -3,7 +3,7 @@ Spider Middleware manager\n \n See documentation in docs/topics/spider-middleware.rst\n \"\"\"\n-import inspect\n+import collections.abc\n from itertools import islice\n \n from twisted.python.failure import Failure\n@@ -96,11 +96,10 @@ class SpiderMiddlewareManager(MiddlewareManager):\n     def _process_spider_output(self, response, spider, result, start_index=0):\n         # items in this iterable do not need to go through the process_spider_output\n         # chain, they went through it already from the process_spider_exception method\n-        if inspect.isasyncgen(result):\n-            iter_class = MutableAsyncChain\n+        if isinstance(result, collections.abc.AsyncIterator):\n+            recovered = MutableAsyncChain()\n         else:\n-            iter_class = MutableChain\n-        recovered = iter_class()\n+            recovered = MutableChain()\n \n         method_list = islice(self.methods['process_spider_output'], start_index, None)\n         for method_index, method in enumerate(method_list, start=start_index):\n@@ -121,16 +120,23 @@ class SpiderMiddlewareManager(MiddlewareManager):\n                        f\"iterable, got {type(result)}\")\n                 raise _InvalidOutput(msg)\n \n-        return iter_class(result, recovered)\n+        # check this again as the middlewares could change \"result\" from sync to async\n+        if isinstance(result, collections.abc.AsyncIterator):\n+            return MutableAsyncChain(result, recovered)\n+        else:\n+            return MutableChain(result, recovered)\n \n     def _process_callback_output(self, response, spider, result):\n-        if inspect.isasyncgen(result):\n-            iter_class = MutableAsyncChain\n+        if isinstance(result, collections.abc.AsyncIterator):\n+            recovered = MutableAsyncChain()\n         else:\n-            iter_class = MutableChain\n-        recovered = iter_class()\n+            recovered = MutableChain()\n         result = self._evaluate_iterable(response, spider, result, 0, recovered)\n-        return iter_class(self._process_spider_output(response, spider, result), recovered)\n+        result = self._process_spider_output(response, spider, result)\n+        if isinstance(result, collections.abc.AsyncIterator):\n+            return MutableAsyncChain(result, recovered)\n+        else:\n+            return MutableChain(result, recovered)\n \n     def scrape_response(self, scrape_func, response, request, spider):\n         def process_callback_output(result):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#1d200258a527668186ea84f14e7c2b23b3200ab5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 604 | Contributors (this commit): 28 | Commits (past 90d): 3 | Contributors (cumulative): 28 | DMM Complexity: None\n\nDIFF:\n@@ -31,7 +31,7 @@ install_requires = [\n     'zope.interface>=4.1.3',\n     'protego>=0.1.15',\n     'itemadapter>=0.1.0',\n-    'h2>=3.2.0',\n+    'h2>=3.0,<4.0',\n ]\n extras_require = {}\n cpython_dependencies = [\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#b5f501df7bc3917af3d144bb6556a763f381cd7e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): -3/0 | Churn Δ: 7 | Churn Cumulative: 511 | Contributors (this commit): 17 | Commits (past 90d): 5 | Contributors (cumulative): 17 | DMM Complexity: 0.0\n\nDIFF:\n@@ -136,8 +136,6 @@ class _AsyncCooperatorAdapter:\n         self.anext_deferred = None\n         result = self.callable(result, *self.callable_args, **self.callable_kwargs)\n         d = self.waiting_deferreds.pop(0)\n-        if d.called:\n-            raise ValueError('Deferred in waiting_deferreds already called')\n         if isinstance(result, defer.Deferred):\n             result.chainDeferred(d)\n         else:\n@@ -152,8 +150,6 @@ class _AsyncCooperatorAdapter:\n         failure.trap(StopAsyncIteration)\n         self.finished = True\n         for d in self.waiting_deferreds:\n-            if d.called:\n-                raise ValueError('Deferred in waiting_deferreds already called')\n             d.callback(None)\n \n     def _call_anext(self):\n@@ -162,9 +158,6 @@ class _AsyncCooperatorAdapter:\n         self.anext_deferred = deferred_from_coro(self.aiterator.__anext__())\n         self.anext_deferred.addCallbacks(self._callback, self._errback)\n \n-    def __iter__(self):\n-        return self\n-\n     def __next__(self):\n         # This puts a new Deferred into self.waiting_deferreds and returns it.\n         # It also calls __anext__() if needed.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#6803779eb7e408b275da62f670aba9deaf3eade9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 28 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 4 | Methods Changed: 7 | Complexity Δ (Sum/Max): 6/6 | Churn Δ: 29 | Churn Cumulative: 133 | Contributors (this commit): 2 | Commits (past 90d): 6 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -57,6 +57,6 @@ def _process_iterable_universal(process_async):\n         if hasattr(iterable, '__iter__'):\n             # convert process_async to process_sync\n             return process_sync(iterable, *args, **kwargs)\n-        raise ValueError(f\"Wrong iterable type {type(iterable)}\")\n+        raise TypeError(f\"Wrong iterable type {type(iterable)}\")\n \n     return process\n\n@@ -2,6 +2,7 @@ from twisted.trial import unittest\n \n from scrapy.utils.asyncgen import as_async_generator, collect_asyncgen, _process_iterable_universal\n from scrapy.utils.defer import deferred_f_from_coro_f\n+from scrapy.utils.test import get_web_client_agent_req\n \n \n class AsyncgenUtilsTest(unittest.TestCase):\n@@ -26,6 +27,13 @@ async def process_iterable(iterable):\n         yield i * 2\n \n \n+@_process_iterable_universal\n+async def process_iterable_awaiting(iterable):\n+    async for i in iterable:\n+        yield i * 2\n+        await get_web_client_agent_req('http://example.com')\n+\n+\n class ProcessIterableUniversalTest(unittest.TestCase):\n \n     def test_normal(self):\n@@ -38,3 +46,22 @@ class ProcessIterableUniversalTest(unittest.TestCase):\n         iterable = as_async_generator([1, 2, 3])\n         results = await collect_asyncgen(process_iterable(iterable))\n         self.assertEqual(results, [2, 4, 6])\n+\n+    @deferred_f_from_coro_f\n+    async def test_blocking(self):\n+        iterable = [1, 2, 3]\n+        with self.assertRaisesRegex(RuntimeError, \"Synchronously-called function\"):\n+            list(process_iterable_awaiting(iterable))\n+\n+    def test_invalid_iterable(self):\n+        with self.assertRaisesRegex(TypeError, \"Wrong iterable type\"):\n+            process_iterable(None)\n+\n+    @deferred_f_from_coro_f\n+    async def test_invalid_process(self):\n+        @_process_iterable_universal\n+        def process_iterable_invalid(iterable):\n+            pass\n+\n+        with self.assertRaisesRegex(ValueError, \"process_async returned wrong type\"):\n+            list(process_iterable_invalid([]))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#d458ccff3b2d6df94df1aa86eeb7d2505d62f2d6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 393 | Contributors (this commit): 10 | Commits (past 90d): 9 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -41,7 +41,7 @@ def get_retry_request(\n     spider: Spider,\n     reason: Union[str, Exception] = 'unspecified',\n     max_retry_times: Optional[int] = None,\n-    priority_adjust: Union[int, float, None] = None,\n+    priority_adjust: Optional[int] = None,\n     logger: Logger = retry_logger,\n     stats_base_key: str = 'retry',\n ):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#ad7456746961fb23beb3ebc051ee1ab0ed82a91e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1040 | Contributors (this commit): 33 | Commits (past 90d): 1 | Contributors (cumulative): 33 | DMM Complexity: None\n\nDIFF:\n@@ -71,7 +71,7 @@ def _urlencode(seq, enc):\n     values = [(to_bytes(k, enc), to_bytes(v, enc))\n               for k, vs in seq\n               for v in (vs if is_listlike(vs) else [vs])]\n-    return urlencode(values, doseq=1)\n+    return urlencode(values, doseq=True)\n \n \n def _get_form(response, formname, formid, formnumber, formxpath):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#9e7cbc05ae10ab6c1335d92b4d41429ba8e2bf24", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 607 | Contributors (this commit): 14 | Commits (past 90d): 4 | Contributors (cumulative): 19 | DMM Complexity: None\n\nDIFF:\n@@ -50,7 +50,7 @@ class _BenchSpider(scrapy.Spider):\n \n     def start_requests(self):\n         qargs = {'total': self.total, 'show': self.show}\n-        url = f'{self.baseurl}?{urlencode(qargs, doseq=1)}'\n+        url = f'{self.baseurl}?{urlencode(qargs, doseq=True)}'\n         return [scrapy.Request(url, dont_filter=True)]\n \n     def parse(self, response):\n\n@@ -45,7 +45,7 @@ class FollowAllSpider(MetaSpider):\n         self.urls_visited = []\n         self.times = []\n         qargs = {'total': total, 'show': show, 'order': order, 'maxlatency': maxlatency}\n-        url = self.mockserver.url(f\"/follow?{urlencode(qargs, doseq=1)}\")\n+        url = self.mockserver.url(f\"/follow?{urlencode(qargs, doseq=True)}\")\n         self.start_urls = [url]\n \n     def parse(self, response):\n@@ -245,7 +245,7 @@ class BrokenStartRequestsSpider(FollowAllSpider):\n \n         for s in range(100):\n             qargs = {'total': 10, 'seed': s}\n-            url = self.mockserver.url(f\"/follow?{urlencode(qargs, doseq=1)}\")\n+            url = self.mockserver.url(f\"/follow?{urlencode(qargs, doseq=True)}\")\n             yield Request(url, meta={'seed': s})\n             if self.fail_yielding:\n                 2 / 0\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#849472535ef9490e8cc2a62cc7f1835b2bc3eaba", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 65 | Contributors (this commit): 2 | Commits (past 90d): 4 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -11,6 +11,7 @@ async def collect_asyncgen(result):\n \n \n async def as_async_generator(it):\n+    \"\"\" Wraps an iterator (sync or async) into an async generator. \"\"\"\n     if isinstance(it, collections.abc.AsyncIterator):\n         async for r in it:\n             yield r\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#30ed7fa349214ad11b4d13c981cbd2fc63ddaf42", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 21 | Files Changed: 2 | Hunks: 11 | Methods Changed: 7 | Complexity Δ (Sum/Max): 0/1 | Churn Δ: 31 | Churn Cumulative: 2089 | Contributors (this commit): 10 | Commits (past 90d): 8 | Contributors (cumulative): 12 | DMM Complexity: 0.0\n\nDIFF:\n@@ -20,10 +20,6 @@ def _isiterable(possible_iterator):\n     return hasattr(possible_iterator, '__iter__') or hasattr(possible_iterator, '__aiter__')\n \n \n-def _fname(f):\n-    return f\"{f.__self__.__class__.__name__}.{f.__func__.__name__}\"\n-\n-\n class SpiderMiddlewareManager(MiddlewareManager):\n \n     component_name = 'spider middleware'\n@@ -48,7 +44,7 @@ class SpiderMiddlewareManager(MiddlewareManager):\n             try:\n                 result = method(response=response, spider=spider)\n                 if result is not None:\n-                    msg = (f\"Middleware {_fname(method)} must return None \"\n+                    msg = (f\"Middleware {method.__qualname__} must return None \"\n                            f\"or raise an exception, got {type(result)}\")\n                     raise _InvalidOutput(msg)\n             except _InvalidOutput:\n@@ -88,7 +84,7 @@ class SpiderMiddlewareManager(MiddlewareManager):\n             elif result is None:\n                 continue\n             else:\n-                msg = (f\"Middleware {_fname(method)} must return None \"\n+                msg = (f\"Middleware {method.__qualname__} must return None \"\n                        f\"or an iterable, got {type(result)}\")\n                 raise _InvalidOutput(msg)\n         return _failure\n@@ -96,7 +92,8 @@ class SpiderMiddlewareManager(MiddlewareManager):\n     def _process_spider_output(self, response, spider, result, start_index=0):\n         # items in this iterable do not need to go through the process_spider_output\n         # chain, they went through it already from the process_spider_exception method\n-        if isinstance(result, collections.abc.AsyncIterator):\n+        result_async = isinstance(result, collections.abc.AsyncIterator)\n+        if result_async:\n             recovered = MutableAsyncChain()\n         else:\n             recovered = MutableChain()\n@@ -116,9 +113,11 @@ class SpiderMiddlewareManager(MiddlewareManager):\n             if _isiterable(result):\n                 result = self._evaluate_iterable(response, spider, result, method_index + 1, recovered)\n             else:\n-                msg = (f\"Middleware {_fname(method)} must return an \"\n+                msg = (f\"Middleware {method.__qualname__} must return an \"\n                        f\"iterable, got {type(result)}\")\n                 raise _InvalidOutput(msg)\n+            if result_async and isinstance(result, collections.abc.Iterator):\n+                raise TypeError(f\"Synchronous {method.__qualname__} called with an async iterable\")\n \n         # check this again as the middlewares could change \"result\" from sync to async\n         if isinstance(result, collections.abc.AsyncIterator):\n\n@@ -122,11 +122,6 @@ class BaseAsyncSpiderMiddlewareTestCase(SpiderMiddlewareTestCase):\n         result = yield self.mwman.scrape_response(self._scrape_func, self.response, self.request, self.spider)\n         return result\n \n-    def assertAsyncGeneratorNotIterable(self, o):\n-        with self.assertRaisesRegex(TypeError,\n-                                    \"'(async_generator|MutableAsyncChain)' object is not iterable\"):\n-            list(o)\n-\n     @defer.inlineCallbacks\n     def _test_simple_base(self, *mw_classes):\n         result = yield self._get_middleware_result(*mw_classes)\n@@ -145,9 +140,8 @@ class BaseAsyncSpiderMiddlewareTestCase(SpiderMiddlewareTestCase):\n \n     @defer.inlineCallbacks\n     def _test_asyncgen_fail(self, *mw_classes):\n-        result = yield self._get_middleware_result(*mw_classes)\n-        self.assertIsInstance(result, collections.abc.Iterable)\n-        self.assertAsyncGeneratorNotIterable(result)\n+        with self.assertRaisesRegex(TypeError, \"Synchronous .+ called with an async iterable\"):\n+            yield self._get_middleware_result(*mw_classes)\n \n \n class ProcessSpiderOutputSimpleMiddleware:\n@@ -238,14 +232,10 @@ class ProcessSpiderOutputAsyncGen(ProcessSpiderOutputSimple):\n         \"\"\" Simple mw; cannot work \"\"\"\n         return self._test_asyncgen_fail(self.MW_SIMPLE)\n \n-    @defer.inlineCallbacks\n     def test_simple_asyncgen(self):\n         \"\"\" Simple mw -> asyncgen mw; cannot work \"\"\"\n-        result = yield self._get_middleware_result(\n-            self.MW_ASYNCGEN,\n+        return self._test_asyncgen_fail(self.MW_ASYNCGEN,\n                                         self.MW_SIMPLE)\n-        self.assertIsInstance(result, collections.abc.AsyncIterable)\n-        self.assertAsyncGeneratorNotIterable(result)\n \n     def test_universal(self):\n         \"\"\" Universal mw \"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#7bd1d888d49d238622007e659e54af76e82bf1c1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 4 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 684 | Contributors (this commit): 9 | Commits (past 90d): 7 | Contributors (cumulative): 9 | DMM Complexity: 0.0\n\nDIFF:\n@@ -92,8 +92,8 @@ class SpiderMiddlewareManager(MiddlewareManager):\n     def _process_spider_output(self, response, spider, result, start_index=0):\n         # items in this iterable do not need to go through the process_spider_output\n         # chain, they went through it already from the process_spider_exception method\n-        result_async = isinstance(result, collections.abc.AsyncIterator)\n-        if result_async:\n+        last_result_async = isinstance(result, collections.abc.AsyncIterator)\n+        if last_result_async:\n             recovered = MutableAsyncChain()\n         else:\n             recovered = MutableChain()\n@@ -116,11 +116,11 @@ class SpiderMiddlewareManager(MiddlewareManager):\n                 msg = (f\"Middleware {method.__qualname__} must return an \"\n                        f\"iterable, got {type(result)}\")\n                 raise _InvalidOutput(msg)\n-            if result_async and isinstance(result, collections.abc.Iterator):\n+            if last_result_async and isinstance(result, collections.abc.Iterator):\n                 raise TypeError(f\"Synchronous {method.__qualname__} called with an async iterable\")\n+            last_result_async = isinstance(result, collections.abc.AsyncIterator)\n \n-        # check this again as the middlewares could change \"result\" from sync to async\n-        if isinstance(result, collections.abc.AsyncIterator):\n+        if last_result_async:\n             return MutableAsyncChain(result, recovered)\n         else:\n             return MutableChain(result, recovered)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#9e3b868dd83a3ac93dfe04b53d5130145154f478", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 13 | Files Changed: 2 | Hunks: 7 | Methods Changed: 8 | Complexity Δ (Sum/Max): -8/0 | Churn Δ: 19 | Churn Cumulative: 986 | Contributors (this commit): 14 | Commits (past 90d): 9 | Contributors (cumulative): 20 | DMM Complexity: 0.2\n\nDIFF:\n@@ -36,8 +36,7 @@ class DownloaderMiddlewareManager(MiddlewareManager):\n                 response = yield deferred_from_coro(method(request=request, spider=spider))\n                 if response is not None and not isinstance(response, (Response, Request)):\n                     raise _InvalidOutput(\n-                        f\"Middleware {method.__self__.__class__.__name__}\"\n-                        \".process_request must return None, Response or \"\n+                        f\"Middleware {method.__qualname__} must return None, Response or \"\n                         f\"Request, got {response.__class__.__name__}\"\n                     )\n                 if response:\n@@ -55,8 +54,7 @@ class DownloaderMiddlewareManager(MiddlewareManager):\n                 response = yield deferred_from_coro(method(request=request, response=response, spider=spider))\n                 if not isinstance(response, (Response, Request)):\n                     raise _InvalidOutput(\n-                        f\"Middleware {method.__self__.__class__.__name__}\"\n-                        \".process_response must return Response or Request, \"\n+                        f\"Middleware {method.__qualname__} must return Response or Request, \"\n                         f\"got {type(response)}\"\n                     )\n                 if isinstance(response, Request):\n@@ -70,8 +68,7 @@ class DownloaderMiddlewareManager(MiddlewareManager):\n                 response = yield deferred_from_coro(method(request=request, exception=exception, spider=spider))\n                 if response is not None and not isinstance(response, (Response, Request)):\n                     raise _InvalidOutput(\n-                        f\"Middleware {method.__self__.__class__.__name__}\"\n-                        \".process_exception must return None, Response or \"\n+                        f\"Middleware {method.__qualname__} must return None, Response or \"\n                         f\"Request, got {type(response)}\"\n                     )\n                 if response:\n\n@@ -18,10 +18,6 @@ def _isiterable(possible_iterator):\n     return hasattr(possible_iterator, '__iter__')\n \n \n-def _fname(f):\n-    return f\"{f.__self__.__class__.__name__}.{f.__func__.__name__}\"\n-\n-\n class SpiderMiddlewareManager(MiddlewareManager):\n \n     component_name = 'spider middleware'\n@@ -46,7 +42,7 @@ class SpiderMiddlewareManager(MiddlewareManager):\n             try:\n                 result = method(response=response, spider=spider)\n                 if result is not None:\n-                    msg = (f\"Middleware {_fname(method)} must return None \"\n+                    msg = (f\"Middleware {method.__qualname__} must return None \"\n                            f\"or raise an exception, got {type(result)}\")\n                     raise _InvalidOutput(msg)\n             except _InvalidOutput:\n@@ -83,7 +79,7 @@ class SpiderMiddlewareManager(MiddlewareManager):\n             elif result is None:\n                 continue\n             else:\n-                msg = (f\"Middleware {_fname(method)} must return None \"\n+                msg = (f\"Middleware {method.__qualname__} must return None \"\n                        f\"or an iterable, got {type(result)}\")\n                 raise _InvalidOutput(msg)\n         return _failure\n@@ -108,7 +104,7 @@ class SpiderMiddlewareManager(MiddlewareManager):\n             if _isiterable(result):\n                 result = self._evaluate_iterable(response, spider, result, method_index + 1, recovered)\n             else:\n-                msg = (f\"Middleware {_fname(method)} must return an \"\n+                msg = (f\"Middleware {method.__qualname__} must return an \"\n                        f\"iterable, got {type(result)}\")\n                 raise _InvalidOutput(msg)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#a9e96f99077865bc2d844ecf0ae174db97ba6d8b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 56 | Lines Deleted: 35 | Files Changed: 6 | Hunks: 44 | Methods Changed: 60 | Complexity Δ (Sum/Max): -38/1 | Churn Δ: 91 | Churn Cumulative: 2709 | Contributors (this commit): 37 | Commits (past 90d): 24 | Contributors (cumulative): 75 | DMM Complexity: 0.6666666666666666\n\nDIFF:\n@@ -3,8 +3,12 @@ Downloader Middleware manager\n \n See documentation in docs/topics/downloader-middleware.rst\n \"\"\"\n-from twisted.internet import defer\n+from typing import Callable, Union\n \n+from twisted.internet import defer\n+from twisted.python.failure import Failure\n+\n+from scrapy import Spider\n from scrapy.exceptions import _InvalidOutput\n from scrapy.http import Request, Response\n from scrapy.middleware import MiddlewareManager\n@@ -29,9 +33,9 @@ class DownloaderMiddlewareManager(MiddlewareManager):\n         if hasattr(mw, 'process_exception'):\n             self.methods['process_exception'].appendleft(mw.process_exception)\n \n-    def download(self, download_func, request, spider):\n+    def download(self, download_func: Callable, request: Request, spider: Spider):\n         @defer.inlineCallbacks\n-        def process_request(request):\n+        def process_request(request: Request):\n             for method in self.methods['process_request']:\n                 response = yield deferred_from_coro(method(request=request, spider=spider))\n                 if response is not None and not isinstance(response, (Response, Request)):\n@@ -45,7 +49,7 @@ class DownloaderMiddlewareManager(MiddlewareManager):\n             return (yield download_func(request=request, spider=spider))\n \n         @defer.inlineCallbacks\n-        def process_response(response):\n+        def process_response(response: Union[Response, Request]):\n             if response is None:\n                 raise TypeError(\"Received None in process_response\")\n             elif isinstance(response, Request):\n@@ -64,7 +68,7 @@ class DownloaderMiddlewareManager(MiddlewareManager):\n             return response\n \n         @defer.inlineCallbacks\n-        def process_exception(failure):\n+        def process_exception(failure: Failure):\n             exception = failure.value\n             for method in self.methods['process_exception']:\n                 response = yield deferred_from_coro(method(request=request, exception=exception, spider=spider))\n\n@@ -3,25 +3,32 @@ Spider Middleware manager\n \n See documentation in docs/topics/spider-middleware.rst\n \"\"\"\n+from collections.abc import Iterable, AsyncIterable\n from itertools import islice\n+from typing import Callable, Union, Any\n \n from twisted.python.failure import Failure\n \n+from scrapy import Request, Spider\n from scrapy.exceptions import _InvalidOutput\n+from scrapy.http import Response\n from scrapy.middleware import MiddlewareManager\n from scrapy.utils.conf import build_component_list\n from scrapy.utils.defer import mustbe_deferred\n from scrapy.utils.python import MutableChain\n \n \n-def _isiterable(possible_iterator):\n-    return hasattr(possible_iterator, '__iter__')\n+def _isiterable(o):\n+    return isinstance(o, Iterable)\n \n \n def _fname(f):\n     return f\"{f.__self__.__class__.__name__}.{f.__func__.__name__}\"\n \n \n+ScrapeFunc = Callable[[Union[Response, Failure], Request, Spider], Any]\n+\n+\n class SpiderMiddlewareManager(MiddlewareManager):\n \n     component_name = 'spider middleware'\n@@ -41,7 +48,7 @@ class SpiderMiddlewareManager(MiddlewareManager):\n         process_spider_exception = getattr(mw, 'process_spider_exception', None)\n         self.methods['process_spider_exception'].appendleft(process_spider_exception)\n \n-    def _process_spider_input(self, scrape_func, response, request, spider):\n+    def _process_spider_input(self, scrape_func: ScrapeFunc, response: Response, request: Request, spider: Spider):\n         for method in self.methods['process_spider_input']:\n             try:\n                 result = method(response=response, spider=spider)\n@@ -55,7 +62,8 @@ class SpiderMiddlewareManager(MiddlewareManager):\n                 return scrape_func(Failure(), request, spider)\n         return scrape_func(response, request, spider)\n \n-    def _evaluate_iterable(self, response, spider, iterable, exception_processor_index, recover_to):\n+    def _evaluate_iterable(self, response: Response, spider: Spider, iterable: Iterable,\n+                           exception_processor_index: int, recover_to: MutableChain):\n         try:\n             for r in iterable:\n                 yield r\n@@ -66,7 +74,7 @@ class SpiderMiddlewareManager(MiddlewareManager):\n                 raise\n             recover_to.extend(exception_result)\n \n-    def _process_spider_exception(self, response, spider, _failure, start_index=0):\n+    def _process_spider_exception(self, response: Response, spider: Spider, _failure: Failure, start_index=0):\n         exception = _failure.value\n         # don't handle _InvalidOutput exception\n         if isinstance(exception, _InvalidOutput):\n@@ -88,7 +96,8 @@ class SpiderMiddlewareManager(MiddlewareManager):\n                 raise _InvalidOutput(msg)\n         return _failure\n \n-    def _process_spider_output(self, response, spider, result, start_index=0):\n+    def _process_spider_output(self, response: Response, spider: Spider,\n+                               result: Iterable, start_index=0):\n         # items in this iterable do not need to go through the process_spider_output\n         # chain, they went through it already from the process_spider_exception method\n         recovered = MutableChain()\n@@ -114,21 +123,21 @@ class SpiderMiddlewareManager(MiddlewareManager):\n \n         return MutableChain(result, recovered)\n \n-    def _process_callback_output(self, response, spider, result):\n+    def _process_callback_output(self, response: Response, spider: Spider, result: Iterable):\n         recovered = MutableChain()\n         result = self._evaluate_iterable(response, spider, result, 0, recovered)\n         return MutableChain(self._process_spider_output(response, spider, result), recovered)\n \n-    def scrape_response(self, scrape_func, response, request, spider):\n-        def process_callback_output(result):\n+    def scrape_response(self, scrape_func: ScrapeFunc, response: Response, request: Request, spider: Spider):\n+        def process_callback_output(result: Iterable):\n             return self._process_callback_output(response, spider, result)\n \n-        def process_spider_exception(_failure):\n+        def process_spider_exception(_failure: Failure):\n             return self._process_spider_exception(response, spider, _failure)\n \n         dfd = mustbe_deferred(self._process_spider_input, scrape_func, response, request, spider)\n         dfd.addCallbacks(callback=process_callback_output, errback=process_spider_exception)\n         return dfd\n \n-    def process_start_requests(self, start_requests, spider):\n+    def process_start_requests(self, start_requests, spider: Spider):\n         return self._process_chain('process_start_requests', start_requests, spider)\n\n@@ -1,6 +1,7 @@\n-from collections import defaultdict, deque\n import logging\n import pprint\n+from collections import defaultdict, deque\n+from typing import Callable\n \n from scrapy.exceptions import NotConfigured\n from scrapy.utils.misc import create_instance, load_object\n@@ -16,7 +17,7 @@ class MiddlewareManager:\n \n     def __init__(self, *middlewares):\n         self.middlewares = middlewares\n-        self.methods = defaultdict(deque)\n+        self.methods: dict[str, deque[Callable]] = defaultdict(deque)\n         for mw in middlewares:\n             self._add_middleware(mw)\n \n@@ -58,13 +59,13 @@ class MiddlewareManager:\n         if hasattr(mw, 'close_spider'):\n             self.methods['close_spider'].appendleft(mw.close_spider)\n \n-    def _process_parallel(self, methodname, obj, *args):\n+    def _process_parallel(self, methodname: str, obj, *args):\n         return process_parallel(self.methods[methodname], obj, *args)\n \n-    def _process_chain(self, methodname, obj, *args):\n+    def _process_chain(self, methodname: str, obj, *args):\n         return process_chain(self.methods[methodname], obj, *args)\n \n-    def _process_chain_both(self, cb_methodname, eb_methodname, obj, *args):\n+    def _process_chain_both(self, cb_methodname: str, eb_methodname: str, obj, *args):\n         return process_chain_both(self.methods[cb_methodname],\n                                   self.methods[eb_methodname], obj, *args)\n \n\n@@ -1,4 +1,7 @@\n-async def collect_asyncgen(result):\n+from collections.abc import AsyncIterable\n+\n+\n+async def collect_asyncgen(result: AsyncIterable):\n     results = []\n     async for x in result:\n         results.append(x)\n\n@@ -3,16 +3,19 @@ Helper functions for dealing with Twisted deferreds\n \"\"\"\n import asyncio\n import inspect\n+from collections.abc import Coroutine\n from functools import wraps\n+from typing import Callable, Iterable, Any\n \n from twisted.internet import defer, task\n from twisted.python import failure\n+from twisted.python.failure import Failure\n \n from scrapy.exceptions import IgnoreRequest\n from scrapy.utils.reactor import is_asyncio_reactor_installed\n \n \n-def defer_fail(_failure):\n+def defer_fail(_failure: Failure):\n     \"\"\"Same as twisted.internet.defer.fail but delay calling errback until\n     next reactor loop\n \n@@ -47,7 +50,7 @@ def defer_result(result):\n         return defer_succeed(result)\n \n \n-def mustbe_deferred(f, *args, **kw):\n+def mustbe_deferred(f: Callable, *args, **kw):\n     \"\"\"Same as twisted.internet.defer.maybeDeferred, but delay calling\n     callback/errback to next reactor loop\n     \"\"\"\n@@ -64,7 +67,7 @@ def mustbe_deferred(f, *args, **kw):\n         return defer_result(result)\n \n \n-def parallel(iterable, count, callable, *args, **named):\n+def parallel(iterable: Iterable, count: int, callable: Callable, *args, **named):\n     \"\"\"Execute a callable over the objects in the given iterable, in parallel,\n     using no more than ``count`` concurrent calls.\n \n@@ -75,7 +78,7 @@ def parallel(iterable, count, callable, *args, **named):\n     return defer.DeferredList([coop.coiterate(work) for _ in range(count)])\n \n \n-def process_chain(callbacks, input, *a, **kw):\n+def process_chain(callbacks: Iterable[Callable], input, *a, **kw):\n     \"\"\"Return a Deferred built by chaining the given callbacks\"\"\"\n     d = defer.Deferred()\n     for x in callbacks:\n@@ -84,7 +87,7 @@ def process_chain(callbacks, input, *a, **kw):\n     return d\n \n \n-def process_chain_both(callbacks, errbacks, input, *a, **kw):\n+def process_chain_both(callbacks: Iterable[Callable], errbacks: Iterable[Callable], input, *a, **kw):\n     \"\"\"Return a Deferred built by chaining the given callbacks and errbacks\"\"\"\n     d = defer.Deferred()\n     for cb, eb in zip(callbacks, errbacks):\n@@ -100,7 +103,7 @@ def process_chain_both(callbacks, errbacks, input, *a, **kw):\n     return d\n \n \n-def process_parallel(callbacks, input, *a, **kw):\n+def process_parallel(callbacks: Iterable[Callable], input, *a, **kw):\n     \"\"\"Return a Deferred with the output of all successful calls to the given\n     callbacks\n     \"\"\"\n@@ -110,7 +113,7 @@ def process_parallel(callbacks, input, *a, **kw):\n     return d\n \n \n-def iter_errback(iterable, errback, *a, **kw):\n+def iter_errback(iterable: Iterable, errback: Callable, *a, **kw):\n     \"\"\"Wraps an iterable calling an errback if an error is caught while\n     iterating it.\n     \"\"\"\n@@ -124,7 +127,7 @@ def iter_errback(iterable, errback, *a, **kw):\n             errback(failure.Failure(), *a, **kw)\n \n \n-def deferred_from_coro(o):\n+def deferred_from_coro(o) -> Any:\n     \"\"\"Converts a coroutine into a Deferred, or returns the object as is if it isn't a coroutine\"\"\"\n     if isinstance(o, defer.Deferred):\n         return o\n@@ -139,7 +142,7 @@ def deferred_from_coro(o):\n     return o\n \n \n-def deferred_f_from_coro_f(coro_f):\n+def deferred_f_from_coro_f(coro_f: Callable[..., Coroutine]):\n     \"\"\" Converts a coroutine function into a function that returns a Deferred.\n \n     The coroutine function will be called at the time when the wrapper is called. Wrapper args will be passed to it.\n@@ -151,7 +154,7 @@ def deferred_f_from_coro_f(coro_f):\n     return f\n \n \n-def maybeDeferred_coro(f, *args, **kw):\n+def maybeDeferred_coro(f: Callable, *args, **kw):\n     \"\"\" Copy of defer.maybeDeferred that also converts coroutines to Deferreds. \"\"\"\n     try:\n         result = f(*args, **kw)\n\n@@ -8,6 +8,7 @@ import re\n import sys\n import warnings\n import weakref\n+from collections.abc import Iterable\n from functools import partial, wraps\n from itertools import chain\n \n@@ -335,15 +336,15 @@ else:\n         gc.collect()\n \n \n-class MutableChain:\n+class MutableChain(Iterable):\n     \"\"\"\n     Thin wrapper around itertools.chain, allowing to add iterables \"in-place\"\n     \"\"\"\n \n-    def __init__(self, *args):\n+    def __init__(self, *args: Iterable):\n         self.data = chain.from_iterable(args)\n \n-    def extend(self, *iterables):\n+    def extend(self, *iterables: Iterable):\n         self.data = chain(self.data, chain.from_iterable(iterables))\n \n     def __iter__(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
