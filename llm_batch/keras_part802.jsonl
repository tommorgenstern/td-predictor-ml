{"custom_id": "keras#7caec085162a6fba076c464851384ebaca2adf56", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 11 | Churn Cumulative: 1825 | Contributors (this commit): 11 | Commits (past 90d): 9 | Contributors (cumulative): 14 | DMM Complexity: 1.0\n\nDIFF:\n@@ -567,7 +567,7 @@ class BaseOptimizer:\n         ):\n             return self._learning_rate(self.iterations)\n         elif callable(self._learning_rate):\n-            return self._learning_rate(self.iterations)\n+            return self._learning_rate()\n         return self._learning_rate\n \n     def _filter_empty_gradients(self, grads, vars):\n\n@@ -243,3 +243,12 @@ class OptimizerTest(testing.TestCase):\n         checkpoint.restore(save_path)\n         pred = model.predict(x)\n         self.assertAllClose(pred, ref_pred, atol=1e-5)\n+\n+    def test_callable_learning_rate(self):\n+        v = backend.Variable([[1.0, 2.0], [3.0, 4.0]])\n+        grads = backend.convert_to_tensor([[1.0, 1.0], [1.0, 1.0]])\n+        optimizer = optimizers.AdamW(learning_rate=lambda: 0.0001)\n+        self.assertAllClose(optimizer.iterations, 0)\n+        optimizer.apply_gradients([(grads, v)])\n+        self.assertAllClose(v, [[1.0, 2.0], [3.0, 4.0]], atol=1e-4)\n+        self.assertAllClose(optimizer.iterations, 1)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7386d373cf3a7060c4886c3dd9f7c0265025fa68", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 32 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 5 | Methods Changed: 2 | Complexity Δ (Sum/Max): 4/3 | Churn Δ: 36 | Churn Cumulative: 89 | Contributors (this commit): 2 | Commits (past 90d): 4 | Contributors (cumulative): 3 | DMM Complexity: 0.72\n\nDIFF:\n@@ -236,18 +236,26 @@ class RNN(Layer):\n             self.single_state = False\n \n     def compute_output_shape(self, sequences_shape, initial_state_shape=None):\n-        state_shape = [(sequences_shape[0], d) for d in self.state_size]\n+        batch_size = sequences_shape[0]\n+        length = sequences_shape[1]\n+        states_shape = []\n+        for state_size in self.state_size:\n+            if isinstance(state_size, int):\n+                states_shape.append((batch_size, state_size))\n+            elif isinstance(state_size, (list, tuple)):\n+                states_shape.append([(batch_size, s) for s in state_size])\n+\n         output_size = getattr(self.cell, \"output_size\", None)\n         if output_size is None:\n             output_size = self.state_size[0]\n         if not isinstance(output_size, int):\n             raise ValueError(\"output_size must be an integer.\")\n         if self.return_sequences:\n-            output_shape = (sequences_shape[0], sequences_shape[1], output_size)\n+            output_shape = (batch_size, length, output_size)\n         else:\n-            output_shape = (sequences_shape[0], output_size)\n+            output_shape = (batch_size, output_size)\n         if self.return_state:\n-            return output_shape, *state_shape\n+            return output_shape, *states_shape\n         return output_shape\n \n     def compute_mask(self, _, mask):\n\n@@ -255,3 +255,23 @@ class StackedRNNTest(testing.TestCase):\n         self.assertAllClose(\n             np.array([[136368.0, 136368.0], [692784.0, 692784.0]]), output\n         )\n+\n+    def test_return_state_stacked_lstm_cell(self):\n+        layer = layers.RNN(\n+            [layers.LSTMCell(10), layers.LSTMCell(10)], return_state=True\n+        )\n+        out = layer(np.zeros((2, 3, 5)))\n+        self.assertLen(out, 3)\n+        self.assertEqual(out[0].shape, (2, 10))\n+        self.assertEqual(out[1][0].shape, (2, 10))\n+        self.assertEqual(out[1][1].shape, (2, 10))\n+        self.assertEqual(out[2][0].shape, (2, 10))\n+        self.assertEqual(out[2][1].shape, (2, 10))\n+\n+        shape = layer.compute_output_shape((2, 3, 5))\n+        self.assertLen(shape, 3)\n+        self.assertEqual(shape[0], (2, 10))\n+        self.assertEqual(shape[1][0], (2, 10))\n+        self.assertEqual(shape[1][1], (2, 10))\n+        self.assertEqual(shape[2][0], (2, 10))\n+        self.assertEqual(shape[2][1], (2, 10))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9e344f5727ae95ec71d83d97404ee93966b9e293", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 53 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 3 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 53 | Churn Cumulative: 2235 | Contributors (this commit): 10 | Commits (past 90d): 6 | Contributors (cumulative): 10 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2244,3 +2244,56 @@ class NNOpsDtypeTest(testing.TestCase, parameterized.TestCase):\n             standardize_dtype(knn.Softsign().symbolic_call(x).dtype),\n             expected_dtype,\n         )\n+\n+    def test_softmax_on_axis_with_size_one_warns(self):\n+        x = np.array([[1.0]])\n+        # Applying softmax on the second axis, which has size 1\n+        axis = 1\n+\n+        # Expected warning message\n+        expected_warning_regex = (\n+            r\"You are using a softmax over axis 1 \"\n+            r\"of a tensor of shape \\(1, 1\\)\\. This axis \"\n+            r\"has size 1\\. The softmax operation will always return \"\n+            r\"the value 1, which is likely not what you intended\\. \"\n+            r\"Did you mean to use a sigmoid instead\\?\"\n+        )\n+\n+        with self.assertWarnsRegex(UserWarning, expected_warning_regex):\n+            knn.softmax(x, axis)\n+\n+    def test_normalize_order_validation(self):\n+        # Test with a non-integer order\n+        with self.assertRaisesRegex(\n+            ValueError, \"Argument `order` must be an int >= 1\"\n+        ):\n+            knn.normalize(np.array([1, 2, 3]), order=\"a\")\n+\n+        # Test with a negative integer\n+        with self.assertRaisesRegex(\n+            ValueError, \"Argument `order` must be an int >= 1\"\n+        ):\n+            knn.normalize(np.array([1, 2, 3]), order=-1)\n+\n+        # Test with zero\n+        with self.assertRaisesRegex(\n+            ValueError, \"Argument `order` must be an int >= 1\"\n+        ):\n+            knn.normalize(np.array([1, 2, 3]), order=0)\n+\n+        # Test with a floating-point number\n+        with self.assertRaisesRegex(\n+            ValueError, \"Argument `order` must be an int >= 1\"\n+        ):\n+            knn.normalize(np.array([1, 2, 3]), order=2.5)\n+\n+    def test_check_shape_first_dim_mismatch(self):\n+        name1, shape1 = \"labels\", (2, 3)\n+        name2, shape2 = \"logits\", (3, 4, 5)\n+        ctc_loss_instance = knn.CtcLoss(mask_index=-1)\n+        with self.assertRaisesRegex(\n+            ValueError, \"must have the same first dimension\"\n+        ):\n+            ctc_loss_instance._check_shape_first_dim(\n+                name1, shape1, name2, shape2\n+            )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2fb6a2aca56029954894c507afc30cd95138d57b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 251 | Lines Deleted: 0 | Files Changed: 6 | Hunks: 8 | Methods Changed: 10 | Complexity Δ (Sum/Max): 48/10 | Churn Δ: 251 | Churn Cumulative: 963 | Contributors (this commit): 4 | Commits (past 90d): 9 | Contributors (cumulative): 15 | DMM Complexity: 0.16847826086956522\n\nDIFF:\n@@ -14,6 +14,29 @@ RESIZE_INTERPOLATIONS = (\n )\n \n \n+def rgb_to_grayscale(image, data_format=\"channels_last\"):\n+    if data_format == \"channels_first\":\n+        if len(image.shape) == 4:\n+            image = jnp.transpose(image, (0, 2, 3, 1))\n+        elif len(image.shape) == 3:\n+            image = jnp.transpose(image, (1, 2, 0))\n+        else:\n+            raise ValueError(\n+                \"Invalid input rank: expected rank 3 (single image) \"\n+                \"or rank 4 (batch of images). Received input with shape: \"\n+                f\"image.shape={image.shape}\"\n+            )\n+    red, green, blue = image[..., 0], image[..., 1], image[..., 2]\n+    grayscale_image = 0.2989 * red + 0.5870 * green + 0.1140 * blue\n+    grayscale_image = jnp.expand_dims(grayscale_image, axis=-1)\n+    if data_format == \"channels_first\":\n+        if len(image.shape) == 4:\n+            grayscale_image = jnp.transpose(grayscale_image, (0, 3, 1, 2))\n+        elif len(image.shape) == 3:\n+            grayscale_image = jnp.transpose(grayscale_image, (2, 0, 1))\n+    return jnp.array(grayscale_image)\n+\n+\n def resize(\n     image,\n     size,\n\n@@ -13,6 +13,29 @@ RESIZE_INTERPOLATIONS = (\n )\n \n \n+def rgb_to_grayscale(image, data_format=\"channels_last\"):\n+    if data_format == \"channels_first\":\n+        if len(image.shape) == 4:\n+            image = np.transpose(image, (0, 2, 3, 1))\n+        elif len(image.shape) == 3:\n+            image = np.transpose(image, (1, 2, 0))\n+        else:\n+            raise ValueError(\n+                \"Invalid input rank: expected rank 3 (single image) \"\n+                \"or rank 4 (batch of images). Received input with shape: \"\n+                f\"image.shape={image.shape}\"\n+            )\n+    red, green, blue = image[..., 0], image[..., 1], image[..., 2]\n+    grayscale_image = 0.2989 * red + 0.5870 * green + 0.1140 * blue\n+    grayscale_image = np.expand_dims(grayscale_image, axis=-1)\n+    if data_format == \"channels_first\":\n+        if len(image.shape) == 4:\n+            grayscale_image = np.transpose(grayscale_image, (0, 3, 1, 2))\n+        elif len(image.shape) == 3:\n+            grayscale_image = np.transpose(grayscale_image, (2, 0, 1))\n+    return np.array(grayscale_image)\n+\n+\n def resize(\n     image,\n     size,\n\n@@ -15,6 +15,27 @@ RESIZE_INTERPOLATIONS = (\n )\n \n \n+def rgb_to_grayscale(image, data_format=\"channels_last\"):\n+    if data_format == \"channels_first\":\n+        if len(image.shape) == 4:\n+            image = tf.transpose(image, (0, 2, 3, 1))\n+        elif len(image.shape) == 3:\n+            image = tf.transpose(image, (1, 2, 0))\n+        else:\n+            raise ValueError(\n+                \"Invalid input rank: expected rank 3 (single image) \"\n+                \"or rank 4 (batch of images). Received input with shape: \"\n+                f\"image.shape={image.shape}\"\n+            )\n+    grayscale_image = tf.image.rgb_to_grayscale(image)\n+    if data_format == \"channels_first\":\n+        if len(image.shape) == 4:\n+            grayscale_image = tf.transpose(grayscale_image, (0, 3, 1, 2))\n+        elif len(image.shape) == 3:\n+            grayscale_image = tf.transpose(grayscale_image, (2, 0, 1))\n+    return tf.cast(grayscale_image, image.dtype)\n+\n+\n def resize(\n     image,\n     size,\n\n@@ -14,6 +14,38 @@ UNSUPPORTED_INTERPOLATIONS = (\n )\n \n \n+def rgb_to_grayscale(image, data_format=\"channel_last\"):\n+    try:\n+        import torchvision\n+    except:\n+        raise ImportError(\n+            \"The torchvision package is necessary to use \"\n+            \"`rgb_to_grayscale` with the torch backend. \"\n+            \"Please install torchvision. \"\n+        )\n+    image = convert_to_tensor(image)\n+    if data_format == \"channels_last\":\n+        if image.ndim == 4:\n+            image = image.permute((0, 3, 1, 2))\n+        elif image.ndim == 3:\n+            image = image.permute((2, 0, 1))\n+        else:\n+            raise ValueError(\n+                \"Invalid input rank: expected rank 3 (single image) \"\n+                \"or rank 4 (batch of images). Received input with shape: \"\n+                f\"image.shape={image.shape}\"\n+            )\n+    grayscale_image = torchvision.transforms.functional.rgb_to_grayscale(\n+        img=image,\n+    )\n+    if data_format == \"channels_last\":\n+        if len(image.shape) == 4:\n+            grayscale_image = grayscale_image.permute((0, 2, 3, 1))\n+        elif len(image.shape) == 3:\n+            grayscale_image = grayscale_image.permute((1, 2, 0))\n+    return grayscale_image\n+\n+\n def resize(\n     image,\n     size,\n\n@@ -7,6 +7,103 @@ from keras.ops.operation import Operation\n from keras.ops.operation_utils import compute_conv_output_shape\n \n \n+class RGBToGrayscale(Operation):\n+    def __init__(\n+        self,\n+        data_format=\"channels_last\",\n+    ):\n+        super().__init__()\n+        self.data_format = data_format\n+\n+    def call(self, image):\n+        return backend.image.rgb_to_grayscale(\n+            image,\n+            data_format=self.data_format,\n+        )\n+\n+    def compute_output_spec(self, image):\n+        if len(image.shape) not in (3, 4):\n+            raise ValueError(\n+                \"Invalid image rank: expected rank 3 (single image) \"\n+                \"or rank 4 (batch of images). Received input with shape: \"\n+                f\"image.shape={image.shape}\"\n+            )\n+\n+        if len(image.shape) == 3:\n+            if self.data_format == \"channels_last\":\n+                return KerasTensor(image.shape[:-1] + (1,), dtype=image.dtype)\n+            else:\n+                return KerasTensor((1,) + image.shape[1:], dtype=image.dtype)\n+        elif len(image.shape) == 4:\n+            if self.data_format == \"channels_last\":\n+                return KerasTensor(\n+                    (image.shape[0],) + image.shape[1:-1] + (1,),\n+                    dtype=image.dtype,\n+                )\n+            else:\n+                return KerasTensor(\n+                    (\n+                        image.shape[0],\n+                        1,\n+                    )\n+                    + image.shape[2:],\n+                    dtype=image.dtype,\n+                )\n+\n+\n+@keras_export(\"keras.ops.image.rgb_to_grayscale\")\n+def rgb_to_grayscale(\n+    image,\n+    data_format=\"channels_last\",\n+):\n+    \"\"\"Convert RGB images to grayscale.\n+\n+    This function converts RGB images to grayscale images. It supports both\n+    3D and 4D tensors, where the last dimension represents channels.\n+\n+    Args:\n+        image: Input RGB image or batch of RGB images. Must be a 3D tensor\n+            with shape `(height, width, channels)` or a 4D tensor with shape\n+            `(batch, height, width, channels)`.\n+        data_format: A string specifying the data format of the input tensor.\n+            It can be either `\"channels_last\"` or `\"channels_first\"`.\n+            `\"channels_last\"` corresponds to inputs with shape\n+            `(batch, height, width, channels)`, while `\"channels_first\"`\n+            corresponds to inputs with shape `(batch, channels, height, width)`.\n+            Defaults to `\"channels_last\"`.\n+\n+    Returns:\n+        Grayscale image or batch of grayscale images.\n+\n+    Examples:\n+\n+    >>> import numpy as np\n+    >>> from keras import ops\n+    >>> x = np.random.random((2, 4, 4, 3))\n+    >>> y = ops.image.rgb_to_grayscale(x)\n+    >>> y.shape\n+    (2, 4, 4, 1)\n+\n+    >>> x = np.random.random((4, 4, 3)) # Single RGB image\n+    >>> y = ops.image.rgb_to_grayscale(x)\n+    >>> y.shape\n+    (4, 4, 1)\n+\n+    >>> x = np.random.random((2, 3, 4, 4))\n+    >>> y = ops.image.rgb_to_grayscale(x, data_format=\"channels_first\")\n+    >>> y.shape\n+    (2, 1, 4, 4)\n+    \"\"\"\n+    if any_symbolic_tensors((image,)):\n+        return RGBToGrayscale(\n+            data_format=data_format,\n+        ).symbolic_call(image)\n+    return backend.image.rgb_to_grayscale(\n+        image,\n+        data_format=data_format,\n+    )\n+\n+\n class Resize(Operation):\n     def __init__(\n         self,\n\n@@ -13,6 +13,11 @@ from keras.ops import image as kimage\n \n \n class ImageOpsDynamicShapeTest(testing.TestCase):\n+    def test_rgb_to_grayscale(self):\n+        x = KerasTensor([None, 20, 20, 3])\n+        out = kimage.rgb_to_grayscale(x)\n+        self.assertEqual(out.shape, (None, 20, 20, 1))\n+\n     def test_resize(self):\n         x = KerasTensor([None, 20, 20, 3])\n         out = kimage.resize(x, size=(15, 15))\n@@ -62,6 +67,11 @@ class ImageOpsDynamicShapeTest(testing.TestCase):\n \n \n class ImageOpsStaticShapeTest(testing.TestCase):\n+    def test_rgb_to_grayscale(self):\n+        x = KerasTensor([20, 20, 3])\n+        out = kimage.rgb_to_grayscale(x)\n+        self.assertEqual(out.shape, (20, 20, 1))\n+\n     def test_resize(self):\n         x = KerasTensor([20, 20, 3])\n         out = kimage.resize(x, size=(15, 15))\n@@ -187,6 +197,51 @@ def _fixed_map_coordinates(\n \n \n class ImageOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n+    @parameterized.parameters(\n+        [\n+            (\"channels_last\"),\n+            (\"channels_first\"),\n+        ]\n+    )\n+    def test_rgb_to_grayscale(self, data_format):\n+        # Unbatched case\n+        if data_format == \"channels_first\":\n+            x = np.random.random((3, 50, 50)) * 255\n+        else:\n+            x = np.random.random((50, 50, 3)) * 255\n+        out = kimage.rgb_to_grayscale(\n+            x,\n+            data_format=data_format,\n+        )\n+        if data_format == \"channels_first\":\n+            x = np.transpose(x, (1, 2, 0))\n+        ref_out = tf.image.rgb_to_grayscale(\n+            x,\n+        )\n+        if data_format == \"channels_first\":\n+            ref_out = np.transpose(ref_out, (2, 0, 1))\n+        self.assertEqual(tuple(out.shape), tuple(ref_out.shape))\n+        self.assertAllClose(ref_out, out, atol=0.3)\n+\n+        # Batched case\n+        if data_format == \"channels_first\":\n+            x = np.random.random((2, 3, 50, 50)) * 255\n+        else:\n+            x = np.random.random((2, 50, 50, 3)) * 255\n+        out = kimage.rgb_to_grayscale(\n+            x,\n+            data_format=data_format,\n+        )\n+        if data_format == \"channels_first\":\n+            x = np.transpose(x, (0, 2, 3, 1))\n+        ref_out = tf.image.rgb_to_grayscale(\n+            x,\n+        )\n+        if data_format == \"channels_first\":\n+            ref_out = np.transpose(ref_out, (0, 3, 1, 2))\n+        self.assertEqual(tuple(out.shape), tuple(ref_out.shape))\n+        self.assertAllClose(ref_out, out, atol=0.3)\n+\n     @parameterized.parameters(\n         [\n             (\"bilinear\", True, \"channels_last\"),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#eb3a6d5325b87f69cff52276526bd7d8631bd9db", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 5 | Churn Cumulative: 258 | Contributors (this commit): 3 | Commits (past 90d): 5 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -560,7 +560,10 @@ def functional_from_config(cls, config, custom_objects=None):\n         if isinstance(tensors, dict):\n             return {k: get_tensor(*v) for k, v in tensors.items()}\n         else:\n-            return [get_tensor(*v) for v in tensors]\n+            tensor_list = [get_tensor(*v) for v in tensors]\n+            if len(tensor_list) == 1:\n+                return tensor_list[0]\n+            return tensor_list\n \n     input_tensors = map_tensors(config[\"input_layers\"])\n     output_tensors = map_tensors(config[\"output_layers\"])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#37deb0f7a5284f900d23dde03a3c452e78f00f73", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 15 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 5 | Methods Changed: 3 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 17 | Churn Cumulative: 513 | Contributors (this commit): 7 | Commits (past 90d): 12 | Contributors (cumulative): 9 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,3 +1,4 @@\n+import gc\n import threading\n \n from keras import backend\n@@ -21,7 +22,7 @@ def get_global_attribute(name, default=None, set_to_default=False):\n \n \n @keras_export([\"keras.utils.clear_session\", \"keras.backend.clear_session\"])\n-def clear_session():\n+def clear_session(free_memory=True):\n     \"\"\"Resets all state generated by Keras.\n \n     Keras manages a global state, which it uses to implement the Functional\n@@ -32,6 +33,14 @@ def clear_session():\n     Calling `clear_session()` releases the global state: this helps avoid\n     clutter from old models and layers, especially when memory is limited.\n \n+    Args:\n+        free_memory: Whether to call Python garbage collection.\n+            It's usually a good practice to call it to make sure\n+            memory used by deleted objects is immediately freed.\n+            However, it may take a few seconds to execute, so\n+            when using `clear_session()` in a short loop,\n+            you may want to skip it.\n+\n     Example 1: calling `clear_session()` when creating models in a loop\n \n     ```python\n@@ -83,3 +92,7 @@ def clear_session():\n         # reset's torchdynamo's cache so that  cached guards, compiled fn, etc\n         # do not persist between clear_session() calls\n         dynamo.reset()\n+\n+    if free_memory:\n+        # Manually trigger garbage collection.\n+        gc.collect()\n\n@@ -28,7 +28,7 @@ class TestCase(unittest.TestCase):\n         # clear global state so that test cases are independent\n         # required for the jit enabled torch tests since dynamo has\n         # a global cache for guards, compiled fn, etc\n-        clear_session()\n+        clear_session(free_memory=False)\n         if traceback_utils.is_traceback_filtering_enabled():\n             traceback_utils.disable_traceback_filtering()\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#37d7900877c6baaddd11d1966b9f3602bf2229f6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 24 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 6/5 | Churn Δ: 24 | Churn Cumulative: 1849 | Contributors (this commit): 11 | Commits (past 90d): 11 | Contributors (cumulative): 14 | DMM Complexity: 0.0\n\nDIFF:\n@@ -501,6 +501,10 @@ class BaseOptimizer:\n \n     @learning_rate.setter\n     def learning_rate(self, learning_rate):\n+        if isinstance(self._learning_rate, backend.Variable):\n+            prev_lr_var = self._learning_rate\n+        else:\n+            prev_lr_var = None\n         if isinstance(\n             learning_rate, learning_rate_schedule.LearningRateSchedule\n         ):\n@@ -519,6 +523,11 @@ class BaseOptimizer:\n                     \"the optimizer with a float `learning_rate` argument.\"\n                 )\n             self._learning_rate.assign(learning_rate)\n+        if prev_lr_var is not None and not isinstance(\n+            self._learning_rate, backend.Variable\n+        ):\n+            # Untrack learning rate variable\n+            self._untrack_variable(prev_lr_var)\n \n     def set_weights(self, weights):\n         \"\"\"Set the weights of the optimizer.\"\"\"\n@@ -832,6 +841,13 @@ class BaseOptimizer:\n         )\n         return values_clip\n \n+    def _untrack_variable(self, variable):\n+        previous_lock_state = self._tracker.locked\n+        self._tracker.unlock()\n+        self._tracker.untrack(variable)\n+        if previous_lock_state is True:\n+            self._tracker.lock()\n+\n \n base_optimizer_keyword_args = \"\"\"name: String. The name to use\n             for momentum accumulator weights created by\n\n@@ -252,3 +252,11 @@ class OptimizerTest(testing.TestCase):\n         optimizer.apply_gradients([(grads, v)])\n         self.assertAllClose(v, [[1.0, 2.0], [3.0, 4.0]], atol=1e-4)\n         self.assertAllClose(optimizer.iterations, 1)\n+\n+    def test_setting_lr_to_callable_untracks_lr_var(self):\n+        adam = optimizers.Adam(learning_rate=0.001)\n+        self.assertLen(adam.variables, 2)\n+        adam.learning_rate = optimizers.schedules.PolynomialDecay(\n+            adam.learning_rate, 4\n+        )\n+        self.assertLen(adam.variables, 1)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5d99879c7151d39df5cf1c55632a642f49b0e992", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 90 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 8 | Complexity Δ (Sum/Max): 8/8 | Churn Δ: 90 | Churn Cumulative: 881 | Contributors (this commit): 6 | Commits (past 90d): 10 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1166,3 +1166,93 @@ class ISTFTTest(testing.TestCase):\n         low_rank_input = np.random.rand(3)\n         with self.assertRaisesRegex(ValueError, \"Input should have rank >= 2\"):\n             istft_op.compute_output_spec((low_rank_input, low_rank_input))\n+\n+    def test_input_not_tuple_or_list_raises_error(self):\n+        irfft_op = kmath.IRFFT()\n+        invalid_input = np.array([1, 2, 3])\n+        with self.assertRaisesRegex(\n+            ValueError, \"Input `x` should be a tuple of two tensors\"\n+        ):\n+            irfft_op.compute_output_spec(invalid_input)\n+\n+    def test_input_tuple_with_less_than_two_elements_raises_error(self):\n+        irfft_op = kmath.IRFFT()\n+        too_short_input = (np.array([1, 2, 3]),)\n+        with self.assertRaisesRegex(\n+            ValueError, \"Input `x` should be a tuple of two tensors\"\n+        ):\n+            irfft_op.compute_output_spec(too_short_input)\n+\n+    def test_input_tuple_with_more_than_two_elements_raises_error(self):\n+        irfft_op = kmath.IRFFT()\n+        too_long_input = (\n+            np.array([1, 2, 3]),\n+            np.array([4, 5, 6]),\n+            np.array([7, 8, 9]),\n+        )\n+        with self.assertRaisesRegex(\n+            ValueError, \"Input `x` should be a tuple of two tensors\"\n+        ):\n+            irfft_op.compute_output_spec(too_long_input)\n+\n+    def test_mismatched_shapes_input_validation(self):\n+        irfft_op = kmath.IRFFT()\n+\n+        # Create real and imaginary parts with mismatched shapes\n+        real_part = np.array([1, 2, 3])\n+        imag_part = np.array([[1, 2], [3, 4]])\n+\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"Both the real and imaginary parts should have the same shape\",\n+        ):\n+            irfft_op.compute_output_spec((real_part, imag_part))\n+\n+    def test_insufficient_rank_input_validation(self):\n+        irfft_op = kmath.IRFFT()\n+\n+        # Create real and imaginary parts with insufficient rank (0D)\n+        real_part = np.array(1)\n+        imag_part = np.array(1)\n+\n+        with self.assertRaisesRegex(ValueError, \"Input should have rank >= 1\"):\n+            irfft_op.compute_output_spec((real_part, imag_part))\n+\n+    def test_with_specified_fft_length(self):\n+        fft_length = 10\n+        irfft_op = kmath.IRFFT(fft_length=fft_length)\n+\n+        real_part = np.random.rand(4, 8)\n+        imag_part = np.random.rand(4, 8)\n+\n+        expected_shape = real_part.shape[:-1] + (fft_length,)\n+        output_shape = irfft_op.compute_output_spec(\n+            (real_part, imag_part)\n+        ).shape\n+\n+        self.assertEqual(output_shape, expected_shape)\n+\n+    def test_inferred_fft_length_with_defined_last_dimension(self):\n+        irfft_op = kmath.IRFFT()\n+\n+        real_part = np.random.rand(4, 8)\n+        imag_part = np.random.rand(4, 8)\n+\n+        inferred_fft_length = 2 * (real_part.shape[-1] - 1)\n+        expected_shape = real_part.shape[:-1] + (inferred_fft_length,)\n+        output_shape = irfft_op.compute_output_spec(\n+            (real_part, imag_part)\n+        ).shape\n+\n+        self.assertEqual(output_shape, expected_shape)\n+\n+    def test_undefined_fft_length_and_last_dimension(self):\n+        irfft_op = kmath.IRFFT()\n+\n+        real_part = KerasTensor(shape=(4, None), dtype=\"float32\")\n+        imag_part = KerasTensor(shape=(4, None), dtype=\"float32\")\n+\n+        output_spec = irfft_op.compute_output_spec((real_part, imag_part))\n+        expected_shape = real_part.shape[:-1] + (None,)\n+\n+        self.assertEqual(output_spec.shape, expected_shape)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#70054103f88dec3e199a54ddbf27174169c66dff", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 4 | Churn Cumulative: 95 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 3 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1,3 +1,5 @@\n+import inspect\n+\n from keras.api_export import keras_export\n from keras.losses.loss import Loss\n from keras.losses.losses import BinaryCrossentropy\n@@ -183,6 +185,8 @@ def get(identifier):\n         obj = identifier\n \n     if callable(obj):\n+        if inspect.isclass(obj):\n+            obj = obj()\n         return obj\n     else:\n         raise ValueError(f\"Could not interpret loss identifier: {identifier}\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c5e939d4e5e4b4e53f71b98a58439fbd54cea4b8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 518 | Contributors (this commit): 6 | Commits (past 90d): 8 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -211,7 +211,13 @@ class BaseOptimizer:\n         if hasattr(reference_variable, \"path\"):\n             name = reference_variable.path.replace(\"/\", \"_\") + \"_\" + name\n         else:\n-            name = str(reference_variable.name).replace(\":\", \"_\") + \"_\" + name\n+            name = (\n+                str(reference_variable.name)\n+                .replace(\"/\", \"_\")\n+                .replace(\":\", \"_\")\n+                + \"_\"\n+                + name\n+            )\n         return self.add_variable(\n             shape=reference_variable.shape,\n             initializer=initializer,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#21dd61e2c3c3ec3fae0220f42a73213bdd9b09e8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 970 | Contributors (this commit): 8 | Commits (past 90d): 4 | Contributors (cumulative): 8 | DMM Complexity: 0.0\n\nDIFF:\n@@ -180,7 +180,9 @@ def load_model(filepath, custom_objects=None, compile=True, safe_mode=True):\n             safe_mode=safe_mode,\n         )\n     if str(filepath).endswith((\".h5\", \".hdf5\")):\n-        return legacy_h5_format.load_model_from_hdf5(filepath)\n+        return legacy_h5_format.load_model_from_hdf5(\n+            filepath, custom_objects=None, compile=compile\n+        )\n     elif str(filepath).endswith(\".keras\"):\n         raise ValueError(\n             f\"File not found: filepath={filepath}. \"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cd62a84c093680f6bff9ee54382778babfc7c5bb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 1494 | Contributors (this commit): 13 | Commits (past 90d): 14 | Contributors (cumulative): 14 | DMM Complexity: 0.0\n\nDIFF:\n@@ -212,9 +212,7 @@ class BaseOptimizer:\n             name = reference_variable.path.replace(\"/\", \"_\") + \"_\" + name\n         else:\n             name = (\n-                str(reference_variable.name)\n-                .replace(\"/\", \"_\")\n-                .replace(\":\", \"_\")\n+                str(reference_variable.name).replace(\"/\", \"_\").replace(\":\", \"_\")\n                 + \"_\"\n                 + name\n             )\n\n@@ -181,7 +181,7 @@ def load_model(filepath, custom_objects=None, compile=True, safe_mode=True):\n         )\n     if str(filepath).endswith((\".h5\", \".hdf5\")):\n         return legacy_h5_format.load_model_from_hdf5(\n-            filepath, custom_objects=None, compile=compile\n+            filepath, custom_objects=custom_objects, compile=compile\n         )\n     elif str(filepath).endswith(\".keras\"):\n         raise ValueError(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#222174fbb11c10aaf41b1dc8243346d5f16bd4a5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 18 | Lines Deleted: 14 | Files Changed: 2 | Hunks: 7 | Methods Changed: 5 | Complexity Δ (Sum/Max): 3/4 | Churn Δ: 32 | Churn Cumulative: 1679 | Contributors (this commit): 11 | Commits (past 90d): 14 | Contributors (cumulative): 17 | DMM Complexity: 1.0\n\nDIFF:\n@@ -53,6 +53,9 @@ class Embedding(Layer):\n             If `mask_zero` is set to `True`, as a consequence,\n             index 0 cannot be used in the vocabulary (`input_dim` should\n             equal size of vocabulary + 1).\n+        weights: Optional floating-point matrix of size\n+            `(input_dim, output_dim)`. The initial embeddings values\n+            to use.\n         lora_rank: Optional integer. If set, the layer's forward pass\n             will implement LoRA (Low-Rank Adaptation)\n             with the provided rank. LoRA sets the layer's embeddings\n@@ -78,6 +81,7 @@ class Embedding(Layer):\n         embeddings_regularizer=None,\n         embeddings_constraint=None,\n         mask_zero=False,\n+        weights=None,\n         lora_rank=None,\n         **kwargs,\n     ):\n@@ -98,7 +102,15 @@ class Embedding(Layer):\n         self.lora_rank = lora_rank\n         self.lora_enabled = False\n \n+        self.build()\n+        if weights is not None:\n+            if not (isinstance(weights, list) and len(weights) == 1):\n+                weights = [weights]\n+            self.set_weights(weights)\n+\n     def build(self, input_shape=None):\n+        if self.built:\n+            return\n         if isinstance(self.dtype_policy, dtype_policies.QuantizedDTypePolicy):\n             self.quantized_build(\n                 input_shape, mode=self.dtype_policy.quantization_mode\n\n@@ -202,13 +202,6 @@ class EmbeddingTest(test_case.TestCase):\n         ):\n             layer.enable_lora(rank=2)\n \n-    def test_enable_lora_on_unbuilt_layer(self):\n-        layer = layers.Embedding(input_dim=10, output_dim=16)\n-        with self.assertRaisesRegex(\n-            ValueError, \"Cannot enable lora on a layer that isn't yet built\"\n-        ):\n-            layer.enable_lora(rank=2)\n-\n     def test_enable_lora_when_already_enabled(self):\n         layer = layers.Embedding(input_dim=10, output_dim=16)\n         layer.build()\n@@ -305,13 +298,6 @@ class EmbeddingTest(test_case.TestCase):\n             supports_masking=True,\n         )\n \n-    def test_quantize_on_unbuilt_layer(self):\n-        layer = layers.Embedding(10, 16)\n-        with self.assertRaisesRegex(\n-            ValueError, \"Cannot quantize a layer that isn't yet built.\"\n-        ):\n-            layer.quantize(\"int8\")\n-\n     def test_quantize_on_subclass(self):\n         class MyEmbedding(layers.Embedding):\n             pass\n@@ -405,3 +391,9 @@ class EmbeddingTest(test_case.TestCase):\n                 reloaded_layer.non_trainable_weights,\n                 len(model.non_trainable_weights),\n             )\n+\n+    def test_weights_constructor_arg(self):\n+        layer = layers.Embedding(3, 4, weights=np.ones((3, 4)))\n+        self.assertAllClose(layer.embeddings.numpy(), np.ones((3, 4)))\n+        layer = layers.Embedding(3, 4, weights=[np.ones((3, 4))])\n+        self.assertAllClose(layer.embeddings.numpy(), np.ones((3, 4)))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#779facd94a8382c7f00d87a3262bda73ea3c1b67", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 87 | Lines Deleted: 44 | Files Changed: 2 | Hunks: 22 | Methods Changed: 11 | Complexity Δ (Sum/Max): -2/1 | Churn Δ: 131 | Churn Cumulative: 890 | Contributors (this commit): 7 | Commits (past 90d): 21 | Contributors (cumulative): 12 | DMM Complexity: 1.0\n\nDIFF:\n@@ -3,7 +3,6 @@ import warnings\n \n import numpy as np\n import tensorflow as tf\n-from packaging.version import Version\n from tensorflow.python.eager import context as tf_context\n \n from keras import callbacks as callbacks_module\n@@ -31,11 +30,6 @@ class TensorFlowTrainer(base_trainer.Trainer):\n         else:\n             self._distribute_strategy = None\n \n-        self._distribute_reduction_method = None\n-        self._supports_reduce_retracing = Version(tf.__version__) >= Version(\n-            \"2.9.0\"\n-        )\n-\n     @property\n     def distribute_strategy(self):\n         return self._distribute_strategy or tf.distribute.get_strategy()\n@@ -110,10 +104,11 @@ class TensorFlowTrainer(base_trainer.Trainer):\n             return self.train_step(data)\n \n         if not self.run_eagerly:\n-            kwargs = {\"jit_compile\": self.jit_compile}\n-            if self._supports_reduce_retracing:\n-                kwargs.update({\"reduce_retracing\": True})\n-            one_step_on_data = tf.function(one_step_on_data, **kwargs)\n+            one_step_on_data = tf.function(\n+                one_step_on_data,\n+                reduce_retracing=True,\n+                jit_compile=self.jit_compile,\n+            )\n \n         @tf.autograph.experimental.do_not_convert\n         def one_step_on_iterator(iterator):\n@@ -125,7 +120,7 @@ class TensorFlowTrainer(base_trainer.Trainer):\n             outputs = reduce_per_replica(\n                 outputs,\n                 self.distribute_strategy,\n-                reduction=self.distribute_reduction_method,\n+                reduction=\"auto\",\n             )\n             return outputs\n \n@@ -141,10 +136,7 @@ class TensorFlowTrainer(base_trainer.Trainer):\n             train_function = one_step_on_iterator\n \n         if not self.run_eagerly:\n-            kwargs = {}\n-            if self._supports_reduce_retracing:\n-                kwargs.update({\"reduce_retracing\": True})\n-            train_function = tf.function(train_function, **kwargs)\n+            train_function = tf.function(train_function, reduce_retracing=True)\n \n         self.train_function = train_function\n \n@@ -158,10 +150,9 @@ class TensorFlowTrainer(base_trainer.Trainer):\n             return self.test_step(data)\n \n         if not self.run_eagerly and self.jit_compile:\n-            kwargs = {\"jit_compile\": True}\n-            if self._supports_reduce_retracing:\n-                kwargs.update({\"reduce_retracing\": True})\n-            one_step_on_data = tf.function(one_step_on_data, **kwargs)\n+            one_step_on_data = tf.function(\n+                one_step_on_data, reduce_retracing=True, jit_compile=True\n+            )\n \n         @tf.autograph.experimental.do_not_convert\n         def one_step_on_iterator(iterator):\n@@ -173,7 +164,7 @@ class TensorFlowTrainer(base_trainer.Trainer):\n             outputs = reduce_per_replica(\n                 outputs,\n                 self.distribute_strategy,\n-                reduction=self.distribute_reduction_method,\n+                reduction=\"auto\",\n             )\n             return outputs\n \n@@ -189,10 +180,7 @@ class TensorFlowTrainer(base_trainer.Trainer):\n             test_function = one_step_on_iterator\n \n         if not self.run_eagerly:\n-            kwargs = {}\n-            if self._supports_reduce_retracing:\n-                kwargs.update({\"reduce_retracing\": True})\n-            test_function = tf.function(test_function, **kwargs)\n+            test_function = tf.function(test_function, reduce_retracing=True)\n \n         self.test_function = test_function\n \n@@ -206,10 +194,9 @@ class TensorFlowTrainer(base_trainer.Trainer):\n             return self.predict_step(data)\n \n         if not self.run_eagerly and self.jit_compile:\n-            kwargs = {\"jit_compile\": True}\n-            if self._supports_reduce_retracing:\n-                kwargs.update({\"reduce_retracing\": True})\n-            one_step_on_data = tf.function(one_step_on_data, **kwargs)\n+            one_step_on_data = tf.function(\n+                one_step_on_data, reduce_retracing=True, jit_compile=True\n+            )\n \n         @tf.autograph.experimental.do_not_convert\n         def one_step_on_data_distributed(data):\n@@ -220,7 +207,7 @@ class TensorFlowTrainer(base_trainer.Trainer):\n             outputs = reduce_per_replica(\n                 outputs,\n                 self.distribute_strategy,\n-                reduction=self.distribute_reduction_method,\n+                reduction=\"concat\",\n             )\n             return outputs\n \n@@ -240,11 +227,9 @@ class TensorFlowTrainer(base_trainer.Trainer):\n             predict_function = one_step_on_data_distributed\n \n         if not self.run_eagerly:\n-            kwargs = {}\n-            if self._supports_reduce_retracing:\n-                kwargs.update({\"reduce_retracing\": True})\n-\n-            predict_function = tf.function(predict_function, **kwargs)\n+            predict_function = tf.function(\n+                predict_function, reduce_retracing=True\n+            )\n \n         self.predict_function = predict_function\n \n@@ -733,22 +718,22 @@ def reduce_per_replica(values, strategy, reduction):\n        axis of dimension 0. This is used in the inference case (`predict()`).\n \n     Args:\n-      values: Structure of `PerReplica` objects or `tf.Tensor`s. `tf.Tensor`s\n-        are returned as-is.\n+        values: Structure of `PerReplica` objects or `tf.Tensor`s.\n+            `tf.Tensor`s are returned as-is.\n         strategy: `tf.distribute.Strategy` object.\n-      reduction: One of `\"auto\"`, `\"first\"`, `\"concat\"`, or `\"sum\"`.\n+        reduction: One of `\"auto\"`, `\"first\"`, `\"concat\"`, `\"mean\"`, or `\"sum\"`.\n             `\"auto\"` will select `\"first\"` when used under a TPUStrategy, or\n-        `\"sum\"` otherwise.\n+            `\"mean\"` otherwise.\n \n     Returns:\n         Structure of `Tensor`s, representing the result of reduction.\n-\n-    Raises:\n-      ValueError: if the reduction method is not supported.\n     \"\"\"\n \n     if reduction == \"auto\":\n-        reduction = \"sum\"  # Ignore TPU strategy which should default to \"first\"\n+        if isinstance(strategy, tf.distribute.TPUStrategy):\n+            reduction = \"first\"\n+        else:\n+            reduction = \"mean\"\n \n     def _reduce(v):\n         \"\"\"Reduce a single `PerReplica` object.\"\"\"\n@@ -756,7 +741,9 @@ def reduce_per_replica(values, strategy, reduction):\n             if reduction == \"concat\":\n                 return _multi_worker_concat(v, strategy)\n             elif reduction == \"sum\":\n-                return strategy.reduce(\"SUM\", v, axis=None)\n+                return strategy.reduce(\"SUM\", v)\n+            elif reduction == \"mean\":\n+                return strategy.reduce(\"MEAN\", v, axis=0)\n \n         if not _is_per_replica_instance(v):\n             return v\n@@ -769,9 +756,14 @@ def reduce_per_replica(values, strategy, reduction):\n                 return concat(strategy.experimental_local_results(v))\n         elif reduction == \"sum\":\n             return tf.reduce_sum(strategy.experimental_local_results(v))\n+        elif reduction == \"mean\":\n+            return tf.reduce_mean(\n+                strategy.experimental_local_results(v), axis=0\n+            )\n         else:\n             raise ValueError(\n-                '`reduction` must be \"first\", \"concat\", \"sum\", or \"auto\". '\n+                \"`reduction` must be one of \"\n+                '\"first\", \"concat\", \"mean\", \"sum\", or \"auto\". '\n                 f\"Received: reduction={reduction}.\"\n             )\n \n\n@@ -1078,6 +1078,7 @@ class TestTrainer(testing.TestCase, parameterized.TestCase):\n             optimizer=\"sgd\", loss=\"mse\", metrics=[metrics_zero, metrics_one]\n         )\n         eval_out = model.evaluate(np.ones((3, 2)), np.ones((3, 3)))\n+        self.assertLen(eval_out, 3)\n         self.assertEqual(eval_out[1], 0.0)\n         self.assertEqual(eval_out[2], 1.0)\n \n@@ -1085,6 +1086,7 @@ class TestTrainer(testing.TestCase, parameterized.TestCase):\n             optimizer=\"sgd\", loss=\"mse\", metrics=[metrics_one, metrics_zero]\n         )\n         eval_out = model.evaluate(np.ones((3, 2)), np.ones((3, 3)))\n+        self.assertLen(eval_out, 3)\n         self.assertEqual(eval_out[1], 1.0)\n         self.assertEqual(eval_out[2], 0.0)\n \n@@ -1345,3 +1347,52 @@ class TestTrainer(testing.TestCase, parameterized.TestCase):\n         y = np.ones((32, 2)) * 2\n         history = model.fit(x, y)\n         self.assertGreater(history.history[\"custom\"][0], 0.0)\n+\n+\n+class TrainerDistributeTest(testing.TestCase):\n+    @pytest.mark.skipif(\n+        backend.backend() != \"tensorflow\", reason=\"Requires tf.distribute\"\n+    )\n+    def test_end_to_end_tf_distribute(self):\n+        import tensorflow as tf\n+        from tensorflow.python.eager import context\n+\n+        context._reset_context()\n+        cpus = tf.config.list_physical_devices(\"CPU\")\n+        tf.config.set_logical_device_configuration(\n+            cpus[0],\n+            [\n+                tf.config.LogicalDeviceConfiguration(),\n+                tf.config.LogicalDeviceConfiguration(),\n+            ],\n+        )\n+        strategy = tf.distribute.MirroredStrategy([\"CPU:0\", \"CPU:1\"])\n+        with strategy.scope():\n+            model = keras.Sequential(\n+                [\n+                    keras.Input((2,)),\n+                    keras.layers.Dense(\n+                        2,\n+                        activation=\"softmax\",\n+                        use_bias=False,\n+                        kernel_initializer=\"ones\",\n+                    ),\n+                ]\n+            )\n+            model.compile(\n+                optimizer=\"sgd\",\n+                loss=\"sparse_categorical_crossentropy\",\n+                metrics=[\"sparse_categorical_accuracy\"],\n+            )\n+            x = (np.arange(512) / 128).reshape((256, 2))\n+            y = (np.arange(256) % 2).reshape((256, 1))\n+            out_fit = model.fit(x, y)\n+            self.assertLess(\n+                out_fit.history[\"sparse_categorical_accuracy\"][0], 0.6\n+            )\n+            out_eval = model.evaluate(x, y)\n+            self.assertLess(out_eval[1], 0.6)\n+            out_predict = model.predict(x)\n+            self.assertEqual(out_predict.shape, (256, 2))\n+\n+        context._reset_context()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cf8ca3c7be849aa87eeddd51530bfd47caa225d6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 14 | Churn Cumulative: 33 | Contributors (this commit): 1 | Commits (past 90d): 2 | Contributors (cumulative): 1 | DMM Complexity: 0.0\n\nDIFF:\n@@ -99,8 +99,22 @@ class BackupAndRestore(Callback):\n \n     def on_train_begin(self, logs=None):\n         \"\"\"Get training state from temporary file and restore it.\"\"\"\n+        if not self.model.built:\n+            raise ValueError(\n+                \"To use the BackupAndRestore callback, \"\n+                \"you model must be built before you call `fit()`. \"\n+                f\"Model {self.model} is unbuilt. You can build it \"\n+                \"beforehand by calling it on a batch of data.\"\n+            )\n         if file_utils.exists(self._weights_path):\n+            if (\n+                self.model.optimizer is not None\n+                and not self.model.optimizer.built\n+            ):\n+                # Make sure optimizer weights exist before loading.\n+                self.model.optimizer.build(self.model.trainable_variables)\n             self.model.load_weights(self._weights_path)\n+\n         if file_utils.exists(self._training_metadata_path):\n             with file_utils.File(self._training_metadata_path, \"r\") as f:\n                 training_metadata = json.loads(f.read())\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
