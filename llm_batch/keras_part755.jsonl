{"custom_id": "keras#04c5ef4eb6711101cdbf663bbabea3eaadb23f78", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 54 | Lines Deleted: 33 | Files Changed: 6 | Hunks: 23 | Methods Changed: 9 | Complexity Δ (Sum/Max): 13/4 | Churn Δ: 87 | Churn Cumulative: 2907 | Contributors (this commit): 17 | Commits (past 90d): 15 | Contributors (cumulative): 22 | DMM Complexity: 0.21052631578947367\n\nDIFF:\n@@ -1025,7 +1025,10 @@ class Layer(BackendLayer, Operation):\n \n     @utils.default\n     def compute_output_shape(self, *args, **kwargs):\n-        return NotImplementedError\n+        raise NotImplementedError(\n+            f\"Layer {self.__class__.__name__} should implement \"\n+            \"`def compute_output_shape(self, input_shape)`.\"\n+        )\n \n     def add_loss(self, loss):\n         \"\"\"Can be called inside of the `call()` method to add a scalar loss.\n\n@@ -200,7 +200,6 @@ def audio_dataset_from_directory(\n             output_sequence_length=output_sequence_length,\n             ragged=ragged,\n         )\n-\n         train_dataset = prepare_dataset(\n             dataset=train_dataset,\n             batch_size=batch_size,\n@@ -234,7 +233,6 @@ def audio_dataset_from_directory(\n             output_sequence_length=output_sequence_length,\n             ragged=ragged,\n         )\n-\n         dataset = prepare_dataset(\n             dataset=dataset,\n             batch_size=batch_size,\n@@ -312,7 +310,7 @@ def get_training_and_validation_dataset(\n         file_paths=file_paths_train,\n         labels=labels_train,\n         label_mode=label_mode,\n-        num_classes=len(class_names),\n+        num_classes=len(class_names) if class_names else 0,\n         sampling_rate=sampling_rate,\n         output_sequence_length=output_sequence_length,\n         ragged=ragged,\n@@ -322,7 +320,7 @@ def get_training_and_validation_dataset(\n         file_paths=file_paths_val,\n         labels=labels_val,\n         label_mode=label_mode,\n-        num_classes=len(class_names),\n+        num_classes=len(class_names) if class_names else 0,\n         sampling_rate=sampling_rate,\n         output_sequence_length=output_sequence_length,\n         ragged=ragged,\n@@ -356,7 +354,7 @@ def get_dataset(\n         file_paths=file_paths,\n         labels=labels,\n         label_mode=label_mode,\n-        num_classes=len(class_names),\n+        num_classes=len(class_names) if class_names else 0,\n         sampling_rate=sampling_rate,\n         output_sequence_length=output_sequence_length,\n         ragged=ragged,\n\n@@ -513,14 +513,15 @@ def index_directory(\n             Otherwise, the directory structure is ignored.\n         labels: Either `\"inferred\"`\n             (labels are generated from the directory structure),\n-            None (no labels),\n+            `None` (no labels),\n             or a list/tuple of integer labels of the same size as the number\n             of valid files found in the directory.\n             Labels should be sorted according\n             to the alphanumeric order of the image file paths\n             (obtained via `os.walk(directory)` in Python).\n-        formats: Allowlist of file extensions to index (e.g. \".jpg\", \".txt\").\n-        class_names: Only valid if \"labels\" is \"inferred\". This is the explicit\n+        formats: Allowlist of file extensions to index\n+            (e.g. `\".jpg\"`, `\".txt\"`).\n+        class_names: Only valid if `labels=\"inferred\"`. This is the explicit\n             list of class names (must match names of subdirectories). Used\n             to control the order of the classes\n             (otherwise alphanumerical order is used).\n@@ -536,11 +537,7 @@ def index_directory(\n         - class_names: names of the classes corresponding to these labels, in\n         order.\n     \"\"\"\n-    if labels != \"inferred\":\n-        # in the explicit/no-label cases, index from the parent directory down.\n-        subdirs = [\"\"]\n-        class_names = subdirs\n-    else:\n+    if labels == \"inferred\":\n         subdirs = []\n         for subdir in sorted(tf.io.gfile.listdir(directory)):\n             if tf.io.gfile.isdir(tf.io.gfile.join(directory, subdir)):\n@@ -548,15 +545,31 @@ def index_directory(\n                     if subdir.endswith(\"/\"):\n                         subdir = subdir[:-1]\n                     subdirs.append(subdir)\n-        if not class_names:\n-            class_names = subdirs\n-        else:\n-            if set(class_names) != set(subdirs):\n+        if class_names is not None:\n+            if set(class_names).issubset(set(subdirs)):\n                 raise ValueError(\n                     \"The `class_names` passed did not match the \"\n                     \"names of the subdirectories of the target directory. \"\n-                    f\"Expected: {subdirs}, but received: {class_names}\"\n+                    f\"Expected: {subdirs} (or a subset of it), \"\n+                    f\"but received: class_names={class_names}\"\n                 )\n+            subdirs = class_names  # Keep provided order.\n+    else:\n+        # In the explicit/no-label cases, index from the parent directory down.\n+        subdirs = [\"\"]\n+        if class_names is not None:\n+            if labels is None:\n+                raise ValueError(\n+                    \"When `labels=None` (no labels), argument `class_names` \"\n+                    \"cannot be specified.\"\n+                )\n+            else:\n+                raise ValueError(\n+                    \"When argument `labels` is specified, argument \"\n+                    \"`class_names` cannot be specified (the `class_names` \"\n+                    \"will be the sorted list of labels).\"\n+                )\n+    class_names = subdirs\n     class_indices = dict(zip(class_names, range(len(class_names))))\n \n     # Build an index of the files\n@@ -577,7 +590,18 @@ def index_directory(\n         partial_filenames, partial_labels = res.get()\n         labels_list.append(partial_labels)\n         filenames += partial_filenames\n-    if labels not in (\"inferred\", None):\n+\n+    if labels == \"inferred\":\n+        # Inferred labels.\n+        i = 0\n+        labels = np.zeros((len(filenames),), dtype=\"int32\")\n+        for partial_labels in labels_list:\n+            labels[i : i + len(partial_labels)] = partial_labels\n+            i += len(partial_labels)\n+    elif labels is None:\n+        class_names = None\n+    else:\n+        # Manual labels.\n         if len(labels) != len(filenames):\n             raise ValueError(\n                 \"Expected the lengths of `labels` to match the number \"\n@@ -586,12 +610,6 @@ def index_directory(\n                 f\"in directory {directory}.\"\n             )\n         class_names = sorted(set(labels))\n-    else:\n-        i = 0\n-        labels = np.zeros((len(filenames),), dtype=\"int32\")\n-        for partial_labels in labels_list:\n-            labels[i : i + len(partial_labels)] = partial_labels\n-            i += len(partial_labels)\n \n     if labels is None:\n         io_utils.print_msg(f\"Found {len(filenames)} files.\")\n@@ -610,6 +628,7 @@ def index_directory(\n             seed = np.random.randint(1e6)\n         rng = np.random.RandomState(seed)\n         rng.shuffle(file_paths)\n+        if labels is not None:\n             rng = np.random.RandomState(seed)\n             rng.shuffle(labels)\n     return file_paths, labels, class_names\n\n@@ -256,7 +256,7 @@ def image_dataset_from_directory(\n             num_channels=num_channels,\n             labels=labels_train,\n             label_mode=label_mode,\n-            num_classes=len(class_names),\n+            num_classes=len(class_names) if class_names else 0,\n             interpolation=interpolation,\n             crop_to_aspect_ratio=crop_to_aspect_ratio,\n             data_format=data_format,\n@@ -268,7 +268,7 @@ def image_dataset_from_directory(\n             num_channels=num_channels,\n             labels=labels_val,\n             label_mode=label_mode,\n-            num_classes=len(class_names),\n+            num_classes=len(class_names) if class_names else 0,\n             interpolation=interpolation,\n             crop_to_aspect_ratio=crop_to_aspect_ratio,\n             data_format=data_format,\n@@ -316,7 +316,7 @@ def image_dataset_from_directory(\n             num_channels=num_channels,\n             labels=labels,\n             label_mode=label_mode,\n-            num_classes=len(class_names),\n+            num_classes=len(class_names) if class_names else 0,\n             interpolation=interpolation,\n             crop_to_aspect_ratio=crop_to_aspect_ratio,\n             data_format=data_format,\n\n@@ -63,7 +63,7 @@ class ImageDatasetFromDirectoryTest(testing.TestCase):\n             i += 1\n         return temp_dir\n \n-    def test_image_dataset_from_directory_standalone(self):\n+    def test_image_dataset_from_directory_no_labels(self):\n         # Test retrieving images without labels from a directory and its\n         # subdirs.\n \n@@ -76,6 +76,7 @@ class ImageDatasetFromDirectoryTest(testing.TestCase):\n         dataset = image_dataset_utils.image_dataset_from_directory(\n             directory, batch_size=5, image_size=(18, 18), labels=None\n         )\n+        self.assertEqual(dataset.class_names, None)\n         batch = next(iter(dataset))\n         # We return plain images\n         self.assertEqual(batch.shape, (5, 18, 18, 3))\n\n@@ -184,14 +184,14 @@ def text_dataset_from_directory(\n             file_paths=file_paths_train,\n             labels=labels_train,\n             label_mode=label_mode,\n-            num_classes=len(class_names),\n+            num_classes=len(class_names) if class_names else 0,\n             max_length=max_length,\n         )\n         val_dataset = paths_and_labels_to_dataset(\n             file_paths=file_paths_val,\n             labels=labels_val,\n             label_mode=label_mode,\n-            num_classes=len(class_names),\n+            num_classes=len(class_names) if class_names else 0,\n             max_length=max_length,\n         )\n \n@@ -227,7 +227,7 @@ def text_dataset_from_directory(\n             file_paths=file_paths,\n             labels=labels,\n             label_mode=label_mode,\n-            num_classes=len(class_names),\n+            num_classes=len(class_names) if class_names else 0,\n             max_length=max_length,\n         )\n         dataset = dataset.prefetch(tf.data.AUTOTUNE)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e237f083784579e5dcbe578c78888951b95bf016", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 38 | Lines Deleted: 14 | Files Changed: 1 | Hunks: 14 | Methods Changed: 5 | Complexity Δ (Sum/Max): 5/5 | Churn Δ: 52 | Churn Cumulative: 89 | Contributors (this commit): 2 | Commits (past 90d): 4 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1,4 +1,3 @@\n-import numpy as np\n import torch\n import torch.nn.functional as tnn\n import tree\n@@ -112,20 +111,30 @@ def _compute_padding_length(\n     input_length, kernel_length, stride, dilation_rate=1\n ):\n     \"\"\"Compute padding length along one dimension.\"\"\"\n-    if (input_length - 1) % stride == 0:\n-        total_padding_length = dilation_rate * (kernel_length - 1)\n-    else:\n     total_padding_length = (\n         dilation_rate * (kernel_length - 1) - (input_length - 1) % stride\n     )\n-    left_padding = int(np.floor(total_padding_length / 2))\n-    right_padding = int(np.ceil(total_padding_length / 2))\n+    left_padding = total_padding_length // 2\n+    right_padding = (total_padding_length + 1) // 2\n     return (left_padding, right_padding)\n \n \n def _apply_same_padding(\n     inputs, kernel_size, strides, operation_type, dilation_rate=1\n ):\n+    \"\"\"Apply same padding to the input tensor.\n+\n+    This function will evaluate if the padding value is compatible with torch\n+    functions. To avoid calling `pad()` as much as possible, which may cause\n+    performance or memory issues, when compatible, it does not apply the padding\n+    to the tensor, but returns the input tensor and the padding value to pass to\n+    the torch functions. If not compatible, it returns the padded tensor and 0\n+    as the padding value.\n+\n+    Returns:\n+        tensor: A padded tensor or the inputs.\n+        padding: The padding value, ready to pass to the torch functions.\n+    \"\"\"\n     spatial_shape = inputs.shape[2:]\n     num_spatial_dims = len(spatial_shape)\n     padding = ()\n@@ -144,9 +153,15 @@ def _apply_same_padding(\n                 spatial_shape[i], kernel_size[i], strides[i], dilation_rate[i]\n             )\n             mode = \"constant\"\n-        padding = padding_size + padding\n+        padding = (padding_size,) + padding\n \n-    return tnn.pad(inputs, padding, mode=mode)\n+    if all([left == right for left, right in padding]):\n+        return inputs, [left for left, _ in padding]\n+\n+    flattened_padding = tuple(\n+        value for left_and_right in padding for value in left_and_right\n+    )\n+    return tnn.pad(inputs, pad=flattened_padding, mode=mode), 0\n \n \n def _transpose_spatial_inputs(inputs):\n@@ -215,9 +230,11 @@ def max_pool(\n     if padding == \"same\":\n         # Torch does not natively support `\"same\"` padding, we need to manually\n         # apply the right amount of padding to `inputs`.\n-        inputs = _apply_same_padding(\n+        inputs, padding = _apply_same_padding(\n             inputs, pool_size, strides, operation_type=\"pooling\"\n         )\n+    else:\n+        padding = 0\n \n     device = get_device()\n     # Torch max pooling ops do not support symbolic tensors.\n@@ -228,11 +245,17 @@ def max_pool(\n         )\n \n     if num_spatial_dims == 1:\n-        outputs = tnn.max_pool1d(inputs, kernel_size=pool_size, stride=strides)\n+        outputs = tnn.max_pool1d(\n+            inputs, kernel_size=pool_size, stride=strides, padding=padding\n+        )\n     elif num_spatial_dims == 2:\n-        outputs = tnn.max_pool2d(inputs, kernel_size=pool_size, stride=strides)\n+        outputs = tnn.max_pool2d(\n+            inputs, kernel_size=pool_size, stride=strides, padding=padding\n+        )\n     elif num_spatial_dims == 3:\n-        outputs = tnn.max_pool3d(inputs, kernel_size=pool_size, stride=strides)\n+        outputs = tnn.max_pool3d(\n+            inputs, kernel_size=pool_size, stride=strides, padding=padding\n+        )\n     else:\n         raise ValueError(\n             \"Inputs to pooling op must have ndim=3, 4 or 5, \"\n@@ -283,6 +306,8 @@ def average_pool(\n                 # Handle unequal padding.\n                 # `torch.nn.pad` sets padding value in the reverse order.\n                 uneven_padding = [0, 1] + uneven_padding\n+        # Only call tnn.pad when needed.\n+        if len(uneven_padding) > 0:\n             inputs = tnn.pad(inputs, uneven_padding)\n \n     if num_spatial_dims == 1:\n@@ -341,14 +366,13 @@ def conv(\n     if padding == \"same\" and any(d != 1 for d in tree.flatten(strides)):\n         # Torch does not support this case in conv2d().\n         # Manually pad the tensor.\n-        inputs = _apply_same_padding(\n+        inputs, padding = _apply_same_padding(\n             inputs,\n             kernel.shape[2:],\n             strides,\n             operation_type=\"conv\",\n             dilation_rate=dilation_rate,\n         )\n-        padding = 0\n     channels = inputs.shape[1]\n     kernel_in_channels = kernel.shape[1]\n     if channels % kernel_in_channels > 0:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ace2f43edc82f5a474301baff7ca2da3ee9d383c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 68 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -701,10 +701,10 @@ base_optimizer_keyword_args = \"\"\"name: String. The name to use\n         weight_decay: Float, defaults to None. If set, weight decay is applied.\n         clipnorm: Float. If set, the gradient of each weight is individually\n           clipped so that its norm is no higher than this value.\n-      clipvalue: Float. If set, the gradient of each weight is clipped to be no\n-          higher than this value.\n-      global_clipnorm: Float. If set, the gradient of all weights is clipped so\n-          that their global norm is no higher than this value.\n+        clipvalue: Float. If set, the gradient of each weight is clipped to be\n+          no higher than this value.\n+        global_clipnorm: Float. If set, the gradient of all weights is clipped\n+          so that their global norm is no higher than this value.\n         use_ema: Boolean, defaults to False. If True, exponential moving average\n           (EMA) is applied. EMA consists of computing an exponential moving\n           average of the weights of the model (as the weight values change after\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ca5fdfae35e23c3422f41cc7799ebcd2ae6bbd41", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 23 | Churn Cumulative: 1219 | Contributors (this commit): 7 | Commits (past 90d): 3 | Contributors (cumulative): 7 | DMM Complexity: 0.6\n\nDIFF:\n@@ -47,7 +47,7 @@ def np_conv1d_transpose(\n         strides,\n         padding,\n         output_padding,\n-        data_format,\n+        \"channels_last\",\n         dilation_rate,\n     )\n     jax_padding = compute_conv_transpose_padding_args_for_jax(\n@@ -770,7 +770,12 @@ class ConvTransposeCorrectnessTest(testing.TestCase, parameterized.TestCase):\n                 \"`output_padding` greater than `strides` is not supported\"\n             )\n \n-        input = np.ones(shape=(1, 3, 1))\n+        if backend.config.image_data_format() == \"channels_last\":\n+            input_shape = (1, 3, 1)\n+        else:\n+            input_shape = (1, 1, 3)\n+\n+        input = np.ones(shape=input_shape)\n         kernel_weights = np.arange(1, kernel_size + 1).reshape(\n             (kernel_size, 1, 1)\n         )\n@@ -783,7 +788,7 @@ class ConvTransposeCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             strides=strides,\n             padding=padding,\n             output_padding=output_padding,\n-            data_format=\"channels_last\",\n+            data_format=backend.config.image_data_format(),\n             dilation_rate=1,\n         )\n \n@@ -796,7 +801,7 @@ class ConvTransposeCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             output_padding=output_padding,\n             dilation_rate=1,\n         )\n-        kc_layer.build(input_shape=(1, 3, 1))\n+        kc_layer.build(input_shape=input_shape)\n         kc_layer.kernel.assign(kernel_weights)\n \n         # Special cases for Torch\n@@ -845,7 +850,13 @@ class ConvTransposeCorrectnessTest(testing.TestCase, parameterized.TestCase):\n     def test_shape_inference_static_unknown_shape(\n         self, kernel_size, strides, padding, output_padding\n     ):\n-        x = layers.Input(shape=(None, None, 3))\n+        if backend.config.image_data_format() == \"channels_last\":\n+            input_shape = (None, None, 3)\n+            output_tensor_shape = (None, None, None, 2)\n+        else:\n+            input_shape = (3, None, None)\n+            output_tensor_shape = (None, 2, None, None)\n+        x = layers.Input(shape=input_shape)\n         x = layers.Conv2DTranspose(\n             filters=2,\n             kernel_size=kernel_size,\n@@ -854,4 +865,4 @@ class ConvTransposeCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             output_padding=output_padding,\n             dilation_rate=1,\n         )(x)\n-        self.assertEqual(x.shape, (None, None, None, 2))\n+        self.assertEqual(x.shape, output_tensor_shape)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#588d3c5d5de7cfa0634f0edf59e83eb31af04f11", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 33 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 5 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 37 | Churn Cumulative: 2779 | Contributors (this commit): 16 | Commits (past 90d): 6 | Contributors (cumulative): 17 | DMM Complexity: 1.0\n\nDIFF:\n@@ -609,7 +609,7 @@ def index_directory(\n                 f\"{len(labels)} while we found {len(filenames)} files \"\n                 f\"in directory {directory}.\"\n             )\n-        class_names = sorted(set(labels))\n+        class_names = [str(label) for label in sorted(set(labels))]\n \n     if labels is None:\n         io_utils.print_msg(f\"Found {len(filenames)} files.\")\n\n@@ -255,17 +255,46 @@ class ImageDatasetFromDirectoryTest(testing.TestCase):\n         self.assertEqual(batch[0].shape, (2, 18, 18, 3))\n \n     def test_image_dataset_from_directory_manual_labels(self):\n-        directory = self._prepare_directory(num_classes=2, count=2)\n+        # Case: wrong number of labels\n+        directory = self._prepare_directory(num_classes=1, count=4)\n+        with self.assertRaisesRegex(ValueError, \"match the number of files\"):\n+            image_dataset_utils.image_dataset_from_directory(\n+                directory,\n+                batch_size=8,\n+                image_size=(18, 18),\n+                labels=[0, 1, 0],\n+                shuffle=False,\n+            )\n+\n+        # Case: single directory\n+        directory = self._prepare_directory(num_classes=1, count=4)\n         dataset = image_dataset_utils.image_dataset_from_directory(\n             directory,\n             batch_size=8,\n             image_size=(18, 18),\n-            labels=[0, 1],\n+            labels=[0, 1, 0, 1],\n             shuffle=False,\n         )\n+        self.assertEqual(dataset.class_names, [\"0\", \"1\"])\n         batch = next(iter(dataset))\n         self.assertLen(batch, 2)\n-        self.assertAllClose(batch[1], [0, 1])\n+        self.assertEqual(batch[0].shape, (4, 18, 18, 3))\n+        self.assertAllClose(batch[1], [0, 1, 0, 1])\n+\n+        # Case: multiple directories\n+        directory = self._prepare_directory(num_classes=3, count=6)\n+        dataset = image_dataset_utils.image_dataset_from_directory(\n+            directory,\n+            batch_size=8,\n+            image_size=(18, 18),\n+            labels=[0, 1, 0, 1, 1, 1],\n+            shuffle=False,\n+        )\n+        self.assertEqual(dataset.class_names, [\"0\", \"1\"])\n+        batch = next(iter(dataset))\n+        self.assertLen(batch, 2)\n+        self.assertEqual(batch[0].shape, (6, 18, 18, 3))\n+        self.assertAllClose(batch[1], [0, 1, 0, 1, 1, 1])\n \n     def test_image_dataset_from_directory_follow_links(self):\n         directory = self._prepare_directory(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#13ef4a827494d11b8755bc83519b0ddbba2cdf73", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 117 | Lines Deleted: 2 | Files Changed: 4 | Hunks: 10 | Methods Changed: 14 | Complexity Δ (Sum/Max): 23/10 | Churn Δ: 119 | Churn Cumulative: 217 | Contributors (this commit): 3 | Commits (past 90d): 11 | Contributors (cumulative): 10 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,5 +1,6 @@\n import itertools\n \n+import numpy as np\n import tree\n \n from keras.trainers.data_adapters.data_adapter import DataAdapter\n@@ -38,6 +39,11 @@ class GeneratorDataAdapter(DataAdapter):\n                 )\n             shape = list(shape)\n             shape[0] = None  # The batch size is not guaranteed to be static.\n+            if isinstance(x, tf.RaggedTensor):\n+                return tf.RaggedTensorSpec(shape=shape, dtype=x.dtype.name)\n+            if isinstance(x, tf.SparseTensor) or is_scipy_sparse(x):\n+                return tf.SparseTensorSpec(shape=shape, dtype=x.dtype.name)\n+            else:\n                 return tf.TensorSpec(shape=shape, dtype=x.dtype.name)\n \n         self._output_signature = tree.map_structure(get_tensor_spec, data)\n@@ -49,10 +55,20 @@ class GeneratorDataAdapter(DataAdapter):\n     def get_tf_dataset(self):\n         from keras.utils.module_utils import tensorflow as tf\n \n+        def convert_to_tf(batch):\n+            if is_scipy_sparse(batch):\n+                batch = scipy_sparse_to_tf_sparse(batch)\n+            return batch\n+\n+        def get_tf_iterator():\n+            for batch in self.generator:\n+                batch = tree.map_structure(convert_to_tf, batch)\n+                yield batch\n+\n         if self._output_signature is None:\n             self._set_tf_output_signature()\n         ds = tf.data.Dataset.from_generator(\n-            self.get_numpy_iterator,\n+            get_tf_iterator,\n             output_signature=self._output_signature,\n         )\n         ds = ds.prefetch(tf.data.AUTOTUNE)\n@@ -70,3 +86,21 @@ class GeneratorDataAdapter(DataAdapter):\n def peek_and_restore(generator):\n     element = next(generator)\n     return element, itertools.chain([element], generator)\n+\n+\n+def is_scipy_sparse(x):\n+    return x.__class__.__module__.startswith(\"scipy.sparse\") and hasattr(\n+        x, \"tocoo\"\n+    )\n+\n+\n+def scipy_sparse_to_tf_sparse(x):\n+    from keras.utils.module_utils import tensorflow as tf\n+\n+    sparse_coo = x.tocoo()\n+    row, col = sparse_coo.row, sparse_coo.col\n+    data, shape = sparse_coo.data, sparse_coo.shape\n+    indices = np.concatenate(\n+        (np.expand_dims(row, axis=1), np.expand_dims(col, axis=1)), axis=1\n+    )\n+    return tf.SparseTensor(indices, data, shape)\n\n@@ -1,6 +1,7 @@\n import math\n \n import numpy as np\n+import scipy\n import tensorflow as tf\n from absl.testing import parameterized\n \n@@ -88,3 +89,49 @@ class GeneratorDataAdapterTest(testing.TestCase, parameterized.TestCase):\n             for i in range(by.shape[0]):\n                 sample_order.append(by[i, 0])\n         self.assertAllClose(sample_order, list(range(64)))\n+\n+    def test_tf_sparse_tensors(self):\n+        def generate_tf():\n+            for i in range(4):\n+                x = tf.SparseTensor(\n+                    indices=[[0, 0], [1, 2]],\n+                    values=[1.0, 2.0],\n+                    dense_shape=(2, 4),\n+                )\n+                y = tf.SparseTensor(\n+                    indices=[[0, 0], [1, 1]],\n+                    values=[3.0, 4.0],\n+                    dense_shape=(2, 2),\n+                )\n+                yield x, y\n+\n+        adapter = generator_data_adapter.GeneratorDataAdapter(generate_tf())\n+        ds = adapter.get_tf_dataset()\n+        for batch in ds:\n+            self.assertEqual(len(batch), 2)\n+            bx, by = batch\n+            self.assertIsInstance(bx, tf.SparseTensor)\n+            self.assertIsInstance(by, tf.SparseTensor)\n+            self.assertEqual(bx.shape, (2, 4))\n+            self.assertEqual(by.shape, (2, 2))\n+\n+    def test_scipy_sparse_tensors(self):\n+        def generate_scipy():\n+            for i in range(4):\n+                x = scipy.sparse.coo_matrix(\n+                    ([1.0, 2.0], ([0, 1], [0, 2])), shape=[2, 4]\n+                )\n+                y = scipy.sparse.coo_matrix(\n+                    ([3.0, 4.0], ([0, 1], [0, 1])), shape=[2, 2]\n+                )\n+                yield x, y\n+\n+        adapter = generator_data_adapter.GeneratorDataAdapter(generate_scipy())\n+        ds = adapter.get_tf_dataset()\n+        for batch in ds:\n+            self.assertEqual(len(batch), 2)\n+            bx, by = batch\n+            self.assertIsInstance(bx, tf.SparseTensor)\n+            self.assertIsInstance(by, tf.SparseTensor)\n+            self.assertEqual(bx.shape, (2, 4))\n+            self.assertEqual(by.shape, (2, 2))\n\n@@ -36,8 +36,15 @@ class TFDatasetAdapter(DataAdapter):\n         self._dataset = dataset\n \n     def get_numpy_iterator(self):\n+        from keras.utils.module_utils import tensorflow as tf\n+\n+        def convert_to_numpy(x):\n+            if isinstance(x, tf.SparseTensor):\n+                x = tf.sparse.to_dense(x)\n+            return x.numpy()\n+\n         for batch in self._dataset:\n-            yield tree.map_structure(lambda x: x.numpy(), batch)\n+            yield tree.map_structure(convert_to_numpy, batch)\n \n     def get_tf_dataset(self):\n         return self._dataset\n\n@@ -252,3 +252,30 @@ class TestTFDatasetAdapter(testing.TestCase):\n             else:\n                 self.assertEqual(tuple(bx.shape), (2, 4))\n                 self.assertEqual(tuple(by.shape), (2, 2))\n+\n+    def test_tf_sparse_tensors(self):\n+        x = tf.SparseTensor(\n+            indices=[[0, 0], [1, 2]], values=[1.0, 2.0], dense_shape=(2, 4)\n+        )\n+        y = tf.SparseTensor(\n+            indices=[[0, 0], [1, 1]], values=[3.0, 4.0], dense_shape=(2, 2)\n+        )\n+        base_ds = tf.data.Dataset.from_tensors((x, y))\n+        adapter = tf_dataset_adapter.TFDatasetAdapter(base_ds)\n+\n+        gen = adapter.get_numpy_iterator()\n+        for batch in gen:\n+            self.assertEqual(len(batch), 2)\n+            bx, by = batch\n+            self.assertIsInstance(bx, np.ndarray)\n+            self.assertIsInstance(by, np.ndarray)\n+            self.assertEqual(bx.shape, (2, 4))\n+            self.assertEqual(by.shape, (2, 2))\n+        ds = adapter.get_tf_dataset()\n+        for batch in ds:\n+            self.assertEqual(len(batch), 2)\n+            bx, by = batch\n+            self.assertIsInstance(bx, tf.SparseTensor)\n+            self.assertIsInstance(by, tf.SparseTensor)\n+            self.assertEqual(bx.shape, (2, 4))\n+            self.assertEqual(by.shape, (2, 2))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a6d1fe1c712d8c3602e7c0a618d12a49bd3dba99", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 70 | Contributors (this commit): 3 | Commits (past 90d): 4 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -698,7 +698,7 @@ class BaseOptimizer:\n base_optimizer_keyword_args = \"\"\"name: String. The name to use\n           for momentum accumulator weights created by\n           the optimizer.\n-        weight_decay: Float, defaults to None. If set, weight decay is applied.\n+        weight_decay: Float. If set, weight decay is applied.\n         clipnorm: Float. If set, the gradient of each weight is individually\n           clipped so that its norm is no higher than this value.\n         clipvalue: Float. If set, the gradient of each weight is clipped to be\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#11cbb29b30a52ee6ea0087eebf4837ce016b97d7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 12 | Churn Cumulative: 22 | Contributors (this commit): 1 | Commits (past 90d): 2 | Contributors (cumulative): 1 | DMM Complexity: 0.0\n\nDIFF:\n@@ -61,14 +61,10 @@ def cond(pred, true_fn, false_fn):\n     return false_fn()\n \n \n-def vectorized_map(function, elements):\n-    if len(elements) == 1:\n-        return function(elements)\n-    else:\n-        batch_size = elements[0].shape[0]\n-        output_store = list()\n-        for index in range(batch_size):\n-            output_store.append(function([x[index] for x in elements]))\n+def vectorized_map(function, x):\n+    output_store = []\n+    for element in x:\n+        output_store.append(function(element))\n     return np.stack(output_store)\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2f825fc7dee09cb2963f601bd004de01477ba698", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 25 | Lines Deleted: 32 | Files Changed: 1 | Hunks: 19 | Methods Changed: 6 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 57 | Churn Cumulative: 400 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -23,7 +23,11 @@ For a more detailed overview of metric learning see:\n \n \"\"\"\n ## Setup\n+\n+Set Keras backend to tensorflow. \n \"\"\"\n+import os\n+os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n \n import random\n import matplotlib.pyplot as plt\n@@ -32,9 +36,8 @@ import tensorflow as tf\n from collections import defaultdict\n from PIL import Image\n from sklearn.metrics import ConfusionMatrixDisplay\n-import keras as keras\n+import keras\n from keras import layers\n-from keras.datasets import cifar10\n \n \"\"\"\n ## Dataset\n@@ -43,6 +46,9 @@ For this example we will be using the\n [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset.\n \"\"\"\n \n+from keras.datasets import cifar10\n+\n+\n (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n \n x_train = x_train.astype(\"float32\") / 255.0\n@@ -70,9 +76,7 @@ def show_collage(examples):\n     )\n     for row_idx in range(num_rows):\n         for col_idx in range(num_cols):\n-            array = (np.array(examples[row_idx, col_idx]) * 255).astype(\n-                np.uint8\n-            )\n+            array = (np.array(examples[row_idx, col_idx]) * 255).astype(np.uint8)\n             collage.paste(\n                 Image.fromarray(array), (col_idx * box_size, row_idx * box_size)\n             )\n@@ -120,18 +124,16 @@ CIFAR-10 this is 10.\n num_classes = 10\n \n \n-class AnchorPositivePairs(keras.utils.PyDataset):\n-    def __init__(self, num_batchs):\n+class AnchorPositivePairs(keras.utils.Sequence):\n+    def __init__(self, num_batches):\n         super().__init__()\n-        self.num_batchs = num_batchs\n+        self.num_batches = num_batches\n \n     def __len__(self):\n-        return self.num_batchs\n+        return self.num_batches\n \n     def __getitem__(self, _idx):\n-        x = np.empty(\n-            (2, num_classes, height_width, height_width, 3), dtype=np.float32\n-        )\n+        x = np.empty((2, num_classes, height_width, height_width, 3), dtype=np.float32)\n         for class_idx in range(num_classes):\n             examples_for_class = class_idx_to_train_idxs[class_idx]\n             anchor_idx = random.choice(examples_for_class)\n@@ -148,7 +150,7 @@ We can visualise a batch in another collage. The top row shows randomly chosen a\n from the 10 classes, the bottom row shows the corresponding 10 positives.\n \"\"\"\n \n-examples = next(iter(AnchorPositivePairs(num_batchs=1)))\n+examples = next(iter(AnchorPositivePairs(num_batches=1)))\n \n show_collage(examples)\n \n@@ -174,7 +176,7 @@ class EmbeddingModel(keras.Model):\n \n             # Calculate cosine similarity between anchors and positives. As they have\n             # been normalised this is just the pair wise dot products.\n-            similarities = tf.einsum(\n+            similarities = keras.ops.einsum(\n                 \"ae,pe->ap\", anchor_embeddings, positive_embeddings\n             )\n \n@@ -188,16 +190,15 @@ class EmbeddingModel(keras.Model):\n             # want the main diagonal values, which correspond to the anchor/positive\n             # pairs, to be high. This loss will move embeddings for the\n             # anchor/positive pairs together and move all other pairs apart.\n-            sparse_labels = tf.range(num_classes)\n-            loss = self.compute_loss(y=sparse_labels, y_pred=similarities)\n+            sparse_labels = keras.ops.arange(num_classes)\n+            loss = self.compiled_loss(sparse_labels, similarities)\n \n         # Calculate gradients and apply via optimizer.\n         gradients = tape.gradient(loss, self.trainable_variables)\n         self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n \n         # Update and return metrics (specifically the one for the loss value).\n-        for metric in self.metrics:\n-            metric.update_state(sparse_labels, similarities)\n+        self.compiled_metrics.update_state(sparse_labels, similarities)\n         return {m.name: m.result() for m in self.metrics}\n \n \n@@ -210,14 +211,12 @@ this model is intentionally small.\n \"\"\"\n \n inputs = layers.Input(shape=(height_width, height_width, 3))\n-x = layers.Conv2D(filters=32, kernel_size=3, strides=2, activation=\"relu\")(\n-    inputs\n-)\n+x = layers.Conv2D(filters=32, kernel_size=3, strides=2, activation=\"relu\")(inputs)\n x = layers.Conv2D(filters=64, kernel_size=3, strides=2, activation=\"relu\")(x)\n x = layers.Conv2D(filters=128, kernel_size=3, strides=2, activation=\"relu\")(x)\n x = layers.GlobalAveragePooling2D()(x)\n embeddings = layers.Dense(units=8, activation=None)(x)\n-embeddings = keras.layers.UnitNormalization()(embeddings)\n+embeddings = layers.UnitNormalization()(embeddings)\n \n model = EmbeddingModel(inputs, embeddings)\n \n@@ -230,7 +229,7 @@ model.compile(\n     loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n )\n \n-history = model.fit(AnchorPositivePairs(num_batchs=1000), epochs=20)\n+history = model.fit(AnchorPositivePairs(num_batches=1000), epochs=20)\n \n plt.plot(history.history[\"loss\"])\n plt.show()\n@@ -249,9 +248,7 @@ near_neighbours_per_example = 10\n \n embeddings = model.predict(x_test)\n gram_matrix = np.einsum(\"ae,be->ab\", embeddings, embeddings)\n-near_neighbours = np.argsort(gram_matrix.T)[\n-    :, -(near_neighbours_per_example + 1) :\n-]\n+near_neighbours = np.argsort(gram_matrix.T)[:, -(near_neighbours_per_example + 1) :]\n \n \"\"\"\n As a visual check of these embeddings we can build a collage of the near neighbours for 5\n@@ -316,10 +313,6 @@ labels = [\n     \"Ship\",\n     \"Truck\",\n ]\n-disp = ConfusionMatrixDisplay(\n-    confusion_matrix=confusion_matrix, display_labels=labels\n-)\n-disp.plot(\n-    include_values=True, cmap=\"viridis\", ax=None, xticks_rotation=\"vertical\"\n-)\n+disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix, display_labels=labels)\n+disp.plot(include_values=True, cmap=\"viridis\", ax=None, xticks_rotation=\"vertical\")\n plt.show()\n\\ No newline at end of file\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7f29a0943905ad3e3c8ee9a4efc45bdd54d28c37", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 10 | Churn Cumulative: 32 | Contributors (this commit): 1 | Commits (past 90d): 3 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -61,10 +61,14 @@ def cond(pred, true_fn, false_fn):\n     return false_fn()\n \n \n-def vectorized_map(function, x):\n+def vectorized_map(function, elements):\n+    if not isinstance(elements, (list, tuple)):\n+        return np.stack([function(x) for x in elements])\n+    else:\n+        batch_size = elements[0].shape[0]\n         output_store = []\n-    for element in x:\n-        output_store.append(function(element))\n+        for index in range(batch_size):\n+            output_store.append(function([x[index] for x in elements]))\n         return np.stack(output_store)\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9197591956a3fc9c9f2c111fa69a1b9ed5eab7c7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 34 | Lines Deleted: 7 | Files Changed: 2 | Hunks: 7 | Methods Changed: 4 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 41 | Churn Cumulative: 165 | Contributors (this commit): 1 | Commits (past 90d): 6 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -596,16 +596,33 @@ def cond(pred, true_fn, false_fn):\n \n # TODO: also create an Op subclass VectorizedMap.\n @keras_export(\"keras.ops.vectorized_map\")\n-def vectorized_map(function, x):\n-    \"\"\"Parallel map of `function` on axis 0 of tensor `x`.\n+def vectorized_map(function, elements):\n+    \"\"\"Parallel map of `function` on axis 0 of tensor(s) `elements`.\n \n-    Schematically, `vectorized_map` implements the following:\n+    Schematically, `vectorized_map` implements the following,\n+    in the case of a single tensor input `elements`:\n \n     ```python\n-    def vectorized_map(function, x)\n+    def vectorized_map(function, elements)\n         outputs = []\n-        for element in x:\n-            outputs.append(function(element))\n+        for e in elements:\n+            outputs.append(function(e))\n         return stack(outputs)\n+    ```\n+\n+    In the case of an iterable of tensors `elements`,\n+    it implements the following:\n+\n+    ```python\n+    def vectorized_map(function, elements)\n+        batch_size = elements[0].shape[0]\n+        outputs = []\n+        for index in range(batch_size):\n+            outputs.append(function([e[index] for e in elements]))\n+        return np.stack(outputs)\n+    ```\n+\n+    In this case, `function` is expected to take as input\n+    a single list of tensor arguments.\n     \"\"\"\n-    return backend.core.vectorized_map(function, x)\n+    return backend.core.vectorized_map(function, elements)\n\n@@ -402,3 +402,13 @@ class CoreOpsCorrectnessTest(testing.TestCase):\n         self.assertAllClose(\n             backend.convert_to_numpy(output), np.zeros((2, 2, 3))\n         )\n+\n+        # Case: multiple args\n+        def fn(elems):\n+            x, y = elems\n+            return x + y\n+\n+        output = ops.vectorized_map(fn, [ops.ones((2, 3)), ops.ones((2, 3))])\n+        self.assertAllClose(\n+            backend.convert_to_numpy(output), 2 * np.ones((2, 3))\n+        )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cf9b2f3235e4b6040d0866b403259b6ee8841804", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 42 | Lines Deleted: 12 | Files Changed: 1 | Hunks: 6 | Methods Changed: 1 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 54 | Churn Cumulative: 297 | Contributors (this commit): 2 | Commits (past 90d): 8 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -108,9 +108,8 @@ def distribute_tensor(tensor, layout):\n def distribute_data_input(inputs, layout):\n     \"\"\"Distribute the input data with the corresponding layout.\n \n-    Note that the inputs here is a local worker batch, which has already\n-    been sharded to 1/N of the global batch size (N being the number of\n-    workers/processes).\n+    Note that the inputs here is a local worker batch. Within the local worker,\n+    the data need to be further partitioned to map to the each of the devices.\n \n     Args:\n         inputs: `jax.Array` that is already sharded to a local process size.\n@@ -125,22 +124,53 @@ def distribute_data_input(inputs, layout):\n     if layout.is_fully_addressable:\n         return jax.device_put(inputs, layout)\n \n-    # TODO(scottzhu): Add support for data+model parallel.\n-    # We assume the data are batch parallel only for now.\n+    # We need the jax mesh information to determine how to place the data\n+    # on to each of the worker.\n+    jax_mesh = layout.mesh\n+    mesh_rank = len(jax_mesh.shape)\n     per_process_batch_size = inputs.shape[0]\n-    num_local_replia = jax.local_device_count()\n-    per_replica_batch_size = per_process_batch_size // num_local_replia\n-\n+    if mesh_rank == 1:\n+        # This is data parallel mesh only. We will split the full data\n+        # across the batch dim.\n+        num_split = jax.local_device_count()\n+        per_replica_batch_size = per_process_batch_size // num_split\n         if per_process_batch_size % per_replica_batch_size != 0:\n             raise ValueError(\n                 f\"The local batch size {per_process_batch_size} is not\"\n-            \"divisible by the number of local replica \"\n-            f\"{num_local_replia}\"\n+                \"divisible by the number of local replicas \"\n+                f\"{num_split}\"\n             )\n         global_batch_size = per_process_batch_size * jax.process_count()\n-    global_shape = (global_batch_size,) + inputs.shape[1:]\n-    per_replica_batches = np.split(inputs, num_local_replia, axis=0)\n+        per_replica_batches = np.split(inputs, num_split, axis=0)\n+    elif mesh_rank == 2:\n+        # Data+Model parallel\n+        # In this case, we need to check if the mesh batch dim shape is large\n+        # than number of local devices, so that we can decide whether a split\n+        # is needed for the data, or a repeat/copy of the data is needed for\n+        # each of the device.\n+        # TODO(scottzhu): The mesh batch dim name is not available here, since\n+        # we only have jax Mesh. We assume the first dim is for batch, and\n+        # second dim is for model for now.\n+        mesh_batch_dim_size = list(jax_mesh.shape.values())[0]\n+        local_device_count = jax.local_device_count()\n+        if mesh_batch_dim_size < local_device_count:\n+            # No split needed, we only need to repeat here.\n+            global_batch_size = per_process_batch_size\n+            per_replica_batches = [inputs for _ in range(local_device_count)]\n+        else:\n+            # Note that global batch size is not simply per_process_batch_size *\n+            # num_process. It actually depends on the model dim size.\n+            global_batch_size = per_process_batch_size * (\n+                mesh_batch_dim_size // local_device_count\n+            )\n+            per_replica_batches = np.split(inputs, local_device_count, axis=0)\n+    else:\n+        raise ValueError(\n+            \"Only 1D or 2D mesh is supported at the moment. \"\n+            f\"Received mesh shape = {jax_mesh.shape}\"\n+        )\n \n+    global_shape = (global_batch_size,) + inputs.shape[1:]\n     global_batch_array = jax.make_array_from_single_device_arrays(\n         global_shape,\n         layout,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b7c0e045338b437a3214d7b94cc1b13b0f4f0401", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2735 | Contributors (this commit): 17 | Commits (past 90d): 4 | Contributors (cumulative): 17 | DMM Complexity: None\n\nDIFF:\n@@ -546,7 +546,7 @@ def index_directory(\n                         subdir = subdir[:-1]\n                     subdirs.append(subdir)\n         if class_names is not None:\n-            if set(class_names).issubset(set(subdirs)):\n+            if not set(class_names).issubset(set(subdirs)):\n                 raise ValueError(\n                     \"The `class_names` passed did not match the \"\n                     \"names of the subdirectories of the target directory. \"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bc4308ce1c0cbd322117ad90a5ce0ca710495913", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 102 | Lines Deleted: 102 | Files Changed: 102 | Hunks: 102 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 204 | Churn Cumulative: 55547 | Contributors (this commit): 32 | Commits (past 90d): 236 | Contributors (cumulative): 298 | DMM Complexity: None\n\nDIFF:\n@@ -21,7 +21,7 @@ from absl import flags\n from absl import logging\n from model_benchmark.benchmark_utils import BenchmarkMetricsCallback\n \n-import keras as keras\n+import keras\n \n flags.DEFINE_string(\"model_size\", \"small\", \"The size of model to benchmark.\")\n flags.DEFINE_string(\n\n@@ -27,7 +27,7 @@ from absl import flags\n from absl import logging\n from model_benchmark.benchmark_utils import BenchmarkMetricsCallback\n \n-import keras as keras\n+import keras\n \n flags.DEFINE_string(\"model\", \"EfficientNetV2B0\", \"The model to benchmark.\")\n flags.DEFINE_integer(\"epochs\", 1, \"The number of epochs.\")\n\n@@ -5,7 +5,7 @@ from keras import layers\n from keras import losses\n from keras import metrics\n from keras import optimizers\n-import keras as keras\n+import keras\n \n keras.config.disable_traceback_filtering()\n \n\n@@ -11,7 +11,7 @@ pp = pprint.PrettyPrinter()\n import jax\n import jax.numpy as jnp\n import tensorflow as tf  # just for tf.data\n-import keras as keras  # Keras multi-backend\n+import keras  # Keras multi-backend\n \n import numpy as np\n from tqdm import tqdm\n\n@@ -41,7 +41,7 @@ import os\n os.environ[\"KERAS_BACKEND\"] = \"jax\"\n \n import keras_nlp\n-import keras as keras\n+import keras\n \n import tensorflow.data as tf_data\n import tensorflow.strings as tf_strings\n\n@@ -42,7 +42,7 @@ with TensorFlow 2.3 or higher.\n import os\n os.environ['KERAS_BACKEND'] = 'tensorflow'\n \n-import keras as keras\n+import keras\n from keras import layers\n from keras import ops\n from keras.layers import TextVectorization\n\n@@ -46,7 +46,7 @@ Five digits (reversed):\n ## Setup\n \"\"\"\n \n-import keras as keras\n+import keras\n from keras import layers\n import numpy as np\n \n\n@@ -11,7 +11,7 @@ Accelerator: GPU\n \"\"\"\n \n import numpy as np\n-import keras as keras\n+import keras\n from keras import layers\n \n max_features = 20000  # Only consider the top 20k words\n\n@@ -29,7 +29,7 @@ import os\n os.environ[\"KERAS_BACKEND\"] = \"jax\"  # or \"tensorflow\" or \"torch\"\n \n import keras_nlp\n-import keras as keras\n+import keras\n import tensorflow as tf\n \n import numpy as np\n\n@@ -52,7 +52,7 @@ import keras_nlp\n import pathlib\n import random\n \n-import keras as keras\n+import keras\n from keras import ops\n \n import tensorflow.data as tf_data\n\n@@ -53,7 +53,7 @@ import numpy as np\n import tensorflow.data as tf_data\n import tensorflow.strings as tf_strings\n \n-import keras as keras\n+import keras\n from keras import layers\n from keras import ops\n from keras.layers import TextVectorization\n\n@@ -84,7 +84,7 @@ import nltk\n import random\n import logging\n \n-import keras as keras\n+import keras\n \n nltk.download(\"punkt\")\n # Set random seed\n\n@@ -46,7 +46,7 @@ import torch.nn.functional as F\n import torchvision\n from torchvision import datasets, models, transforms\n \n-import keras as keras\n+import keras\n from keras.layers import TorchModuleWrapper\n \n \"\"\"\n\n@@ -37,7 +37,7 @@ import matplotlib.pyplot as plt\n import numpy as np\n from zipfile import ZipFile\n \n-import keras as keras\n+import keras\n from keras import layers\n from keras import ops\n \n\n@@ -33,7 +33,7 @@ and 9 categorical features.\n ## Setup\n \"\"\"\n \n-import keras as keras\n+import keras\n from keras import layers\n from keras.layers import StringLookup\n from keras import ops\n\n@@ -21,7 +21,7 @@ into robust contextual embeddings to achieve higher predictive accuracy.\n \n ## Setup\n \"\"\"\n-import keras as keras\n+import keras\n from keras import layers\n from keras import ops\n \n\n@@ -47,7 +47,7 @@ import shutil\n import numpy as np\n \n import tensorflow as tf\n-import keras as keras\n+import keras\n \n from pathlib import Path\n from IPython.display import display, Audio\n\n@@ -108,7 +108,7 @@ import pandas as pd\n import tensorflow as tf\n import tensorflow_hub as hub\n import tensorflow_io as tfio\n-import keras as keras\n+import keras\n import matplotlib.pyplot as plt\n import seaborn as sns\n from scipy import stats\n\n@@ -27,7 +27,7 @@ using cycle-consistent adversarial networks.\n \n import numpy as np\n import matplotlib.pyplot as plt\n-import keras as keras\n+import keras\n from keras import layers\n from keras import ops\n \n\n@@ -11,7 +11,7 @@ Accelerator: GPU\n \"\"\"\n \n import tensorflow as tf\n-import keras as keras\n+import keras\n from keras import layers\n import matplotlib.pyplot as plt\n import os\n\n@@ -72,7 +72,7 @@ import matplotlib.pyplot as plt\n import tensorflow as tf\n import tensorflow_datasets as tfds\n \n-import keras as keras\n+import keras\n from keras import layers\n from keras import ops\n \n\n@@ -90,7 +90,7 @@ import matplotlib.pyplot as plt\n \n # Requires TensorFlow >=2.11 for the GroupNormalization layer.\n import tensorflow as tf\n-import keras as keras\n+import keras\n from keras import layers\n import tensorflow_datasets as tfds\n \n\n@@ -38,7 +38,7 @@ and compare the result to the (resized) original image.\n \n import numpy as np\n import tensorflow as tf\n-import keras as keras\n+import keras\n from keras.applications import inception_v3\n \n base_image_path = keras.utils.get_file(\n\n@@ -25,7 +25,7 @@ has at least ~100k characters. ~1M is better.\n \"\"\"\n ## Setup\n \"\"\"\n-import keras as keras\n+import keras\n from keras import layers\n \n import numpy as np\n\n@@ -40,7 +40,7 @@ keeping the generated image close enough to the original one.\n \n import numpy as np\n import tensorflow as tf\n-import keras as keras\n+import keras\n from keras.applications import vgg19\n \n base_image_path = keras.utils.get_file(\n\n@@ -13,7 +13,7 @@ Accelerator: GPU\n \n import numpy as np\n import tensorflow as tf\n-import keras as keras\n+import keras\n from keras import layers\n \n \"\"\"\n\n@@ -30,7 +30,7 @@ that keeps the L2 norm of the discriminator gradients close to 1.\n \"\"\"\n \n import tensorflow as tf\n-import keras as keras\n+import keras\n from keras import layers\n \n \n\n@@ -23,7 +23,7 @@ features back to a space of the original size.\n \"\"\"\n \n import tensorflow as tf\n-import keras as keras\n+import keras\n from keras import layers\n \n \"\"\"\n\n@@ -12,7 +12,7 @@ Accelerator: GPU\n \"\"\"\n \n import tensorflow as tf\n-import keras as keras\n+import keras\n import numpy as np\n \n \"\"\"\n\n@@ -27,7 +27,7 @@ Using this approach, we can quickly implement a\n [StandardizedConv2D](https://arxiv.org/abs/1903.10520) as shown below.\n \"\"\"\n import tensorflow as tf\n-import keras as keras\n+import keras\n from keras import layers\n import numpy as np\n \n\n@@ -29,7 +29,7 @@ TensorFlow NumPy requires TensorFlow 2.5 or later.\n \n import tensorflow as tf\n import tensorflow.experimental.numpy as tnp\n-import keras as keras\n+import keras\n from keras import layers\n \n \"\"\"\n\n@@ -60,7 +60,7 @@ import shutil\n import requests\n import numpy as np\n import tensorflow as tf\n-import keras as keras\n+import keras\n import matplotlib.pyplot as plt\n \n \"\"\"\n\n@@ -25,7 +25,7 @@ by putting the custom training step in the Trainer class definition.\n \"\"\"\n \n import tensorflow as tf\n-import keras as keras\n+import keras\n \n # Load MNIST dataset and standardize the data\n mnist = keras.datasets.mnist\n\n@@ -50,7 +50,7 @@ from pathlib import Path\n from dataclasses import dataclass\n \n import tensorflow as tf\n-import keras as keras\n+import keras\n from keras import layers\n \n \"\"\"\n\n@@ -47,7 +47,7 @@ models are more common in this domain.\n \"\"\"\n \n import numpy as np\n-import keras as keras\n+import keras\n import os\n from pathlib import Path\n \n\n@@ -34,7 +34,7 @@ wget https://raw.githubusercontent.com/sighsmile/conlleval/master/conlleval.py\n \n import os\n import numpy as np\n-import keras as keras\n+import keras\n from keras import layers\n from datasets import load_dataset\n from collections import Counter\n\n@@ -13,7 +13,7 @@ Accelerator: GPU\n \n import numpy as np\n import tensorflow.data as tf_data\n-import keras as keras\n+import keras\n \n \"\"\"\n ## Introduction\n\n@@ -20,7 +20,7 @@ classification dataset (unprocessed version). We use the `TextVectorization` lay\n \"\"\"\n \n import tensorflow as tf\n-import keras as keras\n+import keras\n from keras.layers import TextVectorization\n from keras import layers\n import string\n\n@@ -44,7 +44,7 @@ import os\n \n os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n \n-import keras as keras\n+import keras\n from keras import layers\n \n import gym\n\n@@ -20,7 +20,7 @@ to train a classification model on data with highly imbalanced classes.\n \"\"\"\n \n import numpy as np\n-import keras as keras\n+import keras\n \n # Get the real data from https://www.kaggle.com/mlg-ulb/creditcardfraud/\n fname = \"/Users/fchollet/Downloads/creditcard.csv\"\n\n@@ -51,7 +51,7 @@ Target | Diagnosis of heart disease (1 = true; 0 = false) | Target\n \n import tensorflow as tf\n import pandas as pd\n-import keras as keras\n+import keras\n from keras import layers\n \n \"\"\"\n\n@@ -61,7 +61,7 @@ Target | Diagnosis of heart disease (1 = true; 0 = false) | Target\n \n import tensorflow as tf\n import pandas as pd\n-import keras as keras\n+import keras\n from keras.utils import FeatureSpace\n \n keras.config.disable_traceback_filtering()\n\n@@ -65,7 +65,7 @@ import pandas as pd\n import matplotlib.pyplot as plt\n import json\n import numpy as np\n-import keras as keras\n+import keras\n from keras import layers\n import tensorflow as tf\n from sklearn import preprocessing, model_selection\n\n@@ -47,7 +47,7 @@ import typing\n import matplotlib.pyplot as plt\n \n import tensorflow as tf\n-import keras as keras\n+import keras\n from keras import layers\n from keras.utils import timeseries_dataset_from_array\n \n\n@@ -14,7 +14,7 @@ This example requires TensorFlow 2.3 or higher.\n \n import pandas as pd\n import matplotlib.pyplot as plt\n-import keras as keras\n+import keras\n \n \"\"\"\n ## Climate Data Time-Series\n\n@@ -42,7 +42,7 @@ import os\n \n os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n \n-import keras as keras\n+import keras\n import numpy as np\n import matplotlib.pyplot as plt\n \n\n@@ -48,7 +48,7 @@ where `rx, ry` are randomly drawn from a uniform distribution with upper bound.\n \n import numpy as np\n import pandas as pd\n-import keras as keras\n+import keras\n import matplotlib.pyplot as plt\n \n from keras import layers\n\n@@ -49,7 +49,7 @@ os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n \n import tensorflow as tf\n import tensorflow_datasets as tfds\n-import keras as keras\n+import keras\n from keras import layers\n \n tfds.disable_progress_bar()\n\n@@ -13,7 +13,7 @@ Adapted from Deep Learning with Python (2017).\n \n import numpy as np\n import tensorflow as tf\n-import keras as keras\n+import keras\n \n # Display\n from IPython.display import Image, display\n\n@@ -17,7 +17,7 @@ import numpy as np\n import matplotlib.pyplot as plt\n \n import tensorflow as tf\n-import keras as keras\n+import keras\n from keras import layers\n from keras.applications import efficientnet\n from keras.layers import TextVectorization\n\n@@ -23,7 +23,7 @@ we use Keras image preprocessing layers for image standardization and data augme\n \"\"\"\n \n import tensorflow as tf\n-import keras as keras\n+import keras\n from keras import layers\n import os\n from pathlib import Path\n\n@@ -58,7 +58,7 @@ from scipy import ndimage\n from IPython.display import Image, display\n \n import tensorflow as tf\n-import keras as keras\n+import keras\n from keras import layers\n from keras.applications import xception\n \n\n@@ -36,7 +36,7 @@ layer.\n \"\"\"\n \n import tensorflow as tf\n-import keras as keras\n+import keras\n import matplotlib.pyplot as plt\n \n # Set seed for reproducibility.\n\n@@ -47,7 +47,7 @@ from glob import glob\n from PIL import Image, ImageOps\n import matplotlib.pyplot as plt\n \n-import keras as keras\n+import keras\n from keras import layers\n \n import tensorflow as tf\n\n@@ -37,7 +37,7 @@ processing, speech, and so on.\n \"\"\"\n \n import numpy as np\n-import keras as keras\n+import keras\n import matplotlib.pyplot as plt\n \n from keras import layers\n\n@@ -43,7 +43,7 @@ pip install -U tensorflow-addons\n \n import numpy as np\n import tensorflow as tf\n-import keras as keras\n+import keras\n from keras import layers\n \n \"\"\"\n\n@@ -22,7 +22,7 @@ import os\n \n os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n \n-import keras as keras\n+import keras\n from keras import layers\n \n import matplotlib.pyplot as plt\n\n@@ -77,7 +77,7 @@ import matplotlib.pyplot as plt\n import tensorflow as tf\n import tensorflow_datasets as tfds\n \n-import keras as keras\n+import keras\n from keras import layers\n \n \"\"\"\n\n@@ -40,7 +40,7 @@ import numpy as np\n import matplotlib.pyplot as plt\n \n import tensorflow as tf\n-import keras as keras\n+import keras\n from keras import layers\n \n \n\n@@ -51,7 +51,7 @@ os.environ['KERAS_BACKEND'] = 'tensorflow'\n \n from keras import layers\n from keras import regularizers\n-import keras as keras\n+import keras\n import tensorflow as tf\n \n import matplotlib.pyplot as plt\n\n@@ -29,7 +29,7 @@ This example requires TensorFlow 2.5 or higher.\n import matplotlib.pyplot as plt\n import numpy as np\n import tensorflow as tf\n-import keras as keras\n+import keras\n from keras import layers\n \n \"\"\"\n\n@@ -26,7 +26,7 @@ import os\n \n os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n \n-import keras as keras\n+import keras\n \n \n import numpy as np\n\n@@ -49,7 +49,7 @@ from glob import glob\n from PIL import Image, ImageOps\n import matplotlib.pyplot as plt\n \n-import keras as keras\n+import keras\n from keras import layers\n \n import tensorflow as tf\n\n@@ -20,7 +20,7 @@ autoencoder model to detect anomalies in timeseries data.\n \n import numpy as np\n import pandas as pd\n-import keras as keras\n+import keras\n from keras import layers\n from matplotlib import pyplot as plt\n \n\n@@ -19,7 +19,7 @@ CSV timeseries files on disk. We demonstrate the workflow on the FordA dataset f\n ## Setup\n \n \"\"\"\n-import keras as keras\n+import keras\n import numpy as np\n import matplotlib.pyplot as plt\n \n\n@@ -62,7 +62,7 @@ You can replace your classification RNN layers with this one: the\n inputs are fully compatible!\n \"\"\"\n \n-import keras as keras\n+import keras\n from keras import layers\n \n \"\"\"\n\n@@ -54,7 +54,7 @@ by TensorFlow.\n \"\"\"\n \n import numpy as np\n-import keras as keras\n+import keras\n from keras import layers\n from keras import ops\n from tqdm import tqdm\n\n@@ -40,7 +40,7 @@ code snippets from another example,\n \"\"\"\n \n from keras import layers\n-import keras as keras\n+import keras\n \n import matplotlib.pyplot as plt\n import numpy as np\n\n@@ -25,7 +25,7 @@ of predicting what video frames come next given a series of past frames.\n import numpy as np\n import matplotlib.pyplot as plt\n \n-import keras as keras\n+import keras\n from keras import layers\n \n import io\n\n@@ -32,7 +32,7 @@ This dataset can be used for the \"human part segmentation\" task.\n \"\"\"\n \n \n-import keras as keras\n+import keras\n from keras import layers\n from keras import ops\n \n\n@@ -25,7 +25,7 @@ implicitly considers the correlations between all samples.\n ## Setup\n \"\"\"\n \n-import keras as keras\n+import keras\n from keras import layers\n from keras import ops\n \n\n@@ -27,7 +27,7 @@ to fix this discrepancy.\n ## Imports\n \"\"\"\n \n-import keras as keras\n+import keras\n from keras import layers\n import tensorflow as tf  # just for image processing and pipeline\n \n\n@@ -34,7 +34,7 @@ pip install tensorflow-datasets\n \n from time import time\n \n-import keras as keras\n+import keras\n from keras import layers\n from keras.optimizers import RMSprop\n from keras import ops\n\n@@ -27,7 +27,7 @@ import os\n \n os.environ[\"KERAS_BACKEND\"] = \"jax\"  # @param [\"tensorflow\", \"jax\", \"torch\"]\n \n-import keras as keras\n+import keras\n from keras import layers\n from keras import ops\n \n\n@@ -42,7 +42,7 @@ os.environ[\"KERAS_BACKEND\"] = \"jax\"\n import json\n import math\n import keras_cv\n-import keras as keras\n+import keras\n from keras import ops\n from keras import losses\n from keras import optimizers\n\n@@ -58,7 +58,7 @@ unzip -qq ~/stanfordextra_v12.zip\n ## Imports\n \"\"\"\n from keras import layers\n-import keras as keras\n+import keras\n \n from imgaug.augmentables.kps import KeypointsOnImage\n from imgaug.augmentables.kps import Keypoint\n\n@@ -40,7 +40,7 @@ using the [DenseNet-121](https://arxiv.org/abs/1608.06993) architecture.\n \"\"\"\n \n from keras import layers\n-import keras as keras\n+import keras\n from keras import ops\n \n from tensorflow import data as tf_data\n\n@@ -29,7 +29,7 @@ main building blocks.\n \"\"\"\n \n import numpy as np\n-import keras as keras\n+import keras\n from keras import layers\n \n \"\"\"\n\n@@ -12,7 +12,7 @@ Accelerator: GPU\n \"\"\"\n \n import numpy as np\n-import keras as keras\n+import keras\n from keras import layers\n \n \"\"\"\n\n@@ -43,7 +43,7 @@ os.environ[\"KERAS_BACKEND\"] = \"jax\"  # @param [\"tensorflow\", \"jax\", \"torch\"]\n \n \n import numpy as np\n-import keras as keras\n+import keras\n from keras import layers\n from keras import ops\n import matplotlib.pyplot as plt\n\n@@ -72,7 +72,7 @@ display(img)\n ## Prepare dataset to load & vectorize batches of data\n \"\"\"\n \n-import keras as keras\n+import keras\n import numpy as np\n from tensorflow import data as tf_data\n from tensorflow import image as tf_image\n\n@@ -26,7 +26,7 @@ the class segmentation of the training inputs.\n \n import random\n import numpy as np\n-import keras as keras\n+import keras\n from keras import ops\n import matplotlib.pyplot as plt\n \n\n@@ -26,7 +26,7 @@ dataset,\n ## Setup\n \"\"\"\n \n-import keras as keras\n+import keras\n from keras import layers\n from keras import ops\n from keras.utils import load_img\n\n@@ -49,7 +49,7 @@ references:\n ## Imports\n \"\"\"\n \n-import keras as keras\n+import keras\n from keras import layers\n from keras import ops\n from tensorflow import data as tf_data\n\n@@ -47,7 +47,7 @@ import os\n \n os.environ[\"KERAS_BACKEND\"] = \"jax\"  # @param [\"tensorflow\", \"jax\", \"torch\"]\n \n-import keras as keras\n+import keras\n from keras import layers\n from keras.applications.densenet import DenseNet121\n \n\n@@ -48,7 +48,7 @@ import os\n os.environ[\"KERAS_BACKEND\"] = \"jax\"\n \n import jax\n-import keras as keras\n+import keras\n import numpy as np\n \n \"\"\"\n\n@@ -48,7 +48,7 @@ import os\n os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n \n import tensorflow as tf\n-import keras as keras\n+import keras\n from keras import layers\n import numpy as np\n \n\n@@ -48,7 +48,7 @@ import os\n os.environ[\"KERAS_BACKEND\"] = \"torch\"\n \n import torch\n-import keras as keras\n+import keras\n from keras import layers\n import numpy as np\n \n\n@@ -46,7 +46,7 @@ os.environ[\"KERAS_BACKEND\"] = \"jax\"\n import jax\n import numpy as np\n import tensorflow as tf\n-import keras as keras\n+import keras\n \n from jax.experimental import mesh_utils\n from jax.sharding import Mesh\n\n@@ -42,7 +42,7 @@ import os\n os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n \n import tensorflow as tf\n-import keras as keras\n+import keras\n \n \"\"\"\n ## Single-host, multi-device synchronous training\n\n@@ -46,7 +46,7 @@ os.environ[\"KERAS_BACKEND\"] = \"torch\"\n \n import torch\n import numpy as np\n-import keras as keras\n+import keras\n \n \n def get_model():\n\n@@ -11,7 +11,7 @@ Accelerator: GPU\n \"\"\"\n \n import numpy as np\n-import keras as keras\n+import keras\n from keras import layers\n from keras import ops\n \n\n@@ -29,7 +29,7 @@ Let's dive in.\n \"\"\"\n \n import numpy as np\n-import keras as keras\n+import keras\n from keras import ops\n from keras import layers\n \n\n@@ -11,7 +11,7 @@ Accelerator: GPU\n \n \"\"\"\n \n-import keras as keras\n+import keras\n from keras import layers\n from keras import ops\n \n\n@@ -17,7 +17,7 @@ import tensorflow as tf\n \n import os\n import numpy as np\n-import keras as keras\n+import keras\n from keras import layers\n from keras import ops\n \n\n@@ -11,7 +11,7 @@ Accelerator: GPU\n \"\"\"\n \n import numpy as np\n-import keras as keras\n+import keras\n from keras import layers\n import tensorflow_datasets as tfds\n import matplotlib.pyplot as plt\n\n@@ -10,7 +10,7 @@ Accelerator: None\n ## Setup\n \"\"\"\n import numpy as np\n-import keras as keras\n+import keras\n from keras import ops\n from keras import layers\n \n\n@@ -19,7 +19,7 @@ import jax\n \n # We import TF so we can use tf.data.\n import tensorflow as tf\n-import keras as keras\n+import keras\n import numpy as np\n \n \"\"\"\n\n@@ -17,7 +17,7 @@ import os\n os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n \n import tensorflow as tf\n-import keras as keras\n+import keras\n import numpy as np\n \n \"\"\"\n\n@@ -16,7 +16,7 @@ import os\n os.environ[\"KERAS_BACKEND\"] = \"torch\"\n \n import torch\n-import keras as keras\n+import keras\n import numpy as np\n \n \"\"\"\n\n@@ -24,7 +24,7 @@ started.\n \"\"\"\n \n import numpy as np\n-import keras as keras\n+import keras\n \n \"\"\"\n ## Keras callbacks overview\n\n@@ -2,7 +2,7 @@ import numpy as np\n import pytest\n from absl.testing import parameterized\n \n-import keras as keras\n+import keras\n from keras import testing\n from keras.applications import imagenet_utils as utils\n from keras.mixed_precision import set_dtype_policy\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
