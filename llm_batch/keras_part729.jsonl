{"custom_id": "keras#21bd0b87c8108102e6b2ea7867b01d940e9ea6f1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 207 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 9 | Methods Changed: 22 | Complexity Δ (Sum/Max): 23/15 | Churn Δ: 212 | Churn Cumulative: 462 | Contributors (this commit): 6 | Commits (past 90d): 7 | Contributors (cumulative): 10 | DMM Complexity: 1.0\n\nDIFF:\n@@ -99,3 +99,104 @@ class TestTFDatasetAdapter(testing.TestCase):\n         self.assertEqual(cardinality, tf.data.UNKNOWN_CARDINALITY)\n         adapter = tf_dataset_adapter.TFDatasetAdapter(dataset)\n         self.assertIsNone(adapter.num_batches)\n+\n+    def test_invalid_dataset_type(self):\n+        with self.assertRaisesRegex(\n+            ValueError, \"Expected argument `dataset` to be a tf.data.Dataset\"\n+        ):\n+            invalid_data = \"This is not a tf.data.Dataset\"\n+            tf_dataset_adapter.TFDatasetAdapter(invalid_data)\n+\n+    def test_class_weight_and_sample_weight_together(self):\n+        x = np.random.random((4, 2))\n+        y = np.array([[0], [1], [2], [3]], dtype=\"int64\")\n+        sw = np.array([0.5, 0.5, 0.5, 0.5])\n+        base_ds = tf.data.Dataset.from_tensor_slices((x, y, sw)).batch(16)\n+        class_weight = {0: 0.1, 1: 0.2, 2: 0.3, 3: 0.4}\n+\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"You cannot `class_weight` and `sample_weight` at the same time.\",\n+        ):\n+            tf_dataset_adapter.TFDatasetAdapter(\n+                base_ds, class_weight=class_weight\n+            )\n+\n+    def test_different_y_shapes_with_class_weight(self):\n+        x = np.random.random((4, 2))\n+        y = np.array(\n+            [[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]],\n+            dtype=\"float32\",\n+        )\n+        base_ds = tf.data.Dataset.from_tensor_slices((x, y)).batch(16)\n+        class_weight = {0: 0.1, 1: 0.2, 2: 0.3, 3: 0.4}\n+        adapter = tf_dataset_adapter.TFDatasetAdapter(\n+            base_ds, class_weight=class_weight\n+        )\n+        gen = adapter.get_numpy_iterator()\n+        for batch in gen:\n+            _, _, bw = batch\n+            self.assertAllClose(bw, [0.1, 0.2, 0.3, 0.4])\n+\n+        y_sparse = np.array([0, 1, 2, 3], dtype=\"int64\")\n+        base_ds = tf.data.Dataset.from_tensor_slices((x, y_sparse)).batch(16)\n+        adapter = tf_dataset_adapter.TFDatasetAdapter(\n+            base_ds, class_weight=class_weight\n+        )\n+        gen = adapter.get_numpy_iterator()\n+        for batch in gen:\n+            _, _, bw = batch\n+            self.assertAllClose(bw, [0.1, 0.2, 0.3, 0.4])\n+\n+    def test_nested_y_with_class_weight(self):\n+        x = np.random.random((4, 2))\n+\n+        # Define two target outputs, y1 and y2, for the dataset\n+        y1 = np.array([0, 1, 2, 3], dtype=\"int64\")\n+        y2 = np.array([0, 1, 2, 3], dtype=\"int64\")\n+\n+        # Create a tf.data Dataset from the input data and two target outputs\n+        base_ds = tf.data.Dataset.from_tensor_slices((x, (y1, y2))).batch(16)\n+\n+        # Define class weights for potential classes in the output\n+        class_weight = {0: 0.1, 1: 0.2, 2: 0.3, 3: 0.4}\n+\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"`class_weight` is only supported for Models with a single output.\",\n+        ):\n+            tf_dataset_adapter.TFDatasetAdapter(\n+                base_ds, class_weight=class_weight\n+            )\n+\n+    def test_class_weights_map_fn_with_sample_weight(self):\n+        class_weight = {0: 0.1, 1: 0.2, 2: 0.3, 3: 0.4}\n+        class_weights_map_fn = tf_dataset_adapter.make_class_weight_map_fn(\n+            class_weight\n+        )\n+\n+        x = np.array([[0.5, 0.5], [0.5, 0.5]])\n+        y = np.array([[1, 0], [0, 1]])\n+        sw = np.array([1.0, 1.0])\n+\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"You cannot `class_weight` and `sample_weight` at the same time.\",\n+        ):\n+            class_weights_map_fn(x, y, sw)\n+\n+    def test_class_weights_map_fn_nested_y(self):\n+        class_weight = {0: 0.1, 1: 0.2, 2: 0.3, 3: 0.4}\n+        class_weights_map_fn = tf_dataset_adapter.make_class_weight_map_fn(\n+            class_weight\n+        )\n+\n+        x = np.array([[0.5, 0.5]])\n+        y1 = np.array([1])\n+        y2 = np.array([0])\n+\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"`class_weight` is only supported for Models with a single output.\",\n+        ):\n+            class_weights_map_fn(x, (y1, y2))\n\n@@ -14,7 +14,6 @@ class TestEpochIterator(testing.TestCase):\n         sample_weight = np.random.random((100,))\n         batch_size = 16\n         shuffle = True\n-\n         iterator = epoch_iterator.EpochIterator(\n             x=x,\n             y=y,\n@@ -43,24 +42,36 @@ class TestEpochIterator(testing.TestCase):\n         batch_size = 8\n         steps_per_epoch = 6\n         dataset_size = batch_size * (steps_per_epoch - 2)\n-\n         x = np.arange(dataset_size).reshape((dataset_size, 1))\n         y = x * 2\n-\n         iterator = epoch_iterator.EpochIterator(\n             x=x,\n             y=y,\n             batch_size=batch_size,\n             steps_per_epoch=steps_per_epoch,\n         )\n-\n         steps_seen = []\n         for step, _ in iterator.enumerate_epoch():\n             steps_seen.append(step)\n-\n         self.assertLen(steps_seen, steps_per_epoch - 2)\n+\n+        self.assertIsInstance(iterator, epoch_iterator.EpochIterator)\n         self.assertTrue(iterator._insufficient_data)\n \n+    def test_unsupported_y_arg_tfdata(self):\n+        with self.assertRaisesRegex(ValueError, \"`y` should not be passed\"):\n+            x = tf.data.Dataset.from_tensor_slices(np.random.random((100, 16)))\n+            y = np.random.random((100, 4))\n+            _ = epoch_iterator.EpochIterator(x=x, y=y)\n+\n+    def test_unsupported_sample_weights_arg_tfdata(self):\n+        with self.assertRaisesRegex(\n+            ValueError, \"`sample_weights` should not be passed\"\n+        ):\n+            x = tf.data.Dataset.from_tensor_slices(np.random.random((100, 16)))\n+            sample_weights = np.random.random((100,))\n+            _ = epoch_iterator.EpochIterator(x=x, sample_weight=sample_weights)\n+\n     @pytest.mark.skipif(\n         backend.backend() != \"torch\", reason=\"Need to import torch\"\n     )\n@@ -89,3 +100,93 @@ class TestEpochIterator(testing.TestCase):\n             batch = batch[0]\n             self.assertEqual(batch[0].shape, (8, 2))\n             self.assertEqual(batch[1].shape, (8, 1))\n+\n+    @pytest.mark.skipif(\n+        backend.backend() != \"torch\", reason=\"Need to import torch\"\n+    )\n+    def test_unsupported_y_arg_torch_dataloader(self):\n+        import torch\n+\n+        class ExampleTorchDataset(torch.utils.data.Dataset):\n+            def __init__(self, x, y):\n+                self.x = x\n+                self.y = y\n+\n+            def __len__(self):\n+                return len(self.x)\n+\n+            def __getitem__(self, idx):\n+                return self.x[idx], self.y[idx]\n+\n+        torch_dataset = ExampleTorchDataset(\n+            np.random.random((100, 16)), np.random.random((100, 4))\n+        )\n+        x = torch.utils.data.DataLoader(\n+            torch_dataset, batch_size=8, shuffle=True\n+        )\n+        y = np.random.random((100, 4))\n+\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"When providing `x` as a torch DataLoader, `y` should not\",\n+        ):\n+            _ = epoch_iterator.EpochIterator(x=x, y=y)\n+\n+    @pytest.mark.skipif(\n+        backend.backend() != \"torch\", reason=\"Need to import torch\"\n+    )\n+    def test_unsupported_sample_weights_arg_torch_dataloader(self):\n+        import torch\n+\n+        class ExampleTorchDataset(torch.utils.data.Dataset):\n+            def __init__(self, x, y):\n+                self.x = x\n+                self.y = y\n+\n+            def __len__(self):\n+                return len(self.x)\n+\n+            def __getitem__(self, idx):\n+                return self.x[idx], self.y[idx]\n+\n+        torch_dataset = ExampleTorchDataset(\n+            np.random.random((100, 16)), np.random.random((100, 4))\n+        )\n+        x = torch.utils.data.DataLoader(\n+            torch_dataset, batch_size=8, shuffle=True\n+        )\n+        sample_weights = np.random.random((100,))\n+\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"When providing `x` as a torch DataLoader, `sample_weights`\",\n+        ):\n+            _ = epoch_iterator.EpochIterator(x=x, sample_weight=sample_weights)\n+\n+    def test_python_generator_input(self):\n+        def generator_example():\n+            for i in range(100):\n+                yield (np.array([i]), np.array([i * 2]))\n+\n+        x = generator_example()\n+        epoch_iter = epoch_iterator.EpochIterator(x=x)\n+        self.assertIsInstance(\n+            epoch_iter.data_adapter,\n+            epoch_iterator.generator_data_adapter.GeneratorDataAdapter,\n+        )\n+\n+    def test_unrecognized_data_type(self):\n+        x = \"unsupported_data\"\n+        with self.assertRaisesRegex(ValueError, \"Unrecognized data type\"):\n+            _ = epoch_iterator.EpochIterator(x=x)\n+\n+    def test_invalid_return_type_in_get_iterator(self):\n+        x = np.random.random((100, 16))\n+        y = np.random.random((100, 4))\n+        epoch_iter = epoch_iterator.EpochIterator(x=x, y=y)\n+\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"Argument `return_type` must be one of `{'np', 'tf'}`\",\n+        ):\n+            _ = epoch_iter._get_iterator(\"unsupported\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bd465a78e6e14b129e14eafb27e7fb397cdfbb54", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 1770 | Contributors (this commit): 3 | Commits (past 90d): 4 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -62,6 +62,7 @@ ATTR_SKIPLIST = frozenset(\n         \"_callable_losses\",\n         \"_captured_weight_regularizer\",\n         \"_checkpoint_dependencies\",\n+        \"_layer_checkpoint_dependencies\",\n         \"_deferred_dependencies\",\n         \"_eager_losses\",\n         \"_inbound_nodes\",\n@@ -71,7 +72,6 @@ ATTR_SKIPLIST = frozenset(\n         \"_keras_api_names\",\n         \"_keras_api_names_v1\",\n         \"_name_based_restores\",\n-        \"_non_trainable_weights\",\n         \"_outbound_nodes\",\n         \"_outbound_nodes_value\",\n         \"_saved_model_arg_spec\",\n@@ -364,7 +364,7 @@ def _write_to_zip_recursively(zipfile_to_save, system_path, zip_path):\n \n \n def _walk_trackable(trackable):\n-    for child_attr in dir(trackable):\n+    for child_attr in sorted(dir(trackable), reverse=True):\n         if child_attr.startswith(\"__\") or child_attr in ATTR_SKIPLIST:\n             continue\n         try:\n\n@@ -749,7 +749,7 @@ class SavingV3Test(tf.test.TestCase, parameterized.TestCase):\n         model.save_weights(weights_filepath)\n         with h5py.File(weights_filepath, \"r\") as f:\n             self.assertAllEqual(\n-                list(f[\"_layer_checkpoint_dependencies\"].keys()),\n+                list(f[\"layers\"].keys()),\n                 [\"dense\", \"dense_1\", \"dense_2\", \"dense_3\"],\n             )\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d279ecebb5ff4e264eb020ef90a293456d5ce8e7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 60 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 5/3 | Churn Δ: 62 | Churn Cumulative: 1337 | Contributors (this commit): 7 | Commits (past 90d): 11 | Contributors (cumulative): 8 | DMM Complexity: 0.625\n\nDIFF:\n@@ -308,8 +308,19 @@ def print_summary(\n     non_trainable_count = count_params(model.non_trainable_weights)\n     non_trainable_memory_size = weight_memory_size(model.non_trainable_weights)\n \n-    total_count = trainable_count + non_trainable_count\n-    total_memory_size = trainable_memory_size + non_trainable_memory_size\n+    if model.compiled and model.optimizer.built:\n+        optimizer_weight_count = count_params(model.optimizer.variables)\n+        optimizer_memory_size = weight_memory_size(model.optimizer.variables)\n+    else:\n+        optimizer_weight_count = 0\n+        optimizer_memory_size = 0\n+\n+    total_count = trainable_count + non_trainable_count + optimizer_weight_count\n+    total_memory_size = (\n+        trainable_memory_size\n+        + non_trainable_memory_size\n+        + optimizer_memory_size\n+    )\n \n     # Create a rich console for printing. Capture for non-interactive logging.\n     if print_fn:\n@@ -338,6 +349,11 @@ def print_summary(\n         + highlight_number(f\"{non_trainable_count:,}\")\n         + f\" ({readable_memory_size(non_trainable_memory_size)})\"\n     )\n+    console.print(\n+        bold_text(\" Optimizer params: \")\n+        + highlight_number(f\"{optimizer_weight_count:,}\")\n+        + f\" ({readable_memory_size(optimizer_memory_size)})\"\n+    )\n \n     # Output captured summary for non-interactive logging.\n     if print_fn:\n\n@@ -0,0 +1,42 @@\n+import os\n+\n+import numpy as np\n+import pytest\n+\n+from keras_core import layers\n+from keras_core import models\n+from keras_core import testing\n+from keras_core.utils import summary_utils\n+\n+\n+class SummaryUtilsTest(testing.TestCase):\n+    @pytest.mark.requires_trainable_backend\n+    def test_print_model_summary(self):\n+        inputs = layers.Input((2,))\n+        outputs = layers.Dense(3)(inputs)\n+        model = models.Model(inputs, outputs)\n+        model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mse\"])\n+        # Trigger the optimizer weights creation\n+        model.fit(x=np.zeros([4, 2]), y=np.zeros([4, 3]))\n+\n+        file_name = \"model_1.txt\"\n+        temp_dir = self.get_temp_dir()\n+        fpath = os.path.join(temp_dir, file_name)\n+        writer = open(fpath, \"w\")\n+\n+        def print_to_file(text, line_break=False):\n+            print(text, file=writer)\n+\n+        try:\n+            summary_utils.print_summary(model, print_fn=print_to_file)\n+            writer.close()\n+            self.assertTrue(os.path.exists(fpath))\n+            with open(fpath, \"r\") as reader:\n+                summary_content = reader.read()\n+            # self.assertEqual(len(lines), 15)\n+            self.assertIn(\"Total params: 29\", summary_content)\n+            self.assertIn(\"Trainable params: 9\", summary_content)\n+            self.assertIn(\"Non-trainable params: 0\", summary_content)\n+            self.assertIn(\"Optimizer params: 20\", summary_content)\n+        except ImportError:\n+            pass\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4f2c626f4541befdf26a55661cae3e2caaf20bec", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 268 | Lines Deleted: 30 | Files Changed: 7 | Hunks: 38 | Methods Changed: 20 | Complexity Δ (Sum/Max): 18/5 | Churn Δ: 298 | Churn Cumulative: 2704 | Contributors (this commit): 22 | Commits (past 90d): 59 | Contributors (cumulative): 46 | DMM Complexity: 0.869281045751634\n\nDIFF:\n@@ -1,3 +1,5 @@\n+import warnings\n+\n import tensorflow as tf\n from tensorflow.experimental import numpy as tfnp\n \n@@ -40,6 +42,22 @@ def subtract(x1, x2):\n \n \n def matmul(x1, x2):\n+    if isinstance(x1, tf.SparseTensor):\n+        # We need at least one id per rows for embedding_lookup_sparse,\n+        # otherwise there will be missing rows in the output.\n+        x1, _ = tf.sparse.fill_empty_rows(x1, 0)\n+        # We need to split x1 into separate ids and weights tensors. The ids\n+        # should be the column indices of x1 and the values of the weights\n+        # can continue to be the actual x1. The column arrangement of ids and\n+        # weights does not matter as we sum over columns. See documentation for\n+        # sparse_ops.sparse_tensor_dense_matmul for details.\n+        ids = tf.SparseTensor(\n+            indices=x1.indices,\n+            values=x1.indices[:, 1],\n+            dense_shape=x1.dense_shape,\n+        )\n+        weights = x1\n+        return tf.nn.embedding_lookup_sparse(x2, ids, weights, combiner=\"sum\")\n     return tfnp.matmul(x1, x2)\n \n \n@@ -550,6 +568,28 @@ def swapaxes(x, axis1, axis2):\n \n \n def take(x, indices, axis=None):\n+    if isinstance(indices, tf.SparseTensor):\n+        if x.dtype not in (tf.float16, tf.float32, tf.float64, tf.bfloat16):\n+            warnings.warn(\n+                \"`take` with the TensorFlow backend does not support \"\n+                f\"`x.dtype={x.dtype}` when `indices` is a sparse tensor; \"\n+                \"densifying `indices`.\"\n+            )\n+            return tfnp.take(x, tf.sparse.to_dense(indices), axis=axis)\n+        if axis is None:\n+            x = tf.reshape(x, (-1,))\n+        elif axis != 0:\n+            warnings.warn(\n+                \"`take` with the TensorFlow backend does not support \"\n+                f\"`axis={axis}` when `indices` is a sparse tensor; \"\n+                \"densifying `indices`.\"\n+            )\n+            return tfnp.take(x, tf.sparse.to_dense(indices), axis=axis)\n+        return tf.nn.safe_embedding_lookup_sparse(\n+            embedding_weights=x,\n+            sparse_ids=tf.sparse.expand_dims(indices, axis=-1),\n+            default_id=0,\n+        )\n     return tfnp.take(x, indices, axis=axis)\n \n \n\n@@ -1,6 +1,7 @@\n import numpy as np\n import pytest\n \n+from keras_core import backend\n from keras_core import layers\n from keras_core import testing\n from keras_core.backend.common import keras_tensor\n@@ -64,3 +65,45 @@ class DenseTest(testing.TestCase):\n             layer = layers.Dense(units=2, activation=\"relu\")\n             layer(keras_tensor.KerasTensor((1, 2)))\n             layer(keras_tensor.KerasTensor((1, 3)))\n+\n+    @pytest.mark.skipif(\n+        not backend.SUPPORTS_SPARSE_TENSORS,\n+        reason=\"Backend does not support sparse tensors.\",\n+    )\n+    def test_dense_sparse(self):\n+        import tensorflow as tf\n+\n+        self.run_layer_test(\n+            layers.Dense,\n+            init_kwargs={\n+                \"units\": 4,\n+            },\n+            input_shape=(2, 3),\n+            input_sparse=True,\n+            expected_output_shape=(2, 4),\n+            expected_num_trainable_weights=2,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_seed_generators=0,\n+            expected_num_losses=0,\n+        )\n+\n+        inputs = 4 * backend.random.uniform((10, 10))\n+        inputs = tf.sparse.from_dense(tf.nn.dropout(inputs, 0.8))\n+\n+        layer = layers.Dense(units=5)\n+        outputs = layer(inputs)\n+\n+        # Verify the computation is the same as if it had been a dense tensor\n+        expected_outputs = tf.add(\n+            tf.matmul(tf.sparse.to_dense(inputs), layer.kernel),\n+            layer.bias,\n+        )\n+        self.assertAllClose(outputs, expected_outputs)\n+\n+        # Verify the gradient is sparse\n+        with tf.GradientTape() as g:\n+            outputs = layer(inputs)\n+\n+        self.assertIsInstance(\n+            g.gradient(outputs, layer.kernel), tf.IndexedSlices\n+        )\n\n@@ -1,6 +1,7 @@\n import numpy as np\n import pytest\n \n+from keras_core import backend\n from keras_core import layers\n from keras_core.testing import test_case\n \n@@ -33,13 +34,55 @@ class EmbeddingTest(test_case.TestCase):\n             supports_masking=True,\n         )\n \n+    @pytest.mark.skipif(\n+        not backend.SUPPORTS_SPARSE_TENSORS,\n+        reason=\"Backend does not support sparse tensors.\",\n+    )\n+    def test_sparse(self):\n+        self.run_layer_test(\n+            layers.Embedding,\n+            {\"input_dim\": 5, \"output_dim\": 4},\n+            input_shape=(2, 3),\n+            input_dtype=\"int32\",\n+            input_sparse=True,\n+            expected_output_shape=(2, 3, 4),\n+            expected_num_trainable_weights=1,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_seed_generators=0,\n+            expected_num_losses=0,\n+            supports_masking=False,\n+        )\n+\n     def test_correctness(self):\n         layer = layers.Embedding(input_dim=3, output_dim=2)\n         layer.build()\n         layer.embeddings.assign(np.array([[0.0, 0.0], [2.0, 2.0], [3.0, 3.0]]))\n-        out = layer(np.array(([2, 1, 0])))\n+        out = layer(np.array([2, 1, 0]))\n         self.assertAllClose(out, np.array([[3.0, 3.0], [2.0, 2.0], [0.0, 0.0]]))\n \n+    @pytest.mark.skipif(\n+        not backend.SUPPORTS_SPARSE_TENSORS,\n+        reason=\"Backend does not support sparse tensors.\",\n+    )\n+    def test_correctness_sparse(self):\n+        import tensorflow as tf\n+\n+        layer = layers.Embedding(input_dim=3, output_dim=2)\n+        layer.build()\n+        layer.embeddings.assign(np.array([[0.0, 0.0], [2.0, 2.0], [3.0, 3.0]]))\n+        x = tf.SparseTensor(\n+            indices=[[0, 0], [1, 2]], values=[2, 1], dense_shape=(2, 3)\n+        )\n+        self.assertAllClose(\n+            layer(x),\n+            np.array(\n+                [\n+                    [[3.0, 3.0], [0.0, 0.0], [0.0, 0.0]],\n+                    [[0.0, 0.0], [0.0, 0.0], [2.0, 2.0]],\n+                ]\n+            ),\n+        )\n+\n     def test_masking(self):\n         layer = layers.Embedding(input_dim=3, output_dim=2, mask_zero=True)\n         layer.build()\n\n@@ -1,4 +1,7 @@\n+import tree\n+\n from keras_core.api_export import keras_core_export\n+from keras_core.backend.common.keras_tensor import KerasTensor\n from keras_core.layers.layer import Layer\n \n \n@@ -16,3 +19,11 @@ class Identity(Layer):\n \n     def call(self, inputs):\n         return inputs\n+\n+    def compute_output_spec(self, inputs):\n+        return tree.map_structure(\n+            lambda input: KerasTensor(\n+                shape=input.shape, dtype=input.dtype, sparse=input.sparse\n+            ),\n+            inputs,\n+        )\n\n@@ -1,20 +1,33 @@\n import pytest\n+from absl.testing import parameterized\n \n+from keras_core import backend\n from keras_core import layers\n from keras_core import testing\n \n \n-class IdentityTest(testing.TestCase):\n+class IdentityTest(testing.TestCase, parameterized.TestCase):\n+    @parameterized.named_parameters(\n+        [\n+            {\"testcase_name\": \"dense\", \"sparse\": False},\n+            {\"testcase_name\": \"sparse\", \"sparse\": True},\n+        ]\n+    )\n     @pytest.mark.requires_trainable_backend\n-    def test_identity_basics(self):\n+    def test_identity_basics(self, sparse):\n+        if sparse and not backend.SUPPORTS_SPARSE_TENSORS:\n+            pytest.skip(\"Backend does not support sparse tensors.\")\n         self.run_layer_test(\n             layers.Identity,\n             init_kwargs={},\n             input_shape=(2, 3),\n+            input_sparse=sparse,\n             expected_output_shape=(2, 3),\n+            expected_output_sparse=sparse,\n             expected_num_trainable_weights=0,\n             expected_num_non_trainable_weights=0,\n             expected_num_seed_generators=0,\n             expected_num_losses=0,\n+            run_training_check=not sparse,\n             supports_masking=True,\n         )\n\n@@ -1,4 +1,5 @@\n import numpy as np\n+import pytest\n from absl.testing import parameterized\n from tensorflow.python.ops.numpy_ops import np_config\n \n@@ -1776,7 +1777,7 @@ class NumpyOneInputOpsStaticShapeTest(testing.TestCase):\n         self.assertEqual(knp.vstack([x, y]).shape, (4, 3))\n \n \n-class NumpyTwoInputOpsCorretnessTest(testing.TestCase):\n+class NumpyTwoInputOpsCorretnessTest(testing.TestCase, parameterized.TestCase):\n     def test_add(self):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n         y = np.array([[4, 5, 6], [3, 2, 1]])\n@@ -1817,6 +1818,31 @@ class NumpyTwoInputOpsCorretnessTest(testing.TestCase):\n         self.assertAllClose(knp.Matmul()(x, y), np.matmul(x, y))\n         self.assertAllClose(knp.Matmul()(x, z), np.matmul(x, z))\n \n+    @parameterized.parameters(\n+        (\"float16\",),\n+        (\"float32\",),\n+        (\"float64\",),\n+        (\"uint8\",),\n+        (\"int8\",),\n+        (\"int16\",),\n+        (\"int32\",),\n+    )\n+    @pytest.mark.skipif(\n+        not backend.SUPPORTS_SPARSE_TENSORS,\n+        reason=\"Backend does not support sparse tensors.\",\n+    )\n+    def test_matmul_sparse(self, dtype):\n+        import tensorflow as tf\n+\n+        rng = np.random.default_rng(0)\n+        x1 = 4 * rng.standard_normal((5, 3))\n+        x1 = tf.sparse.from_dense(tf.cast(tf.nn.dropout(x1, 0.7), dtype=dtype))\n+        x2 = (4 * rng.standard_normal((3, 4))).astype(dtype)\n+        self.assertAllClose(\n+            knp.matmul(x1, x2),\n+            np.matmul(tf.sparse.to_dense(x1).numpy(), x2),\n+        )\n+\n     def test_power(self):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n         y = np.array([[4, 5, 6], [3, 2, 1]])\n@@ -2206,6 +2232,35 @@ class NumpyTwoInputOpsCorretnessTest(testing.TestCase):\n             np.take(x, indices, axis=-2),\n         )\n \n+    @parameterized.product(\n+        dtype=[\n+            \"float16\",\n+            \"float32\",\n+            \"float64\",\n+            \"uint8\",\n+            \"int8\",\n+            \"int16\",\n+            \"int32\",\n+        ],\n+        axis=[None, 0, 1, -1],\n+    )\n+    @pytest.mark.skipif(\n+        not backend.SUPPORTS_SPARSE_TENSORS,\n+        reason=\"Backend does not support sparse tensors.\",\n+    )\n+    def test_take_sparse(self, dtype, axis):\n+        import tensorflow as tf\n+\n+        rng = np.random.default_rng(0)\n+        x = (4 * rng.standard_normal((3, 4, 5))).astype(dtype)\n+        indices = tf.SparseTensor(\n+            indices=[[0, 0], [1, 2]], values=[1, 2], dense_shape=(2, 3)\n+        )\n+        self.assertAllClose(\n+            knp.take(x, indices, axis=axis),\n+            np.take(x, tf.sparse.to_dense(indices).numpy(), axis=axis),\n+        )\n+\n     def test_take_along_axis(self):\n         x = np.arange(24).reshape([1, 2, 3, 4])\n         indices = np.ones([1, 4, 1, 1], dtype=np.int32)\n\n@@ -11,6 +11,7 @@ from keras_core import ops\n from keras_core import utils\n from keras_core.backend.common import is_float_dtype\n from keras_core.backend.common import standardize_dtype\n+from keras_core.backend.common.keras_tensor import KerasTensor\n from keras_core.models import Model\n from keras_core.utils import traceback_utils\n \n@@ -112,9 +113,11 @@ class TestCase(unittest.TestCase):\n         input_shape=None,\n         input_dtype=\"float32\",\n         input_data=None,\n+        input_sparse=False,\n         call_kwargs=None,\n         expected_output_shape=None,\n         expected_output_dtype=None,\n+        expected_output_sparse=False,\n         expected_output=None,\n         expected_num_trainable_weights=None,\n         expected_num_non_trainable_weights=None,\n@@ -272,6 +275,14 @@ class TestCase(unittest.TestCase):\n                     backend.standardize_dtype(output_dtype),\n                     msg=\"Unexpected output dtype\",\n                 )\n+            if expected_output_sparse:\n+                import tensorflow as tf\n+\n+                for x in tree.flatten(output):\n+                    if isinstance(x, KerasTensor):\n+                        self.assertTrue(x.sparse)\n+                    else:\n+                        self.assertIsInstance(x, tf.SparseTensor)\n             if eager:\n                 if expected_output is not None:\n                     self.assertEqual(type(expected_output), type(output))\n@@ -294,13 +305,23 @@ class TestCase(unittest.TestCase):\n                     return self.layer(x)\n \n             model = TestModel(layer)\n-            model.compile(optimizer=\"sgd\", loss=\"mse\", jit_compile=True)\n+\n+            if input_sparse:\n+                import tensorflow as tf\n+\n+                dataset = tf.data.Dataset.from_tensors(\n+                    (input_data, output_data)\n+                )\n+                model.compile(optimizer=\"sgd\", loss=\"mse\", jit_compile=False)\n+                model.fit(dataset, verbose=0)\n+            else:\n                 input_data = tree.map_structure(\n                     lambda x: backend.convert_to_numpy(x), input_data\n                 )\n                 output_data = tree.map_structure(\n                     lambda x: backend.convert_to_numpy(x), output_data\n                 )\n+                model.compile(optimizer=\"sgd\", loss=\"mse\", jit_compile=True)\n                 model.fit(input_data, output_data, verbose=0)\n \n         # Build test.\n@@ -313,7 +334,9 @@ class TestCase(unittest.TestCase):\n             run_build_asserts(layer)\n \n             # Symbolic call test.\n-            keras_tensor_inputs = create_keras_tensors(input_shape, input_dtype)\n+            keras_tensor_inputs = create_keras_tensors(\n+                input_shape, input_dtype, input_sparse\n+            )\n             layer = layer_cls(**init_kwargs)\n             if isinstance(keras_tensor_inputs, dict):\n                 keras_tensor_outputs = layer(\n@@ -331,7 +354,9 @@ class TestCase(unittest.TestCase):\n         # Eager call test and compiled training test.\n         if input_data is not None or input_shape is not None:\n             if input_data is None:\n-                input_data = create_eager_tensors(input_shape, input_dtype)\n+                input_data = create_eager_tensors(\n+                    input_shape, input_dtype, input_sparse\n+                )\n             layer = layer_cls(**init_kwargs)\n             if isinstance(input_data, dict):\n                 output_data = layer(**input_data, **call_kwargs)\n@@ -364,45 +389,53 @@ class TestCase(unittest.TestCase):\n                         self.assertEqual(dtype, \"float32\")\n \n \n-def create_keras_tensors(input_shape, dtype):\n-    from keras_core.backend.common import keras_tensor\n-\n+def create_keras_tensors(input_shape, dtype, sparse):\n     if isinstance(input_shape, tuple):\n-        return keras_tensor.KerasTensor(input_shape, dtype=dtype)\n+        return KerasTensor(input_shape, dtype=dtype, sparse=sparse)\n     if isinstance(input_shape, list):\n-        return [keras_tensor.KerasTensor(s, dtype=dtype) for s in input_shape]\n+        return [KerasTensor(s, dtype=dtype, sparse=sparse) for s in input_shape]\n     if isinstance(input_shape, dict):\n         return {\n-            utils.removesuffix(k, \"_shape\"): keras_tensor.KerasTensor(\n-                v, dtype=dtype\n+            utils.removesuffix(k, \"_shape\"): KerasTensor(\n+                v, dtype=dtype, sparse=sparse\n             )\n             for k, v in input_shape.items()\n         }\n \n \n-def create_eager_tensors(input_shape, dtype):\n+def create_eager_tensors(input_shape, dtype, sparse):\n     from keras_core.backend import random\n \n-    if dtype in [\"float16\", \"float32\", \"float64\"]:\n-        create_fn = random.uniform\n-    elif dtype in [\"int16\", \"int32\", \"int64\"]:\n-\n-        def create_fn(shape, dtype):\n-            shape = list(shape)\n-            for i in range(len(shape)):\n-                if shape[i] is None:\n-                    shape[i] = 2\n-            shape = tuple(shape)\n-            return ops.cast(\n-                random.uniform(shape, dtype=\"float32\") * 3, dtype=dtype\n-            )\n-\n-    else:\n+    if dtype not in [\n+        \"float16\",\n+        \"float32\",\n+        \"float64\",\n+        \"int16\",\n+        \"int32\",\n+        \"int64\",\n+    ]:\n         raise ValueError(\n             \"dtype must be a standard float or int dtype. \"\n             f\"Received: dtype={dtype}\"\n         )\n \n+    if sparse:\n+        import tensorflow as tf\n+\n+        def create_fn(shape, dtype):\n+            min_dim = min(dim for dim in shape if dim > 1)\n+            x = random.uniform(shape, dtype=\"float32\") * 3 / min_dim\n+            x = tf.nn.dropout(x, 1.0 / min_dim)\n+            x = tf.cast(x, dtype=dtype)\n+            return tf.sparse.from_dense(x)\n+\n+    else:\n+\n+        def create_fn(shape, dtype):\n+            return ops.cast(\n+                random.uniform(shape, dtype=\"float32\") * 3, dtype=dtype\n+            )\n+\n     if isinstance(input_shape, tuple):\n         return create_fn(input_shape, dtype=dtype)\n     if isinstance(input_shape, list):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0416d1071013376798975fd54874a83a0c9e894e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 216 | Lines Deleted: 24 | Files Changed: 10 | Hunks: 54 | Methods Changed: 16 | Complexity Δ (Sum/Max): 17/4 | Churn Δ: 240 | Churn Cumulative: 6812 | Contributors (this commit): 26 | Commits (past 90d): 113 | Contributors (cumulative): 64 | DMM Complexity: 1.0\n\nDIFF:\n@@ -524,6 +524,8 @@ def repeat(x, repeats, axis=None):\n \n \n def reshape(x, new_shape):\n+    if isinstance(x, tf.SparseTensor):\n+        return tf.sparse.reshape(x, new_shape)\n     return tfnp.reshape(x, new_shape)\n \n \n@@ -689,6 +691,8 @@ def squeeze(x, axis=None):\n \n \n def transpose(x, axes=None):\n+    if isinstance(x, tf.SparseTensor):\n+        return tf.sparse.transpose(x, perm=axes)\n     return tfnp.transpose(x, axes=axes)\n \n \n\n@@ -3,6 +3,7 @@ import math\n from keras_core import backend\n from keras_core import ops\n from keras_core.api_export import keras_core_export\n+from keras_core.backend.common.keras_tensor import KerasTensor\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n \n@@ -62,6 +63,12 @@ class Flatten(Layer):\n             flattened_dim = math.prod(non_batch_dims)\n         return (input_shape[0], flattened_dim)\n \n+    def compute_output_spec(self, inputs):\n+        output_shape = self.compute_output_shape(inputs.shape)\n+        return KerasTensor(\n+            shape=output_shape, dtype=inputs.dtype, sparse=inputs.sparse\n+        )\n+\n     def get_config(self):\n         config = {\"data_format\": self.data_format}\n         base_config = super().get_config()\n\n@@ -1,42 +1,74 @@\n import numpy as np\n import pytest\n+from absl.testing import parameterized\n \n+from keras_core import backend\n from keras_core import layers\n from keras_core import ops\n from keras_core import testing\n \n \n-class FlattenTest(testing.TestCase):\n+class FlattenTest(testing.TestCase, parameterized.TestCase):\n+    @parameterized.named_parameters(\n+        [\n+            {\"testcase_name\": \"dense\", \"sparse\": False},\n+            {\"testcase_name\": \"sparse\", \"sparse\": True},\n+        ]\n+    )\n     @pytest.mark.requires_trainable_backend\n-    def test_flatten(self):\n-        inputs = np.random.random((10, 3, 5, 5)).astype(\"float32\")\n+    def test_flatten(self, sparse):\n+        if sparse and not backend.SUPPORTS_SPARSE_TENSORS:\n+            pytest.skip(\"Backend does not support sparse tensors.\")\n \n-        # Test default data_format and channels_last\n-        expected_output = ops.convert_to_tensor(\n+        inputs = np.random.random((10, 3, 5, 5)).astype(\"float32\")\n+        # Make the ndarray relatively sparse\n+        inputs = np.multiply(inputs, inputs >= 0.8)\n+        expected_output_channels_last = ops.convert_to_tensor(\n             np.reshape(inputs, (-1, 5 * 5 * 3))\n         )\n+        expected_output_channels_first = ops.convert_to_tensor(\n+            np.reshape(np.transpose(inputs, (0, 2, 3, 1)), (-1, 5 * 5 * 3))\n+        )\n+        if sparse:\n+            import tensorflow as tf\n+\n+            inputs = tf.sparse.from_dense(inputs)\n+            expected_output_channels_last = tf.sparse.from_dense(\n+                expected_output_channels_last\n+            )\n+            expected_output_channels_first = tf.sparse.from_dense(\n+                expected_output_channels_first\n+            )\n+\n+        # Test default data_format and channels_last\n         self.run_layer_test(\n             layers.Flatten,\n             init_kwargs={},\n             input_data=inputs,\n-            expected_output=expected_output,\n+            input_sparse=True,\n+            expected_output=expected_output_channels_last,\n+            expected_output_sparse=sparse,\n+            run_training_check=not sparse,\n         )\n         self.run_layer_test(\n             layers.Flatten,\n             init_kwargs={\"data_format\": \"channels_last\"},\n             input_data=inputs,\n-            expected_output=expected_output,\n+            input_sparse=True,\n+            expected_output=expected_output_channels_last,\n+            expected_output_sparse=sparse,\n+            run_training_check=not sparse,\n         )\n \n         # Test channels_first\n-        expected_output = ops.convert_to_tensor(\n-            np.reshape(np.transpose(inputs, (0, 2, 3, 1)), (-1, 5 * 5 * 3))\n-        )\n         self.run_layer_test(\n             layers.Flatten,\n             init_kwargs={\"data_format\": \"channels_first\"},\n             input_data=inputs,\n-            expected_output=expected_output,\n+            input_sparse=True,\n+            expected_output=expected_output_channels_first,\n+            expected_output_sparse=sparse,\n+            run_training_check=not sparse,\n         )\n \n     @pytest.mark.requires_trainable_backend\n\n@@ -1,5 +1,6 @@\n from keras_core import ops\n from keras_core.api_export import keras_core_export\n+from keras_core.backend.common.keras_tensor import KerasTensor\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n \n@@ -48,6 +49,12 @@ class Permute(Layer):\n             output_shape.append(input_shape[dim])\n         return tuple(output_shape)\n \n+    def compute_output_spec(self, inputs):\n+        output_shape = self.compute_output_shape(inputs.shape)\n+        return KerasTensor(\n+            shape=output_shape, dtype=inputs.dtype, sparse=inputs.sparse\n+        )\n+\n     def call(self, inputs):\n         return ops.transpose(inputs, axes=(0,) + self.dims)\n \n\n@@ -1,23 +1,45 @@\n import numpy as np\n import pytest\n+from absl.testing import parameterized\n \n+from keras_core import backend\n from keras_core import layers\n from keras_core import ops\n from keras_core import testing\n \n \n-class PermuteTest(testing.TestCase):\n-    @pytest.mark.requires_trainable_backend\n-    def test_permute(self):\n-        inputs = np.random.random((2, 3, 5)).astype(\"float32\")\n-        expected_output = ops.convert_to_tensor(\n-            np.transpose(inputs, axes=(0, 2, 1))\n+class PermuteTest(testing.TestCase, parameterized.TestCase):\n+    @parameterized.named_parameters(\n+        [\n+            {\"testcase_name\": \"dense\", \"sparse\": False},\n+            {\"testcase_name\": \"sparse\", \"sparse\": True},\n+        ]\n     )\n+    @pytest.mark.requires_trainable_backend\n+    def test_permute(self, sparse):\n+        if sparse and not backend.SUPPORTS_SPARSE_TENSORS:\n+            pytest.skip(\"Backend does not support sparse tensors.\")\n+\n+        inputs = np.random.random((10, 3, 5, 5)).astype(\"float32\")\n+        # Make the ndarray relatively sparse\n+        inputs = np.multiply(inputs, inputs >= 0.8)\n+        expected_output = ops.convert_to_tensor(\n+            np.transpose(inputs, axes=(0, 3, 1, 2))\n+        )\n+        if sparse:\n+            import tensorflow as tf\n+\n+            inputs = tf.sparse.from_dense(inputs)\n+            expected_output = tf.sparse.from_dense(expected_output)\n+\n         self.run_layer_test(\n             layers.Permute,\n-            init_kwargs={\"dims\": (2, 1)},\n+            init_kwargs={\"dims\": (3, 1, 2)},\n             input_data=inputs,\n+            input_sparse=sparse,\n             expected_output=expected_output,\n+            expected_output_sparse=sparse,\n+            run_training_check=not sparse,\n         )\n \n     def test_permute_with_dynamic_batch_size(self):\n\n@@ -1,5 +1,6 @@\n from keras_core import ops\n from keras_core.api_export import keras_core_export\n+from keras_core.backend.common.keras_tensor import KerasTensor\n from keras_core.layers.layer import Layer\n from keras_core.ops import operation_utils\n \n@@ -46,6 +47,12 @@ class Reshape(Layer):\n             ),\n         )\n \n+    def compute_output_spec(self, inputs):\n+        output_shape = self.compute_output_shape(inputs.shape)\n+        return KerasTensor(\n+            shape=output_shape, dtype=inputs.dtype, sparse=inputs.sparse\n+        )\n+\n     def call(self, inputs):\n         return ops.reshape(inputs, (ops.shape(inputs)[0],) + self.target_shape)\n \n\n@@ -1,58 +1,90 @@\n import pytest\n+from absl.testing import parameterized\n \n+from keras_core import backend\n from keras_core import layers\n from keras_core import testing\n \n \n-class ReshapeTest(testing.TestCase):\n+class ReshapeTest(testing.TestCase, parameterized.TestCase):\n+    @parameterized.named_parameters(\n+        [\n+            {\"testcase_name\": \"dense\", \"sparse\": False},\n+            {\"testcase_name\": \"sparse\", \"sparse\": True},\n+        ]\n+    )\n     @pytest.mark.requires_trainable_backend\n-    def test_reshape(self):\n+    def test_reshape(self, sparse):\n+        if sparse and not backend.SUPPORTS_SPARSE_TENSORS:\n+            pytest.skip(\"Backend does not support sparse tensors.\")\n+\n         self.run_layer_test(\n             layers.Reshape,\n             init_kwargs={\"target_shape\": (8, 1)},\n             input_shape=(3, 2, 4),\n+            input_sparse=sparse,\n             expected_output_shape=(3, 8, 1),\n+            expected_output_sparse=sparse,\n+            run_training_check=not sparse,\n         )\n \n         self.run_layer_test(\n             layers.Reshape,\n             init_kwargs={\"target_shape\": (8,)},\n             input_shape=(3, 2, 4),\n+            input_sparse=sparse,\n             expected_output_shape=(3, 8),\n+            expected_output_sparse=sparse,\n+            run_training_check=not sparse,\n         )\n \n         self.run_layer_test(\n             layers.Reshape,\n             init_kwargs={\"target_shape\": (2, 4)},\n             input_shape=(3, 8),\n+            input_sparse=sparse,\n             expected_output_shape=(3, 2, 4),\n+            expected_output_sparse=sparse,\n+            run_training_check=not sparse,\n         )\n         self.run_layer_test(\n             layers.Reshape,\n             init_kwargs={\"target_shape\": (-1, 1)},\n             input_shape=(3, 2, 4),\n+            input_sparse=sparse,\n             expected_output_shape=(3, 8, 1),\n+            expected_output_sparse=sparse,\n+            run_training_check=not sparse,\n         )\n \n         self.run_layer_test(\n             layers.Reshape,\n             init_kwargs={\"target_shape\": (1, -1)},\n             input_shape=(3, 2, 4),\n+            input_sparse=sparse,\n             expected_output_shape=(3, 1, 8),\n+            expected_output_sparse=sparse,\n+            run_training_check=not sparse,\n         )\n \n         self.run_layer_test(\n             layers.Reshape,\n             init_kwargs={\"target_shape\": (-1,)},\n             input_shape=(3, 2, 4),\n+            input_sparse=sparse,\n             expected_output_shape=(3, 8),\n+            expected_output_sparse=sparse,\n+            run_training_check=not sparse,\n         )\n \n         self.run_layer_test(\n             layers.Reshape,\n             init_kwargs={\"target_shape\": (2, -1)},\n             input_shape=(3, 2, 4),\n+            input_sparse=sparse,\n             expected_output_shape=(3, 2, 4),\n+            expected_output_sparse=sparse,\n+            run_training_check=not sparse,\n         )\n \n     def test_reshape_with_dynamic_batch_size(self):\n\n@@ -4163,7 +4163,7 @@ class Reshape(Operation):\n         output_shape = operation_utils.compute_reshape_output_shape(\n             x.shape, self.new_shape, \"new_shape\"\n         )\n-        return KerasTensor(output_shape, dtype=x.dtype)\n+        return KerasTensor(output_shape, dtype=x.dtype, sparse=x.sparse)\n \n \n @keras_core_export([\"keras_core.ops.reshape\", \"keras_core.ops.numpy.reshape\"])\n@@ -5328,7 +5328,7 @@ class Transpose(Operation):\n     def compute_output_spec(self, x):\n         x_shape = x.shape\n         if self.axes is None:\n-            return KerasTensor(x_shape[::-1])\n+            return KerasTensor(x_shape[::-1], dtype=x.dtype, sparse=x.sparse)\n \n         if len(self.axes) != len(x_shape):\n             raise ValueError(\n@@ -5338,7 +5338,7 @@ class Transpose(Operation):\n         output_shape = []\n         for ax in self.axes:\n             output_shape.append(x_shape[ax])\n-        return KerasTensor(output_shape, dtype=x.dtype)\n+        return KerasTensor(output_shape, dtype=x.dtype, sparse=x.sparse)\n \n \n @keras_core_export(\n\n@@ -1365,6 +1365,12 @@ class NumpyOneInputOpsStaticShapeTest(testing.TestCase):\n         x = KerasTensor([2, 3])\n         self.assertEqual(knp.transpose(x).shape, (3, 2))\n \n+    def test_transpose_sparse(self):\n+        x = KerasTensor([2, 3], sparse=True)\n+        result = knp.transpose(x)\n+        self.assertEqual(result.shape, (3, 2))\n+        self.assertTrue(result.sparse)\n+\n     def test_arccos(self):\n         x = KerasTensor([2, 3])\n         self.assertEqual(knp.arccos(x).shape, (2, 3))\n@@ -1672,6 +1678,25 @@ class NumpyOneInputOpsStaticShapeTest(testing.TestCase):\n         self.assertEqual(knp.reshape(x, (6,)).shape, (6,))\n         self.assertEqual(knp.reshape(x, (-1,)).shape, (6,))\n \n+    def test_reshape_sparse(self):\n+        x = KerasTensor([2, 3], sparse=True)\n+\n+        result = knp.reshape(x, (3, 2))\n+        self.assertEqual(result.shape, (3, 2))\n+        self.assertTrue(result.sparse)\n+\n+        result = knp.reshape(x, (3, -1))\n+        self.assertEqual(result.shape, (3, 2))\n+        self.assertTrue(result.sparse)\n+\n+        result = knp.reshape(x, (6,))\n+        self.assertEqual(result.shape, (6,))\n+        self.assertTrue(result.sparse)\n+\n+        result = knp.reshape(x, (-1,))\n+        self.assertEqual(result.shape, (6,))\n+        self.assertTrue(result.sparse)\n+\n     def test_roll(self):\n         x = KerasTensor([2, 3])\n         self.assertEqual(knp.roll(x, 1).shape, (2, 3))\n@@ -2525,6 +2550,40 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             np.transpose(x, axes=(1, 0, 3, 2, 4)),\n         )\n \n+    @pytest.mark.skipif(\n+        not backend.SUPPORTS_SPARSE_TENSORS,\n+        reason=\"Backend does not support sparse tensors.\",\n+    )\n+    def test_transpose_sparse(self):\n+        import tensorflow as tf\n+\n+        x = tf.SparseTensor(\n+            indices=[[0, 0, 0, 0, 0], [0, 1, 2, 3, 4]],\n+            values=[1, 2],\n+            dense_shape=(1, 2, 3, 4, 5),\n+        )\n+        x_np = tf.sparse.to_dense(x).numpy()\n+\n+        self.assertIsInstance(knp.transpose(x), tf.SparseTensor)\n+        self.assertAllClose(knp.transpose(x), np.transpose(x_np))\n+        self.assertIsInstance(\n+            knp.transpose(x, axes=(1, 0, 3, 2, 4)), tf.SparseTensor\n+        )\n+        self.assertAllClose(\n+            knp.transpose(x, axes=(1, 0, 3, 2, 4)),\n+            np.transpose(x_np, axes=(1, 0, 3, 2, 4)),\n+        )\n+\n+        self.assertIsInstance(knp.Transpose()(x), tf.SparseTensor)\n+        self.assertAllClose(knp.Transpose()(x), np.transpose(x_np))\n+        self.assertIsInstance(\n+            knp.Transpose(axes=(1, 0, 3, 2, 4))(x), tf.SparseTensor\n+        )\n+        self.assertAllClose(\n+            knp.Transpose(axes=(1, 0, 3, 2, 4))(x),\n+            np.transpose(x_np, axes=(1, 0, 3, 2, 4)),\n+        )\n+\n     def test_arccos(self):\n         x = np.array([[1, 0.5, -0.7], [0.9, 0.2, -1]])\n         self.assertAllClose(knp.arccos(x), np.arccos(x))\n@@ -3163,6 +3222,24 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         self.assertAllClose(knp.reshape(x, [3, 2]), np.reshape(x, [3, 2]))\n         self.assertAllClose(knp.Reshape([3, 2])(x), np.reshape(x, [3, 2]))\n \n+    @pytest.mark.skipif(\n+        not backend.SUPPORTS_SPARSE_TENSORS,\n+        reason=\"Backend does not support sparse tensors.\",\n+    )\n+    def test_reshape_sparse(self):\n+        import tensorflow as tf\n+\n+        x = tf.SparseTensor(\n+            indices=[[0, 0], [1, 2]],\n+            values=[1, 2],\n+            dense_shape=(2, 3),\n+        )\n+        x_np = tf.sparse.to_dense(x).numpy()\n+        self.assertIsInstance(knp.reshape(x, [3, 2]), tf.SparseTensor)\n+        self.assertAllClose(knp.reshape(x, [3, 2]), np.reshape(x_np, [3, 2]))\n+        self.assertIsInstance(knp.Reshape([3, 2])(x), tf.SparseTensor)\n+        self.assertAllClose(knp.Reshape([3, 2])(x), np.reshape(x_np, [3, 2]))\n+\n     def test_roll(self):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n         self.assertAllClose(knp.roll(x, 1), np.roll(x, 1))\n\n@@ -112,8 +112,8 @@ class TestCase(unittest.TestCase):\n         init_kwargs,\n         input_shape=None,\n         input_dtype=\"float32\",\n-        input_data=None,\n         input_sparse=False,\n+        input_data=None,\n         call_kwargs=None,\n         expected_output_shape=None,\n         expected_output_dtype=None,\n@@ -139,6 +139,8 @@ class TestCase(unittest.TestCase):\n             input_shape: Shape tuple (or list/dict of shape tuples)\n                 to call the layer on.\n             input_dtype: Corresponding input dtype.\n+            input_sparse: Whether the input is a sparse tensor (this requires\n+                the backend to support sparse tensors).\n             input_data: Tensor (or list/dict of tensors)\n                 to call the layer on.\n             call_kwargs: Dict of arguments to use when calling the\n@@ -147,6 +149,8 @@ class TestCase(unittest.TestCase):\n                 (or list/dict of shape tuples)\n                 expected as output.\n             expected_output_dtype: dtype expected as output.\n+            expected_output_sparse: Whether the output is expected to be sparse\n+                (this requires the backend to support sparse tensors).\n             expected_output: Expected output tensor -- only\n                 to be specified if input_data is provided.\n             expected_num_trainable_weights: Expected number\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
