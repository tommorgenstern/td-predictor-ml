{"custom_id": "keras#843d0575bad5561eef9dd096f5da5cbbeb3d1766", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 24 | Lines Deleted: 27 | Files Changed: 2 | Hunks: 6 | Methods Changed: 2 | Complexity Δ (Sum/Max): -1/4 | Churn Δ: 51 | Churn Cumulative: 3894 | Contributors (this commit): 17 | Commits (past 90d): 50 | Contributors (cumulative): 28 | DMM Complexity: 0.8571428571428571\n\nDIFF:\n@@ -800,22 +800,34 @@ def sort(x, axis=-1):\n \n def split(x, indices_or_sections, axis=0):\n     x = convert_to_tensor(x)\n+    dim = x.shape[axis]\n     if isinstance(indices_or_sections, (list, tuple)):\n         idxs = convert_to_tensor(indices_or_sections)\n         start_size = indices_or_sections[0]\n-        end_size = x.shape[axis] - indices_or_sections[-1]\n+        end_size = dim - indices_or_sections[-1]\n         chunk_sizes = (\n             [start_size]\n             + torch.diff(idxs).type(torch.int).tolist()\n             + [end_size]\n         )\n     else:\n-        chunk_sizes = x.shape[axis] // indices_or_sections\n-    return torch.split(\n+        if dim % indices_or_sections != 0:\n+            raise ValueError(\n+                f\"Received indices_or_sections={indices_or_sections} \"\n+                f\"(interpreted as a number of sections) and axis={axis}, \"\n+                f\"but input dimension x.shape[{axis}]={x.shape[axis]} \"\n+                f\"is not divisible by {indices_or_sections}. \"\n+                f\"Full input shape: x.shape={x.shape}\"\n+            )\n+        chunk_sizes = dim // indices_or_sections\n+    out = torch.split(\n         tensor=x,\n         split_size_or_sections=chunk_sizes,\n         dim=axis,\n     )\n+    if dim == 0 and isinstance(indices_or_sections, int):\n+        out = tuple(out[0].clone() for _ in range(indices_or_sections))\n+    return out\n \n \n def stack(x, axis=0):\n\n@@ -3283,30 +3283,6 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n \n     def test_split(self):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n-        if backend.backend() == \"torch\":\n-            self.assertAllClose(\n-                [backend.convert_to_numpy(t) for t in knp.split(x, 2)],\n-                np.split(x, 2),\n-            )\n-            self.assertAllClose(\n-                [backend.convert_to_numpy(t) for t in knp.Split(2)(x)],\n-                np.split(x, 2),\n-            )\n-            self.assertAllClose(\n-                [\n-                    backend.convert_to_numpy(t)\n-                    for t in knp.split(x, [1, 2], axis=1)\n-                ],\n-                np.split(x, [1, 2], axis=1),\n-            )\n-            self.assertAllClose(\n-                [\n-                    backend.convert_to_numpy(t)\n-                    for t in knp.Split([1, 2], axis=1)(x)\n-                ],\n-                np.split(x, [1, 2], axis=1),\n-            )\n-        else:\n         self.assertAllClose(knp.split(x, 2), np.split(x, 2))\n         self.assertAllClose(knp.Split(2)(x), np.split(x, 2))\n         self.assertAllClose(\n@@ -3318,6 +3294,15 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             np.split(x, [1, 2], axis=1),\n         )\n \n+        # test invalid indices_or_sections\n+        with self.assertRaises(Exception):\n+            knp.split(x, 3)\n+\n+        # test zero dimension\n+        x = np.ones(shape=(0,))\n+        self.assertEqual(len(knp.split(x, 2)), 2)\n+        self.assertEqual(len(knp.Split(2)(x)), 2)\n+\n     def test_sqrt(self):\n         x = np.array([[1, 4, 9], [16, 25, 36]])\n         self.assertAllClose(knp.sqrt(x), np.sqrt(x))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8f8d2abf68f4d11193b781db05f6804b131635b1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 571 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 12 | Complexity Δ (Sum/Max): 26/26 | Churn Δ: 571 | Churn Cumulative: 571 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 0.7708333333333334\n\nDIFF:\n@@ -0,0 +1,571 @@\n+\"\"\"\n+Title: MultipleChoice Task with Transfer Learning\n+Author: Md Awsafur Rahman\n+Date created: 2023/09/14\n+Last modified: 2023/09/14\n+Description: Use pre-trained nlp models for multiplechoice task.\n+Accelerator: GPU\n+\"\"\"\n+\n+\"\"\"\n+## Introduction\n+\n+In this example, we will demonstrate how to perform the **MultipleChoice** task by\n+finetuning pre-trained DebertaV3 model. In this task, several candidate answers are\n+provided along with a context and the model is trained to select the correct answer\n+unlike question answering. We will use SWAG dataset to demonstrate this example.\n+\"\"\"\n+\n+\"\"\"\n+## Setup\n+\"\"\"\n+\n+\"\"\"shell\n+pip install -q keras-core --upgrade\n+pip install -q keras-nlp --upgrade\n+\"\"\"\n+\n+import os\n+os.environ[\"KERAS_BACKEND\"] = \"jax\"  # or \"tensorflow\" or \"torch\"\n+\n+import keras_nlp\n+import keras_core as keras\n+import tensorflow as tf\n+\n+import numpy as np\n+import pandas as pd\n+\n+import matplotlib.pyplot as plt\n+\n+\"\"\"\n+## Dataset\n+In this example we'll use **SWAG** dataset for multiplechoice task.\n+\"\"\"\n+\n+\"\"\"shell\n+wget \"https://github.com/rowanz/swagaf/archive/refs/heads/master.zip\" -O swag.zip\n+unzip -q /content/swag.zip\n+\"\"\"\n+\n+\"\"\"shell\n+ls /content/swagaf-master/data\n+\"\"\"\n+\n+\"\"\"\n+## Configuration\n+\"\"\"\n+\n+\n+class CFG:\n+    preset = \"deberta_v3_extra_small_en\"  # Name of pretrained models\n+    sequence_length = 200  # Input sequence length\n+    seed = 42  # Random seed\n+    epochs = 5  # Training epochs\n+    batch_size = 8  # Batch size\n+    augment = True  # Augmentation (Shuffle Options)\n+\n+\n+\"\"\"\n+## Reproducibility\n+Sets value for random seed to produce similar result in each run.\n+\"\"\"\n+\n+keras.utils.set_random_seed(CFG.seed)\n+\n+\n+\"\"\"\n+## Meta Data\n+* **train.csv** - will be used for training.\n+* `sent1` and `sent2`: these fields show how a sentence starts, and if you put the two\n+together, you get the `startphrase` field.\n+* `ending_<i>`: suggests a possible ending for how a sentence can end, but only one of\n+them is correct.\n+    * `label`: identifies the correct sentence ending.\n+\n+* **val.csv** - similar to `train.csv` but will be used for validation.\n+\"\"\"\n+\n+# Train data\n+train_df = pd.read_csv(\n+    \"/content/swagaf-master/data/train.csv\", index_col=0\n+)  # Read CSV file into a DataFrame\n+train_df = train_df.sample(frac=0.02)\n+print(\"# Train Data: {:,}\".format(len(train_df)))\n+\n+# Valid data\n+valid_df = pd.read_csv(\n+    \"/content/swagaf-master/data/val.csv\", index_col=0\n+)  # Read CSV file into a DataFrame\n+valid_df = valid_df.sample(frac=0.02)\n+print(\"# Valid Data: {:,}\".format(len(valid_df)))\n+\n+\"\"\"\n+## Contextualize Options\n+\n+Our approach entails furnishing the model with question and answer pairs, as opposed to\n+employing a single question for all five options. In practice, this signifies that for\n+the five options, we will supply the model with the same set of five questions combined\n+with each respective answer choice (e.g., `(Q + A)`, `(Q + B)`, and so on). This analogy\n+draws parallels to the practice of revisiting a question multiple times during an exam to\n+promote a deeper understanding of the problem at hand.\n+\n+> Notably, in the context of SWAG dataset, question is the start of a sentence and\n+options are possible ending of that sentence.\n+\"\"\"\n+\n+# Define a function to create options based on the prompt and choices\n+def make_options(row):\n+    row[\"options\"] = [\n+        f\"{row.startphrase}\\n{row.ending0}\",  # Option 0\n+        f\"{row.startphrase}\\n{row.ending1}\",  # Option 1\n+        f\"{row.startphrase}\\n{row.ending2}\",  # Option 2\n+        f\"{row.startphrase}\\n{row.ending3}\",\n+    ]  # Option 3\n+    return row\n+\n+\n+\"\"\"\n+Apply the `make_options` function to each row of the dataframe\n+\"\"\"\n+\n+train_df = train_df.apply(make_options, axis=1)\n+valid_df = valid_df.apply(make_options, axis=1)\n+\n+\"\"\"\n+## Preprocessing\n+\n+**What it does:** The preprocessor takes input strings and transforms them into a\n+dictionary (`token_ids`, `padding_mask`) containing preprocessed tensors. This process\n+starts with tokenization, where input strings are converted into sequences of token IDs.\n+\n+**Why it's important:** Initially, raw text data is complex and challenging for modeling\n+due to its high dimensionality. By converting text into a compact set of tokens, such as\n+transforming `\"The quick brown fox\"` into `[\"the\", \"qu\", \"##ick\", \"br\", \"##own\", \"fox\"]`,\n+we simplify the data. Many models rely on special tokens and additional tensors to\n+understand input. These tokens help divide input and identify padding, among other tasks.\n+Making all sequences the same length through padding boosts computational efficiency,\n+making subsequent steps smoother.\n+\n+Explore the following pages to access the available preprocessing and tokenizer layers in\n+**KerasNLP**:\n+- [Preprocessing](https://keras.io/api/keras_nlp/preprocessing_layers/)\n+- [Tokenizers](https://keras.io/api/keras_nlp/tokenizers/)\n+\"\"\"\n+\n+preprocessor = keras_nlp.models.DebertaV3Preprocessor.from_preset(\n+    preset=CFG.preset,  # Name of the model\n+    sequence_length=CFG.sequence_length,  # Max sequence length, will be padded if shorter\n+)\n+\n+\"\"\"\n+Now, let's examine what the output shape of the preprocessing layer looks like. The\n+output shape of the layer can be represented as $(num\\_choices, sequence\\_length)$.\n+\"\"\"\n+\n+outs = preprocessor(\n+    train_df.options.iloc[0]\n+)  # Process options for the first row\n+\n+# Display the shape of each processed output\n+for k, v in outs.items():\n+    print(k, \":\", v.shape)\n+\n+\"\"\"\n+We'll use the `preprocessing_fn` function to transform each text option using the\n+`dataset.map(preprocessing_fn)` method.\n+\"\"\"\n+\n+\n+def preprocess_fn(text, label=None):\n+    text = preprocessor(text)  # Preprocess text\n+    return (\n+        (text, label) if label is not None else text\n+    )  # Return processed text and label if available\n+\n+\n+\"\"\"\n+## Augmentation\n+\n+In this notebook, we'll experiment with an interesting augmentation technique,\n+`option_shuffle`. Since we're providing the model with one option at a time, we can\n+introduce a shuffle to the order of options. For instance, options `[A, C, E, D, B]`\n+would be rearranged as `[D, B, A, E, C]`. This practice will help the model focus on the\n+content of the options themselves, rather than being influenced by their positions.\n+\n+**Note:** Even though `option_shuffle` function is written in pure\n+tensorflow, it can be used with any backend (e.g. JAX, PyTorch) as it is only used\n+in `tf.data.Dataset` pipeline which is compatible with Keras Core routines.\n+\"\"\"\n+\n+\n+def option_shuffle(options, labels, prob=0.50, seed=None):\n+    if tf.random.uniform([]) > prob:  # Shuffle probability check\n+        return options, labels\n+    # Shuffle indices of options and labels in the same order\n+    indices = tf.random.shuffle(tf.range(tf.shape(options)[0]), seed=seed)\n+    # Shuffle options and labels\n+    options = tf.gather(options, indices)\n+    labels = tf.gather(labels, indices)\n+    return options, labels\n+\n+\n+\"\"\"\n+In the following function, we'll merge all augmentation functions to apply to the text.\n+These augmentations will be applied to the data using the `dataset.map(augment_fn)`\n+approach.\n+\"\"\"\n+\n+\n+def augment_fn(text, label=None):\n+    text, label = option_shuffle(text, label, prob=0.5  # Shuffle the options\n+    return (text, label) if label is not None else text\n+\n+\n+\"\"\"\n+## DataLoader\n+\n+The code below sets up a robust data flow pipeline using `tf.data.Dataset` for data\n+processing. Notable aspects of `tf.data` include its ability to simplify pipeline\n+construction and represent components in sequences.\n+\n+To learn more about `tf.data`, refer to this\n+[documentation](https://www.tensorflow.org/guide/data).\n+\"\"\"\n+\n+\n+def build_dataset(\n+    texts,\n+    labels=None,\n+    batch_size=32,\n+    cache=False,\n+    augment=False,\n+    repeat=False,\n+    shuffle=1024,\n+):\n+    AUTO = tf.data.AUTOTUNE  # AUTOTUNE option\n+    slices = (\n+        (texts,)\n+        if labels is None\n+        else (texts, keras.utils.to_categorical(labels, num_classes=4))\n+    )  # Create slices\n+    ds = tf.data.Dataset.from_tensor_slices(\n+        slices\n+    )  # Create dataset from slices\n+    ds = ds.cache() if cache else ds  # Cache dataset if enabled\n+    if augment:  # Apply augmentation if enabled\n+        ds = ds.map(augment_fn, num_parallel_calls=AUTO)\n+    ds = ds.map(\n+        preprocess_fn, num_parallel_calls=AUTO\n+    )  # Map preprocessing function\n+    ds = ds.repeat() if repeat else ds  # Repeat dataset if enabled\n+    opt = tf.data.Options()  # Create dataset options\n+    if shuffle:\n+        ds = ds.shuffle(shuffle, seed=CFG.seed)  # Shuffle dataset if enabled\n+        opt.experimental_deterministic = False\n+    ds = ds.with_options(opt)  # Set dataset options\n+    ds = ds.batch(batch_size, drop_remainder=True)  # Batch dataset\n+    ds = ds.prefetch(AUTO)  # Prefetch next batch\n+    return ds  # Return the built dataset\n+\n+\n+\"\"\"\n+Now let's create train and valid dataloader using above funciton.\n+\"\"\"\n+\n+# Build train dataloader\n+train_texts = train_df.options.tolist()  # Extract training texts\n+train_labels = train_df.label.tolist()  # Extract training labels\n+train_ds = build_dataset(\n+    train_texts,\n+    train_labels,\n+    batch_size=CFG.batch_size,\n+    cache=True,\n+    shuffle=True,\n+    repeat=True,\n+    augment=CFG.augment,\n+)\n+\n+# Build valid dataloader\n+valid_texts = valid_df.options.tolist()  # Extract validation texts\n+valid_labels = valid_df.label.tolist()  # Extract validation labels\n+valid_ds = build_dataset(\n+    valid_texts,\n+    valid_labels,\n+    batch_size=CFG.batch_size,\n+    cache=True,\n+    shuffle=False,\n+    repeat=False,\n+    augment=False,\n+)\n+\n+\n+\"\"\"\n+## LR Schedule\n+\n+Implementing a learning rate scheduler is crucial for transfer learning. The learning\n+rate initiates at `lr_start` and gradually tapers down to `lr_min` using **cosine**\n+curve.\n+\n+**Importance:** A well-structured learning rate schedule is essential for efficient model\n+training, ensuring optimal convergence and avoiding issues such as overshooting or\n+stagnation.\n+\"\"\"\n+\n+import math\n+\n+\n+def get_lr_callback(batch_size=8, mode=\"cos\", epochs=10, plot=False):\n+    lr_start, lr_max, lr_min = 1.0e-6, 0.6e-6 * batch_size, 1e-6\n+    lr_ramp_ep, lr_sus_ep = 2, 0\n+\n+    def lrfn(epoch):  # Learning rate update function\n+        if epoch < lr_ramp_ep:\n+            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n+        elif epoch < lr_ramp_ep + lr_sus_ep:\n+            lr = lr_max\n+        else:\n+            decay_total_epochs, decay_epoch_index = (\n+                epochs - lr_ramp_ep - lr_sus_ep + 3,\n+                epoch - lr_ramp_ep - lr_sus_ep,\n+            )\n+            phase = math.pi * decay_epoch_index / decay_total_epochs\n+            lr = (lr_max - lr_min) * 0.5 * (1 + math.cos(phase)) + lr_min\n+        return lr\n+\n+    if plot:  # Plot lr curve if plot is True\n+        plt.figure(figsize=(10, 5))\n+        plt.plot(\n+            np.arange(epochs),\n+            [lrfn(epoch) for epoch in np.arange(epochs)],\n+            marker=\"o\",\n+        )\n+        plt.xlabel(\"epoch\")\n+        plt.ylabel(\"lr\")\n+        plt.title(\"LR Scheduler\")\n+        plt.show()\n+\n+    return keras.callbacks.LearningRateScheduler(\n+        lrfn, verbose=False\n+    )  # Create lr callback\n+\n+\n+_ = get_lr_callback(CFG.batch_size, plot=True)\n+\n+\"\"\"\n+## Callbacks\n+\n+The function below will gather all the training callbacks, such as `lr_scheduler`,\n+`model_checkpoint`.\n+\"\"\"\n+\n+\n+def get_callbacks():\n+    callbacks = []\n+    lr_cb = get_lr_callback(CFG.batch_size)  # Get lr callback\n+    ckpt_cb = keras.callbacks.ModelCheckpoint(\n+        f\"best.keras\",\n+        monitor=\"val_accuracy\",\n+        save_best_only=True,\n+        save_weights_only=False,\n+        mode=\"max\",\n+    )  # Get Model checkpoint callback\n+    callbacks.extend([lr_cb, ckpt_cb])  # Add lr and checkpoint callbacks\n+    return callbacks  # Return the list of callbacks\n+\n+\n+callbacks = get_callbacks()\n+\n+\"\"\"\n+## MultipleChoice Model\n+\n+\n+\n+\n+\n+\"\"\"\n+\n+\"\"\"\n+\n+### Pre-trained Models\n+\n+The `KerasNLP` library provides comprehensive, ready-to-use implementations of popular\n+NLP model architectures. It features a variety of pre-trained models including `Bert`,\n+`Roberta`, `DebertaV3`, and more. In this notebook, we'll showcase the usage of\n+`DistillBert`. However, feel free to explore all available models in the [KerasNLP\n+documentation](https://keras.io/api/keras_nlp/models/). Also for a deeper understanding\n+of `KerasNLP`, refer to the informative [getting started\n+guide](https://keras.io/guides/keras_nlp/getting_started/).\n+\n+Our approach involves using `keras_nlp.models.XXClassifier` to process each question and\n+option pari (e.g. (Q+A), (Q+B), etc.), generating logits. These logits are then combined\n+and passed through a softmax function to produce the final output.\n+\"\"\"\n+\n+\"\"\"\n+\n+### Classifier for Multiple-Choice Tasks\n+\n+When dealing with multiple-choice questions, instead of giving the model the question and\n+all options together `(Q + A + B + C ...)`, we provide the model with one option at a\n+time along with the question. For instance, `(Q + A)`, `(Q + B)`, and so on. Once we have\n+the prediction scores (logits) for all options, we combine them using the `Softmax`\n+function to get the ultimate result. If we had given all options at once to the model,\n+the text's length would increase, making it harder for the model to handle. The picture\n+below illustrates this idea:\n+\n+![Model Diagram](https://pbs.twimg.com/media/F3NUju_a8AAS8Fq?format=png&name=large)\n+\n+<div align=\"center\"><b> Picture Credict: </b> <a\n+href=\"https://twitter.com/johnowhitaker\"> @johnowhitaker </a> </div></div><br>\n+\n+From a coding perspective, remember that we use the same model for all five options, with\n+shared weights. Despite the figure suggesting five separate models, they are, in fact,\n+one model with shared weights. Another point to consider is the the input shapes of\n+Classifier and MultipleChoice.\n+\n+* Input shape for **Multiple Choice**: $(batch\\_size, num\\_choices, seq\\_length)$\n+* Input shape for **Classifier**: $(batch\\_size, seq\\_length)$\n+\n+Certainly, it's clear that we can't directly give the data for the multiple-choice task\n+to the model because the input shapes don't match. To handle this, we'll use **slicing**.\n+This means we'll separate the features of each option, like $feature_{(Q + A)}$ and\n+$feature_{(Q + B)}$, and give them one by one to the NLP classifier. After we get the\n+prediction scores $logits_{(Q + A)}$ and $logits_{(Q + B)}$ for all the options, we'll\n+use the Softmax function, like $\\operatorname{Softmax}([logits_{(Q + A)}, logits_{(Q +\n+B)}])$, to combine them. This final step helps us make the ultimate decision or choice.\n+\n+> Note that in the classifier, we set `num_classes=1` instead of `5`. This is because the\n+classifier produces a single output for each option. When dealing with five options,\n+these individual outputs are joined together and then processed through a softmax\n+function to generate the final result, which has a dimension of `5`.\n+\"\"\"\n+\n+# Selects one option from five\n+class SelectOption(keras.layers.Layer):\n+    def __init__(self, index, **kwargs):\n+        super().__init__(**kwargs)\n+        self.index = index\n+\n+    def call(self, inputs):\n+        # Selects a specific slice from the inputs tensor\n+        return inputs[:, self.index, :]\n+\n+    def get_config(self):\n+        # For serialize the model\n+        base_config = super().get_config()\n+        config = {\n+            \"index\": self.index,\n+        }\n+        return {**base_config, **config}\n+\n+\n+def build_model():\n+    # Define input layers\n+    inputs = {\n+        \"token_ids\": keras.Input(\n+            shape=(4, None), dtype=t\"int32\", name=\"token_ids\"\n+        ),\n+        \"padding_mask\": keras.Input(\n+            shape=(4, None), dtype=\"int32\", name=\"padding_mask\"\n+        ),\n+    }\n+    # Create a DebertaV3Classifier model\n+    classifier = keras_nlp.models.DebertaV3Classifier.from_preset(\n+        CFG.preset,\n+        preprocessor=None,\n+        num_classes=1,  # one output per one option, for five options total 5 outputs\n+    )\n+    logits = []\n+    # Loop through each option (Q+A), (Q+B) etc and compute associted logits\n+    for option_idx in range(4):\n+        option = {\n+            k: SelectOption(option_idx, name=f\"{k}_{option_idx}\")(v)\n+            for k, v in inputs.items()\n+        }\n+        logit = classifier(option)\n+        logits.append(logit)\n+\n+    # Compute final output\n+    logits = keras.layers.Concatenate(axis=-1)(logits)\n+    outputs = keras.layers.Softmax(axis=-1)(logits)\n+    model = keras.Model(inputs, outputs)\n+\n+    # Compile the model with optimizer, loss, and metrics\n+    model.compile(\n+        optimizer=keras.optimizers.AdamW(5e-6),\n+        loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.02),\n+        metrics=[\n+            keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n+        ],\n+        jit_compile=True,\n+    )\n+    return model\n+\n+\n+# Build the Build\n+model = build_model()\n+\n+\"\"\"\n+Let's checkout the model summary to have a better insight on the model.\n+\"\"\"\n+\n+model.summary()\n+\n+\"\"\"\n+Finally, let's check the model structure visually if everything is in place.\n+\"\"\"\n+\n+keras.utils.plot_model(model, show_shapes=True)\n+\n+\"\"\"\n+## Training\n+\"\"\"\n+\n+# Start training the model\n+history = model.fit(\n+    train_ds,\n+    epochs=CFG.epochs,\n+    validation_data=valid_ds,\n+    callbacks=callbacks,\n+    steps_per_epoch=int(len(train_df) / CFG.batch_size),\n+    verbose=1,\n+)\n+\n+\"\"\"\n+## Inference\n+\"\"\"\n+\n+# Make predictions using the trained model on last validation data\n+predictions = model.predict(\n+    valid_ds,\n+    batch_size=CFG.batch_size,  # max batch size = valid size\n+    verbose=1,\n+)\n+\n+# Format predictions and true answers\n+pred_answers = np.arange(4)[np.argsort(-predictions)][:, 0]\n+true_answers = valid_df.label.values\n+\n+# Check 5 Predictions\n+print(\"# Predictions\\n\")\n+for i in range(0, 50, 10):\n+    row = valid_df.iloc[i]\n+    question = row.startphrase\n+    pred_answer = f\"ending{pred_answers[i]}\"\n+    true_answer = f\"ending{true_answers[i]}\"\n+    print(f\"❓ Sentence {i+1}:\\n{question}\\n\")\n+    print(f\"✅ True Ending: {true_answer}\\n   >> {row[true_answer]}\\n\")\n+    print(f\"🤖 Predicted Ending: {pred_answer}\\n   >> {row[pred_answer]}\\n\")\n+    print(\"-\" * 90, \"\\n\")\n+\n+\"\"\"\n+## Reference\n+* [Multiple Choice with\n+HF](https://twitter.com/johnowhitaker/status/1689790373454041089?s=20)\n+* [Keras NLP](https://keras.io/api/keras_nlp/)\n+* [BirdCLEF23: Pretraining is All you Need\n+[Train]](https://www.kaggle.com/code/awsaf49/birdclef23-pretraining-is-all-you-need-train)\n+[Train]](https://www.kaggle.com/code/awsaf49/birdclef23-pretraining-is-all-you-need-train)\n+* [Triple Stratified KFold with\n+TFRecords](https://www.kaggle.com/code/cdeotte/triple-stratified-kfold-with-tfrecords)\n+\"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#56494995ca71faea312d18926358ed5bdd854b4b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 36 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 18 | Methods Changed: 18 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 36 | Churn Cumulative: 724 | Contributors (this commit): 9 | Commits (past 90d): 11 | Contributors (cumulative): 9 | DMM Complexity: 1.0\n\nDIFF:\n@@ -96,6 +96,8 @@ def append(\n     x2,\n     axis=None,\n ):\n+    x1 = convert_to_tensor(x1)\n+    x2 = convert_to_tensor(x2)\n     return jnp.append(x1, x2, axis=axis)\n \n \n@@ -272,10 +274,14 @@ def full_like(x, fill_value, dtype=None):\n \n \n def greater(x1, x2):\n+    x1 = convert_to_tensor(x1)\n+    x2 = convert_to_tensor(x2)\n     return jnp.greater(x1, x2)\n \n \n def greater_equal(x1, x2):\n+    x1 = convert_to_tensor(x1)\n+    x2 = convert_to_tensor(x2)\n     return jnp.greater_equal(x1, x2)\n \n \n@@ -292,6 +298,8 @@ def imag(x):\n \n \n def isclose(x1, x2):\n+    x1 = convert_to_tensor(x1)\n+    x2 = convert_to_tensor(x2)\n     return jnp.isclose(x1, x2)\n \n \n@@ -308,10 +316,14 @@ def isnan(x):\n \n \n def less(x1, x2):\n+    x1 = convert_to_tensor(x1)\n+    x2 = convert_to_tensor(x2)\n     return jnp.less(x1, x2)\n \n \n def less_equal(x1, x2):\n+    x1 = convert_to_tensor(x1)\n+    x2 = convert_to_tensor(x2)\n     return jnp.less_equal(x1, x2)\n \n \n@@ -346,10 +358,14 @@ def log2(x):\n \n \n def logaddexp(x1, x2):\n+    x1 = convert_to_tensor(x1)\n+    x2 = convert_to_tensor(x2)\n     return jnp.logaddexp(x1, x2)\n \n \n def logical_and(x1, x2):\n+    x1 = convert_to_tensor(x1)\n+    x2 = convert_to_tensor(x2)\n     return jnp.logical_and(x1, x2)\n \n \n@@ -358,6 +374,8 @@ def logical_not(x):\n \n \n def logical_or(x1, x2):\n+    x1 = convert_to_tensor(x1)\n+    x2 = convert_to_tensor(x2)\n     return jnp.logical_or(x1, x2)\n \n \n@@ -374,6 +392,8 @@ def logspace(start, stop, num=50, endpoint=True, base=10, dtype=None, axis=0):\n \n \n def maximum(x1, x2):\n+    x1 = convert_to_tensor(x1)\n+    x2 = convert_to_tensor(x2)\n     return jnp.maximum(x1, x2)\n \n \n@@ -386,10 +406,14 @@ def min(x, axis=None, keepdims=False, initial=None):\n \n \n def minimum(x1, x2):\n+    x1 = convert_to_tensor(x1)\n+    x2 = convert_to_tensor(x2)\n     return jnp.minimum(x1, x2)\n \n \n def mod(x1, x2):\n+    x1 = convert_to_tensor(x1)\n+    x2 = convert_to_tensor(x2)\n     return jnp.mod(x1, x2)\n \n \n@@ -410,6 +434,8 @@ def nonzero(x):\n \n \n def not_equal(x1, x2):\n+    x1 = convert_to_tensor(x1)\n+    x2 = convert_to_tensor(x2)\n     return jnp.not_equal(x1, x2)\n \n \n@@ -550,6 +576,8 @@ def vstack(xs):\n \n \n def where(condition, x1, x2):\n+    x1 = convert_to_tensor(x1)\n+    x2 = convert_to_tensor(x2)\n     return jnp.where(condition, x1, x2)\n \n \n@@ -560,10 +588,14 @@ def divide(x1, x2):\n \n \n def true_divide(x1, x2):\n+    x1 = convert_to_tensor(x1)\n+    x2 = convert_to_tensor(x2)\n     return jnp.true_divide(x1, x2)\n \n \n def power(x1, x2):\n+    x1 = convert_to_tensor(x1)\n+    x2 = convert_to_tensor(x2)\n     return jnp.power(x1, x2)\n \n \n@@ -609,8 +641,12 @@ def eye(N, M=None, k=0, dtype=\"float32\"):\n \n \n def floor_divide(x1, x2):\n+    x1 = convert_to_tensor(x1)\n+    x2 = convert_to_tensor(x2)\n     return jnp.floor_divide(x1, x2)\n \n \n def logical_xor(x1, x2):\n+    x1 = convert_to_tensor(x1)\n+    x2 = convert_to_tensor(x2)\n     return jnp.logical_xor(x1, x2)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bdd59445ac9b393a32b360b6871241db00416ddd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 792 | Contributors (this commit): 13 | Commits (past 90d): 12 | Contributors (cumulative): 13 | DMM Complexity: 1.0\n\nDIFF:\n@@ -261,10 +261,8 @@ class TestCase(unittest.TestCase):\n                     self.assertIsInstance(output, list)\n                     self.assertEqual(\n                         len(output),\n-                        len(\n-                            expected_output_shape,\n+                        len(expected_output_shape),\n                         msg=\"Unexpected number of outputs\",\n-                        ),\n                     )\n                     output_shape = [v.shape for v in expected_output_shape]\n                     self.assertEqual(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0f54652de83a7506be03c0c0bc6fbb4019daf674", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 743 | Lines Deleted: 1661 | Files Changed: 22 | Hunks: 82 | Methods Changed: 106 | Complexity Δ (Sum/Max): -80/17 | Churn Δ: 2404 | Churn Cumulative: 20553 | Contributors (this commit): 30 | Commits (past 90d): 218 | Contributors (cumulative): 157 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,571 +0,0 @@\n-\"\"\"\n-Title: MultipleChoice Task with Transfer Learning\n-Author: Md Awsafur Rahman\n-Date created: 2023/09/14\n-Last modified: 2023/09/14\n-Description: Use pre-trained nlp models for multiplechoice task.\n-Accelerator: GPU\n-\"\"\"\n-\n-\"\"\"\n-## Introduction\n-\n-In this example, we will demonstrate how to perform the **MultipleChoice** task by\n-finetuning pre-trained DebertaV3 model. In this task, several candidate answers are\n-provided along with a context and the model is trained to select the correct answer\n-unlike question answering. We will use SWAG dataset to demonstrate this example.\n-\"\"\"\n-\n-\"\"\"\n-## Setup\n-\"\"\"\n-\n-\"\"\"shell\n-pip install -q keras-core --upgrade\n-pip install -q keras-nlp --upgrade\n-\"\"\"\n-\n-import os\n-os.environ[\"KERAS_BACKEND\"] = \"jax\"  # or \"tensorflow\" or \"torch\"\n-\n-import keras_nlp\n-import keras_core as keras\n-import tensorflow as tf\n-\n-import numpy as np\n-import pandas as pd\n-\n-import matplotlib.pyplot as plt\n-\n-\"\"\"\n-## Dataset\n-In this example we'll use **SWAG** dataset for multiplechoice task.\n-\"\"\"\n-\n-\"\"\"shell\n-wget \"https://github.com/rowanz/swagaf/archive/refs/heads/master.zip\" -O swag.zip\n-unzip -q /content/swag.zip\n-\"\"\"\n-\n-\"\"\"shell\n-ls /content/swagaf-master/data\n-\"\"\"\n-\n-\"\"\"\n-## Configuration\n-\"\"\"\n-\n-\n-class CFG:\n-    preset = \"deberta_v3_extra_small_en\"  # Name of pretrained models\n-    sequence_length = 200  # Input sequence length\n-    seed = 42  # Random seed\n-    epochs = 5  # Training epochs\n-    batch_size = 8  # Batch size\n-    augment = True  # Augmentation (Shuffle Options)\n-\n-\n-\"\"\"\n-## Reproducibility\n-Sets value for random seed to produce similar result in each run.\n-\"\"\"\n-\n-keras.utils.set_random_seed(CFG.seed)\n-\n-\n-\"\"\"\n-## Meta Data\n-* **train.csv** - will be used for training.\n-* `sent1` and `sent2`: these fields show how a sentence starts, and if you put the two\n-together, you get the `startphrase` field.\n-* `ending_<i>`: suggests a possible ending for how a sentence can end, but only one of\n-them is correct.\n-    * `label`: identifies the correct sentence ending.\n-\n-* **val.csv** - similar to `train.csv` but will be used for validation.\n-\"\"\"\n-\n-# Train data\n-train_df = pd.read_csv(\n-    \"/content/swagaf-master/data/train.csv\", index_col=0\n-)  # Read CSV file into a DataFrame\n-train_df = train_df.sample(frac=0.02)\n-print(\"# Train Data: {:,}\".format(len(train_df)))\n-\n-# Valid data\n-valid_df = pd.read_csv(\n-    \"/content/swagaf-master/data/val.csv\", index_col=0\n-)  # Read CSV file into a DataFrame\n-valid_df = valid_df.sample(frac=0.02)\n-print(\"# Valid Data: {:,}\".format(len(valid_df)))\n-\n-\"\"\"\n-## Contextualize Options\n-\n-Our approach entails furnishing the model with question and answer pairs, as opposed to\n-employing a single question for all five options. In practice, this signifies that for\n-the five options, we will supply the model with the same set of five questions combined\n-with each respective answer choice (e.g., `(Q + A)`, `(Q + B)`, and so on). This analogy\n-draws parallels to the practice of revisiting a question multiple times during an exam to\n-promote a deeper understanding of the problem at hand.\n-\n-> Notably, in the context of SWAG dataset, question is the start of a sentence and\n-options are possible ending of that sentence.\n-\"\"\"\n-\n-# Define a function to create options based on the prompt and choices\n-def make_options(row):\n-    row[\"options\"] = [\n-        f\"{row.startphrase}\\n{row.ending0}\",  # Option 0\n-        f\"{row.startphrase}\\n{row.ending1}\",  # Option 1\n-        f\"{row.startphrase}\\n{row.ending2}\",  # Option 2\n-        f\"{row.startphrase}\\n{row.ending3}\",\n-    ]  # Option 3\n-    return row\n-\n-\n-\"\"\"\n-Apply the `make_options` function to each row of the dataframe\n-\"\"\"\n-\n-train_df = train_df.apply(make_options, axis=1)\n-valid_df = valid_df.apply(make_options, axis=1)\n-\n-\"\"\"\n-## Preprocessing\n-\n-**What it does:** The preprocessor takes input strings and transforms them into a\n-dictionary (`token_ids`, `padding_mask`) containing preprocessed tensors. This process\n-starts with tokenization, where input strings are converted into sequences of token IDs.\n-\n-**Why it's important:** Initially, raw text data is complex and challenging for modeling\n-due to its high dimensionality. By converting text into a compact set of tokens, such as\n-transforming `\"The quick brown fox\"` into `[\"the\", \"qu\", \"##ick\", \"br\", \"##own\", \"fox\"]`,\n-we simplify the data. Many models rely on special tokens and additional tensors to\n-understand input. These tokens help divide input and identify padding, among other tasks.\n-Making all sequences the same length through padding boosts computational efficiency,\n-making subsequent steps smoother.\n-\n-Explore the following pages to access the available preprocessing and tokenizer layers in\n-**KerasNLP**:\n-- [Preprocessing](https://keras.io/api/keras_nlp/preprocessing_layers/)\n-- [Tokenizers](https://keras.io/api/keras_nlp/tokenizers/)\n-\"\"\"\n-\n-preprocessor = keras_nlp.models.DebertaV3Preprocessor.from_preset(\n-    preset=CFG.preset,  # Name of the model\n-    sequence_length=CFG.sequence_length,  # Max sequence length, will be padded if shorter\n-)\n-\n-\"\"\"\n-Now, let's examine what the output shape of the preprocessing layer looks like. The\n-output shape of the layer can be represented as $(num\\_choices, sequence\\_length)$.\n-\"\"\"\n-\n-outs = preprocessor(\n-    train_df.options.iloc[0]\n-)  # Process options for the first row\n-\n-# Display the shape of each processed output\n-for k, v in outs.items():\n-    print(k, \":\", v.shape)\n-\n-\"\"\"\n-We'll use the `preprocessing_fn` function to transform each text option using the\n-`dataset.map(preprocessing_fn)` method.\n-\"\"\"\n-\n-\n-def preprocess_fn(text, label=None):\n-    text = preprocessor(text)  # Preprocess text\n-    return (\n-        (text, label) if label is not None else text\n-    )  # Return processed text and label if available\n-\n-\n-\"\"\"\n-## Augmentation\n-\n-In this notebook, we'll experiment with an interesting augmentation technique,\n-`option_shuffle`. Since we're providing the model with one option at a time, we can\n-introduce a shuffle to the order of options. For instance, options `[A, C, E, D, B]`\n-would be rearranged as `[D, B, A, E, C]`. This practice will help the model focus on the\n-content of the options themselves, rather than being influenced by their positions.\n-\n-**Note:** Even though `option_shuffle` function is written in pure\n-tensorflow, it can be used with any backend (e.g. JAX, PyTorch) as it is only used\n-in `tf.data.Dataset` pipeline which is compatible with Keras Core routines.\n-\"\"\"\n-\n-\n-def option_shuffle(options, labels, prob=0.50, seed=None):\n-    if tf.random.uniform([]) > prob:  # Shuffle probability check\n-        return options, labels\n-    # Shuffle indices of options and labels in the same order\n-    indices = tf.random.shuffle(tf.range(tf.shape(options)[0]), seed=seed)\n-    # Shuffle options and labels\n-    options = tf.gather(options, indices)\n-    labels = tf.gather(labels, indices)\n-    return options, labels\n-\n-\n-\"\"\"\n-In the following function, we'll merge all augmentation functions to apply to the text.\n-These augmentations will be applied to the data using the `dataset.map(augment_fn)`\n-approach.\n-\"\"\"\n-\n-\n-def augment_fn(text, label=None):\n-    text, label = option_shuffle(text, label, prob=0.5  # Shuffle the options\n-    return (text, label) if label is not None else text\n-\n-\n-\"\"\"\n-## DataLoader\n-\n-The code below sets up a robust data flow pipeline using `tf.data.Dataset` for data\n-processing. Notable aspects of `tf.data` include its ability to simplify pipeline\n-construction and represent components in sequences.\n-\n-To learn more about `tf.data`, refer to this\n-[documentation](https://www.tensorflow.org/guide/data).\n-\"\"\"\n-\n-\n-def build_dataset(\n-    texts,\n-    labels=None,\n-    batch_size=32,\n-    cache=False,\n-    augment=False,\n-    repeat=False,\n-    shuffle=1024,\n-):\n-    AUTO = tf.data.AUTOTUNE  # AUTOTUNE option\n-    slices = (\n-        (texts,)\n-        if labels is None\n-        else (texts, keras.utils.to_categorical(labels, num_classes=4))\n-    )  # Create slices\n-    ds = tf.data.Dataset.from_tensor_slices(\n-        slices\n-    )  # Create dataset from slices\n-    ds = ds.cache() if cache else ds  # Cache dataset if enabled\n-    if augment:  # Apply augmentation if enabled\n-        ds = ds.map(augment_fn, num_parallel_calls=AUTO)\n-    ds = ds.map(\n-        preprocess_fn, num_parallel_calls=AUTO\n-    )  # Map preprocessing function\n-    ds = ds.repeat() if repeat else ds  # Repeat dataset if enabled\n-    opt = tf.data.Options()  # Create dataset options\n-    if shuffle:\n-        ds = ds.shuffle(shuffle, seed=CFG.seed)  # Shuffle dataset if enabled\n-        opt.experimental_deterministic = False\n-    ds = ds.with_options(opt)  # Set dataset options\n-    ds = ds.batch(batch_size, drop_remainder=True)  # Batch dataset\n-    ds = ds.prefetch(AUTO)  # Prefetch next batch\n-    return ds  # Return the built dataset\n-\n-\n-\"\"\"\n-Now let's create train and valid dataloader using above funciton.\n-\"\"\"\n-\n-# Build train dataloader\n-train_texts = train_df.options.tolist()  # Extract training texts\n-train_labels = train_df.label.tolist()  # Extract training labels\n-train_ds = build_dataset(\n-    train_texts,\n-    train_labels,\n-    batch_size=CFG.batch_size,\n-    cache=True,\n-    shuffle=True,\n-    repeat=True,\n-    augment=CFG.augment,\n-)\n-\n-# Build valid dataloader\n-valid_texts = valid_df.options.tolist()  # Extract validation texts\n-valid_labels = valid_df.label.tolist()  # Extract validation labels\n-valid_ds = build_dataset(\n-    valid_texts,\n-    valid_labels,\n-    batch_size=CFG.batch_size,\n-    cache=True,\n-    shuffle=False,\n-    repeat=False,\n-    augment=False,\n-)\n-\n-\n-\"\"\"\n-## LR Schedule\n-\n-Implementing a learning rate scheduler is crucial for transfer learning. The learning\n-rate initiates at `lr_start` and gradually tapers down to `lr_min` using **cosine**\n-curve.\n-\n-**Importance:** A well-structured learning rate schedule is essential for efficient model\n-training, ensuring optimal convergence and avoiding issues such as overshooting or\n-stagnation.\n-\"\"\"\n-\n-import math\n-\n-\n-def get_lr_callback(batch_size=8, mode=\"cos\", epochs=10, plot=False):\n-    lr_start, lr_max, lr_min = 1.0e-6, 0.6e-6 * batch_size, 1e-6\n-    lr_ramp_ep, lr_sus_ep = 2, 0\n-\n-    def lrfn(epoch):  # Learning rate update function\n-        if epoch < lr_ramp_ep:\n-            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n-        elif epoch < lr_ramp_ep + lr_sus_ep:\n-            lr = lr_max\n-        else:\n-            decay_total_epochs, decay_epoch_index = (\n-                epochs - lr_ramp_ep - lr_sus_ep + 3,\n-                epoch - lr_ramp_ep - lr_sus_ep,\n-            )\n-            phase = math.pi * decay_epoch_index / decay_total_epochs\n-            lr = (lr_max - lr_min) * 0.5 * (1 + math.cos(phase)) + lr_min\n-        return lr\n-\n-    if plot:  # Plot lr curve if plot is True\n-        plt.figure(figsize=(10, 5))\n-        plt.plot(\n-            np.arange(epochs),\n-            [lrfn(epoch) for epoch in np.arange(epochs)],\n-            marker=\"o\",\n-        )\n-        plt.xlabel(\"epoch\")\n-        plt.ylabel(\"lr\")\n-        plt.title(\"LR Scheduler\")\n-        plt.show()\n-\n-    return keras.callbacks.LearningRateScheduler(\n-        lrfn, verbose=False\n-    )  # Create lr callback\n-\n-\n-_ = get_lr_callback(CFG.batch_size, plot=True)\n-\n-\"\"\"\n-## Callbacks\n-\n-The function below will gather all the training callbacks, such as `lr_scheduler`,\n-`model_checkpoint`.\n-\"\"\"\n-\n-\n-def get_callbacks():\n-    callbacks = []\n-    lr_cb = get_lr_callback(CFG.batch_size)  # Get lr callback\n-    ckpt_cb = keras.callbacks.ModelCheckpoint(\n-        f\"best.keras\",\n-        monitor=\"val_accuracy\",\n-        save_best_only=True,\n-        save_weights_only=False,\n-        mode=\"max\",\n-    )  # Get Model checkpoint callback\n-    callbacks.extend([lr_cb, ckpt_cb])  # Add lr and checkpoint callbacks\n-    return callbacks  # Return the list of callbacks\n-\n-\n-callbacks = get_callbacks()\n-\n-\"\"\"\n-## MultipleChoice Model\n-\n-\n-\n-\n-\n-\"\"\"\n-\n-\"\"\"\n-\n-### Pre-trained Models\n-\n-The `KerasNLP` library provides comprehensive, ready-to-use implementations of popular\n-NLP model architectures. It features a variety of pre-trained models including `Bert`,\n-`Roberta`, `DebertaV3`, and more. In this notebook, we'll showcase the usage of\n-`DistillBert`. However, feel free to explore all available models in the [KerasNLP\n-documentation](https://keras.io/api/keras_nlp/models/). Also for a deeper understanding\n-of `KerasNLP`, refer to the informative [getting started\n-guide](https://keras.io/guides/keras_nlp/getting_started/).\n-\n-Our approach involves using `keras_nlp.models.XXClassifier` to process each question and\n-option pari (e.g. (Q+A), (Q+B), etc.), generating logits. These logits are then combined\n-and passed through a softmax function to produce the final output.\n-\"\"\"\n-\n-\"\"\"\n-\n-### Classifier for Multiple-Choice Tasks\n-\n-When dealing with multiple-choice questions, instead of giving the model the question and\n-all options together `(Q + A + B + C ...)`, we provide the model with one option at a\n-time along with the question. For instance, `(Q + A)`, `(Q + B)`, and so on. Once we have\n-the prediction scores (logits) for all options, we combine them using the `Softmax`\n-function to get the ultimate result. If we had given all options at once to the model,\n-the text's length would increase, making it harder for the model to handle. The picture\n-below illustrates this idea:\n-\n-![Model Diagram](https://pbs.twimg.com/media/F3NUju_a8AAS8Fq?format=png&name=large)\n-\n-<div align=\"center\"><b> Picture Credict: </b> <a\n-href=\"https://twitter.com/johnowhitaker\"> @johnowhitaker </a> </div></div><br>\n-\n-From a coding perspective, remember that we use the same model for all five options, with\n-shared weights. Despite the figure suggesting five separate models, they are, in fact,\n-one model with shared weights. Another point to consider is the the input shapes of\n-Classifier and MultipleChoice.\n-\n-* Input shape for **Multiple Choice**: $(batch\\_size, num\\_choices, seq\\_length)$\n-* Input shape for **Classifier**: $(batch\\_size, seq\\_length)$\n-\n-Certainly, it's clear that we can't directly give the data for the multiple-choice task\n-to the model because the input shapes don't match. To handle this, we'll use **slicing**.\n-This means we'll separate the features of each option, like $feature_{(Q + A)}$ and\n-$feature_{(Q + B)}$, and give them one by one to the NLP classifier. After we get the\n-prediction scores $logits_{(Q + A)}$ and $logits_{(Q + B)}$ for all the options, we'll\n-use the Softmax function, like $\\operatorname{Softmax}([logits_{(Q + A)}, logits_{(Q +\n-B)}])$, to combine them. This final step helps us make the ultimate decision or choice.\n-\n-> Note that in the classifier, we set `num_classes=1` instead of `5`. This is because the\n-classifier produces a single output for each option. When dealing with five options,\n-these individual outputs are joined together and then processed through a softmax\n-function to generate the final result, which has a dimension of `5`.\n-\"\"\"\n-\n-# Selects one option from five\n-class SelectOption(keras.layers.Layer):\n-    def __init__(self, index, **kwargs):\n-        super().__init__(**kwargs)\n-        self.index = index\n-\n-    def call(self, inputs):\n-        # Selects a specific slice from the inputs tensor\n-        return inputs[:, self.index, :]\n-\n-    def get_config(self):\n-        # For serialize the model\n-        base_config = super().get_config()\n-        config = {\n-            \"index\": self.index,\n-        }\n-        return {**base_config, **config}\n-\n-\n-def build_model():\n-    # Define input layers\n-    inputs = {\n-        \"token_ids\": keras.Input(\n-            shape=(4, None), dtype=t\"int32\", name=\"token_ids\"\n-        ),\n-        \"padding_mask\": keras.Input(\n-            shape=(4, None), dtype=\"int32\", name=\"padding_mask\"\n-        ),\n-    }\n-    # Create a DebertaV3Classifier model\n-    classifier = keras_nlp.models.DebertaV3Classifier.from_preset(\n-        CFG.preset,\n-        preprocessor=None,\n-        num_classes=1,  # one output per one option, for five options total 5 outputs\n-    )\n-    logits = []\n-    # Loop through each option (Q+A), (Q+B) etc and compute associted logits\n-    for option_idx in range(4):\n-        option = {\n-            k: SelectOption(option_idx, name=f\"{k}_{option_idx}\")(v)\n-            for k, v in inputs.items()\n-        }\n-        logit = classifier(option)\n-        logits.append(logit)\n-\n-    # Compute final output\n-    logits = keras.layers.Concatenate(axis=-1)(logits)\n-    outputs = keras.layers.Softmax(axis=-1)(logits)\n-    model = keras.Model(inputs, outputs)\n-\n-    # Compile the model with optimizer, loss, and metrics\n-    model.compile(\n-        optimizer=keras.optimizers.AdamW(5e-6),\n-        loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.02),\n-        metrics=[\n-            keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n-        ],\n-        jit_compile=True,\n-    )\n-    return model\n-\n-\n-# Build the Build\n-model = build_model()\n-\n-\"\"\"\n-Let's checkout the model summary to have a better insight on the model.\n-\"\"\"\n-\n-model.summary()\n-\n-\"\"\"\n-Finally, let's check the model structure visually if everything is in place.\n-\"\"\"\n-\n-keras.utils.plot_model(model, show_shapes=True)\n-\n-\"\"\"\n-## Training\n-\"\"\"\n-\n-# Start training the model\n-history = model.fit(\n-    train_ds,\n-    epochs=CFG.epochs,\n-    validation_data=valid_ds,\n-    callbacks=callbacks,\n-    steps_per_epoch=int(len(train_df) / CFG.batch_size),\n-    verbose=1,\n-)\n-\n-\"\"\"\n-## Inference\n-\"\"\"\n-\n-# Make predictions using the trained model on last validation data\n-predictions = model.predict(\n-    valid_ds,\n-    batch_size=CFG.batch_size,  # max batch size = valid size\n-    verbose=1,\n-)\n-\n-# Format predictions and true answers\n-pred_answers = np.arange(4)[np.argsort(-predictions)][:, 0]\n-true_answers = valid_df.label.values\n-\n-# Check 5 Predictions\n-print(\"# Predictions\\n\")\n-for i in range(0, 50, 10):\n-    row = valid_df.iloc[i]\n-    question = row.startphrase\n-    pred_answer = f\"ending{pred_answers[i]}\"\n-    true_answer = f\"ending{true_answers[i]}\"\n-    print(f\"❓ Sentence {i+1}:\\n{question}\\n\")\n-    print(f\"✅ True Ending: {true_answer}\\n   >> {row[true_answer]}\\n\")\n-    print(f\"🤖 Predicted Ending: {pred_answer}\\n   >> {row[pred_answer]}\\n\")\n-    print(\"-\" * 90, \"\\n\")\n-\n-\"\"\"\n-## Reference\n-* [Multiple Choice with\n-HF](https://twitter.com/johnowhitaker/status/1689790373454041089?s=20)\n-* [Keras NLP](https://keras.io/api/keras_nlp/)\n-* [BirdCLEF23: Pretraining is All you Need\n-[Train]](https://www.kaggle.com/code/awsaf49/birdclef23-pretraining-is-all-you-need-train)\n-[Train]](https://www.kaggle.com/code/awsaf49/birdclef23-pretraining-is-all-you-need-train)\n-* [Triple Stratified KFold with\n-TFRecords](https://www.kaggle.com/code/cdeotte/triple-stratified-kfold-with-tfrecords)\n-\"\"\"\n\n@@ -1,285 +0,0 @@\n-\"\"\"\n-Title: Fine-tuning a pre-trained TorchVision Model\n-Author: [Ayush Thakur](https://twitter.com/ayushthakur0), [Soumik Rakshit](https://twitter.com/soumikRakshit96)\n-Date created: 2023/09/18\n-Last modified: 2023/09/18\n-Description: Fine-tuning a pre-trained Torch model from TorchVision for image\n-classification using Keras.\n-\"\"\"\n-\"\"\"\n-## Introduction\n-\n-[TorchVision](https://pytorch.org/vision/stable/index.html) is a library part of the\n-[PyTorch](http://pytorch.org/) project that consists of popular datasets, model\n-architectures, and common image transformations for computer vision. This example\n-demonstrates how we can perform transfer learning for image classification using a\n-pre-trained backbone model from TorchVision on the [Imagenette\n-dataset](https://github.com/fastai/imagenette) using KerasCore. We will also demonstrate\n-the compatibility of KerasCore with an input system consisting of [Torch Datasets and\n-Dataloaders](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html).\n-\n-### References:\n-\n-- [Customizing what happens in `fit()` with\n-PyTorch](https://keras.io/keras_core/guides/custom_train_step_in_torch/)\n-- [PyTorch Datasets and\n-Dataloaders](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)\n-- [Transfer learning for Computer Vision using\n-PyTorch](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)\n-- [Fine-tuning a TorchVision Model using Keras\n-](https://wandb.ai/ml-colabs/keras-torch/reports/Fine-tuning-a-TorchVision-Model-using-Keras--Vmlldzo1NDE5NDE1)\n-\n-## Setup\n-\"\"\"\n-\n-import os\n-\n-os.environ[\"KERAS_BACKEND\"] = \"torch\"\n-\n-import numpy as np\n-import matplotlib.pyplot as plt\n-\n-import torch\n-import torch.nn as nn\n-import torch.nn.functional as F\n-\n-import torchvision\n-from torchvision import datasets, models, transforms\n-\n-import keras_core as keras\n-from keras_core.layers import TorchModuleWrapper\n-\n-\"\"\"\n-## Define the Hyperparameters\n-\"\"\"\n-\n-batch_size = 32\n-image_size = 224\n-initial_learning_rate = 1e-3\n-num_epochs = 5\n-\n-\"\"\"\n-## Creating the Torch Datasets and Dataloaders\n-\n-In this example, we would train an image classification model on the [Imagenette\n-dataset](https://github.com/fastai/imagenette). Imagenette is a subset of 10 easily\n-classified classes from [Imagenet](https://www.image-net.org/) (tench, English springer,\n-cassette player, chain saw, church, French horn, garbage truck, gas pump, golf ball,\n-parachute).\n-\"\"\"\n-\n-# Fetch the imagenette dataset\n-data_dir = keras.utils.get_file(\n-    fname=\"imagenette2-320.tgz\",\n-    origin=\"https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-320.tgz\",\n-    extract=True,\n-)\n-data_dir = data_dir.replace(\".tgz\", \"\")\n-\n-\"\"\"\n-Next, we define pre-processing and augmentation transforms from TorchVision for the train\n-and validation sets.\n-\"\"\"\n-\n-data_transforms = {\n-    \"train\": transforms.Compose(\n-        [\n-            transforms.RandomResizedCrop(image_size),\n-            transforms.RandomHorizontalFlip(),\n-            transforms.ToTensor(),\n-            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n-        ]\n-    ),\n-    \"val\": transforms.Compose(\n-        [\n-            transforms.Resize(256),\n-            transforms.CenterCrop(image_size),\n-            transforms.ToTensor(),\n-            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n-        ]\n-    ),\n-}\n-\n-\"\"\"\n-Finally, we will use TorchVision and the\n-[`torch.utils.data`](https://pytorch.org/docs/stable/data.html) packages for creating the\n-dataloaders for trainig and validation.\n-\"\"\"\n-\n-# Define the train and validation datasets\n-image_datasets = {\n-    x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n-    for x in [\"train\", \"val\"]\n-}\n-\n-# Define the torch dataloaders corresponding to the train and validation dataset\n-dataloaders = {\n-    x: torch.utils.data.DataLoader(\n-        image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4\n-    )\n-    for x in [\"train\", \"val\"]\n-}\n-dataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"val\"]}\n-class_names = image_datasets[\"train\"].classes\n-\n-# Specify the global device\n-device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n-\n-\"\"\"\n-Let us visualize a few samples from the training dataloader.\n-\"\"\"\n-\n-plt.figure(figsize=(10, 10))\n-sample_images, sample_labels = next(iter(dataloaders[\"train\"]))\n-sample_images = sample_images.numpy()\n-sample_labels = sample_labels.numpy()\n-for idx in range(9):\n-    ax = plt.subplot(3, 3, idx + 1)\n-    image = sample_images[idx].transpose((1, 2, 0))\n-    mean = np.array([0.485, 0.456, 0.406])\n-    std = np.array([0.229, 0.224, 0.225])\n-    image = std * image + mean\n-    image = np.clip(image, 0, 1)\n-    plt.imshow(image)\n-    plt.title(\"Ground Truth Label: \" + class_names[int(sample_labels[idx])])\n-    plt.axis(\"off\")\n-\n-\"\"\"\n-## The Image Classification Model\n-\"\"\"\n-\n-\"\"\"\n-We typically define a model in PyTorch using\n-[`torch.nn.Module`s](https://pytorch.org/docs/stable/notes/modules.html) which act as the\n-building blocks of stateful computation. Let us define the ResNet18 model from the\n-TorchVision package as a `torch.nn.Module` pre-trained on the [Imagenet1K\n-dataset](https://huggingface.co/datasets/imagenet-1k).\n-\"\"\"\n-\n-# Define the pre-trained resnet18 module from TorchVision\n-resnet_18 = models.resnet18(weights=\"IMAGENET1K_V1\")\n-\n-# We set the classification head of the pre-trained ResNet18\n-# module to an identity module\n-resnet_18.fc = nn.Identity()\n-\n-\"\"\"\n-Even though Keras supports PyTorch as a backend, it does not mean that we can nest torch\n-modules inside a [`keras_core.Model`](https://keras.io/keras_core/api/models/), because\n-trainable variables inside a Keras Model is tracked exclusively via [Keras\n-Layers](https://keras.io/keras_core/api/layers/).\n-\n-KerasCore provides us with a feature called `TorchModuleWrapper` which enables us to do\n-exactly this. The `TorchModuleWrapper` is a Keras Layer that accepts a torch module and\n-tracks its trainable variables, essentially converting the torch module into a Keras\n-Layer. This enables us to put any torch modules inside a Keras Model and train them with\n-a single `model.fit()`!\n-\"\"\"\n-\n-# We set the trainable ResNet18 backbone to be a Keras Layer\n-# using `TorchModuleWrapper`\n-backbone = TorchModuleWrapper(resnet_18)\n-\n-# We set this to `False` if you want to freeze the backbone\n-backbone.trainable = True\n-\n-\"\"\"\n-Now, we will build a Keras functional model with the backbone layer.\n-\"\"\"\n-\n-inputs = keras.Input(shape=(3, image_size, image_size))\n-x = backbone(inputs)\n-x = keras.layers.Dropout(0.5)(x)\n-x = keras.layers.Dense(len(class_names))(x)\n-outputs = keras.activations.softmax(x, axis=1)\n-model = keras.Model(inputs, outputs, name=\"ResNet18_Classifier\")\n-\n-model.summary()\n-\n-# Create exponential decay learning rate scheduler\n-decay_steps = num_epochs * len(dataloaders[\"train\"]) // batch_size\n-lr_scheduler = keras.optimizers.schedules.ExponentialDecay(\n-    initial_learning_rate=initial_learning_rate,\n-    decay_steps=decay_steps,\n-    decay_rate=0.1,\n-)\n-\n-# Compile the model\n-model.compile(\n-    loss=\"sparse_categorical_crossentropy\",\n-    optimizer=keras.optimizers.Adam(lr_scheduler),\n-    metrics=[\"accuracy\"],\n-)\n-\n-# Define the backend-agnostic WandB callbacks for KerasCore\n-callbacks = [\n-    # Save best model checkpoints\n-    keras.callbacks.ModelCheckpoint(\n-        filepath=\"model.weights.h5\",\n-        monitor=\"val_loss\",\n-        save_best_only=True,\n-        save_weights_only=True,\n-    )\n-]\n-\n-# Train the model by calling model.fit\n-history = model.fit(\n-    dataloaders[\"train\"],\n-    validation_data=dataloaders[\"val\"],\n-    epochs=num_epochs,\n-    callbacks=callbacks,\n-)\n-\n-\n-def plot_history(item):\n-    plt.plot(history.history[item], label=item)\n-    plt.plot(history.history[\"val_\" + item], label=\"val_\" + item)\n-    plt.xlabel(\"Epochs\")\n-    plt.ylabel(item)\n-    plt.title(\"Train and Validation {} Over Epochs\".format(item), fontsize=14)\n-    plt.legend()\n-    plt.grid()\n-    plt.show()\n-\n-\n-plot_history(\"loss\")\n-plot_history(\"accuracy\")\n-\n-\"\"\"\n-## Evaluation and Inference\n-\n-Now, we let us load the best model weights checkpoint and evaluate the model.\n-\"\"\"\n-\n-model.load_weights(\"model.weights.h5\")\n-_, val_accuracy = model.evaluate(dataloaders[\"val\"])\n-print(\"Best Validation Accuracy:\", val_accuracy)\n-\n-\"\"\"\n-Finally, let us visualize the some predictions of the model\n-\"\"\"\n-\n-plt.figure(figsize=(10, 10))\n-sample_images, sample_labels = next(iter(dataloaders[\"train\"]))\n-\n-# We perform inference and detach the predicted probabilities from the Torch\n-# computation graph with a tensor that does not require gradient computation.\n-sample_pred_probas = model(sample_images.to(\"cuda\")).detach()\n-sample_pred_logits = keras.ops.argmax(sample_pred_probas, axis=1)\n-sample_pred_logits = sample_pred_logits.to(\"cpu\").numpy()\n-\n-sample_images = sample_images.numpy()\n-sample_labels = sample_labels.numpy()\n-\n-for idx in range(9):\n-    ax = plt.subplot(3, 3, idx + 1)\n-    image = sample_images[idx].transpose((1, 2, 0))\n-    mean = np.array([0.485, 0.456, 0.406])\n-    std = np.array([0.229, 0.224, 0.225])\n-    image = std * image + mean\n-    image = np.clip(image, 0, 1)\n-    plt.imshow(image)\n-    title = \"Ground Truth Label: \" + class_names[int(sample_labels[idx])]\n-    title += \"\\nPredicted Label: \" + class_names[int(sample_pred_logits[idx])]\n-    plt.title(title)\n-    plt.axis(\"off\")\n\n@@ -255,3 +255,48 @@ def compute_conv_transpose_output_shape(\n     else:\n         output_shape = [input_shape[0], filters] + output_shape\n     return output_shape\n+\n+\n+def encode_categorical_inputs(\n+    inputs,\n+    output_mode,\n+    depth,\n+    dtype=\"float32\",\n+    sparse=False,\n+    count_weights=None,\n+):\n+    from keras_core import ops\n+\n+    \"\"\"Encodes categoical inputs according to output_mode.\"\"\"\n+    if output_mode == \"int\":\n+        return ops.identity(ops.cast(inputs, dtype))\n+\n+    original_shape = inputs.shape\n+    # In all cases, we should uprank scalar input to a single sample.\n+    if len(ops.shape(inputs)) == 0:\n+        inputs = ops.expand_dims(inputs, -1)\n+    # One hot will unprank only if the final output dimension is not already 1.\n+    if output_mode == \"one_hot\":\n+        if ops.shape(inputs)[-1] != 1:\n+            inputs = ops.expand_dims(inputs, -1)\n+\n+    if len(ops.shape(inputs)) > 2:\n+        raise ValueError(\n+            \"When output_mode is not `'int'`, maximum supported output rank \"\n+            f\"is 2. Received output_mode {output_mode} and input shape \"\n+            f\"{original_shape}, \"\n+            f\"which would result in output rank {inputs.shape.rank}.\"\n+        )\n+\n+    binary_output = output_mode in (\"multi_hot\", \"one_hot\")\n+    bincounts = ops.bincount(\n+        inputs,\n+        weights=count_weights,\n+        minlength=depth,\n+    )\n+    if binary_output:\n+        one_hot_input = ops.one_hot(inputs, depth)\n+        bincounts = ops.where(ops.any(one_hot_input, axis=-2), 1, 0)\n+    bincounts = ops.cast(bincounts, dtype)\n+\n+    return bincounts\n\n@@ -162,31 +162,3 @@ def affine_transform(\n     if need_squeeze:\n         affined = jnp.squeeze(affined, axis=0)\n     return affined\n-\n-\n-MAP_COORDINATES_FILL_MODES = {\n-    \"constant\",\n-    \"nearest\",\n-    \"wrap\",\n-    \"mirror\",\n-    \"reflect\",\n-}\n-\n-\n-def map_coordinates(\n-    input, coordinates, order, fill_mode=\"constant\", fill_value=0.0\n-):\n-    if fill_mode not in MAP_COORDINATES_FILL_MODES:\n-        raise ValueError(\n-            \"Invalid value for argument `fill_mode`. Expected one of \"\n-            f\"{set(MAP_COORDINATES_FILL_MODES)}. Received: \"\n-            f\"fill_mode={fill_mode}\"\n-        )\n-    if order not in range(2):\n-        raise ValueError(\n-            \"Invalid value for argument `order`. Expected one of \"\n-            f\"{[0, 1]}. Received: order={order}\"\n-        )\n-    return jax.scipy.ndimage.map_coordinates(\n-        input, coordinates, order, fill_mode, fill_value\n-    )\n\n@@ -96,8 +96,6 @@ def append(\n     x2,\n     axis=None,\n ):\n-    x1 = convert_to_tensor(x1)\n-    x2 = convert_to_tensor(x2)\n     return jnp.append(x1, x2, axis=axis)\n \n \n@@ -274,14 +272,10 @@ def full_like(x, fill_value, dtype=None):\n \n \n def greater(x1, x2):\n-    x1 = convert_to_tensor(x1)\n-    x2 = convert_to_tensor(x2)\n     return jnp.greater(x1, x2)\n \n \n def greater_equal(x1, x2):\n-    x1 = convert_to_tensor(x1)\n-    x2 = convert_to_tensor(x2)\n     return jnp.greater_equal(x1, x2)\n \n \n@@ -298,8 +292,6 @@ def imag(x):\n \n \n def isclose(x1, x2):\n-    x1 = convert_to_tensor(x1)\n-    x2 = convert_to_tensor(x2)\n     return jnp.isclose(x1, x2)\n \n \n@@ -316,14 +308,10 @@ def isnan(x):\n \n \n def less(x1, x2):\n-    x1 = convert_to_tensor(x1)\n-    x2 = convert_to_tensor(x2)\n     return jnp.less(x1, x2)\n \n \n def less_equal(x1, x2):\n-    x1 = convert_to_tensor(x1)\n-    x2 = convert_to_tensor(x2)\n     return jnp.less_equal(x1, x2)\n \n \n@@ -358,14 +346,10 @@ def log2(x):\n \n \n def logaddexp(x1, x2):\n-    x1 = convert_to_tensor(x1)\n-    x2 = convert_to_tensor(x2)\n     return jnp.logaddexp(x1, x2)\n \n \n def logical_and(x1, x2):\n-    x1 = convert_to_tensor(x1)\n-    x2 = convert_to_tensor(x2)\n     return jnp.logical_and(x1, x2)\n \n \n@@ -374,8 +358,6 @@ def logical_not(x):\n \n \n def logical_or(x1, x2):\n-    x1 = convert_to_tensor(x1)\n-    x2 = convert_to_tensor(x2)\n     return jnp.logical_or(x1, x2)\n \n \n@@ -392,8 +374,6 @@ def logspace(start, stop, num=50, endpoint=True, base=10, dtype=None, axis=0):\n \n \n def maximum(x1, x2):\n-    x1 = convert_to_tensor(x1)\n-    x2 = convert_to_tensor(x2)\n     return jnp.maximum(x1, x2)\n \n \n@@ -406,14 +386,10 @@ def min(x, axis=None, keepdims=False, initial=None):\n \n \n def minimum(x1, x2):\n-    x1 = convert_to_tensor(x1)\n-    x2 = convert_to_tensor(x2)\n     return jnp.minimum(x1, x2)\n \n \n def mod(x1, x2):\n-    x1 = convert_to_tensor(x1)\n-    x2 = convert_to_tensor(x2)\n     return jnp.mod(x1, x2)\n \n \n@@ -434,8 +410,6 @@ def nonzero(x):\n \n \n def not_equal(x1, x2):\n-    x1 = convert_to_tensor(x1)\n-    x2 = convert_to_tensor(x2)\n     return jnp.not_equal(x1, x2)\n \n \n@@ -576,8 +550,6 @@ def vstack(xs):\n \n \n def where(condition, x1, x2):\n-    x1 = convert_to_tensor(x1)\n-    x2 = convert_to_tensor(x2)\n     return jnp.where(condition, x1, x2)\n \n \n@@ -588,14 +560,10 @@ def divide(x1, x2):\n \n \n def true_divide(x1, x2):\n-    x1 = convert_to_tensor(x1)\n-    x2 = convert_to_tensor(x2)\n     return jnp.true_divide(x1, x2)\n \n \n def power(x1, x2):\n-    x1 = convert_to_tensor(x1)\n-    x2 = convert_to_tensor(x2)\n     return jnp.power(x1, x2)\n \n \n@@ -641,12 +609,8 @@ def eye(N, M=None, k=0, dtype=\"float32\"):\n \n \n def floor_divide(x1, x2):\n-    x1 = convert_to_tensor(x1)\n-    x2 = convert_to_tensor(x2)\n     return jnp.floor_divide(x1, x2)\n \n \n def logical_xor(x1, x2):\n-    x1 = convert_to_tensor(x1)\n-    x2 = convert_to_tensor(x2)\n     return jnp.logical_xor(x1, x2)\n\n@@ -79,8 +79,3 @@ def dropout(inputs, rate, noise_shape=None, seed=None):\n     return jax.lax.select(\n         mask, inputs / keep_prob, jax.numpy.zeros_like(inputs)\n     )\n-\n-\n-def shuffle(x, axis=0, seed=None):\n-    seed = jax_draw_seed(seed)\n-    return jax.random.shuffle(seed, x, axis)\n\n@@ -173,55 +173,3 @@ def affine_transform(\n     if input_dtype == \"float16\":\n         affined = affined.astype(input_dtype)\n     return affined\n-\n-\n-MAP_COORDINATES_FILL_MODES = {\n-    \"constant\",\n-    \"nearest\",\n-    \"wrap\",\n-    \"mirror\",\n-    \"reflect\",\n-}\n-\n-\n-def map_coordinates(\n-    input, coordinates, order, fill_mode=\"constant\", fill_value=0.0\n-):\n-    if fill_mode not in MAP_COORDINATES_FILL_MODES:\n-        raise ValueError(\n-            \"Invalid value for argument `fill_mode`. Expected one of \"\n-            f\"{set(MAP_COORDINATES_FILL_MODES.keys())}. Received: \"\n-            f\"fill_mode={fill_mode}\"\n-        )\n-    if order not in range(2):\n-        raise ValueError(\n-            \"Invalid value for argument `order`. Expected one of \"\n-            f\"{[0, 1]}. Received: order={order}\"\n-        )\n-    # SciPy's implementation of map_coordinates handles boundaries incorrectly,\n-    # unless mode='reflect'. For order=1, this only affects interpolation\n-    # outside the bounds of the original array.\n-    # https://github.com/scipy/scipy/issues/2640\n-    padding = [\n-        (\n-            max(-np.floor(c.min()).astype(int) + 1, 0),\n-            max(np.ceil(c.max()).astype(int) + 1 - size, 0),\n-        )\n-        for c, size in zip(coordinates, input.shape)\n-    ]\n-    shifted_coords = [c + p[0] for p, c in zip(padding, coordinates)]\n-    pad_mode = {\n-        \"nearest\": \"edge\",\n-        \"mirror\": \"reflect\",\n-        \"reflect\": \"symmetric\",\n-    }.get(fill_mode, fill_mode)\n-    if fill_mode == \"constant\":\n-        padded = np.pad(\n-            input, padding, mode=pad_mode, constant_values=fill_value\n-        )\n-    else:\n-        padded = np.pad(input, padding, mode=pad_mode)\n-    result = scipy.ndimage.map_coordinates(\n-        padded, shifted_coords, order=order, mode=fill_mode, cval=fill_value\n-    )\n-    return result\n\n@@ -86,9 +86,3 @@ def dropout(inputs, rate, noise_shape=None, seed=None):\n     mask = rng.uniform(size=noise_shape) < keep_prob\n     mask = np.broadcast_to(mask, inputs.shape)\n     return np.where(mask, inputs / keep_prob, np.zeros_like(inputs))\n-\n-\n-def shuffle(x, axis=0, seed=None):\n-    seed = draw_seed(seed)\n-    rng = np.random.default_rng(seed)\n-    return rng.permuted(x, axis=axis)\n\n@@ -1,11 +1,5 @@\n-import functools\n-import itertools\n-import operator\n-\n import tensorflow as tf\n \n-from keras_core.backend.tensorflow.core import convert_to_tensor\n-\n RESIZE_INTERPOLATIONS = (\n     \"bilinear\",\n     \"nearest\",\n@@ -125,114 +119,3 @@ def affine_transform(\n     if need_squeeze:\n         affined = tf.squeeze(affined, axis=0)\n     return affined\n-\n-\n-def _mirror_index_fixer(index, size):\n-    s = size - 1  # Half-wavelength of triangular wave\n-    # Scaled, integer-valued version of the triangular wave |x - round(x)|\n-    return tf.abs((index + s) % (2 * s) - s)\n-\n-\n-def _reflect_index_fixer(index, size):\n-    return tf.math.floordiv(\n-        _mirror_index_fixer(2 * index + 1, 2 * size + 1) - 1, 2\n-    )\n-\n-\n-_INDEX_FIXERS = {\n-    \"constant\": lambda index, size: index,\n-    \"nearest\": lambda index, size: tf.clip_by_value(index, 0, size - 1),\n-    \"wrap\": lambda index, size: index % size,\n-    \"mirror\": _mirror_index_fixer,\n-    \"reflect\": _reflect_index_fixer,\n-}\n-\n-\n-def _nearest_indices_and_weights(coordinate):\n-    coordinate = (\n-        coordinate if coordinate.dtype.is_integer else tf.round(coordinate)\n-    )\n-    index = tf.cast(coordinate, tf.int32)\n-    weight = tf.constant(1, coordinate.dtype)\n-    return [(index, weight)]\n-\n-\n-def _linear_indices_and_weights(coordinate):\n-    lower = tf.floor(coordinate)\n-    upper_weight = coordinate - lower\n-    lower_weight = 1 - upper_weight\n-    index = tf.cast(lower, tf.int32)\n-    return [(index, lower_weight), (index + 1, upper_weight)]\n-\n-\n-def map_coordinates(\n-    input, coordinates, order, fill_mode=\"constant\", fill_value=0.0\n-):\n-    input_arr = convert_to_tensor(input)\n-    coordinate_arrs = convert_to_tensor(coordinates)\n-    # unstack into a list of tensors for following operations\n-    coordinate_arrs = tf.unstack(coordinate_arrs, axis=0)\n-    fill_value = convert_to_tensor(tf.cast(fill_value, input_arr.dtype))\n-\n-    if len(coordinates) != len(input_arr.shape):\n-        raise ValueError(\n-            \"coordinates must be a sequence of length input.shape, but \"\n-            f\"{len(coordinates)} != {len(input_arr.shape)}\"\n-        )\n-\n-    index_fixer = _INDEX_FIXERS.get(fill_mode)\n-    if index_fixer is None:\n-        raise ValueError(\n-            \"Invalid value for argument `fill_mode`. Expected one of \"\n-            f\"{set(_INDEX_FIXERS.keys())}. Received: \"\n-            f\"fill_mode={fill_mode}\"\n-        )\n-\n-    def is_valid(index, size):\n-        if fill_mode == \"constant\":\n-            return (0 <= index) & (index < size)\n-        else:\n-            return True\n-\n-    if order == 0:\n-        interp_fun = _nearest_indices_and_weights\n-    elif order == 1:\n-        interp_fun = _linear_indices_and_weights\n-    else:\n-        raise NotImplementedError(\"map_coordinates currently requires order<=1\")\n-\n-    valid_1d_interpolations = []\n-    for coordinate, size in zip(coordinate_arrs, input_arr.shape):\n-        interp_nodes = interp_fun(coordinate)\n-        valid_interp = []\n-        for index, weight in interp_nodes:\n-            fixed_index = index_fixer(index, size)\n-            valid = is_valid(index, size)\n-            valid_interp.append((fixed_index, valid, weight))\n-        valid_1d_interpolations.append(valid_interp)\n-\n-    outputs = []\n-    for items in itertools.product(*valid_1d_interpolations):\n-        indices, validities, weights = zip(*items)\n-        indices = tf.transpose(tf.stack(indices))\n-\n-        def fast_path():\n-            return tf.transpose(tf.gather_nd(input_arr, indices))\n-\n-        def slow_path():\n-            all_valid = functools.reduce(operator.and_, validities)\n-            return tf.where(\n-                all_valid,\n-                tf.transpose(tf.gather_nd(input_arr, indices)),\n-                fill_value,\n-            )\n-\n-        contribution = tf.cond(tf.reduce_all(validities), fast_path, slow_path)\n-        outputs.append(\n-            functools.reduce(operator.mul, weights)\n-            * tf.cast(contribution, weights[0].dtype)\n-        )\n-    result = functools.reduce(operator.add, outputs)\n-    if input_arr.dtype.is_integer:\n-        result = result if result.dtype.is_integer else tf.round(result)\n-    return tf.cast(result, input_arr.dtype)\n\n@@ -1,5 +1,4 @@\n import tensorflow as tf\n-from tensorflow.experimental import numpy as tfnp\n \n from keras_core.backend.common import standardize_dtype\n from keras_core.backend.config import floatx\n@@ -84,13 +83,3 @@ def dropout(inputs, rate, noise_shape=None, seed=None):\n         noise_shape=noise_shape,\n         seed=seed,\n     )\n-\n-\n-def shuffle(x, axis=0, seed=None):\n-    seed = tf_draw_seed(seed)\n-    if axis == 0:\n-        return tf.random.experimental.stateless_shuffle(x, seed=seed)\n-    x = tfnp.swapaxes(x, axis1=0, axis2=axis)\n-    x = tf.random.experimental.stateless_shuffle(x, seed=seed)\n-    x = tfnp.swapaxes(x, axis1=0, axis2=axis)\n-    return x\n\n@@ -1,7 +1,3 @@\n-import functools\n-import itertools\n-import operator\n-\n import torch\n import torch.nn.functional as tnn\n \n@@ -267,109 +263,3 @@ def affine_transform(\n     if need_squeeze:\n         affined = affined.squeeze(dim=0)\n     return affined\n-\n-\n-def _mirror_index_fixer(index, size):\n-    s = size - 1  # Half-wavelength of triangular wave\n-    # Scaled, integer-valued version of the triangular wave |x - round(x)|\n-    return torch.abs((index + s) % (2 * s) - s)\n-\n-\n-def _reflect_index_fixer(index, size):\n-    return torch.floor_divide(\n-        _mirror_index_fixer(2 * index + 1, 2 * size + 1) - 1, 2\n-    )\n-\n-\n-_INDEX_FIXERS = {\n-    \"constant\": lambda index, size: index,\n-    \"nearest\": lambda index, size: torch.clip(index, 0, size - 1),\n-    \"wrap\": lambda index, size: index % size,\n-    \"mirror\": _mirror_index_fixer,\n-    \"reflect\": _reflect_index_fixer,\n-}\n-\n-\n-def _is_integer(a):\n-    if not torch.is_floating_point(a) and not torch.is_complex(a):\n-        return True\n-    return False\n-\n-\n-def _nearest_indices_and_weights(coordinate):\n-    coordinate = (\n-        coordinate if _is_integer(coordinate) else torch.round(coordinate)\n-    )\n-    index = coordinate.to(torch.int32)\n-    weight = torch.tensor(1).to(torch.int32)\n-    return [(index, weight)]\n-\n-\n-def _linear_indices_and_weights(coordinate):\n-    lower = torch.floor(coordinate)\n-    upper_weight = coordinate - lower\n-    lower_weight = 1 - upper_weight\n-    index = lower.to(torch.int32)\n-    return [(index, lower_weight), (index + 1, upper_weight)]\n-\n-\n-def map_coordinates(\n-    input, coordinates, order, fill_mode=\"constant\", fill_value=0.0\n-):\n-    input_arr = convert_to_tensor(input)\n-    coordinate_arrs = [convert_to_tensor(c) for c in coordinates]\n-    fill_value = convert_to_tensor(fill_value, input_arr.dtype)\n-\n-    if len(coordinates) != len(input_arr.shape):\n-        raise ValueError(\n-            \"coordinates must be a sequence of length input.shape, but \"\n-            f\"{len(coordinates)} != {len(input_arr.shape)}\"\n-        )\n-\n-    index_fixer = _INDEX_FIXERS.get(fill_mode)\n-    if index_fixer is None:\n-        raise ValueError(\n-            \"Invalid value for argument `fill_mode`. Expected one of \"\n-            f\"{set(_INDEX_FIXERS.keys())}. Received: \"\n-            f\"fill_mode={fill_mode}\"\n-        )\n-\n-    def is_valid(index, size):\n-        if fill_mode == \"constant\":\n-            return (0 <= index) & (index < size)\n-        else:\n-            return True\n-\n-    if order == 0:\n-        interp_fun = _nearest_indices_and_weights\n-    elif order == 1:\n-        interp_fun = _linear_indices_and_weights\n-    else:\n-        raise NotImplementedError(\"map_coordinates currently requires order<=1\")\n-\n-    valid_1d_interpolations = []\n-    for coordinate, size in zip(coordinate_arrs, input_arr.shape):\n-        interp_nodes = interp_fun(coordinate)\n-        valid_interp = []\n-        for index, weight in interp_nodes:\n-            fixed_index = index_fixer(index, size)\n-            valid = is_valid(index, size)\n-            valid_interp.append((fixed_index, valid, weight))\n-        valid_1d_interpolations.append(valid_interp)\n-\n-    outputs = []\n-    for items in itertools.product(*valid_1d_interpolations):\n-        indices, validities, weights = zip(*items)\n-        if all(valid is True for valid in validities):\n-            # fast path\n-            contribution = input_arr[indices]\n-        else:\n-            all_valid = functools.reduce(operator.and_, validities)\n-            contribution = torch.where(\n-                all_valid, input_arr[indices], fill_value\n-            )\n-        outputs.append(functools.reduce(operator.mul, weights) * contribution)\n-    result = functools.reduce(operator.add, outputs)\n-    if _is_integer(input_arr):\n-        result = result if _is_integer(result) else torch.round(result)\n-    return result.to(input_arr.dtype)\n\n@@ -800,34 +800,22 @@ def sort(x, axis=-1):\n \n def split(x, indices_or_sections, axis=0):\n     x = convert_to_tensor(x)\n-    dim = x.shape[axis]\n     if isinstance(indices_or_sections, (list, tuple)):\n         idxs = convert_to_tensor(indices_or_sections)\n         start_size = indices_or_sections[0]\n-        end_size = dim - indices_or_sections[-1]\n+        end_size = x.shape[axis] - indices_or_sections[-1]\n         chunk_sizes = (\n             [start_size]\n             + torch.diff(idxs).type(torch.int).tolist()\n             + [end_size]\n         )\n     else:\n-        if dim % indices_or_sections != 0:\n-            raise ValueError(\n-                f\"Received indices_or_sections={indices_or_sections} \"\n-                f\"(interpreted as a number of sections) and axis={axis}, \"\n-                f\"but input dimension x.shape[{axis}]={x.shape[axis]} \"\n-                f\"is not divisible by {indices_or_sections}. \"\n-                f\"Full input shape: x.shape={x.shape}\"\n-            )\n-        chunk_sizes = dim // indices_or_sections\n-    out = torch.split(\n+        chunk_sizes = x.shape[axis] // indices_or_sections\n+    return torch.split(\n         tensor=x,\n         split_size_or_sections=chunk_sizes,\n         dim=axis,\n     )\n-    if dim == 0 and isinstance(indices_or_sections, int):\n-        out = tuple(out[0].clone() for _ in range(indices_or_sections))\n-    return out\n \n \n def stack(x, axis=0):\n\n@@ -160,28 +160,3 @@ def dropout(inputs, rate, noise_shape=None, seed=None):\n     return torch.nn.functional.dropout(\n         inputs, p=rate, training=True, inplace=False\n     )\n-\n-\n-def shuffle(x, axis=0, seed=None):\n-    # Ref: https://github.com/pytorch/pytorch/issues/71409\n-    x = convert_to_tensor(x)\n-\n-    # Get permutation indices\n-    # Do not use generator during symbolic execution.\n-    if get_device() == \"meta\":\n-        row_perm = torch.rand(x.shape[: axis + 1], device=get_device()).argsort(\n-            axis\n-        )\n-    else:\n-        generator = torch_seed_generator(seed)\n-        row_perm = torch.rand(\n-            x.shape[: axis + 1], generator=generator, device=get_device()\n-        ).argsort(axis)\n-    for _ in range(x.ndim - axis - 1):\n-        row_perm.unsqueeze_(-1)\n-\n-    # Reformat this for the gather operation\n-    row_perm = row_perm.repeat(\n-        *[1 for _ in range(axis + 1)], *(x.shape[axis + 1 :])\n-    )\n-    return x.gather(axis, row_perm)\n\n@@ -1,97 +1,21 @@\n import numpy as np\n import pytest\n-from absl.testing import parameterized\n \n from keras_core import backend\n from keras_core import layers\n from keras_core import models\n+from keras_core import ops\n from keras_core import testing\n \n \n-def np_dot(a, b, axes):\n-    if isinstance(axes, int):\n-        axes = (axes, axes)\n-    axes = [axis if axis < 0 else axis - 1 for axis in axes]\n-    res = np.stack([np.tensordot(a[i], b[i], axes) for i in range(a.shape[0])])\n-    if len(res.shape) == 1:\n-        res = np.expand_dims(res, axis=1)\n-    return res\n-\n-\n-TEST_PARAMETERS = [\n-    {\n-        \"testcase_name\": \"add\",\n-        \"layer_class\": layers.Add,\n-        \"np_op\": np.add,\n-    },\n-    {\n-        \"testcase_name\": \"substract\",\n-        \"layer_class\": layers.Subtract,\n-        \"np_op\": np.subtract,\n-    },\n-    {\n-        \"testcase_name\": \"minimum\",\n-        \"layer_class\": layers.Minimum,\n-        \"np_op\": np.minimum,\n-    },\n-    {\n-        \"testcase_name\": \"maximum\",\n-        \"layer_class\": layers.Maximum,\n-        \"np_op\": np.maximum,\n-    },\n-    {\n-        \"testcase_name\": \"multiply\",\n-        \"layer_class\": layers.Multiply,\n-        \"np_op\": np.multiply,\n-    },\n-    {\n-        \"testcase_name\": \"average\",\n-        \"layer_class\": layers.Average,\n-        \"np_op\": lambda a, b: np.multiply(np.add(a, b), 0.5),\n-    },\n-    {\n-        \"testcase_name\": \"concat\",\n-        \"layer_class\": layers.Concatenate,\n-        \"np_op\": lambda a, b, **kwargs: np.concatenate((a, b), **kwargs),\n-        \"init_kwargs\": {\"axis\": -1},\n-        \"expected_output_shape\": (2, 4, 10),\n-    },\n-    {\n-        \"testcase_name\": \"dot_2d\",\n-        \"layer_class\": layers.Dot,\n-        \"np_op\": np_dot,\n-        \"init_kwargs\": {\"axes\": -1},\n-        \"input_shape\": (2, 4),\n-        \"expected_output_shape\": (2, 1),\n-        \"skip_mask_test\": True,\n-    },\n-    {\n-        \"testcase_name\": \"dot_3d\",\n-        \"layer_class\": layers.Dot,\n-        \"np_op\": np_dot,\n-        \"init_kwargs\": {\"axes\": -1},\n-        \"expected_output_shape\": (2, 4, 4),\n-        \"skip_mask_test\": True,\n-    },\n-]\n-\n-\n @pytest.mark.requires_trainable_backend\n-class MergingLayersTest(testing.TestCase, parameterized.TestCase):\n-    @parameterized.named_parameters(TEST_PARAMETERS)\n-    def test_basic(\n-        self,\n-        layer_class,\n-        init_kwargs={},\n-        input_shape=(2, 4, 5),\n-        expected_output_shape=(2, 4, 5),\n-        **kwargs\n-    ):\n+class MergingLayersTest(testing.TestCase):\n+    def test_add_basic(self):\n         self.run_layer_test(\n-            layer_class,\n-            init_kwargs=init_kwargs,\n-            input_shape=[input_shape, input_shape],\n-            expected_output_shape=expected_output_shape,\n+            layers.Add,\n+            init_kwargs={},\n+            input_shape=[(2, 3), (2, 3)],\n+            expected_output_shape=(2, 3),\n             expected_num_trainable_weights=0,\n             expected_num_non_trainable_weights=0,\n             expected_num_seed_generators=0,\n@@ -99,37 +23,57 @@ class MergingLayersTest(testing.TestCase, parameterized.TestCase):\n             supports_masking=True,\n         )\n \n-    @parameterized.named_parameters(TEST_PARAMETERS)\n-    def test_correctness_static(\n-        self,\n-        layer_class,\n-        np_op,\n-        init_kwargs={},\n-        input_shape=(2, 4, 5),\n-        expected_output_shape=(2, 4, 5),\n-        skip_mask_test=False,\n-    ):\n-        batch_size = input_shape[0]\n-        shape = input_shape[1:]\n-        x1 = np.random.rand(*input_shape)\n-        x2 = np.random.rand(*input_shape)\n-        x3 = np_op(x1, x2, **init_kwargs)\n+    def test_add_correctness_dynamic(self):\n+        x1 = np.random.rand(2, 4, 5)\n+        x2 = np.random.rand(2, 4, 5)\n+        x3 = ops.convert_to_tensor(x1 + x2)\n+\n+        input_1 = layers.Input(shape=(4, 5))\n+        input_2 = layers.Input(shape=(4, 5))\n+        add_layer = layers.Add()\n+        out = add_layer([input_1, input_2])\n+        model = models.Model([input_1, input_2], out)\n+        res = model([x1, x2])\n+\n+        self.assertEqual(res.shape, (2, 4, 5))\n+        self.assertAllClose(res, x3, atol=1e-4)\n+        self.assertIsNone(\n+            add_layer.compute_mask([input_1, input_2], [None, None])\n+        )\n+        self.assertTrue(\n+            np.all(\n+                backend.convert_to_numpy(\n+                    add_layer.compute_mask(\n+                        [input_1, input_2],\n+                        [backend.Variable(x1), backend.Variable(x2)],\n+                    )\n+                )\n+            )\n+        )\n+\n+    def test_add_correctness_static(self):\n+        batch_size = 2\n+        shape = (4, 5)\n+        x1 = np.random.rand(batch_size, *shape)\n+        x2 = np.random.rand(batch_size, *shape)\n+        x3 = ops.convert_to_tensor(x1 + x2)\n \n         input_1 = layers.Input(shape=shape, batch_size=batch_size)\n         input_2 = layers.Input(shape=shape, batch_size=batch_size)\n-        layer = layer_class(**init_kwargs)\n-        out = layer([input_1, input_2])\n+        add_layer = layers.Add()\n+        out = add_layer([input_1, input_2])\n         model = models.Model([input_1, input_2], out)\n         res = model([x1, x2])\n \n-        self.assertEqual(res.shape, expected_output_shape)\n+        self.assertEqual(res.shape, (batch_size, *shape))\n         self.assertAllClose(res, x3, atol=1e-4)\n-        self.assertIsNone(layer.compute_mask([input_1, input_2], [None, None]))\n-        if not skip_mask_test:\n+        self.assertIsNone(\n+            add_layer.compute_mask([input_1, input_2], [None, None])\n+        )\n         self.assertTrue(\n             np.all(\n                 backend.convert_to_numpy(\n-                        layer.compute_mask(\n+                    add_layer.compute_mask(\n                         [input_1, input_2],\n                         [backend.Variable(x1), backend.Variable(x2)],\n                     )\n@@ -137,81 +81,117 @@ class MergingLayersTest(testing.TestCase, parameterized.TestCase):\n             )\n         )\n \n-    @parameterized.named_parameters(TEST_PARAMETERS)\n-    def test_correctness_dynamic(\n-        self,\n-        layer_class,\n-        np_op,\n-        init_kwargs={},\n-        input_shape=(2, 4, 5),\n-        expected_output_shape=(2, 4, 5),\n-        skip_mask_test=False,\n-    ):\n-        shape = input_shape[1:]\n-        x1 = np.random.rand(*input_shape)\n-        x2 = np.random.rand(*input_shape)\n-        x3 = np_op(x1, x2, **init_kwargs)\n-\n-        input_1 = layers.Input(shape=shape)\n-        input_2 = layers.Input(shape=shape)\n-        layer = layer_class(**init_kwargs)\n-        out = layer([input_1, input_2])\n-        model = models.Model([input_1, input_2], out)\n-        res = model([x1, x2])\n-\n-        self.assertEqual(res.shape, expected_output_shape)\n-        self.assertAllClose(res, x3, atol=1e-4)\n-        self.assertIsNone(layer.compute_mask([input_1, input_2], [None, None]))\n-        if not skip_mask_test:\n-            self.assertTrue(\n-                np.all(\n-                    backend.convert_to_numpy(\n-                        layer.compute_mask(\n-                            [input_1, input_2],\n-                            [backend.Variable(x1), backend.Variable(x2)],\n-                        )\n-                    )\n-                )\n-            )\n-\n-    @parameterized.named_parameters(TEST_PARAMETERS)\n-    def test_errors(\n-        self,\n-        layer_class,\n-        init_kwargs={},\n-        input_shape=(2, 4, 5),\n-        skip_mask_test=False,\n-        **kwargs\n-    ):\n-        if skip_mask_test:\n-            pytest.skip(\"Masking not supported\")\n-\n-        batch_size = input_shape[0]\n-        shape = input_shape[1:]\n-        x1 = np.random.rand(*input_shape)\n+    def test_add_errors(self):\n+        batch_size = 2\n+        shape = (4, 5)\n         x1 = np.random.rand(batch_size, *shape)\n \n         input_1 = layers.Input(shape=shape, batch_size=batch_size)\n         input_2 = layers.Input(shape=shape, batch_size=batch_size)\n-        layer = layer_class(**init_kwargs)\n+        add_layer = layers.Add()\n \n         with self.assertRaisesRegex(ValueError, \"`mask` should be a list.\"):\n-            layer.compute_mask([input_1, input_2], x1)\n+            add_layer.compute_mask([input_1, input_2], x1)\n \n         with self.assertRaisesRegex(ValueError, \"`inputs` should be a list.\"):\n-            layer.compute_mask(input_1, [None, None])\n+            add_layer.compute_mask(input_1, [None, None])\n \n         with self.assertRaisesRegex(\n             ValueError, \" should have the same length.\"\n         ):\n-            layer.compute_mask([input_1, input_2], [None])\n+            add_layer.compute_mask([input_1, input_2], [None])\n \n-    def test_subtract_layer_inputs_length_errors(self):\n+    def test_subtract_basic(self):\n+        self.run_layer_test(\n+            layers.Subtract,\n+            init_kwargs={},\n+            input_shape=[(2, 3), (2, 3)],\n+            expected_output_shape=(2, 3),\n+            expected_num_trainable_weights=0,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_seed_generators=0,\n+            expected_num_losses=0,\n+            supports_masking=True,\n+        )\n+\n+    def test_subtract_correctness_dynamic(self):\n+        x1 = np.random.rand(2, 4, 5)\n+        x2 = np.random.rand(2, 4, 5)\n+        x3 = ops.convert_to_tensor(x1 - x2)\n+\n+        input_1 = layers.Input(shape=(4, 5))\n+        input_2 = layers.Input(shape=(4, 5))\n+        subtract_layer = layers.Subtract()\n+        out = subtract_layer([input_1, input_2])\n+        model = models.Model([input_1, input_2], out)\n+        res = model([x1, x2])\n+\n+        self.assertEqual(res.shape, (2, 4, 5))\n+        self.assertAllClose(res, x3, atol=1e-4)\n+        self.assertIsNone(\n+            subtract_layer.compute_mask([input_1, input_2], [None, None])\n+        )\n+        self.assertTrue(\n+            np.all(\n+                backend.convert_to_numpy(\n+                    subtract_layer.compute_mask(\n+                        [input_1, input_2],\n+                        [backend.Variable(x1), backend.Variable(x2)],\n+                    )\n+                )\n+            )\n+        )\n+\n+    def test_subtract_correctness_static(self):\n+        batch_size = 2\n         shape = (4, 5)\n-        input_1 = layers.Input(shape=shape)\n-        input_2 = layers.Input(shape=shape)\n-        input_3 = layers.Input(shape=shape)\n+        x1 = np.random.rand(batch_size, *shape)\n+        x2 = np.random.rand(batch_size, *shape)\n+        x3 = ops.convert_to_tensor(x1 - x2)\n \n+        input_1 = layers.Input(shape=shape, batch_size=batch_size)\n+        input_2 = layers.Input(shape=shape, batch_size=batch_size)\n+        subtract_layer = layers.Subtract()\n+        out = subtract_layer([input_1, input_2])\n+        model = models.Model([input_1, input_2], out)\n+        res = model([x1, x2])\n+\n+        self.assertEqual(res.shape, (batch_size, *shape))\n+        self.assertAllClose(res, x3, atol=1e-4)\n+        self.assertIsNone(\n+            subtract_layer.compute_mask([input_1, input_2], [None, None])\n+        )\n+        self.assertTrue(\n+            np.all(\n+                backend.convert_to_numpy(\n+                    subtract_layer.compute_mask(\n+                        [input_1, input_2],\n+                        [backend.Variable(x1), backend.Variable(x2)],\n+                    )\n+                )\n+            )\n+        )\n+\n+    def test_subtract_errors(self):\n+        batch_size = 2\n+        shape = (4, 5)\n+        x1 = np.random.rand(batch_size, *shape)\n+\n+        input_1 = layers.Input(shape=shape, batch_size=batch_size)\n+        input_2 = layers.Input(shape=shape, batch_size=batch_size)\n+        input_3 = layers.Input(shape=shape, batch_size=batch_size)\n+        subtract_layer = layers.Subtract()\n+\n+        with self.assertRaisesRegex(ValueError, \"`mask` should be a list.\"):\n+            subtract_layer.compute_mask([input_1, input_2], x1)\n+\n+        with self.assertRaisesRegex(ValueError, \"`inputs` should be a list.\"):\n+            subtract_layer.compute_mask(input_1, [None, None])\n+\n+        with self.assertRaisesRegex(\n+            ValueError, \" should have the same length.\"\n+        ):\n+            subtract_layer.compute_mask([input_1, input_2], [None])\n         with self.assertRaisesRegex(\n             ValueError, \"layer should be called on exactly 2 inputs\"\n         ):\n@@ -220,3 +200,515 @@ class MergingLayersTest(testing.TestCase, parameterized.TestCase):\n             ValueError, \"layer should be called on exactly 2 inputs\"\n         ):\n             layers.Subtract()([input_1])\n+\n+    def test_minimum_basic(self):\n+        self.run_layer_test(\n+            layers.Minimum,\n+            init_kwargs={},\n+            input_shape=[(2, 3), (2, 3)],\n+            expected_output_shape=(2, 3),\n+            expected_num_trainable_weights=0,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_seed_generators=0,\n+            expected_num_losses=0,\n+            supports_masking=True,\n+        )\n+\n+    def test_minimum_correctness_dynamic(self):\n+        x1 = np.random.rand(2, 4, 5)\n+        x2 = np.random.rand(2, 4, 5)\n+        x3 = ops.minimum(x1, x2)\n+\n+        input_1 = layers.Input(shape=(4, 5))\n+        input_2 = layers.Input(shape=(4, 5))\n+        merge_layer = layers.Minimum()\n+        out = merge_layer([input_1, input_2])\n+        model = models.Model([input_1, input_2], out)\n+        res = model([x1, x2])\n+\n+        self.assertEqual(res.shape, (2, 4, 5))\n+        self.assertAllClose(res, x3, atol=1e-4)\n+        self.assertIsNone(\n+            merge_layer.compute_mask([input_1, input_2], [None, None])\n+        )\n+        self.assertTrue(\n+            np.all(\n+                backend.convert_to_numpy(\n+                    merge_layer.compute_mask(\n+                        [input_1, input_2],\n+                        [backend.Variable(x1), backend.Variable(x2)],\n+                    )\n+                )\n+            )\n+        )\n+\n+    def test_minimum_correctness_static(self):\n+        batch_size = 2\n+        shape = (4, 5)\n+        x1 = np.random.rand(batch_size, *shape)\n+        x2 = np.random.rand(batch_size, *shape)\n+        x3 = ops.minimum(x1, x2)\n+\n+        input_1 = layers.Input(shape=shape, batch_size=batch_size)\n+        input_2 = layers.Input(shape=shape, batch_size=batch_size)\n+        merge_layer = layers.Minimum()\n+        out = merge_layer([input_1, input_2])\n+        model = models.Model([input_1, input_2], out)\n+        res = model([x1, x2])\n+\n+        self.assertEqual(res.shape, (batch_size, *shape))\n+        self.assertAllClose(res, x3, atol=1e-4)\n+        self.assertIsNone(\n+            merge_layer.compute_mask([input_1, input_2], [None, None])\n+        )\n+        self.assertTrue(\n+            np.all(\n+                backend.convert_to_numpy(\n+                    merge_layer.compute_mask(\n+                        [input_1, input_2],\n+                        [backend.Variable(x1), backend.Variable(x2)],\n+                    )\n+                )\n+            )\n+        )\n+\n+    def test_minimum_errors(self):\n+        batch_size = 2\n+        shape = (4, 5)\n+        x1 = np.random.rand(batch_size, *shape)\n+\n+        input_1 = layers.Input(shape=shape, batch_size=batch_size)\n+        input_2 = layers.Input(shape=shape, batch_size=batch_size)\n+        merge_layer = layers.Minimum()\n+\n+        with self.assertRaisesRegex(ValueError, \"`mask` should be a list.\"):\n+            merge_layer.compute_mask([input_1, input_2], x1)\n+\n+        with self.assertRaisesRegex(ValueError, \"`inputs` should be a list.\"):\n+            merge_layer.compute_mask(input_1, [None, None])\n+\n+        with self.assertRaisesRegex(\n+            ValueError, \" should have the same length.\"\n+        ):\n+            merge_layer.compute_mask([input_1, input_2], [None])\n+\n+    def test_maximum_basic(self):\n+        self.run_layer_test(\n+            layers.Maximum,\n+            init_kwargs={},\n+            input_shape=[(2, 3), (2, 3)],\n+            expected_output_shape=(2, 3),\n+            expected_num_trainable_weights=0,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_seed_generators=0,\n+            expected_num_losses=0,\n+            supports_masking=True,\n+        )\n+\n+    def test_maximum_correctness_dynamic(self):\n+        x1 = np.random.rand(2, 4, 5)\n+        x2 = np.random.rand(2, 4, 5)\n+        x3 = ops.maximum(x1, x2)\n+\n+        input_1 = layers.Input(shape=(4, 5))\n+        input_2 = layers.Input(shape=(4, 5))\n+        merge_layer = layers.Maximum()\n+        out = merge_layer([input_1, input_2])\n+        model = models.Model([input_1, input_2], out)\n+        res = model([x1, x2])\n+\n+        self.assertEqual(res.shape, (2, 4, 5))\n+        self.assertAllClose(res, x3, atol=1e-4)\n+        self.assertIsNone(\n+            merge_layer.compute_mask([input_1, input_2], [None, None])\n+        )\n+        self.assertTrue(\n+            np.all(\n+                backend.convert_to_numpy(\n+                    merge_layer.compute_mask(\n+                        [input_1, input_2],\n+                        [backend.Variable(x1), backend.Variable(x2)],\n+                    )\n+                )\n+            )\n+        )\n+\n+    def test_maximum_correctness_static(self):\n+        batch_size = 2\n+        shape = (4, 5)\n+        x1 = np.random.rand(batch_size, *shape)\n+        x2 = np.random.rand(batch_size, *shape)\n+        x3 = ops.maximum(x1, x2)\n+\n+        input_1 = layers.Input(shape=shape, batch_size=batch_size)\n+        input_2 = layers.Input(shape=shape, batch_size=batch_size)\n+        merge_layer = layers.Maximum()\n+        out = merge_layer([input_1, input_2])\n+        model = models.Model([input_1, input_2], out)\n+        res = model([x1, x2])\n+\n+        self.assertEqual(res.shape, (batch_size, *shape))\n+        self.assertAllClose(res, x3, atol=1e-4)\n+        self.assertIsNone(\n+            merge_layer.compute_mask([input_1, input_2], [None, None])\n+        )\n+        self.assertTrue(\n+            np.all(\n+                backend.convert_to_numpy(\n+                    merge_layer.compute_mask(\n+                        [input_1, input_2],\n+                        [backend.Variable(x1), backend.Variable(x2)],\n+                    )\n+                )\n+            )\n+        )\n+\n+    def test_maximum_errors(self):\n+        batch_size = 2\n+        shape = (4, 5)\n+        x1 = np.random.rand(batch_size, *shape)\n+\n+        input_1 = layers.Input(shape=shape, batch_size=batch_size)\n+        input_2 = layers.Input(shape=shape, batch_size=batch_size)\n+        merge_layer = layers.Maximum()\n+\n+        with self.assertRaisesRegex(ValueError, \"`mask` should be a list.\"):\n+            merge_layer.compute_mask([input_1, input_2], x1)\n+\n+        with self.assertRaisesRegex(ValueError, \"`inputs` should be a list.\"):\n+            merge_layer.compute_mask(input_1, [None, None])\n+\n+        with self.assertRaisesRegex(\n+            ValueError, \" should have the same length.\"\n+        ):\n+            merge_layer.compute_mask([input_1, input_2], [None])\n+\n+    def test_multiply_basic(self):\n+        self.run_layer_test(\n+            layers.Multiply,\n+            init_kwargs={},\n+            input_shape=[(2, 3), (2, 3)],\n+            expected_output_shape=(2, 3),\n+            expected_num_trainable_weights=0,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_seed_generators=0,\n+            expected_num_losses=0,\n+            supports_masking=True,\n+        )\n+\n+    def test_multiply_correctness_dynamic(self):\n+        x1 = np.random.rand(2, 4, 5)\n+        x2 = np.random.rand(2, 4, 5)\n+        x3 = ops.convert_to_tensor(x1 * x2)\n+\n+        input_1 = layers.Input(shape=(4, 5))\n+        input_2 = layers.Input(shape=(4, 5))\n+        merge_layer = layers.Multiply()\n+        out = merge_layer([input_1, input_2])\n+        model = models.Model([input_1, input_2], out)\n+        res = model([x1, x2])\n+\n+        self.assertEqual(res.shape, (2, 4, 5))\n+        self.assertAllClose(res, x3, atol=1e-4)\n+        self.assertIsNone(\n+            merge_layer.compute_mask([input_1, input_2], [None, None])\n+        )\n+        self.assertTrue(\n+            np.all(\n+                backend.convert_to_numpy(\n+                    merge_layer.compute_mask(\n+                        [input_1, input_2],\n+                        [backend.Variable(x1), backend.Variable(x2)],\n+                    )\n+                )\n+            )\n+        )\n+\n+    def test_multiply_correctness_static(self):\n+        batch_size = 2\n+        shape = (4, 5)\n+        x1 = np.random.rand(batch_size, *shape)\n+        x2 = np.random.rand(batch_size, *shape)\n+        x3 = ops.convert_to_tensor(x1 * x2)\n+\n+        input_1 = layers.Input(shape=shape, batch_size=batch_size)\n+        input_2 = layers.Input(shape=shape, batch_size=batch_size)\n+        merge_layer = layers.Multiply()\n+        out = merge_layer([input_1, input_2])\n+        model = models.Model([input_1, input_2], out)\n+        res = model([x1, x2])\n+\n+        self.assertEqual(res.shape, (batch_size, *shape))\n+        self.assertAllClose(res, x3, atol=1e-4)\n+        self.assertIsNone(\n+            merge_layer.compute_mask([input_1, input_2], [None, None])\n+        )\n+        self.assertTrue(\n+            np.all(\n+                backend.convert_to_numpy(\n+                    merge_layer.compute_mask(\n+                        [input_1, input_2],\n+                        [backend.Variable(x1), backend.Variable(x2)],\n+                    )\n+                )\n+            )\n+        )\n+\n+    def test_multiply_errors(self):\n+        batch_size = 2\n+        shape = (4, 5)\n+        x1 = np.random.rand(batch_size, *shape)\n+\n+        input_1 = layers.Input(shape=shape, batch_size=batch_size)\n+        input_2 = layers.Input(shape=shape, batch_size=batch_size)\n+        merge_layer = layers.Multiply()\n+\n+        with self.assertRaisesRegex(ValueError, \"`mask` should be a list.\"):\n+            merge_layer.compute_mask([input_1, input_2], x1)\n+\n+        with self.assertRaisesRegex(ValueError, \"`inputs` should be a list.\"):\n+            merge_layer.compute_mask(input_1, [None, None])\n+\n+        with self.assertRaisesRegex(\n+            ValueError, \" should have the same length.\"\n+        ):\n+            merge_layer.compute_mask([input_1, input_2], [None])\n+\n+    def test_average_basic(self):\n+        self.run_layer_test(\n+            layers.Average,\n+            init_kwargs={},\n+            input_shape=[(2, 3), (2, 3)],\n+            expected_output_shape=(2, 3),\n+            expected_num_trainable_weights=0,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_seed_generators=0,\n+            expected_num_losses=0,\n+            supports_masking=True,\n+        )\n+\n+    def test_average_correctness_dynamic(self):\n+        x1 = np.random.rand(2, 4, 5)\n+        x2 = np.random.rand(2, 4, 5)\n+        x3 = ops.average(np.array([x1, x2]), axis=0)\n+\n+        input_1 = layers.Input(shape=(4, 5))\n+        input_2 = layers.Input(shape=(4, 5))\n+        merge_layer = layers.Average()\n+        out = merge_layer([input_1, input_2])\n+        model = models.Model([input_1, input_2], out)\n+        res = model([x1, x2])\n+\n+        self.assertEqual(res.shape, (2, 4, 5))\n+        self.assertAllClose(res, x3, atol=1e-4)\n+        self.assertIsNone(\n+            merge_layer.compute_mask([input_1, input_2], [None, None])\n+        )\n+        self.assertTrue(\n+            np.all(\n+                backend.convert_to_numpy(\n+                    merge_layer.compute_mask(\n+                        [input_1, input_2],\n+                        [backend.Variable(x1), backend.Variable(x2)],\n+                    )\n+                )\n+            )\n+        )\n+\n+    def test_average_correctness_static(self):\n+        batch_size = 2\n+        shape = (4, 5)\n+        x1 = np.random.rand(batch_size, *shape)\n+        x2 = np.random.rand(batch_size, *shape)\n+        x3 = ops.average(np.array([x1, x2]), axis=0)\n+\n+        input_1 = layers.Input(shape=shape, batch_size=batch_size)\n+        input_2 = layers.Input(shape=shape, batch_size=batch_size)\n+        merge_layer = layers.Average()\n+        out = merge_layer([input_1, input_2])\n+        model = models.Model([input_1, input_2], out)\n+        res = model([x1, x2])\n+\n+        self.assertEqual(res.shape, (batch_size, *shape))\n+        self.assertAllClose(res, x3, atol=1e-4)\n+        self.assertIsNone(\n+            merge_layer.compute_mask([input_1, input_2], [None, None])\n+        )\n+        self.assertTrue(\n+            np.all(\n+                backend.convert_to_numpy(\n+                    merge_layer.compute_mask(\n+                        [input_1, input_2],\n+                        [backend.Variable(x1), backend.Variable(x2)],\n+                    )\n+                )\n+            )\n+        )\n+\n+    def test_average_errors(self):\n+        batch_size = 2\n+        shape = (4, 5)\n+        x1 = np.random.rand(batch_size, *shape)\n+\n+        input_1 = layers.Input(shape=shape, batch_size=batch_size)\n+        input_2 = layers.Input(shape=shape, batch_size=batch_size)\n+        merge_layer = layers.Average()\n+\n+        with self.assertRaisesRegex(ValueError, \"`mask` should be a list.\"):\n+            merge_layer.compute_mask([input_1, input_2], x1)\n+\n+        with self.assertRaisesRegex(ValueError, \"`inputs` should be a list.\"):\n+            merge_layer.compute_mask(input_1, [None, None])\n+\n+        with self.assertRaisesRegex(\n+            ValueError, \" should have the same length.\"\n+        ):\n+            merge_layer.compute_mask([input_1, input_2], [None])\n+\n+    def test_concatenate_basic(self):\n+        self.run_layer_test(\n+            layers.Concatenate,\n+            init_kwargs={\"axis\": 1},\n+            input_shape=[(2, 3), (2, 3)],\n+            expected_output_shape=(2, 6),\n+            expected_num_trainable_weights=0,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_seed_generators=0,\n+            expected_num_losses=0,\n+            supports_masking=True,\n+        )\n+\n+    def test_concatenate_correctness_dynamic(self):\n+        x1 = np.random.rand(2, 4, 5)\n+        x2 = np.random.rand(2, 4, 5)\n+        axis = 1\n+\n+        x3 = ops.concatenate([x1, x2], axis=axis)\n+\n+        input_1 = layers.Input(shape=(4, 5))\n+        input_2 = layers.Input(shape=(4, 5))\n+        merge_layer = layers.Concatenate(axis=axis)\n+        out = merge_layer([input_1, input_2])\n+        model = models.Model([input_1, input_2], out)\n+        res = model([x1, x2])\n+\n+        self.assertEqual(res.shape, (2, 8, 5))\n+        self.assertAllClose(res, x3, atol=1e-4)\n+        self.assertIsNone(\n+            merge_layer.compute_mask([input_1, input_2], [None, None])\n+        )\n+        self.assertTrue(\n+            np.all(\n+                backend.convert_to_numpy(\n+                    merge_layer.compute_mask(\n+                        [input_1, input_2],\n+                        [backend.Variable(x1), backend.Variable(x2)],\n+                    )\n+                )\n+            )\n+        )\n+\n+    def test_concatenate_correctness_static(self):\n+        batch_size = 2\n+        shape = (4, 5)\n+        axis = 1\n+        x1 = np.random.rand(batch_size, *shape)\n+        x2 = np.random.rand(batch_size, *shape)\n+        x3 = ops.concatenate([x1, x2], axis=axis)\n+\n+        input_1 = layers.Input(shape=shape, batch_size=batch_size)\n+        input_2 = layers.Input(shape=shape, batch_size=batch_size)\n+        merge_layer = layers.Concatenate(axis=axis)\n+        out = merge_layer([input_1, input_2])\n+        model = models.Model([input_1, input_2], out)\n+        res = model([x1, x2])\n+\n+        self.assertEqual(res.shape, (batch_size, 8, 5))\n+        self.assertAllClose(res, x3, atol=1e-4)\n+        self.assertIsNone(\n+            merge_layer.compute_mask([input_1, input_2], [None, None])\n+        )\n+        self.assertTrue(\n+            np.all(\n+                backend.convert_to_numpy(\n+                    merge_layer.compute_mask(\n+                        [input_1, input_2],\n+                        [x1, x2],\n+                    )\n+                )\n+            )\n+        )\n+\n+    def test_concatenate_errors(self):\n+        batch_size = 2\n+        shape = (4, 5)\n+        axis = 1\n+        x1 = np.random.rand(batch_size, *shape)\n+\n+        input_1 = layers.Input(shape=shape, batch_size=batch_size)\n+        input_2 = layers.Input(shape=shape, batch_size=batch_size)\n+        merge_layer = layers.Concatenate(axis=axis)\n+\n+        with self.assertRaisesRegex(ValueError, \"`mask` should be a list.\"):\n+            merge_layer.compute_mask([input_1, input_2], x1)\n+\n+        with self.assertRaisesRegex(ValueError, \"`inputs` should be a list.\"):\n+            merge_layer.compute_mask(input_1, [None, None])\n+\n+        with self.assertRaisesRegex(\n+            ValueError, \" should have the same length.\"\n+        ):\n+            merge_layer.compute_mask([input_1, input_2], [None])\n+\n+    def test_dot_basic(self):\n+        self.run_layer_test(\n+            layers.Dot,\n+            init_kwargs={\"axes\": -1},\n+            input_shape=[(4, 3), (4, 3)],\n+            expected_output_shape=(4, 1),\n+            expected_num_trainable_weights=0,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_seed_generators=0,\n+            expected_num_losses=0,\n+            supports_masking=None,\n+        )\n+\n+    def test_dot_correctness_dynamic(self):\n+        x1 = np.random.rand(2, 4)\n+        x2 = np.random.rand(2, 4)\n+        axes = 1\n+\n+        expected = np.zeros((2, 1))\n+        expected[0, 0] = np.dot(x1[0], x2[0])\n+        expected[1, 0] = np.dot(x1[1], x2[1])\n+\n+        input_1 = layers.Input(shape=(4,))\n+        input_2 = layers.Input(shape=(4,))\n+        merge_layer = layers.Dot(axes=axes)\n+        out = merge_layer([input_1, input_2])\n+        model = models.Model([input_1, input_2], out)\n+        res = model([x1, x2])\n+\n+        self.assertEqual(res.shape, (2, 1))\n+        self.assertAllClose(res, expected, atol=1e-4)\n+\n+    def test_dot_correctness_static(self):\n+        batch_size = 2\n+        shape = (4,)\n+        axes = 1\n+\n+        x1 = np.random.rand(2, 4)\n+        x2 = np.random.rand(2, 4)\n+        expected = np.zeros((2, 1))\n+        expected[0, 0] = np.dot(x1[0], x2[0])\n+        expected[1, 0] = np.dot(x1[1], x2[1])\n+\n+        input_1 = layers.Input(shape=shape, batch_size=batch_size)\n+        input_2 = layers.Input(shape=shape, batch_size=batch_size)\n+        merge_layer = layers.Dot(axes=axes)\n+        out = merge_layer([input_1, input_2])\n+        model = models.Model([input_1, input_2], out)\n+        res = model([x1, x2])\n+\n+        self.assertEqual(res.shape, (2, 1))\n+        self.assertAllClose(res, expected, atol=1e-4)\n\n@@ -1,30 +1,23 @@\n import numpy as np\n \n from keras_core import backend\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n-from keras_core.layers.layer import Layer\n+from keras_core.backend.common.backend_utils import encode_categorical_inputs\n+from keras_core.layers.preprocessing.tf_data_layer import TFDataLayer\n from keras_core.utils import argument_validation\n from keras_core.utils import backend_utils\n-from keras_core.utils import tf_utils\n from keras_core.utils.module_utils import tensorflow as tf\n \n \n @keras_core_export(\"keras_core.layers.Discretization\")\n-class Discretization(Layer):\n+class Discretization(TFDataLayer):\n     \"\"\"A preprocessing layer which buckets continuous features by ranges.\n \n     This layer will place each element of its input data into one of several\n     contiguous ranges and output an integer index indicating which range each\n     element was placed in.\n \n-    **Note:** This layer uses TensorFlow internally. It cannot\n-    be used as part of the compiled computation graph of a model with\n-    any backend other than TensorFlow.\n-    It can however be used with any backend when running eagerly.\n-    It can also always be used as part of an input preprocessing pipeline\n-    with any backend (outside the model itself), which is how we recommend\n-    to use this layer.\n-\n     **Note:** This layer is safe to use inside a `tf.data` pipeline\n     (independently of which backend you're using).\n \n@@ -78,14 +71,14 @@ class Discretization(Layer):\n \n     Examples:\n \n-    Bucketize float values based on provided buckets.\n+    Discretize float values based on provided buckets.\n     >>> input = np.array([[-1.5, 1.0, 3.4, .5], [0.0, 3.0, 1.3, 0.0]])\n     >>> layer = Discretization(bin_boundaries=[0., 1., 2.])\n     >>> layer(input)\n     array([[0, 2, 3, 1],\n            [1, 3, 2, 1]])\n \n-    Bucketize float values based on a number of buckets to compute.\n+    Discretize float values based on a number of buckets to compute.\n     >>> input = np.array([[-1.5, 1.0, 3.4, .5], [0.0, 3.0, 1.3, 0.0]])\n     >>> layer = Discretization(num_bins=4, epsilon=0.01)\n     >>> layer.adapt(input)\n@@ -241,26 +234,18 @@ class Discretization(Layer):\n         if not isinstance(\n             inputs,\n             (\n-                tf.Tensor,\n-                tf.SparseTensor,\n-                tf.RaggedTensor,\n                 np.ndarray,\n                 backend.KerasTensor,\n             ),\n         ):\n-            inputs = tf.convert_to_tensor(\n-                backend.convert_to_numpy(inputs), dtype=self.input_dtype\n-            )\n+            self._convert_input_args = True\n \n-        from keras_core.backend.tensorflow.numpy import digitize\n+        indices = ops.digitize(inputs, self.bin_boundaries)\n \n-        indices = digitize(inputs, self.bin_boundaries)\n-\n-        outputs = tf_utils.encode_categorical_inputs(\n+        outputs = encode_categorical_inputs(\n             indices,\n             output_mode=self.output_mode,\n             depth=len(self.bin_boundaries) + 1,\n-            sparse=self.sparse,\n             dtype=self.compute_dtype,\n         )\n         if (\n@@ -370,7 +355,3 @@ def compress_summary(summary, epsilon):\n     )\n     summary = np.stack((new_bins, new_weights))\n     return summary.astype(\"float32\")\n-\n-\n-def bucketize(inputs, boundaries):\n-    return tf.raw_ops.Bucketize(input=inputs, boundaries=boundaries)\n\n@@ -70,7 +70,9 @@ class DicretizationTest(testing.TestCase):\n \n     def test_tf_data_compatibility(self):\n         # With fixed bins\n-        layer = layers.Discretization(bin_boundaries=[0.0, 0.35, 0.5, 1.0])\n+        layer = layers.Discretization(\n+            bin_boundaries=[0.0, 0.35, 0.5, 1.0], dtype=\"float32\"\n+        )\n         x = np.array([[-1.0, 0.0, 0.1, 0.2, 0.4, 0.5, 1.0, 1.2, 0.98]])\n         self.assertAllClose(layer(x), np.array([[0, 1, 1, 1, 2, 3, 4, 4, 3]]))\n         ds = tf_data.Dataset.from_tensor_slices(x).batch(1).map(layer)\n\n@@ -418,90 +418,3 @@ def _extract_patches(\n     if _unbatched:\n         patches = backend.numpy.squeeze(patches, axis=0)\n     return patches\n-\n-\n-class MapCoordinates(Operation):\n-    def __init__(self, order, fill_mode=\"constant\", fill_value=0):\n-        super().__init__()\n-        self.order = order\n-        self.fill_mode = fill_mode\n-        self.fill_value = fill_value\n-\n-    def call(self, image, coordinates):\n-        return backend.image.map_coordinates(\n-            image,\n-            coordinates,\n-            order=self.order,\n-            fill_mode=self.fill_mode,\n-            fill_value=self.fill_value,\n-        )\n-\n-    def compute_output_spec(self, image, coordinates):\n-        if coordinates.shape[0] != len(image.shape):\n-            raise ValueError(\n-                \"First dim of `coordinates` must be the same as the rank of \"\n-                \"`image`. \"\n-                f\"Received image with shape: {image.shape} and coordinate \"\n-                f\"leading dim of {coordinates.shape[0]}\"\n-            )\n-        if len(coordinates.shape) < 2:\n-            raise ValueError(\n-                \"Invalid coordinates rank: expected at least rank 2.\"\n-                f\" Received input with shape: {coordinates.shape}\"\n-            )\n-        return KerasTensor(coordinates.shape[1:], dtype=image.dtype)\n-\n-\n-@keras_core_export(\"keras_core.ops.image.map_coordinates\")\n-def map_coordinates(\n-    input, coordinates, order, fill_mode=\"constant\", fill_value=0\n-):\n-    \"\"\"Map the input array to new coordinates by interpolation..\n-\n-    Note that interpolation near boundaries differs from the scipy function,\n-    because we fixed an outstanding bug\n-    [scipy/issues/2640](https://github.com/scipy/scipy/issues/2640).\n-\n-    Args:\n-        input: The input array.\n-        coordinates: The coordinates at which input is evaluated.\n-        order: The order of the spline interpolation. The order must be `0` or\n-            `1`. `0` indicates the nearest neighbor and `1` indicates the linear\n-            interpolation.\n-        fill_mode: Points outside the boundaries of the input are filled\n-            according to the given mode. Available methods are `\"constant\"`,\n-            `\"nearest\"`, `\"wrap\"` and `\"mirror\"` and `\"reflect\"`. Defaults to\n-            `\"constant\"`.\n-            - `\"constant\"`: `(k k k k | a b c d | k k k k)`\n-                The input is extended by filling all values beyond\n-                the edge with the same constant value k specified by\n-                `fill_value`.\n-            - `\"nearest\"`: `(a a a a | a b c d | d d d d)`\n-                The input is extended by the nearest pixel.\n-            - `\"wrap\"`: `(a b c d | a b c d | a b c d)`\n-                The input is extended by wrapping around to the opposite edge.\n-            - `\"mirror\"`: `(c d c b | a b c d | c b a b)`\n-                The input is extended by mirroring about the edge.\n-            - `\"reflect\"`: `(d c b a | a b c d | d c b a)`\n-                The input is extended by reflecting about the edge of the last\n-                pixel.\n-        fill_value: Value used for points outside the boundaries of the input if\n-            `fill_mode=\"constant\"`. Defaults to `0`.\n-\n-    Returns:\n-        Output image or batch of images.\n-\n-    \"\"\"\n-    if any_symbolic_tensors((input, coordinates)):\n-        return MapCoordinates(\n-            order,\n-            fill_mode,\n-            fill_value,\n-        ).symbolic_call(input, coordinates)\n-    return backend.image.map_coordinates(\n-        input,\n-        coordinates,\n-        order,\n-        fill_mode,\n-        fill_value,\n-    )\n\n@@ -1,5 +1,3 @@\n-import math\n-\n import numpy as np\n import pytest\n import scipy.ndimage\n@@ -36,12 +34,6 @@ class ImageOpsDynamicShapeTest(testing.TestCase):\n         out = kimage.extract_patches(x, 5)\n         self.assertEqual(out.shape, (None, 4, 4, 75))\n \n-    def test_map_coordinates(self):\n-        input = KerasTensor([20, 20, None])\n-        coordinates = KerasTensor([3, 15, 15, None])\n-        out = kimage.map_coordinates(input, coordinates, 0)\n-        self.assertEqual(out.shape, coordinates.shape[1:])\n-\n \n class ImageOpsStaticShapeTest(testing.TestCase):\n     def test_resize(self):\n@@ -63,12 +55,6 @@ class ImageOpsStaticShapeTest(testing.TestCase):\n         out = kimage.extract_patches(x, 5)\n         self.assertEqual(out.shape, (4, 4, 75))\n \n-    def test_map_coordinates(self):\n-        input = KerasTensor([20, 20, 3])\n-        coordinates = KerasTensor([3, 15, 15, 3])\n-        out = kimage.map_coordinates(input, coordinates, 0)\n-        self.assertEqual(out.shape, coordinates.shape[1:])\n-\n \n AFFINE_TRANSFORM_INTERPOLATIONS = {  # map to order\n     \"nearest\": 0,\n@@ -121,38 +107,6 @@ def _compute_affine_transform_coordinates(image, transform):\n     return coordinates\n \n \n-def _map_coordinates(\n-    input, coordinates, order, fill_mode=\"constant\", fill_value=0.0\n-):\n-    # SciPy's implementation of map_coordinates handles boundaries incorrectly,\n-    # unless mode='reflect'. For order=1, this only affects interpolation\n-    # outside the bounds of the original array.\n-    # https://github.com/scipy/scipy/issues/2640\n-    padding = [\n-        (\n-            max(-np.floor(c.min()).astype(int) + 1, 0),\n-            max(np.ceil(c.max()).astype(int) + 1 - size, 0),\n-        )\n-        for c, size in zip(coordinates, input.shape)\n-    ]\n-    shifted_coords = [c + p[0] for p, c in zip(padding, coordinates)]\n-    pad_mode = {\n-        \"nearest\": \"edge\",\n-        \"mirror\": \"reflect\",\n-        \"reflect\": \"symmetric\",\n-    }.get(fill_mode, fill_mode)\n-    if fill_mode == \"constant\":\n-        padded = np.pad(\n-            input, padding, mode=pad_mode, constant_values=fill_value\n-        )\n-    else:\n-        padded = np.pad(input, padding, mode=pad_mode)\n-    result = scipy.ndimage.map_coordinates(\n-        padded, shifted_coords, order=order, mode=fill_mode, cval=fill_value\n-    )\n-    return result\n-\n-\n class ImageOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n     @parameterized.parameters(\n         [\n@@ -396,30 +350,3 @@ class ImageOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         self.assertAllClose(\n             patches_ref.numpy(), backend.convert_to_numpy(patches_out), atol=0.3\n         )\n-\n-    @parameterized.product(\n-        # (input_shape, coordinates_shape)\n-        shape=[((5,), (7,)), ((3, 4, 5), (2, 3, 4))],\n-        # TODO: scipy.ndimage.map_coordinates does not support float16\n-        # TODO: torch cpu does not support round & floor for float16\n-        dtype=[\"uint8\", \"int32\", \"float32\"],\n-        order=[0, 1],\n-        fill_mode=[\"constant\", \"nearest\", \"wrap\", \"mirror\", \"reflect\"],\n-    )\n-    def test_map_coordinates(self, shape, dtype, order, fill_mode):\n-        input_shape, coordinates_shape = shape\n-        input = np.arange(math.prod(input_shape), dtype=dtype).reshape(\n-            input_shape\n-        )\n-        coordinates_dtype = \"float32\" if \"int\" in dtype else dtype\n-        coordinates = [\n-            (size - 1)\n-            * np.random.uniform(size=coordinates_shape).astype(\n-                coordinates_dtype\n-            )\n-            for size in input_shape\n-        ]\n-        output = kimage.map_coordinates(input, coordinates, order, fill_mode)\n-        expected = _map_coordinates(input, coordinates, order, fill_mode)\n-\n-        self.assertAllClose(output, expected)\n\n@@ -3283,6 +3283,30 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n \n     def test_split(self):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n+        if backend.backend() == \"torch\":\n+            self.assertAllClose(\n+                [backend.convert_to_numpy(t) for t in knp.split(x, 2)],\n+                np.split(x, 2),\n+            )\n+            self.assertAllClose(\n+                [backend.convert_to_numpy(t) for t in knp.Split(2)(x)],\n+                np.split(x, 2),\n+            )\n+            self.assertAllClose(\n+                [\n+                    backend.convert_to_numpy(t)\n+                    for t in knp.split(x, [1, 2], axis=1)\n+                ],\n+                np.split(x, [1, 2], axis=1),\n+            )\n+            self.assertAllClose(\n+                [\n+                    backend.convert_to_numpy(t)\n+                    for t in knp.Split([1, 2], axis=1)(x)\n+                ],\n+                np.split(x, [1, 2], axis=1),\n+            )\n+        else:\n             self.assertAllClose(knp.split(x, 2), np.split(x, 2))\n             self.assertAllClose(knp.Split(2)(x), np.split(x, 2))\n             self.assertAllClose(\n@@ -3294,15 +3318,6 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n                 np.split(x, [1, 2], axis=1),\n             )\n \n-        # test invalid indices_or_sections\n-        with self.assertRaises(Exception):\n-            knp.split(x, 3)\n-\n-        # test zero dimension\n-        x = np.ones(shape=(0,))\n-        self.assertEqual(len(knp.split(x, 2)), 2)\n-        self.assertEqual(len(knp.Split(2)(x)), 2)\n-\n     def test_sqrt(self):\n         x = np.array([[1, 4, 9], [16, 25, 36]])\n         self.assertAllClose(knp.sqrt(x), np.sqrt(x))\n\n@@ -188,23 +188,3 @@ def dropout(inputs, rate, noise_shape=None, seed=None):\n     return backend.random.dropout(\n         inputs, rate, noise_shape=noise_shape, seed=seed\n     )\n-\n-\n-@keras_core_export(\"keras_core.random.shuffle\")\n-def shuffle(x, axis=0, seed=None):\n-    \"\"\"Shuffle the elements of a tensor uniformly at random along an axis.\n-\n-    Args:\n-        x: The tensor to be shuffled.\n-        axis: An integer specifying the axis along which to shuffle. Defaults to\n-            `0`.\n-        seed: A Python integer or instance of\n-            `keras_core.random.SeedGenerator`.\n-            Used to make the behavior of the initializer\n-            deterministic. Note that an initializer seeded with an integer\n-            or None (unseeded) will produce the same random values\n-            across multiple calls. To get different random values\n-            across multiple calls, use as seed an instance\n-            of `keras_core.random.SeedGenerator`.\n-    \"\"\"\n-    return backend.random.shuffle(x, axis=axis, seed=seed)\n\n@@ -216,20 +216,3 @@ class RandomTest(testing.TestCase, parameterized.TestCase):\n         self.assertGreater(np.abs(y2 - y3), 1e-4)\n \n         seed_generator.global_seed_generator().state.assign(seed)\n-\n-    def test_shuffle(self):\n-        x = np.arange(100).reshape(10, 10)\n-\n-        # Test axis=0\n-        y = random.shuffle(x, seed=0)\n-\n-        self.assertFalse(np.all(x == ops.convert_to_numpy(y)))\n-        self.assertAllClose(np.sum(x, axis=0), ops.sum(y, axis=0))\n-        self.assertNotAllClose(np.sum(x, axis=1), ops.sum(y, axis=1))\n-\n-        # Test axis=1\n-        y = random.shuffle(x, axis=1, seed=0)\n-\n-        self.assertFalse(np.all(x == ops.convert_to_numpy(y)))\n-        self.assertAllClose(np.sum(x, axis=1), ops.sum(y, axis=1))\n-        self.assertNotAllClose(np.sum(x, axis=0), ops.sum(y, axis=0))\n\n@@ -261,8 +261,10 @@ class TestCase(unittest.TestCase):\n                     self.assertIsInstance(output, list)\n                     self.assertEqual(\n                         len(output),\n-                        len(expected_output_shape),\n+                        len(\n+                            expected_output_shape,\n                             msg=\"Unexpected number of outputs\",\n+                        ),\n                     )\n                     output_shape = [v.shape for v in expected_output_shape]\n                     self.assertEqual(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
