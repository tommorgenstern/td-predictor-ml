{"custom_id": "requests#2d5517682b3b38547634d153cea43d48fbc8cdb5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 26 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 3/2 | Churn Δ: 26 | Churn Cumulative: 10527 | Contributors (this commit): 205 | Commits (past 90d): 5 | Contributors (cumulative): 212 | DMM Complexity: 0.9090909090909091\n\nDIFF:\n@@ -900,6 +900,8 @@ class Response(object):\n                     # and the server didn't bother to tell us what codec *was*\n                     # used.\n                     pass\n+                except JSONDecodeError as e:\n+                    raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)\n \n         try:\n             return complexjson.loads(self.text, **kwargs)\n\n@@ -6,6 +6,7 @@ import requests\n \n from tests.testserver.server import Server, consume_socket_content\n \n+from requests.compat import JSONDecodeError\n from .utils import override_environ\n \n \n@@ -403,3 +404,26 @@ def test_fragment_update_on_redirect():\n         assert r.url == 'http://{}:{}/final-url/#relevant-section'.format(host, port)\n \n         close_server.set()\n+\n+def test_json_decode_compatibility_for_alt_utf_encodings():\n+\n+    def response_handler(sock):\n+        consume_socket_content(sock, timeout=0.5)\n+        sock.send(\n+            b'HTTP/1.1 200 OK\\r\\n'\n+            b'Content-Length: 18\\r\\n\\r\\n'\n+            b'\\xff\\xfe{\\x00\"\\x00K0\"\\x00=\\x00\"\\x00\\xab0\"\\x00\\r\\n'\n+        )\n+\n+    close_server = threading.Event()\n+    server = Server(response_handler, wait_to_close_event=close_server)\n+\n+    with server as (host, port):\n+        url = 'http://{}:{}/'.format(host, port)\n+        r = requests.get(url)\n+    r.encoding = None\n+    with pytest.raises(requests.exceptions.JSONDecodeError) as excinfo:\n+        r.json()\n+    assert isinstance(excinfo.value, requests.exceptions.RequestException)\n+    assert isinstance(excinfo.value, JSONDecodeError)\n+    assert r.text not in str(excinfo.value)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#2a6f290bc09324406708a4d404a88a45d848ddf9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2729 | Lines Deleted: 2302 | Files Changed: 31 | Hunks: 1216 | Methods Changed: 443 | Complexity Δ (Sum/Max): 1/3 | Churn Δ: 5031 | Churn Cumulative: 40653 | Contributors (this commit): 468 | Commits (past 90d): 49 | Contributors (cumulative): 965 | DMM Complexity: 0.7522123893805309\n\nDIFF:\n@@ -1,5 +1,3 @@\n-# -*- coding: utf-8 -*-\n-\n #   __\n #  /__)  _  _     _   _ _/   _\n # / (   (- (/ (/ (- _)  /  _)\n@@ -40,8 +38,10 @@ is at <https://requests.readthedocs.io>.\n :license: Apache 2.0, see LICENSE for more details.\n \"\"\"\n \n-import urllib3\n import warnings\n+\n+import urllib3\n+\n from .exceptions import RequestsDependencyWarning\n \n try:\n@@ -54,13 +54,14 @@ try:\n except ImportError:\n     chardet_version = None\n \n+\n def check_compatibility(urllib3_version, chardet_version, charset_normalizer_version):\n-    urllib3_version = urllib3_version.split('.')\n-    assert urllib3_version != ['dev']  # Verify urllib3 isn't installed from git.\n+    urllib3_version = urllib3_version.split(\".\")\n+    assert urllib3_version != [\"dev\"]  # Verify urllib3 isn't installed from git.\n \n     # Sometimes, urllib3 only reports its version as 16.1.\n     if len(urllib3_version) == 2:\n-        urllib3_version.append('0')\n+        urllib3_version.append(\"0\")\n \n     # Check urllib3 for compatibility.\n     major, minor, patch = urllib3_version  # noqa: F811\n@@ -72,36 +73,46 @@ def check_compatibility(urllib3_version, chardet_version, charset_normalizer_ver\n \n     # Check charset_normalizer for compatibility.\n     if chardet_version:\n-        major, minor, patch = chardet_version.split('.')[:3]\n+        major, minor, patch = chardet_version.split(\".\")[:3]\n         major, minor, patch = int(major), int(minor), int(patch)\n         # chardet_version >= 3.0.2, < 5.0.0\n         assert (3, 0, 2) <= (major, minor, patch) < (5, 0, 0)\n     elif charset_normalizer_version:\n-        major, minor, patch = charset_normalizer_version.split('.')[:3]\n+        major, minor, patch = charset_normalizer_version.split(\".\")[:3]\n         major, minor, patch = int(major), int(minor), int(patch)\n         # charset_normalizer >= 2.0.0 < 3.0.0\n         assert (2, 0, 0) <= (major, minor, patch) < (3, 0, 0)\n     else:\n         raise Exception(\"You need either charset_normalizer or chardet installed\")\n \n+\n def _check_cryptography(cryptography_version):\n     # cryptography < 1.3.4\n     try:\n-        cryptography_version = list(map(int, cryptography_version.split('.')))\n+        cryptography_version = list(map(int, cryptography_version.split(\".\")))\n     except ValueError:\n         return\n \n     if cryptography_version < [1, 3, 4]:\n-        warning = 'Old version of cryptography ({}) may cause slowdown.'.format(cryptography_version)\n+        warning = \"Old version of cryptography ({}) may cause slowdown.\".format(\n+            cryptography_version\n+        )\n         warnings.warn(warning, RequestsDependencyWarning)\n \n+\n # Check imported dependencies for compatibility.\n try:\n-    check_compatibility(urllib3.__version__, chardet_version, charset_normalizer_version)\n+    check_compatibility(\n+        urllib3.__version__, chardet_version, charset_normalizer_version\n+    )\n except (AssertionError, ValueError):\n-    warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n-                  \"version!\".format(urllib3.__version__, chardet_version, charset_normalizer_version),\n-                  RequestsDependencyWarning)\n+    warnings.warn(\n+        \"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n+        \"version!\".format(\n+            urllib3.__version__, chardet_version, charset_normalizer_version\n+        ),\n+        RequestsDependencyWarning,\n+    )\n \n # Attempt to enable urllib3's fallback for SNI support\n # if the standard library doesn't support SNI or the\n@@ -114,39 +125,56 @@ try:\n \n     if not getattr(ssl, \"HAS_SNI\", False):\n         from urllib3.contrib import pyopenssl\n+\n         pyopenssl.inject_into_urllib3()\n \n         # Check cryptography version\n         from cryptography import __version__ as cryptography_version\n+\n         _check_cryptography(cryptography_version)\n except ImportError:\n     pass\n \n # urllib3's DependencyWarnings should be silenced.\n from urllib3.exceptions import DependencyWarning\n-warnings.simplefilter('ignore', DependencyWarning)\n \n-from .__version__ import __title__, __description__, __url__, __version__\n-from .__version__ import __build__, __author__, __author_email__, __license__\n-from .__version__ import __copyright__, __cake__\n-\n-from . import utils\n-from . import packages\n-from .models import Request, Response, PreparedRequest\n-from .api import request, get, head, post, patch, put, delete, options\n-from .sessions import session, Session\n-from .status_codes import codes\n-from .exceptions import (\n-    RequestException, Timeout, URLRequired,\n-    TooManyRedirects, HTTPError, ConnectionError,\n-    FileModeWarning, ConnectTimeout, ReadTimeout, JSONDecodeError\n-)\n+warnings.simplefilter(\"ignore\", DependencyWarning)\n \n # Set default logging handler to avoid \"No handler found\" warnings.\n import logging\n from logging import NullHandler\n \n+from . import packages, utils\n+from .__version__ import (\n+    __author__,\n+    __author_email__,\n+    __build__,\n+    __cake__,\n+    __copyright__,\n+    __description__,\n+    __license__,\n+    __title__,\n+    __url__,\n+    __version__,\n+)\n+from .api import delete, get, head, options, patch, post, put, request\n+from .exceptions import (\n+    ConnectionError,\n+    ConnectTimeout,\n+    FileModeWarning,\n+    HTTPError,\n+    JSONDecodeError,\n+    ReadTimeout,\n+    RequestException,\n+    Timeout,\n+    TooManyRedirects,\n+    URLRequired,\n+)\n+from .models import PreparedRequest, Request, Response\n+from .sessions import Session, session\n+from .status_codes import codes\n+\n logging.getLogger(__name__).addHandler(NullHandler())\n \n # FileModeWarnings go off per the default.\n-warnings.simplefilter('default', FileModeWarning, append=True)\n+warnings.simplefilter(\"default\", FileModeWarning, append=True)\n\n@@ -2,13 +2,13 @@\n # |(  |-  |.| | | |-  `-.  |  `-.\n # ' ' `-' `-`.`-' `-' `-'  '  `-'\n \n-__title__ = 'requests'\n-__description__ = 'Python HTTP for Humans.'\n-__url__ = 'https://requests.readthedocs.io'\n-__version__ = '2.27.1'\n+__title__ = \"requests\"\n+__description__ = \"Python HTTP for Humans.\"\n+__url__ = \"https://requests.readthedocs.io\"\n+__version__ = \"2.27.1\"\n __build__ = 0x022701\n-__author__ = 'Kenneth Reitz'\n-__author_email__ = 'me@kennethreitz.org'\n-__license__ = 'Apache 2.0'\n-__copyright__ = 'Copyright 2022 Kenneth Reitz'\n-__cake__ = u'\\u2728 \\U0001f370 \\u2728'\n+__author__ = \"Kenneth Reitz\"\n+__author_email__ = \"me@kennethreitz.org\"\n+__license__ = \"Apache 2.0\"\n+__copyright__ = \"Copyright 2022 Kenneth Reitz\"\n+__cake__ = \"\\u2728 \\U0001f370 \\u2728\"\n\n@@ -1,5 +1,3 @@\n-# -*- coding: utf-8 -*-\n-\n \"\"\"\n requests._internal_utils\n ~~~~~~~~~~~~~~\n@@ -11,7 +9,7 @@ which depend on extremely few external helpers (such as compat)\n from .compat import builtin_str\n \n \n-def to_native_string(string, encoding='ascii'):\n+def to_native_string(string, encoding=\"ascii\"):\n     \"\"\"Given a string object, regardless of type, returns a representation of\n     that string in the native string type, encoding and decoding where\n     necessary. This assumes ASCII unless told otherwise.\n@@ -33,7 +31,7 @@ def unicode_is_ascii(u_string):\n     \"\"\"\n     assert isinstance(u_string, str)\n     try:\n-        u_string.encode('ascii')\n+        u_string.encode(\"ascii\")\n         return True\n     except UnicodeEncodeError:\n         return False\n\n@@ -1,5 +1,3 @@\n-# -*- coding: utf-8 -*-\n-\n \"\"\"\n requests.adapters\n ~~~~~~~~~~~~~~~~~\n@@ -9,58 +7,76 @@ and maintain connections.\n \"\"\"\n \n import os.path\n-import socket\n+import socket  # noqa: F401\n \n-from urllib3.poolmanager import PoolManager, proxy_from_url\n-from urllib3.response import HTTPResponse\n-from urllib3.util import parse_url\n-from urllib3.util import Timeout as TimeoutSauce\n-from urllib3.util.retry import Retry\n-from urllib3.exceptions import ClosedPoolError\n-from urllib3.exceptions import ConnectTimeoutError\n+from urllib3.exceptions import ClosedPoolError, ConnectTimeoutError\n from urllib3.exceptions import HTTPError as _HTTPError\n from urllib3.exceptions import InvalidHeader as _InvalidHeader\n-from urllib3.exceptions import MaxRetryError\n-from urllib3.exceptions import NewConnectionError\n+from urllib3.exceptions import (\n+    LocationValueError,\n+    MaxRetryError,\n+    NewConnectionError,\n+    ProtocolError,\n+)\n from urllib3.exceptions import ProxyError as _ProxyError\n-from urllib3.exceptions import ProtocolError\n-from urllib3.exceptions import ReadTimeoutError\n+from urllib3.exceptions import ReadTimeoutError, ResponseError\n from urllib3.exceptions import SSLError as _SSLError\n-from urllib3.exceptions import ResponseError\n-from urllib3.exceptions import LocationValueError\n+from urllib3.poolmanager import PoolManager, proxy_from_url\n+from urllib3.response import HTTPResponse\n+from urllib3.util import Timeout as TimeoutSauce\n+from urllib3.util import parse_url\n+from urllib3.util.retry import Retry\n \n-from .models import Response\n-from .compat import urlparse, basestring\n-from .utils import (DEFAULT_CA_BUNDLE_PATH, extract_zipped_paths,\n-                    get_encoding_from_headers, prepend_scheme_if_needed,\n-                    get_auth_from_url, urldefragauth, select_proxy)\n-from .structures import CaseInsensitiveDict\n-from .cookies import extract_cookies_to_jar\n-from .exceptions import (ConnectionError, ConnectTimeout, ReadTimeout, SSLError,\n-                         ProxyError, RetryError, InvalidSchema, InvalidProxyURL,\n-                         InvalidURL, InvalidHeader)\n from .auth import _basic_auth_str\n+from .compat import basestring, urlparse\n+from .cookies import extract_cookies_to_jar\n+from .exceptions import (\n+    ConnectionError,\n+    ConnectTimeout,\n+    InvalidHeader,\n+    InvalidProxyURL,\n+    InvalidSchema,\n+    InvalidURL,\n+    ProxyError,\n+    ReadTimeout,\n+    RetryError,\n+    SSLError,\n+)\n+from .models import Response\n+from .structures import CaseInsensitiveDict\n+from .utils import (\n+    DEFAULT_CA_BUNDLE_PATH,\n+    extract_zipped_paths,\n+    get_auth_from_url,\n+    get_encoding_from_headers,\n+    prepend_scheme_if_needed,\n+    select_proxy,\n+    urldefragauth,\n+)\n \n try:\n     from urllib3.contrib.socks import SOCKSProxyManager\n except ImportError:\n+\n     def SOCKSProxyManager(*args, **kwargs):\n         raise InvalidSchema(\"Missing dependencies for SOCKS support.\")\n \n+\n DEFAULT_POOLBLOCK = False\n DEFAULT_POOLSIZE = 10\n DEFAULT_RETRIES = 0\n DEFAULT_POOL_TIMEOUT = None\n \n \n-class BaseAdapter(object):\n+class BaseAdapter:\n     \"\"\"The Base Transport Adapter\"\"\"\n \n     def __init__(self):\n-        super(BaseAdapter, self).__init__()\n+        super().__init__()\n \n-    def send(self, request, stream=False, timeout=None, verify=True,\n-             cert=None, proxies=None):\n+    def send(\n+        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n+    ):\n         \"\"\"Sends PreparedRequest object. Returns Response object.\n \n         :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n@@ -108,12 +124,22 @@ class HTTPAdapter(BaseAdapter):\n       >>> a = requests.adapters.HTTPAdapter(max_retries=3)\n       >>> s.mount('http://', a)\n     \"\"\"\n-    __attrs__ = ['max_retries', 'config', '_pool_connections', '_pool_maxsize',\n-                 '_pool_block']\n \n-    def __init__(self, pool_connections=DEFAULT_POOLSIZE,\n-                 pool_maxsize=DEFAULT_POOLSIZE, max_retries=DEFAULT_RETRIES,\n-                 pool_block=DEFAULT_POOLBLOCK):\n+    __attrs__ = [\n+        \"max_retries\",\n+        \"config\",\n+        \"_pool_connections\",\n+        \"_pool_maxsize\",\n+        \"_pool_block\",\n+    ]\n+\n+    def __init__(\n+        self,\n+        pool_connections=DEFAULT_POOLSIZE,\n+        pool_maxsize=DEFAULT_POOLSIZE,\n+        max_retries=DEFAULT_RETRIES,\n+        pool_block=DEFAULT_POOLBLOCK,\n+    ):\n         if max_retries == DEFAULT_RETRIES:\n             self.max_retries = Retry(0, read=False)\n         else:\n@@ -121,7 +147,7 @@ class HTTPAdapter(BaseAdapter):\n         self.config = {}\n         self.proxy_manager = {}\n \n-        super(HTTPAdapter, self).__init__()\n+        super().__init__()\n \n         self._pool_connections = pool_connections\n         self._pool_maxsize = pool_maxsize\n@@ -141,10 +167,13 @@ class HTTPAdapter(BaseAdapter):\n         for attr, value in state.items():\n             setattr(self, attr, value)\n \n-        self.init_poolmanager(self._pool_connections, self._pool_maxsize,\n-                              block=self._pool_block)\n+        self.init_poolmanager(\n+            self._pool_connections, self._pool_maxsize, block=self._pool_block\n+        )\n \n-    def init_poolmanager(self, connections, maxsize, block=DEFAULT_POOLBLOCK, **pool_kwargs):\n+    def init_poolmanager(\n+        self, connections, maxsize, block=DEFAULT_POOLBLOCK, **pool_kwargs\n+    ):\n         \"\"\"Initializes a urllib3 PoolManager.\n \n         This method should not be called from user code, and is only\n@@ -161,8 +190,13 @@ class HTTPAdapter(BaseAdapter):\n         self._pool_maxsize = maxsize\n         self._pool_block = block\n \n-        self.poolmanager = PoolManager(num_pools=connections, maxsize=maxsize,\n-                                       block=block, strict=True, **pool_kwargs)\n+        self.poolmanager = PoolManager(\n+            num_pools=connections,\n+            maxsize=maxsize,\n+            block=block,\n+            strict=True,\n+            **pool_kwargs,\n+        )\n \n     def proxy_manager_for(self, proxy, **proxy_kwargs):\n         \"\"\"Return urllib3 ProxyManager for the given proxy.\n@@ -178,7 +212,7 @@ class HTTPAdapter(BaseAdapter):\n         \"\"\"\n         if proxy in self.proxy_manager:\n             manager = self.proxy_manager[proxy]\n-        elif proxy.lower().startswith('socks'):\n+        elif proxy.lower().startswith(\"socks\"):\n             username, password = get_auth_from_url(proxy)\n             manager = self.proxy_manager[proxy] = SOCKSProxyManager(\n                 proxy,\n@@ -187,7 +221,7 @@ class HTTPAdapter(BaseAdapter):\n                 num_pools=self._pool_connections,\n                 maxsize=self._pool_maxsize,\n                 block=self._pool_block,\n-                **proxy_kwargs\n+                **proxy_kwargs,\n             )\n         else:\n             proxy_headers = self.proxy_headers(proxy)\n@@ -197,7 +231,8 @@ class HTTPAdapter(BaseAdapter):\n                 num_pools=self._pool_connections,\n                 maxsize=self._pool_maxsize,\n                 block=self._pool_block,\n-                **proxy_kwargs)\n+                **proxy_kwargs,\n+            )\n \n         return manager\n \n@@ -213,7 +248,7 @@ class HTTPAdapter(BaseAdapter):\n             to a CA bundle to use\n         :param cert: The SSL certificate to verify.\n         \"\"\"\n-        if url.lower().startswith('https') and verify:\n+        if url.lower().startswith(\"https\") and verify:\n \n             cert_loc = None\n \n@@ -225,17 +260,19 @@ class HTTPAdapter(BaseAdapter):\n                 cert_loc = extract_zipped_paths(DEFAULT_CA_BUNDLE_PATH)\n \n             if not cert_loc or not os.path.exists(cert_loc):\n-                raise IOError(\"Could not find a suitable TLS CA certificate bundle, \"\n-                              \"invalid path: {}\".format(cert_loc))\n+                raise OSError(\n+                    f\"Could not find a suitable TLS CA certificate bundle, \"\n+                    f\"invalid path: {cert_loc}\"\n+                )\n \n-            conn.cert_reqs = 'CERT_REQUIRED'\n+            conn.cert_reqs = \"CERT_REQUIRED\"\n \n             if not os.path.isdir(cert_loc):\n                 conn.ca_certs = cert_loc\n             else:\n                 conn.ca_cert_dir = cert_loc\n         else:\n-            conn.cert_reqs = 'CERT_NONE'\n+            conn.cert_reqs = \"CERT_NONE\"\n             conn.ca_certs = None\n             conn.ca_cert_dir = None\n \n@@ -247,11 +284,14 @@ class HTTPAdapter(BaseAdapter):\n                 conn.cert_file = cert\n                 conn.key_file = None\n             if conn.cert_file and not os.path.exists(conn.cert_file):\n-                raise IOError(\"Could not find the TLS certificate file, \"\n-                              \"invalid path: {}\".format(conn.cert_file))\n+                raise OSError(\n+                    f\"Could not find the TLS certificate file, \"\n+                    f\"invalid path: {conn.cert_file}\"\n+                )\n             if conn.key_file and not os.path.exists(conn.key_file):\n-                raise IOError(\"Could not find the TLS key file, \"\n-                              \"invalid path: {}\".format(conn.key_file))\n+                raise OSError(\n+                    f\"Could not find the TLS key file, invalid path: {conn.key_file}\"\n+                )\n \n     def build_response(self, req, resp):\n         \"\"\"Builds a :class:`Response <requests.Response>` object from a urllib3\n@@ -266,10 +306,10 @@ class HTTPAdapter(BaseAdapter):\n         response = Response()\n \n         # Fallback to None if there's no status_code, for whatever reason.\n-        response.status_code = getattr(resp, 'status', None)\n+        response.status_code = getattr(resp, \"status\", None)\n \n         # Make headers case-insensitive.\n-        response.headers = CaseInsensitiveDict(getattr(resp, 'headers', {}))\n+        response.headers = CaseInsensitiveDict(getattr(resp, \"headers\", {}))\n \n         # Set encoding.\n         response.encoding = get_encoding_from_headers(response.headers)\n@@ -277,7 +317,7 @@ class HTTPAdapter(BaseAdapter):\n         response.reason = response.raw.reason\n \n         if isinstance(req.url, bytes):\n-            response.url = req.url.decode('utf-8')\n+            response.url = req.url.decode(\"utf-8\")\n         else:\n             response.url = req.url\n \n@@ -302,11 +342,13 @@ class HTTPAdapter(BaseAdapter):\n         proxy = select_proxy(url, proxies)\n \n         if proxy:\n-            proxy = prepend_scheme_if_needed(proxy, 'http')\n+            proxy = prepend_scheme_if_needed(proxy, \"http\")\n             proxy_url = parse_url(proxy)\n             if not proxy_url.host:\n-                raise InvalidProxyURL(\"Please check proxy URL. It is malformed\"\n-                                      \" and could be missing the host.\")\n+                raise InvalidProxyURL(\n+                    \"Please check proxy URL. It is malformed \"\n+                    \"and could be missing the host.\"\n+                )\n             proxy_manager = self.proxy_manager_for(proxy)\n             conn = proxy_manager.connection_from_url(url)\n         else:\n@@ -344,11 +386,11 @@ class HTTPAdapter(BaseAdapter):\n         proxy = select_proxy(request.url, proxies)\n         scheme = urlparse(request.url).scheme\n \n-        is_proxied_http_request = (proxy and scheme != 'https')\n+        is_proxied_http_request = proxy and scheme != \"https\"\n         using_socks_proxy = False\n         if proxy:\n             proxy_scheme = urlparse(proxy).scheme.lower()\n-            using_socks_proxy = proxy_scheme.startswith('socks')\n+            using_socks_proxy = proxy_scheme.startswith(\"socks\")\n \n         url = request.path_url\n         if is_proxied_http_request and not using_socks_proxy:\n@@ -387,12 +429,13 @@ class HTTPAdapter(BaseAdapter):\n         username, password = get_auth_from_url(proxy)\n \n         if username:\n-            headers['Proxy-Authorization'] = _basic_auth_str(username,\n-                                                             password)\n+            headers[\"Proxy-Authorization\"] = _basic_auth_str(username, password)\n \n         return headers\n \n-    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):\n+    def send(\n+        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n+    ):\n         \"\"\"Sends PreparedRequest object. Returns Response object.\n \n         :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n@@ -416,20 +459,26 @@ class HTTPAdapter(BaseAdapter):\n \n         self.cert_verify(conn, request.url, verify, cert)\n         url = self.request_url(request, proxies)\n-        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)\n+        self.add_headers(\n+            request,\n+            stream=stream,\n+            timeout=timeout,\n+            verify=verify,\n+            cert=cert,\n+            proxies=proxies,\n+        )\n \n-        chunked = not (request.body is None or 'Content-Length' in request.headers)\n+        chunked = not (request.body is None or \"Content-Length\" in request.headers)\n \n         if isinstance(timeout, tuple):\n             try:\n                 connect, read = timeout\n                 timeout = TimeoutSauce(connect=connect, read=read)\n-            except ValueError as e:\n-                # this may raise a string formatting error.\n-                err = (\"Invalid timeout {}. Pass a (connect, read) \"\n-                       \"timeout tuple, or a single float to set \"\n-                       \"both timeouts to the same value\".format(timeout))\n-                raise ValueError(err)\n+            except ValueError:\n+                raise ValueError(\n+                    f\"Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, \"\n+                    f\"or a single float to set both timeouts to the same value.\"\n+                )\n         elif isinstance(timeout, TimeoutSauce):\n             pass\n         else:\n@@ -447,22 +496,24 @@ class HTTPAdapter(BaseAdapter):\n                     preload_content=False,\n                     decode_content=False,\n                     retries=self.max_retries,\n-                    timeout=timeout\n+                    timeout=timeout,\n                 )\n \n             # Send the request.\n             else:\n-                if hasattr(conn, 'proxy_pool'):\n+                if hasattr(conn, \"proxy_pool\"):\n                     conn = conn.proxy_pool\n \n                 low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)\n \n                 try:\n-                    skip_host = 'Host' in request.headers\n-                    low_conn.putrequest(request.method,\n+                    skip_host = \"Host\" in request.headers\n+                    low_conn.putrequest(\n+                        request.method,\n                         url,\n                         skip_accept_encoding=True,\n-                                        skip_host=skip_host)\n+                        skip_host=skip_host,\n+                    )\n \n                     for header, value in request.headers.items():\n                         low_conn.putheader(header, value)\n@@ -470,11 +521,11 @@ class HTTPAdapter(BaseAdapter):\n                     low_conn.endheaders()\n \n                     for i in request.body:\n-                        low_conn.send(hex(len(i))[2:].encode('utf-8'))\n-                        low_conn.send(b'\\r\\n')\n+                        low_conn.send(hex(len(i))[2:].encode(\"utf-8\"))\n+                        low_conn.send(b\"\\r\\n\")\n                         low_conn.send(i)\n-                        low_conn.send(b'\\r\\n')\n-                    low_conn.send(b'0\\r\\n\\r\\n')\n+                        low_conn.send(b\"\\r\\n\")\n+                    low_conn.send(b\"0\\r\\n\\r\\n\")\n \n                     # Receive the response from the server\n                     r = low_conn.getresponse()\n@@ -484,15 +535,15 @@ class HTTPAdapter(BaseAdapter):\n                         pool=conn,\n                         connection=low_conn,\n                         preload_content=False,\n-                        decode_content=False\n+                        decode_content=False,\n                     )\n-                except:\n+                except Exception:\n                     # If we hit any problems here, clean up the connection.\n-                    # Then, reraise so that we can handle the actual exception.\n+                    # Then, raise so that we can handle the actual exception.\n                     low_conn.close()\n                     raise\n \n-        except (ProtocolError, socket.error) as err:\n+        except (ProtocolError, OSError) as err:\n             raise ConnectionError(err, request=request)\n \n         except MaxRetryError as e:\n\n@@ -1,5 +1,3 @@\n-# -*- coding: utf-8 -*-\n-\n \"\"\"\n requests.api\n ~~~~~~~~~~~~\n@@ -72,7 +70,7 @@ def get(url, params=None, **kwargs):\n     :rtype: requests.Response\n     \"\"\"\n \n-    return request('get', url, params=params, **kwargs)\n+    return request(\"get\", url, params=params, **kwargs)\n \n \n def options(url, **kwargs):\n@@ -84,7 +82,7 @@ def options(url, **kwargs):\n     :rtype: requests.Response\n     \"\"\"\n \n-    return request('options', url, **kwargs)\n+    return request(\"options\", url, **kwargs)\n \n \n def head(url, **kwargs):\n@@ -98,8 +96,8 @@ def head(url, **kwargs):\n     :rtype: requests.Response\n     \"\"\"\n \n-    kwargs.setdefault('allow_redirects', False)\n-    return request('head', url, **kwargs)\n+    kwargs.setdefault(\"allow_redirects\", False)\n+    return request(\"head\", url, **kwargs)\n \n \n def post(url, data=None, json=None, **kwargs):\n@@ -114,7 +112,7 @@ def post(url, data=None, json=None, **kwargs):\n     :rtype: requests.Response\n     \"\"\"\n \n-    return request('post', url, data=data, json=json, **kwargs)\n+    return request(\"post\", url, data=data, json=json, **kwargs)\n \n \n def put(url, data=None, **kwargs):\n@@ -129,7 +127,7 @@ def put(url, data=None, **kwargs):\n     :rtype: requests.Response\n     \"\"\"\n \n-    return request('put', url, data=data, **kwargs)\n+    return request(\"put\", url, data=data, **kwargs)\n \n \n def patch(url, data=None, **kwargs):\n@@ -144,7 +142,7 @@ def patch(url, data=None, **kwargs):\n     :rtype: requests.Response\n     \"\"\"\n \n-    return request('patch', url, data=data, **kwargs)\n+    return request(\"patch\", url, data=data, **kwargs)\n \n \n def delete(url, **kwargs):\n@@ -156,4 +154,4 @@ def delete(url, **kwargs):\n     :rtype: requests.Response\n     \"\"\"\n \n-    return request('delete', url, **kwargs)\n+    return request(\"delete\", url, **kwargs)\n\n@@ -1,5 +1,3 @@\n-# -*- coding: utf-8 -*-\n-\n \"\"\"\n requests.auth\n ~~~~~~~~~~~~~\n@@ -7,22 +5,21 @@ requests.auth\n This module contains the authentication handlers for Requests.\n \"\"\"\n \n+import hashlib\n import os\n import re\n-import time\n-import hashlib\n import threading\n+import time\n import warnings\n-\n from base64 import b64encode\n \n-from .compat import urlparse, str, basestring\n-from .cookies import extract_cookies_to_jar\n from ._internal_utils import to_native_string\n+from .compat import basestring, str, urlparse\n+from .cookies import extract_cookies_to_jar\n from .utils import parse_dict_header\n \n-CONTENT_TYPE_FORM_URLENCODED = 'application/x-www-form-urlencoded'\n-CONTENT_TYPE_MULTI_PART = 'multipart/form-data'\n+CONTENT_TYPE_FORM_URLENCODED = \"application/x-www-form-urlencoded\"\n+CONTENT_TYPE_MULTI_PART = \"multipart/form-data\"\n \n \n def _basic_auth_str(username, password):\n@@ -57,23 +54,23 @@ def _basic_auth_str(username, password):\n     # -- End Removal --\n \n     if isinstance(username, str):\n-        username = username.encode('latin1')\n+        username = username.encode(\"latin1\")\n \n     if isinstance(password, str):\n-        password = password.encode('latin1')\n+        password = password.encode(\"latin1\")\n \n-    authstr = 'Basic ' + to_native_string(\n-        b64encode(b':'.join((username, password))).strip()\n+    authstr = \"Basic \" + to_native_string(\n+        b64encode(b\":\".join((username, password))).strip()\n     )\n \n     return authstr\n \n \n-class AuthBase(object):\n+class AuthBase:\n     \"\"\"Base class that all auth implementations derive from\"\"\"\n \n     def __call__(self, r):\n-        raise NotImplementedError('Auth hooks must be callable.')\n+        raise NotImplementedError(\"Auth hooks must be callable.\")\n \n \n class HTTPBasicAuth(AuthBase):\n@@ -84,16 +81,18 @@ class HTTPBasicAuth(AuthBase):\n         self.password = password\n \n     def __eq__(self, other):\n-        return all([\n-            self.username == getattr(other, 'username', None),\n-            self.password == getattr(other, 'password', None)\n-        ])\n+        return all(\n+            [\n+                self.username == getattr(other, \"username\", None),\n+                self.password == getattr(other, \"password\", None),\n+            ]\n+        )\n \n     def __ne__(self, other):\n         return not self == other\n \n     def __call__(self, r):\n-        r.headers['Authorization'] = _basic_auth_str(self.username, self.password)\n+        r.headers[\"Authorization\"] = _basic_auth_str(self.username, self.password)\n         return r\n \n \n@@ -101,7 +100,7 @@ class HTTPProxyAuth(HTTPBasicAuth):\n     \"\"\"Attaches HTTP Proxy Authentication to a given Request object.\"\"\"\n \n     def __call__(self, r):\n-        r.headers['Proxy-Authorization'] = _basic_auth_str(self.username, self.password)\n+        r.headers[\"Proxy-Authorization\"] = _basic_auth_str(self.username, self.password)\n         return r\n \n \n@@ -116,9 +115,9 @@ class HTTPDigestAuth(AuthBase):\n \n     def init_per_thread_state(self):\n         # Ensure state is initialized just once per-thread\n-        if not hasattr(self._thread_local, 'init'):\n+        if not hasattr(self._thread_local, \"init\"):\n             self._thread_local.init = True\n-            self._thread_local.last_nonce = ''\n+            self._thread_local.last_nonce = \"\"\n             self._thread_local.nonce_count = 0\n             self._thread_local.chal = {}\n             self._thread_local.pos = None\n@@ -129,44 +128,52 @@ class HTTPDigestAuth(AuthBase):\n         :rtype: str\n         \"\"\"\n \n-        realm = self._thread_local.chal['realm']\n-        nonce = self._thread_local.chal['nonce']\n-        qop = self._thread_local.chal.get('qop')\n-        algorithm = self._thread_local.chal.get('algorithm')\n-        opaque = self._thread_local.chal.get('opaque')\n+        realm = self._thread_local.chal[\"realm\"]\n+        nonce = self._thread_local.chal[\"nonce\"]\n+        qop = self._thread_local.chal.get(\"qop\")\n+        algorithm = self._thread_local.chal.get(\"algorithm\")\n+        opaque = self._thread_local.chal.get(\"opaque\")\n         hash_utf8 = None\n \n         if algorithm is None:\n-            _algorithm = 'MD5'\n+            _algorithm = \"MD5\"\n         else:\n             _algorithm = algorithm.upper()\n         # lambdas assume digest modules are imported at the top level\n-        if _algorithm == 'MD5' or _algorithm == 'MD5-SESS':\n+        if _algorithm == \"MD5\" or _algorithm == \"MD5-SESS\":\n+\n             def md5_utf8(x):\n                 if isinstance(x, str):\n-                    x = x.encode('utf-8')\n+                    x = x.encode(\"utf-8\")\n                 return hashlib.md5(x).hexdigest()\n+\n             hash_utf8 = md5_utf8\n-        elif _algorithm == 'SHA':\n+        elif _algorithm == \"SHA\":\n+\n             def sha_utf8(x):\n                 if isinstance(x, str):\n-                    x = x.encode('utf-8')\n+                    x = x.encode(\"utf-8\")\n                 return hashlib.sha1(x).hexdigest()\n+\n             hash_utf8 = sha_utf8\n-        elif _algorithm == 'SHA-256':\n+        elif _algorithm == \"SHA-256\":\n+\n             def sha256_utf8(x):\n                 if isinstance(x, str):\n-                    x = x.encode('utf-8')\n+                    x = x.encode(\"utf-8\")\n                 return hashlib.sha256(x).hexdigest()\n+\n             hash_utf8 = sha256_utf8\n-        elif _algorithm == 'SHA-512':\n+        elif _algorithm == \"SHA-512\":\n+\n             def sha512_utf8(x):\n                 if isinstance(x, str):\n-                    x = x.encode('utf-8')\n+                    x = x.encode(\"utf-8\")\n                 return hashlib.sha512(x).hexdigest()\n+\n             hash_utf8 = sha512_utf8\n \n-        KD = lambda s, d: hash_utf8(\"%s:%s\" % (s, d))\n+        KD = lambda s, d: hash_utf8(f\"{s}:{d}\")  # noqa:E731\n \n         if hash_utf8 is None:\n             return None\n@@ -177,10 +184,10 @@ class HTTPDigestAuth(AuthBase):\n         #: path is request-uri defined in RFC 2616 which should not be empty\n         path = p_parsed.path or \"/\"\n         if p_parsed.query:\n-            path += '?' + p_parsed.query\n+            path += f\"?{p_parsed.query}\"\n \n-        A1 = '%s:%s:%s' % (self.username, realm, self.password)\n-        A2 = '%s:%s' % (method, path)\n+        A1 = f\"{self.username}:{realm}:{self.password}\"\n+        A2 = f\"{method}:{path}\"\n \n         HA1 = hash_utf8(A1)\n         HA2 = hash_utf8(A2)\n@@ -189,22 +196,20 @@ class HTTPDigestAuth(AuthBase):\n             self._thread_local.nonce_count += 1\n         else:\n             self._thread_local.nonce_count = 1\n-        ncvalue = '%08x' % self._thread_local.nonce_count\n-        s = str(self._thread_local.nonce_count).encode('utf-8')\n-        s += nonce.encode('utf-8')\n-        s += time.ctime().encode('utf-8')\n+        ncvalue = f\"{self._thread_local.nonce_count:08x}\"\n+        s = str(self._thread_local.nonce_count).encode(\"utf-8\")\n+        s += nonce.encode(\"utf-8\")\n+        s += time.ctime().encode(\"utf-8\")\n         s += os.urandom(8)\n \n-        cnonce = (hashlib.sha1(s).hexdigest()[:16])\n-        if _algorithm == 'MD5-SESS':\n-            HA1 = hash_utf8('%s:%s:%s' % (HA1, nonce, cnonce))\n+        cnonce = hashlib.sha1(s).hexdigest()[:16]\n+        if _algorithm == \"MD5-SESS\":\n+            HA1 = hash_utf8(f\"{HA1}:{nonce}:{cnonce}\")\n \n         if not qop:\n-            respdig = KD(HA1, \"%s:%s\" % (nonce, HA2))\n-        elif qop == 'auth' or 'auth' in qop.split(','):\n-            noncebit = \"%s:%s:%s:%s:%s\" % (\n-                nonce, ncvalue, cnonce, 'auth', HA2\n-            )\n+            respdig = KD(HA1, f\"{nonce}:{HA2}\")\n+        elif qop == \"auth\" or \"auth\" in qop.split(\",\"):\n+            noncebit = f\"{nonce}:{ncvalue}:{cnonce}:auth:{HA2}\"\n             respdig = KD(HA1, noncebit)\n         else:\n             # XXX handle auth-int.\n@@ -213,18 +218,20 @@ class HTTPDigestAuth(AuthBase):\n         self._thread_local.last_nonce = nonce\n \n         # XXX should the partial digests be encoded too?\n-        base = 'username=\"%s\", realm=\"%s\", nonce=\"%s\", uri=\"%s\", ' \\\n-               'response=\"%s\"' % (self.username, realm, nonce, path, respdig)\n+        base = (\n+            f'username=\"{self.username}\", realm=\"{realm}\", nonce=\"{nonce}\", '\n+            f'uri=\"{path}\", response=\"{respdig}\"'\n+        )\n         if opaque:\n-            base += ', opaque=\"%s\"' % opaque\n+            base += f', opaque=\"{opaque}\"'\n         if algorithm:\n-            base += ', algorithm=\"%s\"' % algorithm\n+            base += f', algorithm=\"{algorithm}\"'\n         if entdig:\n-            base += ', digest=\"%s\"' % entdig\n+            base += f', digest=\"{entdig}\"'\n         if qop:\n-            base += ', qop=\"auth\", nc=%s, cnonce=\"%s\"' % (ncvalue, cnonce)\n+            base += f', qop=\"auth\", nc={ncvalue}, cnonce=\"{cnonce}\"'\n \n-        return 'Digest %s' % (base)\n+        return f\"Digest {base}\"\n \n     def handle_redirect(self, r, **kwargs):\n         \"\"\"Reset num_401_calls counter on redirects.\"\"\"\n@@ -248,13 +255,13 @@ class HTTPDigestAuth(AuthBase):\n             # Rewind the file position indicator of the body to where\n             # it was to resend the request.\n             r.request.body.seek(self._thread_local.pos)\n-        s_auth = r.headers.get('www-authenticate', '')\n+        s_auth = r.headers.get(\"www-authenticate\", \"\")\n \n-        if 'digest' in s_auth.lower() and self._thread_local.num_401_calls < 2:\n+        if \"digest\" in s_auth.lower() and self._thread_local.num_401_calls < 2:\n \n             self._thread_local.num_401_calls += 1\n-            pat = re.compile(r'digest ', flags=re.IGNORECASE)\n-            self._thread_local.chal = parse_dict_header(pat.sub('', s_auth, count=1))\n+            pat = re.compile(r\"digest \", flags=re.IGNORECASE)\n+            self._thread_local.chal = parse_dict_header(pat.sub(\"\", s_auth, count=1))\n \n             # Consume content and release the original connection\n             # to allow our new request to reuse the same one.\n@@ -264,8 +271,9 @@ class HTTPDigestAuth(AuthBase):\n             extract_cookies_to_jar(prep._cookies, r.request, r.raw)\n             prep.prepare_cookies(prep._cookies)\n \n-            prep.headers['Authorization'] = self.build_digest_header(\n-                prep.method, prep.url)\n+            prep.headers[\"Authorization\"] = self.build_digest_header(\n+                prep.method, prep.url\n+            )\n             _r = r.connection.send(prep, **kwargs)\n             _r.history.append(r)\n             _r.request = prep\n@@ -280,7 +288,7 @@ class HTTPDigestAuth(AuthBase):\n         self.init_per_thread_state()\n         # If we have a saved nonce, skip the 401\n         if self._thread_local.last_nonce:\n-            r.headers['Authorization'] = self.build_digest_header(r.method, r.url)\n+            r.headers[\"Authorization\"] = self.build_digest_header(r.method, r.url)\n         try:\n             self._thread_local.pos = r.body.tell()\n         except AttributeError:\n@@ -289,17 +297,19 @@ class HTTPDigestAuth(AuthBase):\n             # file position of the previous body. Ensure it's set to\n             # None.\n             self._thread_local.pos = None\n-        r.register_hook('response', self.handle_401)\n-        r.register_hook('response', self.handle_redirect)\n+        r.register_hook(\"response\", self.handle_401)\n+        r.register_hook(\"response\", self.handle_redirect)\n         self._thread_local.num_401_calls = 1\n \n         return r\n \n     def __eq__(self, other):\n-        return all([\n-            self.username == getattr(other, 'username', None),\n-            self.password == getattr(other, 'password', None)\n-        ])\n+        return all(\n+            [\n+                self.username == getattr(other, \"username\", None),\n+                self.password == getattr(other, \"password\", None),\n+            ]\n+        )\n \n     def __ne__(self, other):\n         return not self == other\n\n@@ -1,5 +1,4 @@\n #!/usr/bin/env python\n-# -*- coding: utf-8 -*-\n \n \"\"\"\n requests.certs\n@@ -14,5 +13,5 @@ packaged CA bundle.\n \"\"\"\n from certifi import where\n \n-if __name__ == '__main__':\n+if __name__ == \"__main__\":\n     print(where())\n\n@@ -1,5 +1,3 @@\n-# -*- coding: utf-8 -*-\n-\n \"\"\"\n requests.compat\n ~~~~~~~~~~~~~~~\n@@ -24,15 +22,16 @@ import sys\n _ver = sys.version_info\n \n #: Python 2.x?\n-is_py2 = (_ver[0] == 2)\n+is_py2 = _ver[0] == 2\n \n #: Python 3.x?\n-is_py3 = (_ver[0] == 3)\n+is_py3 = _ver[0] == 3\n \n # json/simplejson module import resolution\n has_simplejson = False\n try:\n     import simplejson as json\n+\n     has_simplejson = True\n except ImportError:\n     import json\n@@ -42,18 +41,35 @@ if has_simplejson:\n else:\n     from json import JSONDecodeError\n \n-# ---------\n-# Legacy Imports\n-# ---------\n-from urllib.parse import urlparse, urlunparse, urljoin, urlsplit, urlencode, quote, unquote, quote_plus, unquote_plus, urldefrag\n-from urllib.request import parse_http_list, getproxies, proxy_bypass, proxy_bypass_environment, getproxies_environment\n+# Keep OrderedDict for backwards compatibility.\n+from collections import OrderedDict\n+from collections.abc import Callable, Mapping, MutableMapping\n from http import cookiejar as cookielib\n from http.cookies import Morsel\n from io import StringIO\n \n-# Keep OrderedDict for backwards compatibility.\n-from collections import OrderedDict\n-from collections.abc import Callable, Mapping, MutableMapping\n+# --------------\n+# Legacy Imports\n+# --------------\n+from urllib.parse import (\n+    quote,\n+    quote_plus,\n+    unquote,\n+    unquote_plus,\n+    urldefrag,\n+    urlencode,\n+    urljoin,\n+    urlparse,\n+    urlsplit,\n+    urlunparse,\n+)\n+from urllib.request import (\n+    getproxies,\n+    getproxies_environment,\n+    parse_http_list,\n+    proxy_bypass,\n+    proxy_bypass_environment,\n+)\n \n builtin_str = str\n str = str\n\n@@ -1,5 +1,3 @@\n-# -*- coding: utf-8 -*-\n-\n \"\"\"\n requests.cookies\n ~~~~~~~~~~~~~~~~\n@@ -9,12 +7,12 @@ Compatibility code to be able to use `cookielib.CookieJar` with requests.\n requests.utils imports from here, so be careful with imports.\n \"\"\"\n \n+import calendar\n import copy\n import time\n-import calendar\n \n from ._internal_utils import to_native_string\n-from .compat import cookielib, urlparse, urlunparse, Morsel, MutableMapping\n+from .compat import Morsel, MutableMapping, cookielib, urlparse, urlunparse\n \n try:\n     import threading\n@@ -22,7 +20,7 @@ except ImportError:\n     import dummy_threading as threading\n \n \n-class MockRequest(object):\n+class MockRequest:\n     \"\"\"Wraps a `requests.Request` to mimic a `urllib2.Request`.\n \n     The code in `cookielib.CookieJar` expects this interface in order to correctly\n@@ -51,16 +49,22 @@ class MockRequest(object):\n     def get_full_url(self):\n         # Only return the response's URL if the user hadn't set the Host\n         # header\n-        if not self._r.headers.get('Host'):\n+        if not self._r.headers.get(\"Host\"):\n             return self._r.url\n         # If they did set it, retrieve it and reconstruct the expected domain\n-        host = to_native_string(self._r.headers['Host'], encoding='utf-8')\n+        host = to_native_string(self._r.headers[\"Host\"], encoding=\"utf-8\")\n         parsed = urlparse(self._r.url)\n         # Reconstruct the URL as we expect it\n-        return urlunparse([\n-            parsed.scheme, host, parsed.path, parsed.params, parsed.query,\n-            parsed.fragment\n-        ])\n+        return urlunparse(\n+            [\n+                parsed.scheme,\n+                host,\n+                parsed.path,\n+                parsed.params,\n+                parsed.query,\n+                parsed.fragment,\n+            ]\n+        )\n \n     def is_unverifiable(self):\n         return True\n@@ -73,7 +77,9 @@ class MockRequest(object):\n \n     def add_header(self, key, val):\n         \"\"\"cookielib has no legitimate use for this method; add it back if you find one.\"\"\"\n-        raise NotImplementedError(\"Cookie headers should be added with add_unredirected_header()\")\n+        raise NotImplementedError(\n+            \"Cookie headers should be added with add_unredirected_header()\"\n+        )\n \n     def add_unredirected_header(self, name, value):\n         self._new_headers[name] = value\n@@ -94,7 +100,7 @@ class MockRequest(object):\n         return self.get_host()\n \n \n-class MockResponse(object):\n+class MockResponse:\n     \"\"\"Wraps a `httplib.HTTPMessage` to mimic a `urllib.addinfourl`.\n \n     ...what? Basically, expose the parsed HTTP headers from the server response\n@@ -122,8 +128,7 @@ def extract_cookies_to_jar(jar, request, response):\n     :param request: our own requests.Request object\n     :param response: urllib3.HTTPResponse object\n     \"\"\"\n-    if not (hasattr(response, '_original_response') and\n-            response._original_response):\n+    if not (hasattr(response, \"_original_response\") and response._original_response):\n         return\n     # the _original_response field is the wrapped httplib.HTTPResponse object,\n     req = MockRequest(request)\n@@ -140,7 +145,7 @@ def get_cookie_header(jar, request):\n     \"\"\"\n     r = MockRequest(request)\n     jar.add_cookie_header(r)\n-    return r.get_new_headers().get('Cookie')\n+    return r.get_new_headers().get(\"Cookie\")\n \n \n def remove_cookie_by_name(cookiejar, name, domain=None, path=None):\n@@ -205,7 +210,9 @@ class RequestsCookieJar(cookielib.CookieJar, MutableMapping):\n         \"\"\"\n         # support client code that unsets cookies by assignment of a None value:\n         if value is None:\n-            remove_cookie_by_name(self, name, domain=kwargs.get('domain'), path=kwargs.get('path'))\n+            remove_cookie_by_name(\n+                self, name, domain=kwargs.get(\"domain\"), path=kwargs.get(\"path\")\n+            )\n             return\n \n         if isinstance(value, Morsel):\n@@ -305,16 +312,15 @@ class RequestsCookieJar(cookielib.CookieJar, MutableMapping):\n         \"\"\"\n         dictionary = {}\n         for cookie in iter(self):\n-            if (\n-                (domain is None or cookie.domain == domain) and\n-                (path is None or cookie.path == path)\n+            if (domain is None or cookie.domain == domain) and (\n+                path is None or cookie.path == path\n             ):\n                 dictionary[cookie.name] = cookie.value\n         return dictionary\n \n     def __contains__(self, name):\n         try:\n-            return super(RequestsCookieJar, self).__contains__(name)\n+            return super().__contains__(name)\n         except CookieConflictError:\n             return True\n \n@@ -341,9 +347,13 @@ class RequestsCookieJar(cookielib.CookieJar, MutableMapping):\n         remove_cookie_by_name(self, name)\n \n     def set_cookie(self, cookie, *args, **kwargs):\n-        if hasattr(cookie.value, 'startswith') and cookie.value.startswith('\"') and cookie.value.endswith('\"'):\n-            cookie.value = cookie.value.replace('\\\\\"', '')\n-        return super(RequestsCookieJar, self).set_cookie(cookie, *args, **kwargs)\n+        if (\n+            hasattr(cookie.value, \"startswith\")\n+            and cookie.value.startswith('\"')\n+            and cookie.value.endswith('\"')\n+        ):\n+            cookie.value = cookie.value.replace('\\\\\"', \"\")\n+        return super().set_cookie(cookie, *args, **kwargs)\n \n     def update(self, other):\n         \"\"\"Updates this jar with cookies from another CookieJar or dict-like\"\"\"\n@@ -351,7 +361,7 @@ class RequestsCookieJar(cookielib.CookieJar, MutableMapping):\n             for cookie in other:\n                 self.set_cookie(copy.copy(cookie))\n         else:\n-            super(RequestsCookieJar, self).update(other)\n+            super().update(other)\n \n     def _find(self, name, domain=None, path=None):\n         \"\"\"Requests uses this method internally to get cookie values.\n@@ -371,7 +381,7 @@ class RequestsCookieJar(cookielib.CookieJar, MutableMapping):\n                     if path is None or cookie.path == path:\n                         return cookie.value\n \n-        raise KeyError('name=%r, domain=%r, path=%r' % (name, domain, path))\n+        raise KeyError(f\"name={name!r}, domain={domain!r}, path={path!r}\")\n \n     def _find_no_duplicates(self, name, domain=None, path=None):\n         \"\"\"Both ``__get_item__`` and ``get`` call this function: it's never\n@@ -390,25 +400,29 @@ class RequestsCookieJar(cookielib.CookieJar, MutableMapping):\n             if cookie.name == name:\n                 if domain is None or cookie.domain == domain:\n                     if path is None or cookie.path == path:\n-                        if toReturn is not None:  # if there are multiple cookies that meet passed in criteria\n-                            raise CookieConflictError('There are multiple cookies with name, %r' % (name))\n-                        toReturn = cookie.value  # we will eventually return this as long as no cookie conflict\n+                        if toReturn is not None:\n+                            # if there are multiple cookies that meet passed in criteria\n+                            raise CookieConflictError(\n+                                f\"There are multiple cookies with name, {name!r}\"\n+                            )\n+                        # we will eventually return this as long as no cookie conflict\n+                        toReturn = cookie.value\n \n         if toReturn:\n             return toReturn\n-        raise KeyError('name=%r, domain=%r, path=%r' % (name, domain, path))\n+        raise KeyError(f\"name={name!r}, domain={domain!r}, path={path!r}\")\n \n     def __getstate__(self):\n         \"\"\"Unlike a normal CookieJar, this class is pickleable.\"\"\"\n         state = self.__dict__.copy()\n         # remove the unpickleable RLock object\n-        state.pop('_cookies_lock')\n+        state.pop(\"_cookies_lock\")\n         return state\n \n     def __setstate__(self, state):\n         \"\"\"Unlike a normal CookieJar, this class is pickleable.\"\"\"\n         self.__dict__.update(state)\n-        if '_cookies_lock' not in self.__dict__:\n+        if \"_cookies_lock\" not in self.__dict__:\n             self._cookies_lock = threading.RLock()\n \n     def copy(self):\n@@ -427,7 +441,7 @@ def _copy_cookie_jar(jar):\n     if jar is None:\n         return None\n \n-    if hasattr(jar, 'copy'):\n+    if hasattr(jar, \"copy\"):\n         # We're dealing with an instance of RequestsCookieJar\n         return jar.copy()\n     # We're dealing with a generic CookieJar instance\n@@ -445,31 +459,32 @@ def create_cookie(name, value, **kwargs):\n     and sent on every request (this is sometimes called a \"supercookie\").\n     \"\"\"\n     result = {\n-        'version': 0,\n-        'name': name,\n-        'value': value,\n-        'port': None,\n-        'domain': '',\n-        'path': '/',\n-        'secure': False,\n-        'expires': None,\n-        'discard': True,\n-        'comment': None,\n-        'comment_url': None,\n-        'rest': {'HttpOnly': None},\n-        'rfc2109': False,\n+        \"version\": 0,\n+        \"name\": name,\n+        \"value\": value,\n+        \"port\": None,\n+        \"domain\": \"\",\n+        \"path\": \"/\",\n+        \"secure\": False,\n+        \"expires\": None,\n+        \"discard\": True,\n+        \"comment\": None,\n+        \"comment_url\": None,\n+        \"rest\": {\"HttpOnly\": None},\n+        \"rfc2109\": False,\n     }\n \n     badargs = set(kwargs) - set(result)\n     if badargs:\n-        err = 'create_cookie() got unexpected keyword arguments: %s'\n-        raise TypeError(err % list(badargs))\n+        raise TypeError(\n+            f\"create_cookie() got unexpected keyword arguments: {list(badargs)}\"\n+        )\n \n     result.update(kwargs)\n-    result['port_specified'] = bool(result['port'])\n-    result['domain_specified'] = bool(result['domain'])\n-    result['domain_initial_dot'] = result['domain'].startswith('.')\n-    result['path_specified'] = bool(result['path'])\n+    result[\"port_specified\"] = bool(result[\"port\"])\n+    result[\"domain_specified\"] = bool(result[\"domain\"])\n+    result[\"domain_initial_dot\"] = result[\"domain\"].startswith(\".\")\n+    result[\"path_specified\"] = bool(result[\"path\"])\n \n     return cookielib.Cookie(**result)\n \n@@ -478,30 +493,28 @@ def morsel_to_cookie(morsel):\n     \"\"\"Convert a Morsel object into a Cookie containing the one k/v pair.\"\"\"\n \n     expires = None\n-    if morsel['max-age']:\n+    if morsel[\"max-age\"]:\n         try:\n-            expires = int(time.time() + int(morsel['max-age']))\n+            expires = int(time.time() + int(morsel[\"max-age\"]))\n         except ValueError:\n-            raise TypeError('max-age: %s must be integer' % morsel['max-age'])\n-    elif morsel['expires']:\n-        time_template = '%a, %d-%b-%Y %H:%M:%S GMT'\n-        expires = calendar.timegm(\n-            time.strptime(morsel['expires'], time_template)\n-        )\n+            raise TypeError(f\"max-age: {morsel['max-age']} must be integer\")\n+    elif morsel[\"expires\"]:\n+        time_template = \"%a, %d-%b-%Y %H:%M:%S GMT\"\n+        expires = calendar.timegm(time.strptime(morsel[\"expires\"], time_template))\n     return create_cookie(\n-        comment=morsel['comment'],\n-        comment_url=bool(morsel['comment']),\n+        comment=morsel[\"comment\"],\n+        comment_url=bool(morsel[\"comment\"]),\n         discard=False,\n-        domain=morsel['domain'],\n+        domain=morsel[\"domain\"],\n         expires=expires,\n         name=morsel.key,\n-        path=morsel['path'],\n+        path=morsel[\"path\"],\n         port=None,\n-        rest={'HttpOnly': morsel['httponly']},\n+        rest={\"HttpOnly\": morsel[\"httponly\"]},\n         rfc2109=False,\n-        secure=bool(morsel['secure']),\n+        secure=bool(morsel[\"secure\"]),\n         value=morsel.value,\n-        version=morsel['version'] or 0,\n+        version=morsel[\"version\"] or 0,\n     )\n \n \n@@ -534,11 +547,10 @@ def merge_cookies(cookiejar, cookies):\n     :rtype: CookieJar\n     \"\"\"\n     if not isinstance(cookiejar, cookielib.CookieJar):\n-        raise ValueError('You can only merge into CookieJar')\n+        raise ValueError(\"You can only merge into CookieJar\")\n \n     if isinstance(cookies, dict):\n-        cookiejar = cookiejar_from_dict(\n-            cookies, cookiejar=cookiejar, overwrite=False)\n+        cookiejar = cookiejar_from_dict(cookies, cookiejar=cookiejar, overwrite=False)\n     elif isinstance(cookies, cookielib.CookieJar):\n         try:\n             cookiejar.update(cookies)\n\n@@ -1,5 +1,3 @@\n-# -*- coding: utf-8 -*-\n-\n \"\"\"\n requests.exceptions\n ~~~~~~~~~~~~~~~~~~~\n@@ -18,13 +16,12 @@ class RequestException(IOError):\n \n     def __init__(self, *args, **kwargs):\n         \"\"\"Initialize RequestException with `request` and `response` objects.\"\"\"\n-        response = kwargs.pop('response', None)\n+        response = kwargs.pop(\"response\", None)\n         self.response = response\n-        self.request = kwargs.pop('request', None)\n-        if (response is not None and not self.request and\n-                hasattr(response, 'request')):\n+        self.request = kwargs.pop(\"request\", None)\n+        if response is not None and not self.request and hasattr(response, \"request\"):\n             self.request = self.response.request\n-        super(RequestException, self).__init__(*args, **kwargs)\n+        super().__init__(*args, **kwargs)\n \n \n class InvalidJSONError(RequestException):\n@@ -128,6 +125,7 @@ class RetryError(RequestException):\n class UnrewindableBodyError(RequestException):\n     \"\"\"Requests encountered an error when trying to rewind a body.\"\"\"\n \n+\n # Warnings\n \n \n\n@@ -1,10 +1,9 @@\n \"\"\"Module containing bug report helper(s).\"\"\"\n-from __future__ import print_function\n \n import json\n import platform\n-import sys\n import ssl\n+import sys\n \n import idna\n import urllib3\n@@ -28,8 +27,8 @@ except ImportError:\n     OpenSSL = None\n     cryptography = None\n else:\n-    import OpenSSL\n     import cryptography\n+    import OpenSSL\n \n \n def _implementation():\n@@ -45,83 +44,83 @@ def _implementation():\n     \"\"\"\n     implementation = platform.python_implementation()\n \n-    if implementation == 'CPython':\n+    if implementation == \"CPython\":\n         implementation_version = platform.python_version()\n-    elif implementation == 'PyPy':\n-        implementation_version = '%s.%s.%s' % (sys.pypy_version_info.major,\n+    elif implementation == \"PyPy\":\n+        implementation_version = \"{}.{}.{}\".format(\n+            sys.pypy_version_info.major,\n             sys.pypy_version_info.minor,\n-                                               sys.pypy_version_info.micro)\n-        if sys.pypy_version_info.releaselevel != 'final':\n-            implementation_version = ''.join([\n-                implementation_version, sys.pypy_version_info.releaselevel\n-            ])\n-    elif implementation == 'Jython':\n+            sys.pypy_version_info.micro,\n+        )\n+        if sys.pypy_version_info.releaselevel != \"final\":\n+            implementation_version = \"\".join(\n+                [implementation_version, sys.pypy_version_info.releaselevel]\n+            )\n+    elif implementation == \"Jython\":\n         implementation_version = platform.python_version()  # Complete Guess\n-    elif implementation == 'IronPython':\n+    elif implementation == \"IronPython\":\n         implementation_version = platform.python_version()  # Complete Guess\n     else:\n-        implementation_version = 'Unknown'\n+        implementation_version = \"Unknown\"\n \n-    return {'name': implementation, 'version': implementation_version}\n+    return {\"name\": implementation, \"version\": implementation_version}\n \n \n def info():\n     \"\"\"Generate information for a bug report.\"\"\"\n     try:\n         platform_info = {\n-            'system': platform.system(),\n-            'release': platform.release(),\n+            \"system\": platform.system(),\n+            \"release\": platform.release(),\n         }\n-    except IOError:\n+    except OSError:\n         platform_info = {\n-            'system': 'Unknown',\n-            'release': 'Unknown',\n+            \"system\": \"Unknown\",\n+            \"release\": \"Unknown\",\n         }\n \n     implementation_info = _implementation()\n-    urllib3_info = {'version': urllib3.__version__}\n-    charset_normalizer_info = {'version': None}\n-    chardet_info = {'version': None}\n+    urllib3_info = {\"version\": urllib3.__version__}\n+    charset_normalizer_info = {\"version\": None}\n+    chardet_info = {\"version\": None}\n     if charset_normalizer:\n-        charset_normalizer_info = {'version': charset_normalizer.__version__}\n+        charset_normalizer_info = {\"version\": charset_normalizer.__version__}\n     if chardet:\n-        chardet_info = {'version': chardet.__version__}\n+        chardet_info = {\"version\": chardet.__version__}\n \n     pyopenssl_info = {\n-        'version': None,\n-        'openssl_version': '',\n+        \"version\": None,\n+        \"openssl_version\": \"\",\n     }\n     if OpenSSL:\n         pyopenssl_info = {\n-            'version': OpenSSL.__version__,\n-            'openssl_version': '%x' % OpenSSL.SSL.OPENSSL_VERSION_NUMBER,\n+            \"version\": OpenSSL.__version__,\n+            \"openssl_version\": f\"{OpenSSL.SSL.OPENSSL_VERSION_NUMBER:x}\",\n         }\n     cryptography_info = {\n-        'version': getattr(cryptography, '__version__', ''),\n+        \"version\": getattr(cryptography, \"__version__\", \"\"),\n     }\n     idna_info = {\n-        'version': getattr(idna, '__version__', ''),\n+        \"version\": getattr(idna, \"__version__\", \"\"),\n     }\n \n     system_ssl = ssl.OPENSSL_VERSION_NUMBER\n-    system_ssl_info = {\n-        'version': '%x' % system_ssl if system_ssl is not None else ''\n-    }\n+    system_ssl_info = {\"version\": f\"{system_ssl:x}\" if system_ssl is not None else \"\"}\n \n     return {\n-        'platform': platform_info,\n-        'implementation': implementation_info,\n-        'system_ssl': system_ssl_info,\n-        'using_pyopenssl': pyopenssl is not None,\n-        'using_charset_normalizer': chardet is None,\n-        'pyOpenSSL': pyopenssl_info,\n-        'urllib3': urllib3_info,\n-        'chardet': chardet_info,\n-        'charset_normalizer': charset_normalizer_info,\n-        'cryptography': cryptography_info,\n-        'idna': idna_info,\n-        'requests': {\n-            'version': requests_version,\n+        \"platform\": platform_info,\n+        \"implementation\": implementation_info,\n+        \"system_ssl\": system_ssl_info,\n+        \"using_pyopenssl\": pyopenssl is not None,\n+        \"using_charset_normalizer\": chardet is None,\n+        \"pyOpenSSL\": pyopenssl_info,\n+        \"urllib3\": urllib3_info,\n+        \"chardet\": chardet_info,\n+        \"charset_normalizer\": charset_normalizer_info,\n+        \"cryptography\": cryptography_info,\n+        \"idna\": idna_info,\n+        \"requests\": {\n+            \"version\": requests_version,\n         },\n     }\n \n@@ -131,5 +130,5 @@ def main():\n     print(json.dumps(info(), sort_keys=True, indent=2))\n \n \n-if __name__ == '__main__':\n+if __name__ == \"__main__\":\n     main()\n\n@@ -1,5 +1,3 @@\n-# -*- coding: utf-8 -*-\n-\n \"\"\"\n requests.hooks\n ~~~~~~~~~~~~~~\n@@ -11,12 +9,13 @@ Available hooks:\n ``response``:\n     The response generated from a Request.\n \"\"\"\n-HOOKS = ['response']\n+HOOKS = [\"response\"]\n \n \n def default_hooks():\n     return {event: [] for event in HOOKS}\n \n+\n # TODO: response is the only one\n \n \n@@ -25,7 +24,7 @@ def dispatch_hook(key, hooks, hook_data, **kwargs):\n     hooks = hooks or {}\n     hooks = hooks.get(key)\n     if hooks:\n-        if hasattr(hooks, '__call__'):\n+        if hasattr(hooks, \"__call__\"):\n             hooks = [hooks]\n         for hook in hooks:\n             _hook_data = hook(hook_data, **kwargs)\n\n@@ -1,5 +1,3 @@\n-# -*- coding: utf-8 -*-\n-\n \"\"\"\n requests.models\n ~~~~~~~~~~~~~~~\n@@ -12,11 +10,9 @@ import datetime\n # Import encoding now, to avoid implicit import later.\n # Implicit import within threads may cause LookupError when standard library is in a ZIP,\n # such as in Embedded Python. See https://github.com/psf/requests/issues/3578.\n-import encodings.idna\n+import encodings.idna  # noqa: F401\n+from io import UnsupportedOperation\n \n-from urllib3.fields import RequestField\n-from urllib3.filepost import encode_multipart_formdata\n-from urllib3.util import parse_url\n from urllib3.exceptions import (\n     DecodeError,\n     LocationParseError,\n@@ -24,30 +20,51 @@ from urllib3.exceptions import (\n     ReadTimeoutError,\n     SSLError,\n )\n+from urllib3.fields import RequestField\n+from urllib3.filepost import encode_multipart_formdata\n+from urllib3.util import parse_url\n \n-from io import UnsupportedOperation\n-from .hooks import default_hooks\n-from .structures import CaseInsensitiveDict\n-\n-from .auth import HTTPBasicAuth\n-from .cookies import cookiejar_from_dict, get_cookie_header, _copy_cookie_jar\n-from .exceptions import (\n-    HTTPError, MissingSchema, InvalidURL, ChunkedEncodingError,\n-    ContentDecodingError, ConnectionError, StreamConsumedError,\n-    InvalidJSONError)\n-from .exceptions import JSONDecodeError as RequestsJSONDecodeError\n-from .exceptions import SSLError as RequestsSSLError\n from ._internal_utils import to_native_string, unicode_is_ascii\n-from .utils import (\n-    guess_filename, get_auth_from_url, requote_uri,\n-    stream_decode_response_unicode, to_key_val_list, parse_header_links,\n-    iter_slices, guess_json_utf, super_len, check_header_validity)\n+from .auth import HTTPBasicAuth\n from .compat import (\n-    Callable, Mapping,\n-    cookielib, urlunparse, urlsplit, urlencode,\n-    chardet, builtin_str, basestring, JSONDecodeError)\n+    Callable,\n+    JSONDecodeError,\n+    Mapping,\n+    basestring,\n+    builtin_str,\n+    chardet,\n+    cookielib,\n+)\n from .compat import json as complexjson\n+from .compat import urlencode, urlsplit, urlunparse\n+from .cookies import _copy_cookie_jar, cookiejar_from_dict, get_cookie_header\n+from .exceptions import (\n+    ChunkedEncodingError,\n+    ConnectionError,\n+    ContentDecodingError,\n+    HTTPError,\n+    InvalidJSONError,\n+    InvalidURL,\n+)\n+from .exceptions import JSONDecodeError as RequestsJSONDecodeError\n+from .exceptions import MissingSchema\n+from .exceptions import SSLError as RequestsSSLError\n+from .exceptions import StreamConsumedError\n+from .hooks import default_hooks\n from .status_codes import codes\n+from .structures import CaseInsensitiveDict\n+from .utils import (\n+    check_header_validity,\n+    get_auth_from_url,\n+    guess_filename,\n+    guess_json_utf,\n+    iter_slices,\n+    parse_header_links,\n+    requote_uri,\n+    stream_decode_response_unicode,\n+    super_len,\n+    to_key_val_list,\n+)\n \n #: The set of HTTP status codes that indicate an automatically\n #: processable redirect.\n@@ -64,7 +81,7 @@ CONTENT_CHUNK_SIZE = 10 * 1024\n ITER_CHUNK_SIZE = 512\n \n \n-class RequestEncodingMixin(object):\n+class RequestEncodingMixin:\n     @property\n     def path_url(self):\n         \"\"\"Build the path URL to use.\"\"\"\n@@ -75,16 +92,16 @@ class RequestEncodingMixin(object):\n \n         path = p.path\n         if not path:\n-            path = '/'\n+            path = \"/\"\n \n         url.append(path)\n \n         query = p.query\n         if query:\n-            url.append('?')\n+            url.append(\"?\")\n             url.append(query)\n \n-        return ''.join(url)\n+        return \"\".join(url)\n \n     @staticmethod\n     def _encode_params(data):\n@@ -97,18 +114,21 @@ class RequestEncodingMixin(object):\n \n         if isinstance(data, (str, bytes)):\n             return data\n-        elif hasattr(data, 'read'):\n+        elif hasattr(data, \"read\"):\n             return data\n-        elif hasattr(data, '__iter__'):\n+        elif hasattr(data, \"__iter__\"):\n             result = []\n             for k, vs in to_key_val_list(data):\n-                if isinstance(vs, basestring) or not hasattr(vs, '__iter__'):\n+                if isinstance(vs, basestring) or not hasattr(vs, \"__iter__\"):\n                     vs = [vs]\n                 for v in vs:\n                     if v is not None:\n                         result.append(\n-                            (k.encode('utf-8') if isinstance(k, str) else k,\n-                             v.encode('utf-8') if isinstance(v, str) else v))\n+                            (\n+                                k.encode(\"utf-8\") if isinstance(k, str) else k,\n+                                v.encode(\"utf-8\") if isinstance(v, str) else v,\n+                            )\n+                        )\n             return urlencode(result, doseq=True)\n         else:\n             return data\n@@ -123,7 +143,7 @@ class RequestEncodingMixin(object):\n         The tuples may be 2-tuples (filename, fileobj), 3-tuples (filename, fileobj, contentype)\n         or 4-tuples (filename, fileobj, contentype, custom_headers).\n         \"\"\"\n-        if (not files):\n+        if not files:\n             raise ValueError(\"Files must be provided.\")\n         elif isinstance(data, basestring):\n             raise ValueError(\"Data must not be a string.\")\n@@ -133,7 +153,7 @@ class RequestEncodingMixin(object):\n         files = to_key_val_list(files or {})\n \n         for field, val in fields:\n-            if isinstance(val, basestring) or not hasattr(val, '__iter__'):\n+            if isinstance(val, basestring) or not hasattr(val, \"__iter__\"):\n                 val = [val]\n             for v in val:\n                 if v is not None:\n@@ -142,8 +162,13 @@ class RequestEncodingMixin(object):\n                         v = str(v)\n \n                     new_fields.append(\n-                        (field.decode('utf-8') if isinstance(field, bytes) else field,\n-                         v.encode('utf-8') if isinstance(v, str) else v))\n+                        (\n+                            field.decode(\"utf-8\")\n+                            if isinstance(field, bytes)\n+                            else field,\n+                            v.encode(\"utf-8\") if isinstance(v, str) else v,\n+                        )\n+                    )\n \n         for (k, v) in files:\n             # support for explicit filename\n@@ -162,7 +187,7 @@ class RequestEncodingMixin(object):\n \n             if isinstance(fp, (str, bytes, bytearray)):\n                 fdata = fp\n-            elif hasattr(fp, 'read'):\n+            elif hasattr(fp, \"read\"):\n                 fdata = fp.read()\n             elif fp is None:\n                 continue\n@@ -178,16 +203,16 @@ class RequestEncodingMixin(object):\n         return body, content_type\n \n \n-class RequestHooksMixin(object):\n+class RequestHooksMixin:\n     def register_hook(self, event, hook):\n         \"\"\"Properly register a hook.\"\"\"\n \n         if event not in self.hooks:\n-            raise ValueError('Unsupported event specified, with event name \"%s\"' % (event))\n+            raise ValueError(f'Unsupported event specified, with event name \"{event}\"')\n \n         if isinstance(hook, Callable):\n             self.hooks[event].append(hook)\n-        elif hasattr(hook, '__iter__'):\n+        elif hasattr(hook, \"__iter__\"):\n             self.hooks[event].extend(h for h in hook if isinstance(h, Callable))\n \n     def deregister_hook(self, event, hook):\n@@ -230,9 +255,19 @@ class Request(RequestHooksMixin):\n       <PreparedRequest [GET]>\n     \"\"\"\n \n-    def __init__(self,\n-            method=None, url=None, headers=None, files=None, data=None,\n-            params=None, auth=None, cookies=None, hooks=None, json=None):\n+    def __init__(\n+        self,\n+        method=None,\n+        url=None,\n+        headers=None,\n+        files=None,\n+        data=None,\n+        params=None,\n+        auth=None,\n+        cookies=None,\n+        hooks=None,\n+        json=None,\n+    ):\n \n         # Default empty dicts for dict params.\n         data = [] if data is None else data\n@@ -256,7 +291,7 @@ class Request(RequestHooksMixin):\n         self.cookies = cookies\n \n     def __repr__(self):\n-        return '<Request [%s]>' % (self.method)\n+        return f\"<Request [{self.method}]>\"\n \n     def prepare(self):\n         \"\"\"Constructs a :class:`PreparedRequest <PreparedRequest>` for transmission and returns it.\"\"\"\n@@ -314,9 +349,19 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n         #: integer denoting starting position of a readable file-like body.\n         self._body_position = None\n \n-    def prepare(self,\n-            method=None, url=None, headers=None, files=None, data=None,\n-            params=None, auth=None, cookies=None, hooks=None, json=None):\n+    def prepare(\n+        self,\n+        method=None,\n+        url=None,\n+        headers=None,\n+        files=None,\n+        data=None,\n+        params=None,\n+        auth=None,\n+        cookies=None,\n+        hooks=None,\n+        json=None,\n+    ):\n         \"\"\"Prepares the entire request with the given parameters.\"\"\"\n \n         self.prepare_method(method)\n@@ -333,7 +378,7 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n         self.prepare_hooks(hooks)\n \n     def __repr__(self):\n-        return '<PreparedRequest [%s]>' % (self.method)\n+        return f\"<PreparedRequest [{self.method}]>\"\n \n     def copy(self):\n         p = PreparedRequest()\n@@ -357,7 +402,7 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n         import idna\n \n         try:\n-            host = idna.encode(host, uts46=True).decode('utf-8')\n+            host = idna.encode(host, uts46=True).decode(\"utf-8\")\n         except idna.IDNAError:\n             raise UnicodeError\n         return host\n@@ -370,7 +415,7 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n         #: on python 3.x.\n         #: https://github.com/psf/requests/pull/2238\n         if isinstance(url, bytes):\n-            url = url.decode('utf8')\n+            url = url.decode(\"utf8\")\n         else:\n             url = str(url)\n \n@@ -380,7 +425,7 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n         # Don't do any URL preparation for non-HTTP schemes like `mailto`,\n         # `data` etc to work around exceptions from `url_parse`, which\n         # handles RFC 3986 only.\n-        if ':' in url and not url.lower().startswith('http'):\n+        if \":\" in url and not url.lower().startswith(\"http\"):\n             self.url = url\n             return\n \n@@ -391,13 +436,13 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n             raise InvalidURL(*e.args)\n \n         if not scheme:\n-            error = (\"Invalid URL {0!r}: No scheme supplied. Perhaps you meant http://{0}?\")\n-            error = error.format(to_native_string(url, 'utf8'))\n-\n-            raise MissingSchema(error)\n+            raise MissingSchema(\n+                f\"Invalid URL {url!r}: No scheme supplied. \"\n+                f\"Perhaps you meant http://{url}?\"\n+            )\n \n         if not host:\n-            raise InvalidURL(\"Invalid URL %r: No host supplied\" % url)\n+            raise InvalidURL(f\"Invalid URL {url!r}: No host supplied\")\n \n         # In general, we want to try IDNA encoding the hostname if the string contains\n         # non-ASCII characters. This allows users to automatically get the correct IDNA\n@@ -407,21 +452,21 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n             try:\n                 host = self._get_idna_encoded_host(host)\n             except UnicodeError:\n-                raise InvalidURL('URL has an invalid label.')\n-        elif host.startswith((u'*', u'.')):\n-            raise InvalidURL('URL has an invalid label.')\n+                raise InvalidURL(\"URL has an invalid label.\")\n+        elif host.startswith((\"*\", \".\")):\n+            raise InvalidURL(\"URL has an invalid label.\")\n \n         # Carefully reconstruct the network location\n-        netloc = auth or ''\n+        netloc = auth or \"\"\n         if netloc:\n-            netloc += '@'\n+            netloc += \"@\"\n         netloc += host\n         if port:\n-            netloc += ':' + str(port)\n+            netloc += f\":{port}\"\n \n         # Bare domains aren't valid URLs.\n         if not path:\n-            path = '/'\n+            path = \"/\"\n \n         if isinstance(params, (str, bytes)):\n             params = to_native_string(params)\n@@ -429,7 +474,7 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n         enc_params = self._encode_params(params)\n         if enc_params:\n             if query:\n-                query = '%s&%s' % (query, enc_params)\n+                query = f\"{query}&{enc_params}\"\n             else:\n                 query = enc_params\n \n@@ -460,7 +505,7 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n         if not data and json is not None:\n             # urllib3 requires a bytes-like body. Python 2's json.dumps\n             # provides this natively, but Python 3 gives a Unicode string.\n-            content_type = 'application/json'\n+            content_type = \"application/json\"\n \n             try:\n                 body = complexjson.dumps(json, allow_nan=False)\n@@ -468,12 +513,14 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n                 raise InvalidJSONError(ve, request=self)\n \n             if not isinstance(body, bytes):\n-                body = body.encode('utf-8')\n+                body = body.encode(\"utf-8\")\n \n-        is_stream = all([\n-            hasattr(data, '__iter__'),\n-            not isinstance(data, (basestring, list, tuple, Mapping))\n-        ])\n+        is_stream = all(\n+            [\n+                hasattr(data, \"__iter__\"),\n+                not isinstance(data, (basestring, list, tuple, Mapping)),\n+            ]\n+        )\n \n         if is_stream:\n             try:\n@@ -483,24 +530,26 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n \n             body = data\n \n-            if getattr(body, 'tell', None) is not None:\n+            if getattr(body, \"tell\", None) is not None:\n                 # Record the current file position before reading.\n                 # This will allow us to rewind a file in the event\n                 # of a redirect.\n                 try:\n                     self._body_position = body.tell()\n-                except (IOError, OSError):\n+                except OSError:\n                     # This differentiates from None, allowing us to catch\n                     # a failed `tell()` later when trying to rewind the body\n                     self._body_position = object()\n \n             if files:\n-                raise NotImplementedError('Streamed bodies and files are mutually exclusive.')\n+                raise NotImplementedError(\n+                    \"Streamed bodies and files are mutually exclusive.\"\n+                )\n \n             if length:\n-                self.headers['Content-Length'] = builtin_str(length)\n+                self.headers[\"Content-Length\"] = builtin_str(length)\n             else:\n-                self.headers['Transfer-Encoding'] = 'chunked'\n+                self.headers[\"Transfer-Encoding\"] = \"chunked\"\n         else:\n             # Multi-part file uploads.\n             if files:\n@@ -508,16 +557,16 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n             else:\n                 if data:\n                     body = self._encode_params(data)\n-                    if isinstance(data, basestring) or hasattr(data, 'read'):\n+                    if isinstance(data, basestring) or hasattr(data, \"read\"):\n                         content_type = None\n                     else:\n-                        content_type = 'application/x-www-form-urlencoded'\n+                        content_type = \"application/x-www-form-urlencoded\"\n \n             self.prepare_content_length(body)\n \n             # Add content-type if it wasn't explicitly provided.\n-            if content_type and ('content-type' not in self.headers):\n-                self.headers['Content-Type'] = content_type\n+            if content_type and (\"content-type\" not in self.headers):\n+                self.headers[\"Content-Type\"] = content_type\n \n         self.body = body\n \n@@ -528,13 +577,16 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n             if length:\n                 # If length exists, set it. Otherwise, we fallback\n                 # to Transfer-Encoding: chunked.\n-                self.headers['Content-Length'] = builtin_str(length)\n-        elif self.method not in ('GET', 'HEAD') and self.headers.get('Content-Length') is None:\n+                self.headers[\"Content-Length\"] = builtin_str(length)\n+        elif (\n+            self.method not in (\"GET\", \"HEAD\")\n+            and self.headers.get(\"Content-Length\") is None\n+        ):\n             # Set Content-Length to 0 for methods that can have a body\n             # but don't provide one. (i.e. not GET or HEAD)\n-            self.headers['Content-Length'] = '0'\n+            self.headers[\"Content-Length\"] = \"0\"\n \n-    def prepare_auth(self, auth, url=''):\n+    def prepare_auth(self, auth, url=\"\"):\n         \"\"\"Prepares the given HTTP auth data.\"\"\"\n \n         # If no Auth is explicitly provided, extract it from the URL first.\n@@ -574,7 +626,7 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n \n         cookie_header = get_cookie_header(self._cookies, self)\n         if cookie_header is not None:\n-            self.headers['Cookie'] = cookie_header\n+            self.headers[\"Cookie\"] = cookie_header\n \n     def prepare_hooks(self, hooks):\n         \"\"\"Prepares the given hooks.\"\"\"\n@@ -586,14 +638,22 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n             self.register_hook(event, hooks[event])\n \n \n-class Response(object):\n+class Response:\n     \"\"\"The :class:`Response <Response>` object, which contains a\n     server's response to an HTTP request.\n     \"\"\"\n \n     __attrs__ = [\n-        '_content', 'status_code', 'headers', 'url', 'history',\n-        'encoding', 'reason', 'cookies', 'elapsed', 'request'\n+        \"_content\",\n+        \"status_code\",\n+        \"headers\",\n+        \"url\",\n+        \"history\",\n+        \"encoding\",\n+        \"reason\",\n+        \"cookies\",\n+        \"elapsed\",\n+        \"request\",\n     ]\n \n     def __init__(self):\n@@ -662,11 +722,11 @@ class Response(object):\n             setattr(self, name, value)\n \n         # pickled objects do not have .raw\n-        setattr(self, '_content_consumed', True)\n-        setattr(self, 'raw', None)\n+        setattr(self, \"_content_consumed\", True)\n+        setattr(self, \"raw\", None)\n \n     def __repr__(self):\n-        return '<Response [%s]>' % (self.status_code)\n+        return f\"<Response [{self.status_code}]>\"\n \n     def __bool__(self):\n         \"\"\"Returns True if :attr:`status_code` is less than 400.\n@@ -712,12 +772,15 @@ class Response(object):\n         \"\"\"True if this Response is a well-formed HTTP redirect that could have\n         been processed automatically (by :meth:`Session.resolve_redirects`).\n         \"\"\"\n-        return ('location' in self.headers and self.status_code in REDIRECT_STATI)\n+        return \"location\" in self.headers and self.status_code in REDIRECT_STATI\n \n     @property\n     def is_permanent_redirect(self):\n         \"\"\"True if this Response one of the permanent versions of redirect.\"\"\"\n-        return ('location' in self.headers and self.status_code in (codes.moved_permanently, codes.permanent_redirect))\n+        return \"location\" in self.headers and self.status_code in (\n+            codes.moved_permanently,\n+            codes.permanent_redirect,\n+        )\n \n     @property\n     def next(self):\n@@ -727,7 +790,7 @@ class Response(object):\n     @property\n     def apparent_encoding(self):\n         \"\"\"The apparent encoding, provided by the charset_normalizer or chardet libraries.\"\"\"\n-        return chardet.detect(self.content)['encoding']\n+        return chardet.detect(self.content)[\"encoding\"]\n \n     def iter_content(self, chunk_size=1, decode_unicode=False):\n         \"\"\"Iterates over the response data.  When stream=True is set on the\n@@ -748,7 +811,7 @@ class Response(object):\n \n         def generate():\n             # Special case for urllib3.\n-            if hasattr(self.raw, 'stream'):\n+            if hasattr(self.raw, \"stream\"):\n                 try:\n                     for chunk in self.raw.stream(chunk_size, decode_content=True):\n                         yield chunk\n@@ -773,7 +836,9 @@ class Response(object):\n         if self._content_consumed and isinstance(self._content, bool):\n             raise StreamConsumedError()\n         elif chunk_size is not None and not isinstance(chunk_size, int):\n-            raise TypeError(\"chunk_size must be an int, it is instead a %s.\" % type(chunk_size))\n+            raise TypeError(\n+                f\"chunk_size must be an int, it is instead a {type(chunk_size)}.\"\n+            )\n         # simulate reading small chunks of the content\n         reused_chunks = iter_slices(self._content, chunk_size)\n \n@@ -786,7 +851,9 @@ class Response(object):\n \n         return chunks\n \n-    def iter_lines(self, chunk_size=ITER_CHUNK_SIZE, decode_unicode=False, delimiter=None):\n+    def iter_lines(\n+        self, chunk_size=ITER_CHUNK_SIZE, decode_unicode=False, delimiter=None\n+    ):\n         \"\"\"Iterates over the response data, one line at a time.  When\n         stream=True is set on the request, this avoids reading the\n         content at once into memory for large responses.\n@@ -796,7 +863,9 @@ class Response(object):\n \n         pending = None\n \n-        for chunk in self.iter_content(chunk_size=chunk_size, decode_unicode=decode_unicode):\n+        for chunk in self.iter_content(\n+            chunk_size=chunk_size, decode_unicode=decode_unicode\n+        ):\n \n             if pending is not None:\n                 chunk = pending + chunk\n@@ -811,8 +880,7 @@ class Response(object):\n             else:\n                 pending = None\n \n-            for line in lines:\n-                yield line\n+            yield from lines\n \n         if pending is not None:\n             yield pending\n@@ -824,13 +892,12 @@ class Response(object):\n         if self._content is False:\n             # Read the contents.\n             if self._content_consumed:\n-                raise RuntimeError(\n-                    'The content for this response was already consumed')\n+                raise RuntimeError(\"The content for this response was already consumed\")\n \n             if self.status_code == 0 or self.raw is None:\n                 self._content = None\n             else:\n-                self._content = b''.join(self.iter_content(CONTENT_CHUNK_SIZE)) or b''\n+                self._content = b\"\".join(self.iter_content(CONTENT_CHUNK_SIZE)) or b\"\"\n \n         self._content_consumed = True\n         # don't need to release the connection; that's been handled by urllib3\n@@ -855,7 +922,7 @@ class Response(object):\n         encoding = self.encoding\n \n         if not self.content:\n-            return str('')\n+            return \"\"\n \n         # Fallback to auto-detected encoding.\n         if self.encoding is None:\n@@ -863,7 +930,7 @@ class Response(object):\n \n         # Decode unicode from given encoding.\n         try:\n-            content = str(self.content, encoding, errors='replace')\n+            content = str(self.content, encoding, errors=\"replace\")\n         except (LookupError, TypeError):\n             # A LookupError is raised if the encoding was not found which could\n             # indicate a misspelling or similar mistake.\n@@ -871,7 +938,7 @@ class Response(object):\n             # A TypeError can be raised if encoding is None\n             #\n             # So we try blindly encoding.\n-            content = str(self.content, errors='replace')\n+            content = str(self.content, errors=\"replace\")\n \n         return content\n \n@@ -891,9 +958,7 @@ class Response(object):\n             encoding = guess_json_utf(self.content)\n             if encoding is not None:\n                 try:\n-                    return complexjson.loads(\n-                        self.content.decode(encoding), **kwargs\n-                    )\n+                    return complexjson.loads(self.content.decode(encoding), **kwargs)\n                 except UnicodeDecodeError:\n                     # Wrong UTF codec detected; usually because it's not UTF-8\n                     # but some other 8-bit codec.  This is an RFC violation,\n@@ -914,41 +979,44 @@ class Response(object):\n     def links(self):\n         \"\"\"Returns the parsed header links of the response, if any.\"\"\"\n \n-        header = self.headers.get('link')\n+        header = self.headers.get(\"link\")\n \n-        # l = MultiDict()\n-        l = {}\n+        resolved_links = {}\n \n         if header:\n             links = parse_header_links(header)\n \n             for link in links:\n-                key = link.get('rel') or link.get('url')\n-                l[key] = link\n+                key = link.get(\"rel\") or link.get(\"url\")\n+                resolved_links[key] = link\n \n-        return l\n+        return resolved_links\n \n     def raise_for_status(self):\n         \"\"\"Raises :class:`HTTPError`, if one occurred.\"\"\"\n \n-        http_error_msg = ''\n+        http_error_msg = \"\"\n         if isinstance(self.reason, bytes):\n             # We attempt to decode utf-8 first because some servers\n             # choose to localize their reason strings. If the string\n             # isn't utf-8, we fall back to iso-8859-1 for all other\n             # encodings. (See PR #3538)\n             try:\n-                reason = self.reason.decode('utf-8')\n+                reason = self.reason.decode(\"utf-8\")\n             except UnicodeDecodeError:\n-                reason = self.reason.decode('iso-8859-1')\n+                reason = self.reason.decode(\"iso-8859-1\")\n         else:\n             reason = self.reason\n \n         if 400 <= self.status_code < 500:\n-            http_error_msg = u'%s Client Error: %s for url: %s' % (self.status_code, reason, self.url)\n+            http_error_msg = (\n+                f\"{self.status_code} Client Error: {reason} for url: {self.url}\"\n+            )\n \n         elif 500 <= self.status_code < 600:\n-            http_error_msg = u'%s Server Error: %s for url: %s' % (self.status_code, reason, self.url)\n+            http_error_msg = (\n+                f\"{self.status_code} Server Error: {reason} for url: {self.url}\"\n+            )\n \n         if http_error_msg:\n             raise HTTPError(http_error_msg, response=self)\n@@ -962,6 +1030,6 @@ class Response(object):\n         if not self._content_consumed:\n             self.raw.close()\n \n-        release_conn = getattr(self.raw, 'release_conn', None)\n+        release_conn = getattr(self.raw, \"release_conn\", None)\n         if release_conn is not None:\n             release_conn()\n\n@@ -3,24 +3,26 @@ import sys\n try:\n     import chardet\n except ImportError:\n-    import charset_normalizer as chardet\n     import warnings\n \n-    warnings.filterwarnings('ignore', 'Trying to detect', module='charset_normalizer')\n+    import charset_normalizer as chardet\n+\n+    warnings.filterwarnings(\"ignore\", \"Trying to detect\", module=\"charset_normalizer\")\n \n # This code exists for backwards compatibility reasons.\n # I don't like it either. Just look the other way. :)\n \n-for package in ('urllib3', 'idna'):\n+for package in (\"urllib3\", \"idna\"):\n     locals()[package] = __import__(package)\n     # This traversal is apparently necessary such that the identities are\n     # preserved (requests.packages.urllib3.* is urllib3.*)\n     for mod in list(sys.modules):\n-        if mod == package or mod.startswith(package + '.'):\n-            sys.modules['requests.packages.' + mod] = sys.modules[mod]\n+        if mod == package or mod.startswith(f\"{package}.\"):\n+            sys.modules[f\"requests.packages.{mod}\"] = sys.modules[mod]\n \n target = chardet.__name__\n for mod in list(sys.modules):\n-    if mod == target or mod.startswith(target + '.'):\n-        sys.modules['requests.packages.' + target.replace(target, 'chardet')] = sys.modules[mod]\n+    if mod == target or mod.startswith(f\"{target}.\"):\n+        target = target.replace(target, \"chardet\")\n+        sys.modules[f\"requests.packages.{target}\"] = sys.modules[mod]\n # Kinda cool, though, right?\n\n@@ -1,5 +1,3 @@\n-# -*- coding: utf-8 -*-\n-\n \"\"\"\n requests.sessions\n ~~~~~~~~~~~~~~~~~\n@@ -10,35 +8,51 @@ requests (cookies, auth, proxies).\n import os\n import sys\n import time\n-from datetime import timedelta\n from collections import OrderedDict\n+from datetime import timedelta\n \n-from .auth import _basic_auth_str\n-from .compat import cookielib, urljoin, urlparse, Mapping\n-from .cookies import (\n-    cookiejar_from_dict, extract_cookies_to_jar, RequestsCookieJar, merge_cookies)\n-from .models import Request, PreparedRequest, DEFAULT_REDIRECT_LIMIT\n-from .hooks import default_hooks, dispatch_hook\n from ._internal_utils import to_native_string\n-from .utils import to_key_val_list, default_headers, DEFAULT_PORTS\n-from .exceptions import (\n-    TooManyRedirects, InvalidSchema, ChunkedEncodingError, ContentDecodingError)\n-\n-from .structures import CaseInsensitiveDict\n from .adapters import HTTPAdapter\n-\n-from .utils import (\n-    requote_uri, get_environ_proxies, get_netrc_auth, should_bypass_proxies,\n-    get_auth_from_url, rewind_body, resolve_proxies\n+from .auth import _basic_auth_str\n+from .compat import Mapping, cookielib, urljoin, urlparse\n+from .cookies import (\n+    RequestsCookieJar,\n+    cookiejar_from_dict,\n+    extract_cookies_to_jar,\n+    merge_cookies,\n )\n-\n-from .status_codes import codes\n+from .exceptions import (\n+    ChunkedEncodingError,\n+    ContentDecodingError,\n+    InvalidSchema,\n+    TooManyRedirects,\n+)\n+from .hooks import default_hooks, dispatch_hook\n \n # formerly defined here, reexposed here for backward compatibility\n-from .models import REDIRECT_STATI\n+from .models import (  # noqa: F401\n+    DEFAULT_REDIRECT_LIMIT,\n+    REDIRECT_STATI,\n+    PreparedRequest,\n+    Request,\n+)\n+from .status_codes import codes\n+from .structures import CaseInsensitiveDict\n+from .utils import (  # noqa: F401\n+    DEFAULT_PORTS,\n+    default_headers,\n+    get_auth_from_url,\n+    get_environ_proxies,\n+    get_netrc_auth,\n+    requote_uri,\n+    resolve_proxies,\n+    rewind_body,\n+    should_bypass_proxies,\n+    to_key_val_list,\n+)\n \n # Preferred clock, based on which one is more accurate on a given system.\n-if sys.platform == 'win32':\n+if sys.platform == \"win32\":\n     preferred_clock = time.perf_counter\n else:\n     preferred_clock = time.time\n@@ -58,8 +72,7 @@ def merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n \n     # Bypass if not a dictionary (e.g. verify)\n     if not (\n-            isinstance(session_setting, Mapping) and\n-            isinstance(request_setting, Mapping)\n+        isinstance(session_setting, Mapping) and isinstance(request_setting, Mapping)\n     ):\n         return request_setting\n \n@@ -81,17 +94,16 @@ def merge_hooks(request_hooks, session_hooks, dict_class=OrderedDict):\n     This is necessary because when request_hooks == {'response': []}, the\n     merge breaks Session hooks entirely.\n     \"\"\"\n-    if session_hooks is None or session_hooks.get('response') == []:\n+    if session_hooks is None or session_hooks.get(\"response\") == []:\n         return request_hooks\n \n-    if request_hooks is None or request_hooks.get('response') == []:\n+    if request_hooks is None or request_hooks.get(\"response\") == []:\n         return session_hooks\n \n     return merge_setting(request_hooks, session_hooks, dict_class)\n \n \n-class SessionRedirectMixin(object):\n-\n+class SessionRedirectMixin:\n     def get_redirect_target(self, resp):\n         \"\"\"Receives a Response. Returns a redirect URI or ``None``\"\"\"\n         # Due to the nature of how requests processes redirects this method will\n@@ -101,15 +113,15 @@ class SessionRedirectMixin(object):\n         # to cache the redirect location onto the response object as a private\n         # attribute.\n         if resp.is_redirect:\n-            location = resp.headers['location']\n+            location = resp.headers[\"location\"]\n             # Currently the underlying http module on py3 decode headers\n             # in latin1, but empirical evidence suggests that latin1 is very\n             # rarely used with non-ASCII characters in HTTP headers.\n             # It is more likely to get UTF8 header rather than latin1.\n             # This causes incorrect handling of UTF8 encoded location headers.\n             # To solve this, we re-encode the location in latin1.\n-            location = location.encode('latin1')\n-            return to_native_string(location, 'utf8')\n+            location = location.encode(\"latin1\")\n+            return to_native_string(location, \"utf8\")\n         return None\n \n     def should_strip_auth(self, old_url, new_url):\n@@ -122,23 +134,40 @@ class SessionRedirectMixin(object):\n         # ports. This isn't specified by RFC 7235, but is kept to avoid\n         # breaking backwards compatibility with older versions of requests\n         # that allowed any redirects on the same host.\n-        if (old_parsed.scheme == 'http' and old_parsed.port in (80, None)\n-                and new_parsed.scheme == 'https' and new_parsed.port in (443, None)):\n+        if (\n+            old_parsed.scheme == \"http\"\n+            and old_parsed.port in (80, None)\n+            and new_parsed.scheme == \"https\"\n+            and new_parsed.port in (443, None)\n+        ):\n             return False\n \n         # Handle default port usage corresponding to scheme.\n         changed_port = old_parsed.port != new_parsed.port\n         changed_scheme = old_parsed.scheme != new_parsed.scheme\n         default_port = (DEFAULT_PORTS.get(old_parsed.scheme, None), None)\n-        if (not changed_scheme and old_parsed.port in default_port\n-                and new_parsed.port in default_port):\n+        if (\n+            not changed_scheme\n+            and old_parsed.port in default_port\n+            and new_parsed.port in default_port\n+        ):\n             return False\n \n         # Standard case: root URI must match\n         return changed_port or changed_scheme\n \n-    def resolve_redirects(self, resp, req, stream=False, timeout=None,\n-                          verify=True, cert=None, proxies=None, yield_requests=False, **adapter_kwargs):\n+    def resolve_redirects(\n+        self,\n+        resp,\n+        req,\n+        stream=False,\n+        timeout=None,\n+        verify=True,\n+        cert=None,\n+        proxies=None,\n+        yield_requests=False,\n+        **adapter_kwargs,\n+    ):\n         \"\"\"Receives a Response. Returns a generator of Responses or Requests.\"\"\"\n \n         hist = []  # keep track of history\n@@ -159,19 +188,21 @@ class SessionRedirectMixin(object):\n                 resp.raw.read(decode_content=False)\n \n             if len(resp.history) >= self.max_redirects:\n-                raise TooManyRedirects('Exceeded {} redirects.'.format(self.max_redirects), response=resp)\n+                raise TooManyRedirects(\n+                    f\"Exceeded {self.max_redirects} redirects.\", response=resp\n+                )\n \n             # Release the connection back into the pool.\n             resp.close()\n \n             # Handle redirection without scheme (see: RFC 1808 Section 4)\n-            if url.startswith('//'):\n+            if url.startswith(\"//\"):\n                 parsed_rurl = urlparse(resp.url)\n-                url = ':'.join([to_native_string(parsed_rurl.scheme), url])\n+                url = \":\".join([to_native_string(parsed_rurl.scheme), url])\n \n             # Normalize url case and attach previous fragment if needed (RFC 7231 7.1.2)\n             parsed = urlparse(url)\n-            if parsed.fragment == '' and previous_fragment:\n+            if parsed.fragment == \"\" and previous_fragment:\n                 parsed = parsed._replace(fragment=previous_fragment)\n             elif parsed.fragment:\n                 previous_fragment = parsed.fragment\n@@ -190,15 +221,18 @@ class SessionRedirectMixin(object):\n             self.rebuild_method(prepared_request, resp)\n \n             # https://github.com/psf/requests/issues/1084\n-            if resp.status_code not in (codes.temporary_redirect, codes.permanent_redirect):\n+            if resp.status_code not in (\n+                codes.temporary_redirect,\n+                codes.permanent_redirect,\n+            ):\n                 # https://github.com/psf/requests/issues/3490\n-                purged_headers = ('Content-Length', 'Content-Type', 'Transfer-Encoding')\n+                purged_headers = (\"Content-Length\", \"Content-Type\", \"Transfer-Encoding\")\n                 for header in purged_headers:\n                     prepared_request.headers.pop(header, None)\n                 prepared_request.body = None\n \n             headers = prepared_request.headers\n-            headers.pop('Cookie', None)\n+            headers.pop(\"Cookie\", None)\n \n             # Extract any cookies sent on the response to the cookiejar\n             # in the new request. Because we've mutated our copied prepared\n@@ -214,9 +248,8 @@ class SessionRedirectMixin(object):\n             # A failed tell() sets `_body_position` to `object()`. This non-None\n             # value ensures `rewindable` will be True, allowing us to raise an\n             # UnrewindableBodyError, instead of hanging the connection.\n-            rewindable = (\n-                prepared_request._body_position is not None and\n-                ('Content-Length' in headers or 'Transfer-Encoding' in headers)\n+            rewindable = prepared_request._body_position is not None and (\n+                \"Content-Length\" in headers or \"Transfer-Encoding\" in headers\n             )\n \n             # Attempt to rewind consumed file-like object.\n@@ -238,7 +271,7 @@ class SessionRedirectMixin(object):\n                     cert=cert,\n                     proxies=proxies,\n                     allow_redirects=False,\n-                    **adapter_kwargs\n+                    **adapter_kwargs,\n                 )\n \n                 extract_cookies_to_jar(self.cookies, prepared_request, resp.raw)\n@@ -255,10 +288,12 @@ class SessionRedirectMixin(object):\n         headers = prepared_request.headers\n         url = prepared_request.url\n \n-        if 'Authorization' in headers and self.should_strip_auth(response.request.url, url):\n+        if \"Authorization\" in headers and self.should_strip_auth(\n+            response.request.url, url\n+        ):\n             # If we get redirected to a new host, we should strip out any\n             # authentication headers.\n-            del headers['Authorization']\n+            del headers[\"Authorization\"]\n \n         # .netrc might have more auth for us on our new host.\n         new_auth = get_netrc_auth(url) if self.trust_env else None\n@@ -281,8 +316,8 @@ class SessionRedirectMixin(object):\n         scheme = urlparse(prepared_request.url).scheme\n         new_proxies = resolve_proxies(prepared_request, proxies, self.trust_env)\n \n-        if 'Proxy-Authorization' in headers:\n-            del headers['Proxy-Authorization']\n+        if \"Proxy-Authorization\" in headers:\n+            del headers[\"Proxy-Authorization\"]\n \n         try:\n             username, password = get_auth_from_url(new_proxies[scheme])\n@@ -290,7 +325,7 @@ class SessionRedirectMixin(object):\n             username, password = None, None\n \n         if username and password:\n-            headers['Proxy-Authorization'] = _basic_auth_str(username, password)\n+            headers[\"Proxy-Authorization\"] = _basic_auth_str(username, password)\n \n         return new_proxies\n \n@@ -301,18 +336,18 @@ class SessionRedirectMixin(object):\n         method = prepared_request.method\n \n         # https://tools.ietf.org/html/rfc7231#section-6.4.4\n-        if response.status_code == codes.see_other and method != 'HEAD':\n-            method = 'GET'\n+        if response.status_code == codes.see_other and method != \"HEAD\":\n+            method = \"GET\"\n \n         # Do what the browsers do, despite standards...\n         # First, turn 302s into GETs.\n-        if response.status_code == codes.found and method != 'HEAD':\n-            method = 'GET'\n+        if response.status_code == codes.found and method != \"HEAD\":\n+            method = \"GET\"\n \n         # Second, if a POST is responded to with a 301, turn it into a GET.\n         # This bizarre behaviour is explained in Issue 1704.\n-        if response.status_code == codes.moved and method == 'POST':\n-            method = 'GET'\n+        if response.status_code == codes.moved and method == \"POST\":\n+            method = \"GET\"\n \n         prepared_request.method = method\n \n@@ -337,9 +372,18 @@ class Session(SessionRedirectMixin):\n     \"\"\"\n \n     __attrs__ = [\n-        'headers', 'cookies', 'auth', 'proxies', 'hooks', 'params', 'verify',\n-        'cert', 'adapters', 'stream', 'trust_env',\n-        'max_redirects',\n+        \"headers\",\n+        \"cookies\",\n+        \"auth\",\n+        \"proxies\",\n+        \"hooks\",\n+        \"params\",\n+        \"verify\",\n+        \"cert\",\n+        \"adapters\",\n+        \"stream\",\n+        \"trust_env\",\n+        \"max_redirects\",\n     ]\n \n     def __init__(self):\n@@ -401,8 +445,8 @@ class Session(SessionRedirectMixin):\n \n         # Default connection adapters.\n         self.adapters = OrderedDict()\n-        self.mount('https://', HTTPAdapter())\n-        self.mount('http://', HTTPAdapter())\n+        self.mount(\"https://\", HTTPAdapter())\n+        self.mount(\"http://\", HTTPAdapter())\n \n     def __enter__(self):\n         return self\n@@ -428,7 +472,8 @@ class Session(SessionRedirectMixin):\n \n         # Merge with session cookies\n         merged_cookies = merge_cookies(\n-            merge_cookies(RequestsCookieJar(), self.cookies), cookies)\n+            merge_cookies(RequestsCookieJar(), self.cookies), cookies\n+        )\n \n         # Set environment's basic authentication if not explicitly set.\n         auth = request.auth\n@@ -442,7 +487,9 @@ class Session(SessionRedirectMixin):\n             files=request.files,\n             data=request.data,\n             json=request.json,\n-            headers=merge_setting(request.headers, self.headers, dict_class=CaseInsensitiveDict),\n+            headers=merge_setting(\n+                request.headers, self.headers, dict_class=CaseInsensitiveDict\n+            ),\n             params=merge_setting(request.params, self.params),\n             auth=merge_setting(auth, self.auth),\n             cookies=merged_cookies,\n@@ -450,10 +497,25 @@ class Session(SessionRedirectMixin):\n         )\n         return p\n \n-    def request(self, method, url,\n-            params=None, data=None, headers=None, cookies=None, files=None,\n-            auth=None, timeout=None, allow_redirects=True, proxies=None,\n-            hooks=None, stream=None, verify=None, cert=None, json=None):\n+    def request(\n+        self,\n+        method,\n+        url,\n+        params=None,\n+        data=None,\n+        headers=None,\n+        cookies=None,\n+        files=None,\n+        auth=None,\n+        timeout=None,\n+        allow_redirects=True,\n+        proxies=None,\n+        hooks=None,\n+        stream=None,\n+        verify=None,\n+        cert=None,\n+        json=None,\n+    ):\n         \"\"\"Constructs a :class:`Request <Request>`, prepares it and sends it.\n         Returns :class:`Response <Response>` object.\n \n@@ -518,8 +580,8 @@ class Session(SessionRedirectMixin):\n \n         # Send the request.\n         send_kwargs = {\n-            'timeout': timeout,\n-            'allow_redirects': allow_redirects,\n+            \"timeout\": timeout,\n+            \"allow_redirects\": allow_redirects,\n         }\n         send_kwargs.update(settings)\n         resp = self.send(prep, **send_kwargs)\n@@ -534,8 +596,8 @@ class Session(SessionRedirectMixin):\n         :rtype: requests.Response\n         \"\"\"\n \n-        kwargs.setdefault('allow_redirects', True)\n-        return self.request('GET', url, **kwargs)\n+        kwargs.setdefault(\"allow_redirects\", True)\n+        return self.request(\"GET\", url, **kwargs)\n \n     def options(self, url, **kwargs):\n         r\"\"\"Sends a OPTIONS request. Returns :class:`Response` object.\n@@ -545,8 +607,8 @@ class Session(SessionRedirectMixin):\n         :rtype: requests.Response\n         \"\"\"\n \n-        kwargs.setdefault('allow_redirects', True)\n-        return self.request('OPTIONS', url, **kwargs)\n+        kwargs.setdefault(\"allow_redirects\", True)\n+        return self.request(\"OPTIONS\", url, **kwargs)\n \n     def head(self, url, **kwargs):\n         r\"\"\"Sends a HEAD request. Returns :class:`Response` object.\n@@ -556,8 +618,8 @@ class Session(SessionRedirectMixin):\n         :rtype: requests.Response\n         \"\"\"\n \n-        kwargs.setdefault('allow_redirects', False)\n-        return self.request('HEAD', url, **kwargs)\n+        kwargs.setdefault(\"allow_redirects\", False)\n+        return self.request(\"HEAD\", url, **kwargs)\n \n     def post(self, url, data=None, json=None, **kwargs):\n         r\"\"\"Sends a POST request. Returns :class:`Response` object.\n@@ -570,7 +632,7 @@ class Session(SessionRedirectMixin):\n         :rtype: requests.Response\n         \"\"\"\n \n-        return self.request('POST', url, data=data, json=json, **kwargs)\n+        return self.request(\"POST\", url, data=data, json=json, **kwargs)\n \n     def put(self, url, data=None, **kwargs):\n         r\"\"\"Sends a PUT request. Returns :class:`Response` object.\n@@ -582,7 +644,7 @@ class Session(SessionRedirectMixin):\n         :rtype: requests.Response\n         \"\"\"\n \n-        return self.request('PUT', url, data=data, **kwargs)\n+        return self.request(\"PUT\", url, data=data, **kwargs)\n \n     def patch(self, url, data=None, **kwargs):\n         r\"\"\"Sends a PATCH request. Returns :class:`Response` object.\n@@ -594,7 +656,7 @@ class Session(SessionRedirectMixin):\n         :rtype: requests.Response\n         \"\"\"\n \n-        return self.request('PATCH', url, data=data, **kwargs)\n+        return self.request(\"PATCH\", url, data=data, **kwargs)\n \n     def delete(self, url, **kwargs):\n         r\"\"\"Sends a DELETE request. Returns :class:`Response` object.\n@@ -604,7 +666,7 @@ class Session(SessionRedirectMixin):\n         :rtype: requests.Response\n         \"\"\"\n \n-        return self.request('DELETE', url, **kwargs)\n+        return self.request(\"DELETE\", url, **kwargs)\n \n     def send(self, request, **kwargs):\n         \"\"\"Send a given PreparedRequest.\n@@ -613,22 +675,20 @@ class Session(SessionRedirectMixin):\n         \"\"\"\n         # Set defaults that the hooks can utilize to ensure they always have\n         # the correct parameters to reproduce the previous request.\n-        kwargs.setdefault('stream', self.stream)\n-        kwargs.setdefault('verify', self.verify)\n-        kwargs.setdefault('cert', self.cert)\n-        if 'proxies' not in kwargs:\n-            kwargs['proxies'] = resolve_proxies(\n-                request, self.proxies, self.trust_env\n-            )\n+        kwargs.setdefault(\"stream\", self.stream)\n+        kwargs.setdefault(\"verify\", self.verify)\n+        kwargs.setdefault(\"cert\", self.cert)\n+        if \"proxies\" not in kwargs:\n+            kwargs[\"proxies\"] = resolve_proxies(request, self.proxies, self.trust_env)\n \n         # It's possible that users might accidentally send a Request object.\n         # Guard against that specific failure case.\n         if isinstance(request, Request):\n-            raise ValueError('You can only send PreparedRequests.')\n+            raise ValueError(\"You can only send PreparedRequests.\")\n \n         # Set up variables needed for resolve_redirects and dispatching of hooks\n-        allow_redirects = kwargs.pop('allow_redirects', True)\n-        stream = kwargs.get('stream')\n+        allow_redirects = kwargs.pop(\"allow_redirects\", True)\n+        stream = kwargs.get(\"stream\")\n         hooks = request.hooks\n \n         # Get the appropriate adapter to use\n@@ -645,7 +705,7 @@ class Session(SessionRedirectMixin):\n         r.elapsed = timedelta(seconds=elapsed)\n \n         # Response manipulation hooks\n-        r = dispatch_hook('response', hooks, r, **kwargs)\n+        r = dispatch_hook(\"response\", hooks, r, **kwargs)\n \n         # Persist cookies\n         if r.history:\n@@ -675,7 +735,9 @@ class Session(SessionRedirectMixin):\n         # If redirects aren't being followed, store the response on the Request for Response.next().\n         if not allow_redirects:\n             try:\n-                r._next = next(self.resolve_redirects(r, request, yield_requests=True, **kwargs))\n+                r._next = next(\n+                    self.resolve_redirects(r, request, yield_requests=True, **kwargs)\n+                )\n             except StopIteration:\n                 pass\n \n@@ -693,7 +755,7 @@ class Session(SessionRedirectMixin):\n         # Gather clues from the surrounding environment.\n         if self.trust_env:\n             # Set environment's proxies.\n-            no_proxy = proxies.get('no_proxy') if proxies is not None else None\n+            no_proxy = proxies.get(\"no_proxy\") if proxies is not None else None\n             env_proxies = get_environ_proxies(url, no_proxy=no_proxy)\n             for (k, v) in env_proxies.items():\n                 proxies.setdefault(k, v)\n@@ -702,8 +764,8 @@ class Session(SessionRedirectMixin):\n             # and be compatible with cURL.\n             if verify is True or verify is None:\n                 verify = (\n-                    os.environ.get('REQUESTS_CA_BUNDLE')\n-                    or os.environ.get('CURL_CA_BUNDLE')\n+                    os.environ.get(\"REQUESTS_CA_BUNDLE\")\n+                    or os.environ.get(\"CURL_CA_BUNDLE\")\n                     or verify\n                 )\n \n@@ -713,12 +775,7 @@ class Session(SessionRedirectMixin):\n         verify = merge_setting(verify, self.verify)\n         cert = merge_setting(cert, self.cert)\n \n-        return {\n-            'proxies': proxies,\n-            'stream': stream,\n-            'verify': verify,\n-            'cert': cert\n-        }\n+        return {\"proxies\": proxies, \"stream\": stream, \"verify\": verify, \"cert\": cert}\n \n     def get_adapter(self, url):\n         \"\"\"\n@@ -732,7 +789,7 @@ class Session(SessionRedirectMixin):\n                 return adapter\n \n         # Nothing matches :-/\n-        raise InvalidSchema(\"No connection adapters were found for {!r}\".format(url))\n+        raise InvalidSchema(f\"No connection adapters were found for {url!r}\")\n \n     def close(self):\n         \"\"\"Closes all adapters and as such the session\"\"\"\n\n@@ -1,5 +1,3 @@\n-# -*- coding: utf-8 -*-\n-\n r\"\"\"\n The ``codes`` object defines a mapping from common names for HTTP statuses\n to their numerical codes, accessible either as attributes or as dictionary\n@@ -23,101 +21,108 @@ the names are allowed. For example, ``codes.ok``, ``codes.OK``, and\n from .structures import LookupDict\n \n _codes = {\n-\n     # Informational.\n-    100: ('continue',),\n-    101: ('switching_protocols',),\n-    102: ('processing',),\n-    103: ('checkpoint',),\n-    122: ('uri_too_long', 'request_uri_too_long'),\n-    200: ('ok', 'okay', 'all_ok', 'all_okay', 'all_good', '\\\\o/', '✓'),\n-    201: ('created',),\n-    202: ('accepted',),\n-    203: ('non_authoritative_info', 'non_authoritative_information'),\n-    204: ('no_content',),\n-    205: ('reset_content', 'reset'),\n-    206: ('partial_content', 'partial'),\n-    207: ('multi_status', 'multiple_status', 'multi_stati', 'multiple_stati'),\n-    208: ('already_reported',),\n-    226: ('im_used',),\n-\n+    100: (\"continue\",),\n+    101: (\"switching_protocols\",),\n+    102: (\"processing\",),\n+    103: (\"checkpoint\",),\n+    122: (\"uri_too_long\", \"request_uri_too_long\"),\n+    200: (\"ok\", \"okay\", \"all_ok\", \"all_okay\", \"all_good\", \"\\\\o/\", \"✓\"),\n+    201: (\"created\",),\n+    202: (\"accepted\",),\n+    203: (\"non_authoritative_info\", \"non_authoritative_information\"),\n+    204: (\"no_content\",),\n+    205: (\"reset_content\", \"reset\"),\n+    206: (\"partial_content\", \"partial\"),\n+    207: (\"multi_status\", \"multiple_status\", \"multi_stati\", \"multiple_stati\"),\n+    208: (\"already_reported\",),\n+    226: (\"im_used\",),\n     # Redirection.\n-    300: ('multiple_choices',),\n-    301: ('moved_permanently', 'moved', '\\\\o-'),\n-    302: ('found',),\n-    303: ('see_other', 'other'),\n-    304: ('not_modified',),\n-    305: ('use_proxy',),\n-    306: ('switch_proxy',),\n-    307: ('temporary_redirect', 'temporary_moved', 'temporary'),\n-    308: ('permanent_redirect',\n-          'resume_incomplete', 'resume',),  # These 2 to be removed in 3.0\n-\n+    300: (\"multiple_choices\",),\n+    301: (\"moved_permanently\", \"moved\", \"\\\\o-\"),\n+    302: (\"found\",),\n+    303: (\"see_other\", \"other\"),\n+    304: (\"not_modified\",),\n+    305: (\"use_proxy\",),\n+    306: (\"switch_proxy\",),\n+    307: (\"temporary_redirect\", \"temporary_moved\", \"temporary\"),\n+    308: (\n+        \"permanent_redirect\",\n+        \"resume_incomplete\",\n+        \"resume\",\n+    ),  # \"resume\" and \"resume_incomplete\" to be removed in 3.0\n     # Client Error.\n-    400: ('bad_request', 'bad'),\n-    401: ('unauthorized',),\n-    402: ('payment_required', 'payment'),\n-    403: ('forbidden',),\n-    404: ('not_found', '-o-'),\n-    405: ('method_not_allowed', 'not_allowed'),\n-    406: ('not_acceptable',),\n-    407: ('proxy_authentication_required', 'proxy_auth', 'proxy_authentication'),\n-    408: ('request_timeout', 'timeout'),\n-    409: ('conflict',),\n-    410: ('gone',),\n-    411: ('length_required',),\n-    412: ('precondition_failed', 'precondition'),\n-    413: ('request_entity_too_large',),\n-    414: ('request_uri_too_large',),\n-    415: ('unsupported_media_type', 'unsupported_media', 'media_type'),\n-    416: ('requested_range_not_satisfiable', 'requested_range', 'range_not_satisfiable'),\n-    417: ('expectation_failed',),\n-    418: ('im_a_teapot', 'teapot', 'i_am_a_teapot'),\n-    421: ('misdirected_request',),\n-    422: ('unprocessable_entity', 'unprocessable'),\n-    423: ('locked',),\n-    424: ('failed_dependency', 'dependency'),\n-    425: ('unordered_collection', 'unordered'),\n-    426: ('upgrade_required', 'upgrade'),\n-    428: ('precondition_required', 'precondition'),\n-    429: ('too_many_requests', 'too_many'),\n-    431: ('header_fields_too_large', 'fields_too_large'),\n-    444: ('no_response', 'none'),\n-    449: ('retry_with', 'retry'),\n-    450: ('blocked_by_windows_parental_controls', 'parental_controls'),\n-    451: ('unavailable_for_legal_reasons', 'legal_reasons'),\n-    499: ('client_closed_request',),\n-\n+    400: (\"bad_request\", \"bad\"),\n+    401: (\"unauthorized\",),\n+    402: (\"payment_required\", \"payment\"),\n+    403: (\"forbidden\",),\n+    404: (\"not_found\", \"-o-\"),\n+    405: (\"method_not_allowed\", \"not_allowed\"),\n+    406: (\"not_acceptable\",),\n+    407: (\"proxy_authentication_required\", \"proxy_auth\", \"proxy_authentication\"),\n+    408: (\"request_timeout\", \"timeout\"),\n+    409: (\"conflict\",),\n+    410: (\"gone\",),\n+    411: (\"length_required\",),\n+    412: (\"precondition_failed\", \"precondition\"),\n+    413: (\"request_entity_too_large\",),\n+    414: (\"request_uri_too_large\",),\n+    415: (\"unsupported_media_type\", \"unsupported_media\", \"media_type\"),\n+    416: (\n+        \"requested_range_not_satisfiable\",\n+        \"requested_range\",\n+        \"range_not_satisfiable\",\n+    ),\n+    417: (\"expectation_failed\",),\n+    418: (\"im_a_teapot\", \"teapot\", \"i_am_a_teapot\"),\n+    421: (\"misdirected_request\",),\n+    422: (\"unprocessable_entity\", \"unprocessable\"),\n+    423: (\"locked\",),\n+    424: (\"failed_dependency\", \"dependency\"),\n+    425: (\"unordered_collection\", \"unordered\"),\n+    426: (\"upgrade_required\", \"upgrade\"),\n+    428: (\"precondition_required\", \"precondition\"),\n+    429: (\"too_many_requests\", \"too_many\"),\n+    431: (\"header_fields_too_large\", \"fields_too_large\"),\n+    444: (\"no_response\", \"none\"),\n+    449: (\"retry_with\", \"retry\"),\n+    450: (\"blocked_by_windows_parental_controls\", \"parental_controls\"),\n+    451: (\"unavailable_for_legal_reasons\", \"legal_reasons\"),\n+    499: (\"client_closed_request\",),\n     # Server Error.\n-    500: ('internal_server_error', 'server_error', '/o\\\\', '✗'),\n-    501: ('not_implemented',),\n-    502: ('bad_gateway',),\n-    503: ('service_unavailable', 'unavailable'),\n-    504: ('gateway_timeout',),\n-    505: ('http_version_not_supported', 'http_version'),\n-    506: ('variant_also_negotiates',),\n-    507: ('insufficient_storage',),\n-    509: ('bandwidth_limit_exceeded', 'bandwidth'),\n-    510: ('not_extended',),\n-    511: ('network_authentication_required', 'network_auth', 'network_authentication'),\n+    500: (\"internal_server_error\", \"server_error\", \"/o\\\\\", \"✗\"),\n+    501: (\"not_implemented\",),\n+    502: (\"bad_gateway\",),\n+    503: (\"service_unavailable\", \"unavailable\"),\n+    504: (\"gateway_timeout\",),\n+    505: (\"http_version_not_supported\", \"http_version\"),\n+    506: (\"variant_also_negotiates\",),\n+    507: (\"insufficient_storage\",),\n+    509: (\"bandwidth_limit_exceeded\", \"bandwidth\"),\n+    510: (\"not_extended\",),\n+    511: (\"network_authentication_required\", \"network_auth\", \"network_authentication\"),\n }\n \n-codes = LookupDict(name='status_codes')\n+codes = LookupDict(name=\"status_codes\")\n+\n \n def _init():\n     for code, titles in _codes.items():\n         for title in titles:\n             setattr(codes, title, code)\n-            if not title.startswith(('\\\\', '/')):\n+            if not title.startswith((\"\\\\\", \"/\")):\n                 setattr(codes, title.upper(), code)\n \n     def doc(code):\n-        names = ', '.join('``%s``' % n for n in _codes[code])\n-        return '* %d: %s' % (code, names)\n+        names = \", \".join(f\"``{n}``\" for n in _codes[code])\n+        return \"* %d: %s\" % (code, names)\n \n     global __doc__\n-    __doc__ = (__doc__ + '\\n' +\n-               '\\n'.join(doc(code) for code in sorted(_codes))\n-               if __doc__ is not None else None)\n+    __doc__ = (\n+        __doc__ + \"\\n\" + \"\\n\".join(doc(code) for code in sorted(_codes))\n+        if __doc__ is not None\n+        else None\n+    )\n+\n \n _init()\n\n@@ -1,5 +1,3 @@\n-# -*- coding: utf-8 -*-\n-\n \"\"\"\n requests.structures\n ~~~~~~~~~~~~~~~~~~~\n@@ -64,11 +62,7 @@ class CaseInsensitiveDict(MutableMapping):\n \n     def lower_items(self):\n         \"\"\"Like iteritems(), but with all lowercase keys.\"\"\"\n-        return (\n-            (lowerkey, keyval[1])\n-            for (lowerkey, keyval)\n-            in self._store.items()\n-        )\n+        return ((lowerkey, keyval[1]) for (lowerkey, keyval) in self._store.items())\n \n     def __eq__(self, other):\n         if isinstance(other, Mapping):\n@@ -91,10 +85,10 @@ class LookupDict(dict):\n \n     def __init__(self, name=None):\n         self.name = name\n-        super(LookupDict, self).__init__()\n+        super().__init__()\n \n     def __repr__(self):\n-        return '<lookup \\'%s\\'>' % (self.name)\n+        return f\"<lookup '{self.name}'>\"\n \n     def __getitem__(self, key):\n         # We allow fall-through here, so values default to None\n\n@@ -1,5 +1,3 @@\n-# -*- coding: utf-8 -*-\n-\n \"\"\"\n requests.utils\n ~~~~~~~~~~~~~~\n@@ -20,28 +18,46 @@ import tempfile\n import warnings\n import zipfile\n from collections import OrderedDict\n-from urllib3.util import make_headers\n-from urllib3.util import parse_url\n \n-from .__version__ import __version__\n+from urllib3.util import make_headers, parse_url\n+\n from . import certs\n+from .__version__ import __version__\n+\n # to_native_string is unused here, but imported here for backwards compatibility\n-from ._internal_utils import to_native_string\n+from ._internal_utils import to_native_string  # noqa: F401\n+from .compat import (\n+    Mapping,\n+    basestring,\n+    bytes,\n+    getproxies,\n+    getproxies_environment,\n+    integer_types,\n+)\n from .compat import parse_http_list as _parse_list_header\n from .compat import (\n-    quote, urlparse, bytes, str, unquote, getproxies,\n-    proxy_bypass, urlunparse, basestring, integer_types,\n-    proxy_bypass_environment, getproxies_environment, Mapping)\n+    proxy_bypass,\n+    proxy_bypass_environment,\n+    quote,\n+    str,\n+    unquote,\n+    urlparse,\n+    urlunparse,\n+)\n from .cookies import cookiejar_from_dict\n-from .structures import CaseInsensitiveDict\n from .exceptions import (\n-    InvalidURL, InvalidHeader, FileModeWarning, UnrewindableBodyError)\n+    FileModeWarning,\n+    InvalidHeader,\n+    InvalidURL,\n+    UnrewindableBodyError,\n+)\n+from .structures import CaseInsensitiveDict\n \n-NETRC_FILES = ('.netrc', '_netrc')\n+NETRC_FILES = (\".netrc\", \"_netrc\")\n \n DEFAULT_CA_BUNDLE_PATH = certs.where()\n \n-DEFAULT_PORTS = {'http': 80, 'https': 443}\n+DEFAULT_PORTS = {\"http\": 80, \"https\": 443}\n \n # Ensure that ', ' is used to preserve previous delimiter behavior.\n DEFAULT_ACCEPT_ENCODING = \", \".join(\n@@ -49,7 +65,7 @@ DEFAULT_ACCEPT_ENCODING = \", \".join(\n )\n \n \n-if sys.platform == 'win32':\n+if sys.platform == \"win32\":\n     # provide a proxy_bypass version on Windows without DNS lookups\n \n     def proxy_bypass_registry(host):\n@@ -59,14 +75,14 @@ if sys.platform == 'win32':\n             return False\n \n         try:\n-            internetSettings = winreg.OpenKey(winreg.HKEY_CURRENT_USER,\n-                r'Software\\Microsoft\\Windows\\CurrentVersion\\Internet Settings')\n+            internetSettings = winreg.OpenKey(\n+                winreg.HKEY_CURRENT_USER,\n+                r\"Software\\Microsoft\\Windows\\CurrentVersion\\Internet Settings\",\n+            )\n             # ProxyEnable could be REG_SZ or REG_DWORD, normalizing it\n-            proxyEnable = int(winreg.QueryValueEx(internetSettings,\n-                                              'ProxyEnable')[0])\n+            proxyEnable = int(winreg.QueryValueEx(internetSettings, \"ProxyEnable\")[0])\n             # ProxyOverride is almost always a string\n-            proxyOverride = winreg.QueryValueEx(internetSettings,\n-                                                'ProxyOverride')[0]\n+            proxyOverride = winreg.QueryValueEx(internetSettings, \"ProxyOverride\")[0]\n         except OSError:\n             return False\n         if not proxyEnable or not proxyOverride:\n@@ -75,11 +91,11 @@ if sys.platform == 'win32':\n         # make a check value list from the registry entry: replace the\n         # '<local>' string by the localhost entry and the corresponding\n         # canonical entry.\n-        proxyOverride = proxyOverride.split(';')\n+        proxyOverride = proxyOverride.split(\";\")\n         # now check if we match one of the registry values.\n         for test in proxyOverride:\n-            if test == '<local>':\n-                if '.' not in host:\n+            if test == \"<local>\":\n+                if \".\" not in host:\n                     return True\n             test = test.replace(\".\", r\"\\.\")  # mask dots\n             test = test.replace(\"*\", r\".*\")  # change glob sequence\n@@ -103,7 +119,7 @@ if sys.platform == 'win32':\n def dict_to_sequence(d):\n     \"\"\"Returns an internal sequence dictionary update.\"\"\"\n \n-    if hasattr(d, 'items'):\n+    if hasattr(d, \"items\"):\n         d = d.items()\n \n     return d\n@@ -113,13 +129,13 @@ def super_len(o):\n     total_length = None\n     current_position = 0\n \n-    if hasattr(o, '__len__'):\n+    if hasattr(o, \"__len__\"):\n         total_length = len(o)\n \n-    elif hasattr(o, 'len'):\n+    elif hasattr(o, \"len\"):\n         total_length = o.len\n \n-    elif hasattr(o, 'fileno'):\n+    elif hasattr(o, \"fileno\"):\n         try:\n             fileno = o.fileno()\n         except (io.UnsupportedOperation, AttributeError):\n@@ -132,21 +148,23 @@ def super_len(o):\n \n             # Having used fstat to determine the file length, we need to\n             # confirm that this file was opened up in binary mode.\n-            if 'b' not in o.mode:\n-                warnings.warn((\n+            if \"b\" not in o.mode:\n+                warnings.warn(\n+                    (\n                         \"Requests has determined the content-length for this \"\n                         \"request using the binary size of the file: however, the \"\n                         \"file has been opened in text mode (i.e. without the 'b' \"\n                         \"flag in the mode). This may lead to an incorrect \"\n                         \"content-length. In Requests 3.0, support will be removed \"\n-                    \"for files in text mode.\"),\n-                    FileModeWarning\n+                        \"for files in text mode.\"\n+                    ),\n+                    FileModeWarning,\n                 )\n \n-    if hasattr(o, 'tell'):\n+    if hasattr(o, \"tell\"):\n         try:\n             current_position = o.tell()\n-        except (OSError, IOError):\n+        except OSError:\n             # This can happen in some weird situations, such as when the file\n             # is actually a special file descriptor like stdin. In this\n             # instance, we don't know what the length is, so set it to zero and\n@@ -154,7 +172,7 @@ def super_len(o):\n             if total_length is not None:\n                 current_position = total_length\n         else:\n-            if hasattr(o, 'seek') and total_length is None:\n+            if hasattr(o, \"seek\") and total_length is None:\n                 # StringIO and BytesIO have seek but no usable fileno\n                 try:\n                     # seek to end of file\n@@ -164,7 +182,7 @@ def super_len(o):\n                     # seek back to current position to support\n                     # partially read file-like objects\n                     o.seek(current_position or 0)\n-                except (OSError, IOError):\n+                except OSError:\n                     total_length = 0\n \n     if total_length is None:\n@@ -176,14 +194,14 @@ def super_len(o):\n def get_netrc_auth(url, raise_errors=False):\n     \"\"\"Returns the Requests tuple auth for a given url from netrc.\"\"\"\n \n-    netrc_file = os.environ.get('NETRC')\n+    netrc_file = os.environ.get(\"NETRC\")\n     if netrc_file is not None:\n         netrc_locations = (netrc_file,)\n     else:\n-        netrc_locations = ('~/{}'.format(f) for f in NETRC_FILES)\n+        netrc_locations = (f\"~/{f}\" for f in NETRC_FILES)\n \n     try:\n-        from netrc import netrc, NetrcParseError\n+        from netrc import NetrcParseError, netrc\n \n         netrc_path = None\n \n@@ -208,18 +226,18 @@ def get_netrc_auth(url, raise_errors=False):\n \n         # Strip port numbers from netloc. This weird `if...encode`` dance is\n         # used for Python 3.2, which doesn't support unicode literals.\n-        splitstr = b':'\n+        splitstr = b\":\"\n         if isinstance(url, str):\n-            splitstr = splitstr.decode('ascii')\n+            splitstr = splitstr.decode(\"ascii\")\n         host = ri.netloc.split(splitstr)[0]\n \n         try:\n             _netrc = netrc(netrc_path).authenticators(host)\n             if _netrc:\n                 # Return with login / password\n-                login_i = (0 if _netrc[0] else 1)\n+                login_i = 0 if _netrc[0] else 1\n                 return (_netrc[login_i], _netrc[2])\n-        except (NetrcParseError, IOError):\n+        except (NetrcParseError, OSError):\n             # If there was a parsing error or a permissions issue reading the file,\n             # we'll just skip netrc auth unless explicitly asked to raise errors.\n             if raise_errors:\n@@ -232,9 +250,8 @@ def get_netrc_auth(url, raise_errors=False):\n \n def guess_filename(obj):\n     \"\"\"Tries to guess the filename of the given object.\"\"\"\n-    name = getattr(obj, 'name', None)\n-    if (name and isinstance(name, basestring) and name[0] != '<' and\n-            name[-1] != '>'):\n+    name = getattr(obj, \"name\", None)\n+    if name and isinstance(name, basestring) and name[0] != \"<\" and name[-1] != \">\":\n         return os.path.basename(name)\n \n \n@@ -256,7 +273,7 @@ def extract_zipped_paths(path):\n             # If we don't check for an empty prefix after the split (in other words, archive remains unchanged after the split),\n             # we _can_ end up in an infinite loop on a rare corner case affecting a small number of users\n             break\n-        member = '/'.join([prefix, member])\n+        member = \"/\".join([prefix, member])\n \n     if not zipfile.is_zipfile(archive):\n         return path\n@@ -267,7 +284,7 @@ def extract_zipped_paths(path):\n \n     # we have a valid zip archive and a valid member of that archive\n     tmp = tempfile.gettempdir()\n-    extracted_path = os.path.join(tmp, member.split('/')[-1])\n+    extracted_path = os.path.join(tmp, member.split(\"/\")[-1])\n     if not os.path.exists(extracted_path):\n         # use read + write to avoid the creating nested folders, we only want the file, avoids mkdir racing condition\n         with atomic_open(extracted_path) as file_handler:\n@@ -280,7 +297,7 @@ def atomic_open(filename):\n     \"\"\"Write a file to the disk in an atomic fashion\"\"\"\n     tmp_descriptor, tmp_name = tempfile.mkstemp(dir=os.path.dirname(filename))\n     try:\n-        with os.fdopen(tmp_descriptor, 'wb') as tmp_handler:\n+        with os.fdopen(tmp_descriptor, \"wb\") as tmp_handler:\n             yield tmp_handler\n         os.replace(tmp_name, filename)\n     except BaseException:\n@@ -310,7 +327,7 @@ def from_key_val_list(value):\n         return None\n \n     if isinstance(value, (str, bytes, bool, int)):\n-        raise ValueError('cannot encode objects that are not 2-tuples')\n+        raise ValueError(\"cannot encode objects that are not 2-tuples\")\n \n     return OrderedDict(value)\n \n@@ -336,7 +353,7 @@ def to_key_val_list(value):\n         return None\n \n     if isinstance(value, (str, bytes, bool, int)):\n-        raise ValueError('cannot encode objects that are not 2-tuples')\n+        raise ValueError(\"cannot encode objects that are not 2-tuples\")\n \n     if isinstance(value, Mapping):\n         value = value.items()\n@@ -401,10 +418,10 @@ def parse_dict_header(value):\n     \"\"\"\n     result = {}\n     for item in _parse_list_header(value):\n-        if '=' not in item:\n+        if \"=\" not in item:\n             result[item] = None\n             continue\n-        name, value = item.split('=', 1)\n+        name, value = item.split(\"=\", 1)\n         if value[:1] == value[-1:] == '\"':\n             value = unquote_header_value(value[1:-1])\n         result[name] = value\n@@ -432,8 +449,8 @@ def unquote_header_value(value, is_filename=False):\n         # replace sequence below on a UNC path has the effect of turning\n         # the leading double slash into a single slash and then\n         # _fix_ie_filename() doesn't work correctly.  See #458.\n-        if not is_filename or value[:2] != '\\\\\\\\':\n-            return value.replace('\\\\\\\\', '\\\\').replace('\\\\\"', '\"')\n+        if not is_filename or value[:2] != \"\\\\\\\\\":\n+            return value.replace(\"\\\\\\\\\", \"\\\\\").replace('\\\\\"', '\"')\n     return value\n \n \n@@ -468,19 +485,24 @@ def get_encodings_from_content(content):\n \n     :param content: bytestring to extract encodings from.\n     \"\"\"\n-    warnings.warn((\n-        'In requests 3.0, get_encodings_from_content will be removed. For '\n-        'more information, please see the discussion on issue #2266. (This'\n-        ' warning should only appear once.)'),\n-        DeprecationWarning)\n+    warnings.warn(\n+        (\n+            \"In requests 3.0, get_encodings_from_content will be removed. For \"\n+            \"more information, please see the discussion on issue #2266. (This\"\n+            \" warning should only appear once.)\"\n+        ),\n+        DeprecationWarning,\n+    )\n \n     charset_re = re.compile(r'<meta.*?charset=[\"\\']*(.+?)[\"\\'>]', flags=re.I)\n     pragma_re = re.compile(r'<meta.*?content=[\"\\']*;?charset=(.+?)[\"\\'>]', flags=re.I)\n     xml_re = re.compile(r'^<\\?xml.*?encoding=[\"\\']*(.+?)[\"\\'>]')\n \n-    return (charset_re.findall(content) +\n-            pragma_re.findall(content) +\n-            xml_re.findall(content))\n+    return (\n+        charset_re.findall(content)\n+        + pragma_re.findall(content)\n+        + xml_re.findall(content)\n+    )\n \n \n def _parse_content_type_header(header):\n@@ -491,7 +513,7 @@ def _parse_content_type_header(header):\n          parameters\n     \"\"\"\n \n-    tokens = header.split(';')\n+    tokens = header.split(\";\")\n     content_type, params = tokens[0].strip(), tokens[1:]\n     params_dict = {}\n     items_to_strip = \"\\\"' \"\n@@ -515,38 +537,37 @@ def get_encoding_from_headers(headers):\n     :rtype: str\n     \"\"\"\n \n-    content_type = headers.get('content-type')\n+    content_type = headers.get(\"content-type\")\n \n     if not content_type:\n         return None\n \n     content_type, params = _parse_content_type_header(content_type)\n \n-    if 'charset' in params:\n-        return params['charset'].strip(\"'\\\"\")\n+    if \"charset\" in params:\n+        return params[\"charset\"].strip(\"'\\\"\")\n \n-    if 'text' in content_type:\n-        return 'ISO-8859-1'\n+    if \"text\" in content_type:\n+        return \"ISO-8859-1\"\n \n-    if 'application/json' in content_type:\n+    if \"application/json\" in content_type:\n         # Assume UTF-8 based on RFC 4627: https://www.ietf.org/rfc/rfc4627.txt since the charset was unset\n-        return 'utf-8'\n+        return \"utf-8\"\n \n \n def stream_decode_response_unicode(iterator, r):\n     \"\"\"Stream decodes a iterator.\"\"\"\n \n     if r.encoding is None:\n-        for item in iterator:\n-            yield item\n+        yield from iterator\n         return\n \n-    decoder = codecs.getincrementaldecoder(r.encoding)(errors='replace')\n+    decoder = codecs.getincrementaldecoder(r.encoding)(errors=\"replace\")\n     for chunk in iterator:\n         rv = decoder.decode(chunk)\n         if rv:\n             yield rv\n-    rv = decoder.decode(b'', final=True)\n+    rv = decoder.decode(b\"\", final=True)\n     if rv:\n         yield rv\n \n@@ -573,11 +594,14 @@ def get_unicode_from_response(r):\n \n     :rtype: str\n     \"\"\"\n-    warnings.warn((\n-        'In requests 3.0, get_unicode_from_response will be removed. For '\n-        'more information, please see the discussion on issue #2266. (This'\n-        ' warning should only appear once.)'),\n-        DeprecationWarning)\n+    warnings.warn(\n+        (\n+            \"In requests 3.0, get_unicode_from_response will be removed. For \"\n+            \"more information, please see the discussion on issue #2266. (This\"\n+            \" warning should only appear once.)\"\n+        ),\n+        DeprecationWarning,\n+    )\n \n     tried_encodings = []\n \n@@ -592,14 +616,15 @@ def get_unicode_from_response(r):\n \n     # Fall back:\n     try:\n-        return str(r.content, encoding, errors='replace')\n+        return str(r.content, encoding, errors=\"replace\")\n     except TypeError:\n         return r.content\n \n \n # The unreserved URI characters (RFC 3986)\n UNRESERVED_SET = frozenset(\n-    \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\" + \"0123456789-._~\")\n+    \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\" + \"0123456789-._~\"\n+)\n \n \n def unquote_unreserved(uri):\n@@ -608,22 +633,22 @@ def unquote_unreserved(uri):\n \n     :rtype: str\n     \"\"\"\n-    parts = uri.split('%')\n+    parts = uri.split(\"%\")\n     for i in range(1, len(parts)):\n         h = parts[i][0:2]\n         if len(h) == 2 and h.isalnum():\n             try:\n                 c = chr(int(h, 16))\n             except ValueError:\n-                raise InvalidURL(\"Invalid percent-escape sequence: '%s'\" % h)\n+                raise InvalidURL(f\"Invalid percent-escape sequence: '{h}'\")\n \n             if c in UNRESERVED_SET:\n                 parts[i] = c + parts[i][2:]\n             else:\n-                parts[i] = '%' + parts[i]\n+                parts[i] = f\"%{parts[i]}\"\n         else:\n-            parts[i] = '%' + parts[i]\n-    return ''.join(parts)\n+            parts[i] = f\"%{parts[i]}\"\n+    return \"\".join(parts)\n \n \n def requote_uri(uri):\n@@ -656,10 +681,10 @@ def address_in_network(ip, net):\n \n     :rtype: bool\n     \"\"\"\n-    ipaddr = struct.unpack('=L', socket.inet_aton(ip))[0]\n-    netaddr, bits = net.split('/')\n-    netmask = struct.unpack('=L', socket.inet_aton(dotted_netmask(int(bits))))[0]\n-    network = struct.unpack('=L', socket.inet_aton(netaddr))[0] & netmask\n+    ipaddr = struct.unpack(\"=L\", socket.inet_aton(ip))[0]\n+    netaddr, bits = net.split(\"/\")\n+    netmask = struct.unpack(\"=L\", socket.inet_aton(dotted_netmask(int(bits))))[0]\n+    network = struct.unpack(\"=L\", socket.inet_aton(netaddr))[0] & netmask\n     return (ipaddr & netmask) == (network & netmask)\n \n \n@@ -670,8 +695,8 @@ def dotted_netmask(mask):\n \n     :rtype: str\n     \"\"\"\n-    bits = 0xffffffff ^ (1 << 32 - mask) - 1\n-    return socket.inet_ntoa(struct.pack('>I', bits))\n+    bits = 0xFFFFFFFF ^ (1 << 32 - mask) - 1\n+    return socket.inet_ntoa(struct.pack(\">I\", bits))\n \n \n def is_ipv4_address(string_ip):\n@@ -680,7 +705,7 @@ def is_ipv4_address(string_ip):\n     \"\"\"\n     try:\n         socket.inet_aton(string_ip)\n-    except socket.error:\n+    except OSError:\n         return False\n     return True\n \n@@ -691,9 +716,9 @@ def is_valid_cidr(string_network):\n \n     :rtype: bool\n     \"\"\"\n-    if string_network.count('/') == 1:\n+    if string_network.count(\"/\") == 1:\n         try:\n-            mask = int(string_network.split('/')[1])\n+            mask = int(string_network.split(\"/\")[1])\n         except ValueError:\n             return False\n \n@@ -701,8 +726,8 @@ def is_valid_cidr(string_network):\n             return False\n \n         try:\n-            socket.inet_aton(string_network.split('/')[0])\n-        except socket.error:\n+            socket.inet_aton(string_network.split(\"/\")[0])\n+        except OSError:\n             return False\n     else:\n         return False\n@@ -739,13 +764,14 @@ def should_bypass_proxies(url, no_proxy):\n     \"\"\"\n     # Prioritize lowercase environment variables over uppercase\n     # to keep a consistent behaviour with other http projects (curl, wget).\n-    get_proxy = lambda k: os.environ.get(k) or os.environ.get(k.upper())\n+    def get_proxy(key):\n+        return os.environ.get(key) or os.environ.get(key.upper())\n \n     # First check whether no_proxy is defined. If it is, check that the URL\n     # we're getting isn't in the no_proxy list.\n     no_proxy_arg = no_proxy\n     if no_proxy is None:\n-        no_proxy = get_proxy('no_proxy')\n+        no_proxy = get_proxy(\"no_proxy\")\n     parsed = urlparse(url)\n \n     if parsed.hostname is None:\n@@ -755,9 +781,7 @@ def should_bypass_proxies(url, no_proxy):\n     if no_proxy:\n         # We need to check whether we match here. We need to see if we match\n         # the end of the hostname, both with and without the port.\n-        no_proxy = (\n-            host for host in no_proxy.replace(' ', '').split(',') if host\n-        )\n+        no_proxy = (host for host in no_proxy.replace(\" \", \"\").split(\",\") if host)\n \n         if is_ipv4_address(parsed.hostname):\n             for proxy_ip in no_proxy:\n@@ -771,7 +795,7 @@ def should_bypass_proxies(url, no_proxy):\n         else:\n             host_with_port = parsed.hostname\n             if parsed.port:\n-                host_with_port += ':{}'.format(parsed.port)\n+                host_with_port += f\":{parsed.port}\"\n \n             for host in no_proxy:\n                 if parsed.hostname.endswith(host) or host_with_port.endswith(host):\n@@ -779,7 +803,7 @@ def should_bypass_proxies(url, no_proxy):\n                     # to apply the proxies on this URL.\n                     return True\n \n-    with set_environ('no_proxy', no_proxy_arg):\n+    with set_environ(\"no_proxy\", no_proxy_arg):\n         # parsed.hostname can be `None` in cases such as a file URI.\n         try:\n             bypass = proxy_bypass(parsed.hostname)\n@@ -813,13 +837,13 @@ def select_proxy(url, proxies):\n     proxies = proxies or {}\n     urlparts = urlparse(url)\n     if urlparts.hostname is None:\n-        return proxies.get(urlparts.scheme, proxies.get('all'))\n+        return proxies.get(urlparts.scheme, proxies.get(\"all\"))\n \n     proxy_keys = [\n-        urlparts.scheme + '://' + urlparts.hostname,\n+        urlparts.scheme + \"://\" + urlparts.hostname,\n         urlparts.scheme,\n-        'all://' + urlparts.hostname,\n-        'all',\n+        \"all://\" + urlparts.hostname,\n+        \"all\",\n     ]\n     proxy = None\n     for proxy_key in proxy_keys:\n@@ -844,13 +868,13 @@ def resolve_proxies(request, proxies, trust_env=True):\n     proxies = proxies if proxies is not None else {}\n     url = request.url\n     scheme = urlparse(url).scheme\n-    no_proxy = proxies.get('no_proxy')\n+    no_proxy = proxies.get(\"no_proxy\")\n     new_proxies = proxies.copy()\n \n     if trust_env and not should_bypass_proxies(url, no_proxy=no_proxy):\n         environ_proxies = get_environ_proxies(url, no_proxy=no_proxy)\n \n-        proxy = environ_proxies.get(scheme, environ_proxies.get('all'))\n+        proxy = environ_proxies.get(scheme, environ_proxies.get(\"all\"))\n \n         if proxy:\n             new_proxies.setdefault(scheme, proxy)\n@@ -863,19 +887,21 @@ def default_user_agent(name=\"python-requests\"):\n \n     :rtype: str\n     \"\"\"\n-    return '%s/%s' % (name, __version__)\n+    return f\"{name}/{__version__}\"\n \n \n def default_headers():\n     \"\"\"\n     :rtype: requests.structures.CaseInsensitiveDict\n     \"\"\"\n-    return CaseInsensitiveDict({\n-        'User-Agent': default_user_agent(),\n-        'Accept-Encoding': DEFAULT_ACCEPT_ENCODING,\n-        'Accept': '*/*',\n-        'Connection': 'keep-alive',\n-    })\n+    return CaseInsensitiveDict(\n+        {\n+            \"User-Agent\": default_user_agent(),\n+            \"Accept-Encoding\": DEFAULT_ACCEPT_ENCODING,\n+            \"Accept\": \"*/*\",\n+            \"Connection\": \"keep-alive\",\n+        }\n+    )\n \n \n def parse_header_links(value):\n@@ -888,23 +914,23 @@ def parse_header_links(value):\n \n     links = []\n \n-    replace_chars = ' \\'\"'\n+    replace_chars = \" '\\\"\"\n \n     value = value.strip(replace_chars)\n     if not value:\n         return links\n \n-    for val in re.split(', *<', value):\n+    for val in re.split(\", *<\", value):\n         try:\n-            url, params = val.split(';', 1)\n+            url, params = val.split(\";\", 1)\n         except ValueError:\n-            url, params = val, ''\n+            url, params = val, \"\"\n \n-        link = {'url': url.strip('<> \\'\"')}\n+        link = {\"url\": url.strip(\"<> '\\\"\")}\n \n-        for param in params.split(';'):\n+        for param in params.split(\";\"):\n             try:\n-                key, value = param.split('=')\n+                key, value = param.split(\"=\")\n             except ValueError:\n                 break\n \n@@ -916,7 +942,7 @@ def parse_header_links(value):\n \n \n # Null bytes; no need to recreate these on each call to guess_json_utf\n-_null = '\\x00'.encode('ascii')  # encoding to ASCII for Python 3\n+_null = \"\\x00\".encode(\"ascii\")  # encoding to ASCII for Python 3\n _null2 = _null * 2\n _null3 = _null * 3\n \n@@ -930,25 +956,25 @@ def guess_json_utf(data):\n     # determine the encoding. Also detect a BOM, if present.\n     sample = data[:4]\n     if sample in (codecs.BOM_UTF32_LE, codecs.BOM_UTF32_BE):\n-        return 'utf-32'     # BOM included\n+        return \"utf-32\"  # BOM included\n     if sample[:3] == codecs.BOM_UTF8:\n-        return 'utf-8-sig'  # BOM included, MS style (discouraged)\n+        return \"utf-8-sig\"  # BOM included, MS style (discouraged)\n     if sample[:2] in (codecs.BOM_UTF16_LE, codecs.BOM_UTF16_BE):\n-        return 'utf-16'     # BOM included\n+        return \"utf-16\"  # BOM included\n     nullcount = sample.count(_null)\n     if nullcount == 0:\n-        return 'utf-8'\n+        return \"utf-8\"\n     if nullcount == 2:\n         if sample[::2] == _null2:  # 1st and 3rd are null\n-            return 'utf-16-be'\n+            return \"utf-16-be\"\n         if sample[1::2] == _null2:  # 2nd and 4th are null\n-            return 'utf-16-le'\n+            return \"utf-16-le\"\n         # Did not detect 2 valid UTF-16 ascii-range characters\n     if nullcount == 3:\n         if sample[:3] == _null3:\n-            return 'utf-32-be'\n+            return \"utf-32-be\"\n         if sample[1:] == _null3:\n-            return 'utf-32-le'\n+            return \"utf-32-le\"\n         # Did not detect a valid UTF-32 ascii-range character\n     return None\n \n@@ -973,13 +999,13 @@ def prepend_scheme_if_needed(url, new_scheme):\n     if auth:\n         # parse_url doesn't provide the netloc with auth\n         # so we'll add it ourselves.\n-        netloc = '@'.join([auth, netloc])\n+        netloc = \"@\".join([auth, netloc])\n     if scheme is None:\n         scheme = new_scheme\n     if path is None:\n-        path = ''\n+        path = \"\"\n \n-    return urlunparse((scheme, netloc, path, '', query, fragment))\n+    return urlunparse((scheme, netloc, path, \"\", query, fragment))\n \n \n def get_auth_from_url(url):\n@@ -993,14 +1019,14 @@ def get_auth_from_url(url):\n     try:\n         auth = (unquote(parsed.username), unquote(parsed.password))\n     except (AttributeError, TypeError):\n-        auth = ('', '')\n+        auth = (\"\", \"\")\n \n     return auth\n \n \n # Moved outside of function to avoid recompile every call\n-_CLEAN_HEADER_REGEX_BYTE = re.compile(b'^\\\\S[^\\\\r\\\\n]*$|^$')\n-_CLEAN_HEADER_REGEX_STR = re.compile(r'^\\S[^\\r\\n]*$|^$')\n+_CLEAN_HEADER_REGEX_BYTE = re.compile(b\"^\\\\S[^\\\\r\\\\n]*$|^$\")\n+_CLEAN_HEADER_REGEX_STR = re.compile(r\"^\\S[^\\r\\n]*$|^$\")\n \n \n def check_header_validity(header):\n@@ -1018,10 +1044,14 @@ def check_header_validity(header):\n         pat = _CLEAN_HEADER_REGEX_STR\n     try:\n         if not pat.match(value):\n-            raise InvalidHeader(\"Invalid return character or leading space in header: %s\" % name)\n+            raise InvalidHeader(\n+                f\"Invalid return character or leading space in header: {name}\"\n+            )\n     except TypeError:\n-        raise InvalidHeader(\"Value for header {%s: %s} must be of type str or \"\n-                            \"bytes, not %s\" % (name, value, type(value)))\n+        raise InvalidHeader(\n+            f\"Value for header {{{name}: {value}}} must be of type \"\n+            f\"str or bytes, not {type(value)}\"\n+        )\n \n \n def urldefragauth(url):\n@@ -1036,21 +1066,24 @@ def urldefragauth(url):\n     if not netloc:\n         netloc, path = path, netloc\n \n-    netloc = netloc.rsplit('@', 1)[-1]\n+    netloc = netloc.rsplit(\"@\", 1)[-1]\n \n-    return urlunparse((scheme, netloc, path, params, query, ''))\n+    return urlunparse((scheme, netloc, path, params, query, \"\"))\n \n \n def rewind_body(prepared_request):\n     \"\"\"Move file pointer back to its recorded starting position\n     so it can be read again on redirect.\n     \"\"\"\n-    body_seek = getattr(prepared_request.body, 'seek', None)\n-    if body_seek is not None and isinstance(prepared_request._body_position, integer_types):\n+    body_seek = getattr(prepared_request.body, \"seek\", None)\n+    if body_seek is not None and isinstance(\n+        prepared_request._body_position, integer_types\n+    ):\n         try:\n             body_seek(prepared_request._body_position)\n-        except (IOError, OSError):\n-            raise UnrewindableBodyError(\"An error occurred when rewinding request \"\n-                                        \"body for redirect.\")\n+        except OSError:\n+            raise UnrewindableBodyError(\n+                \"An error occurred when rewinding request body for redirect.\"\n+            )\n     else:\n         raise UnrewindableBodyError(\"Unable to rewind request body for redirect.\")\n\n@@ -1,13 +1,11 @@\n #!/usr/bin/env python\n import os\n import sys\n-\n from codecs import open\n \n from setuptools import setup\n from setuptools.command.test import test as TestCommand\n \n-\n CURRENT_PYTHON = sys.version_info[:2]\n REQUIRED_PYTHON = (3, 7)\n \n@@ -29,16 +27,18 @@ pin to an older version of Requests (<2.28).\n     )\n     sys.exit(1)\n \n+\n class PyTest(TestCommand):\n-    user_options = [('pytest-args=', 'a', \"Arguments to pass into py.test\")]\n+    user_options = [(\"pytest-args=\", \"a\", \"Arguments to pass into py.test\")]\n \n     def initialize_options(self):\n         TestCommand.initialize_options(self)\n         try:\n             from multiprocessing import cpu_count\n-            self.pytest_args = ['-n', str(cpu_count()), '--boxed']\n+\n+            self.pytest_args = [\"-n\", str(cpu_count()), \"--boxed\"]\n         except (ImportError, NotImplementedError):\n-            self.pytest_args = ['-n', '1', '--boxed']\n+            self.pytest_args = [\"-n\", \"1\", \"--boxed\"]\n \n     def finalize_options(self):\n         TestCommand.finalize_options(self)\n@@ -51,81 +51,82 @@ class PyTest(TestCommand):\n         errno = pytest.main(self.pytest_args)\n         sys.exit(errno)\n \n+\n # 'setup.py publish' shortcut.\n-if sys.argv[-1] == 'publish':\n-    os.system('python setup.py sdist bdist_wheel')\n-    os.system('twine upload dist/*')\n+if sys.argv[-1] == \"publish\":\n+    os.system(\"python setup.py sdist bdist_wheel\")\n+    os.system(\"twine upload dist/*\")\n     sys.exit()\n \n requires = [\n-    'charset_normalizer~=2.0.0',\n-    'idna>=2.5,<4',\n-    'urllib3>=1.21.1,<1.27',\n-    'certifi>=2017.4.17',\n+    \"charset_normalizer~=2.0.0\",\n+    \"idna>=2.5,<4\",\n+    \"urllib3>=1.21.1,<1.27\",\n+    \"certifi>=2017.4.17\",\n ]\n test_requirements = [\n-    'pytest-httpbin==0.0.7',\n-    'pytest-cov',\n-    'pytest-mock',\n-    'pytest-xdist',\n-    'PySocks>=1.5.6, !=1.5.7',\n-    'pytest>=3',\n+    \"pytest-httpbin==0.0.7\",\n+    \"pytest-cov\",\n+    \"pytest-mock\",\n+    \"pytest-xdist\",\n+    \"PySocks>=1.5.6, !=1.5.7\",\n+    \"pytest>=3\",\n ]\n \n about = {}\n here = os.path.abspath(os.path.dirname(__file__))\n-with open(os.path.join(here, 'requests', '__version__.py'), 'r', 'utf-8') as f:\n+with open(os.path.join(here, \"requests\", \"__version__.py\"), \"r\", \"utf-8\") as f:\n     exec(f.read(), about)\n \n-with open('README.md', 'r', 'utf-8') as f:\n+with open(\"README.md\", \"r\", \"utf-8\") as f:\n     readme = f.read()\n \n setup(\n-    name=about['__title__'],\n-    version=about['__version__'],\n-    description=about['__description__'],\n+    name=about[\"__title__\"],\n+    version=about[\"__version__\"],\n+    description=about[\"__description__\"],\n     long_description=readme,\n-    long_description_content_type='text/markdown',\n-    author=about['__author__'],\n-    author_email=about['__author_email__'],\n-    url=about['__url__'],\n-    packages=['requests'],\n-    package_data={'': ['LICENSE', 'NOTICE']},\n-    package_dir={'requests': 'requests'},\n+    long_description_content_type=\"text/markdown\",\n+    author=about[\"__author__\"],\n+    author_email=about[\"__author_email__\"],\n+    url=about[\"__url__\"],\n+    packages=[\"requests\"],\n+    package_data={\"\": [\"LICENSE\", \"NOTICE\"]},\n+    package_dir={\"requests\": \"requests\"},\n     include_package_data=True,\n     python_requires=\">=3.7, <4\",\n     install_requires=requires,\n-    license=about['__license__'],\n+    license=about[\"__license__\"],\n     zip_safe=False,\n     classifiers=[\n-        'Development Status :: 5 - Production/Stable',\n-        'Environment :: Web Environment',\n-        'Intended Audience :: Developers',\n-        'License :: OSI Approved :: Apache Software License',\n-        'Natural Language :: English',\n-        'Operating System :: OS Independent',\n-        'Programming Language :: Python',\n-        'Programming Language :: Python :: 3',\n-        'Programming Language :: Python :: 3.7',\n-        'Programming Language :: Python :: 3.8',\n-        'Programming Language :: Python :: 3.9',\n-        'Programming Language :: Python :: 3.10',\n-        'Programming Language :: Python :: 3.11',\n-        'Programming Language :: Python :: 3 :: Only',\n-        'Programming Language :: Python :: Implementation :: CPython',\n-        'Programming Language :: Python :: Implementation :: PyPy',\n-        'Topic :: Internet :: WWW/HTTP',\n-        'Topic :: Software Development :: Libraries',\n+        \"Development Status :: 5 - Production/Stable\",\n+        \"Environment :: Web Environment\",\n+        \"Intended Audience :: Developers\",\n+        \"License :: OSI Approved :: Apache Software License\",\n+        \"Natural Language :: English\",\n+        \"Operating System :: OS Independent\",\n+        \"Programming Language :: Python\",\n+        \"Programming Language :: Python :: 3\",\n+        \"Programming Language :: Python :: 3.7\",\n+        \"Programming Language :: Python :: 3.8\",\n+        \"Programming Language :: Python :: 3.9\",\n+        \"Programming Language :: Python :: 3.10\",\n+        \"Programming Language :: Python :: 3.11\",\n+        \"Programming Language :: Python :: 3 :: Only\",\n+        \"Programming Language :: Python :: Implementation :: CPython\",\n+        \"Programming Language :: Python :: Implementation :: PyPy\",\n+        \"Topic :: Internet :: WWW/HTTP\",\n+        \"Topic :: Software Development :: Libraries\",\n     ],\n-    cmdclass={'test': PyTest},\n+    cmdclass={\"test\": PyTest},\n     tests_require=test_requirements,\n     extras_require={\n-        'security': [],\n-        'socks': ['PySocks>=1.5.6, !=1.5.7'],\n-        'use_chardet_on_py3': ['chardet>=3.0.2,<5']\n+        \"security\": [],\n+        \"socks\": [\"PySocks>=1.5.6, !=1.5.7\"],\n+        \"use_chardet_on_py3\": [\"chardet>=3.0.2,<5\"],\n     },\n     project_urls={\n-        'Documentation': 'https://requests.readthedocs.io',\n-        'Source': 'https://github.com/psf/requests',\n+        \"Documentation\": \"https://requests.readthedocs.io\",\n+        \"Source\": \"https://github.com/psf/requests\",\n     },\n )\n\n@@ -1,13 +1,10 @@\n-# -*- coding: utf-8 -*-\n-\n \"\"\"Requests test package initialisation.\"\"\"\n \n import warnings\n \n-import urllib3\n from urllib3.exceptions import SNIMissingWarning\n \n # urllib3 sets SNIMissingWarning to only go off once,\n # while this test suite requires it to always fire\n # so that it occurs during test_requests.test_https_warnings\n-warnings.simplefilter('always', SNIMissingWarning)\n+warnings.simplefilter(\"always\", SNIMissingWarning)\n\n@@ -1,4 +1,3 @@\n-# -*- coding: utf-8 -*-\n import warnings\n \n try:\n\n@@ -1,26 +1,23 @@\n-# -*- coding: utf-8 -*-\n-\n try:\n-    from http.server import HTTPServer\n-    from http.server import SimpleHTTPRequestHandler\n+    from http.server import HTTPServer, SimpleHTTPRequestHandler\n except ImportError:\n     from BaseHTTPServer import HTTPServer\n     from SimpleHTTPServer import SimpleHTTPRequestHandler\n \n import ssl\n-import tempfile\n import threading\n \n import pytest\n+\n from requests.compat import urljoin\n \n \n def prepare_url(value):\n     # Issue #1483: Make sure the URL always has a trailing slash\n-    httpbin_url = value.url.rstrip('/') + '/'\n+    httpbin_url = value.url.rstrip(\"/\") + \"/\"\n \n     def inner(*suffix):\n-        return urljoin(httpbin_url, '/'.join(suffix))\n+        return urljoin(httpbin_url, \"/\".join(suffix))\n \n     return inner\n \n@@ -44,7 +41,7 @@ def nosan_server(tmp_path_factory):\n     tmpdir = tmp_path_factory.mktemp(\"certs\")\n     ca = trustme.CA()\n     # only commonName, no subjectAltName\n-    server_cert = ca.issue_cert(common_name=u\"localhost\")\n+    server_cert = ca.issue_cert(common_name=\"localhost\")\n     ca_bundle = str(tmpdir / \"ca.pem\")\n     ca.cert_pem.write_to_path(ca_bundle)\n \n\n@@ -1,18 +1,12 @@\n-# -*- encoding: utf-8\n-\n-import sys\n-\n-import pytest\n-\n from requests.help import info\n \n \n def test_system_ssl():\n     \"\"\"Verify we're actually setting system_ssl when it should be available.\"\"\"\n-    assert info()['system_ssl']['version'] != ''\n+    assert info()[\"system_ssl\"][\"version\"] != \"\"\n \n \n-class VersionedPackage(object):\n+class VersionedPackage:\n     def __init__(self, version):\n         self.__version__ = version\n \n@@ -21,11 +15,11 @@ def test_idna_without_version_attribute(mocker):\n     \"\"\"Older versions of IDNA don't provide a __version__ attribute, verify\n     that if we have such a package, we don't blow up.\n     \"\"\"\n-    mocker.patch('requests.help.idna', new=None)\n-    assert info()['idna'] == {'version': ''}\n+    mocker.patch(\"requests.help.idna\", new=None)\n+    assert info()[\"idna\"] == {\"version\": \"\"}\n \n \n def test_idna_with_version_attribute(mocker):\n     \"\"\"Verify we're actually setting idna version when it should be available.\"\"\"\n-    mocker.patch('requests.help.idna', new=VersionedPackage('2.6'))\n-    assert info()['idna'] == {'version': '2.6'}\n+    mocker.patch(\"requests.help.idna\", new=VersionedPackage(\"2.6\"))\n+    assert info()[\"idna\"] == {\"version\": \"2.6\"}\n\n@@ -1,5 +1,3 @@\n-# -*- coding: utf-8 -*-\n-\n import pytest\n \n from requests import hooks\n@@ -10,14 +8,15 @@ def hook(value):\n \n \n @pytest.mark.parametrize(\n-    'hooks_list, result', (\n-        (hook, 'ata'),\n-        ([hook, lambda x: None, hook], 'ta'),\n-    )\n+    \"hooks_list, result\",\n+    (\n+        (hook, \"ata\"),\n+        ([hook, lambda x: None, hook], \"ta\"),\n+    ),\n )\n def test_hooks(hooks_list, result):\n-    assert hooks.dispatch_hook('response', {'response': hooks_list}, 'Data') == result\n+    assert hooks.dispatch_hook(\"response\", {\"response\": hooks_list}, \"Data\") == result\n \n \n def test_default_hooks():\n-    assert hooks.default_hooks() == {'response': []}\n+    assert hooks.default_hooks() == {\"response\": []}\n\n@@ -1,12 +1,11 @@\n-# -*- coding: utf-8 -*-\n+import threading\n \n import pytest\n-import threading\n-import requests\n-\n from tests.testserver.server import Server, consume_socket_content\n \n+import requests\n from requests.compat import JSONDecodeError\n+\n from .utils import override_environ\n \n \n@@ -15,9 +14,9 @@ def echo_response_handler(sock):\n     request_content = consume_socket_content(sock, timeout=0.5)\n \n     text_200 = (\n-        b'HTTP/1.1 200 OK\\r\\n'\n-        b'Content-Length: %d\\r\\n\\r\\n'\n-        b'%s'\n+        b\"HTTP/1.1 200 OK\\r\\n\"\n+        b\"Content-Length: %d\\r\\n\\r\\n\"\n+        b\"%s\"\n     ) % (len(request_content), request_content)\n     sock.send(text_200)\n \n@@ -26,15 +25,15 @@ def test_chunked_upload():\n     \"\"\"can safely send generators\"\"\"\n     close_server = threading.Event()\n     server = Server.basic_response_server(wait_to_close_event=close_server)\n-    data = iter([b'a', b'b', b'c'])\n+    data = iter([b\"a\", b\"b\", b\"c\"])\n \n     with server as (host, port):\n-        url = 'http://{}:{}/'.format(host, port)\n+        url = f\"http://{host}:{port}/\"\n         r = requests.post(url, data=data, stream=True)\n         close_server.set()  # release server block\n \n     assert r.status_code == 200\n-    assert r.request.headers['Transfer-Encoding'] == 'chunked'\n+    assert r.request.headers[\"Transfer-Encoding\"] == \"chunked\"\n \n \n def test_chunked_encoding_error():\n@@ -44,8 +43,10 @@ def test_chunked_encoding_error():\n         request_content = consume_socket_content(sock, timeout=0.5)\n \n         # The server never ends the request and doesn't provide any valid chunks\n-        sock.send(b\"HTTP/1.1 200 OK\\r\\n\" +\n-                  b\"Transfer-Encoding: chunked\\r\\n\")\n+        sock.send(\n+            b\"HTTP/1.1 200 OK\\r\\n\"\n+            b\"Transfer-Encoding: chunked\\r\\n\"\n+        )\n \n         return request_content\n \n@@ -53,9 +54,9 @@ def test_chunked_encoding_error():\n     server = Server(incomplete_chunked_response_handler)\n \n     with server as (host, port):\n-        url = 'http://{}:{}/'.format(host, port)\n+        url = f\"http://{host}:{port}/\"\n         with pytest.raises(requests.exceptions.ChunkedEncodingError):\n-            r = requests.get(url)\n+            requests.get(url)\n         close_server.set()  # release server block\n \n \n@@ -64,17 +65,17 @@ def test_chunked_upload_uses_only_specified_host_header():\n     close_server = threading.Event()\n     server = Server(echo_response_handler, wait_to_close_event=close_server)\n \n-    data = iter([b'a', b'b', b'c'])\n-    custom_host = 'sample-host'\n+    data = iter([b\"a\", b\"b\", b\"c\"])\n+    custom_host = \"sample-host\"\n \n     with server as (host, port):\n-        url = 'http://{}:{}/'.format(host, port)\n-        r = requests.post(url, data=data, headers={'Host': custom_host}, stream=True)\n+        url = f\"http://{host}:{port}/\"\n+        r = requests.post(url, data=data, headers={\"Host\": custom_host}, stream=True)\n         close_server.set()  # release server block\n \n-    expected_header = b'Host: %s\\r\\n' % custom_host.encode('utf-8')\n+    expected_header = b\"Host: %s\\r\\n\" % custom_host.encode(\"utf-8\")\n     assert expected_header in r.content\n-    assert r.content.count(b'Host: ') == 1\n+    assert r.content.count(b\"Host: \") == 1\n \n \n def test_chunked_upload_doesnt_skip_host_header():\n@@ -82,17 +83,17 @@ def test_chunked_upload_doesnt_skip_host_header():\n     close_server = threading.Event()\n     server = Server(echo_response_handler, wait_to_close_event=close_server)\n \n-    data = iter([b'a', b'b', b'c'])\n+    data = iter([b\"a\", b\"b\", b\"c\"])\n \n     with server as (host, port):\n-        expected_host = '{}:{}'.format(host, port)\n-        url = 'http://{}:{}/'.format(host, port)\n+        expected_host = f\"{host}:{port}\"\n+        url = f\"http://{host}:{port}/\"\n         r = requests.post(url, data=data, stream=True)\n         close_server.set()  # release server block\n \n-    expected_header = b'Host: %s\\r\\n' % expected_host.encode('utf-8')\n+    expected_header = b\"Host: %s\\r\\n\" % expected_host.encode(\"utf-8\")\n     assert expected_header in r.content\n-    assert r.content.count(b'Host: ') == 1\n+    assert r.content.count(b\"Host: \") == 1\n \n \n def test_conflicting_content_lengths():\n@@ -102,12 +103,14 @@ def test_conflicting_content_lengths():\n \n     def multiple_content_length_response_handler(sock):\n         request_content = consume_socket_content(sock, timeout=0.5)\n-\n-        sock.send(b\"HTTP/1.1 200 OK\\r\\n\" +\n-                  b\"Content-Type: text/plain\\r\\n\" +\n-                  b\"Content-Length: 16\\r\\n\" +\n-                  b\"Content-Length: 32\\r\\n\\r\\n\" +\n-                  b\"-- Bad Actor -- Original Content\\r\\n\")\n+        response = (\n+            b\"HTTP/1.1 200 OK\\r\\n\"\n+            b\"Content-Type: text/plain\\r\\n\"\n+            b\"Content-Length: 16\\r\\n\"\n+            b\"Content-Length: 32\\r\\n\\r\\n\"\n+            b\"-- Bad Actor -- Original Content\\r\\n\"\n+        )\n+        sock.send(response)\n \n         return request_content\n \n@@ -115,9 +118,9 @@ def test_conflicting_content_lengths():\n     server = Server(multiple_content_length_response_handler)\n \n     with server as (host, port):\n-        url = 'http://{}:{}/'.format(host, port)\n+        url = f\"http://{host}:{port}/\"\n         with pytest.raises(requests.exceptions.InvalidHeader):\n-            r = requests.get(url)\n+            requests.get(url)\n         close_server.set()\n \n \n@@ -174,7 +177,7 @@ def test_digestauth_401_count_reset_on_redirect():\n     server = Server(digest_response_handler, wait_to_close_event=close_server)\n \n     with server as (host, port):\n-        url = 'http://{}:{}/'.format(host, port)\n+        url = f'http://{host}:{port}/'\n         r = requests.get(url, auth=auth)\n         # Verify server succeeded in authenticating.\n         assert r.status_code == 200\n@@ -224,7 +227,7 @@ def test_digestauth_401_only_sent_once():\n     server = Server(digest_failed_response_handler, wait_to_close_event=close_server)\n \n     with server as (host, port):\n-        url = 'http://{}:{}/'.format(host, port)\n+        url = f'http://{host}:{port}/'\n         r = requests.get(url, auth=auth)\n         # Verify server didn't authenticate us.\n         assert r.status_code == 401\n@@ -261,7 +264,7 @@ def test_digestauth_only_on_4xx():\n     server = Server(digest_response_handler, wait_to_close_event=close_server)\n \n     with server as (host, port):\n-        url = 'http://{}:{}/'.format(host, port)\n+        url = f'http://{host}:{port}/'\n         r = requests.get(url, auth=auth)\n         # Verify server didn't receive auth from us.\n         assert r.status_code == 200\n@@ -278,17 +281,17 @@ _schemes_by_var_prefix = [\n _proxy_combos = []\n for prefix, schemes in _schemes_by_var_prefix:\n     for scheme in schemes:\n-        _proxy_combos.append((\"{}_proxy\".format(prefix), scheme))\n+        _proxy_combos.append((f\"{prefix}_proxy\", scheme))\n \n _proxy_combos += [(var.upper(), scheme) for var, scheme in _proxy_combos]\n \n \n @pytest.mark.parametrize(\"var,scheme\", _proxy_combos)\n def test_use_proxy_from_environment(httpbin, var, scheme):\n-    url = \"{}://httpbin.org\".format(scheme)\n+    url = f\"{scheme}://httpbin.org\"\n     fake_proxy = Server()  # do nothing with the requests; just close the socket\n     with fake_proxy as (host, port):\n-        proxy_url = \"socks5://{}:{}\".format(host, port)\n+        proxy_url = f\"socks5://{host}:{port}\"\n         kwargs = {var: proxy_url}\n         with override_environ(**kwargs):\n             # fake proxy's lack of response will cause a ConnectionError\n@@ -303,18 +306,20 @@ def test_use_proxy_from_environment(httpbin, var, scheme):\n \n \n def test_redirect_rfc1808_to_non_ascii_location():\n-    path = u'š'\n+    path = 'š'\n     expected_path = b'%C5%A1'\n     redirect_request = []  # stores the second request to the server\n \n     def redirect_resp_handler(sock):\n         consume_socket_content(sock, timeout=0.5)\n-        location = u'//{}:{}/{}'.format(host, port, path)\n+        location = f'//{host}:{port}/{path}'\n         sock.send(\n+            (\n                 b'HTTP/1.1 301 Moved Permanently\\r\\n'\n                 b'Content-Length: 0\\r\\n'\n-            b'Location: ' + location.encode('utf8') + b'\\r\\n'\n+                b'Location: %s\\r\\n'\n                 b'\\r\\n'\n+            ) % location.encode('utf8')\n         )\n         redirect_request.append(consume_socket_content(sock, timeout=0.5))\n         sock.send(b'HTTP/1.1 200 OK\\r\\n\\r\\n')\n@@ -323,31 +328,24 @@ def test_redirect_rfc1808_to_non_ascii_location():\n     server = Server(redirect_resp_handler, wait_to_close_event=close_server)\n \n     with server as (host, port):\n-        url = u'http://{}:{}'.format(host, port)\n+        url = f'http://{host}:{port}'\n         r = requests.get(url=url, allow_redirects=True)\n         assert r.status_code == 200\n         assert len(r.history) == 1\n         assert r.history[0].status_code == 301\n         assert redirect_request[0].startswith(b'GET /' + expected_path + b' HTTP/1.1')\n-        assert r.url == u'{}/{}'.format(url, expected_path.decode('ascii'))\n+        assert r.url == '{}/{}'.format(url, expected_path.decode('ascii'))\n \n         close_server.set()\n \n+\n def test_fragment_not_sent_with_request():\n     \"\"\"Verify that the fragment portion of a URI isn't sent to the server.\"\"\"\n-    def response_handler(sock):\n-        req = consume_socket_content(sock, timeout=0.5)\n-        sock.send(\n-            b'HTTP/1.1 200 OK\\r\\n'\n-            b'Content-Length: '+bytes(len(req))+b'\\r\\n'\n-            b'\\r\\n'+req\n-        )\n-\n     close_server = threading.Event()\n-    server = Server(response_handler, wait_to_close_event=close_server)\n+    server = Server(echo_response_handler, wait_to_close_event=close_server)\n \n     with server as (host, port):\n-        url = 'http://{}:{}/path/to/thing/#view=edit&token=hunter2'.format(host, port)\n+        url = f'http://{host}:{port}/path/to/thing/#view=edit&token=hunter2'\n         r = requests.get(url)\n         raw_request = r.content\n \n@@ -362,6 +360,7 @@ def test_fragment_not_sent_with_request():\n \n         close_server.set()\n \n+\n def test_fragment_update_on_redirect():\n     \"\"\"Verify we only append previous fragment if one doesn't exist on new\n     location. If a new fragment is encountered in a Location header, it should\n@@ -390,21 +389,21 @@ def test_fragment_update_on_redirect():\n     server = Server(response_handler, wait_to_close_event=close_server)\n \n     with server as (host, port):\n-        url = 'http://{}:{}/path/to/thing/#view=edit&token=hunter2'.format(host, port)\n+        url = f'http://{host}:{port}/path/to/thing/#view=edit&token=hunter2'\n         r = requests.get(url)\n-        raw_request = r.content\n \n         assert r.status_code == 200\n         assert len(r.history) == 2\n         assert r.history[0].request.url == url\n \n         # Verify we haven't overwritten the location with our previous fragment.\n-        assert r.history[1].request.url == 'http://{}:{}/get#relevant-section'.format(host, port)\n+        assert r.history[1].request.url == f'http://{host}:{port}/get#relevant-section'\n         # Verify previous fragment is used and not the original.\n-        assert r.url == 'http://{}:{}/final-url/#relevant-section'.format(host, port)\n+        assert r.url == f'http://{host}:{port}/final-url/#relevant-section'\n \n         close_server.set()\n \n+\n def test_json_decode_compatibility_for_alt_utf_encodings():\n \n     def response_handler(sock):\n@@ -419,7 +418,7 @@ def test_json_decode_compatibility_for_alt_utf_encodings():\n     server = Server(response_handler, wait_to_close_event=close_server)\n \n     with server as (host, port):\n-        url = 'http://{}:{}/'.format(host, port)\n+        url = f'http://{host}:{port}/'\n         r = requests.get(url)\n     r.encoding = None\n     with pytest.raises(requests.exceptions.JSONDecodeError) as excinfo:\n\n@@ -1,33 +1,37 @@\n-# -*- coding: utf-8 -*-\n-\n \"\"\"Tests for Requests.\"\"\"\n \n+import collections\n+import contextlib\n+import io\n import json\n import os\n import pickle\n-import collections\n-import contextlib\n-import warnings\n import re\n+import warnings\n \n-import io\n-import requests\n import pytest\n import urllib3\n+from urllib3.util import Timeout as Urllib3Timeout\n+\n+import requests\n from requests.adapters import HTTPAdapter\n from requests.auth import HTTPDigestAuth, _basic_auth_str\n from requests.compat import (\n-    Morsel, cookielib, getproxies, urlparse,\n-    builtin_str)\n-from requests.cookies import (\n-    cookiejar_from_dict, morsel_to_cookie)\n+    JSONDecodeError,\n+    Morsel,\n+    MutableMapping,\n+    builtin_str,\n+    cookielib,\n+    getproxies,\n+    urlparse,\n+)\n+from requests.cookies import cookiejar_from_dict, morsel_to_cookie\n from requests.exceptions import (\n     ChunkedEncodingError,\n     ConnectionError,\n     ConnectTimeout,\n     ContentDecodingError,\n     InvalidHeader,\n-    InvalidJSONError,\n     InvalidProxyURL,\n     InvalidSchema,\n     InvalidURL,\n@@ -36,31 +40,27 @@ from requests.exceptions import (\n     ReadTimeout,\n     RequestException,\n     RetryError,\n-    Timeout,\n-    TooManyRedirects,\n-    UnrewindableBodyError,\n )\n from requests.exceptions import SSLError as RequestsSSLError\n-from requests.models import PreparedRequest\n-from requests.structures import CaseInsensitiveDict\n-from requests.sessions import SessionRedirectMixin\n-from requests.models import urlencode\n+from requests.exceptions import Timeout, TooManyRedirects, UnrewindableBodyError\n from requests.hooks import default_hooks\n-from requests.compat import JSONDecodeError, MutableMapping\n+from requests.models import PreparedRequest, urlencode\n+from requests.sessions import SessionRedirectMixin\n+from requests.structures import CaseInsensitiveDict\n \n from .compat import StringIO\n from .utils import override_environ\n-from urllib3.util import Timeout as Urllib3Timeout\n \n # Requests to this URL should always fail with a connection timeout (nothing\n # listening on that port)\n-TARPIT = 'http://10.255.255.1'\n+TARPIT = \"http://10.255.255.1\"\n \n # This is to avoid waiting the timeout of using TARPIT\n-INVALID_PROXY='http://localhost:1'\n+INVALID_PROXY = \"http://localhost:1\"\n \n try:\n     from ssl import SSLContext\n+\n     del SSLContext\n     HAS_MODERN_SSL = True\n except ImportError:\n@@ -75,7 +75,7 @@ except AttributeError:\n \n class TestRequests:\n \n-    digest_auth_algo = ('MD5', 'SHA-256', 'SHA-512')\n+    digest_auth_algo = (\"MD5\", \"SHA-256\", \"SHA-512\")\n \n     def test_entry_points(self):\n \n@@ -88,102 +88,116 @@ class TestRequests:\n         requests.patch\n         requests.post\n         # Not really an entry point, but people rely on it.\n-        from requests.packages.urllib3.poolmanager import PoolManager\n+        from requests.packages.urllib3.poolmanager import PoolManager  # noqa:F401\n \n     @pytest.mark.parametrize(\n-        'exception, url', (\n-            (MissingSchema, 'hiwpefhipowhefopw'),\n-            (InvalidSchema, 'localhost:3128'),\n-            (InvalidSchema, 'localhost.localdomain:3128/'),\n-            (InvalidSchema, '10.122.1.1:3128/'),\n-            (InvalidURL, 'http://'),\n-            (InvalidURL, 'http://*example.com'),\n-            (InvalidURL, 'http://.example.com'),\n-        ))\n+        \"exception, url\",\n+        (\n+            (MissingSchema, \"hiwpefhipowhefopw\"),\n+            (InvalidSchema, \"localhost:3128\"),\n+            (InvalidSchema, \"localhost.localdomain:3128/\"),\n+            (InvalidSchema, \"10.122.1.1:3128/\"),\n+            (InvalidURL, \"http://\"),\n+            (InvalidURL, \"http://*example.com\"),\n+            (InvalidURL, \"http://.example.com\"),\n+        ),\n+    )\n     def test_invalid_url(self, exception, url):\n         with pytest.raises(exception):\n             requests.get(url)\n \n     def test_basic_building(self):\n         req = requests.Request()\n-        req.url = 'http://kennethreitz.org/'\n-        req.data = {'life': '42'}\n+        req.url = \"http://kennethreitz.org/\"\n+        req.data = {\"life\": \"42\"}\n \n         pr = req.prepare()\n         assert pr.url == req.url\n-        assert pr.body == 'life=42'\n+        assert pr.body == \"life=42\"\n \n-    @pytest.mark.parametrize('method', ('GET', 'HEAD'))\n+    @pytest.mark.parametrize(\"method\", (\"GET\", \"HEAD\"))\n     def test_no_content_length(self, httpbin, method):\n         req = requests.Request(method, httpbin(method.lower())).prepare()\n-        assert 'Content-Length' not in req.headers\n+        assert \"Content-Length\" not in req.headers\n \n-    @pytest.mark.parametrize('method', ('POST', 'PUT', 'PATCH', 'OPTIONS'))\n+    @pytest.mark.parametrize(\"method\", (\"POST\", \"PUT\", \"PATCH\", \"OPTIONS\"))\n     def test_no_body_content_length(self, httpbin, method):\n         req = requests.Request(method, httpbin(method.lower())).prepare()\n-        assert req.headers['Content-Length'] == '0'\n+        assert req.headers[\"Content-Length\"] == \"0\"\n \n-    @pytest.mark.parametrize('method', ('POST', 'PUT', 'PATCH', 'OPTIONS'))\n+    @pytest.mark.parametrize(\"method\", (\"POST\", \"PUT\", \"PATCH\", \"OPTIONS\"))\n     def test_empty_content_length(self, httpbin, method):\n-        req = requests.Request(method, httpbin(method.lower()), data='').prepare()\n-        assert req.headers['Content-Length'] == '0'\n+        req = requests.Request(method, httpbin(method.lower()), data=\"\").prepare()\n+        assert req.headers[\"Content-Length\"] == \"0\"\n \n     def test_override_content_length(self, httpbin):\n-        headers = {\n-            'Content-Length': 'not zero'\n-        }\n-        r = requests.Request('POST', httpbin('post'), headers=headers).prepare()\n-        assert 'Content-Length' in r.headers\n-        assert r.headers['Content-Length'] == 'not zero'\n+        headers = {\"Content-Length\": \"not zero\"}\n+        r = requests.Request(\"POST\", httpbin(\"post\"), headers=headers).prepare()\n+        assert \"Content-Length\" in r.headers\n+        assert r.headers[\"Content-Length\"] == \"not zero\"\n \n     def test_path_is_not_double_encoded(self):\n-        request = requests.Request('GET', \"http://0.0.0.0/get/test case\").prepare()\n+        request = requests.Request(\"GET\", \"http://0.0.0.0/get/test case\").prepare()\n \n-        assert request.path_url == '/get/test%20case'\n+        assert request.path_url == \"/get/test%20case\"\n \n     @pytest.mark.parametrize(\n-        'url, expected', (\n-            ('http://example.com/path#fragment', 'http://example.com/path?a=b#fragment'),\n-            ('http://example.com/path?key=value#fragment', 'http://example.com/path?key=value&a=b#fragment')\n-        ))\n+        \"url, expected\",\n+        (\n+            (\n+                \"http://example.com/path#fragment\",\n+                \"http://example.com/path?a=b#fragment\",\n+            ),\n+            (\n+                \"http://example.com/path?key=value#fragment\",\n+                \"http://example.com/path?key=value&a=b#fragment\",\n+            ),\n+        ),\n+    )\n     def test_params_are_added_before_fragment(self, url, expected):\n-        request = requests.Request('GET', url, params={\"a\": \"b\"}).prepare()\n+        request = requests.Request(\"GET\", url, params={\"a\": \"b\"}).prepare()\n         assert request.url == expected\n \n     def test_params_original_order_is_preserved_by_default(self):\n-        param_ordered_dict = collections.OrderedDict((('z', 1), ('a', 1), ('k', 1), ('d', 1)))\n+        param_ordered_dict = collections.OrderedDict(\n+            ((\"z\", 1), (\"a\", 1), (\"k\", 1), (\"d\", 1))\n+        )\n         session = requests.Session()\n-        request = requests.Request('GET', 'http://example.com/', params=param_ordered_dict)\n+        request = requests.Request(\n+            \"GET\", \"http://example.com/\", params=param_ordered_dict\n+        )\n         prep = session.prepare_request(request)\n-        assert prep.url == 'http://example.com/?z=1&a=1&k=1&d=1'\n+        assert prep.url == \"http://example.com/?z=1&a=1&k=1&d=1\"\n \n     def test_params_bytes_are_encoded(self):\n-        request = requests.Request('GET', 'http://example.com',\n-                                   params=b'test=foo').prepare()\n-        assert request.url == 'http://example.com/?test=foo'\n+        request = requests.Request(\n+            \"GET\", \"http://example.com\", params=b\"test=foo\"\n+        ).prepare()\n+        assert request.url == \"http://example.com/?test=foo\"\n \n     def test_binary_put(self):\n-        request = requests.Request('PUT', 'http://example.com',\n-                                   data=u\"ööö\".encode(\"utf-8\")).prepare()\n+        request = requests.Request(\n+            \"PUT\", \"http://example.com\", data=\"ööö\".encode()\n+        ).prepare()\n         assert isinstance(request.body, bytes)\n \n     def test_whitespaces_are_removed_from_url(self):\n         # Test for issue #3696\n-        request = requests.Request('GET', ' http://example.com').prepare()\n-        assert request.url == 'http://example.com/'\n+        request = requests.Request(\"GET\", \" http://example.com\").prepare()\n+        assert request.url == \"http://example.com/\"\n \n-    @pytest.mark.parametrize('scheme', ('http://', 'HTTP://', 'hTTp://', 'HttP://'))\n+    @pytest.mark.parametrize(\"scheme\", (\"http://\", \"HTTP://\", \"hTTp://\", \"HttP://\"))\n     def test_mixed_case_scheme_acceptable(self, httpbin, scheme):\n         s = requests.Session()\n         s.proxies = getproxies()\n-        parts = urlparse(httpbin('get'))\n+        parts = urlparse(httpbin(\"get\"))\n         url = scheme + parts.netloc + parts.path\n-        r = requests.Request('GET', url)\n+        r = requests.Request(\"GET\", url)\n         r = s.send(r.prepare())\n-        assert r.status_code == 200, 'failed for scheme {}'.format(scheme)\n+        assert r.status_code == 200, f\"failed for scheme {scheme}\"\n \n     def test_HTTP_200_OK_GET_ALTERNATIVE(self, httpbin):\n-        r = requests.Request('GET', httpbin('get'))\n+        r = requests.Request(\"GET\", httpbin(\"get\"))\n         s = requests.Session()\n         s.proxies = getproxies()\n \n@@ -192,103 +206,113 @@ class TestRequests:\n         assert r.status_code == 200\n \n     def test_HTTP_302_ALLOW_REDIRECT_GET(self, httpbin):\n-        r = requests.get(httpbin('redirect', '1'))\n+        r = requests.get(httpbin(\"redirect\", \"1\"))\n         assert r.status_code == 200\n         assert r.history[0].status_code == 302\n         assert r.history[0].is_redirect\n \n     def test_HTTP_307_ALLOW_REDIRECT_POST(self, httpbin):\n-        r = requests.post(httpbin('redirect-to'), data='test', params={'url': 'post', 'status_code': 307})\n+        r = requests.post(\n+            httpbin(\"redirect-to\"),\n+            data=\"test\",\n+            params={\"url\": \"post\", \"status_code\": 307},\n+        )\n         assert r.status_code == 200\n         assert r.history[0].status_code == 307\n         assert r.history[0].is_redirect\n-        assert r.json()['data'] == 'test'\n+        assert r.json()[\"data\"] == \"test\"\n \n     def test_HTTP_307_ALLOW_REDIRECT_POST_WITH_SEEKABLE(self, httpbin):\n-        byte_str = b'test'\n-        r = requests.post(httpbin('redirect-to'), data=io.BytesIO(byte_str), params={'url': 'post', 'status_code': 307})\n+        byte_str = b\"test\"\n+        r = requests.post(\n+            httpbin(\"redirect-to\"),\n+            data=io.BytesIO(byte_str),\n+            params={\"url\": \"post\", \"status_code\": 307},\n+        )\n         assert r.status_code == 200\n         assert r.history[0].status_code == 307\n         assert r.history[0].is_redirect\n-        assert r.json()['data'] == byte_str.decode('utf-8')\n+        assert r.json()[\"data\"] == byte_str.decode(\"utf-8\")\n \n     def test_HTTP_302_TOO_MANY_REDIRECTS(self, httpbin):\n         try:\n-            requests.get(httpbin('relative-redirect', '50'))\n+            requests.get(httpbin(\"relative-redirect\", \"50\"))\n         except TooManyRedirects as e:\n-            url = httpbin('relative-redirect', '20')\n+            url = httpbin(\"relative-redirect\", \"20\")\n             assert e.request.url == url\n             assert e.response.url == url\n             assert len(e.response.history) == 30\n         else:\n-            pytest.fail('Expected redirect to raise TooManyRedirects but it did not')\n+            pytest.fail(\"Expected redirect to raise TooManyRedirects but it did not\")\n \n     def test_HTTP_302_TOO_MANY_REDIRECTS_WITH_PARAMS(self, httpbin):\n         s = requests.session()\n         s.max_redirects = 5\n         try:\n-            s.get(httpbin('relative-redirect', '50'))\n+            s.get(httpbin(\"relative-redirect\", \"50\"))\n         except TooManyRedirects as e:\n-            url = httpbin('relative-redirect', '45')\n+            url = httpbin(\"relative-redirect\", \"45\")\n             assert e.request.url == url\n             assert e.response.url == url\n             assert len(e.response.history) == 5\n         else:\n-            pytest.fail('Expected custom max number of redirects to be respected but was not')\n+            pytest.fail(\n+                \"Expected custom max number of redirects to be respected but was not\"\n+            )\n \n     def test_http_301_changes_post_to_get(self, httpbin):\n-        r = requests.post(httpbin('status', '301'))\n+        r = requests.post(httpbin(\"status\", \"301\"))\n         assert r.status_code == 200\n-        assert r.request.method == 'GET'\n+        assert r.request.method == \"GET\"\n         assert r.history[0].status_code == 301\n         assert r.history[0].is_redirect\n \n     def test_http_301_doesnt_change_head_to_get(self, httpbin):\n-        r = requests.head(httpbin('status', '301'), allow_redirects=True)\n+        r = requests.head(httpbin(\"status\", \"301\"), allow_redirects=True)\n         print(r.content)\n         assert r.status_code == 200\n-        assert r.request.method == 'HEAD'\n+        assert r.request.method == \"HEAD\"\n         assert r.history[0].status_code == 301\n         assert r.history[0].is_redirect\n \n     def test_http_302_changes_post_to_get(self, httpbin):\n-        r = requests.post(httpbin('status', '302'))\n+        r = requests.post(httpbin(\"status\", \"302\"))\n         assert r.status_code == 200\n-        assert r.request.method == 'GET'\n+        assert r.request.method == \"GET\"\n         assert r.history[0].status_code == 302\n         assert r.history[0].is_redirect\n \n     def test_http_302_doesnt_change_head_to_get(self, httpbin):\n-        r = requests.head(httpbin('status', '302'), allow_redirects=True)\n+        r = requests.head(httpbin(\"status\", \"302\"), allow_redirects=True)\n         assert r.status_code == 200\n-        assert r.request.method == 'HEAD'\n+        assert r.request.method == \"HEAD\"\n         assert r.history[0].status_code == 302\n         assert r.history[0].is_redirect\n \n     def test_http_303_changes_post_to_get(self, httpbin):\n-        r = requests.post(httpbin('status', '303'))\n+        r = requests.post(httpbin(\"status\", \"303\"))\n         assert r.status_code == 200\n-        assert r.request.method == 'GET'\n+        assert r.request.method == \"GET\"\n         assert r.history[0].status_code == 303\n         assert r.history[0].is_redirect\n \n     def test_http_303_doesnt_change_head_to_get(self, httpbin):\n-        r = requests.head(httpbin('status', '303'), allow_redirects=True)\n+        r = requests.head(httpbin(\"status\", \"303\"), allow_redirects=True)\n         assert r.status_code == 200\n-        assert r.request.method == 'HEAD'\n+        assert r.request.method == \"HEAD\"\n         assert r.history[0].status_code == 303\n         assert r.history[0].is_redirect\n \n     def test_header_and_body_removal_on_redirect(self, httpbin):\n-        purged_headers = ('Content-Length', 'Content-Type')\n+        purged_headers = (\"Content-Length\", \"Content-Type\")\n         ses = requests.Session()\n-        req = requests.Request('POST', httpbin('post'), data={'test': 'data'})\n+        req = requests.Request(\"POST\", httpbin(\"post\"), data={\"test\": \"data\"})\n         prep = ses.prepare_request(req)\n         resp = ses.send(prep)\n \n         # Mimic a redirect response\n         resp.status_code = 302\n-        resp.headers['location'] = 'get'\n+        resp.headers[\"location\"] = \"get\"\n \n         # Run request through resolve_redirects\n         next_resp = next(ses.resolve_redirects(resp, prep))\n@@ -297,21 +321,21 @@ class TestRequests:\n             assert header not in next_resp.request.headers\n \n     def test_transfer_enc_removal_on_redirect(self, httpbin):\n-        purged_headers = ('Transfer-Encoding', 'Content-Type')\n+        purged_headers = (\"Transfer-Encoding\", \"Content-Type\")\n         ses = requests.Session()\n-        req = requests.Request('POST', httpbin('post'), data=(b'x' for x in range(1)))\n+        req = requests.Request(\"POST\", httpbin(\"post\"), data=(b\"x\" for x in range(1)))\n         prep = ses.prepare_request(req)\n-        assert 'Transfer-Encoding' in prep.headers\n+        assert \"Transfer-Encoding\" in prep.headers\n \n         # Create Response to avoid https://github.com/kevin1024/pytest-httpbin/issues/33\n         resp = requests.Response()\n-        resp.raw = io.BytesIO(b'the content')\n+        resp.raw = io.BytesIO(b\"the content\")\n         resp.request = prep\n-        setattr(resp.raw, 'release_conn', lambda *args: args)\n+        setattr(resp.raw, \"release_conn\", lambda *args: args)\n \n         # Mimic a redirect response\n         resp.status_code = 302\n-        resp.headers['location'] = httpbin('get')\n+        resp.headers[\"location\"] = httpbin(\"get\")\n \n         # Run request through resolve_redirect\n         next_resp = next(ses.resolve_redirects(resp, prep))\n@@ -321,94 +345,93 @@ class TestRequests:\n \n     def test_fragment_maintained_on_redirect(self, httpbin):\n         fragment = \"#view=edit&token=hunter2\"\n-        r = requests.get(httpbin('redirect-to?url=get')+fragment)\n+        r = requests.get(httpbin(\"redirect-to?url=get\") + fragment)\n \n         assert len(r.history) > 0\n-        assert r.history[0].request.url == httpbin('redirect-to?url=get')+fragment\n-        assert r.url == httpbin('get')+fragment\n+        assert r.history[0].request.url == httpbin(\"redirect-to?url=get\") + fragment\n+        assert r.url == httpbin(\"get\") + fragment\n \n     def test_HTTP_200_OK_GET_WITH_PARAMS(self, httpbin):\n-        heads = {'User-agent': 'Mozilla/5.0'}\n+        heads = {\"User-agent\": \"Mozilla/5.0\"}\n \n-        r = requests.get(httpbin('user-agent'), headers=heads)\n+        r = requests.get(httpbin(\"user-agent\"), headers=heads)\n \n-        assert heads['User-agent'] in r.text\n+        assert heads[\"User-agent\"] in r.text\n         assert r.status_code == 200\n \n     def test_HTTP_200_OK_GET_WITH_MIXED_PARAMS(self, httpbin):\n-        heads = {'User-agent': 'Mozilla/5.0'}\n+        heads = {\"User-agent\": \"Mozilla/5.0\"}\n \n-        r = requests.get(httpbin('get') + '?test=true', params={'q': 'test'}, headers=heads)\n+        r = requests.get(\n+            httpbin(\"get\") + \"?test=true\", params={\"q\": \"test\"}, headers=heads\n+        )\n         assert r.status_code == 200\n \n     def test_set_cookie_on_301(self, httpbin):\n         s = requests.session()\n-        url = httpbin('cookies/set?foo=bar')\n+        url = httpbin(\"cookies/set?foo=bar\")\n         s.get(url)\n-        assert s.cookies['foo'] == 'bar'\n+        assert s.cookies[\"foo\"] == \"bar\"\n \n     def test_cookie_sent_on_redirect(self, httpbin):\n         s = requests.session()\n-        s.get(httpbin('cookies/set?foo=bar'))\n-        r = s.get(httpbin('redirect/1'))  # redirects to httpbin('get')\n-        assert 'Cookie' in r.json()['headers']\n+        s.get(httpbin(\"cookies/set?foo=bar\"))\n+        r = s.get(httpbin(\"redirect/1\"))  # redirects to httpbin('get')\n+        assert \"Cookie\" in r.json()[\"headers\"]\n \n     def test_cookie_removed_on_expire(self, httpbin):\n         s = requests.session()\n-        s.get(httpbin('cookies/set?foo=bar'))\n-        assert s.cookies['foo'] == 'bar'\n+        s.get(httpbin(\"cookies/set?foo=bar\"))\n+        assert s.cookies[\"foo\"] == \"bar\"\n         s.get(\n-            httpbin('response-headers'),\n-            params={\n-                'Set-Cookie':\n-                    'foo=deleted; expires=Thu, 01-Jan-1970 00:00:01 GMT'\n-            }\n+            httpbin(\"response-headers\"),\n+            params={\"Set-Cookie\": \"foo=deleted; expires=Thu, 01-Jan-1970 00:00:01 GMT\"},\n         )\n-        assert 'foo' not in s.cookies\n+        assert \"foo\" not in s.cookies\n \n     def test_cookie_quote_wrapped(self, httpbin):\n         s = requests.session()\n         s.get(httpbin('cookies/set?foo=\"bar:baz\"'))\n-        assert s.cookies['foo'] == '\"bar:baz\"'\n+        assert s.cookies[\"foo\"] == '\"bar:baz\"'\n \n     def test_cookie_persists_via_api(self, httpbin):\n         s = requests.session()\n-        r = s.get(httpbin('redirect/1'), cookies={'foo': 'bar'})\n-        assert 'foo' in r.request.headers['Cookie']\n-        assert 'foo' in r.history[0].request.headers['Cookie']\n+        r = s.get(httpbin(\"redirect/1\"), cookies={\"foo\": \"bar\"})\n+        assert \"foo\" in r.request.headers[\"Cookie\"]\n+        assert \"foo\" in r.history[0].request.headers[\"Cookie\"]\n \n     def test_request_cookie_overrides_session_cookie(self, httpbin):\n         s = requests.session()\n-        s.cookies['foo'] = 'bar'\n-        r = s.get(httpbin('cookies'), cookies={'foo': 'baz'})\n-        assert r.json()['cookies']['foo'] == 'baz'\n+        s.cookies[\"foo\"] = \"bar\"\n+        r = s.get(httpbin(\"cookies\"), cookies={\"foo\": \"baz\"})\n+        assert r.json()[\"cookies\"][\"foo\"] == \"baz\"\n         # Session cookie should not be modified\n-        assert s.cookies['foo'] == 'bar'\n+        assert s.cookies[\"foo\"] == \"bar\"\n \n     def test_request_cookies_not_persisted(self, httpbin):\n         s = requests.session()\n-        s.get(httpbin('cookies'), cookies={'foo': 'baz'})\n+        s.get(httpbin(\"cookies\"), cookies={\"foo\": \"baz\"})\n         # Sending a request with cookies should not add cookies to the session\n         assert not s.cookies\n \n     def test_generic_cookiejar_works(self, httpbin):\n         cj = cookielib.CookieJar()\n-        cookiejar_from_dict({'foo': 'bar'}, cj)\n+        cookiejar_from_dict({\"foo\": \"bar\"}, cj)\n         s = requests.session()\n         s.cookies = cj\n-        r = s.get(httpbin('cookies'))\n+        r = s.get(httpbin(\"cookies\"))\n         # Make sure the cookie was sent\n-        assert r.json()['cookies']['foo'] == 'bar'\n+        assert r.json()[\"cookies\"][\"foo\"] == \"bar\"\n         # Make sure the session cj is still the custom one\n         assert s.cookies is cj\n \n     def test_param_cookiejar_works(self, httpbin):\n         cj = cookielib.CookieJar()\n-        cookiejar_from_dict({'foo': 'bar'}, cj)\n+        cookiejar_from_dict({\"foo\": \"bar\"}, cj)\n         s = requests.session()\n-        r = s.get(httpbin('cookies'), cookies=cj)\n+        r = s.get(httpbin(\"cookies\"), cookies=cj)\n         # Make sure the cookie was sent\n-        assert r.json()['cookies']['foo'] == 'bar'\n+        assert r.json()[\"cookies\"][\"foo\"] == \"bar\"\n \n     def test_cookielib_cookiejar_on_redirect(self, httpbin):\n         \"\"\"Tests resolve_redirect doesn't fail when merging cookies\n@@ -416,18 +439,18 @@ class TestRequests:\n \n         See GH #3579\n         \"\"\"\n-        cj = cookiejar_from_dict({'foo': 'bar'}, cookielib.CookieJar())\n+        cj = cookiejar_from_dict({\"foo\": \"bar\"}, cookielib.CookieJar())\n         s = requests.Session()\n-        s.cookies = cookiejar_from_dict({'cookie': 'tasty'})\n+        s.cookies = cookiejar_from_dict({\"cookie\": \"tasty\"})\n \n         # Prepare request without using Session\n-        req = requests.Request('GET', httpbin('headers'), cookies=cj)\n+        req = requests.Request(\"GET\", httpbin(\"headers\"), cookies=cj)\n         prep_req = req.prepare()\n \n         # Send request and simulate redirect\n         resp = s.send(prep_req)\n         resp.status_code = 302\n-        resp.headers['location'] = httpbin('get')\n+        resp.headers[\"location\"] = httpbin(\"get\")\n         redirects = s.resolve_redirects(resp, prep_req)\n         resp = next(redirects)\n \n@@ -439,70 +462,70 @@ class TestRequests:\n         cookies = {}\n         for c in resp.request._cookies:\n             cookies[c.name] = c.value\n-        assert cookies['foo'] == 'bar'\n-        assert cookies['cookie'] == 'tasty'\n+        assert cookies[\"foo\"] == \"bar\"\n+        assert cookies[\"cookie\"] == \"tasty\"\n \n     def test_requests_in_history_are_not_overridden(self, httpbin):\n-        resp = requests.get(httpbin('redirect/3'))\n+        resp = requests.get(httpbin(\"redirect/3\"))\n         urls = [r.url for r in resp.history]\n         req_urls = [r.request.url for r in resp.history]\n         assert urls == req_urls\n \n     def test_history_is_always_a_list(self, httpbin):\n         \"\"\"Show that even with redirects, Response.history is always a list.\"\"\"\n-        resp = requests.get(httpbin('get'))\n+        resp = requests.get(httpbin(\"get\"))\n         assert isinstance(resp.history, list)\n-        resp = requests.get(httpbin('redirect/1'))\n+        resp = requests.get(httpbin(\"redirect/1\"))\n         assert isinstance(resp.history, list)\n         assert not isinstance(resp.history, tuple)\n \n     def test_headers_on_session_with_None_are_not_sent(self, httpbin):\n         \"\"\"Do not send headers in Session.headers with None values.\"\"\"\n         ses = requests.Session()\n-        ses.headers['Accept-Encoding'] = None\n-        req = requests.Request('GET', httpbin('get'))\n+        ses.headers[\"Accept-Encoding\"] = None\n+        req = requests.Request(\"GET\", httpbin(\"get\"))\n         prep = ses.prepare_request(req)\n-        assert 'Accept-Encoding' not in prep.headers\n+        assert \"Accept-Encoding\" not in prep.headers\n \n     def test_headers_preserve_order(self, httpbin):\n         \"\"\"Preserve order when headers provided as OrderedDict.\"\"\"\n         ses = requests.Session()\n         ses.headers = collections.OrderedDict()\n-        ses.headers['Accept-Encoding'] = 'identity'\n-        ses.headers['First'] = '1'\n-        ses.headers['Second'] = '2'\n-        headers = collections.OrderedDict([('Third', '3'), ('Fourth', '4')])\n-        headers['Fifth'] = '5'\n-        headers['Second'] = '222'\n-        req = requests.Request('GET', httpbin('get'), headers=headers)\n+        ses.headers[\"Accept-Encoding\"] = \"identity\"\n+        ses.headers[\"First\"] = \"1\"\n+        ses.headers[\"Second\"] = \"2\"\n+        headers = collections.OrderedDict([(\"Third\", \"3\"), (\"Fourth\", \"4\")])\n+        headers[\"Fifth\"] = \"5\"\n+        headers[\"Second\"] = \"222\"\n+        req = requests.Request(\"GET\", httpbin(\"get\"), headers=headers)\n         prep = ses.prepare_request(req)\n         items = list(prep.headers.items())\n-        assert items[0] == ('Accept-Encoding', 'identity')\n-        assert items[1] == ('First', '1')\n-        assert items[2] == ('Second', '222')\n-        assert items[3] == ('Third', '3')\n-        assert items[4] == ('Fourth', '4')\n-        assert items[5] == ('Fifth', '5')\n+        assert items[0] == (\"Accept-Encoding\", \"identity\")\n+        assert items[1] == (\"First\", \"1\")\n+        assert items[2] == (\"Second\", \"222\")\n+        assert items[3] == (\"Third\", \"3\")\n+        assert items[4] == (\"Fourth\", \"4\")\n+        assert items[5] == (\"Fifth\", \"5\")\n \n-    @pytest.mark.parametrize('key', ('User-agent', 'user-agent'))\n+    @pytest.mark.parametrize(\"key\", (\"User-agent\", \"user-agent\"))\n     def test_user_agent_transfers(self, httpbin, key):\n \n-        heads = {key: 'Mozilla/5.0 (github.com/psf/requests)'}\n+        heads = {key: \"Mozilla/5.0 (github.com/psf/requests)\"}\n \n-        r = requests.get(httpbin('user-agent'), headers=heads)\n+        r = requests.get(httpbin(\"user-agent\"), headers=heads)\n         assert heads[key] in r.text\n \n     def test_HTTP_200_OK_HEAD(self, httpbin):\n-        r = requests.head(httpbin('get'))\n+        r = requests.head(httpbin(\"get\"))\n         assert r.status_code == 200\n \n     def test_HTTP_200_OK_PUT(self, httpbin):\n-        r = requests.put(httpbin('put'))\n+        r = requests.put(httpbin(\"put\"))\n         assert r.status_code == 200\n \n     def test_BASICAUTH_TUPLE_HTTP_200_OK_GET(self, httpbin):\n-        auth = ('user', 'pass')\n-        url = httpbin('basic-auth', 'user', 'pass')\n+        auth = (\"user\", \"pass\")\n+        url = httpbin(\"basic-auth\", \"user\", \"pass\")\n \n         r = requests.get(url, auth=auth)\n         assert r.status_code == 200\n@@ -516,40 +539,44 @@ class TestRequests:\n         assert r.status_code == 200\n \n     @pytest.mark.parametrize(\n-        'username, password', (\n-            ('user', 'pass'),\n-            ('имя'.encode('utf-8'), 'пароль'.encode('utf-8')),\n+        \"username, password\",\n+        (\n+            (\"user\", \"pass\"),\n+            (\"имя\".encode(), \"пароль\".encode()),\n             (42, 42),\n             (None, None),\n-        ))\n+        ),\n+    )\n     def test_set_basicauth(self, httpbin, username, password):\n         auth = (username, password)\n-        url = httpbin('get')\n+        url = httpbin(\"get\")\n \n-        r = requests.Request('GET', url, auth=auth)\n+        r = requests.Request(\"GET\", url, auth=auth)\n         p = r.prepare()\n \n-        assert p.headers['Authorization'] == _basic_auth_str(username, password)\n+        assert p.headers[\"Authorization\"] == _basic_auth_str(username, password)\n \n     def test_basicauth_encodes_byte_strings(self):\n         \"\"\"Ensure b'test' formats as the byte string \"test\" rather\n         than the unicode string \"b'test'\" in Python 3.\n         \"\"\"\n-        auth = (b'\\xc5\\xafsername', b'test\\xc6\\xb6')\n-        r = requests.Request('GET', 'http://localhost', auth=auth)\n+        auth = (b\"\\xc5\\xafsername\", b\"test\\xc6\\xb6\")\n+        r = requests.Request(\"GET\", \"http://localhost\", auth=auth)\n         p = r.prepare()\n \n-        assert p.headers['Authorization'] == 'Basic xa9zZXJuYW1lOnRlc3TGtg=='\n+        assert p.headers[\"Authorization\"] == \"Basic xa9zZXJuYW1lOnRlc3TGtg==\"\n \n     @pytest.mark.parametrize(\n-        'url, exception', (\n+        \"url, exception\",\n+        (\n             # Connecting to an unknown domain should raise a ConnectionError\n-            ('http://doesnotexist.google.com', ConnectionError),\n+            (\"http://doesnotexist.google.com\", ConnectionError),\n             # Connecting to an invalid port should raise a ConnectionError\n-            ('http://localhost:1', ConnectionError),\n+            (\"http://localhost:1\", ConnectionError),\n             # Inputing a URL that cannot be parsed should raise an InvalidURL error\n-            ('http://fe80::5054:ff:fe5a:fc0', InvalidURL)\n-        ))\n+            (\"http://fe80::5054:ff:fe5a:fc0\", InvalidURL),\n+        ),\n+    )\n     def test_errors(self, url, exception):\n         with pytest.raises(exception):\n             requests.get(url, timeout=1)\n@@ -557,33 +584,35 @@ class TestRequests:\n     def test_proxy_error(self):\n         # any proxy related error (address resolution, no route to host, etc) should result in a ProxyError\n         with pytest.raises(ProxyError):\n-            requests.get('http://localhost:1', proxies={'http': 'non-resolvable-address'})\n+            requests.get(\n+                \"http://localhost:1\", proxies={\"http\": \"non-resolvable-address\"}\n+            )\n \n     def test_proxy_error_on_bad_url(self, httpbin, httpbin_secure):\n         with pytest.raises(InvalidProxyURL):\n-            requests.get(httpbin_secure(), proxies={'https': 'http:/badproxyurl:3128'})\n+            requests.get(httpbin_secure(), proxies={\"https\": \"http:/badproxyurl:3128\"})\n \n         with pytest.raises(InvalidProxyURL):\n-            requests.get(httpbin(), proxies={'http': 'http://:8080'})\n+            requests.get(httpbin(), proxies={\"http\": \"http://:8080\"})\n \n         with pytest.raises(InvalidProxyURL):\n-            requests.get(httpbin_secure(), proxies={'https': 'https://'})\n+            requests.get(httpbin_secure(), proxies={\"https\": \"https://\"})\n \n         with pytest.raises(InvalidProxyURL):\n-            requests.get(httpbin(), proxies={'http': 'http:///example.com:8080'})\n+            requests.get(httpbin(), proxies={\"http\": \"http:///example.com:8080\"})\n \n     def test_respect_proxy_env_on_send_self_prepared_request(self, httpbin):\n         with override_environ(http_proxy=INVALID_PROXY):\n             with pytest.raises(ProxyError):\n                 session = requests.Session()\n-                request = requests.Request('GET', httpbin())\n+                request = requests.Request(\"GET\", httpbin())\n                 session.send(request.prepare())\n \n     def test_respect_proxy_env_on_send_session_prepared_request(self, httpbin):\n         with override_environ(http_proxy=INVALID_PROXY):\n             with pytest.raises(ProxyError):\n                 session = requests.Session()\n-                request = requests.Request('GET', httpbin())\n+                request = requests.Request(\"GET\", httpbin())\n                 prepared = session.prepare_request(request)\n                 session.send(prepared)\n \n@@ -591,9 +620,9 @@ class TestRequests:\n         with override_environ(http_proxy=INVALID_PROXY):\n             with pytest.raises(ProxyError):\n                 session = requests.Session()\n-                url = httpbin('redirect/1')\n+                url = httpbin(\"redirect/1\")\n                 print(url)\n-                request = requests.Request('GET', url)\n+                request = requests.Request(\"GET\", url)\n                 session.send(request.prepare())\n \n     def test_respect_proxy_env_on_get(self, httpbin):\n@@ -606,27 +635,29 @@ class TestRequests:\n         with override_environ(http_proxy=INVALID_PROXY):\n             with pytest.raises(ProxyError):\n                 session = requests.Session()\n-                session.request(method='GET', url=httpbin())\n+                session.request(method=\"GET\", url=httpbin())\n \n     def test_proxy_authorization_preserved_on_request(self, httpbin):\n         proxy_auth_value = \"Bearer XXX\"\n         session = requests.Session()\n         session.headers.update({\"Proxy-Authorization\": proxy_auth_value})\n-        resp = session.request(method='GET', url=httpbin('get'))\n-        sent_headers = resp.json().get('headers', {})\n+        resp = session.request(method=\"GET\", url=httpbin(\"get\"))\n+        sent_headers = resp.json().get(\"headers\", {})\n \n         assert sent_headers.get(\"Proxy-Authorization\") == proxy_auth_value\n \n     def test_basicauth_with_netrc(self, httpbin):\n-        auth = ('user', 'pass')\n-        wrong_auth = ('wronguser', 'wrongpass')\n-        url = httpbin('basic-auth', 'user', 'pass')\n+        auth = (\"user\", \"pass\")\n+        wrong_auth = (\"wronguser\", \"wrongpass\")\n+        url = httpbin(\"basic-auth\", \"user\", \"pass\")\n \n         old_auth = requests.sessions.get_netrc_auth\n \n         try:\n+\n             def get_netrc_auth_mock(url):\n                 return auth\n+\n             requests.sessions.get_netrc_auth = get_netrc_auth_mock\n \n             # Should use netrc and work.\n@@ -653,28 +684,28 @@ class TestRequests:\n     def test_DIGEST_HTTP_200_OK_GET(self, httpbin):\n \n         for authtype in self.digest_auth_algo:\n-            auth = HTTPDigestAuth('user', 'pass')\n-            url = httpbin('digest-auth', 'auth', 'user', 'pass', authtype, 'never')\n+            auth = HTTPDigestAuth(\"user\", \"pass\")\n+            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype, \"never\")\n \n             r = requests.get(url, auth=auth)\n             assert r.status_code == 200\n \n             r = requests.get(url)\n             assert r.status_code == 401\n-            print(r.headers['WWW-Authenticate'])\n+            print(r.headers[\"WWW-Authenticate\"])\n \n             s = requests.session()\n-            s.auth = HTTPDigestAuth('user', 'pass')\n+            s.auth = HTTPDigestAuth(\"user\", \"pass\")\n             r = s.get(url)\n             assert r.status_code == 200\n \n     def test_DIGEST_AUTH_RETURNS_COOKIE(self, httpbin):\n \n         for authtype in self.digest_auth_algo:\n-            url = httpbin('digest-auth', 'auth', 'user', 'pass', authtype)\n-            auth = HTTPDigestAuth('user', 'pass')\n+            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n+            auth = HTTPDigestAuth(\"user\", \"pass\")\n             r = requests.get(url)\n-            assert r.cookies['fake'] == 'fake_value'\n+            assert r.cookies[\"fake\"] == \"fake_value\"\n \n             r = requests.get(url, auth=auth)\n             assert r.status_code == 200\n@@ -682,29 +713,29 @@ class TestRequests:\n     def test_DIGEST_AUTH_SETS_SESSION_COOKIES(self, httpbin):\n \n         for authtype in self.digest_auth_algo:\n-            url = httpbin('digest-auth', 'auth', 'user', 'pass', authtype)\n-            auth = HTTPDigestAuth('user', 'pass')\n+            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n+            auth = HTTPDigestAuth(\"user\", \"pass\")\n             s = requests.Session()\n             s.get(url, auth=auth)\n-            assert s.cookies['fake'] == 'fake_value'\n+            assert s.cookies[\"fake\"] == \"fake_value\"\n \n     def test_DIGEST_STREAM(self, httpbin):\n \n         for authtype in self.digest_auth_algo:\n-            auth = HTTPDigestAuth('user', 'pass')\n-            url = httpbin('digest-auth', 'auth', 'user', 'pass', authtype)\n+            auth = HTTPDigestAuth(\"user\", \"pass\")\n+            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n \n             r = requests.get(url, auth=auth, stream=True)\n-            assert r.raw.read() != b''\n+            assert r.raw.read() != b\"\"\n \n             r = requests.get(url, auth=auth, stream=False)\n-            assert r.raw.read() == b''\n+            assert r.raw.read() == b\"\"\n \n     def test_DIGESTAUTH_WRONG_HTTP_401_GET(self, httpbin):\n \n         for authtype in self.digest_auth_algo:\n-            auth = HTTPDigestAuth('user', 'wrongpass')\n-            url = httpbin('digest-auth', 'auth', 'user', 'pass', authtype)\n+            auth = HTTPDigestAuth(\"user\", \"wrongpass\")\n+            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n \n             r = requests.get(url, auth=auth)\n             assert r.status_code == 401\n@@ -720,41 +751,39 @@ class TestRequests:\n     def test_DIGESTAUTH_QUOTES_QOP_VALUE(self, httpbin):\n \n         for authtype in self.digest_auth_algo:\n-            auth = HTTPDigestAuth('user', 'pass')\n-            url = httpbin('digest-auth', 'auth', 'user', 'pass', authtype)\n+            auth = HTTPDigestAuth(\"user\", \"pass\")\n+            url = httpbin(\"digest-auth\", \"auth\", \"user\", \"pass\", authtype)\n \n             r = requests.get(url, auth=auth)\n-            assert '\"auth\"' in r.request.headers['Authorization']\n+            assert '\"auth\"' in r.request.headers[\"Authorization\"]\n \n     def test_POSTBIN_GET_POST_FILES(self, httpbin):\n \n-        url = httpbin('post')\n+        url = httpbin(\"post\")\n         requests.post(url).raise_for_status()\n \n-        post1 = requests.post(url, data={'some': 'data'})\n+        post1 = requests.post(url, data={\"some\": \"data\"})\n         assert post1.status_code == 200\n \n-        with open('requirements-dev.txt') as f:\n-            post2 = requests.post(url, files={'some': f})\n+        with open(\"requirements-dev.txt\") as f:\n+            post2 = requests.post(url, files={\"some\": f})\n         assert post2.status_code == 200\n \n         post4 = requests.post(url, data='[{\"some\": \"json\"}]')\n         assert post4.status_code == 200\n \n         with pytest.raises(ValueError):\n-            requests.post(url, files=['bad file data'])\n+            requests.post(url, files=[\"bad file data\"])\n \n     def test_invalid_files_input(self, httpbin):\n \n-        url = httpbin('post')\n-        post = requests.post(url,\n-                             files={\"random-file-1\": None, \"random-file-2\": 1})\n+        url = httpbin(\"post\")\n+        post = requests.post(url, files={\"random-file-1\": None, \"random-file-2\": 1})\n         assert b'name=\"random-file-1\"' not in post.request.body\n         assert b'name=\"random-file-2\"' in post.request.body\n \n     def test_POSTBIN_SEEKED_OBJECT_WITH_NO_ITER(self, httpbin):\n-\n-        class TestStream(object):\n+        class TestStream:\n             def __init__(self, data):\n                 self.data = data.encode()\n                 self.length = len(self.data)\n@@ -783,34 +812,34 @@ class TestRequests:\n                 elif where == 2:\n                     self.index = self.length + offset\n \n-        test = TestStream('test')\n-        post1 = requests.post(httpbin('post'), data=test)\n+        test = TestStream(\"test\")\n+        post1 = requests.post(httpbin(\"post\"), data=test)\n         assert post1.status_code == 200\n-        assert post1.json()['data'] == 'test'\n+        assert post1.json()[\"data\"] == \"test\"\n \n-        test = TestStream('test')\n+        test = TestStream(\"test\")\n         test.seek(2)\n-        post2 = requests.post(httpbin('post'), data=test)\n+        post2 = requests.post(httpbin(\"post\"), data=test)\n         assert post2.status_code == 200\n-        assert post2.json()['data'] == 'st'\n+        assert post2.json()[\"data\"] == \"st\"\n \n     def test_POSTBIN_GET_POST_FILES_WITH_DATA(self, httpbin):\n \n-        url = httpbin('post')\n+        url = httpbin(\"post\")\n         requests.post(url).raise_for_status()\n \n-        post1 = requests.post(url, data={'some': 'data'})\n+        post1 = requests.post(url, data={\"some\": \"data\"})\n         assert post1.status_code == 200\n \n-        with open('requirements-dev.txt') as f:\n-            post2 = requests.post(url, data={'some': 'data'}, files={'some': f})\n+        with open(\"requirements-dev.txt\") as f:\n+            post2 = requests.post(url, data={\"some\": \"data\"}, files={\"some\": f})\n         assert post2.status_code == 200\n \n         post4 = requests.post(url, data='[{\"some\": \"json\"}]')\n         assert post4.status_code == 200\n \n         with pytest.raises(ValueError):\n-            requests.post(url, files=['bad file data'])\n+            requests.post(url, files=[\"bad file data\"])\n \n     def test_post_with_custom_mapping(self, httpbin):\n         class CustomMapping(MutableMapping):\n@@ -832,128 +861,142 @@ class TestRequests:\n             def __len__(self):\n                 return len(self.data)\n \n-        data = CustomMapping({'some': 'data'})\n-        url = httpbin('post')\n-        found_json = requests.post(url, data=data).json().get('form')\n-        assert found_json == {'some': 'data'}\n+        data = CustomMapping({\"some\": \"data\"})\n+        url = httpbin(\"post\")\n+        found_json = requests.post(url, data=data).json().get(\"form\")\n+        assert found_json == {\"some\": \"data\"}\n \n     def test_conflicting_post_params(self, httpbin):\n-        url = httpbin('post')\n-        with open('requirements-dev.txt') as f:\n+        url = httpbin(\"post\")\n+        with open(\"requirements-dev.txt\") as f:\n             with pytest.raises(ValueError):\n-                requests.post(url, data='[{\"some\": \"data\"}]', files={'some': f})\n+                requests.post(url, data='[{\"some\": \"data\"}]', files={\"some\": f})\n \n     def test_request_ok_set(self, httpbin):\n-        r = requests.get(httpbin('status', '404'))\n+        r = requests.get(httpbin(\"status\", \"404\"))\n         assert not r.ok\n \n     def test_status_raising(self, httpbin):\n-        r = requests.get(httpbin('status', '404'))\n+        r = requests.get(httpbin(\"status\", \"404\"))\n         with pytest.raises(requests.exceptions.HTTPError):\n             r.raise_for_status()\n \n-        r = requests.get(httpbin('status', '500'))\n+        r = requests.get(httpbin(\"status\", \"500\"))\n         assert not r.ok\n \n     def test_decompress_gzip(self, httpbin):\n-        r = requests.get(httpbin('gzip'))\n-        r.content.decode('ascii')\n+        r = requests.get(httpbin(\"gzip\"))\n+        r.content.decode(\"ascii\")\n \n     @pytest.mark.parametrize(\n-        'url, params', (\n-            ('/get', {'foo': 'føø'}),\n-            ('/get', {'føø': 'føø'}),\n-            ('/get', {'føø': 'føø'}),\n-            ('/get', {'foo': 'foo'}),\n-            ('ø', {'foo': 'foo'}),\n-        ))\n+        \"url, params\",\n+        (\n+            (\"/get\", {\"foo\": \"føø\"}),\n+            (\"/get\", {\"føø\": \"føø\"}),\n+            (\"/get\", {\"føø\": \"føø\"}),\n+            (\"/get\", {\"foo\": \"foo\"}),\n+            (\"ø\", {\"foo\": \"foo\"}),\n+        ),\n+    )\n     def test_unicode_get(self, httpbin, url, params):\n         requests.get(httpbin(url), params=params)\n \n     def test_unicode_header_name(self, httpbin):\n         requests.put(\n-            httpbin('put'),\n-            headers={str('Content-Type'): 'application/octet-stream'},\n-            data='\\xff')  # compat.str is unicode.\n+            httpbin(\"put\"),\n+            headers={\"Content-Type\": \"application/octet-stream\"},\n+            data=\"\\xff\",\n+        )  # compat.str is unicode.\n \n     def test_pyopenssl_redirect(self, httpbin_secure, httpbin_ca_bundle):\n-        requests.get(httpbin_secure('status', '301'), verify=httpbin_ca_bundle)\n+        requests.get(httpbin_secure(\"status\", \"301\"), verify=httpbin_ca_bundle)\n \n     def test_invalid_ca_certificate_path(self, httpbin_secure):\n-        INVALID_PATH = '/garbage'\n+        INVALID_PATH = \"/garbage\"\n         with pytest.raises(IOError) as e:\n             requests.get(httpbin_secure(), verify=INVALID_PATH)\n-        assert str(e.value) == 'Could not find a suitable TLS CA certificate bundle, invalid path: {}'.format(INVALID_PATH)\n+        assert str(\n+            e.value\n+        ) == \"Could not find a suitable TLS CA certificate bundle, invalid path: {}\".format(\n+            INVALID_PATH\n+        )\n \n     def test_invalid_ssl_certificate_files(self, httpbin_secure):\n-        INVALID_PATH = '/garbage'\n+        INVALID_PATH = \"/garbage\"\n         with pytest.raises(IOError) as e:\n             requests.get(httpbin_secure(), cert=INVALID_PATH)\n-        assert str(e.value) == 'Could not find the TLS certificate file, invalid path: {}'.format(INVALID_PATH)\n+        assert str(\n+            e.value\n+        ) == \"Could not find the TLS certificate file, invalid path: {}\".format(\n+            INVALID_PATH\n+        )\n \n         with pytest.raises(IOError) as e:\n-            requests.get(httpbin_secure(), cert=('.', INVALID_PATH))\n-        assert str(e.value) == 'Could not find the TLS key file, invalid path: {}'.format(INVALID_PATH)\n+            requests.get(httpbin_secure(), cert=(\".\", INVALID_PATH))\n+        assert str(e.value) == (\n+            f\"Could not find the TLS key file, invalid path: {INVALID_PATH}\"\n+        )\n \n     @pytest.mark.parametrize(\n-        'env, expected', (\n+        \"env, expected\",\n+        (\n             ({}, True),\n-            ({'REQUESTS_CA_BUNDLE': '/some/path'}, '/some/path'),\n-            ({'REQUESTS_CA_BUNDLE': ''}, True),\n-            ({'CURL_CA_BUNDLE': '/some/path'}, '/some/path'),\n-            ({'CURL_CA_BUNDLE': ''}, True),\n-            ({'REQUESTS_CA_BUNDLE': '', 'CURL_CA_BUNDLE': ''}, True),\n+            ({\"REQUESTS_CA_BUNDLE\": \"/some/path\"}, \"/some/path\"),\n+            ({\"REQUESTS_CA_BUNDLE\": \"\"}, True),\n+            ({\"CURL_CA_BUNDLE\": \"/some/path\"}, \"/some/path\"),\n+            ({\"CURL_CA_BUNDLE\": \"\"}, True),\n+            ({\"REQUESTS_CA_BUNDLE\": \"\", \"CURL_CA_BUNDLE\": \"\"}, True),\n             (\n                 {\n-                    'REQUESTS_CA_BUNDLE': '/some/path',\n-                    'CURL_CA_BUNDLE': '/curl/path',\n+                    \"REQUESTS_CA_BUNDLE\": \"/some/path\",\n+                    \"CURL_CA_BUNDLE\": \"/curl/path\",\n                 },\n-                '/some/path',\n+                \"/some/path\",\n             ),\n             (\n                 {\n-                    'REQUESTS_CA_BUNDLE': '',\n-                    'CURL_CA_BUNDLE': '/curl/path',\n+                    \"REQUESTS_CA_BUNDLE\": \"\",\n+                    \"CURL_CA_BUNDLE\": \"/curl/path\",\n                 },\n-                '/curl/path',\n+                \"/curl/path\",\n+            ),\n         ),\n-        )\n     )\n     def test_env_cert_bundles(self, httpbin, mocker, env, expected):\n         s = requests.Session()\n-        mocker.patch('os.environ', env)\n+        mocker.patch(\"os.environ\", env)\n         settings = s.merge_environment_settings(\n-            url=httpbin('get'),\n-            proxies={},\n-            stream=False,\n-            verify=True,\n-            cert=None\n+            url=httpbin(\"get\"), proxies={}, stream=False, verify=True, cert=None\n         )\n-        assert settings['verify'] == expected\n+        assert settings[\"verify\"] == expected\n \n     def test_http_with_certificate(self, httpbin):\n-        r = requests.get(httpbin(), cert='.')\n+        r = requests.get(httpbin(), cert=\".\")\n         assert r.status_code == 200\n \n     def test_https_warnings(self, nosan_server):\n         \"\"\"warnings are emitted with requests.get\"\"\"\n         host, port, ca_bundle = nosan_server\n         if HAS_MODERN_SSL or HAS_PYOPENSSL:\n-            warnings_expected = ('SubjectAltNameWarning', )\n+            warnings_expected = (\"SubjectAltNameWarning\",)\n         else:\n-            warnings_expected = ('SNIMissingWarning',\n-                                 'InsecurePlatformWarning',\n-                                 'SubjectAltNameWarning', )\n+            warnings_expected = (\n+                \"SNIMissingWarning\",\n+                \"InsecurePlatformWarning\",\n+                \"SubjectAltNameWarning\",\n+            )\n \n         with pytest.warns(None) as warning_records:\n-            warnings.simplefilter('always')\n-            requests.get(\"https://localhost:{}/\".format(port), verify=ca_bundle)\n+            warnings.simplefilter(\"always\")\n+            requests.get(f\"https://localhost:{port}/\", verify=ca_bundle)\n \n-        warning_records = [item for item in warning_records\n-                           if item.category.__name__ != 'ResourceWarning']\n+        warning_records = [\n+            item\n+            for item in warning_records\n+            if item.category.__name__ != \"ResourceWarning\"\n+        ]\n \n-        warnings_category = tuple(\n-            item.category.__name__ for item in warning_records)\n+        warnings_category = tuple(item.category.__name__ for item in warning_records)\n         assert warnings_category == warnings_expected\n \n     def test_certificate_failure(self, httpbin_secure):\n@@ -963,83 +1006,96 @@ class TestRequests:\n         with pytest.raises(RequestsSSLError):\n             # Our local httpbin does not have a trusted CA, so this call will\n             # fail if we use our default trust bundle.\n-            requests.get(httpbin_secure('status', '200'))\n+            requests.get(httpbin_secure(\"status\", \"200\"))\n \n     def test_urlencoded_get_query_multivalued_param(self, httpbin):\n \n-        r = requests.get(httpbin('get'), params={'test': ['foo', 'baz']})\n+        r = requests.get(httpbin(\"get\"), params={\"test\": [\"foo\", \"baz\"]})\n         assert r.status_code == 200\n-        assert r.url == httpbin('get?test=foo&test=baz')\n+        assert r.url == httpbin(\"get?test=foo&test=baz\")\n \n     def test_form_encoded_post_query_multivalued_element(self, httpbin):\n-        r = requests.Request(method='POST', url=httpbin('post'),\n-                             data=dict(test=['foo', 'baz']))\n+        r = requests.Request(\n+            method=\"POST\", url=httpbin(\"post\"), data=dict(test=[\"foo\", \"baz\"])\n+        )\n         prep = r.prepare()\n-        assert prep.body == 'test=foo&test=baz'\n+        assert prep.body == \"test=foo&test=baz\"\n \n     def test_different_encodings_dont_break_post(self, httpbin):\n-        r = requests.post(httpbin('post'),\n-            data={'stuff': json.dumps({'a': 123})},\n-            params={'blah': 'asdf1234'},\n-            files={'file': ('test_requests.py', open(__file__, 'rb'))})\n+        r = requests.post(\n+            httpbin(\"post\"),\n+            data={\"stuff\": json.dumps({\"a\": 123})},\n+            params={\"blah\": \"asdf1234\"},\n+            files={\"file\": (\"test_requests.py\", open(__file__, \"rb\"))},\n+        )\n         assert r.status_code == 200\n \n     @pytest.mark.parametrize(\n-        'data', (\n-            {'stuff': 'ëlïxr'},\n-            {'stuff': 'ëlïxr'.encode('utf-8')},\n-            {'stuff': 'elixr'},\n-            {'stuff': 'elixr'.encode('utf-8')},\n-        ))\n+        \"data\",\n+        (\n+            {\"stuff\": \"ëlïxr\"},\n+            {\"stuff\": \"ëlïxr\".encode()},\n+            {\"stuff\": \"elixr\"},\n+            {\"stuff\": b\"elixr\"},\n+        ),\n+    )\n     def test_unicode_multipart_post(self, httpbin, data):\n-        r = requests.post(httpbin('post'),\n+        r = requests.post(\n+            httpbin(\"post\"),\n             data=data,\n-            files={'file': ('test_requests.py', open(__file__, 'rb'))})\n+            files={\"file\": (\"test_requests.py\", open(__file__, \"rb\"))},\n+        )\n         assert r.status_code == 200\n \n     def test_unicode_multipart_post_fieldnames(self, httpbin):\n-        filename = os.path.splitext(__file__)[0] + '.py'\n+        filename = os.path.splitext(__file__)[0] + \".py\"\n         r = requests.Request(\n-            method='POST', url=httpbin('post'),\n-            data={'stuff'.encode('utf-8'): 'elixr'},\n-            files={'file': ('test_requests.py', open(filename, 'rb'))})\n+            method=\"POST\",\n+            url=httpbin(\"post\"),\n+            data={b\"stuff\": \"elixr\"},\n+            files={\"file\": (\"test_requests.py\", open(filename, \"rb\"))},\n+        )\n         prep = r.prepare()\n         assert b'name=\"stuff\"' in prep.body\n-        assert b'name=\"b\\'stuff\\'\"' not in prep.body\n+        assert b\"name=\\\"b'stuff'\\\"\" not in prep.body\n \n     def test_unicode_method_name(self, httpbin):\n-        files = {'file': open(__file__, 'rb')}\n-        r = requests.request(\n-            method='POST', url=httpbin('post'), files=files)\n+        files = {\"file\": open(__file__, \"rb\")}\n+        r = requests.request(method=\"POST\", url=httpbin(\"post\"), files=files)\n         assert r.status_code == 200\n \n     def test_unicode_method_name_with_request_object(self, httpbin):\n-        files = {'file': open(__file__, 'rb')}\n+        files = {\"file\": open(__file__, \"rb\")}\n         s = requests.Session()\n-        req = requests.Request('POST', httpbin('post'), files=files)\n+        req = requests.Request(\"POST\", httpbin(\"post\"), files=files)\n         prep = s.prepare_request(req)\n         assert isinstance(prep.method, builtin_str)\n-        assert prep.method == 'POST'\n+        assert prep.method == \"POST\"\n \n         resp = s.send(prep)\n         assert resp.status_code == 200\n \n     def test_non_prepared_request_error(self):\n         s = requests.Session()\n-        req = requests.Request('POST', '/')\n+        req = requests.Request(\"POST\", \"/\")\n \n         with pytest.raises(ValueError) as e:\n             s.send(req)\n-        assert str(e.value) == 'You can only send PreparedRequests.'\n+        assert str(e.value) == \"You can only send PreparedRequests.\"\n \n     def test_custom_content_type(self, httpbin):\n         r = requests.post(\n-            httpbin('post'),\n-            data={'stuff': json.dumps({'a': 123})},\n+            httpbin(\"post\"),\n+            data={\"stuff\": json.dumps({\"a\": 123})},\n             files={\n-                'file1': ('test_requests.py', open(__file__, 'rb')),\n-                'file2': ('test_requests', open(__file__, 'rb'),\n-                    'text/py-content-type')})\n+                \"file1\": (\"test_requests.py\", open(__file__, \"rb\")),\n+                \"file2\": (\n+                    \"test_requests\",\n+                    open(__file__, \"rb\"),\n+                    \"text/py-content-type\",\n+                ),\n+            },\n+        )\n         assert r.status_code == 200\n         assert b\"text/py-content-type\" in r.request.body\n \n@@ -1049,50 +1105,56 @@ class TestRequests:\n             assert kwargs != {}\n \n         s = requests.Session()\n-        r = requests.Request('GET', httpbin(), hooks={'response': hook})\n+        r = requests.Request(\"GET\", httpbin(), hooks={\"response\": hook})\n         prep = s.prepare_request(r)\n         s.send(prep)\n \n     def test_session_hooks_are_used_with_no_request_hooks(self, httpbin):\n-        hook = lambda x, *args, **kwargs: x\n+        def hook(*args, **kwargs):\n+            pass\n+\n         s = requests.Session()\n-        s.hooks['response'].append(hook)\n-        r = requests.Request('GET', httpbin())\n+        s.hooks[\"response\"].append(hook)\n+        r = requests.Request(\"GET\", httpbin())\n         prep = s.prepare_request(r)\n-        assert prep.hooks['response'] != []\n-        assert prep.hooks['response'] == [hook]\n+        assert prep.hooks[\"response\"] != []\n+        assert prep.hooks[\"response\"] == [hook]\n \n     def test_session_hooks_are_overridden_by_request_hooks(self, httpbin):\n-        hook1 = lambda x, *args, **kwargs: x\n-        hook2 = lambda x, *args, **kwargs: x\n+        def hook1(*args, **kwargs):\n+            pass\n+\n+        def hook2(*args, **kwargs):\n+            pass\n+\n         assert hook1 is not hook2\n         s = requests.Session()\n-        s.hooks['response'].append(hook2)\n-        r = requests.Request('GET', httpbin(), hooks={'response': [hook1]})\n+        s.hooks[\"response\"].append(hook2)\n+        r = requests.Request(\"GET\", httpbin(), hooks={\"response\": [hook1]})\n         prep = s.prepare_request(r)\n-        assert prep.hooks['response'] == [hook1]\n+        assert prep.hooks[\"response\"] == [hook1]\n \n     def test_prepared_request_hook(self, httpbin):\n         def hook(resp, **kwargs):\n             resp.hook_working = True\n             return resp\n \n-        req = requests.Request('GET', httpbin(), hooks={'response': hook})\n+        req = requests.Request(\"GET\", httpbin(), hooks={\"response\": hook})\n         prep = req.prepare()\n \n         s = requests.Session()\n         s.proxies = getproxies()\n         resp = s.send(prep)\n \n-        assert hasattr(resp, 'hook_working')\n+        assert hasattr(resp, \"hook_working\")\n \n     def test_prepared_from_session(self, httpbin):\n         class DummyAuth(requests.auth.AuthBase):\n             def __call__(self, r):\n-                r.headers['Dummy-Auth-Test'] = 'dummy-auth-test-ok'\n+                r.headers[\"Dummy-Auth-Test\"] = \"dummy-auth-test-ok\"\n                 return r\n \n-        req = requests.Request('GET', httpbin('headers'))\n+        req = requests.Request(\"GET\", httpbin(\"headers\"))\n         assert not req.auth\n \n         s = requests.Session()\n@@ -1101,11 +1163,10 @@ class TestRequests:\n         prep = s.prepare_request(req)\n         resp = s.send(prep)\n \n-        assert resp.json()['headers'][\n-            'Dummy-Auth-Test'] == 'dummy-auth-test-ok'\n+        assert resp.json()[\"headers\"][\"Dummy-Auth-Test\"] == \"dummy-auth-test-ok\"\n \n     def test_prepare_request_with_bytestring_url(self):\n-        req = requests.Request('GET', b'https://httpbin.org/')\n+        req = requests.Request(\"GET\", b\"https://httpbin.org/\")\n         s = requests.Session()\n         prep = s.prepare_request(req)\n         assert prep.url == \"https://httpbin.org/\"\n@@ -1113,61 +1174,63 @@ class TestRequests:\n     def test_request_with_bytestring_host(self, httpbin):\n         s = requests.Session()\n         resp = s.request(\n-            'GET',\n-            httpbin('cookies/set?cookie=value'),\n+            \"GET\",\n+            httpbin(\"cookies/set?cookie=value\"),\n             allow_redirects=False,\n-            headers={'Host': b'httpbin.org'}\n+            headers={\"Host\": b\"httpbin.org\"},\n         )\n-        assert resp.cookies.get('cookie') == 'value'\n+        assert resp.cookies.get(\"cookie\") == \"value\"\n \n     def test_links(self):\n         r = requests.Response()\n         r.headers = {\n-            'cache-control': 'public, max-age=60, s-maxage=60',\n-            'connection': 'keep-alive',\n-            'content-encoding': 'gzip',\n-            'content-type': 'application/json; charset=utf-8',\n-            'date': 'Sat, 26 Jan 2013 16:47:56 GMT',\n-            'etag': '\"6ff6a73c0e446c1f61614769e3ceb778\"',\n-            'last-modified': 'Sat, 26 Jan 2013 16:22:39 GMT',\n-            'link': ('<https://api.github.com/users/kennethreitz/repos?'\n+            \"cache-control\": \"public, max-age=60, s-maxage=60\",\n+            \"connection\": \"keep-alive\",\n+            \"content-encoding\": \"gzip\",\n+            \"content-type\": \"application/json; charset=utf-8\",\n+            \"date\": \"Sat, 26 Jan 2013 16:47:56 GMT\",\n+            \"etag\": '\"6ff6a73c0e446c1f61614769e3ceb778\"',\n+            \"last-modified\": \"Sat, 26 Jan 2013 16:22:39 GMT\",\n+            \"link\": (\n+                \"<https://api.github.com/users/kennethreitz/repos?\"\n                 'page=2&per_page=10>; rel=\"next\", <https://api.github.'\n-                     'com/users/kennethreitz/repos?page=7&per_page=10>; '\n-                     ' rel=\"last\"'),\n-            'server': 'GitHub.com',\n-            'status': '200 OK',\n-            'vary': 'Accept',\n-            'x-content-type-options': 'nosniff',\n-            'x-github-media-type': 'github.beta',\n-            'x-ratelimit-limit': '60',\n-            'x-ratelimit-remaining': '57'\n+                \"com/users/kennethreitz/repos?page=7&per_page=10>; \"\n+                ' rel=\"last\"'\n+            ),\n+            \"server\": \"GitHub.com\",\n+            \"status\": \"200 OK\",\n+            \"vary\": \"Accept\",\n+            \"x-content-type-options\": \"nosniff\",\n+            \"x-github-media-type\": \"github.beta\",\n+            \"x-ratelimit-limit\": \"60\",\n+            \"x-ratelimit-remaining\": \"57\",\n         }\n-        assert r.links['next']['rel'] == 'next'\n+        assert r.links[\"next\"][\"rel\"] == \"next\"\n \n     def test_cookie_parameters(self):\n-        key = 'some_cookie'\n-        value = 'some_value'\n+        key = \"some_cookie\"\n+        value = \"some_value\"\n         secure = True\n-        domain = 'test.com'\n-        rest = {'HttpOnly': True}\n+        domain = \"test.com\"\n+        rest = {\"HttpOnly\": True}\n \n         jar = requests.cookies.RequestsCookieJar()\n         jar.set(key, value, secure=secure, domain=domain, rest=rest)\n \n         assert len(jar) == 1\n-        assert 'some_cookie' in jar\n+        assert \"some_cookie\" in jar\n \n         cookie = list(jar)[0]\n         assert cookie.secure == secure\n         assert cookie.domain == domain\n-        assert cookie._rest['HttpOnly'] == rest['HttpOnly']\n+        assert cookie._rest[\"HttpOnly\"] == rest[\"HttpOnly\"]\n \n     def test_cookie_as_dict_keeps_len(self):\n-        key = 'some_cookie'\n-        value = 'some_value'\n+        key = \"some_cookie\"\n+        value = \"some_value\"\n \n-        key1 = 'some_cookie1'\n-        value1 = 'some_value1'\n+        key1 = \"some_cookie1\"\n+        value1 = \"some_value1\"\n \n         jar = requests.cookies.RequestsCookieJar()\n         jar.set(key, value)\n@@ -1183,11 +1246,11 @@ class TestRequests:\n         assert len(d3) == 2\n \n     def test_cookie_as_dict_keeps_items(self):\n-        key = 'some_cookie'\n-        value = 'some_value'\n+        key = \"some_cookie\"\n+        value = \"some_value\"\n \n-        key1 = 'some_cookie1'\n-        value1 = 'some_value1'\n+        key1 = \"some_cookie1\"\n+        value1 = \"some_value1\"\n \n         jar = requests.cookies.RequestsCookieJar()\n         jar.set(key, value)\n@@ -1197,16 +1260,16 @@ class TestRequests:\n         d2 = dict(jar.iteritems())\n         d3 = dict(jar.items())\n \n-        assert d1['some_cookie'] == 'some_value'\n-        assert d2['some_cookie'] == 'some_value'\n-        assert d3['some_cookie1'] == 'some_value1'\n+        assert d1[\"some_cookie\"] == \"some_value\"\n+        assert d2[\"some_cookie\"] == \"some_value\"\n+        assert d3[\"some_cookie1\"] == \"some_value1\"\n \n     def test_cookie_as_dict_keys(self):\n-        key = 'some_cookie'\n-        value = 'some_value'\n+        key = \"some_cookie\"\n+        value = \"some_value\"\n \n-        key1 = 'some_cookie1'\n-        value1 = 'some_value1'\n+        key1 = \"some_cookie1\"\n+        value1 = \"some_value1\"\n \n         jar = requests.cookies.RequestsCookieJar()\n         jar.set(key, value)\n@@ -1218,11 +1281,11 @@ class TestRequests:\n         assert list(keys) == list(keys)\n \n     def test_cookie_as_dict_values(self):\n-        key = 'some_cookie'\n-        value = 'some_value'\n+        key = \"some_cookie\"\n+        value = \"some_value\"\n \n-        key1 = 'some_cookie1'\n-        value1 = 'some_value1'\n+        key1 = \"some_cookie1\"\n+        value1 = \"some_value1\"\n \n         jar = requests.cookies.RequestsCookieJar()\n         jar.set(key, value)\n@@ -1234,11 +1297,11 @@ class TestRequests:\n         assert list(values) == list(values)\n \n     def test_cookie_as_dict_items(self):\n-        key = 'some_cookie'\n-        value = 'some_value'\n+        key = \"some_cookie\"\n+        value = \"some_value\"\n \n-        key1 = 'some_cookie1'\n-        value1 = 'some_value1'\n+        key1 = \"some_cookie1\"\n+        value1 = \"some_value1\"\n \n         jar = requests.cookies.RequestsCookieJar()\n         jar.set(key, value)\n@@ -1250,10 +1313,10 @@ class TestRequests:\n         assert list(items) == list(items)\n \n     def test_cookie_duplicate_names_different_domains(self):\n-        key = 'some_cookie'\n-        value = 'some_value'\n-        domain1 = 'test1.com'\n-        domain2 = 'test2.com'\n+        key = \"some_cookie\"\n+        value = \"some_value\"\n+        domain1 = \"test1.com\"\n+        domain2 = \"test2.com\"\n \n         jar = requests.cookies.RequestsCookieJar()\n         jar.set(key, value, domain=domain1)\n@@ -1271,9 +1334,9 @@ class TestRequests:\n         assert cookie == value\n \n     def test_cookie_duplicate_names_raises_cookie_conflict_error(self):\n-        key = 'some_cookie'\n-        value = 'some_value'\n-        path = 'some_path'\n+        key = \"some_cookie\"\n+        value = \"some_value\"\n+        path = \"some_path\"\n \n         jar = requests.cookies.RequestsCookieJar()\n         jar.set(key, value, path=path)\n@@ -1290,9 +1353,11 @@ class TestRequests:\n         assert isinstance(jar.copy().get_policy(), MyCookiePolicy)\n \n     def test_time_elapsed_blank(self, httpbin):\n-        r = requests.get(httpbin('get'))\n+        r = requests.get(httpbin(\"get\"))\n         td = r.elapsed\n-        total_seconds = ((td.microseconds + (td.seconds + td.days * 24 * 3600) * 10**6) / 10**6)\n+        total_seconds = (\n+            td.microseconds + (td.seconds + td.days * 24 * 3600) * 10**6\n+        ) / 10**6\n         assert total_seconds > 0.0\n \n     def test_empty_response_has_content_none(self):\n@@ -1301,12 +1366,13 @@ class TestRequests:\n \n     def test_response_is_iterable(self):\n         r = requests.Response()\n-        io = StringIO.StringIO('abc')\n+        io = StringIO.StringIO(\"abc\")\n         read_ = io.read\n \n         def read_mock(amt, decode_content=None):\n             return read_(amt)\n-        setattr(io, 'read', read_mock)\n+\n+        setattr(io, \"read\", read_mock)\n         r.raw = io\n         assert next(iter(r))\n         io.close()\n@@ -1317,24 +1383,24 @@ class TestRequests:\n         \"\"\"\n         r = requests.Response()\n         r._content_consumed = True\n-        r._content = b'the content'\n-        r.encoding = 'ascii'\n+        r._content = b\"the content\"\n+        r.encoding = \"ascii\"\n \n         chunks = r.iter_content(decode_unicode=True)\n         assert all(isinstance(chunk, str) for chunk in chunks)\n \n         # also for streaming\n         r = requests.Response()\n-        r.raw = io.BytesIO(b'the content')\n-        r.encoding = 'ascii'\n+        r.raw = io.BytesIO(b\"the content\")\n+        r.encoding = \"ascii\"\n         chunks = r.iter_content(decode_unicode=True)\n         assert all(isinstance(chunk, str) for chunk in chunks)\n \n     def test_response_reason_unicode(self):\n         # check for unicode HTTP status\n         r = requests.Response()\n-        r.url = 'unicode URL'\n-        r.reason = 'Komponenttia ei löydy'.encode('utf-8')\n+        r.url = \"unicode URL\"\n+        r.reason = \"Komponenttia ei löydy\".encode()\n         r.status_code = 404\n         r.encoding = None\n         assert not r.ok  # old behaviour - crashes here\n@@ -1342,9 +1408,9 @@ class TestRequests:\n     def test_response_reason_unicode_fallback(self):\n         # check raise_status falls back to ISO-8859-1\n         r = requests.Response()\n-        r.url = 'some url'\n-        reason = 'Komponenttia ei löydy'\n-        r.reason = reason.encode('latin-1')\n+        r.url = \"some url\"\n+        reason = \"Komponenttia ei löydy\"\n+        r.reason = reason.encode(\"latin-1\")\n         r.status_code = 500\n         r.encoding = None\n         with pytest.raises(requests.exceptions.HTTPError) as e:\n@@ -1356,27 +1422,28 @@ class TestRequests:\n         raise a TypeError.\n         \"\"\"\n         r = requests.Response()\n-        r.raw = io.BytesIO(b'the content')\n+        r.raw = io.BytesIO(b\"the content\")\n         chunks = r.iter_content(1)\n         assert all(len(chunk) == 1 for chunk in chunks)\n \n         r = requests.Response()\n-        r.raw = io.BytesIO(b'the content')\n+        r.raw = io.BytesIO(b\"the content\")\n         chunks = r.iter_content(None)\n-        assert list(chunks) == [b'the content']\n+        assert list(chunks) == [b\"the content\"]\n \n         r = requests.Response()\n-        r.raw = io.BytesIO(b'the content')\n+        r.raw = io.BytesIO(b\"the content\")\n         with pytest.raises(TypeError):\n             chunks = r.iter_content(\"1024\")\n \n     @pytest.mark.parametrize(\n-        'exception, args, expected', (\n+        \"exception, args, expected\",\n+        (\n             (urllib3.exceptions.ProtocolError, tuple(), ChunkedEncodingError),\n             (urllib3.exceptions.DecodeError, tuple(), ContentDecodingError),\n-            (urllib3.exceptions.ReadTimeoutError, (None, '', ''), ConnectionError),\n+            (urllib3.exceptions.ReadTimeoutError, (None, \"\", \"\"), ConnectionError),\n             (urllib3.exceptions.SSLError, tuple(), RequestsSSLError),\n-        )\n+        ),\n     )\n     def test_iter_content_wraps_exceptions(\n         self, httpbin, mocker, exception, args, expected\n@@ -1391,7 +1458,7 @@ class TestRequests:\n             next(r.iter_content(1024))\n \n     def test_request_and_response_are_pickleable(self, httpbin):\n-        r = requests.get(httpbin('get'))\n+        r = requests.get(httpbin(\"get\"))\n \n         # verify we can pickle the original request\n         assert pickle.loads(pickle.dumps(r.request))\n@@ -1403,7 +1470,7 @@ class TestRequests:\n         assert r.request.headers == pr.request.headers\n \n     def test_prepared_request_is_pickleable(self, httpbin):\n-        p = requests.Request('GET', httpbin('get')).prepare()\n+        p = requests.Request(\"GET\", httpbin(\"get\")).prepare()\n \n         # Verify PreparedRequest can be pickled and unpickled\n         r = pickle.loads(pickle.dumps(p))\n@@ -1417,8 +1484,8 @@ class TestRequests:\n         assert resp.status_code == 200\n \n     def test_prepared_request_with_file_is_pickleable(self, httpbin):\n-        files = {'file': open(__file__, 'rb')}\n-        r = requests.Request('POST', httpbin('post'), files=files)\n+        files = {\"file\": open(__file__, \"rb\")}\n+        r = requests.Request(\"POST\", httpbin(\"post\"), files=files)\n         p = r.prepare()\n \n         # Verify PreparedRequest can be pickled and unpickled\n@@ -1433,7 +1500,7 @@ class TestRequests:\n         assert resp.status_code == 200\n \n     def test_prepared_request_with_hook_is_pickleable(self, httpbin):\n-        r = requests.Request('GET', httpbin('get'), hooks=default_hooks())\n+        r = requests.Request(\"GET\", httpbin(\"get\"), hooks=default_hooks())\n         p = r.prepare()\n \n         # Verify PreparedRequest can be pickled\n@@ -1459,12 +1526,12 @@ class TestRequests:\n         response = requests.Response()\n         error = requests.exceptions.HTTPError(response=response)\n         assert error.response == response\n-        error = requests.exceptions.HTTPError('message', response=response)\n-        assert str(error) == 'message'\n+        error = requests.exceptions.HTTPError(\"message\", response=response)\n+        assert str(error) == \"message\"\n         assert error.response == response\n \n     def test_session_pickling(self, httpbin):\n-        r = requests.Request('GET', httpbin('get'))\n+        r = requests.Request(\"GET\", httpbin(\"get\"))\n         s = requests.Session()\n \n         s = pickle.loads(pickle.dumps(s))\n@@ -1476,66 +1543,66 @@ class TestRequests:\n     def test_fixes_1329(self, httpbin):\n         \"\"\"Ensure that header updates are done case-insensitively.\"\"\"\n         s = requests.Session()\n-        s.headers.update({'ACCEPT': 'BOGUS'})\n-        s.headers.update({'accept': 'application/json'})\n-        r = s.get(httpbin('get'))\n+        s.headers.update({\"ACCEPT\": \"BOGUS\"})\n+        s.headers.update({\"accept\": \"application/json\"})\n+        r = s.get(httpbin(\"get\"))\n         headers = r.request.headers\n-        assert headers['accept'] == 'application/json'\n-        assert headers['Accept'] == 'application/json'\n-        assert headers['ACCEPT'] == 'application/json'\n+        assert headers[\"accept\"] == \"application/json\"\n+        assert headers[\"Accept\"] == \"application/json\"\n+        assert headers[\"ACCEPT\"] == \"application/json\"\n \n     def test_uppercase_scheme_redirect(self, httpbin):\n-        parts = urlparse(httpbin('html'))\n+        parts = urlparse(httpbin(\"html\"))\n         url = \"HTTP://\" + parts.netloc + parts.path\n-        r = requests.get(httpbin('redirect-to'), params={'url': url})\n+        r = requests.get(httpbin(\"redirect-to\"), params={\"url\": url})\n         assert r.status_code == 200\n         assert r.url.lower() == url.lower()\n \n     def test_transport_adapter_ordering(self):\n         s = requests.Session()\n-        order = ['https://', 'http://']\n+        order = [\"https://\", \"http://\"]\n         assert order == list(s.adapters)\n-        s.mount('http://git', HTTPAdapter())\n-        s.mount('http://github', HTTPAdapter())\n-        s.mount('http://github.com', HTTPAdapter())\n-        s.mount('http://github.com/about/', HTTPAdapter())\n+        s.mount(\"http://git\", HTTPAdapter())\n+        s.mount(\"http://github\", HTTPAdapter())\n+        s.mount(\"http://github.com\", HTTPAdapter())\n+        s.mount(\"http://github.com/about/\", HTTPAdapter())\n         order = [\n-            'http://github.com/about/',\n-            'http://github.com',\n-            'http://github',\n-            'http://git',\n-            'https://',\n-            'http://',\n+            \"http://github.com/about/\",\n+            \"http://github.com\",\n+            \"http://github\",\n+            \"http://git\",\n+            \"https://\",\n+            \"http://\",\n         ]\n         assert order == list(s.adapters)\n-        s.mount('http://gittip', HTTPAdapter())\n-        s.mount('http://gittip.com', HTTPAdapter())\n-        s.mount('http://gittip.com/about/', HTTPAdapter())\n+        s.mount(\"http://gittip\", HTTPAdapter())\n+        s.mount(\"http://gittip.com\", HTTPAdapter())\n+        s.mount(\"http://gittip.com/about/\", HTTPAdapter())\n         order = [\n-            'http://github.com/about/',\n-            'http://gittip.com/about/',\n-            'http://github.com',\n-            'http://gittip.com',\n-            'http://github',\n-            'http://gittip',\n-            'http://git',\n-            'https://',\n-            'http://',\n+            \"http://github.com/about/\",\n+            \"http://gittip.com/about/\",\n+            \"http://github.com\",\n+            \"http://gittip.com\",\n+            \"http://github\",\n+            \"http://gittip\",\n+            \"http://git\",\n+            \"https://\",\n+            \"http://\",\n         ]\n         assert order == list(s.adapters)\n         s2 = requests.Session()\n-        s2.adapters = {'http://': HTTPAdapter()}\n-        s2.mount('https://', HTTPAdapter())\n-        assert 'http://' in s2.adapters\n-        assert 'https://' in s2.adapters\n+        s2.adapters = {\"http://\": HTTPAdapter()}\n+        s2.mount(\"https://\", HTTPAdapter())\n+        assert \"http://\" in s2.adapters\n+        assert \"https://\" in s2.adapters\n \n     def test_session_get_adapter_prefix_matching(self):\n-        prefix = 'https://example.com'\n-        more_specific_prefix = prefix + '/some/path'\n+        prefix = \"https://example.com\"\n+        more_specific_prefix = prefix + \"/some/path\"\n \n-        url_matching_only_prefix = prefix + '/another/path'\n-        url_matching_more_specific_prefix = more_specific_prefix + '/longer/path'\n-        url_not_matching_prefix = 'https://another.example.com/'\n+        url_matching_only_prefix = prefix + \"/another/path\"\n+        url_matching_more_specific_prefix = more_specific_prefix + \"/longer/path\"\n+        url_not_matching_prefix = \"https://another.example.com/\"\n \n         s = requests.Session()\n         prefix_adapter = HTTPAdapter()\n@@ -1544,12 +1611,18 @@ class TestRequests:\n         s.mount(more_specific_prefix, more_specific_prefix_adapter)\n \n         assert s.get_adapter(url_matching_only_prefix) is prefix_adapter\n-        assert s.get_adapter(url_matching_more_specific_prefix) is more_specific_prefix_adapter\n-        assert s.get_adapter(url_not_matching_prefix) not in (prefix_adapter, more_specific_prefix_adapter)\n+        assert (\n+            s.get_adapter(url_matching_more_specific_prefix)\n+            is more_specific_prefix_adapter\n+        )\n+        assert s.get_adapter(url_not_matching_prefix) not in (\n+            prefix_adapter,\n+            more_specific_prefix_adapter,\n+        )\n \n     def test_session_get_adapter_prefix_matching_mixed_case(self):\n-        mixed_case_prefix = 'hTtPs://eXamPle.CoM/MixEd_CAse_PREfix'\n-        url_matching_prefix = mixed_case_prefix + '/full_url'\n+        mixed_case_prefix = \"hTtPs://eXamPle.CoM/MixEd_CAse_PREfix\"\n+        url_matching_prefix = mixed_case_prefix + \"/full_url\"\n \n         s = requests.Session()\n         my_adapter = HTTPAdapter()\n@@ -1558,8 +1631,10 @@ class TestRequests:\n         assert s.get_adapter(url_matching_prefix) is my_adapter\n \n     def test_session_get_adapter_prefix_matching_is_case_insensitive(self):\n-        mixed_case_prefix = 'hTtPs://eXamPle.CoM/MixEd_CAse_PREfix'\n-        url_matching_prefix_with_different_case = 'HtTpS://exaMPLe.cOm/MiXeD_caSE_preFIX/another_url'\n+        mixed_case_prefix = \"hTtPs://eXamPle.CoM/MixEd_CAse_PREfix\"\n+        url_matching_prefix_with_different_case = (\n+            \"HtTpS://exaMPLe.cOm/MiXeD_caSE_preFIX/another_url\"\n+        )\n \n         s = requests.Session()\n         my_adapter = HTTPAdapter()\n@@ -1570,184 +1645,205 @@ class TestRequests:\n     def test_header_remove_is_case_insensitive(self, httpbin):\n         # From issue #1321\n         s = requests.Session()\n-        s.headers['foo'] = 'bar'\n-        r = s.get(httpbin('get'), headers={'FOO': None})\n-        assert 'foo' not in r.request.headers\n+        s.headers[\"foo\"] = \"bar\"\n+        r = s.get(httpbin(\"get\"), headers={\"FOO\": None})\n+        assert \"foo\" not in r.request.headers\n \n     def test_params_are_merged_case_sensitive(self, httpbin):\n         s = requests.Session()\n-        s.params['foo'] = 'bar'\n-        r = s.get(httpbin('get'), params={'FOO': 'bar'})\n-        assert r.json()['args'] == {'foo': 'bar', 'FOO': 'bar'}\n+        s.params[\"foo\"] = \"bar\"\n+        r = s.get(httpbin(\"get\"), params={\"FOO\": \"bar\"})\n+        assert r.json()[\"args\"] == {\"foo\": \"bar\", \"FOO\": \"bar\"}\n \n     def test_long_authinfo_in_url(self):\n-        url = 'http://{}:{}@{}:9000/path?query#frag'.format(\n-            'E8A3BE87-9E3F-4620-8858-95478E385B5B',\n-            'EA770032-DA4D-4D84-8CE9-29C6D910BF1E',\n-            'exactly-------------sixty-----------three------------characters',\n+        url = \"http://{}:{}@{}:9000/path?query#frag\".format(\n+            \"E8A3BE87-9E3F-4620-8858-95478E385B5B\",\n+            \"EA770032-DA4D-4D84-8CE9-29C6D910BF1E\",\n+            \"exactly-------------sixty-----------three------------characters\",\n         )\n-        r = requests.Request('GET', url).prepare()\n+        r = requests.Request(\"GET\", url).prepare()\n         assert r.url == url\n \n     def test_header_keys_are_native(self, httpbin):\n-        headers = {'unicode': 'blah', 'byte'.encode('ascii'): 'blah'}\n-        r = requests.Request('GET', httpbin('get'), headers=headers)\n+        headers = {\"unicode\": \"blah\", b\"byte\": \"blah\"}\n+        r = requests.Request(\"GET\", httpbin(\"get\"), headers=headers)\n         p = r.prepare()\n \n         # This is testing that they are builtin strings. A bit weird, but there\n         # we go.\n-        assert 'unicode' in p.headers.keys()\n-        assert 'byte' in p.headers.keys()\n+        assert \"unicode\" in p.headers.keys()\n+        assert \"byte\" in p.headers.keys()\n \n     def test_header_validation(self, httpbin):\n         \"\"\"Ensure prepare_headers regex isn't flagging valid header contents.\"\"\"\n-        headers_ok = {'foo': 'bar baz qux',\n-                      'bar': 'fbbq'.encode('utf8'),\n-                      'baz': '',\n-                      'qux': '1'}\n-        r = requests.get(httpbin('get'), headers=headers_ok)\n-        assert r.request.headers['foo'] == headers_ok['foo']\n+        headers_ok = {\n+            \"foo\": \"bar baz qux\",\n+            \"bar\": b\"fbbq\",\n+            \"baz\": \"\",\n+            \"qux\": \"1\",\n+        }\n+        r = requests.get(httpbin(\"get\"), headers=headers_ok)\n+        assert r.request.headers[\"foo\"] == headers_ok[\"foo\"]\n \n     def test_header_value_not_str(self, httpbin):\n         \"\"\"Ensure the header value is of type string or bytes as\n         per discussion in GH issue #3386\n         \"\"\"\n-        headers_int = {'foo': 3}\n-        headers_dict = {'bar': {'foo': 'bar'}}\n-        headers_list = {'baz': ['foo', 'bar']}\n+        headers_int = {\"foo\": 3}\n+        headers_dict = {\"bar\": {\"foo\": \"bar\"}}\n+        headers_list = {\"baz\": [\"foo\", \"bar\"]}\n \n         # Test for int\n         with pytest.raises(InvalidHeader) as excinfo:\n-            r = requests.get(httpbin('get'), headers=headers_int)\n-        assert 'foo' in str(excinfo.value)\n+            requests.get(httpbin(\"get\"), headers=headers_int)\n+        assert \"foo\" in str(excinfo.value)\n         # Test for dict\n         with pytest.raises(InvalidHeader) as excinfo:\n-            r = requests.get(httpbin('get'), headers=headers_dict)\n-        assert 'bar' in str(excinfo.value)\n+            requests.get(httpbin(\"get\"), headers=headers_dict)\n+        assert \"bar\" in str(excinfo.value)\n         # Test for list\n         with pytest.raises(InvalidHeader) as excinfo:\n-            r = requests.get(httpbin('get'), headers=headers_list)\n-        assert 'baz' in str(excinfo.value)\n+            requests.get(httpbin(\"get\"), headers=headers_list)\n+        assert \"baz\" in str(excinfo.value)\n \n     def test_header_no_return_chars(self, httpbin):\n         \"\"\"Ensure that a header containing return character sequences raise an\n         exception. Otherwise, multiple headers are created from single string.\n         \"\"\"\n-        headers_ret = {'foo': 'bar\\r\\nbaz: qux'}\n-        headers_lf = {'foo': 'bar\\nbaz: qux'}\n-        headers_cr = {'foo': 'bar\\rbaz: qux'}\n+        headers_ret = {\"foo\": \"bar\\r\\nbaz: qux\"}\n+        headers_lf = {\"foo\": \"bar\\nbaz: qux\"}\n+        headers_cr = {\"foo\": \"bar\\rbaz: qux\"}\n \n         # Test for newline\n         with pytest.raises(InvalidHeader):\n-            r = requests.get(httpbin('get'), headers=headers_ret)\n+            requests.get(httpbin(\"get\"), headers=headers_ret)\n         # Test for line feed\n         with pytest.raises(InvalidHeader):\n-            r = requests.get(httpbin('get'), headers=headers_lf)\n+            requests.get(httpbin(\"get\"), headers=headers_lf)\n         # Test for carriage return\n         with pytest.raises(InvalidHeader):\n-            r = requests.get(httpbin('get'), headers=headers_cr)\n+            requests.get(httpbin(\"get\"), headers=headers_cr)\n \n     def test_header_no_leading_space(self, httpbin):\n         \"\"\"Ensure headers containing leading whitespace raise\n         InvalidHeader Error before sending.\n         \"\"\"\n-        headers_space = {'foo': ' bar'}\n-        headers_tab = {'foo': '   bar'}\n+        headers_space = {\"foo\": \" bar\"}\n+        headers_tab = {\"foo\": \"   bar\"}\n \n         # Test for whitespace\n         with pytest.raises(InvalidHeader):\n-            r = requests.get(httpbin('get'), headers=headers_space)\n+            requests.get(httpbin(\"get\"), headers=headers_space)\n+\n         # Test for tab\n         with pytest.raises(InvalidHeader):\n-            r = requests.get(httpbin('get'), headers=headers_tab)\n+            requests.get(httpbin(\"get\"), headers=headers_tab)\n \n-    @pytest.mark.parametrize('files', ('foo', b'foo', bytearray(b'foo')))\n+    @pytest.mark.parametrize(\"files\", (\"foo\", b\"foo\", bytearray(b\"foo\")))\n     def test_can_send_objects_with_files(self, httpbin, files):\n-        data = {'a': 'this is a string'}\n-        files = {'b': files}\n-        r = requests.Request('POST', httpbin('post'), data=data, files=files)\n+        data = {\"a\": \"this is a string\"}\n+        files = {\"b\": files}\n+        r = requests.Request(\"POST\", httpbin(\"post\"), data=data, files=files)\n         p = r.prepare()\n-        assert 'multipart/form-data' in p.headers['Content-Type']\n+        assert \"multipart/form-data\" in p.headers[\"Content-Type\"]\n \n     def test_can_send_file_object_with_non_string_filename(self, httpbin):\n         f = io.BytesIO()\n         f.name = 2\n-        r = requests.Request('POST', httpbin('post'), files={'f': f})\n+        r = requests.Request(\"POST\", httpbin(\"post\"), files={\"f\": f})\n         p = r.prepare()\n \n-        assert 'multipart/form-data' in p.headers['Content-Type']\n+        assert \"multipart/form-data\" in p.headers[\"Content-Type\"]\n \n     def test_autoset_header_values_are_native(self, httpbin):\n-        data = 'this is a string'\n-        length = '16'\n-        req = requests.Request('POST', httpbin('post'), data=data)\n+        data = \"this is a string\"\n+        length = \"16\"\n+        req = requests.Request(\"POST\", httpbin(\"post\"), data=data)\n         p = req.prepare()\n \n-        assert p.headers['Content-Length'] == length\n+        assert p.headers[\"Content-Length\"] == length\n \n     def test_nonhttp_schemes_dont_check_URLs(self):\n         test_urls = (\n-            'data:image/gif;base64,R0lGODlhAQABAHAAACH5BAUAAAAALAAAAAABAAEAAAICRAEAOw==',\n-            'file:///etc/passwd',\n-            'magnet:?xt=urn:btih:be08f00302bc2d1d3cfa3af02024fa647a271431',\n+            \"data:image/gif;base64,R0lGODlhAQABAHAAACH5BAUAAAAALAAAAAABAAEAAAICRAEAOw==\",\n+            \"file:///etc/passwd\",\n+            \"magnet:?xt=urn:btih:be08f00302bc2d1d3cfa3af02024fa647a271431\",\n         )\n         for test_url in test_urls:\n-            req = requests.Request('GET', test_url)\n+            req = requests.Request(\"GET\", test_url)\n             preq = req.prepare()\n             assert test_url == preq.url\n \n-    def test_auth_is_stripped_on_http_downgrade(self, httpbin, httpbin_secure, httpbin_ca_bundle):\n+    def test_auth_is_stripped_on_http_downgrade(\n+        self, httpbin, httpbin_secure, httpbin_ca_bundle\n+    ):\n         r = requests.get(\n-            httpbin_secure('redirect-to'),\n-            params={'url': httpbin('get')},\n-            auth=('user', 'pass'),\n-            verify=httpbin_ca_bundle\n+            httpbin_secure(\"redirect-to\"),\n+            params={\"url\": httpbin(\"get\")},\n+            auth=(\"user\", \"pass\"),\n+            verify=httpbin_ca_bundle,\n         )\n-        assert r.history[0].request.headers['Authorization']\n-        assert 'Authorization' not in r.request.headers\n+        assert r.history[0].request.headers[\"Authorization\"]\n+        assert \"Authorization\" not in r.request.headers\n \n     def test_auth_is_retained_for_redirect_on_host(self, httpbin):\n-        r = requests.get(httpbin('redirect/1'), auth=('user', 'pass'))\n-        h1 = r.history[0].request.headers['Authorization']\n-        h2 = r.request.headers['Authorization']\n+        r = requests.get(httpbin(\"redirect/1\"), auth=(\"user\", \"pass\"))\n+        h1 = r.history[0].request.headers[\"Authorization\"]\n+        h2 = r.request.headers[\"Authorization\"]\n \n         assert h1 == h2\n \n     def test_should_strip_auth_host_change(self):\n         s = requests.Session()\n-        assert s.should_strip_auth('http://example.com/foo', 'http://another.example.com/')\n+        assert s.should_strip_auth(\n+            \"http://example.com/foo\", \"http://another.example.com/\"\n+        )\n \n     def test_should_strip_auth_http_downgrade(self):\n         s = requests.Session()\n-        assert s.should_strip_auth('https://example.com/foo', 'http://example.com/bar')\n+        assert s.should_strip_auth(\"https://example.com/foo\", \"http://example.com/bar\")\n \n     def test_should_strip_auth_https_upgrade(self):\n         s = requests.Session()\n-        assert not s.should_strip_auth('http://example.com/foo', 'https://example.com/bar')\n-        assert not s.should_strip_auth('http://example.com:80/foo', 'https://example.com/bar')\n-        assert not s.should_strip_auth('http://example.com/foo', 'https://example.com:443/bar')\n+        assert not s.should_strip_auth(\n+            \"http://example.com/foo\", \"https://example.com/bar\"\n+        )\n+        assert not s.should_strip_auth(\n+            \"http://example.com:80/foo\", \"https://example.com/bar\"\n+        )\n+        assert not s.should_strip_auth(\n+            \"http://example.com/foo\", \"https://example.com:443/bar\"\n+        )\n         # Non-standard ports should trigger stripping\n-        assert s.should_strip_auth('http://example.com:8080/foo', 'https://example.com/bar')\n-        assert s.should_strip_auth('http://example.com/foo', 'https://example.com:8443/bar')\n+        assert s.should_strip_auth(\n+            \"http://example.com:8080/foo\", \"https://example.com/bar\"\n+        )\n+        assert s.should_strip_auth(\n+            \"http://example.com/foo\", \"https://example.com:8443/bar\"\n+        )\n \n     def test_should_strip_auth_port_change(self):\n         s = requests.Session()\n-        assert s.should_strip_auth('http://example.com:1234/foo', 'https://example.com:4321/bar')\n+        assert s.should_strip_auth(\n+            \"http://example.com:1234/foo\", \"https://example.com:4321/bar\"\n+        )\n \n     @pytest.mark.parametrize(\n-        'old_uri, new_uri', (\n-            ('https://example.com:443/foo', 'https://example.com/bar'),\n-            ('http://example.com:80/foo', 'http://example.com/bar'),\n-            ('https://example.com/foo', 'https://example.com:443/bar'),\n-            ('http://example.com/foo', 'http://example.com:80/bar')\n-        ))\n+        \"old_uri, new_uri\",\n+        (\n+            (\"https://example.com:443/foo\", \"https://example.com/bar\"),\n+            (\"http://example.com:80/foo\", \"http://example.com/bar\"),\n+            (\"https://example.com/foo\", \"https://example.com:443/bar\"),\n+            (\"http://example.com/foo\", \"http://example.com:80/bar\"),\n+        ),\n+    )\n     def test_should_strip_auth_default_port(self, old_uri, new_uri):\n         s = requests.Session()\n         assert not s.should_strip_auth(old_uri, new_uri)\n \n     def test_manual_redirect_with_partial_body_read(self, httpbin):\n         s = requests.Session()\n-        r1 = s.get(httpbin('redirect/2'), allow_redirects=False, stream=True)\n+        r1 = s.get(httpbin(\"redirect/2\"), allow_redirects=False, stream=True)\n         assert r1.is_redirect\n         rg = s.resolve_redirects(r1, r1.request, stream=True)\n \n@@ -1765,36 +1861,36 @@ class TestRequests:\n         assert not r3.is_redirect\n \n     def test_prepare_body_position_non_stream(self):\n-        data = b'the data'\n-        prep = requests.Request('GET', 'http://example.com', data=data).prepare()\n+        data = b\"the data\"\n+        prep = requests.Request(\"GET\", \"http://example.com\", data=data).prepare()\n         assert prep._body_position is None\n \n     def test_rewind_body(self):\n-        data = io.BytesIO(b'the data')\n-        prep = requests.Request('GET', 'http://example.com', data=data).prepare()\n+        data = io.BytesIO(b\"the data\")\n+        prep = requests.Request(\"GET\", \"http://example.com\", data=data).prepare()\n         assert prep._body_position == 0\n-        assert prep.body.read() == b'the data'\n+        assert prep.body.read() == b\"the data\"\n \n         # the data has all been read\n-        assert prep.body.read() == b''\n+        assert prep.body.read() == b\"\"\n \n         # rewind it back\n         requests.utils.rewind_body(prep)\n-        assert prep.body.read() == b'the data'\n+        assert prep.body.read() == b\"the data\"\n \n     def test_rewind_partially_read_body(self):\n-        data = io.BytesIO(b'the data')\n+        data = io.BytesIO(b\"the data\")\n         data.read(4)  # read some data\n-        prep = requests.Request('GET', 'http://example.com', data=data).prepare()\n+        prep = requests.Request(\"GET\", \"http://example.com\", data=data).prepare()\n         assert prep._body_position == 4\n-        assert prep.body.read() == b'data'\n+        assert prep.body.read() == b\"data\"\n \n         # the data has all been read\n-        assert prep.body.read() == b''\n+        assert prep.body.read() == b\"\"\n \n         # rewind it back\n         requests.utils.rewind_body(prep)\n-        assert prep.body.read() == b'data'\n+        assert prep.body.read() == b\"data\"\n \n     def test_rewind_body_no_seek(self):\n         class BadFileObj:\n@@ -1807,14 +1903,14 @@ class TestRequests:\n             def __iter__(self):\n                 return\n \n-        data = BadFileObj('the data')\n-        prep = requests.Request('GET', 'http://example.com', data=data).prepare()\n+        data = BadFileObj(\"the data\")\n+        prep = requests.Request(\"GET\", \"http://example.com\", data=data).prepare()\n         assert prep._body_position == 0\n \n         with pytest.raises(UnrewindableBodyError) as e:\n             requests.utils.rewind_body(prep)\n \n-        assert 'Unable to rewind request body' in str(e)\n+        assert \"Unable to rewind request body\" in str(e)\n \n     def test_rewind_body_failed_seek(self):\n         class BadFileObj:\n@@ -1830,14 +1926,14 @@ class TestRequests:\n             def __iter__(self):\n                 return\n \n-        data = BadFileObj('the data')\n-        prep = requests.Request('GET', 'http://example.com', data=data).prepare()\n+        data = BadFileObj(\"the data\")\n+        prep = requests.Request(\"GET\", \"http://example.com\", data=data).prepare()\n         assert prep._body_position == 0\n \n         with pytest.raises(UnrewindableBodyError) as e:\n             requests.utils.rewind_body(prep)\n \n-        assert 'error occurred when rewinding request body' in str(e)\n+        assert \"error occurred when rewinding request body\" in str(e)\n \n     def test_rewind_body_failed_tell(self):\n         class BadFileObj:\n@@ -1850,14 +1946,14 @@ class TestRequests:\n             def __iter__(self):\n                 return\n \n-        data = BadFileObj('the data')\n-        prep = requests.Request('GET', 'http://example.com', data=data).prepare()\n+        data = BadFileObj(\"the data\")\n+        prep = requests.Request(\"GET\", \"http://example.com\", data=data).prepare()\n         assert prep._body_position is not None\n \n         with pytest.raises(UnrewindableBodyError) as e:\n             requests.utils.rewind_body(prep)\n \n-        assert 'Unable to rewind request body' in str(e)\n+        assert \"Unable to rewind request body\" in str(e)\n \n     def _patch_adapter_gzipped_redirect(self, session, url):\n         adapter = session.get_adapter(url=url)\n@@ -1867,7 +1963,7 @@ class TestRequests:\n         def build_response(*args, **kwargs):\n             resp = org_build_response(*args, **kwargs)\n             if not self._patched_response:\n-                resp.raw.headers['content-encoding'] = 'gzip'\n+                resp.raw.headers[\"content-encoding\"] = \"gzip\"\n                 self._patched_response = True\n             return resp\n \n@@ -1875,22 +1971,28 @@ class TestRequests:\n \n     def test_redirect_with_wrong_gzipped_header(self, httpbin):\n         s = requests.Session()\n-        url = httpbin('redirect/1')\n+        url = httpbin(\"redirect/1\")\n         self._patch_adapter_gzipped_redirect(s, url)\n         s.get(url)\n \n     @pytest.mark.parametrize(\n-        'username, password, auth_str', (\n-            ('test', 'test', 'Basic dGVzdDp0ZXN0'),\n-            ('имя'.encode('utf-8'), 'пароль'.encode('utf-8'), 'Basic 0LjQvNGPOtC/0LDRgNC+0LvRjA=='),\n-        ))\n+        \"username, password, auth_str\",\n+        (\n+            (\"test\", \"test\", \"Basic dGVzdDp0ZXN0\"),\n+            (\n+                \"имя\".encode(),\n+                \"пароль\".encode(),\n+                \"Basic 0LjQvNGPOtC/0LDRgNC+0LvRjA==\",\n+            ),\n+        ),\n+    )\n     def test_basic_auth_str_is_always_native(self, username, password, auth_str):\n         s = _basic_auth_str(username, password)\n         assert isinstance(s, builtin_str)\n         assert s == auth_str\n \n     def test_requests_history_is_saved(self, httpbin):\n-        r = requests.get(httpbin('redirect/5'))\n+        r = requests.get(httpbin(\"redirect/5\"))\n         total = r.history[-1].history\n         i = 0\n         for item in r.history:\n@@ -1898,23 +2000,23 @@ class TestRequests:\n             i += 1\n \n     def test_json_param_post_content_type_works(self, httpbin):\n-        r = requests.post(\n-            httpbin('post'),\n-            json={'life': 42}\n-        )\n+        r = requests.post(httpbin(\"post\"), json={\"life\": 42})\n         assert r.status_code == 200\n-        assert 'application/json' in r.request.headers['Content-Type']\n-        assert {'life': 42} == r.json()['json']\n+        assert \"application/json\" in r.request.headers[\"Content-Type\"]\n+        assert {\"life\": 42} == r.json()[\"json\"]\n \n     def test_json_param_post_should_not_override_data_param(self, httpbin):\n-        r = requests.Request(method='POST', url=httpbin('post'),\n-                             data={'stuff': 'elixr'},\n-                             json={'music': 'flute'})\n+        r = requests.Request(\n+            method=\"POST\",\n+            url=httpbin(\"post\"),\n+            data={\"stuff\": \"elixr\"},\n+            json={\"music\": \"flute\"},\n+        )\n         prep = r.prepare()\n-        assert 'stuff=elixr' == prep.body\n+        assert \"stuff=elixr\" == prep.body\n \n     def test_response_iter_lines(self, httpbin):\n-        r = requests.get(httpbin('stream/4'), stream=True)\n+        r = requests.get(httpbin(\"stream/4\"), stream=True)\n         assert r.status_code == 200\n \n         it = r.iter_lines()\n@@ -1922,7 +2024,7 @@ class TestRequests:\n         assert len(list(it)) == 3\n \n     def test_response_context_manager(self, httpbin):\n-        with requests.get(httpbin('stream/4'), stream=True) as response:\n+        with requests.get(httpbin(\"stream/4\"), stream=True) as response:\n             assert isinstance(response, requests.Response)\n \n         assert response.raw.closed\n@@ -1930,7 +2032,7 @@ class TestRequests:\n     def test_unconsumed_session_response_closes_connection(self, httpbin):\n         s = requests.session()\n \n-        with contextlib.closing(s.get(httpbin('stream/4'), stream=True)) as response:\n+        with contextlib.closing(s.get(httpbin(\"stream/4\"), stream=True)) as response:\n             pass\n \n         assert response._content_consumed is False\n@@ -1939,7 +2041,7 @@ class TestRequests:\n     @pytest.mark.xfail\n     def test_response_iter_lines_reentrant(self, httpbin):\n         \"\"\"Response.iter_lines() is not reentrant safe\"\"\"\n-        r = requests.get(httpbin('stream/4'), stream=True)\n+        r = requests.get(httpbin(\"stream/4\"), stream=True)\n         assert r.status_code == 200\n \n         next(r.iter_lines())\n@@ -1947,27 +2049,27 @@ class TestRequests:\n \n     def test_session_close_proxy_clear(self, mocker):\n         proxies = {\n-          'one': mocker.Mock(),\n-          'two': mocker.Mock(),\n+            \"one\": mocker.Mock(),\n+            \"two\": mocker.Mock(),\n         }\n         session = requests.Session()\n-        mocker.patch.dict(session.adapters['http://'].proxy_manager, proxies)\n+        mocker.patch.dict(session.adapters[\"http://\"].proxy_manager, proxies)\n         session.close()\n-        proxies['one'].clear.assert_called_once_with()\n-        proxies['two'].clear.assert_called_once_with()\n+        proxies[\"one\"].clear.assert_called_once_with()\n+        proxies[\"two\"].clear.assert_called_once_with()\n \n     def test_proxy_auth(self):\n         adapter = HTTPAdapter()\n         headers = adapter.proxy_headers(\"http://user:pass@httpbin.org\")\n-        assert headers == {'Proxy-Authorization': 'Basic dXNlcjpwYXNz'}\n+        assert headers == {\"Proxy-Authorization\": \"Basic dXNlcjpwYXNz\"}\n \n     def test_proxy_auth_empty_pass(self):\n         adapter = HTTPAdapter()\n         headers = adapter.proxy_headers(\"http://user:@httpbin.org\")\n-        assert headers == {'Proxy-Authorization': 'Basic dXNlcjo='}\n+        assert headers == {\"Proxy-Authorization\": \"Basic dXNlcjo=\"}\n \n     def test_response_json_when_content_is_None(self, httpbin):\n-        r = requests.get(httpbin('/status/204'))\n+        r = requests.get(httpbin(\"/status/204\"))\n         # Make sure r.content is None\n         r.status_code = 0\n         r._content = False\n@@ -1982,7 +2084,7 @@ class TestRequests:\n         Should work when `release_conn` attr doesn't exist on `response.raw`.\n         \"\"\"\n         resp = requests.Response()\n-        resp.raw = StringIO.StringIO('test')\n+        resp.raw = StringIO.StringIO(\"test\")\n         assert not resp.raw.closed\n         resp.close()\n         assert resp.raw.closed\n@@ -1991,36 +2093,36 @@ class TestRequests:\n         \"\"\"Ensure that a byte stream with size 0 will not set both a Content-Length\n         and Transfer-Encoding header.\n         \"\"\"\n-        auth = ('user', 'pass')\n-        url = httpbin('post')\n-        file_obj = io.BytesIO(b'')\n-        r = requests.Request('POST', url, auth=auth, data=file_obj)\n+        auth = (\"user\", \"pass\")\n+        url = httpbin(\"post\")\n+        file_obj = io.BytesIO(b\"\")\n+        r = requests.Request(\"POST\", url, auth=auth, data=file_obj)\n         prepared_request = r.prepare()\n-        assert 'Transfer-Encoding' in prepared_request.headers\n-        assert 'Content-Length' not in prepared_request.headers\n+        assert \"Transfer-Encoding\" in prepared_request.headers\n+        assert \"Content-Length\" not in prepared_request.headers\n \n     def test_stream_with_auth_does_not_set_transfer_encoding_header(self, httpbin):\n         \"\"\"Ensure that a byte stream with size > 0 will not set both a Content-Length\n         and Transfer-Encoding header.\n         \"\"\"\n-        auth = ('user', 'pass')\n-        url = httpbin('post')\n-        file_obj = io.BytesIO(b'test data')\n-        r = requests.Request('POST', url, auth=auth, data=file_obj)\n+        auth = (\"user\", \"pass\")\n+        url = httpbin(\"post\")\n+        file_obj = io.BytesIO(b\"test data\")\n+        r = requests.Request(\"POST\", url, auth=auth, data=file_obj)\n         prepared_request = r.prepare()\n-        assert 'Transfer-Encoding' not in prepared_request.headers\n-        assert 'Content-Length' in prepared_request.headers\n+        assert \"Transfer-Encoding\" not in prepared_request.headers\n+        assert \"Content-Length\" in prepared_request.headers\n \n     def test_chunked_upload_does_not_set_content_length_header(self, httpbin):\n         \"\"\"Ensure that requests with a generator body stream using\n         Transfer-Encoding: chunked, not a Content-Length header.\n         \"\"\"\n-        data = (i for i in [b'a', b'b', b'c'])\n-        url = httpbin('post')\n-        r = requests.Request('POST', url, data=data)\n+        data = (i for i in [b\"a\", b\"b\", b\"c\"])\n+        url = httpbin(\"post\")\n+        r = requests.Request(\"POST\", url, data=data)\n         prepared_request = r.prepare()\n-        assert 'Transfer-Encoding' in prepared_request.headers\n-        assert 'Content-Length' not in prepared_request.headers\n+        assert \"Transfer-Encoding\" in prepared_request.headers\n+        assert \"Content-Length\" not in prepared_request.headers\n \n     def test_custom_redirect_mixin(self, httpbin):\n         \"\"\"Tests a custom mixin to overwrite ``get_redirect_target``.\n@@ -2034,12 +2136,13 @@ class TestRequests:\n             location = alternate url\n         3. the custom session catches the edge case and follows the redirect\n         \"\"\"\n-        url_final = httpbin('html')\n-        querystring_malformed = urlencode({'location': url_final})\n-        url_redirect_malformed = httpbin('response-headers?%s' % querystring_malformed)\n-        querystring_redirect = urlencode({'url': url_redirect_malformed})\n-        url_redirect = httpbin('redirect-to?%s' % querystring_redirect)\n-        urls_test = [url_redirect,\n+        url_final = httpbin(\"html\")\n+        querystring_malformed = urlencode({\"location\": url_final})\n+        url_redirect_malformed = httpbin(\"response-headers?%s\" % querystring_malformed)\n+        querystring_redirect = urlencode({\"url\": url_redirect_malformed})\n+        url_redirect = httpbin(\"redirect-to?%s\" % querystring_redirect)\n+        urls_test = [\n+            url_redirect,\n             url_redirect_malformed,\n             url_final,\n         ]\n@@ -2048,9 +2151,9 @@ class TestRequests:\n             def get_redirect_target(self, resp):\n                 # default behavior\n                 if resp.is_redirect:\n-                    return resp.headers['location']\n+                    return resp.headers[\"location\"]\n                 # edge case - check to see if 'location' is in headers anyways\n-                location = resp.headers.get('location')\n+                location = resp.headers.get(\"location\")\n                 if location and (location != resp.url):\n                     return location\n                 return None\n@@ -2067,144 +2170,153 @@ class TestRequests:\n \n \n class TestCaseInsensitiveDict:\n-\n     @pytest.mark.parametrize(\n-        'cid', (\n-            CaseInsensitiveDict({'Foo': 'foo', 'BAr': 'bar'}),\n-            CaseInsensitiveDict([('Foo', 'foo'), ('BAr', 'bar')]),\n-            CaseInsensitiveDict(FOO='foo', BAr='bar'),\n-        ))\n+        \"cid\",\n+        (\n+            CaseInsensitiveDict({\"Foo\": \"foo\", \"BAr\": \"bar\"}),\n+            CaseInsensitiveDict([(\"Foo\", \"foo\"), (\"BAr\", \"bar\")]),\n+            CaseInsensitiveDict(FOO=\"foo\", BAr=\"bar\"),\n+        ),\n+    )\n     def test_init(self, cid):\n         assert len(cid) == 2\n-        assert 'foo' in cid\n-        assert 'bar' in cid\n+        assert \"foo\" in cid\n+        assert \"bar\" in cid\n \n     def test_docstring_example(self):\n         cid = CaseInsensitiveDict()\n-        cid['Accept'] = 'application/json'\n-        assert cid['aCCEPT'] == 'application/json'\n-        assert list(cid) == ['Accept']\n+        cid[\"Accept\"] = \"application/json\"\n+        assert cid[\"aCCEPT\"] == \"application/json\"\n+        assert list(cid) == [\"Accept\"]\n \n     def test_len(self):\n-        cid = CaseInsensitiveDict({'a': 'a', 'b': 'b'})\n-        cid['A'] = 'a'\n+        cid = CaseInsensitiveDict({\"a\": \"a\", \"b\": \"b\"})\n+        cid[\"A\"] = \"a\"\n         assert len(cid) == 2\n \n     def test_getitem(self):\n-        cid = CaseInsensitiveDict({'Spam': 'blueval'})\n-        assert cid['spam'] == 'blueval'\n-        assert cid['SPAM'] == 'blueval'\n+        cid = CaseInsensitiveDict({\"Spam\": \"blueval\"})\n+        assert cid[\"spam\"] == \"blueval\"\n+        assert cid[\"SPAM\"] == \"blueval\"\n \n     def test_fixes_649(self):\n         \"\"\"__setitem__ should behave case-insensitively.\"\"\"\n         cid = CaseInsensitiveDict()\n-        cid['spam'] = 'oneval'\n-        cid['Spam'] = 'twoval'\n-        cid['sPAM'] = 'redval'\n-        cid['SPAM'] = 'blueval'\n-        assert cid['spam'] == 'blueval'\n-        assert cid['SPAM'] == 'blueval'\n-        assert list(cid.keys()) == ['SPAM']\n+        cid[\"spam\"] = \"oneval\"\n+        cid[\"Spam\"] = \"twoval\"\n+        cid[\"sPAM\"] = \"redval\"\n+        cid[\"SPAM\"] = \"blueval\"\n+        assert cid[\"spam\"] == \"blueval\"\n+        assert cid[\"SPAM\"] == \"blueval\"\n+        assert list(cid.keys()) == [\"SPAM\"]\n \n     def test_delitem(self):\n         cid = CaseInsensitiveDict()\n-        cid['Spam'] = 'someval'\n-        del cid['sPam']\n-        assert 'spam' not in cid\n+        cid[\"Spam\"] = \"someval\"\n+        del cid[\"sPam\"]\n+        assert \"spam\" not in cid\n         assert len(cid) == 0\n \n     def test_contains(self):\n         cid = CaseInsensitiveDict()\n-        cid['Spam'] = 'someval'\n-        assert 'Spam' in cid\n-        assert 'spam' in cid\n-        assert 'SPAM' in cid\n-        assert 'sPam' in cid\n-        assert 'notspam' not in cid\n+        cid[\"Spam\"] = \"someval\"\n+        assert \"Spam\" in cid\n+        assert \"spam\" in cid\n+        assert \"SPAM\" in cid\n+        assert \"sPam\" in cid\n+        assert \"notspam\" not in cid\n \n     def test_get(self):\n         cid = CaseInsensitiveDict()\n-        cid['spam'] = 'oneval'\n-        cid['SPAM'] = 'blueval'\n-        assert cid.get('spam') == 'blueval'\n-        assert cid.get('SPAM') == 'blueval'\n-        assert cid.get('sPam') == 'blueval'\n-        assert cid.get('notspam', 'default') == 'default'\n+        cid[\"spam\"] = \"oneval\"\n+        cid[\"SPAM\"] = \"blueval\"\n+        assert cid.get(\"spam\") == \"blueval\"\n+        assert cid.get(\"SPAM\") == \"blueval\"\n+        assert cid.get(\"sPam\") == \"blueval\"\n+        assert cid.get(\"notspam\", \"default\") == \"default\"\n \n     def test_update(self):\n         cid = CaseInsensitiveDict()\n-        cid['spam'] = 'blueval'\n-        cid.update({'sPam': 'notblueval'})\n-        assert cid['spam'] == 'notblueval'\n-        cid = CaseInsensitiveDict({'Foo': 'foo', 'BAr': 'bar'})\n-        cid.update({'fOO': 'anotherfoo', 'bAR': 'anotherbar'})\n+        cid[\"spam\"] = \"blueval\"\n+        cid.update({\"sPam\": \"notblueval\"})\n+        assert cid[\"spam\"] == \"notblueval\"\n+        cid = CaseInsensitiveDict({\"Foo\": \"foo\", \"BAr\": \"bar\"})\n+        cid.update({\"fOO\": \"anotherfoo\", \"bAR\": \"anotherbar\"})\n         assert len(cid) == 2\n-        assert cid['foo'] == 'anotherfoo'\n-        assert cid['bar'] == 'anotherbar'\n+        assert cid[\"foo\"] == \"anotherfoo\"\n+        assert cid[\"bar\"] == \"anotherbar\"\n \n     def test_update_retains_unchanged(self):\n-        cid = CaseInsensitiveDict({'foo': 'foo', 'bar': 'bar'})\n-        cid.update({'foo': 'newfoo'})\n-        assert cid['bar'] == 'bar'\n+        cid = CaseInsensitiveDict({\"foo\": \"foo\", \"bar\": \"bar\"})\n+        cid.update({\"foo\": \"newfoo\"})\n+        assert cid[\"bar\"] == \"bar\"\n \n     def test_iter(self):\n-        cid = CaseInsensitiveDict({'Spam': 'spam', 'Eggs': 'eggs'})\n-        keys = frozenset(['Spam', 'Eggs'])\n+        cid = CaseInsensitiveDict({\"Spam\": \"spam\", \"Eggs\": \"eggs\"})\n+        keys = frozenset([\"Spam\", \"Eggs\"])\n         assert frozenset(iter(cid)) == keys\n \n     def test_equality(self):\n-        cid = CaseInsensitiveDict({'SPAM': 'blueval', 'Eggs': 'redval'})\n-        othercid = CaseInsensitiveDict({'spam': 'blueval', 'eggs': 'redval'})\n+        cid = CaseInsensitiveDict({\"SPAM\": \"blueval\", \"Eggs\": \"redval\"})\n+        othercid = CaseInsensitiveDict({\"spam\": \"blueval\", \"eggs\": \"redval\"})\n         assert cid == othercid\n-        del othercid['spam']\n+        del othercid[\"spam\"]\n         assert cid != othercid\n-        assert cid == {'spam': 'blueval', 'eggs': 'redval'}\n+        assert cid == {\"spam\": \"blueval\", \"eggs\": \"redval\"}\n         assert cid != object()\n \n     def test_setdefault(self):\n-        cid = CaseInsensitiveDict({'Spam': 'blueval'})\n-        assert cid.setdefault('spam', 'notblueval') == 'blueval'\n-        assert cid.setdefault('notspam', 'notblueval') == 'notblueval'\n+        cid = CaseInsensitiveDict({\"Spam\": \"blueval\"})\n+        assert cid.setdefault(\"spam\", \"notblueval\") == \"blueval\"\n+        assert cid.setdefault(\"notspam\", \"notblueval\") == \"notblueval\"\n \n     def test_lower_items(self):\n-        cid = CaseInsensitiveDict({\n-            'Accept': 'application/json',\n-            'user-Agent': 'requests',\n-        })\n+        cid = CaseInsensitiveDict(\n+            {\n+                \"Accept\": \"application/json\",\n+                \"user-Agent\": \"requests\",\n+            }\n+        )\n         keyset = frozenset(lowerkey for lowerkey, v in cid.lower_items())\n-        lowerkeyset = frozenset(['accept', 'user-agent'])\n+        lowerkeyset = frozenset([\"accept\", \"user-agent\"])\n         assert keyset == lowerkeyset\n \n     def test_preserve_key_case(self):\n-        cid = CaseInsensitiveDict({\n-            'Accept': 'application/json',\n-            'user-Agent': 'requests',\n-        })\n-        keyset = frozenset(['Accept', 'user-Agent'])\n+        cid = CaseInsensitiveDict(\n+            {\n+                \"Accept\": \"application/json\",\n+                \"user-Agent\": \"requests\",\n+            }\n+        )\n+        keyset = frozenset([\"Accept\", \"user-Agent\"])\n         assert frozenset(i[0] for i in cid.items()) == keyset\n         assert frozenset(cid.keys()) == keyset\n         assert frozenset(cid) == keyset\n \n     def test_preserve_last_key_case(self):\n-        cid = CaseInsensitiveDict({\n-            'Accept': 'application/json',\n-            'user-Agent': 'requests',\n-        })\n-        cid.update({'ACCEPT': 'application/json'})\n-        cid['USER-AGENT'] = 'requests'\n-        keyset = frozenset(['ACCEPT', 'USER-AGENT'])\n+        cid = CaseInsensitiveDict(\n+            {\n+                \"Accept\": \"application/json\",\n+                \"user-Agent\": \"requests\",\n+            }\n+        )\n+        cid.update({\"ACCEPT\": \"application/json\"})\n+        cid[\"USER-AGENT\"] = \"requests\"\n+        keyset = frozenset([\"ACCEPT\", \"USER-AGENT\"])\n         assert frozenset(i[0] for i in cid.items()) == keyset\n         assert frozenset(cid.keys()) == keyset\n         assert frozenset(cid) == keyset\n \n     def test_copy(self):\n-        cid = CaseInsensitiveDict({\n-            'Accept': 'application/json',\n-            'user-Agent': 'requests',\n-        })\n+        cid = CaseInsensitiveDict(\n+            {\n+                \"Accept\": \"application/json\",\n+                \"user-Agent\": \"requests\",\n+            }\n+        )\n         cid_copy = cid.copy()\n         assert cid == cid_copy\n-        cid['changed'] = True\n+        cid[\"changed\"] = True\n         assert cid != cid_copy\n \n \n@@ -2215,19 +2327,21 @@ class TestMorselToCookieExpires:\n         \"\"\"Test case where we convert expires from string time.\"\"\"\n \n         morsel = Morsel()\n-        morsel['expires'] = 'Thu, 01-Jan-1970 00:00:01 GMT'\n+        morsel[\"expires\"] = \"Thu, 01-Jan-1970 00:00:01 GMT\"\n         cookie = morsel_to_cookie(morsel)\n         assert cookie.expires == 1\n \n     @pytest.mark.parametrize(\n-        'value, exception', (\n+        \"value, exception\",\n+        (\n             (100, TypeError),\n-            ('woops', ValueError),\n-        ))\n+            (\"woops\", ValueError),\n+        ),\n+    )\n     def test_expires_invalid_int(self, value, exception):\n         \"\"\"Test case where an invalid type is passed for expires.\"\"\"\n         morsel = Morsel()\n-        morsel['expires'] = value\n+        morsel[\"expires\"] = value\n         with pytest.raises(exception):\n             morsel_to_cookie(morsel)\n \n@@ -2235,7 +2349,7 @@ class TestMorselToCookieExpires:\n         \"\"\"Test case where expires is None.\"\"\"\n \n         morsel = Morsel()\n-        morsel['expires'] = None\n+        morsel[\"expires\"] = None\n         cookie = morsel_to_cookie(morsel)\n         assert cookie.expires is None\n \n@@ -2248,7 +2362,7 @@ class TestMorselToCookieMaxAge:\n         \"\"\"Test case where a valid max age in seconds is passed.\"\"\"\n \n         morsel = Morsel()\n-        morsel['max-age'] = 60\n+        morsel[\"max-age\"] = 60\n         cookie = morsel_to_cookie(morsel)\n         assert isinstance(cookie.expires, int)\n \n@@ -2256,34 +2370,31 @@ class TestMorselToCookieMaxAge:\n         \"\"\"Test case where a invalid max age is passed.\"\"\"\n \n         morsel = Morsel()\n-        morsel['max-age'] = 'woops'\n+        morsel[\"max-age\"] = \"woops\"\n         with pytest.raises(TypeError):\n             morsel_to_cookie(morsel)\n \n \n class TestTimeout:\n-\n     def test_stream_timeout(self, httpbin):\n         try:\n-            requests.get(httpbin('delay/10'), timeout=2.0)\n+            requests.get(httpbin(\"delay/10\"), timeout=2.0)\n         except requests.exceptions.Timeout as e:\n-            assert 'Read timed out' in e.args[0].args[0]\n+            assert \"Read timed out\" in e.args[0].args[0]\n \n     @pytest.mark.parametrize(\n-        'timeout, error_text', (\n-            ((3, 4, 5), '(connect, read)'),\n-            ('foo', 'must be an int, float or None'),\n-        ))\n+        \"timeout, error_text\",\n+        (\n+            ((3, 4, 5), \"(connect, read)\"),\n+            (\"foo\", \"must be an int, float or None\"),\n+        ),\n+    )\n     def test_invalid_timeout(self, httpbin, timeout, error_text):\n         with pytest.raises(ValueError) as e:\n-            requests.get(httpbin('get'), timeout=timeout)\n+            requests.get(httpbin(\"get\"), timeout=timeout)\n         assert error_text in str(e)\n \n-    @pytest.mark.parametrize(\n-        'timeout', (\n-            None,\n-            Urllib3Timeout(connect=None, read=None)\n-        ))\n+    @pytest.mark.parametrize(\"timeout\", (None, Urllib3Timeout(connect=None, read=None)))\n     def test_none_timeout(self, httpbin, timeout):\n         \"\"\"Check that you can set None as a valid timeout value.\n \n@@ -2293,53 +2404,47 @@ class TestTimeout:\n         Instead we verify that setting the timeout to None does not prevent the\n         request from succeeding.\n         \"\"\"\n-        r = requests.get(httpbin('get'), timeout=timeout)\n+        r = requests.get(httpbin(\"get\"), timeout=timeout)\n         assert r.status_code == 200\n \n     @pytest.mark.parametrize(\n-        'timeout', (\n-            (None, 0.1),\n-            Urllib3Timeout(connect=None, read=0.1)\n-        ))\n+        \"timeout\", ((None, 0.1), Urllib3Timeout(connect=None, read=0.1))\n+    )\n     def test_read_timeout(self, httpbin, timeout):\n         try:\n-            requests.get(httpbin('delay/10'), timeout=timeout)\n-            pytest.fail('The recv() request should time out.')\n+            requests.get(httpbin(\"delay/10\"), timeout=timeout)\n+            pytest.fail(\"The recv() request should time out.\")\n         except ReadTimeout:\n             pass\n \n     @pytest.mark.parametrize(\n-        'timeout', (\n-            (0.1, None),\n-            Urllib3Timeout(connect=0.1, read=None)\n-        ))\n+        \"timeout\", ((0.1, None), Urllib3Timeout(connect=0.1, read=None))\n+    )\n     def test_connect_timeout(self, timeout):\n         try:\n             requests.get(TARPIT, timeout=timeout)\n-            pytest.fail('The connect() request should time out.')\n+            pytest.fail(\"The connect() request should time out.\")\n         except ConnectTimeout as e:\n             assert isinstance(e, ConnectionError)\n             assert isinstance(e, Timeout)\n \n     @pytest.mark.parametrize(\n-        'timeout', (\n-            (0.1, 0.1),\n-            Urllib3Timeout(connect=0.1, read=0.1)\n-        ))\n+        \"timeout\", ((0.1, 0.1), Urllib3Timeout(connect=0.1, read=0.1))\n+    )\n     def test_total_timeout_connect(self, timeout):\n         try:\n             requests.get(TARPIT, timeout=timeout)\n-            pytest.fail('The connect() request should time out.')\n+            pytest.fail(\"The connect() request should time out.\")\n         except ConnectTimeout:\n             pass\n \n     def test_encoded_methods(self, httpbin):\n         \"\"\"See: https://github.com/psf/requests/issues/2316\"\"\"\n-        r = requests.request(b'GET', httpbin('get'))\n+        r = requests.request(b\"GET\", httpbin(\"get\"))\n         assert r.ok\n \n \n-SendCall = collections.namedtuple('SendCall', ('args', 'kwargs'))\n+SendCall = collections.namedtuple(\"SendCall\", (\"args\", \"kwargs\"))\n \n \n class RedirectSession(SessionRedirectMixin):\n@@ -2363,14 +2468,14 @@ class RedirectSession(SessionRedirectMixin):\n         except IndexError:\n             r.status_code = 200\n \n-        r.headers = CaseInsensitiveDict({'Location': '/'})\n+        r.headers = CaseInsensitiveDict({\"Location\": \"/\"})\n         r.raw = self._build_raw()\n         r.request = request\n         return r\n \n     def _build_raw(self):\n-        string = StringIO.StringIO('')\n-        setattr(string, 'release_conn', lambda *args: args)\n+        string = StringIO.StringIO(\"\")\n+        setattr(string, \"release_conn\", lambda *args: args)\n         return string\n \n \n@@ -2378,49 +2483,46 @@ def test_json_encodes_as_bytes():\n     # urllib3 expects bodies as bytes-like objects\n     body = {\"key\": \"value\"}\n     p = PreparedRequest()\n-    p.prepare(\n-        method='GET',\n-        url='https://www.example.com/',\n-        json=body\n-    )\n+    p.prepare(method=\"GET\", url=\"https://www.example.com/\", json=body)\n     assert isinstance(p.body, bytes)\n \n \n def test_requests_are_updated_each_time(httpbin):\n     session = RedirectSession([303, 307])\n-    prep = requests.Request('POST', httpbin('post')).prepare()\n+    prep = requests.Request(\"POST\", httpbin(\"post\")).prepare()\n     r0 = session.send(prep)\n-    assert r0.request.method == 'POST'\n+    assert r0.request.method == \"POST\"\n     assert session.calls[-1] == SendCall((r0.request,), {})\n     redirect_generator = session.resolve_redirects(r0, prep)\n     default_keyword_args = {\n-        'stream': False,\n-        'verify': True,\n-        'cert': None,\n-        'timeout': None,\n-        'allow_redirects': False,\n-        'proxies': {},\n+        \"stream\": False,\n+        \"verify\": True,\n@@ -1,26 +1,25 @@\n-# -*- coding: utf-8 -*-\n-\n import pytest\n \n from requests.structures import CaseInsensitiveDict, LookupDict\n \n \n class TestCaseInsensitiveDict:\n-\n     @pytest.fixture(autouse=True)\n     def setup(self):\n         \"\"\"CaseInsensitiveDict instance with \"Accept\" header.\"\"\"\n         self.case_insensitive_dict = CaseInsensitiveDict()\n-        self.case_insensitive_dict['Accept'] = 'application/json'\n+        self.case_insensitive_dict[\"Accept\"] = \"application/json\"\n \n     def test_list(self):\n-        assert list(self.case_insensitive_dict) == ['Accept']\n+        assert list(self.case_insensitive_dict) == [\"Accept\"]\n \n-    possible_keys = pytest.mark.parametrize('key', ('accept', 'ACCEPT', 'aCcEpT', 'Accept'))\n+    possible_keys = pytest.mark.parametrize(\n+        \"key\", (\"accept\", \"ACCEPT\", \"aCcEpT\", \"Accept\")\n+    )\n \n     @possible_keys\n     def test_getitem(self, key):\n-        assert self.case_insensitive_dict[key] == 'application/json'\n+        assert self.case_insensitive_dict[key] == \"application/json\"\n \n     @possible_keys\n     def test_delitem(self, key):\n@@ -28,7 +27,9 @@ class TestCaseInsensitiveDict:\n         assert key not in self.case_insensitive_dict\n \n     def test_lower_items(self):\n-        assert list(self.case_insensitive_dict.lower_items()) == [('accept', 'application/json')]\n+        assert list(self.case_insensitive_dict.lower_items()) == [\n+            (\"accept\", \"application/json\")\n+        ]\n \n     def test_repr(self):\n         assert repr(self.case_insensitive_dict) == \"{'Accept': 'application/json'}\"\n@@ -39,32 +40,33 @@ class TestCaseInsensitiveDict:\n         assert copy == self.case_insensitive_dict\n \n     @pytest.mark.parametrize(\n-        'other, result', (\n-            ({'AccePT': 'application/json'}, True),\n+        \"other, result\",\n+        (\n+            ({\"AccePT\": \"application/json\"}, True),\n             ({}, False),\n-            (None, False)\n-        )\n+            (None, False),\n+        ),\n     )\n     def test_instance_equality(self, other, result):\n         assert (self.case_insensitive_dict == other) is result\n \n \n class TestLookupDict:\n-\n     @pytest.fixture(autouse=True)\n     def setup(self):\n         \"\"\"LookupDict instance with \"bad_gateway\" attribute.\"\"\"\n-        self.lookup_dict = LookupDict('test')\n+        self.lookup_dict = LookupDict(\"test\")\n         self.lookup_dict.bad_gateway = 502\n \n     def test_repr(self):\n         assert repr(self.lookup_dict) == \"<lookup 'test'>\"\n \n     get_item_parameters = pytest.mark.parametrize(\n-        'key, value', (\n-            ('bad_gateway', 502),\n-            ('not_a_key', None)\n-        )\n+        \"key, value\",\n+        (\n+            (\"bad_gateway\", 502),\n+            (\"not_a_key\", None),\n+        ),\n     )\n \n     @get_item_parameters\n\n@@ -1,16 +1,14 @@\n-# -*- coding: utf-8 -*-\n-\n-import threading\n import socket\n+import threading\n import time\n \n import pytest\n-import requests\n from tests.testserver.server import Server\n \n+import requests\n+\n \n class TestTestServer:\n-\n     def test_basic(self):\n         \"\"\"messages are sent and received properly\"\"\"\n         question = b\"success?\"\n@@ -44,36 +42,37 @@ class TestTestServer:\n     def test_text_response(self):\n         \"\"\"the text_response_server sends the given text\"\"\"\n         server = Server.text_response_server(\n-            \"HTTP/1.1 200 OK\\r\\n\" +\n-            \"Content-Length: 6\\r\\n\" +\n-            \"\\r\\nroflol\"\n+            \"HTTP/1.1 200 OK\\r\\n\" \"Content-Length: 6\\r\\n\" \"\\r\\nroflol\"\n         )\n \n         with server as (host, port):\n-            r = requests.get('http://{}:{}'.format(host, port))\n+            r = requests.get(f\"http://{host}:{port}\")\n \n             assert r.status_code == 200\n-            assert r.text == u'roflol'\n-            assert r.headers['Content-Length'] == '6'\n+            assert r.text == \"roflol\"\n+            assert r.headers[\"Content-Length\"] == \"6\"\n \n     def test_basic_response(self):\n         \"\"\"the basic response server returns an empty http response\"\"\"\n         with Server.basic_response_server() as (host, port):\n-            r = requests.get('http://{}:{}'.format(host, port))\n+            r = requests.get(f\"http://{host}:{port}\")\n             assert r.status_code == 200\n-            assert r.text == u''\n-            assert r.headers['Content-Length'] == '0'\n+            assert r.text == \"\"\n+            assert r.headers[\"Content-Length\"] == \"0\"\n \n     def test_basic_waiting_server(self):\n         \"\"\"the server waits for the block_server event to be set before closing\"\"\"\n         block_server = threading.Event()\n \n-        with Server.basic_response_server(wait_to_close_event=block_server) as (host, port):\n+        with Server.basic_response_server(wait_to_close_event=block_server) as (\n+            host,\n+            port,\n+        ):\n             sock = socket.socket()\n             sock.connect((host, port))\n-            sock.sendall(b'send something')\n+            sock.sendall(b\"send something\")\n             time.sleep(2.5)\n-            sock.sendall(b'still alive')\n+            sock.sendall(b\"still alive\")\n             block_server.set()  # release server block\n \n     def test_multiple_requests(self):\n@@ -83,7 +82,7 @@ class TestTestServer:\n         server = Server.basic_response_server(requests_to_handle=requests_to_handle)\n \n         with server as (host, port):\n-            server_url = 'http://{}:{}'.format(host, port)\n+            server_url = f\"http://{host}:{port}\"\n             for _ in range(requests_to_handle):\n                 r = requests.get(server_url)\n                 assert r.status_code == 200\n@@ -97,8 +96,8 @@ class TestTestServer:\n         \"\"\"can check the requests content\"\"\"\n         # TODO: figure out why this sometimes fails when using pytest-xdist.\n         server = Server.basic_response_server(requests_to_handle=2)\n-        first_request = b'put your hands up in the air'\n-        second_request = b'put your hand down in the floor'\n+        first_request = b\"put your hands up in the air\"\n+        second_request = b\"put your hand down in the floor\"\n \n         with server as address:\n             sock1 = socket.socket()\n@@ -123,15 +122,15 @@ class TestTestServer:\n             sock = socket.socket()\n             sock.connect(address)\n             time.sleep(1.5)\n-            sock.sendall(b'hehehe, not received')\n+            sock.sendall(b\"hehehe, not received\")\n             sock.close()\n \n-        assert server.handler_results[0] == b''\n+        assert server.handler_results[0] == b\"\"\n \n     def test_request_recovery_with_bigger_timeout(self):\n         \"\"\"a biggest timeout can be specified\"\"\"\n         server = Server.basic_response_server(request_timeout=3)\n-        data = b'bananadine'\n+        data = b\"bananadine\"\n \n         with server as address:\n             sock = socket.socket()\n\n@@ -1,42 +1,61 @@\n-# -*- coding: utf-8 -*-\n-\n-import os\n import copy\n import filecmp\n-from io import BytesIO\n+import os\n import tarfile\n import zipfile\n from collections import deque\n+from io import BytesIO\n \n import pytest\n+\n from requests import compat\n+from requests._internal_utils import unicode_is_ascii\n from requests.cookies import RequestsCookieJar\n from requests.structures import CaseInsensitiveDict\n from requests.utils import (\n-    address_in_network, dotted_netmask, extract_zipped_paths,\n-    get_auth_from_url, _parse_content_type_header, get_encoding_from_headers,\n-    get_encodings_from_content, get_environ_proxies,\n-    guess_filename, guess_json_utf, is_ipv4_address,\n-    is_valid_cidr, iter_slices, parse_dict_header,\n-    parse_header_links, prepend_scheme_if_needed,\n-    requote_uri, select_proxy, should_bypass_proxies, super_len,\n-    to_key_val_list, to_native_string,\n-    unquote_header_value, unquote_unreserved,\n-    urldefragauth, add_dict_to_cookiejar, set_environ)\n-from requests._internal_utils import unicode_is_ascii\n+    _parse_content_type_header,\n+    add_dict_to_cookiejar,\n+    address_in_network,\n+    dotted_netmask,\n+    extract_zipped_paths,\n+    get_auth_from_url,\n+    get_encoding_from_headers,\n+    get_encodings_from_content,\n+    get_environ_proxies,\n+    guess_filename,\n+    guess_json_utf,\n+    is_ipv4_address,\n+    is_valid_cidr,\n+    iter_slices,\n+    parse_dict_header,\n+    parse_header_links,\n+    prepend_scheme_if_needed,\n+    requote_uri,\n+    select_proxy,\n+    set_environ,\n+    should_bypass_proxies,\n+    super_len,\n+    to_key_val_list,\n+    to_native_string,\n+    unquote_header_value,\n+    unquote_unreserved,\n+    urldefragauth,\n+)\n \n from .compat import StringIO, cStringIO\n \n \n class TestSuperLen:\n-\n     @pytest.mark.parametrize(\n-        'stream, value', (\n-            (StringIO.StringIO, 'Test'),\n-            (BytesIO, b'Test'),\n-            pytest.param(cStringIO, 'Test',\n-                         marks=pytest.mark.skipif('cStringIO is None')),\n-        ))\n+        \"stream, value\",\n+        (\n+            (StringIO.StringIO, \"Test\"),\n+            (BytesIO, b\"Test\"),\n+            pytest.param(\n+                cStringIO, \"Test\", marks=pytest.mark.skipif(\"cStringIO is None\")\n+            ),\n+        ),\n+    )\n     def test_io_streams(self, stream, value):\n         \"\"\"Ensures that we properly deal with different kinds of IO streams.\"\"\"\n         assert super_len(stream()) == 0\n@@ -45,13 +64,14 @@ class TestSuperLen:\n     def test_super_len_correctly_calculates_len_of_partially_read_file(self):\n         \"\"\"Ensure that we handle partially consumed file like objects.\"\"\"\n         s = StringIO.StringIO()\n-        s.write('foobarbogus')\n+        s.write(\"foobarbogus\")\n         assert super_len(s) == 0\n \n-    @pytest.mark.parametrize('error', [IOError, OSError])\n+    @pytest.mark.parametrize(\"error\", [IOError, OSError])\n     def test_super_len_handles_files_raising_weird_errors_in_tell(self, error):\n         \"\"\"If tell() raises errors, assume the cursor is at position zero.\"\"\"\n-        class BoomFile(object):\n+\n+        class BoomFile:\n             def __len__(self):\n                 return 5\n \n@@ -60,10 +80,11 @@ class TestSuperLen:\n \n         assert super_len(BoomFile()) == 0\n \n-    @pytest.mark.parametrize('error', [IOError, OSError])\n+    @pytest.mark.parametrize(\"error\", [IOError, OSError])\n     def test_super_len_tell_ioerror(self, error):\n         \"\"\"Ensure that if tell gives an IOError super_len doesn't fail\"\"\"\n-        class NoLenBoomFile(object):\n+\n+        class NoLenBoomFile:\n             def tell(self):\n                 raise error()\n \n@@ -73,30 +94,32 @@ class TestSuperLen:\n         assert super_len(NoLenBoomFile()) == 0\n \n     def test_string(self):\n-        assert super_len('Test') == 4\n+        assert super_len(\"Test\") == 4\n \n     @pytest.mark.parametrize(\n-        'mode, warnings_num', (\n-            ('r', 1),\n-            ('rb', 0),\n-        ))\n+        \"mode, warnings_num\",\n+        (\n+            (\"r\", 1),\n+            (\"rb\", 0),\n+        ),\n+    )\n     def test_file(self, tmpdir, mode, warnings_num, recwarn):\n-        file_obj = tmpdir.join('test.txt')\n-        file_obj.write('Test')\n+        file_obj = tmpdir.join(\"test.txt\")\n+        file_obj.write(\"Test\")\n         with file_obj.open(mode) as fd:\n             assert super_len(fd) == 4\n         assert len(recwarn) == warnings_num\n \n     def test_tarfile_member(self, tmpdir):\n-        file_obj = tmpdir.join('test.txt')\n-        file_obj.write('Test')\n+        file_obj = tmpdir.join(\"test.txt\")\n+        file_obj.write(\"Test\")\n \n-        tar_obj = str(tmpdir.join('test.tar'))\n-        with tarfile.open(tar_obj, 'w') as tar:\n-            tar.add(str(file_obj), arcname='test.txt')\n+        tar_obj = str(tmpdir.join(\"test.tar\"))\n+        with tarfile.open(tar_obj, \"w\") as tar:\n+            tar.add(str(file_obj), arcname=\"test.txt\")\n \n         with tarfile.open(tar_obj) as tar:\n-            member = tar.extractfile('test.txt')\n+            member = tar.extractfile(\"test.txt\")\n             assert super_len(member) == 4\n \n     def test_super_len_with__len__(self):\n@@ -105,20 +128,20 @@ class TestSuperLen:\n         assert len_foo == 4\n \n     def test_super_len_with_no__len__(self):\n-        class LenFile(object):\n+        class LenFile:\n             def __init__(self):\n                 self.len = 5\n \n         assert super_len(LenFile()) == 5\n \n     def test_super_len_with_tell(self):\n-        foo = StringIO.StringIO('12345')\n+        foo = StringIO.StringIO(\"12345\")\n         assert super_len(foo) == 5\n         foo.read(2)\n         assert super_len(foo) == 3\n \n     def test_super_len_with_fileno(self):\n-        with open(__file__, 'rb') as f:\n+        with open(__file__, \"rb\") as f:\n             length = super_len(f)\n             file_data = f.read()\n         assert length == len(file_data)\n@@ -129,37 +152,39 @@ class TestSuperLen:\n \n \n class TestToKeyValList:\n-\n     @pytest.mark.parametrize(\n-        'value, expected', (\n-            ([('key', 'val')], [('key', 'val')]),\n-            ((('key', 'val'), ), [('key', 'val')]),\n-            ({'key': 'val'}, [('key', 'val')]),\n-            (None, None)\n-        ))\n+        \"value, expected\",\n+        (\n+            ([(\"key\", \"val\")], [(\"key\", \"val\")]),\n+            (((\"key\", \"val\"),), [(\"key\", \"val\")]),\n+            ({\"key\": \"val\"}, [(\"key\", \"val\")]),\n+            (None, None),\n+        ),\n+    )\n     def test_valid(self, value, expected):\n         assert to_key_val_list(value) == expected\n \n     def test_invalid(self):\n         with pytest.raises(ValueError):\n-            to_key_val_list('string')\n+            to_key_val_list(\"string\")\n \n \n class TestUnquoteHeaderValue:\n-\n     @pytest.mark.parametrize(\n-        'value, expected', (\n+        \"value, expected\",\n+        (\n             (None, None),\n-            ('Test', 'Test'),\n-            ('\"Test\"', 'Test'),\n-            ('\"Test\\\\\\\\\"', 'Test\\\\'),\n-            ('\"\\\\\\\\Comp\\\\Res\"', '\\\\Comp\\\\Res'),\n-        ))\n+            (\"Test\", \"Test\"),\n+            ('\"Test\"', \"Test\"),\n+            ('\"Test\\\\\\\\\"', \"Test\\\\\"),\n+            ('\"\\\\\\\\Comp\\\\Res\"', \"\\\\Comp\\\\Res\"),\n+        ),\n+    )\n     def test_valid(self, value, expected):\n         assert unquote_header_value(value) == expected\n \n     def test_is_filename(self):\n-        assert unquote_header_value('\"\\\\\\\\Comp\\\\Res\"', True) == '\\\\\\\\Comp\\\\Res'\n+        assert unquote_header_value('\"\\\\\\\\Comp\\\\Res\"', True) == \"\\\\\\\\Comp\\\\Res\"\n \n \n class TestGetEnvironProxies:\n@@ -167,131 +192,143 @@ class TestGetEnvironProxies:\n     in no_proxy variable.\n     \"\"\"\n \n-    @pytest.fixture(autouse=True, params=['no_proxy', 'NO_PROXY'])\n+    @pytest.fixture(autouse=True, params=[\"no_proxy\", \"NO_PROXY\"])\n     def no_proxy(self, request, monkeypatch):\n-        monkeypatch.setenv(request.param, '192.168.0.0/24,127.0.0.1,localhost.localdomain,172.16.1.1')\n+        monkeypatch.setenv(\n+            request.param, \"192.168.0.0/24,127.0.0.1,localhost.localdomain,172.16.1.1\"\n+        )\n \n     @pytest.mark.parametrize(\n-        'url', (\n-            'http://192.168.0.1:5000/',\n-            'http://192.168.0.1/',\n-            'http://172.16.1.1/',\n-            'http://172.16.1.1:5000/',\n-            'http://localhost.localdomain:5000/v1.0/',\n-        ))\n+        \"url\",\n+        (\n+            \"http://192.168.0.1:5000/\",\n+            \"http://192.168.0.1/\",\n+            \"http://172.16.1.1/\",\n+            \"http://172.16.1.1:5000/\",\n+            \"http://localhost.localdomain:5000/v1.0/\",\n+        ),\n+    )\n     def test_bypass(self, url):\n         assert get_environ_proxies(url, no_proxy=None) == {}\n \n     @pytest.mark.parametrize(\n-        'url', (\n-            'http://192.168.1.1:5000/',\n-            'http://192.168.1.1/',\n-            'http://www.requests.com/',\n-        ))\n+        \"url\",\n+        (\n+            \"http://192.168.1.1:5000/\",\n+            \"http://192.168.1.1/\",\n+            \"http://www.requests.com/\",\n+        ),\n+    )\n     def test_not_bypass(self, url):\n         assert get_environ_proxies(url, no_proxy=None) != {}\n \n     @pytest.mark.parametrize(\n-        'url', (\n-            'http://192.168.1.1:5000/',\n-            'http://192.168.1.1/',\n-            'http://www.requests.com/',\n-        ))\n+        \"url\",\n+        (\n+            \"http://192.168.1.1:5000/\",\n+            \"http://192.168.1.1/\",\n+            \"http://www.requests.com/\",\n+        ),\n+    )\n     def test_bypass_no_proxy_keyword(self, url):\n-        no_proxy = '192.168.1.1,requests.com'\n+        no_proxy = \"192.168.1.1,requests.com\"\n         assert get_environ_proxies(url, no_proxy=no_proxy) == {}\n \n     @pytest.mark.parametrize(\n-        'url', (\n-            'http://192.168.0.1:5000/',\n-            'http://192.168.0.1/',\n-            'http://172.16.1.1/',\n-            'http://172.16.1.1:5000/',\n-            'http://localhost.localdomain:5000/v1.0/',\n-        ))\n+        \"url\",\n+        (\n+            \"http://192.168.0.1:5000/\",\n+            \"http://192.168.0.1/\",\n+            \"http://172.16.1.1/\",\n+            \"http://172.16.1.1:5000/\",\n+            \"http://localhost.localdomain:5000/v1.0/\",\n+        ),\n+    )\n     def test_not_bypass_no_proxy_keyword(self, url, monkeypatch):\n         # This is testing that the 'no_proxy' argument overrides the\n         # environment variable 'no_proxy'\n-        monkeypatch.setenv('http_proxy', 'http://proxy.example.com:3128/')\n-        no_proxy = '192.168.1.1,requests.com'\n+        monkeypatch.setenv(\"http_proxy\", \"http://proxy.example.com:3128/\")\n+        no_proxy = \"192.168.1.1,requests.com\"\n         assert get_environ_proxies(url, no_proxy=no_proxy) != {}\n \n \n class TestIsIPv4Address:\n-\n     def test_valid(self):\n-        assert is_ipv4_address('8.8.8.8')\n+        assert is_ipv4_address(\"8.8.8.8\")\n \n-    @pytest.mark.parametrize('value', ('8.8.8.8.8', 'localhost.localdomain'))\n+    @pytest.mark.parametrize(\"value\", (\"8.8.8.8.8\", \"localhost.localdomain\"))\n     def test_invalid(self, value):\n         assert not is_ipv4_address(value)\n \n \n class TestIsValidCIDR:\n-\n     def test_valid(self):\n-        assert is_valid_cidr('192.168.1.0/24')\n+        assert is_valid_cidr(\"192.168.1.0/24\")\n \n     @pytest.mark.parametrize(\n-        'value', (\n-            '8.8.8.8',\n-            '192.168.1.0/a',\n-            '192.168.1.0/128',\n-            '192.168.1.0/-1',\n-            '192.168.1.999/24',\n-        ))\n+        \"value\",\n+        (\n+            \"8.8.8.8\",\n+            \"192.168.1.0/a\",\n+            \"192.168.1.0/128\",\n+            \"192.168.1.0/-1\",\n+            \"192.168.1.999/24\",\n+        ),\n+    )\n     def test_invalid(self, value):\n         assert not is_valid_cidr(value)\n \n \n class TestAddressInNetwork:\n-\n     def test_valid(self):\n-        assert address_in_network('192.168.1.1', '192.168.1.0/24')\n+        assert address_in_network(\"192.168.1.1\", \"192.168.1.0/24\")\n \n     def test_invalid(self):\n-        assert not address_in_network('172.16.0.1', '192.168.1.0/24')\n+        assert not address_in_network(\"172.16.0.1\", \"192.168.1.0/24\")\n \n \n class TestGuessFilename:\n-\n     @pytest.mark.parametrize(\n-        'value', (1, type('Fake', (object,), {'name': 1})()),\n+        \"value\",\n+        (1, type(\"Fake\", (object,), {\"name\": 1})()),\n     )\n     def test_guess_filename_invalid(self, value):\n         assert guess_filename(value) is None\n \n     @pytest.mark.parametrize(\n-        'value, expected_type', (\n-            (b'value', compat.bytes),\n-            (b'value'.decode('utf-8'), compat.str)\n-        ))\n+        \"value, expected_type\",\n+        (\n+            (b\"value\", compat.bytes),\n+            (b\"value\".decode(\"utf-8\"), compat.str),\n+        ),\n+    )\n     def test_guess_filename_valid(self, value, expected_type):\n-        obj = type('Fake', (object,), {'name': value})()\n+        obj = type(\"Fake\", (object,), {\"name\": value})()\n         result = guess_filename(obj)\n         assert result == value\n         assert isinstance(result, expected_type)\n \n \n class TestExtractZippedPaths:\n-\n     @pytest.mark.parametrize(\n-        'path', (\n-            '/',\n+        \"path\",\n+        (\n+            \"/\",\n             __file__,\n             pytest.__file__,\n-            '/etc/invalid/location',\n-        ))\n+            \"/etc/invalid/location\",\n+        ),\n+    )\n     def test_unzipped_paths_unchanged(self, path):\n         assert path == extract_zipped_paths(path)\n \n     def test_zipped_paths_extracted(self, tmpdir):\n-        zipped_py = tmpdir.join('test.zip')\n-        with zipfile.ZipFile(zipped_py.strpath, 'w') as f:\n+        zipped_py = tmpdir.join(\"test.zip\")\n+        with zipfile.ZipFile(zipped_py.strpath, \"w\") as f:\n             f.write(__file__)\n \n         _, name = os.path.splitdrive(__file__)\n-        zipped_path = os.path.join(zipped_py.strpath, name.lstrip(r'\\/'))\n+        zipped_path = os.path.join(zipped_py.strpath, name.lstrip(r\"\\/\"))\n         extracted_path = extract_zipped_paths(zipped_path)\n \n         assert extracted_path != zipped_path\n@@ -304,13 +341,13 @@ class TestExtractZippedPaths:\n \n \n class TestContentEncodingDetection:\n-\n     def test_none(self):\n-        encodings = get_encodings_from_content('')\n+        encodings = get_encodings_from_content(\"\")\n         assert not len(encodings)\n \n     @pytest.mark.parametrize(\n-        'content', (\n+        \"content\",\n+        (\n             # HTML5 meta charset attribute\n             '<meta charset=\"UTF-8\">',\n             # HTML4 pragma directive\n@@ -319,246 +356,283 @@ class TestContentEncodingDetection:\n             '<meta http-equiv=\"Content-type\" content=\"text/html;charset=UTF-8\" />',\n             # XHTML 1.x served as XML\n             '<?xml version=\"1.0\" encoding=\"UTF-8\"?>',\n-        ))\n+        ),\n+    )\n     def test_pragmas(self, content):\n         encodings = get_encodings_from_content(content)\n         assert len(encodings) == 1\n-        assert encodings[0] == 'UTF-8'\n+        assert encodings[0] == \"UTF-8\"\n \n     def test_precedence(self):\n-        content = '''\n+        content = \"\"\"\n         <?xml version=\"1.0\" encoding=\"XML\"?>\n         <meta charset=\"HTML5\">\n         <meta http-equiv=\"Content-type\" content=\"text/html;charset=HTML4\" />\n-        '''.strip()\n-        assert get_encodings_from_content(content) == ['HTML5', 'HTML4', 'XML']\n+        \"\"\".strip()\n+        assert get_encodings_from_content(content) == [\"HTML5\", \"HTML4\", \"XML\"]\n \n \n class TestGuessJSONUTF:\n-\n     @pytest.mark.parametrize(\n-        'encoding', (\n-            'utf-32', 'utf-8-sig', 'utf-16', 'utf-8', 'utf-16-be', 'utf-16-le',\n-            'utf-32-be', 'utf-32-le'\n-        ))\n+        \"encoding\",\n+        (\n+            \"utf-32\",\n+            \"utf-8-sig\",\n+            \"utf-16\",\n+            \"utf-8\",\n+            \"utf-16-be\",\n+            \"utf-16-le\",\n+            \"utf-32-be\",\n+            \"utf-32-le\",\n+        ),\n+    )\n     def test_encoded(self, encoding):\n-        data = '{}'.encode(encoding)\n+        data = \"{}\".encode(encoding)\n         assert guess_json_utf(data) == encoding\n \n     def test_bad_utf_like_encoding(self):\n-        assert guess_json_utf(b'\\x00\\x00\\x00\\x00') is None\n+        assert guess_json_utf(b\"\\x00\\x00\\x00\\x00\") is None\n \n     @pytest.mark.parametrize(\n-        ('encoding', 'expected'), (\n-            ('utf-16-be', 'utf-16'),\n-            ('utf-16-le', 'utf-16'),\n-            ('utf-32-be', 'utf-32'),\n-            ('utf-32-le', 'utf-32')\n-        ))\n+        (\"encoding\", \"expected\"),\n+        (\n+            (\"utf-16-be\", \"utf-16\"),\n+            (\"utf-16-le\", \"utf-16\"),\n+            (\"utf-32-be\", \"utf-32\"),\n+            (\"utf-32-le\", \"utf-32\"),\n+        ),\n+    )\n     def test_guess_by_bom(self, encoding, expected):\n-        data = u'\\ufeff{}'.encode(encoding)\n+        data = \"\\ufeff{}\".encode(encoding)\n         assert guess_json_utf(data) == expected\n \n \n USER = PASSWORD = \"%!*'();:@&=+$,/?#[] \"\n-ENCODED_USER = compat.quote(USER, '')\n-ENCODED_PASSWORD = compat.quote(PASSWORD, '')\n+ENCODED_USER = compat.quote(USER, \"\")\n+ENCODED_PASSWORD = compat.quote(PASSWORD, \"\")\n \n \n @pytest.mark.parametrize(\n-    'url, auth', (\n+    \"url, auth\",\n     (\n-            'http://' + ENCODED_USER + ':' + ENCODED_PASSWORD + '@' +\n-            'request.com/url.html#test',\n-            (USER, PASSWORD)\n+        (\n+            f\"http://{ENCODED_USER}:{ENCODED_PASSWORD}@request.com/url.html#test\",\n+            (USER, PASSWORD),\n+        ),\n+        (\"http://user:pass@complex.url.com/path?query=yes\", (\"user\", \"pass\")),\n+        (\n+            \"http://user:pass%20pass@complex.url.com/path?query=yes\",\n+            (\"user\", \"pass pass\"),\n+        ),\n+        (\"http://user:pass pass@complex.url.com/path?query=yes\", (\"user\", \"pass pass\")),\n+        (\n+            \"http://user%25user:pass@complex.url.com/path?query=yes\",\n+            (\"user%user\", \"pass\"),\n         ),\n         (\n-            'http://user:pass@complex.url.com/path?query=yes',\n-            ('user', 'pass')\n+            \"http://user:pass%23pass@complex.url.com/path?query=yes\",\n+            (\"user\", \"pass#pass\"),\n         ),\n-        (\n-            'http://user:pass%20pass@complex.url.com/path?query=yes',\n-            ('user', 'pass pass')\n+        (\"http://complex.url.com/path?query=yes\", (\"\", \"\")),\n     ),\n-        (\n-            'http://user:pass pass@complex.url.com/path?query=yes',\n-            ('user', 'pass pass')\n-        ),\n-        (\n-            'http://user%25user:pass@complex.url.com/path?query=yes',\n-            ('user%user', 'pass')\n-        ),\n-        (\n-            'http://user:pass%23pass@complex.url.com/path?query=yes',\n-            ('user', 'pass#pass')\n-        ),\n-        (\n-            'http://complex.url.com/path?query=yes',\n-            ('', '')\n-        ),\n-    ))\n+)\n def test_get_auth_from_url(url, auth):\n     assert get_auth_from_url(url) == auth\n \n \n @pytest.mark.parametrize(\n-    'uri, expected', (\n+    \"uri, expected\",\n+    (\n         (\n             # Ensure requoting doesn't break expectations\n-            'http://example.com/fiz?buz=%25ppicture',\n-            'http://example.com/fiz?buz=%25ppicture',\n+            \"http://example.com/fiz?buz=%25ppicture\",\n+            \"http://example.com/fiz?buz=%25ppicture\",\n         ),\n         (\n             # Ensure we handle unquoted percent signs in redirects\n-            'http://example.com/fiz?buz=%ppicture',\n-            'http://example.com/fiz?buz=%25ppicture',\n+            \"http://example.com/fiz?buz=%ppicture\",\n+            \"http://example.com/fiz?buz=%25ppicture\",\n         ),\n-    ))\n+    ),\n+)\n def test_requote_uri_with_unquoted_percents(uri, expected):\n     \"\"\"See: https://github.com/psf/requests/issues/2356\"\"\"\n     assert requote_uri(uri) == expected\n \n \n @pytest.mark.parametrize(\n-    'uri, expected', (\n+    \"uri, expected\",\n+    (\n         (\n             # Illegal bytes\n-            'http://example.com/?a=%--',\n-            'http://example.com/?a=%--',\n+            \"http://example.com/?a=%--\",\n+            \"http://example.com/?a=%--\",\n         ),\n         (\n             # Reserved characters\n-            'http://example.com/?a=%300',\n-            'http://example.com/?a=00',\n+            \"http://example.com/?a=%300\",\n+            \"http://example.com/?a=00\",\n+        ),\n+    ),\n )\n-    ))\n def test_unquote_unreserved(uri, expected):\n     assert unquote_unreserved(uri) == expected\n \n \n @pytest.mark.parametrize(\n-    'mask, expected', (\n-        (8, '255.0.0.0'),\n-        (24, '255.255.255.0'),\n-        (25, '255.255.255.128'),\n-    ))\n+    \"mask, expected\",\n+    (\n+        (8, \"255.0.0.0\"),\n+        (24, \"255.255.255.0\"),\n+        (25, \"255.255.255.128\"),\n+    ),\n+)\n def test_dotted_netmask(mask, expected):\n     assert dotted_netmask(mask) == expected\n \n \n-http_proxies = {'http': 'http://http.proxy',\n-                'http://some.host': 'http://some.host.proxy'}\n-all_proxies = {'all': 'socks5://http.proxy',\n-               'all://some.host': 'socks5://some.host.proxy'}\n-mixed_proxies = {'http': 'http://http.proxy',\n-                 'http://some.host': 'http://some.host.proxy',\n-                 'all': 'socks5://http.proxy'}\n+http_proxies = {\n+    \"http\": \"http://http.proxy\",\n+    \"http://some.host\": \"http://some.host.proxy\",\n+}\n+all_proxies = {\n+    \"all\": \"socks5://http.proxy\",\n+    \"all://some.host\": \"socks5://some.host.proxy\",\n+}\n+mixed_proxies = {\n+    \"http\": \"http://http.proxy\",\n+    \"http://some.host\": \"http://some.host.proxy\",\n+    \"all\": \"socks5://http.proxy\",\n+}\n+\n+\n @pytest.mark.parametrize(\n-    'url, expected, proxies', (\n-        ('hTTp://u:p@Some.Host/path', 'http://some.host.proxy', http_proxies),\n-        ('hTTp://u:p@Other.Host/path', 'http://http.proxy', http_proxies),\n-        ('hTTp:///path', 'http://http.proxy', http_proxies),\n-        ('hTTps://Other.Host', None, http_proxies),\n-        ('file:///etc/motd', None, http_proxies),\n-\n-        ('hTTp://u:p@Some.Host/path', 'socks5://some.host.proxy', all_proxies),\n-        ('hTTp://u:p@Other.Host/path', 'socks5://http.proxy', all_proxies),\n-        ('hTTp:///path', 'socks5://http.proxy', all_proxies),\n-        ('hTTps://Other.Host', 'socks5://http.proxy', all_proxies),\n-\n-        ('http://u:p@other.host/path', 'http://http.proxy', mixed_proxies),\n-        ('http://u:p@some.host/path', 'http://some.host.proxy', mixed_proxies),\n-        ('https://u:p@other.host/path', 'socks5://http.proxy', mixed_proxies),\n-        ('https://u:p@some.host/path', 'socks5://http.proxy', mixed_proxies),\n-        ('https://', 'socks5://http.proxy', mixed_proxies),\n+    \"url, expected, proxies\",\n+    (\n+        (\"hTTp://u:p@Some.Host/path\", \"http://some.host.proxy\", http_proxies),\n+        (\"hTTp://u:p@Other.Host/path\", \"http://http.proxy\", http_proxies),\n+        (\"hTTp:///path\", \"http://http.proxy\", http_proxies),\n+        (\"hTTps://Other.Host\", None, http_proxies),\n+        (\"file:///etc/motd\", None, http_proxies),\n+        (\"hTTp://u:p@Some.Host/path\", \"socks5://some.host.proxy\", all_proxies),\n+        (\"hTTp://u:p@Other.Host/path\", \"socks5://http.proxy\", all_proxies),\n+        (\"hTTp:///path\", \"socks5://http.proxy\", all_proxies),\n+        (\"hTTps://Other.Host\", \"socks5://http.proxy\", all_proxies),\n+        (\"http://u:p@other.host/path\", \"http://http.proxy\", mixed_proxies),\n+        (\"http://u:p@some.host/path\", \"http://some.host.proxy\", mixed_proxies),\n+        (\"https://u:p@other.host/path\", \"socks5://http.proxy\", mixed_proxies),\n+        (\"https://u:p@some.host/path\", \"socks5://http.proxy\", mixed_proxies),\n+        (\"https://\", \"socks5://http.proxy\", mixed_proxies),\n         # XXX: unsure whether this is reasonable behavior\n-        ('file:///etc/motd', 'socks5://http.proxy', all_proxies),\n-    ))\n+        (\"file:///etc/motd\", \"socks5://http.proxy\", all_proxies),\n+    ),\n+)\n def test_select_proxies(url, expected, proxies):\n     \"\"\"Make sure we can select per-host proxies correctly.\"\"\"\n     assert select_proxy(url, proxies) == expected\n \n \n @pytest.mark.parametrize(\n-    'value, expected', (\n-        ('foo=\"is a fish\", bar=\"as well\"', {'foo': 'is a fish', 'bar': 'as well'}),\n-        ('key_without_value', {'key_without_value': None})\n-    ))\n+    \"value, expected\",\n+    (\n+        ('foo=\"is a fish\", bar=\"as well\"', {\"foo\": \"is a fish\", \"bar\": \"as well\"}),\n+        (\"key_without_value\", {\"key_without_value\": None}),\n+    ),\n+)\n def test_parse_dict_header(value, expected):\n     assert parse_dict_header(value) == expected\n \n \n @pytest.mark.parametrize(\n-    'value, expected', (\n+    \"value, expected\",\n     (\n-            'application/xml',\n-            ('application/xml', {})\n+        (\"application/xml\", (\"application/xml\", {})),\n+        (\n+            \"application/json ; charset=utf-8\",\n+            (\"application/json\", {\"charset\": \"utf-8\"}),\n         ),\n         (\n-            'application/json ; charset=utf-8',\n-            ('application/json', {'charset': 'utf-8'})\n+            \"application/json ; Charset=utf-8\",\n+            (\"application/json\", {\"charset\": \"utf-8\"}),\n         ),\n+        (\"text/plain\", (\"text/plain\", {})),\n         (\n-            'application/json ; Charset=utf-8',\n-            ('application/json', {'charset': 'utf-8'})\n+            \"multipart/form-data; boundary = something ; boundary2='something_else' ; no_equals \",\n+            (\n+                \"multipart/form-data\",\n+                {\n+                    \"boundary\": \"something\",\n+                    \"boundary2\": \"something_else\",\n+                    \"no_equals\": True,\n+                },\n             ),\n-        (\n-            'text/plain',\n-            ('text/plain', {})\n-        ),\n-        (\n-            'multipart/form-data; boundary = something ; boundary2=\\'something_else\\' ; no_equals ',\n-            ('multipart/form-data', {'boundary': 'something', 'boundary2': 'something_else', 'no_equals': True})\n         ),\n         (\n             'multipart/form-data; boundary = something ; boundary2=\"something_else\" ; no_equals ',\n-                ('multipart/form-data', {'boundary': 'something', 'boundary2': 'something_else', 'no_equals': True})\n+            (\n+                \"multipart/form-data\",\n+                {\n+                    \"boundary\": \"something\",\n+                    \"boundary2\": \"something_else\",\n+                    \"no_equals\": True,\n+                },\n+            ),\n         ),\n         (\n-            'multipart/form-data; boundary = something ; \\'boundary2=something_else\\' ; no_equals ',\n-            ('multipart/form-data', {'boundary': 'something', 'boundary2': 'something_else', 'no_equals': True})\n+            \"multipart/form-data; boundary = something ; 'boundary2=something_else' ; no_equals \",\n+            (\n+                \"multipart/form-data\",\n+                {\n+                    \"boundary\": \"something\",\n+                    \"boundary2\": \"something_else\",\n+                    \"no_equals\": True,\n+                },\n+            ),\n         ),\n         (\n             'multipart/form-data; boundary = something ; \"boundary2=something_else\" ; no_equals ',\n-            ('multipart/form-data', {'boundary': 'something', 'boundary2': 'something_else', 'no_equals': True})\n-        ),\n             (\n-            'application/json ; ; ',\n-            ('application/json', {})\n+                \"multipart/form-data\",\n+                {\n+                    \"boundary\": \"something\",\n+                    \"boundary2\": \"something_else\",\n+                    \"no_equals\": True,\n+                },\n+            ),\n+        ),\n+        (\"application/json ; ; \", (\"application/json\", {})),\n+    ),\n )\n-    ))\n def test__parse_content_type_header(value, expected):\n     assert _parse_content_type_header(value) == expected\n \n \n @pytest.mark.parametrize(\n-    'value, expected', (\n+    \"value, expected\",\n     (\n-            CaseInsensitiveDict(),\n-            None\n-        ),\n+        (CaseInsensitiveDict(), None),\n         (\n-            CaseInsensitiveDict({'content-type': 'application/json; charset=utf-8'}),\n-            'utf-8'\n+            CaseInsensitiveDict({\"content-type\": \"application/json; charset=utf-8\"}),\n+            \"utf-8\",\n         ),\n-        (\n-            CaseInsensitiveDict({'content-type': 'text/plain'}),\n-            'ISO-8859-1'\n+        (CaseInsensitiveDict({\"content-type\": \"text/plain\"}), \"ISO-8859-1\"),\n     ),\n-    ))\n+)\n def test_get_encoding_from_headers(value, expected):\n     assert get_encoding_from_headers(value) == expected\n \n \n @pytest.mark.parametrize(\n-    'value, length', (\n-        ('', 0),\n-        ('T', 1),\n-        ('Test', 4),\n-        ('Cont', 0),\n-        ('Other', -5),\n-        ('Content', None),\n-    ))\n+    \"value, length\",\n+    (\n+        (\"\", 0),\n+        (\"T\", 1),\n+        (\"Test\", 4),\n+        (\"Cont\", 0),\n+        (\"Other\", -5),\n+        (\"Content\", None),\n+    ),\n+)\n def test_iter_slices(value, length):\n     if length is None or (length <= 0 and len(value) > 0):\n         # Reads all content at once\n@@ -568,187 +642,197 @@ def test_iter_slices(value, length):\n \n \n @pytest.mark.parametrize(\n-    'value, expected', (\n+    \"value, expected\",\n+    (\n         (\n             '<http:/.../front.jpeg>; rel=front; type=\"image/jpeg\"',\n-            [{'url': 'http:/.../front.jpeg', 'rel': 'front', 'type': 'image/jpeg'}]\n-        ),\n-        (\n-            '<http:/.../front.jpeg>',\n-            [{'url': 'http:/.../front.jpeg'}]\n-        ),\n-        (\n-            '<http:/.../front.jpeg>;',\n-            [{'url': 'http:/.../front.jpeg'}]\n+            [{\"url\": \"http:/.../front.jpeg\", \"rel\": \"front\", \"type\": \"image/jpeg\"}],\n         ),\n+        (\"<http:/.../front.jpeg>\", [{\"url\": \"http:/.../front.jpeg\"}]),\n+        (\"<http:/.../front.jpeg>;\", [{\"url\": \"http:/.../front.jpeg\"}]),\n         (\n             '<http:/.../front.jpeg>; type=\"image/jpeg\",<http://.../back.jpeg>;',\n             [\n-                {'url': 'http:/.../front.jpeg', 'type': 'image/jpeg'},\n-                {'url': 'http://.../back.jpeg'}\n-            ]\n+                {\"url\": \"http:/.../front.jpeg\", \"type\": \"image/jpeg\"},\n+                {\"url\": \"http://.../back.jpeg\"},\n+            ],\n         ),\n-        (\n-            '',\n-            []\n+        (\"\", []),\n     ),\n-    ))\n+)\n def test_parse_header_links(value, expected):\n     assert parse_header_links(value) == expected\n \n \n @pytest.mark.parametrize(\n-    'value, expected', (\n-        ('example.com/path', 'http://example.com/path'),\n-        ('//example.com/path', 'http://example.com/path'),\n-        ('example.com:80', 'http://example.com:80'),\n+    \"value, expected\",\n     (\n-            'http://user:pass@example.com/path?query',\n-            'http://user:pass@example.com/path?query'\n+        (\"example.com/path\", \"http://example.com/path\"),\n+        (\"//example.com/path\", \"http://example.com/path\"),\n+        (\"example.com:80\", \"http://example.com:80\"),\n+        (\n+            \"http://user:pass@example.com/path?query\",\n+            \"http://user:pass@example.com/path?query\",\n+        ),\n+        (\"http://user@example.com/path?query\", \"http://user@example.com/path?query\"),\n     ),\n-        (\n-            'http://user@example.com/path?query',\n-            'http://user@example.com/path?query'\n )\n-    ))\n def test_prepend_scheme_if_needed(value, expected):\n-    assert prepend_scheme_if_needed(value, 'http') == expected\n+    assert prepend_scheme_if_needed(value, \"http\") == expected\n \n \n @pytest.mark.parametrize(\n-    'value, expected', (\n-        ('T', 'T'),\n-        (b'T', 'T'),\n-        (u'T', 'T'),\n-    ))\n+    \"value, expected\",\n+    (\n+        (\"T\", \"T\"),\n+        (b\"T\", \"T\"),\n+        (\"T\", \"T\"),\n+    ),\n+)\n def test_to_native_string(value, expected):\n     assert to_native_string(value) == expected\n \n \n @pytest.mark.parametrize(\n-    'url, expected', (\n-        ('http://u:p@example.com/path?a=1#test', 'http://example.com/path?a=1'),\n-        ('http://example.com/path', 'http://example.com/path'),\n-        ('//u:p@example.com/path', '//example.com/path'),\n-        ('//example.com/path', '//example.com/path'),\n-        ('example.com/path', '//example.com/path'),\n-        ('scheme:u:p@example.com/path', 'scheme://example.com/path'),\n-    ))\n+    \"url, expected\",\n+    (\n+        (\"http://u:p@example.com/path?a=1#test\", \"http://example.com/path?a=1\"),\n+        (\"http://example.com/path\", \"http://example.com/path\"),\n+        (\"//u:p@example.com/path\", \"//example.com/path\"),\n+        (\"//example.com/path\", \"//example.com/path\"),\n+        (\"example.com/path\", \"//example.com/path\"),\n+        (\"scheme:u:p@example.com/path\", \"scheme://example.com/path\"),\n+    ),\n+)\n def test_urldefragauth(url, expected):\n     assert urldefragauth(url) == expected\n \n \n @pytest.mark.parametrize(\n-    'url, expected', (\n-            ('http://192.168.0.1:5000/', True),\n-            ('http://192.168.0.1/', True),\n-            ('http://172.16.1.1/', True),\n-            ('http://172.16.1.1:5000/', True),\n-            ('http://localhost.localdomain:5000/v1.0/', True),\n-            ('http://google.com:6000/', True),\n-            ('http://172.16.1.12/', False),\n-            ('http://172.16.1.12:5000/', False),\n-            ('http://google.com:5000/v1.0/', False),\n-            ('file:///some/path/on/disk', True),\n-    ))\n+    \"url, expected\",\n+    (\n+        (\"http://192.168.0.1:5000/\", True),\n+        (\"http://192.168.0.1/\", True),\n+        (\"http://172.16.1.1/\", True),\n+        (\"http://172.16.1.1:5000/\", True),\n+        (\"http://localhost.localdomain:5000/v1.0/\", True),\n+        (\"http://google.com:6000/\", True),\n+        (\"http://172.16.1.12/\", False),\n+        (\"http://172.16.1.12:5000/\", False),\n+        (\"http://google.com:5000/v1.0/\", False),\n+        (\"file:///some/path/on/disk\", True),\n+    ),\n+)\n def test_should_bypass_proxies(url, expected, monkeypatch):\n     \"\"\"Tests for function should_bypass_proxies to check if proxy\n     can be bypassed or not\n     \"\"\"\n-    monkeypatch.setenv('no_proxy', '192.168.0.0/24,127.0.0.1,localhost.localdomain,172.16.1.1, google.com:6000')\n-    monkeypatch.setenv('NO_PROXY', '192.168.0.0/24,127.0.0.1,localhost.localdomain,172.16.1.1, google.com:6000')\n+    monkeypatch.setenv(\n+        \"no_proxy\",\n+        \"192.168.0.0/24,127.0.0.1,localhost.localdomain,172.16.1.1, google.com:6000\",\n+    )\n+    monkeypatch.setenv(\n+        \"NO_PROXY\",\n+        \"192.168.0.0/24,127.0.0.1,localhost.localdomain,172.16.1.1, google.com:6000\",\n+    )\n     assert should_bypass_proxies(url, no_proxy=None) == expected\n \n \n @pytest.mark.parametrize(\n-    'url, expected', (\n-            ('http://172.16.1.1/', '172.16.1.1'),\n-            ('http://172.16.1.1:5000/', '172.16.1.1'),\n-            ('http://user:pass@172.16.1.1', '172.16.1.1'),\n-            ('http://user:pass@172.16.1.1:5000', '172.16.1.1'),\n-            ('http://hostname/', 'hostname'),\n-            ('http://hostname:5000/', 'hostname'),\n-            ('http://user:pass@hostname', 'hostname'),\n-            ('http://user:pass@hostname:5000', 'hostname'),\n-    ))\n+    \"url, expected\",\n+    (\n+        (\"http://172.16.1.1/\", \"172.16.1.1\"),\n+        (\"http://172.16.1.1:5000/\", \"172.16.1.1\"),\n+        (\"http://user:pass@172.16.1.1\", \"172.16.1.1\"),\n+        (\"http://user:pass@172.16.1.1:5000\", \"172.16.1.1\"),\n+        (\"http://hostname/\", \"hostname\"),\n+        (\"http://hostname:5000/\", \"hostname\"),\n+        (\"http://user:pass@hostname\", \"hostname\"),\n+        (\"http://user:pass@hostname:5000\", \"hostname\"),\n+    ),\n+)\n def test_should_bypass_proxies_pass_only_hostname(url, expected, mocker):\n     \"\"\"The proxy_bypass function should be called with a hostname or IP without\n     a port number or auth credentials.\n     \"\"\"\n-    proxy_bypass = mocker.patch('requests.utils.proxy_bypass')\n+    proxy_bypass = mocker.patch(\"requests.utils.proxy_bypass\")\n     should_bypass_proxies(url, no_proxy=None)\n     proxy_bypass.assert_called_once_with(expected)\n \n \n @pytest.mark.parametrize(\n-    'cookiejar', (\n+    \"cookiejar\",\n+    (\n         compat.cookielib.CookieJar(),\n-        RequestsCookieJar()\n-    ))\n+        RequestsCookieJar(),\n+    ),\n+)\n def test_add_dict_to_cookiejar(cookiejar):\n     \"\"\"Ensure add_dict_to_cookiejar works for\n     non-RequestsCookieJar CookieJars\n     \"\"\"\n-    cookiedict = {'test': 'cookies',\n-                  'good': 'cookies'}\n+    cookiedict = {\"test\": \"cookies\", \"good\": \"cookies\"}\n     cj = add_dict_to_cookiejar(cookiejar, cookiedict)\n     cookies = {cookie.name: cookie.value for cookie in cj}\n     assert cookiedict == cookies\n \n \n @pytest.mark.parametrize(\n-    'value, expected', (\n-                (u'test', True),\n-                (u'æíöû', False),\n-                (u'ジェーピーニック', False),\n-    )\n+    \"value, expected\",\n+    (\n+        (\"test\", True),\n+        (\"æíöû\", False),\n+        (\"ジェーピーニック\", False),\n+    ),\n )\n def test_unicode_is_ascii(value, expected):\n     assert unicode_is_ascii(value) is expected\n \n \n @pytest.mark.parametrize(\n-    'url, expected', (\n-            ('http://192.168.0.1:5000/', True),\n-            ('http://192.168.0.1/', True),\n-            ('http://172.16.1.1/', True),\n-            ('http://172.16.1.1:5000/', True),\n-            ('http://localhost.localdomain:5000/v1.0/', True),\n-            ('http://172.16.1.12/', False),\n-            ('http://172.16.1.12:5000/', False),\n-            ('http://google.com:5000/v1.0/', False),\n-    ))\n-def test_should_bypass_proxies_no_proxy(\n-        url, expected, monkeypatch):\n+    \"url, expected\",\n+    (\n+        (\"http://192.168.0.1:5000/\", True),\n+        (\"http://192.168.0.1/\", True),\n+        (\"http://172.16.1.1/\", True),\n+        (\"http://172.16.1.1:5000/\", True),\n+        (\"http://localhost.localdomain:5000/v1.0/\", True),\n+        (\"http://172.16.1.12/\", False),\n+        (\"http://172.16.1.12:5000/\", False),\n+        (\"http://google.com:5000/v1.0/\", False),\n+    ),\n+)\n+def test_should_bypass_proxies_no_proxy(url, expected, monkeypatch):\n     \"\"\"Tests for function should_bypass_proxies to check if proxy\n     can be bypassed or not using the 'no_proxy' argument\n     \"\"\"\n-    no_proxy = '192.168.0.0/24,127.0.0.1,localhost.localdomain,172.16.1.1'\n+    no_proxy = \"192.168.0.0/24,127.0.0.1,localhost.localdomain,172.16.1.1\"\n     # Test 'no_proxy' argument\n     assert should_bypass_proxies(url, no_proxy=no_proxy) == expected\n \n \n-@pytest.mark.skipif(os.name != 'nt', reason='Test only on Windows')\n+@pytest.mark.skipif(os.name != \"nt\", reason=\"Test only on Windows\")\n @pytest.mark.parametrize(\n-    'url, expected, override', (\n-            ('http://192.168.0.1:5000/', True, None),\n-            ('http://192.168.0.1/', True, None),\n-            ('http://172.16.1.1/', True, None),\n-            ('http://172.16.1.1:5000/', True, None),\n-            ('http://localhost.localdomain:5000/v1.0/', True, None),\n-            ('http://172.16.1.22/', False, None),\n-            ('http://172.16.1.22:5000/', False, None),\n-            ('http://google.com:5000/v1.0/', False, None),\n-            ('http://mylocalhostname:5000/v1.0/', True, '<local>'),\n-            ('http://192.168.0.1/', False, ''),\n-    ))\n-def test_should_bypass_proxies_win_registry(url, expected, override,\n-                                            monkeypatch):\n+    \"url, expected, override\",\n+    (\n+        (\"http://192.168.0.1:5000/\", True, None),\n+        (\"http://192.168.0.1/\", True, None),\n+        (\"http://172.16.1.1/\", True, None),\n+        (\"http://172.16.1.1:5000/\", True, None),\n+        (\"http://localhost.localdomain:5000/v1.0/\", True, None),\n+        (\"http://172.16.1.22/\", False, None),\n+        (\"http://172.16.1.22:5000/\", False, None),\n+        (\"http://google.com:5000/v1.0/\", False, None),\n+        (\"http://mylocalhostname:5000/v1.0/\", True, \"<local>\"),\n+        (\"http://192.168.0.1/\", False, \"\"),\n+    ),\n+)\n+def test_should_bypass_proxies_win_registry(url, expected, override, monkeypatch):\n     \"\"\"Tests for function should_bypass_proxies to check if proxy\n     can be bypassed or not with Windows registry settings\n     \"\"\"\n     if override is None:\n-        override = '192.168.*;127.0.0.1;localhost.localdomain;172.16.1.1'\n+        override = \"192.168.*;127.0.0.1;localhost.localdomain;172.16.1.1\"\n     import winreg\n \n     class RegHandle:\n@@ -763,30 +847,32 @@ def test_should_bypass_proxies_win_registry(url, expected, override,\n \n     def QueryValueEx(key, value_name):\n         if key is ie_settings:\n-            if value_name == 'ProxyEnable':\n+            if value_name == \"ProxyEnable\":\n                 # this could be a string (REG_SZ) or a 32-bit number (REG_DWORD)\n                 proxyEnableValues.rotate()\n                 return [proxyEnableValues[0]]\n-            elif value_name == 'ProxyOverride':\n+            elif value_name == \"ProxyOverride\":\n                 return [override]\n \n-    monkeypatch.setenv('http_proxy', '')\n-    monkeypatch.setenv('https_proxy', '')\n-    monkeypatch.setenv('ftp_proxy', '')\n-    monkeypatch.setenv('no_proxy', '')\n-    monkeypatch.setenv('NO_PROXY', '')\n-    monkeypatch.setattr(winreg, 'OpenKey', OpenKey)\n-    monkeypatch.setattr(winreg, 'QueryValueEx', QueryValueEx)\n+    monkeypatch.setenv(\"http_proxy\", \"\")\n+    monkeypatch.setenv(\"https_proxy\", \"\")\n+    monkeypatch.setenv(\"ftp_proxy\", \"\")\n+    monkeypatch.setenv(\"no_proxy\", \"\")\n+    monkeypatch.setenv(\"NO_PROXY\", \"\")\n+    monkeypatch.setattr(winreg, \"OpenKey\", OpenKey)\n+    monkeypatch.setattr(winreg, \"QueryValueEx\", QueryValueEx)\n     assert should_bypass_proxies(url, None) == expected\n \n \n @pytest.mark.parametrize(\n-    'env_name, value', (\n-            ('no_proxy', '192.168.0.0/24,127.0.0.1,localhost.localdomain'),\n-            ('no_proxy', None),\n-            ('a_new_key', '192.168.0.0/24,127.0.0.1,localhost.localdomain'),\n-            ('a_new_key', None),\n-    ))\n+    \"env_name, value\",\n+    (\n+        (\"no_proxy\", \"192.168.0.0/24,127.0.0.1,localhost.localdomain\"),\n+        (\"no_proxy\", None),\n+        (\"a_new_key\", \"192.168.0.0/24,127.0.0.1,localhost.localdomain\"),\n+        (\"a_new_key\", None),\n+    ),\n+)\n def test_set_environ(env_name, value):\n     \"\"\"Tests set_environ will set environ values and will restore the environ.\"\"\"\n     environ_copy = copy.deepcopy(os.environ)\n@@ -800,7 +886,7 @@ def test_set_environ_raises_exception():\n     \"\"\"Tests set_environ will raise exceptions in context when the\n     value parameter is None.\"\"\"\n     with pytest.raises(Exception) as exception:\n-        with set_environ('test1', None):\n-            raise Exception('Expected exception')\n+        with set_environ(\"test1\", None):\n+            raise Exception(\"Expected exception\")\n \n-    assert 'Expected exception' in str(exception.value)\n+    assert \"Expected exception\" in str(exception.value)\n\n@@ -1,13 +1,11 @@\n-# -*- coding: utf-8 -*-\n-\n-import threading\n-import socket\n import select\n+import socket\n+import threading\n \n \n def consume_socket_content(sock, timeout=0.5):\n     chunks = 65536\n-    content = b''\n+    content = b\"\"\n \n     while True:\n         more_to_read = select.select([sock], [], [], timeout)[0]\n@@ -25,10 +23,18 @@ def consume_socket_content(sock, timeout=0.5):\n \n class Server(threading.Thread):\n     \"\"\"Dummy server using for unit testing\"\"\"\n+\n     WAIT_EVENT_TIMEOUT = 5\n \n-    def __init__(self, handler=None, host='localhost', port=0, requests_to_handle=1, wait_to_close_event=None):\n-        super(Server, self).__init__()\n+    def __init__(\n+        self,\n+        handler=None,\n+        host=\"localhost\",\n+        port=0,\n+        requests_to_handle=1,\n+        wait_to_close_event=None,\n+    ):\n+        super().__init__()\n \n         self.handler = handler or consume_socket_content\n         self.handler_results = []\n@@ -45,19 +51,16 @@ class Server(threading.Thread):\n     def text_response_server(cls, text, request_timeout=0.5, **kwargs):\n         def text_response_handler(sock):\n             request_content = consume_socket_content(sock, timeout=request_timeout)\n-            sock.send(text.encode('utf-8'))\n+            sock.send(text.encode(\"utf-8\"))\n \n             return request_content\n \n-\n         return Server(text_response_handler, **kwargs)\n \n     @classmethod\n     def basic_response_server(cls, **kwargs):\n         return cls.text_response_server(\n-            \"HTTP/1.1 200 OK\\r\\n\" +\n-            \"Content-Length: 0\\r\\n\\r\\n\",\n-            **kwargs\n+            \"HTTP/1.1 200 OK\\r\\n\" + \"Content-Length: 0\\r\\n\\r\\n\", **kwargs\n         )\n \n     def run(self):\n@@ -84,7 +87,7 @@ class Server(threading.Thread):\n     def _close_server_sock_ignore_errors(self):\n         try:\n             self.server_sock.close()\n-        except IOError:\n+        except OSError:\n             pass\n \n     def _handle_requests(self):\n@@ -100,12 +103,14 @@ class Server(threading.Thread):\n \n     def _accept_connection(self):\n         try:\n-            ready, _, _ = select.select([self.server_sock], [], [], self.WAIT_EVENT_TIMEOUT)\n+            ready, _, _ = select.select(\n+                [self.server_sock], [], [], self.WAIT_EVENT_TIMEOUT\n+            )\n             if not ready:\n                 return None\n \n             return self.server_sock.accept()[0]\n-        except (select.error, socket.error):\n+        except OSError:\n             return None\n \n     def __enter__(self):\n\n@@ -1,5 +1,3 @@\n-# -*- coding: utf-8 -*-\n-\n import contextlib\n import os\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
