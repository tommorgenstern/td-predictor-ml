{"custom_id": "keras#bce4ac97d71108f5b2ab96bc72a6396bc9eca2f3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 448 | Contributors (this commit): 12 | Commits (past 90d): 4 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -192,7 +192,7 @@ class ApplicationsTest(tf.test.TestCase, parameterized.TestCase):\n         self.assertShapeEqual(output_shape, (None, last_dim))\n \n     @parameterized.parameters(MODEL_LIST)\n-    def test_application_classifier_activation(self, app):\n+    def test_application_classifier_activation(self, app, _):\n         model = app(\n             weights=None, include_top=True, classifier_activation=\"softmax\"\n         )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#00d48891ef440eaf6f5bc599e052f2b221a03a08", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 5 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 15 | Churn Cumulative: 3005 | Contributors (this commit): 9 | Commits (past 90d): 1 | Contributors (cumulative): 9 | DMM Complexity: 0.5\n\nDIFF:\n@@ -833,11 +833,12 @@ def Stage(block_type, depth, group_width, filters_in, filters_out, name=None):\n     return apply\n \n \n-def Head(num_classes=1000, name=None):\n+def Head(num_classes=1000, classifier_activation=None, name=None):\n     \"\"\"Implementation of classification head of RegNet.\n \n     Args:\n       num_classes: number of classes for Dense layer\n+      classifier_activation: activation function for the Dense layer\n       name: name prefix\n \n     Returns:\n@@ -848,7 +849,11 @@ def Head(num_classes=1000, name=None):\n \n     def apply(x):\n         x = layers.GlobalAveragePooling2D(name=name + \"_head_gap\")(x)\n-        x = layers.Dense(num_classes, name=name + \"head_dense\")(x)\n+        x = layers.Dense(\n+            num_classes,\n+            activation=classifier_activation,\n+            name=name + \"head_dense\",\n+        )(x)\n         return x\n \n     return apply\n@@ -977,8 +982,12 @@ def RegNet(\n         in_channels = out_channels\n \n     if include_top:\n-        x = Head(num_classes=classes)(x)\n         imagenet_utils.validate_activation(classifier_activation, weights)\n+        x = Head(\n+            num_classes=classes,\n+            classifier_activation=classifier_activation,\n+            name=model_name,\n+        )(x)\n \n     else:\n         if pooling == \"avg\":\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2c22d37223f6956e5325f1baec4037630914c1df", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 12 | Files Changed: 1 | Hunks: 5 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 15 | Churn Cumulative: 3020 | Contributors (this commit): 9 | Commits (past 90d): 2 | Contributors (cumulative): 9 | DMM Complexity: 0.5\n\nDIFF:\n@@ -833,12 +833,11 @@ def Stage(block_type, depth, group_width, filters_in, filters_out, name=None):\n     return apply\n \n \n-def Head(num_classes=1000, classifier_activation=None, name=None):\n+def Head(num_classes=1000, name=None):\n     \"\"\"Implementation of classification head of RegNet.\n \n     Args:\n       num_classes: number of classes for Dense layer\n-      classifier_activation: activation function for the Dense layer\n       name: name prefix\n \n     Returns:\n@@ -849,11 +848,7 @@ def Head(num_classes=1000, classifier_activation=None, name=None):\n \n     def apply(x):\n         x = layers.GlobalAveragePooling2D(name=name + \"_head_gap\")(x)\n-        x = layers.Dense(\n-            num_classes,\n-            activation=classifier_activation,\n-            name=name + \"head_dense\",\n-        )(x)\n+        x = layers.Dense(num_classes, name=name + \"head_dense\")(x)\n         return x\n \n     return apply\n@@ -982,12 +977,8 @@ def RegNet(\n         in_channels = out_channels\n \n     if include_top:\n+        x = Head(num_classes=classes)(x)\n         imagenet_utils.validate_activation(classifier_activation, weights)\n-        x = Head(\n-            num_classes=classes,\n-            classifier_activation=classifier_activation,\n-            name=model_name,\n-        )(x)\n \n     else:\n         if pooling == \"avg\":\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3abd441e3f343ac595c0960c3089a4be3136c932", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 2 | Churn Cumulative: 450 | Contributors (this commit): 12 | Commits (past 90d): 5 | Contributors (cumulative): 12 | DMM Complexity: 1.0\n\nDIFF:\n@@ -193,6 +193,8 @@ class ApplicationsTest(tf.test.TestCase, parameterized.TestCase):\n \n     @parameterized.parameters(MODEL_LIST)\n     def test_application_classifier_activation(self, app, _):\n+        if \"RegNet\" in app.__name__:\n+            self.skipTest(\"RegNet models do not support classifier activation\")\n         model = app(\n             weights=None, include_top=True, classifier_activation=\"softmax\"\n         )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c19e7ce73bc96c57b6fb2444ecb8f40cb323379d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 410 | Lines Deleted: 0 | Files Changed: 4 | Hunks: 4 | Methods Changed: 26 | Complexity Δ (Sum/Max): 36/19 | Churn Δ: 410 | Churn Cumulative: 2547 | Contributors (this commit): 6 | Commits (past 90d): 24 | Contributors (cumulative): 12 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,72 @@\n+\"\"\"Test Model.fit with a PyMetric.\"\"\"\n+\n+import tensorflow.compat.v2 as tf\n+from absl.testing import parameterized\n+\n+from keras import Sequential\n+from keras import layers\n+from keras import losses\n+from keras import metrics\n+from keras.testing_infra import test_combinations\n+\n+\n+def get_dataset(num_batches=5, batch_size=2):\n+    x = tf.random.uniform((num_batches * batch_size, 100))\n+    y = tf.random.uniform((num_batches * batch_size, 2))\n+    dataset = (\n+        tf.data.Dataset.from_tensor_slices((x, y))\n+        .prefetch(batch_size * 2)\n+        .batch(batch_size)\n+    )\n+    return dataset\n+\n+\n+class CountingPyMetric(metrics.PyMetric):\n+    \"\"\"A test-only PyMetric which simply counts how many results it's seen.\"\"\"\n+\n+    def update_state(self, y_true, y_pred, sample_weight=None):\n+        self.y_pred.append(y_pred)\n+\n+    def reset_state(self):\n+        self.y_pred = []\n+\n+    def result(self):\n+        return len(self.y_pred)\n+\n+\n+class PyMetricTest(test_combinations.TestCase):\n+    @parameterized.named_parameters((\"eager\", True), (\"graph\", False))\n+    def test_fit(self, run_eagerly):\n+        num_batches = 5\n+        dataset = get_dataset(num_batches=num_batches)\n+\n+        counting_metric = CountingPyMetric()\n+\n+        model = Sequential(layers.Dense(2))\n+        model.compile(\n+            loss=losses.BinaryCrossentropy(),\n+            metrics=[counting_metric],\n+            run_eagerly=run_eagerly,\n+        )\n+        model.fit(dataset, epochs=1)\n+\n+        self.assertEqual(counting_metric.result(), num_batches)\n+\n+    @parameterized.named_parameters((\"eager\", True), (\"graph\", False))\n+    def test_evaluate(self, run_eagerly):\n+        num_batches = 5\n+        dataset = get_dataset(num_batches=num_batches)\n+\n+        model = Sequential(layers.Dense(2))\n+        model.compile(\n+            loss=losses.BinaryCrossentropy(),\n+            metrics=[CountingPyMetric()],\n+            run_eagerly=run_eagerly,\n+        )\n+        loss, count = model.evaluate(dataset)\n+\n+        self.assertEqual(count, num_batches)\n+\n+\n+if __name__ == \"__main__\":\n+    tf.test.main()\n\n@@ -33,6 +33,8 @@ from keras.saving.legacy import serialization as legacy_serialization\n from keras.saving.legacy.serialization import deserialize_keras_object\n from keras.saving.legacy.serialization import serialize_keras_object\n \n+from keras.metrics.py_metric import PyMetric\n+\n # Individual metric classes\n \n # Accuracy metrics\n\n@@ -0,0 +1,191 @@\n+# Copyright 2023 The Keras Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Base class for Python-based metrics\"\"\"\n+\n+import types\n+\n+import tensorflow.compat.v2 as tf\n+from tensorflow.python.util.tf_export import keras_export\n+\n+from keras.metrics import base_metric\n+\n+\n+@keras_export(\"keras.metrics.experimental.PyMetric\", v1=[])\n+class PyMetric(base_metric.Metric):\n+    \"\"\"Metric which runs in Python, compiled outside of the TensorFlow graph.\n+\n+    Args:\n+      name: (Optional) string name of the PyMetric instance.\n+      dtype: (Optional) data type of the PyMetric result.\n+      **kwargs: Additional layer keywords arguments.\n+\n+    Usage of `PyMetric` is generally identical to `keras.metrics.Metric`.\n+    It can be used in isolation, or in tandem with the `compile()` API. For more\n+    information about the usage of `PyMetric`, see `keras.metrics.Metric`.\n+\n+    Unlike regular metrics, `PyMetric` instances are outside-compiled\n+    with respect to the TensorFlow graph during training or evaluation.\n+    They have access to the same\n+    inputs of a standard in-graph metric, but they run in a Python interpreter\n+    on the host CPU. Any data stored in a `PyMetric` is located on the main\n+    memory of the host CPU, and any TensorFlow ops used in a PyMetric are\n+    run eagerly on the host CPU.\n+\n+    As a result, `PyMetric` instances are generally not as performant\n+    as in-graph metrics, and should only be used in cases where computing\n+    the metric inside of the TensorFlow graph is either impossible\n+    or prohibitively expensive.\n+\n+    **Note:** Due to the use of `tf.py_function`, PyMetrics\n+    are incompatible with XLA and therefore TPUs.\n+\n+    Methods to be implemented by subclasses:\n+\n+    * `update_state()`: Handles updates to internal state variables\n+    * `result()`: Computes and returns a scalar value or a dict of scalar values\n+      for the metric from the state variables.\n+    * `reset_state()`: Computes and returns a scalar value for the metric from\n+      the state variables.\n+\n+    This subclass implementation is similar to that of `keras.metrics.Metric`,\n+    with two notable differences:\n+\n+    * Inputs to `update_state()` in a `PyMetric` are eager tensors, and both\n+    `update_state()` and `result()` run outside of the TensorFlow graph,\n+    executing any TensorFlow ops eagerly.\n+    * `reset_state()` is also called at initialization time to initialize the\n+    Python state of the metric.\n+    * `result()` can only return a single scalar. It does not support returning\n+    a dictionary of results like `keras.metrics.Metric`.\n+\n+    Example subclass implementation using sklearn's Jaccard Score:\n+\n+    ```python\n+    from sklearn.metrics import jaccard_score\n+    import tensorflow as tf\n+\n+    class JaccardScore(tf.keras.metrics.experimental.PyMetric):\n+\n+      def __init__(self, name='jaccard_score', **kwargs):\n+        super().__init__(name=name, **kwargs)\n+\n+      def update_state(self, y_true, y_pred, sample_weight=None):\n+        self.jaccard_sum += jaccard_score(y_pred, y_true, average=\"macro\")\n+        self.count += 1\n+\n+      def reset_state(self):\n+        self.jaccard_sum = 0.\n+        self.count = 0.\n+\n+      def result(self):\n+        return self.jaccard_sum / self.count\n+    ```\n+    \"\"\"\n+\n+    def __init__(self, name=None, dtype=None, **kwargs):\n+        super().__init__(name=name, dtype=dtype, **kwargs)\n+        self.reset_state()\n+\n+    def __new__(cls, *args, **kwargs):\n+        obj = super(base_metric.Metric, cls).__new__(cls)\n+\n+        # Wrap the update_state function in a py_function and scope it to /cpu:0\n+        obj_update_state = obj.update_state\n+\n+        def update_state_on_cpu(y_true, y_pred, sample_weight=None):\n+            with tf.device(\"/cpu:0\"):\n+                return obj_update_state(y_true, y_pred, sample_weight)\n+\n+        obj.update_state_on_cpu = update_state_on_cpu\n+\n+        def update_state_fn(self, y_true, y_pred, sample_weight=None):\n+            eager_inputs = [y_true, y_pred]\n+            if sample_weight is not None:\n+                eager_inputs.append(sample_weight)\n+            return tf.py_function(\n+                func=self.update_state_on_cpu, inp=eager_inputs, Tout=[]\n+            )\n+\n+        obj.update_state = types.MethodType(update_state_fn, obj)\n+\n+        # Wrap the result function in a py_function and scope it to /cpu:0\n+        obj_result = obj.result\n+\n+        def result_on_host_cpu():\n+            with tf.device(\"/cpu:0\"):\n+                return obj_result()\n+\n+        obj.result_on_host_cpu = result_on_host_cpu\n+\n+        def result_fn(self):\n+            return tf.py_function(\n+                self.result_on_host_cpu, inp=[], Tout=obj.dtype\n+            )\n+\n+        obj.result = types.MethodType(result_fn, obj)\n+\n+        return obj\n+\n+    def update_state(self, y_true, y_pred, sample_weight=None):\n+        \"\"\"Accumulates statistics for the metric.\n+\n+        **Note:** This function is executed outside of the TensorFlow graph\n+        on the CPU host.\n+\n+        This means:\n+\n+        a) Inputs are eager tensors.\n+        b) Any TensorFlow ops run in this method are run eagerly.\n+        c) Any Tensors created are allocated to the CPU's main memory.\n+\n+        Args:\n+          y_true: Target output\n+          y_pred: Predicted output\n+          sample_weight: (Optional) weights for the individual samples in\n+            `y_true` and `y_pred`\n+        \"\"\"\n+        raise NotImplementedError(\"Subclasses should implement `update_state`\")\n+\n+    def merge_state(self, metrics):\n+        \"\"\"Merges the state from one or more metrics.\n+\n+        `PyMetric` instances that intend to support merging state must override\n+         this method, as the default implementation\n+        in `keras.metrics.Metric` does not apply to `PyMetric`.\n+        \"\"\"\n+        raise NotImplementedError(\"Subclasses should implement `merge_state`\")\n+\n+    def reset_state(self):\n+        \"\"\"Resets all of the metric state variables.\n+\n+        This function is called between epochs when a metric is evaluated during\n+        training. It's also called when the metric is initialized.\n+        \"\"\"\n+        raise NotImplementedError(\"Subclasses should implement `reset_state`\")\n+\n+    def result(self):\n+        \"\"\"Computes and returns the scalar metric value.\n+\n+        **Note:** This function is executed outside of the TensorFlow graph\n+         on the CPU host. This means any TensorFlow ops run in this method\n+         are run eagerly.\n+\n+        Result computation is an idempotent operation that simply calculates the\n+        metric value using the state variables.\n+\n+        Returns:\n+            A Python scalar.\n+        \"\"\"\n+        raise NotImplementedError(\"Subclasses should implement `result`\")\n\n@@ -0,0 +1,145 @@\n+# Copyright 2023 The Keras Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Tests for Keras PyMetric classes.\"\"\"\n+\n+\n+import tensorflow.compat.v2 as tf\n+\n+from keras import metrics\n+from keras.testing_infra import test_combinations\n+\n+\n+class KTrimmedMean(metrics.PyMetric):\n+    \"\"\"An example PyMetric which computes the trimmed mean of `y_pred`.\"\"\"\n+\n+    def __init__(self, k=0.1, name=\"k_trimmed_mean\", **kwargs):\n+        super().__init__(name=name, **kwargs)\n+        self.k = k\n+\n+    def update_state(self, y_true, y_pred, sample_weight=None):\n+        y_true = y_true.numpy()\n+\n+        if sample_weight is not None:\n+            y_true *= sample_weight.numpy()\n+\n+        # Insert y_pred into our values list (keeping the list sorted)\n+        index = 0\n+        for i, element in enumerate(self.values):\n+            if y_true > element:\n+                index = i\n+                break\n+        self.values = self.values[:index] + [y_true] + self.values[index:]\n+\n+    def reset_state(self):\n+        self.values = []\n+\n+    def result(self):\n+        k = int(self.k * len(self.values))\n+        return tf.reduce_mean(self.values[k:-k])\n+\n+    def get_config(self):\n+        config = super().get_config()\n+        config.update({\"k\": self.k})\n+        return config\n+\n+\n+class Mean(metrics.PyMetric):\n+    \"\"\"An example PyMetric which computes the mean of `y_pred`.\"\"\"\n+\n+    def __init__(self, name=\"mean\", **kwargs):\n+        super().__init__(name=name, **kwargs)\n+\n+    def update_state(self, y_true, y_pred, sample_weight=None):\n+        self.values.append(y_true)\n+\n+    def reset_state(self):\n+        self.values = []\n+\n+    def result(self):\n+        return tf.reduce_mean(tf.concat(self.values, axis=0))\n+\n+\n+@test_combinations.generate(test_combinations.combine(mode=[\"graph\", \"eager\"]))\n+class PyMetricsTest(tf.test.TestCase):\n+    def test_config(self):\n+        ktm_object = KTrimmedMean(name=\"ktm\", k=0.2, dtype=tf.float16)\n+        self.assertEqual(ktm_object.name, \"ktm\")\n+        self.assertEqual(ktm_object.k, 0.2)\n+        self.assertEqual(ktm_object.dtype, tf.float16)\n+\n+        # Check save and restore config\n+        ktm_object2 = KTrimmedMean.from_config(ktm_object.get_config())\n+        self.assertEqual(ktm_object2.name, \"ktm\")\n+        self.assertEqual(ktm_object.k, 0.2)\n+        self.assertEqual(ktm_object2.dtype, tf.float16)\n+\n+    def test_unweighted(self):\n+        ktm_object = KTrimmedMean(k=0.2)\n+\n+        for y_true in [-100, -10, 1, 2, 3, 4, 5, 6, 14, 9001]:\n+            self.evaluate(\n+                ktm_object.update_state(\n+                    tf.constant(y_true, dtype=tf.float32),\n+                    y_pred=tf.constant(0, dtype=tf.float32),\n+                )\n+            )\n+\n+        result = ktm_object.result()\n+        self.assertEqual(3.5, self.evaluate(result))\n+\n+    def test_weighted(self):\n+        ktm_object = KTrimmedMean(k=0.2)\n+\n+        for y_true in [-100, -10, 1, 2, 3, 4, 5, 6, 14, 9001]:\n+            self.evaluate(\n+                ktm_object.update_state(\n+                    tf.constant(y_true, dtype=tf.float32),\n+                    y_pred=tf.constant(0, dtype=tf.float32),\n+                    sample_weight=tf.constant(2, dtype=tf.float32),\n+                )\n+            )\n+\n+        result = ktm_object.result()\n+        self.assertEqual(7, self.evaluate(result))\n+\n+    def test_state_stored_on_cpu_host(self):\n+        with tf.device(\"/device:GPU:0\"):\n+            mean_obj = Mean()\n+\n+            y_true_0 = tf.constant([0, 1, 2], dtype=tf.float32)\n+            y_true_1 = tf.constant([3, 4], dtype=tf.float32)\n+            self.evaluate(\n+                mean_obj.update_state(\n+                    y_true=y_true_0, y_pred=tf.constant(0, dtype=tf.float32)\n+                )\n+            )\n+            self.evaluate(\n+                mean_obj.update_state(\n+                    y_true=y_true_1, y_pred=tf.constant(0, dtype=tf.float32)\n+                )\n+            )\n+\n+        self.assertEqual(2, self.evaluate(mean_obj.result()))\n+\n+        if not tf.executing_eagerly():\n+            self.assertEndsWith(y_true_0.device, \"/device:GPU:0\")\n+            self.assertEndsWith(y_true_1.device, \"/device:GPU:0\")\n+\n+        self.assertEndsWith(mean_obj.values[0].device, \"/device:CPU:0\")\n+        self.assertEndsWith(mean_obj.values[1].device, \"/device:CPU:0\")\n+\n+\n+if __name__ == \"__main__\":\n+    tf.test.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6223ee72d553ac9dac14f1423960b2744dbf2d99", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 3163 | Contributors (this commit): 10 | Commits (past 90d): 6 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -219,7 +219,7 @@ class LayerScale(layers.Layer):\n     def build(self, input_shape):\n         self.gamma = tf.Variable(\n             self.init_values * tf.ones((self.projection_dim,)),\n-            dtype=self._compute_dtype_object\n+            dtype=self._compute_dtype_object,\n         )\n \n     def call(self, x):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#adda041b2b14be5448deeb9bd210cf4a48e1521c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 21 | Lines Deleted: 15 | Files Changed: 3 | Hunks: 12 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 36 | Churn Cumulative: 6259 | Contributors (this commit): 49 | Commits (past 90d): 12 | Contributors (cumulative): 58 | DMM Complexity: None\n\nDIFF:\n@@ -39,7 +39,7 @@ class Lambda(Layer):\n     \"\"\"Wraps arbitrary expressions as a `Layer` object.\n \n     The `Lambda` layer exists so that arbitrary expressions can be used\n-    as a `Layer` when constructing `Sequential`\n+    as a `Layer` when constructing Sequential\n     and Functional API models. `Lambda` layers are best suited for simple\n     operations or quick experimentation. For more advanced use cases, follow\n     [this guide](\n@@ -53,7 +53,7 @@ class Lambda(Layer):\n     are saved by serializing the Python bytecode, which is fundamentally\n     non-portable. They should only be loaded in the same environment where\n     they were saved. Subclassed layers can be saved in a more portable way\n-    by overriding their `get_config` method. Models that rely on\n+    by overriding their `get_config()` method. Models that rely on\n     subclassed Layers are also often easier to visualize and reason about.\n \n     Examples:\n@@ -62,6 +62,7 @@ class Lambda(Layer):\n     # add a x -> x^2 layer\n     model.add(Lambda(lambda x: x ** 2))\n     ```\n+\n     ```python\n     # add a layer that returns the concatenation\n     # of the positive part of the input and\n@@ -77,17 +78,18 @@ class Lambda(Layer):\n     model.add(Lambda(antirectifier))\n     ```\n \n-    Variables:\n-      While it is possible to use Variables with Lambda layers, this practice is\n-      discouraged as it can easily lead to bugs. For instance, consider the\n-      following layer:\n+    **Note on Variables:**\n+\n+    While it is possible to use Variables with Lambda layers,\n+    this practice is discouraged as it can easily lead to bugs.\n+    For instance, consider the following layer:\n \n     ```python\n     scale = tf.Variable(1.)\n     scale_layer = tf.keras.layers.Lambda(lambda x: x * scale)\n     ```\n \n-      Because scale_layer does not directly track the `scale` variable, it will\n+    Because `scale_layer` does not directly track the `scale` variable, it will\n     not appear in `scale_layer.trainable_weights` and will therefore not be\n     trained if `scale_layer` is used in a Model.\n \n@@ -95,17 +97,16 @@ class Lambda(Layer):\n \n     ```python\n     class ScaleLayer(tf.keras.layers.Layer):\n-        def __init__(self):\n-          super(ScaleLayer, self).__init__()\n+        def __init__(self, **kwargs):\n+            super().__init__(**kwargs)\n             self.scale = tf.Variable(1.)\n \n         def call(self, inputs):\n             return inputs * self.scale\n     ```\n \n-      In general, Lambda layers can be convenient for simple stateless\n-      computation, but anything more complex should use a subclass Layer\n-      instead.\n+    In general, `Lambda` layers can be convenient for simple stateless\n+    computation, but anything more complex should use a subclass Layer instead.\n \n     Args:\n       function: The function to be evaluated. Takes input tensor as first\n@@ -124,9 +125,11 @@ class Lambda(Layer):\n         returned as output mask regardless of what the input is.\n       arguments: Optional dictionary of keyword arguments to be passed to the\n         function.\n+\n     Input shape: Arbitrary. Use the keyword argument input_shape (tuple of\n       integers, does not include the samples axis) when using this layer as the\n       first layer in a model.\n+\n     Output shape: Specified by `output_shape` argument\n     \"\"\"\n \n\n@@ -33,9 +33,11 @@ from tensorflow.python.util.tf_export import keras_export\n \n @keras_export(\"keras.metrics.Poisson\")\n class Poisson(base_metric.MeanMetricWrapper):\n-    \"\"\"Computes the Poisson metric between `y_true` and `y_pred`.\n+    \"\"\"Computes the Poisson score between `y_true` and `y_pred`.\n \n-    `metric = y_pred - y_true * log(y_pred)`\n+    🐟 🐟 🐟\n+\n+    It is defined as: `poisson_score = y_pred - y_true * log(y_pred)`.\n \n     Args:\n       name: (Optional) string name of the metric instance.\n\n@@ -252,7 +252,8 @@ def get_file(\n     Returns:\n         Path to the downloaded file.\n \n-    **/!\\ Warning on malicious downloads /!\\ **\n+    ⚠️ **Warning on malicious downloads** ⚠️\n+\n     Downloading something from the Internet carries a risk.\n     NEVER download a file/archive if you do not trust the source.\n     We recommend that you specify the `file_hash` argument\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fb5bf606aba9ac712f0016af3c79d58fac1b5cf5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 29 | Files Changed: 1 | Hunks: 5 | Methods Changed: 5 | Complexity Δ (Sum/Max): -3/0 | Churn Δ: 32 | Churn Cumulative: 141 | Contributors (this commit): 5 | Commits (past 90d): 10 | Contributors (cumulative): 5 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1097,13 +1097,6 @@ class Optimizer(_BaseOptimizer):\n             **kwargs,\n         )\n         self._distribution_strategy = tf.distribute.get_strategy()\n-        # `tf.CriticalSection()` is used to resolve race condition under\n-        # PSS training. See b/261724919 for more context.\n-        if isinstance(\n-            self._distribution_strategy,\n-            tf.distribute.ParameterServerStrategy,\n-        ):\n-            self._critical_section = tf.CriticalSection()\n \n     def add_variable_from_reference(\n         self, model_variable, variable_name, shape=None, initial_value=None\n@@ -1247,35 +1240,16 @@ class Optimizer(_BaseOptimizer):\n     ):\n         \"\"\"`apply_gradients` using a `DistributionStrategy`.\"\"\"\n \n-        def apply_grad_to_update_var_step(var, grad):\n+        def apply_grad_to_update_var(var, grad):\n             if self.jit_compile:\n                 return self._update_step_xla(grad, var, id(self._var_key(var)))\n             else:\n                 return self._update_step(grad, var)\n \n-        def apply_grad_to_update_var():\n-            distribution.extended.update(\n-                var, apply_grad_to_update_var_step, args=(grad,), group=False\n-            )\n-            # Functions executed inside `tf.CriticalSection` needs to return\n-            # a tensor. Return a dummy tensor since we have nothing to return.\n-            return tf.constant(0)\n-\n         for grad, var in grads_and_vars:\n-            if isinstance(\n-                self._distribution_strategy,\n-                tf.distribute.ParameterServerStrategy,\n-            ):\n-                # Use `tf.CriticalSection` to avoid race condition, it's the\n-                # same effect as acquiring a mutex. PSS training hit race\n-                # condition without mutex, see b/261724919 for context.\n-                self._critical_section.execute(\n-                    apply_grad_to_update_var,\n-                    exclusive_resource_access=True,\n-                    name=None,\n+            distribution.extended.update(\n+                var, apply_grad_to_update_var, args=(grad,), group=False\n             )\n-            else:\n-                apply_grad_to_update_var()\n \n         if self.use_ema:\n             _, var_list = zip(*grads_and_vars)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#73adeb5933f4e838202ab9fff8846952748ed8b6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 80 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 3 | Methods Changed: 9 | Complexity Δ (Sum/Max): 9/7 | Churn Δ: 80 | Churn Cumulative: 10217 | Contributors (this commit): 25 | Commits (past 90d): 6 | Contributors (cumulative): 32 | DMM Complexity: 1.0\n\nDIFF:\n@@ -4540,6 +4540,72 @@ class TestTrainingWithMetrics(test_combinations.TestCase):\n             [\"loss\", \"mae\", \"my_mse\", \"my_rmse\"],\n         )\n \n+    @test_combinations.run_all_keras_modes(always_skip_v1=True)\n+    def test_add_metric_in_model_call_that_returns_dict(self):\n+        class DictMetric(metrics_module.Metric):\n+            def __init__(self):\n+                super().__init__()\n+                self.sample_count = tf.Variable(0)\n+                self.l2_sum = tf.Variable(0.0)\n+\n+            def update_state(self, y_true, y_pred, sample_weight=None):\n+                self.l2_sum.assign_add(\n+                    tf.reduce_sum(tf.square(y_true - y_pred))\n+                )\n+                self.sample_count.assign_add(tf.shape(y_true)[0])\n+\n+            def reset_state(self):\n+                self.sample_count.assign(0)\n+                self.l2_sum.assign(0.0)\n+\n+            def result(self):\n+                mse = self.l2_sum / tf.cast(self.sample_count, \"float32\")\n+                rmse = tf.sqrt(mse)\n+                return {\"my_mse\": mse, \"my_rmse\": rmse}\n+\n+        class TestModel(training_module.Model):\n+            def __init__(self):\n+                super().__init__(name=\"test_model\")\n+                self.dense1 = layers_module.Dense(2, kernel_initializer=\"ones\")\n+                self.dict_metric = DictMetric()\n+\n+            def call(self, x):\n+                self.add_metric(\n+                    tf.reduce_sum(x), name=\"metric_2\", aggregation=\"mean\"\n+                )\n+                # Provide same name as in the instance created in __init__\n+                # for eager mode\n+                self.add_metric(self.dict_metric(x, 1 - x), name=\"metric_1\")\n+                return self.dense1(x)\n+\n+        model = TestModel()\n+        model.compile(\n+            loss=\"mse\",\n+            optimizer=RMSPropOptimizer(0.01),\n+            run_eagerly=test_utils.should_run_eagerly(),\n+        )\n+\n+        x = np.ones(shape=(10, 1))\n+        y = np.ones(shape=(10, 2))\n+        history = model.fit(\n+            x, y, epochs=2, batch_size=5, validation_data=(x, y)\n+        )\n+        self.assertAlmostEqual(history.history[\"metric_2\"][-1], 5, 0)\n+        self.assertAlmostEqual(history.history[\"val_metric_2\"][-1], 5, 0)\n+        self.assertAlmostEqual(history.history[\"my_mse\"][-1], 1, 0)\n+        self.assertAlmostEqual(history.history[\"val_my_mse\"][-1], 1, 0)\n+        self.assertAlmostEqual(history.history[\"my_rmse\"][-1], 1, 0)\n+        self.assertAlmostEqual(history.history[\"val_my_rmse\"][-1], 1, 0)\n+\n+        eval_results = model.evaluate(x, y, batch_size=5, return_dict=True)\n+        self.assertAlmostEqual(eval_results[\"metric_2\"], 5, 0)\n+        self.assertAlmostEqual(eval_results[\"my_mse\"], 1, 0)\n+        self.assertAlmostEqual(eval_results[\"my_rmse\"], 1, 0)\n+\n+        model.predict(x, batch_size=5)\n+        model.train_on_batch(x, y)\n+        model.test_on_batch(x, y)\n+\n \n class BareUpdateLayer(layers_module.Layer):\n     def build(self, input_shape):\n\n@@ -191,6 +191,12 @@ class Metric(base_layer.Layer, metaclass=abc.ABCMeta):\n             with tf.control_dependencies(update_ops):\n                 result_t = self.result()\n \n+                # If the metric object return a dictionary as a result, wrap it\n+                # with our custom dict object so we can attach the metric object\n+                # to it.\n+                if isinstance(result_t, dict):\n+                    result_t = _MetricDict(**result_t)\n+\n                 # We are adding the metric object as metadata on the result\n                 # tensor.  This is required when we want to use a metric with\n                 # `add_metric` API on a Model/Layer in graph mode. This metric\n@@ -943,3 +949,11 @@ def is_built_in(cls):\n     return cls.__module__.startswith(\n         \".\".join(Metric.__module__.split(\".\")[:-1])\n     )\n+\n+\n+class _MetricDict(dict):\n+    \"\"\"Wrapper for returned dictionary of metrics.\"\"\"\n+\n+    def __init__(self, **kwargs):\n+        super().__init__(**kwargs)\n+        self._metric_obj = None\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5bc61d28a0574236f91d7982ac91891275fb8825", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 2 | Methods Changed: 3 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 7 | Churn Cumulative: 2491 | Contributors (this commit): 16 | Commits (past 90d): 1 | Contributors (cumulative): 16 | DMM Complexity: 1.0\n\nDIFF:\n@@ -140,10 +140,7 @@ def result_wrapper(result_fn):\n                 if isinstance(raw_result, (tf.Tensor, tf.Variable, float, int)):\n                     result_t = tf.identity(raw_result)\n                 elif isinstance(raw_result, dict):\n-                    result_t = {\n-                        key: tf.identity(value)\n-                        for key, value in raw_result.items()\n-                    }\n+                    result_t = tf.nest.map_structure(tf.identity, raw_result)\n                 else:\n                     try:\n                         result_t = tf.identity(raw_result)\n@@ -174,7 +171,7 @@ def result_wrapper(result_fn):\n                 # Wrapping result in identity so that control dependency between\n                 # update_op from `update_state` and result works in case result\n                 # returns a tensor.\n-                return tf.identity(result)\n+                return tf.nest.map_structure(tf.identity, result)\n \n             # Wrapping result in merge_call. merge_call is used when we want to\n             # leave replica mode and compute a value in cross replica mode.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#01903aa85090b0e99b6049531c8dcf431756b1f1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 112 | Contributors (this commit): 4 | Commits (past 90d): 4 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -35,4 +35,4 @@ class Identity(Layer):\n     \"\"\"\n \n     def call(self, inputs):\n-        return tf.identity(inputs)\n+        return tf.nest.map_structure(tf.identity, inputs)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5688b5a8aa8663a84dbde199035f034da4949bf9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 4 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -122,7 +122,7 @@ class Initializer:\n                     \"and being called multiple times, which will return \"\n                     \"identical values each time (even if the initializer is \"\n                     \"unseeded). Please update your code to provide a seed to \"\n-                    \"the initializer, or avoid using the same initalizer \"\n+                    \"the initializer, or avoid using the same initializer \"\n                     \"instance more than once.\"\n                 )\n         else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#138d645e5cd5d9193d7743665a2149a55de21848", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 3170 | Contributors (this commit): 10 | Commits (past 90d): 7 | Contributors (cumulative): 10 | DMM Complexity: 1.0\n\nDIFF:\n@@ -26,6 +26,7 @@ import numpy as np\n import tensorflow.compat.v2 as tf\n \n from keras import backend\n+from keras import initializers\n from keras import layers\n from keras import utils\n from keras.applications import imagenet_utils\n@@ -217,9 +218,11 @@ class LayerScale(layers.Layer):\n         self.projection_dim = projection_dim\n \n     def build(self, input_shape):\n-        self.gamma = tf.Variable(\n-            self.init_values * tf.ones((self.projection_dim,)),\n+        self.gamma = self.add_weight(\n+            shape=(self.projection_dim,),\n             dtype=self._compute_dtype_object,\n+            initializer=initializers.Constant(self.init_values),\n+            trainable=True,\n         )\n \n     def call(self, x):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#810fd3c203dbae8bb1f888ebc91cdd31ff30cf34", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 3171 | Contributors (this commit): 10 | Commits (past 90d): 8 | Contributors (cumulative): 10 | DMM Complexity: 0.0\n\nDIFF:\n@@ -220,7 +220,6 @@ class LayerScale(layers.Layer):\n     def build(self, input_shape):\n         self.gamma = self.add_weight(\n             shape=(self.projection_dim,),\n-            dtype=self._compute_dtype_object,\n             initializer=initializers.Constant(self.init_values),\n             trainable=True,\n         )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#882d4cf331b9b805164c704063df9aeb18413669", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 151 | Contributors (this commit): 5 | Commits (past 90d): 1 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -38,7 +38,7 @@ def _large_compatible_negative(tensor_type):\n       a large negative number.\n     \"\"\"\n     if tensor_type == tf.float16:\n-        return tf.float16.min\n+        return tf.float16.min / 2.0\n     return -1e9\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8c54abfd12936c005c0d01255d6cff45a4ae94a8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 154 | Contributors (this commit): 6 | Commits (past 90d): 2 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -37,6 +37,9 @@ def _large_compatible_negative(tensor_type):\n     Returns:\n       a large negative number.\n     \"\"\"\n+    # In case of dtype=float16 (e.g., for mixed-precision), the largest\n+    # negative number (dtypes.float16.min) is divided by 2, in order to\n+    # avoid overflows when summing negative inputs.\n     if tensor_type == tf.float16:\n         return tf.float16.min / 2.0\n     return -1e9\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#414cdd1e5ee574701aab6e4f5720747b52571427", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 209 | Lines Deleted: 1 | Files Changed: 3 | Hunks: 10 | Methods Changed: 4 | Complexity Δ (Sum/Max): 5/4 | Churn Δ: 210 | Churn Cumulative: 476 | Contributors (this commit): 20 | Commits (past 90d): 7 | Contributors (cumulative): 25 | DMM Complexity: 1.0\n\nDIFF:\n@@ -64,6 +64,7 @@ from keras.utils.data_utils import pad_sequences\n \n # Evaluation related\n from keras.utils.sidecar_evaluator import SidecarEvaluator\n+from keras.utils.sidecar_evaluator import SidecarEvaluatorModelExport\n \n # Visualization related\n from keras.utils.vis_utils import model_to_dot\n\n@@ -14,11 +14,14 @@\n # ==============================================================================\n \"\"\"Python module for evaluation loop.\"\"\"\n \n-import tensorflow.compat.v2 as tf\n+import re\n+\n+import tensorflow as tf\n \n # isort: off\n from tensorflow.python.platform import tf_logging as logging\n from tensorflow.python.util import deprecation\n+from keras.callbacks import ModelCheckpoint\n from keras.optimizers import optimizer\n from tensorflow.python.util.tf_export import keras_export\n \n@@ -327,3 +330,97 @@ class SidecarEvaluatorExperimental(SidecarEvaluator):\n             \"`tf.keras.utils.SidecarEvaluator`.\"\n         )\n         super().__init__(*args, **kwargs)\n+\n+\n+@keras_export(\"keras.callbacks.SidecarEvaluatorModelExport\")\n+class SidecarEvaluatorModelExport(ModelCheckpoint):\n+    \"\"\"Callback to save the best Keras model.\n+\n+    It expands the functionality of the existing ModelCheckpoint callback to\n+    enable exporting the best models after evaluation with validation dataset.\n+\n+    When using the `SidecarEvaluatorModelExport` callback in conjunction with\n+    `keras.utils.SidecarEvaluator`, users should provide the `filepath`, which\n+    is the path for this callback to export model or save weights to, and\n+    `ckpt_filepath`, which is where the checkpoint is available to extract\n+    the epoch number from. The callback will then export the model that the\n+    evaluator deems as the best (among the checkpoints saved by the training\n+    counterpart) to the specified `filepath`. This callback is intended to be\n+    used by SidecarEvaluator only.\n+\n+    Example:\n+\n+    ```python\n+    model.compile(loss=..., optimizer=...,\n+                  metrics=['accuracy'])\n+    sidecar_evaluator = keras.utils.SidecarEvaluator(\n+        model=model,\n+        data=dataset,\n+        checkpoint_dir=checkpoint_dir,\n+        max_evaluations=1,\n+        callbacks=[\n+            SidecarEvaluatorModelExport(\n+                export_filepath=os.path.join(checkpoint_dir,\n+                                      'best_model_eval',\n+                                      'best-model-{epoch:04d}'),\n+                checkpoint_filepath=os.path.join(checkpoint_dir,\n+                'ckpt-{epoch:04d}'),\n+                save_freq=\"eval\",\n+                save_weights_only=True,\n+                monitor=\"loss\",\n+                mode=\"min\",\n+                verbose=1,\n+            ),\n+        ],\n+    )\n+    sidecar_evaluator.start()\n+    # Model weights are saved if evaluator deems it's the best seen so far.\n+\n+    Args:\n+        export_filepath: Path where best models should be saved by this\n+          `SidecarEvaluatorModelExport` callback. Epoch formatting options, such\n+          as `os.path.join(best_model_dir, 'best-model-{epoch:04d}')`, can be\n+          used to allow saved model to preserve epoch information in the file\n+          name. SidecarEvaluatorModelExport will use the \"training epoch\" at\n+          which the checkpoint was saved by training to fill the epoch\n+          placeholder in the path.\n+        checkpoint_filepath: Path where checkpoints were saved by training. This\n+          should be the same as what is provided to `filepath` argument of\n+          `ModelCheckpoint` on the training side, such as\n+          `os.path.join(checkpoint_dir, 'ckpt-{epoch:04d}')`.\n+    \"\"\"\n+\n+    def __init__(self, export_filepath, checkpoint_filepath, **kwargs):\n+        super().__init__(\n+            filepath=export_filepath,\n+            save_best_only=True,\n+            **kwargs,\n+        )\n+\n+        self._checkpoint_filepath = checkpoint_filepath\n+\n+    def on_test_begin(self, logs=None):\n+        \"\"\"Updates export_index to the latest checkpoint.\"\"\"\n+\n+        most_recent_filepath = (\n+            self._get_most_recently_modified_file_matching_pattern(\n+                self._checkpoint_filepath\n+            )\n+        )\n+        if most_recent_filepath is not None:\n+            self.export_index = (\n+                int(\n+                    re.match(r\".*ckpt-(?P<ckpt>\\d+)\", most_recent_filepath)[\n+                        \"ckpt\"\n+                    ]\n+                )\n+                - 1\n+            )\n+        else:\n+            self.export_index = 0\n+\n+    def on_test_end(self, logs):\n+        \"\"\"Saves best model at the end of an evaluation epoch.\"\"\"\n+\n+        self.epochs_since_last_save += 1\n+        self._save_model(epoch=self.export_index, batch=None, logs=logs)\n\n@@ -16,6 +16,7 @@\n \n import enum\n import os\n+import shutil\n import threading\n import time\n \n@@ -25,13 +26,22 @@ from absl.testing import parameterized\n \n import keras\n from keras.optimizers import sgd\n+from keras.testing_infra import test_combinations\n from keras.testing_infra import test_utils\n+from keras.utils import np_utils\n from keras.utils import sidecar_evaluator as sidecar_evaluator_lib\n+from keras.utils.sidecar_evaluator import SidecarEvaluatorModelExport\n \n # isort: off\n from tensorflow.python.platform import tf_logging as logging\n \n _BATCH_SIZE = 32\n+TRAIN_SAMPLES = 20\n+TEST_SAMPLES = 20\n+INPUT_DIM = 3\n+NUM_CLASSES = 2\n+NUM_HIDDEN = 5\n+BATCH_SIZE = 5\n \n \n class TestModel(keras.Model):\n@@ -345,6 +355,106 @@ class SidecarEvaluatorTest(tf.test.TestCase, parameterized.TestCase):\n         )\n         self.assertIn(warning_msg, \"\\n\".join(warning_messages))\n \n+    @test_combinations.run_with_all_model_types\n+    def test_best_model_exporter_with_sidecarevaluator(self):\n+        temp_dir = self.get_temp_dir()\n+        self.addCleanup(shutil.rmtree, temp_dir, ignore_errors=True)\n+\n+        # Create a model with synthetic data, and fit for 20 epochs.\n+        layers = [\n+            keras.layers.Dense(\n+                NUM_HIDDEN, input_dim=INPUT_DIM, activation=\"relu\"\n+            ),\n+            keras.layers.Dense(NUM_CLASSES, activation=\"softmax\"),\n+        ]\n+        model = test_utils.get_model_from_layers(layers, input_shape=(3,))\n+        model.compile(\n+            loss=\"categorical_crossentropy\",\n+            optimizer=\"rmsprop\",\n+            metrics=[\"acc\"],\n+        )\n+\n+        (x_train, y_train), (x_test, y_test) = test_utils.get_test_data(\n+            train_samples=TRAIN_SAMPLES,\n+            test_samples=TEST_SAMPLES,\n+            input_shape=(INPUT_DIM,),\n+            num_classes=NUM_CLASSES,\n+        )\n+        y_test = np_utils.to_categorical(y_test)\n+        y_train = np_utils.to_categorical(y_train)\n+\n+        callbacks = [\n+            keras.callbacks.ModelCheckpoint(\n+                filepath=os.path.join(\n+                    os.path.join(temp_dir, \"ckpt\"), \"ckpt-{epoch:04d}\"\n+                ),\n+                monitor=\"loss\",\n+                save_best_only=True,\n+                save_weights_only=True,\n+                save_freq=\"epoch\",\n+                mode=\"min\",\n+            )\n+        ]\n+\n+        model.fit(\n+            x_train,\n+            y_train,\n+            batch_size=BATCH_SIZE,\n+            validation_data=(x_test, y_test),\n+            callbacks=callbacks,\n+            epochs=20,\n+            verbose=0,\n+        )\n+        self.assertNotEmpty(\n+            tf.io.gfile.listdir(os.path.join(temp_dir, \"ckpt\")),\n+            \"Checkpoints should have been written and \"\n+            \"checkpoint_dir should not be empty.\",\n+        )\n+\n+        # Have a sidecar_evaluator evaluate once.\n+        dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n+        dataset = dataset.batch(BATCH_SIZE)\n+        sidecar_evaluator = keras.utils.SidecarEvaluator(\n+            model=model,\n+            data=dataset,\n+            checkpoint_dir=os.path.join(temp_dir, \"ckpt\"),\n+            max_evaluations=1,\n+            callbacks=[\n+                SidecarEvaluatorModelExport(\n+                    export_filepath=os.path.join(\n+                        os.path.join(temp_dir, \"ckpt\"),\n+                        \"best_model_eval\",\n+                        \"best-model-{epoch:04d}\",\n+                    ),\n+                    checkpoint_filepath=os.path.join(\n+                        os.path.join(temp_dir, \"ckpt\"), \"ckpt-{epoch:04d}\"\n+                    ),\n+                    save_weights_only=False,\n+                    monitor=\"loss\",\n+                    mode=\"min\",\n+                    verbose=1,\n+                ),\n+            ],\n+        )\n+        sidecar_evaluator.start()\n+\n+        # Asserts output directory exists.\n+        assert os.path.exists(\n+            os.path.join(os.path.join(temp_dir, \"ckpt\"), \"best_model_eval\")\n+        )\n+\n+        # Asserts best model files do get written.\n+        self.assertRegex(\n+            str(\n+                tf.io.gfile.listdir(\n+                    os.path.join(\n+                        os.path.join(temp_dir, \"ckpt\"), \"best_model_eval\"\n+                    )\n+                )\n+            ),\n+            r\"(.*best-model.*)+\",\n+        )\n+\n \n if __name__ == \"__main__\":\n     tf.test.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
