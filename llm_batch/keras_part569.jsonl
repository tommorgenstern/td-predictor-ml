{"custom_id": "keras#07504d53a8e9eb1da73659ea4871a5a1275dbd2a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 316 | Lines Deleted: 19 | Files Changed: 3 | Hunks: 17 | Methods Changed: 18 | Complexity Δ (Sum/Max): 22/15 | Churn Δ: 335 | Churn Cumulative: 1516 | Contributors (this commit): 5 | Commits (past 90d): 30 | Contributors (cumulative): 9 | DMM Complexity: 1.0\n\nDIFF:\n@@ -8,6 +8,7 @@ from keras_core.metrics.accuracy_metrics import TopKCategoricalAccuracy\n from keras_core.metrics.confusion_metrics import FalseNegatives\n from keras_core.metrics.confusion_metrics import FalsePositives\n from keras_core.metrics.confusion_metrics import Precision\n+from keras_core.metrics.confusion_metrics import Recall\n from keras_core.metrics.confusion_metrics import TrueNegatives\n from keras_core.metrics.confusion_metrics import TruePositives\n from keras_core.metrics.hinge_metrics import CategoricalHinge\n@@ -39,6 +40,7 @@ ALL_OBJECTS = {\n     FalseNegatives,\n     FalsePositives,\n     Precision,\n+    Recall,\n     TrueNegatives,\n     TruePositives,\n     # Hinge\n\n@@ -14,9 +14,9 @@ class _ConfusionMatrixConditionCount(Metric):\n         confusion_matrix_cond: One of `metrics_utils.ConfusionMatrix`\n             conditions.\n         thresholds: (Optional) Defaults to 0.5. A float value or a python list /\n-            tuple of float threshold values in [0, 1]. A threshold is compared\n+            tuple of float threshold values in `[0, 1]`. A threshold is compared\n             with prediction values to determine the truth value of predictions\n-            (i.e., above the threshold is `true`, below is `false`). One metric\n+            (i.e., above the threshold is `True`, below is `False`). One metric\n             value is generated for each threshold value.\n         name: (Optional) string name of the metric instance.\n         dtype: (Optional) data type of the metric result.\n@@ -85,9 +85,9 @@ class FalsePositives(_ConfusionMatrixConditionCount):\n \n     Args:\n         thresholds: (Optional) Defaults to 0.5. A float value, or a Python\n-            list/tuple of float threshold values in [0, 1]. A threshold is\n+            list/tuple of float threshold values in `[0, 1]`. A threshold is\n             compared with prediction values to determine the truth value of\n-            predictions (i.e., above the threshold is `true`, below is `false`).\n+            predictions (i.e., above the threshold is `True`, below is `False`).\n             If used with a loss function that sets `from_logits=True` (i.e. no\n             sigmoid applied to predictions), `thresholds` should be set to 0.\n             One metric value is generated for each threshold value.\n@@ -129,9 +129,9 @@ class FalseNegatives(_ConfusionMatrixConditionCount):\n \n     Args:\n         thresholds: (Optional) Defaults to 0.5. A float value, or a Python\n-            list/tuple of float threshold values in [0, 1]. A threshold is\n+            list/tuple of float threshold values in `[0, 1]`. A threshold is\n             compared with prediction values to determine the truth value of\n-            predictions (i.e., above the threshold is `true`, below is `false`).\n+            predictions (i.e., above the threshold is `True`, below is `False`).\n             If used with a loss function that sets `from_logits=True` (i.e. no\n             sigmoid applied to predictions), `thresholds` should be set to 0.\n             One metric value is generated for each threshold value.\n@@ -173,9 +173,9 @@ class TrueNegatives(_ConfusionMatrixConditionCount):\n \n     Args:\n         thresholds: (Optional) Defaults to 0.5. A float value, or a Python\n-            list/tuple of float threshold values in [0, 1]. A threshold is\n+            list/tuple of float threshold values in `[0, 1]`. A threshold is\n             compared with prediction values to determine the truth value of\n-            predictions (i.e., above the threshold is `true`, below is `false`).\n+            predictions (i.e., above the threshold is `True`, below is `False`).\n             If used with a loss function that sets `from_logits=True` (i.e. no\n             sigmoid applied to predictions), `thresholds` should be set to 0.\n             One metric value is generated for each threshold value.\n@@ -217,9 +217,9 @@ class TruePositives(_ConfusionMatrixConditionCount):\n \n     Args:\n         thresholds: (Optional) Defaults to 0.5. A float value, or a Python\n-            list/tuple of float threshold values in [0, 1]. A threshold is\n+            list/tuple of float threshold values in `[0, 1]`. A threshold is\n             compared with prediction values to determine the truth value of\n-            predictions (i.e., above the threshold is `true`, below is `false`).\n+            predictions (i.e., above the threshold is `True`, below is `False`).\n             If used with a loss function that sets `from_logits=True` (i.e. no\n             sigmoid applied to predictions), `thresholds` should be set to 0.\n             One metric value is generated for each threshold value.\n@@ -272,13 +272,13 @@ class Precision(Metric):\n \n     Args:\n         thresholds: (Optional) A float value, or a Python list/tuple of float\n-            threshold values in [0, 1]. A threshold is compared with prediction\n-            values to determine the truth value of predictions (i.e., above the\n-            threshold is `true`, below is `false`). If used with a loss function\n-            that sets `from_logits=True` (i.e. no sigmoid applied to\n-            predictions), `thresholds` should be set to 0. One metric value is\n-            generated for each threshold value. If neither thresholds nor top_k\n-            are set, the default is to calculate precision with\n+            threshold values in `[0, 1]`. A threshold is compared with\n+            prediction values to determine the truth value of predictions (i.e.,\n+            above the threshold is `True`, below is `False`). If used with a\n+            loss function that sets `from_logits=True` (i.e. no sigmoid applied\n+            to predictions), `thresholds` should be set to 0. One metric value\n+            is generated for each threshold value. If neither thresholds nor\n+            top_k are set, the default is to calculate precision with\n             `thresholds=0.5`.\n         top_k: (Optional) Unset by default. An int value specifying the top-k\n             predictions to consider when calculating precision.\n@@ -326,7 +326,7 @@ class Precision(Metric):\n \n     ```python\n     model.compile(optimizer='adam',\n-                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n+                  loss=keras_core.losses.BinaryCrossentropy(from_logits=True),\n                   metrics=[keras_core.metrics.Precision(thresholds=0)])\n     ```\n     \"\"\"\n@@ -369,7 +369,7 @@ class Precision(Metric):\n                 Can be a `Tensor` whose rank is either 0, or the same rank as\n                 `y_true`, and must be broadcastable to `y_true`.\n         \"\"\"\n-        return metrics_utils.update_confusion_matrix_variables(\n+        metrics_utils.update_confusion_matrix_variables(\n             {\n                 metrics_utils.ConfusionMatrix.TRUE_POSITIVES: self.true_positives,  # noqa: E501\n                 metrics_utils.ConfusionMatrix.FALSE_POSITIVES: self.false_positives,  # noqa: E501\n@@ -403,3 +403,143 @@ class Precision(Metric):\n         }\n         base_config = super().get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n+\n+\n+@keras_core_export(\"keras_core.metrics.Recall\")\n+class Recall(Metric):\n+    \"\"\"Computes the recall of the predictions with respect to the labels.\n+\n+    This metric creates two local variables, `true_positives` and\n+    `false_negatives`, that are used to compute the recall. This value is\n+    ultimately returned as `recall`, an idempotent operation that simply divides\n+    `true_positives` by the sum of `true_positives` and `false_negatives`.\n+\n+    If `sample_weight` is `None`, weights default to 1.\n+    Use `sample_weight` of 0 to mask values.\n+\n+    If `top_k` is set, recall will be computed as how often on average a class\n+    among the labels of a batch entry is in the top-k predictions.\n+\n+    If `class_id` is specified, we calculate recall by considering only the\n+    entries in the batch for which `class_id` is in the label, and computing the\n+    fraction of them for which `class_id` is above the threshold and/or in the\n+    top-k predictions.\n+\n+    Args:\n+        thresholds: (Optional) A float value, or a Python list/tuple of float\n+            threshold values in `[0, 1]`. A threshold is compared with\n+            prediction values to determine the truth value of predictions (i.e.,\n+            above thethreshold is `True`, below is `False`). If used with a loss\n+            function that sets `from_logits=True` (i.e. no sigmoid applied to\n+            predictions), `thresholds` should be set to 0. One metric value is\n+            generated for each threshold value. If neither thresholds nor top_k\n+            are set, the default is to calculate recall with `thresholds=0.5`.\n+        top_k: (Optional) Unset by default. An int value specifying the top-k\n+            predictions to consider when calculating recall.\n+        class_id: (Optional) Integer class ID for which we want binary metrics.\n+            This must be in the half-open interval `[0, num_classes)`, where\n+            `num_classes` is the last dimension of predictions.\n+        name: (Optional) string name of the metric instance.\n+        dtype: (Optional) data type of the metric result.\n+\n+    Standalone usage:\n+\n+    >>> m = keras_core.metrics.Recall()\n+    >>> m.update_state([0, 1, 1, 1], [1, 0, 1, 1])\n+    >>> m.result()\n+    0.6666667\n+\n+    >>> m.reset_state()\n+    >>> m.update_state([0, 1, 1, 1], [1, 0, 1, 1], sample_weight=[0, 0, 1, 0])\n+    >>> m.result()\n+    1.0\n+\n+    Usage with `compile()` API:\n+\n+    ```python\n+    model.compile(optimizer='sgd',\n+                  loss='mse',\n+                  metrics=[keras_core.metrics.Recall()])\n+    ```\n+\n+    Usage with a loss with `from_logits=True`:\n+\n+    ```python\n+    model.compile(optimizer='adam',\n+                  loss=keras_core.losses.BinaryCrossentropy(from_logits=True),\n+                  metrics=[keras_core.metrics.Recall(thresholds=0)])\n+    ```\n+    \"\"\"\n+\n+    def __init__(\n+        self, thresholds=None, top_k=None, class_id=None, name=None, dtype=None\n+    ):\n+        super().__init__(name=name, dtype=dtype)\n+        self.init_thresholds = thresholds\n+        self.top_k = top_k\n+        self.class_id = class_id\n+\n+        default_threshold = 0.5 if top_k is None else metrics_utils.NEG_INF\n+        self.thresholds = metrics_utils.parse_init_thresholds(\n+            thresholds, default_threshold=default_threshold\n+        )\n+        self._thresholds_distributed_evenly = (\n+            metrics_utils.is_evenly_distributed_thresholds(self.thresholds)\n+        )\n+        self.true_positives = self.add_variable(\n+            shape=(len(self.thresholds),),\n+            initializer=initializers.Zeros(),\n+            name=\"true_positives\",\n+        )\n+        self.false_negatives = self.add_variable(\n+            shape=(len(self.thresholds),),\n+            initializer=initializers.Zeros(),\n+            name=\"false_negatives\",\n+        )\n+\n+    def update_state(self, y_true, y_pred, sample_weight=None):\n+        \"\"\"Accumulates true positive and false negative statistics.\n+\n+        Args:\n+            y_true: The ground truth values, with the same dimensions as\n+                `y_pred`. Will be cast to `bool`.\n+            y_pred: The predicted values. Each element must be in the range\n+                `[0, 1]`.\n+            sample_weight: Optional weighting of each example. Defaults to 1.\n+                Can be a `Tensor` whose rank is either 0, or the same rank as\n+                `y_true`, and must be broadcastable to `y_true`.\n+        \"\"\"\n+        metrics_utils.update_confusion_matrix_variables(\n+            {\n+                metrics_utils.ConfusionMatrix.TRUE_POSITIVES: self.true_positives,  # noqa: E501\n+                metrics_utils.ConfusionMatrix.FALSE_NEGATIVES: self.false_negatives,  # noqa: E501\n+            },\n+            y_true,\n+            y_pred,\n+            thresholds=self.thresholds,\n+            thresholds_distributed_evenly=self._thresholds_distributed_evenly,\n+            top_k=self.top_k,\n+            class_id=self.class_id,\n+            sample_weight=sample_weight,\n+        )\n+\n+    def result(self):\n+        result = ops.divide(\n+            self.true_positives,\n+            self.true_positives + self.false_negatives + backend.epsilon(),\n+        )\n+        return result[0] if len(self.thresholds) == 1 else result\n+\n+    def reset_state(self):\n+        num_thresholds = len(to_list(self.thresholds))\n+        self.true_positives.assign(ops.zeros((num_thresholds,)))\n+        self.false_negatives.assign(ops.zeros((num_thresholds,)))\n+\n+    def get_config(self):\n+        config = {\n+            \"thresholds\": self.init_thresholds,\n+            \"top_k\": self.top_k,\n+            \"class_id\": self.class_id,\n+        }\n+        base_config = super().get_config()\n+        return dict(list(base_config.items()) + list(config.items()))\n\n@@ -534,3 +534,158 @@ class PrecisionTest(testing.TestCase):\n         self.assertAlmostEqual(1, result)\n         self.assertAlmostEqual(1, p_obj.true_positives)\n         self.assertAlmostEqual(0, p_obj.false_positives)\n+\n+\n+class RecallTest(testing.TestCase):\n+    def test_config(self):\n+        r_obj = metrics.Recall(\n+            name=\"my_recall\", thresholds=[0.4, 0.9], top_k=15, class_id=12\n+        )\n+        self.assertEqual(r_obj.name, \"my_recall\")\n+        self.assertLen(r_obj.variables, 2)\n+        self.assertEqual(\n+            [v.name for v in r_obj.variables],\n+            [\"true_positives\", \"false_negatives\"],\n+        )\n+        self.assertEqual(r_obj.thresholds, [0.4, 0.9])\n+        self.assertEqual(r_obj.top_k, 15)\n+        self.assertEqual(r_obj.class_id, 12)\n+\n+        # Check save and restore config\n+        r_obj2 = metrics.Recall.from_config(r_obj.get_config())\n+        self.assertEqual(r_obj2.name, \"my_recall\")\n+        self.assertLen(r_obj2.variables, 2)\n+        self.assertEqual(r_obj2.thresholds, [0.4, 0.9])\n+        self.assertEqual(r_obj2.top_k, 15)\n+        self.assertEqual(r_obj2.class_id, 12)\n+\n+    def test_unweighted(self):\n+        r_obj = metrics.Recall()\n+        y_pred = np.array([1, 0, 1, 0])\n+        y_true = np.array([0, 1, 1, 0])\n+        self.assertAlmostEqual(0.5, r_obj(y_true, y_pred))\n+\n+    def test_unweighted_all_incorrect(self):\n+        r_obj = metrics.Recall(thresholds=[0.5])\n+        inputs = np.random.randint(0, 2, size=(100, 1))\n+        y_pred = np.array(inputs)\n+        y_true = np.array(1 - inputs)\n+        self.assertAlmostEqual(0, r_obj(y_true, y_pred))\n+\n+    def test_weighted(self):\n+        r_obj = metrics.Recall()\n+        y_pred = np.array([[1, 0, 1, 0], [0, 1, 0, 1]])\n+        y_true = np.array([[0, 1, 1, 0], [1, 0, 0, 1]])\n+        result = r_obj(\n+            y_true,\n+            y_pred,\n+            sample_weight=np.array([[1, 2, 3, 4], [4, 3, 2, 1]]),\n+        )\n+        weighted_tp = 3.0 + 1.0\n+        weighted_t = (2.0 + 3.0) + (4.0 + 1.0)\n+        expected_recall = weighted_tp / weighted_t\n+        self.assertAlmostEqual(expected_recall, result)\n+\n+    def test_div_by_zero(self):\n+        r_obj = metrics.Recall()\n+        y_pred = np.array([0, 0, 0, 0])\n+        y_true = np.array([0, 0, 0, 0])\n+        self.assertEqual(0, r_obj(y_true, y_pred))\n+\n+    def test_unweighted_with_threshold(self):\n+        r_obj = metrics.Recall(thresholds=[0.5, 0.7])\n+        y_pred = np.array([1, 0, 0.6, 0])\n+        y_true = np.array([0, 1, 1, 0])\n+        self.assertAllClose([0.5, 0.0], r_obj(y_true, y_pred), 0)\n+\n+    def test_weighted_with_threshold(self):\n+        r_obj = metrics.Recall(thresholds=[0.5, 1.0])\n+        y_true = np.array([[0, 1], [1, 0]])\n+        y_pred = np.array([[1, 0], [0.6, 0]], dtype=\"float32\")\n+        weights = np.array([[1, 4], [3, 2]], dtype=\"float32\")\n+        result = r_obj(y_true, y_pred, sample_weight=weights)\n+        weighted_tp = 0 + 3.0\n+        weighted_positives = (0 + 3.0) + (4.0 + 0.0)\n+        expected_recall = weighted_tp / weighted_positives\n+        self.assertAllClose([expected_recall, 0], result, 1e-3)\n+\n+    def test_multiple_updates(self):\n+        r_obj = metrics.Recall(thresholds=[0.5, 1.0])\n+        y_true = np.array([[0, 1], [1, 0]])\n+        y_pred = np.array([[1, 0], [0.6, 0]], dtype=\"float32\")\n+        weights = np.array([[1, 4], [3, 2]], dtype=\"float32\")\n+        for _ in range(2):\n+            r_obj.update_state(y_true, y_pred, sample_weight=weights)\n+\n+        weighted_tp = (0 + 3.0) + (0 + 3.0)\n+        weighted_positives = ((0 + 3.0) + (4.0 + 0.0)) + (\n+            (0 + 3.0) + (4.0 + 0.0)\n+        )\n+        expected_recall = weighted_tp / weighted_positives\n+        self.assertAllClose([expected_recall, 0], r_obj.result(), 1e-3)\n+\n+    def test_unweighted_top_k(self):\n+        r_obj = metrics.Recall(top_k=3)\n+        y_pred = np.array([0.2, 0.1, 0.5, 0, 0.2])\n+        y_true = np.array([0, 1, 1, 0, 0])\n+        self.assertAlmostEqual(0.5, r_obj(y_true, y_pred))\n+\n+    def test_weighted_top_k(self):\n+        r_obj = metrics.Recall(top_k=3)\n+        y_pred1 = np.array([[0.2, 0.1, 0.4, 0, 0.2]])\n+        y_true1 = np.array([[0, 1, 1, 0, 1]])\n+        r_obj(y_true1, y_pred1, sample_weight=np.array([[1, 4, 2, 3, 5]]))\n+\n+        y_pred2 = np.array([0.2, 0.6, 0.4, 0.2, 0.2])\n+        y_true2 = np.array([1, 0, 1, 1, 1])\n+        result = r_obj(y_true2, y_pred2, sample_weight=np.array(3))\n+\n+        tp = (2 + 5) + (3 + 3)\n+        positives = (4 + 2 + 5) + (3 + 3 + 3 + 3)\n+        expected_recall = tp / positives\n+        self.assertAlmostEqual(expected_recall, result)\n+\n+    def test_unweighted_class_id(self):\n+        r_obj = metrics.Recall(class_id=2)\n+\n+        y_pred = np.array([0.2, 0.1, 0.6, 0, 0.2])\n+        y_true = np.array([0, 1, 1, 0, 0])\n+        self.assertAlmostEqual(1, r_obj(y_true, y_pred))\n+        self.assertAlmostEqual(1, r_obj.true_positives)\n+        self.assertAlmostEqual(0, r_obj.false_negatives)\n+\n+        y_pred = np.array([0.2, 0.1, 0, 0, 0.2])\n+        y_true = np.array([0, 1, 1, 0, 0])\n+        self.assertAlmostEqual(0.5, r_obj(y_true, y_pred))\n+        self.assertAlmostEqual(1, r_obj.true_positives)\n+        self.assertAlmostEqual(1, r_obj.false_negatives)\n+\n+        y_pred = np.array([0.2, 0.1, 0.6, 0, 0.2])\n+        y_true = np.array([0, 1, 0, 0, 0])\n+        self.assertAlmostEqual(0.5, r_obj(y_true, y_pred))\n+        self.assertAlmostEqual(1, r_obj.true_positives)\n+        self.assertAlmostEqual(1, r_obj.false_negatives)\n+\n+    def test_unweighted_top_k_and_class_id(self):\n+        r_obj = metrics.Recall(class_id=2, top_k=2)\n+\n+        y_pred = np.array([0.2, 0.6, 0.3, 0, 0.2])\n+        y_true = np.array([0, 1, 1, 0, 0])\n+        self.assertAlmostEqual(1, r_obj(y_true, y_pred))\n+        self.assertAlmostEqual(1, r_obj.true_positives)\n+        self.assertAlmostEqual(0, r_obj.false_negatives)\n+\n+        y_pred = np.array([1, 1, 0.9, 1, 1])\n+        y_true = np.array([0, 1, 1, 0, 0])\n+        self.assertAlmostEqual(0.5, r_obj(y_true, y_pred))\n+        self.assertAlmostEqual(1, r_obj.true_positives)\n+        self.assertAlmostEqual(1, r_obj.false_negatives)\n+\n+    def test_unweighted_top_k_and_threshold(self):\n+        r_obj = metrics.Recall(thresholds=0.7, top_k=2)\n+\n+        y_pred = np.array([0.2, 0.8, 0.6, 0, 0.2])\n+        y_true = np.array([1, 1, 1, 0, 1])\n+        self.assertAlmostEqual(0.25, r_obj(y_true, y_pred))\n+        self.assertAlmostEqual(1, r_obj.true_positives)\n+        self.assertAlmostEqual(3, r_obj.false_negatives)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ae105069a33a2adbfcfd44edfa3c0d696c3a05ca", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 15 | Churn Cumulative: 600 | Contributors (this commit): 3 | Commits (past 90d): 6 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -277,8 +277,8 @@ class Precision(Metric):\n             above the threshold is `True`, below is `False`). If used with a\n             loss function that sets `from_logits=True` (i.e. no sigmoid applied\n             to predictions), `thresholds` should be set to 0. One metric value\n-            is generated for each threshold value. If neither thresholds nor\n-            top_k are set, the default is to calculate precision with\n+            is generated for each threshold value. If neither `thresholds` nor\n+            `top_k` are set, the default is to calculate precision with\n             `thresholds=0.5`.\n         top_k: (Optional) Unset by default. An int value specifying the top-k\n             predictions to consider when calculating precision.\n@@ -429,11 +429,12 @@ class Recall(Metric):\n         thresholds: (Optional) A float value, or a Python list/tuple of float\n             threshold values in `[0, 1]`. A threshold is compared with\n             prediction values to determine the truth value of predictions (i.e.,\n-            above thethreshold is `True`, below is `False`). If used with a loss\n-            function that sets `from_logits=True` (i.e. no sigmoid applied to\n-            predictions), `thresholds` should be set to 0. One metric value is\n-            generated for each threshold value. If neither thresholds nor top_k\n-            are set, the default is to calculate recall with `thresholds=0.5`.\n+            above the threshold is `True`, below is `False`). If used with a\n+            loss function that sets `from_logits=True` (i.e. no sigmoid\n+            applied to predictions), `thresholds` should be set to 0.\n+            One metric value is generated for each threshold value.\n+            If neither `thresholds` nor `top_k` are set,\n+            the default is to calculate recall with `thresholds=0.5`.\n         top_k: (Optional) Unset by default. An int value specifying the top-k\n             predictions to consider when calculating recall.\n         class_id: (Optional) Integer class ID for which we want binary metrics.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b805a5d2d816cc2f078c0c8dea965e7952331935", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 678 | Lines Deleted: 4 | Files Changed: 3 | Hunks: 4 | Methods Changed: 43 | Complexity Δ (Sum/Max): 96/82 | Churn Δ: 682 | Churn Cumulative: 1006 | Contributors (this commit): 2 | Commits (past 90d): 11 | Contributors (cumulative): 4 | DMM Complexity: 0.756838905775076\n\nDIFF:\n@@ -15,9 +15,7 @@ except ImportError:\n \n \n class ArrayDataAdapter(DataAdapter):\n-    \"\"\"Adapter that handles array-like objects,\n-    e.g. tf.Tensor and NumPy arrays.\n-    \"\"\"\n+    \"\"\"Adapter for array-like objects, e.g. TF/JAX Tensors, NumPy arrays.\"\"\"\n \n     def __init__(\n         self,\n@@ -27,7 +25,7 @@ class ArrayDataAdapter(DataAdapter):\n         batch_size=None,\n         steps=None,\n         shuffle=False,\n-        class_weight=None,  # TODO\n+        class_weight=None,\n     ):\n         types_struct = nest.map_structure(lambda x: type(x), x)\n         flat_types = nest.flatten(types_struct)\n\n@@ -0,0 +1,554 @@\n+import multiprocessing\n+import queue\n+import random\n+import threading\n+import time\n+import weakref\n+from contextlib import closing\n+\n+import numpy as np\n+import tensorflow as tf\n+\n+from keras_core.api_export import keras_core_export\n+from keras_core.trainers.data_adapters.data_adapter import DataAdapter\n+\n+\n+@keras_core_export([\"keras_core.utils.PyDataset\", \"keras_core.utils.Sequence\"])\n+class PyDataset:\n+    \"\"\"Base class for defining a parallel dataset using Python code.\n+\n+    Every `PyDataset` must implement the `__getitem__()` and the `__len__()`\n+    methods. If you want to modify your dataset between epochs,\n+    you may additionally implement `on_epoch_end()`.\n+    The `__getitem__()` method should return a complete batch\n+    (not a single sample), and the `__len__` method should return\n+    the number of batches in the dataset (rather than the number of samples).\n+\n+    Args:\n+        workers: Number of workers to use in multithreading or\n+            multiprocessing.\n+        use_multiprocessing: Whether to use Python multiprocessing for\n+            parallelism. Setting this to `True` means that your\n+            dataset will be replicated in multiple forked processes.\n+            This is necessary to gain compute-level (rather than I/O level)\n+            benefits from parallelism. However it can only be set to\n+            `True` if your dataset can be safely pickled.\n+        max_queue_size: Maximum number of batches to keep in the queue\n+            when iterating over the dataset in a multithreaded or\n+            multipricessed setting.\n+            Reduce this value to reduce the CPU memory consumption of\n+            your dataset. Defaults to 10.\n+\n+    Notes:\n+\n+    - `PyDataset` is a safer way to do multiprocessing.\n+        This structure guarantees that the model will only train\n+        once on each sample per epoch, which is not the case\n+        with Python generators.\n+    - The arguments `workers`, `use_multiprocessing`, and `max_queue_size`\n+        exist to configure how `fit()` uses parallelism to iterate\n+        over the dataset. They are not being used by the `PyDataset` class\n+        directly. When you are manually iterating over a `PyDataset`,\n+        no parallelism is applied.\n+\n+    Example:\n+\n+    ```python\n+    from skimage.io import imread\n+    from skimage.transform import resize\n+    import numpy as np\n+    import math\n+\n+    # Here, `x_set` is list of path to the images\n+    # and `y_set` are the associated classes.\n+\n+    class CIFAR10PyDataset(keras_core.utils.PyDataset):\n+\n+        def __init__(self, x_set, y_set, batch_size, **kwargs):\n+            super().__init__(**kwargs)\n+            self.x, self.y = x_set, y_set\n+            self.batch_size = batch_size\n+\n+        def __len__(self):\n+            # Return number of batches.\n+            return math.ceil(len(self.x) / self.batch_size)\n+\n+        def __getitem__(self, idx):\n+            # Return x, y for batch idx.\n+            low = idx * self.batch_size\n+            # Cap upper bound at array length; the last batch may be smaller\n+            # if the total number of items is not a multiple of batch size.\n+            high = min(low + self.batch_size, len(self.x))\n+            batch_x = self.x[low:high]\n+            batch_y = self.y[low:high]\n+\n+            return np.array([\n+                resize(imread(file_name), (200, 200))\n+                   for file_name in batch_x]), np.array(batch_y)\n+    ```\n+    \"\"\"\n+\n+    def __init__(self, workers=1, use_multiprocessing=False, max_queue_size=10):\n+        self._workers = workers\n+        self._use_multiprocessing = use_multiprocessing\n+        self._max_queue_size = max_queue_size\n+\n+    def _raise_if_super_not_called(self):\n+        raise RuntimeError(\n+            \"Your `PyDataset` class should call \"\n+            \"`super().__init__(**kwargs)` in its constructor. \"\n+            \"`**kwargs` can include `workers`, \"\n+            \"`use_multiprocessing`, `max_queue_size`.\"\n+        )\n+\n+    @property\n+    def workers(self):\n+        if not hasattr(self, \"_workers\"):\n+            self._raise_if_super_not_called()\n+        return self._workers\n+\n+    @workers.setter\n+    def workers(self, value):\n+        self._workers = value\n+\n+    @property\n+    def use_multiprocessing(self):\n+        if not hasattr(self, \"_use_multiprocessing\"):\n+            self._raise_if_super_not_called()\n+        return self._use_multiprocessing\n+\n+    @use_multiprocessing.setter\n+    def use_multiprocessing(self, value):\n+        self._use_multiprocessing = value\n+\n+    @property\n+    def max_queue_size(self):\n+        if not hasattr(self, \"_max_queue_size\"):\n+            self._raise_if_super_not_called()\n+        return self._max_queue_size\n+\n+    @max_queue_size.setter\n+    def max_queue_size(self, value):\n+        self._max_queue_size = value\n+\n+    def __getitem__(self, index):\n+        \"\"\"Gets batch at position `index`.\n+\n+        Args:\n+            index: position of the batch in the PyDataset.\n+\n+        Returns:\n+            A batch\n+        \"\"\"\n+        raise NotImplementedError\n+\n+    def __len__(self):\n+        \"\"\"Number of batch in the PyDataset.\n+\n+        Returns:\n+            The number of batches in the PyDataset.\n+        \"\"\"\n+        raise NotImplementedError\n+\n+    def on_epoch_end(self):\n+        \"\"\"Method called at the end of every epoch.\"\"\"\n+        pass\n+\n+    def __iter__(self):\n+        \"\"\"Create a generator that iterate over the PyDataset.\"\"\"\n+        for i in range(len(self)):\n+            yield self[i]\n+\n+\n+class PyDatasetAdapter(DataAdapter):\n+    \"\"\"Adapter for `keras_core.utils.PyDataset` instances.\"\"\"\n+\n+    def __init__(\n+        self,\n+        x,\n+        shuffle=False,\n+    ):\n+        self.py_dataset = x\n+        self.enqueuer = None\n+        self.shuffle = shuffle\n+\n+        # Grab the first example\n+        data = self.py_dataset[0]\n+        if not isinstance(data, tuple):\n+            raise ValueError(\n+                \"PyDataset.__getitem__() must return a tuple, either \"\n+                \"(input,) or (inputs, targets) or \"\n+                \"(inputs, targets, sample_weights). \"\n+                f\"Received: {data}\"\n+            )\n+\n+        def get_tensor_spec(x):\n+            shape = x.shape\n+            if len(shape) < 1:\n+                raise ValueError(\n+                    \"The arrays returned by PyDataset.__getitem__() \"\n+                    \"must be at least rank 1. Received: \"\n+                    f\"{x} of rank {len(x.shape)}\"\n+                )\n+            shape = list(shape)\n+            shape[0] = None  # The batch size is not guaranteed to be static.\n+            return tf.TensorSpec(shape=shape, dtype=x.dtype.name)\n+\n+        self._output_signature = tf.nest.map_structure(get_tensor_spec, data)\n+\n+    def _make_multiprocessed_generator_fn(self):\n+        workers = self.py_dataset.workers\n+        use_multiprocessing = self.py_dataset.use_multiprocessing\n+        if workers > 1 or (workers > 0 and use_multiprocessing):\n+\n+            def generator_fn():\n+                self.enqueuer = OrderedEnqueuer(\n+                    self.py_dataset,\n+                    use_multiprocessing=use_multiprocessing,\n+                    shuffle=self.shuffle,\n+                )\n+                self.enqueuer.start(\n+                    workers=workers,\n+                    max_queue_size=self.py_dataset.max_queue_size,\n+                )\n+                return self.enqueuer.get()\n+\n+        else:\n+\n+            def generator_fn():\n+                order = range(len(self.py_dataset))\n+                if self.shuffle:\n+                    # Match the shuffle convention in OrderedEnqueuer.\n+                    order = list(order)\n+                    random.shuffle(order)\n+\n+                for i in order:\n+                    yield self.py_dataset[i]\n+\n+        return generator_fn\n+\n+    def get_numpy_iterator(self):\n+        gen_fn = self._make_multiprocessed_generator_fn()\n+        for i, batch in enumerate(gen_fn()):\n+            yield batch\n+            if i >= len(self.py_dataset) - 1 and self.enqueuer:\n+                self.enqueuer.stop()\n+\n+    def get_tf_dataset(self):\n+        ds = tf.data.Dataset.from_generator(\n+            self.get_numpy_iterator,\n+            output_signature=self._output_signature,\n+        )\n+        if self.shuffle:\n+            ds = ds.shuffle(8)\n+        ds = ds.prefetch(tf.data.AUTOTUNE)\n+        return ds\n+\n+    def on_epoch_end(self):\n+        if self.enqueuer:\n+            self.enqueuer.stop()\n+        self._py_dataset.on_epoch_end()\n+\n+    @property\n+    def num_batches(self):\n+        return len(self._py_dataset)\n+\n+    @property\n+    def batch_size(self):\n+        return None\n+\n+\n+# Global variables to be shared across processes\n+_SHARED_SEQUENCES = {}\n+# We use a Value to provide unique id to different processes.\n+_SEQUENCE_COUNTER = None\n+\n+\n+# Because multiprocessing pools are inherently unsafe, starting from a clean\n+# state can be essential to avoiding deadlocks. In order to accomplish this, we\n+# need to be able to check on the status of Pools that we create.\n+_DATA_POOLS = weakref.WeakSet()\n+_WORKER_ID_QUEUE = None  # Only created if needed.\n+_FORCE_THREADPOOL = False\n+\n+\n+def get_pool_class(use_multiprocessing):\n+    global _FORCE_THREADPOOL\n+    if not use_multiprocessing or _FORCE_THREADPOOL:\n+        return multiprocessing.dummy.Pool  # ThreadPool\n+    return multiprocessing.Pool\n+\n+\n+def get_worker_id_queue():\n+    \"\"\"Lazily create the queue to track worker ids.\"\"\"\n+    global _WORKER_ID_QUEUE\n+    if _WORKER_ID_QUEUE is None:\n+        _WORKER_ID_QUEUE = multiprocessing.Queue()\n+    return _WORKER_ID_QUEUE\n+\n+\n+def init_pool(seqs):\n+    global _SHARED_SEQUENCES\n+    _SHARED_SEQUENCES = seqs\n+\n+\n+def get_index(uid, i):\n+    \"\"\"Get the value from the PyDataset `uid` at index `i`.\n+\n+    To allow multiple PyDatasets to be used at the same time, we use `uid` to\n+    get a specific one. A single PyDataset would cause the validation to\n+    overwrite the training PyDataset.\n+\n+    Args:\n+        uid: int, PyDataset identifier\n+        i: index\n+\n+    Returns:\n+        The value at index `i`.\n+    \"\"\"\n+    return _SHARED_SEQUENCES[uid][i]\n+\n+\n+class PyDatasetEnqueuer:\n+    \"\"\"Base class to enqueue inputs.\n+\n+    The task of an Enqueuer is to use parallelism to speed up preprocessing.\n+    This is done with processes or threads.\n+\n+    Example:\n+\n+    ```python\n+        enqueuer = PyDatasetEnqueuer(...)\n+        enqueuer.start()\n+        datas = enqueuer.get()\n+        for data in datas:\n+            # Use the inputs; training, evaluating, predicting.\n+            # ... stop sometime.\n+        enqueuer.stop()\n+    ```\n+\n+    The `enqueuer.get()` should be an infinite stream of data.\n+    \"\"\"\n+\n+    def __init__(self, py_dataset, use_multiprocessing=False):\n+        self.py_dataset = py_dataset\n+        self.use_multiprocessing = use_multiprocessing\n+\n+        global _SEQUENCE_COUNTER\n+        if _SEQUENCE_COUNTER is None:\n+            try:\n+                _SEQUENCE_COUNTER = multiprocessing.Value(\"i\", 0)\n+            except OSError:\n+                # In this case the OS does not allow us to use\n+                # multiprocessing. We resort to an int\n+                # for enqueuer indexing.\n+                _SEQUENCE_COUNTER = 0\n+\n+        if isinstance(_SEQUENCE_COUNTER, int):\n+            self.uid = _SEQUENCE_COUNTER\n+            _SEQUENCE_COUNTER += 1\n+        else:\n+            # Doing Multiprocessing.Value += x is not process-safe.\n+            with _SEQUENCE_COUNTER.get_lock():\n+                self.uid = _SEQUENCE_COUNTER.value\n+                _SEQUENCE_COUNTER.value += 1\n+\n+        self.workers = 0\n+        self.executor_fn = None\n+        self.queue = None\n+        self.run_thread = None\n+        self.stop_signal = None\n+\n+    def is_running(self):\n+        return self.stop_signal is not None and not self.stop_signal.is_set()\n+\n+    def start(self, workers=1, max_queue_size=10):\n+        \"\"\"Starts the handler's workers.\n+\n+        Args:\n+            workers: Number of workers.\n+            max_queue_size: queue size\n+                (when full, workers could block on `put()`)\n+        \"\"\"\n+        if self.use_multiprocessing:\n+            self.executor_fn = self._get_executor_init(workers)\n+        else:\n+            # We do not need the init since it's threads.\n+            self.executor_fn = lambda _: get_pool_class(False)(workers)\n+        self.workers = workers\n+        self.queue = queue.Queue(max_queue_size)\n+        self.stop_signal = threading.Event()\n+        self.run_thread = threading.Thread(target=self._run)\n+        self.run_thread.daemon = True\n+        self.run_thread.start()\n+\n+    def _send_py_dataset(self):\n+        \"\"\"Sends current Iterable to all workers.\"\"\"\n+        # For new processes that may spawn\n+        _SHARED_SEQUENCES[self.uid] = self.py_dataset\n+\n+    def stop(self, timeout=None):\n+        \"\"\"Stops running threads and wait for them to exit, if necessary.\n+\n+        Should be called by the same thread which called `start()`.\n+\n+        Args:\n+            timeout: maximum time to wait on `thread.join()`\n+        \"\"\"\n+        self.stop_signal.set()\n+        with self.queue.mutex:\n+            self.queue.queue.clear()\n+            self.queue.unfinished_tasks = 0\n+            self.queue.not_full.notify()\n+        self.run_thread.join(timeout)\n+        _SHARED_SEQUENCES[self.uid] = None\n+\n+    def __del__(self):\n+        if self.is_running():\n+            self.stop()\n+\n+    def _run(self):\n+        \"\"\"Submits request to the executor and queue the `Future` objects.\"\"\"\n+        raise NotImplementedError\n+\n+    def _get_executor_init(self, workers):\n+        \"\"\"Gets the Pool initializer for multiprocessing.\n+\n+        Args:\n+            workers: Number of workers.\n+\n+        Returns:\n+            Function, a Function to initialize the pool\n+        \"\"\"\n+        raise NotImplementedError\n+\n+    def get(self):\n+        \"\"\"Creates a generator to extract data from the queue.\n+\n+        Skip the data if it is `None`.\n+\n+        Returns:\n+            Generator yielding tuples `(inputs, targets)`\n+                or `(inputs, targets, sample_weights)`.\n+        \"\"\"\n+        raise NotImplementedError\n+\n+\n+class OrderedEnqueuer(PyDatasetEnqueuer):\n+    \"\"\"Builds a Enqueuer from a PyDataset.\n+\n+    Args:\n+        py_dataset: A `keras_core.utils.PyDataset` object.\n+        use_multiprocessing: use multiprocessing if True, otherwise threading\n+        shuffle: whether to shuffle the data at the beginning of each epoch\n+    \"\"\"\n+\n+    def __init__(self, py_dataset, use_multiprocessing=False, shuffle=False):\n+        super().__init__(py_dataset, use_multiprocessing)\n+        self.shuffle = shuffle\n+\n+    def _get_executor_init(self, workers):\n+        \"\"\"Gets the Pool initializer for multiprocessing.\n+\n+        Args:\n+            workers: Number of workers.\n+\n+        Returns:\n+            Function, a Function to initialize the pool\n+        \"\"\"\n+\n+        def pool_fn(seqs):\n+            pool = get_pool_class(True)(\n+                workers,\n+                initializer=init_pool_generator,\n+                initargs=(seqs, None, get_worker_id_queue()),\n+            )\n+            _DATA_POOLS.add(pool)\n+            return pool\n+\n+        return pool_fn\n+\n+    def _wait_queue(self):\n+        \"\"\"Wait for the queue to be empty.\"\"\"\n+        while True:\n+            time.sleep(0.1)\n+            if self.queue.unfinished_tasks == 0 or self.stop_signal.is_set():\n+                return\n+\n+    def _run(self):\n+        \"\"\"Submits request to the executor and queue the `Future` objects.\"\"\"\n+        indices = list(range(len(self.py_dataset)))\n+        if self.shuffle:\n+            random.shuffle(indices)\n+        self._send_py_dataset()  # Share the initial py_dataset\n+        while True:\n+            with closing(self.executor_fn(_SHARED_SEQUENCES)) as executor:\n+                for i in indices:\n+                    if self.stop_signal.is_set():\n+                        return\n+\n+                    self.queue.put(\n+                        executor.apply_async(get_index, (self.uid, i)),\n+                        block=True,\n+                    )\n+\n+                # Done with the current epoch, waiting for the final batches\n+                self._wait_queue()\n+\n+                if self.stop_signal.is_set():\n+                    # We're done\n+                    return\n+\n+            # Call the internal on epoch end.\n+            self.py_dataset.on_epoch_end()\n+            self._send_py_dataset()  # Update the pool\n+\n+    def get(self):\n+        \"\"\"Creates a generator to extract data from the queue.\n+\n+        Skip the data if it is `None`.\n+\n+        Yields:\n+            The next element in the queue, i.e. a tuple\n+            `(inputs, targets)` or\n+            `(inputs, targets, sample_weights)`.\n+        \"\"\"\n+        while self.is_running():\n+            try:\n+                inputs = self.queue.get(block=True, timeout=5).get()\n+                if self.is_running():\n+                    self.queue.task_done()\n+                if inputs is not None:\n+                    yield inputs\n+            except queue.Empty:\n+                pass\n+            except Exception as e:\n+                self.stop()\n+                raise e\n+\n+\n+def init_pool_generator(gens, random_seed=None, id_queue=None):\n+    \"\"\"Initializer function for pool workers.\n+\n+    Args:\n+        gens: State which should be made available to worker processes.\n+        random_seed: An optional value with which to seed child processes.\n+        id_queue: A multiprocessing Queue of worker ids.\n+            This is used to indicate that a worker process\n+            was created by Keras.\n+    \"\"\"\n+    global _SHARED_SEQUENCES\n+    _SHARED_SEQUENCES = gens\n+\n+    worker_proc = multiprocessing.current_process()\n+\n+    # name isn't used for anything, but setting a more descriptive name is\n+    # helpful when diagnosing orphaned processes.\n+    worker_proc.name = f\"Keras_worker_{worker_proc.name}\"\n+\n+    if random_seed is not None:\n+        np.random.seed(random_seed + worker_proc.ident)\n+\n+    if id_queue is not None:\n+        # If a worker dies during init, the pool will just create a replacement.\n+        id_queue.put(worker_proc.ident, block=True, timeout=0.1)\n\n@@ -0,0 +1,122 @@\n+import math\n+import time\n+\n+import numpy as np\n+import tensorflow as tf\n+from absl.testing import parameterized\n+\n+from keras_core import testing\n+from keras_core.trainers.data_adapters import py_dataset_adapter\n+\n+\n+class ExamplePyDataset(py_dataset_adapter.PyDataset):\n+    def __init__(\n+        self, x_set, y_set, sample_weight=None, batch_size=32, delay=0, **kwargs\n+    ):\n+        super().__init__(**kwargs)\n+        self.x, self.y = x_set, y_set\n+        self.batch_size = batch_size\n+        self.sample_weight = sample_weight\n+        self.delay = delay\n+\n+    def __len__(self):\n+        return math.ceil(len(self.x) / self.batch_size)\n+\n+    def __getitem__(self, idx):\n+        # Create artificial delay to test multiprocessing\n+        time.sleep(self.delay)\n+\n+        # Return x, y for batch idx.\n+        low = idx * self.batch_size\n+        # Cap upper bound at array length; the last batch may be smaller\n+        # if the total number of items is not a multiple of batch size.\n+        high = min(low + self.batch_size, len(self.x))\n+        batch_x = self.x[low:high]\n+        batch_y = self.y[low:high]\n+        if self.sample_weight is not None:\n+            return batch_x, batch_y, self.sample_weight[low:high]\n+        return batch_x, batch_y\n+\n+\n+class PyDatasetAdapterTest(testing.TestCase, parameterized.TestCase):\n+    @parameterized.parameters(\n+        [\n+            (True, 2, True, 10),\n+            (False, 2, True, 10),\n+            (True, 2, False, 10),\n+            (False, 2, False, 10),\n+            (True, 0, False, 0),\n+            (False, 0, False, 0),\n+        ]\n+    )\n+    def test_basic_flow(\n+        self, shuffle, workers, use_multiprocessing, max_queue_size\n+    ):\n+        x = np.random.random((64, 4))\n+        y = np.array([[i, i] for i in range(64)], dtype=\"float64\")\n+        py_dataset = ExamplePyDataset(\n+            x,\n+            y,\n+            batch_size=16,\n+            workers=workers,\n+            use_multiprocessing=use_multiprocessing,\n+            max_queue_size=max_queue_size,\n+        )\n+        adapter = py_dataset_adapter.PyDatasetAdapter(\n+            py_dataset, shuffle=shuffle\n+        )\n+\n+        gen = adapter.get_numpy_iterator()\n+        sample_order = []\n+        for batch in gen:\n+            self.assertEqual(len(batch), 2)\n+            bx, by = batch\n+            self.assertTrue(isinstance(bx, np.ndarray))\n+            self.assertTrue(isinstance(by, np.ndarray))\n+            self.assertEqual(bx.dtype, by.dtype)\n+            self.assertEqual(bx.shape, (16, 4))\n+            self.assertEqual(by.shape, (16, 2))\n+            for i in range(by.shape[0]):\n+                sample_order.append(by[i, 0])\n+        if shuffle:\n+            self.assertFalse(sample_order == list(range(64)))\n+        else:\n+            self.assertAllClose(sample_order, list(range(64)))\n+\n+        ds = adapter.get_tf_dataset()\n+        sample_order = []\n+        for batch in ds:\n+            self.assertEqual(len(batch), 2)\n+            bx, by = batch\n+            self.assertTrue(isinstance(bx, tf.Tensor))\n+            self.assertTrue(isinstance(by, tf.Tensor))\n+            self.assertEqual(bx.dtype, by.dtype)\n+            self.assertEqual(tuple(bx.shape), (16, 4))\n+            self.assertEqual(tuple(by.shape), (16, 2))\n+            for i in range(by.shape[0]):\n+                sample_order.append(by[i, 0])\n+        if shuffle:\n+            self.assertFalse(sample_order == list(range(64)))\n+        else:\n+            self.assertAllClose(sample_order, list(range(64)))\n+\n+    def test_speedup(self):\n+        x = np.random.random((40, 4))\n+        y = np.random.random((40, 2))\n+        py_dataset = ExamplePyDataset(\n+            x,\n+            y,\n+            batch_size=4,\n+            workers=4,\n+            use_multiprocessing=True,\n+            max_queue_size=8,\n+            delay=1.0,\n+        )\n+        adapter = py_dataset_adapter.PyDatasetAdapter(py_dataset, shuffle=False)\n+        gen = adapter.get_numpy_iterator()\n+        t0 = time.time()\n+        for batch in gen:\n+            pass\n+        # With non-parallel iteration it should take at least 10s (+ overhead).\n+        # We check it took less than 8s.\n+        self.assertLess(time.time() - t0, 8)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4212fdd5cbeb5debaaeefd47a64fd66f75973014", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 395 | Lines Deleted: 22 | Files Changed: 9 | Hunks: 14 | Methods Changed: 27 | Complexity Δ (Sum/Max): 27/7 | Churn Δ: 417 | Churn Cumulative: 2807 | Contributors (this commit): 7 | Commits (past 90d): 42 | Contributors (cumulative): 23 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,121 @@\n+from keras_core import operations as ops\n+from keras_core.api_export import keras_core_export\n+from keras_core.optimizers import optimizer\n+\n+\n+@keras_core_export([\"keras_core.optimizers.Adadelta\"])\n+class Adadelta(optimizer.Optimizer):\n+    \"\"\"Optimizer that implements the Adadelta algorithm.\n+\n+    Adadelta optimization is a stochastic gradient descent method that is based\n+    on adaptive learning rate per dimension to address two drawbacks:\n+\n+    - The continual decay of learning rates throughout training.\n+    - The need for a manually selected global learning rate.\n+\n+    Adadelta is a more robust extension of Adagrad that adapts learning rates\n+    based on a moving window of gradient updates, instead of accumulating all\n+    past gradients. This way, Adadelta continues learning even when many updates\n+    have been done. Compared to Adagrad, in the original version of Adadelta you\n+    don't have to set an initial learning rate. In this version, the initial\n+    learning rate can be set, as in most other Keras optimizers.\n+\n+    Args:\n+        learning_rate: Initial value for the learning rate: a floating\n+            point value, Defaults to 0.001. Note that `Adadelta` tends\n+            to benefit from higher initial learning rate values compared to\n+            other optimizers.\n+            To match the exact form in the original paper, use 1.0.\n+        rho: A floating point value. The decay rate. Defaults to 0.95.\n+        epsilon: Small floating point value used to maintain numerical\n+            stability.\n+            Defaults to 1e-7.\n+        {{base_optimizer_keyword_args}}\n+\n+    Reference:\n+\n+    - [Zeiler, 2012](http://arxiv.org/abs/1212.5701)\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        learning_rate=0.001,\n+        rho=0.95,\n+        epsilon=1e-7,\n+        weight_decay=None,\n+        clipnorm=None,\n+        clipvalue=None,\n+        global_clipnorm=None,\n+        use_ema=False,\n+        ema_momentum=0.99,\n+        ema_overwrite_frequency=None,\n+        name=\"adadelta\",\n+    ):\n+        super().__init__(\n+            learning_rate=learning_rate,\n+            weight_decay=weight_decay,\n+            clipnorm=clipnorm,\n+            clipvalue=clipvalue,\n+            global_clipnorm=global_clipnorm,\n+            use_ema=use_ema,\n+            ema_momentum=ema_momentum,\n+            ema_overwrite_frequency=ema_overwrite_frequency,\n+            name=name,\n+        )\n+        self.rho = rho\n+        self.epsilon = epsilon\n+\n+    def build(self, var_list):\n+        if self.built:\n+            return\n+        super().build(var_list)\n+        self._accumulated_grads = []\n+        self._accumulated_delta_vars = []\n+        for var in var_list:\n+            self._accumulated_grads.append(\n+                self.add_variable_from_reference(var, \"accumulated_grad\")\n+            )\n+            self._accumulated_delta_vars.append(\n+                self.add_variable_from_reference(var, \"accumulated_delta_var\")\n+            )\n+\n+    def update_step(self, grad, variable, learning_rate):\n+        \"\"\"Update step given gradient and the associated model variable.\"\"\"\n+        lr = ops.cast(learning_rate, variable.dtype)\n+        grad = ops.cast(grad, variable.dtype)\n+\n+        rho = self.rho\n+        accumulated_grad = self._accumulated_grads[\n+            self._get_variable_index(variable)\n+        ]\n+        accumulated_delta_var = self._accumulated_delta_vars[\n+            self._get_variable_index(variable)\n+        ]\n+\n+        def rms(x):\n+            return ops.sqrt(x + self.epsilon)\n+\n+        accumulated_grad.assign(\n+            rho * accumulated_grad + (1 - rho) * grad * grad\n+        )\n+        delta_var = -rms(accumulated_delta_var) * grad / rms(accumulated_grad)\n+        accumulated_delta_var.assign(\n+            rho * accumulated_delta_var + (1 - rho) * delta_var * delta_var\n+        )\n+        variable.assign(variable + lr * delta_var)\n+\n+    def get_config(self):\n+        config = super().get_config()\n+\n+        config.update(\n+            {\n+                \"rho\": self.rho,\n+                \"epsilon\": self.epsilon,\n+            }\n+        )\n+        return config\n+\n+\n+Adadelta.__doc__ = Adadelta.__doc__.replace(\n+    \"{{base_optimizer_keyword_args}}\", optimizer.base_optimizer_keyword_args\n+)\n\n@@ -0,0 +1,74 @@\n+import numpy as np\n+\n+from keras_core import backend\n+from keras_core import testing\n+from keras_core.optimizers.adadelta import Adadelta\n+\n+\n+class AdadeltaTest(testing.TestCase):\n+    def test_config(self):\n+        optimizer = Adadelta(\n+            learning_rate=0.5,\n+            rho=0.9,\n+            epsilon=1e-5,\n+        )\n+        self.run_class_serialization_test(optimizer)\n+\n+    def test_single_step(self):\n+        optimizer = Adadelta(learning_rate=0.5)\n+        grads = np.array([1.0, 6.0, 7.0, 2.0])\n+        vars = backend.Variable([1.0, 2.0, 3.0, 4.0])\n+        optimizer.apply_gradients(zip([grads], [vars]))\n+        self.assertAllClose(\n+            vars, [0.9993, 1.9993, 2.9993, 3.9993], rtol=1e-4, atol=1e-4\n+        )\n+\n+    def test_weight_decay(self):\n+        grads, var1, var2, var3 = (\n+            np.zeros(()),\n+            backend.Variable(2.0),\n+            backend.Variable(2.0, name=\"exclude\"),\n+            backend.Variable(2.0),\n+        )\n+        optimizer_1 = Adadelta(learning_rate=1.0, weight_decay=0.004)\n+        optimizer_1.apply_gradients(zip([grads], [var1]))\n+\n+        optimizer_2 = Adadelta(learning_rate=1.0, weight_decay=0.004)\n+        optimizer_2.exclude_from_weight_decay(var_names=[\"exclude\"])\n+        optimizer_2.apply_gradients(zip([grads, grads], [var1, var2]))\n+\n+        optimizer_3 = Adadelta(learning_rate=1.0, weight_decay=0.004)\n+        optimizer_3.exclude_from_weight_decay(var_list=[var3])\n+        optimizer_3.apply_gradients(zip([grads, grads], [var1, var3]))\n+\n+        self.assertAlmostEqual(var1.numpy(), 1.9760959, decimal=6)\n+        self.assertAlmostEqual(var2.numpy(), 2.0, decimal=6)\n+        self.assertAlmostEqual(var3.numpy(), 2.0, decimal=6)\n+\n+    def test_correctness_with_golden(self):\n+        optimizer = Adadelta(learning_rate=1.0, rho=0.8, epsilon=1e-6)\n+\n+        x = backend.Variable(np.ones([10]))\n+        grads = np.arange(0.1, 1.1, 0.1)\n+        first_grads = np.full((10,), 0.01)\n+\n+        golden = np.tile(\n+            [[0.9978], [0.9947], [0.9915], [0.9882], [0.9849]], (1, 10)\n+        )\n+\n+        optimizer.apply_gradients(zip([first_grads], [x]))\n+        for i in range(5):\n+            self.assertAllClose(x, golden[i], rtol=5e-4, atol=5e-4)\n+            optimizer.apply_gradients(zip([grads], [x]))\n+\n+    def test_clip_norm(self):\n+        optimizer = Adadelta(clipnorm=1)\n+        grad = [np.array([100.0, 100.0])]\n+        clipped_grad = optimizer._clip_gradients(grad)\n+        self.assertAllClose(clipped_grad[0], [2**0.5 / 2, 2**0.5 / 2])\n+\n+    def test_clip_value(self):\n+        optimizer = Adadelta(clipvalue=1)\n+        grad = [np.array([100.0, 100.0])]\n+        clipped_grad = optimizer._clip_gradients(grad)\n+        self.assertAllClose(clipped_grad[0], [1.0, 1.0])\n\n@@ -0,0 +1,107 @@\n+from keras_core import initializers\n+from keras_core import operations as ops\n+from keras_core.api_export import keras_core_export\n+from keras_core.optimizers import optimizer\n+\n+\n+@keras_core_export([\"keras_core.optimizers.Adagrad\"])\n+class Adagrad(optimizer.Optimizer):\n+    \"\"\"Optimizer that implements the Adagrad algorithm.\n+\n+    Adagrad is an optimizer with parameter-specific learning rates,\n+    which are adapted relative to how frequently a parameter gets\n+    updated during training. The more updates a parameter receives,\n+    the smaller the updates.\n+\n+    Args:\n+        learning_rate: Initial value for the learning rate:\n+            a floating point value,\n+            Defaults to 0.001.\n+            Note that `Adagrad` tends to benefit from higher initial\n+            learning rate values compared to other optimizers.\n+            To match the exact form in the original paper, use 1.0.\n+        initial_accumulator_value: Floating point value.\n+            Starting value for the accumulators (per-parameter\n+            momentum values).\n+            Must be non-negative.\n+        epsilon: Small floating point value used to maintain\n+            numerical stability.\n+        {{base_optimizer_keyword_args}}\n+\n+    Reference:\n+\n+    - [Duchi et al., 2011](\n+        http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf).\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        learning_rate=0.001,\n+        initial_accumulator_value=0.1,\n+        epsilon=1e-7,\n+        weight_decay=None,\n+        clipnorm=None,\n+        clipvalue=None,\n+        global_clipnorm=None,\n+        use_ema=False,\n+        ema_momentum=0.99,\n+        ema_overwrite_frequency=None,\n+        name=\"adagrad\",\n+    ):\n+        super().__init__(\n+            learning_rate=learning_rate,\n+            weight_decay=weight_decay,\n+            clipnorm=clipnorm,\n+            clipvalue=clipvalue,\n+            global_clipnorm=global_clipnorm,\n+            use_ema=use_ema,\n+            ema_momentum=ema_momentum,\n+            ema_overwrite_frequency=ema_overwrite_frequency,\n+            name=name,\n+        )\n+        self.initial_accumulator_value = initial_accumulator_value\n+        self.epsilon = epsilon\n+\n+    def build(self, var_list):\n+        if self.built:\n+            return\n+        super().build(var_list)\n+        self._accumulators = []\n+        initializer = initializers.Constant(self.initial_accumulator_value)\n+        for var in var_list:\n+            self._accumulators.append(\n+                self.add_variable(\n+                    shape=var.shape,\n+                    initializer=initializer,\n+                    dtype=var.dtype,\n+                    name=\"accumulator\",\n+                )\n+            )\n+\n+    def update_step(self, gradient, variable, learning_rate):\n+        \"\"\"Update step given gradient and the associated model variable.\"\"\"\n+        lr = ops.cast(learning_rate, variable.dtype)\n+        gradient = ops.cast(gradient, variable.dtype)\n+\n+        accumulator = self._accumulators[self._get_variable_index(variable)]\n+\n+        accumulator.assign(accumulator + gradient * gradient)\n+        variable.assign(\n+            variable - (lr * gradient / ops.sqrt(accumulator + self.epsilon))\n+        )\n+\n+    def get_config(self):\n+        config = super().get_config()\n+\n+        config.update(\n+            {\n+                \"initial_accumulator_value\": self.initial_accumulator_value,\n+                \"epsilon\": self.epsilon,\n+            }\n+        )\n+        return config\n+\n+\n+Adagrad.__doc__ = Adagrad.__doc__.replace(\n+    \"{{base_optimizer_keyword_args}}\", optimizer.base_optimizer_keyword_args\n+)\n\n@@ -0,0 +1,85 @@\n+# flake8: noqa\n+\n+\n+import numpy as np\n+\n+from keras_core import backend\n+from keras_core import testing\n+from keras_core.optimizers.adagrad import Adagrad\n+\n+\n+class AdagradTest(testing.TestCase):\n+    def test_config(self):\n+        optimizer = Adagrad(\n+            learning_rate=0.5,\n+            initial_accumulator_value=0.2,\n+            epsilon=1e-5,\n+        )\n+        self.run_class_serialization_test(optimizer)\n+\n+    def test_single_step(self):\n+        optimizer = Adagrad(learning_rate=0.5)\n+        grads = np.array([1.0, 6.0, 7.0, 2.0])\n+        vars = backend.Variable([1.0, 2.0, 3.0, 4.0])\n+        optimizer.apply_gradients(zip([grads], [vars]))\n+        self.assertAllClose(\n+            vars, [0.5233, 1.5007, 2.5005, 3.5061], rtol=1e-4, atol=1e-4\n+        )\n+\n+    def test_weight_decay(self):\n+        grads, var1, var2, var3 = (\n+            np.zeros(()),\n+            backend.Variable(2.0),\n+            backend.Variable(2.0, name=\"exclude\"),\n+            backend.Variable(2.0),\n+        )\n+        optimizer_1 = Adagrad(learning_rate=1.0, weight_decay=0.004)\n+        optimizer_1.apply_gradients(zip([grads], [var1]))\n+\n+        optimizer_2 = Adagrad(learning_rate=1.0, weight_decay=0.004)\n+        optimizer_2.exclude_from_weight_decay(var_names=[\"exclude\"])\n+        optimizer_2.apply_gradients(zip([grads, grads], [var1, var2]))\n+\n+        optimizer_3 = Adagrad(learning_rate=1.0, weight_decay=0.004)\n+        optimizer_3.exclude_from_weight_decay(var_list=[var3])\n+        optimizer_3.apply_gradients(zip([grads, grads], [var1, var3]))\n+\n+        self.assertAlmostEqual(var1.numpy(), 1.9760959, decimal=6)\n+        self.assertAlmostEqual(var2.numpy(), 2.0, decimal=6)\n+        self.assertAlmostEqual(var3.numpy(), 2.0, decimal=6)\n+\n+    def test_correctness_with_golden(self):\n+        optimizer = Adagrad(\n+            learning_rate=0.2, initial_accumulator_value=0.3, epsilon=1e-6\n+        )\n+\n+        x = backend.Variable(np.ones([10]))\n+        grads = np.arange(0.1, 1.1, 0.1)\n+        first_grads = np.full((10,), 0.01)\n+\n+        # fmt: off\n+        golden = np.array(\n+            [[0.9963, 0.9963, 0.9963, 0.9963, 0.9963, 0.9963, 0.9963, 0.9963, 0.9963, 0.9963],\n+            [0.9604, 0.9278, 0.9003, 0.8784, 0.8615, 0.8487, 0.8388, 0.8313, 0.8255, 0.8209],\n+            [0.9251, 0.8629, 0.8137, 0.7768, 0.7497, 0.7298, 0.7151, 0.704, 0.6956, 0.6891],\n+            [0.8903, 0.8012, 0.7342, 0.6862, 0.6521, 0.6277, 0.6099, 0.5967, 0.5867, 0.579],\n+            [0.856, 0.7422, 0.6604, 0.6037, 0.5644, 0.5367, 0.5168, 0.5021, 0.491, 0.4825]]\n+        )\n+        # fmt: on\n+\n+        optimizer.apply_gradients(zip([first_grads], [x]))\n+        for i in range(5):\n+            self.assertAllClose(x, golden[i], rtol=5e-4, atol=5e-4)\n+            optimizer.apply_gradients(zip([grads], [x]))\n+\n+    def test_clip_norm(self):\n+        optimizer = Adagrad(clipnorm=1)\n+        grad = [np.array([100.0, 100.0])]\n+        clipped_grad = optimizer._clip_gradients(grad)\n+        self.assertAllClose(clipped_grad[0], [2**0.5 / 2, 2**0.5 / 2])\n+\n+    def test_clip_value(self):\n+        optimizer = Adagrad(clipvalue=1)\n+        grad = [np.array([100.0, 100.0])]\n+        clipped_grad = optimizer._clip_gradients(grad)\n+        self.assertAllClose(clipped_grad[0], [1.0, 1.0])\n\n@@ -54,7 +54,6 @@ class Adam(optimizer.Optimizer):\n         ema_momentum=0.99,\n         ema_overwrite_frequency=None,\n         name=\"adam\",\n-        **kwargs\n     ):\n         super().__init__(\n             learning_rate=learning_rate,\n@@ -66,7 +65,6 @@ class Adam(optimizer.Optimizer):\n             use_ema=use_ema,\n             ema_momentum=ema_momentum,\n             ema_overwrite_frequency=ema_overwrite_frequency,\n-            **kwargs\n         )\n         self.beta_1 = beta_1\n         self.beta_2 = beta_2\n\n@@ -62,19 +62,13 @@ class AdamTest(testing.TestCase):\n             optimizer.apply_gradients(zip([grads], [x]))\n \n     def test_clip_norm(self):\n-        # TODO: implement clip_gradients, then uncomment\n-        pass\n-\n-    #     optimizer = Adam(clipnorm=1)\n-    #     grad = [np.array([100.0, 100.0])]\n-    #     clipped_grad = optimizer._clip_gradients(grad)\n-    #     self.assertAllClose(clipped_grad[0], [2**0.5 / 2, 2**0.5 / 2])\n+        optimizer = Adam(clipnorm=1)\n+        grad = [np.array([100.0, 100.0])]\n+        clipped_grad = optimizer._clip_gradients(grad)\n+        self.assertAllClose(clipped_grad[0], [2**0.5 / 2, 2**0.5 / 2])\n \n     def test_clip_value(self):\n-        # TODO: implement clip_gradients, then uncomment\n-        pass\n-\n-    #     optimizer = Adam(clipvalue=1)\n-    #     grad = [np.array([100.0, 100.0])]\n-    #     clipped_grad = optimizer._clip_gradients(grad)\n-    #     self.assertAllClose(clipped_grad[0], [1.0, 1.0])\n+        optimizer = Adam(clipvalue=1)\n+        grad = [np.array([100.0, 100.0])]\n+        clipped_grad = optimizer._clip_gradients(grad)\n+        self.assertAllClose(clipped_grad[0], [1.0, 1.0])\n\n@@ -64,7 +64,6 @@ class AdamW(optimizer.Optimizer):\n         ema_momentum=0.99,\n         ema_overwrite_frequency=None,\n         name=\"adamw\",\n-        **kwargs\n     ):\n         super().__init__(\n             learning_rate=learning_rate,\n@@ -75,7 +74,6 @@ class AdamW(optimizer.Optimizer):\n             use_ema=use_ema,\n             ema_momentum=ema_momentum,\n             ema_overwrite_frequency=ema_overwrite_frequency,\n-            **kwargs\n         )\n         self.weight_decay = weight_decay\n         self.beta_1 = beta_1\n\n@@ -63,7 +63,6 @@ class RMSprop(optimizer.Optimizer):\n         ema_momentum=0.99,\n         ema_overwrite_frequency=100,\n         name=\"rmsprop\",\n-        **kwargs\n     ):\n         super().__init__(\n             learning_rate=learning_rate,\n@@ -75,7 +74,6 @@ class RMSprop(optimizer.Optimizer):\n             ema_momentum=ema_momentum,\n             ema_overwrite_frequency=ema_overwrite_frequency,\n             name=name,\n-            **kwargs\n         )\n         self.rho = rho\n         self.momentum = momentum\n\n@@ -51,7 +51,6 @@ class SGD(optimizer.Optimizer):\n         ema_momentum=0.99,\n         ema_overwrite_frequency=None,\n         name=\"SGD\",\n-        **kwargs\n     ):\n         super().__init__(\n             learning_rate=learning_rate,\n@@ -63,7 +62,6 @@ class SGD(optimizer.Optimizer):\n             use_ema=use_ema,\n             ema_momentum=ema_momentum,\n             ema_overwrite_frequency=ema_overwrite_frequency,\n-            **kwargs\n         )\n         if not isinstance(momentum, float) or momentum < 0 or momentum > 1:\n             raise ValueError(\"`momentum` must be a float between [0, 1].\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
