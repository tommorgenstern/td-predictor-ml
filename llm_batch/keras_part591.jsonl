{"custom_id": "keras#c9dc3e7a53c26bff673019c43ba9bef41004ed80", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 323 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 3 | Methods Changed: 12 | Complexity Δ (Sum/Max): 14/8 | Churn Δ: 323 | Churn Cumulative: 442 | Contributors (this commit): 9 | Commits (past 90d): 54 | Contributors (cumulative): 11 | DMM Complexity: 1.0\n\nDIFF:\n@@ -70,6 +70,7 @@ from keras_core.layers.preprocessing.normalization import Normalization\n from keras_core.layers.preprocessing.random_brightness import RandomBrightness\n from keras_core.layers.preprocessing.random_contrast import RandomContrast\n from keras_core.layers.preprocessing.random_crop import RandomCrop\n+from keras_core.layers.preprocessing.random_translation import RandomTranslation\n from keras_core.layers.preprocessing.rescaling import Rescaling\n from keras_core.layers.preprocessing.resizing import Resizing\n from keras_core.layers.preprocessing.string_lookup import StringLookup\n\n@@ -0,0 +1,99 @@\n+import numpy as np\n+import tensorflow as tf\n+\n+from keras_core import backend\n+from keras_core.api_export import keras_core_export\n+from keras_core.layers.layer import Layer\n+\n+\n+@keras_core_export(\"keras_core.layers.RandomTranslation\")\n+class RandomTranslation(Layer):\n+    \"\"\"A preprocessing layer which randomly translates images during training.\n+\n+    This layer will apply random translations to each image during training,\n+    filling empty space according to `fill_mode`.\n+\n+    Input pixel values can be of any range (e.g. `[0., 1.)` or `[0, 255]`) and\n+    of integer or floating point dtype. By default, the layer will output\n+    floats.\n+\n+    Args:\n+      height_factor: a float represented as fraction of value, or a tuple of\n+          size 2 representing lower and upper bound for shifting vertically. A\n+          negative value means shifting image up, while a positive value means\n+          shifting image down. When represented as a single positive float, this\n+          value is used for both the upper and lower bound. For instance,\n+          `height_factor=(-0.2, 0.3)` results in an output shifted by a random\n+          amount in the range `[-20%, +30%]`.  `height_factor=0.2` results in an\n+          output height shifted by a random amount in the range `[-20%, +20%]`.\n+      width_factor: a float represented as fraction of value, or a tuple of size\n+          2 representing lower and upper bound for shifting horizontally. A\n+          negative value means shifting image left, while a positive value means\n+          shifting image right. When represented as a single positive float,\n+          this value is used for both the upper and lower bound. For instance,\n+          `width_factor=(-0.2, 0.3)` results in an output shifted left by 20%,\n+          and shifted right by 30%. `width_factor=0.2` results\n+          in an output height shifted left or right by 20%.\n+      fill_mode: Points outside the boundaries of the input are filled according\n+          to the given mode\n+          (one of `{\"constant\", \"reflect\", \"wrap\", \"nearest\"}`).\n+          - *reflect*: `(d c b a | a b c d | d c b a)` The input is extended by\n+              reflecting about the edge of the last pixel.\n+          - *constant*: `(k k k k | a b c d | k k k k)` The input is extended by\n+              filling all values beyond the edge with the same constant value\n+              k = 0.\n+          - *wrap*: `(a b c d | a b c d | a b c d)` The input is extended by\n+              wrapping around to the opposite edge.\n+          - *nearest*: `(a a a a | a b c d | d d d d)` The input is extended by\n+              the nearest pixel.\n+      interpolation: Interpolation mode. Supported values: `\"nearest\"`,\n+          `\"bilinear\"`.\n+      seed: Integer. Used to create a random seed.\n+      fill_value: a float represents the value to be filled outside the\n+          boundaries when `fill_mode=\"constant\"`.\n+\n+    Input shape:\n+        3D (unbatched) or 4D (batched) tensor with shape:\n+        `(..., height, width, channels)`,  in `\"channels_last\"` format.\n+\n+    Output shape:\n+        3D (unbatched) or 4D (batched) tensor with shape:\n+        `(..., height, width, channels)`,  in `\"channels_last\"` format.\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        height_factor,\n+        width_factor,\n+        fill_mode=\"reflect\",\n+        interpolation=\"bilinear\",\n+        seed=None,\n+        fill_value=0.0,\n+        name=None,\n+        **kwargs,\n+    ):\n+        super().__init__(name=name)\n+        self.layer = tf.keras.layers.RandomTranslation(\n+            height_factor=height_factor,\n+            width_factor=width_factor,\n+            fill_mode=fill_mode,\n+            interpolation=interpolation,\n+            seed=seed,\n+            fill_value=fill_value,\n+            name=name,\n+            **kwargs,\n+        )\n+\n+    def call(self, inputs, training=True):\n+        if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n+            inputs = tf.convert_to_tensor(np.array(inputs))\n+        outputs = self.layer.call(inputs)\n+        if backend.backend() != \"tensorflow\":\n+            outputs = backend.convert_to_tensor(outputs)\n+        return outputs\n+\n+    def compute_output_shape(self, input_shape):\n+        return tuple(self.layer.compute_output_shape(input_shape))\n+\n+    def get_config(self):\n+        return self.layer.get_config()\n\n@@ -0,0 +1,223 @@\n+import numpy as np\n+from absl.testing import parameterized\n+\n+from keras_core import backend\n+from keras_core import layers\n+from keras_core import testing\n+\n+\n+class RandomTranslationTest(testing.TestCase, parameterized.TestCase):\n+    @parameterized.named_parameters(\n+        (\"random_translate_4_by_6\", 0.4, 0.6),\n+        (\"random_translate_3_by_2\", 0.3, 0.2),\n+        (\"random_translate_tuple_factor\", (-0.5, 0.4), (0.2, 0.3)),\n+    )\n+    def test_random_translation(self, height_factor, width_factor):\n+        self.run_layer_test(\n+            layers.RandomTranslation,\n+            init_kwargs={\n+                \"height_factor\": height_factor,\n+                \"width_factor\": width_factor,\n+            },\n+            input_shape=(2, 3, 4),\n+            expected_output_shape=(2, 3, 4),\n+            supports_masking=False,\n+        )\n+\n+    def test_random_translation_up_numeric_reflect(self):\n+        input_image = np.reshape(np.arange(0, 25), (1, 5, 5, 1))\n+        expected_output = np.asarray(\n+            [\n+                [5, 6, 7, 8, 9],\n+                [10, 11, 12, 13, 14],\n+                [15, 16, 17, 18, 19],\n+                [20, 21, 22, 23, 24],\n+                [20, 21, 22, 23, 24],\n+            ]\n+        )\n+        expected_output = backend.convert_to_tensor(\n+            np.reshape(expected_output, (1, 5, 5, 1))\n+        )\n+        self.run_layer_test(\n+            layers.RandomTranslation,\n+            init_kwargs={\n+                \"height_factor\": (-0.2, -0.2),\n+                \"width_factor\": 0.0,\n+            },\n+            input_shape=None,\n+            input_data=input_image,\n+            expected_output=expected_output,\n+            supports_masking=False,\n+        )\n+\n+    def test_random_translation_up_numeric_constant(self):\n+        input_image = np.reshape(np.arange(0, 25), (1, 5, 5, 1)).astype(\n+            \"float32\"\n+        )\n+        # Shifting by -.2 * 5 = 1 pixel.\n+        expected_output = np.asarray(\n+            [\n+                [5, 6, 7, 8, 9],\n+                [10, 11, 12, 13, 14],\n+                [15, 16, 17, 18, 19],\n+                [20, 21, 22, 23, 24],\n+                [0, 0, 0, 0, 0],\n+            ]\n+        )\n+        expected_output = backend.convert_to_tensor(\n+            np.reshape(expected_output, (1, 5, 5, 1)), dtype=\"float32\"\n+        )\n+        self.run_layer_test(\n+            layers.RandomTranslation,\n+            init_kwargs={\n+                \"height_factor\": (-0.2, -0.2),\n+                \"width_factor\": 0.0,\n+                \"fill_mode\": \"constant\",\n+            },\n+            input_shape=None,\n+            input_data=input_image,\n+            expected_output=expected_output,\n+            supports_masking=False,\n+        )\n+\n+    def test_random_translation_down_numeric_reflect(self):\n+        input_image = np.reshape(np.arange(0, 25), (1, 5, 5, 1))\n+        # Shifting by .2 * 5 = 1 pixel.\n+        expected_output = np.asarray(\n+            [\n+                [0, 1, 2, 3, 4],\n+                [0, 1, 2, 3, 4],\n+                [5, 6, 7, 8, 9],\n+                [10, 11, 12, 13, 14],\n+                [15, 16, 17, 18, 19],\n+            ]\n+        )\n+        expected_output = backend.convert_to_tensor(\n+            np.reshape(expected_output, (1, 5, 5, 1))\n+        )\n+        self.run_layer_test(\n+            layers.RandomTranslation,\n+            init_kwargs={\n+                \"height_factor\": (0.2, 0.2),\n+                \"width_factor\": 0.0,\n+            },\n+            input_shape=None,\n+            input_data=input_image,\n+            expected_output=expected_output,\n+            supports_masking=False,\n+        )\n+\n+    def test_random_translation_asymmetric_size_numeric_reflect(self):\n+        input_image = np.reshape(np.arange(0, 16), (1, 8, 2, 1))\n+        # Shifting by .2 * 5 = 1 pixel.\n+        expected_output = np.asarray(\n+            [\n+                [6, 7],\n+                [4, 5],\n+                [2, 3],\n+                [0, 1],\n+                [0, 1],\n+                [2, 3],\n+                [4, 5],\n+                [6, 7],\n+            ]\n+        )\n+        expected_output = backend.convert_to_tensor(\n+            np.reshape(expected_output, (1, 8, 2, 1))\n+        )\n+        self.run_layer_test(\n+            layers.RandomTranslation,\n+            init_kwargs={\n+                \"height_factor\": (0.5, 0.5),\n+                \"width_factor\": 0.0,\n+            },\n+            input_shape=None,\n+            input_data=input_image,\n+            expected_output=expected_output,\n+            supports_masking=False,\n+        )\n+\n+    def test_random_translation_down_numeric_constant(self):\n+        input_image = np.reshape(np.arange(0, 25), (1, 5, 5, 1))\n+        # Shifting by .2 * 5 = 1 pixel.\n+        expected_output = np.asarray(\n+            [\n+                [0, 0, 0, 0, 0],\n+                [0, 1, 2, 3, 4],\n+                [5, 6, 7, 8, 9],\n+                [10, 11, 12, 13, 14],\n+                [15, 16, 17, 18, 19],\n+            ]\n+        )\n+        expected_output = backend.convert_to_tensor(\n+            np.reshape(expected_output, (1, 5, 5, 1))\n+        )\n+        self.run_layer_test(\n+            layers.RandomTranslation,\n+            init_kwargs={\n+                \"height_factor\": (0.2, 0.2),\n+                \"width_factor\": 0.0,\n+                \"fill_mode\": \"constant\",\n+                \"fill_value\": 0.0,\n+            },\n+            input_shape=None,\n+            input_data=input_image,\n+            expected_output=expected_output,\n+            supports_masking=False,\n+        )\n+\n+    def test_random_translation_left_numeric_reflect(self):\n+        input_image = np.reshape(np.arange(0, 25), (1, 5, 5, 1))\n+        # Shifting by .2 * 5 = 1 pixel.\n+        expected_output = np.asarray(\n+            [\n+                [1, 2, 3, 4, 4],\n+                [6, 7, 8, 9, 9],\n+                [11, 12, 13, 14, 14],\n+                [16, 17, 18, 19, 19],\n+                [21, 22, 23, 24, 24],\n+            ]\n+        )\n+        expected_output = backend.convert_to_tensor(\n+            np.reshape(expected_output, (1, 5, 5, 1))\n+        )\n+        self.run_layer_test(\n+            layers.RandomTranslation,\n+            init_kwargs={\n+                \"height_factor\": 0.0,\n+                \"width_factor\": (-0.2, -0.2),\n+            },\n+            input_shape=None,\n+            input_data=input_image,\n+            expected_output=expected_output,\n+            supports_masking=False,\n+        )\n+\n+    def test_random_translation_left_numeric_constant(self):\n+        input_image = np.reshape(np.arange(0, 25), (1, 5, 5, 1))\n+        # Shifting by .2 * 5 = 1 pixel.\n+        expected_output = np.asarray(\n+            [\n+                [1, 2, 3, 4, 0],\n+                [6, 7, 8, 9, 0],\n+                [11, 12, 13, 14, 0],\n+                [16, 17, 18, 19, 0],\n+                [21, 22, 23, 24, 0],\n+            ]\n+        )\n+        expected_output = backend.convert_to_tensor(\n+            np.reshape(expected_output, (1, 5, 5, 1))\n+        )\n+        self.run_layer_test(\n+            layers.RandomTranslation,\n+            init_kwargs={\n+                \"height_factor\": 0.0,\n+                \"width_factor\": (-0.2, -0.2),\n+                \"fill_mode\": \"constant\",\n+                \"fill_value\": 0.0,\n+            },\n+            input_shape=None,\n+            input_data=input_image,\n+            expected_output=expected_output,\n+            supports_masking=False,\n+        )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a3f224d2ebff062ed85750cb150298d1251feded", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 887 | Lines Deleted: 85 | Files Changed: 9 | Hunks: 25 | Methods Changed: 19 | Complexity Δ (Sum/Max): 19/21 | Churn Δ: 972 | Churn Cumulative: 7775 | Contributors (this commit): 14 | Commits (past 90d): 127 | Contributors (cumulative): 33 | DMM Complexity: 0.958904109589041\n\nDIFF:\n@@ -6,18 +6,17 @@ import tensorflow as tf\n from tensorflow.python.eager import context\n \n from keras_core import backend\n-from keras_core.backend.tensorflow import trainer as tf_trainer\n from keras_core import layers\n from keras_core import models\n from keras_core import testing\n+from keras_core.backend.tensorflow import trainer as tf_trainer\n \n \n @pytest.mark.skipif(\n-    backend.backend() != 'tensorflow',\n-    reason='The distribute test can only run with TF backend.',\n+    backend.backend() != \"tensorflow\",\n+    reason=\"The distribute test can only run with TF backend.\",\n )\n class DistributeTest(testing.TestCase):\n-\n     def setUp(self):\n         super().setUp()\n         # Need at least 2 devices for distribution related tests.\n@@ -32,22 +31,23 @@ class DistributeTest(testing.TestCase):\n         )\n \n     def test_variable_creation(self):\n-        strategy = tf.distribute.MirroredStrategy(['CPU:0', 'CPU:1'])\n+        strategy = tf.distribute.MirroredStrategy([\"CPU:0\", \"CPU:1\"])\n         with strategy.scope():\n             dense = layers.Dense(2)\n             dense.build([4, 2])\n \n         self.assertIsInstance(dense.kernel, backend.KerasVariable)\n-        self.assertIsInstance(dense.kernel.value,\n-                              tf.distribute.DistributedValues)\n-        self.assertIn('MirroredVariable', dense.kernel.value.__class__.__name__)\n+        self.assertIsInstance(\n+            dense.kernel.value, tf.distribute.DistributedValues\n+        )\n+        self.assertIn(\"MirroredVariable\", dense.kernel.value.__class__.__name__)\n \n         self.assertIsInstance(dense.kernel, backend.KerasVariable)\n         self.assertIsInstance(dense.bias.value, tf.distribute.DistributedValues)\n-        self.assertIn('MirroredVariable', dense.bias.value.__class__.__name__)\n+        self.assertIn(\"MirroredVariable\", dense.bias.value.__class__.__name__)\n \n     def test_strategy_run(self):\n-        strategy = tf.distribute.MirroredStrategy(['CPU:0', 'CPU:1'])\n+        strategy = tf.distribute.MirroredStrategy([\"CPU:0\", \"CPU:1\"])\n \n         with strategy.scope():\n             inputs = layers.Input(shape=[4])\n@@ -56,8 +56,9 @@ class DistributeTest(testing.TestCase):\n             model = models.Functional(inputs, output)\n \n         self.assertIsInstance(dense.kernel, backend.KerasVariable)\n-        self.assertIsInstance(dense.kernel.value,\n-                              tf.distribute.DistributedValues)\n+        self.assertIsInstance(\n+            dense.kernel.value, tf.distribute.DistributedValues\n+        )\n \n         def input_fn(ctx):\n             if ctx.replica_id_in_sync_group == 1:\n@@ -65,8 +66,9 @@ class DistributeTest(testing.TestCase):\n             else:\n                 return tf.zeros([8, 4])\n \n-        distributed_inputs = strategy.\\\n-            experimental_distribute_values_from_function(input_fn)\n+        distributed_inputs = (\n+            strategy.experimental_distribute_values_from_function(input_fn)\n+        )\n \n         @tf.function\n         def run_fn(data):\n@@ -74,8 +76,9 @@ class DistributeTest(testing.TestCase):\n \n         result = strategy.run(run_fn, args=(distributed_inputs,))\n \n-        self.assertIsInstance(result,\n-                              tf.types.experimental.distributed.PerReplica)\n+        self.assertIsInstance(\n+            result, tf.types.experimental.distributed.PerReplica\n+        )\n         self.assertLen(result.values, 2)\n         self.assertEqual(result.values[0].shape, [8, 2])\n         self.assertEqual(result.values[1].shape, [8, 2])\n@@ -89,7 +92,7 @@ class DistributeTest(testing.TestCase):\n         batch_size = 16\n         shuffle = True\n \n-        strategy = tf.distribute.MirroredStrategy(['CPU:0', 'CPU:1'])\n+        strategy = tf.distribute.MirroredStrategy([\"CPU:0\", \"CPU:1\"])\n \n         epoch_iterator = tf_trainer.TFEpochIterator(\n             x=x,\n@@ -97,7 +100,7 @@ class DistributeTest(testing.TestCase):\n             sample_weight=sample_weight,\n             batch_size=batch_size,\n             shuffle=shuffle,\n-            distribute_strategy=strategy\n+            distribute_strategy=strategy,\n         )\n         steps_seen = []\n         for step, data_iterator in epoch_iterator.enumerate_epoch():\n@@ -106,8 +109,8 @@ class DistributeTest(testing.TestCase):\n             self.assertEqual(len(batch), 3)\n             x, y, sample_weight = batch\n             self.assertTrue(\n-                isinstance(x,\n-                           tf.types.experimental.distributed.PerReplica))\n+                isinstance(x, tf.types.experimental.distributed.PerReplica)\n+            )\n             # Make sure the local batch size is 8\n             if step < 6:\n                 self.assertEqual(x.values[0].shape, [8, 16])\n\n@@ -245,7 +245,9 @@ def depthwise_conv(\n             \"`inputs` rank must be 3 (1D conv) or 4 (2D conv). Received: \"\n             \"{inputs.ndim}.\"\n         )\n-    tf_data_format = _convert_data_format(data_format, len(inputs.shape))\n+    # Because we use `tf.nn.depthwise_conv2d` for both 1D and 2D convs, we set\n+    # `tf_data_format` using 2D conv format.\n+    tf_data_format = _convert_data_format(data_format, 4)\n     padding = padding.upper()\n     if isinstance(strides, int):\n         strides = (strides,) * num_spatial_dims\n\n@@ -442,13 +442,17 @@ class TFEpochIterator(EpochIterator):\n             if not self._current_iterator:\n                 self._current_iterator = iter(\n                     self._distribute_strategy.experimental_distribute_dataset(\n-                        self.data_adapter.get_tf_dataset()))\n+                        self.data_adapter.get_tf_dataset()\n+                    )\n+                )\n             for step in range(self.steps_per_epoch):\n                 yield step, self._current_iterator\n         else:\n             iterator = iter(\n                 self._distribute_strategy.experimental_distribute_dataset(\n-                    self.data_adapter.get_tf_dataset()))\n+                    self.data_adapter.get_tf_dataset()\n+                )\n+            )\n             if self.num_batches:\n                 for step in range(self.num_batches):\n                     yield step, iterator\n\n@@ -6,6 +6,8 @@ from keras_core.layers.convolutional.conv2d import Conv2D\n from keras_core.layers.convolutional.conv2d_transpose import Conv2DTranspose\n from keras_core.layers.convolutional.conv3d import Conv3D\n from keras_core.layers.convolutional.conv3d_transpose import Conv3DTranspose\n+from keras_core.layers.convolutional.depthwise_conv1d import DepthwiseConv1D\n+from keras_core.layers.convolutional.depthwise_conv2d import DepthwiseConv2D\n from keras_core.layers.core.dense import Dense\n from keras_core.layers.core.einsum_dense import EinsumDense\n from keras_core.layers.core.embedding import Embedding\n\n@@ -0,0 +1,279 @@\n+\"\"\"Keras base class for depthwise convolution layers.\"\"\"\n+\n+from keras_core import activations\n+from keras_core import constraints\n+from keras_core import initializers\n+from keras_core import operations as ops\n+from keras_core import regularizers\n+from keras_core.backend import standardize_data_format\n+from keras_core.layers.input_spec import InputSpec\n+from keras_core.layers.layer import Layer\n+from keras_core.operations.operation_utils import compute_conv_output_shape\n+\n+\n+class BaseDepthwiseConv(Layer):\n+    \"\"\"Abstract N-D depthwise convolution layer.\n+\n+    Depthwise convolution is a type of convolution in which each input channel\n+    is convolved with a different kernel (called a depthwise kernel). You can\n+    understand depthwise convolution as the first step in a depthwise separable\n+    convolution.\n+\n+    It is implemented via the following steps:\n+\n+    - Split the input into individual channels.\n+    - Convolve each channel with an individual depthwise kernel with\n+      `depth_multiplier` output channels.\n+    - Concatenate the convolved outputs along the channels axis.\n+\n+    Unlike a regular convolution, depthwise convolution does not mix information\n+    across different input channels.\n+\n+    The `depth_multiplier` argument determines how many filter are applied to\n+    one input channel. As such, it controls the amount of output channels that\n+    are generated per input channel in the depthwise step.\n+\n+\n+    Args:\n+        rank: int, the rank of the convolution, e.g. 2 for 2D convolution.\n+        depth_multiplier: The number of depthwise convolution output channels\n+            for each input channel. The total number of depthwise convolution\n+            output channels will be equal to `input_channel * depth_multiplier`.\n+        kernel_size: int or tuple/list of N integers (N=`rank`), specifying the\n+            size of the depthwise convolution window.\n+        strides: int or tuple/list of N integers, specifying the stride length\n+            of the depthwise convolution. If only one int is specified, the same\n+            stride size will be used for all dimensions. `stride value != 1` is\n+            incompatible with `dilation_rate != 1`.\n+        padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n+            `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n+            the left/right or up/down of the input such that output has the same\n+            height/width dimension as the input.\n+        data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n+            The ordering of the dimensions in the inputs. `\"channels_last\"`\n+            corresponds to inputs with shape `(batch, steps, features)`\n+            while `\"channels_first\"` corresponds to inputs with shape\n+            `(batch, features, steps)`. It defaults to the `image_data_format`\n+            value found in your Keras config file at `~/.keras/keras.json`.\n+            If you never set it, then it will be `\"channels_last\"`.\n+        dilation_rate: int or tuple/list of N integers, specifying the dilation\n+            rate to use for dilated convolution. If only one int is specified,\n+            the same dilation rate will be used for all dimensions.\n+        activation: Activation function. If `None`, no activation is applied.\n+        use_bias: bool, if `True`, bias will be added to the output.\n+        kernel_initializer: Initializer for the convolution kernel. If `None`,\n+            the default initializer (`\"glorot_uniform\"`) will be used.\n+        bias_initializer: Initializer for the bias vector. If `None`, the\n+            default initializer (`\"zeros\"`) will be used.\n+        kernel_regularizer: Optional regularizer for the convolution kernel.\n+        bias_regularizer: Optional regularizer for the bias vector.\n+        activity_regularizer: Optional regularizer function for the output.\n+        kernel_constraint: Optional projection function to be applied to the\n+            kernel after being updated by an `Optimizer` (e.g. used to implement\n+            norm constraints or value constraints for layer weights). The\n+            function must take as input the unprojected variable and must return\n+            the projected variable (which must have the same shape). Constraints\n+            are not safe to use when doing asynchronous distributed training.\n+        bias_constraint: Optional projection function to be applied to the\n+            bias after being updated by an `Optimizer`.\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        rank,\n+        depth_multiplier,\n+        kernel_size,\n+        strides=1,\n+        padding=\"valid\",\n+        data_format=None,\n+        dilation_rate=1,\n+        activation=None,\n+        use_bias=True,\n+        kernel_initializer=\"glorot_uniform\",\n+        bias_initializer=\"zeros\",\n+        kernel_regularizer=None,\n+        bias_regularizer=None,\n+        activity_regularizer=None,\n+        kernel_constraint=None,\n+        bias_constraint=None,\n+        trainable=True,\n+        name=None,\n+        **kwargs,\n+    ):\n+        super().__init__(\n+            trainable=trainable,\n+            name=name,\n+            activity_regularizer=regularizers.get(activity_regularizer),\n+            **kwargs,\n+        )\n+        self.rank = rank\n+        self.depth_multiplier = depth_multiplier\n+\n+        if isinstance(kernel_size, int):\n+            kernel_size = (kernel_size,) * self.rank\n+        self.kernel_size = kernel_size\n+\n+        if isinstance(strides, int):\n+            strides = (strides,) * self.rank\n+        self.strides = strides\n+\n+        if isinstance(dilation_rate, int):\n+            dilation_rate = (dilation_rate,) * self.rank\n+        self.dilation_rate = dilation_rate\n+\n+        self.padding = padding\n+        self.data_format = standardize_data_format(data_format)\n+        self.activation = activations.get(activation)\n+        self.use_bias = use_bias\n+        self.kernel_initializer = initializers.get(kernel_initializer)\n+        self.bias_initializer = initializers.get(bias_initializer)\n+        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n+        self.bias_regularizer = regularizers.get(bias_regularizer)\n+        self.kernel_constraint = constraints.get(kernel_constraint)\n+        self.bias_constraint = constraints.get(bias_constraint)\n+        self.input_spec = InputSpec(min_ndim=self.rank + 2)\n+        self.data_format = self.data_format\n+\n+        if self.depth_multiplier is not None and self.depth_multiplier <= 0:\n+            raise ValueError(\n+                \"Invalid value for argument `depth_multiplier`. Expected a \"\n+                \"strictly  positive value. Received \"\n+                f\"depth_multiplier={self.depth_multiplier}.\"\n+            )\n+\n+        if not all(self.kernel_size):\n+            raise ValueError(\n+                \"The argument `kernel_size` cannot contain 0(s). Received: \"\n+                f\"{self.kernel_size}\"\n+            )\n+\n+        if not all(self.strides):\n+            raise ValueError(\n+                \"The argument `strides` cannot contains 0(s). Received: \"\n+                f\"{self.strides}\"\n+            )\n+\n+        if max(self.strides) > 1 and max(self.dilation_rate) > 1:\n+            raise ValueError(\n+                \"`strides > 1` not supported in conjunction with \"\n+                f\"`dilation_rate > 1`. Received: strides={self.strides} and \"\n+                f\"dilation_rate={self.dilation_rate}\"\n+            )\n+\n+    def build(self, input_shape):\n+        if self.data_format == \"channels_last\":\n+            channel_axis = -1\n+            input_channel = input_shape[-1]\n+        else:\n+            channel_axis = 1\n+            input_channel = input_shape[1]\n+        self.input_spec = InputSpec(\n+            min_ndim=self.rank + 2, axes={channel_axis: input_channel}\n+        )\n+        kernel_shape = self.kernel_size + (\n+            input_channel,\n+            self.depth_multiplier,\n+        )\n+        self.kernel = self.add_weight(\n+            name=\"kernel\",\n+            shape=kernel_shape,\n+            initializer=self.kernel_initializer,\n+            regularizer=self.kernel_regularizer,\n+            constraint=self.kernel_constraint,\n+            trainable=True,\n+            dtype=self.dtype,\n+        )\n+        if self.use_bias:\n+            self.bias = self.add_weight(\n+                name=\"bias\",\n+                shape=(self.depth_multiplier * input_channel,),\n+                initializer=self.bias_initializer,\n+                regularizer=self.bias_regularizer,\n+                constraint=self.bias_constraint,\n+                trainable=True,\n+                dtype=self.dtype,\n+            )\n+        else:\n+            self.bias = None\n+        self.built = True\n+\n+    def _get_input_channel(self, input_shape):\n+        if self.data_format == \"channels_last\":\n+            input_channel = input_shape[-1]\n+        else:\n+            input_channel = input_shape[1]\n+        return input_channel\n+\n+    def call(self, inputs):\n+        input_channel = self._get_input_channel(inputs.shape)\n+        outputs = ops.depthwise_conv(\n+            inputs,\n+            self.kernel,\n+            strides=self.strides,\n+            padding=self.padding,\n+            dilation_rate=self.dilation_rate,\n+            data_format=self.data_format,\n+        )\n+\n+        if self.use_bias:\n+            if self.data_format == \"channels_last\":\n+                bias_shape = (1,) * (self.rank + 1) + (\n+                    self.depth_multiplier * input_channel,\n+                )\n+            else:\n+                bias_shape = (1, self.depth_multiplier * input_channel) + (\n+                    1,\n+                ) * self.rank\n+            bias = ops.reshape(self.bias, bias_shape)\n+            outputs += bias\n+\n+        if self.activation is not None:\n+            return self.activation(outputs)\n+        return outputs\n+\n+    def compute_output_shape(self, input_shape):\n+        input_channel = self._get_input_channel(input_shape)\n+        return compute_conv_output_shape(\n+            input_shape,\n+            self.depth_multiplier * input_channel,\n+            self.kernel_size,\n+            strides=self.strides,\n+            padding=self.padding,\n+            data_format=self.data_format,\n+            dilation_rate=self.dilation_rate,\n+        )\n+\n+    def get_config(self):\n+        config = super().get_config()\n+        config.update(\n+            {\n+                \"depth_multiplier\": self.depth_multiplier,\n+                \"kernel_size\": self.kernel_size,\n+                \"strides\": self.strides,\n+                \"padding\": self.padding,\n+                \"data_format\": self.data_format,\n+                \"dilation_rate\": self.dilation_rate,\n+                \"activation\": activations.serialize(self.activation),\n+                \"use_bias\": self.use_bias,\n+                \"kernel_initializer\": initializers.serialize(\n+                    self.kernel_initializer\n+                ),\n+                \"bias_initializer\": initializers.serialize(\n+                    self.bias_initializer\n+                ),\n+                \"kernel_regularizer\": regularizers.serialize(\n+                    self.kernel_regularizer\n+                ),\n+                \"bias_regularizer\": regularizers.serialize(\n+                    self.bias_regularizer\n+                ),\n+                \"activity_regularizer\": regularizers.serialize(\n+                    self.activity_regularizer\n+                ),\n+                \"kernel_constraint\": constraints.serialize(\n+                    self.kernel_constraint\n+                ),\n+                \"bias_constraint\": constraints.serialize(self.bias_constraint),\n+            }\n+        )\n+        return config\n\n@@ -0,0 +1,136 @@\n+from keras_core.api_export import keras_core_export\n+from keras_core.layers.convolutional.base_depthwise_conv import (\n+    BaseDepthwiseConv,\n+)\n+\n+\n+@keras_core_export(\"keras_core.layers.DepthwiseConv1D\")\n+class DepthwiseConv1D(BaseDepthwiseConv):\n+    \"\"\"1D depthwise convolution layer.\n+\n+    Depthwise convolution is a type of convolution in which each input channel\n+    is convolved with a different kernel (called a depthwise kernel). You can\n+    understand depthwise convolution as the first step in a depthwise separable\n+    convolution.\n+\n+    It is implemented via the following steps:\n+\n+    - Split the input into individual channels.\n+    - Convolve each channel with an individual depthwise kernel with\n+      `depth_multiplier` output channels.\n+    - Concatenate the convolved outputs along the channels axis.\n+\n+    Unlike a regular 1D convolution, depthwise convolution does not mix\n+    information across different input channels.\n+\n+    The `depth_multiplier` argument determines how many filters are applied to\n+    one input channel. As such, it controls the amount of output channels that\n+    are generated per input channel in the depthwise step.\n+\n+    Args:\n+        depth_multiplier: The number of depthwise convolution output channels\n+            for each input channel. The total number of depthwise convolution\n+            output channels will be equal to `input_channel * depth_multiplier`.\n+        kernel_size: int or tuple/list of 1 integer, specifying the size of the\n+            depthwise convolution window.\n+        strides: int or tuple/list of 1 integer, specifying the stride length\n+            of the convolution. `stride value != 1` is incompatible\n+            with `dilation_rate != 1`.\n+        padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n+            `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n+            the left/right or up/down of the input such that output has the same\n+            height/width dimension as the input.\n+        data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n+            The ordering of the dimensions in the inputs. `\"channels_last\"`\n+            corresponds to inputs with shape `(batch, steps, features)`\n+            while `\"channels_first\"` corresponds to inputs with shape\n+            `(batch, features, steps)`. It defaults to the `image_data_format`\n+            value found in your Keras config file at `~/.keras/keras.json`.\n+            If you never set it, then it will be `\"channels_last\"`.\n+        dilation_rate: int or tuple/list of 1 integers, specifying the dilation\n+            rate to use for dilated convolution.\n+        activation: Activation function. If `None`, no activation is applied.\n+        use_bias: bool, if `True`, bias will be added to the output.\n+        kernel_initializer: Initializer for the convolution kernel. If `None`,\n+            the default initializer (`\"glorot_uniform\"`) will be used.\n+        bias_initializer: Initializer for the bias vector. If `None`, the\n+            default initializer (`\"zeros\"`) will be used.\n+        kernel_regularizer: Optional regularizer for the convolution kernel.\n+        bias_regularizer: Optional regularizer for the bias vector.\n+        activity_regularizer: Optional regularizer function for the output.\n+        kernel_constraint: Optional projection function to be applied to the\n+            kernel after being updated by an `Optimizer` (e.g. used to implement\n+            norm constraints or value constraints for layer weights). The\n+            function must take as input the unprojected variable and must return\n+            the projected variable (which must have the same shape). Constraints\n+            are not safe to use when doing asynchronous distributed training.\n+        bias_constraint: Optional projection function to be applied to the\n+            bias after being updated by an `Optimizer`.\n+\n+    Input shape:\n+    - If `data_format=\"channels_last\"`:\n+        A 3D tensor with shape: `(batch_shape, steps, channels)`\n+    - If `data_format=\"channels_first\"`:\n+        A 3D tensor with shape: `(batch_shape, channels, steps)`\n+\n+    Output shape:\n+    - If `data_format=\"channels_last\"`:\n+        A 3D tensor with shape:\n+        `(batch_shape, new_steps, channels * depth_multiplier)`\n+    - If `data_format=\"channels_first\"`:\n+        A 3D tensor with shape:\n+        `(batch_shape, channels * depth_multiplier, new_steps)`\n+\n+    Returns:\n+        A 3D tensor representing\n+        `activation(depthwise_conv1d(inputs, kernel) + bias)`.\n+\n+    Raises:\n+        ValueError: when both `strides > 1` and `dilation_rate > 1`.\n+\n+    Examples:\n+\n+    >>> x = np.random.rand(4, 10, 12)\n+    >>> y = keras_core.layers.DepthwiseConv1D(3, 3, 2, activation='relu')(x)\n+    >>> print(y.shape)\n+    (4, 4, 36)\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        depth_multiplier,\n+        kernel_size,\n+        strides=1,\n+        padding=\"valid\",\n+        data_format=\"channels_last\",\n+        dilation_rate=1,\n+        activation=None,\n+        use_bias=True,\n+        kernel_initializer=\"glorot_uniform\",\n+        bias_initializer=\"zeros\",\n+        kernel_regularizer=None,\n+        bias_regularizer=None,\n+        activity_regularizer=None,\n+        kernel_constraint=None,\n+        bias_constraint=None,\n+        **kwargs\n+    ):\n+        super().__init__(\n+            rank=1,\n+            depth_multiplier=depth_multiplier,\n+            kernel_size=kernel_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+            dilation_rate=dilation_rate,\n+            activation=activation,\n+            use_bias=use_bias,\n+            kernel_initializer=kernel_initializer,\n+            bias_initializer=bias_initializer,\n+            kernel_regularizer=kernel_regularizer,\n+            bias_regularizer=bias_regularizer,\n+            activity_regularizer=activity_regularizer,\n+            kernel_constraint=kernel_constraint,\n+            bias_constraint=bias_constraint,\n+            **kwargs\n+        )\n\n@@ -0,0 +1,136 @@\n+from keras_core.api_export import keras_core_export\n+from keras_core.layers.convolutional.base_depthwise_conv import (\n+    BaseDepthwiseConv,\n+)\n+\n+\n+@keras_core_export(\"keras_core.layers.DepthwiseConv2D\")\n+class DepthwiseConv2D(BaseDepthwiseConv):\n+    \"\"\"2D depthwise convolution layer.\n+\n+    Depthwise convolution is a type of convolution in which each input channel\n+    is convolved with a different kernel (called a depthwise kernel). You can\n+    understand depthwise convolution as the first step in a depthwise separable\n+    convolution.\n+\n+    It is implemented via the following steps:\n+\n+    - Split the input into individual channels.\n+    - Convolve each channel with an individual depthwise kernel with\n+      `depth_multiplier` output channels.\n+    - Concatenate the convolved outputs along the channels axis.\n+\n+    Unlike a regular 2D convolution, depthwise convolution does not mix\n+    information across different input channels.\n+\n+    The `depth_multiplier` argument determines how many filters are applied to\n+    one input channel. As such, it controls the amount of output channels that\n+    are generated per input channel in the depthwise step.\n+\n+    Args:\n+        depth_multiplier: The number of depthwise convolution output channels\n+            for each input channel. The total number of depthwise convolution\n+            output channels will be equal to `input_channel * depth_multiplier`.\n+        kernel_size: int or tuple/list of 2 integer, specifying the size of the\n+            depthwise convolution window.\n+        strides: int or tuple/list of 2 integer, specifying the stride length\n+            of the depthwise convolution. `stride value != 1` is incompatible\n+            with `dilation_rate != 1`.\n+        padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n+            `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n+            the left/right or up/down of the input such that output has the same\n+            height/width dimension as the input.\n+        data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n+            The ordering of the dimensions in the inputs. `\"channels_last\"`\n+            corresponds to inputs with shape `(batch, steps, features)`\n+            while `\"channels_first\"` corresponds to inputs with shape\n+            `(batch, features, steps)`. It defaults to the `image_data_format`\n+            value found in your Keras config file at `~/.keras/keras.json`.\n+            If you never set it, then it will be `\"channels_last\"`.\n+        dilation_rate: int or tuple/list of 2 integers, specifying the dilation\n+            rate to use for dilated convolution.\n+        activation: Activation function. If `None`, no activation is applied.\n+        use_bias: bool, if `True`, bias will be added to the output.\n+        kernel_initializer: Initializer for the convolution kernel. If `None`,\n+            the default initializer (`\"glorot_uniform\"`) will be used.\n+        bias_initializer: Initializer for the bias vector. If `None`, the\n+            default initializer (`\"zeros\"`) will be used.\n+        kernel_regularizer: Optional regularizer for the convolution kernel.\n+        bias_regularizer: Optional regularizer for the bias vector.\n+        activity_regularizer: Optional regularizer function for the output.\n+        kernel_constraint: Optional projection function to be applied to the\n+            kernel after being updated by an `Optimizer` (e.g. used to implement\n+            norm constraints or value constraints for layer weights). The\n+            function must take as input the unprojected variable and must return\n+            the projected variable (which must have the same shape). Constraints\n+            are not safe to use when doing asynchronous distributed training.\n+        bias_constraint: Optional projection function to be applied to the\n+            bias after being updated by an `Optimizer`.\n+\n+    Input shape:\n+    - If `data_format=\"channels_last\"`:\n+        A 4D tensor with shape: `(batch_size, height, width, channels)`\n+    - If `data_format=\"channels_first\"`:\n+        A 4D tensor with shape: `(batch_size, channels, height, width)`\n+\n+    Output shape:\n+    - If `data_format=\"channels_last\"`:\n+        A 4D tensor with shape:\n+        `(batch_size, new_height, new_width, channels * depth_multiplier)`\n+    - If `data_format=\"channels_first\"`:\n+        A 4D tensor with shape:\n+        `(batch_size, channels * depth_multiplier, new_height, new_width)`\n+\n+    Returns:\n+        A 4D tensor representing\n+        `activation(depthwise_conv2d(inputs, kernel) + bias)`.\n+\n+    Raises:\n+        ValueError: when both `strides > 1` and `dilation_rate > 1`.\n+\n+    Examples:\n+\n+    >>> x = np.random.rand(4, 10, 10, 12)\n+    >>> y = keras_core.layers.DepthwiseConv2D(3, 3, activation='relu')(x)\n+    >>> print(y.shape)\n+    (4, 8, 8, 36)\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        depth_multiplier,\n+        kernel_size,\n+        strides=1,\n+        padding=\"valid\",\n+        data_format=\"channels_last\",\n+        dilation_rate=1,\n+        activation=None,\n+        use_bias=True,\n+        kernel_initializer=\"glorot_uniform\",\n+        bias_initializer=\"zeros\",\n+        kernel_regularizer=None,\n+        bias_regularizer=None,\n+        activity_regularizer=None,\n+        kernel_constraint=None,\n+        bias_constraint=None,\n+        **kwargs\n+    ):\n+        super().__init__(\n+            rank=2,\n+            depth_multiplier=depth_multiplier,\n+            kernel_size=kernel_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+            dilation_rate=dilation_rate,\n+            activation=activation,\n+            use_bias=use_bias,\n+            kernel_initializer=kernel_initializer,\n+            bias_initializer=bias_initializer,\n+            kernel_regularizer=kernel_regularizer,\n+            bias_regularizer=bias_regularizer,\n+            activity_regularizer=activity_regularizer,\n+            kernel_constraint=kernel_constraint,\n+            bias_constraint=bias_constraint,\n+            **kwargs\n+        )\n\n@@ -0,0 +1,294 @@\n+import numpy as np\n+import tensorflow as tf\n+from absl.testing import parameterized\n+\n+from keras_core import layers\n+from keras_core import testing\n+\n+\n+class DepthwiseConvBasicTest(testing.TestCase, parameterized.TestCase):\n+    @parameterized.parameters(\n+        {\n+            \"depth_multiplier\": 5,\n+            \"kernel_size\": 2,\n+            \"strides\": 1,\n+            \"padding\": \"valid\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": 1,\n+            \"input_shape\": (3, 5, 4),\n+            \"output_shape\": (3, 4, 20),\n+        },\n+        {\n+            \"depth_multiplier\": 6,\n+            \"kernel_size\": 2,\n+            \"strides\": 1,\n+            \"padding\": \"same\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": (2,),\n+            \"input_shape\": (3, 4, 4),\n+            \"output_shape\": (3, 4, 24),\n+        },\n+        {\n+            \"depth_multiplier\": 6,\n+            \"kernel_size\": 2,\n+            \"strides\": (2,),\n+            \"padding\": \"valid\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": 1,\n+            \"input_shape\": (3, 5, 4),\n+            \"output_shape\": (3, 2, 24),\n+        },\n+    )\n+    def test_depthwise_conv1d_basic(\n+        self,\n+        depth_multiplier,\n+        kernel_size,\n+        strides,\n+        padding,\n+        data_format,\n+        dilation_rate,\n+        input_shape,\n+        output_shape,\n+    ):\n+        self.run_layer_test(\n+            layers.DepthwiseConv1D,\n+            init_kwargs={\n+                \"depth_multiplier\": depth_multiplier,\n+                \"kernel_size\": kernel_size,\n+                \"strides\": strides,\n+                \"padding\": padding,\n+                \"data_format\": data_format,\n+                \"dilation_rate\": dilation_rate,\n+            },\n+            input_shape=input_shape,\n+            expected_output_shape=output_shape,\n+            expected_num_trainable_weights=2,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_losses=0,\n+            supports_masking=False,\n+        )\n+\n+    @parameterized.parameters(\n+        {\n+            \"depth_multiplier\": 5,\n+            \"kernel_size\": 2,\n+            \"strides\": 1,\n+            \"padding\": \"valid\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": 1,\n+            \"input_shape\": (3, 5, 5, 4),\n+            \"output_shape\": (3, 4, 4, 20),\n+        },\n+        {\n+            \"depth_multiplier\": 6,\n+            \"kernel_size\": 2,\n+            \"strides\": 1,\n+            \"padding\": \"same\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": (2, 2),\n+            \"input_shape\": (3, 4, 4, 4),\n+            \"output_shape\": (3, 4, 4, 24),\n+        },\n+        {\n+            \"depth_multiplier\": 6,\n+            \"kernel_size\": (2, 2),\n+            \"strides\": (2, 2),\n+            \"padding\": \"valid\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": (1, 1),\n+            \"input_shape\": (3, 5, 5, 4),\n+            \"output_shape\": (3, 2, 2, 24),\n+        },\n+    )\n+    def test_depthwise_conv2d_basic(\n+        self,\n+        depth_multiplier,\n+        kernel_size,\n+        strides,\n+        padding,\n+        data_format,\n+        dilation_rate,\n+        input_shape,\n+        output_shape,\n+    ):\n+        self.run_layer_test(\n+            layers.DepthwiseConv2D,\n+            init_kwargs={\n+                \"depth_multiplier\": depth_multiplier,\n+                \"kernel_size\": kernel_size,\n+                \"strides\": strides,\n+                \"padding\": padding,\n+                \"data_format\": data_format,\n+                \"dilation_rate\": dilation_rate,\n+            },\n+            input_shape=input_shape,\n+            expected_output_shape=output_shape,\n+            expected_num_trainable_weights=2,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_losses=0,\n+            supports_masking=False,\n+        )\n+\n+    def test_bad_init_args(self):\n+        # `depth_multiplier` is not positive.\n+        with self.assertRaises(ValueError):\n+            layers.DepthwiseConv1D(depth_multiplier=0, kernel_size=1)\n+\n+        # `kernel_size` has 0.\n+        with self.assertRaises(ValueError):\n+            layers.DepthwiseConv2D(depth_multiplier=2, kernel_size=(1, 0))\n+\n+        # `strides` has 0.\n+        with self.assertRaises(ValueError):\n+            layers.DepthwiseConv2D(\n+                depth_multiplier=2, kernel_size=(2, 2), strides=(1, 0)\n+            )\n+\n+        # `dilation_rate > 1` while `strides > 1`.\n+        with self.assertRaises(ValueError):\n+            layers.DepthwiseConv2D(\n+                depth_multiplier=2,\n+                kernel_size=(2, 2),\n+                strides=2,\n+                dilation_rate=(2, 1),\n+            )\n+\n+\n+class DepthwiseConvCorrectnessTest(testing.TestCase, parameterized.TestCase):\n+    @parameterized.parameters(\n+        {\n+            \"depth_multiplier\": 5,\n+            \"kernel_size\": 2,\n+            \"strides\": 1,\n+            \"padding\": \"valid\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": 1,\n+        },\n+        {\n+            \"depth_multiplier\": 6,\n+            \"kernel_size\": 2,\n+            \"strides\": 1,\n+            \"padding\": \"same\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": (2,),\n+        },\n+        {\n+            \"depth_multiplier\": 6,\n+            \"kernel_size\": (2,),\n+            \"strides\": (2,),\n+            \"padding\": \"valid\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": 1,\n+        },\n+    )\n+    def test_depthwise_conv1d(\n+        self,\n+        depth_multiplier,\n+        kernel_size,\n+        strides,\n+        padding,\n+        data_format,\n+        dilation_rate,\n+    ):\n+        layer = layers.DepthwiseConv1D(\n+            depth_multiplier=depth_multiplier,\n+            kernel_size=kernel_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+            dilation_rate=dilation_rate,\n+        )\n+        tf_keras_layer = tf.keras.layers.DepthwiseConv1D(\n+            depth_multiplier=depth_multiplier,\n+            kernel_size=kernel_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+            dilation_rate=dilation_rate,\n+        )\n+\n+        inputs = np.random.normal(size=[2, 8, 4])\n+        layer.build(input_shape=inputs.shape)\n+        tf_keras_layer.build(input_shape=inputs.shape)\n+\n+        kernel_shape = layer.kernel.shape\n+        kernel_weights = np.random.normal(size=kernel_shape)\n+        bias_weights = np.random.normal(size=(depth_multiplier * 4,))\n+        layer.kernel.assign(kernel_weights)\n+        tf_keras_layer.depthwise_kernel.assign(kernel_weights)\n+\n+        layer.bias.assign(bias_weights)\n+        tf_keras_layer.bias.assign(bias_weights)\n+\n+        outputs = layer(inputs)\n+        expected = tf_keras_layer(inputs)\n+        self.assertAllClose(outputs, expected)\n+\n+    @parameterized.parameters(\n+        {\n+            \"depth_multiplier\": 5,\n+            \"kernel_size\": 2,\n+            \"strides\": 1,\n+            \"padding\": \"valid\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": 1,\n+        },\n+        {\n+            \"depth_multiplier\": 6,\n+            \"kernel_size\": 2,\n+            \"strides\": 1,\n+            \"padding\": \"same\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": (2, 2),\n+        },\n+        {\n+            \"depth_multiplier\": 6,\n+            \"kernel_size\": (2, 2),\n+            \"strides\": (2, 2),\n+            \"padding\": \"valid\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": (1, 1),\n+        },\n+    )\n+    def test_depthwise_conv2d(\n+        self,\n+        depth_multiplier,\n+        kernel_size,\n+        strides,\n+        padding,\n+        data_format,\n+        dilation_rate,\n+    ):\n+        layer = layers.DepthwiseConv2D(\n+            depth_multiplier=depth_multiplier,\n+            kernel_size=kernel_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+            dilation_rate=dilation_rate,\n+        )\n+        tf_keras_layer = tf.keras.layers.DepthwiseConv2D(\n+            depth_multiplier=depth_multiplier,\n+            kernel_size=kernel_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+            dilation_rate=dilation_rate,\n+        )\n+\n+        inputs = np.random.normal(size=[2, 8, 8, 4])\n+        layer.build(input_shape=inputs.shape)\n+        tf_keras_layer.build(input_shape=inputs.shape)\n+\n+        kernel_shape = layer.kernel.shape\n+        kernel_weights = np.random.normal(size=kernel_shape)\n+        bias_weights = np.random.normal(size=(depth_multiplier * 4,))\n+        layer.kernel.assign(kernel_weights)\n+        tf_keras_layer.depthwise_kernel.assign(kernel_weights)\n+\n+        layer.bias.assign(bias_weights)\n+        tf_keras_layer.bias.assign(bias_weights)\n+\n+        outputs = layer(inputs)\n+        expected = tf_keras_layer(inputs)\n+        self.assertAllClose(outputs, expected)\n\n@@ -29,8 +29,6 @@ in_top_k\n ctc ??\n \"\"\"\n \n-import numpy as np\n-\n from keras_core import backend\n from keras_core.backend import KerasTensor\n from keras_core.backend import any_symbolic_tensors\n@@ -565,67 +563,15 @@ class DepthwiseConv(Operation):\n         )\n \n     def compute_output_spec(self, inputs, kernel):\n-        input_shape = inputs.shape\n-        if self.data_format == \"channels_last\":\n-            spatial_shape = input_shape[1:-1]\n-        else:\n-            spatial_shape = input_shape[2:]\n-        if len(kernel.shape) != len(inputs.shape):\n-            raise ValueError(\n-                \"Kernel shape must have the same length as input, but received \"\n-                f\"kernel of shape {kernel.shape} and \"\n-                f\"input of shape {input_shape}.\"\n+        output_shape = operation_utils.compute_conv_output_shape(\n+            inputs.shape,\n+            kernel.shape[-1] * kernel.shape[-2],\n+            kernel.shape[:-2],\n+            self.strides,\n+            self.padding,\n+            self.data_format,\n+            self.dilation_rate,\n         )\n-        if isinstance(self.dilation_rate, int):\n-            dilation_rate = (self.dilation_rate,) * len(spatial_shape)\n-        else:\n-            dilation_rate = self.dilation_rate\n-        if len(dilation_rate) != len(spatial_shape):\n-            raise ValueError(\n-                \"Dilation must be None, scalar or tuple/list of length of \"\n-                \"inputs' spatial shape, but received \"\n-                f\"`dilation_rate={self.dilation_rate}` and input of \"\n-                f\"shape {input_shape}.\"\n-            )\n-        spatial_shape = np.array(spatial_shape)\n-        kernel_spatial_shape = np.array(kernel.shape[:-2])\n-        dilation_rate = np.array(self.dilation_rate)\n-        if self.padding == \"valid\":\n-            output_spatial_shape = (\n-                np.floor(\n-                    (\n-                        spatial_shape\n-                        - dilation_rate * (kernel_spatial_shape - 1)\n-                        - 1\n-                    )\n-                    / self.strides\n-                )\n-                + 1\n-            )\n-            negative_in_shape = np.all(output_spatial_shape < 0)\n-            if negative_in_shape:\n-                raise ValueError(\n-                    \"Computed output size would be negative. Received \"\n-                    f\"`inputs shape={inputs.shape}`, \"\n-                    f\"`kernel spatial size={kernel.size}`, \"\n-                    f\"`dilation_rate={self.dilation_rate}`.\"\n-                )\n-        elif self.padding == \"same\":\n-            output_spatial_shape = (\n-                np.floor((spatial_shape - 1) / self.strides) + 1\n-            )\n-\n-        output_spatial_shape = [int(i) for i in output_spatial_shape]\n-        output_channels = kernel.shape[-1] * kernel.shape[-2]\n-        if self.data_format == \"channels_last\":\n-            output_shape = (\n-                [input_shape[0]] + output_spatial_shape + [output_channels]\n-            )\n-        else:\n-            output_shape = [\n-                input_shape[0],\n-                output_channels,\n-            ] + output_spatial_shape\n         return KerasTensor(output_shape, dtype=inputs.dtype)\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
