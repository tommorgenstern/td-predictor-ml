{"custom_id": "keras#f763aac1d361f157dacd2fbd1dda430f370d79c9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 516 | Lines Deleted: 344 | Files Changed: 3 | Hunks: 26 | Methods Changed: 18 | Complexity Δ (Sum/Max): 21/21 | Churn Δ: 860 | Churn Cumulative: 3292 | Contributors (this commit): 4 | Commits (past 90d): 13 | Contributors (cumulative): 10 | DMM Complexity: 0.08843537414965986\n\nDIFF:\n@@ -7,6 +7,269 @@ from keras_core import layers\n from keras_core import testing\n \n \n+def _same_padding(input_size, kernel_size, stride):\n+    if input_size % stride == 0:\n+        padding = max(kernel_size - stride, 0)\n+    else:\n+        padding = max(kernel_size - (input_size % stride), 0)\n+    return padding // 2, padding - padding // 2\n+\n+\n+def np_conv1d(\n+    x,\n+    kernel_weights,\n+    bias_weights,\n+    strides,\n+    padding,\n+    data_format,\n+    dilation_rate,\n+    groups,\n+):\n+    if data_format == \"channels_first\":\n+        x = x.swapaxes(1, 2)\n+    if isinstance(strides, (tuple, list)):\n+        h_stride = strides[0]\n+    else:\n+        h_stride = strides\n+    if isinstance(dilation_rate, (tuple, list)):\n+        dilation_rate = dilation_rate[0]\n+    kernel_size, ch_in, ch_out = kernel_weights.shape\n+\n+    if dilation_rate > 1:\n+        new_kernel_size = kernel_size + (dilation_rate - 1) * (kernel_size - 1)\n+        new_kernel_weights = np.zeros(\n+            (new_kernel_size, ch_in, ch_out), dtype=kernel_weights.dtype\n+        )\n+        new_kernel_weights[::dilation_rate] = kernel_weights\n+        kernel_weights = new_kernel_weights\n+        kernel_size = kernel_weights.shape[0]\n+\n+    if padding != \"valid\":\n+        n_batch, h_x, _ = x.shape\n+        h_pad = _same_padding(h_x, kernel_size, h_stride)\n+        npad = [(0, 0)] * x.ndim\n+        if padding == \"causal\":\n+            npad[1] = (h_pad[0] + h_pad[1], 0)\n+        else:\n+            npad[1] = h_pad\n+        x = np.pad(x, pad_width=npad, mode=\"constant\", constant_values=0)\n+\n+    n_batch, h_x, _ = x.shape\n+    h_out = int((h_x - kernel_size) / h_stride) + 1\n+\n+    kernel_weights = kernel_weights.reshape(-1, ch_out)\n+    bias_weights = bias_weights.reshape(1, ch_out)\n+\n+    out_grps = []\n+    for grp in range(1, groups + 1):\n+        x_in = x[..., (grp - 1) * ch_in : grp * ch_in]\n+        stride_shape = (n_batch, h_out, kernel_size, ch_in)\n+        strides = (\n+            x_in.strides[0],\n+            h_stride * x_in.strides[1],\n+            x_in.strides[1],\n+            x_in.strides[2],\n+        )\n+        inner_dim = kernel_size * ch_in\n+        x_strided = as_strided(\n+            x_in, shape=stride_shape, strides=strides\n+        ).reshape(n_batch, h_out, inner_dim)\n+        ch_out_groups = ch_out // groups\n+        kernel_weights_grp = kernel_weights[\n+            ..., (grp - 1) * ch_out_groups : grp * ch_out_groups\n+        ]\n+        bias_weights_grp = bias_weights[\n+            ..., (grp - 1) * ch_out_groups : grp * ch_out_groups\n+        ]\n+        out_grps.append(x_strided @ kernel_weights_grp + bias_weights_grp)\n+    out = np.concatenate(out_grps, axis=-1)\n+    if data_format == \"channels_first\":\n+        out = out.swapaxes(1, 2)\n+    return out\n+\n+\n+def np_conv2d(\n+    x,\n+    kernel_weights,\n+    bias_weights,\n+    strides,\n+    padding,\n+    data_format,\n+    dilation_rate,\n+    groups,\n+):\n+    if data_format == \"channels_first\":\n+        x = x.transpose((0, 2, 3, 1))\n+    if isinstance(strides, (tuple, list)):\n+        h_stride, w_stride = strides\n+    else:\n+        h_stride = strides\n+        w_stride = strides\n+    if isinstance(dilation_rate, (tuple, list)):\n+        h_dilation, w_dilation = dilation_rate\n+    else:\n+        h_dilation = dilation_rate\n+        w_dilation = dilation_rate\n+    h_kernel, w_kernel, ch_in, ch_out = kernel_weights.shape\n+\n+    if h_dilation > 1 or w_dilation > 1:\n+        new_h_kernel = h_kernel + (h_dilation - 1) * (h_kernel - 1)\n+        new_w_kernel = w_kernel + (w_dilation - 1) * (w_kernel - 1)\n+        new_kenel_size_tuple = (new_h_kernel, new_w_kernel)\n+        new_kernel_weights = np.zeros(\n+            (*new_kenel_size_tuple, ch_in, ch_out),\n+            dtype=kernel_weights.dtype,\n+        )\n+        new_kernel_weights[::h_dilation, ::w_dilation] = kernel_weights\n+        kernel_weights = new_kernel_weights\n+        h_kernel, w_kernel = kernel_weights.shape[:2]\n+\n+    if padding == \"same\":\n+        n_batch, h_x, w_x, _ = x.shape\n+        h_pad = _same_padding(h_x, h_kernel, h_stride)\n+        w_pad = _same_padding(w_x, w_kernel, w_stride)\n+        npad = [(0, 0)] * x.ndim\n+        npad[1] = h_pad\n+        npad[2] = w_pad\n+        x = np.pad(x, pad_width=npad, mode=\"constant\", constant_values=0)\n+\n+    n_batch, h_x, w_x, _ = x.shape\n+    h_out = int((h_x - h_kernel) / h_stride) + 1\n+    w_out = int((w_x - w_kernel) / w_stride) + 1\n+\n+    out_grps = []\n+    for grp in range(1, groups + 1):\n+        x_in = x[..., (grp - 1) * ch_in : grp * ch_in]\n+        stride_shape = (n_batch, h_out, w_out, h_kernel, w_kernel, ch_in)\n+        strides = (\n+            x_in.strides[0],\n+            h_stride * x_in.strides[1],\n+            w_stride * x_in.strides[2],\n+            x_in.strides[1],\n+            x_in.strides[2],\n+            x_in.strides[3],\n+        )\n+        inner_dim = h_kernel * w_kernel * ch_in\n+        x_strided = as_strided(\n+            x_in, shape=stride_shape, strides=strides\n+        ).reshape(-1, inner_dim)\n+        ch_out_groups = ch_out // groups\n+        kernel_weights_grp = kernel_weights[\n+            ..., (grp - 1) * ch_out_groups : grp * ch_out_groups\n+        ].reshape(-1, ch_out_groups)\n+        bias_weights_grp = bias_weights[\n+            ..., (grp - 1) * ch_out_groups : grp * ch_out_groups\n+        ]\n+        out_grps.append(x_strided @ kernel_weights_grp + bias_weights_grp)\n+    out = np.concatenate(out_grps, axis=-1).reshape(\n+        n_batch, h_out, w_out, ch_out\n+    )\n+    if data_format == \"channels_first\":\n+        out = out.transpose((0, 3, 1, 2))\n+    return out\n+\n+\n+def np_conv3d(\n+    x,\n+    kernel_weights,\n+    bias_weights,\n+    strides,\n+    padding,\n+    data_format,\n+    dilation_rate,\n+    groups,\n+):\n+    if data_format == \"channels_first\":\n+        x = x.transpose((0, 2, 3, 4, 1))\n+    if isinstance(strides, (tuple, list)):\n+        h_stride, w_stride, d_stride = strides\n+    else:\n+        h_stride = strides\n+        w_stride = strides\n+        d_stride = strides\n+    if isinstance(dilation_rate, (tuple, list)):\n+        h_dilation, w_dilation, d_dilation = dilation_rate\n+    else:\n+        h_dilation = dilation_rate\n+        w_dilation = dilation_rate\n+        d_dilation = dilation_rate\n+\n+    h_kernel, w_kernel, d_kernel, ch_in, ch_out = kernel_weights.shape\n+\n+    if h_dilation > 1 or w_dilation > 1 or d_dilation > 1:\n+        new_h_kernel = h_kernel + (h_dilation - 1) * (h_kernel - 1)\n+        new_w_kernel = w_kernel + (w_dilation - 1) * (w_kernel - 1)\n+        new_d_kernel = d_kernel + (d_dilation - 1) * (d_kernel - 1)\n+        new_kenel_size_tuple = (new_h_kernel, new_w_kernel, new_d_kernel)\n+        new_kernel_weights = np.zeros(\n+            (*new_kenel_size_tuple, ch_in, ch_out),\n+            dtype=kernel_weights.dtype,\n+        )\n+        new_kernel_weights[\n+            ::h_dilation, ::w_dilation, ::d_dilation\n+        ] = kernel_weights\n+        kernel_weights = new_kernel_weights\n+        h_kernel, w_kernel, d_kernel = kernel_weights.shape[:3]\n+\n+    if padding == \"same\":\n+        n_batch, h_x, w_x, d_x, _ = x.shape\n+        h_pad = _same_padding(h_x, h_kernel, h_stride)\n+        w_pad = _same_padding(w_x, w_kernel, w_stride)\n+        d_pad = _same_padding(d_x, d_kernel, d_stride)\n+        npad = [(0, 0)] * x.ndim\n+        npad[1] = h_pad\n+        npad[2] = w_pad\n+        npad[3] = d_pad\n+        x = np.pad(x, pad_width=npad, mode=\"constant\", constant_values=0)\n+\n+    n_batch, h_x, w_x, d_x, _ = x.shape\n+    h_out = int((h_x - h_kernel) / h_stride) + 1\n+    w_out = int((w_x - w_kernel) / w_stride) + 1\n+    d_out = int((d_x - d_kernel) / d_stride) + 1\n+\n+    out_grps = []\n+    for grp in range(1, groups + 1):\n+        x_in = x[..., (grp - 1) * ch_in : grp * ch_in]\n+        stride_shape = (\n+            n_batch,\n+            h_out,\n+            w_out,\n+            d_out,\n+            h_kernel,\n+            w_kernel,\n+            d_kernel,\n+            ch_in,\n+        )\n+        strides = (\n+            x_in.strides[0],\n+            h_stride * x_in.strides[1],\n+            w_stride * x_in.strides[2],\n+            d_stride * x_in.strides[3],\n+            x_in.strides[1],\n+            x_in.strides[2],\n+            x_in.strides[3],\n+            x_in.strides[4],\n+        )\n+        inner_dim = h_kernel * w_kernel * d_kernel * ch_in\n+        x_strided = as_strided(\n+            x_in, shape=stride_shape, strides=strides\n+        ).reshape(-1, inner_dim)\n+        ch_out_groups = ch_out // groups\n+        kernel_weights_grp = kernel_weights[\n+            ..., (grp - 1) * ch_out_groups : grp * ch_out_groups\n+        ].reshape(-1, ch_out_groups)\n+        bias_weights_grp = bias_weights[\n+            ..., (grp - 1) * ch_out_groups : grp * ch_out_groups\n+        ]\n+        out_grps.append(x_strided @ kernel_weights_grp + bias_weights_grp)\n+    out = np.concatenate(out_grps, axis=-1).reshape(\n+        n_batch, h_out, w_out, d_out, ch_out\n+    )\n+    if data_format == \"channels_first\":\n+        out = out.transpose((0, 4, 1, 2, 3))\n+    return out\n+\n+\n class ConvBasicTest(testing.TestCase, parameterized.TestCase):\n     @parameterized.parameters(\n         {\n@@ -245,270 +508,6 @@ class ConvBasicTest(testing.TestCase, parameterized.TestCase):\n \n \n class ConvCorrectnessTest(testing.TestCase, parameterized.TestCase):\n-    def _same_padding(self, input_size, kernel_size, stride):\n-        if input_size % stride == 0:\n-            padding = max(kernel_size - stride, 0)\n-        else:\n-            padding = max(kernel_size - (input_size % stride), 0)\n-        return padding // 2, padding - padding // 2\n-\n-    def _np_conv1d(\n-        self,\n-        x,\n-        kernel_weights,\n-        bias_weights,\n-        strides,\n-        padding,\n-        data_format,\n-        dilation_rate,\n-        groups,\n-    ):\n-        if data_format == \"channels_first\":\n-            x = x.swapaxes(1, 2)\n-        if isinstance(strides, (tuple, list)):\n-            h_stride = strides[0]\n-        else:\n-            h_stride = strides\n-        if isinstance(dilation_rate, (tuple, list)):\n-            dilation_rate = dilation_rate[0]\n-        kernel_size, ch_in, ch_out = kernel_weights.shape\n-\n-        if dilation_rate > 1:\n-            new_kernel_size = kernel_size + (dilation_rate - 1) * (\n-                kernel_size - 1\n-            )\n-            new_kernel_weights = np.zeros(\n-                (new_kernel_size, ch_in, ch_out), dtype=kernel_weights.dtype\n-            )\n-            new_kernel_weights[::dilation_rate] = kernel_weights\n-            kernel_weights = new_kernel_weights\n-            kernel_size = kernel_weights.shape[0]\n-\n-        if padding != \"valid\":\n-            n_batch, h_x, _ = x.shape\n-            h_pad = self._same_padding(h_x, kernel_size, h_stride)\n-            npad = [(0, 0)] * x.ndim\n-            if padding == \"causal\":\n-                npad[1] = (h_pad[0] + h_pad[1], 0)\n-            else:\n-                npad[1] = h_pad\n-            x = np.pad(x, pad_width=npad, mode=\"constant\", constant_values=0)\n-\n-        n_batch, h_x, _ = x.shape\n-        h_out = int((h_x - kernel_size) / h_stride) + 1\n-\n-        kernel_weights = kernel_weights.reshape(-1, ch_out)\n-        bias_weights = bias_weights.reshape(1, ch_out)\n-\n-        out_grps = []\n-        for grp in range(1, groups + 1):\n-            x_in = x[..., (grp - 1) * ch_in : grp * ch_in]\n-            stride_shape = (n_batch, h_out, kernel_size, ch_in)\n-            strides = (\n-                x_in.strides[0],\n-                h_stride * x_in.strides[1],\n-                x_in.strides[1],\n-                x_in.strides[2],\n-            )\n-            inner_dim = kernel_size * ch_in\n-            x_strided = as_strided(\n-                x_in, shape=stride_shape, strides=strides\n-            ).reshape(n_batch, h_out, inner_dim)\n-            ch_out_groups = ch_out // groups\n-            kernel_weights_grp = kernel_weights[\n-                ..., (grp - 1) * ch_out_groups : grp * ch_out_groups\n-            ]\n-            bias_weights_grp = bias_weights[\n-                ..., (grp - 1) * ch_out_groups : grp * ch_out_groups\n-            ]\n-            out_grps.append(x_strided @ kernel_weights_grp + bias_weights_grp)\n-        out = np.concatenate(out_grps, axis=-1)\n-        if data_format == \"channels_first\":\n-            out = out.swapaxes(1, 2)\n-        return out\n-\n-    def _np_conv2d(\n-        self,\n-        x,\n-        kernel_weights,\n-        bias_weights,\n-        strides,\n-        padding,\n-        data_format,\n-        dilation_rate,\n-        groups,\n-    ):\n-        if data_format == \"channels_first\":\n-            x = x.transpose((0, 2, 3, 1))\n-        if isinstance(strides, (tuple, list)):\n-            h_stride, w_stride = strides\n-        else:\n-            h_stride = strides\n-            w_stride = strides\n-        if isinstance(dilation_rate, (tuple, list)):\n-            h_dilation, w_dilation = dilation_rate\n-        else:\n-            h_dilation = dilation_rate\n-            w_dilation = dilation_rate\n-        h_kernel, w_kernel, ch_in, ch_out = kernel_weights.shape\n-\n-        if h_dilation > 1 or w_dilation > 1:\n-            new_h_kernel = h_kernel + (h_dilation - 1) * (h_kernel - 1)\n-            new_w_kernel = w_kernel + (w_dilation - 1) * (w_kernel - 1)\n-            new_kenel_size_tuple = (new_h_kernel, new_w_kernel)\n-            new_kernel_weights = np.zeros(\n-                (*new_kenel_size_tuple, ch_in, ch_out),\n-                dtype=kernel_weights.dtype,\n-            )\n-            new_kernel_weights[::h_dilation, ::w_dilation] = kernel_weights\n-            kernel_weights = new_kernel_weights\n-            h_kernel, w_kernel = kernel_weights.shape[:2]\n-\n-        if padding == \"same\":\n-            n_batch, h_x, w_x, _ = x.shape\n-            h_pad = self._same_padding(h_x, h_kernel, h_stride)\n-            w_pad = self._same_padding(w_x, w_kernel, w_stride)\n-            npad = [(0, 0)] * x.ndim\n-            npad[1] = h_pad\n-            npad[2] = w_pad\n-            x = np.pad(x, pad_width=npad, mode=\"constant\", constant_values=0)\n-\n-        n_batch, h_x, w_x, _ = x.shape\n-        h_out = int((h_x - h_kernel) / h_stride) + 1\n-        w_out = int((w_x - w_kernel) / w_stride) + 1\n-\n-        out_grps = []\n-        for grp in range(1, groups + 1):\n-            x_in = x[..., (grp - 1) * ch_in : grp * ch_in]\n-            stride_shape = (n_batch, h_out, w_out, h_kernel, w_kernel, ch_in)\n-            strides = (\n-                x_in.strides[0],\n-                h_stride * x_in.strides[1],\n-                w_stride * x_in.strides[2],\n-                x_in.strides[1],\n-                x_in.strides[2],\n-                x_in.strides[3],\n-            )\n-            inner_dim = h_kernel * w_kernel * ch_in\n-            x_strided = as_strided(\n-                x_in, shape=stride_shape, strides=strides\n-            ).reshape(-1, inner_dim)\n-            ch_out_groups = ch_out // groups\n-            kernel_weights_grp = kernel_weights[\n-                ..., (grp - 1) * ch_out_groups : grp * ch_out_groups\n-            ].reshape(-1, ch_out_groups)\n-            bias_weights_grp = bias_weights[\n-                ..., (grp - 1) * ch_out_groups : grp * ch_out_groups\n-            ]\n-            out_grps.append(x_strided @ kernel_weights_grp + bias_weights_grp)\n-        out = np.concatenate(out_grps, axis=-1).reshape(\n-            n_batch, h_out, w_out, ch_out\n-        )\n-        if data_format == \"channels_first\":\n-            out = out.transpose((0, 3, 1, 2))\n-        return out\n-\n-    def _np_conv3d(\n-        self,\n-        x,\n-        kernel_weights,\n-        bias_weights,\n-        strides,\n-        padding,\n-        data_format,\n-        dilation_rate,\n-        groups,\n-    ):\n-        if data_format == \"channels_first\":\n-            x = x.transpose((0, 2, 3, 4, 1))\n-        if isinstance(strides, (tuple, list)):\n-            h_stride, w_stride, d_stride = strides\n-        else:\n-            h_stride = strides\n-            w_stride = strides\n-            d_stride = strides\n-        if isinstance(dilation_rate, (tuple, list)):\n-            h_dilation, w_dilation, d_dilation = dilation_rate\n-        else:\n-            h_dilation = dilation_rate\n-            w_dilation = dilation_rate\n-            d_dilation = dilation_rate\n-\n-        h_kernel, w_kernel, d_kernel, ch_in, ch_out = kernel_weights.shape\n-\n-        if h_dilation > 1 or w_dilation > 1 or d_dilation > 1:\n-            new_h_kernel = h_kernel + (h_dilation - 1) * (h_kernel - 1)\n-            new_w_kernel = w_kernel + (w_dilation - 1) * (w_kernel - 1)\n-            new_d_kernel = d_kernel + (d_dilation - 1) * (d_kernel - 1)\n-            new_kenel_size_tuple = (new_h_kernel, new_w_kernel, new_d_kernel)\n-            new_kernel_weights = np.zeros(\n-                (*new_kenel_size_tuple, ch_in, ch_out),\n-                dtype=kernel_weights.dtype,\n-            )\n-            new_kernel_weights[\n-                ::h_dilation, ::w_dilation, ::d_dilation\n-            ] = kernel_weights\n-            kernel_weights = new_kernel_weights\n-            h_kernel, w_kernel, d_kernel = kernel_weights.shape[:3]\n-\n-        if padding == \"same\":\n-            n_batch, h_x, w_x, d_x, _ = x.shape\n-            h_pad = self._same_padding(h_x, h_kernel, h_stride)\n-            w_pad = self._same_padding(w_x, w_kernel, w_stride)\n-            d_pad = self._same_padding(d_x, d_kernel, d_stride)\n-            npad = [(0, 0)] * x.ndim\n-            npad[1] = h_pad\n-            npad[2] = w_pad\n-            npad[3] = d_pad\n-            x = np.pad(x, pad_width=npad, mode=\"constant\", constant_values=0)\n-\n-        n_batch, h_x, w_x, d_x, _ = x.shape\n-        h_out = int((h_x - h_kernel) / h_stride) + 1\n-        w_out = int((w_x - w_kernel) / w_stride) + 1\n-        d_out = int((d_x - d_kernel) / d_stride) + 1\n-\n-        out_grps = []\n-        for grp in range(1, groups + 1):\n-            x_in = x[..., (grp - 1) * ch_in : grp * ch_in]\n-            stride_shape = (\n-                n_batch,\n-                h_out,\n-                w_out,\n-                d_out,\n-                h_kernel,\n-                w_kernel,\n-                d_kernel,\n-                ch_in,\n-            )\n-            strides = (\n-                x_in.strides[0],\n-                h_stride * x_in.strides[1],\n-                w_stride * x_in.strides[2],\n-                d_stride * x_in.strides[3],\n-                x_in.strides[1],\n-                x_in.strides[2],\n-                x_in.strides[3],\n-                x_in.strides[4],\n-            )\n-            inner_dim = h_kernel * w_kernel * d_kernel * ch_in\n-            x_strided = as_strided(\n-                x_in, shape=stride_shape, strides=strides\n-            ).reshape(-1, inner_dim)\n-            ch_out_groups = ch_out // groups\n-            kernel_weights_grp = kernel_weights[\n-                ..., (grp - 1) * ch_out_groups : grp * ch_out_groups\n-            ].reshape(-1, ch_out_groups)\n-            bias_weights_grp = bias_weights[\n-                ..., (grp - 1) * ch_out_groups : grp * ch_out_groups\n-            ]\n-            out_grps.append(x_strided @ kernel_weights_grp + bias_weights_grp)\n-        out = np.concatenate(out_grps, axis=-1).reshape(\n-            n_batch, h_out, w_out, d_out, ch_out\n-        )\n-        if data_format == \"channels_first\":\n-            out = out.transpose((0, 4, 1, 2, 3))\n-        return out\n-\n     @parameterized.parameters(\n         {\n             \"filters\": 5,\n@@ -586,7 +585,7 @@ class ConvCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         layer.bias.assign(bias_weights)\n \n         outputs = layer(inputs)\n-        expected = self._np_conv1d(\n+        expected = np_conv1d(\n             inputs,\n             kernel_weights,\n             bias_weights,\n@@ -684,7 +683,7 @@ class ConvCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         layer.bias.assign(bias_weights)\n \n         outputs = layer(inputs)\n-        expected = self._np_conv2d(\n+        expected = np_conv2d(\n             inputs,\n             kernel_weights,\n             bias_weights,\n@@ -773,7 +772,7 @@ class ConvCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         layer.bias.assign(bias_weights)\n \n         outputs = layer(inputs)\n-        expected = self._np_conv3d(\n+        expected = np_conv3d(\n             inputs,\n             kernel_weights,\n             bias_weights,\n\n@@ -1,12 +1,171 @@\n import numpy as np\n import pytest\n-import tensorflow as tf\n from absl.testing import parameterized\n+from numpy.lib.stride_tricks import as_strided\n \n from keras_core import layers\n from keras_core import testing\n \n \n+def _same_padding(input_size, kernel_size, stride):\n+    if input_size % stride == 0:\n+        padding = max(kernel_size - stride, 0)\n+    else:\n+        padding = max(kernel_size - (input_size % stride), 0)\n+    return padding // 2, padding - padding // 2\n+\n+\n+def np_depthwise_conv1d(\n+    x,\n+    kernel_weights,\n+    bias_weights,\n+    strides,\n+    padding,\n+    data_format,\n+    dilation_rate,\n+):\n+    if data_format == \"channels_first\":\n+        x = x.transpose((0, 2, 1))\n+    if isinstance(strides, (tuple, list)):\n+        h_stride = strides[0]\n+    else:\n+        h_stride = strides\n+    if isinstance(dilation_rate, (tuple, list)):\n+        h_dilation = dilation_rate[0]\n+    else:\n+        h_dilation = dilation_rate\n+    h_kernel, ch_in, ch_out = kernel_weights.shape\n+\n+    if h_dilation > 1:\n+        new_h_kernel = h_kernel + (h_dilation - 1) * (h_kernel - 1)\n+        new_kernel_weights = np.zeros(\n+            (new_h_kernel, ch_in, ch_out),\n+            dtype=kernel_weights.dtype,\n+        )\n+        new_kernel_weights[::h_dilation] = kernel_weights\n+        kernel_weights = new_kernel_weights\n+        h_kernel = kernel_weights.shape[0]\n+\n+    if padding == \"same\":\n+        n_batch, h_x, _ = x.shape\n+        h_pad = _same_padding(h_x, h_kernel, h_stride)\n+        npad = [(0, 0)] * x.ndim\n+        npad[1] = h_pad\n+        x = np.pad(x, pad_width=npad, mode=\"constant\", constant_values=0)\n+\n+    n_batch, h_x, _ = x.shape\n+    h_out = int((h_x - h_kernel) / h_stride) + 1\n+\n+    out_grps = []\n+    bias_weights = bias_weights.reshape(ch_in, ch_out)\n+    for ch_in_idx in range(ch_in):\n+        for ch_out_idx in range(ch_out):\n+            x_in = np.ascontiguousarray(x[..., ch_in_idx])\n+            stride_shape = (n_batch, h_out, h_kernel)\n+            strides = (\n+                x_in.strides[0],\n+                h_stride * x_in.strides[1],\n+                x_in.strides[1],\n+            )\n+            inner_dim = h_kernel\n+            x_strided = as_strided(\n+                x_in, shape=stride_shape, strides=strides\n+            ).reshape(-1, inner_dim)\n+            kernel_weights_grp = kernel_weights[\n+                ..., ch_in_idx, ch_out_idx\n+            ].reshape(-1, 1)\n+            bias_weights_grp = bias_weights[..., ch_in_idx, ch_out_idx]\n+            out_grps.append(\n+                (x_strided @ kernel_weights_grp + bias_weights_grp).reshape(\n+                    n_batch, h_out, 1\n+                )\n+            )\n+    out = np.concatenate(out_grps, axis=-1)\n+    if data_format == \"channels_first\":\n+        out = out.transpose((0, 2, 1))\n+    return out\n+\n+\n+def np_depthwise_conv2d(\n+    x,\n+    kernel_weights,\n+    bias_weights,\n+    strides,\n+    padding,\n+    data_format,\n+    dilation_rate,\n+):\n+    if data_format == \"channels_first\":\n+        x = x.transpose((0, 2, 3, 1))\n+    if isinstance(strides, (tuple, list)):\n+        h_stride, w_stride = strides\n+    else:\n+        h_stride = strides\n+        w_stride = strides\n+    if isinstance(dilation_rate, (tuple, list)):\n+        h_dilation, w_dilation = dilation_rate\n+    else:\n+        h_dilation = dilation_rate\n+        w_dilation = dilation_rate\n+    h_kernel, w_kernel, ch_in, ch_out = kernel_weights.shape\n+\n+    if h_dilation > 1 or w_dilation > 1:\n+        new_h_kernel = h_kernel + (h_dilation - 1) * (h_kernel - 1)\n+        new_w_kernel = w_kernel + (w_dilation - 1) * (w_kernel - 1)\n+        new_kenel_size_tuple = (new_h_kernel, new_w_kernel)\n+        new_kernel_weights = np.zeros(\n+            (*new_kenel_size_tuple, ch_in, ch_out),\n+            dtype=kernel_weights.dtype,\n+        )\n+        new_kernel_weights[::h_dilation, ::w_dilation] = kernel_weights\n+        kernel_weights = new_kernel_weights\n+        h_kernel, w_kernel = kernel_weights.shape[:2]\n+\n+    if padding == \"same\":\n+        n_batch, h_x, w_x, _ = x.shape\n+        h_pad = _same_padding(h_x, h_kernel, h_stride)\n+        w_pad = _same_padding(w_x, w_kernel, w_stride)\n+        npad = [(0, 0)] * x.ndim\n+        npad[1] = h_pad\n+        npad[2] = w_pad\n+        x = np.pad(x, pad_width=npad, mode=\"constant\", constant_values=0)\n+\n+    n_batch, h_x, w_x, _ = x.shape\n+    h_out = int((h_x - h_kernel) / h_stride) + 1\n+    w_out = int((w_x - w_kernel) / w_stride) + 1\n+\n+    out_grps = []\n+    bias_weights = bias_weights.reshape(ch_in, ch_out)\n+    for ch_in_idx in range(ch_in):\n+        for ch_out_idx in range(ch_out):\n+            x_in = np.ascontiguousarray(x[..., ch_in_idx])\n+            stride_shape = (n_batch, h_out, w_out, h_kernel, w_kernel)\n+            strides = (\n+                x_in.strides[0],\n+                h_stride * x_in.strides[1],\n+                w_stride * x_in.strides[2],\n+                x_in.strides[1],\n+                x_in.strides[2],\n+            )\n+            inner_dim = h_kernel * w_kernel\n+            x_strided = as_strided(\n+                x_in, shape=stride_shape, strides=strides\n+            ).reshape(-1, inner_dim)\n+            kernel_weights_grp = kernel_weights[\n+                ..., ch_in_idx, ch_out_idx\n+            ].reshape(-1, 1)\n+            bias_weights_grp = bias_weights[..., ch_in_idx, ch_out_idx]\n+            out_grps.append(\n+                (x_strided @ kernel_weights_grp + bias_weights_grp).reshape(\n+                    n_batch, h_out, w_out, 1\n+                )\n+            )\n+    out = np.concatenate(out_grps, axis=-1)\n+    if data_format == \"channels_first\":\n+        out = out.transpose((0, 3, 1, 2))\n+    return out\n+\n+\n class DepthwiseConvBasicTest(testing.TestCase, parameterized.TestCase):\n     @parameterized.parameters(\n         {\n@@ -201,30 +360,26 @@ class DepthwiseConvCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             data_format=data_format,\n             dilation_rate=dilation_rate,\n         )\n-        tf_keras_layer = tf.keras.layers.DepthwiseConv1D(\n-            depth_multiplier=depth_multiplier,\n-            kernel_size=kernel_size,\n-            strides=strides,\n-            padding=padding,\n-            data_format=data_format,\n-            dilation_rate=dilation_rate,\n-        )\n \n         inputs = np.random.normal(size=[2, 8, 4])\n         layer.build(input_shape=inputs.shape)\n-        tf_keras_layer.build(input_shape=inputs.shape)\n \n         kernel_shape = layer.kernel.shape\n         kernel_weights = np.random.normal(size=kernel_shape)\n         bias_weights = np.random.normal(size=(depth_multiplier * 4,))\n         layer.kernel.assign(kernel_weights)\n-        tf_keras_layer.depthwise_kernel.assign(kernel_weights)\n-\n         layer.bias.assign(bias_weights)\n-        tf_keras_layer.bias.assign(bias_weights)\n \n         outputs = layer(inputs)\n-        expected = tf_keras_layer(inputs)\n+        expected = np_depthwise_conv1d(\n+            inputs,\n+            kernel_weights,\n+            bias_weights,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+            dilation_rate=dilation_rate,\n+        )\n         self.assertAllClose(outputs, expected)\n \n     @parameterized.parameters(\n@@ -270,28 +425,25 @@ class DepthwiseConvCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             data_format=data_format,\n             dilation_rate=dilation_rate,\n         )\n-        tf_keras_layer = tf.keras.layers.DepthwiseConv2D(\n-            depth_multiplier=depth_multiplier,\n-            kernel_size=kernel_size,\n-            strides=strides,\n-            padding=padding,\n-            data_format=data_format,\n-            dilation_rate=dilation_rate,\n-        )\n \n         inputs = np.random.normal(size=[2, 8, 8, 4])\n         layer.build(input_shape=inputs.shape)\n-        tf_keras_layer.build(input_shape=inputs.shape)\n \n         kernel_shape = layer.kernel.shape\n         kernel_weights = np.random.normal(size=kernel_shape)\n         bias_weights = np.random.normal(size=(depth_multiplier * 4,))\n         layer.kernel.assign(kernel_weights)\n-        tf_keras_layer.depthwise_kernel.assign(kernel_weights)\n-\n         layer.bias.assign(bias_weights)\n-        tf_keras_layer.bias.assign(bias_weights)\n \n         outputs = layer(inputs)\n-        expected = tf_keras_layer(inputs)\n-        self.assertAllClose(outputs, expected)\n+        expected = np_depthwise_conv2d(\n+            inputs,\n+            kernel_weights,\n+            bias_weights,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+            dilation_rate=dilation_rate,\n+        )\n+        self.assertAllClose(outputs.shape, expected.shape)\n+        self.assertAllClose(outputs, expected, atol=1e-5)\n\n@@ -1,10 +1,17 @@\n import numpy as np\n import pytest\n-import tensorflow as tf\n from absl.testing import parameterized\n \n from keras_core import layers\n from keras_core import testing\n+from keras_core.layers.convolutional.conv_test import np_conv1d\n+from keras_core.layers.convolutional.conv_test import np_conv2d\n+from keras_core.layers.convolutional.depthwise_conv_test import (\n+    np_depthwise_conv1d,\n+)\n+from keras_core.layers.convolutional.depthwise_conv_test import (\n+    np_depthwise_conv2d,\n+)\n \n \n class SeparableConvBasicTest(testing.TestCase, parameterized.TestCase):\n@@ -226,36 +233,43 @@ class SeparableConvCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             data_format=data_format,\n             dilation_rate=dilation_rate,\n         )\n-        tf_keras_layer = tf.keras.layers.SeparableConv1D(\n-            depth_multiplier=depth_multiplier,\n-            filters=filters,\n-            kernel_size=kernel_size,\n+\n+        inputs = np.random.normal(size=[2, 8, 4])\n+        layer.build(input_shape=inputs.shape)\n+\n+        depthwise_kernel_shape = layer.depthwise_kernel.shape\n+        depthwise_kernel_weights = np.random.normal(size=depthwise_kernel_shape)\n+        layer.depthwise_kernel.assign(depthwise_kernel_weights)\n+\n+        pointwise_kernel_shape = layer.pointwise_kernel.shape\n+        pointwise_kernel_weights = np.random.normal(size=pointwise_kernel_shape)\n+        layer.pointwise_kernel.assign(pointwise_kernel_weights)\n+\n+        bias_weights = np.random.normal(size=(filters,))\n+        layer.bias.assign(bias_weights)\n+\n+        outputs = layer(inputs)\n+        expected_depthwise = np_depthwise_conv1d(\n+            inputs,\n+            depthwise_kernel_weights,\n+            np.zeros(4 * depth_multiplier),\n             strides=strides,\n             padding=padding,\n             data_format=data_format,\n             dilation_rate=dilation_rate,\n         )\n+        expected = np_conv1d(\n+            expected_depthwise,\n+            pointwise_kernel_weights,\n+            bias_weights,\n+            strides=1,\n+            padding=padding,\n+            data_format=data_format,\n+            dilation_rate=1,\n+            groups=1,\n+        )\n \n-        inputs = np.random.normal(size=[2, 8, 4])\n-        layer.build(input_shape=inputs.shape)\n-        tf_keras_layer.build(input_shape=inputs.shape)\n-\n-        depthwise_kernel_shape = layer.depthwise_kernel.shape\n-        depthwise_kernel_weights = np.random.normal(size=depthwise_kernel_shape)\n-        layer.depthwise_kernel.assign(depthwise_kernel_weights)\n-        tf_keras_layer.depthwise_kernel.assign(depthwise_kernel_weights)\n-\n-        pointwise_kernel_shape = layer.pointwise_kernel.shape\n-        pointwise_kernel_weights = np.random.normal(size=pointwise_kernel_shape)\n-        layer.pointwise_kernel.assign(pointwise_kernel_weights)\n-        tf_keras_layer.pointwise_kernel.assign(pointwise_kernel_weights)\n-\n-        bias_weights = np.random.normal(size=(filters,))\n-        layer.bias.assign(bias_weights)\n-        tf_keras_layer.bias.assign(bias_weights)\n-\n-        outputs = layer(inputs)\n-        expected = tf_keras_layer(inputs)\n+        self.assertAllClose(outputs.shape, expected.shape)\n         self.assertAllClose(outputs, expected, rtol=1e-5, atol=1e-5)\n \n     @parameterized.parameters(\n@@ -306,34 +320,41 @@ class SeparableConvCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             data_format=data_format,\n             dilation_rate=dilation_rate,\n         )\n-        tf_keras_layer = tf.keras.layers.SeparableConv2D(\n-            depth_multiplier=depth_multiplier,\n-            filters=filters,\n-            kernel_size=kernel_size,\n+\n+        inputs = np.random.normal(size=[2, 8, 8, 4])\n+        layer.build(input_shape=inputs.shape)\n+\n+        depthwise_kernel_shape = layer.depthwise_kernel.shape\n+        depthwise_kernel_weights = np.random.normal(size=depthwise_kernel_shape)\n+        layer.depthwise_kernel.assign(depthwise_kernel_weights)\n+\n+        pointwise_kernel_shape = layer.pointwise_kernel.shape\n+        pointwise_kernel_weights = np.random.normal(size=pointwise_kernel_shape)\n+        layer.pointwise_kernel.assign(pointwise_kernel_weights)\n+\n+        bias_weights = np.random.normal(size=(filters,))\n+        layer.bias.assign(bias_weights)\n+\n+        outputs = layer(inputs)\n+        expected_depthwise = np_depthwise_conv2d(\n+            inputs,\n+            depthwise_kernel_weights,\n+            np.zeros(4 * depth_multiplier),\n             strides=strides,\n             padding=padding,\n             data_format=data_format,\n             dilation_rate=dilation_rate,\n         )\n+        expected = np_conv2d(\n+            expected_depthwise,\n+            pointwise_kernel_weights,\n+            bias_weights,\n+            strides=1,\n+            padding=padding,\n+            data_format=data_format,\n+            dilation_rate=1,\n+            groups=1,\n+        )\n \n-        inputs = np.random.normal(size=[2, 8, 8, 4])\n-        layer.build(input_shape=inputs.shape)\n-        tf_keras_layer.build(input_shape=inputs.shape)\n-\n-        depthwise_kernel_shape = layer.depthwise_kernel.shape\n-        depthwise_kernel_weights = np.random.normal(size=depthwise_kernel_shape)\n-        layer.depthwise_kernel.assign(depthwise_kernel_weights)\n-        tf_keras_layer.depthwise_kernel.assign(depthwise_kernel_weights)\n-\n-        pointwise_kernel_shape = layer.pointwise_kernel.shape\n-        pointwise_kernel_weights = np.random.normal(size=pointwise_kernel_shape)\n-        layer.pointwise_kernel.assign(pointwise_kernel_weights)\n-        tf_keras_layer.pointwise_kernel.assign(pointwise_kernel_weights)\n-\n-        bias_weights = np.random.normal(size=(filters,))\n-        layer.bias.assign(bias_weights)\n-        tf_keras_layer.bias.assign(bias_weights)\n-\n-        outputs = layer(inputs)\n-        expected = tf_keras_layer(inputs)\n+        self.assertAllClose(outputs.shape, expected.shape)\n         self.assertAllClose(outputs, expected, rtol=1e-5, atol=1e-5)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#26136ecc2c675e404c78a8ec46d0e7bc5f09614d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 64 | Lines Deleted: 8 | Files Changed: 2 | Hunks: 9 | Methods Changed: 7 | Complexity Δ (Sum/Max): 5/4 | Churn Δ: 72 | Churn Cumulative: 3809 | Contributors (this commit): 12 | Commits (past 90d): 46 | Contributors (cumulative): 19 | DMM Complexity: 0.9166666666666666\n\nDIFF:\n@@ -200,21 +200,50 @@ def shape_equal(shape1, shape2, axis=None, allow_none=True):\n     \"\"\"Check if two shapes are equal.\n \n     Args:\n-        shape1: A tuple or list of integers.\n-        shape2: A tuple or list of integers.\n-        axis: int or list/tuple of ints, defaults to `None`. If specified, the\n-            shape check will ignore the axes specified by `axis`.\n-        allow_none: bool, defaults to `True`. If `True`, `None` in the shape\n-            will match any value.\n+        shape1: A list or tuple of integers for first shape to be compared.\n+        shape2: A list or tuple of integers for second shape to be compared.\n+        axis: An integer, list, or tuple of integers (optional):\n+            Axes to ignore during comparison. Default is `None`.\n+        allow_none (bool, optional): If `True`, allows `None` in a shape\n+            to match any value in the corresponding position of the other shape.\n+            Default is `True`.\n+\n+    Returns:\n+        bool: `True` if shapes are considered equal based on the criteria,\n+        `False` otherwise.\n+\n+    Examples:\n+\n+    >>> shape_equal((32, 64, 128), (32, 64, 128))\n+    True\n+    >>> shape_equal((32, 64, 128), (32, 64, 127))\n+    False\n+    >>> shape_equal((32, 64, None), (32, 64, 128), allow_none=True)\n+    True\n+    >>> shape_equal((32, 64, None), (32, 64, 128), allow_none=False)\n+    False\n+    >>> shape_equal((32, 64, 128), (32, 63, 128), axis=1)\n+    True\n+    >>> shape_equal((32, 64, 128), (32, 63, 127), axis=(1, 2))\n+    True\n+    >>> shape_equal((32, 64, 128), (32, 63, 127), axis=[1,2])\n+    True\n+    >>> shape_equal((32, 64), (32, 64, 128))\n+    False\n     \"\"\"\n     if len(shape1) != len(shape2):\n         return False\n+\n     shape1 = list(shape1)\n     shape2 = list(shape2)\n+\n     if axis is not None:\n+        if isinstance(axis, int):\n+            axis = [axis]\n         for ax in axis:\n             shape1[ax] = -1\n             shape2[ax] = -1\n+\n     if allow_none:\n         for i in range(len(shape1)):\n             if shape1[i] is None:\n@@ -246,9 +275,10 @@ def absolute(x):\n         An array containing the absolute value of each element in `x`.\n \n     Example:\n+\n     >>> x = keras_core.ops.convert_to_tensor([-1.2, 1.2])\n     >>> keras_core.ops.absolute(x)\n-    array([1.2 1.2], shape=(2,), dtype=float32)\n+    array([1.2, 1.2], dtype=float32)\n     \"\"\"\n     if any_symbolic_tensors((x,)):\n         return Absolute().symbolic_call(x)\n@@ -291,7 +321,7 @@ def add(x1, x2):\n     >>> x1 = keras_core.ops.convert_to_tensor([1, 4])\n     >>> x2 = keras_core.ops.convert_to_tensor([5, 6])\n     >>> keras_core.ops.add(x1, x2)\n-    array([ 6 10], shape=(2,), dtype=int32)\n+    array([6, 10], dtype=int32)\n \n     `keras_core.ops.add` also broadcasts shapes:\n     >>> x1 = keras_core.ops.convert_to_tensor(\n\n@@ -257,6 +257,32 @@ class NumpyTwoInputOpsDynamicShapeTest(testing.TestCase):\n         y = KerasTensor((2, None))\n         self.assertEqual(knp.logical_xor(x, y).shape, (2, 3))\n \n+    def test_shape_equal_basic_equality(self):\n+        x = KerasTensor([3, 4]).shape\n+        y = KerasTensor([3, 4]).shape\n+        self.assertTrue(knp.shape_equal(x, y))\n+        y = KerasTensor([3, 5]).shape\n+        self.assertFalse(knp.shape_equal(x, y))\n+\n+    def test_shape_equal_allow_none(self):\n+        x = KerasTensor([3, 4, None]).shape\n+        y = KerasTensor([3, 4, 5]).shape\n+        self.assertTrue(knp.shape_equal(x, y, allow_none=True))\n+        self.assertFalse(knp.shape_equal(x, y, allow_none=False))\n+\n+    def test_shape_equal_different_shape_lengths(self):\n+        x = KerasTensor([3, 4]).shape\n+        y = KerasTensor([3, 4, 5]).shape\n+        self.assertFalse(knp.shape_equal(x, y))\n+\n+    def test_shape_equal_ignore_axes(self):\n+        x = KerasTensor([3, 4, 5]).shape\n+        y = KerasTensor([3, 6, 5]).shape\n+        self.assertTrue(knp.shape_equal(x, y, axis=1))\n+        y = KerasTensor([3, 6, 7]).shape\n+        self.assertTrue(knp.shape_equal(x, y, axis=(1, 2)))\n+        self.assertFalse(knp.shape_equal(x, y, axis=1))\n+\n \n class NumpyTwoInputOpsStaticShapeTest(testing.TestCase):\n     def test_add(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8e75ea03408d2b7acd002bb0dffb8bd42f6f2b7d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 65 | Files Changed: 3 | Hunks: 10 | Methods Changed: 8 | Complexity Δ (Sum/Max): -5/0 | Churn Δ: 75 | Churn Cumulative: 4437 | Contributors (this commit): 13 | Commits (past 90d): 57 | Contributors (cumulative): 21 | DMM Complexity: 0.08333333333333333\n\nDIFF:\n@@ -106,7 +106,8 @@ class Discretization(Layer):\n     ):\n         if dtype is None:\n             dtype = \"int64\" if output_mode == \"int\" else backend.floatx()\n-        super().__init__(name=name)\n+        \n+        super().__init__(name=name, dtype=dtype)\n \n         if sparse and backend.backend() != \"tensorflow\":\n             raise ValueError(\n\n@@ -200,50 +200,21 @@ def shape_equal(shape1, shape2, axis=None, allow_none=True):\n     \"\"\"Check if two shapes are equal.\n \n     Args:\n-        shape1: A list or tuple of integers for first shape to be compared.\n-        shape2: A list or tuple of integers for second shape to be compared.\n-        axis: An integer, list, or tuple of integers (optional):\n-            Axes to ignore during comparison. Default is `None`.\n-        allow_none (bool, optional): If `True`, allows `None` in a shape\n-            to match any value in the corresponding position of the other shape.\n-            Default is `True`.\n-\n-    Returns:\n-        bool: `True` if shapes are considered equal based on the criteria,\n-        `False` otherwise.\n-\n-    Examples:\n-\n-    >>> shape_equal((32, 64, 128), (32, 64, 128))\n-    True\n-    >>> shape_equal((32, 64, 128), (32, 64, 127))\n-    False\n-    >>> shape_equal((32, 64, None), (32, 64, 128), allow_none=True)\n-    True\n-    >>> shape_equal((32, 64, None), (32, 64, 128), allow_none=False)\n-    False\n-    >>> shape_equal((32, 64, 128), (32, 63, 128), axis=1)\n-    True\n-    >>> shape_equal((32, 64, 128), (32, 63, 127), axis=(1, 2))\n-    True\n-    >>> shape_equal((32, 64, 128), (32, 63, 127), axis=[1,2])\n-    True\n-    >>> shape_equal((32, 64), (32, 64, 128))\n-    False\n+        shape1: A tuple or list of integers.\n+        shape2: A tuple or list of integers.\n+        axis: int or list/tuple of ints, defaults to `None`. If specified, the\n+            shape check will ignore the axes specified by `axis`.\n+        allow_none: bool, defaults to `True`. If `True`, `None` in the shape\n+            will match any value.\n     \"\"\"\n     if len(shape1) != len(shape2):\n         return False\n-\n     shape1 = list(shape1)\n     shape2 = list(shape2)\n-\n     if axis is not None:\n-        if isinstance(axis, int):\n-            axis = [axis]\n         for ax in axis:\n             shape1[ax] = -1\n             shape2[ax] = -1\n-\n     if allow_none:\n         for i in range(len(shape1)):\n             if shape1[i] is None:\n@@ -275,10 +246,9 @@ def absolute(x):\n         An array containing the absolute value of each element in `x`.\n \n     Example:\n-\n     >>> x = keras_core.ops.convert_to_tensor([-1.2, 1.2])\n     >>> keras_core.ops.absolute(x)\n-    array([1.2, 1.2], dtype=float32)\n+    array([1.2 1.2], shape=(2,), dtype=float32)\n     \"\"\"\n     if any_symbolic_tensors((x,)):\n         return Absolute().symbolic_call(x)\n@@ -321,7 +291,7 @@ def add(x1, x2):\n     >>> x1 = keras_core.ops.convert_to_tensor([1, 4])\n     >>> x2 = keras_core.ops.convert_to_tensor([5, 6])\n     >>> keras_core.ops.add(x1, x2)\n-    array([6, 10], dtype=int32)\n+    array([ 6 10], shape=(2,), dtype=int32)\n \n     `keras_core.ops.add` also broadcasts shapes:\n     >>> x1 = keras_core.ops.convert_to_tensor(\n\n@@ -257,32 +257,6 @@ class NumpyTwoInputOpsDynamicShapeTest(testing.TestCase):\n         y = KerasTensor((2, None))\n         self.assertEqual(knp.logical_xor(x, y).shape, (2, 3))\n \n-    def test_shape_equal_basic_equality(self):\n-        x = KerasTensor([3, 4]).shape\n-        y = KerasTensor([3, 4]).shape\n-        self.assertTrue(knp.shape_equal(x, y))\n-        y = KerasTensor([3, 5]).shape\n-        self.assertFalse(knp.shape_equal(x, y))\n-\n-    def test_shape_equal_allow_none(self):\n-        x = KerasTensor([3, 4, None]).shape\n-        y = KerasTensor([3, 4, 5]).shape\n-        self.assertTrue(knp.shape_equal(x, y, allow_none=True))\n-        self.assertFalse(knp.shape_equal(x, y, allow_none=False))\n-\n-    def test_shape_equal_different_shape_lengths(self):\n-        x = KerasTensor([3, 4]).shape\n-        y = KerasTensor([3, 4, 5]).shape\n-        self.assertFalse(knp.shape_equal(x, y))\n-\n-    def test_shape_equal_ignore_axes(self):\n-        x = KerasTensor([3, 4, 5]).shape\n-        y = KerasTensor([3, 6, 5]).shape\n-        self.assertTrue(knp.shape_equal(x, y, axis=1))\n-        y = KerasTensor([3, 6, 7]).shape\n-        self.assertTrue(knp.shape_equal(x, y, axis=(1, 2)))\n-        self.assertFalse(knp.shape_equal(x, y, axis=1))\n-\n \n class NumpyTwoInputOpsStaticShapeTest(testing.TestCase):\n     def test_add(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6a8477cb92baee1d49847d6facff5e544207f99f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 15 | Lines Deleted: 15 | Files Changed: 1 | Hunks: 6 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 30 | Churn Cumulative: 153 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -2,8 +2,8 @@\n \n Distribution related class for JAX backend.\n \n-This is just a prototype and we might want to unify it in future for other\n-backends.\n+This is just a prototype and we might want to unify it\n+with other backends in the future.\n \"\"\"\n \n import contextlib\n@@ -33,20 +33,20 @@ class DataParallelDistribution:\n     def __init__(self, mesh=None, devices=None):\n         \"\"\"Create the data parallel distribution.\n \n-        User can choose to create this instance by either `Mesh` or `devices`\n-        parameters (but not both).\n+        You can choose to create this instance by either specifing\n+        the `Mesh` or `devices` parameters (but not both).\n \n         The mesh is expected to be a `jax.sharding.Mesh` instance, and is\n-        expected to be 1D only. In case that the mesh has multiple axises, then\n-        the first axis will be treated as data parallel dimension (and a warning\n-        will be raised).\n+        expected to be 1D only. In case that the mesh has multiple axes, then\n+        the first axis will be treated as the data parallel dimension\n+        (and a warning will be raised).\n \n         When a list of `devices` are provided, they will be used to construct a\n         1D mesh.\n \n-        When both `mesh` and `devices` are absent, then we will rely on\n-        `jax.devices` to detect any available devices, and create mesh from\n-        them.\n+        When both `mesh` and `devices` are absent, then `jax.devices()`\n+        will be used to detect any available devices\n+        and create a 1D mesh from them.\n         \"\"\"\n         super().__init__()\n         if mesh:\n@@ -84,16 +84,16 @@ class DataParallelDistribution:\n     def _initialize_with_mesh(self, mesh):\n         if not isinstance(mesh, jax.sharding.Mesh):\n             raise ValueError(\n-                \"Expect the mesh to be type of jax.sharding.Mesh, \"\n-                f\"Received {type(mesh)}\"\n+                \"Expect `mesh` to be an instance of `jax.sharding.Mesh`. \"\n+                f\"Received: mesh={mesh} (of type {type(mesh)})\"\n             )\n         self._user_provide_devices = None\n         self.mesh = mesh\n         if self.mesh.devices.ndim != 1:\n             logging.warning(\n-                \"Expect the input mesh to be 1D, but received %dD. \"\n-                \"The first axis will be used for data parallel sharding\",\n-                self.mesh.devices.ndim,\n+                \"Expect the input mesh to be 1D, but received \"\n+                f\"mesh.devices.ndim={mesh.devices.ndim}. \"\n+                \"The first axis will be used for data-parallel sharding.\"\n             )\n \n     def _initialize_mesh_from_devices(self, devices):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
