{"custom_id": "keras#24060372be8b37fa35dd9580b375278ea05af924", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 38 | Lines Deleted: 10 | Files Changed: 2 | Hunks: 10 | Methods Changed: 2 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 48 | Churn Cumulative: 938 | Contributors (this commit): 7 | Commits (past 90d): 33 | Contributors (cumulative): 12 | DMM Complexity: 0.36\n\nDIFF:\n@@ -4345,26 +4345,44 @@ class Repeat(Operation):\n \n     def compute_output_spec(self, x):\n         x_shape = list(x.shape)\n+        repeats = self.repeats\n+        if isinstance(repeats, int):\n+            repeats = [repeats]\n+        repeats_size = len(repeats)\n+        broadcast = repeats_size == 1\n+\n         if self.axis is None:\n             if None in x_shape:\n                 return KerasTensor([None], dtype=x.dtype)\n \n             x_flatten_size = int(np.prod(x_shape))\n-            if isinstance(self.repeats, int):\n-                output_shape = [x_flatten_size * self.repeats]\n+            if broadcast:\n+                output_shape = [x_flatten_size * repeats[0]]\n+            elif repeats_size != x_flatten_size:\n+                raise ValueError(\n+                    \"Size of `repeats` and \"\n+                    \"dimensions of `x` after flattening should be compatible. \"\n+                    f\"Received: {repeats_size} and {x_flatten_size}\"\n+                )\n             else:\n-                output_shape = [int(np.sum(self.repeats))]\n+                output_shape = [int(np.sum(repeats))]\n             return KerasTensor(output_shape, dtype=x.dtype)\n \n         size_on_ax = x_shape[self.axis]\n-        output_shape = x_shape\n-        if isinstance(self.repeats, int):\n         if size_on_ax is None:\n-                output_shape[self.axis] = None\n+            return KerasTensor(x_shape, dtype=x.dtype)\n+\n+        output_shape = x_shape\n+        if broadcast:\n+            output_shape[self.axis] = size_on_ax * repeats[0]\n+        elif size_on_ax != repeats_size:\n+            raise ValueError(\n+                \"Size of `repeats` and \"\n+                f\"dimensions of `axis {self.axis} of x` should be compatible. \"\n+                f\"Received: {repeats_size} and {x_shape}\"\n+            )\n         else:\n-                output_shape[self.axis] = size_on_ax * self.repeats\n-        else:\n-            output_shape[self.axis] = int(np.sum(self.repeats))\n+            output_shape[self.axis] = int(np.sum(repeats))\n         return KerasTensor(output_shape, dtype=x.dtype)\n \n \n\n@@ -1364,7 +1364,7 @@ class NumpyOneInputOpsDynamicShapeTest(testing.TestCase):\n         x = KerasTensor((None, 3))\n         self.assertEqual(knp.repeat(x, 2).shape, (None,))\n         self.assertEqual(knp.repeat(x, 3, axis=1).shape, (None, 9))\n-        self.assertEqual(knp.repeat(x, [1, 2], axis=0).shape, (3, 3))\n+        self.assertEqual(knp.repeat(x, [1, 2], axis=0).shape, (None, 3))\n         self.assertEqual(knp.repeat(x, 2, axis=0).shape, (None, 3))\n \n     def test_reshape(self):\n@@ -1875,9 +1875,15 @@ class NumpyOneInputOpsStaticShapeTest(testing.TestCase):\n     def test_repeat(self):\n         x = KerasTensor((2, 3))\n         self.assertEqual(knp.repeat(x, 2).shape, (12,))\n+        self.assertEqual(knp.repeat(x, [2]).shape, (12,))\n         self.assertEqual(knp.repeat(x, 3, axis=1).shape, (2, 9))\n         self.assertEqual(knp.repeat(x, [1, 2], axis=0).shape, (3, 3))\n \n+        with self.assertRaises(ValueError):\n+            knp.repeat(x, [1, 1])\n+        with self.assertRaises(ValueError):\n+            knp.repeat(x, [1, 1, 1], axis=0)\n+\n     def test_reshape(self):\n         x = KerasTensor((2, 3))\n         self.assertEqual(knp.reshape(x, (3, 2)).shape, (3, 2))\n@@ -3902,6 +3908,10 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n     def test_repeat(self):\n         x = np.array([[1, 2], [3, 4]])\n         self.assertAllClose(knp.repeat(x, 2), np.repeat(x, 2))\n+        self.assertAllClose(\n+            knp.Repeat(np.array([2]))(x),\n+            np.repeat(x, np.array([2])),\n+        )\n         self.assertAllClose(knp.repeat(x, 3, axis=1), np.repeat(x, 3, axis=1))\n         self.assertAllClose(\n             knp.repeat(x, np.array([1, 2]), axis=-1),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#47bedf1418135575a629990e7f1b7aeabc93cb69", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 47 | Contributors (this commit): 3 | Commits (past 90d): 6 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -209,9 +209,9 @@ class Metric(KerasSaveable):\n \n     @property\n     def variables(self):\n-        variables = self._variables[:]\n+        variables = list(self._variables)\n         for metric in self._metrics:\n-            variables.extend(metric._variables)\n+            variables.extend(metric.variables)\n         return variables\n \n     def __call__(self, *args, **kwargs):\n\n@@ -161,6 +161,12 @@ class MetricTest(testing.TestCase):\n         }\n         self.assertEqual(len(metric.variables), 6)\n \n+        # Two levels deep\n+        metric = ExampleMetric(name=\"mse\")\n+        metric.submetric = ExampleMetric(name=\"submse\")\n+        metric.submetric.submetric = ExampleMetric(name=\"subsubmse\")\n+        self.assertEqual(len(metric.variables), 6)\n+\n     def test_serialization(self):\n         self.run_class_serialization_test(\n             ExampleMetric(name=\"mse\"),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2c48f2e9aa29f81d2d8b23c380a85ca689ae9e30", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 12 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -270,9 +270,9 @@ def get_file(\n                 self.finished = False\n \n             def __call__(self, block_num, block_size, total_size):\n-                if not self.progbar:\n                 if total_size == -1:\n                     total_size = None\n+                if not self.progbar:\n                     self.progbar = Progbar(total_size)\n                 current = block_num * block_size\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#224de28928f46c017f00661513590e80bee47787", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 105 | Lines Deleted: 125 | Files Changed: 1 | Hunks: 65 | Methods Changed: 19 | Complexity Δ (Sum/Max): -4/0 | Churn Δ: 230 | Churn Cumulative: 484 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 3 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1,7 +1,7 @@\n import collections\n \n import numpy as np\n-import parameterized\n+from absl.testing import parameterized\n \n from keras.src import ops\n from keras.src import testing\n@@ -13,97 +13,89 @@ STRUCTURE2 = (((\"foo1\", \"foo2\"), \"foo3\"), \"foo4\", (\"foo5\", \"foo6\"))\n STRUCTURE_DIFFERENT_NUM_ELEMENTS = (\"spam\", \"eggs\")\n STRUCTURE_DIFFERENT_NESTING = (((1, 2), 3), 4, 5, (6,))\n \n+TEST_CASES = []\n+if dmtree.available:\n+    from keras.src.tree import dmtree_impl\n \n-@parameterized.parameterized_class(\n-    (\"tree_module\",),\n-    [\n-        (dmtree,),\n-        (optree,),\n-    ],\n-)\n+    TEST_CASES += [\n+        {\n+            \"testcase_name\": \"dmtree\",\n+            \"tree_impl\": dmtree_impl,\n+            \"is_optree\": False,\n+        }\n+    ]\n+if optree.available:\n+    from keras.src.tree import optree_impl\n+\n+    TEST_CASES += [\n+        {\n+            \"testcase_name\": \"optree\",\n+            \"tree_impl\": optree_impl,\n+            \"is_optree\": True,\n+        },\n+    ]\n+\n+\n+@parameterized.named_parameters(TEST_CASES)\n class TreeTest(testing.TestCase):\n-    tree_impl = None\n-    tree_api_name = \"\"\n \n-    def setUp(self):\n-        super().setUp()\n-        if self.tree_module.available:\n-            if self.tree_module == dmtree:\n-                from keras.src.tree import dmtree_impl as tree_impl\n-\n-                self.tree_impl = tree_impl\n-                self.tree_api_name = \"dmtree\"\n-            elif self.tree_module == optree:\n-                from keras.src.tree import optree_impl as tree_impl\n-\n-                self.tree_impl = tree_impl\n-                self.tree_api_name = \"optree\"\n-            else:\n-                raise ValueError(f\"Unrecognized module {self.tree_module}.\")\n-        else:\n-            self.skipTest(f\"Skip since {self.tree_module} is not available.\")\n-\n-    def test_is_nested(self):\n-        self.assertFalse(self.tree_impl.is_nested(\"1234\"))\n-        self.assertFalse(self.tree_impl.is_nested(b\"1234\"))\n-        self.assertFalse(self.tree_impl.is_nested(bytearray(\"1234\", \"ascii\")))\n-        self.assertTrue(self.tree_impl.is_nested([1, 3, [4, 5]]))\n-        self.assertTrue(self.tree_impl.is_nested(((7, 8), (5, 6))))\n-        self.assertTrue(self.tree_impl.is_nested([]))\n-        self.assertTrue(self.tree_impl.is_nested({\"a\": 1, \"b\": 2}))\n-        self.assertFalse(self.tree_impl.is_nested(set([1, 2])))\n+    def test_is_nested(self, tree_impl, is_optree):\n+        self.assertFalse(tree_impl.is_nested(\"1234\"))\n+        self.assertFalse(tree_impl.is_nested(b\"1234\"))\n+        self.assertFalse(tree_impl.is_nested(bytearray(\"1234\", \"ascii\")))\n+        self.assertTrue(tree_impl.is_nested([1, 3, [4, 5]]))\n+        self.assertTrue(tree_impl.is_nested(((7, 8), (5, 6))))\n+        self.assertTrue(tree_impl.is_nested([]))\n+        self.assertTrue(tree_impl.is_nested({\"a\": 1, \"b\": 2}))\n+        self.assertFalse(tree_impl.is_nested(set([1, 2])))\n         ones = np.ones([2, 3])\n-        self.assertFalse(self.tree_impl.is_nested(ones))\n-        self.assertFalse(self.tree_impl.is_nested(np.tanh(ones)))\n-        self.assertFalse(self.tree_impl.is_nested(np.ones((4, 5))))\n+        self.assertFalse(tree_impl.is_nested(ones))\n+        self.assertFalse(tree_impl.is_nested(np.tanh(ones)))\n+        self.assertFalse(tree_impl.is_nested(np.ones((4, 5))))\n \n-    def test_flatten(self):\n+    def test_flatten(self, tree_impl, is_optree):\n         structure = ((3, 4), 5, (6, 7, (9, 10), 8))\n         flat = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\"]\n \n         self.assertEqual(\n-            self.tree_impl.flatten(structure), [3, 4, 5, 6, 7, 9, 10, 8]\n+            tree_impl.flatten(structure), [3, 4, 5, 6, 7, 9, 10, 8]\n         )\n         point = collections.namedtuple(\"Point\", [\"x\", \"y\"])\n         structure = (point(x=4, y=2), ((point(x=1, y=0),),))\n         flat = [4, 2, 1, 0]\n-        self.assertEqual(self.tree_impl.flatten(structure), flat)\n+        self.assertEqual(tree_impl.flatten(structure), flat)\n \n-        self.assertEqual([5], self.tree_impl.flatten(5))\n-        self.assertEqual([np.array([5])], self.tree_impl.flatten(np.array([5])))\n+        self.assertEqual([5], tree_impl.flatten(5))\n+        self.assertEqual([np.array([5])], tree_impl.flatten(np.array([5])))\n \n-    def test_flatten_dict_order(self):\n+    def test_flatten_dict_order(self, tree_impl, is_optree):\n         ordered = collections.OrderedDict(\n             [(\"d\", 3), (\"b\", 1), (\"a\", 0), (\"c\", 2)]\n         )\n         plain = {\"d\": 3, \"b\": 1, \"a\": 0, \"c\": 2}\n-        ordered_flat = self.tree_impl.flatten(ordered)\n-        plain_flat = self.tree_impl.flatten(plain)\n+        ordered_flat = tree_impl.flatten(ordered)\n+        plain_flat = tree_impl.flatten(plain)\n         # dmtree does not respect the ordered dict.\n-        if self.tree_api_name == \"optree\":\n+        if is_optree:\n             self.assertEqual([3, 1, 0, 2], ordered_flat)\n         else:\n             self.assertEqual([0, 1, 2, 3], ordered_flat)\n         self.assertEqual([0, 1, 2, 3], plain_flat)\n \n-    def test_map_structure(self):\n+    def test_map_structure(self, tree_impl, is_optree):\n         assertion_message = (\n             \"have the same structure\"\n-            if self.tree_api_name == \"optree\"\n+            if is_optree\n             else \"have the same nested structure\"\n         )\n-        assertion_type_error = (\n-            ValueError if self.tree_api_name == \"optree\" else TypeError\n-        )\n+        assertion_type_error = ValueError if is_optree else TypeError\n         structure2 = (((7, 8), 9), 10, (11, 12))\n-        structure1_plus1 = self.tree_impl.map_structure(\n-            lambda x: x + 1, STRUCTURE1\n-        )\n-        self.tree_impl.assert_same_structure(STRUCTURE1, structure1_plus1)\n+        structure1_plus1 = tree_impl.map_structure(lambda x: x + 1, STRUCTURE1)\n+        tree_impl.assert_same_structure(STRUCTURE1, structure1_plus1)\n         self.assertAllEqual(\n-            [2, 3, 4, 5, 6, 7], self.tree_impl.flatten(structure1_plus1)\n+            [2, 3, 4, 5, 6, 7], tree_impl.flatten(structure1_plus1)\n         )\n-        structure1_plus_structure2 = self.tree_impl.map_structure(\n+        structure1_plus_structure2 = tree_impl.map_structure(\n             lambda x, y: x + y, STRUCTURE1, structure2\n         )\n         self.assertEqual(\n@@ -111,57 +103,49 @@ class TreeTest(testing.TestCase):\n             structure1_plus_structure2,\n         )\n \n-        self.assertEqual(3, self.tree_impl.map_structure(lambda x: x - 1, 4))\n+        self.assertEqual(3, tree_impl.map_structure(lambda x: x - 1, 4))\n \n-        self.assertEqual(\n-            7, self.tree_impl.map_structure(lambda x, y: x + y, 3, 4)\n-        )\n+        self.assertEqual(7, tree_impl.map_structure(lambda x, y: x + y, 3, 4))\n \n         # Empty structures\n-        self.assertEqual((), self.tree_impl.map_structure(lambda x: x + 1, ()))\n-        self.assertEqual([], self.tree_impl.map_structure(lambda x: x + 1, []))\n-        self.assertEqual({}, self.tree_impl.map_structure(lambda x: x + 1, {}))\n+        self.assertEqual((), tree_impl.map_structure(lambda x: x + 1, ()))\n+        self.assertEqual([], tree_impl.map_structure(lambda x: x + 1, []))\n+        self.assertEqual({}, tree_impl.map_structure(lambda x: x + 1, {}))\n         empty_nt = collections.namedtuple(\"empty_nt\", \"\")\n         self.assertEqual(\n             empty_nt(),\n-            self.tree_impl.map_structure(lambda x: x + 1, empty_nt()),\n+            tree_impl.map_structure(lambda x: x + 1, empty_nt()),\n         )\n \n         # This is checking actual equality of types, empty list != empty tuple\n-        self.assertNotEqual(\n-            (), self.tree_impl.map_structure(lambda x: x + 1, [])\n-        )\n+        self.assertNotEqual((), tree_impl.map_structure(lambda x: x + 1, []))\n \n         with self.assertRaisesRegex(TypeError, \"callable\"):\n-            self.tree_impl.map_structure(\"bad\", structure1_plus1)\n+            tree_impl.map_structure(\"bad\", structure1_plus1)\n         with self.assertRaisesRegex(ValueError, \"at least one structure\"):\n-            self.tree_impl.map_structure(lambda x: x)\n+            tree_impl.map_structure(lambda x: x)\n         with self.assertRaisesRegex(ValueError, assertion_message):\n-            self.tree_impl.map_structure(lambda x, y: None, (3, 4), (3, 4, 5))\n+            tree_impl.map_structure(lambda x, y: None, (3, 4), (3, 4, 5))\n         with self.assertRaisesRegex(ValueError, assertion_message):\n-            self.tree_impl.map_structure(lambda x, y: None, 3, (3,))\n+            tree_impl.map_structure(lambda x, y: None, 3, (3,))\n         with self.assertRaisesRegex(assertion_type_error, assertion_message):\n-            self.tree_impl.map_structure(\n-                lambda x, y: None, ((3, 4), 5), [(3, 4), 5]\n-            )\n+            tree_impl.map_structure(lambda x, y: None, ((3, 4), 5), [(3, 4), 5])\n         with self.assertRaisesRegex(ValueError, assertion_message):\n-            self.tree_impl.map_structure(\n-                lambda x, y: None, ((3, 4), 5), (3, (4, 5))\n-            )\n+            tree_impl.map_structure(lambda x, y: None, ((3, 4), 5), (3, (4, 5)))\n \n         structure1_list = [[[1, 2], 3], 4, [5, 6]]\n         with self.assertRaisesRegex(assertion_type_error, assertion_message):\n-            self.tree_impl.map_structure(\n+            tree_impl.map_structure(\n                 lambda x, y: None, STRUCTURE1, structure1_list\n             )\n \n-    def test_map_structure_up_to(self):\n+    def test_map_structure_up_to(self, tree_impl, is_optree):\n         # Named tuples.\n         ab_tuple = collections.namedtuple(\"ab_tuple\", \"a, b\")\n         op_tuple = collections.namedtuple(\"op_tuple\", \"add, mul\")\n         inp_val = ab_tuple(a=2, b=3)\n         inp_ops = ab_tuple(a=op_tuple(add=1, mul=2), b=op_tuple(add=2, mul=3))\n-        out = self.tree_impl.map_structure_up_to(\n+        out = tree_impl.map_structure_up_to(\n             inp_val,\n             lambda val, ops: (val + ops.add) * ops.mul,\n             inp_val,\n@@ -173,7 +157,7 @@ class TreeTest(testing.TestCase):\n         # Lists.\n         data_list = [[2, 4, 6, 8], [[1, 3, 5, 7, 9], [3, 5, 7]]]\n         name_list = [\"evens\", [\"odds\", \"primes\"]]\n-        out = self.tree_impl.map_structure_up_to(\n+        out = tree_impl.map_structure_up_to(\n             name_list,\n             lambda name, sec: \"first_{}_{}\".format(len(sec), name),\n             name_list,\n@@ -183,77 +167,75 @@ class TreeTest(testing.TestCase):\n             out, [\"first_4_evens\", [\"first_5_odds\", \"first_3_primes\"]]\n         )\n \n-    def test_assert_same_structure(self):\n+    def test_assert_same_structure(self, tree_impl, is_optree):\n         assertion_message = (\n             \"have the same structure\"\n-            if self.tree_api_name == \"optree\"\n+            if is_optree\n             else \"have the same nested structure\"\n         )\n-        assertion_type_error = (\n-            ValueError if self.tree_api_name == \"optree\" else TypeError\n-        )\n-        self.tree_impl.assert_same_structure(\n+        assertion_type_error = ValueError if is_optree else TypeError\n+        tree_impl.assert_same_structure(\n             STRUCTURE1, STRUCTURE2, check_types=False\n         )\n-        self.tree_impl.assert_same_structure(\"abc\", 1.0, check_types=False)\n-        self.tree_impl.assert_same_structure(b\"abc\", 1.0, check_types=False)\n-        self.tree_impl.assert_same_structure(\"abc\", 1.0, check_types=False)\n-        self.tree_impl.assert_same_structure(\n+        tree_impl.assert_same_structure(\"abc\", 1.0, check_types=False)\n+        tree_impl.assert_same_structure(b\"abc\", 1.0, check_types=False)\n+        tree_impl.assert_same_structure(\"abc\", 1.0, check_types=False)\n+        tree_impl.assert_same_structure(\n             bytearray(\"abc\", \"ascii\"), 1.0, check_types=False\n         )\n-        self.tree_impl.assert_same_structure(\n+        tree_impl.assert_same_structure(\n             \"abc\", np.array([0, 1]), check_types=False\n         )\n \n         with self.assertRaisesRegex(ValueError, assertion_message):\n-            self.tree_impl.assert_same_structure(\n+            tree_impl.assert_same_structure(\n                 STRUCTURE1, STRUCTURE_DIFFERENT_NUM_ELEMENTS\n             )\n         with self.assertRaisesRegex(ValueError, assertion_message):\n-            self.tree_impl.assert_same_structure([0, 1], np.array([0, 1]))\n+            tree_impl.assert_same_structure([0, 1], np.array([0, 1]))\n         with self.assertRaisesRegex(ValueError, assertion_message):\n-            self.tree_impl.assert_same_structure(0, [0, 1])\n+            tree_impl.assert_same_structure(0, [0, 1])\n         with self.assertRaisesRegex(assertion_type_error, assertion_message):\n-            self.tree_impl.assert_same_structure((0, 1), [0, 1])\n+            tree_impl.assert_same_structure((0, 1), [0, 1])\n         with self.assertRaisesRegex(ValueError, assertion_message):\n-            self.tree_impl.assert_same_structure(\n+            tree_impl.assert_same_structure(\n                 STRUCTURE1, STRUCTURE_DIFFERENT_NESTING\n             )\n         with self.assertRaisesRegex(ValueError, assertion_message):\n-            self.tree_impl.assert_same_structure([[3], 4], [3, [4]])\n+            tree_impl.assert_same_structure([[3], 4], [3, [4]])\n         with self.assertRaisesRegex(ValueError, assertion_message):\n-            self.tree_impl.assert_same_structure({\"a\": 1}, {\"b\": 1})\n+            tree_impl.assert_same_structure({\"a\": 1}, {\"b\": 1})\n         structure1_list = [[[1, 2], 3], 4, [5, 6]]\n         with self.assertRaisesRegex(assertion_type_error, assertion_message):\n-            self.tree_impl.assert_same_structure(STRUCTURE1, structure1_list)\n-        self.tree_impl.assert_same_structure(\n+            tree_impl.assert_same_structure(STRUCTURE1, structure1_list)\n+        tree_impl.assert_same_structure(\n             STRUCTURE1, STRUCTURE2, check_types=False\n         )\n         # dm-tree treat list and tuple only on type mismatch, but optree treat\n         # them as structure mismatch.\n-        if self.tree_api_name == \"optree\":\n+        if is_optree:\n             with self.assertRaisesRegex(\n                 assertion_type_error, assertion_message\n             ):\n-                self.tree_impl.assert_same_structure(\n+                tree_impl.assert_same_structure(\n                     STRUCTURE1, structure1_list, check_types=False\n                 )\n         else:\n-            self.tree_impl.assert_same_structure(\n+            tree_impl.assert_same_structure(\n                 STRUCTURE1, structure1_list, check_types=False\n             )\n \n-    def test_pack_sequence_as(self):\n+    def test_pack_sequence_as(self, tree_impl, is_optree):\n         structure = {\"key3\": \"\", \"key1\": \"\", \"key2\": \"\"}\n         flat_sequence = [\"value1\", \"value2\", \"value3\"]\n         self.assertEqual(\n-            self.tree_impl.pack_sequence_as(structure, flat_sequence),\n+            tree_impl.pack_sequence_as(structure, flat_sequence),\n             {\"key3\": \"value3\", \"key1\": \"value1\", \"key2\": \"value2\"},\n         )\n         structure = ((\"a\", \"b\"), (\"c\", \"d\", \"e\"), \"f\")\n         flat_sequence = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0]\n         self.assertEqual(\n-            self.tree_impl.pack_sequence_as(structure, flat_sequence),\n+            tree_impl.pack_sequence_as(structure, flat_sequence),\n             ((1.0, 2.0), (3.0, 4.0, 5.0), 6.0),\n         )\n         structure = {\n@@ -262,7 +244,7 @@ class TreeTest(testing.TestCase):\n         }\n         flat_sequence = [\"val2\", \"val1\", 3.0, 1.0, 2.0]\n         self.assertEqual(\n-            self.tree_impl.pack_sequence_as(structure, flat_sequence),\n+            tree_impl.pack_sequence_as(structure, flat_sequence),\n             {\n                 \"key3\": {\"c\": (1.0, 2.0), \"a\": 3.0},\n                 \"key1\": {\"e\": \"val1\", \"d\": \"val2\"},\n@@ -271,43 +253,41 @@ class TreeTest(testing.TestCase):\n         structure = [\"a\"]\n         flat_sequence = [np.array([[1, 2], [3, 4]])]\n         self.assertAllClose(\n-            self.tree_impl.pack_sequence_as(structure, flat_sequence),\n+            tree_impl.pack_sequence_as(structure, flat_sequence),\n             [np.array([[1, 2], [3, 4]])],\n         )\n         structure = [\"a\"]\n         flat_sequence = [ops.ones([2, 2])]\n         self.assertAllClose(\n-            self.tree_impl.pack_sequence_as(structure, flat_sequence),\n+            tree_impl.pack_sequence_as(structure, flat_sequence),\n             [ops.ones([2, 2])],\n         )\n \n         with self.assertRaisesRegex(TypeError, \"Attempted to pack value:\"):\n             structure = [\"a\"]\n             flat_sequence = 1\n-            self.tree_impl.pack_sequence_as(structure, flat_sequence)\n+            tree_impl.pack_sequence_as(structure, flat_sequence)\n         with self.assertRaisesRegex(ValueError, \"The target structure is of\"):\n             structure = \"a\"\n             flat_sequence = [1, 2]\n-            self.tree_impl.pack_sequence_as(structure, flat_sequence)\n+            tree_impl.pack_sequence_as(structure, flat_sequence)\n \n-    def test_lists_to_tuples(self):\n+    def test_lists_to_tuples(self, tree_impl, is_optree):\n         structure = [1, 2, 3]\n-        self.assertEqual(self.tree_impl.lists_to_tuples(structure), (1, 2, 3))\n+        self.assertEqual(tree_impl.lists_to_tuples(structure), (1, 2, 3))\n         structure = [[1], [2, 3]]\n-        self.assertEqual(\n-            self.tree_impl.lists_to_tuples(structure), ((1,), (2, 3))\n-        )\n+        self.assertEqual(tree_impl.lists_to_tuples(structure), ((1,), (2, 3)))\n         structure = [[1], [2, [3]]]\n         self.assertEqual(\n-            self.tree_impl.lists_to_tuples(structure), ((1,), (2, (3,)))\n+            tree_impl.lists_to_tuples(structure), ((1,), (2, (3,)))\n         )\n \n-    def test_traverse(self):\n+    def test_traverse(self, tree_impl, is_optree):\n         # Lists to tuples\n         structure = [(1, 2), [3], {\"a\": [4]}]\n         self.assertEqual(\n             ((1, 2), (3,), {\"a\": (4,)}),\n-            self.tree_impl.traverse(\n+            tree_impl.traverse(\n                 lambda x: tuple(x) if isinstance(x, list) else x,\n                 structure,\n                 top_down=False,\n@@ -321,7 +301,7 @@ class TreeTest(testing.TestCase):\n             visited.append(x)\n             return \"X\" if isinstance(x, tuple) and len(x) > 2 else None\n \n-        output = self.tree_impl.traverse(visit, structure)\n+        output = tree_impl.traverse(visit, structure)\n         self.assertEqual([(1, [2]), [3, \"X\"]], output)\n         self.assertEqual(\n             [\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a8aac9720d166eb10c37bba292c21896ae9ca36d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 9 | Churn Cumulative: 27 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -214,6 +214,15 @@ class BatchNormalization(Layer):\n         return input_shape\n \n     def call(self, inputs, training=None, mask=None):\n+        # Check if the mask has one less dimension than the inputs.\n+        if mask is not None:\n+            if len(mask.shape) != len(inputs.shape) - 1:\n+                # Raise a value error\n+                raise ValueError(\n+                    \"The mask provided should be one dimension less than the inputs. \"\n+                    f\"Received: mask.shape={mask.shape}, inputs.shape={inputs.shape}\"\n+                )\n+\n         input_dtype = standardize_dtype(inputs.dtype)\n         if input_dtype in (\"float16\", \"bfloat16\"):\n             # BN is prone to overflowing for float16/bfloat16 inputs, so we opt\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1c60668f6bdd05dab619806e7b2dc25d3ed4ccbf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 32 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 3 | DMM Complexity: 0.0\n\nDIFF:\n@@ -219,8 +219,9 @@ class BatchNormalization(Layer):\n             if len(mask.shape) != len(inputs.shape) - 1:\n                 # Raise a value error\n                 raise ValueError(\n-                    \"The mask provided should be one dimension less than the inputs. \"\n-                    f\"Received: mask.shape={mask.shape}, inputs.shape={inputs.shape}\"\n+                    \"The mask provided should be one dimension less \"\n+                    \"than the inputs. Received: \"\n+                    f\"mask.shape={mask.shape}, inputs.shape={inputs.shape}\"\n                 )\n \n         input_dtype = standardize_dtype(inputs.dtype)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#101119fd2f0e2ee29364e31c212a3aa2fd66c91a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 177 | Contributors (this commit): 3 | Commits (past 90d): 4 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -254,7 +254,7 @@ def slice(inputs, start_indices, shape):\n     inputs = np.zeros((5, 5))\n     start_indices = np.array([3, 3])\n     shape = np.array([2, 2])\n-    inputs = keras.ops.slice(inputs, start_indices, updates)\n+    inputs = keras.ops.slice(inputs, start_indices, shape)\n     ```\n \n     Args:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d1b404df9fb518c24dd30d0d903692c27ff272db", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 11 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -14,8 +14,9 @@ class UnitNormalization(Layer):\n \n     >>> data = np.arange(6).reshape(2, 3)\n     >>> normalized_data = keras.layers.UnitNormalization()(data)\n-    >>> print(np.sum(normalized_data[0, :] ** 2)\n-    1.0\n+    >>> print(np.sum(normalized_data[0, :] ** 2))\n+    0.99999994\n+\n \n     Args:\n         axis: Integer or list/tuple. The axis or axes to normalize across.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9ad3ca0ba5a77b4616b223481fb43898e31d272e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 16 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -14,9 +14,8 @@ class UnitNormalization(Layer):\n \n     >>> data = np.arange(6).reshape(2, 3)\n     >>> normalized_data = keras.layers.UnitNormalization()(data)\n-    >>> print(np.sum(normalized_data[0, :] ** 2))\n-    0.99999994\n-\n+    >>> np.sum(normalized_data[0, :] ** 2)\n+    1.0\n \n     Args:\n         axis: Integer or list/tuple. The axis or axes to normalize across.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#46df34110339ae3dfbc896f446ace9f33da64838", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 144 | Lines Deleted: 21 | Files Changed: 6 | Hunks: 25 | Methods Changed: 28 | Complexity Δ (Sum/Max): 10/8 | Churn Δ: 165 | Churn Cumulative: 570 | Contributors (this commit): 3 | Commits (past 90d): 21 | Contributors (cumulative): 14 | DMM Complexity: 0.9719626168224299\n\nDIFF:\n@@ -63,6 +63,7 @@ class JAXTrainer(base_trainer.Trainer):\n             y=y,\n             y_pred=y_pred,\n             sample_weight=sample_weight,\n+            training=training,\n         )\n         if losses:\n             self._losses_override.clear()\n\n@@ -28,8 +28,8 @@ class NumpyTrainer(base_trainer.Trainer):\n             y_pred = self(x, training=False)\n         else:\n             y_pred = self(x)\n-        loss = self.compute_loss(\n-            x=x, y=y, y_pred=y_pred, sample_weight=sample_weight\n+        loss = self._compute_loss(\n+            x=x, y=y, y_pred=y_pred, sample_weight=sample_weight, training=False\n         )\n         self._loss_tracker.update_state(\n             loss, sample_weight=tree.flatten(x)[0].shape[0]\n\n@@ -51,8 +51,12 @@ class TensorFlowTrainer(base_trainer.Trainer):\n                 y_pred = self(x, training=True)\n             else:\n                 y_pred = self(x)\n-            loss = self.compute_loss(\n-                x=x, y=y, y_pred=y_pred, sample_weight=sample_weight\n+            loss = self._compute_loss(\n+                x=x,\n+                y=y,\n+                y_pred=y_pred,\n+                sample_weight=sample_weight,\n+                training=True,\n             )\n             self._loss_tracker.update_state(\n                 loss, sample_weight=tf.shape(tree.flatten(x)[0])[0]\n@@ -78,8 +82,8 @@ class TensorFlowTrainer(base_trainer.Trainer):\n             y_pred = self(x, training=False)\n         else:\n             y_pred = self(x)\n-        loss = self.compute_loss(\n-            x=x, y=y, y_pred=y_pred, sample_weight=sample_weight\n+        loss = self._compute_loss(\n+            x=x, y=y, y_pred=y_pred, sample_weight=sample_weight, training=False\n         )\n         self._loss_tracker.update_state(\n             loss, sample_weight=tf.shape(tree.flatten(x)[0])[0]\n@@ -601,8 +605,8 @@ class TensorFlowTrainer(base_trainer.Trainer):\n         self, y, y_pred, sample_weight=None, regularization_losses=None\n     ):\n         warnings.warn(\n-            \"`model.compiled_loss()` is deprecated. \"\n-            \"Instead, use `model.compute_loss(x, y, y_pred, sample_weight)`.\",\n+            \"`model.compiled_loss()` is deprecated. Instead, use \"\n+            \"`model.compute_loss(x, y, y_pred, sample_weight, training)`.\",\n         )\n         return self.compute_loss(\n             x=None, y=y, y_pred=y_pred, sample_weight=sample_weight\n@@ -610,8 +614,8 @@ class TensorFlowTrainer(base_trainer.Trainer):\n \n     def loss(self, y, y_pred, sample_weight=None):\n         warnings.warn(\n-            \"`model.loss` is deprecated. \"\n-            \"Instead, use `model.compute_loss(x, y, y_pred, sample_weight)`.\",\n+            \"`model.loss()` is deprecated. Instead, use \"\n+            \"`model.compute_loss(x, y, y_pred, sample_weight, training)`.\",\n         )\n         return self.compute_loss(\n             x=None, y=y, y_pred=y_pred, sample_weight=sample_weight\n\n@@ -49,8 +49,8 @@ class TorchTrainer(base_trainer.Trainer):\n         # for the weights from the previous train step.\n         self.zero_grad()\n \n-        loss = self.compute_loss(\n-            x=x, y=y, y_pred=y_pred, sample_weight=sample_weight\n+        loss = self._compute_loss(\n+            x=x, y=y, y_pred=y_pred, sample_weight=sample_weight, training=True\n         )\n         self._loss_tracker.update_state(\n             loss, sample_weight=tree.flatten(x)[0].shape[0]\n@@ -85,8 +85,8 @@ class TorchTrainer(base_trainer.Trainer):\n             y_pred = self(x, training=False)\n         else:\n             y_pred = self(x)\n-        loss = self.compute_loss(\n-            x=x, y=y, y_pred=y_pred, sample_weight=sample_weight\n+        loss = self._compute_loss(\n+            x=x, y=y, y_pred=y_pred, sample_weight=sample_weight, training=False\n         )\n         self._loss_tracker.update_state(\n             loss, sample_weight=tree.flatten(x)[0].shape[0]\n\n@@ -1,3 +1,4 @@\n+import inspect\n import platform\n import warnings\n \n@@ -25,6 +26,9 @@ class Trainer:\n         self.steps_per_execution = 1\n         # Can be set by callbacks in on_train_begin\n         self._initial_epoch = None\n+        self._compute_loss_has_training_arg = (\n+            \"training\" in inspect.signature(self.compute_loss).parameters\n+        )\n \n     @traceback_utils.filter_traceback\n     @tracking.no_automatic_dependency_tracking\n@@ -262,6 +266,7 @@ class Trainer:\n         y=None,\n         y_pred=None,\n         sample_weight=None,\n+        training=True,\n     ):\n         \"\"\"Compute the total loss, validate it, and return it.\n \n@@ -276,7 +281,7 @@ class Trainer:\n                 super().__init__(*args, **kwargs)\n                 self.loss_tracker = metrics.Mean(name='loss')\n \n-            def compute_loss(self, x, y, y_pred, sample_weight):\n+            def compute_loss(self, x, y, y_pred, sample_weight, training=True):\n                 loss = ops.means((y_pred - y) ** 2)\n                 loss += ops.sum(self.losses)\n                 self.loss_tracker.update_state(loss)\n@@ -306,12 +311,15 @@ class Trainer:\n             y: Target data.\n             y_pred: Predictions returned by the model (output of `model(x)`)\n             sample_weight: Sample weights for weighting the loss function.\n+            training: Whether we are training or evaluating the model.\n \n         Returns:\n             The total loss as a scalar tensor, or `None` if no loss results\n             (which is the case when called by `Model.test_step`).\n         \"\"\"\n-        del x  # The default implementation does not use `x`.\n+        # The default implementation does not use `x` or `training`.\n+        del x\n+        del training\n         losses = []\n         if self._compile_loss is not None:\n             loss = self._compile_loss(y, y_pred, sample_weight)\n@@ -331,6 +339,27 @@ class Trainer:\n             total_loss = ops.sum(losses)\n         return total_loss\n \n+    def _compute_loss(\n+        self,\n+        x=None,\n+        y=None,\n+        y_pred=None,\n+        sample_weight=None,\n+        training=True,\n+    ):\n+        \"\"\"Backwards compatibility wrapper for `compute_loss`.\n+\n+        This should be used instead `compute_loss` within `train_step` and\n+        `test_step` to support overrides of `compute_loss` that may not have\n+        the `training` argument, as this argument was added in Keras 3.3.\n+        \"\"\"\n+        if self._compute_loss_has_training_arg:\n+            return self.compute_loss(\n+                x, y, y_pred, sample_weight, training=training\n+            )\n+        else:\n+            return self.compute_loss(x, y, y_pred, sample_weight)\n+\n     def stateless_compute_loss(\n         self,\n         trainable_variables,\n@@ -340,6 +369,7 @@ class Trainer:\n         y=None,\n         y_pred=None,\n         sample_weight=None,\n+        training=True,\n     ):\n         var_mapping = list(zip(self.trainable_variables, trainable_variables))\n         var_mapping.extend(\n@@ -349,11 +379,12 @@ class Trainer:\n         with backend.StatelessScope(state_mapping=var_mapping) as scope:\n             # Note that this is needed for the regularization loss, which need\n             # the latest value of train/non-trainable variables.\n-            loss = self.compute_loss(\n+            loss = self._compute_loss(\n                 x,\n                 y,\n                 y_pred,\n                 sample_weight=sample_weight,\n+                training=training,\n             )\n \n         # Update non trainable vars (may have been updated in compute_loss)\n\n@@ -1387,6 +1387,7 @@ class TestTrainer(testing.TestCase, parameterized.TestCase):\n \n     @pytest.mark.requires_trainable_backend\n     def test_metric_update_in_compute_loss(self):\n+        test_self = self\n \n         class MyModel(keras.Model):\n             def __init__(self):\n@@ -1398,9 +1399,17 @@ class TestTrainer(testing.TestCase, parameterized.TestCase):\n                 return self.dense(x)\n \n             def compute_loss(\n-                self, x=None, y=None, y_pred=None, sample_weight=None\n+                self,\n+                x=None,\n+                y=None,\n+                y_pred=None,\n+                sample_weight=None,\n+                training=True,\n             ):\n-                loss = super().compute_loss(x, y, y_pred, sample_weight)\n+                test_self.assertTrue(training)\n+                loss = super().compute_loss(\n+                    x, y, y_pred, sample_weight, training\n+                )\n                 self.custom_metric.update_state(loss * 4)\n                 return loss\n \n@@ -1415,6 +1424,7 @@ class TestTrainer(testing.TestCase, parameterized.TestCase):\n \n     @pytest.mark.requires_trainable_backend\n     def test_fwd_pass_loss_presence_in_compute_loss(self):\n+        test_self = self\n \n         class MyModel(keras.Model):\n             def __init__(self):\n@@ -1426,9 +1436,17 @@ class TestTrainer(testing.TestCase, parameterized.TestCase):\n                 return self.dense(x)\n \n             def compute_loss(\n-                self, x=None, y=None, y_pred=None, sample_weight=None\n+                self,\n+                x=None,\n+                y=None,\n+                y_pred=None,\n+                sample_weight=None,\n+                training=True,\n             ):\n-                loss = super().compute_loss(x, y, y_pred, sample_weight)\n+                test_self.assertTrue(training)\n+                loss = super().compute_loss(\n+                    x, y, y_pred, sample_weight, training\n+                )\n                 self.custom_metric.update_state(sum(self.losses))\n                 return loss\n \n@@ -1439,6 +1457,75 @@ class TestTrainer(testing.TestCase, parameterized.TestCase):\n         history = model.fit(x, y)\n         self.assertGreater(history.history[\"custom\"][0], 0.0)\n \n+    @pytest.mark.requires_trainable_backend\n+    def test_evaluate_with_custom_compute_loss(self):\n+        test_self = self\n+\n+        class MyModel(keras.Model):\n+            def __init__(self):\n+                super().__init__()\n+                self.custom_metric = keras.metrics.Mean(name=\"custom\")\n+                self.dense = keras.layers.Dense(2, activity_regularizer=\"l2\")\n+\n+            def call(self, x):\n+                return self.dense(x)\n+\n+            def compute_loss(\n+                self,\n+                x=None,\n+                y=None,\n+                y_pred=None,\n+                sample_weight=None,\n+                training=True,\n+            ):\n+                test_self.assertFalse(training)\n+                loss = super().compute_loss(\n+                    x, y, y_pred, sample_weight, training\n+                )\n+                self.custom_metric.update_state(loss * 4)\n+                return loss\n+\n+        model = MyModel()\n+        model.compile(optimizer=\"sgd\", loss=\"mse\")\n+        x = np.ones((32, 4))\n+        y = np.ones((32, 2)) * 2\n+        logs = model.evaluate(x, y, return_dict=True)\n+        self.assertAlmostEqual(logs[\"custom\"], logs[\"loss\"] * 4)\n+\n+    @pytest.mark.requires_trainable_backend\n+    def test_compute_loss_no_training_backwards_compatibility(self):\n+\n+        class MyModel(keras.Model):\n+            def __init__(self):\n+                super().__init__()\n+                self.custom_metric = keras.metrics.Mean(name=\"custom\")\n+                self.dense = keras.layers.Dense(2, activity_regularizer=\"l2\")\n+\n+            def call(self, x):\n+                return self.dense(x)\n+\n+            def compute_loss(\n+                self,\n+                x=None,\n+                y=None,\n+                y_pred=None,\n+                sample_weight=None,\n+            ):\n+                loss = super().compute_loss(x, y, y_pred, sample_weight)\n+                self.custom_metric.update_state(loss * 4)\n+                return loss\n+\n+        model = MyModel()\n+        model.compile(optimizer=\"sgd\", loss=\"mse\")\n+        x = np.ones((32, 4))\n+        y = np.ones((32, 2)) * 2\n+        logs = model.evaluate(x, y, return_dict=True)\n+        self.assertAlmostEqual(logs[\"custom\"], logs[\"loss\"] * 4)\n+        history = model.fit(x, y)\n+        self.assertAlmostEqual(\n+            history.history[\"custom\"][0], history.history[\"loss\"][0] * 4\n+        )\n+\n     @pytest.mark.requires_trainable_backend\n     def test_loss_weights(self):\n         epochs = 3\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4551644005364fbeb4757344f6f909efee8d9de1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 29 | Lines Deleted: 0 | Files Changed: 4 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 29 | Churn Cumulative: 118 | Contributors (this commit): 3 | Commits (past 90d): 9 | Contributors (cumulative): 9 | DMM Complexity: 1.0\n\nDIFF:\n@@ -49,6 +49,7 @@ ALL_OBJECTS_DICT.update(\n         \"uniform\": RandomUniform,\n         \"normal\": RandomNormal,\n         \"orthogonal\": OrthogonalInitializer,\n+        \"Orthogonal\": OrthogonalInitializer,  # Legacy\n         \"one\": Ones,\n         \"zero\": Zeros,\n     }\n\n@@ -147,6 +147,10 @@ class InitializersTest(testing.TestCase):\n \n         self.run_class_serialization_test(initializer)\n \n+        # Test legacy class_name\n+        initializer = initializers.get(\"Orthogonal\")\n+        self.assertIsInstance(initializer, initializers.OrthogonalInitializer)\n+\n     def test_get_method(self):\n         obj = initializers.get(\"glorot_normal\")\n         self.assertTrue(obj, initializers.GlorotNormal)\n\n@@ -500,6 +500,7 @@ class GRU(RNN):\n             trainable=kwargs.get(\"trainable\", True),\n             name=\"gru_cell\",\n             seed=seed,\n+            implementation=kwargs.pop(\"implementation\", 2),\n         )\n         super().__init__(\n             cell,\n\n@@ -286,3 +286,26 @@ class GRUTest(testing.TestCase, parameterized.TestCase):\n             np.array([[0.11669192, 0.11669192], [0.28380975, 0.28380975]]),\n             output,\n         )\n+\n+    def test_legacy_implementation_argument(self):\n+        sequence = np.arange(72).reshape((3, 6, 4)).astype(\"float32\")\n+        layer = layers.GRU(\n+            3,\n+            kernel_initializer=initializers.Constant(0.01),\n+            recurrent_initializer=initializers.Constant(0.02),\n+            bias_initializer=initializers.Constant(0.03),\n+        )\n+        config = layer.get_config()\n+        config[\"implementation\"] = 0  # Add legacy argument\n+        layer = layers.GRU.from_config(config)\n+        output = layer(sequence)\n+        self.assertAllClose(\n+            np.array(\n+                [\n+                    [0.5217289, 0.5217289, 0.5217289],\n+                    [0.6371659, 0.6371659, 0.6371659],\n+                    [0.39384964, 0.39384964, 0.3938496],\n+                ]\n+            ),\n+            output,\n+        )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#77ef1792201cd30b52146c71dd0380786512ac84", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 15 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 20 | Churn Cumulative: 108 | Contributors (this commit): 4 | Commits (past 90d): 9 | Contributors (cumulative): 8 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1711,6 +1711,9 @@ def sparse_categorical_crossentropy(\n     array([0.0513, 2.303], dtype=float32)\n     \"\"\"\n \n+    if len(y_true.shape) == len(y_pred.shape) and y_true.shape[-1] == 1:\n+        y_true = ops.squeeze(y_true, axis=-1)\n+\n     if ignore_class is not None:\n         res_shape = ops.shape(y_pred)[:-1]\n         valid_mask = ops.not_equal(y_true, ops.cast(ignore_class, y_pred.dtype))\n\n@@ -1055,7 +1055,7 @@ class CategoricalCrossentropyTest(testing.TestCase):\n             from_logits=True, reduction=None\n         )\n         loss = cce_obj(y_true, logits)\n-        self.assertAllClose((0.001822, 0.000459, 0.169846), loss, 3)\n+        self.assertAllClose((0.001822, 0.000459, 0.169846), loss)\n \n     def test_label_smoothing(self):\n         logits = np.array([[100.0, -100.0, -100.0]])\n@@ -1170,7 +1170,7 @@ class SparseCategoricalCrossentropyTest(testing.TestCase):\n             from_logits=True, reduction=None\n         )\n         loss = cce_obj(y_true, logits)\n-        self.assertAllClose((0.001822, 0.000459, 0.169846), loss, 3)\n+        self.assertAllClose((0.001822, 0.000459, 0.169846), loss)\n \n     def test_ignore_class(self):\n         y_true = np.array([[-1, 2]])\n@@ -1179,7 +1179,15 @@ class SparseCategoricalCrossentropyTest(testing.TestCase):\n             from_logits=True, ignore_class=-1, reduction=None\n         )\n         loss = cce_obj(y_true, logits)\n-        self.assertAllClose([[0.0, 1.48012]], loss, 3)\n+        self.assertAllClose([[0.0, 1.480129]], loss)\n+\n+        y_true = np.array([[[-1], [2]]])\n+        logits = np.array([[[0.854, 0.698, 0.598], [0.088, 0.86, 0.018]]])\n+        cce_obj = losses.SparseCategoricalCrossentropy(\n+            from_logits=True, ignore_class=-1, reduction=None\n+        )\n+        loss = cce_obj(y_true, logits)\n+        self.assertAllClose([[0.0, 1.480129]], loss)\n \n \n class BinaryFocalCrossentropyTest(testing.TestCase):\n@@ -1272,7 +1280,7 @@ class BinaryFocalCrossentropyTest(testing.TestCase):\n             reduction=None,\n         )\n         loss = obj(y_true, y_pred)\n-        self.assertAllClose(loss, (0.5155, 0.0205), 3)\n+        self.assertAllClose(loss, (0.515547, 0.020513))\n \n \n class CategoricalFocalCrossentropyTest(testing.TestCase):\n@@ -1358,7 +1366,6 @@ class CategoricalFocalCrossentropyTest(testing.TestCase):\n         self.assertAllClose(\n             (1.5096224e-09, 2.4136547e-11, 1.0360638e-03),\n             loss,\n-            3,\n         )\n \n     def test_label_smoothing(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
