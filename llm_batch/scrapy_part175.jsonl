{"custom_id": "scrapy#1276b12c258b42a68ef79c195b5cbd0dee0e52fa", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 25 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 3 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 25 | Churn Cumulative: 164 | Contributors (this commit): 3 | Commits (past 90d): 1 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2,6 +2,31 @@ import json\n from . import default_settings\n \n \n+class SettingsAttribute(object):\n+\n+    \"\"\"Class for storing data related to settings attributes.\n+\n+    This class is intended for internal usage, you should try Settings class\n+    for settings configuration, not this one.\n+    \"\"\"\n+\n+    def __init__(self, value, priority):\n+        self.value = value\n+        self.priority = priority\n+\n+    def set(self, value, priority):\n+        \"\"\"Sets value if priority is higher or equal than current priority.\"\"\"\n+        if priority >= self.priority:\n+            self.value = value\n+            self.priority = priority\n+\n+    def __str__(self):\n+        return \"<SettingsAttribute value={self.value!r} \" \\\n+               \"priority={self.priority}>\".format(self=self)\n+\n+    __repr__ = __str__\n+\n+\n class Settings(object):\n \n     def __init__(self, values=None):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#384efce0a6a43cc5427cb8df4b9c0f6062b73106", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 172 | Contributors (this commit): 3 | Commits (past 90d): 2 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -2,6 +2,14 @@ import json\n from . import default_settings\n \n \n+SETTINGS_PRIORITIES = {\n+    'default': 0,\n+    'command': 10,\n+    'project': 20,\n+    'cmdline': 40,\n+}\n+\n+\n class SettingsAttribute(object):\n \n     \"\"\"Class for storing data related to settings attributes.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#95ba68683ef3e57bbd93502bb556352028ffba72", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 26 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 6 | Methods Changed: 6 | Complexity Δ (Sum/Max): 6/6 | Churn Δ: 33 | Churn Cumulative: 205 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,4 +1,6 @@\n+import six\n import json\n+\n from . import default_settings\n \n \n@@ -37,14 +39,18 @@ class SettingsAttribute(object):\n \n class Settings(object):\n \n-    def __init__(self, values=None):\n-        self.values = values.copy() if values else {}\n-        self.global_defaults = default_settings\n+    def __init__(self, values=None, priority='project'):\n+        self.attributes = {}\n+        for name, defvalue in iter_default_settings():\n+            self.set(name, defvalue, 'default')\n+        if values is not None:\n+            self.setdict(values, priority)\n \n     def __getitem__(self, opt_name):\n-        if opt_name in self.values:\n-            return self.values[opt_name]\n-        return getattr(self.global_defaults, opt_name, None)\n+        value = None\n+        if opt_name in self.attributes:\n+            value = self.attributes[opt_name].value\n+        return value\n \n     def get(self, name, default=None):\n         return self[name] if self[name] is not None else default\n@@ -75,12 +81,25 @@ class Settings(object):\n         value = self.get(name)\n         if value is None:\n             return default or {}\n-        if isinstance(value, basestring):\n+        if isinstance(value, six.string_types):\n             value = json.loads(value)\n         if isinstance(value, dict):\n             return value\n         raise ValueError(\"Cannot convert value for setting '%s' to dict: '%s'\" % (name, value))\n \n+    def set(self, name, value, priority='project'):\n+        if isinstance(priority, six.string_types):\n+            priority = SETTINGS_PRIORITIES[priority]\n+        if name not in self.attributes:\n+            self.attributes[name] = SettingsAttribute(value, priority)\n+        else:\n+            self.attributes[name].set(value, priority)\n+\n+    def setdict(self, values, priority='project'):\n+        for name, value in six.iteritems(values):\n+            self.set(name, value, priority)\n+\n+\n class CrawlerSettings(Settings):\n \n     def __init__(self, settings_module=None, **kw):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#22572834fb80835d82d851bf6fa134d7ac45877b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 215 | Contributors (this commit): 3 | Commits (past 90d): 4 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -1,6 +1,8 @@\n import six\n import json\n \n+from scrapy.utils.deprecate import create_deprecated_class\n+\n from . import default_settings\n \n \n@@ -103,7 +105,7 @@ class Settings(object):\n class CrawlerSettings(Settings):\n \n     def __init__(self, settings_module=None, **kw):\n-        super(CrawlerSettings, self).__init__(**kw)\n+        Settings.__init__(self, **kw)\n         self.settings_module = settings_module\n         self.overrides = {}\n         self.defaults = {}\n@@ -115,11 +117,15 @@ class CrawlerSettings(Settings):\n             return getattr(self.settings_module, opt_name)\n         if opt_name in self.defaults:\n             return self.defaults[opt_name]\n-        return super(CrawlerSettings, self).__getitem__(opt_name)\n+        return Settings.__getitem__(self, opt_name)\n \n     def __str__(self):\n         return \"<CrawlerSettings module=%r>\" % self.settings_module\n \n+CrawlerSettings = create_deprecated_class(\n+    'CrawlerSettings', CrawlerSettings,\n+    new_class_path='scrapy.settings.Settings')\n+\n \n def iter_default_settings():\n     \"\"\"Return the default settings as an iterator of (name, value) tuples\"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#b4b17049e952e4b8e6311d605044243a6f38b36b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 162 | Lines Deleted: 82 | Files Changed: 3 | Hunks: 3 | Methods Changed: 16 | Complexity Δ (Sum/Max): 9/14 | Churn Δ: 244 | Churn Cumulative: 341 | Contributors (this commit): 4 | Commits (past 90d): 3 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,82 +0,0 @@\n-import unittest\n-\n-from scrapy.settings import Settings\n-from scrapy.utils.test import get_crawler\n-from scrapy.spider import Spider\n-\n-class SettingsTest(unittest.TestCase):\n-\n-    def test_get(self):\n-        settings = Settings({\n-            'TEST_ENABLED1': '1',\n-            'TEST_ENABLED2': True,\n-            'TEST_ENABLED3': 1,\n-            'TEST_DISABLED1': '0',\n-            'TEST_DISABLED2': False,\n-            'TEST_DISABLED3': 0,\n-            'TEST_INT1': 123,\n-            'TEST_INT2': '123',\n-            'TEST_FLOAT1': 123.45,\n-            'TEST_FLOAT2': '123.45',\n-            'TEST_LIST1': ['one', 'two'],\n-            'TEST_LIST2': 'one,two',\n-            'TEST_STR': 'value',\n-            'TEST_DICT1': {'key1': 'val1', 'ke2': 3},\n-            'TEST_DICT2': '{\"key1\": \"val1\", \"ke2\": 3}',\n-        })\n-        assert settings.getbool('TEST_ENABLED1') is True\n-        assert settings.getbool('TEST_ENABLED2') is True\n-        assert settings.getbool('TEST_ENABLED3') is True\n-        assert settings.getbool('TEST_ENABLEDx') is False\n-        assert settings.getbool('TEST_ENABLEDx', True) is True\n-        assert settings.getbool('TEST_DISABLED1') is False\n-        assert settings.getbool('TEST_DISABLED2') is False\n-        assert settings.getbool('TEST_DISABLED3') is False\n-        self.assertEqual(settings.getint('TEST_INT1'), 123)\n-        self.assertEqual(settings.getint('TEST_INT2'), 123)\n-        self.assertEqual(settings.getint('TEST_INTx'), 0)\n-        self.assertEqual(settings.getint('TEST_INTx', 45), 45)\n-        self.assertEqual(settings.getfloat('TEST_FLOAT1'), 123.45)\n-        self.assertEqual(settings.getfloat('TEST_FLOAT2'), 123.45)\n-        self.assertEqual(settings.getfloat('TEST_FLOATx'), 0.0)\n-        self.assertEqual(settings.getfloat('TEST_FLOATx', 55.0), 55.0)\n-        self.assertEqual(settings.getlist('TEST_LIST1'), ['one', 'two'])\n-        self.assertEqual(settings.getlist('TEST_LIST2'), ['one', 'two'])\n-        self.assertEqual(settings.getlist('TEST_LISTx'), [])\n-        self.assertEqual(settings.getlist('TEST_LISTx', ['default']), ['default'])\n-        self.assertEqual(settings['TEST_STR'], 'value')\n-        self.assertEqual(settings.get('TEST_STR'), 'value')\n-        self.assertEqual(settings['TEST_STRx'], None)\n-        self.assertEqual(settings.get('TEST_STRx'), None)\n-        self.assertEqual(settings.get('TEST_STRx', 'default'), 'default')\n-        self.assertEqual(settings.getdict('TEST_DICT1'), {'key1': 'val1', 'ke2': 3})\n-        self.assertEqual(settings.getdict('TEST_DICT2'), {'key1': 'val1', 'ke2': 3})\n-        self.assertEqual(settings.getdict('TEST_DICT3'), {})\n-        self.assertEqual(settings.getdict('TEST_DICT3', {'key1': 5}), {'key1': 5})\n-        self.assertRaises(ValueError, settings.getdict, 'TEST_LIST1')\n-\n-\n-class CrawlerSettingsTest(unittest.TestCase):\n-\n-    def test_global_defaults(self):\n-        crawler = get_crawler()\n-        self.assertEqual(crawler.settings.getint('DOWNLOAD_TIMEOUT'), 180)\n-\n-    def test_defaults(self):\n-        crawler = get_crawler()\n-        crawler.settings.defaults['DOWNLOAD_TIMEOUT'] = '99'\n-        self.assertEqual(crawler.settings.getint('DOWNLOAD_TIMEOUT'), 99)\n-\n-    def test_settings_module(self):\n-        crawler = get_crawler({'DOWNLOAD_TIMEOUT': '3'})\n-        self.assertEqual(crawler.settings.getint('DOWNLOAD_TIMEOUT'), 3)\n-\n-    def test_overrides(self):\n-        crawler = get_crawler({'DOWNLOAD_TIMEOUT': '3'})\n-        crawler.settings.overrides['DOWNLOAD_TIMEOUT'] = '15'\n-        self.assertEqual(crawler.settings.getint('DOWNLOAD_TIMEOUT'), 15)\n-\n-\n-if __name__ == \"__main__\":\n-    unittest.main()\n-\n\n@@ -0,0 +1,160 @@\n+import six\n+import unittest\n+try:\n+    from unittest import mock\n+except ImportError:\n+    import mock\n+\n+from scrapy.settings import Settings, SettingsAttribute\n+from . import default_settings\n+\n+\n+class SettingsAttributeTest(unittest.TestCase):\n+\n+    def setUp(self):\n+        self.attribute = SettingsAttribute('value', 10)\n+\n+    def test_set_greater_priority(self):\n+        self.attribute.set('value2', 20)\n+        self.assertEqual(self.attribute.value, 'value2')\n+        self.assertEqual(self.attribute.priority, 20)\n+\n+    def test_set_equal_priority(self):\n+        self.attribute.set('value2', 10)\n+        self.assertEqual(self.attribute.value, 'value2')\n+        self.assertEqual(self.attribute.priority, 10)\n+\n+    def test_set_less_priority(self):\n+        self.attribute.set('value2', 0)\n+        self.assertEqual(self.attribute.value, 'value')\n+        self.assertEqual(self.attribute.priority, 10)\n+\n+\n+class SettingsTest(unittest.TestCase):\n+\n+    def setUp(self):\n+        self.settings = Settings()\n+\n+    @mock.patch.dict('scrapy.settings.SETTINGS_PRIORITIES', {'default': 10})\n+    @mock.patch('scrapy.settings.default_settings', default_settings)\n+    def test_initial_defaults(self):\n+        settings = Settings()\n+        self.assertEqual(len(settings.attributes), 1)\n+        self.assertIn('TEST_DEFAULT', settings.attributes)\n+\n+        attr = settings.attributes['TEST_DEFAULT']\n+        self.assertIsInstance(attr, SettingsAttribute)\n+        self.assertEqual(attr.value, 'defvalue')\n+        self.assertEqual(attr.priority, 10)\n+\n+    @mock.patch.dict('scrapy.settings.SETTINGS_PRIORITIES', {})\n+    @mock.patch('scrapy.settings.default_settings', {})\n+    def test_initial_values(self):\n+        settings = Settings({'TEST_OPTION': 'value'}, 10)\n+        self.assertEqual(len(settings.attributes), 1)\n+        self.assertIn('TEST_OPTION', settings.attributes)\n+\n+        attr = settings.attributes['TEST_OPTION']\n+        self.assertIsInstance(attr, SettingsAttribute)\n+        self.assertEqual(attr.value, 'value')\n+        self.assertEqual(attr.priority, 10)\n+\n+    def test_set_new_attribute(self):\n+        self.settings.attributes = {}\n+        self.settings.set('TEST_OPTION', 'value', 0)\n+        self.assertIn('TEST_OPTION', self.settings.attributes)\n+\n+        attr = self.settings.attributes['TEST_OPTION']\n+        self.assertIsInstance(attr, SettingsAttribute)\n+        self.assertEqual(attr.value, 'value')\n+        self.assertEqual(attr.priority, 0)\n+\n+    def test_set_instance_identity_on_update(self):\n+        attr = SettingsAttribute('value', 0)\n+        self.settings.attributes = {'TEST_OPTION': attr}\n+        self.settings.set('TEST_OPTION', 'othervalue', 10)\n+\n+        self.assertIn('TEST_OPTION', self.settings.attributes)\n+        self.assertIs(attr, self.settings.attributes['TEST_OPTION'])\n+\n+    def test_set_calls_settings_attributes_methods_on_update(self):\n+        with mock.patch.object(SettingsAttribute, '__setattr__') as mock_setattr, \\\n+                mock.patch.object(SettingsAttribute, 'set') as mock_set:\n+\n+            attr = SettingsAttribute('value', 10)\n+            self.settings.attributes = {'TEST_OPTION': attr}\n+            mock_set.reset_mock()\n+            mock_setattr.reset_mock()\n+\n+            for priority in (0, 10, 20):\n+                self.settings.set('TEST_OPTION', 'othervalue', priority)\n+                mock_set.assert_called_once_with('othervalue', priority)\n+                self.assertFalse(mock_setattr.called)\n+                mock_set.reset_mock()\n+                mock_setattr.reset_mock()\n+\n+    def test_setdict_alias(self):\n+        with mock.patch.object(self.settings, 'set') as mock_set:\n+            self.settings.setdict({'TEST_1': 'value1', 'TEST_2': 'value2'}, 10)\n+            self.assertEqual(mock_set.call_count, 2)\n+            calls = [mock.call('TEST_1', 'value1', 10),\n+                     mock.call('TEST_2', 'value2', 10)]\n+            mock_set.assert_has_calls(calls, any_order=True)\n+\n+    def test_get(self):\n+        test_configuration = {\n+            'TEST_ENABLED1': '1',\n+            'TEST_ENABLED2': True,\n+            'TEST_ENABLED3': 1,\n+            'TEST_DISABLED1': '0',\n+            'TEST_DISABLED2': False,\n+            'TEST_DISABLED3': 0,\n+            'TEST_INT1': 123,\n+            'TEST_INT2': '123',\n+            'TEST_FLOAT1': 123.45,\n+            'TEST_FLOAT2': '123.45',\n+            'TEST_LIST1': ['one', 'two'],\n+            'TEST_LIST2': 'one,two',\n+            'TEST_STR': 'value',\n+            'TEST_DICT1': {'key1': 'val1', 'ke2': 3},\n+            'TEST_DICT2': '{\"key1\": \"val1\", \"ke2\": 3}',\n+        }\n+        settings = self.settings\n+        settings.attributes = {key: SettingsAttribute(value, 0) for key, value\n+                               in six.iteritems(test_configuration)}\n+\n+        self.assertTrue(settings.getbool('TEST_ENABLED1'))\n+        self.assertTrue(settings.getbool('TEST_ENABLED2'))\n+        self.assertTrue(settings.getbool('TEST_ENABLED3'))\n+        self.assertFalse(settings.getbool('TEST_ENABLEDx'))\n+        self.assertTrue(settings.getbool('TEST_ENABLEDx', True))\n+        self.assertFalse(settings.getbool('TEST_DISABLED1'))\n+        self.assertFalse(settings.getbool('TEST_DISABLED2'))\n+        self.assertFalse(settings.getbool('TEST_DISABLED3'))\n+        self.assertEqual(settings.getint('TEST_INT1'), 123)\n+        self.assertEqual(settings.getint('TEST_INT2'), 123)\n+        self.assertEqual(settings.getint('TEST_INTx'), 0)\n+        self.assertEqual(settings.getint('TEST_INTx', 45), 45)\n+        self.assertEqual(settings.getfloat('TEST_FLOAT1'), 123.45)\n+        self.assertEqual(settings.getfloat('TEST_FLOAT2'), 123.45)\n+        self.assertEqual(settings.getfloat('TEST_FLOATx'), 0.0)\n+        self.assertEqual(settings.getfloat('TEST_FLOATx', 55.0), 55.0)\n+        self.assertEqual(settings.getlist('TEST_LIST1'), ['one', 'two'])\n+        self.assertEqual(settings.getlist('TEST_LIST2'), ['one', 'two'])\n+        self.assertEqual(settings.getlist('TEST_LISTx'), [])\n+        self.assertEqual(settings.getlist('TEST_LISTx', ['default']), ['default'])\n+        self.assertEqual(settings['TEST_STR'], 'value')\n+        self.assertEqual(settings.get('TEST_STR'), 'value')\n+        self.assertEqual(settings['TEST_STRx'], None)\n+        self.assertEqual(settings.get('TEST_STRx'), None)\n+        self.assertEqual(settings.get('TEST_STRx', 'default'), 'default')\n+        self.assertEqual(settings.getdict('TEST_DICT1'), {'key1': 'val1', 'ke2': 3})\n+        self.assertEqual(settings.getdict('TEST_DICT2'), {'key1': 'val1', 'ke2': 3})\n+        self.assertEqual(settings.getdict('TEST_DICT3'), {})\n+        self.assertEqual(settings.getdict('TEST_DICT3', {'key1': 5}), {'key1': 5})\n+        self.assertRaises(ValueError, settings.getdict, 'TEST_LIST1')\n+\n+\n+if __name__ == \"__main__\":\n+    unittest.main()\n+\n\n@@ -0,0 +1,2 @@\n+\n+TEST_DEFAULT = 'defvalue'\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#ed033854e24e66488cc2fd149345376874a12925", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 44 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 4 | Methods Changed: 5 | Complexity Δ (Sum/Max): 7/4 | Churn Δ: 46 | Churn Cumulative: 421 | Contributors (this commit): 3 | Commits (past 90d): 7 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,5 +1,6 @@\n import six\n import json\n+from importlib import import_module\n \n from scrapy.utils.deprecate import create_deprecated_class\n \n@@ -43,8 +44,7 @@ class Settings(object):\n \n     def __init__(self, values=None, priority='project'):\n         self.attributes = {}\n-        for name, defvalue in iter_default_settings():\n-            self.set(name, defvalue, 'default')\n+        self.setmodule(default_settings, priority='default')\n         if values is not None:\n             self.setdict(values, priority)\n \n@@ -101,6 +101,13 @@ class Settings(object):\n         for name, value in six.iteritems(values):\n             self.set(name, value, priority)\n \n+    def setmodule(self, module, priority='project'):\n+        if isinstance(module, six.string_types):\n+            module = import_module(module)\n+        for key in dir(module):\n+            if key.isupper():\n+                self.set(key, getattr(module, key), priority)\n+\n \n class CrawlerSettings(Settings):\n \n\n@@ -101,6 +101,41 @@ class SettingsTest(unittest.TestCase):\n                      mock.call('TEST_2', 'value2', 10)]\n             mock_set.assert_has_calls(calls, any_order=True)\n \n+    def test_setmodule_only_load_uppercase_vars(self):\n+        class ModuleMock():\n+            UPPERCASE_VAR = 'value'\n+            MIXEDcase_VAR = 'othervalue'\n+            lowercase_var = 'anothervalue'\n+\n+        self.settings.attributes = {}\n+        self.settings.setmodule(ModuleMock(), 10)\n+        self.assertIn('UPPERCASE_VAR', self.settings.attributes)\n+        self.assertNotIn('MIXEDcase_VAR', self.settings.attributes)\n+        self.assertNotIn('lowercase_var', self.settings.attributes)\n+        self.assertEqual(len(self.settings.attributes), 1)\n+\n+    def test_setmodule_alias(self):\n+        with mock.patch.object(self.settings, 'set') as mock_set:\n+            self.settings.setmodule(default_settings, 10)\n+            mock_set.assert_called_with('TEST_DEFAULT', 'defvalue', 10)\n+\n+    def test_setmodule_by_path(self):\n+        self.settings.attributes = {}\n+        self.settings.setmodule(default_settings, 10)\n+        ctrl_attributes = self.settings.attributes.copy()\n+\n+        self.settings.attributes = {}\n+        self.settings.setmodule(\n+            'scrapy.tests.test_settings.default_settings', 10)\n+\n+        self.assertItemsEqual(six.iterkeys(self.settings.attributes),\n+                              six.iterkeys(ctrl_attributes))\n+\n+        for attr, ctrl_attr in zip(six.itervalues(self.settings.attributes),\n+                                   six.itervalues(ctrl_attributes)):\n+            self.assertEqual(attr.value, ctrl_attr.value)\n+            self.assertEqual(attr.priority, ctrl_attr.priority)\n+\n     def test_get(self):\n         test_configuration = {\n             'TEST_ENABLED1': '1',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#b397f5e935c616b1d4887ef8654f185321d35731", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 11 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 15 | Churn Cumulative: 150 | Contributors (this commit): 6 | Commits (past 90d): 3 | Contributors (cumulative): 6 | DMM Complexity: 0.0\n\nDIFF:\n@@ -22,20 +22,13 @@ def assert_aws_environ():\n \n def get_crawler(settings_dict=None):\n     \"\"\"Return an unconfigured Crawler object. If settings_dict is given, it\n-    will be used as the settings present in the settings module of the\n-    CrawlerSettings.\n+    will be used to populate the crawler settings with a project level\n+    priority.\n     \"\"\"\n     from scrapy.crawler import Crawler\n-    from scrapy.settings import CrawlerSettings\n+    from scrapy.settings import Settings\n \n-    class SettingsModuleMock(object):\n-        pass\n-    settings_module = SettingsModuleMock()\n-    if settings_dict:\n-        for k, v in settings_dict.items():\n-            setattr(settings_module, k, v)\n-    settings = CrawlerSettings(settings_module)\n-    return Crawler(settings)\n+    return Crawler(Settings(settings_dict))\n \n def get_pythonpath():\n     \"\"\"Return a PYTHONPATH suitable to use in processes so that they find this\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#c496468e2ac7b87e5d9ad16a3cf4a7f65b10ff5a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 9 | Files Changed: 1 | Hunks: 5 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 19 | Churn Cumulative: 189 | Contributors (this commit): 5 | Commits (past 90d): 1 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -6,7 +6,7 @@ from importlib import import_module\n from os.path import join, dirname, abspath, isabs, exists\n \n from scrapy.utils.conf import closest_scrapy_cfg, get_config, init_env\n-from scrapy.settings import CrawlerSettings\n+from scrapy.settings import Settings\n from scrapy.exceptions import NotConfigured\n \n ENVVAR = 'SCRAPY_SETTINGS_MODULE'\n@@ -53,20 +53,21 @@ def get_project_settings():\n     if ENVVAR not in os.environ:\n         project = os.environ.get('SCRAPY_PROJECT', 'default')\n         init_env(project)\n+\n+    settings = Settings()\n     settings_module_path = os.environ.get(ENVVAR)\n     if settings_module_path:\n-        settings_module = import_module(settings_module_path)\n-    else:\n-        settings_module = None\n-    settings = CrawlerSettings(settings_module)\n+        settings.setmodule(settings_module_path, priority='project')\n \n     # XXX: remove this hack\n     pickled_settings = os.environ.get(\"SCRAPY_PICKLED_SETTINGS_TO_OVERRIDE\")\n-    settings.overrides = pickle.loads(pickled_settings) if pickled_settings else {}\n+    if pickled_settings:\n+        settings.setdict(pickle.loads(pickled_settings), priority='project')\n \n     # XXX: deprecate and remove this functionality\n-    for k, v in os.environ.items():\n-        if k.startswith('SCRAPY_'):\n-            settings.overrides[k[7:]] = v\n+    env_overrides = {k[7:]: v for k, v in os.environ.items() if\n+                     k.startswith('SCRAPY_')}\n+    if env_overrides:\n+        settings.setdict(env_overrides, priority='project')\n \n     return settings\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#080a28f3e978bc184b1c0b94233b013fd0e8d561", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 574 | Contributors (this commit): 5 | Commits (past 90d): 1 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -133,7 +133,7 @@ def execute(argv=None, settings=None):\n     cmd = cmds[cmdname]\n     parser.usage = \"scrapy %s %s\" % (cmdname, cmd.syntax())\n     parser.description = cmd.long_desc()\n-    settings.defaults.update(cmd.default_settings)\n+    settings.setdict(cmd.default_settings, priority='command')\n     cmd.settings = settings\n     cmd.add_options(parser)\n     opts, args = parser.parse_args(args=argv[1:])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#c81b087de18d4410554ee398122aff8479d8e84a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 12 | Files Changed: 3 | Hunks: 10 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 25 | Churn Cumulative: 502 | Contributors (this commit): 8 | Commits (past 90d): 12 | Contributors (cumulative): 18 | DMM Complexity: 0.0\n\nDIFF:\n@@ -103,20 +103,21 @@ class ScrapyCommand(object):\n \n     def process_options(self, args, opts):\n         try:\n-            self.settings.overrides.update(arglist_to_dict(opts.set))\n+            self.settings.setdict(arglist_to_dict(opts.set),\n+                                  priority='cmdline')\n         except ValueError:\n             raise UsageError(\"Invalid -s value, use -s NAME=VALUE\", print_help=False)\n \n         if opts.logfile:\n-            self.settings.overrides['LOG_ENABLED'] = True\n-            self.settings.overrides['LOG_FILE'] = opts.logfile\n+            self.settings.set('LOG_ENABLED', True, priority='cmdline')\n+            self.settings.set('LOG_FILE', opts.logfile, priority='cmdline')\n \n         if opts.loglevel:\n-            self.settings.overrides['LOG_ENABLED'] = True\n-            self.settings.overrides['LOG_LEVEL'] = opts.loglevel\n+            self.settings.set('LOG_ENABLED', True, priority='cmdline')\n+            self.settings.set('LOG_LEVEL', opts.loglevel, priority='cmdline')\n \n         if opts.nolog:\n-            self.settings.overrides['LOG_ENABLED'] = False\n+            self.settings.set('LOG_ENABLED', False, priority='cmdline')\n \n         if opts.pidfile:\n             with open(opts.pidfile, \"w\") as f:\n\n@@ -31,9 +31,9 @@ class Command(ScrapyCommand):\n             raise UsageError(\"Invalid -a value, use -a NAME=VALUE\", print_help=False)\n         if opts.output:\n             if opts.output == '-':\n-                self.settings.overrides['FEED_URI'] = 'stdout:'\n+                self.settings.set('FEED_URI', 'stdout:', priority='cmdline')\n             else:\n-                self.settings.overrides['FEED_URI'] = opts.output\n+                self.settings.set('FEED_URI', opts.output, priority='cmdline')\n             valid_output_formats = self.settings['FEED_EXPORTERS'].keys() + self.settings['FEED_EXPORTERS_BASE'].keys()\n             if not opts.output_format:\n                 opts.output_format = os.path.splitext(opts.output)[1].replace(\".\", \"\")\n@@ -42,7 +42,7 @@ class Command(ScrapyCommand):\n                                  \" using the '-t' switch or as a file extension\"\n                                  \" from the supported list %s\" % (opts.output_format,\n                                                                   tuple(valid_output_formats)))\n-            self.settings.overrides['FEED_FORMAT'] = opts.output_format\n+            self.settings.set('FEED_FORMAT', opts.output_format, priority='cmdline')\n \n     def run(self, args, opts):\n         if len(args) < 1:\n\n@@ -54,9 +54,9 @@ class Command(ScrapyCommand):\n             raise UsageError(\"Invalid -a value, use -a NAME=VALUE\", print_help=False)\n         if opts.output:\n             if opts.output == '-':\n-                self.settings.overrides['FEED_URI'] = 'stdout:'\n+                self.settings.set('FEED_URI', 'stdout:', priority='cmdline')\n             else:\n-                self.settings.overrides['FEED_URI'] = opts.output\n+                self.settings.set('FEED_URI', opts.output, priority='cmdline')\n             valid_output_formats = self.settings['FEED_EXPORTERS'].keys() + self.settings['FEED_EXPORTERS_BASE'].keys()\n             if not opts.output_format:\n                 opts.output_format = os.path.splitext(opts.output)[1].replace(\".\", \"\")\n@@ -65,7 +65,7 @@ class Command(ScrapyCommand):\n                                  \" using the '-t' switch or as a file extension\"\n                                  \" from the supported list %s\" % (opts.output_format,\n                                                                   tuple(valid_output_formats)))\n-            self.settings.overrides['FEED_FORMAT'] = opts.output_format\n+            self.settings.set('FEED_FORMAT', opts.output_format, priority='cmdline')\n \n     def run(self, args, opts):\n         if len(args) != 1:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#43ae69e436992285292aa96b7eabc74df45a206e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 334 | Contributors (this commit): 8 | Commits (past 90d): 13 | Contributors (cumulative): 14 | DMM Complexity: 0.0\n\nDIFF:\n@@ -34,7 +34,10 @@ class Command(ScrapyCommand):\n                 self.settings.set('FEED_URI', 'stdout:', priority='cmdline')\n             else:\n                 self.settings.set('FEED_URI', opts.output, priority='cmdline')\n-            valid_output_formats = self.settings['FEED_EXPORTERS'].keys() + self.settings['FEED_EXPORTERS_BASE'].keys()\n+            valid_output_formats = (\n+                list(self.settings.getdict('FEED_EXPORTERS').keys()) +\n+                list(self.settings.getdict('FEED_EXPORTERS_BASE').keys())\n+            )\n             if not opts.output_format:\n                 opts.output_format = os.path.splitext(opts.output)[1].replace(\".\", \"\")\n             if opts.output_format not in valid_output_formats:\n\n@@ -57,7 +57,10 @@ class Command(ScrapyCommand):\n                 self.settings.set('FEED_URI', 'stdout:', priority='cmdline')\n             else:\n                 self.settings.set('FEED_URI', opts.output, priority='cmdline')\n-            valid_output_formats = self.settings['FEED_EXPORTERS'].keys() + self.settings['FEED_EXPORTERS_BASE'].keys()\n+            valid_output_formats = (\n+                list(self.settings.getdict('FEED_EXPORTERS').keys()) +\n+                list(self.settings.getdict('FEED_EXPORTERS_BASE').keys())\n+            )\n             if not opts.output_format:\n                 opts.output_format = os.path.splitext(opts.output)[1].replace(\".\", \"\")\n             if opts.output_format not in valid_output_formats:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#6730e3c9f73f6864acdea51c88f6c2277b7ae439", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 92 | Contributors (this commit): 3 | Commits (past 90d): 2 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -3,7 +3,7 @@\n class TestExtension(object):\n \n     def __init__(self, settings):\n-        settings.overrides['TEST1'] = \"%s + %s\" % (settings['TEST1'], 'started')\n+        settings.set('TEST1', \"%s + %s\" % (settings['TEST1'], 'started'))\n \n     @classmethod\n     def from_crawler(cls, crawler):\n\n@@ -6,17 +6,17 @@ from twisted.trial import unittest\n from scrapy.contrib.downloadermiddleware.robotstxt import RobotsTxtMiddleware\n from scrapy.exceptions import IgnoreRequest, NotConfigured\n from scrapy.http import Request, Response\n-from scrapy.settings import CrawlerSettings\n+from scrapy.settings import Settings\n \n \n class RobotsTxtMiddlewareTest(unittest.TestCase):\n \n     def test(self):\n         crawler = mock.MagicMock()\n-        crawler.settings = CrawlerSettings()\n-        crawler.settings.overrides['USER_AGENT'] = 'CustomAgent'\n+        crawler.settings = Settings()\n+        crawler.settings.set('USER_AGENT', 'CustomAgent')\n         self.assertRaises(NotConfigured, RobotsTxtMiddleware, crawler)\n-        crawler.settings.overrides['ROBOTSTXT_OBEY'] = True\n+        crawler.settings.set('ROBOTSTXT_OBEY', True)\n         crawler.engine.download = mock.MagicMock()\n         ROBOTS = re.sub(r'^\\s+(?m)', '', '''\n         User-Agent: *\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#eefa878f98e404fd00af017e58c97261968f9067", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 2 | Churn Cumulative: 185 | Contributors (this commit): 7 | Commits (past 90d): 1 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -49,7 +49,7 @@ class OffsiteMiddleware(object):\n         allowed_domains = getattr(spider, 'allowed_domains', None)\n         if not allowed_domains:\n             return re.compile('') # allow all by default\n-        regex = r'^(.*\\.)?(%s)$' % '|'.join(re.escape(d) for d in allowed_domains)\n+        regex = r'^(.*\\.)?(%s)$' % '|'.join(re.escape(d) for d in allowed_domains if d is not None)\n         return re.compile(regex)\n \n     def spider_opened(self, spider):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#a069d366529d8fa9d4dcdfcc8bfc88a90d83e4b0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 13 | Churn Cumulative: 107 | Contributors (this commit): 8 | Commits (past 90d): 1 | Contributors (cumulative): 8 | DMM Complexity: 1.0\n\nDIFF:\n@@ -5,6 +5,7 @@ from scrapy.spider import Spider\n from scrapy.contrib.spidermiddleware.offsite import OffsiteMiddleware\n from scrapy.utils.test import get_crawler\n \n+from urlparse import urlparse\n \n class TestOffsiteMiddleware(TestCase):\n \n@@ -52,3 +53,15 @@ class TestOffsiteMiddleware3(TestOffsiteMiddleware2):\n     def _get_spider(self):\n         return Spider('foo')\n \n+\n+class TestOffsiteMiddleware4(TestOffsiteMiddleware3):\n+\n+    def _get_spider(self):\n+      bad_hostname = urlparse('http:////scrapytest.org').hostname\n+      return Spider('foo', allowed_domains=['scrapytest.org', None, bad_hostname])\n+\n+    def test_process_spider_output(self):\n+      res = Response('http://scrapytest.org')\n+      reqs = [Request('http://scrapytest.org/1')]\n+      out = list(self.mw.process_spider_output(res, reqs, self.spider))\n+      self.assertEquals(out, reqs)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#5fb22ba4e7766f616020a13c038a78cc0c72ef87", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 9 | Churn Cumulative: 265 | Contributors (this commit): 4 | Commits (past 90d): 3 | Contributors (cumulative): 4 | DMM Complexity: 0.0\n\nDIFF:\n@@ -53,8 +53,8 @@ class Command(ScrapyCommand):\n         ScrapyCommand.add_options(self, parser)\n         parser.add_option(\"-l\", \"--list\", dest=\"list\", action=\"store_true\",\n                           help=\"only list contracts, without checking them\")\n-        parser.add_option(\"-v\", \"--verbose\", dest=\"verbose\", default=1, action=\"count\",\n-                          help=\"print all contract hooks\")\n+        parser.add_option(\"-v\", \"--verbose\", dest=\"verbose\", default=False, action='store_true',\n+                          help=\"print contract tests for all spiders\")\n \n     def run(self, args, opts):\n         # load contracts\n@@ -63,7 +63,7 @@ class Command(ScrapyCommand):\n             self.settings['SPIDER_CONTRACTS'],\n         )\n         conman = ContractsManager([load_object(c) for c in contracts])\n-        runner = TextTestRunner(verbosity=opts.verbose)\n+        runner = TextTestRunner(verbosity=2 if opts.verbose else 1)\n         result = TextTestResult(runner.stream, runner.descriptions, runner.verbosity)\n \n         # contract requests\n@@ -75,6 +75,7 @@ class Command(ScrapyCommand):\n         for spider in args or spiders.list():\n             spider = spiders.create(spider)\n             requests = self.get_requests(spider, conman, result)\n+            contract_reqs[spider.name] = []\n \n             if opts.list:\n                 for req in requests:\n@@ -86,6 +87,8 @@ class Command(ScrapyCommand):\n         # start checks\n         if opts.list:\n             for spider, methods in sorted(contract_reqs.iteritems()):\n+                if not methods and not opts.verbose:\n+                    continue\n                 print(spider)\n                 for method in sorted(methods):\n                     print('  * %s' % method)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#bfe02b019ef7358be889b3704ca5c17ff7a616db", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 234 | Contributors (this commit): 6 | Commits (past 90d): 2 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -123,7 +123,7 @@ except ImportError:\n     from distutils.core import setup\n else:\n     setup_args['install_requires'] = [\n-        'Twisted>=10.0.0,<14.0.0',\n+        'Twisted>=10.0.0',\n         'w3lib>=1.2',\n         'queuelib',\n         'lxml',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#d48158427ae29001c10743b0c924d20795f79788", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 1033 | Contributors (this commit): 4 | Commits (past 90d): 1 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -118,6 +118,7 @@ class TunnelingAgent(Agent):\n         super(TunnelingAgent, self).__init__(reactor, contextFactory,\n             connectTimeout, bindAddress, pool)\n         self._proxyConf = proxyConf\n+        self._contextFactory = contextFactory\n \n     def _getEndpoint(self, scheme, host, port):\n         return TunnelingTCP4ClientEndpoint(self._reactor, host, port,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#f224ac132885d8adbd36d0ce39ecbad7dc6e4bab", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 28 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): 4/3 | Churn Δ: 29 | Churn Cumulative: 450 | Contributors (this commit): 4 | Commits (past 90d): 9 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,8 +1,10 @@\n import six\n import json\n+import warnings\n from importlib import import_module\n \n from scrapy.utils.deprecate import create_deprecated_class\n+from scrapy.exceptions import ScrapyDeprecationWarning\n \n from . import default_settings\n \n@@ -108,6 +110,22 @@ class Settings(object):\n             if key.isupper():\n                 self.set(key, getattr(module, key), priority)\n \n+    @property\n+    def overrides(self):\n+        warnings.warn(\"`Settings.overrides` attribute is deprecated and won't \"\n+                      \"be supported in Scrapy 0.26, use \"\n+                      \"`Settings.set(name, value, priority='cmdline')` instead\",\n+                      category=ScrapyDeprecationWarning, stacklevel=2)\n+        try:\n+            o = self._overrides\n+        except AttributeError:\n+            class _DictProxy(dict):\n+                def __setitem__(this, key, value):\n+                    super(_DictProxy, this).__setitem__(key, value)\n+                    self.set(key, value, priority='cmdline')\n+            self._overrides = o = _DictProxy()\n+        return o\n+\n \n class CrawlerSettings(Settings):\n \n\n@@ -1,5 +1,6 @@\n import six\n import unittest\n+import warnings\n try:\n     from unittest import mock\n except ImportError:\n@@ -189,7 +190,15 @@ class SettingsTest(unittest.TestCase):\n         self.assertEqual(settings.getdict('TEST_DICT3', {'key1': 5}), {'key1': 5})\n         self.assertRaises(ValueError, settings.getdict, 'TEST_LIST1')\n \n+    def test_deprecated_attribute(self):\n+        self.settings.set('BAR', 'fuz', priority='cmdline')\n+        with warnings.catch_warnings(record=True) as w:\n+            self.settings.overrides['BAR'] = 'foo'\n+            self.assertIn(\"Settings.overrides\", str(w[0].message))\n+            self.assertEqual(self.settings.get('BAR'), 'foo')\n+            self.assertEqual(self.settings.overrides.get('BAR'), 'foo')\n+            self.assertIn('BAR', self.settings.overrides)\n+\n \n if __name__ == \"__main__\":\n     unittest.main()\n-\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#5b2faf61c3b12ea5f81d61cdae1672a5d850a8cc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 238 | Contributors (this commit): 13 | Commits (past 90d): 3 | Contributors (cumulative): 13 | DMM Complexity: None\n\nDIFF:\n@@ -136,6 +136,7 @@ FEED_EXPORTERS = {}\n FEED_EXPORTERS_BASE = {\n     'json': 'scrapy.contrib.exporter.JsonItemExporter',\n     'jsonlines': 'scrapy.contrib.exporter.JsonLinesItemExporter',\n+    'jl': 'scrapy.contrib.exporter.JsonLinesItemExporter',\n     'csv': 'scrapy.contrib.exporter.CsvItemExporter',\n     'xml': 'scrapy.contrib.exporter.XmlItemExporter',\n     'marshal': 'scrapy.contrib.exporter.MarshalItemExporter',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#a9ecef566253deb36455012279f4b7e7b50a487b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 8 | Files Changed: 4 | Hunks: 9 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 17 | Churn Cumulative: 1069 | Contributors (this commit): 8 | Commits (past 90d): 5 | Contributors (cumulative): 19 | DMM Complexity: None\n\nDIFF:\n@@ -5,3 +5,4 @@ This package contains a collection of Link Extractors.\n \n For more info see docs/topics/link-extractors.rst\n \"\"\"\n+from .lxmlhtml import LxmlLinkExtractor as LinkExtractor\n\n@@ -8,7 +8,7 @@ from urllib import urlencode\n from scrapy.spider import Spider\n from scrapy.http import Request\n from scrapy.item import Item\n-from scrapy.contrib.linkextractors.sgml import SgmlLinkExtractor\n+from scrapy.contrib.linkextractors import LinkExtractor\n \n \n class MetaSpider(Spider):\n@@ -26,7 +26,7 @@ class MetaSpider(Spider):\n class FollowAllSpider(MetaSpider):\n \n     name = 'follow'\n-    link_extractor = SgmlLinkExtractor()\n+    link_extractor = LinkExtractor()\n \n     def __init__(self, total=10, show=20, order=\"rand\", maxlatency=0.0, *args, **kwargs):\n         super(FollowAllSpider, self).__init__(*args, **kwargs)\n\n@@ -23,7 +23,7 @@ from scrapy.xlib.pydispatch import dispatcher\n from scrapy.tests import tests_datadir\n from scrapy.spider import Spider\n from scrapy.item import Item, Field\n-from scrapy.contrib.linkextractors.sgml import SgmlLinkExtractor\n+from scrapy.contrib.linkextractors import LinkExtractor\n from scrapy.http import Request\n from scrapy.utils.signal import disconnect_all\n \n@@ -41,7 +41,7 @@ class TestSpider(Spider):\n     price_re = re.compile(\">Price: \\$(.*?)<\", re.M)\n \n     def parse(self, response):\n-        xlink = SgmlLinkExtractor()\n+        xlink = LinkExtractor()\n         itemre = re.compile(self.itemurl_re)\n         for link in xlink.extract_links(response):\n             if itemre.search(link.url):\n\n@@ -11,7 +11,7 @@ from scrapy.http import Request, Response, TextResponse, XmlResponse, HtmlRespon\n from scrapy.contrib.spiders.init import InitSpider\n from scrapy.contrib.spiders import CrawlSpider, Rule, XMLFeedSpider, \\\n     CSVFeedSpider, SitemapSpider\n-from scrapy.contrib.linkextractors.sgml import SgmlLinkExtractor\n+from scrapy.contrib.linkextractors import LinkExtractor\n from scrapy.exceptions import ScrapyDeprecationWarning\n \n \n@@ -124,7 +124,7 @@ class CrawlSpiderTest(SpiderTest):\n             name=\"test\"\n             allowed_domains=['example.org']\n             rules = (\n-                Rule(SgmlLinkExtractor(), process_links=\"dummy_process_links\"),\n+                Rule(LinkExtractor(), process_links=\"dummy_process_links\"),\n             )\n \n             def dummy_process_links(self, links):\n@@ -150,7 +150,7 @@ class CrawlSpiderTest(SpiderTest):\n             name=\"test\"\n             allowed_domains=['example.org']\n             rules = (\n-                Rule(SgmlLinkExtractor(), process_links=\"filter_process_links\"),\n+                Rule(LinkExtractor(), process_links=\"filter_process_links\"),\n             )\n             _test_regex = re.compile('nofollow')\n             def filter_process_links(self, links):\n@@ -174,7 +174,7 @@ class CrawlSpiderTest(SpiderTest):\n             name=\"test\"\n             allowed_domains=['example.org']\n             rules = (\n-                Rule(SgmlLinkExtractor(), process_links=\"dummy_process_links\"),\n+                Rule(LinkExtractor(), process_links=\"dummy_process_links\"),\n             )\n \n             def dummy_process_links(self, links):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#53057728fb0283df927217a31202d719881792bd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 11 | Churn Cumulative: 144 | Contributors (this commit): 3 | Commits (past 90d): 1 | Contributors (cumulative): 3 | DMM Complexity: 0.0\n\nDIFF:\n@@ -34,8 +34,6 @@ class LxmlParserLinkExtractor(object):\n         self.process_attr = process if callable(process) else lambda v: v\n         self.unique = unique\n \n-        self.links = []\n-\n     def _iter_links(self, document):\n         for el in document.iter(etree.Element):\n             tag = _nons(el.tag)\n@@ -46,6 +44,7 @@ class LxmlParserLinkExtractor(object):\n                 yield (el, attrib, attribs[attrib])\n \n     def _extract_links(self, selector, response_url, response_encoding, base_url):\n+        links = []\n         # hacky way to get the underlying lxml parsed document\n         for el, attr, attr_val in self._iter_links(selector._root):\n             if self.scan_tag(el.tag) and self.scan_attr(attr):\n@@ -60,12 +59,10 @@ class LxmlParserLinkExtractor(object):\n                 url = urljoin(response_url, url)\n                 link = Link(url, _collect_string_content(el) or u'',\n                     nofollow=True if el.get('rel') == 'nofollow' else False)\n-                self.links.append(link)\n+                links.append(link)\n \n-        links = unique_list(self.links, key=lambda link: link.url) \\\n-                if self.unique else self.links\n-\n-        return links\n+        return unique_list(links, key=lambda link: link.url) \\\n+                if self.unique else links\n \n     def extract_links(self, response):\n         html = Selector(response)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
