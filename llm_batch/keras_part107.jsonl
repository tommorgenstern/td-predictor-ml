{"custom_id": "keras#1deaf71388ef7e831411ccbd9ec77ab795b286a1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 14 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 15 | Churn Cumulative: 110 | Contributors (this commit): 3 | Commits (past 90d): 2 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -53,21 +53,8 @@ model.compile(loss='categorical_crossentropy',\n               metrics=['accuracy'])\n \n history = model.fit(X_train, Y_train,\n-                    batch_size=batch_size, nb_epoch=3,\n+                    batch_size=batch_size, nb_epoch=nb_epoch,\n                     verbose=1, validation_data=(X_test, Y_test))\n score = model.evaluate(X_test, Y_test, verbose=0)\n print('Test score:', score[0])\n print('Test accuracy:', score[1])\n-\n-model.save('tmp.h5')\n-\n-from keras.models import load_model\n-model = load_model('tmp.h5')\n-\n-score = model.evaluate(X_test, Y_test, verbose=0)\n-print('Test score:', score[0])\n-print('Test accuracy:', score[1])\n-\n-model.fit(X_train, Y_train,\n-            batch_size=batch_size, nb_epoch=3,\n-            verbose=1, validation_data=(X_test, Y_test))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5367a44acb16cc496eb784d7a0518d70a94f221c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 4 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 11 | Churn Cumulative: 322 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -28,6 +28,7 @@ https://drive.google.com/open?id=0B4ChsjFJvew3NWN5THdxcTdSWmc ('tf' dim ordering\n \n @author: BigMoyan, University of Electronic Science and Technology of China\n '''\n+from __future__ import print_function\n from keras.layers import merge\n from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D\n from keras.layers.core import Dense, Activation, Flatten\n@@ -70,7 +71,7 @@ def identity_block(input_tensor, kernel_size, filters, stage, block):\n     out = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(out)\n     out = Activation('relu')(out)\n \n-    out = out = Convolution2D(nb_filter2, kernel_size, kernel_size, border_mode='same',\n+    out = Convolution2D(nb_filter2, kernel_size, kernel_size, border_mode='same',\n                         dim_ordering=dim_ordering, name=conv_name_base + '2b')(out)\n     out = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(out)\n     out = Activation('relu')(out)\n@@ -210,10 +211,10 @@ if __name__ == '__main__':\n     lines = class_table.readlines()\n \n     test_img1 = read_img('cat.jpg')\n-    print 'result for test 1 is'\n-    print lines[np.argmax(resnet_model.predict(test_img1)[0])]\n+    print('Result for test 1 is:')\n+    print(lines[np.argmax(resnet_model.predict(test_img1)[0])])\n \n     test_img2 = read_img('elephant.jpg')\n-    print 'result for test 2 is'\n-    print lines[np.argmax(resnet_model.predict(test_img2)[0])]\n+    print('Result for test 2 is:')\n+    print(lines[np.argmax(resnet_model.predict(test_img2)[0])])\n     class_table.close()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#97d2a73dd36e90a3502c575a8ea93125e894c84a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 4495 | Contributors (this commit): 38 | Commits (past 90d): 56 | Contributors (cumulative): 57 | DMM Complexity: 1.0\n\nDIFF:\n@@ -649,7 +649,9 @@ def normalize_batch_in_training(x, gamma, beta,\n \n \n def batch_normalization(x, mean, std, beta, gamma, epsilon=0.0001):\n-    '''Apply batch normalization on x given mean, std, beta and gamma.\n+    '''Apply batch normalization on x given mean, std, beta and gamma:\n+\n+    output = (x - mean) / (sqrt(std) + epsilon) * gamma + beta\n     '''\n     return tf.nn.batch_normalization(x, mean, std, beta, gamma, epsilon)\n \n\n@@ -386,7 +386,8 @@ def normalize_batch_in_training(x, gamma, beta,\n def batch_normalization(x, mean, std, beta, gamma, epsilon=0.0001):\n     '''Apply batch normalization on x given mean, std, beta and gamma.\n     '''\n-    normed = T.nnet.bn.batch_normalization(x, gamma, beta, mean, std + epsilon,\n+    normed = T.nnet.bn.batch_normalization(x, gamma, beta, mean,\n+                                           sqrt(std) + epsilon,\n                                            mode='high_mem')\n     return normed\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#05883934f1b9a13e09a46ec6845927d9397f3540", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 16 | Files Changed: 2 | Hunks: 14 | Methods Changed: 6 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 32 | Churn Cumulative: 4527 | Contributors (this commit): 38 | Commits (past 90d): 57 | Contributors (cumulative): 57 | DMM Complexity: None\n\nDIFF:\n@@ -622,10 +622,10 @@ def normalize_batch_in_training(x, gamma, beta,\n                                 reduction_axes, epsilon=0.0001):\n     '''Compute mean and std for batch then apply batch_normalization on batch.\n     '''\n-    mean, std = tf.nn.moments(x, reduction_axes,\n+    mean, var = tf.nn.moments(x, reduction_axes,\n                               shift=None, name=None, keep_dims=False)\n     if sorted(reduction_axes) == range(ndim(x))[:-1]:\n-        normed = tf.nn.batch_normalization(x, mean, std,\n+        normed = tf.nn.batch_normalization(x, mean, var,\n                                            beta, gamma,\n                                            epsilon)\n     else:\n@@ -639,21 +639,21 @@ def normalize_batch_in_training(x, gamma, beta,\n         target_shape = tf.pack(target_shape)\n \n         broadcast_mean = tf.reshape(mean, target_shape)\n-        broadcast_std = tf.reshape(std, target_shape)\n+        broadcast_var = tf.reshape(var, target_shape)\n         broadcast_gamma = tf.reshape(gamma, target_shape)\n         broadcast_beta = tf.reshape(beta, target_shape)\n-        normed = tf.nn.batch_normalization(x, broadcast_mean, broadcast_std,\n+        normed = tf.nn.batch_normalization(x, broadcast_mean, broadcast_var,\n                                            broadcast_beta, broadcast_gamma,\n                                            epsilon)\n-    return normed, mean, std\n+    return normed, mean, var\n \n \n-def batch_normalization(x, mean, std, beta, gamma, epsilon=0.0001):\n-    '''Apply batch normalization on x given mean, std, beta and gamma:\n+def batch_normalization(x, mean, var, beta, gamma, epsilon=0.0001):\n+    '''Apply batch normalization on x given mean, var, beta and gamma:\n \n-    output = (x - mean) / (sqrt(std) + epsilon) * gamma + beta\n+    output = (x - mean) / (sqrt(var) + epsilon) * gamma + beta\n     '''\n-    return tf.nn.batch_normalization(x, mean, std, beta, gamma, epsilon)\n+    return tf.nn.batch_normalization(x, mean, var, beta, gamma, epsilon)\n \n \n # SHAPE OPERATIONS\n\n@@ -362,7 +362,7 @@ def normalize_batch_in_training(x, gamma, beta,\n                                 reduction_axes, epsilon=0.0001):\n     '''Compute mean and std for batch then apply batch_normalization on batch.\n     '''\n-    std = T.sqrt(x.var(reduction_axes) + epsilon)\n+    var = x.var(reduction_axes)\n     mean = x.mean(reduction_axes)\n \n     target_shape = []\n@@ -374,20 +374,20 @@ def normalize_batch_in_training(x, gamma, beta,\n     target_shape = T.stack(*target_shape)\n \n     broadcast_mean = T.reshape(mean, target_shape)\n-    broadcast_std = T.reshape(std, target_shape)\n+    broadcast_var = T.reshape(var, target_shape)\n     broadcast_beta = T.reshape(beta, target_shape)\n     broadcast_gamma = T.reshape(gamma, target_shape)\n-    normed = batch_normalization(x, broadcast_mean, broadcast_std,\n+    normed = batch_normalization(x, broadcast_mean, broadcast_var,\n                                  broadcast_beta, broadcast_gamma,\n                                  epsilon)\n-    return normed, mean, std\n+    return normed, mean, var\n \n \n-def batch_normalization(x, mean, std, beta, gamma, epsilon=0.0001):\n-    '''Apply batch normalization on x given mean, std, beta and gamma.\n+def batch_normalization(x, mean, var, beta, gamma, epsilon=0.0001):\n+    '''Apply batch normalization on x given mean, var, beta and gamma.\n     '''\n     normed = T.nnet.bn.batch_normalization(x, gamma, beta, mean,\n-                                           sqrt(std) + epsilon,\n+                                           sqrt(var) + epsilon,\n                                            mode='high_mem')\n     return normed\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#046a3c8a285be1c4b695aa3ea57cf7f8a9922024", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 781 | Contributors (this commit): 13 | Commits (past 90d): 2 | Contributors (cumulative): 13 | DMM Complexity: None\n\nDIFF:\n@@ -112,7 +112,7 @@ class ELU(Layer):\n         return pos + self.alpha * (K.exp(neg) - 1.)\n \n     def get_config(self):\n-        config = {'alpha': self.alpha}\n+        config = {'alpha': float(self.alpha)}\n         base_config = super(ELU, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n \n@@ -161,8 +161,8 @@ class ParametricSoftplus(Layer):\n         return K.softplus(self.betas * x) * self.alphas\n \n     def get_config(self):\n-        config = {'alpha_init': self.alpha_init,\n-                  'beta_init': self.beta_init}\n+        config = {'alpha_init': float(self.alpha_init),\n+                  'beta_init': float(self.beta_init)}\n         base_config = super(ParametricSoftplus, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n \n@@ -195,7 +195,7 @@ class ThresholdedReLU(Layer):\n         return x * K.cast(x > self.theta, K.floatx())\n \n     def get_config(self):\n-        config = {'theta': self.theta}\n+        config = {'theta': float(self.theta)}\n         base_config = super(ThresholdedReLU, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f9c03f183fdf45fb684b35114d4b66fa0f29359e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 31 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 7 | Methods Changed: 9 | Complexity Δ (Sum/Max): 6/6 | Churn Δ: 36 | Churn Cumulative: 3157 | Contributors (this commit): 19 | Commits (past 90d): 30 | Contributors (cumulative): 19 | DMM Complexity: 0.8888888888888888\n\nDIFF:\n@@ -323,6 +323,30 @@ class Layer(object):\n             if 'create_input_layer' in kwargs:\n                 self.create_input_layer(batch_input_shape, input_dtype)\n \n+    @property\n+    def trainable_weights(self):\n+        trainable = getattr(self, 'trainable', True)\n+        if trainable:\n+            return self._trainable_weights\n+        else:\n+            return []\n+\n+    @trainable_weights.setter\n+    def trainable_weights(self, weights):\n+        self._trainable_weights = weights\n+\n+    @property\n+    def non_trainable_weights(self):\n+        trainable = getattr(self, 'trainable', True)\n+        if not trainable:\n+            return self._trainable_weights + self._non_trainable_weights\n+        else:\n+            return self._non_trainable_weights\n+\n+    @non_trainable_weights.setter\n+    def non_trainable_weights(self, weights):\n+        self._non_trainable_weights = weights\n+\n     def create_input_layer(self, batch_input_shape,\n                            input_dtype=None, name=None):\n         if not name:\n@@ -844,7 +868,7 @@ class Layer(object):\n                 of the layer (i.e. it should match the\n                 output of `get_weights`).\n         '''\n-        params = self.trainable_weights + self.non_trainable_weights\n+        params = self.weights\n         if len(params) != len(weights):\n             raise Exception('You called `set_weights(weights)` on layer \"' + self.name +\n                             '\" with a  weight list of length ' + str(len(weights)) +\n@@ -867,7 +891,7 @@ class Layer(object):\n         '''Returns the current weights of the layer,\n         as a list of numpy arrays.\n         '''\n-        params = self.trainable_weights + self.non_trainable_weights\n+        params = self.weights\n         return K.batch_get_value(params)\n \n     def get_config(self):\n@@ -926,6 +950,8 @@ class InputLayer(Layer):\n         self.uses_learning_phase = False\n         self.trainable = False\n         self.built = True\n+        self.trainable_weights = []\n+        self.non_trainable_weights = []\n \n         self.inbound_nodes = []\n         self.outbound_nodes = []\n@@ -2391,7 +2417,7 @@ class Container(Layer):\n \n         for layer in flattened_layers:\n             g = f.create_group(layer.name)\n-            symbolic_weights = layer.trainable_weights + layer.non_trainable_weights\n+            symbolic_weights = layer.weights\n             weight_values = K.batch_get_value(symbolic_weights)\n             weight_names = []\n             for i, (w, val) in enumerate(zip(symbolic_weights, weight_values)):\n@@ -2451,7 +2477,7 @@ class Container(Layer):\n             # new file format\n             filtered_layers = []\n             for layer in flattened_layers:\n-                weights = layer.trainable_weights + layer.non_trainable_weights\n+                weights = layer.weights\n                 if weights:\n                     filtered_layers.append(layer)\n             flattened_layers = filtered_layers\n@@ -2478,7 +2504,7 @@ class Container(Layer):\n                 weight_names = [n.decode('utf8') for n in g.attrs['weight_names']]\n                 weight_values = [g[weight_name] for weight_name in weight_names]\n                 layer = flattened_layers[k]\n-                symbolic_weights = layer.trainable_weights + layer.non_trainable_weights\n+                symbolic_weights = layer.weights\n                 if len(weight_values) != len(symbolic_weights):\n                     raise Exception('Layer #' + str(k) +\n                                     ' (named \"' + layer.name +\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ad3231c29a30d766dc4e56c64d81c25ca982cc86", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 3161 | Contributors (this commit): 20 | Commits (past 90d): 31 | Contributors (cumulative): 20 | DMM Complexity: None\n\nDIFF:\n@@ -1116,7 +1116,7 @@ class Merge(Layer):\n             If lambda/function, it should take as input a list of tensors\n             and return a single tensor.\n         concat_axis: integer, axis to use in mode `concat`.\n-        dot_axes: integer or tuple of integers, axes to use in mode `dot`.\n+        dot_axes: integer or tuple of integers, axes to use in mode `dot` or `cos`.\n         output_shape: either a shape tuple (tuple of integers), or a lambda/function\n             to compute `output_shape` (only if merge mode is a lambda/function).\n             If the argument is a tuple,\n@@ -1492,7 +1492,7 @@ def merge(inputs, mode='sum', concat_axis=-1,\n             If lambda/function, it should take as input a list of tensors\n             and return a single tensor.\n         concat_axis: integer, axis to use in mode `concat`.\n-        dot_axes: integer or tuple of integers, axes to use in mode `dot`.\n+        dot_axes: integer or tuple of integers, axes to use in mode `dot` or `cos`.\n         output_shape: shape tuple (tuple of integers), or lambda/function\n             to compute output_shape (only if merge mode is a lambda/function).\n             If the latter case, it should take as input a list of shape tuples\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#984ad34a61b5415ddb2fa25c8baebadc4f7c1535", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 30 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 5/2 | Churn Δ: 30 | Churn Cumulative: 5311 | Contributors (this commit): 39 | Commits (past 90d): 68 | Contributors (cumulative): 71 | DMM Complexity: 1.0\n\nDIFF:\n@@ -840,6 +840,13 @@ def spatial_3d_padding(x, padding=(1, 1, 1), dim_ordering='th'):\n def pack(x):\n     return tf.pack(x)\n \n+def one_hot(indices, nb_classes):\n+    '''\n+    Input: nD integer tensor of shape (batch_size, dim1, dim2, ... dim(n-1))\n+    Output: (n + 1)D one hot representation of the input with shape (batch_size, dim1, dim2, ... dim(n-1), nb_classes)\n+    '''\n+    return tf.one_hot(indices, depth=nb_classes, axis=-1)\n+\n \n # VALUE MANIPULATION\n \n\n@@ -595,6 +595,19 @@ def spatial_3d_padding(x, padding=(1, 1, 1), dim_ordering='th'):\n def pack(x):\n     return T.stack(*x)\n \n+\n+def one_hot(indices, nb_classes):\n+    '''\n+    Input: nD integer tensor of shape (batch_size, dim1, dim2, ... dim(n-1))\n+    Output: (n + 1)D one hot representation of the input with shape (batch_size, dim1, dim2, ... dim(n-1), nb_classes)\n+    '''\n+    input_shape = tuple((indices.shape[i] for i in range(indices.ndim)))\n+    indices = T.flatten(indices)\n+    oh = T.extra_ops.to_one_hot(indices, nb_classes)\n+    oh = T.reshape(oh, input_shape + (nb_classes,))\n+    return oh\n+\n+\n # VALUE MANIPULATION\n \n \n\n@@ -580,6 +580,16 @@ class TestBackend(object):\n         assert(np.max(rand) == 1)\n         assert(np.min(rand) == 0)\n \n+    def test_one_hot(self):\n+        input_length = 10\n+        nb_classes = 20\n+        batch_size = 30\n+        indices = np.random.randint(0, nb_classes, size=(batch_size, input_length))\n+        oh = np.eye(nb_classes)[indices]\n+        for K in [KTH, KTF]:\n+            koh = K.eval(K.one_hot(K.variable(indices, dtype='int32'), nb_classes))\n+            assert np.all(koh == oh)\n+\n \n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#84f435e24b18352d6c9efa098061d316d5be516e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 4 | Churn Cumulative: 1216 | Contributors (this commit): 15 | Commits (past 90d): 11 | Contributors (cumulative): 15 | DMM Complexity: 0.0\n\nDIFF:\n@@ -126,7 +126,9 @@ def array_to_img(x, dim_ordering='default', scale=True):\n         x = x.transpose(1, 2, 0)\n     if scale:\n         x += max(-np.min(x), 0)\n-        x /= np.max(x)\n+        x_max = np.max(x)\n+        if x_max != 0:\n+            x /= x_max\n         x *= 255\n     if x.shape[2] == 3:\n         # RGB\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b508ab64bd1a3d4e9942728300f88f4721f2485f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 1632 | Contributors (this commit): 24 | Commits (past 90d): 12 | Contributors (cumulative): 24 | DMM Complexity: None\n\nDIFF:\n@@ -231,12 +231,12 @@ class ModelCheckpoint(Callback):\n         verbose: verbosity mode, 0 or 1.\n         save_best_only: if `save_best_only=True`,\n             the latest best model according to\n-            the validation loss will not be overwritten.\n+            the quantity monitored will not be overwritten.\n         mode: one of {auto, min, max}.\n             If `save_best_only=True`, the decision\n             to overwrite the current save file is made\n             based on either the maximization or the\n-            minization of the monitored. For `val_acc`,\n+            minimization of the monitored quantity. For `val_acc`,\n             this should be `max`, for `val_loss` this should\n             be `min`, etc. In `auto` mode, the direction is\n             automatically inferred from the name of the monitored quantity.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1b08a8d67520a0472c769a50b0dffb689d510e62", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 1421 | Contributors (this commit): 15 | Commits (past 90d): 8 | Contributors (cumulative): 15 | DMM Complexity: None\n\nDIFF:\n@@ -453,9 +453,8 @@ class Nadam(Optimizer):\n         epsilon: float >= 0. Fuzz factor.\n \n     # References\n-        [1] Nadam report - http://cs229.stanford.edu/proj2015/054_report.pdf\n-        [2] On the importance of initialization and momentum in deep learning -\n-            http://www.cs.toronto.edu/~fritz/absps/momentum.pdf\n+        - [Nadam report](http://cs229.stanford.edu/proj2015/054_report.pdf)\n+        - [On the importance of initialization and momentum in deep learning](http://www.cs.toronto.edu/~fritz/absps/momentum.pdf)\n     '''\n     def __init__(self, lr=0.002, beta_1=0.9, beta_2=0.999,\n                  epsilon=1e-8, schedule_decay=0.004, **kwargs):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#98b289630adf400399d520826ba48668a3db9e99", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 148 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -22,6 +22,7 @@ from keras.utils.np_utils import to_categorical\n from keras.layers import Dense, Input, Flatten\n from keras.layers import Conv1D, MaxPooling1D, Embedding\n from keras.models import Model\n+import sys\n \n BASE_DIR = ''\n GLOVE_DIR = BASE_DIR + '/glove.6B/'\n@@ -61,7 +62,10 @@ for name in sorted(os.listdir(TEXT_DATA_DIR)):\n         for fname in sorted(os.listdir(path)):\n             if fname.isdigit():\n                 fpath = os.path.join(path, fname)\n+                if sys.version_info < (3,):\n                     f = open(fpath)\n+                else:\n+                    f = open(fpath, encoding='latin-1')\n                 texts.append(f.read())\n                 f.close()\n                 labels.append(label_id)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b6f81c6cc3018553adbdae8e86a09825ac5b9b33", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 420 | Contributors (this commit): 2 | Commits (past 90d): 4 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -61,8 +61,9 @@ class MaxPooling1D(_Pooling1D):\n         3D tensor with shape: `(samples, downsampled_steps, features)`.\n \n     # Arguments\n-        pool_length: factor by which to downscale. 2 will halve the input.\n-        stride: integer, or None. Stride value.\n+        pool_length: size of the region to which max pooling is applied\n+        stride: integer, or None. factor by which to downscale.\n+            2 will halve the input.\n             If None, it will default to `pool_length`.\n         border_mode: 'valid' or 'same'.\n             Note: 'same' will only work with TensorFlow for the time being.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b2c66816d7c5dc39e4fc434b3102f57723ff0329", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 221 | Contributors (this commit): 8 | Commits (past 90d): 10 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -15,4 +15,4 @@ from . import objectives\n from . import optimizers\r\n from . import regularizers\r\n \r\n-__version__ = '1.0.6'\r\n+__version__ = '1.0.7'\r\n\n@@ -3,12 +3,12 @@ from setuptools import find_packages\n \n \n setup(name='Keras',\n-      version='1.0.6',\n+      version='1.0.7',\n       description='Deep Learning for Python',\n       author='Francois Chollet',\n       author_email='francois.chollet@gmail.com',\n       url='https://github.com/fchollet/keras',\n-      download_url='https://github.com/fchollet/keras/tarball/1.0.6',\n+      download_url='https://github.com/fchollet/keras/tarball/1.0.7',\n       license='MIT',\n       install_requires=['theano', 'pyyaml', 'six'],\n       extras_require={\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0af7e004c79d0d7ef2fc01105909fb4109b37b40", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 25 | Lines Deleted: 18 | Files Changed: 3 | Hunks: 16 | Methods Changed: 11 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 43 | Churn Cumulative: 4709 | Contributors (this commit): 39 | Commits (past 90d): 64 | Contributors (cumulative): 60 | DMM Complexity: 1.0\n\nDIFF:\n@@ -241,17 +241,27 @@ def ones_like(x, name=None):\n     return tf.ones_like(x, name=name)\n \n \n-def random_uniform_variable(shape, low, high, dtype=_FLOATX, name=None):\n+def random_uniform_variable(shape, low, high, dtype=_FLOATX,\n+                            name=None, seed=None):\n     shape = tuple(map(int, shape))\n     tf_dtype = _convert_string_dtype(dtype)\n-    value = tf.random_uniform_initializer(low, high, dtype=tf_dtype)(shape)\n+    if seed is None:\n+        # ensure that randomness is conditioned by the Numpy RNG\n+        seed = np.random.randint(10e8)\n+    value = tf.random_uniform_initializer(\n+        low, high, dtype=tf_dtype, seed=seed)(shape)\n     return variable(value, dtype=dtype, name=name)\n \n \n-def random_normal_variable(shape, mean, scale, dtype=_FLOATX, name=None):\n+def random_normal_variable(shape, mean, scale, dtype=_FLOATX,\n+                           name=None, seed=None):\n     shape = tuple(map(int, shape))\n     tf_dtype = _convert_string_dtype(dtype)\n-    value = tf.random_normal_initializer(mean, scale, dtype=tf_dtype)(shape)\n+    if seed is None:\n+        # ensure that randomness is conditioned by the Numpy RNG\n+        seed = np.random.randint(10e8)\n+    value = tf.random_normal_initializer(\n+        mean, scale, dtype=tf_dtype, seed=seed)(shape)\n     return variable(value, dtype=dtype, name=name)\n \n \n@@ -840,10 +850,11 @@ def spatial_3d_padding(x, padding=(1, 1, 1), dim_ordering='th'):\n def pack(x):\n     return tf.pack(x)\n \n+\n def one_hot(indices, nb_classes):\n-    '''\n-    Input: nD integer tensor of shape (batch_size, dim1, dim2, ... dim(n-1))\n-    Output: (n + 1)D one hot representation of the input with shape (batch_size, dim1, dim2, ... dim(n-1), nb_classes)\n+    '''Input: nD integer tensor of shape (batch_size, dim1, dim2, ... dim(n-1))\n+    Output: (n + 1)D one hot representation of the input\n+    with shape (batch_size, dim1, dim2, ... dim(n-1), nb_classes)\n     '''\n     return tf.one_hot(indices, depth=nb_classes, axis=-1)\n \n\n@@ -597,9 +597,9 @@ def pack(x):\n \n \n def one_hot(indices, nb_classes):\n-    '''\n-    Input: nD integer tensor of shape (batch_size, dim1, dim2, ... dim(n-1))\n-    Output: (n + 1)D one hot representation of the input with shape (batch_size, dim1, dim2, ... dim(n-1), nb_classes)\n+    '''Input: nD integer tensor of shape (batch_size, dim1, dim2, ... dim(n-1))\n+    Output: (n + 1)D one hot representation of the input\n+    with shape (batch_size, dim1, dim2, ... dim(n-1), nb_classes)\n     '''\n     input_shape = tuple((indices.shape[i] for i in range(indices.ndim)))\n     indices = T.flatten(indices)\n\n@@ -1,5 +1,6 @@\n from __future__ import print_function\n import numpy as np\n+np.random.seed(1337)\n import pytest\n import string\n \n@@ -22,7 +23,6 @@ def test_temporal_classification():\n     single layer of GRU units and softmax applied\n     to the last activations of the units\n     '''\n-    np.random.seed(1337)\n     (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=500,\n                                                          nb_test=500,\n                                                          input_shape=(3, 5),\n@@ -41,7 +41,7 @@ def test_temporal_classification():\n     history = model.fit(X_train, y_train, nb_epoch=20, batch_size=32,\n                         validation_data=(X_test, y_test),\n                         verbose=0)\n-    assert(history.history['val_acc'][-1] >= 0.85)\n+    assert(history.history['val_acc'][-1] >= 0.8)\n \n \n @keras_test\n@@ -50,9 +50,8 @@ def test_temporal_regression():\n     Predict float numbers (regression) based on sequences\n     of float numbers of length 3 using a single layer of GRU units\n     '''\n-    np.random.seed(1337)\n     (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=500,\n-                                                         nb_test=200,\n+                                                         nb_test=400,\n                                                          input_shape=(3, 5),\n                                                          output_shape=(2,),\n                                                          classification=False)\n@@ -62,7 +61,7 @@ def test_temporal_regression():\n     model.compile(loss='hinge', optimizer='adam')\n     history = model.fit(X_train, y_train, nb_epoch=5, batch_size=16,\n                         validation_data=(X_test, y_test), verbose=0)\n-    assert(history.history['val_loss'][-1] < 0.75)\n+    assert(history.history['val_loss'][-1] < 0.8)\n \n \n @keras_test\n@@ -73,7 +72,6 @@ def test_sequence_to_sequence():\n     This does not make use of the temporal structure of the sequence\n     (see TimeDistributedDense for more details)\n     '''\n-    np.random.seed(1337)\n     (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=500,\n                                                          nb_test=200,\n                                                          input_shape=(3, 5),\n@@ -96,7 +94,6 @@ def test_stacked_lstm_char_prediction():\n     Predict the whole alphabet based on the first two letters ('ab' -> 'ab...z')\n     See non-toy example in examples/lstm_text_generation.py\n     '''\n-    np.random.seed(1336)\n     # generate alphabet: http://stackoverflow.com/questions/16060899/alphabet-range-python\n     alphabet = string.ascii_lowercase\n     number_of_chars = len(alphabet)\n@@ -152,7 +149,6 @@ def test_masked_temporal():\n     The ground-truth best cross-entropy loss should, then be -log(0.5) = 0.69\n \n     '''\n-    np.random.seed(55318)\n     model = Sequential()\n     model.add(Embedding(10, 20, mask_zero=True, input_length=20))\n     model.add(TimeDistributedDense(10))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e3c260e7d38e65eadd348337d206a66f82ae8029", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 133 | Contributors (this commit): 3 | Commits (past 90d): 4 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -61,7 +61,7 @@ def test_temporal_regression():\n     model.compile(loss='hinge', optimizer='adam')\n     history = model.fit(X_train, y_train, nb_epoch=5, batch_size=16,\n                         validation_data=(X_test, y_test), verbose=0)\n-    assert(history.history['val_loss'][-1] < 0.8)\n+    assert(history.history['val_loss'][-1] < 1.)\n \n \n @keras_test\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bc779df8b7b0745eedaaaca281728bbcea118e08", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 15 | Churn Cumulative: 2424 | Contributors (this commit): 27 | Commits (past 90d): 41 | Contributors (cumulative): 27 | DMM Complexity: 1.0\n\nDIFF:\n@@ -885,8 +885,14 @@ def set_value(x, value):\n     '''\n     value = np.asarray(value)\n     tf_dtype = _convert_string_dtype(x.dtype.name.split('_')[0])\n+    if hasattr(x, '_assign_placeholder'):\n+        assign_placeholder = x._assign_placeholder\n+        assign_op = x._assign_op\n+    else:\n         assign_placeholder = tf.placeholder(tf_dtype, shape=value.shape)\n         assign_op = x.assign(assign_placeholder)\n+        x._assign_placeholder = assign_placeholder\n+        x._assign_op = assign_op\n     get_session().run(assign_op, feed_dict={assign_placeholder: value})\n \n \n@@ -903,8 +909,15 @@ def batch_set_value(tuples):\n         for x, value in tuples:\n             value = np.asarray(value)\n             tf_dtype = _convert_string_dtype(x.dtype.name.split('_')[0])\n+            if hasattr(x, '_assign_placeholder'):\n+                assign_placeholder = x._assign_placeholder\n+                assign_op = x._assign_op\n+            else:\n                 assign_placeholder = tf.placeholder(tf_dtype, shape=value.shape)\n-            assign_ops.append(x.assign(assign_placeholder))\n+                assign_op = x.assign(assign_placeholder)\n+                x._assign_placeholder = assign_placeholder\n+                x._assign_op = assign_op\n+            assign_ops.append(assign_op)\n             feed_dict[assign_placeholder] = value\n         get_session().run(assign_ops, feed_dict=feed_dict)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#89f1e051472cd6fd5d0c5d002ca353b50524a0db", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 24 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 5/5 | Churn Δ: 24 | Churn Cumulative: 3185 | Contributors (this commit): 20 | Commits (past 90d): 31 | Contributors (cumulative): 20 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1965,6 +1965,30 @@ class Container(Layer):\n             weights += layer.non_trainable_weights\n         return weights\n \n+    def get_weights(self):\n+        '''Returns the weights of the model,\n+        as a flat list of Numpy arrays.\n+        '''\n+        weights = []\n+        for layer in self.layers:\n+            weights += layer.weights\n+        return K.batch_get_value(weights)\n+\n+    def set_weights(self, weights):\n+        '''Sets the weights of the model.\n+        The `weights` argument should be a list\n+        of Numpy arrays with shapes and types matching\n+        the output of `model.get_weights()`.\n+        '''\n+        tuples = []\n+        for layer in self.layers:\n+            nb_param = len(layer.weights)\n+            layer_weights = weights[:nb_param]\n+            for sw, w in zip(layer.weights, layer_weights):\n+                tuples.append((sw, w))\n+            weights = weights[nb_param:]\n+        K.batch_set_value(tuples)\n+\n     @property\n     def input_spec(self):\n         specs = []\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#69d5139b8ccc860cd3ed8b63be83a104ceeedafb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 21 | Lines Deleted: 1 | Files Changed: 3 | Hunks: 7 | Methods Changed: 3 | Complexity Δ (Sum/Max): 4/2 | Churn Δ: 22 | Churn Cumulative: 3422 | Contributors (this commit): 26 | Commits (past 90d): 41 | Contributors (cumulative): 32 | DMM Complexity: 0.5\n\nDIFF:\n@@ -12,6 +12,8 @@ from .common import cast_to_floatx\n from .common import image_dim_ordering\n from .common import set_image_dim_ordering\n from .common import is_keras_tensor\n+from .common import legacy_weight_ordering\n+from .common import set_legacy_weight_ordering\n \n _keras_base_dir = os.path.expanduser('~')\n if not os.access(_keras_base_dir, os.W_OK):\n\n@@ -7,6 +7,7 @@ _FLOATX = 'float32'\n _EPSILON = 10e-8\n _UID_PREFIXES = defaultdict(int)\n _IMAGE_DIM_ORDERING = 'th'\n+_LEGACY_WEIGHT_ORDERING = False\n \n \n def epsilon():\n@@ -76,3 +77,13 @@ def is_keras_tensor(x):\n         return True\n     else:\n         return False\n+\n+\n+def set_legacy_weight_ordering(value):\n+    global _LEGACY_WEIGHT_ORDERING\n+    assert value in {True, False}\n+    _LEGACY_WEIGHT_ORDERING = value\n+\n+\n+def legacy_weight_ordering():\n+    return _LEGACY_WEIGHT_ORDERING\n\n@@ -1713,6 +1713,7 @@ class Container(Layer):\n         container_nodes = set()  # ids of all nodes relevant to the Container\n         nodes_depths = {}  # map {node: depth value}\n         layers_depths = {}  # map {layer: depth value}\n+        layer_indices = {}  # map {layer: index in traversal}\n \n         def make_node_marker(node, depth):\n             return str(id(node)) + '-' + str(depth)\n@@ -1756,6 +1757,8 @@ class Container(Layer):\n             else:\n                 current_depth = max(depth, previously_seen_depth)\n             layers_depths[layer] = current_depth\n+            if layer not in layer_indices:\n+                layer_indices[layer] = len(layer_indices)\n \n             # propagate to all previous tensors connected to this node\n             for i in range(len(node.inbound_layers)):\n@@ -1796,8 +1799,12 @@ class Container(Layer):\n         layers = []\n         for depth in depth_keys:\n             layers_for_depth = layers_by_depth[depth]\n-            # container.layers needs to have a deterministic order\n+            # container.layers needs to have a deterministic order:\n+            # here we order them by traversal order\n+            if K.legacy_weight_ordering():\n                 layers_for_depth.sort(key=lambda x: x.name)\n+            else:\n+                layers_for_depth.sort(key=lambda x: layer_indices[x])\n             for layer in layers_for_depth:\n                 layers.append(layer)\n         self.layers = layers\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#55447cbb3d33c2c209fdad8a1d53a166bc39544e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 8 | Churn Cumulative: 2177 | Contributors (this commit): 30 | Commits (past 90d): 22 | Contributors (cumulative): 30 | DMM Complexity: 0.0\n\nDIFF:\n@@ -504,11 +504,9 @@ def expand_dims(x, dim=-1):\n def squeeze(x, axis):\n     '''Remove a 1-dimension from the tensor at index \"axis\".\n     '''\n-    broadcastable = x.broadcastable[:axis] + x.broadcastable[axis+1:]\n-    x = T.patternbroadcast(x, [i == axis for i in range(x.type.ndim)])\n-    x = T.squeeze(x)\n-    x = T.patternbroadcast(x, broadcastable)\n-    return x\n+    shape = list(x.shape)\n+    shape.pop(axis)\n+    return T.reshape(x, tuple(shape))\n \n \n def temporal_padding(x, padding=1):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4805e5856ba3f00d5953ee54a16abc7c4e96cc77", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 22 | Lines Deleted: 11 | Files Changed: 1 | Hunks: 9 | Methods Changed: 1 | Complexity Δ (Sum/Max): 11/11 | Churn Δ: 33 | Churn Cumulative: 4517 | Contributors (this commit): 22 | Commits (past 90d): 12 | Contributors (cumulative): 22 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1045,7 +1045,8 @@ class UpSampling1D(Layer):\n         super(UpSampling1D, self).__init__(**kwargs)\n \n     def get_output_shape_for(self, input_shape):\n-        return (input_shape[0], self.length * input_shape[1], input_shape[2])\n+        length = self.length * input_shape[1] if input_shape[1] is not None else None\n+        return (input_shape[0], length, input_shape[2])\n \n     def call(self, x, mask=None):\n         output = K.repeat_elements(x, self.length, axis=1)\n@@ -1094,14 +1095,18 @@ class UpSampling2D(Layer):\n \n     def get_output_shape_for(self, input_shape):\n         if self.dim_ordering == 'th':\n+            width = self.size[0] * input_shape[2] if input_shape[2] is not None else None\n+            height = self.size[1] * input_shape[3] if input_shape[3] is not None else None\n             return (input_shape[0],\n                     input_shape[1],\n-                    self.size[0] * input_shape[2],\n-                    self.size[1] * input_shape[3])\n+                    width,\n+                    height)\n         elif self.dim_ordering == 'tf':\n+            width = self.size[0] * input_shape[1] if input_shape[1] is not None else None\n+            height = self.size[1] * input_shape[2] if input_shape[2] is not None else None\n             return (input_shape[0],\n-                    self.size[0] * input_shape[1],\n-                    self.size[1] * input_shape[2],\n+                    width,\n+                    height,\n                     input_shape[3])\n         else:\n             raise Exception('Invalid dim_ordering: ' + self.dim_ordering)\n@@ -1153,16 +1158,22 @@ class UpSampling3D(Layer):\n \n     def get_output_shape_for(self, input_shape):\n         if self.dim_ordering == 'th':\n+            dim1 = self.size[0] * input_shape[2] if input_shape[2] is not None else None\n+            dim2 = self.size[1] * input_shape[3] if input_shape[3] is not None else None\n+            dim3 = self.size[2] * input_shape[4] if input_shape[4] is not None else None\n             return (input_shape[0],\n                     input_shape[1],\n-                    self.size[0] * input_shape[2],\n-                    self.size[1] * input_shape[3],\n-                    self.size[2] * input_shape[4])\n+                    dim1,\n+                    dim2,\n+                    dim3)\n         elif self.dim_ordering == 'tf':\n+            dim1 = self.size[0] * input_shape[1] if input_shape[1] is not None else None\n+            dim2 = self.size[1] * input_shape[2] if input_shape[2] is not None else None\n+            dim3 = self.size[2] * input_shape[3] if input_shape[3] is not None else None\n             return (input_shape[0],\n-                    self.size[0] * input_shape[1],\n-                    self.size[1] * input_shape[2],\n-                    self.size[2] * input_shape[3],\n+                    dim1,\n+                    dim2,\n+                    dim3,\n                     input_shape[4])\n         else:\n             raise Exception('Invalid dim_ordering: ' + self.dim_ordering)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ec6eda77ad77de28cda603889110428cd63f69ce", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 765 | Contributors (this commit): 14 | Commits (past 90d): 10 | Contributors (cumulative): 14 | DMM Complexity: 1.0\n\nDIFF:\n@@ -92,6 +92,7 @@ class TestBackend(object):\n         check_single_tensor_operation('expand_dims', (4, 3), dim=-1)\n         check_single_tensor_operation('expand_dims', (4, 3, 2), dim=1)\n         check_single_tensor_operation('squeeze', (4, 3, 1), axis=2)\n+        check_single_tensor_operation('squeeze', (4, 1, 1), axis=1)\n         check_composed_tensor_operations('reshape', {'shape': (4, 3, 1, 1)},\n                                          'squeeze', {'axis': 2},\n                                          (4, 3, 1, 1))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#46d5b197e022815c2074fbc94ca324d31d470dd0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 69 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 69 | Churn Cumulative: 69 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -0,0 +1,69 @@\n+'''This example demonstrates the use of fasttext for text classification\n+\n+Based on Joulin et al's paper:\n+\n+Bags of Tricks for Efficient Text Classification\n+https://arxiv.org/abs/1607.01759\n+\n+Can achieve accuracy around 88% after 5 epochs in 70s.\n+\n+'''\n+\n+from __future__ import print_function\n+import numpy as np\n+np.random.seed(1337)  # for reproducibility\n+\n+from keras.preprocessing import sequence\n+from keras.models import Sequential\n+from keras.layers import Dense, Activation, Flatten\n+from keras.layers import Embedding\n+from keras.layers import AveragePooling1D\n+from keras.datasets import imdb\n+from keras import backend as K\n+\n+\n+# set parameters:\n+max_features = 20000\n+maxlen = 400\n+batch_size = 32\n+embedding_dims = 20\n+nb_epoch = 5\n+\n+print('Loading data...')\n+(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features)\n+print(len(X_train), 'train sequences')\n+print(len(X_test), 'test sequences')\n+\n+print('Pad sequences (samples x time)')\n+X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n+X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n+print('X_train shape:', X_train.shape)\n+print('X_test shape:', X_test.shape)\n+\n+print('Build model...')\n+model = Sequential()\n+\n+# we start off with an efficient embedding layer which maps\n+# our vocab indices into embedding_dims dimensions\n+model.add(Embedding(max_features,\n+                    embedding_dims,\n+                    input_length=maxlen))\n+\n+# we add a AveragePooling1D, which will average the embeddings\n+# of all words in the document\n+model.add(AveragePooling1D(pool_length=model.output_shape[1]))\n+\n+# We flatten the output of the AveragePooling1D layer\n+model.add(Flatten())\n+\n+# We project onto a single unit output layer, and squash it with a sigmoid:\n+model.add(Dense(1, activation = 'sigmoid'))\n+\n+model.compile(loss='binary_crossentropy',\n+              optimizer='adam',\n+              metrics=['accuracy'])\n+\n+model.fit(X_train, y_train,\n+          batch_size=batch_size,\n+          nb_epoch=nb_epoch,\n+          validation_data=(X_test, y_test))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
