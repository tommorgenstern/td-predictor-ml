{"custom_id": "keras#60927c5d5235422bf674ef2a9b94db58d02e5858", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 267 | Lines Deleted: 199 | Files Changed: 3 | Hunks: 129 | Methods Changed: 27 | Complexity Δ (Sum/Max): 5/5 | Churn Δ: 466 | Churn Cumulative: 1982 | Contributors (this commit): 3 | Commits (past 90d): 8 | Contributors (cumulative): 6 | DMM Complexity: 0.9482758620689655\n\nDIFF:\n@@ -62,10 +62,10 @@ ARG_TO_MODEL = {\n                       efficientnet.EfficientNetB4, efficientnet.EfficientNetB5,\n                       efficientnet.EfficientNetB6, efficientnet.EfficientNetB7]),\n     'efficientnet_v2': (efficientnet_v2,\n-                        [efficientnet_v2.EfficientNetV2_B0, efficientnet_v2.EfficientNetV2_B1,\n-                        efficientnet_v2.EfficientNetV2_B2, efficientnet_v2.EfficientNetV2_B3,\n-                        efficientnet_v2.EfficientNetV2_S, efficientnet_v2.EfficientNetV2_M,\n-                        efficientnet_v2.EfficientNetV2_L])\n+                        [efficientnet_v2.EfficientNetV2B0, efficientnet_v2.EfficientNetV2B1,\n+                         efficientnet_v2.EfficientNetV2B2, efficientnet_v2.EfficientNetV2B3,\n+                         efficientnet_v2.EfficientNetV2S, efficientnet_v2.EfficientNetV2M,\n+                         efficientnet_v2.EfficientNetV2L])\n }\n \n TEST_IMAGE_PATH = ('https://storage.googleapis.com/tensorflow/'\n\n@@ -1,4 +1,4 @@\n-# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n+# Copyright 2021 The TensorFlow Authors. All Rights Reserved.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n # you may not use this file except in compliance with the License.\n@@ -25,10 +25,9 @@ import tensorflow.compat.v2 as tf\n import copy\n import math\n \n-from keras import backend\n+from keras import backend, layers\n from keras.applications import imagenet_utils\n from keras.engine import training\n-from keras.layers import VersionAwareLayers\n from keras.utils import data_utils\n from keras.utils import layer_utils\n from tensorflow.python.util.tf_export import keras_export\n@@ -531,6 +530,7 @@ DENSE_KERNEL_INITIALIZER = {\n }\n \n BASE_DOCSTRING = \"\"\"Instantiates the {name} architecture.\n+  \n   Reference:\n   - [EfficientNetV2: Smaller Models and Faster Training](\n       https://arxiv.org/abs/2104.00298) (ICML 2021)\n@@ -547,16 +547,22 @@ BASE_DOCSTRING = \"\"\"Instantiates the {name} architecture.\n     https://keras.io/guides/transfer_learning/).\n \n   Note: each Keras Application expects a specific kind of input preprocessing. \n-  For EfficientNetV2, call `keras.applications.efficientnet_v2.preprocess_input` on \n-    your inputs before passing them to the model.  \n-    `efficientnet_v2.preprocess_input` will scale input pixels between -1 and 1.\n+  For EfficientNetV2, by default input preprocessing is included as a part of the\n+  model (as a `Rescaling` layer), and thus\n+  `tf.keras.applications.efficientnet_v2.preprocess_input` is actually a\n+  pass-through function. In this use case, EfficientNetV2 models expect their inputs\n+  to be float tensors of pixels with values in the [0-255] range.\n+  At the same time, preprocessing as a part of the model (i.e. `Rescaling`\n+  layer) can be disabled by setting `include_preprocessing` argument to False.\n+  With preprocessing disabled EfficientNetV2 models expect their inputs to be float\n+  tensors of pixels with values in the [-1, 1] range. \n \n   Args:\n-    include_top: Whether to include the fully-connected\n+    include_top: Boolean, whether to include the fully-connected\n       layer at the top of the network. Defaults to True.\n     weights: One of `None` (random initialization),\n-          'imagenet' (pre-training on ImageNet),\n-          or the path to the weights file to be loaded. Defaults to 'imagenet'.\n+      `'imagenet'` (pre-training on ImageNet),\n+      or the path to the weights file to be loaded. Defaults to `'imagenet'`.\n     input_tensor: Optional Keras tensor\n       (i.e. output of `layers.Input()`)\n       to use as image input for the model.\n@@ -568,32 +574,45 @@ BASE_DOCSTRING = \"\"\"Instantiates the {name} architecture.\n       - `None` means that the output of the model will be\n           the 4D tensor output of the\n           last convolutional layer.\n-        - `avg` means that global average pooling\n+      - `'avg'` means that global average pooling\n           will be applied to the output of the\n           last convolutional layer, and thus\n           the output of the model will be a 2D tensor.\n-        - `max` means that global max pooling will\n+      - `'max'` means that global max pooling will\n           be applied.\n     classes: Optional number of classes to classify images\n       into, only to be specified if `include_top` is True, and\n       if no `weights` argument is specified. Defaults to 1000 (number of\n       ImageNet classes).\n-    classifier_activation: A `str` or callable. The activation function to use\n-        on the \"top\" layer. Ignored unless `include_top=True`. Set\n+    classifier_activation: A string or callable. The activation function to use\n+      on the `\"top\"` layer. Ignored unless `include_top=True`. Set\n       `classifier_activation=None` to return the logits of the \"top\" layer.\n-        Defaults to 'softmax'.\n+      Defaults to `'softmax'`.\n       When loading pretrained weights, `classifier_activation` can only\n-        be `None` or `\"softmax\"`.\n+      be `None` or `'softmax'`.\n \n   Returns:\n     A `keras.Model` instance.\n \"\"\"\n \n-layers = VersionAwareLayers()\n+\n+def round_filters(filters, width_coefficient, min_depth, depth_divisor):\n+    \"\"\"Round number of filters based on depth multiplier.\"\"\"\n+    filters *= width_coefficient\n+    minimum_depth = min_depth or depth_divisor\n+    new_filters = max(\n+        minimum_depth,\n+        int(filters + depth_divisor / 2) // depth_divisor * depth_divisor,\n+    )\n+    return int(new_filters)\n \n \n-def block_0(\n-    inputs,\n+def round_repeats(repeats, depth_coefficient):\n+    \"\"\"Round number of repeats based on depth multiplier.\"\"\"\n+    return int(math.ceil(depth_coefficient * repeats))\n+\n+\n+def Block0(\n     input_filters: int,\n     output_filters: int,\n     expand_ratio=1,\n@@ -601,13 +620,17 @@ def block_0(\n     strides=1,\n     se_ratio=0.0,\n     bn_momentum=0.9,\n-    activation=\"swish\",\n+    activation='swish',\n     survival_probability: float = 0.8,\n-    name: str = \"\",\n+    name=None,\n ):\n     \"\"\"MBConv block: Mobile Inverted Residual Bottleneck.\"\"\"\n-    bn_axis = 3 if backend.image_data_format() == \"channels_last\" else 1\n+    bn_axis = 3 if backend.image_data_format() == 'channels_last' else 1\n \n+    if name is None:\n+        name = backend.get_uid('block0')\n+\n+    def apply(inputs):\n         # Expansion phase\n         filters = input_filters * expand_ratio\n         if expand_ratio != 1:\n@@ -616,17 +639,17 @@ def block_0(\n               kernel_size=1,\n               strides=1,\n               kernel_initializer=CONV_KERNEL_INITIALIZER,\n-          padding=\"same\",\n-          data_format=\"channels_last\",\n+              padding='same',\n+              data_format='channels_last',\n               use_bias=False,\n-          name=name + \"expand_conv\",\n+              name=name + 'expand_conv',\n           )(inputs)\n           x = layers.BatchNormalization(\n               axis=bn_axis,\n               momentum=bn_momentum,\n-          name=name + \"expand_bn\",\n+              name=name + 'expand_bn',\n           )(x)\n-      x = layers.Activation(activation, name=name + \"expand_activation\")(x)\n+          x = layers.Activation(activation, name=name + 'expand_activation')(x)\n         else:\n           x = inputs\n \n@@ -635,45 +658,44 @@ def block_0(\n             kernel_size=kernel_size,\n             strides=strides,\n             depthwise_initializer=CONV_KERNEL_INITIALIZER,\n-        padding=\"same\",\n-        data_format=\"channels_last\",\n+            padding='same',\n+            data_format='channels_last',\n             use_bias=False,\n-        name=name + \"dwconv2\",\n+            name=name + 'dwconv2',\n         )(x)\n         x = layers.BatchNormalization(\n-        axis=bn_axis, momentum=bn_momentum, name=name + \"bn\"\n+            axis=bn_axis, momentum=bn_momentum, name=name + 'bn'\n         )(x)\n-    x = layers.Activation(activation, name=name + \"activation\")(x)\n+        x = layers.Activation(activation, name=name + 'activation')(x)\n \n         # Squeeze and excite\n         if 0 < se_ratio <= 1:\n           filters_se = max(1, int(input_filters * se_ratio))\n-      se = layers.GlobalAveragePooling2D(name=name + \"se_squeeze\")(x)\n+          se = layers.GlobalAveragePooling2D(name=name + 'se_squeeze')(x)\n           if bn_axis == 1:\n               se_shape = (filters, 1, 1)\n           else:\n               se_shape = (1, 1, filters)\n-      se = layers.Reshape(se_shape, name=name + \"se_reshape\")(se)\n+          se = layers.Reshape(se_shape, name=name + 'se_reshape')(se)\n \n-      # Warning. Is local pooling always false?\n           se = layers.Conv2D(\n               filters_se,\n               1,\n-          padding=\"same\",\n+              padding='same',\n               activation=activation,\n               kernel_initializer=CONV_KERNEL_INITIALIZER,\n-          name=name + \"se_reduce\",\n+              name=name + 'se_reduce',\n           )(se)\n           se = layers.Conv2D(\n               filters,\n               1,\n-          padding=\"same\",\n-          activation=\"sigmoid\",\n+              padding='same',\n+              activation='sigmoid',\n               kernel_initializer=CONV_KERNEL_INITIALIZER,\n-          name=name + \"se_expand\",\n+              name=name + 'se_expand',\n           )(se)\n \n-      x = layers.multiply([x, se], name=name + \"se_excite\")\n+          x = layers.multiply([x, se], name=name + 'se_excite')\n \n         # Output phase\n         x = layers.Conv2D(\n@@ -681,27 +703,27 @@ def block_0(\n             kernel_size=1,\n             strides=1,\n             kernel_initializer=CONV_KERNEL_INITIALIZER,\n-        padding=\"same\",\n-        data_format=\"channels_last\",\n+            padding='same',\n+            data_format='channels_last',\n             use_bias=False,\n-        name=name + \"project_conv\",\n+            name=name + 'project_conv',\n         )(x)\n         x = layers.BatchNormalization(\n-        axis=bn_axis, momentum=bn_momentum, name=name + \"project_bn\"\n+            axis=bn_axis, momentum=bn_momentum, name=name + 'project_bn'\n         )(x)\n \n         if strides == 1 and input_filters == output_filters:\n           if survival_probability:\n             x = layers.Dropout(\n-          survival_probability, noise_shape=(None, 1, 1, 1), name=name + \"drop\"\n+              survival_probability, noise_shape=(None, 1, 1, 1), name=name + 'drop'\n             )(x)\n \n-      x = layers.add([x, inputs], name=name + \"add\")\n+          x = layers.add([x, inputs], name=name + 'add')\n         return x\n+    return apply\n \n \n-def block_1(\n-    inputs,\n+def Block1(\n     input_filters: int,\n     output_filters: int,\n     expand_ratio=1,\n@@ -709,14 +731,17 @@ def block_1(\n     strides=1,\n     se_ratio=0.0,\n     bn_momentum=0.9,\n-    activation=\"swish\",\n+    activation='swish',\n     survival_probability: float = 0.8,\n-    name: str = \"\",\n+    name=None,\n ):\n     \"\"\"Fused MBConv Block: Fusing the proj conv1x1 and depthwise_conv into a conv2d.\"\"\"\n+    bn_axis = 3 if backend.image_data_format() == 'channels_last' else 1\n \n-    bn_axis = 3 if backend.image_data_format() == \"channels_last\" else 1\n+    if name is None:\n+        name = backend.get_uid('block0')\n \n+    def apply(inputs):\n         filters = input_filters * expand_ratio\n         if expand_ratio != 1:\n           x = layers.Conv2D(\n@@ -724,16 +749,16 @@ def block_1(\n               kernel_size=kernel_size,\n               strides=strides,\n               kernel_initializer=CONV_KERNEL_INITIALIZER,\n-          data_format=\"channels_last\",\n-          padding=\"same\",\n+              data_format='channels_last',\n+              padding='same',\n               use_bias=False,\n-          name=name + \"expand_conv\",\n+              name=name + 'expand_conv',\n           )(inputs)\n           x = layers.BatchNormalization(\n-          axis=bn_axis, momentum=bn_momentum, name=name + \"expand_bn\"\n+              axis=bn_axis, momentum=bn_momentum, name=name + 'expand_bn'\n           )(x)\n           x = layers.Activation(\n-          activation=activation, name=name + \"expand_activation\"\n+              activation=activation, name=name + 'expand_activation'\n           )(x)\n         else:\n           x = inputs\n@@ -741,32 +766,32 @@ def block_1(\n         # Squeeze and excite\n         if 0 < se_ratio <= 1:\n           filters_se = max(1, int(input_filters * se_ratio))\n-      se = layers.GlobalAveragePooling2D(name=name + \"se_squeeze\")(x)\n+          se = layers.GlobalAveragePooling2D(name=name + 'se_squeeze')(x)\n           if bn_axis == 1:\n             se_shape = (filters, 1, 1)\n           else:\n             se_shape = (1, 1, filters)\n \n-      se = layers.Reshape(se_shape, name=name + \"se_reshape\")(se)\n+          se = layers.Reshape(se_shape, name=name + 'se_reshape')(se)\n \n           se = layers.Conv2D(\n               filters_se,\n               1,\n-          padding=\"same\",\n+              padding='same',\n               activation=activation,\n               kernel_initializer=CONV_KERNEL_INITIALIZER,\n-          name=name + \"se_reduce\",\n+              name=name + 'se_reduce',\n           )(se)\n           se = layers.Conv2D(\n               filters,\n               1,\n-          padding=\"same\",\n-          activation=\"sigmoid\",\n+              padding='same',\n+              activation='sigmoid',\n               kernel_initializer=CONV_KERNEL_INITIALIZER,\n-          name=name + \"se_expand\",\n+              name=name + 'se_expand',\n           )(se)\n \n-      x = layers.multiply([x, se], name=name + \"se_excite\")\n+          x = layers.multiply([x, se], name=name + 'se_excite')\n \n         # Output phase:\n         x = layers.Conv2D(\n@@ -774,26 +799,27 @@ def block_1(\n             kernel_size=1 if expand_ratio != 1 else kernel_size,\n             strides=1 if expand_ratio != 1 else strides,\n             kernel_initializer=CONV_KERNEL_INITIALIZER,\n-        padding=\"same\",\n+            padding='same',\n             use_bias=False,\n-        name=name + \"project_conv\",\n+            name=name + 'project_conv',\n         )(x)\n         x = layers.BatchNormalization(\n-        axis=bn_axis, momentum=bn_momentum, name=name + \"project_bn\"\n+            axis=bn_axis, momentum=bn_momentum, name=name + 'project_bn'\n         )(x)\n         if expand_ratio == 1:\n-      x = layers.Activation(activation=activation, name=name + \"project_activation\")(x)\n+          x = layers.Activation(\n+              activation=activation, name=name + 'project_activation'\n+          )(x)\n \n         # Residual:\n         if strides == 1 and input_filters == output_filters:\n           if survival_probability:\n             x = layers.Dropout(\n-              survival_probability, noise_shape=(None, 1, 1, 1), name=name + \"drop\"\n+                  survival_probability, noise_shape=(None, 1, 1, 1), name=name + 'drop'\n                 )(x)\n-\n-      x = layers.add([x, inputs], name=name + \"add\")\n-    \n+          x = layers.add([x, inputs], name=name + 'add')\n         return x\n+    return apply\n \n \n def EfficientNetV2(\n@@ -805,16 +831,17 @@ def EfficientNetV2(\n     depth_divisor=8,\n     min_depth=8,\n     bn_momentum=0.9,\n-    activation=\"swish\",\n-    blocks_args=\"default\",\n-    model_name=\"efficientnetv2\",\n+    activation='swish',\n+    blocks_args='default',\n+    model_name='efficientnetv2',\n     include_top=True,\n-    weights=\"imagenet\",\n+    weights='imagenet',\n     input_tensor=None,\n     input_shape=None,\n     pooling=None,\n     classes=1000,\n-    classifier_activation=\"softmax\",\n+    classifier_activation='softmax',\n+    include_preprocessing=True,\n ):\n   \"\"\"Instantiates the EfficientNetV2 architecture using given scaling coefficients.\n     \n@@ -826,18 +853,17 @@ def EfficientNetV2(\n     drop_connect_rate: float, dropout rate at skip connections.\n     depth_divisor: integer, a unit of network width.\n     min_depth: integer, minimum number of filters.\n-    bn_momentu: float. Momentum parameter for Batch Normalization layers.\n+    bn_momentum: float. Momentum parameter for Batch Normalization layers.\n     activation: activation function.\n     blocks_args: list of dicts, parameters to construct block modules.\n     model_name: string, model name.\n     include_top: whether to include the fully-connected\n         layer at the top of the network.\n     weights: one of `None` (random initialization),\n-        'imagenet' (pre-training on ImageNet),\n+        `'imagenet'` (pre-training on ImageNet),\n         or the path to the weights file to be loaded.\n-    input_tensor: optional Keras tensor\n-        (i.e. output of `layers.Input()`)\n-        to use as image input for the model.\n+    input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n+      or numpy array to use as image input for the model.\n     input_shape: optional shape tuple, only to be specified\n         if `include_top` is False.\n         It should have exactly 3 inputs channels.\n@@ -846,25 +872,27 @@ def EfficientNetV2(\n         - `None` means that the output of the model will be\n             the 4D tensor output of the\n             last convolutional layer.\n-        - `avg` means that global average pooling\n+        - ''avg'' means that global average pooling\n             will be applied to the output of the\n             last convolutional layer, and thus\n             the output of the model will be a 2D tensor.\n-        - `max` means that global max pooling will\n+        - `'max'` means that global max pooling will\n             be applied.\n     classes: optional number of classes to classify images\n         into, only to be specified if `include_top` is True, and\n         if no `weights` argument is specified.\n-    classifier_activation: A `str` or callable. The activation function to use\n-        on the \"top\" layer. Ignored unless `include_top=True`. Set\n-        `classifier_activation=None` to return the logits of the \"top\" layer.\n+    classifier_activation: A string or callable. The activation function to use\n+        on the `\"top\"` layer. Ignored unless `include_top=True`. Set\n+        `classifier_activation=None` to return the logits of the `\"top\"` layer.\n+    include_preprocessing: Boolean, whether to include the preprocessing\n+        layer (`Rescaling`) at the bottom of the network. Defaults to `True`.\n   Returns:\n     A `keras.Model` instance.\n \n   Raises:\n     ValueError: in case of invalid argument for `weights`,\n       or invalid input shape.\n-    ValueError: if `classifier_activation` is not `softmax` or `None` when\n+    ValueError: if `classifier_activation` is not `'softmax'` or `None` when\n       using a pretrained top layer.\n   \"\"\"\n \n@@ -875,11 +903,13 @@ def EfficientNetV2(\n     raise ValueError('The `weights` argument should be either '\n                      '`None` (random initialization), `imagenet` '\n                      '(pre-training on ImageNet), '\n-                     'or the path to the weights file to be loaded.')\n+                     'or the path to the weights file to be loaded.'\n+                     f'Received: weights={weights}')\n \n   if weights == 'imagenet' and include_top and classes != 1000:\n     raise ValueError('If using `weights` as `\"imagenet\"` with `include_top`'\n-                     ' as true, `classes` should be 1000')\n+                     ' as true, `classes` should be 1000'\n+                     f'Received: classes={classes}')\n   \n   # Determine proper input shape\n   input_shape = imagenet_utils.obtain_input_shape(\n@@ -900,87 +930,98 @@ def EfficientNetV2(\n \n   bn_axis = 3 if backend.image_data_format() == 'channels_last' else 1\n \n-  def round_filters(filters):\n-    \"\"\"Round number of filters based on depth multiplier.\"\"\"\n-    filters *= width_coefficient\n-    minimum_depth = min_depth or depth_divisor\n-    new_filters = max(\n-      minimum_depth,\n-      int(filters + depth_divisor / 2) // depth_divisor * depth_divisor,\n-    )\n-    return int(new_filters)\n-\n-  def round_repeats(repeats):\n-    \"\"\"Round number of filters based on depth multiplier.\"\"\"\n-    return int(math.ceil(depth_coefficient * repeats))\n-  \n-  # Build stem\n   x = img_input\n \n-  stem_filters = blocks_args[0][\"input_filters\"]\n+  if include_preprocessing:\n+    x = layers.Rescaling(scale=1./128.0, offset=-1)(x)\n+\n+  # Build stem\n+  stem_filters = round_filters(\n+    filters=blocks_args[0]['input_filters'],\n+    width_coefficient=width_coefficient,\n+    min_depth=min_depth,\n+    depth_divisor=depth_divisor,\n+  )\n   x = layers.Conv2D(\n-    filters=round_filters(stem_filters),\n+    filters=stem_filters,\n     kernel_size=3,\n     strides=2,\n     kernel_initializer=CONV_KERNEL_INITIALIZER,\n-    padding=\"same\",\n+    padding='same',\n     use_bias=False,\n-    name=\"stem_conv\",\n+    name='stem_conv',\n   )(x)\n   x = layers.BatchNormalization(\n     axis=bn_axis,\n     momentum=bn_momentum,\n-    name=\"stem_bn\",\n+    name='stem_bn',\n   )(x)\n-  x = layers.Activation(activation, name=\"stem_activation\")(x)\n+  x = layers.Activation(activation, name='stem_activation')(x)\n \n   # Build blocks\n   blocks_args = copy.deepcopy(blocks_args)\n   b = 0\n-  blocks = float(sum(args[\"num_repeat\"] for args in blocks_args))\n+  blocks = float(sum(args['num_repeat'] for args in blocks_args))\n \n   for (i, args) in enumerate(blocks_args):\n-    assert args[\"num_repeat\"] > 0\n+    assert args['num_repeat'] > 0\n \n     # Update block input and output filters based on depth multiplier.\n-    args[\"input_filters\"] = round_filters(args[\"input_filters\"])\n-    args[\"output_filters\"] = round_filters(args[\"output_filters\"])\n-\n-    # Determine which conv type to use:\n-    block = {0: block_0, 1: block_1}[args.pop(\"conv_type\")]\n-\n-    for j in range(round_repeats(args.pop(\"num_repeat\"))):\n-      # The first block needs to take care of stride and filter size increase.\n-      if j > 0:\n-        args[\"strides\"] = 1\n-        args[\"input_filters\"] = args[\"output_filters\"]\n-      \n-      x = block(\n-        inputs=x,\n-        activation=activation,\n-        bn_momentum=bn_momentum,\n-        survival_probability=drop_connect_rate * b / blocks,  # Is this ok? Copied from V1.\n-        name=\"block{}{}_\".format(i + 1, chr(j + 97)),\n-        **args,\n+    args['input_filters'] = round_filters(\n+      filters=args['input_filters'],\n+      width_coefficient=width_coefficient,\n+      min_depth=min_depth,\n+      depth_divisor=depth_divisor\n+    )\n+    args['output_filters'] = round_filters(\n+      filters=args['output_filters'],\n+      width_coefficient=width_coefficient,\n+      min_depth=min_depth,\n+      depth_divisor=depth_divisor\n     )\n \n+    # Determine which conv type to use:\n+    block = {0: Block0, 1: Block1}[args.pop('conv_type')]\n+    repeats = round_repeats(\n+      repeats=args.pop('num_repeat'), depth_coefficient=depth_coefficient\n+    )\n+    for j in range(repeats):\n+      # The first block needs to take care of stride and filter size increase.\n+      if j > 0:\n+        args['strides'] = 1\n+        args['input_filters'] = args['output_filters']\n+      \n+      x = block(\n+        activation=activation,\n+        bn_momentum=bn_momentum,\n+        survival_probability=drop_connect_rate * b / blocks,\n+        name='block{}{}_'.format(i + 1, chr(j + 97)),\n+        **args,\n+      )(x)\n+  \n   # Build top\n+  top_filters = round_filters(\n+    filters=1280,\n+    width_coefficient=width_coefficient,\n+    min_depth=min_depth,\n+    depth_divisor=depth_divisor\n+  )\n   x = layers.Conv2D(\n-    filters=round_filters(1280),\n+    filters=top_filters,\n     kernel_size=1,\n     strides=1,\n     kernel_initializer=CONV_KERNEL_INITIALIZER,\n-    padding=\"same\",\n-    data_format=\"channels_last\",\n+    padding='same',\n+    data_format='channels_last',\n     use_bias=False,\n-    name=\"top_conv\",\n+    name='top_conv',\n   )(x)\n   x = layers.BatchNormalization(\n     axis=bn_axis,\n     momentum=bn_momentum,\n-    name=\"top_bn\",\n+    name='top_bn',\n   )(x)\n-  x = layers.Activation(activation=activation, name=\"top_activation\")(x)\n+  x = layers.Activation(activation=activation, name='top_activation')(x)\n   \n   if include_top:\n     x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n@@ -992,7 +1033,8 @@ def EfficientNetV2(\n       activation=classifier_activation,\n       kernel_initializer=DENSE_KERNEL_INITIALIZER,\n       bias_initializer=tf.constant_initializer(0),\n-        name='predictions')(x)\n+      name='predictions'\n+    )(x)\n   else:\n     if pooling == 'avg':\n       x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n@@ -1030,21 +1072,23 @@ def EfficientNetV2(\n   return model\n \n \n-@keras_export('keras.applications.efficientnetv2.EfficientNetV2_B0',\n-              'keras.applications.EfficientNetV2_B0')\n-def EfficientNetV2_B0(include_top=True,\n+@keras_export('keras.applications.efficientnet_v2.EfficientNetV2B0',\n+              'keras.applications.EfficientNetV2B0')\n+def EfficientNetV2B0(\n+  include_top=True,\n   weights='imagenet',\n   input_tensor=None,\n   input_shape=None,\n   pooling=None,\n   classes=1000,\n   classifier_activation='softmax',\n-                      **kwargs):\n+  include_preprocessing=True,\n+):\n   return EfficientNetV2(\n     width_coefficient=1.0,\n     depth_coefficient=1.0,\n     default_size=224,\n-      model_name=\"efficientnetv2-b0\",\n+    model_name='efficientnetv2-b0',\n     include_top=include_top,\n     weights=weights,\n     input_tensor=input_tensor,\n@@ -1052,25 +1096,27 @@ def EfficientNetV2_B0(include_top=True,\n     pooling=pooling,\n     classes=classes,\n     classifier_activation=classifier_activation,\n-      **kwargs)\n+    include_preprocessing=include_preprocessing\n+  )\n \n \n-@keras_export('keras.applications.efficientnetv2.EfficientNetV2_B1',\n-              'keras.applications.EfficientNetV2_B1')\n-def EfficientNetV2_B1(include_top=True,\n+@keras_export('keras.applications.efficientnet_v2.EfficientNetV2B1',\n+              'keras.applications.EfficientNetV2B1')\n+def EfficientNetV2B1(\n+  include_top=True,\n   weights='imagenet',\n   input_tensor=None,\n   input_shape=None,\n   pooling=None,\n   classes=1000,\n   classifier_activation='softmax',\n-                      **kwargs):\n-\n+  include_preprocessing=True,\n+):\n   return EfficientNetV2(\n     width_coefficient=1.0,\n     depth_coefficient=1.1,\n     default_size=240,\n-      model_name=\"efficientnetv2-b1\",\n+    model_name='efficientnetv2-b1',\n     include_top=include_top,\n     weights=weights,\n     input_tensor=input_tensor,\n@@ -1078,24 +1124,27 @@ def EfficientNetV2_B1(include_top=True,\n     pooling=pooling,\n     classes=classes,\n     classifier_activation=classifier_activation,\n-      **kwargs)\n+    include_preprocessing=include_preprocessing,\n+  )\n \n \n-@keras_export('keras.applications.efficientnetv2.EfficientNetV2_B2',\n-              'keras.applications.EfficientNetV2_B2')\n-def EfficientNetV2_B2(include_top=True,\n+@keras_export('keras.applications.efficientnet_v2.EfficientNetV2B2',\n+              'keras.applications.EfficientNetV2B2')\n+def EfficientNetV2B2(\n+  include_top=True,\n   weights='imagenet',\n   input_tensor=None,\n   input_shape=None,\n   pooling=None,\n   classes=1000,\n   classifier_activation='softmax',\n-                      **kwargs):\n+  include_preprocessing=True,\n+):\n   return EfficientNetV2(        \n     width_coefficient=1.1,\n     depth_coefficient=1.2,\n     default_size=260,\n-      model_name=\"efficientnetv2-b2\",\n+    model_name='efficientnetv2-b2',\n     include_top=include_top,\n     weights=weights,\n     input_tensor=input_tensor,\n@@ -1103,23 +1152,27 @@ def EfficientNetV2_B2(include_top=True,\n     pooling=pooling,\n     classes=classes,\n     classifier_activation=classifier_activation,\n-      **kwargs)\n+    include_preprocessing=include_preprocessing,\n+  )\n \n-@keras_export('keras.applications.efficientnetv2.EfficientNetV2_B3',\n-              'keras.applications.EfficientNetV2_B3')\n-def EfficientNetV2_B3(include_top=True,\n+\n+@keras_export('keras.applications.efficientnet_v2.EfficientNetV2B3',\n+              'keras.applications.EfficientNetV2B3')\n+def EfficientNetV2B3(\n+  include_top=True,\n   weights='imagenet',\n   input_tensor=None,\n   input_shape=None,\n   pooling=None,\n   classes=1000,\n   classifier_activation='softmax',\n-                      **kwargs):\n+  include_preprocessing=True,\n+):\n   return EfficientNetV2(\n     width_coefficient=1.2,\n     depth_coefficient=1.4,\n     default_size=300,\n-      model_name=\"efficientnetv2-b3\",\n+    model_name='efficientnetv2-b3',\n     include_top=include_top,\n     weights=weights,\n     input_tensor=input_tensor,\n@@ -1127,24 +1180,27 @@ def EfficientNetV2_B3(include_top=True,\n     pooling=pooling,\n     classes=classes,\n     classifier_activation=classifier_activation,\n-      **kwargs)\n+    include_preprocessing=include_preprocessing,\n+  )\n \n \n-@keras_export('keras.applications.efficientnetv2.EfficientNetV2_S',\n-              'keras.applications.EfficientNetV2_S')\n-def EfficientNetV2_S(include_top=True,\n+@keras_export('keras.applications.efficientnet_v2.EfficientNetV2S',\n+              'keras.applications.EfficientNetV2S')\n+def EfficientNetV2S(\n+  include_top=True,\n   weights='imagenet',\n   input_tensor=None,\n   input_shape=None,\n   pooling=None,\n   classes=1000,\n   classifier_activation='softmax',\n-                      **kwargs):\n+  include_preprocessing=True,\n+):\n   return EfficientNetV2(\n     width_coefficient=1.0,\n     depth_coefficient=1.0,\n     default_size=384,\n-      model_name=\"efficientnetv2-s\",\n+    model_name='efficientnetv2-s',\n     include_top=include_top,\n     weights=weights,\n     input_tensor=input_tensor,\n@@ -1152,23 +1208,27 @@ def EfficientNetV2_S(include_top=True,\n     pooling=pooling,\n     classes=classes,\n     classifier_activation=classifier_activation,\n-      **kwargs)\n+    include_preprocessing=include_preprocessing,\n+  )\n \n-@keras_export('keras.applications.efficientnetv2.EfficientNetV2_M',\n-              'keras.applications.EfficientNetV2_M')\n-def EfficientNetV2_M(include_top=True,\n+\n+@keras_export('keras.applications.efficientnet_v2.EfficientNetV2M',\n+              'keras.applications.EfficientNetV2M')\n+def EfficientNetV2M(\n+  include_top=True,\n   weights='imagenet',\n   input_tensor=None,\n   input_shape=None,\n   pooling=None,\n   classes=1000,\n   classifier_activation='softmax',\n-                      **kwargs):\n+  include_preprocessing=True,\n+):\n   return EfficientNetV2(\n     width_coefficient=1.0,\n     depth_coefficient=1.0,\n     default_size=480,\n-      model_name=\"efficientnetv2-m\",\n+    model_name='efficientnetv2-m',\n     include_top=include_top,\n     weights=weights,\n     input_tensor=input_tensor,\n@@ -1176,24 +1236,27 @@ def EfficientNetV2_M(include_top=True,\n     pooling=pooling,\n     classes=classes,\n     classifier_activation=classifier_activation,\n-      **kwargs)\n+    include_preprocessing=include_preprocessing,\n+  )\n \n \n-@keras_export('keras.applications.efficientnetv2.EfficientNetV2_L',\n-              'keras.applications.EfficientNetV2_L')\n-def EfficientNetV2_L(include_top=True,\n+@keras_export('keras.applications.efficientnet_v2.EfficientNetV2L',\n+              'keras.applications.EfficientNetV2L')\n+def EfficientNetV2L(\n+  include_top=True,\n   weights='imagenet',\n   input_tensor=None,\n   input_shape=None,\n   pooling=None,\n   classes=1000,\n   classifier_activation='softmax',\n-                      **kwargs):\n+  include_preprocessing=True,\n+):\n   return EfficientNetV2(\n     width_coefficient=1.0,\n     depth_coefficient=1.0,\n     default_size=480,\n-      model_name=\"efficientnetv2-l\",\n+    model_name='efficientnetv2-l',\n     include_top=include_top,\n     weights=weights,\n     input_tensor=input_tensor,\n@@ -1201,30 +1264,36 @@ def EfficientNetV2_L(include_top=True,\n     pooling=pooling,\n     classes=classes,\n     classifier_activation=classifier_activation,\n-      **kwargs)\n+    include_preprocessing=include_preprocessing,\n+  )\n \n \n-EfficientNetV2_B0.__doc__ = BASE_DOCSTRING.format(name='EfficientNetV2_B0')\n-EfficientNetV2_B1.__doc__ = BASE_DOCSTRING.format(name='EfficientNetV2_B1')\n-EfficientNetV2_B2.__doc__ = BASE_DOCSTRING.format(name='EfficientNetV2_B2')\n-EfficientNetV2_B3.__doc__ = BASE_DOCSTRING.format(name='EfficientNetV2_B3')\n-EfficientNetV2_S.__doc__ = BASE_DOCSTRING.format(name='EfficientNetV2_S')\n-EfficientNetV2_M.__doc__ = BASE_DOCSTRING.format(name='EfficientNetV2_M')\n-EfficientNetV2_L.__doc__ = BASE_DOCSTRING.format(name='EfficientNetV2_L')\n+EfficientNetV2B0.__doc__ = BASE_DOCSTRING.format(name='EfficientNetV2B0')\n+EfficientNetV2B1.__doc__ = BASE_DOCSTRING.format(name='EfficientNetV2B1')\n+EfficientNetV2B2.__doc__ = BASE_DOCSTRING.format(name='EfficientNetV2B2')\n+EfficientNetV2B3.__doc__ = BASE_DOCSTRING.format(name='EfficientNetV2B3')\n+EfficientNetV2S.__doc__ = BASE_DOCSTRING.format(name='EfficientNetV2S')\n+EfficientNetV2M.__doc__ = BASE_DOCSTRING.format(name='EfficientNetV2M')\n+EfficientNetV2L.__doc__ = BASE_DOCSTRING.format(name='EfficientNetV2L')\n \n \n @keras_export('keras.applications.efficientnet_v2.preprocess_input')\n def preprocess_input(x, data_format=None):  # pylint: disable=unused-argument\n-  \"\"\"\n-  Scale the values from 0-255 to values in range [-1, +1].\n+  \"\"\"A placeholder method for backward compatibility.\n+\n+  The preprocessing logic has been included in the EfficientNetV2 model\n+  implementation. Users are no longer required to call this method to normalize\n+  the input data. This method does nothing and only kept as a placeholder to\n+  align the API surface between old and new version of model.\n \n   Args:\n     x: A floating point `numpy.array` or a `tf.Tensor`.\n     data_format: Optional data format of the image tensor/array. Defaults to\n       None, in which case the global setting\n       `tf.keras.backend.image_data_format()` is used (unless you changed it,\n-      it defaults to \"channels_last\").{mode}\n+      it defaults to 'channels_last').{mode}\n+\n   Returns:\n-    Rescaled `numpy.array` or `tf.Tensor`.\n+    Unchanged `numpy.array` or `tf.Tensor`.\n   \"\"\"\n-  return (tf.cast(x, tf.float32) - 128.0) / 128.0\n+  return x\n\n@@ -25,7 +25,6 @@ import os\n PIP_EXCLUDED_FILES = frozenset([\n     'keras/api/create_python_api_wrapper.py',\n     'keras/applications/efficientnet_weight_update_util.py',\n-    'keras/applications/efficientnet_v2_weight_update_util.py',\n     'keras/distribute/tpu_strategy_test_utils.py',\n     'keras/saving/saved_model/create_test_saved_model.py',\n     'keras/tools/pip_package/setup.py',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#279fabea17a0292b691e9e20a8d3576277c53522", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 6 | Files Changed: 3 | Hunks: 7 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 18 | Churn Cumulative: 864 | Contributors (this commit): 6 | Commits (past 90d): 10 | Contributors (cumulative): 15 | DMM Complexity: 1.0\n\nDIFF:\n@@ -204,13 +204,18 @@ def labels_to_dataset(labels, label_mode, num_classes):\n     - 'categorical' means that the labels are mapped into a categorical vector.\n       (e.g. for `categorical_crossentropy` loss).\n     num_classes: number of classes of labels.\n+\n+  Returns:\n+    A `Dataset` instance.\n   \"\"\"\n   label_ds = tf.data.Dataset.from_tensor_slices(labels)\n   if label_mode == 'binary':\n     label_ds = label_ds.map(\n-        lambda x: tf.expand_dims(tf.cast(x, 'float32'), axis=-1))\n+        lambda x: tf.expand_dims(tf.cast(x, 'float32'), axis=-1),\n+        num_parallel_calls=tf.data.AUTOTUNE)\n   elif label_mode == 'categorical':\n-    label_ds = label_ds.map(lambda x: tf.one_hot(x, num_classes))\n+    label_ds = label_ds.map(lambda x: tf.one_hot(x, num_classes),\n+                            num_parallel_calls=tf.data.AUTOTUNE)\n   return label_ds\n \n \n@@ -218,12 +223,12 @@ def check_validation_split_arg(validation_split, subset, shuffle, seed):\n   \"\"\"Raise errors in case of invalid argument values.\n \n   Args:\n-    shuffle: Whether to shuffle the data. Either True or False.\n-    seed: random seed for shuffling and transformations.\n     validation_split: float between 0 and 1, fraction of data to reserve for\n       validation.\n     subset: One of \"training\" or \"validation\". Only used if `validation_split`\n       is set.\n+    shuffle: Whether to shuffle the data. Either True or False.\n+    seed: random seed for shuffling and transformations.\n   \"\"\"\n   if validation_split and not 0 < validation_split < 1:\n     raise ValueError(\n\n@@ -240,7 +240,7 @@ def paths_and_labels_to_dataset(image_paths,\n   path_ds = tf.data.Dataset.from_tensor_slices(image_paths)\n   args = (image_size, num_channels, interpolation, crop_to_aspect_ratio)\n   img_ds = path_ds.map(\n-      lambda x: load_image(x, *args))\n+      lambda x: load_image(x, *args), num_parallel_calls=tf.data.AUTOTUNE)\n   if label_mode:\n     label_ds = dataset_utils.labels_to_dataset(labels, label_mode, num_classes)\n     img_ds = tf.data.Dataset.zip((img_ds, label_ds))\n\n@@ -180,7 +180,8 @@ def paths_and_labels_to_dataset(file_paths,\n   \"\"\"Constructs a dataset of text strings and labels.\"\"\"\n   path_ds = tf.data.Dataset.from_tensor_slices(file_paths)\n   string_ds = path_ds.map(\n-      lambda x: path_to_string_content(x, max_length))\n+      lambda x: path_to_string_content(x, max_length),\n+      num_parallel_calls=tf.data.AUTOTUNE)\n   if label_mode:\n     label_ds = dataset_utils.labels_to_dataset(labels, label_mode, num_classes)\n     string_ds = tf.data.Dataset.zip((string_ds, label_ds))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#79d105de9e4e208161aa570b5d806a5a4ba44017", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 294 | Lines Deleted: 170 | Files Changed: 4 | Hunks: 68 | Methods Changed: 8 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 464 | Churn Cumulative: 4405 | Contributors (this commit): 5 | Commits (past 90d): 8 | Contributors (cumulative): 20 | DMM Complexity: None\n\nDIFF:\n@@ -83,12 +83,15 @@ class Conv1D(keras_layers.Conv1D, base.Layer):\n     name: A string, the name of the layer.\n \n   @compatibility(TF2)\n-  This API is not compatible with eager execution or `tf.function`.\n+  This API is a legacy api that is only compatible with eager execution and\n+  `tf.function` if you combine it with\n+  `tf.compat.v1.keras.utils.track_tf1_style_variables`\n \n-  Please refer to [tf.layers section of the migration guide]\n-  (https://www.tensorflow.org/guide/migrate#models_based_on_tflayers)\n-  to migrate a TensorFlow v1 model to Keras. The corresponding TensorFlow v2\n-  layer is `tf.keras.layers.Conv1D`.\n+  Please refer to [tf.layers model mapping section of the migration guide]\n+  (https://www.tensorflow.org/guide/migrate/model_mapping)\n+  to learn how to use your TensorFlow v1 model in TF2 with Keras.\n+\n+  The corresponding TensorFlow v2 layer is `tf.keras.layers.Conv1D`.\n \n \n   #### Structural Mapping to Native TF2\n@@ -230,12 +233,15 @@ def conv1d(inputs,\n \n \n   @compatibility(TF2)\n-  This API is not compatible with eager execution or `tf.function`.\n+  This API is a legacy api that is only compatible with eager execution and\n+  `tf.function` if you combine it with\n+  `tf.compat.v1.keras.utils.track_tf1_style_variables`\n \n-  Please refer to [tf.layers section of the migration guide]\n-  (https://www.tensorflow.org/guide/migrate#models_based_on_tflayers)\n-  to migrate a TensorFlow v1 model to Keras. The corresponding TensorFlow v2\n-  layer is `tf.keras.layers.Conv1D`.\n+  Please refer to [tf.layers model mapping section of the migration guide]\n+  (https://www.tensorflow.org/guide/migrate/model_mapping)\n+  to learn how to use your TensorFlow v1 model in TF2 with Keras.\n+\n+  The corresponding TensorFlow v2 layer is `tf.keras.layers.Conv1D`.\n \n \n   #### Structural Mapping to Native TF2\n@@ -351,12 +357,15 @@ class Conv2D(keras_layers.Conv2D, base.Layer):\n \n \n   @compatibility(TF2)\n-  This API is not compatible with eager execution or `tf.function`.\n+  This API is a legacy api that is only compatible with eager execution and\n+  `tf.function` if you combine it with\n+  `tf.compat.v1.keras.utils.track_tf1_style_variables`\n \n-  Please refer to [tf.layers section of the migration guide]\n-  (https://www.tensorflow.org/guide/migrate#models_based_on_tflayers)\n-  to migrate a TensorFlow v1 model to Keras. The corresponding TensorFlow v2\n-  layer is `tf.keras.layers.Conv2D`.\n+  Please refer to [tf.layers model mapping section of the migration guide]\n+  (https://www.tensorflow.org/guide/migrate/model_mapping)\n+  to learn how to use your TensorFlow v1 model in TF2 with Keras.\n+\n+  The corresponding TensorFlow v2 layer is `tf.keras.layers.Conv2D`.\n \n \n   #### Structural Mapping to Native TF2\n@@ -505,12 +514,15 @@ def conv2d(inputs,\n \n \n   @compatibility(TF2)\n-  This API is not compatible with eager execution or `tf.function`.\n+  This API is a legacy api that is only compatible with eager execution and\n+  `tf.function` if you combine it with\n+  `tf.compat.v1.keras.utils.track_tf1_style_variables`\n \n-  Please refer to [tf.layers section of the migration guide]\n-  (https://www.tensorflow.org/guide/migrate#models_based_on_tflayers)\n-  to migrate a TensorFlow v1 model to Keras. The corresponding TensorFlow v2\n-  layer is `tf.keras.layers.Conv2D`.\n+  Please refer to [tf.layers model mapping section of the migration guide]\n+  (https://www.tensorflow.org/guide/migrate/model_mapping)\n+  to learn how to use your TensorFlow v1 model in TF2 with Keras.\n+\n+  The corresponding TensorFlow v2 layer is `tf.keras.layers.Conv2D`.\n \n \n   #### Structural Mapping to Native TF2\n@@ -627,12 +639,15 @@ class Conv3D(keras_layers.Conv3D, base.Layer):\n \n \n   @compatibility(TF2)\n-  This API is not compatible with eager execution or `tf.function`.\n+  This API is a legacy api that is only compatible with eager execution and\n+  `tf.function` if you combine it with\n+  `tf.compat.v1.keras.utils.track_tf1_style_variables`\n \n-  Please refer to [tf.layers section of the migration guide]\n-  (https://www.tensorflow.org/guide/migrate#models_based_on_tflayers)\n-  to migrate a TensorFlow v1 model to Keras. The corresponding TensorFlow v2\n-  layer is `tf.keras.layers.Conv3D`.\n+  Please refer to [tf.layers model mapping section of the migration guide]\n+  (https://www.tensorflow.org/guide/migrate/model_mapping)\n+  to learn how to use your TensorFlow v1 model in TF2 with Keras.\n+\n+  The corresponding TensorFlow v2 layer is `tf.keras.layers.Conv3D`.\n \n \n   #### Structural Mapping to Native TF2\n@@ -782,12 +797,15 @@ def conv3d(inputs,\n \n \n   @compatibility(TF2)\n-  This API is not compatible with eager execution or `tf.function`.\n+  This API is a legacy api that is only compatible with eager execution and\n+  `tf.function` if you combine it with\n+  `tf.compat.v1.keras.utils.track_tf1_style_variables`\n \n-  Please refer to [tf.layers section of the migration guide]\n-  (https://www.tensorflow.org/guide/migrate#models_based_on_tflayers)\n-  to migrate a TensorFlow v1 model to Keras. The corresponding TensorFlow v2\n-  layer is `tf.keras.layers.Conv3D`.\n+  Please refer to [tf.layers model mapping section of the migration guide]\n+  (https://www.tensorflow.org/guide/migrate/model_mapping)\n+  to learn how to use your TensorFlow v1 model in TF2 with Keras.\n+\n+  The corresponding TensorFlow v2 layer is `tf.keras.layers.Conv3D`.\n \n \n   #### Structural Mapping to Native TF2\n@@ -905,12 +923,16 @@ class SeparableConv1D(keras_layers.SeparableConv1D, base.Layer):\n \n \n   @compatibility(TF2)\n-  This API is not compatible with eager execution or `tf.function`.\n+  This API is a legacy api that is only compatible with eager execution and\n+  `tf.function` if you combine it with\n+  `tf.compat.v1.keras.utils.track_tf1_style_variables`\n \n-  Please refer to [tf.layers section of the migration guide]\n-  (https://www.tensorflow.org/guide/migrate#models_based_on_tflayers)\n-  to migrate a TensorFlow v1 model to Keras. The corresponding TensorFlow v2\n-  layer is `tf.keras.layers.SeparableConv1D`.\n+  Please refer to [tf.layers model mapping section of the migration guide]\n+  (https://www.tensorflow.org/guide/migrate/model_mapping)\n+  to learn how to use your TensorFlow v1 model in TF2 with Keras.\n+\n+  The corresponding TensorFlow v2 layer is\n+  `tf.keras.layers.SeparableConv1D`.\n \n \n   #### Structural Mapping to Native TF2\n@@ -1048,12 +1070,16 @@ class SeparableConv2D(keras_layers.SeparableConv2D, base.Layer):\n \n \n   @compatibility(TF2)\n-  This API is not compatible with eager execution or `tf.function`.\n+  This API is a legacy api that is only compatible with eager execution and\n+  `tf.function` if you combine it with\n+  `tf.compat.v1.keras.utils.track_tf1_style_variables`\n \n-  Please refer to [tf.layers section of the migration guide]\n-  (https://www.tensorflow.org/guide/migrate#models_based_on_tflayers)\n-  to migrate a TensorFlow v1 model to Keras. The corresponding TensorFlow v2\n-  layer is `tf.keras.layers.SeparableConv2D`.\n+  Please refer to [tf.layers model mapping section of the migration guide]\n+  (https://www.tensorflow.org/guide/migrate/model_mapping)\n+  to learn how to use your TensorFlow v1 model in TF2 with Keras.\n+\n+  The corresponding TensorFlow v2 layer is\n+  `tf.keras.layers.SeparableConv2D`.\n \n \n   #### Structural Mapping to Native TF2\n@@ -1217,12 +1243,16 @@ def separable_conv1d(inputs,\n \n \n   @compatibility(TF2)\n-  This API is not compatible with eager execution or `tf.function`.\n+  This API is a legacy api that is only compatible with eager execution and\n+  `tf.function` if you combine it with\n+  `tf.compat.v1.keras.utils.track_tf1_style_variables`\n \n-  Please refer to [tf.layers section of the migration guide]\n-  (https://www.tensorflow.org/guide/migrate#models_based_on_tflayers)\n-  to migrate a TensorFlow v1 model to Keras. The corresponding TensorFlow v2\n-  layer is `tf.keras.layers.SeparableConv1D`.\n+  Please refer to [tf.layers model mapping section of the migration guide]\n+  (https://www.tensorflow.org/guide/migrate/model_mapping)\n+  to learn how to use your TensorFlow v1 model in TF2 with Keras.\n+\n+  The corresponding TensorFlow v2 layer is\n+  `tf.keras.layers.SeparableConv1D`.\n \n \n   #### Structural Mapping to Native TF2\n@@ -1380,12 +1410,16 @@ def separable_conv2d(inputs,\n \n \n   @compatibility(TF2)\n-  This API is not compatible with eager execution or `tf.function`.\n+  This API is a legacy api that is only compatible with eager execution and\n+  `tf.function` if you combine it with\n+  `tf.compat.v1.keras.utils.track_tf1_style_variables`\n \n-  Please refer to [tf.layers section of the migration guide]\n-  (https://www.tensorflow.org/guide/migrate#models_based_on_tflayers)\n-  to migrate a TensorFlow v1 model to Keras. The corresponding TensorFlow v2\n-  layer is `tf.keras.layers.SeparableConv2D`.\n+  Please refer to [tf.layers model mapping section of the migration guide]\n+  (https://www.tensorflow.org/guide/migrate/model_mapping)\n+  to learn how to use your TensorFlow v1 model in TF2 with Keras.\n+\n+  The corresponding TensorFlow v2 layer is\n+  `tf.keras.layers.SeparableConv2D`.\n \n \n   #### Structural Mapping to Native TF2\n@@ -1495,12 +1529,16 @@ class Conv2DTranspose(keras_layers.Conv2DTranspose, base.Layer):\n \n \n   @compatibility(TF2)\n-  This API is not compatible with eager execution or `tf.function`.\n+  This API is a legacy api that is only compatible with eager execution and\n+  `tf.function` if you combine it with\n+  `tf.compat.v1.keras.utils.track_tf1_style_variables`\n \n-  Please refer to [tf.layers section of the migration guide]\n-  (https://www.tensorflow.org/guide/migrate#models_based_on_tflayers)\n-  to migrate a TensorFlow v1 model to Keras. The corresponding TensorFlow v2\n-  layer is `tf.keras.layers.Conv2DTranspose`.\n+  Please refer to [tf.layers model mapping section of the migration guide]\n+  (https://www.tensorflow.org/guide/migrate/model_mapping)\n+  to learn how to use your TensorFlow v1 model in TF2 with Keras.\n+\n+  The corresponding TensorFlow v2 layer is\n+  `tf.keras.layers.Conv2DTranspose`.\n \n \n   #### Structural Mapping to Native TF2\n@@ -1637,12 +1675,16 @@ def conv2d_transpose(inputs,\n \n \n   @compatibility(TF2)\n-  This API is not compatible with eager execution or `tf.function`.\n+  This API is a legacy api that is only compatible with eager execution and\n+  `tf.function` if you combine it with\n+  `tf.compat.v1.keras.utils.track_tf1_style_variables`\n \n-  Please refer to [tf.layers section of the migration guide]\n-  (https://www.tensorflow.org/guide/migrate#models_based_on_tflayers)\n-  to migrate a TensorFlow v1 model to Keras. The corresponding TensorFlow v2\n-  layer is `tf.keras.layers.Conv2DTranspose`.\n+  Please refer to [tf.layers model mapping section of the migration guide]\n+  (https://www.tensorflow.org/guide/migrate/model_mapping)\n+  to learn how to use your TensorFlow v1 model in TF2 with Keras.\n+\n+  The corresponding TensorFlow v2 layer is\n+  `tf.keras.layers.Conv2DTranspose`.\n \n \n   #### Structural Mapping to Native TF2\n@@ -1743,12 +1785,16 @@ class Conv3DTranspose(keras_layers.Conv3DTranspose, base.Layer):\n \n \n   @compatibility(TF2)\n-  This API is not compatible with eager execution or `tf.function`.\n+  This API is a legacy api that is only compatible with eager execution and\n+  `tf.function` if you combine it with\n+  `tf.compat.v1.keras.utils.track_tf1_style_variables`\n \n-  Please refer to [tf.layers section of the migration guide]\n-  (https://www.tensorflow.org/guide/migrate#models_based_on_tflayers)\n-  to migrate a TensorFlow v1 model to Keras. The corresponding TensorFlow v2\n-  layer is `tf.keras.layers.Conv3DTranspose`.\n+  Please refer to [tf.layers model mapping section of the migration guide]\n+  (https://www.tensorflow.org/guide/migrate/model_mapping)\n+  to learn how to use your TensorFlow v1 model in TF2 with Keras.\n+\n+  The corresponding TensorFlow v2 layer is\n+  `tf.keras.layers.Conv3DTranspose`.\n \n \n   #### Structural Mapping to Native TF2\n@@ -1880,12 +1926,16 @@ def conv3d_transpose(inputs,\n \n \n   @compatibility(TF2)\n-  This API is not compatible with eager execution or `tf.function`.\n+  This API is a legacy api that is only compatible with eager execution and\n+  `tf.function` if you combine it with\n+  `tf.compat.v1.keras.utils.track_tf1_style_variables`\n \n-  Please refer to [tf.layers section of the migration guide]\n-  (https://www.tensorflow.org/guide/migrate#models_based_on_tflayers)\n-  to migrate a TensorFlow v1 model to Keras. The corresponding TensorFlow v2\n-  layer is `tf.keras.layers.Conv3DTranspose`.\n+  Please refer to [tf.layers model mapping section of the migration guide]\n+  (https://www.tensorflow.org/guide/migrate/model_mapping)\n+  to learn how to use your TensorFlow v1 model in TF2 with Keras.\n+\n+  The corresponding TensorFlow v2 layer is\n+  `tf.keras.layers.Conv3DTranspose`.\n \n \n   #### Structural Mapping to Native TF2\n\n@@ -86,12 +86,15 @@ class Dense(keras_layers.Dense, base.Layer):\n \n \n   @compatibility(TF2)\n-  This API is not compatible with eager execution or `tf.function`.\n+  This API is a legacy api that is only compatible with eager execution and\n+  `tf.function` if you combine it with\n+  `tf.compat.v1.keras.utils.track_tf1_style_variables`\n \n-  Please refer to [tf.layers section of the migration guide]\n-  (https://www.tensorflow.org/guide/migrate#models_based_on_tflayers)\n-  to migrate a TensorFlow v1 model to Keras. The corresponding TensorFlow v2\n-  layer is `tf.keras.layers.Dense`.\n+  Please refer to [tf.layers model mapping section of the migration guide]\n+  (https://www.tensorflow.org/guide/migrate/model_mapping)\n+  to learn how to use your TensorFlow v1 model in TF2 with Keras.\n+\n+  The corresponding TensorFlow v2 layer is `tf.keras.layers.Dense`.\n \n \n   #### Structural Mapping to Native TF2\n@@ -202,12 +205,15 @@ def dense(\n \n \n   @compatibility(TF2)\n-  This API is not compatible with eager execution or `tf.function`.\n+  This API is a legacy api that is only compatible with eager execution and\n+  `tf.function` if you combine it with\n+  `tf.compat.v1.keras.utils.track_tf1_style_variables`\n \n-  Please refer to [tf.layers section of the migration guide]\n-  (https://www.tensorflow.org/guide/migrate#models_based_on_tflayers)\n-  to migrate a TensorFlow v1 model to Keras. The corresponding TensorFlow v2\n-  layer is `tf.keras.layers.Dense`.\n+  Please refer to [tf.layers model mapping section of the migration guide]\n+  (https://www.tensorflow.org/guide/migrate/model_mapping)\n+  to learn how to use your TensorFlow v1 model in TF2 with Keras.\n+\n+  The corresponding TensorFlow v2 layer is `tf.keras.layers.Dense`.\n \n \n   #### Structural Mapping to Native TF2\n@@ -281,12 +287,15 @@ class Dropout(keras_layers.Dropout, base.Layer):\n \n \n   @compatibility(TF2)\n-  This API is not compatible with eager execution or `tf.function`.\n+  This API is a legacy api that is only compatible with eager execution and\n+  `tf.function` if you combine it with\n+  `tf.compat.v1.keras.utils.track_tf1_style_variables`\n \n-  Please refer to [tf.layers section of the migration guide]\n-  (https://www.tensorflow.org/guide/migrate#models_based_on_tflayers)\n-  to migrate a TensorFlow v1 model to Keras. The corresponding TensorFlow v2\n-  layer is `tf.keras.layers.Dropout`.\n+  Please refer to [tf.layers model mapping section of the migration guide]\n+  (https://www.tensorflow.org/guide/migrate/model_mapping)\n+  to learn how to use your TensorFlow v1 model in TF2 with Keras.\n+\n+  The corresponding TensorFlow v2 layer is `tf.keras.layers.Dropout`.\n \n \n   #### Structural Mapping to Native TF2\n@@ -362,12 +371,15 @@ def dropout(inputs,\n     ValueError: if eager execution is enabled.\n \n   @compatibility(TF2)\n-  This API is not compatible with eager execution or `tf.function`.\n+  This API is a legacy api that is only compatible with eager execution and\n+  `tf.function` if you combine it with\n+  `tf.compat.v1.keras.utils.track_tf1_style_variables`\n \n-  Please refer to [tf.layers section of the migration guide]\n-  (https://www.tensorflow.org/guide/migrate#models_based_on_tflayers)\n-  to migrate a TensorFlow v1 model to Keras. The corresponding TensorFlow v2\n-  layer is `tf.keras.layers.Dropout`.\n+  Please refer to [tf.layers model mapping section of the migration guide]\n+  (https://www.tensorflow.org/guide/migrate/model_mapping)\n+  to learn how to use your TensorFlow v1 model in TF2 with Keras.\n+\n+  The corresponding TensorFlow v2 layer is `tf.keras.layers.Dropout`.\n \n \n   #### Structural Mapping to Native TF2\n@@ -426,12 +438,15 @@ class Flatten(keras_layers.Flatten, base.Layer):\n   ```\n \n   @compatibility(TF2)\n-  This API is not compatible with eager execution or `tf.function`.\n+  This API is a legacy api that is only compatible with eager execution and\n+  `tf.function` if you combine it with\n+  `tf.compat.v1.keras.utils.track_tf1_style_variables`\n \n-  Please refer to [tf.layers section of the migration guide]\n-  (https://www.tensorflow.org/guide/migrate#models_based_on_tflayers)\n-  to migrate a TensorFlow v1 model to Keras. The corresponding TensorFlow v2\n-  layer is `tf.keras.layers.Flatten`.\n+  Please refer to [tf.layers model mapping section of the migration guide]\n+  (https://www.tensorflow.org/guide/migrate/model_mapping)\n+  to learn how to use your TensorFlow v1 model in TF2 with Keras.\n+\n+  The corresponding TensorFlow v2 layer is `tf.keras.layers.Flatten`.\n \n \n   #### Structural Mapping to Native TF2\n@@ -484,12 +499,15 @@ def flatten(inputs, name=None, data_format='channels_last'):\n   ```\n \n   @compatibility(TF2)\n-  This API is not compatible with eager execution or`tf.function`.\n+  This API is a legacy api that is only compatible with eager execution and\n+  `tf.function` if you combine it with\n+  `tf.compat.v1.keras.utils.track_tf1_style_variables`\n \n-  Please refer to [tf.layers section of the migration guide]\n-  (https://www.tensorflow.org/guide/migrate#models_based_on_tflayers)\n-  to migrate a TensorFlow v1 model to Keras. The corresponding TensorFlow v2\n-  layer is `tf.keras.layers.Flatten`.\n+  Please refer to [tf.layers model mapping section of the migration guide]\n+  (https://www.tensorflow.org/guide/migrate/model_mapping)\n+  to learn how to use your TensorFlow v1 model in TF2 with Keras.\n+\n+  The corresponding TensorFlow v2 layer is `tf.keras.layers.Flatten`.\n \n \n   #### Structural Mapping to Native TF2\n\n@@ -124,12 +124,16 @@ class BatchNormalization(batch_normalization_v1.BatchNormalization, base.Layer):\n \n \n   @compatibility(TF2)\n-  This API is not compatible with eager execution or `tf.function`.\n+  This API is a legacy api that is only compatible with eager execution and\n+  `tf.function` if you combine it with\n+  `tf.compat.v1.keras.utils.track_tf1_style_variables`\n \n-  Please refer to [tf.layers section of the migration guide]\n-  (https://www.tensorflow.org/guide/migrate#models_based_on_tflayers)\n-  to migrate a TensorFlow v1 model to Keras. The corresponding TensorFlow v2\n-  layer is `tf.keras.layers.BatchNormalization`.\n+  Please refer to [tf.layers model mapping section of the migration guide]\n+  (https://www.tensorflow.org/guide/migrate/model_mapping)\n+  to learn how to use your TensorFlow v1 model in TF2 with Keras.\n+\n+  The corresponding TensorFlow v2 layer is\n+  `tf.keras.layers.BatchNormalization`.\n \n \n   #### Structural Mapping to Native TF2\n@@ -361,12 +365,16 @@ def batch_normalization(inputs,\n       ([pdf](http://papers.nips.cc/paper/6790-batch-renormalization-towards-reducing-minibatch-dependence-in-batch-normalized-models.pdf))\n \n   @compatibility(TF2)\n-  This API is not compatible with eager execution or `tf.function`.\n+  This API is a legacy api that is only compatible with eager execution and\n+  `tf.function` if you combine it with\n+  `tf.compat.v1.keras.utils.track_tf1_style_variables`\n \n-  Please refer to [tf.layers section of the migration guide]\n-  (https://www.tensorflow.org/guide/migrate#models_based_on_tflayers)\n-  to migrate a TensorFlow v1 model to Keras. The corresponding TensorFlow v2\n-  layer is `tf.keras.layers.BatchNormalization`.\n+  Please refer to [tf.layers model mapping section of the migration guide]\n+  (https://www.tensorflow.org/guide/migrate/model_mapping)\n+  to learn how to use your TensorFlow v1 model in TF2 with Keras.\n+\n+  The corresponding TensorFlow v2 layer is\n+  `tf.keras.layers.BatchNormalization`.\n \n   The batch updating pattern with\n   `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used in\n\n@@ -47,12 +47,16 @@ class AveragePooling1D(keras_layers.AveragePooling1D, base.Layer):\n \n \n   @compatibility(TF2)\n-  This API is not compatible with eager execution or `tf.function`.\n+  This API is a legacy api that is only compatible with eager execution and\n+  `tf.function` if you combine it with\n+  `tf.compat.v1.keras.utils.track_tf1_style_variables`\n \n-  Please refer to [tf.layers section of the migration guide]\n-  (https://www.tensorflow.org/guide/migrate#models_based_on_tflayers)\n-  to migrate a TensorFlow v1 model to Keras. The corresponding TensorFlow v2\n-  layer is `tf.keras.layers.AveragePooling1D`.\n+  Please refer to [tf.layers model mapping section of the migration guide]\n+  (https://www.tensorflow.org/guide/migrate/model_mapping)\n+  to learn how to use your TensorFlow v1 model in TF2 with Keras.\n+\n+  The corresponding TensorFlow v2 layer is\n+  `tf.keras.layers.AveragePooling1D`.\n \n \n   #### Structural Mapping to Native TF2\n@@ -117,12 +121,16 @@ def average_pooling1d(inputs, pool_size, strides,\n \n \n   @compatibility(TF2)\n-  This API is not compatible with eager execution or `tf.function`.\n+  This API is a legacy api that is only compatible with eager execution and\n+  `tf.function` if you combine it with\n+  `tf.compat.v1.keras.utils.track_tf1_style_variables`\n \n-  Please refer to [tf.layers section of the migration guide]\n-  (https://www.tensorflow.org/guide/migrate#models_based_on_tflayers)\n-  to migrate a TensorFlow v1 model to Keras. The corresponding TensorFlow v2\n-  layer is `tf.keras.layers.AveragePooling1D`.\n+  Please refer to [tf.layers model mapping section of the migration guide]\n+  (https://www.tensorflow.org/guide/migrate/model_mapping)\n+  to learn how to use your TensorFlow v1 model in TF2 with Keras.\n+\n+  The corresponding TensorFlow v2 layer is\n+  `tf.keras.layers.AveragePooling1D`.\n \n \n   #### Structural Mapping to Native TF2\n@@ -181,12 +189,16 @@ class MaxPooling1D(keras_layers.MaxPooling1D, base.Layer):\n \n \n   @compatibility(TF2)\n-  This API is not compatible with eager execution or `tf.function`.\n+  This API is a legacy api that is only compatible with eager execution and\n+  `tf.function` if you combine it with\n+  `tf.compat.v1.keras.utils.track_tf1_style_variables`\n \n-  Please refer to [tf.layers section of the migration guide]\n-  (https://www.tensorflow.org/guide/migrate#models_based_on_tflayers)\n-  to migrate a TensorFlow v1 model to Keras. The corresponding TensorFlow v2\n-  layer is `tf.keras.layers.MaxPooling1D`.\n+  Please refer to [tf.layers model mapping section of the migration guide]\n+  (https://www.tensorflow.org/guide/migrate/model_mapping)\n+  to learn how to use your TensorFlow v1 model in TF2 with Keras.\n+\n+  The corresponding TensorFlow v2 layer is\n+  `tf.keras.layers.MaxPooling1D`.\n \n \n   #### Structural Mapping to Native TF2\n@@ -251,12 +263,16 @@ def max_pooling1d(inputs, pool_size, strides,\n \n \n   @compatibility(TF2)\n-  This API is not compatible with eager execution or `tf.function`.\n+  This API is a legacy api that is only compatible with eager execution and\n+  `tf.function` if you combine it with\n+  `tf.compat.v1.keras.utils.track_tf1_style_variables`\n \n-  Please refer to [tf.layers section of the migration guide]\n-  (https://www.tensorflow.org/guide/migrate#models_based_on_tflayers)\n-  to migrate a TensorFlow v1 model to Keras. The corresponding TensorFlow v2\n-  layer is `tf.keras.layers.MaxPooling1D`.\n+  Please refer to [tf.layers model mapping section of the migration guide]\n+  (https://www.tensorflow.org/guide/migrate/model_mapping)\n+  to learn how to use your TensorFlow v1 model in TF2 with Keras.\n+\n+  The corresponding TensorFlow v2 layer is\n+  `tf.keras.layers.MaxPooling1D`.\n \n \n   #### Structural Mapping to Native TF2\n@@ -319,12 +335,16 @@ class AveragePooling2D(keras_layers.AveragePooling2D, base.Layer):\n \n \n   @compatibility(TF2)\n-  This API is not compatible with eager execution or `tf.function`.\n+  This API is a legacy api that is only compatible with eager execution and\n+  `tf.function` if you combine it with\n+  `tf.compat.v1.keras.utils.track_tf1_style_variables`\n \n-  Please refer to [tf.layers section of the migration guide]\n-  (https://www.tensorflow.org/guide/migrate#models_based_on_tflayers)\n-  to migrate a TensorFlow v1 model to Keras. The corresponding TensorFlow v2\n-  layer is `tf.keras.layers.AveragePooling2D`.\n+  Please refer to [tf.layers model mapping section of the migration guide]\n+  (https://www.tensorflow.org/guide/migrate/model_mapping)\n+  to learn how to use your TensorFlow v1 model in TF2 with Keras.\n+\n+  The corresponding TensorFlow v2 layer is\n+  `tf.keras.layers.AveragePooling2D`.\n \n \n   #### Structural Mapping to Native TF2\n@@ -390,12 +410,16 @@ def average_pooling2d(inputs,\n \n \n   @compatibility(TF2)\n-  This API is not compatible with eager execution or `tf.function`.\n+  This API is a legacy api that is only compatible with eager execution and\n+  `tf.function` if you combine it with\n+  `tf.compat.v1.keras.utils.track_tf1_style_variables`\n \n-  Please refer to [tf.layers section of the migration guide]\n-  (https://www.tensorflow.org/guide/migrate#models_based_on_tflayers)\n-  to migrate a TensorFlow v1 model to Keras. The corresponding TensorFlow v2\n-  layer is `tf.keras.layers.AveragePooling2D`.\n+  Please refer to [tf.layers model mapping section of the migration guide]\n+  (https://www.tensorflow.org/guide/migrate/model_mapping)\n+  to learn how to use your TensorFlow v1 model in TF2 with Keras.\n+\n+  The corresponding TensorFlow v2 layer is\n+  `tf.keras.layers.AveragePooling2D`.\n \n \n   #### Structural Mapping to Native TF2\n@@ -456,12 +480,16 @@ class MaxPooling2D(keras_layers.MaxPooling2D, base.Layer):\n \n \n   @compatibility(TF2)\n-  This API is not compatible with eager execution or `tf.function`.\n+  This API is a legacy api that is only compatible with eager execution and\n+  `tf.function` if you combine it with\n+  `tf.compat.v1.keras.utils.track_tf1_style_variables`\n \n-  Please refer to [tf.layers section of the migration guide]\n-  (https://www.tensorflow.org/guide/migrate#models_based_on_tflayers)\n-  to migrate a TensorFlow v1 model to Keras. The corresponding TensorFlow v2\n-  layer is `tf.keras.layers.MaxPooling2D`.\n+  Please refer to [tf.layers model mapping section of the migration guide]\n+  (https://www.tensorflow.org/guide/migrate/model_mapping)\n+  to learn how to use your TensorFlow v1 model in TF2 with Keras.\n+\n+  The corresponding TensorFlow v2 layer is\n+  `tf.keras.layers.MaxPooling2D`.\n \n \n   #### Structural Mapping to Native TF2\n@@ -527,12 +555,16 @@ def max_pooling2d(inputs,\n \n \n   @compatibility(TF2)\n-  This API is not compatible with eager execution or `tf.function`.\n+  This API is a legacy api that is only compatible with eager execution and\n+  `tf.function` if you combine it with\n+  `tf.compat.v1.keras.utils.track_tf1_style_variables`\n \n-  Please refer to [tf.layers section of the migration guide]\n-  (https://www.tensorflow.org/guide/migrate#models_based_on_tflayers)\n-  to migrate a TensorFlow v1 model to Keras. The corresponding TensorFlow v2\n-  layer is `tf.keras.layers.MaxPooling2D`.\n+  Please refer to [tf.layers model mapping section of the migration guide]\n+  (https://www.tensorflow.org/guide/migrate/model_mapping)\n+  to learn how to use your TensorFlow v1 model in TF2 with Keras.\n+\n+  The corresponding TensorFlow v2 layer is\n+  `tf.keras.layers.MaxPooling2D`.\n \n \n   #### Structural Mapping to Native TF2\n@@ -595,12 +627,16 @@ class AveragePooling3D(keras_layers.AveragePooling3D, base.Layer):\n \n \n   @compatibility(TF2)\n-  This API is not compatible with eager execution or `tf.function`.\n+  This API is a legacy api that is only compatible with eager execution and\n+  `tf.function` if you combine it with\n+  `tf.compat.v1.keras.utils.track_tf1_style_variables`\n \n-  Please refer to [tf.layers section of the migration guide]\n-  (https://www.tensorflow.org/guide/migrate#models_based_on_tflayers)\n-  to migrate a TensorFlow v1 model to Keras. The corresponding TensorFlow v2\n-  layer is `tf.keras.layers.AveragePooling3D`.\n+  Please refer to [tf.layers model mapping section of the migration guide]\n+  (https://www.tensorflow.org/guide/migrate/model_mapping)\n+  to learn how to use your TensorFlow v1 model in TF2 with Keras.\n+\n+  The corresponding TensorFlow v2 layer is\n+  `tf.keras.layers.AveragePooling3D`.\n \n \n   #### Structural Mapping to Native TF2\n@@ -668,12 +704,16 @@ def average_pooling3d(inputs,\n \n \n   @compatibility(TF2)\n-  This API is not compatible with eager execution or `tf.function`.\n+  This API is a legacy api that is only compatible with eager execution and\n+  `tf.function` if you combine it with\n+  `tf.compat.v1.keras.utils.track_tf1_style_variables`\n \n-  Please refer to [tf.layers section of the migration guide]\n-  (https://www.tensorflow.org/guide/migrate#models_based_on_tflayers)\n-  to migrate a TensorFlow v1 model to Keras. The corresponding TensorFlow v2\n-  layer is `tf.keras.layers.AveragePooling3D`.\n+  Please refer to [tf.layers model mapping section of the migration guide]\n+  (https://www.tensorflow.org/guide/migrate/model_mapping)\n+  to learn how to use your TensorFlow v1 model in TF2 with Keras.\n+\n+  The corresponding TensorFlow v2 layer is\n+  `tf.keras.layers.AveragePooling3D`.\n \n \n   #### Structural Mapping to Native TF2\n@@ -736,12 +776,16 @@ class MaxPooling3D(keras_layers.MaxPooling3D, base.Layer):\n \n \n   @compatibility(TF2)\n-  This API is not compatible with eager execution or `tf.function`.\n+  This API is a legacy api that is only compatible with eager execution and\n+  `tf.function` if you combine it with\n+  `tf.compat.v1.keras.utils.track_tf1_style_variables`\n \n-  Please refer to [tf.layers section of the migration guide]\n-  (https://www.tensorflow.org/guide/migrate#models_based_on_tflayers)\n-  to migrate a TensorFlow v1 model to Keras. The corresponding TensorFlow v2\n-  layer is `tf.keras.layers.MaxPooling3D`.\n+  Please refer to [tf.layers model mapping section of the migration guide]\n+  (https://www.tensorflow.org/guide/migrate/model_mapping)\n+  to learn how to use your TensorFlow v1 model in TF2 with Keras.\n+\n+  The corresponding TensorFlow v2 layer is\n+  `tf.keras.layers.MaxPooling3D`.\n \n \n   #### Structural Mapping to Native TF2\n@@ -807,12 +851,16 @@ def max_pooling3d(inputs,\n \n \n   @compatibility(TF2)\n-  This API is not compatible with eager execution or `tf.function`.\n+  This API is a legacy api that is only compatible with eager execution and\n+  `tf.function` if you combine it with\n+  `tf.compat.v1.keras.utils.track_tf1_style_variables`\n \n-  Please refer to [tf.layers section of the migration guide]\n-  (https://www.tensorflow.org/guide/migrate#models_based_on_tflayers)\n-  to migrate a TensorFlow v1 model to Keras. The corresponding TensorFlow v2\n-  layer is `tf.keras.layers.MaxPooling3D`.\n+  Please refer to [tf.layers model mapping section of the migration guide]\n+  (https://www.tensorflow.org/guide/migrate/model_mapping)\n+  to learn how to use your TensorFlow v1 model in TF2 with Keras.\n+\n+  The corresponding TensorFlow v2 layer is\n+  `tf.keras.layers.MaxPooling3D`.\n \n \n   #### Structural Mapping to Native TF2\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
