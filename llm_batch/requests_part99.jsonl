{"custom_id": "requests#576b447a3708cce7c6d0c26695ca980b11c4bdc9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 26 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 3/2 | Churn Δ: 27 | Churn Cumulative: 5700 | Contributors (this commit): 84 | Commits (past 90d): 35 | Contributors (cumulative): 96 | DMM Complexity: 1.0\n\nDIFF:\n@@ -15,7 +15,7 @@ import threading\n \n from base64 import b64encode\n \n-from .compat import urlparse, str\n+from .compat import urlparse, str, basestring\n from .cookies import extract_cookies_to_jar\n from ._internal_utils import to_native_string\n from .utils import parse_dict_header\n@@ -28,6 +28,20 @@ CONTENT_TYPE_MULTI_PART = 'multipart/form-data'\n def _basic_auth_str(username, password):\n     \"\"\"Returns a Basic Auth string.\"\"\"\n \n+    # \"I want us to put a big-ol' comment on top of it that\n+    # says that this behaviour is dumb but we need to preserve\n+    # it because people are relying on it.\"\n+    #    - Lukasa\n+    #\n+    # These are here solely to maintain backwards compatibility\n+    # for things like ints. This will be removed in 3.0.0.\n+    if not isinstance(username, basestring):\n+        username = str(username)\n+\n+    if not isinstance(password, basestring):\n+        password = str(password)\n+    # -- End Removal --\n+\n     if isinstance(username, str):\n         username = username.encode('latin1')\n \n\n@@ -484,6 +484,7 @@ class TestRequests:\n         'username, password', (\n             ('user', 'pass'),\n             (u'имя'.encode('utf-8'), u'пароль'.encode('utf-8')),\n+            (42, 42)\n         ))\n     def test_set_basicauth(self, httpbin, username, password):\n         auth = (username, password)\n@@ -494,6 +495,16 @@ class TestRequests:\n \n         assert p.headers['Authorization'] == _basic_auth_str(username, password)\n \n+    def test_basicauth_encodes_byte_strings(self):\n+        \"\"\"Ensure b'test' formats as the byte string \"test\" rather\n+        than the unicode string \"b'test'\" in Python 3.\n+        \"\"\"\n+        auth = (b'\\xc5\\xafsername', b'test\\xc6\\xb6')\n+        r = requests.Request('GET', 'http://localhost', auth=auth)\n+        p = r.prepare()\n+\n+        assert p.headers['Authorization'] == 'Basic xa9zZXJuYW1lOnRlc3TGtg=='\n+\n     @pytest.mark.parametrize(\n         'url, exception', (\n             # Connecting to an unknown domain should raise a ConnectionError\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#fae670147814f7107f6978117948b8395030a522", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 4 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 18 | Churn Cumulative: 5718 | Contributors (this commit): 84 | Commits (past 90d): 37 | Contributors (cumulative): 96 | DMM Complexity: 1.0\n\nDIFF:\n@@ -12,6 +12,7 @@ import re\n import time\n import hashlib\n import threading\n+import warnings\n \n from base64 import b64encode\n \n@@ -36,9 +37,23 @@ def _basic_auth_str(username, password):\n     # These are here solely to maintain backwards compatibility\n     # for things like ints. This will be removed in 3.0.0.\n     if not isinstance(username, basestring):\n+        warnings.warn(\n+            \"Non-string usernames will no longer be supported in Requests \"\n+            \"3.0.0. Please convert the object you've passed in ({!r}) to \"\n+            \"a string or bytes object in the near future to avoid \"\n+            \"problems.\".format(username),\n+            category=DeprecationWarning,\n+        )\n         username = str(username)\n \n     if not isinstance(password, basestring):\n+        warnings.warn(\n+            \"Non-string passwords will no longer be supported in Requests \"\n+            \"3.0.0. Please convert the object you've passed in ({!r}) to \"\n+            \"a string or bytes object in the near future to avoid \"\n+            \"problems.\".format(password),\n+            category=DeprecationWarning,\n+        )\n         password = str(password)\n     # -- End Removal --\n \n\n@@ -484,7 +484,8 @@ class TestRequests:\n         'username, password', (\n             ('user', 'pass'),\n             (u'имя'.encode('utf-8'), u'пароль'.encode('utf-8')),\n-            (42, 42)\n+            (42, 42),\n+            (None, None),\n         ))\n     def test_set_basicauth(self, httpbin, username, password):\n         auth = (username, password)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#1da121356181844967fae02aedc17384e435581d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 112 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 4 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 113 | Churn Cumulative: 175 | Contributors (this commit): 3 | Commits (past 90d): 1 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -5,7 +5,7 @@ import pytest\n import threading\n import requests\n \n-from tests.testserver.server import Server\n+from tests.testserver.server import Server, consume_socket_content\n \n from .utils import override_environ\n \n@@ -25,6 +25,117 @@ def test_chunked_upload():\n     assert r.request.headers['Transfer-Encoding'] == 'chunked'\n \n \n+def test_digestauth_401_count_reset_on_redirect():\n+    \"\"\"Ensure we correctly reset num_401_calls after a successful digest auth,\n+    followed by a 302 redirect to another digest auth prompt.\n+\n+    See https://github.com/kennethreitz/requests/issues/1979.\n+    \"\"\"\n+    text_401 = (b'HTTP/1.1 401 UNAUTHORIZED\\r\\n'\n+                b'Content-Length: 0\\r\\n'\n+                b'WWW-Authenticate: Digest nonce=\"6bf5d6e4da1ce66918800195d6b9130d\"'\n+                b', opaque=\"372825293d1c26955496c80ed6426e9e\", '\n+                b'realm=\"me@kennethreitz.com\", qop=auth\\r\\n\\r\\n')\n+\n+    text_302 = (b'HTTP/1.1 302 FOUND\\r\\n'\n+                b'Content-Length: 0\\r\\n'\n+                b'Location: /\\r\\n\\r\\n')\n+\n+    text_200 = (b'HTTP/1.1 200 OK\\r\\n'\n+                b'Content-Length: 0\\r\\n\\r\\n')\n+\n+    expected_digest = (b'Authorization: Digest username=\"user\", '\n+                       b'realm=\"me@kennethreitz.com\", '\n+                       b'nonce=\"6bf5d6e4da1ce66918800195d6b9130d\", uri=\"/\"')\n+\n+    auth = requests.auth.HTTPDigestAuth('user', 'pass')\n+\n+    def digest_response_handler(sock):\n+        # Respond to initial GET with a challenge.\n+        request_content = consume_socket_content(sock, timeout=0.5)\n+        assert request_content.startswith(b\"GET / HTTP/1.1\")\n+        sock.send(text_401)\n+\n+        # Verify we receive an Authorization header in response, then redirect.\n+        request_content = consume_socket_content(sock, timeout=0.5)\n+        assert expected_digest in request_content\n+        sock.send(text_302)\n+\n+        # Verify Authorization isn't sent to the redirected host,\n+        # then send another challenge.\n+        request_content = consume_socket_content(sock, timeout=0.5)\n+        assert b'Authorization:' not in request_content\n+        sock.send(text_401)\n+\n+        # Verify Authorization is sent correctly again, and return 200 OK.\n+        request_content = consume_socket_content(sock, timeout=0.5)\n+        assert expected_digest in request_content\n+        sock.send(text_200)\n+\n+        return request_content\n+\n+    close_server = threading.Event()\n+    server = Server(digest_response_handler, wait_to_close_event=close_server)\n+\n+    with server as (host, port):\n+        url = 'http://{0}:{1}/'.format(host, port)\n+        r = requests.get(url, auth=auth)\n+        # Verify server succeeded in authenticating.\n+        assert r.status_code == 200\n+        # Verify Authorization was sent in final request.\n+        assert 'Authorization' in r.request.headers\n+        assert r.request.headers['Authorization'].startswith('Digest ')\n+        # Verify redirect happened as we expected.\n+        assert r.history[0].status_code == 302\n+        close_server.set()\n+\n+\n+def test_digestauth_401_only_sent_once():\n+    \"\"\"Ensure we correctly respond to a 401 challenge once, and then\n+    stop responding if challenged again.\n+    \"\"\"\n+    text_401 = (b'HTTP/1.1 401 UNAUTHORIZED\\r\\n'\n+                b'Content-Length: 0\\r\\n'\n+                b'WWW-Authenticate: Digest nonce=\"6bf5d6e4da1ce66918800195d6b9130d\"'\n+                b', opaque=\"372825293d1c26955496c80ed6426e9e\", '\n+                b'realm=\"me@kennethreitz.com\", qop=auth\\r\\n\\r\\n')\n+\n+    expected_digest = (b'Authorization: Digest username=\"user\", '\n+                       b'realm=\"me@kennethreitz.com\", '\n+                       b'nonce=\"6bf5d6e4da1ce66918800195d6b9130d\", uri=\"/\"')\n+\n+    auth = requests.auth.HTTPDigestAuth('user', 'pass')\n+\n+    def digest_failed_response_handler(sock):\n+        # Respond to initial GET with a challenge.\n+        request_content = consume_socket_content(sock, timeout=0.5)\n+        assert request_content.startswith(b\"GET / HTTP/1.1\")\n+        sock.send(text_401)\n+\n+        # Verify we receive an Authorization header in response, then\n+        # challenge again.\n+        request_content = consume_socket_content(sock, timeout=0.5)\n+        assert expected_digest in request_content\n+        sock.send(text_401)\n+\n+        # Verify the client didn't respond to second challenge.\n+        request_content = consume_socket_content(sock, timeout=0.5)\n+        assert request_content == b''\n+\n+        return request_content\n+\n+    close_server = threading.Event()\n+    server = Server(digest_failed_response_handler, wait_to_close_event=close_server)\n+\n+    with server as (host, port):\n+        url = 'http://{0}:{1}/'.format(host, port)\n+        r = requests.get(url, auth=auth)\n+        # Verify server didn't authenticate us.\n+        assert r.status_code == 401\n+        assert r.history[0].status_code == 401\n+        close_server.set()\n+\n+\n _schemes_by_var_prefix = [\n     ('http', ['http']),\n     ('https', ['https']),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#1285f576ae0a848de27af10d917c19b60940d1fa", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 674 | Contributors (this commit): 16 | Commits (past 90d): 5 | Contributors (cumulative): 16 | DMM Complexity: None\n\nDIFF:\n@@ -41,8 +41,8 @@ is at <http://python-requests.org>.\n \"\"\"\n \n __title__ = 'requests'\n-__version__ = '2.12.3'\n-__build__ = 0x021203\n+__version__ = '2.12.4'\n+__build__ = 0x021204\n __author__ = 'Kenneth Reitz'\n __license__ = 'Apache 2.0'\n __copyright__ = 'Copyright 2016 Kenneth Reitz'\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#789f21807d4cc0eb939181494fea8399dfc5206a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 1546 | Contributors (this commit): 44 | Commits (past 90d): 7 | Contributors (cumulative): 44 | DMM Complexity: None\n\nDIFF:\n@@ -39,7 +39,7 @@ def _basic_auth_str(username, password):\n     if not isinstance(username, basestring):\n         warnings.warn(\n             \"Non-string usernames will no longer be supported in Requests \"\n-            \"3.0.0. Please convert the object you've passed in ({!r}) to \"\n+            \"3.0.0. Please convert the object you've passed in ({0!r}) to \"\n             \"a string or bytes object in the near future to avoid \"\n             \"problems.\".format(username),\n             category=DeprecationWarning,\n@@ -49,7 +49,7 @@ def _basic_auth_str(username, password):\n     if not isinstance(password, basestring):\n         warnings.warn(\n             \"Non-string passwords will no longer be supported in Requests \"\n-            \"3.0.0. Please convert the object you've passed in ({!r}) to \"\n+            \"3.0.0. Please convert the object you've passed in ({0!r}) to \"\n             \"a string or bytes object in the near future to avoid \"\n             \"problems.\".format(password),\n             category=DeprecationWarning,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#5aa66615870beeb7b0ed3af27457f689db262ab3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 370 | Contributors (this commit): 5 | Commits (past 90d): 3 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -111,7 +111,7 @@ class AppEngineManager(RequestMethods):\n         warnings.warn(\n             \"urllib3 is using URLFetch on Google App Engine sandbox instead \"\n             \"of sockets. To use sockets directly instead of URLFetch see \"\n-            \"https://urllib3.readthedocs.io/en/latest/contrib.html.\",\n+            \"https://urllib3.readthedocs.io/en/latest/reference/urllib3.contrib.html.\",\n             AppEnginePlatformWarning)\n \n         RequestMethods.__init__(self, headers)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#1c34ac3ae66ef05820d781bde7ae8eda673eaa46", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 13 | Churn Cumulative: 3830 | Contributors (this commit): 71 | Commits (past 90d): 8 | Contributors (cumulative): 83 | DMM Complexity: 1.0\n\nDIFF:\n@@ -714,7 +714,7 @@ def guess_json_utf(data):\n     # easy as counting the nulls and from their location and count\n     # determine the encoding. Also detect a BOM, if present.\n     sample = data[:4]\n-    if sample in (codecs.BOM_UTF32_LE, codecs.BOM32_BE):\n+    if sample in (codecs.BOM_UTF32_LE, codecs.BOM_UTF32_BE):\n         return 'utf-32'     # BOM included\n     if sample[:3] == codecs.BOM_UTF8:\n         return 'utf-8-sig'  # BOM included, MS style (discouraged)\n\n@@ -274,6 +274,17 @@ class TestGuessJSONUTF:\n     def test_bad_utf_like_encoding(self):\n         assert guess_json_utf(b'\\x00\\x00\\x00\\x00') is None\n \n+    @pytest.mark.parametrize(\n+        ('encoding', 'expected'), (\n+            ('utf-16-be', 'utf-16'),\n+            ('utf-16-le', 'utf-16'),\n+            ('utf-32-be', 'utf-32'),\n+            ('utf-32-le', 'utf-32')\n+        ))\n+    def test_guess_by_bom(self, encoding, expected):\n+        data = '\\ufeff{}'.encode(encoding)\n+        assert guess_json_utf(data) == expected\n+\n \n USER = PASSWORD = \"%!*'();:@&=+$,/?#[] \"\n ENCODED_USER = compat.quote(USER, '')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#0cb6ddaecf8fe88f3c6ba9ae60aa6b9d063f0ca1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1159 | Contributors (this commit): 14 | Commits (past 90d): 5 | Contributors (cumulative): 14 | DMM Complexity: None\n\nDIFF:\n@@ -282,7 +282,7 @@ class TestGuessJSONUTF:\n             ('utf-32-le', 'utf-32')\n         ))\n     def test_guess_by_bom(self, encoding, expected):\n-        data = '\\ufeff{}'.encode(encoding)\n+        data = u'\\ufeff{}'.encode(encoding)\n         assert guess_json_utf(data) == expected\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#33b29be8cf93572870415b04c21a895ca3edf3ce", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 510 | Contributors (this commit): 22 | Commits (past 90d): 4 | Contributors (cumulative): 22 | DMM Complexity: None\n\nDIFF:\n@@ -47,7 +47,7 @@ packages = [\n ]\n \n requires = []\n-test_requirements = ['pytest>=2.8.0', 'pytest-httpbin==0.0.7', 'pytest-cov']\n+test_requirements = ['pytest>=2.8.0', 'pytest-httpbin==0.0.7', 'pytest-cov', 'pytest-mock']\n \n with open('requests/__init__.py', 'r') as fd:\n     version = re.search(r'^__version__\\s*=\\s*[\\'\"]([^\\'\"]*)[\\'\"]',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#2bcaff99eaffda691eadfa3298507db6ffe17ca9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 511 | Contributors (this commit): 23 | Commits (past 90d): 5 | Contributors (cumulative): 23 | DMM Complexity: None\n\nDIFF:\n@@ -88,6 +88,7 @@ setup(\n         'Programming Language :: Python :: 3.3',\n         'Programming Language :: Python :: 3.4',\n         'Programming Language :: Python :: 3.5',\n+        'Programming Language :: Python :: 3.6',\n         'Programming Language :: Python :: Implementation :: CPython',\n         'Programming Language :: Python :: Implementation :: PyPy'\n     ),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#e8c0a99cb11c630b1e778a8c7e6b33b36d8088a7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 5340 | Contributors (this commit): 59 | Commits (past 90d): 34 | Contributors (cumulative): 68 | DMM Complexity: None\n\nDIFF:\n@@ -20,7 +20,7 @@ from requests.compat import (\n     Morsel, cookielib, getproxies, str, urlparse,\n     builtin_str, OrderedDict)\n from requests.cookies import (\n-    cookiejar_from_dict, morsel_to_cookie, merge_cookies)\n+    cookiejar_from_dict, morsel_to_cookie)\n from requests.exceptions import (\n     ConnectionError, ConnectTimeout, InvalidSchema, InvalidURL,\n     MissingSchema, ReadTimeout, Timeout, RetryError, TooManyRedirects,\n@@ -2293,4 +2293,3 @@ class TestPreparingURLs(object):\n         r = requests.Request('GET', url=input, params=params)\n         p = r.prepare()\n         assert p.url == expected\n-\n\n@@ -4,7 +4,7 @@ from io import BytesIO\n \n import pytest\n from requests import compat\n-from requests.cookies import RequestsCookieJar, cookiejar_from_dict\n+from requests.cookies import RequestsCookieJar\n from requests.structures import CaseInsensitiveDict\n from requests.utils import (\n     address_in_network, dotted_netmask,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#2432dd62085629c775abc269ec92e7f13a63b73f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1179 | Contributors (this commit): 41 | Commits (past 90d): 3 | Contributors (cumulative): 41 | DMM Complexity: None\n\nDIFF:\n@@ -33,7 +33,7 @@ def request(method, url, **kwargs):\n         before giving up, as a float, or a :ref:`(connect timeout, read\n         timeout) <timeouts>` tuple.\n     :type timeout: float or tuple\n-    :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection.\n+    :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``.\n     :type allow_redirects: bool\n     :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.\n     :param verify: (optional) whether the SSL cert will be verified. A CA_BUNDLE path can also be provided. Defaults to ``True``.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#fae3f92c34d8d7267de33ecb676b3d5600146257", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 26 | Lines Deleted: 16 | Files Changed: 2 | Hunks: 6 | Methods Changed: 2 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 42 | Churn Cumulative: 9929 | Contributors (this commit): 175 | Commits (past 90d): 12 | Contributors (cumulative): 179 | DMM Complexity: 0.8461538461538461\n\nDIFF:\n@@ -9,6 +9,7 @@ This module contains the primary objects that power Requests.\n \n import collections\n import datetime\n+import sys\n \n # Import encoding now, to avoid implicit import later.\n # Implicit import within threads may cause LookupError when standard library is in a ZIP,\n@@ -21,7 +22,6 @@ from .structures import CaseInsensitiveDict\n \n from .auth import HTTPBasicAuth\n from .cookies import cookiejar_from_dict, get_cookie_header, _copy_cookie_jar\n-from .packages import idna\n from .packages.urllib3.fields import RequestField\n from .packages.urllib3.filepost import encode_multipart_formdata\n from .packages.urllib3.util import parse_url\n@@ -331,6 +331,22 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n         if self.method is not None:\n             self.method = to_native_string(self.method.upper())\n \n+    @staticmethod\n+    def _get_idna_encoded_host(host):\n+        try:\n+            from .packages import idna\n+        except ImportError:\n+            # tolerate the possibility of downstream repackagers unvendoring `requests`\n+            # For more information, read: packages/__init__.py\n+            import idna\n+            sys.modules['requests.packages.idna'] = idna\n+\n+        try:\n+            host = idna.encode(host, uts46=True).decode('utf-8')\n+        except idna.IDNAError:\n+            raise UnicodeError\n+        return host\n+\n     def prepare_url(self, url, params):\n         \"\"\"Prepares the given HTTP URL.\"\"\"\n         #: Accept objects that have string representations.\n@@ -368,16 +384,16 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n         if not host:\n             raise InvalidURL(\"Invalid URL %r: No host supplied\" % url)\n \n-        # In general, we want to try IDNA encoding every hostname, as that\n-        # allows users to automatically get the correct behaviour. However,\n-        # we’re quite strict about IDNA encoding, so certain valid hostnames\n-        # may fail to encode. On failure, we verify the hostname meets a\n-        # minimum standard of only containing ASCII characters, and not starting\n-        # with a wildcard (*), before allowing the unencoded hostname through.\n+        # In general, we want to try IDNA encoding the hostname if the string contains\n+        # non-ASCII characters. This allows users to automatically get the correct IDNA\n+        # behaviour. For strings containing only ASCII characters, we need to also verify\n+        # it doesn't start with a wildcard (*), before allowing the unencoded hostname.\n+        if not unicode_is_ascii(host):\n             try:\n-            host = idna.encode(host, uts46=True).decode('utf-8')\n-        except (UnicodeError, idna.IDNAError):\n-            if not unicode_is_ascii(host) or host.startswith(u'*'):\n+                host = self._get_idna_encoded_host(host)\n+            except UnicodeError:\n+                raise InvalidURL('URL has an invalid label.')\n+        elif host.startswith(u'*'):\n             raise InvalidURL('URL has an invalid label.')\n \n         # Carefully reconstruct the network location\n\n@@ -34,9 +34,3 @@ try:\n except ImportError:\n     import chardet\n     sys.modules['%s.chardet' % __name__] = chardet\n-\n-try:\n-    from . import idna\n-except ImportError:\n-    import idna\n-    sys.modules['%s.idna' % __name__] = idna\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#5dcc03945765a7e7b7044b5f41ff5ee8d707c49b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 678 | Contributors (this commit): 16 | Commits (past 90d): 6 | Contributors (cumulative): 16 | DMM Complexity: None\n\nDIFF:\n@@ -41,8 +41,8 @@ is at <http://python-requests.org>.\n \"\"\"\n \n __title__ = 'requests'\n-__version__ = '2.12.4'\n-__build__ = 0x021204\n+__version__ = '2.12.5'\n+__build__ = 0x021205\n __author__ = 'Kenneth Reitz'\n __license__ = 'Apache 2.0'\n __copyright__ = 'Copyright 2016 Kenneth Reitz'\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#97b5bc21d1f95bf31d12bfe52267e62f88f82f9b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 4185 | Contributors (this commit): 53 | Commits (past 90d): 26 | Contributors (cumulative): 53 | DMM Complexity: None\n\nDIFF:\n@@ -632,7 +632,7 @@ class TestRequests:\n         post1 = requests.post(url, data={'some': 'data'})\n         assert post1.status_code == 200\n \n-        with open('requirements.txt') as f:\n+        with open('Pipfile') as f:\n             post2 = requests.post(url, files={'some': f})\n         assert post2.status_code == 200\n \n@@ -692,7 +692,7 @@ class TestRequests:\n         post1 = requests.post(url, data={'some': 'data'})\n         assert post1.status_code == 200\n \n-        with open('requirements.txt') as f:\n+        with open('Pipfile') as f:\n             post2 = requests.post(url, data={'some': 'data'}, files={'some': f})\n         assert post2.status_code == 200\n \n@@ -729,7 +729,7 @@ class TestRequests:\n \n     def test_conflicting_post_params(self, httpbin):\n         url = httpbin('post')\n-        with open('requirements.txt') as f:\n+        with open('Pipfile') as f:\n             pytest.raises(ValueError, \"requests.post(url, data='[{\\\"some\\\": \\\"data\\\"}]', files={'some': f})\")\n             pytest.raises(ValueError, \"requests.post(url, data=u('[{\\\"some\\\": \\\"data\\\"}]'), files={'some': f})\")\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#b5704a63ca335fa5d513083909fb8cc4aab23a91", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 738 | Lines Deleted: 62 | Files Changed: 14 | Hunks: 49 | Methods Changed: 54 | Complexity Δ (Sum/Max): 140/115 | Churn Δ: 800 | Churn Cumulative: 8970 | Contributors (this commit): 21 | Commits (past 90d): 25 | Contributors (cumulative): 86 | DMM Complexity: 0.7239583333333334\n\nDIFF:\n@@ -32,7 +32,7 @@ except ImportError:\n \n __author__ = 'Andrey Petrov (andrey.petrov@shazow.net)'\n __license__ = 'MIT'\n-__version__ = '1.19.1'\n+__version__ = '1.20'\n \n __all__ = (\n     'HTTPConnectionPool',\n\n@@ -56,7 +56,10 @@ port_by_scheme = {\n     'https': 443,\n }\n \n-RECENT_DATE = datetime.date(2014, 1, 1)\n+# When updating RECENT_DATE, move it to\n+# within two years of the current date, and no\n+# earlier than 6 months ago.\n+RECENT_DATE = datetime.date(2016, 1, 1)\n \n \n class DummyConnection(object):\n\n@@ -25,7 +25,7 @@ from .exceptions import (\n )\n from .packages.ssl_match_hostname import CertificateError\n from .packages import six\n-from .packages.six.moves.queue import LifoQueue, Empty, Full\n+from .packages.six.moves import queue\n from .connection import (\n     port_by_scheme,\n     DummyConnection,\n@@ -36,6 +36,7 @@ from .request import RequestMethods\n from .response import HTTPResponse\n \n from .util.connection import is_connection_dropped\n+from .util.request import set_file_position\n from .util.response import assert_header_parsing\n from .util.retry import Retry\n from .util.timeout import Timeout\n@@ -61,19 +62,13 @@ class ConnectionPool(object):\n     \"\"\"\n \n     scheme = None\n-    QueueCls = LifoQueue\n+    QueueCls = queue.LifoQueue\n \n     def __init__(self, host, port=None):\n         if not host:\n             raise LocationValueError(\"No host specified.\")\n \n-        # httplib doesn't like it when we include brackets in ipv6 addresses\n-        # Specifically, if we include brackets but also pass the port then\n-        # httplib crazily doubles up the square brackets on the Host header.\n-        # Instead, we need to make sure we never pass ``None`` as the port.\n-        # However, for backward compatibility reasons we can't actually\n-        # *assert* that.\n-        self.host = host.strip('[]')\n+        self.host = _ipv6_host(host).lower()\n         self.port = port\n \n     def __str__(self):\n@@ -154,7 +149,7 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n         A dictionary with proxy headers, should not be used directly,\n         instead, see :class:`urllib3.connectionpool.ProxyManager`\"\n \n-    :param \\**conn_kw:\n+    :param \\\\**conn_kw:\n         Additional parameters are used to create fresh :class:`urllib3.connection.HTTPConnection`,\n         :class:`urllib3.connection.HTTPSConnection` instances.\n     \"\"\"\n@@ -235,7 +230,7 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n         except AttributeError:  # self.pool is None\n             raise ClosedPoolError(self, \"Pool is closed.\")\n \n-        except Empty:\n+        except queue.Empty:\n             if self.block:\n                 raise EmptyPoolError(self,\n                                      \"Pool reached maximum size and no more \"\n@@ -274,7 +269,7 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n         except AttributeError:\n             # self.pool is None.\n             pass\n-        except Full:\n+        except queue.Full:\n             # This should never happen if self.block == True\n             log.warning(\n                 \"Connection pool is full, discarding connection: %s\",\n@@ -424,7 +419,7 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n                 if conn:\n                     conn.close()\n \n-        except Empty:\n+        except queue.Empty:\n             pass  # Done.\n \n     def is_same_host(self, url):\n@@ -438,6 +433,8 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n         # TODO: Add optional support for socket.gethostbyname checking.\n         scheme, host, port = get_host(url)\n \n+        host = _ipv6_host(host).lower()\n+\n         # Use explicit default port for comparison when none is given\n         if self.port and not port:\n             port = port_by_scheme.get(scheme)\n@@ -449,7 +446,7 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n     def urlopen(self, method, url, body=None, headers=None, retries=None,\n                 redirect=True, assert_same_host=True, timeout=_Default,\n                 pool_timeout=None, release_conn=None, chunked=False,\n-                **response_kw):\n+                body_pos=None, **response_kw):\n         \"\"\"\n         Get a connection from the pool and perform an HTTP request. This is the\n         lowest level call for making a request, so you'll need to specify all\n@@ -531,7 +528,12 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n             encoding. Otherwise, urllib3 will send the body using the standard\n             content-length form. Defaults to False.\n \n-        :param \\**response_kw:\n+        :param int body_pos:\n+            Position to seek to in file-like body in the event of a retry or\n+            redirect. Typically this won't need to be set because urllib3 will\n+            auto-populate the value when needed.\n+\n+        :param \\\\**response_kw:\n             Additional parameters are passed to\n             :meth:`urllib3.response.HTTPResponse.from_httplib`\n         \"\"\"\n@@ -576,6 +578,10 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n         # ensures we do proper cleanup in finally.\n         clean_exit = False\n \n+        # Rewind body position, if needed. Record current position\n+        # for future rewinds in the event of a redirect/retry.\n+        body_pos = set_file_position(body, body_pos)\n+\n         try:\n             # Request a connection from the queue.\n             timeout_obj = self._get_timeout(timeout)\n@@ -612,7 +618,7 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n             # Everything went great!\n             clean_exit = True\n \n-        except Empty:\n+        except queue.Empty:\n             # Timed out by queue.\n             raise EmptyPoolError(self, \"No pool connections are available.\")\n \n@@ -668,7 +674,8 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n             return self.urlopen(method, url, body, headers, retries,\n                                 redirect, assert_same_host,\n                                 timeout=timeout, pool_timeout=pool_timeout,\n-                                release_conn=release_conn, **response_kw)\n+                                release_conn=release_conn, body_pos=body_pos,\n+                                **response_kw)\n \n         # Handle redirect?\n         redirect_location = redirect and response.get_redirect_location()\n@@ -693,7 +700,8 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n                 retries=retries, redirect=redirect,\n                 assert_same_host=assert_same_host,\n                 timeout=timeout, pool_timeout=pool_timeout,\n-                release_conn=release_conn, **response_kw)\n+                release_conn=release_conn, body_pos=body_pos,\n+                **response_kw)\n \n         # Check if we should retry the HTTP response.\n         has_retry_after = bool(response.getheader('Retry-After'))\n@@ -714,7 +722,8 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n                 retries=retries, redirect=redirect,\n                 assert_same_host=assert_same_host,\n                 timeout=timeout, pool_timeout=pool_timeout,\n-                release_conn=release_conn, **response_kw)\n+                release_conn=release_conn,\n+                body_pos=body_pos, **response_kw)\n \n         return response\n \n@@ -853,7 +862,7 @@ def connection_from_url(url, **kw):\n     :param url:\n         Absolute URL string that must include the scheme. Port is optional.\n \n-    :param \\**kw:\n+    :param \\\\**kw:\n         Passes additional parameters to the constructor of the appropriate\n         :class:`.ConnectionPool`. Useful for specifying things like\n         timeout, maxsize, headers, etc.\n@@ -869,3 +878,22 @@ def connection_from_url(url, **kw):\n         return HTTPSConnectionPool(host, port=port, **kw)\n     else:\n         return HTTPConnectionPool(host, port=port, **kw)\n+\n+\n+def _ipv6_host(host):\n+    \"\"\"\n+    Process IPv6 address literals\n+    \"\"\"\n+\n+    # httplib doesn't like it when we include brackets in IPv6 addresses\n+    # Specifically, if we include brackets but also pass the port then\n+    # httplib crazily doubles up the square brackets on the Host header.\n+    # Instead, we need to make sure we never pass ``None`` as the port.\n+    # However, for backward compatibility reasons we can't actually\n+    # *assert* that.  See http://bugs.python.org/issue28539\n+    #\n+    # Also if an IPv6 address literal has a zone identifier, the\n+    # percent sign might be URIencoded, convert it back into ASCII\n+    if host.startswith('[') and host.endswith(']'):\n+        host = host.replace('%25', '%').strip('[]')\n+    return host\n\n@@ -43,7 +43,6 @@ set the ``urllib3.contrib.pyopenssl.DEFAULT_SSL_CIPHER_LIST`` variable.\n \"\"\"\n from __future__ import absolute_import\n \n-import idna\n import OpenSSL.SSL\n from cryptography import x509\n from cryptography.hazmat.backends.openssl import backend as openssl_backend\n@@ -60,7 +59,6 @@ except ImportError:  # Platform-specific: Python 3\n \n import logging\n import ssl\n-import select\n import six\n import sys\n \n@@ -111,6 +109,8 @@ log = logging.getLogger(__name__)\n def inject_into_urllib3():\n     'Monkey-patch urllib3 with PyOpenSSL-backed SSL-support.'\n \n+    _validate_dependencies_met()\n+\n     util.ssl_.SSLContext = PyOpenSSLContext\n     util.HAS_SNI = HAS_SNI\n     util.ssl_.HAS_SNI = HAS_SNI\n@@ -128,6 +128,26 @@ def extract_from_urllib3():\n     util.ssl_.IS_PYOPENSSL = False\n \n \n+def _validate_dependencies_met():\n+    \"\"\"\n+    Verifies that PyOpenSSL's package-level dependencies have been met.\n+    Throws `ImportError` if they are not met.\n+    \"\"\"\n+    # Method added in `cryptography==1.1`; not available in older versions\n+    from cryptography.x509.extensions import Extensions\n+    if getattr(Extensions, \"get_extension_for_class\", None) is None:\n+        raise ImportError(\"'cryptography' module missing required functionality.  \"\n+                          \"Try upgrading to v1.3.4 or newer.\")\n+\n+    # pyOpenSSL 0.14 and above use cryptography for OpenSSL bindings. The _x509\n+    # attribute is only present on those versions.\n+    from OpenSSL.crypto import X509\n+    x509 = X509()\n+    if getattr(x509, \"_x509\", None) is None:\n+        raise ImportError(\"'pyOpenSSL' module missing required functionality. \"\n+                          \"Try upgrading to v0.14 or newer.\")\n+\n+\n def _dnsname_to_stdlib(name):\n     \"\"\"\n     Converts a dNSName SubjectAlternativeName field to the form used by the\n@@ -144,6 +164,8 @@ def _dnsname_to_stdlib(name):\n         that we can't just safely call `idna.encode`: it can explode for\n         wildcard names. This avoids that problem.\n         \"\"\"\n+        import idna\n+\n         for prefix in [u'*.', u'.']:\n             if name.startswith(prefix):\n                 name = name[len(prefix):]\n@@ -242,8 +264,7 @@ class WrappedSocket(object):\n             else:\n                 raise\n         except OpenSSL.SSL.WantReadError:\n-            rd, wd, ed = select.select(\n-                [self.socket], [], [], self.socket.gettimeout())\n+            rd = util.wait_for_read(self.socket, self.socket.gettimeout())\n             if not rd:\n                 raise timeout('The read operation timed out')\n             else:\n@@ -265,8 +286,7 @@ class WrappedSocket(object):\n             else:\n                 raise\n         except OpenSSL.SSL.WantReadError:\n-            rd, wd, ed = select.select(\n-                [self.socket], [], [], self.socket.gettimeout())\n+            rd = util.wait_for_read(self.socket, self.socket.gettimeout())\n             if not rd:\n                 raise timeout('The read operation timed out')\n             else:\n@@ -280,9 +300,8 @@ class WrappedSocket(object):\n             try:\n                 return self.connection.send(data)\n             except OpenSSL.SSL.WantWriteError:\n-                _, wlist, _ = select.select([], [self.socket], [],\n-                                            self.socket.gettimeout())\n-                if not wlist:\n+                wr = util.wait_for_write(self.socket, self.socket.gettimeout())\n+                if not wr:\n                     raise timeout()\n                 continue\n \n@@ -416,7 +435,7 @@ class PyOpenSSLContext(object):\n             try:\n                 cnx.do_handshake()\n             except OpenSSL.SSL.WantReadError:\n-                rd, _, _ = select.select([sock], [], [], sock.gettimeout())\n+                rd = util.wait_for_read(sock, sock.gettimeout())\n                 if not rd:\n                     raise timeout('select timed out')\n                 continue\n\n@@ -83,6 +83,7 @@ class SOCKSConnection(HTTPConnection):\n                 proxy_port=self._socks_options['proxy_port'],\n                 proxy_username=self._socks_options['username'],\n                 proxy_password=self._socks_options['password'],\n+                proxy_rdns=self._socks_options['rdns'],\n                 timeout=self.timeout,\n                 **extra_kw\n             )\n@@ -153,8 +154,16 @@ class SOCKSProxyManager(PoolManager):\n \n         if parsed.scheme == 'socks5':\n             socks_version = socks.PROXY_TYPE_SOCKS5\n+            rdns = False\n+        elif parsed.scheme == 'socks5h':\n+            socks_version = socks.PROXY_TYPE_SOCKS5\n+            rdns = True\n         elif parsed.scheme == 'socks4':\n             socks_version = socks.PROXY_TYPE_SOCKS4\n+            rdns = False\n+        elif parsed.scheme == 'socks4a':\n+            socks_version = socks.PROXY_TYPE_SOCKS4\n+            rdns = True\n         else:\n             raise ValueError(\n                 \"Unable to determine SOCKS version from %s\" % proxy_url\n@@ -168,6 +177,7 @@ class SOCKSProxyManager(PoolManager):\n             'proxy_port': parsed.port,\n             'username': username,\n             'password': password,\n+            'rdns': rdns\n         }\n         connection_pool_kw['_socks_options'] = socks_options\n \n\n@@ -239,3 +239,8 @@ class HeaderParsingError(HTTPError):\n     def __init__(self, defects, unparsed_data):\n         message = '%s, unparsed data: %r' % (defects or 'Unknown', unparsed_data)\n         super(HeaderParsingError, self).__init__(message)\n+\n+\n+class UnrewindableBodyError(HTTPError):\n+    \"urllib3 encountered an error when trying to rewind a body\"\n+    pass\n\n@@ -93,7 +93,7 @@ class PoolManager(RequestMethods):\n         Headers to include with all requests, unless other headers are given\n         explicitly.\n \n-    :param \\**connection_pool_kw:\n+    :param \\\\**connection_pool_kw:\n         Additional parameters are used to create fresh\n         :class:`urllib3.connectionpool.ConnectionPool` instances.\n \n\n@@ -24,6 +24,10 @@ from .url import (\n     split_first,\n     Url,\n )\n+from .wait import (\n+    wait_for_read,\n+    wait_for_write\n+)\n \n __all__ = (\n     'HAS_SNI',\n@@ -43,4 +47,6 @@ __all__ = (\n     'resolve_ssl_version',\n     'split_first',\n     'ssl_wrap_socket',\n+    'wait_for_read',\n+    'wait_for_write'\n )\n\n@@ -1,13 +1,7 @@\n from __future__ import absolute_import\n import socket\n-try:\n-    from select import poll, POLLIN\n-except ImportError:  # `poll` doesn't exist on OSX and other platforms\n-    poll = False\n-    try:\n-        from select import select\n-    except ImportError:  # `select` doesn't exist on AppEngine.\n-        select = False\n+from .wait import wait_for_read\n+from .selectors import HAS_SELECT, SelectorError\n \n \n def is_connection_dropped(conn):  # Platform-specific\n@@ -26,21 +20,12 @@ def is_connection_dropped(conn):  # Platform-specific\n     if sock is None:  # Connection already closed (such as by httplib).\n         return True\n \n-    if not poll:\n-        if not select:  # Platform-specific: AppEngine\n+    if not HAS_SELECT:\n         return False\n \n     try:\n-            return select([sock], [], [], 0.0)[0]\n-        except socket.error:\n-            return True\n-\n-    # This version is better on platforms that support it.\n-    p = poll()\n-    p.register(sock, POLLIN)\n-    for (fno, ev) in p.poll(0.0):\n-        if fno == sock.fileno():\n-            # Either data is buffered (bad), or the connection is dropped.\n+        return bool(wait_for_read(sock, timeout=0.0))\n+    except SelectorError:\n         return True\n \n \n\n@@ -1,9 +1,11 @@\n from __future__ import absolute_import\n from base64 import b64encode\n \n-from ..packages.six import b\n+from ..packages.six import b, integer_types\n+from ..exceptions import UnrewindableBodyError\n \n ACCEPT_ENCODING = 'gzip,deflate'\n+_FAILEDTELL = object()\n \n \n def make_headers(keep_alive=None, accept_encoding=None, user_agent=None,\n@@ -70,3 +72,47 @@ def make_headers(keep_alive=None, accept_encoding=None, user_agent=None,\n         headers['cache-control'] = 'no-cache'\n \n     return headers\n+\n+\n+def set_file_position(body, pos):\n+    \"\"\"\n+    If a position is provided, move file to that point.\n+    Otherwise, we'll attempt to record a position for future use.\n+    \"\"\"\n+    if pos is not None:\n+        rewind_body(body, pos)\n+    elif getattr(body, 'tell', None) is not None:\n+        try:\n+            pos = body.tell()\n+        except (IOError, OSError):\n+            # This differentiates from None, allowing us to catch\n+            # a failed `tell()` later when trying to rewind the body.\n+            pos = _FAILEDTELL\n+\n+    return pos\n+\n+\n+def rewind_body(body, body_pos):\n+    \"\"\"\n+    Attempt to rewind body to a certain position.\n+    Primarily used for request redirects and retries.\n+\n+    :param body:\n+        File-like object that supports seek.\n+\n+    :param int pos:\n+        Position to seek to in file.\n+    \"\"\"\n+    body_seek = getattr(body, 'seek', None)\n+    if body_seek is not None and isinstance(body_pos, integer_types):\n+        try:\n+            body_seek(body_pos)\n+        except (IOError, OSError):\n+            raise UnrewindableBodyError(\"An error occured when rewinding request \"\n+                                        \"body for redirect/retry.\")\n+    elif body_pos is _FAILEDTELL:\n+        raise UnrewindableBodyError(\"Unable to record file position for rewinding \"\n+                                    \"request body during a redirect/retry.\")\n+    else:\n+        raise ValueError(\"body_pos must be of type integer, \"\n+                         \"instead it was %s.\" % type(body_pos))\n\n@@ -273,12 +273,25 @@ class Retry(object):\n         \"\"\"\n         return isinstance(err, (ReadTimeoutError, ProtocolError))\n \n-    def is_retry(self, method, status_code, has_retry_after=False):\n-        \"\"\" Is this method/status code retryable? (Based on method/codes whitelists)\n+    def _is_method_retryable(self, method):\n+        \"\"\" Checks if a given HTTP method should be retried upon, depending if\n+        it is included on the method whitelist.\n         \"\"\"\n         if self.method_whitelist and method.upper() not in self.method_whitelist:\n             return False\n \n+        return True\n+\n+    def is_retry(self, method, status_code, has_retry_after=False):\n+        \"\"\" Is this method/status code retryable? (Based on whitelists and control\n+        variables such as the number of total retries to allow, whether to\n+        respect the Retry-After header, whether this header is present, and\n+        whether the returned status code is on the list of status codes to\n+        be retried upon on the presence of the aforementioned header)\n+        \"\"\"\n+        if not self._is_method_retryable(method):\n+            return False\n+\n         if self.status_forcelist and status_code in self.status_forcelist:\n             return True\n \n@@ -330,7 +343,7 @@ class Retry(object):\n \n         elif error and self._is_read_error(error):\n             # Read retry?\n-            if read is False:\n+            if read is False or not self._is_method_retryable(method):\n                 raise six.reraise(type(error), error, _stacktrace)\n             elif read is not None:\n                 read -= 1\n\n@@ -0,0 +1,524 @@\n+# Backport of selectors.py from Python 3.5+ to support Python < 3.4\n+# Also has the behavior specified in PEP 475 which is to retry syscalls\n+# in the case of an EINTR error. This module is required because selectors34\n+# does not follow this behavior and instead returns that no dile descriptor\n+# events have occurred rather than retry the syscall. The decision to drop\n+# support for select.devpoll is made to maintain 100% test coverage.\n+\n+import errno\n+import math\n+import select\n+from collections import namedtuple, Mapping\n+\n+import time\n+try:\n+    monotonic = time.monotonic\n+except (AttributeError, ImportError):  # Python 3.3<\n+    monotonic = time.time\n+\n+EVENT_READ = (1 << 0)\n+EVENT_WRITE = (1 << 1)\n+\n+HAS_SELECT = True  # Variable that shows whether the platform has a selector.\n+_SYSCALL_SENTINEL = object()  # Sentinel in case a system call returns None.\n+\n+\n+class SelectorError(Exception):\n+    def __init__(self, errcode):\n+        super(SelectorError, self).__init__()\n+        self.errno = errcode\n+\n+    def __repr__(self):\n+        return \"<SelectorError errno={0}>\".format(self.errno)\n+\n+    def __str__(self):\n+        return self.__repr__()\n+\n+\n+def _fileobj_to_fd(fileobj):\n+    \"\"\" Return a file descriptor from a file object. If\n+    given an integer will simply return that integer back. \"\"\"\n+    if isinstance(fileobj, int):\n+        fd = fileobj\n+    else:\n+        try:\n+            fd = int(fileobj.fileno())\n+        except (AttributeError, TypeError, ValueError):\n+            raise ValueError(\"Invalid file object: {0!r}\".format(fileobj))\n+    if fd < 0:\n+        raise ValueError(\"Invalid file descriptor: {0}\".format(fd))\n+    return fd\n+\n+\n+def _syscall_wrapper(func, recalc_timeout, *args, **kwargs):\n+    \"\"\" Wrapper function for syscalls that could fail due to EINTR.\n+    All functions should be retried if there is time left in the timeout\n+    in accordance with PEP 475. \"\"\"\n+    timeout = kwargs.get(\"timeout\", None)\n+    if timeout is None:\n+        expires = None\n+        recalc_timeout = False\n+    else:\n+        timeout = float(timeout)\n+        if timeout < 0.0:  # Timeout less than 0 treated as no timeout.\n+            expires = None\n+        else:\n+            expires = monotonic() + timeout\n+\n+    args = list(args)\n+    if recalc_timeout and \"timeout\" not in kwargs:\n+        raise ValueError(\n+            \"Timeout must be in args or kwargs to be recalculated\")\n+\n+    result = _SYSCALL_SENTINEL\n+    while result is _SYSCALL_SENTINEL:\n+        try:\n+            result = func(*args, **kwargs)\n+        # OSError is thrown by select.select\n+        # IOError is thrown by select.epoll.poll\n+        # select.error is thrown by select.poll.poll\n+        # Aren't we thankful for Python 3.x rework for exceptions?\n+        except (OSError, IOError, select.error) as e:\n+            # select.error wasn't a subclass of OSError in the past.\n+            errcode = None\n+            if hasattr(e, \"errno\"):\n+                errcode = e.errno\n+            elif hasattr(e, \"args\"):\n+                errcode = e.args[0]\n+\n+            # Also test for the Windows equivalent of EINTR.\n+            is_interrupt = (errcode == errno.EINTR or (hasattr(errno, \"WSAEINTR\") and\n+                                                       errcode == errno.WSAEINTR))\n+\n+            if is_interrupt:\n+                if expires is not None:\n+                    current_time = monotonic()\n+                    if current_time > expires:\n+                        raise OSError(errno=errno.ETIMEDOUT)\n+                    if recalc_timeout:\n+                        if \"timeout\" in kwargs:\n+                            kwargs[\"timeout\"] = expires - current_time\n+                continue\n+            if errcode:\n+                raise SelectorError(errcode)\n+            else:\n+                raise\n+    return result\n+\n+\n+SelectorKey = namedtuple('SelectorKey', ['fileobj', 'fd', 'events', 'data'])\n+\n+\n+class _SelectorMapping(Mapping):\n+    \"\"\" Mapping of file objects to selector keys \"\"\"\n+\n+    def __init__(self, selector):\n+        self._selector = selector\n+\n+    def __len__(self):\n+        return len(self._selector._fd_to_key)\n+\n+    def __getitem__(self, fileobj):\n+        try:\n+            fd = self._selector._fileobj_lookup(fileobj)\n+            return self._selector._fd_to_key[fd]\n+        except KeyError:\n+            raise KeyError(\"{0!r} is not registered.\".format(fileobj))\n+\n+    def __iter__(self):\n+        return iter(self._selector._fd_to_key)\n+\n+\n+class BaseSelector(object):\n+    \"\"\" Abstract Selector class\n+\n+    A selector supports registering file objects to be monitored\n+    for specific I/O events.\n+\n+    A file object is a file descriptor or any object with a\n+    `fileno()` method. An arbitrary object can be attached to the\n+    file object which can be used for example to store context info,\n+    a callback, etc.\n+\n+    A selector can use various implementations (select(), poll(), epoll(),\n+    and kqueue()) depending on the platform. The 'DefaultSelector' class uses\n+    the most efficient implementation for the current platform.\n+    \"\"\"\n+    def __init__(self):\n+        # Maps file descriptors to keys.\n+        self._fd_to_key = {}\n+\n+        # Read-only mapping returned by get_map()\n+        self._map = _SelectorMapping(self)\n+\n+    def _fileobj_lookup(self, fileobj):\n+        \"\"\" Return a file descriptor from a file object.\n+        This wraps _fileobj_to_fd() to do an exhaustive\n+        search in case the object is invalid but we still\n+        have it in our map. Used by unregister() so we can\n+        unregister an object that was previously registered\n+        even if it is closed. It is also used by _SelectorMapping\n+        \"\"\"\n+        try:\n+            return _fileobj_to_fd(fileobj)\n+        except ValueError:\n+\n+            # Search through all our mapped keys.\n+            for key in self._fd_to_key.values():\n+                if key.fileobj is fileobj:\n+                    return key.fd\n+\n+            # Raise ValueError after all.\n+            raise\n+\n+    def register(self, fileobj, events, data=None):\n+        \"\"\" Register a file object for a set of events to monitor. \"\"\"\n+        if (not events) or (events & ~(EVENT_READ | EVENT_WRITE)):\n+            raise ValueError(\"Invalid events: {0!r}\".format(events))\n+\n+        key = SelectorKey(fileobj, self._fileobj_lookup(fileobj), events, data)\n+\n+        if key.fd in self._fd_to_key:\n+            raise KeyError(\"{0!r} (FD {1}) is already registered\"\n+                           .format(fileobj, key.fd))\n+\n+        self._fd_to_key[key.fd] = key\n+        return key\n+\n+    def unregister(self, fileobj):\n+        \"\"\" Unregister a file object from being monitored. \"\"\"\n+        try:\n+            key = self._fd_to_key.pop(self._fileobj_lookup(fileobj))\n+        except KeyError:\n+            raise KeyError(\"{0!r} is not registered\".format(fileobj))\n+        return key\n+\n+    def modify(self, fileobj, events, data=None):\n+        \"\"\" Change a registered file object monitored events and data. \"\"\"\n+        # NOTE: Some subclasses optimize this operation even further.\n+        try:\n+            key = self._fd_to_key[self._fileobj_lookup(fileobj)]\n+        except KeyError:\n+            raise KeyError(\"{0!r} is not registered\".format(fileobj))\n+\n+        if events != key.events:\n+            self.unregister(fileobj)\n+            key = self.register(fileobj, events, data)\n+\n+        elif data != key.data:\n+            # Use a shortcut to update the data.\n+            key = key._replace(data=data)\n+            self._fd_to_key[key.fd] = key\n+\n+        return key\n+\n+    def select(self, timeout=None):\n+        \"\"\" Perform the actual selection until some monitored file objects\n+        are ready or the timeout expires. \"\"\"\n+        raise NotImplementedError()\n+\n+    def close(self):\n+        \"\"\" Close the selector. This must be called to ensure that all\n+        underlying resources are freed. \"\"\"\n+        self._fd_to_key.clear()\n+        self._map = None\n+\n+    def get_key(self, fileobj):\n+        \"\"\" Return the key associated with a registered file object. \"\"\"\n+        mapping = self.get_map()\n+        if mapping is None:\n+            raise RuntimeError(\"Selector is closed\")\n+        try:\n+            return mapping[fileobj]\n+        except KeyError:\n+            raise KeyError(\"{0!r} is not registered\".format(fileobj))\n+\n+    def get_map(self):\n+        \"\"\" Return a mapping of file objects to selector keys \"\"\"\n+        return self._map\n+\n+    def _key_from_fd(self, fd):\n+        \"\"\" Return the key associated to a given file descriptor\n+         Return None if it is not found. \"\"\"\n+        try:\n+            return self._fd_to_key[fd]\n+        except KeyError:\n+            return None\n+\n+    def __enter__(self):\n+        return self\n+\n+    def __exit__(self, *args):\n+        self.close()\n+\n+\n+# Almost all platforms have select.select()\n+if hasattr(select, \"select\"):\n+    class SelectSelector(BaseSelector):\n+        \"\"\" Select-based selector. \"\"\"\n+        def __init__(self):\n+            super(SelectSelector, self).__init__()\n+            self._readers = set()\n+            self._writers = set()\n+\n+        def register(self, fileobj, events, data=None):\n+            key = super(SelectSelector, self).register(fileobj, events, data)\n+            if events & EVENT_READ:\n+                self._readers.add(key.fd)\n+            if events & EVENT_WRITE:\n+                self._writers.add(key.fd)\n+            return key\n+\n+        def unregister(self, fileobj):\n+            key = super(SelectSelector, self).unregister(fileobj)\n+            self._readers.discard(key.fd)\n+            self._writers.discard(key.fd)\n+            return key\n+\n+        def _select(self, r, w, timeout=None):\n+            \"\"\" Wrapper for select.select because timeout is a positional arg \"\"\"\n+            return select.select(r, w, [], timeout)\n+\n+        def select(self, timeout=None):\n+            # Selecting on empty lists on Windows errors out.\n+            if not len(self._readers) and not len(self._writers):\n+                return []\n+\n+            timeout = None if timeout is None else max(timeout, 0.0)\n+            ready = []\n+            r, w, _ = _syscall_wrapper(self._select, True, self._readers,\n+                                       self._writers, timeout)\n+            r = set(r)\n+            w = set(w)\n+            for fd in r | w:\n+                events = 0\n+                if fd in r:\n+                    events |= EVENT_READ\n+                if fd in w:\n+                    events |= EVENT_WRITE\n+\n+                key = self._key_from_fd(fd)\n+                if key:\n+                    ready.append((key, events & key.events))\n+            return ready\n+\n+\n+if hasattr(select, \"poll\"):\n+    class PollSelector(BaseSelector):\n+        \"\"\" Poll-based selector \"\"\"\n+        def __init__(self):\n+            super(PollSelector, self).__init__()\n+            self._poll = select.poll()\n+\n+        def register(self, fileobj, events, data=None):\n+            key = super(PollSelector, self).register(fileobj, events, data)\n+            event_mask = 0\n+            if events & EVENT_READ:\n+                event_mask |= select.POLLIN\n+            if events & EVENT_WRITE:\n+                event_mask |= select.POLLOUT\n+            self._poll.register(key.fd, event_mask)\n+            return key\n+\n+        def unregister(self, fileobj):\n+            key = super(PollSelector, self).unregister(fileobj)\n+            self._poll.unregister(key.fd)\n+            return key\n+\n+        def _wrap_poll(self, timeout=None):\n+            \"\"\" Wrapper function for select.poll.poll() so that\n+            _syscall_wrapper can work with only seconds. \"\"\"\n+            if timeout is not None:\n+                if timeout <= 0:\n+                    timeout = 0\n+                else:\n+                    # select.poll.poll() has a resolution of 1 millisecond,\n+                    # round away from zero to wait *at least* timeout seconds.\n+                    timeout = math.ceil(timeout * 1e3)\n+\n+            result = self._poll.poll(timeout)\n+            return result\n+\n+        def select(self, timeout=None):\n+            ready = []\n+            fd_events = _syscall_wrapper(self._wrap_poll, True, timeout=timeout)\n+            for fd, event_mask in fd_events:\n+                events = 0\n+                if event_mask & ~select.POLLIN:\n+                    events |= EVENT_WRITE\n+                if event_mask & ~select.POLLOUT:\n+                    events |= EVENT_READ\n+\n+                key = self._key_from_fd(fd)\n+                if key:\n+                    ready.append((key, events & key.events))\n+\n+            return ready\n+\n+\n+if hasattr(select, \"epoll\"):\n+    class EpollSelector(BaseSelector):\n+        \"\"\" Epoll-based selector \"\"\"\n+        def __init__(self):\n+            super(EpollSelector, self).__init__()\n+            self._epoll = select.epoll()\n+\n+        def fileno(self):\n+            return self._epoll.fileno()\n+\n+        def register(self, fileobj, events, data=None):\n+            key = super(EpollSelector, self).register(fileobj, events, data)\n+            events_mask = 0\n+            if events & EVENT_READ:\n+                events_mask |= select.EPOLLIN\n+            if events & EVENT_WRITE:\n+                events_mask |= select.EPOLLOUT\n+            _syscall_wrapper(self._epoll.register, False, key.fd, events_mask)\n+            return key\n+\n+        def unregister(self, fileobj):\n+            key = super(EpollSelector, self).unregister(fileobj)\n+            try:\n+                _syscall_wrapper(self._epoll.unregister, False, key.fd)\n+            except SelectorError:\n+                # This can occur when the fd was closed since registry.\n+                pass\n+            return key\n+\n+        def select(self, timeout=None):\n+            if timeout is not None:\n+                if timeout <= 0:\n+                    timeout = 0.0\n+                else:\n+                    # select.epoll.poll() has a resolution of 1 millisecond\n+                    # but luckily takes seconds so we don't need a wrapper\n+                    # like PollSelector. Just for better rounding.\n+                    timeout = math.ceil(timeout * 1e3) * 1e-3\n+                timeout = float(timeout)\n+            else:\n+                timeout = -1.0  # epoll.poll() must have a float.\n+\n+            # We always want at least 1 to ensure that select can be called\n+            # with no file descriptors registered. Otherwise will fail.\n+            max_events = max(len(self._fd_to_key), 1)\n+\n+            ready = []\n+            fd_events = _syscall_wrapper(self._epoll.poll, True,\n+                                         timeout=timeout,\n+                                         maxevents=max_events)\n+            for fd, event_mask in fd_events:\n+                events = 0\n+                if event_mask & ~select.EPOLLIN:\n+                    events |= EVENT_WRITE\n+                if event_mask & ~select.EPOLLOUT:\n+                    events |= EVENT_READ\n+\n+                key = self._key_from_fd(fd)\n+                if key:\n+                    ready.append((key, events & key.events))\n+            return ready\n+\n+        def close(self):\n+            self._epoll.close()\n+            super(EpollSelector, self).close()\n+\n+\n+if hasattr(select, \"kqueue\"):\n+    class KqueueSelector(BaseSelector):\n+        \"\"\" Kqueue / Kevent-based selector \"\"\"\n+        def __init__(self):\n+            super(KqueueSelector, self).__init__()\n+            self._kqueue = select.kqueue()\n+\n+        def fileno(self):\n+            return self._kqueue.fileno()\n+\n+        def register(self, fileobj, events, data=None):\n+            key = super(KqueueSelector, self).register(fileobj, events, data)\n+            if events & EVENT_READ:\n+                kevent = select.kevent(key.fd,\n+                                       select.KQ_FILTER_READ,\n+                                       select.KQ_EV_ADD)\n+\n+                _syscall_wrapper(self._kqueue.control, False, [kevent], 0, 0)\n+\n+            if events & EVENT_WRITE:\n+                kevent = select.kevent(key.fd,\n+                                       select.KQ_FILTER_WRITE,\n+                                       select.KQ_EV_ADD)\n+\n+                _syscall_wrapper(self._kqueue.control, False, [kevent], 0, 0)\n+\n+            return key\n+\n+        def unregister(self, fileobj):\n+            key = super(KqueueSelector, self).unregister(fileobj)\n+            if key.events & EVENT_READ:\n+                kevent = select.kevent(key.fd,\n+                                       select.KQ_FILTER_READ,\n+                                       select.KQ_EV_DELETE)\n+                try:\n+                    _syscall_wrapper(self._kqueue.control, False, [kevent], 0, 0)\n+                except SelectorError:\n+                    pass\n+            if key.events & EVENT_WRITE:\n+                kevent = select.kevent(key.fd,\n+                                       select.KQ_FILTER_WRITE,\n+                                       select.KQ_EV_DELETE)\n+                try:\n+                    _syscall_wrapper(self._kqueue.control, False, [kevent], 0, 0)\n+                except SelectorError:\n+                    pass\n+\n+            return key\n+\n+        def select(self, timeout=None):\n+            if timeout is not None:\n+                timeout = max(timeout, 0)\n+\n+            max_events = len(self._fd_to_key) * 2\n+            ready_fds = {}\n+\n+            kevent_list = _syscall_wrapper(self._kqueue.control, True,\n+                                           None, max_events, timeout)\n+\n+            for kevent in kevent_list:\n+                fd = kevent.ident\n+                event_mask = kevent.filter\n+                events = 0\n+                if event_mask == select.KQ_FILTER_READ:\n+                    events |= EVENT_READ\n+                if event_mask == select.KQ_FILTER_WRITE:\n+                    events |= EVENT_WRITE\n+\n+                key = self._key_from_fd(fd)\n+                if key:\n+                    if key.fd not in ready_fds:\n+                        ready_fds[key.fd] = (key, events & key.events)\n+                    else:\n+                        old_events = ready_fds[key.fd][1]\n+                        ready_fds[key.fd] = (key, (events | old_events) & key.events)\n+\n+            return list(ready_fds.values())\n+\n+        def close(self):\n+            self._kqueue.close()\n+            super(KqueueSelector, self).close()\n+\n+\n+# Choose the best implementation, roughly:\n+# kqueue == epoll > poll > select. Devpoll not supported. (See above)\n+# select() also can't accept a FD > FD_SETSIZE (usually around 1024)\n+if 'KqueueSelector' in globals():  # Platform-specific: Mac OS and BSD\n+    DefaultSelector = KqueueSelector\n+elif 'EpollSelector' in globals():  # Platform-specific: Linux\n+    DefaultSelector = EpollSelector\n+elif 'PollSelector' in globals():  # Platform-specific: Linux\n+    DefaultSelector = PollSelector\n+elif 'SelectSelector' in globals():  # Platform-specific: Windows\n+    DefaultSelector = SelectSelector\n+else:  # Platform-specific: AppEngine\n+    def no_selector(_):\n+        raise ValueError(\"Platform does not have a selector\")\n+    DefaultSelector = no_selector\n+    HAS_SELECT = False\n\n@@ -11,11 +11,8 @@ from ..exceptions import TimeoutStateError\n _Default = object()\n \n \n-def current_time():\n-    \"\"\"\n-    Retrieve the current time. This function is mocked out in unit testing.\n-    \"\"\"\n-    return time.time()\n+# Use time.monotonic if available.\n+current_time = getattr(time, \"monotonic\", time.time)\n \n \n class Timeout(object):\n\n@@ -0,0 +1,40 @@\n+from .selectors import (\n+    HAS_SELECT,\n+    DefaultSelector,\n+    EVENT_READ,\n+    EVENT_WRITE\n+)\n+\n+\n+def _wait_for_io_events(socks, events, timeout=None):\n+    \"\"\" Waits for IO events to be available from a list of sockets\n+    or optionally a single socket if passed in. Returns a list of\n+    sockets that can be interacted with immediately. \"\"\"\n+    if not HAS_SELECT:\n+        raise ValueError('Platform does not have a selector')\n+    if not isinstance(socks, list):\n+        # Probably just a single socket.\n+        if hasattr(socks, \"fileno\"):\n+            socks = [socks]\n+        # Otherwise it might be a non-list iterable.\n+        else:\n+            socks = list(socks)\n+    with DefaultSelector() as selector:\n+        for sock in socks:\n+            selector.register(sock, events)\n+        return [key[0].fileobj for key in\n+                selector.select(timeout) if key[1] & events]\n+\n+\n+def wait_for_read(socks, timeout=None):\n+    \"\"\" Waits for reading to be available from a list of sockets\n+    or optionally a single socket if passed in. Returns a list of\n+    sockets that can be read from immediately. \"\"\"\n+    return _wait_for_io_events(socks, EVENT_READ, timeout)\n+\n+\n+def wait_for_write(socks, timeout=None):\n+    \"\"\" Waits for writing to be available from a list of sockets\n+    or optionally a single socket if passed in. Returns a list of\n+    sockets that can be written to immediately. \"\"\"\n+    return _wait_for_io_events(socks, EVENT_WRITE, timeout)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
