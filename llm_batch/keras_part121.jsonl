{"custom_id": "keras#b89a93faae8237561181f3d22b164de5b6dc728c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 175 | Contributors (this commit): 4 | Commits (past 90d): 2 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -11,7 +11,7 @@ from keras.preprocessing import sequence\n from keras.models import Sequential\n from keras.layers import Dense, Dropout, Activation\n from keras.layers import Embedding\n-from keras.layers import LSTM, GRU, SimpleRNN\n+from keras.layers import LSTM\n from keras.layers import Convolution1D, MaxPooling1D\n from keras.datasets import imdb\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#70ebb15a333ee543e72770c1613767a64ffb1ca6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 62 | Lines Deleted: 11 | Files Changed: 3 | Hunks: 23 | Methods Changed: 19 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 73 | Churn Cumulative: 9031 | Contributors (this commit): 56 | Commits (past 90d): 24 | Contributors (cumulative): 63 | DMM Complexity: None\n\nDIFF:\n@@ -40,6 +40,7 @@ Index\n     Sequence preprocessing\n \n Objectives\n+Metrics\n Optimizers\n Activations\n Callbacks\n@@ -79,6 +80,7 @@ from keras import callbacks\n from keras import models\n from keras.engine import topology\n from keras import objectives\n+from keras import metrics\n from keras import backend\n from keras import constraints\n from keras import activations\n@@ -225,7 +227,10 @@ PAGES = [\n         'page': 'layers/wrappers.md',\n         'all_module_classes': [wrappers],\n     },\n-\n+    {\n+        'page': 'metrics.md',\n+        'all_module_functions': [metrics],\n+    },\n     {\n         'page': 'optimizers.md',\n         'all_module_classes': [optimizers],\n\n@@ -4,86 +4,131 @@ from .utils.generic_utils import get_from_module\n \n \n def binary_accuracy(y_true, y_pred):\n+    '''Calculates the mean accuracy rate across all predictions for binary\n+    classification problems\n+    '''\n     return K.mean(K.equal(y_true, K.round(y_pred)))\n \n \n def categorical_accuracy(y_true, y_pred):\n+    '''Calculates the mean accuracy rate across all predictions for\n+    multiclass classification problems\n+    '''\n     return K.mean(K.equal(K.argmax(y_true, axis=-1),\n                   K.argmax(y_pred, axis=-1)))\n \n \n def sparse_categorical_accuracy(y_true, y_pred):\n+    '''Same as categorical_accuracy, but useful when the predictions are for\n+    sparse targets\n+    '''\n     return K.mean(K.equal(K.max(y_true, axis=-1),\n                           K.cast(K.argmax(y_pred, axis=-1), K.floatx())))\n \n \n def top_k_categorical_accuracy(y_true, y_pred, k=5):\n+    '''Calculates the top-k categorical accuracy rate, i.e. success when the\n+    target class is within the top-k predictions provided\n+    '''\n     return K.mean(K.in_top_k(y_pred, K.argmax(y_true, axis=-1), k))\n \n \n def mean_squared_error(y_true, y_pred):\n+    '''Calculates the mean squared error (mse) rate between predicted and target\n+    values\n+    '''\n     return K.mean(K.square(y_pred - y_true))\n \n \n def mean_absolute_error(y_true, y_pred):\n+    '''Calculates the mean absolute error (mae) rate between predicted and target\n+    values\n+    '''\n     return K.mean(K.abs(y_pred - y_true))\n \n \n def mean_absolute_percentage_error(y_true, y_pred):\n+    '''Calculates the mean absolute percentage error (mape) rate between predicted\n+    and target values\n+    '''\n     diff = K.abs((y_true - y_pred) / K.clip(K.abs(y_true), K.epsilon(), np.inf))\n     return 100. * K.mean(diff)\n \n \n def mean_squared_logarithmic_error(y_true, y_pred):\n+    '''Calculates the mean squared logarithmic error (msle) rate between predicted\n+    and target values\n+    '''\n     first_log = K.log(K.clip(y_pred, K.epsilon(), np.inf) + 1.)\n     second_log = K.log(K.clip(y_true, K.epsilon(), np.inf) + 1.)\n     return K.mean(K.square(first_log - second_log))\n \n \n-def squared_hinge(y_true, y_pred):\n-    return K.mean(K.square(K.maximum(1. - y_true * y_pred, 0.)))\n-\n-\n def hinge(y_true, y_pred):\n+    '''Calculates the hinge loss, which is defined as\n+    `max(1 - y_true * y_pred, 0)`\n+    '''\n     return K.mean(K.maximum(1. - y_true * y_pred, 0.))\n \n \n+def squared_hinge(y_true, y_pred):\n+    '''Calculates the squared value of the hinge loss\n+    '''\n+    return K.mean(K.square(K.maximum(1. - y_true * y_pred, 0.)))\n+\n+\n def categorical_crossentropy(y_true, y_pred):\n-    '''Expects a binary class matrix instead of a vector of scalar classes.\n+    '''Calculates the cross-entropy value for multiclass classification\n+    problems. Note: Expects a binary class matrix instead of a vector\n+    of scalar classes.\n     '''\n     return K.mean(K.categorical_crossentropy(y_pred, y_true))\n \n \n def sparse_categorical_crossentropy(y_true, y_pred):\n-    '''expects an array of integer classes.\n-    Note: labels shape must have the same number of dimensions as output shape.\n-    If you get a shape error, add a length-1 dimension to labels.\n+    '''Calculates the cross-entropy value for multiclass classification\n+    problems with sparse targets. Note: Expects an array of integer\n+    classes. Labels shape must have the same number of dimensions as\n+    output shape. If you get a shape error, add a length-1 dimension\n+    to labels.\n     '''\n     return K.mean(K.sparse_categorical_crossentropy(y_pred, y_true))\n \n \n def binary_crossentropy(y_true, y_pred):\n+    '''Calculates the cross-entropy value for binary classification\n+    problems.\n+    '''\n     return K.mean(K.binary_crossentropy(y_pred, y_true))\n \n \n def kullback_leibler_divergence(y_true, y_pred):\n+    '''Calculates the Kullback-Leibler (KL) divergence between prediction\n+    and target values\n+    '''\n     y_true = K.clip(y_true, K.epsilon(), 1)\n     y_pred = K.clip(y_pred, K.epsilon(), 1)\n     return K.sum(y_true * K.log(y_true / y_pred), axis=-1)\n \n \n def poisson(y_true, y_pred):\n+    '''Calculates the poisson function over prediction and target values.\n+    '''\n     return K.mean(y_pred - y_true * K.log(y_pred + K.epsilon()))\n \n \n def cosine_proximity(y_true, y_pred):\n+    '''Calculates the cosine similarity between the prediction and target\n+    values.\n+    '''\n     y_true = K.l2_normalize(y_true, axis=-1)\n     y_pred = K.l2_normalize(y_pred, axis=-1)\n     return -K.mean(y_true * y_pred)\n \n \n def matthews_correlation(y_true, y_pred):\n-    ''' Matthews correlation coefficient\n+    '''Calculates the Matthews correlation coefficient measure for quality\n+    of binary classification problems.\n     '''\n     y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n     y_pred_neg = 1 - y_pred_pos\n@@ -104,7 +149,7 @@ def matthews_correlation(y_true, y_pred):\n \n \n def fbeta_score(y_true, y_pred, beta=1):\n-    '''Compute F score, the weighted harmonic mean of precision and recall.\n+    '''Computes the F score, the weighted harmonic mean of precision and recall.\n \n     This is useful for multi-label classification where input samples can be\n     tagged with a set of labels. By only using accuracy (precision) a model\n\n@@ -517,6 +517,7 @@ class Sequential(Model):\n             metrics: list of metrics to be evaluated by the model\n                 during training and testing.\n                 Typically you will use `metrics=['accuracy']`.\n+                See [metrics](/metrics).\n             sample_weight_mode: if you need to do timestep-wise\n                 sample weighting (2D weights), set this to \"temporal\".\n                 \"None\" defaults to sample-wise weights (1D).\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3e95633b1fb920e7821737522f23725512df8d1c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 19 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 8 | Methods Changed: 4 | Complexity Δ (Sum/Max): 6/6 | Churn Δ: 24 | Churn Cumulative: 2179 | Contributors (this commit): 24 | Commits (past 90d): 11 | Contributors (cumulative): 24 | DMM Complexity: 0.0\n\nDIFF:\n@@ -453,7 +453,7 @@ def generator_queue(generator, max_q_size=10,\n             q.close()\n         raise\n \n-    return q, _stop\n+    return q, _stop, generator_threads\n \n \n class Model(Container):\n@@ -1406,7 +1406,7 @@ class Model(Container):\n             self.validation_data = None\n \n         # start generator thread storing batches into a queue\n-        data_gen_queue, _stop = generator_queue(generator, max_q_size=max_q_size, nb_worker=nb_worker,\n+        data_gen_queue, _stop, generator_threads = generator_queue(generator, max_q_size=max_q_size, nb_worker=nb_worker,\n                                                                    pickle_safe=pickle_safe)\n \n         callback_model.stop_training = False\n@@ -1481,7 +1481,9 @@ class Model(Container):\n                     if val_gen:\n                         val_outs = self.evaluate_generator(validation_data,\n                                                            nb_val_samples,\n-                                                           max_q_size=max_q_size)\n+                                                           max_q_size=max_q_size,\n+                                                           nb_worker=nb_worker,\n+                                                           pickle_safe=pickle_safe)\n                     else:\n                         # no need for try/except because\n                         # data has already been validated\n@@ -1502,6 +1504,10 @@ class Model(Container):\n \n         _stop.set()\n         if pickle_safe:\n+            # Terminate all daemon processes\n+            for p in generator_threads:\n+                if p.is_alive():\n+                    p.terminate()\n             data_gen_queue.close()\n         callbacks.on_train_end()\n         return self.history\n@@ -1536,7 +1542,7 @@ class Model(Container):\n         wait_time = 0.01\n         all_outs = []\n         weights = []\n-        data_gen_queue, _stop = generator_queue(generator, max_q_size=max_q_size, nb_worker=nb_worker,\n+        data_gen_queue, _stop, generator_threads = generator_queue(generator, max_q_size=max_q_size, nb_worker=nb_worker,\n                                                                    pickle_safe=pickle_safe)\n \n         while processed_samples < val_samples:\n@@ -1582,6 +1588,10 @@ class Model(Container):\n \n         _stop.set()\n         if pickle_safe:\n+            # Terminate all daemon processes\n+            for p in generator_threads:\n+                if p.is_alive():\n+                    p.terminate()\n             data_gen_queue.close()\n         if type(outs) is not list:\n             return np.average(np.asarray(all_outs),\n@@ -1617,7 +1627,7 @@ class Model(Container):\n         processed_samples = 0\n         wait_time = 0.01\n         all_outs = []\n-        data_gen_queue, _stop = generator_queue(generator, max_q_size=max_q_size, nb_worker=nb_worker,\n+        data_gen_queue, _stop, generator_threads = generator_queue(generator, max_q_size=max_q_size, nb_worker=nb_worker,\n                                                                    pickle_safe=pickle_safe)\n \n         while processed_samples < val_samples:\n@@ -1671,6 +1681,10 @@ class Model(Container):\n \n         _stop.set()\n         if pickle_safe:\n+            # Terminate all daemon processes\n+            for p in generator_threads:\n+                if p.is_alive():\n+                    p.terminate()\n             data_gen_queue.close()\n         if len(all_outs) == 1:\n             return all_outs[0]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#94ee8e15704d76fb3ef06a91c2c9c72aa07678e9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 215 | Lines Deleted: 4 | Files Changed: 3 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 13/13 | Churn Δ: 219 | Churn Cumulative: 537 | Contributors (this commit): 1 | Commits (past 90d): 7 | Contributors (cumulative): 3 | DMM Complexity: 0.04032258064516129\n\nDIFF:\n@@ -2,3 +2,4 @@ from .vgg16 import VGG16\n from .vgg19 import VGG19\n from .resnet50 import ResNet50\n from .inception_v3 import InceptionV3\n+from .xception import Xception\n\n@@ -7,8 +7,8 @@ only gets to 7.8% (same as a fully-converged ResNet 50).\n For comparison, VGG16 only gets to 9.9%, quite a bit worse.\n \n Also, do note that the input image format for this model is different than for\n-other models (299x299 instead of 224x224), and that the input preprocessing function\n-is also different.\n+the VGG16 and ResNet models (299x299 instead of 224x224), and that the input preprocessing function\n+is also different (same as Xception).\n \n # Reference:\n \n@@ -76,8 +76,8 @@ def InceptionV3(include_top=True, weights='imagenet',\n     Note that the default input image size for this model is 299x299.\n \n     # Arguments\n-        include_top: whether to include the 3 fully-connected\n-            layers at the top of the network.\n+        include_top: whether to include the fully-connected\n+            layer at the top of the network.\n         weights: one of `None` (random initialization)\n             or \"imagenet\" (pre-training on ImageNet).\n         input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n\n@@ -0,0 +1,210 @@\n+# -*- coding: utf-8 -*-\n+'''Xception V1 model for Keras.\n+\n+On ImageNet, this model gets to a top-1 validation accuracy of 0.790\n+and a top-5 validation accuracy of 0.945.\n+\n+Do note that the input image format for this model is different than for\n+the VGG16 and ResNet models (299x299 instead of 224x224),\n+and that the input preprocessing function\n+is also different (same as Inception V3).\n+\n+Also do note that this model is only available for the TensorFlow backend,\n+due to its reliance on `SeparableConvolution` layers.\n+\n+# Reference:\n+\n+- [Xception: Deep Learning with Depthwise Separable Convolutions](https://arxiv.org/abs/1610.02357)\n+\n+'''\n+from __future__ import print_function\n+from __future__ import absolute_import\n+\n+import warnings\n+\n+from ..models import Model\n+from ..layers import Dense, Input, BatchNormalization, Activation, merge\n+from ..layers import Conv2D, SeparableConv2D, MaxPooling2D, GlobalAveragePooling2D\n+from ..utils.data_utils import get_file\n+from .. import backend as K\n+from .imagenet_utils import decode_predictions\n+\n+\n+TF_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels.h5'\n+TF_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5'\n+\n+\n+def Xception(include_top=True, weights='imagenet',\n+             input_tensor=None):\n+    '''Instantiate the Xception architecture,\n+    optionally loading weights pre-trained\n+    on ImageNet. This model is available for TensorFlow only,\n+    and can only be used with inputs following the TensorFlow\n+    dimension ordering `(width, height, channels)`.\n+    You should set `image_dim_ordering=\"tf\"` in your Keras config\n+    located at ~/.keras/keras.json.\n+\n+    Note that the default input image size for this model is 299x299.\n+\n+    # Arguments\n+        include_top: whether to include the fully-connected\n+            layer at the top of the network.\n+        weights: one of `None` (random initialization)\n+            or \"imagenet\" (pre-training on ImageNet).\n+        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n+            to use as image input for the model.\n+\n+    # Returns\n+        A Keras model instance.\n+    '''\n+    if weights not in {'imagenet', None}:\n+        raise ValueError('The `weights` argument should be either '\n+                         '`None` (random initialization) or `imagenet` '\n+                         '(pre-training on ImageNet).')\n+    if K.backend() != 'tensorflow':\n+        raise Exception('The Xception model is only available with '\n+                        'the TensorFlow backend.')\n+    if K.image_dim_ordering() != 'tf':\n+        warnings.warn('The Xception model is only available for the '\n+                      'input dimension ordering \"tf\" '\n+                      '(width, height, channels). '\n+                      'However your settings specify the default '\n+                      'dimension ordering \"th\" (channels, width, height). '\n+                      'You should set `image_dim_ordering=\"tf\"` in your Keras '\n+                      'config located at ~/.keras/keras.json. '\n+                      'The model being returned right now will expect inputs '\n+                      'to follow the \"tf\" dimension ordering.')\n+        K.set_image_dim_ordering('tf')\n+        old_dim_ordering = 'th'\n+    else:\n+        old_dim_ordering = None\n+\n+    # Determine proper input shape\n+    if include_top:\n+        input_shape = (299, 299, 3)\n+    else:\n+        input_shape = (None, None, 3)\n+\n+    if input_tensor is None:\n+        img_input = Input(shape=input_shape)\n+    else:\n+        if not K.is_keras_tensor(input_tensor):\n+            img_input = Input(tensor=input_tensor, shape=input_shape)\n+        else:\n+            img_input = input_tensor\n+\n+    x = Conv2D(32, 3, 3, subsample=(2, 2), bias=False, name='block1_conv1')(img_input)\n+    x = BatchNormalization(name='block1_conv1_bn')(x)\n+    x = Activation('relu', name='block1_conv1_act')(x)\n+    x = Conv2D(64, 3, 3, bias=False, name='block1_conv2')(x)\n+    x = BatchNormalization(name='block1_conv2_bn')(x)\n+    x = Activation('relu', name='block1_conv2_act')(x)\n+\n+    residual = Conv2D(128, 1, 1, subsample=(2, 2),\n+                      border_mode='same', bias=False)(x)\n+    residual = BatchNormalization()(residual)\n+\n+    x = SeparableConv2D(128, 3, 3, border_mode='same', bias=False, name='block2_sepconv1')(x)\n+    x = BatchNormalization(name='block2_sepconv1_bn')(x)\n+    x = Activation('relu', name='block2_sepconv2_act')(x)\n+    x = SeparableConv2D(128, 3, 3, border_mode='same', bias=False, name='block2_sepconv2')(x)\n+    x = BatchNormalization(name='block2_sepconv2_bn')(x)\n+\n+    x = MaxPooling2D((3, 3), strides=(2, 2), border_mode='same', name='block2_pool')(x)\n+    x = merge([x, residual], mode='sum')\n+\n+    residual = Conv2D(256, 1, 1, subsample=(2, 2),\n+                      border_mode='same', bias=False)(x)\n+    residual = BatchNormalization()(residual)\n+\n+    x = Activation('relu', name='block3_sepconv1_act')(x)\n+    x = SeparableConv2D(256, 3, 3, border_mode='same', bias=False, name='block3_sepconv1')(x)\n+    x = BatchNormalization(name='block3_sepconv1_bn')(x)\n+    x = Activation('relu', name='block3_sepconv2_act')(x)\n+    x = SeparableConv2D(256, 3, 3, border_mode='same', bias=False, name='block3_sepconv2')(x)\n+    x = BatchNormalization(name='block3_sepconv2_bn')(x)\n+\n+    x = MaxPooling2D((3, 3), strides=(2, 2), border_mode='same', name='block3_pool')(x)\n+    x = merge([x, residual], mode='sum')\n+\n+    residual = Conv2D(728, 1, 1, subsample=(2, 2),\n+                      border_mode='same', bias=False)(x)\n+    residual = BatchNormalization()(residual)\n+\n+    x = Activation('relu', name='block4_sepconv1_act')(x)\n+    x = SeparableConv2D(728, 3, 3, border_mode='same', bias=False, name='block4_sepconv1')(x)\n+    x = BatchNormalization(name='block4_sepconv1_bn')(x)\n+    x = Activation('relu', name='block4_sepconv2_act')(x)\n+    x = SeparableConv2D(728, 3, 3, border_mode='same', bias=False, name='block4_sepconv2')(x)\n+    x = BatchNormalization(name='block4_sepconv2_bn')(x)\n+\n+    x = MaxPooling2D((3, 3), strides=(2, 2), border_mode='same', name='block4_pool')(x)\n+    x = merge([x, residual], mode='sum')\n+\n+    for i in range(8):\n+        residual = x\n+        prefix = 'block' + str(i + 5)\n+\n+        x = Activation('relu', name=prefix + '_sepconv1_act')(x)\n+        x = SeparableConv2D(728, 3, 3, border_mode='same', bias=False, name=prefix + '_sepconv1')(x)\n+        x = BatchNormalization(name=prefix + '_sepconv1_bn')(x)\n+        x = Activation('relu', name=prefix + '_sepconv2_act')(x)\n+        x = SeparableConv2D(728, 3, 3, border_mode='same', bias=False, name=prefix + '_sepconv2')(x)\n+        x = BatchNormalization(name=prefix + '_sepconv2_bn')(x)\n+        x = Activation('relu', name=prefix + '_sepconv3_act')(x)\n+        x = SeparableConv2D(728, 3, 3, border_mode='same', bias=False, name=prefix + '_sepconv3')(x)\n+        x = BatchNormalization(name=prefix + '_sepconv3_bn')(x)\n+\n+        x = merge([x, residual], mode='sum')\n+\n+    residual = Conv2D(1024, 1, 1, subsample=(2, 2),\n+                      border_mode='same', bias=False)(x)\n+    residual = BatchNormalization()(residual)\n+\n+    x = Activation('relu', name='block13_sepconv1_act')(x)\n+    x = SeparableConv2D(728, 3, 3, border_mode='same', bias=False, name='block13_sepconv1')(x)\n+    x = BatchNormalization(name='block13_sepconv1_bn')(x)\n+    x = Activation('relu', name='block13_sepconv2_act')(x)\n+    x = SeparableConv2D(1024, 3, 3, border_mode='same', bias=False, name='block13_sepconv2')(x)\n+    x = BatchNormalization(name='block13_sepconv2_bn')(x)\n+\n+    x = MaxPooling2D((3, 3), strides=(2, 2), border_mode='same', name='block13_pool')(x)\n+    x = merge([x, residual], mode='sum')\n+\n+    x = SeparableConv2D(1536, 3, 3, border_mode='same', bias=False, name='block14_sepconv1')(x)\n+    x = BatchNormalization(name='block14_sepconv1_bn')(x)\n+    x = Activation('relu', name='block14_sepconv1_act')(x)\n+\n+    x = SeparableConv2D(2048, 3, 3, border_mode='same', bias=False, name='block14_sepconv2')(x)\n+    x = BatchNormalization(name='block14_sepconv2_bn')(x)\n+    x = Activation('relu', name='block14_sepconv2_act')(x)\n+\n+    if include_top:\n+        x = GlobalAveragePooling2D(name='avg_pool')(x)\n+        x = Dense(1000, activation='softmax', name='predictions')(x)\n+\n+    # Create model\n+    model = Model(img_input, x)\n+\n+    # load weights\n+    if weights == 'imagenet':\n+        if include_top:\n+            weights_path = get_file('xception_weights_tf_dim_ordering_tf_kernels.h5',\n+                                    TF_WEIGHTS_PATH,\n+                                    cache_subdir='models')\n+        else:\n+            weights_path = get_file('xception_weights_tf_dim_ordering_tf_kernels_notop.h5',\n+                                    TF_WEIGHTS_PATH_NO_TOP,\n+                                    cache_subdir='models')\n+        model.load_weights(weights_path)\n+\n+    if old_dim_ordering:\n+        K.set_image_dim_ordering(old_dim_ordering)\n+    return model\n+\n+\n+def preprocess_input(x):\n+    x /= 255.\n+    x -= 0.5\n+    x *= 2.\n+    return x\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6ffa6f39e6222c5417f70eea84ebd92e2d6113f5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 3342 | Contributors (this commit): 24 | Commits (past 90d): 21 | Contributors (cumulative): 24 | DMM Complexity: None\n\nDIFF:\n@@ -1106,7 +1106,7 @@ class Merge(Layer):\n \n     ```python\n     model1 = Sequential()\n-    model1.add(Dense(32))\n+    model1.add(Dense(32, input_dim=32))\n \n     model2 = Sequential()\n     model2.add(Dense(32))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#66e59447995bcdf0c2adad98766efa666fb2684f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 3344 | Contributors (this commit): 24 | Commits (past 90d): 22 | Contributors (cumulative): 24 | DMM Complexity: None\n\nDIFF:\n@@ -1109,7 +1109,7 @@ class Merge(Layer):\n     model1.add(Dense(32, input_dim=32))\n \n     model2 = Sequential()\n-    model2.add(Dense(32))\n+    model2.add(Dense(32, input_dim=32))\n \n     merged_model = Sequential()\n     merged_model.add(Merge([model1, model2], mode='concat', concat_axis=1)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f1bc3c03ede03a28111caba2b2a75d5752f4cc98", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 4 | Churn Cumulative: 993 | Contributors (this commit): 10 | Commits (past 90d): 3 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -66,7 +66,7 @@ class BaseWrapper(object):\n                             Sequential.predict_classes, Sequential.evaluate]\n         if self.build_fn is None:\n             legal_params_fns.append(self.__call__)\n-        elif not isinstance(self.build_fn, types.FunctionType):\n+        elif not isinstance(self.build_fn, types.FunctionType) and not isinstance(self.build_fn, types.MethodType):\n             legal_params_fns.append(self.build_fn.__call__)\n         else:\n             legal_params_fns.append(self.build_fn)\n@@ -130,7 +130,7 @@ class BaseWrapper(object):\n \n         if self.build_fn is None:\n             self.model = self.__call__(**self.filter_sk_params(self.__call__))\n-        elif not isinstance(self.build_fn, types.FunctionType):\n+        elif not isinstance(self.build_fn, types.FunctionType) and not isinstance(self.build_fn, types.MethodType):\n             self.model = self.build_fn(\n                 **self.filter_sk_params(self.build_fn.__call__))\n         else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3feca20c59a233ddd75a7d333f0bed22942423f3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 12 | Files Changed: 5 | Hunks: 9 | Methods Changed: 4 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 26 | Churn Cumulative: 2667 | Contributors (this commit): 11 | Commits (past 90d): 8 | Contributors (cumulative): 19 | DMM Complexity: 1.0\n\nDIFF:\n@@ -538,7 +538,8 @@ class Graph(Model):\n                       verbose=1, callbacks=[],\n                       validation_data=None, nb_val_samples=None,\n                       class_weight={},\n-                      max_q_size=10, **kwargs):\n+                      max_q_size=10, nb_worker=1,\n+                      pickle_safe=False, **kwargs):\n         '''Fits a model on data generated batch-by-batch by a Python generator.\n         The generator is run in parallel to the model, for efficiency.\n         For instance, this allows you to do real-time data augmentation\n@@ -599,10 +600,6 @@ class Graph(Model):\n                           'the model at compile time:\\n'\n                           '`model.compile(optimizer, loss, '\n                           'metrics=[\"accuracy\"])`')\n-        if 'nb_worker' in kwargs:\n-            kwargs.pop('nb_worker')\n-            warnings.warn('The \"nb_worker\" argument is deprecated, '\n-                          'please remove it from your code.')\n         if 'nb_val_worker' in kwargs:\n             kwargs.pop('nb_val_worker')\n             warnings.warn('The \"nb_val_worker\" argument is deprecated, '\n@@ -647,13 +644,16 @@ class Graph(Model):\n                                                    validation_data=validation_data,\n                                                    nb_val_samples=nb_val_samples,\n                                                    class_weight=class_weight,\n-                                                   max_q_size=max_q_size)\n+                                                   max_q_size=max_q_size,\n+                                                   nb_worker=nb_worker,\n+                                                   pickle_safe=pickle_safe)\n         self.train_on_batch = self._train_on_batch\n         self.evaluate = self._evaluate\n         return history\n \n     def evaluate_generator(self, generator, val_samples,\n-                           verbose=1, max_q_size=10, **kwargs):\n+                           verbose=1, max_q_size=10, nb_worker=1,\n+                           pickle_safe=False, **kwargs):\n         '''Evaluates the model on a generator. The generator should\n         return the same kind of data with every yield as accepted\n         by `evaluate`.\n@@ -707,7 +707,9 @@ class Graph(Model):\n         generator = fixed_generator()\n         history = super(Graph, self).evaluate_generator(generator,\n                                                         val_samples,\n-                                                        max_q_size=max_q_size)\n+                                                        max_q_size=max_q_size,\n+                                                        nb_worker=nb_worker,\n+                                                        pickle_safe=pickle_safe)\n         self.test_on_batch = self._test_on_batch\n         return history\n \n\n@@ -5,7 +5,7 @@ from numpy.testing import assert_allclose\n from keras.layers import Dense, Dropout\n from keras.engine.topology import merge, Input\n from keras.engine.training import Model\n-from keras.models import Sequential, Graph\n+from keras.models import Sequential\n from keras import backend as K\n from keras.utils.test_utils import keras_test\n \n\n@@ -5,7 +5,7 @@ from numpy.testing import assert_allclose\n from keras.layers.core import Dense, Activation\n from keras.utils.test_utils import layer_test, keras_test\n from keras.layers import normalization\n-from keras.models import Sequential, Graph\n+from keras.models import Sequential\n from keras import backend as K\n \n input_1 = np.arange(10)\n\n@@ -6,7 +6,7 @@ import numpy as np\n np.random.seed(1337)\n \n from keras import backend as K\n-from keras.models import Graph, Sequential\n+from keras.models import Sequential\n from keras.layers.core import Dense, Activation, Merge, Lambda\n from keras.utils import np_utils\n from keras.utils.test_utils import get_test_data, keras_test\n\n@@ -5,7 +5,7 @@ import numpy as np\n np.random.seed(1337)\n \n from keras.utils.test_utils import get_test_data\n-from keras.models import Sequential, Graph\n+from keras.models import Sequential\n from keras.layers import Dense, Activation, RepeatVector, TimeDistributedDense, GRU\n from keras.utils import np_utils\n from keras.utils.test_utils import keras_test\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#41741c38e5f29ebf69fe9bd82a604eba3c0b97e5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2932 | Contributors (this commit): 39 | Commits (past 90d): 34 | Contributors (cumulative): 39 | DMM Complexity: None\n\nDIFF:\n@@ -1261,7 +1261,7 @@ def rnn(step_function, inputs, initial_states,\n                     new_state = new_states[0]\n                 else:\n                     # return dummy state, otherwise _dynamic_rnn_loop breaks\n-                    new_state = output\n+                    new_state = state\n                 return output, new_state\n \n         _step.state_size = state_size * nb_states\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#028aae19bf5ae6efe0b32d25d1c700224eebfcf9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 3/2 | Churn Δ: 6 | Churn Cumulative: 10069 | Contributors (this commit): 67 | Commits (past 90d): 21 | Contributors (cumulative): 75 | DMM Complexity: 0.0\n\nDIFF:\n@@ -258,6 +258,11 @@ def collect_trainable_weights(layer):\n         weights += layer.trainable_weights\n     # dedupe weights\n     weights = list(set(weights))\n+    # TF variables have auto-generated the name, while Theano has auto-generated the auto_name variable. name in Theano is None\n+    if weights:\n+        if K.backend() == 'theano':\n+            weights.sort(key=lambda x: x.auto_name)\n+        else:\n             weights.sort(key=lambda x: x.name)\n     return weights\n \n\n@@ -400,6 +400,7 @@ class Sequential(Model):\n         if self._flattened_layers is not None:\n             return self._flattened_layers\n         layers = []\n+        if self.layers:\n             if self.layers[0].__class__.__name__ == 'Merge':\n                 merge = self.layers[0]\n                 for layer in merge.layers:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4cd83631ee003fb2847b78838880392101542517", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 150 | Contributors (this commit): 5 | Commits (past 90d): 3 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -12,9 +12,9 @@ np.random.seed(1337)  # for reproducibility\n \n from keras.preprocessing import sequence\n from keras.models import Sequential\n-from keras.layers import Dense, Dropout, Activation, Flatten\n+from keras.layers import Dense, Dropout, Activation\n from keras.layers import Embedding\n-from keras.layers import Convolution1D, MaxPooling1D\n+from keras.layers import Convolution1D, GlobalMaxPooling1D\n from keras.datasets import imdb\n from keras import backend as K\n \n@@ -58,11 +58,7 @@ model.add(Convolution1D(nb_filter=nb_filter,\n                         activation='relu',\n                         subsample_length=1))\n # we use max pooling:\n-model.add(MaxPooling1D(pool_length=model.output_shape[1]))\n-\n-# We flatten the output of the conv layer,\n-# so that we can add a vanilla dense layer:\n-model.add(Flatten())\n+model.add(GlobalMaxPooling1D())\n \n # We add a vanilla hidden layer:\n model.add(Dense(hidden_dims))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#68495894306acfef6b5dc9c812abdca01ddc54a7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 2936 | Contributors (this commit): 39 | Commits (past 90d): 33 | Contributors (cumulative): 39 | DMM Complexity: None\n\nDIFF:\n@@ -146,7 +146,7 @@ def variable(value, dtype=_FLOATX, name=None):\n         sparse_coo = value.tocoo()\n         indices = np.concatenate((np.expand_dims(sparse_coo.row, 1), np.expand_dims(sparse_coo.col, 1)), 1)\n         # SparseTensor doesn't need initialization\n-        return tf.SparseTensor(indices=indices, values=value.data, shape=value.shape)\n+        return tf.SparseTensor(indices=indices, values=sparse_coo.data, shape=sparse_coo.shape)\n \n     v = tf.Variable(value, dtype=_convert_string_dtype(dtype), name=name)\n     if _MANUAL_VAR_INIT:\n@@ -1034,7 +1034,7 @@ class Function(object):\n             if is_sparse(tensor):\n                 sparse_coo = value.tocoo()\n                 indices = np.concatenate((np.expand_dims(sparse_coo.row, 1), np.expand_dims(sparse_coo.col, 1)), 1)\n-                value = (indices, value.data, value.shape)\n+                value = (indices, sparse_coo.data, sparse_coo.shape)\n             feed_dict[tensor] = value\n         session = get_session()\n         updated = session.run(self.outputs + [self.updates_op], feed_dict=feed_dict)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8dd61c1dc4fa36238725408e7eb293706828b43a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 37 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 38 | Churn Cumulative: 2415 | Contributors (this commit): 28 | Commits (past 90d): 13 | Contributors (cumulative): 34 | DMM Complexity: 1.0\n\nDIFF:\n@@ -530,7 +530,7 @@ class TensorBoard(Callback):\n                 continue\n             summary = tf.Summary()\n             summary_value = summary.value.add()\n-            summary_value.simple_value = value\n+            summary_value.simple_value = value.item()\n             summary_value.tag = name\n             self.writer.add_summary(summary, epoch)\n         self.writer.flush()\n\n@@ -343,5 +343,41 @@ def test_LambdaCallback():\n     assert not p.is_alive()\n \n \n+@pytest.mark.skipif((K._BACKEND != 'tensorflow'),\n+                    reason=\"Requires tensorflow backend\")\n+def test_TensorBoard_with_ReduceLROnPlateau():\n+    import shutil\n+    filepath = './logs'\n+    (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=train_samples,\n+                                                         nb_test=test_samples,\n+                                                         input_shape=(input_dim,),\n+                                                         classification=True,\n+                                                         nb_class=nb_class)\n+    y_test = np_utils.to_categorical(y_test)\n+    y_train = np_utils.to_categorical(y_train)\n+\n+    model = Sequential()\n+    model.add(Dense(nb_hidden, input_dim=input_dim, activation='relu'))\n+    model.add(Dense(nb_class, activation='softmax'))\n+    model.compile(loss='binary_crossentropy',\n+                  optimizer='sgd',\n+                  metrics=['accuracy'])\n+\n+    cbks = [\n+        callbacks.ReduceLROnPlateau(\n+            monitor='val_loss',\n+            factor=0.5,\n+            patience=4,\n+            verbose=1),\n+        callbacks.TensorBoard(\n+            log_dir=filepath)]\n+\n+    model.fit(X_train, y_train, batch_size=batch_size,\n+              validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=2)\n+\n+    assert os.path.exists(filepath)\n+    shutil.rmtree(filepath)\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4401120ca62e31660f7060e2415c4ed6c0f17834", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 7895 | Contributors (this commit): 50 | Commits (past 90d): 10 | Contributors (cumulative): 50 | DMM Complexity: 0.25\n\nDIFF:\n@@ -787,7 +787,8 @@ class Sequential(Model):\n     def fit_generator(self, generator, samples_per_epoch, nb_epoch,\n                       verbose=1, callbacks=[],\n                       validation_data=None, nb_val_samples=None,\n-                      class_weight=None, max_q_size=10, nb_worker=1, pickle_safe=False, **kwargs):\n+                      class_weight=None, max_q_size=10, nb_worker=1,\n+                      pickle_safe=False, **kwargs):\n         '''Fits the model on data generated batch-by-batch by\n         a Python generator.\n         The generator is run in parallel to the model, for efficiency.\n@@ -875,7 +876,9 @@ class Sequential(Model):\n                                         nb_worker=nb_worker,\n                                         pickle_safe=pickle_safe)\n \n-    def evaluate_generator(self, generator, val_samples, max_q_size=10, nb_worker=1, pickle_safe=False, **kwargs):\n+    def evaluate_generator(self, generator, val_samples,\n+                           max_q_size=10, nb_worker=1,\n+                           pickle_safe=False, **kwargs):\n         '''Evaluates the model on a data generator. The generator should\n         return the same kind of data as accepted by `test_on_batch`.\n \n@@ -917,7 +920,8 @@ class Sequential(Model):\n                                              nb_worker=nb_worker,\n                                              pickle_safe=pickle_safe)\n \n-    def predict_generator(self, generator, val_samples, max_q_size=10, nb_worker=1, pickle_safe=False):\n+    def predict_generator(self, generator, val_samples,\n+                          max_q_size=10, nb_worker=1, pickle_safe=False):\n         '''Generates predictions for the input samples from a data generator.\n         The generator should return the same kind of data as accepted by\n         `predict_on_batch`.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8b11f13507162e7d15ca8ec5bc5e47f4effcfcbc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 10 | Files Changed: 2 | Hunks: 10 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 20 | Churn Cumulative: 1046 | Contributors (this commit): 1 | Commits (past 90d): 13 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -7,7 +7,7 @@ from ..utils.np_utils import conv_output_length\n import warnings\n \n \n-class RecurrentConv2D(Layer):\n+class ConvRecurrent2D(Layer):\n     '''Abstract base class for recurrent layers.\n     Do not use in a model -- it's not a functional layer!\n \n@@ -88,7 +88,7 @@ class RecurrentConv2D(Layer):\n         self.dim_ordering = dim_ordering\n         self.input_spec = [InputSpec(ndim=5)]\n \n-        super(RecurrentConv2D, self).__init__(**kwargs)\n+        super(ConvRecurrent2D, self).__init__(**kwargs)\n \n     def compute_mask(self, input, mask):\n         if self.return_sequences:\n@@ -195,11 +195,11 @@ class RecurrentConv2D(Layer):\n         if self.stateful:\n             config['batch_input_shape'] = self.input_spec[0].shape\n \n-        base_config = super(RecurrentConv2D, self).get_config()\n+        base_config = super(ConvRecurrent2D, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n \n \n-class LSTMConv2D(RecurrentConv2D):\n+class ConvLSTM2D(ConvRecurrent2D):\n     '''\n     # Input shape\n         - if dim_ordering='th'\n@@ -304,7 +304,7 @@ class LSTMConv2D(RecurrentConv2D):\n         if self.dropout_W or self.dropout_U:\n             self.uses_learning_phase = True\n \n-        super(LSTMConv2D, self).__init__(**kwargs)\n+        super(ConvLSTM2D, self).__init__(**kwargs)\n \n     def build(self, input_shape):\n         self.input_spec = [InputSpec(shape=input_shape)]\n@@ -519,5 +519,5 @@ class LSTMConv2D(RecurrentConv2D):\n                   'dim_ordering': self.dim_ordering,\n                   'border_mode': self.border_mode,\n                   'inner_activation': self.inner_activation.__name__}\n-        base_config = super(LSTMConv2D, self).get_config()\n+        base_config = super(ConvLSTM2D, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n\n@@ -32,7 +32,7 @@ def test_recurrent_convolutional():\n \n         for return_sequences in [True, False]:\n             # test for ouptput shape:\n-            output = layer_test(recurrent_convolutional.LSTMConv2D,\n+            output = layer_test(recurrent_convolutional.ConvLSTM2D,\n                                 kwargs={'dim_ordering': dim_ordering,\n                                         'return_sequences': return_sequences,\n                                         'nb_filter': nb_filter,\n@@ -67,7 +67,7 @@ def test_recurrent_convolutional():\n                       'stateful': True,\n                       'batch_input_shape': input.shape,\n                       'border_mode': \"same\"}\n-            layer = recurrent_convolutional.LSTMConv2D(**kwargs)\n+            layer = recurrent_convolutional.ConvLSTM2D(**kwargs)\n \n             model.add(layer)\n             model.compile(optimizer='sgd', loss='mse')\n@@ -110,13 +110,13 @@ def test_recurrent_convolutional():\n                       'b_regularizer': 'l2',\n                       'border_mode': \"same\"}\n \n-            layer = recurrent_convolutional.LSTMConv2D(**kwargs)\n+            layer = recurrent_convolutional.ConvLSTM2D(**kwargs)\n             layer.set_input(K.variable(np.ones(input.shape)),\n                             shape=input.shape)\n             K.eval(layer.output)\n \n             # check dropout\n-            layer_test(recurrent_convolutional.LSTMConv2D,\n+            layer_test(recurrent_convolutional.ConvLSTM2D,\n                        kwargs={'dim_ordering': dim_ordering,\n                                'return_sequences': return_sequences,\n                                'nb_filter': nb_filter,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7a6ee934e1e5414a13c7aca670640e178d2cca94", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 18 | Lines Deleted: 9 | Files Changed: 1 | Hunks: 7 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 27 | Churn Cumulative: 457 | Contributors (this commit): 10 | Commits (past 90d): 2 | Contributors (cumulative): 10 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1,5 +1,7 @@\n import os\n \n+from ..layers.wrappers import Wrapper\n+\n try:\n     # pydot-ng is a fork of pydot that is better maintained\n     import pydot_ng as pydot\n@@ -23,17 +25,25 @@ def model_to_dot(model, show_shapes=False, show_layer_names=True):\n         model = model.model\n     layers = model.layers\n \n-    # first, populate the nodes of the graph\n+    # Create graph nodes.\n     for layer in layers:\n         layer_id = str(id(layer))\n-        if show_layer_names:\n-            label = str(layer.name) + ' (' + layer.__class__.__name__ + ')'\n-        else:\n-            label = layer.__class__.__name__\n         \n+        # Append a wrapped layer's label to node's label, if it exists.\n+        layer_name = layer.name\n+        class_name = layer.__class__.__name__\n+        if isinstance(layer, Wrapper):\n+            layer_name = '{}({})'.format(layer_name, layer.layer.name)\n+            class_name = '{}({})'.format(class_name, layer.layer.__class__.__name__)\n+\n+        # Create node's label.\n+        if show_layer_names:\n+            label = '{}: {}'.format(layer_name, class_name)\n+        else:\n+            label = class_name\n+\n+        # Rebuild the label as a table including input/output shapes.\n         if show_shapes:\n-            # Build the label that will actually contain a table with the\n-            # input/output\n             try:\n                 outputlabels = str(layer.output_shape)\n             except:\n@@ -50,13 +60,12 @@ def model_to_dot(model, show_shapes=False, show_layer_names=True):\n         node = pydot.Node(layer_id, label=label)\n         dot.add_node(node)\n \n-    # second, add the edges\n+    # Connect nodes with edges.\n     for layer in layers:\n         layer_id = str(id(layer))\n         for i, node in enumerate(layer.inbound_nodes):\n             node_key = layer.name + '_ib-' + str(i)\n             if node_key in model.container_nodes:\n-                # add edges\n                 for inbound_layer in node.inbound_layers:\n                     inbound_layer_id = str(id(inbound_layer))\n                     layer_id = str(id(layer))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
