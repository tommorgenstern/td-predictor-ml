{"custom_id": "keras#205c38e8d9998b8b2a5399ae0120951030f354ce", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 37 | Lines Deleted: 30 | Files Changed: 12 | Hunks: 26 | Methods Changed: 23 | Complexity Δ (Sum/Max): -1/1 | Churn Δ: 67 | Churn Cumulative: 14972 | Contributors (this commit): 20 | Commits (past 90d): 355 | Contributors (cumulative): 78 | DMM Complexity: 1.0\n\nDIFF:\n@@ -30,7 +30,7 @@ class JAXTrainer(base_trainer.Trainer):\n     ):\n         \"\"\"This method is stateless and is intended for use with jax.grad.\"\"\"\n         kwargs = {}\n-        if self._call_has_training_arg():\n+        if self._call_has_training_arg:\n             kwargs[\"training\"] = training\n         y_pred, non_trainable_variables, losses = self.stateless_call(\n             trainable_variables,\n@@ -167,7 +167,7 @@ class JAXTrainer(base_trainer.Trainer):\n     def predict_step(self, state, data):\n         trainable_variables, non_trainable_variables = state\n         kwargs = {}\n-        if self._call_has_training_arg():\n+        if self._call_has_training_arg:\n             kwargs[\"training\"] = False\n \n         x, _, _ = data_adapter_utils.unpack_x_y_sample_weight(data)\n\n@@ -48,7 +48,7 @@ class TensorFlowTrainer(base_trainer.Trainer):\n \n         # Forward pass\n         with tf.GradientTape() as tape:\n-            if self._call_has_training_arg():\n+            if self._call_has_training_arg:\n                 y_pred = self(x, training=True)\n             else:\n                 y_pred = self(x)\n@@ -71,7 +71,7 @@ class TensorFlowTrainer(base_trainer.Trainer):\n \n     def test_step(self, data):\n         x, y, sample_weight = data_adapter_utils.unpack_x_y_sample_weight(data)\n-        if self._call_has_training_arg():\n+        if self._call_has_training_arg:\n             y_pred = self(x, training=False)\n         else:\n             y_pred = self(x)\n@@ -83,7 +83,7 @@ class TensorFlowTrainer(base_trainer.Trainer):\n \n     def predict_step(self, data):\n         x, _, _ = data_adapter_utils.unpack_x_y_sample_weight(data)\n-        if self._call_has_training_arg():\n+        if self._call_has_training_arg:\n             y_pred = self(x, training=False)\n         else:\n             y_pred = self(x)\n\n@@ -126,9 +126,12 @@ def _get_concrete_noise_shape(inputs, noise_shape):\n \n \n def dropout(inputs, rate, noise_shape=None, seed=None):\n+    if noise_shape is not None:\n         keep_prob = 1.0 - rate\n         noise_shape = _get_concrete_noise_shape(inputs, noise_shape)\n-    keep_prob_matrix = torch.full(noise_shape, keep_prob, device=get_device())\n+        keep_prob_matrix = torch.full(\n+            noise_shape, keep_prob, device=get_device()\n+        )\n         generator = torch_seed_generator(seed)\n \n         # Do not use generator during symbolic execution.\n@@ -140,5 +143,12 @@ def dropout(inputs, rate, noise_shape=None, seed=None):\n         mask = mask.bool()\n         mask = torch.broadcast_to(mask, inputs.shape)\n         return torch.where(\n-        mask, inputs / keep_prob, torch.zeros_like(inputs, dtype=inputs.dtype)\n+            mask,\n+            inputs / keep_prob,\n+            torch.zeros_like(inputs, dtype=inputs.dtype),\n+        )\n+    # Fast path, unseeded (since torch doesn't support seeding dropout!!!!)\n+    # Using the above implementation is possible, but much slower.\n+    return torch.nn.functional.dropout(\n+        inputs, p=rate, training=True, inplace=False\n     )\n\n@@ -27,7 +27,7 @@ class TorchTrainer(base_trainer.Trainer):\n         x, y, sample_weight = data_adapter_utils.unpack_x_y_sample_weight(data)\n \n         # Compute predictions\n-        if self._call_has_training_arg():\n+        if self._call_has_training_arg:\n             y_pred = self(x, training=True)\n         else:\n             y_pred = self(x)\n@@ -64,7 +64,7 @@ class TorchTrainer(base_trainer.Trainer):\n             y,\n             sample_weight,\n         ) = data_adapter_utils.unpack_x_y_sample_weight(data)\n-        if self._call_has_training_arg():\n+        if self._call_has_training_arg:\n             y_pred = self(x, training=False)\n         else:\n             y_pred = self(x)\n@@ -76,7 +76,7 @@ class TorchTrainer(base_trainer.Trainer):\n \n     def predict_step(self, data):\n         x, _, _ = data_adapter_utils.unpack_x_y_sample_weight(data)\n-        if self._call_has_training_arg():\n+        if self._call_has_training_arg:\n             y_pred = self(x, training=False)\n         else:\n             y_pred = self(x)\n\n@@ -250,9 +250,12 @@ class Layer(BackendLayer, Operation):\n         self._losses = []\n         self._loss_ids = set()\n \n-        self._call_signature_parameters = [\n+        call_signature_parameters = [\n             p.name for p in inspect.signature(self.call).parameters.values()\n         ]\n+        self._call_has_training_arg = \"training\" in call_signature_parameters\n+        self._call_has_mask_arg = \"mask\" in call_signature_parameters\n+\n         self._supports_masking = not utils.is_default(self.compute_mask)\n         # Whether to automatically convert (+ auto-cast) inputs to `call()`.\n         self._convert_input_args = True\n@@ -693,7 +696,7 @@ class Layer(BackendLayer, Operation):\n                 # Get signature default value\n                 training = call_spec.arguments_dict.get(\"training\", None)\n         call_context.training = training\n-        if self._call_has_training_arg() and training is not None:\n+        if self._call_has_training_arg and training is not None:\n             # Only populate arg if it has a concrete value\n             kwargs[\"training\"] = training\n \n@@ -1191,12 +1194,6 @@ class Layer(BackendLayer, Operation):\n                 self.input_spec, arg_0, layer_name=self.name\n             )\n \n-    def _call_has_training_arg(self):\n-        return \"training\" in self._call_signature_parameters\n-\n-    def _call_has_mask_arg(self):\n-        return \"mask\" in self._call_signature_parameters\n-\n     def _get_call_context(self):\n         \"\"\"Returns currently active `CallContext`.\"\"\"\n         layer_call_ctx = global_state.get_global_attribute(\"current_call_ctx\")\n\n@@ -141,7 +141,7 @@ class LayerTest(testing.TestCase):\n                 self.seed_gen = backend.random.SeedGenerator(seed=1337)\n \n             def call(self, x):\n-                return backend.random.dropout(x, rate=0.5, seed=self.seed_gen)\n+                return x * backend.random.normal(x.shape, seed=self.seed_gen)\n \n         layer = RNGLayer()\n         self.assertEqual(layer.variables, [layer.seed_gen.state])\n@@ -158,8 +158,8 @@ class LayerTest(testing.TestCase):\n                 self.seed_gens.append(backend.random.SeedGenerator(seed=10))\n \n             def call(self, x):\n-                x = backend.random.dropout(x, rate=0.5, seed=self.seed_gens[0])\n-                x = backend.random.dropout(x, rate=0.5, seed=self.seed_gens[1])\n+                x = x * backend.random.normal(x.shape, seed=self.seed_gens[0])\n+                x = x * backend.random.normal(x.shape, seed=self.seed_gens[1])\n                 return x\n \n         layer = RNGListLayer()\n\n@@ -198,9 +198,9 @@ class Bidirectional(Wrapper):\n         training=None,\n     ):\n         kwargs = {}\n-        if self.forward_layer._call_has_training_arg():\n+        if self.forward_layer._call_has_training_arg:\n             kwargs[\"training\"] = training\n-        if self.forward_layer._call_has_mask_arg():\n+        if self.forward_layer._call_has_mask_arg:\n             kwargs[\"mask\"] = mask\n \n         if initial_state is not None:\n\n@@ -323,7 +323,7 @@ class RNN(Layer):\n \n     def inner_loop(self, sequences, initial_state, mask, training=False):\n         cell_kwargs = {}\n-        if isinstance(self.cell, Layer) and self.cell._call_has_training_arg():\n+        if isinstance(self.cell, Layer) and self.cell._call_has_training_arg:\n             cell_kwargs[\"training\"] = training\n \n         def step(inputs, states):\n\n@@ -90,7 +90,7 @@ class StackedRNNCells(Layer):\n         new_states = []\n         for cell, states in zip(self.cells, states):\n             states = list(states) if tree.is_nested(states) else [states]\n-            if isinstance(cell, Layer) and cell._call_has_training_arg():\n+            if isinstance(cell, Layer) and cell._call_has_training_arg:\n                 kwargs[\"training\"] = training\n             else:\n                 kwargs.pop(\"training\", None)\n\n@@ -95,9 +95,9 @@ class TimeDistributed(Wrapper):\n \n         def step_function(i):\n             kwargs = {}\n-            if self.layer._call_has_mask_arg() and mask is not None:\n+            if self.layer._call_has_mask_arg and mask is not None:\n                 kwargs[\"mask\"] = mask[i]\n-            if self.layer._call_has_training_arg():\n+            if self.layer._call_has_training_arg:\n                 kwargs[\"training\"] = training\n             return self.layer.call(inputs[i], **kwargs)\n \n\n@@ -542,7 +542,7 @@ def operation_fn(operation, training):\n     def call(*args, **kwargs):\n         if (\n             hasattr(operation, \"_call_has_training_arg\")\n-            and operation._call_has_training_arg()\n+            and operation._call_has_training_arg\n             and training is not None\n         ):\n             kwargs[\"training\"] = training\n\n@@ -183,9 +183,9 @@ class Sequential(Model):\n             # end of each iteration `inputs` is set to `outputs` to prepare for\n             # the next layer.\n             kwargs = {}\n-            if layer._call_has_mask_arg():\n+            if layer._call_has_mask_arg:\n                 kwargs[\"mask\"] = mask\n-            if layer._call_has_training_arg() and training is not None:\n+            if layer._call_has_training_arg and training is not None:\n                 kwargs[\"training\"] = training\n             outputs = layer(inputs, **kwargs)\n             inputs = outputs\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ed26f7f4c531dfd4b348ed1a6d7ad8bd14d07eb4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 96 | Lines Deleted: 37 | Files Changed: 13 | Hunks: 27 | Methods Changed: 26 | Complexity Δ (Sum/Max): 4/3 | Churn Δ: 133 | Churn Cumulative: 15105 | Contributors (this commit): 21 | Commits (past 90d): 368 | Contributors (cumulative): 91 | DMM Complexity: 1.0\n\nDIFF:\n@@ -30,7 +30,7 @@ class JAXTrainer(base_trainer.Trainer):\n     ):\n         \"\"\"This method is stateless and is intended for use with jax.grad.\"\"\"\n         kwargs = {}\n-        if self._call_has_training_arg:\n+        if self._call_has_training_arg():\n             kwargs[\"training\"] = training\n         y_pred, non_trainable_variables, losses = self.stateless_call(\n             trainable_variables,\n@@ -167,7 +167,7 @@ class JAXTrainer(base_trainer.Trainer):\n     def predict_step(self, state, data):\n         trainable_variables, non_trainable_variables = state\n         kwargs = {}\n-        if self._call_has_training_arg:\n+        if self._call_has_training_arg():\n             kwargs[\"training\"] = False\n \n         x, _, _ = data_adapter_utils.unpack_x_y_sample_weight(data)\n\n@@ -48,7 +48,7 @@ class TensorFlowTrainer(base_trainer.Trainer):\n \n         # Forward pass\n         with tf.GradientTape() as tape:\n-            if self._call_has_training_arg:\n+            if self._call_has_training_arg():\n                 y_pred = self(x, training=True)\n             else:\n                 y_pred = self(x)\n@@ -71,7 +71,7 @@ class TensorFlowTrainer(base_trainer.Trainer):\n \n     def test_step(self, data):\n         x, y, sample_weight = data_adapter_utils.unpack_x_y_sample_weight(data)\n-        if self._call_has_training_arg:\n+        if self._call_has_training_arg():\n             y_pred = self(x, training=False)\n         else:\n             y_pred = self(x)\n@@ -83,7 +83,7 @@ class TensorFlowTrainer(base_trainer.Trainer):\n \n     def predict_step(self, data):\n         x, _, _ = data_adapter_utils.unpack_x_y_sample_weight(data)\n-        if self._call_has_training_arg:\n+        if self._call_has_training_arg():\n             y_pred = self(x, training=False)\n         else:\n             y_pred = self(x)\n\n@@ -126,12 +126,9 @@ def _get_concrete_noise_shape(inputs, noise_shape):\n \n \n def dropout(inputs, rate, noise_shape=None, seed=None):\n-    if noise_shape is not None:\n     keep_prob = 1.0 - rate\n     noise_shape = _get_concrete_noise_shape(inputs, noise_shape)\n-        keep_prob_matrix = torch.full(\n-            noise_shape, keep_prob, device=get_device()\n-        )\n+    keep_prob_matrix = torch.full(noise_shape, keep_prob, device=get_device())\n     generator = torch_seed_generator(seed)\n \n     # Do not use generator during symbolic execution.\n@@ -143,12 +140,5 @@ def dropout(inputs, rate, noise_shape=None, seed=None):\n     mask = mask.bool()\n     mask = torch.broadcast_to(mask, inputs.shape)\n     return torch.where(\n-            mask,\n-            inputs / keep_prob,\n-            torch.zeros_like(inputs, dtype=inputs.dtype),\n-        )\n-    # Fast path, unseeded (since torch doesn't support seeding dropout!!!!)\n-    # Using the above implementation is possible, but much slower.\n-    return torch.nn.functional.dropout(\n-        inputs, p=rate, training=True, inplace=False\n+        mask, inputs / keep_prob, torch.zeros_like(inputs, dtype=inputs.dtype)\n     )\n\n@@ -27,7 +27,7 @@ class TorchTrainer(base_trainer.Trainer):\n         x, y, sample_weight = data_adapter_utils.unpack_x_y_sample_weight(data)\n \n         # Compute predictions\n-        if self._call_has_training_arg:\n+        if self._call_has_training_arg():\n             y_pred = self(x, training=True)\n         else:\n             y_pred = self(x)\n@@ -64,7 +64,7 @@ class TorchTrainer(base_trainer.Trainer):\n             y,\n             sample_weight,\n         ) = data_adapter_utils.unpack_x_y_sample_weight(data)\n-        if self._call_has_training_arg:\n+        if self._call_has_training_arg():\n             y_pred = self(x, training=False)\n         else:\n             y_pred = self(x)\n@@ -76,7 +76,7 @@ class TorchTrainer(base_trainer.Trainer):\n \n     def predict_step(self, data):\n         x, _, _ = data_adapter_utils.unpack_x_y_sample_weight(data)\n-        if self._call_has_training_arg:\n+        if self._call_has_training_arg():\n             y_pred = self(x, training=False)\n         else:\n             y_pred = self(x)\n\n@@ -250,12 +250,9 @@ class Layer(BackendLayer, Operation):\n         self._losses = []\n         self._loss_ids = set()\n \n-        call_signature_parameters = [\n+        self._call_signature_parameters = [\n             p.name for p in inspect.signature(self.call).parameters.values()\n         ]\n-        self._call_has_training_arg = \"training\" in call_signature_parameters\n-        self._call_has_mask_arg = \"mask\" in call_signature_parameters\n-\n         self._supports_masking = not utils.is_default(self.compute_mask)\n         # Whether to automatically convert (+ auto-cast) inputs to `call()`.\n         self._convert_input_args = True\n@@ -696,7 +693,7 @@ class Layer(BackendLayer, Operation):\n                 # Get signature default value\n                 training = call_spec.arguments_dict.get(\"training\", None)\n         call_context.training = training\n-        if self._call_has_training_arg and training is not None:\n+        if self._call_has_training_arg() and training is not None:\n             # Only populate arg if it has a concrete value\n             kwargs[\"training\"] = training\n \n@@ -1194,6 +1191,12 @@ class Layer(BackendLayer, Operation):\n                 self.input_spec, arg_0, layer_name=self.name\n             )\n \n+    def _call_has_training_arg(self):\n+        return \"training\" in self._call_signature_parameters\n+\n+    def _call_has_mask_arg(self):\n+        return \"mask\" in self._call_signature_parameters\n+\n     def _get_call_context(self):\n         \"\"\"Returns currently active `CallContext`.\"\"\"\n         layer_call_ctx = global_state.get_global_attribute(\"current_call_ctx\")\n\n@@ -141,7 +141,7 @@ class LayerTest(testing.TestCase):\n                 self.seed_gen = backend.random.SeedGenerator(seed=1337)\n \n             def call(self, x):\n-                return x * backend.random.normal(x.shape, seed=self.seed_gen)\n+                return backend.random.dropout(x, rate=0.5, seed=self.seed_gen)\n \n         layer = RNGLayer()\n         self.assertEqual(layer.variables, [layer.seed_gen.state])\n@@ -158,8 +158,8 @@ class LayerTest(testing.TestCase):\n                 self.seed_gens.append(backend.random.SeedGenerator(seed=10))\n \n             def call(self, x):\n-                x = x * backend.random.normal(x.shape, seed=self.seed_gens[0])\n-                x = x * backend.random.normal(x.shape, seed=self.seed_gens[1])\n+                x = backend.random.dropout(x, rate=0.5, seed=self.seed_gens[0])\n+                x = backend.random.dropout(x, rate=0.5, seed=self.seed_gens[1])\n                 return x\n \n         layer = RNGListLayer()\n\n@@ -198,9 +198,9 @@ class Bidirectional(Wrapper):\n         training=None,\n     ):\n         kwargs = {}\n-        if self.forward_layer._call_has_training_arg:\n+        if self.forward_layer._call_has_training_arg():\n             kwargs[\"training\"] = training\n-        if self.forward_layer._call_has_mask_arg:\n+        if self.forward_layer._call_has_mask_arg():\n             kwargs[\"mask\"] = mask\n \n         if initial_state is not None:\n\n@@ -323,7 +323,7 @@ class RNN(Layer):\n \n     def inner_loop(self, sequences, initial_state, mask, training=False):\n         cell_kwargs = {}\n-        if isinstance(self.cell, Layer) and self.cell._call_has_training_arg:\n+        if isinstance(self.cell, Layer) and self.cell._call_has_training_arg():\n             cell_kwargs[\"training\"] = training\n \n         def step(inputs, states):\n\n@@ -90,7 +90,7 @@ class StackedRNNCells(Layer):\n         new_states = []\n         for cell, states in zip(self.cells, states):\n             states = list(states) if tree.is_nested(states) else [states]\n-            if isinstance(cell, Layer) and cell._call_has_training_arg:\n+            if isinstance(cell, Layer) and cell._call_has_training_arg():\n                 kwargs[\"training\"] = training\n             else:\n                 kwargs.pop(\"training\", None)\n\n@@ -95,9 +95,9 @@ class TimeDistributed(Wrapper):\n \n         def step_function(i):\n             kwargs = {}\n-            if self.layer._call_has_mask_arg and mask is not None:\n+            if self.layer._call_has_mask_arg() and mask is not None:\n                 kwargs[\"mask\"] = mask[i]\n-            if self.layer._call_has_training_arg:\n+            if self.layer._call_has_training_arg():\n                 kwargs[\"training\"] = training\n             return self.layer.call(inputs[i], **kwargs)\n \n\n@@ -542,7 +542,7 @@ def operation_fn(operation, training):\n     def call(*args, **kwargs):\n         if (\n             hasattr(operation, \"_call_has_training_arg\")\n-            and operation._call_has_training_arg\n+            and operation._call_has_training_arg()\n             and training is not None\n         ):\n             kwargs[\"training\"] = training\n\n@@ -183,9 +183,9 @@ class Sequential(Model):\n             # end of each iteration `inputs` is set to `outputs` to prepare for\n             # the next layer.\n             kwargs = {}\n-            if layer._call_has_mask_arg:\n+            if layer._call_has_mask_arg():\n                 kwargs[\"mask\"] = mask\n-            if layer._call_has_training_arg and training is not None:\n+            if layer._call_has_training_arg() and training is not None:\n                 kwargs[\"training\"] = training\n             outputs = layer(inputs, **kwargs)\n             inputs = outputs\n\n@@ -0,0 +1,66 @@\n+import numpy as np\n+\n+from keras_core import Layer\n+from keras_core import testing\n+from keras_core.backend import KerasTensor\n+from keras_core.ops.node import Node\n+\n+\n+class DummyLayer(Layer):\n+    pass\n+\n+\n+class NodeTest(testing.TestCase):\n+    # Testing a simple node and layer combination **a**\n+    def test_simple_case(self):\n+        shape = (2, 3, 4)\n+        a = KerasTensor(shape=shape)\n+        a_layer = DummyLayer()\n+        node = Node(a_layer, outputs=a, call_args=(), call_kwargs={})\n+\n+        self.assertEqual(node.is_input, True)\n+\n+        self.assertEqual(node.output_tensors[0], a)\n+        self.assertEqual(node.output_tensors[0].shape, shape)\n+\n+    # Testing a simple node connection with args and kwargs **a** --> **b**\n+    def test_single_wired_layers(self):\n+        shape = (2, 3, 4)\n+        a = KerasTensor(shape=shape)\n+        a_layer = DummyLayer()\n+        node1 = Node(a_layer, outputs=a, call_args=(), call_kwargs={})\n+\n+        b = KerasTensor(shape=shape)\n+        x = KerasTensor(shape=shape)\n+        kwargs = {\"x\": x}\n+        args = (a,)\n+        b_layer = DummyLayer()\n+        node2 = Node(b_layer, outputs=b, call_args=args, call_kwargs=kwargs)\n+\n+        self.assertEqual(node1.is_input, True)\n+        self.assertEqual(node2.is_input, False)\n+\n+        self.assertEqual(node1.operation, a_layer)\n+        self.assertEqual(node2.operation, b_layer)\n+\n+        self.assertEqual(node1.output_tensors[0], a)\n+        self.assertEqual(node1.output_tensors[0].shape, shape)\n+\n+        self.assertEqual(a_layer._inbound_nodes[0], node1)\n+        self.assertEqual(a_layer._outbound_nodes[0], node2)\n+\n+        self.assertEqual(b_layer._inbound_nodes[0], node2)\n+        self.assertEqual(node2.parent_nodes[0], node1)\n+\n+        self.assertEqual(node2.input_tensors, [a, x])\n+        self.assertEqual(node2.arguments.kwargs, kwargs)\n+        self.assertEqual(node2.arguments.args, args)\n+\n+    # Testing when output tensor is not Keras Tensor\n+    def test_output_tensor_error(self):\n+        a = np.random.rand(2, 3, 4)\n+        a_layer = DummyLayer()\n+        with self.assertRaisesRegex(\n+            ValueError, \"operation outputs must be tensors.\"\n+        ):\n+            Node(a_layer, outputs=a, call_args=(), call_kwargs={})\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0d7026cf9a963b75a8a24da081b0f3693adf589e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 37 | Lines Deleted: 30 | Files Changed: 12 | Hunks: 26 | Methods Changed: 23 | Complexity Δ (Sum/Max): -1/1 | Churn Δ: 67 | Churn Cumulative: 15106 | Contributors (this commit): 21 | Commits (past 90d): 378 | Contributors (cumulative): 90 | DMM Complexity: 1.0\n\nDIFF:\n@@ -30,7 +30,7 @@ class JAXTrainer(base_trainer.Trainer):\n     ):\n         \"\"\"This method is stateless and is intended for use with jax.grad.\"\"\"\n         kwargs = {}\n-        if self._call_has_training_arg():\n+        if self._call_has_training_arg:\n             kwargs[\"training\"] = training\n         y_pred, non_trainable_variables, losses = self.stateless_call(\n             trainable_variables,\n@@ -167,7 +167,7 @@ class JAXTrainer(base_trainer.Trainer):\n     def predict_step(self, state, data):\n         trainable_variables, non_trainable_variables = state\n         kwargs = {}\n-        if self._call_has_training_arg():\n+        if self._call_has_training_arg:\n             kwargs[\"training\"] = False\n \n         x, _, _ = data_adapter_utils.unpack_x_y_sample_weight(data)\n\n@@ -48,7 +48,7 @@ class TensorFlowTrainer(base_trainer.Trainer):\n \n         # Forward pass\n         with tf.GradientTape() as tape:\n-            if self._call_has_training_arg():\n+            if self._call_has_training_arg:\n                 y_pred = self(x, training=True)\n             else:\n                 y_pred = self(x)\n@@ -71,7 +71,7 @@ class TensorFlowTrainer(base_trainer.Trainer):\n \n     def test_step(self, data):\n         x, y, sample_weight = data_adapter_utils.unpack_x_y_sample_weight(data)\n-        if self._call_has_training_arg():\n+        if self._call_has_training_arg:\n             y_pred = self(x, training=False)\n         else:\n             y_pred = self(x)\n@@ -83,7 +83,7 @@ class TensorFlowTrainer(base_trainer.Trainer):\n \n     def predict_step(self, data):\n         x, _, _ = data_adapter_utils.unpack_x_y_sample_weight(data)\n-        if self._call_has_training_arg():\n+        if self._call_has_training_arg:\n             y_pred = self(x, training=False)\n         else:\n             y_pred = self(x)\n\n@@ -126,9 +126,12 @@ def _get_concrete_noise_shape(inputs, noise_shape):\n \n \n def dropout(inputs, rate, noise_shape=None, seed=None):\n+    if noise_shape is not None:\n         keep_prob = 1.0 - rate\n         noise_shape = _get_concrete_noise_shape(inputs, noise_shape)\n-    keep_prob_matrix = torch.full(noise_shape, keep_prob, device=get_device())\n+        keep_prob_matrix = torch.full(\n+            noise_shape, keep_prob, device=get_device()\n+        )\n         generator = torch_seed_generator(seed)\n \n         # Do not use generator during symbolic execution.\n@@ -140,5 +143,12 @@ def dropout(inputs, rate, noise_shape=None, seed=None):\n         mask = mask.bool()\n         mask = torch.broadcast_to(mask, inputs.shape)\n         return torch.where(\n-        mask, inputs / keep_prob, torch.zeros_like(inputs, dtype=inputs.dtype)\n+            mask,\n+            inputs / keep_prob,\n+            torch.zeros_like(inputs, dtype=inputs.dtype),\n+        )\n+    # Fast path, unseeded (since torch doesn't support seeding dropout!!!!)\n+    # Using the above implementation is possible, but much slower.\n+    return torch.nn.functional.dropout(\n+        inputs, p=rate, training=True, inplace=False\n     )\n\n@@ -27,7 +27,7 @@ class TorchTrainer(base_trainer.Trainer):\n         x, y, sample_weight = data_adapter_utils.unpack_x_y_sample_weight(data)\n \n         # Compute predictions\n-        if self._call_has_training_arg():\n+        if self._call_has_training_arg:\n             y_pred = self(x, training=True)\n         else:\n             y_pred = self(x)\n@@ -64,7 +64,7 @@ class TorchTrainer(base_trainer.Trainer):\n             y,\n             sample_weight,\n         ) = data_adapter_utils.unpack_x_y_sample_weight(data)\n-        if self._call_has_training_arg():\n+        if self._call_has_training_arg:\n             y_pred = self(x, training=False)\n         else:\n             y_pred = self(x)\n@@ -76,7 +76,7 @@ class TorchTrainer(base_trainer.Trainer):\n \n     def predict_step(self, data):\n         x, _, _ = data_adapter_utils.unpack_x_y_sample_weight(data)\n-        if self._call_has_training_arg():\n+        if self._call_has_training_arg:\n             y_pred = self(x, training=False)\n         else:\n             y_pred = self(x)\n\n@@ -250,9 +250,12 @@ class Layer(BackendLayer, Operation):\n         self._losses = []\n         self._loss_ids = set()\n \n-        self._call_signature_parameters = [\n+        call_signature_parameters = [\n             p.name for p in inspect.signature(self.call).parameters.values()\n         ]\n+        self._call_has_training_arg = \"training\" in call_signature_parameters\n+        self._call_has_mask_arg = \"mask\" in call_signature_parameters\n+\n         self._supports_masking = not utils.is_default(self.compute_mask)\n         # Whether to automatically convert (+ auto-cast) inputs to `call()`.\n         self._convert_input_args = True\n@@ -693,7 +696,7 @@ class Layer(BackendLayer, Operation):\n                 # Get signature default value\n                 training = call_spec.arguments_dict.get(\"training\", None)\n         call_context.training = training\n-        if self._call_has_training_arg() and training is not None:\n+        if self._call_has_training_arg and training is not None:\n             # Only populate arg if it has a concrete value\n             kwargs[\"training\"] = training\n \n@@ -1191,12 +1194,6 @@ class Layer(BackendLayer, Operation):\n                 self.input_spec, arg_0, layer_name=self.name\n             )\n \n-    def _call_has_training_arg(self):\n-        return \"training\" in self._call_signature_parameters\n-\n-    def _call_has_mask_arg(self):\n-        return \"mask\" in self._call_signature_parameters\n-\n     def _get_call_context(self):\n         \"\"\"Returns currently active `CallContext`.\"\"\"\n         layer_call_ctx = global_state.get_global_attribute(\"current_call_ctx\")\n\n@@ -141,7 +141,7 @@ class LayerTest(testing.TestCase):\n                 self.seed_gen = backend.random.SeedGenerator(seed=1337)\n \n             def call(self, x):\n-                return backend.random.dropout(x, rate=0.5, seed=self.seed_gen)\n+                return x * backend.random.normal(x.shape, seed=self.seed_gen)\n \n         layer = RNGLayer()\n         self.assertEqual(layer.variables, [layer.seed_gen.state])\n@@ -158,8 +158,8 @@ class LayerTest(testing.TestCase):\n                 self.seed_gens.append(backend.random.SeedGenerator(seed=10))\n \n             def call(self, x):\n-                x = backend.random.dropout(x, rate=0.5, seed=self.seed_gens[0])\n-                x = backend.random.dropout(x, rate=0.5, seed=self.seed_gens[1])\n+                x = x * backend.random.normal(x.shape, seed=self.seed_gens[0])\n+                x = x * backend.random.normal(x.shape, seed=self.seed_gens[1])\n                 return x\n \n         layer = RNGListLayer()\n\n@@ -198,9 +198,9 @@ class Bidirectional(Wrapper):\n         training=None,\n     ):\n         kwargs = {}\n-        if self.forward_layer._call_has_training_arg():\n+        if self.forward_layer._call_has_training_arg:\n             kwargs[\"training\"] = training\n-        if self.forward_layer._call_has_mask_arg():\n+        if self.forward_layer._call_has_mask_arg:\n             kwargs[\"mask\"] = mask\n \n         if initial_state is not None:\n\n@@ -323,7 +323,7 @@ class RNN(Layer):\n \n     def inner_loop(self, sequences, initial_state, mask, training=False):\n         cell_kwargs = {}\n-        if isinstance(self.cell, Layer) and self.cell._call_has_training_arg():\n+        if isinstance(self.cell, Layer) and self.cell._call_has_training_arg:\n             cell_kwargs[\"training\"] = training\n \n         def step(inputs, states):\n\n@@ -90,7 +90,7 @@ class StackedRNNCells(Layer):\n         new_states = []\n         for cell, states in zip(self.cells, states):\n             states = list(states) if tree.is_nested(states) else [states]\n-            if isinstance(cell, Layer) and cell._call_has_training_arg():\n+            if isinstance(cell, Layer) and cell._call_has_training_arg:\n                 kwargs[\"training\"] = training\n             else:\n                 kwargs.pop(\"training\", None)\n\n@@ -95,9 +95,9 @@ class TimeDistributed(Wrapper):\n \n         def step_function(i):\n             kwargs = {}\n-            if self.layer._call_has_mask_arg() and mask is not None:\n+            if self.layer._call_has_mask_arg and mask is not None:\n                 kwargs[\"mask\"] = mask[i]\n-            if self.layer._call_has_training_arg():\n+            if self.layer._call_has_training_arg:\n                 kwargs[\"training\"] = training\n             return self.layer.call(inputs[i], **kwargs)\n \n\n@@ -542,7 +542,7 @@ def operation_fn(operation, training):\n     def call(*args, **kwargs):\n         if (\n             hasattr(operation, \"_call_has_training_arg\")\n-            and operation._call_has_training_arg()\n+            and operation._call_has_training_arg\n             and training is not None\n         ):\n             kwargs[\"training\"] = training\n\n@@ -183,9 +183,9 @@ class Sequential(Model):\n             # end of each iteration `inputs` is set to `outputs` to prepare for\n             # the next layer.\n             kwargs = {}\n-            if layer._call_has_mask_arg():\n+            if layer._call_has_mask_arg:\n                 kwargs[\"mask\"] = mask\n-            if layer._call_has_training_arg() and training is not None:\n+            if layer._call_has_training_arg and training is not None:\n                 kwargs[\"training\"] = training\n             outputs = layer(inputs, **kwargs)\n             inputs = outputs\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1dd4de852276182be7a53a8dbb99b32cc60ae0ce", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 362 | Lines Deleted: 37 | Files Changed: 18 | Hunks: 36 | Methods Changed: 40 | Complexity Δ (Sum/Max): 52/19 | Churn Δ: 399 | Churn Cumulative: 16179 | Contributors (this commit): 24 | Commits (past 90d): 424 | Contributors (cumulative): 127 | DMM Complexity: 0.4075829383886256\n\nDIFF:\n@@ -43,3 +43,43 @@ def qr(x, mode=\"reduced\"):\n             f\"Received: mode={mode}\"\n         )\n     return jax.numpy.linalg.qr(x, mode=mode)\n+\n+\n+def _get_complex_tensor_from_tuple(a):\n+    if not isinstance(a, (tuple, list)) or len(a) != 2:\n+        raise ValueError(\n+            \"Input `a` should be a tuple of two tensors - real and imaginary.\"\n+            f\"Received: a={a}\"\n+        )\n+    # `convert_to_tensor` does not support passing complex tensors. We separate\n+    # the input out into real and imaginary and convert them separately.\n+    real, imag = a\n+    # Check shapes.\n+    if real.shape != imag.shape:\n+        raise ValueError(\n+            \"Input `a` should be a tuple of two tensors - real and imaginary.\"\n+            \"Both the real and imaginary parts should have the same shape. \"\n+            f\"Received: a[0].shape = {real.shape}, a[1].shape = {imag.shape}\"\n+        )\n+    # Ensure dtype is float.\n+    if not jnp.issubdtype(real.dtype, jnp.floating) or not jnp.issubdtype(\n+        imag.dtype, jnp.floating\n+    ):\n+        raise ValueError(\n+            \"At least one tensor in input `a` is not of type float.\"\n+            f\"Received: a={a}.\"\n+        )\n+    complex_input = jax.lax.complex(real, imag)\n+    return complex_input\n+\n+\n+def fft(a):\n+    complex_input = _get_complex_tensor_from_tuple(a)\n+    complex_output = jax.numpy.fft.fft(complex_input)\n+    return jax.numpy.real(complex_output), jax.numpy.imag(complex_output)\n+\n+\n+def fft2(a):\n+    complex_input = _get_complex_tensor_from_tuple(a)\n+    complex_output = jax.numpy.fft.fft2(complex_input)\n+    return jax.numpy.real(complex_output), jax.numpy.imag(complex_output)\n\n@@ -30,7 +30,7 @@ class JAXTrainer(base_trainer.Trainer):\n     ):\n         \"\"\"This method is stateless and is intended for use with jax.grad.\"\"\"\n         kwargs = {}\n-        if self._call_has_training_arg:\n+        if self._call_has_training_arg():\n             kwargs[\"training\"] = training\n         y_pred, non_trainable_variables, losses = self.stateless_call(\n             trainable_variables,\n@@ -167,7 +167,7 @@ class JAXTrainer(base_trainer.Trainer):\n     def predict_step(self, state, data):\n         trainable_variables, non_trainable_variables = state\n         kwargs = {}\n-        if self._call_has_training_arg:\n+        if self._call_has_training_arg():\n             kwargs[\"training\"] = False\n \n         x, _, _ = data_adapter_utils.unpack_x_y_sample_weight(data)\n\n@@ -1,5 +1,8 @@\n import numpy as np\n \n+from keras_core.backend.jax.math import fft as jax_fft\n+from keras_core.backend.jax.math import fft2 as jax_fft2\n+\n \n def segment_sum(data, segment_ids, num_segments=None, sorted=False):\n     if num_segments is None:\n@@ -74,3 +77,13 @@ def qr(x, mode=\"reduced\"):\n             f\"Received: mode={mode}\"\n         )\n     return np.linalg.qr(x, mode=mode)\n+\n+\n+def fft(a):\n+    real, imag = jax_fft(a)\n+    return np.array(real), np.array(imag)\n+\n+\n+def fft2(a):\n+    real, imag = jax_fft2(a)\n+    return np.array(real), np.array(imag)\n\n@@ -1,5 +1,7 @@\n import tensorflow as tf\n \n+from keras_core.backend.tensorflow.core import convert_to_tensor\n+\n \n def segment_sum(data, segment_ids, num_segments=None, sorted=False):\n     if sorted:\n@@ -33,3 +35,43 @@ def qr(x, mode=\"reduced\"):\n     if mode == \"reduced\":\n         return tf.linalg.qr(x)\n     return tf.linalg.qr(x, full_matrices=True)\n+\n+\n+def _get_complex_tensor_from_tuple(a):\n+    if not isinstance(a, (tuple, list)) or len(a) != 2:\n+        raise ValueError(\n+            \"Input `a` should be a tuple of two tensors - real and imaginary.\"\n+            f\"Received: a={a}\"\n+        )\n+    # `convert_to_tensor` does not support passing complex tensors. We separate\n+    # the input out into real and imaginary and convert them separately.\n+    real, imag = a\n+    real = convert_to_tensor(real)\n+    imag = convert_to_tensor(imag)\n+    # Check shapes.\n+    if real.shape != imag.shape:\n+        raise ValueError(\n+            \"Input `a` should be a tuple of two tensors - real and imaginary.\"\n+            \"Both the real and imaginary parts should have the same shape. \"\n+            f\"Received: a[0].shape = {real.shape}, a[1].shape = {imag.shape}\"\n+        )\n+    # Ensure dtype is float.\n+    if not real.dtype.is_floating or not imag.dtype.is_floating:\n+        raise ValueError(\n+            \"At least one tensor in input `a` is not of type float.\"\n+            f\"Received: a={a}.\"\n+        )\n+    complex_input = tf.dtypes.complex(real, imag)\n+    return complex_input\n+\n+\n+def fft(a):\n+    complex_input = _get_complex_tensor_from_tuple(a)\n+    complex_output = tf.signal.fft(complex_input)\n+    return tf.math.real(complex_output), tf.math.imag(complex_output)\n+\n+\n+def fft2(a):\n+    complex_input = _get_complex_tensor_from_tuple(a)\n+    complex_output = tf.signal.fft2d(complex_input)\n+    return tf.math.real(complex_output), tf.math.imag(complex_output)\n\n@@ -48,7 +48,7 @@ class TensorFlowTrainer(base_trainer.Trainer):\n \n         # Forward pass\n         with tf.GradientTape() as tape:\n-            if self._call_has_training_arg:\n+            if self._call_has_training_arg():\n                 y_pred = self(x, training=True)\n             else:\n                 y_pred = self(x)\n@@ -71,7 +71,7 @@ class TensorFlowTrainer(base_trainer.Trainer):\n \n     def test_step(self, data):\n         x, y, sample_weight = data_adapter_utils.unpack_x_y_sample_weight(data)\n-        if self._call_has_training_arg:\n+        if self._call_has_training_arg():\n             y_pred = self(x, training=False)\n         else:\n             y_pred = self(x)\n@@ -83,7 +83,7 @@ class TensorFlowTrainer(base_trainer.Trainer):\n \n     def predict_step(self, data):\n         x, _, _ = data_adapter_utils.unpack_x_y_sample_weight(data)\n-        if self._call_has_training_arg:\n+        if self._call_has_training_arg():\n             y_pred = self(x, training=False)\n         else:\n             y_pred = self(x)\n\n@@ -81,3 +81,44 @@ def qr(x, mode=\"reduced\"):\n         )\n     x = convert_to_tensor(x)\n     return torch.linalg.qr(x, mode=mode)\n+\n+\n+def _get_complex_tensor_from_tuple(a):\n+    if not isinstance(a, (tuple, list)) or len(a) != 2:\n+        raise ValueError(\n+            \"Input `a` should be a tuple of two tensors - real and imaginary.\"\n+            f\"Received: a={a}\"\n+        )\n+    # `convert_to_tensor` does not support passing complex tensors. We separate\n+    # the input out into real and imaginary and convert them separately.\n+    real, imag = a\n+    real = convert_to_tensor(real)\n+    imag = convert_to_tensor(imag)\n+    # Check shape.\n+    if real.shape != imag.shape:\n+        raise ValueError(\n+            \"Input `a` should be a tuple of two tensors - real and imaginary.\"\n+            \"Both the real and imaginary parts should have the same shape. \"\n+            f\"Received: a[0].shape = {real.shape}, a[1].shape = {imag.shape}\"\n+        )\n+    # Ensure dtype is float.\n+    if not torch.is_floating_point(real) or not torch.is_floating_point(imag):\n+        raise ValueError(\n+            \"At least one tensor in input `a` is not of type float.\"\n+            f\"Received: a={a}.\"\n+        )\n+\n+    complex_input = torch.complex(real, imag)\n+    return complex_input\n+\n+\n+def fft(a):\n+    complex_input = _get_complex_tensor_from_tuple(a)\n+    complex_output = torch.fft.fft(complex_input)\n+    return complex_output.real, complex_output.imag\n+\n+\n+def fft2(a):\n+    complex_input = _get_complex_tensor_from_tuple(a)\n+    complex_output = torch.fft.fft2(complex_input)\n+    return complex_output.real, complex_output.imag\n\n@@ -126,12 +126,9 @@ def _get_concrete_noise_shape(inputs, noise_shape):\n \n \n def dropout(inputs, rate, noise_shape=None, seed=None):\n-    if noise_shape is not None:\n     keep_prob = 1.0 - rate\n     noise_shape = _get_concrete_noise_shape(inputs, noise_shape)\n-        keep_prob_matrix = torch.full(\n-            noise_shape, keep_prob, device=get_device()\n-        )\n+    keep_prob_matrix = torch.full(noise_shape, keep_prob, device=get_device())\n     generator = torch_seed_generator(seed)\n \n     # Do not use generator during symbolic execution.\n@@ -143,12 +140,5 @@ def dropout(inputs, rate, noise_shape=None, seed=None):\n     mask = mask.bool()\n     mask = torch.broadcast_to(mask, inputs.shape)\n     return torch.where(\n-            mask,\n-            inputs / keep_prob,\n-            torch.zeros_like(inputs, dtype=inputs.dtype),\n-        )\n-    # Fast path, unseeded (since torch doesn't support seeding dropout!!!!)\n-    # Using the above implementation is possible, but much slower.\n-    return torch.nn.functional.dropout(\n-        inputs, p=rate, training=True, inplace=False\n+        mask, inputs / keep_prob, torch.zeros_like(inputs, dtype=inputs.dtype)\n     )\n\n@@ -27,7 +27,7 @@ class TorchTrainer(base_trainer.Trainer):\n         x, y, sample_weight = data_adapter_utils.unpack_x_y_sample_weight(data)\n \n         # Compute predictions\n-        if self._call_has_training_arg:\n+        if self._call_has_training_arg():\n             y_pred = self(x, training=True)\n         else:\n             y_pred = self(x)\n@@ -64,7 +64,7 @@ class TorchTrainer(base_trainer.Trainer):\n             y,\n             sample_weight,\n         ) = data_adapter_utils.unpack_x_y_sample_weight(data)\n-        if self._call_has_training_arg:\n+        if self._call_has_training_arg():\n             y_pred = self(x, training=False)\n         else:\n             y_pred = self(x)\n@@ -76,7 +76,7 @@ class TorchTrainer(base_trainer.Trainer):\n \n     def predict_step(self, data):\n         x, _, _ = data_adapter_utils.unpack_x_y_sample_weight(data)\n-        if self._call_has_training_arg:\n+        if self._call_has_training_arg():\n             y_pred = self(x, training=False)\n         else:\n             y_pred = self(x)\n\n@@ -250,12 +250,9 @@ class Layer(BackendLayer, Operation):\n         self._losses = []\n         self._loss_ids = set()\n \n-        call_signature_parameters = [\n+        self._call_signature_parameters = [\n             p.name for p in inspect.signature(self.call).parameters.values()\n         ]\n-        self._call_has_training_arg = \"training\" in call_signature_parameters\n-        self._call_has_mask_arg = \"mask\" in call_signature_parameters\n-\n         self._supports_masking = not utils.is_default(self.compute_mask)\n         # Whether to automatically convert (+ auto-cast) inputs to `call()`.\n         self._convert_input_args = True\n@@ -696,7 +693,7 @@ class Layer(BackendLayer, Operation):\n                 # Get signature default value\n                 training = call_spec.arguments_dict.get(\"training\", None)\n         call_context.training = training\n-        if self._call_has_training_arg and training is not None:\n+        if self._call_has_training_arg() and training is not None:\n             # Only populate arg if it has a concrete value\n             kwargs[\"training\"] = training\n \n@@ -1194,6 +1191,12 @@ class Layer(BackendLayer, Operation):\n                 self.input_spec, arg_0, layer_name=self.name\n             )\n \n+    def _call_has_training_arg(self):\n+        return \"training\" in self._call_signature_parameters\n+\n+    def _call_has_mask_arg(self):\n+        return \"mask\" in self._call_signature_parameters\n+\n     def _get_call_context(self):\n         \"\"\"Returns currently active `CallContext`.\"\"\"\n         layer_call_ctx = global_state.get_global_attribute(\"current_call_ctx\")\n\n@@ -141,7 +141,7 @@ class LayerTest(testing.TestCase):\n                 self.seed_gen = backend.random.SeedGenerator(seed=1337)\n \n             def call(self, x):\n-                return x * backend.random.normal(x.shape, seed=self.seed_gen)\n+                return backend.random.dropout(x, rate=0.5, seed=self.seed_gen)\n \n         layer = RNGLayer()\n         self.assertEqual(layer.variables, [layer.seed_gen.state])\n@@ -158,8 +158,8 @@ class LayerTest(testing.TestCase):\n                 self.seed_gens.append(backend.random.SeedGenerator(seed=10))\n \n             def call(self, x):\n-                x = x * backend.random.normal(x.shape, seed=self.seed_gens[0])\n-                x = x * backend.random.normal(x.shape, seed=self.seed_gens[1])\n+                x = backend.random.dropout(x, rate=0.5, seed=self.seed_gens[0])\n+                x = backend.random.dropout(x, rate=0.5, seed=self.seed_gens[1])\n                 return x\n \n         layer = RNGListLayer()\n\n@@ -198,9 +198,9 @@ class Bidirectional(Wrapper):\n         training=None,\n     ):\n         kwargs = {}\n-        if self.forward_layer._call_has_training_arg:\n+        if self.forward_layer._call_has_training_arg():\n             kwargs[\"training\"] = training\n-        if self.forward_layer._call_has_mask_arg:\n+        if self.forward_layer._call_has_mask_arg():\n             kwargs[\"mask\"] = mask\n \n         if initial_state is not None:\n\n@@ -323,7 +323,7 @@ class RNN(Layer):\n \n     def inner_loop(self, sequences, initial_state, mask, training=False):\n         cell_kwargs = {}\n-        if isinstance(self.cell, Layer) and self.cell._call_has_training_arg:\n+        if isinstance(self.cell, Layer) and self.cell._call_has_training_arg():\n             cell_kwargs[\"training\"] = training\n \n         def step(inputs, states):\n\n@@ -90,7 +90,7 @@ class StackedRNNCells(Layer):\n         new_states = []\n         for cell, states in zip(self.cells, states):\n             states = list(states) if tree.is_nested(states) else [states]\n-            if isinstance(cell, Layer) and cell._call_has_training_arg:\n+            if isinstance(cell, Layer) and cell._call_has_training_arg():\n                 kwargs[\"training\"] = training\n             else:\n                 kwargs.pop(\"training\", None)\n\n@@ -95,9 +95,9 @@ class TimeDistributed(Wrapper):\n \n         def step_function(i):\n             kwargs = {}\n-            if self.layer._call_has_mask_arg and mask is not None:\n+            if self.layer._call_has_mask_arg() and mask is not None:\n                 kwargs[\"mask\"] = mask[i]\n-            if self.layer._call_has_training_arg:\n+            if self.layer._call_has_training_arg():\n                 kwargs[\"training\"] = training\n             return self.layer.call(inputs[i], **kwargs)\n \n\n@@ -542,7 +542,7 @@ def operation_fn(operation, training):\n     def call(*args, **kwargs):\n         if (\n             hasattr(operation, \"_call_has_training_arg\")\n-            and operation._call_has_training_arg\n+            and operation._call_has_training_arg()\n             and training is not None\n         ):\n             kwargs[\"training\"] = training\n\n@@ -183,9 +183,9 @@ class Sequential(Model):\n             # end of each iteration `inputs` is set to `outputs` to prepare for\n             # the next layer.\n             kwargs = {}\n-            if layer._call_has_mask_arg:\n+            if layer._call_has_mask_arg():\n                 kwargs[\"mask\"] = mask\n-            if layer._call_has_training_arg and training is not None:\n+            if layer._call_has_training_arg() and training is not None:\n                 kwargs[\"training\"] = training\n             outputs = layer(inputs, **kwargs)\n             inputs = outputs\n\n@@ -260,3 +260,141 @@ def qr(x, mode=\"reduced\"):\n     if any_symbolic_tensors((x,)):\n         return Qr(mode=mode).symbolic_call(x)\n     return backend.math.qr(x, mode=mode)\n+\n+\n+class FFT(Operation):\n+    def compute_output_spec(self, a):\n+        if not isinstance(a, (tuple, list)) or len(a) != 2:\n+            raise ValueError(\n+                \"Input `a` should be a tuple of two tensors - real and \"\n+                f\"imaginary. Received: a={a}\"\n+            )\n+\n+        real, imag = a\n+        # Both real and imaginary parts should have the same shape.\n+        if real.shape != imag.shape:\n+            raise ValueError(\n+                \"Input `a` should be a tuple of two tensors - real and \"\n+                \"imaginary. Both the real and imaginary parts should have the \"\n+                f\"same shape. Received: a[0].shape = {real.shape}, \"\n+                f\"a[1].shape = {imag.shape}\"\n+            )\n+\n+        # We are calculating 1D FFT. Hence, rank >= 1.\n+        if len(real.shape) < 1:\n+            raise ValueError(\n+                f\"Input should have rank >= 1. \"\n+                f\"Received: input.shape = {real.shape}\"\n+            )\n+\n+        # The axis along which we are calculating FFT should be fully-defined.\n+        m = real.shape[-1]\n+        if m is None:\n+            raise ValueError(\n+                f\"Input should have its {self.axis}th axis fully-defined. \"\n+                f\"Received: input.shape = {real.shape}\"\n+            )\n+\n+        return (\n+            KerasTensor(shape=real.shape, dtype=real.dtype),\n+            KerasTensor(shape=imag.shape, dtype=imag.dtype),\n+        )\n+\n+    def call(self, x):\n+        return backend.math.fft(x)\n+\n+\n+class FFT2(Operation):\n+    def compute_output_spec(self, a):\n+        if not isinstance(a, (tuple, list)) or len(a) != 2:\n+            raise ValueError(\n+                \"Input `a` should be a tuple of two tensors - real and \"\n+                f\"imaginary. Received: a={a}\"\n+            )\n+\n+        real, imag = a\n+        # Both real and imaginary parts should have the same shape.\n+        if real.shape != imag.shape:\n+            raise ValueError(\n+                \"Input `a` should be a tuple of two tensors - real and \"\n+                \"imaginary. Both the real and imaginary parts should have the \"\n+                f\"same shape. Received: a[0].shape = {real.shape}, \"\n+                f\"a[1].shape = {imag.shape}\"\n+            )\n+        # We are calculating 2D FFT. Hence, rank >= 2.\n+        if len(real.shape) < 2:\n+            raise ValueError(\n+                f\"Input should have rank >= 2. \"\n+                f\"Received: input.shape = {real.shape}\"\n+            )\n+\n+        # The axes along which we are calculating FFT should be fully-defined.\n+        m = real.shape[-1]\n+        n = real.shape[-2]\n+        if m is None or n is None:\n+            raise ValueError(\n+                f\"Input should have its {self.axes} axes fully-defined. \"\n+                f\"Received: input.shape = {real.shape}\"\n+            )\n+\n+        return (\n+            KerasTensor(shape=real.shape, dtype=real.dtype),\n+            KerasTensor(shape=imag.shape, dtype=imag.dtype),\n+        )\n+\n+    def call(self, x):\n+        return backend.math.fft2(x)\n+\n+\n+@keras_core_export(\"keras_core.ops.fft\")\n+def fft(a):\n+    \"\"\"Computes the Fast Fourier Transform along last axis of input.\n+\n+    Args:\n+        a: Tuple of the real and imaginary parts of the input tensor. Both\n+            tensors in the tuple should be of floating type.\n+\n+    Returns:\n+        A tuple containing two tensors - the real and imaginary parts of the\n+        output tensor.\n+\n+    Example:\n+\n+    >>> a = (\n+    ...     keras_core.ops.convert_to_tensor([1., 2.]),\n+    ...     keras_core.ops.convert_to_tensor([0., 1.]),\n+    ... )\n+    >>> fft(x)\n+    (array([ 3., -1.], dtype=float32), array([ 1., -1.], dtype=float32))\n+    \"\"\"\n+    if any_symbolic_tensors(a):\n+        return FFT().symbolic_call(a)\n+    return backend.math.fft(a)\n+\n+\n+@keras_core_export(\"keras_core.ops.fft2\")\n+def fft2(a):\n+    \"\"\"Computes the 2D Fast Fourier Transform along the last two axes of input.\n+\n+    Args:\n+        a: Tuple of the real and imaginary parts of the input tensor. Both\n+            tensors in the tuple should be of floating type.\n+\n+    Returns:\n+        A tuple containing two tensors - the real and imaginary parts of the\n+        output.\n+\n+    Example:\n+\n+    >>> x = (\n+    ...     keras_core.ops.convert_to_tensor([[1., 2.], [2., 1.]]),\n+    ...     keras_core.ops.convert_to_tensor([[0., 1.], [1., 0.]]),\n+    ... )\n+    >>> fft2(x)\n+    (array([[ 6.,  0.],\n+        [ 0., -2.]], dtype=float32), array([[ 2.,  0.],\n+        [ 0., -2.]], dtype=float32))\n+    \"\"\"\n+    if any_symbolic_tensors(a):\n+        return FFT2().symbolic_call(a)\n+    return backend.math.fft2(a)\n\n@@ -54,6 +54,24 @@ class MathOpsDynamicShapeTest(testing.TestCase):\n         self.assertEqual(q.shape, qref_shape)\n         self.assertEqual(r.shape, rref_shape)\n \n+    def test_fft(self):\n+        real = KerasTensor((None, 4, 3), dtype=\"float32\")\n+        imag = KerasTensor((None, 4, 3), dtype=\"float32\")\n+        real_output, imag_output = kmath.fft((real, imag))\n+        ref = np.fft.fft(np.ones((2, 4, 3)))\n+        ref_shape = (None,) + ref.shape[1:]\n+        self.assertEqual(real_output.shape, ref_shape)\n+        self.assertEqual(imag_output.shape, ref_shape)\n+\n+    def test_fft2(self):\n+        real = KerasTensor((None, 4, 3), dtype=\"float32\")\n+        imag = KerasTensor((None, 4, 3), dtype=\"float32\")\n+        real_output, imag_output = kmath.fft2((real, imag))\n+        ref = np.fft.fft2(np.ones((2, 4, 3)))\n+        ref_shape = (None,) + ref.shape[1:]\n+        self.assertEqual(real_output.shape, ref_shape)\n+        self.assertEqual(imag_output.shape, ref_shape)\n+\n \n class MathOpsStaticShapeTest(testing.TestCase):\n     @pytest.mark.skipif(\n@@ -100,6 +118,22 @@ class MathOpsStaticShapeTest(testing.TestCase):\n         self.assertEqual(q.shape, qref.shape)\n         self.assertEqual(r.shape, rref.shape)\n \n+    def test_fft(self):\n+        real = KerasTensor((2, 4, 3), dtype=\"float32\")\n+        imag = KerasTensor((2, 4, 3), dtype=\"float32\")\n+        real_output, imag_output = kmath.fft((real, imag))\n+        ref = np.fft.fft(np.ones((2, 4, 3)))\n+        self.assertEqual(real_output.shape, ref.shape)\n+        self.assertEqual(imag_output.shape, ref.shape)\n+\n+    def test_fft2(self):\n+        real = KerasTensor((2, 4, 3), dtype=\"float32\")\n+        imag = KerasTensor((2, 4, 3), dtype=\"float32\")\n+        real_output, imag_output = kmath.fft2((real, imag))\n+        ref = np.fft.fft2(np.ones((2, 4, 3)))\n+        self.assertEqual(real_output.shape, ref.shape)\n+        self.assertEqual(imag_output.shape, ref.shape)\n+\n \n class MathOpsCorrectnessTest(testing.TestCase):\n     @pytest.mark.skipif(\n@@ -226,3 +260,27 @@ class MathOpsCorrectnessTest(testing.TestCase):\n         qref, rref = np.linalg.qr(x, mode=\"complete\")\n         self.assertAllClose(qref, q)\n         self.assertAllClose(rref, r)\n+\n+    def test_fft(self):\n+        real = np.random.random((2, 4, 3))\n+        imag = np.random.random((2, 4, 3))\n+        complex_arr = real + 1j * imag\n+\n+        real_output, imag_output = kmath.fft((real, imag))\n+        ref = np.fft.fft(complex_arr)\n+        real_ref = np.real(ref)\n+        imag_ref = np.imag(ref)\n+        self.assertAllClose(real_ref, real_output)\n+        self.assertAllClose(imag_ref, imag_output)\n+\n+    def test_fft2(self):\n+        real = np.random.random((2, 4, 3))\n+        imag = np.random.random((2, 4, 3))\n+        complex_arr = real + 1j * imag\n+\n+        real_output, imag_output = kmath.fft2((real, imag))\n+        ref = np.fft.fft2(complex_arr)\n+        real_ref = np.real(ref)\n+        imag_ref = np.imag(ref)\n+        self.assertAllClose(real_ref, real_output)\n+        self.assertAllClose(imag_ref, imag_output)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
