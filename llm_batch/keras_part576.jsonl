{"custom_id": "keras#601ddc0c1774f30ddcd172c3d3617e979d839abb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 53 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 3 | Methods Changed: 5 | Complexity Δ (Sum/Max): 5/3 | Churn Δ: 53 | Churn Cumulative: 53 | Contributors (this commit): 1 | Commits (past 90d): 3 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1 @@\n+from keras_core.layers.activations.elu import ELU\n\n@@ -0,0 +1,29 @@\n+from keras_core import activations\n+from keras_core.api_export import keras_core_export\n+from keras_core.layers.layer import Layer\n+\n+\n+@keras_core_export(\"keras_core.layers.ELU\")\n+class ELU(Layer):\n+    \"\"\"Applies an Exponential Linear Unit function to an output.\n+\n+    Formula:\n+    ```python\n+    f(x) = (exp(x) - 1.) for x < 0\n+    f(x) = x for x >= 0\n+    ```\n+\n+    Args:\n+        **kwargs: Base layer keyword arguments, such as\n+            `name` and `dtype`.\n+    \"\"\"\n+\n+    def __init__(self, **kwargs):\n+        super().__init__(**kwargs)\n+        self.supports_masking = True\n+\n+    def call(self, inputs):\n+        return activations.elu(inputs)\n+\n+    def compute_output_shape(self, input_shape):\n+        return input_shape\n\n@@ -0,0 +1,23 @@\n+import numpy as np\n+\n+from keras_core import testing\n+from keras_core.layers.activations import elu\n+\n+\n+class ELUTest(testing.TestCase):\n+    def test_config(self):\n+        elu_layer = elu.ELU()\n+        self.run_class_serialization_test(elu_layer)\n+\n+    def test_elu(self):\n+        self.run_layer_test(\n+            elu.ELU,\n+            init_kwargs={},\n+            input_shape=(2, 3, 4),\n+            supports_masking=True,\n+        )\n+\n+        x = np.random.random((2, 5))\n+        elu_layer = elu.ELU()\n+        result = elu_layer(x[np.newaxis, :])[0]\n+        self.assertAllClose(result, x, rtol=1e-05)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4594ab246dd6aae3089025e294643e0ba3ffe0df", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 100 | Lines Deleted: 1 | Files Changed: 3 | Hunks: 3 | Methods Changed: 6 | Complexity Δ (Sum/Max): 6/3 | Churn Δ: 101 | Churn Cumulative: 5904 | Contributors (this commit): 8 | Commits (past 90d): 63 | Contributors (cumulative): 17 | DMM Complexity: 1.0\n\nDIFF:\n@@ -226,7 +226,7 @@ class LogCosh(LossFunctionWrapper):\n \n     ```python\n     error = y_pred - y_true\n-    logcosh = log((exp(error) + exp(-error))/2)`\n+    logcosh = mean(log((exp(error) + exp(-error))/2), axis=-1)`\n     ```\n     where x is the error `y_pred - y_true`.\n \n\n@@ -174,6 +174,72 @@ class MeanSquaredLogarithmicError(reduction_metrics.MeanMetricWrapper):\n         return {\"name\": self.name, \"dtype\": self.dtype}\n \n \n+@keras_core_export(\"keras_core.metrics.RootMeanSquaredError\")\n+class RootMeanSquaredError(reduction_metrics.Mean):\n+    \"\"\"Computes root mean squared error metric between `y_true` and `y_pred`.\n+\n+    Formula:\n+\n+    ```python\n+    loss = sqrt(mean((y_pred-y_true)^2))\n+    ```\n+\n+    Args:\n+        name: (Optional) string name of the metric instance.\n+        dtype: (Optional) data type of the metric result.\n+\n+    Examples:\n+\n+    Standalone usage:\n+\n+    >>> m = keras_core.metrics.RootMeanSquaredError()\n+    >>> m.update_state([[0, 1], [0, 0]], [[1, 1], [0, 0]])\n+    >>> m.result()\n+    0.5\n+\n+    >>> m.reset_state()\n+    >>> m.update_state([[0, 1], [0, 0]], [[1, 1], [0, 0]],\n+    ...                sample_weight=[1, 0])\n+    >>> m.result().numpy()\n+    0.70710677\n+\n+    Usage with `compile()` API:\n+\n+    ```python\n+    model.compile(\n+        optimizer='sgd',\n+        loss='mse',\n+        metrics=[keras_core.metrics.RootMeanSquaredError()])\n+    ```\n+    \"\"\"\n+\n+    def __init__(self, name=\"root_mean_squared_error\", dtype=None):\n+        super().__init__(name, dtype=dtype)\n+\n+    def update_state(self, y_true, y_pred, sample_weight=None):\n+        \"\"\"Accumulates root mean squared error statistics.\n+\n+        Args:\n+            y_true: The ground truth values.\n+            y_pred: The predicted values.\n+            sample_weight: Optional weighting of each example. Can\n+                be a `Tensor` whose rank is either 0, or the same rank as\n+                `y_true`, and must be broadcastable to `y_true`.\n+                Defaults to `1`.\n+\n+        Returns:\n+            Update op.\n+        \"\"\"\n+        y_true = ops.convert_to_tensor(y_true, self._dtype)\n+        y_pred = ops.convert_to_tensor(y_pred, self._dtype)\n+        y_true, y_pred = squeeze_to_same_rank(y_true, y_pred)\n+        error_sq = ops.square(y_pred - y_true)\n+        return super().update_state(error_sq, sample_weight=sample_weight)\n+\n+    def result(self):\n+        return ops.sqrt(super().result())\n+\n+\n @keras_core_export(\"keras_core.metrics.CosineSimilarity\")\n class CosineSimilarity(reduction_metrics.MeanMetricWrapper):\n     \"\"\"Computes the cosine similarity between the labels and predictions.\n\n@@ -223,6 +223,39 @@ class MeanSquaredLogarithmicErrorTest(testing.TestCase):\n         self.assertAllClose(0.26082, result, atol=1e-5)\n \n \n+class RootMeanSquaredErrorTest(testing.TestCase):\n+    def test_config(self):\n+        rmse_obj = metrics.RootMeanSquaredError(name=\"rmse\", dtype=\"int32\")\n+        self.assertEqual(rmse_obj.name, \"rmse\")\n+        self.assertEqual(rmse_obj._dtype, \"int32\")\n+\n+        rmse_obj2 = metrics.RootMeanSquaredError.from_config(\n+            rmse_obj.get_config()\n+        )\n+        self.assertEqual(rmse_obj2.name, \"rmse\")\n+        self.assertEqual(rmse_obj2._dtype, \"int32\")\n+\n+    def test_unweighted(self):\n+        rmse_obj = metrics.RootMeanSquaredError()\n+        y_true = np.array([2, 4, 6])\n+        y_pred = np.array([1, 3, 2])\n+\n+        rmse_obj.update_state(y_true, y_pred)\n+        result = rmse_obj.result()\n+        # error = [-1, -1, -4], square(error) = [1, 1, 16], mean = 18/3 = 6\n+        self.assertAllClose(np.sqrt(6), result, atol=1e-3)\n+\n+    def test_weighted(self):\n+        rmse_obj = metrics.RootMeanSquaredError()\n+        y_true = np.array([2, 4, 6])\n+        y_pred = np.array([1, 3, 2])\n+        y_true = np.array([2, 4, 6, 8])\n+        y_pred = np.array([1, 3, 2, 3])\n+        sample_weight = np.array([0, 1, 0, 1])\n+        result = rmse_obj(y_true, y_pred, sample_weight=sample_weight)\n+        self.assertAllClose(np.sqrt(13), result, atol=1e-3)\n+\n+\n class LogCoshErrorTest(testing.TestCase):\n     def setup(self):\n         y_true = np.asarray([[1, 9, 2], [-5, -2, 6]], dtype=np.float32)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a46bc5a88bf118aa73af53f3c6cc9631850cc3fe", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 78 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 3 | Methods Changed: 6 | Complexity Δ (Sum/Max): 6/4 | Churn Δ: 78 | Churn Cumulative: 143 | Contributors (this commit): 4 | Commits (past 90d): 29 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -45,6 +45,7 @@ from keras_core.layers.pooling.max_pooling1d import MaxPooling1D\n from keras_core.layers.pooling.max_pooling2d import MaxPooling2D\n from keras_core.layers.pooling.max_pooling3d import MaxPooling3D\n from keras_core.layers.preprocessing.normalization import Normalization\n+from keras_core.layers.preprocessing.rescaling import Rescaling\n from keras_core.layers.regularization.activity_regularization import (\n     ActivityRegularization,\n )\n\n@@ -0,0 +1,52 @@\n+from keras_core import operations as ops\n+from keras_core.api_export import keras_core_export\n+from keras_core.layers.layer import Layer\n+\n+\n+@keras_core_export(\"keras_core.layers.Rescaling\")\n+class Rescaling(Layer):\n+    \"\"\"A preprocessing layer which rescales input values to a new range.\n+\n+    This layer rescales every value of an input (often an image) by multiplying\n+    by `scale` and adding `offset`.\n+\n+    For instance:\n+\n+    1. To rescale an input in the `[0, 255]` range\n+    to be in the `[0, 1]` range, you would pass `scale=1./255`.\n+\n+    2. To rescale an input in the `[0, 255]` range to be in the `[-1, 1]` range,\n+    you would pass `scale=1./127.5, offset=-1`.\n+\n+    The rescaling is applied both during training and inference. Inputs can be\n+    of integer or floating point dtype, and by default the layer will output\n+    floats.\n+\n+    Args:\n+        scale: Float, the scale to apply to the inputs.\n+        offset: Float, the offset to apply to the inputs.\n+        **kwargs: Base layer keyword arguments, such as `name` and `dtype.\n+    \"\"\"\n+\n+    def __init__(self, scale, offset=0.0, **kwargs):\n+        super().__init__(**kwargs)\n+        self.scale = scale\n+        self.offset = offset\n+        self.supports_masking = True\n+\n+    def call(self, inputs):\n+        dtype = self.compute_dtype\n+        scale = ops.cast(self.scale, dtype)\n+        offset = ops.cast(self.offset, dtype)\n+        return inputs * scale + offset\n+\n+    def compute_output_shape(self, input_shape):\n+        return input_shape\n+\n+    def get_config(self):\n+        base_config = super().get_config()\n+        config = {\n+            \"scale\": self.scale,\n+            \"offset\": self.offset,\n+        }\n+        return {**base_config, **config}\n\n@@ -0,0 +1,25 @@\n+import numpy as np\n+\n+from keras_core import layers\n+from keras_core import testing\n+\n+\n+class RescalingTest(testing.TestCase):\n+    def test_rescaling_basics(self):\n+        self.run_layer_test(\n+            layers.Rescaling,\n+            init_kwargs={\"scale\": 1.0 / 255, \"offset\": 0.5},\n+            input_shape=(2, 3),\n+            expected_output_shape=(2, 3),\n+            expected_num_trainable_weights=0,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_seed_generators=0,\n+            expected_num_losses=0,\n+            supports_masking=True,\n+        )\n+\n+    def test_rescaling_correctness(self):\n+        layer = layers.Rescaling(scale=1.0 / 255, offset=0.5)\n+        x = np.random.random((3, 10, 10, 3)) * 255\n+        out = layer(x)\n+        self.assertAllClose(out, x / 255 + 0.5)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2e62dffed7f6e8bbcae56fe3afbd02c87f540e81", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 217 | Lines Deleted: 0 | Files Changed: 6 | Hunks: 6 | Methods Changed: 8 | Complexity Δ (Sum/Max): 27/9 | Churn Δ: 217 | Churn Cumulative: 1529 | Contributors (this commit): 6 | Commits (past 90d): 62 | Contributors (cumulative): 14 | DMM Complexity: 0.5704225352112676\n\nDIFF:\n@@ -11,6 +11,7 @@ from keras_core.backend.common.keras_tensor import KerasTensor\n from keras_core.backend.common.stateless_scope import StatelessScope\n from keras_core.backend.common.stateless_scope import get_stateless_scope\n from keras_core.backend.common.stateless_scope import in_stateless_scope\n+from keras_core.backend.jax import image\n from keras_core.backend.jax import math\n from keras_core.backend.jax import nn\n from keras_core.backend.jax import numpy\n\n@@ -0,0 +1,41 @@\n+import jax\n+\n+RESIZE_METHODS = (\n+    \"bilinear\",\n+    \"nearest\",\n+    \"lanczos3\",\n+    \"lanczos5\",\n+    \"bicubic\",\n+)\n+\n+\n+def resize(\n+    image, size, method=\"bilinear\", antialias=False, data_format=\"channels_last\"\n+):\n+    if method not in RESIZE_METHODS:\n+        raise ValueError(\n+            \"Invalid value for argument `method`. Expected of one \"\n+            f\"{RESIZE_METHODS}. Received: method={method}\"\n+        )\n+    if not len(size) == 2:\n+        raise ValueError(\n+            \"Argument `size` must be a tuple of two elements \"\n+            f\"(height, width). Received: size={size}\"\n+        )\n+    if len(image.shape) == 4:\n+        if data_format == \"channels_last\":\n+            size = (image.shape[0],) + size + (image.shape[-1],)\n+        else:\n+            size = (image.shape[0], image.shape[1]) + size\n+    elif len(image.shape) == 3:\n+        if data_format == \"channels_last\":\n+            size = size + (image.shape[-1],)\n+        else:\n+            size = (image.shape[0],) + size\n+    else:\n+        raise ValueError(\n+            \"Invalid input rank: expected rank 3 (single image) \"\n+            \"or rank 4 (batch of images). Received input with shape: \"\n+            f\"image.shape={image.shape}\"\n+        )\n+    return jax.image.resize(image, size, method=method, antialias=antialias)\n\n@@ -8,6 +8,7 @@ from keras_core.backend.common.keras_tensor import KerasTensor\n from keras_core.backend.common.stateless_scope import StatelessScope\n from keras_core.backend.common.stateless_scope import get_stateless_scope\n from keras_core.backend.common.stateless_scope import in_stateless_scope\n+from keras_core.backend.tensorflow import image\n from keras_core.backend.tensorflow import math\n from keras_core.backend.tensorflow import nn\n from keras_core.backend.tensorflow import numpy\n\n@@ -0,0 +1,44 @@\n+import tensorflow as tf\n+\n+RESIZE_METHODS = (\n+    \"bilinear\",\n+    \"nearest\",\n+    \"lanczos3\",\n+    \"lanczos5\",\n+    \"bicubic\",\n+)\n+\n+\n+def resize(\n+    image, size, method=\"bilinear\", antialias=False, data_format=\"channels_last\"\n+):\n+    if method not in RESIZE_METHODS:\n+        raise ValueError(\n+            \"Invalid value for argument `method`. Expected of one \"\n+            f\"{RESIZE_METHODS}. Received: method={method}\"\n+        )\n+    if not len(size) == 2:\n+        raise ValueError(\n+            \"Argument `size` must be a tuple of two elements \"\n+            f\"(height, width). Received: size={size}\"\n+        )\n+\n+    if data_format == \"channels_first\":\n+        if len(image.shape) == 4:\n+            image = tf.transpose(image, (0, 2, 3, 1))\n+        elif len(image.shape) == 3:\n+            image = tf.transpose(image, (1, 2, 0))\n+        else:\n+            raise ValueError(\n+                \"Invalid input rank: expected rank 3 (single image) \"\n+                \"or rank 4 (batch of images). Received input with shape: \"\n+                f\"image.shape={image.shape}\"\n+            )\n+\n+    resized = tf.image.resize(image, size, method=method, antialias=antialias)\n+    if data_format == \"channels_first\":\n+        if len(image.shape) == 4:\n+            resized = tf.transpose(image, (0, 3, 1, 2))\n+        elif len(image.shape) == 3:\n+            image = tf.transpose(image, (2, 0, 1))\n+    return resized\n\n@@ -0,0 +1,62 @@\n+from keras_core import backend\n+from keras_core.backend import KerasTensor\n+from keras_core.backend import any_symbolic_tensors\n+from keras_core.operations.operation import Operation\n+\n+\n+class Resize(Operation):\n+    def __init__(\n+        self,\n+        size,\n+        method=\"bilinear\",\n+        antialias=False,\n+        data_format=\"channels_last\",\n+    ):\n+        super().__init__()\n+        self.size = tuple(size)\n+        self.method = method\n+        self.antialias = antialias\n+        self.data_format = data_format\n+\n+    def call(self, image):\n+        return backend.image.resize(\n+            image,\n+            self.shape,\n+            method=self.method,\n+            antialias=self.antialias,\n+            data_format=self.data_format,\n+        )\n+\n+    def compute_output_spec(self, image):\n+        if len(image.shape) == 3:\n+            return KerasTensor(\n+                self.size + (image.shape[-1],), dtype=image.dtype\n+            )\n+        elif len(image.shape) == 4:\n+            if self.data_format == \"channels_last\":\n+                return KerasTensor(\n+                    (image.shape[0],) + self.size + (image.shape[-1],),\n+                    dtype=image.dtype,\n+                )\n+            else:\n+                return KerasTensor(\n+                    (image.shape[0], image.shape[1]) + self.size,\n+                    dtype=image.dtype,\n+                )\n+        raise ValueError(\n+            \"Invalid input rank: expected rank 3 (single image) \"\n+            \"or rank 4 (batch of images). Received input with shape: \"\n+            f\"image.shape={image.shape}\"\n+        )\n+\n+\n+def resize(\n+    image, size, method=\"bilinear\", antialias=False, data_format=\"channels_last\"\n+):\n+    if any_symbolic_tensors((image,)):\n+        return Resize(\n+            size, method=method, antialias=antialias, data_format=data_format\n+        ).symbolic_call(image)\n+    return backend.image.resize(\n+        image, size, method=method, antialias=antialias, data_format=data_format\n+    )\n\n@@ -0,0 +1,68 @@\n+import numpy as np\n+import pytest\n+import tensorflow as tf\n+from absl.testing import parameterized\n+\n+from keras_core import backend\n+from keras_core import testing\n+from keras_core.backend.common.keras_tensor import KerasTensor\n+from keras_core.operations import image as kimage\n+\n+\n+@pytest.mark.skipif(\n+    not backend.DYNAMIC_SHAPES_OK,\n+    reason=\"Backend does not support dynamic shapes\",\n+)\n+class ImageOpsDynamicShapeTest(testing.TestCase):\n+    def test_resize(self):\n+        x = KerasTensor([None, 20, 20, 3])\n+        out = kimage.resize(x, size=(15, 15))\n+        self.assertEqual(out.shape, (None, 15, 15, 3))\n+\n+        x = KerasTensor([None, None, 3])\n+        out = kimage.resize(x, size=(15, 15))\n+        self.assertEqual(out.shape, (15, 15, 3))\n+\n+\n+class ImageOpsStaticShapeTest(testing.TestCase):\n+    def test_resize(self):\n+        x = KerasTensor([20, 20, 3])\n+        out = kimage.resize(x, size=(15, 15))\n+        self.assertEqual(out.shape, (15, 15, 3))\n+\n+\n+class ImageOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n+    @parameterized.parameters(\n+        [\n+            (\"bilinear\", True),\n+            (\"nearest\", True),\n+            (\"lanczos3\", True),\n+            (\"lanczos5\", True),\n+            (\"bicubic\", True),\n+            (\"bilinear\", False),\n+            (\"nearest\", False),\n+            (\"lanczos3\", False),\n+            (\"lanczos5\", False),\n+            (\"bicubic\", False),\n+        ]\n+    )\n+    def test_resize(self, method, antialias):\n+        x = np.random.random((50, 50, 3)) * 255\n+        out = kimage.resize(\n+            x, size=(25, 25), method=method, antialias=antialias\n+        )\n+        ref_out = tf.image.resize(\n+            x, size=(25, 25), method=method, antialias=antialias\n+        )\n+        self.assertEqual(tuple(out.shape), tuple(ref_out.shape))\n+        self.assertAllClose(ref_out, out, atol=0.3)\n+\n+        x = np.random.random((2, 50, 50, 3)) * 255\n+        out = kimage.resize(\n+            x, size=(25, 25), method=method, antialias=antialias\n+        )\n+        ref_out = tf.image.resize(\n+            x, size=(25, 25), method=method, antialias=antialias\n+        )\n+        self.assertEqual(tuple(out.shape), tuple(ref_out.shape))\n+        self.assertAllClose(ref_out, out, atol=0.3)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8c014ca9959f50d11c169b0d84be876a7a4c2400", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 427 | Lines Deleted: 448 | Files Changed: 12 | Hunks: 25 | Methods Changed: 26 | Complexity Δ (Sum/Max): -1/10 | Churn Δ: 875 | Churn Cumulative: 1869 | Contributors (this commit): 7 | Commits (past 90d): 54 | Contributors (cumulative): 23 | DMM Complexity: 0.0\n\nDIFF:\n@@ -38,7 +38,7 @@ def resize(\n     resized = tf.image.resize(image, size, method=method, antialias=antialias)\n     if data_format == \"channels_first\":\n         if len(image.shape) == 4:\n-            resized = tf.transpose(image, (0, 3, 1, 2))\n+            resized = tf.transpose(resized, (0, 3, 1, 2))\n         elif len(image.shape) == 3:\n-            image = tf.transpose(image, (2, 0, 1))\n+            resized = tf.transpose(resized, (2, 0, 1))\n     return resized\n\n@@ -26,10 +26,6 @@ from keras_core.layers.merging.subtract import subtract\n from keras_core.layers.normalization.batch_normalization import (\n     BatchNormalization,\n )\n-from keras_core.layers.normalization.layer_normalization import (\n-    LayerNormalization,\n-)\n-from keras_core.layers.normalization.unit_normalization import UnitNormalization\n from keras_core.layers.pooling.average_pooling1d import AveragePooling1D\n from keras_core.layers.pooling.average_pooling2d import AveragePooling2D\n from keras_core.layers.pooling.average_pooling3d import AveragePooling3D\n@@ -50,6 +46,7 @@ from keras_core.layers.pooling.max_pooling2d import MaxPooling2D\n from keras_core.layers.pooling.max_pooling3d import MaxPooling3D\n from keras_core.layers.preprocessing.normalization import Normalization\n from keras_core.layers.preprocessing.rescaling import Rescaling\n+from keras_core.layers.preprocessing.resizing import Resizing\n from keras_core.layers.regularization.activity_regularization import (\n     ActivityRegularization,\n )\n\n@@ -1,239 +0,0 @@\n-from keras_core import constraints\n-from keras_core import initializers\n-from keras_core import operations as ops\n-from keras_core import regularizers\n-from keras_core.api_export import keras_core_export\n-from keras_core.layers.layer import Layer\n-\n-\n-@keras_core_export(\"keras_core.layers.LayerNormalization\")\n-class LayerNormalization(Layer):\n-    \"\"\"Layer normalization layer (Ba et al., 2016).\n-\n-    Normalize the activations of the previous layer for each given example in a\n-    batch independently, rather than across a batch like Batch Normalization.\n-    i.e. applies a transformation that maintains the mean activation within each\n-    example close to 0 and the activation standard deviation close to 1.\n-\n-    If `scale` or `center` are enabled, the layer will scale the normalized\n-    outputs by broadcasting them with a trainable variable `gamma`, and center\n-    the outputs by broadcasting with a trainable variable `beta`. `gamma` will\n-    default to a ones tensor and `beta` will default to a zeros tensor, so that\n-    centering and scaling are no-ops before training has begun.\n-\n-    So, with scaling and centering enabled the normalization equations\n-    are as follows:\n-\n-    Let the intermediate activations for a mini-batch to be the `inputs`.\n-\n-    For each sample `x_i` in `inputs` with `k` features, we compute the mean and\n-    variance of the sample:\n-\n-    ```python\n-    mean_i = sum(x_i[j] for j in range(k)) / k\n-    var_i = sum((x_i[j] - mean_i) ** 2 for j in range(k)) / k\n-    ```\n-\n-    and then compute a normalized `x_i_normalized`, including a small factor\n-    `epsilon` for numerical stability.\n-\n-    ```python\n-    x_i_normalized = (x_i - mean_i) / sqrt(var_i + epsilon)\n-    ```\n-\n-    And finally `x_i_normalized ` is linearly transformed by `gamma` and `beta`,\n-    which are learned parameters:\n-\n-    ```python\n-    output_i = x_i_normalized * gamma + beta\n-    ```\n-\n-    `gamma` and `beta` will span the axes of `inputs` specified in `axis`, and\n-    this part of the inputs' shape must be fully defined.\n-\n-    For example:\n-\n-    >>> layer = keras_core.layers.LayerNormalization(axis=[1, 2, 3])\n-    >>> layer.build([5, 20, 30, 40])\n-    >>> print(layer.beta.shape)\n-    (20, 30, 40)\n-    >>> print(layer.gamma.shape)\n-    (20, 30, 40)\n-\n-    Note that other implementations of layer normalization may choose to define\n-    `gamma` and `beta` over a separate set of axes from the axes being\n-    normalized across. For example, Group Normalization\n-    ([Wu et al. 2018](https://arxiv.org/abs/1803.08494)) with group size of 1\n-    corresponds to a Layer Normalization that normalizes across height, width,\n-    and channel and has `gamma` and `beta` span only the channel dimension.\n-    So, this Layer Normalization implementation will not match a Group\n-    Normalization layer with group size set to 1.\n-\n-    Args:\n-        axis: Integer or List/Tuple. The axis or axes to normalize across.\n-            Typically, this is the features axis/axes. The left-out axes are\n-            typically the batch axis/axes. `-1` is the last dimension in the\n-            input. Defaults to `-1`.\n-        epsilon: Small float added to variance to avoid dividing by zero.\n-            Defaults to 1e-3.\n-        center: If True, add offset of `beta` to normalized tensor. If False,\n-            `beta` is ignored. Defaults to `True`.\n-        scale: If True, multiply by `gamma`. If False, `gamma` is not used.\n-            When the next layer is linear (also e.g. `nn.relu`), this can be\n-            disabled since the scaling will be done by the next layer.\n-            Defaults to `True`.\n-        beta_initializer: Initializer for the beta weight. Defaults to zeros.\n-        gamma_initializer: Initializer for the gamma weight. Defaults to ones.\n-        beta_regularizer: Optional regularizer for the beta weight.\n-            None by default.\n-        gamma_regularizer: Optional regularizer for the gamma weight.\n-            None by default.\n-        beta_constraint: Optional constraint for the beta weight.\n-            None by default.\n-        gamma_constraint: Optional constraint for the gamma weight.\n-            None by default.\n-        **kwargs: Base layer keyword arguments (e.g. `name` and `dtype`).\n-\n-\n-    Reference:\n-\n-    - [Lei Ba et al., 2016](https://arxiv.org/abs/1607.06450).\n-    \"\"\"\n-\n-    def __init__(\n-        self,\n-        axis=-1,\n-        epsilon=1e-3,\n-        center=True,\n-        scale=True,\n-        beta_initializer=\"zeros\",\n-        gamma_initializer=\"ones\",\n-        beta_regularizer=None,\n-        gamma_regularizer=None,\n-        beta_constraint=None,\n-        gamma_constraint=None,\n-        **kwargs\n-    ):\n-        super().__init__(**kwargs)\n-        if isinstance(axis, (list, tuple)):\n-            self.axis = list(axis)\n-        elif isinstance(axis, int):\n-            self.axis = axis\n-        else:\n-            raise TypeError(\n-                \"Expected an int or a list/tuple of ints for the \"\n-                \"argument 'axis', but received: %r\" % axis\n-            )\n-\n-        self.epsilon = epsilon\n-        self.center = center\n-        self.scale = scale\n-        self.beta_initializer = initializers.get(beta_initializer)\n-        self.gamma_initializer = initializers.get(gamma_initializer)\n-        self.beta_regularizer = regularizers.get(beta_regularizer)\n-        self.gamma_regularizer = regularizers.get(gamma_regularizer)\n-        self.beta_constraint = constraints.get(beta_constraint)\n-        self.gamma_constraint = constraints.get(gamma_constraint)\n-\n-        self.supports_masking = True\n-\n-    def build(self, input_shape):\n-        if isinstance(self.axis, list):\n-            shape = tuple([input_shape[dim] for dim in self.axis])\n-        else:\n-            shape = (input_shape[self.axis],)\n-            self.axis = [self.axis]\n-        if self.scale:\n-            self.gamma = self.add_weight(\n-                name=\"gamma\",\n-                shape=shape,\n-                initializer=self.gamma_initializer,\n-                regularizer=self.gamma_regularizer,\n-                constraint=self.gamma_constraint,\n-                trainable=True,\n-            )\n-        else:\n-            self.gamma = None\n-\n-        if self.center:\n-            self.beta = self.add_weight(\n-                name=\"beta\",\n-                shape=shape,\n-                initializer=self.beta_initializer,\n-                regularizer=self.beta_regularizer,\n-                constraint=self.beta_constraint,\n-                trainable=True,\n-            )\n-        else:\n-            self.beta = None\n-\n-        self.built = True\n-\n-    def call(self, inputs):\n-        inputs = ops.cast(inputs, self.compute_dtype)\n-        # Compute the axes along which to reduce the mean / variance\n-        input_shape = inputs.shape\n-        ndims = len(input_shape)\n-\n-        # Broadcasting only necessary for norm when the axis is not just\n-        # the last dimension\n-        broadcast_shape = [1] * ndims\n-        for dim in self.axis:\n-            broadcast_shape[dim] = input_shape[dim]\n-\n-        def _broadcast(v):\n-            if (\n-                v is not None\n-                and len(v.shape) != ndims\n-                and self.axis != [ndims - 1]\n-            ):\n-                return ops.reshape(v, broadcast_shape)\n-            return v\n-\n-        input_dtype = inputs.dtype\n-        if input_dtype in (\"float16\", \"bfloat16\") and self.dtype == \"float32\":\n-            # If mixed precision is used, cast inputs to float32 so that\n-            # this is at least as numerically stable as the fused version.\n-            inputs = ops.cast(inputs, \"float32\")\n-\n-        # Calculate the mean and variance last axis (layer activations).\n-        mean = ops.mean(inputs, axis=self.axis, keepdims=True)\n-        variance = ops.var(inputs, axis=self.axis, keepdims=True)\n-\n-        scale, offset = _broadcast(self.gamma), _broadcast(self.beta)\n-\n-        # Compute the batch normalization.\n-        inv = 1 / ops.sqrt(variance + self.epsilon)\n-        if scale is not None:\n-            inv *= scale\n-\n-        x = offset - mean * inv if offset is not None else -mean * inv\n-        outputs = inputs * ops.cast(inv, inputs.dtype) + ops.cast(\n-            x, inputs.dtype\n-        )\n-\n-        outputs = ops.cast(outputs, input_dtype)\n-\n-        # If some components of the shape got lost due to adjustments, fix that.\n-        outputs = ops.reshape(outputs, input_shape)\n-\n-        return outputs\n-\n-    def compute_output_shape(self, input_shape):\n-        return input_shape\n-\n-    def get_config(self):\n-        config = {\n-            \"axis\": self.axis,\n-            \"epsilon\": self.epsilon,\n-            \"center\": self.center,\n-            \"scale\": self.scale,\n-            \"beta_initializer\": initializers.serialize(self.beta_initializer),\n-            \"gamma_initializer\": initializers.serialize(self.gamma_initializer),\n-            \"beta_regularizer\": regularizers.serialize(self.beta_regularizer),\n-            \"gamma_regularizer\": regularizers.serialize(self.gamma_regularizer),\n-            \"beta_constraint\": constraints.serialize(self.beta_constraint),\n-            \"gamma_constraint\": constraints.serialize(self.gamma_constraint),\n-        }\n-        base_config = super().get_config()\n-        return {**base_config, **config}\n\n@@ -1,85 +0,0 @@\n-import numpy as np\n-\n-from keras_core import layers\n-from keras_core import operations as ops\n-from keras_core import regularizers\n-from keras_core import testing\n-\n-\n-class LayerNormalizationTest(testing.TestCase):\n-    def test_ln_basics(self):\n-        self.run_layer_test(\n-            layers.LayerNormalization,\n-            init_kwargs={\n-                \"gamma_regularizer\": regularizers.L2(0.01),\n-                \"beta_regularizer\": regularizers.L2(0.01),\n-            },\n-            input_shape=(3, 4, 2),\n-            expected_output_shape=(3, 4, 2),\n-            expected_num_trainable_weights=2,\n-            expected_num_non_trainable_weights=0,\n-            expected_num_seed_generators=0,\n-            expected_num_losses=2,\n-            supports_masking=True,\n-        )\n-        self.run_layer_test(\n-            layers.LayerNormalization,\n-            init_kwargs={\n-                \"gamma_initializer\": \"ones\",\n-                \"beta_initializer\": \"ones\",\n-            },\n-            input_shape=(3, 4, 2),\n-            expected_output_shape=(3, 4, 2),\n-            expected_num_trainable_weights=2,\n-            expected_num_non_trainable_weights=0,\n-            expected_num_seed_generators=0,\n-            expected_num_losses=0,\n-            supports_masking=True,\n-        )\n-        self.run_layer_test(\n-            layers.LayerNormalization,\n-            init_kwargs={\"scale\": False, \"center\": False},\n-            input_shape=(3, 3),\n-            expected_output_shape=(3, 3),\n-            expected_num_trainable_weights=0,\n-            expected_num_non_trainable_weights=0,\n-            expected_num_seed_generators=0,\n-            expected_num_losses=0,\n-            supports_masking=True,\n-        )\n-        self.run_layer_test(\n-            layers.LayerNormalization,\n-            init_kwargs={\"axis\": (-3, -2, -1)},\n-            input_shape=(2, 8, 8, 3),\n-            expected_output_shape=(2, 8, 8, 3),\n-            expected_num_trainable_weights=2,\n-            expected_num_non_trainable_weights=0,\n-            expected_num_seed_generators=0,\n-            expected_num_losses=0,\n-            supports_masking=True,\n-        )\n-        self.run_layer_test(\n-            layers.LayerNormalization,\n-            init_kwargs={},\n-            input_shape=(1, 0, 10),\n-            expected_output_shape=(1, 0, 10),\n-            expected_num_trainable_weights=2,\n-            expected_num_non_trainable_weights=0,\n-            expected_num_seed_generators=0,\n-            expected_num_losses=0,\n-            supports_masking=True,\n-        )\n-\n-    def test_correctness(self):\n-        layer = layers.LayerNormalization(dtype=\"float32\")\n-        layer.build(input_shape=(2, 2, 2))\n-        inputs = np.random.normal(\n-            loc=5.0, scale=10.0, size=(1000, 2, 2, 2)\n-        ).astype(\"float32\")\n-\n-        out = layer(inputs)\n-        out -= layer.beta\n-        out /= layer.gamma\n-\n-        self.assertAllClose(ops.mean(out), 0.0, atol=1e-1)\n-        self.assertAllClose(ops.std(out), 1.0, atol=1e-1)\n\n@@ -1,57 +0,0 @@\n-from keras_core import operations as ops\n-from keras_core.api_export import keras_core_export\n-from keras_core.layers.layer import Layer\n-\n-\n-@keras_core_export(\"keras_core.layers.UnitNormalization\")\n-class UnitNormalization(Layer):\n-    \"\"\"Unit normalization layer.\n-\n-    Normalize a batch of inputs so that each input in the batch has a L2 norm\n-    equal to 1 (across the axes specified in `axis`).\n-\n-    Example:\n-\n-    >>> data = np.arange(6).reshape(2, 3)\n-    >>> normalized_data = keras_core.layers.UnitNormalization()(data)\n-    >>> print(np.sum(normalized_data[0, :] ** 2)\n-    1.0\n-\n-    Args:\n-        axis: Integer or list/tuple. The axis or axes to normalize across.\n-            Typically, this is the features axis or axes. The left-out axes are\n-            typically the batch axis or axes. `-1` is the last dimension\n-            in the input. Defaults to `-1`.\n-    \"\"\"\n-\n-    def __init__(self, axis=-1, **kwargs):\n-        super().__init__(**kwargs)\n-        if isinstance(axis, (list, tuple)):\n-            self.axis = list(axis)\n-        elif isinstance(axis, int):\n-            self.axis = axis\n-        else:\n-            raise TypeError(\n-                \"Invalid value for `axis` argument: \"\n-                \"expected an int or a list/tuple of ints. \"\n-                f\"Received: axis={axis}\"\n-            )\n-        self.supports_masking = True\n-\n-    def build(self, input_shape):\n-        self.built = True\n-\n-    def call(self, inputs):\n-        x = ops.cast(inputs, self.compute_dtype)\n-\n-        square_sum = ops.sum(ops.square(x), axis=self.axis, keepdims=True)\n-        x_inv_norm = 1 / ops.sqrt(ops.maximum(square_sum, 1e-12))\n-        return ops.multiply(x, x_inv_norm)\n-\n-    def compute_output_shape(self, input_shape):\n-        return input_shape\n-\n-    def get_config(self):\n-        config = super().get_config()\n-        config.update({\"axis\": self.axis})\n-        return config\n\n@@ -1,47 +0,0 @@\n-import numpy as np\n-\n-from keras_core import layers\n-from keras_core import testing\n-\n-\n-def squared_l2_norm(x):\n-    return np.sum(x**2)\n-\n-\n-class UnitNormalizationTest(testing.TestCase):\n-    def test_un_basics(self):\n-        self.run_layer_test(\n-            layers.UnitNormalization,\n-            init_kwargs={\"axis\": -1},\n-            input_shape=(2, 3),\n-            expected_output_shape=(2, 3),\n-            supports_masking=True,\n-        )\n-        self.run_layer_test(\n-            layers.UnitNormalization,\n-            init_kwargs={\"axis\": (1, 2)},\n-            input_shape=(1, 3, 3),\n-            expected_output_shape=(1, 3, 3),\n-            supports_masking=True,\n-        )\n-\n-    def test_correctness(self):\n-        layer = layers.UnitNormalization(axis=-1)\n-        inputs = np.random.normal(size=(2, 3))\n-        outputs = layer(inputs)\n-        self.assertAllClose(squared_l2_norm(outputs[0, :]), 1.0)\n-        self.assertAllClose(squared_l2_norm(outputs[1, :]), 1.0)\n-\n-        layer = layers.UnitNormalization(axis=(1, 2))\n-        inputs = np.random.normal(size=(2, 3, 3))\n-        outputs = layer(inputs)\n-        self.assertAllClose(squared_l2_norm(outputs[0, :, :]), 1.0)\n-        self.assertAllClose(squared_l2_norm(outputs[1, :, :]), 1.0)\n-\n-        layer = layers.UnitNormalization(axis=1)\n-        inputs = np.random.normal(size=(2, 3, 2))\n-        outputs = layer(inputs)\n-        self.assertAllClose(squared_l2_norm(outputs[0, :, 0]), 1.0)\n-        self.assertAllClose(squared_l2_norm(outputs[1, :, 0]), 1.0)\n-        self.assertAllClose(squared_l2_norm(outputs[0, :, 1]), 1.0)\n-        self.assertAllClose(squared_l2_norm(outputs[1, :, 1]), 1.0)\n\n@@ -25,7 +25,7 @@ class Rescaling(Layer):\n     Args:\n         scale: Float, the scale to apply to the inputs.\n         offset: Float, the offset to apply to the inputs.\n-        **kwargs: Base layer keyword arguments, such as `name` and `dtype.\n+        **kwargs: Base layer keyword arguments, such as `name` and `dtype`.\n     \"\"\"\n \n     def __init__(self, scale, offset=0.0, **kwargs):\n\n@@ -0,0 +1,102 @@\n+from keras_core import backend\n+from keras_core import operations as ops\n+from keras_core.api_export import keras_core_export\n+from keras_core.layers.layer import Layer\n+from keras_core.utils import image_utils\n+\n+\n+@keras_core_export(\"keras_core.layers.Resizing\")\n+class Resizing(Layer):\n+    \"\"\"A preprocessing layer which resizes images.\n+\n+    This layer resizes an image input to a target height and width. The input\n+    should be a 4D (batched) or 3D (unbatched) tensor in `\"channels_last\"`\n+    format. Input pixel values can be of any range\n+    (e.g. `[0., 1.)` or `[0, 255]`).\n+\n+    Args:\n+        height: Integer, the height of the output shape.\n+        width: Integer, the width of the output shape.\n+        interpolation: String, the interpolation method.\n+            Supports `\"bilinear\"`, `\"nearest\"`, `\"bicubic\"`,\n+            `\"lanczos3\"`, `\"lanczos5\"`. Defaults to `\"bilinear\"`.\n+        crop_to_aspect_ratio: If `True`, resize the images without aspect\n+            ratio distortion. When the original aspect ratio differs\n+            from the target aspect ratio, the output image will be\n+            cropped so as to return the\n+            largest possible window in the image (of size `(height, width)`)\n+            that matches the target aspect ratio. By default\n+            (`crop_to_aspect_ratio=False`), aspect ratio may not be preserved.\n+        data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n+            The ordering of the dimensions in the inputs. `\"channels_last\"`\n+            corresponds to inputs with shape `(batch, height, width, channels)`\n+            while `\"channels_first\"` corresponds to inputs with shape\n+            `(batch, channels, height, width)`. It defaults to the\n+            `image_data_format` value found in your Keras config file at\n+            `~/.keras/keras.json`. If you never set it, then it will be\n+            `\"channels_last\"`.\n+        **kwargs: Base layer keyword arguments, such as `name` and `dtype`.\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        height,\n+        width,\n+        interpolation=\"bilinear\",\n+        crop_to_aspect_ratio=False,\n+        data_format=None,\n+        **kwargs,\n+    ):\n+        super().__init__(**kwargs)\n+        self.height = height\n+        self.width = width\n+        self.interpolation = interpolation\n+        self.data_format = data_format or backend.image_data_format()\n+        self.crop_to_aspect_ratio = crop_to_aspect_ratio\n+\n+    def call(self, inputs):\n+        size = (self.height, self.width)\n+        if self.crop_to_aspect_ratio:\n+            outputs = image_utils.smart_resize(\n+                inputs,\n+                size=size,\n+                interpolation=self.interpolation,\n+                data_format=self.data_format,\n+            )\n+        else:\n+            outputs = ops.image.resize(\n+                inputs,\n+                size=size,\n+                method=self.interpolation,\n+                data_format=self.data_format,\n+            )\n+        return outputs\n+\n+    def compute_output_shape(self, input_shape):\n+        input_shape = list(input_shape)\n+        if len(input_shape) == 4:\n+            if self.data_format == \"channels_last\":\n+                input_shape[1] = self.height\n+                input_shape[2] = self.width\n+            else:\n+                input_shape[2] = self.height\n+                input_shape[3] = self.width\n+        else:\n+            if self.data_format == \"channels_last\":\n+                input_shape[0] = self.height\n+                input_shape[1] = self.width\n+            else:\n+                input_shape[1] = self.height\n+                input_shape[2] = self.width\n+        return tuple(input_shape)\n+\n+    def get_config(self):\n+        base_config = super().get_config()\n+        config = {\n+            \"height\": self.height,\n+            \"width\": self.width,\n+            \"interpolation\": self.interpolation,\n+            \"crop_to_aspect_ratio\": self.crop_to_aspect_ratio,\n+            \"data_format\": self.data_format,\n+        }\n+        return {**base_config, **config}\n\n@@ -0,0 +1,140 @@\n+import numpy as np\n+import tensorflow as tf\n+from absl.testing import parameterized\n+\n+from keras_core import layers\n+from keras_core import testing\n+\n+\n+class ResizingTest(testing.TestCase, parameterized.TestCase):\n+    def test_resizing_basics(self):\n+        self.run_layer_test(\n+            layers.Resizing,\n+            init_kwargs={\n+                \"height\": 6,\n+                \"width\": 6,\n+                \"data_format\": \"channels_last\",\n+                \"interpolation\": \"bicubic\",\n+                \"crop_to_aspect_ratio\": True,\n+            },\n+            input_shape=(2, 12, 12, 3),\n+            expected_output_shape=(2, 6, 6, 3),\n+            expected_num_trainable_weights=0,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_seed_generators=0,\n+            expected_num_losses=0,\n+            supports_masking=False,\n+        )\n+        self.run_layer_test(\n+            layers.Resizing,\n+            init_kwargs={\n+                \"height\": 6,\n+                \"width\": 6,\n+                \"data_format\": \"channels_first\",\n+                \"interpolation\": \"bilinear\",\n+                \"crop_to_aspect_ratio\": True,\n+            },\n+            input_shape=(2, 3, 12, 12),\n+            expected_output_shape=(2, 3, 6, 6),\n+            expected_num_trainable_weights=0,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_seed_generators=0,\n+            expected_num_losses=0,\n+            supports_masking=False,\n+        )\n+        self.run_layer_test(\n+            layers.Resizing,\n+            init_kwargs={\n+                \"height\": 6,\n+                \"width\": 6,\n+                \"data_format\": \"channels_last\",\n+                \"interpolation\": \"nearest\",\n+                \"crop_to_aspect_ratio\": False,\n+            },\n+            input_shape=(2, 12, 12, 3),\n+            expected_output_shape=(2, 6, 6, 3),\n+            expected_num_trainable_weights=0,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_seed_generators=0,\n+            expected_num_losses=0,\n+            supports_masking=False,\n+        )\n+        self.run_layer_test(\n+            layers.Resizing,\n+            init_kwargs={\n+                \"height\": 6,\n+                \"width\": 6,\n+                \"data_format\": \"channels_first\",\n+                \"interpolation\": \"lanczos5\",\n+                \"crop_to_aspect_ratio\": False,\n+            },\n+            input_shape=(2, 3, 12, 12),\n+            expected_output_shape=(2, 3, 6, 6),\n+            expected_num_trainable_weights=0,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_seed_generators=0,\n+            expected_num_losses=0,\n+            supports_masking=False,\n+        )\n+\n+    @parameterized.parameters(\n+        [\n+            ((5, 7), \"channels_first\", True),\n+            ((5, 7), \"channels_last\", True),\n+            ((6, 8), \"channels_first\", False),\n+            ((6, 8), \"channels_last\", False),\n+        ]\n+    )\n+    def test_resizing_correctness(\n+        self, size, data_format, crop_to_aspect_ratio\n+    ):\n+        # batched case\n+        if data_format == \"channels_first\":\n+            img = np.random.random((2, 3, 9, 11))\n+        else:\n+            img = np.random.random((2, 9, 11, 3))\n+        out = layers.Resizing(\n+            size[0],\n+            size[1],\n+            data_format=data_format,\n+            crop_to_aspect_ratio=crop_to_aspect_ratio,\n+        )(img)\n+        if data_format == \"channels_first\":\n+            img_transpose = np.transpose(img, (0, 2, 3, 1))\n+\n+            ref_out = tf.transpose(\n+                tf.keras.layers.Resizing(\n+                    size[0], size[1], crop_to_aspect_ratio=crop_to_aspect_ratio\n+                )(img_transpose),\n+                (0, 3, 1, 2),\n+            )\n+        else:\n+            ref_out = tf.keras.layers.Resizing(\n+                size[0], size[1], crop_to_aspect_ratio=crop_to_aspect_ratio\n+            )(img)\n+        self.assertAllClose(ref_out, out)\n+\n+        # unbatched case\n+        if data_format == \"channels_first\":\n+            img = np.random.random((3, 9, 11))\n+        else:\n+            img = np.random.random((9, 11, 3))\n+        out = layers.Resizing(\n+            size[0],\n+            size[1],\n+            data_format=data_format,\n+            crop_to_aspect_ratio=crop_to_aspect_ratio,\n+        )(img)\n+        if data_format == \"channels_first\":\n+            img_transpose = np.transpose(img, (1, 2, 0))\n+            ref_out = tf.transpose(\n+                tf.keras.layers.Resizing(\n+                    size[0], size[1], crop_to_aspect_ratio=crop_to_aspect_ratio\n+                )(img_transpose),\n+                (2, 0, 1),\n+            )\n+        else:\n+            ref_out = tf.keras.layers.Resizing(\n+                size[0], size[1], crop_to_aspect_ratio=crop_to_aspect_ratio\n+            )(img)\n+        self.assertAllClose(ref_out, out)\n\n@@ -9,6 +9,7 @@ from keras_core.backend import is_tensor\n from keras_core.backend import name_scope\n from keras_core.backend import random\n from keras_core.backend import shape\n+from keras_core.operations import image\n from keras_core.operations import operation_utils\n from keras_core.operations.math import *  # noqa: F403\n from keras_core.operations.nn import *  # noqa: F403\n\n@@ -34,35 +34,60 @@ class ImageOpsStaticShapeTest(testing.TestCase):\n class ImageOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n     @parameterized.parameters(\n         [\n-            (\"bilinear\", True),\n-            (\"nearest\", True),\n-            (\"lanczos3\", True),\n-            (\"lanczos5\", True),\n-            (\"bicubic\", True),\n-            (\"bilinear\", False),\n-            (\"nearest\", False),\n-            (\"lanczos3\", False),\n-            (\"lanczos5\", False),\n-            (\"bicubic\", False),\n+            (\"bilinear\", True, \"channels_last\"),\n+            (\"nearest\", True, \"channels_last\"),\n+            (\"lanczos3\", True, \"channels_last\"),\n+            (\"lanczos5\", True, \"channels_last\"),\n+            (\"bicubic\", True, \"channels_last\"),\n+            (\"bilinear\", False, \"channels_last\"),\n+            (\"nearest\", False, \"channels_last\"),\n+            (\"lanczos3\", False, \"channels_last\"),\n+            (\"lanczos5\", False, \"channels_last\"),\n+            (\"bicubic\", False, \"channels_last\"),\n+            (\"bilinear\", True, \"channels_first\"),\n         ]\n     )\n-    def test_resize(self, method, antialias):\n+    def test_resize(self, method, antialias, data_format):\n+        # Unbatched case\n+        if data_format == \"channels_first\":\n+            x = np.random.random((3, 50, 50)) * 255\n+        else:\n             x = np.random.random((50, 50, 3)) * 255\n         out = kimage.resize(\n-            x, size=(25, 25), method=method, antialias=antialias\n+            x,\n+            size=(25, 25),\n+            method=method,\n+            antialias=antialias,\n+            data_format=data_format,\n         )\n+        if data_format == \"channels_first\":\n+            x = np.transpose(x, (1, 2, 0))\n         ref_out = tf.image.resize(\n             x, size=(25, 25), method=method, antialias=antialias\n         )\n+        if data_format == \"channels_first\":\n+            ref_out = np.transpose(ref_out, (2, 0, 1))\n         self.assertEqual(tuple(out.shape), tuple(ref_out.shape))\n         self.assertAllClose(ref_out, out, atol=0.3)\n \n+        # Batched case\n+        if data_format == \"channels_first\":\n+            x = np.random.random((2, 3, 50, 50)) * 255\n+        else:\n             x = np.random.random((2, 50, 50, 3)) * 255\n         out = kimage.resize(\n-            x, size=(25, 25), method=method, antialias=antialias\n+            x,\n+            size=(25, 25),\n+            method=method,\n+            antialias=antialias,\n+            data_format=data_format,\n         )\n+        if data_format == \"channels_first\":\n+            x = np.transpose(x, (0, 2, 3, 1))\n         ref_out = tf.image.resize(\n             x, size=(25, 25), method=method, antialias=antialias\n         )\n+        if data_format == \"channels_first\":\n+            ref_out = np.transpose(ref_out, (0, 3, 1, 2))\n         self.assertEqual(tuple(out.shape), tuple(ref_out.shape))\n         self.assertAllClose(ref_out, out, atol=0.3)\n\n@@ -7,6 +7,7 @@ import warnings\n import numpy as np\n \n from keras_core import backend\n+from keras_core import operations as ops\n from keras_core.api_export import keras_core_export\n \n try:\n@@ -112,8 +113,10 @@ def array_to_img(x, data_format=None, scale=True, dtype=None):\n \n \n @keras_core_export(\n+    [\n         \"keras_core.utils.img_to_array\",\n         \"keras_core.preprocessing.image.img_to_array\",\n+    ]\n )\n def img_to_array(img, data_format=None, dtype=None):\n     \"\"\"Converts a PIL Image instance to a NumPy array.\n@@ -301,3 +304,142 @@ def load_img(\n             else:\n                 img = img.resize(width_height_tuple, resample)\n     return img\n+\n+\n+def smart_resize(\n+    x, size, interpolation=\"bilinear\", data_format=\"channels_last\"\n+):\n+    \"\"\"Resize images to a target size without aspect ratio distortion.\n+\n+    Image datasets typically yield images that have each a different\n+    size. However, these images need to be batched before they can be\n+    processed by Keras layers. To be batched, images need to share the same\n+    height and width.\n+\n+    You could simply do, in TF (or JAX equivalent):\n+\n+    ```python\n+    size = (200, 200)\n+    ds = ds.map(lambda img: resize(img, size))\n+    ```\n+\n+    However, if you do this, you distort the aspect ratio of your images, since\n+    in general they do not all have the same aspect ratio as `size`. This is\n+    fine in many cases, but not always (e.g. for image generation models\n+    this can be a problem).\n+\n+    Note that passing the argument `preserve_aspect_ratio=True` to `resize`\n+    will preserve the aspect ratio, but at the cost of no longer respecting the\n+    provided target size.\n+\n+    This calls for:\n+\n+    ```python\n+    size = (200, 200)\n+    ds = ds.map(lambda img: smart_resize(img, size))\n+    ```\n+\n+    Your output images will actually be `(200, 200)`, and will not be distorted.\n+    Instead, the parts of the image that do not fit within the target size\n+    get cropped out.\n+\n+    The resizing process is:\n+\n+    1. Take the largest centered crop of the image that has the same aspect\n+    ratio as the target size. For instance, if `size=(200, 200)` and the input\n+    image has size `(340, 500)`, we take a crop of `(340, 340)` centered along\n+    the width.\n+    2. Resize the cropped image to the target size. In the example above,\n+    we resize the `(340, 340)` crop to `(200, 200)`.\n+\n+    Args:\n+        x: Input image or batch of images (as a tensor or NumPy array).\n+            Must be in format `(height, width, channels)`\n+            or `(batch_size, height, width, channels)`.\n+        size: Tuple of `(height, width)` integer. Target size.\n+        interpolation: String, interpolation to use for resizing.\n+            Defaults to `'bilinear'`.\n+            Supports `bilinear`, `nearest`, `bicubic`,\n+            `lanczos3`, `lanczos5`.\n+        data_format: `\"channels_last\"` or `\"channels_first\"`.\n+\n+    Returns:\n+        Array with shape `(size[0], size[1], channels)`. If the input image was a\n+        NumPy array, the output is a NumPy array,\n+        and if it was a backend-native tensor,\n+        the output is a backend-native tensor.\n+    \"\"\"\n+    if len(size) != 2:\n+        raise ValueError(\n+            f\"Expected `size` to be a tuple of 2 integers, but got: {size}.\"\n+        )\n+    img = backend.convert_to_tensor(x)\n+    if len(img.shape) is not None:\n+        if len(img.shape) < 3 or len(img.shape) > 4:\n+            raise ValueError(\n+                \"Expected an image array with shape `(height, width, \"\n+                \"channels)`, or `(batch_size, height, width, channels)`, but \"\n+                f\"got input with incorrect rank, of shape {img.shape}.\"\n+            )\n+    shape = ops.shape(img)\n+    if data_format == \"channels_last\":\n+        height, width = shape[-3], shape[-2]\n+    else:\n+        height, width = shape[-2], shape[-1]\n+    target_height, target_width = size\n+\n+    crop_height = ops.cast(\n+        ops.cast(width * target_height, \"float32\") / target_width, \"int32\"\n+    )\n+    crop_width = ops.cast(\n+        ops.cast(height * target_width, \"float32\") / target_height, \"int32\"\n+    )\n+\n+    # Set back to input height / width if crop_height / crop_width is not\n+    # smaller.\n+    crop_height = ops.minimum(height, crop_height)\n+    crop_width = ops.minimum(width, crop_width)\n+\n+    crop_box_hstart = ops.cast(\n+        ops.cast(height - crop_height, \"float32\") / 2, \"int32\"\n+    )\n+    crop_box_wstart = ops.cast(\n+        ops.cast(width - crop_width, \"float32\") / 2, \"int32\"\n+    )\n+\n+    if data_format == \"channels_last\":\n+        if len(img.shape) == 4:\n+            img = img[\n+                :,\n+                crop_box_hstart : crop_box_hstart + crop_height,\n+                crop_box_wstart : crop_box_wstart + crop_width,\n+                :,\n+            ]\n+        else:\n+            img = img[\n+                crop_box_hstart : crop_box_hstart + crop_height,\n+                crop_box_wstart : crop_box_wstart + crop_width,\n+                :,\n+            ]\n+    else:\n+        if len(img.shape) == 4:\n+            img = img[\n+                :,\n+                :,\n+                crop_box_hstart : crop_box_hstart + crop_height,\n+                crop_box_wstart : crop_box_wstart + crop_width,\n+            ]\n+        else:\n+            img = img[\n+                :,\n+                crop_box_hstart : crop_box_hstart + crop_height,\n+                crop_box_wstart : crop_box_wstart + crop_width,\n+            ]\n+\n+    img = ops.image.resize(\n+        img, size=size, method=interpolation, data_format=data_format\n+    )\n+\n+    if isinstance(x, np.ndarray):\n+        return np.array(img)\n+    return img\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
