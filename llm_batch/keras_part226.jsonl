{"custom_id": "keras#2bf4a17899820f23ff2f6e014cd78b6c8f09f4a7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 6 | Churn Cumulative: 1091 | Contributors (this commit): 22 | Commits (past 90d): 5 | Contributors (cumulative): 22 | DMM Complexity: 0.0\n\nDIFF:\n@@ -21,7 +21,7 @@ def count_params(weights):\n     return int(np.sum([K.count_params(p) for p in set(weights)]))\n \n \n-def print_summary(model, line_length=None, positions=None, print_fn=print):\n+def print_summary(model, line_length=None, positions=None, print_fn=None):\n     \"\"\"Prints a summary of a model.\n \n     # Arguments\n@@ -35,7 +35,11 @@ def print_summary(model, line_length=None, positions=None, print_fn=print):\n             It will be called on each line of the summary.\n             You can set it to a custom function\n             in order to capture the string summary.\n+            It defaults to `print` (prints to stdout).\n     \"\"\"\n+    if print_fn is None:\n+        print_fn = print\n+\n     if model.__class__.__name__ == 'Sequential':\n         sequential_like = True\n     else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9e6ffc36973148e0d99929c96edfe20dfaefca8e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 111 | Lines Deleted: 74 | Files Changed: 5 | Hunks: 48 | Methods Changed: 15 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 185 | Churn Cumulative: 2543 | Contributors (this commit): 25 | Commits (past 90d): 26 | Contributors (cumulative): 35 | DMM Complexity: 1.0\n\nDIFF:\n@@ -17,6 +17,22 @@ _IMAGENET_MEAN = None\n \n \n def _preprocess_numpy_input(x, data_format, mode):\n+    \"\"\"Preprocesses a Numpy array encoding a batch of images.\n+\n+    # Arguments\n+        x: Input array, 3D or 4D.\n+        data_format: Data format of the image array.\n+        mode: One of \"caffe\", \"tf\".\n+            - caffe: will convert the images from RGB to BGR,\n+                then will zero-center each color channel with\n+                respect to the ImageNet dataset,\n+                without scaling.\n+            - tf: will scale pixels between -1 and 1,\n+                sample-wise.\n+\n+    # Returns\n+        Preprocessed Numpy array.\n+    \"\"\"\n     if mode == 'tf':\n         x /= 127.5\n         x -= 1.\n@@ -69,6 +85,22 @@ def _preprocess_numpy_input(x, data_format, mode):\n \n \n def _preprocess_symbolic_input(x, data_format, mode):\n+    \"\"\"Preprocesses a tensor encoding a batch of images.\n+\n+    # Arguments\n+        x: Input tensor, 3D or 4D.\n+        data_format: Data format of the image tensor.\n+        mode: One of \"caffe\", \"tf\".\n+            - caffe: will convert the images from RGB to BGR,\n+                then will zero-center each color channel with\n+                respect to the ImageNet dataset,\n+                without scaling.\n+            - tf: will scale pixels between -1 and 1,\n+                sample-wise.\n+\n+    # Returns\n+        Preprocessed tensor.\n+    \"\"\"\n     global _IMAGENET_MEAN\n \n     if mode == 'tf':\n@@ -107,11 +139,11 @@ def _preprocess_symbolic_input(x, data_format, mode):\n \n \n def preprocess_input(x, data_format=None, mode='caffe'):\n-    \"\"\"Preprocesses a tensor encoding a batch of images.\n+    \"\"\"Preprocesses a tensor or Numpy array encoding a batch of images.\n \n     # Arguments\n-        x: input Numpy or symoblic tensor, 3D or 4D.\n-        data_format: data format of the image tensor.\n+        x: Input Numpy or symbolic tensor, 3D or 4D.\n+        data_format: Data format of the image tensor/array.\n         mode: One of \"caffe\", \"tf\".\n             - caffe: will convert the images from RGB to BGR,\n                 then will zero-center each color channel with\n@@ -121,7 +153,10 @@ def preprocess_input(x, data_format=None, mode='caffe'):\n                 sample-wise.\n \n     # Returns\n-        Preprocessed tensor.\n+        Preprocessed tensor or Numpy array.\n+\n+    # Raises\n+        ValueError: In case of unknown `data_format` argument.\n     \"\"\"\n     if data_format is None:\n         data_format = K.image_data_format()\n@@ -140,7 +175,7 @@ def decode_predictions(preds, top=5):\n \n     # Arguments\n         preds: Numpy tensor encoding a batch of predictions.\n-        top: integer, how many top-guesses to return.\n+        top: Integer, how many top-guesses to return.\n \n     # Returns\n         A list of lists of top class prediction tuples\n@@ -148,7 +183,7 @@ def decode_predictions(preds, top=5):\n         One list of tuples per sample in batch input.\n \n     # Raises\n-        ValueError: in case of invalid shape of the `pred` array\n+        ValueError: In case of invalid shape of the `pred` array\n             (must be 2D).\n     \"\"\"\n     global CLASS_INDEX\n@@ -178,17 +213,17 @@ def _obtain_input_shape(input_shape,\n                         data_format,\n                         require_flatten,\n                         weights=None):\n-    \"\"\"Internal utility to compute/validate an ImageNet model's input shape.\n+    \"\"\"Internal utility to compute/validate a model's input shape.\n \n     # Arguments\n-        input_shape: either None (will return the default network input shape),\n+        input_shape: Either None (will return the default network input shape),\n             or a user-provided shape to be validated.\n-        default_size: default input width/height for the model.\n-        min_size: minimum input width/height accepted by the model.\n-        data_format: image data format to use.\n-        require_flatten: whether the model is expected to\n+        default_size: Default input width/height for the model.\n+        min_size: Minimum input width/height accepted by the model.\n+        data_format: Image data format to use.\n+        require_flatten: Whether the model is expected to\n             be linked to a classifier via a Flatten layer.\n-        weights: one of `None` (random initialization)\n+        weights: One of `None` (random initialization)\n             or 'imagenet' (pre-training on ImageNet).\n             If weights='imagenet' input channels must be equal to 3.\n \n@@ -196,7 +231,7 @@ def _obtain_input_shape(input_shape,\n         An integer shape tuple (may include None entries).\n \n     # Raises\n-        ValueError: in case of invalid argument values.\n+        ValueError: In case of invalid argument values.\n     \"\"\"\n     if weights != 'imagenet' and input_shape and len(input_shape) == 3:\n         if data_format == 'channels_first':\n\n@@ -1,4 +1,4 @@\n-'''NASNet-A models for Keras\n+'''NASNet-A models for Keras.\n \n NASNet refers to Neural Architecture Search Network, a family of models\n that were designed automatically by learning the model architectures\n@@ -86,36 +86,36 @@ def NASNet(input_shape=None,\n     at `~/.keras/keras.json`.\n \n     # Arguments\n-        input_shape: optional shape tuple, only to be specified\n+        input_shape: Optional shape tuple, only to be specified\n             if `include_top` is False (otherwise the input shape\n             has to be `(331, 331, 3)` for NASNetLarge or\n             `(224, 224, 3)` for NASNetMobile\n             It should have exactly 3 inputs channels,\n             and width and height should be no smaller than 32.\n             E.g. `(224, 224, 3)` would be one valid value.\n-        penultimate_filters: number of filters in the penultimate layer.\n+        penultimate_filters: Number of filters in the penultimate layer.\n             NASNet models use the notation `NASNet (N @ P)`, where:\n                 -   N is the number of blocks\n                 -   P is the number of penultimate filters\n-        num_blocks: number of repeated blocks of the NASNet model.\n+        num_blocks: Number of repeated blocks of the NASNet model.\n             NASNet models use the notation `NASNet (N @ P)`, where:\n                 -   N is the number of blocks\n                 -   P is the number of penultimate filters\n-        stem_block_filters: number of filters in the initial stem block\n+        stem_block_filters: Number of filters in the initial stem block\n         skip_reduction: Whether to skip the reduction step at the tail\n             end of the network. Set to `False` for CIFAR models.\n-        filter_multiplier: controls the width of the network.\n+        filter_multiplier: Controls the width of the network.\n             - If `filter_multiplier` < 1.0, proportionally decreases the number\n                 of filters in each layer.\n             - If `filter_multiplier` > 1.0, proportionally increases the number\n                 of filters in each layer.\n             - If `filter_multiplier` = 1, default number of filters from the\n                  paper are used at each layer.\n-        include_top: whether to include the fully-connected\n+        include_top: Whether to include the fully-connected\n             layer at the top of the network.\n         weights: `None` (random initialization) or\n             `imagenet` (ImageNet weights)\n-        input_tensor: optional Keras tensor (i.e. output of\n+        input_tensor: Optional Keras tensor (i.e. output of\n             `layers.Input()`)\n             to use as image input for the model.\n         pooling: Optional pooling mode for feature extraction\n@@ -130,16 +130,16 @@ def NASNet(input_shape=None,\n                 2D tensor.\n             - `max` means that global max pooling will\n                 be applied.\n-        classes: optional number of classes to classify images\n+        classes: Optional number of classes to classify images\n             into, only to be specified if `include_top` is True, and\n             if no `weights` argument is specified.\n-        default_size: specifies the default image size of the model\n+        default_size: Specifies the default image size of the model\n \n     # Returns\n         A Keras model instance.\n \n     # Raises\n-        ValueError: in case of invalid argument for `weights`,\n+        ValueError: In case of invalid argument for `weights`,\n             invalid input shape or invalid `penultimate_filters` value.\n         RuntimeError: If attempting to run this model with a\n             backend that does not support separable convolutions.\n@@ -314,17 +314,17 @@ def NASNetLarge(input_shape=None,\n     at `~/.keras/keras.json`.\n \n     # Arguments\n-        input_shape: optional shape tuple, only to be specified\n+        input_shape: Optional shape tuple, only to be specified\n             if `include_top` is False (otherwise the input shape\n             has to be `(331, 331, 3)` for NASNetLarge.\n             It should have exactly 3 inputs channels,\n             and width and height should be no smaller than 32.\n             E.g. `(224, 224, 3)` would be one valid value.\n-        include_top: whether to include the fully-connected\n+        include_top: Whether to include the fully-connected\n             layer at the top of the network.\n         weights: `None` (random initialization) or\n             `imagenet` (ImageNet weights)\n-        input_tensor: optional Keras tensor (i.e. output of\n+        input_tensor:Ooptional Keras tensor (i.e. output of\n             `layers.Input()`)\n             to use as image input for the model.\n         pooling: Optional pooling mode for feature extraction\n@@ -339,10 +339,9 @@ def NASNetLarge(input_shape=None,\n                 2D tensor.\n             - `max` means that global max pooling will\n                 be applied.\n-        classes: optional number of classes to classify images\n+        classes: Optional number of classes to classify images\n             into, only to be specified if `include_top` is True, and\n             if no `weights` argument is specified.\n-        default_size: specifies the default image size of the model\n \n     # Returns\n         A Keras model instance.\n@@ -381,17 +380,17 @@ def NASNetMobile(input_shape=None,\n     at `~/.keras/keras.json`.\n \n     # Arguments\n-        input_shape: optional shape tuple, only to be specified\n+        input_shape: Optional shape tuple, only to be specified\n             if `include_top` is False (otherwise the input shape\n             has to be `(224, 224, 3)` for NASNetMobile\n             It should have exactly 3 inputs channels,\n             and width and height should be no smaller than 32.\n             E.g. `(224, 224, 3)` would be one valid value.\n-        include_top: whether to include the fully-connected\n+        include_top: Whether to include the fully-connected\n             layer at the top of the network.\n         weights: `None` (random initialization) or\n             `imagenet` (ImageNet weights)\n-        input_tensor: optional Keras tensor (i.e. output of\n+        input_tensor: Optional Keras tensor (i.e. output of\n             `layers.Input()`)\n             to use as image input for the model.\n         pooling: Optional pooling mode for feature extraction\n@@ -406,16 +405,15 @@ def NASNetMobile(input_shape=None,\n                 2D tensor.\n             - `max` means that global max pooling will\n                 be applied.\n-        classes: optional number of classes to classify images\n+        classes: Optional number of classes to classify images\n             into, only to be specified if `include_top` is True, and\n             if no `weights` argument is specified.\n-        default_size: specifies the default image size of the model\n \n     # Returns\n         A Keras model instance.\n \n     # Raises\n-        ValueError: in case of invalid argument for `weights`,\n+        ValueError: In case of invalid argument for `weights`,\n             or invalid input shape.\n         RuntimeError: If attempting to run this model with a\n             backend that does not support separable convolutions.\n@@ -434,19 +432,21 @@ def NASNetMobile(input_shape=None,\n                   default_size=224)\n \n \n-def _separable_conv_block(ip, filters, kernel_size=(3, 3), strides=(1, 1),\n+def _separable_conv_block(ip, filters,\n+                          kernel_size=(3, 3),\n+                          strides=(1, 1),\n                           block_id=None):\n-    '''Adds 2 blocks of [relu-separable conv-batchnorm]\n+    '''Adds 2 blocks of [relu-separable conv-batchnorm].\n \n-    # Arguments:\n-        ip: input tensor\n-        filters: number of output filters per layer\n-        kernel_size: kernel size of separable convolutions\n-        strides: strided convolution for downsampling\n-        block_id: string block_id\n+    # Arguments\n+        ip: Input tensor\n+        filters: Number of output filters per layer\n+        kernel_size: Kernel size of separable convolutions\n+        strides: Strided convolution for downsampling\n+        block_id: String block_id\n \n-    # Returns:\n-        a Keras tensor\n+    # Returns\n+        A Keras tensor\n     '''\n     channel_dim = 1 if K.image_data_format() == 'channels_first' else -1\n \n@@ -471,18 +471,18 @@ def _separable_conv_block(ip, filters, kernel_size=(3, 3), strides=(1, 1),\n \n \n def _adjust_block(p, ip, filters, block_id=None):\n-    '''\n-    Adjusts the input `previous path` to match the shape of the `input`\n-    or situations where the output number of filters needs to be changed\n+    '''Adjusts the input `previous path` to match the shape of the `input`.\n \n-    # Arguments:\n-        p: input tensor which needs to be modified\n-        ip: input tensor whose shape needs to be matched\n-        filters: number of output filters to be matched\n-        block_id: string block_id\n+    Used in situations where the output number of filters needs to be changed.\n \n-    # Returns:\n-        an adjusted Keras tensor\n+    # Arguments\n+        p: Input tensor which needs to be modified\n+        ip: Input tensor whose shape needs to be matched\n+        filters: Number of output filters to be matched\n+        block_id: String block_id\n+\n+    # Returns\n+        Adjusted Keras tensor\n     '''\n     channel_dim = 1 if K.image_data_format() == 'channels_first' else -1\n     img_dim = 2 if K.image_data_format() == 'channels_first' else -2\n@@ -535,14 +535,14 @@ def _adjust_block(p, ip, filters, block_id=None):\n def _normal_a_cell(ip, p, filters, block_id=None):\n     '''Adds a Normal cell for NASNet-A (Fig. 4 in the paper)\n \n-    # Arguments:\n-        ip: input tensor `x`\n-        p: input tensor `p`\n-        filters: number of output filters\n-        block_id: string block_id\n+    # Arguments\n+        ip: Input tensor `x`\n+        p: Input tensor `p`\n+        filters: Number of output filters\n+        block_id: String block_id\n \n-    # Returns:\n-        a Keras tensor\n+    # Returns\n+        A Keras tensor\n     '''\n     channel_dim = 1 if K.image_data_format() == 'channels_first' else -1\n \n@@ -596,14 +596,14 @@ def _normal_a_cell(ip, p, filters, block_id=None):\n def _reduction_a_cell(ip, p, filters, block_id=None):\n     '''Adds a Reduction cell for NASNet-A (Fig. 4 in the paper)\n \n-    # Arguments:\n-        ip: input tensor `x`\n-        p: input tensor `p`\n-        filters: number of output filters\n-        block_id: string block_id\n+    # Arguments\n+        ip: Input tensor `x`\n+        p: Input tensor `p`\n+        filters: Number of output filters\n+        block_id: String block_id\n \n-    # Returns:\n-        a Keras tensor\n+    # Returns\n+        A Keras tensor\n     '''\n     channel_dim = 1 if K.image_data_format() == 'channels_first' else -1\n \n\n@@ -23,8 +23,10 @@ def load_data():\n              't10k-labels-idx1-ubyte.gz', 't10k-images-idx3-ubyte.gz']\n \n     paths = []\n-    for file in files:\n-        paths.append(get_file(file, origin=base + file, cache_subdir=dirname))\n+    for fname in files:\n+        paths.append(get_file(fname,\n+                              origin=base + fname,\n+                              cache_subdir=dirname))\n \n     with gzip.open(paths[0], 'rb') as lbpath:\n         y_train = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n\n@@ -93,7 +93,7 @@ def load_data(path='imdb.npz', num_words=None, skip_top=0,\n     if oov_char is not None:\n         xs = [[w if (skip_top <= w < num_words) else oov_char for w in x] for x in xs]\n     else:\n-        xs = [[w for w in x if (skip_top <= w < num_words)] for x in xs]\n+        xs = [[w for w in x if skip_top <= w < num_words] for x in xs]\n \n     idx = len(x_train)\n     x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n\n@@ -339,7 +339,7 @@ class Concatenate(_Merge):\n         # Used purely for shape validation.\n         if not isinstance(input_shape, list) or len(input_shape) < 2:\n             raise ValueError('A `Concatenate` layer should be called '\n-                             'on a list of of at least 2 inputs')\n+                             'on a list of at least 2 inputs')\n         if all([shape is None for shape in input_shape]):\n             return\n         reduced_inputs_shapes = [list(shape) for shape in input_shape]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4778fa0cec5e35be043fd157ce70b99421b621e1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 11 | Files Changed: 6 | Hunks: 12 | Methods Changed: 9 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 27 | Churn Cumulative: 11690 | Contributors (this commit): 142 | Commits (past 90d): 74 | Contributors (cumulative): 167 | DMM Complexity: None\n\nDIFF:\n@@ -1,3 +1,5 @@\n+\"\"\"Utilities for ImageNet data preprocessing & prediction decoding.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n\n@@ -324,7 +324,7 @@ def NASNetLarge(input_shape=None,\n             layer at the top of the network.\n         weights: `None` (random initialization) or\n             `imagenet` (ImageNet weights)\n-        input_tensor:Ooptional Keras tensor (i.e. output of\n+        input_tensor: Optional Keras tensor (i.e. output of\n             `layers.Input()`)\n             to use as image input for the model.\n         pooling: Optional pooling mode for feature extraction\n@@ -533,7 +533,7 @@ def _adjust_block(p, ip, filters, block_id=None):\n \n \n def _normal_a_cell(ip, p, filters, block_id=None):\n-    '''Adds a Normal cell for NASNet-A (Fig. 4 in the paper)\n+    '''Adds a Normal cell for NASNet-A (Fig. 4 in the paper).\n \n     # Arguments\n         ip: Input tensor `x`\n@@ -594,7 +594,7 @@ def _normal_a_cell(ip, p, filters, block_id=None):\n \n \n def _reduction_a_cell(ip, p, filters, block_id=None):\n-    '''Adds a Reduction cell for NASNet-A (Fig. 4 in the paper)\n+    '''Adds a Reduction cell for NASNet-A (Fig. 4 in the paper).\n \n     # Arguments\n         ip: Input tensor `x`\n\n@@ -77,9 +77,9 @@ def load_data(path='reuters.npz', num_words=None, skip_top=0,\n     # reserve 'index_from' (=3 by default) characters:\n     # 0 (padding), 1 (start), 2 (OOV)\n     if oov_char is not None:\n-        xs = [[w if (skip_top <= w < num_words) else oov_char for w in x] for x in xs]\n+        xs = [[w if skip_top <= w < num_words else oov_char for w in x] for x in xs]\n     else:\n-        xs = [[w for w in x if (skip_top <= w < num_words)] for x in xs]\n+        xs = [[w for w in x if skip_top <= w < num_words] for x in xs]\n \n     idx = int(len(xs) * (1 - test_split))\n     x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n\n@@ -697,10 +697,10 @@ class Model(Container):\n                                          'dictionary: \"' + name + '\". '\n                                          'Only expected the following keys: ' +\n                                          str(self.output_names))\n-                _target_tensors = []\n+                tmp_target_tensors = []\n                 for name in self.output_names:\n-                    _target_tensors.append(target_tensors.get(name, None))\n-                target_tensors = _target_tensors\n+                    tmp_target_tensors.append(target_tensors.get(name, None))\n+                target_tensors = tmp_target_tensors\n             else:\n                 raise TypeError('Expected `target_tensors` to be '\n                                 'a list or dict, but got:', target_tensors)\n@@ -1020,6 +1020,9 @@ class Model(Container):\n             processed based on the size of the first dimension of the\n             first input numpy array. When steps is not `None` and\n             `batch_size` is `None`, returns `None`.\n+\n+        # Raises\n+            ValueError: In case of invalid arguments.\n         \"\"\"\n         if steps is not None:\n             num_samples = None\n@@ -1696,7 +1699,6 @@ class Model(Container):\n                 before declaring the evaluation round finished.\n                 Ignored with the default value of `None`.\n \n-\n         # Returns\n             Scalar test loss (if the model has a single output and no metrics)\n             or list of scalars (if the model has multiple outputs\n\n@@ -956,7 +956,7 @@ def _count_valid_files_in_directory(directory, white_list_formats, follow_links)\n         return sorted(os.walk(subpath, followlinks=follow_links), key=lambda tpl: tpl[0])\n \n     samples = 0\n-    for root, _, files in _recursive_list(directory):\n+    for _, _, files in _recursive_list(directory):\n         for fname in files:\n             is_valid = False\n             for extension in white_list_formats:\n\n@@ -48,7 +48,8 @@ def print_summary(model, line_length=None, positions=None, print_fn=None):\n         nodes = []\n         for v in nodes_by_depth:\n             if (len(v) > 1) or (len(v) == 1 and len(v[0].inbound_layers) > 1):\n-                # if the model has multiple nodes or if the nodes have multiple inbound_layers\n+                # if the model has multiple nodes\n+                # or if the nodes have multiple inbound_layers\n                 # the model is no longer sequential\n                 sequential_like = False\n                 break\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9357c41bbe9d1fb2fa8669066b029350f49f3767", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 22 | Lines Deleted: 21 | Files Changed: 6 | Hunks: 13 | Methods Changed: 8 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 43 | Churn Cumulative: 5395 | Contributors (this commit): 38 | Commits (past 90d): 39 | Contributors (cumulative): 52 | DMM Complexity: 0.0\n\nDIFF:\n@@ -363,15 +363,15 @@ def InceptionResNetV2(include_top=True,\n                               'your Keras config '\n                               'at ~/.keras/keras.json.')\n         if include_top:\n-            weights_filename = 'inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5'\n-            weights_path = get_file(weights_filename,\n-                                    BASE_WEIGHT_URL + weights_filename,\n+            fname = 'inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5'\n+            weights_path = get_file(fname,\n+                                    BASE_WEIGHT_URL + fname,\n                                     cache_subdir='models',\n                                     file_hash='e693bd0210a403b3192acc6073ad2e96')\n         else:\n-            weights_filename = 'inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5'\n-            weights_path = get_file(weights_filename,\n-                                    BASE_WEIGHT_URL + weights_filename,\n+            fname = 'inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5'\n+            weights_path = get_file(fname,\n+                                    BASE_WEIGHT_URL + fname,\n                                     cache_subdir='models',\n                                     file_hash='d19885ff4a710c122648d3b5c3b684e4')\n         model.load_weights(weights_path)\n\n@@ -21,11 +21,11 @@ The below table describes the performance on ImageNet 2012:\n Weights obtained from the official Tensorflow repository found at\n https://github.com/tensorflow/models/tree/master/research/slim/nets/nasnet\n \n-# References:\n+# References\n  - [Learning Transferable Architectures for Scalable Image Recognition]\n     (https://arxiv.org/abs/1707.07012)\n \n-Based on the following implementations:\n+# Based on the following implementations\n  - [TF Slim Implementation]\n    (https://github.com/tensorflow/models/blob/master/research/slim/nets/nasnet/nasnet.py)\n  - [TensorNets implementation]\n\n@@ -86,11 +86,13 @@ def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2))\n         filters: list of integers, the filters of 3 conv layer at main path\n         stage: integer, current stage label, used for generating layer names\n         block: 'a','b'..., current block label, used for generating layer names\n+        strides: Strides for the first conv layer in the block.\n \n     # Returns\n         Output tensor for the block.\n \n-    Note that from stage 3, the first conv layer at main path is with strides=(2,2)\n+    Note that from stage 3,\n+    the first conv layer at main path is with strides=(2, 2)\n     And the shortcut should have strides=(2, 2) as well\n     \"\"\"\n     filters1, filters2, filters3 = filters\n\n@@ -151,8 +151,6 @@ class LocallyConnected1D(Layer):\n         return (input_shape[0], length, self.filters)\n \n     def call(self, inputs):\n-        output_length, _, filters = self.kernel_shape\n-\n         output = K.local_conv1d(inputs, self.kernel, self.kernel_size, self.strides)\n         if self.use_bias:\n             output = K.bias_add(output, self.bias)\n\n@@ -44,7 +44,7 @@ class _Merge(Layer):\n             return None\n         elif len(shape1) < len(shape2):\n             return self._compute_elemwise_op_output_shape(shape2, shape1)\n-        elif len(shape2) == 0:\n+        elif not shape2:\n             return shape1\n         output_shape = list(shape1[:-len(shape2)])\n         for i, j in zip(shape1[-len(shape2):], shape2):\n\n@@ -389,7 +389,6 @@ def get_index(uid, i):\n     # Returns\n         The value at index `i`.\n     \"\"\"\n-    global _SHARED_SEQUENCES\n     return _SHARED_SEQUENCES[uid][i]\n \n \n@@ -546,9 +545,10 @@ class OrderedEnqueuer(SequenceEnqueuer):\n \n         Skip the data if it is `None`.\n \n-        # Returns\n-            Generator yielding tuples (inputs, targets)\n-                or (inputs, targets, sample_weights)\n+        # Yields\n+            The next element in the queue, i.e. a tuple\n+            `(inputs, targets)` or\n+            `(inputs, targets, sample_weights)`.\n         \"\"\"\n         try:\n             while self.is_running():\n@@ -562,8 +562,8 @@ class OrderedEnqueuer(SequenceEnqueuer):\n \n     def _send_sequence(self):\n         \"\"\"Send current Sequence to all workers.\"\"\"\n-        global _SHARED_SEQUENCES\n-        _SHARED_SEQUENCES[self.uid] = self.sequence  # For new processes that may spawn\n+        # For new processes that may spawn\n+        _SHARED_SEQUENCES[self.uid] = self.sequence\n \n     def stop(self, timeout=None):\n         \"\"\"Stops running threads and wait for them to exit, if necessary.\n@@ -573,7 +573,6 @@ class OrderedEnqueuer(SequenceEnqueuer):\n         # Arguments\n             timeout: maximum time to wait on `thread.join()`\n         \"\"\"\n-        global _SHARED_SEQUENCES\n         self.stop_signal.set()\n         with self.queue.mutex:\n             self.queue.queue.clear()\n@@ -739,8 +738,10 @@ class GeneratorEnqueuer(SequenceEnqueuer):\n \n         Skip the data if it is `None`.\n \n-        # Returns\n-            A generator\n+        # Yields\n+            The next element in the queue, i.e. a tuple\n+            `(inputs, targets)` or\n+            `(inputs, targets, sample_weights)`.\n         \"\"\"\n         while self.is_running():\n             if not self.queue.empty():\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#86a0e2c86354cc3874a524e8f500ac8ee94eb08f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 7 | Files Changed: 3 | Hunks: 6 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 18 | Churn Cumulative: 13219 | Contributors (this commit): 100 | Commits (past 90d): 48 | Contributors (cumulative): 107 | DMM Complexity: 0.0\n\nDIFF:\n@@ -457,7 +457,7 @@ class RNN(Layer):\n \n         if self.state_spec is not None:\n             # initial_state was passed in call, check compatibility\n-            if not [spec.shape[-1] for spec in self.state_spec] == state_size:\n+            if [spec.shape[-1] for spec in self.state_spec] != state_size:\n                 raise ValueError(\n                     'An initial_state was passed that is not compatible with '\n                     '`cell.state_size`. Received `state_spec`={}; '\n\n@@ -940,10 +940,11 @@ class NumpyArrayIterator(Iterator):\n \n \n def _count_valid_files_in_directory(directory, white_list_formats, follow_links):\n-    \"\"\"Count files with extension in `white_list_formats` contained in a directory.\n+    \"\"\"Count files with extension in `white_list_formats` contained in directory.\n \n     # Arguments\n-        directory: absolute path to the directory containing files to be counted\n+        directory: absolute path to the directory\n+            containing files to be counted\n         white_list_formats: set of strings containing allowed extensions for\n             the files to be counted.\n         follow_links: boolean.\n\n@@ -515,7 +515,7 @@ class OrderedEnqueuer(SequenceEnqueuer):\n                 return\n \n     def _run(self):\n-        \"\"\"Function to submit request to the executor and queue the `Future` objects.\"\"\"\n+        \"\"\"Submits request to the executor and queue the `Future` objects.\"\"\"\n         sequence = list(range(len(self.sequence)))\n         self._send_sequence()  # Share the initial sequence\n         while True:\n@@ -625,10 +625,13 @@ class GeneratorEnqueuer(SequenceEnqueuer):\n             while not self._stop_event.is_set():\n                 with self.genlock:\n                     try:\n-                        if self.queue is not None and self.queue.qsize() < self.max_queue_size:\n-                            # On all OSes, avoid **SYSTEMATIC** error in multithreading mode:\n+                        if (self.queue is not None and\n+                                self.queue.qsize() < self.max_queue_size):\n+                            # On all OSes, avoid **SYSTEMATIC** error\n+                            # in multithreading mode:\n                             # `ValueError: generator already executing`\n-                            # => Serialize calls to infinite iterator/generator's next() function\n+                            # => Serialize calls to\n+                            # infinite iterator/generator's next() function\n                             generator_output = next(self._generator)\n                             self.queue.put((True, generator_output))\n                         else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3ce40705a7235cabe81cfaa2ab9b9d56f225af52", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 9302 | Contributors (this commit): 101 | Commits (past 90d): 29 | Contributors (cumulative): 101 | DMM Complexity: None\n\nDIFF:\n@@ -998,7 +998,7 @@ def moving_average_update(x, value, momentum):\n         An operation to update the variable.\n     \"\"\"\n     return moving_averages.assign_moving_average(\n-        x, value, momentum, zero_debias=False)\n+        x, value, momentum, zero_debias=True)\n \n \n # LINEAR ALGEBRA\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#869114cadf7e590712d67623d11e370fd9ab5806", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 1345 | Contributors (this commit): 14 | Commits (past 90d): 15 | Contributors (cumulative): 14 | DMM Complexity: 0.0\n\nDIFF:\n@@ -649,7 +649,8 @@ class GeneratorEnqueuer(SequenceEnqueuer):\n         else:\n             while not self._stop_event.is_set():\n                 try:\n-                    if self.queue is not None and self.queue.qsize() < self.max_queue_size:\n+                    if (self.queue is not None and\n+                            self.queue.qsize() < self.max_queue_size):\n                         generator_output = next(self._generator)\n                         self.queue.put((True, generator_output))\n                     else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9c24aed50db289f0fdeedc6e0e69c916a5b66f8f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 5 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 15 | Churn Cumulative: 354 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -1,14 +1,17 @@\n # -*- coding: utf-8 -*-\n \"\"\"DenseNet models for Keras.\n \n-# Reference paper:\n+# Reference paper\n \n-- [Densely Connected Convolutional Networks](https://arxiv.org/abs/1608.06993) (CVPR 2017 Best Paper Award)\n+- [Densely Connected Convolutional Networks]\n+  (https://arxiv.org/abs/1608.06993) (CVPR 2017 Best Paper Award)\n \n-# Reference implementation:\n+# Reference implementation\n \n-- [Torch DenseNets](https://github.com/liuzhuang13/DenseNet/blob/master/models/densenet.lua)\n-- [TensorNets](https://github.com/taehoonlee/tensornets/blob/master/tensornets/densenets.py)\n+- [Torch DenseNets]\n+  (https://github.com/liuzhuang13/DenseNet/blob/master/models/densenet.lua)\n+- [TensorNets]\n+  (https://github.com/taehoonlee/tensornets/blob/master/tensornets/densenets.py)\n \"\"\"\n from __future__ import absolute_import\n from __future__ import division\n@@ -75,7 +78,7 @@ def transition_block(x, reduction, name):\n     x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n                            name=name + '_bn')(x)\n     x = Activation('relu', name=name + '_relu')(x)\n-    x = Conv2D(int(x._keras_shape[bn_axis] * reduction), 1, use_bias=False,\n+    x = Conv2D(int(K.int_shape(x)[bn_axis] * reduction), 1, use_bias=False,\n                name=name + '_conv')(x)\n     x = AveragePooling2D(2, strides=2, name=name + '_pool')(x)\n     return x\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4c7143ef59a69c08fc3b09f8d12d93fdfbf497b8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 8467 | Contributors (this commit): 54 | Commits (past 90d): 11 | Contributors (cumulative): 54 | DMM Complexity: None\n\nDIFF:\n@@ -2704,7 +2704,7 @@ class Container(Layer):\n         \"\"\"\n         return yaml.dump(self._updated_config(), **kwargs)\n \n-    def summary(self, line_length=None, positions=None, print_fn=print):\n+    def summary(self, line_length=None, positions=None, print_fn=None):\n         \"\"\"Prints a string summary of the network.\n \n         # Arguments\n@@ -2718,6 +2718,7 @@ class Container(Layer):\n                 It will be called on each line of the summary.\n                 You can set it to a custom function\n                 in order to capture the string summary.\n+                It defaults to `print` (prints to stdout).\n         \"\"\"\n         return print_layer_summary(self,\n                                    line_length=line_length,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d2c94474ac11da442dff4548c0fe325eeecc5561", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 355 | Contributors (this commit): 2 | Commits (past 90d): 4 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -27,7 +27,6 @@ from ..layers import BatchNormalization\n from ..layers import Concatenate\n from ..layers import Conv2D\n from ..layers import Dense\n-from ..layers import Flatten\n from ..layers import GlobalAveragePooling2D\n from ..layers import Input\n from ..layers import MaxPooling2D\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#759174064b28851577a8489f464f4575c09d770c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 9/9 | Churn Δ: 13 | Churn Cumulative: 17623 | Contributors (this commit): 91 | Commits (past 90d): 31 | Contributors (cumulative): 102 | DMM Complexity: 0.0\n\nDIFF:\n@@ -65,6 +65,15 @@ class InputSpec(object):\n         self.min_ndim = min_ndim\n         self.axes = axes or {}\n \n+    def __repr__(self):\n+        spec = [('dtype=' + str(self.dtype)) if self.dtype else '',\n+                ('shape=' + str(self.shape)) if self.shape else '',\n+                ('ndim=' + str(self.ndim)) if self.ndim else '',\n+                ('max_ndim=' + str(self.max_ndim)) if self.max_ndim else '',\n+                ('min_ndim=' + str(self.min_ndim)) if self.min_ndim else '',\n+                ('axes=' + str(self.axes)) if self.axes else '']\n+        return 'InputSpec(%s)' % ', '.join(x for x in spec if x)\n+\n \n class Node(object):\n     \"\"\"A `Node` describes the connectivity between two layers.\n\n@@ -459,9 +459,9 @@ class RNN(Layer):\n             # initial_state was passed in call, check compatibility\n             if [spec.shape[-1] for spec in self.state_spec] != state_size:\n                 raise ValueError(\n-                    'An initial_state was passed that is not compatible with '\n+                    'An `initial_state` was passed that is not compatible with '\n                     '`cell.state_size`. Received `state_spec`={}; '\n-                    'However `cell.state_size` is '\n+                    'however `cell.state_size` is '\n                     '{}'.format(self.state_spec, self.cell.state_size))\n         else:\n             self.state_spec = [InputSpec(shape=(None, dim))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7d7060fdc1cba0e7ead68df7385e0995abfd1ad5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 85 | Lines Deleted: 2 | Files Changed: 5 | Hunks: 11 | Methods Changed: 4 | Complexity Δ (Sum/Max): 12/9 | Churn Δ: 87 | Churn Cumulative: 1877 | Contributors (this commit): 35 | Commits (past 90d): 16 | Contributors (cumulative): 45 | DMM Complexity: 1.0\n\nDIFF:\n@@ -21,7 +21,8 @@ setup(name='Keras',\n                     'pytest-pep8',\n                     'pytest-xdist',\n                     'pytest-cov',\n-                    'pandas'],\n+                    'pandas',\n+                    'requests'],\n       },\n       classifiers=[\n           'Development Status :: 5 - Production/Stable',\n\n@@ -6,6 +6,7 @@ import pytest\n from keras.preprocessing.sequence import pad_sequences\n from keras.preprocessing.sequence import make_sampling_table\n from keras.preprocessing.sequence import skipgrams\n+from keras.preprocessing.sequence import _remove_long_seq\n \n \n def test_pad_sequences():\n@@ -82,5 +83,17 @@ def test_skipgrams():\n         assert len(l) == 2\n \n \n+def test_remove_long_seq():\n+    maxlen = 5\n+    seq = [\n+        [1, 2, 3],\n+        [1, 2, 3, 4, 5, 6],\n+    ]\n+    label = ['a', 'b']\n+    new_seq, new_label = _remove_long_seq(maxlen, seq, label)\n+    assert new_seq == [[1, 2, 3]]\n+    assert new_label == ['a']\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n@@ -17,6 +17,11 @@ from keras.utils.test_utils import get_test_data\n from keras.utils.test_utils import keras_test\n from keras import backend as K\n from keras.utils import np_utils\n+try:\n+    from unittest.mock import patch\n+except:\n+    from mock import patch\n+\n \n input_dim = 2\n num_hidden = 4\n@@ -787,5 +792,27 @@ def test_TensorBoard_with_ReduceLROnPlateau(tmpdir):\n     assert not tmpdir.listdir()\n \n \n+@keras_test\n+def tests_RemoteMonitor():\n+    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,\n+                                                         num_test=test_samples,\n+                                                         input_shape=(input_dim,),\n+                                                         classification=True,\n+                                                         num_classes=num_classes)\n+    y_test = np_utils.to_categorical(y_test)\n+    y_train = np_utils.to_categorical(y_train)\n+    model = Sequential()\n+    model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))\n+    model.add(Dense(num_classes, activation='softmax'))\n+    model.compile(loss='categorical_crossentropy',\n+                  optimizer='rmsprop',\n+                  metrics=['accuracy'])\n+    cbks = [callbacks.RemoteMonitor()]\n+\n+    with patch('requests.post'):\n+        model.fit(X_train, y_train, batch_size=batch_size,\n+                  validation_data=(X_test, y_test), callbacks=cbks, epochs=1)\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n@@ -1,13 +1,19 @@\n '''Tests for functions in io_utils.py.\n '''\n import os\n+import sys\n import pytest\n from keras.models import Sequential\n from keras.layers import Dense\n from keras.utils.io_utils import HDF5Matrix\n+from keras.utils.io_utils import ask_to_proceed_with_overwrite\n import numpy as np\n import warnings\n import h5py\n+try:\n+    from unittest.mock import patch\n+except:\n+    from mock import patch\n \n \n @pytest.fixture\n@@ -76,8 +82,45 @@ def test_io_utils(in_tmpdir):\n     # test slicing for shortened array\n     assert len(X_train[0:]) == len(X_train), 'Incorrect shape for sliced data'\n \n+    # test __getitem__\n+    with pytest.raises(IndexError):\n+        X_train[1000]\n+    with pytest.raises(IndexError):\n+        X_train[1000:1001]\n+    with pytest.raises(IndexError):\n+        X_train[[1000, 1001]]\n+    with pytest.raises(IndexError):\n+        X_train[np.array([1000])]\n+    with pytest.raises(IndexError):\n+        X_train[None]\n+    assert (X_train[0] == X_train[:1][0]).all()\n+    assert (X_train[[0, 1]] == X_train[:2]).all()\n+    assert (X_train[np.array([0, 1])] == X_train[:2]).all()\n+\n+    # test normalizer\n+    normalizer = lambda x: x + 1\n+    normalized_X_train = HDF5Matrix(h5_path, 'my_data', start=0, end=150, normalizer=normalizer)\n+    assert np.isclose(normalized_X_train[0][0], X_train[0][0] + 1)\n+\n     os.remove(h5_path)\n \n \n+def test_ask_to_proceed_with_overwrite():\n+    if sys.version_info[:2] <= (2, 7):\n+        with patch('__builtin__.raw_input') as mock:\n+            mock.return_value = 'y'\n+            assert ask_to_proceed_with_overwrite('/tmp/not_exists')\n+\n+            mock.return_value = 'n'\n+            assert not ask_to_proceed_with_overwrite('/tmp/not_exists')\n+    else:\n+        with patch('builtins.input') as mock:\n+            mock.return_value = 'y'\n+            assert ask_to_proceed_with_overwrite('/tmp/not_exists')\n+\n+            mock.return_value = 'n'\n+            assert not ask_to_proceed_with_overwrite('/tmp/not_exists')\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n@@ -11,7 +11,6 @@ from keras.models import Sequential\n from keras.utils import vis_utils\n \n \n-@pytest.mark.skipif(sys.version_info > (3, 0), reason='pydot-ng currently supports python 3.4')\n def test_plot_model():\n     model = Sequential()\n     model.add(Conv2D(filters=2, kernel_size=(2, 3), input_shape=(3, 5, 5), name='conv'))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#32aa192548b6b59bf407e583fbd246ba9f5f5676", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 2741 | Contributors (this commit): 46 | Commits (past 90d): 16 | Contributors (cumulative): 46 | DMM Complexity: 0.0\n\nDIFF:\n@@ -748,9 +748,10 @@ class ImageDataGenerator(object):\n \n         if self.zca_whitening:\n             flat_x = np.reshape(x, (x.shape[0], x.shape[1] * x.shape[2] * x.shape[3]))\n-            sigma = np.dot(flat_x.T, flat_x) / flat_x.shape[0]\n-            u, s, _ = linalg.svd(sigma)\n-            self.principal_components = np.dot(np.dot(u, np.diag(1. / np.sqrt(s + self.zca_epsilon))), u.T)\n+            num_examples = flat_x.shape[0]\n+            u, s, vt = linalg.svd(flat_x / np.sqrt(num_examples))\n+            s_expand = np.hstack((s, np.zeros(vt.shape[0] - num_examples, dtype=flat_x.dtype)))\n+            self.principal_components = (vt.T / np.sqrt(s_expand ** 2 + self.zca_epsilon)).dot(vt)\n \n \n class Iterator(Sequence):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f699346386e2de5a76fbed1f1c2d16c6fa1d9000", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 10 | Churn Cumulative: 9312 | Contributors (this commit): 102 | Commits (past 90d): 29 | Contributors (cumulative): 102 | DMM Complexity: 0.0\n\nDIFF:\n@@ -2915,15 +2915,13 @@ def relu(x, alpha=0., max_value=None):\n         A tensor.\n     \"\"\"\n     if alpha != 0.:\n-        negative_part = tf.nn.relu(-x)\n+        x = tf.nn.leaky_relu(x, alpha)\n+    else:\n         x = tf.nn.relu(x)\n+\n     if max_value is not None:\n         max_value = _to_tensor(max_value, x.dtype.base_dtype)\n-        zero = _to_tensor(0., x.dtype.base_dtype)\n-        x = tf.clip_by_value(x, zero, max_value)\n-    if alpha != 0.:\n-        alpha = _to_tensor(alpha, x.dtype.base_dtype)\n-        x -= alpha * negative_part\n+        x = tf.minimum(x, max_value)\n     return x\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
