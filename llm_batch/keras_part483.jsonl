{"custom_id": "keras#ff4a15ce3278512a0d9582fce9339a3ae022e59f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 4 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 932 | Contributors (this commit): 7 | Commits (past 90d): 3 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -36,6 +36,7 @@ from keras.utils import tf_inspect\n \n # isort: off\n from tensorflow.python.util.tf_export import tf_export\n+from tensorflow.python.util.deprecation import deprecated\n \n \n class _RNNCellWrapper(AbstractRNNCell):\n@@ -142,6 +143,7 @@ class _RNNCellWrapper(AbstractRNNCell):\n         return cls(cell, **config)\n \n \n+@deprecated(None, \"Please use tf.keras.layers.RNN instead.\")\n @tf_export(\"nn.RNNCellDropoutWrapper\", v1=[])\n class DropoutWrapper(_RNNCellWrapper):\n     \"\"\"Operator adding dropout to inputs and outputs of the given cell.\"\"\"\n@@ -488,6 +490,7 @@ class DropoutWrapper(_RNNCellWrapper):\n         )\n \n \n+@deprecated(None, \"Please use tf.keras.layers.RNN instead.\")\n @tf_export(\"nn.RNNCellResidualWrapper\", v1=[])\n class ResidualWrapper(_RNNCellWrapper):\n     \"\"\"RNNCell wrapper that ensures cell inputs are added to the outputs.\"\"\"\n@@ -577,6 +580,7 @@ class ResidualWrapper(_RNNCellWrapper):\n         )\n \n \n+@deprecated(None, \"Please use tf.keras.layers.RNN instead.\")\n @tf_export(\"nn.RNNCellDeviceWrapper\", v1=[])\n class DeviceWrapper(_RNNCellWrapper):\n     \"\"\"Operator that ensures an RNNCell runs on a particular device.\"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0cd72df9f858ad17861e38f0938b3e8778db7180", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 3917 | Contributors (this commit): 13 | Commits (past 90d): 4 | Contributors (cumulative): 13 | DMM Complexity: None\n\nDIFF:\n@@ -73,6 +73,10 @@ class VocabWeightHandler(base_layer_utils.TrackableWeightHandler):\n     \"\"\"Adds the vocabulary as a layer weight during serialization.\"\"\"\n \n     def __init__(self, lookup_layer):\n+        # Note that this class doesn't call super().__init__() in order to\n+        # have customized behavior. The fileds like '_dtype' and\n+        # '_distribute_strategy' are required by the parent class, as well as\n+        # tf.distribute. See `strategy.extended.variable_created_in_scope`\n         self._layer = lookup_layer\n         self._dtype = lookup_layer.vocabulary_dtype\n         self._distribute_strategy = tf.distribute.get_strategy()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#983868f4f883052ca122ec132b9ba7a0611f0076", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -21/0 | Churn Δ: 2 | Churn Cumulative: 10647 | Contributors (this commit): 34 | Commits (past 90d): 10 | Contributors (cumulative): 34 | DMM Complexity: None\n\nDIFF:\n@@ -841,7 +841,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n                 instead of an integer.\n \n         Returns:\n-            An output shape tuple.\n+            A shape tuple or `tf.TensorShape` instance\n         \"\"\"\n         if tf.executing_eagerly():\n             # In this case we build the model first in order to do shape\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3cec735c5602a1bd9880b1b5735c5ce64a94eb76", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 4 | Churn Cumulative: 4388 | Contributors (this commit): 43 | Commits (past 90d): 5 | Contributors (cumulative): 43 | DMM Complexity: 0.0\n\nDIFF:\n@@ -284,6 +284,10 @@ def get_file(\n                         total_size = None\n                     self.progbar = Progbar(total_size)\n                 current = block_num * block_size\n+\n+                if total_size is None:\n+                    self.progbar.update(current)\n+                else:\n                     if current < total_size:\n                         self.progbar.update(current)\n                     elif not self.finished:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a1c1aff5c7503d8f8d8d6de59cc7aedc540581a2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 10655 | Contributors (this commit): 34 | Commits (past 90d): 11 | Contributors (cumulative): 34 | DMM Complexity: None\n\nDIFF:\n@@ -835,13 +835,15 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n         inputs that match the input shape provided here.\n \n         Args:\n-            input_shape: Shape tuple (tuple of integers)\n-                or list of shape tuples (one per output tensor of the layer).\n+            input_shape: Shape tuple (tuple of integers) or `tf.TensorShape`,\n+                or structure of shape tuples / `tf.TensorShape` instances\n+                (one per output tensor of the layer).\n                 Shape tuples can include None for free dimensions,\n                 instead of an integer.\n \n         Returns:\n-            A shape tuple or `tf.TensorShape` instance\n+            A `tf.TensorShape` instance\n+            or structure of `tf.TensorShape` instances.\n         \"\"\"\n         if tf.executing_eagerly():\n             # In this case we build the model first in order to do shape\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#062073cfc4a5fe4c24ed3e326c673951c040982f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 193 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 6 | Methods Changed: 13 | Complexity Δ (Sum/Max): 15/8 | Churn Δ: 193 | Churn Cumulative: 20024 | Contributors (this commit): 136 | Commits (past 90d): 23 | Contributors (cumulative): 137 | DMM Complexity: 0.7978723404255319\n\nDIFF:\n@@ -1105,6 +1105,16 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n         \"\"\"\n         del x  # The default implementation does not use `x`.\n         self.compiled_metrics.update_state(y, y_pred, sample_weight)\n+        return self._get_metrics_result()\n+\n+    def _get_metrics_result(self):\n+        \"\"\"Returns model metrics as a dict.\n+\n+        Returns:\n+          A `dict` containing values of the metrics listed in `self.metrics`.\n+          Example:\n+          `{'loss': 0.2, 'accuracy': 0.7}`.\n+        \"\"\"\n         # Collect metrics to return\n         return_metrics = {}\n         for metric in self.metrics:\n@@ -1115,6 +1125,50 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n                 return_metrics[metric.name] = result\n         return return_metrics\n \n+    def _validate_and_get_metrics_result(self, logs):\n+        \"\"\"Returns model metrics as a dict if the keys match with input logs.\n+\n+        When the training / evalution is performed with asynchronous steps, such\n+        as the case with `tf.distribute.ParameterServerStrategy`, the last\n+        scheduled `train / test_step` may not give the latest metrics because it\n+        is not guaranteed to be executed the last. This method gets metrics from\n+        the model directly instead of relying on the return from last step\n+        function.\n+\n+        It logs a warning if the metric results could not be overridden when\n+        used with `tf.distribute.ParameterServerStrategy`.\n+\n+        When the user has custom train / test step functions, the metrics\n+        returned may be different from `Model.metrics`. In those instances,\n+        this function will be no-op and return the logs.\n+\n+        Args:\n+          logs: A `dict` of metrics returned by train / test step function.\n+\n+        Returns:\n+          A `dict` containing values of the metrics listed in `self.metrics`\n+          when logs and model metrics keys match. Otherwise it returns input\n+          `logs`.\n+        \"\"\"\n+        PSS_WARN_MSG = \"Could not get Model metric results. \\\n+        Using the results of last step function could lead to incorrect \\\n+        results when used with ParameterServerStrategy\"\n+        try:\n+            metric_logs = self._get_metrics_result()\n+        except TypeError:\n+            if self._cluster_coordinator:\n+                logging.warning(PSS_WARN_MSG)\n+        else:\n+            # Verify that train / test step logs passed and metric logs have\n+            # matching keys. Could be different when using custom step functions\n+            if isinstance(logs, dict) and set(logs.keys()) == set(\n+                metric_logs.keys()\n+            ):\n+                logs = tf_utils.sync_to_numpy_or_python_type(metric_logs)\n+            elif self._cluster_coordinator:\n+                logging.warning(PSS_WARN_MSG)\n+        return logs\n+\n     def make_train_function(self, force=False):\n         \"\"\"Creates a function that executes one step of training.\n \n@@ -1598,6 +1652,8 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n                         \"information of where went wrong, or file a \"\n                         \"issue/bug to `tf.keras`.\"\n                     )\n+                # Override with model metrics instead of last step logs\n+                logs = self._validate_and_get_metrics_result(logs)\n                 epoch_logs = copy.copy(logs)\n \n                 # Run validation.\n@@ -1970,7 +2026,10 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n                             logs = tmp_logs\n                             end_step = step + data_handler.step_increment\n                             callbacks.on_test_batch_end(end_step, logs)\n+\n             logs = tf_utils.sync_to_numpy_or_python_type(logs)\n+            # Override with model metrics instead of last step logs\n+            logs = self._validate_and_get_metrics_result(logs)\n             callbacks.on_test_end(logs=logs)\n \n             if return_dict:\n\n@@ -0,0 +1,134 @@\n+# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Tests training metrics with PSS distribution strategy.\"\"\"\n+\n+import numpy as np\n+import tensorflow.compat.v2 as tf\n+\n+from keras import layers as layers_module\n+from keras import metrics as metrics_module\n+from keras.engine import training as training_module\n+from keras.testing_infra import test_combinations\n+\n+# isort: off\n+from tensorflow.python.distribute import (\n+    multi_process_runner,\n+    multi_worker_test_base,\n+)\n+\n+\n+class ParameterServerTrainingMetricTest(test_combinations.TestCase):\n+    \"\"\"Test Parameter Server Distribution strategy with Keras Model Training\"\"\"\n+\n+    @classmethod\n+    def setUpClass(cls):\n+        super().setUpClass()\n+        cls.cluster = multi_worker_test_base.create_multi_process_cluster(\n+            num_workers=2, num_ps=3, rpc_layer=\"grpc\"\n+        )\n+        cls.cluster_resolver = cls.cluster.cluster_resolver\n+\n+    @classmethod\n+    def tearDownClass(cls):\n+        super().tearDownClass()\n+        cls.cluster.stop()\n+\n+    @test_combinations.run_all_keras_modes(always_skip_v1=True)\n+    def test_pss_fit_metric_batch_counter(self):\n+        \"\"\"Verify that metric data is complete during fit when using\n+        ParameterServerStrategy\n+        \"\"\"\n+        strategy = tf.distribute.ParameterServerStrategy(\n+            self.cluster_resolver,\n+            variable_partitioner=None,\n+        )\n+\n+        class BatchCount(metrics_module.Sum):\n+            def __init__(self, name=\"batch_count\", dtype=tf.int64):\n+                super().__init__(name=name, dtype=dtype)\n+\n+            def update_state(self, y_true, y_pred, sample_weight=None):\n+                return super().update_state(1, sample_weight)\n+\n+        # Build and compile model within strategy scope.\n+        with strategy.scope():\n+            inputs = layers_module.Input((1,))\n+            outputs = layers_module.Dense(1)(inputs)\n+            model = training_module.Model(inputs, outputs)\n+            model.compile(\n+                loss=\"mse\", metrics=[BatchCount()], steps_per_execution=2\n+            )\n+\n+        BATCH_SIZE = 10\n+        x, y = np.ones((400, 1)), np.ones((400, 1))\n+        val_x, val_y = np.ones((100, 1)), np.ones((100, 1))\n+        train_dataset = tf.data.Dataset.from_tensor_slices((x, y))\n+        train_dataset = train_dataset.batch(BATCH_SIZE)\n+        val_dataset = tf.data.Dataset.from_tensor_slices((val_x, val_y))\n+        val_dataset = val_dataset.batch(BATCH_SIZE)\n+        train_batch_count = x.shape[0] // BATCH_SIZE\n+        val_batch_count = val_x.shape[0] // BATCH_SIZE\n+        # Verify that Model fit doesn't drop any batches\n+        hist = model.fit(\n+            train_dataset,\n+            steps_per_epoch=train_batch_count,\n+            validation_data=val_dataset,\n+            validation_steps=val_batch_count,\n+            epochs=5,\n+        )\n+        # Verify that min and max value of batch count metric is accurate\n+        self.assertEqual(max(hist.history[\"batch_count\"]), train_batch_count)\n+        self.assertEqual(min(hist.history[\"batch_count\"]), train_batch_count)\n+        self.assertEqual(max(hist.history[\"val_batch_count\"]), val_batch_count)\n+        self.assertEqual(min(hist.history[\"val_batch_count\"]), val_batch_count)\n+\n+    @test_combinations.run_all_keras_modes(always_skip_v1=True)\n+    def test_pss_evaluate_metric_batch_counter(self):\n+        \"\"\"Verify that metric data is complete during evaluate when using\n+        ParameterServerStrategy\n+        \"\"\"\n+        strategy = tf.distribute.ParameterServerStrategy(\n+            self.cluster_resolver,\n+            variable_partitioner=None,\n+        )\n+\n+        class BatchCount(metrics_module.Sum):\n+            def __init__(self, name=\"batch_count\", dtype=tf.int64):\n+                super().__init__(name=name, dtype=dtype)\n+\n+            def update_state(self, y_true, y_pred, sample_weight=None):\n+                return super().update_state(1, sample_weight)\n+\n+        # Build and compile model within strategy scope.\n+        with strategy.scope():\n+            inputs = layers_module.Input((1,))\n+            outputs = layers_module.Dense(1)(inputs)\n+            model = training_module.Model(inputs, outputs)\n+            model.compile(\n+                loss=\"mse\", metrics=[BatchCount()], steps_per_execution=2\n+            )\n+\n+        BATCH_SIZE = 10\n+        x, y = np.ones((400, 1)), np.ones((400, 1))\n+        dataset = tf.data.Dataset.from_tensor_slices((x, y))\n+        batch_count = x.shape[0] // BATCH_SIZE\n+        # Verify that Model Eval batch counter metric is accurate.\n+        eval_results = model.evaluate(dataset, steps=batch_count)\n+        self.assertEqual(eval_results[-1], batch_count)\n+\n+\n+if __name__ == \"__main__\":\n+    tf.enable_v2_behavior()\n+    multi_process_runner.test_main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#87cf3fe6ae7a20bdef847b3a2db7664d878024ff", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 19898 | Contributors (this commit): 136 | Commits (past 90d): 23 | Contributors (cumulative): 136 | DMM Complexity: None\n\nDIFF:\n@@ -71,9 +71,11 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     \"\"\"`Model` groups layers into an object with training and inference features.\n \n     Args:\n-        inputs: The input(s) of the model: a `keras.Input` object or list of\n-            `keras.Input` objects.\n-        outputs: The output(s) of the model. See Functional API example below.\n+        inputs: The input(s) of the model: a `keras.Input` object or a\n+            combination of `keras.Input` objects in a dict, list or tuple.\n+        outputs: The output(s) of the model: a tensor that originated from\n+            `keras.Input` objects or a combination of such tensors in a dict,\n+            list or tuple. See Functional API example below.\n         name: String, the name of the model.\n \n     There are two ways to instantiate a `Model`:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3ba4d8dadb4db52cf066662f5068e4f99ebd87ee", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 35 | Lines Deleted: 35 | Files Changed: 1 | Hunks: 2 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 70 | Churn Cumulative: 992 | Contributors (this commit): 8 | Commits (past 90d): 21 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -684,6 +684,41 @@ class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):\n         \"\"\"\n         return self._variables\n \n+    def _get_state(self):\n+        \"\"\"Get the state of this optimizer object.\"\"\"\n+        result = {}\n+        for variable in self.variables():\n+            result[variable.name] = variable.numpy()\n+        return result\n+\n+    def _set_state(self, state):\n+        \"\"\"Set the state of this optimizer object.\"\"\"\n+        for variable in self.variables():\n+            variable.assign(state[variable.name])\n+\n+    def _save_state(self, dir_path):\n+        # To avoid circular import\n+        from keras.saving.experimental import saving_lib\n+\n+        file_path = tf.io.gfile.join(dir_path, saving_lib.STATE_FILENAME)\n+        weights = self._get_state()\n+        if weights:\n+            # Only save the state if that of the trackable is available.\n+            np.savez(file_path, **weights)\n+            logging.debug(f\"Saved state to {file_path}\")\n+\n+    def _load_state(self, dir_path):\n+        # To avoid circular import\n+        from keras.saving.experimental import saving_lib\n+\n+        file_path = tf.io.gfile.join(dir_path, saving_lib.STATE_FILENAME)\n+        if tf.io.gfile.exists(file_path):\n+            loaded_npz = np.load(file_path)\n+            logging.debug(f\"Loaded state from {file_path}\")\n+            self._set_state(\n+                {file: loaded_npz[file] for file in loaded_npz.files}\n+            )\n+\n \n base_optimizer_keyword_args = \"\"\"name: String. The name to use\n         for momentum accumulator weights created by\n@@ -1057,41 +1092,6 @@ class Optimizer(_BaseOptimizer):\n                 )\n         return self.iterations.assign_add(1)\n \n-    def _get_state(self):\n-        \"\"\"Get the state of this optimizer object.\"\"\"\n-        result = {}\n-        for variable in self.variables():\n-            result[variable.name] = variable.numpy()\n-        return result\n-\n-    def _set_state(self, state):\n-        \"\"\"Set the state of this optimizer object.\"\"\"\n-        for variable in self.variables():\n-            variable.assign(state[variable.name])\n-\n-    def _save_state(self, dir_path):\n-        # To avoid circular import\n-        from keras.saving.experimental import saving_lib\n-\n-        file_path = tf.io.gfile.join(dir_path, saving_lib.STATE_FILENAME)\n-        weights = self._get_state()\n-        if weights:\n-            # Only save the state if that of the trackable is available.\n-            np.savez(file_path, **weights)\n-            logging.debug(f\"Saved state to {file_path}\")\n-\n-    def _load_state(self, dir_path):\n-        # To avoid circular import\n-        from keras.saving.experimental import saving_lib\n-\n-        file_path = tf.io.gfile.join(dir_path, saving_lib.STATE_FILENAME)\n-        if tf.io.gfile.exists(file_path):\n-            loaded_npz = np.load(file_path)\n-            logging.debug(f\"Loaded state from {file_path}\")\n-            self._set_state(\n-                {file: loaded_npz[file] for file in loaded_npz.files}\n-            )\n-\n \n class RestoredOptimizer(Optimizer):\n     def __init__(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a116637f53c8bf191f4f51853f3ee58d2ec858d9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 21/21 | Churn Δ: 3 | Churn Cumulative: 10658 | Contributors (this commit): 34 | Commits (past 90d): 11 | Contributors (cumulative): 34 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1080,8 +1080,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n             call_fn = traceback_utils.inject_argument_info_in_traceback(\n                 call_fn,\n                 object_name=(\n-                    f'layer \"{self.name}\" \"                 f\"(type'\n-                    f\" {self.__class__.__name__})\"\n+                    f\"layer '{self.name}' (type {self.__class__.__name__})\"\n                 ),\n             )\n             with contextlib.ExitStack() as namescope_stack:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#10457f5664b8153e4a8df7ffd0e6f8c717494e91", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 10670 | Contributors (this commit): 34 | Commits (past 90d): 11 | Contributors (cumulative): 34 | DMM Complexity: None\n\nDIFF:\n@@ -145,6 +145,11 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n     * in the first invocation of `call()`, with some caveats discussed\n       below.\n \n+    Layers are recursively composable: If you assign a Layer instance as an\n+    attribute of another Layer, the outer layer will start tracking the weights\n+    created by the inner layer. Nested layers should be instantiated in the\n+    `__init__()` method.\n+\n     Users will just instantiate a layer and then treat it as a callable.\n \n     Args:\n@@ -502,9 +507,10 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n \n         The `call()` method may not create state (except in its first\n         invocation, wrapping the creation of variables or other resources in\n-        `tf.init_scope()`).  It is recommended to create state in `__init__()`,\n-        or the `build()` method that is called automatically before `call()`\n-        executes the first time.\n+        `tf.init_scope()`).  It is recommended to create state, including\n+        `tf.Variable` instances and nested `Layer` instances,\n+         in `__init__()`, or in the `build()` method that is\n+        called automatically before `call()` executes for the first time.\n \n         Args:\n           inputs: Input tensor, or dict/list/tuple of input tensors.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#86ed065f3b5cc86fcc8910fe7abf0ab3a1f422a9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 35 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 5 | Methods Changed: 4 | Complexity Δ (Sum/Max): 4/2 | Churn Δ: 37 | Churn Cumulative: 1571 | Contributors (this commit): 9 | Commits (past 90d): 41 | Contributors (cumulative): 14 | DMM Complexity: 0.19047619047619047\n\nDIFF:\n@@ -222,7 +222,10 @@ class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):\n           loss: `Tensor` or callable. If a callable, `loss` should take no\n             arguments and return the value to minimize.\n           var_list: list or tuple of `Variable` objects to update to minimize\n-            `loss`.\n+            `loss`, or a callable returning the list or tuple of `Variable`\n+            objects. Use callable when the variable list would otherwise be\n+            incomplete before `minimize` since the variables are created at the\n+            first time `loss` is called.\n           tape: (Optional) `tf.GradientTape`. If `loss` is provided as a\n             `Tensor`, the tape that computed the `loss` must be provided.\n \n@@ -239,8 +242,12 @@ class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):\n             tape = tf.GradientTape()\n         if callable(loss):\n             with tape:\n+                if not callable(var_list):\n                     tape.watch(var_list)\n                 loss = loss()\n+                if callable(var_list):\n+                    var_list = var_list()\n+\n         grads = tape.gradient(loss, var_list)\n         return list(zip(grads, var_list))\n \n@@ -490,7 +497,10 @@ class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):\n           loss: `Tensor` or callable. If a callable, `loss` should take no\n             arguments and return the value to minimize.\n           var_list: list or tuple of `Variable` objects to update to minimize\n-            `loss`.\n+            `loss`, or a callable returning the list or tuple of `Variable`\n+            objects.  Use callable when the variable list would otherwise be\n+            incomplete before `minimize` since the variables are created at the\n+            first time `loss` is called.\n           tape: (Optional) `tf.GradientTape`.\n \n         Returns:\n\n@@ -115,6 +115,29 @@ class OptimizerFuntionalityTest(tf.test.TestCase, parameterized.TestCase):\n             optimizer._index_dict[optimizer._var_key(var_list[7])], 7\n         )\n \n+    def testComputeGradients(self):\n+        optimizer = adam_new.Adam()\n+        x = tf.Variable([1.0, 2.0], dtype=tf.float32)\n+        loss_fn = lambda: x\n+        # Test Tensor-type var_list.\n+        var_list = [x]\n+        grads_and_vars = optimizer.compute_gradients(loss_fn, var_list)\n+        grads, _ = zip(*grads_and_vars)\n+        self.assertAllEqual(grads[0], tf.constant([1.0, 1.0]))\n+        # Test callable-type var_list, and create variable in loss fn.\n+        x = []\n+\n+        def loss_fn():\n+            variable = tf.Variable([1.0, 2.0], dtype=tf.float32)\n+            x.append(variable)\n+            return variable\n+\n+        var_list = lambda: x\n+\n+        grads_and_vars = optimizer.compute_gradients(loss_fn, var_list)\n+        grads, _ = zip(*grads_and_vars)\n+        self.assertAllEqual(grads[0], tf.constant([1.0, 1.0]))\n+\n     def testClipNorm(self):\n         optimizer = adam_new.Adam(clipnorm=1)\n         grad = [tf.convert_to_tensor([100.0, 100.0])]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6c642d048a298bc976bd99af1177b7d7e28617bd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 526 | Contributors (this commit): 11 | Commits (past 90d): 7 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -151,11 +151,10 @@ class MultiHeadAttention(Layer):\n     Finally, the result tensor with the last dimension as value_dim can take an\n     linear projection and return.\n \n-    When using MultiHeadAttention inside a custom Layer, the custom Layer must\n-    implement `build()` and call MultiHeadAttention's `_build_from_signature()`.\n+    When using `MultiHeadAttention` inside a custom layer, the custom layer must\n+    implement its own `build()` method and call `MultiHeadAttention`'s\n+    `_build_from_signature()` there.\n     This enables weights to be restored correctly when the model is loaded.\n-    TODO(b/172609172): link to documentation about calling custom build\n-    functions when used in a custom Layer.\n \n     Examples:\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#15d7257fe1aeb184c725c4a70766d853271f94cf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 11 | Files Changed: 1 | Hunks: 10 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 22 | Churn Cumulative: 1003 | Contributors (this commit): 11 | Commits (past 90d): 7 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -105,14 +105,14 @@ class OptimizerV2(tf.__internal__.tracking.Trackable):\n     \"\"\"Base class for Keras optimizers.\n \n     You should not use this class directly, but instead instantiate one of its\n-    subclasses such as `tf.keras.optimizers.SGD`, `tf.keras.optimizers.Adam`,\n-    etc.\n+    subclasses such as `tf.keras.optimizers.legacy.SGD`,\n+    `tf.keras.optimizers.legacy.Adam`, etc.\n \n     ### Usage\n \n     ```python\n     # Create an optimizer with the desired parameters.\n-    opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n+    opt = tf.keras.optimizers.legacy.SGD(learning_rate=0.1)\n     # `loss` is a callable that takes no argument and returns the value\n     # to minimize.\n     var1 = tf.Variable(2.0)\n@@ -136,7 +136,7 @@ class OptimizerV2(tf.__internal__.tracking.Trackable):\n     Example:\n \n     ```python\n-    opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n+    opt = tf.keras.optimizers.legacy.SGD(learning_rate=0.1)\n     model = tf.keras.Sequential()\n     model.add(tf.keras.layers.Dense(num_hidden, activation='relu'))\n     model.add(tf.keras.layers.Dense(num_classes, activation='sigmoid'))\n@@ -160,7 +160,7 @@ class OptimizerV2(tf.__internal__.tracking.Trackable):\n \n     ```python\n     # Create an optimizer.\n-    opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n+    opt = tf.keras.optimizers.legacy.SGD(learning_rate=0.1)\n \n     # Compute the gradients for a list of variables.\n     with tf.GradientTape() as tape:\n@@ -236,7 +236,7 @@ class OptimizerV2(tf.__internal__.tracking.Trackable):\n \n     ```python\n     # Create an optimizer with the desired parameters.\n-    opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n+    opt = tf.keras.optimizers.legacy.SGD(learning_rate=0.1)\n     # `loss` is a callable that takes no argument and returns the value\n     # to minimize.\n     loss = lambda: 3 * var1 + 2 * var2\n@@ -260,7 +260,7 @@ class OptimizerV2(tf.__internal__.tracking.Trackable):\n     >>> var = tf.Variable(np.random.random(size=(1,)))\n     >>> learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(\n     ... initial_learning_rate=.01, decay_steps=20, decay_rate=.1)\n-    >>> opt = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n+    >>> opt = tf.keras.optimizers.legacy.SGD(learning_rate=learning_rate)\n     >>> loss = lambda: 3 * var\n     >>> opt.minimize(loss, var_list=[var])\n     <tf.Variable...\n@@ -273,7 +273,7 @@ class OptimizerV2(tf.__internal__.tracking.Trackable):\n     >>> var = tf.Variable(np.random.random(size=(1,)))\n     >>> def lr_callable():\n     ...   return .1\n-    >>> opt = tf.keras.optimizers.SGD(learning_rate=lr_callable)\n+    >>> opt = tf.keras.optimizers.legacy.SGD(learning_rate=lr_callable)\n     >>> loss = lambda: 3 * var\n     >>> opt.minimize(loss, var_list=[var])\n     <tf.Variable...\n@@ -327,7 +327,7 @@ class OptimizerV2(tf.__internal__.tracking.Trackable):\n           # Simple example, double the gradients.\n           return [(2. * g, v) for g, v in grads_and_vars]\n \n-        optimizer = tf.keras.optimizers.SGD(\n+        optimizer = tf.keras.optimizers.legacy.SGD(\n             1e-3, gradient_transformers=[my_gradient_transformer])\n         ```\n \n@@ -1252,7 +1252,7 @@ class OptimizerV2(tf.__internal__.tracking.Trackable):\n         of three values-- the iteration count, followed by the root-mean-square\n         value of the kernel and bias of the single Dense layer:\n \n-        >>> opt = tf.keras.optimizers.RMSprop()\n+        >>> opt = tf.keras.optimizers.legacy.RMSprop()\n         >>> m = tf.keras.models.Sequential([tf.keras.layers.Dense(10)])\n         >>> m.compile(opt, loss='mse')\n         >>> data = np.arange(100).reshape(5, 20)\n@@ -1282,7 +1282,7 @@ class OptimizerV2(tf.__internal__.tracking.Trackable):\n         three values-- the iteration count, followed by the root-mean-square\n         value of the kernel and bias of the single Dense layer:\n \n-        >>> opt = tf.keras.optimizers.RMSprop()\n+        >>> opt = tf.keras.optimizers.legacy.RMSprop()\n         >>> m = tf.keras.models.Sequential([tf.keras.layers.Dense(10)])\n         >>> m.compile(opt, loss='mse')\n         >>> data = np.arange(100).reshape(5, 20)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#32b15912a216a5517e751c810e3f172c3b8f6be2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 131 | Contributors (this commit): 5 | Commits (past 90d): 1 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -158,7 +158,7 @@ class RMSprop(optimizer.Optimizer):\n                 average_grad.assign(rho * average_grad)\n                 average_grad.scatter_add(\n                     tf.IndexedSlices(\n-                        tf.square(gradient.values) * (1 - rho), gradient.indices\n+                        gradient.values * (1 - rho), gradient.indices\n                     )\n                 )\n                 velocity.assign_add(-tf.square(average_grad))\n@@ -182,9 +182,7 @@ class RMSprop(optimizer.Optimizer):\n             # Dense gradients.\n             velocity.assign(rho * velocity + (1 - rho) * tf.square(gradient))\n             if self.centered:\n-                average_grad.assign(\n-                    rho * average_grad + (1 - rho) * tf.square(gradient)\n-                )\n+                average_grad.assign(rho * average_grad + (1 - rho) * gradient)\n                 velocity.assign_add(-tf.square(average_grad))\n             transformed_grad = gradient / (tf.sqrt(velocity) + self.epsilon)\n             if self.momentum > 0:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0d426ebe561405cb88a0ae5ad13f6ac59342b4b9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 10777 | Contributors (this commit): 22 | Commits (past 90d): 12 | Contributors (cumulative): 22 | DMM Complexity: None\n\nDIFF:\n@@ -1823,7 +1823,7 @@ _USE_GENERATOR_FOR_RNG = False\n # way, so that each client of the program could start with same seed. This is\n # very important for certain use case that requires all the client to have their\n # state in sync. This instance will be set when user call\n-# `tf.keras.util.set_random_seed()`\n+# `tf.keras.utils.set_random_seed()`\n _SEED_GENERATOR = threading.local()\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1d68a60bcf39a433186797f8ad6f25ecf72cc7ca", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 108 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 3 | Complexity Δ (Sum/Max): 9/5 | Churn Δ: 108 | Churn Cumulative: 1325 | Contributors (this commit): 12 | Commits (past 90d): 12 | Contributors (cumulative): 20 | DMM Complexity: 1.0\n\nDIFF:\n@@ -696,3 +696,31 @@ class MultiHeadAttention(Layer):\n         return tf.linalg.band_part(  # creates a lower triangular matrix\n             tf.ones((1, q_seq_length, v_seq_length), tf.bool), -1, 0\n         )\n+\n+    def compute_output_shape(self, query_shape, value_shape, key_shape=None):\n+\n+        if key_shape is None:\n+            key_shape = value_shape\n+\n+        query_shape = tf.TensorShape(query_shape)\n+        value_shape = tf.TensorShape(value_shape)\n+        key_shape = tf.TensorShape(key_shape)\n+\n+        if query_shape[-1] != value_shape[-1]:\n+            raise ValueError(\n+                \"The last dimension of `query_shape` and `value_shape` \"\n+                f\"must be equal, but are {query_shape[-1]}, {value_shape[-1]}. \"\n+                \"Received: query_shape={query_shape}, value_shape={value_shape}\"\n+            )\n+\n+        if value_shape[1:-1] != key_shape[1:-1]:\n+            raise ValueError(\n+                \"All dimensions of `value` and `key`, except the last one, \"\n+                f\"must be equal. Received {value_shape} and \"\n+                f\"{key_shape}\"\n+            )\n+\n+        if self._output_shape:\n+            return query_shape[:-1].concatenate(self._output_shape)\n+\n+        return query_shape\n\n@@ -391,6 +391,86 @@ class MultiHeadAttentionTest(test_combinations.TestCase):\n             attention_mask=float_mask,\n         )\n \n+    @parameterized.named_parameters(\n+        (\"without_key_same_proj\", [40, 80], [20, 80], None, None),\n+        (\"with_key_same_proj\", [40, 80], [20, 80], [20, 30], None),\n+        (\"wihtout_key_different_proj\", [40, 80], [20, 80], None, [30, 40]),\n+        (\"with_key_different_proj\", [40, 80], [20, 80], [20, 30], [15, 50]),\n+        (\n+            \"high_dim_same_proj\",\n+            [40, 20, 30, 80],\n+            [10, 10, 50, 80],\n+            [10, 10, 50, 20],\n+            None,\n+        ),\n+        (\n+            \"high_dim_different_proj\",\n+            [40, 20, 30, 80],\n+            [10, 10, 50, 80],\n+            [10, 10, 50, 20],\n+            [30, 20],\n+        ),\n+    )\n+    def test_compute_output_shape(\n+        self, query_dims, value_dims, key_dims, output_shape\n+    ):\n+        \"\"\"Test computed shape is equal to the layer output's shape.\"\"\"\n+        test_layer = keras.layers.MultiHeadAttention(\n+            num_heads=2,\n+            key_dim=2,\n+            value_dim=2,\n+            output_shape=output_shape,\n+        )\n+        batch_size = None\n+        query_shape = [batch_size] + query_dims\n+        value_shape = [batch_size] + value_dims\n+\n+        if key_dims:\n+            key_shape = [batch_size] + key_dims\n+        else:\n+            key_shape = None\n+\n+        query = keras.Input(query_shape[1:])\n+        value = keras.Input(value_shape[1:])\n+        if key_shape:\n+            key = keras.Input(key_shape[1:])\n+        else:\n+            key = None\n+        output = test_layer(query=query, value=value, key=key)\n+        comp_output_shape = test_layer.compute_output_shape(\n+            query_shape, value_shape, key_shape\n+        )\n+        self.assertListEqual(\n+            output.shape.as_list(), comp_output_shape.as_list()\n+        )\n+\n+    @parameterized.named_parameters(\n+        (\"query_value_dim_mismatch\", (None, 40, 80), (None, 20, 70), None),\n+        (\n+            \"key_value_dim_mismatch\",\n+            (None, 40, 80),\n+            (None, 20, 80),\n+            (None, 10, 70),\n+        ),\n+        (\n+            \"key_value_dim_mismatch_high_dim\",\n+            (None, 40, 20, 30, 80),\n+            (None, 10, 10, 50, 80),\n+            (None, 10, 15, 50, 20),\n+        ),\n+    )\n+    def test_compute_output_shape_raises_error(\n+        self, query_shape, value_shape, key_shape\n+    ):\n+        \"\"\"Test dimension mismatches\"\"\"\n+        test_layer = keras.layers.MultiHeadAttention(\n+            num_heads=4,\n+            key_dim=2,\n+            value_dim=2,\n+        )\n+        with self.assertRaisesRegex(ValueError, r\"must be equal\"):\n+            test_layer.compute_output_shape(query_shape, value_shape, key_shape)\n+\n \n class SubclassAttention(keras.layers.MultiHeadAttention):\n     def _build_attention(self, qkv_rank):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b7b72ce451b5d433ff072f499c7a60f109bd06f4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 51 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 4 | Methods Changed: 7 | Complexity Δ (Sum/Max): 9/6 | Churn Δ: 51 | Churn Cumulative: 14415 | Contributors (this commit): 35 | Commits (past 90d): 14 | Contributors (cumulative): 49 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1266,6 +1266,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n         Returns:\n           A list of trainable variables.\n         \"\"\"\n+        self._update_trackables()\n         if self.trainable:\n             children_weights = self._gather_children_attribute(\n                 \"trainable_variables\"\n@@ -1286,6 +1287,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n         Returns:\n           A list of non-trainable variables.\n         \"\"\"\n+        self._update_trackables()\n         if self.trainable:\n             children_weights = self._gather_children_attribute(\n                 \"non_trainable_variables\"\n@@ -3145,6 +3147,16 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n             name, value\n         )\n \n+    def _update_trackables(self):\n+        \"\"\"Track variables added to lists/dicts after creation\n+        \"\"\"\n+        for trackable_obj in self._self_tracked_trackables:\n+            if isinstance(\n+                    trackable_obj,\n+                    tf.__internal__.tracking.TrackableDataStructure\n+            ):\n+                self._track_variables(trackable_obj)\n+\n     def _track_variables(self, value):\n         \"\"\"Tracks `Variable`s including `Variable`s in `CompositeTensor`s.\"\"\"\n         for val in tf.nest.flatten(value):\n\n@@ -1037,6 +1037,45 @@ class BaseLayerTest(test_combinations.TestCase):\n         self.assertLen(model.trainable_variables, 0)\n         self.assertLen(model.non_trainable_variables, 2)\n \n+    def test_tf_tracking_lists(self):\n+        class MyLayer(base_layer.Layer):\n+\n+            def __init__(self, num_weights):\n+                super().__init__()\n+                self.num_weights = num_weights\n+\n+            def build(self, input_shape):\n+                super().build(input_shape)\n+                self.my_weights = []\n+                w_init = tf.random_normal_initializer()\n+                for i in range(self.num_weights):\n+                    self.my_weights.append(\n+                        tf.Variable(\n+                            name=f'w_{i}',\n+                            initial_value=w_init(\n+                                shape=(input_shape[1], input_shape[1]),\n+                                dtype=\"float32\"\n+                            ),\n+                            trainable=True\n+                        )\n+                    )\n+\n+            def call(self, x):\n+                for w in self.my_weights:\n+                    x = tf.matmul(x, w)\n+                return x\n+\n+        layer = MyLayer(3)\n+        layer(tf.constant([[1.0, 1.0, 1.0, 1.0]]))\n+        self.assertLen(layer.variables, 3)\n+        self.assertLen(layer.trainable_variables, 3)\n+        self.assertLen(layer.non_trainable_variables, 0)\n+\n+        layer.trainable = False\n+        self.assertLen(layer.variables, 3)\n+        self.assertLen(layer.trainable_variables, 0)\n+        self.assertLen(layer.non_trainable_variables, 3)\n+\n \n @test_utils.run_v2_only\n class SymbolicSupportTest(test_combinations.TestCase):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#00524152437b957ca4e850a5db014e223d3c6826", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 8 | Files Changed: 2 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 13 | Churn Cumulative: 14428 | Contributors (this commit): 35 | Commits (past 90d): 16 | Contributors (cumulative): 49 | DMM Complexity: 0.0\n\nDIFF:\n@@ -3148,12 +3148,10 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n         )\n \n     def _update_trackables(self):\n-        \"\"\"Track variables added to lists/dicts after creation\n-        \"\"\"\n+        \"\"\"Track variables added to lists/dicts after creation\"\"\"\n         for trackable_obj in self._self_tracked_trackables:\n             if isinstance(\n-                    trackable_obj,\n-                    tf.__internal__.tracking.TrackableDataStructure\n+                trackable_obj, tf.__internal__.tracking.TrackableDataStructure\n             ):\n                 self._track_variables(trackable_obj)\n \n\n@@ -1039,7 +1039,6 @@ class BaseLayerTest(test_combinations.TestCase):\n \n     def test_tf_tracking_lists(self):\n         class MyLayer(base_layer.Layer):\n-\n             def __init__(self, num_weights):\n                 super().__init__()\n                 self.num_weights = num_weights\n@@ -1051,12 +1050,12 @@ class BaseLayerTest(test_combinations.TestCase):\n                 for i in range(self.num_weights):\n                     self.my_weights.append(\n                         tf.Variable(\n-                            name=f'w_{i}',\n+                            name=f\"w_{i}\",\n                             initial_value=w_init(\n                                 shape=(input_shape[1], input_shape[1]),\n-                                dtype=\"float32\"\n+                                dtype=\"float32\",\n                             ),\n-                            trainable=True\n+                            trainable=True,\n                         )\n                     )\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#919626d70912fcc9eb933bb8d1221d7eb96d1260", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 14 | Churn Cumulative: 1020 | Contributors (this commit): 8 | Commits (past 90d): 23 | Contributors (cumulative): 8 | DMM Complexity: 0.0\n\nDIFF:\n@@ -542,11 +542,11 @@ class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):\n                     dtype=current_learning_rate.dtype,\n                     trainable=False,\n                 )\n-        grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)\n-        if len(list(grads_and_vars)) == 0:\n+        grads_and_vars = list(grads_and_vars)\n+        if len(grads_and_vars) == 0:\n             # It is possible that the grad is empty. In this case,\n             # `apply_gradients` is a no-op.\n-            return\n+            return self._iterations\n         grads, trainable_variables = zip(*grads_and_vars)\n         scope_name = name or self.name or \"optimizer\"\n         with tf.name_scope(scope_name):\n@@ -554,6 +554,14 @@ class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):\n                 # Lift variable creation to init scope to avoid environment\n                 # issues.\n                 self.build(trainable_variables)\n+        grads_and_vars = list(zip(grads, trainable_variables))\n+        grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)\n+        if len(list(grads_and_vars)) == 0:\n+            # Check again after filtering gradients.\n+            return self._iterations\n+\n+        grads, trainable_variables = zip(*grads_and_vars)\n+\n         grads = self._clip_gradients(grads)\n         grads = self._deduplicate_sparse_grad(grads)\n         grads_and_vars = list(zip(grads, trainable_variables))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
