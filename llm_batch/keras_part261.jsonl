{"custom_id": "keras#1a2290ae91a944416ef8eb517e97b21733c9681e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 57 | Lines Deleted: 37 | Files Changed: 2 | Hunks: 16 | Methods Changed: 6 | Complexity Δ (Sum/Max): 5/3 | Churn Δ: 94 | Churn Cumulative: 4921 | Contributors (this commit): 29 | Commits (past 90d): 14 | Contributors (cumulative): 31 | DMM Complexity: 1.0\n\nDIFF:\n@@ -12,6 +12,7 @@ import reference_operations as KNP\n \n \n BACKENDS = []  # Holds a list of all available back-ends\n+WITH_NP = [K, KNP]\n \n try:\n     from keras.backend import cntk_backend as KC\n@@ -282,7 +283,7 @@ class TestBackend(object):\n         check_two_tensor_operation('concatenate', (4, 3), (4, 2), BACKENDS,\n                                    axis=-1, concat_args=True)\n \n-        check_single_tensor_operation('reshape', (4, 2), BACKENDS, shape=(8, 1))\n+        check_single_tensor_operation('reshape', (4, 2), WITH_NP, shape=(8, 1))\n         check_single_tensor_operation('permute_dimensions', (4, 2, 3), BACKENDS,\n                                       pattern=(2, 0, 1))\n         check_single_tensor_operation('repeat', (4, 1), BACKENDS, n=3)\n@@ -387,55 +388,47 @@ class TestBackend(object):\n         check_single_tensor_operation('print_tensor', (1, 2, 3), BACKENDS)\n \n     def test_elementwise_operations(self):\n-        check_single_tensor_operation('max', (4, 2), BACKENDS)\n-        check_single_tensor_operation('max', (4, 2), BACKENDS, axis=1, keepdims=True)\n+        check_single_tensor_operation('max', (4, 2), WITH_NP)\n+        check_single_tensor_operation('max', (4, 2), WITH_NP, axis=1, keepdims=True)\n \n-        check_single_tensor_operation('min', (4, 2), BACKENDS)\n-        check_single_tensor_operation('min', (4, 2), BACKENDS, axis=1, keepdims=True)\n-        check_single_tensor_operation('min', (4, 2, 3), BACKENDS, axis=[1, -1])\n+        check_single_tensor_operation('min', (4, 2), WITH_NP)\n+        check_single_tensor_operation('min', (4, 2), WITH_NP, axis=1, keepdims=True)\n+        check_single_tensor_operation('min', (4, 2, 3), WITH_NP, axis=[1, -1])\n \n-        check_single_tensor_operation('mean', (4, 2), BACKENDS)\n-        check_single_tensor_operation('mean', (4, 2), BACKENDS, axis=1, keepdims=True)\n-        check_single_tensor_operation('mean', (4, 2, 3), BACKENDS, axis=-1, keepdims=True)\n-        check_single_tensor_operation('mean', (4, 2, 3), BACKENDS, axis=[1, -1])\n+        check_single_tensor_operation('mean', (4, 2), WITH_NP)\n+        check_single_tensor_operation('mean', (4, 2), WITH_NP, axis=1, keepdims=True)\n+        check_single_tensor_operation('mean', (4, 2, 3), WITH_NP, axis=-1, keepdims=True)\n+        check_single_tensor_operation('mean', (4, 2, 3), WITH_NP, axis=[1, -1])\n \n-        check_single_tensor_operation('std', (4, 2), BACKENDS)\n-        check_single_tensor_operation('std', (4, 2), BACKENDS, axis=1, keepdims=True)\n+        check_single_tensor_operation('std', (4, 2), WITH_NP)\n+        check_single_tensor_operation('std', (4, 2), WITH_NP, axis=1, keepdims=True)\n         # check_single_tensor_operation('std', (4, 2, 3), BACKENDS, axis=[1, -1])\n \n-        check_single_tensor_operation('prod', (4, 2), BACKENDS)\n-        check_single_tensor_operation('prod', (4, 2), BACKENDS, axis=1, keepdims=True)\n-        check_single_tensor_operation('prod', (4, 2, 3), BACKENDS, axis=[1, -1])\n+        check_single_tensor_operation('prod', (4, 2), WITH_NP)\n+        check_single_tensor_operation('prod', (4, 2), WITH_NP, axis=1, keepdims=True)\n+        check_single_tensor_operation('prod', (4, 2, 3), WITH_NP, axis=[1, -1])\n \n-        # cntk does not support cumsum and cumprod yet\n-        check_single_tensor_operation('cumsum', (4, 2), [KTF, KTH])\n-        check_single_tensor_operation('cumsum', (4, 2), [KTF, KTH], axis=1)\n+        check_single_tensor_operation('any', (4, 2), WITH_NP)\n+        check_single_tensor_operation('any', (4, 2), WITH_NP, axis=1, keepdims=True)\n \n-        check_single_tensor_operation('cumprod', (4, 2), [KTF, KTH])\n-        check_single_tensor_operation('cumprod', (4, 2), [KTF, KTH], axis=1)\n+        check_single_tensor_operation('all', (4, 2), WITH_NP)\n+        check_single_tensor_operation('all', (4, 2), WITH_NP, axis=1, keepdims=True)\n \n-        check_single_tensor_operation('any', (4, 2), BACKENDS)\n-        check_single_tensor_operation('any', (4, 2), BACKENDS, axis=1, keepdims=True)\n+        check_single_tensor_operation('argmax', (4, 2), WITH_NP)\n+        check_single_tensor_operation('argmax', (4, 2), WITH_NP, axis=1)\n \n-        check_single_tensor_operation('all', (4, 2), BACKENDS)\n-        check_single_tensor_operation('all', (4, 2), BACKENDS, axis=1, keepdims=True)\n+        check_single_tensor_operation('argmin', (4, 2), WITH_NP)\n+        check_single_tensor_operation('argmin', (4, 2), WITH_NP, axis=1)\n \n-        check_single_tensor_operation('argmax', (4, 2), BACKENDS)\n-        check_single_tensor_operation('argmax', (4, 2), BACKENDS, axis=1)\n-\n-        check_single_tensor_operation('argmin', (4, 2), BACKENDS)\n-        check_single_tensor_operation('argmin', (4, 2), BACKENDS, axis=1)\n-\n-        check_single_tensor_operation('square', (4, 2), BACKENDS)\n-        check_single_tensor_operation('abs', (4, 2), BACKENDS)\n-        check_single_tensor_operation('sqrt', (4, 2), BACKENDS)\n+        check_single_tensor_operation('square', (4, 2), WITH_NP)\n+        check_single_tensor_operation('abs', (4, 2), WITH_NP)\n+        check_single_tensor_operation('sqrt', (4, 2), WITH_NP)\n         check_single_tensor_operation('exp', (4, 2), BACKENDS)\n-        # cntk return -85.1 for zero or negative number, not nan, so can't compare with other backend.\n-        check_single_tensor_operation('log', (4, 2), [KTH, KTF])\n+\n         check_single_tensor_operation('round', (4, 2), BACKENDS)\n         check_single_tensor_operation('sign', (4, 2), BACKENDS)\n-        check_single_tensor_operation('pow', (4, 2), BACKENDS, a=3)\n-        check_single_tensor_operation('clip', (4, 2), BACKENDS, min_value=0.4,\n+        check_single_tensor_operation('pow', (4, 2), WITH_NP, a=3)\n+        check_single_tensor_operation('clip', (4, 2), WITH_NP, min_value=0.4,\n                                       max_value=0.6)\n \n         # two-tensor ops\n@@ -448,6 +441,22 @@ class TestBackend(object):\n         check_two_tensor_operation('maximum', (4, 2), (4, 2), BACKENDS)\n         check_two_tensor_operation('minimum', (4, 2), (4, 2), BACKENDS)\n \n+    @pytest.mark.skipif(K.backend() == 'cntk', reason='cntk does not support '\n+                                                      'cumsum and cumprod yet')\n+    def test_cumsum_cumprod(self):\n+        check_single_tensor_operation('cumsum', (4, 2), WITH_NP)\n+        check_single_tensor_operation('cumsum', (4, 2), WITH_NP, axis=1)\n+\n+        check_single_tensor_operation('cumprod', (4, 2), WITH_NP)\n+        check_single_tensor_operation('cumprod', (4, 2), WITH_NP, axis=1)\n+\n+    @pytest.mark.skipif(K.backend() == 'cntk',\n+                        reason='cntk return -85.1 for zero or '\n+                               'negative number, not nan, so can\\'t '\n+                               'compare with other backend.')\n+    def test_log(self):\n+        check_single_tensor_operation('log', (4, 2), WITH_NP)\n+\n     # cntk doesn't support gradient in this way\n     def test_gradient(self):\n         val = np.random.random((4, 2))\n\n@@ -300,6 +300,17 @@ def clip(x, min_value, max_value):\n     return np.clip(x, min_value, max_value)\n \n \n+def reshape(x, shape):\n+    return np.reshape(x, shape)\n+\n+\n+def variable(value, dtype=None, name=None, constraint=None):\n+    if constraint is not None:\n+        raise TypeError(\"Constraint must be None when \"\n+                        \"using the NumPy backend.\")\n+    return np.array(value, dtype)\n+\n+\n square = np.square\n abs = np.abs\n exp = np.exp\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#09a984bb256e0c28ef03eb8128bdcc851b3604ec", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 2 | Churn Cumulative: 1228 | Contributors (this commit): 15 | Commits (past 90d): 8 | Contributors (cumulative): 15 | DMM Complexity: 0.0\n\nDIFF:\n@@ -689,7 +689,9 @@ def test_zero_padding_2d():\n     input_num_row = 4\n     input_num_col = 5\n     for data_format in ['channels_first', 'channels_last']:\n+        if data_format == 'channels_last':\n             inputs = np.ones((num_samples, input_num_row, input_num_col, stack_size))\n+        else:\n             inputs = np.ones((num_samples, stack_size, input_num_row, input_num_col))\n \n         # basic test\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#96c3c195ca805758e094780b59077bea9db99f41", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 140 | Lines Deleted: 66 | Files Changed: 12 | Hunks: 52 | Methods Changed: 16 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 206 | Churn Cumulative: 5492 | Contributors (this commit): 49 | Commits (past 90d): 12 | Contributors (cumulative): 100 | DMM Complexity: 0.7346938775510204\n\nDIFF:\n@@ -129,8 +129,11 @@ stitched_filters = np.zeros((width, height, 3))\n for i in range(n):\n     for j in range(n):\n         img, loss = kept_filters[i * n + j]\n-        stitched_filters[(img_width + margin) * i: (img_width + margin) * i + img_width,\n-                         (img_height + margin) * j: (img_height + margin) * j + img_height, :] = img\n+        width_margin = (img_width + margin) * i\n+        height_margin = (img_height + margin) * j\n+        stitched_filters[\n+            width_margin: width_margin + img_width,\n+            height_margin: height_margin + img_height, :] = img\n \n # save the result to disk\n save_img('stitched_filters_%dx%d.png' % (n, n), stitched_filters)\n\n@@ -83,7 +83,8 @@ layer_dict = dict([(layer.name, layer) for layer in model.layers])\n loss = K.variable(0.)\n for layer_name in settings['features']:\n     # Add the L2 norm of the features of a layer to the loss.\n-    assert layer_name in layer_dict.keys(), 'Layer ' + layer_name + ' not found in model.'\n+    assert (layer_name in layer_dict.keys(),\n+            'Layer ' + layer_name + ' not found in model.')\n     coeff = settings['features'][layer_name]\n     x = layer_dict[layer_name].output\n     # We avoid border artifacts by only involving non-border pixels in the loss.\n\n@@ -88,16 +88,23 @@ def paint_text(text, w, h, rotate=False, ud=False, multi_fonts=False):\n         context.paint()\n         # this font list works in CentOS 7\n         if multi_fonts:\n-            fonts = ['Century Schoolbook', 'Courier', 'STIX', 'URW Chancery L', 'FreeMono']\n-            context.select_font_face(np.random.choice(fonts), cairo.FONT_SLANT_NORMAL,\n+            fonts = [\n+                'Century Schoolbook', 'Courier', 'STIX',\n+                'URW Chancery L', 'FreeMono']\n+            context.select_font_face(\n+                np.random.choice(fonts),\n+                cairo.FONT_SLANT_NORMAL,\n                 np.random.choice([cairo.FONT_WEIGHT_BOLD, cairo.FONT_WEIGHT_NORMAL]))\n         else:\n-            context.select_font_face('Courier', cairo.FONT_SLANT_NORMAL, cairo.FONT_WEIGHT_BOLD)\n+            context.select_font_face('Courier',\n+                                     cairo.FONT_SLANT_NORMAL,\n+                                     cairo.FONT_WEIGHT_BOLD)\n         context.set_font_size(25)\n         box = context.text_extents(text)\n         border_w_h = (4, 4)\n         if box[2] > (w - 2 * border_w_h[1]) or box[3] > (h - 2 * border_w_h[0]):\n-            raise IOError('Could not fit string into image. Max char count is too large for given image width.')\n+            raise IOError(('Could not fit string into image.'\n+                           'Max char count is too large for given image width.'))\n \n         # teach the RNN translational invariance by\n         # fitting text box randomly on canvas, with some room to rotate\n@@ -211,13 +218,18 @@ class TextImageGenerator(keras.callbacks.Callback):\n         self.X_text = []\n         self.Y_len = [0] * self.num_words\n \n+        def _is_length_of_word_valid(word):\n+            return (max_string_len == -1 or\n+                    max_string_len is None or\n+                    len(word) <= max_string_len)\n+\n         # monogram file is sorted by frequency in english speech\n         with codecs.open(self.monogram_file, mode='r', encoding='utf-8') as f:\n             for line in f:\n                 if len(tmp_string_list) == int(self.num_words * mono_fraction):\n                     break\n                 word = line.rstrip()\n-                if max_string_len == -1 or max_string_len is None or len(word) <= max_string_len:\n+                if _is_length_of_word_valid(word):\n                     tmp_string_list.append(word)\n \n         # bigram file contains common word pairings in english speech\n@@ -228,11 +240,11 @@ class TextImageGenerator(keras.callbacks.Callback):\n                     break\n                 columns = line.lower().split()\n                 word = columns[0] + ' ' + columns[1]\n-                if is_valid_str(word) and \\\n-                        (max_string_len == -1 or max_string_len is None or len(word) <= max_string_len):\n+                if is_valid_str(word) and _is_length_of_word_valid(word):\n                     tmp_string_list.append(word)\n         if len(tmp_string_list) != self.num_words:\n-            raise IOError('Could not pull enough words from supplied monogram and bigram files. ')\n+            raise IOError('Could not pull enough words'\n+                          'from supplied monogram and bigram files.')\n         # interlace to mix up the easy and hard words\n         self.string_list[::2] = tmp_string_list[:self.num_words // 2]\n         self.string_list[1::2] = tmp_string_list[self.num_words // 2:]\n@@ -274,9 +286,11 @@ class TextImageGenerator(keras.callbacks.Callback):\n                 source_str.append('')\n             else:\n                 if K.image_data_format() == 'channels_first':\n-                    X_data[i, 0, 0:self.img_w, :] = self.paint_func(self.X_text[index + i])[0, :, :].T\n+                    X_data[i, 0, 0:self.img_w, :] = (\n+                        self.paint_func(self.X_text[index + i])[0, :, :].T)\n                 else:\n-                    X_data[i, 0:self.img_w, :, 0] = self.paint_func(self.X_text[index + i])[0, :, :].T\n+                    X_data[i, 0:self.img_w, :, 0] = (\n+                        self.paint_func(self.X_text[index + i])[0, :, :].T)\n                 labels[i, :] = self.Y_data[index + i]\n                 input_length[i] = self.img_w // self.downsample_factor - 2\n                 label_length[i] = self.Y_len[index + i]\n@@ -292,7 +306,8 @@ class TextImageGenerator(keras.callbacks.Callback):\n \n     def next_train(self):\n         while 1:\n-            ret = self.get_batch(self.cur_train_index, self.minibatch_size, train=True)\n+            ret = self.get_batch(self.cur_train_index,\n+                                 self.minibatch_size, train=True)\n             self.cur_train_index += self.minibatch_size\n             if self.cur_train_index >= self.val_split:\n                 self.cur_train_index = self.cur_train_index % 32\n@@ -302,7 +317,8 @@ class TextImageGenerator(keras.callbacks.Callback):\n \n     def next_val(self):\n         while 1:\n-            ret = self.get_batch(self.cur_val_index, self.minibatch_size, train=False)\n+            ret = self.get_batch(self.cur_val_index,\n+                                 self.minibatch_size, train=False)\n             self.cur_val_index += self.minibatch_size\n             if self.cur_val_index >= self.num_words:\n                 self.cur_val_index = self.val_split + self.cur_val_index % 32\n@@ -310,19 +326,23 @@ class TextImageGenerator(keras.callbacks.Callback):\n \n     def on_train_begin(self, logs={}):\n         self.build_word_list(16000, 4, 1)\n-        self.paint_func = lambda text: paint_text(text, self.img_w, self.img_h,\n+        self.paint_func = lambda text: paint_text(\n+            text, self.img_w, self.img_h,\n             rotate=False, ud=False, multi_fonts=False)\n \n     def on_epoch_begin(self, epoch, logs={}):\n         # rebind the paint function to implement curriculum learning\n         if 3 <= epoch < 6:\n-            self.paint_func = lambda text: paint_text(text, self.img_w, self.img_h,\n+            self.paint_func = lambda text: paint_text(\n+                text, self.img_w, self.img_h,\n                 rotate=False, ud=True, multi_fonts=False)\n         elif 6 <= epoch < 9:\n-            self.paint_func = lambda text: paint_text(text, self.img_w, self.img_h,\n+            self.paint_func = lambda text: paint_text(\n+                text, self.img_w, self.img_h,\n                 rotate=False, ud=True, multi_fonts=True)\n         elif epoch >= 9:\n-            self.paint_func = lambda text: paint_text(text, self.img_w, self.img_h,\n+            self.paint_func = lambda text: paint_text(\n+                text, self.img_w, self.img_h,\n                 rotate=True, ud=True, multi_fonts=True)\n         if epoch >= 21 and self.max_string_len < 12:\n             self.build_word_list(32000, 12, 0.5)\n@@ -371,22 +391,27 @@ class VizCallback(keras.callbacks.Callback):\n         while num_left > 0:\n             word_batch = next(self.text_img_gen)[0]\n             num_proc = min(word_batch['the_input'].shape[0], num_left)\n-            decoded_res = decode_batch(self.test_func, word_batch['the_input'][0:num_proc])\n+            decoded_res = decode_batch(self.test_func,\n+                                       word_batch['the_input'][0:num_proc])\n             for j in range(num_proc):\n-                edit_dist = editdistance.eval(decoded_res[j], word_batch['source_str'][j])\n+                edit_dist = editdistance.eval(decoded_res[j],\n+                                              word_batch['source_str'][j])\n                 mean_ed += float(edit_dist)\n                 mean_norm_ed += float(edit_dist) / len(word_batch['source_str'][j])\n             num_left -= num_proc\n         mean_norm_ed = mean_norm_ed / num\n         mean_ed = mean_ed / num\n-        print('\\nOut of %d samples:  Mean edit distance: %.3f Mean normalized edit distance: %0.3f'\n+        print('\\nOut of %d samples:  Mean edit distance:'\n+              '%.3f Mean normalized edit distance: %0.3f'\n               % (num, mean_ed, mean_norm_ed))\n \n     def on_epoch_end(self, epoch, logs={}):\n-        self.model.save_weights(os.path.join(self.output_dir, 'weights%02d.h5' % (epoch)))\n+        self.model.save_weights(\n+            os.path.join(self.output_dir, 'weights%02d.h5' % (epoch)))\n         self.show_edit_distance(256)\n         word_batch = next(self.text_img_gen)[0]\n-        res = decode_batch(self.test_func, word_batch['the_input'][0:self.num_display_words])\n+        res = decode_batch(self.test_func,\n+                           word_batch['the_input'][0:self.num_display_words])\n         if word_batch['the_input'][0].shape[0] < 256:\n             cols = 2\n         else:\n@@ -398,7 +423,9 @@ class VizCallback(keras.callbacks.Callback):\n             else:\n                 the_input = word_batch['the_input'][i, :, :, 0]\n             pylab.imshow(the_input.T, cmap='Greys_r')\n-            pylab.xlabel('Truth = \\'%s\\'\\nDecoded = \\'%s\\'' % (word_batch['source_str'][i], res[i]))\n+            pylab.xlabel(\n+                'Truth = \\'%s\\'\\nDecoded = \\'%s\\'' %\n+                (word_batch['source_str'][i], res[i]))\n         fig = pylab.gcf()\n         fig.set_size_inches(10, 13)\n         pylab.savefig(os.path.join(self.output_dir, 'e%02d.png' % (epoch)))\n@@ -425,17 +452,19 @@ def train(run_name, start_epoch, stop_epoch, img_w):\n     else:\n         input_shape = (img_w, img_h, 1)\n \n-    fdir = os.path.dirname(get_file('wordlists.tgz',\n-                                    origin='http://www.mythic-ai.com/datasets/wordlists.tgz', untar=True))\n+    fdir = os.path.dirname(\n+        get_file('wordlists.tgz',\n+                 origin='http://www.mythic-ai.com/datasets/wordlists.tgz',\n+                 untar=True))\n \n-    img_gen = TextImageGenerator(monogram_file=os.path.join(fdir, 'wordlist_mono_clean.txt'),\n+    img_gen = TextImageGenerator(\n+        monogram_file=os.path.join(fdir, 'wordlist_mono_clean.txt'),\n         bigram_file=os.path.join(fdir, 'wordlist_bi_clean.txt'),\n         minibatch_size=minibatch_size,\n         img_w=img_w,\n         img_h=img_h,\n         downsample_factor=(pool_size ** 2),\n-                                 val_split=words_per_epoch - val_words\n-                                 )\n+        val_split=words_per_epoch - val_words)\n     act = 'relu'\n     input_data = Input(name='the_input', shape=input_shape, dtype='float32')\n     inner = Conv2D(conv_filters, kernel_size, padding='same',\n@@ -447,7 +476,8 @@ def train(run_name, start_epoch, stop_epoch, img_w):\n                    name='conv2')(inner)\n     inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max2')(inner)\n \n-    conv_to_rnn_dims = (img_w // (pool_size ** 2), (img_h // (pool_size ** 2)) * conv_filters)\n+    conv_to_rnn_dims = (img_w // (pool_size ** 2),\n+                        (img_h // (pool_size ** 2)) * conv_filters)\n     inner = Reshape(target_shape=conv_to_rnn_dims, name='reshape')(inner)\n \n     # cuts down input size going into RNN:\n@@ -455,11 +485,16 @@ def train(run_name, start_epoch, stop_epoch, img_w):\n \n     # Two layers of bidirectional GRUs\n     # GRU seems to work as well, if not better than LSTM:\n-    gru_1 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru1')(inner)\n-    gru_1b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru1_b')(inner)\n+    gru_1 = GRU(rnn_size, return_sequences=True,\n+                kernel_initializer='he_normal', name='gru1')(inner)\n+    gru_1b = GRU(rnn_size, return_sequences=True,\n+                 go_backwards=True, kernel_initializer='he_normal',\n+                 name='gru1_b')(inner)\n     gru1_merged = add([gru_1, gru_1b])\n-    gru_2 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru2')(gru1_merged)\n-    gru_2b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru2_b')(gru1_merged)\n+    gru_2 = GRU(rnn_size, return_sequences=True,\n+                kernel_initializer='he_normal', name='gru2')(gru1_merged)\n+    gru_2b = GRU(rnn_size, return_sequences=True, go_backwards=True,\n+                 kernel_initializer='he_normal', name='gru2_b')(gru1_merged)\n \n     # transforms RNN output to character activations:\n     inner = Dense(img_gen.get_output_size(), kernel_initializer='he_normal',\n@@ -467,29 +502,36 @@ def train(run_name, start_epoch, stop_epoch, img_w):\n     y_pred = Activation('softmax', name='softmax')(inner)\n     Model(inputs=input_data, outputs=y_pred).summary()\n \n-    labels = Input(name='the_labels', shape=[img_gen.absolute_max_string_len], dtype='float32')\n+    labels = Input(name='the_labels',\n+                   shape=[img_gen.absolute_max_string_len], dtype='float32')\n     input_length = Input(name='input_length', shape=[1], dtype='int64')\n     label_length = Input(name='label_length', shape=[1], dtype='int64')\n     # Keras doesn't currently support loss funcs with extra parameters\n     # so CTC loss is implemented in a lambda layer\n-    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n+    loss_out = Lambda(\n+        ctc_lambda_func, output_shape=(1,),\n+        name='ctc')([y_pred, labels, input_length, label_length])\n \n     # clipnorm seems to speeds up convergence\n     sgd = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n \n-    model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n+    model = Model(inputs=[input_data, labels, input_length, label_length],\n+                  outputs=loss_out)\n \n     # the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n     model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)\n     if start_epoch > 0:\n-        weight_file = os.path.join(OUTPUT_DIR, os.path.join(run_name, 'weights%02d.h5' % (start_epoch - 1)))\n+        weight_file = os.path.join(\n+            OUTPUT_DIR,\n+            os.path.join(run_name, 'weights%02d.h5' % (start_epoch - 1)))\n         model.load_weights(weight_file)\n     # captures output of softmax so we can decode the output during visualization\n     test_func = K.function([input_data], [y_pred])\n \n     viz_cb = VizCallback(run_name, test_func, img_gen.next_val())\n \n-    model.fit_generator(generator=img_gen.next_train(),\n+    model.fit_generator(\n+        generator=img_gen.next_train(),\n         steps_per_epoch=(words_per_epoch - val_words) // minibatch_size,\n         epochs=stop_epoch,\n         validation_data=img_gen.next_val(),\n@@ -501,5 +543,6 @@ def train(run_name, start_epoch, stop_epoch, img_w):\n if __name__ == '__main__':\n     run_name = datetime.datetime.now().strftime('%Y:%m:%d:%H:%M:%S')\n     train(run_name, 0, 20, 128)\n-    # increase to wider images and start at epoch 20. The learned weights are reloaded\n+    # increase to wider images and start at epoch 20.\n+    # The learned weights are reloaded\n     train(run_name, 20, 25, 512)\n\n@@ -75,8 +75,10 @@ print('Loading data...')\n (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n print(len(x_train), 'train sequences')\n print(len(x_test), 'test sequences')\n-print('Average train sequence length: {}'.format(np.mean(list(map(len, x_train)), dtype=int)))\n-print('Average test sequence length: {}'.format(np.mean(list(map(len, x_test)), dtype=int)))\n+print('Average train sequence length: {}'.format(\n+    np.mean(list(map(len, x_train)), dtype=int)))\n+print('Average test sequence length: {}'.format(\n+    np.mean(list(map(len, x_test)), dtype=int)))\n \n if ngram_range > 1:\n     print('Adding {}-gram features'.format(ngram_range))\n@@ -100,8 +102,10 @@ if ngram_range > 1:\n     # Augmenting x_train and x_test with n-grams features\n     x_train = add_ngram(x_train, token_indice, ngram_range)\n     x_test = add_ngram(x_test, token_indice, ngram_range)\n-    print('Average train sequence length: {}'.format(np.mean(list(map(len, x_train)), dtype=int)))\n-    print('Average test sequence length: {}'.format(np.mean(list(map(len, x_test)), dtype=int)))\n+    print('Average train sequence length: {}'.format(\n+        np.mean(list(map(len, x_train)), dtype=int)))\n+    print('Average test sequence length: {}'.format(\n+        np.mean(list(map(len, x_test)), dtype=int)))\n \n print('Pad sequences (samples x time)')\n x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n\n@@ -21,7 +21,8 @@ from keras.layers import LSTM\n from keras.datasets import imdb\n \n max_features = 20000\n-maxlen = 80  # cut texts after this number of words (among top max_features most common words)\n+# cut texts after this number of words (among top max_features most common words)\n+maxlen = 80\n batch_size = 32\n \n print('Loading data...')\n\n@@ -22,7 +22,9 @@ import random\n import sys\n import io\n \n-path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n+path = get_file(\n+    'nietzsche.txt',\n+    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n with io.open(path, encoding='utf-8') as f:\n     text = f.read().lower()\n print('corpus length:', len(text))\n\n@@ -12,12 +12,14 @@ the word-level and sentence-level structure of the context.\n \n # References\n \n-- [A Hierarchical Neural Autoencoder for Paragraphs and Documents](https://arxiv.org/abs/1506.01057)\n+- [A Hierarchical Neural Autoencoder for Paragraphs and Documents]\n+    (https://arxiv.org/abs/1506.01057)\n     Encodes paragraphs and documents with HRNN.\n     Results have shown that HRNN outperforms standard\n     RNNs and may play some role in more sophisticated generation tasks like\n     summarization or question answering.\n-- [Hierarchical recurrent neural network for skeleton based action recognition](http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7298714)\n+- [Hierarchical recurrent neural network for skeleton based action recognition]\n+    (http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7298714)\n     Achieved state-of-the-art results on\n     skeleton based action recognition with 3 levels\n     of bidirectional HRNN combined with fully connected layers.\n\n@@ -123,7 +123,8 @@ def wider2net_conv2d(teacher_w1, teacher_b1, teacher_w2, new_width, init):\n     if init == 'random-pad':\n         new_w1 = np.random.normal(0, 0.1, size=teacher_w1.shape[:3] + (n,))\n         new_b1 = np.ones(n) * 0.1\n-        new_w2 = np.random.normal(0, 0.1,\n+        new_w2 = np.random.normal(\n+            0, 0.1,\n             size=teacher_w2.shape[:2] + (n, teacher_w2.shape[3]))\n     elif init == 'net2wider':\n         index = np.random.randint(teacher_w1.shape[3], size=n)\n\n@@ -29,7 +29,8 @@ epochs = 20\n \n def euclidean_distance(vects):\n     x, y = vects\n-    return K.sqrt(K.maximum(K.sum(K.square(x - y), axis=1, keepdims=True), K.epsilon()))\n+    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n+    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n \n \n def eucl_dist_output_shape(shapes):\n@@ -42,8 +43,9 @@ def contrastive_loss(y_true, y_pred):\n     http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n     '''\n     margin = 1\n-    return K.mean(y_true * K.square(y_pred) +\n-                  (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n+    sqaure_pred = K.square(y_pred)\n+    margin_square = K.square(K.maximum(margin - y_pred, 0))\n+    return K.mean(y_true * sqaure_pred + (1 - y_true) * margin_square)\n \n \n def create_pairs(x, digit_indices):\n\n@@ -206,7 +206,8 @@ test_model.compile(optimizer=keras.optimizers.RMSprop(lr=2e-3, decay=1e-5),\n coord = tf.train.Coordinator()\n threads = tf.train.start_queue_runners(sess, coord)\n \n-train_model.fit(epochs=epochs,\n+train_model.fit(\n+    epochs=epochs,\n     steps_per_epoch=int(np.ceil(data.train.num_examples / float(batch_size))),\n     callbacks=[EvaluateInputTensor(test_model, steps=100)])\n \n\n@@ -31,11 +31,16 @@ python neural_doodle.py --nlabels 4 --style-image Renoir/style.png \\\n \r\n # References\r\n \r\n-- [Dmitry Ulyanov's blog on fast-neural-doodle](http://dmitryulyanov.github.io/feed-forward-neural-doodle/)\r\n-- [Torch code for fast-neural-doodle](https://github.com/DmitryUlyanov/fast-neural-doodle)\r\n-- [Torch code for online-neural-doodle](https://github.com/DmitryUlyanov/online-neural-doodle)\r\n-- [Paper Texture Networks: Feed-forward Synthesis of Textures and Stylized Images](http://arxiv.org/abs/1603.03417)\r\n-- [Discussion on parameter tuning](https://github.com/keras-team/keras/issues/3705)\r\n+- [Dmitry Ulyanov's blog on fast-neural-doodle]\r\n+    (http://dmitryulyanov.github.io/feed-forward-neural-doodle/)\r\n+- [Torch code for fast-neural-doodle]\r\n+    (https://github.com/DmitryUlyanov/fast-neural-doodle)\r\n+- [Torch code for online-neural-doodle]\r\n+    (https://github.com/DmitryUlyanov/online-neural-doodle)\r\n+- [Paper Texture Networks: Feed-forward Synthesis of Textures and Stylized Images]\r\n+    (http://arxiv.org/abs/1603.03417)\r\n+- [Discussion on parameter tuning]\r\n+    (https://github.com/keras-team/keras/issues/3705)\r\n \r\n # Resources\r\n \r\n@@ -134,7 +139,8 @@ def kmeans(xs, k):\n def load_mask_labels():\r\n     '''Load both target and style masks.\r\n     A mask image (nr x nc) with m labels/colors will be loaded\r\n-    as a 4D boolean tensor: (1, m, nr, nc) for 'channels_first' or (1, nr, nc, m) for 'channels_last'\r\n+    as a 4D boolean tensor:\r\n+        (1, m, nr, nc) for 'channels_first' or (1, nr, nc, m) for 'channels_last'\r\n     '''\r\n     target_mask_img = load_img(target_mask_path,\r\n                                target_size=(img_nrows, img_ncols))\r\n\n@@ -2,15 +2,18 @@\n \n Run the script with:\n ```\n-python neural_style_transfer.py path_to_your_base_image.jpg path_to_your_reference.jpg prefix_for_results\n+python neural_style_transfer.py path_to_your_base_image.jpg \\\n+    path_to_your_reference.jpg prefix_for_results\n ```\n e.g.:\n ```\n-python neural_style_transfer.py img/tuebingen.jpg img/starry_night.jpg results/my_result\n+python neural_style_transfer.py img/tuebingen.jpg \\\n+    img/starry_night.jpg results/my_result\n ```\n Optional parameters:\n ```\n---iter, To specify the number of iterations the style transfer takes place (Default is 10)\n+--iter, To specify the number of iterations \\\n+    the style transfer takes place (Default is 10)\n --content_weight, The weight given to the content loss (Default is 0.025)\n --style_weight, The weight given to the style loss (Default is 1.0)\n --tv_weight, The weight given to the total variation loss (Default is 1.0)\n@@ -189,11 +192,15 @@ def content_loss(base, combination):\n def total_variation_loss(x):\n     assert K.ndim(x) == 4\n     if K.image_data_format() == 'channels_first':\n-        a = K.square(x[:, :, :img_nrows - 1, :img_ncols - 1] - x[:, :, 1:, :img_ncols - 1])\n-        b = K.square(x[:, :, :img_nrows - 1, :img_ncols - 1] - x[:, :, :img_nrows - 1, 1:])\n+        a = K.square(\n+            x[:, :, :img_nrows - 1, :img_ncols - 1] - x[:, :, 1:, :img_ncols - 1])\n+        b = K.square(\n+            x[:, :, :img_nrows - 1, :img_ncols - 1] - x[:, :, :img_nrows - 1, 1:])\n     else:\n-        a = K.square(x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, 1:, :img_ncols - 1, :])\n-        b = K.square(x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, :img_nrows - 1, 1:, :])\n+        a = K.square(\n+            x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, 1:, :img_ncols - 1, :])\n+        b = K.square(\n+            x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, :img_nrows - 1, 1:, :])\n     return K.sum(K.pow(a + b, 1.25))\n \n # combine these loss functions into a single scalar\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4bcb8c95d8bba3147dd86446cd91be77051cef96", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 0 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 0 | Churn Cumulative: 0 | Contributors (this commit): 1 | Commits (past 90d): 3 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n\n\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#be6d8293f26d6d577b61874ccf6d68f116734d5a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 120 | Lines Deleted: 103 | Files Changed: 2 | Hunks: 42 | Methods Changed: 26 | Complexity Δ (Sum/Max): -3/14 | Churn Δ: 223 | Churn Cumulative: 5144 | Contributors (this commit): 29 | Commits (past 90d): 16 | Contributors (cumulative): 31 | DMM Complexity: 1.0\n\nDIFF:\n@@ -12,7 +12,6 @@ import reference_operations as KNP\n \n \n BACKENDS = []  # Holds a list of all available back-ends\n-WITH_NP = [K, KNP]\n \n try:\n     from keras.backend import cntk_backend as KC\n@@ -36,6 +35,9 @@ except ImportError:\n     warnings.warn('Could not import the Theano backend')\n \n \n+WITH_NP = [KTH if K.backend() == 'theano' else KC if K.backend() == 'cntk' else KTF, KNP]\n+\n+\n def check_dtype(var, dtype):\n     if K._BACKEND == 'theano':\n         assert var.dtype == dtype\n@@ -84,12 +86,6 @@ def assert_list_pairwise(z_list, shape=True, allclose=True, itself=False, atol=1\n             assert z1 == z2\n \n \n-def assert_list_with_ref(z_list, ref):\n-    for z in z_list:\n-        assert z.shape == ref.shape\n-        assert_allclose(z, ref, atol=1e-05)\n-\n-\n def assert_list_keras_shape(t_list, z_list):\n     for t, z in zip(t_list, z_list):\n         if hasattr(t, '_keras_shape') and len(t._keras_shape) > 1:\n@@ -102,23 +98,11 @@ def assert_list_keras_shape(t_list, z_list):\n def check_single_tensor_operation(function_name, x_shape_or_val, backend_list, **kwargs):\n     shape_or_val = kwargs.pop('shape_or_val', True)\n     assert_value_equality = kwargs.pop('assert_value_equality', True)\n-    assert_value_with_ref = kwargs.pop('assert_value_with_ref', None)\n     cntk_dynamicity = kwargs.pop('cntk_dynamicity', False)\n-    return_results = kwargs.pop('return_results', False)\n \n     if shape_or_val:\n         x_shape, x_val = parse_shape_or_val(x_shape_or_val)\n \n-        # If we can take a NumPy output, it is efficient to compare the outputs\n-        # from a single backend and NumPy.\n-        try:\n-            assert_value_with_ref = getattr(KNP, function_name)(x_val, **kwargs)\n-            # Leave only the designated backend from the test list of backends.\n-            backend_list = [k for k in backend_list\n-                            if K.backend() == k.__name__.split('.')[-1][:-8]]\n-        except:\n-            assert_value_with_ref = None\n-\n     t_list = []\n     z_list = []\n     for k in backend_list:\n@@ -135,15 +119,6 @@ def check_single_tensor_operation(function_name, x_shape_or_val, backend_list, *\n         t_list += [t]\n         z_list += [z]\n \n-    if return_results:\n-        if len(z_list) > 1:\n-            return z_list\n-        else:\n-            return z_list[0]\n-\n-    if assert_value_with_ref is not None:\n-        assert_list_with_ref(z_list, assert_value_with_ref)\n-    else:\n     assert_list_pairwise(z_list, allclose=assert_value_equality)\n     assert_list_keras_shape(t_list, z_list)\n \n@@ -151,20 +126,16 @@ def check_single_tensor_operation(function_name, x_shape_or_val, backend_list, *\n @keras_test\n def check_two_tensor_operation(function_name, x_shape_or_val,\n                                y_shape_or_val, backend_list, **kwargs):\n-    shape_or_val = kwargs.pop('shape_or_val', True)\n     concat_args = kwargs.pop('concat_args', False)\n     cntk_dynamicity = kwargs.pop('cntk_dynamicity', False)\n     cntk_two_dynamicity = kwargs.pop('cntk_two_dynamicity', False)\n-    return_results = kwargs.pop('return_results', False)\n \n-    if shape_or_val:\n     x_shape, x_val = parse_shape_or_val(x_shape_or_val)\n     y_shape, y_val = parse_shape_or_val(y_shape_or_val)\n \n     t_list = []\n     z_list = []\n     for k in backend_list:\n-        if shape_or_val:\n         if (k == KC) & (cntk_dynamicity):\n             t, f = cntk_func_two_tensor(function_name, x_shape, y=y_val, **kwargs)\n             z = f([x_val])[0]\n@@ -183,18 +154,9 @@ def check_two_tensor_operation(function_name, x_shape_or_val,\n             t = getattr(k, function_name)(\n                 k.variable(x_val), k.variable(y_val), **kwargs)\n             z = k.eval(t)\n-        else:\n-            t = getattr(k, function_name)(x_shape_or_val, y_shape_or_val, **kwargs)\n-            z = k.eval(t)\n         t_list += [t]\n         z_list += [z]\n \n-    if return_results:\n-        if len(z_list) > 1:\n-            return z_list\n-        else:\n-            return z_list[0]\n-\n     assert_list_pairwise(z_list)\n     assert_list_keras_shape(t_list, z_list)\n \n@@ -319,10 +281,8 @@ class TestBackend(object):\n             arr = np.arange(np.prod(shape)).reshape(shape)\n \n             for rep_axis in range(ndims):\n-                np_rep = np.repeat(arr, reps, axis=rep_axis)\n-                check_single_tensor_operation('repeat_elements', arr, BACKENDS,\n-                                              rep=reps, axis=rep_axis,\n-                                              assert_value_with_ref=np_rep)\n+                check_single_tensor_operation('repeat_elements', arr, WITH_NP,\n+                                              rep=reps, axis=rep_axis)\n \n                 if K.backend() != 'cntk':\n                     shape = list(shape)\n@@ -423,23 +383,23 @@ class TestBackend(object):\n         check_single_tensor_operation('square', (4, 2), WITH_NP)\n         check_single_tensor_operation('abs', (4, 2), WITH_NP)\n         check_single_tensor_operation('sqrt', (4, 2), WITH_NP)\n-        check_single_tensor_operation('exp', (4, 2), BACKENDS)\n+        check_single_tensor_operation('exp', (4, 2), WITH_NP)\n \n-        check_single_tensor_operation('round', (4, 2), BACKENDS)\n-        check_single_tensor_operation('sign', (4, 2), BACKENDS)\n+        check_single_tensor_operation('round', (4, 2), WITH_NP)\n+        check_single_tensor_operation('sign', (4, 2), WITH_NP)\n         check_single_tensor_operation('pow', (4, 2), WITH_NP, a=3)\n         check_single_tensor_operation('clip', (4, 2), WITH_NP, min_value=0.4,\n                                       max_value=0.6)\n \n         # two-tensor ops\n-        check_two_tensor_operation('equal', (4, 2), (4, 2), BACKENDS)\n-        check_two_tensor_operation('not_equal', (4, 2), (4, 2), BACKENDS)\n-        check_two_tensor_operation('greater', (4, 2), (4, 2), BACKENDS)\n-        check_two_tensor_operation('greater_equal', (4, 2), (4, 2), BACKENDS)\n-        check_two_tensor_operation('less', (4, 2), (4, 2), BACKENDS)\n-        check_two_tensor_operation('less_equal', (4, 2), (4, 2), BACKENDS)\n-        check_two_tensor_operation('maximum', (4, 2), (4, 2), BACKENDS)\n-        check_two_tensor_operation('minimum', (4, 2), (4, 2), BACKENDS)\n+        check_two_tensor_operation('equal', (4, 2), (4, 2), WITH_NP)\n+        check_two_tensor_operation('not_equal', (4, 2), (4, 2), WITH_NP)\n+        check_two_tensor_operation('greater', (4, 2), (4, 2), WITH_NP)\n+        check_two_tensor_operation('greater_equal', (4, 2), (4, 2), WITH_NP)\n+        check_two_tensor_operation('less', (4, 2), (4, 2), WITH_NP)\n+        check_two_tensor_operation('less_equal', (4, 2), (4, 2), WITH_NP)\n+        check_two_tensor_operation('maximum', (4, 2), (4, 2), WITH_NP)\n+        check_two_tensor_operation('minimum', (4, 2), (4, 2), WITH_NP)\n \n     @pytest.mark.skipif(K.backend() == 'cntk', reason='cntk does not support '\n                                                       'cumsum and cumprod yet')\n@@ -955,34 +915,35 @@ class TestBackend(object):\n             z = K.dropout(K.variable(val), level=-0.5)\n \n     def test_nn_operations(self):\n-        check_single_tensor_operation('relu', (4, 2), BACKENDS, alpha=0.1, max_value=0.5)\n-        check_single_tensor_operation('softplus', (4, 10), BACKENDS)\n-        check_single_tensor_operation('elu', (4, 10), BACKENDS, alpha=0.5)\n+        check_single_tensor_operation('relu', (4, 2), WITH_NP, alpha=0.1, max_value=0.5)\n+        check_single_tensor_operation('softplus', (4, 10), WITH_NP)\n+        check_single_tensor_operation('elu', (4, 10), WITH_NP, alpha=0.5)\n \n-        check_single_tensor_operation('sigmoid', (4, 2), BACKENDS)\n-        check_single_tensor_operation('hard_sigmoid', (4, 2), BACKENDS)\n-        check_single_tensor_operation('tanh', (4, 2), BACKENDS)\n+        check_single_tensor_operation('sigmoid', (4, 2), WITH_NP)\n+        check_single_tensor_operation('hard_sigmoid', (4, 2), WITH_NP)\n+        check_single_tensor_operation('tanh', (4, 2), WITH_NP)\n \n-        check_single_tensor_operation('softmax', (4, 10), BACKENDS)\n-        check_single_tensor_operation('softmax', (4, 5, 3, 10), BACKENDS, axis=2)\n+        check_single_tensor_operation('softmax', (4, 10), WITH_NP)\n+        check_single_tensor_operation('softmax', (4, 5, 3, 10), WITH_NP, axis=2)\n \n-        check_two_tensor_operation('binary_crossentropy', (4, 2), (4, 2), BACKENDS, from_logits=True)\n+        check_two_tensor_operation('binary_crossentropy', (4, 2), (4, 2), WITH_NP, from_logits=True)\n         # cross_entropy call require the label is a valid probability distribution,\n         # otherwise it is garbage in garbage out...\n         # due to the algo difference, we can't guarantee CNTK has the same result on the garbage input.\n         # so create a separate test case for valid label input\n-        check_two_tensor_operation('categorical_crossentropy', (4, 2), (4, 2), [KTH, KTF], from_logits=True)\n+        if K.backend() != 'cntk':\n+            check_two_tensor_operation('categorical_crossentropy', (4, 2), (4, 2), WITH_NP, from_logits=True)\n         xval = np.asarray([[0.26157712, 0.0432167], [-0.43380741, 0.30559841],\n                            [0.20225059, -0.38956559], [-0.13805378, 0.08506755]], dtype=np.float32)\n         yval = np.asarray([[0.46221867, 0.53778133], [0.51228984, 0.48771016],\n                            [0.64916514, 0.35083486], [0.47028078, 0.52971922]], dtype=np.float32)\n         check_two_tensor_operation('categorical_crossentropy', yval, xval,\n-                                   BACKENDS, cntk_two_dynamicity=True, from_logits=True)\n-        check_two_tensor_operation('binary_crossentropy', (4, 2), (4, 2), BACKENDS, from_logits=False)\n-        check_two_tensor_operation('categorical_crossentropy', (4, 2), (4, 2), BACKENDS, from_logits=False)\n+                                   WITH_NP, cntk_two_dynamicity=True, from_logits=True)\n+        check_two_tensor_operation('binary_crossentropy', (4, 2), (4, 2), WITH_NP, from_logits=False)\n+        check_two_tensor_operation('categorical_crossentropy', (4, 2), (4, 2), WITH_NP, from_logits=False)\n \n-        check_single_tensor_operation('l2_normalize', (4, 3), BACKENDS, axis=-1)\n-        check_single_tensor_operation('l2_normalize', (4, 3), BACKENDS, axis=1)\n+        check_single_tensor_operation('l2_normalize', (4, 3), WITH_NP, axis=-1)\n+        check_single_tensor_operation('l2_normalize', (4, 3), WITH_NP, axis=1)\n \n     def test_in_top_k(self):\n         batch_size = 20\n@@ -1026,15 +987,10 @@ class TestBackend(object):\n         ('conv3d', (1, 3, 5, 4, 2), (3, 3, 3, 2, 3), 'same', 'channels_last'),\n     ])\n     def test_conv(self, op, input_shape, kernel_shape, padding, data_format):\n-        k = K.backend()\n-        _, x = parse_shape_or_val(input_shape)\n-        _, w = parse_shape_or_val(kernel_shape)\n-        y1 = KNP.conv(x, w, padding, data_format)\n-        y2 = check_two_tensor_operation(\n-            op, x, w, [KTH if k == 'theano' else KC if k == 'cntk' else KTF],\n+        check_two_tensor_operation(\n+            op, input_shape, kernel_shape, WITH_NP,\n             padding=padding, data_format=data_format,\n-            cntk_dynamicity=True, return_results=True)\n-        assert_allclose(y1, y2, atol=1e-05)\n+            cntk_dynamicity=True)\n \n     @pytest.mark.parametrize('op,input_shape,kernel_shape,padding,data_format', [\n         ('depthwise_conv2d', (2, 3, 4, 5), (3, 3, 3, 2), 'same', 'channels_first'),\n@@ -1043,15 +999,10 @@ class TestBackend(object):\n         ('depthwise_conv2d', (1, 7, 6, 3), (3, 3, 3, 4), 'same', 'channels_last'),\n     ])\n     def test_depthwise_conv(self, op, input_shape, kernel_shape, padding, data_format):\n-        k = K.backend()\n-        _, x = parse_shape_or_val(input_shape)\n-        _, w = parse_shape_or_val(kernel_shape)\n-        y1 = KNP.depthwise_conv(x, w, padding, data_format)\n-        y2 = check_two_tensor_operation(\n-            op, x, w, [KTH if k == 'theano' else KC if k == 'cntk' else KTF],\n+        check_two_tensor_operation(\n+            op, input_shape, kernel_shape, WITH_NP,\n             padding=padding, data_format=data_format,\n-            cntk_dynamicity=True, return_results=True)\n-        assert_allclose(y1, y2, atol=1e-05)\n+            cntk_dynamicity=True)\n \n     @pytest.mark.parametrize('op,input_shape,pool_size,strides,padding,data_format,pool_mode', [\n         ('pool2d', (2, 3, 7, 7), (3, 3), (1, 1), 'same', 'channels_first', 'avg'),\n@@ -1064,15 +1015,11 @@ class TestBackend(object):\n         ('pool3d', (3, 5, 6, 7, 3), (3, 3, 3), (1, 1, 1), 'same', 'channels_last', 'max'),\n     ])\n     def test_pool(self, op, input_shape, pool_size, strides, padding, data_format, pool_mode):\n-        k = K.backend()\n-        _, x = parse_shape_or_val(input_shape)\n-        y1 = KNP.pool(x, pool_size, strides, padding, data_format, pool_mode)\n-        y2 = check_single_tensor_operation(\n-            op, x, [KTH if k == 'theano' else KC if k == 'cntk' else KTF],\n+        check_single_tensor_operation(\n+            op, input_shape, WITH_NP,\n             pool_size=pool_size, strides=strides,\n             padding=padding, data_format=data_format, pool_mode=pool_mode,\n-            cntk_dynamicity=True, return_results=True)\n-        assert_allclose(y1, y2, atol=1e-05)\n+            cntk_dynamicity=True)\n \n     def legacy_test_conv1d(self):\n         # channels_last input shape: (n, length, input_depth)\n@@ -1133,7 +1080,8 @@ class TestBackend(object):\n         _, x = parse_shape_or_val(input_shape)\n         _, depthwise = parse_shape_or_val(kernel_shape + (input_depth, depth_multiplier))\n         _, pointwise = parse_shape_or_val((1,) * len(kernel_shape) + (input_depth * depth_multiplier, 7))\n-        y1 = KNP.separable_conv(x, depthwise, pointwise, padding, data_format)\n+        y1 = KNP.separable_conv(x, depthwise, pointwise,\n+                                padding=padding, data_format=data_format)\n         if K.backend() == 'cntk':\n             y2 = cntk_func_three_tensor(\n                 op, input_shape,\n\n@@ -8,28 +8,28 @@ import scipy.signal as signal\n \n \n def normalize_conv(func):\n-    def wrapper(*args):\n+    def wrapper(*args, **kwargs):\n         x = args[0]\n         w = args[1]\n         if x.ndim == 3:\n             w = np.flipud(w)\n             w = np.transpose(w, (1, 2, 0))\n-            if args[3] == 'channels_last':\n+            if kwargs['data_format'] == 'channels_last':\n                 x = np.transpose(x, (0, 2, 1))\n         elif x.ndim == 4:\n             w = np.fliplr(np.flipud(w))\n             w = np.transpose(w, (2, 3, 0, 1))\n-            if args[3] == 'channels_last':\n+            if kwargs['data_format'] == 'channels_last':\n                 x = np.transpose(x, (0, 3, 1, 2))\n         else:\n             w = np.flip(np.fliplr(np.flipud(w)), axis=2)\n             w = np.transpose(w, (3, 4, 0, 1, 2))\n-            if args[3] == 'channels_last':\n+            if kwargs['data_format'] == 'channels_last':\n                 x = np.transpose(x, (0, 4, 1, 2, 3))\n \n-        y = func(x, w, args[2], args[3])\n+        y = func(x, w, **kwargs)\n \n-        if args[3] == 'channels_last':\n+        if kwargs['data_format'] == 'channels_last':\n             if y.ndim == 3:\n                 y = np.transpose(y, (0, 2, 1))\n             elif y.ndim == 4:\n@@ -73,8 +73,16 @@ def depthwise_conv(x, w, padding, data_format):\n \n \n def separable_conv(x, w1, w2, padding, data_format):\n-    x2 = depthwise_conv(x, w1, padding, data_format)\n-    return conv(x2, w2, padding, data_format)\n+    x2 = depthwise_conv(x, w1, padding=padding, data_format=data_format)\n+    return conv(x2, w2, padding=padding, data_format=data_format)\n+\n+\n+conv1d = conv\n+conv2d = conv\n+conv3d = conv\n+depthwise_conv2d = depthwise_conv\n+separable_conv1d = separable_conv\n+separable_conv2d = separable_conv\n \n \n def pool(x, pool_size, strides, padding, data_format, pool_mode):\n@@ -129,6 +137,10 @@ def pool(x, pool_size, strides, padding, data_format, pool_mode):\n     return y\n \n \n+pool2d = pool\n+pool3d = pool\n+\n+\n def rnn(x, w, init, go_backwards=False, mask=None, unroll=False, input_length=None):\n     w_i, w_h, w_o = w\n     h = []\n@@ -208,6 +220,23 @@ def l2_normalize(x, axis=-1):\n     return x / np.sqrt(y)\n \n \n+def binary_crossentropy(target, output, from_logits=False):\n+    if not from_logits:\n+        output = np.clip(output, 1e-7, 1 - 1e-7)\n+        output = np.log(output / (1 - output))\n+    return (target * -np.log(sigmoid(output)) +\n+            (1 - target) * -np.log(1 - sigmoid(output)))\n+\n+\n+def categorical_crossentropy(target, output, from_logits=False):\n+    if from_logits:\n+        output = softmax(output)\n+    else:\n+        output /= output.sum(axis=-1, keepdims=True)\n+    output = np.clip(output, 1e-7, 1 - 1e-7)\n+    return np.sum(target * -np.log(output), axis=-1, keepdims=False)\n+\n+\n def max(x, axis=None, keepdims=False):\n     if isinstance(axis, list):\n         for a in axis:\n@@ -304,6 +333,14 @@ def reshape(x, shape):\n     return np.reshape(x, shape)\n \n \n+def repeat_elements(x, rep, axis):\n+    return np.repeat(x, rep, axis=axis)\n+\n+\n+def eval(x):\n+    return x\n+\n+\n def variable(value, dtype=None, name=None, constraint=None):\n     if constraint is not None:\n         raise TypeError(\"Constraint must be None when \"\n@@ -311,6 +348,38 @@ def variable(value, dtype=None, name=None, constraint=None):\n     return np.array(value, dtype)\n \n \n+def equal(x, y):\n+    return x == y\n+\n+\n+def not_equal(x, y):\n+    return x != y\n+\n+\n+def greater(x, y):\n+    return x > y\n+\n+\n+def greater_equal(x, y):\n+    return x >= y\n+\n+\n+def less(x, y):\n+    return x < y\n+\n+\n+def less_equal(x, y):\n+    return x <= y\n+\n+\n+def maximum(x, y):\n+    return np.maximum(x, y)\n+\n+\n+def minimum(x, y):\n+    return np.minimum(x, y)\n+\n+\n square = np.square\n abs = np.abs\n exp = np.exp\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
