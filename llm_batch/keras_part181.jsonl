{"custom_id": "keras#b64e5919715f8dee546fbfc5049f8ec1574c2567", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 6499 | Contributors (this commit): 36 | Commits (past 90d): 28 | Contributors (cumulative): 36 | DMM Complexity: None\n\nDIFF:\n@@ -373,7 +373,7 @@ class SimpleRNN(Recurrent):\n         units: Positive integer, dimensionality of the output space.\n         activation: Activation function to use\n             (see [activations](../activations.md)).\n-            If you don't specify anything, no activation is applied\n+            If you pass None, no activation is applied\n             (ie. \"linear\" activation: `a(x) = x`).\n         use_bias: Boolean, whether the layer uses a bias vector.\n         kernel_initializer: Initializer for the `kernel` weights matrix,\n@@ -585,7 +585,7 @@ class GRU(Recurrent):\n         units: Positive integer, dimensionality of the output space.\n         activation: Activation function to use\n             (see [activations](../activations.md)).\n-            If you don't specify anything, no activation is applied\n+            If you pass None, no activation is applied\n             (ie. \"linear\" activation: `a(x) = x`).\n         recurrent_activation: Activation function to use\n             for the recurrent step\n@@ -858,7 +858,7 @@ class LSTM(Recurrent):\n         units: Positive integer, dimensionality of the output space.\n         activation: Activation function to use\n             (see [activations](../activations.md)).\n-            If you don't specify anything, no activation is applied\n+            If you pass None, no activation is applied\n             (ie. \"linear\" activation: `a(x) = x`).\n         recurrent_activation: Activation function to use\n             for the recurrent step\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b9fc5625fe33b1e3026df96bb611ce52bd12f93b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 14 | Churn Cumulative: 212 | Contributors (this commit): 4 | Commits (past 90d): 6 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -107,6 +107,20 @@ def test_merge_concatenate():\n     assert out.shape == (2, 8, 5)\n     assert_allclose(out, np.concatenate([x1, x2], axis=1), atol=1e-4)\n \n+    x3 = np.random.random((1, 1, 1))\n+    nb_layers = 4\n+    x_i = layers.Input(shape=(None, None))\n+    x_list = [x_i]\n+    x = x_i\n+    for i in range(nb_layers):\n+        x_list.append(x)\n+        x = layers.concatenate(x_list, axis=1)\n+    concat_model = models.Model(x_i, x)\n+    concat_out = concat_model.predict([x3])\n+    x3 = np.repeat(x3, 16, axis=1)\n+    assert concat_out.shape == (1, 16, 1)\n+    assert_allclose(concat_out, x3)\n+\n \n @keras_test\n def test_merge_dot():\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b260333eed8552a997d0207dcef0a1538e5ae91e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 763 | Contributors (this commit): 6 | Commits (past 90d): 5 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -127,9 +127,9 @@ def shuffle_mats_or_lists(matrix_list, stop_ind=None):\n         stop_ind = len_val\n     assert stop_ind <= len_val\n \n-    a = range(stop_ind)\n+    a = list(range(stop_ind))\n     np.random.shuffle(a)\n-    a += range(stop_ind, len_val)\n+    a += list(range(stop_ind, len_val))\n     for mat in matrix_list:\n         if isinstance(mat, np.ndarray):\n             ret.append(mat[a])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#86b12f6fd2c4e2d1f362cc526351e0bbae348240", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 671 | Contributors (this commit): 7 | Commits (past 90d): 16 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -160,7 +160,7 @@ class _Merge(Layer):\n         batch_sizes = set(batch_sizes)\n         batch_sizes -= set([None])\n         if len(batch_sizes) == 1:\n-            output_shape = (batch_sizes[0],) + output_shape\n+            output_shape = (list(batch_sizes)[0],) + output_shape\n         else:\n             output_shape = (None,) + output_shape\n         return output_shape\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#aec0e56ada7e321273f51156915b5cefc02f704c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 9643 | Contributors (this commit): 41 | Commits (past 90d): 43 | Contributors (cumulative): 41 | DMM Complexity: None\n\nDIFF:\n@@ -604,7 +604,7 @@ class Conv2DTranspose(Conv2D):\n \n     # Arguments\n         filters: Integer, the dimensionality of the output space\n-            (i.e. the number output of filters in the convolution).\n+            (i.e. the number of output filters in the convolution).\n         kernel_size: An integer or tuple/list of 2 integers, specifying the\n             width and height of the 2D convolution window.\n             Can be a single integer to specify the same value for\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7c3f8822375eb007beacd1170459ea7dfef92de5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 3 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 13446 | Contributors (this commit): 98 | Commits (past 90d): 117 | Contributors (cumulative): 148 | DMM Complexity: None\n\nDIFF:\n@@ -1479,7 +1479,7 @@ def normalize_batch_in_training(x, gamma, beta,\n     \"\"\"\n     mean, var = tf.nn.moments(x, reduction_axes,\n                               shift=None, name=None, keep_dims=False)\n-    if sorted(reduction_axes) == range(ndim(x))[:-1]:\n+    if sorted(reduction_axes) == list(range(ndim(x)))[:-1]:\n         normed = tf.nn.batch_normalization(x, mean, var,\n                                            beta, gamma,\n                                            epsilon)\n\n@@ -615,7 +615,7 @@ def batch_normalization(x, mean, var, beta, gamma, epsilon=1e-3):\n \n     if mean.ndim == 1:\n         # based on TensorFlow's default: normalize along rightmost dimension\n-        reduction_axes = range(x.ndim - 1)\n+        reduction_axes = list(range(x.ndim - 1))\n     else:\n         reduction_axes = [i for i in range(x.ndim) if mean.broadcastable[i]]\n \n\n@@ -133,7 +133,7 @@ class BatchNormalization(Layer):\n         broadcast_shape[self.axis] = input_shape[self.axis]\n \n         # Determines whether broadcasting is needed.\n-        needs_broadcasting = (sorted(reduction_axes) != range(ndim)[:-1])\n+        needs_broadcasting = (sorted(reduction_axes) != list(range(ndim))[:-1])\n \n         normed, mean, variance = K.normalize_batch_in_training(\n             inputs, self.gamma, self.beta, reduction_axes,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3308778b9dfa28dbb9d5e450a7f587aea6f12198", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 954 | Contributors (this commit): 18 | Commits (past 90d): 16 | Contributors (cumulative): 18 | DMM Complexity: None\n\nDIFF:\n@@ -145,7 +145,7 @@ def count_total_params(layers, layer_set=None):\n         else:\n             trainable_count += np.sum([K.count_params(p) for p in layer.trainable_weights])\n             non_trainable_count += np.sum([K.count_params(p) for p in layer.non_trainable_weights])\n-    return trainable_count, non_trainable_count\n+    return int(trainable_count), int(non_trainable_count)\n \n \n def convert_all_kernels_in_model(model):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fe48b41c2228b64357bedd1942ab981ef2ad3cbc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 482 | Contributors (this commit): 10 | Commits (past 90d): 6 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -20,11 +20,6 @@ num_classes = 10\n epochs = 200\n data_augmentation = True\n \n-# input image dimensions\n-img_rows, img_cols = 32, 32\n-# The CIFAR10 images are RGB.\n-img_channels = 3\n-\n # The data, shuffled and split between train and test sets:\n (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n print('x_train shape:', x_train.shape)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3a666b497db59491d71ce671e3b01af90332e8b9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 6 | Files Changed: 3 | Hunks: 6 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 13 | Churn Cumulative: 14066 | Contributors (this commit): 66 | Commits (past 90d): 56 | Contributors (cumulative): 73 | DMM Complexity: None\n\nDIFF:\n@@ -22,14 +22,16 @@ class Initializer(object):\n \n \n class Zeros(Initializer):\n-    \"\"\"Initializer that generates tensors initialized to 0.\"\"\"\n+    \"\"\"Initializer that generates tensors initialized to 0.\n+    \"\"\"\n \n     def __call__(self, shape, dtype=None):\n         return K.constant(0, shape=shape, dtype=dtype)\n \n \n class Ones(Initializer):\n-    \"\"\"Initializer that generates tensors initialized to 1.\"\"\"\n+    \"\"\"Initializer that generates tensors initialized to 1.\n+    \"\"\"\n \n     def __call__(self, shape, dtype=None):\n         return K.constant(1, shape=shape, dtype=dtype)\n@@ -111,7 +113,7 @@ class RandomUniform(Initializer):\n class TruncatedNormal(Initializer):\n     \"\"\"Initializer that generates a truncated normal distribution.\n \n-    These values are similar to values from a `random_normal_initializer`\n+    These values are similar to values from a `RandomNormal`\n     except that values more than two standard deviations from the mean\n     are discarded and re-drawn. This is the recommended initializer for\n     neural network weights and filters.\n@@ -146,6 +148,7 @@ class VarianceScaling(Initializer):\n \n     With `distribution=\"normal\"`, samples are drawn from a truncated normal\n     distribution centered on zero, with `stddev = sqrt(scale / n)` where n is:\n+\n         - number of input units in the weight tensor, if mode = \"fan_in\"\n         - number of output units, if mode = \"fan_out\"\n         - average of the numbers of input and output units, if mode = \"fan_avg\"\n\n@@ -73,7 +73,7 @@ class Dropout(Layer):\n     \"\"\"Applies Dropout to the input.\n \n     Dropout consists in randomly setting\n-    a fraction `p` of input units to 0 at each update during training time,\n+    a fraction `rate` of input units to 0 at each update during training time,\n     which helps prevent overfitting.\n \n     # Arguments\n\n@@ -220,8 +220,6 @@ class LocallyConnected2D(Layer):\n             specifying the strides of the convolution along the width and height.\n             Can be a single integer to specify the same value for\n             all spatial dimensions.\n-            Specifying any stride value != 1 is incompatible with specifying\n-            any `dilation_rate` value != 1.\n         padding: Currently only support `\"valid\"` (case-insensitive).\n             `\"same\"` will be supported in future.\n         data_format: A string,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#986ecdb8c66f2e181d519f17320cc99badc2a2f5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 7660 | Contributors (this commit): 31 | Commits (past 90d): 50 | Contributors (cumulative): 31 | DMM Complexity: None\n\nDIFF:\n@@ -467,7 +467,7 @@ class Layer(object):\n                                     str(spec.shape) + ', found shape=' +\n                                     str(x_shape))\n \n-    def call(self, inputs):\n+    def call(self, inputs, **kwargs):\n         \"\"\"This is where the layer's logic lives.\n \n         # Arguments\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#dbe13670d963444238abdd064da680108a908856", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 4 | Methods Changed: 7 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 30 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -39,7 +39,7 @@ def build_fn_clf(hidden_dims):\n     return model\n \n \n-def test_clasify_build_fn():\n+def test_classify_build_fn():\n     clf = KerasClassifier(\n         build_fn=build_fn_clf, hidden_dims=hidden_dims,\n         batch_size=batch_size, epochs=epochs)\n@@ -48,7 +48,7 @@ def test_clasify_build_fn():\n     assert_string_classification_works(clf)\n \n \n-def test_clasify_class_build_fn():\n+def test_classify_class_build_fn():\n     class ClassBuildFnClf(object):\n \n         def __call__(self, hidden_dims):\n@@ -62,7 +62,7 @@ def test_clasify_class_build_fn():\n     assert_string_classification_works(clf)\n \n \n-def test_clasify_inherit_class_build_fn():\n+def test_classify_inherit_class_build_fn():\n     class InheritClassBuildFnClf(KerasClassifier):\n \n         def __call__(self, hidden_dims):\n@@ -96,7 +96,7 @@ def assert_string_classification_works(clf):\n     string_classes = ['cls{}'.format(x) for x in range(num_class)]\n     str_y_train = np.array(string_classes)[y_train]\n \n-    clf.fit(X_train, str_y_train, batch_size=batch_size, nb_epoch=epochs)\n+    clf.fit(X_train, str_y_train, batch_size=batch_size, epochs=epochs)\n \n     score = clf.score(X_train, str_y_train, batch_size=batch_size)\n     assert np.isscalar(score) and np.isfinite(score)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#48e056d31fa3be6b53b46aac46e39c576fc4e89c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 11 | Files Changed: 4 | Hunks: 9 | Methods Changed: 6 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 27 | Churn Cumulative: 16547 | Contributors (this commit): 91 | Commits (past 90d): 143 | Contributors (cumulative): 114 | DMM Complexity: 0.0\n\nDIFF:\n@@ -3349,10 +3349,10 @@ def map_fn(fn, elems, name=None, dtype=None):\n         fn: Callable that will be called upon each element in elems\n         elems: tensor\n         name: A string name for the map node in the graph\n+        dtype: Output data type.\n \n     # Returns\n-        Tensor with first dimension equal to the elems and second depending on\n-        fn\n+        Tensor with dtype `dtype`.\n     \"\"\"\n     return tf.map_fn(fn, elems, name=name, dtype=dtype)\n \n@@ -3368,7 +3368,7 @@ def foldl(fn, elems, initializer=None, name=None):\n         name: A string name for the foldl node in the graph\n \n     # Returns\n-        Same type and shape as initializer\n+        Tensor with same type and shape as `initializer`.\n     \"\"\"\n     return tf.foldl(fn, elems, initializer=initializer, name=name)\n \n\n@@ -471,7 +471,8 @@ class Layer(object):\n         \"\"\"This is where the layer's logic lives.\n \n         # Arguments\n-            inputs: input tensor, or list/tuple of input tensors.\n+            inputs: Input tensor, or list/tuple of input tensors.\n+            **kwargs: Additional keyword arguments.\n \n         # Returns\n             A tensor or list/tuple of tensors.\n@@ -503,7 +504,7 @@ class Layer(object):\n             ValueError: in case the layer is missing shape information\n                 for its `build` call.\n         \"\"\"\n-        if type(inputs) is list:\n+        if isinstance(inputs, list):\n             inputs = inputs[:]\n         with K.name_scope(self.name):\n             # Handle laying building (weight creating, input spec locking).\n\n@@ -31,8 +31,8 @@ class _Merge(Layer):\n             tuple or None.\n \n         # Raises\n-            ValueError if shape1 and shape2 are not compaible for\n-            element-wise operations\n+            ValueError: if shape1 and shape2 are not compatible for\n+                element-wise operations.\n         \"\"\"\n         if None in [shape1, shape2]:\n             return None\n\n@@ -158,6 +158,9 @@ class Bidirectional(Wrapper):\n             If None, the outputs will not be combined,\n             they will be returned as a list.\n \n+    # Raises\n+        ValueError: In case of invalid `merge_mode` argument.\n+\n     # Examples\n \n     ```python\n@@ -210,11 +213,12 @@ class Bidirectional(Wrapper):\n             return [self.forward_layer.compute_output_shape(input_shape)] * 2\n \n     def call(self, inputs, training=None, mask=None):\n-        func_args = inspect.getargspec(self.layer.call).args\n         kwargs = {}\n-        for arg in ('training', 'mask'):\n-            if arg in func_args:\n-                kwargs[arg] = eval(arg)\n+        func_args = inspect.getargspec(self.layer.call).args\n+        if 'training' in func_args:\n+            kwargs['training'] = training\n+        if 'mask' in func_args:\n+            kwargs['mask'] = mask\n \n         y = self.forward_layer.call(inputs, **kwargs)\n         y_rev = self.backward_layer.call(inputs, **kwargs)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9749ea330977dd97c8073911d9ceb0439292b170", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 1223 | Contributors (this commit): 13 | Commits (past 90d): 13 | Contributors (cumulative): 13 | DMM Complexity: None\n\nDIFF:\n@@ -190,6 +190,9 @@ class KerasClassifier(BaseWrapper):\n         # Returns\n             history : object\n                 details about the training history at each epoch.\n+\n+        # Raises\n+            ValueError: In case of invalid shape for `y` argument.\n         \"\"\"\n         y = np.array(y)\n         if len(y.shape) == 2 and y.shape[1] > 1:\n@@ -198,7 +201,7 @@ class KerasClassifier(BaseWrapper):\n             self.classes_ = np.unique(y)\n             y = np.searchsorted(self.classes_, y)\n         else:\n-            raise ValueError('Invalid shape for y')\n+            raise ValueError('Invalid shape for y: ' + str(y.shape))\n         self.n_classes_ = len(self.classes_)\n         return super(KerasClassifier, self).fit(x, y, **kwargs)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#90d24ddf1aefc1493436d8952da97b224cf937f4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 6505 | Contributors (this commit): 37 | Commits (past 90d): 29 | Contributors (cumulative): 37 | DMM Complexity: None\n\nDIFF:\n@@ -528,7 +528,7 @@ class SimpleRNN(Recurrent):\n \n     def get_constants(self, inputs, training=None):\n         constants = []\n-        if self.implementation == 0 and 0 < self.dropout < 1:\n+        if self.implementation != 0 and 0 < self.dropout < 1:\n             input_shape = K.int_shape(inputs)\n             input_dim = input_shape[-1]\n             ones = K.ones_like(K.reshape(inputs[:, 0, 0], (-1, 1)))\n@@ -746,7 +746,7 @@ class GRU(Recurrent):\n \n     def get_constants(self, inputs, training=None):\n         constants = []\n-        if self.implementation == 0 and 0 < self.dropout < 1:\n+        if self.implementation != 0 and 0 < self.dropout < 1:\n             input_shape = K.int_shape(inputs)\n             input_dim = input_shape[-1]\n             ones = K.ones_like(K.reshape(inputs[:, 0, 0], (-1, 1)))\n@@ -1036,7 +1036,7 @@ class LSTM(Recurrent):\n \n     def get_constants(self, inputs, training=None):\n         constants = []\n-        if self.implementation == 0 and 0 < self.dropout < 1:\n+        if self.implementation != 0 and 0 < self.dropout < 1:\n             input_shape = K.int_shape(inputs)\n             input_dim = input_shape[-1]\n             ones = K.ones_like(K.reshape(inputs[:, 0, 0], (-1, 1)))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e57965ec769f9679bb0a3d7e7e49f512d85043b4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 13 | Churn Cumulative: 6518 | Contributors (this commit): 38 | Commits (past 90d): 30 | Contributors (cumulative): 38 | DMM Complexity: None\n\nDIFF:\n@@ -78,12 +78,15 @@ class Recurrent(Layer):\n         # now model.output_shape == (None, 32)\n         # note: `None` is the batch dimension.\n \n-        # the following is identical:\n-        model = Sequential()\n-        model.add(LSTM(32, input_dim=64, input_length=10))\n-\n-        # for subsequent layers, not need to specify the input size:\n+        # for subsequent layers, no need to specify the input size:\n         model.add(LSTM(16))\n+\n+        # to stack recurrent layers, you must use return_sequences=True on any recurrent layer that feeds into another recurrent layer.\n+        # note that you only need to specify the input size on the first layer.\n+        model = Sequential()\n+        model.add(LSTM(64, input_dim=64, input_length=10, return_sequences=True))\n+        model.add(LSTM(32, return_sequences=True))\n+        model.add(LSTM(10))\n     ```\n \n     # Arguments\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d7341b3f39f4abea3561805d6af72f76efb0433e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 6521 | Contributors (this commit): 38 | Commits (past 90d): 31 | Contributors (cumulative): 38 | DMM Complexity: None\n\nDIFF:\n@@ -81,7 +81,8 @@ class Recurrent(Layer):\n         # for subsequent layers, no need to specify the input size:\n         model.add(LSTM(16))\n \n-        # to stack recurrent layers, you must use return_sequences=True on any recurrent layer that feeds into another recurrent layer.\n+        # to stack recurrent layers, you must use return_sequences=True\n+        # on any recurrent layer that feeds into another recurrent layer.\n         # note that you only need to specify the input size on the first layer.\n         model = Sequential()\n         model.add(LSTM(64, input_dim=64, input_length=10, return_sequences=True))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f9c9c0ab3fd2ce9613f110b5b229ac0fc0e51b82", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 5 | Files Changed: 3 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 11 | Churn Cumulative: 18838 | Contributors (this commit): 108 | Commits (past 90d): 139 | Contributors (cumulative): 169 | DMM Complexity: None\n\nDIFF:\n@@ -2175,8 +2175,8 @@ def rnn(step_function, inputs, initial_states,\n             (no time dimension),\n             containing the initial values for the states used in\n             the step function.\n-        go_backwards: boolean. If True, do the iteration over\n-            the time dimension in reverse order.\n+        go_backwards: boolean. If True, do the iteration over the time\n+            dimension in reverse order and return the reversed sequence.\n         mask: binary tensor with shape `(samples, time, 1)`,\n             with a zero for every element that is masked.\n         constants: a list of constant values passed at each step.\n\n@@ -1166,8 +1166,8 @@ def rnn(step_function, inputs, initial_states,\n         initial_states: tensor with shape (samples, ...) (no time dimension),\n             containing the initial values for the states used in\n             the step function.\n-        go_backwards: boolean. If True, do the iteration over\n-            the time dimension in reverse order.\n+        go_backwards: boolean. If True, do the iteration over the time\n+            dimension in reverse order and return the reversed sequence.\n         mask: binary tensor with shape (samples, time),\n             with a zero for every element that is masked.\n         constants: a list of constant values passed at each step.\n\n@@ -97,7 +97,8 @@ class Recurrent(Layer):\n         return_sequences: Boolean. Whether to return the last output\n             in the output sequence, or the full sequence.\n         go_backwards: Boolean (default False).\n-            If True, process the input sequence backwards.\n+            If True, process the input sequence backwards and return the\n+            reversed sequence.\n         stateful: Boolean (default False). If True, the last state\n             for each sample at index i in a batch will be used as initial\n             state for the sample of index i in the following batch.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3382c0bb894b2ecaac2562238f34c2a46bf413c9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 9077 | Contributors (this commit): 60 | Commits (past 90d): 30 | Contributors (cumulative): 60 | DMM Complexity: None\n\nDIFF:\n@@ -1041,8 +1041,10 @@ class Sequential(Model):\n                 - A tuple (inputs, targets, sample_weights).\n             validation_steps: Only relevant if `validation_data`\n                 is a generator.\n-                Number of samples to use from validation generator\n-                at the end of every epoch.\n+                Number of steps to yield from validation generator\n+                at the end of every epoch. It should typically\n+                be equal to the number of unique samples of your\n+                validation dataset divided by the batch size.\n             class_weight: Dictionary mapping class indices to a weight\n                 for the class.\n             max_q_size: Maximum size for the generator queue\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#64d2421599e97a0bef3df462fab2046443810734", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1012 | Contributors (this commit): 6 | Commits (past 90d): 19 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -340,7 +340,7 @@ class ConvLSTM2D(ConvRecurrent2D):\n             self.states = [None, None]\n \n         if self.data_format == 'channels_first':\n-            channel_axis = 1\n+            channel_axis = 2\n         else:\n             channel_axis = -1\n         if input_shape[channel_axis] is None:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4fe78f340053dffbc3e36644dc43fdf8fc959081", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 209 | Lines Deleted: 35 | Files Changed: 2 | Hunks: 13 | Methods Changed: 7 | Complexity Δ (Sum/Max): 21/20 | Churn Δ: 244 | Churn Cumulative: 448 | Contributors (this commit): 4 | Commits (past 90d): 5 | Contributors (cumulative): 5 | DMM Complexity: 0.5694444444444444\n\nDIFF:\n@@ -4,10 +4,12 @@ from __future__ import print_function\n \n import functools\n import tarfile\n+import zipfile\n import os\n import sys\n import shutil\n import hashlib\n+import six\n from six.moves.urllib.request import urlopen\n from six.moves.urllib.error import URLError\n from six.moves.urllib.error import HTTPError\n@@ -55,24 +57,105 @@ else:\n     from six.moves.urllib.request import urlretrieve\n \n \n-def get_file(fname, origin, untar=False,\n-             md5_hash=None, cache_subdir='datasets'):\n-    \"\"\"Downloads a file from a URL if it not already in the cache.\n-\n-    Passing the MD5 hash will verify the file after download\n-    as well as if it is already present in the cache.\n+def _extract_archive(file_path, path='.', archive_format='auto'):\n+    \"\"\"Extracts an archive if it matches the tar, tar.gz, tar.bz, or zip formats\n \n     # Arguments\n-        fname: name of the file\n-        origin: original URL of the file\n-        untar: boolean, whether the file should be decompressed\n-        md5_hash: MD5 hash of the file for verification\n-        cache_subdir: directory being used as the cache\n+        file_path: path to the archive file\n+        path: path to extract the archive file\n+        archive_format: Archive format to try for extracting the file.\n+            Options are 'auto', 'tar', 'zip', and None.\n+            'tar' includes tar, tar.gz, and tar.bz files.\n+            The default 'auto' is ['tar', 'zip'].\n+            None or an empty list will return no matches found.\n+\n+    # Return:\n+        True if a match was found and an archive extraction was completed,\n+        False otherwise.\n+    \"\"\"\n+    if archive_format is None:\n+        return False\n+    if archive_format is 'auto':\n+        archive_format = ['tar', 'zip']\n+    if isinstance(archive_format, six.string_types):\n+        archive_format = [archive_format]\n+\n+    for archive_type in archive_format:\n+        if archive_type is 'tar':\n+            open_fn = tarfile.open\n+            is_match_fn = tarfile.is_tarfile\n+        if archive_type is 'zip':\n+            open_fn = zipfile.ZipFile\n+            is_match_fn = zipfile.is_zipfile\n+\n+        if is_match_fn(file_path):\n+            with open_fn(file_path) as archive:\n+                try:\n+                    archive.extractall(path)\n+                except (tarfile.TarError, RuntimeError,\n+                        KeyboardInterrupt) as e:\n+                    if os.path.exists(path):\n+                        if os.path.isfile(path):\n+                            os.remove(path)\n+                        else:\n+                            shutil.rmtree(path)\n+                    raise\n+            return True\n+    return False\n+\n+\n+def get_file(fname, origin, untar=False,\n+             md5_hash=None, cache_subdir='datasets',\n+             file_hash=None,\n+             hash_algorithm='auto',\n+             extract=False,\n+             archive_format='auto',\n+             cache_dir=None):\n+    \"\"\"Downloads a file from a URL if it not already in the cache.\n+\n+    By default the file at the url `origin` is downloaded to the\n+    cache_dir `~/.keras`, placed in the cache_subdir `datasets`,\n+    and given the filename `fname`. The final location of a file\n+    `example.txt` would therefore be `~/.keras/datasets/example.txt`.\n+\n+    Files in tar, tar.gz, tar.bz, and zip formats can also be extracted.\n+    Passing a hash will verify the file after download. The command line\n+    programs `shasum` and `sha256sum` can compute the hash.\n+\n+    # Arguments\n+        fname: Name of the file. If an absolute path `/path/to/file.txt` is\n+            specified the file will be saved at that location.\n+        origin: Original URL of the file.\n+        untar: Deprecated in favor of 'extract'.\n+            boolean, whether the file should be decompressed\n+        md5_hash: Deprecated in favor of 'file_hash'.\n+            md5 hash of the file for verification\n+        file_hash: The expected hash string of the file after download.\n+            The sha256 and md5 hash algorithms are both supported.\n+        cache_subdir: Subdirectory under the Keras cache dir where the file is\n+            saved. If an absolute path `/path/to/folder` is\n+            specified the file will be saved at that location.\n+        hash_algorithm: Select the hash algorithm to verify the file.\n+            options are 'md5', 'sha256', and 'auto'.\n+            The default 'auto' detects the hash algorithm in use.\n+        extract: True tries extracting the file as an Archive, like tar or zip.\n+        archive_format: Archive format to try for extracting the file.\n+            Options are 'auto', 'tar', 'zip', and None.\n+            'tar' includes tar, tar.gz, and tar.bz files.\n+            The default 'auto' is ['tar', 'zip'].\n+            None or an empty list will return no matches found.\n+        cache_dir: Location to store cached files, when None it\n+            defaults to the [Keras Directory](/faq/#where-is-the-keras-configuration-filed-stored).\n \n     # Returns\n         Path to the downloaded file\n     \"\"\"\n-    datadir_base = os.path.expanduser(os.path.join('~', '.keras'))\n+    if cache_dir is None:\n+        cache_dir = os.path.expanduser(os.path.join('~', '.keras'))\n+    if md5_hash is not None and file_hash is None:\n+        file_hash = md5_hash\n+        hash_algorithm = 'md5'\n+    datadir_base = os.path.expanduser(cache_dir)\n     if not os.access(datadir_base, os.W_OK):\n         datadir_base = os.path.join('/tmp', '.keras')\n     datadir = os.path.join(datadir_base, cache_subdir)\n@@ -88,10 +171,12 @@ def get_file(fname, origin, untar=False,\n     download = False\n     if os.path.exists(fpath):\n         # File found; verify integrity if a hash was provided.\n-        if md5_hash is not None:\n-            if not validate_file(fpath, md5_hash):\n+        if file_hash is not None:\n+            if not validate_file(fpath, file_hash, algorithm=hash_algorithm):\n                 print('A local file was found, but it seems to be '\n-                      'incomplete or outdated.')\n+                      'incomplete or outdated because the ' + hash_algorithm +\n+                      ' file hash does not match the original value of ' +\n+                      file_hash + ' so we will re-download the data.')\n                 download = True\n     else:\n         download = True\n@@ -123,38 +208,68 @@ def get_file(fname, origin, untar=False,\n \n     if untar:\n         if not os.path.exists(untar_fpath):\n-            print('Untaring file...')\n-            tfile = tarfile.open(fpath, 'r:gz')\n-            try:\n-                tfile.extractall(path=datadir)\n-            except (Exception, KeyboardInterrupt) as e:\n-                if os.path.exists(untar_fpath):\n-                    if os.path.isfile(untar_fpath):\n-                        os.remove(untar_fpath)\n-                    else:\n-                        shutil.rmtree(untar_fpath)\n-                raise\n-            tfile.close()\n+            _extract_archive(fpath, datadir, archive_format='tar')\n         return untar_fpath\n \n+    if extract:\n+        _extract_archive(fpath, datadir, archive_format)\n+\n     return fpath\n \n \n-def validate_file(fpath, md5_hash):\n-    \"\"\"Validates a file against a MD5 hash.\n+def _hash_file(fpath, algorithm='sha256', chunk_size=65535):\n+    \"\"\"Calculates a file sha256 or md5 hash.\n+\n+    # Example\n+\n+    ```python\n+       >>> from keras.data_utils import _hash_file\n+       >>> _hash_file('/path/to/file.zip')\n+       'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855'\n+    ```\n \n     # Arguments\n         fpath: path to the file being validated\n-        md5_hash: the MD5 hash being validated against\n+        algorithm: hash algorithm, one of 'auto', 'sha256', or 'md5'.\n+            The default 'auto' detects the hash algorithm in use.\n+        chunk_size: Bytes to read at a time, important for large files.\n+\n+    # Returns\n+        The file hash\n+    \"\"\"\n+    if (algorithm is 'sha256') or (algorithm is 'auto' and len(hash) is 64):\n+        hasher = hashlib.sha256()\n+    else:\n+        hasher = hashlib.md5()\n+\n+    with open(fpath, 'rb') as fpath_file:\n+        for chunk in iter(lambda: fpath_file.read(chunk_size), b''):\n+            hasher.update(chunk)\n+\n+    return hasher.hexdigest()\n+\n+\n+def validate_file(fpath, file_hash, algorithm='auto', chunk_size=65535):\n+    \"\"\"Validates a file against a sha256 or md5 hash.\n+\n+    # Arguments\n+        fpath: path to the file being validated\n+        file_hash:  The expected hash string of the file.\n+            The sha256 and md5 hash algorithms are both supported.\n+        algorithm: Hash algorithm, one of 'auto', 'sha256', or 'md5'.\n+            The default 'auto' detects the hash algorithm in use.\n+        chunk_size: Bytes to read at a time, important for large files.\n \n     # Returns\n         Whether the file is valid\n     \"\"\"\n-    hasher = hashlib.md5()\n-    with open(fpath, 'rb') as f:\n-        buf = f.read()\n-        hasher.update(buf)\n-    if str(hasher.hexdigest()) == str(md5_hash):\n+    if ((algorithm is 'sha256') or\n+            (algorithm is 'auto' and len(file_hash) is 64)):\n+        hasher = 'sha256'\n+    else:\n+        hasher = 'md5'\n+\n+    if str(_hash_file(fpath, hasher, chunk_size)) == str(file_hash):\n         return True\n     else:\n         return False\n\n@@ -0,0 +1,59 @@\n+\"\"\"Tests for functions in data_utils.py.\n+\"\"\"\n+import os\n+import pytest\n+import tarfile\n+import zipfile\n+from six.moves.urllib.request import pathname2url\n+from six.moves.urllib.parse import urljoin\n+from keras.utils.data_utils import get_file\n+from keras.utils.data_utils import validate_file\n+from keras.utils.data_utils import _hash_file\n+from keras import activations\n+from keras import regularizers\n+\n+\n+def test_data_utils():\n+    \"\"\"Tests get_file from a url, plus extraction and validation.\n+    \"\"\"\n+    dirname = 'data_utils'\n+\n+    with open('test.txt', 'w') as text_file:\n+        text_file.write('Float like a butterfly, sting like a bee.')\n+\n+    with tarfile.open('test.tar.gz', 'w:gz') as tar_file:\n+        tar_file.add('test.txt')\n+\n+    with zipfile.ZipFile('test.zip', 'w') as zip_file:\n+        zip_file.write('test.txt')\n+\n+    origin = urljoin('file://', pathname2url(os.path.abspath('test.tar.gz')))\n+\n+    path = get_file(dirname, origin, untar=True)\n+    filepath = path + '.tar.gz'\n+    hashval_sha256 = _hash_file(filepath)\n+    hashval_md5 = _hash_file(filepath, algorithm='md5')\n+    path = get_file(dirname, origin, md5_hash=hashval_md5, untar=True)\n+    path = get_file(filepath, origin, file_hash=hashval_sha256, extract=True)\n+    assert os.path.exists(filepath)\n+    assert validate_file(filepath, hashval_sha256)\n+    assert validate_file(filepath, hashval_md5)\n+    os.remove(filepath)\n+    os.remove('test.tar.gz')\n+\n+    origin = urljoin('file://', pathname2url(os.path.abspath('test.zip')))\n+\n+    hashval_sha256 = _hash_file('test.zip')\n+    hashval_md5 = _hash_file('test.zip', algorithm='md5')\n+    path = get_file(dirname, origin, md5_hash=hashval_md5, extract=True)\n+    path = get_file(dirname, origin, file_hash=hashval_sha256, extract=True)\n+    assert os.path.exists(path)\n+    assert validate_file(path, hashval_sha256)\n+    assert validate_file(path, hashval_md5)\n+\n+    os.remove(path)\n+    os.remove('test.txt')\n+    os.remove('test.zip')\n+\n+if __name__ == '__main__':\n+    pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0930ca9eb771ad418338a5c9d3587e977c14b398", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 37 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 2 | Methods Changed: 3 | Complexity Δ (Sum/Max): 4/3 | Churn Δ: 38 | Churn Cumulative: 9533 | Contributors (this commit): 63 | Commits (past 90d): 34 | Contributors (cumulative): 65 | DMM Complexity: 0.7307692307692307\n\nDIFF:\n@@ -213,7 +213,14 @@ def load_model(filepath, custom_objects=None):\n         if isinstance(obj, dict):\n             deserialized = {}\n             for key, value in obj.items():\n-                if value in custom_objects:\n+                deserialized[key] = []\n+                if isinstance(value, list):\n+                    for element in value:\n+                        if element in custom_objects:\n+                            deserialized[key].append(custom_objects[element])\n+                        else:\n+                            deserialized[key].append(element)\n+                elif value in custom_objects:\n                     deserialized[key] = custom_objects[value]\n                 else:\n                     deserialized[key] = value\n\n@@ -100,6 +100,35 @@ def test_fuctional_model_saving():\n     assert_allclose(out, out2, atol=1e-05)\n \n \n+@keras_test\n+def test_saving_multiple_metrics_outputs():\n+    input = Input(shape=(5,))\n+    x = Dense(5)(input)\n+    output1 = Dense(1, name='output1')(x)\n+    output2 = Dense(1, name='output2')(x)\n+\n+    model = Model(inputs=input, outputs=[output1, output2])\n+\n+    metrics = {'output1': ['mse', 'binary_accuracy'],\n+               'output2': ['mse', 'binary_accuracy']\n+               }\n+    loss = {'output1': 'mse', 'output2': 'mse'}\n+\n+    model.compile(loss=loss, optimizer='sgd', metrics=metrics)\n+\n+    # assure that model is working\n+    x = np.array([[1, 1, 1, 1, 1]])\n+    out = model.predict(x)\n+    _, fname = tempfile.mkstemp('.h5')\n+    save_model(model, fname)\n+\n+    model = load_model(fname)\n+    os.remove(fname)\n+\n+    out2 = model.predict(x)\n+    assert_allclose(out, out2, atol=1e-05)\n+\n+\n @keras_test\n def test_saving_without_compilation():\n     model = Sequential()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#655f5af76e008f2e547f3c038d3fd363fcaa844d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 765 | Contributors (this commit): 6 | Commits (past 90d): 6 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -416,7 +416,7 @@ def train(run_name, start_epoch, stop_epoch, img_w):\n         input_shape = (img_w, img_h, 1)\n \n     fdir = os.path.dirname(get_file('wordlists.tgz',\n-                                    origin='http://www.isosemi.com/datasets/wordlists.tgz', untar=True))\n+                                    origin='http://www.mythic-ai.com/datasets/wordlists.tgz', untar=True))\n \n     img_gen = TextImageGenerator(monogram_file=os.path.join(fdir, 'wordlist_mono_clean.txt'),\n                                  bigram_file=os.path.join(fdir, 'wordlist_bi_clean.txt'),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4785d51705949e72316770413ba187f07f05a5bc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 7667 | Contributors (this commit): 31 | Commits (past 90d): 52 | Contributors (cumulative): 31 | DMM Complexity: None\n\nDIFF:\n@@ -398,7 +398,7 @@ class Layer(object):\n                              str(len(input_spec)) + ' inputs, '\n                              'but it received ' + str(len(inputs)) +\n                              ' input tensors. Input received: ' +\n-                             str(input))\n+                             str(inputs))\n         for input_index, (x, spec) in enumerate(zip(inputs, input_spec)):\n             if spec is None:\n                 continue\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7c6463da6f972ffaa466b0f55d06b760a98caf8e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 140 | Contributors (this commit): 3 | Commits (past 90d): 4 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -12,8 +12,8 @@ into one, large matrix, resulting in faster computation time as the GPU can\n utilize more cores, at the expense of reduced regularization because the same\n dropout is shared across the gates.\n \n-Note that the relative performance of the different `consume_less` modes\n-can vary depending on your device, your model and the size of your data.\n+Note that the relative performance of the different implementations can\n+vary depending on your device, your model and the size of your data.\n '''\n \n import time\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ae020bfee0fe9fb0f3d505f678ade85e6f2af6de", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 6 | Methods Changed: 4 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 10 | Churn Cumulative: 16763 | Contributors (this commit): 86 | Commits (past 90d): 85 | Contributors (cumulative): 93 | DMM Complexity: None\n\nDIFF:\n@@ -2393,7 +2393,7 @@ class Container(Layer):\n             output_tensors.append(layer_output_tensors[tensor_index])\n         return cls(inputs=input_tensors, outputs=output_tensors, name=name)\n \n-    def save(self, filepath, overwrite=True):\n+    def save(self, filepath, overwrite=True, include_optimizer=True):\n         \"\"\"Save the model to a single HDF5 file.\n \n         The savefile includes:\n@@ -2414,6 +2414,7 @@ class Container(Layer):\n             filepath: String, path to the file to save the weights to.\n             overwrite: Whether to silently overwrite any existing file at the\n                 target location, or provide the user with a manual prompt.\n+            include_optimizer: If True, save optimizer's state together.\n \n         # Example\n \n@@ -2429,7 +2430,7 @@ class Container(Layer):\n         ```\n         \"\"\"\n         from ..models import save_model\n-        save_model(self, filepath, overwrite)\n+        save_model(self, filepath, overwrite, include_optimizer)\n \n     def save_weights(self, filepath, overwrite=True):\n         \"\"\"Dumps all layer weights to a HDF5 file.\n\n@@ -27,7 +27,7 @@ except ImportError:\n     h5py = None\n \n \n-def save_model(model, filepath, overwrite=True):\n+def save_model(model, filepath, overwrite=True, include_optimizer=True):\n     \"\"\"Save a model to a HDF5 file.\n \n     The saved model contains:\n@@ -45,6 +45,7 @@ def save_model(model, filepath, overwrite=True):\n         overwrite: Whether we should overwrite any existing\n             model at the target location, or instead\n             ask the user with a manual prompt.\n+        include_optimizer: If True, save optimizer's state together.\n \n     # Raises\n         ImportError: if h5py is not available.\n@@ -108,7 +109,7 @@ def save_model(model, filepath, overwrite=True):\n         model_layers = model.layers\n     topology.save_weights_to_hdf5_group(model_weights_group, model_layers)\n \n-    if hasattr(model, 'optimizer'):\n+    if include_optimizer and hasattr(model, 'optimizer'):\n         if isinstance(model.optimizer, optimizers.TFOptimizer):\n             warnings.warn(\n                 'TensorFlow optimizers do not '\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
