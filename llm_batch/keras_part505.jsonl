{"custom_id": "keras#ab5d40bdcccb048a5bd0e1f9e68c96cfeee2e292", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 70 | Lines Deleted: 50 | Files Changed: 3 | Hunks: 14 | Methods Changed: 10 | Complexity Δ (Sum/Max): 9/8 | Churn Δ: 120 | Churn Cumulative: 15719 | Contributors (this commit): 39 | Commits (past 90d): 16 | Contributors (cumulative): 58 | DMM Complexity: 0.0\n\nDIFF:\n@@ -213,21 +213,10 @@ class ObjectPathMappingTest(test_util.DTensorBaseTest):\n \n         # Also make sure we repopulate the cached attributes like\n         # layer._trainable_weights\n-        # TODO(b/234770465): Check the order of trainable_weights.\n-        self.assertLen(d1.trainable_weights, 2)\n-        self.assertIsInstance(\n-            d1.trainable_weights[0], tf.experimental.dtensor.DVariable\n-        )\n-        self.assertIsInstance(\n-            d1.trainable_weights[1], tf.experimental.dtensor.DVariable\n-        )\n-        self.assertLen(d2.trainable_weights, 2)\n-        self.assertIsInstance(\n-            d2.trainable_weights[0], tf.experimental.dtensor.DVariable\n-        )\n-        self.assertIsInstance(\n-            d2.trainable_weights[1], tf.experimental.dtensor.DVariable\n-        )\n+        self.assertIs(d1.kernel, d1._trainable_weights[0])\n+        self.assertIs(d1.bias, d1._trainable_weights[1])\n+        self.assertIs(d2.kernel, d2._trainable_weights[0])\n+        self.assertIs(d2.bias, d2._trainable_weights[1])\n \n         result = model(inputs, training=True)\n         self.assertAllClose(\n@@ -268,21 +257,10 @@ class ObjectPathMappingTest(test_util.DTensorBaseTest):\n \n         # Also make sure we repopulate the cached attributes like\n         # layer._trainable_weights\n-        # TODO(b/234770465): Check the order of trainable_weights.\n-        self.assertLen(d1.trainable_weights, 2)\n-        self.assertIsInstance(\n-            d1.trainable_weights[0], tf.experimental.dtensor.DVariable\n-        )\n-        self.assertIsInstance(\n-            d1.trainable_weights[1], tf.experimental.dtensor.DVariable\n-        )\n-        self.assertLen(d2.trainable_weights, 2)\n-        self.assertIsInstance(\n-            d2.trainable_weights[0], tf.experimental.dtensor.DVariable\n-        )\n-        self.assertIsInstance(\n-            d2.trainable_weights[1], tf.experimental.dtensor.DVariable\n-        )\n+        self.assertIs(d1.kernel, d1._trainable_weights[0])\n+        self.assertIs(d1.bias, d1._trainable_weights[1])\n+        self.assertIs(d2.kernel, d2._trainable_weights[0])\n+        self.assertIs(d2.bias, d2._trainable_weights[1])\n \n         inputs = tf.zeros((10, 10))\n         inputs = dtensor.copy_to_mesh(inputs, layout=self.layout_2d)\n@@ -324,21 +302,10 @@ class ObjectPathMappingTest(test_util.DTensorBaseTest):\n \n         # Also make sure we repopulate the cached attributes like\n         # layer._trainable_weights\n-        # TODO(b/234770465): Check the order of trainable_weights.\n-        self.assertLen(d1.trainable_weights, 2)\n-        self.assertIsInstance(\n-            d1.trainable_weights[0], tf.experimental.dtensor.DVariable\n-        )\n-        self.assertIsInstance(\n-            d1.trainable_weights[1], tf.experimental.dtensor.DVariable\n-        )\n-        self.assertLen(d2.trainable_weights, 2)\n-        self.assertIsInstance(\n-            d2.trainable_weights[0], tf.experimental.dtensor.DVariable\n-        )\n-        self.assertIsInstance(\n-            d2.trainable_weights[1], tf.experimental.dtensor.DVariable\n-        )\n+        self.assertIs(d1.kernel, d1._trainable_weights[0])\n+        self.assertIs(d1.bias, d1._trainable_weights[1])\n+        self.assertIs(d2.kernel, d2._trainable_weights[0])\n+        self.assertIs(d2.bias, d2._trainable_weights[1])\n \n         inputs = tf.zeros((10, 10))\n         inputs = dtensor.copy_to_mesh(inputs, layout=self.layout_2d)\n\n@@ -3167,6 +3167,37 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n         reference_counts = self._obj_reference_counts\n         reference_counts[value] = reference_counts.get(value, 0) + 1\n \n+        # When replacing an existing tf.Variable with a new one, we want to\n+        # check its existing position in the\n+        # self._trainable/non_trainable_variable, so that we can put it back to\n+        # the original position.\n+        if isinstance(value, tf.Variable) and isinstance(\n+            getattr(self, name, None), tf.Variable\n+        ):\n+            existing_variable = getattr(self, name)\n+\n+            def _get_variable_from_list(var_list, var):\n+                # helper function to get the tf.variable from the list\n+                # the default list.index() use == for comparison, which will\n+                # cause issue for eager tensor.\n+                for i in range(len(var_list)):\n+                    if var_list[i] is var:\n+                        return i\n+                return None\n+\n+            if existing_variable.trainable:\n+                self._maybe_create_attribute(\"_trainable_weights\", [])\n+                position = _get_variable_from_list(\n+                    self._trainable_weights, existing_variable\n+                )\n+            else:\n+                self._maybe_create_attribute(\"_non_trainable_variable\", [])\n+                position = _get_variable_from_list(\n+                    self._non_trainable_variable, existing_variable\n+                )\n+        else:\n+            position = None\n+\n         # Clean out the old attribute, which clears _layers and\n         # _trainable_weights if necessary.\n         try:\n@@ -3200,7 +3231,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n         # Append value to list of trainable / non-trainable weights if relevant\n         # TODO(b/125122625): This won't pick up on any variables added to a\n         # list/dict after creation.\n-        self._track_variables(value)\n+        self._track_variables(value, position=position)\n \n         # TODO(b/180760306) Skip the auto trackable from tf.Module to keep\n         # status quo. See the comment at __delattr__.\n@@ -3216,19 +3247,19 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n             ):\n                 self._track_variables(trackable_obj)\n \n-    def _track_variables(self, value):\n+    def _track_variables(self, value, position=None):\n         \"\"\"Tracks `Variable`s including `Variable`s in `CompositeTensor`s.\"\"\"\n         for val in tf.nest.flatten(value):\n             if isinstance(val, tf.Variable):\n-                self._track_variable(val)\n+                self._track_variable(val, position=position)\n             elif tf_utils.is_extension_type(val):\n                 # Manually expand extension types to track resource variables.\n                 nested_vals = tf_utils.type_spec_from_value(val)._to_components(\n                     val\n                 )\n-                self._track_variables(nested_vals)\n+                self._track_variables(nested_vals, position=position)\n \n-    def _track_variable(self, val):\n+    def _track_variable(self, val, position=None):\n         \"\"\"Tracks the given `tf.Variable`.\"\"\"\n         # Users may add extra weights/variables simply by assigning them to\n         # attributes (invalid for graph networks)\n@@ -3237,11 +3268,17 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n         if val.trainable:\n             if any(val is w for w in self._trainable_weights):\n                 return\n+            if position is None:\n                 self._trainable_weights.append(val)\n+            else:\n+                self._trainable_weights.insert(position, val)\n         else:\n             if any(val is w for w in self._non_trainable_weights):\n                 return\n+            if position is None:\n                 self._non_trainable_weights.append(val)\n+            else:\n+                self._non_trainable_weights.insert(position, val)\n         backend.track_variable(val)\n \n     def _gather_children_attribute(self, attribute):\n\n@@ -326,6 +326,22 @@ class BaseLayerTest(test_combinations.TestCase):\n         )\n         self.assertIs(variable, added)\n \n+    def test_variable_resetting(self):\n+        dense = layers.Dense(1)\n+        dense.build([8, 2])\n+\n+        self.assertIs(dense.trainable_variables[0], dense.kernel)\n+        self.assertIs(dense.trainable_variables[1], dense.bias)\n+\n+        # when we reset the variable to another instance, make sure the ordering\n+        # of the variable in the trainable_variables doesn't change.\n+        # This is important for h5 saving/loading.\n+        dense.bias = tf.Variable(initial_value=tf.zeros(shape=(1,)))\n+        dense.kernel = tf.Variable(initial_value=tf.zeros(shape=(2, 1)))\n+\n+        self.assertIs(dense.trainable_variables[0], dense.kernel)\n+        self.assertIs(dense.trainable_variables[1], dense.bias)\n+\n     @test_combinations.generate(\n         test_combinations.keras_mode_combinations(mode=[\"eager\"])\n     )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#94a6581d8016bb5362020770fbe893c72c3ef42a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 1738 | Contributors (this commit): 9 | Commits (past 90d): 11 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -966,7 +966,7 @@ class SequenceFeaturesSavingTest(tf.test.TestCase, parameterized.TestCase):\n             indices_a, values_a, (batch_size, timesteps, 1)\n         )\n \n-        values_b = np.zeros(10, dtype=np.str)\n+        values_b = np.zeros(10, dtype=str)\n         indices_b = np.zeros((10, 3), dtype=np.int64)\n         indices_b[:, 0] = np.arange(10)\n         inputs_b = tf.SparseTensor(\n\n@@ -384,7 +384,7 @@ class TestJson(test_combinations.TestCase):\n             indices_a, values_a, (batch_size, timesteps, 1)\n         )\n \n-        values_b = np.zeros(10, dtype=np.str)\n+        values_b = np.zeros(10, dtype=str)\n         indices_b = np.zeros((10, 3), dtype=np.int64)\n         indices_b[:, 0] = np.arange(10)\n         inputs_b = tf.SparseTensor(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#083b2131f67daffdc20ca84eb4e752b199ca88bf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 3 | Churn Cumulative: 2655 | Contributors (this commit): 20 | Commits (past 90d): 1 | Contributors (cumulative): 20 | DMM Complexity: 0.0\n\nDIFF:\n@@ -72,6 +72,9 @@ def handle_partial_sample_weights(\n       Tuple of sample weights, one sample weight for every output, and booleans\n       describing the raw sample weights.\n     \"\"\"\n+    if not isinstance(sample_weights, (list, tuple)):\n+        sample_weights = (sample_weights,)\n+\n     any_sample_weight = sample_weights is not None and any(\n         w is not None for w in sample_weights\n     )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4cf0df5976c60666a61292827f78e73d3bb2ad6b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 772 | Contributors (this commit): 7 | Commits (past 90d): 2 | Contributors (cumulative): 7 | DMM Complexity: 1.0\n\nDIFF:\n@@ -46,7 +46,6 @@ def audio_dataset_from_directory(\n     validation_split=None,\n     subset=None,\n     follow_links=False,\n-    verbose=1,\n ):\n     \"\"\"Generates a `tf.data.Dataset` from audio files in a directory.\n \n@@ -108,8 +107,6 @@ def audio_dataset_from_directory(\n         \"both\". Only used if `validation_split` is set.\n       follow_links: Whether to visits subdirectories pointed to by symlinks.\n         Defaults to False.\n-      verbose: 0 or 1. Verbosity mode.\n-          0 = silent, 1 = print how many files and classes were found.\n \n     Returns:\n       A `tf.data.Dataset` object.\n@@ -197,7 +194,6 @@ def audio_dataset_from_directory(\n         shuffle=shuffle,\n         seed=seed,\n         follow_links=follow_links,\n-        verbose=verbose,\n     )\n \n     if label_mode == \"binary\" and len(class_names) != 2:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f47bfc910865543e48dff2492d041bc7d4b3fc78", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 291 | Contributors (this commit): 11 | Commits (past 90d): 3 | Contributors (cumulative): 11 | DMM Complexity: 1.0\n\nDIFF:\n@@ -47,7 +47,6 @@ def image_dataset_from_directory(\n     interpolation=\"bilinear\",\n     follow_links=False,\n     crop_to_aspect_ratio=False,\n-    verbose=1,\n     **kwargs,\n ):\n     \"\"\"Generates a `tf.data.Dataset` from image files in a directory.\n@@ -129,8 +128,6 @@ def image_dataset_from_directory(\n         largest possible window in the image (of size `image_size`) that matches\n         the target aspect ratio. By default (`crop_to_aspect_ratio=False`),\n         aspect ratio may not be preserved.\n-      verbose: 0 or 1. Verbosity mode.\n-          0 = silent, 1 = print how many files and classes were found.\n       **kwargs: Legacy keyword arguments.\n \n     Returns:\n@@ -218,7 +215,6 @@ def image_dataset_from_directory(\n         shuffle=shuffle,\n         seed=seed,\n         follow_links=follow_links,\n-        verbose=verbose,\n     )\n \n     if label_mode == \"binary\" and len(class_names) != 2:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7af9b8ca5fc3acd819e1a383ed4439d5b8d44c00", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 225 | Contributors (this commit): 8 | Commits (past 90d): 2 | Contributors (cumulative): 8 | DMM Complexity: 1.0\n\nDIFF:\n@@ -40,7 +40,6 @@ def text_dataset_from_directory(\n     validation_split=None,\n     subset=None,\n     follow_links=False,\n-    verbose=1,\n ):\n     \"\"\"Generates a `tf.data.Dataset` from text files in a directory.\n \n@@ -106,8 +105,6 @@ def text_dataset_from_directory(\n           (the training and validation datasets respectively).\n       follow_links: Whether to visits subdirectories pointed to by symlinks.\n           Defaults to False.\n-      verbose: 0 or 1. Verbosity mode.\n-          0 = silent, 1 = print how many files and classes were found.\n \n     Returns:\n       A `tf.data.Dataset` object.\n@@ -166,7 +163,6 @@ def text_dataset_from_directory(\n         shuffle=shuffle,\n         seed=seed,\n         follow_links=follow_links,\n-        verbose=verbose,\n     )\n \n     if label_mode == \"binary\" and len(class_names) != 2:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d68aac7f864bd2ca506e44ad5ebd0de65c73cc7f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 4 | Churn Cumulative: 1820 | Contributors (this commit): 10 | Commits (past 90d): 4 | Contributors (cumulative): 10 | DMM Complexity: 1.0\n\nDIFF:\n@@ -493,7 +493,6 @@ def index_directory(\n     shuffle=True,\n     seed=None,\n     follow_links=False,\n-    verbose=1,\n ):\n     \"\"\"Make list of all files in the subdirs of `directory`, with their labels.\n \n@@ -515,8 +514,6 @@ def index_directory(\n           If set to False, sorts the data in alphanumeric order.\n       seed: Optional random seed for shuffling.\n       follow_links: Whether to visits subdirectories pointed to by symlinks.\n-      verbose: 0 or 1. Verbosity mode.\n-          0 = silent, 1 = print how many files and classes were found.\n \n     Returns:\n       tuple (file_paths, labels, class_names).\n@@ -580,7 +577,6 @@ def index_directory(\n             labels[i : i + len(partial_labels)] = partial_labels\n             i += len(partial_labels)\n \n-    if verbose:\n     if labels is None:\n         print(f\"Found {len(filenames)} files.\")\n     else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b2e4b0485304705dc4e4ea22710b5b79eac90ced", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 1826 | Contributors (this commit): 10 | Commits (past 90d): 5 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -23,6 +23,8 @@ import warnings\n import numpy as np\n import tensorflow.compat.v2 as tf\n \n+from keras.utils import io_utils\n+\n # isort: off\n from tensorflow.python.util.tf_export import keras_export\n \n@@ -578,9 +580,9 @@ def index_directory(\n             i += len(partial_labels)\n \n     if labels is None:\n-        print(f\"Found {len(filenames)} files.\")\n+        io_utils.print_msg(f\"Found {len(filenames)} files.\")\n     else:\n-        print(\n+        io_utils.print_msg(\n             f\"Found {len(filenames)} files belonging \"\n             f\"to {len(class_names)} classes.\"\n         )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bf63270b3277bec3edd2897ee38964fe52078b72", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 202 | Contributors (this commit): 6 | Commits (past 90d): 3 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -58,7 +58,7 @@ setuptools.setup(\n     packages=setuptools.find_packages(),\n     install_requires=REQUIRED_PACKAGES,\n     # Supported Python versions\n-    python_requires=\">=3.7\",\n+    python_requires=\">=3.8\",\n     # PyPI package information.\n     classifiers=[\n         \"Development Status :: 5 - Production/Stable\",\n@@ -67,10 +67,10 @@ setuptools.setup(\n         \"Intended Audience :: Science/Research\",\n         \"License :: OSI Approved :: Apache Software License\",\n         \"Programming Language :: Python :: 3\",\n-        \"Programming Language :: Python :: 3.7\",\n         \"Programming Language :: Python :: 3.8\",\n         \"Programming Language :: Python :: 3.9\",\n         \"Programming Language :: Python :: 3.10\",\n+        \"Programming Language :: Python :: 3.11\",\n         \"Programming Language :: Python :: 3 :: Only\",\n         \"Topic :: Scientific/Engineering\",\n         \"Topic :: Scientific/Engineering :: Mathematics\",\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ab02bd5c8d75a9c8cc9f78cc7cdb5e7a01307588", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 11 | Files Changed: 7 | Hunks: 11 | Methods Changed: 11 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 22 | Churn Cumulative: 7111 | Contributors (this commit): 26 | Commits (past 90d): 9 | Contributors (cumulative): 61 | DMM Complexity: None\n\nDIFF:\n@@ -497,7 +497,7 @@ class GRUGraphRewriteTest(test_combinations.TestCase):\n         units = 4\n \n         inputs = np.random.randn(batch_size, timestep, units).astype(np.float32)\n-        mask = np.ones((batch_size, timestep)).astype(np.bool)\n+        mask = np.ones((batch_size, timestep)).astype(bool)\n         mask[:, masksteps:] = 0\n \n         gru_layer = keras.layers.GRU(\n\n@@ -156,7 +156,7 @@ class GRUGraphRewriteTest(test_combinations.TestCase):\n         units = 4\n \n         inputs = np.random.randn(batch_size, timestep, units).astype(np.float32)\n-        mask = np.ones((batch_size, timestep)).astype(np.bool)\n+        mask = np.ones((batch_size, timestep)).astype(bool)\n         mask[:, masksteps:] = 0\n \n         gru_layer = gru_v1.GRU(units, return_sequences=True, go_backwards=True)\n\n@@ -696,7 +696,7 @@ class LSTMGraphRewriteTest(test_combinations.TestCase):\n         units = 4\n \n         inputs = np.random.randn(batch_size, timestep, units).astype(np.float32)\n-        mask = np.ones((batch_size, timestep)).astype(np.bool)\n+        mask = np.ones((batch_size, timestep)).astype(bool)\n         mask[:, masksteps:] = 0\n \n         lstm_layer = keras.layers.LSTM(\n\n@@ -185,7 +185,7 @@ class LSTMGraphRewriteTest(test_combinations.TestCase):\n         units = 4\n \n         inputs = np.random.randn(batch_size, timestep, units).astype(np.float32)\n-        mask = np.ones((batch_size, timestep)).astype(np.bool)\n+        mask = np.ones((batch_size, timestep)).astype(bool)\n         mask[:, masksteps:] = 0\n \n         lstm_v1_layer = lstm_v1.LSTM(\n\n@@ -315,7 +315,7 @@ def conv_kernel_mask(input_shape, kernel_shape, strides, padding):\n     )\n \n     mask_shape = input_shape + output_shape\n-    mask = np.zeros(mask_shape, np.bool)\n+    mask = np.zeros(mask_shape, bool)\n \n     output_axes_ticks = [range(dim) for dim in output_shape]\n     for output_position in itertools.product(*output_axes_ticks):\n\n@@ -243,7 +243,7 @@ class TestConvUtils(tf.test.TestCase, parameterized.TestCase):\n         ndims = len(input_shape)\n         strides = (1,) * ndims\n         output_shape = _get_const_output_shape(input_shape, dim=1)\n-        mask = np.ones(input_shape + output_shape, np.bool)\n+        mask = np.ones(input_shape + output_shape, bool)\n         self.assertAllEqual(\n             mask,\n             conv_utils.conv_kernel_mask(\n@@ -257,7 +257,7 @@ class TestConvUtils(tf.test.TestCase, parameterized.TestCase):\n         strides = (1,) * ndims\n \n         for padding in [\"valid\", \"same\"]:\n-            mask = np.identity(int(np.prod(input_shape)), np.bool)\n+            mask = np.identity(int(np.prod(input_shape)), bool)\n             mask = np.reshape(mask, input_shape * 2)\n             self.assertAllEqual(\n                 mask,\n@@ -273,7 +273,7 @@ class TestConvUtils(tf.test.TestCase, parameterized.TestCase):\n         strides = tuple([max(d, 1) for d in input_shape])\n         output_shape = _get_const_output_shape(input_shape, dim=1)\n \n-        mask = np.zeros(input_shape + output_shape, np.bool)\n+        mask = np.zeros(input_shape + output_shape, bool)\n         if all(d > 0 for d in mask.shape):\n             mask[(0,) * len(output_shape)] = True\n \n@@ -291,7 +291,7 @@ class TestConvUtils(tf.test.TestCase, parameterized.TestCase):\n         strides = tuple([max(d - 1, 1) for d in input_shape])\n         output_shape = _get_const_output_shape(input_shape, dim=2)\n \n-        mask = np.zeros(input_shape + output_shape, np.bool)\n+        mask = np.zeros(input_shape + output_shape, bool)\n         if all(d > 0 for d in mask.shape):\n             for in_position in itertools.product(\n                 *[[0, d - 1] for d in input_shape]\n@@ -318,7 +318,7 @@ class TestConvUtils(tf.test.TestCase, parameterized.TestCase):\n             output_shape = list(input_shape)\n             output_shape[d] = min(1, input_shape[d])\n \n-            mask = np.identity(int(np.prod(input_shape)), np.bool)\n+            mask = np.identity(int(np.prod(input_shape)), bool)\n             mask = np.reshape(mask, input_shape * 2)\n \n             for p in itertools.product(\n\n@@ -379,7 +379,7 @@ class TestImageLoading(test_combinations.TestCase):\n         loaded_im_array = image_utils.img_to_array(loaded_im)\n         self.assertEqual(loaded_im_array.shape, (25, 25, 3))\n \n-        red_channel_arr = loaded_im_array[:, :, 0].astype(np.bool)\n+        red_channel_arr = loaded_im_array[:, :, 0].astype(bool)\n         square_width = np.sum(np.sum(red_channel_arr, axis=0))\n         square_height = np.sum(np.sum(red_channel_arr, axis=1))\n         aspect_ratio_result = square_width / square_height\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ca17b535bcd66e98567966d20d14280399b32fac", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 10 | Churn Cumulative: 10844 | Contributors (this commit): 24 | Commits (past 90d): 9 | Contributors (cumulative): 24 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2153,13 +2153,21 @@ class RandomGenerator(tf.__internal__.tracking.AutoTrackable):\n \n     def dropout(self, inputs, rate, noise_shape=None):\n         self._maybe_init()\n-        if self._rng_type in [self.RNG_STATEFUL, self.RNG_STATELESS]:\n+        if self._rng_type == self.RNG_STATEFUL:\n+            return tf.nn.experimental.general_dropout(\n+                inputs,\n+                rate=rate,\n+                noise_shape=noise_shape,\n+                uniform_sampler=self._generator.uniform,\n+            )\n+        elif self._rng_type == self.RNG_STATELESS:\n             return tf.nn.experimental.stateless_dropout(\n                 inputs,\n                 rate=rate,\n                 noise_shape=noise_shape,\n                 seed=self.make_seed_for_stateless_op(),\n             )\n+        else:\n             return tf.nn.dropout(\n                 inputs,\n                 rate=rate,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#30e8b0373a57fa29e605a1896f90e7b3c4e279d2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 12 | Files Changed: 2 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 13 | Churn Cumulative: 12302 | Contributors (this commit): 38 | Commits (past 90d): 15 | Contributors (cumulative): 46 | DMM Complexity: 0.0\n\nDIFF:\n@@ -2153,21 +2153,13 @@ class RandomGenerator(tf.__internal__.tracking.AutoTrackable):\n \n     def dropout(self, inputs, rate, noise_shape=None):\n         self._maybe_init()\n-        if self._rng_type == self.RNG_STATEFUL:\n-            return tf.nn.experimental.general_dropout(\n-                inputs,\n-                rate=rate,\n-                noise_shape=noise_shape,\n-                uniform_sampler=self._generator.uniform,\n-            )\n-        elif self._rng_type == self.RNG_STATELESS:\n+        if self._rng_type in [self.RNG_STATEFUL, self.RNG_STATELESS]:\n             return tf.nn.experimental.stateless_dropout(\n                 inputs,\n                 rate=rate,\n                 noise_shape=noise_shape,\n                 seed=self.make_seed_for_stateless_op(),\n             )\n-        else:\n         return tf.nn.dropout(\n             inputs,\n             rate=rate,\n\n@@ -158,9 +158,6 @@ from keras.layers.reshaping.zero_padding1d import ZeroPadding1D\n from keras.layers.reshaping.zero_padding2d import ZeroPadding2D\n from keras.layers.reshaping.zero_padding3d import ZeroPadding3D\n \n-# isort: off\n-from tensorflow.python import tf2\n-\n if tf.__internal__.tf2.enabled():\n     from keras.layers.normalization.batch_normalization import (\n         BatchNormalization,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fb9a667ef21e3920983cbe12f99c368643357249", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 2361 | Contributors (this commit): 5 | Commits (past 90d): 1 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -737,6 +737,7 @@ def MBConvBlock(\n                     name=name + \"drop\",\n                 )(x)\n             x = layers.add([x, inputs], name=name + \"add\")\n+\n         return x\n \n     return apply\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#799f70761eeb8155dc25c6afce8c1d22b38367b0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 195 | Lines Deleted: 4 | Files Changed: 6 | Hunks: 20 | Methods Changed: 17 | Complexity Δ (Sum/Max): 22/16 | Churn Δ: 199 | Churn Cumulative: 3226 | Contributors (this commit): 12 | Commits (past 90d): 12 | Contributors (cumulative): 22 | DMM Complexity: 0.9473684210526315\n\nDIFF:\n@@ -210,7 +210,10 @@ def assert_input_compatibility(input_spec, inputs, layer_name):\n         # invalid type we are guarding for is a Layer instance (Functional API),\n         # which does not have a `shape` attribute.\n         if not hasattr(x, \"shape\"):\n-            raise TypeError(f\"Inputs to a layer should be tensors. Got: {x}\")\n+            raise TypeError(\n+                f\"Inputs to a layer should be tensors. Got '{x}' \"\n+                f\"(of type {type(x)}) as input for layer '{layer_name}'.\"\n+            )\n \n     if len(inputs) != len(input_spec):\n         raise ValueError(\n\n@@ -384,3 +384,8 @@ class Normalization(base_preprocessing_layer.PreprocessingLayer):\n         if inputs.dtype != self.compute_dtype:\n             inputs = tf.cast(inputs, self.compute_dtype)\n         return inputs\n+\n+    def _load_own_variables(self, store):\n+        # Ensure that we call finalize_state after variable loading.\n+        super()._load_own_variables(store)\n+        self.finalize_state()\n\n@@ -74,6 +74,7 @@ ATTR_SKIPLIST = frozenset(\n         \"_self_name_based_restores\",\n         \"_self_saveable_object_factories\",\n         \"_self_tracked_trackables\",\n+        \"_saved_model_inputs_spec\",\n         \"_self_unconditional_checkpoint_dependencies\",\n         \"_self_unconditional_deferred_dependencies\",\n         \"_self_unconditional_dependency_names\",\n@@ -86,6 +87,9 @@ ATTR_SKIPLIST = frozenset(\n         \"_updates\",\n         \"_layer_call_argspecs\",\n         \"inbound_nodes\",\n+        \"outbound_nodes\",\n+        \"input_shape\",\n+        \"output_shape\",\n         \"submodules\",\n         \"weights\",\n         \"non_trainable_weights\",\n@@ -460,6 +464,9 @@ def _save_container_state(\n     container, weights_store, assets_store, inner_path, visited_trackables\n ):\n     used_names = {}\n+    if isinstance(container, dict):\n+        container = list(container.values())\n+\n     for trackable in container:\n         if _is_keras_trackable(trackable):\n             # Do NOT address the trackable via `trackable.name`, since\n@@ -489,6 +496,9 @@ def _load_container_state(\n     visited_trackables,\n ):\n     used_names = {}\n+    if isinstance(container, dict):\n+        container = list(container.values())\n+\n     for trackable in container:\n         if _is_keras_trackable(trackable):\n             name = generic_utils.to_snake_case(trackable.__class__.__name__)\n\n@@ -702,6 +702,38 @@ class SavingV3Test(tf.test.TestCase, parameterized.TestCase):\n             model = saving_lib.load_model(temp_filepath)\n         model = saving_lib.load_model(temp_filepath, safe_mode=False)\n \n+    def test_normalization_kpl(self):\n+        # With adapt\n+        temp_filepath = os.path.join(self.get_temp_dir(), \"norm_model.keras\")\n+        model = keras.Sequential(\n+            [\n+                keras.Input(shape=(3,)),\n+                keras.layers.Normalization(),\n+            ]\n+        )\n+        data = np.random.random((3, 3))\n+        model.layers[0].adapt(data)\n+        ref_out = model(data)\n+        model.save(temp_filepath, save_format=\"keras_v3\")\n+        model = saving_lib.load_model(temp_filepath)\n+        out = model(data)\n+        self.assertAllClose(ref_out, out, atol=1e-6)\n+\n+        # Without adapt\n+        model = keras.Sequential(\n+            [\n+                keras.Input(shape=(3,)),\n+                keras.layers.Normalization(\n+                    mean=np.random.random((3,)), variance=np.random.random((3,))\n+                ),\n+            ]\n+        )\n+        ref_out = model(data)\n+        model.save(temp_filepath, save_format=\"keras_v3\")\n+        model = saving_lib.load_model(temp_filepath)\n+        out = model(data)\n+        self.assertAllClose(ref_out, out, atol=1e-6)\n+\n \n if __name__ == \"__main__\":\n     tf.test.main()\n\n@@ -17,6 +17,9 @@\n import tensorflow.compat.v2 as tf\n \n from keras import backend\n+from keras.engine import base_layer\n+from keras.saving import saving_lib\n+from keras.saving import serialization_lib\n from keras.utils.generic_utils import LazyLoader\n \n # isort: off\n@@ -41,6 +44,17 @@ class Cross:\n     def name(self):\n         return \"_X_\".join(self.feature_names)\n \n+    def get_config(self):\n+        return {\n+            \"feature_names\": self.feature_names,\n+            \"crossing_dim\": self.crossing_dim,\n+            \"output_mode\": self.output_mode,\n+        }\n+\n+    @classmethod\n+    def from_config(cls, config):\n+        return cls(**config)\n+\n \n class Feature:\n     def __init__(self, dtype, preprocessor, output_mode):\n@@ -51,12 +65,29 @@ class Feature:\n                 f\"Received: output_mode={output_mode}\"\n             )\n         self.dtype = dtype\n+        if isinstance(preprocessor, dict):\n+            preprocessor = serialization_lib.deserialize_keras_object(\n+                preprocessor\n+            )\n         self.preprocessor = preprocessor\n         self.output_mode = output_mode\n \n+    def get_config(self):\n+        return {\n+            \"dtype\": self.dtype,\n+            \"preprocessor\": serialization_lib.serialize_keras_object(\n+                self.preprocessor\n+            ),\n+            \"output_mode\": self.output_mode,\n+        }\n+\n+    @classmethod\n+    def from_config(cls, config):\n+        return cls(**config)\n+\n \n @keras_export(\"keras.utils.FeatureSpace\", v1=[])\n-class FeatureSpace:\n+class FeatureSpace(base_layer.Layer):\n     \"\"\"One-stop utility for preprocessing and encoding structured data.\n \n     Arguments:\n@@ -245,6 +276,13 @@ class FeatureSpace:\n     # It's an instance of keras.layers.HashedCrossing.\n     crossing_layer = feature_space.crossers[\"feature1_X_feature2\"]\n     ```\n+\n+    **Saving and reloading a FeatureSpace:**\n+\n+    ```python\n+    feature_space.save(\"myfeaturespace.keras\")\n+    reloaded_feature_space = keras.models.load_model(\"myfeaturespace.keras\")\n+    ```\n     \"\"\"\n \n     @classmethod\n@@ -257,9 +295,11 @@ class FeatureSpace:\n \n     @classmethod\n     def float(cls, name=None):\n+        from keras.layers.core import identity\n+\n         name = name or backend.unique_object_name(\"float\")\n-        preprocessor = lambda x: tf.cast(\n-            x, dtype=\"float32\", name=f\"{name}_preprocessor\"\n+        preprocessor = identity.Identity(\n+            dtype=\"float32\", name=f\"{name}_preprocessor\"\n         )\n         return Feature(\n             dtype=\"float32\", preprocessor=preprocessor, output_mode=\"float\"\n@@ -377,6 +417,8 @@ class FeatureSpace:\n         if crosses:\n             feature_set = set(features.keys())\n             for cross in crosses:\n+                if isinstance(cross, dict):\n+                    cross = serialization_lib.deserialize_keras_object(cross)\n                 if isinstance(cross, Cross):\n                     self.crosses.append(cross)\n                 else:\n@@ -431,6 +473,9 @@ class FeatureSpace:\n         if isinstance(feature, Feature):\n             return feature\n \n+        if isinstance(feature, dict):\n+            return serialization_lib.deserialize_keras_object(feature)\n+\n         if feature == \"float\":\n             return self.float(name=name)\n         elif feature == \"float_normalized\":\n@@ -682,3 +727,46 @@ class FeatureSpace:\n                     if x.shape.rank == 2 and x.shape[0] == 1:\n                         merged_data[name] = tf.squeeze(x, axis=0)\n         return merged_data\n+\n+    def get_config(self):\n+        return {\n+            \"features\": serialization_lib.serialize_keras_object(self.features),\n+            \"output_mode\": self.output_mode,\n+            \"crosses\": serialization_lib.serialize_keras_object(self.crosses),\n+            \"crossing_dim\": self.crossing_dim,\n+            \"hashing_dim\": self.hashing_dim,\n+            \"num_discretization_bins\": self.num_discretization_bins,\n+        }\n+\n+    @classmethod\n+    def from_config(cls, config):\n+        return cls(**config)\n+\n+    def get_build_config(self):\n+        return {\n+            name: feature.preprocessor.get_build_config()\n+            for name, feature in self.features.items()\n+        }\n+\n+    def build_from_config(self, config):\n+        for name in config.keys():\n+            self.features[name].preprocessor.build_from_config(config[name])\n+        self._is_adapted = True\n+\n+    def save(self, filepath):\n+        \"\"\"Save the `FeatureSpace` instance to a `.keras` file.\n+\n+        You can reload it via `keras.models.load_model()`:\n+\n+        ```python\n+        feature_space.save(\"myfeaturespace.keras\")\n+        reloaded_feature_space = keras.models.load_model(\"myfeaturespace.keras\")\n+        ```\n+        \"\"\"\n+        saving_lib.save_model(self, filepath)\n+\n+    def _save_own_variables(self, store):\n+        return\n+\n+    def _load_own_variables(self, store):\n+        return\n\n@@ -14,6 +14,8 @@\n # ==============================================================================\n \"\"\"Tests for FeatureSpace utility.\"\"\"\n \n+import os\n+\n import tensorflow.compat.v2 as tf\n \n import keras\n@@ -290,6 +292,57 @@ class FeatureSpaceTest(test_combinations.TestCase):\n         out = fs(data)\n         self.assertEqual(out.shape.as_list(), [10, 32])\n \n+    def test_saving(self):\n+        cls = feature_space.FeatureSpace\n+        fs = feature_space.FeatureSpace(\n+            features={\n+                \"float_1\": cls.float(),\n+                \"float_2\": cls.float_normalized(),\n+                \"float_3\": cls.float_discretized(num_bins=3),\n+                \"string_1\": cls.string_categorical(max_tokens=5),\n+                \"string_2\": cls.string_hashed(num_bins=32),\n+                \"int_1\": cls.integer_categorical(\n+                    max_tokens=5, num_oov_indices=2\n+                ),\n+                \"int_2\": cls.integer_hashed(num_bins=32),\n+                \"int_3\": cls.integer_categorical(max_tokens=5),\n+            },\n+            crosses=[\n+                cls.cross((\"float_3\", \"string_1\"), crossing_dim=32),\n+                cls.cross((\"string_2\", \"int_2\"), crossing_dim=32),\n+            ],\n+            output_mode=\"concat\",\n+        )\n+        fs.adapt(self._get_train_data_dict(as_dataset=True))\n+        data = {\n+            key: value[0] for key, value in self._get_train_data_dict().items()\n+        }\n+        ref_out = fs(data)\n+\n+        temp_filepath = os.path.join(self.get_temp_dir(), \"fs.keras\")\n+        fs.save(temp_filepath)\n+        fs = keras.models.load_model(temp_filepath)\n+\n+        # Save again immediately after loading to test idempotency\n+        temp_filepath = os.path.join(self.get_temp_dir(), \"fs2.keras\")\n+        fs.save(temp_filepath)\n+\n+        # Test correctness of the first saved FS\n+        out = fs(data)\n+        self.assertAllClose(out, ref_out)\n+\n+        inputs = fs.get_inputs()\n+        outputs = fs.get_encoded_features()\n+        model = keras.Model(inputs=inputs, outputs=outputs)\n+        ds = self._get_train_data_dict(as_dataset=True)\n+        out = model.predict(ds.batch(4))\n+        self.assertAllClose(out[0], ref_out)\n+\n+        # Test correctness of the re-saved FS\n+        fs = keras.models.load_model(temp_filepath)\n+        out = fs(data)\n+        self.assertAllClose(out, ref_out)\n+\n     def test_errors(self):\n         # Test no features\n         with self.assertRaisesRegex(ValueError, \"cannot be None or empty\"):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1b32391798a952176b733660c940b1589c2fc8a4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 41 | Lines Deleted: 3 | Files Changed: 4 | Hunks: 10 | Methods Changed: 6 | Complexity Δ (Sum/Max): 12/4 | Churn Δ: 44 | Churn Cumulative: 22724 | Contributors (this commit): 142 | Commits (past 90d): 29 | Contributors (cumulative): 162 | DMM Complexity: 0.7307692307692307\n\nDIFF:\n@@ -697,6 +697,8 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n               for more details.\n             **kwargs: Arguments supported for backwards compatibility only.\n         \"\"\"\n+        if jit_compile and not tf_utils.can_jit_compile(warn=True):\n+            jit_compile = False\n         base_layer.keras_api_gauge.get_cell(\"compile\").set(True)\n         self._compile_config = serialization_lib.Config(\n             optimizer=optimizer,\n@@ -957,9 +959,12 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n         if self._jit_compile == value:\n             # Avoid reseting compiler cache if possible if the value is the same\n             return\n+        # Check if TensorFlow is compiled with XLA before setting the value\n+        if value and not tf_utils.can_jit_compile(warn=True):\n+            self._jit_compile = False\n+            return\n \n         self._jit_compile = value\n-\n         # Setting `jit_compile` should invalidate previously cached functions.\n         self._reset_compile_cache()\n \n\n@@ -53,10 +53,15 @@ class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):\n         self.global_clipnorm = global_clipnorm\n         self.clipvalue = clipvalue\n         self.use_ema = use_ema\n-        self.jit_compile = jit_compile\n-        if not tf.config.list_physical_devices(\"GPU\"):\n         # Optimizer only benefits from XLA when training on GPU. So if no\n         # GPU is found, we turn off XLA.\n+        if (\n+            jit_compile\n+            and tf_utils.can_jit_compile()\n+            and tf.config.list_physical_devices(\"GPU\")\n+        ):\n+            self.jit_compile = True\n+        else:\n             self.jit_compile = False\n         if use_ema:\n             # Verify the arguments related to EMA.\n\n@@ -16,10 +16,12 @@\n \n import collections\n import copy\n+import platform\n import random\n \n import numpy as np\n import tensorflow.compat.v2 as tf\n+from absl import logging\n \n from keras import backend\n from keras.engine import keras_tensor\n@@ -675,3 +677,15 @@ def _astuple(attrs):\n     for field in fields:\n         values.append(getattr(attrs, field.name))\n     return tuple(values)\n+\n+\n+def can_jit_compile(warn=False):\n+    \"\"\"Returns True if TensorFlow XLA is available for the platform.\"\"\"\n+    if platform.system() == \"Darwin\" and \"arm\" in platform.processor().lower():\n+        if warn:\n+            logging.warning(\n+                \"Tensorflow is not compiled with XLA on Mac M1 Arm processors, \"\n+                \"so cannot set `jit_compile` to True.\"\n+            )\n+        return False\n+    return True\n\n@@ -14,6 +14,9 @@\n # ==============================================================================\n \"\"\"Tests for Keras TF utils.\"\"\"\n \n+from unittest.mock import MagicMock\n+from unittest.mock import patch\n+\n import numpy as np\n import tensorflow.compat.v2 as tf\n from absl.testing import parameterized\n@@ -470,5 +473,16 @@ class TestSyncToNumpyOrPythonType(parameterized.TestCase):\n         self.assertEqual(tf_utils.sync_to_numpy_or_python_type(tensor), value)\n \n \n+class TestCanJitCompile(tf.test.TestCase):\n+    def test_darwin_arm_xla(self):\n+        with patch(\"platform.processor\", MagicMock(return_value=\"arm\")):\n+            with patch(\"platform.system\", MagicMock(return_value=\"Darwin\")):\n+                self.assertFalse(tf_utils.can_jit_compile())\n+\n+    def test_linux_xla(self):\n+        with patch(\"platform.system\", MagicMock(return_value=\"Linux\")):\n+            self.assertTrue(tf_utils.can_jit_compile())\n+\n+\n if __name__ == \"__main__\":\n     tf.test.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c15f099eb30626100e6dbc5347ac62c929be9b80", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 15 | Churn Cumulative: 10187 | Contributors (this commit): 33 | Commits (past 90d): 14 | Contributors (cumulative): 42 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1965,7 +1965,8 @@ def categorical_crossentropy(\n             \"Recieved an one-dimensional output. \"\n             \"Consider using binary crossentropy \"\n             \"instead of categorical crossentropy \"\n-            \"if you have only 2 labels\"\n+            \"if you have only 2 labels\",\n+            SyntaxWarning,\n         )\n \n     def _smooth_labels():\n\n@@ -14,6 +14,8 @@\n # ==============================================================================\n \"\"\"Tests for Keras loss functions.\"\"\"\n \n+import warnings\n+\n import numpy as np\n import tensorflow.compat.v2 as tf\n from absl.testing import parameterized\n@@ -1794,6 +1796,16 @@ class CategoricalCrossentropyTest(tf.test.TestCase):\n         loss = cce_obj(y_true, logits, sample_weight=sample_weight)\n         self.assertAlmostEqual(self.evaluate(loss), 0.3181, 3)\n \n+    def test_binary_labels(self):\n+        # raise a warning if the shape of y_true and y_pred are all (None, 1).\n+        # categorical_crossentropy shouldn't be used with binary labels.\n+        with warnings.catch_warnings(record=True) as w:\n+            warnings.simplefilter(\"always\")\n+            cce_obj = losses.CategoricalCrossentropy()\n+            cce_obj(tf.constant([[1.0], [0.0]]), tf.constant([[1.0], [1.0]]))\n+            assert issubclass(w[-1].category, SyntaxWarning)\n+            assert \"Recieved an one-dimensional output..*\" in str(w[-1].message)\n+\n \n @test_combinations.generate(test_combinations.combine(mode=[\"graph\", \"eager\"]))\n class SparseCategoricalCrossentropyTest(tf.test.TestCase):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#eb2bbc2f845a3ac3a8895e94baed2b94d595f9d1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 6 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 14 | Churn Cumulative: 10201 | Contributors (this commit): 33 | Commits (past 90d): 16 | Contributors (cumulative): 42 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1962,10 +1962,10 @@ def categorical_crossentropy(\n \n     if y_pred.shape[-1] == 1:\n         warnings.warn(\n-            \"Recieved an one-dimensional output. \"\n-            \"Consider using binary crossentropy \"\n-            \"instead of categorical crossentropy \"\n-            \"if you have only 2 labels\",\n+            \"Expected the tensor's shape passed to 'categorical_crossentropy' \"\n+            \"to be (batch_size, n_classes), \"\n+            f\"where n_classes > 1. Received: y_pred.shape={y_pred.shape}. \"\n+            \"Consider using 'binary_crossentropy' if you only have 2 classes.\",\n             SyntaxWarning,\n         )\n \n\n@@ -1803,8 +1803,10 @@ class CategoricalCrossentropyTest(tf.test.TestCase):\n             warnings.simplefilter(\"always\")\n             cce_obj = losses.CategoricalCrossentropy()\n             cce_obj(tf.constant([[1.0], [0.0]]), tf.constant([[1.0], [1.0]]))\n-            assert issubclass(w[-1].category, SyntaxWarning)\n-            assert \"Recieved an one-dimensional output..*\" in str(w[-1].message)\n+            self.assertIsInstance(w[-1].category, SyntaxWarning)\n+            self.assertIn(\n+                \"Expected the tensor's shape passed..*\", w[-1].message\n+            )\n \n \n @test_combinations.generate(test_combinations.combine(mode=[\"graph\", \"eager\"]))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
