{"custom_id": "keras#cc3521ea93b0470e9ea11151a44c30b54d4d726a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 145 | Lines Deleted: 31 | Files Changed: 6 | Hunks: 17 | Methods Changed: 12 | Complexity Δ (Sum/Max): 16/6 | Churn Δ: 176 | Churn Cumulative: 38017 | Contributors (this commit): 186 | Commits (past 90d): 77 | Contributors (cumulative): 340 | DMM Complexity: 0.4318181818181818\n\nDIFF:\n@@ -1156,7 +1156,8 @@ def permute_dimensions(x, pattern):\n     return C.transpose(x, axis)\n \n \n-def resize_images(x, height_factor, width_factor, data_format):\n+def resize_images(x, height_factor, width_factor, data_format, interpolation='nearest'):\n+    if interpolation == 'nearest':\n         if data_format == 'channels_first':\n             output = repeat_elements(x, height_factor, axis=2)\n             output = repeat_elements(output, width_factor, axis=3)\n@@ -1166,7 +1167,9 @@ def resize_images(x, height_factor, width_factor, data_format):\n             output = repeat_elements(output, width_factor, axis=2)\n             return output\n         else:\n-        raise ValueError('CNTK Backend: Invalid data_format:', data_format)\n+            raise ValueError('CNTK Backend: Invalid data_format: %s' % data_format)\n+    else:\n+        raise NotImplementedError('CNTK only supports `nearest` interpolation.')\n \n \n def resize_volumes(x, depth_factor, height_factor, width_factor, data_format):\n@@ -1181,7 +1184,7 @@ def resize_volumes(x, depth_factor, height_factor, width_factor, data_format):\n         output = repeat_elements(output, width_factor, axis=3)\n         return output\n     else:\n-        raise ValueError('CNTK Backend: Invalid data_format:', data_format)\n+        raise ValueError('CNTK Backend: Invalid data_format: %s' % data_format)\n \n \n def repeat_elements(x, rep, axis):\n\n@@ -1963,7 +1963,11 @@ def permute_dimensions(x, pattern):\n     return tf.transpose(x, perm=pattern)\n \n \n-def resize_images(x, height_factor, width_factor, data_format):\n+def resize_images(x,\n+                  height_factor,\n+                  width_factor,\n+                  data_format,\n+                  interpolation='nearest'):\n     \"\"\"Resizes the images contained in a 4D tensor.\n \n     # Arguments\n@@ -1971,6 +1975,7 @@ def resize_images(x, height_factor, width_factor, data_format):\n         height_factor: Positive integer.\n         width_factor: Positive integer.\n         data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n+        interpolation: A string, one of `nearest` or `bilinear`.\n \n     # Returns\n         A tensor.\n@@ -1979,25 +1984,39 @@ def resize_images(x, height_factor, width_factor, data_format):\n         ValueError: if `data_format` is neither `\"channels_last\"` or `\"channels_first\"`.\n     \"\"\"\n     if data_format == 'channels_first':\n-        original_shape = int_shape(x)\n-        new_shape = tf.shape(x)[2:]\n-        new_shape *= tf.constant(np.array([height_factor, width_factor]).astype('int32'))\n-        x = permute_dimensions(x, [0, 2, 3, 1])\n-        x = tf.image.resize_nearest_neighbor(x, new_shape)\n-        x = permute_dimensions(x, [0, 3, 1, 2])\n-        x.set_shape((None, None, original_shape[2] * height_factor if original_shape[2] is not None else None,\n-                     original_shape[3] * width_factor if original_shape[3] is not None else None))\n-        return x\n-    elif data_format == 'channels_last':\n-        original_shape = int_shape(x)\n-        new_shape = tf.shape(x)[1:3]\n-        new_shape *= tf.constant(np.array([height_factor, width_factor]).astype('int32'))\n-        x = tf.image.resize_nearest_neighbor(x, new_shape)\n-        x.set_shape((None, original_shape[1] * height_factor if original_shape[1] is not None else None,\n-                     original_shape[2] * width_factor if original_shape[2] is not None else None, None))\n-        return x\n+        rows, cols = 2, 3\n     else:\n-        raise ValueError('Unknown data_format: ' + str(data_format))\n+        rows, cols = 1, 2\n+\n+    original_shape = int_shape(x)\n+    new_shape = tf.shape(x)[rows:cols + 1]\n+    new_shape *= tf.constant(np.array([height_factor, width_factor], dtype='int32'))\n+\n+    if data_format == 'channels_first':\n+        x = permute_dimensions(x, [0, 2, 3, 1])\n+    if interpolation == 'nearest':\n+        x = tf.image.resize_nearest_neighbor(x, new_shape)\n+    elif interpolation == 'bilinear':\n+        x = tf.image.resize_bilinear(x, new_shape)\n+    else:\n+        raise ValueError('interpolation should be one '\n+                         'of \"nearest\" or \"bilinear\".')\n+    if data_format == 'channels_first':\n+        x = permute_dimensions(x, [0, 3, 1, 2])\n+\n+    if original_shape[rows] is None:\n+        new_height = None\n+    else:\n+        new_height = original_shape[rows] * height_factor\n+\n+    if original_shape[cols] is None:\n+        new_width = None\n+    else:\n+        new_width = original_shape[cols] * width_factor\n+\n+    output_shape = (None, new_height, new_width, None)\n+    x.set_shape(transpose_shape(output_shape, data_format, spatial_axes=(1, 2)))\n+    return x\n \n \n def resize_volumes(x, depth_factor, height_factor, width_factor, data_format):\n\n@@ -965,7 +965,11 @@ def repeat_elements(x, rep, axis):\n     return y\n \n \n-def resize_images(x, height_factor, width_factor, data_format):\n+def resize_images(x,\n+                  height_factor,\n+                  width_factor,\n+                  data_format,\n+                  interpolation='nearest'):\n     \"\"\"Resize the images contained in a 4D tensor of shape\n     - [batch, channels, height, width] (for 'channels_first' data_format)\n     - [batch, height, width, channels] (for 'channels_last' data_format)\n@@ -973,16 +977,40 @@ def resize_images(x, height_factor, width_factor, data_format):\n     positive integers.\n     \"\"\"\n     if data_format == 'channels_first':\n-        output = repeat_elements(x, height_factor, axis=2)\n-        output = repeat_elements(output, width_factor, axis=3)\n-        return output\n+        axis_1 = 2\n+        axis_2 = 3\n     elif data_format == 'channels_last':\n-        output = repeat_elements(x, height_factor, axis=1)\n-        output = repeat_elements(output, width_factor, axis=2)\n-        return output\n+        axis_1 = 1\n+        axis_2 = 2\n     else:\n         raise ValueError('Invalid data_format:', data_format)\n \n+    if interpolation == 'nearest':\n+        output = repeat_elements(x, height_factor, axis=axis_1)\n+        output = repeat_elements(output, width_factor, axis=axis_2)\n+    elif interpolation == 'bilinear':\n+        if not (height_factor == width_factor == 2):\n+            raise NotImplementedError(\n+                'Bilinear upscaling with factors other than (2, 2)'\n+                'is not available when using the Theano backend.')\n+        if data_format == 'channels_last':\n+            output = permute_dimensions(x, [0, 3, 1, 2])\n+        else:\n+            output = x\n+        output = T.nnet.abstract_conv.bilinear_upsampling(output,\n+                                                          ratio=height_factor)\n+        if data_format == 'channels_last':\n+            output = permute_dimensions(output, [0, 2, 3, 1])\n+        if hasattr(x, '_keras_shape'):\n+            output._keras_shape = list(x._keras_shape)\n+            output._keras_shape[axis_1] *= height_factor\n+            output._keras_shape[axis_2] *= width_factor\n+            output._keras_shape = tuple(output._keras_shape)\n+    else:\n+        raise ValueError('interpolation should be one of \"nearest\" or \"bilinear\".')\n+\n+    return output\n+\n \n def resize_volumes(x, depth_factor, height_factor, width_factor, data_format):\n     \"\"\"Resize the volume contained in a 5D tensor of shape\n\n@@ -1919,6 +1919,9 @@ class UpSampling2D(Layer):\n             It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n             If you never set it, then it will be \"channels_last\".\n+        interpolation: A string, one of `nearest` or `bilinear`.\n+            Note that CNTK does not support yet the `bilinear` upscaling\n+            and that with Theano, only `size=(2, 2)` is possible.\n \n     # Input shape\n         4D tensor with shape:\n@@ -1936,11 +1939,15 @@ class UpSampling2D(Layer):\n     \"\"\"\n \n     @interfaces.legacy_upsampling2d_support\n-    def __init__(self, size=(2, 2), data_format=None, **kwargs):\n+    def __init__(self, size=(2, 2), data_format=None, interpolation='nearest', **kwargs):\n         super(UpSampling2D, self).__init__(**kwargs)\n         self.data_format = K.normalize_data_format(data_format)\n         self.size = conv_utils.normalize_tuple(size, 2, 'size')\n         self.input_spec = InputSpec(ndim=4)\n+        if interpolation not in ['nearest', 'bilinear']:\n+            raise ValueError('interpolation should be one '\n+                             'of \"nearest\" or \"bilinear\".')\n+        self.interpolation = interpolation\n \n     def compute_output_shape(self, input_shape):\n         if self.data_format == 'channels_first':\n@@ -1960,7 +1967,7 @@ class UpSampling2D(Layer):\n \n     def call(self, inputs):\n         return K.resize_images(inputs, self.size[0], self.size[1],\n-                               self.data_format)\n+                               self.data_format, self.interpolation)\n \n     def get_config(self):\n         config = {'size': self.size,\n\n@@ -1271,6 +1271,23 @@ class TestBackend(object):\n             K.resize_images(K.variable(xval), 2, 2,\n                             data_format='channels_middle')\n \n+    @staticmethod\n+    def _helper_bilinear(data_format, height_factor, width_factor):\n+        x_shape = (2, 3, 4, 5)\n+        check_single_tensor_operation('resize_images', x_shape,\n+                                      [KTF, KTH],\n+                                      height_factor=height_factor,\n+                                      width_factor=width_factor,\n+                                      data_format=data_format,\n+                                      interpolation='bilinear')\n+\n+    @pytest.mark.skipif(K.backend() == 'cntk', reason='Not supported.')\n+    @pytest.mark.parametrize('data_format', ['channels_first', 'channels_last'])\n+    def test_resize_images_bilinear(self, data_format):\n+        self._helper_bilinear(data_format, 2, 2)\n+        with pytest.raises(NotImplementedError):\n+            self._helper_bilinear(data_format, 4, 4)\n+\n     def test_resize_volumes(self):\n         for data_format in ['channels_first', 'channels_last']:\n             shape = (5, 5, 5)\n\n@@ -874,6 +874,46 @@ def test_upsampling_2d():\n                 assert_allclose(np_output, expected_out)\n \n \n+@pytest.mark.skipif((K.backend() == 'cntk'),\n+                    reason='cntk does not support it yet')\n+@pytest.mark.parametrize('data_format',\n+                         ['channels_first', 'channels_last'])\n+def test_upsampling_2d_bilinear(data_format):\n+    num_samples = 2\n+    stack_size = 2\n+    input_num_row = 11\n+    input_num_col = 12\n+\n+    if data_format == 'channels_first':\n+        inputs = np.random.rand(num_samples, stack_size, input_num_row,\n+                                input_num_col)\n+    else:  # tf\n+        inputs = np.random.rand(num_samples, input_num_row, input_num_col,\n+                                stack_size)\n+\n+    # basic test\n+    layer_test(convolutional.UpSampling2D,\n+               kwargs={'size': (2, 2),\n+                       'data_format': data_format,\n+                       'interpolation': 'bilinear'},\n+               input_shape=inputs.shape)\n+\n+    for length_row in [2]:\n+        for length_col in [2, 3]:\n+            layer = convolutional.UpSampling2D(\n+                size=(length_row, length_col),\n+                data_format=data_format)\n+            layer.build(inputs.shape)\n+            outputs = layer(K.variable(inputs))\n+            np_output = K.eval(outputs)\n+            if data_format == 'channels_first':\n+                assert np_output.shape[2] == length_row * input_num_row\n+                assert np_output.shape[3] == length_col * input_num_col\n+            else:  # tf\n+                assert np_output.shape[1] == length_row * input_num_row\n+                assert np_output.shape[2] == length_col * input_num_col\n+\n+\n @pytest.mark.skipif((K.backend() == 'cntk'),\n                     reason=\"cntk does not support it yet\")\n def test_upsampling_3d():\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8e8f989b850d37a4cbec7a0409343262bd963d0d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 18 | Churn Cumulative: 3106 | Contributors (this commit): 77 | Commits (past 90d): 6 | Contributors (cumulative): 77 | DMM Complexity: 1.0\n\nDIFF:\n@@ -534,14 +534,10 @@ class EarlyStopping(Callback):\n             self.best = np.Inf if self.monitor_op == np.less else -np.Inf\n \n     def on_epoch_end(self, epoch, logs=None):\n-        current = logs.get(self.monitor)\n+        current = self.get_monitor_value(logs)\n         if current is None:\n-            warnings.warn(\n-                'Early stopping conditioned on metric `%s` '\n-                'which is not available. Available metrics are: %s' %\n-                (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n-            )\n             return\n+\n         if self.monitor_op(current - self.min_delta, self.best):\n             self.best = current\n             self.wait = 0\n@@ -561,6 +557,16 @@ class EarlyStopping(Callback):\n         if self.stopped_epoch > 0 and self.verbose > 0:\n             print('Epoch %05d: early stopping' % (self.stopped_epoch + 1))\n \n+    def get_monitor_value(self, logs):\n+        monitor_value = logs.get(self.monitor)\n+        if monitor_value is None:\n+            warnings.warn(\n+                'Early stopping conditioned on metric `%s` '\n+                'which is not available. Available metrics are: %s' %\n+                (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n+            )\n+        return monitor_value\n+\n \n class RemoteMonitor(Callback):\n     \"\"\"Callback used to stream events to a server.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3b7b071bb7b4537576306f00703c5c409bedbb43", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 4771 | Contributors (this commit): 29 | Commits (past 90d): 16 | Contributors (cumulative): 29 | DMM Complexity: None\n\nDIFF:\n@@ -1146,7 +1146,7 @@ class TestBackend(object):\n \n             # test that random_normal also generates different values when used within a function\n             r = K.random_normal((10, 10), mean=mean, stddev=std, seed=1337)\n-            samples = [K.eval(r) for _ in range(200)]\n+            samples = np.array([K.eval(r) for _ in range(200)])\n             assert np.abs(np.mean(samples) - mean) < std * 0.015\n             assert np.abs(np.std(samples) - std) < std * 0.015\n \n@@ -1159,8 +1159,8 @@ class TestBackend(object):\n         assert max_val - 0.015 < np.max(rand) <= max_val\n         assert min_val + 0.015 > np.min(rand) >= min_val\n \n-        r = K.random_uniform((1,), minval=min_val, maxval=max_val)\n-        samples = [K.eval(r) for _ in range(20000)]\n+        r = K.random_uniform((10, 10), minval=min_val, maxval=max_val)\n+        samples = np.array([K.eval(r) for _ in range(200)])\n         assert np.abs(np.mean(samples)) < 0.015\n         assert max_val - 0.015 < np.max(samples) <= max_val\n         assert min_val + 0.015 > np.min(samples) >= min_val\n@@ -1173,8 +1173,8 @@ class TestBackend(object):\n         assert np.max(rand) == 1\n         assert np.min(rand) == 0\n \n-        r = K.random_binomial((1,), p)\n-        samples = [K.eval(r) for _ in range(20000)]\n+        r = K.random_binomial((10, 10), p)\n+        samples = np.array([K.eval(r) for _ in range(200)])\n         assert np.abs(np.mean(samples) - p) < 0.015\n         assert np.max(samples) == 1\n         assert np.min(samples) == 0\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cc380c48f842c2bfb4c4a124b7b567f0ee5a148d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 521 | Contributors (this commit): 12 | Commits (past 90d): 1 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -192,7 +192,7 @@ if __name__ == '__main__':\n                show_shapes=True)\n \n     if args.weights:\n-        vae = vae.load_weights(args.weights)\n+        vae.load_weights(args.weights)\n     else:\n         # train the autoencoder\n         vae.fit(x_train,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e8f8e62add2a7073e50cd31f4f6571bf1ebe21b3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 284 | Contributors (this commit): 15 | Commits (past 90d): 2 | Contributors (cumulative): 15 | DMM Complexity: None\n\nDIFF:\n@@ -13,7 +13,7 @@ has at least ~100k characters. ~1M is better.\n from __future__ import print_function\n from keras.callbacks import LambdaCallback\n from keras.models import Sequential\n-from keras.layers import Dense, Activation\n+from keras.layers import Dense\n from keras.layers import LSTM\n from keras.optimizers import RMSprop\n from keras.utils.data_utils import get_file\n@@ -57,8 +57,7 @@ for i, sentence in enumerate(sentences):\n print('Build model...')\n model = Sequential()\n model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n-model.add(Dense(len(chars)))\n-model.add(Activation('softmax'))\n+model.add(Dense(len(chars), activation='softmax'))\n \n optimizer = RMSprop(lr=0.01)\n model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n@@ -74,7 +73,7 @@ def sample(preds, temperature=1.0):\n     return np.argmax(probas)\n \n \n-def on_epoch_end(epoch, logs):\n+def on_epoch_end(epoch, _):\n     # Function invoked at end of each epoch. Prints generated text.\n     print()\n     print('----- Generating text after Epoch: %d' % epoch)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5027630fa41f499a9226a8f9d952ceabf2c247aa", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 6 | Files Changed: 3 | Hunks: 7 | Methods Changed: 5 | Complexity Δ (Sum/Max): 2/3 | Churn Δ: 26 | Churn Cumulative: 2883 | Contributors (this commit): 23 | Commits (past 90d): 15 | Contributors (cumulative): 29 | DMM Complexity: 1.0\n\nDIFF:\n@@ -7,6 +7,7 @@ from __future__ import print_function\n import warnings\n import numpy as np\n \n+from .training_utils import iter_sequence_infinite\n from .. import backend as K\n from ..utils.data_utils import Sequence\n from ..utils.data_utils import GeneratorEnqueuer\n@@ -121,7 +122,7 @@ def fit_generator(model,\n             elif val_gen:\n                 val_data = validation_data\n                 if isinstance(val_data, Sequence):\n-                    val_enqueuer_gen = iter(val_data)\n+                    val_enqueuer_gen = iter_sequence_infinite(generator)\n                 else:\n                     val_enqueuer_gen = val_data\n             else:\n@@ -160,7 +161,7 @@ def fit_generator(model,\n             output_generator = enqueuer.get()\n         else:\n             if is_sequence:\n-                output_generator = iter(generator)\n+                output_generator = iter_sequence_infinite(generator)\n             else:\n                 output_generator = generator\n \n@@ -315,7 +316,7 @@ def evaluate_generator(model, generator,\n             output_generator = enqueuer.get()\n         else:\n             if is_sequence:\n-                output_generator = iter(generator)\n+                output_generator = iter_sequence_infinite(generator)\n             else:\n                 output_generator = generator\n \n@@ -420,7 +421,7 @@ def predict_generator(model, generator,\n             output_generator = enqueuer.get()\n         else:\n             if is_sequence:\n-                output_generator = iter(generator)\n+                output_generator = iter_sequence_infinite(generator)\n             else:\n                 output_generator = generator\n \n\n@@ -575,3 +575,17 @@ def check_num_samples(ins,\n     if hasattr(ins[0], 'shape'):\n         return int(ins[0].shape[0])\n     return None  # Edge case where ins == [static_learning_phase]\n+\n+\n+def iter_sequence_infinite(seq):\n+    \"\"\"Iterate indefinitely over a Sequence.\n+\n+    # Arguments\n+        seq: Sequence object\n+\n+    # Returns\n+        Generator yielding batches.\n+    \"\"\"\n+    while True:\n+        for item in seq:\n+            yield item\n\n@@ -368,8 +368,7 @@ class Sequence(object):\n         pass\n \n     def __iter__(self):\n-        \"\"\"Create an infinite generator that iterate over the Sequence.\"\"\"\n-        while True:\n+        \"\"\"Create a generator that iterate over the Sequence.\"\"\"\n         for item in (self[i] for i in range(len(self))):\n             yield item\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fa51c5c0d9bdf02692367f2257228ae5f570f6e3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 20 | Files Changed: 1 | Hunks: 10 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 40 | Churn Cumulative: 671 | Contributors (this commit): 10 | Commits (past 90d): 1 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -182,36 +182,26 @@ if __name__ == '__main__':\n     for epoch in range(1, epochs + 1):\n         print('Epoch {}/{}'.format(epoch, epochs))\n \n-        num_batches = int(x_train.shape[0] / batch_size)\n+        num_batches = int(np.ceil(x_train.shape[0] / float(batch_size)))\n         progress_bar = Progbar(target=num_batches)\n \n-        # we don't want the discriminator to also maximize the classification\n-        # accuracy of the auxiliary classifier on generated images, so we\n-        # don't train discriminator to produce class labels for generated\n-        # images (see https://openreview.net/forum?id=rJXTf9Bxg).\n-        # To preserve sum of sample weights for the auxiliary classifier,\n-        # we assign sample weight of 2 to the real images.\n-        disc_sample_weight = [np.ones(2 * batch_size),\n-                              np.concatenate((np.ones(batch_size) * 2,\n-                                              np.zeros(batch_size)))]\n-\n         epoch_gen_loss = []\n         epoch_disc_loss = []\n \n         for index in range(num_batches):\n-            # generate a new batch of noise\n-            noise = np.random.uniform(-1, 1, (batch_size, latent_size))\n-\n             # get a batch of real images\n             image_batch = x_train[index * batch_size:(index + 1) * batch_size]\n             label_batch = y_train[index * batch_size:(index + 1) * batch_size]\n \n+            # generate a new batch of noise\n+            noise = np.random.uniform(-1, 1, (len(image_batch), latent_size))\n+\n             # sample some labels from p_c\n-            sampled_labels = np.random.randint(0, num_classes, batch_size)\n+            sampled_labels = np.random.randint(0, num_classes, len(image_batch))\n \n             # generate a batch of fake images, using the generated labels as a\n             # conditioner. We reshape the sampled labels to be\n-            # (batch_size, 1) so that we can feed them into the embedding\n+            # (len(image_batch), 1) so that we can feed them into the embedding\n             # layer as a length one sequence\n             generated_images = generator.predict(\n                 [noise, sampled_labels.reshape((-1, 1))], verbose=0)\n@@ -222,9 +212,19 @@ if __name__ == '__main__':\n             # Salimans et al., 2016\n             # https://arxiv.org/pdf/1606.03498.pdf (Section 3.4)\n             soft_zero, soft_one = 0, 0.95\n-            y = np.array([soft_one] * batch_size + [soft_zero] * batch_size)\n+            y = np.array([soft_one] * len(image_batch) + [soft_zero] * len(image_batch))\n             aux_y = np.concatenate((label_batch, sampled_labels), axis=0)\n \n+            # we don't want the discriminator to also maximize the classification\n+            # accuracy of the auxilary classifier on generated images, so we\n+            # don't train discriminator to produce class labels for generated\n+            # images (see https://openreview.net/forum?id=rJXTf9Bxg).\n+            # To preserve sum of sample weights for the auxilary classifier,\n+            # we assign sample weight of 2 to the real images.\n+            disc_sample_weight = [np.ones(2 * len(image_batch)),\n+                                  np.concatenate((np.ones(len(image_batch)) * 2,\n+                                                  np.zeros(len(image_batch))))]\n+\n             # see if the discriminator can figure itself out...\n             epoch_disc_loss.append(discriminator.train_on_batch(\n                 x, [y, aux_y], sample_weight=disc_sample_weight))\n@@ -232,13 +232,13 @@ if __name__ == '__main__':\n             # make new noise. we generate 2 * batch size here such that we have\n             # the generator optimize over an identical number of images as the\n             # discriminator\n-            noise = np.random.uniform(-1, 1, (2 * batch_size, latent_size))\n-            sampled_labels = np.random.randint(0, num_classes, 2 * batch_size)\n+            noise = np.random.uniform(-1, 1, (2 * len(image_batch), latent_size))\n+            sampled_labels = np.random.randint(0, num_classes, 2 * len(image_batch))\n \n             # we want to train the generator to trick the discriminator\n             # For the generator, we want all the {fake, not-fake} labels to say\n             # not-fake\n-            trick = np.ones(2 * batch_size) * soft_one\n+            trick = np.ones(2 * len(image_batch)) * soft_one\n \n             epoch_gen_loss.append(combined.train_on_batch(\n                 [noise, sampled_labels.reshape((-1, 1))],\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1ef28433ba6899c31f1cc3133edc1bf1def0bd35", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 674 | Contributors (this commit): 11 | Commits (past 90d): 2 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -212,7 +212,8 @@ if __name__ == '__main__':\n             # Salimans et al., 2016\n             # https://arxiv.org/pdf/1606.03498.pdf (Section 3.4)\n             soft_zero, soft_one = 0, 0.95\n-            y = np.array([soft_one] * len(image_batch) + [soft_zero] * len(image_batch))\n+            y = np.array(\n+                [soft_one] * len(image_batch) + [soft_zero] * len(image_batch))\n             aux_y = np.concatenate((label_batch, sampled_labels), axis=0)\n \n             # we don't want the discriminator to also maximize the classification\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6dd087ab73b09e449144ff17450cc14f981b9ac2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 76 | Lines Deleted: 16 | Files Changed: 6 | Hunks: 26 | Methods Changed: 12 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 92 | Churn Cumulative: 33614 | Contributors (this commit): 186 | Commits (past 90d): 70 | Contributors (cumulative): 322 | DMM Complexity: 0.4482758620689655\n\nDIFF:\n@@ -2186,7 +2186,7 @@ def in_top_k(predictions, targets, k):\n \n \n def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n-                     padding='valid', data_format=None):\n+                     padding='valid', data_format=None, dilation_rate=(1, 1)):\n     data_format = normalize_data_format(data_format)\n \n     x = _preprocess_conv2d_input(x, data_format)\n@@ -2208,7 +2208,8 @@ def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n             False,\n             padding,\n             padding],\n-        output_shape=output_shape)\n+        output_shape=output_shape,\n+        dilation=dilation_rate)\n     return _postprocess_conv2d_output(x, data_format)\n \n \n\n@@ -3433,12 +3433,14 @@ def _preprocess_conv1d_input(x, data_format):\n     return x, tf_data_format\n \n \n-def _preprocess_conv2d_input(x, data_format):\n+def _preprocess_conv2d_input(x, data_format, force_transpose=False):\n     \"\"\"Transpose and cast the input before the conv2d.\n \n     # Arguments\n         x: input tensor.\n         data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n+        force_transpose: boolean, whether force to transpose input from NCHW to NHWC\n+                        if the `data_format` is `\"channels_first\"`.\n \n     # Returns\n         A tensor.\n@@ -3449,7 +3451,7 @@ def _preprocess_conv2d_input(x, data_format):\n         x = tf.cast(x, 'float32')\n     tf_data_format = 'NHWC'\n     if data_format == 'channels_first':\n-        if not _has_nchw_support():\n+        if not _has_nchw_support() or force_transpose:\n             x = tf.transpose(x, (0, 2, 3, 1))  # NCHW -> NHWC\n         else:\n             tf_data_format = 'NCHW'\n@@ -3586,7 +3588,7 @@ def conv2d(x, kernel, strides=(1, 1), padding='valid',\n \n \n def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n-                     padding='valid', data_format=None):\n+                     padding='valid', data_format=None, dilation_rate=(1, 1)):\n     \"\"\"2D deconvolution (i.e. transposed convolution).\n \n     # Arguments\n@@ -3598,6 +3600,7 @@ def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n         data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n             Whether to use Theano or TensorFlow/CNTK data format\n             for inputs/kernels/outputs.\n+        dilation_rate: tuple of 2 integers.\n \n     # Returns\n         A tensor, result of transposed 2D convolution.\n@@ -3610,7 +3613,13 @@ def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n     if isinstance(output_shape, (tuple, list)):\n         output_shape = tf.stack(output_shape)\n \n-    x, tf_data_format = _preprocess_conv2d_input(x, data_format)\n+    # tf.nn.atrous_conv2d_transpose input only supports NHWC format\n+    if data_format == 'channels_first' and dilation_rate != (1, 1):\n+        force_transpose = True\n+    else:\n+        force_transpose = False\n+\n+    x, tf_data_format = _preprocess_conv2d_input(x, data_format, force_transpose)\n \n     if data_format == 'channels_first' and tf_data_format == 'NHWC':\n         output_shape = (output_shape[0],\n@@ -3627,9 +3636,15 @@ def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n     else:\n         strides = (1, 1) + strides\n \n+    if dilation_rate == (1, 1):\n         x = tf.nn.conv2d_transpose(x, kernel, output_shape, strides,\n                                    padding=padding,\n                                    data_format=tf_data_format)\n+    else:\n+        assert dilation_rate[0] == dilation_rate[1]\n+        x = tf.nn.atrous_conv2d_transpose(\n+            x, kernel, output_shape, dilation_rate[0], padding)\n+\n     if data_format == 'channels_first' and tf_data_format == 'NHWC':\n         x = tf.transpose(x, (0, 3, 1, 2))  # NHWC -> NCHW\n     return x\n\n@@ -2134,7 +2134,7 @@ def conv2d(x, kernel, strides=(1, 1), padding='valid',\n \n \n def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n-                     padding='valid', data_format=None):\n+                     padding='valid', data_format=None, dilation_rate=(1, 1)):\n     \"\"\"2D deconvolution (transposed convolution).\n \n     # Arguments\n@@ -2145,6 +2145,7 @@ def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n         data_format: \"channels_last\" or \"channels_first\".\n             Whether to use Theano or TensorFlow data format\n             in inputs/kernels/outputs.\n+        dilation_rate: tuple of 2 integers.\n \n     # Raises\n         ValueError: if using an even kernel size with padding 'same'.\n@@ -2177,7 +2178,8 @@ def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n                                                         kshp=kernel_shape,\n                                                         subsample=strides,\n                                                         border_mode=th_padding,\n-                                                        filter_flip=not flip_filters)\n+                                                        filter_flip=not flip_filters,\n+                                                        filter_dilation=dilation_rate)\n     conv_out = op(kernel, x, output_shape[2:])\n     conv_out = _postprocess_conv2d_output(conv_out, x, padding,\n                                           kernel_shape, strides, data_format)\n\n@@ -731,6 +731,7 @@ class Conv2DTranspose(Conv2D):\n                  padding='valid',\n                  output_padding=None,\n                  data_format=None,\n+                 dilation_rate=(1, 1),\n                  activation=None,\n                  use_bias=True,\n                  kernel_initializer='glorot_uniform',\n@@ -747,6 +748,7 @@ class Conv2DTranspose(Conv2D):\n             strides=strides,\n             padding=padding,\n             data_format=data_format,\n+            dilation_rate=dilation_rate,\n             activation=activation,\n             use_bias=use_bias,\n             kernel_initializer=kernel_initializer,\n@@ -820,11 +822,13 @@ class Conv2DTranspose(Conv2D):\n         out_height = conv_utils.deconv_length(height,\n                                               stride_h, kernel_h,\n                                               self.padding,\n-                                              out_pad_h)\n+                                              out_pad_h,\n+                                              self.dilation_rate[0])\n         out_width = conv_utils.deconv_length(width,\n                                              stride_w, kernel_w,\n                                              self.padding,\n-                                             out_pad_w)\n+                                             out_pad_w,\n+                                             self.dilation_rate[1])\n         if self.data_format == 'channels_first':\n             output_shape = (batch_size, self.filters, out_height, out_width)\n         else:\n@@ -836,7 +840,8 @@ class Conv2DTranspose(Conv2D):\n             output_shape,\n             self.strides,\n             padding=self.padding,\n-            data_format=self.data_format)\n+            data_format=self.data_format,\n+            dilation_rate=self.dilation_rate)\n \n         if self.use_bias:\n             outputs = K.bias_add(\n@@ -867,17 +872,18 @@ class Conv2DTranspose(Conv2D):\n                                                         stride_h,\n                                                         kernel_h,\n                                                         self.padding,\n-                                                        out_pad_h)\n+                                                        out_pad_h,\n+                                                        self.dilation_rate[0])\n         output_shape[w_axis] = conv_utils.deconv_length(output_shape[w_axis],\n                                                         stride_w,\n                                                         kernel_w,\n                                                         self.padding,\n-                                                        out_pad_w)\n+                                                        out_pad_w,\n+                                                        self.dilation_rate[1])\n         return tuple(output_shape)\n \n     def get_config(self):\n         config = super(Conv2DTranspose, self).get_config()\n-        config.pop('dilation_rate')\n         config['output_padding'] = self.output_padding\n         return config\n \n\n@@ -135,7 +135,8 @@ def conv_input_length(output_length, filter_size, padding, stride):\n     return (output_length - 1) * stride - 2 * pad + filter_size\n \n \n-def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):\n+def deconv_length(dim_size, stride_size, kernel_size, padding,\n+                  output_padding, dilation=1):\n     \"\"\"Determines output length of a transposed convolution given input length.\n \n     # Arguments\n@@ -146,6 +147,7 @@ def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):\n         padding: One of `\"same\"`, `\"valid\"`, `\"full\"`.\n         output_padding: Integer, amount of padding along the output dimension,\n             Can be set to `None` in which case the output length is inferred.\n+        dilation: dilation rate, integer.\n \n     # Returns\n         The output length (integer).\n@@ -154,6 +156,9 @@ def deconv_length(dim_size, stride_size, kernel_size, padding, output_padding):\n     if dim_size is None:\n         return None\n \n+    # Get the dilated kernel size\n+    kernel_size = kernel_size + (kernel_size - 1) * (dilation - 1)\n+\n     # Infer length if output padding is None, else compute the exact length\n     if output_padding is None:\n         if padding == 'valid':\n\n@@ -164,7 +164,7 @@ def test_convolution_2d_channels_last():\n \n @keras_test\n @pytest.mark.skipif((K.backend() == 'cntk'),\n-                    reason=\"cntk only supports dilated conv on GPU\")\n+                    reason='cntk only supports dilated conv on GPU')\n def test_convolution_2d_dilation():\n     num_samples = 2\n     filters = 2\n@@ -225,6 +225,37 @@ def test_conv2d_transpose(padding, out_padding, strides):\n                fixed_batch_size=True)\n \n \n+@keras_test\n+@pytest.mark.skipif((K.backend() == 'cntk'),\n+                    reason='cntk only supports dilated conv transpose on GPU')\n+def test_conv2d_transpose_dilation():\n+\n+    layer_test(convolutional.Conv2DTranspose,\n+               kwargs={'filters': 2,\n+                       'kernel_size': 3,\n+                       'padding': 'same',\n+                       'data_format': 'channels_last',\n+                       'dilation_rate': (2, 2)},\n+               input_shape=(2, 5, 6, 3))\n+\n+    # Check dilated conv transpose returns expected output\n+    input_data = np.arange(48).reshape((1, 4, 4, 3)).astype(np.float32)\n+    expected_output = np.float32([[192, 228, 192, 228],\n+                                  [336, 372, 336, 372],\n+                                  [192, 228, 192, 228],\n+                                  [336, 372, 336, 372]]).reshape((1, 4, 4, 1))\n+\n+    layer_test(convolutional.Conv2DTranspose,\n+               input_data=input_data,\n+               kwargs={'filters': 1,\n+                       'kernel_size': 3,\n+                       'padding': 'same',\n+                       'data_format': 'channels_last',\n+                       'dilation_rate': (2, 2),\n+                       'kernel_initializer': 'ones'},\n+               expected_output=expected_output)\n+\n+\n @keras_test\n def test_conv2d_transpose_channels_first():\n     num_samples = 2\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#780f5e447799b4ab343164ab8beceabcd4ab15f0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 43 | Lines Deleted: 14 | Files Changed: 2 | Hunks: 10 | Methods Changed: 9 | Complexity Δ (Sum/Max): 6/6 | Churn Δ: 57 | Churn Cumulative: 5234 | Contributors (this commit): 29 | Commits (past 90d): 22 | Contributors (cumulative): 31 | DMM Complexity: 1.0\n\nDIFF:\n@@ -195,7 +195,7 @@ class TestBackend(object):\n             K.set_learning_phase(2)\n \n     def test_eye(self):\n-        z_list = [k.eval(k.eye(3)) for k in BACKENDS]\n+        z_list = [k.eval(k.eye(3)) for k in WITH_NP]\n         assert_list_pairwise(z_list)\n \n     def test_linear_operations(self):\n@@ -242,23 +242,23 @@ class TestBackend(object):\n         assert_allclose(K.eval(xy_batch_dot), np.ones((32, 1)) * 20, atol=1e-05)\n \n     def test_shape_operations(self):\n-        check_two_tensor_operation('concatenate', (4, 3), (4, 2), BACKENDS,\n+        check_two_tensor_operation('concatenate', (4, 3), (4, 2), WITH_NP,\n                                    axis=-1, concat_args=True)\n \n         check_single_tensor_operation('reshape', (4, 2), WITH_NP, shape=(8, 1))\n         check_single_tensor_operation('permute_dimensions', (4, 2, 3), BACKENDS,\n                                       pattern=(2, 0, 1))\n-        check_single_tensor_operation('repeat', (4, 1), BACKENDS, n=3)\n-        check_single_tensor_operation('flatten', (4, 1), BACKENDS)\n-        check_single_tensor_operation('batch_flatten', (20, 2, 5), BACKENDS,\n+        check_single_tensor_operation('repeat', (4, 1), WITH_NP, n=3)\n+        check_single_tensor_operation('flatten', (4, 1), WITH_NP)\n+        check_single_tensor_operation('batch_flatten', (20, 2, 5), WITH_NP,\n                                       cntk_dynamicity=True)\n-        check_single_tensor_operation('expand_dims', (4, 3), BACKENDS, axis=-1)\n-        check_single_tensor_operation('expand_dims', (4, 3, 2), BACKENDS, axis=1)\n-        check_single_tensor_operation('squeeze', (4, 3, 1), BACKENDS, axis=2)\n-        check_single_tensor_operation('squeeze', (4, 1, 1), BACKENDS, axis=1)\n+        check_single_tensor_operation('expand_dims', (4, 3), WITH_NP, axis=-1)\n+        check_single_tensor_operation('expand_dims', (4, 3, 2), WITH_NP, axis=1)\n+        check_single_tensor_operation('squeeze', (4, 3, 1), WITH_NP, axis=2)\n+        check_single_tensor_operation('squeeze', (4, 1, 1), WITH_NP, axis=1)\n         check_composed_tensor_operations('reshape', {'shape': (4, 3, 1, 1)},\n                                          'squeeze', {'axis': 2},\n-                                         (4, 3, 1, 1), BACKENDS)\n+                                         (4, 3, 1, 1), WITH_NP)\n \n     def test_none_shape_operations(self):\n         # Test shape inference when input\n@@ -342,10 +342,10 @@ class TestBackend(object):\n                 assert_list_pairwise(v_list, shape=False, allclose=False, itself=True)\n \n         # print_tensor\n-        check_single_tensor_operation('print_tensor', (), BACKENDS)\n-        check_single_tensor_operation('print_tensor', (2,), BACKENDS)\n-        check_single_tensor_operation('print_tensor', (4, 3), BACKENDS)\n-        check_single_tensor_operation('print_tensor', (1, 2, 3), BACKENDS)\n+        check_single_tensor_operation('print_tensor', (), WITH_NP)\n+        check_single_tensor_operation('print_tensor', (2,), WITH_NP)\n+        check_single_tensor_operation('print_tensor', (4, 3), WITH_NP)\n+        check_single_tensor_operation('print_tensor', (1, 2, 3), WITH_NP)\n \n     def test_elementwise_operations(self):\n         check_single_tensor_operation('max', (4, 2), WITH_NP)\n\n@@ -329,6 +329,10 @@ def clip(x, min_value, max_value):\n     return np.clip(x, min_value, max_value)\n \n \n+def concatenate(tensors, axis=-1):\n+    return np.concatenate(tensors, axis)\n+\n+\n def reshape(x, shape):\n     return np.reshape(x, shape)\n \n@@ -337,10 +341,33 @@ def repeat_elements(x, rep, axis):\n     return np.repeat(x, rep, axis=axis)\n \n \n+def repeat(x, n):\n+    y = np.expand_dims(x, 1)\n+    y = np.repeat(y, n, axis=1)\n+    return y\n+\n+\n+def flatten(x):\n+    return np.reshape(x, (-1,))\n+\n+\n+def batch_flatten(x):\n+    return np.reshape(x, (x.shape[0], -1))\n+\n+\n def eval(x):\n     return x\n \n \n+def print_tensor(x, message=''):\n+    print(x, message)\n+    return x\n+\n+\n+def eye(size, dtype=None, name=None):\n+    return np.eye(size, dtype=dtype)\n+\n+\n def variable(value, dtype=None, name=None, constraint=None):\n     if constraint is not None:\n         raise TypeError(\"Constraint must be None when \"\n@@ -386,3 +413,5 @@ exp = np.exp\n log = np.log\n round = np.round\n sign = np.sign\n+expand_dims = np.expand_dims\n+squeeze = np.squeeze\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c7f4ad56532a378833f88648f6849e76f9d769be", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 35 | Lines Deleted: 12 | Files Changed: 2 | Hunks: 15 | Methods Changed: 5 | Complexity Δ (Sum/Max): 5/5 | Churn Δ: 47 | Churn Cumulative: 5281 | Contributors (this commit): 29 | Commits (past 90d): 24 | Contributors (cumulative): 31 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1531,8 +1531,9 @@ class TestBackend(object):\n         assert np.alltrue(decode_truth == decode_pred)\n         assert np.allclose(log_prob_truth, log_prob_pred)\n \n-    '''tensorflow only, need special handle'''\n-\n+    @pytest.mark.skipif(K.backend() != 'tensorflow',\n+                        reason='Beam search is only implemented with '\n+                               'the TensorFlow backend.')\n     def test_ctc_decode_beam_search(self):\n         \"\"\"Test one batch, two beams - hibernating beam search.\"\"\"\n \n@@ -1554,10 +1555,10 @@ class TestBackend(object):\n                    for t in range(seq_len_0)] +  # Pad to max_time_steps = 8\n                   2 * [np.zeros((1, depth), dtype=np.float32)])\n \n-        inputs = KTF.variable(np.asarray(inputs).transpose((1, 0, 2)))\n+        inputs = K.variable(np.asarray(inputs).transpose((1, 0, 2)))\n \n         # batch_size length vector of sequence_lengths\n-        input_length = KTF.variable(np.array([seq_len_0], dtype=np.int32))\n+        input_length = K.variable(np.array([seq_len_0], dtype=np.int32))\n         # batch_size length vector of negative log probabilities\n         log_prob_truth = np.array([\n             0.584855,  # output beam 0\n@@ -1569,7 +1570,7 @@ class TestBackend(object):\n         beam_width = 2\n         top_paths = 2\n \n-        decode_pred_tf, log_prob_pred_tf = KTF.ctc_decode(inputs,\n+        decode_pred_tf, log_prob_pred_tf = K.ctc_decode(inputs,\n                                                         input_length,\n                                                         greedy=False,\n                                                         beam_width=beam_width,\n@@ -1577,10 +1578,10 @@ class TestBackend(object):\n \n         assert len(decode_pred_tf) == top_paths\n \n-        log_prob_pred = KTF.eval(log_prob_pred_tf)\n+        log_prob_pred = K.eval(log_prob_pred_tf)\n \n         for i in range(top_paths):\n-            assert np.alltrue(decode_truth[i] == KTF.eval(decode_pred_tf[i]))\n+            assert np.alltrue(decode_truth[i] == K.eval(decode_pred_tf[i]))\n \n         assert np.allclose(log_prob_truth, log_prob_pred)\n \n@@ -1593,6 +1594,8 @@ class TestBackend(object):\n         koh = K.eval(K.one_hot(K.variable(indices, dtype='int32'), num_classes))\n         assert np.all(koh == oh)\n \n+    @pytest.mark.skipif(K.backend() == 'cntk',\n+                        reason='Sparse tensors are not supported in cntk.')\n     def test_sparse_dot(self):\n         x_d = np.array([0, 7, 2, 3], dtype=np.float32)\n         x_r = np.array([0, 2, 2, 3], dtype=np.int64)\n@@ -1689,12 +1692,13 @@ class TestBackend(object):\n         assert p1 < p2\n         assert 9e-38 < p2 <= 1e-37\n \n+    @pytest.mark.skipif(K.backend() == 'cntk',\n+                        reason='cntk has issues with negative number.')\n     def test_arange(self):\n         for test_value in (-20, 0, 1, 10):\n             a_list = []\n             dtype_list = []\n-            # cntk has issue with negative number\n-            for k in [KTH, KTF]:\n+            for k in WITH_NP:\n                 t = k.arange(test_value)\n                 a = k.eval(t)\n                 assert np.array_equal(a, np.arange(test_value))\n@@ -1706,7 +1710,7 @@ class TestBackend(object):\n \n         for start, stop, step in ((0, 5, 1), (-5, 5, 2), (0, 1, 2)):\n             a_list = []\n-            for k in [KTH, KTF]:\n+            for k in WITH_NP:\n                 a = k.eval(k.arange(start, stop, step))\n                 assert np.array_equal(a, np.arange(start, stop, step))\n                 a_list.append(a)\n@@ -1714,11 +1718,11 @@ class TestBackend(object):\n                 assert np.array_equal(a_list[i], a_list[i + 1])\n \n         for dtype in ('int32', 'int64', 'float32', 'float64'):\n-            for k in [KTH, KTF]:\n+            for k in WITH_NP:\n                 t = k.arange(10, dtype=dtype)\n                 assert k.dtype(t) == dtype\n \n-        for k in [KTH, KTF]:\n+        for k in WITH_NP:\n             start = k.constant(1, dtype='int32')\n             t = k.arange(start)\n             assert len(k.eval(t)) == 1\n\n@@ -5,6 +5,7 @@ from __future__ import print_function\n \n import numpy as np\n import scipy.signal as signal\n+from keras.backend import floatx\n \n \n def normalize_conv(func):\n@@ -347,6 +348,10 @@ def repeat(x, n):\n     return y\n \n \n+def arange(start, stop=None, step=1, dtype='int32'):\n+    return np.arange(start, stop, step, dtype)\n+\n+\n def flatten(x):\n     return np.reshape(x, (-1,))\n \n@@ -359,6 +364,20 @@ def eval(x):\n     return x\n \n \n+def dtype(x):\n+    return x.dtype.name\n+\n+\n+def constant(value, dtype=None, shape=None, name=None):\n+    if dtype is None:\n+        dtype = floatx()\n+    if shape is None:\n+        shape = ()\n+    np_value = value * np.ones(shape)\n+    np_value.astype(dtype)\n+    return np_value\n+\n+\n def print_tensor(x, message=''):\n     print(x, message)\n     return x\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
