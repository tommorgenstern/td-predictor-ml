{"custom_id": "keras#b23c9fe95de5b6425e2bf76641852f48174dd036", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 288 | Contributors (this commit): 17 | Commits (past 90d): 2 | Contributors (cumulative): 17 | DMM Complexity: 0.0\n\nDIFF:\n@@ -98,7 +98,6 @@ def on_epoch_end(epoch, _):\n             next_index = sample(preds, diversity)\n             next_char = indices_char[next_index]\n \n-            generated += next_char\n             sentence = sentence[1:] + next_char\n \n             sys.stdout.write(next_char)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ad5db1010c40500793cc42539f1d97fa5fe36221", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 96 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 20/20 | Churn Δ: 100 | Churn Cumulative: 10943 | Contributors (this commit): 55 | Commits (past 90d): 47 | Contributors (cumulative): 74 | DMM Complexity: 0.0\n\nDIFF:\n@@ -2792,8 +2792,102 @@ def map_fn(fn, elems, name=None, dtype=None):\n \n \n def foldl(fn, elems, initializer=None, name=None):\n-    raise NotImplementedError\n+    \"\"\"Reduce `elems` by `fn` combined them from left to right on dimension 0.\n+\n+    # Arguments\n+        fn: Callable that will be called upon each element in `elems`\n+            (and on the optional `initializer`) passed as a second argument.\n+            The first argument passed to `fn` is the accumulator which is the\n+            accumulated value calculated from the preceding invocation of `fn`.\n+            Example For `fn`:\n+            ```python\n+            lambda acc, x: acc + x\n+            ```\n+        elems: Tensor\n+        initializer: (optional) Tensor, the initial value for the accumulator.\n+            In case of None value is provided during the call\n+            the first value is used (`elems[0]`) as `initializer` from `elems`\n+        name: (optional) String, name for the foldl node in the graph.\n+\n+    # Returns\n+        Same type and shape as `initializer`\n+\n+    # Raises:\n+        TypeError: if `fn` is not callable.\n+        TypeError: if `initializer` is neither a tensor nor None value.\n+        TypeError: if `elems` is not a tensor.\n+    \"\"\"\n+    if not callable(fn):\n+        raise TypeError(\"`fn` must be callable.\")\n+    if initializer is not None and not is_tensor(initializer):\n+        raise TypeError(\"`initializer` must be a tensor or None\")\n+    if not is_tensor(elems):\n+        raise TypeError('`elems` must be a tensor')\n+\n+    if initializer is None and shape(elems)[0] > 1:\n+        initializer = elems[0]\n+        elems = elems[1:]\n+    elif initializer is None:\n+        initializer = elems[0]\n+        elems = None\n+\n+    accumulator = initializer\n+    if elems is not None:\n+        for i in range(shape(elems)[0]):\n+            accumulator = fn(accumulator, elems[i])\n+\n+    if name is not None:\n+        accumulator.name = str(name)\n+\n+    return reshape(accumulator, shape(initializer)[1:])\n \n \n def foldr(fn, elems, initializer=None, name=None):\n-    raise NotImplementedError\n+    \"\"\"Reduce `elems` by `fn` combined them from right to left on dimension 0.\n+\n+    # Arguments\n+        fn: Callable that will be called upon each element in `elems`\n+            (and on the optional `initializer`) passed as a second argument.\n+            The first argument passed to `fn` is the accumulator which is the\n+            accumulated value calculated from the preceding invocation of `fn`.\n+            Example For `fn`:\n+            ```python\n+            lambda acc, x: acc + x\n+            ```\n+        elems: Tensor\n+        initializer: (optional) Tensor, the initial value for the accumulator.\n+            In case of None value is provided during the call\n+            the last value is used (`elems[-1]`) as `initializer` from `elems`\n+        name: (optional) String, name for the foldr node in the graph.\n+\n+    # Returns\n+        Same type and shape as `initializer`\n+\n+    # Raises:\n+        TypeError: if `fn` is not callable.\n+        TypeError: if `initializer` is neither a tensor nor None value.\n+        TypeError: if `elems` is not a tensor.\n+    \"\"\"\n+    if not callable(fn):\n+        raise TypeError(\"`fn` must be callable.\")\n+    if initializer is not None and not is_tensor(initializer):\n+        raise TypeError(\"`initializer` must be a tensor or None\")\n+    if not is_tensor(elems):\n+        raise TypeError('`elems` must be a tensor')\n+\n+    if initializer is None and shape(elems)[0] > 1:\n+        initializer = elems[-1]\n+        elems = elems[:-1]\n+    elif initializer is None:\n+        initializer = elems[0]\n+        elems = None\n+\n+    accumulator = initializer\n+    if elems is not None:\n+        for i in range(shape(elems)[0]):\n+            accumulator = fn(accumulator, elems[-i])\n+\n+    if name is not None:\n+        accumulator.name = str(name)\n+\n+    return reshape(accumulator, shape(initializer)[1:])\n\n@@ -1948,7 +1948,6 @@ class TestBackend(object):\n         assert_allclose(x.sum(axis=1), kx, atol=1e-05)\n         assert_allclose(kx, kx2, atol=1e-05)\n \n-    @pytest.mark.skipif(K.backend() == 'cntk', reason='Not supported.')\n     def test_foldl(self):\n         x = np.random.rand(10, 3).astype(np.float32)\n         kx = K.eval(K.foldl(lambda a, b: a + b, K.variable(x)))\n@@ -1956,7 +1955,6 @@ class TestBackend(object):\n         assert (3,) == kx.shape\n         assert_allclose(x.sum(axis=0), kx, atol=1e-05)\n \n-    @pytest.mark.skipif(K.backend() == 'cntk', reason='Not supported.')\n     def test_foldr(self):\n         # This test aims to make sure that we walk the array from right to left\n         # and checks it in the following way: multiplying left to right 1e-40\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#91efaaa1d7486df71be30a54d82b907443d80bf1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 40 | Lines Deleted: 34 | Files Changed: 2 | Hunks: 11 | Methods Changed: 4 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 74 | Churn Cumulative: 14131 | Contributors (this commit): 74 | Commits (past 90d): 5 | Contributors (cumulative): 87 | DMM Complexity: 0.0\n\nDIFF:\n@@ -191,17 +191,7 @@ class _Conv(Layer):\n     def compute_output_shape(self, input_shape):\n         if self.data_format == 'channels_last':\n             space = input_shape[1:-1]\n-            new_space = []\n-            for i in range(len(space)):\n-                new_dim = conv_utils.conv_output_length(\n-                    space[i],\n-                    self.kernel_size[i],\n-                    padding=self.padding,\n-                    stride=self.strides[i],\n-                    dilation=self.dilation_rate[i])\n-                new_space.append(new_dim)\n-            return (input_shape[0],) + tuple(new_space) + (self.filters,)\n-        if self.data_format == 'channels_first':\n+        elif self.data_format == 'channels_first':\n             space = input_shape[2:]\n         new_space = []\n         for i in range(len(space)):\n@@ -212,6 +202,9 @@ class _Conv(Layer):\n                 stride=self.strides[i],\n                 dilation=self.dilation_rate[i])\n             new_space.append(new_dim)\n+        if self.data_format == 'channels_last':\n+            return (input_shape[0],) + tuple(new_space) + (self.filters,)\n+        elif self.data_format == 'channels_first':\n             return (input_shape[0], self.filters) + tuple(new_space)\n \n     def get_config(self):\n@@ -1727,6 +1720,12 @@ class DepthwiseConv2D(Conv2D):\n             It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n             If you never set it, then it will be 'channels_last'.\n+        dilation_rate: an integer or tuple/list of 2 integers, specifying\n+            the dilation rate to use for dilated convolution.\n+            Can be a single integer to specify the same value for\n+            all spatial dimensions.\n+            Currently, specifying any `dilation_rate` value != 1 is\n+            incompatible with specifying any stride value != 1.\n         activation: Activation function to use\n             (see [activations](../activations.md)).\n             If you don't specify anything, no activation is applied\n@@ -1774,6 +1773,7 @@ class DepthwiseConv2D(Conv2D):\n                  padding='valid',\n                  depth_multiplier=1,\n                  data_format=None,\n+                 dilation_rate=(1, 1),\n                  activation=None,\n                  use_bias=True,\n                  depthwise_initializer='glorot_uniform',\n@@ -1790,6 +1790,7 @@ class DepthwiseConv2D(Conv2D):\n             strides=strides,\n             padding=padding,\n             data_format=data_format,\n+            dilation_rate=dilation_rate,\n             activation=activation,\n             use_bias=use_bias,\n             bias_regularizer=bias_regularizer,\n@@ -1860,25 +1861,25 @@ class DepthwiseConv2D(Conv2D):\n         return outputs\n \n     def compute_output_shape(self, input_shape):\n-        if self.data_format == 'channels_first':\n-            rows = input_shape[2]\n-            cols = input_shape[3]\n-            out_filters = input_shape[1] * self.depth_multiplier\n-        elif self.data_format == 'channels_last':\n-            rows = input_shape[1]\n-            cols = input_shape[2]\n+        if self.data_format == 'channels_last':\n+            space = input_shape[1:-1]\n             out_filters = input_shape[3] * self.depth_multiplier\n-\n-        rows = conv_utils.conv_output_length(rows, self.kernel_size[0],\n-                                             self.padding,\n-                                             self.strides[0])\n-        cols = conv_utils.conv_output_length(cols, self.kernel_size[1],\n-                                             self.padding,\n-                                             self.strides[1])\n-        if self.data_format == 'channels_first':\n-            return (input_shape[0], out_filters, rows, cols)\n-        elif self.data_format == 'channels_last':\n-            return (input_shape[0], rows, cols, out_filters)\n+        elif self.data_format == 'channels_first':\n+            space = input_shape[2:]\n+            out_filters = input_shape[1] * self.depth_multiplier\n+        new_space = []\n+        for i in range(len(space)):\n+            new_dim = conv_utils.conv_output_length(\n+                space[i],\n+                self.kernel_size[i],\n+                padding=self.padding,\n+                stride=self.strides[i],\n+                dilation=self.dilation_rate[i])\n+            new_space.append(new_dim)\n+        if self.data_format == 'channels_last':\n+            return (input_shape[0], new_space[0], new_space[1], out_filters)\n+        elif self.data_format == 'channels_first':\n+            return (input_shape[0], out_filters, new_space[0], new_space[1])\n \n     def get_config(self):\n         config = super(DepthwiseConv2D, self).get_config()\n\n@@ -433,14 +433,18 @@ def test_separable_conv_2d_invalid():\n \n \n @pytest.mark.parametrize(\n-    'padding,strides,multiplier',\n-    [(padding, strides, multiplier)\n+    'padding,strides,multiplier,dilation_rate',\n+    [(padding, strides, multiplier, dilation_rate)\n      for padding in _convolution_paddings\n      for strides in [(1, 1), (2, 2)]\n      for multiplier in [1, 2]\n-     if not (padding == 'same' and strides != (1, 1))]\n+     for dilation_rate in [(1, 1), (2, 2), (2, 1), (1, 2)]\n+     if (not (padding == 'same' and strides != (1, 1))\n+         and not (dilation_rate != (1, 1) and strides != (1, 1))\n+         and not (dilation_rate != (1, 1) and multiplier == dilation_rate[0])\n+         and not (dilation_rate != (1, 1) and K.backend() == 'cntk'))]\n )\n-def test_depthwise_conv_2d(padding, strides, multiplier):\n+def test_depthwise_conv_2d(padding, strides, multiplier, dilation_rate):\n     num_samples = 2\n     stack_size = 3\n     num_row = 7\n@@ -450,7 +454,8 @@ def test_depthwise_conv_2d(padding, strides, multiplier):\n                kwargs={'kernel_size': (3, 3),\n                        'padding': padding,\n                        'strides': strides,\n-                       'depth_multiplier': multiplier},\n+                       'depth_multiplier': multiplier,\n+                       'dilation_rate': dilation_rate},\n                input_shape=(num_samples,\n                             num_row,\n                             num_col,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d789bd94a3a1bdc18390b8bff742936dcc70c54f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 21 | Lines Deleted: 46 | Files Changed: 1 | Hunks: 13 | Methods Changed: 9 | Complexity Δ (Sum/Max): -4/0 | Churn Δ: 67 | Churn Cumulative: 7017 | Contributors (this commit): 39 | Commits (past 90d): 32 | Contributors (cumulative): 39 | DMM Complexity: 0.0\n\nDIFF:\n@@ -5,7 +5,6 @@ import scipy.sparse as sparse\n import warnings\n \n from keras import backend as K\n-from keras.backend import floatx, set_floatx, variable\n from keras.utils.conv_utils import convert_kernel\n from keras.backend import numpy_backend as KNP\n \n@@ -44,10 +43,10 @@ else:\n \n \n def check_dtype(var, dtype):\n-    if K.backend() == 'theano':\n-        assert var.dtype == dtype\n+    if K.backend() == 'tensorflow':\n+        assert dtype in str(var.dtype.name)\n     else:\n-        assert var.dtype.name == '%s_ref' % dtype\n+        assert dtype in str(var.dtype)\n \n \n def cntk_func_tensors(function_name, shapes_or_vals, **kwargs):\n@@ -2020,57 +2019,33 @@ class TestBackend(object):\n         check_two_tensor_operation('in_test_phase', (2, 3), (2, 3), WITH_NP,\n                                    training=training)\n \n-    def test_setfloatx_incorrect_values(self):\n+    @pytest.mark.parametrize('dtype', ['', 'beerfloat', 123])\n+    def test_setfloatx_incorrect_values(self, dtype):\n         # Keep track of the old value\n-        old_floatx = floatx()\n-        # Try some incorrect values\n-        initial = floatx()\n-        for value in ['', 'beerfloat', 123]:\n+        old_floatx = K.floatx()\n         with pytest.raises(ValueError):\n-                set_floatx(value)\n-        assert floatx() == initial\n-        # Restore old value\n-        set_floatx(old_floatx)\n+            K.set_floatx(dtype)\n+        assert K.floatx() == old_floatx\n \n-    def test_setfloatx_correct_values(self):\n+    @pytest.mark.parametrize('dtype', ['float16', 'float32', 'float64'])\n+    def test_setfloatx_correct_values(self, dtype):\n         # Keep track of the old value\n-        old_floatx = floatx()\n+        old_floatx = K.floatx()\n         # Check correct values\n-        for value in ['float16', 'float32', 'float64']:\n-            set_floatx(value)\n-            assert floatx() == value\n+        K.set_floatx(dtype)\n+        assert K.floatx() == dtype\n+        # Make sure that changes to the global floatx are effectively\n+        # taken into account by the backend.\n+        check_dtype(K.variable([10]), dtype)\n         # Restore old value\n-        set_floatx(old_floatx)\n+        K.set_floatx(old_floatx)\n \n-    @pytest.mark.skipif((K.backend() == 'cntk'),\n-                        reason='cntk does not support float16')\n-    def test_set_floatx(self):\n-        \"\"\"\n-        Make sure that changes to the global floatx are effectively\n-        taken into account by the backend.\n-        \"\"\"\n-        # Keep track of the old value\n-        old_floatx = floatx()\n-\n-        set_floatx('float16')\n-        var = variable([10])\n-        check_dtype(var, 'float16')\n-\n-        set_floatx('float64')\n-        var = variable([10])\n-        check_dtype(var, 'float64')\n-\n-        # Restore old value\n-        set_floatx(old_floatx)\n-\n-    def test_dtype(self):\n-        assert K.dtype(K.variable(1, dtype='float64')) == 'float64'\n-        assert K.dtype(K.variable(1, dtype='float32')) == 'float32'\n-        assert K.dtype(K.variable(1, dtype='float16')) == 'float16'\n+    @pytest.mark.parametrize('dtype', ['float16', 'float32', 'float64'])\n+    def test_dtype(self, dtype):\n+        assert K.dtype(K.variable(1, dtype=dtype)) == dtype\n \n+    @pytest.mark.skipif(K.backend() == 'cntk', reason='Not supported')\n     def test_variable_support_bool_dtype(self):\n-        # Github issue: 7819\n-        if K.backend() == 'tensorflow':\n         assert K.dtype(K.variable(1, dtype='int16')) == 'int16'\n         assert K.dtype(K.variable(False, dtype='bool')) == 'bool'\n         with pytest.raises(TypeError):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9e6b181b0b27d9ea1157b2ed7bcce04434bc8d77", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 6 | Churn Cumulative: 14623 | Contributors (this commit): 129 | Commits (past 90d): 29 | Contributors (cumulative): 129 | DMM Complexity: 0.0\n\nDIFF:\n@@ -2629,7 +2629,11 @@ def slice(x, start, size):\n \n     {{np_implementation}}\n     \"\"\"\n-    if not (len(int_shape(x)) == len(start) == len(size)):\n+    x_shape = int_shape(x)\n+    if (x_shape is not None) and (x_shape[0] is not None):\n+        len_start = int_shape(start)[0] if is_tensor(start) else len(start)\n+        len_size = int_shape(size)[0] if is_tensor(size) else len(size)\n+        if not (len(int_shape(x)) == len_start == len_size):\n             raise ValueError('The dimension and the size of indices should match.')\n     return tf.slice(x, start, size)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#766e5f7a6e95d46ba9530c470dc19468a20bd711", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -4/0 | Churn Δ: 2 | Churn Cumulative: 700 | Contributors (this commit): 12 | Commits (past 90d): 6 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -284,7 +284,7 @@ class Identity(Initializer):\n             raise ValueError(\n                 'Identity matrix initializer can only be used for 2D matrices.')\n \n-        return self.gain * np.eye(shape[0], shape[1])\n+        return self.gain * K.eye((shape[0], shape[1]), dtype=dtype)\n \n     def get_config(self):\n         return {\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7c7e51ea5ab47b67cd68374400051dd022bdc662", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 393 | Lines Deleted: 54 | Files Changed: 3 | Hunks: 48 | Methods Changed: 18 | Complexity Δ (Sum/Max): 27/15 | Churn Δ: 447 | Churn Cumulative: 12305 | Contributors (this commit): 105 | Commits (past 90d): 18 | Contributors (cumulative): 137 | DMM Complexity: 0.5806451612903226\n\nDIFF:\n@@ -13,11 +13,14 @@ from .base_layer import Layer\n from .training_utils import collect_metrics\n from .training_utils import check_array_length_consistency\n from .training_utils import check_loss_and_target_compatibility\n+from .training_utils import check_generator_arguments\n from .training_utils import standardize_class_weights\n from .training_utils import standardize_input_data\n from .training_utils import standardize_sample_weights\n from .training_utils import standardize_weights\n from .training_utils import weighted_masked_objective\n+from .training_utils import get_static_batch_size\n+from .training_utils import is_generator_or_sequence\n from . import training_arrays\n from . import training_generator\n from .. import backend as K\n@@ -564,20 +567,23 @@ class Model(Network):\n         time what their inputs look like.\n \n         # Arguments\n-          inputs: Single array, or list of arrays. The arrays could be placeholders,\n-            Numpy arrays, or data tensors.\n-            - if placeholders: the model is built on top of these placeholders,\n-              and we expect Numpy data to be fed for them when calling `fit`/etc.\n-            - if Numpy data: we create placeholders matching the shape of the Numpy\n-              arrays. We expect Numpy data to be fed for these placeholders\n+            inputs: Single array, or list of arrays. The arrays could be\n+                placeholders, Numpy arrays, or data tensors.\n+                - if placeholders: the model is built on top of these\n+                  placeholders, and we expect Numpy data to be fed for them\n                   when calling `fit`/etc.\n+                - if Numpy data: we create placeholders matching the shape of\n+                  the Numpy arrays. We expect Numpy data to be fed for these\n+                  placeholders when calling `fit`/etc.\n                 - if data tensors: the model is built on top of these tensors.\n-              We do not expect any Numpy data to be provided when calling `fit`/etc.\n+                  We do not expect any Numpy data to be provided when calling\n+                  `fit`/etc.\n             outputs: Optional output tensors (if already computed by running\n                 the model).\n-          training: Boolean or None. Only relevant in symbolic mode. Specifies\n-            whether to build the model's graph in inference mode (False), training\n-            mode (True), or using the Keras learning phase (None).\n+            training: Boolean or None. Only relevant in symbolic mode.\n+                Specifies whether to build the model's graph in inference\n+                mode (False), training mode (True), or using the Keras\n+                learning phase (None).\n         \"\"\"\n         if self.__class__.__name__ == 'Sequential':\n             # Note: we can't test whether the model\n@@ -829,6 +835,58 @@ class Model(Network):\n             return self.callback_model\n         return self\n \n+    def _validate_or_infer_batch_size(self, batch_size, steps, x):\n+        \"\"\"Validates that the `batch_size` provided is consistent with InputLayer.\n+\n+        It's possible that the user specified a static batch size in their\n+        InputLayer. If so, this method checks the provided `batch_size` and `x`\n+        arguments are consistent with this static batch size. Also, if\n+        `batch_size` is `None`, this method will attempt to infer the batch size\n+        from the static batch size of the InputLayer. Lastly, ValueError will be\n+        raised if `x` is a generator or `Sequence` instance and `batch_size` is\n+        specified as we expect users to provide batched datasets.\n+\n+        # Arguments\n+            batch_size: The batch_size provided as an argument to\n+                fit/evaluate/predict.\n+            steps: The steps provided as an argument to fit/evaluate/predict.\n+            x: The data passed as `x` to fit/evaluate/predict.\n+\n+        # Returns\n+            The validated batch_size, auto-inferred from the first layer if\n+            not provided.\n+\n+        # Raises\n+            ValueError: if a batch size is specified and a generator/Sequence\n+                is passed, or if the specified batch size does not match the\n+                exepected size defined in the Input Layer.\n+        \"\"\"\n+        if batch_size is not None and is_generator_or_sequence(x):\n+            raise ValueError('The `batch_size` argument must not be specified when'\n+                             ' using a generator or Sequence as an input.')\n+\n+        layers = super(Model, self).layers  # Avoids the override in Sequential.\n+        if layers:\n+            first_layer = layers[0]\n+            static_batch_size = get_static_batch_size(first_layer)\n+            if static_batch_size is not None:\n+\n+                # Check `batch_size` argument is consistent with InputLayer.\n+                if batch_size is not None and batch_size != static_batch_size:\n+                    raise ValueError('The `batch_size` argument value {} is '\n+                                     'incompatible with the specified batch '\n+                                     'size of your Input Layer: {}'\n+                                     .format(batch_size, static_batch_size))\n+\n+                # Set inferred batch size from the InputLayer.\n+                if steps is None:\n+                    batch_size = static_batch_size\n+\n+        if batch_size is None and steps is None:\n+            # Backwards compatibility\n+            batch_size = 32\n+        return batch_size\n+\n     def fit(self,\n             x=None,\n             y=None,\n@@ -845,26 +903,38 @@ class Model(Network):\n             steps_per_epoch=None,\n             validation_steps=None,\n             validation_freq=1,\n+            max_queue_size=10,\n+            workers=1,\n+            use_multiprocessing=False,\n             **kwargs):\n-        \"\"\"Trains the model for a given number of epochs (iterations on a dataset).\n+        \"\"\"Trains the model for a fixed number of epochs (iterations on a dataset).\n \n         # Arguments\n-            x: Numpy array of training data (if the model has a single input),\n-                or list of Numpy arrays (if the model has multiple inputs).\n-                If input layers in the model are named, you can also pass a\n-                dictionary mapping input names to Numpy arrays.\n-                `x` can be `None` (default) if feeding from\n-                framework-native tensors (e.g. TensorFlow data tensors).\n-            y: Numpy array of target (label) data\n-                (if the model has a single output),\n-                or list of Numpy arrays (if the model has multiple outputs).\n+            x: Input data. It could be:\n+                - A Numpy array (or array-like), or a list of arrays\n+                  (in case the model has multiple inputs).\n+                - A dict mapping input names to the corresponding\n+                  array/tensors, if the model has named inputs.\n+                - A generator or `keras.utils.Sequence` returning\n+                  `(inputs, targets)` or `(inputs, targets, sample weights)`.\n+                - None (default) if feeding from framework-native\n+                  tensors (e.g. TensorFlow data tensors).\n+            y: Target data. Like the input data `x`,\n+                it could be either Numpy array(s), framework-native tensor(s),\n+                list of Numpy arrays (if the model has multiple outputs) or\n+                None (default) if feeding from framework-native tensors\n+                (e.g. TensorFlow data tensors).\n                 If output layers in the model are named, you can also pass a\n                 dictionary mapping output names to Numpy arrays.\n-                `y` can be `None` (default) if feeding from\n-                framework-native tensors (e.g. TensorFlow data tensors).\n+                If `x` is a generator, or `keras.utils.Sequence` instance,\n+                `y` should not be specified (since targets will be obtained\n+                from `x`).\n             batch_size: Integer or `None`.\n                 Number of samples per gradient update.\n                 If unspecified, `batch_size` will default to 32.\n+                Do not specify the `batch_size` if your data is in the\n+                form of symbolic tensors, generators, or `Sequence` instances\n+                (since they generate batches).\n             epochs: Integer. Number of epochs to train the model.\n                 An epoch is an iteration over the entire `x` and `y`\n                 data provided.\n@@ -887,11 +957,18 @@ class Model(Network):\n                 on this data at the end of each epoch.\n                 The validation data is selected from the last samples\n                 in the `x` and `y` data provided, before shuffling.\n-            validation_data: tuple `(x_val, y_val)` or tuple\n-                `(x_val, y_val, val_sample_weights)` on which to evaluate\n+                This argument is not supported when `x` is a generator or\n+                `Sequence` instance.\n+            validation_data: Data on which to evaluate\n                 the loss and any model metrics at the end of each epoch.\n                 The model will not be trained on this data.\n                 `validation_data` will override `validation_split`.\n+                `validation_data` could be:\n+                    - tuple `(x_val, y_val)` of Numpy arrays or tensors\n+                    - tuple `(x_val, y_val, val_sample_weights)` of Numpy arrays\n+                    - dataset or a dataset iterator\n+                For the first two cases, `batch_size` must be provided.\n+                For the last case, `validation_steps` must be provided.\n             shuffle: Boolean (whether to shuffle the training data\n                 before each epoch) or str (for 'batch').\n                 'batch' is a special option for dealing with the\n@@ -913,7 +990,9 @@ class Model(Network):\n                 `(samples, sequence_length)`,\n                 to apply a different weight to every timestep of every sample.\n                 In this case you should make sure to specify\n-                `sample_weight_mode=\"temporal\"` in `compile()`.\n+                `sample_weight_mode=\"temporal\"` in `compile()`. This argument\n+                is not supported when `x` generator, or `Sequence` instance,\n+                instead provide the sample_weights as the third element of `x`.\n             initial_epoch: Integer.\n                 Epoch at which to start training\n                 (useful for resuming a previous training run).\n@@ -927,6 +1006,10 @@ class Model(Network):\n             validation_steps: Only relevant if `steps_per_epoch`\n                 is specified. Total number of steps (batches of samples)\n                 to validate before stopping.\n+            validation_steps: Only relevant if `validation_data` is provided\n+                and is a generator. Total number of steps (batches of samples)\n+                to draw before stopping when performing validation at the end\n+                of every epoch.\n             validation_freq: Only relevant if validation data is provided. Integer\n                 or list/tuple/set. If an integer, specifies how many training\n                 epochs to run before a new validation run is performed, e.g.\n@@ -934,6 +1017,21 @@ class Model(Network):\n                 tuple, or set, specifies the epochs on which to run validation,\n                 e.g. `validation_freq=[1, 2, 10]` runs validation at the end\n                 of the 1st, 2nd, and 10th epochs.\n+            max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n+                input only. Maximum size for the generator queue.\n+                If unspecified, `max_queue_size` will default to 10.\n+            workers: Integer. Used for generator or `keras.utils.Sequence` input\n+                only. Maximum number of processes to spin up\n+                when using process-based threading. If unspecified, `workers`\n+                will default to 1. If 0, will execute the generator on the main\n+                thread.\n+            use_multiprocessing: Boolean. Used for generator or\n+                `keras.utils.Sequence` input only. If `True`, use process-based\n+                threading. If unspecified, `use_multiprocessing` will default to\n+                `False`. Note that because this implementation relies on\n+                multiprocessing, you should not pass non-picklable arguments to\n+                the generator as they can't be passed easily to children processes.\n+            **kwargs: Used for backwards compatibility.\n \n         # Returns\n             A `History` object. Its `History.history` attribute is\n@@ -946,9 +1044,6 @@ class Model(Network):\n             ValueError: In case of mismatch between the provided input data\n                 and what the model expects.\n         \"\"\"\n-        # Backwards compatibility\n-        if batch_size is None and steps_per_epoch is None:\n-            batch_size = 32\n         # Legacy support\n         if 'nb_epoch' in kwargs:\n             warnings.warn('The `nb_epoch` argument in `fit` '\n@@ -956,16 +1051,43 @@ class Model(Network):\n             epochs = kwargs.pop('nb_epoch')\n         if kwargs:\n             raise TypeError('Unrecognized keyword arguments: ' + str(kwargs))\n+\n         if x is None and y is None and steps_per_epoch is None:\n             raise ValueError('If fitting from data tensors, '\n                              'you should specify the `steps_per_epoch` '\n                              'argument.')\n-        # Validate user data.\n+\n+        batch_size = self._validate_or_infer_batch_size(\n+            batch_size, steps_per_epoch, x)\n+\n+        # Case 1: generator-like. Input is Python generator,\n+        # or Sequence object, or iterator.\n+        if is_generator_or_sequence(x):\n+            check_generator_arguments(\n+                y, sample_weight, validation_split=validation_split)\n+            return self.fit_generator(\n+                x,\n+                steps_per_epoch=steps_per_epoch,\n+                epochs=epochs,\n+                verbose=verbose,\n+                callbacks=callbacks,\n+                validation_data=validation_data,\n+                validation_steps=validation_steps,\n+                validation_freq=validation_freq,\n+                class_weight=class_weight,\n+                max_queue_size=max_queue_size,\n+                workers=workers,\n+                use_multiprocessing=use_multiprocessing,\n+                shuffle=shuffle,\n+                initial_epoch=initial_epoch)\n+\n+        # Case 2: Symbolic tensors or Numpy array-like.\n         x, y, sample_weights = self._standardize_user_data(\n             x, y,\n             sample_weight=sample_weight,\n             class_weight=class_weight,\n             batch_size=batch_size)\n+\n         # Prepare validation data.\n         do_validation = False\n         if validation_data:\n@@ -1055,33 +1177,47 @@ class Model(Network):\n                                         validation_steps=validation_steps,\n                                         validation_freq=validation_freq)\n \n-    def evaluate(self, x=None, y=None,\n+    def evaluate(self,\n+                 x=None,\n+                 y=None,\n                  batch_size=None,\n                  verbose=1,\n                  sample_weight=None,\n                  steps=None,\n-                 callbacks=None):\n+                 callbacks=None,\n+                 max_queue_size=10,\n+                 workers=1,\n+                 use_multiprocessing=False):\n         \"\"\"Returns the loss value & metrics values for the model in test mode.\n \n         Computation is done in batches.\n \n         # Arguments\n-            x: Numpy array of test data (if the model has a single input),\n-                or list of Numpy arrays (if the model has multiple inputs).\n-                If input layers in the model are named, you can also pass a\n-                dictionary mapping input names to Numpy arrays.\n-                `x` can be `None` (default) if feeding from\n-                framework-native tensors (e.g. TensorFlow data tensors).\n-            y: Numpy array of target (label) data\n-                (if the model has a single output),\n-                or list of Numpy arrays (if the model has multiple outputs).\n+            x: Input data. It could be:\n+                - A Numpy array (or array-like), or a list of arrays\n+                  (in case the model has multiple inputs).\n+                - A dict mapping input names to the corresponding\n+                  array/tensors, if the model has named inputs.\n+                - A generator or `keras.utils.Sequence` returning\n+                  `(inputs, targets)` or `(inputs, targets, sample weights)`.\n+                - None (default) if feeding from framework-native\n+                  tensors (e.g. TensorFlow data tensors).\n+            y: Target data. Like the input data `x`,\n+                it could be either Numpy array(s), framework-native tensor(s),\n+                list of Numpy arrays (if the model has multiple outputs) or\n+                None (default) if feeding from framework-native tensors\n+                (e.g. TensorFlow data tensors).\n                 If output layers in the model are named, you can also pass a\n                 dictionary mapping output names to Numpy arrays.\n-                `y` can be `None` (default) if feeding from\n-                framework-native tensors (e.g. TensorFlow data tensors).\n+                If `x` is a generator, or `keras.utils.Sequence` instance,\n+                `y` should not be specified (since targets will be obtained\n+                from `x`).\n             batch_size: Integer or `None`.\n-                Number of samples per evaluation step.\n+                Number of samples per gradient update.\n                 If unspecified, `batch_size` will default to 32.\n+                Do not specify the `batch_size` is your data is in the\n+                form of symbolic tensors, generators, or\n+                `keras.utils.Sequence` instances (since they generate batches).\n             verbose: 0 or 1. Verbosity mode.\n                 0 = silent, 1 = progress bar.\n             sample_weight: Optional Numpy array of weights for\n@@ -1102,6 +1238,22 @@ class Model(Network):\n             callbacks: List of `keras.callbacks.Callback` instances.\n                 List of callbacks to apply during evaluation.\n                 See [callbacks](/callbacks).\n+            max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n+                input only. Maximum size for the generator queue.\n+                If unspecified, `max_queue_size` will default to 10.\n+            workers: Integer. Used for generator or `keras.utils.Sequence` input\n+                only. Maximum number of processes to spin up when using\n+                process-based threading. If unspecified, `workers` will default\n+                to 1. If 0, will execute the generator on the main thread.\n+            use_multiprocessing: Boolean. Used for generator or\n+                `keras.utils.Sequence` input only. If `True`, use process-based\n+                threading. If unspecified, `use_multiprocessing` will default to\n+                `False`. Note that because this implementation relies on\n+                multiprocessing, you should not pass non-picklable arguments to\n+                the generator as they can't be passed easily to children processes.\n+\n+        # Raises\n+            ValueError: in case of invalid arguments.\n \n         # Returns\n             Scalar test loss (if the model has a single output and no metrics)\n@@ -1109,9 +1261,22 @@ class Model(Network):\n             and/or metrics). The attribute `model.metrics_names` will give you\n             the display labels for the scalar outputs.\n         \"\"\"\n-        # Backwards compatibility.\n-        if batch_size is None and steps is None:\n-            batch_size = 32\n+\n+        batch_size = self._validate_or_infer_batch_size(batch_size, steps, x)\n+\n+        # Case 1: generator-like. Input is Python generator, or Sequence object.\n+        if is_generator_or_sequence(x):\n+            check_generator_arguments(y, sample_weight)\n+            return self.evaluate_generator(\n+                x,\n+                steps=steps,\n+                verbose=verbose,\n+                callbacks=callbacks,\n+                max_queue_size=max_queue_size,\n+                workers=workers,\n+                use_multiprocessing=use_multiprocessing)\n+\n+        # Case 2: Symbolic tensors or Numpy array-like.\n         if x is None and y is None and steps is None:\n             raise ValueError('If evaluating from data tensors, '\n                              'you should specify the `steps` '\n@@ -1138,15 +1303,30 @@ class Model(Network):\n                 batch_size=None,\n                 verbose=0,\n                 steps=None,\n-                callbacks=None):\n+                callbacks=None,\n+                max_queue_size=10,\n+                workers=1,\n+                use_multiprocessing=False):\n         \"\"\"Generates output predictions for the input samples.\n \n         Computation is done in batches.\n \n         # Arguments\n-            x: The input data, as a Numpy array\n-                (or list of Numpy arrays if the model has multiple inputs).\n-            batch_size: Integer. If unspecified, it will default to 32.\n+            x: Input data. It could be:\n+                - A Numpy array (or array-like), or a list of arrays\n+                  (in case the model has multiple inputs).\n+                - A dict mapping input names to the corresponding\n+                  array/tensors, if the model has named inputs.\n+                - A generator or `keras.utils.Sequence` returning\n+                  `(inputs, targets)` or `(inputs, targets, sample weights)`.\n+                - None (default) if feeding from framework-native\n+                  tensors (e.g. TensorFlow data tensors).\n+            batch_size: Integer or `None`.\n+                Number of samples per gradient update.\n+                If unspecified, `batch_size` will default to 32.\n+                Do not specify the `batch_size` is your data is in the\n+                form of symbolic tensors, generators, or\n+                `keras.utils.Sequence` instances (since they generate batches).\n             verbose: Verbosity mode, 0 or 1.\n             steps: Total number of steps (batches of samples)\n                 before declaring the prediction round finished.\n@@ -1154,6 +1334,19 @@ class Model(Network):\n             callbacks: List of `keras.callbacks.Callback` instances.\n                 List of callbacks to apply during prediction.\n                 See [callbacks](/callbacks).\n+            max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n+                input only. Maximum size for the generator queue.\n+                If unspecified, `max_queue_size` will default to 10.\n+            workers: Integer. Used for generator or `keras.utils.Sequence` input\n+                only. Maximum number of processes to spin up when using\n+                process-based threading. If unspecified, `workers` will default\n+                to 1. If 0, will execute the generator on the main thread.\n+            use_multiprocessing: Boolean. Used for generator or\n+                `keras.utils.Sequence` input only. If `True`, use process-based\n+                threading. If unspecified, `use_multiprocessing` will default to\n+                `False`. Note that because this implementation relies on\n+                multiprocessing, you should not pass non-picklable arguments to\n+                the generator as they can't be passed easily to children processes.\n \n         # Returns\n             Numpy array(s) of predictions.\n@@ -1164,14 +1357,26 @@ class Model(Network):\n                 or in case a stateful model receives a number of samples\n                 that is not a multiple of the batch size.\n         \"\"\"\n-        # Backwards compatibility.\n-        if batch_size is None and steps is None:\n-            batch_size = 32\n+\n+        batch_size = self._validate_or_infer_batch_size(batch_size, steps, x)\n+\n+        # Case 1: generator-like. Input is Python generator, or Sequence object.\n+        if is_generator_or_sequence(x):\n+            return self.predict_generator(\n+                x,\n+                steps=steps,\n+                verbose=verbose,\n+                callbacks=callbacks,\n+                max_queue_size=max_queue_size,\n+                workers=workers,\n+                use_multiprocessing=use_multiprocessing)\n+\n         if x is None and steps is None:\n             raise ValueError('If predicting from data tensors, '\n                              'you should specify the `steps` '\n                              'argument.')\n-        # Validate user data.\n+\n+        # Case 2: Symbolic tensors or Numpy array-like.\n         x, _, _ = self._standardize_user_data(x)\n         if self.stateful:\n             if x[0].shape[0] > batch_size and x[0].shape[0] % batch_size != 0:\n\n@@ -4,6 +4,7 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n+import inspect\n import collections\n import copy\n import numpy as np\n@@ -298,6 +299,22 @@ def check_loss_and_target_compatibility(targets, loss_fns, output_shapes):\n                         'as the output.')\n \n \n+def check_generator_arguments(y=None, sample_weight=None,\n+                              validation_split=None):\n+    \"\"\"Validates arguments passed when using a generator.\"\"\"\n+    if y is not None:\n+        raise ValueError('`y` argument is not supported when data is'\n+                         'a generator or Sequence instance. Instead pass targets'\n+                         ' as the second element of the generator.')\n+    if sample_weight is not None:\n+        raise ValueError('`sample_weight` argument is not supported when data is'\n+                         'a generator or Sequence instance. Instead pass sample'\n+                         ' weights as the third element of the generator.')\n+    if validation_split:\n+        raise ValueError('If your data is in the form of a Python generator, '\n+                         'you cannot use `validation_split`.')\n+\n+\n def collect_metrics(metrics, output_names):\n     \"\"\"Maps metric functions to model outputs.\n \n@@ -618,6 +635,11 @@ def is_sequence(seq):\n             or set(dir(Sequence())).issubset(set(dir(seq) + ['use_sequence_api'])))\n \n \n+def is_generator_or_sequence(x):\n+    \"\"\"Check if `x` is a Keras generator type.\"\"\"\n+    return inspect.isgenerator(x) or is_sequence(x)\n+\n+\n def should_run_validation(validation_freq, epoch):\n     \"\"\"Checks if validation should be run this epoch.\n \n@@ -646,3 +668,48 @@ def should_run_validation(validation_freq, epoch):\n         raise ValueError('`validation_freq` must be an Integer or '\n                          '`collections.Container` (e.g. list, tuple, etc.)')\n     return one_indexed_epoch in validation_freq\n+\n+\n+def get_static_batch_size(layer):\n+    \"\"\"Gets the static batch size of a Layer.\n+\n+    # Arguments\n+        layer: a `Layer` instance.\n+\n+    # Returns\n+        The static batch size of a Layer.\n+    \"\"\"\n+    batch_input_shape, _ = get_input_shape_and_dtype(layer)\n+    if batch_input_shape is not None:\n+        return batch_input_shape[0]\n+    return None\n+\n+\n+def get_input_shape_and_dtype(layer):\n+    \"\"\"Retrieves input shape and input dtype of layer if applicable.\n+\n+    # Arguments\n+        layer: Layer (or model) instance.\n+\n+    # Returns\n+        Tuple (input_shape, input_dtype). Both could be None if the layer\n+        does not have a defined input shape.\n+\n+    # Raises\n+      ValueError: in case an empty Sequential or Functional model is passed.\n+    \"\"\"\n+    def _is_graph_model(layer):\n+        return ((hasattr(layer, '_is_graph_network') and layer._is_graph_network) or\n+                layer.__class__.__name__ == 'Sequential')\n+\n+    # In case of nested models: recover the first layer\n+    # of the deepest model to infer input shape and dtype.\n+    # Subclassed Models may not have been built so can't be checked.\n+    while _is_graph_model(layer):\n+        if not layer.layers:\n+            raise ValueError('An empty Model cannot be used as a Layer.')\n+        layer = layer.layers[0]\n+\n+    if hasattr(layer, '_batch_input_shape'):\n+        return layer._batch_input_shape, layer.dtype\n+    return None, None\n\n@@ -350,6 +350,9 @@ def test_model_methods():\n \n     # enable verbose for evaluate_generator\n     out = model.evaluate_generator(gen_data(4), steps=3, verbose=1)\n+    # pass generator directly so `is_generator_or_sequence`\n+    # doesn't get confused.\n+    out = model.evaluate(gen_data(4).it, steps=3, verbose=1)\n \n     # empty batch\n     with pytest.raises(ValueError):\n@@ -359,6 +362,13 @@ def test_model_methods():\n                 yield (np.asarray([]), np.asarray([]))\n \n         out = model.evaluate_generator(gen_data(), steps=1)\n+    with pytest.raises(ValueError):\n+        @threadsafe_generator\n+        def gen_data():\n+            while True:\n+                yield (np.asarray([]), np.asarray([]))\n+\n+        out = model.evaluate(gen_data().it, steps=1)\n \n     # x is not a list of numpy arrays.\n     with pytest.raises(ValueError):\n@@ -479,6 +489,20 @@ def test_fit_generator():\n     assert tracker_cb.trained_batches == list(range(3)) * 5\n     assert len(val_seq.logs) <= 4 * 5\n \n+    tracker_cb = TrackerCallback()\n+    val_seq = RandomSequence(4)\n+    out = model.fit(RandomSequence(3),\n+                    steps_per_epoch=3,\n+                    epochs=5,\n+                    initial_epoch=0,\n+                    validation_data=val_seq,\n+                    validation_steps=3,\n+                    max_queue_size=1,\n+                    callbacks=[tracker_cb])\n+    assert tracker_cb.trained_epochs == [0, 1, 2, 3, 4]\n+    assert tracker_cb.trained_batches == list(range(3)) * 5\n+    assert len(val_seq.logs) <= 4 * 5\n+\n     # steps_per_epoch will be equal to len of sequence if it's unspecified\n     tracker_cb = TrackerCallback()\n     val_seq = RandomSequence(4)\n@@ -492,6 +516,18 @@ def test_fit_generator():\n     assert tracker_cb.trained_batches == list(range(12)) * 5\n     assert 12 * 5 <= len(val_seq.logs) <= (12 * 5) + 2  # the queue may be full.\n \n+    tracker_cb = TrackerCallback()\n+    val_seq = RandomSequence(4)\n+    out = model.fit(RandomSequence(3),\n+                    epochs=5,\n+                    initial_epoch=0,\n+                    validation_data=val_seq,\n+                    callbacks=[tracker_cb],\n+                    max_queue_size=1)\n+    assert tracker_cb.trained_epochs == [0, 1, 2, 3, 4]\n+    assert tracker_cb.trained_batches == list(range(12)) * 5\n+    assert 12 * 5 <= len(val_seq.logs) <= (12 * 5) + 2  # the queue may be full.\n+\n     # test for workers = 0\n     tracker_cb = TrackerCallback()\n     val_seq = RandomSequence(4)\n@@ -504,6 +540,20 @@ def test_fit_generator():\n     assert tracker_cb.trained_batches == list(range(12)) * 5\n     assert len(val_seq.logs) == 12 * 5\n \n+    tracker_cb = TrackerCallback()\n+    val_seq = RandomSequence(4)\n+    out = model.fit(RandomSequence(3),\n+                    steps_per_epoch=3,\n+                    epochs=5,\n+                    initial_epoch=0,\n+                    validation_data=val_seq,\n+                    validation_steps=3,\n+                    max_queue_size=1,\n+                    callbacks=[tracker_cb])\n+    assert tracker_cb.trained_epochs == [0, 1, 2, 3, 4]\n+    assert tracker_cb.trained_batches == list(range(3)) * 5\n+    assert len(val_seq.logs) <= 4 * 5\n+\n     # fit_generator will throw an exception\n     # if steps is unspecified for regular generator\n     with pytest.raises(ValueError):\n@@ -570,6 +620,10 @@ def test_fit_generator_shape():\n         RandomSequence(batch_size, sequence_length=sequence_length))\n     assert np.shape(out[0]) == shape_0 and np.shape(out[1]) == shape_1\n \n+    out = model.predict(\n+        RandomSequence(batch_size, sequence_length=sequence_length))\n+    assert np.shape(out[0]) == shape_0 and np.shape(out[1]) == shape_1\n+\n     # Multiple outputs and multiple steps.\n     batch_size = 5\n     sequence_length = 2\n@@ -578,6 +632,10 @@ def test_fit_generator_shape():\n         RandomSequence(batch_size, sequence_length=sequence_length))\n     assert np.shape(out[0]) == shape_0 and np.shape(out[1]) == shape_1\n \n+    out = model.predict(\n+        RandomSequence(batch_size, sequence_length=sequence_length))\n+    assert np.shape(out[0]) == shape_0 and np.shape(out[1]) == shape_1\n+\n     # Create a model with a single output.\n     single_output_model = get_model(num_outputs=1)\n     single_output_model.compile(optimizer, loss,\n@@ -591,6 +649,10 @@ def test_fit_generator_shape():\n         RandomSequence(batch_size, sequence_length=sequence_length))\n     assert np.shape(out) == shape_0\n \n+    out = single_output_model.predict(\n+        RandomSequence(batch_size, sequence_length=sequence_length))\n+    assert np.shape(out) == shape_0\n+\n     # Single output and multiple steps.\n     batch_size = 5\n     sequence_length = 2\n@@ -599,6 +661,10 @@ def test_fit_generator_shape():\n         RandomSequence(batch_size, sequence_length=sequence_length))\n     assert np.shape(out) == shape_0\n \n+    out = single_output_model.predict(\n+        RandomSequence(batch_size, sequence_length=sequence_length))\n+    assert np.shape(out) == shape_0\n+\n \n @pytest.mark.skipif(sys.version_info < (3,),\n                     reason='Cannot catch warnings in python 2')\n@@ -1029,6 +1095,7 @@ def test_model_with_external_loss():\n \n         # test evaluate_generator for framework-native data tensors\n         out = model.evaluate_generator(generator, steps=3)\n+        out = model.evaluate(generator, steps=3)\n \n         # test fit with validation data\n         with pytest.raises(ValueError):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
