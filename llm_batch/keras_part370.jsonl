{"custom_id": "keras#7cf407ef55f07a07e8ccb3010c5f194f508e1881", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 11 | Churn Cumulative: 4118 | Contributors (this commit): 7 | Commits (past 90d): 13 | Contributors (cumulative): 7 | DMM Complexity: 1.0\n\nDIFF:\n@@ -3789,6 +3789,9 @@ class TestFunctionTracing(keras_parameterized.TestCase):\n   @keras_parameterized.run_all_keras_modes(\n       always_skip_v1=True, always_skip_eager=True)\n   def test_no_tracing_between_epoch(self):\n+    if _is_oss():\n+      self.skipTest('b/198729465')\n+\n     model, x, y = self._seq_model_and_data()\n \n     logging.set_verbosity(1)\n@@ -3801,6 +3804,9 @@ class TestFunctionTracing(keras_parameterized.TestCase):\n   @keras_parameterized.run_all_keras_modes(\n       always_skip_v1=True, always_skip_eager=True)\n   def test_evaluate_no_cached_data(self):\n+    if _is_oss():\n+      self.skipTest('b/198729465')\n+\n     model, x, y = self._seq_model_and_data()\n \n     new_func_graph = 'INFO:absl:Creating new FuncGraph for Python function'\n@@ -3930,5 +3936,10 @@ class ScalarDataModelTest(keras_parameterized.TestCase):\n     self.assertAllClose(preds, y, atol=2e-1)\n \n \n+def _is_oss():\n+  \"\"\"Returns whether the test is run under OSS.\"\"\"\n+  return len(sys.argv) >= 1 and 'bazel' in sys.argv[0]\n+\n+\n if __name__ == '__main__':\n   tf.test.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5bc862c90f3ccdec18ed0b12d47973d1fc754f1c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1169 | Contributors (this commit): 6 | Commits (past 90d): 8 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -662,7 +662,7 @@ class CosineDecayRestarts(LearningRateSchedule):\n   The learning rate multiplier first decays\n   from 1 to `alpha` for `first_decay_steps` steps. Then, a warm\n   restart is performed. Each new warm restart runs for `t_mul` times more\n-  steps and with `m_mul` times larger initial learning rate.\n+  steps and with `m_mul` times initial learning rate as the new learning rate.\n \n   Example usage:\n   ```python\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#69562730e2f2b34bf1d55d1f592cf7a8708ace8a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 4/3 | Churn Δ: 12 | Churn Cumulative: 1811 | Contributors (this commit): 5 | Commits (past 90d): 4 | Contributors (cumulative): 8 | DMM Complexity: 0.4\n\nDIFF:\n@@ -205,6 +205,12 @@ def load_model(filepath, custom_objects=None, compile=True, options=None):  # py\n \n         filepath = path_to_string(filepath)\n         if isinstance(filepath, str):\n+          if not tf.io.gfile.exists(filepath):\n+            raise IOError(f'No file or directory found at {filepath}')\n+          if saving_utils.is_hdf5_filepath(filepath) and h5py is None:\n+            raise ImportError(\n+                'Filepath looks like a hdf5 file but h5py is not available.'\n+                f' filepath={filepath}')\n           return saved_model_load.load(filepath, compile, options)\n \n   raise IOError(\n\n@@ -65,6 +65,12 @@ class TestSaveModel(tf.test.TestCase, parameterized.TestCase):\n   def assert_saved_model(self, path):\n     tf.__internal__.saved_model.parse_saved_model(path)\n \n+  @testing_utils.run_v2_only\n+  def test_load_file_not_found(self):\n+    path = pathlib.Path(self.get_temp_dir()) / 'does_not_exist'\n+    with self.assertRaisesRegex(IOError, 'No file or directory found at'):\n+      save.load_model(path)\n+\n   @testing_utils.run_v2_only\n   def test_save_format_defaults(self):\n     path = os.path.join(self.get_temp_dir(), 'model_path')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#91c98330a16a2b957957e12344b33f0a4a4ea0de", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 4 | Churn Cumulative: 3754 | Contributors (this commit): 5 | Commits (past 90d): 14 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -709,7 +709,7 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n        np.array([\"earth\", \"wind\", \"and\", \"fire\"]),\n        [2, 3, 4, 5]),\n       (\"array_0\", [],\n-       tf.constant(\"earth\"),\n+       lambda: tf.constant(\"earth\"),\n        2),\n       (\"str\", [],\n        \"earth\",\n@@ -723,6 +723,8 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n   )  # pyformat: disable\n   def test_int_output(self, shape, input_array, expected_output):\n     vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n+    if callable(input_array):\n+      input_array = input_array()\n \n     layer = index_lookup.IndexLookup(\n         max_tokens=None,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1e859f75070ea2c145850bddc61a0de82f69db61", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 38 | Lines Deleted: 7 | Files Changed: 12 | Hunks: 19 | Methods Changed: 11 | Complexity Δ (Sum/Max): 11/6 | Churn Δ: 45 | Churn Cumulative: 6495 | Contributors (this commit): 14 | Commits (past 90d): 48 | Contributors (cumulative): 33 | DMM Complexity: 0.0\n\nDIFF:\n@@ -160,6 +160,8 @@ class TestImageNetUtils(keras_parameterized.TestCase):\n       },\n   ])\n   def test_preprocess_input_symbolic_mixed_precision(self, mode):\n+    if not tf.__internal__.tf2.enabled():\n+      self.skipTest('The global policy can only be tested in TensorFlow 2')\n     set_global_policy('mixed_float16')\n     shape = (20, 20, 3)\n     inputs = keras.layers.Input(shape=shape)\n\n@@ -95,6 +95,12 @@ class KerasPremadeModelsTest(tf.test.TestCase, parameterized.TestCase):\n       self.skipTest(\n           'Parameter Server strategy requires dataset creator to be used in '\n           'model.fit.')\n+    if (not tf.__internal__.tf2.enabled() and use_dataset_creator\n+        and isinstance(distribution,\n+                       tf.distribute.experimental.ParameterServerStrategy)):\n+      self.skipTest(\n+          'Parameter Server strategy with dataset creator needs to be run when '\n+          'eager execution is enabled.')\n     with distribution.scope():\n       model = linear.LinearModel()\n       opt = gradient_descent.SGD(learning_rate=0.1)\n@@ -118,6 +124,12 @@ class KerasPremadeModelsTest(tf.test.TestCase, parameterized.TestCase):\n       self.skipTest(\n           'Parameter Server strategy requires dataset creator to be used in '\n           'model.fit.')\n+    if (not tf.__internal__.tf2.enabled() and use_dataset_creator\n+        and isinstance(distribution,\n+                       tf.distribute.experimental.ParameterServerStrategy)):\n+      self.skipTest(\n+          'Parameter Server strategy with dataset creator needs to be run when '\n+          'eager execution is enabled.')\n     with distribution.scope():\n       linear_model = linear.LinearModel(units=1)\n       dnn_model = sequential.Sequential([core.Dense(units=1)])\n\n@@ -27,6 +27,7 @@ import numpy as np\n import tensorflow.compat.v2 as tf\n \n \n+@keras_parameterized.run_all_keras_modes(always_skip_v1=True)\n class FunctionalModelSlideTest(keras_parameterized.TestCase):\n \n   def test_find_nodes_by_inputs_and_outputs(self):\n\n@@ -1715,7 +1715,7 @@ class TrainingTest(keras_parameterized.TestCase):\n \n class TestExceptionsAndWarnings(keras_parameterized.TestCase):\n \n-  @keras_parameterized.run_all_keras_modes\n+  @keras_parameterized.run_all_keras_modes(always_skip_v1=True)\n   @keras_parameterized.run_with_all_model_types\n   def test_fit_on_no_output(self):\n     inputs = layers_module.Input((3,))\n@@ -1726,7 +1726,7 @@ class TestExceptionsAndWarnings(keras_parameterized.TestCase):\n     with self.assertRaisesRegex(TypeError, 'Target data is missing..*'):\n       model.fit(x)\n \n-  @keras_parameterized.run_all_keras_modes\n+  @keras_parameterized.run_all_keras_modes(always_skip_v1=True)\n   @keras_parameterized.run_with_all_model_types\n   def test_fit_on_wrong_output_type(self):\n     inputs1 = layers_module.Input((3,), name='a')\n@@ -3906,14 +3906,15 @@ class TestBuildCustomModel(keras_parameterized.TestCase):\n \n class ScalarDataModelTest(keras_parameterized.TestCase):\n \n+  @keras_parameterized.run_all_keras_modes(always_skip_v1=True)\n   def test_scalar_loss_reduction(self):\n \n     class MyModel(training_module.Model):\n \n       def __init__(self):\n         super().__init__()\n-        self.w = self.add_weight((), initializer='ones')\n-        self.b = self.add_weight((), initializer='zeros')\n+        self.w = self.add_weight(initializer='ones', name='kernel')\n+        self.b = self.add_weight(initializer='zeros', name='bias')\n \n       def call(self, inputs):\n         return inputs * self.w + self.b\n\n@@ -44,6 +44,12 @@ class DistributedTrainingTest(tf.test.TestCase):\n   \"\"\"Test to demonstrate basic Keras training with a variety of strategies.\"\"\"\n \n   def testKerasTrainingAPI(self, strategy):\n+    if (not tf.__internal__.tf2.enabled()\n+        and isinstance(strategy,\n+                       tf.distribute.experimental.ParameterServerStrategy)):\n+      self.skipTest(\n+          \"Parameter Server strategy with dataset creator need to be run when \"\n+          \"eager execution is enabled.\")\n \n     # A `dataset_fn` is required for `Model.fit` to work across all strategies.\n     def dataset_fn(input_context):\n\n@@ -311,4 +311,5 @@ class HessianTests(tf.test.TestCase, parameterized.TestCase):\n \n \n if __name__ == \"__main__\":\n+  if tf.__internal__.tf2.enabled():\n     tf.test.main()\n\n@@ -235,4 +235,5 @@ class AutomaticControlDependenciesTest(tf.test.TestCase):\n \n \n if __name__ == '__main__':\n+  if tf.__internal__.tf2.enabled():\n     tf.test.main()\n\n@@ -133,4 +133,5 @@ class GradientsTest(tf.test.TestCase):\n \n \n if __name__ == \"__main__\":\n+  if tf.__internal__.tf2.enabled():\n     tf.test.main()\n\n@@ -130,4 +130,5 @@ class ParameterServerCustomTrainingLoopTest(tf.test.TestCase):\n \n \n if __name__ == \"__main__\":\n+  if tf.__internal__.tf2.enabled():\n     tf.__internal__.distribute.multi_process_runner.test_main()\n\n@@ -37,7 +37,7 @@ def make_dataset():\n     The dataset.\n   \"\"\"\n   tf.random.set_seed(197011)\n-  floats = tf.random.uniform((DS_SIZE, 1), maxval=10, dtype=\"float64\")\n+  floats = tf.random.uniform((DS_SIZE, 1), maxval=10, dtype=\"float32\")\n   # Generate a 100 unique integer values, but over a wide range to showcase a\n   # common use case for IntegerLookup.\n   ints = tf.random.uniform((DS_SIZE, 1), maxval=VOCAB_SIZE, dtype=\"int64\")\n@@ -56,7 +56,7 @@ def make_dataset():\n def make_preprocessing_model(file_dir):\n   \"\"\"Make a standalone preprocessing model.\"\"\"\n   # The name of our keras.Input should match the column name in the dataset.\n-  float_in = tf.keras.Input(shape=(1,), dtype=\"float64\", name=\"float_col\")\n+  float_in = tf.keras.Input(shape=(1,), dtype=\"float32\", name=\"float_col\")\n   int_in = tf.keras.Input(shape=(1,), dtype=\"int64\", name=\"int_col\")\n   string_in = tf.keras.Input(shape=(1,), dtype=\"string\", name=\"string_col\")\n \n@@ -85,7 +85,7 @@ def make_preprocessing_model(file_dir):\n \n def make_training_model():\n   \"\"\"Make a trainable model for the preprocessed inputs.\"\"\"\n-  float_in = tf.keras.Input(shape=(1,), dtype=\"float64\", name=\"float_col\")\n+  float_in = tf.keras.Input(shape=(1,), dtype=\"float32\", name=\"float_col\")\n   # After preprocessing, both the string and int column are integer ready for\n   # embedding.\n   int_in = tf.keras.Input(shape=(1,), dtype=\"int64\", name=\"int_col\")\n\n@@ -235,4 +235,5 @@ class KerasLoadTest(tf.test.TestCase, parameterized.TestCase):\n \n \n if __name__ == \"__main__\":\n+  if tf.__internal__.tf2.enabled():\n     tf.test.main()\n\n@@ -95,6 +95,8 @@ class TpuStrategyTest(tf.test.TestCase):\n     return label_inverse_lookup_layer\n \n   def test_keras_metric_outside_strategy_scope_per_replica(self):\n+    if not tf.compat.v1.executing_eagerly():\n+      self.skipTest(\"connect_to_cluster() can only be called in eager mode\")\n     strategy = get_tpu_strategy()\n     metric = tf.keras.metrics.Mean(\"test_metric\", dtype=tf.float32)\n \n@@ -114,6 +116,8 @@ class TpuStrategyTest(tf.test.TestCase):\n \n   @test_util.disable_mlir_bridge(\"TODO(b/168036682): Support dynamic padder\")\n   def test_train_and_serve(self):\n+    if not tf.compat.v1.executing_eagerly():\n+      self.skipTest(\"connect_to_cluster() can only be called in eager mode\")\n     strategy = get_tpu_strategy()\n     use_adapt = False\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4ed7a01460a9f99e55bb0ced1ec82cd8ea936055", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 4 | Churn Cumulative: 15721 | Contributors (this commit): 70 | Commits (past 90d): 10 | Contributors (cumulative): 70 | DMM Complexity: 0.0\n\nDIFF:\n@@ -880,7 +880,9 @@ class RNN(Layer):\n       else:\n         initial_state = self.states\n       initial_state = tf.nest.map_structure(\n-          lambda v: tf.cast(v, self.compute_dtype), initial_state\n+          # When the layer has a inferred dtype, use the dtype from the cell.\n+          lambda v: tf.cast(v, self.compute_dtype or self.cell.compute_dtype),\n+          initial_state\n       )\n     elif initial_state is None:\n       initial_state = self.get_initial_state(inputs)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f351f8073b446f91c1e7dac4496f4de00ea789c8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 3 | Files Changed: 4 | Hunks: 7 | Methods Changed: 6 | Complexity Δ (Sum/Max): 5/2 | Churn Δ: 15 | Churn Cumulative: 4298 | Contributors (this commit): 10 | Commits (past 90d): 21 | Contributors (cumulative): 16 | DMM Complexity: 0.0\n\nDIFF:\n@@ -324,6 +324,8 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n       model.fit(np.ones((10, 1)), np.ones((10, 1)), epochs=0, callbacks=[cbk])\n \n   def test_backup_restore_train_counter(self):\n+    if not tf.compat.v1.executing_eagerly():\n+      self.skipTest('BackupAndRestore only available when execution is enabled')\n     model = keras.Sequential([keras.layers.Dense(1)])\n     model.compile('sgd', 'mse')\n     cbk = BackupAndRestore(self.get_temp_dir())\n@@ -523,6 +525,8 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n     model_type = testing_utils.get_model_type()\n     if model_type == 'subclass':\n       return  # Skip test since subclassed models cannot be saved in .h5 format.\n+    if not tf.__internal__.tf2.enabled():\n+      self.skipTest('Checkpoint callback only available in v2.')\n \n     layers = [\n         keras.layers.Dense(NUM_HIDDEN, input_dim=INPUT_DIM, activation='relu'),\n@@ -1118,7 +1122,7 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n             1, activation='sigmoid'),))\n     model.compile(\n         optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n-    expected_log = r'(.*- loss:.*- accuracy:.*epoch)+'\n+    expected_log = r'(.*- loss:.*- acc.*:.*epoch)+'\n     with self.captureWritesToStream(sys.stdout) as printed:\n       model.fit(data, labels, verbose=2, epochs=20)\n       self.assertRegex(printed.contents(), expected_log)\n\n@@ -127,6 +127,8 @@ class TestModelCloning(keras_parameterized.TestCase):\n         list(new_model._flatten_layers(include_self=False, recursive=False))[0],\n         keras.layers.InputLayer)\n     # The new models inputs should have the properties of the new input tensor\n+    if tf.__internal__.tf2.enabled():\n+      # In TF1, the new model will be a:0\n       self.assertEqual(new_model.input_names[0], input_a.name)\n     self.assertEqual(new_model.inputs[0].shape, input_a.shape)\n     self.assertTrue(new_model._is_graph_network)\n\n@@ -35,7 +35,8 @@ class TestPickleProtocol(keras_parameterized.TestCase):\n         for protocol in range(pickle.HIGHEST_PROTOCOL + 1)))\n   def test_built_models(self, serializer):\n     \"\"\"Built models should be copyable and picklable for all model types.\"\"\"\n-\n+    if not tf.__internal__.tf2.enabled():\n+      self.skipTest('pickle model only available in v2 when tf format is used.')\n     model = testing_utils.get_small_mlp(\n         num_hidden=1, num_classes=2, input_dim=3)\n     model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy')\n@@ -63,7 +64,8 @@ class TestPickleProtocol(keras_parameterized.TestCase):\n   )\n   def test_unbuilt_models(self, serializer):\n     \"\"\"Unbuilt models should be copyable & deepcopyable for all model types.\"\"\"\n-\n+    if not tf.__internal__.tf2.enabled():\n+      self.skipTest('pickle model only available in v2 when tf format is used.')\n     original_model = testing_utils.get_small_mlp(\n         num_hidden=1, num_classes=2, input_dim=3)\n     # roundtrip without compiling or training\n\n@@ -189,4 +189,5 @@ class LayerCallInfoInjectionTest(tf.test.TestCase):\n \n \n if __name__ == '__main__':\n+  if tf.__internal__.tf2.enabled():\n     tf.test.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#580f044609280ad8888b9ee12475acf2ebb43a3a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 1530 | Contributors (this commit): 3 | Commits (past 90d): 9 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1159,7 +1159,7 @@ class TF1VariableScopeLayerTest(tf.test.TestCase, parameterized.TestCase):\n       # Use multiple calls to verify that no new weights get created\n       self.assertAllEqual(layer(tf.ones(shape=(2, 3))),\n                           tf.constant(1.5, shape=(2, 3)))\n-    self.assertAllEqual({var.name: var for var in layer.weights},\n+    self.assertAllEqual({var.name: var.numpy() for var in layer.weights},\n                         {\"foo/scale_by_y/y:0\": 1.5})\n     self.assertAllEqual(tf.add_n(layer.losses),\n                         regularizers.L2()(layer.weights[0]))\n@@ -1179,7 +1179,7 @@ class TF1VariableScopeLayerTest(tf.test.TestCase, parameterized.TestCase):\n       out, loss = foo(tf.ones(shape=(2, 3)))\n       self.assertAllEqual(out, tf.constant(1.5, shape=(2, 3)))\n       self.assertAllEqual(loss, regularizers.L2()(layer.weights[0]))\n-    self.assertAllEqual({var.name: var for var in layer.weights},\n+    self.assertAllEqual({var.name: var.numpy() for var in layer.weights},\n                         {\"foo/scale_by_y/y:0\": 1.5})\n \n   def test_compat_v1_make_template_in_trace_in_shim(self):\n@@ -1199,7 +1199,8 @@ class TF1VariableScopeLayerTest(tf.test.TestCase, parameterized.TestCase):\n       out, loss = bar(tf.ones(shape=(2, 3)))\n       self.assertAllEqual(out, tf.constant(1.5, shape=(2, 3)))\n       self.assertAllEqual(loss, regularizers.L2()(layers[\"layer\"].weights[0]))\n-    self.assertAllEqual({var.name: var for var in layers[\"layer\"].weights},\n+    self.assertAllEqual(\n+        {var.name: var.numpy() for var in layers[\"layer\"].weights},\n         {\"foo/scale_by_y/y:0\": 1.5})\n \n   def test_only_track_get_variable(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f753edca5d8d1507cfa05805c6211e73910d4c4c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 33 | Lines Deleted: 44 | Files Changed: 1 | Hunks: 12 | Methods Changed: 9 | Complexity Δ (Sum/Max): -5/0 | Churn Δ: 77 | Churn Cumulative: 15928 | Contributors (this commit): 113 | Commits (past 90d): 42 | Contributors (cumulative): 113 | DMM Complexity: 1.0\n\nDIFF:\n@@ -843,18 +843,11 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n       write_scalar_summaries(outputs, step=model._train_counter)  # pylint: disable=protected-access\n       return outputs\n \n-    if (self._steps_per_execution is None or\n-        self._steps_per_execution.numpy().item() == 1):\n-\n-      def train_function(iterator):\n-        \"\"\"Runs a training execution with one step.\"\"\"\n-        return step_function(self, iterator)\n-\n-    else:\n-\n-      def train_function(iterator):\n+    def train_function(iterator, steps_per_execution):\n       \"\"\"Runs a training execution with multiple steps.\"\"\"\n-        for _ in tf.range(self._steps_per_execution):\n+      outputs = step_function(self, iterator)\n+      if steps_per_execution > 1:\n+        for _ in tf.range(steps_per_execution - 1):\n           outputs = step_function(self, iterator)\n       return outputs\n \n@@ -863,11 +856,14 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n           train_function, experimental_relax_shapes=True)\n       self.train_tf_function = train_function\n \n-    self.train_function = train_function\n-\n     if self._cluster_coordinator:\n-      self.train_function = lambda iterator: self._cluster_coordinator.schedule(  # pylint: disable=g-long-lambda\n-          train_function, args=(iterator,))\n+      self.train_function = lambda it: self._cluster_coordinator.schedule(  # pylint: disable=g-long-lambda\n+          train_function,\n+          args=(it, self._steps_per_execution.numpy().item()))\n+    else:\n+      self.train_function = lambda it: train_function(  # pylint: disable=g-long-lambda\n+          it,\n+          self._steps_per_execution.numpy().item())\n \n     return self.train_function\n \n@@ -1327,18 +1323,11 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n           outputs, self.distribute_strategy, reduction='first')\n       return outputs\n \n-    if (self._steps_per_execution is None or\n-        self._steps_per_execution.numpy().item() == 1):\n-\n-      def test_function(iterator):\n-        \"\"\"Runs an evaluation execution with one step.\"\"\"\n-        return step_function(self, iterator)\n-\n-    else:\n-\n-      def test_function(iterator):\n+    def test_function(iterator, steps_per_execution):\n       \"\"\"Runs an evaluation execution with multiple steps.\"\"\"\n-        for _ in tf.range(self._steps_per_execution):\n+      outputs = step_function(self, iterator)\n+      if steps_per_execution > 1:\n+        for _ in tf.range(steps_per_execution - 1):\n           outputs = step_function(self, iterator)\n       return outputs\n \n@@ -1346,11 +1335,14 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n       test_function = tf.function(\n           test_function, experimental_relax_shapes=True)\n \n-    self.test_function = test_function\n-\n     if self._cluster_coordinator:\n-      self.test_function = lambda iterator: self._cluster_coordinator.schedule(  # pylint: disable=g-long-lambda\n-          test_function, args=(iterator,))\n+      self.test_function = lambda it: self._cluster_coordinator.schedule(  # pylint: disable=g-long-lambda\n+          test_function,\n+          args=(it, self._steps_per_execution.numpy().item()))\n+    else:\n+      self.test_function = lambda it: test_function(  # pylint: disable=g-long-lambda\n+          it,\n+          self._steps_per_execution.numpy().item())\n \n     return self.test_function\n \n@@ -1582,33 +1574,30 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n           outputs, self.distribute_strategy, reduction='concat')\n       return outputs\n \n-    if (self._steps_per_execution is None or\n-        self._steps_per_execution.numpy().item() == 1):\n-\n-      def predict_function(iterator):\n-        \"\"\"Runs an evaluation execution with one step.\"\"\"\n-        return step_function(self, iterator)\n-\n-    else:\n-\n-      def predict_function(iterator):\n+    def predict_function(iterator, steps_per_execution):\n       \"\"\"Runs an evaluation execution with multiple steps.\"\"\"\n       outputs = step_function(self, iterator)\n-        for _ in tf.range(self._steps_per_execution - 1):\n+      if steps_per_execution > 1:\n+        for _ in tf.range(steps_per_execution - 1):\n           tf.autograph.experimental.set_loop_options(\n               shape_invariants=[(\n                   t, tf_utils.get_tensor_spec(t, dynamic_batch=True).shape)\n                                 for t in tf.nest.flatten(outputs)])\n           step_outputs = step_function(self, iterator)\n-          outputs = tf.nest.map_structure(lambda t1, t2: concat([t1, t2]), outputs,\n-                                       step_outputs)\n+          outputs = tf.nest.map_structure(lambda t1, t2: concat([t1, t2]),\n+                                          outputs, step_outputs)\n       return outputs\n \n     if not self.run_eagerly:\n       predict_function = tf.function(\n           predict_function, experimental_relax_shapes=True)\n \n-    self.predict_function = predict_function\n+    steps_per_execution = (\n+        lambda: self._steps_per_execution.numpy().item()  # pylint: disable=g-long-lambda\n+        if self._steps_per_execution is not None else 1)\n+    self.predict_function = lambda it: predict_function(  # pylint: disable=g-long-lambda\n+        it, steps_per_execution())\n+\n     return self.predict_function\n \n   @traceback_utils.filter_traceback\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#184d4c22fa319b8da3feee0dcac26ad29b8571c8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 18 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 5 | Methods Changed: 3 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 22 | Churn Cumulative: 16986 | Contributors (this commit): 127 | Commits (past 90d): 48 | Contributors (cumulative): 134 | DMM Complexity: 0.0\n\nDIFF:\n@@ -2535,10 +2535,8 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     \"\"\"\n     if not self.built:\n       raise ValueError('This model has not yet been built. '\n-                       'Build the model first by calling `build()` or calling '\n-                       '`fit()` with some data, or specify '\n-                       'an `input_shape` argument in the first layer(s) for '\n-                       'automatic build.')\n+                       'Build the model first by calling `build()` or by calling '\n+                       'the model on a batch of data.')\n     layer_utils.print_summary(\n         self,\n         line_length=line_length,\n\n@@ -135,8 +135,15 @@ def model_to_dot(model,\n     `subgraph=True`.\n \n   Raises:\n+    ValueError: if `model_to_dot` is called before the model is built.\n     ImportError: if graphviz or pydot are not available.\n   \"\"\"\n+\n+  if not model.built:\n+    raise ValueError('This model has not yet been built. '\n+                     'Build the model first by calling `build()` or by calling '\n+                     'the model on a batch of data.')\n+\n   from keras.layers import wrappers\n   from keras.engine import sequential\n   from keras.engine import functional\n@@ -394,10 +401,19 @@ def plot_model(model,\n     show_layer_activations: Display layer activations (only for layers that\n       have an `activation` property).\n \n+  Raises:\n+    ValueError: if `plot_model` is called before the model is built.\n+\n   Returns:\n     A Jupyter notebook Image object if Jupyter is installed.\n     This enables in-line display of the model plots in notebooks.\n   \"\"\"\n+\n+  if not model.built:\n+    raise ValueError('This model has not yet been built. '\n+                     'Build the model first by calling `build()` or by calling '\n+                     'the model on a batch of data.')\n+\n   dot = model_to_dot(\n       model,\n       show_shapes=show_shapes,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8b824e8bc7538091d50d5cc07e92a25100bf2785", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 326 | Contributors (this commit): 8 | Commits (past 90d): 1 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -58,7 +58,7 @@ def load_data():\n     with shape `(50000, 1)` for the training data.\n \n   **x_test**: uint8 NumPy array of grayscale image data with shapes\n-    (10000, 32, 32, 3), containing the test data. Pixel values range\n+    `(10000, 32, 32, 3)`, containing the test data. Pixel values range\n     from 0 to 255.\n \n   **y_test**: uint8 NumPy array of labels (integers in range 0-9)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f31256bca86bf551d9beeb4bd899234cc2f725d4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 8/8 | Churn Δ: 16 | Churn Cumulative: 20515 | Contributors (this commit): 80 | Commits (past 90d): 25 | Contributors (cumulative): 84 | DMM Complexity: 0.0\n\nDIFF:\n@@ -3522,6 +3522,12 @@ class Cropping2D(Layer):\n   def call(self, inputs):\n     # pylint: disable=invalid-unary-operand-type\n     if self.data_format == 'channels_first':\n+      if (inputs.shape[2] is not None and inputs.shape[3] is not None and\n+        (sum(self.cropping[0]) >= inputs.shape[2] or\n+          sum(self.cropping[1]) >= inputs.shape[3])):\n+          raise ValueError('cropping parameter of Cropping layer must be '\n+                        'greater than the input shape. Received: inputs.shape='\n+                        f'{inputs.shape}, and cropping={self.cropping}')  \n       if self.cropping[0][1] == self.cropping[1][1] == 0:\n         return inputs[:, :, self.cropping[0][0]:, self.cropping[1][0]:]\n       elif self.cropping[0][1] == 0:\n@@ -3533,6 +3539,12 @@ class Cropping2D(Layer):\n       return inputs[:, :, self.cropping[0][0]:-self.cropping[0][1],\n                     self.cropping[1][0]:-self.cropping[1][1]]\n     else:\n+      if (inputs.shape[1] is not None and inputs.shape[2] is not None and\n+        (sum(self.cropping[0]) >= inputs.shape[1] or\n+          sum(self.cropping[1]) >= inputs.shape[2])):\n+          raise ValueError('cropping parameter of Cropping layer must be '\n+                        'greater than the input shape. Received: inputs.shape='\n+                        f'{inputs.shape}, and cropping={self.cropping}')   \n       if self.cropping[0][1] == self.cropping[1][1] == 0:\n         return inputs[:, self.cropping[0][0]:, self.cropping[1][0]:, :]\n       elif self.cropping[0][1] == 0:\n\n@@ -1082,6 +1082,10 @@ class CroppingTest(keras_parameterized.TestCase):\n       keras.layers.Cropping2D(cropping=(1, 1, 1))\n     with self.assertRaises(ValueError):\n       keras.layers.Cropping2D(cropping=None)\n+    with self.assertRaises(ValueError):\n+      input_layer = keras.layers.Input(\n+          shape=(num_samples, input_len_dim1, input_len_dim2, stack_size))\n+      keras.layers.Cropping2D(cropping=((5, 4),(3, 4)))(input_layer)\n \n   def test_cropping_3d(self):\n     num_samples = 2\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d238d7a95b420e977cb6914617b8f2cdbd3803a7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 349 | Contributors (this commit): 2 | Commits (past 90d): 1 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -275,7 +275,7 @@ class TestDistributionStrategyDnnCorrectnessWithSubclassedModel(\n       with self.assertRaisesRegex(\n           ValueError,\n           'Expected `model` argument to be a functional `Model` instance, '\n-          'but got a subclass model instead.'):\n+          'but got a subclassed model instead.'):\n         self.run_correctness_test(distribution, use_numpy, use_validation_data)\n     else:\n       with self.assertRaisesRegex(\n@@ -295,7 +295,7 @@ class TestDistributionStrategyDnnCorrectnessWithSubclassedModel(\n       with self.assertRaisesRegex(\n           ValueError,\n           'Expected `model` argument to be a functional `Model` instance, '\n-          'but got a subclass model instead.'):\n+          'but got a subclassed model instead.'):\n         self.run_dynamic_lr_test(distribution)\n     else:\n       with self.assertRaisesRegex(\n@@ -313,7 +313,7 @@ class TestDistributionStrategyDnnCorrectnessWithSubclassedModel(\n     with self.assertRaisesRegex(\n         ValueError,\n         'Expected `model` argument to be a functional `Model` instance, '\n-        'but got a subclass model instead.'):\n+        'but got a subclassed model instead.'):\n       self.run_correctness_test(\n           distribution,\n           use_numpy,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#59d53eddaa7ec5afb648e6ec4429bb33985d5679", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 260 | Contributors (this commit): 7 | Commits (past 90d): 2 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -49,7 +49,7 @@ def load_data(label_mode='fine'):\n     with shape `(50000, 1)` for the training data.\n \n   **x_test**: uint8 NumPy array of grayscale image data with shapes\n-    (10000, 32, 32, 3), containing the test data. Pixel values range\n+    `(10000, 32, 32, 3)`, containing the test data. Pixel values range\n     from 0 to 255.\n \n   **y_test**: uint8 NumPy array of labels (integers in range 0-99)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5550cb0c96c508211b1f0af4aa5af6caff7385a2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 19 | Lines Deleted: 0 | Files Changed: 4 | Hunks: 5 | Methods Changed: 4 | Complexity Δ (Sum/Max): 6/2 | Churn Δ: 19 | Churn Cumulative: 825 | Contributors (this commit): 4 | Commits (past 90d): 13 | Contributors (cumulative): 8 | DMM Complexity: 1.0\n\nDIFF:\n@@ -46,6 +46,12 @@ class PreprocessingAppliedInDatasetCreatorTest(tf.test.TestCase):\n   \"\"\"Demonstrate Keras preprocessing layers applied in tf.data.Dataset.map.\"\"\"\n \n   def testDistributedModelFit(self, strategy):\n+    if (not tf.__internal__.tf2.enabled()\n+        and isinstance(strategy,\n+                       tf.distribute.experimental.ParameterServerStrategy)):\n+      self.skipTest(\n+          \"Parameter Server strategy with dataset creator need to be run when \"\n+          \"eager execution is enabled.\")\n     with strategy.scope():\n       preprocessing_model = utils.make_preprocessing_model(self.get_temp_dir())\n       training_model = utils.make_training_model()\n\n@@ -47,6 +47,12 @@ class PreprocessingAppliedInModelTest(tf.test.TestCase):\n   \"\"\"Demonstrate Keras preprocessing layers applied inside a Model.\"\"\"\n \n   def testDistributedModelFit(self, strategy):\n+    if (not tf.__internal__.tf2.enabled()\n+        and isinstance(strategy,\n+                       tf.distribute.experimental.ParameterServerStrategy)):\n+      self.skipTest(\n+          \"Parameter Server strategy with dataset creator need to be run when \"\n+          \"eager execution is enabled.\")\n     with strategy.scope():\n       preprocessing_model = utils.make_preprocessing_model(self.get_temp_dir())\n       training_model = utils.make_training_model()\n\n@@ -183,7 +183,12 @@ class LayerUtilsTest(tf.test.TestCase):\n       reader = open(fpath, 'r')\n       lines = reader.readlines()\n       reader.close()\n+      # The output content are slightly different for the input shapes between\n+      # v1 and v2.\n+      if tf.__internal__.tf2.enabled():\n         self.assertEqual(len(lines), 39)\n+      else:\n+        self.assertEqual(len(lines), 40)\n     except ImportError:\n       pass\n \n\n@@ -232,6 +232,8 @@ class TestIsExtensionType(tf.test.TestCase):\n class TestRandomSeedSetting(tf.test.TestCase):\n \n   def test_seeds(self):\n+    if not tf.__internal__.tf2.enabled():\n+      self.skipTest('set_random_seed() is only expected to work in tf2.')\n     def get_model_output():\n       model = keras.Sequential([\n           keras.layers.Dense(10),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f4f65ef0edc1c8785e2254cdbab2b645538d06d8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 7 | Files Changed: 4 | Hunks: 4 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 5850 | Contributors (this commit): 19 | Commits (past 90d): 15 | Contributors (cumulative): 30 | DMM Complexity: 0.0\n\nDIFF:\n@@ -196,7 +196,7 @@ class Dense(Layer):\n         outputs = tf.nn.embedding_lookup_sparse(\n             self.kernel, ids, weights, combiner='sum')\n       else:\n-        outputs = tf.raw_ops.MatMul(a=inputs, b=self.kernel)\n+        outputs = tf.matmul(a=inputs, b=self.kernel)\n     # Broadcast kernel to inputs.\n     else:\n       outputs = tf.tensordot(inputs, self.kernel, [[rank - 1], [0]])\n\n@@ -210,7 +210,7 @@ class RandomFourierFeatures(base_layer.Layer):\n     inputs = tf.convert_to_tensor(inputs, dtype=self.dtype)\n     inputs = tf.cast(inputs, tf.float32)\n     kernel = (1.0 / self.kernel_scale) * self.unscaled_kernel\n-    outputs = tf.raw_ops.MatMul(a=inputs, b=kernel)\n+    outputs = tf.matmul(a=inputs, b=kernel)\n     outputs = tf.nn.bias_add(outputs, self.bias)\n     return tf.cos(outputs)\n \n\n@@ -775,10 +775,8 @@ def local_conv_sparse_matmul(inputs, kernel, kernel_idxs, kernel_shape,\n       Output (N+2)-D dense tensor with shape `output_shape`.\n   \"\"\"\n   inputs_flat = backend.reshape(inputs, (backend.shape(inputs)[0], -1))\n-  output_flat = tf.raw_ops.SparseTensorDenseMatMul(\n-      a_indices=kernel_idxs,\n-      a_values=kernel,\n-      a_shape=kernel_shape,\n+  output_flat = tf.sparse.sparse_dense_matmul(\n+      sp_a=tf.SparseTensor(kernel_idxs, kernel, kernel_shape),\n       b=inputs_flat,\n       adjoint_b=True)\n   output_flat_transpose = backend.transpose(output_flat)\n\n@@ -642,7 +642,7 @@ def update_confusion_matrix_variables(variables_to_update,\n   if y_pred.shape.ndims == 1:\n     num_labels = 1\n   else:\n-    num_labels = tf.raw_ops.Prod(input=pred_shape[1:], axis=0)\n+    num_labels = tf.math.reduce_prod(pred_shape[1:], axis=0)\n   thresh_label_tile = tf.where(one_thresh, num_labels,\n                                          tf.ones([], dtype=tf.int32))\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#37bed5b37b5b6d3774209c4232afa9f4d2e27992", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 217 | Lines Deleted: 26 | Files Changed: 4 | Hunks: 22 | Methods Changed: 19 | Complexity Δ (Sum/Max): 27/10 | Churn Δ: 243 | Churn Cumulative: 1973 | Contributors (this commit): 8 | Commits (past 90d): 19 | Contributors (cumulative): 19 | DMM Complexity: 0.981651376146789\n\nDIFF:\n@@ -14,8 +14,11 @@\n # ==============================================================================\n \"\"\"Keras Input Tensor used to track functional API Topology.\"\"\"\n \n-import tensorflow.compat.v2 as tf\n+import copy\n from keras.utils import object_identity\n+import tensorflow.compat.v2 as tf\n+\n+from tensorflow.python.data.util import structure  # pylint: disable=g-direct-tensorflow-import\n \n # pylint: disable=g-classes-have-attributes\n \n@@ -116,6 +119,18 @@ class KerasTensor:\n     self._inferred_value = inferred_value\n     self._name = name\n \n+    if not isinstance(type_spec, structure.NoneTensorSpec):\n+      if not hasattr(type_spec, 'shape'):\n+        raise ValueError(\n+            'KerasTensor only supports TypeSpecs that have a shape field; got '\n+            f'{type(type_spec).__qualname__}, which does not have a shape.')\n+      if not isinstance(type_spec.shape, tf.TensorShape):\n+        raise TypeError(\n+            \"KerasTensor requires that wrapped TypeSpec's shape is a \"\n+            f'TensorShape; got TypeSpec {type(type_spec).__qualname__}, whose '\n+            'shape field has unexpected type '\n+            f'{type(type_spec.dtype).__qualname__}.')\n+\n   @property\n   def type_spec(self):\n     \"\"\"Returns the `tf.TypeSpec` symbolically inferred for this Keras output.\"\"\"\n@@ -124,11 +139,7 @@ class KerasTensor:\n   @property\n   def shape(self):\n     \"\"\"Returns the `TensorShape` symbolically inferred for this Keras output.\"\"\"\n-    # TODO(kaftan): This is only valid for normal/sparse/ragged tensors.\n-    # may need to raise an error when it's not valid for a type_spec,\n-    # but some keras code (e.g. build-related stuff) will likely fail when\n-    # it can't access shape or dtype\n-    return self._type_spec._shape  # pylint: disable=protected-access\n+    return self._type_spec.shape\n \n   @classmethod\n   def from_tensor(cls, tensor):\n@@ -273,7 +284,12 @@ class KerasTensor:\n           f\"Keras symbolic input/output's shape {self.shape} is not \"\n           f\"compatible with supplied shape {shape}.\")\n     else:\n+      if isinstance(self._type_spec, tf.TensorSpec):\n+        # Note: this mutates self._type_spec in place -- if any other code has\n+        # a reference to self._type_spec, then they will also see this change.\n         self._type_spec._shape = shape  # pylint: disable=protected-access\n+      else:\n+        self._type_spec = type_spec_with_shape(self._type_spec, shape)\n \n   def __str__(self):\n     symbolic_description = ''\n@@ -313,11 +329,17 @@ class KerasTensor:\n   @property\n   def dtype(self):\n     \"\"\"Returns the `dtype` symbolically inferred for this Keras output.\"\"\"\n-    # TODO(kaftan): This is only valid for normal/sparse/ragged tensors.\n-    # may need to raise an error when it's not valid for a type_spec,\n-    # but some keras code (e.g. build-related stuff) will likely fail when\n-    # it can't access shape or dtype\n-    return self._type_spec._dtype  # pylint: disable=protected-access\n+    type_spec = self._type_spec\n+    if not hasattr(type_spec, 'dtype'):\n+      raise AttributeError(\n+          f'KerasTensor wraps TypeSpec {type(type_spec).__qualname__}, '\n+          'which does not have a dtype.')\n+    if not isinstance(type_spec.dtype, tf.DType):\n+      raise TypeError(\n+          \"KerasTensor requires that wrapped TypeSpec's dtype is a DType; got \"\n+          f'TypeSpec {type(type_spec).__qualname__}, whose dtype field has '\n+          f'unexpected type {type(type_spec.dtype).__qualname__}.')\n+    return type_spec.dtype\n \n   def ref(self):\n     \"\"\"Returns a hashable reference object to this KerasTensor.\n@@ -615,3 +637,20 @@ def keras_tensor_from_type_spec(type_spec, name=None):\n       break\n \n   return keras_tensor_cls.from_type_spec(type_spec, name=name)\n+\n+\n+def type_spec_with_shape(spec, shape):\n+  \"\"\"Returns a copy of TypeSpec `spec` with its shape set to `shape`.\"\"\"\n+  if isinstance(spec,\n+                (tf.TensorSpec, tf.RaggedTensorSpec, tf.SparseTensorSpec)):\n+    result = copy.deepcopy(spec)\n+    result._shape = shape  # pylint: disable=protected-access\n+    return result\n+  elif hasattr(spec, 'with_shape'):\n+    # TODO(edloper): Consider adding .with_shape method to TensorSpec,\n+    # RaggedTensorSpec, and SparseTensorSpec.\n+    return spec.with_shape(shape)\n+  else:\n+    # TODO(edloper): Consider moving this check to the KerasTensor constructor.\n+    raise ValueError('Keras requires TypeSpec to have a `with_shape` method '\n+                     'that returns a copy of `self` with an updated shape.')\n\n@@ -24,6 +24,28 @@ from keras.engine import keras_tensor\n from keras.engine import training\n \n \n+class CustomTypeSpec(tf.TypeSpec):\n+  \"\"\"Stubbed-out custom type spec, for testing.\"\"\"\n+\n+  def __init__(self, shape, dtype):\n+    self.shape = tf.TensorShape(shape)\n+    self.dtype = tf.dtypes.as_dtype(dtype)\n+\n+  # Stub implementations for all the TypeSpec methods:\n+  value_type = None\n+  _to_components = lambda self, value: None\n+  _from_components = lambda self, components: None\n+  _component_specs = property(lambda self: None)\n+  _serialize = lambda self: (self.shape, self.dtype)\n+\n+\n+class CustomTypeSpec2(CustomTypeSpec):\n+  \"\"\"Adds a with_shape method to CustomTypeSpec.\"\"\"\n+\n+  def with_shape(self, new_shape):\n+    return CustomTypeSpec2(new_shape, self.dtype)\n+\n+\n class KerasTensorTest(keras_parameterized.TestCase):\n \n   def test_repr_and_string(self):\n@@ -108,6 +130,76 @@ class KerasTensorTest(keras_parameterized.TestCase):\n     model2 = training.Model.from_config(model_config)\n     self.assertAllEqual(model2(x), expected_property)\n \n+  @parameterized.parameters([\n+      (tf.TensorSpec([2, 3], tf.int32), [2, 3]),\n+      (tf.RaggedTensorSpec([2, None]), [2, None]),\n+      (tf.SparseTensorSpec([8]), [8]),\n+      (CustomTypeSpec([3, 8], tf.int32), [3, 8]),\n+  ])\n+  def test_shape(self, spec, expected_shape):\n+    kt = keras_tensor.KerasTensor(spec)\n+    self.assertEqual(kt.shape.as_list(), expected_shape)\n+\n+  @parameterized.parameters([\n+      (tf.TensorSpec([8, 3], tf.int32), [8, 3]),\n+      (tf.TensorSpec([None, 3], tf.int32), [8, 3]),\n+      (tf.TensorSpec(None, tf.int32), [8, 3]),\n+      (tf.TensorSpec(None, tf.int32), [8, None]),\n+      (tf.TensorSpec(None, tf.int32), None),\n+      (tf.RaggedTensorSpec([2, None, None]), [2, None, 5]),\n+      (tf.SparseTensorSpec([8]), [8]),\n+      (CustomTypeSpec2([3, None], tf.int32), [3, 8]),\n+  ])\n+  def test_set_shape(self, spec, new_shape):\n+    kt = keras_tensor.KerasTensor(spec)\n+    kt.set_shape(new_shape)\n+    if new_shape is None:\n+      self.assertIsNone(kt.type_spec.shape.rank)\n+    else:\n+      self.assertEqual(kt.type_spec.shape.as_list(), new_shape)\n+    self.assertTrue(kt.type_spec.is_compatible_with(spec))\n+\n+  def test_set_shape_error(self):\n+    spec = CustomTypeSpec([3, None], tf.int32)\n+    kt = keras_tensor.KerasTensor(spec)\n+    with self.assertRaisesRegex(\n+        ValueError, \"Keras requires TypeSpec to have a `with_shape` method\"):\n+      kt.set_shape([3, 3])\n+\n+  def test_missing_shape_error(self):\n+    spec = CustomTypeSpec(None, tf.int32)\n+    del spec.shape\n+    with self.assertRaisesRegex(\n+        ValueError,\n+        \"KerasTensor only supports TypeSpecs that have a shape field; .*\"):\n+      keras_tensor.KerasTensor(spec)\n+\n+  def test_wrong_shape_type_error(self):\n+    spec = CustomTypeSpec(None, tf.int32)\n+    spec.shape = \"foo\"\n+    with self.assertRaisesRegex(\n+        TypeError, \"KerasTensor requires that wrapped TypeSpec's shape is a \"\n+        \"TensorShape; .*\"):\n+      keras_tensor.KerasTensor(spec)\n+\n+  def test_missing_dtype_error(self):\n+    spec = CustomTypeSpec(None, tf.int32)\n+    del spec.dtype\n+    kt = keras_tensor.KerasTensor(spec)\n+    with self.assertRaisesRegex(\n+        AttributeError,\n+        \"KerasTensor wraps TypeSpec .* which does not have a dtype.\"):\n+      kt.dtype  # pylint: disable=pointless-statement\n+\n+  def test_wrong_dtype_type_error(self):\n+    spec = CustomTypeSpec(None, tf.int32)\n+    spec.dtype = \"foo\"\n+    kt = keras_tensor.KerasTensor(spec)\n+    with self.assertRaisesRegex(\n+        TypeError,\n+        \"KerasTensor requires that wrapped TypeSpec's dtype is a DType; .*\"):\n+      kt.dtype  # pylint: disable=pointless-statement\n+\n \n if __name__ == \"__main__\":\n   tf.compat.v1.enable_eager_execution()\n\n@@ -14,18 +14,21 @@\n # ==============================================================================\n \"\"\"TensorFlow-related utilities.\"\"\"\n \n-import tensorflow.compat.v2 as tf\n-\n import collections\n-import copy\n import random\n-import numpy as np\n-from tensorflow.python.framework import ops\n+\n from keras import backend\n from keras.engine import keras_tensor\n from keras.utils import object_identity\n from keras.utils import tf_contextlib\n+\n+import numpy as np\n+\n+import tensorflow.compat.v2 as tf\n+# pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.framework import ops\n from tensorflow.python.util.tf_export import keras_export\n+# pylint: enable=g-direct-tensorflow-import\n \n \n @keras_export('keras.utils.set_random_seed', v1=[])\n@@ -503,19 +506,18 @@ def get_tensor_spec(t, dynamic_batch=False, name=None):\n     spec = tf.TensorSpec(shape=t.shape, dtype=t.dtype, name=name)\n   else:\n     return None  # Allow non-Tensors to pass through.\n+  # pylint: enable=protected-access\n \n   if not dynamic_batch:\n     return spec\n \n-  dynamic_batch_spec = copy.deepcopy(spec)\n-  # RaggedTensorSpec only has a private _shape.\n-  shape = dynamic_batch_spec._shape\n-  if shape.rank is not None and shape.rank > 0:\n+  shape = spec.shape\n+  if shape.rank is None or shape.rank == 0:\n+    return spec\n+\n   shape_list = shape.as_list()\n   shape_list[0] = None\n-    dynamic_batch_spec._shape = tf.TensorShape(shape_list)\n-  return dynamic_batch_spec\n-  # pylint: enable=protected-access\n+  return keras_tensor.type_spec_with_shape(spec, tf.TensorShape(shape_list))\n \n \n def sync_to_numpy_or_python_type(tensors):\n\n@@ -14,13 +14,12 @@\n # ==============================================================================\n \"\"\"Tests for Keras TF utils.\"\"\"\n \n-import tensorflow.compat.v2 as tf\n-\n from absl.testing import parameterized\n-import numpy as np\n import keras\n from keras import combinations\n from keras.utils import tf_utils\n+import numpy as np\n+import tensorflow.compat.v2 as tf\n \n try:\n   import attr  # pylint:disable=g-import-not-at-top\n@@ -251,5 +250,64 @@ class TestRandomSeedSetting(tf.test.TestCase):\n     self.assertAllClose(y1, y2, atol=1e-6)\n \n \n+class CustomTypeSpec(tf.TypeSpec):\n+  \"\"\"Stubbed-out custom type spec, for testing.\"\"\"\n+\n+  def __init__(self, shape, dtype):\n+    self.shape = tf.TensorShape(shape)\n+    self.dtype = tf.dtypes.as_dtype(dtype)\n+\n+  def with_shape(self, new_shape):\n+    return CustomTypeSpec(new_shape, self.dtype)\n+\n+  # Stub implementations for all the TypeSpec methods:\n+  value_type = None\n+  _to_components = lambda self, value: None\n+  _from_components = lambda self, components: None\n+  _component_specs = property(lambda self: None)\n+  _serialize = lambda self: (self.shape, self.dtype)\n+\n+\n+class TestGetTensorSpec(parameterized.TestCase):\n+\n+  @parameterized.parameters([\n+      (lambda: tf.constant([[1, 2]]), [1, 2]),\n+      (tf.TensorSpec([8, 3], tf.int32), [8, 3]),\n+      (tf.TensorSpec([8], tf.int32), [8]),\n+      (tf.TensorSpec([], tf.int32), []),\n+      (tf.TensorSpec(None, tf.int32), None),\n+      (tf.RaggedTensorSpec([8, 3], tf.int32), [8, 3]),\n+      (tf.SparseTensorSpec([8, 3], tf.int32), [8, 3]),\n+  ])\n+  def test_without_dynamic_batch(self, t, expected_shape):\n+    if callable(t):\n+      t = t()\n+    result = tf_utils.get_tensor_spec(t)\n+    self.assertTrue(result.is_compatible_with(t))\n+    if expected_shape is None:\n+      self.assertIsNone(result.shape.rank)\n+    else:\n+      self.assertEqual(result.shape.as_list(), expected_shape)\n+\n+  @parameterized.parameters([\n+      (lambda: tf.constant([[1, 2]]), [None, 2]),\n+      (tf.TensorSpec([8, 3], tf.int32), [None, 3]),\n+      (tf.TensorSpec([8], tf.int32), [None]),\n+      (tf.TensorSpec([], tf.int32), []),\n+      (tf.TensorSpec(None, tf.int32), None),\n+      (tf.RaggedTensorSpec([8, 3], tf.int32), [None, 3]),\n+      (tf.SparseTensorSpec([8, 3], tf.int32), [None, 3]),\n+  ])\n+  def test_with_dynamic_batch(self, t, expected_shape):\n+    if callable(t):\n+      t = t()\n+    result = tf_utils.get_tensor_spec(t, True)\n+    self.assertTrue(result.is_compatible_with(t))\n+    if expected_shape is None:\n+      self.assertIsNone(result.shape.rank)\n+    else:\n+      self.assertEqual(result.shape.as_list(), expected_shape)\n+\n+\n if __name__ == '__main__':\n   tf.test.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
