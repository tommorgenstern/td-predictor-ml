{"custom_id": "keras#a2542cefd924ed70ef381dc432233fbdf348596a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 157 | Lines Deleted: 6 | Files Changed: 2 | Hunks: 10 | Methods Changed: 7 | Complexity Δ (Sum/Max): 14/14 | Churn Δ: 163 | Churn Cumulative: 1152 | Contributors (this commit): 3 | Commits (past 90d): 7 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -74,6 +74,12 @@ class GroupNormalization(Layer):\n         default.  Input shape: Arbitrary. Use the keyword argument `input_shape`\n         (tuple of integers, does not include the samples axis) when using this\n         layer as the first layer in a model.  Output shape: Same shape as input.\n+\n+    Call arguments:\n+      inputs: Input tensor (of any rank).\n+      mask: The mask parameter is a tensor that indicates the weight for each\n+        position in the input tensor when computing the mean and variance.\n+\n     Reference: - [Yuxin Wu & Kaiming He, 2018](https://arxiv.org/abs/1803.08494)\n     \"\"\"\n \n@@ -160,13 +166,19 @@ class GroupNormalization(Layer):\n \n         super().build(input_shape)\n \n-    def call(self, inputs):\n+    def call(self, inputs, mask=None):\n         input_shape = tf.shape(inputs)\n \n+        if mask is None:\n+            mask = tf.ones_like(inputs)\n+\n         reshaped_inputs = self._reshape_into_groups(inputs)\n+        reshaped_mask = self._reshape_into_groups(mask)\n \n         normalized_inputs = self._apply_normalization(\n-            reshaped_inputs, input_shape\n+            reshaped_inputs=reshaped_inputs,\n+            input_shape=input_shape,\n+            reshaped_mask=reshaped_mask,\n         )\n \n         return tf.reshape(normalized_inputs, input_shape)\n@@ -181,14 +193,25 @@ class GroupNormalization(Layer):\n         reshaped_inputs = tf.reshape(inputs, group_shape)\n         return reshaped_inputs\n \n-    def _apply_normalization(self, reshaped_inputs, input_shape):\n+    def _apply_normalization(\n+        self,\n+        *,\n+        reshaped_inputs,\n+        reshaped_mask,\n+        input_shape,\n+    ):\n         group_reduction_axes = list(range(1, reshaped_inputs.shape.rank))\n \n-        axis = -2 if self.axis == -1 else self.axis - 1\n+        axis = self.axis - 1\n         group_reduction_axes.pop(axis)\n \n-        mean, variance = tf.nn.moments(\n-            reshaped_inputs, group_reduction_axes, keepdims=True\n+        mask_weights = tf.cast(reshaped_mask, reshaped_inputs.dtype)\n+\n+        mean, variance = tf.nn.weighted_moments(\n+            reshaped_inputs,\n+            axes=group_reduction_axes,\n+            frequency_weights=mask_weights,\n+            keepdims=True,\n         )\n \n         gamma, beta = self._get_reshaped_weights(input_shape)\n\n@@ -105,6 +105,72 @@ class GroupNormalizationTest(test_combinations.TestCase):\n             atol=1e-3,\n         )\n \n+    @test_combinations.run_all_keras_modes\n+    def test_correctness_1d_with_mask(self):\n+        layer_with_1_group = GroupNormalization(\n+            groups=1, axis=-1, input_shape=(8,), scale=False, center=False\n+        )\n+        layer_with_2_groups = GroupNormalization(\n+            groups=2, axis=1, input_shape=(8,), scale=False, center=False\n+        )\n+\n+        inputs = tf.constant(\n+            [-1.0, -1.0, 1.0, 1.0, 2.0, 2.0, 0, -2.0], shape=(1, 8)\n+        )\n+\n+        mask1 = tf.constant(\n+            [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], shape=(1, 8)\n+        )\n+        mask2 = tf.constant(\n+            [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0], shape=(1, 8)\n+        )\n+\n+        expected_output_1_group = tf.constant(\n+            [-0.706, -0.706, 1.413, 1.413, 2.473, 2.473, 0.353, -1.766],\n+            shape=(1, 8),\n+        )\n+        self.assertAllClose(\n+            _build_group_normalization_model(layer_with_1_group)(\n+                inputs, mask=mask1\n+            ),\n+            expected_output_1_group,\n+            atol=1e-3,\n+        )\n+\n+        expected_output_2_groups = tf.constant(\n+            [-1.0, -1.0, 1.0, 1.0, 0.999, 0.999, 0.0, -0.999], shape=(1, 8)\n+        )\n+        self.assertAllClose(\n+            _build_group_normalization_model(layer_with_2_groups)(\n+                inputs, mask=mask2\n+            ),\n+            expected_output_2_groups,\n+            atol=1e-3,\n+        )\n+\n+    @test_combinations.run_all_keras_modes\n+    def test_correctness_1d_with_non_binary_mask(self):\n+        norm = GroupNormalization(\n+            groups=1, axis=-1, input_shape=(8,), scale=False, center=False\n+        )\n+        inputs = tf.constant(\n+            [-1.0, -1.0, 1.0, 1.0, 2.0, 2.0, 0, -2.0], shape=(1, 8)\n+        )\n+\n+        mask = tf.constant(\n+            [0.5, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], shape=(1, 8)\n+        )\n+\n+        expected_output = tf.constant(\n+            [-0.999, -0.999, 0.999, 0.999, 1.999, 1.999, 0.0, -1.999],\n+            shape=(1, 8),\n+        )\n+        self.assertAllClose(\n+            _build_group_normalization_model(norm)(inputs, mask=mask),\n+            expected_output,\n+            atol=1e-3,\n+        )\n+\n     @test_combinations.run_all_keras_modes\n     def test_correctness_2d(self):\n         layer_with_1_group = GroupNormalization(\n@@ -138,6 +204,68 @@ class GroupNormalizationTest(test_combinations.TestCase):\n             atol=1e-3,\n         )\n \n+    @test_combinations.run_all_keras_modes\n+    def test_correctness_2d_with_mask(self):\n+        layer_with_1_group = GroupNormalization(\n+            groups=1, axis=-1, input_shape=(2, 4), scale=False, center=False\n+        )\n+        layer_with_2_groups = GroupNormalization(\n+            groups=2, axis=2, input_shape=(2, 4), scale=False, center=False\n+        )\n+\n+        inputs = tf.constant(\n+            [[-1.0, -1.0, 2.0, 2.0], [1.0, 1.0, 0, -2.0]], shape=(1, 2, 4)\n+        )\n+\n+        mask1 = tf.constant(\n+            [\n+                [\n+                    1.0,\n+                    1.0,\n+                    0.0,\n+                    0.0,\n+                ],\n+                [1.0, 0.0, 0.0, 0.0],\n+            ],\n+            shape=(1, 2, 4),\n+        )\n+        mask2 = tf.constant(\n+            [\n+                [\n+                    1.0,\n+                    1.0,\n+                    0.0,\n+                    1.0,\n+                ],\n+                [1.0, 1.0, 0.0, 1.0],\n+            ],\n+            shape=(1, 2, 4),\n+        )\n+\n+        expected_output_1_group = tf.constant(\n+            [[-0.706, -0.706, 2.473, 2.473], [1.413, 1.413, 0.353, -1.766]],\n+            shape=(1, 2, 4),\n+        )\n+        self.assertAllClose(\n+            _build_group_normalization_model(layer_with_1_group)(\n+                inputs, mask=mask1\n+            ),\n+            expected_output_1_group,\n+            atol=1e-3,\n+        )\n+\n+        expected_output_2_groups = tf.constant(\n+            [[-1.0, -1.0, 0.999, 0.999], [1.0, 1.0, 0.0, -0.999]],\n+            shape=(1, 2, 4),\n+        )\n+        self.assertAllClose(\n+            _build_group_normalization_model(layer_with_2_groups)(\n+                inputs, mask=mask2\n+            ),\n+            expected_output_2_groups,\n+            atol=1e-3,\n+        )\n+\n     @test_combinations.run_all_keras_modes\n     def test_correctness_instance_norm(self):\n         instance_norm_layer = GroupNormalization(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d5493319b89b052d2f617e736f7d4a4cf3b92371", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 395 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 3 | Methods Changed: 7 | Complexity Δ (Sum/Max): 28/28 | Churn Δ: 395 | Churn Cumulative: 566 | Contributors (this commit): 2 | Commits (past 90d): 8 | Contributors (cumulative): 3 | DMM Complexity: 0.4367816091954023\n\nDIFF:\n@@ -14,6 +14,7 @@ from keras_core.applications import mobilenet\n from keras_core.applications import mobilenet_v2\n from keras_core.applications import mobilenet_v3\n from keras_core.applications import nasnet\n+from keras_core.applications import resnet\n from keras_core.applications import vgg16\n from keras_core.applications import vgg19\n from keras_core.applications import xception\n@@ -69,6 +70,8 @@ MODEL_LIST = [\n     # nasnet\n     (nasnet.NASNetMobile, 1056, nasnet),\n     (nasnet.NASNetLarge, 4032, nasnet),\n+    # resnet\n+    (resnet.ResNet50, 2048, resnet),\n ]\n # Add names for `named_parameters`.\n MODEL_LIST = [(e[0].__name__, *e) for e in MODEL_LIST]\n\n@@ -0,0 +1,392 @@\n+from tensorflow.io import gfile\n+\n+from keras_core import backend\n+from keras_core import layers\n+from keras_core.api_export import keras_core_export\n+from keras_core.applications import imagenet_utils\n+from keras_core.models import Functional\n+from keras_core.operations import operation_utils\n+from keras_core.utils import file_utils\n+\n+BASE_WEIGHTS_PATH = (\n+    \"https://storage.googleapis.com/tensorflow/keras-applications/resnet/\"\n+)\n+WEIGHTS_HASHES = {\n+    \"resnet50\": (\n+        \"2cb95161c43110f7111970584f804107\",\n+        \"4d473c1dd8becc155b73f8504c6f6626\",\n+    ),\n+}\n+\n+\n+def ResNet(\n+    stack_fn,\n+    preact,\n+    use_bias,\n+    model_name=\"resnet\",\n+    include_top=True,\n+    weights=\"imagenet\",\n+    input_tensor=None,\n+    input_shape=None,\n+    pooling=None,\n+    classes=1000,\n+    classifier_activation=\"softmax\",\n+):\n+    \"\"\"Instantiates the ResNet, ResNetV2, and ResNeXt architecture.\n+\n+    Args:\n+        stack_fn: A function that returns output tensor for the\n+            stacked residual blocks.\n+        preact: Whether to use pre-activation or not. `True` for ResNetV2,\n+            `False` for ResNet and ResNeXt.\n+        use_bias: Whether to use biases for convolutional layers or not.\n+            `True` for ResNet and ResNetV2, `False` for ResNeXt.\n+        model_name: Name of the model.\n+        include_top: Whether to include the fully-connected\n+            layer at the top of the network.\n+        weights: One of `None` (random initialization),\n+            `\"imagenet\"` (pre-training on ImageNet),\n+            or the path to the weights file to be loaded.\n+        input_tensor: Optional Keras tensor (i.e. output of `layers.Input()`)\n+            to use as image input for the model.\n+        input_shape: Optional shape tuple, only to be specified\n+            if `include_top` is `False` (otherwise the input shape\n+            has to be `(224, 224, 3)` (with `channels_last` data format)\n+            or `(3, 224, 224)` (with `\"channels_first\"` data format). It\n+            should have exactly 3 inputs channels.\n+        pooling: Optional pooling mode for feature extraction\n+            when `include_top` is `False`.\n+            - `None` means that the output of the model will be\n+                the 4D tensor output of the\n+                last convolutional layer.\n+            - `avg` means that global average pooling\n+                will be applied to the output of the\n+                last convolutional layer, and thus\n+                the output of the model will be a 2D tensor.\n+            - `max` means that global max pooling will\n+                be applied.\n+        classes: optional number of classes to classify images\n+          into, only to be specified if `include_top` is `True`,\n+          and if no `weights` argument is specified.\n+        classifier_activation: A `str` or callable. The activation\n+            function to use on the \"top\" layer. Ignored unless\n+            `include_top=True`. Set `classifier_activation=None` to\n+            return the logits of the \"top\" layer. When loading\n+            pretrained weights, `classifier_activation` can only be\n+            `None` or `\"softmax\"`.\n+\n+    Returns:\n+        A Model instance.\n+    \"\"\"\n+\n+    if not (weights in {\"imagenet\", None} or gfile.exists(weights)):\n+        raise ValueError(\n+            \"The `weights` argument should be either \"\n+            \"`None` (random initialization), 'imagenet' \"\n+            \"(pre-training on ImageNet), \"\n+            \"or the path to the weights file to be loaded.  Received: \"\n+            f\"weights={weights}\"\n+        )\n+\n+    if weights == \"imagenet\" and include_top and classes != 1000:\n+        raise ValueError(\n+            \"If using `weights='imagenet'` with `include_top=True`, \"\n+            \"`classes` should be 1000.  \"\n+            f\"Received classes={classes}\"\n+        )\n+\n+    # Determine proper input shape\n+    input_shape = imagenet_utils.obtain_input_shape(\n+        input_shape,\n+        default_size=224,\n+        min_size=32,\n+        data_format=backend.image_data_format(),\n+        require_flatten=include_top,\n+        weights=weights,\n+    )\n+\n+    if input_tensor is None:\n+        img_input = layers.Input(shape=input_shape)\n+    else:\n+        if not backend.is_keras_tensor(input_tensor):\n+            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n+        else:\n+            img_input = input_tensor\n+\n+    if backend.image_data_format() == \"channels_last\":\n+        bn_axis = 3\n+    else:\n+        bn_axis = 1\n+\n+    x = layers.ZeroPadding2D(padding=((3, 3), (3, 3)), name=\"conv1_pad\")(\n+        img_input\n+    )\n+    x = layers.Conv2D(64, 7, strides=2, use_bias=use_bias, name=\"conv1_conv\")(x)\n+\n+    if not preact:\n+        x = layers.BatchNormalization(\n+            axis=bn_axis, epsilon=1.001e-5, name=\"conv1_bn\"\n+        )(x)\n+        x = layers.Activation(\"relu\", name=\"conv1_relu\")(x)\n+\n+    x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name=\"pool1_pad\")(x)\n+    x = layers.MaxPooling2D(3, strides=2, name=\"pool1_pool\")(x)\n+\n+    x = stack_fn(x)\n+\n+    if preact:\n+        x = layers.BatchNormalization(\n+            axis=bn_axis, epsilon=1.001e-5, name=\"post_bn\"\n+        )(x)\n+        x = layers.Activation(\"relu\", name=\"post_relu\")(x)\n+\n+    if include_top:\n+        x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(x)\n+\n+        # Validate activation for the classifier layer\n+        imagenet_utils.validate_activation(classifier_activation, weights)\n+\n+        x = layers.Dense(\n+            classes, activation=classifier_activation, name=\"predictions\"\n+        )(x)\n+    else:\n+        if pooling == \"avg\":\n+            x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(x)\n+        elif pooling == \"max\":\n+            x = layers.GlobalMaxPooling2D(name=\"max_pool\")(x)\n+\n+    # Ensure that the model takes into account\n+    # any potential predecessors of `input_tensor`.\n+    if input_tensor is not None:\n+        inputs = operation_utils.get_source_inputs(input_tensor)\n+    else:\n+        inputs = img_input\n+\n+    # Create model.\n+    model = Functional(inputs, x, name=model_name)\n+\n+    # Load weights.\n+    if (weights == \"imagenet\") and (model_name in WEIGHTS_HASHES):\n+        if include_top:\n+            file_name = model_name + \"_weights_tf_dim_ordering_tf_kernels.h5\"\n+            file_hash = WEIGHTS_HASHES[model_name][0]\n+        else:\n+            file_name = (\n+                model_name + \"_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n+            )\n+            file_hash = WEIGHTS_HASHES[model_name][1]\n+        weights_path = file_utils.get_file(\n+            file_name,\n+            BASE_WEIGHTS_PATH + file_name,\n+            cache_subdir=\"models\",\n+            file_hash=file_hash,\n+        )\n+        model.load_weights(weights_path)\n+    elif weights is not None:\n+        model.load_weights(weights)\n+\n+    return model\n+\n+\n+def residual_block_v1(\n+    x, filters, kernel_size=3, stride=1, conv_shortcut=True, name=None\n+):\n+    \"\"\"A residual block for ResNet*_v1.\n+\n+    Args:\n+        x: Input tensor.\n+        filters: No of filters in the bottleneck layer.\n+        kernel_size: Kernel size of the bottleneck layer. Defaults to 3\n+        stride: Stride of the first layer. Defaults to 1\n+        conv_shortcut: Use convolution shortcut if `True`, otherwise\n+            use identity shortcut. Defaults to `True`\n+        name(optional): Name of the block\n+\n+    Returns:\n+        Output tensor for the residual block.\n+    \"\"\"\n+\n+    if backend.image_data_format() == \"channels_last\":\n+        bn_axis = 3\n+    else:\n+        bn_axis = 1\n+\n+    if conv_shortcut:\n+        shortcut = layers.Conv2D(\n+            4 * filters, 1, strides=stride, name=name + \"_0_conv\"\n+        )(x)\n+        shortcut = layers.BatchNormalization(\n+            axis=bn_axis, epsilon=1.001e-5, name=name + \"_0_bn\"\n+        )(shortcut)\n+    else:\n+        shortcut = x\n+\n+    x = layers.Conv2D(filters, 1, strides=stride, name=name + \"_1_conv\")(x)\n+    x = layers.BatchNormalization(\n+        axis=bn_axis, epsilon=1.001e-5, name=name + \"_1_bn\"\n+    )(x)\n+    x = layers.Activation(\"relu\", name=name + \"_1_relu\")(x)\n+\n+    x = layers.Conv2D(\n+        filters, kernel_size, padding=\"SAME\", name=name + \"_2_conv\"\n+    )(x)\n+    x = layers.BatchNormalization(\n+        axis=bn_axis, epsilon=1.001e-5, name=name + \"_2_bn\"\n+    )(x)\n+    x = layers.Activation(\"relu\", name=name + \"_2_relu\")(x)\n+\n+    x = layers.Conv2D(4 * filters, 1, name=name + \"_3_conv\")(x)\n+    x = layers.BatchNormalization(\n+        axis=bn_axis, epsilon=1.001e-5, name=name + \"_3_bn\"\n+    )(x)\n+\n+    x = layers.Add(name=name + \"_add\")([shortcut, x])\n+    x = layers.Activation(\"relu\", name=name + \"_out\")(x)\n+    return x\n+\n+\n+def stack_residual_blocks_v1(x, filters, blocks, stride1=2, name=None):\n+    \"\"\"A set of stacked residual blocks.\n+\n+    Args:\n+        x: Input tensor.\n+        filters: Number of filters in the bottleneck layer in a block.\n+        blocks: Number of blocks in the stacked blocks.\n+        stride1: Stride of the first layer in the first block. Defaults to 2.\n+        name: Stack label.\n+\n+    Returns:\n+        Output tensor for the stacked blocks.\n+    \"\"\"\n+\n+    x = residual_block_v1(x, filters, stride=stride1, name=name + \"_block1\")\n+    for i in range(2, blocks + 1):\n+        x = residual_block_v1(\n+            x, filters, conv_shortcut=False, name=name + \"_block\" + str(i)\n+        )\n+    return x\n+\n+\n+@keras_core_export(\n+    [\n+        \"keras_core.applications.resnet50.ResNet50\",\n+        \"keras_core.applications.resnet.ResNet50\",\n+        \"keras_core.applications.ResNet50\",\n+    ]\n+)\n+def ResNet50(\n+    include_top=True,\n+    weights=\"imagenet\",\n+    input_tensor=None,\n+    input_shape=None,\n+    pooling=None,\n+    classes=1000,\n+    classifier_activation=\"softmax\",\n+):\n+    \"\"\"Instantiates the ResNet50 architecture.\"\"\"\n+\n+    def stack_fn(x):\n+        x = stack_residual_blocks_v1(x, 64, 3, stride1=1, name=\"conv2\")\n+        x = stack_residual_blocks_v1(x, 128, 4, name=\"conv3\")\n+        x = stack_residual_blocks_v1(x, 256, 6, name=\"conv4\")\n+        return stack_residual_blocks_v1(x, 512, 3, name=\"conv5\")\n+\n+    return ResNet(\n+        stack_fn,\n+        False,\n+        True,\n+        \"resnet50\",\n+        include_top,\n+        weights,\n+        input_tensor,\n+        input_shape,\n+        pooling,\n+        classes,\n+        classifier_activation=classifier_activation,\n+    )\n+\n+\n+@keras_core_export(\n+    [\n+        \"keras_core.applications.resnet50.preprocess_input\",\n+        \"keras_core.applications.resnet.preprocess_input\",\n+    ]\n+)\n+def preprocess_input(x, data_format=None):\n+    return imagenet_utils.preprocess_input(\n+        x, data_format=data_format, mode=\"caffe\"\n+    )\n+\n+\n+@keras_core_export(\n+    [\n+        \"keras_core.applications.resnet50.decode_predictions\",\n+        \"keras_core.applications.resnet.decode_predictions\",\n+    ]\n+)\n+def decode_predictions(preds, top=5):\n+    return imagenet_utils.decode_predictions(preds, top=top)\n+\n+\n+preprocess_input.__doc__ = imagenet_utils.PREPROCESS_INPUT_DOC.format(\n+    mode=\"\",\n+    ret=imagenet_utils.PREPROCESS_INPUT_RET_DOC_CAFFE,\n+    error=imagenet_utils.PREPROCESS_INPUT_ERROR_DOC,\n+)\n+decode_predictions.__doc__ = imagenet_utils.decode_predictions.__doc__\n+\n+DOC = \"\"\"\n+\n+Reference:\n+- [Deep Residual Learning for Image Recognition](\n+    https://arxiv.org/abs/1512.03385) (CVPR 2015)\n+\n+For image classification use cases, see [this page for detailed examples](\n+    https://keras.io/api/applications/#usage-examples-for-image-classification-models).\n+\n+For transfer learning use cases, make sure to read the\n+[guide to transfer learning & fine-tuning](\n+    https://keras.io/guides/transfer_learning/).\n+\n+Note: each Keras Application expects a specific kind of input preprocessing.\n+For ResNet, call `keras_core.applications.resnet.preprocess_input` on your\n+inputs before passing them to the model. `resnet.preprocess_input` will convert\n+the input images from RGB to BGR, then will zero-center each color channel with\n+respect to the ImageNet dataset, without scaling.\n+\n+Args:\n+    include_top: whether to include the fully-connected\n+        layer at the top of the network.\n+    weights: one of `None` (random initialization),\n+        `\"imagenet\"` (pre-training on ImageNet), or the path to the weights\n+        file to be loaded.\n+    input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n+        to use as image input for the model.\n+    input_shape: optional shape tuple, only to be specified if `include_top`\n+        is `False` (otherwise the input shape has to be `(224, 224, 3)`\n+        (with `\"channels_last\"` data format) or `(3, 224, 224)`\n+        (with `\"channels_first\"` data format). It should have exactly 3\n+        inputs channels, and width and height should be no smaller than 32.\n+        E.g. `(200, 200, 3)` would be one valid value.\n+    pooling: Optional pooling mode for feature extraction when `include_top`\n+        is `False`.\n+        - `None` means that the output of the model will be the 4D tensor\n+                output of the last convolutional block.\n+        - `avg` means that global average pooling will be applied to the output\n+                of the last convolutional block, and thus the output of the\n+                model will be a 2D tensor.\n+        - `max` means that global max pooling will be applied.\n+    classes: optional number of classes to classify images into, only to be\n+        specified if `include_top` is `True`, and if no `weights` argument is\n+        specified.\n+    classifier_activation: A `str` or callable. The activation function to\n+        use on the \"top\" layer. Ignored unless `include_top=True`. Set\n+        `classifier_activation=None` to return the logits of the \"top\" layer.\n+        When loading pretrained weights, `classifier_activation` can only\n+        be `None` or `\"softmax\"`.\n+\n+Returns:\n+    A Model instance.\n+\"\"\"\n+\n+setattr(ResNet50, \"__doc__\", ResNet50.__doc__ + DOC)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#090112323cf12f5da6b6c7532cb0331bdf4330ec", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 399 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 7 | Methods Changed: 14 | Complexity Δ (Sum/Max): 18/10 | Churn Δ: 399 | Churn Cumulative: 965 | Contributors (this commit): 2 | Commits (past 90d): 11 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -15,6 +15,7 @@ from keras_core.applications import mobilenet_v2\n from keras_core.applications import mobilenet_v3\n from keras_core.applications import nasnet\n from keras_core.applications import resnet\n+from keras_core.applications import resnet_v2\n from keras_core.applications import vgg16\n from keras_core.applications import vgg19\n from keras_core.applications import xception\n@@ -72,6 +73,11 @@ MODEL_LIST = [\n     (nasnet.NASNetLarge, 4032, nasnet),\n     # resnet\n     (resnet.ResNet50, 2048, resnet),\n+    (resnet.ResNet101, 2048, resnet),\n+    (resnet.ResNet152, 2048, resnet),\n+    (resnet_v2.ResNet50V2, 2048, resnet_v2),\n+    (resnet_v2.ResNet101V2, 2048, resnet_v2),\n+    (resnet_v2.ResNet152V2, 2048, resnet_v2),\n ]\n # Add names for `named_parameters`.\n MODEL_LIST = [(e[0].__name__, *e) for e in MODEL_LIST]\n\n@@ -16,6 +16,34 @@ WEIGHTS_HASHES = {\n         \"2cb95161c43110f7111970584f804107\",\n         \"4d473c1dd8becc155b73f8504c6f6626\",\n     ),\n+    \"resnet101\": (\n+        \"f1aeb4b969a6efcfb50fad2f0c20cfc5\",\n+        \"88cf7a10940856eca736dc7b7e228a21\",\n+    ),\n+    \"resnet152\": (\n+        \"100835be76be38e30d865e96f2aaae62\",\n+        \"ee4c566cf9a93f14d82f913c2dc6dd0c\",\n+    ),\n+    \"resnet50v2\": (\n+        \"3ef43a0b657b3be2300d5770ece849e0\",\n+        \"fac2f116257151a9d068a22e544a4917\",\n+    ),\n+    \"resnet101v2\": (\n+        \"6343647c601c52e1368623803854d971\",\n+        \"c0ed64b8031c3730f411d2eb4eea35b5\",\n+    ),\n+    \"resnet152v2\": (\n+        \"a49b44d1979771252814e80f8ec446f9\",\n+        \"ed17cf2e0169df9d443503ef94b23b33\",\n+    ),\n+    \"resnext50\": (\n+        \"67a5b30d522ed92f75a1f16eef299d1a\",\n+        \"62527c363bdd9ec598bed41947b379fc\",\n+    ),\n+    \"resnext101\": (\n+        \"34fb605428fcc7aa4d62f44404c11509\",\n+        \"0f678c91647380debd923963594981b3\",\n+    ),\n }\n \n \n@@ -267,6 +295,92 @@ def stack_residual_blocks_v1(x, filters, blocks, stride1=2, name=None):\n     return x\n \n \n+def residual_block_v2(\n+    x, filters, kernel_size=3, stride=1, conv_shortcut=False, name=None\n+):\n+    \"\"\"A residual block for ResNet*_v2.\n+\n+    Args:\n+        x: Input tensor.\n+        filters: No of filters in the bottleneck layer.\n+        kernel_size: Kernel size of the bottleneck layer. Defaults to 3\n+        stride: Stride of the first layer. Defaults to 1\n+        conv_shortcut: Use convolution shortcut if `True`, otherwise\n+            use identity shortcut. Defaults to `True`\n+        name(optional): Name of the block\n+\n+    Returns:\n+        Output tensor for the residual block.\n+    \"\"\"\n+\n+    if backend.image_data_format() == \"channels_last\":\n+        bn_axis = 3\n+    else:\n+        bn_axis = 1\n+\n+    preact = layers.BatchNormalization(\n+        axis=bn_axis, epsilon=1.001e-5, name=name + \"_preact_bn\"\n+    )(x)\n+    preact = layers.Activation(\"relu\", name=name + \"_preact_relu\")(preact)\n+\n+    if conv_shortcut:\n+        shortcut = layers.Conv2D(\n+            4 * filters, 1, strides=stride, name=name + \"_0_conv\"\n+        )(preact)\n+    else:\n+        shortcut = (\n+            layers.MaxPooling2D(1, strides=stride)(x) if stride > 1 else x\n+        )\n+\n+    x = layers.Conv2D(\n+        filters, 1, strides=1, use_bias=False, name=name + \"_1_conv\"\n+    )(preact)\n+    x = layers.BatchNormalization(\n+        axis=bn_axis, epsilon=1.001e-5, name=name + \"_1_bn\"\n+    )(x)\n+    x = layers.Activation(\"relu\", name=name + \"_1_relu\")(x)\n+\n+    x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name=name + \"_2_pad\")(x)\n+    x = layers.Conv2D(\n+        filters,\n+        kernel_size,\n+        strides=stride,\n+        use_bias=False,\n+        name=name + \"_2_conv\",\n+    )(x)\n+    x = layers.BatchNormalization(\n+        axis=bn_axis, epsilon=1.001e-5, name=name + \"_2_bn\"\n+    )(x)\n+    x = layers.Activation(\"relu\", name=name + \"_2_relu\")(x)\n+\n+    x = layers.Conv2D(4 * filters, 1, name=name + \"_3_conv\")(x)\n+    x = layers.Add(name=name + \"_out\")([shortcut, x])\n+    return x\n+\n+\n+def stack_residual_blocks_v2(x, filters, blocks, stride1=2, name=None):\n+    \"\"\"A set of stacked residual blocks.\n+\n+    Args:\n+        x: Input tensor.\n+        filters: Number of filters in the bottleneck layer in a block.\n+        blocks: Number of blocks in the stacked blocks.\n+        stride1: Stride of the first layer in the first block. Defaults to 2.\n+        name: Stack label.\n+\n+    Returns:\n+        Output tensor for the stacked blocks.\n+    \"\"\"\n+\n+    x = residual_block_v2(x, filters, conv_shortcut=True, name=name + \"_block1\")\n+    for i in range(2, blocks):\n+        x = residual_block_v2(x, filters, name=name + \"_block\" + str(i))\n+    x = residual_block_v2(\n+        x, filters, stride=stride1, name=name + \"_block\" + str(blocks)\n+    )\n+    return x\n+\n+\n @keras_core_export(\n     [\n         \"keras_core.applications.resnet50.ResNet50\",\n@@ -306,6 +420,82 @@ def ResNet50(\n     )\n \n \n+@keras_core_export(\n+    [\n+        \"keras_core.applications.resnet.ResNet101\",\n+        \"keras_core.applications.ResNet101\",\n+    ]\n+)\n+def ResNet101(\n+    include_top=True,\n+    weights=\"imagenet\",\n+    input_tensor=None,\n+    input_shape=None,\n+    pooling=None,\n+    classes=1000,\n+    classifier_activation=\"softmax\",\n+):\n+    \"\"\"Instantiates the ResNet101 architecture.\"\"\"\n+\n+    def stack_fn(x):\n+        x = stack_residual_blocks_v1(x, 64, 3, stride1=1, name=\"conv2\")\n+        x = stack_residual_blocks_v1(x, 128, 4, name=\"conv3\")\n+        x = stack_residual_blocks_v1(x, 256, 23, name=\"conv4\")\n+        return stack_residual_blocks_v1(x, 512, 3, name=\"conv5\")\n+\n+    return ResNet(\n+        stack_fn,\n+        False,\n+        True,\n+        \"resnet101\",\n+        include_top,\n+        weights,\n+        input_tensor,\n+        input_shape,\n+        pooling,\n+        classes,\n+        classifier_activation=classifier_activation,\n+    )\n+\n+\n+@keras_core_export(\n+    [\n+        \"keras_core.applications.resnet.ResNet152\",\n+        \"keras_core.applications.ResNet152\",\n+    ]\n+)\n+def ResNet152(\n+    include_top=True,\n+    weights=\"imagenet\",\n+    input_tensor=None,\n+    input_shape=None,\n+    pooling=None,\n+    classes=1000,\n+    classifier_activation=\"softmax\",\n+):\n+    \"\"\"Instantiates the ResNet152 architecture.\"\"\"\n+\n+    def stack_fn(x):\n+        x = stack_residual_blocks_v1(x, 64, 3, stride1=1, name=\"conv2\")\n+        x = stack_residual_blocks_v1(x, 128, 8, name=\"conv3\")\n+        x = stack_residual_blocks_v1(x, 256, 36, name=\"conv4\")\n+        return stack_residual_blocks_v1(x, 512, 3, name=\"conv5\")\n+\n+    return ResNet(\n+        stack_fn,\n+        False,\n+        True,\n+        \"resnet152\",\n+        include_top,\n+        weights,\n+        input_tensor,\n+        input_shape,\n+        pooling,\n+        classes,\n+        classifier_activation=classifier_activation,\n+    )\n+\n+\n @keras_core_export(\n     [\n         \"keras_core.applications.resnet50.preprocess_input\",\n@@ -390,3 +580,5 @@ Returns:\n \"\"\"\n \n setattr(ResNet50, \"__doc__\", ResNet50.__doc__ + DOC)\n+setattr(ResNet101, \"__doc__\", ResNet101.__doc__ + DOC)\n+setattr(ResNet152, \"__doc__\", ResNet152.__doc__ + DOC)\n\n@@ -0,0 +1,201 @@\n+from keras_core.api_export import keras_core_export\n+from keras_core.applications import imagenet_utils\n+from keras_core.applications import resnet\n+\n+\n+@keras_core_export(\n+    [\n+        \"keras_core.applications.resnet_v2.ResNet50V2\",\n+        \"keras_core.applications.resnet_v2.ResNet50V2\",\n+    ]\n+)\n+def ResNet50V2(\n+    include_top=True,\n+    weights=\"imagenet\",\n+    input_tensor=None,\n+    input_shape=None,\n+    pooling=None,\n+    classes=1000,\n+    classifier_activation=\"softmax\",\n+):\n+    \"\"\"Instantiates the ResNet50V2 architecture.\"\"\"\n+\n+    def stack_fn(x):\n+        x = resnet.stack_residual_blocks_v2(x, 64, 3, name=\"conv2\")\n+        x = resnet.stack_residual_blocks_v2(x, 128, 4, name=\"conv3\")\n+        x = resnet.stack_residual_blocks_v2(x, 256, 6, name=\"conv4\")\n+        return resnet.stack_residual_blocks_v2(\n+            x, 512, 3, stride1=1, name=\"conv5\"\n+        )\n+\n+    return resnet.ResNet(\n+        stack_fn,\n+        True,\n+        True,\n+        \"resnet50v2\",\n+        include_top,\n+        weights,\n+        input_tensor,\n+        input_shape,\n+        pooling,\n+        classes,\n+        classifier_activation=classifier_activation,\n+    )\n+\n+\n+@keras_core_export(\n+    [\n+        \"keras_core.applications.resnet_v2.ResNet101V2\",\n+        \"keras_core.applications.resnet_v2.ResNet101V2\",\n+    ]\n+)\n+def ResNet101V2(\n+    include_top=True,\n+    weights=\"imagenet\",\n+    input_tensor=None,\n+    input_shape=None,\n+    pooling=None,\n+    classes=1000,\n+    classifier_activation=\"softmax\",\n+):\n+    \"\"\"Instantiates the ResNet101V2 architecture.\"\"\"\n+\n+    def stack_fn(x):\n+        x = resnet.stack_residual_blocks_v2(x, 64, 3, name=\"conv2\")\n+        x = resnet.stack_residual_blocks_v2(x, 128, 4, name=\"conv3\")\n+        x = resnet.stack_residual_blocks_v2(x, 256, 23, name=\"conv4\")\n+        return resnet.stack_residual_blocks_v2(\n+            x, 512, 3, stride1=1, name=\"conv5\"\n+        )\n+\n+    return resnet.ResNet(\n+        stack_fn,\n+        True,\n+        True,\n+        \"resnet101v2\",\n+        include_top,\n+        weights,\n+        input_tensor,\n+        input_shape,\n+        pooling,\n+        classes,\n+        classifier_activation=classifier_activation,\n+    )\n+\n+\n+@keras_core_export(\n+    [\n+        \"keras_core.applications.resnet_v2.ResNet152V2\",\n+        \"keras_core.applications.resnet_v2.ResNet152V2\",\n+    ]\n+)\n+def ResNet152V2(\n+    include_top=True,\n+    weights=\"imagenet\",\n+    input_tensor=None,\n+    input_shape=None,\n+    pooling=None,\n+    classes=1000,\n+    classifier_activation=\"softmax\",\n+):\n+    \"\"\"Instantiates the ResNet152V2 architecture.\"\"\"\n+\n+    def stack_fn(x):\n+        x = resnet.stack_residual_blocks_v2(x, 64, 3, name=\"conv2\")\n+        x = resnet.stack_residual_blocks_v2(x, 128, 8, name=\"conv3\")\n+        x = resnet.stack_residual_blocks_v2(x, 256, 36, name=\"conv4\")\n+        return resnet.stack_residual_blocks_v2(\n+            x, 512, 3, stride1=1, name=\"conv5\"\n+        )\n+\n+    return resnet.ResNet(\n+        stack_fn,\n+        True,\n+        True,\n+        \"resnet152v2\",\n+        include_top,\n+        weights,\n+        input_tensor,\n+        input_shape,\n+        pooling,\n+        classes,\n+        classifier_activation=classifier_activation,\n+    )\n+\n+\n+@keras_core_export(\"keras_core.applications.resnet_v2.preprocess_input\")\n+def preprocess_input(x, data_format=None):\n+    return imagenet_utils.preprocess_input(\n+        x, data_format=data_format, mode=\"tf\"\n+    )\n+\n+\n+@keras_core_export(\"keras_core.applications.resnet_v2.decode_predictions\")\n+def decode_predictions(preds, top=5):\n+    return imagenet_utils.decode_predictions(preds, top=top)\n+\n+\n+preprocess_input.__doc__ = imagenet_utils.PREPROCESS_INPUT_DOC.format(\n+    mode=\"\",\n+    ret=imagenet_utils.PREPROCESS_INPUT_RET_DOC_TF,\n+    error=imagenet_utils.PREPROCESS_INPUT_ERROR_DOC,\n+)\n+decode_predictions.__doc__ = imagenet_utils.decode_predictions.__doc__\n+\n+\n+DOC = \"\"\"\n+\n+Reference:\n+- [Identity Mappings in Deep Residual Networks](\n+    https://arxiv.org/abs/1603.05027) (CVPR 2016)\n+\n+For image classification use cases, see [this page for detailed examples](\n+    https://keras.io/api/applications/#usage-examples-for-image-classification-models).\n+\n+For transfer learning use cases, make sure to read the\n+[guide to transfer learning & fine-tuning](\n+    https://keras.io/guides/transfer_learning/).\n+\n+Note: each Keras Application expects a specific kind of input preprocessing.\n+For ResNet, call `keras_core.applications.resnet_v2.preprocess_input` on your\n+inputs before passing them to the model. `resnet_v2.preprocess_input` will\n+scale input pixels between -1 and 1.\n+\n+Args:\n+    include_top: whether to include the fully-connected\n+        layer at the top of the network.\n+    weights: one of `None` (random initialization),\n+        `\"imagenet\"` (pre-training on ImageNet), or the path to the weights\n+        file to be loaded.\n+    input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n+        to use as image input for the model.\n+    input_shape: optional shape tuple, only to be specified if `include_top`\n+        is `False` (otherwise the input shape has to be `(224, 224, 3)`\n+        (with `\"channels_last\"` data format) or `(3, 224, 224)`\n+        (with `\"channels_first\"` data format). It should have exactly 3\n+        inputs channels, and width and height should be no smaller than 32.\n+        E.g. `(200, 200, 3)` would be one valid value.\n+    pooling: Optional pooling mode for feature extraction when `include_top`\n+        is `False`.\n+        - `None` means that the output of the model will be the 4D tensor\n+                output of the last convolutional block.\n+        - `avg` means that global average pooling will be applied to the output\n+                of the last convolutional block, and thus the output of the\n+                model will be a 2D tensor.\n+        - `max` means that global max pooling will be applied.\n+    classes: optional number of classes to classify images into, only to be\n+        specified if `include_top` is `True`, and if no `weights` argument is\n+        specified.\n+    classifier_activation: A `str` or callable. The activation function to\n+        use on the \"top\" layer. Ignored unless `include_top=True`. Set\n+        `classifier_activation=None` to return the logits of the \"top\" layer.\n+        When loading pretrained weights, `classifier_activation` can only\n+        be `None` or `\"softmax\"`.\n+\n+Returns:\n+    A Model instance.\n+\"\"\"\n+\n+setattr(ResNet50V2, \"__doc__\", ResNet50V2.__doc__ + DOC)\n+setattr(ResNet101V2, \"__doc__\", ResNet101V2.__doc__ + DOC)\n+setattr(ResNet152V2, \"__doc__\", ResNet152V2.__doc__ + DOC)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8fdc3615fe3cb965d37ea34d9d0ec0e03baba81d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 399 | Files Changed: 3 | Hunks: 7 | Methods Changed: 14 | Complexity Δ (Sum/Max): -18/0 | Churn Δ: 399 | Churn Cumulative: 1364 | Contributors (this commit): 2 | Commits (past 90d): 14 | Contributors (cumulative): 6 | DMM Complexity: 0.0\n\nDIFF:\n@@ -15,7 +15,6 @@ from keras_core.applications import mobilenet_v2\n from keras_core.applications import mobilenet_v3\n from keras_core.applications import nasnet\n from keras_core.applications import resnet\n-from keras_core.applications import resnet_v2\n from keras_core.applications import vgg16\n from keras_core.applications import vgg19\n from keras_core.applications import xception\n@@ -73,11 +72,6 @@ MODEL_LIST = [\n     (nasnet.NASNetLarge, 4032, nasnet),\n     # resnet\n     (resnet.ResNet50, 2048, resnet),\n-    (resnet.ResNet101, 2048, resnet),\n-    (resnet.ResNet152, 2048, resnet),\n-    (resnet_v2.ResNet50V2, 2048, resnet_v2),\n-    (resnet_v2.ResNet101V2, 2048, resnet_v2),\n-    (resnet_v2.ResNet152V2, 2048, resnet_v2),\n ]\n # Add names for `named_parameters`.\n MODEL_LIST = [(e[0].__name__, *e) for e in MODEL_LIST]\n\n@@ -16,34 +16,6 @@ WEIGHTS_HASHES = {\n         \"2cb95161c43110f7111970584f804107\",\n         \"4d473c1dd8becc155b73f8504c6f6626\",\n     ),\n-    \"resnet101\": (\n-        \"f1aeb4b969a6efcfb50fad2f0c20cfc5\",\n-        \"88cf7a10940856eca736dc7b7e228a21\",\n-    ),\n-    \"resnet152\": (\n-        \"100835be76be38e30d865e96f2aaae62\",\n-        \"ee4c566cf9a93f14d82f913c2dc6dd0c\",\n-    ),\n-    \"resnet50v2\": (\n-        \"3ef43a0b657b3be2300d5770ece849e0\",\n-        \"fac2f116257151a9d068a22e544a4917\",\n-    ),\n-    \"resnet101v2\": (\n-        \"6343647c601c52e1368623803854d971\",\n-        \"c0ed64b8031c3730f411d2eb4eea35b5\",\n-    ),\n-    \"resnet152v2\": (\n-        \"a49b44d1979771252814e80f8ec446f9\",\n-        \"ed17cf2e0169df9d443503ef94b23b33\",\n-    ),\n-    \"resnext50\": (\n-        \"67a5b30d522ed92f75a1f16eef299d1a\",\n-        \"62527c363bdd9ec598bed41947b379fc\",\n-    ),\n-    \"resnext101\": (\n-        \"34fb605428fcc7aa4d62f44404c11509\",\n-        \"0f678c91647380debd923963594981b3\",\n-    ),\n }\n \n \n@@ -295,92 +267,6 @@ def stack_residual_blocks_v1(x, filters, blocks, stride1=2, name=None):\n     return x\n \n \n-def residual_block_v2(\n-    x, filters, kernel_size=3, stride=1, conv_shortcut=False, name=None\n-):\n-    \"\"\"A residual block for ResNet*_v2.\n-\n-    Args:\n-        x: Input tensor.\n-        filters: No of filters in the bottleneck layer.\n-        kernel_size: Kernel size of the bottleneck layer. Defaults to 3\n-        stride: Stride of the first layer. Defaults to 1\n-        conv_shortcut: Use convolution shortcut if `True`, otherwise\n-            use identity shortcut. Defaults to `True`\n-        name(optional): Name of the block\n-\n-    Returns:\n-        Output tensor for the residual block.\n-    \"\"\"\n-\n-    if backend.image_data_format() == \"channels_last\":\n-        bn_axis = 3\n-    else:\n-        bn_axis = 1\n-\n-    preact = layers.BatchNormalization(\n-        axis=bn_axis, epsilon=1.001e-5, name=name + \"_preact_bn\"\n-    )(x)\n-    preact = layers.Activation(\"relu\", name=name + \"_preact_relu\")(preact)\n-\n-    if conv_shortcut:\n-        shortcut = layers.Conv2D(\n-            4 * filters, 1, strides=stride, name=name + \"_0_conv\"\n-        )(preact)\n-    else:\n-        shortcut = (\n-            layers.MaxPooling2D(1, strides=stride)(x) if stride > 1 else x\n-        )\n-\n-    x = layers.Conv2D(\n-        filters, 1, strides=1, use_bias=False, name=name + \"_1_conv\"\n-    )(preact)\n-    x = layers.BatchNormalization(\n-        axis=bn_axis, epsilon=1.001e-5, name=name + \"_1_bn\"\n-    )(x)\n-    x = layers.Activation(\"relu\", name=name + \"_1_relu\")(x)\n-\n-    x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name=name + \"_2_pad\")(x)\n-    x = layers.Conv2D(\n-        filters,\n-        kernel_size,\n-        strides=stride,\n-        use_bias=False,\n-        name=name + \"_2_conv\",\n-    )(x)\n-    x = layers.BatchNormalization(\n-        axis=bn_axis, epsilon=1.001e-5, name=name + \"_2_bn\"\n-    )(x)\n-    x = layers.Activation(\"relu\", name=name + \"_2_relu\")(x)\n-\n-    x = layers.Conv2D(4 * filters, 1, name=name + \"_3_conv\")(x)\n-    x = layers.Add(name=name + \"_out\")([shortcut, x])\n-    return x\n-\n-\n-def stack_residual_blocks_v2(x, filters, blocks, stride1=2, name=None):\n-    \"\"\"A set of stacked residual blocks.\n-\n-    Args:\n-        x: Input tensor.\n-        filters: Number of filters in the bottleneck layer in a block.\n-        blocks: Number of blocks in the stacked blocks.\n-        stride1: Stride of the first layer in the first block. Defaults to 2.\n-        name: Stack label.\n-\n-    Returns:\n-        Output tensor for the stacked blocks.\n-    \"\"\"\n-\n-    x = residual_block_v2(x, filters, conv_shortcut=True, name=name + \"_block1\")\n-    for i in range(2, blocks):\n-        x = residual_block_v2(x, filters, name=name + \"_block\" + str(i))\n-    x = residual_block_v2(\n-        x, filters, stride=stride1, name=name + \"_block\" + str(blocks)\n-    )\n-    return x\n-\n-\n @keras_core_export(\n     [\n         \"keras_core.applications.resnet50.ResNet50\",\n@@ -420,82 +306,6 @@ def ResNet50(\n     )\n \n \n-@keras_core_export(\n-    [\n-        \"keras_core.applications.resnet.ResNet101\",\n-        \"keras_core.applications.ResNet101\",\n-    ]\n-)\n-def ResNet101(\n-    include_top=True,\n-    weights=\"imagenet\",\n-    input_tensor=None,\n-    input_shape=None,\n-    pooling=None,\n-    classes=1000,\n-    classifier_activation=\"softmax\",\n-):\n-    \"\"\"Instantiates the ResNet101 architecture.\"\"\"\n-\n-    def stack_fn(x):\n-        x = stack_residual_blocks_v1(x, 64, 3, stride1=1, name=\"conv2\")\n-        x = stack_residual_blocks_v1(x, 128, 4, name=\"conv3\")\n-        x = stack_residual_blocks_v1(x, 256, 23, name=\"conv4\")\n-        return stack_residual_blocks_v1(x, 512, 3, name=\"conv5\")\n-\n-    return ResNet(\n-        stack_fn,\n-        False,\n-        True,\n-        \"resnet101\",\n-        include_top,\n-        weights,\n-        input_tensor,\n-        input_shape,\n-        pooling,\n-        classes,\n-        classifier_activation=classifier_activation,\n-    )\n-\n-\n-@keras_core_export(\n-    [\n-        \"keras_core.applications.resnet.ResNet152\",\n-        \"keras_core.applications.ResNet152\",\n-    ]\n-)\n-def ResNet152(\n-    include_top=True,\n-    weights=\"imagenet\",\n-    input_tensor=None,\n-    input_shape=None,\n-    pooling=None,\n-    classes=1000,\n-    classifier_activation=\"softmax\",\n-):\n-    \"\"\"Instantiates the ResNet152 architecture.\"\"\"\n-\n-    def stack_fn(x):\n-        x = stack_residual_blocks_v1(x, 64, 3, stride1=1, name=\"conv2\")\n-        x = stack_residual_blocks_v1(x, 128, 8, name=\"conv3\")\n-        x = stack_residual_blocks_v1(x, 256, 36, name=\"conv4\")\n-        return stack_residual_blocks_v1(x, 512, 3, name=\"conv5\")\n-\n-    return ResNet(\n-        stack_fn,\n-        False,\n-        True,\n-        \"resnet152\",\n-        include_top,\n-        weights,\n-        input_tensor,\n-        input_shape,\n-        pooling,\n-        classes,\n-        classifier_activation=classifier_activation,\n-    )\n-\n-\n @keras_core_export(\n     [\n         \"keras_core.applications.resnet50.preprocess_input\",\n@@ -580,5 +390,3 @@ Returns:\n \"\"\"\n \n setattr(ResNet50, \"__doc__\", ResNet50.__doc__ + DOC)\n-setattr(ResNet101, \"__doc__\", ResNet101.__doc__ + DOC)\n-setattr(ResNet152, \"__doc__\", ResNet152.__doc__ + DOC)\n\n@@ -1,201 +0,0 @@\n-from keras_core.api_export import keras_core_export\n-from keras_core.applications import imagenet_utils\n-from keras_core.applications import resnet\n-\n-\n-@keras_core_export(\n-    [\n-        \"keras_core.applications.resnet_v2.ResNet50V2\",\n-        \"keras_core.applications.resnet_v2.ResNet50V2\",\n-    ]\n-)\n-def ResNet50V2(\n-    include_top=True,\n-    weights=\"imagenet\",\n-    input_tensor=None,\n-    input_shape=None,\n-    pooling=None,\n-    classes=1000,\n-    classifier_activation=\"softmax\",\n-):\n-    \"\"\"Instantiates the ResNet50V2 architecture.\"\"\"\n-\n-    def stack_fn(x):\n-        x = resnet.stack_residual_blocks_v2(x, 64, 3, name=\"conv2\")\n-        x = resnet.stack_residual_blocks_v2(x, 128, 4, name=\"conv3\")\n-        x = resnet.stack_residual_blocks_v2(x, 256, 6, name=\"conv4\")\n-        return resnet.stack_residual_blocks_v2(\n-            x, 512, 3, stride1=1, name=\"conv5\"\n-        )\n-\n-    return resnet.ResNet(\n-        stack_fn,\n-        True,\n-        True,\n-        \"resnet50v2\",\n-        include_top,\n-        weights,\n-        input_tensor,\n-        input_shape,\n-        pooling,\n-        classes,\n-        classifier_activation=classifier_activation,\n-    )\n-\n-\n-@keras_core_export(\n-    [\n-        \"keras_core.applications.resnet_v2.ResNet101V2\",\n-        \"keras_core.applications.resnet_v2.ResNet101V2\",\n-    ]\n-)\n-def ResNet101V2(\n-    include_top=True,\n-    weights=\"imagenet\",\n-    input_tensor=None,\n-    input_shape=None,\n-    pooling=None,\n-    classes=1000,\n-    classifier_activation=\"softmax\",\n-):\n-    \"\"\"Instantiates the ResNet101V2 architecture.\"\"\"\n-\n-    def stack_fn(x):\n-        x = resnet.stack_residual_blocks_v2(x, 64, 3, name=\"conv2\")\n-        x = resnet.stack_residual_blocks_v2(x, 128, 4, name=\"conv3\")\n-        x = resnet.stack_residual_blocks_v2(x, 256, 23, name=\"conv4\")\n-        return resnet.stack_residual_blocks_v2(\n-            x, 512, 3, stride1=1, name=\"conv5\"\n-        )\n-\n-    return resnet.ResNet(\n-        stack_fn,\n-        True,\n-        True,\n-        \"resnet101v2\",\n-        include_top,\n-        weights,\n-        input_tensor,\n-        input_shape,\n-        pooling,\n-        classes,\n-        classifier_activation=classifier_activation,\n-    )\n-\n-\n-@keras_core_export(\n-    [\n-        \"keras_core.applications.resnet_v2.ResNet152V2\",\n-        \"keras_core.applications.resnet_v2.ResNet152V2\",\n-    ]\n-)\n-def ResNet152V2(\n-    include_top=True,\n-    weights=\"imagenet\",\n-    input_tensor=None,\n-    input_shape=None,\n-    pooling=None,\n-    classes=1000,\n-    classifier_activation=\"softmax\",\n-):\n-    \"\"\"Instantiates the ResNet152V2 architecture.\"\"\"\n-\n-    def stack_fn(x):\n-        x = resnet.stack_residual_blocks_v2(x, 64, 3, name=\"conv2\")\n-        x = resnet.stack_residual_blocks_v2(x, 128, 8, name=\"conv3\")\n-        x = resnet.stack_residual_blocks_v2(x, 256, 36, name=\"conv4\")\n-        return resnet.stack_residual_blocks_v2(\n-            x, 512, 3, stride1=1, name=\"conv5\"\n-        )\n-\n-    return resnet.ResNet(\n-        stack_fn,\n-        True,\n-        True,\n-        \"resnet152v2\",\n-        include_top,\n-        weights,\n-        input_tensor,\n-        input_shape,\n-        pooling,\n-        classes,\n-        classifier_activation=classifier_activation,\n-    )\n-\n-\n-@keras_core_export(\"keras_core.applications.resnet_v2.preprocess_input\")\n-def preprocess_input(x, data_format=None):\n-    return imagenet_utils.preprocess_input(\n-        x, data_format=data_format, mode=\"tf\"\n-    )\n-\n-\n-@keras_core_export(\"keras_core.applications.resnet_v2.decode_predictions\")\n-def decode_predictions(preds, top=5):\n-    return imagenet_utils.decode_predictions(preds, top=top)\n-\n-\n-preprocess_input.__doc__ = imagenet_utils.PREPROCESS_INPUT_DOC.format(\n-    mode=\"\",\n-    ret=imagenet_utils.PREPROCESS_INPUT_RET_DOC_TF,\n-    error=imagenet_utils.PREPROCESS_INPUT_ERROR_DOC,\n-)\n-decode_predictions.__doc__ = imagenet_utils.decode_predictions.__doc__\n-\n-\n-DOC = \"\"\"\n-\n-Reference:\n-- [Identity Mappings in Deep Residual Networks](\n-    https://arxiv.org/abs/1603.05027) (CVPR 2016)\n-\n-For image classification use cases, see [this page for detailed examples](\n-    https://keras.io/api/applications/#usage-examples-for-image-classification-models).\n-\n-For transfer learning use cases, make sure to read the\n-[guide to transfer learning & fine-tuning](\n-    https://keras.io/guides/transfer_learning/).\n-\n-Note: each Keras Application expects a specific kind of input preprocessing.\n-For ResNet, call `keras_core.applications.resnet_v2.preprocess_input` on your\n-inputs before passing them to the model. `resnet_v2.preprocess_input` will\n-scale input pixels between -1 and 1.\n-\n-Args:\n-    include_top: whether to include the fully-connected\n-        layer at the top of the network.\n-    weights: one of `None` (random initialization),\n-        `\"imagenet\"` (pre-training on ImageNet), or the path to the weights\n-        file to be loaded.\n-    input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n-        to use as image input for the model.\n-    input_shape: optional shape tuple, only to be specified if `include_top`\n-        is `False` (otherwise the input shape has to be `(224, 224, 3)`\n-        (with `\"channels_last\"` data format) or `(3, 224, 224)`\n-        (with `\"channels_first\"` data format). It should have exactly 3\n-        inputs channels, and width and height should be no smaller than 32.\n-        E.g. `(200, 200, 3)` would be one valid value.\n-    pooling: Optional pooling mode for feature extraction when `include_top`\n-        is `False`.\n-        - `None` means that the output of the model will be the 4D tensor\n-                output of the last convolutional block.\n-        - `avg` means that global average pooling will be applied to the output\n-                of the last convolutional block, and thus the output of the\n-                model will be a 2D tensor.\n-        - `max` means that global max pooling will be applied.\n-    classes: optional number of classes to classify images into, only to be\n-        specified if `include_top` is `True`, and if no `weights` argument is\n-        specified.\n-    classifier_activation: A `str` or callable. The activation function to\n-        use on the \"top\" layer. Ignored unless `include_top=True`. Set\n-        `classifier_activation=None` to return the logits of the \"top\" layer.\n-        When loading pretrained weights, `classifier_activation` can only\n-        be `None` or `\"softmax\"`.\n-\n-Returns:\n-    A Model instance.\n-\"\"\"\n-\n-setattr(ResNet50V2, \"__doc__\", ResNet50V2.__doc__ + DOC)\n-setattr(ResNet101V2, \"__doc__\", ResNet101V2.__doc__ + DOC)\n-setattr(ResNet152V2, \"__doc__\", ResNet152V2.__doc__ + DOC)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
