{"custom_id": "keras#ee2252e1ac5ba6c3cb0a1d5e31e2a86a806363dc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 11 | Churn Cumulative: 639 | Contributors (this commit): 2 | Commits (past 90d): 14 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -26,7 +26,7 @@ def list_devices(device_type=None):\n     \"\"\"\n     device_type = device_type.lower() if device_type else None\n     jax_devices = jax.devices(backend=device_type)\n-    return [f\"{device.device_kind}:{device.id}\" for device in jax_devices]\n+    return [f\"{device.platform}:{device.id}\" for device in jax_devices]\n \n \n def distribute_variable(value, layout):\n\n@@ -37,6 +37,15 @@ class JaxDistributionLibTest(testing.TestCase):\n         self.assertEqual(len(distribution_lib.list_devices(\"cpu\")), 8)\n         self.assertEqual(len(distribution_lib.list_devices(\"cpu\")), 8)\n \n+    def test_device_conversion(self):\n+        devices = distribution_lib.list_devices(\"cpu\")\n+        jax_devices = jax.devices(\"cpu\")\n+\n+        for d, jax_d in zip(devices, jax_devices):\n+            converted_jax_device = backend_dlib._to_jax_device(d)\n+            self.assertIsInstance(converted_jax_device, jax.Device)\n+            self.assertEqual(jax_d, converted_jax_device)\n+\n     @mock.patch.object(jax.distributed, \"initialize\", return_value=None)\n     def test_initialize_with_all_job_addresses(self, mock_jax_initialze):\n         backend_dlib.initialize(\"10.0.0.1:1234,10.0.0.2:2345\", 2, 0)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a769e3b830c7466b71f5070221be1af5363a090b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 59 | Contributors (this commit): 5 | Commits (past 90d): 5 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -92,7 +92,7 @@ class TestCase(unittest.TestCase):\n             revived_config, sort_keys=True, indent=4\n         )\n         self.assertEqual(config_json, revived_config_json)\n-        self.assertEqual(ref_dir, dir(revived_instance))\n+        self.assertEqual(set(ref_dir), set(dir(revived_instance)))\n \n         # serialization roundtrip\n         serialized = serialize_keras_object(instance)\n@@ -110,7 +110,7 @@ class TestCase(unittest.TestCase):\n         for lst in [ref_dir, new_dir]:\n             if \"__annotations__\" in lst:\n                 lst.remove(\"__annotations__\")\n-        self.assertEqual(ref_dir, new_dir)\n+        self.assertEqual(set(ref_dir), set(new_dir))\n         return revived_instance\n \n     def run_layer_test(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#698a88edd4358275f1928b353124eb6c4825d426", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 5 | Methods Changed: 4 | Complexity Δ (Sum/Max): 3/2 | Churn Δ: 15 | Churn Cumulative: 428 | Contributors (this commit): 8 | Commits (past 90d): 6 | Contributors (cumulative): 13 | DMM Complexity: 1.0\n\nDIFF:\n@@ -54,16 +54,17 @@ class Reshape(Layer):\n         )\n \n     def build(self, input_shape):\n-        self._sample_output_shape = (\n-            operation_utils.compute_reshape_output_shape(\n+        sample_output_shape = operation_utils.compute_reshape_output_shape(\n             input_shape[1:], self.target_shape, \"target_shape\"\n         )\n+        self._resolved_target_shape = tuple(\n+            -1 if d is None else d for d in sample_output_shape\n         )\n         self.built = True\n \n     def call(self, inputs):\n         return ops.reshape(\n-            inputs, (ops.shape(inputs)[0],) + self._sample_output_shape\n+            inputs, (ops.shape(inputs)[0],) + self._resolved_target_shape\n         )\n \n     def get_config(self):\n\n@@ -96,9 +96,17 @@ class ReshapeTest(testing.TestCase, parameterized.TestCase):\n     def test_reshape_with_dynamic_batch_size_and_minus_one(self):\n         input = KerasTensor((None, 6, 4))\n         layer = layers.Reshape((-1, 8))\n+        layer.build(input.shape)\n         reshaped = backend.compute_output_spec(layer.__call__, input)\n         self.assertEqual(reshaped.shape, (None, 3, 8))\n \n+    def test_reshape_with_dynamic_dim_and_minus_one(self):\n+        input = KerasTensor((4, 6, None, 3))\n+        layer = layers.Reshape((-1, 3))\n+        layer.build(input.shape)\n+        reshaped = backend.compute_output_spec(layer.__call__, input)\n+        self.assertEqual(reshaped.shape, (4, None, 3))\n+\n     def test_reshape_sets_static_shape(self):\n         input_layer = layers.Input(batch_shape=(2, None))\n         reshaped = layers.Reshape((3, 5))(input_layer)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a2771856206be275330e636b43ba266fe7f23a20", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 9 | Methods Changed: 2 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 13 | Churn Cumulative: 195 | Contributors (this commit): 6 | Commits (past 90d): 2 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,6 +1,7 @@\n import numpy as np\n import pytest\n \n+from keras import backend\n from keras import layers\n from keras.testing import test_case\n \n@@ -71,10 +72,16 @@ class SpatialDropoutTest(test_case.TestCase):\n         layer(inputs, training=True)\n \n     def test_spatial_dropout_2D_correctness(self):\n+        if backend.config.image_data_format() == \"channels_last\":\n             inputs = np.ones((10, 3, 3, 10))\n+        else:\n+            inputs = np.ones((10, 10, 3, 3))\n         layer = layers.SpatialDropout2D(0.5)\n         outputs = layer(inputs, training=True)\n+        if backend.config.image_data_format() == \"channels_last\":\n             self.assertAllClose(outputs[:, 0, 0, :], outputs[:, 1, 1, :])\n+        else:\n+            self.assertAllClose(outputs[:, :, 0, 0], outputs[:, :, 1, 1])\n \n     def test_spatial_dropout_3D_dynamic(self):\n         inputs = layers.Input((3, 2, 4, 2))\n@@ -82,7 +89,13 @@ class SpatialDropoutTest(test_case.TestCase):\n         layer(inputs, training=True)\n \n     def test_spatial_dropout_3D_correctness(self):\n+        if backend.config.image_data_format() == \"channels_last\":\n             inputs = np.ones((10, 3, 3, 3, 10))\n+        else:\n+            inputs = np.ones((10, 10, 3, 3, 3))\n         layer = layers.SpatialDropout3D(0.5)\n         outputs = layer(inputs, training=True)\n+        if backend.config.image_data_format() == \"channels_last\":\n             self.assertAllClose(outputs[:, 0, 0, 0, :], outputs[:, 1, 1, 1, :])\n+        else:\n+            self.assertAllClose(outputs[:, :, 0, 0, 0], outputs[:, :, 1, 1, 1])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#443b0db9d63ff226040aeb5b66c2e7bd71381f71", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 45 | Lines Deleted: 9 | Files Changed: 7 | Hunks: 27 | Methods Changed: 7 | Complexity Δ (Sum/Max): 11/2 | Churn Δ: 54 | Churn Cumulative: 307 | Contributors (this commit): 7 | Commits (past 90d): 16 | Contributors (cumulative): 20 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2,6 +2,7 @@ import numpy as np\n import pytest\n from absl.testing import parameterized\n \n+from keras import backend\n from keras import layers\n from keras import ops\n from keras import testing\n@@ -63,9 +64,15 @@ class Cropping2DTest(testing.TestCase, parameterized.TestCase):\n         )\n \n     def test_cropping_2d_with_dynamic_spatial_dim(self):\n+        if backend.config.image_data_format() == \"channels_last\":\n             input_layer = layers.Input(batch_shape=(1, 7, None, 5))\n+        else:\n+            input_layer = layers.Input(batch_shape=(1, 5, 7, None))\n         cropped = layers.Cropping2D(((1, 2), (3, 4)))(input_layer)\n+        if backend.config.image_data_format() == \"channels_last\":\n             self.assertEqual(cropped.shape, (1, 4, None, 5))\n+        else:\n+            self.assertEqual(cropped.shape, (1, 5, 4, None))\n \n     @parameterized.product(\n         (\n\n@@ -2,6 +2,7 @@ import numpy as np\n import pytest\n from absl.testing import parameterized\n \n+from keras import backend\n from keras import layers\n from keras import ops\n from keras import testing\n@@ -123,9 +124,15 @@ class Cropping3DTest(testing.TestCase, parameterized.TestCase):\n         )\n \n     def test_cropping_3d_with_dynamic_spatial_dim(self):\n+        if backend.config.image_data_format() == \"channels_last\":\n             input_layer = layers.Input(batch_shape=(1, 7, None, 13, 5))\n+        else:\n+            input_layer = layers.Input(batch_shape=(1, 5, 7, None, 13))\n         cropped = layers.Cropping3D(((1, 2), (3, 4), (5, 6)))(input_layer)\n+        if backend.config.image_data_format() == \"channels_last\":\n             self.assertEqual(cropped.shape, (1, 4, None, 2, 5))\n+        else:\n+            self.assertEqual(cropped.shape, (1, 5, 4, None, 2))\n \n     @parameterized.product(\n         (\n\n@@ -46,7 +46,9 @@ class FlattenTest(testing.TestCase, parameterized.TestCase):\n             init_kwargs={},\n             input_data=inputs,\n             input_sparse=True,\n-            expected_output=expected_output_channels_last,\n+            expected_output=expected_output_channels_last\n+            if backend.config.image_data_format() == \"channels_last\"\n+            else expected_output_channels_first,\n             expected_output_sparse=sparse,\n             run_training_check=not sparse,\n         )\n\n@@ -106,10 +106,8 @@ class UpSampling2dTest(testing.TestCase, parameterized.TestCase):\n     def test_upsampling_2d_correctness(self):\n         input_shape = (2, 2, 1, 3)\n         x = np.arange(np.prod(input_shape)).reshape(input_shape)\n-        self.assertAllClose(\n-            layers.UpSampling2D(size=(1, 2))(x),\n+        expected_output = np.array(\n             # fmt: off\n-            np.array(\n             [[[[ 0.,  1.,  2.],\n                [ 0.,  1.,  2.]],\n               [[ 3.,  4.,  5.],\n@@ -118,9 +116,14 @@ class UpSampling2dTest(testing.TestCase, parameterized.TestCase):\n                [ 6.,  7.,  8.]],\n               [[ 9., 10., 11.],\n                [ 9., 10., 11.]]]]\n-            ),\n             # fmt: on\n         )\n+        if backend.config.image_data_format() == \"channels_first\":\n+            expected_output = expected_output.transpose((0, 3, 1, 2))\n+            x = x.transpose((0, 3, 1, 2))\n+        self.assertAllClose(\n+            layers.UpSampling2D(size=(1, 2))(x), expected_output\n+        )\n \n     def test_upsampling_2d_various_interpolation_methods(self):\n         input_shape = (2, 2, 1, 3)\n\n@@ -90,9 +90,7 @@ class UpSampling3dTest(testing.TestCase, parameterized.TestCase):\n     def test_upsampling_3d_correctness(self):\n         input_shape = (2, 1, 2, 1, 3)\n         x = np.arange(np.prod(input_shape)).reshape(input_shape)\n-        self.assertAllClose(\n-            layers.UpSampling3D(size=(2, 2, 2))(x),\n-            np.array(\n+        expected_output = np.array(\n             [\n                 [\n                     [\n@@ -123,5 +121,10 @@ class UpSampling3dTest(testing.TestCase, parameterized.TestCase):\n                     ],\n                 ],\n             ]\n-            ),\n+        )\n+        if backend.config.image_data_format() == \"channels_first\":\n+            expected_output = expected_output.transpose((0, 4, 1, 2, 3))\n+            x = x.transpose((0, 4, 1, 2, 3))\n+        self.assertAllClose(\n+            layers.UpSampling3D(size=(2, 2, 2))(x), expected_output\n         )\n\n@@ -1,6 +1,7 @@\n import numpy as np\n from absl.testing import parameterized\n \n+from keras import backend\n from keras import layers\n from keras import testing\n \n@@ -57,9 +58,15 @@ class ZeroPadding2DTest(testing.TestCase, parameterized.TestCase):\n             self.assertAllClose(outputs[:, 2:-2, 2:-2, :], inputs)\n \n     def test_zero_padding_2d_with_dynamic_spatial_dim(self):\n+        if backend.config.image_data_format() == \"channels_last\":\n             input_layer = layers.Input(batch_shape=(1, 2, None, 4))\n+        else:\n+            input_layer = layers.Input(batch_shape=(1, 4, 2, None))\n         padded = layers.ZeroPadding2D(((1, 2), (3, 4)))(input_layer)\n+        if backend.config.image_data_format() == \"channels_last\":\n             self.assertEqual(padded.shape, (1, 5, None, 4))\n+        else:\n+            self.assertEqual(padded.shape, (1, 4, 5, None))\n \n     def test_zero_padding_2d_errors_if_padding_argument_invalid(self):\n         with self.assertRaises(ValueError):\n\n@@ -1,6 +1,7 @@\n import numpy as np\n from absl.testing import parameterized\n \n+from keras import backend\n from keras import layers\n from keras import testing\n \n@@ -63,9 +64,15 @@ class ZeroPadding3DTest(testing.TestCase, parameterized.TestCase):\n             self.assertAllClose(outputs[:, 2:-2, 2:-2, 2:-2, :], inputs)\n \n     def test_zero_padding_3d_with_dynamic_spatial_dim(self):\n+        if backend.config.image_data_format() == \"channels_last\":\n             input_layer = layers.Input(batch_shape=(1, 2, None, 4, 5))\n+        else:\n+            input_layer = layers.Input(batch_shape=(1, 5, 2, None, 4))\n         padded = layers.ZeroPadding3D(((1, 2), (3, 4), (5, 6)))(input_layer)\n+        if backend.config.image_data_format() == \"channels_last\":\n             self.assertEqual(padded.shape, (1, 5, None, 15, 5))\n+        else:\n+            self.assertEqual(padded.shape, (1, 5, 5, None, 15))\n \n     def test_zero_padding_3d_errors_if_padding_argument_invalid(self):\n         with self.assertRaises(ValueError):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a6d93e9385191cbcce357bb0e7e8573cd56c17c3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 103 | Lines Deleted: 56 | Files Changed: 5 | Hunks: 31 | Methods Changed: 8 | Complexity Δ (Sum/Max): 24/7 | Churn Δ: 159 | Churn Cumulative: 2358 | Contributors (this commit): 7 | Commits (past 90d): 10 | Contributors (cumulative): 18 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1,6 +1,7 @@\n import numpy as np\n import pytest\n \n+from keras import backend\n from keras import initializers\n from keras import layers\n from keras import testing\n@@ -9,11 +10,12 @@ from keras import testing\n class ConvLSTM1DTest(testing.TestCase):\n     @pytest.mark.requires_trainable_backend\n     def test_basics(self):\n+        channels_last = backend.config.image_data_format() == \"channels_last\"\n         self.run_layer_test(\n             layers.ConvLSTM1D,\n             init_kwargs={\"filters\": 5, \"kernel_size\": 3, \"padding\": \"same\"},\n-            input_shape=(3, 2, 4, 3),\n-            expected_output_shape=(3, 4, 5),\n+            input_shape=(3, 2, 4, 3) if channels_last else (3, 2, 3, 4),\n+            expected_output_shape=(3, 4, 5) if channels_last else (3, 5, 4),\n             expected_num_trainable_weights=3,\n             expected_num_non_trainable_weights=0,\n             supports_masking=True,\n@@ -26,9 +28,9 @@ class ConvLSTM1DTest(testing.TestCase):\n                 \"padding\": \"valid\",\n                 \"recurrent_dropout\": 0.5,\n             },\n-            input_shape=(3, 2, 8, 3),\n+            input_shape=(3, 2, 8, 3) if channels_last else (3, 2, 3, 8),\n             call_kwargs={\"training\": True},\n-            expected_output_shape=(3, 6, 5),\n+            expected_output_shape=(3, 6, 5) if channels_last else (3, 5, 6),\n             expected_num_trainable_weights=3,\n             expected_num_non_trainable_weights=0,\n             supports_masking=True,\n@@ -41,8 +43,10 @@ class ConvLSTM1DTest(testing.TestCase):\n                 \"padding\": \"valid\",\n                 \"return_sequences\": True,\n             },\n-            input_shape=(3, 2, 8, 3),\n-            expected_output_shape=(3, 2, 6, 5),\n+            input_shape=(3, 2, 8, 3) if channels_last else (3, 2, 3, 8),\n+            expected_output_shape=(3, 2, 6, 5)\n+            if channels_last\n+            else (3, 2, 5, 6),\n             expected_num_trainable_weights=3,\n             expected_num_non_trainable_weights=0,\n             supports_masking=True,\n@@ -50,6 +54,15 @@ class ConvLSTM1DTest(testing.TestCase):\n \n     def test_correctness(self):\n         sequence = np.arange(120).reshape((2, 3, 4, 5)).astype(\"float32\") / 10\n+        expected_output = np.array(\n+            [\n+                [[0.40807986, 0.40807986], [0.46421072, 0.46421072]],\n+                [[0.80933154, 0.80933154], [0.8233646, 0.8233646]],\n+            ]\n+        )\n+        if backend.config.image_data_format() == \"channels_first\":\n+            sequence = sequence.transpose((0, 1, 3, 2))\n+            expected_output = expected_output.transpose((0, 2, 1))\n         layer = layers.ConvLSTM1D(\n             filters=2,\n             kernel_size=3,\n@@ -59,11 +72,6 @@ class ConvLSTM1DTest(testing.TestCase):\n         )\n         output = layer(sequence)\n         self.assertAllClose(\n-            np.array(\n-                [\n-                    [[0.40807986, 0.40807986], [0.46421072, 0.46421072]],\n-                    [[0.80933154, 0.80933154], [0.8233646, 0.8233646]],\n-                ]\n-            ),\n+            expected_output,\n             output,\n         )\n\n@@ -1,6 +1,7 @@\n import numpy as np\n import pytest\n \n+from keras import backend\n from keras import initializers\n from keras import layers\n from keras import testing\n@@ -9,11 +10,14 @@ from keras import testing\n class ConvLSTM2DTest(testing.TestCase):\n     @pytest.mark.requires_trainable_backend\n     def test_basics(self):\n+        channels_last = backend.config.image_data_format() == \"channels_last\"\n         self.run_layer_test(\n             layers.ConvLSTM2D,\n             init_kwargs={\"filters\": 5, \"kernel_size\": 3, \"padding\": \"same\"},\n-            input_shape=(3, 2, 4, 4, 3),\n-            expected_output_shape=(3, 4, 4, 5),\n+            input_shape=(3, 2, 4, 4, 3) if channels_last else (3, 2, 3, 4, 4),\n+            expected_output_shape=(3, 4, 4, 5)\n+            if channels_last\n+            else (3, 5, 4, 4),\n             expected_num_trainable_weights=3,\n             expected_num_non_trainable_weights=0,\n             supports_masking=True,\n@@ -26,9 +30,11 @@ class ConvLSTM2DTest(testing.TestCase):\n                 \"padding\": \"valid\",\n                 \"recurrent_dropout\": 0.5,\n             },\n-            input_shape=(3, 2, 8, 8, 3),\n+            input_shape=(3, 2, 8, 8, 3) if channels_last else (3, 2, 3, 8, 8),\n             call_kwargs={\"training\": True},\n-            expected_output_shape=(3, 6, 6, 5),\n+            expected_output_shape=(3, 6, 6, 5)\n+            if channels_last\n+            else (3, 5, 6, 6),\n             expected_num_trainable_weights=3,\n             expected_num_non_trainable_weights=0,\n             supports_masking=True,\n@@ -41,8 +47,10 @@ class ConvLSTM2DTest(testing.TestCase):\n                 \"padding\": \"valid\",\n                 \"return_sequences\": True,\n             },\n-            input_shape=(3, 2, 8, 8, 3),\n-            expected_output_shape=(3, 2, 6, 6, 5),\n+            input_shape=(3, 2, 8, 8, 3) if channels_last else (3, 2, 3, 8, 8),\n+            expected_output_shape=(3, 2, 6, 6, 5)\n+            if channels_last\n+            else (3, 2, 5, 6, 6),\n             expected_num_trainable_weights=3,\n             expected_num_non_trainable_weights=0,\n             supports_masking=True,\n@@ -52,16 +60,7 @@ class ConvLSTM2DTest(testing.TestCase):\n         sequence = (\n             np.arange(480).reshape((2, 3, 4, 4, 5)).astype(\"float32\") / 100\n         )\n-        layer = layers.ConvLSTM2D(\n-            filters=2,\n-            kernel_size=3,\n-            kernel_initializer=initializers.Constant(0.01),\n-            recurrent_initializer=initializers.Constant(0.02),\n-            bias_initializer=initializers.Constant(0.03),\n-        )\n-        output = layer(sequence)\n-        self.assertAllClose(\n-            np.array(\n+        expected_output = np.array(\n             [\n                 [\n                     [[0.48694518, 0.48694518], [0.50237733, 0.50237733]],\n@@ -72,6 +71,19 @@ class ConvLSTM2DTest(testing.TestCase):\n                     [[0.8774414, 0.8774414], [0.8800861, 0.8800861]],\n                 ],\n             ]\n-            ),\n+        )\n+        if backend.config.image_data_format() == \"channels_first\":\n+            sequence = sequence.transpose((0, 1, 4, 2, 3))\n+            expected_output = expected_output.transpose((0, 3, 1, 2))\n+        layer = layers.ConvLSTM2D(\n+            filters=2,\n+            kernel_size=3,\n+            kernel_initializer=initializers.Constant(0.01),\n+            recurrent_initializer=initializers.Constant(0.02),\n+            bias_initializer=initializers.Constant(0.03),\n+        )\n+        output = layer(sequence)\n+        self.assertAllClose(\n+            expected_output,\n             output,\n         )\n\n@@ -1,6 +1,7 @@\n import numpy as np\n import pytest\n \n+from keras import backend\n from keras import initializers\n from keras import layers\n from keras import testing\n@@ -9,11 +10,16 @@ from keras import testing\n class ConvLSTM1DTest(testing.TestCase):\n     @pytest.mark.requires_trainable_backend\n     def test_basics(self):\n+        channels_last = backend.config.image_data_format() == \"channels_last\"\n         self.run_layer_test(\n             layers.ConvLSTM3D,\n             init_kwargs={\"filters\": 5, \"kernel_size\": 3, \"padding\": \"same\"},\n-            input_shape=(3, 2, 4, 4, 4, 3),\n-            expected_output_shape=(3, 4, 4, 4, 5),\n+            input_shape=(3, 2, 4, 4, 4, 3)\n+            if channels_last\n+            else (3, 2, 3, 4, 4, 4),\n+            expected_output_shape=(3, 4, 4, 4, 5)\n+            if channels_last\n+            else (3, 5, 4, 4, 4),\n             expected_num_trainable_weights=3,\n             expected_num_non_trainable_weights=0,\n             supports_masking=True,\n@@ -26,9 +32,13 @@ class ConvLSTM1DTest(testing.TestCase):\n                 \"padding\": \"valid\",\n                 \"recurrent_dropout\": 0.5,\n             },\n-            input_shape=(3, 2, 8, 8, 8, 3),\n+            input_shape=(3, 2, 8, 8, 8, 3)\n+            if channels_last\n+            else (3, 2, 3, 8, 8, 8),\n             call_kwargs={\"training\": True},\n-            expected_output_shape=(3, 6, 6, 6, 5),\n+            expected_output_shape=(3, 6, 6, 6, 5)\n+            if channels_last\n+            else (3, 5, 6, 6, 6),\n             expected_num_trainable_weights=3,\n             expected_num_non_trainable_weights=0,\n             supports_masking=True,\n@@ -41,8 +51,12 @@ class ConvLSTM1DTest(testing.TestCase):\n                 \"padding\": \"valid\",\n                 \"return_sequences\": True,\n             },\n-            input_shape=(3, 2, 8, 8, 8, 3),\n-            expected_output_shape=(3, 2, 6, 6, 6, 5),\n+            input_shape=(3, 2, 8, 8, 8, 3)\n+            if channels_last\n+            else (3, 2, 3, 8, 8, 8),\n+            expected_output_shape=(3, 2, 6, 6, 6, 5)\n+            if channels_last\n+            else (3, 2, 5, 6, 6, 6),\n             expected_num_trainable_weights=3,\n             expected_num_non_trainable_weights=0,\n             supports_masking=True,\n@@ -52,30 +66,15 @@ class ConvLSTM1DTest(testing.TestCase):\n         sequence = (\n             np.arange(1920).reshape((2, 3, 4, 4, 4, 5)).astype(\"float32\") / 100\n         )\n-        layer = layers.ConvLSTM3D(\n-            filters=2,\n-            kernel_size=3,\n-            kernel_initializer=initializers.Constant(0.01),\n-            recurrent_initializer=initializers.Constant(0.02),\n-            bias_initializer=initializers.Constant(0.03),\n-        )\n-        output = layer(sequence)\n-        self.assertAllClose(\n-            np.array(\n+        expected_output = np.array(\n             [\n                 [\n                     [\n-                            [\n-                                [0.99149036, 0.99149036],\n-                                [0.99180907, 0.99180907],\n-                            ],\n+                        [[0.99149036, 0.99149036], [0.99180907, 0.99180907]],\n                         [[0.99258363, 0.99258363], [0.9927925, 0.9927925]],\n                     ],\n                     [\n-                            [\n-                                [0.99413764, 0.99413764],\n-                                [0.99420583, 0.99420583],\n-                            ],\n+                        [[0.99413764, 0.99413764], [0.99420583, 0.99420583]],\n                         [[0.9943788, 0.9943788], [0.9944278, 0.9944278]],\n                     ],\n                 ],\n@@ -90,6 +89,19 @@ class ConvLSTM1DTest(testing.TestCase):\n                     ],\n                 ],\n             ]\n-            ),\n+        )\n+        if backend.config.image_data_format() == \"channels_first\":\n+            sequence = sequence.transpose((0, 1, 5, 2, 3, 4))\n+            expected_output = expected_output.transpose((0, 4, 1, 2, 3))\n+        layer = layers.ConvLSTM3D(\n+            filters=2,\n+            kernel_size=3,\n+            kernel_initializer=initializers.Constant(0.01),\n+            recurrent_initializer=initializers.Constant(0.02),\n+            bias_initializer=initializers.Constant(0.03),\n+        )\n+        output = layer(sequence)\n+        self.assertAllClose(\n+            expected_output,\n             output,\n         )\n\n@@ -13,6 +13,10 @@ class ConvLSTMCellTest(testing.TestCase):\n         s1 = np.arange(200).reshape((2, 5, 5, 4)).astype(\"float32\") / 10\n         s2 = np.arange(200).reshape((2, 5, 5, 4)).astype(\"float32\") / 10\n \n+        if backend.config.image_data_format() == \"channels_first\":\n+            x = x.transpose((0, 3, 1, 2))\n+            s1 = s1.transpose((0, 3, 1, 2))\n+            s2 = s2.transpose((0, 3, 1, 2))\n         layer = ConvLSTMCell(\n             rank=2,\n             filters=4,\n@@ -36,6 +40,10 @@ class ConvLSTMTest(testing.TestCase):\n         s1 = np.arange(200).reshape((2, 5, 5, 4)).astype(\"float32\") / 100\n         s2 = np.arange(200).reshape((2, 5, 5, 4)).astype(\"float32\") / 100\n \n+        if backend.config.image_data_format() == \"channels_first\":\n+            x = x.transpose((0, 1, 4, 2, 3))\n+            s1 = s1.transpose((0, 3, 1, 2))\n+            s2 = s2.transpose((0, 3, 1, 2))\n         layer = ConvLSTM(\n             rank=2,\n             filters=4,\n\n@@ -1,6 +1,7 @@\n import numpy as np\n import pytest\n \n+from keras import backend\n from keras import initializers\n from keras import layers\n from keras import ops\n@@ -21,10 +22,16 @@ class TimeDistributedTest(testing.TestCase):\n         )\n \n     def test_build(self):\n-        inputs = layers.Input(shape=(10, 128, 128, 3), batch_size=32)\n+        if backend.config.image_data_format() == \"channels_last\":\n+            input_shape = (10, 128, 128, 3)\n+            output_shape = (32, 10, 126, 126, 64)\n+        else:\n+            input_shape = (10, 3, 128, 128)\n+            output_shape = (32, 10, 64, 126, 126)\n+        inputs = layers.Input(shape=input_shape, batch_size=32)\n         conv_2d_layer = layers.Conv2D(64, (3, 3))\n         outputs = layers.TimeDistributed(conv_2d_layer)(inputs)\n-        self.assertEqual(outputs.shape, (32, 10, 126, 126, 64))\n+        self.assertEqual(outputs.shape, output_shape)\n \n     def test_correctness(self):\n         sequence = np.arange(24).reshape((3, 2, 4)).astype(\"float32\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#332a52d4ec20daf26219de7d796a90aeb3a82ea5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 4 | Churn Cumulative: 417 | Contributors (this commit): 4 | Commits (past 90d): 2 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,6 +1,7 @@\n import numpy as np\n import pytest\n \n+from keras import backend\n from keras import initializers\n from keras import layers\n from keras import testing\n@@ -48,7 +49,10 @@ class SpectralNormalizationTest(testing.TestCase):\n             layer(inputs)\n \n     def test_apply_layer(self):\n+        if backend.config.image_data_format() == \"channels_last\":\n             images = np.ones((1, 2, 2, 1))\n+        else:\n+            images = np.ones((1, 1, 2, 2))\n         sn_wrapper = layers.SpectralNormalization(\n             layers.Conv2D(\n                 1, (2, 2), kernel_initializer=initializers.Constant(value=1)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e2671789bf8840dffc0bf734e4e2eb35691c7b1e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 11 | Churn Cumulative: 29 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -351,8 +351,13 @@ class TestTensorBoardV2(testing.TestCase):\n \n     @pytest.mark.requires_trainable_backend\n     def test_TensorBoard_weight_images(self):\n-        model = self._get_model()\n-        x, y = np.ones((10, 10, 10, 1)), np.ones((10, 1))\n+        if backend.config.image_data_format() == \"channels_last\":\n+            input_shape = (10, 10, 1)\n+            x_shape = (10, 10, 10, 1)\n+        else:\n+            input_shape = (1, 10, 10)\n+            x_shape = (10, 1, 10, 10)\n+        x, y = np.ones(x_shape), np.ones((10, 1))\n         logdir, train_dir, validation_dir = self._get_log_dirs()\n         tb_cbk = callbacks.TensorBoard(\n             logdir, histogram_freq=1, write_images=True\n@@ -360,7 +365,7 @@ class TestTensorBoardV2(testing.TestCase):\n         model_type = \"sequential\"\n         model = models.Sequential(\n             [\n-                layers.Input((10, 10, 1)),\n+                layers.Input(input_shape),\n                 layers.Conv2D(3, 10),\n                 layers.GlobalAveragePooling2D(),\n                 layers.Dense(1),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#aef288fa5e2730fffc9afdc02e88e0cbb244e204", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 98 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 11 | Complexity Δ (Sum/Max): 12/12 | Churn Δ: 98 | Churn Cumulative: 191 | Contributors (this commit): 4 | Commits (past 90d): 6 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -878,3 +878,101 @@ class MathOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         output = kmath.solve(x1, x2)\n         expected_result = np.array([[2, 0], [0, 2]], dtype=\"float32\")\n         self.assertAllClose(output, expected_result)\n+\n+\n+class QrOpTest(testing.TestCase):\n+    def test_qr_init_mode_reduced(self):\n+        qr_op = kmath.Qr(mode=\"reduced\")\n+        self.assertIsNotNone(qr_op)\n+\n+    def test_qr_init_mode_complete(self):\n+        qr_op = kmath.Qr(mode=\"complete\")\n+        self.assertIsNotNone(qr_op)\n+\n+    def test_qr_init_invalid_mode(self):\n+        invalid_mode = \"invalid_mode\"\n+        expected_error = (\n+            r\"`mode` argument value not supported. \"\n+            r\"Expected one of \\{'reduced', 'complete'\\}. \"\n+            f\"Received: mode={invalid_mode}\"\n+        )\n+        with self.assertRaisesRegex(ValueError, expected_error):\n+            kmath.Qr(mode=invalid_mode)\n+\n+    def test_compute_output_spec_low_rank(self):\n+        qr_op = kmath.Qr(mode=\"reduced\")\n+        low_rank_input = np.random.rand(3)\n+        with self.assertRaisesRegex(\n+            ValueError, r\"Input should have rank >= 2. Received: .*\"\n+        ):\n+            qr_op.compute_output_spec(low_rank_input)\n+\n+    def test_compute_output_spec_undefined_dimensions(self):\n+        qr_op = kmath.Qr(mode=\"reduced\")\n+        undefined_dim_input = KerasTensor(shape=(None, 4), dtype=\"float32\")\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            r\"Input should have its last 2 dimensions \"\n+            r\"fully-defined. Received: .*\",\n+        ):\n+            qr_op.compute_output_spec(undefined_dim_input)\n+\n+    def test_qr_call_mode_reduced(self):\n+        qr_op = kmath.Qr(mode=\"reduced\")\n+        test_input = np.random.rand(10, 10)\n+        q, r = qr_op.call(test_input)\n+        self.assertEqual(q.shape, (10, 10))\n+        self.assertEqual(r.shape, (10, 10))\n+\n+    def test_qr_call_mode_complete(self):\n+        qr_op = kmath.Qr(mode=\"complete\")\n+        test_input = np.random.rand(10, 10)\n+        q, r = qr_op.call(test_input)\n+        self.assertEqual(q.shape, (10, 10))\n+        self.assertEqual(r.shape, (10, 10))\n+\n+\n+class ExtractSequencesOpTest(testing.TestCase):\n+    def test_extract_sequences_init_length_1_stride_1(self):\n+        extract_op = kmath.ExtractSequences(\n+            sequence_length=1, sequence_stride=1\n+        )\n+        self.assertIsNotNone(extract_op)\n+        self.assertEqual(extract_op.sequence_length, 1)\n+        self.assertEqual(extract_op.sequence_stride, 1)\n+\n+    def test_extract_sequences_init_length_5_stride_2(self):\n+        extract_op = kmath.ExtractSequences(\n+            sequence_length=5, sequence_stride=2\n+        )\n+        self.assertIsNotNone(extract_op)\n+        self.assertEqual(extract_op.sequence_length, 5)\n+        self.assertEqual(extract_op.sequence_stride, 2)\n+\n+    def test_compute_output_spec_low_rank(self):\n+        extract_op = kmath.ExtractSequences(\n+            sequence_length=5, sequence_stride=1\n+        )\n+        low_rank_input = np.array(42)\n+        error_message = r\"Input should have rank >= 1. Received: .*\"\n+        with self.assertRaisesRegex(ValueError, error_message):\n+            extract_op.compute_output_spec(low_rank_input)\n+\n+    def test_extract_sequences_call(self):\n+        sequence_length, sequence_stride = 5, 2\n+        extract_op = kmath.ExtractSequences(sequence_length, sequence_stride)\n+        test_input = np.random.rand(10, 20)\n+        result = extract_op.call(test_input)\n+\n+        expected_shape = self.calculate_expected_shape(\n+            test_input.shape, sequence_length, sequence_stride\n+        )\n+        self.assertEqual(result.shape, expected_shape)\n+\n+    def calculate_expected_shape(\n+        self, input_shape, sequence_length, sequence_stride\n+    ):\n+        num_sequences = (\n+            (input_shape[1] - sequence_length) // sequence_stride\n+        ) + 1\n+        return (input_shape[0], num_sequences, sequence_length)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4501d8b9bc1e6f4f10ac09fe89f61494330b98a2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 316 | Lines Deleted: 21 | Files Changed: 7 | Hunks: 18 | Methods Changed: 11 | Complexity Δ (Sum/Max): 27/8 | Churn Δ: 337 | Churn Cumulative: 7581 | Contributors (this commit): 16 | Commits (past 90d): 34 | Contributors (cumulative): 30 | DMM Complexity: 1.0\n\nDIFF:\n@@ -527,3 +527,24 @@ def moments(x, axes, keepdims=False, synchronized=False):\n         mean = cast(mean, ori_dtype)\n         variance = cast(variance, ori_dtype)\n     return mean, variance\n+\n+\n+def batch_normalization(\n+    x, mean, variance, axis, offset=None, scale=None, epsilon=1e-3\n+):\n+    shape = [1] * len(x.shape)\n+    shape[axis] = mean.shape[0]\n+    mean = jnp.reshape(mean, shape)\n+    variance = jnp.reshape(variance, shape)\n+\n+    inv = jax.lax.rsqrt(variance + epsilon)\n+    if scale is not None:\n+        scale = jnp.reshape(scale, shape)\n+        inv = inv * scale\n+\n+    res = -mean * inv\n+    if offset is not None:\n+        offset = jnp.reshape(offset, shape)\n+        res = res + offset\n+\n+    return x * inv + res\n\n@@ -555,3 +555,24 @@ def moments(x, axes, keepdims=False, synchronized=False):\n         mean = cast(mean, ori_dtype)\n         variance = cast(variance, ori_dtype)\n     return mean, variance\n+\n+\n+def batch_normalization(\n+    x, mean, variance, axis, offset=None, scale=None, epsilon=1e-3\n+):\n+    shape = [1] * len(x.shape)\n+    shape[axis] = mean.shape[0]\n+    mean = np.reshape(mean, shape)\n+    variance = np.reshape(variance, shape)\n+\n+    inv = 1.0 / np.sqrt(variance + epsilon)\n+    if scale is not None:\n+        scale = np.reshape(scale, shape)\n+        inv = inv * scale\n+\n+    res = -mean * inv\n+    if offset is not None:\n+        offset = np.reshape(offset, shape)\n+        res = res + offset\n+\n+    return x * inv + res\n\n@@ -729,3 +729,26 @@ def _compute_moments(x, axes, keepdims):\n         mean = cast(mean, ori_dtype)\n         variance = cast(variance, ori_dtype)\n     return mean, variance\n+\n+\n+def batch_normalization(\n+    x, mean, variance, axis, offset=None, scale=None, epsilon=1e-3\n+):\n+    if axis != -1:\n+        shape = [1] * len(x.shape)\n+        shape[axis] = mean.shape[0]\n+        mean = tf.reshape(mean, shape)\n+        variance = tf.reshape(variance, shape)\n+        if offset is not None:\n+            offset = tf.reshape(offset, shape)\n+        if scale is not None:\n+            scale = tf.reshape(scale, shape)\n+\n+    return tf.nn.batch_normalization(\n+        x=x,\n+        mean=mean,\n+        variance=variance,\n+        offset=offset,\n+        scale=scale,\n+        variance_epsilon=epsilon,\n+    )\n\n@@ -686,3 +686,44 @@ def moments(x, axes, keepdims=False, synchronized=False):\n         mean = cast(mean, ori_dtype)\n         variance = cast(variance, ori_dtype)\n     return mean, variance\n+\n+\n+def batch_normalization(\n+    x, mean, variance, axis, offset=None, scale=None, epsilon=1e-3\n+):\n+    x = convert_to_tensor(x)\n+    mean = convert_to_tensor(mean).detach()\n+    variance = convert_to_tensor(variance).detach()\n+    if offset is not None:\n+        offset = convert_to_tensor(offset)\n+    if scale is not None:\n+        scale = convert_to_tensor(scale)\n+\n+    def _batch_norm():\n+        return tnn.batch_norm(\n+            input=x,\n+            running_mean=mean,\n+            running_var=variance,\n+            weight=scale,\n+            bias=offset,\n+            training=False,\n+            eps=epsilon,\n+        )\n+\n+    if axis == 1:\n+        return _batch_norm()\n+\n+    if axis < 0:\n+        axis = len(x.shape) + axis\n+\n+    order = list(range(len(x.shape)))\n+    order.pop(axis)\n+    order.insert(1, axis)\n+    x = x.permute(order)\n+\n+    x = _batch_norm()\n+\n+    order = list(range(len(x.shape)))\n+    order.pop(1)\n+    order.insert(axis, 1)\n+    return x.permute(order)\n\n@@ -210,56 +210,53 @@ class BatchNormalization(Layer):\n             # out BN for mixed precision.\n             inputs = ops.cast(inputs, \"float32\")\n \n-        broadcast_shape = [1] * len(inputs.shape)\n-        broadcast_shape[self.axis] = inputs.shape[self.axis]\n         if training and self.trainable:\n             mean, variance = ops.moments(\n                 inputs,\n                 axes=self._reduction_axes,\n-                keepdims=True,\n                 synchronized=self.synchronized,\n             )\n             moving_mean = ops.cast(self.moving_mean, inputs.dtype)\n             moving_variance = ops.cast(self.moving_variance, inputs.dtype)\n             self.moving_mean.assign(\n                 ops.cast(\n-                    moving_mean * self.momentum\n-                    + ops.squeeze(mean, self._reduction_axes)\n-                    * (1.0 - self.momentum),\n+                    moving_mean * self.momentum + mean * (1.0 - self.momentum),\n                     inputs.dtype,\n                 )\n             )\n             self.moving_variance.assign(\n                 ops.cast(\n                     moving_variance * self.momentum\n-                    + ops.squeeze(variance, self._reduction_axes)\n-                    * (1.0 - self.momentum),\n+                    + variance * (1.0 - self.momentum),\n                     inputs.dtype,\n                 )\n             )\n         else:\n             moving_mean = ops.cast(self.moving_mean, inputs.dtype)\n             moving_variance = ops.cast(self.moving_variance, inputs.dtype)\n-            moving_mean = ops.reshape(moving_mean, broadcast_shape)\n-            moving_variance = ops.reshape(moving_variance, broadcast_shape)\n             mean = moving_mean\n             variance = moving_variance\n \n-        inv = ops.rsqrt(variance + self.epsilon)\n         if self.scale:\n-            gamma = ops.reshape(self.gamma, broadcast_shape)\n-            gamma = ops.cast(gamma, inputs.dtype)\n-            inv = inv * gamma\n+            gamma = ops.cast(self.gamma, inputs.dtype)\n+        else:\n+            gamma = None\n \n-        res = -mean * inv\n         if self.center:\n-            beta = ops.reshape(self.beta, broadcast_shape)\n-            beta = ops.cast(beta, inputs.dtype)\n-            res = res + beta\n+            beta = ops.cast(self.beta, inputs.dtype)\n+        else:\n+            beta = None\n+\n+        outputs = ops.batch_normalization(\n+            x=inputs,\n+            mean=mean,\n+            variance=variance,\n+            axis=self.axis,\n+            offset=beta,\n+            scale=gamma,\n+            epsilon=self.epsilon,\n+        )\n \n-        # Note: Folding BatchNormalization depends on the precise order of ops\n-        # that are generated by the expression below\n-        outputs = inputs * inv + res\n         return ops.cast(outputs, input_dtype)\n \n     def get_config(self):\n\n@@ -1637,3 +1637,87 @@ def moments(x, axes, keepdims=False, synchronized=False):\n         )\n \n     return backend.nn.moments(x, axes, keepdims, synchronized=synchronized)\n+\n+\n+class BatchNorm(Operation):\n+    def __init__(self, axis, epsilon, name=None):\n+        super().__init__(name)\n+        self.axis = axis\n+        self.epsilon = epsilon\n+\n+    def _check_shape(self, name, shape, expected_shape):\n+        if shape != expected_shape:\n+            raise ValueError(\n+                f\"Arguments `{name}` must be a vector of length \"\n+                f\"`x.shape[axis]`. Expected: `{expected_shape}`. \"\n+                f\"Received: `{shape}.\"\n+            )\n+\n+    def compute_output_spec(self, x, mean, variance, offset, scale):\n+        shape = (x.shape[self.axis],)\n+        self._check_shape(\"mean\", tuple(mean.shape), shape)\n+        self._check_shape(\"variance\", tuple(variance.shape), shape)\n+        if offset is not None:\n+            self._check_shape(\"offset\", tuple(offset.shape), shape)\n+        if offset is not scale:\n+            self._check_shape(\"scale\", tuple(scale.shape), shape)\n+        return KerasTensor(x.shape, dtype=x.dtype)\n+\n+\n+@keras_export(\n+    [\n+        \"keras.ops.batch_normalization\",\n+        \"keras.ops.nn.batch_normalization\",\n+    ]\n+)\n+def batch_normalization(\n+    x, mean, variance, axis, offset=None, scale=None, epsilon=1e-3\n+):\n+    \"\"\"Normalizes `x` by `mean` and `variance`.\n+\n+    This op is typically used by the batch normalization step in a neural\n+    network. It normalizes the input tensor along the given axis.\n+\n+    Args:\n+        x: Input tensor.\n+        mean: A mean vector of the same length as the `axis` dimension of the\n+            input thensor.\n+        variance: A variance vector of the same length as the `axis` dimension\n+            of the input tensor.\n+        axis: Integer, the axis that should be normalized.\n+        offset: An offset vector of the same length as the `axis` dimension of\n+            the input tensor. If not `None`, `offset` is added to the normalized\n+            tensor. Defaults to `None`.\n+        scale: A scale vector of the same length as the `axis` dimension of the\n+            input tensor. If not `None`, the normalized tensor is multiplied by\n+            `scale`. Defaults to `None`.\n+        epsilon: Small float added to variance to avoid dividing by zero.\n+            Defaults to 1e-3.\n+\n+    Returns:\n+        The normalized tensor.\n+\n+    Example:\n+\n+    >>> x = keras.ops.convert_to_tensor(\n+    ...     [[0.1, 0.2, 0.3], [0.4, 0.5, 0.6], [0.7, 0.8, 0.9]]\n+    ... )\n+    >>> keras.ops.batch_normalization(\n+    ...     x,\n+    ...     mean=[0.4, 0.5, 0.6],\n+    ...     variance=[0.67, 0.67, 0.67],\n+    ...     axis=-1\n+    ... )\n+    array([[-3.6624e-01, -3.6624e-01, -3.6624e-01],\n+           [-4.6445e-09,  0.0000e+00, -1.8578e-08],\n+           [ 3.6624e-01,  3.6624e-01,  3.6624e-01]])\n+\n+    \"\"\"\n+    if any_symbolic_tensors((x, mean, variance, offset, scale)):\n+        return BatchNorm(axis, epsilon).symbolic_call(\n+            x, mean, variance, offset, scale\n+        )\n+\n+    return backend.nn.batch_normalization(\n+        x, mean, variance, axis, offset, scale, epsilon\n+    )\n\n@@ -493,6 +493,54 @@ class NNOpsDynamicShapeTest(testing.TestCase, parameterized.TestCase):\n             knn.moments(x, axes=[1, 2], keepdims=True)[0].shape, (None, 1, 1)\n         )\n \n+    def test_batch_normalization(self):\n+        x = KerasTensor([None, 3, 4])\n+        mean = KerasTensor([4])\n+        variance = KerasTensor([4])\n+        self.assertEqual(\n+            knn.batch_normalization(x, mean, variance, axis=-1).shape,\n+            (None, 3, 4),\n+        )\n+\n+        x = KerasTensor([None, 3, 4, 5])\n+        self.assertEqual(\n+            knn.batch_normalization(x, mean, variance, axis=2).shape,\n+            (None, 3, 4, 5),\n+        )\n+\n+        mean = KerasTensor([3])\n+        variance = KerasTensor([3])\n+        self.assertEqual(\n+            knn.batch_normalization(x, mean, variance, axis=1).shape,\n+            (None, 3, 4, 5),\n+        )\n+\n+        # Test wrong offset shape\n+        self.assertRaisesRegex(\n+            ValueError,\n+            \"`offset` must be a vector of length\",\n+            knn.batch_normalization,\n+            KerasTensor([None, 3, 4, 5]),\n+            KerasTensor([5]),\n+            KerasTensor([5]),\n+            axis=-1,\n+            offset=KerasTensor([3]),\n+            scale=KerasTensor([5]),\n+        )\n+\n+        # Test wrong scale shape\n+        self.assertRaisesRegex(\n+            ValueError,\n+            \"`scale` must be a vector of length\",\n+            knn.batch_normalization,\n+            KerasTensor([None, 3, 4, 5]),\n+            KerasTensor([5]),\n+            KerasTensor([5]),\n+            axis=-1,\n+            offset=KerasTensor([5]),\n+            scale=KerasTensor([3]),\n+        )\n+\n \n class NNOpsStaticShapeTest(testing.TestCase):\n     def test_relu(self):\n@@ -888,6 +936,28 @@ class NNOpsStaticShapeTest(testing.TestCase):\n             knn.moments(x, axes=[0, 1], keepdims=True)[0].shape, (1, 1, 4)\n         )\n \n+    def test_batch_normalization(self):\n+        x = KerasTensor([10, 3, 4])\n+        mean = KerasTensor([4])\n+        variance = KerasTensor([4])\n+        self.assertEqual(\n+            knn.batch_normalization(x, mean, variance, axis=-1).shape,\n+            (10, 3, 4),\n+        )\n+\n+        x = KerasTensor([10, 3, 4, 5])\n+        self.assertEqual(\n+            knn.batch_normalization(x, mean, variance, axis=2).shape,\n+            (10, 3, 4, 5),\n+        )\n+\n+        mean = KerasTensor([3])\n+        variance = KerasTensor([3])\n+        self.assertEqual(\n+            knn.batch_normalization(x, mean, variance, axis=1).shape,\n+            (10, 3, 4, 5),\n+        )\n+\n \n class NNOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n     def test_relu(self):\n@@ -1611,6 +1681,44 @@ class NNOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             self.assertEqual(variance.values[0], 8.75)\n             self.assertEqual(variance.values[0], 8.75)\n \n+    def test_batch_normalization(self):\n+        x = np.array([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]])\n+        mean = np.array([0.2, 0.3, 0.4])\n+        variance = np.array([4.0, 16.0, 64.0])\n+        output = knn.batch_normalization(\n+            x,\n+            mean,\n+            variance,\n+            axis=-1,\n+            offset=np.array([5.0, 10.0, 15.0]),\n+            scale=np.array([10.0, 20.0, 30.0]),\n+            epsilon=1e-7,\n+        )\n+        expected_output = np.array([[4.5, 9.5, 14.625], [6.0, 11.0, 15.75]])\n+        self.assertAllClose(output, expected_output)\n+\n+        output = knn.batch_normalization(\n+            x,\n+            mean,\n+            variance,\n+            axis=1,\n+            epsilon=1e-7,\n+        )\n+        expected_output = np.array(\n+            [[-0.05, -0.025, -0.0125], [0.1, 0.05, 0.025]]\n+        )\n+        self.assertAllClose(output, expected_output)\n+\n+        output = knn.batch_normalization(\n+            np.random.uniform(size=[2, 3, 3, 5]),\n+            np.random.uniform(size=[5]),\n+            np.random.uniform(size=[5]),\n+            axis=3,\n+            offset=np.random.uniform(size=[5]),\n+            scale=np.random.uniform(size=[5]),\n+        )\n+        self.assertEqual(tuple(output.shape), (2, 3, 3, 5))\n+\n \n class TestLogitRecovery(testing.TestCase):\n     def test_logit_recovery_binary_crossentropy(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
