{"custom_id": "keras#4fa7e5d454dd4f3f33f1d756a2a8659f2e789141", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 274 | Contributors (this commit): 10 | Commits (past 90d): 11 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -15,4 +15,4 @@ from . import objectives\n from . import optimizers\r\n from . import regularizers\r\n \r\n-__version__ = '1.2.1'\r\n+__version__ = '1.2.2'\r\n\n@@ -3,12 +3,12 @@ from setuptools import find_packages\n \n \n setup(name='Keras',\n-      version='1.2.1',\n+      version='1.2.2',\n       description='Deep Learning for Python',\n       author='Francois Chollet',\n       author_email='francois.chollet@gmail.com',\n       url='https://github.com/fchollet/keras',\n-      download_url='https://github.com/fchollet/keras/tarball/1.2.1',\n+      download_url='https://github.com/fchollet/keras/tarball/1.2.2',\n       license='MIT',\n       install_requires=['theano', 'pyyaml', 'six'],\n       extras_require={\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#46649e5d97a750379fdec85b3a8ae39f90e26674", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 84 | Lines Deleted: 89 | Files Changed: 7 | Hunks: 63 | Methods Changed: 23 | Complexity Δ (Sum/Max): 2/4 | Churn Δ: 173 | Churn Cumulative: 21818 | Contributors (this commit): 102 | Commits (past 90d): 136 | Contributors (cumulative): 181 | DMM Complexity: 0.0\n\nDIFF:\n@@ -15,4 +15,4 @@ from . import losses\n from . import optimizers\r\n from . import regularizers\r\n \r\n-__version__ = '1.2.1'\r\n+__version__ = '2.0.0'\r\n\n@@ -1577,6 +1577,12 @@ def repeat_elements(x, rep, axis):\n         A tensor.\n     \"\"\"\n     x_shape = x.get_shape().as_list()\n+    if x_shape[axis] is None:\n+        raise ValueError('Axis ' + str(axis) + ' of input tensor '\n+                         ' should have a defined dimension, but is None. '\n+                         'Full tensor shape: ' + str(tuple(x_shape)) + '. '\n+                         'Typically you need to pass a fully-defined '\n+                         '`input_shape` argument to your first layer.')\n     # slices along the repeat axis\n     try:\n         splits = tf.split(value=x, num_or_size_splits=x_shape[axis], axis=axis)\n@@ -2758,6 +2764,8 @@ def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n         data_format = image_data_format()\n     if data_format not in {'channels_first', 'channels_last'}:\n         raise ValueError('Unknown data_format ' + str(data_format))\n+    if isinstance(output_shape, (tuple, list)):\n+        output_shape = tf.stack(output_shape)\n \n     x = _preprocess_conv2d_input(x, data_format)\n     output_shape = _preprocess_deconv_output_shape(x, output_shape, data_format)\n\n@@ -868,7 +868,6 @@ def asymmetric_spatial_2d_padding(x, top_pad=1, bottom_pad=1,\n                         input_shape[1] + top_pad + bottom_pad,\n                         input_shape[2] + left_pad + right_pad,\n                         input_shape[3])\n-        print(output_shape)\n         output = T.zeros(output_shape)\n         indices = (slice(None),\n                    slice(top_pad, input_shape[1] + top_pad),\n@@ -879,7 +878,7 @@ def asymmetric_spatial_2d_padding(x, top_pad=1, bottom_pad=1,\n     return T.set_subtensor(output[indices], x)\n \n \n-def spatial_3d_padding(x, padding=(1, 1, 1), data_format=None):\n+def spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None):\n     \"\"\"Pad the 2nd, 3rd and 4th dimensions of a 5D tensor\n     with \"padding[0]\", \"padding[1]\" and \"padding[2]\" (resp.) zeros left and right.\n     \"\"\"\n@@ -892,27 +891,27 @@ def spatial_3d_padding(x, padding=(1, 1, 1), data_format=None):\n     if data_format == 'channels_first':\n         output_shape = (input_shape[0],\n                         input_shape[1],\n-                        input_shape[2] + 2 * padding[0],\n-                        input_shape[3] + 2 * padding[1],\n-                        input_shape[4] + 2 * padding[2])\n+                        input_shape[2] + padding[0][0] + padding[0][1],\n+                        input_shape[3] + padding[1][0] + padding[1][1],\n+                        input_shape[4] + padding[2][0] + padding[2][1])\n         output = T.zeros(output_shape)\n         indices = (slice(None),\n                    slice(None),\n-                   slice(padding[0], input_shape[2] + padding[0]),\n-                   slice(padding[1], input_shape[3] + padding[1]),\n-                   slice(padding[2], input_shape[4] + padding[2]))\n+                   slice(padding[0][0], input_shape[2] + padding[0][0]),\n+                   slice(padding[1][0], input_shape[3] + padding[1][0]),\n+                   slice(padding[2][0], input_shape[4] + padding[2][0]))\n \n     elif data_format == 'channels_last':\n         output_shape = (input_shape[0],\n-                        input_shape[1] + 2 * padding[0],\n-                        input_shape[2] + 2 * padding[1],\n-                        input_shape[3] + 2 * padding[2],\n+                        input_shape[1] + padding[0][0] + padding[0][1],\n+                        input_shape[2] + padding[1][0] + padding[1][1],\n+                        input_shape[3] + padding[2][0] + padding[2][1],\n                         input_shape[4])\n         output = T.zeros(output_shape)\n         indices = (slice(None),\n-                   slice(padding[0], input_shape[1] + padding[0]),\n-                   slice(padding[1], input_shape[2] + padding[1]),\n-                   slice(padding[2], input_shape[3] + padding[2]),\n+                   slice(padding[0][0], input_shape[1] + padding[0][0]),\n+                   slice(padding[1][0], input_shape[2] + padding[1][0]),\n+                   slice(padding[2][0], input_shape[3] + padding[2][0]),\n                    slice(None))\n     else:\n         raise ValueError('Invalid data_format:', data_format)\n@@ -1424,7 +1423,7 @@ def _preprocess_padding(padding):\n     return th_padding\n \n \n-def _preprocess_conv2d_image_shape(data_format, image_shape):\n+def _preprocess_conv2d_image_shape(image_shape, data_format):\n     # Theano might not accept long type\n     def int_or_none(value):\n         try:\n@@ -1440,7 +1439,7 @@ def _preprocess_conv2d_image_shape(data_format, image_shape):\n     return image_shape\n \n \n-def _preprocess_conv3d_volume_shape(data_format, volume_shape):\n+def _preprocess_conv3d_volume_shape(volume_shape, data_format):\n     # Theano might not accept long type\n     def int_or_none(value):\n         try:\n@@ -1456,14 +1455,13 @@ def _preprocess_conv3d_volume_shape(data_format, volume_shape):\n     return volume_shape\n \n \n-def _preprocess_conv2d_filter_shape(data_format, filter_shape):\n+def _preprocess_conv2d_filter_shape(filter_shape, data_format):\n     # Theano might not accept long type\n     def int_or_none(value):\n         try:\n             return int(value)\n         except TypeError:\n             return None\n-    if data_format == 'channels_last':\n     if filter_shape:\n         filter_shape = (filter_shape[3], filter_shape[2],\n                         filter_shape[0], filter_shape[1])\n@@ -1472,14 +1470,13 @@ def _preprocess_conv2d_filter_shape(data_format, filter_shape):\n     return filter_shape\n \n \n-def _preprocess_conv3d_filter_shape(data_format, filter_shape):\n+def _preprocess_conv3d_filter_shape(filter_shape, data_format):\n     # Theano might not accept long type\n     def int_or_none(value):\n         try:\n             return int(value)\n         except TypeError:\n             return None\n-    if data_format == 'channels_last':\n     if filter_shape:\n         filter_shape = (filter_shape[4], filter_shape[3],\n                         filter_shape[0], filter_shape[1], filter_shape[2])\n@@ -1525,34 +1522,36 @@ def conv1d(x, kernel, stride=1, padding='valid',\n         strides: stride integer.\n         padding: string, \"same\" or \"valid\".\n         data_format: string, one of \"channels_last\", \"channels_first\"\n-        dilate_rate: integer.\n+        dilation_rate: integer.\n     \"\"\"\n     if data_format is None:\n         data_format = image_data_format()\n     if data_format not in {'channels_first', 'channels_last'}:\n         raise ValueError('Unknown data_format ', data_format)\n+    if hasattr(x, '_keras_shape'):\n+        shape = x._keras_shape\n+    else:\n+        shape = None\n     if data_format == 'channels_last':\n         # original shape: (batch, length, input_dim)\n         # add dim to x to have (batch, length, 1, input_dim)\n         x = expand_dims(x, 2)\n         # update x._keras_shape\n-        if hasattr(x, '_keras_shape'):\n-            shape = x._keras_shape\n+        if shape is not None:\n             x._keras_shape = (shape[0], shape[1], 1, shape[2])\n     else:\n         # original shape: (batch, input_dim, length)\n         # add dim to x to have (batch, input_dim, length, 1)\n         x = expand_dims(x, 3)\n         # update x._keras_shape\n-        if hasattr(x, '_keras_shape'):\n-            shape = x._keras_shape\n+        if shape is not None:\n             x._keras_shape = (shape[0], shape[1], shape[2], 1)\n     # update dilation rate, strides\n     dilation_rate = (dilation_rate, 1)\n     strides = (stride, 1)\n     # add dim to kernel (always same format independently of data_format)\n     # i.e. (rows, 1, input_depth, depth)\n-    kernel = expand_dims(x, 1)\n+    kernel = expand_dims(kernel, 1)\n     output = conv2d(x, kernel,\n                     strides=strides, padding=padding,\n                     data_format=data_format, dilation_rate=dilation_rate)\n@@ -1581,19 +1580,20 @@ def conv2d(x, kernel, strides=(1, 1), padding='valid',\n     if data_format not in {'channels_first', 'channels_last'}:\n         raise ValueError('Unknown data_format ', data_format)\n \n-    x = _preprocess_conv2d_input(x, data_format)\n-    kernel = _preprocess_conv2d_kernel(kernel, data_format)\n-    th_padding = _preprocess_padding(padding)\n-\n+    if hasattr(x, '_keras_shape'):\n+        image_shape = _preprocess_conv2d_image_shape(int_shape(x), data_format)\n+    else:\n+        image_shape = None\n     if hasattr(kernel, '_keras_shape'):\n         kernel_shape = kernel._keras_shape\n     else:\n         # Will only work if `kernel` is a shared variable.\n         kernel_shape = kernel.eval().shape\n+    kernel_shape = _preprocess_conv2d_filter_shape(kernel_shape, data_format)\n \n-    image_shape = int_shape(x)\n-    image_shape = _preprocess_conv2d_image_shape(data_format, image_shape)\n-    kernel_shape = _preprocess_conv2d_filter_shape(data_format, kernel_shape)\n+    x = _preprocess_conv2d_input(x, data_format)\n+    kernel = _preprocess_conv2d_kernel(kernel, data_format)\n+    th_padding = _preprocess_padding(padding)\n \n     conv_out = T.nnet.conv2d(x, kernel,\n                              border_mode=th_padding,\n@@ -1631,22 +1631,18 @@ def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n                         output_shape[1],\n                         output_shape[2])\n \n-    x = _preprocess_conv2d_input(x, data_format)\n-    kernel = _preprocess_conv2d_kernel(kernel, data_format)\n-\n-    kernel = kernel.dimshuffle((1, 0, 2, 3))\n-    th_padding = _preprocess_padding(padding)\n-\n     if hasattr(kernel, '_keras_shape'):\n         kernel_shape = kernel._keras_shape\n     else:\n         # Will only work if `kernel` is a shared variable.\n         kernel_shape = kernel.eval().shape\n+    kernel_shape = _preprocess_conv2d_filter_shape(kernel_shape, data_format)\n \n-    filter_shape = _preprocess_conv2d_filter_shape(data_format, kernel_shape)\n-    filter_shape = tuple(filter_shape[i] for i in (1, 0, 2, 3))\n+    x = _preprocess_conv2d_input(x, data_format)\n+    kernel = _preprocess_conv2d_kernel(kernel, data_format)\n \n-    op = T.nnet.abstract_conv.AbstractConv2d_gradInputs(imshp=output_shape,\n+    th_padding = _preprocess_padding(padding)\n+    op = T.nnet.abstract_conv.AbstractConv2d_gradInputs(imshp=None,\n                                                         kshp=kernel_shape,\n                                                         subsample=strides,\n                                                         border_mode=th_padding,\n@@ -1680,19 +1676,20 @@ def conv3d(x, kernel, strides=(1, 1, 1),\n     if data_format not in {'channels_first', 'channels_last'}:\n         raise ValueError('Unknown data_format:', data_format)\n \n-    x = _preprocess_conv3d_input(x, data_format)\n-    kernel = _preprocess_conv3d_kernel(kernel, data_format)\n-    th_padding = _preprocess_padding(padding)\n-\n+    if hasattr(x, '_keras_shape'):\n+        volume_shape = _preprocess_conv3d_volume_shape(int_shape(x), data_format)\n+    else:\n+        volume_shape = None\n     if hasattr(kernel, '_keras_shape'):\n         kernel_shape = kernel._keras_shape\n     else:\n         # Will only work if `kernel` is a shared variable.\n         kernel_shape = kernel.eval().shape\n+    kernel_shape = _preprocess_conv3d_filter_shape(kernel_shape, data_format)\n \n-    volume_shape = int_shape(x)\n-    volume_shape = _preprocess_conv3d_volume_shape(data_format, volume_shape)\n-    kernel_shape = _preprocess_conv3d_filter_shape(data_format, kernel_shape)\n+    x = _preprocess_conv3d_input(x, data_format)\n+    kernel = _preprocess_conv3d_kernel(kernel, data_format)\n+    th_padding = _preprocess_padding(padding)\n \n     conv_out = T.nnet.conv3d(x, kernel,\n                              border_mode=th_padding,\n@@ -1815,12 +1812,12 @@ def bias_add(x, bias, data_format=None):\n             x += reshape(bias, (1, bias.shape[0], 1, 1, 1))\n         elif data_format == 'channels_last':\n             x += reshape(bias, (1, 1, 1, 1, bias.shape[0]))\n-    if ndim(x) == 4:\n+    elif ndim(x) == 4:\n         if data_format == 'channels_first':\n             x += reshape(bias, (1, bias.shape[0], 1, 1))\n         elif data_format == 'channels_last':\n             x += reshape(bias, (1, 1, 1, bias.shape[0]))\n-    if ndim(x) == 3:\n+    elif ndim(x) == 3:\n         if data_format == 'channels_first':\n             x += reshape(bias, (1, bias.shape[0], 1))\n         elif data_format == 'channels_last':\n\n@@ -750,11 +750,10 @@ class Conv2DTranspose(Conv2D):\n         else:\n             output_shape = (batch_size, out_height, out_width, self.filters)\n \n-        output_shape_tensor = K.stack(output_shape)\n         outputs = K.conv2d_transpose(\n             inputs,\n             self.kernel,\n-            output_shape_tensor,\n+            output_shape,\n             self.strides,\n             padding=self.padding,\n             data_format=self.data_format)\n@@ -1573,12 +1572,12 @@ class Cropping2D(Layer):\n         if self.data_format == 'channels_first':\n             return (input_shape[0],\n                     input_shape[1],\n-                    input_shape[2] - self.cropping[0][0] - self.cropping[0][1],\n-                    input_shape[3] - self.cropping[1][0] - self.cropping[1][1])\n+                    input_shape[2] - self.cropping[0][0] - self.cropping[0][1] if input_shape[2] else None,\n+                    input_shape[3] - self.cropping[1][0] - self.cropping[1][1] if input_shape[3] else None)\n         elif self.data_format == 'channels_last':\n             return (input_shape[0],\n-                    input_shape[1] - self.cropping[0][0] - self.cropping[0][1],\n-                    input_shape[2] - self.cropping[1][0] - self.cropping[1][1],\n+                    input_shape[1] - self.cropping[0][0] - self.cropping[0][1] if input_shape[1] else None,\n+                    input_shape[2] - self.cropping[1][0] - self.cropping[1][1] if input_shape[2] else None,\n                     input_shape[3])\n         else:\n             raise ValueError('Invalid data_format:', self.data_format)\n\n@@ -61,14 +61,13 @@ def normalize_padding(value):\n     return padding\n \n \n-def convert_kernel(kernel, data_format=None):\n+def convert_kernel(kernel):\n     \"\"\"Converts a Numpy kernel matrix from Theano format to TensorFlow format.\n \n     Also works reciprocally, since the transformation is its own inverse.\n \n     # Arguments\n         kernel: Numpy array (4D or 5D).\n-        data_format: the data format.\n \n     # Returns\n         The converted kernel.\n@@ -76,20 +75,11 @@ def convert_kernel(kernel, data_format=None):\n     # Raises\n         ValueError: in case of invalid kernel shape or invalid data_format.\n     \"\"\"\n-    if data_format is None:\n-        data_format = K.image_data_format()\n     if not 4 <= kernel.ndim <= 5:\n         raise ValueError('Invalid kernel shape:', kernel.shape)\n-\n     slices = [slice(None, None, -1) for _ in range(kernel.ndim)]\n     no_flip = (slice(None, None), slice(None, None))\n-    if data_format == 'channels_first':  # (out_depth, input_depth, ...)\n-        slices[:2] = no_flip\n-    elif data_format == 'channels_last':  # (..., input_depth, out_depth)\n     slices[-2:] = no_flip\n-    else:\n-        raise ValueError('Invalid data_format:', data_format)\n-\n     return np.copy(kernel[slices])\n \n \n\n@@ -3,12 +3,12 @@ from setuptools import find_packages\n \n \n setup(name='Keras',\n-      version='1.2.1',\n+      version='2.0.0',\n       description='Deep Learning for Python',\n       author='Francois Chollet',\n       author_email='francois.chollet@gmail.com',\n       url='https://github.com/fchollet/keras',\n-      download_url='https://github.com/fchollet/keras/tarball/1.2.1',\n+      download_url='https://github.com/fchollet/keras/tarball/2.0.0',\n       license='MIT',\n       install_requires=['theano', 'pyyaml', 'six'],\n       extras_require={\n\n@@ -6,7 +6,7 @@ import scipy.sparse as sparse\n from keras import backend as K\n from keras.backend import theano_backend as KTH, floatx, set_floatx, variable\n from keras.backend import tensorflow_backend as KTF\n-from keras.utils.np_utils import convert_kernel\n+from keras.utils.conv_utils import convert_kernel\n \n \n def check_dtype(var, dtype):\n@@ -541,11 +541,12 @@ class TestBackend(object):\n         check_single_tensor_operation('l2_normalize', (4, 3), axis=1)\n \n     def test_conv2d(self):\n-        # TH kernel shape: (depth, input_depth, rows, cols)\n         # TF kernel shape: (rows, cols, input_depth, depth)\n \n+        # channels_first input shape: (n, input_depth, rows, cols)\n         for input_shape in [(2, 3, 4, 5), (2, 3, 5, 6)]:\n-            for kernel_shape in [(4, 3, 2, 2), (4, 3, 3, 4)]:\n+            for kernel_shape in [(2, 2, 3, 4), (4, 3, 3, 4)]:\n+                for padding in ['valid', 'same']:\n                     xval = np.random.random(input_shape)\n \n                     xth = KTH.variable(xval)\n@@ -553,7 +554,7 @@ class TestBackend(object):\n \n                     kernel_val = np.random.random(kernel_shape) - 0.5\n \n-                kernel_th = KTH.variable(convert_kernel(kernel_val, data_format='channels_first'))\n+                    kernel_th = KTH.variable(convert_kernel(kernel_val))\n                     kernel_tf = KTF.variable(kernel_val)\n \n                     zth = KTH.eval(KTH.conv2d(xth, kernel_th, data_format='channels_first'))\n@@ -572,7 +573,7 @@ class TestBackend(object):\n \n         kernel_val = np.random.random(kernel_shape) - 0.5\n \n-        kernel_th = KTH.variable(convert_kernel(kernel_val, data_format='channels_last'))\n+        kernel_th = KTH.variable(convert_kernel(kernel_val))\n         kernel_tf = KTF.variable(kernel_val)\n \n         zth = KTH.eval(KTH.conv2d(xth, kernel_th, data_format='channels_last'))\n@@ -587,9 +588,9 @@ class TestBackend(object):\n         # TH kernel shape: (depth, input_depth, x, y, z)\n         # TF kernel shape: (x, y, z, input_depth, depth)\n \n-        # test in data_format = th\n+        # test in data_format = channels_first\n         for input_shape in [(2, 3, 4, 5, 4), (2, 3, 5, 4, 6)]:\n-            for kernel_shape in [(4, 3, 2, 2, 2), (4, 3, 3, 2, 4)]:\n+            for kernel_shape in [(2, 2, 2, 3, 4), (3, 2, 4, 3, 4)]:\n                 xval = np.random.random(input_shape)\n \n                 xth = KTH.variable(xval)\n@@ -597,7 +598,7 @@ class TestBackend(object):\n \n                 kernel_val = np.random.random(kernel_shape) - 0.5\n \n-                kernel_th = KTH.variable(convert_kernel(kernel_val, data_format='channels_first'))\n+                kernel_th = KTH.variable(convert_kernel(kernel_val))\n                 kernel_tf = KTF.variable(kernel_val)\n \n                 zth = KTH.eval(KTH.conv3d(xth, kernel_th, data_format='channels_first'))\n@@ -606,7 +607,7 @@ class TestBackend(object):\n                 assert zth.shape == ztf.shape\n                 assert_allclose(zth, ztf, atol=1e-05)\n \n-        # test in data_format = tf\n+        # test in data_format = channels_last\n         input_shape = (1, 2, 2, 2, 1)\n         kernel_shape = (2, 2, 2, 1, 1)\n \n@@ -617,7 +618,7 @@ class TestBackend(object):\n \n         kernel_val = np.random.random(kernel_shape) - 0.5\n \n-        kernel_th = KTH.variable(convert_kernel(kernel_val, data_format='channels_last'))\n+        kernel_th = KTH.variable(convert_kernel(kernel_val))\n         kernel_tf = KTF.variable(kernel_val)\n \n         zth = KTH.eval(KTH.conv3d(xth, kernel_th, data_format='channels_last'))\n@@ -628,33 +629,33 @@ class TestBackend(object):\n \n     def test_pool2d(self):\n         check_single_tensor_operation('pool2d', (5, 10, 12, 3), pool_size=(2, 2),\n-                                      strides=(1, 1), border_mode='valid')\n+                                      strides=(1, 1), padding='valid')\n \n         check_single_tensor_operation('pool2d', (5, 9, 11, 3), pool_size=(2, 2),\n-                                      strides=(1, 1), border_mode='valid')\n+                                      strides=(1, 1), padding='valid')\n \n         check_single_tensor_operation('pool2d', (5, 9, 11, 3), pool_size=(2, 3),\n-                                      strides=(1, 1), border_mode='valid')\n+                                      strides=(1, 1), padding='valid')\n \n     def test_pool3d(self):\n         check_single_tensor_operation('pool3d', (5, 10, 12, 5, 3), pool_size=(2, 2, 2),\n-                                      strides=(1, 1, 1), border_mode='valid')\n+                                      strides=(1, 1, 1), padding='valid')\n \n         check_single_tensor_operation('pool3d', (5, 9, 11, 5, 3), pool_size=(2, 2, 2),\n-                                      strides=(1, 1, 1), border_mode='valid')\n+                                      strides=(1, 1, 1), padding='valid')\n \n         check_single_tensor_operation('pool3d', (5, 9, 11, 5, 3), pool_size=(2, 3, 2),\n-                                      strides=(1, 1, 1), border_mode='valid')\n+                                      strides=(1, 1, 1), padding='valid')\n \n     def test_random_normal(self):\n         mean = 0.\n         std = 1.\n-        rand = KTF.eval(KTF.random_normal((1000, 1000), mean=mean, std=std))\n+        rand = KTF.eval(KTF.random_normal((1000, 1000), mean=mean, stddev=std))\n         assert rand.shape == (1000, 1000)\n         assert np.abs(np.mean(rand) - mean) < 0.01\n         assert np.abs(np.std(rand) - std) < 0.01\n \n-        rand = KTH.eval(KTH.random_normal((1000, 1000), mean=mean, std=std))\n+        rand = KTH.eval(KTH.random_normal((1000, 1000), mean=mean, stddev=std))\n         assert rand.shape == (1000, 1000)\n         assert np.abs(np.mean(rand) - mean) < 0.01\n         assert np.abs(np.std(rand) - std) < 0.01\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b118cef26fae748d5ec23c33b29e9989a7abbe17", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 393 | Lines Deleted: 554 | Files Changed: 10 | Hunks: 114 | Methods Changed: 47 | Complexity Δ (Sum/Max): -30/1 | Churn Δ: 947 | Churn Cumulative: 35483 | Contributors (this commit): 136 | Commits (past 90d): 184 | Contributors (cumulative): 241 | DMM Complexity: 0.0\n\nDIFF:\n@@ -20,7 +20,7 @@ TAGS = ['rock', 'pop', 'alternative', 'indie', 'electronic',\n         'sad', 'House', 'happy']\n \n \n-def preprocess_input(audio_path, data_format='default'):\n+def preprocess_input(audio_path, data_format=None):\n     \"\"\"Reads an audio file and outputs a Mel-spectrogram.\n \n     # Arguments\n@@ -33,7 +33,7 @@ def preprocess_input(audio_path, data_format='default'):\n     # Raises\n         ImportError: if librosa is not available.\n     \"\"\"\n-    if data_format == 'default':\n+    if data_format is None:\n         data_format = K.image_data_format()\n     assert data_format in {'channels_last', 'channels_first'}\n \n\n@@ -8,7 +8,7 @@ CLASS_INDEX = None\n CLASS_INDEX_PATH = 'https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json'\n \n \n-def preprocess_input(x, data_format='default'):\n+def preprocess_input(x, data_format=None):\n     \"\"\"Preprocesses a tensor encoding a batch of images.\n \n     # Arguments\n@@ -18,7 +18,7 @@ def preprocess_input(x, data_format='default'):\n     # Returns\n         Preprocessed tensor.\n     \"\"\"\n-    if data_format == 'default':\n+    if data_format is None:\n         data_format = K.image_data_format()\n     assert data_format in {'channels_last', 'channels_first'}\n \n\n@@ -2237,17 +2237,6 @@ def rnn(step_function, inputs, initial_states,\n     return last_output, outputs, new_states\n \n \n-def _cond(condition, then_lambda, else_lambda):\n-    \"\"\"Backwards compatible interface to tf.cond prior to public introduction.\n-    \"\"\"\n-    try:\n-        cond_fn = tf.cond\n-    except AttributeError:\n-        from tensorflow.python.ops import control_flow_ops\n-        cond_fn = control_flow_ops.cond\n-    return cond_fn(condition, then_lambda, else_lambda)\n-\n-\n def switch(condition, then_expression, else_expression):\n     \"\"\"Switches between two operations\n     depending on a scalar value (`int` or `bool`).\n@@ -2274,56 +2263,54 @@ def switch(condition, then_expression, else_expression):\n             return else_expression\n     else:\n         else_expression_fn = else_expression\n-    x = _cond(condition,\n+    x = tf.cond(condition,\n                 then_expression_fn,\n                 else_expression_fn)\n     return x\n \n \n-def in_train_phase(x, alt):\n+def in_train_phase(x, alt, training=None):\n     \"\"\"Selects `x` in train phase, and `alt` otherwise.\n+\n     Note that `alt` should have the *same shape* as `x`.\n \n     # Returns\n-        Either `x` or `alt` based on `K.learning_phase`.\n+        Either `x` or `alt` based on the `training` flag.\n+        the `training` flag defaults to `K.learning_phase()`.\n     \"\"\"\n-    if learning_phase() is 1:\n+    if training is None:\n+        training = learning_phase()\n+        uses_learning_phase = True\n+    else:\n+        uses_learning_phase = False\n+\n+    if training is 1 or training is True:\n         if callable(x):\n             return x()\n         else:\n             return x\n-    elif learning_phase() is 0:\n+\n+    elif training is 0 or training is False:\n         if callable(alt):\n             return alt()\n         else:\n             return alt\n+\n     # else: assume learning phase is a placeholder tensor.\n-    x = switch(learning_phase(), x, alt)\n+    x = switch(training, x, alt)\n+    if uses_learning_phase:\n         x._uses_learning_phase = True\n     return x\n \n \n-def in_test_phase(x, alt):\n+def in_test_phase(x, alt, training=None):\n     \"\"\"Selects `x` in test phase, and `alt` otherwise.\n     Note that `alt` should have the *same shape* as `x`.\n \n     # Returns\n         Either `x` or `alt` based on `K.learning_phase`.\n     \"\"\"\n-    if learning_phase() is 1:\n-        if callable(alt):\n-            return alt()\n-        else:\n-            return alt\n-    elif learning_phase() is 0:\n-        if callable(x):\n-            return x()\n-        else:\n-            return x\n-    # else: assume learning phase is a placeholder tensor.\n-    x = switch(learning_phase(), alt, x)\n-    x._uses_learning_phase = True\n-    return x\n+    return in_train_phase(alt, x, training=training)\n \n \n # NN OPERATIONS\n\n@@ -1207,32 +1207,48 @@ def switch(condition, then_expression, else_expression):\n     return T.switch(condition, then_expression, else_expression)\n \n \n-def in_train_phase(x, alt):\n+def in_train_phase(x, alt, training=None):\n+    \"\"\"Selects `x` in train phase, and `alt` otherwise.\n+\n+    Note that `alt` should have the *same shape* as `x`.\n+\n+    # Returns\n+        Either `x` or `alt` based on the `training` flag.\n+        the `training` flag defaults to `K.learning_phase()`.\n+    \"\"\"\n+    if training is None:\n+        training = learning_phase()\n+        uses_learning_phase = True\n+    else:\n+        uses_learning_phase = False\n+\n+    if training is 1 or training is True:\n         if callable(x):\n-        x = x()\n-    if callable(alt):\n-        alt = alt()\n-    if _LEARNING_PHASE is 1:\n+            return x()\n+        else:\n             return x\n-    elif _LEARNING_PHASE is 0:\n+\n+    elif training is 0 or training is False:\n+        if callable(alt):\n+            return alt()\n+        else:\n             return alt\n-    x = theano.ifelse.ifelse(_LEARNING_PHASE, x, alt)\n+\n+    # else: assume learning phase is a placeholder tensor.\n+    x = theano.ifelse.ifelse(training, x, alt)\n+    if uses_learning_phase:\n         x._uses_learning_phase = True\n     return x\n \n \n-def in_test_phase(x, alt):\n-    if callable(x):\n-        x = x()\n-    if callable(alt):\n-        alt = alt()\n-    if _LEARNING_PHASE is 1:\n-        return alt\n-    elif _LEARNING_PHASE is 0:\n-        return x\n-    x = theano.ifelse.ifelse(_LEARNING_PHASE, alt, x)\n-    x._uses_learning_phase = True\n-    return x\n+def in_test_phase(x, alt, training=None):\n+    \"\"\"Selects `x` in test phase, and `alt` otherwise.\n+    Note that `alt` should have the *same shape* as `x`.\n+\n+    # Returns\n+        Either `x` or `alt` based on `K.learning_phase`.\n+    \"\"\"\n+    return in_train_phase(alt, x, training=training)\n \n \n # NN OPERATIONS\n\n@@ -1,7 +1,8 @@\n from .. import initializers\n+from .. import regularizers\n+from .. import constraints\n from ..engine import Layer\n from .. import backend as K\n-import numpy as np\n \n \n class LeakyReLU(Layer):\n@@ -27,11 +28,11 @@ class LeakyReLU(Layer):\n     \"\"\"\n \n     def __init__(self, alpha=0.3, **kwargs):\n-        self.supports_masking = True\n-        self.alpha = alpha\n         super(LeakyReLU, self).__init__(**kwargs)\n+        self.supports_masking = True\n+        self.alpha = K.cast_to_floatx(alpha)\n \n-    def call(self, x, mask=None):\n+    def call(self, x):\n         return K.relu(x, alpha=self.alpha)\n \n     def get_config(self):\n@@ -44,9 +45,9 @@ class PReLU(Layer):\n     \"\"\"Parametric Rectified Linear Unit.\n \n     It follows:\n-    `f(x) = alphas * x for x < 0`,\n+    `f(x) = alpha * x for x < 0`,\n     `f(x) = x for x >= 0`,\n-    where `alphas` is a learned array with the same shape as x.\n+    where `alpha` is a learned array with the same shape as x.\n \n     # Input shape\n         Arbitrary. Use the keyword argument `input_shape`\n@@ -57,8 +58,9 @@ class PReLU(Layer):\n         Same shape as the input.\n \n     # Arguments\n-        init: initializer function for the weights.\n-        weights: initial weights, as a list of a single Numpy array.\n+        alpha_initializer: initializer function for the weights.\n+        alpha_regularizer: regularizer for the weights.\n+        alpha_constraint: constraint for the weights.\n         shared_axes: the axes along which to share learnable\n             parameters for the activation function.\n             For example, if the incoming feature maps\n@@ -72,15 +74,20 @@ class PReLU(Layer):\n         - [Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification](https://arxiv.org/abs/1502.01852)\n     \"\"\"\n \n-    def __init__(self, init='zero', weights=None, shared_axes=None, **kwargs):\n+    def __init__(self, alpha_initializer='zeros',\n+                 alpha_regularizer=None,\n+                 alpha_constraint=None,\n+                 shared_axes=None,\n+                 **kwargs):\n+        super(PReLU, self).__init__(**kwargs)\n         self.supports_masking = True\n-        self.init = initializers.get(init)\n-        self.initial_weights = weights\n+        self.alpha_initializer = initializers.get(alpha_initializer)\n+        self.alpha_regularizer = regularizers.get(alpha_regularizer)\n+        self.alpha_constraint = constraints.get(alpha_constraint)\n         if not isinstance(shared_axes, (list, tuple)):\n             self.shared_axes = [shared_axes]\n         else:\n             self.shared_axes = list(shared_axes)\n-        super(PReLU, self).__init__(**kwargs)\n \n     def build(self, input_shape):\n         param_shape = list(input_shape[1:])\n@@ -89,22 +96,19 @@ class PReLU(Layer):\n             for i in self.shared_axes:\n                 param_shape[i - 1] = 1\n                 self.param_broadcast[i - 1] = True\n-\n-        self.alphas = self.init(param_shape,\n-                                name='{}_alphas'.format(self.name))\n-        self.trainable_weights = [self.alphas]\n-\n-        if self.initial_weights is not None:\n-            self.set_weights(self.initial_weights)\n-            del self.initial_weights\n+        self.alpha = self.add_weight(param_shape,\n+                                     name='alpha',\n+                                     initializer=self.alpha_initializer,\n+                                     regularizer=self.alpha_regularizer,\n+                                     constraint=self.alpha_constraint)\n \n     def call(self, x, mask=None):\n         pos = K.relu(x)\n         if K.backend() == 'theano':\n-            neg = (K.pattern_broadcast(self.alphas, self.param_broadcast) *\n+            neg = (K.pattern_broadcast(self.alpha, self.param_broadcast) *\n                    (x - K.abs(x)) * 0.5)\n         else:\n-            neg = self.alphas * (x - K.abs(x)) * 0.5\n+            neg = self.alpha * (x - K.abs(x)) * 0.5\n         return pos + neg\n \n     def get_config(self):\n@@ -136,11 +140,11 @@ class ELU(Layer):\n     \"\"\"\n \n     def __init__(self, alpha=1.0, **kwargs):\n+        super(ELU, self).__init__(**kwargs)\n         self.supports_masking = True\n         self.alpha = K.cast_to_floatx(alpha)\n-        super(ELU, self).__init__(**kwargs)\n \n-    def call(self, x, mask=None):\n+    def call(self, x):\n         return K.elu(x, self.alpha)\n \n     def get_config(self):\n@@ -149,82 +153,6 @@ class ELU(Layer):\n         return dict(list(base_config.items()) + list(config.items()))\n \n \n-class ParametricSoftplus(Layer):\n-    \"\"\"Parametric Softplus.\n-\n-    It follows:\n-    `f(x) = alpha * log(1 + exp(beta * x))`\n-\n-    # Input shape\n-        Arbitrary. Use the keyword argument `input_shape`\n-        (tuple of integers, does not include the samples axis)\n-        when using this layer as the first layer in a model.\n-\n-    # Output shape\n-        Same shape as the input.\n-\n-    # Arguments\n-        alpha_init: float. Initial value of the alpha weights.\n-        beta_init: float. Initial values of the beta weights.\n-        weights: initial weights, as a list of 2 numpy arrays.\n-        shared_axes: the axes along which to share learnable\n-            parameters for the activation function.\n-            For example, if the incoming feature maps\n-            are from a 2D convolution\n-            with output shape `(batch, height, width, channels)`,\n-            and you wish to share parameters across space\n-            so that each filter only has one set of parameters,\n-            set `shared_axes=[1, 2]`.\n-\n-    # References\n-        - [Inferring Nonlinear Neuronal Computation Based on Physiologically Plausible Inputs](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003143)\n-    \"\"\"\n-\n-    def __init__(self, alpha_init=0.2, beta_init=5.0,\n-                 weights=None, shared_axes=None, **kwargs):\n-        self.supports_masking = True\n-        self.alpha_init = K.cast_to_floatx(alpha_init)\n-        self.beta_init = K.cast_to_floatx(beta_init)\n-        self.initial_weights = weights\n-        if not isinstance(shared_axes, (list, tuple)):\n-            self.shared_axes = [shared_axes]\n-        else:\n-            self.shared_axes = list(shared_axes)\n-        super(ParametricSoftplus, self).__init__(**kwargs)\n-\n-    def build(self, input_shape):\n-        param_shape = list(input_shape[1:])\n-        self.param_broadcast = [False] * len(param_shape)\n-        if self.shared_axes[0] is not None:\n-            for i in self.shared_axes:\n-                param_shape[i - 1] = 1\n-                self.param_broadcast[i - 1] = True\n-\n-        self.alphas = K.variable(self.alpha_init * np.ones(param_shape),\n-                                 name='{}_alphas'.format(self.name))\n-        self.betas = K.variable(self.beta_init * np.ones(param_shape),\n-                                name='{}_betas'.format(self.name))\n-        self.trainable_weights = [self.alphas, self.betas]\n-\n-        if self.initial_weights is not None:\n-            self.set_weights(self.initial_weights)\n-            del self.initial_weights\n-\n-    def call(self, x, mask=None):\n-        if K.backend() == 'theano':\n-            return (K.softplus(K.pattern_broadcast(self.betas,\n-                                                   self.param_broadcast) * x) *\n-                    K.pattern_broadcast(self.alphas, self.param_broadcast))\n-        else:\n-            return K.softplus(self.betas * x) * self.alphas\n-\n-    def get_config(self):\n-        config = {'alpha_init': float(self.alpha_init),\n-                  'beta_init': float(self.beta_init)}\n-        base_config = super(ParametricSoftplus, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n class ThresholdedReLU(Layer):\n     \"\"\"Thresholded Rectified Linear Unit.\n \n@@ -248,9 +176,9 @@ class ThresholdedReLU(Layer):\n     \"\"\"\n \n     def __init__(self, theta=1.0, **kwargs):\n+        super(ThresholdedReLU, self).__init__(**kwargs)\n         self.supports_masking = True\n         self.theta = K.cast_to_floatx(theta)\n-        super(ThresholdedReLU, self).__init__(**kwargs)\n \n     def call(self, x, mask=None):\n         return x * K.cast(x > self.theta, K.floatx())\n@@ -259,105 +187,3 @@ class ThresholdedReLU(Layer):\n         config = {'theta': float(self.theta)}\n         base_config = super(ThresholdedReLU, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class SReLU(Layer):\n-    \"\"\"S-shaped Rectified Linear Unit.\n-\n-    It follows:\n-    `f(x) = t^r + a^r(x - t^r) for x >= t^r`,\n-    `f(x) = x for t^r > x > t^l`,\n-    `f(x) = t^l + a^l(x - t^l) for x <= t^l`.\n-\n-    # Input shape\n-        Arbitrary. Use the keyword argument `input_shape`\n-        (tuple of integers, does not include the samples axis)\n-        when using this layer as the first layer in a model.\n-\n-    # Output shape\n-        Same shape as the input.\n-\n-    # Arguments\n-        t_left_init: initializer function for the left part intercept\n-        a_left_init: initializer function for the left part slope\n-        t_right_init: initializer function for the right part intercept\n-        a_right_init: initializer function for the right part slope\n-        shared_axes: the axes along which to share learnable\n-            parameters for the activation function.\n-            For example, if the incoming feature maps\n-            are from a 2D convolution\n-            with output shape `(batch, height, width, channels)`,\n-            and you wish to share parameters across space\n-            so that each filter only has one set of parameters,\n-            set `shared_axes=[1, 2]`.\n-\n-    # References\n-        - [Deep Learning with S-shaped Rectified Linear Activation Units](http://arxiv.org/abs/1512.07030)\n-    \"\"\"\n-\n-    def __init__(self, t_left_init='zero', a_left_init='glorot_uniform',\n-                 t_right_init='glorot_uniform', a_right_init='one',\n-                 shared_axes=None, **kwargs):\n-        self.supports_masking = True\n-        self.t_left_init = t_left_init\n-        self.a_left_init = a_left_init\n-        self.t_right_init = t_right_init\n-        self.a_right_init = a_right_init\n-        if not isinstance(shared_axes, (list, tuple)):\n-            self.shared_axes = [shared_axes]\n-        else:\n-            self.shared_axes = list(shared_axes)\n-        super(SReLU, self).__init__(**kwargs)\n-\n-    def build(self, input_shape):\n-        param_shape = list(input_shape[1:])\n-        self.param_broadcast = [False] * len(param_shape)\n-        if self.shared_axes[0] is not None:\n-            for i in self.shared_axes:\n-                param_shape[i - 1] = 1\n-                self.param_broadcast[i - 1] = True\n-\n-        t_left_init = initializers.get(self.t_left_init)\n-        a_left_init = initializers.get(self.a_left_init)\n-        t_right_init = initializers.get(self.t_right_init)\n-        a_right_init = initializers.get(self.a_right_init)\n-\n-        self.t_left = t_left_init(param_shape,\n-                                  name='{}_t_left'.format(self.name))\n-        self.a_left = a_left_init(param_shape,\n-                                  name='{}_a_left'.format(self.name))\n-        self.t_right = t_right_init(param_shape,\n-                                    name='{}_t_right'.format(self.name))\n-        self.a_right = a_right_init(param_shape,\n-                                    name='{}_a_right'.format(self.name))\n-        # ensure the the right part is always to the right of the left\n-        self.t_right_actual = self.t_left + K.abs(self.t_right)\n-        self.trainable_weights = [self.t_left, self.a_left,\n-                                  self.t_right, self.a_right]\n-\n-    def call(self, x, mask=None):\n-        if K.backend() == 'theano':\n-            t_left = K.pattern_broadcast(self.t_left, self.param_broadcast)\n-            a_left = K.pattern_broadcast(self.a_left, self.param_broadcast)\n-            a_right = K.pattern_broadcast(self.a_right, self.param_broadcast)\n-            t_right_actual = K.pattern_broadcast(self.t_right_actual,\n-                                                 self.param_broadcast)\n-        else:\n-            t_left = self.t_left\n-            a_left = self.a_left\n-            a_right = self.a_right\n-            t_right_actual = self.t_right_actual\n-\n-        y_left_and_center = t_left + K.relu(x - t_left,\n-                                            a_left,\n-                                            t_right_actual - t_left)\n-        y_right = K.relu(x - t_right_actual) * a_right\n-        return y_left_and_center + y_right\n-\n-    def get_config(self):\n-        config = {'t_left_init': self.t_left_init,\n-                  'a_left_init': self.a_left_init,\n-                  't_right_init': self.t_right_init,\n-                  'a_right_init': self.a_right_init}\n-        base_config = super(SReLU, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n\n@@ -1,6 +1,5 @@\n # -*- coding: utf-8 -*-\n from __future__ import absolute_import\n-import copy\n \n from .. import backend as K\n from .. import activations\n@@ -168,7 +167,7 @@ class _Conv(Layer):\n                 data_format=self.data_format,\n                 dilation_rate=self.dilation_rate)\n \n-        if self.bias is not None:\n+        if self.use_bias:\n             outputs = K.bias_add(\n                 outputs,\n                 self.bias,\n@@ -281,11 +280,9 @@ class Conv1D(_Conv):\n \n     # Input shape\n         3D tensor with shape: `(batch_size, steps, input_dim)`\n-        (if `data_format` is `channels_last`).\n \n     # Output shape\n         3D tensor with shape: `(batch_size, new_steps, nb_filter)`\n-        (if `data_format` is `channels_last`).\n         `steps` value might have changed due to padding or strides.\n     \"\"\"\n \n@@ -1823,3 +1820,13 @@ class Cropping3D(Layer):\n         config = {'cropping': self.cropping}\n         base_config = super(Cropping3D, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n+\n+\n+# Aliases\n+\n+Convolution1D = Conv1D\n+Convolution2D = Conv2D\n+Convolution3D = Conv3D\n+SeparableConvolution2D = SeparableConv2D\n+Convolution2DTranspose = Conv2DTranspose\n+Deconvolution2D = Deconv2D = Conv2DTranspose\n\n@@ -257,7 +257,7 @@ class ConvLSTM2D(ConvRecurrent2D):\n                  init='glorot_uniform', inner_init='orthogonal',\n                  forget_bias_init='one', activation='tanh',\n                  inner_activation='hard_sigmoid',\n-                 data_format='default',\n+                 data_format=None,\n                  border_mode='valid', subsample=(1, 1),\n                  W_regularizer=None, U_regularizer=None, b_regularizer=None,\n                  dropout_W=0., dropout_U=0., **kwargs):\n@@ -267,7 +267,7 @@ class ConvLSTM2D(ConvRecurrent2D):\n         kwargs['data_format'] = data_format\n         super(ConvLSTM2D, self).__init__(**kwargs)\n \n-        if data_format == 'default':\n+        if data_format is None:\n             data_format = K.image_data_format()\n         if data_format not in {'channels_last', 'channels_first'}:\n             raise ValueError('data_format must be in '\n\n@@ -100,13 +100,13 @@ class Dropout(Layer):\n     def _get_noise_shape(self, _):\n         return self.noise_shape\n \n-    def call(self, x, mask=None):\n+    def call(self, x, training=None):\n         if 0. < self.rate < 1.:\n             noise_shape = self._get_noise_shape(x)\n \n             def dropped_inputs():\n                 return K.dropout(x, self.rate, noise_shape, seed=self.seed)\n-            x = K.in_train_phase(dropped_inputs, lambda: x)\n+            x = K.in_train_phase(dropped_inputs, x, training=training)\n         return x\n \n     def get_config(self):\n\n@@ -8,23 +8,16 @@ from .. import regularizers\n from .. import constraints\n from ..engine import Layer\n from ..engine import InputSpec\n-from ..utils.conv_utils import conv_output_length\n+from ..utils import conv_utils\n \n \n class LocallyConnected1D(Layer):\n     \"\"\"Locally-connected layer for 1D inputs.\n \n     The `LocallyConnected1D` layer works similarly to\n-    the `Convolution1D` layer, except that weights are unshared,\n+    the `Conv1D` layer, except that weights are unshared,\n     that is, a different set of filters is applied at each different patch\n     of the input.\n-    When using this layer as the first layer in a model,\n-    either provide the keyword argument `input_dim`\n-    (int, e.g. 128 for sequences of 128-dimensional vectors), or `input_shape`\n-    (tuple of integers, e.g. `input_shape=(10, 128)`\n-    for sequences of 10 vectors of 128-dimensional vectors).\n-    Also, note that this layer can only be used with\n-    a fully-specified input shape (`None` dimensions not allowed).\n \n     # Example\n     ```python\n@@ -39,147 +32,146 @@ class LocallyConnected1D(Layer):\n     ```\n \n     # Arguments\n-        nb_filter: Dimensionality of the output.\n-        filter_length: The extension (spatial or temporal) of each filter.\n-        init: name of initializer function for the weights of the layer\n-            (see [initializers](../initializers.md)),\n-            or alternatively, Theano function to use for weights initializer.\n-            This parameter is only relevant if you don't pass a `weights` argument.\n-        activation: name of activation function to use\n-            (see [activations](../activations.md)),\n-            or alternatively, elementwise Theano function.\n+        filters: Integer, the dimensionality of the output space\n+            (i.e. the number output of filters in the convolution).\n+        kernel_size: An integer or tuple/list of a single integer,\n+            specifying the length of the 1D convolution window.\n+        strides: An integer or tuple/list of a single integer,\n+            specifying the stride length of the convolution.\n+            Specifying any stride value != 1 is incompatible with specifying\n+            any `dilation_rate` value != 1.\n+        padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n+        activation: Activation function to use\n+            (see [activations](../activations.md)).\n             If you don't specify anything, no activation is applied\n-            (ie. \"linear\" activation: a(x) = x).\n-        weights: list of numpy arrays to set as initial weights.\n-        border_mode: Only support 'valid'. Please make good use of\n-            ZeroPadding1D to achieve same output length.\n-        subsample_length: factor by which to subsample output.\n-        W_regularizer: instance of [WeightRegularizer](../regularizers.md)\n-            (eg. L1 or L2 regularization), applied to the main weights matrix.\n-        b_regularizer: instance of [WeightRegularizer](../regularizers.md),\n-            applied to the bias.\n-        activity_regularizer: instance of [ActivityRegularizer](../regularizers.md),\n-            applied to the network output.\n-        W_constraint: instance of the [constraints](../constraints.md) module\n-            (eg. maxnorm, nonneg), applied to the main weights matrix.\n-        b_constraint: instance of the [constraints](../constraints.md) module,\n-            applied to the bias.\n-        bias: whether to include a bias (i.e. make the layer affine rather than linear).\n-        input_dim: Number of channels/dimensions in the input.\n-            Either this argument or the keyword argument `input_shape`must be\n-            provided when using this layer as the first layer in a model.\n-        input_length: Length of input sequences, when it is constant.\n-            This argument is required if you are going to connect\n-            `Flatten` then `Dense` layers upstream\n-            (without it, the shape of the dense outputs cannot be computed).\n+            (ie. \"linear\" activation: `a(x) = x`).\n+        use_bias: Boolean, whether the layer uses a bias vector.\n+        kernel_initializer: Initializer for the `kernel` weights matrix\n+            (see [initializers](../initializers.md)).\n+        bias_initializer: Initializer for the bias vector\n+            (see [initializers](../initializers.md)).\n+        kernel_regularizer: Regularizer function applied to\n+            the `kernel` weights matrix\n+            (see [regularizer](../regularizers.md)).\n+        bias_regularizer: Regularizer function applied to the bias vector\n+            (see [regularizer](../regularizers.md)).\n+        activity_regularizer: Regularizer function applied to\n+            the output of the layer (its \"activation\").\n+            (see [regularizer](../regularizers.md)).\n+        kernel_constraint: Constraint function applied to the kernel matrix\n+            (see [constraints](../constraints.md)).\n+        bias_constraint: Constraint function applied to the bias vector\n+            (see [constraints](../constraints.md)).\n \n     # Input shape\n-        3D tensor with shape: `(samples, steps, input_dim)`.\n+        3D tensor with shape: `(batch_size, steps, input_dim)`\n \n     # Output shape\n-        3D tensor with shape: `(samples, new_steps, nb_filter)`.\n-        `steps` value might have changed due to padding.\n+        3D tensor with shape: `(batch_size, new_steps, nb_filter)`\n+        `steps` value might have changed due to padding or strides.\n     \"\"\"\n \n-    def __init__(self, nb_filter, filter_length,\n-                 init='glorot_uniform', activation=None, weights=None,\n-                 border_mode='valid', subsample_length=1,\n-                 W_regularizer=None, b_regularizer=None, activity_regularizer=None,\n-                 W_constraint=None, b_constraint=None,\n-                 bias=True, input_dim=None, input_length=None, **kwargs):\n-        if border_mode != 'valid':\n-            raise ValueError('Invalid border mode for LocallyConnected1D '\n-                             '(only \"valid\" is supported):', border_mode)\n-        self.nb_filter = nb_filter\n-        self.filter_length = filter_length\n-        self.init = initializers.get(init, data_format='channels_first')\n-        self.activation = activations.get(activation)\n-\n-        self.border_mode = border_mode\n-        self.subsample_length = subsample_length\n-\n-        self.W_regularizer = regularizers.get(W_regularizer)\n-        self.b_regularizer = regularizers.get(b_regularizer)\n-        self.activity_regularizer = regularizers.get(activity_regularizer)\n-\n-        self.W_constraint = constraints.get(W_constraint)\n-        self.b_constraint = constraints.get(b_constraint)\n-\n-        self.bias = bias\n-        self.input_spec = [InputSpec(ndim=3)]\n-        self.initial_weights = weights\n-        self.input_dim = input_dim\n-        self.input_length = input_length\n-        if self.input_dim:\n-            kwargs['input_shape'] = (self.input_length, self.input_dim)\n+    def __init__(self, filters,\n+                 kernel_size,\n+                 strides=1,\n+                 padding='valid',\n+                 data_format=None,\n+                 activation=None,\n+                 use_bias=True,\n+                 kernel_initializer='glorot_uniform',\n+                 bias_initializer='zeros',\n+                 kernel_regularizer=None,\n+                 bias_regularizer=None,\n+                 activity_regularizer=None,\n+                 kernel_constraint=None,\n+                 bias_constraint=None,\n+                 **kwargs):\n         super(LocallyConnected1D, self).__init__(**kwargs)\n+        self.filters = filters\n+        self.kernel_size = conv_utils.normalize_tuple(kernel_size, 1, 'kernel_size')\n+        self.strides = conv_utils.normalize_tuple(strides, 1, 'strides')\n+        self.padding = conv_utils.normalize_padding(padding)\n+        self.data_format = conv_utils.normalize_data_format(data_format)\n+        self.activation = activations.get(activation)\n+        self.use_bias = use_bias\n+        self.kernel_initializer = initializers.get(kernel_initializer)\n+        self.bias_initializer = initializers.get(bias_initializer)\n+        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n+        self.bias_regularizer = regularizers.get(bias_regularizer)\n+        self.activity_regularizer = regularizers.get(activity_regularizer)\n+        self.kernel_constraint = constraints.get(kernel_constraint)\n+        self.bias_constraint = constraints.get(bias_constraint)\n+        self.input_spec = [InputSpec(ndim=3)]\n \n     def build(self, input_shape):\n         input_dim = input_shape[2]\n-        _, output_length, nb_filter = self.get_output_shape_for(input_shape)\n-        self.W_shape = (output_length,\n-                        self.filter_length * input_dim,\n-                        nb_filter)\n-        self.W = self.add_weight(self.W_shape,\n+        if input_dim is None:\n+            raise ValueError('Axis 2 of input should be fully-defined. '\n+                             'Found shape:', input_shape)\n+        _, output_length, filters = self.get_output_shape_for(input_shape)\n+        self.kernel_shape = (output_length,\n+                             self.kernel_size[0] * input_dim,\n+                             filters)\n+        self.kernel = self.add_weight(\n+            self.kernel_shape,\n             initializer=self.init,\n-                                 name='{}_W'.format(self.name),\n-                                 regularizer=self.W_regularizer,\n-                                 constraint=self.W_constraint)\n-        if self.bias:\n-            self.b = self.add_weight((output_length, self.nb_filter),\n-                                     initializer='zero',\n-                                     name='{}_b'.format(self.name),\n-                                     regularizer=self.b_regularizer,\n-                                     constraint=self.b_constraint)\n+            name='kernel',\n+            regularizer=self.kernel_regularizer,\n+            constraint=self.kernel_constraint)\n+        if self.use_bias:\n+            self.bias = self.add_weight(\n+                (output_length, self.filters),\n+                initializer=self.bias_initializer,\n+                name='bias',\n+                regularizer=self.bias_regularizer,\n+                constraint=self.bias_constraint)\n         else:\n-            self.b = None\n-\n-        if self.initial_weights is not None:\n-            self.set_weights(self.initial_weights)\n-            del self.initial_weights\n-        self.built = True\n+            self.bias = None\n \n     def get_output_shape_for(self, input_shape):\n-        length = conv_output_length(input_shape[1],\n-                                    self.filter_length,\n-                                    self.border_mode,\n-                                    self.subsample_length)\n-        return (input_shape[0], length, self.nb_filter)\n+        length = conv_utils.conv_output_length(input_shape[1],\n+                                               self.kernel_size[0],\n+                                               self.padding,\n+                                               self.strides[0])\n+        return (input_shape[0], length, self.filters)\n \n-    def call(self, x, mask=None):\n-        stride = self.subsample_length\n-        output_length, feature_dim, nb_filter = self.W_shape\n+    def call(self, x):\n+        stride = self.strides[0]\n+        output_length, feature_dim, filters = self.kernel_shape\n \n         xs = []\n         for i in range(output_length):\n-            slice_length = slice(i * stride, i * stride + self.filter_length)\n+            slice_length = slice(i * stride, i * stride + self.kernel_size[0])\n             xs.append(K.reshape(x[:, slice_length, :], (1, -1, feature_dim)))\n         x_aggregate = K.concatenate(xs, axis=0)\n-        # (output_length, batch_size, nb_filter)\n-        output = K.batch_dot(x_aggregate, self.W)\n+        # (output_length, batch_size, filters)\n+        output = K.batch_dot(x_aggregate, self.kernel)\n         output = K.permute_dimensions(output, (1, 0, 2))\n \n-        if self.bias:\n-            output += K.reshape(self.b, (1, output_length, nb_filter))\n-\n+        if self.use_bias:\n+            output = K.bias_add(output,\n+                                self.bias,\n+                                data_format='channels_last')\n+        if self.activation is not None:\n             output = self.activation(output)\n         return output\n \n     def get_config(self):\n-        config = {'nb_filter': self.nb_filter,\n-                  'filter_length': self.filter_length,\n-                  'init': initializers.get_config(self.init),\n-                  'activation': self.activation.__name__,\n-                  'border_mode': self.border_mode,\n-                  'subsample_length': self.subsample_length,\n-                  'W_regularizer': self.W_regularizer.get_config() if self.W_regularizer else None,\n-                  'b_regularizer': self.b_regularizer.get_config() if self.b_regularizer else None,\n-                  'activity_regularizer': self.activity_regularizer.get_config() if self.activity_regularizer else None,\n-                  'W_constraint': self.W_constraint.get_config() if self.W_constraint else None,\n-                  'b_constraint': self.b_constraint.get_config() if self.b_constraint else None,\n-                  'bias': self.bias,\n-                  'input_dim': self.input_dim,\n-                  'input_length': self.input_length}\n+        config = {\n+            'filters': self.filters,\n+            'kernel_size': self.kernel_size,\n+            'strides': self.strides,\n+            'padding': self.padding,\n+            'activation': activations.serialize(self.activation),\n+            'use_bias': self.use_bias,\n+            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n+            'bias_initializer': initializers.serialize(self.kernel_initializer),\n+            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n+            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n+            'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n+            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n+            'bias_constraint': constraints.serialize(self.bias_constraint)\n+        }\n         base_config = super(LocallyConnected1D, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n \n@@ -188,61 +180,69 @@ class LocallyConnected2D(Layer):\n     \"\"\"Locally-connected layer for 2D inputs.\n \n     The `LocallyConnected2D` layer works similarly\n-    to the `Convolution2D` layer, except that weights are unshared,\n+    to the `Conv2D` layer, except that weights are unshared,\n     that is, a different set of filters is applied at each\n     different patch of the input.\n-    When using this layer as the\n-    first layer in a model, provide the keyword argument `input_shape` (tuple\n-    of integers, does not include the sample axis), e.g.\n-    `input_shape=(3, 128, 128)` for 128x128 RGB pictures.\n-    Also, note that this layer can only be used with\n-    a fully-specified input shape (`None` dimensions not allowed).\n \n     # Examples\n     ```python\n-        # apply a 3x3 unshared weights convolution with 64 output filters on a 32x32 image:\n+        # apply a 3x3 unshared weights convolution with 64 output filters on a 32x32 image\n+        # with `data_format=\"channels_last\"`:\n         model = Sequential()\n-        model.add(LocallyConnected2D(64, 3, 3, input_shape=(3, 32, 32)))\n-        # now model.output_shape == (None, 64, 30, 30)\n+        model.add(LocallyConnected2D(64, (3, 3), input_shape=(32, 32, 3)))\n+        # now model.output_shape == (None, 30, 30, 64)\n         # notice that this layer will consume (30*30)*(3*3*3*64) + (30*30)*64 parameters\n \n         # add a 3x3 unshared weights convolution on top, with 32 output filters:\n-        model.add(LocallyConnected2D(32, 3, 3))\n-        # now model.output_shape == (None, 32, 28, 28)\n+        model.add(LocallyConnected2D(32, (3, 3)))\n+        # now model.output_shape == (None, 28, 28, 32)\n     ```\n \n     # Arguments\n-        nb_filter: Number of convolution filters to use.\n-        nb_row: Number of rows in the convolution kernel.\n-        nb_col: Number of columns in the convolution kernel.\n-        init: name of initializer function for the weights of the layer\n-            (see [initializers](../initializers.md)), or alternatively,\n-            Theano function to use for weights initializer.\n-            This parameter is only relevant if you don't pass\n-            a `weights` argument.\n-        activation: name of activation function to use\n-            (see [activations](../activations.md)),\n-            or alternatively, elementwise Theano function.\n+        filters: Integer, the dimensionality of the output space\n+            (i.e. the number output of filters in the convolution).\n+        kernel_size: An integer or tuple/list of 2 integers, specifying the\n+            width and height of the 2D convolution window.\n+            Can be a single integer to specify the same value for\n+            all spatial dimensions.\n+        strides: An integer or tuple/list of 2 integers,\n+            specifying the strides of the convolution along the width and height.\n+            Can be a single integer to specify the same value for\n+            all spatial dimensions.\n+            Specifying any stride value != 1 is incompatible with specifying\n+            any `dilation_rate` value != 1.\n+        padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n+        data_format: A string,\n+            one of `channels_last` (default) or `channels_first`.\n+            The ordering of the dimensions in the inputs.\n+            `channels_last` corresponds to inputs with shape\n+            `(batch, width, height, channels)` while `channels_first`\n+            corresponds to inputs with shape\n+            `(batch, channels, width, height)`.\n+            It defaults to the `image_data_format` value found in your\n+            Keras config file at `~/.keras/keras.json`.\n+            If you never set it, then it will be \"channels_last\".\n+        activation: Activation function to use\n+            (see [activations](../activations.md)).\n             If you don't specify anything, no activation is applied\n-            (ie. \"linear\" activation: a(x) = x).\n-        weights: list of numpy arrays to set as initial weights.\n-        border_mode: Only support 'valid'. Please make good use of\n-            ZeroPadding2D to achieve same output shape.\n-        subsample: tuple of length 2. Factor by which to subsample output.\n-            Also called strides elsewhere.\n-        W_regularizer: instance of [WeightRegularizer](../regularizers.md)\n-            (eg. L1 or L2 regularization), applied to the main weights matrix.\n-        b_regularizer: instance of [WeightRegularizer](../regularizers.md),\n-            applied to the bias.\n-        activity_regularizer: instance of [ActivityRegularizer](../regularizers.md),\n-            applied to the network output.\n-        W_constraint: instance of the [constraints](../constraints.md) module\n-            (eg. maxnorm, nonneg), applied to the main weights matrix.\n-        b_constraint: instance of the [constraints](../constraints.md) module,\n-            applied to the bias.\n-        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension\n-            (the depth) is at index 1, in 'channels_last' mode is it at index 3.\n-        bias: whether to include a bias (i.e. make the layer affine rather than linear).\n+            (ie. \"linear\" activation: `a(x) = x`).\n+        use_bias: Boolean, whether the layer uses a bias vector.\n+        kernel_initializer: Initializer for the `kernel` weights matrix\n+            (see [initializers](../initializers.md)).\n+        bias_initializer: Initializer for the bias vector\n+            (see [initializers](../initializers.md)).\n+        kernel_regularizer: Regularizer function applied to\n+            the `kernel` weights matrix\n+            (see [regularizer](../regularizers.md)).\n+        bias_regularizer: Regularizer function applied to the bias vector\n+            (see [regularizer](../regularizers.md)).\n+        activity_regularizer: Regularizer function applied to\n+            the output of the layer (its \"activation\").\n+            (see [regularizer](../regularizers.md)).\n+        kernel_constraint: Constraint function applied to the kernel matrix\n+            (see [constraints](../constraints.md)).\n+        bias_constraint: Constraint function applied to the bias vector\n+            (see [constraints](../constraints.md)).\n \n     # Input shape\n         4D tensor with shape:\n@@ -258,76 +258,75 @@ class LocallyConnected2D(Layer):\n         `rows` and `cols` values might have changed due to padding.\n     \"\"\"\n \n-    def __init__(self, nb_filter, nb_row, nb_col,\n-                 init='glorot_uniform', activation=None, weights=None,\n-                 border_mode='valid', subsample=(1, 1),\n+    def __init__(self, filters,\n+                 kernel_size,\n+                 strides=(1, 1),\n+                 padding='valid',\n                  data_format=None,\n-                 W_regularizer=None, b_regularizer=None, activity_regularizer=None,\n-                 W_constraint=None, b_constraint=None,\n-                 bias=True, **kwargs):\n-        if data_format is None:\n-            data_format = K.image_data_format()\n-        if border_mode != 'valid':\n-            raise ValueError('Invalid border mode for LocallyConnected2D '\n-                             '(only \"valid\" is supported):', border_mode)\n-        self.nb_filter = nb_filter\n-        self.nb_row = nb_row\n-        self.nb_col = nb_col\n-        self.init = initializers.get(init, data_format=data_format)\n-        self.activation = activations.get(activation)\n-\n-        self.border_mode = border_mode\n-        self.subsample = tuple(subsample)\n-        if data_format not in {'channels_last', 'channels_first'}:\n-            raise ValueError('`data_format` must be in {\"channels_last\", \"channels_first\"}.')\n-        self.data_format = data_format\n-\n-        self.W_regularizer = regularizers.get(W_regularizer)\n-        self.b_regularizer = regularizers.get(b_regularizer)\n-        self.activity_regularizer = regularizers.get(activity_regularizer)\n-\n-        self.W_constraint = constraints.get(W_constraint)\n-        self.b_constraint = constraints.get(b_constraint)\n-\n-        self.bias = bias\n-        self.input_spec = [InputSpec(ndim=4)]\n-        self.initial_weights = weights\n+                 activation=None,\n+                 use_bias=True,\n+                 kernel_initializer='glorot_uniform',\n+                 bias_initializer='zeros',\n+                 kernel_regularizer=None,\n+                 bias_regularizer=None,\n+                 activity_regularizer=None,\n+                 kernel_constraint=None,\n+                 bias_constraint=None,\n+                 **kwargs):\n         super(LocallyConnected2D, self).__init__(**kwargs)\n+        self.filters = filters\n+        self.kernel_size = conv_utils.normalize_tuple(kernel_size, 2, 'kernel_size')\n+        self.strides = conv_utils.normalize_tuple(strides, 2, 'strides')\n+        self.padding = conv_utils.normalize_padding(padding)\n+        self.data_format = conv_utils.normalize_data_format(data_format)\n+        self.activation = activations.get(activation)\n+        self.use_bias = use_bias\n+        self.kernel_initializer = initializers.get(kernel_initializer)\n+        self.bias_initializer = initializers.get(bias_initializer)\n+        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n+        self.bias_regularizer = regularizers.get(bias_regularizer)\n+        self.activity_regularizer = regularizers.get(activity_regularizer)\n+        self.kernel_constraint = constraints.get(kernel_constraint)\n+        self.bias_constraint = constraints.get(bias_constraint)\n+        self.input_spec = [InputSpec(ndim=4)]\n \n     def build(self, input_shape):\n+        if self.data_format == 'channels_last':\n+            space = input_shape[1:-1]\n+        else:\n+            space = input_shape[2:]\n+        if space[0] is None or space[1] is None:\n+            raise ValueError('The spatial dimensions of the inputs to '\n+                             ' a LocallyConnected2D layer '\n+                             'should be fully-defined, but layer received '\n+                             'the inputs shape ' + str(input_shape))\n+\n         output_shape = self.get_output_shape_for(input_shape)\n         if self.data_format == 'channels_first':\n-            _, nb_filter, output_row, output_col = output_shape\n+            _, filters, output_row, output_col = output_shape\n             input_filter = input_shape[1]\n         elif self.data_format == 'channels_last':\n-            _, output_row, output_col, nb_filter = output_shape\n+            _, output_row, output_col, filters = output_shape\n             input_filter = input_shape[3]\n-        else:\n-            raise ValueError('Invalid data_format:', self.data_format)\n \n         self.output_row = output_row\n         self.output_col = output_col\n-        self.W_shape = (output_row * output_col,\n-                        self.nb_row * self.nb_col * input_filter,\n-                        nb_filter)\n-        self.W = self.add_weight(self.W_shape,\n-                                 initializer=self.init,\n-                                 name='{}_W'.format(self.name),\n-                                 regularizer=self.W_regularizer,\n-                                 constraint=self.W_constraint)\n+        self.kernel_shape = (output_row * output_col,\n+                             self.kernel_size[0] * self.kernel_size[1] * input_filter,\n+                             self.filters)\n+        self.kernel = self.add_weight(self.kernel_shape,\n+                                      initializer=self.kernel_initializer,\n+                                      name='kernel',\n+                                      regularizer=self.kernel_regularizer,\n+                                      constraint=self.kernel_constraint)\n         if self.bias:\n-            self.b = self.add_weight((output_row, output_col, nb_filter),\n-                                     initializer='zero',\n-                                     name='{}_b'.format(self.name),\n-                                     regularizer=self.b_regularizer,\n-                                     constraint=self.b_constraint)\n+            self.bias = self.add_weight((output_row, output_col, filters),\n+                                        initializer=self.bias_initializer,\n+                                        name='bias',\n+                                        regularizer=self.bias_regularizer,\n+                                        constraint=self.bias_constraint)\n         else:\n-            self.b = None\n-\n-        if self.initial_weights is not None:\n-            self.set_weights(self.initial_weights)\n-            del self.initial_weights\n-        self.built = True\n+            self.bias = None\n \n     def get_output_shape_for(self, input_shape):\n         if self.data_format == 'channels_first':\n@@ -339,19 +338,19 @@ class LocallyConnected2D(Layer):\n         else:\n             raise ValueError('Invalid data_format:', self.data_format)\n \n-        rows = conv_output_length(rows, self.nb_row,\n-                                  self.border_mode, self.subsample[0])\n-        cols = conv_output_length(cols, self.nb_col,\n-                                  self.border_mode, self.subsample[1])\n+        rows = conv_utils.conv_output_length(rows, self.kernel_size[0],\n+                                             self.padding, self.strides[0])\n+        cols = conv_utils.conv_output_length(cols, self.kernel_size[1],\n+                                             self.padding, self.strides[1])\n \n         if self.data_format == 'channels_first':\n-            return (input_shape[0], self.nb_filter, rows, cols)\n+            return (input_shape[0], self.filters, rows, cols)\n         elif self.data_format == 'channels_last':\n-            return (input_shape[0], rows, cols, self.nb_filter)\n+            return (input_shape[0], rows, cols, self.filters)\n \n-    def call(self, x, mask=None):\n-        stride_row, stride_col = self.subsample\n-        _, feature_dim, nb_filter = self.W_shape\n+    def call(self, x):\n+        stride_row, stride_col = self.strides\n+        _, feature_dim, filters = self.kernel_shape\n \n         if self.data_format == 'channels_first':\n             if K.backend() == 'theano':\n@@ -359,64 +358,69 @@ class LocallyConnected2D(Layer):\n                 for i in range(self.output_row):\n                     for j in range(self.output_col):\n                         slice_row = slice(i * stride_row,\n-                                          i * stride_row + self.nb_row)\n+                                          i * stride_row + self.kernel_size[0])\n                         slice_col = slice(j * stride_col,\n-                                          j * stride_col + self.nb_col)\n-                        x_flatten = K.reshape(x[:, :, slice_row, slice_col], (1, -1, feature_dim))\n-                        output.append(K.dot(x_flatten, self.W[i * self.output_col + j, :, :]))\n+                                          j * stride_col + self.kernel_size[1])\n+                        x_flatten = K.reshape(x[:, :, slice_row, slice_col],\n+                                              (1, -1, feature_dim))\n+                        output.append(K.dot(x_flatten,\n+                                      self.kernel[i * self.output_col + j, :, :]))\n                 output = K.concatenate(output, axis=0)\n             else:\n                 xs = []\n                 for i in range(self.output_row):\n                     for j in range(self.output_col):\n                         slice_row = slice(i * stride_row,\n-                                          i * stride_row + self.nb_row)\n+                                          i * stride_row + self.kernel_size[0])\n                         slice_col = slice(j * stride_col,\n-                                          j * stride_col + self.nb_col)\n-                        xs.append(K.reshape(x[:, :, slice_row, slice_col], (1, -1, feature_dim)))\n+                                          j * stride_col + self.kernel_size[1])\n+                        xs.append(K.reshape(x[:, :, slice_row, slice_col],\n+                                            (1, -1, feature_dim)))\n                 x_aggregate = K.concatenate(xs, axis=0)\n-                output = K.batch_dot(x_aggregate, self.W)\n-            output = K.reshape(output, (self.output_row, self.output_col, -1, nb_filter))\n+                output = K.batch_dot(x_aggregate, self.kernel)\n+            output = K.reshape(output,\n+                               (self.output_row, self.output_col, -1, filters))\n             output = K.permute_dimensions(output, (2, 3, 0, 1))\n+\n         elif self.data_format == 'channels_last':\n             xs = []\n             for i in range(self.output_row):\n                 for j in range(self.output_col):\n                     slice_row = slice(i * stride_row,\n-                                      i * stride_row + self.nb_row)\n+                                      i * stride_row + self.kernel_size[0])\n                     slice_col = slice(j * stride_col,\n-                                      j * stride_col + self.nb_col)\n-                    xs.append(K.reshape(x[:, slice_row, slice_col, :], (1, -1, feature_dim)))\n+                                      j * stride_col + self.kernel_size[1])\n+                    xs.append(K.reshape(x[:, slice_row, slice_col, :],\n+                                        (1, -1, feature_dim)))\n             x_aggregate = K.concatenate(xs, axis=0)\n-            output = K.batch_dot(x_aggregate, self.W)\n-            output = K.reshape(output, (self.output_row, self.output_col, -1, nb_filter))\n+            output = K.batch_dot(x_aggregate, self.kernel)\n+            output = K.reshape(output,\n+                               (self.output_row, self.output_col, -1, filters))\n             output = K.permute_dimensions(output, (2, 0, 1, 3))\n-        else:\n-            raise ValueError('Invalid data_format:', self.data_format)\n-\n-        if self.bias:\n-            if self.data_format == 'channels_first':\n-                output += K.reshape(self.b, (1, nb_filter, self.output_row, self.output_col))\n-            elif self.data_format == 'channels_last':\n-                output += K.reshape(self.b, (1, self.output_row, self.output_col, nb_filter))\n \n+        if self.use_bias:\n+            output = K.bias_add(output,\n+                                self.bias,\n+                                data_format=self.data_format)\n         output = self.activation(output)\n         return output\n \n     def get_config(self):\n-        config = {'nb_filter': self.nb_filter,\n-                  'nb_row': self.nb_row,\n-                  'nb_col': self.nb_col,\n-                  'init': initializers.get_config(self.init),\n-                  'activation': self.activation.__name__,\n-                  'border_mode': self.border_mode,\n-                  'subsample': self.subsample,\n+        config = {\n+            'filters': self.filters,\n+            'kernel_size': self.kernel_size,\n+            'strides': self.strides,\n+            'padding': self.padding,\n             'data_format': self.data_format,\n-                  'W_regularizer': self.W_regularizer.get_config() if self.W_regularizer else None,\n-                  'b_regularizer': self.b_regularizer.get_config() if self.b_regularizer else None,\n-                  'activity_regularizer': self.activity_regularizer.get_config() if self.activity_regularizer else None,\n-                  'W_constraint': self.W_constraint.get_config() if self.W_constraint else None,\n-                  'b_constraint': self.b_constraint.get_config() if self.b_constraint else None,\n-                  'bias': self.bias}\n+            'activation': activations.serialize(self.activation),\n+            'use_bias': self.use_bias,\n+            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n+            'bias_initializer': initializers.serialize(self.kernel_initializer),\n+            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n+            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n+            'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n+            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n+            'bias_constraint': constraints.serialize(self.bias_constraint)\n+        }\n         base_config = super(LocallyConnected2D, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n\n@@ -15,7 +15,7 @@ class GaussianNoise(Layer):\n     As it is a regularization layer, it is only active at training time.\n \n     # Arguments\n-        sigma: float, standard deviation of the noise distribution.\n+        stddev: float, standard deviation of the noise distribution.\n \n     # Input shape\n         Arbitrary. Use the keyword argument `input_shape`\n@@ -26,20 +26,20 @@ class GaussianNoise(Layer):\n         Same shape as input.\n     \"\"\"\n \n-    def __init__(self, sigma, **kwargs):\n-        self.supports_masking = True\n-        self.sigma = sigma\n-        self.uses_learning_phase = True\n+    def __init__(self, stddev, **kwargs):\n         super(GaussianNoise, self).__init__(**kwargs)\n+        self.supports_masking = True\n+        self.stddev = stddev\n \n-    def call(self, x, mask=None):\n-        noise_x = x + K.random_normal(shape=K.shape(x),\n+    def call(self, x, training=None):\n+        def noised(x):\n+            return x + K.random_normal(shape=K.shape(x),\n                                        mean=0.,\n-                                      std=self.sigma)\n-        return K.in_train_phase(noise_x, x)\n+                                       stddev=self.stddev)\n+        return K.in_train_phase(noised, x, training=training)\n \n     def get_config(self):\n-        config = {'sigma': self.sigma}\n+        config = {'stddev': self.stddev}\n         base_config = super(GaussianNoise, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n \n@@ -50,9 +50,9 @@ class GaussianDropout(Layer):\n     As it is a regularization layer, it is only active at training time.\n \n     # Arguments\n-        p: float, drop probability (as with `Dropout`).\n+        rate: float, drop probability (as with `Dropout`).\n             The multiplicative noise will have\n-            standard deviation `sqrt(p / (1 - p))`.\n+            standard deviation `sqrt(rate / (1 - rate))`.\n \n     # Input shape\n         Arbitrary. Use the keyword argument `input_shape`\n@@ -66,21 +66,20 @@ class GaussianDropout(Layer):\n         - [Dropout: A Simple Way to Prevent Neural Networks from Overfitting Srivastava, Hinton, et al. 2014](http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf)\n     \"\"\"\n \n-    def __init__(self, p, **kwargs):\n-        self.supports_masking = True\n-        self.p = p\n-        if 0 < p < 1:\n-            self.uses_learning_phase = True\n+    def __init__(self, rate, **kwargs):\n         super(GaussianDropout, self).__init__(**kwargs)\n+        self.supports_masking = True\n+        self.rate = rate\n \n-    def call(self, x, mask=None):\n-        if 0 < self.p < 1:\n-            noise_x = x * K.random_normal(shape=K.shape(x), mean=1.0,\n-                                          std=np.sqrt(self.p / (1.0 - self.p)))\n-            return K.in_train_phase(noise_x, x)\n+    def call(self, x, training=None):\n+        if 0 < self.rate < 1:\n+            def noised(x):\n+                return x + K.random_normal(shape=K.shape(x), mean=1.0,\n+                                           stddev=np.sqrt(self.rate / (1.0 - self.rate)))\n+            return K.in_train_phase(noised, x, training=training)\n         return x\n \n     def get_config(self):\n-        config = {'p': self.p}\n+        config = {'rate': self.rate}\n         base_config = super(GaussianDropout, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
