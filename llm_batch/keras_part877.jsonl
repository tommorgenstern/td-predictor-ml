{"custom_id": "keras#8e6cdf2ade8cf06b424ca0ec40177354c5a4b7cf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 26 | Files Changed: 1 | Hunks: 11 | Methods Changed: 7 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 37 | Churn Cumulative: 1300 | Contributors (this commit): 14 | Commits (past 90d): 12 | Contributors (cumulative): 14 | DMM Complexity: 0.0\n\nDIFF:\n@@ -24,9 +24,7 @@ class NumPyTestRot90(testing.TestCase):\n         array = np.array([[1, 2], [3, 4]])\n         rotated = knp.rot90(array)\n         expected = np.array([[2, 4], [1, 3]])\n-        assert np.array_equal(rotated, expected), (\n-            f\"Failed basic 2D test: {rotated}\"\n-        )\n+        self.assertAllClose(rotated, expected)\n \n     def test_multiple_k(self):\n         array = np.array([[1, 2], [3, 4]])\n@@ -34,60 +32,47 @@ class NumPyTestRot90(testing.TestCase):\n         # k=2 (180 degrees rotation)\n         rotated = knp.rot90(array, k=2)\n         expected = np.array([[4, 3], [2, 1]])\n-        assert np.array_equal(rotated, expected), f\"Failed k=2 test: {rotated}\"\n+        self.assertAllClose(rotated, expected)\n \n         # k=3 (270 degrees rotation)\n         rotated = knp.rot90(array, k=3)\n         expected = np.array([[3, 1], [4, 2]])\n-        assert np.array_equal(rotated, expected), f\"Failed k=3 test: {rotated}\"\n+        self.assertAllClose(rotated, expected)\n \n         # k=4 (full rotation)\n         rotated = knp.rot90(array, k=4)\n         expected = array\n-        assert np.array_equal(rotated, expected), f\"Failed k=4 test: {rotated}\"\n+        self.assertAllClose(rotated, expected)\n \n     def test_axes(self):\n         array = np.arange(8).reshape((2, 2, 2))\n         rotated = knp.rot90(array, k=1, axes=(1, 2))\n         expected = np.array([[[1, 3], [0, 2]], [[5, 7], [4, 6]]])\n-        assert np.array_equal(rotated, expected), (\n-            f\"Failed custom axes test: {rotated}\"\n-        )\n+        self.assertAllClose(rotated, expected)\n \n     def test_single_image(self):\n         array = np.random.random((4, 4, 3))\n         rotated = knp.rot90(array, k=1, axes=(0, 1))\n         expected = np.rot90(array, k=1, axes=(0, 1))\n-        assert np.allclose(rotated, expected), \"Failed single image test\"\n+        self.assertAllClose(rotated, expected)\n \n     def test_batch_images(self):\n         array = np.random.random((2, 4, 4, 3))\n         rotated = knp.rot90(array, k=1, axes=(1, 2))\n         expected = np.rot90(array, k=1, axes=(1, 2))\n-        assert np.allclose(rotated, expected), \"Failed batch images test\"\n+        self.assertAllClose(rotated, expected)\n \n     def test_invalid_axes(self):\n         array = np.array([[1, 2], [3, 4]])\n-        try:\n+        with self.assertRaisesRegex(ValueError, \"Invalid axes\"):\n             knp.rot90(array, axes=(0, 0))\n-        except ValueError as e:\n-            assert (\n-                \"Invalid axes: (0, 0). Axes must be a tuple of two different\"\n-                in str(e)\n-            ), f\"Failed invalid axes test: {e}\"\n-        else:\n-            raise AssertionError(\"Failed to raise error for invalid axes\")\n \n     def test_invalid_rank(self):\n         array = np.array([1, 2, 3])  # 1D array\n-        try:\n+        with self.assertRaisesRegex(\n+            ValueError, \"Input array must have at least 2 dimensions\"\n+        ):\n             knp.rot90(array)\n-        except ValueError as e:\n-            assert \"Input array must have at least 2 dimensions.\" in str(e), (\n-                f\"Failed invalid rank test: {e}\"\n-            )\n-        else:\n-            raise AssertionError(\"Failed to raise error for invalid input\")\n \n \n class NumpyTwoInputOpsDynamicShapeTest(testing.TestCase):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e0108291a2c7a91271cb774bb130a4b8c576fb20", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 0 | Files Changed: 4 | Hunks: 4 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 870 | Contributors (this commit): 13 | Commits (past 90d): 42 | Contributors (cumulative): 36 | DMM Complexity: None\n\nDIFF:\n@@ -225,6 +225,7 @@ from keras.src.ops.numpy import repeat\n from keras.src.ops.numpy import reshape\n from keras.src.ops.numpy import right_shift\n from keras.src.ops.numpy import roll\n+from keras.src.ops.numpy import rot90\n from keras.src.ops.numpy import round\n from keras.src.ops.numpy import searchsorted\n from keras.src.ops.numpy import select\n\n@@ -125,6 +125,7 @@ from keras.src.ops.numpy import repeat\n from keras.src.ops.numpy import reshape\n from keras.src.ops.numpy import right_shift\n from keras.src.ops.numpy import roll\n+from keras.src.ops.numpy import rot90\n from keras.src.ops.numpy import round\n from keras.src.ops.numpy import select\n from keras.src.ops.numpy import sign\n\n@@ -225,6 +225,7 @@ from keras.src.ops.numpy import repeat\n from keras.src.ops.numpy import reshape\n from keras.src.ops.numpy import right_shift\n from keras.src.ops.numpy import roll\n+from keras.src.ops.numpy import rot90\n from keras.src.ops.numpy import round\n from keras.src.ops.numpy import searchsorted\n from keras.src.ops.numpy import select\n\n@@ -125,6 +125,7 @@ from keras.src.ops.numpy import repeat\n from keras.src.ops.numpy import reshape\n from keras.src.ops.numpy import right_shift\n from keras.src.ops.numpy import roll\n+from keras.src.ops.numpy import rot90\n from keras.src.ops.numpy import round\n from keras.src.ops.numpy import select\n from keras.src.ops.numpy import sign\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7d4b7bb4e2d95bba58e31a07458d5bd85cc13bf5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 6 | Churn Cumulative: 70 | Contributors (this commit): 5 | Commits (past 90d): 5 | Contributors (cumulative): 5 | DMM Complexity: 0.0\n\nDIFF:\n@@ -324,11 +324,13 @@ class TestJaxLayer(testing.TestCase):\n         model2.export(path, format=\"tf_saved_model\")\n         model4 = tf.saved_model.load(path)\n         output4 = model4.serve(x_test)\n+        # The output difference is greater when using the GPU or bfloat16\n+        lower_precision = testing.jax_uses_gpu() or \"dtype\" in layer_init_kwargs\n         self.assertAllClose(\n             output1,\n             output4,\n-            # The output difference might be significant when using the GPU\n-            atol=1e-2 if testing.jax_uses_gpu() else 1e-6,\n+            atol=1e-2 if lower_precision else 1e-6,\n+            rtol=1e-3 if lower_precision else 1e-6,\n         )\n \n         # test subclass model building without a build method\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bb340d6780fdd6e115f2f4f78d8dbe374971c930", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 3 | Churn Cumulative: 47 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 3 | DMM Complexity: 0.0\n\nDIFF:\n@@ -783,7 +783,8 @@ def _retrieve_class_or_fn(\n \n         # Otherwise, attempt to retrieve the class object given the `module`\n         # and `class_name`. Import the module, find the class.\n-        if module == \"keras.src\" or module.startswith(\"keras.src.\"):\n+        package = module.split(\".\", maxsplit=1)[0]\n+        if package in {\"keras\", \"keras_hub\", \"keras_cv\", \"keras_nlp\"}:\n             try:\n                 mod = importlib.import_module(module)\n                 obj = vars(mod).get(name, None)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f70fd8a98eacb6e2ec705abcac363d996b05e63d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 144 | Lines Deleted: 22 | Files Changed: 16 | Hunks: 51 | Methods Changed: 30 | Complexity Δ (Sum/Max): 19/4 | Churn Δ: 166 | Churn Cumulative: 3587 | Contributors (this commit): 19 | Commits (past 90d): 50 | Contributors (cumulative): 91 | DMM Complexity: 0.7407407407407407\n\nDIFF:\n@@ -32,6 +32,7 @@ class KerasTensor:\n         shape,\n         dtype=\"float32\",\n         sparse=False,\n+        ragged=False,\n         record_history=True,\n         name=None,\n     ):\n@@ -40,6 +41,12 @@ class KerasTensor:\n         self._shape = backend.standardize_shape(shape)\n         self._dtype = backend.standardize_dtype(dtype)\n         self._sparse = bool(sparse)\n+        self._ragged = bool(ragged)\n+        if self._sparse and self._ragged:\n+            raise ValueError(\n+                \"KerasTensor cannot have `sparse=True` and `ragged=True` at \"\n+                \"the same time.\"\n+            )\n         self.name = name or auto_name(self.__class__.__name__)\n         self.record_history = record_history\n \n@@ -50,7 +57,7 @@ class KerasTensor:\n     @shape.setter\n     def shape(self, value):\n         raise AttributeError(\n-            f\"The shape of {self.__class__.__name__} is immutable. One should \"\n+            \"The `shape` attribute of KerasTensor is immutable. One should \"\n             \"create a new instance of KerasTensor for this.\"\n         )\n \n@@ -61,7 +68,7 @@ class KerasTensor:\n     @dtype.setter\n     def dtype(self, value):\n         raise AttributeError(\n-            f\"The dtype of {self.__class__.__name__} is immutable. One should \"\n+            \"The `dtype` attribute of KerasTensor is immutable. One should \"\n             \"create a new instance of KerasTensor for this.\"\n         )\n \n@@ -72,7 +79,18 @@ class KerasTensor:\n     @sparse.setter\n     def sparse(self, value):\n         raise AttributeError(\n-            f\"The sparse of {self.__class__.__name__} is immutable. One should \"\n+            \"The `sparse` attribute of KerasTensor is immutable. One should \"\n+            \"create a new instance of KerasTensor for this.\"\n+        )\n+\n+    @property\n+    def ragged(self):\n+        return self._ragged\n+\n+    @ragged.setter\n+    def ragged(self, value):\n+        raise AttributeError(\n+            \"The `ragged` attribute of KerasTensor is immutable. One should \"\n             \"create a new instance of KerasTensor for this.\"\n         )\n \n@@ -160,7 +178,7 @@ class KerasTensor:\n     def __repr__(self):\n         return (\n             f\"<KerasTensor shape={self.shape}, dtype={self.dtype}, \"\n-            f\"sparse={self.sparse}, name={self.name}>\"\n+            f\"sparse={self.sparse}, ragged={self.ragged}, name={self.name}>\"\n         )\n \n     def __iter__(self):\n\n@@ -19,18 +19,42 @@ class KerasTensorTest(testing.TestCase):\n \n         # Raise error if trying to set attributes\n         with self.assertRaisesRegex(\n-            AttributeError, \"The shape of KerasTensor is immutable.\"\n+            AttributeError, \"The `shape` attribute of KerasTensor is immutable.\"\n         ):\n             x.shape = [3, 2]\n         with self.assertRaisesRegex(\n-            AttributeError, \"The dtype of KerasTensor is immutable.\"\n+            AttributeError, \"The `dtype` attribute of KerasTensor is immutable.\"\n         ):\n             x.dtype = \"int32\"\n+\n+    def test_attributes_sparse(self):\n+        x = keras_tensor.KerasTensor(shape=(3,), dtype=\"float32\", sparse=True)\n+        self.assertEqual(x.sparse, True)\n+\n+        # Raise error if trying to set attributes\n         with self.assertRaisesRegex(\n-            AttributeError, \"The sparse of KerasTensor is immutable.\"\n+            AttributeError,\n+            \"The `sparse` attribute of KerasTensor is immutable.\",\n         ):\n             x.sparse = False\n \n+    def test_attributes_ragged(self):\n+        x = keras_tensor.KerasTensor(shape=(3,), dtype=\"float32\", ragged=True)\n+        self.assertEqual(x.ragged, True)\n+\n+        # Raise error if trying to set attributes\n+        with self.assertRaisesRegex(\n+            AttributeError,\n+            \"The `ragged` attribute of KerasTensor is immutable.\",\n+        ):\n+            x.ragged = False\n+\n+    def test_init_sparse_ragged_raises(self):\n+        with self.assertRaisesRegex(\n+            ValueError, \"cannot have `sparse=True` and `ragged=True`\"\n+        ):\n+            keras_tensor.KerasTensor(shape=(3,), sparse=True, ragged=True)\n+\n     def test_numpy_methods(self):\n         x = keras_tensor.KerasTensor(shape=(3, 2), dtype=\"float32\")\n \n\n@@ -8,6 +8,7 @@ from keras.src.backend.jax import numpy\n from keras.src.backend.jax import random\n from keras.src.backend.jax import tensorboard\n from keras.src.backend.jax.core import IS_THREAD_SAFE\n+from keras.src.backend.jax.core import SUPPORTS_RAGGED_TENSORS\n from keras.src.backend.jax.core import SUPPORTS_SPARSE_TENSORS\n from keras.src.backend.jax.core import Variable\n from keras.src.backend.jax.core import cast\n\n@@ -15,6 +15,7 @@ from keras.src.backend.common.symbolic_scope import SymbolicScope\n from keras.src.backend.jax import distribution_lib\n \n SUPPORTS_SPARSE_TENSORS = True\n+SUPPORTS_RAGGED_TENSORS = False\n IS_THREAD_SAFE = True\n \n \n@@ -46,7 +47,9 @@ class Variable(KerasVariable):\n         return self.value\n \n \n-def convert_to_tensor(x, dtype=None, sparse=True):\n+def convert_to_tensor(x, dtype=None, sparse=None, ragged=None):\n+    if ragged:\n+        raise ValueError(\"`ragged=True` is not supported with jax backend\")\n     if dtype is not None:\n         dtype = standardize_dtype(dtype)\n     if isinstance(x, (jnp.ndarray, jax.Array)) and (\n\n@@ -7,6 +7,7 @@ from keras.src.backend.numpy import nn\n from keras.src.backend.numpy import numpy\n from keras.src.backend.numpy import random\n from keras.src.backend.numpy.core import IS_THREAD_SAFE\n+from keras.src.backend.numpy.core import SUPPORTS_RAGGED_TENSORS\n from keras.src.backend.numpy.core import SUPPORTS_SPARSE_TENSORS\n from keras.src.backend.numpy.core import Variable\n from keras.src.backend.numpy.core import cast\n\n@@ -15,6 +15,7 @@ from keras.src.backend.common.stateless_scope import StatelessScope\n from keras.src.backend.common.symbolic_scope import SymbolicScope\n \n SUPPORTS_SPARSE_TENSORS = False\n+SUPPORTS_RAGGED_TENSORS = False\n IS_THREAD_SAFE = True\n \n \n@@ -33,9 +34,11 @@ class Variable(KerasVariable):\n         return self.value\n \n \n-def convert_to_tensor(x, dtype=None, sparse=None):\n+def convert_to_tensor(x, dtype=None, sparse=None, ragged=None):\n     if sparse:\n         raise ValueError(\"`sparse=True` is not supported with numpy backend\")\n+    if ragged:\n+        raise ValueError(\"`ragged=True` is not supported with numpy backend\")\n     if dtype is not None:\n         dtype = standardize_dtype(dtype)\n     if isinstance(x, Variable):\n\n@@ -7,6 +7,7 @@ from keras.src.backend.openvino import nn\n from keras.src.backend.openvino import numpy\n from keras.src.backend.openvino import random\n from keras.src.backend.openvino.core import IS_THREAD_SAFE\n+from keras.src.backend.openvino.core import SUPPORTS_RAGGED_TENSORS\n from keras.src.backend.openvino.core import SUPPORTS_SPARSE_TENSORS\n from keras.src.backend.openvino.core import Variable\n from keras.src.backend.openvino.core import cast\n\n@@ -19,6 +19,7 @@ from keras.src.backend.common.keras_tensor import KerasTensor\n from keras.src.backend.common.stateless_scope import StatelessScope\n \n SUPPORTS_SPARSE_TENSORS = False\n+SUPPORTS_RAGGED_TENSORS = False\n IS_THREAD_SAFE = True\n \n OPENVINO_DTYPES = {\n@@ -367,9 +368,11 @@ def _get_first_element(x):\n     return None\n \n \n-def convert_to_tensor(x, dtype=None, sparse=None):\n+def convert_to_tensor(x, dtype=None, sparse=None, ragged=None):\n     if sparse:\n         raise ValueError(\"`sparse=True` is not supported with openvino backend\")\n+    if ragged:\n+        raise ValueError(\"`ragged=True` is not supported with openvino backend\")\n     if isinstance(x, OpenVINOKerasTensor):\n         return x\n     elif isinstance(x, np.ndarray):\n\n@@ -8,6 +8,7 @@ from keras.src.backend.tensorflow import numpy\n from keras.src.backend.tensorflow import random\n from keras.src.backend.tensorflow import tensorboard\n from keras.src.backend.tensorflow.core import IS_THREAD_SAFE\n+from keras.src.backend.tensorflow.core import SUPPORTS_RAGGED_TENSORS\n from keras.src.backend.tensorflow.core import SUPPORTS_SPARSE_TENSORS\n from keras.src.backend.tensorflow.core import Variable\n from keras.src.backend.tensorflow.core import cast\n\n@@ -19,6 +19,7 @@ from keras.src.backend.tensorflow.sparse import sparse_to_dense\n from keras.src.utils.naming import auto_name\n \n SUPPORTS_SPARSE_TENSORS = True\n+SUPPORTS_RAGGED_TENSORS = True\n # https://github.com/tensorflow/tensorflow/issues/78338\n IS_THREAD_SAFE = False\n \n@@ -122,9 +123,11 @@ class Variable(\n         return mapping[aggregation]\n \n \n-def convert_to_tensor(x, dtype=None, sparse=None):\n+def convert_to_tensor(x, dtype=None, sparse=None, ragged=None):\n     if isinstance(x, tf.SparseTensor) and sparse is not None and not sparse:\n         x = sparse_to_dense(x)\n+    if isinstance(x, tf.RaggedTensor) and ragged is not None and not ragged:\n+        x = x.to_tensor()\n     if dtype is not None:\n         dtype = standardize_dtype(dtype)\n     if not tf.is_tensor(x):\n\n@@ -23,6 +23,7 @@ from keras.src.backend.torch import nn\n from keras.src.backend.torch import numpy\n from keras.src.backend.torch import random\n from keras.src.backend.torch.core import IS_THREAD_SAFE\n+from keras.src.backend.torch.core import SUPPORTS_RAGGED_TENSORS\n from keras.src.backend.torch.core import SUPPORTS_SPARSE_TENSORS\n from keras.src.backend.torch.core import Variable\n from keras.src.backend.torch.core import cast\n\n@@ -20,6 +20,7 @@ from keras.src.backend.common.symbolic_scope import SymbolicScope\n from keras.src.backend.config import floatx\n \n SUPPORTS_SPARSE_TENSORS = False\n+SUPPORTS_RAGGED_TENSORS = False\n IS_THREAD_SAFE = True\n \n # Some operators such as 'aten::_foreach_mul_.Scalar'\n@@ -185,9 +186,11 @@ class Variable(KerasVariable):\n             return False\n \n \n-def convert_to_tensor(x, dtype=None, sparse=None):\n+def convert_to_tensor(x, dtype=None, sparse=None, ragged=None):\n     if sparse:\n         raise ValueError(\"`sparse=True` is not supported with torch backend\")\n+    if ragged:\n+        raise ValueError(\"`ragged=True` is not supported with torch backend\")\n     if isinstance(x, Variable):\n         # TorchDynamo has bugs supporting nn.Parameter type check.\n         # Return it directly instead of pass it to the rest of the logic in the\n\n@@ -14,13 +14,13 @@ class InputLayer(Layer):\n         batch_size=None,\n         dtype=None,\n         sparse=None,\n+        ragged=None,\n         batch_shape=None,\n         input_tensor=None,\n         optional=False,\n         name=None,\n         **kwargs,\n     ):\n-        # TODO: support for ragged.\n         super().__init__(name=name)\n \n         if \"input_shape\" in kwargs:\n@@ -97,12 +97,23 @@ class InputLayer(Layer):\n         self.sparse = bool(sparse)\n         if self.sparse and not backend.SUPPORTS_SPARSE_TENSORS:\n             raise ValueError(\n-                \"`sparse=True` is not supported with backend: \"\n-                f\"{backend.backend()}\"\n+                f\"`sparse=True` is not supported with the {backend.backend()} \"\n+                \"backend\"\n             )\n+        self.ragged = bool(ragged)\n+        if self.ragged and not backend.SUPPORTS_RAGGED_TENSORS:\n+            raise ValueError(\n+                f\"`ragged=True` is not supported with the {backend.backend()} \"\n+                \"backend\"\n+            )\n+\n         if input_tensor is None:\n             input_tensor = backend.KerasTensor(\n-                shape=batch_shape, dtype=dtype, sparse=sparse, name=name\n+                shape=batch_shape,\n+                dtype=dtype,\n+                sparse=sparse,\n+                ragged=ragged,\n+                name=name,\n             )\n         self._input_tensor = input_tensor\n         Node(operation=self, call_args=(), call_kwargs={}, outputs=input_tensor)\n@@ -125,6 +136,7 @@ class InputLayer(Layer):\n             \"batch_shape\": self.batch_shape,\n             \"dtype\": self.dtype,\n             \"sparse\": self.sparse,\n+            \"ragged\": self.ragged,\n             \"name\": self.name,\n         }\n \n@@ -135,6 +147,7 @@ def Input(\n     batch_size=None,\n     dtype=None,\n     sparse=None,\n+    ragged=None,\n     batch_shape=None,\n     name=None,\n     tensor=None,\n@@ -163,6 +176,11 @@ def Input(\n         sparse: A boolean specifying whether the expected input will be sparse\n             tensors. Note that, if `sparse` is `False`, sparse tensors can still\n             be passed into the input - they will be densified with a default\n+            value of 0. This feature is only supported with the TensorFlow and\n+            the JAX backends. Defaults to `False`.\n+        ragged: A boolean specifying whether the expected input will be ragged\n+            tensors. Note that, if `ragged` is `False`, ragged tensors can still\n+            be passed into the input - they will be densified with a default\n             value of 0. This feature is only supported with the TensorFlow\n             backend. Defaults to `False`.\n         batch_shape: Optional shape tuple (tuple of integers or `None` objects),\n@@ -193,6 +211,7 @@ def Input(\n         batch_size=batch_size,\n         dtype=dtype,\n         sparse=sparse,\n+        ragged=ragged,\n         batch_shape=batch_shape,\n         name=name,\n         input_tensor=tensor,\n\n@@ -11,11 +11,12 @@ class InputLayerTest(testing.TestCase):\n     # Testing happy path for layer without input tensor\n     @parameterized.named_parameters(\n         [\n-            {\"testcase_name\": \"dense\", \"sparse\": False},\n+            {\"testcase_name\": \"dense\"},\n             {\"testcase_name\": \"sparse\", \"sparse\": True},\n+            {\"testcase_name\": \"ragged\", \"ragged\": True},\n         ]\n     )\n-    def test_input_basic(self, sparse):\n+    def test_input_basic(self, sparse=False, ragged=False):\n         input_shape = (2, 3)\n         batch_size = 4\n         dtype = \"float32\"\n@@ -26,6 +27,7 @@ class InputLayerTest(testing.TestCase):\n             \"batch_size\": batch_size,\n             \"dtype\": dtype,\n             \"sparse\": sparse,\n+            \"ragged\": ragged,\n         }\n \n         if sparse and not backend.SUPPORTS_SPARSE_TENSORS:\n@@ -34,6 +36,12 @@ class InputLayerTest(testing.TestCase):\n             ):\n                 InputLayer(**init_kwargs)\n             return\n+        if ragged and not backend.SUPPORTS_RAGGED_TENSORS:\n+            with self.assertRaisesRegex(\n+                ValueError, \"`ragged=True` is not supported\"\n+            ):\n+                InputLayer(**init_kwargs)\n+            return\n \n         values = InputLayer(**init_kwargs)\n \n@@ -41,11 +49,13 @@ class InputLayerTest(testing.TestCase):\n         self.assertEqual(values.batch_shape[0], batch_size)\n         self.assertEqual(values.batch_shape[1:], input_shape)\n         self.assertEqual(values.sparse, sparse)\n+        self.assertEqual(values.ragged, ragged)\n         self.assertEqual(values.trainable, True)\n         self.assertIsInstance(values.output, KerasTensor)\n         self.assertEqual(values.output.ndim, ndim)\n         self.assertEqual(values.output.dtype, dtype)\n         self.assertEqual(values.output.sparse, sparse)\n+        self.assertEqual(values.output.ragged, ragged)\n \n     # Testing shape is not None and batch_shape is not None condition\n     def test_input_error1(self):\n\n@@ -929,8 +929,11 @@ class ConvertToTensor(Operation):\n \n \n @keras_export(\"keras.ops.convert_to_tensor\")\n-def convert_to_tensor(x, dtype=None, sparse=None):\n-    \"\"\"Convert a NumPy array to a tensor.\n+def convert_to_tensor(x, dtype=None, sparse=None, ragged=None):\n+    \"\"\"Convert a NumPy array or Python array to a tensor.\n+\n+    Native tensors for the current backend or left unchanged unless the `dtype`,\n+    `sparse` or `ragged` arguments are set.\n \n     Args:\n         x: A NumPy array, Python array (can be nested) or a backend tensor.\n@@ -938,6 +941,9 @@ def convert_to_tensor(x, dtype=None, sparse=None):\n         sparse: Whether to keep sparse tensors. `False` will cause sparse\n             tensors to be densified. The default value of `None` means that\n             sparse tensors are kept only if the backend supports them.\n+        ragged: Whether to keep ragged tensors. `False` will cause ragged\n+            tensors to be densified. The default value of `None` means that\n+            ragged tensors are kept only if the backend supports them.\n \n     Returns:\n         A backend tensor of the specified `dtype` and sparseness.\n@@ -949,7 +955,9 @@ def convert_to_tensor(x, dtype=None, sparse=None):\n     \"\"\"\n     if any_symbolic_tensors((x,)):\n         return ConvertToTensor(dtype=dtype, sparse=sparse)(x)\n-    return backend.core.convert_to_tensor(x, dtype=dtype, sparse=sparse)\n+    return backend.core.convert_to_tensor(\n+        x, dtype=dtype, sparse=sparse, ragged=ragged\n+    )\n \n \n @keras_export(\"keras.ops.convert_to_numpy\")\n\n@@ -644,7 +644,7 @@ class CoreOpsCorrectnessTest(testing.TestCase):\n         self.assertAllEqual(core.shape(x), (2, 3))\n \n     @pytest.mark.skipif(\n-        backend.backend() != \"tensorflow\",\n+        not backend.SUPPORTS_SPARSE_TENSORS,\n         reason=\"Backend does not support ragged tensors.\",\n     )\n     def test_shape_ragged(self):\n@@ -704,6 +704,29 @@ class CoreOpsCorrectnessTest(testing.TestCase):\n         self.assertIsInstance(x_numpy, np.ndarray)\n         self.assertAllClose(x_numpy, x_dense)\n \n+    @pytest.mark.skipif(\n+        not backend.SUPPORTS_RAGGED_TENSORS,\n+        reason=\"Backend does not support ragged tensors.\",\n+    )\n+    def test_convert_to_tensor_ragged(self):\n+        import tensorflow as tf\n+\n+        x = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])\n+\n+        x_default = ops.convert_to_tensor(x)\n+        self.assertIsInstance(x_default, tf.RaggedTensor)\n+        self.assertAllClose(x, x_default)\n+        x_ragged = ops.convert_to_tensor(x, ragged=True)\n+        self.assertIsInstance(x_ragged, tf.RaggedTensor)\n+        self.assertAllClose(x, x_ragged)\n+        x_dense = ops.convert_to_tensor(x, ragged=False)\n+        self.assertNotIsInstance(x_dense, tf.RaggedTensor)\n+        self.assertAllClose(x, x_dense)\n+\n+        x_numpy = ops.convert_to_numpy(x)\n+        self.assertIsInstance(x_numpy, np.ndarray)\n+        self.assertAllClose(x_numpy, x_dense)\n+\n     def test_cond(self):\n         t = ops.cond(True, lambda: 0, lambda: 1)\n         self.assertEqual(t, 0)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#57c94f305c0b0347ed02b11535623a8b375eee5f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 791 | Contributors (this commit): 6 | Commits (past 90d): 4 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -1073,7 +1073,7 @@ class NpzIOStore:\n                 self.f = archive.open(root_path, mode=\"r\")\n             else:\n                 self.f = open(root_path, mode=\"rb\")\n-            self.contents = np.load(self.f, allow_pickle=True)\n+            self.contents = np.load(self.f)\n \n     def make(self, path, metadata=None):\n         if not path:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e37ee792a342356fc426d33236f6b7e46892dcd0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 23 | Lines Deleted: 25 | Files Changed: 2 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 48 | Churn Cumulative: 484 | Contributors (this commit): 2 | Commits (past 90d): 5 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -550,18 +550,13 @@ class ExportArchive(BackendExportArchive):\n         # Next, track lookup tables.\n         # Hopefully, one day this will be automated at the tf.function level.\n         self._tf_trackable._misc_assets = []\n-        from keras.src.layers import IntegerLookup\n-        from keras.src.layers import StringLookup\n-        from keras.src.layers import TextVectorization\n+        from tensorflow.saved_model.experimental import TrackableResource\n \n         if hasattr(self, \"_tracked\"):\n             for root in self._tracked:\n                 descendants = tf.train.TrackableView(root).descendants()\n                 for trackable in descendants:\n-                    if isinstance(\n-                        trackable,\n-                        (IntegerLookup, StringLookup, TextVectorization),\n-                    ):\n+                    if isinstance(trackable, TrackableResource):\n                         self._tf_trackable._misc_assets.append(trackable)\n \n \n\n@@ -782,25 +782,28 @@ class ExportArchiveTest(testing.TestCase):\n             }\n         )\n \n-    # def test_model_with_lookup_table(self):\n-    #     tf.debugging.disable_traceback_filtering()\n-    #     temp_filepath = os.path.join(self.get_temp_dir(), \"exported_model\")\n-    #     text_vectorization = layers.TextVectorization()\n-    #     text_vectorization.adapt([\"one two\", \"three four\", \"five six\"])\n-    #     model = models.Sequential(\n-    #         [\n-    #             layers.Input(shape=(), dtype=\"string\"),\n-    #             text_vectorization,\n-    #             layers.Embedding(10, 32),\n-    #             layers.Dense(1),\n-    #         ]\n-    #     )\n-    #     ref_input = tf.convert_to_tensor([\"one two three four\"])\n-    #     ref_output = model(ref_input)\n+    @pytest.mark.skipif(\n+        backend.backend() != \"tensorflow\",\n+        reason=\"String lookup requires TensorFlow backend\",\n+    )\n+    def test_model_with_lookup_table(self):\n+        temp_filepath = os.path.join(self.get_temp_dir(), \"exported_model\")\n+        text_vectorization = layers.TextVectorization()\n+        text_vectorization.adapt([\"one two\", \"three four\", \"five six\"])\n+        model = models.Sequential(\n+            [\n+                layers.Input(shape=(), dtype=\"string\"),\n+                text_vectorization,\n+                layers.Embedding(10, 32),\n+                layers.Dense(1),\n+            ]\n+        )\n+        ref_input = tf.convert_to_tensor([\"one two three four\"])\n+        ref_output = model(ref_input)\n \n-    #     saved_model.export_saved_model(model, temp_filepath)\n-    #     revived_model = tf.saved_model.load(temp_filepath)\n-    #     self.assertAllClose(ref_output, revived_model.serve(ref_input))\n+        saved_model.export_saved_model(model, temp_filepath)\n+        revived_model = tf.saved_model.load(temp_filepath)\n+        self.assertAllClose(ref_output, revived_model.serve(ref_input))\n \n     def test_track_multiple_layers(self):\n         temp_filepath = os.path.join(self.get_temp_dir(), \"exported_model\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#617b8219abf1c00cf469325f5a52b91b6d6a0953", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 242 | Lines Deleted: 0 | Files Changed: 4 | Hunks: 4 | Methods Changed: 16 | Complexity Δ (Sum/Max): 37/30 | Churn Δ: 242 | Churn Cumulative: 780 | Contributors (this commit): 13 | Commits (past 90d): 36 | Contributors (cumulative): 28 | DMM Complexity: 0.8632478632478633\n\nDIFF:\n@@ -30,6 +30,7 @@ from keras.src.ops.core import switch\n from keras.src.ops.core import unstack\n from keras.src.ops.core import vectorized_map\n from keras.src.ops.core import while_loop\n+from keras.src.ops.einops import rearrange\n from keras.src.ops.linalg import cholesky\n from keras.src.ops.linalg import det\n from keras.src.ops.linalg import eig\n\n@@ -30,6 +30,7 @@ from keras.src.ops.core import switch\n from keras.src.ops.core import unstack\n from keras.src.ops.core import vectorized_map\n from keras.src.ops.core import while_loop\n+from keras.src.ops.einops import rearrange\n from keras.src.ops.linalg import cholesky\n from keras.src.ops.linalg import det\n from keras.src.ops.linalg import eig\n\n@@ -0,0 +1,189 @@\n+import re\n+\n+from keras.src.api_export import keras_export\n+from keras.src.backend import KerasTensor\n+from keras.src.backend import any_symbolic_tensors\n+from keras.src.ops.core import shape\n+from keras.src.ops.numpy import prod\n+from keras.src.ops.numpy import reshape\n+from keras.src.ops.numpy import transpose\n+from keras.src.ops.operation import Operation\n+\n+\n+def _create_axes_map(axes, input_shape, axes_lengths):\n+    axes_map = {}\n+\n+    for axis, dim in zip(axes, input_shape):\n+        # Check for grouped axes pattern, e.g., \"(h1 h)\"\n+        grouped_axes = re.match(r\"\\(([\\w\\s]+)\\)\", axis)\n+\n+        if grouped_axes:\n+            inner_axes = grouped_axes.group(1).split()\n+            known_axes = [a for a in inner_axes if a in axes_lengths]\n+            inferred_axes = [a for a in inner_axes if a not in axes_lengths]\n+\n+            if inferred_axes:\n+                inferred_axis = inferred_axes[0]\n+                known_product = prod([axes_lengths[a] for a in known_axes])\n+                axes_lengths[inferred_axis] = dim // known_product\n+\n+            axes_map.update({a: axes_lengths[a] for a in inner_axes})\n+        else:\n+            axes_map[axis] = dim\n+\n+    return axes_map\n+\n+\n+def _create_grouped_axes(axes):\n+    grouped_output_axes = []\n+    for axis in axes:\n+        grouped_axes = re.match(r\"\\(([\\w\\s]+)\\)\", axis)\n+\n+        if grouped_axes:\n+            inner_axes = grouped_axes.group(1).split()\n+            grouped_output_axes.append(inner_axes)\n+        else:\n+            grouped_output_axes.append([axis])\n+\n+    return grouped_output_axes\n+\n+\n+def _flatten_group(axes):\n+    return [x for xs in axes for x in xs]\n+\n+\n+def _get_transpose_order(from_shape, to_shape):\n+    flattened_from_shape = _flatten_group(_create_grouped_axes(from_shape))\n+\n+    return [flattened_from_shape.index(dim) for dim in to_shape]\n+\n+\n+def _compute_output_shape(axes_map, grouped_axes):\n+    output_shape = []\n+    for group in grouped_axes:\n+        size = 1\n+        for axis in group:\n+            size *= axes_map[axis]\n+        output_shape.append(size)\n+\n+    return tuple(output_shape)\n+\n+\n+def _compute_decomposed_shape(input_axes, axes_lengths, axes_map):\n+    reshaped_input_axes = []\n+    reshaped_sizes = []\n+\n+    for axis in input_axes:\n+        if \"(\" in axis:  # Decomposed axis\n+            inner_axes = re.findall(r\"\\w+\", axis)\n+            sizes = [axes_lengths[a] for a in inner_axes]\n+            reshaped_input_axes.extend(inner_axes)\n+            reshaped_sizes.extend(sizes)\n+        else:\n+            reshaped_input_axes.append(axis)\n+            reshaped_sizes.append(axes_map[axis])\n+\n+    return reshaped_sizes\n+\n+\n+class Rearrange(Operation):\n+    def call(self, tensor, pattern, **axes_lengths):\n+        return rearrange(tensor, pattern, **axes_lengths)\n+\n+    def compute_output_spec(self, tensor, pattern, **axes_lengths):\n+        input_pattern, output_pattern = re.split(r\"\\s*->\\s*\", pattern)\n+        input_axes = re.findall(r\"\\w+|\\(.*?\\)\", input_pattern)\n+        output_axes = re.findall(r\"\\w+|\\(.*?\\)\", output_pattern)\n+        input_shape = shape(tensor)\n+\n+        axes_map = _create_axes_map(input_axes, input_shape, axes_lengths)\n+        grouped_output_axes = _create_grouped_axes(output_axes)\n+        output_shape = _compute_output_shape(axes_map, grouped_output_axes)\n+\n+        return KerasTensor(shape=output_shape, dtype=tensor.dtype)\n+\n+\n+@keras_export(\"keras.ops.rearrange\")\n+def rearrange(tensor, pattern, **axes_lengths):\n+    \"\"\"Rearranges the axes of a Keras tensor according to a specified pattern,\n+    einops-style.\n+\n+    Args:\n+        tensor: Input Keras tensor.\n+        pattern: String describing the rearrangement in einops notation.\n+        **axes_lengths: Keyword arguments specifying lengths of axes\n+            when axes decomposition is used.\n+\n+    Returns:\n+        Tensor: A Keras tensor with rearranged axes.\n+\n+    Follows the logic of:\n+\n+    1. If decomposition is needed, reshape to match decomposed dimensions.\n+    2. Permute known and inferred axes to match the form of the output.\n+    3. Reshape to match the desired output shape.\n+\n+\n+    Example Usage:\n+\n+    ```\n+    >>> import numpy as np\n+    >>> from keras.ops import rearrange\n+    >>> images = np.random.rand(32, 30, 40, 3) # BHWC format\n+\n+    # Reordering to BCHW\n+    >>> rearrange(images, 'b h w c -> b c h w').shape\n+    TensorShape([32, 3, 30, 40])\n+\n+    # \"Merge\" along first axis - concat images from a batch\n+    >>> rearrange(images, 'b h w c -> (b h) w c').shape\n+    TensorShape([960, 40, 3])\n+\n+    # \"Merge\" along second axis - concat images horizontally\n+    >>> rearrange(images, 'b h w c -> h (b w) c').shape\n+    TensorShape([30, 1280, 3])\n+\n+    # Flatten images into a CHW vector\n+    >>> rearrange(images, 'b h w c -> b (c h w)').shape\n+    TensorShape([32, 3600])\n+\n+    # Decompose H and W axes into 4 smaller patches\n+    >>> rearrange(images, 'b (h1 h) (w1 w) c -> (b h1 w1) h w c', h1=2, w1=2).shape\n+    TensorShape([128, 15, 20, 3])\n+\n+    # Space-to-depth decomposition of input axes\n+    >>> rearrange(images, 'b (h h1) (w w1) c -> b h w (c h1 w1)', h1=2, w1=2).shape\n+    TensorShape([32, 15, 20, 12])\n+    ```\n+    \"\"\"  # noqa: E501\n+\n+    if any_symbolic_tensors((tensor,)):\n+        return Rearrange().symbolic_call(tensor, pattern, **axes_lengths)\n+\n+    # Split the input and output patterns\n+    input_pattern, output_pattern = re.split(r\"\\s*->\\s*\", pattern)\n+    input_axes = re.findall(r\"\\w+|\\(.*?\\)\", input_pattern)\n+    output_axes = re.findall(r\"\\w+|\\(.*?\\)\", output_pattern)\n+    input_shape = shape(tensor)\n+\n+    # Create axes map, and flattened output group\n+    axes_map = _create_axes_map(input_axes, input_shape, axes_lengths)\n+    grouped_output_axes = _create_grouped_axes(output_axes)\n+    flattened_output_axes = _flatten_group(grouped_output_axes)\n+\n+    # 1. Axes decomposition\n+    decomposed_shapes = _compute_decomposed_shape(\n+        input_axes, axes_lengths, axes_map\n+    )\n+    if decomposed_shapes != tensor.shape:\n+        tensor = reshape(tensor, decomposed_shapes)\n+\n+    # 2. Transpose to match target shape\n+    permute_order = _get_transpose_order(input_axes, flattened_output_axes)\n+    tensor = transpose(tensor, permute_order)\n+\n+    # 3. Reshape to final target shape\n+    output_shape = _compute_output_shape(axes_map, grouped_output_axes)\n+    tensor = reshape(tensor, output_shape)\n+\n+    return tensor\n\n@@ -0,0 +1,51 @@\n+from conftest import skip_if_backend\n+from keras.src import ops\n+from keras.src import testing\n+from keras.src.backend.common import keras_tensor\n+from keras.src.ops.einops import rearrange\n+\n+\n+class RearrangeTest(testing.TestCase):\n+    def test_basic_rearrangement_symbolic(self):\n+        x = keras_tensor.KerasTensor((2, 3, 4))\n+        y = rearrange(x, \"b c h -> b h c\")\n+        self.assertIsInstance(y, keras_tensor.KerasTensor)\n+        self.assertEqual(y.shape, (2, 4, 3))\n+\n+    @skip_if_backend(\"openvino\", \"Test operation not supported by openvino\")\n+    def test_basic_rearrangement(self):\n+        x = ops.random.uniform((2, 3, 4))\n+        y = rearrange(x, \"b c h -> b h c\")\n+        self.assertEqual(y.shape, (2, 4, 3))\n+        self.assertTrue(ops.all(ops.equal(y, ops.transpose(x, (0, 2, 1)))))\n+\n+    @skip_if_backend(\"openvino\", \"Test operation not supported by openvino\")\n+    def test_output_composition(self):\n+        x = ops.random.uniform((2, 4, 4, 3))\n+        y = rearrange(x, \"b h w c -> (b h) w c\")\n+        target_shape = (8, 4, 3)\n+        self.assertEqual(y.shape, target_shape)\n+        self.assertTrue(ops.all(ops.equal(y, ops.reshape(x, (8, 4, 3)))))\n+\n+    def test_basic_decomposition_and_rearrangement_symbolic(self):\n+        x = keras_tensor.KerasTensor((6, 8))\n+        y = rearrange(x, \"(h w) c -> h w c\", h=2, w=3)\n+        self.assertIsInstance(y, keras_tensor.KerasTensor)\n+        self.assertEqual(y.shape, (2, 3, 8))\n+\n+    def test_basic_decomposition_and_rearrangement(self):\n+        x = ops.random.uniform((6, 8))\n+        y = rearrange(x, \"(h w) c -> h w c\", h=2, w=3)\n+        self.assertEqual(y.shape, (2, 3, 8))\n+\n+    @skip_if_backend(\"openvino\", \"Test operation not supported by openvino\")\n+    def test_unchanged_shape(self):\n+        x = ops.ones([2, 3, 4])\n+        y = rearrange(x, \"b h c -> b h c\")\n+        self.assertTrue(ops.all(ops.equal(y, x)))\n+        self.assertTrue(x.shape, y.shape)\n+\n+    def test_unchanged_shape_symbolic(self):\n+        x = keras_tensor.KerasTensor((2, 3, 4))\n+        y = rearrange(x, \"b h c -> b h c\")\n+        self.assertTrue(x.shape, y.shape)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e345cbdfba9c656b01ef4e116822ad03ffe9d804", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 24 | Lines Deleted: 27 | Files Changed: 15 | Hunks: 21 | Methods Changed: 22 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 51 | Churn Cumulative: 8924 | Contributors (this commit): 31 | Commits (past 90d): 65 | Contributors (cumulative): 96 | DMM Complexity: 0.0\n\nDIFF:\n@@ -356,7 +356,7 @@ def _vectorize_parse_input_dimensions(\n             f\"expected {len(input_core_dims)}, got {len(args)}\"\n         )\n     shapes = []\n-    dim_sizes: dict[str, int] = {}\n+    dim_sizes = {}\n     for arg, core_dims in zip(args, input_core_dims):\n         _vectorize_update_dim_sizes(\n             dim_sizes, arg.shape, core_dims, is_input=True\n\n@@ -43,7 +43,7 @@ class DtypesTest(test_case.TestCase):\n         self.jax_enable_x64.__enter__()\n         return super().setUp()\n \n-    def tearDown(self) -> None:\n+    def tearDown(self):\n         self.jax_enable_x64.__exit__(None, None, None)\n         return super().tearDown()\n \n\n@@ -820,7 +820,7 @@ class VariableOpsDTypeTest(test_case.TestCase):\n         self.jax_enable_x64.__enter__()\n         return super().setUp()\n \n-    def tearDown(self) -> None:\n+    def tearDown(self):\n         self.jax_enable_x64.__exit__(None, None, None)\n         return super().tearDown()\n \n\n@@ -1,6 +1,3 @@\n-from typing import Iterator\n-from typing import Tuple\n-\n import torch\n \n from keras.src.backend.common.stateless_scope import in_stateless_scope\n@@ -30,10 +27,10 @@ class TorchLayer(torch.nn.Module):\n \n     def named_parameters(\n         self,\n-        prefix: str = \"\",\n-        recurse: bool = True,\n-        remove_duplicate: bool = True,\n-    ) -> Iterator[Tuple[str, torch.nn.Parameter]]:\n+        prefix=\"\",\n+        recurse=True,\n+        remove_duplicate=True,\n+    ):\n         if not hasattr(self, \"_torch_params\"):\n             self._track_variables()\n         return torch.nn.Module.named_parameters(\n\n@@ -22,8 +22,8 @@ class BoundingBox:\n     def convert_format(\n         self,\n         boxes,\n-        source: str,\n-        target: str,\n+        source,\n+        target,\n         height=None,\n         width=None,\n         dtype=\"float32\",\n\n@@ -936,7 +936,7 @@ class CoreOpsDtypeTest(testing.TestCase):\n         self.jax_enable_x64.__enter__()\n         return super().setUp()\n \n-    def tearDown(self) -> None:\n+    def tearDown(self):\n         self.jax_enable_x64.__exit__(None, None, None)\n         return super().tearDown()\n \n\n@@ -20,7 +20,7 @@ class ImageOpsDynamicShapeTest(testing.TestCase):\n         backend.set_image_data_format(\"channels_last\")\n         return super().setUp()\n \n-    def tearDown(self) -> None:\n+    def tearDown(self):\n         backend.set_image_data_format(self.data_format)\n         return super().tearDown()\n \n@@ -171,7 +171,7 @@ class ImageOpsStaticShapeTest(testing.TestCase):\n         backend.set_image_data_format(\"channels_last\")\n         return super().setUp()\n \n-    def tearDown(self) -> None:\n+    def tearDown(self):\n         backend.set_image_data_format(self.data_format)\n         return super().tearDown()\n \n@@ -396,7 +396,7 @@ class ImageOpsCorrectnessTest(testing.TestCase):\n         backend.set_image_data_format(\"channels_last\")\n         return super().setUp()\n \n-    def tearDown(self) -> None:\n+    def tearDown(self):\n         backend.set_image_data_format(self.data_format)\n         return super().tearDown()\n \n@@ -1144,7 +1144,7 @@ class ImageOpsBehaviorTests(testing.TestCase):\n         backend.set_image_data_format(\"channels_last\")\n         return super().setUp()\n \n-    def tearDown(self) -> None:\n+    def tearDown(self):\n         backend.set_image_data_format(self.data_format)\n         return super().tearDown()\n \n\n@@ -1003,7 +1003,7 @@ class MathDtypeTest(testing.TestCase):\n         self.jax_enable_x64.__enter__()\n         return super().setUp()\n \n-    def tearDown(self) -> None:\n+    def tearDown(self):\n         self.jax_enable_x64.__exit__(None, None, None)\n         return super().tearDown()\n \n\n@@ -2474,7 +2474,7 @@ class NNOpsDtypeTest(testing.TestCase):\n         self.jax_enable_x64.__enter__()\n         return super().setUp()\n \n-    def tearDown(self) -> None:\n+    def tearDown(self):\n         self.jax_enable_x64.__exit__(None, None, None)\n         return super().tearDown()\n \n\n@@ -5357,7 +5357,7 @@ class NumpyDtypeTest(testing.TestCase):\n         self.jax_enable_x64.__enter__()\n         return super().setUp()\n \n-    def tearDown(self) -> None:\n+    def tearDown(self):\n         self.jax_enable_x64.__exit__(None, None, None)\n         return super().tearDown()\n \n\n@@ -456,7 +456,7 @@ class RandomDTypeTest(testing.TestCase):\n             self.jax_enable_x64.__enter__()\n         return super().setUp()\n \n-    def tearDown(self) -> None:\n+    def tearDown(self):\n         if backend.backend() == \"jax\":\n             self.jax_enable_x64.__exit__(None, None, None)\n         return super().tearDown()\n\n@@ -253,7 +253,7 @@ class SavingTest(testing.TestCase):\n         saving_lib._MEMORY_UPPER_BOUND = 0\n         return super().setUp()\n \n-    def tearDown(self) -> None:\n+    def tearDown(self):\n         saving_lib._MEMORY_UPPER_BOUND = self.original_value\n         return super().tearDown()\n \n@@ -621,7 +621,7 @@ class SavingTest(testing.TestCase):\n         )\n \n     @pytest.mark.requires_trainable_backend\n-    def test_save_to_fileobj(self) -> None:\n+    def test_save_to_fileobj(self):\n         model = keras.Sequential(\n             [keras.layers.Dense(1, input_shape=(1,)), keras.layers.Dense(1)]\n         )\n\n@@ -104,6 +104,6 @@ def draw_segmentation_masks(\n     return outputs\n \n \n-def _generate_color_palette(num_classes: int):\n+def _generate_color_palette(num_classes):\n     palette = np.array([2**25 - 1, 2**15 - 1, 2**21 - 1])\n     return [((i * palette) % 255).tolist() for i in range(num_classes)]\n\n@@ -21,7 +21,7 @@ from keras.src.wrappers import SKLearnTransformer\n def wrapped_parametrize_with_checks(\n     estimators,\n     *,\n-    legacy: bool = True,\n+    legacy=True,\n     expected_failed_checks=None,\n ):\n     \"\"\"Wrapped `parametrize_with_checks` handling backwards compat.\"\"\"\n@@ -77,7 +77,7 @@ def dynamic_model(X, y, loss, layers=[10]):\n \n \n @contextmanager\n-def use_floatx(x: str):\n+def use_floatx(x):\n     \"\"\"Context manager to temporarily\n     set the keras backend precision.\n     \"\"\"\n\n@@ -107,7 +107,7 @@ class SKLBase(BaseEstimator):\n         )\n \n     @property\n-    def epoch_(self) -> int:\n+    def epoch_(self):\n         \"\"\"The current training epoch.\"\"\"\n         return getattr(self, \"history_\", {}).get(\"epoch\", 0)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
