{"custom_id": "keras#f1ed6c7c94fb28837aecec42d53c37d410d387db", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 3692 | Contributors (this commit): 7 | Commits (past 90d): 14 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -277,7 +277,8 @@ class BaseImageAugmentationLayer(base_layer.BaseRandomLayer):\n \n   Note that since the randomness is also a common functionnality, this layer\n   also includes a tf.keras.backend.RandomGenerator, which can be used to produce\n-  the random numbers.\n+  the random numbers.  The random number generator is stored in the\n+  `self._random_generator` attribute.\n   \"\"\"\n \n   def __init__(self, rate=1.0, seed=None, **kwargs):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7007cd0fd548032f1bb2c23b1defa4812628baec", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 168 | Lines Deleted: 0 | Files Changed: 12 | Hunks: 12 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 168 | Churn Cumulative: 2406 | Contributors (this commit): 2 | Commits (past 90d): 25 | Contributors (cumulative): 13 | DMM Complexity: None\n\nDIFF:\n@@ -1,3 +1,17 @@\n+# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n \"\"\"DTensor specific Keras initializers.\"\"\"\n \n import inspect\n\n@@ -1,3 +1,17 @@\n+# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n \"\"\"Tests for initializers.\"\"\"\n \n from absl.testing import parameterized\n\n@@ -1,3 +1,17 @@\n+# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n \"\"\"E2E test for DTensor with Mnist model.\n \n Note that this is used as prototype and verification of current functionality,\n\n@@ -1,3 +1,17 @@\n+# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n \"\"\"DTensor specific Keras layers.\"\"\"\n \n import functools\n\n@@ -1,3 +1,17 @@\n+# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n \"\"\"Tests for layers.\"\"\"\n \n from keras.dtensor import layers\n\n@@ -1,3 +1,17 @@\n+# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n \"\"\"Library for map layout and corresponding tf.Variable.\"\"\"\n \n import collections\n\n@@ -1,3 +1,17 @@\n+# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n \"\"\"Tests for layout_map.\"\"\"\n \n from keras import backend\n\n@@ -1,3 +1,17 @@\n+# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n \"\"\"Lazily initialized variables, useful for creating a symbolic Keras model.\"\"\"\n \n # pylint: disable=g-direct-tensorflow-import\n\n@@ -1,3 +1,17 @@\n+# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n \"\"\"E2E Tests for mnist_model.\"\"\"\n \n from keras import backend\n\n@@ -1,3 +1,17 @@\n+# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n \"\"\"DTensor specific Keras optimizers.\"\"\"\n \n from keras.optimizers import learning_rate_schedule\n\n@@ -1,3 +1,17 @@\n+# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n \"\"\"Tests for initializers.\"\"\"\n \n from absl.testing import parameterized\n\n@@ -1,3 +1,17 @@\n+# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n \"\"\"Tests for utils.\"\"\"\n \n from absl.testing import parameterized\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#96efc4eb1fcb57419a6d4e63e216f4d4e810b8d2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 1 | Churn Cumulative: 2102 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 0.0\n\nDIFF:\n@@ -991,6 +991,7 @@ def EfficientNetV2(\n           name=\"block{}{}_\".format(i + 1, chr(j + 97)),\n           **args,\n       )(x)\n+      b += 1\n \n   # Build top\n   top_filters = round_filters(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d43e59d7f00c532aca9eaed6bd3d94d28a3a68a8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 9 | Files Changed: 9 | Hunks: 9 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 29 | Churn Cumulative: 182 | Contributors (this commit): 3 | Commits (past 90d): 37 | Contributors (cumulative): 27 | DMM Complexity: None\n\nDIFF:\n@@ -23,7 +23,8 @@ from keras.optimizers.optimizer_v2 import optimizer_v2\n from tensorflow.python.util.tf_export import keras_export\n \n \n-@keras_export('keras.optimizers.Adadelta')\n+# pylint: disable=g-classes-have-attributes\n+@keras_export('keras.optimizers.Adadelta', 'keras.optimizers_legacy.Adadelta')\n class Adadelta(optimizer_v2.OptimizerV2):\n   r\"\"\"Optimizer that implements the Adadelta algorithm.\n \n\n@@ -23,7 +23,8 @@ from keras.optimizers.optimizer_v2 import optimizer_v2\n from tensorflow.python.util.tf_export import keras_export\n \n \n-@keras_export('keras.optimizers.Adagrad')\n+# pylint: disable=g-classes-have-attributes\n+@keras_export('keras.optimizers.Adagrad', 'keras.optimizers_legacy.Adagrad')\n class Adagrad(optimizer_v2.OptimizerV2):\n   r\"\"\"Optimizer that implements the Adagrad algorithm.\n \n\n@@ -20,7 +20,8 @@ from keras.optimizers.optimizer_v2 import optimizer_v2\n from tensorflow.python.util.tf_export import keras_export\n \n \n-@keras_export('keras.optimizers.Adam')\n+# pylint: disable=g-classes-have-attributes\n+@keras_export('keras.optimizers.Adam', 'keras.optimizers_legacy.Adam')\n class Adam(optimizer_v2.OptimizerV2):\n   r\"\"\"Optimizer that implements the Adam algorithm.\n \n\n@@ -20,7 +20,8 @@ from keras.optimizers.optimizer_v2 import optimizer_v2\n from tensorflow.python.util.tf_export import keras_export\n \n \n-@keras_export('keras.optimizers.Adamax')\n+# pylint: disable=g-classes-have-attributes\n+@keras_export('keras.optimizers.Adamax', 'keras.optimizers_legacy.Adamax')\n class Adamax(optimizer_v2.OptimizerV2):\n   \"\"\"Optimizer that implements the Adamax algorithm.\n \n\n@@ -21,7 +21,8 @@ from keras.optimizers.optimizer_v2 import optimizer_v2\n from tensorflow.python.util.tf_export import keras_export  # pylint: disable=g-direct-tensorflow-import\n \n \n-@keras_export('keras.optimizers.Ftrl')\n+# pylint: disable=g-classes-have-attributes\n+@keras_export('keras.optimizers.Ftrl', 'keras.optimizers_legacy.Ftrl')\n class Ftrl(optimizer_v2.OptimizerV2):\n   r\"\"\"Optimizer that implements the FTRL algorithm.\n \n\n@@ -20,7 +20,8 @@ from keras.optimizers.optimizer_v2 import optimizer_v2\n from tensorflow.python.util.tf_export import keras_export  # pylint: disable=g-direct-tensorflow-import\n \n \n-@keras_export(\"keras.optimizers.SGD\")\n+# pylint: disable=g-classes-have-attributes\n+@keras_export(\"keras.optimizers.SGD\", \"keras.optimizers_legacy.SGD\")\n class SGD(optimizer_v2.OptimizerV2):\n   r\"\"\"Gradient descent (with momentum) optimizer.\n \n\n@@ -21,7 +21,8 @@ from keras.optimizers.optimizer_v2 import optimizer_v2\n from tensorflow.python.util.tf_export import keras_export\n \n \n-@keras_export('keras.optimizers.Nadam')\n+# pylint: disable=g-classes-have-attributes\n+@keras_export('keras.optimizers.Nadam', 'keras.optimizers_legacy.Nadam')\n class Nadam(optimizer_v2.OptimizerV2):\n   r\"\"\"Optimizer that implements the NAdam algorithm.\n   Much like Adam is essentially RMSprop with momentum, Nadam is Adam with\n\n@@ -92,7 +92,10 @@ def name_scope_only_in_function_or_graph(name):\n     return NullContextmanager()\n \n \n-@keras_export(\"keras.optimizers.Optimizer\", metaclass=abc.ABCMeta)\n+@keras_export(\n+    \"keras.optimizers.Optimizer\",\n+    \"keras.optimizers_legacy.Optimizer\",\n+    metaclass=abc.ABCMeta)\n class OptimizerV2(tf.__internal__.tracking.Trackable):\n   \"\"\"Base class for Keras optimizers.\n \n\n@@ -23,7 +23,8 @@ from keras.optimizers.optimizer_v2 import optimizer_v2\n from tensorflow.python.util.tf_export import keras_export\n \n \n-@keras_export(\"keras.optimizers.RMSprop\")\n+# pylint: disable=g-classes-have-attributes\n+@keras_export(\"keras.optimizers.RMSprop\", \"keras.optimizers_legacy.RMSprop\")\n class RMSprop(optimizer_v2.OptimizerV2):\n   r\"\"\"Optimizer that implements the RMSprop algorithm.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#39ffc7ad09f8877ad90773a7390a1ede6c4a6cbb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 2 | Files Changed: 3 | Hunks: 5 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 9 | Churn Cumulative: 245 | Contributors (this commit): 6 | Commits (past 90d): 8 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -25,6 +25,9 @@ from keras.optimizers.optimizer_experimental import optimizer as optimizer_exper\n from keras.optimizers.optimizer_experimental import adadelta as adadelta_experimental\n from keras.optimizers.optimizer_experimental import adagrad as adagrad_experimental\n from keras.optimizers.optimizer_experimental import adam as adam_experimental\n+from keras.optimizers.optimizer_experimental import adamax as adamax_experimental\n+from keras.optimizers.optimizer_experimental import adamw as adamw_experimental\n+from keras.optimizers.optimizer_experimental import rmsprop as rmsprop_experimental\n from keras.optimizers.optimizer_experimental import sgd as sgd_experimental\n from keras.optimizers.optimizer_v1 import Optimizer\n from keras.optimizers.optimizer_v1 import TFOptimizer\n\n@@ -12,4 +12,4 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n # ==============================================================================\n-\"\"\"This is under development, and subject to interface/implementation changes.\"\"\"\n+\"\"\"Experimental optimizer package.\"\"\"\n\n@@ -17,11 +17,13 @@\n from keras.optimizers.optimizer_experimental import optimizer\n from keras.utils import generic_utils\n import tensorflow.compat.v2 as tf\n+# pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.util.tf_export import keras_export\n \n \n # pylint: disable=g-classes-have-attributes\n-# TODO(b/221112624): Export Adamax.\n @generic_utils.register_keras_serializable()\n+@keras_export('keras.optimizers.experimental.Adamax', v1=[])\n class Adamax(optimizer.Optimizer):\n   \"\"\"Optimizer that implements the Adamax algorithm.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1380d4d4c7a15930a4bf4ef84b9cdb17b35462d8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 16730 | Contributors (this commit): 123 | Commits (past 90d): 28 | Contributors (cumulative): 123 | DMM Complexity: None\n\nDIFF:\n@@ -2064,8 +2064,8 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n           - A dict mapping input names to the corresponding array/tensors,\n               if the model has named inputs.\n         y: Target data. Like the input data `x`, it could be either Numpy\n-          array(s) or TensorFlow tensor(s). It should be consistent with `x`\n-          (you cannot have Numpy inputs and tensor targets, or inversely).\n+          array(s) or TensorFlow tensor(s). It is preferred to be consistent\n+           with `x`.\n         sample_weight: Optional array of the same length as x, containing\n           weights to apply to the model's loss for each sample. In the case of\n           temporal data, you can pass a 2D array with shape (samples,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#795f3aa49735550dbdcc27b9b7cabd8730e1d7cc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 16733 | Contributors (this commit): 123 | Commits (past 90d): 29 | Contributors (cumulative): 123 | DMM Complexity: None\n\nDIFF:\n@@ -2064,8 +2064,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n           - A dict mapping input names to the corresponding array/tensors,\n               if the model has named inputs.\n         y: Target data. Like the input data `x`, it could be either Numpy\n-          array(s) or TensorFlow tensor(s). It is preferred to be consistent\n-           with `x`.\n+          array(s) or TensorFlow tensor(s).\n         sample_weight: Optional array of the same length as x, containing\n           weights to apply to the model's loss for each sample. In the case of\n           temporal data, you can pass a 2D array with shape (samples,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2d05d1ba2b390f1566de27f7592197f60164f6b0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 22 | Files Changed: 1 | Hunks: 9 | Methods Changed: 8 | Complexity Δ (Sum/Max): -4/0 | Churn Δ: 36 | Churn Cumulative: 230 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 3 | DMM Complexity: 0.0\n\nDIFF:\n@@ -15,47 +15,34 @@\n # ==============================================================================\n \"\"\"Tests for evaluation using Keras model and ParameterServerStrategy.\"\"\"\n \n-import tensorflow.compat.v2 as tf\n-\n import time\n \n import keras\n from keras.testing_infra import test_utils\n+import tensorflow.compat.v2 as tf\n+\n from tensorflow.python.distribute import multi_worker_test_base\n from tensorflow.python.distribute.cluster_resolver import SimpleClusterResolver\n from tensorflow.python.ops import resource_variable_ops\n \n \n # TODO(yuefengz): move the following implementation to Keras core.\n-class KerasMetricTypeSpec(tf.TypeSpec):\n+class MeanMetricSpec(tf.TypeSpec):\n \n-  def __init__(self, cls, config, weights):\n-    self._cls = cls\n+  def __init__(self, config, weights):\n     self._config = config\n     self._weights = weights\n \n   def _serialize(self):\n-    return (self._cls.__name__, self._config)\n+    return (self._config, self._weights)\n \n   @property\n   def value_type(self):\n-    return self._cls\n-\n-  def most_specific_compatible_type(self, other):\n-    if (type(self) is not type(other) or self._cls != other._cls or\n-        self._config != other._config):\n-      raise ValueError(\"No TypeSpec is compatible with both %s and %s\" %\n-                       (self, other))\n-    return KerasMetricTypeSpec(self._cls, self._config, self._weights)\n+    return MeanMetricAsCompositeTensor\n \n   @property\n   def _component_specs(self):\n-    ret = []\n-    for w in self._weights:\n-      ret.append(\n-          resource_variable_ops.VariableSpec(\n-              w.shape, w.dtype, w.name.split(\":\")[0], trainable=False))\n-    return ret\n+    return self._weights\n \n   def _to_components(self, value):\n     return value.weights\n@@ -72,7 +59,7 @@ class KerasMetricTypeSpec(tf.TypeSpec):\n       return var\n \n     with tf.variable_creator_scope(fetch_variable):\n-      ret = self._cls.from_config(self._config)\n+      ret = MeanMetricAsCompositeTensor.from_config(self._config)\n     assert len(weights) == len(ret.weights)\n     return ret\n \n@@ -85,7 +72,12 @@ class MeanMetricAsCompositeTensor(keras.metrics.Mean,\n \n   @property\n   def _type_spec(self):\n-    return KerasMetricTypeSpec(self.__class__, self.get_config(), self.weights)\n+    weight_specs = []\n+    for w in self.weights:\n+      weight_specs.append(\n+          resource_variable_ops.VariableSpec(\n+              w.shape, w.dtype, w.name.split(\":\")[0], trainable=False))\n+    return MeanMetricSpec(self.get_config(), weight_specs)\n \n \n @test_utils.run_v2_only\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8798311b04f4615dd0a4e355e01be13e14606bf3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 75 | Lines Deleted: 123 | Files Changed: 6 | Hunks: 44 | Methods Changed: 18 | Complexity Δ (Sum/Max): -6/3 | Churn Δ: 198 | Churn Cumulative: 19952 | Contributors (this commit): 127 | Commits (past 90d): 54 | Contributors (cumulative): 138 | DMM Complexity: 0.14285714285714285\n\nDIFF:\n@@ -46,7 +46,7 @@ def get_model_with_layout_map(layout_map):\n     a CNN Keras model used for MNIST\n   \"\"\"\n \n-  with layout_map_lib.layout_map_scope(layout_map):\n+  def model_fn():\n     # Define a CNN model to recognize MNIST digits.\n     model = models.Sequential()\n     model.add(\n@@ -79,6 +79,8 @@ def get_model_with_layout_map(layout_map):\n         ))\n     return model\n \n+  return layout_map_lib.init_model_with_layout_map(layout_map, model_fn)\n+\n \n def get_all_replicated_layout_map(mesh):\n   layout_map = layout_map_lib.LayoutMap(mesh=mesh)\n\n@@ -15,9 +15,7 @@\n \"\"\"Library for map layout and corresponding tf.Variable.\"\"\"\n \n import collections\n-import contextlib\n import re\n-import threading\n \n from keras.dtensor import dtensor_api as dtensor\n from keras.dtensor import lazy_variable\n@@ -34,13 +32,6 @@ _KERAS_ATTRIBUTES_TO_SKIP = ['_self_tracked_trackables', '_trainable_weights',\n                              '_non_trainable_weights']\n \n \n-_LAYOUT_MAP = threading.local()\n-\n-\n-def get_current_layout_map():\n-  return getattr(_LAYOUT_MAP, 'layout_map', None)\n-\n-\n class LayoutMap(collections.MutableMapping):\n \n   def __init__(self, mesh=None):\n@@ -104,9 +95,8 @@ class LayoutMap(collections.MutableMapping):\n     return self._default_mesh\n \n \n-@contextlib.contextmanager\n-def layout_map_scope(layout_map):\n-  \"\"\"Apply the layout to all the tf.Variables created under the scope.\n+def init_model_with_layout_map(layout_map, model_init_fn):\n+  \"\"\"Apply the layout to all the tf.Variables in the model_init_fn.\n \n   Create a scope that all the tf.Variable created under this scope\n   will be lazily inited, and initialized later on with proper layout when the\n@@ -143,27 +133,32 @@ def layout_map_scope(layout_map):\n     x = self.d1(inputs)\n     return self.d2(x)\n \n-  with layout_map_scope(layout_map):\n+  def model_init_fn():\n     model = SubclassModel()\n-  # Triggering the creation of weights within or outside of the scope works\n-  inputs = tf.zeros((10, 10))\n-  results = model(inputs)\n+    inputs = tf.keras.Input((10,), batch_size=10)\n+    model(inputs)\n+    return model\n \n-  model.d1.kernel.layout == layout_1\n-  model.d1.bias.layout == layout_2\n-  model.d2.kernel.layout == layout_3\n-  model.d2.bias.layout == layout_4\n+  model_with_layout = layout_map_lib.init_model_with_layout_map(\n+        layout_map, model_init_fn)\n+  model_with_layout.d1.kernel.layout == layout_1\n+  model_with_layout.d1.bias.layout == layout_2\n+  model_with_layout.d2.kernel.layout == layout_3\n+  model_with_layout.d2.bias.layout == layout_4\n \n   ## Functional model\n-  with layout_map_scope(layout_map):\n+  def model_init_fn():\n     inputs = tf.keras.Input((10,), batch_size=10)\n     x = tf.keras.layers.Dense(20, name='d1')(inputs)\n     output = tf.keras.layers.Dense(30, name='d2')(x)\n \n     model = tf.keras.Model(inputs, output)\n+    return model\n \n-  d1 = model.layers[1]\n-  d2 = model.layers[2]\n+  model_with_layout = layout_map_lib.init_model_with_layout_map(\n+      layout_map, model_init_fn)\n+  d1 = model_with_layout.layers[1]\n+  d2 = model_with_layout.layers[2]\n \n   d1.kernel.layout == layout_1\n   d1.bias.layout == layout_2\n@@ -171,14 +166,17 @@ def layout_map_scope(layout_map):\n   d1.bias.layout == layout_4\n \n   ## Sequential model\n-  with layout_map_scope(layout_map):\n+  def model_init_fn():\n     model = tf.keras.Sequential([\n         tf.keras.layers.Dense(20, name='d1', input_shape=(10,)),\n         tf.keras.layers.Dense(30, name='d2')\n     ])\n+    return model\n \n-  d1 = model.layers[0]\n-  d2 = model.layers[1]\n+  model_with_layout = layout_map_lib.init_model_with_layout_map(\n+        layout_map, model_init_fn)\n+  d1 = model_with_layout.layers[0]\n+  d2 = model_with_layout.layers[1]\n \n   d1.kernel.layout == layout_1\n   d1.bias.layout == layout_2\n@@ -190,20 +188,28 @@ def layout_map_scope(layout_map):\n     layout_map: a LayoutMap which contains the variable_object_path (string) ->\n       Layout. When a layout is not found for the variable, a default all\n       replicated layout will be created for the variable.\n+    model_init_fn: A function that will trigger the weights creation and return\n+      a Keras model instance. Eg, for a Keras functional model, the\n+      `tf.keras.Model(inputs, output)` will trigger the weights creation. For\n+      subclass model which doesn't have the `build()` method implemented, user\n+      will need to do `model(tf.keras.Input(shape=shape))` to init the weights.\n+      Note that this method need to return the model instance, and the instance\n+      will be used as the root object to track all the tf.Variables that\n+      attached to it.\n \n-  Yields:\n-    A context that will lazily initialize all `tf.Variable` objects\n-    within the model, with their attributed layouts.\n+  Returns:\n+    The same model instance returned from model_init_fn, with all tf.Variable\n+    have the proper layout populated.\n   \"\"\"\n-  previous_layout_map = get_current_layout_map()\n-  global _LAYOUT_MAP\n-  _LAYOUT_MAP.layout_map = layout_map\n-\n   with lazy_variable.lazy_init_scope():\n-    try:\n-      yield\n-    finally:\n-      _LAYOUT_MAP.layout_map = previous_layout_map\n+    model = model_init_fn()\n+\n+  if model._is_graph_network:  # pylint: disable=protected-access\n+    # Functional/Sequential model\n+    return _map_functional_model_variable(model, layout_map)\n+  else:\n+    # Subclass Model\n+    return _map_subclass_model_variable(model, layout_map)\n \n \n def _map_subclass_model_variable(model, layout_map):\n@@ -334,7 +340,6 @@ def _create_dvariable(layout_map, object_path, variable):\n         rank=variable_rank)\n   init_val = variable._initial_value  # pylint: disable=protected-access\n   if callable(init_val):\n-    with lazy_variable.disable_init_variable_creator():\n     init_val = utils.call_with_layout(init_val, layout)\n   else:\n     # The init value is probably already created as a tensor, we will just copy\n\n@@ -173,16 +173,16 @@ class ObjectPathMappingTest(test_util.DTensorBaseTest):\n     layout_map['d2.kernel'] = self.layout_2d\n     layout_map['d2.bias'] = self.layout_1d\n \n-    with layout_map_lib.layout_map_scope(layout_map):\n+    def model_init_fn():\n       model = SubclassModel(name='model')\n+      inputs = tf.keras.Input((10,), batch_size=10)\n+      model(inputs)\n+      return model\n \n-    # Init the model with eager tensor, make sure the model weights have correct\n-    # layout, as well as produce correct result.\n-    inputs = tf.zeros((10, 10), layout=self.layout_2d)\n-    result = model(inputs)\n-    self.assertAllClose(result, tf.zeros((10, 1000)))\n-    d1 = model.d1\n-    d2 = model.d2\n+    model_with_layout = layout_map_lib.init_model_with_layout_map(\n+        layout_map, model_init_fn)\n+    d1 = model_with_layout.d1\n+    d2 = model_with_layout.d2\n     self.assertEqual(d1.kernel.layout, self.layout_2d)\n     self.assertEqual(d1.bias.layout, self.layout_1d)\n     self.assertEqual(d2.kernel.layout, self.layout_2d)\n@@ -195,7 +195,8 @@ class ObjectPathMappingTest(test_util.DTensorBaseTest):\n     self.assertIs(d2.kernel, d2._trainable_weights[0])\n     self.assertIs(d2.bias, d2._trainable_weights[1])\n \n-    result = model(tf.zeros((10, 10), layout=self.layout_2d), training=True)\n+    result = model_with_layout(tf.zeros((10, 10), layout=self.layout_2d),\n+                               training=True)\n     self.assertAllClose(result, tf.zeros((10, 1000), layout=self.layout_2d))\n \n   def test_init_functional_model_variable_with_layout(self):\n@@ -209,18 +210,21 @@ class ObjectPathMappingTest(test_util.DTensorBaseTest):\n     layout_map['d2.kernel'] = self.layout_2d\n     layout_map['d2.bias'] = self.layout_1d\n \n-    with layout_map_lib.layout_map_scope(layout_map):\n+    def model_init_fn():\n       inputs = tf.keras.Input((10,), batch_size=10)\n       x = layers.Dense(20, name='d1')(inputs)\n       x = layers.Dropout(0.1)(x)\n       output = layers.Dense(30, name='d2')(x)\n \n       model = tf.keras.Model(inputs, output)\n+      return model\n \n+    model_with_layout = layout_map_lib.init_model_with_layout_map(\n+        layout_map, model_init_fn)\n     # It includes input layer as well.\n-    self.assertLen(model.layers, 4)\n-    d1 = model.layers[1]\n-    d2 = model.layers[3]\n+    self.assertLen(model_with_layout.layers, 4)\n+    d1 = model_with_layout.layers[1]\n+    d2 = model_with_layout.layers[3]\n \n     self.assertEqual(d1.kernel.layout, self.layout_2d)\n     self.assertEqual(d1.bias.layout, self.layout_1d)\n@@ -234,7 +238,8 @@ class ObjectPathMappingTest(test_util.DTensorBaseTest):\n     self.assertIs(d2.kernel, d2._trainable_weights[0])\n     self.assertIs(d2.bias, d2._trainable_weights[1])\n \n-    result = model(tf.zeros((10, 10), layout=self.layout_2d), training=True)\n+    result = model_with_layout(tf.zeros((10, 10), layout=self.layout_2d),\n+                               training=True)\n     self.assertAllClose(result, tf.zeros((10, 30), layout=self.layout_2d))\n \n   def test_init_sequential_model_variable_with_layout(self):\n@@ -248,16 +253,19 @@ class ObjectPathMappingTest(test_util.DTensorBaseTest):\n     layout_map['d2.kernel'] = self.layout_2d\n     layout_map['d2.bias'] = self.layout_1d\n \n-    with layout_map_lib.layout_map_scope(layout_map):\n+    def model_init_fn():\n       model = tf.keras.Sequential([\n           layers.Dense(20, name='d1', input_shape=(10,)),\n           layers.Dropout(0.1),\n           layers.Dense(30, name='d2')\n       ])\n+      return model\n \n-    self.assertLen(model.layers, 3)\n-    d1 = model.layers[0]\n-    d2 = model.layers[2]\n+    model_with_layout = layout_map_lib.init_model_with_layout_map(\n+        layout_map, model_init_fn)\n+    self.assertLen(model_with_layout.layers, 3)\n+    d1 = model_with_layout.layers[0]\n+    d2 = model_with_layout.layers[2]\n \n     self.assertEqual(d1.kernel.layout, self.layout_2d)\n     self.assertEqual(d1.bias.layout, self.layout_1d)\n@@ -271,7 +279,8 @@ class ObjectPathMappingTest(test_util.DTensorBaseTest):\n     self.assertIs(d2.kernel, d2._trainable_weights[0])\n     self.assertIs(d2.bias, d2._trainable_weights[1])\n \n-    result = model(tf.zeros((10, 10), layout=self.layout_2d), training=True)\n+    result = model_with_layout(tf.zeros((10, 10), layout=self.layout_2d),\n+                               training=True)\n     self.assertAllClose(result, tf.zeros((10, 30), layout=self.layout_2d))\n \n \n\n@@ -14,8 +14,6 @@\n # ==============================================================================\n \"\"\"Lazily initialized variables, useful for creating a symbolic Keras model.\"\"\"\n \n-import threading\n-\n # pylint: disable=g-direct-tensorflow-import\n from tensorflow.core.framework import attr_value_pb2\n from tensorflow.python.eager import context\n@@ -28,9 +26,6 @@ from tensorflow.python.util import compat\n from tensorflow.python.util import tf_contextlib\n \n \n-_DISABLE_LAZY_VARIABLE_INIT = threading.local()\n-\n-\n def _infer_shape_dtype_and_create_handle(initial_value, shape, dtype, name):\n   \"\"\"Infer shape and dtype from initial_value and create a variable handle.\"\"\"\n   with ops.name_scope(name, \"Variable\", skip_on_eager=False) as name:\n@@ -196,9 +191,7 @@ class LazyInitVariable(resource_variable_ops.BaseResourceVariable):\n \n \n def _lazy_init_variable_creator(next_creator, **kwargs):\n-  if getattr(_DISABLE_LAZY_VARIABLE_INIT, \"disabled\", False):\n-    return next_creator(**kwargs)\n-  else:\n+  del next_creator\n   return LazyInitVariable(**kwargs)\n \n \n@@ -207,14 +200,3 @@ def lazy_init_scope():\n   with variable_scope.variable_creator_scope(_lazy_init_variable_creator):\n     yield\n \n-\n-@tf_contextlib.contextmanager\n-def disable_init_variable_creator():\n-  try:\n-    global _DISABLE_LAZY_VARIABLE_INIT\n-    existing_value = getattr(_DISABLE_LAZY_VARIABLE_INIT, \"disabled\", False)\n-    _DISABLE_LAZY_VARIABLE_INIT.disabled = True\n-    yield\n-  finally:\n-    _DISABLE_LAZY_VARIABLE_INIT.disabled = existing_value\n-\n\n@@ -21,7 +21,6 @@ import copy\n import itertools\n import warnings\n from keras import backend\n-from keras.dtensor import layout_map as layout_map_lib\n from keras.engine import base_layer\n from keras.engine import base_layer_utils\n from keras.engine import functional_utils\n@@ -259,12 +258,6 @@ class Functional(training_lib.Model):\n     self._set_save_spec(self._nested_inputs)\n     tf_utils.assert_no_legacy_layers(self.layers)\n \n-    # Note that this mehtod is used by both functional and sequential model,\n-    # so we can't just this method in functional.__init__, which will miss the\n-    # coverage of sequential model.\n-    if self._layout_map:\n-      layout_map_lib._map_functional_model_variable(self, self._layout_map)\n-\n   @property\n   def input(self):\n     \"\"\"Retrieves the input tensor(s) of a layer.\n\n@@ -24,12 +24,10 @@ import weakref\n from keras import backend\n from keras import callbacks as callbacks_module\n from keras import optimizers\n-from keras.dtensor import layout_map as layout_map_lib\n from keras.engine import base_layer\n from keras.engine import base_layer_utils\n from keras.engine import compile_utils\n from keras.engine import data_adapter\n-from keras.engine import input_layer as input_layer_module\n from keras.engine import training_utils\n from keras.mixed_precision import loss_scale_optimizer as lso\n from keras.optimizers import optimizer_v1\n@@ -48,8 +46,6 @@ from keras.utils import tf_utils\n from keras.utils import traceback_utils\n from keras.utils import version_utils\n from keras.utils.mode_keys import ModeKeys\n-\n-import numpy as np\n import tensorflow.compat.v2 as tf\n \n from tensorflow.python.eager import context\n@@ -289,8 +285,6 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     # `evaluate`, and `predict`.\n     self._jit_compile = None\n \n-    self._layout_map = layout_map_lib.get_current_layout_map()\n-\n   @tf.__internal__.tracking.no_automatic_dependency_tracking\n   def _init_batch_counters(self):\n     # Untracked Variables, used to keep track of mini-batches seen in `fit`,\n@@ -457,39 +451,6 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n                            f'`call` is: {e}.')\n     super(Model, self).build(input_shape)\n \n-  @traceback_utils.filter_traceback\n-  def __call__(self, *args, **kwargs):\n-    if self._layout_map and not self.built:\n-      # Note that this method is only overridden for DTensor and layout\n-      # injection purpose.\n-      # Capture the inputs and create graph input as replacement for model\n-      # to initialize its weights first.\n-      copied_args = copy.copy(args)\n-      copied_kwargs = copy.copy(kwargs)\n-\n-      inputs, copied_args, copied_kwargs = self._split_out_first_arg(\n-          copied_args, copied_kwargs)\n-\n-      def _convert_to_graph_inputs(x):\n-        if isinstance(x, (tf.Tensor, np.ndarray, float, int)):\n-          x = tf.convert_to_tensor(x)\n-          return input_layer_module.Input(x.shape)\n-\n-      # TODO(scottzhu): maybe better handle mask and training flag.\n-      inputs = tf.nest.map_structure(_convert_to_graph_inputs, inputs)\n-      copied_args = tf.nest.map_structure(_convert_to_graph_inputs, copied_args)\n-      copied_kwargs = tf.nest.map_structure(\n-          _convert_to_graph_inputs, copied_kwargs)\n-\n-        # pylint: disable=g-import-not-at-top\n-      with layout_map_lib.layout_map_scope(self._layout_map):\n-        # We ignore the result here.\n-        super().__call__(inputs, *copied_args, **copied_kwargs)\n-\n-      layout_map_lib._map_subclass_model_variable(self, self._layout_map)\n-\n-    return super().__call__(*args, **kwargs)\n-\n   @doc_controls.doc_in_current_and_subclasses\n   def call(self, inputs, training=None, mask=None):\n     \"\"\"Calls the model on new inputs and returns the outputs as tensors.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a1ae8cb577675e49e2b2b4963a333ee04d467978", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 177 | Lines Deleted: 145 | Files Changed: 2 | Hunks: 68 | Methods Changed: 24 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 322 | Churn Cumulative: 1380 | Contributors (this commit): 5 | Commits (past 90d): 5 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -72,8 +72,12 @@ ARG_TO_MODEL = {\n         efficientnet_v2.EfficientNetV2S, efficientnet_v2.EfficientNetV2M,\n         efficientnet_v2.EfficientNetV2L\n     ]),\n-    'resnet_rs':(resnet_rs,[resnet_rs.ResNetRS50,resnet_rs.ResNetRS101,resnet_rs.ResNetRS152,\n-    resnet_rs.ResNetRS200,resnet_rs.ResNetRS270,resnet_rs.ResNetRS350,resnet_rs.ResNetRS420]),\n+    'resnet_rs': (resnet_rs, [\n+        resnet_rs.ResNetRS50, resnet_rs.ResNetRS101,\n+        resnet_rs.ResNetRS152, resnet_rs.ResNetRS200,\n+        resnet_rs.ResNetRS270, resnet_rs.ResNetRS350,\n+        resnet_rs.ResNetRS420\n+    ]),\n     'regnet': (regnet, [\n         regnet.RegNetX002, regnet.RegNetX004, regnet.RegNetX006,\n         regnet.RegNetX008, regnet.RegNetX016, regnet.RegNetX032,\n\n@@ -123,9 +123,83 @@ CONV_KERNEL_INITIALIZER = {\n     }\n }\n \n-def Conv2DFixedPadding(filters, kernel_size, strides, name):\n-    \"\"\"Conv2D block with fixed padding.\n+BASE_DOCSTRING = \"\"\"Instantiates the {name} architecture.\n+\n+    Reference:\n+    [Revisiting ResNets: Improved Training and Scaling Strategies](\n+    https://arxiv.org/pdf/2103.07579.pdf)\n+\n+    For image classification use cases, see\n+    [this page for detailed examples](\n+    https://keras.io/api/applications/#usage-examples-for-image-classification-models).\n+\n+    For transfer learning use cases, make sure to read the\n+    [guide to transfer learning & fine-tuning](\n+    https://keras.io/guides/transfer_learning/).\n+\n+    Note: each Keras Application expects a specific kind of input preprocessing.\n+    For ResNetRs, by default input preprocessing is included as a part of the\n+    model (as a `Rescaling` layer), and thus\n+    `tf.keras.applications.resnet_rs.preprocess_input` is actually a\n+    pass-through function. In this use case, ResNetRS models expect their inputs\n+    to be float tensors of pixels with values in the [0-255] range.\n+    At the same time, preprocessing as a part of the model (i.e. `Rescaling`\n+    layer) can be disabled by setting `include_preprocessing` argument to False.\n+    With preprocessing disabled ResNetRS models expect their inputs to be float\n+    tensors of pixels with values in the [-1, 1] range.\n+\n+    Args:\n+        depth: Depth of ResNet network.\n+        dropout_rate: dropout rate before final classifier layer.\n+        bn_momentum: Momentum parameter for Batch Normalization layers.\n+        bn_epsilon: Epsilon parameter for Batch Normalization layers.\n+        activation: activation function.\n+        block_args: list of dicts, parameters to construct block modules.\n+        se_ratio: Squeeze and Excitation layer ratio.\n+        model_name: name of the model.\n+        drop_connect_rate: dropout rate at skip connections.\n+        include_top: whether to include the fully-connected layer at the top of\n+        the network.\n+        weights: one of `None` (random initialization), `'imagenet'`\n+            (pre-training on ImageNet), or the path to the weights file to be loaded.\n+            Note: one model can have multiple imagenet variants depending on\n+            input shape it was trained with. For input_shape 224x224 pass\n+            `imagenet-i224` as argument. By default, highest input shape weights are\n+            downloaded.\n+        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`) to\n+            use as image input for the model.\n+        input_shape: optional shape tuple. It should have exactly 3 inputs\n+            channels, and width and height should be no smaller than 32.\n+            E.g. (200, 200, 3) would be one valid value.\n+        pooling: optional pooling mode for feature extraction when `include_top`\n+            is `False`.\n+            - `None` means that the output of the model will be\n+                the 4D tensor output of the\n+                last convolutional layer.\n+            - `avg` means that global average pooling\n+                will be applied to the output of the\n+                last convolutional layer, and thus\n+                the output of the model will be a 2D tensor.\n+            - `max` means that global max pooling will\n+                be applied.\n+        classes: optional number of classes to classify images into, only to be\n+            specified if `include_top` is True, and if no `weights` argument is\n+            specified.\n+        classifier_activation: A `str` or callable. The activation function to\n+            use on the \"top\" layer. Ignored unless `include_top=True`. Set\n+            `classifier_activation=None` to return the logits of the \"top\" layer.\n+        include_preprocessing: Boolean, whether to include the preprocessing layer\n+            (`Rescaling`) at the bottom of the network. Defaults to `True`.\n+\n+    Returns:\n+        A `keras.Model` instance.\n \"\"\"\n+\n+def Conv2DFixedPadding(filters, kernel_size, strides, name = None):\n+    \"\"\"Conv2D block with fixed padding.\"\"\"\n+    if name is None:\n+        name = backend.get_uid(\"conv\")\n+\n     def apply(inputs):\n         if strides > 1:\n             inputs = fixed_padding(inputs, kernel_size)\n@@ -140,75 +214,79 @@ def Conv2DFixedPadding(filters, kernel_size, strides, name):\n         )(inputs)\n     return apply\n \n-def STEM(bn_momentum: float, bn_epsilon: float, activation: str):\n+def STEM(bn_momentum: float = 0.0, bn_epsilon: float =1e-5, activation: str =\"relu\", name = None):\n     \"\"\"ResNet-D type STEM block.\"\"\"\n+    if name is None:\n+        name = \"stem\" + str(backend.get_uid(\"stem\"))\n \n     def apply(inputs):\n         bn_axis = 3 if backend.image_data_format() == \"channels_last\" else 1\n \n         # First stem block\n         x = Conv2DFixedPadding(\n-            filters=32, kernel_size=3, strides=2, name=\"stem_conv_1\"\n+            filters=32, kernel_size=3, strides=2, name= name + \"_stem_conv_1\"\n         )(inputs)\n         x = layers.BatchNormalization(\n             axis=bn_axis,\n             momentum=bn_momentum,\n             epsilon=bn_epsilon,\n-            name=\"stem_batch_norm_1\",\n+            name=name + \"_stem_batch_norm_1\",\n         )(x)\n-        x = layers.Activation(activation, name=\"stem_act_1\")(x)\n+        x = layers.Activation(activation, name= name + \"_stem_act_1\")(x)\n \n         # Second stem block\n         x = Conv2DFixedPadding(\n-            filters=32, kernel_size=3, strides=1, name=\"stem_conv_2\"\n+            filters=32, kernel_size=3, strides=1, name= name + \"_stem_conv_2\"\n         )(x)\n         x = layers.BatchNormalization(\n             axis=bn_axis,\n             momentum=bn_momentum,\n             epsilon=bn_epsilon,\n-            name=\"stem_batch_norm_2\",\n+            name=name + \"_stem_batch_norm_2\",\n         )(x)\n-        x = layers.Activation(activation, name=\"stem_act_2\")(x)\n+        x = layers.Activation(activation, name= name + \"_stem_act_2\")(x)\n \n         # Final Stem block:\n         x = Conv2DFixedPadding(\n-            filters=64, kernel_size=3, strides=1, name=\"stem_conv_3\"\n+            filters=64, kernel_size=3, strides=1, name= name + \"_stem_conv_3\"\n         )(x)\n         x = layers.BatchNormalization(\n             axis=bn_axis,\n             momentum=bn_momentum,\n             epsilon=bn_epsilon,\n-            name=\"stem_batch_norm_3\",\n+            name=name + \"_stem_batch_norm_3\",\n         )(x)\n-        x = layers.Activation(activation, name=\"stem_act_3\")(x)\n+        x = layers.Activation(activation, name= name + \"_stem_act_3\")(x)\n \n         # Replace stem max pool:\n         x = Conv2DFixedPadding(\n-            filters=64, kernel_size=3, strides=2, name=\"stem_conv_4\"\n+            filters=64, kernel_size=3, strides=2, name= name + \"_stem_conv_4\"\n         )(x)\n         x = layers.BatchNormalization(\n             axis=bn_axis,\n             momentum=bn_momentum,\n             epsilon=bn_epsilon,\n-            name=\"stem_batch_norm_4\",\n+            name=name + \"_stem_batch_norm_4\",\n         )(x)\n-        x = layers.Activation(activation, name=\"stem_act_4\")(x)\n+        x = layers.Activation(activation, name= name + \"_stem_act_4\")(x)\n         return x\n \n     return apply\n \n \n-def SE(in_filters: int, se_ratio: float, name: str, expand_ratio: int = 1):\n+def SE(in_filters: int, se_ratio: float =0.25,  expand_ratio: int = 1,name = None):\n     \"\"\"Squeeze and Excitation block.\"\"\"\n     bn_axis = 3 if backend.image_data_format() == \"channels_last\" else 1\n+    if name is None:\n+        name = \"se\" + str(backend.get_uid(\"se\"))\n \n     def apply(inputs):\n-        x = layers.GlobalAveragePooling2D(name=name + \"se_squeeze\")(inputs)\n+        x = layers.GlobalAveragePooling2D(name=name + \"_se_squeeze\")(inputs)\n         if bn_axis == 1:\n             se_shape = (x.shape[-1], 1, 1)\n         else:\n             se_shape = (1, 1, x.shape[-1])\n-        x = layers.Reshape(se_shape, name=name + \"se_reshape\")(x)\n+        x = layers.Reshape(se_shape, name=name + \"_se_reshape\")(x)\n \n         num_reduced_filters = max(1, int(in_filters * 4 * se_ratio))\n \n@@ -220,7 +298,7 @@ def SE(in_filters: int, se_ratio: float, name: str, expand_ratio: int = 1):\n             padding=\"same\",\n             use_bias=True,\n             activation=\"relu\",\n-            name=name + \"se_reduce\",\n+            name=name + \"_se_reduce\",\n         )(x)\n \n         x = layers.Conv2D(\n@@ -231,10 +309,10 @@ def SE(in_filters: int, se_ratio: float, name: str, expand_ratio: int = 1):\n             padding=\"same\",\n             use_bias=True,\n             activation=\"sigmoid\",\n-            name=name + \"se_expand\",\n+            name=name + \"_se_expand\",\n         )(x)\n \n-        return layers.multiply([inputs, x], name=name + \"se_excite\")\n+        return layers.multiply([inputs, x], name=name + \"_se_excite\")\n \n     return apply\n \n@@ -243,15 +321,16 @@ def BottleneckBlock(\n     filters: int,\n     strides: int,\n     use_projection: bool,\n-    bn_momentum: float,\n-    bn_epsilon: float,\n-    activation: str,\n-    se_ratio: float,\n-    survival_probability: float,\n-    name: str = None,\n+    bn_momentum: float =0.0,\n+    bn_epsilon: float = 1e-5,\n+    activation: str = \"relu\",\n+    se_ratio: float = 0.25,\n+    survival_probability: float = 0.8,\n+    name = None,\n ):\n     \"\"\"Bottleneck block variant for residual networks with BN after convolutions.\"\"\"\n-\n+    if name is None:\n+        name = \"block_0_\" + str(backend.get_uid(\"block_0_\"))\n     def apply(inputs):\n         bn_axis = 3 if backend.image_data_format() == \"channels_last\" else 1\n \n@@ -264,32 +343,32 @@ def BottleneckBlock(\n                     pool_size=(2, 2),\n                     strides=(2, 2),\n                     padding=\"same\",\n-                    name=name + \"projection_pooling\",\n+                    name=name + \"_projection_pooling\",\n                 )(inputs)\n                 shortcut = Conv2DFixedPadding(\n                     filters=filters_out,\n                     kernel_size=1,\n                     strides=1,\n-                    name=name + \"projection_conv\",\n+                    name=name + \"_projection_conv\",\n                 )(shortcut)\n             else:\n                 shortcut = Conv2DFixedPadding(\n                     filters=filters_out,\n                     kernel_size=1,\n                     strides=strides,\n-                    name=name + \"projection_conv\",\n+                    name=name + \"_projection_conv\",\n                 )(inputs)\n \n             shortcut = layers.BatchNormalization(\n                 axis=bn_axis,\n                 momentum=bn_momentum,\n                 epsilon=bn_epsilon,\n-                name=name + \"projection_batch_norm\",\n+                name=name + \"_projection_batch_norm\",\n             )(shortcut)\n \n         # First conv layer:\n         x = Conv2DFixedPadding(\n-            filters=filters, kernel_size=1, strides=1, name=name + \"conv_1\"\n+            filters=filters, kernel_size=1, strides=1, name=name + \"_conv_1\"\n         )(inputs)\n         x = layers.BatchNormalization(\n             axis=bn_axis,\n@@ -297,43 +376,43 @@ def BottleneckBlock(\n             epsilon=bn_epsilon,\n             name=name + \"batch_norm_1\",\n         )(x)\n-        x = layers.Activation(activation, name=name + \"act_1\")(x)\n+        x = layers.Activation(activation, name=name + \"_act_1\")(x)\n \n         # Second conv layer:\n         x = Conv2DFixedPadding(\n-            filters=filters, kernel_size=3, strides=strides, name=name + \"conv_2\"\n+            filters=filters, kernel_size=3, strides=strides, name=name + \"_conv_2\"\n         )(x)\n         x = layers.BatchNormalization(\n             axis=bn_axis,\n             momentum=bn_momentum,\n             epsilon=bn_epsilon,\n-            name=name + \"batch_norm_2\",\n+            name=name + \"_batch_norm_2\",\n         )(x)\n-        x = layers.Activation(activation, name=name + \"act_2\")(x)\n+        x = layers.Activation(activation, name=name + \"_act_2\")(x)\n \n         # Third conv layer:\n         x = Conv2DFixedPadding(\n-            filters=filters * 4, kernel_size=1, strides=1, name=name + \"conv_3\"\n+            filters=filters * 4, kernel_size=1, strides=1, name=name + \"_conv_3\"\n         )(x)\n         x = layers.BatchNormalization(\n             axis=bn_axis,\n             momentum=bn_momentum,\n             epsilon=bn_epsilon,\n-            name=name + \"batch_norm_3\",\n+            name=name + \"_batch_norm_3\",\n         )(x)\n \n         if 0 < se_ratio < 1:\n-            x = SE(filters, se_ratio=se_ratio, name=name)(x)\n+            x = SE(filters, se_ratio=se_ratio, name=name + \"_se\")(x)\n \n         # Drop connect\n         if survival_probability:\n             x = layers.Dropout(\n-                survival_probability, noise_shape=(None, 1, 1, 1), name=name + \"drop\"\n+                survival_probability, noise_shape=(None, 1, 1, 1), name=name + \"_drop\"\n             )(x)\n \n         x = layers.Add()([x, shortcut])\n \n-        return layers.Activation(activation, name=name + \"output_act\")(x)\n+        return layers.Activation(activation, name=name + \"_output_act\")(x)\n \n     return apply\n \n@@ -341,15 +420,17 @@ def BottleneckBlock(\n def BlockGroup(\n     filters,\n     strides,\n-    se_ratio,\n-    bn_epsilon,\n-    bn_momentum,\n     num_repeats,\n-    activation,\n-    survival_probability: float,\n-    name: str,\n+    se_ratio : float =0.25,\n+    bn_epsilon : float = 1e-5,\n+    bn_momentum : float =0.0,\n+    activation : str = \"relu\",\n+    survival_probability: float =0.8,\n+    name = None,\n ):\n     \"\"\"Create one group of blocks for the ResNet model.\"\"\"\n+    if name is None:\n+        name = \"block_group\" + str(backend.get_uid(\"block_group\"))\n \n     def apply(inputs):\n         # Only the first block per block_group uses projection shortcut and strides.\n@@ -362,7 +443,7 @@ def BlockGroup(\n             bn_momentum=bn_momentum,\n             activation=activation,\n             survival_probability=survival_probability,\n-            name=name + \"block_0_\",\n+            name=name + \"_block_0_\",\n         )(inputs)\n \n         for i in range(1, num_repeats):\n@@ -375,15 +456,14 @@ def BlockGroup(\n                 bn_epsilon=bn_epsilon,\n                 bn_momentum=bn_momentum,\n                 survival_probability=survival_probability,\n-                name=name + f\"block_{i}_\",\n+                name=name + f\"_block_{i}_\",\n             )(x)\n         return x\n \n     return apply\n \n def get_survival_probability(init_rate, block_num, total_blocks):\n-    \"\"\"Get survival probability based on block number and initial rate.\n-    \"\"\"\n+    \"\"\"Get survival probability based on block number and initial rate.\"\"\"\n     return init_rate * float(block_num) / total_blocks\n \n \n@@ -427,6 +507,7 @@ def ResNetRS(\n     include_preprocessing=True\n ):\n     \"\"\"Build Resnet-RS model, given provided parameters.\n+\n     Parameters:\n         :param depth: Depth of ResNet network.\n         :param dropout_rate: dropout rate before final classifier layer.\n@@ -524,16 +605,7 @@ def ResNetRS(\n     bn_axis = 3 if backend.image_data_format() == \"channels_last\" else 1\n     x = img_input\n     if include_preprocessing:\n-        num_channels = input_shape[bn_axis - 1]\n-        if  num_channels == 3:\n         x = layers.Rescaling(scale=1. / 255)(x)\n-            x = layers.Normalization(\n-                mean=[0.485, 0.456, 0.406],\n-                variance=[0.229**2, 0.224**2, 0.225**2],\n-                axis=bn_axis,\n-            )(x)\n-        else:\n-            x = layers.Rescaling(scale=1. / 128.0, offset=-1)(x)\n \n     # Build stem\n     x = STEM(bn_momentum=bn_momentum, bn_epsilon=bn_epsilon, activation=activation)(\n@@ -560,7 +632,7 @@ def ResNetRS(\n             bn_momentum=bn_momentum,\n             bn_epsilon=bn_epsilon,\n             survival_probability=survival_probability,\n-            name=f\"c{i + 2}_\",\n+            name=f\"BlockGroup{i + 2}_\",\n         )(x)\n \n     # Build head:\n@@ -621,6 +693,7 @@ def ResNetRS50(\n     input_tensor=None,\n     pooling=None,\n     classifier_activation=\"softmax\",\n+    include_preprocessing=True,\n ):\n     \"\"\"Build ResNet-RS50 model.\"\"\"\n     return ResNetRS(\n@@ -635,6 +708,7 @@ def ResNetRS50(\n         pooling=pooling,\n         classifier_activation=classifier_activation,\n         model_name=\"resnet-rs-50\",\n+        include_preprocessing=include_preprocessing,\n     )\n \n @keras_export('keras.applications.resnet_rs.ResNetRS101',\n@@ -647,6 +721,7 @@ def ResNetRS101(\n     input_tensor=None,\n     pooling=None,\n     classifier_activation=\"softmax\",\n+    include_preprocessing=True,\n ):\n     \"\"\"Build ResNet-RS101 model.\"\"\"\n     return ResNetRS(\n@@ -661,6 +736,7 @@ def ResNetRS101(\n         pooling=pooling,\n         classifier_activation=classifier_activation,\n         model_name=\"resnet-rs-101\",\n+        include_preprocessing=include_preprocessing,\n     )\n \n @keras_export('keras.applications.resnet_rs.ResNetRS152',\n@@ -673,6 +749,7 @@ def ResNetRS152(\n     input_tensor=None,\n     pooling=None,\n     classifier_activation=\"softmax\",\n+    include_preprocessing=True,\n ):\n     \"\"\"Build ResNet-RS152 model.\"\"\"\n     return ResNetRS(\n@@ -687,6 +764,7 @@ def ResNetRS152(\n         pooling=pooling,\n         classifier_activation=classifier_activation,\n         model_name=\"resnet-rs-152\",\n+        include_preprocessing=include_preprocessing,\n     )\n \n @keras_export('keras.applications.resnet_rs.ResNetRS200',\n@@ -699,6 +777,7 @@ def ResNetRS200(\n     input_tensor=None,\n     pooling=None,\n     classifier_activation=\"softmax\",\n+    include_preprocessing=True,\n ):\n     \"\"\"Build ResNet-RS200 model.\"\"\"\n     return ResNetRS(\n@@ -713,6 +792,7 @@ def ResNetRS200(\n         pooling=pooling,\n         classifier_activation=classifier_activation,\n         model_name=\"resnet-rs-200\",\n+        include_preprocessing=include_preprocessing,\n     )\n \n @keras_export('keras.applications.resnet_rs.ResNetRS270',\n@@ -725,6 +805,7 @@ def ResNetRS270(\n     input_tensor=None,\n     pooling=None,\n     classifier_activation=\"softmax\",\n+    include_preprocessing=True,\n ):\n     \"\"\"Build ResNet-RS-270 model.\"\"\"\n     allow_bigger_recursion(1300)\n@@ -740,6 +821,7 @@ def ResNetRS270(\n         pooling=pooling,\n         classifier_activation=classifier_activation,\n         model_name=\"resnet-rs-270\",\n+        include_preprocessing=include_preprocessing,\n     )\n \n @keras_export('keras.applications.resnet_rs.ResNetRS350',\n@@ -752,6 +834,7 @@ def ResNetRS350(\n     input_tensor=None,\n     pooling=None,\n     classifier_activation=\"softmax\",\n+    include_preprocessing=True,\n ):\n     \"\"\"Build ResNet-RS350 model.\"\"\"\n     allow_bigger_recursion(1500)\n@@ -767,6 +850,7 @@ def ResNetRS350(\n         pooling=pooling,\n         classifier_activation=classifier_activation,\n         model_name=\"resnet-rs-350\",\n+        include_preprocessing=include_preprocessing,\n     )\n \n @keras_export('keras.applications.resnet_rs.ResNetRS420',\n@@ -779,6 +863,7 @@ def ResNetRS420(\n     input_tensor=None,\n     pooling=None,\n     classifier_activation=\"softmax\",\n+    include_preprocessing=True,\n ):\n     \"\"\"Build ResNet-RS420 model.\"\"\"\n     allow_bigger_recursion(1800)\n@@ -794,10 +879,28 @@ def ResNetRS420(\n         pooling=pooling,\n         classifier_activation=classifier_activation,\n         model_name=\"resnet-rs-420\",\n+        include_preprocessing=include_preprocessing,\n     )\n \n @keras_export('keras.applications.resnet_rs.preprocess_input')\n def preprocess_input(x, data_format=None):\n+  \"\"\"A placeholder method for backward compatibility.\n+\n+  The preprocessing logic has been included in the ResnetRS model\n+  implementation. Users are no longer required to call this method to normalize\n+  the input data. This method does nothing and only kept as a placeholder to\n+  align the API surface between old and new version of model.\n+\n+  Args:\n+    x: A floating point `numpy.array` or a `tf.Tensor`.\n+    data_format: Optional data format of the image tensor/array. Defaults to\n+      None, in which case the global setting\n+      `tf.keras.backend.image_data_format()` is used (unless you changed it, it\n+      defaults to \"channels_last\").{mode}\n+\n+  Returns:\n+    Unchanged `numpy.array` or `tf.Tensor`.\n+  \"\"\"\n   return x\n \n \n@@ -805,87 +908,12 @@ def preprocess_input(x, data_format=None):\n def decode_predictions(preds, top=5):\n   return imagenet_utils.decode_predictions(preds, top=top)\n \n-preprocess_input.__doc__ = imagenet_utils.PREPROCESS_INPUT_DOC.format(\n-    mode='',\n-    ret=imagenet_utils.PREPROCESS_INPUT_RET_DOC_TF,\n-    error=imagenet_utils.PREPROCESS_INPUT_ERROR_DOC)\n decode_predictions.__doc__ = imagenet_utils.decode_predictions.__doc__\n \n-DOC = \"\"\"\n+ResNetRS50.__doc__= BASE_DOCSTRING.format(name=\"ResNetRS50\")\n+ResNetRS152.__doc__= BASE_DOCSTRING.format(name=\"ResNetRS152\")\n+ResNetRS200.__doc__= BASE_DOCSTRING.format(name=\"ResNetRS200\")\n+ResNetRS270.__doc__= BASE_DOCSTRING.format(name=\"ResNetRS270\")\n+ResNetRS350.__doc__= BASE_DOCSTRING.format(name=\"ResNetRS350\")\n+ResNetRS420.__doc__= BASE_DOCSTRING.format(name=\"ResNetRS420\")\n \n-  Reference:\n-  [Revisiting ResNets: Improved Training and Scaling Strategies](\n-    https://arxiv.org/pdf/2103.07579.pdf)\n-\n-  For image classification use cases, see\n-  [this page for detailed examples](\n-    https://keras.io/api/applications/#usage-examples-for-image-classification-models).\n-\n-  For transfer learning use cases, make sure to read the\n-  [guide to transfer learning & fine-tuning](\n-    https://keras.io/guides/transfer_learning/).\n-\n-  Note: each Keras Application expects a specific kind of input preprocessing.\n-  For ResNetRs, by default input preprocessing is included as a part of the\n-  model (as a `Rescaling` layer), and thus\n-  `tf.keras.applications.resnet_rs.preprocess_input` is actually a\n-  pass-through function. In this use case, ResNetRS models expect their inputs\n-  to be float tensors of pixels with values in the [0-255] range.\n-  At the same time, preprocessing as a part of the model (i.e. `Rescaling`\n-  layer) can be disabled by setting `include_preprocessing` argument to False.\n-  With preprocessing disabled ResNetRS models expect their inputs to be float\n-  tensors of pixels with values in the [-1, 1] range.\n-\n-  Args:\n-        depth: Depth of ResNet network.\n-        dropout_rate: dropout rate before final classifier layer.\n-        bn_momentum: Momentum parameter for Batch Normalization layers.\n-        bn_epsilon: Epsilon parameter for Batch Normalization layers.\n-        activation: activation function.\n-        block_args: list of dicts, parameters to construct block modules.\n-        se_ratio: Squeeze and Excitation layer ratio.\n-        model_name: name of the model.\n-        drop_connect_rate: dropout rate at skip connections.\n-        include_top: whether to include the fully-connected layer at the top of\n-        the network.\n-        weights: one of `None` (random initialization), `'imagenet'`\n-            (pre-training on ImageNet), or the path to the weights file to be loaded.\n-            Note: one model can have multiple imagenet variants depending on\n-            input shape it was trained with. For input_shape 224x224 pass\n-            `imagenet-i224` as argument. By default, highest input shape weights are\n-            downloaded.\n-        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`) to\n-            use as image input for the model.\n-        input_shape: optional shape tuple. It should have exactly 3 inputs\n-            channels, and width and height should be no smaller than 32.\n-            E.g. (200, 200, 3) would be one valid value.\n-        pooling: optional pooling mode for feature extraction when `include_top`\n-            is `False`.\n-            - `None` means that the output of the model will be\n-                the 4D tensor output of the\n-                last convolutional layer.\n-            - `avg` means that global average pooling\n-                will be applied to the output of the\n-                last convolutional layer, and thus\n-                the output of the model will be a 2D tensor.\n-            - `max` means that global max pooling will\n-                be applied.\n-        classes: optional number of classes to classify images into, only to be\n-            specified if `include_top` is True, and if no `weights` argument is\n-            specified.\n-        classifier_activation: A `str` or callable. The activation function to\n-            use on the \"top\" layer. Ignored unless `include_top=True`. Set\n-            `classifier_activation=None` to return the logits of the \"top\" layer.\n-        include_preprocessing: Boolean, whether to include the preprocessing layer\n-            (`Rescaling`) at the bottom of the network. Defaults to `True`.\n-\n-  Returns:\n-    A `keras.Model` instance.\n-\"\"\"\n-\n-setattr(ResNetRS50, '__doc__', ResNetRS50.__doc__ + DOC)\n-setattr(ResNetRS152, '__doc__', ResNetRS152.__doc__ + DOC)\n-setattr(ResNetRS200, '__doc__', ResNetRS200.__doc__ + DOC)\n-setattr(ResNetRS270, '__doc__', ResNetRS270.__doc__ + DOC)\n-setattr(ResNetRS350, '__doc__', ResNetRS350.__doc__ + DOC)\n-setattr(ResNetRS420, '__doc__', ResNetRS420.__doc__ + DOC)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
