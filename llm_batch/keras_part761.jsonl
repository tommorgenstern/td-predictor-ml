{"custom_id": "keras#c17e6b74b1f3c9967f9a8ef207fa63fbc2491845", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 444 | Contributors (this commit): 1 | Commits (past 90d): 2 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -281,7 +281,7 @@ model.compile(\n model.summary()\n \n epochs = 40  # @param {type: \"slider\", min:10, max:100}\n-hist = model.fit(ds_train, epochs=epochs, validation_data=ds_test, verbose=2)\n+hist = model.fit(ds_train, epochs=epochs, validation_data=ds_test)\n \n \n \"\"\"\n@@ -358,7 +358,7 @@ applied, the validation accuracy may only reach ~60%.\n model = build_model(num_classes=NUM_CLASSES)\n \n epochs = 25  # @param {type: \"slider\", min:8, max:80}\n-hist = model.fit(ds_train, epochs=epochs, validation_data=ds_test, verbose=2)\n+hist = model.fit(ds_train, epochs=epochs, validation_data=ds_test)\n plot_hist(hist)\n \n \"\"\"\n@@ -402,7 +402,7 @@ def unfreeze_model(model):\n unfreeze_model(model)\n \n epochs = 10  # @param {type: \"slider\", min:8, max:50}\n-hist = model.fit(ds_train, epochs=epochs, validation_data=ds_test, verbose=2)\n+hist = model.fit(ds_train, epochs=epochs, validation_data=ds_test)\n plot_hist(hist)\n \n \"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8afbca7cdf1570b99b654144b7286c7962d7191b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 610 | Contributors (this commit): 1 | Commits (past 90d): 2 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -505,9 +505,8 @@ training_step_size = total_training_examples // BATCH_SIZE\n total_training_steps = training_step_size * EPOCHS\n print(f\"Total training steps: {total_training_steps}.\")\n \n-lr_schedule = keras.optimizers.schedules.PiecewiseConstantDecay(\n-    boundaries=[training_step_size * 15, training_step_size * 15],\n-    values=[INITIAL_LR, INITIAL_LR * 0.5, INITIAL_LR * 0.25],\n+lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n+    initial_learning_rate=0.001, decay_steps=total_training_steps * 15, decay_rate=0.5, staircase=True\n )\n \n steps = range(total_training_steps)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#238eb32f6dc93cd1504f1844bc72df3472bb0c66", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 614 | Contributors (this commit): 1 | Commits (past 90d): 3 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -498,7 +498,7 @@ segmentation_model.summary()\n ## Training\n \n For the training the authors recommend using a learning rate schedule that decays the\n-initial learning rate by half every 20 epochs. In this example, we resort to 15 epochs.\n+initial learning rate by half every 20 epochs. In this example, we use 10 epochs.\n \"\"\"\n \n training_step_size = total_training_examples // BATCH_SIZE\n@@ -506,7 +506,7 @@ total_training_steps = training_step_size * EPOCHS\n print(f\"Total training steps: {total_training_steps}.\")\n \n lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n-    initial_learning_rate=0.001, decay_steps=total_training_steps * 15, decay_rate=0.5, staircase=True\n+    initial_learning_rate=0.01, decay_steps=total_training_steps * 10, decay_rate=0.5, staircase=True\n )\n \n steps = range(total_training_steps)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#60a913e01130bab7a4ed8c7a1eec6c0d1e247c65", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 616 | Contributors (this commit): 1 | Commits (past 90d): 4 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -506,7 +506,7 @@ total_training_steps = training_step_size * EPOCHS\n print(f\"Total training steps: {total_training_steps}.\")\n \n lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n-    initial_learning_rate=0.01, decay_steps=total_training_steps * 10, decay_rate=0.5, staircase=True\n+    initial_learning_rate=0.003, decay_steps=total_training_steps * 10, decay_rate=0.5, staircase=True\n )\n \n steps = range(total_training_steps)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0996b9260ec988f204ef7cbfee5365c3f5580a02", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 446 | Contributors (this commit): 1 | Commits (past 90d): 3 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -321,7 +321,7 @@ and we fine-tune it on our own dataset.\n \n def build_model(num_classes):\n     inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n-    model = EfficientNetB0(include_top=False, input_tensor=x, weights=\"imagenet\")\n+    model = EfficientNetB0(include_top=False, input_tensor=inputs, weights=\"imagenet\")\n \n     # Freeze the pretrained weights\n     model.trainable = False\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a30ca32b7fc1b0ff995ed9079ee9f20ccb8c3ba7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 620 | Contributors (this commit): 1 | Commits (past 90d): 5 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -498,7 +498,7 @@ segmentation_model.summary()\n ## Training\n \n For the training the authors recommend using a learning rate schedule that decays the\n-initial learning rate by half every 20 epochs. In this example, we use 10 epochs.\n+initial learning rate by half every 20 epochs. In this example, we use 5 epochs.\n \"\"\"\n \n training_step_size = total_training_examples // BATCH_SIZE\n@@ -506,7 +506,7 @@ total_training_steps = training_step_size * EPOCHS\n print(f\"Total training steps: {total_training_steps}.\")\n \n lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n-    initial_learning_rate=0.003, decay_steps=total_training_steps * 10, decay_rate=0.5, staircase=True\n+    initial_learning_rate=0.003, decay_steps=total_training_steps * 5, decay_rate=0.5, staircase=True\n )\n \n steps = range(total_training_steps)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5488d43d536793549a633dcd8a1b485681692cdb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 626 | Contributors (this commit): 1 | Commits (past 90d): 6 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -263,7 +263,7 @@ def load_data(point_cloud_batch, label_cloud_batch):\n \n def augment(point_cloud_batch, label_cloud_batch):\n     noise = tf.random.uniform(\n-        tf.shape(label_cloud_batch), -0.005, 0.005, dtype=tf.float64\n+        tf.shape(label_cloud_batch), -0.001, 0.001, dtype=tf.float64\n     )\n     point_cloud_batch += noise[:, :, :3]\n     return point_cloud_batch, label_cloud_batch\n@@ -364,13 +364,13 @@ perceptron block.\n \n def conv_block(x, filters, name):\n     x = layers.Conv1D(filters, kernel_size=1, padding=\"valid\", name=f\"{name}_conv\")(x)\n-    x = layers.BatchNormalization(momentum=0.0, name=f\"{name}_batch_norm\")(x)\n+    x = layers.BatchNormalization(momentum=0.9, name=f\"{name}_batch_norm\")(x)\n     return layers.Activation(\"relu\", name=f\"{name}_relu\")(x)\n \n \n def mlp_block(x, filters, name):\n     x = layers.Dense(filters, name=f\"{name}_dense\")(x)\n-    x = layers.BatchNormalization(momentum=0.0, name=f\"{name}_batch_norm\")(x)\n+    x = layers.BatchNormalization(momentum=0.9, name=f\"{name}_batch_norm\")(x)\n     return layers.Activation(\"relu\", name=f\"{name}_relu\")(x)\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#42bd8487c3db2f2f0753b1b116ad2877d15af19d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 657 | Contributors (this commit): 1 | Commits (past 90d): 5 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -199,7 +199,7 @@ class RepresentationLearner(keras.Model):\n             feature_vectors = keras.utils.normalize(feature_vectors)\n         # The logits shape is [num_augmentations * batch_size, num_augmentations * batch_size].\n         logits = (\n-            keras.ops.matmul(feature_vectors, keras.ops.transpose(feature_vectors))\n+            tf.linalg.matmul(feature_vectors, feature_vectors, transpose_b=True)\n             / self.temperature\n         )\n         # Apply log-max trick for numerical stability.\n@@ -273,7 +273,7 @@ representation_learner.compile(\n history = representation_learner.fit(\n     x=x_data,\n     batch_size=512,\n-    epochs=50,  # for better results, increase the number of epochs to 500.\n+    epochs=1,  # for better results, increase the number of epochs to 500.\n )\n \n \n@@ -311,7 +311,7 @@ for batch_idx in tqdm(range(num_batches)):\n     end_idx = start_idx + batch_size\n     current_batch = feature_vectors[start_idx:end_idx]\n     # Compute the dot similarity.\n-    similarities = keras.ops.matmul(current_batch, keras.ops.transpose(feature_vectors))\n+    similarities = tf.linalg.matmul(current_batch, feature_vectors, transpose_b=True)\n     # Get the indices of most similar vectors.\n     _, indices = keras.ops.top_k(similarities, k=k_neighbours + 1, sorted=True)\n     # Add the indices to the neighbours.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f1b5858e7246f6eba035c122590ee34847feabff", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 628 | Contributors (this commit): 1 | Commits (past 90d): 7 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -506,7 +506,7 @@ total_training_steps = training_step_size * EPOCHS\n print(f\"Total training steps: {total_training_steps}.\")\n \n lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n-    initial_learning_rate=0.003, decay_steps=total_training_steps * 5, decay_rate=0.5, staircase=True\n+    initial_learning_rate=0.003, decay_steps=training_step_size * 5, decay_rate=0.5, staircase=True\n )\n \n steps = range(total_training_steps)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bd3a53d69c28bf51e4e24e7c71bbb7390b212bcb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 11 | Churn Cumulative: 639 | Contributors (this commit): 1 | Commits (past 90d): 8 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -364,13 +364,13 @@ perceptron block.\n \n def conv_block(x, filters, name):\n     x = layers.Conv1D(filters, kernel_size=1, padding=\"valid\", name=f\"{name}_conv\")(x)\n-    x = layers.BatchNormalization(momentum=0.9, name=f\"{name}_batch_norm\")(x)\n+    x = layers.BatchNormalization(name=f\"{name}_batch_norm\")(x)\n     return layers.Activation(\"relu\", name=f\"{name}_relu\")(x)\n \n \n def mlp_block(x, filters, name):\n     x = layers.Dense(filters, name=f\"{name}_dense\")(x)\n-    x = layers.BatchNormalization(momentum=0.9, name=f\"{name}_batch_norm\")(x)\n+    x = layers.BatchNormalization(name=f\"{name}_batch_norm\")(x)\n     return layers.Activation(\"relu\", name=f\"{name}_relu\")(x)\n \n \n@@ -501,12 +501,13 @@ For the training the authors recommend using a learning rate schedule that decay\n initial learning rate by half every 20 epochs. In this example, we use 5 epochs.\n \"\"\"\n \n-training_step_size = total_training_examples // BATCH_SIZE\n-total_training_steps = training_step_size * EPOCHS\n+steps_per_epoch = total_training_examples // BATCH_SIZE\n+total_training_steps = steps_per_epoch * EPOCHS\n+print(f\"Steps per epoch: {steps_per_epoch}.\")\n print(f\"Total training steps: {total_training_steps}.\")\n \n lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n-    initial_learning_rate=0.003, decay_steps=training_step_size * 5, decay_rate=0.5, staircase=True\n+    initial_learning_rate=0.003, decay_steps=steps_per_epoch * 5, decay_rate=0.5, staircase=True\n )\n \n steps = range(total_training_steps)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#13aeced913fc5e7e56cdd7c38a6cb07fbc95d2a5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 9 | Files Changed: 1 | Hunks: 6 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 19 | Churn Cumulative: 676 | Contributors (this commit): 1 | Commits (past 90d): 6 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -273,7 +273,7 @@ representation_learner.compile(\n history = representation_learner.fit(\n     x=x_data,\n     batch_size=512,\n-    epochs=1,  # for better results, increase the number of epochs to 500.\n+    epochs=50,  # for better results, increase the number of epochs to 500.\n )\n \n \n@@ -483,7 +483,7 @@ clustering_learner = create_clustering_learner(clustering_model)\n losses = [ClustersConsistencyLoss(), ClustersEntropyLoss(entropy_loss_weight=5)]\n # Create the model inputs and labels.\n inputs = {\"anchors\": x_data, \"neighbours\": tf.gather(x_data, neighbours)}\n-labels = tf.ones(shape=(x_data.shape[0]))\n+labels = np.ones(shape=(x_data.shape[0]))\n # Compile the model.\n clustering_learner.compile(\n     optimizer=keras.optimizers.AdamW(learning_rate=0.0005, weight_decay=0.0001),\n@@ -528,13 +528,14 @@ clusters = defaultdict(list)\n for idx, c in enumerate(cluster_assignments):\n     clusters[c].append((idx, cluster_confidence[idx]))\n \n+non_empty_clusters = defaultdict(list)\n+for c in clusters.keys():\n+    if clusters[c]:\n+        non_empty_clusters[c] = clusters[c]\n+\n for c in range(num_clusters):\n     print(\"cluster\", c, \":\", len(clusters[c]))\n \n-\"\"\"\n-Notice that the clusters have roughly balanced sizes.\n-\"\"\"\n-\n \"\"\"\n ### Visualize cluster images\n \n@@ -544,12 +545,12 @@ Display the *prototypes*—instances with the highest clustering confidence—of\n num_images = 8\n plt.figure(figsize=(15, 15))\n position = 1\n-for c in range(num_clusters):\n-    cluster_instances = sorted(clusters[c], key=lambda kv: kv[1], reverse=True)\n+for c in non_empty_clusters.keys():\n+    cluster_instances = sorted(non_empty_clusters[c], key=lambda kv: kv[1], reverse=True)\n \n     for j in range(num_images):\n         image_idx = cluster_instances[j][0]\n-        plt.subplot(num_clusters, num_images, position)\n+        plt.subplot(len(non_empty_clusters), num_images, position)\n         plt.imshow(x_data[image_idx].astype(\"uint8\"))\n         plt.title(classes[y_data[image_idx][0]])\n         plt.axis(\"off\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a894c97da59ad9fe5ebf5556c20581e57a5b87cf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 9 | Files Changed: 3 | Hunks: 3 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 21 | Churn Cumulative: 557 | Contributors (this commit): 6 | Commits (past 90d): 14 | Contributors (cumulative): 11 | DMM Complexity: 0.0\n\nDIFF:\n@@ -268,10 +268,9 @@ def result_type(*dtypes):\n     \"float32\"\n     \"\"\"\n     if len(dtypes) == 0:\n-        raise ValueError(\n-            \"Invalid `dtypes`. At least one dtype is required. \"\n-            f\"Received: dtypes={dtypes}\"\n-        )\n+        # If no dtypes provided, default to floatx, this matches\n+        # `ops.convert_to_tensor([])`\n+        return backend.floatx()\n     return _lattice_result_type(\n         *(backend.floatx() if arg is None else arg for arg in dtypes),\n     )\n\n@@ -66,11 +66,8 @@ class DtypesTest(test_case.TestCase, parameterized.TestCase):\n \n         self.assertEqual(backend.result_type(None), jnp.result_type(None).name)\n \n-    def test_result_type_invalid_dtypes(self):\n-        with self.assertRaisesRegexp(\n-            ValueError, \"Invalid `dtypes`. At least one dtype is required.\"\n-        ):\n-            backend.result_type()\n+    def test_result_type_empty_list(self):\n+        self.assertEqual(backend.result_type(), \"float32\")\n \n     def test_respect_weak_type_for_bool(self):\n         self.assertEqual(dtypes._respect_weak_type(\"bool\", True), \"bool\")\n\n@@ -299,6 +299,13 @@ class CoreOpsCorrectnessTest(testing.TestCase):\n         self.assertAllEqual(x, (1, 1))\n         self.assertIsInstance(x, np.ndarray)\n \n+        # Empty lists should give an empty array with the default float type.\n+        x = ops.convert_to_tensor([])\n+        x = ops.convert_to_numpy(x)\n+        self.assertAllEqual(x, [])\n+        self.assertIsInstance(x, np.ndarray)\n+        self.assertEqual(x.dtype.name, \"float32\")\n+\n         # Partially converted.\n         x = ops.convert_to_tensor((1, ops.array(2), 3))\n         self.assertAllEqual(x, (1, 2, 3))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#23dcdc2b3980b932553fe78987bc5e1661a06118", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 28 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 28 | Churn Cumulative: 3837 | Contributors (this commit): 8 | Commits (past 90d): 32 | Contributors (cumulative): 15 | DMM Complexity: 0.8571428571428571\n\nDIFF:\n@@ -105,6 +105,11 @@ def convert_to_tensor(x, dtype=None, sparse=None):\n     if dtype is not None:\n         dtype = standardize_dtype(dtype)\n     if not tf.is_tensor(x):\n+        if dtype == \"bool\":\n+            # TensorFlow boolean conversion is stricter than other backends.\n+            # It does not allow ints. We convert without dtype and cast instead.\n+            x = tf.convert_to_tensor(x)\n+            return tf.cast(x, dtype)\n         return tf.convert_to_tensor(x, dtype=dtype)\n     elif dtype is not None:\n         return tf.cast(x, dtype=dtype)\n\n@@ -11,6 +11,7 @@ from keras import models\n from keras import ops\n from keras import optimizers\n from keras import testing\n+from keras.backend.common import standardize_dtype\n from keras.backend.common.keras_tensor import KerasTensor\n from keras.backend.common.variables import ALLOWED_DTYPES\n from keras.ops import core\n@@ -310,6 +311,17 @@ class CoreOpsCorrectnessTest(testing.TestCase):\n         x = ops.convert_to_tensor((1, ops.array(2), 3))\n         self.assertAllEqual(x, (1, 2, 3))\n \n+        # Check dtype convertion.\n+        x = [[1, 0, 1], [1, 1, 0]]\n+        output = ops.convert_to_tensor(x, dtype=\"int32\")\n+        self.assertEqual(standardize_dtype(output.dtype), \"int32\")\n+        x = [[1, 0, 1], [1, 1, 0]]\n+        output = ops.convert_to_tensor(x, dtype=\"float32\")\n+        self.assertEqual(standardize_dtype(output.dtype), \"float32\")\n+        x = [[1, 0, 1], [1, 1, 0]]\n+        output = ops.convert_to_tensor(x, dtype=\"bool\")\n+        self.assertEqual(standardize_dtype(output.dtype), \"bool\")\n+\n         with self.assertRaises(ValueError):\n             ops.convert_to_numpy(KerasTensor((2,)))\n \n\n@@ -2936,6 +2936,17 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         self.assertTrue(backend.is_tensor(knp.array(x)))\n         self.assertTrue(backend.is_tensor(knp.Array()(x)))\n \n+        # Check dtype convertion.\n+        x = [[1, 0, 1], [1, 1, 0]]\n+        output = knp.array(x, dtype=\"int32\")\n+        self.assertEqual(standardize_dtype(output.dtype), \"int32\")\n+        x = [[1, 0, 1], [1, 1, 0]]\n+        output = knp.array(x, dtype=\"float32\")\n+        self.assertEqual(standardize_dtype(output.dtype), \"float32\")\n+        x = [[1, 0, 1], [1, 1, 0]]\n+        output = knp.array(x, dtype=\"bool\")\n+        self.assertEqual(standardize_dtype(output.dtype), \"bool\")\n+\n     def test_average(self):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n         weights = np.ones([2, 3])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#21a3c0b7ce2bf738d81e3737aedba1a1ebd93c8b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 4601 | Contributors (this commit): 7 | Commits (past 90d): 45 | Contributors (cumulative): 16 | DMM Complexity: 1.0\n\nDIFF:\n@@ -129,6 +129,7 @@ def arange(start, stop=None, step=1, dtype=None):\n         if stop is not None:\n             dtypes_to_resolve.append(getattr(stop, \"dtype\", type(stop)))\n         dtype = dtypes.result_type(*dtypes_to_resolve)\n+    dtype = standardize_dtype(dtype)\n     return jnp.arange(start, stop, step=step, dtype=dtype)\n \n \n\n@@ -341,6 +341,7 @@ def arange(start, stop=None, step=1, dtype=None):\n         if stop is not None:\n             dtypes_to_resolve.append(getattr(stop, \"dtype\", type(stop)))\n         dtype = dtypes.result_type(*dtypes_to_resolve)\n+    dtype = standardize_dtype(dtype)\n     return tf.range(start, stop, delta=step, dtype=dtype)\n \n \n\n@@ -3891,6 +3891,9 @@ class NumpyArrayCreateOpsCorrectnessTest(testing.TestCase):\n         self.assertAllClose(knp.Arange()(3, 7, 2), np.arange(3, 7, 2))\n \n         self.assertEqual(standardize_dtype(knp.arange(3).dtype), \"int32\")\n+        with pytest.warns(None) as record:\n+            knp.arange(3, dtype=\"int\")\n+        self.assertEqual(len(record), 0)\n \n     def test_full(self):\n         self.assertAllClose(knp.full([2, 3], 0), np.full([2, 3], 0))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0cf88180a54adbb0b9bee3b5f44c027226544c1f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 65 | Lines Deleted: 17 | Files Changed: 2 | Hunks: 30 | Methods Changed: 11 | Complexity Δ (Sum/Max): 13/10 | Churn Δ: 82 | Churn Cumulative: 156 | Contributors (this commit): 2 | Commits (past 90d): 8 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -389,6 +389,8 @@ def load_image(\n     if crop_to_aspect_ratio:\n         from keras.backend import tensorflow as tf_backend\n \n+        if data_format == \"channels_first\":\n+            img = tf.transpose(img, (2, 0, 1))\n         img = image_utils.smart_resize(\n             img,\n             image_size,\n@@ -398,5 +400,10 @@ def load_image(\n         )\n     else:\n         img = tf.image.resize(img, image_size, method=interpolation)\n+        if data_format == \"channels_first\":\n+            img = tf.transpose(img, (2, 0, 1))\n+    if data_format == \"channels_last\":\n         img.set_shape((image_size[0], image_size[1], num_channels))\n+    else:\n+        img.set_shape((num_channels, image_size[0], image_size[1]))\n     return img\n\n@@ -2,6 +2,7 @@ import os\n \n import numpy as np\n \n+from keras import backend\n from keras import testing\n from keras.utils import image_dataset_utils\n from keras.utils import image_utils\n@@ -19,6 +20,8 @@ class ImageDatasetFromDirectoryTest(testing.TestCase):\n                 img = np.random.randint(0, 256, size=(height, width, 4))\n             else:\n                 img = np.random.randint(0, 256, size=(height, width, 3))\n+            if backend.config.image_data_format() == \"channels_first\":\n+                img = np.transpose(img, (2, 0, 1))\n             img = image_utils.array_to_img(img)\n             imgs.append(img)\n         return imgs\n@@ -76,10 +79,14 @@ class ImageDatasetFromDirectoryTest(testing.TestCase):\n         dataset = image_dataset_utils.image_dataset_from_directory(\n             directory, batch_size=5, image_size=(18, 18), labels=None\n         )\n+        if backend.config.image_data_format() == \"channels_last\":\n+            output_shape = [5, 18, 18, 3]\n+        else:\n+            output_shape = [5, 3, 18, 18]\n         self.assertEqual(dataset.class_names, None)\n         batch = next(iter(dataset))\n         # We return plain images\n-        self.assertEqual(batch.shape, (5, 18, 18, 3))\n+        self.assertEqual(batch.shape, output_shape)\n         self.assertEqual(batch.dtype.name, \"float32\")\n         # Count samples\n         batch_count = 0\n@@ -95,9 +102,13 @@ class ImageDatasetFromDirectoryTest(testing.TestCase):\n         dataset = image_dataset_utils.image_dataset_from_directory(\n             directory, batch_size=8, image_size=(18, 18), label_mode=\"int\"\n         )\n+        if backend.config.image_data_format() == \"channels_last\":\n+            output_shape = [8, 18, 18, 3]\n+        else:\n+            output_shape = [8, 3, 18, 18]\n         batch = next(iter(dataset))\n         self.assertLen(batch, 2)\n-        self.assertEqual(batch[0].shape, (8, 18, 18, 3))\n+        self.assertEqual(batch[0].shape, output_shape)\n         self.assertEqual(batch[0].dtype.name, \"float32\")\n         self.assertEqual(batch[1].shape, (8,))\n         self.assertEqual(batch[1].dtype.name, \"int32\")\n@@ -107,7 +118,7 @@ class ImageDatasetFromDirectoryTest(testing.TestCase):\n         )\n         batch = next(iter(dataset))\n         self.assertLen(batch, 2)\n-        self.assertEqual(batch[0].shape, (8, 18, 18, 3))\n+        self.assertEqual(batch[0].shape, output_shape)\n         self.assertEqual(batch[0].dtype.name, \"float32\")\n         self.assertEqual(batch[1].shape, (8, 1))\n         self.assertEqual(batch[1].dtype.name, \"float32\")\n@@ -120,7 +131,7 @@ class ImageDatasetFromDirectoryTest(testing.TestCase):\n         )\n         batch = next(iter(dataset))\n         self.assertLen(batch, 2)\n-        self.assertEqual(batch[0].shape, (8, 18, 18, 3))\n+        self.assertEqual(batch[0].shape, output_shape)\n         self.assertEqual(batch[0].dtype.name, \"float32\")\n         self.assertEqual(batch[1].shape, (8, 2))\n         self.assertEqual(batch[1].dtype.name, \"float32\")\n@@ -131,11 +142,15 @@ class ImageDatasetFromDirectoryTest(testing.TestCase):\n             directory, batch_size=8, image_size=(18, 18), label_mode=\"int\"\n         )\n         test_case = self\n+        if backend.config.image_data_format() == \"channels_last\":\n+            output_shape = [None, 18, 18, 3]\n+        else:\n+            output_shape = [None, 3, 18, 18]\n \n         @tf.function\n         def symbolic_fn(ds):\n             for x, _ in ds.take(1):\n-                test_case.assertListEqual(x.shape.as_list(), [None, 18, 18, 3])\n+                test_case.assertListEqual(x.shape.as_list(), output_shape)\n \n         symbolic_fn(dataset)\n \n@@ -155,8 +170,12 @@ class ImageDatasetFromDirectoryTest(testing.TestCase):\n         dataset = image_dataset_utils.image_dataset_from_directory(\n             directory, batch_size=8, image_size=(18, 18), label_mode=None\n         )\n+        if backend.config.image_data_format() == \"channels_last\":\n+            output_shape = [8, 18, 18, 3]\n+        else:\n+            output_shape = [8, 3, 18, 18]\n         batch = next(iter(dataset))\n-        self.assertEqual(batch.shape, (8, 18, 18, 3))\n+        self.assertEqual(batch.shape, output_shape)\n \n         dataset = image_dataset_utils.image_dataset_from_directory(\n             directory, batch_size=8, image_size=(18, 18), label_mode=None\n@@ -172,7 +191,7 @@ class ImageDatasetFromDirectoryTest(testing.TestCase):\n         )\n         batch = next(iter(dataset))\n         self.assertLen(batch, 2)\n-        self.assertEqual(batch[0].shape, (8, 18, 18, 3))\n+        self.assertEqual(batch[0].shape, output_shape)\n         self.assertEqual(batch[0].dtype.name, \"float32\")\n         self.assertEqual(batch[1].shape, (8,))\n         self.assertEqual(batch[1].dtype.name, \"int32\")\n@@ -185,7 +204,7 @@ class ImageDatasetFromDirectoryTest(testing.TestCase):\n         )\n         batch = next(iter(dataset))\n         self.assertLen(batch, 2)\n-        self.assertEqual(batch[0].shape, (8, 18, 18, 3))\n+        self.assertEqual(batch[0].shape, (output_shape))\n         self.assertEqual(batch[0].dtype.name, \"float32\")\n         self.assertEqual(batch[1].shape, (8, 4))\n         self.assertEqual(batch[1].dtype.name, \"float32\")\n@@ -195,9 +214,13 @@ class ImageDatasetFromDirectoryTest(testing.TestCase):\n         dataset = image_dataset_utils.image_dataset_from_directory(\n             directory, batch_size=8, image_size=(18, 18), color_mode=\"rgba\"\n         )\n+        if backend.config.image_data_format() == \"channels_last\":\n+            output_shape = [8, 18, 18, 4]\n+        else:\n+            output_shape = [8, 4, 18, 18]\n         batch = next(iter(dataset))\n         self.assertLen(batch, 2)\n-        self.assertEqual(batch[0].shape, (8, 18, 18, 4))\n+        self.assertEqual(batch[0].shape, output_shape)\n         self.assertEqual(batch[0].dtype.name, \"float32\")\n \n         directory = self._prepare_directory(\n@@ -206,9 +229,13 @@ class ImageDatasetFromDirectoryTest(testing.TestCase):\n         dataset = image_dataset_utils.image_dataset_from_directory(\n             directory, batch_size=8, image_size=(18, 18), color_mode=\"grayscale\"\n         )\n+        if backend.config.image_data_format() == \"channels_last\":\n+            output_shape = [8, 18, 18, 1]\n+        else:\n+            output_shape = [8, 1, 18, 18]\n         batch = next(iter(dataset))\n         self.assertLen(batch, 2)\n-        self.assertEqual(batch[0].shape, (8, 18, 18, 1))\n+        self.assertEqual(batch[0].shape, output_shape)\n         self.assertEqual(batch[0].dtype.name, \"float32\")\n \n     def test_image_dataset_from_directory_validation_split(self):\n@@ -223,7 +250,13 @@ class ImageDatasetFromDirectoryTest(testing.TestCase):\n         )\n         batch = next(iter(dataset))\n         self.assertLen(batch, 2)\n-        self.assertEqual(batch[0].shape, (8, 18, 18, 3))\n+        if backend.config.image_data_format() == \"channels_last\":\n+            train_output_shape = [8, 18, 18, 3]\n+            val_output_shape = [2, 18, 18, 3]\n+        else:\n+            train_output_shape = [8, 3, 18, 18]\n+            val_output_shape = [2, 3, 18, 18]\n+        self.assertEqual(batch[0].shape, train_output_shape)\n         dataset = image_dataset_utils.image_dataset_from_directory(\n             directory,\n             batch_size=10,\n@@ -234,7 +267,7 @@ class ImageDatasetFromDirectoryTest(testing.TestCase):\n         )\n         batch = next(iter(dataset))\n         self.assertLen(batch, 2)\n-        self.assertEqual(batch[0].shape, (2, 18, 18, 3))\n+        self.assertEqual(batch[0].shape, val_output_shape)\n \n         (\n             train_dataset,\n@@ -249,10 +282,10 @@ class ImageDatasetFromDirectoryTest(testing.TestCase):\n         )\n         batch = next(iter(train_dataset))\n         self.assertLen(batch, 2)\n-        self.assertEqual(batch[0].shape, (8, 18, 18, 3))\n+        self.assertEqual(batch[0].shape, train_output_shape)\n         batch = next(iter(val_dataset))\n         self.assertLen(batch, 2)\n-        self.assertEqual(batch[0].shape, (2, 18, 18, 3))\n+        self.assertEqual(batch[0].shape, val_output_shape)\n \n     def test_image_dataset_from_directory_manual_labels(self):\n         # Case: wrong number of labels\n@@ -275,10 +308,14 @@ class ImageDatasetFromDirectoryTest(testing.TestCase):\n             labels=[0, 1, 0, 1],\n             shuffle=False,\n         )\n+        if backend.config.image_data_format() == \"channels_last\":\n+            output_shape = [18, 18, 3]\n+        else:\n+            output_shape = [3, 18, 18]\n         self.assertEqual(dataset.class_names, [\"0\", \"1\"])\n         batch = next(iter(dataset))\n         self.assertLen(batch, 2)\n-        self.assertEqual(batch[0].shape, (4, 18, 18, 3))\n+        self.assertEqual(batch[0].shape, [4] + output_shape)\n         self.assertAllClose(batch[1], [0, 1, 0, 1])\n \n         # Case: multiple directories\n@@ -293,7 +330,7 @@ class ImageDatasetFromDirectoryTest(testing.TestCase):\n         self.assertEqual(dataset.class_names, [\"0\", \"1\"])\n         batch = next(iter(dataset))\n         self.assertLen(batch, 2)\n-        self.assertEqual(batch[0].shape, (6, 18, 18, 3))\n+        self.assertEqual(batch[0].shape, [6] + output_shape)\n         self.assertAllClose(batch[1], [0, 1, 0, 1, 1, 1])\n \n     def test_image_dataset_from_directory_follow_links(self):\n@@ -325,9 +362,13 @@ class ImageDatasetFromDirectoryTest(testing.TestCase):\n             image_size=(18, 18),\n             crop_to_aspect_ratio=True,\n         )\n+        if backend.config.image_data_format() == \"channels_last\":\n+            output_shape = [5, 18, 18, 3]\n+        else:\n+            output_shape = [5, 3, 18, 18]\n         batch = next(iter(dataset))\n         self.assertLen(batch, 2)\n-        self.assertEqual(batch[0].shape, (5, 18, 18, 3))\n+        self.assertEqual(batch[0].shape, output_shape)\n \n     def test_image_dataset_from_directory_errors(self):\n         directory = self._prepare_directory(num_classes=3, count=5)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6936412a184b97cd5283f79b1091e242848cb518", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 24 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 5 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 32 | Churn Cumulative: 38 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -109,20 +109,36 @@ class PyDatasetAdapterTest(testing.TestCase, parameterized.TestCase):\n     def test_speedup(self):\n         x = np.random.random((40, 4))\n         y = np.random.random((40, 2))\n-        py_dataset = ExamplePyDataset(\n+\n+        no_speedup_py_dataset = ExamplePyDataset(\n+            x,\n+            y,\n+            batch_size=4,\n+            delay=0.2,\n+        )\n+        adapter = py_dataset_adapter.PyDatasetAdapter(\n+            no_speedup_py_dataset, shuffle=False\n+        )\n+        t0 = time.time()\n+        for batch in adapter.get_numpy_iterator():\n+            pass\n+        no_speed_up_time = time.time() - t0\n+\n+        speedup_py_dataset = ExamplePyDataset(\n             x,\n             y,\n             batch_size=4,\n             workers=4,\n             use_multiprocessing=True,\n             max_queue_size=8,\n-            delay=1.0,\n+            delay=0.2,\n+        )\n+        adapter = py_dataset_adapter.PyDatasetAdapter(\n+            speedup_py_dataset, shuffle=False\n         )\n-        adapter = py_dataset_adapter.PyDatasetAdapter(py_dataset, shuffle=False)\n-        gen = adapter.get_numpy_iterator()\n         t0 = time.time()\n-        for batch in gen:\n+        for batch in adapter.get_numpy_iterator():\n             pass\n-        # With non-parallel iteration it should take at least 10s (+ overhead).\n-        # We check it took less than 8s.\n-        self.assertLess(time.time() - t0, 8)\n+        speed_up_time = time.time() - t0\n+\n+        self.assertLess(speed_up_time, no_speed_up_time)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ca337b3180273f2d2e82454176df66356b32294c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 39 | Lines Deleted: 10 | Files Changed: 2 | Hunks: 11 | Methods Changed: 6 | Complexity Δ (Sum/Max): 5/5 | Churn Δ: 49 | Churn Cumulative: 65 | Contributors (this commit): 2 | Commits (past 90d): 4 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -53,7 +53,7 @@ class RandomCrop(TFDataLayer):\n         self.data_format = backend.standardize_data_format(data_format)\n \n         if self.data_format == \"channels_first\":\n-            self.heigh_axis = -2\n+            self.height_axis = -2\n             self.width_axis = -1\n         elif self.data_format == \"channels_last\":\n             self.height_axis = -3\n\n@@ -1,6 +1,7 @@\n import numpy as np\n from tensorflow import data as tf_data\n \n+from keras import backend\n from keras import layers\n from keras import testing\n \n@@ -21,54 +22,82 @@ class RandomCropTest(testing.TestCase):\n     def test_random_crop_full(self):\n         np.random.seed(1337)\n         height, width = 8, 16\n-        inp = np.random.random((12, 8, 16, 3))\n+        if backend.config.image_data_format() == \"channels_last\":\n+            input_shape = (12, 8, 16, 3)\n+        else:\n+            input_shape = (12, 3, 8, 16)\n+        inp = np.random.random(input_shape)\n         layer = layers.RandomCrop(height, width)\n         actual_output = layer(inp, training=False)\n         self.assertAllClose(inp, actual_output)\n \n     def test_random_crop_partial(self):\n+        if backend.config.image_data_format() == \"channels_last\":\n+            input_shape = (12, 8, 16, 3)\n+            output_shape = (12, 8, 8, 3)\n+        else:\n+            input_shape = (12, 3, 8, 16)\n+            output_shape = (12, 3, 8, 8)\n         self.run_layer_test(\n             layers.RandomCrop,\n             init_kwargs={\n                 \"height\": 8,\n                 \"width\": 8,\n             },\n-            input_shape=(12, 8, 16, 3),\n-            expected_output_shape=(12, 8, 8, 3),\n+            input_shape=input_shape,\n+            expected_output_shape=output_shape,\n             supports_masking=False,\n             run_training_check=False,\n         )\n \n     def test_predicting_with_longer_height(self):\n+        if backend.config.image_data_format() == \"channels_last\":\n+            input_shape = (12, 8, 16, 3)\n+            output_shape = (12, 10, 8, 3)\n+        else:\n+            input_shape = (12, 3, 8, 16)\n+            output_shape = (12, 3, 10, 8)\n         self.run_layer_test(\n             layers.RandomCrop,\n             init_kwargs={\n                 \"height\": 10,\n                 \"width\": 8,\n             },\n-            input_shape=(12, 8, 16, 3),\n-            expected_output_shape=(12, 10, 8, 3),\n+            input_shape=input_shape,\n+            expected_output_shape=output_shape,\n             supports_masking=False,\n             run_training_check=False,\n         )\n \n     def test_predicting_with_longer_width(self):\n+        if backend.config.image_data_format() == \"channels_last\":\n+            input_shape = (12, 8, 16, 3)\n+            output_shape = (12, 8, 18, 3)\n+        else:\n+            input_shape = (12, 3, 8, 16)\n+            output_shape = (12, 3, 8, 18)\n         self.run_layer_test(\n             layers.RandomCrop,\n             init_kwargs={\n                 \"height\": 8,\n                 \"width\": 18,\n             },\n-            input_shape=(12, 8, 16, 3),\n-            expected_output_shape=(12, 8, 18, 3),\n+            input_shape=input_shape,\n+            expected_output_shape=output_shape,\n             supports_masking=False,\n             run_training_check=False,\n         )\n \n     def test_tf_data_compatibility(self):\n         layer = layers.RandomCrop(8, 9)\n-        input_data = np.random.random((2, 10, 12, 3))\n+        if backend.config.image_data_format() == \"channels_last\":\n+            input_shape = (2, 10, 12, 3)\n+            output_shape = (2, 8, 9, 3)\n+        else:\n+            input_shape = (2, 3, 10, 12)\n+            output_shape = (2, 3, 8, 9)\n+        input_data = np.random.random(input_shape)\n         ds = tf_data.Dataset.from_tensor_slices(input_data).batch(2).map(layer)\n         for output in ds.take(1):\n             output = output.numpy()\n-        self.assertEqual(list(output.shape), [2, 8, 9, 3])\n+        self.assertEqual(tuple(output.shape), output_shape)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e5dddf84ba446c715a20557e76c9fad60aaa7307", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 36 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 12 | Methods Changed: 4 | Complexity Δ (Sum/Max): 5/5 | Churn Δ: 42 | Churn Cumulative: 46 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -3,20 +3,34 @@ import pytest\n from absl.testing import parameterized\n from tensorflow import data as tf_data\n \n+from keras import backend\n from keras import layers\n from keras import testing\n \n \n class CenterCropTest(testing.TestCase, parameterized.TestCase):\n-    def np_center_crop(self, img, h_new, w_new):\n+    def np_center_crop(self, img, h_new, w_new, data_format=\"channels_last\"):\n         img = np.array(img)\n         if img.ndim == 4:\n+            if data_format == \"channels_last\":\n                 _, h, w = img.shape[:3]\n             else:\n+                _, h, w = img.shape[1:]\n+        else:\n+            if data_format == \"channels_last\":\n                 h, w = img.shape[:2]\n+            else:\n+                h, w = img.shape[1:]\n         h_start = (h - h_new) // 2\n         w_start = (w - w_new) // 2\n-        return img[..., h_start : h_start + h_new, w_start : w_start + w_new, :]\n+        if data_format == \"channels_last\":\n+            return img[\n+                ..., h_start : h_start + h_new, w_start : w_start + w_new, :\n+            ]\n+        else:\n+            return img[\n+                ..., h_start : h_start + h_new, w_start : w_start + w_new\n+            ]\n \n     @pytest.mark.requires_trainable_backend\n     def test_center_crop_basics(self):\n@@ -148,19 +162,35 @@ class CenterCropTest(testing.TestCase, parameterized.TestCase):\n         self.assertAllClose(ref_out, out)\n \n     def test_tf_data_compatibility(self):\n+        if backend.config.image_data_format() == \"channels_last\":\n+            input_shape = (2, 10, 12, 3)\n+            output_shape = (2, 8, 9, 3)\n+        else:\n+            input_shape = (2, 3, 10, 12)\n+            output_shape = (2, 3, 8, 9)\n         layer = layers.CenterCrop(8, 9)\n-        input_data = np.random.random((2, 10, 12, 3))\n+        input_data = np.random.random(input_shape)\n         ds = tf_data.Dataset.from_tensor_slices(input_data).batch(2).map(layer)\n         for output in ds.take(1):\n             output = output.numpy()\n-        self.assertEqual(list(output.shape), [2, 8, 9, 3])\n+        self.assertEqual(tuple(output.shape), output_shape)\n \n     def test_list_compatibility(self):\n+        if backend.config.image_data_format() == \"channels_last\":\n             images = [\n                 np.random.rand(10, 10, 3),\n                 np.random.rand(10, 10, 3),\n             ]\n+            output_shape = (2, 6, 5, 3)\n+        else:\n+            images = [\n+                np.random.rand(3, 10, 10),\n+                np.random.rand(3, 10, 10),\n+            ]\n+            output_shape = (2, 3, 6, 5)\n         output = layers.CenterCrop(height=6, width=5)(images)\n-        ref_output = self.np_center_crop(images, 6, 5)\n-        self.assertListEqual(list(output.shape), [2, 6, 5, 3])\n+        ref_output = self.np_center_crop(\n+            images, 6, 5, data_format=backend.config.image_data_format()\n+        )\n+        self.assertEqual(tuple(output.shape), output_shape)\n         self.assertAllClose(ref_output, output)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ce9c0952b8129a65673639746802e9e5cf179b2c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 5 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 475 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -1,11 +1,11 @@\n \"\"\"\n Title: CutMix data augmentation for image classification\n Author: [Sayan Nath](https://twitter.com/sayannath2350)\n-Converted to Keras 3 By: [Piyush Thakur](https://github.com/cosmo3769)\n Date created: 2021/06/08\n-Last modified: 2023/07/24\n+Last modified: 2023/11/14\n Description: Data augmentation with CutMix for image classification on CIFAR-10.\n Accelerator: GPU\n+Converted to Keras 3 By: [Piyush Thakur](https://github.com/cosmo3769)\n \"\"\"\n \n \"\"\"\n@@ -47,7 +47,6 @@ where `rx, ry` are randomly drawn from a uniform distribution with upper bound.\n \"\"\"\n \n import numpy as np\n-import pandas as pd\n import keras\n import matplotlib.pyplot as plt\n \n@@ -147,7 +146,10 @@ test_ds = (\n \"\"\"\n ## Define the CutMix data augmentation function\n \n-The CutMix function takes two `image` and `label` pairs to perform the augmentation. It samples `λ(l)` from the [Beta distribution](https://en.wikipedia.org/wiki/Beta_distribution) and returns a bounding box from `get_box` function. We then crop the second image (`image2`) and pad this image in the final padded image at the same location.\n+The CutMix function takes two `image` and `label` pairs to perform the augmentation.\n+It samples `λ(l)` from the [Beta distribution](https://en.wikipedia.org/wiki/Beta_distribution)\n+and returns a bounding box from `get_box` function. We then crop the second image (`image2`)\n+and pad this image in the final padded image at the same location.\n \"\"\"\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a47c586b0e8c7d15d6550c7737404d5f0b4dac19", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 487 | Contributors (this commit): 3 | Commits (past 90d): 4 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -105,7 +105,7 @@ IMG_SIZE = 32\n def preprocess_image(image, label):\n     image = tf_image.resize(image, (IMG_SIZE, IMG_SIZE))\n     image = tf_image.convert_image_dtype(image, \"float32\") / 255.0\n-    label = keras.backend.cast(label, dtype=\"float32\")\n+    label = keras.ops.cast(label, dtype=\"float32\")\n     return image, label\n \n \n@@ -163,15 +163,15 @@ def get_box(lambda_value):\n     cut_rat = keras.ops.sqrt(1.0 - lambda_value)\n \n     cut_w = IMG_SIZE * cut_rat  # rw\n-    cut_w = keras.backend.cast(cut_w, \"int32\")\n+    cut_w = keras.ops.cast(cut_w, \"int32\")\n \n     cut_h = IMG_SIZE * cut_rat  # rh\n-    cut_h = keras.backend.cast(cut_h, \"int32\")\n+    cut_h = keras.ops.cast(cut_h, \"int32\")\n \n     cut_x = keras.random.random.uniform((1,), minval=0, maxval=IMG_SIZE)  # rx\n-    cut_x = keras.backend.cast(cut_x, \"int32\")\n+    cut_x = keras.ops.cast(cut_x, \"int32\")\n     cut_y = keras.random.random.uniform((1,), minval=0, maxval=IMG_SIZE)  # ry\n-    cut_y = keras.backend.cast(cut_y, \"int32\")\n+    cut_y = keras.ops.cast(cut_y, \"int32\")\n \n     boundaryx1 = clip_by_value(cut_x[0] - cut_w // 2, 0, IMG_SIZE)\n     boundaryy1 = clip_by_value(cut_y[0] - cut_h // 2, 0, IMG_SIZE)\n@@ -229,7 +229,7 @@ def cutmix(train_ds_one, train_ds_two):\n \n     # Adjust Lambda in accordance to the pixel ration\n     lambda_value = 1 - (target_w * target_h) / (IMG_SIZE * IMG_SIZE)\n-    lambda_value = keras.backend.cast(lambda_value, \"float32\")\n+    lambda_value = keras.ops.cast(lambda_value, \"float32\")\n \n     # Combine the labels of both images\n     label = lambda_value * label1 + (1 - lambda_value) * label2\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
