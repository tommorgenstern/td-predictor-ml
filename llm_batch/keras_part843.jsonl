{"custom_id": "keras#0a550691fe44b69edb71f7b48ccd0a0fed9b853e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 4 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 501 | Contributors (this commit): 2 | Commits (past 90d): 4 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -139,6 +139,9 @@ from keras.src.layers.preprocessing.category_encoding import CategoryEncoding\n from keras.src.layers.preprocessing.discretization import Discretization\n from keras.src.layers.preprocessing.hashed_crossing import HashedCrossing\n from keras.src.layers.preprocessing.hashing import Hashing\n+from keras.src.layers.preprocessing.image_preprocessing.auto_contrast import (\n+    AutoContrast,\n+)\n from keras.src.layers.preprocessing.image_preprocessing.center_crop import (\n     CenterCrop,\n )\n@@ -164,6 +167,9 @@ from keras.src.layers.preprocessing.image_preprocessing.random_zoom import (\n     RandomZoom,\n )\n from keras.src.layers.preprocessing.image_preprocessing.resizing import Resizing\n+from keras.src.layers.preprocessing.image_preprocessing.solarization import (\n+    Solarization,\n+)\n from keras.src.layers.preprocessing.integer_lookup import IntegerLookup\n from keras.src.layers.preprocessing.mel_spectrogram import MelSpectrogram\n from keras.src.layers.preprocessing.normalization import Normalization\n\n@@ -139,6 +139,9 @@ from keras.src.layers.preprocessing.category_encoding import CategoryEncoding\n from keras.src.layers.preprocessing.discretization import Discretization\n from keras.src.layers.preprocessing.hashed_crossing import HashedCrossing\n from keras.src.layers.preprocessing.hashing import Hashing\n+from keras.src.layers.preprocessing.image_preprocessing.auto_contrast import (\n+    AutoContrast,\n+)\n from keras.src.layers.preprocessing.image_preprocessing.center_crop import (\n     CenterCrop,\n )\n@@ -164,6 +167,9 @@ from keras.src.layers.preprocessing.image_preprocessing.random_zoom import (\n     RandomZoom,\n )\n from keras.src.layers.preprocessing.image_preprocessing.resizing import Resizing\n+from keras.src.layers.preprocessing.image_preprocessing.solarization import (\n+    Solarization,\n+)\n from keras.src.layers.preprocessing.integer_lookup import IntegerLookup\n from keras.src.layers.preprocessing.mel_spectrogram import MelSpectrogram\n from keras.src.layers.preprocessing.normalization import Normalization\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4c33773871d3cd484bade9a52d5013a666664886", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 11/11 | Churn Δ: 7 | Churn Cumulative: 7 | Contributors (this commit): 1 | Commits (past 90d): 2 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -53,6 +53,7 @@ class RandomFlipTest(testing.TestCase, parameterized.TestCase):\n             MockedRandomFlip,\n             init_kwargs={\n                 \"mode\": \"horizontal\",\n+                \"data_format\": \"channels_last\",\n                 \"seed\": 42,\n             },\n             input_data=np.asarray([[[2, 3, 4], [5, 6, 7]]]),\n@@ -65,6 +66,7 @@ class RandomFlipTest(testing.TestCase, parameterized.TestCase):\n             MockedRandomFlip,\n             init_kwargs={\n                 \"mode\": \"horizontal\",\n+                \"data_format\": \"channels_last\",\n                 \"seed\": 42,\n             },\n             input_data=np.asarray(\n@@ -91,6 +93,7 @@ class RandomFlipTest(testing.TestCase, parameterized.TestCase):\n             MockedRandomFlip,\n             init_kwargs={\n                 \"mode\": \"vertical\",\n+                \"data_format\": \"channels_last\",\n                 \"seed\": 42,\n             },\n             input_data=np.asarray([[[2, 3, 4]], [[5, 6, 7]]]),\n@@ -131,7 +134,9 @@ class RandomFlipTest(testing.TestCase, parameterized.TestCase):\n \n     def test_tf_data_compatibility(self):\n         # Test 3D input: shape (2, 1, 3)\n-        layer = layers.RandomFlip(\"vertical\", seed=42)\n+        layer = layers.RandomFlip(\n+            \"vertical\", data_format=\"channels_last\", seed=42\n+        )\n         input_data = np.array([[[2, 3, 4]], [[5, 6, 7]]])\n         expected_output = np.array([[[5, 6, 7]], [[2, 3, 4]]])\n         ds = tf_data.Dataset.from_tensor_slices(input_data).batch(2).map(layer)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#dd5f870ecf4f37078074fe9f44e390625f77db4e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 12 | Contributors (this commit): 1 | Commits (past 90d): 3 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -108,6 +108,7 @@ class RandomFlipTest(testing.TestCase, parameterized.TestCase):\n             MockedRandomFlip,\n             init_kwargs={\n                 \"mode\": \"vertical\",\n+                \"data_format\": \"channels_last\",\n                 \"seed\": 42,\n             },\n             input_data=np.asarray(\n@@ -144,7 +145,9 @@ class RandomFlipTest(testing.TestCase, parameterized.TestCase):\n             output = output.numpy()\n         self.assertAllClose(output, expected_output)\n         # Test 4D input: shape (2, 2, 1, 3)\n-        layer = layers.RandomFlip(\"vertical\", seed=42)\n+        layer = layers.RandomFlip(\n+            \"vertical\", data_format=\"channels_last\", seed=42\n+        )\n         input_data = np.array(\n             [\n                 [\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#dd80697a431826f4b9c8f503e03efd3079d6e56f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 101 | Contributors (this commit): 1 | Commits (past 90d): 2 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -90,6 +90,6 @@ class AutoContrastTest(testing.TestCase, parameterized.TestCase):\n \n         layer = layers.AutoContrast(value_range=(0, 1))\n         ys = layer(img)\n-\n-        self.assertTrue(np.any(ops.convert_to_numpy(ys[0]) == 0.0))\n-        self.assertTrue(np.any(ops.convert_to_numpy(ys[0]) == 1.0))\n+        self.assertAllClose(\n+            ops.convert_to_numpy(ys[0]), np.array([[[0.0]], [[1]]])\n+        )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#86a78b11b754f145b883250b4e00c4edb811a5b7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 122 | Lines Deleted: 119 | Files Changed: 89 | Hunks: 121 | Methods Changed: 2 | Complexity Δ (Sum/Max): 65/21 | Churn Δ: 241 | Churn Cumulative: 11288 | Contributors (this commit): 24 | Commits (past 90d): 230 | Contributors (cumulative): 269 | DMM Complexity: 1.0\n\nDIFF:\n@@ -118,7 +118,7 @@ def _get_elephant(target_size):\n     reason=\"Env variable set to skip.\",\n )\n @pytest.mark.requires_trainable_backend\n-class ApplicationsTest(testing.TestCase, parameterized.TestCase):\n+class ApplicationsTest(testing.TestCase):\n     @classmethod\n     def setUpClass(cls):\n         cls.original_image_data_format = backend.image_data_format()\n\n@@ -9,7 +9,7 @@ from keras.src.applications import imagenet_utils as utils\n from keras.src.dtype_policies.dtype_policy import set_dtype_policy\n \n \n-class TestImageNetUtils(testing.TestCase, parameterized.TestCase):\n+class TestImageNetUtils(testing.TestCase):\n     def test_preprocess_input(self):\n         # Test invalid mode check\n         x = np.random.uniform(0, 255, (10, 10, 3))\n\n@@ -9,7 +9,7 @@ from keras.src.testing import test_case\n from keras.src.testing.test_utils import named_product\n \n \n-class DtypesTest(test_case.TestCase, parameterized.TestCase):\n+class DtypesTest(test_case.TestCase):\n     \"\"\"Test the dtype to verify that the behavior matches JAX.\"\"\"\n \n     if backend.backend() == \"torch\":\n\n@@ -81,7 +81,7 @@ class VariableInitializationTest(test_case.TestCase):\n             KerasVariable(initializer=lambda: np.ones((2, 2)))\n \n \n-class VariablePropertiesTest(test_case.TestCase, parameterized.TestCase):\n+class VariablePropertiesTest(test_case.TestCase):\n     \"\"\"Tests for KerasVariable._deferred_initialize\n     KerasVariable._maybe_autocast\"\"\"\n \n@@ -665,7 +665,7 @@ class VariableOpsBehaviorTest(test_case.TestCase):\n             float(v)\n \n \n-class VariableOpsDTypeTest(test_case.TestCase, parameterized.TestCase):\n+class VariableOpsDTypeTest(test_case.TestCase):\n     \"\"\"Test the dtype to verify that the behavior matches JAX.\"\"\"\n \n     # TODO: Using uint64 will lead to weak type promotion (`float`),\n\n@@ -15,7 +15,7 @@ from keras.src.optimizers.sgd import SGD\n     backend.backend() != \"tensorflow\",\n     reason=\"The distribute test can only run with TF backend.\",\n )\n-class OptimizerDistributeTest(testing.TestCase, parameterized.TestCase):\n+class OptimizerDistributeTest(testing.TestCase):\n     def setUp(self):\n         super().setUp()\n         # Need at least 2 devices for distribution related tests.\n\n@@ -52,7 +52,7 @@ class CustomSignatureModel(models.Model):\n     backend.backend() != \"tensorflow\",\n     reason=\"The SavedModel test can only run with TF backend.\",\n )\n-class SavedModelTest(testing.TestCase, parameterized.TestCase):\n+class SavedModelTest(testing.TestCase):\n     def test_sequential(self):\n         model = models.Sequential([layers.Dense(1)])\n         model.compile(loss=\"mse\", optimizer=\"adam\")\n\n@@ -12,7 +12,7 @@ from keras.src.dtype_policies.dtype_policy import set_dtype_policy\n from keras.src.testing import test_case\n \n \n-class DTypePolicyTest(test_case.TestCase, parameterized.TestCase):\n+class DTypePolicyTest(test_case.TestCase):\n     \"\"\"Test `DTypePolicy`.\n \n     In the tests, we also test `DTypePolicy` for historical reasons.\n@@ -227,7 +227,7 @@ class DTypePolicyTest(test_case.TestCase, parameterized.TestCase):\n         )\n \n \n-class QuantizedDTypePolicyTest(test_case.TestCase, parameterized.TestCase):\n+class QuantizedDTypePolicyTest(test_case.TestCase):\n     def setUp(self):\n         \"\"\"Record the global dtype policy before each test.\"\"\"\n         super().setUp()\n\n@@ -53,7 +53,7 @@ def get_model(type=\"sequential\", input_shape=(10,), layer_list=None):\n     backend.backend() not in (\"tensorflow\", \"jax\"),\n     reason=\"Export only currently supports the TF and JAX backends.\",\n )\n-class ExportArchiveTest(testing.TestCase, parameterized.TestCase):\n+class ExportArchiveTest(testing.TestCase):\n     @parameterized.named_parameters(\n         named_product(model_type=[\"sequential\", \"functional\", \"subclass\"])\n     )\n\n@@ -117,6 +117,7 @@ from keras.src.layers.preprocessing.index_lookup import IndexLookup\n from keras.src.layers.preprocessing.integer_lookup import IntegerLookup\n from keras.src.layers.preprocessing.mel_spectrogram import MelSpectrogram\n from keras.src.layers.preprocessing.normalization import Normalization\n+from keras.src.layers.preprocessing.pipeline import Pipeline\n from keras.src.layers.preprocessing.rescaling import Rescaling\n from keras.src.layers.preprocessing.string_lookup import StringLookup\n from keras.src.layers.preprocessing.text_vectorization import TextVectorization\n\n@@ -8,7 +8,7 @@ from keras.src import layers\n from keras.src import testing\n \n \n-class GroupedQueryAttentionTest(testing.TestCase, parameterized.TestCase):\n+class GroupedQueryAttentionTest(testing.TestCase):\n     def test_basics(self):\n         self.run_layer_test(\n             layers.GroupedQueryAttention,\n\n@@ -14,7 +14,7 @@ from keras.src import saving\n from keras.src import testing\n \n \n-class MultiHeadAttentionTest(testing.TestCase, parameterized.TestCase):\n+class MultiHeadAttentionTest(testing.TestCase):\n     def test_basics(self):\n         self.run_layer_test(\n             layers.MultiHeadAttention,\n\n@@ -276,7 +276,7 @@ def np_conv3d(\n     return out\n \n \n-class ConvBasicTest(testing.TestCase, parameterized.TestCase):\n+class ConvBasicTest(testing.TestCase):\n     @parameterized.parameters(\n         {\n             \"filters\": 5,\n@@ -758,7 +758,7 @@ class ConvBasicTest(testing.TestCase, parameterized.TestCase):\n         )\n \n \n-class ConvCorrectnessTest(testing.TestCase, parameterized.TestCase):\n+class ConvCorrectnessTest(testing.TestCase):\n     @parameterized.parameters(\n         {\n             \"filters\": 5,\n\n@@ -286,7 +286,7 @@ def np_conv3d_transpose(\n     return output\n \n \n-class ConvTransposeBasicTest(testing.TestCase, parameterized.TestCase):\n+class ConvTransposeBasicTest(testing.TestCase):\n     @parameterized.parameters(\n         {\n             \"filters\": 5,\n@@ -546,7 +546,7 @@ class ConvTransposeBasicTest(testing.TestCase, parameterized.TestCase):\n             )\n \n \n-class ConvTransposeCorrectnessTest(testing.TestCase, parameterized.TestCase):\n+class ConvTransposeCorrectnessTest(testing.TestCase):\n     @parameterized.parameters(\n         {\n             \"filters\": 5,\n\n@@ -166,7 +166,7 @@ def np_depthwise_conv2d(\n     return out\n \n \n-class DepthwiseConvBasicTest(testing.TestCase, parameterized.TestCase):\n+class DepthwiseConvBasicTest(testing.TestCase):\n     @parameterized.parameters(\n         {\n             \"depth_multiplier\": 5,\n@@ -336,7 +336,7 @@ class DepthwiseConvBasicTest(testing.TestCase, parameterized.TestCase):\n             )\n \n \n-class DepthwiseConvCorrectnessTest(testing.TestCase, parameterized.TestCase):\n+class DepthwiseConvCorrectnessTest(testing.TestCase):\n     @parameterized.parameters(\n         {\n             \"depth_multiplier\": 5,\n\n@@ -14,7 +14,7 @@ from keras.src.layers.convolutional.depthwise_conv_test import (\n )\n \n \n-class SeparableConvBasicTest(testing.TestCase, parameterized.TestCase):\n+class SeparableConvBasicTest(testing.TestCase):\n     @parameterized.parameters(\n         {\n             \"depth_multiplier\": 5,\n@@ -208,7 +208,7 @@ class SeparableConvBasicTest(testing.TestCase, parameterized.TestCase):\n             )\n \n \n-class SeparableConvCorrectnessTest(testing.TestCase, parameterized.TestCase):\n+class SeparableConvCorrectnessTest(testing.TestCase):\n     @parameterized.parameters(\n         {\n             \"depth_multiplier\": 5,\n\n@@ -17,7 +17,7 @@ from keras.src.backend.common import keras_tensor\n from keras.src.export import export_lib\n \n \n-class DenseTest(testing.TestCase, parameterized.TestCase):\n+class DenseTest(testing.TestCase):\n     @pytest.mark.requires_trainable_backend\n     def test_dense_basics(self):\n         # 2D case, no bias.\n\n@@ -16,7 +16,7 @@ from keras.src import testing\n from keras.src.export import export_lib\n \n \n-class EinsumDenseTest(testing.TestCase, parameterized.TestCase):\n+class EinsumDenseTest(testing.TestCase):\n     @parameterized.named_parameters(\n         {\n             \"testcase_name\": \"_1d_end_weight\",\n\n@@ -14,7 +14,7 @@ from keras.src.export import export_lib\n from keras.src.testing import test_case\n \n \n-class EmbeddingTest(test_case.TestCase, parameterized.TestCase):\n+class EmbeddingTest(test_case.TestCase):\n     @pytest.mark.requires_trainable_backend\n     def test_embedding_basics(self):\n         self.run_layer_test(\n\n@@ -6,7 +6,7 @@ from keras.src import layers\n from keras.src import testing\n \n \n-class IdentityTest(testing.TestCase, parameterized.TestCase):\n+class IdentityTest(testing.TestCase):\n     @parameterized.named_parameters(\n         [\n             {\"testcase_name\": \"dense\", \"sparse\": False},\n\n@@ -7,7 +7,7 @@ from keras.src.backend import KerasTensor\n from keras.src.layers import InputLayer\n \n \n-class InputLayerTest(testing.TestCase, parameterized.TestCase):\n+class InputLayerTest(testing.TestCase):\n     # Testing happy path for layer without input tensor\n     @parameterized.named_parameters(\n         [\n\n@@ -14,7 +14,7 @@ from keras.src import testing\n from keras.src.backend.common import global_state\n \n \n-class LayerTest(testing.TestCase, parameterized.TestCase):\n+class LayerTest(testing.TestCase):\n \n     def test_compute_output_spec(self):\n         # Test that implementing compute_output_shape\n\n@@ -77,7 +77,7 @@ TEST_PARAMETERS = [\n \n \n @pytest.mark.requires_trainable_backend\n-class MergingLayersTest(testing.TestCase, parameterized.TestCase):\n+class MergingLayersTest(testing.TestCase):\n     @parameterized.named_parameters(TEST_PARAMETERS)\n     def test_basic(\n         self,\n\n@@ -10,7 +10,7 @@ from keras.src.losses import MeanSquaredError\n from keras.src.models import Model\n \n \n-class BatchNormalizationTest(testing.TestCase, parameterized.TestCase):\n+class BatchNormalizationTest(testing.TestCase):\n     @pytest.mark.requires_trainable_backend\n     def test_bn_basics(self):\n         # vector case\n\n@@ -135,7 +135,7 @@ def np_avgpool3d(x, pool_size, strides, padding, data_format):\n \n \n @pytest.mark.requires_trainable_backend\n-class AveragePoolingBasicTest(testing.TestCase, parameterized.TestCase):\n+class AveragePoolingBasicTest(testing.TestCase):\n     @parameterized.parameters(\n         (2, 1, \"valid\", \"channels_last\", (3, 5, 4), (3, 4, 4)),\n         (2, 1, \"same\", \"channels_first\", (3, 5, 4), (3, 5, 4)),\n@@ -242,7 +242,7 @@ class AveragePoolingBasicTest(testing.TestCase, parameterized.TestCase):\n         )\n \n \n-class AveragePoolingCorrectnessTest(testing.TestCase, parameterized.TestCase):\n+class AveragePoolingCorrectnessTest(testing.TestCase):\n     @parameterized.parameters(\n         (2, 1, \"valid\", \"channels_last\"),\n         (2, 1, \"valid\", \"channels_first\"),\n\n@@ -7,7 +7,7 @@ from keras.src import testing\n \n \n @pytest.mark.requires_trainable_backend\n-class GlobalAveragePoolingBasicTest(testing.TestCase, parameterized.TestCase):\n+class GlobalAveragePoolingBasicTest(testing.TestCase):\n     @parameterized.parameters(\n         (\"channels_last\", False, (3, 5, 4), (3, 4)),\n         (\"channels_last\", True, (3, 5, 4), (3, 1, 4)),\n@@ -90,9 +90,7 @@ class GlobalAveragePoolingBasicTest(testing.TestCase, parameterized.TestCase):\n         )\n \n \n-class GlobalAveragePoolingCorrectnessTest(\n-    testing.TestCase, parameterized.TestCase\n-):\n+class GlobalAveragePoolingCorrectnessTest(testing.TestCase):\n     @parameterized.parameters(\n         (\"channels_last\", False),\n         (\"channels_last\", True),\n\n@@ -7,7 +7,7 @@ from keras.src import testing\n \n \n @pytest.mark.requires_trainable_backend\n-class GlobalMaxPoolingBasicTest(testing.TestCase, parameterized.TestCase):\n+class GlobalMaxPoolingBasicTest(testing.TestCase):\n     @parameterized.parameters(\n         (\"channels_last\", False, (3, 5, 4), (3, 4)),\n         (\"channels_last\", True, (3, 5, 4), (3, 1, 4)),\n@@ -90,7 +90,7 @@ class GlobalMaxPoolingBasicTest(testing.TestCase, parameterized.TestCase):\n         )\n \n \n-class GlobalMaxPoolingCorrectnessTest(testing.TestCase, parameterized.TestCase):\n+class GlobalMaxPoolingCorrectnessTest(testing.TestCase):\n     @parameterized.parameters(\n         (\"channels_last\", False),\n         (\"channels_last\", True),\n\n@@ -134,7 +134,7 @@ def np_maxpool3d(x, pool_size, strides, padding, data_format):\n \n \n @pytest.mark.requires_trainable_backend\n-class MaxPoolingBasicTest(testing.TestCase, parameterized.TestCase):\n+class MaxPoolingBasicTest(testing.TestCase):\n     @parameterized.parameters(\n         (2, 1, \"valid\", \"channels_last\", (3, 5, 4), (3, 4, 4)),\n         (2, 1, \"same\", \"channels_first\", (3, 5, 4), (3, 5, 4)),\n@@ -238,7 +238,7 @@ class MaxPoolingBasicTest(testing.TestCase, parameterized.TestCase):\n         )\n \n \n-class MaxPoolingCorrectnessTest(testing.TestCase, parameterized.TestCase):\n+class MaxPoolingCorrectnessTest(testing.TestCase):\n     @parameterized.parameters(\n         (2, 1, \"valid\", \"channels_last\"),\n         (2, 1, \"valid\", \"channels_first\"),\n\n@@ -11,7 +11,7 @@ if backend.SUPPORTS_SPARSE_TENSORS:\n     TEST_CASES += [{\"testcase_name\": \"sparse\", \"sparse\": True}]\n \n \n-class CategoryEncodingTest(testing.TestCase, parameterized.TestCase):\n+class CategoryEncodingTest(testing.TestCase):\n     @parameterized.named_parameters(TEST_CASES)\n     def test_count_output(self, sparse):\n         input_array = np.array([1, 2, 3, 1])\n\n@@ -13,7 +13,7 @@ from keras.src.saving import saving_api\n from keras.src.testing.test_utils import named_product\n \n \n-class DiscretizationTest(testing.TestCase, parameterized.TestCase):\n+class DiscretizationTest(testing.TestCase):\n     def test_discretization_basics(self):\n         self.run_layer_test(\n             layers.Discretization,\n\n@@ -9,7 +9,7 @@ from keras.src import testing\n from keras.src.testing.test_utils import named_product\n \n \n-class HashedCrossingTest(testing.TestCase, parameterized.TestCase):\n+class HashedCrossingTest(testing.TestCase):\n     def test_basics(self):\n         self.run_layer_test(\n             layers.HashedCrossing,\n\n@@ -23,7 +23,7 @@ class ArrayLike:\n @pytest.mark.skipif(\n     backend.backend() == \"numpy\", reason=\"Broken with NumPy backend.\"\n )\n-class HashingTest(testing.TestCase, parameterized.TestCase):\n+class HashingTest(testing.TestCase):\n     def test_config(self):\n         layer = layers.Hashing(\n             num_bins=8,\n\n@@ -101,3 +101,6 @@ class AutoContrast(BaseImagePreprocessingLayer):\n         config = super().get_config()\n         config.update({\"value_range\": self.value_range})\n         return config\n+\n+    def compute_output_shape(self, input_shape):\n+        return input_shape\n\n@@ -1,13 +1,12 @@\n import numpy as np\n import pytest\n-from absl.testing import parameterized\n \n from keras.src import layers\n from keras.src import ops\n from keras.src import testing\n \n \n-class AutoContrastTest(testing.TestCase, parameterized.TestCase):\n+class AutoContrastTest(testing.TestCase):\n     @pytest.mark.requires_trainable_backend\n     def test_layer(self):\n         self.run_layer_test(\n\n@@ -8,7 +8,7 @@ from keras.src import layers\n from keras.src import testing\n \n \n-class CenterCropTest(testing.TestCase, parameterized.TestCase):\n+class CenterCropTest(testing.TestCase):\n     def np_center_crop(self, img, h_new, w_new, data_format=\"channels_last\"):\n         img = np.array(img)\n         if img.ndim == 4:\n\n@@ -26,7 +26,7 @@ class MockedRandomFlip(layers.RandomFlip):\n         return out\n \n \n-class RandomFlipTest(testing.TestCase, parameterized.TestCase):\n+class RandomFlipTest(testing.TestCase):\n     @parameterized.named_parameters(\n         (\"random_flip_horizontal\", \"horizontal\"),\n         (\"random_flip_vertical\", \"vertical\"),\n\n@@ -7,7 +7,7 @@ from keras.src import layers\n from keras.src import testing\n \n \n-class RandomRotationTest(testing.TestCase, parameterized.TestCase):\n+class RandomRotationTest(testing.TestCase):\n     @parameterized.named_parameters(\n         (\"random_rotate_neg4\", -0.4),\n         (\"random_rotate_neg2\", -0.2),\n\n@@ -7,7 +7,7 @@ from keras.src import layers\n from keras.src import testing\n \n \n-class RandomTranslationTest(testing.TestCase, parameterized.TestCase):\n+class RandomTranslationTest(testing.TestCase):\n     @parameterized.named_parameters(\n         (\"random_translate_4_by_6\", 0.4, 0.6),\n         (\"random_translate_3_by_2\", 0.3, 0.2),\n\n@@ -9,7 +9,7 @@ from keras.src import models\n from keras.src import testing\n \n \n-class RandomZoomTest(testing.TestCase, parameterized.TestCase):\n+class RandomZoomTest(testing.TestCase):\n     @parameterized.named_parameters(\n         (\"random_zoom_in_4_by_6\", -0.4, -0.6),\n         (\"random_zoom_in_2_by_3\", -0.2, -0.3),\n\n@@ -9,7 +9,7 @@ from keras.src import layers\n from keras.src import testing\n \n \n-class ResizingTest(testing.TestCase, parameterized.TestCase):\n+class ResizingTest(testing.TestCase):\n     def test_resizing_basics(self):\n         self.run_layer_test(\n             layers.Resizing,\n\n@@ -206,3 +206,6 @@ class Solarization(BaseImagePreprocessingLayer):\n             \"seed\": self.seed,\n         }\n         return {**base_config, **config}\n+\n+    def compute_output_shape(self, input_shape):\n+        return input_shape\n\n@@ -8,7 +8,7 @@ from keras.src import random\n from keras.src import testing\n \n \n-class SolarizationTest(testing.TestCase, parameterized.TestCase):\n+class SolarizationTest(testing.TestCase):\n     def _test_input_output(self, layer, input_value, expected_value, dtype):\n         input = np.ones(shape=(2, 224, 224, 3), dtype=dtype) * input_value\n         expected_output = ops.clip(\n\n@@ -2,7 +2,6 @@ import os\n \n import numpy as np\n import pytest\n-from absl.testing import parameterized\n from tensorflow import data as tf_data\n \n from keras.src import backend\n@@ -15,7 +14,7 @@ from keras.src.saving import saving_api\n @pytest.mark.skipif(\n     backend.backend() == \"numpy\", reason=\"Failing for numpy backend.\"\n )\n-class IndexLookupLayerTest(testing.TestCase, parameterized.TestCase):\n+class IndexLookupLayerTest(testing.TestCase):\n     def test_basics_string_vocab(self):\n         # Case: adapt + list inputs\n         adapt_data = [\"one\", \"one\", \"one\", \"two\", \"two\", \"three\"]\n\n@@ -7,7 +7,7 @@ from keras.src import layers\n from keras.src import testing\n \n \n-class MelSpectrogramTest(testing.TestCase, parameterized.TestCase):\n+class MelSpectrogramTest(testing.TestCase):\n     @pytest.mark.requires_trainable_backend\n     def test_mel_spectrogram_basics(self):\n         self.run_layer_test(\n\n@@ -8,7 +8,7 @@ from keras.src import layers\n from keras.src import testing\n \n \n-class NormalizationTest(testing.TestCase, parameterized.TestCase):\n+class NormalizationTest(testing.TestCase):\n     @pytest.mark.requires_trainable_backend\n     def test_normalization_basics(self):\n         self.run_layer_test(\n\n@@ -8,7 +8,7 @@ from keras.src import ops\n from keras.src import testing\n \n \n-class Cropping2DTest(testing.TestCase, parameterized.TestCase):\n+class Cropping2DTest(testing.TestCase):\n     @parameterized.product(\n         (\n             # different cropping values\n\n@@ -8,7 +8,7 @@ from keras.src import ops\n from keras.src import testing\n \n \n-class Cropping3DTest(testing.TestCase, parameterized.TestCase):\n+class Cropping3DTest(testing.TestCase):\n     @parameterized.product(\n         (\n             {\"dim1_cropping\": (1, 2), \"dim1_expected\": (1, 5)},  # both\n\n@@ -8,7 +8,7 @@ from keras.src import ops\n from keras.src import testing\n \n \n-class FlattenTest(testing.TestCase, parameterized.TestCase):\n+class FlattenTest(testing.TestCase):\n     @parameterized.named_parameters(\n         [\n             {\"testcase_name\": \"dense\", \"sparse\": False},\n\n@@ -8,7 +8,7 @@ from keras.src import ops\n from keras.src import testing\n \n \n-class PermuteTest(testing.TestCase, parameterized.TestCase):\n+class PermuteTest(testing.TestCase):\n     @parameterized.named_parameters(\n         [\n             {\"testcase_name\": \"dense\", \"sparse\": False},\n\n@@ -7,7 +7,7 @@ from keras.src import testing\n from keras.src.backend.common.keras_tensor import KerasTensor\n \n \n-class ReshapeTest(testing.TestCase, parameterized.TestCase):\n+class ReshapeTest(testing.TestCase):\n     @parameterized.named_parameters(\n         [\n             {\"testcase_name\": \"dense\", \"sparse\": False},\n\n@@ -8,7 +8,7 @@ from keras.src import layers\n from keras.src import testing\n \n \n-class UpSampling2dTest(testing.TestCase, parameterized.TestCase):\n+class UpSampling2dTest(testing.TestCase):\n     @parameterized.product(\n         data_format=[\"channels_first\", \"channels_last\"],\n         length_row=[2],\n\n@@ -7,7 +7,7 @@ from keras.src import layers\n from keras.src import testing\n \n \n-class UpSampling3dTest(testing.TestCase, parameterized.TestCase):\n+class UpSampling3dTest(testing.TestCase):\n     @parameterized.product(\n         data_format=[\"channels_first\", \"channels_last\"],\n         length_dim1=[2, 3],\n\n@@ -6,7 +6,7 @@ from keras.src import layers\n from keras.src import testing\n \n \n-class ZeroPadding1DTest(testing.TestCase, parameterized.TestCase):\n+class ZeroPadding1DTest(testing.TestCase):\n     @parameterized.parameters(\n         {\"data_format\": \"channels_first\"},\n         {\"data_format\": \"channels_last\"},\n\n@@ -7,7 +7,7 @@ from keras.src import layers\n from keras.src import testing\n \n \n-class ZeroPadding2DTest(testing.TestCase, parameterized.TestCase):\n+class ZeroPadding2DTest(testing.TestCase):\n     @parameterized.parameters(\n         {\"data_format\": \"channels_first\"},\n         {\"data_format\": \"channels_last\"},\n\n@@ -7,7 +7,7 @@ from keras.src import layers\n from keras.src import testing\n \n \n-class ZeroPadding3DTest(testing.TestCase, parameterized.TestCase):\n+class ZeroPadding3DTest(testing.TestCase):\n     @parameterized.parameters(\n         {\"data_format\": \"channels_first\"}, {\"data_format\": \"channels_last\"}\n     )\n\n@@ -7,7 +7,7 @@ from keras.src import layers\n from keras.src import testing\n \n \n-class GRUTest(testing.TestCase, parameterized.TestCase):\n+class GRUTest(testing.TestCase):\n     @pytest.mark.requires_trainable_backend\n     def test_basics(self):\n         self.run_layer_test(\n\n@@ -7,7 +7,7 @@ from keras.src import layers\n from keras.src import testing\n \n \n-class LSTMTest(testing.TestCase, parameterized.TestCase):\n+class LSTMTest(testing.TestCase):\n     @pytest.mark.requires_trainable_backend\n     def test_basics(self):\n         self.run_layer_test(\n\n@@ -700,7 +700,7 @@ class RecallTest(testing.TestCase):\n         self.assertAlmostEqual(3, r_obj.false_negatives)\n \n \n-class SensitivityAtSpecificityTest(testing.TestCase, parameterized.TestCase):\n+class SensitivityAtSpecificityTest(testing.TestCase):\n     def test_config(self):\n         s_obj = metrics.SensitivityAtSpecificity(\n             0.4,\n@@ -788,7 +788,7 @@ class SensitivityAtSpecificityTest(testing.TestCase, parameterized.TestCase):\n             metrics.SensitivityAtSpecificity(0.4, num_thresholds=-1)\n \n \n-class SpecificityAtSensitivityTest(testing.TestCase, parameterized.TestCase):\n+class SpecificityAtSensitivityTest(testing.TestCase):\n     def test_config(self):\n         s_obj = metrics.SpecificityAtSensitivity(\n             0.4,\n@@ -877,7 +877,7 @@ class SpecificityAtSensitivityTest(testing.TestCase, parameterized.TestCase):\n             metrics.SpecificityAtSensitivity(0.4, num_thresholds=-1)\n \n \n-class PrecisionAtRecallTest(testing.TestCase, parameterized.TestCase):\n+class PrecisionAtRecallTest(testing.TestCase):\n     def test_config(self):\n         s_obj = metrics.PrecisionAtRecall(\n             0.4, num_thresholds=100, class_id=12, name=\"precision_at_recall_1\"\n@@ -965,7 +965,7 @@ class PrecisionAtRecallTest(testing.TestCase, parameterized.TestCase):\n             metrics.PrecisionAtRecall(0.4, num_thresholds=-1)\n \n \n-class RecallAtPrecisionTest(testing.TestCase, parameterized.TestCase):\n+class RecallAtPrecisionTest(testing.TestCase):\n     def test_config(self):\n         s_obj = metrics.RecallAtPrecision(\n             0.4, num_thresholds=100, class_id=12, name=\"recall_at_precision_1\"\n\n@@ -5,7 +5,7 @@ from keras.src import testing\n from keras.src.metrics import f_score_metrics\n \n \n-class FBetaScoreTest(parameterized.TestCase, testing.TestCase):\n+class FBetaScoreTest(testing.TestCase):\n     def _run_test(\n         self,\n         y_true,\n\n@@ -299,7 +299,7 @@ class LogCoshErrorTest(testing.TestCase):\n         self.assertAllClose(result, expected_result, atol=1e-3)\n \n \n-class R2ScoreTest(parameterized.TestCase, testing.TestCase):\n+class R2ScoreTest(testing.TestCase):\n     def _run_test(\n         self,\n         y_true,\n\n@@ -75,7 +75,7 @@ def get_subclassed_model():\n \n \n @pytest.mark.requires_trainable_backend\n-class CloneModelTest(testing.TestCase, parameterized.TestCase):\n+class CloneModelTest(testing.TestCase):\n \n     def assert_models_equal(self, model1, model2, ref_input):\n         result1 = model1(ref_input)\n\n@@ -16,7 +16,7 @@ from keras.src.models import Model\n from keras.src.models import Sequential\n \n \n-class FunctionalTest(testing.TestCase, parameterized.TestCase):\n+class FunctionalTest(testing.TestCase):\n     @pytest.mark.requires_trainable_backend\n     def test_basic_flow_multi_input(self):\n         input_a = Input(shape=(3,), batch_size=2, name=\"input_a\")\n\n@@ -120,7 +120,7 @@ def _get_variable_value_by_path(variables, path):\n \n \n @pytest.mark.requires_trainable_backend\n-class ModelTest(testing.TestCase, parameterized.TestCase):\n+class ModelTest(testing.TestCase):\n     def test_functional_rerouting(self):\n         model = _get_model()\n         self.assertIsInstance(model, Functional)\n\n@@ -144,7 +144,7 @@ class CoreOpsStaticShapeTest(testing.TestCase):\n             core.unstack(x, axis=axis)\n \n \n-class CoreOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n+class CoreOpsCorrectnessTest(testing.TestCase):\n     def test_map(self):\n         def f(x):\n             return x**2\n@@ -863,7 +863,7 @@ class CoreOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             self.assertEqual(ops.convert_to_numpy(x.grad), 1.0)\n \n \n-class CoreOpsDtypeTest(testing.TestCase, parameterized.TestCase):\n+class CoreOpsDtypeTest(testing.TestCase):\n     import jax  # enable bfloat16 for numpy\n \n     # TODO: Using uint64 will lead to weak type promotion (`float`),\n\n@@ -389,7 +389,7 @@ def _fixed_map_coordinates(\n     return result\n \n \n-class ImageOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n+class ImageOpsCorrectnessTest(testing.TestCase):\n     def setUp(self):\n         # Defaults to channels_last\n         self.data_format = backend.image_data_format()\n@@ -1138,7 +1138,7 @@ class ImageOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         self.assertAllClose(ref_cropped_image, cropped_image)\n \n \n-class ImageOpsBehaviorTests(testing.TestCase, parameterized.TestCase):\n+class ImageOpsBehaviorTests(testing.TestCase):\n     def setUp(self):\n         # Defaults to channels_last\n         self.data_format = backend.image_data_format()\n\n@@ -329,7 +329,7 @@ class LinalgOpsStaticShapeTest(testing.TestCase):\n         self.assertEqual(s.shape, (10, 2))\n \n \n-class LinalgOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n+class LinalgOpsCorrectnessTest(testing.TestCase):\n \n     def test_cholesky(self):\n         x = np.random.rand(4, 3, 3).astype(\"float32\")\n\n@@ -144,7 +144,7 @@ def _max_reduce(left, right):\n     return np.max(np.stack([left, right]), axis=0)\n \n \n-class MathOpsDynamicShapeTest(testing.TestCase, parameterized.TestCase):\n+class MathOpsDynamicShapeTest(testing.TestCase):\n \n     @parameterized.parameters([(kmath.segment_sum,), (kmath.segment_max,)])\n     def test_segment_reduce(self, segment_reduce_op):\n@@ -281,7 +281,7 @@ class MathOpsDynamicShapeTest(testing.TestCase, parameterized.TestCase):\n         self.assertEqual(out.shape, (None,))\n \n \n-class MathOpsStaticShapeTest(testing.TestCase, parameterized.TestCase):\n+class MathOpsStaticShapeTest(testing.TestCase):\n     @parameterized.parameters([(kmath.segment_sum,), (kmath.segment_max,)])\n     @pytest.mark.skipif(\n         backend.backend() == \"jax\",\n@@ -417,7 +417,7 @@ class MathOpsStaticShapeTest(testing.TestCase, parameterized.TestCase):\n         self.assertEqual(out.shape, (2, 4))\n \n \n-class MathOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n+class MathOpsCorrectnessTest(testing.TestCase):\n \n     def run_segment_reduce_test(\n         self,\n@@ -948,7 +948,7 @@ class MathOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         self.assertAllClose(out, -1.1178946, atol=1e-3)\n \n \n-class MathDtypeTest(testing.TestCase, parameterized.TestCase):\n+class MathDtypeTest(testing.TestCase):\n     \"\"\"Test the floating dtype to verify that the behavior matches JAX.\"\"\"\n \n     # TODO: Using uint64 will lead to weak type promotion (`float`),\n@@ -1344,7 +1344,7 @@ class ISTFTTest(testing.TestCase):\n         self.assertEqual(output_spec.shape, expected_shape)\n \n \n-class TestMathErrors(testing.TestCase, parameterized.TestCase):\n+class TestMathErrors(testing.TestCase):\n \n     @parameterized.parameters([(kmath.segment_sum,), (kmath.segment_max,)])\n     @pytest.mark.skipif(\n\n@@ -35,7 +35,7 @@ from keras.src.ops import numpy as knp\n from keras.src.testing.test_utils import named_product\n \n \n-class NNOpsDynamicShapeTest(testing.TestCase, parameterized.TestCase):\n+class NNOpsDynamicShapeTest(testing.TestCase):\n     def test_relu(self):\n         x = KerasTensor([None, 2, 3])\n         self.assertEqual(knn.relu(x).shape, (None, 2, 3))\n@@ -1139,7 +1139,7 @@ class NNOpsStaticShapeTest(testing.TestCase):\n         self.assertEqual(out.shape, ())\n \n \n-class NNOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n+class NNOpsCorrectnessTest(testing.TestCase):\n     def test_relu(self):\n         x = np.array([-1, 0, 1, 2, 3], dtype=np.float32)\n         self.assertAllClose(knn.relu(x), [0, 0, 1, 2, 3])\n@@ -2137,7 +2137,7 @@ class NNOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         self.assertAlmostEqual(psnr_2, expected_psnr_2)\n \n \n-class NNOpsDtypeTest(testing.TestCase, parameterized.TestCase):\n+class NNOpsDtypeTest(testing.TestCase):\n     \"\"\"Test the dtype to verify that the behavior matches JAX.\"\"\"\n \n     FLOAT_DTYPES = dtypes.FLOAT_TYPES\n@@ -2499,7 +2499,7 @@ class NNOpsDtypeTest(testing.TestCase, parameterized.TestCase):\n         self.assertEqual(standardize_dtype(scores.dtype), expected_dtype)\n \n \n-class NNOpsBehaviorTest(testing.TestCase, parameterized.TestCase):\n+class NNOpsBehaviorTest(testing.TestCase):\n     def test_logit_recovery_binary_crossentropy(self):\n         layer = layers.Dense(\n             4, activation=\"sigmoid\", use_bias=False, kernel_initializer=\"ones\"\n\n@@ -2096,7 +2096,7 @@ class NumpyOneInputOpsStaticShapeTest(testing.TestCase):\n             knp.argpartition(x, (1, 3))\n \n \n-class NumpyTwoInputOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n+class NumpyTwoInputOpsCorrectnessTest(testing.TestCase):\n     def test_add(self):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n         y = np.array([[4, 5, 6], [3, 2, 1]])\n@@ -3015,7 +3015,7 @@ class NumpyTwoInputOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         )\n \n \n-class NumpyOneInputOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n+class NumpyOneInputOpsCorrectnessTest(testing.TestCase):\n     def test_mean(self):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n         self.assertAllClose(knp.mean(x), np.mean(x))\n@@ -4761,7 +4761,7 @@ def snake_to_pascal_case(name):\n     not backend.SUPPORTS_SPARSE_TENSORS,\n     reason=\"Backend does not support sparse tensors.\",\n )\n-class SparseTest(testing.TestCase, parameterized.TestCase):\n+class SparseTest(testing.TestCase):\n     DTYPES = [\"int32\", \"float32\"]\n     DENSIFYING_UNARY_OPS = [\n         \"arccos\",\n@@ -5138,7 +5138,7 @@ class SparseTest(testing.TestCase, parameterized.TestCase):\n         self.assertAllClose(knp.Divide()(x, y), expected_result)\n \n \n-class NumpyDtypeTest(testing.TestCase, parameterized.TestCase):\n+class NumpyDtypeTest(testing.TestCase):\n     \"\"\"Test the dtype to verify that the behavior matches JAX.\"\"\"\n \n     # TODO: Using uint64 will lead to weak type promotion (`float`),\n\n@@ -8,7 +8,7 @@ from keras.src.optimizers.loss_scale_optimizer import LossScaleOptimizer\n from keras.src.optimizers.sgd import SGD\n \n \n-class LossScaleOptimizerTest(testing.TestCase, parameterized.TestCase):\n+class LossScaleOptimizerTest(testing.TestCase):\n     def _skip_test_for_stateless(self, stateless):\n         if not stateless and backend.backend() == \"jax\":\n             self.skipTest(\n\n@@ -130,7 +130,7 @@ TEST_CASES = [\n     not backend.SUPPORTS_SPARSE_TENSORS,\n     reason=\"Backend does not support sparse tensors.\",\n )\n-class OptimizerSparseTest(testing.TestCase, parameterized.TestCase):\n+class OptimizerSparseTest(testing.TestCase):\n     @parameterized.named_parameters(TEST_CASES)\n     def test_sparse_gradients(\n         self,\n\n@@ -13,7 +13,7 @@ from keras.src import optimizers\n from keras.src import testing\n \n \n-class OptimizerTest(testing.TestCase, parameterized.TestCase):\n+class OptimizerTest(testing.TestCase):\n     def test_iterations_counter(self):\n         v = backend.Variable([[1.0, 2.0], [3.0, 4.0]])\n         grads = backend.convert_to_tensor([[1.0, 1.0], [1.0, 1.0]])\n\n@@ -14,7 +14,7 @@ from keras.src.testing.test_utils import named_product\n from keras.src.utils.rng_utils import set_random_seed\n \n \n-class RandomCorrectnessTest(testing.TestCase, parameterized.TestCase):\n+class RandomCorrectnessTest(testing.TestCase):\n     @parameterized.parameters(\n         {\"seed\": 10, \"shape\": (5,), \"mean\": 0, \"stddev\": 1},\n         {\"seed\": 10, \"shape\": (2, 3), \"mean\": 0, \"stddev\": 1},\n@@ -322,7 +322,7 @@ class RandomCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             )\n \n \n-class RandomBehaviorTest(testing.TestCase, parameterized.TestCase):\n+class RandomBehaviorTest(testing.TestCase):\n     def test_beta_tf_data_compatibility(self):\n         import tensorflow as tf\n \n@@ -439,7 +439,7 @@ class RandomBehaviorTest(testing.TestCase, parameterized.TestCase):\n         self.assertAllClose(outputs_mod, outputs_nomod)\n \n \n-class RandomDTypeTest(testing.TestCase, parameterized.TestCase):\n+class RandomDTypeTest(testing.TestCase):\n     INT_DTYPES = [x for x in dtypes.INT_TYPES if x != \"uint64\"]\n     FLOAT_DTYPES = dtypes.FLOAT_TYPES\n     if backend.backend() == \"torch\":\n\n@@ -103,7 +103,7 @@ class SaveModelTests(test_case.TestCase):\n         )\n \n \n-class LoadModelTests(test_case.TestCase, parameterized.TestCase):\n+class LoadModelTests(test_case.TestCase):\n     def get_model(self, dtype=None):\n         return Sequential(\n             [\n@@ -191,7 +191,7 @@ class LoadModelTests(test_case.TestCase, parameterized.TestCase):\n         self.assertTrue(np.allclose(model.predict(x), loaded_model.predict(x)))\n \n \n-class LoadWeightsTests(test_case.TestCase, parameterized.TestCase):\n+class LoadWeightsTests(test_case.TestCase):\n     def get_model(self, dtype=None):\n         return Sequential(\n             [\n\n@@ -246,7 +246,7 @@ def _load_model_fn(filepath):\n     saving_lib.load_model(filepath)\n \n \n-class SavingTest(testing.TestCase, parameterized.TestCase):\n+class SavingTest(testing.TestCase):\n     def setUp(self):\n         # Set `_MEMORY_UPPER_BOUND` to zero for testing purpose.\n         self.original_value = saving_lib._MEMORY_UPPER_BOUND\n\n@@ -5,6 +5,7 @@ import unittest\n from pathlib import Path\n \n import numpy as np\n+from absl.testing import parameterized\n \n from keras.src import backend\n from keras.src import distribution\n@@ -19,7 +20,7 @@ from keras.src.models import Model\n from keras.src.utils import traceback_utils\n \n \n-class TestCase(unittest.TestCase):\n+class TestCase(parameterized.TestCase, unittest.TestCase):\n     maxDiff = None\n \n     def __init__(self, *args, **kwargs):\n\n@@ -234,7 +234,7 @@ class TestCompileMetrics(testing.TestCase):\n         self.assertTrue(\"my_custom_metric\" in result)\n \n \n-class TestCompileLoss(testing.TestCase, parameterized.TestCase):\n+class TestCompileLoss(testing.TestCase):\n     def test_single_output_case(self):\n         compile_loss = CompileLoss(\n             loss=losses_module.MeanSquaredError(),\n\n@@ -13,7 +13,7 @@ from keras.src.testing.test_utils import named_product\n from keras.src.trainers.data_adapters import array_data_adapter\n \n \n-class TestArrayDataAdapter(testing.TestCase, parameterized.TestCase):\n+class TestArrayDataAdapter(testing.TestCase):\n     def make_array(self, array_type, shape, dtype):\n         x = np.array([[i] * shape[1] for i in range(shape[0])], dtype=dtype)\n         if array_type == \"np\":\n\n@@ -31,7 +31,7 @@ def example_generator(x, y, sample_weight=None, batch_size=32):\n     return make\n \n \n-class GeneratorDataAdapterTest(testing.TestCase, parameterized.TestCase):\n+class GeneratorDataAdapterTest(testing.TestCase):\n     @parameterized.named_parameters(\n         named_product(\n             [\n\n@@ -94,7 +94,7 @@ class ExceptionPyDataset(py_dataset_adapter.PyDataset):\n         raise ValueError(\"Expected exception\")\n \n \n-class PyDatasetAdapterTest(testing.TestCase, parameterized.TestCase):\n+class PyDatasetAdapterTest(testing.TestCase):\n     @parameterized.named_parameters(\n         named_product(\n             [\n\n@@ -5,14 +5,13 @@ import numpy as np\n import pytest\n import tensorflow as tf\n import torch\n-from absl.testing import parameterized\n \n from keras.src import backend\n from keras.src import testing\n from keras.src.trainers.data_adapters import tf_dataset_adapter\n \n \n-class TestTFDatasetAdapter(testing.TestCase, parameterized.TestCase):\n+class TestTFDatasetAdapter(testing.TestCase):\n     def test_basic_flow(self):\n         x = tf.random.normal((34, 4))\n         y = tf.random.normal((34, 2))\n\n@@ -13,7 +13,7 @@ from keras.src.trainers.data_adapters.torch_data_loader_adapter import (\n )\n \n \n-class TestTorchDataLoaderAdapter(testing.TestCase, parameterized.TestCase):\n+class TestTorchDataLoaderAdapter(testing.TestCase):\n     def test_basic_dataloader(self):\n         x = torch.normal(2, 3, size=(34, 4))\n         y = torch.normal(1, 3, size=(34, 2))\n\n@@ -9,7 +9,7 @@ from keras.src.trainers import data_adapters\n from keras.src.trainers import epoch_iterator\n \n \n-class TestEpochIterator(testing.TestCase, parameterized.TestCase):\n+class TestEpochIterator(testing.TestCase):\n     def test_basic_flow(self):\n         x = np.random.random((100, 16))\n         y = np.random.random((100, 4))\n\n@@ -170,7 +170,7 @@ def sparse_generator(generator_type):\n         raise ValueError(f\"Invalid generator type {generator_type}\")\n \n \n-class TestTrainer(testing.TestCase, parameterized.TestCase):\n+class TestTrainer(testing.TestCase):\n     @pytest.mark.requires_trainable_backend\n     def test_metric_tracking(self):\n         class ModelWithMetric(Trainer, layers.Dense):\n\n@@ -6,7 +6,7 @@ from keras.src import testing\n from keras.src.utils import backend_utils\n \n \n-class BackendUtilsTest(testing.TestCase, parameterized.TestCase):\n+class BackendUtilsTest(testing.TestCase):\n     @parameterized.named_parameters(\n         (\"numpy\", \"numpy\"),\n         (\"jax\", \"jax\"),\n\n@@ -23,7 +23,7 @@ class MyTorchDataset(TorchDataset):\n         return self.x[index], self.y[index]\n \n \n-class DatasetUtilsTest(test_case.TestCase, parameterized.TestCase):\n+class DatasetUtilsTest(test_case.TestCase):\n     @parameterized.named_parameters(\n         named_product(\n             dataset_type=[\"list\", \"tuple\", \"tensorflow\", \"torch\"],\n\n@@ -182,7 +182,7 @@ if flax is not None:\n     backend.backend() != \"jax\",\n     reason=\"JaxLayer and FlaxLayer are only supported with JAX backend\",\n )\n-class TestJaxLayer(testing.TestCase, parameterized.TestCase):\n+class TestJaxLayer(testing.TestCase):\n     def _test_layer(\n         self,\n         model_name,\n\n@@ -8,7 +8,7 @@ from keras.src.utils import numerical_utils\n NUM_CLASSES = 5\n \n \n-class TestNumericalUtils(testing.TestCase, parameterized.TestCase):\n+class TestNumericalUtils(testing.TestCase):\n     @parameterized.parameters(\n         [\n             ((1,), (1, NUM_CLASSES)),\n\n@@ -9,7 +9,7 @@ from keras.src import testing\n from keras.src.utils import summary_utils\n \n \n-class SummaryUtilsTest(testing.TestCase, parameterized.TestCase):\n+class SummaryUtilsTest(testing.TestCase):\n     @parameterized.parameters([(\"adam\",), (None,)])\n     @pytest.mark.requires_trainable_backend\n     def test_print_model_summary(self, optimizer):\n\n@@ -56,7 +56,7 @@ class ClassifierWithNoSpecialCasing(models.Model):\n @pytest.mark.skipif(\n     backend.backend() != \"torch\", reason=\"Requires torch backend\"\n )\n-class TorchUtilsTest(testing.TestCase, parameterized.TestCase):\n+class TorchUtilsTest(testing.TestCase):\n     @parameterized.parameters(\n         {\"use_batch_norm\": False, \"num_torch_layers\": 1},\n         {\"use_batch_norm\": True, \"num_torch_layers\": 1},\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7628a1895269f162191231ef57aed7ef67fd6250", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 151 | Lines Deleted: 0 | Files Changed: 4 | Hunks: 4 | Methods Changed: 13 | Complexity Δ (Sum/Max): 21/11 | Churn Δ: 151 | Churn Cumulative: 652 | Contributors (this commit): 2 | Commits (past 90d): 8 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -173,6 +173,7 @@ from keras.src.layers.preprocessing.image_preprocessing.solarization import (\n from keras.src.layers.preprocessing.integer_lookup import IntegerLookup\n from keras.src.layers.preprocessing.mel_spectrogram import MelSpectrogram\n from keras.src.layers.preprocessing.normalization import Normalization\n+from keras.src.layers.preprocessing.pipeline import Pipeline\n from keras.src.layers.preprocessing.rescaling import Rescaling\n from keras.src.layers.preprocessing.string_lookup import StringLookup\n from keras.src.layers.preprocessing.text_vectorization import TextVectorization\n\n@@ -173,6 +173,7 @@ from keras.src.layers.preprocessing.image_preprocessing.solarization import (\n from keras.src.layers.preprocessing.integer_lookup import IntegerLookup\n from keras.src.layers.preprocessing.mel_spectrogram import MelSpectrogram\n from keras.src.layers.preprocessing.normalization import Normalization\n+from keras.src.layers.preprocessing.pipeline import Pipeline\n from keras.src.layers.preprocessing.rescaling import Rescaling\n from keras.src.layers.preprocessing.string_lookup import StringLookup\n from keras.src.layers.preprocessing.text_vectorization import TextVectorization\n\n@@ -0,0 +1,81 @@\n+from keras.src import tree\n+from keras.src.api_export import keras_export\n+from keras.src.layers.layer import Layer\n+from keras.src.saving import serialization_lib\n+\n+\n+@keras_export(\"keras.layers.Pipeline\")\n+class Pipeline(Layer):\n+    \"\"\"Applies a series of layers to an input.\n+\n+    This class is useful to build a preprocessing pipeline.\n+    Compared to a `Sequential` model, `Pipeline` features\n+    a few important differences:\n+\n+    - It's not a `Model`, just a plain layer.\n+    - When the layers in the pipeline are compatible\n+        with `tf.data`, the pipeline will also\n+        remain `tf.data` compatible. That is to say,\n+        the pipeline will not attempt to convert\n+        its inputs to backend-native tensors\n+        when in a tf.data context (unlike a `Sequential`\n+        model).\n+\n+    Example:\n+\n+    ```python\n+    from keras import layers\n+    preprocessing_pipeline = layers.Pipeline([\n+        layers.AutoContrast(),\n+        layers.RandomZoom(0.2),\n+        layers.RandomRotation(0.2),\n+    ])\n+\n+    # `ds` is a tf.data.Dataset\n+    preprocessed_ds = ds.map(\n+        preprocessing_pipeline,\n+        num_parallel_calls=4,\n+    )\n+    ```\n+    \"\"\"\n+\n+    def __init__(self, layers, name=None):\n+        super().__init__(name=name)\n+        self._pipeline_layers = layers\n+        self._convert_input_args = False\n+        self._allow_non_tensor_positional_args = True\n+\n+    @property\n+    def layers(self):\n+        return self._pipeline_layers\n+\n+    def build(self, input_shape):\n+        for layer in self._pipeline_layers:\n+            layer.build(input_shape)\n+            input_shape = layer.compute_output_shape(input_shape)\n+        self.built = True\n+\n+    def call(self, inputs, training=True, mask=None):\n+        for layer in self._pipeline_layers:\n+            kwargs = {}\n+            if layer._call_has_mask_arg:\n+                kwargs[\"mask\"] = mask\n+            if layer._call_has_training_arg and training is not None:\n+                kwargs[\"training\"] = training\n+            outputs = layer(inputs, **kwargs)\n+            inputs = outputs\n+\n+            def _get_mask_from_keras_tensor(kt):\n+                return getattr(kt, \"_keras_mask\", None)\n+\n+            mask = tree.map_structure(_get_mask_from_keras_tensor, outputs)\n+        return outputs\n+\n+    def get_config(self):\n+        config = {\n+            \"layers\": serialization_lib.serialize_keras_object(\n+                self._pipeline_layers\n+            ),\n+            \"name\": self.name,\n+        }\n+        return config\n\n@@ -0,0 +1,68 @@\n+import numpy as np\n+from tensorflow import data as tf_data\n+\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n+\n+\n+class CanaryLayer(layers.Layer):\n+    def __init__(self):\n+        super().__init__()\n+        self.training = None\n+        self.received_mask = False\n+\n+    def call(self, x, training=False, mask=None):\n+        self.training = training\n+        if mask is not None:\n+            self.received_mask = True\n+        return x\n+\n+    def compute_mask(self, x, mask=None):\n+        return x\n+\n+    def compute_output_shape(self, input_shape):\n+        return input_shape\n+\n+\n+class PipelineTest(testing.TestCase):\n+    def test_basics(self):\n+        self.run_layer_test(\n+            layers.Pipeline,\n+            init_kwargs={\n+                \"layers\": [layers.AutoContrast(), layers.RandomBrightness(0.1)],\n+            },\n+            input_shape=(8, 3, 4, 3),\n+            supports_masking=False,\n+            expected_output_shape=(8, 3, 4, 3),\n+            run_mixed_precision_check=False,\n+        )\n+\n+    def test_correctness(self):\n+        pipeline = layers.Pipeline([CanaryLayer(), CanaryLayer()])\n+        x = np.array([0])\n+        mask = np.array([0])\n+        pipeline(x, training=True, mask=mask)\n+        self.assertTrue(pipeline.layers[0].training)\n+        self.assertTrue(pipeline.layers[0].received_mask)\n+        self.assertTrue(pipeline.layers[1].training)\n+        self.assertTrue(pipeline.layers[1].received_mask)\n+\n+    def test_tf_data_compatibility(self):\n+        if backend.config.image_data_format() == \"channels_last\":\n+            input_shape = (2, 10, 12, 3)\n+            output_shape = (2, 8, 9, 3)\n+        else:\n+            input_shape = (2, 3, 10, 12)\n+            output_shape = (2, 3, 8, 9)\n+        layer = layers.Pipeline(\n+            [\n+                layers.AutoContrast(),\n+                layers.CenterCrop(8, 9),\n+            ]\n+        )\n+        input_data = np.random.random(input_shape)\n+        ds = tf_data.Dataset.from_tensor_slices(input_data).batch(2).map(layer)\n+        for output in ds.take(1):\n+            output = output.numpy()\n+        self.assertEqual(tuple(output.shape), output_shape)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
