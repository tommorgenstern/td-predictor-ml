{"custom_id": "keras#13b084d5864e8f316d5eea5ac84445404cfaa846", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 4 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 436 | Contributors (this commit): 3 | Commits (past 90d): 5 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -82,19 +82,19 @@ class TestBasicConvUtilsTest(tf.test.TestCase):\n \n     with self.assertRaises(ValueError) as ctx:\n       conv_utils.normalize_tuple((2, 1), n=3, name='strides', validation_fn=lambda x: x >= 0, fn_alt='>=0')\n-    self.assertTrue('The `strides` argument must be a tuple of 3' in str(ctx.exception))\n+    self.assertIn('The `strides` argument must be a tuple of 3', str(ctx.exception))\n \n     with self.assertRaises(ValueError) as ctx:\n       conv_utils.normalize_tuple(None, n=3, name='kernel_size')\n-    self.assertTrue('The `kernel_size` argument must be a tuple of 3' in str(ctx.exception))\n+    self.assertIn('The `kernel_size` argument must be a tuple of 3', str(ctx.exception))\n \n     with self.assertRaises(ValueError) as ctx:\n       conv_utils.normalize_tuple(-4, n=3, name='strides', validation_fn=lambda x: x >= 0, fn_alt='>=0')\n-    self.assertTrue('that does not satisfy the requirement' in str(ctx.exception))\n+    self.assertIn('that does not satisfy the requirement >=0', str(ctx.exception))\n \n     with self.assertRaises(ValueError) as ctx:\n       conv_utils.normalize_tuple((0, 1, 2), n=3, name='pool_size')\n-    self.assertTrue('that does not satisfy the requirement' in str(ctx.exception))\n+    self.assertIn('that does not satisfy the requirement >0', str(ctx.exception))\n \n   def test_normalize_data_format(self):\n     self.assertEqual('channels_last',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8d874de12ed2e199d9528bfff891f4f60ee2a636", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 14 | Churn Cumulative: 920 | Contributors (this commit): 5 | Commits (past 90d): 7 | Contributors (cumulative): 8 | DMM Complexity: 1.0\n\nDIFF:\n@@ -48,8 +48,8 @@ MODEL_LIST_NO_NASNET = [\n     (inception_resnet_v2.InceptionResNetV2, 1536),\n     (mobilenet.MobileNet, 1024),\n     (mobilenet_v2.MobileNetV2, 1280),\n-    (mobilenet_v3.MobileNetV3Small, 576),\n-    (mobilenet_v3.MobileNetV3Large, 960),\n+    (mobilenet_v3.MobileNetV3Small, 1024),\n+    (mobilenet_v3.MobileNetV3Large, 1280),\n     (densenet.DenseNet121, 1024),\n     (densenet.DenseNet169, 1664),\n     (densenet.DenseNet201, 1920),\n@@ -93,7 +93,7 @@ class ApplicationsTest(tf.test.TestCase, parameterized.TestCase):\n \n   @parameterized.parameters(*MODEL_LIST)\n   def test_application_notop(self, app, last_dim):\n-    if 'NASNet' in app.__name__:\n+    if 'NASNet' or 'MobileNetV3' in app.__name__:\n       only_check_last_dim = True\n     else:\n       only_check_last_dim = False\n@@ -119,6 +119,9 @@ class ApplicationsTest(tf.test.TestCase, parameterized.TestCase):\n       input_shape = (None, None, 1)\n     output_shape = _get_output_shape(\n         lambda: app(weights=None, include_top=False, input_shape=input_shape))\n+    if 'MobileNetV3' in app.__name__:\n+      self.assertShapeEqual(output_shape, (None, 1, 1, last_dim))\n+    else:\n       self.assertShapeEqual(output_shape, (None, None, None, last_dim))\n     backend.clear_session()\n \n@@ -128,6 +131,9 @@ class ApplicationsTest(tf.test.TestCase, parameterized.TestCase):\n       input_shape = (None, None, 4)\n     output_shape = _get_output_shape(\n         lambda: app(weights=None, include_top=False, input_shape=input_shape))\n+    if 'MobileNetV3' in app.__name__:\n+      self.assertShapeEqual(output_shape, (None, 1, 1, last_dim))\n+    else:\n       self.assertShapeEqual(output_shape, (None, None, None, last_dim))\n     backend.clear_session()\n \n\n@@ -310,7 +310,6 @@ def MobileNetV3(stack_fn,\n       axis=channel_axis, epsilon=1e-3,\n       momentum=0.999, name='Conv_1/BatchNorm')(x)\n   x = activation(x)\n-  if include_top:\n   x = layers.GlobalAveragePooling2D(keepdims=True)(x)\n   x = layers.Conv2D(\n       last_point_ch,\n@@ -320,6 +319,7 @@ def MobileNetV3(stack_fn,\n       name='Conv_2')(x)\n   x = activation(x)\n \n+  if include_top:\n     if dropout_rate > 0:\n       x = layers.Dropout(dropout_rate)(x)\n     x = layers.Conv2D(classes, kernel_size=1, padding='same', name='Logits')(x)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d8c81998185b67e409fd0d31a07bbe9d1d61122f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 47 | Lines Deleted: 46 | Files Changed: 6 | Hunks: 30 | Methods Changed: 15 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 93 | Churn Cumulative: 34136 | Contributors (this commit): 114 | Commits (past 90d): 65 | Contributors (cumulative): 165 | DMM Complexity: 0.0\n\nDIFF:\n@@ -139,7 +139,7 @@ class Conv(Layer):\n     self.kernel_size = conv_utils.normalize_tuple(\n         kernel_size, rank, 'kernel_size')\n     self.strides = conv_utils.normalize_tuple(\n-        strides, rank, 'strides', lambda x: x >= 0, '>=0')\n+        strides, rank, 'strides', allow_zero=True)\n     self.padding = conv_utils.normalize_padding(padding)\n     self.data_format = conv_utils.normalize_data_format(data_format)\n     self.dilation_rate = conv_utils.normalize_tuple(\n@@ -954,7 +954,7 @@ class Conv1DTranspose(Conv1D):\n     self.output_padding = output_padding\n     if self.output_padding is not None:\n       self.output_padding = conv_utils.normalize_tuple(\n-          self.output_padding, 1, 'output_padding', lambda x: x >= 0, '>=0')\n+          self.output_padding, 1, 'output_padding', allow_zero=True)\n       for stride, out_pad in zip(self.strides, self.output_padding):\n         if out_pad >= stride:\n           raise ValueError('Strides must be greater than output padding. '\n@@ -1228,7 +1228,7 @@ class Conv2DTranspose(Conv2D):\n     self.output_padding = output_padding\n     if self.output_padding is not None:\n       self.output_padding = conv_utils.normalize_tuple(\n-          self.output_padding, 2, 'output_padding', lambda x: x >= 0, '>=0')\n+          self.output_padding, 2, 'output_padding', allow_zero=True)\n       for stride, out_pad in zip(self.strides, self.output_padding):\n         if out_pad >= stride:\n           raise ValueError('Strides must be greater than output padding. '\n@@ -1541,7 +1541,7 @@ class Conv3DTranspose(Conv3D):\n     self.output_padding = output_padding\n     if self.output_padding is not None:\n       self.output_padding = conv_utils.normalize_tuple(\n-          self.output_padding, 3, 'output_padding', lambda x: x >= 0, '>=0')\n+          self.output_padding, 3, 'output_padding', allow_zero=True)\n       for stride, out_pad in zip(self.strides, self.output_padding):\n         if out_pad >= stride:\n           raise ValueError('Strides must be greater than output padding. '\n@@ -3082,7 +3082,7 @@ class ZeroPadding1D(Layer):\n \n   def __init__(self, padding=1, **kwargs):\n     super(ZeroPadding1D, self).__init__(**kwargs)\n-    self.padding = conv_utils.normalize_tuple(padding, 2, 'padding', lambda x: x >= 0, '>=0')\n+    self.padding = conv_utils.normalize_tuple(padding, 2, 'padding', allow_zero=True)\n     self.input_spec = InputSpec(ndim=3)\n \n   def compute_output_shape(self, input_shape):\n@@ -3178,9 +3178,9 @@ class ZeroPadding2D(Layer):\n         raise ValueError('`padding` should have two elements. '\n                          f'Received: {padding}.')\n       height_padding = conv_utils.normalize_tuple(padding[0], 2,\n-                                                  '1st entry of padding', lambda x: x >= 0, '>=0')\n+                                                  '1st entry of padding', allow_zero=True)\n       width_padding = conv_utils.normalize_tuple(padding[1], 2,\n-                                                 '2nd entry of padding', lambda x: x >= 0, '>=0')\n+                                                 '2nd entry of padding', allow_zero=True)\n       self.padding = (height_padding, width_padding)\n     else:\n       raise ValueError('`padding` should be either an int, '\n@@ -3292,13 +3292,13 @@ class ZeroPadding3D(Layer):\n                          f'Received: {padding}.')\n       dim1_padding = conv_utils.normalize_tuple(padding[0], 2,\n                                                 '1st entry of padding',\n-                                                lambda x: x >= 0, '>=0')\n+                                                allow_zero=True)\n       dim2_padding = conv_utils.normalize_tuple(padding[1], 2,\n                                                 '2nd entry of padding',\n-                                                lambda x: x >= 0, '>=0')\n+                                                allow_zero=True)\n       dim3_padding = conv_utils.normalize_tuple(padding[2], 2,\n                                                 '3rd entry of padding',\n-                                                lambda x: x >= 0, '>=0')\n+                                                allow_zero=True)\n       self.padding = (dim1_padding, dim2_padding, dim3_padding)\n     else:\n       raise ValueError(\n@@ -3393,8 +3393,8 @@ class Cropping1D(Layer):\n \n   def __init__(self, cropping=(1, 1), **kwargs):\n     super(Cropping1D, self).__init__(**kwargs)\n-    self.cropping = conv_utils.normalize_tuple(\n-        cropping, 2, 'cropping', lambda x: x >= 0, '>=0')\n+    self.cropping = conv_utils.normalize_tuple(cropping, 2, 'cropping',\n+                                               allow_zero=True)\n     self.input_spec = InputSpec(ndim=3)\n \n   def compute_output_shape(self, input_shape):\n@@ -3483,10 +3483,10 @@ class Cropping2D(Layer):\n                          f'Received: {cropping}.')\n       height_cropping = conv_utils.normalize_tuple(cropping[0], 2,\n                                                    '1st entry of cropping',\n-                                                   lambda x: x >= 0, '>=0')\n+                                                   allow_zero=True)\n       width_cropping = conv_utils.normalize_tuple(cropping[1], 2,\n                                                   '2nd entry of cropping',\n-                                                  lambda x: x >= 0, '>=0')\n+                                                  allow_zero=True)\n       self.cropping = (height_cropping, width_cropping)\n     else:\n       raise ValueError('`cropping` should be either an int, '\n@@ -3617,13 +3617,13 @@ class Cropping3D(Layer):\n                          f'Received: {cropping}.')\n       dim1_cropping = conv_utils.normalize_tuple(cropping[0], 2,\n                                                  '1st entry of cropping',\n-                                                 lambda x: x >= 0, '>=0')\n+                                                 allow_zero=True)\n       dim2_cropping = conv_utils.normalize_tuple(cropping[1], 2,\n                                                  '2nd entry of cropping',\n-                                                 lambda x: x >= 0, '>=0')\n+                                                 allow_zero=True)\n       dim3_cropping = conv_utils.normalize_tuple(cropping[2], 2,\n                                                  '3rd entry of cropping',\n-                                                 lambda x: x >= 0, '>=0')\n+                                                 allow_zero=True)\n       self.cropping = (dim1_cropping, dim2_cropping, dim3_cropping)\n     else:\n       raise ValueError(\n\n@@ -490,7 +490,7 @@ class ConvLSTMCell(DropoutRNNCellMixin, Layer):\n     self.kernel_size = conv_utils.normalize_tuple(\n         kernel_size, self.rank, 'kernel_size')\n     self.strides = conv_utils.normalize_tuple(\n-        strides, self.rank, 'strides', lambda x: x >= 0, '>=0')\n+        strides, self.rank, 'strides', allow_zero=True)\n     self.padding = conv_utils.normalize_padding(padding)\n     self.data_format = conv_utils.normalize_data_format(data_format)\n     self.dilation_rate = conv_utils.normalize_tuple(\n@@ -645,7 +645,7 @@ class ConvLSTMCell(DropoutRNNCellMixin, Layer):\n     return conv_out\n \n   def recurrent_conv(self, x, w):\n-    strides = conv_utils.normalize_tuple(1, self.rank, 'strides', lambda s: s >= 0, '>=0')\n+    strides = conv_utils.normalize_tuple(1, self.rank, 'strides', True)\n     conv_out = self._conv_func(\n         x, w, strides=strides, padding='same', data_format=self.data_format)\n     return conv_out\n\n@@ -133,7 +133,7 @@ class LocallyConnected1D(Layer):\n     super(LocallyConnected1D, self).__init__(**kwargs)\n     self.filters = filters\n     self.kernel_size = conv_utils.normalize_tuple(kernel_size, 1, 'kernel_size')\n-    self.strides = conv_utils.normalize_tuple(strides, 1, 'strides', lambda x: x >= 0, '>=0')\n+    self.strides = conv_utils.normalize_tuple(strides, 1, 'strides', True)\n     self.padding = conv_utils.normalize_padding(padding)\n     if self.padding != 'valid' and implementation == 1:\n       raise ValueError('Invalid border mode for LocallyConnected1D '\n@@ -440,7 +440,7 @@ class LocallyConnected2D(Layer):\n     super(LocallyConnected2D, self).__init__(**kwargs)\n     self.filters = filters\n     self.kernel_size = conv_utils.normalize_tuple(kernel_size, 2, 'kernel_size')\n-    self.strides = conv_utils.normalize_tuple(strides, 2, 'strides', lambda x: x >= 0, '>=0')\n+    self.strides = conv_utils.normalize_tuple(strides, 2, 'strides', True)\n     self.padding = conv_utils.normalize_padding(padding)\n     if self.padding != 'valid' and implementation == 1:\n       raise ValueError('Invalid border mode for LocallyConnected2D '\n\n@@ -57,7 +57,7 @@ class Pooling1D(Layer):\n       strides = pool_size\n     self.pool_function = pool_function\n     self.pool_size = conv_utils.normalize_tuple(pool_size, 1, 'pool_size')\n-    self.strides = conv_utils.normalize_tuple(strides, 1, 'strides', lambda x: x >= 0, '>=0')\n+    self.strides = conv_utils.normalize_tuple(strides, 1, 'strides', True)\n     self.padding = conv_utils.normalize_padding(padding)\n     self.data_format = conv_utils.normalize_data_format(data_format)\n     self.input_spec = InputSpec(ndim=3)\n@@ -340,7 +340,7 @@ class Pooling2D(Layer):\n       strides = pool_size\n     self.pool_function = pool_function\n     self.pool_size = conv_utils.normalize_tuple(pool_size, 2, 'pool_size')\n-    self.strides = conv_utils.normalize_tuple(strides, 2, 'strides', lambda x: x >= 0, '>=0')\n+    self.strides = conv_utils.normalize_tuple(strides, 2, 'strides', True)\n     self.padding = conv_utils.normalize_padding(padding)\n     self.data_format = conv_utils.normalize_data_format(data_format)\n     self.input_spec = InputSpec(ndim=4)\n@@ -678,7 +678,7 @@ class Pooling3D(Layer):\n       strides = pool_size\n     self.pool_function = pool_function\n     self.pool_size = conv_utils.normalize_tuple(pool_size, 3, 'pool_size')\n-    self.strides = conv_utils.normalize_tuple(strides, 3, 'strides', lambda x: x >= 0, '>=0')\n+    self.strides = conv_utils.normalize_tuple(strides, 3, 'strides', allow_zero=True)\n     self.padding = conv_utils.normalize_padding(padding)\n     self.data_format = conv_utils.normalize_data_format(data_format)\n     self.input_spec = InputSpec(ndim=5)\n\n@@ -49,7 +49,7 @@ def convert_data_format(data_format, ndim):\n         'Expected values are [\"channels_first\", \"channels_last\"]')\n \n \n-def normalize_tuple(value, n, name, validation_fn=lambda x: x > 0, fn_alt='>0'):\n+def normalize_tuple(value, n, name, allow_zero=False):\n   \"\"\"Transforms a single integer or iterable of integers into an integer tuple.\n \n   Args:\n@@ -58,8 +58,7 @@ def normalize_tuple(value, n, name, validation_fn=lambda x: x > 0, fn_alt='>0'):\n     n: The size of the tuple to be returned.\n     name: The name of the argument being validated, e.g. \"strides\" or\n       \"kernel_size\". This is only used to format error messages.\n-    validation_fn: the function used to filter out unqualified values.\n-    fn_alt: alternative text for validation_fn.\n+    allow_zero: Whether the function will accept zero values.\n   Returns:\n     A tuple of n integers.\n \n@@ -87,11 +86,16 @@ def normalize_tuple(value, n, name, validation_fn=lambda x: x > 0, fn_alt='>0'):\n                       f'type {type(single_value)}')\n         raise ValueError(error_msg)\n \n-  unqualified_values = [v for v in value_tuple if validation_fn and (not validation_fn(v))]\n+  if allow_zero:\n+    qualified_values = list(filter(lambda x: x >= 0, value_tuple))\n+    req_msg = '>=0'\n+  else:\n+    qualified_values = list(filter(lambda x: x > 0, value_tuple))\n+    req_msg = '>0'\n \n-  if len(unqualified_values) > 0:\n-    error_msg += (f' including {unqualified_values}'\n-                  f' that does not satisfy the requirement {fn_alt}.')\n+  if len(qualified_values) < len(value_tuple):\n+    error_msg += (f' including {qualified_values}'\n+                  f' that does not satisfy the requirement {req_msg}.')\n     raise ValueError(error_msg)\n \n   return value_tuple\n\n@@ -66,22 +66,19 @@ class TestBasicConvUtilsTest(tf.test.TestCase):\n       conv_utils.convert_data_format('invalid', 2)\n \n   def test_normalize_tuple(self):\n-    self.assertEqual((2, 2, 2),\n-                     conv_utils.normalize_tuple(2,\n-                                                n=3, name='strides', validation_fn=lambda x: x >= 0, fn_alt='>=0'))\n-    self.assertEqual((2, 1, 2),\n-                     conv_utils.normalize_tuple((2, 1, 2),\n-                                                n=3, name='strides', validation_fn=lambda x: x >= 0, fn_alt='>=0'))\n-    self.assertEqual((1, 2, 3,),\n-                     conv_utils.normalize_tuple((1, 2, 3), n=3, name='pool_size'))\n-    self.assertEqual((3, 3, 3),\n-                     conv_utils.normalize_tuple(3, n=3, name='pool_size'))\n-    self.assertEqual((3, -1, 3),\n-                     conv_utils.normalize_tuple((3, -1, 3),\n-                                                n=3, name='negative_size', validation_fn=None, fn_alt=None))\n+    self.assertEqual((2, 2, 2), conv_utils.normalize_tuple(\n+        2, n=3, name='strides', allow_zero=True))\n+    self.assertEqual((2, 1, 2), conv_utils.normalize_tuple(\n+        (2, 1, 2), n=3, name='strides', allow_zero=True))\n+    self.assertEqual((1, 2, 3,), conv_utils.normalize_tuple(\n+        (1, 2, 3), n=3, name='pool_size'))\n+    self.assertEqual((3, 3, 3), conv_utils.normalize_tuple(\n+        3, n=3, name='pool_size'))\n+    self.assertEqual((3, -1, 3), conv_utils.normalize_tuple(\n+        (3, -1, 3), n=3, name='negative_size', allow_zero=True))\n \n     with self.assertRaises(ValueError) as ctx:\n-      conv_utils.normalize_tuple((2, 1), n=3, name='strides', validation_fn=lambda x: x >= 0, fn_alt='>=0')\n+      conv_utils.normalize_tuple((2, 1), n=3, name='strides', allow_zero=True)\n     self.assertIn('The `strides` argument must be a tuple of 3', str(ctx.exception))\n \n     with self.assertRaises(ValueError) as ctx:\n@@ -89,7 +86,7 @@ class TestBasicConvUtilsTest(tf.test.TestCase):\n     self.assertIn('The `kernel_size` argument must be a tuple of 3', str(ctx.exception))\n \n     with self.assertRaises(ValueError) as ctx:\n-      conv_utils.normalize_tuple(-4, n=3, name='strides', validation_fn=lambda x: x >= 0, fn_alt='>=0')\n+      conv_utils.normalize_tuple(-4, n=3, name='strides', allow_zero=True)\n     self.assertIn('that does not satisfy the requirement >=0', str(ctx.exception))\n \n     with self.assertRaises(ValueError) as ctx:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#18faa2fa06f42afd39a5af3f99392ec43680f34e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 469 | Contributors (this commit): 3 | Commits (past 90d): 7 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -74,8 +74,10 @@ class TestBasicConvUtilsTest(tf.test.TestCase):\n         (1, 2, 3), n=3, name='pool_size'))\n     self.assertEqual((3, 3, 3), conv_utils.normalize_tuple(\n         3, n=3, name='pool_size'))\n-    self.assertEqual((3, -1, 3), conv_utils.normalize_tuple(\n-        (3, -1, 3), n=3, name='negative_size', allow_zero=True))\n+\n+    with self.assertRaises(ValueError) as ctx:\n+      conv_utils.normalize_tuple((3, -1, 3), n=3, name='negative_size')\n+    self.assertIn('that does not satisfy the requirement >0', str(ctx.exception))\n \n     with self.assertRaises(ValueError) as ctx:\n       conv_utils.normalize_tuple((2, 1), n=3, name='strides', allow_zero=True)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8a675e1bf9a5f1adcfe36cc5767d6072286beb32", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 18 | Lines Deleted: 20 | Files Changed: 3 | Hunks: 18 | Methods Changed: 4 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 38 | Churn Cumulative: 5922 | Contributors (this commit): 29 | Commits (past 90d): 23 | Contributors (cumulative): 41 | DMM Complexity: 0.0\n\nDIFF:\n@@ -57,7 +57,7 @@ class Pooling1D(Layer):\n       strides = pool_size\n     self.pool_function = pool_function\n     self.pool_size = conv_utils.normalize_tuple(pool_size, 1, 'pool_size')\n-    self.strides = conv_utils.normalize_tuple(strides, 1, 'strides', True)\n+    self.strides = conv_utils.normalize_tuple(strides, 1, 'strides', allow_zero=True)\n     self.padding = conv_utils.normalize_padding(padding)\n     self.data_format = conv_utils.normalize_data_format(data_format)\n     self.input_spec = InputSpec(ndim=3)\n@@ -340,7 +340,7 @@ class Pooling2D(Layer):\n       strides = pool_size\n     self.pool_function = pool_function\n     self.pool_size = conv_utils.normalize_tuple(pool_size, 2, 'pool_size')\n-    self.strides = conv_utils.normalize_tuple(strides, 2, 'strides', True)\n+    self.strides = conv_utils.normalize_tuple(strides, 2, 'strides', allow_zero=True)\n     self.padding = conv_utils.normalize_padding(padding)\n     self.data_format = conv_utils.normalize_data_format(data_format)\n     self.input_spec = InputSpec(ndim=4)\n\n@@ -50,7 +50,7 @@ def convert_data_format(data_format, ndim):\n \n \n def normalize_tuple(value, n, name, allow_zero=False):\n-  \"\"\"Transforms a single integer or iterable of integers into an integer tuple.\n+  \"\"\"Transforms non-negative/positive single integer/integers into an integer tuple.\n \n   Args:\n     value: The value to validate and convert. Could an int, or any iterable of\n@@ -58,12 +58,12 @@ def normalize_tuple(value, n, name, allow_zero=False):\n     n: The size of the tuple to be returned.\n     name: The name of the argument being validated, e.g. \"strides\" or\n       \"kernel_size\". This is only used to format error messages.\n-    allow_zero: Whether the function will accept zero values.\n+    allow_zero: Default to False. A ValueError will raised if zero is received and this param is False.\n   Returns:\n     A tuple of n integers.\n \n   Raises:\n-    ValueError: If something else than an int/long or iterable thereof was\n+    ValueError: If something else than an int/long or iterable thereof or a negative value is\n       passed.\n   \"\"\"\n   error_msg = (f'The `{name}` argument must be a tuple of {n} '\n@@ -87,15 +87,15 @@ def normalize_tuple(value, n, name, allow_zero=False):\n         raise ValueError(error_msg)\n \n   if allow_zero:\n-    qualified_values = list(filter(lambda x: x >= 0, value_tuple))\n+    unqualified_values = [v for v in value_tuple if v < 0]\n     req_msg = '>= 0'\n   else:\n-    qualified_values = list(filter(lambda x: x > 0, value_tuple))\n+    unqualified_values = [v for v in value_tuple if v <= 0]\n     req_msg = '> 0'\n \n-  if len(qualified_values) < len(value_tuple):\n-    error_msg += (f' including {qualified_values}'\n-                  f' that does not satisfy the requirement {req_msg}.')\n+  if len(unqualified_values) < len(value_tuple):\n+    error_msg += (f' including {unqualified_values}'\n+                  f' that does not satisfy the requirement `{req_msg}`.')\n     raise ValueError(error_msg)\n \n   return value_tuple\n\n@@ -75,25 +75,23 @@ class TestBasicConvUtilsTest(tf.test.TestCase):\n     self.assertEqual((3, 3, 3), conv_utils.normalize_tuple(\n         3, n=3, name='pool_size'))\n \n-    with self.assertRaises(ValueError) as ctx:\n+    with self.assertRaisesRegex(ValueError,\n+                                f'including {[-1]} that does not satisfy the requirement `> 0`') as ctx:\n       conv_utils.normalize_tuple((3, -1, 3), n=3, name='negative_size')\n-    self.assertIn('that does not satisfy the requirement >0', str(ctx.exception))\n \n-    with self.assertRaises(ValueError) as ctx:\n+    with self.assertRaisesRegex(ValueError, f'The `strides` argument must be a tuple of 3') as ctx:\n       conv_utils.normalize_tuple((2, 1), n=3, name='strides', allow_zero=True)\n-    self.assertIn('The `strides` argument must be a tuple of 3', str(ctx.exception))\n \n-    with self.assertRaises(ValueError) as ctx:\n+    with self.assertRaises(ValueError, 'The `kernel_size` argument must be a tuple of 3') as ctx:\n       conv_utils.normalize_tuple(None, n=3, name='kernel_size')\n-    self.assertIn('The `kernel_size` argument must be a tuple of 3', str(ctx.exception))\n \n-    with self.assertRaises(ValueError) as ctx:\n+    with self.assertRaises(ValueError,\n+                           f'including {[-4, -4, -4]} that does not satisfy the requirement `>= 0`') as ctx:\n       conv_utils.normalize_tuple(-4, n=3, name='strides', allow_zero=True)\n-    self.assertIn('that does not satisfy the requirement >=0', str(ctx.exception))\n \n-    with self.assertRaises(ValueError) as ctx:\n+    with self.assertRaises(ValueError,\n+                           f'including {[0]} that does not satisfy the requirement `> 0`') as ctx:\n       conv_utils.normalize_tuple((0, 1, 2), n=3, name='pool_size')\n-    self.assertIn('that does not satisfy the requirement >0', str(ctx.exception))\n \n   def test_normalize_data_format(self):\n     self.assertEqual('channels_last',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#da69df59e5344be7120dcea96eec1d845d188eac", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1193 | Contributors (this commit): 17 | Commits (past 90d): 11 | Contributors (cumulative): 17 | DMM Complexity: None\n\nDIFF:\n@@ -93,7 +93,7 @@ def normalize_tuple(value, n, name, allow_zero=False):\n     unqualified_values = [v for v in value_tuple if v <= 0]\n     req_msg = '> 0'\n \n-  if len(unqualified_values) < len(value_tuple):\n+  if len(unqualified_values) > 0:\n     error_msg += (f' including {unqualified_values}'\n                   f' that does not satisfy the requirement `{req_msg}`.')\n     raise ValueError(error_msg)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4d1a464760e2a7d7ed60fec1f04cbe462c5a5d62", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 5 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 14 | Churn Cumulative: 501 | Contributors (this commit): 3 | Commits (past 90d): 9 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -75,22 +75,24 @@ class TestBasicConvUtilsTest(tf.test.TestCase):\n     self.assertEqual((3, 3, 3), conv_utils.normalize_tuple(\n         3, n=3, name='pool_size'))\n \n-    with self.assertRaisesRegex(ValueError,\n-                                f'including {[-1]} that does not satisfy the requirement `> 0`') as ctx:\n+    msg_fmt1 = 'The `{}` argument must be a tuple of {} integers. Received: {}'\n+    msg_fmt2 = msg_fmt1 + ' including {} that does not satisfy the requirement `{}`.'\n+    with self.assertRaisesRegex(\n+            ValueError, msg_fmt2.format('negative_size', 3, (3, -1, 3), [-1], '> 0')):\n       conv_utils.normalize_tuple((3, -1, 3), n=3, name='negative_size')\n \n-    with self.assertRaisesRegex(ValueError, f'The `strides` argument must be a tuple of 3') as ctx:\n+    with self.assertRaisesRegex(ValueError, msg_fmt1.format('strides', 3, (2, 1))):\n       conv_utils.normalize_tuple((2, 1), n=3, name='strides', allow_zero=True)\n \n-    with self.assertRaises(ValueError, 'The `kernel_size` argument must be a tuple of 3') as ctx:\n+    with self.assertRaises(ValueError, msg_fmt1.format('kernel_size', 3, None)):\n       conv_utils.normalize_tuple(None, n=3, name='kernel_size')\n \n     with self.assertRaises(ValueError,\n-                           f'including {[-4, -4, -4]} that does not satisfy the requirement `>= 0`') as ctx:\n+                           msg_fmt2.format('strides', 3, -4, [-4, -4, -4], '>= 0')):\n       conv_utils.normalize_tuple(-4, n=3, name='strides', allow_zero=True)\n \n     with self.assertRaises(ValueError,\n-                           f'including {[0]} that does not satisfy the requirement `> 0`') as ctx:\n+                           msg_fmt2.format('pool_size', 3, (0, 1, 2), [0], '> 0')):\n       conv_utils.normalize_tuple((0, 1, 2), n=3, name='pool_size')\n \n   def test_normalize_data_format(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2e781d79dd93f20a9bc262f10317d0024353134c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 9 | Files Changed: 1 | Hunks: 6 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 18 | Churn Cumulative: 519 | Contributors (this commit): 3 | Commits (past 90d): 10 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -75,24 +75,24 @@ class TestBasicConvUtilsTest(tf.test.TestCase):\n     self.assertEqual((3, 3, 3), conv_utils.normalize_tuple(\n         3, n=3, name='pool_size'))\n \n-    msg_fmt1 = 'The `{}` argument must be a tuple of {} integers. Received: {}'\n-    msg_fmt2 = msg_fmt1 + ' including {} that does not satisfy the requirement `{}`.'\n     with self.assertRaisesRegex(\n-            ValueError, msg_fmt2.format('negative_size', 3, (3, -1, 3), [-1], '> 0')):\n+            ValueError, r'including \\[-1\\] that does not satisfy the requirement `> 0`'):\n       conv_utils.normalize_tuple((3, -1, 3), n=3, name='negative_size')\n \n-    with self.assertRaisesRegex(ValueError, msg_fmt1.format('strides', 3, (2, 1))):\n+    with self.assertRaisesRegex(\n+            ValueError, r'The `strides` argument .* a tuple of 3 integers .* \\(2, 1\\)$'):\n       conv_utils.normalize_tuple((2, 1), n=3, name='strides', allow_zero=True)\n \n-    with self.assertRaises(ValueError, msg_fmt1.format('kernel_size', 3, None)):\n+    with self.assertRaises(\n+            ValueError, r'The `kernel_size` argument .* tuple of 3 integers .* None$'):\n       conv_utils.normalize_tuple(None, n=3, name='kernel_size')\n \n-    with self.assertRaises(ValueError,\n-                           msg_fmt2.format('strides', 3, -4, [-4, -4, -4], '>= 0')):\n+    with self.assertRaises(\n+            ValueError, r'including \\[-4, -4, -4\\] that does not .* `>= 0`'):\n       conv_utils.normalize_tuple(-4, n=3, name='strides', allow_zero=True)\n \n-    with self.assertRaises(ValueError,\n-                           msg_fmt2.format('pool_size', 3, (0, 1, 2), [0], '> 0')):\n+    with self.assertRaises(\n+            ValueError, r'including \\[0\\] that does not .* `> 0`'):\n       conv_utils.normalize_tuple((0, 1, 2), n=3, name='pool_size')\n \n   def test_normalize_data_format(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#be235550ef05043fef1b18706ef7b2015861375b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 525 | Contributors (this commit): 3 | Commits (past 90d): 11 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -83,15 +83,15 @@ class TestBasicConvUtilsTest(tf.test.TestCase):\n             ValueError, r'The `strides` argument .* a tuple of 3 integers.* \\(2, 1\\)$'):\n       conv_utils.normalize_tuple((2, 1), n=3, name='strides', allow_zero=True)\n \n-    with self.assertRaises(\n+    with self.assertRaisesRegex(\n             ValueError, r'The `kernel_size` argument .* tuple of 3 integers.* None$'):\n       conv_utils.normalize_tuple(None, n=3, name='kernel_size')\n \n-    with self.assertRaises(\n+    with self.assertRaisesRegex(\n             ValueError, r'including \\[-4, -4, -4\\] that does not .* `>= 0`'):\n       conv_utils.normalize_tuple(-4, n=3, name='strides', allow_zero=True)\n \n-    with self.assertRaises(\n+    with self.assertRaisesRegex(\n             ValueError, r'including \\[0\\] that does not .* `> 0`'):\n       conv_utils.normalize_tuple((0, 1, 2), n=3, name='pool_size')\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1587fb9c43558b86fc34bbe441831be195488f72", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 8948 | Contributors (this commit): 33 | Commits (past 90d): 15 | Contributors (cumulative): 41 | DMM Complexity: None\n\nDIFF:\n@@ -645,7 +645,7 @@ class ConvLSTMCell(DropoutRNNCellMixin, Layer):\n     return conv_out\n \n   def recurrent_conv(self, x, w):\n-    strides = conv_utils.normalize_tuple(1, self.rank, 'strides', True)\n+    strides = conv_utils.normalize_tuple(1, self.rank, 'strides', allow_zero=True)\n     conv_out = self._conv_func(\n         x, w, strides=strides, padding='same', data_format=self.data_format)\n     return conv_out\n\n@@ -133,7 +133,7 @@ class LocallyConnected1D(Layer):\n     super(LocallyConnected1D, self).__init__(**kwargs)\n     self.filters = filters\n     self.kernel_size = conv_utils.normalize_tuple(kernel_size, 1, 'kernel_size')\n-    self.strides = conv_utils.normalize_tuple(strides, 1, 'strides', True)\n+    self.strides = conv_utils.normalize_tuple(strides, 1, 'strides', allow_zero=True)\n     self.padding = conv_utils.normalize_padding(padding)\n     if self.padding != 'valid' and implementation == 1:\n       raise ValueError('Invalid border mode for LocallyConnected1D '\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#dc82b3ee7eb7c4134f86a83eb465a21e1b620609", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 3198 | Contributors (this commit): 18 | Commits (past 90d): 10 | Contributors (cumulative): 18 | DMM Complexity: None\n\nDIFF:\n@@ -440,7 +440,7 @@ class LocallyConnected2D(Layer):\n     super(LocallyConnected2D, self).__init__(**kwargs)\n     self.filters = filters\n     self.kernel_size = conv_utils.normalize_tuple(kernel_size, 2, 'kernel_size')\n-    self.strides = conv_utils.normalize_tuple(strides, 2, 'strides', True)\n+    self.strides = conv_utils.normalize_tuple(strides, 2, 'strides', allow_zero=True)\n     self.padding = conv_utils.normalize_padding(padding)\n     if self.padding != 'valid' and implementation == 1:\n       raise ValueError('Invalid border mode for LocallyConnected2D '\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#dee8f31c68e71dc13a6d69917804c684689b11e7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 1726 | Contributors (this commit): 17 | Commits (past 90d): 24 | Contributors (cumulative): 20 | DMM Complexity: None\n\nDIFF:\n@@ -94,7 +94,7 @@ def normalize_tuple(value, n, name, allow_zero=False):\n     req_msg = '> 0'\n \n   if len(unqualified_values) > 0:\n-    error_msg += (f' including {unqualified_values}'\n+    error_msg += (f' including {set(unqualified_values)}'\n                   f' that does not satisfy the requirement `{req_msg}`.')\n     raise ValueError(error_msg)\n \n\n@@ -76,7 +76,7 @@ class TestBasicConvUtilsTest(tf.test.TestCase):\n         3, n=3, name='pool_size'))\n \n     with self.assertRaisesRegex(\n-            ValueError, r'including \\[-1\\] that does not satisfy the requirement `> 0`'):\n+            ValueError, r'including \\{-1\\} that does not satisfy the requirement `> 0`'):\n       conv_utils.normalize_tuple((3, -1, 3), n=3, name='negative_size')\n \n     with self.assertRaisesRegex(\n@@ -88,11 +88,11 @@ class TestBasicConvUtilsTest(tf.test.TestCase):\n       conv_utils.normalize_tuple(None, n=3, name='kernel_size')\n \n     with self.assertRaisesRegex(\n-            ValueError, r'including \\[-4, -4, -4\\] that does not .* `>= 0`'):\n+            ValueError, r'including \\{-4\\} that does not .* `>= 0`'):\n       conv_utils.normalize_tuple(-4, n=3, name='strides', allow_zero=True)\n \n     with self.assertRaisesRegex(\n-            ValueError, r'including \\[0\\] that does not .* `> 0`'):\n+            ValueError, r'including \\{0\\} that does not .* `> 0`'):\n       conv_utils.normalize_tuple((0, 1, 2), n=3, name='pool_size')\n \n   def test_normalize_data_format(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a3e794a8f786faf81071bffdc7d558f72d493f96", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 1201 | Contributors (this commit): 17 | Commits (past 90d): 13 | Contributors (cumulative): 17 | DMM Complexity: None\n\nDIFF:\n@@ -87,14 +87,14 @@ def normalize_tuple(value, n, name, allow_zero=False):\n         raise ValueError(error_msg)\n \n   if allow_zero:\n-    unqualified_values = [v for v in value_tuple if v < 0]\n+    unqualified_values = {v for v in value_tuple if v < 0}\n     req_msg = '>= 0'\n   else:\n-    unqualified_values = [v for v in value_tuple if v <= 0]\n+    unqualified_values = {v for v in value_tuple if v <= 0}\n     req_msg = '> 0'\n \n   if len(unqualified_values) > 0:\n-    error_msg += (f' including {set(unqualified_values)}'\n+    error_msg += (f' including {unqualified_values}'\n                   f' that does not satisfy the requirement `{req_msg}`.')\n     raise ValueError(error_msg)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e787c3d9cd6421c95c7088e2139145812ab2a100", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 260 | Lines Deleted: 159 | Files Changed: 6 | Hunks: 30 | Methods Changed: 23 | Complexity Δ (Sum/Max): 12/16 | Churn Δ: 419 | Churn Cumulative: 7593 | Contributors (this commit): 7 | Commits (past 90d): 31 | Contributors (cumulative): 22 | DMM Complexity: 1.0\n\nDIFF:\n@@ -14,22 +14,22 @@\n # ==============================================================================\n \"\"\"Keras CategoryEncoding preprocessing layer.\"\"\"\n \n-import tensorflow.compat.v2 as tf\n # pylint: disable=g-classes-have-attributes\n+# pylint: disable=g-direct-tensorflow-import\n \n-import numpy as np\n-from keras import backend\n from keras.engine import base_layer\n from keras.engine import base_preprocessing_layer\n+from keras.layers.preprocessing import preprocessing_utils as utils\n from keras.utils import layer_utils\n-from keras.utils import tf_utils\n+import numpy as np\n+import tensorflow.compat.v2 as tf\n from tensorflow.python.platform import tf_logging as logging\n from tensorflow.python.util.tf_export import keras_export\n \n-INT = \"int\"\n-ONE_HOT = \"one_hot\"\n-MULTI_HOT = \"multi_hot\"\n-COUNT = \"count\"\n+INT = utils.INT\n+ONE_HOT = utils.ONE_HOT\n+MULTI_HOT = utils.MULTI_HOT\n+COUNT = utils.COUNT\n \n \n @keras_export(\"keras.layers.CategoryEncoding\",\n@@ -180,35 +180,12 @@ class CategoryEncoding(base_layer.Layer):\n     if isinstance(inputs, (list, np.ndarray)):\n       inputs = tf.convert_to_tensor(inputs)\n \n-    def expand_dims(inputs, axis):\n-      if tf_utils.is_sparse(inputs):\n-        return tf.sparse.expand_dims(inputs, axis)\n-      else:\n-        return tf.expand_dims(inputs, axis)\n-\n-    original_shape = inputs.shape\n-    # In all cases, we should uprank scalar input to a single sample.\n-    if inputs.shape.rank == 0:\n-      inputs = expand_dims(inputs, -1)\n-    # One hot will unprank only if the final output dimension is not already 1.\n-    if self.output_mode == ONE_HOT:\n-      if inputs.shape[-1] != 1:\n-        inputs = expand_dims(inputs, -1)\n-\n-    # TODO(b/190445202): remove output rank restriction.\n-    if inputs.shape.rank > 2:\n-      raise ValueError(\n-          \"Received input shape {}, which would result in output rank {}. \"\n-          \"Currently only outputs up to rank 2 are supported.\".format(\n-              original_shape, inputs.shape.rank))\n-\n     if count_weights is not None and self.output_mode != COUNT:\n       raise ValueError(\n           \"`count_weights` is not used when `output_mode` is not `'count'`. \"\n           \"Received `count_weights={}`.\".format(count_weights))\n \n-    out_depth = self.num_tokens\n-    binary_output = self.output_mode in (MULTI_HOT, ONE_HOT)\n+    depth = self.num_tokens\n     if isinstance(inputs, tf.SparseTensor):\n       max_value = tf.reduce_max(inputs.values)\n       min_value = tf.reduce_min(inputs.values)\n@@ -216,58 +193,16 @@ class CategoryEncoding(base_layer.Layer):\n       max_value = tf.reduce_max(inputs)\n       min_value = tf.reduce_min(inputs)\n     condition = tf.logical_and(\n-        tf.greater(\n-            tf.cast(out_depth, max_value.dtype), max_value),\n-        tf.greater_equal(\n-            min_value, tf.cast(0, min_value.dtype)))\n+        tf.greater(tf.cast(depth, max_value.dtype), max_value),\n+        tf.greater_equal(min_value, tf.cast(0, min_value.dtype)))\n     assertion = tf.Assert(condition, [\n         \"Input values must be in the range 0 <= values < num_tokens\"\n-        \" with num_tokens={}\".format(out_depth)\n+        \" with num_tokens={}\".format(depth)\n     ])\n     with tf.control_dependencies([assertion]):\n-      if self.sparse:\n-        return sparse_bincount(inputs, out_depth, binary_output,\n-                               count_weights)\n-      else:\n-        return dense_bincount(inputs, out_depth, binary_output,\n-                              count_weights)\n-\n-\n-def sparse_bincount(inputs, out_depth, binary_output, count_weights=None):\n-  \"\"\"Apply binary or count encoding to an input and return a sparse tensor.\"\"\"\n-  result = tf.sparse.bincount(\n+      return utils.encode_categorical_inputs(\n           inputs,\n-      weights=count_weights,\n-      minlength=out_depth,\n-      maxlength=out_depth,\n-      axis=-1,\n-      binary_output=binary_output)\n-  if inputs.shape.rank == 1:\n-    output_shape = (out_depth,)\n-  else:\n-    result = tf.cast(result, backend.floatx())\n-    batch_size = tf.shape(result)[0]\n-    output_shape = (batch_size, out_depth)\n-  result = tf.SparseTensor(\n-      indices=result.indices,\n-      values=result.values,\n-      dense_shape=output_shape)\n-  return result\n-\n-\n-def dense_bincount(inputs, out_depth, binary_output, count_weights=None):\n-  \"\"\"Apply binary or count encoding to an input.\"\"\"\n-  result = tf.math.bincount(\n-      inputs,\n-      weights=count_weights,\n-      minlength=out_depth,\n-      maxlength=out_depth,\n-      dtype=backend.floatx(),\n-      axis=-1,\n-      binary_output=binary_output)\n-  if inputs.shape.rank == 1:\n-    result.set_shape(tf.TensorShape((out_depth,)))\n-  else:\n-    batch_size = inputs.shape.as_list()[0]\n-    result.set_shape(tf.TensorShape((batch_size, out_depth)))\n-  return result\n+          output_mode=self.output_mode,\n+          depth=depth,\n+          sparse=self.sparse,\n+          count_weights=count_weights)\n\n@@ -370,9 +370,9 @@ class CategoryEncodingOutputTest(keras_parameterized.TestCase,\n   def test_one_hot_rank_3_output_fails(self):\n     layer = category_encoding.CategoryEncoding(\n         num_tokens=4, output_mode=category_encoding.ONE_HOT)\n-    with self.assertRaisesRegex(ValueError, \"only outputs up to rank 2\"):\n+    with self.assertRaisesRegex(ValueError, \"maximum supported output rank\"):\n       _ = layer(keras.Input(shape=(4,), dtype=tf.int32))\n-    with self.assertRaisesRegex(ValueError, \"only outputs up to rank 2\"):\n+    with self.assertRaisesRegex(ValueError, \"maximum supported output rank\"):\n       _ = layer(np.array([[3, 2, 0, 1], [3, 2, 0, 1]]))\n \n   def test_multi_hot_output(self):\n@@ -436,9 +436,9 @@ class CategoryEncodingOutputTest(keras_parameterized.TestCase,\n   def test_multi_hot_rank_3_output_fails(self):\n     layer = category_encoding.CategoryEncoding(\n         num_tokens=4, output_mode=category_encoding.ONE_HOT)\n-    with self.assertRaisesRegex(ValueError, \"only outputs up to rank 2\"):\n+    with self.assertRaisesRegex(ValueError, \"maximum supported output rank\"):\n       _ = layer(keras.Input(shape=(3, 4,), dtype=tf.int32))\n-    with self.assertRaisesRegex(ValueError, \"only outputs up to rank 2\"):\n+    with self.assertRaisesRegex(ValueError, \"maximum supported output rank\"):\n       _ = layer(np.array([[[3, 2, 0, 1], [3, 2, 0, 1]]]))\n \n   def test_count_output(self):\n\n@@ -22,7 +22,6 @@ import collections\n from keras import backend\n from keras.engine import base_layer_utils\n from keras.engine import base_preprocessing_layer\n-from keras.layers.preprocessing import category_encoding\n from keras.layers.preprocessing import preprocessing_utils as utils\n from keras.saving.saved_model import layer_serialization\n from keras.utils import layer_utils\n@@ -31,11 +30,11 @@ import numpy as np\n import tensorflow.compat.v2 as tf\n from tensorflow.python.platform import tf_logging as logging\n \n-INT = \"int\"\n-MULTI_HOT = \"multi_hot\"\n-ONE_HOT = \"one_hot\"\n-COUNT = \"count\"\n-TF_IDF = \"tf_idf\"\n+INT = utils.INT\n+MULTI_HOT = utils.MULTI_HOT\n+ONE_HOT = utils.ONE_HOT\n+COUNT = utils.COUNT\n+TF_IDF = utils.TF_IDF\n \n _VOCAB_NAME = \"vocab\"\n _IDF_WEIGHTS_NAME = \"idf_weights\"\n@@ -295,11 +294,9 @@ class IndexLookup(base_preprocessing_layer.PreprocessingLayer):\n   def compute_output_shape(self, input_shape):\n     if self.output_mode == INT:\n       return input_shape\n-    if self.pad_to_max_tokens:\n-      out_depth = self.max_tokens\n-    else:\n-      out_depth = self.vocabulary_size()\n-    return tf.TensorShape([input_shape[0], out_depth])\n+    depth = (\n+        self.max_tokens if self.pad_to_max_tokens else self._frozen_vocab_size)\n+    return tf.TensorShape([input_shape[0], depth])\n \n   def compute_output_signature(self, input_spec):\n     output_shape = self.compute_output_shape(input_spec.shape.as_list())\n@@ -644,42 +641,15 @@ class IndexLookup(base_preprocessing_layer.PreprocessingLayer):\n         lookups = tf.squeeze(lookups, -1)\n       return lookups\n \n-    # One hot will unprank only if the final output dimension is not already 1.\n-    if self.output_mode == ONE_HOT:\n-      if lookups.shape[-1] != 1:\n-        lookups = self._expand_dims(lookups, -1)\n-\n-    # TODO(b/190445202): remove output rank restriction.\n-    if lookups.shape.rank > 2:\n-      raise ValueError(\n-          \"Received input shape {}, which would result in output rank {}. \"\n-          \"Currently only outputs up to rank 2 are supported for \"\n-          \"`output_mode={}`.\".format(original_shape, lookups.shape.rank,\n-                                     self.output_mode))\n-\n-    binary_output = self.output_mode in (MULTI_HOT, ONE_HOT)\n-    if self.pad_to_max_tokens:\n-      out_depth = self.max_tokens\n-    else:\n-      out_depth = self._frozen_vocab_size\n-    if self.sparse:\n-      bincounts = category_encoding.sparse_bincount(lookups, out_depth,\n-                                                    binary_output)\n-    else:\n-      bincounts = category_encoding.dense_bincount(lookups, out_depth,\n-                                                   binary_output)\n-\n-    if self.output_mode == TF_IDF:\n-      if self.sparse:\n-        value_weights = tf.gather(self.idf_weights_const,\n-                                  bincounts.indices[:, -1])\n-        return tf.SparseTensor(bincounts.indices,\n-                               value_weights * bincounts.values,\n-                               bincounts.dense_shape)\n-      else:\n-        return tf.multiply(bincounts, self.idf_weights_const)\n-\n-    return bincounts\n+    depth = (\n+        self.max_tokens if self.pad_to_max_tokens else self._frozen_vocab_size)\n+    idf_weights = self.idf_weights_const if self.output_mode == TF_IDF else None\n+    return utils.encode_categorical_inputs(\n+        lookups,\n+        output_mode=self.output_mode,\n+        depth=depth,\n+        sparse=self.sparse,\n+        idf_weights=idf_weights)\n \n   def _lookup_dense(self, inputs):\n     \"\"\"Lookup table values for a dense Tensor, handling masking and OOV.\"\"\"\n@@ -725,9 +695,6 @@ class IndexLookup(base_preprocessing_layer.PreprocessingLayer):\n     with tf.control_dependencies(lookup_checks):\n       return tf.identity(lookups)\n \n-  def _encode_output(self, lookups):\n-    \"\"\"Encode the lookup result to the final output depending on output_mode.\"\"\"\n-\n   def _uninitialized_lookup_table(self):\n     with tf.init_scope():\n       initializer = NullInitializer(self._key_dtype, self._value_dtype)\n@@ -789,7 +756,7 @@ class IndexLookup(base_preprocessing_layer.PreprocessingLayer):\n     with tf.init_scope():\n       if not tf.executing_eagerly():\n         raise RuntimeError(\n-            \"When using `output_mode={}` eager mode execution must be enabled.\"\n+            \"When using `output_mode={}` eager execution must be enabled.\"\n             .format(self.output_mode))\n       new_vocab_size = self.vocabulary_size()\n     if new_vocab_size == self._token_start_index():\n\n@@ -14,9 +14,17 @@\n # ==============================================================================\n \"\"\"Utils for preprocessing layers.\"\"\"\n \n+from keras import backend\n+from keras.utils import tf_utils\n import numpy as np\n import tensorflow.compat.v2 as tf\n \n+INT = \"int\"\n+ONE_HOT = \"one_hot\"\n+MULTI_HOT = \"multi_hot\"\n+COUNT = \"count\"\n+TF_IDF = \"tf_idf\"\n+\n \n def listify_tensors(x):\n   \"\"\"Convert any tensors or numpy arrays to lists for config serialization.\"\"\"\n@@ -25,3 +33,97 @@ def listify_tensors(x):\n   if isinstance(x, np.ndarray):\n     x = x.tolist()\n   return x\n+\n+\n+def sparse_bincount(inputs, depth, binary_output, count_weights=None):\n+  \"\"\"Apply binary or count encoding to an input and return a sparse tensor.\"\"\"\n+  result = tf.sparse.bincount(\n+      inputs,\n+      weights=count_weights,\n+      minlength=depth,\n+      maxlength=depth,\n+      axis=-1,\n+      binary_output=binary_output)\n+  result = tf.cast(result, backend.floatx())\n+  if inputs.shape.rank == 1:\n+    output_shape = (depth,)\n+  else:\n+    batch_size = tf.shape(result)[0]\n+    output_shape = (batch_size, depth)\n+  result = tf.SparseTensor(\n+      indices=result.indices, values=result.values, dense_shape=output_shape)\n+  return result\n+\n+\n+def dense_bincount(inputs, depth, binary_output, count_weights=None):\n+  \"\"\"Apply binary or count encoding to an input.\"\"\"\n+  result = tf.math.bincount(\n+      inputs,\n+      weights=count_weights,\n+      minlength=depth,\n+      maxlength=depth,\n+      dtype=backend.floatx(),\n+      axis=-1,\n+      binary_output=binary_output)\n+  if inputs.shape.rank == 1:\n+    result.set_shape(tf.TensorShape((depth,)))\n+  else:\n+    batch_size = inputs.shape.as_list()[0]\n+    result.set_shape(tf.TensorShape((batch_size, depth)))\n+  return result\n+\n+\n+def expand_dims(inputs, axis):\n+  if tf_utils.is_sparse(inputs):\n+    return tf.sparse.expand_dims(inputs, axis)\n+  else:\n+    return tf.expand_dims(inputs, axis)\n+\n+\n+def encode_categorical_inputs(inputs,\n+                              output_mode,\n+                              depth,\n+                              sparse=False,\n+                              count_weights=None,\n+                              idf_weights=None):\n+  \"\"\"Encodes categoical inputs according to output_mode.\"\"\"\n+  if output_mode == INT:\n+    return inputs\n+\n+  original_shape = inputs.shape\n+  # In all cases, we should uprank scalar input to a single sample.\n+  if inputs.shape.rank == 0:\n+    inputs = expand_dims(inputs, -1)\n+  # One hot will unprank only if the final output dimension is not already 1.\n+  if output_mode == ONE_HOT:\n+    if inputs.shape[-1] != 1:\n+      inputs = expand_dims(inputs, -1)\n+\n+  # TODO(b/190445202): remove output rank restriction.\n+  if inputs.shape.rank > 2:\n+    raise ValueError(\n+        f\"When output_mode is not `'int'`, maximum supported output rank is 2. \"\n+        f\"Received output_mode {output_mode} and input shape {original_shape}, \"\n+        f\"which would result in output rank {inputs.shape.rank}.\")\n+\n+  binary_output = output_mode in (MULTI_HOT, ONE_HOT)\n+  if sparse:\n+    bincounts = sparse_bincount(inputs, depth, binary_output, count_weights)\n+  else:\n+    bincounts = dense_bincount(inputs, depth, binary_output, count_weights)\n+\n+  if output_mode != TF_IDF:\n+    return bincounts\n+\n+  if idf_weights is None:\n+    raise ValueError(\n+        f\"When output mode is `'tf_idf'`, idf_weights must be provided. \"\n+        f\"Received: output_mode={output_mode} and idf_weights={idf_weights}\")\n+\n+  if sparse:\n+    value_weights = tf.gather(idf_weights, bincounts.indices[:, -1])\n+    return tf.SparseTensor(bincounts.indices,\n+                           value_weights * bincounts.values,\n+                           bincounts.dense_shape)\n+  else:\n+    return tf.multiply(bincounts, idf_weights)\n\n@@ -0,0 +1,115 @@\n+# Copyright 2021 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Tests for preprocessing utils.\"\"\"\n+\n+from absl.testing import parameterized\n+from keras import keras_parameterized\n+from keras.layers.preprocessing import preprocessing_utils\n+import numpy as np\n+import tensorflow.compat.v2 as tf\n+\n+\n+@keras_parameterized.run_all_keras_modes(always_skip_v1=True)\n+class ListifyTensorsTest(keras_parameterized.TestCase):\n+\n+  def test_tensor_input(self):\n+    inputs = tf.constant([0, 1, 2, 3, 4])\n+    outputs = preprocessing_utils.listify_tensors(inputs)\n+    self.assertAllEqual([0, 1, 2, 3, 4], outputs)\n+    self.assertIsInstance(outputs, list)\n+\n+  def test_numpy_input(self):\n+    inputs = np.array([0, 1, 2, 3, 4])\n+    outputs = preprocessing_utils.listify_tensors(inputs)\n+    self.assertAllEqual([0, 1, 2, 3, 4], outputs)\n+    self.assertIsInstance(outputs, list)\n+\n+\n+@keras_parameterized.run_all_keras_modes\n+class EncodeCategoricalInputsTest(keras_parameterized.TestCase):\n+\n+  def test_int_encoding(self):\n+    inputs = tf.constant([0, 1, 2])\n+    outputs = preprocessing_utils.encode_categorical_inputs(\n+        inputs, output_mode='int', depth=4)\n+    self.assertAllEqual([0, 1, 2], outputs)\n+\n+  @parameterized.named_parameters(\n+      ('sparse', True),\n+      ('dense', False),\n+  )\n+  def test_one_hot_encoding(self, sparse):\n+    inputs = tf.constant([0, 1, 2])\n+    outputs = preprocessing_utils.encode_categorical_inputs(\n+        inputs, output_mode='one_hot', depth=4, sparse=sparse)\n+    if sparse:\n+      outputs = tf.sparse.to_dense(outputs)\n+    self.assertAllEqual([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0]], outputs)\n+\n+  @parameterized.named_parameters(\n+      ('sparse', True),\n+      ('dense', False),\n+  )\n+  def test_multi_hot_encoding(self, sparse):\n+    inputs = tf.constant([0, 1, 2])\n+    outputs = preprocessing_utils.encode_categorical_inputs(\n+        inputs, output_mode='multi_hot', depth=4, sparse=sparse)\n+    if sparse:\n+      outputs = tf.sparse.to_dense(outputs)\n+    self.assertAllEqual([1, 1, 1, 0], outputs)\n+\n+  @parameterized.named_parameters(\n+      ('sparse', True),\n+      ('dense', False),\n+  )\n+  def test_count_encoding(self, sparse):\n+    inputs = tf.constant([0, 1, 1, 2, 2, 2])\n+    outputs = preprocessing_utils.encode_categorical_inputs(\n+        inputs, output_mode='count', depth=4, sparse=sparse)\n+    if sparse:\n+      outputs = tf.sparse.to_dense(outputs)\n+    self.assertAllEqual([1, 2, 3, 0], outputs)\n+\n+  @parameterized.named_parameters(\n+      ('sparse', True),\n+      ('dense', False),\n+  )\n+  def test_tf_idf_encoding(self, sparse):\n+    inputs = tf.constant([0, 1, 1, 2, 2, 2])\n+    outputs = preprocessing_utils.encode_categorical_inputs(\n+        inputs,\n+        output_mode='tf_idf',\n+        depth=4,\n+        sparse=sparse,\n+        idf_weights=[0.1, 1.0, 10.0, 0])\n+    if sparse:\n+      outputs = tf.sparse.to_dense(outputs)\n+    self.assertAllClose([.1, 2, 30, 0], outputs)\n+\n+  def test_rank_3_output_fails(self):\n+    inputs = tf.constant([[[0]], [[1]], [[2]]])\n+    with self.assertRaisesRegex(ValueError,\n+                                'maximum supported output rank is 2'):\n+      preprocessing_utils.encode_categorical_inputs(inputs, 'multi_hot', 4)\n+\n+  def test_tf_idf_output_with_no_weights_fails(self):\n+    inputs = tf.constant([0, 1, 2])\n+    with self.assertRaisesRegex(ValueError,\n+                                'idf_weights must be provided'):\n+      preprocessing_utils.encode_categorical_inputs(inputs, 'tf_idf', 4)\n+\n+\n+if __name__ == '__main__':\n+  tf.test.main()\n\n@@ -19,7 +19,6 @@\n \n from keras import backend\n from keras.engine import base_preprocessing_layer\n-from keras.layers.preprocessing import index_lookup\n from keras.layers.preprocessing import preprocessing_utils as utils\n from keras.layers.preprocessing import string_lookup\n from keras.saving.saved_model import layer_serialization\n@@ -30,35 +29,18 @@ import tensorflow.compat.v2 as tf\n from tensorflow.python.util.tf_export import keras_export\n \n LOWER_AND_STRIP_PUNCTUATION = \"lower_and_strip_punctuation\"\n-\n SPLIT_ON_WHITESPACE = \"whitespace\"\n \n-TF_IDF = index_lookup.TF_IDF\n-INT = index_lookup.INT\n-MULTI_HOT = index_lookup.MULTI_HOT\n-COUNT = index_lookup.COUNT\n+TF_IDF = utils.TF_IDF\n+INT = utils.INT\n+MULTI_HOT = utils.MULTI_HOT\n+COUNT = utils.COUNT\n \n # This is an explicit regex of all the tokens that will be stripped if\n # LOWER_AND_STRIP_PUNCTUATION is set. If an application requires other\n # stripping, a Callable should be passed into the 'standardize' arg.\n DEFAULT_STRIP_REGEX = r'[!\"#$%&()\\*\\+,-\\./:;<=>?@\\[\\\\\\]^_`{|}~\\']'\n \n-# The string tokens in the extracted vocabulary\n-_VOCAB_NAME = \"vocab\"\n-# The inverse-document-frequency weights\n-_IDF_NAME = \"idf\"\n-# The IDF data for the OOV token\n-_OOV_IDF_NAME = \"oov_idf\"\n-\n-# The string tokens in the full vocabulary\n-_ACCUMULATOR_VOCAB_NAME = \"vocab\"\n-# The total counts of each token in the vocabulary\n-_ACCUMULATOR_COUNTS_NAME = \"counts\"\n-# The number of documents / examples that each token appears in.\n-_ACCUMULATOR_DOCUMENT_COUNTS = \"document_counts\"\n-# The total number of documents / examples in the dataset.\n-_ACCUMULATOR_NUM_DOCUMENTS = \"num_documents\"\n-\n \n @keras_export(\n     \"keras.layers.TextVectorization\",\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
