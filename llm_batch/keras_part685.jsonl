{"custom_id": "keras#30f71b8150ba886e5e176bb516916caf38145e70", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 47 | Lines Deleted: 34 | Files Changed: 2 | Hunks: 12 | Methods Changed: 8 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 81 | Churn Cumulative: 491 | Contributors (this commit): 4 | Commits (past 90d): 15 | Contributors (cumulative): 7 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,10 +1,6 @@\n-import numpy as np\n-\n-from keras_core import backend\n from keras_core.api_export import keras_core_export\n-from keras_core.layers.layer import Layer\n-from keras_core.utils import backend_utils\n-from keras_core.utils.module_utils import tensorflow as tf\n+from keras_core.layers.preprocessing.tf_data_layer import TFDataLayer\n+from keras_core.random.seed_generator import SeedGenerator\n \n HORIZONTAL = \"horizontal\"\n VERTICAL = \"vertical\"\n@@ -12,7 +8,7 @@ HORIZONTAL_AND_VERTICAL = \"horizontal_and_vertical\"\n \n \n @keras_core_export(\"keras_core.layers.RandomFlip\")\n-class RandomFlip(Layer):\n+class RandomFlip(TFDataLayer):\n     \"\"\"A preprocessing layer which randomly flips images during training.\n \n     This layer will flip the images horizontally and or vertically based on the\n@@ -46,39 +42,44 @@ class RandomFlip(Layer):\n     def __init__(\n         self, mode=HORIZONTAL_AND_VERTICAL, seed=None, name=None, **kwargs\n     ):\n-        if not tf.available:\n-            raise ImportError(\n-                \"Layer RandomFlip requires TensorFlow. \"\n-                \"Install it via `pip install tensorflow`.\"\n-            )\n-\n         super().__init__(name=name)\n-        self.seed = seed or backend.random.make_default_seed()\n-        self.layer = tf.keras.layers.RandomFlip(\n-            mode=mode,\n-            name=name,\n-            seed=self.seed,\n-            **kwargs,\n-        )\n+        self.seed = seed\n+        self.generator = SeedGenerator(seed)\n+        self.mode = mode\n         self.supports_jit = False\n         self._convert_input_args = False\n         self._allow_non_tensor_positional_args = True\n \n     def call(self, inputs, training=True):\n-        if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n-            inputs = tf.convert_to_tensor(backend.convert_to_numpy(inputs))\n-        outputs = self.layer.call(inputs, training=training)\n-        if (\n-            backend.backend() != \"tensorflow\"\n-            and not backend_utils.in_tf_graph()\n-        ):\n-            outputs = backend.convert_to_tensor(outputs)\n-        return outputs\n+        def random_flipped_inputs(inputs):\n+            flipped_outputs = inputs\n+            seed_generator = self._get_seed_generator()\n+            if self.mode == HORIZONTAL or self.mode == HORIZONTAL_AND_VERTICAL:\n+                flipped_outputs = self.backend.cond(\n+                    self.backend.random.uniform(shape=(), seed=seed_generator)\n+                    <= 0.5,\n+                    lambda: self.backend.numpy.flip(flipped_outputs, axis=-2),\n+                    lambda: flipped_outputs,\n+                )\n+            if self.mode == VERTICAL or self.mode == HORIZONTAL_AND_VERTICAL:\n+                flipped_outputs = self.backend.cond(\n+                    self.backend.random.uniform(shape=(), seed=seed_generator)\n+                    <= 0.5,\n+                    lambda: self.backend.numpy.flip(flipped_outputs, axis=-3),\n+                    lambda: flipped_outputs,\n+                )\n+            return flipped_outputs\n+\n+        inputs = self.backend.cast(inputs, self.compute_dtype)\n+        if training:\n+            return random_flipped_inputs(inputs)\n+        else:\n+            return inputs\n \n     def compute_output_shape(self, input_shape):\n-        return tuple(self.layer.compute_output_shape(input_shape))\n+        return input_shape\n \n     def get_config(self):\n-        config = self.layer.get_config()\n-        config.update({\"seed\": self.seed})\n+        config = super().get_config()\n+        config.update({\"seed\": self.seed, \"mode\": self.mode})\n         return config\n\n@@ -1,3 +1,4 @@\n+import unittest.mock\n import numpy as np\n import tensorflow as tf\n from absl.testing import parameterized\n@@ -8,6 +9,17 @@ from keras_core import testing\n from keras_core import utils\n \n \n+class MockedRandomFlip(layers.RandomFlip):\n+    def call(self, inputs, training=True):\n+        with unittest.mock.patch.object(\n+                self.backend.random,\n+                \"uniform\",\n+                return_value=0.1\n+        ):\n+            out = super().call(inputs, training=training)\n+        return out\n+\n+\n class RandomFlipTest(testing.TestCase, parameterized.TestCase):\n     @parameterized.named_parameters(\n         (\"random_flip_horizontal\", \"horizontal\"),\n@@ -29,7 +41,7 @@ class RandomFlipTest(testing.TestCase, parameterized.TestCase):\n     def test_random_flip_horizontal(self):\n         utils.set_random_seed(0)\n         self.run_layer_test(\n-            layers.RandomFlip,\n+            MockedRandomFlip,\n             init_kwargs={\n                 \"mode\": \"horizontal\",\n                 \"seed\": 42,\n@@ -43,7 +55,7 @@ class RandomFlipTest(testing.TestCase, parameterized.TestCase):\n     def test_random_flip_vertical(self):\n         utils.set_random_seed(0)\n         self.run_layer_test(\n-            layers.RandomFlip,\n+            MockedRandomFlip,\n             init_kwargs={\n                 \"mode\": \"vertical\",\n                 \"seed\": 42,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9068899c0de65b21f79aaab1aafecc4edd752f42", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 118 | Lines Deleted: 30 | Files Changed: 1 | Hunks: 11 | Methods Changed: 8 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 148 | Churn Cumulative: 2186 | Contributors (this commit): 11 | Commits (past 90d): 46 | Contributors (cumulative): 11 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,14 +1,15 @@\n-import numpy as np\n-\n from keras_core import backend\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n-from keras_core.layers.layer import Layer\n+from keras_core.layers.preprocessing.tf_data_layer import TFDataLayer\n+from keras_core.random.seed_generator import SeedGenerator\n from keras_core.utils import backend_utils\n-from keras_core.utils.module_utils import tensorflow as tf\n+from keras_core.utils import image_utils\n+from keras_core.utils import dtype_utils\n \n \n @keras_core_export(\"keras_core.layers.RandomCrop\")\n-class RandomCrop(Layer):\n+class RandomCrop(TFDataLayer):\n     \"\"\"A preprocessing layer which randomly crops images during training.\n \n     During training, this layer will randomly choose a location to crop images\n@@ -52,41 +53,128 @@ class RandomCrop(Layer):\n             `name` and `dtype`.\n     \"\"\"\n \n-    def __init__(self, height, width, seed=None, name=None, **kwargs):\n-        if not tf.available:\n-            raise ImportError(\n-                \"Layer RandomCrop requires TensorFlow. \"\n-                \"Install it via `pip install tensorflow`.\"\n-            )\n-\n+    def __init__(\n+        self, height, width, seed=None, data_format=None, name=None, **kwargs\n+    ):\n         super().__init__(name=name, **kwargs)\n+        self.height = height\n+        self.width = width\n         self.seed = seed or backend.random.make_default_seed()\n-        self.layer = tf.keras.layers.RandomCrop(\n-            height=height,\n-            width=width,\n-            seed=self.seed,\n-            name=name,\n-        )\n+        self.seed_generator = SeedGenerator(seed)\n+        self.data_format = backend.standardize_data_format(data_format)\n+\n+        if self.data_format == \"channels_first\":\n+            self.heigh_axis = -2\n+            self.width_axis = -1\n+        elif self.data_format == \"channels_last\":\n+            self.height_axis = -3\n+            self.width_axis = -2\n+\n         self.supports_masking = False\n         self.supports_jit = False\n         self._convert_input_args = False\n         self._allow_non_tensor_positional_args = True\n \n     def call(self, inputs, training=True):\n-        if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n-            inputs = tf.convert_to_tensor(backend.convert_to_numpy(inputs))\n-        outputs = self.layer.call(inputs, training=training)\n-        if (\n-            backend.backend() != \"tensorflow\"\n-            and not backend_utils.in_tf_graph()\n-        ):\n-            outputs = backend.convert_to_tensor(outputs)\n+        inputs = self.backend.cast(inputs, self.compute_dtype)\n+        input_shape = self.backend.shape(inputs)\n+        is_batched = len(input_shape) > 3\n+        inputs = (\n+            self.backend.numpy.expand_dims(inputs, axis=0)\n+            if not is_batched\n+            else inputs\n+        )\n+\n+        h_diff = input_shape[self.height_axis] - self.height\n+        w_diff = input_shape[self.width_axis] - self.width\n+\n+        def random_crop():\n+            # input_dtype_max = (2 ** dtype_utils.dtype_size(inputs.dtype)) - 1\n+            input_height, input_width = (\n+                input_shape[self.height_axis],\n+                input_shape[self.width_axis],\n+            )\n+\n+            h_start = self.backend.cast(\n+                ops.random.uniform(\n+                    (),\n+                    0,\n+                    maxval=float(input_height - self.height + 1),\n+                    dtype=inputs.dtype,\n+                    seed=self.seed_generator,\n+                ),\n+                h_diff.dtype,\n+            )\n+            w_start = self.backend.cast(\n+                ops.random.uniform(\n+                    (),\n+                    0,\n+                    maxval=float(input_width - self.width + 1),\n+                    dtype=inputs.dtype,\n+                    seed=self.seed_generator,\n+                ),\n+                h_diff.dtype,\n+            )\n+            # rands = ops.random.uniform(\n+            #     [2], 0, input_dtype_max, inputs.dtype, seed=self.seed_generator\n+            # )\n+            # original_dtype = h_diff.dtype\n+            # h_start = self.backend.cast(\n+            #     rands[0] % self.backend.cast((h_diff + 1), self.compute_dtype),\n+            #     original_dtype,\n+            # )\n+            # w_start = self.backend.cast(\n+            #     rands[1] % self.backend.cast((w_diff + 1), self.compute_dtype),\n+            #     original_dtype,\n+            # )\n+            if self.data_format == \"channels_last\":\n+                return inputs[\n+                    :,\n+                    h_start : h_start + self.height,\n+                    w_start : w_start + self.width,\n+                ]\n+            else:\n+                return inputs[\n+                    :,\n+                    :,\n+                    h_start : h_start + self.height,\n+                    w_start : w_start + self.width,\n+                ]\n+\n+        def resize():\n+            outputs = image_utils.smart_resize(\n+                inputs,\n+                [self.height, self.width],\n+                data_format=self.data_format,\n+                backend_module=self.backend,\n+            )\n+            # smart_resize will always output float32, so we need to re-cast.\n+            return self.backend.cast(outputs, self.compute_dtype)\n+\n+        outputs = self.backend.cond(\n+            self.backend.numpy.all((training, h_diff >= 0, w_diff >= 0)),\n+            random_crop,\n+            resize,\n+        )\n+\n+        if self.backend != \"tensorflow\" and not backend_utils.in_tf_graph():\n+            outputs = self.backend.convert_to_tensor(outputs)\n         return outputs\n \n-    def compute_output_shape(self, input_shape):\n-        return tuple(self.layer.compute_output_shape(input_shape))\n+    def compute_output_shape(self, input_shape, *args, **kwargs):\n+        input_shape = list(input_shape)\n+        input_shape[self.height_axis] = self.height\n+        input_shape[self.width_axis] = self.width\n+        return tuple(input_shape)\n \n     def get_config(self):\n-        config = self.layer.get_config()\n-        config.update({\"seed\": self.seed})\n+        config = super().get_config()\n+        config.update(\n+            {\n+                \"height\": self.height,\n+                \"width\": self.width,\n+                \"seed\": self.seed,\n+                \"data_format\": self.data_format,\n+            }\n+        )\n         return config\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7c712b194def013432ba8e6a3ad5b22aa203507c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 13 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 13 | Churn Cumulative: 2199 | Contributors (this commit): 11 | Commits (past 90d): 47 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -89,7 +89,6 @@ class RandomCrop(TFDataLayer):\n         w_diff = input_shape[self.width_axis] - self.width\n \n         def random_crop():\n-            # input_dtype_max = (2 ** dtype_utils.dtype_size(inputs.dtype)) - 1\n             input_height, input_width = (\n                 input_shape[self.height_axis],\n                 input_shape[self.width_axis],\n@@ -115,18 +114,6 @@ class RandomCrop(TFDataLayer):\n                 ),\n                 h_diff.dtype,\n             )\n-            # rands = ops.random.uniform(\n-            #     [2], 0, input_dtype_max, inputs.dtype, seed=self.seed_generator\n-            # )\n-            # original_dtype = h_diff.dtype\n-            # h_start = self.backend.cast(\n-            #     rands[0] % self.backend.cast((h_diff + 1), self.compute_dtype),\n-            #     original_dtype,\n-            # )\n-            # w_start = self.backend.cast(\n-            #     rands[1] % self.backend.cast((w_diff + 1), self.compute_dtype),\n-            #     original_dtype,\n-            # )\n             if self.data_format == \"channels_last\":\n                 return inputs[\n                     :,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#15788b5d1bc11852d03a6c0e5088ce05bc8c21ac", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 2203 | Contributors (this commit): 11 | Commits (past 90d): 48 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -102,7 +102,7 @@ class RandomCrop(TFDataLayer):\n                     dtype=inputs.dtype,\n                     seed=self.seed_generator,\n                 ),\n-                h_diff.dtype,\n+                \"int32\",\n             )\n             w_start = self.backend.cast(\n                 ops.random.uniform(\n@@ -112,7 +112,7 @@ class RandomCrop(TFDataLayer):\n                     dtype=inputs.dtype,\n                     seed=self.seed_generator,\n                 ),\n-                h_diff.dtype,\n+                \"int32\",\n             )\n             if self.data_format == \"channels_last\":\n                 return inputs[\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8172f4cf7fcfc87e0e19f402dc1c82b8c63ede51", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 7 | Churn Cumulative: 2210 | Contributors (this commit): 11 | Commits (past 90d): 49 | Contributors (cumulative): 11 | DMM Complexity: 1.0\n\nDIFF:\n@@ -5,7 +5,6 @@ from keras_core.layers.preprocessing.tf_data_layer import TFDataLayer\n from keras_core.random.seed_generator import SeedGenerator\n from keras_core.utils import backend_utils\n from keras_core.utils import image_utils\n-from keras_core.utils import dtype_utils\n \n \n @keras_core_export(\"keras_core.layers.RandomCrop\")\n@@ -144,6 +143,12 @@ class RandomCrop(TFDataLayer):\n             resize,\n         )\n \n+        outputs = (\n+            self.backend.numpy.squeeze(outputs, axis=0)\n+            if not is_batched\n+            else outputs\n+        )\n+\n         if self.backend != \"tensorflow\" and not backend_utils.in_tf_graph():\n             outputs = self.backend.convert_to_tensor(outputs)\n         return outputs\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5c06f2c17c6b422c31dae20b2afe68158ecc9129", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 328 | Lines Deleted: 187 | Files Changed: 3 | Hunks: 59 | Methods Changed: 33 | Complexity Δ (Sum/Max): 15/11 | Churn Δ: 515 | Churn Cumulative: 3099 | Contributors (this commit): 12 | Commits (past 90d): 62 | Contributors (cumulative): 19 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,14 +1,14 @@\n+import numpy as np\n+\n from keras_core import backend\n-from keras_core import ops\n from keras_core.api_export import keras_core_export\n-from keras_core.layers.preprocessing.tf_data_layer import TFDataLayer\n-from keras_core.random.seed_generator import SeedGenerator\n+from keras_core.layers.layer import Layer\n from keras_core.utils import backend_utils\n-from keras_core.utils import image_utils\n+from keras_core.utils.module_utils import tensorflow as tf\n \n \n @keras_core_export(\"keras_core.layers.RandomCrop\")\n-class RandomCrop(TFDataLayer):\n+class RandomCrop(Layer):\n     \"\"\"A preprocessing layer which randomly crops images during training.\n \n     During training, this layer will randomly choose a location to crop images\n@@ -52,121 +52,41 @@ class RandomCrop(TFDataLayer):\n             `name` and `dtype`.\n     \"\"\"\n \n-    def __init__(\n-        self, height, width, seed=None, data_format=None, name=None, **kwargs\n-    ):\n+    def __init__(self, height, width, seed=None, name=None, **kwargs):\n+        if not tf.available:\n+            raise ImportError(\n+                \"Layer RandomCrop requires TensorFlow. \"\n+                \"Install it via `pip install tensorflow`.\"\n+            )\n+\n         super().__init__(name=name, **kwargs)\n-        self.height = height\n-        self.width = width\n         self.seed = seed or backend.random.make_default_seed()\n-        self.seed_generator = SeedGenerator(seed)\n-        self.data_format = backend.standardize_data_format(data_format)\n-\n-        if self.data_format == \"channels_first\":\n-            self.heigh_axis = -2\n-            self.width_axis = -1\n-        elif self.data_format == \"channels_last\":\n-            self.height_axis = -3\n-            self.width_axis = -2\n-\n+        self.layer = tf.keras.layers.RandomCrop(\n+            height=height,\n+            width=width,\n+            seed=self.seed,\n+            name=name,\n+        )\n         self.supports_masking = False\n         self.supports_jit = False\n         self._convert_input_args = False\n         self._allow_non_tensor_positional_args = True\n \n     def call(self, inputs, training=True):\n-        inputs = self.backend.cast(inputs, self.compute_dtype)\n-        input_shape = self.backend.shape(inputs)\n-        is_batched = len(input_shape) > 3\n-        inputs = (\n-            self.backend.numpy.expand_dims(inputs, axis=0)\n-            if not is_batched\n-            else inputs\n-        )\n-\n-        h_diff = input_shape[self.height_axis] - self.height\n-        w_diff = input_shape[self.width_axis] - self.width\n-\n-        def random_crop():\n-            input_height, input_width = (\n-                input_shape[self.height_axis],\n-                input_shape[self.width_axis],\n-            )\n-\n-            h_start = self.backend.cast(\n-                ops.random.uniform(\n-                    (),\n-                    0,\n-                    maxval=float(input_height - self.height + 1),\n-                    dtype=inputs.dtype,\n-                    seed=self.seed_generator,\n-                ),\n-                \"int32\",\n-            )\n-            w_start = self.backend.cast(\n-                ops.random.uniform(\n-                    (),\n-                    0,\n-                    maxval=float(input_width - self.width + 1),\n-                    dtype=inputs.dtype,\n-                    seed=self.seed_generator,\n-                ),\n-                \"int32\",\n-            )\n-            if self.data_format == \"channels_last\":\n-                return inputs[\n-                    :,\n-                    h_start : h_start + self.height,\n-                    w_start : w_start + self.width,\n-                ]\n-            else:\n-                return inputs[\n-                    :,\n-                    :,\n-                    h_start : h_start + self.height,\n-                    w_start : w_start + self.width,\n-                ]\n-\n-        def resize():\n-            outputs = image_utils.smart_resize(\n-                inputs,\n-                [self.height, self.width],\n-                data_format=self.data_format,\n-                backend_module=self.backend,\n-            )\n-            # smart_resize will always output float32, so we need to re-cast.\n-            return self.backend.cast(outputs, self.compute_dtype)\n-\n-        outputs = self.backend.cond(\n-            self.backend.numpy.all((training, h_diff >= 0, w_diff >= 0)),\n-            random_crop,\n-            resize,\n-        )\n-\n-        outputs = (\n-            self.backend.numpy.squeeze(outputs, axis=0)\n-            if not is_batched\n-            else outputs\n-        )\n-\n-        if self.backend != \"tensorflow\" and not backend_utils.in_tf_graph():\n-            outputs = self.backend.convert_to_tensor(outputs)\n+        if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n+            inputs = tf.convert_to_tensor(backend.convert_to_numpy(inputs))\n+        outputs = self.layer.call(inputs, training=training)\n+        if (\n+            backend.backend() != \"tensorflow\"\n+            and not backend_utils.in_tf_graph()\n+        ):\n+            outputs = backend.convert_to_tensor(outputs)\n         return outputs\n \n-    def compute_output_shape(self, input_shape, *args, **kwargs):\n-        input_shape = list(input_shape)\n-        input_shape[self.height_axis] = self.height\n-        input_shape[self.width_axis] = self.width\n-        return tuple(input_shape)\n+    def compute_output_shape(self, input_shape):\n+        return tuple(self.layer.compute_output_shape(input_shape))\n \n     def get_config(self):\n-        config = super().get_config()\n-        config.update(\n-            {\n-                \"height\": self.height,\n-                \"width\": self.width,\n-                \"seed\": self.seed,\n-                \"data_format\": self.data_format,\n-            }\n-        )\n+        config = self.layer.get_config()\n+        config.update({\"seed\": self.seed})\n         return config\n\n@@ -1,14 +1,11 @@\n-import numpy as np\n-\n from keras_core import backend\n from keras_core.api_export import keras_core_export\n-from keras_core.layers.layer import Layer\n-from keras_core.utils import backend_utils\n-from keras_core.utils.module_utils import tensorflow as tf\n+from keras_core.layers.preprocessing.tf_data_layer import TFDataLayer\n+from keras_core.random.seed_generator import SeedGenerator\n \n \n @keras_core_export(\"keras_core.layers.RandomTranslation\")\n-class RandomTranslation(Layer):\n+class RandomTranslation(TFDataLayer):\n     \"\"\"A preprocessing layer which randomly translates images during training.\n \n     This layer will apply random translations to each image during training,\n@@ -18,6 +15,17 @@ class RandomTranslation(Layer):\n     of integer or floating point dtype. By default, the layer will output\n     floats.\n \n+    Input shape:\n+        3D (unbatched) or 4D (batched) tensor with shape:\n+        `(..., height, width, channels)`, in `\"channels_last\"` format,\n+        or `(..., channels, height, width)`, in `\"channels_first\"` format.\n+\n+    Output shape:\n+        3D (unbatched) or 4D (batched) tensor with shape:\n+        `(..., target_height, target_width, channels)`,\n+        or `(..., channels, target_height, target_width)`,\n+        in `\"channels_first\"` format.\n+\n     **Note:** This layer is safe to use inside a `tf.data` pipeline\n     (independently of which backend you're using).\n \n@@ -25,46 +33,55 @@ class RandomTranslation(Layer):\n         height_factor: a float represented as fraction of value, or a tuple of\n             size 2 representing lower and upper bound for shifting vertically. A\n             negative value means shifting image up, while a positive value means\n-          shifting image down. When represented as a single positive float, this\n-          value is used for both the upper and lower bound. For instance,\n-          `height_factor=(-0.2, 0.3)` results in an output shifted by a random\n-          amount in the range `[-20%, +30%]`.  `height_factor=0.2` results in an\n-          output height shifted by a random amount in the range `[-20%, +20%]`.\n-      width_factor: a float represented as fraction of value, or a tuple of size\n-          2 representing lower and upper bound for shifting horizontally. A\n-          negative value means shifting image left, while a positive value means\n-          shifting image right. When represented as a single positive float,\n+            shifting image down. When represented as a single positive float,\n             this value is used for both the upper and lower bound. For instance,\n-          `width_factor=(-0.2, 0.3)` results in an output shifted left by 20%,\n-          and shifted right by 30%. `width_factor=0.2` results\n+            `height_factor=(-0.2, 0.3)` results in an output shifted by a random\n+            amount in the range `[-20%, +30%]`. `height_factor=0.2` results in\n+            an output height shifted by a random amount in the range\n+            `[-20%, +20%]`.\n+        width_factor: a float represented as fraction of value, or a tuple of\n+            size 2 representing lower and upper bound for shifting horizontally.\n+            A negative value means shifting image left, while a positive value\n+            means shifting image right. When represented as a single positive\n+            float, this value is used for both the upper and lower bound. For\n+            instance, `width_factor=(-0.2, 0.3)` results in an output shifted\n+            left by 20%, and shifted right by 30%. `width_factor=0.2` results\n             in an output height shifted left or right by 20%.\n-      fill_mode: Points outside the boundaries of the input are filled according\n-          to the given mode\n+        fill_mode: Points outside the boundaries of the input are filled\n+            according to the given mode\n             (one of `{\"constant\", \"reflect\", \"wrap\", \"nearest\"}`).\n-          - *reflect*: `(d c b a | a b c d | d c b a)` The input is extended by\n-              reflecting about the edge of the last pixel.\n-          - *constant*: `(k k k k | a b c d | k k k k)` The input is extended by\n-              filling all values beyond the edge with the same constant value\n-              k = 0.\n+            - *reflect*: `(d c b a | a b c d | d c b a)` The input is extended\n+                by reflecting about the edge of the last pixel.\n+            - *constant*: `(k k k k | a b c d | k k k k)` The input is extended\n+                by filling all values beyond the edge with the same constant\n+                value k = 0.\n             - *wrap*: `(a b c d | a b c d | a b c d)` The input is extended by\n                 wrapping around to the opposite edge.\n-          - *nearest*: `(a a a a | a b c d | d d d d)` The input is extended by\n-              the nearest pixel.\n+            - *nearest*: `(a a a a | a b c d | d d d d)` The input is extended\n+                by the nearest pixel.\n         interpolation: Interpolation mode. Supported values: `\"nearest\"`,\n             `\"bilinear\"`.\n         seed: Integer. Used to create a random seed.\n         fill_value: a float represents the value to be filled outside the\n             boundaries when `fill_mode=\"constant\"`.\n-\n-    Input shape:\n-        3D (unbatched) or 4D (batched) tensor with shape:\n-        `(..., height, width, channels)`,  in `\"channels_last\"` format.\n-\n-    Output shape:\n-        3D (unbatched) or 4D (batched) tensor with shape:\n-        `(..., height, width, channels)`,  in `\"channels_last\"` format.\n+        data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n+            The ordering of the dimensions in the inputs. `\"channels_last\"`\n+            corresponds to inputs with shape `(batch, height, width, channels)`\n+            while `\"channels_first\"` corresponds to inputs with shape\n+            `(batch, channels, height, width)`. It defaults to the\n+            `image_data_format` value found in your Keras config file at\n+            `~/.keras/keras.json`. If you never set it, then it will be\n+            `\"channels_last\"`.\n+        **kwargs: Base layer keyword arguments, such as `name` and `dtype`.\n     \"\"\"\n \n+    _FACTOR_VALIDATION_ERROR = (\n+        \"The `factor` argument should be a number (or a list of two numbers) \"\n+        \"in the range [-1.0, 1.0]. \"\n+    )\n+    _SUPPORTED_FILL_MODE = (\"reflect\", \"wrap\", \"constant\", \"nearest\")\n+    _SUPPORTED_INTERPOLATION = (\"nearest\", \"bilinear\")\n+\n     def __init__(\n         self,\n         height_factor,\n@@ -73,43 +90,155 @@ class RandomTranslation(Layer):\n         interpolation=\"bilinear\",\n         seed=None,\n         fill_value=0.0,\n-        name=None,\n+        data_format=None,\n         **kwargs,\n     ):\n-        if not tf.available:\n-            raise ImportError(\n-                \"Layer RandomTranslation requires TensorFlow. \"\n-                \"Install it via `pip install tensorflow`.\"\n+        super().__init__(**kwargs)\n+        self.height_factor = height_factor\n+        self.height_lower, self.height_upper = self._set_factor(\n+            height_factor, \"height_factor\"\n+        )\n+        self.width_factor = width_factor\n+        self.width_lower, self.width_upper = self._set_factor(\n+            width_factor, \"width_factor\"\n         )\n \n-        super().__init__(name=name)\n-        self.layer = tf.keras.layers.RandomTranslation(\n-            height_factor=height_factor,\n-            width_factor=width_factor,\n-            fill_mode=fill_mode,\n-            interpolation=interpolation,\n-            seed=seed,\n-            fill_value=fill_value,\n-            name=name,\n-            **kwargs,\n+        if fill_mode not in self._SUPPORTED_FILL_MODE:\n+            raise NotImplementedError(\n+                f\"Unknown `fill_mode` {fill_mode}. Expected of one \"\n+                f\"{self._SUPPORTED_FILL_MODE}.\"\n             )\n+        if interpolation not in self._SUPPORTED_INTERPOLATION:\n+            raise NotImplementedError(\n+                f\"Unknown `interpolation` {interpolation}. Expected of one \"\n+                f\"{self._SUPPORTED_INTERPOLATION}.\"\n+            )\n+\n+        self.fill_mode = fill_mode\n+        self.fill_value = fill_value\n+        self.interpolation = interpolation\n+        self.seed = seed\n+        self.generator = SeedGenerator(seed)\n+        self.data_format = backend.standardize_data_format(data_format)\n+\n         self.supports_jit = False\n-        self._convert_input_args = False\n-        self._allow_non_tensor_positional_args = True\n+\n+    def _set_factor(self, factor, factor_name):\n+        if isinstance(factor, (tuple, list)):\n+            if len(factor) != 2:\n+                raise ValueError(\n+                    self._FACTOR_VALIDATION_ERROR\n+                    + f\"Received: {factor_name}={factor}\"\n+                )\n+            self._check_factor_range(factor[0])\n+            self._check_factor_range(factor[1])\n+            lower, upper = sorted(factor)\n+        elif isinstance(factor, (int, float)):\n+            self._check_factor_range(factor)\n+            factor = abs(factor)\n+            lower, upper = [-factor, factor]\n+        else:\n+            raise ValueError(\n+                self._FACTOR_VALIDATION_ERROR\n+                + f\"Received: {factor_name}={factor}\"\n+            )\n+        return lower, upper\n+\n+    def _check_factor_range(self, input_number):\n+        if input_number > 1.0 or input_number < -1.0:\n+            raise ValueError(\n+                self._FACTOR_VALIDATION_ERROR\n+                + f\"Received: input_number={input_number}\"\n+            )\n \n     def call(self, inputs, training=True):\n-        if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n-            inputs = tf.convert_to_tensor(backend.convert_to_numpy(inputs))\n-        outputs = self.layer.call(inputs, training=training)\n-        if (\n-            backend.backend() != \"tensorflow\"\n-            and not backend_utils.in_tf_graph()\n-        ):\n-            outputs = backend.convert_to_tensor(outputs)\n+        inputs = self.backend.cast(inputs, self.compute_dtype)\n+        if training:\n+            return self._randomly_translate_inputs(inputs)\n+        else:\n+            return inputs\n+\n+    def _randomly_translate_inputs(self, inputs):\n+        unbatched = len(inputs.shape) == 3\n+        if unbatched:\n+            inputs = self.backend.numpy.expand_dims(inputs, axis=0)\n+\n+        batch_size = self.backend.shape(inputs)[0]\n+        if self.data_format == \"channels_first\":\n+            height = inputs.shape[-2]\n+            width = inputs.shape[-1]\n+        else:\n+            height = inputs.shape[-3]\n+            width = inputs.shape[-2]\n+\n+        seed_generator = self._get_seed_generator(self.backend._backend)\n+        height_translate = self.backend.random.uniform(\n+            minval=self.height_lower,\n+            maxval=self.height_upper,\n+            shape=[batch_size, 1],\n+            seed=seed_generator,\n+        )\n+        height_translate = height_translate * height\n+        width_translate = self.backend.random.uniform(\n+            minval=self.width_lower,\n+            maxval=self.width_upper,\n+            shape=[batch_size, 1],\n+            seed=seed_generator,\n+        )\n+        width_translate = width_translate * width\n+        translations = self.backend.cast(\n+            self.backend.numpy.concatenate(\n+                [width_translate, height_translate], axis=1\n+            ),\n+            dtype=\"float32\",\n+        )\n+\n+        outputs = self.backend.image.affine_transform(\n+            inputs,\n+            transform=self._get_translation_matrix(translations),\n+            interpolation=self.interpolation,\n+            fill_mode=self.fill_mode,\n+            fill_value=self.fill_value,\n+            data_format=self.data_format,\n+        )\n+\n+        if unbatched:\n+            outputs = self.backend.numpy.squeeze(outputs, axis=0)\n         return outputs\n \n+    def _get_translation_matrix(self, translations):\n+        num_translations = self.backend.shape(translations)[0]\n+        # The translation matrix looks like:\n+        #     [[1 0 -dx]\n+        #      [0 1 -dy]\n+        #      [0 0 1]]\n+        # where the last entry is implicit.\n+        # translation matrices are always float32.\n+        return self.backend.numpy.concatenate(\n+            [\n+                self.backend.numpy.ones((num_translations, 1)),\n+                self.backend.numpy.zeros((num_translations, 1)),\n+                -translations[:, 0:1],\n+                self.backend.numpy.zeros((num_translations, 1)),\n+                self.backend.numpy.ones((num_translations, 1)),\n+                -translations[:, 1:],\n+                self.backend.numpy.zeros((num_translations, 2)),\n+            ],\n+            axis=1,\n+        )\n+\n     def compute_output_shape(self, input_shape):\n-        return tuple(self.layer.compute_output_shape(input_shape))\n+        return input_shape\n \n     def get_config(self):\n-        return self.layer.get_config()\n+        base_config = super().get_config()\n+        config = {\n+            \"height_factor\": self.height_factor,\n+            \"width_factor\": self.width_factor,\n+            \"fill_mode\": self.fill_mode,\n+            \"interpolation\": self.interpolation,\n+            \"seed\": self.seed,\n+            \"fill_value\": self.fill_value,\n+            \"data_format\": self.data_format,\n+        }\n+        return {**base_config, **config}\n\n@@ -26,8 +26,38 @@ class RandomTranslationTest(testing.TestCase, parameterized.TestCase):\n             run_training_check=False,\n         )\n \n-    def test_random_translation_up_numeric_reflect(self):\n-        input_image = np.reshape(np.arange(0, 25), (1, 5, 5, 1))\n+    @parameterized.named_parameters(\n+        (\"bad_len\", [0.1, 0.2, 0.3], 0.0),\n+        (\"bad_type\", {\"dummy\": 0.3}, 0.0),\n+        (\"exceed_range_single\", -1.1, 0.0),\n+        (\"exceed_range_tuple\", (-1.1, 0.0), 0.0),\n+    )\n+    def test_random_translation_with_bad_factor(\n+        self, height_factor, width_factor\n+    ):\n+        with self.assertRaises(ValueError):\n+            self.run_layer_test(\n+                layers.RandomTranslation,\n+                init_kwargs={\n+                    \"height_factor\": height_factor,\n+                    \"width_factor\": width_factor,\n+                },\n+                input_shape=(2, 3, 4),\n+                expected_output_shape=(2, 3, 4),\n+                supports_masking=False,\n+                run_training_check=False,\n+            )\n+\n+    def test_random_translation_with_inference_mode(self):\n+        input_data = np.random.random((1, 4, 4, 3))\n+        expected_output = input_data\n+        layer = layers.RandomTranslation(0.2, 0.1)\n+        output = layer(input_data, training=False)\n+        self.assertAllClose(output, expected_output)\n+\n+    @parameterized.parameters([\"channels_first\", \"channels_last\"])\n+    def test_random_translation_up_numeric_reflect(self, data_format):\n+        input_image = np.arange(0, 25)\n         expected_output = np.asarray(\n             [\n                 [5, 6, 7, 8, 9],\n@@ -37,14 +67,22 @@ class RandomTranslationTest(testing.TestCase, parameterized.TestCase):\n                 [20, 21, 22, 23, 24],\n             ]\n         )\n+        if data_format == \"channels_last\":\n+            input_image = np.reshape(input_image, (1, 5, 5, 1))\n             expected_output = backend.convert_to_tensor(\n                 np.reshape(expected_output, (1, 5, 5, 1))\n             )\n+        else:\n+            input_image = np.reshape(input_image, (1, 1, 5, 5))\n+            expected_output = backend.convert_to_tensor(\n+                np.reshape(expected_output, (1, 1, 5, 5))\n+            )\n         self.run_layer_test(\n             layers.RandomTranslation,\n             init_kwargs={\n                 \"height_factor\": (-0.2, -0.2),\n                 \"width_factor\": 0.0,\n+                \"data_format\": data_format,\n             },\n             input_shape=None,\n             input_data=input_image,\n@@ -53,10 +91,9 @@ class RandomTranslationTest(testing.TestCase, parameterized.TestCase):\n             run_training_check=False,\n         )\n \n-    def test_random_translation_up_numeric_constant(self):\n-        input_image = np.reshape(np.arange(0, 25), (1, 5, 5, 1)).astype(\n-            \"float32\"\n-        )\n+    @parameterized.parameters([\"channels_first\", \"channels_last\"])\n+    def test_random_translation_up_numeric_constant(self, data_format):\n+        input_image = np.arange(0, 25).astype(\"float32\")\n         # Shifting by -.2 * 5 = 1 pixel.\n         expected_output = np.asarray(\n             [\n@@ -67,15 +104,23 @@ class RandomTranslationTest(testing.TestCase, parameterized.TestCase):\n                 [0, 0, 0, 0, 0],\n             ]\n         )\n+        if data_format == \"channels_last\":\n+            input_image = np.reshape(input_image, (1, 5, 5, 1))\n             expected_output = backend.convert_to_tensor(\n                 np.reshape(expected_output, (1, 5, 5, 1)), dtype=\"float32\"\n             )\n+        else:\n+            input_image = np.reshape(input_image, (1, 1, 5, 5))\n+            expected_output = backend.convert_to_tensor(\n+                np.reshape(expected_output, (1, 1, 5, 5)), dtype=\"float32\"\n+            )\n         self.run_layer_test(\n             layers.RandomTranslation,\n             init_kwargs={\n                 \"height_factor\": (-0.2, -0.2),\n                 \"width_factor\": 0.0,\n                 \"fill_mode\": \"constant\",\n+                \"data_format\": data_format,\n             },\n             input_shape=None,\n             input_data=input_image,\n@@ -84,8 +129,9 @@ class RandomTranslationTest(testing.TestCase, parameterized.TestCase):\n             run_training_check=False,\n         )\n \n-    def test_random_translation_down_numeric_reflect(self):\n-        input_image = np.reshape(np.arange(0, 25), (1, 5, 5, 1))\n+    @parameterized.parameters([\"channels_first\", \"channels_last\"])\n+    def test_random_translation_down_numeric_reflect(self, data_format):\n+        input_image = np.arange(0, 25)\n         # Shifting by .2 * 5 = 1 pixel.\n         expected_output = np.asarray(\n             [\n@@ -96,14 +142,22 @@ class RandomTranslationTest(testing.TestCase, parameterized.TestCase):\n                 [15, 16, 17, 18, 19],\n             ]\n         )\n+        if data_format == \"channels_last\":\n+            input_image = np.reshape(input_image, (1, 5, 5, 1))\n             expected_output = backend.convert_to_tensor(\n                 np.reshape(expected_output, (1, 5, 5, 1))\n             )\n+        else:\n+            input_image = np.reshape(input_image, (1, 1, 5, 5))\n+            expected_output = backend.convert_to_tensor(\n+                np.reshape(expected_output, (1, 1, 5, 5))\n+            )\n         self.run_layer_test(\n             layers.RandomTranslation,\n             init_kwargs={\n                 \"height_factor\": (0.2, 0.2),\n                 \"width_factor\": 0.0,\n+                \"data_format\": data_format,\n             },\n             input_shape=None,\n             input_data=input_image,\n@@ -112,8 +166,11 @@ class RandomTranslationTest(testing.TestCase, parameterized.TestCase):\n             run_training_check=False,\n         )\n \n-    def test_random_translation_asymmetric_size_numeric_reflect(self):\n-        input_image = np.reshape(np.arange(0, 16), (1, 8, 2, 1))\n+    @parameterized.parameters([\"channels_first\", \"channels_last\"])\n+    def test_random_translation_asymmetric_size_numeric_reflect(\n+        self, data_format\n+    ):\n+        input_image = np.arange(0, 16)\n         # Shifting by .2 * 5 = 1 pixel.\n         expected_output = np.asarray(\n             [\n@@ -127,14 +184,22 @@ class RandomTranslationTest(testing.TestCase, parameterized.TestCase):\n                 [6, 7],\n             ]\n         )\n+        if data_format == \"channels_last\":\n+            input_image = np.reshape(input_image, (1, 8, 2, 1))\n             expected_output = backend.convert_to_tensor(\n                 np.reshape(expected_output, (1, 8, 2, 1))\n             )\n+        else:\n+            input_image = np.reshape(input_image, (1, 1, 8, 2))\n+            expected_output = backend.convert_to_tensor(\n+                np.reshape(expected_output, (1, 1, 8, 2))\n+            )\n         self.run_layer_test(\n             layers.RandomTranslation,\n             init_kwargs={\n                 \"height_factor\": (0.5, 0.5),\n                 \"width_factor\": 0.0,\n+                \"data_format\": data_format,\n             },\n             input_shape=None,\n             input_data=input_image,\n@@ -143,8 +208,9 @@ class RandomTranslationTest(testing.TestCase, parameterized.TestCase):\n             run_training_check=False,\n         )\n \n-    def test_random_translation_down_numeric_constant(self):\n-        input_image = np.reshape(np.arange(0, 25), (1, 5, 5, 1))\n+    @parameterized.parameters([\"channels_first\", \"channels_last\"])\n+    def test_random_translation_down_numeric_constant(self, data_format):\n+        input_image = np.arange(0, 25)\n         # Shifting by .2 * 5 = 1 pixel.\n         expected_output = np.asarray(\n             [\n@@ -155,9 +221,16 @@ class RandomTranslationTest(testing.TestCase, parameterized.TestCase):\n                 [15, 16, 17, 18, 19],\n             ]\n         )\n+        if data_format == \"channels_last\":\n+            input_image = np.reshape(input_image, (1, 5, 5, 1))\n             expected_output = backend.convert_to_tensor(\n                 np.reshape(expected_output, (1, 5, 5, 1))\n             )\n+        else:\n+            input_image = np.reshape(input_image, (1, 1, 5, 5))\n+            expected_output = backend.convert_to_tensor(\n+                np.reshape(expected_output, (1, 1, 5, 5))\n+            )\n         self.run_layer_test(\n             layers.RandomTranslation,\n             init_kwargs={\n@@ -165,6 +238,7 @@ class RandomTranslationTest(testing.TestCase, parameterized.TestCase):\n                 \"width_factor\": 0.0,\n                 \"fill_mode\": \"constant\",\n                 \"fill_value\": 0.0,\n+                \"data_format\": data_format,\n             },\n             input_shape=None,\n             input_data=input_image,\n@@ -173,8 +247,9 @@ class RandomTranslationTest(testing.TestCase, parameterized.TestCase):\n             run_training_check=False,\n         )\n \n-    def test_random_translation_left_numeric_reflect(self):\n-        input_image = np.reshape(np.arange(0, 25), (1, 5, 5, 1))\n+    @parameterized.parameters([\"channels_first\", \"channels_last\"])\n+    def test_random_translation_left_numeric_reflect(self, data_format):\n+        input_image = np.arange(0, 25)\n         # Shifting by .2 * 5 = 1 pixel.\n         expected_output = np.asarray(\n             [\n@@ -185,14 +260,22 @@ class RandomTranslationTest(testing.TestCase, parameterized.TestCase):\n                 [21, 22, 23, 24, 24],\n             ]\n         )\n+        if data_format == \"channels_last\":\n+            input_image = np.reshape(input_image, (1, 5, 5, 1))\n             expected_output = backend.convert_to_tensor(\n                 np.reshape(expected_output, (1, 5, 5, 1))\n             )\n+        else:\n+            input_image = np.reshape(input_image, (1, 1, 5, 5))\n+            expected_output = backend.convert_to_tensor(\n+                np.reshape(expected_output, (1, 1, 5, 5))\n+            )\n         self.run_layer_test(\n             layers.RandomTranslation,\n             init_kwargs={\n                 \"height_factor\": 0.0,\n                 \"width_factor\": (-0.2, -0.2),\n+                \"data_format\": data_format,\n             },\n             input_shape=None,\n             input_data=input_image,\n@@ -201,8 +284,9 @@ class RandomTranslationTest(testing.TestCase, parameterized.TestCase):\n             run_training_check=False,\n         )\n \n-    def test_random_translation_left_numeric_constant(self):\n-        input_image = np.reshape(np.arange(0, 25), (1, 5, 5, 1))\n+    @parameterized.parameters([\"channels_first\", \"channels_last\"])\n+    def test_random_translation_left_numeric_constant(self, data_format):\n+        input_image = np.arange(0, 25)\n         # Shifting by .2 * 5 = 1 pixel.\n         expected_output = np.asarray(\n             [\n@@ -213,9 +297,16 @@ class RandomTranslationTest(testing.TestCase, parameterized.TestCase):\n                 [21, 22, 23, 24, 0],\n             ]\n         )\n+        if data_format == \"channels_last\":\n+            input_image = np.reshape(input_image, (1, 5, 5, 1))\n             expected_output = backend.convert_to_tensor(\n                 np.reshape(expected_output, (1, 5, 5, 1))\n             )\n+        else:\n+            input_image = np.reshape(input_image, (1, 1, 5, 5))\n+            expected_output = backend.convert_to_tensor(\n+                np.reshape(expected_output, (1, 1, 5, 5))\n+            )\n         self.run_layer_test(\n             layers.RandomTranslation,\n             init_kwargs={\n@@ -223,6 +314,7 @@ class RandomTranslationTest(testing.TestCase, parameterized.TestCase):\n                 \"width_factor\": (-0.2, -0.2),\n                 \"fill_mode\": \"constant\",\n                 \"fill_value\": 0.0,\n+                \"data_format\": data_format,\n             },\n             input_shape=None,\n             input_data=input_image,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
