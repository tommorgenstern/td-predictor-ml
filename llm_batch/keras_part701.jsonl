{"custom_id": "keras#2d6fcdd2b32bc94054433a6bb6f6e9e53da96b52", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 195 | Lines Deleted: 125 | Files Changed: 7 | Hunks: 68 | Methods Changed: 52 | Complexity Δ (Sum/Max): 14/13 | Churn Δ: 320 | Churn Cumulative: 4395 | Contributors (this commit): 14 | Commits (past 90d): 70 | Contributors (cumulative): 25 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1,9 +1,8 @@\n \"\"\"\n Title: Image classification with modern MLP models\n Author: [Khalid Salama](https://www.linkedin.com/in/khalid-salama-24403144/)\n-Converted to Keras Core by: [Guillaume Baquiast](https://www.linkedin.com/in/guillaume-baquiast-478965ba/), [divyasreepat](https://github.com/divyashreepathihalli)\n Date created: 2021/05/30\n-Last modified: 2023/08/03\n+Last modified: 2021/05/30\n Description: Implementing the MLP-Mixer, FNet, and gMLP models for CIFAR-100 image classification.\n Accelerator: GPU\n \"\"\"\n@@ -29,8 +28,10 @@ main building blocks.\n \"\"\"\n \n import numpy as np\n+import tensorflow as tf\n import keras_core as keras\n from keras_core import layers\n+from keras_core.layers import Lambda\n \n \"\"\"\n ## Prepare the data\n@@ -75,11 +76,15 @@ def build_classifier(blocks, positional_encoding=False):\n     # Augment data.\n     augmented = data_augmentation(inputs)\n     # Create patches.\n-    patches = Patches(patch_size)(augmented)\n+    patches = Patches(patch_size, num_patches)(augmented)\n     # Encode patches to generate a [batch_size, num_patches, embedding_dim] tensor.\n     x = layers.Dense(units=embedding_dim)(patches)\n     if positional_encoding:\n-        x = x + PositionEmbedding(sequence_length=num_patches)(x)\n+        positions = tf.range(start=0, limit=num_patches, delta=1)\n+        position_embedding = layers.Embedding(\n+            input_dim=num_patches, output_dim=embedding_dim\n+        )(positions)\n+        x = x + position_embedding\n     # Process x using the module blocks.\n     x = blocks(x)\n     # Apply global average pooling to generate a [batch_size, embedding_dim] representation tensor.\n@@ -163,74 +168,26 @@ data_augmentation.layers[0].adapt(x_train)\n \n \n class Patches(layers.Layer):\n-    def __init__(self, patch_size, **kwargs):\n-        super().__init__(**kwargs)\n+    def __init__(self, patch_size, num_patches):\n+        super().__init__()\n         self.patch_size = patch_size\n+        self.num_patches = num_patches\n \n-    def call(self, x):\n-        patches = keras.ops.image.extract_patches(x, self.patch_size)\n-        batch_size = keras.ops.shape(patches)[0]\n-        num_patches = keras.ops.shape(patches)[1] * keras.ops.shape(patches)[2]\n-        patch_dim = keras.ops.shape(patches)[3]\n-        out = keras.ops.reshape(patches, (batch_size, num_patches, patch_dim))\n-        return out\n-\n-\"\"\"\n-## Implement position embedding as a layer\n-\"\"\"\n-\n-class PositionEmbedding(keras.layers.Layer):\n-    def __init__(\n-        self,\n-        sequence_length,\n-        initializer=\"glorot_uniform\",\n-        **kwargs,\n-    ):\n-        super().__init__(**kwargs)\n-        if sequence_length is None:\n-            raise ValueError(\n-                \"`sequence_length` must be an Integer, received `None`.\"\n+    def call(self, images):\n+        batch_size = tf.shape(images)[0]\n+        patches = tf.image.extract_patches(\n+            images=images,\n+            sizes=[1, self.patch_size, self.patch_size, 1],\n+            strides=[1, self.patch_size, self.patch_size, 1],\n+            rates=[1, 1, 1, 1],\n+            padding=\"VALID\",\n         )\n-        self.sequence_length = int(sequence_length)\n-        self.initializer = keras.initializers.get(initializer)\n-\n-    def get_config(self):\n-        config = super().get_config()\n-        config.update(\n-            {\n-                \"sequence_length\": self.sequence_length,\n-                \"initializer\": keras.initializers.serialize(self.initializer),\n-            }\n+        patch_dims = patches.shape[-1]\n+        patches = tf.reshape(\n+            patches, [batch_size, self.num_patches, patch_dims]\n         )\n-        return config\n+        return patches\n \n-    def build(self, input_shape):\n-        feature_size = input_shape[-1]\n-        self.position_embeddings = self.add_weight(\n-            name=\"embeddings\",\n-            shape=[self.sequence_length, feature_size],\n-            initializer=self.initializer,\n-            trainable=True,\n-        )\n-\n-        super().build(input_shape)\n-\n-    def call(self, inputs, start_index=0):\n-        shape = keras.ops.shape(inputs)\n-        feature_length = shape[-1]\n-        sequence_length = shape[-2]\n-        # trim to match the length of the input sequence, which might be less\n-        # than the sequence_length of the layer.\n-        position_embeddings = keras.ops.convert_to_tensor(self.position_embeddings)\n-        position_embeddings = keras.ops.slice(\n-            position_embeddings,\n-            (start_index, 0),\n-            (sequence_length, feature_length),\n-        )\n-        return keras.ops.broadcast_to(position_embeddings, shape)\n-\n-    def compute_output_shape(self, input_shape):\n-        return input_shape\n \n \"\"\"\n ## The MLP-Mixer model\n@@ -267,7 +224,7 @@ class MLPMixerLayer(layers.Layer):\n         self.mlp2 = keras.Sequential(\n             [\n                 layers.Dense(units=num_patches, activation=\"gelu\"),\n-                layers.Dense(units=hidden_units),\n+                layers.Dense(units=embedding_dim),\n                 layers.Dropout(rate=dropout_rate),\n             ]\n         )\n@@ -280,11 +237,11 @@ class MLPMixerLayer(layers.Layer):\n         # Apply layer normalization.\n         x = self.normalize(inputs)\n         # Transpose inputs from [num_batches, num_patches, hidden_units] to [num_batches, hidden_units, num_patches].\n-        x_channels = keras.ops.transpose(x, axes=(0, 2, 1))\n+        x_channels = tf.linalg.matrix_transpose(x)\n         # Apply mlp1 on each channel independently.\n         mlp1_outputs = self.mlp1(x_channels)\n         # Transpose mlp1_outputs from [num_batches, hidden_dim, num_patches] to [num_batches, num_patches, hidden_units].\n-        mlp1_outputs = keras.ops.transpose(mlp1_outputs, axes=(0, 2, 1))\n+        mlp1_outputs = tf.linalg.matrix_transpose(mlp1_outputs)\n         # Add skip connection.\n         x = mlp1_outputs + inputs\n         # Apply layer normalization.\n@@ -322,7 +279,7 @@ As mentioned in the [MLP-Mixer](https://arxiv.org/abs/2105.01601) paper,\n when pre-trained on large datasets, or with modern regularization schemes,\n the MLP-Mixer attains competitive scores to state-of-the-art models.\n You can obtain better results by increasing the embedding dimensions,\n-increasing the number of mixer blocks, and training the model for longer.\n+increasing, increasing the number of mixer blocks, and training the model for longer.\n You may also try to increase the size of the input images and use different patch sizes.\n \"\"\"\n \n@@ -343,7 +300,7 @@ in the Transformer block with a parameter-free 2D Fourier transformation layer:\n \n class FNetLayer(layers.Layer):\n     def __init__(\n-        self, embedding_dim, dropout_rate, *args, **kwargs\n+        self, num_patches, embedding_dim, dropout_rate, *args, **kwargs\n     ):\n         super().__init__(*args, **kwargs)\n \n@@ -360,9 +317,10 @@ class FNetLayer(layers.Layer):\n \n     def call(self, inputs):\n         # Apply fourier transformations.\n-        real_part = inputs\n-        im_part = keras.ops.zeros_like(inputs)\n-        x = keras.ops.fft2((real_part, im_part))[0]\n+        x = tf.cast(\n+            tf.signal.fft2d(tf.cast(inputs, dtype=tf.dtypes.complex64)),\n+            dtype=tf.dtypes.float32,\n+        )\n         # Add skip connection.\n         x = x + inputs\n         # Apply layer normalization.\n@@ -384,7 +342,7 @@ takes around 8 seconds per epoch.\n \n fnet_blocks = keras.Sequential(\n     [\n-        FNetLayer(embedding_dim, dropout_rate)\n+        FNetLayer(num_patches, embedding_dim, dropout_rate)\n         for _ in range(num_blocks)\n     ]\n )\n@@ -440,14 +398,14 @@ class gMLPLayer(layers.Layer):\n \n     def spatial_gating_unit(self, x):\n         # Split x along the channel dimensions.\n-        # Tensors u and v will in the shape of [batch_size, num_patchs, embedding_dim].\n-        u, v = keras.ops.split(x, indices_or_sections=2, axis=2)\n+        # Tensors u and v will in th shape of [batch_size, num_patchs, embedding_dim].\n+        u, v = tf.split(x, num_or_size_splits=2, axis=2)\n         # Apply layer normalization.\n         v = self.normalize2(v)\n         # Apply spatial projection.\n-        v_channels = keras.ops.transpose(v, axes=(0, 2, 1))\n+        v_channels = tf.linalg.matrix_transpose(v)\n         v_projected = self.spatial_projection(v_channels)\n-        v_projected = keras.ops.transpose(v_projected, axes=(0, 2, 1))\n+        v_projected = tf.linalg.matrix_transpose(v_projected)\n         # Apply element-wise multiplication.\n         return u * v_projected\n \n\n@@ -11,7 +11,14 @@ class KerasVariable:\n     def __init__(\n         self, initializer, shape=None, dtype=None, trainable=True, name=None\n     ):\n-        self.name = name or auto_name(self.__class__.__name__)\n+        name = name or auto_name(self.__class__.__name__)\n+        if not isinstance(name, str) or \"/\" in name:\n+            raise ValueError(\n+                \"Argument `name` must be a string and \"\n+                \"cannot contain character `/`. \"\n+                f\"Received: name={name}\"\n+            )\n+        self.name = name\n         dtype = standardize_dtype(dtype)\n         self._dtype = dtype\n         self._shape = None\n\n@@ -68,7 +68,10 @@ class Sum(Metric):\n     def __init__(self, name=\"sum\", dtype=None):\n         super().__init__(name=name, dtype=dtype)\n         self.total = self.add_variable(\n-            shape=(), initializer=initializers.Zeros(), dtype=self.dtype\n+            shape=(),\n+            initializer=initializers.Zeros(),\n+            dtype=self.dtype,\n+            name=\"total\",\n         )\n \n     def update_state(self, values, sample_weight=None):\n@@ -115,10 +118,16 @@ class Mean(Metric):\n     def __init__(self, name=\"mean\", dtype=None):\n         super().__init__(name=name, dtype=dtype)\n         self.total = self.add_variable(\n-            shape=(), initializer=initializers.Zeros(), dtype=self.dtype\n+            shape=(),\n+            initializer=initializers.Zeros(),\n+            dtype=self.dtype,\n+            name=\"total\",\n         )\n         self.count = self.add_variable(\n-            shape=(), initializer=initializers.Zeros(), dtype=self.dtype\n+            shape=(),\n+            initializer=initializers.Zeros(),\n+            dtype=self.dtype,\n+            name=\"count\",\n         )\n \n     def update_state(self, values, sample_weight=None):\n\n@@ -7,6 +7,7 @@ from keras_core import backend\n from keras_core import utils\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n+from keras_core.models.variable_mapping import map_trackable_variables\n from keras_core.saving import saving_api\n from keras_core.saving import saving_lib\n from keras_core.trainers import trainer as base_trainer\n@@ -507,6 +508,13 @@ class Model(Trainer, Layer):\n                 f\"Error encountered during deserialization: {e}\"\n             )\n \n+    def _get_variable_map(self):\n+        store = {}\n+        map_trackable_variables(\n+            self, store=store, inner_path=\"\", visited_trackables=set()\n+        )\n+        return store\n+\n \n @keras_core_export(\"keras_core.models.model_from_json\")\n def model_from_json(json_string, custom_objects=None):\n\n@@ -0,0 +1,57 @@\n+from keras_core.layers.layer import Layer\n+from keras_core.metrics.metric import Metric\n+from keras_core.optimizers.optimizer import Optimizer\n+from keras_core.saving import saving_lib\n+from keras_core.utils import file_utils\n+\n+\n+def map_trackable_variables(trackable, store, inner_path, visited_trackables):\n+    # If the trackable has already been saved, skip it.\n+    if id(trackable) in visited_trackables:\n+        return\n+\n+    visited_trackables.add(id(trackable))\n+\n+    variables = []\n+    if isinstance(trackable, Layer):\n+        variables = (\n+            trackable._trainable_variables + trackable._non_trainable_variables\n+        )\n+    elif isinstance(trackable, Optimizer):\n+        variables = trackable._variables\n+    elif isinstance(trackable, Metric):\n+        variables = trackable._variables\n+    for v in variables:\n+        store[inner_path + \"/\" + v.name] = v\n+\n+    # Recursively save state of children trackables (layers, optimizers, etc.)\n+    for child_attr, child_obj in saving_lib._walk_trackable(trackable):\n+        if saving_lib._is_keras_trackable(child_obj):\n+            map_trackable_variables(\n+                child_obj,\n+                store,\n+                inner_path=file_utils.join(inner_path, child_obj.name),\n+                visited_trackables=visited_trackables,\n+            )\n+        elif isinstance(child_obj, (list, dict, tuple, set)):\n+            map_container_variables(\n+                child_obj,\n+                store,\n+                inner_path=file_utils.join(inner_path, child_attr),\n+                visited_trackables=visited_trackables,\n+            )\n+\n+\n+def map_container_variables(container, store, inner_path, visited_trackables):\n+    if isinstance(container, dict):\n+        container = list(container.values())\n+\n+    for trackable in container:\n+        if saving_lib._is_keras_trackable(trackable):\n+            name = trackable.name\n+            map_trackable_variables(\n+                trackable,\n+                store,\n+                inner_path=file_utils.join(inner_path, name),\n+                visited_trackables=visited_trackables,\n+            )\n\n@@ -17,6 +17,7 @@ from keras_core.optimizers.optimizer import Optimizer\n from keras_core.saving.serialization_lib import ObjectSharingScope\n from keras_core.saving.serialization_lib import deserialize_keras_object\n from keras_core.saving.serialization_lib import serialize_keras_object\n+from keras_core.trainers.compile_utils import CompileMetrics\n from keras_core.utils import file_utils\n from keras_core.utils import naming\n from keras_core.version import __version__ as keras_version\n@@ -252,7 +253,14 @@ def _write_to_zip_recursively(zipfile_to_save, system_path, zip_path):\n \n \n def _walk_trackable(trackable):\n-    if isinstance(trackable, Layer):\n+    from keras_core.models import Functional\n+    from keras_core.models import Sequential\n+\n+    if isinstance(trackable, Sequential):\n+        obj_type = \"Sequential\"\n+    elif isinstance(trackable, Functional):\n+        obj_type = \"Functional\"\n+    elif isinstance(trackable, Layer):\n         obj_type = \"Layer\"\n     elif isinstance(trackable, Optimizer):\n         obj_type = \"Optimizer\"\n@@ -264,7 +272,7 @@ def _walk_trackable(trackable):\n         raise ValueError(f\"Invalid obj_type: {obj_type}\")\n     attr_skiplist = get_attr_skiplist(obj_type)\n \n-    for child_attr in dir(trackable):\n+    for child_attr in sorted(dir(trackable)):\n         if child_attr.startswith(\"__\") or child_attr in attr_skiplist:\n             continue\n         try:\n@@ -276,7 +284,11 @@ def _walk_trackable(trackable):\n \n \n def _save_state(\n-    trackable, weights_store, assets_store, inner_path, visited_trackables\n+    trackable,\n+    weights_store,\n+    assets_store,\n+    inner_path,\n+    visited_trackables,\n ):\n     # If the trackable has already been saved, skip it.\n     if id(trackable) in visited_trackables:\n@@ -592,19 +604,30 @@ def get_attr_skiplist(obj_type):\n     )\n     if skiplist is not None:\n         return skiplist\n+\n+    skiplist = [\n+        \"_self_unconditional_dependency_names\",\n+    ]\n     if obj_type == \"Layer\":\n         ref_obj = Layer()\n-        skiplist = dir(ref_obj)\n+        skiplist += dir(ref_obj)\n+    elif obj_type == \"Functional\":\n+        ref_obj = Layer()\n+        skiplist += dir(ref_obj) + [\"operations\", \"_operations\"]\n+    elif obj_type == \"Sequential\":\n+        ref_obj = Layer()\n+        skiplist += dir(ref_obj) + [\"_functional\"]\n     elif obj_type == \"Metric\":\n-        ref_obj = Metric()\n-        skiplist = dir(ref_obj)\n+        ref_obj_a = Metric()\n+        ref_obj_b = CompileMetrics([], [])\n+        skiplist += dir(ref_obj_a) + dir(ref_obj_b)\n     elif obj_type == \"Optimizer\":\n         ref_obj = Optimizer(1.0)\n-        skiplist = dir(ref_obj)\n+        skiplist += dir(ref_obj)\n         skiplist.remove(\"variables\")\n     elif obj_type == \"Loss\":\n         ref_obj = Loss()\n-        skiplist = dir(ref_obj)\n+        skiplist += dir(ref_obj)\n     else:\n         raise ValueError(f\"Invalid obj_type: {obj_type}\")\n     global_state.set_global_attribute(\n\n@@ -20,7 +20,7 @@ class MyDense(keras_core.layers.Layer):\n     def __init__(self, units, **kwargs):\n         super().__init__(**kwargs)\n         self.units = units\n-        self.nested_layer = keras_core.layers.Dense(self.units)\n+        self.nested_layer = keras_core.layers.Dense(self.units, name=\"dense\")\n \n     def build(self, input_shape):\n         self.additional_weights = [\n@@ -85,8 +85,8 @@ class LayerWithCustomSaving(MyDense):\n class CustomModelX(keras_core.Model):\n     def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n-        self.dense1 = MyDense(1)\n-        self.dense2 = MyDense(1)\n+        self.dense1 = MyDense(1, name=\"my_dense_1\")\n+        self.dense2 = MyDense(1, name=\"my_dense_2\")\n \n     def call(self, inputs):\n         out = self.dense1(inputs)\n@@ -131,10 +131,8 @@ def my_mean_squared_error(y_true, y_pred):\n     return ops.mean(ops.square(y_pred - y_true), axis=-1)\n \n \n-@pytest.mark.requires_trainable_backend\n-class SavingTest(testing.TestCase):\n-    def _get_subclassed_model(self, compile=True):\n-        subclassed_model = CustomModelX()\n+def _get_subclassed_model(compile=True):\n+    subclassed_model = CustomModelX(name=\"custom_model_x\")\n     if compile:\n         subclassed_model.compile(\n             optimizer=\"adam\",\n@@ -143,7 +141,8 @@ class SavingTest(testing.TestCase):\n         )\n     return subclassed_model\n \n-    def _get_custom_sequential_model(self, compile=True):\n+\n+def _get_custom_sequential_model(compile=True):\n     sequential_model = keras_core.Sequential([MyDense(1), MyDense(1)])\n     if compile:\n         sequential_model.compile(\n@@ -153,9 +152,13 @@ class SavingTest(testing.TestCase):\n         )\n     return sequential_model\n \n-    def _get_basic_sequential_model(self, compile=True):\n+\n+def _get_basic_sequential_model(compile=True):\n     sequential_model = keras_core.Sequential(\n-            [keras_core.layers.Dense(1), keras_core.layers.Dense(1)]\n+        [\n+            keras_core.layers.Dense(1, name=\"dense_1\"),\n+            keras_core.layers.Dense(1, name=\"dense_2\"),\n+        ]\n     )\n     if compile:\n         sequential_model.compile(\n@@ -165,7 +168,8 @@ class SavingTest(testing.TestCase):\n         )\n     return sequential_model\n \n-    def _get_custom_functional_model(self, compile=True):\n+\n+def _get_custom_functional_model(compile=True):\n     inputs = keras_core.Input(shape=(4,), batch_size=2)\n     x = MyDense(1, name=\"first_dense\")(inputs)\n     outputs = MyDense(1, name=\"second_dense\")(x)\n@@ -178,7 +182,8 @@ class SavingTest(testing.TestCase):\n         )\n     return functional_model\n \n-    def _get_basic_functional_model(self, compile=True):\n+\n+def _get_basic_functional_model(compile=True):\n     inputs = keras_core.Input(shape=(4,), batch_size=2)\n     x = keras_core.layers.Dense(1, name=\"first_dense\")(inputs)\n     outputs = keras_core.layers.Dense(1, name=\"second_dense\")(x)\n@@ -191,6 +196,9 @@ class SavingTest(testing.TestCase):\n         )\n     return functional_model\n \n+\n+@pytest.mark.requires_trainable_backend\n+class SavingTest(testing.TestCase):\n     def _test_inference_after_instantiation(self, model):\n         x_ref = np.random.random((2, 4))\n         y_ref = model(x_ref)\n@@ -204,23 +212,23 @@ class SavingTest(testing.TestCase):\n         self.assertAllClose(y_ref, loaded_model(x_ref))\n \n     def test_inference_after_instantiation_subclassed(self):\n-        model = self._get_subclassed_model(compile=False)\n+        model = _get_subclassed_model(compile=False)\n         self._test_inference_after_instantiation(model)\n \n     def test_inference_after_instantiation_basic_sequential(self):\n-        model = self._get_basic_sequential_model(compile=False)\n+        model = _get_basic_sequential_model(compile=False)\n         self._test_inference_after_instantiation(model)\n \n     def test_inference_after_instantiation_basic_functional(self):\n-        model = self._get_basic_functional_model(compile=False)\n+        model = _get_basic_functional_model(compile=False)\n         self._test_inference_after_instantiation(model)\n \n     def test_inference_after_instantiation_custom_sequential(self):\n-        model = self._get_custom_sequential_model(compile=False)\n+        model = _get_custom_sequential_model(compile=False)\n         self._test_inference_after_instantiation(model)\n \n     def test_inference_after_instantiation_custom_functional(self):\n-        model = self._get_custom_functional_model(compile=False)\n+        model = _get_custom_functional_model(compile=False)\n         self._test_inference_after_instantiation(model)\n \n     def _test_compile_preserved(self, model):\n@@ -256,23 +264,23 @@ class SavingTest(testing.TestCase):\n             self.assertAllClose(ref_m, m)\n \n     def test_compile_preserved_subclassed(self):\n-        model = self._get_subclassed_model(compile=True)\n+        model = _get_subclassed_model(compile=True)\n         self._test_compile_preserved(model)\n \n     def test_compile_preserved_basic_sequential(self):\n-        model = self._get_basic_sequential_model(compile=True)\n+        model = _get_basic_sequential_model(compile=True)\n         self._test_compile_preserved(model)\n \n     def test_compile_preserved_custom_sequential(self):\n-        model = self._get_custom_sequential_model(compile=True)\n+        model = _get_custom_sequential_model(compile=True)\n         self._test_compile_preserved(model)\n \n     def test_compile_preserved_basic_functional(self):\n-        model = self._get_basic_functional_model(compile=True)\n+        model = _get_basic_functional_model(compile=True)\n         self._test_compile_preserved(model)\n \n     def test_compile_preserved_custom_functional(self):\n-        model = self._get_custom_functional_model(compile=True)\n+        model = _get_custom_functional_model(compile=True)\n         self._test_compile_preserved(model)\n \n     def test_saving_preserve_unbuilt_state(self):\n@@ -286,7 +294,7 @@ class SavingTest(testing.TestCase):\n \n     def test_saved_module_paths_and_class_names(self):\n         temp_filepath = os.path.join(self.get_temp_dir(), \"my_model.keras\")\n-        subclassed_model = self._get_subclassed_model()\n+        subclassed_model = _get_subclassed_model()\n         x = np.random.random((100, 32))\n         y = np.random.random((100, 1))\n         subclassed_model.fit(x, y, epochs=1)\n@@ -393,7 +401,7 @@ class SavingTest(testing.TestCase):\n \n     def test_load_model_api_endpoint(self):\n         temp_filepath = Path(os.path.join(self.get_temp_dir(), \"mymodel.keras\"))\n-        model = self._get_basic_functional_model()\n+        model = _get_basic_functional_model()\n         ref_input = np.random.random((2, 4))\n         ref_output = model.predict(ref_input)\n         model.save(temp_filepath)\n@@ -404,36 +412,36 @@ class SavingTest(testing.TestCase):\n         temp_filepath = Path(\n             os.path.join(self.get_temp_dir(), \"mymodel.weights.h5\")\n         )\n-        model = self._get_basic_functional_model()\n+        model = _get_basic_functional_model()\n         ref_input = np.random.random((2, 4))\n         ref_output = model.predict(ref_input)\n         saving_lib.save_weights_only(model, temp_filepath)\n-        model = self._get_basic_functional_model()\n+        model = _get_basic_functional_model()\n         saving_lib.load_weights_only(model, temp_filepath)\n         self.assertAllClose(model.predict(ref_input), ref_output, atol=1e-6)\n         # Test with Model method\n-        model = self._get_basic_functional_model()\n+        model = _get_basic_functional_model()\n         model.load_weights(temp_filepath)\n         self.assertAllClose(model.predict(ref_input), ref_output, atol=1e-6)\n \n     def test_load_weights_only_with_keras_file(self):\n         # Test loading weights from whole saved model\n         temp_filepath = Path(os.path.join(self.get_temp_dir(), \"mymodel.keras\"))\n-        model = self._get_basic_functional_model()\n+        model = _get_basic_functional_model()\n         ref_input = np.random.random((2, 4))\n         ref_output = model.predict(ref_input)\n         saving_lib.save_model(model, temp_filepath)\n-        model = self._get_basic_functional_model()\n+        model = _get_basic_functional_model()\n         saving_lib.load_weights_only(model, temp_filepath)\n         self.assertAllClose(model.predict(ref_input), ref_output, atol=1e-6)\n         # Test with Model method\n-        model = self._get_basic_functional_model()\n+        model = _get_basic_functional_model()\n         model.load_weights(temp_filepath)\n         self.assertAllClose(model.predict(ref_input), ref_output, atol=1e-6)\n \n     def test_compile_arg(self):\n         temp_filepath = os.path.join(self.get_temp_dir(), \"mymodel.keras\")\n-        model = self._get_basic_functional_model()\n+        model = _get_basic_functional_model()\n         model.compile(\"sgd\", \"mse\")\n         model.fit(np.random.random((2, 4)), np.random.random((2, 1)))\n         saving_lib.save_model(model, temp_filepath)\n@@ -445,7 +453,7 @@ class SavingTest(testing.TestCase):\n \n     # def test_overwrite(self):\n     #     temp_filepath = os.path.join(self.get_temp_dir(), \"mymodel.keras\")\n-    #     model = self._get_basic_functional_model()\n+    #     model = _get_basic_functional_model()\n     #     model.save(temp_filepath)\n     #     model.save(temp_filepath, overwrite=True)\n     #     with self.assertRaises(EOFError):\n@@ -454,7 +462,7 @@ class SavingTest(testing.TestCase):\n     #     temp_filepath = os.path.join(\n     #         self.get_temp_dir(), \"mymodel.weights.h5\"\n     #     )\n-    #     model = self._get_basic_functional_model()\n+    #     model = _get_basic_functional_model()\n     #     model.save_weights(temp_filepath)\n     #     model.save_weights(temp_filepath, overwrite=True)\n     #     with self.assertRaises(EOFError):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c58985b02da524f4dce8642d100d033cf1333142", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 82 | Lines Deleted: 40 | Files Changed: 1 | Hunks: 20 | Methods Changed: 15 | Complexity Δ (Sum/Max): 6/6 | Churn Δ: 122 | Churn Cumulative: 887 | Contributors (this commit): 4 | Commits (past 90d): 7 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,8 +1,9 @@\n \"\"\"\n Title: Image classification with modern MLP models\n Author: [Khalid Salama](https://www.linkedin.com/in/khalid-salama-24403144/)\n+Converted to Keras Core by: [Guillaume Baquiast](https://www.linkedin.com/in/guillaume-baquiast-478965ba/), [divyasreepat](https://github.com/divyashreepathihalli)\n Date created: 2021/05/30\n-Last modified: 2021/05/30\n+Last modified: 2023/08/03\n Description: Implementing the MLP-Mixer, FNet, and gMLP models for CIFAR-100 image classification.\n Accelerator: GPU\n \"\"\"\n@@ -28,10 +29,8 @@ main building blocks.\n \"\"\"\n \n import numpy as np\n-import tensorflow as tf\n import keras_core as keras\n from keras_core import layers\n-from keras_core.layers import Lambda\n \n \"\"\"\n ## Prepare the data\n@@ -76,15 +75,11 @@ def build_classifier(blocks, positional_encoding=False):\n     # Augment data.\n     augmented = data_augmentation(inputs)\n     # Create patches.\n-    patches = Patches(patch_size, num_patches)(augmented)\n+    patches = Patches(patch_size)(augmented)\n     # Encode patches to generate a [batch_size, num_patches, embedding_dim] tensor.\n     x = layers.Dense(units=embedding_dim)(patches)\n     if positional_encoding:\n-        positions = tf.range(start=0, limit=num_patches, delta=1)\n-        position_embedding = layers.Embedding(\n-            input_dim=num_patches, output_dim=embedding_dim\n-        )(positions)\n-        x = x + position_embedding\n+        x = x + PositionEmbedding(sequence_length=num_patches)(x)\n     # Process x using the module blocks.\n     x = blocks(x)\n     # Apply global average pooling to generate a [batch_size, embedding_dim] representation tensor.\n@@ -168,26 +163,74 @@ data_augmentation.layers[0].adapt(x_train)\n \n \n class Patches(layers.Layer):\n-    def __init__(self, patch_size, num_patches):\n-        super().__init__()\n+    def __init__(self, patch_size, **kwargs):\n+        super().__init__(**kwargs)\n         self.patch_size = patch_size\n-        self.num_patches = num_patches\n \n-    def call(self, images):\n-        batch_size = tf.shape(images)[0]\n-        patches = tf.image.extract_patches(\n-            images=images,\n-            sizes=[1, self.patch_size, self.patch_size, 1],\n-            strides=[1, self.patch_size, self.patch_size, 1],\n-            rates=[1, 1, 1, 1],\n-            padding=\"VALID\",\n-        )\n-        patch_dims = patches.shape[-1]\n-        patches = tf.reshape(\n-            patches, [batch_size, self.num_patches, patch_dims]\n-        )\n-        return patches\n+    def call(self, x):\n+        patches = keras.ops.image.extract_patches(x, self.patch_size)\n+        batch_size = keras.ops.shape(patches)[0]\n+        num_patches = keras.ops.shape(patches)[1] * keras.ops.shape(patches)[2]\n+        patch_dim = keras.ops.shape(patches)[3]\n+        out = keras.ops.reshape(patches, (batch_size, num_patches, patch_dim))\n+        return out\n \n+\"\"\"\n+## Implement position embedding as a layer\n+\"\"\"\n+\n+class PositionEmbedding(keras.layers.Layer):\n+    def __init__(\n+        self,\n+        sequence_length,\n+        initializer=\"glorot_uniform\",\n+        **kwargs,\n+    ):\n+        super().__init__(**kwargs)\n+        if sequence_length is None:\n+            raise ValueError(\n+                \"`sequence_length` must be an Integer, received `None`.\"\n+            )\n+        self.sequence_length = int(sequence_length)\n+        self.initializer = keras.initializers.get(initializer)\n+\n+    def get_config(self):\n+        config = super().get_config()\n+        config.update(\n+            {\n+                \"sequence_length\": self.sequence_length,\n+                \"initializer\": keras.initializers.serialize(self.initializer),\n+            }\n+        )\n+        return config\n+\n+    def build(self, input_shape):\n+        feature_size = input_shape[-1]\n+        self.position_embeddings = self.add_weight(\n+            name=\"embeddings\",\n+            shape=[self.sequence_length, feature_size],\n+            initializer=self.initializer,\n+            trainable=True,\n+        )\n+\n+        super().build(input_shape)\n+\n+    def call(self, inputs, start_index=0):\n+        shape = keras.ops.shape(inputs)\n+        feature_length = shape[-1]\n+        sequence_length = shape[-2]\n+        # trim to match the length of the input sequence, which might be less\n+        # than the sequence_length of the layer.\n+        position_embeddings = keras.ops.convert_to_tensor(self.position_embeddings)\n+        position_embeddings = keras.ops.slice(\n+            position_embeddings,\n+            (start_index, 0),\n+            (sequence_length, feature_length),\n+        )\n+        return keras.ops.broadcast_to(position_embeddings, shape)\n+\n+    def compute_output_shape(self, input_shape):\n+        return input_shape\n \n \"\"\"\n ## The MLP-Mixer model\n@@ -224,7 +267,7 @@ class MLPMixerLayer(layers.Layer):\n         self.mlp2 = keras.Sequential(\n             [\n                 layers.Dense(units=num_patches, activation=\"gelu\"),\n-                layers.Dense(units=embedding_dim),\n+                layers.Dense(units=hidden_units),\n                 layers.Dropout(rate=dropout_rate),\n             ]\n         )\n@@ -237,11 +280,11 @@ class MLPMixerLayer(layers.Layer):\n         # Apply layer normalization.\n         x = self.normalize(inputs)\n         # Transpose inputs from [num_batches, num_patches, hidden_units] to [num_batches, hidden_units, num_patches].\n-        x_channels = tf.linalg.matrix_transpose(x)\n+        x_channels = keras.ops.transpose(x, axes=(0, 2, 1))\n         # Apply mlp1 on each channel independently.\n         mlp1_outputs = self.mlp1(x_channels)\n         # Transpose mlp1_outputs from [num_batches, hidden_dim, num_patches] to [num_batches, num_patches, hidden_units].\n-        mlp1_outputs = tf.linalg.matrix_transpose(mlp1_outputs)\n+        mlp1_outputs = keras.ops.transpose(mlp1_outputs, axes=(0, 2, 1))\n         # Add skip connection.\n         x = mlp1_outputs + inputs\n         # Apply layer normalization.\n@@ -279,7 +322,7 @@ As mentioned in the [MLP-Mixer](https://arxiv.org/abs/2105.01601) paper,\n when pre-trained on large datasets, or with modern regularization schemes,\n the MLP-Mixer attains competitive scores to state-of-the-art models.\n You can obtain better results by increasing the embedding dimensions,\n-increasing, increasing the number of mixer blocks, and training the model for longer.\n+increasing the number of mixer blocks, and training the model for longer.\n You may also try to increase the size of the input images and use different patch sizes.\n \"\"\"\n \n@@ -300,7 +343,7 @@ in the Transformer block with a parameter-free 2D Fourier transformation layer:\n \n class FNetLayer(layers.Layer):\n     def __init__(\n-        self, num_patches, embedding_dim, dropout_rate, *args, **kwargs\n+        self, embedding_dim, dropout_rate, *args, **kwargs\n     ):\n         super().__init__(*args, **kwargs)\n \n@@ -317,10 +360,9 @@ class FNetLayer(layers.Layer):\n \n     def call(self, inputs):\n         # Apply fourier transformations.\n-        x = tf.cast(\n-            tf.signal.fft2d(tf.cast(inputs, dtype=tf.dtypes.complex64)),\n-            dtype=tf.dtypes.float32,\n-        )\n+        real_part = inputs\n+        im_part = keras.ops.zeros_like(inputs)\n+        x = keras.ops.fft2((real_part, im_part))[0]\n         # Add skip connection.\n         x = x + inputs\n         # Apply layer normalization.\n@@ -342,7 +384,7 @@ takes around 8 seconds per epoch.\n \n fnet_blocks = keras.Sequential(\n     [\n-        FNetLayer(num_patches, embedding_dim, dropout_rate)\n+        FNetLayer(embedding_dim, dropout_rate)\n         for _ in range(num_blocks)\n     ]\n )\n@@ -398,14 +440,14 @@ class gMLPLayer(layers.Layer):\n \n     def spatial_gating_unit(self, x):\n         # Split x along the channel dimensions.\n-        # Tensors u and v will in th shape of [batch_size, num_patchs, embedding_dim].\n-        u, v = tf.split(x, num_or_size_splits=2, axis=2)\n+        # Tensors u and v will in the shape of [batch_size, num_patchs, embedding_dim].\n+        u, v = keras.ops.split(x, indices_or_sections=2, axis=2)\n         # Apply layer normalization.\n         v = self.normalize2(v)\n         # Apply spatial projection.\n-        v_channels = tf.linalg.matrix_transpose(v)\n+        v_channels = keras.ops.transpose(v, axes=(0, 2, 1))\n         v_projected = self.spatial_projection(v_channels)\n-        v_projected = tf.linalg.matrix_transpose(v_projected)\n+        v_projected = keras.ops.transpose(v_projected, axes=(0, 2, 1))\n         # Apply element-wise multiplication.\n         return u * v_projected\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#85f65c41bec1f64f197ff29b1f7533698507ba23", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 201 | Lines Deleted: 65 | Files Changed: 2 | Hunks: 20 | Methods Changed: 14 | Complexity Δ (Sum/Max): 14/13 | Churn Δ: 266 | Churn Cumulative: 472 | Contributors (this commit): 4 | Commits (past 90d): 13 | Contributors (cumulative): 7 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2,13 +2,12 @@ import numpy as np\n \n from keras_core import backend\n from keras_core.api_export import keras_core_export\n-from keras_core.layers.layer import Layer\n-from keras_core.utils import backend_utils\n-from keras_core.utils.module_utils import tensorflow as tf\n+from keras_core.layers.preprocessing.tf_data_layer import TFDataLayer\n+from keras_core.random.seed_generator import SeedGenerator\n \n \n @keras_core_export(\"keras_core.layers.RandomRotation\")\n-class RandomRotation(Layer):\n+class RandomRotation(TFDataLayer):\n     \"\"\"A preprocessing layer which randomly rotates images during training.\n \n     This layer will apply random rotations to each image, filling empty space\n@@ -22,14 +21,6 @@ class RandomRotation(Layer):\n     of integer or floating point dtype.\n     By default, the layer will output floats.\n \n-    **Note:** This layer wraps `tf.keras.layers.RandomRotation`. It cannot\n-    be used as part of the compiled computation graph of a model with\n-    any backend other than TensorFlow.\n-    It can however be used with any backend when running eagerly.\n-    It can also always be used as part of an input preprocessing pipeline\n-    with any backend (outside the model itself), which is how we recommend\n-    to use this layer.\n-\n     **Note:** This layer is safe to use inside a `tf.data` pipeline\n     (independently of which backend you're using).\n \n@@ -76,6 +67,17 @@ class RandomRotation(Layer):\n             the boundaries when `fill_mode=\"constant\"`.\n     \"\"\"\n \n+    _FACTOR_VALIDATION_ERROR = (\n+        \"The `factor` argument should be a number (or a list of two numbers) \"\n+        \"in the range [-1.0, 1.0]. \"\n+    )\n+    _VALUE_RANGE_VALIDATION_ERROR = (\n+        \"The `value_range` argument should be a list of two numbers. \"\n+    )\n+\n+    _SUPPORTED_FILL_MODE = (\"reflect\", \"wrap\", \"constant\", \"nearest\")\n+    _SUPPORTED_INTERPOLATION = (\"nearest\", \"bilinear\")\n+\n     def __init__(\n         self,\n         factor,\n@@ -83,45 +85,168 @@ class RandomRotation(Layer):\n         interpolation=\"bilinear\",\n         seed=None,\n         fill_value=0.0,\n-        name=None,\n+        value_range=(0, 255),\n+        data_format=None,\n         **kwargs,\n     ):\n-        if not tf.available:\n-            raise ImportError(\n-                \"Layer RandomRotation requires TensorFlow. \"\n-                \"Install it via `pip install tensorflow`.\"\n-            )\n+        super().__init__(**kwargs)\n+        self.seed = seed\n+        self.generator = SeedGenerator(seed)\n+        self._set_factor(factor)\n+        self._set_value_range(value_range)\n+        self.data_format = backend.standardize_data_format(data_format)\n+        self.fill_mode = fill_mode\n+        self.interpolation = interpolation\n+        self.fill_value = fill_value\n \n-        super().__init__(name=name, **kwargs)\n-        self.seed = seed or backend.random.make_default_seed()\n-        self.layer = tf.keras.layers.RandomRotation(\n-            factor=factor,\n-            fill_mode=fill_mode,\n-            interpolation=interpolation,\n-            seed=self.seed,\n-            fill_value=fill_value,\n-            name=name,\n-            **kwargs,\n-        )\n         self.supports_jit = False\n-        self._convert_input_args = False\n-        self._allow_non_tensor_positional_args = True\n \n-    def call(self, inputs, training=True):\n-        if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n-            inputs = tf.convert_to_tensor(backend.convert_to_numpy(inputs))\n-        outputs = self.layer.call(inputs, training=training)\n-        if (\n-            backend.backend() != \"tensorflow\"\n-            and not backend_utils.in_tf_graph()\n-        ):\n-            outputs = backend.convert_to_tensor(outputs)\n+        if self.fill_mode not in self._SUPPORTED_FILL_MODE:\n+            raise NotImplementedError(\n+                f\"Unknown `fill_mode` {fill_mode}. Expected of one \"\n+                f\"{self._SUPPORTED_FILL_MODE}.\"\n+            )\n+        if self.interpolation not in self._SUPPORTED_INTERPOLATION:\n+            raise NotImplementedError(\n+                f\"Unknown `interpolation` {interpolation}. Expected of one \"\n+                f\"{self._SUPPORTED_INTERPOLATION}.\"\n+            )\n+\n+    def _set_value_range(self, value_range):\n+        if not isinstance(value_range, (tuple, list)):\n+            raise ValueError(\n+                self.value_range_VALIDATION_ERROR\n+                + f\"Received: value_range={value_range}\"\n+            )\n+        if len(value_range) != 2:\n+            raise ValueError(\n+                self.value_range_VALIDATION_ERROR\n+                + f\"Received: value_range={value_range}\"\n+            )\n+        self.value_range = sorted(value_range)\n+\n+    def _set_factor(self, factor):\n+        if isinstance(factor, (tuple, list)):\n+            if len(factor) != 2:\n+                raise ValueError(\n+                    self._FACTOR_VALIDATION_ERROR + f\"Received: factor={factor}\"\n+                )\n+            self._check_factor_range(factor[0])\n+            self._check_factor_range(factor[1])\n+            self._factor = sorted(factor)\n+        elif isinstance(factor, (int, float)):\n+            self._check_factor_range(factor)\n+            factor = abs(factor)\n+            self._factor = [-factor, factor]\n+        else:\n+            raise ValueError(\n+                self._FACTOR_VALIDATION_ERROR + f\"Received: factor={factor}\"\n+            )\n+\n+    def _check_factor_range(self, input_number):\n+        if input_number > 1.0 or input_number < -1.0:\n+            raise ValueError(\n+                self._FACTOR_VALIDATION_ERROR\n+                + f\"Received: input_number={input_number}\"\n+            )\n+\n+    \"\"\"\n+    Assume an angle ø, then rotation matrix is defined by\n+    | cos(ø)   -sin(ø)  x_offset |\n+    | sin(ø)    cos(ø)  y_offset |\n+    |   0         0         1    |\n+\n+    This function is returning the 8 elements barring the final 1 as a 1D array\n+    \"\"\"\n+\n+    def _get_rotation_matrix(self, inputs):\n+        input_shape = len(inputs.shape)\n+        if input_shape == 4:\n+            if self.data_format == \"channels_last\":\n+                batch_size = inputs.shape[0]\n+                image_height = inputs.shape[1]\n+                image_width = inputs.shape[2]\n+            else:\n+                batch_size = inputs.shape[1]\n+                image_height = inputs.shape[2]\n+                image_width = inputs.shape[3]\n+        else:\n+            batch_size = 1\n+            if self.data_format == \"channels_last\":\n+                image_height = inputs.shape[0]\n+                image_width = inputs.shape[1]\n+            else:\n+                image_height = inputs.shape[1]\n+                image_width = inputs.shape[2]\n+\n+        lower = self._factor[0] * 2.0 * self.backend.convert_to_tensor(np.pi)\n+        upper = self._factor[1] * 2.0 * self.backend.convert_to_tensor(np.pi)\n+\n+        seed_generator = self._get_seed_generator(self.backend._backend)\n+        angle = self.backend.random.uniform(\n+            shape=(batch_size,),\n+            minval=lower,\n+            maxval=upper,\n+            seed=seed_generator,\n+        )\n+\n+        cos_theta = self.backend.numpy.cos(angle)\n+        sin_theta = self.backend.numpy.sin(angle)\n+\n+        x_offset = (\n+            (image_width - 1)\n+            - (cos_theta * (image_width - 1) - sin_theta * (image_height - 1))\n+        ) / 2.0\n+\n+        y_offset = (\n+            (image_height - 1)\n+            - (sin_theta * (image_width - 1) + cos_theta * (image_height - 1))\n+        ) / 2.0\n+\n+        outputs = self.backend.numpy.concatenate(\n+            [\n+                self.backend.numpy.cos(angle)[:, None],\n+                -self.backend.numpy.sin(angle)[:, None],\n+                x_offset[:, None],\n+                self.backend.numpy.sin(angle)[:, None],\n+                self.backend.numpy.cos(angle)[:, None],\n+                y_offset[:, None],\n+                self.backend.numpy.zeros((batch_size, 2)),\n+            ],\n+            axis=1,\n+        )\n+        if input_shape == 3:\n+            outputs = self.backend.numpy.squeeze(outputs, axis=0)\n         return outputs\n \n+    def call(self, inputs, training=True):\n+        inputs = self.backend.cast(inputs, self.compute_dtype)\n+        if training:\n+            rotation_matrix = self._get_rotation_matrix(inputs)\n+            transformed_image = self.backend.image.affine_transform(\n+                image=inputs,\n+                transform=rotation_matrix,\n+                interpolation=self.interpolation,\n+                fill_mode=self.fill_mode,\n+                fill_value=self.fill_value,\n+                data_format=self.data_format,\n+            )\n+            return transformed_image\n+        else:\n+            return inputs\n+\n     def compute_output_shape(self, input_shape):\n-        return tuple(self.layer.compute_output_shape(input_shape))\n+        return input_shape\n \n     def get_config(self):\n-        config = self.layer.get_config()\n-        config.update({\"seed\": self.seed})\n-        return config\n+        config = {\n+            \"factor\": self._factor,\n+            \"value_range\": self.value_range,\n+            \"data_format\": self.data_format,\n+            \"fill_mode\": self.fill_mode,\n+            \"fill_value\": self.fill_value,\n+            \"interpolation\": self.interpolation,\n+            \"seed\": self.seed,\n+        }\n+        base_config = super().get_config()\n+        return {**base_config, **config}\n\n@@ -9,11 +9,13 @@ from keras_core import testing\n \n class RandomRotationTest(testing.TestCase, parameterized.TestCase):\n     @parameterized.named_parameters(\n+        (\"random_rotate_neg4\", -0.4),\n+        (\"random_rotate_neg2\", -0.2),\n         (\"random_rotate_4\", 0.4),\n-        (\"random_rotate_3\", 0.3),\n-        (\"random_rotate_tuple_factor\", (-0.5, 0.4)),\n+        (\"random_rotate_2\", 0.2),\n+        (\"random_rotate_tuple\", (-0.2, 0.4)),\n     )\n-    def test_random_rotation(self, factor):\n+    def test_random_rotation_shapes(self, factor):\n         self.run_layer_test(\n             layers.RandomRotation,\n             init_kwargs={\n@@ -27,6 +29,8 @@ class RandomRotationTest(testing.TestCase, parameterized.TestCase):\n \n     def test_random_rotation_correctness(self):\n         input_image = np.reshape(np.arange(0, 25), (1, 5, 5, 1))\n+        layer = layers.RandomRotation(factor=(0.5, 0.5))\n+        actual_output = layer(input_image)\n         expected_output = np.asarray(\n             [\n                 [24, 23, 22, 21, 20],\n@@ -35,25 +39,32 @@ class RandomRotationTest(testing.TestCase, parameterized.TestCase):\n                 [9, 8, 7, 6, 5],\n                 [4, 3, 2, 1, 0],\n             ]\n-        )\n-        expected_output = backend.convert_to_tensor(\n-            np.reshape(expected_output, (1, 5, 5, 1))\n-        )\n-        self.run_layer_test(\n-            layers.RandomRotation,\n-            init_kwargs={\n-                \"factor\": (0.5, 0.5),\n-            },\n-            input_shape=None,\n-            input_data=input_image,\n-            expected_output=expected_output,\n-            supports_masking=False,\n-            run_training_check=False,\n+        ).reshape((1, 5, 5, 1))\n+\n+        self.assertAllClose(\n+            backend.convert_to_tensor(expected_output), actual_output, atol=1e-5\n         )\n \n+    def test_training_false(self):\n+        input_image = np.reshape(np.arange(0, 25), (1, 5, 5, 1))\n+        layer = layers.RandomRotation(factor=(0.5, 0.5))\n+        actual_output = layer(input_image, training=False)\n+        self.assertAllClose(actual_output, input_image)\n+\n     def test_tf_data_compatibility(self):\n-        layer = layers.RandomRotation(0.2)\n-        input_data = np.random.random((1, 4, 4, 3))\n-        ds = tf.data.Dataset.from_tensor_slices(input_data).batch(1).map(layer)\n+        input_image = np.reshape(np.arange(0, 25), (1, 5, 5, 1))\n+        layer = layers.RandomRotation(factor=(0.5, 0.5))\n+\n+        ds = tf.data.Dataset.from_tensor_slices(input_image).map(layer)\n+        expected_output = np.asarray(\n+            [\n+                [24, 23, 22, 21, 20],\n+                [19, 18, 17, 16, 15],\n+                [14, 13, 12, 11, 10],\n+                [9, 8, 7, 6, 5],\n+                [4, 3, 2, 1, 0],\n+            ]\n+        ).reshape((5, 5, 1))\n         for output in ds.take(1):\n-            output.numpy()\n+            output = output.numpy()\n+        self.assertAllClose(expected_output, output)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
