{"custom_id": "keras#3fcb38c1a7221473232581a6e0215dc0c7fa9518", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 35 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 3 | Methods Changed: 4 | Complexity Δ (Sum/Max): 8/5 | Churn Δ: 35 | Churn Cumulative: 349 | Contributors (this commit): 5 | Commits (past 90d): 7 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -42,6 +42,15 @@ class TFOptimizer(base_optimizer.BaseOptimizer):\n             \"(as it is incompatible with tf.distribute).\"\n         )\n \n+    def assign(self, variable, value):\n+        if isinstance(variable, KerasVariable):\n+            variable = variable.value\n+        value = tf.cast(value, variable.dtype)\n+        if isinstance(value, tf.IndexedSlices):\n+            variable.scatter_update(value)\n+        else:\n+            variable.assign(value)\n+\n     def assign_add(self, variable, value):\n         if isinstance(variable, KerasVariable):\n             variable = variable.value\n\n@@ -8,6 +8,26 @@ from keras import ops\n from keras import optimizers\n from keras import testing\n \n+\n+class ScatterUpdateOptimizer(optimizers.Optimizer):\n+    def __init__(self):\n+        super().__init__(learning_rate=0.001)\n+\n+    def build(self, variables):\n+        if self.built:\n+            return\n+        super().build(variables)\n+        self.momentums = [\n+            self.add_variable_from_reference(v, name=\"momentum\")\n+            for v in variables\n+        ]\n+\n+    def update_step(self, grad, variable, learning_rate):\n+        momentum = self.momentums[self._get_variable_index(variable)]\n+        self.assign(momentum, ops.cast(grad, momentum.dtype))\n+        self.assign(variable, ops.cast(grad, variable.dtype))\n+\n+\n TEST_CASES = [\n     {\n         \"testcase_name\": \"adadelta\",\n@@ -97,6 +117,12 @@ TEST_CASES = [\n         \"optimizer_class\": optimizers.SGD,\n         \"init_kwargs\": {\"momentum\": 0.05, \"nesterov\": True},\n     },\n+    {\n+        \"testcase_name\": \"scatter_update\",\n+        \"optimizer_class\": ScatterUpdateOptimizer,\n+        \"expect_model_sparse_variable_updates\": True,\n+        \"expect_optimizer_sparse_variable_updates\": True,\n+    },\n ]\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#65c646229e5f1c3ea01dedde683ae7fe0adbd32c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 215 | Lines Deleted: 87 | Files Changed: 7 | Hunks: 22 | Methods Changed: 20 | Complexity Δ (Sum/Max): 30/12 | Churn Δ: 302 | Churn Cumulative: 1488 | Contributors (this commit): 8 | Commits (past 90d): 28 | Contributors (cumulative): 22 | DMM Complexity: 0.04807692307692308\n\nDIFF:\n@@ -4,6 +4,8 @@ from keras import backend\n from keras.api_export import keras_export\n from keras.utils import tree\n \n+NUM_BATCHES_FOR_TENSOR_SPEC = 2\n+\n \n @keras_export(\"keras.utils.unpack_x_y_sample_weight\")\n def unpack_x_y_sample_weight(data):\n@@ -125,6 +127,54 @@ def class_weight_to_sample_weights(y, class_weight):\n     return sample_weight\n \n \n+def get_tensor_spec(batches):\n+    \"\"\"Return the common tensor spec for a list of batches.\n+\n+    Args:\n+        batches: list of structures of tensors. The structures must be\n+            identical, but the shape at each leaf may be different.\n+    Returns: the common tensor spec for all the batches.\n+    \"\"\"\n+    from keras.utils.module_utils import tensorflow as tf\n+\n+    def get_single_tensor_spec(*tensors):\n+        x = tensors[0]\n+        rank = len(x.shape)\n+        if rank < 1:\n+            raise ValueError(\n+                \"When passing a dataset to a Keras model, the arrays must \"\n+                f\"be at least rank 1. Received: {x} of rank {len(x.shape)}.\"\n+            )\n+        for t in tensors:\n+            if len(t.shape) != rank:\n+                raise ValueError(\n+                    \"When passing a dataset to a Keras model, the \"\n+                    \"corresponding arrays in each batch must have the same \"\n+                    f\"rank. Received: {x} and {t}\"\n+                )\n+        shape = []\n+        # Merge shapes: go through each dimension one by one and keep the\n+        # common values\n+        for dims in zip(*[list(x.shape) for x in tensors]):\n+            dims_set = set(dims)\n+            shape.append(dims_set.pop() if len(dims_set) == 1 else None)\n+        shape[0] = None  # batch size may not be static\n+\n+        dtype = backend.standardize_dtype(x.dtype)\n+        if isinstance(x, tf.RaggedTensor):\n+            return tf.RaggedTensorSpec(shape=shape, dtype=dtype)\n+        if (\n+            isinstance(x, tf.SparseTensor)\n+            or is_scipy_sparse(x)\n+            or is_jax_sparse(x)\n+        ):\n+            return tf.SparseTensorSpec(shape=shape, dtype=dtype)\n+        else:\n+            return tf.TensorSpec(shape=shape, dtype=dtype)\n+\n+    return tree.map_structure(get_single_tensor_spec, *batches)\n+\n+\n def get_jax_iterator(iterable):\n     from keras.backend.jax.core import convert_to_tensor\n \n\n@@ -1,6 +1,5 @@\n import itertools\n \n-from keras import backend\n from keras.trainers.data_adapters import data_adapter_utils\n from keras.trainers.data_adapters.data_adapter import DataAdapter\n from keras.utils import tree\n@@ -10,47 +9,17 @@ class GeneratorDataAdapter(DataAdapter):\n     \"\"\"Adapter for Python generators.\"\"\"\n \n     def __init__(self, generator):\n-        first_batch, generator = peek_and_restore(generator)\n+        first_batches, generator = peek_and_restore(generator)\n         self.generator = generator\n-        self._first_batch = first_batch\n+        self._first_batches = first_batches\n         self._output_signature = None\n-        if not isinstance(first_batch, tuple):\n+        if not isinstance(first_batches[0], tuple):\n             raise ValueError(\n                 \"When passing a Python generator to a Keras model, \"\n                 \"the generator must return a tuple, either \"\n                 \"(input,) or (inputs, targets) or \"\n                 \"(inputs, targets, sample_weights). \"\n-                f\"Received: {first_batch}\"\n-            )\n-\n-    def _set_tf_output_signature(self):\n-        from keras.utils.module_utils import tensorflow as tf\n-\n-        def get_tensor_spec(x):\n-            shape = x.shape\n-            if len(shape) < 1:\n-                raise ValueError(\n-                    \"When passing a Python generator to a Keras model, \"\n-                    \"the arrays returned by the generator \"\n-                    \"must be at least rank 1. Received: \"\n-                    f\"{x} of rank {len(x.shape)}\"\n-                )\n-            shape = list(shape)\n-            shape[0] = None  # The batch size is not guaranteed to be static.\n-            dtype = backend.standardize_dtype(x.dtype)\n-            if isinstance(x, tf.RaggedTensor):\n-                return tf.RaggedTensorSpec(shape=shape, dtype=dtype)\n-            if (\n-                isinstance(x, tf.SparseTensor)\n-                or data_adapter_utils.is_scipy_sparse(x)\n-                or data_adapter_utils.is_jax_sparse(x)\n-            ):\n-                return tf.SparseTensorSpec(shape=shape, dtype=dtype)\n-            else:\n-                return tf.TensorSpec(shape=shape, dtype=dtype)\n-\n-        self._output_signature = tree.map_structure(\n-            get_tensor_spec, self._first_batch\n+                f\"Received: {first_batches[0]}\"\n             )\n \n     def get_numpy_iterator(self):\n@@ -85,7 +54,9 @@ class GeneratorDataAdapter(DataAdapter):\n                 yield batch\n \n         if self._output_signature is None:\n-            self._set_tf_output_signature()\n+            self._output_signature = data_adapter_utils.get_tensor_spec(\n+                self._first_batches\n+            )\n         ds = tf.data.Dataset.from_generator(\n             get_tf_iterator,\n             output_signature=self._output_signature,\n@@ -106,5 +77,9 @@ class GeneratorDataAdapter(DataAdapter):\n \n \n def peek_and_restore(generator):\n-    element = next(generator)\n-    return element, itertools.chain([element], generator)\n+    batches = list(\n+        itertools.islice(\n+            generator, data_adapter_utils.NUM_BATCHES_FOR_TENSOR_SPEC\n+        )\n+    )\n+    return batches, itertools.chain(batches, generator)\n\n@@ -101,6 +101,41 @@ class GeneratorDataAdapterTest(testing.TestCase, parameterized.TestCase):\n                 sample_order.append(by[i, 0])\n         self.assertAllClose(sample_order, list(range(34)))\n \n+    @parameterized.named_parameters(\n+        named_product(iterator_type=[\"np\", \"tf\", \"jax\", \"torch\"])\n+    )\n+    def test_with_different_shapes(self, iterator_type):\n+        def generator():\n+            yield np.ones([16, 4], \"float32\"), np.ones([16, 2], \"float32\")\n+            yield np.ones([16, 5], \"float32\"), np.ones([16, 2], \"float32\")\n+            yield np.ones([2, 6], \"float32\"), np.ones([2, 2], \"float32\")\n+\n+        adapter = generator_data_adapter.GeneratorDataAdapter(generator())\n+\n+        if iterator_type == \"np\":\n+            it = adapter.get_numpy_iterator()\n+        elif iterator_type == \"tf\":\n+            it = adapter.get_tf_dataset()\n+        elif iterator_type == \"jax\":\n+            it = adapter.get_jax_iterator()\n+        elif iterator_type == \"torch\":\n+            it = adapter.get_torch_dataloader()\n+\n+        for i, batch in enumerate(it):\n+            self.assertEqual(len(batch), 2)\n+            bx, by = batch\n+            self.assertEqual(bx.dtype, by.dtype)\n+            self.assertContainsExactSubsequence(str(bx.dtype), \"float32\")\n+            if i == 0:\n+                self.assertEqual(bx.shape, (16, 4))\n+                self.assertEqual(by.shape, (16, 2))\n+            elif i == 1:\n+                self.assertEqual(bx.shape, (16, 5))\n+                self.assertEqual(by.shape, (16, 2))\n+            else:\n+                self.assertEqual(bx.shape, (2, 6))\n+                self.assertEqual(by.shape, (2, 2))\n+\n     @parameterized.named_parameters(\n         named_product(\n             generator_type=[\"tf\", \"jax\", \"scipy\"], iterator_type=[\"tf\", \"jax\"]\n\n@@ -9,11 +9,9 @@ from contextlib import closing\n \n import numpy as np\n \n-from keras import backend\n from keras.api_export import keras_export\n from keras.trainers.data_adapters import data_adapter_utils\n from keras.trainers.data_adapters.data_adapter import DataAdapter\n-from keras.utils import tree\n \n \n @keras_export([\"keras.utils.PyDataset\", \"keras.utils.Sequence\"])\n@@ -188,28 +186,6 @@ class PyDatasetAdapter(DataAdapter):\n         self.shuffle = shuffle\n         self._output_signature = None\n \n-    def _set_tf_output_signature(self):\n-        from keras.utils.module_utils import tensorflow as tf\n-\n-        def get_tensor_spec(x):\n-            shape = x.shape\n-            if len(shape) < 1:\n-                raise ValueError(\n-                    \"The arrays returned by PyDataset.__getitem__() \"\n-                    \"must be at least rank 1. Received: \"\n-                    f\"{x} of rank {len(x.shape)}\"\n-                )\n-            shape = list(shape)\n-            shape[0] = None  # The batch size is not guaranteed to be static.\n-            dtype = backend.standardize_dtype(x.dtype)\n-            return tf.TensorSpec(shape=shape, dtype=dtype)\n-\n-        # Grab the first example\n-        batch = self.py_dataset[0]\n-        # Run checks on it and format it\n-        batch = self._standardize_batch(batch)\n-        self._output_signature = tree.map_structure(get_tensor_spec, batch)\n-\n     def _standardize_batch(self, batch):\n         if isinstance(batch, dict):\n             return batch\n@@ -287,7 +263,15 @@ class PyDatasetAdapter(DataAdapter):\n         from keras.utils.module_utils import tensorflow as tf\n \n         if self._output_signature is None:\n-            self._set_tf_output_signature()\n+            num_samples = min(\n+                data_adapter_utils.NUM_BATCHES_FOR_TENSOR_SPEC,\n+                len(self.py_dataset),\n+            )\n+            batches = [\n+                self._standardize_batch(self.py_dataset[i])\n+                for i in range(num_samples)\n+            ]\n+            self._output_signature = data_adapter_utils.get_tensor_spec(batches)\n \n         ds = tf.data.Dataset.from_generator(\n             self._get_iterator,\n\n@@ -233,3 +233,54 @@ class PyDatasetAdapterTest(testing.TestCase, parameterized.TestCase):\n             self.assertEqual(bx.dtype, by.dtype)\n             self.assertEqual(tuple(bx.shape), (4, 4))\n             self.assertEqual(tuple(by.shape), (4, 2))\n+\n+    @parameterized.named_parameters(\n+        named_product(iterator_type=[\"np\", \"tf\", \"jax\", \"torch\"])\n+    )\n+    def test_with_different_shapes(self, iterator_type):\n+\n+        class TestPyDataset(py_dataset_adapter.PyDataset):\n+            def __len__(self):\n+                return 3\n+\n+            def __getitem__(self, idx):\n+                if idx == 0:\n+                    return np.ones([16, 4], \"float32\"), np.ones(\n+                        [16, 2], \"float32\"\n+                    )\n+                if idx == 1:\n+                    return np.ones([16, 5], \"float32\"), np.ones(\n+                        [16, 2], \"float32\"\n+                    )\n+                else:\n+                    return np.ones([2, 6], \"float32\"), np.ones(\n+                        [2, 2], \"float32\"\n+                    )\n+\n+        adapter = py_dataset_adapter.PyDatasetAdapter(\n+            TestPyDataset(), shuffle=False\n+        )\n+\n+        if iterator_type == \"np\":\n+            it = adapter.get_numpy_iterator()\n+        elif iterator_type == \"tf\":\n+            it = adapter.get_tf_dataset()\n+        elif iterator_type == \"jax\":\n+            it = adapter.get_jax_iterator()\n+        elif iterator_type == \"torch\":\n+            it = adapter.get_torch_dataloader()\n+\n+        for i, batch in enumerate(it):\n+            self.assertEqual(len(batch), 2)\n+            bx, by = batch\n+            self.assertEqual(bx.dtype, by.dtype)\n+            self.assertContainsExactSubsequence(str(bx.dtype), \"float32\")\n+            if i == 0:\n+                self.assertEqual(bx.shape, (16, 4))\n+                self.assertEqual(by.shape, (16, 2))\n+            elif i == 1:\n+                self.assertEqual(bx.shape, (16, 5))\n+                self.assertEqual(by.shape, (16, 2))\n+            else:\n+                self.assertEqual(bx.shape, (2, 6))\n+                self.assertEqual(by.shape, (2, 2))\n\n@@ -1,6 +1,7 @@\n+import itertools\n+\n import numpy as np\n \n-from keras import backend\n from keras.trainers.data_adapters import data_adapter_utils\n from keras.trainers.data_adapters.data_adapter import DataAdapter\n from keras.utils import tree\n@@ -19,6 +20,7 @@ class TorchDataLoaderAdapter(DataAdapter):\n             )\n \n         self._dataloader = dataloader\n+        self._output_signature = None\n         self._batch_size = dataloader.batch_size\n         self._num_batches = None\n         self._partial_batch_size = None\n@@ -44,36 +46,24 @@ class TorchDataLoaderAdapter(DataAdapter):\n     def get_tf_dataset(self):\n         from keras.utils.module_utils import tensorflow as tf\n \n-        output_signature = self.peek_and_get_tensor_spec()\n+        if self._output_signature is None:\n+            batches = list(\n+                itertools.islice(\n+                    self._dataloader,\n+                    data_adapter_utils.NUM_BATCHES_FOR_TENSOR_SPEC,\n+                )\n+            )\n+            self._output_signature = tuple(\n+                data_adapter_utils.get_tensor_spec(batches)\n+            )\n         return tf.data.Dataset.from_generator(\n             self.get_numpy_iterator,\n-            output_signature=output_signature,\n+            output_signature=self._output_signature,\n         )\n \n     def get_torch_dataloader(self):\n         return self._dataloader\n \n-    def peek_and_get_tensor_spec(self):\n-        from keras.utils.module_utils import tensorflow as tf\n-\n-        batch_data = next(iter(self._dataloader))\n-\n-        def get_tensor_spec(x):\n-            shape = x.shape\n-            if len(shape) < 1:\n-                raise ValueError(\n-                    \"When passing a Pytorch DataLoader to a Keras model, \"\n-                    \"the arrays returned by the generator \"\n-                    \"must be at least rank 1. Received: \"\n-                    f\"{x} of rank {len(x.shape)}\"\n-                )\n-            shape = list(shape)\n-            shape[0] = None  # The batch size is not guaranteed to be static.\n-            dtype = backend.standardize_dtype(x.dtype)\n-            return tf.TensorSpec(shape=shape, dtype=dtype)\n-\n-        return tuple(tree.map_structure(get_tensor_spec, batch_data))\n-\n     @property\n     def num_batches(self):\n         return self._num_batches\n\n@@ -141,3 +141,46 @@ class TestTorchDataLoaderAdapter(testing.TestCase, parameterized.TestCase):\n             self.assertEqual(batch_count, math.ceil(10 / batch_size))\n         else:\n             self.assertEqual(batch_count, 10)\n+\n+    @parameterized.named_parameters(\n+        named_product(iterator_type=[\"np\", \"tf\", \"jax\", \"torch\"])\n+    )\n+    def test_with_different_shapes(self, iterator_type):\n+        x = (\n+            [np.ones([4], \"float32\")] * 16\n+            + [np.ones([5], \"float32\")] * 16\n+            + [np.ones([6], \"float32\")] * 2\n+        )\n+        y = np.ones((34, 2), \"float32\")\n+        ds = torch.utils.data.StackDataset(x, y)\n+        dataloader = torch.utils.data.DataLoader(ds, batch_size=16)\n+        adapter = TorchDataLoaderAdapter(dataloader)\n+\n+        self.assertEqual(adapter.num_batches, 3)\n+        self.assertEqual(adapter.batch_size, 16)\n+        self.assertEqual(adapter.has_partial_batch, True)\n+        self.assertEqual(adapter.partial_batch_size, 2)\n+\n+        if iterator_type == \"np\":\n+            it = adapter.get_numpy_iterator()\n+        elif iterator_type == \"tf\":\n+            it = adapter.get_tf_dataset()\n+        elif iterator_type == \"jax\":\n+            it = adapter.get_jax_iterator()\n+        elif iterator_type == \"torch\":\n+            it = adapter.get_torch_dataloader()\n+\n+        for i, batch in enumerate(it):\n+            self.assertEqual(len(batch), 2)\n+            bx, by = batch\n+            self.assertEqual(bx.dtype, by.dtype)\n+            self.assertContainsExactSubsequence(str(bx.dtype), \"float32\")\n+            if i == 0:\n+                self.assertEqual(bx.shape, (16, 4))\n+                self.assertEqual(by.shape, (16, 2))\n+            elif i == 1:\n+                self.assertEqual(bx.shape, (16, 5))\n+                self.assertEqual(by.shape, (16, 2))\n+            else:\n+                self.assertEqual(bx.shape, (2, 6))\n+                self.assertEqual(by.shape, (2, 2))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c1dfba32279c46775fb820aec8f974b83263593e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 30 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 4 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 31 | Churn Cumulative: 1483 | Contributors (this commit): 10 | Commits (past 90d): 12 | Contributors (cumulative): 12 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2,10 +2,11 @@ import tensorflow as tf\n \n from keras import backend\n from keras.backend.common import KerasVariable\n+from keras.backend.tensorflow.trackable import KerasAutoTrackable\n from keras.optimizers import base_optimizer\n \n \n-class TFOptimizer(base_optimizer.BaseOptimizer):\n+class TFOptimizer(KerasAutoTrackable, base_optimizer.BaseOptimizer):\n     \"\"\"A class for Tensorflow specific optimizer logic.\n \n     The major behavior change for this class is for tf.distribute.\n\n@@ -1,3 +1,5 @@\n+import os\n+\n import numpy as np\n import pytest\n \n@@ -147,3 +149,29 @@ class OptimizerTest(testing.TestCase):\n             optimizer._accumulated_gradients[0], [[1.0, 1.0], [1.0, 1.0]]\n         )\n         self.assertAllClose(optimizer.iterations, 4)\n+\n+    @pytest.mark.skipif(backend.backend() != \"tensorflow\", reason=\"Requires TF\")\n+    def test_tf_checkpointing(self):\n+        import tensorflow as tf\n+\n+        model = models.Sequential([layers.Dense(2)])\n+        optimizer = optimizers.Adam()\n+        x, y = np.random.random((1, 2)), np.random.random((1, 2))\n+        model.compile(optimizer, \"mse\")\n+        model.train_on_batch(x, y)\n+        ref_pred = model.predict(x)\n+\n+        # Both model and optimizer are Trackables\n+        checkpoint = tf.train.Checkpoint(model, optimizer=optimizer)\n+        temp_filepath = os.path.join(self.get_temp_dir(), \"tf_ckpt\")\n+        save_path = checkpoint.save(temp_filepath)\n+\n+        # Keep training the model (predictions now differ)\n+        model.train_on_batch(x, y)\n+        pred = model.predict(x)\n+        self.assertNotAllClose(pred, ref_pred, atol=1e-3)\n+\n+        # Restore the model and check prediction correctness\n+        checkpoint.restore(save_path)\n+        pred = model.predict(x)\n+        self.assertAllClose(pred, ref_pred, atol=1e-5)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#55945e7cb5e963115f8f379c00403a987119aa78", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 23 | Contributors (this commit): 1 | Commits (past 90d): 5 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -1,7 +1,7 @@\n from keras.api_export import keras_export\n \n # Unique source of truth for the version number.\n-__version__ = \"3.1.0\"\n+__version__ = \"3.2.0\"\n \n \n @keras_export(\"keras.version\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4c356306273153d5dc26fc5772b106b4f750095f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 3 | Files Changed: 3 | Hunks: 5 | Methods Changed: 5 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 16 | Churn Cumulative: 395 | Contributors (this commit): 3 | Commits (past 90d): 10 | Contributors (cumulative): 9 | DMM Complexity: 1.0\n\nDIFF:\n@@ -14,7 +14,7 @@ def get(identifier):\n     if isinstance(identifier, dict):\n         return serialization_lib.deserialize_keras_object(identifier)\n     if isinstance(identifier, str):\n-        if \"int8\" in identifier:\n+        if identifier.startswith(\"int8\"):\n             return QuantizedDTypePolicy(identifier)\n         else:\n             return FloatDTypePolicy(identifier)\n\n@@ -64,7 +64,7 @@ class DTypePolicy:\n         # For backwards compatibility\n         # TODO: We should consider deprecating this behavior\n         if cls is __class__:\n-            if \"int8\" in name:\n+            if name.startswith(\"int8\"):\n                 return QuantizedDTypePolicy(name)\n             return FloatDTypePolicy(name)\n         return super().__new__(cls)\n@@ -173,6 +173,9 @@ class FloatDTypePolicy(DTypePolicy):\n             return \"float16\", \"float32\"\n         elif name == \"mixed_bfloat16\":\n             return \"bfloat16\", \"float32\"\n+        elif name == \"uint8\":\n+            dtype = backend.standardize_dtype(name)\n+            return dtype, dtype\n         try:\n             dtype = backend.standardize_dtype(name)\n             return dtype, dtype\n@@ -250,7 +253,7 @@ def set_dtype_policy(policy):\n     \"\"\"\n     if not isinstance(policy, DTypePolicy):\n         if isinstance(policy, str):\n-            if \"int8\" in policy:\n+            if policy.startswith(\"int8\"):\n                 policy = QuantizedDTypePolicy(policy)\n             else:\n                 policy = FloatDTypePolicy(policy)\n\n@@ -103,6 +103,13 @@ class FloatDTypePolicyTest(test_case.TestCase):\n         self.assertEqual(policy.compute_dtype, \"float16\")\n         self.assertEqual(policy.name, \"mixed_float16\")\n \n+    def test_properties_uint8(self):\n+        \"\"\"Test properties for 'uint8'.\"\"\"\n+        policy = FloatDTypePolicy(\"uint8\")\n+        self.assertEqual(policy.compute_dtype, \"uint8\")\n+        self.assertEqual(policy.variable_dtype, \"uint8\")\n+        self.assertEqual(policy.name, \"uint8\")\n+\n     def test_repr(self):\n         \"\"\"Test __repr__ method.\"\"\"\n         policy = FloatDTypePolicy(\"mixed_float16\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b2ef949cceb01c53d231a4da9cbfbaa12cea981d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 18 | Lines Deleted: 4 | Files Changed: 3 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/1 | Churn Δ: 22 | Churn Cumulative: 2340 | Contributors (this commit): 12 | Commits (past 90d): 10 | Contributors (cumulative): 22 | DMM Complexity: 1.0\n\nDIFF:\n@@ -173,9 +173,6 @@ class FloatDTypePolicy(DTypePolicy):\n             return \"float16\", \"float32\"\n         elif name == \"mixed_bfloat16\":\n             return \"bfloat16\", \"float32\"\n-        elif name == \"uint8\":\n-            dtype = backend.standardize_dtype(name)\n-            return dtype, dtype\n         try:\n             dtype = backend.standardize_dtype(name)\n             return dtype, dtype\n\n@@ -242,7 +242,8 @@ class Attention(Layer):\n         return ops.convert_to_tensor(mask[0])\n \n     def compute_output_shape(self, input_shape):\n-        return input_shape[0]\n+        \"\"\"Returns shape of value tensor dim, but for query tensor length\"\"\"\n+        return (*input_shape[0][:-1], input_shape[1][-1])\n \n     def _validate_inputs(self, inputs, mask=None):\n         \"\"\"Validates arguments of the call method.\"\"\"\n\n@@ -342,3 +342,19 @@ class AttentionTest(testing.TestCase):\n             computed_mask = layer.compute_mask(inputs=dummy_inputs, mask=mask)\n             computed_mask = ops.convert_to_numpy(computed_mask)\n             self.assertTrue(np.array_equal(computed_mask, valid_mask))\n+\n+    def test_attention_compute_output_shape(self):\n+        layer = layers.Attention()\n+\n+        query = np.random.random((2, 3, 4))\n+        value = np.random.random((2, 3, 5))\n+        key = np.random.random((2, 3, 4))\n+        layer = layers.Attention()\n+        output = layer([query, value, key])\n+        self.assertAllEqual(output.shape, value.shape)\n+        self.assertAllEqual(\n+            layer.compute_output_shape(\n+                input_shape=[query.shape, value.shape, key.shape]\n+            ),\n+            output.shape,\n+        )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#060af934c65b94f4c3ec768cdec33b3504947b22", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 4 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 9 | Churn Cumulative: 19 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -21,11 +21,16 @@ def set_random_seed(seed):\n \n     ```python\n     import random\n-    import numpy as np\n-    from keras.utils.module_utils import tensorflow as tf\n     random.seed(seed)\n+\n+    import numpy as np\n     np.random.seed(seed)\n+\n+    import tensorflow as tf  # Only if TF is installed\n     tf.random.set_seed(seed)\n+\n+    import torch  # Only if the backend is 'torch'\n+    torch.manual_seed(seed)\n     ```\n \n     Note that the TensorFlow seed is set even if you're not using TensorFlow\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#42a1535ed7d3d75711a11d295f58a2dc9a59fdae", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 25 | Contributors (this commit): 1 | Commits (past 90d): 6 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -1,7 +1,7 @@\n from keras.api_export import keras_export\n \n # Unique source of truth for the version number.\n-__version__ = \"3.2.0\"\n+__version__ = \"3.1.1\"\n \n \n @keras_export(\"keras.version\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6d7ef4e268bd3c59b7943610503ea3273eb202ec", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 27 | Contributors (this commit): 1 | Commits (past 90d): 7 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -1,7 +1,7 @@\n from keras.api_export import keras_export\n \n # Unique source of truth for the version number.\n-__version__ = \"3.1.1\"\n+__version__ = \"3.2.0\"\n \n \n @keras_export(\"keras.version\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e71cafe20735d348882ee2be6351024ca1aaf56a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 10 | Churn Cumulative: 483 | Contributors (this commit): 11 | Commits (past 90d): 2 | Contributors (cumulative): 11 | DMM Complexity: 1.0\n\nDIFF:\n@@ -140,11 +140,7 @@ class UpSampling2D(Layer):\n         Returns:\n             A tensor.\n         \"\"\"\n-        if data_format == \"channels_first\":\n-            rows, cols = 2, 3\n-        elif data_format == \"channels_last\":\n-            rows, cols = 1, 2\n-        else:\n+        if data_format not in {\"channels_last\", \"channels_first\"}:\n             raise ValueError(f\"Invalid `data_format` argument: {data_format}\")\n \n         if data_format == \"channels_first\":\n@@ -163,8 +159,8 @@ class UpSampling2D(Layer):\n             # will be traced as a symbolic variable (specifically\n             # a `FakeTensor`) which does not have a `tolist()` method.\n             new_shape = (\n-                x.shape[rows] * height_factor,\n-                x.shape[cols] * width_factor,\n+                x.shape[1] * height_factor,\n+                x.shape[2] * width_factor,\n             )\n             x = ops.image.resize(x, new_shape, interpolation=interpolation)\n         if data_format == \"channels_first\":\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ed4c80203321576e15099b64b636c346da571895", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 82 | Lines Deleted: 90 | Files Changed: 38 | Hunks: 85 | Methods Changed: 8 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 172 | Churn Cumulative: 25753 | Contributors (this commit): 39 | Commits (past 90d): 69 | Contributors (cumulative): 267 | DMM Complexity: None\n\nDIFF:\n@@ -90,8 +90,6 @@ class TensorBoard(Callback):\n \n     Examples:\n \n-    Basic usage:\n-\n     ```python\n     tensorboard_callback = keras.callbacks.TensorBoard(log_dir=\"./logs\")\n     model.fit(x_train, y_train, epochs=2, callbacks=[tensorboard_callback])\n\n@@ -80,7 +80,7 @@ class Conv1D(BaseConv):\n     Raises:\n         ValueError: when both `strides > 1` and `dilation_rate > 1`.\n \n-    Examples:\n+    Example:\n \n     >>> # The inputs are 128-length vectors with 10 timesteps, and the\n     >>> # batch size is 4.\n\n@@ -81,7 +81,7 @@ class Conv1DTranspose(BaseConvTranspose):\n     - [Deconvolutional Networks](\n         https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)\n \n-    Examples:\n+    Example:\n \n     >>> x = np.random.rand(4, 10, 128)\n     >>> y = keras.layers.Conv1DTranspose(32, 3, 2, activation='relu')(x)\n\n@@ -76,7 +76,7 @@ class Conv2D(BaseConv):\n     Raises:\n         ValueError: when both `strides > 1` and `dilation_rate > 1`.\n \n-    Examples:\n+    Example:\n \n     >>> x = np.random.rand(4, 10, 10, 128)\n     >>> y = keras.layers.Conv2D(32, 3, activation='relu')(x)\n\n@@ -83,7 +83,7 @@ class Conv2DTranspose(BaseConvTranspose):\n     - [Deconvolutional Networks](\n         https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)\n \n-    Examples:\n+    Example:\n \n     >>> x = np.random.rand(4, 10, 8, 128)\n     >>> y = keras.layers.Conv2DTranspose(32, 2, 2, activation='relu')(x)\n\n@@ -82,7 +82,7 @@ class Conv3D(BaseConv):\n     Raises:\n         ValueError: when both `strides > 1` and `dilation_rate > 1`.\n \n-    Examples:\n+    Example:\n \n     >>> x = np.random.rand(4, 10, 10, 10, 128)\n     >>> y = keras.layers.Conv3D(32, 3, activation='relu')(x)\n\n@@ -88,7 +88,7 @@ class Conv3DTranspose(BaseConvTranspose):\n     - [Deconvolutional Networks](\n         https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)\n \n-    Examples:\n+    Example:\n \n     >>> x = np.random.rand(4, 10, 8, 12, 128)\n     >>> y = keras.layers.Conv3DTranspose(32, 2, 2, activation='relu')(x)\n\n@@ -87,7 +87,7 @@ class DepthwiseConv1D(BaseDepthwiseConv):\n     Raises:\n         ValueError: when both `strides > 1` and `dilation_rate > 1`.\n \n-    Examples:\n+    Example:\n \n     >>> x = np.random.rand(4, 10, 12)\n     >>> y = keras.layers.DepthwiseConv1D(3, 3, 2, activation='relu')(x)\n\n@@ -88,7 +88,7 @@ class DepthwiseConv2D(BaseDepthwiseConv):\n     Raises:\n         ValueError: when both `strides > 1` and `dilation_rate > 1`.\n \n-    Examples:\n+    Example:\n \n     >>> x = np.random.rand(4, 10, 10, 12)\n     >>> y = keras.layers.DepthwiseConv2D(3, 3, activation='relu')(x)\n\n@@ -85,7 +85,7 @@ class SeparableConv1D(BaseSeparableConv):\n         A 3D tensor representing\n         `activation(separable_conv1d(inputs, kernel) + bias)`.\n \n-    Examples:\n+    Example:\n \n     >>> x = np.random.rand(4, 10, 12)\n     >>> y = keras.layers.SeparableConv1D(3, 4, 3, 2, activation='relu')(x)\n\n@@ -86,7 +86,7 @@ class SeparableConv2D(BaseSeparableConv):\n         A 4D tensor representing\n         `activation(separable_conv2d(inputs, kernel) + bias)`.\n \n-    Examples:\n+    Example:\n \n     >>> x = np.random.rand(4, 10, 10, 12)\n     >>> y = keras.layers.SeparableConv2D(3, 4, 3, 2, activation='relu')(x)\n\n@@ -29,7 +29,7 @@ def batch_dot(x, y, axes=None):\n         `y` has been summed over.\n         (`dot_axes[1]` = 2) `output_shape` = `(100, 30)`\n \n-    Examples:\n+    Example:\n \n     >>> x_batch = np.ones(shape=(32, 20, 1))\n     >>> y_batch = np.ones(shape=(32, 30, 20))\n@@ -209,7 +209,7 @@ class Dot(Merge):\n     inputs. e.g. with `axes=(1, 2)`, the dot product of `x`, and `y`\n     will result in a tensor with shape `(2, 5, 10)`\n \n-    Examples:\n+    Example:\n \n     >>> x = np.arange(10).reshape(1, 5, 2)\n     >>> y = np.arange(10, 20).reshape(1, 2, 5)\n\n@@ -41,7 +41,7 @@ class RandomBrightness(TFDataLayer):\n         the valid range of RGB colors, and\n         rescaled based on the `value_range` if needed.\n \n-    Sample usage:\n+    Example:\n \n     ```python\n     random_bright = keras.layers.RandomBrightness(factor=0.2)\n\n@@ -10,7 +10,7 @@ class Cropping1D(Layer):\n \n     It crops along the time dimension (axis 1).\n \n-    Examples:\n+    Example:\n \n     >>> input_shape = (2, 3, 2)\n     >>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n\n@@ -11,7 +11,7 @@ class Cropping2D(Layer):\n \n     It crops along spatial dimensions, i.e. height and width.\n \n-    Examples:\n+    Example:\n \n     >>> input_shape = (2, 28, 28, 3)\n     >>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n\n@@ -9,7 +9,7 @@ from keras.utils import argument_validation\n class Cropping3D(Layer):\n     \"\"\"Cropping layer for 3D data (e.g. spatial or spatio-temporal).\n \n-    Examples:\n+    Example:\n \n     >>> input_shape = (2, 28, 28, 10, 3)\n     >>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n\n@@ -10,7 +10,7 @@ class UpSampling1D(Layer):\n \n     Repeats each temporal step `size` times along the time axis.\n \n-    Examples:\n+    Example:\n \n     >>> input_shape = (2, 2, 3)\n     >>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n\n@@ -14,7 +14,7 @@ class UpSampling2D(Layer):\n     (specified by the `interpolation` argument). Use `interpolation=nearest`\n     to repeat the rows and columns of the data.\n \n-    Examples:\n+    Example:\n \n     >>> input_shape = (2, 2, 1, 3)\n     >>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n\n@@ -9,7 +9,7 @@ from keras.utils import argument_validation\n class ZeroPadding1D(Layer):\n     \"\"\"Zero-padding layer for 1D input (e.g. temporal sequence).\n \n-    Examples:\n+    Example:\n \n     >>> input_shape = (2, 2, 3)\n     >>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n\n@@ -13,7 +13,7 @@ class ZeroPadding2D(Layer):\n     This layer can add rows and columns of zeros at the top, bottom, left and\n     right side of an image tensor.\n \n-    Examples:\n+    Example:\n \n     >>> input_shape = (1, 1, 2, 2)\n     >>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n\n@@ -10,7 +10,7 @@ from keras.utils import argument_validation\n class ZeroPadding3D(Layer):\n     \"\"\"Zero-padding layer for 3D data (spatial or spatio-temporal).\n \n-    Examples:\n+    Example:\n \n     >>> input_shape = (1, 1, 2, 2, 3)\n     >>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n\n@@ -14,7 +14,7 @@ class StackedRNNCells(Layer):\n     Args:\n       cells: List of RNN cell instances.\n \n-    Examples:\n+    Example:\n \n     ```python\n     batch_size = 3\n\n@@ -31,7 +31,7 @@ class Accuracy(reduction_metrics.MeanMetricWrapper):\n         name: (Optional) string name of the metric instance.\n         dtype: (Optional) data type of the metric result.\n \n-    Standalone usage:\n+    Examples:\n \n     >>> m = keras.metrics.Accuracy()\n     >>> m.update_state([[1], [2], [3], [4]], [[0], [2], [3], [4]])\n@@ -93,7 +93,7 @@ class BinaryAccuracy(reduction_metrics.MeanMetricWrapper):\n         threshold: (Optional) Float representing the threshold for deciding\n         whether prediction values are 1 or 0.\n \n-    Standalone usage:\n+    Example:\n \n     >>> m = keras.metrics.BinaryAccuracy()\n     >>> m.update_state([[1], [1], [0], [0]], [[0.98], [1], [0], [0.6]])\n@@ -192,7 +192,7 @@ class CategoricalAccuracy(reduction_metrics.MeanMetricWrapper):\n         name: (Optional) string name of the metric instance.\n         dtype: (Optional) data type of the metric result.\n \n-    Standalone usage:\n+    Example:\n \n     >>> m = keras.metrics.CategoricalAccuracy()\n     >>> m.update_state([[0, 0, 1], [0, 1, 0]], [[0.1, 0.9, 0.8],\n@@ -281,7 +281,7 @@ class SparseCategoricalAccuracy(reduction_metrics.MeanMetricWrapper):\n         name: (Optional) string name of the metric instance.\n         dtype: (Optional) data type of the metric result.\n \n-    Standalone usage:\n+    Example:\n \n     >>> m = keras.metrics.SparseCategoricalAccuracy()\n     >>> m.update_state([[2], [1]], [[0.1, 0.6, 0.3], [0.05, 0.95, 0]])\n@@ -352,7 +352,7 @@ class TopKCategoricalAccuracy(reduction_metrics.MeanMetricWrapper):\n         name: (Optional) string name of the metric instance.\n         dtype: (Optional) data type of the metric result.\n \n-    Standalone usage:\n+    Example:\n \n     >>> m = keras.metrics.TopKCategoricalAccuracy(k=1)\n     >>> m.update_state([[0, 0, 1], [0, 1, 0]],\n@@ -430,7 +430,7 @@ class SparseTopKCategoricalAccuracy(reduction_metrics.MeanMetricWrapper):\n         name: (Optional) string name of the metric instance.\n         dtype: (Optional) data type of the metric result.\n \n-    Standalone usage:\n+    Example:\n \n     >>> m = keras.metrics.SparseTopKCategoricalAccuracy(k=1)\n     >>> m.update_state([2, 1], [[0.1, 0.9, 0.8], [0.05, 0.95, 0]])\n\n@@ -97,7 +97,7 @@ class FalsePositives(_ConfusionMatrixConditionCount):\n         name: (Optional) string name of the metric instance.\n         dtype: (Optional) data type of the metric result.\n \n-    Standalone usage:\n+    Examples:\n \n     >>> m = keras.metrics.FalsePositives()\n     >>> m.update_state([0, 1, 0, 0], [0, 0, 1, 1])\n@@ -141,7 +141,7 @@ class FalseNegatives(_ConfusionMatrixConditionCount):\n         name: (Optional) string name of the metric instance.\n         dtype: (Optional) data type of the metric result.\n \n-    Standalone usage:\n+    Example:\n \n     >>> m = keras.metrics.FalseNegatives()\n     >>> m.update_state([0, 1, 1, 1], [0, 1, 0, 0])\n@@ -185,7 +185,7 @@ class TrueNegatives(_ConfusionMatrixConditionCount):\n         name: (Optional) string name of the metric instance.\n         dtype: (Optional) data type of the metric result.\n \n-    Standalone usage:\n+    Example:\n \n     >>> m = keras.metrics.TrueNegatives()\n     >>> m.update_state([0, 1, 0, 0], [1, 1, 0, 0])\n@@ -229,7 +229,7 @@ class TruePositives(_ConfusionMatrixConditionCount):\n         name: (Optional) string name of the metric instance.\n         dtype: (Optional) data type of the metric result.\n \n-    Standalone usage:\n+    Example:\n \n     >>> m = keras.metrics.TruePositives()\n     >>> m.update_state([0, 1, 1, 1], [1, 0, 1, 1])\n@@ -291,7 +291,7 @@ class Precision(Metric):\n         name: (Optional) string name of the metric instance.\n         dtype: (Optional) data type of the metric result.\n \n-    Standalone usage:\n+    Example:\n \n     >>> m = keras.metrics.Precision()\n     >>> m.update_state([0, 1, 1, 1], [1, 0, 1, 1])\n@@ -449,7 +449,7 @@ class Recall(Metric):\n         name: (Optional) string name of the metric instance.\n         dtype: (Optional) data type of the metric result.\n \n-    Standalone usage:\n+    Example:\n \n     >>> m = keras.metrics.Recall()\n     >>> m.update_state([0, 1, 1, 1], [1, 0, 1, 1])\n@@ -710,7 +710,7 @@ class SensitivityAtSpecificity(SensitivitySpecificityBase):\n         name: (Optional) string name of the metric instance.\n         dtype: (Optional) data type of the metric result.\n \n-    Standalone usage:\n+    Example:\n \n     >>> m = keras.metrics.SensitivityAtSpecificity(0.5)\n     >>> m.update_state([0, 0, 0, 1, 1], [0, 0.3, 0.8, 0.3, 0.8])\n@@ -814,7 +814,7 @@ class SpecificityAtSensitivity(SensitivitySpecificityBase):\n         name: (Optional) string name of the metric instance.\n         dtype: (Optional) data type of the metric result.\n \n-    Standalone usage:\n+    Example:\n \n     >>> m = keras.metrics.SpecificityAtSensitivity(0.5)\n     >>> m.update_state([0, 0, 0, 1, 1], [0, 0.3, 0.8, 0.3, 0.8])\n@@ -909,7 +909,7 @@ class PrecisionAtRecall(SensitivitySpecificityBase):\n         name: (Optional) string name of the metric instance.\n         dtype: (Optional) data type of the metric result.\n \n-    Standalone usage:\n+    Example:\n \n     >>> m = keras.metrics.PrecisionAtRecall(0.5)\n     >>> m.update_state([0, 0, 0, 1, 1], [0, 0.3, 0.8, 0.3, 0.8])\n@@ -999,7 +999,7 @@ class RecallAtPrecision(SensitivitySpecificityBase):\n         name: (Optional) string name of the metric instance.\n         dtype: (Optional) data type of the metric result.\n \n-    Standalone usage:\n+    Example:\n \n     >>> m = keras.metrics.RecallAtPrecision(0.8)\n     >>> m.update_state([0, 0, 1, 1], [0, 0.5, 0.3, 0.9])\n@@ -1155,7 +1155,7 @@ class AUC(Metric):\n         when using a keras loss, the `from_logits` constructor argument of the\n         loss should match the AUC `from_logits` constructor argument.\n \n-    Standalone usage:\n+    Example:\n \n     >>> m = keras.metrics.AUC(num_thresholds=3)\n     >>> m.update_state([0, 0, 1, 1], [0, 0.5, 0.3, 0.9])\n\n@@ -16,7 +16,7 @@ class Hinge(reduction_metrics.MeanMetricWrapper):\n         name: (Optional) string name of the metric instance.\n         dtype: (Optional) data type of the metric result.\n \n-    Standalone usage:\n+    Examples:\n \n     >>> m = keras.metrics.Hinge()\n     >>> m.update_state([[0, 1], [0, 0]], [[0.6, 0.4], [0.4, 0.6]])\n@@ -49,7 +49,7 @@ class SquaredHinge(reduction_metrics.MeanMetricWrapper):\n         name: (Optional) string name of the metric instance.\n         dtype: (Optional) data type of the metric result.\n \n-    Standalone usage:\n+    Example:\n \n     >>> m = keras.metrics.SquaredHinge()\n     >>> m.update_state([[0, 1], [0, 0]], [[0.6, 0.4], [0.4, 0.6]])\n@@ -79,7 +79,7 @@ class CategoricalHinge(reduction_metrics.MeanMetricWrapper):\n         name: (Optional) string name of the metric instance.\n         dtype: (Optional) data type of the metric result.\n \n-    Standalone usage:\n+    Example:\n     >>> m = keras.metrics.CategoricalHinge()\n     >>> m.update_state([[0, 1], [0, 0]], [[0.6, 0.4], [0.4, 0.6]])\n     >>> m.result().numpy()\n\n@@ -186,8 +186,6 @@ class IoU(_IoUBase):\n \n     Examples:\n \n-    Standalone usage:\n-\n     >>> # cm = [[1, 1],\n     >>> #        [1, 1]]\n     >>> # sum_row = [2, 2], sum_col = [2, 2], true_positives = [1, 1]\n@@ -338,9 +336,9 @@ class BinaryIoU(IoU):\n         name: (Optional) string name of the metric instance.\n         dtype: (Optional) data type of the metric result.\n \n-    Examples:\n+    Example:\n \n-    Standalone usage:\n+    Example:\n \n     >>> m = keras.metrics.BinaryIoU(target_class_ids=[0, 1], threshold=0.3)\n     >>> m.update_state([0, 1, 0, 1], [0.1, 0.2, 0.4, 0.7])\n@@ -459,9 +457,9 @@ class MeanIoU(IoU):\n             is used to determine each sample's most likely associated label.\n         axis: (Optional) The dimension containing the logits. Defaults to `-1`.\n \n-    Examples:\n+    Example:\n \n-    Standalone usage:\n+    Example:\n \n     >>> # cm = [[1, 1],\n     >>> #        [1, 1]]\n@@ -572,9 +570,9 @@ class OneHotIoU(IoU):\n             is used to determine each sample's most likely associated label.\n         axis: (Optional) The dimension containing the logits. Defaults to `-1`.\n \n-    Examples:\n+    Example:\n \n-    Standalone usage:\n+    Example:\n \n     >>> y_true = np.array([[0, 0, 1], [1, 0, 0], [0, 1, 0], [1, 0, 0]])\n     >>> y_pred = np.array([[0.2, 0.3, 0.5], [0.1, 0.2, 0.7], [0.5, 0.3, 0.1],\n@@ -688,9 +686,9 @@ class OneHotMeanIoU(MeanIoU):\n             associated label.\n         axis: (Optional) The dimension containing the logits. Defaults to `-1`.\n \n-    Examples:\n+    Example:\n \n-    Standalone usage:\n+    Example:\n \n     >>> y_true = np.array([[0, 0, 1], [1, 0, 0], [0, 1, 0], [1, 0, 0]])\n     >>> y_pred = np.array([[0.2, 0.3, 0.5], [0.1, 0.2, 0.7], [0.5, 0.3, 0.1],\n\n@@ -14,7 +14,7 @@ class Metric:\n         name: (Optional) string name of the metric instance.\n         dtype: (Optional) data type of the metric result.\n \n-    Standalone usage:\n+    Example:\n \n     ```python\n     m = SomeMetric(...)\n\n@@ -22,7 +22,7 @@ class KLDivergence(reduction_metrics.MeanMetricWrapper):\n         name: (Optional) string name of the metric instance.\n         dtype: (Optional) data type of the metric result.\n \n-    Standalone usage:\n+    Examples:\n \n     >>> m = keras.metrics.KLDivergence()\n     >>> m.update_state([[0, 1], [0, 0]], [[0.6, 0.4], [0.4, 0.6]])\n@@ -65,9 +65,9 @@ class Poisson(reduction_metrics.MeanMetricWrapper):\n         name: (Optional) string name of the metric instance.\n         dtype: (Optional) data type of the metric result.\n \n-    Examples:\n+    Example:\n \n-    Standalone usage:\n+    Example:\n \n     >>> m = keras.metrics.Poisson()\n     >>> m.update_state([[0, 1], [0, 0]], [[1, 1], [0, 0]])\n@@ -115,9 +115,9 @@ class BinaryCrossentropy(reduction_metrics.MeanMetricWrapper):\n             e.g. `label_smoothing=0.2` means that we will use\n             a value of 0.1 for label \"0\" and 0.9 for label \"1\".\n \n-    Examples:\n+    Example:\n \n-    Standalone usage:\n+    Example:\n \n     >>> m = keras.metrics.BinaryCrossentropy()\n     >>> m.update_state([[0, 1], [0, 0]], [[0.6, 0.4], [0.4, 0.6]])\n@@ -191,9 +191,9 @@ class CategoricalCrossentropy(reduction_metrics.MeanMetricWrapper):\n         axis: (Optional) Defaults to `-1`.\n             The dimension along which entropy is computed.\n \n-    Examples:\n+    Example:\n \n-    Standalone usage:\n+    Example:\n \n     >>> # EPSILON = 1e-7, y = y_true, y` = y_pred\n     >>> # y` = clip_ops.clip_by_value(output, EPSILON, 1. - EPSILON)\n@@ -278,9 +278,9 @@ class SparseCategoricalCrossentropy(reduction_metrics.MeanMetricWrapper):\n         axis: (Optional) Defaults to `-1`.\n             The dimension along which entropy is computed.\n \n-    Examples:\n+    Example:\n \n-    Standalone usage:\n+    Example:\n \n     >>> # y_true = one_hot(y_true) = [[0, 1, 0], [0, 0, 1]]\n     >>> # logits = log(y_pred)\n\n@@ -60,8 +60,6 @@ class MeanAbsoluteError(reduction_metrics.MeanMetricWrapper):\n \n     Examples:\n \n-    Standalone usage:\n-\n     >>> m = keras.metrics.MeanAbsoluteError()\n     >>> m.update_state([[0, 1], [0, 0]], [[1, 1], [0, 0]])\n     >>> m.result()\n@@ -105,9 +103,9 @@ class MeanAbsolutePercentageError(reduction_metrics.MeanMetricWrapper):\n         name: (Optional) string name of the metric instance.\n         dtype: (Optional) data type of the metric result.\n \n-    Examples:\n+    Example:\n \n-    Standalone usage:\n+    Example:\n \n     >>> m = keras.metrics.MeanAbsolutePercentageError()\n     >>> m.update_state([[0, 1], [0, 0]], [[1, 1], [0, 0]])\n@@ -152,9 +150,9 @@ class MeanSquaredLogarithmicError(reduction_metrics.MeanMetricWrapper):\n         name: (Optional) string name of the metric instance.\n         dtype: (Optional) data type of the metric result.\n \n-    Examples:\n+    Example:\n \n-    Standalone usage:\n+    Example:\n \n     >>> m = keras.metrics.MeanSquaredLogarithmicError()\n     >>> m.update_state([[0, 1], [0, 0]], [[1, 1], [0, 0]])\n@@ -199,9 +197,9 @@ class RootMeanSquaredError(reduction_metrics.Mean):\n         name: (Optional) string name of the metric instance.\n         dtype: (Optional) data type of the metric result.\n \n-    Examples:\n+    Example:\n \n-    Standalone usage:\n+    Example:\n \n     >>> m = keras.metrics.RootMeanSquaredError()\n     >>> m.update_state([[0, 1], [0, 0]], [[1, 1], [0, 0]])\n@@ -272,9 +270,9 @@ class CosineSimilarity(reduction_metrics.MeanMetricWrapper):\n         axis: (Optional) Defaults to `-1`. The dimension along which the cosine\n             similarity is computed.\n \n-    Examples:\n+    Example:\n \n-    Standalone usage:\n+    Example:\n \n     >>> # l2_norm(y_true) = [[0., 1.], [1./1.414, 1./1.414]]\n     >>> # l2_norm(y_pred) = [[1., 0.], [1./1.414, 1./1.414]]\n@@ -325,9 +323,9 @@ class LogCoshError(reduction_metrics.MeanMetricWrapper):\n         name: (Optional) string name of the metric instance.\n         dtype: (Optional) data type of the metric result.\n \n-    Examples:\n+    Example:\n \n-    Standalone usage:\n+    Example:\n \n     >>> m = keras.metrics.LogCoshError()\n     >>> m.update_state([[0, 1], [0, 0]], [[1, 1], [0, 0]])\n\n@@ -48,9 +48,7 @@ def clone_model(model, input_tensors=None, clone_function=None):\n         differently from the original model if a custom `clone_function`\n         modifies the layer.\n \n-    Examples:\n-\n-    Basic usage:\n+    Example:\n \n     ```python\n     # Create a test Sequential model.\n\n@@ -563,7 +563,7 @@ class Model(Trainer, Layer):\n def model_from_json(json_string, custom_objects=None):\n     \"\"\"Parses a JSON model configuration string and returns a model instance.\n \n-    Usage:\n+    Example:\n \n     >>> model = keras.Sequential([\n     ...     keras.layers.Dense(5, input_shape=(3,)),\n\n@@ -35,7 +35,7 @@ class RMSprop(optimizer.Optimizer):\n             expensive in terms of computation and memory. Defaults to `False`.\n         {{base_optimizer_keyword_args}}\n \n-    Usage:\n+    Example:\n \n     >>> opt = keras.optimizers.RMSprop(learning_rate=0.1)\n     >>> var1 = keras.backend.Variable(10.0)\n\n@@ -782,7 +782,7 @@ class CosineDecayRestarts(LearningRateSchedule):\n     restart is performed. Each new warm restart runs for `t_mul` times more\n     steps and with `m_mul` times initial learning rate as the new learning rate.\n \n-    Example usage:\n+    Example:\n     ```python\n     first_decay_steps = 1000\n     lr_decayed_fn = (\n\n@@ -16,7 +16,7 @@ def unpack_x_y_sample_weight(data):\n     This utility makes it easy to support data of the form `(x,)`,\n     `(x, y)`, or `(x, y, sample_weight)`.\n \n-    Standalone usage:\n+    Example:\n \n     >>> features_batch = ops.ones((10, 5))\n     >>> labels_batch = ops.zeros((10, 5))\n@@ -57,7 +57,7 @@ def pack_x_y_sample_weight(x, y=None, sample_weight=None):\n     This is a convenience utility for packing data into the tuple formats\n     that `Model.fit()` uses.\n \n-    Standalone usage:\n+    Example:\n \n     >>> x = ops.ones((10, 1))\n     >>> data = pack_x_y_sample_weight(x)\n\n@@ -43,7 +43,7 @@ class TFGraphScope:\n class DynamicBackend:\n     \"\"\"A class that can be used to switch from one backend to another.\n \n-    Usage:\n+    Example:\n \n     ```python\n     backend = DynamicBackend(\"tensorflow\")\n\n@@ -41,7 +41,7 @@ if pil_image_resampling is not None:\n def array_to_img(x, data_format=None, scale=True, dtype=None):\n     \"\"\"Converts a 3D NumPy array to a PIL Image instance.\n \n-    Usage:\n+    Example:\n \n     ```python\n     from PIL import Image\n@@ -116,7 +116,7 @@ def array_to_img(x, data_format=None, scale=True, dtype=None):\n def img_to_array(img, data_format=None, dtype=None):\n     \"\"\"Converts a PIL Image instance to a NumPy array.\n \n-    Usage:\n+    Example:\n \n     ```python\n     from PIL import Image\n@@ -194,7 +194,7 @@ def load_img(\n ):\n     \"\"\"Loads an image into PIL format.\n \n-    Usage:\n+    Example:\n \n     ```python\n     image = keras.utils.load_img(image_path)\n\n@@ -23,7 +23,7 @@ class TorchModuleWrapper(Layer):\n             it once).\n         name: The name of the layer (string).\n \n-    Examples:\n+    Example:\n \n     Here's an example of how the `TorchModuleWrapper` can be used with vanilla\n     PyTorch modules.\n\n@@ -41,7 +41,7 @@ class Tracker:\n     still get tracked. This is done by wrapping these\n     collections into an equivalent, tracking-aware object.\n \n-    Usage:\n+    Example:\n \n     ```python\n     def __init__(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
