{"custom_id": "keras#6557961e7f222050b2caac21ba308e6ecc94dcda", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 525 | Lines Deleted: 0 | Files Changed: 5 | Hunks: 7 | Methods Changed: 8 | Complexity Δ (Sum/Max): 20/11 | Churn Δ: 525 | Churn Cumulative: 647 | Contributors (this commit): 5 | Commits (past 90d): 5 | Contributors (cumulative): 14 | DMM Complexity: 0.9108910891089109\n\nDIFF:\n@@ -12,4 +12,7 @@ from keras.src.quantizers.quantizers import Quantizer\n from keras.src.quantizers.quantizers import abs_max_quantize\n from keras.src.quantizers.quantizers import compute_float8_amax_history\n from keras.src.quantizers.quantizers import compute_float8_scale\n+from keras.src.quantizers.quantizers import (\n+    fake_quant_with_min_max_vars as fake_quant_with_min_max_vars_per_channel,\n+)\n from keras.src.quantizers.quantizers import quantize_and_dequantize\n\n@@ -12,4 +12,7 @@ from keras.src.quantizers.quantizers import Quantizer\n from keras.src.quantizers.quantizers import abs_max_quantize\n from keras.src.quantizers.quantizers import compute_float8_amax_history\n from keras.src.quantizers.quantizers import compute_float8_scale\n+from keras.src.quantizers.quantizers import (\n+    fake_quant_with_min_max_vars as fake_quant_with_min_max_vars_per_channel,\n+)\n from keras.src.quantizers.quantizers import quantize_and_dequantize\n\n@@ -6,6 +6,7 @@ from keras.src.quantizers.quantizers import Quantizer\n from keras.src.quantizers.quantizers import abs_max_quantize\n from keras.src.quantizers.quantizers import compute_float8_amax_history\n from keras.src.quantizers.quantizers import compute_float8_scale\n+from keras.src.quantizers.quantizers import fake_quant_with_min_max_vars\n from keras.src.quantizers.quantizers import quantize_and_dequantize\n from keras.src.saving import serialization_lib\n from keras.src.utils.naming import to_snake_case\n\n@@ -4,6 +4,7 @@ import numpy as np\n from keras.src import backend\n from keras.src import ops\n from keras.src.api_export import keras_export\n+from keras.src.backend.common.backend_utils import canonicalize_axis\n from keras.src.backend.common.backend_utils import standardize_axis_for_numpy\n \n \"\"\"Int8-related classes and methods\"\"\"\n@@ -127,6 +128,142 @@ class AbsMaxQuantizer(Quantizer):\n         }\n \n \n+def adjust_and_nudge(min_range, max_range, num_bits, narrow_range):\n+    \"\"\"Adjusts and nudges the quantization range for better accuracy.\"\"\"\n+\n+    quant_max = ops.cast(ops.subtract(ops.power(2, num_bits), 1.0), \"float32\")\n+\n+    quant_min = ops.cast(0.0 if not narrow_range else 1.0, \"float32\")\n+\n+    # Calculate the scale and ensure it's positive\n+    scale = ops.divide(\n+        ops.subtract(max_range, min_range), ops.subtract(quant_max, quant_min)\n+    )\n+\n+    inv_scale = ops.reciprocal(scale)\n+\n+    # Calculate the zero point from the min range\n+    zero_point_from_min = quant_min - ops.divide(min_range, scale)\n+\n+    # Ensure zero point is within valid range [0, quant_max]\n+    zero_point = ops.clip(zero_point_from_min, quant_min, quant_max)\n+\n+    # Nudge zero point if it's very close to an integer\n+    nudged_zero_point = ops.round(zero_point)\n+\n+    # Calculate nudged limits\n+    nudged_min = ops.multiply(ops.subtract(quant_min, nudged_zero_point), scale)\n+    nudged_max = ops.multiply(ops.subtract(quant_max, nudged_zero_point), scale)\n+\n+    return nudged_min, nudged_max, scale, inv_scale\n+\n+\n+@keras_export(\"keras.quantizers.fake_quant_with_min_max_vars_per_channel\")\n+def fake_quant_with_min_max_vars(\n+    inputs,\n+    min_vals,\n+    max_vals,\n+    num_bits,\n+    narrow_range=False,\n+    axis=None,\n+):\n+    \"\"\"\n+    Perform per-tensor or per-channel fake quantization.\n+\n+    `[min_vals, max_vals]` define the clamping range for the `inputs`.\n+\n+    The `inputs` are quantized into the quantization range:\n+    - `[0, 2^num_bits - 1]` when `narrow_range=False`\n+    - `[1, 2^num_bits - 1]` when `narrow_range=True`\n+\n+    After quantization, the values are dequantized and output as floats within\n+    the `[min_vals, max_vals]` interval.\n+\n+    This operation supports gradient computation, allowing `min_vals` and\n+    `max_vals` to be trained.\n+\n+    Args:\n+        inputs: Input tensor of float dtype.\n+        min_vals: A global minimum scalar or a per-channel minimum tensor.\n+        max_vals: A global maximum scalar or a per-channel maximum tensor.\n+        num_bits: Quantization bit width (e.g., `8` for int8).\n+        narrow_range: Whether to use narrow quantization range.\n+        axis: Axis along which to perform per-channel quantization. If `None`,\n+              per-tensor quantization is performed. Defaults to `None`.\n+\n+\n+    Returns:\n+        Fake-quantized tensor\n+    \"\"\"\n+    inputs = ops.convert_to_tensor(inputs)\n+    min_vals = ops.convert_to_tensor(min_vals)\n+    max_vals = ops.convert_to_tensor(max_vals)\n+\n+    if axis is not None:\n+        axis = canonicalize_axis(axis, inputs.ndim)\n+\n+    @ops.custom_gradient\n+    def _fake_quant_with_min_max_vars_per_channel(x, min_val, max_val):\n+        # Calculate quantization parameters for all channels at once\n+        nudged_min, nudged_max, scale, inv_scale = adjust_and_nudge(\n+            min_val, max_val, num_bits, narrow_range\n+        )\n+\n+        quant_zero = ops.floor(\n+            ops.add(ops.multiply(-nudged_min, inv_scale), 0.5)\n+        )\n+        x_clamped = ops.clip(x, nudged_min, nudged_max)\n+        x_clamped_shifted = ops.subtract(x_clamped, nudged_min)\n+        result = ops.multiply(\n+            ops.floor(\n+                ops.add(\n+                    ops.subtract(\n+                        ops.multiply(x_clamped_shifted, inv_scale), quant_zero\n+                    ),\n+                    0.5,\n+                )\n+            ),\n+            scale,\n+        )\n+\n+        # Create gradient mask for all channels\n+        masks = ops.cast(\n+            (x >= nudged_min) & (x <= nudged_max),\n+            dtype=\"float32\",\n+        )\n+\n+        def grad(*args, upstream=None):\n+            if upstream is None:\n+                (upstream,) = args\n+\n+            # Gradient for x\n+            dx = ops.multiply(upstream, masks)\n+            axes = [i for i in range(len(dx.shape)) if i != axis]\n+            # Gradient for min_val\n+            # When x is clipped to min, the gradient flows to min_val\n+            min_mask = ops.cast(x <= nudged_min, dtype=\"float32\")\n+            grad_min = ops.multiply(upstream, min_mask)\n+            if axis is not None:\n+                grad_min = ops.sum(grad_min, axis=axes)\n+            else:\n+                grad_min = ops.sum(grad_min)\n+\n+            # Gradient for max_val\n+            # When x is clipped to max, the gradient flows to max_val\n+            max_mask = ops.cast(x >= nudged_max, dtype=\"float32\")\n+            grad_max = ops.multiply(upstream, max_mask)\n+            if axis is not None:\n+                grad_max = ops.sum(grad_max, axis=axes)\n+            else:\n+                grad_max = ops.sum(grad_max)\n+\n+            return dx, grad_min, grad_max\n+\n+        return result, grad\n+\n+    return _fake_quant_with_min_max_vars_per_channel(inputs, min_vals, max_vals)\n+\n+\n \"\"\"Float8-related methods\"\"\"\n \n \n\n@@ -1,3 +1,6 @@\n+from absl.testing import parameterized\n+\n+from keras.src import backend\n from keras.src import ops\n from keras.src import quantizers\n from keras.src import random\n@@ -100,3 +103,381 @@ class QuantizersTest(testing.TestCase):\n         )\n         # A loose assertion due to an expected quantization error\n         self.assertAllClose(qdq_values, values, atol=5e-1)\n+\n+    @parameterized.named_parameters(\n+        [\n+            {\n+                \"testcase_name\": \"wide_8bits_input_mins_0.0_input_maxs_255.0\",\n+                \"narrow_range\": False,\n+                \"input_mins\": [0.0],\n+                \"input_maxs\": [255.0],\n+                \"num_bits\": 8,\n+                \"expected_nudged_input_mins\": [0.0],\n+                \"expected_nudged_input_maxs\": [255.0],\n+                \"expected_steps\": [1.0],\n+                \"axis\": None,\n+            },\n+            {\n+                \"testcase_name\": \"wide_8bits_input_mins_0.5_input_maxs_128.0\",\n+                \"narrow_range\": False,\n+                \"input_mins\": [0.5],\n+                \"input_maxs\": [128.0],\n+                \"num_bits\": 8,\n+                \"expected_nudged_input_mins\": [0.0],\n+                \"expected_nudged_input_maxs\": [127.5],\n+                \"expected_steps\": [0.5],\n+                \"axis\": None,\n+            },\n+            {\n+                \"testcase_name\": \"wide_8bits_input_mins_-128.0_input_maxs_-0.5\",\n+                \"narrow_range\": False,\n+                \"input_mins\": [-128.0],\n+                \"input_maxs\": [-0.5],\n+                \"num_bits\": 8,\n+                \"expected_nudged_input_mins\": [-127.5],\n+                \"expected_nudged_input_maxs\": [0.0],\n+                \"expected_steps\": [0.5],\n+                \"axis\": None,\n+            },\n+            {\n+                \"testcase_name\": \"wide_8bits_input_mins_-0.1_input_maxs_127.4\",\n+                \"narrow_range\": False,\n+                \"input_mins\": [-0.1],\n+                \"input_maxs\": [127.4],\n+                \"num_bits\": 8,\n+                \"expected_nudged_input_mins\": [0.0],\n+                \"expected_nudged_input_maxs\": [127.5],\n+                \"expected_steps\": [0.5],\n+                \"axis\": None,\n+            },\n+            {\n+                \"testcase_name\": \"narrow_8bits_input_mins_0.0_input_maxs_254.0\",\n+                \"narrow_range\": True,\n+                \"input_mins\": [0.0],\n+                \"input_maxs\": [254.0],\n+                \"num_bits\": 8,\n+                \"expected_nudged_input_mins\": [0.0],\n+                \"expected_nudged_input_maxs\": [254.0],\n+                \"expected_steps\": [1.0],\n+                \"axis\": None,\n+            },\n+            {\n+                \"testcase_name\": \"narrow_8bits_input_mins_0.1_input_maxs_127.1\",\n+                \"narrow_range\": True,\n+                \"input_mins\": [0.1],\n+                \"input_maxs\": [127.1],\n+                \"num_bits\": 8,\n+                \"expected_nudged_input_mins\": [0.0],\n+                \"expected_nudged_input_maxs\": [127.0],\n+                \"expected_steps\": [0.5],\n+                \"axis\": None,\n+            },\n+            {\n+                \"testcase_name\": (\n+                    \"narrow_8bits_input_mins_-127.1_input_maxs_-0.1\"\n+                ),\n+                \"narrow_range\": True,\n+                \"input_mins\": [-127.1],\n+                \"input_maxs\": [-0.1],\n+                \"num_bits\": 8,\n+                \"expected_nudged_input_mins\": [-127.0],\n+                \"expected_nudged_input_maxs\": [0.0],\n+                \"expected_steps\": [0.5],\n+                \"axis\": None,\n+            },\n+            {\n+                \"testcase_name\": (\n+                    \"narrow_8bits_input_mins_-0.1_input_maxs_126.9\"\n+                ),\n+                \"narrow_range\": True,\n+                \"input_mins\": [-0.1],\n+                \"input_maxs\": [126.9],\n+                \"num_bits\": 8,\n+                \"expected_nudged_input_mins\": [0.0],\n+                \"expected_nudged_input_maxs\": [127.0],\n+                \"expected_steps\": [0.5],\n+                \"axis\": None,\n+            },\n+            {\n+                \"testcase_name\": \"wide_7bits_input_mins_0.0_input_maxs_127.0\",\n+                \"narrow_range\": False,\n+                \"input_mins\": [0.0],\n+                \"input_maxs\": [127.0],\n+                \"num_bits\": 7,\n+                \"expected_nudged_input_mins\": [0.0],\n+                \"expected_nudged_input_maxs\": [127.0],\n+                \"expected_steps\": [1.0],\n+                \"axis\": None,\n+            },\n+            {\n+                \"testcase_name\": \"wide_7bits_input_mins_0.5_input_maxs_64.0\",\n+                \"narrow_range\": False,\n+                \"input_mins\": [0.5],\n+                \"input_maxs\": [64.0],\n+                \"num_bits\": 7,\n+                \"expected_nudged_input_mins\": [0.0],\n+                \"expected_nudged_input_maxs\": [63.5],\n+                \"expected_steps\": [0.5],\n+                \"axis\": None,\n+            },\n+            {\n+                \"testcase_name\": \"wide_7bits_input_mins_-64.0_input_maxs_-0.5\",\n+                \"narrow_range\": False,\n+                \"input_mins\": [-64.0],\n+                \"input_maxs\": [-0.5],\n+                \"num_bits\": 7,\n+                \"expected_nudged_input_mins\": [-63.5],\n+                \"expected_nudged_input_maxs\": [0.0],\n+                \"expected_steps\": [0.5],\n+                \"axis\": None,\n+            },\n+            {\n+                \"testcase_name\": \"wide_7bits_input_mins_-0.1_input_maxs_63.4\",\n+                \"narrow_range\": False,\n+                \"input_mins\": [-0.1],\n+                \"input_maxs\": [63.4],\n+                \"num_bits\": 7,\n+                \"expected_nudged_input_mins\": [0.0],\n+                \"expected_nudged_input_maxs\": [63.5],\n+                \"expected_steps\": [0.5],\n+                \"axis\": None,\n+            },\n+            {\n+                \"testcase_name\": \"narrow_7bits_input_mins_0.0_input_maxs_126.0\",\n+                \"narrow_range\": True,\n+                \"input_mins\": [0.0],\n+                \"input_maxs\": [126.0],\n+                \"num_bits\": 7,\n+                \"expected_nudged_input_mins\": [0.0],\n+                \"expected_nudged_input_maxs\": [126.0],\n+                \"expected_steps\": [1.0],\n+                \"axis\": None,\n+            },\n+            {\n+                \"testcase_name\": \"narrow_7bits_input_mins_0.1_input_maxs_63.1\",\n+                \"narrow_range\": True,\n+                \"input_mins\": [0.1],\n+                \"input_maxs\": [63.1],\n+                \"num_bits\": 7,\n+                \"expected_nudged_input_mins\": [0.0],\n+                \"expected_nudged_input_maxs\": [63.0],\n+                \"expected_steps\": [0.5],\n+                \"axis\": None,\n+            },\n+            {\n+                \"testcase_name\": (\n+                    \"narrow_7bits_input_mins_-63.1_input_maxs_-0.1\"\n+                ),\n+                \"narrow_range\": True,\n+                \"input_mins\": [-63.1],\n+                \"input_maxs\": [-0.1],\n+                \"num_bits\": 7,\n+                \"expected_nudged_input_mins\": [-63.0],\n+                \"expected_nudged_input_maxs\": [0.0],\n+                \"expected_steps\": [0.5],\n+                \"axis\": None,\n+            },\n+            {\n+                \"testcase_name\": \"narrow_7bits_input_mins_-0.1_input_maxs_62.9\",\n+                \"narrow_range\": True,\n+                \"input_mins\": [-0.1],\n+                \"input_maxs\": [62.9],\n+                \"num_bits\": 7,\n+                \"expected_nudged_input_mins\": [0.0],\n+                \"expected_nudged_input_maxs\": [63.0],\n+                \"expected_steps\": [0.5],\n+                \"axis\": None,\n+            },\n+            {\n+                \"testcase_name\": \"wide_8bits_multi_channel\",\n+                \"narrow_range\": False,\n+                \"input_mins\": [0.0, 0.5, -128.0, -0.1],\n+                \"input_maxs\": [255.0, 128.0, -0.5, 127.4],\n+                \"num_bits\": 8,\n+                \"expected_nudged_input_mins\": [0.0, 0.0, -127.5, 0.0],\n+                \"expected_nudged_input_maxs\": [255.0, 127.5, 0.0, 127.5],\n+                \"expected_steps\": [1.0, 0.5, 0.5, 0.5],\n+                \"axis\": 1,\n+            },\n+            {\n+                \"testcase_name\": \"narrow_8bits_multi_channel\",\n+                \"narrow_range\": True,\n+                \"input_mins\": [0.0, 0.1, -127.1, -0.1],\n+                \"input_maxs\": [254.0, 127.1, -0.1, 126.9],\n+                \"num_bits\": 8,\n+                \"expected_nudged_input_mins\": [0.0, 0.0, -127.0, 0.0],\n+                \"expected_nudged_input_maxs\": [254.0, 127.0, 0.0, 127.0],\n+                \"expected_steps\": [1.0, 0.5, 0.5, 0.5],\n+                \"axis\": 1,\n+            },\n+            {\n+                \"testcase_name\": \"wide_7bits_multi_channel\",\n+                \"narrow_range\": False,\n+                \"input_mins\": [0.0, 0.5, -64.0, -0.1],\n+                \"input_maxs\": [127.0, 64.0, -0.5, 63.4],\n+                \"num_bits\": 7,\n+                \"expected_nudged_input_mins\": [0.0, 0.0, -63.5, 0.0],\n+                \"expected_nudged_input_maxs\": [127.0, 63.5, 0.0, 63.5],\n+                \"expected_steps\": [1.0, 0.5, 0.5, 0.5],\n+                \"axis\": 1,\n+            },\n+            {\n+                \"testcase_name\": \"narrow_7bits_multi_channel\",\n+                \"narrow_range\": True,\n+                \"input_mins\": [0.0, 0.1, -63.1, -0.1],\n+                \"input_maxs\": [126.0, 63.1, -0.1, 62.9],\n+                \"num_bits\": 7,\n+                \"expected_nudged_input_mins\": [0.0, 0.0, -63.0, 0.0],\n+                \"expected_nudged_input_maxs\": [126.0, 63.0, 0.0, 63.0],\n+                \"expected_steps\": [1.0, 0.5, 0.5, 0.5],\n+                \"axis\": 1,\n+            },\n+        ]\n+    )\n+    def test_op(\n+        self,\n+        input_mins,\n+        input_maxs,\n+        num_bits,\n+        narrow_range,\n+        axis,\n+        expected_nudged_input_mins,\n+        expected_nudged_input_maxs,\n+        expected_steps,\n+    ):\n+        num_channels = len(input_mins)\n+        inputs_list = []\n+        expected_list = []\n+        initial_gradients_list = []\n+        expected_backprops_wrt_input_list = []\n+        for i in range(num_channels):\n+            expected_nudged_input_min = expected_nudged_input_mins[i]\n+            expected_nudged_input_max = expected_nudged_input_maxs[i]\n+            expected_step = expected_steps[i]\n+\n+            inputs_list.append(\n+                [\n+                    expected_nudged_input_min - expected_step,\n+                    expected_nudged_input_min - 0.01,\n+                    expected_nudged_input_min,\n+                    expected_nudged_input_min + 0.01,\n+                    expected_nudged_input_min + expected_step - 0.01,\n+                    expected_nudged_input_min + expected_step,\n+                    expected_nudged_input_min + expected_step + 0.01,\n+                    expected_nudged_input_max - 0.01,\n+                    expected_nudged_input_max,\n+                    expected_nudged_input_max + 0.01,\n+                    expected_nudged_input_max + expected_step,\n+                ]\n+            )\n+            expected_list.append(\n+                [\n+                    expected_nudged_input_min,\n+                    expected_nudged_input_min,\n+                    expected_nudged_input_min,\n+                    expected_nudged_input_min,\n+                    expected_nudged_input_min + expected_step,\n+                    expected_nudged_input_min + expected_step,\n+                    expected_nudged_input_min + expected_step,\n+                    expected_nudged_input_max,\n+                    expected_nudged_input_max,\n+                    expected_nudged_input_max,\n+                    expected_nudged_input_max,\n+                ]\n+            )\n+            initial_gradients_list.append(\n+                list(range(1, len(inputs_list[-1]) + 1))\n+            )\n+            expected_backprops_wrt_input_list.append(\n+                [0.0, 0.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 0.0, 0.0]\n+            )\n+        inputs = ops.transpose(ops.array(inputs_list, dtype=\"float32\"))\n+        expected = ops.transpose(ops.array(expected_list, dtype=\"float32\"))\n+        expected_backprops_wrt_input = ops.transpose(\n+            ops.array(expected_backprops_wrt_input_list, dtype=\"float32\")\n+        )\n+        input_min = ops.array(input_mins, dtype=\"float32\")\n+        input_max = ops.array(input_maxs, dtype=\"float32\")\n+        initial_gradients = ops.transpose(\n+            ops.array(initial_gradients_list, dtype=\"float32\")\n+        )\n+        if backend.backend() == \"tensorflow\":\n+            import tensorflow as tf\n+\n+            @tf.function(jit_compile=True)\n+            def test_op(\n+                inputs, input_mins, input_maxs, num_bits, narrow_range, axis\n+            ):\n+                with tf.GradientTape() as tape:\n+                    tape.watch(inputs)\n+                    result = quantizers.fake_quant_with_min_max_vars(\n+                        inputs,\n+                        input_mins,\n+                        input_maxs,\n+                        num_bits,\n+                        narrow_range,\n+                        axis,\n+                    )\n+                return initial_gradients * tape.gradient(result, inputs)\n+\n+            gradients = test_op(\n+                inputs, input_mins, input_maxs, num_bits, narrow_range, axis\n+            )\n+            # test gradients\n+            self.assertAllClose(gradients, expected_backprops_wrt_input)\n+\n+        if backend.backend() == \"torch\":\n+            import torch\n+\n+            def test_op(inputs, input_mins, input_maxs, num_bits, narrow_range):\n+                # Create tensor and enable gradient tracking\n+                inputs = torch.tensor(\n+                    inputs, dtype=torch.float32, requires_grad=True\n+                )\n+\n+                # Apply the quantization operation\n+                result = quantizers.fake_quant_with_min_max_vars(\n+                    inputs, input_mins, input_maxs, num_bits, narrow_range\n+                )\n+\n+                # Compute gradients\n+                result.backward(torch.ones_like(result))\n+\n+                return initial_gradients * inputs.grad\n+\n+            gradients = test_op(\n+                inputs, input_min, input_max, num_bits, narrow_range\n+            )\n+            # test gradients\n+            self.assertAllClose(gradients, expected_backprops_wrt_input)\n+\n+        if backend.backend() == \"jax\":\n+            import jax\n+\n+            def test_op(inputs, input_mins, input_maxs, num_bits, narrow_range):\n+                # Define the function to compute gradients for\n+                def quantize_fn(x):\n+                    return quantizers.fake_quant_with_min_max_vars(\n+                        x, input_mins, input_maxs, num_bits, narrow_range\n+                    )\n+\n+                _, f_vjp = jax.vjp(quantize_fn, inputs)\n+                # NOTE:python 3.10 input_gradients = f_vjp.args[0].args[0][0] !\n+                input_gradients = f_vjp.args[0].args[0][1]\n+\n+                return ops.multiply(initial_gradients, input_gradients)\n+\n+            gradients = test_op(\n+                inputs, input_min, input_max, num_bits, narrow_range\n+            )\n+            # test gradients\n+            self.assertAllClose(gradients, expected_backprops_wrt_input)\n+        outputs = quantizers.fake_quant_with_min_max_vars(\n+            inputs,\n+            input_min,\n+            input_max,\n+            num_bits=num_bits,\n+            narrow_range=narrow_range,\n+            axis=axis,\n+        )\n+        self.assertAllClose(outputs, expected)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0454f06d09516209304b2080f06e524510376cf4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 394 | Lines Deleted: 0 | Files Changed: 5 | Hunks: 5 | Methods Changed: 14 | Complexity Δ (Sum/Max): 30/23 | Churn Δ: 394 | Churn Cumulative: 1259 | Contributors (this commit): 7 | Commits (past 90d): 44 | Contributors (cumulative): 23 | DMM Complexity: 0.8257575757575758\n\nDIFF:\n@@ -139,6 +139,7 @@ from keras.src.layers.preprocessing.category_encoding import CategoryEncoding\n from keras.src.layers.preprocessing.discretization import Discretization\n from keras.src.layers.preprocessing.hashed_crossing import HashedCrossing\n from keras.src.layers.preprocessing.hashing import Hashing\n+from keras.src.layers.preprocessing.image_preprocessing.aug_mix import AugMix\n from keras.src.layers.preprocessing.image_preprocessing.auto_contrast import (\n     AutoContrast,\n )\n\n@@ -139,6 +139,7 @@ from keras.src.layers.preprocessing.category_encoding import CategoryEncoding\n from keras.src.layers.preprocessing.discretization import Discretization\n from keras.src.layers.preprocessing.hashed_crossing import HashedCrossing\n from keras.src.layers.preprocessing.hashing import Hashing\n+from keras.src.layers.preprocessing.image_preprocessing.aug_mix import AugMix\n from keras.src.layers.preprocessing.image_preprocessing.auto_contrast import (\n     AutoContrast,\n )\n\n@@ -83,6 +83,7 @@ from keras.src.layers.preprocessing.category_encoding import CategoryEncoding\n from keras.src.layers.preprocessing.discretization import Discretization\n from keras.src.layers.preprocessing.hashed_crossing import HashedCrossing\n from keras.src.layers.preprocessing.hashing import Hashing\n+from keras.src.layers.preprocessing.image_preprocessing.aug_mix import AugMix\n from keras.src.layers.preprocessing.image_preprocessing.auto_contrast import (\n     AutoContrast,\n )\n\n@@ -0,0 +1,325 @@\n+import random as py_random\n+\n+import keras.src.layers as layers\n+from keras.src.api_export import keras_export\n+from keras.src.layers.preprocessing.image_preprocessing.base_image_preprocessing_layer import (  # noqa: E501\n+    BaseImagePreprocessingLayer,\n+)\n+from keras.src.random import SeedGenerator\n+from keras.src.utils import backend_utils\n+\n+AUGMENT_LAYERS_ALL = [\n+    \"random_shear\",\n+    \"random_translation\",\n+    \"random_rotation\",\n+    \"random_posterization\",\n+    \"solarization\",\n+    \"auto_contrast\",\n+    \"equalization\",\n+    \"random_brightness\",\n+    \"random_color_degeneration\",\n+    \"random_contrast\",\n+    \"random_sharpness\",\n+]\n+\n+AUGMENT_LAYERS = [\n+    \"random_shear\",\n+    \"random_translation\",\n+    \"random_rotation\",\n+    \"random_posterization\",\n+    \"solarization\",\n+    \"auto_contrast\",\n+    \"equalization\",\n+]\n+\n+\n+@keras_export(\"keras.layers.AugMix\")\n+class AugMix(BaseImagePreprocessingLayer):\n+    \"\"\"Performs the AugMix data augmentation technique.\n+\n+    AugMix aims to produce images with variety while preserving the image\n+    semantics and local statistics. During the augmentation process,\n+    the same augmentation is applied across all images in the batch\n+    in num_chains different ways, with each chain consisting of\n+    chain_depth augmentations.\n+\n+    Args:\n+        value_range: the range of values the incoming images will have.\n+            Represented as a two number tuple written (low, high).\n+            This is typically either `(0, 1)` or `(0, 255)` depending\n+            on how your preprocessing pipeline is set up.\n+        num_chains: an integer representing the number of different chains to\n+            be mixed, defaults to 3.\n+        chain_depth: an integer representing the maximum number of\n+            transformations to be applied in each chain. The actual number\n+            of transformations in each chain will be sampled randomly\n+            from the range `[0, `chain_depth`]`. Defaults to 3.\n+        factor: The strength of the augmentation as a normalized value\n+            between 0 and 1. Default is 0.3.\n+        alpha: a float value used as the probability coefficients for the\n+            Beta and Dirichlet distributions, defaults to 1.0.\n+        all_ops: Use all operations (including random_brightness,\n+            random_color_degeneration, random_contrast and random_sharpness).\n+            Default is True.\n+        interpolation: The interpolation method to use for resizing operations.\n+            Options include `\"nearest\"`, `\"bilinear\"`. Default is `\"bilinear\"`.\n+        seed: Integer. Used to create a random seed.\n+\n+    References:\n+        - [AugMix paper](https://arxiv.org/pdf/1912.02781)\n+        - [Official Code](https://github.com/google-research/augmix)\n+    \"\"\"\n+\n+    _USE_BASE_FACTOR = False\n+    _FACTOR_BOUNDS = (0, 1)\n+\n+    def __init__(\n+        self,\n+        value_range=(0, 255),\n+        num_chains=3,\n+        chain_depth=3,\n+        factor=0.3,\n+        alpha=1.0,\n+        all_ops=True,\n+        interpolation=\"bilinear\",\n+        seed=None,\n+        data_format=None,\n+        **kwargs,\n+    ):\n+        super().__init__(data_format=data_format, **kwargs)\n+\n+        self.value_range = value_range\n+        self.num_chains = num_chains\n+        self.chain_depth = chain_depth\n+        self._set_factor(factor)\n+        self.alpha = alpha\n+        self.all_ops = all_ops\n+        self.interpolation = interpolation\n+        self.seed = seed\n+        self.generator = SeedGenerator(seed)\n+\n+        if self.all_ops:\n+            self._augment_layers = AUGMENT_LAYERS_ALL\n+        else:\n+            self._augment_layers = AUGMENT_LAYERS\n+\n+        self.random_shear = layers.RandomShear(\n+            x_factor=self.factor,\n+            y_factor=self.factor,\n+            interpolation=interpolation,\n+            seed=self.seed,\n+            data_format=data_format,\n+            **kwargs,\n+        )\n+\n+        self.random_translation = layers.RandomTranslation(\n+            height_factor=self.factor,\n+            width_factor=self.factor,\n+            interpolation=interpolation,\n+            seed=self.seed,\n+            data_format=data_format,\n+            **kwargs,\n+        )\n+\n+        self.random_rotation = layers.RandomRotation(\n+            factor=self.factor,\n+            interpolation=interpolation,\n+            seed=self.seed,\n+            data_format=data_format,\n+            **kwargs,\n+        )\n+\n+        self.solarization = layers.Solarization(\n+            addition_factor=self.factor,\n+            threshold_factor=self.factor,\n+            value_range=self.value_range,\n+            seed=self.seed,\n+            data_format=data_format,\n+            **kwargs,\n+        )\n+\n+        self.random_posterization = layers.RandomPosterization(\n+            factor=max(1, int(8 * self.factor[1])),\n+            value_range=self.value_range,\n+            seed=self.seed,\n+            data_format=data_format,\n+            **kwargs,\n+        )\n+\n+        self.auto_contrast = layers.AutoContrast(\n+            value_range=self.value_range, data_format=data_format, **kwargs\n+        )\n+\n+        self.equalization = layers.Equalization(\n+            value_range=self.value_range, data_format=data_format, **kwargs\n+        )\n+\n+        if self.all_ops:\n+            self.random_brightness = layers.RandomBrightness(\n+                factor=self.factor,\n+                value_range=self.value_range,\n+                seed=self.seed,\n+                data_format=data_format,\n+                **kwargs,\n+            )\n+\n+            self.random_color_degeneration = layers.RandomColorDegeneration(\n+                factor=self.factor,\n+                value_range=self.value_range,\n+                seed=self.seed,\n+                data_format=data_format,\n+                **kwargs,\n+            )\n+\n+            self.random_contrast = layers.RandomContrast(\n+                factor=self.factor,\n+                value_range=self.value_range,\n+                seed=self.seed,\n+                data_format=data_format,\n+                **kwargs,\n+            )\n+\n+            self.random_sharpness = layers.RandomSharpness(\n+                factor=self.factor,\n+                value_range=self.value_range,\n+                seed=self.seed,\n+                data_format=data_format,\n+                **kwargs,\n+            )\n+\n+    def build(self, input_shape):\n+        for layer_name in self._augment_layers:\n+            augmentation_layer = getattr(self, layer_name)\n+            augmentation_layer.build(input_shape)\n+\n+    def _sample_from_dirichlet(self, shape, alpha, seed):\n+        gamma_sample = self.backend.random.gamma(\n+            shape=shape,\n+            alpha=alpha,\n+            seed=seed,\n+        )\n+        return gamma_sample / self.backend.numpy.sum(\n+            gamma_sample, axis=-1, keepdims=True\n+        )\n+\n+    def get_random_transformation(self, data, training=True, seed=None):\n+        if not training:\n+            return None\n+\n+        if backend_utils.in_tf_graph():\n+            self.backend.set_backend(\"tensorflow\")\n+\n+            for layer_name in self._augment_layers:\n+                augmentation_layer = getattr(self, layer_name)\n+                augmentation_layer.backend.set_backend(\"tensorflow\")\n+\n+        seed = seed or self._get_seed_generator(self.backend._backend)\n+\n+        chain_mixing_weights = self._sample_from_dirichlet(\n+            [self.num_chains], self.alpha, seed\n+        )\n+        weight_sample = self.backend.random.beta(\n+            shape=(),\n+            alpha=self.alpha,\n+            beta=self.alpha,\n+            seed=seed,\n+        )\n+\n+        chain_transforms = []\n+        for _ in range(self.num_chains):\n+            depth_transforms = []\n+            for _ in range(self.chain_depth):\n+                layer_name = py_random.choice(self._augment_layers + [None])\n+                if layer_name is None:\n+                    continue\n+                augmentation_layer = getattr(self, layer_name)\n+                depth_transforms.append(\n+                    {\n+                        \"layer_name\": layer_name,\n+                        \"transformation\": (\n+                            augmentation_layer.get_random_transformation(\n+                                data,\n+                                seed=self._get_seed_generator(\n+                                    self.backend._backend\n+                                ),\n+                            )\n+                        ),\n+                    }\n+                )\n+            chain_transforms.append(depth_transforms)\n+\n+        transformation = {\n+            \"chain_mixing_weights\": chain_mixing_weights,\n+            \"weight_sample\": weight_sample,\n+            \"chain_transforms\": chain_transforms,\n+        }\n+\n+        return transformation\n+\n+    def transform_images(self, images, transformation, training=True):\n+        if training:\n+            images = self.backend.cast(images, self.compute_dtype)\n+\n+            chain_mixing_weights = self.backend.cast(\n+                transformation[\"chain_mixing_weights\"], dtype=self.compute_dtype\n+            )\n+            weight_sample = self.backend.cast(\n+                transformation[\"weight_sample\"], dtype=self.compute_dtype\n+            )\n+            chain_transforms = transformation[\"chain_transforms\"]\n+\n+            aug_images = self.backend.numpy.zeros_like(images)\n+            for idx, chain_transform in enumerate(chain_transforms):\n+                copied_images = self.backend.numpy.copy(images)\n+                for depth_transform in chain_transform:\n+                    layer_name = depth_transform[\"layer_name\"]\n+                    layer_transform = depth_transform[\"transformation\"]\n+\n+                    augmentation_layer = getattr(self, layer_name)\n+                    copied_images = augmentation_layer.transform_images(\n+                        copied_images, layer_transform\n+                    )\n+                aug_images += copied_images * chain_mixing_weights[idx]\n+            images = weight_sample * images + (1 - weight_sample) * aug_images\n+\n+            images = self.backend.numpy.clip(\n+                images, self.value_range[0], self.value_range[1]\n+            )\n+\n+        images = self.backend.cast(images, self.compute_dtype)\n+        return images\n+\n+    def transform_labels(self, labels, transformation, training=True):\n+        return labels\n+\n+    def transform_bounding_boxes(\n+        self,\n+        bounding_boxes,\n+        transformation,\n+        training=True,\n+    ):\n+        return bounding_boxes\n+\n+    def transform_segmentation_masks(\n+        self, segmentation_masks, transformation, training=True\n+    ):\n+        return self.transform_images(\n+            segmentation_masks, transformation, training=training\n+        )\n+\n+    def compute_output_shape(self, input_shape):\n+        return input_shape\n+\n+    def get_config(self):\n+        config = {\n+            \"value_range\": self.value_range,\n+            \"num_chains\": self.chain_depth,\n+            \"chain_depth\": self.num_chains,\n+            \"factor\": self.factor,\n+            \"alpha\": self.alpha,\n+            \"all_ops\": self.all_ops,\n+            \"interpolation\": self.interpolation,\n+            \"seed\": self.seed,\n+        }\n+        base_config = super().get_config()\n+        return {**base_config, **config}\n\n@@ -0,0 +1,66 @@\n+import numpy as np\n+import pytest\n+from tensorflow import data as tf_data\n+\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n+\n+\n+class RandAugmentTest(testing.TestCase):\n+    @pytest.mark.requires_trainable_backend\n+    def test_layer(self):\n+        self.run_layer_test(\n+            layers.AugMix,\n+            init_kwargs={\n+                \"value_range\": (0, 255),\n+                \"num_chains\": 2,\n+                \"chain_depth\": 2,\n+                \"factor\": 1,\n+                \"alpha\": 1.0,\n+                \"all_ops\": True,\n+                \"interpolation\": \"nearest\",\n+                \"seed\": 43,\n+                \"data_format\": \"channels_last\",\n+            },\n+            input_shape=(8, 3, 4, 3),\n+            supports_masking=False,\n+            expected_output_shape=(8, 3, 4, 3),\n+        )\n+\n+    def test_aug_mix_inference(self):\n+        seed = 3481\n+        layer = layers.AugMix()\n+\n+        np.random.seed(seed)\n+        inputs = np.random.randint(0, 255, size=(224, 224, 3))\n+        output = layer(inputs, training=False)\n+        self.assertAllClose(inputs, output)\n+\n+    def test_random_augment_randomness(self):\n+        data_format = backend.config.image_data_format()\n+        if data_format == \"channels_last\":\n+            input_data = np.random.random((2, 8, 8, 3))\n+        else:\n+            input_data = np.random.random((2, 3, 8, 8))\n+\n+        layer = layers.AugMix(\n+            num_chains=11, all_ops=True, data_format=data_format\n+        )\n+        augmented_image = layer(input_data)\n+\n+        self.assertNotAllClose(\n+            backend.convert_to_numpy(augmented_image), input_data\n+        )\n+\n+    def test_tf_data_compatibility(self):\n+        data_format = backend.config.image_data_format()\n+        if data_format == \"channels_last\":\n+            input_data = np.random.random((2, 8, 8, 3))\n+        else:\n+            input_data = np.random.random((2, 3, 8, 8))\n+        layer = layers.AugMix(data_format=data_format)\n+\n+        ds = tf_data.Dataset.from_tensor_slices(input_data).batch(2).map(layer)\n+        for output in ds.take(1):\n+            output.numpy()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#25d6d80a6ecd31f0da52c325cd16dbe4a29b7329", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 5 | Methods Changed: 4 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 8 | Churn Cumulative: 64 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -217,7 +217,6 @@ class JaxLayer(Layer):\n         params=None,\n         state=None,\n         seed=None,\n-        dtype=None,\n         **kwargs,\n     ):\n         if backend.backend() != \"jax\":\n@@ -231,10 +230,9 @@ class JaxLayer(Layer):\n                 \"`init_fn`, `params` and `state` cannot all be `None`.\"\n             )\n \n-        super().__init__(dtype=dtype, **kwargs)\n+        super().__init__(**kwargs)\n         self.call_fn = call_fn\n         self.init_fn = init_fn\n-        self.has_dtype_policy = dtype is not None\n         self.seed_generator = backend.random.SeedGenerator(seed)\n         self.tracked_params = self._create_variables(params, trainable=True)\n         self.tracked_state = self._create_variables(state, trainable=False)\n@@ -301,7 +299,7 @@ class JaxLayer(Layer):\n                 value, (np.ndarray, np.generic)\n             ):\n                 dtype = value.dtype\n-                if self.has_dtype_policy and is_float_dtype(dtype):\n+                if is_float_dtype(dtype):\n                     dtype = None  # Use the layer dtype policy\n                 return self.add_weight(\n                     value.shape,\n@@ -311,7 +309,7 @@ class JaxLayer(Layer):\n                 )\n             elif isinstance(value, (bool, int, float)):\n                 dtype = standardize_dtype(type(value))\n-                if self.has_dtype_policy and is_float_dtype(dtype):\n+                if is_float_dtype(dtype):\n                     dtype = None  # Use the layer dtype policy\n                 return self.add_weight(\n                     (),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5ca3d3af75f0cdba69b7d61761b3e2e26aa9ad44", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 91 | Lines Deleted: 30 | Files Changed: 2 | Hunks: 11 | Methods Changed: 9 | Complexity Δ (Sum/Max): 9/8 | Churn Δ: 121 | Churn Cumulative: 2230 | Contributors (this commit): 8 | Commits (past 90d): 4 | Contributors (cumulative): 13 | DMM Complexity: 0.5909090909090909\n\nDIFF:\n@@ -431,23 +431,9 @@ def map_coordinates(\n             f\" Received input with shape: {coordinate_arrs.shape}\"\n         )\n \n-    # unstack into a list of tensors for following operations\n+    fill_value = convert_to_tensor(fill_value, dtype=input_arr.dtype)\n+\n     coordinate_arrs = tf.unstack(coordinate_arrs, axis=0)\n-    fill_value = convert_to_tensor(tf.cast(fill_value, input_arr.dtype))\n-\n-    index_fixer = _INDEX_FIXERS.get(fill_mode)\n-    if index_fixer is None:\n-        raise ValueError(\n-            \"Invalid value for argument `fill_mode`. Expected one of \"\n-            f\"{set(_INDEX_FIXERS.keys())}. Received: \"\n-            f\"fill_mode={fill_mode}\"\n-        )\n-\n-    def is_valid(index, size):\n-        if fill_mode == \"constant\":\n-            return (0 <= index) & (index < size)\n-        else:\n-            return True\n \n     if order == 0:\n         interp_fun = _nearest_indices_and_weights\n@@ -456,14 +442,40 @@ def map_coordinates(\n     else:\n         raise NotImplementedError(\"map_coordinates currently requires order<=1\")\n \n+    def process_coordinates(coords, size):\n+        if fill_mode == \"constant\":\n+            valid = (coords >= 0) & (coords < size)\n+            safe_coords = tf.clip_by_value(coords, 0, size - 1)\n+            return safe_coords, valid\n+        elif fill_mode == \"nearest\":\n+            return tf.clip_by_value(coords, 0, size - 1), tf.ones_like(\n+                coords, dtype=tf.bool\n+            )\n+        elif fill_mode in [\"mirror\", \"reflect\"]:\n+            coords = tf.abs(coords)\n+            size_2 = size * 2\n+            mod = tf.math.mod(coords, size_2)\n+            under = mod < size\n+            over = ~under\n+            # reflect mode is same as mirror for under\n+            coords = tf.where(under, mod, size_2 - mod)\n+            # for reflect mode, adjust the over case\n+            if fill_mode == \"reflect\":\n+                coords = tf.where(over, coords - 1, coords)\n+            return coords, tf.ones_like(coords, dtype=tf.bool)\n+        elif fill_mode == \"wrap\":\n+            coords = tf.math.mod(coords, size)\n+            return coords, tf.ones_like(coords, dtype=tf.bool)\n+        else:\n+            raise ValueError(f\"Unknown fill_mode: {fill_mode}\")\n+\n     valid_1d_interpolations = []\n     for coordinate, size in zip(coordinate_arrs, input_arr.shape):\n         interp_nodes = interp_fun(coordinate)\n         valid_interp = []\n         for index, weight in interp_nodes:\n-            fixed_index = index_fixer(index, size)\n-            valid = is_valid(index, size)\n-            valid_interp.append((fixed_index, valid, weight))\n+            safe_index, valid = process_coordinates(index, size)\n+            valid_interp.append((safe_index, valid, weight))\n         valid_1d_interpolations.append(valid_interp)\n \n     outputs = []\n@@ -471,23 +483,20 @@ def map_coordinates(\n         indices, validities, weights = zip(*items)\n         indices = tf.transpose(tf.stack(indices))\n \n-        def fast_path():\n-            return tf.transpose(tf.gather_nd(input_arr, indices))\n+        gathered = tf.transpose(tf.gather_nd(input_arr, indices))\n \n-        def slow_path():\n-            all_valid = functools.reduce(operator.and_, validities)\n-            return tf.where(\n-                all_valid,\n-                tf.transpose(tf.gather_nd(input_arr, indices)),\n-                fill_value,\n-            )\n+        if fill_mode == \"constant\":\n+            all_valid = tf.reduce_all(validities)\n+            gathered = tf.where(all_valid, gathered, fill_value)\n \n-        contribution = tf.cond(tf.reduce_all(validities), fast_path, slow_path)\n+        contribution = gathered\n         outputs.append(\n             functools.reduce(operator.mul, weights)\n             * tf.cast(contribution, weights[0].dtype)\n         )\n+\n     result = functools.reduce(operator.add, outputs)\n+\n     if input_arr.dtype.is_integer:\n-        result = result if result.dtype.is_integer else tf.round(result)\n+        result = tf.round(result)\n     return tf.cast(result, input_arr.dtype)\n\n@@ -261,6 +261,58 @@ class ImageOpsStaticShapeTest(testing.TestCase):\n         out = kimage.map_coordinates(input, coordinates, 0)\n         self.assertEqual(out.shape, coordinates.shape[1:])\n \n+    def test_map_coordinates_uint8(self):\n+        image_uint8 = tf.ones((1, 1, 3), dtype=tf.uint8)\n+        coordinates = tf.convert_to_tensor([-1.0, 0.0, 0.0])[..., None, None]\n+\n+        if backend.backend() != \"tensorflow\":\n+            pytest.skip(\"Skipping test because the backend is not TensorFlow.\")\n+\n+        out = kimage.map_coordinates(\n+            image_uint8, coordinates, order=1, fill_mode=\"constant\"\n+        )\n+        assert out.shape == coordinates.shape[1:]\n+\n+    def test_map_coordinates_float32(self):\n+        image_float32 = tf.ones((1, 1, 3), dtype=tf.float32)\n+        coordinates = tf.convert_to_tensor([-1.0, 0.0, 0.0])[..., None, None]\n+\n+        if backend.backend() != \"tensorflow\":\n+            pytest.skip(\"Skipping test because the backend is not TensorFlow.\")\n+\n+        out = kimage.map_coordinates(\n+            image_float32, coordinates, order=1, fill_mode=\"constant\"\n+        )\n+        assert out.shape == coordinates.shape[1:]\n+\n+    def test_map_coordinates_nearest(self):\n+        image_uint8 = tf.ones((1, 1, 3), dtype=tf.uint8)\n+        coordinates = tf.convert_to_tensor([-1.0, 0.0, 0.0])[..., None, None]\n+\n+        if backend.backend() != \"tensorflow\":\n+            pytest.skip(\"Skipping test because the backend is not TensorFlow.\")\n+\n+        out = kimage.map_coordinates(\n+            image_uint8, coordinates, order=1, fill_mode=\"nearest\"\n+        )\n+        assert out.shape == coordinates.shape[1:]\n+\n+    def test_map_coordinates_manual_cast(self):\n+        image_uint8 = tf.ones((1, 1, 3), dtype=tf.uint8)\n+        coordinates = tf.convert_to_tensor([-1.0, 0.0, 0.0])[..., None, None]\n+        image_uint8_casted = tf.cast(image_uint8, dtype=tf.float32)\n+\n+        if backend.backend() != \"tensorflow\":\n+            pytest.skip(\"Skipping test because the backend is not TensorFlow.\")\n+\n+        out = tf.cast(\n+            kimage.map_coordinates(\n+                image_uint8_casted, coordinates, order=1, fill_mode=\"constant\"\n+            ),\n+            dtype=tf.uint8,\n+        )\n+        assert out.shape == coordinates.shape[1:]\n+\n     def test_pad_images(self):\n         # Test channels_last\n         x = KerasTensor([15, 25, 3])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#dca9e61606374d08f4dd9dd5a56451ea60d9466b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 44 | Contributors (this commit): 4 | Commits (past 90d): 5 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -354,8 +354,6 @@ class BinaryIoU(IoU):\n \n     Example:\n \n-    Example:\n-\n     >>> m = keras.metrics.BinaryIoU(target_class_ids=[0, 1], threshold=0.3)\n     >>> m.update_state([0, 1, 0, 1], [0.1, 0.2, 0.4, 0.7])\n     >>> m.result()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
