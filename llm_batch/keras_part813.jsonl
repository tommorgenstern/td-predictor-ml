{"custom_id": "keras#688daa5a1c0c750442997bbadfe0962b657f7b5a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 143 | Lines Deleted: 0 | Files Changed: 10 | Hunks: 13 | Methods Changed: 11 | Complexity Δ (Sum/Max): 17/6 | Churn Δ: 143 | Churn Cumulative: 2374 | Contributors (this commit): 7 | Commits (past 90d): 84 | Contributors (cumulative): 42 | DMM Complexity: 1.0\n\nDIFF:\n@@ -102,6 +102,7 @@ from keras.src.ops.numpy import arctan2\n from keras.src.ops.numpy import arctanh\n from keras.src.ops.numpy import argmax\n from keras.src.ops.numpy import argmin\n+from keras.src.ops.numpy import argpartition\n from keras.src.ops.numpy import argsort\n from keras.src.ops.numpy import array\n from keras.src.ops.numpy import average\n\n@@ -22,6 +22,7 @@ from keras.src.ops.numpy import arctan2\n from keras.src.ops.numpy import arctanh\n from keras.src.ops.numpy import argmax\n from keras.src.ops.numpy import argmin\n+from keras.src.ops.numpy import argpartition\n from keras.src.ops.numpy import argsort\n from keras.src.ops.numpy import array\n from keras.src.ops.numpy import average\n\n@@ -102,6 +102,7 @@ from keras.src.ops.numpy import arctan2\n from keras.src.ops.numpy import arctanh\n from keras.src.ops.numpy import argmax\n from keras.src.ops.numpy import argmin\n+from keras.src.ops.numpy import argpartition\n from keras.src.ops.numpy import argsort\n from keras.src.ops.numpy import array\n from keras.src.ops.numpy import average\n\n@@ -22,6 +22,7 @@ from keras.src.ops.numpy import arctan2\n from keras.src.ops.numpy import arctanh\n from keras.src.ops.numpy import argmax\n from keras.src.ops.numpy import argmin\n+from keras.src.ops.numpy import argpartition\n from keras.src.ops.numpy import argsort\n from keras.src.ops.numpy import array\n from keras.src.ops.numpy import average\n\n@@ -1167,3 +1167,7 @@ def select(condlist, choicelist, default=0):\n def slogdet(x):\n     x = convert_to_tensor(x)\n     return tuple(jnp.linalg.slogdet(x))\n+\n+\n+def argpartition(x, kth, axis=-1):\n+    return jnp.argpartition(x, kth, axis)\n\n@@ -1102,3 +1102,7 @@ def select(condlist, choicelist, default=0):\n \n def slogdet(x):\n     return tuple(np.linalg.slogdet(x))\n+\n+\n+def argpartition(x, kth, axis=-1):\n+    return np.argpartition(x, kth, axis).astype(\"int32\")\n\n@@ -2435,3 +2435,24 @@ def select(condlist, choicelist, default=0):\n def slogdet(x):\n     x = convert_to_tensor(x)\n     return tuple(tf.linalg.slogdet(x))\n+\n+\n+def argpartition(x, kth, axis=-1):\n+    x = convert_to_tensor(x, tf.int32)\n+\n+    x = swapaxes(x, axis, -1)\n+    bottom_ind = tf.math.top_k(-x, kth + 1).indices\n+\n+    n = tf.shape(x)[-1]\n+\n+    mask = tf.reduce_sum(tf.one_hot(bottom_ind, n, dtype=tf.int32), axis=0)\n+\n+    indices = tf.where(mask)\n+    updates = tf.squeeze(tf.zeros(tf.shape(indices)[0], dtype=tf.int32))\n+\n+    final_mask = tf.tensor_scatter_nd_update(x, indices, updates)\n+\n+    top_ind = tf.math.top_k(final_mask, tf.shape(x)[-1] - kth - 1).indices\n+\n+    out = tf.concat([bottom_ind, top_ind], axis=x.ndim - 1)\n+    return swapaxes(out, -1, axis)\n\n@@ -1613,3 +1613,23 @@ def select(condlist, choicelist, default=0):\n def slogdet(x):\n     x = convert_to_tensor(x)\n     return tuple(torch.linalg.slogdet(x))\n+\n+\n+def argpartition(x, kth, axis=-1):\n+    x = convert_to_tensor(x, \"int32\")\n+\n+    x = torch.transpose(x, axis, -1)\n+    bottom_ind = torch.topk(-x, kth + 1)[1]\n+\n+    def set_to_zero(a, i):\n+        a[i] = 0\n+        return a\n+\n+    for _ in range(x.dim() - 1):\n+        set_to_zero = torch.vmap(set_to_zero)\n+    proxy = set_to_zero(torch.ones(x.shape, dtype=torch.int32), bottom_ind)\n+\n+    top_ind = torch.topk(proxy, x.shape[-1] - kth - 1)[1]\n+\n+    out = torch.cat([bottom_ind, top_ind], dim=x.dim() - 1)\n+    return cast(torch.transpose(out, -1, axis), \"int32\")\n\n@@ -6191,3 +6191,45 @@ def slogdet(x):\n     if any_symbolic_tensors((x,)):\n         return Slogdet().symbolic_call(x)\n     return backend.numpy.slogdet(x)\n+\n+\n+class Argpartition(Operation):\n+    def __init__(self, kth, axis=-1):\n+        super().__init__()\n+        if not isinstance(kth, int):\n+            raise ValueError(\"kth must be an integer. Received:\" f\"kth = {kth}\")\n+        self.kth = kth\n+        self.axis = axis\n+\n+    def call(self, x):\n+        return backend.numpy.argpartition(x, kth=self.kth, axis=self.axis)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=\"int32\")\n+\n+\n+@keras_export([\"keras.ops.argpartition\", \"keras.ops.numpy.argpartition\"])\n+def argpartition(x, kth, axis=-1):\n+    \"\"\"Performs an indirect partition along the given axis.\n+\n+    It returns an array\n+    of indices of the same shape as `x` that index data along the given axis\n+    in partitioned order.\n+\n+    Args:\n+        a: Array to sort.\n+        kth: Element index to partition by.\n+            The k-th element will be in its final sorted position and all\n+            smaller elements will be moved before it and all larger elements\n+            behind it. The order of all elements in the partitions is undefined.\n+            If provided with a sequence of k-th it will partition all of them\n+            into their sorted position at once.\n+        axis: Axis along which to sort. The default is -1 (the last axis).\n+            If `None`, the flattened array is used.\n+\n+    Returns:\n+        Array of indices that partition `x` along the specified `axis`.\n+    \"\"\"\n+    if any_symbolic_tensors((x,)):\n+        return Argpartition(kth, axis).symbolic_call(x)\n+    return backend.numpy.argpartition(x, kth, axis)\n\n@@ -1475,6 +1475,14 @@ class NumpyOneInputOpsDynamicShapeTest(testing.TestCase):\n         y = KerasTensor((None, None))\n         self.assertEqual(knp.vstack([x, y]).shape, (None, 3))\n \n+    def test_argpartition(self):\n+        x = KerasTensor((None, 3))\n+        self.assertEqual(knp.argpartition(x, 3).shape, (None, 3))\n+        self.assertEqual(knp.argpartition(x, 1, axis=1).shape, (None, 3))\n+\n+        with self.assertRaises(ValueError):\n+            knp.argpartition(x, (1, 3))\n+\n \n class NumpyOneInputOpsStaticShapeTest(testing.TestCase):\n     def test_mean(self):\n@@ -1981,6 +1989,14 @@ class NumpyOneInputOpsStaticShapeTest(testing.TestCase):\n         y = KerasTensor((2, 3))\n         self.assertEqual(knp.vstack([x, y]).shape, (4, 3))\n \n+    def test_argpartition(self):\n+        x = KerasTensor((2, 3))\n+        self.assertEqual(knp.argpartition(x, 3).shape, (2, 3))\n+        self.assertEqual(knp.argpartition(x, 1, axis=1).shape, (2, 3))\n+\n+        with self.assertRaises(ValueError):\n+            knp.argpartition(x, (1, 3))\n+\n \n class NumpyTwoInputOpsCorretnessTest(testing.TestCase, parameterized.TestCase):\n     def test_add(self):\n@@ -4303,6 +4319,19 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             out, np.vectorize(np.diag, signature=\"(d,d)->(d)\")(np.eye(4))\n         )\n \n+    def test_argpartition(self):\n+        x = np.array([3, 4, 2, 1])\n+        self.assertAllClose(knp.argpartition(x, 2), np.argpartition(x, 2))\n+        self.assertAllClose(knp.Argpartition(2)(x), np.argpartition(x, 2))\n+\n+        x = np.array([[3, 4, 2], [1, 3, 1]])\n+        self.assertAllClose(knp.argpartition(x, 1), np.argpartition(x, 1))\n+        self.assertAllClose(knp.Argpartition(1)(x), np.argpartition(x, 1))\n+\n+        x = np.array([[[3, 4], [2, 3]], [[1, 2], [0, 1]]])\n+        self.assertAllClose(knp.argpartition(x, 1), np.argpartition(x, 1))\n+        self.assertAllClose(knp.Argpartition(1)(x), np.argpartition(x, 1))\n+\n \n class NumpyArrayCreateOpsCorrectnessTest(testing.TestCase):\n     def test_ones(self):\n@@ -5402,6 +5431,25 @@ class NumpyDtypeTest(testing.TestCase, parameterized.TestCase):\n             expected_dtype,\n         )\n \n+    @parameterized.named_parameters(named_product(dtype=ALL_DTYPES))\n+    def test_argpartition(self, dtype):\n+        import jax.numpy as jnp\n+\n+        if dtype == \"bool\":\n+            self.skipTest(\"argpartition doesn't support bool dtype\")\n+\n+        x = knp.array([1, 2, 3], dtype=dtype)\n+        x_jax = jnp.array([1, 2, 3], dtype=dtype)\n+        expected_dtype = standardize_dtype(jnp.argpartition(x_jax, 1).dtype)\n+\n+        self.assertEqual(\n+            standardize_dtype(knp.argpartition(x, 1).dtype), expected_dtype\n+        )\n+        self.assertEqual(\n+            standardize_dtype(knp.Argpartition(1).symbolic_call(x).dtype),\n+            expected_dtype,\n+        )\n+\n     @parameterized.named_parameters(named_product(dtype=ALL_DTYPES))\n     def test_argsort(self, dtype):\n         import jax.numpy as jnp\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#32fe905f89326a753ba51cd7d8f6df12da2bfe2a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 55 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 57 | Churn Cumulative: 76 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -244,5 +244,58 @@ class TestArrayDataAdapter(testing.TestCase, parameterized.TestCase):\n             self.assertAllClose(bw, [0.1, 0.2, 0.3, 0.4])\n \n     def test_errors(self):\n-        # TODO\n-        pass\n+        x = np.random.random((34, 1))\n+        y = np.random.random((34, 3))\n+        sw = np.random.random((34,))\n+        cw = {\n+            0: 0.1,\n+            1: 0.2,\n+            2: 0.3,\n+            3: 0.4,\n+        }\n+\n+        with self.assertRaisesRegex(\n+            ValueError, \"Expected all elements of `x` to be array-like\"\n+        ):\n+            array_data_adapter.ArrayDataAdapter(x=\"Invalid\")\n+        with self.assertRaisesRegex(\n+            ValueError, \"Expected all elements of `x` to be array-like\"\n+        ):\n+            array_data_adapter.ArrayDataAdapter(x=x, y=\"Invalid\")\n+        with self.assertRaisesRegex(\n+            ValueError, \"Expected all elements of `x` to be array-like\"\n+        ):\n+            array_data_adapter.ArrayDataAdapter(\n+                x=x, y=y, sample_weight=\"Invalid\"\n+            )\n+\n+        with self.assertRaisesRegex(\n+            ValueError, \"You cannot `class_weight` and `sample_weight`\"\n+        ):\n+            array_data_adapter.ArrayDataAdapter(\n+                x=x, y=y, sample_weight=sw, class_weight=cw\n+            )\n+\n+        nested_y = ({\"x\": x, \"y\": y},)\n+        with self.assertRaisesRegex(\n+            ValueError, \"You should provide one `sample_weight` array per\"\n+        ):\n+            array_data_adapter.ArrayDataAdapter(\n+                x=x, y=nested_y, sample_weight=[]\n+            )\n+\n+        tensor_sw = self.make_array(\"tf\", (34, 2), \"int32\")\n+        with self.assertRaisesRegex(\n+            ValueError, \"For a model with multiple outputs, when providing\"\n+        ):\n+            array_data_adapter.ArrayDataAdapter(\n+                x=x, y=nested_y, sample_weight=tensor_sw\n+            )\n+\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"`class_weight` is only supported for Models with a single\",\n+        ):\n+            array_data_adapter.ArrayDataAdapter(\n+                x=x, y=nested_y, class_weight=cw\n+            )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0f3bd5222bb46ac6da3ed96187e7ec908aa851fa", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 134 | Contributors (this commit): 5 | Commits (past 90d): 11 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -1627,7 +1627,7 @@ def argpartition(x, kth, axis=-1):\n \n     for _ in range(x.dim() - 1):\n         set_to_zero = torch.vmap(set_to_zero)\n-    proxy = set_to_zero(torch.ones(x.shape, dtype=torch.int32), bottom_ind)\n+    proxy = set_to_zero(ones(x.shape, dtype=torch.int32), bottom_ind)\n \n     top_ind = torch.topk(proxy, x.shape[-1] - kth - 1)[1]\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b41f687d7b0760ce42c158566e4f6793962db5ba", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 9 | Churn Cumulative: 932 | Contributors (this commit): 5 | Commits (past 90d): 21 | Contributors (cumulative): 9 | DMM Complexity: 1.0\n\nDIFF:\n@@ -19,6 +19,7 @@ from keras.src.backend.common.backend_utils import vectorize_impl\n from keras.src.backend.tensorflow import sparse\n from keras.src.backend.tensorflow.core import cast\n from keras.src.backend.tensorflow.core import convert_to_tensor\n+from keras.src.backend.tensorflow.core import shape as shape_op\n \n \n @sparse.elementwise_binary_union(tf.sparse.add)\n@@ -756,7 +757,7 @@ def _keepdims(x, y, axis):\n     if axis is None:\n         shape = [1 for _ in range(len(x.shape))]\n     else:\n-        shape = [tf.shape[i] for i in range(len(x.shape))]\n+        shape = list(shape_op(x))\n         for axis in tree.flatten(axis):\n             shape[axis] = 1\n     y = tf.reshape(y, shape)\n\n@@ -3105,9 +3105,13 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         self.assertAllClose(knp.Arctanh()(x), np.arctanh(x))\n \n     def test_argmax(self):\n-        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        x = np.array([[1, 2, 3], [3, 2, 1], [4, 5, 6]])\n         self.assertAllClose(knp.argmax(x), np.argmax(x))\n         self.assertAllClose(knp.argmax(x, axis=1), np.argmax(x, axis=1))\n+        self.assertAllClose(\n+            knp.argmax(x, axis=1, keepdims=True),\n+            np.argmax(x, axis=1, keepdims=True),\n+        )\n         self.assertAllClose(\n             knp.argmax(x, keepdims=True), np.argmax(x, keepdims=True)\n         )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#54e15eb3eecea8a743e1138a93bbc87703da96e2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 37 | Lines Deleted: 29 | Files Changed: 1 | Hunks: 12 | Methods Changed: 5 | Complexity Δ (Sum/Max): 11/11 | Churn Δ: 66 | Churn Cumulative: 662 | Contributors (this commit): 5 | Commits (past 90d): 12 | Contributors (cumulative): 5 | DMM Complexity: 0.42857142857142855\n\nDIFF:\n@@ -828,15 +828,10 @@ def average(x, axis=None, weights=None):\n         if axis is None:\n             avg = _rank_equal_case()\n         else:\n-            # We condition on rank rather than shape equality, because if we do\n-            # the latter, when the shapes are partially unknown but the ranks\n-            # are known and different, np_utils.cond will run shape checking on\n-            # the true branch, which will raise a shape-checking error.\n-            avg = tf.cond(\n-                tf.equal(tf.rank(x), tf.rank(weights)),\n-                _rank_equal_case,\n-                _rank_not_equal_case,\n-            )\n+            if len(x.shape) == len(weights.shape):\n+                avg = _rank_equal_case()\n+            else:\n+                avg = _rank_not_equal_case()\n     return avg\n \n \n@@ -929,6 +924,10 @@ def count_nonzero(x, axis=None):\n def cross(x1, x2, axisa=-1, axisb=-1, axisc=-1, axis=None):\n     x1 = convert_to_tensor(x1)\n     x2 = convert_to_tensor(x2)\n+    dtype = dtypes.result_type(x1.dtype, x2.dtype)\n+    x1 = tf.cast(x1, dtype)\n+    x2 = tf.cast(x2, dtype)\n+\n     if axis is not None:\n         axisa = axis\n         axisb = axis\n@@ -936,10 +935,6 @@ def cross(x1, x2, axisa=-1, axisb=-1, axisc=-1, axis=None):\n     x1 = moveaxis(x1, axisa, -1)\n     x2 = moveaxis(x2, axisb, -1)\n \n-    dtype = dtypes.result_type(x1.dtype, x2.dtype)\n-    x1 = tf.cast(x1, dtype)\n-    x2 = tf.cast(x2, dtype)\n-\n     def maybe_pad_zeros(x, size_of_last_dim):\n         def pad_zeros(x):\n             return tf.pad(\n@@ -953,28 +948,40 @@ def cross(x1, x2, axisa=-1, axisb=-1, axisc=-1, axis=None):\n                 ),\n             )\n \n+        if isinstance(size_of_last_dim, int):\n+            if size_of_last_dim == 2:\n+                return pad_zeros(x)\n+            return x\n+\n         return tf.cond(\n             tf.equal(size_of_last_dim, 2), lambda: pad_zeros(x), lambda: x\n         )\n \n-    x1_dim = tf.shape(x1)[-1]\n-    x2_dim = tf.shape(x2)[-1]\n+    x1_dim = shape_op(x1)[-1]\n+    x2_dim = shape_op(x2)[-1]\n+\n     x1 = maybe_pad_zeros(x1, x1_dim)\n     x2 = maybe_pad_zeros(x2, x2_dim)\n \n     # Broadcast each other\n-    shape = tf.shape(x1)\n-    shape = tf.broadcast_dynamic_shape(shape, tf.shape(x2))\n+    shape = shape_op(x1)\n+\n+    shape = tf.broadcast_dynamic_shape(shape, shape_op(x2))\n     x1 = tf.broadcast_to(x1, shape)\n     x2 = tf.broadcast_to(x2, shape)\n \n     c = tf.linalg.cross(x1, x2)\n-    c = tf.cond(\n+\n+    if isinstance(x1_dim, int) and isinstance(x2_dim, int):\n+        if (x1_dim == 2) & (x2_dim == 2):\n+            return c[..., 2]\n+        return moveaxis(c, -1, axisc)\n+\n+    return tf.cond(\n         (x1_dim == 2) & (x2_dim == 2),\n         lambda: c[..., 2],\n         lambda: moveaxis(c, -1, axisc),\n     )\n-    return c\n \n \n def cumprod(x, axis=None, dtype=None):\n@@ -1024,18 +1031,22 @@ def diagonal(x, offset=0, axis1=0, axis2=1):\n         return tf.linalg.diag_part(x)\n \n     x = moveaxis(x, (axis1, axis2), (-2, -1))\n-    x_shape = tf.shape(x)\n+    x_shape = shape_op(x)\n \n     def _zeros():\n         return tf.zeros(tf.concat([x_shape[:-1], [0]], 0), dtype=x.dtype)\n \n-    x, offset = tf.cond(\n+    if isinstance(x_shape[-1], int) and isinstance(x_shape[-2], int):\n+        if offset <= -1 * x_shape[-2] or offset >= x_shape[-1]:\n+            x = _zeros()\n+    else:\n+        x = tf.cond(\n             tf.logical_or(\n                 tf.less_equal(offset, -1 * x_shape[-2]),\n                 tf.greater_equal(offset, x_shape[-1]),\n             ),\n-        _zeros,\n-        lambda: (x, offset),\n+            lambda: _zeros(),\n+            lambda: x,\n         )\n     return tf.linalg.diag_part(x, k=offset)\n \n@@ -1225,12 +1236,9 @@ def hstack(xs):\n     if len(dtype_set) > 1:\n         dtype = dtypes.result_type(*dtype_set)\n         xs = tree.map_structure(lambda x: convert_to_tensor(x, dtype), xs)\n-    rank = tf.rank(xs[0])\n-    return tf.cond(\n-        tf.equal(rank, 1),\n-        lambda: tf.concat(xs, axis=0),\n-        lambda: tf.concat(xs, axis=1),\n-    )\n+    if len(xs[0].shape) == 1:\n+        return tf.concat(xs, axis=0)\n+    return tf.concat(xs, axis=1)\n \n \n def identity(n, dtype=None):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#81c004708a8ea9aa135edebf08ba17ba3f95e0d1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 6 | Files Changed: 2 | Hunks: 5 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 9 | Churn Cumulative: 479 | Contributors (this commit): 5 | Commits (past 90d): 23 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -1617,19 +1617,16 @@ def slogdet(x):\n \n def argpartition(x, kth, axis=-1):\n     x = convert_to_tensor(x, \"int32\")\n-\n     x = torch.transpose(x, axis, -1)\n     bottom_ind = torch.topk(-x, kth + 1)[1]\n \n     def set_to_zero(a, i):\n-        a[i] = 0\n+        a[i] = torch.zeros(1, dtype=a.dtype, device=a.device)\n         return a\n \n     for _ in range(x.dim() - 1):\n         set_to_zero = torch.vmap(set_to_zero)\n-    proxy = set_to_zero(ones(x.shape, dtype=torch.int32), bottom_ind)\n-\n+    proxy = set_to_zero(torch.ones_like(x, dtype=torch.int32), bottom_ind)\n     top_ind = torch.topk(proxy, x.shape[-1] - kth - 1)[1]\n-\n     out = torch.cat([bottom_ind, top_ind], dim=x.dim() - 1)\n     return cast(torch.transpose(out, -1, axis), \"int32\")\n\n@@ -4328,7 +4328,7 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         self.assertAllClose(knp.argpartition(x, 2), np.argpartition(x, 2))\n         self.assertAllClose(knp.Argpartition(2)(x), np.argpartition(x, 2))\n \n-        x = np.array([[3, 4, 2], [1, 3, 1]])\n+        x = np.array([[3, 4, 2], [1, 3, 4]])\n         self.assertAllClose(knp.argpartition(x, 1), np.argpartition(x, 1))\n         self.assertAllClose(knp.Argpartition(1)(x), np.argpartition(x, 1))\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d5c95408ca6d35fc4ef12bd844ed42288894cf27", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 790 | Contributors (this commit): 4 | Commits (past 90d): 23 | Contributors (cumulative): 8 | DMM Complexity: 1.0\n\nDIFF:\n@@ -3881,7 +3881,7 @@ class Nonzero(Operation):\n         return backend.numpy.nonzero(x)\n \n     def compute_output_spec(self, x):\n-        return KerasTensor([None] * len(x.shape))\n+        return KerasTensor([None] * len(x.shape), dtype=\"int32\")\n \n \n @keras_export([\"keras.ops.nonzero\", \"keras.ops.numpy.nonzero\"])\n\n@@ -7102,7 +7102,10 @@ class NumpyDtypeTest(testing.TestCase, parameterized.TestCase):\n         self.assertEqual(\n             standardize_dtype(knp.nonzero(x)[0].dtype), expected_dtype\n         )\n-        # TODO: verify Nonzero\n+        self.assertEqual(\n+            standardize_dtype(knp.Nonzero().symbolic_call(x)[0].dtype),\n+            expected_dtype,\n+        )\n \n     @parameterized.named_parameters(\n         named_product(dtypes=itertools.combinations(ALL_DTYPES, 2))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#880f0cdd67591474d8ed98a6b192655322b7ecfc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 95 | Lines Deleted: 69 | Files Changed: 8 | Hunks: 66 | Methods Changed: 27 | Complexity Δ (Sum/Max): 3/4 | Churn Δ: 164 | Churn Cumulative: 2106 | Contributors (this commit): 5 | Commits (past 90d): 40 | Contributors (cumulative): 31 | DMM Complexity: 0.0\n\nDIFF:\n@@ -593,7 +593,7 @@ def ctc_loss(target, output, target_length, output_length, mask_index=0):\n     output = convert_to_tensor(output)\n     target_length = convert_to_tensor(target_length, \"int32\")\n     output_length = convert_to_tensor(output_length, \"int32\")\n-    batch_size, _, num_classes = output.shape\n+    batch_size, max_input_length, num_classes = output.shape\n     batch_size, max_label_length = target.shape\n     log_epsilon = -1e5\n \n@@ -610,7 +610,7 @@ def ctc_loss(target, output, target_length, output_length, mask_index=0):\n         return jnp.logical_not(elem_valid)\n \n     target_paddings = _lengths_to_paddings(target_length, max_label_length)\n-    output_paddings = _lengths_to_paddings(output_length, max_label_length)\n+    output_paddings = _lengths_to_paddings(output_length, max_input_length)\n     target_paddings = target_paddings.astype(output.dtype)\n     output_paddings = output_paddings.astype(output.dtype)\n \n@@ -690,12 +690,12 @@ def ctc_loss(target, output, target_length, output_length, mask_index=0):\n \n def _ctc_greedy_decode(\n     inputs,\n-    sequence_length,\n+    sequence_lengths,\n     merge_repeated=True,\n     mask_index=None,\n ):\n     inputs = convert_to_tensor(inputs)\n-    sequence_length = convert_to_tensor(sequence_length, dtype=\"int32\")\n+    sequence_lengths = convert_to_tensor(sequence_lengths, dtype=\"int32\")\n     batch_size, max_length, num_classes = inputs.shape\n \n     if mask_index is None:\n@@ -705,7 +705,7 @@ def _ctc_greedy_decode(\n     scores = jnp.max(inputs, axis=-1)\n \n     seqlen_mask = jnp.arange(max_length)[None, :]\n-    seqlen_mask = seqlen_mask >= sequence_length[:, None]\n+    seqlen_mask = seqlen_mask >= sequence_lengths[:, None]\n \n     indices = jnp.where(seqlen_mask, mask_index, indices)\n     scores = jnp.where(seqlen_mask, 0.0, scores)\n@@ -715,16 +715,17 @@ def _ctc_greedy_decode(\n         repeat_mask = jnp.pad(repeat_mask, ((0, 0), (1, 0)))\n         indices = jnp.where(repeat_mask, mask_index, indices)\n \n-    # We rearrange the indices by moving `mask_index` to the end of the array\n+    # We set to -1 for blank labels\n     invalid_mask = indices == mask_index\n+    indices = jnp.where(invalid_mask, -1, indices)\n+\n+    # We rearrange the indices by moving `mask_index` to the end of the array\n     order = jnp.expand_dims(jnp.arange(max_length), axis=0)  # [1, N]\n     order = jnp.tile(order, (batch_size, 1))  # [B, N]\n     order = jnp.where(invalid_mask, max_length, order)\n     order = jnp.argsort(order, axis=-1)\n     indices = jnp.take_along_axis(indices, order, axis=-1)\n \n-    # We set to -1 for blank labels\n-    indices = jnp.where(invalid_mask, -1, indices)\n     scores = -jnp.sum(scores, axis=1)[:, None]\n     indices = jnp.expand_dims(indices, axis=0)\n     return indices, scores\n@@ -732,17 +733,17 @@ def _ctc_greedy_decode(\n \n def _ctc_beam_search_decode(\n     inputs,\n-    sequence_length,\n+    sequence_lengths,\n     beam_width=100,\n     top_paths=1,\n     mask_index=None,\n ):\n     inputs = convert_to_tensor(inputs)\n-    sequence_length = convert_to_tensor(sequence_length)\n+    sequence_lengths = convert_to_tensor(sequence_lengths)\n \n     batch_size, max_seq_len, num_classes = inputs.shape\n     inputs = jnn.log_softmax(inputs)\n-    seqlen_mask = jnp.arange(max_seq_len)[None, :] >= sequence_length[:, None]\n+    seqlen_mask = jnp.arange(max_seq_len)[None, :] >= sequence_lengths[:, None]\n \n     if mask_index is None:\n         mask_index = num_classes - 1\n@@ -895,12 +896,12 @@ def _ctc_beam_search_decode(\n \n def ctc_decode(\n     inputs,\n-    sequence_length,\n+    sequence_lengths,\n     strategy=\"greedy\",\n     beam_width=100,\n     top_paths=1,\n     merge_repeated=True,\n-    mask_index=None,\n+    mask_index=0,\n ):\n     inputs = convert_to_tensor(inputs)\n     dtype = backend.result_type(inputs.dtype, \"float32\")\n@@ -909,14 +910,14 @@ def ctc_decode(\n     if strategy == \"greedy\":\n         return _ctc_greedy_decode(\n             inputs,\n-            sequence_length,\n+            sequence_lengths,\n             merge_repeated=merge_repeated,\n             mask_index=mask_index,\n         )\n     elif strategy == \"beam_search\":\n         return _ctc_beam_search_decode(\n             inputs,\n-            sequence_length,\n+            sequence_lengths,\n             beam_width=beam_width,\n             top_paths=top_paths,\n             mask_index=mask_index,\n\n@@ -621,7 +621,7 @@ def ctc_loss(target, output, target_length, output_length, mask_index=0):\n     output = convert_to_tensor(output)\n     target_length = convert_to_tensor(target_length, \"int32\")\n     output_length = convert_to_tensor(output_length, \"int32\")\n-    batch_size, _, num_classes = output.shape\n+    batch_size, max_input_length, num_classes = output.shape\n     batch_size, max_label_length = target.shape\n     log_epsilon = -1e5\n \n@@ -638,7 +638,7 @@ def ctc_loss(target, output, target_length, output_length, mask_index=0):\n         return np.logical_not(elem_valid)\n \n     target_paddings = _lengths_to_paddings(target_length, max_label_length)\n-    output_paddings = _lengths_to_paddings(output_length, max_label_length)\n+    output_paddings = _lengths_to_paddings(output_length, max_input_length)\n     target_paddings = target_paddings.astype(output.dtype)\n     output_paddings = output_paddings.astype(output.dtype)\n \n@@ -729,12 +729,12 @@ def ctc_loss(target, output, target_length, output_length, mask_index=0):\n \n def _ctc_greedy_decode(\n     inputs,\n-    sequence_length,\n+    sequence_lengths,\n     merge_repeated=True,\n     mask_index=None,\n ):\n     inputs = convert_to_tensor(inputs)\n-    sequence_length = convert_to_tensor(sequence_length, dtype=\"int32\")\n+    sequence_lengths = convert_to_tensor(sequence_lengths, dtype=\"int32\")\n     batch_size, max_length, num_classes = inputs.shape\n \n     if mask_index is None:\n@@ -744,7 +744,7 @@ def _ctc_greedy_decode(\n     scores = np.max(inputs, axis=-1)\n \n     seqlen_mask = np.arange(max_length)[None, :]\n-    seqlen_mask = seqlen_mask >= sequence_length[:, None]\n+    seqlen_mask = seqlen_mask >= sequence_lengths[:, None]\n \n     indices = np.where(seqlen_mask, mask_index, indices)\n     scores = np.where(seqlen_mask, 0.0, scores)\n@@ -754,16 +754,17 @@ def _ctc_greedy_decode(\n         repeat_mask = np.pad(repeat_mask, ((0, 0), (1, 0)))\n         indices = np.where(repeat_mask, mask_index, indices)\n \n-    # We rearrange the indices by moving `mask_index` to the end of the array\n+    # We set to -1 for blank labels\n     invalid_mask = indices == mask_index\n+    indices = np.where(invalid_mask, -1, indices)\n+\n+    # We rearrange the indices by moving `mask_index` to the end of the array\n     order = np.expand_dims(np.arange(max_length), axis=0)  # [1, N]\n     order = np.tile(order, (batch_size, 1))  # [B, N]\n     order = np.where(invalid_mask, max_length, order)\n     order = np.argsort(order, axis=-1)\n     indices = np.take_along_axis(indices, order, axis=-1)\n \n-    # We set to -1 for blank labels\n-    indices = np.where(invalid_mask, -1, indices)\n     scores = -np.sum(scores, axis=1)[:, None]\n     indices = np.expand_dims(indices, axis=0)\n     return indices, scores\n@@ -771,17 +772,17 @@ def _ctc_greedy_decode(\n \n def _ctc_beam_search_decode(\n     inputs,\n-    sequence_length,\n+    sequence_lengths,\n     beam_width=100,\n     top_paths=1,\n     mask_index=None,\n ):\n     inputs = convert_to_tensor(inputs)\n-    sequence_length = convert_to_tensor(sequence_length)\n+    sequence_lengths = convert_to_tensor(sequence_lengths)\n \n     batch_size, max_seq_len, num_classes = inputs.shape\n     inputs = log_softmax(inputs, axis=-1)\n-    seqlen_mask = np.arange(max_seq_len)[None, :] >= sequence_length[:, None]\n+    seqlen_mask = np.arange(max_seq_len)[None, :] >= sequence_lengths[:, None]\n \n     if mask_index is None:\n         mask_index = num_classes - 1\n@@ -936,12 +937,12 @@ def _ctc_beam_search_decode(\n \n def ctc_decode(\n     inputs,\n-    sequence_length,\n+    sequence_lengths,\n     strategy=\"greedy\",\n     beam_width=100,\n     top_paths=1,\n     merge_repeated=True,\n-    mask_index=None,\n+    mask_index=0,\n ):\n     inputs = convert_to_tensor(inputs)\n     dtype = backend.result_type(inputs.dtype, \"float32\")\n@@ -950,14 +951,14 @@ def ctc_decode(\n     if strategy == \"greedy\":\n         return _ctc_greedy_decode(\n             inputs,\n-            sequence_length,\n+            sequence_lengths,\n             merge_repeated=merge_repeated,\n             mask_index=mask_index,\n         )\n     elif strategy == \"beam_search\":\n         return _ctc_beam_search_decode(\n             inputs,\n-            sequence_length,\n+            sequence_lengths,\n             beam_width=beam_width,\n             top_paths=top_paths,\n             mask_index=mask_index,\n\n@@ -802,12 +802,12 @@ def ctc_loss(\n \n def ctc_decode(\n     inputs,\n-    sequence_length,\n+    sequence_lengths,\n     strategy=\"greedy\",\n     beam_width=100,\n     top_paths=1,\n     merge_repeated=True,\n-    mask_index=None,\n+    mask_index=0,\n ):\n     inputs = convert_to_tensor(inputs)\n     input_shape = tf.shape(inputs)\n@@ -817,18 +817,27 @@ def ctc_decode(\n     dtype = backend.result_type(inputs.dtype, \"float32\")\n     inputs = tf.cast(inputs, dtype)\n \n-    sequence_length = convert_to_tensor(sequence_length, dtype=\"int32\")\n+    sequence_lengths = convert_to_tensor(sequence_lengths, dtype=\"int32\")\n     if strategy == \"greedy\":\n         (decoded, scores) = tf.nn.ctc_greedy_decoder(\n             inputs=inputs,\n-            sequence_length=sequence_length,\n+            sequence_length=sequence_lengths,\n             merge_repeated=merge_repeated,\n             blank_index=mask_index,\n         )\n     elif strategy == \"beam_search\":\n+        # Move `mask_index` column to the last position since this is the\n+        # default for `tf.nn.ctc_beam_search_decoder`\n+        if mask_index is not None:\n+            inputs_before = inputs[..., :mask_index]\n+            inputs_mask = inputs[..., mask_index : mask_index + 1]\n+            inputs_after = inputs[..., mask_index + 1 :]\n+            inputs = tf.concat(\n+                [inputs_before, inputs_after, inputs_mask], axis=-1\n+            )\n         (decoded, scores) = tf.nn.ctc_beam_search_decoder(\n             inputs=inputs,\n-            sequence_length=sequence_length,\n+            sequence_length=sequence_lengths,\n             beam_width=beam_width,\n             top_paths=top_paths,\n         )\n@@ -845,6 +854,14 @@ def ctc_decode(\n         decoded_dense.append(tf.sparse.to_dense(sp_input=st, default_value=-1))\n     decoded_dense = tf.stack(decoded_dense, axis=0)\n     decoded_dense = tf.cast(decoded_dense, \"int32\")\n+\n+    # We need to recover the labels because we swapped the indices earlier\n+    if strategy == \"beam_search\" and mask_index is not None:\n+        if mask_index < 0:\n+            mask_index = mask_index + input_shape[-1]\n+        decoded_dense = tf.where(\n+            decoded_dense >= mask_index, decoded_dense + 1, decoded_dense\n+        )\n     return decoded_dense, scores\n \n \n\n@@ -775,12 +775,12 @@ def ctc_loss(\n \n def _ctc_greedy_decode(\n     inputs,\n-    sequence_length,\n+    sequence_lengths,\n     merge_repeated=True,\n     mask_index=None,\n ):\n     inputs = convert_to_tensor(inputs)\n-    sequence_length = convert_to_tensor(sequence_length, dtype=\"int32\")\n+    sequence_lengths = convert_to_tensor(sequence_lengths, dtype=\"int32\")\n     batch_size, max_length, num_classes = inputs.shape\n \n     if mask_index is None:\n@@ -791,7 +791,7 @@ def _ctc_greedy_decode(\n     scores = torch.max(inputs, axis=-1)[0]\n \n     seqlen_mask = torch.arange(max_length, device=indices.device)[None, :]\n-    seqlen_mask = seqlen_mask >= sequence_length[:, None]\n+    seqlen_mask = seqlen_mask >= sequence_lengths[:, None]\n \n     indices = torch.where(seqlen_mask, mask_index, indices)\n     scores = torch.where(seqlen_mask, 0.0, scores)\n@@ -801,8 +801,11 @@ def _ctc_greedy_decode(\n         repeat = tnn.pad(repeat, (1, 0, 0, 0))\n         indices = torch.where(repeat, mask_index, indices)\n \n-    # We rearrange the indices by moving `mask_index` to the end of the array\n+    # We set to -1 for blank labels\n     invalid_mask = indices == mask_index\n+    indices = torch.where(invalid_mask, -1, indices)\n+\n+    # We rearrange the indices by moving `mask_index` to the end of the array\n     order = torch.unsqueeze(\n         torch.arange(max_length, device=indices.device), dim=0\n     )  # [1, N]\n@@ -811,8 +814,6 @@ def _ctc_greedy_decode(\n     order = torch.argsort(order, dim=-1)\n     indices = torch.take_along_dim(indices, order, dim=-1)\n \n-    # We set to -1 for blank labels\n-    indices = torch.where(invalid_mask, -1, indices)\n     scores = -torch.sum(scores, axis=1)[:, None]\n     indices = torch.unsqueeze(indices, dim=0)\n     return indices, scores\n@@ -820,12 +821,12 @@ def _ctc_greedy_decode(\n \n def ctc_decode(\n     inputs,\n-    sequence_length,\n+    sequence_lengths,\n     strategy=\"greedy\",\n     beam_width=100,\n     top_paths=1,\n     merge_repeated=True,\n-    mask_index=None,\n+    mask_index=0,\n ):\n     inputs = convert_to_tensor(inputs)\n     dtype = backend.result_type(inputs.dtype, \"float32\")\n@@ -834,7 +835,7 @@ def ctc_decode(\n     if strategy == \"greedy\":\n         return _ctc_greedy_decode(\n             inputs,\n-            sequence_length,\n+            sequence_lengths,\n             merge_repeated=merge_repeated,\n             mask_index=mask_index,\n         )\n\n@@ -1933,14 +1933,16 @@ def ctc(y_true, y_pred):\n             f\"Received: y_pred.shape={ops.shape(y_pred)}\"\n         )\n \n-    batch_length = ops.cast(ops.shape(y_true)[0], dtype=\"int32\")\n-    input_length = ops.cast(ops.shape(y_pred)[1], dtype=\"int32\")\n-    label_length = ops.cast(ops.shape(y_true)[1], dtype=\"int32\")\n+    mask_index = 0\n+    batch_length = ops.shape(y_pred)[0]\n+    input_length = ops.shape(y_pred)[1]\n     input_length = input_length * ops.ones((batch_length,), dtype=\"int32\")\n-    label_length = label_length * ops.ones((batch_length,), dtype=\"int32\")\n+    label_length = ops.cast(\n+        ops.sum(y_true != mask_index, axis=-1), dtype=\"int32\"\n+    )\n \n     return ops.ctc_loss(\n-        y_true, y_pred, label_length, input_length, mask_index=0\n+        y_true, y_pred, label_length, input_length, mask_index=mask_index\n     )\n \n \n\n@@ -1387,7 +1387,7 @@ class CTCTest(testing.TestCase):\n         logits = (np.arange(24).reshape((2, 4, 3)).astype(\"float32\") - 12) / 100\n         y_true = np.array(([[1, 2, 1, 0], [1, 2, 0, 2]]))\n         output = losses.CTC()(y_true, logits)\n-        self.assertAllClose(output, 4.389582)\n+        self.assertAllClose(output, 2.448645)\n \n \n class DiceTest(testing.TestCase):\n\n@@ -1880,7 +1880,7 @@ class CTCDecode(Operation):\n         beam_width=100,\n         top_paths=1,\n         merge_repeated=True,\n-        mask_index=None,\n+        mask_index=0,\n     ):\n         super().__init__()\n         self.strategy = strategy\n@@ -1928,7 +1928,7 @@ def ctc_decode(\n     beam_width=100,\n     top_paths=1,\n     merge_repeated=True,\n-    mask_index=None,\n+    mask_index=0,\n ):\n     \"\"\"Decodes the output of a CTC model.\n \n@@ -1947,7 +1947,7 @@ def ctc_decode(\n         merge_repeated: A boolean scalar, whether to merge repeated\n             labels in the output. Defaults to `True`.\n         mask_index: An integer scalar, the index of the mask character in\n-            the vocabulary. Defaults to `None`.\n+            the vocabulary. Defaults to `0`.\n \n     Returns:\n         A tuple containing:\n@@ -1973,7 +1973,7 @@ def ctc_decode(\n         ).symbolic_call(inputs, sequence_lengths)\n     return backend.nn.ctc_decode(\n         inputs=inputs,\n-        sequence_length=sequence_lengths,\n+        sequence_lengths=sequence_lengths,\n         strategy=strategy,\n         beam_width=beam_width,\n         top_paths=top_paths,\n\n@@ -1946,30 +1946,31 @@ class NNOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             [\n                 [\n                     [0.1, 0.4, 0.2, 0.4],\n-                    [0.3, 0.3, 0.4, 0.2],\n+                    [0.3, -0.3, 0.4, 0.2],\n                     [0.3, 0.2, 0.4, 0.3],\n                 ],\n                 [\n-                    [0.1, 0.4, 0.7, 0.2],\n+                    [0.7, 0.4, 0.3, 0.2],\n                     [0.3, 0.3, 0.4, 0.1],\n-                    [0.2, 0.1, 0.1, 0.5],\n+                    [0.6, -0.1, 0.1, 0.5],\n                 ],\n                 [\n                     [0.1, 0.4, 0.2, 0.7],\n-                    [0.3, 0.3, 0.2, 0.7],\n+                    [0.3, 0.3, -0.2, 0.7],\n                     [0.3, 0.2, 0.4, 0.1],\n                 ],\n             ]\n         )\n-        labels = np.array([[1, 2, -1], [2, -1, -1], [-1, -1, -1]])\n-        score_labels = np.array([[-1.2], [-1.6], [-0.7]])\n-        repeated_labels = np.array([[1, 2, 2], [2, 2, -1], [-1, -1, -1]])\n+        labels = np.array([[1, 2, -1], [2, -1, -1], [3, -1, -1]])\n+        score_labels = np.array([[-1.2], [-1.7], [-0.7]])\n+        repeated_labels = np.array([[1, 2, 2], [2, -1, -1], [3, -1, -1]])\n \n         # Test strategy=\"greedy\" and merge_repeated=True\n         (decoded,), scores = knn.ctc_decode(\n             inputs,\n             sequence_lengths=[3, 3, 1],\n             strategy=\"greedy\",\n+            mask_index=0,\n         )\n         self.assertAllClose(decoded, labels)\n         self.assertAllClose(scores, score_labels)\n@@ -1980,6 +1981,7 @@ class NNOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             sequence_lengths=[3, 3, 1],\n             strategy=\"greedy\",\n             merge_repeated=False,\n+            mask_index=0,\n         )\n         self.assertAllClose(decoded, repeated_labels)\n         self.assertAllClose(scores, score_labels)\n@@ -1987,15 +1989,17 @@ class NNOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         if backend.backend() == \"torch\":\n             self.skipTest(\"torch doesn't support 'beam_search' strategy\")\n \n-        labels = [\n-            np.array([[1, 2, -1], [2, -1, -1], [-1, -1, -1]]),\n-            np.array([[2, -1, -1], [2, 0, -1], [1, -1, -1]]),\n+        labels = np.array(\n+            [\n+                [[1, 2, -1], [2, -1, -1], [3, -1, -1]],\n+                [[2, -1, -1], [3, -1, -1], [1, -1, -1]],\n             ]\n+        )\n         score_labels = np.array(\n             [\n-                [-2.33578291, -2.44335217],\n-                [-2.22499622, -2.25768432],\n-                [-1.0633859, -1.3633859],\n+                [-2.426537, -2.435596],\n+                [-2.127681, -2.182338],\n+                [-1.063386, -1.363386],\n             ]\n         )\n         beam_width = 4\n@@ -2008,9 +2012,9 @@ class NNOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             strategy=\"beam_search\",\n             beam_width=beam_width,\n             top_paths=top_paths,\n+            mask_index=0,\n         )\n-        for i in range(top_paths):\n-            self.assertAllClose(decoded[i], labels[i])\n+        self.assertAllClose(decoded, labels)\n         self.assertAllClose(scores, score_labels)\n \n     def test_normalize(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4cb5671e9aed82433de33455de285783fa81f8ee", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 57 | Lines Deleted: 20 | Files Changed: 4 | Hunks: 16 | Methods Changed: 10 | Complexity Δ (Sum/Max): 7/3 | Churn Δ: 77 | Churn Cumulative: 163 | Contributors (this commit): 4 | Commits (past 90d): 11 | Contributors (cumulative): 10 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,5 +1,4 @@\n from keras.src import backend\n-from keras.src import ops\n from keras.src.api_export import keras_export\n from keras.src.backend.common import global_state\n \n@@ -135,25 +134,27 @@ class DTypePolicy:\n         return self._name\n \n     def convert_input(self, x, autocast, dtype):\n+        \"\"\"Converts the input dtype based on `autocast` and `dtype`.\n+\n+        Note that `x` can be a tensor, symbolic tensor or numpy array, and this\n+        method will keep integer inputs untouched and only apply casting to\n+        floats.\n+        \"\"\"\n+\n         dtype = backend.standardize_dtype(dtype)\n         if backend.is_tensor(x):\n-            if (\n-                autocast\n-                and backend.is_float_dtype(x.dtype)\n-                and x.dtype != dtype\n-            ):\n+            if self._should_cast(x, autocast, dtype):\n                 x = backend.cast(x, dtype=dtype)\n             return x\n         elif backend.is_keras_tensor(x):\n-            if (\n-                autocast\n-                and backend.is_float_dtype(x.dtype)\n-                and x.dtype != dtype\n-            ):\n+            if self._should_cast(x, autocast, dtype):\n                 x.dtype = dtype\n             return x\n         elif hasattr(x, \"__array__\"):\n-            return ops.convert_to_tensor(x, dtype=dtype)\n+            x = backend.convert_to_tensor(x)\n+            if self._should_cast(x, autocast, dtype):\n+                x = backend.cast(x, dtype=dtype)\n+            return x\n         return x\n \n     def get_config(self):\n@@ -163,6 +164,13 @@ class DTypePolicy:\n     def from_config(cls, config):\n         return cls(**config)\n \n+    def _should_cast(self, x, autocast, dtype):\n+        x_dtype = backend.standardize_dtype(x.dtype)\n+        if autocast and backend.is_float_dtype(x_dtype) and x_dtype != dtype:\n+            return True\n+        else:\n+            return False\n+\n \n @keras_export(\n     [\"keras.FloatDTypePolicy\", \"keras.dtype_policies.FloatDTypePolicy\"]\n\n@@ -437,13 +437,13 @@ class LayerTest(testing.TestCase):\n         y = layer(x)\n         self.assertEqual(layer.compute_dtype, \"float16\")\n         self.assertEqual(layer.variable_dtype, \"float16\")\n-        self.assertEqual(backend.standardize_dtype(y.dtype), \"float16\")\n+        self.assertDType(y, \"float16\")\n \n         layer = layers.Dense(2, dtype=\"mixed_float16\")\n         y = layer(x)\n         self.assertEqual(layer.compute_dtype, \"float16\")\n         self.assertEqual(layer.variable_dtype, \"float32\")\n-        self.assertEqual(backend.standardize_dtype(y.dtype), \"float16\")\n+        self.assertDType(y, \"float16\")\n         self.assertEqual(layer.kernel.dtype, \"float32\")\n \n     @pytest.mark.skipif(\n@@ -451,7 +451,7 @@ class LayerTest(testing.TestCase):\n         reason=\"Some torch ops not implemented for float16 on CPU.\",\n     )\n     def test_autocast(self):\n-        assertEqual = self.assertEqual\n+        assertDType = self.assertDType\n \n         # A layer with a int dtype (some preprocessing layers do this).\n         class InnerLayerOne(layers.Layer):\n@@ -467,7 +467,7 @@ class LayerTest(testing.TestCase):\n \n             def call(self, x):\n                 # Should not autocast.\n-                assertEqual(backend.standardize_dtype(self.v.dtype), \"float32\")\n+                assertDType(self.v, \"float32\")\n                 return ops.cast(x, \"float32\") + self.v\n \n         # A layer that is explicitly full precision.\n@@ -483,7 +483,7 @@ class LayerTest(testing.TestCase):\n \n             def call(self, x):\n                 # Should not autocast.\n-                assertEqual(backend.standardize_dtype(self.v.dtype), \"float32\")\n+                assertDType(self.v, \"float32\")\n                 return x + self.v\n \n         # A layer that is explicitly mixed precision but with autocast=False\n@@ -501,7 +501,7 @@ class LayerTest(testing.TestCase):\n \n             def call(self, x):\n                 # Should not autocast `self.v`.\n-                assertEqual(backend.standardize_dtype(self.v.dtype), \"float32\")\n+                assertDType(self.v, \"float32\")\n                 return ops.add(x, self.v)\n \n         # A layer that is explicitly mixed precision with inner layers.\n@@ -520,7 +520,7 @@ class LayerTest(testing.TestCase):\n \n             def call(self, x):\n                 # Should autocast.\n-                assertEqual(backend.standardize_dtype(self.v.dtype), \"float16\")\n+                assertDType(self.v, \"float16\")\n                 return self.inner_three(\n                     self.inner_two(self.inner_one(x + self.v))\n                 )\n@@ -529,6 +529,21 @@ class LayerTest(testing.TestCase):\n         y = layer(np.array(0.0))\n         self.assertEqual(y, 4.0)\n \n+    def test_autocast_with_np_array(self):\n+        assertDType = self.assertDType\n+\n+        class CustomLayer(layers.Layer):\n+            def __init__(self, **kwargs):\n+                super().__init__(**kwargs)\n+\n+            def call(self, x):\n+                # Here are the assertions.\n+                assertDType(x[0], \"float32\")  # Cast to compute_dtype\n+                assertDType(x[1], \"int32\")  # Untouched\n+\n+        x = [np.zeros(1, dtype=\"float64\"), np.zeros(1, dtype=\"int32\")]\n+        CustomLayer()(x)\n+\n     @pytest.mark.skipif(\n         backend.backend() == \"numpy\",\n         reason=\"Numpy backend does not support masking.\",\n\n@@ -25,7 +25,7 @@ class SpectralNormalizationTest(testing.TestCase):\n         self.run_layer_test(\n             layers.SpectralNormalization,\n             init_kwargs={\"layer\": layers.Embedding(10, 4)},\n-            input_data=np.random.randint(10, size=(10,)),\n+            input_data=np.random.randint(10, size=(10,)).astype(\"float32\"),\n             expected_output_shape=(10, 4),\n             expected_num_trainable_weights=1,\n             expected_num_non_trainable_weights=1,\n\n@@ -99,6 +99,20 @@ class TestCase(unittest.TestCase):\n                 f\"Backend {backend.backend()} does not support sparse tensors\",\n             )\n \n+    def assertDType(self, x, dtype, msg=None):\n+        if hasattr(x, \"dtype\"):\n+            x_dtype = backend.standardize_dtype(x.dtype)\n+        else:\n+            # If x is a python number\n+            x_dtype = backend.standardize_dtype(type(x))\n+        standardized_dtype = backend.standardize_dtype(dtype)\n+        default_msg = (\n+            \"The dtype of x does not match the expected one. \"\n+            f\"Received: x.dtype={x_dtype} and dtype={dtype}\"\n+        )\n+        msg = msg or default_msg\n+        self.assertEqual(x_dtype, standardized_dtype, msg=msg)\n+\n     def run_class_serialization_test(self, instance, custom_objects=None):\n         from keras.src.saving import custom_object_scope\n         from keras.src.saving import deserialize_keras_object\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
