{"custom_id": "keras#4e5348c5cab9842d8508375d3b6bf06b97d9db50", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 14 | Files Changed: 1 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 21 | Churn Cumulative: 8081 | Contributors (this commit): 43 | Commits (past 90d): 43 | Contributors (cumulative): 43 | DMM Complexity: 0.0\n\nDIFF:\n@@ -579,7 +579,7 @@ class Merge(Layer):\n         elif self.mode == 'dot':\n             l1 = self.layers[0].get_output(train)\n             l2 = self.layers[1].get_output(train)\n-            output = K.tensordot(l1, l2, self.dot_axes)  # T.batched_tensordot(l1, l2, self.dot_axes)\n+            output = K.batch_dot(l1, l2, self.dot_axes)\n             output_shape = list(self.output_shape)\n             output_shape[0] = -1\n             output = K.reshape(output, (tuple(output_shape)))\n@@ -587,8 +587,8 @@ class Merge(Layer):\n         elif self.mode == 'cos':\n             l1 = self.layers[0].get_output(train)\n             l2 = self.layers[1].get_output(train)\n-            output = K.tensordot(l1, l2, self.dot_axes) / K.sqrt(\n-                K.tensordot(l1, l1, self.dot_axes) * K.tensordot(l2, l2, self.dot_axes))\n+            output = K.batch_dot(l1, l2, self.dot_axes) / K.sqrt(\n+                K.batch_dot(l1, l1, self.dot_axes) * K.batch_dot(l2, l2, self.dot_axes))\n             output = output.dimshuffle((0, 'x'))\n             return output\n         else:\n@@ -1800,24 +1800,17 @@ class Siamese(Layer):\n         return s\n \n     def get_output_dot(self, train=False):\n-        if K._BACKEND != 'theano':\n-            raise Exception('\"dot\" merge mode will only work with Theano.')\n-        from theano import tensor as T\n         l1 = self.get_output_at(0, train)\n         l2 = self.get_output_at(1, train)\n-        output = T.batched_tensordot(l1, l2, self.dot_axes)\n-        output = output.dimshuffle((0, 'x'))\n+        output = K.batch_dot(l1, l2, self.dot_axes)\n+        output = K.expand_dims(output, -1)\n         return output\n \n     def get_output_cos(self, train=False):\n-        if K._BACKEND != 'theano':\n-            raise Exception('\"cos\" merge mode will only work with Theano.')\n-        import theano\n-        from theano import tensor as T\n         l1 = self.get_output_at(0, train)\n         l2 = self.get_output_at(1, train)\n-        output = T.batched_tensordot(l1, l2, self.dot_axes) / T.sqrt(T.batched_tensordot(l1, l1, self.dot_axes) * T.batched_tensordot(l2, l2, self.dot_axes))\n-        output = output.dimshuffle((0, 'x'))\n+        output = K.batch_dot(l1, l2, self.dot_axes) / K.sqrt(K.batch_dot(l1, l1, self.dot_axes) * K.batch_dot(l2, l2, self.dot_axes))\n+        output = K.expand_dims(output, -1)\n         return output\n \n     def get_output(self, train=False):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d4fce4f5f1b9c164de6a873dbb877d46e00c75e1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 11 | Files Changed: 2 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): -4/0 | Churn Δ: 14 | Churn Cumulative: 2592 | Contributors (this commit): 20 | Commits (past 90d): 75 | Contributors (cumulative): 28 | DMM Complexity: 1.0\n\nDIFF:\n@@ -94,13 +94,9 @@ def dot(x, y):\n \n \n def batch_dot(x, y, axes=None):\n-    if ndim(x) != 3 or ndim(y) != 3:\n-        raise Exception('batch_dot supports only 3D tensor. ' +\n-                        'Input1 dim is {}, Input2 ndim is {}.'.format(\n-                            ndim(x), ndim(y)))\n     if axes:\n-        adj_x = None if axes[0][0] == 2 else True\n-        adj_y = True if axes[1][0] == 2 else None\n+        adj_x = None if axes[0][0] == x.ndim-1 else True\n+        adj_y = True if axes[1][0] == y.ndim-1 else None\n     else:\n         adj_x = None\n         adj_y = None\n\n@@ -112,13 +112,9 @@ def dot(x, y):\n \n \n def batch_dot(x, y, axes=None):\n-    if ndim(x) != 3 or ndim(y) != 3:\n-        raise Exception('batch_dot supports only 3D tensor. ' +\n-                        'Input1 dim is {}, Input2 ndim is {}.'.format(\n-                            ndim(x), ndim(y)))\n     if axes is None:\n         # behaves like tf.batch_matmul as default\n-        axes = [(2,), (1,)]\n+        axes = [(x.ndim-1,), (y.ndim-2,)]\n     return T.batched_tensordot(x, y, axes=axes)\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d2ce35065746aa83bc60b046a18022bb2dc26270", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 1118 | Contributors (this commit): 12 | Commits (past 90d): 34 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -95,8 +95,8 @@ def dot(x, y):\n \n def batch_dot(x, y, axes=None):\n     if axes:\n-        adj_x = None if axes[0][0] == x.ndim-1 else True\n-        adj_y = True if axes[1][0] == y.ndim-1 else None\n+        adj_x = None if axes[0][0] == ndim(x)-1 else True\n+        adj_y = True if axes[1][0] == ndim(y)-1 else None\n     else:\n         adj_x = None\n         adj_y = None\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8661e78f0823c4cc8c8cb0d04dfd625f787fafc2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 273 | Contributors (this commit): 3 | Commits (past 90d): 5 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -216,9 +216,9 @@ for i in range(5):\n     print('Start of iteration', i)\n     start_time = time.time()\n \n-    # add a random jitter to the initial image. This will be reverted at decoding time\n-    random_jitter = (settings['jitter'] * 2) * (np.random.random((3, img_width, img_height)) - 0.5)\n-    x += random_jitter\n+    # add a random offset jitter to the initial image. This will be reverted at decoding time\n+    ox, oy = np.random.randint(-settings['jitter'], settings['jitter']+1, 2)\n+    x = np.roll(np.roll(x, ox, -1), oy, -2)\n \n     # run L-BFGS for 7 steps\n     x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n@@ -226,7 +226,7 @@ for i in range(5):\n     print('Current loss value:', min_val)\n     # decode the dream and save it\n     x = x.reshape((3, img_width, img_height))\n-    x -= random_jitter\n+    x = np.roll(np.roll(x, -ox, -1), -oy, -2) # unshift image\n     img = deprocess_image(x)\n     fname = result_prefix + '_at_iteration_%d.png' % i\n     imsave(fname, img)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8056f0dd37f9daee46b1a0679b1ef3aee693eedd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 9 | Churn Cumulative: 3069 | Contributors (this commit): 22 | Commits (past 90d): 87 | Contributors (cumulative): 40 | DMM Complexity: 1.0\n\nDIFF:\n@@ -225,6 +225,10 @@ def round(x):\n     return tf.round(x)\n \n \n+def sign(x):\n+    return tf.sign(x)\n+\n+\n def pow(x, a):\n     return tf.pow(x, a)\n \n\n@@ -189,6 +189,10 @@ def round(x):\n     return T.round(x)\n \n \n+def sign(x):\n+    return T.sgn(x)\n+\n+\n def pow(x, a):\n     return T.pow(x, a)\n \n\n@@ -147,6 +147,7 @@ class TestBackend(object):\n         check_single_tensor_operation('exp', (4, 2))\n         check_single_tensor_operation('log', (4, 2))\n         check_single_tensor_operation('round', (4, 2))\n+        check_single_tensor_operation('sign', (4, 2))\n         check_single_tensor_operation('pow', (4, 2), a=3)\n         check_single_tensor_operation('clip', (4, 2), min_value=0.4,\n                                       max_value=0.6)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#122be6e30b7fc1ecb5ea7b23cbb7ae6cb5bfcc72", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 121 | Contributors (this commit): 7 | Commits (past 90d): 4 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -18,7 +18,7 @@ _config_path = os.path.expanduser(os.path.join(_keras_dir, 'keras.json'))\n if os.path.exists(_config_path):\n     _config = json.load(open(_config_path))\n     _floatx = _config.get('floatx', floatx())\n-    assert _floatx in {'float32', 'float64'}\n+    assert _floatx in {'float16', 'float32', 'float64'}\n     _epsilon = _config.get('epsilon', epsilon())\n     assert type(_epsilon) == float\n     _backend = _config.get('backend', _BACKEND)\n\n@@ -20,7 +20,7 @@ def floatx():\n \n def set_floatx(floatx):\n     global _FLOATX\n-    if floatx not in {'float32', 'float64'}:\n+    if floatx not in {'float16', 'float32', 'float64'}:\n         raise Exception('Unknown floatx type: ' + str(floatx))\n     floatx = str(floatx)\n     _FLOATX = floatx\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bdd70d06d3590828deeaa6e41c08bba1e6c74abc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 156 | Contributors (this commit): 8 | Commits (past 90d): 6 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -1 +1 @@\n-__version__ = '0.3.2'\r\n+__version__ = '0.3.3'\r\n\n@@ -3,12 +3,12 @@ from setuptools import find_packages\n \n \n setup(name='Keras',\n-      version='0.3.2',\n+      version='0.3.3',\n       description='Deep Learning for Python',\n       author='Francois Chollet',\n       author_email='francois.chollet@gmail.com',\n       url='https://github.com/fchollet/keras',\n-      download_url='https://github.com/fchollet/keras/tarball/0.3.2',\n+      download_url='https://github.com/fchollet/keras/tarball/0.3.3',\n       license='MIT',\n       install_requires=['theano', 'pyyaml', 'six'],\n       extras_require={\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#61ade48343bbc9a030f60e4398b1f9007e984517", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 680 | Files Changed: 4 | Hunks: 8 | Methods Changed: 39 | Complexity Δ (Sum/Max): -175/0 | Churn Δ: 680 | Churn Cumulative: 5726 | Contributors (this commit): 20 | Commits (past 90d): 18 | Contributors (cumulative): 23 | DMM Complexity: 0.42332613390928725\n\nDIFF:\n@@ -2227,7 +2227,6 @@ class Container(Layer):\n                                 str(len(flattened_layers)) + ' layers.')\n \n             for k, name in enumerate(layer_names):\n-                print('layer', name)\n                 g = f[name]\n                 weight_names = g.attrs['weight_names']\n                 if len(weight_names):\n\n@@ -1,616 +0,0 @@\n-# -*- coding: utf-8 -*-\n-from __future__ import absolute_import\n-from __future__ import print_function\n-\n-from collections import OrderedDict\n-from .. import backend as K\n-from ..engine import Layer, Merge, merge\n-from six.moves import range\n-\n-\n-class Sequential(Layer):\n-    '''The Sequential container is a linear stack of layers.\n-    Apart from the `add` methods and the `layers` constructor argument,\n-    the API is identical to that of the `Layer` class.\n-\n-    This class is also the basis for the `keras.models.Sequential` model.\n-\n-    # Arguments\n-        layers: list of layers to be added to the container.\n-    '''\n-    def __init__(self, layers=[]):\n-        self.layers = []\n-        self.layer_cache = {}\n-        self.shape_cache = {}\n-        for layer in layers:\n-            self.add(layer)\n-        self._cache_enabled = True\n-\n-    @property\n-    def cache_enabled(self):\n-        return self._cache_enabled\n-\n-    @cache_enabled.setter\n-    def cache_enabled(self, value):\n-        self._cache_enabled = value\n-        for l in self.layers:\n-            l.cache_enabled = value\n-\n-    @property\n-    def layer_cache(self):\n-        return super(Sequential, self).layer_cache\n-\n-    @layer_cache.setter\n-    def layer_cache(self, value):\n-        self._layer_cache = value\n-        for layer in self.layers:\n-            layer.layer_cache = self._layer_cache\n-\n-    @property\n-    def shape_cache(self):\n-        return super(Sequential, self).shape_cache\n-\n-    @shape_cache.setter\n-    def shape_cache(self, value):\n-        self._shape_cache = value\n-        for layer in self.layers:\n-            layer.shape_cache = self._shape_cache\n-\n-    def set_previous(self, layer, reset_weights=True):\n-        self.layers[0].set_previous(layer, reset_weights)\n-\n-    def clear_previous(self, reset_weights=True):\n-        self.layers[0].clear_previous(reset_weights)\n-\n-    def add(self, layer):\n-        layer.layer_cache = self.layer_cache\n-        layer.shape_cache = self.shape_cache\n-        self.layers.append(layer)\n-        if len(self.layers) > 1:\n-            self.layers[-1].set_previous(self.layers[-2])\n-            if not hasattr(self.layers[0], 'input'):\n-                self.set_input()\n-\n-    @property\n-    def trainable_weights(self):\n-        weights = []\n-        for l in self.layers:\n-            if l.trainable:\n-                weights += l.get_params()[0]\n-        return weights\n-\n-    @property\n-    def regularizers(self):\n-        regularizers = []\n-        for l in self.layers:\n-            if l.trainable:\n-                regularizers += l.get_params()[1]\n-        return regularizers\n-\n-    @property\n-    def constraints(self):\n-        constraints = []\n-        for l in self.layers:\n-            if l.trainable:\n-                constraints += l.get_params()[2]\n-        return constraints\n-\n-    @property\n-    def updates(self):\n-        updates = []\n-        for l in self.layers:\n-            if l.trainable:\n-                updates += l.get_params()[3]\n-        return updates\n-\n-    @property\n-    def state_updates(self):\n-        \"\"\"\n-        Return the `updates` from all layers in the sequence that are\n-        stateful.  This is useful for separating _training_ updates and\n-        _prediction_ updates for when we need to update a layers internal state\n-        during a stateful prediction.\n-        \"\"\"\n-        state_updates = []\n-        for l in self.layers:\n-            if getattr(l, 'stateful', False):\n-                state_updates += l.get_params()[3]\n-        return state_updates\n-\n-    def reset_states(self):\n-        for l in self.layers:\n-            if hasattr(l, 'reset_states') and getattr(l, 'stateful', False):\n-                l.reset_states()\n-\n-    @property\n-    def output_shape(self):\n-        return self.layers[-1].output_shape\n-\n-    def get_output(self, train=False):\n-        return self.layers[-1].get_output(train)\n-\n-    def set_input(self):\n-        for l in self.layers:\n-            if hasattr(l, 'input'):\n-                ndim = K.ndim(l.input)\n-                self.layers[0].input = K.placeholder(ndim=ndim)\n-                break\n-\n-    def get_input(self, train=False):\n-        if not hasattr(self.layers[0], 'input'):\n-            self.set_input()\n-        return self.layers[0].get_input(train)\n-\n-    @property\n-    def input_shape(self):\n-        return self.layers[0].input_shape\n-\n-    @property\n-    def input(self):\n-        return self.get_input()\n-\n-    def get_weights(self):\n-        weights = []\n-        for layer in self.layers:\n-            weights += layer.get_weights()\n-        return weights\n-\n-    def set_weights(self, weights):\n-        for layer in self.layers:\n-            nb_param = len(layer.get_weights())\n-            layer.set_weights(weights[:nb_param])\n-            weights = weights[nb_param:]\n-\n-    def get_config(self):\n-        return {'name': self.__class__.__name__,\n-                'layers': [layer.get_config() for layer in self.layers]}\n-\n-    def count_params(self):\n-        return sum([layer.count_params() for layer in self.layers])\n-\n-\n-class Graph(Layer):\n-    '''Implement a NN graph with arbitrary layer connections,\n-    arbitrary number of inputs and arbitrary number of outputs.\n-\n-    This class is also the basis for the `keras.models.Graph` model.\n-\n-    Note: `Graph` can only be used as a layer\n-    (connect, input, get_input, get_output)\n-    when it has exactly one input and one output.\n-    '''\n-    def __init__(self):\n-        self.namespace = set()  # strings\n-        self.nodes = OrderedDict()  # layer-like\n-        self.inputs = {}  # layer-like\n-        self.input_order = []  # strings\n-        self.outputs = {}  # layer-like\n-        self.output_order = []  # strings\n-        self.input_config = []  # dicts\n-        self.output_config = []  # dicts\n-        self.node_config = []  # dicts\n-        self.layer_cache = {}\n-        self.shape_cache = {}\n-        self._cache_enabled = True\n-\n-    def __call__(self, X, mask=None, train=False):\n-        if type(X) != dict:\n-            return super(Graph, self).__call__(X, mask, train)\n-        else:\n-            # turn off layer cache temporarily\n-            tmp_cache_enabled = self.cache_enabled\n-            self.cache_enabled = False\n-            # create a temporary layer for each input\n-            tmp_previous = {}\n-            for name, input in self.inputs.items():\n-                layer = Layer(batch_input_shape=input.input_shape)\n-                layer.input = X[name]\n-                if hasattr(self, 'get_input_mask'):\n-                    layer.get_input_mask = lambda _: mask[name]\n-                # set temporary previous\n-                if hasattr(input, 'previous'):\n-                    tmp_previous[name] = input.previous\n-                input.set_previous(layer, False)\n-            Y = self.get_output(train=train)\n-            # return previous to what it was\n-            for name, input in self.inputs.items():\n-                if name in tmp_previous:\n-                    input.set_previous(tmp_previous[name], False)\n-                else:\n-                    input.clear_previous(False)\n-            self.cache_enabled = tmp_cache_enabled\n-            return Y\n-\n-    @property\n-    def cache_enabled(self):\n-        return self._cache_enabled\n-\n-    @cache_enabled.setter\n-    def cache_enabled(self, value):\n-        self._cache_enabled = value\n-        for l in self.nodes.values():\n-            l.cache_enabled = value\n-        for l in self.inputs.values():\n-            l.cache_enabled = value\n-\n-    @property\n-    def layer_cache(self):\n-        return super(Graph, self).layer_cache\n-\n-    @layer_cache.setter\n-    def layer_cache(self, value):\n-        self._layer_cache = value\n-        for layer in self.nodes.values():\n-            layer.layer_cache = self._layer_cache\n-        for layer in self.inputs.values():\n-            layer.layer_cache = self._layer_cache\n-\n-    @property\n-    def shape_cache(self):\n-        return super(Graph, self).shape_cache\n-\n-    @shape_cache.setter\n-    def shape_cache(self, value):\n-        self._shape_cache = value\n-        for layer in self.nodes.values():\n-            layer.shape_cache = self._shape_cache\n-        for layer in self.inputs.values():\n-            layer.shape_cache = self._shape_cache\n-\n-    @property\n-    def nb_input(self):\n-        return len(self.inputs)\n-\n-    @property\n-    def nb_output(self):\n-        return len(self.outputs)\n-\n-    @property\n-    def trainable_weights(self):\n-        weights = []\n-        for l in self.nodes.values():\n-            if l.trainable:\n-                weights += l.get_params()[0]\n-        return weights\n-\n-    @property\n-    def regularizers(self):\n-        regularizers = []\n-        for l in self.nodes.values():\n-            if l.trainable:\n-                regularizers += l.get_params()[1]\n-        return regularizers\n-\n-    @property\n-    def constraints(self):\n-        constraints = []\n-        for l in self.nodes.values():\n-            if l.trainable:\n-                constraints += l.get_params()[2]\n-        return constraints\n-\n-    @property\n-    def updates(self):\n-        updates = []\n-        for l in self.nodes.values():\n-            if l.trainable:\n-                updates += l.get_params()[3]\n-        return updates\n-\n-    @property\n-    def state_updates(self):\n-        \"\"\"\n-        Return the `updates` from all nodes in that graph for nodes that are\n-        stateful.  This is useful for separating _training_ updates and\n-        _prediction_ updates for when we need to update a layers internal state\n-        during a stateful prediction.\n-        \"\"\"\n-        state_updates = []\n-        for l in self.nodes.values():\n-            if getattr(l, 'stateful', False):\n-                state_updates += l.get_params()[3]\n-        return state_updates\n-\n-    def reset_states(self):\n-        for l in self.nodes.values():\n-            if hasattr(l, 'reset_states') and getattr(l, 'stateful', False):\n-                l.reset_states()\n-\n-    def set_previous(self, layer, connection_map={}, reset_weights=True):\n-        if self.nb_input != layer.nb_output:\n-            raise Exception('Cannot connect layers: '\n-                            'input count does not match output count.')\n-        if self.nb_input == 1:\n-            self.inputs[self.input_order[0]].set_previous(layer, reset_weights)\n-        else:\n-            if not connection_map:\n-                raise Exception('Cannot attach multi-input layer: '\n-                                'no connection_map provided.')\n-            for k, v in connection_map.items():\n-                if k in self.inputs and v in layer.outputs:\n-                    self.inputs[k].set_previous(layer.outputs[v], reset_weights)\n-                else:\n-                    raise Exception('Invalid connection map.')\n-\n-    def clear_previous(self, reset_weights=True):\n-        for k in self.inputs.values():\n-            k.clear_previous(reset_weights)\n-\n-    @property\n-    def input_shape(self):\n-        if self.nb_input == 1:\n-            # return tuple\n-            return self.inputs[self.input_order[0]].input_shape\n-        else:\n-            # return dictionary mapping input names to shape tuples\n-            return dict([(k, v.input_shape) for k, v in self.inputs.items()])\n-\n-    def get_input(self, train=False):\n-        if len(self.inputs) == len(self.outputs) == 1:\n-            return self.inputs[self.input_order[0]].get_input(train)\n-        else:\n-            return dict([(k, v.get_input(train)) for k, v in self.inputs.items()])\n-\n-    @property\n-    def input(self):\n-        return self.get_input()\n-\n-    @property\n-    def output_shape(self):\n-        if self.nb_output == 1:\n-            # return tuple\n-            return self.outputs[self.output_order[0]].output_shape\n-        else:\n-            # return dictionary mapping output names to shape tuples\n-            return dict([(k, v.output_shape) for k, v in self.outputs.items()])\n-\n-    def get_output(self, train=False):\n-        if len(self.inputs) == len(self.outputs) == 1:\n-            return self.outputs[self.output_order[0]].get_output(train)\n-        else:\n-            return dict([(k, v.get_output(train)) for k, v in self.outputs.items()])\n-\n-    def add_input(self, name, input_shape=None,\n-                  batch_input_shape=None, dtype='float'):\n-        '''Add an input to the graph.\n-\n-        # Arguments:\n-            name: string. The name of the new input. Must be unique in the graph.\n-            input_shape: a tuple of integers, the expected shape of the input samples.\n-                Does not include the batch size.\n-            batch_input_shape: a tuple of integers, the expected shape of the\n-                whole input batch, including the batch size.\n-            dtype: 'float' or 'int'.\n-        '''\n-        if name in self.namespace:\n-            raise Exception('Duplicate node identifier: ' + name)\n-        self.namespace.add(name)\n-        self.input_order.append(name)\n-        layer = Layer(name=name)  # empty layer\n-        if input_shape:\n-            layer.set_input_shape((None,) + tuple(input_shape))\n-        elif batch_input_shape:\n-            layer.set_input_shape(batch_input_shape)\n-        if dtype == 'float':\n-            layer.input = K.placeholder(shape=layer.input_shape, name=name)\n-        else:\n-            if (input_shape and len(input_shape) == 1) or (batch_input_shape and len(batch_input_shape) == 2):\n-                layer.input = K.placeholder(shape=layer.input_shape,\n-                                            dtype='int32',\n-                                            name=name)\n-            else:\n-                raise Exception('Type \"int\" can only be used with ndim==2 (Embedding).')\n-        self.inputs[name] = layer\n-        config = {'name': name, 'dtype': dtype}\n-        if batch_input_shape:\n-            config['batch_input_shape'] = batch_input_shape\n-        else:\n-            config['input_shape'] = input_shape\n-        self.input_config.append(config)\n-\n-    def add_node(self, layer, name, input=None, inputs=[],\n-                 merge_mode='concat', concat_axis=-1, dot_axes=-1,\n-                 create_output=False):\n-        '''Add a node in the graph. It can be connected to multiple\n-        inputs, which will first be merged into one tensor\n-        according to the mode specified.\n-\n-        # Arguments\n-            layer: the layer at the node.\n-            name: name for the node.\n-            input: when connecting the layer to a single input,\n-                this is the name of the incoming node.\n-            inputs: when connecting the layer to multiple inputs,\n-                this is a list of names of incoming nodes.\n-            merge_mode: one of {concat, sum, dot, ave, mul}\n-            concat_axis: when `merge_mode=='concat'`, this is the\n-                input concatenation axis.\n-            dot_axes: when `merge_mode='dot'`, this is the contraction axes\n-                specification; see the `Merge layer for details.\n-            create_output: boolean. Set this to `True` if you want the output\n-                of your node to be an output of the graph.\n-        '''\n-        if name in self.namespace:\n-            raise Exception('Duplicate node identifier: ' + name)\n-        layer.name = name\n-        if input:\n-            if input not in self.namespace:\n-                raise Exception('Unknown node/input identifier: ' + input)\n-            if input in self.nodes:\n-                layer.set_previous(self.nodes[input])\n-            elif input in self.inputs:\n-                layer.set_previous(self.inputs[input])\n-        if inputs:\n-            to_merge = []\n-            for n in inputs:\n-                if n in self.nodes:\n-                    to_merge.append(self.nodes[n])\n-                elif n in self.inputs:\n-                    to_merge.append(self.inputs[n])\n-                else:\n-                    raise Exception('Unknown identifier: ' + n)\n-            merge = Merge(to_merge, mode=merge_mode,\n-                          concat_axis=concat_axis, dot_axes=dot_axes)\n-            layer.set_previous(merge)\n-\n-        self.namespace.add(name)\n-        layer.layer_cache = self.layer_cache\n-        layer.shape_cache = self.shape_cache\n-        self.nodes[name] = layer\n-        self.node_config.append({'name': name,\n-                                 'input': input,\n-                                 'inputs': inputs,\n-                                 'merge_mode': merge_mode,\n-                                 'concat_axis': concat_axis,\n-                                 'dot_axes': dot_axes,\n-                                 'create_output': create_output})\n-\n-        if create_output:\n-            self.add_output(name, input=name)\n-\n-    def add_shared_node(self, layer, name, inputs=[], merge_mode=None,\n-                        concat_axis=-1, dot_axes=-1, outputs=[],\n-                        create_output=False):\n-        '''Used to share a same layer across multiple nodes.\n-\n-        Supposed, for instance, that you want to apply one same `Dense`\n-        layer after to the output of two different nodes.\n-        You can then add the `Dense` layer as a shared node.\n-\n-        # Arguments\n-            layer: The layer to be shared across multiple inputs\n-            name: Name of the shared node\n-            inputs: List of names of input nodes\n-            merge_mode: Same meaning as `merge_mode` argument of `add_node()`\n-            concat_axis: Same meaning as `concat_axis` argument of `add_node()`\n-            dot_axes: Same meaning as `dot_axes` argument of `add_node()`\n-            outputs: Used when `merge_mode=None`. Names for the output nodes.\n-            create_output: Same meaning as `create_output` argument of `add_node()`.\n-        '''\n-        if name in self.namespace:\n-            raise Exception('Duplicate node identifier: ' + name)\n-        for o in outputs:\n-            if o in self.namespace:\n-                raise Exception('Duplicate node identifier: ' + o)\n-        if merge_mode:\n-            if merge_mode not in {'sum', 'ave', 'mul', 'dot', 'cos', 'concat', 'join'}:\n-                raise Exception('Invalid merge mode')\n-        layers = []\n-        for i in range(len(inputs)):\n-            input = inputs[i]\n-            if input in self.nodes:\n-                n = self.nodes[input]\n-                if n.__class__.__name__ == 'Siamese':\n-                    if n.merge_mode is None:\n-                        for j in range(len(n.inputs)):\n-                            sh = SiameseHead(j)\n-                            sh.previous = n\n-                            layers.append(sh)\n-                    else:\n-                        layers.append(n)\n-                else:\n-                    layers.append(n)\n-            elif input in self.inputs:\n-                n = self.inputs[input]\n-                layers.append(n)\n-            else:\n-                raise Exception('Unknown identifier: ' + input)\n-        s = Siamese(layer, layers, merge_mode,\n-                    concat_axis=concat_axis,\n-                    dot_axes=dot_axes,\n-                    is_graph=True)\n-        self.namespace.add(name)\n-        self.nodes[name] = s\n-        self.node_config.append({'name': name,\n-                                 'inputs': inputs,\n-                                 'merge_mode': merge_mode,\n-                                 'concat_axis': concat_axis,\n-                                 'dot_axes': dot_axes,\n-                                 'create_output': create_output if merge_mode else False})\n-        if not merge_mode:\n-            for i in range(len(outputs)):\n-                sh = SiameseHead(i)\n-                sh.previous = s\n-                sh_name = outputs[i]\n-                sh.name = sh_name\n-                self.namespace.add(sh_name)\n-                self.nodes[sh_name] = sh\n-                self.node_config.append({'name': sh_name,\n-                                         'inputs': [name],\n-                                         'create_output': create_output})\n-                if create_output:\n-                    self.add_output(sh_name, input=sh_name)\n-\n-        if create_output and merge_mode:\n-            if merge_mode == 'join':\n-                raise Exception('Output can not be of type OrderedDict')\n-            self.add_output(name, input=name)\n-\n-    def add_output(self, name, input=None, inputs=[],\n-                   merge_mode='concat', concat_axis=-1, dot_axes=-1):\n-        '''Add an output to the graph.\n-\n-        This output can merge several node outputs into a single output.\n-\n-        # Arguments\n-            name: name of the output.\n-            input: when connecting the layer to a single input,\n-                this is the name of the incoming node.\n-            inputs: when connecting the layer to multiple inputs,\n-                this is a list of names of incoming nodes.\n-            merge_mode: one of {concat, sum, dot, ave, mul}\n-            concat_axis: when `merge_mode=='concat'`, this is the\n-                input concatenation axis.\n-            dot_axes: when `merge_mode='dot'`, this is the contraction axes\n-                specification; see the `Merge layer for details.\n-        '''\n-        if name in self.output_order:\n-            raise Exception('Duplicate output identifier: ' + name)\n-        if input:\n-            if input not in self.namespace:\n-                raise Exception('Unknown node/input identifier: ' + input)\n-            if input in self.nodes:\n-                self.outputs[name] = self.nodes[input]\n-            elif input in self.inputs:\n-                self.outputs[name] = self.inputs[input]\n-        if inputs:\n-            to_merge = []\n-            for n in inputs:\n-                if n not in self.nodes:\n-                    raise Exception('Unknown identifier: ' + n)\n-                to_merge.append(self.nodes[n])\n-            merge = Merge(to_merge, mode=merge_mode,\n-                          concat_axis=concat_axis, dot_axes=dot_axes)\n-            self.outputs[name] = merge\n-\n-        self.output_order.append(name)\n-        self.output_config.append({'name': name,\n-                                   'input': input,\n-                                   'inputs': inputs,\n-                                   'merge_mode': merge_mode,\n-                                   'concat_axis': concat_axis,\n-                                   'dot_axes': dot_axes})\n-\n-    def get_config(self):\n-        return {'name': self.__class__.__name__,\n-                'input_config': self.input_config,\n-                'node_config': self.node_config,\n-                'output_config': self.output_config,\n-                'input_order': self.input_order,\n-                'output_order': self.output_order,\n-                'nodes': dict([(c['name'], self.nodes[c['name']].get_config()) for c in self.node_config])}\n-\n-    def count_params(self):\n-        return sum([layer.count_params() for layer in self.nodes.values()])\n-\n-    def get_weights(self):\n-        weights = []\n-        for layer in self.nodes.values():\n-            weights += layer.get_weights()\n-        return weights\n-\n-    def set_weights(self, weights):\n-        for layer in self.nodes.values():\n-            nb_param = len(layer.get_weights())\n-            layer.set_weights(weights[:nb_param])\n-            weights = weights[nb_param:]\n\n@@ -715,10 +715,6 @@ class Graph(Model):\n             if name in self._graph_shared_nodes_names:\n                 nodes[name]['shared'] = True\n         config['nodes'] = nodes\n-        print('node_config')\n-        print(config['node_config'])\n-        print('nodes')\n-        print(config['nodes'])\n         return copy.deepcopy(config)\n \n     @classmethod\n@@ -745,12 +741,8 @@ class Graph(Model):\n \n         nodes = config.get('node_config')\n         for node in nodes:\n-            print('node:')\n-            print(node)\n             layer_config = config['nodes'][node['name']]\n             layer_config = normalize_legacy_config(layer_config)\n-            print('layer config:', layer_config)\n-\n             if 'layer' in node:\n                 # for add_shared_node\n                 node['layer'] = layer_from_config(node['layer'])\n@@ -760,8 +752,6 @@ class Graph(Model):\n \n             node['create_output'] = False  # outputs will be added below\n             if layer_config.get('shared'):\n-                print('calling add_shared_node with:')\n-                print(node)\n                 graph.add_shared_node(**node)\n             else:\n                 graph.add_node(**node)\n\n@@ -9,56 +9,6 @@ from keras import backend as K\n from keras.models import model_from_json, model_from_yaml\n \n \n-def test_masking():\n-    from keras.models import Sequential\n-    from keras.layers import Embedding, Masking\n-\n-    model = Sequential()\n-    model.add(Masking(input_shape=(10,)))\n-    model.compile(loss='categorical_crossentropy',\n-                  optimizer='adam',\n-                  sample_weight_mode=None)\n-\n-    model = Sequential()\n-    model.add(Masking(input_shape=(10,)))\n-    model.compile(loss='categorical_crossentropy',\n-                  optimizer='adam',\n-                  sample_weight_mode='temporal')\n-\n-    model = Sequential()\n-    model.add(Embedding(10, 10, mask_zero=True, input_length=2))\n-    model.compile(loss='categorical_crossentropy',\n-                  optimizer='adam',\n-                  sample_weight_mode='temporal')\n-\n-    X = np.random.random_integers(1, 9, (100, 2))\n-    for rowi in range(X.shape[0]):\n-        padding = np.random.random_integers(X.shape[1] / 2)\n-        X[rowi, :padding] = 0\n-\n-    # 50% of the time the correct output is the input.\n-    # The other 50% of the time it's 2 * input % 10\n-    y = (X * np.random.random_integers(1, 2, X.shape)) % 10\n-    Y = np.zeros((y.size, 10), dtype='int32')\n-    for i, target in enumerate(y.flat):\n-        Y[i, target] = 1\n-    Y = Y.reshape(y.shape + (10,))\n-\n-    print('X shape:', X.shape)\n-    print('Y shape:', Y.shape)\n-    model.fit(X, Y, validation_split=0.05,\n-              sample_weight=None,\n-              verbose=1, nb_epoch=1)\n-    # with sample_weight\n-    sample_weight = np.random.random_integers(0, 1, y.shape)\n-    print('X shape:', X.shape)\n-    print('Y shape:', Y.shape)\n-    print('sample_weight shape:', Y.shape)\n-    model.fit(X, Y, validation_split=0.05,\n-              sample_weight=sample_weight,\n-              verbose=1, nb_epoch=1)\n-\n-\n def test_lambda_serialization():\n     from keras.layers import Lambda\n     from keras.utils.layer_utils import layer_from_config\n@@ -640,6 +590,3 @@ def test_sequential_regression():\n \n if __name__ == \"__main__\":\n     pytest.main([__file__])\n-    # test_lambda_serialization()\n-    # test_masking()\n-\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ca96737b20642356c7c6a575458d8938ea2e735b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 54 | Lines Deleted: 44 | Files Changed: 4 | Hunks: 27 | Methods Changed: 12 | Complexity Δ (Sum/Max): -3/2 | Churn Δ: 98 | Churn Cumulative: 10128 | Contributors (this commit): 48 | Commits (past 90d): 52 | Contributors (cumulative): 59 | DMM Complexity: 1.0\n\nDIFF:\n@@ -448,23 +448,15 @@ class TensorBoard(Callback):\n         self.model = model\n         self.sess = KTF.get_session()\n         if self.histogram_freq and not self.merged:\n-            mod_type = self.model.get_config()['name']\n-            if mod_type == 'Sequential':\n-                layers = {l.get_config()['name']: l for l in self.model.layers}\n-            elif mod_type == 'Graph':\n-                layers = self.model.nodes\n-            else:\n-                raise Exception('Unrecognized model:',\n-                                self.model.get_config()['name'])\n-            for l in layers:\n-                cur_layer = layers[l]\n-                if hasattr(cur_layer, 'W'):\n-                    tf.histogram_summary('{}_W'.format(l), cur_layer.W)\n-                if hasattr(cur_layer, 'b'):\n-                    tf.histogram_summary('{}_b'.format(l), cur_layer.b)\n-                if hasattr(cur_layer, 'get_output'):\n-                    tf.histogram_summary('{}_out'.format(l),\n-                                         cur_layer.get_output())\n+            layers = self.model.layers\n+            for layer in layers:\n+                if hasattr(layer, 'W'):\n+                    tf.histogram_summary('{}_W'.format(layer), layer.W)\n+                if hasattr(layer, 'b'):\n+                    tf.histogram_summary('{}_b'.format(layer), layer.b)\n+                if hasattr(layer, 'output'):\n+                    tf.histogram_summary('{}_out'.format(layer),\n+                                         layer.output)\n         self.merged = tf.merge_all_summaries()\n         self.writer = tf.train.SummaryWriter(self.log_dir,\n                                              self.sess.graph_def)\n@@ -474,14 +466,10 @@ class TensorBoard(Callback):\n \n         if self.model.validation_data and self.histogram_freq:\n             if epoch % self.histogram_freq == 0:\n-                if self.params.get('show_accuracy'):\n-                    test_function = self.model._test_with_acc\n-                else:\n-                    test_function = self.model._test\n-                names = [v.name for v in test_function.inputs]\n                 # TODO: implement batched calls to sess.run\n                 # (current call will likely go OOM on GPU)\n-                feed_dict = dict(zip(names, self.model.validation_data))\n+                feed_dict = dict(zip(self.model.inputs,\n+                                     self.model.validation_data))\n                 result = self.sess.run([self.merged], feed_dict=feed_dict)\n                 summary_str = result[0]\n                 self.writer.add_summary(summary_str, epoch)\n\n@@ -35,7 +35,8 @@ class Graph(Model):\n         self._graph_shared_nodes_names = []\n \n         if not name:\n-            name = 'graph_' + str(id(self))\n+            prefix = 'graph_'\n+            name = prefix + str(K.get_uid(prefix))\n         self.name = name\n \n     def __call__(self, x, mask=None):\n\n@@ -2,6 +2,7 @@ from __future__ import print_function\n import warnings\n import copy\n \n+from . import backend as K\n from .engine.training import Model\n from .engine.topology import get_source_inputs, Node\n from .legacy.models import Graph\n@@ -77,7 +78,8 @@ class Sequential(Model):\n         self.built = False\n \n         if not name:\n-            name = 'sequential_' + str(id(self))\n+            prefix = 'sequential_'\n+            name = prefix + str(K.get_uid(prefix))\n         self.name = name\n \n         for layer in layers:\n@@ -173,6 +175,8 @@ class Sequential(Model):\n         self.output_layers_tensor_indices = self.model.output_layers_tensor_indices\n         self.nodes_by_depth = self.model.nodes_by_depth\n         self.container_nodes = self.model.container_nodes\n+        self.output_names = self.model.output_names\n+        self.input_names = self.model.input_names\n \n         self.built = True\n \n@@ -265,6 +269,14 @@ class Sequential(Model):\n             layer.set_weights(weights[:nb_param])\n             weights = weights[nb_param:]\n \n+    @property\n+    def validation_data(self):\n+        return self.model.validation_data\n+\n+    @property\n+    def training_data(self):\n+        return self.model.training_data\n+\n     def compile(self, optimizer, loss,\n                 metrics=[],\n                 sample_weight_mode=None,\n@@ -306,6 +318,8 @@ class Sequential(Model):\n                            metrics=metrics,\n                            sample_weight_mode=sample_weight_mode,\n                            **kwargs)\n+        self.optimizer = self.model.optimizer\n+        self.sample_weight_mode = self.model.sample_weight_mode\n \n     def fit(self, x, y, batch_size=32, nb_epoch=10, verbose=1, callbacks=[],\n             validation_split=0., validation_data=None, shuffle=True,\n\n@@ -36,11 +36,13 @@ def test_ModelCheckpoint():\n     model = Sequential()\n     model.add(Dense(nb_hidden, input_dim=input_dim, activation='relu'))\n     model.add(Dense(nb_class, activation='softmax'))\n-    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n+    model.compile(loss='categorical_crossentropy',\n+                  optimizer='rmsprop',\n+                  metrics=['accuracy'])\n \n     cbks = [callbacks.ModelCheckpoint(filepath, monitor=monitor,\n                                       save_best_only=save_best_only, mode=mode)]\n-    model.fit(X_train, y_train, batch_size=batch_size, show_accuracy=True,\n+    model.fit(X_train, y_train, batch_size=batch_size,\n               validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=1)\n     assert os.path.exists(filepath)\n     os.remove(filepath)\n@@ -49,7 +51,7 @@ def test_ModelCheckpoint():\n     mode = 'min'\n     cbks = [callbacks.ModelCheckpoint(filepath, monitor=monitor,\n                                       save_best_only=save_best_only, mode=mode)]\n-    model.fit(X_train, y_train, batch_size=batch_size, show_accuracy=True,\n+    model.fit(X_train, y_train, batch_size=batch_size,\n               validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=1)\n     assert os.path.exists(filepath)\n     os.remove(filepath)\n@@ -59,7 +61,7 @@ def test_ModelCheckpoint():\n     monitor = 'val_acc'\n     cbks = [callbacks.ModelCheckpoint(filepath, monitor=monitor,\n                                       save_best_only=save_best_only, mode=mode)]\n-    model.fit(X_train, y_train, batch_size=batch_size, show_accuracy=True,\n+    model.fit(X_train, y_train, batch_size=batch_size,\n               validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=1)\n     assert os.path.exists(filepath)\n     os.remove(filepath)\n@@ -68,7 +70,7 @@ def test_ModelCheckpoint():\n     save_best_only = True\n     cbks = [callbacks.ModelCheckpoint(filepath, monitor=monitor,\n                                       save_best_only=save_best_only, mode=mode)]\n-    model.fit(X_train, y_train, batch_size=batch_size, show_accuracy=True,\n+    model.fit(X_train, y_train, batch_size=batch_size,\n               validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=1)\n     assert os.path.exists(filepath)\n     os.remove(filepath)\n@@ -85,20 +87,21 @@ def test_EarlyStopping():\n     model = Sequential()\n     model.add(Dense(nb_hidden, input_dim=input_dim, activation='relu'))\n     model.add(Dense(nb_class, activation='softmax'))\n-    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n-\n+    model.compile(loss='categorical_crossentropy',\n+                  optimizer='rmsprop',\n+                  metrics=['accuracy'])\n     mode = 'max'\n     monitor = 'val_acc'\n     patience = 0\n     cbks = [callbacks.EarlyStopping(patience=patience, monitor=monitor, mode=mode)]\n-    history = model.fit(X_train, y_train, batch_size=batch_size, show_accuracy=True,\n+    history = model.fit(X_train, y_train, batch_size=batch_size,\n                         validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=20)\n \n     mode = 'auto'\n     monitor = 'val_acc'\n     patience = 2\n     cbks = [callbacks.EarlyStopping(patience=patience, monitor=monitor, mode=mode)]\n-    history = model.fit(X_train, y_train, batch_size=batch_size, show_accuracy=True,\n+    history = model.fit(X_train, y_train, batch_size=batch_size,\n                         validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=20)\n \n \n@@ -113,10 +116,12 @@ def test_LearningRateScheduler():\n     model = Sequential()\n     model.add(Dense(nb_hidden, input_dim=input_dim, activation='relu'))\n     model.add(Dense(nb_class, activation='softmax'))\n-    model.compile(loss='categorical_crossentropy', optimizer='sgd')\n+    model.compile(loss='categorical_crossentropy',\n+                  optimizer='sgd',\n+                  metrics=['accuracy'])\n \n     cbks = [callbacks.LearningRateScheduler(lambda x: 1. / (1. + x))]\n-    model.fit(X_train, y_train, batch_size=batch_size, show_accuracy=True,\n+    model.fit(X_train, y_train, batch_size=batch_size,\n               validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=5)\n     assert (float(K.get_value(model.optimizer.lr)) - 0.2) < K.epsilon()\n \n@@ -166,39 +171,37 @@ def test_TensorBoard():\n         model = Sequential()\n         model.add(Dense(nb_hidden, input_dim=input_dim, activation='relu'))\n         model.add(Dense(nb_class, activation='softmax'))\n-        model.compile(loss='categorical_crossentropy', optimizer='sgd')\n+        model.compile(loss='categorical_crossentropy',\n+                      optimizer='sgd',\n+                      metrics=['accuracy'])\n \n         tsb = callbacks.TensorBoard(log_dir=filepath, histogram_freq=1)\n         cbks = [tsb]\n \n         # fit with validation data\n-        model.fit(X_train, y_train, batch_size=batch_size, show_accuracy=False,\n+        model.fit(X_train, y_train, batch_size=batch_size,\n                   validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=2)\n \n         # fit with validation data and accuracy\n-        model.fit(X_train, y_train, batch_size=batch_size, show_accuracy=True,\n+        model.fit(X_train, y_train, batch_size=batch_size,\n                   validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=2)\n \n         # fit generator with validation data\n         model.fit_generator(data_generator(True), len(X_train), nb_epoch=2,\n-                            show_accuracy=False,\n                             validation_data=(X_test, y_test),\n                             callbacks=cbks)\n \n         # fit generator without validation data\n         model.fit_generator(data_generator(True), len(X_train), nb_epoch=2,\n-                            show_accuracy=False,\n                             callbacks=cbks)\n \n         # fit generator with validation data and accuracy\n         model.fit_generator(data_generator(True), len(X_train), nb_epoch=2,\n-                            show_accuracy=True,\n                             validation_data=(X_test, y_test),\n                             callbacks=cbks)\n \n         # fit generator without validation data and accuracy\n         model.fit_generator(data_generator(True), len(X_train), nb_epoch=2,\n-                            show_accuracy=True,\n                             callbacks=cbks)\n \n         assert os.path.exists(filepath)\n@@ -249,4 +252,8 @@ def test_TensorBoard():\n     KTF.set_session(old_session)\n \n if __name__ == '__main__':\n-    pytest.main([__file__])\n+    # pytest.main([__file__])\n+    # test_ModelCheckpoint()\n+    # test_EarlyStopping()\n+    # test_LearningRateScheduler()\n+    test_TensorBoard()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
