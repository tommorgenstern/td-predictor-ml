{"custom_id": "keras#920b9c63327a688c2007819af849630751c2a8f7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 15 | Lines Deleted: 26 | Files Changed: 6 | Hunks: 14 | Methods Changed: 11 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 41 | Churn Cumulative: 31552 | Contributors (this commit): 155 | Commits (past 90d): 45 | Contributors (cumulative): 196 | DMM Complexity: 0.0\n\nDIFF:\n@@ -478,7 +478,7 @@ class Sequential(functional.Functional):\n             )\n             model.add(layer)\n \n-        if saving_lib._ENABLED:\n+        if saving_lib._SAVING_V3_ENABLED.value:\n \n             # Grab the information from the `config` for `compile()` and\n             # `build()`.\n\n@@ -3070,7 +3070,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n         # as a result.\n         config = {}\n \n-        if saving_lib._ENABLED:\n+        if saving_lib._SAVING_V3_ENABLED.value:\n             config[\"is_compiled\"] = self._is_compiled\n             if self.optimizer:\n                 config[\"optimizer\"] = saving_lib.serialize_keras_object(\n@@ -3147,8 +3147,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n                         f\"Error encountered during deserialization:\\n{e}\"\n                     )\n \n-            if saving_lib._ENABLED:\n-\n+            if saving_lib._SAVING_V3_ENABLED.value:\n                 has_overridden_compile = cls.compile != Model.compile\n                 has_overridden_from_config = (\n                     cls.from_config.__func__.__qualname__\n\n@@ -24,7 +24,6 @@ import numpy as np\n import tensorflow.compat.v2 as tf\n from absl.testing import parameterized\n \n-from keras.saving.experimental import saving_lib\n from keras.testing_infra import test_utils\n from keras.utils import generic_utils\n \n@@ -39,16 +38,7 @@ class CustomObjectSavingTest(tf.test.TestCase, parameterized.TestCase):\n         super().setUp()\n         generic_utils.get_custom_objects().clear()\n \n-    @tf.__internal__.distribute.combinations.generate(\n-        tf.__internal__.test.combinations.combine(\n-            mode=[\"eager\"], idempotent_saving_enabled=[True, False]\n-        )\n-    )\n-    def test_register_keras_serializable_correct_class(\n-        self, idempotent_saving_enabled\n-    ):\n-        saving_lib._ENABLED = idempotent_saving_enabled\n-\n+    def test_register_keras_serializable_correct_class(self):\n         train_step_message = \"This is my training step\"\n         temp_dir = os.path.join(self.get_temp_dir(), \"my_model\")\n \n\n@@ -278,7 +278,7 @@ class LossFunctionWrapper(Loss):\n                 backend.eval(v) if tf_utils.is_tensor_or_variable(v) else v\n             )\n \n-        if saving_lib._ENABLED:\n+        if saving_lib._SAVING_V3_ENABLED.value:\n             config[\"fn\"] = generic_utils.get_registered_name(self.fn)\n \n         base_config = super().get_config()\n@@ -294,7 +294,7 @@ class LossFunctionWrapper(Loss):\n         Returns:\n             A `keras.losses.Loss` instance.\n         \"\"\"\n-        if saving_lib._ENABLED:\n+        if saving_lib._SAVING_V3_ENABLED.value:\n             fn_name = config.pop(\"fn\", None)\n             if fn_name and cls is LossFunctionWrapper:\n                 config[\"fn\"] = get(fn_name)\n\n@@ -18,6 +18,7 @@ import datetime\n import json\n import os\n import tempfile\n+import threading\n import uuid\n import warnings\n import zipfile\n@@ -41,7 +42,8 @@ _METADATA_FILENAME = \"metadata.json\"\n _STATES_ROOT_DIRNAME = \"model\"\n \n # A temporary flag to enable the new idempotent saving framework.\n-_ENABLED = False\n+_SAVING_V3_ENABLED = threading.local()\n+_SAVING_V3_ENABLED.value = False\n \n \n def _print_archive(zipfile, action):\n@@ -149,6 +151,8 @@ def load_model(filepath, custom_objects=None):\n             \"Invalid filename: expected a `.keras` extension. \"\n             f\"Received: filepath={filepath}\"\n         )\n+    saving_v3_enabled_value = _SAVING_V3_ENABLED.value\n+    _SAVING_V3_ENABLED.value = True\n     temp_path = _get_temp_dir()\n     try:\n         with zipfile.ZipFile(filepath, \"r\") as zipfile_to_load:\n@@ -167,6 +171,7 @@ def load_model(filepath, custom_objects=None):\n     else:\n         return model\n     finally:\n+        _SAVING_V3_ENABLED.value = saving_v3_enabled_value\n         if tf.io.gfile.exists(temp_path):\n             tf.io.gfile.rmtree(temp_path)\n \n@@ -297,6 +302,8 @@ def save_model(model, filepath):\n             \"on some data.\",\n             stacklevel=2,\n         )\n+    saving_v3_enabled_value = _SAVING_V3_ENABLED.value\n+    _SAVING_V3_ENABLED.value = True\n \n     serialized_model_dict = serialize_keras_object(model)\n     config_json = json.dumps(serialized_model_dict).encode()\n@@ -324,6 +331,7 @@ def save_model(model, filepath):\n     except Exception as e:\n         raise e\n     finally:\n+        _SAVING_V3_ENABLED.value = saving_v3_enabled_value\n         # Remove the directory temporarily used.\n         tf.io.gfile.rmtree(temp_path)\n \n\n@@ -135,14 +135,6 @@ module_my_mean_squared_error = my_mean_squared_error\n \n \n class NewSavingTest(tf.test.TestCase, parameterized.TestCase):\n-    def setUp(self):\n-        super().setUp()\n-        saving_lib._ENABLED = True\n-\n-    def tearDown(self):\n-        super().tearDown()\n-        saving_lib._ENABLED = False\n-\n     def _get_subclassed_model(self):\n         subclassed_model = CustomModelX()\n         subclassed_model.compile(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a9031c842571b45668a1de34091f3c2b73990033", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 5 | Churn Cumulative: 19912 | Contributors (this commit): 136 | Commits (past 90d): 23 | Contributors (cumulative): 136 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1701,7 +1701,10 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n                 if self.stop_training:\n                     break\n \n-            if isinstance(self.optimizer, optimizer_experimental.Optimizer):\n+            if (\n+                isinstance(self.optimizer, optimizer_experimental.Optimizer)\n+                and epochs > 0\n+            ):\n                 self.optimizer.finalize_variable_values(\n                     self.trainable_variables\n                 )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fb8446132b67aac6014e1835dd22934b0d6a7198", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 6 | Files Changed: 3 | Hunks: 5 | Methods Changed: 5 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 11 | Churn Cumulative: 29434 | Contributors (this commit): 155 | Commits (past 90d): 36 | Contributors (cumulative): 180 | DMM Complexity: None\n\nDIFF:\n@@ -478,8 +478,7 @@ class Sequential(functional.Functional):\n             )\n             model.add(layer)\n \n-        if saving_lib._SAVING_V3_ENABLED.value:\n-\n+        if getattr(saving_lib._SAVING_V3_ENABLED, \"value\", False):\n             # Grab the information from the `config` for `compile()` and\n             # `build()`.\n             is_compiled = config.pop(\"is_compiled\", False)\n\n@@ -3073,7 +3073,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n         # as a result.\n         config = {}\n \n-        if saving_lib._SAVING_V3_ENABLED.value:\n+        if getattr(saving_lib._SAVING_V3_ENABLED, \"value\", False):\n             config[\"is_compiled\"] = self._is_compiled\n             if self.optimizer:\n                 config[\"optimizer\"] = saving_lib.serialize_keras_object(\n@@ -3150,7 +3150,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n                         f\"Error encountered during deserialization:\\n{e}\"\n                     )\n \n-            if saving_lib._SAVING_V3_ENABLED.value:\n+            if getattr(saving_lib._SAVING_V3_ENABLED, \"value\", False):\n                 has_overridden_compile = cls.compile != Model.compile\n                 has_overridden_from_config = (\n                     cls.from_config.__func__.__qualname__\n\n@@ -278,7 +278,7 @@ class LossFunctionWrapper(Loss):\n                 backend.eval(v) if tf_utils.is_tensor_or_variable(v) else v\n             )\n \n-        if saving_lib._SAVING_V3_ENABLED.value:\n+        if getattr(saving_lib._SAVING_V3_ENABLED, \"value\", False):\n             config[\"fn\"] = generic_utils.get_registered_name(self.fn)\n \n         base_config = super().get_config()\n@@ -294,7 +294,7 @@ class LossFunctionWrapper(Loss):\n         Returns:\n             A `keras.losses.Loss` instance.\n         \"\"\"\n-        if saving_lib._SAVING_V3_ENABLED.value:\n+        if getattr(saving_lib._SAVING_V3_ENABLED, \"value\", False):\n             fn_name = config.pop(\"fn\", None)\n             if fn_name and cls is LossFunctionWrapper:\n                 config[\"fn\"] = get(fn_name)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2ed044d06d0ae552477672aa8b778f8edafb52f1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 77 | Lines Deleted: 59 | Files Changed: 12 | Hunks: 31 | Methods Changed: 14 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 136 | Churn Cumulative: 32159 | Contributors (this commit): 164 | Commits (past 90d): 52 | Contributors (cumulative): 243 | DMM Complexity: 0.8888888888888888\n\nDIFF:\n@@ -194,7 +194,7 @@ class PreprocessingLayerTest(test_combinations.TestCase):\n         model.save(output_path, save_format=\"tf\")\n \n         with self.assertRaisesRegex(\n-            ValueError, \"Unknown layer: AddingPreprocessingLayer\"\n+            ValueError, \"Unknown layer: 'AddingPreprocessingLayer'\"\n         ):\n             _ = keras.models.load_model(output_path)\n \n\n@@ -363,7 +363,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n         if self.built:\n             return (\n                 pickle_utils.deserialize_model_from_bytecode,\n-                pickle_utils.serialize_model_as_bytecode(self),\n+                (pickle_utils.serialize_model_as_bytecode(self),),\n             )\n         else:\n             # SavedModel (and hence serialize_model_as_bytecode) only support\n@@ -378,7 +378,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     def __deepcopy__(self, memo):\n         if self.built:\n             new = pickle_utils.deserialize_model_from_bytecode(\n-                *pickle_utils.serialize_model_as_bytecode(self)\n+                pickle_utils.serialize_model_as_bytecode(self)\n             )\n             memo[id(self)] = new\n         else:\n\n@@ -76,7 +76,7 @@ class LayerSerializationTest(parameterized.TestCase, tf.test.TestCase):\n         # Because we're passing an unknown class here, deserialization should\n         # fail unless we add SerializableInt to the custom object dict.\n         with self.assertRaisesRegex(\n-            ValueError, \"Unknown config_item: SerializableInt.*\"\n+            ValueError, \"Unknown config_item: 'SerializableInt.*\"\n         ):\n             _ = keras.layers.deserialize(config)\n \n\n@@ -28,6 +28,7 @@ from keras import backend\n from keras.optimizers.optimizer_experimental import adam\n from keras.saving.experimental import saving_lib\n from keras.saving.saved_model import json_utils\n+from keras.testing_infra import test_utils\n from keras.utils import generic_utils\n from keras.utils import io_utils\n \n@@ -134,7 +135,8 @@ def my_mean_squared_error(y_true, y_pred):\n module_my_mean_squared_error = my_mean_squared_error\n \n \n-class NewSavingTest(tf.test.TestCase, parameterized.TestCase):\n+@test_utils.run_v2_only\n+class SavingV3Test(tf.test.TestCase, parameterized.TestCase):\n     def _get_subclassed_model(self):\n         subclassed_model = CustomModelX()\n         subclassed_model.compile(\n@@ -492,5 +494,4 @@ class NewSavingTest(tf.test.TestCase, parameterized.TestCase):\n \n \n if __name__ == \"__main__\":\n-    if tf.__internal__.tf2.enabled():\n     tf.test.main()\n\n@@ -134,6 +134,11 @@ def _get_class_or_fn_config(obj):\n     # All classes:\n     if hasattr(obj, \"get_config\"):\n         config = obj.get_config()\n+        if not isinstance(config, dict):\n+            raise TypeError(\n+                f\"The `get_config()` method of {obj} should return \"\n+                f\"a dict. It returned: {config}\"\n+            )\n         return serialize_dict(config)\n     else:\n         raise TypeError(\n\n@@ -22,6 +22,7 @@ from absl.testing import parameterized\n \n import keras\n from keras.saving.experimental import serialization_lib\n+from keras.testing_infra import test_utils\n \n \n def custom_fn(x):\n@@ -67,6 +68,7 @@ class NestedCustomLayer(keras.layers.Layer):\n         }\n \n \n+@test_utils.run_v2_only\n class SerializationLibTest(tf.test.TestCase, parameterized.TestCase):\n     def roundtrip(self, obj, custom_objects=None):\n         serialized = serialization_lib.serialize_keras_object(obj)\n@@ -149,5 +151,4 @@ class SerializationLibTest(tf.test.TestCase, parameterized.TestCase):\n \n \n if __name__ == \"__main__\":\n-    if tf.__internal__.tf2.enabled():\n     tf.test.main()\n\n@@ -13,70 +13,65 @@\n # limitations under the License.\n # ==============================================================================\n \"\"\"Saving utilities to support Python's Pickle protocol.\"\"\"\n-import io\n import os\n-import tarfile\n-import uuid\n+import tempfile\n \n-import numpy\n import tensorflow.compat.v2 as tf\n \n-from keras.saving import save as save_module\n+from keras.saving.experimental import saving_lib\n \n \n def deserialize_model_from_bytecode(serialized_model):\n     \"\"\"Reconstruct a Model from the output of `serialize_model_as_bytecode`.\n \n     Args:\n-        serialized_model: (np.array) return value from\n+        serialized_model: (bytes) return value from\n           `serialize_model_as_bytecode`.\n \n     Returns:\n-        keras.Model: Keras Model instance.\n+        Keras Model instance.\n     \"\"\"\n-    temp_dir = f\"ram://{uuid.uuid4()}\"\n-    b = io.BytesIO(serialized_model)\n-    with tarfile.open(fileobj=b, mode=\"r\") as archive:\n-        for name in archive.getnames():\n-            dest_path = tf.io.gfile.join(temp_dir, name)\n-            member = archive.getmember(name)\n-            tf.io.gfile.makedirs(os.path.dirname(dest_path))\n-            if member.isfile():\n-                with tf.io.gfile.GFile(dest_path, \"wb\") as f:\n-                    f.write(archive.extractfile(name).read())\n-    model = save_module.load_model(temp_dir)\n-    tf.io.gfile.rmtree(temp_dir)\n+    # Note: we don't use a RAM path for this because zipfile cannot write\n+    # to such paths.\n+    temp_dir = tempfile.mkdtemp()\n+    try:\n+        filepath = os.path.join(temp_dir, \"model.keras\")\n+        with open(filepath, \"wb\") as f:\n+            f.write(serialized_model)\n+        # When loading, direct import will work for most custom objects\n+        # though it will require get_config() to be implemented.\n+        # Some custom objects (e.g. an activation in a Dense layer,\n+        # serialized as a string by Dense.get_config()) will require\n+        # a custom_object_scope.\n+        model = saving_lib.load_model(filepath)\n+    except Exception as e:\n+        raise e\n+    else:\n         return model\n+    finally:\n+        tf.io.gfile.rmtree(temp_dir)\n \n \n def serialize_model_as_bytecode(model):\n     \"\"\"Convert a Keras Model into a bytecode representation for pickling.\n \n     Args:\n-        model: (tf.keras.Model) Keras Model instance.\n+        model: Keras Model instance.\n \n     Returns:\n-        tuple: tuple of arguments that can be sent to\n-            `deserialize_from_bytecode`.\n+        Tuple that can be read by `deserialize_from_bytecode`.\n     \"\"\"\n-    temp_dir = f\"ram://{uuid.uuid4()}\"\n-    model.save(temp_dir)\n-    b = io.BytesIO()\n-    with tarfile.open(fileobj=b, mode=\"w\") as archive:\n-        for root, dirs, filenames in tf.io.gfile.walk(temp_dir):\n-            for dirname in dirs:\n-                dest_path = tf.io.gfile.join(root, dirname)\n-                t = tarfile.TarInfo(dest_path)\n-                t.type = tarfile.DIRTYPE\n-                archive.addfile(t)\n-            for filename in filenames:\n-                dest_path = tf.io.gfile.join(root, filename)\n-                with tf.io.gfile.GFile(dest_path, \"rb\") as f:\n-                    info = tarfile.TarInfo(\n-                        name=os.path.relpath(dest_path, temp_dir)\n-                    )\n-                    info.size = f.size()\n-                    archive.addfile(tarinfo=info, fileobj=f)\n+    # Note: we don't use a RAM path for this because zipfile cannot write\n+    # to such paths.\n+    temp_dir = tempfile.mkdtemp()\n+    try:\n+        filepath = os.path.join(temp_dir, \"model.keras\")\n+        saving_lib.save_model(model, filepath)\n+        with open(filepath, \"rb\") as f:\n+            data = f.read()\n+    except Exception as e:\n+        raise e\n+    else:\n+        return data\n+    finally:\n         tf.io.gfile.rmtree(temp_dir)\n-    b.seek(0)\n-    return (numpy.asarray(memoryview(b.read())),)\n\n@@ -23,6 +23,7 @@ from keras.testing_infra import test_combinations\n from keras.testing_infra import test_utils\n \n \n+@test_utils.run_v2_only\n class TestPickleProtocol(test_combinations.TestCase):\n     \"\"\"Tests pickle protocol support.\"\"\"\n \n@@ -52,8 +53,8 @@ class TestPickleProtocol(test_combinations.TestCase):\n         model.compile(optimizer=\"sgd\", loss=\"sparse_categorical_crossentropy\")\n \n         # train\n-        x = np.random.random(size=(1000, 3))\n-        y = np.random.randint(low=0, high=2, size=(1000,))\n+        x = np.random.random(size=(10, 3))\n+        y = np.random.randint(low=0, high=2, size=(10,))\n         model.fit(x, y)  # builds model\n         y1 = model.predict(x)\n         # roundtrip with training\n\n@@ -415,7 +415,7 @@ class TestSavedModelFormatAllModes(test_combinations.TestCase):\n         )\n         model.save(saved_model_dir, save_format=\"tf\")\n         with self.assertRaisesRegex(\n-            ValueError, \"Unknown layer: LayerThatShouldFailIfNotAdded\"\n+            ValueError, \"Unknown layer: 'LayerThatShouldFailIfNotAdded'\"\n         ):\n             _ = keras_load.load(saved_model_dir)\n \n\n@@ -494,6 +494,8 @@ class SmallSubclassMLP(models.Model):\n         self, num_hidden, num_classes, use_bn=False, use_dp=False, **kwargs\n     ):\n         super().__init__(name=\"test_model\", **kwargs)\n+        self.num_hidden = num_hidden\n+        self.num_classes = num_classes\n         self.use_bn = use_bn\n         self.use_dp = use_dp\n \n@@ -513,6 +515,18 @@ class SmallSubclassMLP(models.Model):\n             x = self.bn(x)\n         return self.layer_b(x)\n \n+    def get_config(self):\n+        config = super().get_config()\n+        config.update(\n+            {\n+                \"num_hidden\": self.num_hidden,\n+                \"num_classes\": self.num_classes,\n+                \"use_bn\": self.use_bn,\n+                \"use_dp\": self.use_dp,\n+            }\n+        )\n+        return config\n+\n \n class _SmallSubclassMLPCustomBuild(models.Model):\n     \"\"\"A subclass model small MLP that uses a custom build method.\"\"\"\n\n@@ -603,9 +603,9 @@ def class_and_config_for_serialized_keras_object(\n     cls = get_registered_object(class_name, custom_objects, module_objects)\n     if cls is None:\n         raise ValueError(\n-            f\"Unknown {printable_module_name}: {class_name}. \"\n-            \"Please ensure this \"\n-            \"object is passed to the `custom_objects` argument. See \"\n+            f\"Unknown {printable_module_name}: '{class_name}'. \"\n+            \"Please ensure you are using a `keras.utils.custom_object_scope` \"\n+            \"and that this object is included in the scope. See \"\n             \"https://www.tensorflow.org/guide/keras/save_and_serialize\"\n             \"#registering_the_custom_object for details.\"\n         )\n@@ -767,9 +767,10 @@ def deserialize_keras_object(\n             obj = module_objects.get(object_name)\n             if obj is None:\n                 raise ValueError(\n-                    f\"Unknown {printable_module_name}: {object_name}. Please \"\n-                    \"ensure this object is passed to the `custom_objects` \"\n-                    \"argument. See \"\n+                    f\"Unknown {printable_module_name}: '{object_name}'. \"\n+                    \"Please ensure you are using a \"\n+                    \"`keras.utils.custom_object_scope` \"\n+                    \"and that this object is included in the scope. See \"\n                     \"https://www.tensorflow.org/guide/keras/save_and_serialize\"\n                     \"#registering_the_custom_object for details.\"\n                 )\n\n@@ -412,7 +412,7 @@ class SerializeKerasObjectTest(tf.test.TestCase):\n         layer = CustomLayer()\n         config = keras.utils.generic_utils.serialize_keras_object(layer)\n         with self.assertRaisesRegexp(\n-            ValueError, \"passed to the `custom_objects` arg\"\n+            ValueError, \"using a `keras.utils.custom_object_scope`\"\n         ):\n             keras.utils.generic_utils.deserialize_keras_object(config)\n         restored = keras.utils.generic_utils.deserialize_keras_object(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#571d8786df580d6daa5c57c77b5b15a125631c8f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 38 | Lines Deleted: 7 | Files Changed: 2 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 5/4 | Churn Δ: 45 | Churn Cumulative: 1640 | Contributors (this commit): 9 | Commits (past 90d): 45 | Contributors (cumulative): 14 | DMM Complexity: 1.0\n\nDIFF:\n@@ -692,16 +692,35 @@ class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):\n                 )\n         return cls(**config)\n \n-    @doc_controls.do_not_generate_docs\n     def variables(self):\n-        \"\"\"Returns variables of this Optimizer.\n-\n-        We override the `variable` property method of `tf.Module` for the\n-        sake of backward compatibility with `optimizer_v2.Optimizer`'s\n-        `variable()` method.\n-        \"\"\"\n+        \"\"\"Returns variables of this optimizer.\"\"\"\n         return self._variables\n \n+    def set_weights(self, weights):\n+        \"\"\"Set the weights of the optimizer.\n+\n+        Args:\n+            weights: a list of `tf.Variable`s or numpy arrays, the target values\n+                of optimizer variables. It should have the same order as\n+                `self._variables`.\n+        \"\"\"\n+        if not getattr(self, \"_built\", False):\n+            raise ValueError(\n+                \"You are calling `set_weights()` on an optimizer that has not \"\n+                \"yet been built. Please call \"\n+                \"`optimizer.build(trainable_variables)` to create the \"\n+                \"optimizer weights before calling `set_weights()`.\"\n+            )\n+\n+        for variable, weight in zip(self._variables, weights):\n+            if variable.shape != weight.shape:\n+                raise ValueError(\n+                    f\"Optimizer variable {self._var_key(variable)} has shape \"\n+                    f\"{str(variable.shape)} not compatible with provided \"\n+                    f\"weight shape {str(weight.shape)}.\"\n+                )\n+            variable.assign(weight)\n+\n     def _get_state(self):\n         \"\"\"Get the state of this optimizer object.\"\"\"\n         result = {}\n\n@@ -211,6 +211,18 @@ class OptimizerFuntionalityTest(tf.test.TestCase, parameterized.TestCase):\n             ],\n         )\n \n+    def testSetWeights(self):\n+        x = tf.Variable([[1.0, 2.0], [3.0, 4.0]], dtype=tf.float32)\n+        optimizer_1 = adam_new.Adam()\n+        grads = tf.convert_to_tensor([[1.0, 2.0], [3.0, 4.0]])\n+        optimizer_1.apply_gradients(zip([grads], [x]))\n+        optimizer_2 = adam_new.Adam()\n+        with self.assertRaisesRegex(ValueError, \"You are calling*\"):\n+            optimizer_2.set_weights(optimizer_1.variables())\n+        optimizer_2.build([x])\n+        optimizer_2.set_weights(optimizer_1.variables())\n+        self.assertAllClose(optimizer_1.variables(), optimizer_2.variables())\n+\n     def testSetLearningRate(self):\n         optimizer = adam_new.Adam(learning_rate=1.0)\n         self.assertIsInstance(optimizer._learning_rate, tf.Variable)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#05d90d2a6931b5a583579cd2ef2e6932919afa63", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 9 | Churn Cumulative: 9303 | Contributors (this commit): 110 | Commits (past 90d): 14 | Contributors (cumulative): 110 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1946,6 +1946,10 @@ class EarlyStopping(Callback):\n           of the performance relative to the `baseline`. If no epoch\n           improves on `baseline`, training will run for `patience`\n           epochs and restore weights from the best epoch in that set.\n+      start_from_epoch: Number of initial epochs to wait before starting\n+          to monitor improvement. This allows a warm-up period in which\n+          no improvement is expected and thus training will not be stopped.\n+\n \n     Example:\n \n@@ -1970,6 +1974,7 @@ class EarlyStopping(Callback):\n         mode=\"auto\",\n         baseline=None,\n         restore_best_weights=False,\n+        start_from_epoch=0,\n     ):\n         super().__init__()\n \n@@ -1982,6 +1987,7 @@ class EarlyStopping(Callback):\n         self.stopped_epoch = 0\n         self.restore_best_weights = restore_best_weights\n         self.best_weights = None\n+        self.start_from_epoch = start_from_epoch\n \n         if mode not in [\"auto\", \"min\", \"max\"]:\n             logging.warning(\n@@ -2019,7 +2025,8 @@ class EarlyStopping(Callback):\n \n     def on_epoch_end(self, epoch, logs=None):\n         current = self.get_monitor_value(logs)\n-        if current is None:\n+        if current is None or epoch <= self.start_from_epoch:\n+            # If no monitor value exists or still in initial warm-up stage.\n             return\n         if self.restore_best_weights and self.best_weights is None:\n             # Restore the weights after first epoch if no progress is ever made.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c492e45a017ecff5196a45d962d1618cac89467a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 40 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 40 | Churn Cumulative: 6357 | Contributors (this commit): 21 | Commits (past 90d): 5 | Contributors (cumulative): 21 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1869,6 +1869,46 @@ class KerasCallbacksTest(test_combinations.TestCase):\n         self.assertEqual(epochs_trained, 5)\n         self.assertEqual(early_stop.model.get_weights(), 2)\n \n+    def test_EarlyStopping_with_start_from_epoch(self):\n+        with self.cached_session():\n+            np.random.seed(1337)\n+\n+            (data, labels), _ = test_utils.get_test_data(\n+                train_samples=100,\n+                test_samples=50,\n+                input_shape=(1,),\n+                num_classes=NUM_CLASSES,\n+            )\n+            model = test_utils.get_small_sequential_mlp(\n+                num_hidden=1, num_classes=1, input_dim=1\n+            )\n+            model.compile(\n+                optimizer=\"sgd\", loss=\"binary_crossentropy\", metrics=[\"acc\"]\n+            )\n+            start_from_epoch = 2\n+            patience = 3\n+            stopper = keras.callbacks.EarlyStopping(\n+                monitor=\"acc\",\n+                patience=patience,\n+                start_from_epoch=start_from_epoch,\n+            )\n+            hist = model.fit(\n+                data, labels, callbacks=[stopper], verbose=0, epochs=20\n+            )\n+            assert len(hist.epoch) >= patience + start_from_epoch\n+\n+            start_from_epoch = 2\n+            patience = 0\n+            stopper = keras.callbacks.EarlyStopping(\n+                monitor=\"acc\",\n+                patience=patience,\n+                start_from_epoch=start_from_epoch,\n+            )\n+            hist = model.fit(\n+                data, labels, callbacks=[stopper], verbose=0, epochs=20\n+            )\n+            assert len(hist.epoch) >= start_from_epoch\n+\n     def test_RemoteMonitor(self):\n         if requests is None:\n             self.skipTest(\"`requests` required to run this test\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d568b3071d5a1475596fb2f9eafd6f08a8937371", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 9305 | Contributors (this commit): 110 | Commits (past 90d): 15 | Contributors (cumulative): 110 | DMM Complexity: None\n\nDIFF:\n@@ -1946,7 +1946,7 @@ class EarlyStopping(Callback):\n           of the performance relative to the `baseline`. If no epoch\n           improves on `baseline`, training will run for `patience`\n           epochs and restore weights from the best epoch in that set.\n-      start_from_epoch: Number of initial epochs to wait before starting\n+      start_from_epoch: Number of epochs to wait before starting\n           to monitor improvement. This allows a warm-up period in which\n           no improvement is expected and thus training will not be stopped.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b7f641961f58876a326d5f94762ad1ae2e83022c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 1422 | Contributors (this commit): 7 | Commits (past 90d): 2 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -186,8 +186,10 @@ class RNN(base_layer.Layer):\n     Examples:\n \n     ```python\n-    # First, let's define a RNN Cell, as a layer subclass.\n+    from keras.layers import RNN\n+    from keras import backend\n \n+    # First, let's define a RNN Cell, as a layer subclass.\n     class MinimalRNNCell(keras.layers.Layer):\n \n         def __init__(self, units, **kwargs):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1a94dee878ab85f90a65fb3f195e3cec41fde708", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 61 | Lines Deleted: 104 | Files Changed: 3 | Hunks: 19 | Methods Changed: 8 | Complexity Δ (Sum/Max): -6/1 | Churn Δ: 165 | Churn Cumulative: 24619 | Contributors (this commit): 141 | Commits (past 90d): 38 | Contributors (cumulative): 158 | DMM Complexity: 1.0\n\nDIFF:\n@@ -479,39 +479,11 @@ class Sequential(functional.Functional):\n             model.add(layer)\n \n         if getattr(saving_lib._SAVING_V3_ENABLED, \"value\", False):\n-            # Grab the information from the `config` for `compile()` and\n-            # `build()`.\n-            is_compiled = config.pop(\"is_compiled\", False)\n-            optimizer, loss = None, None\n-            optimizer_dict = config.pop(\"optimizer\", {})\n-            if optimizer_dict:\n-                optimizer = saving_lib.deserialize_keras_object(\n-                    optimizer_dict, custom_objects\n+            compile_config = config.get(\"compile_config\", None)\n+            if compile_config is not None:\n+                model._compile_from_config(\n+                    compile_config, base_class=Sequential\n                 )\n-            loss_dict = config.pop(\"loss\", {})\n-            if loss_dict:\n-                loss = saving_lib.deserialize_keras_object(\n-                    loss_dict, custom_objects\n-                )\n-\n-            has_overridden_compile = cls.compile != Sequential.compile\n-            has_overridden_from_config = (\n-                cls.from_config.__func__.__qualname__\n-                != Sequential.from_config.__func__.__qualname__\n-            )\n-            if has_overridden_compile and (not has_overridden_from_config):\n-                logging.warning(\n-                    \"`compile()` was not called as part of model loading \"\n-                    \"because the model's `compile()` method is custom. \"\n-                    \"All subclassed Models that have `compile()` \"\n-                    \"overridden should also override `from_config()` in order \"\n-                    \"to call `compile()`. Alternatively, you can call \"\n-                    \"`compile()` manually after loading.\"\n-                )\n-\n-            if (not has_overridden_compile) and is_compiled:\n-                # TODO(rchao): Handle other compile args.\n-                model.compile(optimizer=optimizer, loss=loss)\n \n         if (\n             not model.inputs\n\n@@ -3072,40 +3072,20 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n         # they don't override `from_config()`, which would use `cls(**config)`\n         # as a result.\n         config = {}\n-\n         if getattr(saving_lib._SAVING_V3_ENABLED, \"value\", False):\n-            config[\"is_compiled\"] = self._is_compiled\n-            if self.optimizer:\n-                config[\"optimizer\"] = saving_lib.serialize_keras_object(\n-                    self.optimizer\n-                )\n-            if self.compiled_loss:\n-                config[\"loss\"] = saving_lib.serialize_keras_object(\n-                    self.compiled_loss\n+            if self._is_compiled:\n+                compile_config = self._get_compile_args()\n+                config[\"compile_config\"] = saving_lib.serialize_keras_object(\n+                    compile_config\n                 )\n             if self.built:\n-                config[\"input_shape\"] = self._build_input_shape\n-\n+                config[\"build_input_shape\"] = self._build_input_shape\n         return config\n \n     @classmethod\n     def from_config(cls, config, custom_objects=None):\n-\n-        # Grab the information from the `config` for `compile()` and\n-        # `build()`.\n-        is_compiled = config.pop(\"is_compiled\", False)\n-        optimizer, loss = None, None\n-        optimizer_dict = config.pop(\"optimizer\", {})\n-        if optimizer_dict:\n-            optimizer = saving_lib.deserialize_keras_object(\n-                optimizer_dict, custom_objects\n-            )\n-        loss_dict = config.pop(\"loss\", {})\n-        if loss_dict:\n-            loss = saving_lib.deserialize_keras_object(\n-                loss_dict, custom_objects\n-            )\n-        input_shape = config.pop(\"input_shape\", {})\n+        compile_config = config.pop(\"compile_config\", None)\n+        build_input_shape = config.pop(\"build_input_shape\", {})\n \n         # `from_config` assumes `cls` is either `Functional` or a child class of\n         # `Functional`. In the case that `cls` is meant to behave like a child\n@@ -3151,27 +3131,10 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n                     )\n \n             if getattr(saving_lib._SAVING_V3_ENABLED, \"value\", False):\n-                has_overridden_compile = cls.compile != Model.compile\n-                has_overridden_from_config = (\n-                    cls.from_config.__func__.__qualname__\n-                    != Model.from_config.__func__.__qualname__\n-                )\n-\n-                if has_overridden_compile and (not has_overridden_from_config):\n-                    logging.warning(\n-                        \"`compile()` was not called as part of model loading \"\n-                        \"because the model's `compile()` method is custom. \"\n-                        \"All subclassed Models that have `compile()` \"\n-                        \"overridden should also override `from_config()` in \"\n-                        \"order to call `compile()`. Alternatively, you can \"\n-                        \"call `compile()` manually after loading.\"\n-                    )\n-                elif (not has_overridden_compile) and is_compiled:\n-                    # TODO(rchao): Handle other compile args.\n-                    model.compile(optimizer=optimizer, loss=loss)\n-\n-                if input_shape:\n-                    model.build(input_shape)\n+                if build_input_shape:\n+                    model.build(build_input_shape)\n+                if compile_config is not None:\n+                    model._compile_from_config(compile_config, base_class=Model)\n \n             return model\n \n@@ -3791,6 +3754,27 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n                 f\"type {type(validation_freq)}.\"\n             )\n \n+    def _compile_from_config(self, compile_config, base_class):\n+        has_overridden_compile = self.__class__.compile != base_class.compile\n+        has_overridden_from_config = (\n+            self.__class__.from_config.__func__.__qualname__\n+            != base_class.from_config.__func__.__qualname__\n+        )\n+\n+        if not has_overridden_compile:\n+            compile_config = saving_lib.deserialize_keras_object(compile_config)\n+            self.compile(**compile_config)\n+        else:\n+            if not has_overridden_from_config:\n+                logging.warning(\n+                    \"`compile()` was not called as part of model loading \"\n+                    \"because the model's `compile()` method is custom. \"\n+                    \"All subclassed Models that have `compile()` \"\n+                    \"overridden should also override `from_config()` in \"\n+                    \"order to call `compile()`. Alternatively, you can \"\n+                    \"call `compile()` manually after loading.\"\n+                )\n+\n     ######################################################################\n     # Functions below exist only as v1 / v2 compatibility shims.\n     ######################################################################\n@@ -3807,23 +3791,23 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n         \"\"\"\n         self._assert_compile_was_called()\n \n-        saved_metrics = self.compiled_metrics._user_metrics\n-        saved_weighted_metrics = self.compiled_metrics._user_weighted_metrics\n+        compile_args = {}\n+        if self.compiled_metrics:\n+            if user_metrics:\n+                metrics = self.compiled_metrics._user_metrics\n+                weighted_metrics = self.compiled_metrics._user_weighted_metrics\n+            else:\n+                metrics = self.compiled_metrics._metrics\n+                weighted_metrics = self.compiled_metrics._weighted_metrics\n+            compile_args[\"metrics\"] = metrics\n+            compile_args[\"weighted_metrics\"] = weighted_metrics\n \n-        if not user_metrics:\n-            if saved_metrics is not None:\n-                saved_metrics = self.compiled_metrics._metrics\n-            if saved_weighted_metrics is not None:\n-                saved_weighted_metrics = self.compiled_metrics._weighted_metrics\n-\n-        compile_args = {\n-            \"optimizer\": self.optimizer,\n-            \"loss\": self.compiled_loss._user_losses,\n-            \"metrics\": saved_metrics,\n-            \"weighted_metrics\": saved_weighted_metrics,\n-            \"loss_weights\": self.compiled_loss._user_loss_weights,\n-        }\n+        if self.compiled_loss:\n+            compile_args[\"loss\"] = self.compiled_loss._user_losses\n+            compile_args[\"loss_weights\"] = self.compiled_loss._user_loss_weights\n \n+        if hasattr(self, \"optimizer\"):\n+            compile_args[\"optimizer\"] = self.optimizer\n         return compile_args\n \n     def _get_callback_model(self):\n\n@@ -109,7 +109,7 @@ class CompileOverridingModel(keras.Model):\n         self.dense1 = MyDense(1)\n \n     def compile(self, some_random_arg):\n-        pass\n+        self._is_compiled = True\n \n     def call(self, inputs):\n         return self.dense1(inputs)\n@@ -120,7 +120,7 @@ class CompileOverridingModel(keras.Model):\n )\n class CompileOverridingSequential(keras.Sequential):\n     def compile(self, some_random_arg):\n-        pass\n+        self._is_compiled = True\n \n \n @keras.utils.generic_utils.register_keras_serializable(\n@@ -337,19 +337,17 @@ class SavingV3Test(tf.test.TestCase, parameterized.TestCase):\n             config_dict[\"registered_name\"], \"my_custom_package>CustomModelX\"\n         )\n         self.assertEqual(\n-            config_dict[\"config\"][\"optimizer\"][\"module\"],\n+            config_dict[\"config\"][\"compile_config\"][\"optimizer\"][\"module\"],\n             \"keras.optimizers.experimental\",\n         )\n         self.assertEqual(\n-            config_dict[\"config\"][\"optimizer\"][\"class_name\"],\n+            config_dict[\"config\"][\"compile_config\"][\"optimizer\"][\"class_name\"],\n             \"Adam\",\n         )\n+        self.assertLen(config_dict[\"config\"][\"compile_config\"][\"loss\"], 4)\n         self.assertEqual(\n-            config_dict[\"config\"][\"loss\"][\"module\"],\n-            \"keras.engine.compile_utils\",\n-        )\n-        self.assertEqual(\n-            config_dict[\"config\"][\"loss\"][\"class_name\"], \"LossesContainer\"\n+            config_dict[\"config\"][\"compile_config\"][\"loss\"][0],\n+            \"mse\",\n         )\n \n     @tf.__internal__.distribute.combinations.generate(\n@@ -471,10 +469,13 @@ class SavingV3Test(tf.test.TestCase, parameterized.TestCase):\n                 [keras.layers.Embedding(4, 1), MyDense(1), MyDense(1)]\n             )\n         )\n+        model.compile(None)\n         model._save_experimental(temp_filepath)\n \n         with mock.patch.object(logging, \"warning\") as mock_warn:\n             saving_lib.load_model(temp_filepath)\n+        if not mock_warn.call_args_list:\n+            raise AssertionError(\"Did not warn.\")\n         self.assertIn(\n             \"`compile()` was not called as part of model loading \"\n             \"because the model's `compile()` method is custom. \",\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c10e73e39656ebb381dbdc6dc2aaece3dfe45dcd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 9 | Files Changed: 1 | Hunks: 8 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 23 | Churn Cumulative: 6380 | Contributors (this commit): 21 | Commits (past 90d): 6 | Contributors (cumulative): 21 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1872,15 +1872,17 @@ class KerasCallbacksTest(test_combinations.TestCase):\n     def test_EarlyStopping_with_start_from_epoch(self):\n         with self.cached_session():\n             np.random.seed(1337)\n-\n             (data, labels), _ = test_utils.get_test_data(\n-                train_samples=100,\n-                test_samples=50,\n-                input_shape=(1,),\n+                train_samples=TRAIN_SAMPLES,\n+                test_samples=TEST_SAMPLES,\n+                input_shape=(INPUT_DIM,),\n                 num_classes=NUM_CLASSES,\n             )\n+            labels = np_utils.to_categorical(labels)\n             model = test_utils.get_small_sequential_mlp(\n-                num_hidden=1, num_classes=1, input_dim=1\n+                num_hidden=NUM_HIDDEN,\n+                num_classes=NUM_CLASSES,\n+                input_dim=INPUT_DIM,\n             )\n             model.compile(\n                 optimizer=\"sgd\", loss=\"binary_crossentropy\", metrics=[\"acc\"]\n@@ -1892,10 +1894,12 @@ class KerasCallbacksTest(test_combinations.TestCase):\n                 patience=patience,\n                 start_from_epoch=start_from_epoch,\n             )\n-            hist = model.fit(\n+            history = model.fit(\n                 data, labels, callbacks=[stopper], verbose=0, epochs=20\n             )\n-            assert len(hist.epoch) >= patience + start_from_epoch\n+            # Test 'patience' argument functions correctly when used\n+            # in conjunction with 'start_from_epoch'.\n+            assert len(history.epoch) >= patience + start_from_epoch\n \n             start_from_epoch = 2\n             patience = 0\n@@ -1904,10 +1908,11 @@ class KerasCallbacksTest(test_combinations.TestCase):\n                 patience=patience,\n                 start_from_epoch=start_from_epoch,\n             )\n-            hist = model.fit(\n+            history = model.fit(\n                 data, labels, callbacks=[stopper], verbose=0, epochs=20\n             )\n-            assert len(hist.epoch) >= start_from_epoch\n+            # Test for boundary condition when 'patience' = 0.\n+            assert len(history.epoch) >= start_from_epoch\n \n     def test_RemoteMonitor(self):\n         if requests is None:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8f4970c0b10af5aa921c9801e47beaa0cb42c270", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 10781 | Contributors (this commit): 22 | Commits (past 90d): 13 | Contributors (cumulative): 22 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1974,7 +1974,9 @@ class RandomGenerator(tf.__internal__.tracking.AutoTrackable):\n         elif self._rng_type == self.RNG_STATEFUL:\n             with tf_utils.maybe_init_scope(self):\n                 seed = self._create_seed(self._seed)\n-                self._generator = tf.random.Generator.from_seed(seed)\n+                self._generator = tf.random.Generator.from_seed(\n+                    seed, alg=tf.random.Algorithm.AUTO_SELECT\n+                )\n         else:\n             # In legacy stateful, we use stateful op, regardless whether user\n             # provide seed or not. Seeded stateful op will ensure generating\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#584c3dd400af7c3a9699e3a97ce79b6a6eb486b0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 4 | Hunks: 4 | Methods Changed: 4 | Complexity Δ (Sum/Max): 4/1 | Churn Δ: 8 | Churn Cumulative: 2083 | Contributors (this commit): 9 | Commits (past 90d): 5 | Contributors (cumulative): 23 | DMM Complexity: None\n\nDIFF:\n@@ -305,7 +305,7 @@ class Conv(Layer):\n                         outputs, self.bias, data_format=self._tf_data_format\n                     )\n \n-        if not tf.executing_eagerly():\n+        if not tf.executing_eagerly() and input_shape.rank:\n             # Infer the static output shape:\n             out_shape = self.compute_output_shape(input_shape)\n             outputs.set_shape(out_shape)\n\n@@ -256,7 +256,7 @@ class Conv1DTranspose(Conv1D):\n             dilations=self.dilation_rate,\n         )\n \n-        if not tf.executing_eagerly():\n+        if not tf.executing_eagerly() and inputs.shape.rank:\n             # Infer the static output shape:\n             out_shape = self.compute_output_shape(inputs.shape)\n             outputs.set_shape(out_shape)\n\n@@ -303,7 +303,7 @@ class Conv2DTranspose(Conv2D):\n             dilation_rate=self.dilation_rate,\n         )\n \n-        if not tf.executing_eagerly():\n+        if not tf.executing_eagerly() and inputs.shape.rank:\n             # Infer the static output shape:\n             out_shape = self.compute_output_shape(inputs.shape)\n             outputs.set_shape(out_shape)\n\n@@ -322,7 +322,7 @@ class Conv3DTranspose(Conv3D):\n             padding=self.padding.upper(),\n         )\n \n-        if not tf.executing_eagerly():\n+        if not tf.executing_eagerly() and inputs.shape.rank:\n             # Infer the static output shape:\n             out_shape = self.compute_output_shape(inputs.shape)\n             outputs.set_shape(out_shape)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
