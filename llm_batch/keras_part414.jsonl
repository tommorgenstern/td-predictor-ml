{"custom_id": "keras#685f2abecf8f532fc085887af5b890a56ce39b25", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 5 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 14 | Churn Cumulative: 10069 | Contributors (this commit): 30 | Commits (past 90d): 8 | Contributors (cumulative): 30 | DMM Complexity: 0.0\n\nDIFF:\n@@ -4152,20 +4152,28 @@ def sparse_top_k_categorical_accuracy(y_true, y_pred, k=5):\n   Returns:\n     Sparse top K categorical accuracy value.\n   \"\"\"\n+  reshape_matches = False\n   y_pred_rank = tf.convert_to_tensor(y_pred).shape.ndims\n-  y_true_rank = tf.convert_to_tensor(y_true).shape.ndims\n+  y_true_org_shape = tf.convert_to_tensor(y_true).shape\n+  y_true_rank = y_true_org_shape.ndims\n   # Flatten y_pred to (batch_size, num_samples) and y_true to (num_samples,)\n   if (y_true_rank is not None) and (y_pred_rank is not None):\n     if y_pred_rank > 2:\n       y_pred = tf.reshape(y_pred, [-1, y_pred.shape[-1]])\n     if y_true_rank > 1:\n+      reshape_matches = True\n       y_true = tf.reshape(y_true, [-1])\n \n-  return tf.cast(\n-      tf.math.in_top_k(\n+  matches = tf.cast(tf.math.in_top_k(\n                       predictions=y_pred, targets=tf.cast(y_true, 'int32'), k=k),\n                       dtype=backend.floatx())\n   \n+  # returned matches is expected to have same shape as y_true input\n+  if reshape_matches:\n+    return tf.reshape(matches, shape=y_true_org_shape)\n+\n+  return matches\n+\n \n def cosine_proximity(y_true, y_pred, axis=-1):\n   \"\"\"Computes the cosine similarity between labels and predictions.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c223693db91473c9a71c330d4e38a751d149f93c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 901 | Lines Deleted: 1 | Files Changed: 3 | Hunks: 5 | Methods Changed: 23 | Complexity Δ (Sum/Max): 58/58 | Churn Δ: 902 | Churn Cumulative: 1339 | Contributors (this commit): 6 | Commits (past 90d): 6 | Contributors (cumulative): 12 | DMM Complexity: 0.6189555125725339\n\nDIFF:\n@@ -35,6 +35,7 @@ from keras.applications import resnet_v2\n from keras.applications import vgg16\n from keras.applications import vgg19\n from keras.applications import xception\n+from keras.applications import resnet_rs\n from keras.preprocessing import image\n from keras.utils import data_utils\n \n@@ -71,6 +72,8 @@ ARG_TO_MODEL = {\n         efficientnet_v2.EfficientNetV2S, efficientnet_v2.EfficientNetV2M,\n         efficientnet_v2.EfficientNetV2L\n     ]),\n+    'resnet_rs':(resnet_rs,[resnet_rs.ResNetRS50,resnet_rs.ResNetRS101,resnet_rs.ResNetRS152,\n+    resnet_rs.ResNetRS200,resnet_rs.ResNetRS270,resnet_rs.ResNetRS350,resnet_rs.ResNetRS420]),\n     'regnet': (regnet, [\n         regnet.RegNetX002, regnet.RegNetX004, regnet.RegNetX006,\n         regnet.RegNetX008, regnet.RegNetX016, regnet.RegNetX032,\n\n@@ -34,6 +34,7 @@ from keras.applications import resnet_v2\n from keras.applications import vgg16\n from keras.applications import vgg19\n from keras.applications import xception\n+from keras.applications import resnet_rs\n \n \n MODEL_LIST_NO_NASNET = [(resnet.ResNet50, 2048), (resnet.ResNet101, 2048),\n@@ -76,7 +77,12 @@ MODEL_LIST_NO_NASNET = [(resnet.ResNet50, 2048), (resnet.ResNet101, 2048),\n                         (regnet.RegNetY016, 888), (regnet.RegNetY032, 1512),\n                         (regnet.RegNetY040, 1088), (regnet.RegNetY064, 1296),\n                         (regnet.RegNetY080, 2016), (regnet.RegNetY120, 2240),\n-                        (regnet.RegNetY160, 3024), (regnet.RegNetY320, 3712)]\n+                        (regnet.RegNetY160, 3024), (regnet.RegNetY320, 3712),\n+                        (resnet_rs.ResNetRS50,2048),(resnet_rs.ResNetRS101,2048),\n+                        (resnet_rs.ResNetRS152,2048),(resnet_rs.ResNetRS200,2048),\n+                        (resnet_rs.ResNetRS270,2048),(resnet_rs.ResNetRS350,2048),\n+                        (resnet_rs.ResNetRS420,2048)\n+                        ]\n \n NASNET_LIST = [\n     (nasnet.NASNetMobile, 1056),\n\n@@ -0,0 +1,891 @@\n+# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+# pylint: disable=invalid-name\n+# pylint: disable=missing-function-docstring\n+\"\"\"ResNet-RS models for Keras.\n+\n+Reference:\n+- [Revisiting ResNets: Improved Training and Scaling Strategies](\n+    https://arxiv.org/pdf/2103.07579.pdf)\n+\"\"\"\n+import sys\n+from keras import backend\n+from keras.utils import data_utils\n+from keras.utils import layer_utils\n+from keras import layers\n+from keras.engine import training\n+from keras.applications import imagenet_utils\n+import tensorflow.compat.v2 as tf\n+from typing import Callable, Dict, List, Union\n+from tensorflow.python.util.tf_export import keras_export\n+\n+\n+BASE_WEIGHTS_URL = (\n+    \"https://github.com/sebastian-sz/resnet-rs-keras/releases/download/v1.0/\"\n+)\n+\n+WEIGHT_HASHES = {\n+    \"resnet-rs-101-i160.h5\": \"544b3434d00efc199d66e9058c7f3379\",\n+    \"resnet-rs-101-i160_notop.h5\": \"82d5b90c5ce9d710da639d6216d0f979\",\n+    \"resnet-rs-101-i192.h5\": \"eb285be29ab42cf4835ff20a5e3b5d23\",\n+    \"resnet-rs-101-i192_notop.h5\": \"f9a0f6b85faa9c3db2b6e233c4eebb5b\",\n+    \"resnet-rs-152-i192.h5\": \"8d72a301ed8a6f11a47c4ced4396e338\",\n+    \"resnet-rs-152-i192_notop.h5\": \"5fbf7ac2155cb4d5a6180ee9e3aa8704\",\n+    \"resnet-rs-152-i224.h5\": \"31a46a92ab21b84193d0d71dd8c3d03b\",\n+    \"resnet-rs-152-i224_notop.h5\": \"dc8b2cba2005552eafa3167f00dc2133\",\n+    \"resnet-rs-152-i256.h5\": \"ba6271b99bdeb4e7a9b15c05964ef4ad\",\n+    \"resnet-rs-152-i256_notop.h5\": \"fa79794252dbe47c89130f65349d654a\",\n+    \"resnet-rs-200-i256.h5\": \"a76930b741884e09ce90fa7450747d5f\",\n+    \"resnet-rs-200-i256_notop.h5\": \"bbdb3994718dfc0d1cd45d7eff3f3d9c\",\n+    \"resnet-rs-270-i256.h5\": \"20d575825ba26176b03cb51012a367a8\",\n+    \"resnet-rs-270-i256_notop.h5\": \"2c42ecb22e35f3e23d2f70babce0a2aa\",\n+    \"resnet-rs-350-i256.h5\": \"f4a039dc3c421321b7fc240494574a68\",\n+    \"resnet-rs-350-i256_notop.h5\": \"6e44b55025bbdff8f51692a023143d66\",\n+    \"resnet-rs-350-i320.h5\": \"7ccb858cc738305e8ceb3c0140bee393\",\n+    \"resnet-rs-350-i320_notop.h5\": \"ab0c1f9079d2f85a9facbd2c88aa6079\",\n+    \"resnet-rs-420-i320.h5\": \"ae0eb9bed39e64fc8d7e0db4018dc7e8\",\n+    \"resnet-rs-420-i320_notop.h5\": \"fe6217c32be8305b1889657172b98884\",\n+    \"resnet-rs-50-i160.h5\": \"69d9d925319f00a8bdd4af23c04e4102\",\n+    \"resnet-rs-50-i160_notop.h5\": \"90daa68cd26c95aa6c5d25451e095529\",\n+}\n+\n+DEPTH_TO_WEIGHT_VARIANTS = {\n+    50: [160],\n+    101: [160, 192],\n+    152: [192, 224, 256],\n+    200: [256],\n+    270: [256],\n+    350: [256, 320],\n+    420: [320],\n+}\n+BLOCK_ARGS = {\n+    50: [\n+        {\"input_filters\": 64, \"num_repeats\": 3},\n+        {\"input_filters\": 128, \"num_repeats\": 4},\n+        {\"input_filters\": 256, \"num_repeats\": 6},\n+        {\"input_filters\": 512, \"num_repeats\": 3},\n+    ],\n+    101: [\n+        {\"input_filters\": 64, \"num_repeats\": 3},\n+        {\"input_filters\": 128, \"num_repeats\": 4},\n+        {\"input_filters\": 256, \"num_repeats\": 23},\n+        {\"input_filters\": 512, \"num_repeats\": 3},\n+    ],\n+    152: [\n+        {\"input_filters\": 64, \"num_repeats\": 3},\n+        {\"input_filters\": 128, \"num_repeats\": 8},\n+        {\"input_filters\": 256, \"num_repeats\": 36},\n+        {\"input_filters\": 512, \"num_repeats\": 3},\n+    ],\n+    200: [\n+        {\"input_filters\": 64, \"num_repeats\": 3},\n+        {\"input_filters\": 128, \"num_repeats\": 24},\n+        {\"input_filters\": 256, \"num_repeats\": 36},\n+        {\"input_filters\": 512, \"num_repeats\": 3},\n+    ],\n+    270: [\n+        {\"input_filters\": 64, \"num_repeats\": 4},\n+        {\"input_filters\": 128, \"num_repeats\": 29},\n+        {\"input_filters\": 256, \"num_repeats\": 53},\n+        {\"input_filters\": 512, \"num_repeats\": 4},\n+    ],\n+    350: [\n+        {\"input_filters\": 64, \"num_repeats\": 4},\n+        {\"input_filters\": 128, \"num_repeats\": 36},\n+        {\"input_filters\": 256, \"num_repeats\": 72},\n+        {\"input_filters\": 512, \"num_repeats\": 4},\n+    ],\n+    420: [\n+        {\"input_filters\": 64, \"num_repeats\": 4},\n+        {\"input_filters\": 128, \"num_repeats\": 44},\n+        {\"input_filters\": 256, \"num_repeats\": 87},\n+        {\"input_filters\": 512, \"num_repeats\": 4},\n+    ],\n+}\n+CONV_KERNEL_INITIALIZER = {\n+    \"class_name\": \"VarianceScaling\",\n+    \"config\": {\n+        \"scale\": 2.0,\n+        \"mode\": \"fan_out\",\n+        \"distribution\": \"truncated_normal\"\n+    }\n+}\n+\n+def Conv2DFixedPadding(filters, kernel_size, strides, name):\n+    \"\"\"Conv2D block with fixed padding.\n+    \"\"\"\n+    def apply(inputs):\n+        if strides > 1:\n+            inputs = fixed_padding(inputs, kernel_size)\n+        return layers.Conv2D(\n+            filters=filters,\n+            kernel_size=kernel_size,\n+            strides=strides,\n+            padding=\"same\" if strides == 1 else \"valid\",\n+            use_bias=False,\n+            kernel_initializer=CONV_KERNEL_INITIALIZER,\n+            name=name,\n+        )(inputs)\n+    return apply\n+\n+def STEM(bn_momentum: float, bn_epsilon: float, activation: str):\n+    \"\"\"ResNet-D type STEM block.\"\"\"\n+\n+    def apply(inputs):\n+        bn_axis = 3 if backend.image_data_format() == \"channels_last\" else 1\n+\n+        # First stem block\n+        x = Conv2DFixedPadding(\n+            filters=32, kernel_size=3, strides=2, name=\"stem_conv_1\"\n+        )(inputs)\n+        x = layers.BatchNormalization(\n+            axis=bn_axis,\n+            momentum=bn_momentum,\n+            epsilon=bn_epsilon,\n+            name=\"stem_batch_norm_1\",\n+        )(x)\n+        x = layers.Activation(activation, name=\"stem_act_1\")(x)\n+\n+        # Second stem block\n+        x = Conv2DFixedPadding(\n+            filters=32, kernel_size=3, strides=1, name=\"stem_conv_2\"\n+        )(x)\n+        x = layers.BatchNormalization(\n+            axis=bn_axis,\n+            momentum=bn_momentum,\n+            epsilon=bn_epsilon,\n+            name=\"stem_batch_norm_2\",\n+        )(x)\n+        x = layers.Activation(activation, name=\"stem_act_2\")(x)\n+\n+        # Final Stem block:\n+        x = Conv2DFixedPadding(\n+            filters=64, kernel_size=3, strides=1, name=\"stem_conv_3\"\n+        )(x)\n+        x = layers.BatchNormalization(\n+            axis=bn_axis,\n+            momentum=bn_momentum,\n+            epsilon=bn_epsilon,\n+            name=\"stem_batch_norm_3\",\n+        )(x)\n+        x = layers.Activation(activation, name=\"stem_act_3\")(x)\n+\n+        # Replace stem max pool:\n+        x = Conv2DFixedPadding(\n+            filters=64, kernel_size=3, strides=2, name=\"stem_conv_4\"\n+        )(x)\n+        x = layers.BatchNormalization(\n+            axis=bn_axis,\n+            momentum=bn_momentum,\n+            epsilon=bn_epsilon,\n+            name=\"stem_batch_norm_4\",\n+        )(x)\n+        x = layers.Activation(activation, name=\"stem_act_4\")(x)\n+        return x\n+\n+    return apply\n+\n+\n+def SE(in_filters: int, se_ratio: float, name: str, expand_ratio: int = 1):\n+    \"\"\"Squeeze and Excitation block.\"\"\"\n+    bn_axis = 3 if backend.image_data_format() == \"channels_last\" else 1\n+\n+    def apply(inputs):\n+        x = layers.GlobalAveragePooling2D(name=name + \"se_squeeze\")(inputs)\n+        if bn_axis == 1:\n+            se_shape = (x.shape[-1], 1, 1)\n+        else:\n+            se_shape = (1, 1, x.shape[-1])\n+        x = layers.Reshape(se_shape, name=name + \"se_reshape\")(x)\n+\n+        num_reduced_filters = max(1, int(in_filters * 4 * se_ratio))\n+\n+        x = layers.Conv2D(\n+            filters=num_reduced_filters,\n+            kernel_size=[1, 1],\n+            strides=[1, 1],\n+            kernel_initializer=CONV_KERNEL_INITIALIZER,\n+            padding=\"same\",\n+            use_bias=True,\n+            activation=\"relu\",\n+            name=name + \"se_reduce\",\n+        )(x)\n+\n+        x = layers.Conv2D(\n+            filters=4 * in_filters * expand_ratio,  # Expand ratio is 1 by default\n+            kernel_size=[1, 1],\n+            strides=[1, 1],\n+            kernel_initializer=CONV_KERNEL_INITIALIZER,\n+            padding=\"same\",\n+            use_bias=True,\n+            activation=\"sigmoid\",\n+            name=name + \"se_expand\",\n+        )(x)\n+\n+        return layers.multiply([inputs, x], name=name + \"se_excite\")\n+\n+    return apply\n+\n+\n+def BottleneckBlock(\n+    filters: int,\n+    strides: int,\n+    use_projection: bool,\n+    bn_momentum: float,\n+    bn_epsilon: float,\n+    activation: str,\n+    se_ratio: float,\n+    survival_probability: float,\n+    name: str = None,\n+):\n+    \"\"\"Bottleneck block variant for residual networks with BN after convolutions.\"\"\"\n+\n+    def apply(inputs):\n+        bn_axis = 3 if backend.image_data_format() == \"channels_last\" else 1\n+\n+        shortcut = inputs\n+\n+        if use_projection:\n+            filters_out = filters * 4\n+            if strides == 2:\n+                shortcut = layers.AveragePooling2D(\n+                    pool_size=(2, 2),\n+                    strides=(2, 2),\n+                    padding=\"same\",\n+                    name=name + \"projection_pooling\",\n+                )(inputs)\n+                shortcut = Conv2DFixedPadding(\n+                    filters=filters_out,\n+                    kernel_size=1,\n+                    strides=1,\n+                    name=name + \"projection_conv\",\n+                )(shortcut)\n+            else:\n+                shortcut = Conv2DFixedPadding(\n+                    filters=filters_out,\n+                    kernel_size=1,\n+                    strides=strides,\n+                    name=name + \"projection_conv\",\n+                )(inputs)\n+\n+            shortcut = layers.BatchNormalization(\n+                axis=bn_axis,\n+                momentum=bn_momentum,\n+                epsilon=bn_epsilon,\n+                name=name + \"projection_batch_norm\",\n+            )(shortcut)\n+\n+        # First conv layer:\n+        x = Conv2DFixedPadding(\n+            filters=filters, kernel_size=1, strides=1, name=name + \"conv_1\"\n+        )(inputs)\n+        x = layers.BatchNormalization(\n+            axis=bn_axis,\n+            momentum=bn_momentum,\n+            epsilon=bn_epsilon,\n+            name=name + \"batch_norm_1\",\n+        )(x)\n+        x = layers.Activation(activation, name=name + \"act_1\")(x)\n+\n+        # Second conv layer:\n+        x = Conv2DFixedPadding(\n+            filters=filters, kernel_size=3, strides=strides, name=name + \"conv_2\"\n+        )(x)\n+        x = layers.BatchNormalization(\n+            axis=bn_axis,\n+            momentum=bn_momentum,\n+            epsilon=bn_epsilon,\n+            name=name + \"batch_norm_2\",\n+        )(x)\n+        x = layers.Activation(activation, name=name + \"act_2\")(x)\n+\n+        # Third conv layer:\n+        x = Conv2DFixedPadding(\n+            filters=filters * 4, kernel_size=1, strides=1, name=name + \"conv_3\"\n+        )(x)\n+        x = layers.BatchNormalization(\n+            axis=bn_axis,\n+            momentum=bn_momentum,\n+            epsilon=bn_epsilon,\n+            name=name + \"batch_norm_3\",\n+        )(x)\n+\n+        if 0 < se_ratio < 1:\n+            x = SE(filters, se_ratio=se_ratio, name=name)(x)\n+\n+        # Drop connect\n+        if survival_probability:\n+            x = layers.Dropout(\n+                survival_probability, noise_shape=(None, 1, 1, 1), name=name + \"drop\"\n+            )(x)\n+\n+        x = layers.Add()([x, shortcut])\n+\n+        return layers.Activation(activation, name=name + \"output_act\")(x)\n+\n+    return apply\n+\n+\n+def BlockGroup(\n+    filters,\n+    strides,\n+    se_ratio,\n+    bn_epsilon,\n+    bn_momentum,\n+    num_repeats,\n+    activation,\n+    survival_probability: float,\n+    name: str,\n+):\n+    \"\"\"Create one group of blocks for the ResNet model.\"\"\"\n+\n+    def apply(inputs):\n+        # Only the first block per block_group uses projection shortcut and strides.\n+        x = BottleneckBlock(\n+            filters=filters,\n+            strides=strides,\n+            use_projection=True,\n+            se_ratio=se_ratio,\n+            bn_epsilon=bn_epsilon,\n+            bn_momentum=bn_momentum,\n+            activation=activation,\n+            survival_probability=survival_probability,\n+            name=name + \"block_0_\",\n+        )(inputs)\n+\n+        for i in range(1, num_repeats):\n+            x = BottleneckBlock(\n+                filters=filters,\n+                strides=1,\n+                use_projection=False,\n+                se_ratio=se_ratio,\n+                activation=activation,\n+                bn_epsilon=bn_epsilon,\n+                bn_momentum=bn_momentum,\n+                survival_probability=survival_probability,\n+                name=name + f\"block_{i}_\",\n+            )(x)\n+        return x\n+\n+    return apply\n+\n+def get_survival_probability(init_rate, block_num, total_blocks):\n+    \"\"\"Get survival probability based on block number and initial rate.\n+    \"\"\"\n+    return init_rate * float(block_num) / total_blocks\n+\n+\n+def allow_bigger_recursion(target_limit: int):\n+    \"\"\"Increase default recursion limit to create larger models.\"\"\"\n+    current_limit = sys.getrecursionlimit()\n+    if current_limit < target_limit:\n+        sys.setrecursionlimit(target_limit)\n+\n+\n+def fixed_padding(inputs, kernel_size):\n+    \"\"\"Pad the input along the spatial dimensions independently of input size.\"\"\"\n+    pad_total = kernel_size - 1\n+    pad_beg = pad_total // 2\n+    pad_end = pad_total - pad_beg\n+\n+    # Use ZeroPadding as to avoid TFOpLambda layer\n+    padded_inputs = layers.ZeroPadding2D(\n+        padding=((pad_beg, pad_end), (pad_beg, pad_end))\n+    )(inputs)\n+\n+    return padded_inputs\n+\n+def ResNetRS(\n+    depth: int,\n+    input_shape=None,\n+    bn_momentum=0.0,\n+    bn_epsilon=1e-5,\n+    activation: str = \"relu\",\n+    se_ratio=0.25,\n+    dropout_rate=0.25,\n+    drop_connect_rate=0.2,\n+    include_top=True,\n+    block_args: List[Dict[str, int]] = None,\n+    model_name=\"resnet-rs\",\n+    pooling=None,\n+    weights=\"imagenet\",\n+    input_tensor=None,\n+    classes=1000,\n+    classifier_activation: Union[str, Callable] = \"softmax\",\n+    include_preprocessing=True\n+):\n+    \"\"\"Build Resnet-RS model, given provided parameters.\n+    Parameters:\n+        :param depth: Depth of ResNet network.\n+        :param dropout_rate: dropout rate before final classifier layer.\n+        :param bn_momentum: Momentum parameter for Batch Normalization layers.\n+        :param bn_epsilon: Epsilon parameter for Batch Normalization layers.\n+        :param activation: activation function.\n+        :param block_args: list of dicts, parameters to construct block modules.\n+        :param se_ratio: Squeeze and Excitation layer ratio.\n+        :param model_name: name of the model.\n+        :param drop_connect_rate: dropout rate at skip connections.\n+        :param include_top: whether to include the fully-connected layer at the top of\n+        the network.\n+        :param weights: one of `None` (random initialization), `'imagenet'`\n+            (pre-training on ImageNet), or the path to the weights file to be loaded.\n+            Note: one model can have multiple imagenet variants depending on\n+            input shape it was trained with. For input_shape 224x224 pass\n+            `imagenet-i224` as argument. By default, highest input shape weights are\n+            downloaded.\n+        :param input_tensor: optional Keras tensor (i.e. output of `layers.Input()`) to\n+            use as image input for the model.\n+        :param input_shape: optional shape tuple. It should have exactly 3 inputs\n+            channels, and width and height should be no smaller than 32.\n+            E.g. (200, 200, 3) would be one valid value.\n+        :param  pooling: optional pooling mode for feature extraction when `include_top`\n+            is `False`.\n+            - `None` means that the output of the model will be\n+                the 4D tensor output of the\n+                last convolutional layer.\n+            - `avg` means that global average pooling\n+                will be applied to the output of the\n+                last convolutional layer, and thus\n+                the output of the model will be a 2D tensor.\n+            - `max` means that global max pooling will\n+                be applied.\n+        :param classes: optional number of classes to classify images into, only to be\n+            specified if `include_top` is True, and if no `weights` argument is\n+            specified.\n+        :param classifier_activation: A `str` or callable. The activation function to\n+            use on the \"top\" layer. Ignored unless `include_top=True`. Set\n+            `classifier_activation=None` to return the logits of the \"top\" layer.\n+        :param include_preprocessing: Boolean, whether to include the preprocessing layer\n+            (`Rescaling`) at the bottom of the network. Defaults to `True`.\n+    Returns:\n+        A `tf.keras.Model` instance.\n+    Raises:\n+        ValueError: in case of invalid argument for `weights`, or invalid input\n+            shape.\n+        ValueError: if `classifier_activation` is not `softmax` or `None` when\n+            using a pretrained top layer.\n+    \"\"\"\n+    # Validate parameters\n+    available_weight_variants = DEPTH_TO_WEIGHT_VARIANTS[depth]\n+    if weights == \"imagenet\":\n+        max_input_shape = max(available_weight_variants)\n+        \"\"\"logging.warning(\n+            f\"Received `imagenet` argument without \"\n+            f\"explicit weights input size. Picking weights trained with \"\n+            f\"biggest available shape: imagenet-i{max_input_shape}\"\n+        )\"\"\"\n+        weights = f\"{weights}-i{max_input_shape}\"\n+\n+    weights_allow_list = [f\"imagenet-i{x}\" for x in available_weight_variants]\n+    if not (weights in {*weights_allow_list, None} or file_io.file_exists_v2(weights)):\n+        raise ValueError(\n+            \"The `weights` argument should be either \"\n+            \"`None` (random initialization), `'imagenet'` \"\n+            \"(pre-training on ImageNet, with highest available input shape),\"\n+            \" or the path to the weights file to be loaded. \"\n+            f\"For ResNetRS{depth} the following weight variants are \"\n+            f\"available {weights_allow_list} (default=highest).\"\n+            f\" Received weights={weights}\"\n+        )\n+\n+    if weights in weights_allow_list and include_top and classes != 1000:\n+        raise ValueError(\n+            f\"If using `weights` as `'imagenet'` or any of {weights_allow_list} with \"\n+            f\"`include_top` as true, `classes` should be 1000. \"\n+            f\"Received classes={classes}\"\n+        )\n+    input_shape = imagenet_utils.obtain_input_shape(\n+      input_shape,\n+      default_size=224,\n+      min_size=32,\n+      data_format=backend.image_data_format(),\n+      require_flatten=include_top,\n+      weights=weights)\n+    # Define input tensor\n+    if input_tensor is None:\n+        img_input = layers.Input(shape=input_shape)\n+    else:\n+        if not backend.is_keras_tensor(input_tensor):\n+            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n+        else:\n+            img_input = input_tensor\n+    bn_axis = 3 if backend.image_data_format() == \"channels_last\" else 1\n+    x = img_input\n+    if include_preprocessing:\n+        num_channels = input_shape[bn_axis - 1]\n+        if  num_channels == 3:\n+            x = layers.Rescaling(scale=1. / 255)(x)\n+            x = layers.Normalization(\n+                mean=[0.485, 0.456, 0.406],\n+                variance=[0.229**2, 0.224**2, 0.225**2],\n+                axis=bn_axis,\n+            )(x)\n+        else:\n+            x = layers.Rescaling(scale=1. / 128.0, offset=-1)(x)\n+\n+    # Build stem\n+    x = STEM(bn_momentum=bn_momentum, bn_epsilon=bn_epsilon, activation=activation)(\n+        x\n+    )\n+\n+    # Build blocks\n+    if block_args is None:\n+        block_args = BLOCK_ARGS[depth]\n+\n+    for i, args in enumerate(block_args):\n+        survival_probability = get_survival_probability(\n+            init_rate=drop_connect_rate,\n+            block_num=i + 2,\n+            total_blocks=len(block_args) + 1,\n+        )\n+\n+        x = BlockGroup(\n+            filters=args[\"input_filters\"],\n+            activation=activation,\n+            strides=(1 if i == 0 else 2),\n+            num_repeats=args[\"num_repeats\"],\n+            se_ratio=se_ratio,\n+            bn_momentum=bn_momentum,\n+            bn_epsilon=bn_epsilon,\n+            survival_probability=survival_probability,\n+            name=f\"c{i + 2}_\",\n+        )(x)\n+\n+    # Build head:\n+    if include_top:\n+        x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(x)\n+        if dropout_rate > 0:\n+            x = layers.Dropout(dropout_rate, name=\"top_dropout\")(x)\n+\n+        imagenet_utils.validate_activation(classifier_activation, weights)\n+        x = layers.Dense(\n+            classes, activation=classifier_activation, name=\"predictions\"\n+        )(x)\n+    else:\n+        if pooling == \"avg\":\n+            x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(x)\n+        elif pooling == \"max\":\n+            x = layers.GlobalMaxPooling2D(name=\"max_pool\")(x)\n+\n+    # Ensure that the model takes into account\n+    # any potential predecessors of `input_tensor`.\n+    if input_tensor is not None:\n+        inputs = layer_utils.get_source_inputs(input_tensor)\n+    else:\n+        inputs = img_input\n+\n+    # Create model.\n+    model = training.Model(inputs, x, name=model_name)\n+\n+    # Download weights\n+    if weights in weights_allow_list:\n+        weights_input_shape = weights.split(\"-\")[-1]  # e. g. \"i160\"\n+        weights_name = f\"{model_name}-{weights_input_shape}\"\n+        if not include_top:\n+            weights_name += \"_notop\"\n+\n+        filename = f\"{weights_name}.h5\"\n+        download_url = BASE_WEIGHTS_URL + filename\n+        weights_path = data_utils.get_file(\n+            fname=filename,\n+            origin=download_url,\n+            cache_subdir=\"models\",\n+            file_hash=WEIGHT_HASHES[filename],\n+        )\n+        model.load_weights(weights_path)\n+\n+    elif weights is not None:\n+        model.load_weights(weights)\n+\n+    return model\n+\n+@keras_export('keras.applications.resnet_rs.ResNetRS50',\n+              'keras.applications.ResNetRS50')\n+def ResNetRS50(\n+    include_top=True,\n+    weights=\"imagenet\",\n+    classes=1000,\n+    input_shape=None,\n+    input_tensor=None,\n+    pooling=None,\n+    classifier_activation=\"softmax\",\n+):\n+    \"\"\"Build ResNet-RS50 model.\"\"\"\n+    return ResNetRS(\n+        depth=50,\n+        include_top=include_top,\n+        drop_connect_rate=0.0,\n+        dropout_rate=0.25,\n+        weights=weights,\n+        classes=classes,\n+        input_shape=input_shape,\n+        input_tensor=input_tensor,\n+        pooling=pooling,\n+        classifier_activation=classifier_activation,\n+        model_name=\"resnet-rs-50\",\n+    )\n+\n+@keras_export('keras.applications.resnet_rs.ResNetRS101',\n+              'keras.applications.ResNetRS101')\n+def ResNetRS101(\n+    include_top=True,\n+    weights=\"imagenet\",\n+    classes=1000,\n+    input_shape=None,\n+    input_tensor=None,\n+    pooling=None,\n+    classifier_activation=\"softmax\",\n+):\n+    \"\"\"Build ResNet-RS101 model.\"\"\"\n+    return ResNetRS(\n+        depth=101,\n+        include_top=include_top,\n+        drop_connect_rate=0.0,\n+        dropout_rate=0.25,\n+        weights=weights,\n+        classes=classes,\n+        input_shape=input_shape,\n+        input_tensor=input_tensor,\n+        pooling=pooling,\n+        classifier_activation=classifier_activation,\n+        model_name=\"resnet-rs-101\",\n+    )\n+\n+@keras_export('keras.applications.resnet_rs.ResNetRS152',\n+              'keras.applications.ResNetRS152')\n+def ResNetRS152(\n+    include_top=True,\n+    weights=\"imagenet\",\n+    classes=1000,\n+    input_shape=None,\n+    input_tensor=None,\n+    pooling=None,\n+    classifier_activation=\"softmax\",\n+):\n+    \"\"\"Build ResNet-RS152 model.\"\"\"\n+    return ResNetRS(\n+        depth=152,\n+        include_top=include_top,\n+        drop_connect_rate=0.0,\n+        dropout_rate=0.25,\n+        weights=weights,\n+        classes=classes,\n+        input_shape=input_shape,\n+        input_tensor=input_tensor,\n+        pooling=pooling,\n+        classifier_activation=classifier_activation,\n+        model_name=\"resnet-rs-152\",\n+    )\n+\n+@keras_export('keras.applications.resnet_rs.ResNetRS200',\n+              'keras.applications.ResNetRS200')\n+def ResNetRS200(\n+    include_top=True,\n+    weights=\"imagenet\",\n+    classes=1000,\n+    input_shape=None,\n+    input_tensor=None,\n+    pooling=None,\n+    classifier_activation=\"softmax\",\n+):\n+    \"\"\"Build ResNet-RS200 model.\"\"\"\n+    return ResNetRS(\n+        depth=200,\n+        include_top=include_top,\n+        drop_connect_rate=0.1,\n+        dropout_rate=0.25,\n+        weights=weights,\n+        classes=classes,\n+        input_shape=input_shape,\n+        input_tensor=input_tensor,\n+        pooling=pooling,\n+        classifier_activation=classifier_activation,\n+        model_name=\"resnet-rs-200\",\n+    )\n+\n+@keras_export('keras.applications.resnet_rs.ResNetRS270',\n+              'keras.applications.ResNetRS270')\n+def ResNetRS270(\n+    include_top=True,\n+    weights=\"imagenet\",\n+    classes=1000,\n+    input_shape=None,\n+    input_tensor=None,\n+    pooling=None,\n+    classifier_activation=\"softmax\",\n+):\n+    \"\"\"Build ResNet-RS-270 model.\"\"\"\n+    allow_bigger_recursion(1300)\n+    return ResNetRS(\n+        depth=270,\n+        include_top=include_top,\n+        drop_connect_rate=0.1,\n+        dropout_rate=0.25,\n+        weights=weights,\n+        classes=classes,\n+        input_shape=input_shape,\n+        input_tensor=input_tensor,\n+        pooling=pooling,\n+        classifier_activation=classifier_activation,\n+        model_name=\"resnet-rs-270\",\n+    )\n+\n+@keras_export('keras.applications.resnet_rs.ResNetRS350',\n+              'keras.applications.ResNetRS350')\n+def ResNetRS350(\n+    include_top=True,\n+    weights=\"imagenet\",\n+    classes=1000,\n+    input_shape=None,\n+    input_tensor=None,\n+    pooling=None,\n+    classifier_activation=\"softmax\",\n+):\n+    \"\"\"Build ResNet-RS350 model.\"\"\"\n+    allow_bigger_recursion(1500)\n+    return ResNetRS(\n+        depth=350,\n+        include_top=include_top,\n+        drop_connect_rate=0.1,\n+        dropout_rate=0.4,\n+        weights=weights,\n+        classes=classes,\n+        input_shape=input_shape,\n+        input_tensor=input_tensor,\n+        pooling=pooling,\n+        classifier_activation=classifier_activation,\n+        model_name=\"resnet-rs-350\",\n+    )\n+\n+@keras_export('keras.applications.resnet_rs.ResNetRS420',\n+              'keras.applications.ResNetRS420')\n+def ResNetRS420(\n+    include_top=True,\n+    weights=\"imagenet\",\n+    classes=1000,\n+    input_shape=None,\n+    input_tensor=None,\n+    pooling=None,\n+    classifier_activation=\"softmax\",\n+):\n+    \"\"\"Build ResNet-RS420 model.\"\"\"\n+    allow_bigger_recursion(1800)\n+    return ResNetRS(\n+        depth=420,\n+        include_top=include_top,\n+        dropout_rate=0.4,\n+        drop_connect_rate=0.1,\n+        weights=weights,\n+        classes=classes,\n+        input_shape=input_shape,\n+        input_tensor=input_tensor,\n+        pooling=pooling,\n+        classifier_activation=classifier_activation,\n+        model_name=\"resnet-rs-420\",\n+    )\n+\n+@keras_export('keras.applications.resnet_rs.preprocess_input')\n+def preprocess_input(x, data_format=None):\n+  return x\n+\n+\n+@keras_export('keras.applications.resnet_rs.decode_predictions')\n+def decode_predictions(preds, top=5):\n+  return imagenet_utils.decode_predictions(preds, top=top)\n+\n+preprocess_input.__doc__ = imagenet_utils.PREPROCESS_INPUT_DOC.format(\n+    mode='',\n+    ret=imagenet_utils.PREPROCESS_INPUT_RET_DOC_TF,\n+    error=imagenet_utils.PREPROCESS_INPUT_ERROR_DOC)\n+decode_predictions.__doc__ = imagenet_utils.decode_predictions.__doc__\n+\n+DOC = \"\"\"\n+\n+  Reference:\n+  [Revisiting ResNets: Improved Training and Scaling Strategies](\n+    https://arxiv.org/pdf/2103.07579.pdf)\n+\n+  For image classification use cases, see\n+  [this page for detailed examples](\n+    https://keras.io/api/applications/#usage-examples-for-image-classification-models).\n+\n+  For transfer learning use cases, make sure to read the\n+  [guide to transfer learning & fine-tuning](\n+    https://keras.io/guides/transfer_learning/).\n+\n+  Note: each Keras Application expects a specific kind of input preprocessing.\n+  For ResNetRs, by default input preprocessing is included as a part of the\n+  model (as a `Rescaling` layer), and thus\n+  `tf.keras.applications.resnet_rs.preprocess_input` is actually a\n+  pass-through function. In this use case, ResNetRS models expect their inputs\n+  to be float tensors of pixels with values in the [0-255] range.\n+  At the same time, preprocessing as a part of the model (i.e. `Rescaling`\n+  layer) can be disabled by setting `include_preprocessing` argument to False.\n+  With preprocessing disabled ResNetRS models expect their inputs to be float\n+  tensors of pixels with values in the [-1, 1] range.\n+\n+  Args:\n+        depth: Depth of ResNet network.\n+        dropout_rate: dropout rate before final classifier layer.\n+        bn_momentum: Momentum parameter for Batch Normalization layers.\n+        bn_epsilon: Epsilon parameter for Batch Normalization layers.\n+        activation: activation function.\n+        block_args: list of dicts, parameters to construct block modules.\n+        se_ratio: Squeeze and Excitation layer ratio.\n+        model_name: name of the model.\n+        drop_connect_rate: dropout rate at skip connections.\n+        include_top: whether to include the fully-connected layer at the top of\n+        the network.\n+        weights: one of `None` (random initialization), `'imagenet'`\n+            (pre-training on ImageNet), or the path to the weights file to be loaded.\n+            Note: one model can have multiple imagenet variants depending on\n+            input shape it was trained with. For input_shape 224x224 pass\n+            `imagenet-i224` as argument. By default, highest input shape weights are\n+            downloaded.\n+        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`) to\n+            use as image input for the model.\n+        input_shape: optional shape tuple. It should have exactly 3 inputs\n+            channels, and width and height should be no smaller than 32.\n+            E.g. (200, 200, 3) would be one valid value.\n+        pooling: optional pooling mode for feature extraction when `include_top`\n+            is `False`.\n+            - `None` means that the output of the model will be\n+                the 4D tensor output of the\n+                last convolutional layer.\n+            - `avg` means that global average pooling\n+                will be applied to the output of the\n+                last convolutional layer, and thus\n+                the output of the model will be a 2D tensor.\n+            - `max` means that global max pooling will\n+                be applied.\n+        classes: optional number of classes to classify images into, only to be\n+            specified if `include_top` is True, and if no `weights` argument is\n+            specified.\n+        classifier_activation: A `str` or callable. The activation function to\n+            use on the \"top\" layer. Ignored unless `include_top=True`. Set\n+            `classifier_activation=None` to return the logits of the \"top\" layer.\n+        include_preprocessing: Boolean, whether to include the preprocessing layer\n+            (`Rescaling`) at the bottom of the network. Defaults to `True`.\n+\n+  Returns:\n+    A `keras.Model` instance.\n+\"\"\"\n+\n+setattr(ResNetRS50, '__doc__', ResNetRS50.__doc__ + DOC)\n+setattr(ResNetRS152, '__doc__', ResNetRS152.__doc__ + DOC)\n+setattr(ResNetRS200, '__doc__', ResNetRS200.__doc__ + DOC)\n+setattr(ResNetRS270, '__doc__', ResNetRS270.__doc__ + DOC)\n+setattr(ResNetRS350, '__doc__', ResNetRS350.__doc__ + DOC)\n+setattr(ResNetRS420, '__doc__', ResNetRS420.__doc__ + DOC)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#19a5f370bbad112bdd9db02f4fc05598dbe42697", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 6 | Files Changed: 6 | Hunks: 12 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 18 | Churn Cumulative: 2885 | Contributors (this commit): 5 | Commits (past 90d): 59 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -21,6 +21,7 @@ import tensorflow.compat.v2 as tf\n from tensorflow.python.util.tf_export import keras_export\n \n \n+# pylint: disable=g-classes-have-attributes\n @generic_utils.register_keras_serializable()\n @keras_export('keras.optimizers.experimental.Adadelta', v1=[])\n class Adadelta(optimizer.Optimizer):\n@@ -39,7 +40,7 @@ class Adadelta(optimizer.Optimizer):\n   don't have to set an initial learning rate. In this version, the initial\n   learning rate can be set, as in most other Keras optimizers.\n \n-  Attributes:\n+  Args:\n     learning_rate: Initial value for the learning rate:\n       either a floating point value,\n       or a `tf.keras.optimizers.schedules.LearningRateSchedule` instance.\n\n@@ -22,6 +22,7 @@ import tensorflow.compat.v2 as tf\n from tensorflow.python.util.tf_export import keras_export\n \n \n+# pylint: disable=g-classes-have-attributes\n @generic_utils.register_keras_serializable()\n @keras_export('keras.optimizers.experimental.Adagrad', v1=[])\n class Adagrad(optimizer.Optimizer):\n@@ -32,7 +33,7 @@ class Adagrad(optimizer.Optimizer):\n   updated during training. The more updates a parameter receives,\n   the smaller the updates.\n \n-  Attributes:\n+  Args:\n     learning_rate: Initial value for the learning rate:\n       either a floating point value,\n       or a `tf.keras.optimizers.schedules.LearningRateSchedule` instance.\n\n@@ -21,6 +21,7 @@ import tensorflow.compat.v2 as tf\n from tensorflow.python.util.tf_export import keras_export\n \n \n+# pylint: disable=g-classes-have-attributes\n @generic_utils.register_keras_serializable()\n @keras_export('keras.optimizers.experimental.Adam', v1=[])\n class Adam(optimizer.Optimizer):\n@@ -36,7 +37,7 @@ class Adam(optimizer.Optimizer):\n   gradients, and is well suited for problems that are large in terms of\n   data/parameters*\".\n \n-  Attributes:\n+  Args:\n     learning_rate: A `tf.Tensor`, floating point value, a schedule that is a\n       `tf.keras.optimizers.schedules.LearningRateSchedule`, or a callable\n       that takes no arguments and returns the actual value to use. The\n\n@@ -518,6 +518,7 @@ class _BaseOptimizer(tf.Module):\n     return cls(**config)\n \n \n+# pylint: disable=g-classes-have-attributes\n @keras_export(\"keras.optimizers.experimental.Optimizer\", v1=[])\n class Optimizer(_BaseOptimizer):\n   \"\"\"Abstract optimizer base class.\n@@ -525,7 +526,7 @@ class Optimizer(_BaseOptimizer):\n   This class supports distributed training. If you want to implement your own\n   optimizer, please subclass this class instead of _BaseOptimizer.\n \n-  Attributes:\n+  Args:\n     name: string. The name to use for momentum accumulator weights created by\n       the optimizer.\n     clipnorm: float. If set, the gradient of each weight is individually\n\n@@ -19,6 +19,7 @@ from keras.utils import generic_utils\n import tensorflow.compat.v2 as tf\n \n \n+# pylint: disable=g-classes-have-attributes\n @generic_utils.register_keras_serializable()\n class RMSprop(optimizer.Optimizer):\n   r\"\"\"Optimizer that implements the RMSprop algorithm.\n@@ -33,7 +34,7 @@ class RMSprop(optimizer.Optimizer):\n   The centered version additionally maintains a moving average of the\n   gradients, and uses that average to estimate the variance.\n \n-  Attributes:\n+  Args:\n     learning_rate: Initial value for the learning rate:\n       either a floating point value,\n       or a `tf.keras.optimizers.schedules.LearningRateSchedule` instance.\n\n@@ -21,6 +21,7 @@ import tensorflow.compat.v2 as tf\n from tensorflow.python.util.tf_export import keras_export\n \n \n+# pylint: disable=g-classes-have-attributes\n @generic_utils.register_keras_serializable()\n @keras_export('keras.optimizers.experimental.SGD', v1=[])\n class SGD(optimizer.Optimizer):\n@@ -46,7 +47,7 @@ class SGD(optimizer.Optimizer):\n   w = w + momentum * velocity - learning_rate * g\n   ```\n \n-  Attributes:\n+  Args:\n     learning_rate: A `Tensor`, floating point value, or a schedule that is a\n       `tf.keras.optimizers.schedules.LearningRateSchedule`, or a callable\n       that takes no arguments and returns the actual value to use. The\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f864b66caa679035857d815a4bb3bfb732402fbc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 1756 | Contributors (this commit): 24 | Commits (past 90d): 2 | Contributors (cumulative): 24 | DMM Complexity: None\n\nDIFF:\n@@ -218,7 +218,8 @@ class TimeseriesGenerator(data_utils.Sequence):\n     return json.dumps(timeseries_generator_config, **kwargs)\n \n \n-@keras_export('keras.preprocessing.sequence.pad_sequences')\n+@keras_export('keras.utils.pad_sequences',\n+              'keras.preprocessing.sequence.pad_sequences')\n def pad_sequences(sequences, maxlen=None, dtype='int32',\n                   padding='pre', truncating='pre', value=0.):\n   \"\"\"Pads sequences to the same length.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8c57ae054504588c67a17defc09eed290b3dbe60", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 7 | Methods Changed: 6 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 20 | Churn Cumulative: 1282 | Contributors (this commit): 5 | Commits (past 90d): 1 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -328,10 +328,11 @@ def DenseNet121(include_top=True,\n                 input_tensor=None,\n                 input_shape=None,\n                 pooling=None,\n-                classes=1000):\n+                classes=1000,\n+                classifier_activation='softmax'):\n   \"\"\"Instantiates the Densenet121 architecture.\"\"\"\n   return DenseNet([6, 12, 24, 16], include_top, weights, input_tensor,\n-                  input_shape, pooling, classes)\n+                  input_shape, pooling, classes, classifier_activation)\n \n \n @keras_export('keras.applications.densenet.DenseNet169',\n@@ -341,10 +342,11 @@ def DenseNet169(include_top=True,\n                 input_tensor=None,\n                 input_shape=None,\n                 pooling=None,\n-                classes=1000):\n+                classes=1000,\n+                classifier_activation='softmax'):\n   \"\"\"Instantiates the Densenet169 architecture.\"\"\"\n   return DenseNet([6, 12, 32, 32], include_top, weights, input_tensor,\n-                  input_shape, pooling, classes)\n+                  input_shape, pooling, classes, classifier_activation)\n \n \n @keras_export('keras.applications.densenet.DenseNet201',\n@@ -354,10 +356,11 @@ def DenseNet201(include_top=True,\n                 input_tensor=None,\n                 input_shape=None,\n                 pooling=None,\n-                classes=1000):\n+                classes=1000,\n+                classifier_activation='softmax'):\n   \"\"\"Instantiates the Densenet201 architecture.\"\"\"\n   return DenseNet([6, 12, 48, 32], include_top, weights, input_tensor,\n-                  input_shape, pooling, classes)\n+                  input_shape, pooling, classes, classifier_activation)\n \n \n @keras_export('keras.applications.densenet.preprocess_input')\n@@ -420,6 +423,11 @@ DOC = \"\"\"\n     classes: optional number of classes to classify images\n       into, only to be specified if `include_top` is True, and\n       if no `weights` argument is specified.\n+    classifier_activation: A `str` or callable. The activation function to use\n+      on the \"top\" layer. Ignored unless `include_top=True`. Set\n+      `classifier_activation=None` to return the logits of the \"top\" layer.\n+      When loading pretrained weights, `classifier_activation` can only\n+      be `None` or `\"softmax\"`.\n \n   Returns:\n     A Keras model instance.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a63613cd040abbaa0500f95eb91eab26493dbed8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 18 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 6 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 22 | Churn Cumulative: 2508 | Contributors (this commit): 9 | Commits (past 90d): 1 | Contributors (cumulative): 9 | DMM Complexity: 1.0\n\nDIFF:\n@@ -328,7 +328,8 @@ def NASNetMobile(input_shape=None,\n                  weights='imagenet',\n                  input_tensor=None,\n                  pooling=None,\n-                 classes=1000):\n+                 classes=1000,\n+                 classifier_activation='softmax'):\n   \"\"\"Instantiates a Mobile NASNet model in ImageNet mode.\n \n   Reference:\n@@ -373,6 +374,11 @@ def NASNetMobile(input_shape=None,\n       classes: Optional number of classes to classify images\n           into, only to be specified if `include_top` is True, and\n           if no `weights` argument is specified.\n+      classifier_activation: A `str` or callable. The activation function to use\n+          on the \"top\" layer. Ignored unless `include_top=True`. Set\n+          `classifier_activation=None` to return the logits of the \"top\" layer.\n+          When loading pretrained weights, `classifier_activation` can only\n+          be `None` or `\"softmax\"`.\n \n   Returns:\n       A Keras model instance.\n@@ -395,7 +401,8 @@ def NASNetMobile(input_shape=None,\n       input_tensor=input_tensor,\n       pooling=pooling,\n       classes=classes,\n-      default_size=224)\n+      default_size=224,\n+      classifier_activation=classifier_activation)\n \n \n @keras_export('keras.applications.nasnet.NASNetLarge',\n@@ -405,7 +412,8 @@ def NASNetLarge(input_shape=None,\n                 weights='imagenet',\n                 input_tensor=None,\n                 pooling=None,\n-                classes=1000):\n+                classes=1000,\n+                classifier_activation='softmax'):\n   \"\"\"Instantiates a NASNet model in ImageNet mode.\n \n   Reference:\n@@ -450,6 +458,11 @@ def NASNetLarge(input_shape=None,\n       classes: Optional number of classes to classify images\n           into, only to be specified if `include_top` is True, and\n           if no `weights` argument is specified.\n+      classifier_activation: A `str` or callable. The activation function to use\n+          on the \"top\" layer. Ignored unless `include_top=True`. Set\n+          `classifier_activation=None` to return the logits of the \"top\" layer.\n+          When loading pretrained weights, `classifier_activation` can only\n+          be `None` or `\"softmax\"`.\n \n   Returns:\n       A Keras model instance.\n@@ -472,7 +485,8 @@ def NASNetLarge(input_shape=None,\n       input_tensor=input_tensor,\n       pooling=pooling,\n       classes=classes,\n-      default_size=331)\n+      default_size=331,\n+      classifier_activation=classifier_activation)\n \n \n def _separable_conv_block(ip,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
