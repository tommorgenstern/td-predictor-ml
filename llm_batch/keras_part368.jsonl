{"custom_id": "keras#ebb0405fde891f22485dba4603abd5f7c46c0943", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 67 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 4 | Methods Changed: 5 | Complexity Δ (Sum/Max): 6/6 | Churn Δ: 69 | Churn Cumulative: 245 | Contributors (this commit): 3 | Commits (past 90d): 1 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -14,6 +14,7 @@\n # ==============================================================================\n \"\"\"Tests for layer_utils.\"\"\"\n \n+import keras\n import tensorflow.compat.v2 as tf\n \n import collections\n@@ -24,7 +25,6 @@ import time\n import timeit\n \n import numpy as np\n-\n from keras.utils import layer_utils\n \n \n@@ -47,6 +47,70 @@ class MyPickleableObject(tf.__internal__.tracking.AutoTrackable):\n \n class LayerUtilsTest(tf.test.TestCase):\n \n+  def test_print_summary(self):\n+    model = keras.Sequential()\n+    model.add(\n+        keras.layers.Conv2D(\n+            filters=2, kernel_size=(2, 3), input_shape=(3, 5, 5), name='conv'))\n+    model.add(keras.layers.Flatten(name='flat'))\n+    model.add(keras.layers.Dense(5, name='dense'))\n+\n+    file_name = 'model_1.txt'\n+    writer = open(file_name, 'w')\n+\n+    def print_to_file(text, end=\"\\n\"):\n+      print(text, end=end, file=writer)\n+    try:\n+      layer_utils.print_summary(model,\n+                                print_fn=print_to_file)\n+      self.assertTrue(tf.io.gfile.exists(file_name))\n+      writer.close()\n+      reader = open(file_name, 'r')\n+      lines = reader.readlines()\n+      reader.close()\n+      self.assertEquals(len(lines), 15)\n+      tf.io.gfile.remove(file_name)\n+\n+    except ImportError:\n+      pass\n+\n+  def test_print_summary_expand_nested(self):\n+    inputs = keras.Input(shape=(None, 3))\n+    lstm = keras.layers.LSTM(6, return_sequences=True, name='lstm')\n+    x = lstm(inputs)\n+    # Add layer inside a Wrapper\n+    bilstm = keras.layers.Bidirectional(\n+        keras.layers.LSTM(16, return_sequences=True, name='bilstm'))\n+    x = bilstm(x)\n+    # Add model inside a Wrapper\n+    submodel = keras.Sequential(\n+        [keras.layers.Dense(32, name='dense', input_shape=(None, 32))]\n+    )\n+    wrapped_dense = keras.layers.TimeDistributed(submodel)\n+    x = wrapped_dense(x)\n+    # Add shared submodel\n+    outputs = submodel(x)\n+    model = keras.Model(inputs, outputs)\n+\n+    file_name = 'model_2.txt'\n+    writer = open(file_name, 'w')\n+\n+    def print_to_file(text, end=\"\\n\"):\n+      print(text, end=end, file=writer)\n+    try:\n+      layer_utils.print_summary(model,\n+                                print_fn=print_to_file, expand_nested=True)\n+      self.assertTrue(tf.io.gfile.exists(file_name))\n+      writer.close()\n+      reader = open(file_name, 'r')\n+      lines = reader.readlines()\n+      reader.close()\n+      self.assertEquals(len(lines), 23)\n+      tf.io.gfile.remove(file_name)\n+\n+    except ImportError:\n+      pass\n+\n   def test_property_cache(self):\n     test_counter = collections.Counter()\n \n@@ -76,7 +140,8 @@ class LayerUtilsTest(tf.test.TestCase):\n     self.assertEqual(second_object.test_property, id(second_object))\n \n     # Make sure the cache does not share across objects\n-    self.assertNotEqual(first_object.test_property, second_object.test_property)\n+    self.assertNotEqual(first_object.test_property,\n+                        second_object.test_property)\n \n     # Check again (Now the values should be cached.)\n     self.assertEqual(first_object.test_property, id(first_object))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4ffb39e5cea540f65ce05bcf46f8ca5beccf1671", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 26 | Lines Deleted: 14 | Files Changed: 6 | Hunks: 13 | Methods Changed: 12 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 40 | Churn Cumulative: 28328 | Contributors (this commit): 123 | Commits (past 90d): 39 | Contributors (cumulative): 151 | DMM Complexity: 0.3333333333333333\n\nDIFF:\n@@ -104,7 +104,8 @@ def write_ckpt_to_h5(path_h5, path_ckpt, keras_model, use_ema=True):\n     except ValueError as e:\n       if any([x in w.name for x in ['top', 'predictions', 'probs']]):\n         warnings.warn('Fail to load top layer variable {}'\n-                      'from {} because of {}.'.format(w.name, tf_name, e))\n+                      'from {} because of {}.'.format(w.name, tf_name, e),\n+                      stacklevel=2)\n       else:\n         raise ValueError('Fail to load {} from {}'.format(w.name, tf_name))\n \n@@ -330,7 +331,7 @@ def check_match(keras_block, tf_block, keras_weight_names, tf_weight_names,\n   names_unused = names_from_tf - names_from_keras\n   if names_unused:\n     warnings.warn('{} variables from checkpoint file are not used: {}'.format(\n-        len(names_unused), names_unused))\n+        len(names_unused), names_unused), stacklevel=2)\n \n \n if __name__ == '__main__':\n\n@@ -326,13 +326,15 @@ def obtain_input_shape(input_shape,\n       if input_shape[0] not in {1, 3}:\n         warnings.warn('This model usually expects 1 or 3 input channels. '\n                       'However, it was passed an input_shape with ' +\n-                      str(input_shape[0]) + ' input channels.')\n+                      str(input_shape[0]) + ' input channels.',\n+                      stacklevel=2)\n       default_shape = (input_shape[0], default_size, default_size)\n     else:\n       if input_shape[-1] not in {1, 3}:\n         warnings.warn('This model usually expects 1 or 3 input channels. '\n                       'However, it was passed an input_shape with ' +\n-                      str(input_shape[-1]) + ' input channels.')\n+                      str(input_shape[-1]) + ' input channels.',\n+                      stacklevel=2)\n       default_shape = (default_size, default_size, input_shape[-1])\n   else:\n     if data_format == 'channels_first':\n\n@@ -472,7 +472,8 @@ def learning_phase_scope(value):\n   warnings.warn('`tf.keras.backend.learning_phase_scope` is deprecated and '\n                 'will be removed after 2020-10-11. To update it, simply '\n                 'pass a True/False value to the `training` argument of the '\n-                '`__call__` method of your layer or model.')\n+                '`__call__` method of your layer or model.',\n+                stacklevel=2)\n   with deprecated_internal_learning_phase_scope(value):\n     try:\n       yield\n@@ -4999,7 +5000,8 @@ def categorical_crossentropy(target, output, from_logits=False, axis=-1):\n       warnings.warn(\n           '\"`categorical_crossentropy` received `from_logits=True`, but '\n           'the `output` argument was produced by a sigmoid or softmax '\n-          'activation and thus does not represent logits. Was this intended?\"')\n+          'activation and thus does not represent logits. Was this intended?\"',\n+          stacklevel=2)\n     from_logits = True\n \n   if from_logits:\n@@ -5059,7 +5061,8 @@ def sparse_categorical_crossentropy(target, output, from_logits=False, axis=-1):\n       warnings.warn(\n           '\"`sparse_categorical_crossentropy` received `from_logits=True`, but '\n           'the `output` argument was produced by a sigmoid or softmax '\n-          'activation and thus does not represent logits. Was this intended?\"')\n+          'activation and thus does not represent logits. Was this intended?\"',\n+          stacklevel=2)\n     from_logits = True\n   elif (not from_logits and\n         not isinstance(output, (tf.__internal__.EagerTensor, tf.Variable)) and\n@@ -5146,7 +5149,8 @@ def binary_crossentropy(target, output, from_logits=False):\n       warnings.warn(\n           '\"`binary_crossentropy` received `from_logits=True`, but the `output`'\n           ' argument was produced by a sigmoid or softmax activation and thus '\n-          'does not represent logits. Was this intended?\"')\n+          'does not represent logits. Was this intended?\"',\n+          stacklevel=2)\n     from_logits = True\n \n   if from_logits:\n@@ -6241,7 +6245,8 @@ def random_binomial(shape, p=0.0, dtype=None, seed=None):\n   \"\"\"\n   warnings.warn('`tf.keras.backend.random_binomial` is deprecated, '\n                 'and will be removed in a future version.'\n-                'Please use `tf.keras.backend.random_bernoulli` instead.')\n+                'Please use `tf.keras.backend.random_bernoulli` instead.',\n+                stacklevel=2)\n   return random_bernoulli(shape, p, dtype, seed)\n \n \n\n@@ -1824,8 +1824,10 @@ class EarlyStopping(Callback):\n       self.model.stop_training = True\n       if self.restore_best_weights and self.best_weights is not None:\n         if self.verbose > 0:\n-          print('Restoring model weights from the end of the best epoch: '\n-                f'{self.best_epoch + 1}.')\n+          print(\n+            'Restoring model weights from the end of the best epoch: '\n+            f'{self.best_epoch + 1}'\n+          )\n         self.model.set_weights(self.best_weights)\n \n   def on_train_end(self, logs=None):\n\n@@ -1675,7 +1675,8 @@ class Layer(base_layer.Layer):\n     \"\"\"\n     warnings.warn('`layer.apply` is deprecated and '\n                   'will be removed in a future version. '\n-                  'Please use `layer.__call__` method instead.')\n+                  'Please use `layer.__call__` method instead.',\n+                  stacklevel=2)\n     return self.__call__(inputs, *args, **kwargs)\n \n   @doc_controls.do_not_doc_inheritable\n@@ -1683,7 +1684,8 @@ class Layer(base_layer.Layer):\n     \"\"\"Deprecated, do NOT use! Alias for `add_weight`.\"\"\"\n     warnings.warn('`layer.add_variable` is deprecated and '\n                   'will be removed in a future version. '\n-                  'Please use `layer.add_weight` method instead.')\n+                  'Please use `layer.add_weight` method instead.',\n+                  stacklevel=2)\n     return self.add_weight(*args, **kwargs)\n \n   @property\n\n@@ -258,7 +258,7 @@ class Metric(base_layer.Layer, metaclass=abc.ABCMeta):\n       warnings.warn('Metric %s implements a `reset_states()` method; rename it '\n                     'to `reset_state()` (without the final \"s\"). The name '\n                     '`reset_states()` has been deprecated to improve API '\n-                    'consistency.' % (self.__class__.__name__,))\n+                    'consistency.' % (self.__class__.__name__,), stacklevel=2)\n       return self.reset_states()\n     else:\n       backend.batch_set_value([(v, 0) for v in self.variables])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#14cf11eb0474898c5451b8ea9770dd0d36f4e5d1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 7211 | Contributors (this commit): 95 | Commits (past 90d): 12 | Contributors (cumulative): 95 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1824,10 +1824,8 @@ class EarlyStopping(Callback):\n       self.model.stop_training = True\n       if self.restore_best_weights and self.best_weights is not None:\n         if self.verbose > 0:\n-          print(\n-            'Restoring model weights from the end of the best epoch: '\n-            f'{self.best_epoch + 1}'\n-          )\n+          print('Restoring model weights from the end of the best epoch (%s).' %\n+                (self.best_epoch + 1))\n         self.model.set_weights(self.best_weights)\n \n   def on_train_end(self, logs=None):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a650b158dfdd88722e27ee7bde8d2f6be81f72ca", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 82 | Lines Deleted: 45 | Files Changed: 17 | Hunks: 45 | Methods Changed: 35 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 127 | Churn Cumulative: 59908 | Contributors (this commit): 213 | Commits (past 90d): 129 | Contributors (cumulative): 326 | DMM Complexity: 0.8275862068965517\n\nDIFF:\n@@ -1394,7 +1394,8 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n   def updates(self):\n     warnings.warn('`layer.updates` will be removed in a future version. '\n                   'This property should not be used in TensorFlow 2.0, '\n-                  'as `updates` are applied automatically.')\n+                  'as `updates` are applied automatically.',\n+                  stacklevel=2)\n     return []\n \n   @property\n@@ -1927,7 +1928,8 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n     \"\"\"\n     warnings.warn('`layer.get_updates_for` is deprecated and '\n                   'will be removed in a future version. '\n-                  'Please use `layer.updates` method instead.')\n+                  'Please use `layer.updates` method instead.',\n+                  stacklevel=2)\n     return self.updates\n \n   @doc_controls.do_not_generate_docs\n@@ -1944,7 +1946,8 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n     \"\"\"\n     warnings.warn('`layer.get_losses_for` is deprecated and '\n                   'will be removed in a future version. '\n-                  'Please use `layer.losses` instead.')\n+                  'Please use `layer.losses` instead.',\n+                  stacklevel=2)\n     return self.losses\n \n   @doc_controls.do_not_doc_inheritable\n@@ -2266,7 +2269,8 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n     \"\"\"\n     warnings.warn('`layer.apply` is deprecated and '\n                   'will be removed in a future version. '\n-                  'Please use `layer.__call__` method instead.')\n+                  'Please use `layer.__call__` method instead.',\n+                  stacklevel=2)\n     return self.__call__(inputs, *args, **kwargs)\n \n   @doc_controls.do_not_doc_inheritable\n@@ -2274,7 +2278,8 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n     \"\"\"Deprecated, do NOT use! Alias for `add_weight`.\"\"\"\n     warnings.warn('`layer.add_variable` is deprecated and '\n                   'will be removed in a future version. '\n-                  'Please use `layer.add_weight` method instead.')\n+                  'Please use `layer.add_weight` method instead.',\n+                  stacklevel=2)\n     return self.add_weight(*args, **kwargs)\n \n   @property\n\n@@ -593,7 +593,8 @@ class Functional(training_lib.Model):\n         warnings.warn(\n             'Input dict contained keys {} which did not match any model input. '\n             'They will be ignored by the model.'.format(\n-                [n for n in tensors.keys() if n not in ref_input_names])\n+                [n for n in tensors.keys() if n not in ref_input_names]),\n+            stacklevel=2\n             )\n \n       try:\n\n@@ -1720,7 +1720,8 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n           warnings.warn('Using Model.predict with '\n                         'MultiWorkerDistributionStrategy or TPUStrategy and '\n                         'AutoShardPolicy.FILE might lead to out-of-order result'\n-                        '. Consider setting it to AutoShardPolicy.DATA.')\n+                        '. Consider setting it to AutoShardPolicy.DATA.',\n+                        stacklevel=2)\n \n       data_handler = data_adapter.get_data_handler(\n           x=x,\n@@ -1977,7 +1978,8 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     \"\"\"\n     warnings.warn('`Model.fit_generator` is deprecated and '\n                   'will be removed in a future version. '\n-                  'Please use `Model.fit`, which supports generators.')\n+                  'Please use `Model.fit`, which supports generators.',\n+                  stacklevel=2)\n     return self.fit(\n         generator,\n         steps_per_epoch=steps_per_epoch,\n@@ -2011,7 +2013,8 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     \"\"\"\n     warnings.warn('`Model.evaluate_generator` is deprecated and '\n                   'will be removed in a future version. '\n-                  'Please use `Model.evaluate`, which supports generators.')\n+                  'Please use `Model.evaluate`, which supports generators.',\n+                  stacklevel=2)\n     self._check_call_args('evaluate_generator')\n \n     return self.evaluate(\n@@ -2040,7 +2043,8 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     \"\"\"\n     warnings.warn('`Model.predict_generator` is deprecated and '\n                   'will be removed in a future version. '\n-                  'Please use `Model.predict`, which supports generators.')\n+                  'Please use `Model.predict`, which supports generators.',\n+                  stacklevel=2)\n     return self.predict(\n         generator,\n         steps=steps,\n@@ -2480,7 +2484,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     \"\"\"\n     warnings.warn('`Model.state_updates` will be removed in a future version. '\n                   'This property should not be used in TensorFlow 2.0, '\n-                  'as `updates` are applied automatically.')\n+                  'as `updates` are applied automatically.', stacklevel=2)\n     state_updates = []\n     for layer in self.layers:\n       if getattr(layer, 'stateful', False):\n\n@@ -1227,7 +1227,8 @@ class Model(training_lib.Model):\n     \"\"\"\n     warnings.warn('`model.fit_generator` is deprecated and '\n                   'will be removed in a future version. '\n-                  'Please use `Model.fit`, which supports generators.')\n+                  'Please use `Model.fit`, which supports generators.',\n+                  stacklevel=2)\n     return self.fit(\n         generator,\n         steps_per_epoch=steps_per_epoch,\n@@ -1260,7 +1261,8 @@ class Model(training_lib.Model):\n     \"\"\"\n     warnings.warn('`Model.evaluate_generator` is deprecated and '\n                   'will be removed in a future version. '\n-                  'Please use `Model.evaluate`, which supports generators.')\n+                  'Please use `Model.evaluate`, which supports generators.',\n+                  stacklevel=2)\n     self._check_call_args('evaluate_generator')\n \n     return self.evaluate(\n@@ -1288,7 +1290,8 @@ class Model(training_lib.Model):\n     \"\"\"\n     warnings.warn('`Model.predict_generator` is deprecated and '\n                   'will be removed in a future version. '\n-                  'Please use `Model.predict`, which supports generators.')\n+                  'Please use `Model.predict`, which supports generators.',\n+                  stacklevel=2)\n     return self.predict(\n         generator,\n         steps=steps,\n\n@@ -335,7 +335,7 @@ class Lambda(Layer):\n       # Note: we don't know the name of the function if it's a lambda.\n       warnings.warn(\n           '{} is not loaded, but a Lambda layer uses it. '\n-          'It may cause errors.'.format(module), UserWarning)\n+          'It may cause errors.'.format(module), UserWarning, stacklevel=2)\n     if custom_objects:\n       globs.update(custom_objects)\n     function_type = config.pop(func_type_attr_name)\n\n@@ -416,7 +416,8 @@ class BasicRNNCell(LayerRNNCell):\n     warnings.warn(\"`tf.nn.rnn_cell.BasicRNNCell` is deprecated and will be \"\n                   \"removed in a future version. This class \"\n                   \"is equivalent as `tf.keras.layers.SimpleRNNCell`, \"\n-                  \"and will be replaced by that in Tensorflow 2.0.\")\n+                  \"and will be replaced by that in Tensorflow 2.0.\",\n+                  stacklevel=2)\n     super(BasicRNNCell, self).__init__(\n         _reuse=reuse, name=name, dtype=dtype, **kwargs)\n     _check_supported_dtypes(self.dtype)\n@@ -526,7 +527,8 @@ class GRUCell(LayerRNNCell):\n     warnings.warn(\"`tf.nn.rnn_cell.GRUCell` is deprecated and will be removed \"\n                   \"in a future version. This class \"\n                   \"is equivalent as `tf.keras.layers.GRUCell`, \"\n-                  \"and will be replaced by that in Tensorflow 2.0.\")\n+                  \"and will be replaced by that in Tensorflow 2.0.\",\n+                  stacklevel=2)\n     super(GRUCell, self).__init__(\n         _reuse=reuse, name=name, dtype=dtype, **kwargs)\n     _check_supported_dtypes(self.dtype)\n@@ -702,7 +704,8 @@ class BasicLSTMCell(LayerRNNCell):\n     warnings.warn(\"`tf.nn.rnn_cell.BasicLSTMCell` is deprecated and will be \"\n                   \"removed in a future version. This class \"\n                   \"is equivalent as `tf.keras.layers.LSTMCell`, \"\n-                  \"and will be replaced by that in Tensorflow 2.0.\")\n+                  \"and will be replaced by that in Tensorflow 2.0.\",\n+                  stacklevel=2)\n     super(BasicLSTMCell, self).__init__(\n         _reuse=reuse, name=name, dtype=dtype, **kwargs)\n     _check_supported_dtypes(self.dtype)\n@@ -905,7 +908,8 @@ class LSTMCell(LayerRNNCell):\n     warnings.warn(\"`tf.nn.rnn_cell.LSTMCell` is deprecated and will be \"\n                   \"removed in a future version. This class \"\n                   \"is equivalent as `tf.keras.layers.LSTMCell`, \"\n-                  \"and will be replaced by that in Tensorflow 2.0.\")\n+                  \"and will be replaced by that in Tensorflow 2.0.\",\n+                  stacklevel=2)\n     super(LSTMCell, self).__init__(\n         _reuse=reuse, name=name, dtype=dtype, **kwargs)\n     _check_supported_dtypes(self.dtype)\n\n@@ -469,7 +469,8 @@ def _parse_config_to_function(config, custom_objects, func_attr_name,\n   elif module is not None:\n     # Note: we don't know the name of the function if it's a lambda.\n     warnings.warn(\"{} is not loaded, but a layer uses it. \"\n-                  \"It may cause errors.\".format(module), UserWarning)\n+                  \"It may cause errors.\".format(module), UserWarning,\n+                  stacklevel=2)\n   if custom_objects:\n     globs.update(custom_objects)\n   function_type = config.pop(func_type_attr_name)\n\n@@ -2599,7 +2599,7 @@ class PeepholeLSTMCell(LSTMCell):\n     warnings.warn('`tf.keras.experimental.PeepholeLSTMCell` is deprecated '\n                   'and will be removed in a future version. '\n                   'Please use tensorflow_addons.rnn.PeepholeLSTMCell '\n-                  'instead.')\n+                  'instead.', stacklevel=2)\n     super(PeepholeLSTMCell, self).__init__(\n         units=units,\n         activation=activation,\n\n@@ -246,7 +246,7 @@ class Layer(base_layer.Layer):\n     warnings.warn('`Layer.graph` is deprecated and '\n                   'will be removed in a future version. '\n                   'Please stop using this property because tf.layers layers no '\n-                  'longer track their graph.')\n+                  'longer track their graph.', stacklevel=2)\n     if tf.executing_eagerly():\n       raise RuntimeError('Layer.graph not supported when executing eagerly.')\n     return None\n\n@@ -262,7 +262,8 @@ def conv1d(inputs,\n   \"\"\"\n   warnings.warn('`tf.layers.conv1d` is deprecated and '\n                 'will be removed in a future version. '\n-                'Please Use `tf.keras.layers.Conv1D` instead.')\n+                'Please Use `tf.keras.layers.Conv1D` instead.',\n+                stacklevel=2)\n   layer = Conv1D(\n       filters=filters,\n       kernel_size=kernel_size,\n@@ -535,7 +536,8 @@ def conv2d(inputs,\n   \"\"\"\n   warnings.warn('`tf.layers.conv2d` is deprecated and '\n                 'will be removed in a future version. '\n-                'Please Use `tf.keras.layers.Conv2D` instead.')\n+                'Please Use `tf.keras.layers.Conv2D` instead.',\n+                stacklevel=2)\n   layer = Conv2D(\n       filters=filters,\n       kernel_size=kernel_size,\n@@ -810,7 +812,8 @@ def conv3d(inputs,\n   \"\"\"\n   warnings.warn('`tf.layers.conv3d` is deprecated and '\n                 'will be removed in a future version. '\n-                'Please Use `tf.keras.layers.Conv3D` instead.')\n+                'Please Use `tf.keras.layers.Conv3D` instead.',\n+                stacklevel=2)\n   layer = Conv3D(\n       filters=filters,\n       kernel_size=kernel_size,\n@@ -1243,7 +1246,8 @@ def separable_conv1d(inputs,\n   \"\"\"\n   warnings.warn('`tf.layers.separable_conv1d` is deprecated and '\n                 'will be removed in a future version. '\n-                'Please Use `tf.keras.layers.SeparableConv1D` instead.')\n+                'Please Use `tf.keras.layers.SeparableConv1D` instead.',\n+                stacklevel=2)\n   layer = SeparableConv1D(\n       filters=filters,\n       kernel_size=kernel_size,\n@@ -1404,7 +1408,8 @@ def separable_conv2d(inputs,\n   \"\"\"\n   warnings.warn('`tf.layers.separable_conv2d` is deprecated and '\n                 'will be removed in a future version. '\n-                'Please Use `tf.keras.layers.SeparableConv2D` instead.')\n+                'Please Use `tf.keras.layers.SeparableConv2D` instead.',\n+                stacklevel=2)\n   layer = SeparableConv2D(\n       filters=filters,\n       kernel_size=kernel_size,\n@@ -1659,7 +1664,8 @@ def conv2d_transpose(inputs,\n   \"\"\"\n   warnings.warn('`tf.layers.conv2d_transpose` is deprecated and '\n                 'will be removed in a future version. '\n-                'Please Use `tf.keras.layers.Conv2DTranspose` instead.')\n+                'Please Use `tf.keras.layers.Conv2DTranspose` instead.',\n+                stacklevel=2)\n   layer = Conv2DTranspose(\n       filters=filters,\n       kernel_size=kernel_size,\n@@ -1900,7 +1906,8 @@ def conv3d_transpose(inputs,\n   \"\"\"\n   warnings.warn('`tf.layers.conv3d_transpose` is deprecated and '\n                 'will be removed in a future version. '\n-                'Please Use `tf.keras.layers.Conv3DTranspose` instead.')\n+                'Please Use `tf.keras.layers.Conv3DTranspose` instead.',\n+                stacklevel=2)\n   layer = Conv3DTranspose(\n       filters=filters,\n       kernel_size=kernel_size,\n\n@@ -235,7 +235,8 @@ def dense(\n   \"\"\"\n   warnings.warn('`tf.layers.dense` is deprecated and '\n                 'will be removed in a future version. '\n-                'Please use `tf.keras.layers.Dense` instead.')\n+                'Please use `tf.keras.layers.Dense` instead.',\n+                stacklevel=2)\n   layer = Dense(units,\n                 activation=activation,\n                 use_bias=use_bias,\n@@ -392,7 +393,8 @@ def dropout(inputs,\n   \"\"\"\n   warnings.warn('`tf.layers.dropout` is deprecated and '\n                 'will be removed in a future version. '\n-                'Please use `tf.keras.layers.Dropout` instead.')\n+                'Please use `tf.keras.layers.Dropout` instead.',\n+                stacklevel=2)\n   layer = Dropout(rate, noise_shape=noise_shape, seed=seed, name=name)\n   return layer.apply(inputs, training=training)\n \n@@ -512,7 +514,8 @@ def flatten(inputs, name=None, data_format='channels_last'):\n   \"\"\"\n   warnings.warn('`tf.layers.flatten` is deprecated and '\n                 'will be removed in a future version. '\n-                'Please use `tf.keras.layers.Flatten` instead.')\n+                'Please use `tf.keras.layers.Flatten` instead.',\n+                stacklevel=2)\n   layer = Flatten(name=name, data_format=data_format)\n   return layer.apply(inputs)\n \n\n@@ -426,7 +426,7 @@ def batch_normalization(inputs,\n       'Please use `tf.keras.layers.BatchNormalization` instead. '\n       'In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` '\n       'should not be used (consult the `tf.keras.layers.BatchNormalization` '\n-      'documentation).')\n+      'documentation).', stacklevel=2)\n   layer = BatchNormalization(\n       axis=axis,\n       momentum=momentum,\n\n@@ -149,7 +149,8 @@ def average_pooling1d(inputs, pool_size, strides,\n   \"\"\"\n   warnings.warn('`tf.layers.average_pooling1d` is deprecated and '\n                 'will be removed in a future version. '\n-                'Please use `tf.keras.layers.AveragePooling1D` instead.')\n+                'Please use `tf.keras.layers.AveragePooling1D` instead.',\n+                stacklevel=2)\n   layer = AveragePooling1D(pool_size=pool_size,\n                            strides=strides,\n                            padding=padding,\n@@ -281,7 +282,8 @@ def max_pooling1d(inputs, pool_size, strides,\n   \"\"\"\n   warnings.warn('`tf.layers.max_pooling1d` is deprecated and '\n                 'will be removed in a future version. '\n-                'Please use `tf.keras.layers.MaxPooling1D` instead.')\n+                'Please use `tf.keras.layers.MaxPooling1D` instead.',\n+                stacklevel=2)\n   layer = MaxPooling1D(pool_size=pool_size,\n                        strides=strides,\n                        padding=padding,\n@@ -418,7 +420,8 @@ def average_pooling2d(inputs,\n   \"\"\"\n   warnings.warn('`tf.layers.average_pooling2d` is deprecated and '\n                 'will be removed in a future version. '\n-                'Please use `tf.keras.layers.AveragePooling2D` instead.')\n+                'Please use `tf.keras.layers.AveragePooling2D` instead.',\n+                stacklevel=2)\n   layer = AveragePooling2D(pool_size=pool_size, strides=strides,\n                            padding=padding, data_format=data_format,\n                            name=name)\n@@ -553,7 +556,8 @@ def max_pooling2d(inputs,\n   \"\"\"\n   warnings.warn('`tf.layers.max_pooling2d` is deprecated and '\n                 'will be removed in a future version. '\n-                'Please use `tf.keras.layers.MaxPooling2D` instead.')\n+                'Please use `tf.keras.layers.MaxPooling2D` instead.',\n+                stacklevel=2)\n   layer = MaxPooling2D(pool_size=pool_size, strides=strides,\n                        padding=padding, data_format=data_format,\n                        name=name)\n@@ -692,7 +696,8 @@ def average_pooling3d(inputs,\n   \"\"\"\n   warnings.warn('`tf.layers.average_pooling3d` is deprecated and '\n                 'will be removed in a future version. '\n-                'Please use `tf.keras.layers.AveragePooling3D` instead.')\n+                'Please use `tf.keras.layers.AveragePooling3D` instead.',\n+                stacklevel=2)\n   layer = AveragePooling3D(pool_size=pool_size, strides=strides,\n                            padding=padding, data_format=data_format,\n                            name=name)\n@@ -829,7 +834,8 @@ def max_pooling3d(inputs,\n   \"\"\"\n   warnings.warn('`tf.layers.max_pooling3d` is deprecated and '\n                 'will be removed in a future version. '\n-                'Please use `tf.keras.layers.MaxPooling3D` instead.')\n+                'Please use `tf.keras.layers.MaxPooling3D` instead.',\n+                stacklevel=2)\n   layer = MaxPooling3D(pool_size=pool_size, strides=strides,\n                        padding=padding, data_format=data_format,\n                        name=name)\n\n@@ -354,7 +354,8 @@ class OptimizerV2(tf.__internal__.tracking.Trackable):\n         raise ValueError(\"Expected {} >= 0, received: {}\".format(k, kwargs[k]))\n       if k == \"lr\":\n         warnings.warn(\n-            \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n+            \"The `lr` argument is deprecated, use `learning_rate` instead.\",\n+            stacklevel=2)\n \n     self._use_locking = True\n     self._init_set_name(name)\n\n@@ -117,7 +117,8 @@ def export_saved_model(model,\n   warnings.warn('`tf.keras.experimental.export_saved_model` is deprecated'\n                 'and will be removed in a future version. '\n                 'Please use `model.save(..., save_format=\"tf\")` or '\n-                '`tf.keras.models.save_model(..., save_format=\"tf\")`.')\n+                '`tf.keras.models.save_model(..., save_format=\"tf\")`.',\n+                stacklevel=2)\n   if serving_only:\n     tf.saved_model.save(\n         model,\n@@ -400,7 +401,8 @@ def load_from_saved_model(saved_model_path, custom_objects=None):\n   \"\"\"\n   warnings.warn('`tf.keras.experimental.load_from_saved_model` is deprecated'\n                 'and will be removed in a future version. '\n-                'Please switch to `tf.keras.models.load_model`.')\n+                'Please switch to `tf.keras.models.load_model`.',\n+                stacklevel=2)\n   # restore model topology from json string\n   model_json_filepath = os.path.join(\n       tf.compat.as_bytes(saved_model_path),\n\n@@ -502,7 +502,7 @@ def serialize_keras_object(instance):\n     warnings.warn('Custom mask layers require a config and must override '\n                   'get_config. When loading, the custom mask layer must be '\n                   'passed to the custom_objects argument.',\n-                  category=CustomMaskWarning)\n+                  category=CustomMaskWarning, stacklevel=2)\n   # pylint: enable=protected-access\n \n   if hasattr(instance, 'get_config'):\n\n@@ -197,7 +197,7 @@ class KerasClassifier(BaseWrapper):\n     warnings.warn(\n         'KerasClassifier is deprecated, '\n         'use Sci-Keras (https://github.com/adriangb/scikeras) instead.',\n-        DeprecationWarning\n+        DeprecationWarning, stacklevel=2\n     )\n     super().__init__(build_fn, **sk_params)\n \n@@ -334,7 +334,7 @@ class KerasRegressor(BaseWrapper):\n     warnings.warn(\n         'KerasRegressor is deprecated, '\n         'use Sci-Keras (https://github.com/adriangb/scikeras) instead.',\n-        DeprecationWarning\n+        DeprecationWarning, stacklevel=2\n     )\n     super().__init__(build_fn, **sk_params)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1e6647ba69ff38f439ef3cba4a219882a2bfc6db", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 7215 | Contributors (this commit): 95 | Commits (past 90d): 13 | Contributors (cumulative): 95 | DMM Complexity: None\n\nDIFF:\n@@ -1824,8 +1824,8 @@ class EarlyStopping(Callback):\n       self.model.stop_training = True\n       if self.restore_best_weights and self.best_weights is not None:\n         if self.verbose > 0:\n-          print('Restoring model weights from the end of the best epoch (%s).' %\n-                (self.best_epoch + 1))\n+          print('Restoring model weights from the end of the best epoch: '\n+                f'{self.best_epoch + 1}.')\n         self.model.set_weights(self.best_weights)\n \n   def on_train_end(self, logs=None):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e24262ab08d7eaa5405c39281a38439b699d7e3d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 47 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 2 | Methods Changed: 7 | Complexity Δ (Sum/Max): 7/7 | Churn Δ: 48 | Churn Cumulative: 2487 | Contributors (this commit): 32 | Commits (past 90d): 9 | Contributors (cumulative): 35 | DMM Complexity: 1.0\n\nDIFF:\n@@ -284,7 +284,7 @@ def print_summary(model, line_length=None, positions=None,\n     else:\n       print_layer_summary_with_connections(layer, nested_level)\n \n-    if expand_nested and isinstance(layer, type(model)) and layer.layers:\n+    if expand_nested and hasattr(layer, 'layers') and layer.layers:\n       print_fn('|' * (nested_level + 1) +\n                '¯' * (line_length - 2 * nested_level - 2) +\n                '|' * (nested_level + 1))\n\n@@ -111,6 +111,52 @@ class LayerUtilsTest(tf.test.TestCase):\n     except ImportError:\n       pass\n \n+  def test_summary_subclass_model_expand_nested(self):\n+\n+    class SampleModel(tf.keras.Model):\n+\n+      def __init__(self, classes, backbone_model, *args, **kwargs):\n+          super(SampleModel, self).__init__(self, args, kwargs)\n+          self.backbone = backbone_model\n+          self.classify_layer = keras.layers.Dense(\n+              classes, activation='sigmoid')\n+\n+      def my_process_layers(self, inputs):\n+          layers = self.backbone.layers\n+          tmp_x = inputs\n+          for i in range(1, len(layers)):\n+              tmp_x = layers[i](tmp_x)\n+          return tmp_x\n+\n+      def call(self, inputs):\n+          x = self.my_process_layers(inputs)\n+          x = self.classify_layer(x)\n+          return x\n+\n+    inputs = keras.Input(shape=(224, 224, 3))\n+    model = SampleModel(inputs=inputs, classes=61,\n+                        backbone_model=tf.keras.applications.MobileNet())\n+    model.build(input_shape=(20, 224, 224, 3))\n+\n+    file_name = 'model_3.txt'\n+    writer = open(file_name, 'w')\n+\n+    def print_to_file(text, end=\"\\n\"):\n+      print(text, end=end, file=writer)\n+    try:\n+      layer_utils.print_summary(model, line_length=120,\n+                                print_fn=print_to_file, expand_nested=True)\n+      self.assertTrue(tf.io.gfile.exists(file_name))\n+      writer.close()\n+      reader = open(file_name, 'r')\n+      lines = reader.readlines()\n+      reader.close()\n+      self.assertEquals(len(lines), 197)\n+      tf.io.gfile.remove(file_name)\n+\n+    except ImportError:\n+      pass\n+\n   def test_property_cache(self):\n     test_counter = collections.Counter()\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#317dd1491b0a0f3550b39e06e99a13755ae45866", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 60 | Lines Deleted: 40 | Files Changed: 1 | Hunks: 7 | Methods Changed: 11 | Complexity Δ (Sum/Max): 7/7 | Churn Δ: 100 | Churn Cumulative: 391 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -68,29 +68,28 @@ class LayerUtilsTest(tf.test.TestCase):\n       reader = open(file_name, 'r')\n       lines = reader.readlines()\n       reader.close()\n-      self.assertEquals(len(lines), 15)\n+      self.assertEqual(len(lines), 15)\n       tf.io.gfile.remove(file_name)\n \n     except ImportError:\n       pass\n \n   def test_print_summary_expand_nested(self):\n-    inputs = keras.Input(shape=(None, 3))\n-    lstm = keras.layers.LSTM(6, return_sequences=True, name='lstm')\n-    x = lstm(inputs)\n-    # Add layer inside a Wrapper\n-    bilstm = keras.layers.Bidirectional(\n-        keras.layers.LSTM(16, return_sequences=True, name='bilstm'))\n-    x = bilstm(x)\n-    # Add model inside a Wrapper\n-    submodel = keras.Sequential(\n-        [keras.layers.Dense(32, name='dense', input_shape=(None, 32))]\n-    )\n-    wrapped_dense = keras.layers.TimeDistributed(submodel)\n-    x = wrapped_dense(x)\n-    # Add shared submodel\n-    outputs = submodel(x)\n-    model = keras.Model(inputs, outputs)\n+    shape = (None, None, 3)\n+\n+    def BNModel():\n+        x = inputs = keras.Input(shape)\n+        x = keras.layers.Conv2D(3, 1)(x)\n+        x = keras.layers.BatchNormalization()(x)\n+        return keras.Model(inputs, x)\n+\n+    x = inner_inputs = keras.Input(shape)\n+    x = BNModel()(x)\n+    x = BNModel()(x)\n+    inner_model = keras.Model(inner_inputs, x)\n+\n+    inputs = keras.Input(shape)\n+    model = keras.Model(inputs, inner_model(inputs))\n \n     file_name = 'model_2.txt'\n     writer = open(file_name, 'w')\n@@ -105,7 +104,7 @@ class LayerUtilsTest(tf.test.TestCase):\n       reader = open(file_name, 'r')\n       lines = reader.readlines()\n       reader.close()\n-      self.assertEquals(len(lines), 23)\n+      self.assertEqual(len(lines), 34)\n       tf.io.gfile.remove(file_name)\n \n     except ImportError:\n@@ -113,30 +112,51 @@ class LayerUtilsTest(tf.test.TestCase):\n \n   def test_summary_subclass_model_expand_nested(self):\n \n-    class SampleModel(tf.keras.Model):\n+    class Sequential(keras.Model):\n+      def __init__(self, *args):\n+          super(Sequential, self).__init__()\n+          self.module_list = list(args) if args else []\n \n-      def __init__(self, classes, backbone_model, *args, **kwargs):\n-          super(SampleModel, self).__init__(self, args, kwargs)\n-          self.backbone = backbone_model\n-          self.classify_layer = keras.layers.Dense(\n-              classes, activation='sigmoid')\n-\n-      def my_process_layers(self, inputs):\n-          layers = self.backbone.layers\n-          tmp_x = inputs\n-          for i in range(1, len(layers)):\n-              tmp_x = layers[i](tmp_x)\n-          return tmp_x\n-\n-      def call(self, inputs):\n-          x = self.my_process_layers(inputs)\n-          x = self.classify_layer(x)\n+      def call(self, x):\n+          for module in self.module_list:\n+              x = module(x)\n           return x\n \n-    inputs = keras.Input(shape=(224, 224, 3))\n-    model = SampleModel(inputs=inputs, classes=61,\n-                        backbone_model=tf.keras.applications.MobileNet())\n-    model.build(input_shape=(20, 224, 224, 3))\n+    class Block(keras.Model):\n+        def __init__(self):\n+            super(Block, self).__init__()\n+            self.module = Sequential(\n+                    keras.layers.Dense(10),\n+                    keras.layers.Dense(10),)\n+\n+        def call(self, input_tensor):\n+            x = self.module(input_tensor)\n+            return x\n+\n+    class Base(keras.Model):\n+        def __init__(self):\n+            super(Base, self).__init__()\n+            self.module = Sequential(\n+                    Block(),\n+                    Block())\n+\n+        def call(self, input_tensor):\n+            x = self.module(input_tensor)\n+            y = self.module(x)\n+            return x, y\n+\n+    class Network(keras.Model):\n+        def __init__(self):\n+            super(Network, self).__init__()\n+            self.child = Base()\n+\n+        def call(self, inputs):\n+            return self.child(inputs)\n+\n+    net = Network()\n+    inputs = keras.Input(shape=(10, ))\n+    outputs = net(inputs)\n+    model = keras.models.Model(inputs=inputs, outputs=outputs)\n \n     file_name = 'model_3.txt'\n     writer = open(file_name, 'w')\n@@ -151,7 +171,7 @@ class LayerUtilsTest(tf.test.TestCase):\n       reader = open(file_name, 'r')\n       lines = reader.readlines()\n       reader.close()\n-      self.assertEquals(len(lines), 197)\n+      self.assertEqual(len(lines), 39)\n       tf.io.gfile.remove(file_name)\n \n     except ImportError:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#47196da9eb7a4e64b319ad6175d363077de2bf9a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 5 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 7222 | Contributors (this commit): 95 | Commits (past 90d): 14 | Contributors (cumulative): 95 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2393,7 +2393,6 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):\n   def on_train_begin(self, logs=None):\n     self._global_train_batch = 0\n     self._previous_epoch_iterations = 0\n-    self._train_accumulated_time = 0\n     self._push_writer(self._train_writer, self._train_step)\n \n   def on_train_end(self, logs=None):\n@@ -2438,7 +2437,6 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):\n       self._should_write_train_graph = False\n     if self.write_steps_per_second:\n       batch_run_time = time.time() - self._batch_start_time\n-      self._train_accumulated_time += batch_run_time\n       tf.summary.scalar(\n           'batch_steps_per_second', 1. / batch_run_time, step=self._train_step)\n     if not self._should_trace:\n@@ -2451,7 +2449,7 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):\n     # Keeps track of epoch for profiling.\n     if self.write_steps_per_second:\n       self._previous_epoch_iterations = self.model.optimizer.iterations.numpy()\n-      self._train_accumulated_time = 0\n+      self._epoch_start_time = time.time()\n \n   def on_epoch_end(self, epoch, logs=None):\n     \"\"\"Runs metrics and histogram summaries at epoch end.\"\"\"\n@@ -2487,8 +2485,9 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):\n \n   def _compute_steps_per_second(self):\n     current_iteration = self.model.optimizer.iterations.numpy()\n+    time_since_epoch_begin = time.time() - self._epoch_start_time\n     steps_per_second = ((current_iteration - self._previous_epoch_iterations) /\n-                        (self._train_accumulated_time))\n+                        time_since_epoch_begin)\n     return steps_per_second\n \n   def _log_epoch_metrics(self, epoch, logs):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#247ef93e35b16c9af85ad0f87e1f9b524411ac34", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 165 | Contributors (this commit): 4 | Commits (past 90d): 2 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -86,7 +86,7 @@ class BenchmarkLayer(tf.test.Benchmark):\n       ds = ds.prefetch(batch_size)\n       img_augmentation = functools.partial(\n           image_augmentation, batch_size=batch_size)\n-      ds = ds.map(img_augmentation)\n+      ds = ds.map(img_augmentation,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n       starts.append(time.time())\n       count = 0\n       # Benchmarked code begins here.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b8d5b516149455b51454ce890cff79a0371505da", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 82 | Contributors (this commit): 2 | Commits (past 90d): 1 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -48,7 +48,7 @@ class MemoryTests(tf.test.TestCase):\n     self._model = _ModelWithOptimizerUsingDefun()\n \n   @test_util.assert_no_garbage_created\n-  def test_no_reference_cycles(self):\n+  def DISABLED_test_no_reference_cycles(self):\n     x = tf.constant([[3., 4.]])\n     y = tf.constant([2.])\n     self._model.call(x, y)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4cdb5a9441c467821bf7b5b31f060bbe6687dcfa", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 18 | Lines Deleted: 18 | Files Changed: 18 | Hunks: 18 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 36 | Churn Cumulative: 2884 | Contributors (this commit): 6 | Commits (past 90d): 31 | Contributors (cumulative): 34 | DMM Complexity: None\n\nDIFF:\n@@ -15,7 +15,7 @@\n \"\"\"Tests for KPL + CentralStorageStrategy.\"\"\"\n \n from absl.testing import parameterized\n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from tensorflow.python.distribute import combinations as ds_combinations\n from tensorflow.python.distribute import strategy_combinations\n\n@@ -17,7 +17,7 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n ds_combinations = tf.__internal__.distribute.combinations\n \n # Note: Strategy combinations are not (yet) public APIs, so they are subject\n\n@@ -17,7 +17,7 @@ import functools\n \n from absl.testing import parameterized\n import numpy as np\n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n \n def _jvp(f, primals, tangents):\n\n@@ -15,7 +15,7 @@\n \n import sys\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n \n class MiniModel(tf.keras.Model):\n\n@@ -15,7 +15,7 @@\n \n import gc\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from tensorflow.python.platform import test as test_lib\n \n\n@@ -14,7 +14,7 @@\n # ==============================================================================\n \n import numpy as np\n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n \n class TestKerasModelClass(tf.keras.Model):\n\n@@ -13,7 +13,7 @@\n # limitations under the License.\n # ==============================================================================\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n \n class ModuleTest(tf.test.TestCase):\n\n@@ -23,7 +23,7 @@ import zipfile\n from absl import logging\n from absl.testing import parameterized\n import numpy as np\n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n PER_WORKER_BATCH_SIZE = 64\n NUM_WORKERS = 2\n\n@@ -19,7 +19,7 @@ from __future__ import print_function\n import multiprocessing\n from absl import logging\n import portpicker\n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n NUM_EPOCHS = 10\n NUM_STEPS = 100\n\n@@ -22,7 +22,7 @@ import tempfile\n from absl.testing import parameterized\n import numpy as np\n import portpicker\n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n \n # These vocabularies usually come from TFT or a Beam pipeline.\n\n@@ -17,7 +17,7 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras.integration_test import preprocessing_test_utils as utils\n \n ds_combinations = tf.__internal__.distribute.combinations\n\n@@ -17,7 +17,7 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras.integration_test import preprocessing_test_utils as utils\n \n ds_combinations = tf.__internal__.distribute.combinations\n\n@@ -17,7 +17,7 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras.integration_test import preprocessing_test_utils as utils\n \n ds_combinations = tf.__internal__.distribute.combinations\n\n@@ -16,7 +16,7 @@\n \n import os\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n preprocessing = tf.keras.layers\n \n BATCH_SIZE = 64\n\n@@ -18,7 +18,7 @@ import tempfile\n \n from absl.testing import parameterized\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n \n def cycle(obj, cycles, signatures=None):\n\n@@ -18,7 +18,7 @@ import tempfile\n \n from absl import flags\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n import tensorflow_text as tf_text\n \n \n\n@@ -19,7 +19,7 @@ import tempfile\n \n from absl import flags\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from tensorflow.python.framework import test_util\n \n FLAGS = flags.FLAGS\n\n@@ -13,7 +13,7 @@\n # limitations under the License.\n # ==============================================================================\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n \n class VectorizedMapTest(tf.test.TestCase):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
