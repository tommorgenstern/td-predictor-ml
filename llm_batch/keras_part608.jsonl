{"custom_id": "keras#b4de088ee877ed9ad62e8819cb7a05b1c021ef1a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 368 | Contributors (this commit): 2 | Commits (past 90d): 4 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -95,7 +95,7 @@ class ZeroPadding3D(Layer):\n                 \"((left_dim1_pad, right_dim1_pad),\"\n                 \" (left_dim2_pad, right_dim2_pad),\"\n                 \" (left_dim3_pad, right_dim2_pad)). \"\n-                f\"Received: {padding}.\"\n+                f\"Received: padding={padding}.\"\n             )\n         self.input_spec = InputSpec(ndim=5)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#04436b0da6fddeb177a93f15a4c6c290d016bf27", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 3 | Methods Changed: 4 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 20 | Churn Cumulative: 29 | Contributors (this commit): 3 | Commits (past 90d): 5 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -87,7 +87,7 @@ class Variable(KerasVariable):\n \n def convert_to_tensor(x, dtype=None):\n     # TODO: Need to address device placement arg of `as_tensor`\n-    dtype = to_torch_dtype(dtype)\n+    dtype = to_torch_dtype(dtype or x.dtype)\n     if isinstance(x, Variable):\n         if dtype and dtype != x.dtype:\n             return x.value.to(dtype)\n@@ -126,8 +126,20 @@ def cond(pred, true_fn, false_fn):\n \n \n def vectorized_map(function, elements):\n-    raise NotImplementedError\n+    return torch.vmap(function)(elements)\n \n \n-def scatter(*args, **kwargs):\n-    raise NotImplementedError\n+def scatter(indices, values, shape):\n+    indices = convert_to_tensor(indices)\n+    values = convert_to_tensor(values)\n+    zeros = torch.zeros(shape, dtype=values.dtype)\n+\n+    index_length = indices.shape[-1]\n+    value_shape = shape[index_length:]\n+    indices = torch.reshape(indices, [-1, index_length])\n+    values = torch.reshape(values, [-1] + list(value_shape))\n+\n+    for i in range(indices.shape[0]):\n+        index = indices[i]\n+        zeros[tuple(index)] += values[i]\n+    return zeros\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#00d7e176ac631a0c7d5bd38f4e19cd3a68c9f8e5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 6/3 | Churn Δ: 8 | Churn Cumulative: 889 | Contributors (this commit): 15 | Commits (past 90d): 4 | Contributors (cumulative): 25 | DMM Complexity: None\n\nDIFF:\n@@ -52,14 +52,14 @@ def load_data():\n     Returns:\n       Tuple of NumPy arrays: `(x_train, y_train), (x_test, y_test)`.\n \n-    **x_train**: uint8 NumPy array of grayscale image data with shapes\n+    **x_train**: uint8 NumPy array of image data with shapes\n       `(50000, 32, 32, 3)`, containing the training data. Pixel values range\n       from 0 to 255.\n \n     **y_train**: uint8 NumPy array of labels (integers in range 0-9)\n       with shape `(50000, 1)` for the training data.\n \n-    **x_test**: uint8 NumPy array of grayscale image data with shapes\n+    **x_test**: uint8 NumPy array of image data with shapes\n       `(10000, 32, 32, 3)`, containing the test data. Pixel values range\n       from 0 to 255.\n \n\n@@ -43,14 +43,14 @@ def load_data(label_mode=\"fine\"):\n     Returns:\n       Tuple of NumPy arrays: `(x_train, y_train), (x_test, y_test)`.\n \n-    **x_train**: uint8 NumPy array of grayscale image data with shapes\n+    **x_train**: uint8 NumPy array of image data with shapes\n       `(50000, 32, 32, 3)`, containing the training data. Pixel values range\n       from 0 to 255.\n \n     **y_train**: uint8 NumPy array of labels (integers in range 0-99)\n       with shape `(50000, 1)` for the training data.\n \n-    **x_test**: uint8 NumPy array of grayscale image data with shapes\n+    **x_test**: uint8 NumPy array of image data with shapes\n       `(10000, 32, 32, 3)`, containing the test data. Pixel values range\n       from 0 to 255.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7fe95d6a80fe3d670385b618335d879b0a6aa9ed", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 300 | Contributors (this commit): 4 | Commits (past 90d): 4 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -88,10 +88,10 @@ class Ftrl(optimizer.Optimizer):\n         l2_regularization_strength: A float value, must be greater than or equal\n             to zero. Defaults to `0.0`.\n         l2_shrinkage_regularization_strength: A float value, must be greater\n-        than or equal to zero. This differs from L2 above in that the L2 above\n-        is a stabilization penalty, whereas this L2 shrinkage is a magnitude\n-        penalty. When input is sparse shrinkage will only happen on the active\n-        weights.\n+            than or equal to zero. This differs from L2 above in that the L2\n+            above is a stabilization penalty, whereas this L2 shrinkage is a\n+            magnitude penalty. When input is sparse shrinkage will only happen\n+            on the active weights.\n         beta: A float value, representing the beta value from the paper.\n             Defaults to 0.0.\n         {{base_optimizer_keyword_args}}\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#485535486481ae413d5e1033eef9b876d31d5b0a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 224 | Contributors (this commit): 5 | Commits (past 90d): 4 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -59,8 +59,8 @@ class SGD(optimizer.Optimizer):\n             that takes no arguments and returns the actual value to use. The\n             learning rate. Defaults to 0.001.\n         momentum: float hyperparameter >= 0 that accelerates gradient descent in\n-        the relevant direction and dampens oscillations. Defaults to 0, i.e.,\n-        vanilla gradient descent.\n+            the relevant direction and dampens oscillations.\n+            Defaults to 0, i.e., vanilla gradient descent.\n         nesterov: boolean. Whether to apply Nesterov momentum.\n             Defaults to `False`.\n       {{base_optimizer_keyword_args}}\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9b0184f6449dfeb4ebb16b47064362939ea32b25", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 262 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 3 | Methods Changed: 7 | Complexity Δ (Sum/Max): 20/14 | Churn Δ: 262 | Churn Cumulative: 417 | Contributors (this commit): 10 | Commits (past 90d): 80 | Contributors (cumulative): 12 | DMM Complexity: 0.7865853658536586\n\nDIFF:\n@@ -103,6 +103,7 @@ from keras_core.layers.reshaping.permute import Permute\n from keras_core.layers.reshaping.repeat_vector import RepeatVector\n from keras_core.layers.reshaping.reshape import Reshape\n from keras_core.layers.reshaping.up_sampling1d import UpSampling1D\n+from keras_core.layers.reshaping.up_sampling3d import UpSampling3D\n from keras_core.layers.reshaping.zero_padding3d import ZeroPadding3D\n from keras_core.layers.rnn.bidirectional import Bidirectional\n from keras_core.layers.rnn.conv_lstm1d import ConvLSTM1D\n\n@@ -0,0 +1,136 @@\n+from keras_core import backend\n+from keras_core import operations as ops\n+from keras_core.api_export import keras_core_export\n+from keras_core.layers.input_spec import InputSpec\n+from keras_core.layers.layer import Layer\n+from keras_core.utils import argument_validation\n+\n+\n+@keras_core_export(\"keras_core.layers.UpSampling3D\")\n+class UpSampling3D(Layer):\n+    \"\"\"Upsampling layer for 3D inputs.\n+\n+    Repeats the 1st, 2nd and 3rd dimensions\n+    of the data by `size[0]`, `size[1]` and `size[2]` respectively.\n+\n+    Examples:\n+    >>> input_shape = (2, 1, 2, 1, 3)\n+    >>> x = np.ones(input_shape)\n+    >>> y = keras_core.layers.UpSampling3D(size=(2, 2, 2))(x)\n+    >>> y.shape\n+    (2, 2, 4, 2, 3)\n+\n+    Args:\n+        size: Int, or tuple of 3 integers.\n+            The upsampling factors for dim1, dim2 and dim3.\n+        data_format: A string,\n+            one of `\"channels_last\"` (default) or `\"channels_first\"`.\n+            The ordering of the dimensions in the inputs.\n+            `\"channels_last\"` corresponds to inputs with shape\n+            `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n+            while `\"channels_first\"` corresponds to inputs with shape\n+            `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n+            When unspecified, uses\n+            `image_data_format` value found in your Keras config file at\n+             `~/.keras/keras.json` (if exists) else `\"channels_last\"`.\n+            Defaults to `\"channels_last\"`.\n+\n+    Input shape:\n+        5D tensor with shape:\n+        - If `data_format` is `\"channels_last\"`:\n+            `(batch_size, dim1, dim2, dim3, channels)`\n+        - If `data_format` is `\"channels_first\"`:\n+            `(batch_size, channels, dim1, dim2, dim3)`\n+\n+    Output shape:\n+        5D tensor with shape:\n+        - If `data_format` is `\"channels_last\"`:\n+            `(batch_size, upsampled_dim1, upsampled_dim2, upsampled_dim3,\n+            channels)`\n+        - If `data_format` is `\"channels_first\"`:\n+            `(batch_size, channels, upsampled_dim1, upsampled_dim2,\n+            upsampled_dim3)`\n+    \"\"\"\n+\n+    def __init__(self, size=(2, 2, 2), data_format=None, **kwargs):\n+        super().__init__(**kwargs)\n+        self.data_format = backend.config.standardize_data_format(data_format)\n+        self.size = argument_validation.standardize_tuple(size, 3, \"size\")\n+        self.input_spec = InputSpec(ndim=5)\n+\n+    def compute_output_shape(self, input_shape):\n+        if self.data_format == \"channels_first\":\n+            dim1 = (\n+                self.size[0] * input_shape[2]\n+                if input_shape[2] is not None\n+                else None\n+            )\n+            dim2 = (\n+                self.size[1] * input_shape[3]\n+                if input_shape[3] is not None\n+                else None\n+            )\n+            dim3 = (\n+                self.size[2] * input_shape[4]\n+                if input_shape[4] is not None\n+                else None\n+            )\n+            return (input_shape[0], input_shape[1], dim1, dim2, dim3)\n+        else:\n+            dim1 = (\n+                self.size[0] * input_shape[1]\n+                if input_shape[1] is not None\n+                else None\n+            )\n+            dim2 = (\n+                self.size[1] * input_shape[2]\n+                if input_shape[2] is not None\n+                else None\n+            )\n+            dim3 = (\n+                self.size[2] * input_shape[3]\n+                if input_shape[3] is not None\n+                else None\n+            )\n+            return (input_shape[0], dim1, dim2, dim3, input_shape[4])\n+\n+    def call(self, inputs):\n+        return self._resize_volumes(\n+            inputs, self.size[0], self.size[1], self.size[2], self.data_format\n+        )\n+\n+    def get_config(self):\n+        config = {\"size\": self.size, \"data_format\": self.data_format}\n+        base_config = super().get_config()\n+        return {**base_config, **config}\n+\n+    def _resize_volumes(\n+        self, x, depth_factor, height_factor, width_factor, data_format\n+    ):\n+        \"\"\"Resizes the volume contained in a 5D tensor.\n+        Args:\n+            x: Tensor or variable to resize.\n+            depth_factor: Positive integer.\n+            height_factor: Positive integer.\n+            width_factor: Positive integer.\n+            data_format: One of `\"channels_first\"`, `\"channels_last\"`.\n+\n+        Returns:\n+            A tensor.\n+\n+        Raises:\n+            ValueError: if `data_format` is neither\n+                `channels_last` or `channels_first`.\n+        \"\"\"\n+        if data_format == \"channels_first\":\n+            output = ops.repeat(x, depth_factor, axis=2)\n+            output = ops.repeat(output, height_factor, axis=3)\n+            output = ops.repeat(output, width_factor, axis=4)\n+            return output\n+        elif data_format == \"channels_last\":\n+            output = ops.repeat(x, depth_factor, axis=1)\n+            output = ops.repeat(output, height_factor, axis=2)\n+            output = ops.repeat(output, width_factor, axis=3)\n+            return output\n+        else:\n+            raise ValueError(\"Invalid data_format: \" + str(data_format))\n\n@@ -0,0 +1,125 @@\n+import numpy as np\n+from absl.testing import parameterized\n+\n+from keras_core import backend\n+from keras_core import layers\n+from keras_core import testing\n+\n+\n+class UpSampling3dTest(testing.TestCase, parameterized.TestCase):\n+    @parameterized.product(\n+        data_format=[\"channels_first\", \"channels_last\"],\n+        length_dim1=[2, 3],\n+        length_dim2=[2],\n+        length_dim3=[3],\n+    )\n+    def test_upsampling_3d(\n+        self, data_format, length_dim1, length_dim2, length_dim3\n+    ):\n+        num_samples = 2\n+        stack_size = 2\n+        input_len_dim1 = 10\n+        input_len_dim2 = 11\n+        input_len_dim3 = 12\n+\n+        if data_format == \"channels_first\":\n+            inputs = np.random.rand(\n+                num_samples,\n+                stack_size,\n+                input_len_dim1,\n+                input_len_dim2,\n+                input_len_dim3,\n+            )\n+        else:\n+            inputs = np.random.rand(\n+                num_samples,\n+                input_len_dim1,\n+                input_len_dim2,\n+                input_len_dim3,\n+                stack_size,\n+            )\n+\n+        # basic test\n+        if data_format == \"channels_first\":\n+            expected_output_shape = (2, 2, 20, 22, 24)\n+        else:\n+            expected_output_shape = (2, 20, 22, 24, 2)\n+\n+        self.run_layer_test(\n+            layers.UpSampling3D,\n+            init_kwargs={\"size\": (2, 2, 2), \"data_format\": data_format},\n+            input_shape=inputs.shape,\n+            expected_output_shape=expected_output_shape,\n+            expected_output_dtype=\"float32\",\n+            expected_num_trainable_weights=0,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_seed_generators=0,\n+            expected_num_losses=0,\n+            supports_masking=False,\n+        )\n+\n+        layer = layers.UpSampling3D(\n+            size=(length_dim1, length_dim2, length_dim3),\n+            data_format=data_format,\n+        )\n+        layer.build(inputs.shape)\n+        np_output = layer(inputs=backend.Variable(inputs))\n+        if data_format == \"channels_first\":\n+            assert np_output.shape[2] == length_dim1 * input_len_dim1\n+            assert np_output.shape[3] == length_dim2 * input_len_dim2\n+            assert np_output.shape[4] == length_dim3 * input_len_dim3\n+        else:  # tf\n+            assert np_output.shape[1] == length_dim1 * input_len_dim1\n+            assert np_output.shape[2] == length_dim2 * input_len_dim2\n+            assert np_output.shape[3] == length_dim3 * input_len_dim3\n+\n+        # compare with numpy\n+        if data_format == \"channels_first\":\n+            expected_out = np.repeat(inputs, length_dim1, axis=2)\n+            expected_out = np.repeat(expected_out, length_dim2, axis=3)\n+            expected_out = np.repeat(expected_out, length_dim3, axis=4)\n+        else:  # tf\n+            expected_out = np.repeat(inputs, length_dim1, axis=1)\n+            expected_out = np.repeat(expected_out, length_dim2, axis=2)\n+            expected_out = np.repeat(expected_out, length_dim3, axis=3)\n+\n+        np.testing.assert_allclose(np_output, expected_out)\n+\n+    def test_upsampling_3d_correctness(self):\n+        input_shape = (2, 1, 2, 1, 3)\n+        x = np.arange(np.prod(input_shape)).reshape(input_shape)\n+        np.testing.assert_array_equal(\n+            layers.UpSampling3D(size=(2, 2, 2))(x),\n+            np.array(\n+                [\n+                    [\n+                        [\n+                            [[0.0, 1.0, 2.0], [0.0, 1.0, 2.0]],\n+                            [[0.0, 1.0, 2.0], [0.0, 1.0, 2.0]],\n+                            [[3.0, 4.0, 5.0], [3.0, 4.0, 5.0]],\n+                            [[3.0, 4.0, 5.0], [3.0, 4.0, 5.0]],\n+                        ],\n+                        [\n+                            [[0.0, 1.0, 2.0], [0.0, 1.0, 2.0]],\n+                            [[0.0, 1.0, 2.0], [0.0, 1.0, 2.0]],\n+                            [[3.0, 4.0, 5.0], [3.0, 4.0, 5.0]],\n+                            [[3.0, 4.0, 5.0], [3.0, 4.0, 5.0]],\n+                        ],\n+                    ],\n+                    [\n+                        [\n+                            [[6.0, 7.0, 8.0], [6.0, 7.0, 8.0]],\n+                            [[6.0, 7.0, 8.0], [6.0, 7.0, 8.0]],\n+                            [[9.0, 10.0, 11.0], [9.0, 10.0, 11.0]],\n+                            [[9.0, 10.0, 11.0], [9.0, 10.0, 11.0]],\n+                        ],\n+                        [\n+                            [[6.0, 7.0, 8.0], [6.0, 7.0, 8.0]],\n+                            [[6.0, 7.0, 8.0], [6.0, 7.0, 8.0]],\n+                            [[9.0, 10.0, 11.0], [9.0, 10.0, 11.0]],\n+                            [[9.0, 10.0, 11.0], [9.0, 10.0, 11.0]],\n+                        ],\n+                    ],\n+                ]\n+            ),\n+        )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5b1c0ed4440b8a5c5923c696a8abad4760a2bfc2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 185 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 3 | Methods Changed: 13 | Complexity Δ (Sum/Max): 24/17 | Churn Δ: 185 | Churn Cumulative: 341 | Contributors (this commit): 11 | Commits (past 90d): 81 | Contributors (cumulative): 13 | DMM Complexity: 1.0\n\nDIFF:\n@@ -114,3 +114,4 @@ from keras_core.layers.rnn.lstm import LSTM\n from keras_core.layers.rnn.rnn import RNN\n from keras_core.layers.rnn.simple_rnn import SimpleRNN\n from keras_core.layers.rnn.stacked_rnn_cells import StackedRNNCells\n+from keras_core.layers.rnn.time_distributed import TimeDistributed\n\n@@ -0,0 +1,114 @@\n+\"\"\"Wrapper layer to apply every temporal slice of an input.\"\"\"\n+\n+from keras_core import backend\n+from keras_core import operations as ops\n+from keras_core.api_export import keras_core_export\n+from keras_core.layers.core.wrapper import Wrapper\n+from keras_core.layers.layer import Layer\n+\n+\n+@keras_core_export(\"keras_core.layers.TimeDistributed\")\n+class TimeDistributed(Wrapper):\n+    \"\"\"This wrapper allows to apply a layer to every temporal slice of an input.\n+\n+    Every input should be at least 3D, and the dimension of index one of the\n+    first input will be considered to be the temporal dimension.\n+\n+    Consider a batch of 32 video samples, where each sample is a 128x128 RGB\n+    image with `channels_last` data format, across 10 timesteps.\n+    The batch input shape is `(32, 10, 128, 128, 3)`.\n+\n+    You can then use `TimeDistributed` to apply the same `Conv2D` layer to each\n+    of the 10 timesteps, independently:\n+\n+    >>> inputs = layers.Input(shape=(10, 128, 128, 3), batch_size=32)\n+    >>> conv_2d_layer = layers.Conv2D(64, (3, 3))\n+    >>> outputs = layers.TimeDistributed(conv_2d_layer)(inputs)\n+    >>> outputs.shape\n+    (32, 10, 126, 126, 64)\n+\n+    Because `TimeDistributed` applies the same instance of `Conv2D` to each of\n+    the timestamps, the same set of weights are used at each timestamp.\n+\n+    Args:\n+        layer: a `keras_core.layers.Layer` instance.\n+\n+    Call arguments:\n+        inputs: Input tensor of shape (batch, time, ...) or nested tensors,\n+            and each of which has shape (batch, time, ...).\n+        training: Python boolean indicating whether the layer should behave in\n+            training mode or in inference mode. This argument is passed to the\n+            wrapped layer (only if the layer supports this argument).\n+        mask: Binary tensor of shape `(samples, timesteps)` indicating whether\n+            a given timestep should be masked. This argument is passed to the\n+            wrapped layer (only if the layer supports this argument).\n+    \"\"\"\n+\n+    def __init__(self, layer, **kwargs):\n+        if not isinstance(layer, Layer):\n+            raise ValueError(\n+                \"Please initialize `TimeDistributed` layer with a \"\n+                f\"`keras_core.layers.Layer` instance. Received: {layer}\"\n+            )\n+        super().__init__(layer, **kwargs)\n+        self.supports_masking = True\n+\n+    def _get_child_input_shape(self, input_shape):\n+        if not isinstance(input_shape, (tuple, list)) or len(input_shape) < 3:\n+            raise ValueError(\n+                \"`TimeDistributed` Layer should be passed an `input_shape` \"\n+                f\"with at least 3 dimensions, received: {input_shape}\"\n+            )\n+        return (input_shape[0], *input_shape[2:])\n+\n+    def compute_output_shape(self, input_shape):\n+        child_input_shape = self._get_child_input_shape(input_shape)\n+        child_output_shape = self.layer.compute_output_shape(child_input_shape)\n+        return (child_output_shape[0], input_shape[1], *child_output_shape[1:])\n+\n+    def build(self, input_shape):\n+        child_input_shape = self._get_child_input_shape(input_shape)\n+        super().build(child_input_shape)\n+        self.built = True\n+\n+    def call(self, inputs, training=None, mask=None):\n+        input_shape = inputs.shape\n+        mask_shape = None if mask is None else tuple(mask.shape)\n+        batch_size = input_shape[0]\n+        timesteps = input_shape[1]\n+\n+        if mask_shape is not None and mask_shape[:2] != (batch_size, timesteps):\n+            raise ValueError(\n+                \"`TimeDistributed` Layer should be passed a `mask` of shape \"\n+                f\"({batch_size}, {timesteps}, ...), \"\n+                f\"received: mask.shape={mask_shape}\"\n+            )\n+\n+        def time_distributed_transpose(data):\n+            \"\"\"Swaps the timestep and batch dimensions of a tensor.\"\"\"\n+            axes = [1, 0, *range(2, len(data.shape))]\n+            return ops.transpose(data, axes=axes)\n+\n+        time_distributed_inputs = time_distributed_transpose(inputs)\n+        if mask is None:\n+            time_distributed_mask = None\n+        else:\n+            time_distributed_mask = time_distributed_transpose(mask)\n+\n+        def per_batch_function(batch):\n+            kwargs = {}\n+            if self.layer._call_has_mask_arg():\n+                kwargs[\"mask\"] = (\n+                    None\n+                    if time_distributed_mask is None\n+                    else time_distributed_mask[batch]\n+                )\n+            if self.layer._call_has_training_arg():\n+                kwargs[\"training\"] = training\n+            return self.layer.call(time_distributed_inputs[batch], **kwargs)\n+\n+        outputs = backend.vectorized_map(\n+            per_batch_function, ops.arange(timesteps)\n+        )\n+\n+        return time_distributed_transpose(outputs)\n\n@@ -0,0 +1,70 @@\n+import numpy as np\n+\n+from keras_core import initializers\n+from keras_core import layers\n+from keras_core import operations as ops\n+from keras_core import testing\n+\n+\n+class TimeDistributedTest(testing.TestCase):\n+    def test_basics(self):\n+        self.run_layer_test(\n+            layers.TimeDistributed,\n+            init_kwargs={\"layer\": layers.Dense(1, use_bias=False)},\n+            input_shape=(3, 2, 4),\n+            expected_output_shape=(3, 2, 1),\n+            expected_num_trainable_weights=1,\n+            expected_num_non_trainable_weights=0,\n+            supports_masking=True,\n+        )\n+\n+    def test_build(self):\n+        inputs = layers.Input(shape=(10, 128, 128, 3), batch_size=32)\n+        conv_2d_layer = layers.Conv2D(64, (3, 3))\n+        outputs = layers.TimeDistributed(conv_2d_layer)(inputs)\n+        self.assertEqual(outputs.shape, (32, 10, 126, 126, 64))\n+\n+    def test_correctness(self):\n+        sequence = np.arange(24).reshape((3, 2, 4)).astype(\"float32\")\n+        layer = layers.Dense(\n+            1,\n+            kernel_initializer=initializers.Constant(0.01),\n+            use_bias=False,\n+        )\n+        layer = layers.TimeDistributed(layer=layer)\n+        output = layer(sequence)\n+        self.assertAllClose(\n+            np.array(\n+                [[[0.06], [0.22]], [[0.38], [0.53999996]], [[0.7], [0.86]]]\n+            ),\n+            output,\n+        )\n+\n+    def test_masking(self):\n+        class MaskedDense(layers.Wrapper):\n+            def __init__(self, units, **kwargs):\n+                layer = layers.Dense(\n+                    units,\n+                    kernel_initializer=initializers.Constant(0.01),\n+                    use_bias=False,\n+                )\n+                super().__init__(layer, **kwargs)\n+                self.supports_masking = True\n+\n+            def call(self, inputs, training=False, mask=None):\n+                unmasked = self.layer.call(inputs)\n+                if mask is None:\n+                    return unmasked\n+                else:\n+                    return ops.transpose(\n+                        ops.transpose(unmasked) * ops.cast(mask, inputs.dtype)\n+                    )\n+\n+        sequence = np.arange(24).reshape((3, 2, 4)).astype(\"float32\")\n+        layer = layers.TimeDistributed(layer=MaskedDense(1))\n+        mask = np.array([[False, True], [True, False], [True, True]])\n+        output = layer(sequence, mask=mask)\n+        self.assertAllClose(\n+            np.array([[[0], [0.22]], [[0.38], [0]], [[0.7], [0.86]]]),\n+            output,\n+        )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3ed33bc7d08c36b94b9d88a6340f4309cc003816", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 185 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 3 | Methods Changed: 13 | Complexity Δ (Sum/Max): 24/17 | Churn Δ: 185 | Churn Cumulative: 711 | Contributors (this commit): 11 | Commits (past 90d): 87 | Contributors (cumulative): 15 | DMM Complexity: 1.0\n\nDIFF:\n@@ -114,3 +114,4 @@ from keras_core.layers.rnn.lstm import LSTM\n from keras_core.layers.rnn.rnn import RNN\n from keras_core.layers.rnn.simple_rnn import SimpleRNN\n from keras_core.layers.rnn.stacked_rnn_cells import StackedRNNCells\n+from keras_core.layers.rnn.time_distributed import TimeDistributed\n\n@@ -0,0 +1,114 @@\n+\"\"\"Wrapper layer to apply every temporal slice of an input.\"\"\"\n+\n+from keras_core import backend\n+from keras_core import operations as ops\n+from keras_core.api_export import keras_core_export\n+from keras_core.layers.core.wrapper import Wrapper\n+from keras_core.layers.layer import Layer\n+\n+\n+@keras_core_export(\"keras_core.layers.TimeDistributed\")\n+class TimeDistributed(Wrapper):\n+    \"\"\"This wrapper allows to apply a layer to every temporal slice of an input.\n+\n+    Every input should be at least 3D, and the dimension of index one of the\n+    first input will be considered to be the temporal dimension.\n+\n+    Consider a batch of 32 video samples, where each sample is a 128x128 RGB\n+    image with `channels_last` data format, across 10 timesteps.\n+    The batch input shape is `(32, 10, 128, 128, 3)`.\n+\n+    You can then use `TimeDistributed` to apply the same `Conv2D` layer to each\n+    of the 10 timesteps, independently:\n+\n+    >>> inputs = layers.Input(shape=(10, 128, 128, 3), batch_size=32)\n+    >>> conv_2d_layer = layers.Conv2D(64, (3, 3))\n+    >>> outputs = layers.TimeDistributed(conv_2d_layer)(inputs)\n+    >>> outputs.shape\n+    (32, 10, 126, 126, 64)\n+\n+    Because `TimeDistributed` applies the same instance of `Conv2D` to each of\n+    the timestamps, the same set of weights are used at each timestamp.\n+\n+    Args:\n+        layer: a `keras_core.layers.Layer` instance.\n+\n+    Call arguments:\n+        inputs: Input tensor of shape (batch, time, ...) or nested tensors,\n+            and each of which has shape (batch, time, ...).\n+        training: Python boolean indicating whether the layer should behave in\n+            training mode or in inference mode. This argument is passed to the\n+            wrapped layer (only if the layer supports this argument).\n+        mask: Binary tensor of shape `(samples, timesteps)` indicating whether\n+            a given timestep should be masked. This argument is passed to the\n+            wrapped layer (only if the layer supports this argument).\n+    \"\"\"\n+\n+    def __init__(self, layer, **kwargs):\n+        if not isinstance(layer, Layer):\n+            raise ValueError(\n+                \"Please initialize `TimeDistributed` layer with a \"\n+                f\"`keras_core.layers.Layer` instance. Received: {layer}\"\n+            )\n+        super().__init__(layer, **kwargs)\n+        self.supports_masking = True\n+\n+    def _get_child_input_shape(self, input_shape):\n+        if not isinstance(input_shape, (tuple, list)) or len(input_shape) < 3:\n+            raise ValueError(\n+                \"`TimeDistributed` Layer should be passed an `input_shape` \"\n+                f\"with at least 3 dimensions, received: {input_shape}\"\n+            )\n+        return (input_shape[0], *input_shape[2:])\n+\n+    def compute_output_shape(self, input_shape):\n+        child_input_shape = self._get_child_input_shape(input_shape)\n+        child_output_shape = self.layer.compute_output_shape(child_input_shape)\n+        return (child_output_shape[0], input_shape[1], *child_output_shape[1:])\n+\n+    def build(self, input_shape):\n+        child_input_shape = self._get_child_input_shape(input_shape)\n+        super().build(child_input_shape)\n+        self.built = True\n+\n+    def call(self, inputs, training=None, mask=None):\n+        input_shape = inputs.shape\n+        mask_shape = None if mask is None else tuple(mask.shape)\n+        batch_size = input_shape[0]\n+        timesteps = input_shape[1]\n+\n+        if mask_shape is not None and mask_shape[:2] != (batch_size, timesteps):\n+            raise ValueError(\n+                \"`TimeDistributed` Layer should be passed a `mask` of shape \"\n+                f\"({batch_size}, {timesteps}, ...), \"\n+                f\"received: mask.shape={mask_shape}\"\n+            )\n+\n+        def time_distributed_transpose(data):\n+            \"\"\"Swaps the timestep and batch dimensions of a tensor.\"\"\"\n+            axes = [1, 0, *range(2, len(data.shape))]\n+            return ops.transpose(data, axes=axes)\n+\n+        time_distributed_inputs = time_distributed_transpose(inputs)\n+        if mask is None:\n+            time_distributed_mask = None\n+        else:\n+            time_distributed_mask = time_distributed_transpose(mask)\n+\n+        def per_batch_function(batch):\n+            kwargs = {}\n+            if self.layer._call_has_mask_arg():\n+                kwargs[\"mask\"] = (\n+                    None\n+                    if time_distributed_mask is None\n+                    else time_distributed_mask[batch]\n+                )\n+            if self.layer._call_has_training_arg():\n+                kwargs[\"training\"] = training\n+            return self.layer.call(time_distributed_inputs[batch], **kwargs)\n+\n+        outputs = backend.vectorized_map(\n+            per_batch_function, ops.arange(timesteps)\n+        )\n+\n+        return time_distributed_transpose(outputs)\n\n@@ -0,0 +1,70 @@\n+import numpy as np\n+\n+from keras_core import initializers\n+from keras_core import layers\n+from keras_core import operations as ops\n+from keras_core import testing\n+\n+\n+class TimeDistributedTest(testing.TestCase):\n+    def test_basics(self):\n+        self.run_layer_test(\n+            layers.TimeDistributed,\n+            init_kwargs={\"layer\": layers.Dense(1, use_bias=False)},\n+            input_shape=(3, 2, 4),\n+            expected_output_shape=(3, 2, 1),\n+            expected_num_trainable_weights=1,\n+            expected_num_non_trainable_weights=0,\n+            supports_masking=True,\n+        )\n+\n+    def test_build(self):\n+        inputs = layers.Input(shape=(10, 128, 128, 3), batch_size=32)\n+        conv_2d_layer = layers.Conv2D(64, (3, 3))\n+        outputs = layers.TimeDistributed(conv_2d_layer)(inputs)\n+        self.assertEqual(outputs.shape, (32, 10, 126, 126, 64))\n+\n+    def test_correctness(self):\n+        sequence = np.arange(24).reshape((3, 2, 4)).astype(\"float32\")\n+        layer = layers.Dense(\n+            1,\n+            kernel_initializer=initializers.Constant(0.01),\n+            use_bias=False,\n+        )\n+        layer = layers.TimeDistributed(layer=layer)\n+        output = layer(sequence)\n+        self.assertAllClose(\n+            np.array(\n+                [[[0.06], [0.22]], [[0.38], [0.53999996]], [[0.7], [0.86]]]\n+            ),\n+            output,\n+        )\n+\n+    def test_masking(self):\n+        class MaskedDense(layers.Wrapper):\n+            def __init__(self, units, **kwargs):\n+                layer = layers.Dense(\n+                    units,\n+                    kernel_initializer=initializers.Constant(0.01),\n+                    use_bias=False,\n+                )\n+                super().__init__(layer, **kwargs)\n+                self.supports_masking = True\n+\n+            def call(self, inputs, training=False, mask=None):\n+                unmasked = self.layer.call(inputs)\n+                if mask is None:\n+                    return unmasked\n+                else:\n+                    return ops.transpose(\n+                        ops.transpose(unmasked) * ops.cast(mask, inputs.dtype)\n+                    )\n+\n+        sequence = np.arange(24).reshape((3, 2, 4)).astype(\"float32\")\n+        layer = layers.TimeDistributed(layer=MaskedDense(1))\n+        mask = np.array([[False, True], [True, False], [True, True]])\n+        output = layer(sequence, mask=mask)\n+        self.assertAllClose(\n+            np.array([[[0], [0.22]], [[0.38], [0]], [[0.7], [0.86]]]),\n+            output,\n+        )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a1089e6602721b93894a51d983547c9c979485e8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 10/10 | Churn Δ: 19 | Churn Cumulative: 2376 | Contributors (this commit): 9 | Commits (past 90d): 13 | Contributors (cumulative): 14 | DMM Complexity: 1.0\n\nDIFF:\n@@ -85,6 +85,18 @@ class OptimizersTest(test_util.DTensorBaseTest):\n             optimizer._index_dict[optimizer._var_key(var_list[7])], 7\n         )\n \n+    def test_aggregate_gradients_noop(self):\n+        optimizer = adam.Adam(mesh=self.mesh)\n+\n+        variable_init_value = tf.ones(shape=(), dtype=tf.float32)\n+        model_variable = dtensor.DVariable(variable_init_value, trainable=True)\n+        grads = tf.ones_like(variable_init_value)\n+\n+        grad_and_var = zip([grads], [model_variable])\n+\n+        result = optimizer.aggregate_gradients(grad_and_var)\n+        self.assertEqual(result, grad_and_var)\n+\n     @parameterized.named_parameters(\n         (\n             \"Adadelta\",\n\n@@ -1174,9 +1174,12 @@ class Optimizer(_BaseOptimizer):\n           List of (gradient, variable) pairs.\n         \"\"\"\n         if self._mesh or self._run_with_dtensor:\n-            raise NotImplementedError(\n-                \"Dtensor doesn't need to manually aggregate gradients\"\n+            logging.warning(\n+                \"Calling aggregate_gradients is unnecessary when the model \"\n+                \"is used with DTensor, which includes aggregation of \"\n+                \"replicated gradients as part of backward pass.\"\n             )\n+            return grads_and_vars\n         else:\n             return optimizer_utils.all_reduce_sum_gradients(grads_and_vars)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1baec319b03cbd9a378c11b3dd4746313e347575", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1610 | Lines Deleted: 698 | Files Changed: 18 | Hunks: 205 | Methods Changed: 204 | Complexity Δ (Sum/Max): 48/125 | Churn Δ: 2308 | Churn Cumulative: 13024 | Contributors (this commit): 14 | Commits (past 90d): 182 | Contributors (cumulative): 57 | DMM Complexity: 0.0\n\nDIFF:\n@@ -26,7 +26,7 @@ class MyDense(layers.Layer):\n         # You can also use add_weight\n         self.b = self.add_weight(\n             shape=(self.units,),\n-            initializer=\"zeros\",\n+            initializer=initializers.Zeros(),\n             name=\"bias\",\n             trainable=True,\n         )\n\n@@ -6,7 +6,7 @@ from keras_core import losses\n from keras_core import metrics\n from keras_core import optimizers\n \n-inputs = layers.Input((100,), batch_size=32)\n+inputs = layers.Input((100,))\n x = layers.Dense(256, activation=\"relu\")(inputs)\n residual = x\n x = layers.Dense(256, activation=\"relu\")(x)\n@@ -27,9 +27,18 @@ model.compile(\n     loss=losses.MeanSquaredError(),\n     metrics=[metrics.CategoricalAccuracy(name=\"acc\"), metrics.MeanSquaredError(name=\"mse\")],\n )\n+\n+print(\"\\nTrain model\")\n history = model.fit(\n     x, y, batch_size=batch_size, epochs=epochs, validation_split=0.2\n )\n-\n-print(\"History:\")\n+print(\"\\nHistory:\")\n print(history.history)\n+\n+print(\"\\nEvaluate model\")\n+scores = model.evaluate(x, y, return_dict=True)\n+print(scores)\n+\n+print(\"\\nRun inference\")\n+pred = model.predict(x)\n+print(f\"Inferred output shape {pred.shape}\")\n\n@@ -9,10 +9,11 @@ class KerasTensor:\n     def __init__(self, shape, dtype=\"float32\", record_history=True, name=None):\n         from keras_core import backend\n \n-        if backend.DYNAMIC_SHAPES_OK:\n-            shape = backend.standardize_shape(shape, fully_defined=False)\n-        else:\n-            shape = backend.standardize_shape(shape, fully_defined=True)\n+        shape = backend.standardize_shape(\n+            shape,\n+            allow_dynamic_batch_size=backend.DYNAMIC_BATCH_SIZE_OK,\n+            allow_all_dynamic=backend.DYNAMIC_SHAPES_OK,\n+        )\n         self.shape = shape\n         self.dtype = backend.standardize_dtype(dtype)\n         self.name = name or auto_name(self.__class__.__name__)\n\n@@ -1,13 +1,12 @@\n from keras_core.api_export import keras_core_export\n from keras_core.backend.common import global_state\n-from keras_core.backend.common.variables import KerasVariable\n-from keras_core.backend.common.variables import initialize_all_variables\n \n \n @keras_core_export(\"keras_core.StatelessScope\")\n class StatelessScope:\n     def __init__(self, state_mapping=None, collect_losses=False):\n         from keras_core import backend\n+        from keras_core.backend.common.variables import KerasVariable\n \n         self.collect_losses = collect_losses\n         self.losses = []\n@@ -54,6 +53,10 @@ class StatelessScope:\n             # We're back in eager scope;\n             # if any variables were created within the stateless\n             # scope, we initialize them here.\n+            from keras_core.backend.common.variables import (\n+                initialize_all_variables,\n+            )\n+\n             initialize_all_variables()\n \n \n\n@@ -1,5 +1,9 @@\n+import numpy as np\n+\n from keras_core.backend import config\n from keras_core.backend.common import global_state\n+from keras_core.backend.common.stateless_scope import get_stateless_scope\n+from keras_core.backend.common.stateless_scope import in_stateless_scope\n from keras_core.utils.naming import auto_name\n \n \n@@ -20,7 +24,6 @@ class KerasVariable:\n                     f\"Received: initializer={initializer} \"\n                     f\"and shape={shape}\"\n                 )\n-        from keras_core.backend.common.stateless_scope import in_stateless_scope\n \n         if in_stateless_scope():\n             if callable(initializer):\n@@ -76,6 +79,42 @@ class KerasVariable:\n             return autocast_scope.maybe_cast(value)\n         return value\n \n+    def numpy(self):\n+        return np.array(self.value)\n+\n+    @property\n+    def value(self):\n+        if in_stateless_scope():\n+            scope = get_stateless_scope()\n+            value = scope.get_current_value(self)\n+            if value is not None:\n+                return self._maybe_autocast(value)\n+        if self._value is None:\n+            # Unitialized variable. Return a placeholder.\n+            # This is fine because it's only ever used\n+            # in during shape inference / graph tracing\n+            # (anything else would be a bug, to be fixed.)\n+            return self._maybe_autocast(\n+                self._initializer(self._shape, dtype=self._dtype)\n+            )\n+        return self._maybe_autocast(self._value)\n+\n+    def assign(self, value):\n+        value = self._convert_to_tensor(value, dtype=self.dtype)\n+        if value.shape != self.value.shape:\n+            raise ValueError(\n+                \"The shape of the target variable and \"\n+                \"the shape of the target value in \"\n+                \"`variable.assign(value)` must match. \"\n+                f\"Received: value.shape={value.shape}; \"\n+                f\"variable.shape={self.value.shape}\"\n+            )\n+        if in_stateless_scope():\n+            scope = get_stateless_scope()\n+            scope.add_update((self, value))\n+        else:\n+            self._direct_assign(value)\n+\n     @property\n     def dtype(self):\n         autocast_scope = get_autocast_scope()\n@@ -100,16 +139,6 @@ class KerasVariable:\n     def _initialize(self, value):\n         raise NotImplementedError\n \n-    @property\n-    def value(self):\n-        raise NotImplementedError\n-\n-    def numpy(self):\n-        raise NotImplementedError\n-\n-    def assign(self, value):\n-        raise NotImplementedError\n-\n     def _convert_to_tensor(self, value, dtype=None):\n         raise NotImplementedError\n \n@@ -336,50 +365,59 @@ ALLOWED_DTYPES = {\n     \"int64\",\n     \"bfloat16\",\n     \"bool\",\n-}\n-\n-PYTHON_DTYPES_MAP = {\n-    bool: \"bool\",\n-    int: \"int\",  # TBD by backend\n-    float: \"float32\",\n+    \"string\",\n }\n \n \n def standardize_dtype(dtype):\n-    if dtype is None:\n-        return config.floatx()\n-    if dtype in PYTHON_DTYPES_MAP:\n-        dtype = PYTHON_DTYPES_MAP.get(dtype)\n     if dtype == \"int\":\n         if config.backend() == \"tensorflow\":\n             dtype = \"int64\"\n         else:\n             dtype = \"int32\"\n+    if dtype is None:\n+        return config.floatx()\n     if hasattr(dtype, \"name\"):\n         dtype = dtype.name\n-\n     if dtype not in ALLOWED_DTYPES:\n         raise ValueError(f\"Invalid dtype: {dtype}\")\n     return dtype\n \n \n-def standardize_shape(shape, fully_defined=False):\n+def standardize_shape(\n+    shape, allow_dynamic_batch_size=True, allow_all_dynamic=True\n+):\n     if not isinstance(shape, tuple):\n         if shape is None:\n             raise ValueError(\"Undefined shapes are not supported.\")\n         if not hasattr(shape, \"__iter__\"):\n             raise ValueError(f\"Cannot convert '{shape}' to a shape.\")\n         shape = tuple(shape)\n-    for e in shape:\n-        if not fully_defined and e is None:\n+\n+    for i, e in enumerate(shape):\n+        if i == 0 and allow_dynamic_batch_size and e is None:\n+            continue\n+        if allow_all_dynamic and e is None:\n             continue\n         if not isinstance(e, int):\n-            raise ValueError(\n+            msg = (\n                 f\"Cannot convert '{shape}' to a shape. \"\n-                f\"Found invalid entry '{e}'. Only \"\n-                \"fully-defined shapes are allowed with the \"\n-                f\"{config.backend()} backend.\"\n+                f\"Found invalid entry '{e}'. \"\n             )\n+            if allow_dynamic_batch_size:\n+                msg += (\n+                    \"Dynamic shapes (shapes with `None` entries) \"\n+                    f\"are not allowed with the {config.backend()}, \"\n+                    \"except for the batch size (axis 0).\"\n+                )\n+            else:\n+                msg += (\n+                    \"Dynamic shapes (shapes with `None` entries) \"\n+                    f\"are not allowed with the {config.backend()}. \"\n+                    \"All dimensions should be positive integers, \"\n+                    \"including the batch size (axis 0).\"\n+                )\n+            raise ValueError(msg)\n         if e < 0:\n             raise ValueError(\n                 f\"Cannot convert '{shape}' to a shape. \"\n\n@@ -4,6 +4,7 @@ from keras_core.backend.jax import math\n from keras_core.backend.jax import nn\n from keras_core.backend.jax import numpy\n from keras_core.backend.jax import random\n+from keras_core.backend.jax.core import DYNAMIC_BATCH_SIZE_OK\n from keras_core.backend.jax.core import DYNAMIC_SHAPES_OK\n from keras_core.backend.jax.core import Variable\n from keras_core.backend.jax.core import cast\n\n@@ -1,69 +1,30 @@\n import jax\n import jax.numpy as jnp\n-import numpy as np\n from tensorflow import nest\n \n from keras_core.backend.common import KerasVariable\n from keras_core.backend.common import standardize_dtype\n from keras_core.backend.common.keras_tensor import KerasTensor\n from keras_core.backend.common.stateless_scope import StatelessScope\n-from keras_core.backend.common.stateless_scope import get_stateless_scope\n-from keras_core.backend.common.stateless_scope import in_stateless_scope\n \n DYNAMIC_SHAPES_OK = False  # Dynamic shapes NG\n+DYNAMIC_BATCH_SIZE_OK = True\n \n \n class Variable(KerasVariable):\n     def _initialize(self, value):\n         self._value = jnp.array(value, dtype=self._dtype)\n \n-    def assign(self, value):\n-        value = convert_to_tensor(value, dtype=self.dtype)\n-        if value.shape != self.shape:\n-            raise ValueError(\n-                \"The shape of the target variable and \"\n-                \"the shape of the target value in \"\n-                \"`variable.assign(value)` must match. \"\n-                f\"Received: value.shape={value.shape}; \"\n-                f\"variable.shape={self.value.shape}\"\n-            )\n-        if in_stateless_scope():\n-            scope = get_stateless_scope()\n-            scope.add_update((self, value))\n-        else:\n-            if isinstance(value, jnp.ndarray) and value.dtype == self.dtype:\n-                # Avoid a memory copy\n+    def _direct_assign(self, value):\n         self._value = value\n-            else:\n-                self._value = jnp.array(value, dtype=self.dtype)\n \n-    @property\n-    def value(self):\n-        if in_stateless_scope():\n-            scope = get_stateless_scope()\n-            value = scope.get_current_value(self)\n-            if value is not None:\n-                return self._maybe_autocast(value)\n-        if self._value is None:\n-            # Unitialized variable. Return a placeholder.\n-            # This is fine because it's only ever used\n-            # in during shape inference with JAX tracer objects\n-            # (anything else would be a bug, to be fixed.)\n-            return self._maybe_autocast(\n-                self._initializer(self._shape, dtype=self._dtype)\n-            )\n-        return self._maybe_autocast(self._value)\n-\n-    def numpy(self):\n-        return np.array(self.value)\n+    def _convert_to_tensor(self, value, dtype=None):\n+        return convert_to_tensor(value, dtype=dtype)\n \n     # Overload native accessor.\n     def __jax_array__(self):\n         return self.value\n \n-    def _convert_to_tensor(self, value, dtype=None):\n-        return convert_to_tensor(value, dtype=dtype)\n-\n \n def convert_to_tensor(x, dtype=None):\n     if dtype is not None:\n@@ -98,10 +59,22 @@ def name_scope(name):\n # Shape / dtype inference util\n def compute_output_spec(fn, *args, **kwargs):\n     with StatelessScope():\n+        dynamic_batch_map = {}\n+        magic_number = 3\n \n         def convert_keras_tensor_to_jax(x):\n             if isinstance(x, KerasTensor):\n-                return jax.ShapeDtypeStruct(x.shape, dtype=x.dtype)\n+                shape = x.shape\n+                if shape and x.shape[0] is None:\n+                    shape = list(shape)\n+                    shape[0] = magic_number\n+                    dynamic_batch = True\n+                else:\n+                    dynamic_batch = False\n+\n+                jax_tensor = jax.ShapeDtypeStruct(shape, dtype=x.dtype)\n+                dynamic_batch_map[jax_tensor] = dynamic_batch\n+                return jax_tensor\n             return x\n \n         built_in_types = (type(None), int, float, str, bool, complex, bytes)\n@@ -136,6 +109,17 @@ def compute_output_spec(fn, *args, **kwargs):\n \n         def convert_jax_spec_to_keras_tensor(x):\n             if isinstance(x, jax.ShapeDtypeStruct):\n+                if dynamic_batch_map.get(x, False):\n+                    shape = list(x.shape)\n+                    if shape[0] != magic_number:\n+                        raise ValueError(\n+                            f\"Function {fn} appears to change the \"\n+                            \"batch size of its input. This is not \"\n+                            \"allowed when used in conjunction with \"\n+                            \"dynamic batch sizes. Consider using \"\n+                            \"a static batch size here.\"\n+                        )\n+                    shape[0] = None\n                 return KerasTensor(x.shape, x.dtype)\n             return x\n \n\n@@ -5,6 +5,7 @@ from keras_core.backend.tensorflow import nn\n from keras_core.backend.tensorflow import numpy\n from keras_core.backend.tensorflow import random\n from keras_core.backend.tensorflow.core import DYNAMIC_SHAPES_OK\n+from keras_core.backend.tensorflow.core import DYNAMIC_BATCH_SIZE_OK\n from keras_core.backend.tensorflow.core import Variable\n from keras_core.backend.tensorflow.core import cast\n from keras_core.backend.tensorflow.core import compute_output_spec\n\n@@ -4,11 +4,10 @@ from keras_core.backend.common import KerasVariable\n from keras_core.backend.common import standardize_dtype\n from keras_core.backend.common.keras_tensor import KerasTensor\n from keras_core.backend.common.stateless_scope import StatelessScope\n-from keras_core.backend.common.stateless_scope import get_stateless_scope\n-from keras_core.backend.common.stateless_scope import in_stateless_scope\n from keras_core.utils.naming import auto_name\n \n DYNAMIC_SHAPES_OK = True\n+DYNAMIC_BATCH_SIZE_OK = True\n \n \n class Variable(KerasVariable, tf.__internal__.types.Tensor):\n@@ -23,37 +22,11 @@ class Variable(KerasVariable, tf.__internal__.types.Tensor):\n             value, dtype=self._dtype, trainable=self.trainable, name=self.name\n         )\n \n-    def assign(self, value):\n-        value = convert_to_tensor(value, dtype=self.dtype)\n-        if value.shape != self.value.shape:\n-            raise ValueError(\n-                \"The shape of the target variable and \"\n-                \"the shape of the target value in \"\n-                \"`variable.assign(value)` must match. \"\n-                f\"Received: value.shape={value.shape}; \"\n-                f\"variable.shape={self.value.shape}\"\n-            )\n-        if in_stateless_scope():\n-            scope = get_stateless_scope()\n-            scope.add_update((self, value))\n-        else:\n+    def _direct_assign(self, value):\n         self.value.assign(value)\n \n-    @property\n-    def value(self):\n-        if in_stateless_scope():\n-            scope = get_stateless_scope()\n-            value = scope.get_current_value(self)\n-            if value is not None:\n-                return self._maybe_autocast(value)\n-        if self._value is None:\n-            # Unitialized variable. Return a placeholder.\n-            # This is fine because it's only ever used\n-            # during shape inference in a scratch graph\n-            # (anything else would be a bug, to be fixed.)\n-            init_val = self._initializer(self._shape, dtype=self._dtype)\n-            return self._maybe_autocast(init_val)\n-        return self._maybe_autocast(self._value)\n+    def _convert_to_tensor(self, value, dtype=None):\n+        return convert_to_tensor(value, dtype=dtype)\n \n     def numpy(self):  # noqa: F811\n         return self.value.numpy()\n@@ -66,9 +39,6 @@ class Variable(KerasVariable, tf.__internal__.types.Tensor):\n     def __tf_tensor__(self, dtype=None, name=None):\n         return tf.convert_to_tensor(self.value, dtype=dtype, name=name)\n \n-    def _convert_to_tensor(self, value, dtype=None):\n-        return convert_to_tensor(value, dtype=dtype)\n-\n \n def convert_to_tensor(x, dtype=None):\n     if dtype is not None:\n\n@@ -1,12 +1,11 @@\n-import numpy as np\n import torch\n \n from keras_core.backend.common import KerasVariable\n from keras_core.backend.common import standardize_dtype\n-from keras_core.backend.common.stateless_scope import get_stateless_scope\n-from keras_core.backend.common.stateless_scope import in_stateless_scope\n \n DYNAMIC_SHAPES_OK = True\n+DYNAMIC_BATCH_SIZE_OK = True\n+\n \n TORCH_DTYPES = {\n     \"float16\": torch.float16,\n@@ -37,53 +36,16 @@ class Variable(KerasVariable):\n     def _initialize(self, value):\n         self._value = convert_to_tensor(value, dtype=self._dtype)\n \n-    def assign(self, value):\n-        value = convert_to_tensor(value, dtype=self.dtype)\n-        if value.shape != self.shape:\n-            raise ValueError(\n-                \"The shape of the target variable and \"\n-                \"the shape of the target value in \"\n-                \"`variable.assign(value)` must match. \"\n-                f\"Received: value.shape={value.shape}; \"\n-                f\"variable.shape={self.value.shape}\"\n-            )\n-        if in_stateless_scope():\n-            scope = get_stateless_scope()\n-            scope.add_update((self, value))\n-        else:\n-            # torch `as_tensor` by default, doesn't copy if tensor is same type\n-            self._value = convert_to_tensor(value, dtype=self.dtype)\n-\n-    @property\n-    def value(self):\n-        if in_stateless_scope():\n-            scope = get_stateless_scope()\n-            value = scope.get_current_value(self)\n-            if value is not None:\n-                return self._maybe_autocast(value)\n-        if self._value is None:\n-            # Unitialized variable. Return a placeholder.\n-            # This is fine because it's only ever used\n-            # during shape inference in a scratch graph\n-            # (anything else would be a bug, to be fixed.)\n-            return self._maybe_autocast(\n-                convert_to_tensor(\n-                    self._initializer(self._shape, dtype=self._dtype),\n-                    dtype=self._dtype,\n-                )\n-            )\n-        return self._maybe_autocast(self._value)\n-\n-    def numpy(self):\n-        return np.array(self.value)\n-\n-    # Overload native accessor.\n-    def __torch_function__(self, func, types, args=(), kwargs=None):\n-        raise NotImplementedError\n+    def _direct_assign(self, value):\n+        self._value = value\n \n     def _convert_to_tensor(self, value, dtype=None):\n         return convert_to_tensor(value, dtype=dtype)\n \n+    # Overload native accessor.\n+    def __torch_function__(self, func, types, args=(), kwargs=None):\n+        return func(self.value, *args, **kwargs)\n+\n \n def convert_to_tensor(x, dtype=None):\n     # TODO: Need to address device placement arg of `as_tensor`\n\n@@ -1,109 +1,93 @@\n import torch\n \n-from keras_core.backend.torch.core import convert_to_tensor\n from keras_core.backend.torch.core import to_torch_dtype\n \n \n def add(x1, x2):\n-    x1, x2 = convert_to_tensor(x1), convert_to_tensor(x2)\n-    return torch.add(x1, x2)\n+    return x1 + x2\n \n \n def einsum(subscripts, *operands, **kwargs):\n-    operands = [convert_to_tensor(operand) for operand in operands]\n-    return torch.einsum(subscripts, *operands)\n+    pass\n+    # return tfnp.einsum(subscripts, *operands, **kwargs)\n \n \n def subtract(x1, x2):\n-    x1, x2 = convert_to_tensor(x1), convert_to_tensor(x2)\n-    return torch.subtract(x1, x2)\n+    return x1 - x2\n \n \n def matmul(x1, x2):\n-    x1, x2 = convert_to_tensor(x1), convert_to_tensor(x2)\n-    return torch.matmul(x1, x2)\n+    pass\n+    # return tfnp.matmul(x1, x2)\n \n \n def multiply(x1, x2):\n-    x1, x2 = convert_to_tensor(x1), convert_to_tensor(x2)\n-    return torch.multiply(x1, x2)\n+    return x1 * x2\n \n \n def mean(x, axis=None, keepdims=False):\n-    x = convert_to_tensor(x)\n-    return torch.mean(x, axis=axis, keepdims=keepdims)\n+    return torch.mean(x, dim=axis, keepdim=keepdims)\n \n \n def max(x, axis=None, keepdims=False, initial=None):\n-    x = convert_to_tensor(x)\n-    if axis is None:\n-        result = torch.max(x)\n-    else:\n-        if isinstance(axis, list):\n-            axis = axis[-1]\n-        result = torch.max(x, dim=axis, keepdim=keepdims)\n+    # TODO: handle initial\n+    return torch.max(x, dim=axis, keepdim=keepdims)\n+    # The TensorFlow numpy API implementation doesn't support `initial` so we\n+    # handle it manually here.\n+    # if initial is not None:\n+    #    return tf.math.maximum(\n+    #        tfnp.max(x, axis=axis, keepdims=keepdims), initial\n+    #    )\n \n-    if isinstance(getattr(result, \"values\", None), torch.Tensor):\n-        result = result.values\n+    # TensorFlow returns -inf by default for an empty list, but for consistency\n+    # with other backends and the numpy API we want to throw in this case.\n+    # tf.assert_greater(\n+    #    size(x),\n+    #    tf.constant(0, dtype=tf.int64),\n+    #    message=\"Cannot compute the max of an empty tensor.\",\n+    # )\n \n-    if initial is not None:\n-        return torch.maximum(result, initial)\n-    return result\n+    # return tfnp.max(x, axis=axis, keepdims=keepdims)\n \n \n def ones(shape, dtype=\"float32\"):\n     dtype = to_torch_dtype(dtype)\n-    return torch.ones(*shape, dtype=dtype)\n+    torch.ones(*shape, dtype=dtype)\n \n \n def zeros(shape, dtype=\"float32\"):\n     dtype = to_torch_dtype(dtype)\n-    return torch.zeros(*shape, dtype=dtype)\n+    torch.zeros(*shape, dtype=dtype)\n \n \n def absolute(x):\n-    return abs(x)\n+    pass\n+    # return tfnp.absolute(x)\n \n \n def abs(x):\n-    x = convert_to_tensor(x)\n-    return torch.abs(x)\n+    pass\n+    # return absolute(x)\n \n \n def all(x, axis=None, keepdims=False):\n-    x = convert_to_tensor(x)\n-    if axis is not None:\n-        if isinstance(axis, list):\n-            axis = axis[-1]\n-        return torch.all(x, dim=axis, keepdim=keepdims)\n-    else:\n-        return torch.all(x)\n+    pass\n+    # return tfnp.all(x, axis=axis, keepdims=keepdims)\n \n \n def any(x, axis=None, keepdims=False):\n-    x = convert_to_tensor(x)\n-    if axis is not None:\n-        if isinstance(axis, list):\n-            axis = axis[-1]\n-        return torch.any(x, dim=axis, keepdim=keepdims)\n-    else:\n-        return torch.any(x)\n+    pass\n+    # return tfnp.any(x, axis=axis, keepdims=keepdims)\n \n \n def amax(x, axis=None, keepdims=False):\n-    x = convert_to_tensor(x)\n-    if axis is not None:\n-        return torch.amax(x, dim=axis, keepdim=keepdims)\n-    else:\n-        return torch.amax(x)\n+    pass\n+    # return tfnp.amax(x, axis=axis, keepdims=keepdims)\n \n \n def amin(x, axis=None, keepdims=False):\n-    x = convert_to_tensor(x)\n-    if axis is not None:\n-        return torch.amin(x, dim=axis, keepdim=keepdims)\n-    else:\n-        return torch.amin(x)\n+    pass\n+    # return tfnp.amin(x, axis=axis, keepdims=keepdims)\n \n \n def append(\n@@ -111,694 +95,594 @@ def append(\n     x2,\n     axis=None,\n ):\n-    x1, x2 = convert_to_tensor(x1), convert_to_tensor(x2)\n-    if axis is None:\n-        return torch.cat((x1.flatten(), x2.flatten()))\n-    return torch.cat((x1, x2), dim=axis)\n+    pass\n+    # return tfnp.append(x1, x2, axis=axis)\n \n \n def arange(start, stop=None, step=None, dtype=None):\n-    dtype = to_torch_dtype(dtype)\n-    if stop is None:\n-        return torch.arange(start, step=step, dtype=dtype)\n-    step = step or 1\n-    return torch.arange(start, stop, step=step, dtype=dtype)\n+    pass\n+    # return tfnp.arange(start, stop, step=step, dtype=dtype)\n \n \n def arccos(x):\n-    x = convert_to_tensor(x)\n-    return torch.arccos(x)\n+    pass\n+    # return tfnp.arccos(x)\n \n \n def arcsin(x):\n-    x = convert_to_tensor(x)\n-    return torch.arcsin(x)\n+    pass\n+    # return tfnp.arcsin(x)\n \n \n def arctan(x):\n-    x = convert_to_tensor(x)\n-    return torch.arctan(x)\n+    pass\n+    # return tfnp.arctan(x)\n \n \n def arctan2(x1, x2):\n-    x1, x2 = convert_to_tensor(x1), convert_to_tensor(x2)\n-    return torch.arctan2(x1, x2)\n+    pass\n+    # return tfnp.arctan2(x1, x2)\n \n \n def argmax(x, axis=None):\n-    x = convert_to_tensor(x)\n-    return torch.argmax(x, dim=axis)\n+    pass\n+    # return tfnp.argmax(x, axis=axis)\n \n \n def argmin(x, axis=None):\n-    x = convert_to_tensor(x)\n-    return torch.argmin(x, dim=axis)\n+    pass\n+    # return tfnp.argmin(x, axis=axis)\n \n \n def argsort(x, axis=-1):\n-    x = convert_to_tensor(x)\n-    if axis is None:\n-        axis = -1\n-        x = x.reshape(-1)\n-    return torch.argsort(x, dim=axis)\n+    pass\n+    # return tfnp.argsort(x, axis=axis)\n \n \n def array(x, dtype=None):\n-    dtype = to_torch_dtype(dtype)\n-    if not isinstance(x, torch.Tensor):\n-        return x\n-    return x.numpy()\n+    pass\n+    # return tfnp.array(x, dtype=dtype)\n \n \n def average(x, axis=None, weights=None):\n-    x = convert_to_tensor(x)\n-    if weights is not None:\n-        weights = convert_to_tensor(weights)\n-        return torch.sum(torch.mul(x, weights), dim=axis) / torch.sum(\n-            weights, dim=-1\n-        )\n-    return torch.mean(x, axis)\n-\n-\n-def bincount(x, weights=None, minlength=0):\n-    x = convert_to_tensor(x, dtype=int)\n-    weights = convert_to_tensor(weights)\n-    return torch.bincount(x, weights, minlength)\n+    pass\n+    # return tfnp.average(x, weights=weights, axis=axis)\n \n \n def broadcast_to(x, shape):\n-    x = convert_to_tensor(x)\n-    return torch.broadcast_to(x, shape)\n+    pass\n+    # return tfnp.broadcast_to(x, shape)\n \n \n def ceil(x):\n-    x = convert_to_tensor(x)\n-    return torch.ceil(x)\n+    pass\n+    # return tfnp.ceil(x)\n \n \n def clip(x, x_min, x_max):\n-    x = convert_to_tensor(x)\n-    x_min, x_max = convert_to_tensor(x_min), convert_to_tensor(x_max)\n-    return torch.clip(x, min=x_min, max=x_max)\n+    pass\n+    # return tfnp.clip(x, x_min, x_max)\n \n \n def concatenate(xs, axis=0):\n-    xs = [convert_to_tensor(x) for x in xs]\n-    return torch.cat(xs, dim=axis)\n+    pass\n+    # return tfnp.concatenate(xs, axis=axis)\n \n \n def conjugate(x):\n-    if not isinstance(x, torch.Tensor):\n-        x = torch.from_numpy(x)  # needed for complex type conversion\n-    return torch.conj(x).resolve_conj()\n+    pass\n+    # return tfnp.conjugate(x)\n \n \n def conj(x):\n-    if not isinstance(x, torch.Tensor):\n-        x = torch.from_numpy(x)  # needed for complex type conversion\n-    return torch.conj(x).resolve_conj()\n+    pass\n+    # return conjugate(x)\n \n \n def copy(x):\n-    x = convert_to_tensor(x)\n-    return torch.clone(x)\n+    pass\n+    # return tfnp.copy(x)\n \n \n def cos(x):\n-    x = convert_to_tensor(x)\n-    return torch.cos(x)\n+    pass\n+    # return tfnp.cos(x)\n \n \n def count_nonzero(x, axis=None):\n-    x = convert_to_tensor(x)\n-    return torch.count_nonzero(x, dim=axis).T\n+    pass\n+    # return tfnp.count_nonzero(x, axis=axis)\n \n \n def cross(x1, x2, axisa=-1, axisb=-1, axisc=-1, axis=None):\n-    # TODO: There is API divergence between np.cross and torch.cross,\n-    # preventing `axisa`, `axisb`, and `axisc` parameters from\n-    # being used.\n-    # https://github.com/pytorch/pytorch/issues/50273\n-    if axisa != -1 or axisb != -1 or axisc != -1:\n-        raise NotImplementedError(\n-            \"Due to API divergence between `torch.cross()` and \"\n-            \"`np.cross`, the following arguments are not supported: \"\n-            f\"axisa={axisa}, axisb={axisb}, axisc={axisc}\"\n-        )\n-    x1, x2 = convert_to_tensor(x1), convert_to_tensor(x2)\n-    return torch.cross(x1, x2, dim=axis)\n+    pass\n+    # return tfnp.cross(\n+    #    x1,\n+    #    x2,\n+    #    axisa=axisa,\n+    #    axisb=axisb,\n+    #    axisc=axisc,\n+    #    axis=axis,\n+    # )\n \n \n def cumprod(x, axis=None):\n-    x = convert_to_tensor(x)\n-    if axis is None:\n-        x = x.flatten()\n-        axis = 0\n-    return torch.cumprod(x, dim=axis)\n+    pass\n+    # return tfnp.cumprod(x, axis=axis)\n \n \n def cumsum(x, axis=None):\n-    x = convert_to_tensor(x)\n-    if axis is None:\n-        x = x.flatten()\n-        axis = 0\n-    return torch.cumsum(x, dim=axis)\n+    pass\n+    # return tfnp.cumsum(x, axis=axis)\n \n \n def diag(x, k=0):\n-    x = convert_to_tensor(x)\n-    return torch.diag(x, diagonal=k)\n+    pass\n+    # return tfnp.diag(x, k=k)\n \n \n def diagonal(x, offset=0, axis1=0, axis2=1):\n-    x = convert_to_tensor(x)\n-    return torch.diagonal(\n-        x,\n-        offset=offset,\n-        dim1=axis1,\n-        dim2=axis2,\n-    )\n+    pass\n+    # return tfnp.diagonal(\n+    #    x,\n+    #    offset=offset,\n+    #    axis1=axis1,\n+    #    axis2=axis2,\n+    # )\n \n \n def dot(x, y):\n-    x, y = convert_to_tensor(x), convert_to_tensor(y)\n-    if len(x.shape) == 0 or len(y.shape) == 0:\n-        return torch.multiply(x, y)\n-    return torch.matmul(x, y)\n+    pass\n+    # return tfnp.dot(x, y)\n \n \n def empty(shape, dtype=\"float32\"):\n-    dtype = to_torch_dtype(dtype)\n-    return torch.empty(size=shape, dtype=dtype)\n+    pass\n+    # return tfnp.empty(shape, dtype=dtype)\n \n \n def equal(x1, x2):\n-    x1, x2 = convert_to_tensor(x1), convert_to_tensor(x2)\n-    return torch.equal(x1, x2)\n+    pass\n+    # return tfnp.equal(x1, x2)\n \n \n def exp(x):\n-    x = convert_to_tensor(x)\n-    return torch.exp(x)\n+    pass\n+    # return tfnp.exp(x)\n \n \n def expand_dims(x, axis):\n-    x = convert_to_tensor(x)\n-    return torch.unsqueeze(x, dim=axis)\n+    pass\n+    # return tfnp.expand_dims(x, axis)\n \n \n def expm1(x):\n-    x = convert_to_tensor(x)\n-    return torch.expm1(x)\n+    pass\n+    # return tfnp.expm1(x)\n \n \n def flip(x, axis=None):\n-    x = convert_to_tensor(x)\n-    if axis is None:\n-        axis = tuple(range(len(x.shape)))\n-    if isinstance(axis, int):\n-        axis = (axis,)\n-    return torch.flip(x, dims=axis)\n+    pass\n+    # return tfnp.flip(x, axis=axis)\n \n \n def floor(x):\n-    x = convert_to_tensor(x)\n-    return torch.floor(x)\n+    pass\n+    # return tfnp.floor(x)\n \n \n def full(shape, fill_value, dtype=None):\n-    dtype = to_torch_dtype(dtype)\n-    if hasattr(fill_value, \"__len__\"):\n-        raise NotImplementedError(\n-            \"`torch.full()` only accepts scalars for `fill_value`. \"\n-            f\"Received: fill_value={fill_value}\"\n-        )\n-        # TODO: implement conversion of shape into repetitions for `torch.tile``\n-        # return torch.tile(fill_value, reps)\n-    return torch.full(size=shape, fill_value=fill_value, dtype=dtype)\n+    pass\n+    # return tfnp.full(shape, fill_value, dtype=dtype)\n \n \n def full_like(x, fill_value, dtype=None):\n-    dtype = to_torch_dtype(dtype)\n-    if hasattr(fill_value, \"__len__\"):\n-        raise NotImplementedError(\n-            \"`torch.full()` only accepts scalars for `fill_value`.\"\n-        )\n-        # TODO: implement conversion of shape into repetitions for `torch.tile``\n-        # return torch.tile(fill_value, reps)\n-    x = convert_to_tensor(x)\n-    return torch.full_like(input=x, fill_value=fill_value, dtype=dtype)\n+    pass\n+    # return tfnp.full_like(x, fill_value, dtype=dtype)\n \n \n def greater(x1, x2):\n-    x1, x2 = convert_to_tensor(x1), convert_to_tensor(x2)\n-    return torch.greater(x1, x2)\n+    pass\n+    # return tfnp.greater(x1, x2)\n \n \n def greater_equal(x1, x2):\n-    x1, x2 = convert_to_tensor(x1), convert_to_tensor(x2)\n-    return torch.greater_equal(x1, x2)\n+    pass\n+    # return tfnp.greater_equal(x1, x2)\n \n \n def hstack(xs):\n-    xs = [convert_to_tensor(x) for x in xs]\n-    return torch.hstack(xs)\n+    pass\n+    # return tfnp.hstack(xs)\n \n \n def identity(n, dtype=\"float32\"):\n-    dtype = to_torch_dtype(dtype)\n-    return torch.eye(n, dtype=dtype)\n+    pass\n+    # return tfnp.identity(n, dtype=dtype)\n \n \n def imag(x):\n-    if not isinstance(x, torch.Tensor):\n-        x = torch.from_numpy(x)  # needed for complex type conversion\n-    return torch.imag(x)\n+    pass\n+    # return tfnp.imag(x)\n \n \n def isclose(x1, x2):\n-    x1, x2 = convert_to_tensor(x1), convert_to_tensor(x2)\n-    return torch.isclose(x1, x2)\n+    pass\n+    # return tfnp.isclose(x1, x2)\n \n \n def isfinite(x):\n-    x = convert_to_tensor(x)\n-    return torch.isfinite(x)\n+    pass\n+    # return tfnp.isfinite(x)\n \n \n def isinf(x):\n-    x = convert_to_tensor(x)\n-    return torch.isinf(x)\n+    pass\n+    # return tfnp.isinf(x)\n \n \n def isnan(x):\n-    x = convert_to_tensor(x)\n-    return torch.isnan(x)\n+    pass\n+    # return tfnp.isnan(x)\n \n \n def less(x1, x2):\n-    x1, x2 = convert_to_tensor(x1), convert_to_tensor(x2)\n-    return torch.less(x1, x2)\n+    pass\n+    # return tfnp.less(x1, x2)\n \n \n def less_equal(x1, x2):\n-    x1, x2 = convert_to_tensor(x1), convert_to_tensor(x2)\n-    return torch.less_equal(x1, x2)\n+    pass\n+    # return tfnp.less_equal(x1, x2)\n \n \n def linspace(\n     start, stop, num=50, endpoint=True, retstep=False, dtype=None, axis=0\n ):\n-    if axis != 0:\n-        raise ValueError(\n-            \"torch.linspace does not support an `axis` argument. \"\n-            f\"Received axis={axis}\"\n-        )\n-        dtype = to_torch_dtype(dtype)\n-    if endpoint is False:\n-        stop = stop - ((stop - start) / num)\n-    linspace = torch.linspace(\n-        start=start,\n-        end=stop,\n-        steps=num,\n-        dtype=dtype,\n-    )\n-    if retstep is True:\n-        return (linspace, num)\n-    return linspace\n+    pass\n+    # return tfnp.linspace(\n+    #    start,\n+    #    stop,\n+    #    num=num,\n+    #    endpoint=endpoint,\n+    #    retstep=retstep,\n+    #    dtype=dtype,\n+    #    axis=axis,\n+    # )\n \n \n def log(x):\n-    x = convert_to_tensor(x)\n-    return torch.log(x)\n+    pass\n+    # return tfnp.log(x)\n \n \n def log10(x):\n-    x = convert_to_tensor(x)\n-    return torch.log10(x)\n+    pass\n+    # return tfnp.log10(x)\n \n \n def log1p(x):\n-    x = convert_to_tensor(x)\n-    return torch.log1p(x)\n+    pass\n+    # return tfnp.log1p(x)\n \n \n def log2(x):\n-    x = convert_to_tensor(x)\n-    return torch.log2(x)\n+    pass\n+    # return tfnp.log2(x)\n \n \n def logaddexp(x1, x2):\n-    x1, x2 = convert_to_tensor(x1), convert_to_tensor(x2)\n-    return torch.logaddexp(x1, x2)\n+    pass\n+    # return tfnp.logaddexp(x1, x2)\n \n \n def logical_and(x1, x2):\n-    x1, x2 = convert_to_tensor(x1), convert_to_tensor(x2)\n-    return torch.logical_and(x1, x2)\n+    pass\n+    # return tfnp.logical_and(x1, x2)\n \n \n def logical_not(x):\n-    x = convert_to_tensor(x)\n-    return torch.logical_not(x)\n+    pass\n+    # return tfnp.logical_not(x)\n \n \n def logical_or(x1, x2):\n-    x1, x2 = convert_to_tensor(x1), convert_to_tensor(x2)\n-    return torch.logical_or(x1, x2)\n+    pass\n+    # return tfnp.logical_or(x1, x2)\n \n \n def logspace(start, stop, num=50, endpoint=True, base=10, dtype=None, axis=0):\n-    if axis != 0:\n-        raise ValueError(\n-            \"torch.logspace does not support an `axis` argument. \"\n-            f\"Received axis={axis}\"\n-        )\n-    dtype = to_torch_dtype(dtype)\n-    if endpoint is False:\n-        stop = stop - ((stop - start) / num)\n-    logspace = torch.logspace(\n-        start=start,\n-        end=stop,\n-        steps=num,\n-        base=base,\n-        dtype=dtype,\n-    )\n-    return logspace\n+    pass\n+    # return tfnp.logspace(\n+    #    start,\n+    #    stop,\n+    #    num=num,\n+    #    endpoint=endpoint,\n+    #    base=base,\n+    #    dtype=dtype,\n+    #    axis=axis,\n+    # )\n \n \n def maximum(x1, x2):\n-    x1, x2 = convert_to_tensor(x1), convert_to_tensor(x2)\n-    return torch.maximum(x1, x2)\n+    pass\n+    # return tfnp.maximum(x1, x2)\n \n \n def meshgrid(*x, indexing=\"xy\"):\n-    x = [convert_to_tensor(sc_tensor) for sc_tensor in x]\n-    result = torch.meshgrid(x, indexing=indexing)\n-    return [arr.numpy() for arr in result]\n+    pass\n+    # return tfnp.meshgrid(*x, indexing=indexing)\n \n \n def min(x, axis=None, keepdims=False, initial=None):\n-    x = convert_to_tensor(x)\n-    if axis is None:\n-        result = torch.min(x)\n-    else:\n-        if isinstance(axis, list):\n-            axis = axis[-1]\n-        result = torch.min(x, dim=axis, keepdim=keepdims)\n+    pass\n+    ## The TensorFlow numpy API implementation doesn't support `initial` so we\n+    ## handle it manually here.\n+    # if initial is not None:\n+    #    return tf.math.minimum(\n+    #        tfnp.min(x, axis=axis, keepdims=keepdims), initial\n+    #    )\n \n-    if isinstance(getattr(result, \"values\", None), torch.Tensor):\n-        result = result.values\n+    ## TensorFlow returns inf by default for an empty list, but for consistency\n+    ## with other backends and the numpy API we want to throw in this case.\n+    # tf.assert_greater(\n+    #    size(x),\n+    #    tf.constant(0, dtype=tf.int64),\n+    #    message=\"Cannot compute the min of an empty tensor.\",\n+    # )\n \n-    if initial is not None:\n-        return torch.minimum(result, initial)\n-    return result\n+    # return tfnp.min(x, axis=axis, keepdims=keepdims)\n \n \n def minimum(x1, x2):\n-    x1, x2 = convert_to_tensor(x1), convert_to_tensor(x2)\n-    return torch.minimum(x1, x2)\n+    pass\n+    # return tfnp.minimum(x1, x2)\n \n \n def mod(x1, x2):\n-    x1, x2 = convert_to_tensor(x1), convert_to_tensor(x2)\n-    return torch.remainder(x1, x2)\n+    pass\n+    # return tfnp.mod(x1, x2)\n \n \n def moveaxis(x, source, destination):\n-    x = convert_to_tensor(x)\n-    return torch.moveaxis(x, source=source, destination=destination)\n+    pass\n+    # return tfnp.moveaxis(x, source=source, destination=destination)\n \n \n def nan_to_num(x):\n-    x = convert_to_tensor(x)\n-    return torch.nan_to_num(x)\n+    pass\n+    ## Replace NaN with 0\n+    # x = tf.where(tf.math.is_nan(x), 0, x)\n+\n+    ## Replace positive infinitiy with dtype.max\n+    # x = tf.where(tf.math.is_inf(x) & (x > 0), x.dtype.max, x)\n+\n+    ## Replace negative infinity with dtype.min\n+    # x = tf.where(tf.math.is_inf(x) & (x < 0), x.dtype.min, x)\n+\n+    # return x\n \n \n def ndim(x):\n-    x = convert_to_tensor(x)\n-    return x.ndim\n+    pass\n+    # return tfnp.ndim(x)\n \n \n def nonzero(x):\n-    x = convert_to_tensor(x)\n-    return torch.nonzero(x).T\n+    pass\n+    # return tfnp.nonzero(x)\n \n \n def not_equal(x1, x2):\n-    x1, x2 = convert_to_tensor(x1), convert_to_tensor(x2)\n-    return torch.not_equal(x1, x2)\n+    pass\n+    # return tfnp.not_equal(x1, x2)\n \n \n def ones_like(x, dtype=None):\n-    x = convert_to_tensor(x)\n-    dtype = to_torch_dtype(dtype)\n-    return torch.ones_like(x, dtype=dtype)\n+    pass\n+    # return tfnp.ones_like(x, dtype=dtype)\n \n \n def outer(x1, x2):\n-    x1, x2 = convert_to_tensor(x1), convert_to_tensor(x2)\n-    return torch.outer(x1.flatten(), x2.flatten())\n+    pass\n+    # return tfnp.outer(x1, x2)\n \n \n def pad(x, pad_width, mode=\"constant\"):\n-    x = convert_to_tensor(x)\n-    pad_sum = ()\n-    for pad in pad_width:\n-        pad_sum += pad\n-    return torch.nn.functional.pad(x, pad=pad_sum, mode=mode)\n+    pass\n+    # return tfnp.pad(x, pad_width, mode=mode)\n \n \n def prod(x, axis=None, keepdims=False, dtype=None):\n-    x = convert_to_tensor(x)\n-    dtype = to_torch_dtype(dtype)\n-    if axis is None:\n-        return torch.prod(x, dtype=dtype)\n-    elif isinstance(axis, list):\n-        axis = axis[-1]\n-    return torch.prod(x, dim=axis, keepdim=keepdims, dtype=dtype)\n+    pass\n+    # return tfnp.prod(x, axis=axis, keepdims=keepdims, dtype=dtype)\n \n \n def ravel(x):\n-    x = convert_to_tensor(x)\n-    return torch.ravel(x)\n+    pass\n+    # return tfnp.ravel(x)\n \n \n def real(x):\n-    x = convert_to_tensor(x)\n-    return torch.real(x)\n+    pass\n+    # return tfnp.real(x)\n \n \n def reciprocal(x):\n-    x = convert_to_tensor(x)\n-    return torch.reciprocal(x)\n+    pass\n+    # return tfnp.reciprocal(x)\n \n \n def repeat(x, repeats, axis=None):\n-    x = convert_to_tensor(x)\n-    repeats = convert_to_tensor(repeats, dtype=int)\n-    return torch.repeat_interleave(x, repeats, dim=axis)\n+    pass\n+    # return tfnp.repeat(x, repeats, axis=axis)\n \n \n def reshape(x, new_shape):\n-    x = convert_to_tensor(x)\n-    return torch.reshape(x, new_shape)\n+    pass\n+    # return tfnp.reshape(x, new_shape)\n \n \n def roll(x, shift, axis=None):\n-    x = convert_to_tensor(x)\n-    return torch.roll(x, shift, dims=axis)\n+    pass\n+    # return tfnp.roll(x, shift, axis=axis)\n \n \n def sign(x):\n-    x = convert_to_tensor(x)\n-    return torch.sign(x)\n+    pass\n+    # return tfnp.sign(x)\n \n \n def sin(x):\n-    x = convert_to_tensor(x)\n-    return torch.sin(x)\n+    pass\n+    # return tfnp.sin(x)\n \n \n def size(x):\n-    x_shape = convert_to_tensor(tuple(x.shape))\n-    return torch.prod(x_shape)\n+    pass\n+    # return tfnp.size(x)\n \n \n def sort(x, axis=-1):\n-    x = convert_to_tensor(x)\n-    return torch.sort(x, dim=axis).values\n+    pass\n+    # return tfnp.sort(x, axis=axis)\n \n \n def split(x, indices_or_sections, axis=0):\n-    x = convert_to_tensor(x)\n-    return torch.split(\n-        tensor=x,\n-        split_size_or_sections=indices_or_sections,\n-        dim=axis,\n-    )\n+    pass\n+    # return tfnp.split(x, indices_or_sections, axis=axis)\n \n \n def stack(x, axis=0):\n-    x = [convert_to_tensor(elem) for elem in x]\n-    return torch.stack(x, dim=axis)\n+    pass\n+    # return tfnp.stack(x, axis=axis)\n \n \n def std(x, axis=None, keepdims=False):\n-    x = convert_to_tensor(x)\n-    # Remove Bessel correction to align with numpy\n-    return torch.std(x, dim=axis, keepdim=keepdims, unbiased=False)\n+    pass\n+    # return tfnp.std(x, axis=axis, keepdims=keepdims)\n \n \n def swapaxes(x, axis1, axis2):\n-    x = convert_to_tensor(x)\n-    return torch.swapaxes(x, axis0=axis1, axis1=axis2)\n+    pass\n+    # return tfnp.swapaxes(x, axis1=axis1, axis2=axis2)\n \n \n def take(x, indices, axis=None):\n-    x = convert_to_tensor(x)\n-    indices = convert_to_tensor(indices).long()\n-    if axis is not None:\n-        return torch.index_select(x, dim=axis, index=indices)\n-    return torch.take(x, index=indices)\n+    pass\n+    # return tfnp.take(x, indices, axis=axis)\n \n \n def take_along_axis(x, indices, axis=None):\n-    x = convert_to_tensor(x)\n-    indices = convert_to_tensor(indices).long()\n-    return torch.take_along_dim(x, indices, dim=axis)\n+    pass\n+    # return tfnp.take_along_axis(x, indices, axis=axis)\n \n \n def tan(x):\n-    x = convert_to_tensor(x)\n-    return torch.tan(x)\n+    pass\n+    # return tfnp.tan(x)\n \n \n def tensordot(x1, x2, axes=2):\n-    x1, x2 = convert_to_tensor(x1), convert_to_tensor(x2)\n-    return torch.tensordot(x1, x2, dims=axes)\n+    pass\n+    # return tfnp.tensordot(x1, x2, axes=axes)\n \n \n def round(x, decimals=0):\n-    x = convert_to_tensor(x)\n-    return torch.round(x, decimals=decimals)\n+    pass\n+    # return tfnp.round(x, decimals=decimals)\n \n \n def tile(x, repeats):\n-    x = convert_to_tensor(x)\n-    return torch.tile(x, dims=repeats)\n+    pass\n+    # return tfnp.tile(x, repeats)\n \n \n-def trace(x, offset=None, axis1=None, axis2=None):\n-    x = convert_to_tensor(x)\n-    # TODO: implement support for these arguments\n-    # API divergence between `np.trace()` and `torch.trace()`\n-    if offset or axis1 or axis2:\n-        raise NotImplementedError(\n-            \"Arguments not supported by `torch.trace: \"\n-            f\"offset={offset}, axis1={axis1}, axis2={axis2}\"\n-        )\n-    return torch.trace(x)\n+def trace(x, offset=0, axis1=0, axis2=1):\n+    pass\n+    # return tfnp.trace(x, offset=offset, axis1=axis1, axis2=axis2)\n \n \n def tri(N, M=None, k=0, dtype=\"float32\"):\n-    dtype = to_torch_dtype(dtype)\n     pass\n+    # return tfnp.tri(N, M=M, k=k, dtype=dtype)\n \n \n def tril(x, k=0):\n-    x = convert_to_tensor(x)\n-    return torch.tril(x, diagonal=k)\n+    pass\n+    # return tfnp.tril(x, k=k)\n \n \n def triu(x, k=0):\n-    x = convert_to_tensor(x)\n-    return torch.triu(x, diagonal=k)\n+    pass\n+    # return tfnp.triu(x, k=k)\n \n \n def vdot(x1, x2):\n-    x1, x2 = convert_to_tensor(x1), convert_to_tensor(x2)\n-    return torch.vdot(x1, x2)\n+    pass\n+    # return tfnp.vdot(x1, x2)\n \n \n def vstack(xs):\n-    xs = [convert_to_tensor(x) for x in xs]\n-    return torch.vstack(xs)\n+    pass\n+    # return tfnp.vstack(xs)\n \n \n def where(condition, x1, x2):\n-    condition = convert_to_tensor(condition, dtype=bool)\n-    x1, x2 = convert_to_tensor(x1), convert_to_tensor(x2)\n-    return torch.where(condition, x1, x2)\n+    pass\n+    # return tfnp.where(condition, x1, x2)\n \n \n def divide(x1, x2):\n-    x1, x2 = convert_to_tensor(x1), convert_to_tensor(x2)\n-    return torch.divide(x1, x2)\n+    pass\n+    # return tfnp.divide(x1, x2)\n \n \n def true_divide(x1, x2):\n-    x1, x2 = convert_to_tensor(x1), convert_to_tensor(x2)\n-    return torch.true_divide(x1, x2)\n+    pass\n+    # return tfnp.true_divide(x1, x2)\n \n \n def power(x1, x2):\n-    x1, x2 = convert_to_tensor(x1), convert_to_tensor(x2)\n-    return torch.pow(x1, x2)\n+    pass\n+    # return tfnp.power(x1, x2)\n \n \n def negative(x):\n-    x = convert_to_tensor(x)\n-    return torch.negative(x)\n+    pass\n+    # return tfnp.negative(x)\n \n \n def square(x):\n-    x = convert_to_tensor(x)\n-    return torch.square(x)\n+    pass\n+    # return tfnp.square(x)\n \n \n def sqrt(x):\n-    x = convert_to_tensor(x)\n-    return torch.sqrt(x)\n+    pass\n+    # return tfnp.sqrt(x)\n \n \n def squeeze(x, axis=None):\n-    x = convert_to_tensor(x)\n-    if axis is not None:\n-        return torch.squeeze(x, dim=axis)\n-    return torch.squeeze(x)\n+    pass\n+    # return tfnp.squeeze(x, axis=axis)\n \n \n def transpose(x, axes=None):\n-    x = convert_to_tensor(x)\n-    if axes is not None:\n-        return torch.permute(x, dims=axes)\n-    return x.T\n+    pass\n+    # return tfnp.transpose(x, axes=axes)\n \n \n def var(x, axis=None, keepdims=False):\n-    x = convert_to_tensor(x)\n-    # Bessel correction removed for numpy compatibility\n-    return torch.var(x, dim=axis, keepdim=keepdims, correction=0)\n+    pass\n+    # return tfnp.var(x, axis=axis, keepdims=keepdims)\n \n \n def sum(x, axis=None, keepdims=False):\n-    x = convert_to_tensor(x)\n-    if axis is not None:\n-        return torch.sum(x, axis=axis, keepdim=keepdims)\n-    return torch.sum(x)\n+    pass\n+    # return tfnp.sum(x, axis=axis, keepdims=keepdims)\n \n \n-def eye(N, M=None, k=None, dtype=\"float32\"):\n-    # TODO: implement support for `k` diagonal arg,\n-    # does not exist in torch.eye()\n-    if k is not None:\n-        raise NotImplementedError(\n-            \"Due to API divergence bewtween `torch.eye` \"\n-            \"and `np.eye`, the argument k is not supported: \"\n-            f\"Received: k={k}\"\n-        )\n-    dtype = to_torch_dtype(dtype)\n-    if M is not None:\n-        return torch.eye(n=N, m=M, dtype=dtype)\n-    return torch.eye(n=N, dtype=dtype)\n+def eye(N, M=None, k=0, dtype=\"float32\"):\n+    pass\n+    # return tfnp.eye(N, M=M, k=k, dtype=dtype)\n\n@@ -49,14 +49,19 @@ class UpSamplingTest(testing.TestCase):\n         )\n \n     @pytest.mark.skipif(\n-        not backend.DYNAMIC_SHAPES_OK,\n-        reason=\"Backend does not support dynamic shapes\",\n+        not backend.DYNAMIC_BATCH_SIZE_OK,\n+        reason=\"Backend does not support dynamic batch sizes\",\n     )\n-    def test_upsampling_1d_with_dynamic_shape(self):\n+    def test_upsampling_1d_with_dynamic_batch_size(self):\n         x = KerasTensor([None, 2, 3])\n         self.assertEqual(layers.UpSampling1D(size=2)(x).shape, (None, 4, 3))\n         self.assertEqual(layers.UpSampling1D(size=4)(x).shape, (None, 8, 3))\n \n+    @pytest.mark.skipif(\n+        not backend.DYNAMIC_SHAPES_OK,\n+        reason=\"Backend does not support dynamic shapes\",\n+    )\n+    def test_upsampling_1d_with_dynamic_shape(self):\n         y = KerasTensor([2, None, 3])\n         self.assertEqual(layers.UpSampling1D(size=2)(y).shape, (2, None, 3))\n         self.assertEqual(layers.UpSampling1D(size=4)(y).shape, (2, None, 3))\n\n@@ -13,7 +13,8 @@ class UpSampling3D(Layer):\n     Repeats the 1st, 2nd and 3rd dimensions\n     of the data by `size[0]`, `size[1]` and `size[2]` respectively.\n \n-    Examples:\n+    Example:\n+\n     >>> input_shape = (2, 1, 2, 1, 3)\n     >>> x = np.ones(input_shape)\n     >>> y = keras_core.layers.UpSampling3D(size=(2, 2, 2))(x)\n@@ -108,6 +109,7 @@ class UpSampling3D(Layer):\n         self, x, depth_factor, height_factor, width_factor, data_format\n     ):\n         \"\"\"Resizes the volume contained in a 5D tensor.\n+\n         Args:\n             x: Tensor or variable to resize.\n             depth_factor: Positive integer.\n@@ -116,11 +118,7 @@ class UpSampling3D(Layer):\n             data_format: One of `\"channels_first\"`, `\"channels_last\"`.\n \n         Returns:\n-            A tensor.\n-\n-        Raises:\n-            ValueError: if `data_format` is neither\n-                `channels_last` or `channels_first`.\n+            Resized tensor.\n         \"\"\"\n         if data_format == \"channels_first\":\n             output = ops.repeat(x, depth_factor, axis=2)\n@@ -133,4 +131,4 @@ class UpSampling3D(Layer):\n             output = ops.repeat(output, width_factor, axis=3)\n             return output\n         else:\n-            raise ValueError(\"Invalid data_format: \" + str(data_format))\n+            raise ValueError(f\"Invalid data_format: {data_format}\")\n\n@@ -65,8 +65,8 @@ class ZeroPaddingTest(testing.TestCase, parameterized.TestCase):\n             self.assertAllClose(outputs[:, 2:-2, 2:-2, 2:-2, :], inputs)\n \n     @pytest.mark.skipif(\n-        not backend.DYNAMIC_SHAPES_OK,\n-        reason=\"Backend does not support dynamic shapes\",\n+        not backend.DYNAMIC_BATCH_SIZE_OK,\n+        reason=\"Backend does not support dynamic batch sizes\",\n     )\n     def test_zero_padding_3d_with_dynamic_batch_size(self):\n         input_layer = layers.Input(batch_shape=(None, 2, 3, 4, 5))\n\n@@ -42,10 +42,11 @@ class FunctionTest(testing.TestCase):\n         self.assertAllClose(y_val[0], np.ones((2, 3)) * 6)\n         self.assertAllClose(y_val[1], np.ones((2, 3)) * 4)\n \n+    @pytest.mark.skipif(\n+        not backend.DYNAMIC_BATCH_SIZE_OK,\n+        reason=\"Test only valid if dynamic batch sizes are supported\",\n+    )\n     def test_dynamic_shape_inference(self):\n-        if not backend.DYNAMIC_SHAPES_OK:\n-            pytest.skip(\"Test only valid for dynamic shape backends\")\n-\n         x = keras_tensor.KerasTensor((None, 3))\n         y = x**2\n         fn = function.Function(x, y)\n\n@@ -1665,17 +1665,11 @@ class NumpyTwoInputOpsCorretnessTest(testing.TestCase):\n         y3 = np.ones([1, 5, 4, 2])\n         self.assertAllClose(np.array(knp.cross(x1, y1)), np.cross(x1, y1))\n         self.assertAllClose(np.array(knp.cross(x1, y2)), np.cross(x1, y2))\n-        if backend.backend() != \"torch\":\n-            # API divergence between `torch.cross` and `np.cross`\n-            # `torch.cross` only allows dim 3, `np.cross` allows dim 2 or 3\n         self.assertAllClose(np.array(knp.cross(x1, y3)), np.cross(x1, y3))\n         self.assertAllClose(np.array(knp.cross(x2, y3)), np.cross(x2, y3))\n \n         self.assertAllClose(np.array(knp.Cross()(x1, y1)), np.cross(x1, y1))\n         self.assertAllClose(np.array(knp.Cross()(x1, y2)), np.cross(x1, y2))\n-        if backend.backend() != \"torch\":\n-            # API divergence between `torch.cross` and `np.cross`\n-            # `torch.cross` only allows dim 3, `np.cross` allows dim 2 or 3\n         self.assertAllClose(np.array(knp.Cross()(x1, y3)), np.cross(x1, y3))\n         self.assertAllClose(np.array(knp.Cross()(x2, y3)), np.cross(x2, y3))\n \n@@ -1717,35 +1711,24 @@ class NumpyTwoInputOpsCorretnessTest(testing.TestCase):\n     def test_full_like(self):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n         self.assertAllClose(np.array(knp.full_like(x, 2)), np.full_like(x, 2))\n+        self.assertAllClose(\n+            np.array(knp.full_like(x, np.ones([2, 3]))),\n+            np.full_like(x, np.ones([2, 3])),\n+        )\n         self.assertAllClose(\n             np.array(knp.full_like(x, 2, dtype=\"float32\")),\n             np.full_like(x, 2, dtype=\"float32\"),\n         )\n \n         self.assertAllClose(np.array(knp.FullLike()(x, 2)), np.full_like(x, 2))\n-        self.assertAllClose(\n-            np.array(knp.FullLike()(x, 2, dtype=\"float32\")),\n-            np.full_like(x, 2, dtype=\"float32\"),\n-        )\n-\n-    # TODO: implement conversion of shape into repetitions, pass to\n-    # `torch.tile`, since `torch.full()` only accepts scalars\n-    # for `fill_value`.\"\n-    @pytest.mark.skipif(\n-        backend.backend() == \"torch\",\n-        reason=\"`torch.full` only accepts scalars for `fill_value`.\",\n-    )\n-    def test_full_like_without_torch(self):\n-        x = np.array([[1, 2, 3], [3, 2, 1]])\n-        self.assertAllClose(\n-            np.array(knp.full_like(x, np.ones([2, 3]))),\n-            np.full_like(x, np.ones([2, 3])),\n-        )\n-\n         self.assertAllClose(\n             np.array(knp.FullLike()(x, np.ones([2, 3]))),\n             np.full_like(x, np.ones([2, 3])),\n         )\n+        self.assertAllClose(\n+            np.array(knp.FullLike()(x, 2, dtype=\"float32\")),\n+            np.full_like(x, 2, dtype=\"float32\"),\n+        )\n \n     def test_greater(self):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n@@ -1842,14 +1825,6 @@ class NumpyTwoInputOpsCorretnessTest(testing.TestCase):\n             np.linspace(0, 10, 5, endpoint=False),\n         )\n \n-    # TODO: torch.linspace does not support tensor or array\n-    # for start/stop, create manual implementation\n-    @pytest.mark.skipif(\n-        backend.backend() == \"torch\",\n-        reason=\"`torch.linspace` has no support for array start/stop.\",\n-    )\n-    def test_linspace_without_torch(self):\n-\n         start = np.zeros([2, 3, 4])\n         stop = np.ones([2, 3, 4])\n         self.assertAllClose(\n@@ -1954,13 +1929,6 @@ class NumpyTwoInputOpsCorretnessTest(testing.TestCase):\n             np.logspace(0, 10, 5, endpoint=False),\n         )\n \n-    # TODO: torch.logspace does not support tensor or array\n-    # for start/stop, create manual implementation\n-    @pytest.mark.skipif(\n-        backend.backend() == \"torch\",\n-        reason=\"`torch.logspace` has no support for array start/stop.\",\n-    )\n-    def test_logspace_without_torch(self):\n         start = np.zeros([2, 3, 4])\n         stop = np.ones([2, 3, 4])\n         self.assertAllClose(\n@@ -2036,11 +2004,6 @@ class NumpyTwoInputOpsCorretnessTest(testing.TestCase):\n         self.assertAllClose(np.array(knp.outer(x, y)), np.outer(x, y))\n         self.assertAllClose(np.array(knp.Outer()(x, y)), np.outer(x, y))\n \n-    # TODO: Fix numpy compatibility (squeeze by one dimension only)\n-    @pytest.mark.skipif(\n-        backend.backend() == \"torch\",\n-        reason=\"`torch.take` and `np.take` have return shape divergence.\",\n-    )\n     def test_take(self):\n         x = np.arange(24).reshape([1, 2, 3, 4])\n         indices = np.array([0, 1])\n@@ -2804,23 +2767,6 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase):\n             np.array(knp.pad(x, ((1, 1), (1, 1)))),\n             np.pad(x, ((1, 1), (1, 1))),\n         )\n-\n-        self.assertAllClose(\n-            np.array(knp.Pad(((1, 1), (1, 1)))(x)), np.pad(x, ((1, 1), (1, 1)))\n-        )\n-        self.assertAllClose(\n-            np.array(knp.Pad(((1, 1), (1, 1)))(x)),\n-            np.pad(x, ((1, 1), (1, 1))),\n-        )\n-\n-    # TODO: implement padding with non-constant padding,\n-    # bypass NotImplementedError for PyTorch\n-    @pytest.mark.skipif(\n-        backend.backend() == \"torch\",\n-        reason=\"padding not implemented for non-constant use case\",\n-    )\n-    def test_pad_without_torch(self):\n-        x = np.array([[1, 2], [3, 4]])\n         self.assertAllClose(\n             np.array(knp.pad(x, ((1, 1), (1, 1)), mode=\"reflect\")),\n             np.pad(x, ((1, 1), (1, 1)), mode=\"reflect\"),\n@@ -2830,6 +2776,13 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase):\n             np.pad(x, ((1, 1), (1, 1)), mode=\"symmetric\"),\n         )\n \n+        self.assertAllClose(\n+            np.array(knp.Pad(((1, 1), (1, 1)))(x)), np.pad(x, ((1, 1), (1, 1)))\n+        )\n+        self.assertAllClose(\n+            np.array(knp.Pad(((1, 1), (1, 1)))(x)),\n+            np.pad(x, ((1, 1), (1, 1))),\n+        )\n         self.assertAllClose(\n             np.array(knp.Pad(((1, 1), (1, 1)), mode=\"reflect\")(x)),\n             np.pad(x, ((1, 1), (1, 1)), mode=\"reflect\"),\n@@ -2952,12 +2905,6 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase):\n         self.assertAllClose(np.array(knp.sort(x, axis=0)), np.sort(x, axis=0))\n         self.assertAllClose(np.array(knp.Sort(axis=0)(x)), np.sort(x, axis=0))\n \n-    # TODO: implement split for `torch` with support for conversion\n-    # of numpy.split args.\n-    @pytest.mark.skipif(\n-        backend.backend() == \"torch\",\n-        reason=\"`torch.split` and `np.split` have return arg divergence.\",\n-    )\n     def test_split(self):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n         self.assertAllClose(np.array(knp.split(x, 2)), np.split(x, 2))\n@@ -3025,13 +2972,7 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase):\n         self.assertAllClose(np.array(knp.tile(x, [2, 3])), np.tile(x, [2, 3]))\n         self.assertAllClose(np.array(knp.Tile([2, 3])(x)), np.tile(x, [2, 3]))\n \n-    @pytest.mark.skipif(\n-        backend.backend() == \"torch\",\n-        reason=\"`torch.split` does not support args `offset`, `axis1`, `axis2`\",\n-    )\n     def test_trace(self):\n-        # TODO: implement `torch.trace` support for arguments `offset`,\n-        # `axis1`, `axis2` and delete NotImplementedError\n         x = np.arange(24).reshape([1, 2, 3, 4])\n         self.assertAllClose(np.array(knp.trace(x)), np.trace(x))\n         self.assertAllClose(\n@@ -3071,14 +3012,7 @@ class NumpyArrayCreateOpsCorrectnessTest(testing.TestCase):\n         self.assertAllClose(np.array(knp.zeros([2, 3])), np.zeros([2, 3]))\n         self.assertAllClose(np.array(knp.Zeros()([2, 3])), np.zeros([2, 3]))\n \n-    @pytest.mark.skipif(\n-        backend.backend() == \"torch\",\n-        reason=\"`torch.eye` does not support arg `k`.\",\n-    )\n     def test_eye(self):\n-        # TODO: implement support for `k` diagonal arg,\n-        # does not exist in torch.eye()\n-\n         self.assertAllClose(np.array(knp.eye(3)), np.eye(3))\n         self.assertAllClose(np.array(knp.eye(3, 4)), np.eye(3, 4))\n         self.assertAllClose(np.array(knp.eye(3, 4, 1)), np.eye(3, 4, 1))\n@@ -3101,25 +3035,15 @@ class NumpyArrayCreateOpsCorrectnessTest(testing.TestCase):\n         self.assertAllClose(\n             np.array(knp.full([2, 3], 0.1)), np.full([2, 3], 0.1)\n         )\n-\n-        self.assertAllClose(np.array(knp.Full()([2, 3], 0)), np.full([2, 3], 0))\n-        self.assertAllClose(\n-            np.array(knp.Full()([2, 3], 0.1)), np.full([2, 3], 0.1)\n-        )\n-\n-    # TODO: implement conversion of shape into repetitions, pass to\n-    # `torch.tile`, since `torch.full()` only accepts scalars\n-    # for `fill_value`.\"\n-    @pytest.mark.skipif(\n-        backend.backend() == \"torch\",\n-        reason=\"`torch.full` only accepts scalars for `fill_value`.\",\n-    )\n-    def test_full_without_torch(self):\n         self.assertAllClose(\n             np.array(knp.full([2, 3], np.array([1, 4, 5]))),\n             np.full([2, 3], np.array([1, 4, 5])),\n         )\n \n+        self.assertAllClose(np.array(knp.Full()([2, 3], 0)), np.full([2, 3], 0))\n+        self.assertAllClose(\n+            np.array(knp.Full()([2, 3], 0.1)), np.full([2, 3], 0.1)\n+        )\n         self.assertAllClose(\n             np.array(knp.Full()([2, 3], np.array([1, 4, 5]))),\n             np.full([2, 3], np.array([1, 4, 5])),\n@@ -3129,11 +3053,7 @@ class NumpyArrayCreateOpsCorrectnessTest(testing.TestCase):\n         self.assertAllClose(np.array(knp.identity(3)), np.identity(3))\n         self.assertAllClose(np.array(knp.Identity()(3)), np.identity(3))\n \n-    @pytest.mark.skipif(\n-        backend.backend() == \"torch\", reason=\"No torch equivalent for `np.tri`\"\n-    )\n     def test_tri(self):\n-        # TODO: create a manual implementation, as PyTorch has no equivalent\n         self.assertAllClose(np.array(knp.tri(3)), np.tri(3))\n         self.assertAllClose(np.array(knp.tri(3, 4)), np.tri(3, 4))\n         self.assertAllClose(np.array(knp.tri(3, 4, 1)), np.tri(3, 4, 1))\n\n@@ -0,0 +1,757 @@\n+from tensorflow import data as tf_data\n+\n+from keras_core import layers\n+from keras_core import operations as ops\n+from keras_core.api_export import keras_core_export\n+from keras_core.layers.layer import Layer\n+from keras_core.saving import saving_lib\n+from keras_core.saving import serialization_lib\n+from keras_core.utils.naming import auto_name\n+\n+\n+class Cross:\n+    def __init__(self, feature_names, crossing_dim, output_mode=\"one_hot\"):\n+        if output_mode not in {\"int\", \"one_hot\"}:\n+            raise ValueError(\n+                \"Invalid value for argument `output_mode`. \"\n+                \"Expected one of {'int', 'one_hot'}. \"\n+                f\"Received: output_mode={output_mode}\"\n+            )\n+        self.feature_names = tuple(feature_names)\n+        self.crossing_dim = crossing_dim\n+        self.output_mode = output_mode\n+\n+    @property\n+    def name(self):\n+        return \"_X_\".join(self.feature_names)\n+\n+    def get_config(self):\n+        return {\n+            \"feature_names\": self.feature_names,\n+            \"crossing_dim\": self.crossing_dim,\n+            \"output_mode\": self.output_mode,\n+        }\n+\n+    @classmethod\n+    def from_config(cls, config):\n+        return cls(**config)\n+\n+\n+class Feature:\n+    def __init__(self, dtype, preprocessor, output_mode):\n+        if output_mode not in {\"int\", \"one_hot\", \"float\"}:\n+            raise ValueError(\n+                \"Invalid value for argument `output_mode`. \"\n+                \"Expected one of {'int', 'one_hot', 'float'}. \"\n+                f\"Received: output_mode={output_mode}\"\n+            )\n+        self.dtype = dtype\n+        if isinstance(preprocessor, dict):\n+            preprocessor = serialization_lib.deserialize_keras_object(\n+                preprocessor\n+            )\n+        self.preprocessor = preprocessor\n+        self.output_mode = output_mode\n+\n+    def get_config(self):\n+        return {\n+            \"dtype\": self.dtype,\n+            \"preprocessor\": serialization_lib.serialize_keras_object(\n+                self.preprocessor\n+            ),\n+            \"output_mode\": self.output_mode,\n+        }\n+\n+    @classmethod\n+    def from_config(cls, config):\n+        return cls(**config)\n+\n+\n+@keras_core_export(\"keras_core.utils.FeatureSpace\")\n+class FeatureSpace(Layer):\n+    \"\"\"One-stop utility for preprocessing and encoding structured data.\n+\n+    Arguments:\n+        feature_names: Dict mapping the names of your features to their\n+            type specification, e.g. `{\"my_feature\": \"integer_categorical\"}`\n+            or `{\"my_feature\": FeatureSpace.integer_categorical()}`.\n+            For a complete list of all supported types, see\n+            \"Available feature types\" paragraph below.\n+        output_mode: One of `\"concat\"` or `\"dict\"`. In concat mode, all\n+            features get concatenated together into a single vector.\n+            In dict mode, the FeatureSpace returns a dict of individually\n+            encoded features (with the same keys as the input dict keys).\n+        crosses: List of features to be crossed together, e.g.\n+            `crosses=[(\"feature_1\", \"feature_2\")]`. The features will be\n+            \"crossed\" by hashing their combined value into\n+            a fixed-length vector.\n+        crossing_dim: Default vector size for hashing crossed features.\n+            Defaults to `32`.\n+        hashing_dim: Default vector size for hashing features of type\n+            `\"integer_hashed\"` and `\"string_hashed\"`. Defaults to `32`.\n+        num_discretization_bins: Default number of bins to be used for\n+            discretizing features of type `\"float_discretized\"`.\n+            Defaults to `32`.\n+\n+    **Available feature types:**\n+\n+    Note that all features can be referred to by their string name,\n+    e.g. `\"integer_categorical\"`. When using the string name, the default\n+    argument values are used.\n+\n+    ```python\n+    # Plain float values.\n+    FeatureSpace.float(name=None)\n+\n+    # Float values to be preprocessed via featurewise standardization\n+    # (i.e. via a `keras.layers.Normalization` layer).\n+    FeatureSpace.float_normalized(name=None)\n+\n+    # Float values to be preprocessed via linear rescaling\n+    # (i.e. via a `keras.layers.Rescaling` layer).\n+    FeatureSpace.float_rescaled(scale=1., offset=0., name=None)\n+\n+    # Float values to be discretized. By default, the discrete\n+    # representation will then be one-hot encoded.\n+    FeatureSpace.float_discretized(\n+        num_bins, bin_boundaries=None, output_mode=\"one_hot\", name=None)\n+\n+    # Integer values to be indexed. By default, the discrete\n+    # representation will then be one-hot encoded.\n+    FeatureSpace.integer_categorical(\n+        max_tokens=None, num_oov_indices=1, output_mode=\"one_hot\", name=None)\n+\n+    # String values to be indexed. By default, the discrete\n+    # representation will then be one-hot encoded.\n+    FeatureSpace.string_categorical(\n+        max_tokens=None, num_oov_indices=1, output_mode=\"one_hot\", name=None)\n+\n+    # Integer values to be hashed into a fixed number of bins.\n+    # By default, the discrete representation will then be one-hot encoded.\n+    FeatureSpace.integer_hashed(num_bins, output_mode=\"one_hot\", name=None)\n+\n+    # String values to be hashed into a fixed number of bins.\n+    # By default, the discrete representation will then be one-hot encoded.\n+    FeatureSpace.string_hashed(num_bins, output_mode=\"one_hot\", name=None)\n+    ```\n+\n+    Examples:\n+\n+    **Basic usage with a dict of input data:**\n+\n+    ```python\n+    raw_data = {\n+        \"float_values\": [0.0, 0.1, 0.2, 0.3],\n+        \"string_values\": [\"zero\", \"one\", \"two\", \"three\"],\n+        \"int_values\": [0, 1, 2, 3],\n+    }\n+    dataset = tf.data.Dataset.from_tensor_slices(raw_data)\n+\n+    feature_space = FeatureSpace(\n+        features={\n+            \"float_values\": \"float_normalized\",\n+            \"string_values\": \"string_categorical\",\n+            \"int_values\": \"integer_categorical\",\n+        },\n+        crosses=[(\"string_values\", \"int_values\")],\n+        output_mode=\"concat\",\n+    )\n+    # Before you start using the FeatureSpace,\n+    # you must `adapt()` it on some data.\n+    feature_space.adapt(dataset)\n+\n+    # You can call the FeatureSpace on a dict of data (batched or unbatched).\n+    output_vector = feature_space(raw_data)\n+    ```\n+\n+    **Basic usage with `tf.data`:**\n+\n+    ```python\n+    # Unlabeled data\n+    preprocessed_ds = unlabeled_dataset.map(feature_space)\n+\n+    # Labeled data\n+    preprocessed_ds = labeled_dataset.map(lambda x, y: (feature_space(x), y))\n+    ```\n+\n+    **Basic usage with the Keras Functional API:**\n+\n+    ```python\n+    # Retrieve a dict Keras Input objects\n+    inputs = feature_space.get_inputs()\n+    # Retrieve the corresponding encoded Keras tensors\n+    encoded_features = feature_space.get_encoded_features()\n+    # Build a Functional model\n+    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(encoded_features)\n+    model = keras.Model(inputs, outputs)\n+    ```\n+\n+    **Customizing each feature or feature cross:**\n+\n+    ```python\n+    feature_space = FeatureSpace(\n+        features={\n+            \"float_values\": FeatureSpace.float_normalized(),\n+            \"string_values\": FeatureSpace.string_categorical(max_tokens=10),\n+            \"int_values\": FeatureSpace.integer_categorical(max_tokens=10),\n+        },\n+        crosses=[\n+            FeatureSpace.cross((\"string_values\", \"int_values\"), crossing_dim=32)\n+        ],\n+        output_mode=\"concat\",\n+    )\n+    ```\n+\n+    **Returning a dict of integer-encoded features:**\n+\n+    ```python\n+    feature_space = FeatureSpace(\n+        features={\n+            \"string_values\": FeatureSpace.string_categorical(output_mode=\"int\"),\n+            \"int_values\": FeatureSpace.integer_categorical(output_mode=\"int\"),\n+        },\n+        crosses=[\n+            FeatureSpace.cross(\n+                feature_names=(\"string_values\", \"int_values\"),\n+                crossing_dim=32,\n+                output_mode=\"int\",\n+            )\n+        ],\n+        output_mode=\"dict\",\n+    )\n+    ```\n+\n+    **Specifying your own Keras preprocessing layer:**\n+\n+    ```python\n+    # Let's say that one of the features is a short text paragraph that\n+    # we want to encode as a vector (one vector per paragraph) via TF-IDF.\n+    data = {\n+        \"text\": [\"1st string\", \"2nd string\", \"3rd string\"],\n+    }\n+\n+    # There's a Keras layer for this: TextVectorization.\n+    custom_layer = layers.TextVectorization(output_mode=\"tf_idf\")\n+\n+    # We can use FeatureSpace.feature to create a custom feature\n+    # that will use our preprocessing layer.\n+    feature_space = FeatureSpace(\n+        features={\n+            \"text\": FeatureSpace.feature(\n+                preprocessor=custom_layer, dtype=\"string\", output_mode=\"float\"\n+            ),\n+        },\n+        output_mode=\"concat\",\n+    )\n+    feature_space.adapt(tf.data.Dataset.from_tensor_slices(data))\n+    output_vector = feature_space(data)\n+    ```\n+\n+    **Retrieving the underlying Keras preprocessing layers:**\n+\n+    ```python\n+    # The preprocessing layer of each feature is available in `.preprocessors`.\n+    preprocessing_layer = feature_space.preprocessors[\"feature1\"]\n+\n+    # The crossing layer of each feature cross is available in `.crossers`.\n+    # It's an instance of keras.layers.HashedCrossing.\n+    crossing_layer = feature_space.crossers[\"feature1_X_feature2\"]\n+    ```\n+\n+    **Saving and reloading a FeatureSpace:**\n+\n+    ```python\n+    feature_space.save(\"myfeaturespace.keras\")\n+    reloaded_feature_space = keras.models.load_model(\"myfeaturespace.keras\")\n+    ```\n+    \"\"\"\n+\n+    @classmethod\n+    def cross(cls, feature_names, crossing_dim, output_mode=\"one_hot\"):\n+        return Cross(feature_names, crossing_dim, output_mode=output_mode)\n+\n+    @classmethod\n+    def feature(cls, dtype, preprocessor, output_mode):\n+        return Feature(dtype, preprocessor, output_mode)\n+\n+    @classmethod\n+    def float(cls, name=None):\n+        from keras.layers.core import identity\n+\n+        name = name or auto_name(\"float\")\n+        preprocessor = identity.Identity(\n+            dtype=\"float32\", name=f\"{name}_preprocessor\"\n+        )\n+        return Feature(\n+            dtype=\"float32\", preprocessor=preprocessor, output_mode=\"float\"\n+        )\n+\n+    @classmethod\n+    def float_rescaled(cls, scale=1.0, offset=0.0, name=None):\n+        name = name or auto_name(\"float_rescaled\")\n+        preprocessor = layers.Rescaling(\n+            scale=scale, offset=offset, name=f\"{name}_preprocessor\"\n+        )\n+        return Feature(\n+            dtype=\"float32\", preprocessor=preprocessor, output_mode=\"float\"\n+        )\n+\n+    @classmethod\n+    def float_normalized(cls, name=None):\n+        name = name or auto_name(\"float_normalized\")\n+        preprocessor = layers.Normalization(\n+            axis=-1, name=f\"{name}_preprocessor\"\n+        )\n+        return Feature(\n+            dtype=\"float32\", preprocessor=preprocessor, output_mode=\"float\"\n+        )\n+\n+    @classmethod\n+    def float_discretized(\n+        cls, num_bins, bin_boundaries=None, output_mode=\"one_hot\", name=None\n+    ):\n+        name = name or auto_name(\"float_discretized\")\n+        preprocessor = layers.Discretization(\n+            num_bins=num_bins,\n+            bin_boundaries=bin_boundaries,\n+            name=f\"{name}_preprocessor\",\n+        )\n+        return Feature(\n+            dtype=\"float32\", preprocessor=preprocessor, output_mode=output_mode\n+        )\n+\n+    @classmethod\n+    def integer_categorical(\n+        cls,\n+        max_tokens=None,\n+        num_oov_indices=1,\n+        output_mode=\"one_hot\",\n+        name=None,\n+    ):\n+        name = name or auto_name(\"integer_categorical\")\n+        preprocessor = layers.IntegerLookup(\n+            name=f\"{name}_preprocessor\",\n+            max_tokens=max_tokens,\n+            num_oov_indices=num_oov_indices,\n+        )\n+        return Feature(\n+            dtype=\"int64\", preprocessor=preprocessor, output_mode=output_mode\n+        )\n+\n+    @classmethod\n+    def string_categorical(\n+        cls,\n+        max_tokens=None,\n+        num_oov_indices=1,\n+        output_mode=\"one_hot\",\n+        name=None,\n+    ):\n+        name = name or auto_name(\"string_categorical\")\n+        preprocessor = layers.StringLookup(\n+            name=f\"{name}_preprocessor\",\n+            max_tokens=max_tokens,\n+            num_oov_indices=num_oov_indices,\n+        )\n+        return Feature(\n+            dtype=\"string\", preprocessor=preprocessor, output_mode=output_mode\n+        )\n+\n+    @classmethod\n+    def string_hashed(cls, num_bins, output_mode=\"one_hot\", name=None):\n+        name = name or auto_name(\"string_hashed\")\n+        preprocessor = layers.Hashing(\n+            name=f\"{name}_preprocessor\", num_bins=num_bins\n+        )\n+        return Feature(\n+            dtype=\"string\", preprocessor=preprocessor, output_mode=output_mode\n+        )\n+\n+    @classmethod\n+    def integer_hashed(cls, num_bins, output_mode=\"one_hot\", name=None):\n+        name = name or auto_name(\"integer_hashed\")\n+        preprocessor = layers.Hashing(\n+            name=f\"{name}_preprocessor\", num_bins=num_bins\n+        )\n+        return Feature(\n+            dtype=\"int64\", preprocessor=preprocessor, output_mode=output_mode\n+        )\n+\n+    def __init__(\n+        self,\n+        features,\n+        output_mode=\"concat\",\n+        crosses=None,\n+        crossing_dim=32,\n+        hashing_dim=32,\n+        num_discretization_bins=32,\n+        name=None,\n+    ):\n+        super().__init__(name=name)\n+        if not features:\n+            raise ValueError(\"The `features` argument cannot be None or empty.\")\n+        self.crossing_dim = crossing_dim\n+        self.hashing_dim = hashing_dim\n+        self.num_discretization_bins = num_discretization_bins\n+        self.features = {\n+            name: self._standardize_feature(name, value)\n+            for name, value in features.items()\n+        }\n+        self.crosses = []\n+        if crosses:\n+            feature_set = set(features.keys())\n+            for cross in crosses:\n+                if isinstance(cross, dict):\n+                    cross = serialization_lib.deserialize_keras_object(cross)\n+                if isinstance(cross, Cross):\n+                    self.crosses.append(cross)\n+                else:\n+                    if not crossing_dim:\n+                        raise ValueError(\n+                            \"When specifying `crosses`, the argument \"\n+                            \"`crossing_dim` \"\n+                            \"(dimensionality of the crossing space) \"\n+                            \"should be specified as well.\"\n+                        )\n+                    for key in cross:\n+                        if key not in feature_set:\n+                            raise ValueError(\n+                                \"All features referenced \"\n+                                \"in the `crosses` argument \"\n+                                \"should be present in the `features` dict. \"\n+                                f\"Received unknown features: {cross}\"\n+                            )\n+                    self.crosses.append(Cross(cross, crossing_dim=crossing_dim))\n+        self.crosses_by_name = {cross.name: cross for cross in self.crosses}\n+\n+        if output_mode not in {\"dict\", \"concat\"}:\n+            raise ValueError(\n+                \"Invalid value for argument `output_mode`. \"\n+                \"Expected one of {'dict', 'concat'}. \"\n+                f\"Received: output_mode={output_mode}\"\n+            )\n+        self.output_mode = output_mode\n+\n+        self.inputs = {\n+            name: self._feature_to_input(name, value)\n+            for name, value in self.features.items()\n+        }\n+        self.preprocessors = {\n+            name: value.preprocessor for name, value in self.features.items()\n+        }\n+        self.encoded_features = None\n+        self.crossers = {\n+            cross.name: self._cross_to_crosser(cross) for cross in self.crosses\n+        }\n+        self.one_hot_encoders = {}\n+        self.built = False\n+        self._is_adapted = False\n+        self.concat = None\n+        self._preprocessed_features_names = None\n+        self._crossed_features_names = None\n+\n+    def _feature_to_input(self, name, feature):\n+        return layers.Input(shape=(1,), dtype=feature.dtype, name=name)\n+\n+    def _standardize_feature(self, name, feature):\n+        if isinstance(feature, Feature):\n+            return feature\n+\n+        if isinstance(feature, dict):\n+            return serialization_lib.deserialize_keras_object(feature)\n+\n+        if feature == \"float\":\n+            return self.float(name=name)\n+        elif feature == \"float_normalized\":\n+            return self.float_normalized(name=name)\n+        elif feature == \"float_rescaled\":\n+            return self.float_rescaled(name=name)\n+        elif feature == \"float_discretized\":\n+            return self.float_discretized(\n+                name=name, num_bins=self.num_discretization_bins\n+            )\n+        elif feature == \"integer_categorical\":\n+            return self.integer_categorical(name=name)\n+        elif feature == \"string_categorical\":\n+            return self.string_categorical(name=name)\n+        elif feature == \"integer_hashed\":\n+            return self.integer_hashed(self.hashing_dim, name=name)\n+        elif feature == \"string_hashed\":\n+            return self.string_hashed(self.hashing_dim, name=name)\n+        else:\n+            raise ValueError(f\"Invalid feature type: {feature}\")\n+\n+    def _cross_to_crosser(self, cross):\n+        return layers.HashedCrossing(cross.crossing_dim, name=cross.name)\n+\n+    def _list_adaptable_preprocessors(self):\n+        adaptable_preprocessors = []\n+        for name in self.features.keys():\n+            preprocessor = self.preprocessors[name]\n+            # Special case: a Normalization layer with preset mean/variance.\n+            # Not adaptable.\n+            if isinstance(preprocessor, layers.Normalization):\n+                if preprocessor.input_mean is not None:\n+                    continue\n+            if hasattr(preprocessor, \"adapt\"):\n+                adaptable_preprocessors.append(name)\n+        return adaptable_preprocessors\n+\n+    def adapt(self, dataset):\n+        if not isinstance(dataset, tf_data.Dataset):\n+            raise ValueError(\n+                \"`adapt()` can only be called on a tf.data.Dataset. \"\n+                f\"Received instead: {dataset} (of type {type(dataset)})\"\n+            )\n+\n+        for name in self._list_adaptable_preprocessors():\n+            # Call adapt() on each individual adaptable layer.\n+\n+            # TODO: consider rewriting this to instead iterate on the\n+            # dataset once, split each batch into individual features,\n+            # and call the layer's `_adapt_function` on each batch\n+            # to simulate the behavior of adapt() in a more performant fashion.\n+\n+            feature_dataset = dataset.map(lambda x: x[name])\n+            preprocessor = self.preprocessors[name]\n+            # TODO: consider adding an adapt progress bar.\n+            # Sample 1 element to check the rank\n+            for x in feature_dataset.take(1):\n+                pass\n+            if x.shape.rank == 0:\n+                # The dataset yields unbatched scalars; batch it.\n+                feature_dataset = feature_dataset.batch(32)\n+            if x.shape.rank in {0, 1}:\n+                # If the rank is 1, add a dimension\n+                # so we can reduce on axis=-1.\n+                # Note: if rank was previously 0, it is now 1.\n+                feature_dataset = feature_dataset.map(\n+                    lambda x: ops.expand_dims(x, -1)\n+                )\n+            preprocessor.adapt(feature_dataset)\n+        self._is_adapted = True\n+        self.get_encoded_features()  # Finish building the layer\n+        self.built = True\n+\n+    def get_inputs(self):\n+        self._check_if_built()\n+        return self.inputs\n+\n+    def get_encoded_features(self):\n+        self._check_if_adapted()\n+\n+        if self.encoded_features is None:\n+            preprocessed_features = self._preprocess_features(self.inputs)\n+            crossed_features = self._cross_features(preprocessed_features)\n+            merged_features = self._merge_features(\n+                preprocessed_features, crossed_features\n+            )\n+            self.encoded_features = merged_features\n+        return self.encoded_features\n+\n+    def _preprocess_features(self, features):\n+        return {\n+            name: self.preprocessors[name](features[name])\n+            for name in features.keys()\n+        }\n+\n+    def _cross_features(self, features):\n+        all_outputs = {}\n+        for cross in self.crosses:\n+            inputs = [features[name] for name in cross.feature_names]\n+            outputs = self.crossers[cross.name](inputs)\n+            all_outputs[cross.name] = outputs\n+        return all_outputs\n+\n+    def _merge_features(self, preprocessed_features, crossed_features):\n+        if not self._preprocessed_features_names:\n+            self._preprocessed_features_names = sorted(\n+                preprocessed_features.keys()\n+            )\n+            self._crossed_features_names = sorted(crossed_features.keys())\n+\n+        all_names = (\n+            self._preprocessed_features_names + self._crossed_features_names\n+        )\n+        all_features = [\n+            preprocessed_features[name]\n+            for name in self._preprocessed_features_names\n+        ] + [crossed_features[name] for name in self._crossed_features_names]\n+\n+        if self.output_mode == \"dict\":\n+            output_dict = {}\n+        else:\n+            features_to_concat = []\n+\n+        if self.built:\n+            # Fast mode.\n+            for name, feature in zip(all_names, all_features):\n+                encoder = self.one_hot_encoders.get(name, None)\n+                if encoder:\n+                    feature = encoder(feature)\n+                if self.output_mode == \"dict\":\n+                    output_dict[name] = feature\n+                else:\n+                    features_to_concat.append(feature)\n+            if self.output_mode == \"dict\":\n+                return output_dict\n+            else:\n+                return self.concat(features_to_concat)\n+\n+        # If the object isn't built,\n+        # we create the encoder and concat layers below\n+        all_specs = [\n+            self.features[name] for name in self._preprocessed_features_names\n+        ] + [\n+            self.crosses_by_name[name] for name in self._crossed_features_names\n+        ]\n+        for name, feature, spec in zip(all_names, all_features, all_specs):\n+            dtype = feature.dtype\n+\n+            if spec.output_mode == \"one_hot\":\n+                preprocessor = self.preprocessors.get(\n+                    name\n+                ) or self.crossers.get(name)\n+                cardinality = None\n+                if not feature.dtype.startswith(\"int\"):\n+                    raise ValueError(\n+                        f\"Feature '{name}' has `output_mode='one_hot'`. \"\n+                        \"Thus its preprocessor should return an int64 dtype. \"\n+                        f\"Instead it returns a {dtype} dtype.\"\n+                    )\n+\n+                if isinstance(\n+                    preprocessor, (layers.IntegerLookup, layers.StringLookup)\n+                ):\n+                    cardinality = preprocessor.vocabulary_size()\n+                elif isinstance(preprocessor, layers.CategoryEncoding):\n+                    cardinality = preprocessor.num_tokens\n+                elif isinstance(preprocessor, layers.Discretization):\n+                    cardinality = preprocessor.num_bins\n+                elif isinstance(\n+                    preprocessor, (layers.HashedCrossing, layers.Hashing)\n+                ):\n+                    cardinality = preprocessor.num_bins\n+                else:\n+                    raise ValueError(\n+                        f\"Feature '{name}' has `output_mode='one_hot'`. \"\n+                        \"However it isn't a standard feature and the \"\n+                        \"dimensionality of its output space is not known, \"\n+                        \"thus it cannot be one-hot encoded. \"\n+                        \"Try using `output_mode='int'`.\"\n+                    )\n+                if cardinality is not None:\n+                    encoder = layers.CategoryEncoding(\n+                        num_tokens=cardinality, output_mode=\"multi_hot\"\n+                    )\n+                    self.one_hot_encoders[name] = encoder\n+                    feature = encoder(feature)\n+\n+            if self.output_mode == \"concat\":\n+                dtype = feature.dtype\n+                if dtype.startswith(\"int\") or dtype == \"string\":\n+                    raise ValueError(\n+                        f\"Cannot concatenate features because feature '{name}' \"\n+                        f\"has not been encoded (it has dtype {dtype}). \"\n+                        \"Consider using `output_mode='dict'`.\"\n+                    )\n+                features_to_concat.append(feature)\n+            else:\n+                output_dict[name] = feature\n+\n+        if self.output_mode == \"concat\":\n+            self.concat = layers.Concatenate(axis=-1)\n+            return self.concat(features_to_concat)\n+        else:\n+            return output_dict\n+\n+    def _check_if_adapted(self):\n+        if not self._is_adapted:\n+            if not self._list_adaptable_preprocessors():\n+                self._is_adapted = True\n+            else:\n+                raise ValueError(\n+                    \"You need to call `.adapt(dataset)` on the FeatureSpace \"\n+                    \"before you can start using it.\"\n+                )\n+\n+    def _check_if_built(self):\n+        if not self.built:\n+            self._check_if_adapted()\n+            # Finishes building\n+            self.get_encoded_features()\n+            self.built = True\n+\n+    def __call__(self, data):\n+        self._check_if_built()\n+        if not isinstance(data, dict):\n+            raise ValueError(\n+                \"A FeatureSpace can only be called with a dict. \"\n+                f\"Received: data={data} (of type {type(data)}\"\n+            )\n+\n+        data = {\n+            key: ops.convert_to_tensor(value) for key, value in data.items()\n+        }\n+        rebatched = False\n+        for name, x in data.items():\n+            if x.shape.rank == 0:\n+                data[name] = ops.reshape(x, (1, 1))\n+                rebatched = True\n+            elif x.shape.rank == 1:\n+                data[name] = ops.expand_dims(x, -1)\n+\n+        preprocessed_data = self._preprocess_features(data)\n+        crossed_data = self._cross_features(preprocessed_data)\n+        merged_data = self._merge_features(preprocessed_data, crossed_data)\n+        if rebatched:\n+            if self.output_mode == \"concat\":\n+                assert merged_data.shape[0] == 1\n+                return ops.squeeze(merged_data, axis=0)\n+            else:\n+                for name, x in merged_data.items():\n+                    if x.shape.rank == 2 and x.shape[0] == 1:\n+                        merged_data[name] = ops.squeeze(x, axis=0)\n+        return merged_data\n+\n+    def get_config(self):\n+        return {\n+            \"features\": serialization_lib.serialize_keras_object(self.features),\n+            \"output_mode\": self.output_mode,\n+            \"crosses\": serialization_lib.serialize_keras_object(self.crosses),\n+            \"crossing_dim\": self.crossing_dim,\n+            \"hashing_dim\": self.hashing_dim,\n+            \"num_discretization_bins\": self.num_discretization_bins,\n+        }\n+\n+    @classmethod\n+    def from_config(cls, config):\n+        return cls(**config)\n+\n+    def get_build_config(self):\n+        return {\n+            name: feature.preprocessor.get_build_config()\n+            for name, feature in self.features.items()\n+        }\n+\n+    def build_from_config(self, config):\n+        for name in config.keys():\n+            self.features[name].preprocessor.build_from_config(config[name])\n+        self._is_adapted = True\n+\n+    def save(self, filepath):\n+        \"\"\"Save the `FeatureSpace` instance to a `.keras` file.\n+\n+        You can reload it via `keras.models.load_model()`:\n+\n+        ```python\n+        feature_space.save(\"myfeaturespace.keras\")\n+        reloaded_feature_space = keras.models.load_model(\"myfeaturespace.keras\")\n+        ```\n+        \"\"\"\n+        saving_lib.save_model(self, filepath)\n+\n+    def save_own_variables(self, store):\n+        return\n+\n+    def load_own_variables(self, store):\n+        return\n\n@@ -0,0 +1,378 @@\n+# from keras_core import testing\n+# from keras_core.utils import feature_space\n+# from keras_core import operations as ops\n+# from tensorflow import nest\n+# from tensorflow import data as tf_data\n+# from keras_core import layers\n+# from keras_core import models\n+# import os\n+\n+\n+# class FeatureSpaceTest(testing.TestCase):\n+#     def _get_train_data_dict(\n+#         self, as_dataset=False, as_tf_tensors=False, as_labeled_dataset=False\n+#     ):\n+#         data = {\n+#             \"float_1\": [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n+#             \"float_2\": [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n+#             \"float_3\": [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n+#             \"string_1\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"],\n+#             \"string_2\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"],\n+#             \"int_1\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n+#             \"int_2\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n+#             \"int_3\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n+#         }\n+#         if as_dataset:\n+#             return tf_data.Dataset.from_tensor_slices(data)\n+#         elif as_tf_tensors:\n+#             return nest.map_structure(ops.convert_to_tensor, data)\n+#         elif as_labeled_dataset:\n+#             labels = [0, 1, 0, 1, 0, 0, 1, 0, 1, 1]\n+#             return tf_data.Dataset.from_tensor_slices((data, labels))\n+#         return data\n+\n+#     def test_basic_usage(self):\n+#         fs = feature_space.FeatureSpace(\n+#             features={\n+#                 \"float_1\": \"float\",\n+#                 \"float_2\": \"float_normalized\",\n+#                 \"float_3\": \"float_discretized\",\n+#                 \"string_1\": \"string_categorical\",\n+#                 \"string_2\": \"string_hashed\",\n+#                 \"int_1\": \"integer_categorical\",\n+#                 \"int_2\": \"integer_hashed\",\n+#                 \"int_3\": \"integer_categorical\",\n+#             },\n+#             crosses=[(\"float_3\", \"string_1\"), (\"string_2\", \"int_2\")],\n+#             output_mode=\"concat\",\n+#         )\n+#         # Test unbatched adapt\n+#         fs.adapt(self._get_train_data_dict(as_dataset=True))\n+#         # Test batched adapt\n+#         fs.adapt(self._get_train_data_dict(as_dataset=True).batch(4))\n+\n+#         # Test unbatched call on raw data\n+#         data = {\n+#             key: value[0] for key, value in self._get_train_data_dict().items()\n+#         }\n+#         out = fs(data)\n+#         self.assertEqual(out.shape, [195])\n+\n+#         # Test unbatched call on TF tensors\n+#         data = self._get_train_data_dict(as_tf_tensors=True)\n+#         data = {key: value[0] for key, value in data.items()}\n+#         out = fs(data)\n+#         self.assertEqual(out.shape, [195])\n+\n+#         # Test batched call on raw data\n+#         out = fs(self._get_train_data_dict())\n+#         self.assertEqual(out.shape, [10, 195])\n+\n+#         # Test batched call on TF tensors\n+#         out = fs(self._get_train_data_dict(as_tf_tensors=True))\n+#         self.assertEqual(out.shape, [10, 195])\n+\n+#     def test_output_mode_dict(self):\n+#         fs = feature_space.FeatureSpace(\n+#             features={\n+#                 \"float_1\": \"float\",\n+#                 \"float_2\": \"float_normalized\",\n+#                 \"float_3\": \"float_discretized\",\n+#                 \"string_1\": \"string_categorical\",\n+#                 \"string_2\": \"string_hashed\",\n+#                 \"int_1\": \"integer_categorical\",\n+#                 \"int_2\": \"integer_hashed\",\n+#                 \"int_3\": \"integer_categorical\",\n+#             },\n+#             crosses=[(\"float_3\", \"string_1\"), (\"string_2\", \"int_2\")],\n+#             output_mode=\"dict\",\n+#         )\n+#         fs.adapt(self._get_train_data_dict(as_dataset=True))\n+\n+#         # Test unbatched call on raw data\n+#         data = {\n+#             key: value[0] for key, value in self._get_train_data_dict().items()\n+#         }\n+#         out = fs(data)\n+#         self.assertIsInstance(out, dict)\n+#         self.assertLen(out, 10)\n+#         self.assertEqual(out[\"string_1\"].shape, [11])\n+#         self.assertEqual(out[\"int_2\"].shape, [32])\n+#         self.assertEqual(out[\"string_2_X_int_2\"].shape, [32])\n+\n+#         # Test batched call on raw data\n+#         out = fs(self._get_train_data_dict())\n+#         self.assertIsInstance(out, dict)\n+#         self.assertLen(out, 10)\n+#         self.assertEqual(out[\"string_1\"].shape, [10, 11])\n+#         self.assertEqual(out[\"int_2\"].shape, [10, 32])\n+#         self.assertEqual(out[\"string_2_X_int_2\"].shape, [10, 32])\n+\n+#         # Test batched call on TF tensors\n+#         out = fs(self._get_train_data_dict(as_tf_tensors=True))\n+#         self.assertIsInstance(out, dict)\n+#         self.assertLen(out, 10)\n+#         self.assertEqual(out[\"string_1\"].shape, [10, 11])\n+#         self.assertEqual(out[\"int_2\"].shape, [10, 32])\n+#         self.assertEqual(out[\"string_2_X_int_2\"].shape, [10, 32])\n+\n+#     def test_output_mode_dict_of_ints(self):\n+#         cls = feature_space.FeatureSpace\n+#         fs = feature_space.FeatureSpace(\n+#             features={\n+#                 \"float_1\": \"float\",\n+#                 \"float_2\": \"float_normalized\",\n+#                 \"float_3\": \"float_discretized\",\n+#                 \"string_1\": cls.string_categorical(output_mode=\"int\"),\n+#                 \"string_2\": cls.string_hashed(num_bins=32, output_mode=\"int\"),\n+#                 \"int_1\": cls.integer_categorical(output_mode=\"int\"),\n+#                 \"int_2\": cls.integer_hashed(num_bins=32, output_mode=\"int\"),\n+#                 \"int_3\": cls.integer_categorical(output_mode=\"int\"),\n+#             },\n+#             crosses=[\n+#                 cls.cross(\n+#                     (\"float_3\", \"string_1\"), output_mode=\"int\", crossing_dim=32\n+#                 ),\n+#                 cls.cross(\n+#                     (\"string_2\", \"int_2\"), output_mode=\"int\", crossing_dim=32\n+#                 ),\n+#             ],\n+#             output_mode=\"dict\",\n+#         )\n+#         fs.adapt(self._get_train_data_dict(as_dataset=True))\n+#         data = {\n+#             key: value[0] for key, value in self._get_train_data_dict().items()\n+#         }\n+#         out = fs(data)\n+#         self.assertIsInstance(out, dict)\n+#         self.assertLen(out, 10)\n+#         self.assertEqual(out[\"string_1\"].shape, [1])\n+#         self.assertEqual(out[\"string_1\"].dtype.name, \"int64\")\n+#         self.assertEqual(out[\"int_2\"].shape, [1])\n+#         self.assertEqual(out[\"int_2\"].dtype.name, \"int64\")\n+#         self.assertEqual(out[\"string_2_X_int_2\"].shape, [1])\n+#         self.assertEqual(out[\"string_2_X_int_2\"].dtype.name, \"int64\")\n+\n+#     def test_functional_api_sync_processing(self):\n+#         fs = feature_space.FeatureSpace(\n+#             features={\n+#                 \"float_1\": \"float\",\n+#                 \"float_2\": \"float_normalized\",\n+#                 \"float_3\": \"float_discretized\",\n+#                 \"string_1\": \"string_categorical\",\n+#                 \"string_2\": \"string_hashed\",\n+#                 \"int_1\": \"integer_categorical\",\n+#                 \"int_2\": \"integer_hashed\",\n+#                 \"int_3\": \"integer_categorical\",\n+#             },\n+#             crosses=[(\"float_3\", \"string_1\"), (\"string_2\", \"int_2\")],\n+#             output_mode=\"concat\",\n+#         )\n+#         fs.adapt(self._get_train_data_dict(as_dataset=True))\n+#         inputs = fs.get_inputs()\n+#         features = fs.get_encoded_features()\n+#         outputs = layers.Dense(1)(features)\n+#         model = models.Model(inputs=inputs, outputs=outputs)\n+#         model.compile(\"adam\", \"mse\")\n+#         ds = self._get_train_data_dict(as_labeled_dataset=True)\n+#         model.fit(ds.batch(4))\n+#         model.evaluate(ds.batch(4))\n+#         ds = self._get_train_data_dict(as_dataset=True)\n+#         model.predict(ds.batch(4))\n+\n+#     def test_tf_data_async_processing(self):\n+#         fs = feature_space.FeatureSpace(\n+#             features={\n+#                 \"float_1\": \"float\",\n+#                 \"float_2\": \"float_normalized\",\n+#                 \"float_3\": \"float_discretized\",\n+#                 \"string_1\": \"string_categorical\",\n+#                 \"string_2\": \"string_hashed\",\n+#                 \"int_1\": \"integer_categorical\",\n+#                 \"int_2\": \"integer_hashed\",\n+#                 \"int_3\": \"integer_categorical\",\n+#             },\n+#             crosses=[(\"float_3\", \"string_1\"), (\"string_2\", \"int_2\")],\n+#             output_mode=\"concat\",\n+#         )\n+#         fs.adapt(self._get_train_data_dict(as_dataset=True))\n+#         features = fs.get_encoded_features()\n+#         outputs = layers.Dense(1)(features)\n+#         model = models.Model(inputs=features, outputs=outputs)\n+#         model.compile(\"adam\", \"mse\")\n+#         ds = self._get_train_data_dict(as_labeled_dataset=True)\n+#         # Try map before batch\n+#         ds = ds.map(lambda x, y: (fs(x), y))\n+#         model.fit(ds.batch(4))\n+#         # Try map after batch\n+#         ds = self._get_train_data_dict(as_labeled_dataset=True)\n+#         ds = ds.batch(4)\n+#         ds = ds.map(lambda x, y: (fs(x), y))\n+#         model.evaluate(ds)\n+#         ds = self._get_train_data_dict(as_dataset=True)\n+#         ds = ds.map(fs)\n+#         model.predict(ds.batch(4))\n+\n+#     def test_advanced_usage(self):\n+#         cls = feature_space.FeatureSpace\n+#         fs = feature_space.FeatureSpace(\n+#             features={\n+#                 \"float_1\": cls.float(),\n+#                 \"float_2\": cls.float_normalized(),\n+#                 \"float_3\": cls.float_discretized(num_bins=3),\n+#                 \"string_1\": cls.string_categorical(max_tokens=5),\n+#                 \"string_2\": cls.string_hashed(num_bins=32),\n+#                 \"int_1\": cls.integer_categorical(\n+#                     max_tokens=5, num_oov_indices=2\n+#                 ),\n+#                 \"int_2\": cls.integer_hashed(num_bins=32),\n+#                 \"int_3\": cls.integer_categorical(max_tokens=5),\n+#             },\n+#             crosses=[\n+#                 cls.cross((\"float_3\", \"string_1\"), crossing_dim=32),\n+#                 cls.cross((\"string_2\", \"int_2\"), crossing_dim=32),\n+#             ],\n+#             output_mode=\"concat\",\n+#         )\n+#         fs.adapt(self._get_train_data_dict(as_dataset=True))\n+#         data = {\n+#             key: value[0] for key, value in self._get_train_data_dict().items()\n+#         }\n+#         out = fs(data)\n+#         self.assertEqual(out.shape, [148])\n+\n+#     def test_manual_kpl(self):\n+#         data = {\n+#             \"text\": [\"1st string\", \"2nd string\", \"3rd string\"],\n+#         }\n+#         cls = feature_space.FeatureSpace\n+\n+#         # Test with a tf-idf TextVectorization layer\n+#         tv = layers.TextVectorization(output_mode=\"tf_idf\")\n+#         fs = feature_space.FeatureSpace(\n+#             features={\n+#                 \"text\": cls.feature(\n+#                     preprocessor=tv, dtype=\"string\", output_mode=\"float\"\n+#                 ),\n+#             },\n+#             output_mode=\"concat\",\n+#         )\n+#         fs.adapt(tf_data.Dataset.from_tensor_slices(data))\n+#         out = fs(data)\n+#         self.assertEqual(out.shape, [3, 5])\n+\n+#     def test_no_adapt(self):\n+#         data = {\n+#             \"int_1\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n+#         }\n+#         fs = feature_space.FeatureSpace(\n+#             {\n+#                 \"int_1\": \"integer_hashed\",\n+#             },\n+#             output_mode=\"concat\",\n+#         )\n+#         out = fs(data)\n+#         self.assertEqual(out.shape, [10, 32])\n+\n+#     def test_saving(self):\n+#         cls = feature_space.FeatureSpace\n+#         fs = feature_space.FeatureSpace(\n+#             features={\n+#                 \"float_1\": cls.float(),\n+#                 \"float_2\": cls.float_normalized(),\n+#                 \"float_3\": cls.float_discretized(num_bins=3),\n+#                 \"string_1\": cls.string_categorical(max_tokens=5),\n+#                 \"string_2\": cls.string_hashed(num_bins=32),\n+#                 \"int_1\": cls.integer_categorical(\n+#                     max_tokens=5, num_oov_indices=2\n+#                 ),\n+#                 \"int_2\": cls.integer_hashed(num_bins=32),\n+#                 \"int_3\": cls.integer_categorical(max_tokens=5),\n+#             },\n+#             crosses=[\n+#                 cls.cross((\"float_3\", \"string_1\"), crossing_dim=32),\n+#                 cls.cross((\"string_2\", \"int_2\"), crossing_dim=32),\n+#             ],\n+#             output_mode=\"concat\",\n+#         )\n+#         fs.adapt(self._get_train_data_dict(as_dataset=True))\n+#         data = {\n+#             key: value[0] for key, value in self._get_train_data_dict().items()\n+#         }\n+#         ref_out = fs(data)\n+\n+#         temp_filepath = os.path.join(self.get_temp_dir(), \"fs.keras\")\n+#         fs.save(temp_filepath)\n+#         fs = models.models.load_model(temp_filepath)\n+\n+#         # Save again immediately after loading to test idempotency\n+#         temp_filepath = os.path.join(self.get_temp_dir(), \"fs2.keras\")\n+#         fs.save(temp_filepath)\n+\n+#         # Test correctness of the first saved FS\n+#         out = fs(data)\n+#         self.assertAllClose(out, ref_out)\n+\n+#         inputs = fs.get_inputs()\n+#         outputs = fs.get_encoded_features()\n+#         model = models.Model(inputs=inputs, outputs=outputs)\n+#         ds = self._get_train_data_dict(as_dataset=True)\n+#         out = model.predict(ds.batch(4))\n+#         self.assertAllClose(out[0], ref_out)\n+\n+#         # Test correctness of the re-saved FS\n+#         fs = models.models.load_model(temp_filepath)\n+#         out = fs(data)\n+#         self.assertAllClose(out, ref_out)\n+\n+#     def test_errors(self):\n+#         # Test no features\n+#         with self.assertRaisesRegex(ValueError, \"cannot be None or empty\"):\n+#             feature_space.FeatureSpace(features={})\n+#         # Test no crossing dim\n+#         with self.assertRaisesRegex(ValueError, \"`crossing_dim`\"):\n+#             feature_space.FeatureSpace(\n+#                 features={\n+#                     \"f1\": \"integer_categorical\",\n+#                     \"f2\": \"integer_categorical\",\n+#                 },\n+#                 crosses=[(\"f1\", \"f2\")],\n+#                 crossing_dim=None,\n+#             )\n+#         # Test wrong cross feature name\n+#         with self.assertRaisesRegex(ValueError, \"should be present in \"):\n+#             feature_space.FeatureSpace(\n+#                 features={\n+#                     \"f1\": \"integer_categorical\",\n+#                     \"f2\": \"integer_categorical\",\n+#                 },\n+#                 crosses=[(\"f1\", \"unknown\")],\n+#                 crossing_dim=32,\n+#             )\n+#         # Test wrong output mode\n+#         with self.assertRaisesRegex(ValueError, \"for argument `output_mode`\"):\n+#             feature_space.FeatureSpace(\n+#                 features={\n+#                     \"f1\": \"integer_categorical\",\n+#                     \"f2\": \"integer_categorical\",\n+#                 },\n+#                 output_mode=\"unknown\",\n+#             )\n+#         # Test call before adapt\n+#         with self.assertRaisesRegex(ValueError, \"You need to call `.adapt\"):\n+#             fs = feature_space.FeatureSpace(\n+#                 features={\n+#                     \"f1\": \"integer_categorical\",\n+#                     \"f2\": \"integer_categorical\",\n+#                 }\n+#             )\n+#             fs({\"f1\": [0], \"f2\": [0]})\n+#         # Test get_encoded_features before adapt\n+#         with self.assertRaisesRegex(ValueError, \"You need to call `.adapt\"):\n+#             fs = feature_space.FeatureSpace(\n+#                 features={\n+#                     \"f1\": \"integer_categorical\",\n+#                     \"f2\": \"integer_categorical\",\n+#                 }\n+#             )\n+#             fs.get_encoded_features()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
