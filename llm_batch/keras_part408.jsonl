{"custom_id": "keras#26adeff60c3e36937e59ecfd1f8ef04dd4f0dc0f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 196 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 196 | Churn Cumulative: 408 | Contributors (this commit): 3 | Commits (past 90d): 1 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -1,196 +0,0 @@\n-# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n-#\n-# Licensed under the Apache License, Version 2.0 (the \"License\");\n-# you may not use this file except in compliance with the License.\n-# You may obtain a copy of the License at\n-#\n-#     http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing, software\n-# distributed under the License is distributed on an \"AS IS\" BASIS,\n-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-# See the License for the specific language governing permissions and\n-# limitations under the License.\n-# ==============================================================================\n-# pylint: disable=g-classes-have-attributes\n-\"\"\"Python module for Keras base types.\n-\n-All the classes in this module is abstract classes that contains none or minimal\n-implementations. It is designed be used as base class for other concrete\n-classes, type checks, and python3 type hints.\n-\"\"\"\n-\n-import abc\n-\n-# TODO(scottzhu): Export all the types under this module with API symbol.\n-\n-\n-class Layer(object, metaclass=abc.ABCMeta):\n-  \"\"\"This is the class from which all layers inherit.\n-\n-  A layer is a callable object that takes as input one or more tensors and\n-  that outputs one or more tensors. It involves *computation*, defined\n-  in the `call()` method, and a *state* (weight variables), defined\n-  either in the constructor `__init__()` or in the `build()` method.\n-\n-  Users will just instantiate a layer and then treat it as a callable.\n-\n-  We recommend that descendants of `Layer` implement the following methods:\n-\n-  * `__init__()`: Defines custom layer attributes, and creates layer state\n-    variables that do not depend on input shapes, using `add_weight()`.\n-  * `build(self, input_shape)`: This method can be used to create weights that\n-    depend on the shape(s) of the input(s), using `add_weight()`. `__call__()`\n-    will automatically build the layer (if it has not been built yet) by\n-    calling `build()`.\n-  * `call(self, *args, **kwargs)`: Called in `__call__` after making sure\n-    `build()` has been called. `call()` performs the logic of applying the\n-    layer to the input tensors (which should be passed in as argument).\n-    Two reserved keyword arguments you can optionally use in `call()` are:\n-      - `training` (boolean, whether the call is in\n-        inference mode or training mode)\n-      - `mask` (boolean tensor encoding masked timesteps in the input, used\n-        in RNN layers)\n-  * `get_config(self)`: Returns a dictionary containing the configuration used\n-    to initialize this layer. If the keys differ from the arguments\n-    in `__init__`, then override `from_config(self)` as well.\n-    This method is used when saving\n-    the layer or a model that contains this layer.\n-\n-  Examples:\n-\n-  Here's a basic example: a layer with two variables, `w` and `b`,\n-  that returns `y = w . x + b`.\n-  It shows how to implement `build()` and `call()`.\n-  Variables set as attributes of a layer are tracked as weights\n-  of the layers (in `layer.weights`).\n-\n-  ```python\n-  class SimpleDense(Layer):\n-\n-    def __init__(self, units=32):\n-        super(SimpleDense, self).__init__()\n-        self.units = units\n-\n-    def build(self, input_shape):  # Create the state of the layer (weights)\n-      w_init = tf.random_normal_initializer()\n-      self.w = tf.Variable(\n-          initial_value=w_init(shape=(input_shape[-1], self.units),\n-                               dtype='float32'),\n-          trainable=True)\n-      b_init = tf.zeros_initializer()\n-      self.b = tf.Variable(\n-          initial_value=b_init(shape=(self.units,), dtype='float32'),\n-          trainable=True)\n-\n-    def call(self, inputs):  # Defines the computation from inputs to outputs\n-        return tf.matmul(inputs, self.w) + self.b\n-\n-  # Instantiates the layer.\n-  linear_layer = SimpleDense(4)\n-\n-  # This will also call `build(input_shape)` and create the weights.\n-  y = linear_layer(tf.ones((2, 2)))\n-  assert len(linear_layer.weights) == 2\n-\n-  # These weights are trainable, so they're listed in `trainable_weights`:\n-  assert len(linear_layer.trainable_weights) == 2\n-  ```\n-\n-  Note that the method `add_weight()` offers a shortcut to create weights:\n-\n-  ```python\n-  class SimpleDense(Layer):\n-\n-    def __init__(self, units=32):\n-        super(SimpleDense, self).__init__()\n-        self.units = units\n-\n-    def build(self, input_shape):\n-        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n-                                 initializer='random_normal',\n-                                 trainable=True)\n-        self.b = self.add_weight(shape=(self.units,),\n-                                 initializer='random_normal',\n-                                 trainable=True)\n-\n-    def call(self, inputs):\n-        return tf.matmul(inputs, self.w) + self.b\n-  ```\n-\n-  Besides trainable weights, updated via backpropagation during training,\n-  layers can also have non-trainable weights. These weights are meant to\n-  be updated manually during `call()`. Here's a example layer that computes\n-  the running sum of its inputs:\n-\n-  ```python\n-  class ComputeSum(Layer):\n-\n-    def __init__(self, input_dim):\n-        super(ComputeSum, self).__init__()\n-        # Create a non-trainable weight.\n-        self.total = tf.Variable(initial_value=tf.zeros((input_dim,)),\n-                                 trainable=False)\n-\n-    def call(self, inputs):\n-        self.total.assign_add(tf.reduce_sum(inputs, axis=0))\n-        return self.total\n-\n-  my_sum = ComputeSum(2)\n-  x = tf.ones((2, 2))\n-\n-  y = my_sum(x)\n-  print(y.numpy())  # [2. 2.]\n-\n-  y = my_sum(x)\n-  print(y.numpy())  # [4. 4.]\n-\n-  assert my_sum.weights == [my_sum.total]\n-  assert my_sum.non_trainable_weights == [my_sum.total]\n-  assert my_sum.trainable_weights == []\n-  ```\n-\n-  For more information about creating layers, see the guide\n-  [Making new Layers and Models via subclassing](\n-    https://www.tensorflow.org/guide/keras/custom_layers_and_models)\n-\n-  Args:\n-    trainable: Boolean, whether the layer's variables should be trainable.\n-    name: String name of the layer.\n-    dtype: The dtype of the layer's computations and weights (default of\n-      `None` means use `tf.keras.backend.floatx` in TensorFlow 2, or the type\n-      of the first input in TensorFlow 1).\n-    dynamic: Set this to `True` if your layer should only be run eagerly, and\n-      should not be used to generate a static computation graph.\n-      This would be the case for a Tree-RNN or a recursive network,\n-      for example, or generally for any layer that manipulates tensors\n-      using Python control flow. If `False`, we assume that the layer can\n-      safely be used to generate a static computation graph.\n-\n-  Attributes:\n-    name: The name of the layer (string).\n-    dtype: The dtype of the layer's computations and weights. If mixed\n-      precision is used with a `tf.keras.mixed_precision.Policy`, this is\n-      instead just the dtype of the layer's weights, as the computations are\n-      done in a different dtype.\n-    updates: List of update ops of this layer.\n-    losses: List of losses added by this layer.\n-    trainable_weights: List of variables to be included in backprop.\n-    non_trainable_weights: List of variables that should not be\n-      included in backprop.\n-    weights: The concatenation of the lists trainable_weights and\n-      non_trainable_weights (in this order).\n-    trainable: Whether the layer should be trained (boolean).\n-    input_spec: Optional (list of) `InputSpec` object(s) specifying the\n-      constraints on inputs that can be accepted by the layer.\n-\n-  Each layer has a dtype, which is typically the dtype of the layer's\n-  computations and variables. A layer's dtype can be queried via the\n-  `Layer.dtype` property. The dtype is specified with the `dtype` constructor\n-  argument. In TensorFlow 2, the dtype defaults to `tf.keras.backend.floatx()`\n-  if no dtype is passed. `floatx()` itself defaults to \"float32\". Additionally,\n-  layers will cast their inputs to the layer's dtype in TensorFlow 2. When mixed\n-  precision is used, layers may have different computation and variable dtypes.\n-  See `tf.keras.mixed_precision.Policy` for details on layer dtypes.\n-  \"\"\"\n-  pass\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8ca59d5598cdcece9196b6943358f7cba37d0306", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 494 | Files Changed: 3 | Hunks: 3 | Methods Changed: 12 | Complexity Δ (Sum/Max): -44/0 | Churn Δ: 494 | Churn Cumulative: 1550 | Contributors (this commit): 14 | Commits (past 90d): 4 | Contributors (cumulative): 20 | DMM Complexity: 0.2751937984496124\n\nDIFF:\n@@ -31,7 +31,6 @@ from keras.utils.generic_utils import get_custom_objects\n from keras.utils.generic_utils import Progbar\n from keras.utils.generic_utils import serialize_keras_object\n from keras.utils.layer_utils import get_source_inputs\n-from keras.utils.multi_gpu_utils import multi_gpu_model\n from keras.utils.np_utils import normalize\n from keras.utils.np_utils import to_categorical\n from keras.utils.vis_utils import model_to_dot\n\n@@ -1,255 +0,0 @@\n-# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n-#\n-# Licensed under the Apache License, Version 2.0 (the \"License\");\n-# you may not use this file except in compliance with the License.\n-# You may obtain a copy of the License at\n-#\n-#     http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing, software\n-# distributed under the License is distributed on an \"AS IS\" BASIS,\n-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-# See the License for the specific language governing permissions and\n-# limitations under the License.\n-# ==============================================================================\n-\"\"\"Utilities for multi-gpu training.\"\"\"\n-\n-from keras import backend\n-from keras.engine.training import Model\n-from keras.layers.core.lambda_layer import Lambda\n-from keras.layers.merging import concatenate\n-import tensorflow.compat.v2 as tf\n-\n-\n-def _get_available_devices():\n-  return [x.name for x in backend.get_session().list_devices()]\n-\n-\n-def _normalize_device_name(name):\n-  name = '/' + name.lower().split('device:')[1]\n-  return name\n-\n-\n-def multi_gpu_model(model, gpus, cpu_merge=True, cpu_relocation=False):\n-  \"\"\"Replicates a model on different GPUs.\n-\n-  Specifically, this function implements single-machine\n-  multi-GPU data parallelism. It works in the following way:\n-\n-  - Divide the model's input(s) into multiple sub-batches.\n-  - Apply a model copy on each sub-batch. Every model copy\n-      is executed on a dedicated GPU.\n-  - Concatenate the results (on CPU) into one big batch.\n-\n-  E.g. if your `batch_size` is 64 and you use `gpus=2`,\n-  then we will divide the input into 2 sub-batches of 32 samples,\n-  process each sub-batch on one GPU, then return the full\n-  batch of 64 processed samples.\n-\n-  This induces quasi-linear speedup on up to 8 GPUs.\n-\n-  This function is only available with the TensorFlow backend\n-  for the time being.\n-\n-  Args:\n-      model: A Keras model instance. To avoid OOM errors, this model could have\n-        been built on CPU, for instance (see usage example below).\n-      gpus: Integer >= 2, number of on GPUs on which to create model replicas.\n-      cpu_merge: A boolean value to identify whether to force merging model\n-        weights under the scope of the CPU or not.\n-      cpu_relocation: A boolean value to identify whether to create the model's\n-        weights under the scope of the CPU. If the model is not defined under\n-        any preceding device scope, you can still rescue it by activating this\n-        option.\n-\n-  Returns:\n-      A Keras `Model` instance which can be used just like the initial\n-      `model` argument, but which distributes its workload on multiple GPUs.\n-\n-  Example 1: Training models with weights merge on CPU\n-\n-  ```python\n-      import tensorflow as tf\n-      from keras.applications import Xception\n-      from keras.utils import multi_gpu_model\n-      import numpy as np\n-\n-      num_samples = 1000\n-      height = 224\n-      width = 224\n-      num_classes = 1000\n-\n-      # Instantiate the base model (or \"template\" model).\n-      # We recommend doing this with under a CPU device scope,\n-      # so that the model's weights are hosted on CPU memory.\n-      # Otherwise they may end up hosted on a GPU, which would\n-      # complicate weight sharing.\n-      with tf.device('/cpu:0'):\n-          model = Xception(weights=None,\n-                           input_shape=(height, width, 3),\n-                           classes=num_classes)\n-\n-      # Replicates the model on 8 GPUs.\n-      # This assumes that your machine has 8 available GPUs.\n-      parallel_model = multi_gpu_model(model, gpus=8)\n-      parallel_model.compile(loss='categorical_crossentropy',\n-                             optimizer='rmsprop')\n-\n-      # Generate dummy data.\n-      x = np.random.random((num_samples, height, width, 3))\n-      y = np.random.random((num_samples, num_classes))\n-\n-      # This `fit` call will be distributed on 8 GPUs.\n-      # Since the batch size is 256, each GPU will process 32 samples.\n-      parallel_model.fit(x, y, epochs=20, batch_size=256)\n-\n-      # Save model via the template model (which shares the same weights):\n-      model.save('my_model.h5')\n-  ```\n-\n-  Example 2: Training models with weights merge on CPU using cpu_relocation\n-\n-  ```python\n-       ..\n-       # Not needed to change the device scope for model definition:\n-       model = Xception(weights=None, ..)\n-\n-       try:\n-           model = multi_gpu_model(model, cpu_relocation=True)\n-           print(\"Training using multiple GPUs..\")\n-       except:\n-           print(\"Training using single GPU or CPU..\")\n-\n-       model.compile(..)\n-       ..\n-  ```\n-\n-  Example 3: Training models with weights merge on GPU (recommended for NV-link)\n-\n-  ```python\n-       ..\n-       # Not needed to change the device scope for model definition:\n-       model = Xception(weights=None, ..)\n-\n-       try:\n-           model = multi_gpu_model(model, cpu_merge=False)\n-           print(\"Training using multiple GPUs..\")\n-       except:\n-           print(\"Training using single GPU or CPU..\")\n-       model.compile(..)\n-       ..\n-  ```\n-\n-  Raises:\n-    ValueError: if the `gpus` argument does not match available devices.\n-  \"\"\"\n-  if isinstance(gpus, (list, tuple)):\n-    if len(gpus) <= 1:\n-      raise ValueError('For multi-gpu usage to be effective, '\n-                       'call `multi_gpu_model` with `len(gpus) >= 2`. '\n-                       'Received: `gpus=%s`' % gpus)\n-    num_gpus = len(gpus)\n-    target_gpu_ids = gpus\n-  else:\n-    if gpus <= 1:\n-      raise ValueError('For multi-gpu usage to be effective, '\n-                       'call `multi_gpu_model` with `gpus >= 2`. '\n-                       'Received: `gpus=%s`' % gpus)\n-    num_gpus = gpus\n-    target_gpu_ids = range(num_gpus)\n-\n-  target_devices = ['/cpu:0'] + ['/gpu:%d' % i for i in target_gpu_ids]\n-  available_devices = _get_available_devices()\n-  available_devices = [\n-      _normalize_device_name(name) for name in available_devices\n-  ]\n-  for device in target_devices:\n-    if device not in available_devices:\n-      raise ValueError('To call `multi_gpu_model` with `gpus=%s`, '\n-                       'we expect the following devices to be available: %s. '\n-                       'However this machine only has: %s. '\n-                       'Try reducing `gpus`.' %\n-                       (gpus, target_devices, available_devices))\n-\n-  def get_slice(data, i, parts):\n-    \"\"\"Slice an array into `parts` slices and return slice `i`.\n-\n-    Args:\n-      data: array to slice.\n-      i: index of slice to return.\n-      parts: number of slices to make.\n-\n-    Returns:\n-      Slice `i` of `data`.\n-    \"\"\"\n-    shape = tf.shape(data)\n-    batch_size = shape[:1]\n-    input_shape = shape[1:]\n-    step = batch_size // parts\n-    if i == parts - 1:\n-      size = batch_size - step * i\n-    else:\n-      size = step\n-    size = tf.concat([size, input_shape], axis=0)\n-    stride = tf.concat([step, input_shape * 0], axis=0)\n-    start = stride * i\n-    return tf.slice(data, start, size)\n-\n-  # Relocate the model definition under CPU device scope if needed\n-  if cpu_relocation:\n-    from keras.models import clone_model  # pylint: disable=g-import-not-at-top\n-    with tf.device('/cpu:0'):\n-      model = clone_model(model)\n-\n-  all_outputs = [[] for _ in range(len(model.outputs))]\n-\n-  # Place a copy of the model on each GPU,\n-  # each getting a slice of the inputs.\n-  for i, gpu_id in enumerate(target_gpu_ids):\n-    with tf.device('/gpu:%d' % gpu_id):\n-      with backend.name_scope('replica_%d' % gpu_id):\n-        inputs = []\n-        # Retrieve a slice of the input.\n-        for x in model.inputs:\n-          input_shape = tuple(x.shape.as_list())[1:]\n-          slice_i = Lambda(\n-              get_slice,\n-              output_shape=input_shape,\n-              arguments={\n-                  'i': i,\n-                  'parts': num_gpus\n-              })(\n-                  x)\n-          inputs.append(slice_i)\n-\n-        # Apply model on slice\n-        # (creating a model replica on the target device).\n-        outputs = model(inputs)\n-        if not isinstance(outputs, list):\n-          outputs = [outputs]\n-\n-        # Save the outputs for merging back together later.\n-        for o, output in enumerate(outputs):\n-          all_outputs[o].append(output)\n-\n-  # Deduplicate output names to handle Siamese networks.\n-  occurrences = {}\n-  for n in model.output_names:\n-    if n not in occurrences:\n-      occurrences[n] = 1\n-    else:\n-      occurrences[n] += 1\n-  conflict_counter = {n: 0 for n, count in occurrences.items() if count > 1}\n-  output_names = []\n-  for n in model.output_names:\n-    if n in conflict_counter:\n-      conflict_counter[n] += 1\n-      n += '_%d' % conflict_counter[n]\n-    output_names.append(n)\n-\n-  # Merge outputs under expected scope.\n-  with tf.device('/cpu:0' if cpu_merge else '/gpu:%d' % target_gpu_ids[0]):\n-    merged = []\n-    for name, outputs in zip(output_names, all_outputs):\n-      merged.append(concatenate(outputs, axis=0, name=name))\n-    return Model(model.inputs, merged)\n\n@@ -1,238 +0,0 @@\n-# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n-#\n-# Licensed under the Apache License, Version 2.0 (the \"License\");\n-# you may not use this file except in compliance with the License.\n-# You may obtain a copy of the License at\n-#\n-#     http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing, software\n-# distributed under the License is distributed on an \"AS IS\" BASIS,\n-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-# See the License for the specific language governing permissions and\n-# limitations under the License.\n-# ==============================================================================\n-\"\"\"Tests for multi-gpu training utilities.\"\"\"\n-\n-import tensorflow.compat.v2 as tf\n-\n-import numpy as np\n-import keras\n-from keras import optimizer_v1\n-from keras.utils import multi_gpu_utils\n-from keras.utils import np_utils\n-\n-\n-def check_if_compatible_devices(gpus=2):\n-  available_devices = [\n-      keras.utils.multi_gpu_utils._normalize_device_name(name)\n-      for name in keras.utils.multi_gpu_utils._get_available_devices()\n-  ]\n-  if '/gpu:%d' % (gpus - 1) not in available_devices:\n-    return False\n-  return True\n-\n-\n-class TestMultiGPUModel(tf.test.TestCase):\n-\n-  def __init__(self, methodName='runTest'):  # pylint: disable=invalid-name\n-    super(TestMultiGPUModel, self).__init__(methodName)\n-    gpu_devices = tf.config.list_physical_devices('GPU')\n-    if len(gpu_devices) == 1:\n-      # A GPU is available, simulate 2 instead.\n-      tf.config.set_logical_device_configuration(gpu_devices[0], [\n-          tf.config.LogicalDeviceConfiguration(500),\n-          tf.config.LogicalDeviceConfiguration(500)\n-      ])\n-\n-  def test_multi_gpu_test_simple_model(self):\n-    gpus = 2\n-    num_samples = 1000\n-    input_dim = 10\n-    output_dim = 1\n-    hidden_dim = 10\n-    epochs = 2\n-    target_gpu_id = [0, 1]\n-\n-    if not check_if_compatible_devices(gpus=gpus):\n-      self.skipTest('multi gpu only')\n-\n-    with self.cached_session():\n-      model = keras.models.Sequential()\n-      model.add(keras.layers.Dense(hidden_dim,\n-                                   input_shape=(input_dim,)))\n-      model.add(keras.layers.Dense(output_dim))\n-\n-      x = np.random.random((num_samples, input_dim))\n-      y = np.random.random((num_samples, output_dim))\n-\n-      parallel_model = multi_gpu_utils.multi_gpu_model(model, gpus=gpus)\n-      parallel_model.compile(loss='mse', optimizer='rmsprop')\n-      parallel_model.fit(x, y, epochs=epochs)\n-      parallel_model = multi_gpu_utils.multi_gpu_model(\n-          model, gpus=target_gpu_id)\n-      parallel_model.compile(loss='mse', optimizer='rmsprop')\n-      parallel_model.fit(x, y, epochs=epochs)\n-\n-  def test_multi_gpu_test_multi_io_model(self):\n-    gpus = 2\n-    num_samples = 1000\n-    input_dim_a = 10\n-    input_dim_b = 5\n-    output_dim_a = 1\n-    output_dim_b = 2\n-    hidden_dim = 10\n-    epochs = 2\n-    target_gpu_id = [0, 1]\n-\n-    if not check_if_compatible_devices(gpus=gpus):\n-      self.skipTest('multi gpu only')\n-\n-    with self.cached_session():\n-      input_a = keras.Input((input_dim_a,))\n-      input_b = keras.Input((input_dim_b,))\n-      a = keras.layers.Dense(hidden_dim)(input_a)\n-      b = keras.layers.Dense(hidden_dim)(input_b)\n-      c = keras.layers.concatenate([a, b])\n-      output_a = keras.layers.Dense(output_dim_a)(c)\n-      output_b = keras.layers.Dense(output_dim_b)(c)\n-      model = keras.models.Model([input_a, input_b], [output_a, output_b])\n-\n-      a_x = np.random.random((num_samples, input_dim_a))\n-      b_x = np.random.random((num_samples, input_dim_b))\n-      a_y = np.random.random((num_samples, output_dim_a))\n-      b_y = np.random.random((num_samples, output_dim_b))\n-\n-      parallel_model = multi_gpu_utils.multi_gpu_model(model, gpus=gpus)\n-      parallel_model.compile(loss='mse', optimizer='rmsprop')\n-      parallel_model.fit([a_x, b_x], [a_y, b_y], epochs=epochs)\n-\n-      parallel_model = multi_gpu_utils.multi_gpu_model(\n-          model, gpus=target_gpu_id)\n-      parallel_model.compile(loss='mse', optimizer='rmsprop')\n-      parallel_model.fit([a_x, b_x], [a_y, b_y], epochs=epochs)\n-\n-  def test_multi_gpu_test_invalid_devices(self):\n-    if not check_if_compatible_devices(gpus=2):\n-      self.skipTest('multi gpu only')\n-\n-    with self.cached_session():\n-      input_shape = (1000, 10)\n-      model = keras.models.Sequential()\n-      model.add(keras.layers.Dense(10,\n-                                   activation='relu',\n-                                   input_shape=input_shape[1:]))\n-      model.add(keras.layers.Dense(1, activation='sigmoid'))\n-      model.compile(loss='mse', optimizer='rmsprop')\n-\n-      x = np.random.random(input_shape)\n-      y = np.random.random((input_shape[0], 1))\n-      with self.assertRaises(ValueError):\n-        parallel_model = multi_gpu_utils.multi_gpu_model(\n-            model, gpus=len(keras.backend._get_available_gpus()) + 1)\n-        parallel_model.fit(x, y, epochs=2)\n-\n-      with self.assertRaises(ValueError):\n-        parallel_model = multi_gpu_utils.multi_gpu_model(\n-            model, gpus=[0, 2, 4, 6, 8])\n-        parallel_model.fit(x, y, epochs=2)\n-\n-      with self.assertRaises(ValueError):\n-        parallel_model = multi_gpu_utils.multi_gpu_model(model, gpus=1)\n-        parallel_model.fit(x, y, epochs=2)\n-\n-      with self.assertRaises(ValueError):\n-        parallel_model = multi_gpu_utils.multi_gpu_model(model, gpus=[0])\n-        parallel_model.fit(x, y, epochs=2)\n-\n-  def test_nested_model_with_tensor_input(self):\n-    gpus = 2\n-    input_dim = 10\n-    shape = (input_dim,)\n-    num_samples = 16\n-    num_classes = 10\n-\n-    if not check_if_compatible_devices(gpus=gpus):\n-      self.skipTest('multi gpu only')\n-\n-    with tf.Graph().as_default(), self.cached_session():\n-      input_shape = (num_samples,) + shape\n-      x_train = np.random.randint(0, 255, input_shape)\n-      y_train = np.random.randint(0, num_classes, (input_shape[0],))\n-\n-      y_train = np_utils.to_categorical(y_train, num_classes)\n-\n-      x_train = x_train.astype('float32')\n-      y_train = y_train.astype('float32')\n-\n-      dataset = tf.compat.v1.data.Dataset.from_tensor_slices((x_train, y_train))\n-      dataset = dataset.repeat()\n-      dataset = dataset.batch(4)\n-      iterator = tf.compat.v1.data.make_one_shot_iterator(dataset)\n-\n-      inputs, targets = iterator.get_next()\n-\n-      input_tensor = keras.layers.Input(tensor=inputs)\n-\n-      model = keras.models.Sequential()\n-      model.add(keras.layers.Dense(3,\n-                                   input_shape=(input_dim,)))\n-      model.add(keras.layers.Dense(num_classes))\n-\n-      output = model(input_tensor)\n-      outer_model = keras.Model(input_tensor, output)\n-      parallel_model = multi_gpu_utils.multi_gpu_model(outer_model, gpus=gpus)\n-\n-      parallel_model.compile(\n-          loss='categorical_crossentropy',\n-          optimizer=optimizer_v1.RMSprop(lr=0.0001, decay=1e-6),\n-          metrics=['accuracy'],\n-          target_tensors=[targets])\n-      parallel_model.fit(epochs=1, steps_per_epoch=3)\n-\n-  def test_multi_gpu_with_multi_input_layers(self):\n-    gpus = 2\n-\n-    if not check_if_compatible_devices(gpus=gpus):\n-      self.skipTest('multi gpu only')\n-\n-    with self.cached_session():\n-      inputs = keras.Input((4, 3))\n-      init_state = keras.Input((3,))\n-      outputs = keras.layers.SimpleRNN(\n-          3, return_sequences=True)(inputs, initial_state=init_state)\n-      x = [np.random.randn(2, 4, 3), np.random.randn(2, 3)]\n-      y = np.random.randn(2, 4, 3)\n-      model = keras.Model([inputs, init_state], outputs)\n-      parallel_model = multi_gpu_utils.multi_gpu_model(model, gpus=gpus)\n-      parallel_model.compile(loss='mean_squared_error', optimizer='adam')\n-      parallel_model.train_on_batch(x, y)\n-\n-  def test_multi_gpu_with_siamese_network(self):\n-    gpus = 2\n-\n-    if not check_if_compatible_devices(gpus=gpus):\n-      self.skipTest('multi gpu only')\n-\n-    with self.cached_session():\n-      input_shape = (3,)\n-      nested_model = keras.models.Sequential([\n-          keras.layers.Dense(32, input_shape=input_shape),\n-          keras.layers.Dense(1)\n-      ], name='nested')\n-\n-      input1 = keras.Input(input_shape)\n-      input2 = keras.Input(input_shape)\n-      score1 = nested_model(input1)\n-      score2 = nested_model(input2)\n-      score_sum = keras.layers.Add(name='add')([score1, score2])\n-\n-      siamese = keras.models.Model(inputs=[input1, input2],\n-                                   outputs=[score_sum, score1, score2],\n-                                   name='siamese')\n-      parallel_siamese = multi_gpu_utils.multi_gpu_model(siamese, gpus)\n-      self.assertEqual(parallel_siamese.output_names,\n-                       ['add', 'nested', 'nested_1'])\n-\n-if __name__ == '__main__':\n-  tf.test.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1fc75b4041e6baf4338a7a2c68779d290b9945eb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1572 | Lines Deleted: 1476 | Files Changed: 14 | Hunks: 43 | Methods Changed: 131 | Complexity Δ (Sum/Max): 62/41 | Churn Δ: 3048 | Churn Cumulative: 6881 | Contributors (this commit): 24 | Commits (past 90d): 53 | Contributors (cumulative): 54 | DMM Complexity: 0.0\n\nDIFF:\n@@ -57,6 +57,11 @@ from keras.layers.advanced_activations import ReLU\n from keras.layers.advanced_activations import ThresholdedReLU\n from keras.layers.advanced_activations import Softmax\n \n+# Attention layers.\n+from keras.layers.attention.multi_head_attention import MultiHeadAttention\n+from keras.layers.attention.attention import Attention\n+from keras.layers.attention.additive_attention import AdditiveAttention\n+\n # Convolution layers.\n from keras.layers.convolutional.conv1d import Conv1D\n from keras.layers.convolutional.conv2d import Conv2D\n@@ -115,19 +120,12 @@ from keras.layers.core.tf_op_layer import InstanceProperty\n from keras.layers.core.tf_op_layer import SlicingOpLambda\n from keras.layers.core.tf_op_layer import TFOpLambda\n \n-# Dense Attention layers.\n-from keras.layers.dense_attention import AdditiveAttention\n-from keras.layers.dense_attention import Attention\n-\n # Embedding layers.\n from keras.layers.embeddings import Embedding\n \n # Einsum-based dense layer/\n from keras.layers.einsum_dense import EinsumDense\n \n-# Multi-head Attention layer.\n-from keras.layers.multi_head_attention import MultiHeadAttention\n-\n # Locally-connected layers.\n from keras.layers.local import LocallyConnected1D\n from keras.layers.local import LocallyConnected2D\n\n@@ -0,0 +1,20 @@\n+# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Keras attention layers.\"\"\"\n+# pylint: disable=g-bad-import-order\n+\n+from keras.layers.attention.multi_head_attention import MultiHeadAttention\n+from keras.layers.attention.attention import Attention\n+from keras.layers.attention.additive_attention import AdditiveAttention\n\n@@ -0,0 +1,175 @@\n+# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Additive attention layer that can be used in sequence DNN/CNN models.\n+\n+This file follows the terminology of https://arxiv.org/abs/1706.03762 Figure 2.\n+Attention is formed by three tensors: Query, Key and Value.\n+\"\"\"\n+# pylint: disable=g-classes-have-attributes,g-direct-tensorflow-import\n+\n+from keras.layers.attention.base_dense_attention import BaseDenseAttention\n+import tensorflow.compat.v2 as tf\n+\n+from tensorflow.python.util.tf_export import keras_export\n+\n+\n+@keras_export('keras.layers.AdditiveAttention')\n+class AdditiveAttention(BaseDenseAttention):\n+  \"\"\"Additive attention layer, a.k.a. Bahdanau-style attention.\n+\n+  Inputs are `query` tensor of shape `[batch_size, Tq, dim]`, `value` tensor of\n+  shape `[batch_size, Tv, dim]` and `key` tensor of shape\n+  `[batch_size, Tv, dim]`. The calculation follows the steps:\n+\n+  1. Reshape `query` and `key` into shapes `[batch_size, Tq, 1, dim]`\n+     and `[batch_size, 1, Tv, dim]` respectively.\n+  2. Calculate scores with shape `[batch_size, Tq, Tv]` as a non-linear\n+     sum: `scores = tf.reduce_sum(tf.tanh(query + key), axis=-1)`\n+  3. Use scores to calculate a distribution with shape\n+     `[batch_size, Tq, Tv]`: `distribution = tf.nn.softmax(scores)`.\n+  4. Use `distribution` to create a linear combination of `value` with\n+     shape `[batch_size, Tq, dim]`:\n+     `return tf.matmul(distribution, value)`.\n+\n+  Args:\n+    use_scale: If `True`, will create a variable to scale the attention scores.\n+    causal: Boolean. Set to `True` for decoder self-attention. Adds a mask such\n+      that position `i` cannot attend to positions `j > i`. This prevents the\n+      flow of information from the future towards the past.\n+      Defaults to `False`.\n+    dropout: Float between 0 and 1. Fraction of the units to drop for the\n+      attention scores. Defaults to 0.0.\n+\n+  Call Args:\n+\n+    inputs: List of the following tensors:\n+      * query: Query `Tensor` of shape `[batch_size, Tq, dim]`.\n+      * value: Value `Tensor` of shape `[batch_size, Tv, dim]`.\n+      * key: Optional key `Tensor` of shape `[batch_size, Tv, dim]`. If not\n+        given, will use `value` for both `key` and `value`, which is the\n+        most common case.\n+    mask: List of the following tensors:\n+      * query_mask: A boolean mask `Tensor` of shape `[batch_size, Tq]`.\n+        If given, the output will be zero at the positions where\n+        `mask==False`.\n+      * value_mask: A boolean mask `Tensor` of shape `[batch_size, Tv]`.\n+        If given, will apply the mask such that values at positions where\n+        `mask==False` do not contribute to the result.\n+    training: Python boolean indicating whether the layer should behave in\n+      training mode (adding dropout) or in inference mode (no dropout).\n+    return_attention_scores: bool, it `True`, returns the attention scores\n+      (after masking and softmax) as an additional output argument.\n+\n+  Output:\n+\n+    Attention outputs of shape `[batch_size, Tq, dim]`.\n+    [Optional] Attention scores after masking and softmax with shape\n+      `[batch_size, Tq, Tv]`.\n+\n+  The meaning of `query`, `value` and `key` depend on the application. In the\n+  case of text similarity, for example, `query` is the sequence embeddings of\n+  the first piece of text and `value` is the sequence embeddings of the second\n+  piece of text. `key` is usually the same tensor as `value`.\n+\n+  Here is a code example for using `AdditiveAttention` in a CNN+Attention\n+  network:\n+\n+  ```python\n+  # Variable-length int sequences.\n+  query_input = tf.keras.Input(shape=(None,), dtype='int32')\n+  value_input = tf.keras.Input(shape=(None,), dtype='int32')\n+\n+  # Embedding lookup.\n+  token_embedding = tf.keras.layers.Embedding(max_tokens, dimension)\n+  # Query embeddings of shape [batch_size, Tq, dimension].\n+  query_embeddings = token_embedding(query_input)\n+  # Value embeddings of shape [batch_size, Tv, dimension].\n+  value_embeddings = token_embedding(value_input)\n+\n+  # CNN layer.\n+  cnn_layer = tf.keras.layers.Conv1D(\n+      filters=100,\n+      kernel_size=4,\n+      # Use 'same' padding so outputs have the same shape as inputs.\n+      padding='same')\n+  # Query encoding of shape [batch_size, Tq, filters].\n+  query_seq_encoding = cnn_layer(query_embeddings)\n+  # Value encoding of shape [batch_size, Tv, filters].\n+  value_seq_encoding = cnn_layer(value_embeddings)\n+\n+  # Query-value attention of shape [batch_size, Tq, filters].\n+  query_value_attention_seq = tf.keras.layers.AdditiveAttention()(\n+      [query_seq_encoding, value_seq_encoding])\n+\n+  # Reduce over the sequence axis to produce encodings of shape\n+  # [batch_size, filters].\n+  query_encoding = tf.keras.layers.GlobalAveragePooling1D()(\n+      query_seq_encoding)\n+  query_value_attention = tf.keras.layers.GlobalAveragePooling1D()(\n+      query_value_attention_seq)\n+\n+  # Concatenate query and document encodings to produce a DNN input layer.\n+  input_layer = tf.keras.layers.Concatenate()(\n+      [query_encoding, query_value_attention])\n+\n+  # Add DNN layers, and create Model.\n+  # ...\n+  ```\n+  \"\"\"\n+\n+  def __init__(self, use_scale=True, **kwargs):\n+    super(AdditiveAttention, self).__init__(**kwargs)\n+    self.use_scale = use_scale\n+\n+  def build(self, input_shape):\n+    v_shape = tf.TensorShape(input_shape[1])\n+    dim = v_shape[-1]\n+    dim = tf.compat.dimension_value(dim)\n+    if self.use_scale:\n+      self.scale = self.add_weight(\n+          name='scale',\n+          shape=[dim],\n+          initializer='glorot_uniform',\n+          dtype=self.dtype,\n+          trainable=True)\n+    else:\n+      self.scale = None\n+    super(AdditiveAttention, self).build(input_shape)\n+\n+  def _calculate_scores(self, query, key):\n+    \"\"\"Calculates attention scores as a nonlinear sum of query and key.\n+\n+    Args:\n+      query: Query tensor of shape `[batch_size, Tq, dim]`.\n+      key: Key tensor of shape `[batch_size, Tv, dim]`.\n+    Returns:\n+      Tensor of shape `[batch_size, Tq, Tv]`.\n+    \"\"\"\n+    # Reshape tensors to enable broadcasting.\n+    # Reshape into [batch_size, Tq, 1, dim].\n+    q_reshaped = tf.expand_dims(query, axis=-2)\n+    # Reshape into [batch_size, 1, Tv, dim].\n+    k_reshaped = tf.expand_dims(key, axis=-3)\n+    if self.use_scale:\n+      scale = self.scale\n+    else:\n+      scale = 1.\n+    return tf.reduce_sum(\n+        scale * tf.tanh(q_reshaped + k_reshaped), axis=-1)\n+\n+  def get_config(self):\n+    config = {'use_scale': self.use_scale}\n+    base_config = super(AdditiveAttention, self).get_config()\n+    return dict(list(base_config.items()) + list(config.items()))\n\n@@ -0,0 +1,279 @@\n+# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Tests AdditiveAttention layer.\"\"\"\n+\n+from absl.testing import parameterized\n+import keras\n+from keras import combinations\n+from keras import testing_utils\n+from keras.mixed_precision import policy\n+import numpy as np\n+import tensorflow.compat.v2 as tf\n+\n+\n+@combinations.generate(combinations.combine(mode=['graph', 'eager']))\n+class AdditiveAttentionTest(tf.test.TestCase, parameterized.TestCase):\n+\n+  def test_calculate_scores_one_dim(self):\n+    # Query tensor of shape [1, 1, 1]\n+    q = np.array([[[1.1]]], dtype=np.float32)\n+    # Key tensor of shape [1, 1, 1]\n+    k = np.array([[[1.6]]], dtype=np.float32)\n+    attention_layer = keras.layers.AdditiveAttention()\n+    attention_layer.build(input_shape=([1, 1, 1], [1, 1, 1]))\n+    # Scale tensor of shape [1]\n+    attention_layer.scale = np.array([[[0.5]]], dtype=np.float32)\n+    actual = attention_layer._calculate_scores(query=q, key=k)\n+\n+    # Expected tensor of shape [1, 1, 1].\n+    # expected000 = 0.5 * tanh(1.1 + 1.6) = 0.49550372683\n+    expected = np.array([[[0.49550372683]]], dtype=np.float32)\n+    self.assertAllClose(expected, actual)\n+\n+  def test_calculate_scores_multi_dim(self):\n+    # Query tensor of shape [1, 2, 4]\n+    q = np.array([[[1., 1.1, 1.2, 1.3], [2., 2.1, 2.2, 2.3]]], dtype=np.float32)\n+    # Key tensor of shape [1, 3, 4]\n+    k = np.array(\n+        [[[1.5, 1.6, 1.7, 1.8], [2.5, 2.6, 2.7, 2.8], [3.5, 3.6, 3.7, 3.8]]],\n+        dtype=np.float32)\n+    attention_layer = keras.layers.AdditiveAttention()\n+    attention_layer.build(input_shape=([1, 2, 4], [1, 3, 4]))\n+    # Scale tensor of shape [4]\n+    attention_layer.scale = np.array([[[0.5, 0.6, 0.7, 0.8]]], dtype=np.float32)\n+    actual = attention_layer._calculate_scores(query=q, key=k)\n+\n+    # pylint:disable=line-too-long\n+    # expected000 = 0.5*tanh(1.+1.5) + 0.6*tanh(1.1+1.6) + 0.7*tanh(1.2+1.7) + 0.8*tanh(1.3+1.8) = 2.58044532581\n+    # expected001 = 0.5*tanh(1.+2.5) + 0.6*tanh(1.1+2.6) + 0.7*tanh(1.2+2.7) + 0.8*tanh(1.3+2.8) = 2.59734317449\n+    # expected002 = 0.5*tanh(1.+3.5) + 0.6*tanh(1.1+3.6) + 0.7*tanh(1.2+3.7) + 0.8*tanh(1.3+3.8) = 2.59964024652\n+    # expected010 = 0.5*tanh(2.+1.5) + 0.6*tanh(2.1+1.6) + 0.7*tanh(2.2+1.7) + 0.8*tanh(2.3+1.8) = 2.59734317449\n+    # expected011 = 0.5*tanh(2.+2.5) + 0.6*tanh(2.1+2.6) + 0.7*tanh(2.2+2.7) + 0.8*tanh(2.3+2.8) = 2.59964024652\n+    # expected012 = 0.5*tanh(2.+3.5) + 0.6*tanh(2.1+3.6) + 0.7*tanh(2.2+3.7) + 0.8*tanh(2.3+3.8) = 2.59995130916\n+    # pylint:enable=line-too-long\n+    expected = np.array([[[2.58044532581, 2.59734317449, 2.59964024652],\n+                          [2.59734317449, 2.59964024652, 2.59995130916]]],\n+                        dtype=np.float32)\n+    self.assertAllClose(expected, actual)\n+\n+  def test_calculate_scores_one_dim_batch_size_two(self):\n+    # Query tensor of shape [2, 1, 1]\n+    q = np.array([[[1.1]], [[2.1]]], dtype=np.float32)\n+    # Key tensor of shape [2, 1, 1]\n+    k = np.array([[[1.6]], [[2.6]]], dtype=np.float32)\n+    attention_layer = keras.layers.AdditiveAttention()\n+    attention_layer.build(input_shape=([2, 1, 1], [2, 1, 1]))\n+    # Scale tensor of shape [1]\n+    attention_layer.scale = np.array([[[0.5]]], dtype=np.float32)\n+    actual = attention_layer._calculate_scores(query=q, key=k)\n+\n+    # Expected tensor of shape [2, 1, 1].\n+    # expected000 = 0.5 * tanh(1.1 + 1.6) = 0.49550372683\n+    # expected100 = 0.5 * tanh(2.1 + 2.6) = 0.49991728277\n+    expected = np.array([[[0.49550372683]], [[0.49991728277]]],\n+                        dtype=np.float32)\n+    self.assertAllClose(expected, actual)\n+\n+  def test_shape(self):\n+    # Query tensor of shape [1, 2, 4]\n+    q = np.array([[[1., 1.1, 1.2, 1.3], [2., 2.1, 2.2, 2.3]]], dtype=np.float32)\n+    # Value tensor of shape [1, 3, 4]\n+    v = np.array(\n+        [[[1.5, 1.6, 1.7, 1.8], [2.5, 2.6, 2.7, 2.8], [3.5, 3.6, 3.7, 3.8]]],\n+        dtype=np.float32)\n+    # Value mask tensor of shape [1, 3]\n+    v_mask = np.array([[True, True, False]], dtype=np.bool_)\n+    attention_layer = keras.layers.AdditiveAttention()\n+    actual = attention_layer([q, v], mask=[None, v_mask])\n+\n+    expected_shape = [1, 2, 4]\n+    self.assertAllEqual(expected_shape, tf.shape(actual))\n+\n+  def test_shape_no_scale(self):\n+    # Query tensor of shape [1, 2, 4]\n+    q = np.array([[[1., 1.1, 1.2, 1.3], [2., 2.1, 2.2, 2.3]]], dtype=np.float32)\n+    # Value tensor of shape [1, 3, 4]\n+    v = np.array(\n+        [[[1.5, 1.6, 1.7, 1.8], [2.5, 2.6, 2.7, 2.8], [3.5, 3.6, 3.7, 3.8]]],\n+        dtype=np.float32)\n+    # Value mask tensor of shape [1, 3]\n+    v_mask = np.array([[True, True, False]], dtype=np.bool_)\n+    attention_layer = keras.layers.AdditiveAttention(use_scale=False)\n+    actual = attention_layer([q, v], mask=[None, v_mask])\n+\n+    expected_shape = [1, 2, 4]\n+    self.assertAllEqual(expected_shape, tf.shape(actual))\n+\n+  def test_shape_with_key(self):\n+    # Query tensor of shape [1, 2, 4]\n+    q = np.array([[[1., 1.1, 1.2, 1.3], [2., 2.1, 2.2, 2.3]]], dtype=np.float32)\n+    # Value tensor of shape [1, 3, 4]\n+    v = np.array(\n+        [[[1.5, 1.6, 1.7, 1.8], [2.5, 2.6, 2.7, 2.8], [3.5, 3.6, 3.7, 3.8]]],\n+        dtype=np.float32)\n+    # Key tensor of shape [1, 3, 4]\n+    k = np.array(\n+        [[[1.5, 1.6, 1.7, 1.8], [2.5, 2.6, 2.7, 2.8], [3.5, 3.6, 3.7, 3.8]]],\n+        dtype=np.float32)\n+    # Value mask tensor of shape [1, 3]\n+    v_mask = np.array([[True, True, False]], dtype=np.bool_)\n+    attention_layer = keras.layers.AdditiveAttention()\n+    actual = attention_layer([q, v, k], mask=[None, v_mask])\n+\n+    expected_shape = [1, 2, 4]\n+    self.assertAllEqual(expected_shape, tf.shape(actual))\n+\n+  def test_multi_dim(self):\n+    # Query tensor of shape [1, 1, 1]\n+    q = np.array([[[1.1]]], dtype=np.float32)\n+    # Value tensor of shape [1, 3, 1]\n+    v = np.array([[[1.6], [0.7], [-0.8]]], dtype=np.float32)\n+    # Value mask tensor of shape [1, 3]\n+    v_mask = np.array([[True, True, False]], dtype=np.bool_)\n+    attention_layer = keras.layers.AdditiveAttention()\n+    attention_layer.build(input_shape=([1, 1, 1], [1, 3, 1]))\n+    # Scale tensor of shape [1]\n+    attention_layer.scale = np.array([[[0.5]]], dtype=np.float32)\n+    actual = attention_layer([q, v], mask=[None, v_mask])\n+\n+    # pylint:disable=line-too-long\n+    # Expected scores of shape [1, 1, 3]\n+    # scores = [[[0.5 * tanh(1.1 + 1.6), 0.5 * tanh(1.1 + 0.7), 0.5 * tanh(1.1 - 0.8)]]]\n+    #        = [[[0.49550372683, 0.47340300642, 0.14565630622]]]\n+    # Expected attention distribution = softmax(scores) with zeros in\n+    # positions where v_mask == False.\n+    # => attention_distribution000\n+    #      = exp(0.49550372683)/(exp(0.49550372683) + exp(0.47340300642))\n+    #      = 0.50552495521\n+    #    attention_distribution001\n+    #      = exp(0.47340300642)/(exp(0.49550372683) + exp(0.47340300642))\n+    #      = 0.49447504478\n+    #    attention_distribution002 = 0\n+    #\n+    # Expected tensor of shape [1, 1, 1].\n+    # expected000 = 0.50552495521 * 1.6 + 0.49447504478 * 0.7 - 0 * 0.8\n+    #             = 1.15497245968\n+    # pylint:enable=line-too-long\n+    expected = np.array([[[1.15497245968]]], dtype=np.float32)\n+    self.assertAllClose(expected, actual)\n+\n+  def test_multi_dim_with_key(self):\n+    # Query tensor of shape [1, 1, 1]\n+    q = np.array([[[1.1]]], dtype=np.float32)\n+    # Value tensor of shape [1, 3, 1]\n+    v = np.array([[[0.5], [0.8], [-0.3]]], dtype=np.float32)\n+    # Key tensor of shape [1, 3, 1]\n+    k = np.array([[[1.6], [0.7], [-0.8]]], dtype=np.float32)\n+    # Value mask tensor of shape [1, 3]\n+    v_mask = np.array([[True, True, False]], dtype=np.bool_)\n+    attention_layer = keras.layers.AdditiveAttention()\n+    attention_layer.build(input_shape=([1, 1, 1], [1, 3, 1]))\n+    # Scale tensor of shape [1]\n+    attention_layer.scale = np.array([[[0.5]]], dtype=np.float32)\n+    actual = attention_layer([q, v, k], mask=[None, v_mask])\n+\n+    # pylint:disable=line-too-long\n+    # Expected scores of shape [1, 1, 3]\n+    # scores = [[[0.5 * tanh(1.1 + 1.6), 0.5 * tanh(1.1 + 0.7), 0.5 * tanh(1.1 - 0.8)]]]\n+    #        = [[[0.49550372683, 0.47340300642, 0.14565630622]]]\n+    # Expected attention distribution = softmax(scores) with zeros in\n+    # positions where v_mask == False.\n+    # => attention_distribution000\n+    #        = exp(0.49550372683)/(exp(0.49550372683) + exp(0.47340300642))\n+    #        = 0.50552495521\n+    #    attention_distribution001\n+    #        = exp(0.47340300642)/(exp(0.49550372683) + exp(0.47340300642))\n+    #        = 0.49447504478\n+    #    attention_distribution002 = 0\n+    #\n+    # Expected tensor of shape [1, 1, 1].\n+    # expected000 = 0.50552495521 * 0.5 + 0.49447504478 * 0.8 - 0 * 0.3\n+    #             = 0.64834251342\n+    # pylint:enable=line-too-long\n+    expected = np.array([[[0.64834251342]]], dtype=np.float32)\n+    self.assertAllClose(expected, actual)\n+\n+  def test_multi_dim_with_query_mask(self):\n+    # Query tensor of shape [1, 2, 1]\n+    q = np.array([[[1.1], [-0.5]]], dtype=np.float32)\n+    # Value tensor of shape [1, 3, 1]\n+    v = np.array([[[1.6], [0.7], [-0.8]]], dtype=np.float32)\n+    # Query mask tensor of shape [1, 2]\n+    q_mask = np.array([[True, False]], dtype=np.bool_)\n+    # Value mask tensor of shape [1, 3]\n+    v_mask = np.array([[True, True, False]], dtype=np.bool_)\n+    attention_layer = keras.layers.AdditiveAttention()\n+    attention_layer.build(input_shape=([1, 1, 1], [1, 3, 1]))\n+    # Scale tensor of shape [1]\n+    attention_layer.scale = np.array([[[0.5]]], dtype=np.float32)\n+    actual = attention_layer([q, v], mask=[q_mask, v_mask])\n+\n+    # pylint:disable=line-too-long\n+    # Expected scores of shape [1, 2, 3]\n+    # scores = [[[0.5 * tanh(1.1 + 1.6), 0.5 * tanh(1.1 + 0.7), 0.5 * tanh(1.1 - 0.8)],\n+    #            [0.5 * tanh(-0.5 + 1.6), 0.5 * tanh(-0.5 + 0.7), 0.5 * tanh(-0.5 - 0.8)]]]\n+    #        = [[[0.49550372683, 0.47340300642, 0.14565630622],\n+    #            [0.40024951088, 0.09868766011, -0.43086157965]]]\n+    # Expected attention distribution = softmax(scores) with zeros in\n+    # positions where v_mask == False.\n+    # => attention_distribution000\n+    #        = exp(0.49550372683)/(exp(0.49550372683) + exp(0.47340300642))\n+    #        = 0.50552495521\n+    #    attention_distribution001\n+    #        = exp(0.47340300642)/(exp(0.49550372683) + exp(0.47340300642))\n+    #        = 0.49447504478\n+    #    attention_distribution002 = 0\n+    # => attention_distribution010\n+    #        = exp(0.40024951088)/(exp(0.40024951088) + exp(0.09868766011))\n+    #        = 0.57482427975\n+    #    attention_distribution011\n+    #        = exp(0.09868766011)/(exp(0.40024951088) + exp(0.09868766011))\n+    #        = 0.42517572025\n+    #    attention_distribution012 = 0\n+    #\n+    # Expected tensor of shape [1, 2, 1] with zeros where  q_mask == False.\n+    # expected000 = 0.50552495521 * 1.6 + 0.49447504478 * 0.7 - 0 * 0.8\n+    #             = 1.15497245968\n+    # expected000 = 0\n+    # pylint:enable=line-too-long\n+    expected = np.array([[[1.15497245968], [0.]]], dtype=np.float32)\n+    self.assertAllClose(expected, actual)\n+\n+  def test_serialization(self):\n+    # Test serialization with use_scale\n+    layer = keras.layers.AdditiveAttention(use_scale=True)\n+\n+    config = keras.layers.serialize(layer)\n+    new_layer = keras.layers.deserialize(config)\n+    self.assertEqual(new_layer.use_scale, True)\n+\n+    config = layer.get_config()\n+    new_layer = keras.layers.AdditiveAttention.from_config(config)\n+    self.assertEqual(new_layer.use_scale, True)\n+\n+  @testing_utils.enable_v2_dtype_behavior\n+  def test_mixed_float16_policy(self):\n+    # Test case for GitHub issue:\n+    # https://github.com/tensorflow/tensorflow/issues/46064\n+    with policy.policy_scope('mixed_float16'):\n+      q = tf.cast(tf.random.uniform((2, 3, 4), seed=1), 'float16')\n+      v = tf.cast(tf.random.uniform((2, 3, 4), seed=2), 'float16')\n+      k = tf.cast(tf.random.uniform((2, 3, 4), seed=3), 'float16')\n+      layer = keras.layers.AdditiveAttention(causal=True)\n+      _ = layer([q, v, k])\n+\n+\n+if __name__ == '__main__':\n+  tf.test.main()\n\n@@ -0,0 +1,195 @@\n+# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Attention layer that can be used in sequence DNN/CNN models.\n+\n+This file follows the terminology of https://arxiv.org/abs/1706.03762 Figure 2.\n+Attention is formed by three tensors: Query, Key and Value.\n+\"\"\"\n+# pylint: disable=g-classes-have-attributes,g-direct-tensorflow-import\n+\n+from keras.layers.attention.base_dense_attention import BaseDenseAttention\n+import tensorflow.compat.v2 as tf\n+\n+from tensorflow.python.util.tf_export import keras_export\n+\n+\n+@keras_export('keras.layers.Attention')\n+class Attention(BaseDenseAttention):\n+  \"\"\"Dot-product attention layer, a.k.a. Luong-style attention.\n+\n+  Inputs are `query` tensor of shape `[batch_size, Tq, dim]`, `value` tensor of\n+  shape `[batch_size, Tv, dim]` and `key` tensor of shape\n+  `[batch_size, Tv, dim]`. The calculation follows the steps:\n+\n+  1. Calculate scores with shape `[batch_size, Tq, Tv]` as a `query`-`key` dot\n+     product: `scores = tf.matmul(query, key, transpose_b=True)`.\n+  2. Use scores to calculate a distribution with shape\n+     `[batch_size, Tq, Tv]`: `distribution = tf.nn.softmax(scores)`.\n+  3. Use `distribution` to create a linear combination of `value` with\n+     shape `[batch_size, Tq, dim]`:\n+     `return tf.matmul(distribution, value)`.\n+\n+  Args:\n+    use_scale: If `True`, will create a scalar variable to scale the attention\n+      scores.\n+    causal: Boolean. Set to `True` for decoder self-attention. Adds a mask such\n+      that position `i` cannot attend to positions `j > i`. This prevents the\n+      flow of information from the future towards the past.\n+      Defaults to `False`.\n+    dropout: Float between 0 and 1. Fraction of the units to drop for the\n+      attention scores. Defaults to 0.0.\n+    score_mode: Function to use to compute attention scores, one of\n+      `{\"dot\", \"concat\"}`. `\"dot\"` refers to the dot product between the query\n+      and key vectors. `\"concat\"` refers to the hyperbolic tangent of the\n+      concatenation of the query and key vectors.\n+\n+  Call Args:\n+\n+    inputs: List of the following tensors:\n+      * query: Query `Tensor` of shape `[batch_size, Tq, dim]`.\n+      * value: Value `Tensor` of shape `[batch_size, Tv, dim]`.\n+      * key: Optional key `Tensor` of shape `[batch_size, Tv, dim]`. If not\n+        given, will use `value` for both `key` and `value`, which is the\n+        most common case.\n+    mask: List of the following tensors:\n+      * query_mask: A boolean mask `Tensor` of shape `[batch_size, Tq]`.\n+        If given, the output will be zero at the positions where\n+        `mask==False`.\n+      * value_mask: A boolean mask `Tensor` of shape `[batch_size, Tv]`.\n+        If given, will apply the mask such that values at positions where\n+        `mask==False` do not contribute to the result.\n+    return_attention_scores: bool, it `True`, returns the attention scores\n+      (after masking and softmax) as an additional output argument.\n+    training: Python boolean indicating whether the layer should behave in\n+      training mode (adding dropout) or in inference mode (no dropout).\n+\n+  Output:\n+\n+    Attention outputs of shape `[batch_size, Tq, dim]`.\n+    [Optional] Attention scores after masking and softmax with shape\n+      `[batch_size, Tq, Tv]`.\n+\n+  The meaning of `query`, `value` and `key` depend on the application. In the\n+  case of text similarity, for example, `query` is the sequence embeddings of\n+  the first piece of text and `value` is the sequence embeddings of the second\n+  piece of text. `key` is usually the same tensor as `value`.\n+\n+  Here is a code example for using `Attention` in a CNN+Attention network:\n+\n+  ```python\n+  # Variable-length int sequences.\n+  query_input = tf.keras.Input(shape=(None,), dtype='int32')\n+  value_input = tf.keras.Input(shape=(None,), dtype='int32')\n+\n+  # Embedding lookup.\n+  token_embedding = tf.keras.layers.Embedding(input_dim=1000, output_dim=64)\n+  # Query embeddings of shape [batch_size, Tq, dimension].\n+  query_embeddings = token_embedding(query_input)\n+  # Value embeddings of shape [batch_size, Tv, dimension].\n+  value_embeddings = token_embedding(value_input)\n+\n+  # CNN layer.\n+  cnn_layer = tf.keras.layers.Conv1D(\n+      filters=100,\n+      kernel_size=4,\n+      # Use 'same' padding so outputs have the same shape as inputs.\n+      padding='same')\n+  # Query encoding of shape [batch_size, Tq, filters].\n+  query_seq_encoding = cnn_layer(query_embeddings)\n+  # Value encoding of shape [batch_size, Tv, filters].\n+  value_seq_encoding = cnn_layer(value_embeddings)\n+\n+  # Query-value attention of shape [batch_size, Tq, filters].\n+  query_value_attention_seq = tf.keras.layers.Attention()(\n+      [query_seq_encoding, value_seq_encoding])\n+\n+  # Reduce over the sequence axis to produce encodings of shape\n+  # [batch_size, filters].\n+  query_encoding = tf.keras.layers.GlobalAveragePooling1D()(\n+      query_seq_encoding)\n+  query_value_attention = tf.keras.layers.GlobalAveragePooling1D()(\n+      query_value_attention_seq)\n+\n+  # Concatenate query and document encodings to produce a DNN input layer.\n+  input_layer = tf.keras.layers.Concatenate()(\n+      [query_encoding, query_value_attention])\n+\n+  # Add DNN layers, and create Model.\n+  # ...\n+  ```\n+  \"\"\"\n+\n+  def __init__(self, use_scale=False, score_mode='dot', **kwargs):\n+    super(Attention, self).__init__(**kwargs)\n+    self.use_scale = use_scale\n+    self.score_mode = score_mode\n+    if self.score_mode not in ['dot', 'concat']:\n+      raise ValueError(f'Received: score_mode={score_mode}. Acceptable values '\n+                       'are: [\"dot\", \"concat\"]')\n+\n+  def build(self, input_shape):\n+    \"\"\"Creates variable when `use_scale` is True or `score_mode` is `concat`.\"\"\"\n+    if self.use_scale:\n+      self.scale = self.add_weight(\n+          name='scale',\n+          shape=(),\n+          initializer='ones',\n+          dtype=self.dtype,\n+          trainable=True)\n+    else:\n+      self.scale = None\n+    if self.score_mode == 'concat':\n+      self.concat_score_weight = self.add_weight(\n+          name='concat_score_weight',\n+          shape=(),\n+          initializer='ones',\n+          dtype=self.dtype,\n+          trainable=True)\n+    else:\n+      self.concat_score_weight = None\n+    super(Attention, self).build(input_shape)\n+\n+  def _calculate_scores(self, query, key):\n+    \"\"\"Calculates attention scores as a query-key dot product.\n+\n+    Args:\n+      query: Query tensor of shape `[batch_size, Tq, dim]`.\n+      key: Key tensor of shape `[batch_size, Tv, dim]`.\n+    Returns:\n+      Tensor of shape `[batch_size, Tq, Tv]`.\n+    \"\"\"\n+    if self.score_mode == 'dot':\n+      scores = tf.matmul(query, key, transpose_b=True)\n+      if self.scale is not None:\n+        scores *= self.scale\n+    elif self.score_mode == 'concat':\n+      # Reshape tensors to enable broadcasting.\n+      # Reshape into [batch_size, Tq, 1, dim].\n+      q_reshaped = tf.expand_dims(query, axis=-2)\n+      # Reshape into [batch_size, 1, Tv, dim].\n+      k_reshaped = tf.expand_dims(key, axis=-3)\n+      if self.scale is not None:\n+        scores = self.concat_score_weight * tf.reduce_sum(\n+            tf.tanh(self.scale * (q_reshaped + k_reshaped)), axis=-1)\n+      else:\n+        scores = self.concat_score_weight * tf.reduce_sum(\n+            tf.tanh(q_reshaped + k_reshaped), axis=-1)\n+\n+    return scores\n+\n+  def get_config(self):\n+    config = {'use_scale': self.use_scale, 'score_mode': self.score_mode}\n+    base_config = super(Attention, self).get_config()\n+    return dict(list(base_config.items()) + list(config.items()))\n\n@@ -0,0 +1,455 @@\n+# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Tests Attention layer.\"\"\"\n+\n+from absl.testing import parameterized\n+import keras\n+from keras import combinations\n+from keras.layers import core\n+import numpy as np\n+import tensorflow.compat.v2 as tf\n+\n+\n+@combinations.generate(combinations.combine(mode=['graph', 'eager']))\n+class AttentionTest(tf.test.TestCase, parameterized.TestCase):\n+\n+  def test_calculate_scores_one_dim(self):\n+    # Query tensor of shape [1, 1, 1]\n+    q = np.array([[[1.1]]], dtype=np.float32)\n+    # Key tensor of shape [1, 1, 1]\n+    k = np.array([[[1.6]]], dtype=np.float32)\n+    attention_layer = keras.layers.Attention()\n+    attention_layer.build(input_shape=([1, 1, 1], [1, 1, 1]))\n+    actual = attention_layer._calculate_scores(query=q, key=k)\n+\n+    # Expected tensor of shape [1, 1, 1].\n+    # expected000 = 1.1*1.6 = 1.76\n+    expected = np.array([[[1.76]]], dtype=np.float32)\n+    self.assertAllClose(expected, actual)\n+\n+  def test_calculate_scores_multi_dim(self):\n+    # Query tensor of shape [1, 2, 4]\n+    q = np.array([[[1., 1.1, 1.2, 1.3], [2., 2.1, 2.2, 2.3]]], dtype=np.float32)\n+    # Key tensor of shape [1, 3, 4]\n+    k = np.array(\n+        [[[1.5, 1.6, 1.7, 1.8], [2.5, 2.6, 2.7, 2.8], [3.5, 3.6, 3.7, 3.8]]],\n+        dtype=np.float32)\n+    attention_layer = keras.layers.Attention()\n+    attention_layer.build(input_shape=([1, 2, 4], [1, 3, 4]))\n+    actual = attention_layer._calculate_scores(query=q, key=k)\n+\n+    # Expected tensor of shape [1, 2, 3].\n+    # expected000 = 1.*1.5+1.1*1.6+1.2*1.7+1.3*1.8 = 7.64\n+    # expected001 = 1.*2.5+1.1*2.6+1.2*2.7+1.3*2.8 = 12.24\n+    # expected002 = 1.*3.5+1.1*3.6+1.2*3.7+1.3*3.8 = 16.84\n+    # expected010 = 2.*1.5+2.1*1.6+2.2*1.7+2.3*1.8 = 14.24\n+    # expected011 = 2.*2.5+2.1*2.6+2.2*2.7+2.3*2.8 = 22.84\n+    # expected012 = 2.*3.5+2.1*3.6+2.2*3.7+2.3*3.8 = 31.44\n+    expected = np.array([[[7.64, 12.24, 16.84], [14.24, 22.84, 31.44]]],\n+                        dtype=np.float32)\n+    self.assertAllClose(expected, actual)\n+\n+  def test_calculate_scores_multi_dim_concat(self):\n+    # Query tensor of shape [1, 2, 4]\n+    q = np.array([[[1., 1.1, 1.2, 1.3], [2., 2.1, 2.2, 2.3]]], dtype=np.float32)\n+    # Key tensor of shape [1, 3, 4]\n+    k = np.array(\n+        [[[1.5, 1.6, 1.7, 1.8], [2.5, 2.6, 2.7, 2.8], [3.5, 3.6, 3.7, 3.8]]],\n+        dtype=np.float32)\n+    attention_layer = keras.layers.Attention(score_mode='concat')\n+    attention_layer.concat_score_weight = 1\n+    attention_layer.build(input_shape=([1, 2, 4], [1, 3, 4]))\n+    actual = keras.backend.get_value(\n+        attention_layer._calculate_scores(query=q, key=k))\n+\n+    # pylint:disable=line-too-long\n+    # expected000 = tanh(1.+1.5) + tanh(1.1+1.6) + tanh(1.2+1.7) + tanh(1.3+1.8) = 3.96753427840\n+    # expected001 = tanh(1.+2.5) + tanh(1.1+2.6) + tanh(1.2+2.7) + tanh(1.3+2.8) = 3.99558784825\n+    # expected002 = tanh(1.+3.5) + tanh(1.1+3.6) + tanh(1.2+3.7) + tanh(1.3+3.8) = 3.99940254147\n+    # expected010 = tanh(2.+1.5) + tanh(2.1+1.6) + tanh(2.2+1.7) + tanh(2.3+1.8) = 3.99558784825\n+    # expected011 = tanh(2.+2.5) + tanh(2.1+2.6) + tanh(2.2+2.7) + tanh(2.3+2.8) = 3.99940254147\n+    # expected012 = tanh(2.+3.5) + tanh(2.1+3.6) + tanh(2.2+3.7) + tanh(2.3+3.8) = 3.99991913657\n+    expected = np.array([[[3.96753427840, 3.99558784825, 3.99940254147],\n+                          [3.99558784825, 3.99940254147, 3.99991913657]]],\n+                        dtype=np.float32)\n+    self.assertAllClose(expected, actual)\n+\n+  def test_calculate_scores_one_dim_batch_size_two(self):\n+    # Query tensor of shape [2, 1, 1]\n+    q = np.array([[[1.1]], [[2.1]]], dtype=np.float32)\n+    # Key tensor of shape [2, 1, 1]\n+    k = np.array([[[1.6]], [[2.6]]], dtype=np.float32)\n+    attention_layer = keras.layers.Attention()\n+    attention_layer.build(input_shape=([2, 1, 1], [2, 1, 1]))\n+    actual = attention_layer._calculate_scores(query=q, key=k)\n+\n+    # Expected tensor of shape [2, 1, 1].\n+    # expected000 = 1.1*1.6 = 1.76\n+    # expected100 = 2.1*2.6 = 5.46\n+    expected = np.array([[[1.76]], [[5.46]]], dtype=np.float32)\n+    self.assertAllClose(expected, actual)\n+\n+  def test_calculate_scores_one_dim_with_scale(self):\n+    \"\"\"Tests that scores are multiplied by scale.\"\"\"\n+    # Query tensor of shape [1, 1, 1]\n+    q = np.array([[[1.1]]], dtype=np.float32)\n+    # Key tensor of shape [1, 1, 1]\n+    k = np.array([[[1.6]]], dtype=np.float32)\n+    attention_layer = keras.layers.Attention(use_scale=True)\n+    attention_layer.build(input_shape=([1, 1, 1], [1, 1, 1]))\n+    attention_layer.scale = -2.\n+    actual = attention_layer._calculate_scores(query=q, key=k)\n+\n+    # Expected tensor of shape [1, 1, 1].\n+    # expected000 = -2*1.1*1.6 = -3.52\n+    expected = np.array([[[-3.52]]], dtype=np.float32)\n+    self.assertAllClose(expected, actual)\n+\n+  def test_calculate_scores_one_dim_with_scale_concat(self):\n+    \"\"\"Tests that scores are multiplied by scale.\"\"\"\n+    # Query tensor of shape [1, 1, 1]\n+    q = np.array([[[1.1]]], dtype=np.float32)\n+    # Key tensor of shape [1, 1, 1]\n+    k = np.array([[[1.6]]], dtype=np.float32)\n+    attention_layer = keras.layers.Attention(\n+        use_scale=True, score_mode='concat')\n+    attention_layer.concat_score_weight = 1\n+    attention_layer.build(input_shape=([1, 1, 1], [1, 1, 1]))\n+    attention_layer.scale = 2.\n+    actual = keras.backend.get_value(\n+        attention_layer._calculate_scores(query=q, key=k))\n+\n+    # Expected tensor of shape [1, 1, 1].\n+    # expected000 = tanh(2*(1.1+1.6)) = 0.9999592018254402\n+    expected = np.array([[[0.999959202]]], dtype=np.float32)\n+    self.assertAllClose(expected, actual)\n+\n+  def test_shape(self):\n+    # Query tensor of shape [1, 2, 4]\n+    q = np.array([[[1., 1.1, 1.2, 1.3], [2., 2.1, 2.2, 2.3]]], dtype=np.float32)\n+    # Value tensor of shape [1, 3, 4]\n+    v = np.array(\n+        [[[1.5, 1.6, 1.7, 1.8], [2.5, 2.6, 2.7, 2.8], [3.5, 3.6, 3.7, 3.8]]],\n+        dtype=np.float32)\n+    # Value mask tensor of shape [1, 3]\n+    v_mask = np.array([[True, True, False]], dtype=np.bool_)\n+    attention_layer = keras.layers.Attention()\n+    actual = attention_layer([q, v], mask=[None, v_mask])\n+\n+    expected_shape = [1, 2, 4]\n+    self.assertAllEqual(expected_shape, tf.shape(actual))\n+\n+  def test_shape_concat(self):\n+    # Query tensor of shape [1, 2, 4]\n+    q = np.array([[[1., 1.1, 1.2, 1.3], [2., 2.1, 2.2, 2.3]]], dtype=np.float32)\n+    # Value tensor of shape [1, 3, 4]\n+    v = np.array(\n+        [[[1.5, 1.6, 1.7, 1.8], [2.5, 2.6, 2.7, 2.8], [3.5, 3.6, 3.7, 3.8]]],\n+        dtype=np.float32)\n+    # Value mask tensor of shape [1, 3]\n+    v_mask = np.array([[True, True, False]], dtype=np.bool_)\n+    attention_layer = keras.layers.Attention(score_mode='concat')\n+    attention_layer.concat_score_weight = 1\n+    actual = attention_layer([q, v], mask=[None, v_mask])\n+\n+    expected_shape = [1, 2, 4]\n+    self.assertAllEqual(expected_shape, tf.shape(actual))\n+\n+  def test_shape_with_key(self):\n+    # Query tensor of shape [1, 2, 4]\n+    q = np.array([[[1., 1.1, 1.2, 1.3], [2., 2.1, 2.2, 2.3]]], dtype=np.float32)\n+    # Value tensor of shape [1, 3, 4]\n+    v = np.array(\n+        [[[1.5, 1.6, 1.7, 1.8], [2.5, 2.6, 2.7, 2.8], [3.5, 3.6, 3.7, 3.8]]],\n+        dtype=np.float32)\n+    # Key tensor of shape [1, 3, 4]\n+    k = np.array(\n+        [[[1.5, 1.6, 1.7, 1.8], [2.5, 2.6, 2.7, 2.8], [3.5, 3.6, 3.7, 3.8]]],\n+        dtype=np.float32)\n+    # Value mask tensor of shape [1, 3]\n+    v_mask = np.array([[True, True, False]], dtype=np.bool_)\n+    attention_layer = keras.layers.Attention()\n+    actual = attention_layer([q, v, k], mask=[None, v_mask])\n+\n+    expected_shape = [1, 2, 4]\n+    self.assertAllEqual(expected_shape, tf.shape(actual))\n+\n+  def test_shape_with_key_concat(self):\n+    # Query tensor of shape [1, 2, 4]\n+    q = np.array([[[1., 1.1, 1.2, 1.3], [2., 2.1, 2.2, 2.3]]], dtype=np.float32)\n+    # Value tensor of shape [1, 3, 4]\n+    v = np.array(\n+        [[[1.5, 1.6, 1.7, 1.8], [2.5, 2.6, 2.7, 2.8], [3.5, 3.6, 3.7, 3.8]]],\n+        dtype=np.float32)\n+    # Key tensor of shape [1, 3, 4]\n+    k = np.array(\n+        [[[1.5, 1.6, 1.7, 1.8], [2.5, 2.6, 2.7, 2.8], [3.5, 3.6, 3.7, 3.8]]],\n+        dtype=np.float32)\n+    # Value mask tensor of shape [1, 3]\n+    v_mask = np.array([[True, True, False]], dtype=np.bool_)\n+    attention_layer = keras.layers.Attention(score_mode='concat')\n+    attention_layer.concat_score_weight = 1\n+    actual = attention_layer([q, v, k], mask=[None, v_mask])\n+\n+    expected_shape = [1, 2, 4]\n+    self.assertAllEqual(expected_shape, tf.shape(actual))\n+\n+  def test_multi_dim(self):\n+    # Query tensor of shape [1, 1, 1]\n+    q = np.array([[[1.1]]], dtype=np.float32)\n+    # Value tensor of shape [1, 3, 1]\n+    v = np.array([[[1.6], [0.7], [-0.8]]], dtype=np.float32)\n+    # Value mask tensor of shape [1, 3]\n+    v_mask = np.array([[True, True, False]], dtype=np.bool_)\n+    attention_layer = keras.layers.Attention()\n+    actual = attention_layer([q, v], mask=[None, v_mask])\n+\n+    # Expected scores of shape [1, 1, 3]\n+    # scores = [[[1.1*1.6, 1.1*0.7, -1.1*0.8]]] = [[[1.76, 0.77, -0.88]]]\n+    # Expected attention distribution = softmax(scores) with zeros in\n+    # positions where v_mask == False.\n+    # => attention_distribution000 = exp(1.76)/(exp(1.76) + exp(0.77))\n+    #                              = 0.72908792234\n+    #    attention_distribution001 = exp(0.77)/(exp(1.76) + exp(0.77))\n+    #                              = 0.27091207765\n+    #    attention_distribution002 = 0\n+    #\n+    # Expected tensor of shape [1, 1, 1].\n+    # expected000 = 0.72908792234 * 1.6 + 0.27091207765 * 0.7 - 0 * 0.8\n+    #             = 1.3561791301\n+    expected = np.array([[[1.3561791301]]], dtype=np.float32)\n+    self.assertAllClose(expected, actual)\n+\n+  def test_multi_dim_with_key(self):\n+    # Query tensor of shape [1, 1, 1]\n+    q = np.array([[[1.1]]], dtype=np.float32)\n+    # Value tensor of shape [1, 3, 1]\n+    v = np.array([[[0.5], [0.8], [-0.3]]], dtype=np.float32)\n+    # Key tensor of shape [1, 3, 1]\n+    k = np.array([[[1.6], [0.7], [-0.8]]], dtype=np.float32)\n+    # Value mask tensor of shape [1, 3]\n+    v_mask = np.array([[True, True, False]], dtype=np.bool_)\n+    attention_layer = keras.layers.Attention()\n+    actual = attention_layer([q, v, k], mask=[None, v_mask])\n+\n+    # Expected scores of shape [1, 1, 3]\n+    # scores = [[[1.1*1.6, 1.1*0.7, -1.1*0.8]]] = [[[1.76, 0.77, -0.88]]]\n+    # Expected attention distribution = softmax(scores) with zeros in\n+    # positions where v_mask == False.\n+    # => attention_distribution000 = exp(1.76)/(exp(1.76) + exp(0.77))\n+    #                              = 0.72908792234\n+    #    attention_distribution001 = exp(0.77)/(exp(1.76) + exp(0.77))\n+    #                              = 0.27091207765\n+    #    attention_distribution002 = 0\n+    #\n+    # Expected tensor of shape [1, 1, 1].\n+    # expected000 = 0.72908792234 * 0.5 + 0.27091207765 * 0.8 - 0 * 0.3\n+    #             = 0.58127362329\n+    expected = np.array([[[0.58127362329]]], dtype=np.float32)\n+    self.assertAllClose(expected, actual)\n+\n+  @parameterized.named_parameters(\n+      ('', False),\n+      ('return_attention_scores', True),\n+  )\n+  def test_multi_dim_with_query_mask(self, return_attention_scores):\n+    # Query tensor of shape [1, 2, 1]\n+    q = np.array([[[1.1], [-0.5]]], dtype=np.float32)\n+    # Value tensor of shape [1, 3, 1]\n+    v = np.array([[[1.6], [0.7], [-0.8]]], dtype=np.float32)\n+    # Query mask tensor of shape [1, 2]\n+    q_mask = np.array([[True, False]], dtype=np.bool_)\n+    # Value mask tensor of shape [1, 3]\n+    v_mask = np.array([[True, True, False]], dtype=np.bool_)\n+    attention_layer = keras.layers.Attention()\n+    if return_attention_scores:\n+      actual, actual_scores = attention_layer(\n+          [q, v],\n+          mask=[q_mask, v_mask],\n+          return_attention_scores=return_attention_scores)\n+    else:\n+      actual = attention_layer([q, v],\n+                               mask=[q_mask, v_mask],\n+                               return_attention_scores=return_attention_scores)\n+\n+    # Expected scores of shape [1, 2, 3]\n+    # scores = [[[1.1*1.6, 1.1*0.7, -1.1*0.8], [-0.5*1.6, -0.5*0.7, 0.5*0.8]]]\n+    #        = [[[1.76, 0.77, -0.88], [-0.8, -0.35, 0.4]]]\n+    # Expected attention distribution = softmax(scores) with zeros in\n+    # positions where v_mask == False.\n+    # => attention_distribution000 = exp(1.76)/(exp(1.76) + exp(0.77))\n+    #                              = 0.72908792234\n+    #    attention_distribution001 = exp(0.77)/(exp(1.76) + exp(0.77))\n+    #                              = 0.27091207765\n+    #    attention_distribution002 = 0\n+    # => attention_distribution010 = exp(-0.8)/(exp(-0.8) + exp(-0.35))\n+    #                              = 0.38936076605\n+    #    attention_distribution011 = exp(-0.35)/(exp(-0.8) + exp(-0.35))\n+    #                              = 0.61063923394\n+    #    attention_distribution012 = 0\n+    if return_attention_scores:\n+      expected_scores = np.array([[[0.72908792234, 0.27091207765, 0.],\n+                                   [0.38936076605, 0.61063923394, 0.]]],\n+                                 dtype=np.float32)\n+      self.assertAllClose(expected_scores, actual_scores)\n+    # Expected tensor of shape [1, 2, 1] with zeros where  q_mask == False.\n+    # expected000 = 0.72908792234 * 1.6 + 0.27091207765 * 0.7 - 0 * 0.8\n+    #             = 1.3561791301\n+    # expected000 = 0\n+    expected = np.array([[[1.3561791301], [0.]]], dtype=np.float32)\n+    self.assertAllClose(expected, actual)\n+\n+  def test_scale_none(self):\n+    \"\"\"Tests that scale is None by default.\"\"\"\n+    attention_layer = keras.layers.Attention()\n+    attention_layer.build(input_shape=([1, 1, 1], [1, 1, 1]))\n+    self.assertIsNone(attention_layer.scale)\n+\n+  def test_scale_init_eager(self):\n+    \"\"\"Tests that scale initializes to 1 when use_scale=True.\"\"\"\n+    if not tf.executing_eagerly():\n+      self.skipTest('Only run in eager mode')\n+    attention_layer = keras.layers.Attention(use_scale=True)\n+    attention_layer.build(input_shape=([1, 1, 1], [1, 1, 1]))\n+    self.assertAllClose(1., attention_layer.scale.value())\n+\n+  def test_scale_init_graph(self):\n+    \"\"\"Tests that scale initializes to 1 when use_scale=True.\"\"\"\n+    with self.cached_session() as sess:\n+      attention_layer = keras.layers.Attention(use_scale=True)\n+      attention_layer.build(input_shape=([1, 1, 1], [1, 1, 1]))\n+      sess.run(attention_layer.scale.initializer)\n+      self.assertAllClose(1., attention_layer.scale.value())\n+\n+  @parameterized.named_parameters(\n+      ('', False),\n+      ('return_attention_scores', True),\n+  )\n+  def test_self_attention_causal(self, return_attention_scores):\n+    # Query-value tensor of shape [1, 3, 1]\n+    q = np.array([[[0.5], [0.8], [-0.3]]], dtype=np.float32)\n+    attention_layer = keras.layers.Attention(causal=True)\n+    if return_attention_scores:\n+      actual, actual_scores = attention_layer(\n+          [q, q], return_attention_scores=return_attention_scores)\n+    else:\n+      actual = attention_layer([q, q],\n+                               return_attention_scores=return_attention_scores)\n+\n+    # Expected scores of shape [1, 3, 3]\n+    # scores = [[0.25, 0.4, -0.15], [0.4, 0.64, -0.24], [-0.15, -0.24, 0.09]]\n+    # Expected attention distribution = softmax(scores) lower triangular\n+    # => attention_distribution00 = [1., 0., 0.]\n+    #    attention_distribution01\n+    #      = [exp(0.4), exp(0.64), 0.] / (exp(0.4) + exp(0.64))\n+    #      = [0.44028635073, 0.55971364926, 0.]\n+    #    attention_distribution02\n+    #      = [exp(-0.15), exp(-0.24), exp(0.09)]\n+    #        / (exp(-0.15) + exp(-0.24) + exp(0.09))\n+    #      = [0.31395396638, 0.28693232061, 0.399113713]\n+    if return_attention_scores:\n+      expected_scores = np.array(\n+          [[[1., 0., 0.], [0.44028635073, 0.55971364926, 0.],\n+            [0.31395396638, 0.28693232061, 0.399113713]]],\n+          dtype=np.float32)\n+      self.assertAllClose(expected_scores, actual_scores)\n+    # Expected tensor of shape [1, 3, 1].\n+    # expected000 = 0.5\n+    # expected010 = 0.44028635073 * 0.5 + 0.55971364926 * 0.8\n+    #             = 0.66791409477\n+    # expected020 = 0.31395396638 * 0.5 +0.28693232061 * 0.8 -0.399113713 * 0.3\n+    #             = 0.26678872577\n+    expected = np.array([[[0.5], [0.66791409477], [0.26678872577]]],\n+                        dtype=np.float32)\n+    self.assertAllClose(expected, actual)\n+\n+  def test_inputs_not_list(self):\n+    attention_layer = keras.layers.Attention()\n+    q = np.array([[[1.1]]], dtype=np.float32)\n+    with self.assertRaisesRegex(\n+        ValueError, 'Attention layer must be called on a list of inputs'):\n+      attention_layer(q)\n+\n+  def test_inputs_too_short(self):\n+    attention_layer = keras.layers.Attention()\n+    q = np.array([[[1.1]]], dtype=np.float32)\n+    with self.assertRaisesRegex(\n+        ValueError, 'Attention layer accepts inputs list of length 2 or 3'):\n+      attention_layer([q])\n+\n+  def test_inputs_too_long(self):\n+    attention_layer = keras.layers.Attention()\n+    q = np.array([[[1.1]]], dtype=np.float32)\n+    with self.assertRaisesRegex(\n+        ValueError, 'Attention layer accepts inputs list of length 2 or 3'):\n+      attention_layer([q, q, q, q])\n+\n+  def test_mask_not_list(self):\n+    attention_layer = keras.layers.Attention()\n+    q = np.array([[[1.1]]], dtype=np.float32)\n+    mask = np.array([[True]], dtype=np.bool_)\n+    with self.assertRaisesRegex(ValueError,\n+                                'Attention layer mask must be a list'):\n+      attention_layer([q, q], mask=mask)\n+\n+  def test_mask_too_short(self):\n+    attention_layer = keras.layers.Attention()\n+    q = np.array([[[1.1]]], dtype=np.float32)\n+    mask = np.array([[True]], dtype=np.bool_)\n+    with self.assertRaisesRegex(\n+        ValueError, 'Attention layer mask must be a list of length 2'):\n+      attention_layer([q, q], mask=[mask])\n+\n+  def test_mask_too_long(self):\n+    attention_layer = keras.layers.Attention()\n+    q = np.array([[[1.1]]], dtype=np.float32)\n+    mask = np.array([[True]], dtype=np.bool_)\n+    with self.assertRaisesRegex(\n+        ValueError, 'Attention layer mask must be a list of length 2'):\n+      attention_layer([q, q], mask=[mask, mask, mask])\n+\n+  def test_override_mask(self):\n+    attention_layer = keras.layers.Attention()\n+    q = core.Masking()(np.array([[[1.1]]], dtype=np.float32))\n+    mask = np.array([[False]], dtype=np.bool_)\n+    actual = attention_layer([q, q], mask=[mask, mask])\n+    self.assertAllClose([[[0]]], actual)\n+\n+  def test_implicit_mask(self):\n+    attention_layer = keras.layers.Attention()\n+    q = core.Masking(1.1)(np.array([[[1.1], [1]]], dtype=np.float32))\n+    v = core.Masking(1.2)(np.array([[[1.2], [1]]], dtype=np.float32))\n+    actual = attention_layer([q, v])\n+    self.assertAllClose([[[0], [1]]], actual)\n+\n+  @parameterized.named_parameters(\n+      ('', False),\n+      ('use_scale', True),\n+  )\n+  def test_serialization(self, use_scale):\n+    # Test serialization with use_scale\n+    layer = keras.layers.Attention(use_scale=use_scale)\n+\n+    config = keras.layers.serialize(layer)\n+    new_layer = keras.layers.deserialize(config)\n+    self.assertEqual(new_layer.use_scale, use_scale)\n+\n+    config = layer.get_config()\n+    new_layer = keras.layers.Attention.from_config(config)\n+    self.assertEqual(new_layer.use_scale, use_scale)\n+\n+\n+if __name__ == '__main__':\n+  tf.test.main()\n\n@@ -0,0 +1,233 @@\n+# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Base class for attention layers that can be used in sequence DNN/CNN models.\n+\n+This file follows the terminology of https://arxiv.org/abs/1706.03762 Figure 2.\n+Attention is formed by three tensors: Query, Key and Value.\n+\"\"\"\n+# pylint: disable=g-classes-have-attributes\n+\n+from keras import backend\n+from keras.engine import base_layer\n+from keras.utils import control_flow_util\n+import tensorflow.compat.v2 as tf\n+\n+\n+class BaseDenseAttention(base_layer.BaseRandomLayer):\n+  \"\"\"Base Attention class for Dense networks.\n+\n+  This class is suitable for Dense or CNN networks, and not for RNN networks.\n+\n+  Implementations of attention mechanisms should inherit from this class, and\n+  reuse the `apply_attention_scores()` method.\n+\n+  Args:\n+    causal: Boolean. Set to `True` for decoder self-attention. Adds a mask such\n+      that position `i` cannot attend to positions `j > i`. This prevents the\n+      flow of information from the future towards the past.\n+    dropout: Float between 0 and 1. Fraction of the units to drop for the\n+      attention scores.\n+\n+  Call Args:\n+\n+    inputs: List of the following tensors:\n+      * query: Query `Tensor` of shape `[batch_size, Tq, dim]`.\n+      * value: Value `Tensor` of shape `[batch_size, Tv, dim]`.\n+      * key: Optional key `Tensor` of shape `[batch_size, Tv, dim]`. If not\n+        given, will use `value` for both `key` and `value`, which is the\n+        most common case.\n+    mask: List of the following tensors:\n+      * query_mask: A boolean mask `Tensor` of shape `[batch_size, Tq]`.\n+        If given, the output will be zero at the positions where\n+        `mask==False`.\n+      * value_mask: A boolean mask `Tensor` of shape `[batch_size, Tv]`.\n+        If given, will apply the mask such that values at positions where\n+        `mask==False` do not contribute to the result.\n+    training: Python boolean indicating whether the layer should behave in\n+      training mode (adding dropout) or in inference mode (no dropout).\n+    return_attention_scores: bool, if `True`, returns the attention scores\n+      (after masking and softmax) as an additional output argument.\n+\n+  Output:\n+\n+    Attention outputs of shape `[batch_size, Tq, dim]`.\n+    [Optional] Attention scores after masking and softmax with shape\n+      `[batch_size, Tq, Tv]`.\n+  \"\"\"\n+\n+  def __init__(self, causal=False, dropout=0.0, **kwargs):\n+    super(BaseDenseAttention, self).__init__(**kwargs)\n+    self.causal = causal\n+    self.dropout = dropout\n+    self.supports_masking = True\n+\n+  def _calculate_scores(self, query, key):\n+    \"\"\"Calculates attention scores.\n+\n+    Args:\n+      query: Query tensor of shape `[batch_size, Tq, dim]`.\n+      key: Key tensor of shape `[batch_size, Tv, dim]`.\n+\n+    Returns:\n+      Tensor of shape `[batch_size, Tq, Tv]`.\n+    \"\"\"\n+    return NotImplementedError\n+\n+  def _apply_scores(self, scores, value, scores_mask=None, training=None):\n+    \"\"\"Applies attention scores to the given value tensor.\n+\n+    To use this method in your attention layer, follow the steps:\n+\n+    * Use `query` tensor of shape `[batch_size, Tq]` and `key` tensor of shape\n+      `[batch_size, Tv]` to calculate the attention `scores`.\n+    * Pass `scores` and `value` tensors to this method. The method applies\n+      `scores_mask`, calculates `attention_distribution = softmax(scores)`, then\n+      returns `matmul(attention_distribution, value).\n+    * Apply `query_mask` and return the result.\n+\n+    Args:\n+      scores: Scores float tensor of shape `[batch_size, Tq, Tv]`.\n+      value: Value tensor of shape `[batch_size, Tv, dim]`.\n+      scores_mask: A boolean mask `Tensor` of shape `[batch_size, 1, Tv]` or\n+        `[batch_size, Tq, Tv]`. If given, scores at positions where\n+        `scores_mask==False` do not contribute to the result. It must contain\n+        at least one `True` value in each line along the last dimension.\n+      training: Python boolean indicating whether the layer should behave in\n+        training mode (adding dropout) or in inference mode (no dropout).\n+\n+    Returns:\n+      Tensor of shape `[batch_size, Tq, dim]`.\n+      Attention scores after masking and softmax with shape\n+        `[batch_size, Tq, Tv]`.\n+    \"\"\"\n+    if scores_mask is not None:\n+      padding_mask = tf.logical_not(scores_mask)\n+      # Bias so padding positions do not contribute to attention distribution.\n+      # Note 65504. is the max float16 value.\n+      if scores.dtype is tf.float16:\n+        scores -= 65504. * tf.cast(padding_mask, dtype=scores.dtype)\n+      else:\n+        scores -= 1.e9 * tf.cast(padding_mask, dtype=scores.dtype)\n+    if training is None:\n+      training = backend.learning_phase()\n+    weights = tf.nn.softmax(scores)\n+\n+    def dropped_weights():\n+      return self._random_generator.dropout(weights, rate=self.dropout)\n+\n+    weights = control_flow_util.smart_cond(training, dropped_weights,\n+                                           lambda: tf.identity(weights))\n+    return tf.matmul(weights, value), weights\n+\n+  # TODO(b/125916026): Consider exposing a __call__ method with named args.\n+  def call(self,\n+           inputs,\n+           mask=None,\n+           training=None,\n+           return_attention_scores=False):\n+    self._validate_call_args(inputs=inputs, mask=mask)\n+    q = inputs[0]\n+    v = inputs[1]\n+    k = inputs[2] if len(inputs) > 2 else v\n+    q_mask = mask[0] if mask else None\n+    v_mask = mask[1] if mask else None\n+    scores = self._calculate_scores(query=q, key=k)\n+    if v_mask is not None:\n+      # Mask of shape [batch_size, 1, Tv].\n+      v_mask = tf.expand_dims(v_mask, axis=-2)\n+    if self.causal:\n+      # Creates a lower triangular mask, so position i cannot attend to\n+      # positions j>i. This prevents the flow of information from the future\n+      # into the past.\n+      scores_shape = tf.shape(scores)\n+      # causal_mask_shape = [1, Tq, Tv].\n+      causal_mask_shape = tf.concat(\n+          [tf.ones_like(scores_shape[:-2]), scores_shape[-2:]],\n+          axis=0)\n+      causal_mask = _lower_triangular_mask(causal_mask_shape)\n+    else:\n+      causal_mask = None\n+    scores_mask = _merge_masks(v_mask, causal_mask)\n+    result, attention_scores = self._apply_scores(\n+        scores=scores, value=v, scores_mask=scores_mask, training=training)\n+    if q_mask is not None:\n+      # Mask of shape [batch_size, Tq, 1].\n+      q_mask = tf.expand_dims(q_mask, axis=-1)\n+      result *= tf.cast(q_mask, dtype=result.dtype)\n+    if return_attention_scores:\n+      return result, attention_scores\n+    return result\n+\n+  def compute_mask(self, inputs, mask=None):\n+    self._validate_call_args(inputs=inputs, mask=mask)\n+    if mask:\n+      q_mask = mask[0]\n+      if q_mask is None:\n+        return None\n+      return tf.convert_to_tensor(q_mask)\n+    return None\n+\n+  def compute_output_shape(self, input_shape):\n+    # return_attention_scores argument of BaseDenseAttention.call method\n+    # is ignored. Output shape of attention_scores cannot be returned.\n+    return tf.TensorShape(input_shape[0])\n+\n+  def _validate_call_args(self, inputs, mask):\n+    \"\"\"Validates arguments of the call method.\"\"\"\n+    class_name = self.__class__.__name__\n+    if not isinstance(inputs, list):\n+      raise ValueError(\n+          f'{class_name} layer must be called on a list of inputs, '\n+          'namely [query, value] or [query, value, key]. '\n+          f'Received: {inputs}.')\n+    if len(inputs) < 2 or len(inputs) > 3:\n+      raise ValueError(\n+          f'{class_name} layer accepts inputs list of length 2 or 3, '\n+          'namely [query, value] or [query, value, key]. '\n+          f'Received length: {len(inputs)}.')\n+    if mask:\n+      if not isinstance(mask, list):\n+        raise ValueError(\n+            f'{class_name} layer mask must be a list, '\n+            f'namely [query_mask, value_mask]. Received: {mask}.')\n+      if len(mask) < 2 or len(mask) > len(inputs):\n+        raise ValueError(\n+            f'{class_name} layer mask must be a list of length 2, '\n+            f'namely [query_mask, value_mask]. Received length: {len(mask)}.')\n+\n+  def get_config(self):\n+    config = {\n+        'causal': self.causal,\n+        'dropout': self.dropout,\n+    }\n+    base_config = super(BaseDenseAttention, self).get_config()\n+    return dict(list(base_config.items()) + list(config.items()))\n+\n+\n+def _lower_triangular_mask(shape):\n+  \"\"\"Creates a lower-triangular boolean mask over the last 2 dimensions.\"\"\"\n+  row_index = tf.cumsum(\n+      tf.ones(shape=shape, dtype=tf.int32), axis=-2)\n+  col_index = tf.cumsum(\n+      tf.ones(shape=shape, dtype=tf.int32), axis=-1)\n+  return tf.greater_equal(row_index, col_index)\n+\n+\n+def _merge_masks(x, y):\n+  if x is None:\n+    return y\n+  if y is None:\n+    return x\n+  return tf.logical_and(x, y)\n\n@@ -0,0 +1,176 @@\n+# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Tests BaseDenseAttention layer.\"\"\"\n+\n+from absl.testing import parameterized\n+from keras import combinations\n+from keras.layers.attention.base_dense_attention import _lower_triangular_mask\n+from keras.layers.attention.base_dense_attention import BaseDenseAttention\n+import numpy as np\n+import tensorflow.compat.v2 as tf\n+\n+\n+@combinations.generate(combinations.combine(mode=['graph', 'eager']))\n+class BaseDenseAttentionTest(tf.test.TestCase, parameterized.TestCase):\n+\n+  def test_one_dim_with_mask(self):\n+    # Scores tensor of shape [1, 1, 1]\n+    scores = np.array([[[1.1]]], dtype=np.float32)\n+    # Value tensor of shape [1, 1, 1]\n+    v = np.array([[[1.6]]], dtype=np.float32)\n+    # Scores mask tensor of shape [1, 1, 1]\n+    scores_mask = np.array([[[True]]], dtype=np.bool_)\n+    actual, actual_scores = BaseDenseAttention()._apply_scores(\n+        scores=scores, value=v, scores_mask=scores_mask)\n+\n+    # Expected softmax_scores = [[[1]]]\n+    expected_scores = np.array([[[1.]]], dtype=np.float32)\n+    self.assertAllClose(expected_scores, actual_scores)\n+    # Expected tensor of shape [1, 1, 1].\n+    # expected000 = softmax_scores[0, 0] * 1.6 = 1.6\n+    expected = np.array([[[1.6]]], dtype=np.float32)\n+    self.assertAllClose(expected, actual)\n+\n+  def test_one_dim_no_mask(self):\n+    # Scores tensor of shape [1, 1, 1]\n+    scores = np.array([[[1.1]]], dtype=np.float32)\n+    # Value tensor of shape [1, 1, 1]\n+    v = np.array([[[1.6]]], dtype=np.float32)\n+    actual, actual_scores = BaseDenseAttention()._apply_scores(\n+        scores=scores, value=v)\n+\n+    # Expected softmax_scores = [[[1]]]\n+    expected_scores = np.array([[[1.]]], dtype=np.float32)\n+    self.assertAllClose(expected_scores, actual_scores)\n+    # Expected tensor of shape [1, 1, 1].\n+    # expected000 = softmax_scores[0, 0] * 1.6 = 1.6\n+    expected = np.array([[[1.6]]], dtype=np.float32)\n+    self.assertAllClose(expected, actual)\n+\n+  def test_multi_dim_with_mask(self):\n+    # Scores tensor of shape [1, 1, 3]\n+    scores = np.array([[[1., 0., 1.]]], dtype=np.float32)\n+    # Value tensor of shape [1, 3, 1]\n+    v = np.array([[[1.6], [0.7], [-0.8]]], dtype=np.float32)\n+    # Scores mask tensor of shape [1, 1, 3]\n+    scores_mask = np.array([[[True, True, False]]], dtype=np.bool_)\n+    actual, actual_scores = BaseDenseAttention()._apply_scores(\n+        scores=scores, value=v, scores_mask=scores_mask)\n+\n+    # Expected softmax scores = softmax(scores) with zeros in positions where\n+    # v_mask == False.\n+    # => softmax_scores000 = exp(1)/(exp(1) + exp(0)) = 0.73105857863\n+    #    softmax_scores001 = exp(0)/(exp(1) + exp(0)) = 0.26894142137\n+    #    softmax_scores002 = 0\n+    expected_scores = np.array([[[0.73105857863, 0.26894142137, 0.]]],\n+                               dtype=np.float32)\n+    self.assertAllClose(expected_scores, actual_scores)\n+    # Expected tensor of shape [1, 1, 1].\n+    # expected000 = 0.73105857863 * 1.6 + 0.26894142137 * 0.7 - 0 * 0.8\n+    #             = 1.35795272077\n+    expected = np.array([[[1.35795272077]]], dtype=np.float32)\n+    self.assertAllClose(expected, actual)\n+\n+  def test_multi_dim_no_mask(self):\n+    # Scores tensor of shape [1, 1, 3]\n+    scores = np.array([[[1., 0., 1.]]], dtype=np.float32)\n+    # Value tensor of shape [1, 3, 1]\n+    v = np.array([[[1.6], [0.7], [-0.8]]], dtype=np.float32)\n+    actual, actual_scores = BaseDenseAttention()._apply_scores(\n+        scores=scores, value=v)\n+\n+    # Expected softmax_scores = softmax(scores).\n+    # => softmax_scores000 = exp(1)/(exp(1) + exp(0) + exp(1))\n+    #                      = 0.42231879825\n+    #    softmax_scores001 = exp(0)/(exp(1) + exp(0) + exp(1))\n+    #                      = 0.15536240349\n+    #    softmax_scores002 = exp(1)/(exp(1) + exp(0) + exp(1))\n+    #                      = 0.42231879825\n+    expected_scores = np.array(\n+        [[[0.42231879825, 0.15536240349, 0.42231879825]]], dtype=np.float32)\n+    self.assertAllClose(expected_scores, actual_scores)\n+    # Expected tensor of shape [1, 1, 1].\n+    # expected000 = 0.42231879825 * 1.6 + 0.15536240349 * 0.7\n+    #               - 0.42231879825 * 0.8\n+    #             = 0.44660872104\n+    expected = np.array([[[0.44660872104]]], dtype=np.float32)\n+    self.assertAllClose(expected, actual)\n+\n+  def test_one_dim_batch_size_two(self):\n+    # Scores tensor of shape [2, 1, 1]\n+    scores = np.array([[[1.1]], [[2.1]]], dtype=np.float32)\n+    # Value tensor of shape [2, 1, 1]\n+    v = np.array([[[1.6]], [[2.6]]], dtype=np.float32)\n+    # Scpres mask tensor of shape [2, 1, 1]\n+    scores_mask = np.array([[[True]], [[True]]], dtype=np.bool_)\n+    actual, actual_scores = BaseDenseAttention()._apply_scores(\n+        scores=scores, value=v, scores_mask=scores_mask)\n+\n+    # Expected softmax_scores = [[[1]], [[1]]]\n+    expected_scores = np.array([[[1.]], [[1.]]], dtype=np.float32)\n+    self.assertAllClose(expected_scores, actual_scores)\n+    # Expected tensor of shape [2, 1, 1].\n+    # expected000 = softmax_scores[0, 0] * 1.6 = 1.6\n+    # expected100 = softmax_scores[1, 0] * 2.6 = 2.6\n+    expected = np.array([[[1.6]], [[2.6]]], dtype=np.float32)\n+    self.assertAllClose(expected, actual)\n+\n+  def test_shape_with_dropout(self):\n+    # scores: Scores float tensor of shape `[batch_size, tq, tv]`.\n+    # value: Value tensor of shape `[batch_size, tv, dim]`.\n+    batch_size = 4\n+    tq = 5\n+    tv = 6\n+    dim = 7\n+    scores = np.ones((batch_size, tq, tv))\n+    value = np.ones((batch_size, tv, dim))\n+    actual, actual_scores = BaseDenseAttention(\n+        dropout=0.1)._apply_scores(\n+            scores=scores, value=value, training=False)\n+\n+    # Expected Tensor of shape `[batch_size, tq, tv]`.\n+    expected_scores_shape = [batch_size, tq, tv]\n+    self.assertAllEqual(expected_scores_shape, tf.shape(actual_scores))\n+    # Expected Tensor of shape `[batch_size, tq, dim]`.\n+    expected_shape = [batch_size, tq, dim]\n+    self.assertAllEqual(expected_shape, tf.shape(actual))\n+\n+\n+@combinations.generate(combinations.combine(mode=['graph', 'eager']))\n+class LowerTriangularMaskTest(tf.test.TestCase, parameterized.TestCase):\n+\n+  def test_square_shape(self):\n+    actual = _lower_triangular_mask([3, 3])\n+    expected = np.array(\n+        [[True, False, False], [True, True, False], [True, True, True]],\n+        dtype=np.bool_)\n+    self.assertAllEqual(expected, actual)\n+\n+  def test_orthogonal_shape(self):\n+    actual = _lower_triangular_mask([3, 2])\n+    expected = np.array([[True, False], [True, True], [True, True]],\n+                        dtype=np.bool_)\n+    self.assertAllEqual(expected, actual)\n+\n+  def test_three_dim(self):\n+    actual = _lower_triangular_mask([1, 3, 3])\n+    expected = np.array(\n+        [[[True, False, False], [True, True, False], [True, True, True]]],\n+        dtype=np.bool_)\n+    self.assertAllEqual(expected, actual)\n+\n+\n+if __name__ == '__main__':\n+  tf.test.main()\n\n@@ -13,16 +13,13 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n # ==============================================================================\n-\"\"\"Keras-based attention layer.\"\"\"\n-\n-import tensorflow.compat.v2 as tf\n-# pylint: disable=g-classes-have-attributes\n+\"\"\"Keras-based multi-head attention layer.\"\"\"\n+# pylint: disable=g-classes-have-attributes,g-direct-tensorflow-import\n \n import collections\n import math\n import string\n \n-import numpy as np\n from keras import constraints\n from keras import initializers\n from keras import regularizers\n@@ -31,6 +28,9 @@ from keras.layers import advanced_activations\n from keras.layers import einsum_dense\n from keras.layers import regularization\n from keras.utils import tf_utils\n+import numpy as np\n+import tensorflow.compat.v2 as tf\n+\n from tensorflow.python.platform import tf_logging as logging\n from tensorflow.python.util.tf_export import keras_export\n \n@@ -469,8 +469,7 @@ class MultiHeadAttention(Layer):\n \n     # Take the dot product between \"query\" and \"key\" to get the raw\n     # attention scores.\n-    attention_scores = tf.einsum(self._dot_product_equation, key,\n-                                               query)\n+    attention_scores = tf.einsum(self._dot_product_equation, key, query)\n \n     attention_scores = self._masked_softmax(attention_scores, attention_mask)\n \n\n@@ -12,17 +12,13 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n # ==============================================================================\n-\"\"\"Tests for the attention layer.\"\"\"\n-\n-import tensorflow.compat.v2 as tf\n+\"\"\"Tests for the MultiHeadAttention layer.\"\"\"\n \n from absl.testing import parameterized\n-\n-import numpy as np\n-\n import keras\n from keras import keras_parameterized\n-from keras.layers import multi_head_attention\n+import numpy as np\n+import tensorflow.compat.v2 as tf\n \n \n # This decorator runs the test in V1, V2-Eager, and V2-Functional mode. It\n@@ -36,7 +32,7 @@ class MultiHeadAttentionTest(keras_parameterized.TestCase):\n   )\n   def test_non_masked_attention(self, value_dim, output_shape, output_dims):\n     \"\"\"Test that the attention layer can be created without a mask tensor.\"\"\"\n-    test_layer = multi_head_attention.MultiHeadAttention(\n+    test_layer = keras.layers.MultiHeadAttention(\n         num_heads=12,\n         key_dim=64,\n         value_dim=value_dim,\n@@ -49,7 +45,7 @@ class MultiHeadAttentionTest(keras_parameterized.TestCase):\n \n   def test_non_masked_self_attention(self):\n     \"\"\"Test with one input (self-attenntion) and no mask tensor.\"\"\"\n-    test_layer = multi_head_attention.MultiHeadAttention(\n+    test_layer = keras.layers.MultiHeadAttention(\n         num_heads=12, key_dim=64)\n     # Create a 3-dimensional input (the first dimension is implicit).\n     query = keras.Input(shape=(40, 80))\n@@ -58,7 +54,7 @@ class MultiHeadAttentionTest(keras_parameterized.TestCase):\n \n   def test_attention_scores(self):\n     \"\"\"Test attention outputs with coefficients.\"\"\"\n-    test_layer = multi_head_attention.MultiHeadAttention(\n+    test_layer = keras.layers.MultiHeadAttention(\n         num_heads=12, key_dim=64)\n     # Create a 3-dimensional input (the first dimension is implicit).\n     query = keras.Input(shape=(40, 80))\n@@ -68,7 +64,7 @@ class MultiHeadAttentionTest(keras_parameterized.TestCase):\n \n   def test_attention_scores_with_values(self):\n     \"\"\"Test attention outputs with coefficients.\"\"\"\n-    test_layer = multi_head_attention.MultiHeadAttention(\n+    test_layer = keras.layers.MultiHeadAttention(\n         num_heads=12, key_dim=64)\n     # Create a 3-dimensional input (the first dimension is implicit).\n     query = keras.Input(shape=(40, 80))\n@@ -80,7 +76,7 @@ class MultiHeadAttentionTest(keras_parameterized.TestCase):\n   @parameterized.named_parameters((\"with_bias\", True), (\"no_bias\", False))\n   def test_masked_attention(self, use_bias):\n     \"\"\"Test with a mask tensor.\"\"\"\n-    test_layer = multi_head_attention.MultiHeadAttention(\n+    test_layer = keras.layers.MultiHeadAttention(\n         num_heads=2, key_dim=2, use_bias=use_bias)\n     # Create a 3-dimensional input (the first dimension is implicit).\n     batch_size = 3\n@@ -130,7 +126,7 @@ class MultiHeadAttentionTest(keras_parameterized.TestCase):\n \n   def test_initializer(self):\n     \"\"\"Test with a specified initializer.\"\"\"\n-    test_layer = multi_head_attention.MultiHeadAttention(\n+    test_layer = keras.layers.MultiHeadAttention(\n         num_heads=12,\n         key_dim=64,\n         kernel_initializer=keras.initializers.TruncatedNormal(stddev=0.02))\n@@ -141,7 +137,7 @@ class MultiHeadAttentionTest(keras_parameterized.TestCase):\n \n   def test_masked_attention_with_scores(self):\n     \"\"\"Test with a mask tensor.\"\"\"\n-    test_layer = multi_head_attention.MultiHeadAttention(\n+    test_layer = keras.layers.MultiHeadAttention(\n         num_heads=2, key_dim=2)\n     # Create a 3-dimensional input (the first dimension is implicit).\n     batch_size = 3\n@@ -194,7 +190,7 @@ class MultiHeadAttentionTest(keras_parameterized.TestCase):\n        (2, 3)))\n   def test_high_dim_attention(self, q_dims, v_dims, mask_dims, attention_axes):\n     \"\"\"Test with a mask tensor.\"\"\"\n-    test_layer = multi_head_attention.MultiHeadAttention(\n+    test_layer = keras.layers.MultiHeadAttention(\n         num_heads=2, key_dim=2, attention_axes=attention_axes)\n     batch_size, hidden_size = 3, 8\n     # Generate data for the input (non-mask) tensors.\n@@ -223,7 +219,7 @@ class MultiHeadAttentionTest(keras_parameterized.TestCase):\n         model.predict([query, value, null_mask_data]))\n \n   def test_dropout(self):\n-    test_layer = multi_head_attention.MultiHeadAttention(\n+    test_layer = keras.layers.MultiHeadAttention(\n         num_heads=2, key_dim=2, dropout=0.5)\n \n     # Generate data for the input (non-mask) tensors.\n@@ -239,7 +235,7 @@ class MultiHeadAttentionTest(keras_parameterized.TestCase):\n         keras.backend.eval(test_out))\n \n \n-class SubclassAttention(multi_head_attention.MultiHeadAttention):\n+class SubclassAttention(keras.layers.MultiHeadAttention):\n \n   def _build_attention(self, qkv_rank):\n     pass\n@@ -269,7 +265,7 @@ class TestModel(keras.Model):\n \n   def __init__(self):\n     super(TestModel, self).__init__()\n-    self.attention = multi_head_attention.MultiHeadAttention(\n+    self.attention = keras.layers.MultiHeadAttention(\n         num_heads=3,\n         key_dim=4,\n         value_dim=4,\n@@ -308,7 +304,7 @@ class KerasModelSavingTest(keras_parameterized.TestCase):\n   def test_keras_saving_functional(self, save_format):\n     model = TestModel()\n     query = keras.Input(shape=(40, 80))\n-    output = multi_head_attention.MultiHeadAttention(\n+    output = keras.layers.MultiHeadAttention(\n         num_heads=3,\n         key_dim=4,\n         value_dim=4,\n@@ -325,10 +321,10 @@ class KerasModelSavingTest(keras_parameterized.TestCase):\n       self.assertAllEqual(src_v, loaded_v)\n \n   def test_create_without_build(self):\n-    not_intialized_layer = multi_head_attention.MultiHeadAttention(\n+    not_initialized_layer = keras.layers.MultiHeadAttention(\n         num_heads=3, key_dim=4, value_dim=4)\n-    multi_head_attention.MultiHeadAttention.from_config(\n-        not_intialized_layer.get_config())\n+    keras.layers.MultiHeadAttention.from_config(\n+        not_initialized_layer.get_config())\n \n \n if __name__ == \"__main__\":\n\n@@ -1,554 +0,0 @@\n-# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n-#\n-# Licensed under the Apache License, Version 2.0 (the \"License\");\n-# you may not use this file except in compliance with the License.\n-# You may obtain a copy of the License at\n-#\n-#     http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing, software\n-# distributed under the License is distributed on an \"AS IS\" BASIS,\n-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-# See the License for the specific language governing permissions and\n-# limitations under the License.\n-# ==============================================================================\n-\"\"\"Attention layers that can be used in sequence DNN/CNN models.\n-\n-This file follows the terminology of https://arxiv.org/abs/1706.03762 Figure 2.\n-Attention is formed by three tensors: Query, Key and Value.\n-\"\"\"\n-# pylint: disable=g-classes-have-attributes,g-direct-tensorflow-import\n-\n-from keras import backend\n-from keras.engine import base_layer\n-from keras.utils import control_flow_util\n-import tensorflow.compat.v2 as tf\n-from tensorflow.python.util.tf_export import keras_export\n-\n-\n-class BaseDenseAttention(base_layer.BaseRandomLayer):\n-  \"\"\"Base Attention class for Dense networks.\n-\n-  This class is suitable for Dense or CNN networks, and not for RNN networks.\n-\n-  Implementations of attention mechanisms should inherit from this class, and\n-  reuse the `apply_attention_scores()` method.\n-\n-  Args:\n-    causal: Boolean. Set to `True` for decoder self-attention. Adds a mask such\n-      that position `i` cannot attend to positions `j > i`. This prevents the\n-      flow of information from the future towards the past.\n-    dropout: Float between 0 and 1. Fraction of the units to drop for the\n-      attention scores.\n-\n-  Call Args:\n-\n-    inputs: List of the following tensors:\n-      * query: Query `Tensor` of shape `[batch_size, Tq, dim]`.\n-      * value: Value `Tensor` of shape `[batch_size, Tv, dim]`.\n-      * key: Optional key `Tensor` of shape `[batch_size, Tv, dim]`. If not\n-        given, will use `value` for both `key` and `value`, which is the\n-        most common case.\n-    mask: List of the following tensors:\n-      * query_mask: A boolean mask `Tensor` of shape `[batch_size, Tq]`.\n-        If given, the output will be zero at the positions where\n-        `mask==False`.\n-      * value_mask: A boolean mask `Tensor` of shape `[batch_size, Tv]`.\n-        If given, will apply the mask such that values at positions where\n-        `mask==False` do not contribute to the result.\n-    training: Python boolean indicating whether the layer should behave in\n-      training mode (adding dropout) or in inference mode (no dropout).\n-    return_attention_scores: bool, if `True`, returns the attention scores\n-      (after masking and softmax) as an additional output argument.\n-\n-  Output:\n-\n-    Attention outputs of shape `[batch_size, Tq, dim]`.\n-    [Optional] Attention scores after masking and softmax with shape\n-      `[batch_size, Tq, Tv]`.\n-  \"\"\"\n-\n-  def __init__(self, causal=False, dropout=0.0, **kwargs):\n-    super(BaseDenseAttention, self).__init__(**kwargs)\n-    self.causal = causal\n-    self.dropout = dropout\n-    self.supports_masking = True\n-\n-  def _calculate_scores(self, query, key):\n-    \"\"\"Calculates attention scores.\n-\n-    Args:\n-      query: Query tensor of shape `[batch_size, Tq, dim]`.\n-      key: Key tensor of shape `[batch_size, Tv, dim]`.\n-\n-    Returns:\n-      Tensor of shape `[batch_size, Tq, Tv]`.\n-    \"\"\"\n-    return NotImplementedError\n-\n-  def _apply_scores(self, scores, value, scores_mask=None, training=None):\n-    \"\"\"Applies attention scores to the given value tensor.\n-\n-    To use this method in your attention layer, follow the steps:\n-\n-    * Use `query` tensor of shape `[batch_size, Tq]` and `key` tensor of shape\n-      `[batch_size, Tv]` to calculate the attention `scores`.\n-    * Pass `scores` and `value` tensors to this method. The method applies\n-      `scores_mask`, calculates `attention_distribution = softmax(scores)`, then\n-      returns `matmul(attention_distribution, value).\n-    * Apply `query_mask` and return the result.\n-\n-    Args:\n-      scores: Scores float tensor of shape `[batch_size, Tq, Tv]`.\n-      value: Value tensor of shape `[batch_size, Tv, dim]`.\n-      scores_mask: A boolean mask `Tensor` of shape `[batch_size, 1, Tv]` or\n-        `[batch_size, Tq, Tv]`. If given, scores at positions where\n-        `scores_mask==False` do not contribute to the result. It must contain\n-        at least one `True` value in each line along the last dimension.\n-      training: Python boolean indicating whether the layer should behave in\n-        training mode (adding dropout) or in inference mode (no dropout).\n-\n-    Returns:\n-      Tensor of shape `[batch_size, Tq, dim]`.\n-      Attention scores after masking and softmax with shape\n-        `[batch_size, Tq, Tv]`.\n-    \"\"\"\n-    if scores_mask is not None:\n-      padding_mask = tf.logical_not(scores_mask)\n-      # Bias so padding positions do not contribute to attention distribution.\n-      # Note 65504. is the max float16 value.\n-      if scores.dtype is tf.float16:\n-        scores -= 65504. * tf.cast(padding_mask, dtype=scores.dtype)\n-      else:\n-        scores -= 1.e9 * tf.cast(padding_mask, dtype=scores.dtype)\n-    if training is None:\n-      training = backend.learning_phase()\n-    weights = tf.nn.softmax(scores)\n-\n-    def dropped_weights():\n-      return self._random_generator.dropout(weights, rate=self.dropout)\n-\n-    weights = control_flow_util.smart_cond(training, dropped_weights,\n-                                           lambda: tf.identity(weights))\n-    return tf.matmul(weights, value), weights\n-\n-  # TODO(b/125916026): Consider exposing a __call__ method with named args.\n-  def call(self,\n-           inputs,\n-           mask=None,\n-           training=None,\n-           return_attention_scores=False):\n-    self._validate_call_args(inputs=inputs, mask=mask)\n-    q = inputs[0]\n-    v = inputs[1]\n-    k = inputs[2] if len(inputs) > 2 else v\n-    q_mask = mask[0] if mask else None\n-    v_mask = mask[1] if mask else None\n-    scores = self._calculate_scores(query=q, key=k)\n-    if v_mask is not None:\n-      # Mask of shape [batch_size, 1, Tv].\n-      v_mask = tf.expand_dims(v_mask, axis=-2)\n-    if self.causal:\n-      # Creates a lower triangular mask, so position i cannot attend to\n-      # positions j>i. This prevents the flow of information from the future\n-      # into the past.\n-      scores_shape = tf.shape(scores)\n-      # causal_mask_shape = [1, Tq, Tv].\n-      causal_mask_shape = tf.concat(\n-          [tf.ones_like(scores_shape[:-2]), scores_shape[-2:]],\n-          axis=0)\n-      causal_mask = _lower_triangular_mask(causal_mask_shape)\n-    else:\n-      causal_mask = None\n-    scores_mask = _merge_masks(v_mask, causal_mask)\n-    result, attention_scores = self._apply_scores(\n-        scores=scores, value=v, scores_mask=scores_mask, training=training)\n-    if q_mask is not None:\n-      # Mask of shape [batch_size, Tq, 1].\n-      q_mask = tf.expand_dims(q_mask, axis=-1)\n-      result *= tf.cast(q_mask, dtype=result.dtype)\n-    if return_attention_scores:\n-      return result, attention_scores\n-    return result\n-\n-  def compute_mask(self, inputs, mask=None):\n-    self._validate_call_args(inputs=inputs, mask=mask)\n-    if mask:\n-      q_mask = mask[0]\n-      if q_mask is None:\n-        return None\n-      return tf.convert_to_tensor(q_mask)\n-    return None\n-\n-  def compute_output_shape(self, input_shape):\n-    # return_attention_scores argument of BaseDenseAttention.call method\n-    # is ignored. Output shape of attention_scores cannot be returned.\n-    return tf.TensorShape(input_shape[0])\n-\n-  def _validate_call_args(self, inputs, mask):\n-    \"\"\"Validates arguments of the call method.\"\"\"\n-    class_name = self.__class__.__name__\n-    if not isinstance(inputs, list):\n-      raise ValueError(\n-          f'{class_name} layer must be called on a list of inputs, '\n-          'namely [query, value] or [query, value, key]. '\n-          f'Received: {inputs}.')\n-    if len(inputs) < 2 or len(inputs) > 3:\n-      raise ValueError(\n-          f'{class_name} layer accepts inputs list of length 2 or 3, '\n-          'namely [query, value] or [query, value, key]. '\n-          f'Received length: {len(inputs)}.')\n-    if mask:\n-      if not isinstance(mask, list):\n-        raise ValueError(\n-            f'{class_name} layer mask must be a list, '\n-            f'namely [query_mask, value_mask]. Received: {mask}.')\n-      if len(mask) < 2 or len(mask) > len(inputs):\n-        raise ValueError(\n-            f'{class_name} layer mask must be a list of length 2, '\n-            f'namely [query_mask, value_mask]. Received length: {len(mask)}.')\n-\n-  def get_config(self):\n-    config = {\n-        'causal': self.causal,\n-        'dropout': self.dropout,\n-    }\n-    base_config = super(BaseDenseAttention, self).get_config()\n-    return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-@keras_export('keras.layers.Attention')\n-class Attention(BaseDenseAttention):\n-  \"\"\"Dot-product attention layer, a.k.a. Luong-style attention.\n-\n-  Inputs are `query` tensor of shape `[batch_size, Tq, dim]`, `value` tensor of\n-  shape `[batch_size, Tv, dim]` and `key` tensor of shape\n-  `[batch_size, Tv, dim]`. The calculation follows the steps:\n-\n-  1. Calculate scores with shape `[batch_size, Tq, Tv]` as a `query`-`key` dot\n-     product: `scores = tf.matmul(query, key, transpose_b=True)`.\n-  2. Use scores to calculate a distribution with shape\n-     `[batch_size, Tq, Tv]`: `distribution = tf.nn.softmax(scores)`.\n-  3. Use `distribution` to create a linear combination of `value` with\n-     shape `[batch_size, Tq, dim]`:\n-     `return tf.matmul(distribution, value)`.\n-\n-  Args:\n-    use_scale: If `True`, will create a scalar variable to scale the attention\n-      scores.\n-    causal: Boolean. Set to `True` for decoder self-attention. Adds a mask such\n-      that position `i` cannot attend to positions `j > i`. This prevents the\n-      flow of information from the future towards the past.\n-      Defaults to `False`.\n-    dropout: Float between 0 and 1. Fraction of the units to drop for the\n-      attention scores. Defaults to 0.0.\n-    score_mode: Function to use to compute attention scores, one of\n-      `{\"dot\", \"concat\"}`. `\"dot\"` refers to the dot product between the query\n-      and key vectors. `\"concat\"` refers to the hyperbolic tangent of the\n-      concatenation of the query and key vectors.\n-\n-  Call Args:\n-\n-    inputs: List of the following tensors:\n-      * query: Query `Tensor` of shape `[batch_size, Tq, dim]`.\n-      * value: Value `Tensor` of shape `[batch_size, Tv, dim]`.\n-      * key: Optional key `Tensor` of shape `[batch_size, Tv, dim]`. If not\n-        given, will use `value` for both `key` and `value`, which is the\n-        most common case.\n-    mask: List of the following tensors:\n-      * query_mask: A boolean mask `Tensor` of shape `[batch_size, Tq]`.\n-        If given, the output will be zero at the positions where\n-        `mask==False`.\n-      * value_mask: A boolean mask `Tensor` of shape `[batch_size, Tv]`.\n-        If given, will apply the mask such that values at positions where\n-        `mask==False` do not contribute to the result.\n-    return_attention_scores: bool, it `True`, returns the attention scores\n-      (after masking and softmax) as an additional output argument.\n-    training: Python boolean indicating whether the layer should behave in\n-      training mode (adding dropout) or in inference mode (no dropout).\n-\n-  Output:\n-\n-    Attention outputs of shape `[batch_size, Tq, dim]`.\n-    [Optional] Attention scores after masking and softmax with shape\n-      `[batch_size, Tq, Tv]`.\n-\n-  The meaning of `query`, `value` and `key` depend on the application. In the\n-  case of text similarity, for example, `query` is the sequence embeddings of\n-  the first piece of text and `value` is the sequence embeddings of the second\n-  piece of text. `key` is usually the same tensor as `value`.\n-\n-  Here is a code example for using `Attention` in a CNN+Attention network:\n-\n-  ```python\n-  # Variable-length int sequences.\n-  query_input = tf.keras.Input(shape=(None,), dtype='int32')\n-  value_input = tf.keras.Input(shape=(None,), dtype='int32')\n-\n-  # Embedding lookup.\n-  token_embedding = tf.keras.layers.Embedding(input_dim=1000, output_dim=64)\n-  # Query embeddings of shape [batch_size, Tq, dimension].\n-  query_embeddings = token_embedding(query_input)\n-  # Value embeddings of shape [batch_size, Tv, dimension].\n-  value_embeddings = token_embedding(value_input)\n-\n-  # CNN layer.\n-  cnn_layer = tf.keras.layers.Conv1D(\n-      filters=100,\n-      kernel_size=4,\n-      # Use 'same' padding so outputs have the same shape as inputs.\n-      padding='same')\n-  # Query encoding of shape [batch_size, Tq, filters].\n-  query_seq_encoding = cnn_layer(query_embeddings)\n-  # Value encoding of shape [batch_size, Tv, filters].\n-  value_seq_encoding = cnn_layer(value_embeddings)\n-\n-  # Query-value attention of shape [batch_size, Tq, filters].\n-  query_value_attention_seq = tf.keras.layers.Attention()(\n-      [query_seq_encoding, value_seq_encoding])\n-\n-  # Reduce over the sequence axis to produce encodings of shape\n-  # [batch_size, filters].\n-  query_encoding = tf.keras.layers.GlobalAveragePooling1D()(\n-      query_seq_encoding)\n-  query_value_attention = tf.keras.layers.GlobalAveragePooling1D()(\n-      query_value_attention_seq)\n-\n-  # Concatenate query and document encodings to produce a DNN input layer.\n-  input_layer = tf.keras.layers.Concatenate()(\n-      [query_encoding, query_value_attention])\n-\n-  # Add DNN layers, and create Model.\n-  # ...\n-  ```\n-  \"\"\"\n-\n-  def __init__(self, use_scale=False, score_mode='dot', **kwargs):\n-    super(Attention, self).__init__(**kwargs)\n-    self.use_scale = use_scale\n-    self.score_mode = score_mode\n-    if self.score_mode not in ['dot', 'concat']:\n-      raise ValueError(f'Received: score_mode={score_mode}. Acceptable values '\n-                       'are: [\"dot\", \"concat\"]')\n-\n-  def build(self, input_shape):\n-    \"\"\"Creates variable when `use_scale` is True or `score_mode` is `concat`.\"\"\"\n-    if self.use_scale:\n-      self.scale = self.add_weight(\n-          name='scale',\n-          shape=(),\n-          initializer='ones',\n-          dtype=self.dtype,\n-          trainable=True)\n-    else:\n-      self.scale = None\n-    if self.score_mode == 'concat':\n-      self.concat_score_weight = self.add_weight(\n-          name='concat_score_weight',\n-          shape=(),\n-          initializer='ones',\n-          dtype=self.dtype,\n-          trainable=True)\n-    else:\n-      self.concat_score_weight = None\n-    super(Attention, self).build(input_shape)\n-\n-  def _calculate_scores(self, query, key):\n-    \"\"\"Calculates attention scores as a query-key dot product.\n-\n-    Args:\n-      query: Query tensor of shape `[batch_size, Tq, dim]`.\n-      key: Key tensor of shape `[batch_size, Tv, dim]`.\n-    Returns:\n-      Tensor of shape `[batch_size, Tq, Tv]`.\n-    \"\"\"\n-    if self.score_mode == 'dot':\n-      scores = tf.matmul(query, key, transpose_b=True)\n-      if self.scale is not None:\n-        scores *= self.scale\n-    elif self.score_mode == 'concat':\n-      # Reshape tensors to enable broadcasting.\n-      # Reshape into [batch_size, Tq, 1, dim].\n-      q_reshaped = tf.expand_dims(query, axis=-2)\n-      # Reshape into [batch_size, 1, Tv, dim].\n-      k_reshaped = tf.expand_dims(key, axis=-3)\n-      if self.scale is not None:\n-        scores = self.concat_score_weight * tf.reduce_sum(\n-            tf.tanh(self.scale * (q_reshaped + k_reshaped)), axis=-1)\n-      else:\n-        scores = self.concat_score_weight * tf.reduce_sum(\n-            tf.tanh(q_reshaped + k_reshaped), axis=-1)\n-\n-    return scores\n-\n-  def get_config(self):\n-    config = {'use_scale': self.use_scale, 'score_mode': self.score_mode}\n-    base_config = super(Attention, self).get_config()\n-    return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-@keras_export('keras.layers.AdditiveAttention')\n-class AdditiveAttention(BaseDenseAttention):\n-  \"\"\"Additive attention layer, a.k.a. Bahdanau-style attention.\n-\n-  Inputs are `query` tensor of shape `[batch_size, Tq, dim]`, `value` tensor of\n-  shape `[batch_size, Tv, dim]` and `key` tensor of shape\n-  `[batch_size, Tv, dim]`. The calculation follows the steps:\n-\n-  1. Reshape `query` and `key` into shapes `[batch_size, Tq, 1, dim]`\n-     and `[batch_size, 1, Tv, dim]` respectively.\n-  2. Calculate scores with shape `[batch_size, Tq, Tv]` as a non-linear\n-     sum: `scores = tf.reduce_sum(tf.tanh(query + key), axis=-1)`\n-  3. Use scores to calculate a distribution with shape\n-     `[batch_size, Tq, Tv]`: `distribution = tf.nn.softmax(scores)`.\n-  4. Use `distribution` to create a linear combination of `value` with\n-     shape `[batch_size, Tq, dim]`:\n-     `return tf.matmul(distribution, value)`.\n-\n-  Args:\n-    use_scale: If `True`, will create a variable to scale the attention scores.\n-    causal: Boolean. Set to `True` for decoder self-attention. Adds a mask such\n-      that position `i` cannot attend to positions `j > i`. This prevents the\n-      flow of information from the future towards the past.\n-      Defaults to `False`.\n-    dropout: Float between 0 and 1. Fraction of the units to drop for the\n-      attention scores. Defaults to 0.0.\n-\n-  Call Args:\n-\n-    inputs: List of the following tensors:\n-      * query: Query `Tensor` of shape `[batch_size, Tq, dim]`.\n-      * value: Value `Tensor` of shape `[batch_size, Tv, dim]`.\n-      * key: Optional key `Tensor` of shape `[batch_size, Tv, dim]`. If not\n-        given, will use `value` for both `key` and `value`, which is the\n-        most common case.\n-    mask: List of the following tensors:\n-      * query_mask: A boolean mask `Tensor` of shape `[batch_size, Tq]`.\n-        If given, the output will be zero at the positions where\n-        `mask==False`.\n-      * value_mask: A boolean mask `Tensor` of shape `[batch_size, Tv]`.\n-        If given, will apply the mask such that values at positions where\n-        `mask==False` do not contribute to the result.\n-    training: Python boolean indicating whether the layer should behave in\n-      training mode (adding dropout) or in inference mode (no dropout).\n-    return_attention_scores: bool, it `True`, returns the attention scores\n-      (after masking and softmax) as an additional output argument.\n-\n-  Output:\n-\n-    Attention outputs of shape `[batch_size, Tq, dim]`.\n-    [Optional] Attention scores after masking and softmax with shape\n-      `[batch_size, Tq, Tv]`.\n-\n-  The meaning of `query`, `value` and `key` depend on the application. In the\n-  case of text similarity, for example, `query` is the sequence embeddings of\n-  the first piece of text and `value` is the sequence embeddings of the second\n-  piece of text. `key` is usually the same tensor as `value`.\n-\n-  Here is a code example for using `AdditiveAttention` in a CNN+Attention\n-  network:\n-\n-  ```python\n-  # Variable-length int sequences.\n-  query_input = tf.keras.Input(shape=(None,), dtype='int32')\n-  value_input = tf.keras.Input(shape=(None,), dtype='int32')\n-\n-  # Embedding lookup.\n-  token_embedding = tf.keras.layers.Embedding(max_tokens, dimension)\n-  # Query embeddings of shape [batch_size, Tq, dimension].\n-  query_embeddings = token_embedding(query_input)\n-  # Value embeddings of shape [batch_size, Tv, dimension].\n-  value_embeddings = token_embedding(value_input)\n-\n-  # CNN layer.\n-  cnn_layer = tf.keras.layers.Conv1D(\n-      filters=100,\n-      kernel_size=4,\n-      # Use 'same' padding so outputs have the same shape as inputs.\n-      padding='same')\n-  # Query encoding of shape [batch_size, Tq, filters].\n-  query_seq_encoding = cnn_layer(query_embeddings)\n-  # Value encoding of shape [batch_size, Tv, filters].\n-  value_seq_encoding = cnn_layer(value_embeddings)\n-\n-  # Query-value attention of shape [batch_size, Tq, filters].\n-  query_value_attention_seq = tf.keras.layers.AdditiveAttention()(\n-      [query_seq_encoding, value_seq_encoding])\n-\n-  # Reduce over the sequence axis to produce encodings of shape\n-  # [batch_size, filters].\n-  query_encoding = tf.keras.layers.GlobalAveragePooling1D()(\n-      query_seq_encoding)\n-  query_value_attention = tf.keras.layers.GlobalAveragePooling1D()(\n-      query_value_attention_seq)\n-\n-  # Concatenate query and document encodings to produce a DNN input layer.\n-  input_layer = tf.keras.layers.Concatenate()(\n-      [query_encoding, query_value_attention])\n-\n-  # Add DNN layers, and create Model.\n-  # ...\n-  ```\n-  \"\"\"\n-\n-  def __init__(self, use_scale=True, **kwargs):\n-    super(AdditiveAttention, self).__init__(**kwargs)\n-    self.use_scale = use_scale\n-\n-  def build(self, input_shape):\n-    v_shape = tf.TensorShape(input_shape[1])\n-    dim = v_shape[-1]\n-    dim = tf.compat.dimension_value(dim)\n-    if self.use_scale:\n-      self.scale = self.add_weight(\n-          name='scale',\n-          shape=[dim],\n-          initializer='glorot_uniform',\n-          dtype=self.dtype,\n-          trainable=True)\n-    else:\n-      self.scale = None\n-    super(AdditiveAttention, self).build(input_shape)\n-\n-  def _calculate_scores(self, query, key):\n-    \"\"\"Calculates attention scores as a nonlinear sum of query and key.\n-\n-    Args:\n-      query: Query tensor of shape `[batch_size, Tq, dim]`.\n-      key: Key tensor of shape `[batch_size, Tv, dim]`.\n-    Returns:\n-      Tensor of shape `[batch_size, Tq, Tv]`.\n-    \"\"\"\n-    # Reshape tensors to enable broadcasting.\n-    # Reshape into [batch_size, Tq, 1, dim].\n-    q_reshaped = tf.expand_dims(query, axis=-2)\n-    # Reshape into [batch_size, 1, Tv, dim].\n-    k_reshaped = tf.expand_dims(key, axis=-3)\n-    if self.use_scale:\n-      scale = self.scale\n-    else:\n-      scale = 1.\n-    return tf.reduce_sum(\n-        scale * tf.tanh(q_reshaped + k_reshaped), axis=-1)\n-\n-  def get_config(self):\n-    config = {'use_scale': self.use_scale}\n-    base_config = super(AdditiveAttention, self).get_config()\n-    return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-def _lower_triangular_mask(shape):\n-  \"\"\"Creates a lower-triangular boolean mask over the last 2 dimensions.\"\"\"\n-  row_index = tf.cumsum(\n-      tf.ones(shape=shape, dtype=tf.int32), axis=-2)\n-  col_index = tf.cumsum(\n-      tf.ones(shape=shape, dtype=tf.int32), axis=-1)\n-  return tf.greater_equal(row_index, col_index)\n-\n-\n-def _merge_masks(x, y):\n-  if x is None:\n-    return y\n-  if y is None:\n-    return x\n-  return tf.logical_and(x, y)\n\n@@ -1,874 +0,0 @@\n-# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n-#\n-# Licensed under the Apache License, Version 2.0 (the \"License\");\n-# you may not use this file except in compliance with the License.\n-# You may obtain a copy of the License at\n-#\n-#     http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing, software\n-# distributed under the License is distributed on an \"AS IS\" BASIS,\n-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-# See the License for the specific language governing permissions and\n-# limitations under the License.\n-# ==============================================================================\n-\"\"\"Tests dense attention layers.\"\"\"\n-\n-import tensorflow.compat.v2 as tf\n-\n-from absl.testing import parameterized\n-import numpy as np\n-\n-import keras\n-from keras import combinations\n-from keras import testing_utils\n-from keras.layers import core\n-from keras.layers import dense_attention\n-from keras.mixed_precision import policy\n-\n-\n-@combinations.generate(combinations.combine(mode=['graph', 'eager']))\n-class BaseDenseAttentionTest(tf.test.TestCase, parameterized.TestCase):\n-\n-  def test_one_dim_with_mask(self):\n-    # Scores tensor of shape [1, 1, 1]\n-    scores = np.array([[[1.1]]], dtype=np.float32)\n-    # Value tensor of shape [1, 1, 1]\n-    v = np.array([[[1.6]]], dtype=np.float32)\n-    # Scores mask tensor of shape [1, 1, 1]\n-    scores_mask = np.array([[[True]]], dtype=np.bool_)\n-    actual, actual_scores = dense_attention.BaseDenseAttention()._apply_scores(\n-        scores=scores, value=v, scores_mask=scores_mask)\n-\n-    # Expected softmax_scores = [[[1]]]\n-    expected_scores = np.array([[[1.]]], dtype=np.float32)\n-    self.assertAllClose(expected_scores, actual_scores)\n-    # Expected tensor of shape [1, 1, 1].\n-    # expected000 = softmax_scores[0, 0] * 1.6 = 1.6\n-    expected = np.array([[[1.6]]], dtype=np.float32)\n-    self.assertAllClose(expected, actual)\n-\n-  def test_one_dim_no_mask(self):\n-    # Scores tensor of shape [1, 1, 1]\n-    scores = np.array([[[1.1]]], dtype=np.float32)\n-    # Value tensor of shape [1, 1, 1]\n-    v = np.array([[[1.6]]], dtype=np.float32)\n-    actual, actual_scores = dense_attention.BaseDenseAttention()._apply_scores(\n-        scores=scores, value=v)\n-\n-    # Expected softmax_scores = [[[1]]]\n-    expected_scores = np.array([[[1.]]], dtype=np.float32)\n-    self.assertAllClose(expected_scores, actual_scores)\n-    # Expected tensor of shape [1, 1, 1].\n-    # expected000 = softmax_scores[0, 0] * 1.6 = 1.6\n-    expected = np.array([[[1.6]]], dtype=np.float32)\n-    self.assertAllClose(expected, actual)\n-\n-  def test_multi_dim_with_mask(self):\n-    # Scores tensor of shape [1, 1, 3]\n-    scores = np.array([[[1., 0., 1.]]], dtype=np.float32)\n-    # Value tensor of shape [1, 3, 1]\n-    v = np.array([[[1.6], [0.7], [-0.8]]], dtype=np.float32)\n-    # Scores mask tensor of shape [1, 1, 3]\n-    scores_mask = np.array([[[True, True, False]]], dtype=np.bool_)\n-    actual, actual_scores = dense_attention.BaseDenseAttention()._apply_scores(\n-        scores=scores, value=v, scores_mask=scores_mask)\n-\n-    # Expected softmax scores = softmax(scores) with zeros in positions where\n-    # v_mask == False.\n-    # => softmax_scores000 = exp(1)/(exp(1) + exp(0)) = 0.73105857863\n-    #    softmax_scores001 = exp(0)/(exp(1) + exp(0)) = 0.26894142137\n-    #    softmax_scores002 = 0\n-    expected_scores = np.array([[[0.73105857863, 0.26894142137, 0.]]],\n-                               dtype=np.float32)\n-    self.assertAllClose(expected_scores, actual_scores)\n-    # Expected tensor of shape [1, 1, 1].\n-    # expected000 = 0.73105857863 * 1.6 + 0.26894142137 * 0.7 - 0 * 0.8\n-    #             = 1.35795272077\n-    expected = np.array([[[1.35795272077]]], dtype=np.float32)\n-    self.assertAllClose(expected, actual)\n-\n-  def test_multi_dim_no_mask(self):\n-    # Scores tensor of shape [1, 1, 3]\n-    scores = np.array([[[1., 0., 1.]]], dtype=np.float32)\n-    # Value tensor of shape [1, 3, 1]\n-    v = np.array([[[1.6], [0.7], [-0.8]]], dtype=np.float32)\n-    actual, actual_scores = dense_attention.BaseDenseAttention()._apply_scores(\n-        scores=scores, value=v)\n-\n-    # Expected softmax_scores = softmax(scores).\n-    # => softmax_scores000 = exp(1)/(exp(1) + exp(0) + exp(1))\n-    #                      = 0.42231879825\n-    #    softmax_scores001 = exp(0)/(exp(1) + exp(0) + exp(1))\n-    #                      = 0.15536240349\n-    #    softmax_scores002 = exp(1)/(exp(1) + exp(0) + exp(1))\n-    #                      = 0.42231879825\n-    expected_scores = np.array(\n-        [[[0.42231879825, 0.15536240349, 0.42231879825]]], dtype=np.float32)\n-    self.assertAllClose(expected_scores, actual_scores)\n-    # Expected tensor of shape [1, 1, 1].\n-    # expected000 = 0.42231879825 * 1.6 + 0.15536240349 * 0.7\n-    #               - 0.42231879825 * 0.8\n-    #             = 0.44660872104\n-    expected = np.array([[[0.44660872104]]], dtype=np.float32)\n-    self.assertAllClose(expected, actual)\n-\n-  def test_one_dim_batch_size_two(self):\n-    # Scores tensor of shape [2, 1, 1]\n-    scores = np.array([[[1.1]], [[2.1]]], dtype=np.float32)\n-    # Value tensor of shape [2, 1, 1]\n-    v = np.array([[[1.6]], [[2.6]]], dtype=np.float32)\n-    # Scpres mask tensor of shape [2, 1, 1]\n-    scores_mask = np.array([[[True]], [[True]]], dtype=np.bool_)\n-    actual, actual_scores = dense_attention.BaseDenseAttention()._apply_scores(\n-        scores=scores, value=v, scores_mask=scores_mask)\n-\n-    # Expected softmax_scores = [[[1]], [[1]]]\n-    expected_scores = np.array([[[1.]], [[1.]]], dtype=np.float32)\n-    self.assertAllClose(expected_scores, actual_scores)\n-    # Expected tensor of shape [2, 1, 1].\n-    # expected000 = softmax_scores[0, 0] * 1.6 = 1.6\n-    # expected100 = softmax_scores[1, 0] * 2.6 = 2.6\n-    expected = np.array([[[1.6]], [[2.6]]], dtype=np.float32)\n-    self.assertAllClose(expected, actual)\n-\n-  def test_shape_with_dropout(self):\n-    # scores: Scores float tensor of shape `[batch_size, tq, tv]`.\n-    # value: Value tensor of shape `[batch_size, tv, dim]`.\n-    batch_size = 4\n-    tq = 5\n-    tv = 6\n-    dim = 7\n-    scores = np.ones((batch_size, tq, tv))\n-    value = np.ones((batch_size, tv, dim))\n-    actual, actual_scores = dense_attention.BaseDenseAttention(\n-        dropout=0.1)._apply_scores(\n-            scores=scores, value=value, training=False)\n-\n-    # Expected Tensor of shape `[batch_size, tq, tv]`.\n-    expected_scores_shape = [batch_size, tq, tv]\n-    self.assertAllEqual(expected_scores_shape, tf.shape(actual_scores))\n-    # Expected Tensor of shape `[batch_size, tq, dim]`.\n-    expected_shape = [batch_size, tq, dim]\n-    self.assertAllEqual(expected_shape, tf.shape(actual))\n-\n-  def test_serialization(self):\n-    # Test serialization with causal\n-    layer = dense_attention.BaseDenseAttention(causal=True)\n-\n-    config = keras.layers.serialize(layer)\n-    new_layer = keras.layers.deserialize(config)\n-    self.assertEqual(new_layer.causal, True)\n-\n-    config = layer.get_config()\n-    new_layer = dense_attention.BaseDenseAttention.from_config(config)\n-    self.assertEqual(new_layer.causal, True)\n-\n-\n-@combinations.generate(combinations.combine(mode=['graph', 'eager']))\n-class AttentionTest(tf.test.TestCase, parameterized.TestCase):\n-\n-  def test_calculate_scores_one_dim(self):\n-    # Query tensor of shape [1, 1, 1]\n-    q = np.array([[[1.1]]], dtype=np.float32)\n-    # Key tensor of shape [1, 1, 1]\n-    k = np.array([[[1.6]]], dtype=np.float32)\n-    attention_layer = dense_attention.Attention()\n-    attention_layer.build(input_shape=([1, 1, 1], [1, 1, 1]))\n-    actual = attention_layer._calculate_scores(query=q, key=k)\n-\n-    # Expected tensor of shape [1, 1, 1].\n-    # expected000 = 1.1*1.6 = 1.76\n-    expected = np.array([[[1.76]]], dtype=np.float32)\n-    self.assertAllClose(expected, actual)\n-\n-  def test_calculate_scores_multi_dim(self):\n-    # Query tensor of shape [1, 2, 4]\n-    q = np.array([[[1., 1.1, 1.2, 1.3], [2., 2.1, 2.2, 2.3]]], dtype=np.float32)\n-    # Key tensor of shape [1, 3, 4]\n-    k = np.array(\n-        [[[1.5, 1.6, 1.7, 1.8], [2.5, 2.6, 2.7, 2.8], [3.5, 3.6, 3.7, 3.8]]],\n-        dtype=np.float32)\n-    attention_layer = dense_attention.Attention()\n-    attention_layer.build(input_shape=([1, 2, 4], [1, 3, 4]))\n-    actual = attention_layer._calculate_scores(query=q, key=k)\n-\n-    # Expected tensor of shape [1, 2, 3].\n-    # expected000 = 1.*1.5+1.1*1.6+1.2*1.7+1.3*1.8 = 7.64\n-    # expected001 = 1.*2.5+1.1*2.6+1.2*2.7+1.3*2.8 = 12.24\n-    # expected002 = 1.*3.5+1.1*3.6+1.2*3.7+1.3*3.8 = 16.84\n-    # expected010 = 2.*1.5+2.1*1.6+2.2*1.7+2.3*1.8 = 14.24\n-    # expected011 = 2.*2.5+2.1*2.6+2.2*2.7+2.3*2.8 = 22.84\n-    # expected012 = 2.*3.5+2.1*3.6+2.2*3.7+2.3*3.8 = 31.44\n-    expected = np.array([[[7.64, 12.24, 16.84], [14.24, 22.84, 31.44]]],\n-                        dtype=np.float32)\n-    self.assertAllClose(expected, actual)\n-\n-  def test_calculate_scores_multi_dim_concat(self):\n-    # Query tensor of shape [1, 2, 4]\n-    q = np.array([[[1., 1.1, 1.2, 1.3], [2., 2.1, 2.2, 2.3]]], dtype=np.float32)\n-    # Key tensor of shape [1, 3, 4]\n-    k = np.array(\n-        [[[1.5, 1.6, 1.7, 1.8], [2.5, 2.6, 2.7, 2.8], [3.5, 3.6, 3.7, 3.8]]],\n-        dtype=np.float32)\n-    attention_layer = dense_attention.Attention(score_mode='concat')\n-    attention_layer.concat_score_weight = 1\n-    attention_layer.build(input_shape=([1, 2, 4], [1, 3, 4]))\n-    actual = keras.backend.get_value(\n-        attention_layer._calculate_scores(query=q, key=k))\n-\n-    # pylint:disable=line-too-long\n-    # expected000 = tanh(1.+1.5) + tanh(1.1+1.6) + tanh(1.2+1.7) + tanh(1.3+1.8) = 3.96753427840\n-    # expected001 = tanh(1.+2.5) + tanh(1.1+2.6) + tanh(1.2+2.7) + tanh(1.3+2.8) = 3.99558784825\n-    # expected002 = tanh(1.+3.5) + tanh(1.1+3.6) + tanh(1.2+3.7) + tanh(1.3+3.8) = 3.99940254147\n-    # expected010 = tanh(2.+1.5) + tanh(2.1+1.6) + tanh(2.2+1.7) + tanh(2.3+1.8) = 3.99558784825\n-    # expected011 = tanh(2.+2.5) + tanh(2.1+2.6) + tanh(2.2+2.7) + tanh(2.3+2.8) = 3.99940254147\n-    # expected012 = tanh(2.+3.5) + tanh(2.1+3.6) + tanh(2.2+3.7) + tanh(2.3+3.8) = 3.99991913657\n-    expected = np.array([[[3.96753427840, 3.99558784825, 3.99940254147],\n-                          [3.99558784825, 3.99940254147, 3.99991913657]]],\n-                        dtype=np.float32)\n-    self.assertAllClose(expected, actual)\n-\n-  def test_calculate_scores_one_dim_batch_size_two(self):\n-    # Query tensor of shape [2, 1, 1]\n-    q = np.array([[[1.1]], [[2.1]]], dtype=np.float32)\n-    # Key tensor of shape [2, 1, 1]\n-    k = np.array([[[1.6]], [[2.6]]], dtype=np.float32)\n-    attention_layer = dense_attention.Attention()\n-    attention_layer.build(input_shape=([2, 1, 1], [2, 1, 1]))\n-    actual = attention_layer._calculate_scores(query=q, key=k)\n-\n-    # Expected tensor of shape [2, 1, 1].\n-    # expected000 = 1.1*1.6 = 1.76\n-    # expected100 = 2.1*2.6 = 5.46\n-    expected = np.array([[[1.76]], [[5.46]]], dtype=np.float32)\n-    self.assertAllClose(expected, actual)\n-\n-  def test_calculate_scores_one_dim_with_scale(self):\n-    \"\"\"Tests that scores are multiplied by scale.\"\"\"\n-    # Query tensor of shape [1, 1, 1]\n-    q = np.array([[[1.1]]], dtype=np.float32)\n-    # Key tensor of shape [1, 1, 1]\n-    k = np.array([[[1.6]]], dtype=np.float32)\n-    attention_layer = dense_attention.Attention(use_scale=True)\n-    attention_layer.build(input_shape=([1, 1, 1], [1, 1, 1]))\n-    attention_layer.scale = -2.\n-    actual = attention_layer._calculate_scores(query=q, key=k)\n-\n-    # Expected tensor of shape [1, 1, 1].\n-    # expected000 = -2*1.1*1.6 = -3.52\n-    expected = np.array([[[-3.52]]], dtype=np.float32)\n-    self.assertAllClose(expected, actual)\n-\n-  def test_calculate_scores_one_dim_with_scale_concat(self):\n-    \"\"\"Tests that scores are multiplied by scale.\"\"\"\n-    # Query tensor of shape [1, 1, 1]\n-    q = np.array([[[1.1]]], dtype=np.float32)\n-    # Key tensor of shape [1, 1, 1]\n-    k = np.array([[[1.6]]], dtype=np.float32)\n-    attention_layer = dense_attention.Attention(\n-        use_scale=True, score_mode='concat')\n-    attention_layer.concat_score_weight = 1\n-    attention_layer.build(input_shape=([1, 1, 1], [1, 1, 1]))\n-    attention_layer.scale = 2.\n-    actual = keras.backend.get_value(\n-        attention_layer._calculate_scores(query=q, key=k))\n-\n-    # Expected tensor of shape [1, 1, 1].\n-    # expected000 = tanh(2*(1.1+1.6)) = 0.9999592018254402\n-    expected = np.array([[[0.999959202]]], dtype=np.float32)\n-    self.assertAllClose(expected, actual)\n-\n-  def test_shape(self):\n-    # Query tensor of shape [1, 2, 4]\n-    q = np.array([[[1., 1.1, 1.2, 1.3], [2., 2.1, 2.2, 2.3]]], dtype=np.float32)\n-    # Value tensor of shape [1, 3, 4]\n-    v = np.array(\n-        [[[1.5, 1.6, 1.7, 1.8], [2.5, 2.6, 2.7, 2.8], [3.5, 3.6, 3.7, 3.8]]],\n-        dtype=np.float32)\n-    # Value mask tensor of shape [1, 3]\n-    v_mask = np.array([[True, True, False]], dtype=np.bool_)\n-    attention_layer = dense_attention.Attention()\n-    actual = attention_layer([q, v], mask=[None, v_mask])\n-\n-    expected_shape = [1, 2, 4]\n-    self.assertAllEqual(expected_shape, tf.shape(actual))\n-\n-  def test_shape_concat(self):\n-    # Query tensor of shape [1, 2, 4]\n-    q = np.array([[[1., 1.1, 1.2, 1.3], [2., 2.1, 2.2, 2.3]]], dtype=np.float32)\n-    # Value tensor of shape [1, 3, 4]\n-    v = np.array(\n-        [[[1.5, 1.6, 1.7, 1.8], [2.5, 2.6, 2.7, 2.8], [3.5, 3.6, 3.7, 3.8]]],\n-        dtype=np.float32)\n-    # Value mask tensor of shape [1, 3]\n-    v_mask = np.array([[True, True, False]], dtype=np.bool_)\n-    attention_layer = dense_attention.Attention(score_mode='concat')\n-    attention_layer.concat_score_weight = 1\n-    actual = attention_layer([q, v], mask=[None, v_mask])\n-\n-    expected_shape = [1, 2, 4]\n-    self.assertAllEqual(expected_shape, tf.shape(actual))\n-\n-  def test_shape_with_key(self):\n-    # Query tensor of shape [1, 2, 4]\n-    q = np.array([[[1., 1.1, 1.2, 1.3], [2., 2.1, 2.2, 2.3]]], dtype=np.float32)\n-    # Value tensor of shape [1, 3, 4]\n-    v = np.array(\n-        [[[1.5, 1.6, 1.7, 1.8], [2.5, 2.6, 2.7, 2.8], [3.5, 3.6, 3.7, 3.8]]],\n-        dtype=np.float32)\n-    # Key tensor of shape [1, 3, 4]\n-    k = np.array(\n-        [[[1.5, 1.6, 1.7, 1.8], [2.5, 2.6, 2.7, 2.8], [3.5, 3.6, 3.7, 3.8]]],\n-        dtype=np.float32)\n-    # Value mask tensor of shape [1, 3]\n-    v_mask = np.array([[True, True, False]], dtype=np.bool_)\n-    attention_layer = dense_attention.Attention()\n-    actual = attention_layer([q, v, k], mask=[None, v_mask])\n-\n-    expected_shape = [1, 2, 4]\n-    self.assertAllEqual(expected_shape, tf.shape(actual))\n-\n-  def test_shape_with_key_concat(self):\n-    # Query tensor of shape [1, 2, 4]\n-    q = np.array([[[1., 1.1, 1.2, 1.3], [2., 2.1, 2.2, 2.3]]], dtype=np.float32)\n-    # Value tensor of shape [1, 3, 4]\n-    v = np.array(\n-        [[[1.5, 1.6, 1.7, 1.8], [2.5, 2.6, 2.7, 2.8], [3.5, 3.6, 3.7, 3.8]]],\n-        dtype=np.float32)\n-    # Key tensor of shape [1, 3, 4]\n-    k = np.array(\n-        [[[1.5, 1.6, 1.7, 1.8], [2.5, 2.6, 2.7, 2.8], [3.5, 3.6, 3.7, 3.8]]],\n-        dtype=np.float32)\n-    # Value mask tensor of shape [1, 3]\n-    v_mask = np.array([[True, True, False]], dtype=np.bool_)\n-    attention_layer = dense_attention.Attention(score_mode='concat')\n-    attention_layer.concat_score_weight = 1\n-    actual = attention_layer([q, v, k], mask=[None, v_mask])\n-\n-    expected_shape = [1, 2, 4]\n-    self.assertAllEqual(expected_shape, tf.shape(actual))\n-\n-  def test_multi_dim(self):\n-    # Query tensor of shape [1, 1, 1]\n-    q = np.array([[[1.1]]], dtype=np.float32)\n-    # Value tensor of shape [1, 3, 1]\n-    v = np.array([[[1.6], [0.7], [-0.8]]], dtype=np.float32)\n-    # Value mask tensor of shape [1, 3]\n-    v_mask = np.array([[True, True, False]], dtype=np.bool_)\n-    attention_layer = dense_attention.Attention()\n-    actual = attention_layer([q, v], mask=[None, v_mask])\n-\n-    # Expected scores of shape [1, 1, 3]\n-    # scores = [[[1.1*1.6, 1.1*0.7, -1.1*0.8]]] = [[[1.76, 0.77, -0.88]]]\n-    # Expected attention distribution = softmax(scores) with zeros in\n-    # positions where v_mask == False.\n-    # => attention_distribution000 = exp(1.76)/(exp(1.76) + exp(0.77))\n-    #                              = 0.72908792234\n-    #    attention_distribution001 = exp(0.77)/(exp(1.76) + exp(0.77))\n-    #                              = 0.27091207765\n-    #    attention_distribution002 = 0\n-    #\n-    # Expected tensor of shape [1, 1, 1].\n-    # expected000 = 0.72908792234 * 1.6 + 0.27091207765 * 0.7 - 0 * 0.8\n-    #             = 1.3561791301\n-    expected = np.array([[[1.3561791301]]], dtype=np.float32)\n-    self.assertAllClose(expected, actual)\n-\n-  def test_multi_dim_with_key(self):\n-    # Query tensor of shape [1, 1, 1]\n-    q = np.array([[[1.1]]], dtype=np.float32)\n-    # Value tensor of shape [1, 3, 1]\n-    v = np.array([[[0.5], [0.8], [-0.3]]], dtype=np.float32)\n-    # Key tensor of shape [1, 3, 1]\n-    k = np.array([[[1.6], [0.7], [-0.8]]], dtype=np.float32)\n-    # Value mask tensor of shape [1, 3]\n-    v_mask = np.array([[True, True, False]], dtype=np.bool_)\n-    attention_layer = dense_attention.Attention()\n-    actual = attention_layer([q, v, k], mask=[None, v_mask])\n-\n-    # Expected scores of shape [1, 1, 3]\n-    # scores = [[[1.1*1.6, 1.1*0.7, -1.1*0.8]]] = [[[1.76, 0.77, -0.88]]]\n-    # Expected attention distribution = softmax(scores) with zeros in\n-    # positions where v_mask == False.\n-    # => attention_distribution000 = exp(1.76)/(exp(1.76) + exp(0.77))\n-    #                              = 0.72908792234\n-    #    attention_distribution001 = exp(0.77)/(exp(1.76) + exp(0.77))\n-    #                              = 0.27091207765\n-    #    attention_distribution002 = 0\n-    #\n-    # Expected tensor of shape [1, 1, 1].\n-    # expected000 = 0.72908792234 * 0.5 + 0.27091207765 * 0.8 - 0 * 0.3\n-    #             = 0.58127362329\n-    expected = np.array([[[0.58127362329]]], dtype=np.float32)\n-    self.assertAllClose(expected, actual)\n-\n-  @parameterized.named_parameters(\n-      ('', False),\n-      ('return_attention_scores', True),\n-  )\n-  def test_multi_dim_with_query_mask(self, return_attention_scores):\n-    # Query tensor of shape [1, 2, 1]\n-    q = np.array([[[1.1], [-0.5]]], dtype=np.float32)\n-    # Value tensor of shape [1, 3, 1]\n-    v = np.array([[[1.6], [0.7], [-0.8]]], dtype=np.float32)\n-    # Query mask tensor of shape [1, 2]\n-    q_mask = np.array([[True, False]], dtype=np.bool_)\n-    # Value mask tensor of shape [1, 3]\n-    v_mask = np.array([[True, True, False]], dtype=np.bool_)\n-    attention_layer = dense_attention.Attention()\n-    if return_attention_scores:\n-      actual, actual_scores = attention_layer(\n-          [q, v],\n-          mask=[q_mask, v_mask],\n-          return_attention_scores=return_attention_scores)\n-    else:\n-      actual = attention_layer([q, v],\n-                               mask=[q_mask, v_mask],\n-                               return_attention_scores=return_attention_scores)\n-\n-    # Expected scores of shape [1, 2, 3]\n-    # scores = [[[1.1*1.6, 1.1*0.7, -1.1*0.8], [-0.5*1.6, -0.5*0.7, 0.5*0.8]]]\n-    #        = [[[1.76, 0.77, -0.88], [-0.8, -0.35, 0.4]]]\n-    # Expected attention distribution = softmax(scores) with zeros in\n-    # positions where v_mask == False.\n-    # => attention_distribution000 = exp(1.76)/(exp(1.76) + exp(0.77))\n-    #                              = 0.72908792234\n-    #    attention_distribution001 = exp(0.77)/(exp(1.76) + exp(0.77))\n-    #                              = 0.27091207765\n-    #    attention_distribution002 = 0\n-    # => attention_distribution010 = exp(-0.8)/(exp(-0.8) + exp(-0.35))\n-    #                              = 0.38936076605\n-    #    attention_distribution011 = exp(-0.35)/(exp(-0.8) + exp(-0.35))\n-    #                              = 0.61063923394\n-    #    attention_distribution012 = 0\n-    if return_attention_scores:\n-      expected_scores = np.array([[[0.72908792234, 0.27091207765, 0.],\n-                                   [0.38936076605, 0.61063923394, 0.]]],\n-                                 dtype=np.float32)\n-      self.assertAllClose(expected_scores, actual_scores)\n-    # Expected tensor of shape [1, 2, 1] with zeros where  q_mask == False.\n-    # expected000 = 0.72908792234 * 1.6 + 0.27091207765 * 0.7 - 0 * 0.8\n-    #             = 1.3561791301\n-    # expected000 = 0\n-    expected = np.array([[[1.3561791301], [0.]]], dtype=np.float32)\n-    self.assertAllClose(expected, actual)\n-\n-  def test_scale_None(self):\n-    \"\"\"Tests that scale is None by default.\"\"\"\n-    attention_layer = dense_attention.Attention()\n-    attention_layer.build(input_shape=([1, 1, 1], [1, 1, 1]))\n-    self.assertIsNone(attention_layer.scale)\n-\n-  def test_scale_init_eager(self):\n-    \"\"\"Tests that scale initializes to 1 when use_scale=True.\"\"\"\n-    if not tf.executing_eagerly():\n-      self.skipTest('Only run in eager mode')\n-    attention_layer = dense_attention.Attention(use_scale=True)\n-    attention_layer.build(input_shape=([1, 1, 1], [1, 1, 1]))\n-    self.assertAllClose(1., attention_layer.scale.value())\n-\n-  def test_scale_init_graph(self):\n-    \"\"\"Tests that scale initializes to 1 when use_scale=True.\"\"\"\n-    with self.cached_session() as sess:\n-      attention_layer = dense_attention.Attention(use_scale=True)\n-      attention_layer.build(input_shape=([1, 1, 1], [1, 1, 1]))\n-      sess.run(attention_layer.scale.initializer)\n-      self.assertAllClose(1., attention_layer.scale.value())\n-\n-  @parameterized.named_parameters(\n-      ('', False),\n-      ('return_attention_scores', True),\n-  )\n-  def test_self_attention_causal(self, return_attention_scores):\n-    # Query-value tensor of shape [1, 3, 1]\n-    q = np.array([[[0.5], [0.8], [-0.3]]], dtype=np.float32)\n-    attention_layer = dense_attention.Attention(causal=True)\n-    if return_attention_scores:\n-      actual, actual_scores = attention_layer(\n-          [q, q], return_attention_scores=return_attention_scores)\n-    else:\n-      actual = attention_layer([q, q],\n-                               return_attention_scores=return_attention_scores)\n-\n-    # Expected scores of shape [1, 3, 3]\n-    # scores = [[0.25, 0.4, -0.15], [0.4, 0.64, -0.24], [-0.15, -0.24, 0.09]]\n-    # Expected attention distribution = softmax(scores) lower triangular\n-    # => attention_distribution00 = [1., 0., 0.]\n-    #    attention_distribution01\n-    #      = [exp(0.4), exp(0.64), 0.] / (exp(0.4) + exp(0.64))\n-    #      = [0.44028635073, 0.55971364926, 0.]\n-    #    attention_distribution02\n-    #      = [exp(-0.15), exp(-0.24), exp(0.09)]\n-    #        / (exp(-0.15) + exp(-0.24) + exp(0.09))\n-    #      = [0.31395396638, 0.28693232061, 0.399113713]\n-    if return_attention_scores:\n-      expected_scores = np.array(\n-          [[[1., 0., 0.], [0.44028635073, 0.55971364926, 0.],\n-            [0.31395396638, 0.28693232061, 0.399113713]]],\n-          dtype=np.float32)\n-      self.assertAllClose(expected_scores, actual_scores)\n-    # Expected tensor of shape [1, 3, 1].\n-    # expected000 = 0.5\n-    # expected010 = 0.44028635073 * 0.5 + 0.55971364926 * 0.8\n-    #             = 0.66791409477\n-    # expected020 = 0.31395396638 * 0.5 +0.28693232061 * 0.8 -0.399113713 * 0.3\n-    #             = 0.26678872577\n-    expected = np.array([[[0.5], [0.66791409477], [0.26678872577]]],\n-                        dtype=np.float32)\n-    self.assertAllClose(expected, actual)\n-\n-  def test_inputs_not_list(self):\n-    attention_layer = dense_attention.Attention()\n-    q = np.array([[[1.1]]], dtype=np.float32)\n-    with self.assertRaisesRegex(\n-        ValueError, 'Attention layer must be called on a list of inputs'):\n-      attention_layer(q)\n-\n-  def test_inputs_too_short(self):\n-    attention_layer = dense_attention.Attention()\n-    q = np.array([[[1.1]]], dtype=np.float32)\n-    with self.assertRaisesRegex(\n-        ValueError, 'Attention layer accepts inputs list of length 2 or 3'):\n-      attention_layer([q])\n-\n-  def test_inputs_too_long(self):\n-    attention_layer = dense_attention.Attention()\n-    q = np.array([[[1.1]]], dtype=np.float32)\n-    with self.assertRaisesRegex(\n-        ValueError, 'Attention layer accepts inputs list of length 2 or 3'):\n-      attention_layer([q, q, q, q])\n-\n-  def test_mask_not_list(self):\n-    attention_layer = dense_attention.Attention()\n-    q = np.array([[[1.1]]], dtype=np.float32)\n-    mask = np.array([[True]], dtype=np.bool_)\n-    with self.assertRaisesRegex(ValueError,\n-                                'Attention layer mask must be a list'):\n-      attention_layer([q, q], mask=mask)\n-\n-  def test_mask_too_short(self):\n-    attention_layer = dense_attention.Attention()\n-    q = np.array([[[1.1]]], dtype=np.float32)\n-    mask = np.array([[True]], dtype=np.bool_)\n-    with self.assertRaisesRegex(\n-        ValueError, 'Attention layer mask must be a list of length 2'):\n-      attention_layer([q, q], mask=[mask])\n-\n-  def test_mask_too_long(self):\n-    attention_layer = dense_attention.Attention()\n-    q = np.array([[[1.1]]], dtype=np.float32)\n-    mask = np.array([[True]], dtype=np.bool_)\n-    with self.assertRaisesRegex(\n-        ValueError, 'Attention layer mask must be a list of length 2'):\n-      attention_layer([q, q], mask=[mask, mask, mask])\n-\n-  def test_override_mask(self):\n-    attention_layer = dense_attention.Attention()\n-    q = core.Masking()(np.array([[[1.1]]], dtype=np.float32))\n-    mask = np.array([[False]], dtype=np.bool_)\n-    actual = attention_layer([q, q], mask=[mask, mask])\n-    self.assertAllClose([[[0]]], actual)\n-\n-  def test_implicit_mask(self):\n-    attention_layer = dense_attention.Attention()\n-    q = core.Masking(1.1)(np.array([[[1.1], [1]]], dtype=np.float32))\n-    v = core.Masking(1.2)(np.array([[[1.2], [1]]], dtype=np.float32))\n-    actual = attention_layer([q, v])\n-    self.assertAllClose([[[0], [1]]], actual)\n-\n-  @parameterized.named_parameters(\n-      ('', False),\n-      ('use_scale', True),\n-  )\n-  def test_serialization(self, use_scale):\n-    # Test serialization with use_scale\n-    layer = dense_attention.Attention(use_scale=use_scale)\n-\n-    config = keras.layers.serialize(layer)\n-    new_layer = keras.layers.deserialize(config)\n-    self.assertEqual(new_layer.use_scale, use_scale)\n-\n-    config = layer.get_config()\n-    new_layer = dense_attention.Attention.from_config(config)\n-    self.assertEqual(new_layer.use_scale, use_scale)\n-\n-\n-@combinations.generate(combinations.combine(mode=['graph', 'eager']))\n-class AdditiveAttentionTest(tf.test.TestCase, parameterized.TestCase):\n-\n-  def test_calculate_scores_one_dim(self):\n-    # Query tensor of shape [1, 1, 1]\n-    q = np.array([[[1.1]]], dtype=np.float32)\n-    # Key tensor of shape [1, 1, 1]\n-    k = np.array([[[1.6]]], dtype=np.float32)\n-    attention_layer = dense_attention.AdditiveAttention()\n-    attention_layer.build(input_shape=([1, 1, 1], [1, 1, 1]))\n-    # Scale tensor of shape [1]\n-    attention_layer.scale = np.array([[[0.5]]], dtype=np.float32)\n-    actual = attention_layer._calculate_scores(query=q, key=k)\n-\n-    # Expected tensor of shape [1, 1, 1].\n-    # expected000 = 0.5 * tanh(1.1 + 1.6) = 0.49550372683\n-    expected = np.array([[[0.49550372683]]], dtype=np.float32)\n-    self.assertAllClose(expected, actual)\n-\n-  def test_calculate_scores_multi_dim(self):\n-    # Query tensor of shape [1, 2, 4]\n-    q = np.array([[[1., 1.1, 1.2, 1.3], [2., 2.1, 2.2, 2.3]]], dtype=np.float32)\n-    # Key tensor of shape [1, 3, 4]\n-    k = np.array(\n-        [[[1.5, 1.6, 1.7, 1.8], [2.5, 2.6, 2.7, 2.8], [3.5, 3.6, 3.7, 3.8]]],\n-        dtype=np.float32)\n-    attention_layer = dense_attention.AdditiveAttention()\n-    attention_layer.build(input_shape=([1, 2, 4], [1, 3, 4]))\n-    # Scale tensor of shape [4]\n-    attention_layer.scale = np.array([[[0.5, 0.6, 0.7, 0.8]]], dtype=np.float32)\n-    actual = attention_layer._calculate_scores(query=q, key=k)\n-\n-    # pylint:disable=line-too-long\n-    # expected000 = 0.5*tanh(1.+1.5) + 0.6*tanh(1.1+1.6) + 0.7*tanh(1.2+1.7) + 0.8*tanh(1.3+1.8) = 2.58044532581\n-    # expected001 = 0.5*tanh(1.+2.5) + 0.6*tanh(1.1+2.6) + 0.7*tanh(1.2+2.7) + 0.8*tanh(1.3+2.8) = 2.59734317449\n-    # expected002 = 0.5*tanh(1.+3.5) + 0.6*tanh(1.1+3.6) + 0.7*tanh(1.2+3.7) + 0.8*tanh(1.3+3.8) = 2.59964024652\n-    # expected010 = 0.5*tanh(2.+1.5) + 0.6*tanh(2.1+1.6) + 0.7*tanh(2.2+1.7) + 0.8*tanh(2.3+1.8) = 2.59734317449\n-    # expected011 = 0.5*tanh(2.+2.5) + 0.6*tanh(2.1+2.6) + 0.7*tanh(2.2+2.7) + 0.8*tanh(2.3+2.8) = 2.59964024652\n-    # expected012 = 0.5*tanh(2.+3.5) + 0.6*tanh(2.1+3.6) + 0.7*tanh(2.2+3.7) + 0.8*tanh(2.3+3.8) = 2.59995130916\n-    # pylint:enable=line-too-long\n-    expected = np.array([[[2.58044532581, 2.59734317449, 2.59964024652],\n-                          [2.59734317449, 2.59964024652, 2.59995130916]]],\n-                        dtype=np.float32)\n-    self.assertAllClose(expected, actual)\n-\n-  def test_calculate_scores_one_dim_batch_size_two(self):\n-    # Query tensor of shape [2, 1, 1]\n-    q = np.array([[[1.1]], [[2.1]]], dtype=np.float32)\n-    # Key tensor of shape [2, 1, 1]\n-    k = np.array([[[1.6]], [[2.6]]], dtype=np.float32)\n-    attention_layer = dense_attention.AdditiveAttention()\n-    attention_layer.build(input_shape=([2, 1, 1], [2, 1, 1]))\n-    # Scale tensor of shape [1]\n-    attention_layer.scale = np.array([[[0.5]]], dtype=np.float32)\n-    actual = attention_layer._calculate_scores(query=q, key=k)\n-\n-    # Expected tensor of shape [2, 1, 1].\n-    # expected000 = 0.5 * tanh(1.1 + 1.6) = 0.49550372683\n-    # expected100 = 0.5 * tanh(2.1 + 2.6) = 0.49991728277\n-    expected = np.array([[[0.49550372683]], [[0.49991728277]]],\n-                        dtype=np.float32)\n-    self.assertAllClose(expected, actual)\n-\n-  def test_shape(self):\n-    # Query tensor of shape [1, 2, 4]\n-    q = np.array([[[1., 1.1, 1.2, 1.3], [2., 2.1, 2.2, 2.3]]], dtype=np.float32)\n-    # Value tensor of shape [1, 3, 4]\n-    v = np.array(\n-        [[[1.5, 1.6, 1.7, 1.8], [2.5, 2.6, 2.7, 2.8], [3.5, 3.6, 3.7, 3.8]]],\n-        dtype=np.float32)\n-    # Value mask tensor of shape [1, 3]\n-    v_mask = np.array([[True, True, False]], dtype=np.bool_)\n-    attention_layer = dense_attention.AdditiveAttention()\n-    actual = attention_layer([q, v], mask=[None, v_mask])\n-\n-    expected_shape = [1, 2, 4]\n-    self.assertAllEqual(expected_shape, tf.shape(actual))\n-\n-  def test_shape_no_scale(self):\n-    # Query tensor of shape [1, 2, 4]\n-    q = np.array([[[1., 1.1, 1.2, 1.3], [2., 2.1, 2.2, 2.3]]], dtype=np.float32)\n-    # Value tensor of shape [1, 3, 4]\n-    v = np.array(\n-        [[[1.5, 1.6, 1.7, 1.8], [2.5, 2.6, 2.7, 2.8], [3.5, 3.6, 3.7, 3.8]]],\n-        dtype=np.float32)\n-    # Value mask tensor of shape [1, 3]\n-    v_mask = np.array([[True, True, False]], dtype=np.bool_)\n-    attention_layer = dense_attention.AdditiveAttention(use_scale=False)\n-    actual = attention_layer([q, v], mask=[None, v_mask])\n-\n-    expected_shape = [1, 2, 4]\n-    self.assertAllEqual(expected_shape, tf.shape(actual))\n-\n-  def test_shape_with_key(self):\n-    # Query tensor of shape [1, 2, 4]\n-    q = np.array([[[1., 1.1, 1.2, 1.3], [2., 2.1, 2.2, 2.3]]], dtype=np.float32)\n-    # Value tensor of shape [1, 3, 4]\n-    v = np.array(\n-        [[[1.5, 1.6, 1.7, 1.8], [2.5, 2.6, 2.7, 2.8], [3.5, 3.6, 3.7, 3.8]]],\n-        dtype=np.float32)\n-    # Key tensor of shape [1, 3, 4]\n-    k = np.array(\n-        [[[1.5, 1.6, 1.7, 1.8], [2.5, 2.6, 2.7, 2.8], [3.5, 3.6, 3.7, 3.8]]],\n-        dtype=np.float32)\n-    # Value mask tensor of shape [1, 3]\n-    v_mask = np.array([[True, True, False]], dtype=np.bool_)\n-    attention_layer = dense_attention.AdditiveAttention()\n-    actual = attention_layer([q, v, k], mask=[None, v_mask])\n-\n-    expected_shape = [1, 2, 4]\n-    self.assertAllEqual(expected_shape, tf.shape(actual))\n-\n-  def test_multi_dim(self):\n-    # Query tensor of shape [1, 1, 1]\n-    q = np.array([[[1.1]]], dtype=np.float32)\n-    # Value tensor of shape [1, 3, 1]\n-    v = np.array([[[1.6], [0.7], [-0.8]]], dtype=np.float32)\n-    # Value mask tensor of shape [1, 3]\n-    v_mask = np.array([[True, True, False]], dtype=np.bool_)\n-    attention_layer = dense_attention.AdditiveAttention()\n-    attention_layer.build(input_shape=([1, 1, 1], [1, 3, 1]))\n-    # Scale tensor of shape [1]\n-    attention_layer.scale = np.array([[[0.5]]], dtype=np.float32)\n-    actual = attention_layer([q, v], mask=[None, v_mask])\n-\n-    # pylint:disable=line-too-long\n-    # Expected scores of shape [1, 1, 3]\n-    # scores = [[[0.5 * tanh(1.1 + 1.6), 0.5 * tanh(1.1 + 0.7), 0.5 * tanh(1.1 - 0.8)]]]\n-    #        = [[[0.49550372683, 0.47340300642, 0.14565630622]]]\n-    # Expected attention distribution = softmax(scores) with zeros in\n-    # positions where v_mask == False.\n-    # => attention_distribution000\n-    #      = exp(0.49550372683)/(exp(0.49550372683) + exp(0.47340300642))\n-    #      = 0.50552495521\n-    #    attention_distribution001\n-    #      = exp(0.47340300642)/(exp(0.49550372683) + exp(0.47340300642))\n-    #      = 0.49447504478\n-    #    attention_distribution002 = 0\n-    #\n-    # Expected tensor of shape [1, 1, 1].\n-    # expected000 = 0.50552495521 * 1.6 + 0.49447504478 * 0.7 - 0 * 0.8\n-    #             = 1.15497245968\n-    # pylint:enable=line-too-long\n-    expected = np.array([[[1.15497245968]]], dtype=np.float32)\n-    self.assertAllClose(expected, actual)\n-\n-  def test_multi_dim_with_key(self):\n-    # Query tensor of shape [1, 1, 1]\n-    q = np.array([[[1.1]]], dtype=np.float32)\n-    # Value tensor of shape [1, 3, 1]\n-    v = np.array([[[0.5], [0.8], [-0.3]]], dtype=np.float32)\n-    # Key tensor of shape [1, 3, 1]\n-    k = np.array([[[1.6], [0.7], [-0.8]]], dtype=np.float32)\n-    # Value mask tensor of shape [1, 3]\n-    v_mask = np.array([[True, True, False]], dtype=np.bool_)\n-    attention_layer = dense_attention.AdditiveAttention()\n-    attention_layer.build(input_shape=([1, 1, 1], [1, 3, 1]))\n-    # Scale tensor of shape [1]\n-    attention_layer.scale = np.array([[[0.5]]], dtype=np.float32)\n-    actual = attention_layer([q, v, k], mask=[None, v_mask])\n-\n-    # pylint:disable=line-too-long\n-    # Expected scores of shape [1, 1, 3]\n-    # scores = [[[0.5 * tanh(1.1 + 1.6), 0.5 * tanh(1.1 + 0.7), 0.5 * tanh(1.1 - 0.8)]]]\n-    #        = [[[0.49550372683, 0.47340300642, 0.14565630622]]]\n-    # Expected attention distribution = softmax(scores) with zeros in\n-    # positions where v_mask == False.\n-    # => attention_distribution000\n-    #        = exp(0.49550372683)/(exp(0.49550372683) + exp(0.47340300642))\n-    #        = 0.50552495521\n-    #    attention_distribution001\n-    #        = exp(0.47340300642)/(exp(0.49550372683) + exp(0.47340300642))\n-    #        = 0.49447504478\n-    #    attention_distribution002 = 0\n-    #\n-    # Expected tensor of shape [1, 1, 1].\n-    # expected000 = 0.50552495521 * 0.5 + 0.49447504478 * 0.8 - 0 * 0.3\n-    #             = 0.64834251342\n-    # pylint:enable=line-too-long\n-    expected = np.array([[[0.64834251342]]], dtype=np.float32)\n-    self.assertAllClose(expected, actual)\n-\n-  def test_multi_dim_with_query_mask(self):\n-    # Query tensor of shape [1, 2, 1]\n-    q = np.array([[[1.1], [-0.5]]], dtype=np.float32)\n-    # Value tensor of shape [1, 3, 1]\n-    v = np.array([[[1.6], [0.7], [-0.8]]], dtype=np.float32)\n-    # Query mask tensor of shape [1, 2]\n-    q_mask = np.array([[True, False]], dtype=np.bool_)\n-    # Value mask tensor of shape [1, 3]\n-    v_mask = np.array([[True, True, False]], dtype=np.bool_)\n-    attention_layer = dense_attention.AdditiveAttention()\n-    attention_layer.build(input_shape=([1, 1, 1], [1, 3, 1]))\n-    # Scale tensor of shape [1]\n-    attention_layer.scale = np.array([[[0.5]]], dtype=np.float32)\n-    actual = attention_layer([q, v], mask=[q_mask, v_mask])\n-\n-    # pylint:disable=line-too-long\n-    # Expected scores of shape [1, 2, 3]\n-    # scores = [[[0.5 * tanh(1.1 + 1.6), 0.5 * tanh(1.1 + 0.7), 0.5 * tanh(1.1 - 0.8)],\n-    #            [0.5 * tanh(-0.5 + 1.6), 0.5 * tanh(-0.5 + 0.7), 0.5 * tanh(-0.5 - 0.8)]]]\n-    #        = [[[0.49550372683, 0.47340300642, 0.14565630622],\n-    #            [0.40024951088, 0.09868766011, -0.43086157965]]]\n-    # Expected attention distribution = softmax(scores) with zeros in\n-    # positions where v_mask == False.\n-    # => attention_distribution000\n-    #        = exp(0.49550372683)/(exp(0.49550372683) + exp(0.47340300642))\n-    #        = 0.50552495521\n-    #    attention_distribution001\n-    #        = exp(0.47340300642)/(exp(0.49550372683) + exp(0.47340300642))\n-    #        = 0.49447504478\n-    #    attention_distribution002 = 0\n-    # => attention_distribution010\n-    #        = exp(0.40024951088)/(exp(0.40024951088) + exp(0.09868766011))\n-    #        = 0.57482427975\n-    #    attention_distribution011\n-    #        = exp(0.09868766011)/(exp(0.40024951088) + exp(0.09868766011))\n-    #        = 0.42517572025\n-    #    attention_distribution012 = 0\n-    #\n-    # Expected tensor of shape [1, 2, 1] with zeros where  q_mask == False.\n-    # expected000 = 0.50552495521 * 1.6 + 0.49447504478 * 0.7 - 0 * 0.8\n-    #             = 1.15497245968\n-    # expected000 = 0\n-    # pylint:enable=line-too-long\n-    expected = np.array([[[1.15497245968], [0.]]], dtype=np.float32)\n-    self.assertAllClose(expected, actual)\n-\n-  def test_serialization(self):\n-    # Test serialization with use_scale\n-    layer = dense_attention.AdditiveAttention(use_scale=True)\n-\n-    config = keras.layers.serialize(layer)\n-    new_layer = keras.layers.deserialize(config)\n-    self.assertEqual(new_layer.use_scale, True)\n-\n-    config = layer.get_config()\n-    new_layer = dense_attention.AdditiveAttention.from_config(config)\n-    self.assertEqual(new_layer.use_scale, True)\n-\n-  @testing_utils.enable_v2_dtype_behavior\n-  def test_mixed_float16_policy(self):\n-    # Test case for GitHub issue:\n-    # https://github.com/tensorflow/tensorflow/issues/46064\n-    with policy.policy_scope('mixed_float16'):\n-      q = tf.cast(tf.random.uniform((2, 3, 4), seed=1), 'float16')\n-      v = tf.cast(tf.random.uniform((2, 3, 4), seed=2), 'float16')\n-      k = tf.cast(tf.random.uniform((2, 3, 4), seed=3), 'float16')\n-      layer = dense_attention.AdditiveAttention(causal=True)\n-      _ = layer([q, v, k])\n-\n-\n-@combinations.generate(combinations.combine(mode=['graph', 'eager']))\n-class LowerTriangularMaskTest(tf.test.TestCase, parameterized.TestCase):\n-\n-  def test_square_shape(self):\n-    actual = dense_attention._lower_triangular_mask([3, 3])\n-    expected = np.array(\n-        [[True, False, False], [True, True, False], [True, True, True]],\n-        dtype=np.bool_)\n-    self.assertAllEqual(expected, actual)\n-\n-  def test_orthogonal_shape(self):\n-    actual = dense_attention._lower_triangular_mask([3, 2])\n-    expected = np.array([[True, False], [True, True], [True, True]],\n-                        dtype=np.bool_)\n-    self.assertAllEqual(expected, actual)\n-\n-  def test_three_dim(self):\n-    actual = dense_attention._lower_triangular_mask([1, 3, 3])\n-    expected = np.array(\n-        [[[True, False, False], [True, True, False], [True, True, True]]],\n-        dtype=np.bool_)\n-    self.assertAllEqual(expected, actual)\n-\n-\n-if __name__ == '__main__':\n-  tf.test.main()\n\n@@ -22,16 +22,15 @@ from keras.engine import base_layer\n from keras.engine import input_layer\n from keras.engine import input_spec\n from keras.layers import advanced_activations\n+from keras.layers import attention\n from keras.layers import convolutional\n from keras.layers import convolutional_recurrent\n from keras.layers import core\n from keras.layers import cudnn_recurrent\n-from keras.layers import dense_attention\n from keras.layers import einsum_dense\n from keras.layers import embeddings\n from keras.layers import local\n from keras.layers import merging\n-from keras.layers import multi_head_attention\n from keras.layers import noise\n from keras.layers import pooling\n from keras.layers import recurrent\n@@ -58,14 +57,14 @@ from keras.utils import generic_utils\n from keras.utils import tf_inspect as inspect\n from tensorflow.python.util.tf_export import keras_export\n \n-ALL_MODULES = (base_layer, input_layer, advanced_activations, convolutional,\n-               convolutional_recurrent, core, cudnn_recurrent, dense_attention,\n+ALL_MODULES = (base_layer, input_layer, advanced_activations, attention,\n+               convolutional, convolutional_recurrent, core, cudnn_recurrent,\n                embeddings, einsum_dense, local, merging, batch_normalization_v1,\n                layer_normalization, unit_normalization, pooling,\n                image_preprocessing, recurrent, regularization, reshaping,\n                wrappers, hashing, hashed_crossing, category_encoding,\n-               discretization, multi_head_attention, integer_lookup,\n-               preprocessing_normalization, string_lookup, text_vectorization)\n+               discretization, integer_lookup, preprocessing_normalization,\n+               string_lookup, text_vectorization)\n ALL_V2_MODULES = (rnn_cell_wrapper_v2, batch_normalization, layer_normalization,\n                   recurrent_v2)\n # ALL_OBJECTS is meant to be a global mutable. Hence we need to make it\n\n@@ -22,10 +22,10 @@ from keras import keras_parameterized\n from keras import layers\n from keras import models\n from keras.layers import advanced_activations\n+from keras.layers import attention\n from keras.layers import convolutional\n from keras.layers import convolutional_recurrent\n from keras.layers import core\n-from keras.layers import dense_attention\n from keras.layers import embeddings\n from keras.layers import local\n from keras.layers import merging\n@@ -110,9 +110,8 @@ class LayerCorrectnessTest(keras_parameterized.TestCase):\n       ('Activation', lambda: core.Activation('sigmoid'), (2, 2)),\n       ('Reshape', lambda: reshaping.Reshape((1, 4, 1)), (2, 2, 2)),\n       ('Permute', lambda: reshaping.Permute((2, 1)), (2, 2, 2)),\n-      ('Attention', dense_attention.Attention, [(2, 2, 3), (2, 3, 3),\n-                                                (2, 3, 3)]),\n-      ('AdditiveAttention', dense_attention.AdditiveAttention, [(2, 2, 3),\n+      ('Attention', attention.Attention, [(2, 2, 3), (2, 3, 3), (2, 3, 3)]),\n+      ('AdditiveAttention', attention.AdditiveAttention, [(2, 2, 3),\n                                                           (2, 3, 3),\n                                                           (2, 3, 3)]),\n       ('Embedding', lambda: embeddings.Embedding(4, 4),\n@@ -157,11 +156,11 @@ class LayerCorrectnessTest(keras_parameterized.TestCase):\n        (2, 2, 2)),\n       ('Bidirectional',\n        lambda: wrappers.Bidirectional(recurrent.SimpleRNN(units=4)), (2, 2, 2)),\n-      ('AttentionLayerCausal', lambda: dense_attention.Attention(causal=True), [\n+      ('AttentionLayerCausal', lambda: attention.Attention(causal=True), [\n           (2, 2, 3), (2, 3, 3), (2, 3, 3)\n       ]),\n       ('AdditiveAttentionLayerCausal',\n-       lambda: dense_attention.AdditiveAttention(causal=True), [(2, 3, 4),\n+       lambda: attention.AdditiveAttention(causal=True), [(2, 3, 4),\n                                                           (2, 3, 4),\n                                                           (2, 3, 4)]),\n       ('NormalizationAdapt', _create_normalization_layer_with_adapt, (4, 4)),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
