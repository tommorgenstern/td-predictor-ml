{"custom_id": "keras#cc217583b894306f0ccb68c818fc8aff5644466f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 2 | Churn Cumulative: 2796 | Contributors (this commit): 62 | Commits (past 90d): 6 | Contributors (cumulative): 62 | DMM Complexity: 1.0\n\nDIFF:\n@@ -45,6 +45,7 @@ class CallbackList(object):\n \n     def set_model(self, model):\n         for callback in self.callbacks:\n+            if callback.model is None:\n                 callback.set_model(model)\n \n     def on_epoch_begin(self, epoch, logs=None):\n@@ -168,6 +169,7 @@ class Callback(object):\n \n     def __init__(self):\n         self.validation_data = None\n+        self.model = None\n \n     def set_params(self, params):\n         self.params = params\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ae599e2314813f9424df56c35e474fd5ac33863a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 396 | Contributors (this commit): 6 | Commits (past 90d): 4 | Contributors (cumulative): 6 | DMM Complexity: 0.5\n\nDIFF:\n@@ -14,9 +14,8 @@ _IMAGENET_MEAN = None\n \n def _preprocess_numpy_input(x, data_format, mode):\n     if mode == 'tf':\n-        x /= 255.\n-        x -= 0.5\n-        x *= 2.\n+        x /= 127.5\n+        x -= 1.\n         return x\n \n     if data_format == 'channels_first':\n@@ -46,9 +45,8 @@ def _preprocess_symbolic_input(x, data_format, mode):\n     global _IMAGENET_MEAN\n \n     if mode == 'tf':\n-        x /= 255.\n-        x -= 0.5\n-        x *= 2.\n+        x /= 127.5\n+        x -= 1.\n         return x\n \n     if data_format == 'channels_first':\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b00ec66ba948077b61e25cf7dc004857c432b01a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 9027 | Contributors (this commit): 96 | Commits (past 90d): 24 | Contributors (cumulative): 96 | DMM Complexity: None\n\nDIFF:\n@@ -36,7 +36,7 @@ _GRAPH_LEARNING_PHASES = {}\n \n # This dictionary holds a mapping {graph: UID_DICT}.\n # each UID_DICT is a dictionary mapping name prefixes to a current index,\n-# used for generic graph-specific string UIDs\n+# used for generating graph-specific string UIDs\n # for various names (e.g. layer names).\n _GRAPH_UID_DICTS = {}\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#94b86c420f2c8fe484a177a77dbfec76a018bd0a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 74 | Lines Deleted: 35 | Files Changed: 7 | Hunks: 35 | Methods Changed: 7 | Complexity Δ (Sum/Max): 14/2 | Churn Δ: 109 | Churn Cumulative: 3876 | Contributors (this commit): 15 | Commits (past 90d): 23 | Contributors (cumulative): 50 | DMM Complexity: 0.0\n\nDIFF:\n@@ -16,6 +16,7 @@ https://github.com/tensorflow/models/tree/master/research/slim#pre-trained-model\n from __future__ import print_function\n from __future__ import absolute_import\n \n+import os\n import warnings\n \n from ..models import Model\n@@ -197,8 +198,9 @@ def InceptionResNetV2(include_top=True,\n     # Arguments\n         include_top: whether to include the fully-connected\n             layer at the top of the network.\n-        weights: one of `None` (random initialization)\n-            or `'imagenet'` (pre-training on ImageNet).\n+        weights: one of `None` (random initialization),\n+              'imagenet' (pre-training on ImageNet),\n+              or the path to the weights file to be loaded.\n         input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n             to use as image input for the model.\n         input_shape: optional shape tuple, only to be specified\n@@ -228,10 +230,11 @@ def InceptionResNetV2(include_top=True,\n         ValueError: in case of invalid argument for `weights`,\n             or invalid input shape.\n     \"\"\"\n-    if weights not in {'imagenet', None}:\n+    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n         raise ValueError('The `weights` argument should be either '\n-                         '`None` (random initialization) or `imagenet` '\n-                         '(pre-training on ImageNet).')\n+                         '`None` (random initialization), `imagenet` '\n+                         '(pre-training on ImageNet), '\n+                         'or the path to the weights file to be loaded.')\n \n     if weights == 'imagenet' and include_top and classes != 1000:\n         raise ValueError('If using `weights` as imagenet with `include_top`'\n@@ -371,5 +374,7 @@ def InceptionResNetV2(include_top=True,\n                                     cache_subdir='models',\n                                     file_hash='d19885ff4a710c122648d3b5c3b684e4')\n         model.load_weights(weights_path)\n+    elif weights is not None:\n+        model.load_weights(weights)\n \n     return model\n\n@@ -13,6 +13,7 @@ and that the input preprocessing function is also different (same as Xception).\n from __future__ import print_function\n from __future__ import absolute_import\n \n+import os\n import warnings\n \n from ..models import Model\n@@ -104,8 +105,9 @@ def InceptionV3(include_top=True,\n     # Arguments\n         include_top: whether to include the fully-connected\n             layer at the top of the network.\n-        weights: one of `None` (random initialization)\n-            or 'imagenet' (pre-training on ImageNet).\n+        weights: one of `None` (random initialization),\n+              'imagenet' (pre-training on ImageNet),\n+              or the path to the weights file to be loaded.\n         input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n             to use as image input for the model.\n         input_shape: optional shape tuple, only to be specified\n@@ -137,10 +139,11 @@ def InceptionV3(include_top=True,\n         ValueError: in case of invalid argument for `weights`,\n             or invalid input shape.\n     \"\"\"\n-    if weights not in {'imagenet', None}:\n+    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n         raise ValueError('The `weights` argument should be either '\n-                         '`None` (random initialization) or `imagenet` '\n-                         '(pre-training on ImageNet).')\n+                         '`None` (random initialization), `imagenet` '\n+                         '(pre-training on ImageNet), '\n+                         'or the path to the weights file to be loaded.')\n \n     if weights == 'imagenet' and include_top and classes != 1000:\n         raise ValueError('If using `weights` as imagenet with `include_top`'\n@@ -385,6 +388,9 @@ def InceptionV3(include_top=True,\n                 cache_subdir='models',\n                 file_hash='bcbd6486424b2319ff4ef7d526e38f63')\n         model.load_weights(weights_path)\n+    elif weights is not None:\n+        model.load_weights(weights)\n+\n     return model\n \n \n\n@@ -53,6 +53,7 @@ from __future__ import print_function\n from __future__ import absolute_import\n from __future__ import division\n \n+import os\n import warnings\n \n from ..models import Model\n@@ -338,8 +339,9 @@ def MobileNet(input_shape=None,\n         dropout: dropout rate\n         include_top: whether to include the fully-connected\n             layer at the top of the network.\n-        weights: `None` (random initialization) or\n-            `imagenet` (ImageNet weights)\n+        weights: one of `None` (random initialization),\n+              'imagenet' (pre-training on ImageNet),\n+              or the path to the weights file to be loaded.\n         input_tensor: optional Keras tensor (i.e. output of\n             `layers.Input()`)\n             to use as image input for the model.\n@@ -374,10 +376,11 @@ def MobileNet(input_shape=None,\n                            'as other backends do not support '\n                            'depthwise convolution.')\n \n-    if weights not in {'imagenet', None}:\n+    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n         raise ValueError('The `weights` argument should be either '\n-                         '`None` (random initialization) or `imagenet` '\n-                         '(pre-training on ImageNet).')\n+                         '`None` (random initialization), `imagenet` '\n+                         '(pre-training on ImageNet), '\n+                         'or the path to the weights file to be loaded.')\n \n     if weights == 'imagenet' and include_top and classes != 1000:\n         raise ValueError('If using `weights` as ImageNet with `include_top` '\n@@ -531,6 +534,8 @@ def MobileNet(input_shape=None,\n                                     weigh_path,\n                                     cache_subdir='models')\n         model.load_weights(weights_path)\n+    elif weights is not None:\n+        model.load_weights(weights)\n \n     if old_data_format:\n         K.set_image_data_format(old_data_format)\n\n@@ -10,6 +10,7 @@ Adapted from code contributed by BigMoyan.\n from __future__ import print_function\n from __future__ import absolute_import\n \n+import os\n import warnings\n \n from ..layers import Input\n@@ -141,8 +142,9 @@ def ResNet50(include_top=True, weights='imagenet',\n     # Arguments\n         include_top: whether to include the fully-connected\n             layer at the top of the network.\n-        weights: one of `None` (random initialization)\n-            or 'imagenet' (pre-training on ImageNet).\n+        weights: one of `None` (random initialization),\n+              'imagenet' (pre-training on ImageNet),\n+              or the path to the weights file to be loaded.\n         input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n             to use as image input for the model.\n         input_shape: optional shape tuple, only to be specified\n@@ -174,10 +176,11 @@ def ResNet50(include_top=True, weights='imagenet',\n         ValueError: in case of invalid argument for `weights`,\n             or invalid input shape.\n     \"\"\"\n-    if weights not in {'imagenet', None}:\n+    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n         raise ValueError('The `weights` argument should be either '\n-                         '`None` (random initialization) or `imagenet` '\n-                         '(pre-training on ImageNet).')\n+                         '`None` (random initialization), `imagenet` '\n+                         '(pre-training on ImageNet), '\n+                         'or the path to the weights file to be loaded.')\n \n     if weights == 'imagenet' and include_top and classes != 1000:\n         raise ValueError('If using `weights` as imagenet with `include_top`'\n@@ -279,4 +282,7 @@ def ResNet50(include_top=True, weights='imagenet',\n                           '`image_data_format=\"channels_last\"` in '\n                           'your Keras config '\n                           'at ~/.keras/keras.json.')\n+    elif weights is not None:\n+        model.load_weights(weights)\n+\n     return model\n\n@@ -9,6 +9,7 @@\n from __future__ import print_function\n from __future__ import absolute_import\n \n+import os\n import warnings\n \n from ..models import Model\n@@ -52,8 +53,9 @@ def VGG16(include_top=True, weights='imagenet',\n     # Arguments\n         include_top: whether to include the 3 fully-connected\n             layers at the top of the network.\n-        weights: one of `None` (random initialization)\n-            or 'imagenet' (pre-training on ImageNet).\n+        weights: one of `None` (random initialization),\n+              'imagenet' (pre-training on ImageNet),\n+              or the path to the weights file to be loaded.\n         input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n             to use as image input for the model.\n         input_shape: optional shape tuple, only to be specified\n@@ -85,10 +87,11 @@ def VGG16(include_top=True, weights='imagenet',\n         ValueError: in case of invalid argument for `weights`,\n             or invalid input shape.\n     \"\"\"\n-    if weights not in {'imagenet', None}:\n+    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n         raise ValueError('The `weights` argument should be either '\n-                         '`None` (random initialization) or `imagenet` '\n-                         '(pre-training on ImageNet).')\n+                         '`None` (random initialization), `imagenet` '\n+                         '(pre-training on ImageNet), '\n+                         'or the path to the weights file to be loaded.')\n \n     if weights == 'imagenet' and include_top and classes != 1000:\n         raise ValueError('If using `weights` as imagenet with `include_top`'\n@@ -189,4 +192,7 @@ def VGG16(include_top=True, weights='imagenet',\n                               '`image_data_format=\"channels_last\"` in '\n                               'your Keras config '\n                               'at ~/.keras/keras.json.')\n+    elif weights is not None:\n+        model.load_weights(weights)\n+\n     return model\n\n@@ -9,6 +9,7 @@\n from __future__ import print_function\n from __future__ import absolute_import\n \n+import os\n import warnings\n \n from ..models import Model\n@@ -52,8 +53,9 @@ def VGG19(include_top=True, weights='imagenet',\n     # Arguments\n         include_top: whether to include the 3 fully-connected\n             layers at the top of the network.\n-        weights: one of `None` (random initialization)\n-            or 'imagenet' (pre-training on ImageNet).\n+        weights: one of `None` (random initialization),\n+              'imagenet' (pre-training on ImageNet),\n+              or the path to the weights file to be loaded.\n         input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n             to use as image input for the model.\n         input_shape: optional shape tuple, only to be specified\n@@ -85,10 +87,11 @@ def VGG19(include_top=True, weights='imagenet',\n         ValueError: in case of invalid argument for `weights`,\n             or invalid input shape.\n     \"\"\"\n-    if weights not in {'imagenet', None}:\n+    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n         raise ValueError('The `weights` argument should be either '\n-                         '`None` (random initialization) or `imagenet` '\n-                         '(pre-training on ImageNet).')\n+                         '`None` (random initialization), `imagenet` '\n+                         '(pre-training on ImageNet), '\n+                         'or the path to the weights file to be loaded.')\n \n     if weights == 'imagenet' and include_top and classes != 1000:\n         raise ValueError('If using `weights` as imagenet with `include_top`'\n@@ -192,4 +195,7 @@ def VGG19(include_top=True, weights='imagenet',\n                               '`image_data_format=\"channels_last\"` in '\n                               'your Keras config '\n                               'at ~/.keras/keras.json.')\n+    elif weights is not None:\n+        model.load_weights(weights)\n+\n     return model\n\n@@ -20,6 +20,7 @@ due to its reliance on `SeparableConvolution` layers.\n from __future__ import print_function\n from __future__ import absolute_import\n \n+import os\n import warnings\n \n from ..models import Model\n@@ -63,8 +64,9 @@ def Xception(include_top=True, weights='imagenet',\n     # Arguments\n         include_top: whether to include the fully-connected\n             layer at the top of the network.\n-        weights: one of `None` (random initialization)\n-            or 'imagenet' (pre-training on ImageNet).\n+        weights: one of `None` (random initialization),\n+              'imagenet' (pre-training on ImageNet),\n+              or the path to the weights file to be loaded.\n         input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n             to use as image input for the model.\n         input_shape: optional shape tuple, only to be specified\n@@ -97,10 +99,11 @@ def Xception(include_top=True, weights='imagenet',\n         RuntimeError: If attempting to run this model with a\n             backend that does not support separable convolutions.\n     \"\"\"\n-    if weights not in {'imagenet', None}:\n+    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n         raise ValueError('The `weights` argument should be either '\n-                         '`None` (random initialization) or `imagenet` '\n-                         '(pre-training on ImageNet).')\n+                         '`None` (random initialization), `imagenet` '\n+                         '(pre-training on ImageNet), '\n+                         'or the path to the weights file to be loaded.')\n \n     if weights == 'imagenet' and include_top and classes != 1000:\n         raise ValueError('If using `weights` as imagenet with `include_top`'\n@@ -257,6 +260,8 @@ def Xception(include_top=True, weights='imagenet',\n                                     cache_subdir='models',\n                                     file_hash='b0042744bf5b25fce3cb969f33bebb97')\n         model.load_weights(weights_path)\n+    elif weights is not None:\n+        model.load_weights(weights)\n \n     if old_data_format:\n         K.set_image_data_format(old_data_format)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#71df15c84ab73db38a4524b7c0fb7dfac2d14f82", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 23 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 25 | Churn Cumulative: 9157 | Contributors (this commit): 99 | Commits (past 90d): 27 | Contributors (cumulative): 103 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2920,8 +2920,9 @@ def sparse_categorical_crossentropy(target, output, from_logits=False):\n     res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n         labels=targets,\n         logits=logits)\n-    if len(output_shape) == 3:\n-        # if our output includes timesteps we need to reshape\n+    if len(output_shape) >= 3:\n+        # if our output includes timestep dimension\n+        # or spatial dimensions we need to reshape\n         return tf.reshape(res, tf.shape(output)[:-1])\n     else:\n         return res\n\n@@ -68,6 +68,26 @@ def test_sparse_categorical_crossentropy():\n     assert np.isclose(expected_loss, np.mean(loss))\n \n \n+def test_sparse_categorical_crossentropy_4d():\n+    y_pred = K.variable(np.array([[[[0.7, 0.1, 0.2],\n+                                    [0.0, 0.3, 0.7],\n+                                    [0.1, 0.1, 0.8]],\n+                                   [[0.3, 0.7, 0.0],\n+                                    [0.3, 0.4, 0.3],\n+                                    [0.2, 0.5, 0.3]],\n+                                   [[0.8, 0.1, 0.1],\n+                                    [1.0, 0.0, 0.0],\n+                                    [0.4, 0.3, 0.3]]]]))\n+    y_true = K.variable(np.array([[[0, 1, 0],\n+                                   [2, 1, 0],\n+                                   [2, 2, 1]]]))\n+    expected_loss = - (np.log(0.7) + np.log(0.3) + np.log(0.1) +\n+                       np.log(K.epsilon()) + np.log(0.4) + np.log(0.2) +\n+                       np.log(0.1) + np.log(K.epsilon()) + np.log(0.3)) / 9\n+    loss = K.eval(losses.sparse_categorical_crossentropy(y_true, y_pred))\n+    assert np.isclose(expected_loss, np.mean(loss))\n+\n+\n class MSE_MAE_loss:\n     \"\"\"Loss function with internal state, for testing serialization code.\"\"\"\n     def __init__(self, mse_fraction):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4bec1ee434a98fb8c9c62d9ebb6df5d27c9bb72a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 3049 | Contributors (this commit): 18 | Commits (past 90d): 10 | Contributors (cumulative): 18 | DMM Complexity: None\n\nDIFF:\n@@ -906,8 +906,8 @@ class TestBackend(object):\n         mean = 0.\n         std = 1.\n         for k in BACKENDS:\n-            rand = k.eval(k.random_normal((200, 100), mean=mean, stddev=std))\n-            assert rand.shape == (200, 100)\n+            rand = k.eval(k.random_normal((300, 100), mean=mean, stddev=std))\n+            assert rand.shape == (300, 100)\n             assert np.abs(np.mean(rand) - mean) < 0.015\n             assert np.abs(np.std(rand) - std) < 0.015\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9065eff2d38a0d44dabef4ec3cec7edb1c551609", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 213 | Contributors (this commit): 7 | Commits (past 90d): 9 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -9,7 +9,7 @@ def _get_available_devices():\n \n \n def _normalize_device_name(name):\n-    name = '/' + name.lower().split('device:')[1]\n+    name = '/' + ':'.join(name.lower().replace('/', '').split(':')[-2:])\n     return name\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#722f710a5307dfeca8945975f9550a962e60aa4b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 351 | Contributors (this commit): 10 | Commits (past 90d): 4 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -18,7 +18,7 @@ def load_data(path='imdb.npz', num_words=None, skip_top=0,\n             the most frequent words are kept\n         skip_top: skip the top N most frequently occurring words\n             (which may not be informative).\n-        maxlen: truncate sequences after this length.\n+        maxlen: sequences longer than this will be filtered out.\n         seed: random seed for sample shuffling.\n         start_char: The start of a sequence will be marked with this character.\n             Set to 1 because 0 is usually the padding character.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#da1ff3db476c8d0ed4cf794a3c7de1c7caf3f8b5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 1 | Churn Cumulative: 2797 | Contributors (this commit): 62 | Commits (past 90d): 7 | Contributors (cumulative): 62 | DMM Complexity: 0.0\n\nDIFF:\n@@ -45,7 +45,6 @@ class CallbackList(object):\n \n     def set_model(self, model):\n         for callback in self.callbacks:\n-            if callback.model is None:\n             callback.set_model(model)\n \n     def on_epoch_begin(self, epoch, logs=None):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bc14560f02e7231bc1bb1121fe98dadacadb9cfb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 38 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 3 | Methods Changed: 7 | Complexity Δ (Sum/Max): 9/5 | Churn Δ: 39 | Churn Cumulative: 1105 | Contributors (this commit): 26 | Commits (past 90d): 16 | Contributors (cumulative): 31 | DMM Complexity: 0.3333333333333333\n\nDIFF:\n@@ -199,6 +199,27 @@ def func_load(code, defaults=None, closure=None, globs=None):\n         code, defaults, closure = code\n         if isinstance(defaults, list):\n             defaults = tuple(defaults)\n+\n+    def ensure_value_to_cell(value):\n+        \"\"\"Ensures that a value is converted to a python cell object.\n+\n+        # Arguments\n+            value: Any value that needs to be casted to the cell type\n+\n+        # Returns\n+            A value wrapped as a cell object (see function \"func_load\")\n+\n+        \"\"\"\n+        def dummy_fn():\n+            value  # just access it so it gets captured in .__closure__\n+        cell_value = dummy_fn.__closure__[0]\n+        if not isinstance(value, type(cell_value)):\n+            return cell_value\n+        else:\n+            return value\n+\n+    if closure is not None:\n+        closure = tuple(ensure_value_to_cell(_) for _ in closure)\n     raw_code = codecs.decode(code.encode('ascii'), 'base64')\n     code = marshal.loads(raw_code)\n     if globs is None:\n\n@@ -78,9 +78,25 @@ def test_has_arg_positional_only():\n     assert has_arg(pow, 'x') is False\n \n \n-def test_func_dump_and_load():\n+@pytest.mark.parametrize(\n+    'test_funcion_type',\n+    ('simple function', 'closured function'))\n+def test_func_dump_and_load(test_funcion_type):\n+\n+    if test_funcion_type == 'simple function':\n         def test_func():\n             return r'\\u'\n+    elif test_funcion_type == 'closured function':\n+        def get_test_func():\n+            x = r'\\u'\n+\n+            def test_func():\n+                return x\n+            return test_func\n+        test_func = get_test_func()\n+    else:\n+        raise Exception('Unknown test case for test_func_dump_and_load')\n+\n     serialized = func_dump(test_func)\n     deserialized = func_load(serialized)\n     assert deserialized.__code__ == test_func.__code__\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#88594d7f2e219f46b8df4784ce7b2017e0456295", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 5 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 1115 | Contributors (this commit): 26 | Commits (past 90d): 18 | Contributors (cumulative): 31 | DMM Complexity: None\n\nDIFF:\n@@ -212,6 +212,7 @@ def func_load(code, defaults=None, closure=None, globs=None):\n         \"\"\"\n         def dummy_fn():\n             value  # just access it so it gets captured in .__closure__\n+\n         cell_value = dummy_fn.__closure__[0]\n         if not isinstance(value, type(cell_value)):\n             return cell_value\n\n@@ -79,14 +79,15 @@ def test_has_arg_positional_only():\n \n \n @pytest.mark.parametrize(\n-    'test_funcion_type',\n+    'test_function_type',\n     ('simple function', 'closured function'))\n-def test_func_dump_and_load(test_funcion_type):\n+def test_func_dump_and_load(test_function_type):\n \n-    if test_funcion_type == 'simple function':\n+    if test_function_type == 'simple function':\n         def test_func():\n             return r'\\u'\n-    elif test_funcion_type == 'closured function':\n+\n+    elif test_function_type == 'closured function':\n         def get_test_func():\n             x = r'\\u'\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d956d19fccf6de6344c282218f1b027453785fa9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 7 | Churn Cumulative: 530 | Contributors (this commit): 14 | Commits (past 90d): 7 | Contributors (cumulative): 16 | DMM Complexity: 1.0\n\nDIFF:\n@@ -19,7 +19,7 @@ def to_categorical(y, num_classes=None):\n     \"\"\"\n     y = np.array(y, dtype='int')\n     input_shape = y.shape\n-    if input_shape and input_shape[-1] == 1:\n+    if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n         input_shape = tuple(input_shape[:-1])\n     y = y.ravel()\n     if not num_classes:\n\n@@ -7,8 +7,9 @@ from keras.utils import to_categorical\n \n def test_to_categorical():\n     num_classes = 5\n-    shapes = [(3,), (4, 3), (5, 4, 3), (3, 1), (3, 2, 1)]\n-    expected_shapes = [(3, num_classes),\n+    shapes = [(1,), (3,), (4, 3), (5, 4, 3), (3, 1), (3, 2, 1)]\n+    expected_shapes = [(1, num_classes),\n+                       (3, num_classes),\n                        (4, 3, num_classes),\n                        (5, 4, 3, num_classes),\n                        (3, num_classes),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4a58b178073f0ba3b166220f7ebd7d56149bfb20", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 44 | Lines Deleted: 23 | Files Changed: 3 | Hunks: 22 | Methods Changed: 12 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 67 | Churn Cumulative: 2045 | Contributors (this commit): 18 | Commits (past 90d): 22 | Contributors (cumulative): 28 | DMM Complexity: 0.14285714285714285\n\nDIFF:\n@@ -11,6 +11,7 @@ import sys\n import tarfile\n import threading\n import time\n+import traceback\n import zipfile\n from abc import abstractmethod\n from multiprocessing.pool import ThreadPool\n@@ -553,7 +554,7 @@ class OrderedEnqueuer(SequenceEnqueuer):\n                     yield inputs\n         except Exception as e:\n             self.stop()\n-            raise StopIteration(e)\n+            six.raise_from(StopIteration(e), e)\n \n     def _send_sequence(self):\n         \"\"\"Send current Sequence to all workers.\"\"\"\n@@ -614,6 +615,7 @@ class GeneratorEnqueuer(SequenceEnqueuer):\n         self._use_multiprocessing = use_multiprocessing\n         self._threads = []\n         self._stop_event = None\n+        self._manager = None\n         self.queue = None\n         self.seed = seed\n \n@@ -631,18 +633,27 @@ class GeneratorEnqueuer(SequenceEnqueuer):\n                 try:\n                     if self._use_multiprocessing or self.queue.qsize() < max_queue_size:\n                         generator_output = next(self._generator)\n-                        self.queue.put(generator_output)\n+                        self.queue.put((True, generator_output))\n                     else:\n                         time.sleep(self.wait_time)\n                 except StopIteration:\n                     break\n-                except Exception:\n+                except Exception as e:\n+                    # Can't pick tracebacks.\n+                    # As a compromise, print the traceback and pickle None instead.\n+                    if self._use_multiprocessing:\n+                        traceback.print_exc()\n+                        setattr(e, '__traceback__', None)\n+                    elif not hasattr(e, '__traceback__'):\n+                        setattr(e, '__traceback__', sys.exc_info()[2])\n+                    self.queue.put((False, e))\n                     self._stop_event.set()\n-                    raise\n+                    break\n \n         try:\n             if self._use_multiprocessing:\n-                self.queue = multiprocessing.Queue(maxsize=max_queue_size)\n+                self._manager = multiprocessing.Manager()\n+                self.queue = self._manager.Queue(maxsize=max_queue_size)\n                 self._stop_event = multiprocessing.Event()\n             else:\n                 self.queue = queue.Queue()\n@@ -686,9 +697,8 @@ class GeneratorEnqueuer(SequenceEnqueuer):\n                 else:\n                     thread.join(timeout)\n \n-        if self._use_multiprocessing:\n-            if self.queue is not None:\n-                self.queue.close()\n+        if self._manager:\n+            self._manager.shutdown()\n \n         self._threads = []\n         self._stop_event = None\n@@ -704,12 +714,22 @@ class GeneratorEnqueuer(SequenceEnqueuer):\n         \"\"\"\n         while self.is_running():\n             if not self.queue.empty():\n-                inputs = self.queue.get()\n-                if inputs is not None:\n-                    yield inputs\n+                success, value = self.queue.get()\n+                # Rethrow any exceptions found in the queue\n+                if not success:\n+                    six.reraise(value.__class__, value, value.__traceback__)\n+                # Yield regular values\n+                if value is not None:\n+                    yield value\n             else:\n                 all_finished = all([not thread.is_alive() for thread in self._threads])\n                 if all_finished and self.queue.empty():\n                     raise StopIteration()\n                 else:\n                     time.sleep(self.wait_time)\n+\n+        # Make sure to rethrow the first exception in the queue, if any\n+        while not self.queue.empty():\n+            success, value = self.queue.get()\n+            if not success:\n+                six.reraise(value.__class__, value, value.__traceback__)\n\n@@ -182,7 +182,7 @@ def test_generator_enqueuer_fail_threads():\n         FaultSequence()), use_multiprocessing=False)\n     enqueuer.start(3, 10)\n     gen_output = enqueuer.get()\n-    with pytest.raises(StopIteration):\n+    with pytest.raises(IndexError):\n         next(gen_output)\n \n \n@@ -191,7 +191,7 @@ def test_generator_enqueuer_fail_processes():\n         FaultSequence()), use_multiprocessing=True)\n     enqueuer.start(3, 10)\n     gen_output = enqueuer.get()\n-    with pytest.raises(StopIteration):\n+    with pytest.raises(IndexError):\n         next(gen_output)\n \n \n\n@@ -232,7 +232,7 @@ def test_multiprocessing_fit_error():\n         \"\"\"Raises an exception after a few good batches\"\"\"\n         for i in range(good_batches):\n             yield (np.random.randint(batch_size, 256, (50, 2)),\n-                   np.random.randint(batch_size, 2, 50))\n+                   np.random.randint(batch_size, 12, 50))\n         raise RuntimeError\n \n     model = Sequential()\n@@ -241,13 +241,13 @@ def test_multiprocessing_fit_error():\n \n     samples = batch_size * (good_batches + 1)\n \n-    with pytest.raises(StopIteration):\n+    with pytest.raises(RuntimeError):\n         model.fit_generator(\n             custom_generator(), samples, 1,\n             workers=4, use_multiprocessing=True,\n         )\n \n-    with pytest.raises(StopIteration):\n+    with pytest.raises(RuntimeError):\n         model.fit_generator(\n             custom_generator(), samples, 1,\n             use_multiprocessing=False,\n@@ -258,25 +258,26 @@ def test_multiprocessing_fit_error():\n def test_multiprocessing_evaluate_error():\n     batch_size = 10\n     good_batches = 3\n+    workers = 4\n \n     def custom_generator():\n         \"\"\"Raises an exception after a few good batches\"\"\"\n         for i in range(good_batches):\n             yield (np.random.randint(batch_size, 256, (50, 2)),\n-                   np.random.randint(batch_size, 2, 50))\n+                   np.random.randint(batch_size, 12, 50))\n         raise RuntimeError\n \n     model = Sequential()\n     model.add(Dense(1, input_shape=(2, )))\n     model.compile(loss='mse', optimizer='adadelta')\n \n-    with pytest.raises(StopIteration):\n+    with pytest.raises(RuntimeError):\n         model.evaluate_generator(\n-            custom_generator(), good_batches + 1, 1,\n-            workers=4, use_multiprocessing=True,\n+            custom_generator(), good_batches * workers + 1, 1,\n+            workers=workers, use_multiprocessing=True,\n         )\n \n-    with pytest.raises(StopIteration):\n+    with pytest.raises(RuntimeError):\n         model.evaluate_generator(\n             custom_generator(), good_batches + 1, 1,\n             use_multiprocessing=False,\n@@ -299,13 +300,13 @@ def test_multiprocessing_predict_error():\n     model.add(Dense(1, input_shape=(5,)))\n     model.compile(loss='mse', optimizer='adadelta')\n \n-    with pytest.raises(StopIteration):\n+    with pytest.raises(RuntimeError):\n         model.predict_generator(\n             custom_generator(), good_batches * workers + 1, 1,\n             workers=workers, use_multiprocessing=True,\n         )\n \n-    with pytest.raises(StopIteration):\n+    with pytest.raises(RuntimeError):\n         model.predict_generator(\n             custom_generator(), good_batches + 1, 1,\n             use_multiprocessing=False,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#26d5e100148272166868da8f817e1a4fb49e34cc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 405 | Contributors (this commit): 15 | Commits (past 90d): 9 | Contributors (cumulative): 16 | DMM Complexity: None\n\nDIFF:\n@@ -23,4 +23,4 @@ from .layers import Input\n from .models import Model\r\n from .models import Sequential\r\n \r\n-__version__ = '2.1.1'\r\n+__version__ = '2.1.2'\r\n\n@@ -3,12 +3,12 @@ from setuptools import find_packages\n \n \n setup(name='Keras',\n-      version='2.1.1',\n+      version='2.1.2',\n       description='Deep Learning for Python',\n       author='Francois Chollet',\n       author_email='francois.chollet@gmail.com',\n       url='https://github.com/fchollet/keras',\n-      download_url='https://github.com/fchollet/keras/tarball/2.1.1',\n+      download_url='https://github.com/fchollet/keras/tarball/2.1.2',\n       license='MIT',\n       install_requires=['numpy>=1.9.1',\n                         'scipy>=0.14',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#dec0c7b7aeddab2b31b55ccb015d7e0735206d59", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 113 | Lines Deleted: 107 | Files Changed: 4 | Hunks: 21 | Methods Changed: 14 | Complexity Δ (Sum/Max): 0/2 | Churn Δ: 220 | Churn Cumulative: 19173 | Contributors (this commit): 131 | Commits (past 90d): 49 | Contributors (cumulative): 164 | DMM Complexity: 0.0\n\nDIFF:\n@@ -663,6 +663,8 @@ def zeros(shape, dtype=None, name=None):\n \n     # Returns\n         A variable (including Keras metadata), filled with `0.0`.\n+        Note that if `shape` was symbolic, we cannot return a variable,\n+        and will return a dynamically-shaped tensor instead.\n \n     # Example\n     ```python\n@@ -677,12 +679,14 @@ def zeros(shape, dtype=None, name=None):\n     if dtype is None:\n         dtype = floatx()\n     tf_dtype = tf.as_dtype(dtype)\n-    return variable(tf.constant_initializer(0., dtype=tf_dtype)(shape),\n-                    dtype, name)\n+    v = tf.zeros(shape=shape, dtype=tf_dtype, name=name)\n+    if py_all(v.get_shape().as_list()):\n+        return variable(v, dtype=dtype, name=name)\n+    return v\n \n \n def ones(shape, dtype=None, name=None):\n-    \"\"\"Instantiates an all-ones tensor variable and returns it.\n+    \"\"\"Instantiates an all-ones variable and returns it.\n \n     # Arguments\n         shape: Tuple of integers, shape of returned Keras variable.\n@@ -691,6 +695,8 @@ def ones(shape, dtype=None, name=None):\n \n     # Returns\n         A Keras variable, filled with `1.0`.\n+        Note that if `shape` was symbolic, we cannot return a variable,\n+        and will return a dynamically-shaped tensor instead.\n \n     # Example\n     ```python\n@@ -705,8 +711,10 @@ def ones(shape, dtype=None, name=None):\n     if dtype is None:\n         dtype = floatx()\n     tf_dtype = tf.as_dtype(dtype)\n-    return variable(tf.constant_initializer(1., dtype=tf_dtype)(shape),\n-                    dtype, name)\n+    v = tf.ones(shape=shape, dtype=tf_dtype, name=name)\n+    if py_all(v.get_shape().as_list()):\n+        return variable(v, dtype=dtype, name=name)\n+    return v\n \n \n def eye(size, dtype=None, name=None):\n\n@@ -861,37 +861,19 @@ class SimpleRNNCell(Layer):\n             self.bias = None\n         self.built = True\n \n-    def _generate_dropout_mask(self, inputs, training=None):\n-        if 0 < self.dropout < 1:\n-            ones = K.ones_like(K.squeeze(inputs[:, 0:1, :], axis=1))\n-\n-            def dropped_inputs():\n-                return K.dropout(ones, self.dropout)\n-\n-            self._dropout_mask = K.in_train_phase(\n-                dropped_inputs,\n-                ones,\n-                training=training)\n-        else:\n-            self._dropout_mask = None\n-\n-    def _generate_recurrent_dropout_mask(self, inputs, training=None):\n-        if 0 < self.recurrent_dropout < 1:\n-            ones = K.ones_like(K.reshape(inputs[:, 0, 0], (-1, 1)))\n-            ones = K.tile(ones, (1, self.units))\n-\n-            def dropped_inputs():\n-                return K.dropout(ones, self.dropout)\n-\n-            self._recurrent_dropout_mask = K.in_train_phase(\n-                dropped_inputs,\n-                ones,\n-                training=training)\n-        else:\n-            self._recurrent_dropout_mask = None\n-\n     def call(self, inputs, states, training=None):\n         prev_output = states[0]\n+        if 0 < self.dropout < 1 and self._dropout_mask is None:\n+            self._dropout_mask = _generate_dropout_mask(K.shape(inputs),\n+                                                        self.dropout,\n+                                                        training=training)\n+        if (0 < self.recurrent_dropout < 1 and\n+                self._recurrent_dropout_mask is None):\n+            self._recurrent_dropout_mask = _generate_dropout_mask(\n+                [K.shape(inputs)[0], self.units],\n+                self.recurrent_dropout,\n+                training=training)\n+\n         dp_mask = self._dropout_mask\n         rec_dp_mask = self._recurrent_dropout_mask\n \n@@ -1011,7 +993,15 @@ class SimpleRNN(RNN):\n                     'when using dynamic RNNs (i.e. non-unrolled). '\n                     'You can either set `unroll=True`, '\n                     'set `dropout` and `recurrent_dropout` to 0, '\n-                    'or use a different backend.')\n+                    'or use the TensorFlow backend.')\n+                dropout = 0.\n+                recurrent_dropout = 0.\n+        if K.backend() == 'theano':\n+            warnings.warn(\n+                'RNN dropout is no longer supported with the Theano backend '\n+                'due to technical limitations. '\n+                'You can either set `dropout` and `recurrent_dropout` to 0, '\n+                'or use the TensorFlow backend.')\n             dropout = 0.\n             recurrent_dropout = 0.\n \n@@ -1039,8 +1029,6 @@ class SimpleRNN(RNN):\n         self.activity_regularizer = regularizers.get(activity_regularizer)\n \n     def call(self, inputs, mask=None, training=None, initial_state=None):\n-        self.cell._generate_dropout_mask(inputs, training=training)\n-        self.cell._generate_recurrent_dropout_mask(inputs, training=training)\n         return super(SimpleRNN, self).call(inputs,\n                                            mask=mask,\n                                            training=training,\n@@ -1265,40 +1253,22 @@ class GRUCell(Layer):\n             self.bias_h = None\n         self.built = True\n \n-    def _generate_dropout_mask(self, inputs, training=None):\n-        if 0 < self.dropout < 1:\n-            ones = K.ones_like(K.squeeze(inputs[:, 0:1, :], axis=1))\n-\n-            def dropped_inputs():\n-                return K.dropout(ones, self.dropout)\n-\n-            self._dropout_mask = [K.in_train_phase(\n-                dropped_inputs,\n-                ones,\n-                training=training)\n-                for _ in range(3)]\n-        else:\n-            self._dropout_mask = None\n-\n-    def _generate_recurrent_dropout_mask(self, inputs, training=None):\n-        if 0 < self.recurrent_dropout < 1:\n-            ones = K.ones_like(K.reshape(inputs[:, 0, 0], (-1, 1)))\n-            ones = K.tile(ones, (1, self.units))\n-\n-            def dropped_inputs():\n-                return K.dropout(ones, self.dropout)\n-\n-            self._recurrent_dropout_mask = [K.in_train_phase(\n-                dropped_inputs,\n-                ones,\n-                training=training)\n-                for _ in range(3)]\n-        else:\n-            self._recurrent_dropout_mask = None\n-\n     def call(self, inputs, states, training=None):\n         h_tm1 = states[0]  # previous memory\n \n+        if 0 < self.dropout < 1 and self._dropout_mask is None:\n+            self._dropout_mask = _generate_dropout_mask(K.shape(inputs),\n+                                                        self.dropout,\n+                                                        training=training,\n+                                                        count=3)\n+        if (0 < self.recurrent_dropout < 1 and\n+                self._recurrent_dropout_mask is None):\n+            self._recurrent_dropout_mask = _generate_dropout_mask(\n+                [K.shape(inputs)[0], self.units],\n+                self.recurrent_dropout,\n+                training=training,\n+                count=3)\n+\n         # dropout matrices for input units\n         dp_mask = self._dropout_mask\n         # dropout matrices for recurrent units\n@@ -1480,6 +1450,14 @@ class GRU(RNN):\n                     'or use a different backend.')\n                 dropout = 0.\n                 recurrent_dropout = 0.\n+        if K.backend() == 'theano':\n+            warnings.warn(\n+                'RNN dropout is no longer supported with the Theano backend '\n+                'due to technical limitations. '\n+                'You can either set `dropout` and `recurrent_dropout` to 0, '\n+                'or use the TensorFlow backend.')\n+            dropout = 0.\n+            recurrent_dropout = 0.\n \n         cell = GRUCell(units,\n                        activation=activation,\n@@ -1507,8 +1485,6 @@ class GRU(RNN):\n         self.activity_regularizer = regularizers.get(activity_regularizer)\n \n     def call(self, inputs, mask=None, training=None, initial_state=None):\n-        self.cell._generate_dropout_mask(inputs, training=training)\n-        self.cell._generate_recurrent_dropout_mask(inputs, training=training)\n         return super(GRU, self).call(inputs,\n                                      mask=mask,\n                                      training=training,\n@@ -1761,38 +1737,20 @@ class LSTMCell(Layer):\n             self.bias_o = None\n         self.built = True\n \n-    def _generate_dropout_mask(self, inputs, training=None):\n-        if 0 < self.dropout < 1:\n-            ones = K.ones_like(K.squeeze(inputs[:, 0:1, :], axis=1))\n-\n-            def dropped_inputs():\n-                return K.dropout(ones, self.dropout)\n-\n-            self._dropout_mask = [K.in_train_phase(\n-                dropped_inputs,\n-                ones,\n-                training=training)\n-                for _ in range(4)]\n-        else:\n-            self._dropout_mask = None\n-\n-    def _generate_recurrent_dropout_mask(self, inputs, training=None):\n-        if 0 < self.recurrent_dropout < 1:\n-            ones = K.ones_like(K.reshape(inputs[:, 0, 0], (-1, 1)))\n-            ones = K.tile(ones, (1, self.units))\n-\n-            def dropped_inputs():\n-                return K.dropout(ones, self.dropout)\n-\n-            self._recurrent_dropout_mask = [K.in_train_phase(\n-                dropped_inputs,\n-                ones,\n-                training=training)\n-                for _ in range(4)]\n-        else:\n-            self._recurrent_dropout_mask = None\n-\n     def call(self, inputs, states, training=None):\n+        if 0 < self.dropout < 1 and self._dropout_mask is None:\n+            self._dropout_mask = _generate_dropout_mask(K.shape(inputs),\n+                                                        self.dropout,\n+                                                        training=training,\n+                                                        count=4)\n+        if (0 < self.recurrent_dropout < 1 and\n+                self._recurrent_dropout_mask is None):\n+            self._recurrent_dropout_mask = _generate_dropout_mask(\n+                [K.shape(inputs)[0], self.units],\n+                self.recurrent_dropout,\n+                training=training,\n+                count=4)\n+\n         # dropout matrices for input units\n         dp_mask = self._dropout_mask\n         # dropout matrices for recurrent units\n@@ -1987,6 +1945,14 @@ class LSTM(RNN):\n                     'or use a different backend.')\n                 dropout = 0.\n                 recurrent_dropout = 0.\n+        if K.backend() == 'theano':\n+            warnings.warn(\n+                'RNN dropout is no longer supported with the Theano backend '\n+                'due to technical limitations. '\n+                'You can either set `dropout` and `recurrent_dropout` to 0, '\n+                'or use the TensorFlow backend.')\n+            dropout = 0.\n+            recurrent_dropout = 0.\n \n         cell = LSTMCell(units,\n                         activation=activation,\n@@ -2015,8 +1981,6 @@ class LSTM(RNN):\n         self.activity_regularizer = regularizers.get(activity_regularizer)\n \n     def call(self, inputs, mask=None, training=None, initial_state=None):\n-        self.cell._generate_dropout_mask(inputs, training=training)\n-        self.cell._generate_recurrent_dropout_mask(inputs, training=training)\n         return super(LSTM, self).call(inputs,\n                                       mask=mask,\n                                       training=training,\n@@ -2118,3 +2082,20 @@ class LSTM(RNN):\n         if 'implementation' in config and config['implementation'] == 0:\n             config['implementation'] = 1\n         return cls(**config)\n+\n+\n+def _generate_dropout_mask(shape, rate, training=None, count=1):\n+    ones = K.ones(shape)\n+\n+    def dropped_inputs():\n+        return K.dropout(ones, rate)\n+\n+    if count > 1:\n+        return [K.in_train_phase(\n+            dropped_inputs,\n+            ones,\n+            training=training) for _ in range(count)]\n+    return K.in_train_phase(\n+        dropped_inputs,\n+        ones,\n+        training=training)\n\n@@ -70,8 +70,8 @@ def test_stateful_invalid_use(layer_class):\n \n \n @rnn_test\n-@pytest.mark.skipif((K.backend() == 'cntk'),\n-                    reason='Not yet supported.')\n+@pytest.mark.skipif((K.backend() in ['cntk', 'theano']),\n+                    reason='Not supported.')\n def test_dropout(layer_class):\n     for unroll in [True, False]:\n         layer_test(layer_class,\n@@ -556,6 +556,23 @@ def test_minimal_rnn_cell_layer():\n     assert_allclose(y_np, y_np_2, atol=1e-4)\n \n \n+@keras_test\n+@pytest.mark.skipif((K.backend() in ['cntk', 'theano']),\n+                    reason='Not supported.')\n+def test_stacked_rnn_dropout():\n+    cells = [recurrent.LSTMCell(3, dropout=0.1, recurrent_dropout=0.1),\n+             recurrent.LSTMCell(3, dropout=0.1, recurrent_dropout=0.1)]\n+    layer = recurrent.RNN(cells)\n+\n+    x = keras.Input((None, 5))\n+    y = layer(x)\n+    model = keras.models.Model(x, y)\n+    model.compile('sgd', 'mse')\n+    x_np = np.random.random((6, 5, 5))\n+    y_np = np.random.random((6, 3))\n+    model.train_on_batch(x_np, y_np)\n+\n+\n @keras_test\n def test_stacked_rnn_attributes():\n     cells = [recurrent.LSTMCell(3),\n\n@@ -199,8 +199,8 @@ def test_Bidirectional():\n         outputs = wrappers.Bidirectional(rnn(output_dim, dropout=dropout_rate,\n                                              recurrent_dropout=dropout_rate),\n                                          merge_mode=mode)(inputs)\n-        if dropout_rate and K.backend() != 'cntk':\n-            # Dropout is disabled with CNTK for now.\n+        if dropout_rate and K.backend() == 'tensorflow':\n+            # Dropout is disabled with CNTK/Theano.\n             assert outputs._uses_learning_phase\n         model = Model(inputs, outputs)\n         model.compile(loss='mse', optimizer='sgd')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
