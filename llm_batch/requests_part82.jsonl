{"custom_id": "requests#adf475ef82cbd29f63814c0626f64926deb2355b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 905 | Contributors (this commit): 26 | Commits (past 90d): 11 | Contributors (cumulative): 26 | DMM Complexity: None\n\nDIFF:\n@@ -64,7 +64,9 @@ class HTTPAdapter(BaseAdapter):\n         should attempt. Note, this applies only to failed DNS lookups, socket\n         connections and connection timeouts, never to requests where data has\n         made it to the server. By default, Requests does not retry failed\n-        connections.\n+        connections. If you need granular control over the conditions under\n+        which we retry a request, import urllib3's ``Retry`` class and pass\n+        that instead.\n     :param pool_block: Whether the connection pool should block for connections.\n \n     Usage::\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#087a27aba97d3eac017d321e37bf1970f8833c1a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 18 | Lines Deleted: 10 | Files Changed: 2 | Hunks: 5 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/1 | Churn Δ: 28 | Churn Cumulative: 14098 | Contributors (this commit): 174 | Commits (past 90d): 36 | Contributors (cumulative): 228 | DMM Complexity: 0.0\n\nDIFF:\n@@ -20,7 +20,7 @@ from .packages.urllib3.fields import RequestField\n from .packages.urllib3.filepost import encode_multipart_formdata\n from .packages.urllib3.util import parse_url\n from .packages.urllib3.exceptions import (\n-    DecodeError, ReadTimeoutError, ProtocolError)\n+    DecodeError, ReadTimeoutError, ProtocolError, LocationParseError)\n from .exceptions import (\n     HTTPError, RequestException, MissingSchema, InvalidURL, \n     ChunkedEncodingError, ContentDecodingError, ConnectionError, \n@@ -351,7 +351,10 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n             return\n \n         # Support for unicode domain names and paths.\n+        try:\n             scheme, auth, host, port, path, query, fragment = parse_url(url)\n+        except LocationParseError as e:\n+            raise ConnectionError(e.message)\n \n         if not scheme:\n             raise MissingSchema(\"Invalid URL {0!r}: No schema supplied. \"\n\n@@ -309,6 +309,11 @@ class RequestsTestCase(unittest.TestCase):\n         with pytest.raises(ConnectionError):\n             requests.get(\"http://httpbin.org:1\")\n \n+    def test_LocationParseError(self):\n+        \"\"\"Inputing a URL that cannot be parsed should raise a ConnectionError\"\"\"\n+        with pytest.raises(ConnectionError):\n+            requests.get(\"http://fe80::5054:ff:fe5a:fc0\")\n+\n     def test_basicauth_with_netrc(self):\n         auth = ('user', 'pass')\n         wrong_auth = ('wronguser', 'wrongpass')\n@@ -820,15 +825,15 @@ class RequestsTestCase(unittest.TestCase):\n         assert str(error) == 'message'\n         assert error.response == response\n \n-    def test_session_pickling(self):\n-        r = requests.Request('GET', httpbin('get'))\n-        s = requests.Session()\n-\n-        s = pickle.loads(pickle.dumps(s))\n-        s.proxies = getproxies()\n-\n-        r = s.send(r.prepare())\n-        assert r.status_code == 200\n+##    def test_session_pickling(self):\n+##        r = requests.Request('GET', httpbin('get'))\n+##        s = requests.Session()\n+##\n+##        s = pickle.loads(pickle.dumps(s))\n+##        s.proxies = getproxies()\n+##\n+##        r = s.send(r.prepare())\n+##        assert r.status_code == 200\n \n     def test_fixes_1329(self):\n         \"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#3246b1fe172ca3d4f098e85467234ded2f833b31", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 14104 | Contributors (this commit): 174 | Commits (past 90d): 37 | Contributors (cumulative): 228 | DMM Complexity: None\n\nDIFF:\n@@ -354,7 +354,7 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n         try:\n             scheme, auth, host, port, path, query, fragment = parse_url(url)\n         except LocationParseError as e:\n-            raise ConnectionError(e.message)\n+            raise InvalidURL(e.message)\n \n         if not scheme:\n             raise MissingSchema(\"Invalid URL {0!r}: No schema supplied. \"\n\n@@ -310,8 +310,8 @@ class RequestsTestCase(unittest.TestCase):\n             requests.get(\"http://httpbin.org:1\")\n \n     def test_LocationParseError(self):\n-        \"\"\"Inputing a URL that cannot be parsed should raise a ConnectionError\"\"\"\n-        with pytest.raises(ConnectionError):\n+        \"\"\"Inputing a URL that cannot be parsed should raise an InvalidURL error\"\"\"\n+        with pytest.raises(InvalidURL):\n             requests.get(\"http://fe80::5054:ff:fe5a:fc0\")\n \n     def test_basicauth_with_netrc(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#c8baf881257ff3194879ad79bef81c27007b4dcf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 15 | Churn Cumulative: 2994 | Contributors (this commit): 59 | Commits (past 90d): 12 | Contributors (cumulative): 59 | DMM Complexity: 1.0\n\nDIFF:\n@@ -36,6 +36,8 @@ from .status_codes import codes\n # formerly defined here, reexposed here for backward compatibility\n from .models import REDIRECT_STATI\n \n+REDIRECT_CACHE_SIZE = 1000\n+\n \n def merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n     \"\"\"\n@@ -274,7 +276,7 @@ class Session(SessionRedirectMixin):\n     __attrs__ = [\n         'headers', 'cookies', 'auth', 'proxies', 'hooks', 'params', 'verify',\n         'cert', 'prefetch', 'adapters', 'stream', 'trust_env',\n-        'max_redirects', 'redirect_cache'\n+        'max_redirects',\n     ]\n \n     def __init__(self):\n@@ -329,7 +331,7 @@ class Session(SessionRedirectMixin):\n         self.mount('http://', HTTPAdapter())\n \n         # Only store 1000 redirects to prevent using infinite memory\n-        self.redirect_cache = RecentlyUsedContainer(1000)\n+        self.redirect_cache = RecentlyUsedContainer(REDIRECT_CACHE_SIZE)\n \n     def __enter__(self):\n         return self\n@@ -660,12 +662,19 @@ class Session(SessionRedirectMixin):\n             self.adapters[key] = self.adapters.pop(key)\n \n     def __getstate__(self):\n-        return dict((attr, getattr(self, attr, None)) for attr in self.__attrs__)\n+        state = dict((attr, getattr(self, attr, None)) for attr in self.__attrs__)\n+        state['redirect_cache'] = dict(self.redirect_cache)\n+        return state\n \n     def __setstate__(self, state):\n+        redirect_cache = state.pop('redirect_cache', {})\n         for attr, value in state.items():\n             setattr(self, attr, value)\n \n+        self.redirect_cache = RecentlyUsedContainer(REDIRECT_CACHE_SIZE)\n+        for redirect, to in redirect_cache.items():\n+            self.redirect_cache[redirect] = to\n+\n \n def session():\n     \"\"\"Returns a :class:`Session` for context-management.\"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#2a5364cf72fb8156773d6304c0e3e21472de8002", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 2 | Churn Cumulative: 2996 | Contributors (this commit): 59 | Commits (past 90d): 10 | Contributors (cumulative): 59 | DMM Complexity: None\n\nDIFF:\n@@ -129,7 +129,7 @@ class SessionRedirectMixin(object):\n             # Facilitate relative 'location' headers, as allowed by RFC 7231.\n             # (e.g. '/path/to/resource' instead of 'http://domain.tld/path/to/resource')\n             # Compliant with RFC3986, we percent encode the url.\n-            if not urlparse(url).netloc:\n+            if not parsed.netloc:\n                 url = urljoin(resp.url, requote_uri(url))\n             else:\n                 url = requote_uri(url)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#7aa6c62d6d917e11f81b166d1d6c9e60340783ac", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 376 | Lines Deleted: 121 | Files Changed: 17 | Hunks: 77 | Methods Changed: 36 | Complexity Δ (Sum/Max): 23/15 | Churn Δ: 497 | Churn Cumulative: 9643 | Contributors (this commit): 15 | Commits (past 90d): 24 | Contributors (cumulative): 74 | DMM Complexity: 0.35714285714285715\n\nDIFF:\n@@ -15,7 +15,7 @@\n # 02110-1301  USA\n ######################### END LICENSE BLOCK #########################\n \n-__version__ = \"2.2.1\"\n+__version__ = \"2.3.0\"\n from sys import version_info\n \n \n\n@@ -12,34 +12,68 @@ Example::\n If no paths are provided, it takes its input from stdin.\n \n \"\"\"\n-from io import open\n-from sys import argv, stdin\n \n+from __future__ import absolute_import, print_function, unicode_literals\n+\n+import argparse\n+import sys\n+from io import open\n+\n+from chardet import __version__\n from chardet.universaldetector import UniversalDetector\n \n \n-def description_of(file, name='stdin'):\n-    \"\"\"Return a string describing the probable encoding of a file.\"\"\"\n+def description_of(lines, name='stdin'):\n+    \"\"\"\n+    Return a string describing the probable encoding of a file or\n+    list of strings.\n+\n+    :param lines: The lines to get the encoding of.\n+    :type lines: Iterable of bytes\n+    :param name: Name of file or collection of lines\n+    :type name: str\n+    \"\"\"\n     u = UniversalDetector()\n-    for line in file:\n+    for line in lines:\n         u.feed(line)\n     u.close()\n     result = u.result\n     if result['encoding']:\n-        return '%s: %s with confidence %s' % (name,\n-                                              result['encoding'],\n+        return '{0}: {1} with confidence {2}'.format(name, result['encoding'],\n                                                      result['confidence'])\n     else:\n-        return '%s: no result' % name\n+        return '{0}: no result'.format(name)\n \n \n-def main():\n-    if len(argv) <= 1:\n-        print(description_of(stdin))\n-    else:\n-        for path in argv[1:]:\n-            with open(path, 'rb') as f:\n-                print(description_of(f, path))\n+def main(argv=None):\n+    '''\n+    Handles command line arguments and gets things started.\n+\n+    :param argv: List of arguments, as if specified on the command-line.\n+                 If None, ``sys.argv[1:]`` is used instead.\n+    :type argv: list of str\n+    '''\n+    # Get command line arguments\n+    parser = argparse.ArgumentParser(\n+        description=\"Takes one or more file paths and reports their detected \\\n+                     encodings\",\n+        formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n+        conflict_handler='resolve')\n+    parser.add_argument('input',\n+                        help='File whose encoding we would like to determine.',\n+                        type=argparse.FileType('rb'), nargs='*',\n+                        default=[sys.stdin])\n+    parser.add_argument('--version', action='version',\n+                        version='%(prog)s {0}'.format(__version__))\n+    args = parser.parse_args(argv)\n+\n+    for f in args.input:\n+        if f.isatty():\n+            print(\"You are running chardetect interactively. Press \" +\n+                  \"CTRL-D twice at the start of a blank line to signal the \" +\n+                  \"end of your input. If you want help, run chardetect \" +\n+                  \"--help\\n\", file=sys.stderr)\n+        print(description_of(f, f.name))\n \n \n if __name__ == '__main__':\n\n@@ -177,6 +177,12 @@ class JapaneseContextAnalysis:\n         return -1, 1\n \n class SJISContextAnalysis(JapaneseContextAnalysis):\n+    def __init__(self):\n+        self.charset_name = \"SHIFT_JIS\"\n+\n+    def get_charset_name(self):\n+        return self.charset_name\n+\n     def get_order(self, aBuf):\n         if not aBuf:\n             return -1, 1\n@@ -184,6 +190,8 @@ class SJISContextAnalysis(JapaneseContextAnalysis):\n         first_char = wrap_ord(aBuf[0])\n         if ((0x81 <= first_char <= 0x9F) or (0xE0 <= first_char <= 0xFC)):\n             charLen = 2\n+            if (first_char == 0x87) or (0xFA <= first_char <= 0xFC):\n+                self.charset_name = \"CP932\"\n         else:\n             charLen = 1\n \n\n@@ -129,11 +129,11 @@ class Latin1Prober(CharSetProber):\n         if total < 0.01:\n             confidence = 0.0\n         else:\n-            confidence = ((self._mFreqCounter[3] / total)\n-                          - (self._mFreqCounter[1] * 20.0 / total))\n+            confidence = ((self._mFreqCounter[3] - self._mFreqCounter[1] * 20.0)\n+                          / total)\n         if confidence < 0.0:\n             confidence = 0.0\n         # lower the confidence of latin1 so that other more accurate\n         # detector can take priority.\n-        confidence = confidence * 0.5\n+        confidence = confidence * 0.73\n         return confidence\n\n@@ -353,7 +353,7 @@ SJIS_cls = (\n     2,2,2,2,2,2,2,2,  # 68 - 6f\n     2,2,2,2,2,2,2,2,  # 70 - 77\n     2,2,2,2,2,2,2,1,  # 78 - 7f\n-    3,3,3,3,3,3,3,3,  # 80 - 87\n+    3,3,3,3,3,2,2,3,  # 80 - 87\n     3,3,3,3,3,3,3,3,  # 88 - 8f\n     3,3,3,3,3,3,3,3,  # 90 - 97\n     3,3,3,3,3,3,3,3,  # 98 - 9f\n@@ -369,9 +369,8 @@ SJIS_cls = (\n     2,2,2,2,2,2,2,2,  # d8 - df\n     3,3,3,3,3,3,3,3,  # e0 - e7\n     3,3,3,3,3,4,4,4,  # e8 - ef\n-    4,4,4,4,4,4,4,4,  # f0 - f7\n-    4,4,4,4,4,0,0,0   # f8 - ff\n-)\n+    3,3,3,3,3,3,3,3,  # f0 - f7\n+    3,3,3,3,3,0,0,0)  # f8 - ff\n \n \n SJIS_st = (\n@@ -571,5 +570,3 @@ UTF8SMModel = {'classTable': UTF8_cls,\n                'stateTable': UTF8_st,\n                'charLenTable': UTF8CharLenTable,\n                'name': 'UTF-8'}\n-\n-# flake8: noqa\n\n@@ -47,7 +47,7 @@ class SJISProber(MultiByteCharSetProber):\n         self._mContextAnalyzer.reset()\n \n     def get_charset_name(self):\n-        return \"SHIFT_JIS\"\n+        return self._mContextAnalyzer.get_charset_name()\n \n     def feed(self, aBuf):\n         aLen = len(aBuf)\n\n@@ -71,9 +71,9 @@ class UniversalDetector:\n \n         if not self._mGotData:\n             # If the data starts with BOM, we know it is UTF\n-            if aBuf[:3] == codecs.BOM:\n+            if aBuf[:3] == codecs.BOM_UTF8:\n                 # EF BB BF  UTF-8 with BOM\n-                self.result = {'encoding': \"UTF-8\", 'confidence': 1.0}\n+                self.result = {'encoding': \"UTF-8-SIG\", 'confidence': 1.0}\n             elif aBuf[:4] == codecs.BOM_UTF32_LE:\n                 # FF FE 00 00  UTF-32, little-endian BOM\n                 self.result = {'encoding': \"UTF-32LE\", 'confidence': 1.0}\n\n@@ -57,7 +57,7 @@ del NullHandler\n \n # Set security warning to only go off once by default.\n import warnings\n-warnings.simplefilter('module', exceptions.SecurityWarning)\n+warnings.simplefilter('always', exceptions.SecurityWarning)\n \n def disable_warnings(category=exceptions.HTTPWarning):\n     \"\"\"\n\n@@ -14,7 +14,7 @@ try: # Python 2.7+\n     from collections import OrderedDict\n except ImportError:\n     from .packages.ordered_dict import OrderedDict\n-from .packages.six import itervalues\n+from .packages.six import iterkeys, itervalues\n \n \n __all__ = ['RecentlyUsedContainer', 'HTTPHeaderDict']\n@@ -85,8 +85,7 @@ class RecentlyUsedContainer(MutableMapping):\n     def clear(self):\n         with self.lock:\n             # Copy pointers to all values, then wipe the mapping\n-            # under Python 2, this copies the list of values twice :-|\n-            values = list(self._container.values())\n+            values = list(itervalues(self._container))\n             self._container.clear()\n \n         if self.dispose_func:\n@@ -95,7 +94,7 @@ class RecentlyUsedContainer(MutableMapping):\n \n     def keys(self):\n         with self.lock:\n-            return self._container.keys()\n+            return list(iterkeys(self._container))\n \n \n class HTTPHeaderDict(MutableMapping):\n\n@@ -3,6 +3,7 @@ import sys\n import socket\n from socket import timeout as SocketTimeout\n import warnings\n+from .packages import six\n \n try:  # Python 3\n     from http.client import HTTPConnection as _HTTPConnection, HTTPException\n@@ -26,12 +27,20 @@ except (ImportError, AttributeError):  # Platform-specific: No SSL.\n         pass\n \n \n+try:  # Python 3:\n+    # Not a no-op, we're adding this to the namespace so it can be imported.\n+    ConnectionError = ConnectionError\n+except NameError:  # Python 2:\n+    class ConnectionError(Exception):\n+        pass\n+\n+\n from .exceptions import (\n     ConnectTimeoutError,\n     SystemTimeWarning,\n+    SecurityWarning,\n )\n from .packages.ssl_match_hostname import match_hostname\n-from .packages import six\n \n from .util.ssl_ import (\n     resolve_cert_reqs,\n@@ -40,8 +49,8 @@ from .util.ssl_ import (\n     assert_fingerprint,\n )\n \n-from .util import connection\n \n+from .util import connection\n \n port_by_scheme = {\n     'http': 80,\n@@ -233,8 +242,15 @@ class VerifiedHTTPSConnection(HTTPSConnection):\n                                self.assert_fingerprint)\n         elif resolved_cert_reqs != ssl.CERT_NONE \\\n                 and self.assert_hostname is not False:\n-            match_hostname(self.sock.getpeercert(),\n-                           self.assert_hostname or hostname)\n+            cert = self.sock.getpeercert()\n+            if not cert.get('subjectAltName', ()):\n+                warnings.warn((\n+                    'Certificate has no `subjectAltName`, falling back to check for a `commonName` for now. '\n+                    'This feature is being removed by major browsers and deprecated by RFC 2818. '\n+                    '(See https://github.com/shazow/urllib3/issues/497 for details.)'),\n+                    SecurityWarning\n+                )\n+            match_hostname(cert, self.assert_hostname or hostname)\n \n         self.is_verified = (resolved_cert_reqs == ssl.CERT_REQUIRED\n                             or self.assert_fingerprint is not None)\n\n@@ -32,7 +32,7 @@ from .connection import (\n     port_by_scheme,\n     DummyConnection,\n     HTTPConnection, HTTPSConnection, VerifiedHTTPSConnection,\n-    HTTPException, BaseSSLError,\n+    HTTPException, BaseSSLError, ConnectionError\n )\n from .request import RequestMethods\n from .response import HTTPResponse\n@@ -278,6 +278,23 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n             # can be removed later\n             return Timeout.from_float(timeout)\n \n+    def _raise_timeout(self, err, url, timeout_value):\n+        \"\"\"Is the error actually a timeout? Will raise a ReadTimeout or pass\"\"\"\n+\n+        if isinstance(err, SocketTimeout):\n+            raise ReadTimeoutError(self, url, \"Read timed out. (read timeout=%s)\" % timeout_value)\n+\n+        # See the above comment about EAGAIN in Python 3. In Python 2 we have\n+        # to specifically catch it and throw the timeout error\n+        if hasattr(err, 'errno') and err.errno in _blocking_errnos:\n+            raise ReadTimeoutError(self, url, \"Read timed out. (read timeout=%s)\" % timeout_value)\n+\n+        # Catch possible read timeouts thrown as SSL errors. If not the\n+        # case, rethrow the original. We need to do this because of:\n+        # http://bugs.python.org/issue10272\n+        if 'timed out' in str(err) or 'did not complete (read)' in str(err):  # Python 2.6\n+            raise ReadTimeoutError(self, url, \"Read timed out. (read timeout=%s)\" % timeout_value)\n+\n     def _make_request(self, conn, method, url, timeout=_Default,\n                       **httplib_request_kw):\n         \"\"\"\n@@ -301,7 +318,12 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n         conn.timeout = timeout_obj.connect_timeout\n \n         # Trigger any extra validation we need to do.\n+        try:\n             self._validate_conn(conn)\n+        except (SocketTimeout, BaseSSLError) as e:\n+            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\n+            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n+            raise\n \n         # conn.request() calls httplib.*.request, not the method in\n         # urllib3.request. It also calls makefile (recv) on the socket.\n@@ -331,28 +353,8 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n                 httplib_response = conn.getresponse(buffering=True)\n             except TypeError:  # Python 2.6 and older\n                 httplib_response = conn.getresponse()\n-        except SocketTimeout:\n-            raise ReadTimeoutError(\n-                self, url, \"Read timed out. (read timeout=%s)\" % read_timeout)\n-\n-        except BaseSSLError as e:\n-            # Catch possible read timeouts thrown as SSL errors. If not the\n-            # case, rethrow the original. We need to do this because of:\n-            # http://bugs.python.org/issue10272\n-            if 'timed out' in str(e) or \\\n-               'did not complete (read)' in str(e):  # Python 2.6\n-                raise ReadTimeoutError(\n-                        self, url, \"Read timed out. (read timeout=%s)\" % read_timeout)\n-\n-            raise\n-\n-        except SocketError as e:  # Platform-specific: Python 2\n-            # See the above comment about EAGAIN in Python 3. In Python 2 we\n-            # have to specifically catch it and throw the timeout error\n-            if e.errno in _blocking_errnos:\n-                raise ReadTimeoutError(\n-                    self, url, \"Read timed out. (read timeout=%s)\" % read_timeout)\n-\n+        except (SocketTimeout, BaseSSLError, SocketError) as e:\n+            self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n             raise\n \n         # AppEngine doesn't have a version attr.\n@@ -537,12 +539,15 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n             raise EmptyPoolError(self, \"No pool connections are available.\")\n \n         except (BaseSSLError, CertificateError) as e:\n-            # Release connection unconditionally because there is no way to\n-            # close it externally in case of exception.\n-            release_conn = True\n+            # Close the connection. If a connection is reused on which there\n+            # was a Certificate error, the next request will certainly raise\n+            # another Certificate error.\n+            if conn:\n+                conn.close()\n+                conn = None\n             raise SSLError(e)\n \n-        except (TimeoutError, HTTPException, SocketError) as e:\n+        except (TimeoutError, HTTPException, SocketError, ConnectionError) as e:\n             if conn:\n                 # Discard the connection for these exceptions. It will be\n                 # be replaced during the next _get_conn() call.\n@@ -725,8 +730,7 @@ class HTTPSConnectionPool(HTTPConnectionPool):\n             warnings.warn((\n                 'Unverified HTTPS request is being made. '\n                 'Adding certificate verification is strongly advised. See: '\n-                'https://urllib3.readthedocs.org/en/latest/security.html '\n-                '(This warning will only appear once by default.)'),\n+                'https://urllib3.readthedocs.org/en/latest/security.html'),\n                 InsecureRequestWarning)\n \n \n\n@@ -29,7 +29,7 @@ Now you can use :mod:`urllib3` as you normally would, and it will support SNI\n when the required modules are installed.\n \n Activating this module also has the positive side effect of disabling SSL/TLS\n-encryption in Python 2 (see `CRIME attack`_).\n+compression in Python 2 (see `CRIME attack`_).\n \n If you want to configure the default list of supported cipher suites, you can\n set the ``urllib3.contrib.pyopenssl.DEFAULT_SSL_CIPHER_LIST`` variable.\n@@ -70,9 +70,14 @@ HAS_SNI = SUBJ_ALT_NAME_SUPPORT\n # Map from urllib3 to PyOpenSSL compatible parameter-values.\n _openssl_versions = {\n     ssl.PROTOCOL_SSLv23: OpenSSL.SSL.SSLv23_METHOD,\n-    ssl.PROTOCOL_SSLv3: OpenSSL.SSL.SSLv3_METHOD,\n     ssl.PROTOCOL_TLSv1: OpenSSL.SSL.TLSv1_METHOD,\n }\n+\n+try:\n+    _openssl_versions.update({ssl.PROTOCOL_SSLv3: OpenSSL.SSL.SSLv3_METHOD})\n+except AttributeError:\n+    pass\n+\n _openssl_verify = {\n     ssl.CERT_NONE: OpenSSL.SSL.VERIFY_NONE,\n     ssl.CERT_OPTIONAL: OpenSSL.SSL.VERIFY_PEER,\n@@ -199,8 +204,21 @@ class WrappedSocket(object):\n     def settimeout(self, timeout):\n         return self.socket.settimeout(timeout)\n \n+    def _send_until_done(self, data):\n+        while True:\n+            try:\n+                return self.connection.send(data)\n+            except OpenSSL.SSL.WantWriteError:\n+                _, wlist, _ = select.select([], [self.socket], [],\n+                                            self.socket.gettimeout())\n+                if not wlist:\n+                    raise timeout()\n+                continue\n+\n     def sendall(self, data):\n-        return self.connection.sendall(data)\n+        while len(data):\n+            sent = self._send_until_done(data)\n+            data = data[sent:]\n \n     def close(self):\n         if self._makefile_refs < 1:\n@@ -248,6 +266,7 @@ def ssl_wrap_socket(sock, keyfile=None, certfile=None, cert_reqs=None,\n                     ssl_version=None):\n     ctx = OpenSSL.SSL.Context(_openssl_versions[ssl_version])\n     if certfile:\n+        keyfile = keyfile or certfile  # Match behaviour of the normal python ssl library\n         ctx.use_certificate_file(certfile)\n     if keyfile:\n         ctx.use_privatekey_file(keyfile)\n\n@@ -72,11 +72,8 @@ class MaxRetryError(RequestError):\n     def __init__(self, pool, url, reason=None):\n         self.reason = reason\n \n-        message = \"Max retries exceeded with url: %s\" % url\n-        if reason:\n-            message += \" (Caused by %r)\" % reason\n-        else:\n-            message += \" (Caused by redirect)\"\n+        message = \"Max retries exceeded with url: %s (Caused by %r)\" % (\n+            url, reason)\n \n         RequestError.__init__(self, pool, url, message)\n \n@@ -141,6 +138,12 @@ class LocationParseError(LocationValueError):\n         self.location = location\n \n \n+class ResponseError(HTTPError):\n+    \"Used as a container for an error reason supplied in a MaxRetryError.\"\n+    GENERIC_ERROR = 'too many error responses'\n+    SPECIFIC_ERROR = 'too many {status_code} error responses'\n+\n+\n class SecurityWarning(HTTPWarning):\n     \"Warned when perfoming security reducing actions\"\n     pass\n\n@@ -118,18 +118,24 @@ class RequestMethods(object):\n         which is used to compose the body of the request. The random boundary\n         string can be explicitly set with the ``multipart_boundary`` parameter.\n         \"\"\"\n-        if encode_multipart:\n-            body, content_type = encode_multipart_formdata(\n-                fields or {}, boundary=multipart_boundary)\n-        else:\n-            body, content_type = (urlencode(fields or {}),\n-                                  'application/x-www-form-urlencoded')\n-\n         if headers is None:\n             headers = self.headers\n \n-        headers_ = {'Content-Type': content_type}\n-        headers_.update(headers)\n+        extra_kw = {'headers': {}}\n \n-        return self.urlopen(method, url, body=body, headers=headers_,\n-                            **urlopen_kw)\n+        if fields:\n+            if 'body' in urlopen_kw:\n+                raise TypeError('request got values for both \\'fields\\' and \\'body\\', can only specify one.')\n+\n+            if encode_multipart:\n+                body, content_type = encode_multipart_formdata(fields, boundary=multipart_boundary)\n+            else:\n+                body, content_type = urlencode(fields), 'application/x-www-form-urlencoded'\n+\n+            extra_kw['body'] = body\n+            extra_kw['headers'] = {'Content-Type': content_type}\n+\n+        extra_kw['headers'].update(headers)\n+        extra_kw.update(urlopen_kw)\n+\n+        return self.urlopen(method, url, **extra_kw)\n\n@@ -2,10 +2,11 @@ import time\n import logging\n \n from ..exceptions import (\n-    ProtocolError,\n     ConnectTimeoutError,\n-    ReadTimeoutError,\n     MaxRetryError,\n+    ProtocolError,\n+    ReadTimeoutError,\n+    ResponseError,\n )\n from ..packages import six\n \n@@ -36,7 +37,6 @@ class Retry(object):\n     Errors will be wrapped in :class:`~urllib3.exceptions.MaxRetryError` unless\n     retries are disabled, in which case the causing exception will be raised.\n \n-\n     :param int total:\n         Total number of retries to allow. Takes precedence over other counts.\n \n@@ -184,8 +184,8 @@ class Retry(object):\n         return isinstance(err, ConnectTimeoutError)\n \n     def _is_read_error(self, err):\n-        \"\"\" Errors that occur after the request has been started, so we can't\n-        assume that the server did not process any of it.\n+        \"\"\" Errors that occur after the request has been started, so we should\n+        assume that the server began processing it.\n         \"\"\"\n         return isinstance(err, (ReadTimeoutError, ProtocolError))\n \n@@ -198,8 +198,7 @@ class Retry(object):\n         return self.status_forcelist and status_code in self.status_forcelist\n \n     def is_exhausted(self):\n-        \"\"\" Are we out of retries?\n-        \"\"\"\n+        \"\"\" Are we out of retries? \"\"\"\n         retry_counts = (self.total, self.connect, self.read, self.redirect)\n         retry_counts = list(filter(None, retry_counts))\n         if not retry_counts:\n@@ -230,6 +229,7 @@ class Retry(object):\n         connect = self.connect\n         read = self.read\n         redirect = self.redirect\n+        cause = 'unknown'\n \n         if error and self._is_connection_error(error):\n             # Connect retry?\n@@ -251,10 +251,16 @@ class Retry(object):\n             # Redirect retry?\n             if redirect is not None:\n                 redirect -= 1\n+            cause = 'too many redirects'\n \n         else:\n-            # FIXME: Nothing changed, scenario doesn't make sense.\n+            # Incrementing because of a server error like a 500 in\n+            # status_forcelist and a the given method is in the whitelist\n             _observed_errors += 1\n+            cause = ResponseError.GENERIC_ERROR\n+            if response and response.status:\n+                cause = ResponseError.SPECIFIC_ERROR.format(\n+                    status_code=response.status)\n \n         new_retry = self.new(\n             total=total,\n@@ -262,7 +268,7 @@ class Retry(object):\n             _observed_errors=_observed_errors)\n \n         if new_retry.is_exhausted():\n-            raise MaxRetryError(_pool, url, error)\n+            raise MaxRetryError(_pool, url, error or ResponseError(cause))\n \n         log.debug(\"Incremented Retry for (url='%s'): %r\" % (url, new_retry))\n \n\n@@ -4,18 +4,84 @@ from hashlib import md5, sha1\n from ..exceptions import SSLError\n \n \n-try:  # Test for SSL features\n SSLContext = None\n HAS_SNI = False\n+create_default_context = None\n \n+import errno\n import ssl\n+\n+try:  # Test for SSL features\n     from ssl import wrap_socket, CERT_NONE, PROTOCOL_SSLv23\n-    from ssl import SSLContext  # Modern SSL?\n     from ssl import HAS_SNI  # Has SNI?\n except ImportError:\n     pass\n \n \n+try:\n+    from ssl import OP_NO_SSLv2, OP_NO_SSLv3, OP_NO_COMPRESSION\n+except ImportError:\n+    OP_NO_SSLv2, OP_NO_SSLv3 = 0x1000000, 0x2000000\n+    OP_NO_COMPRESSION = 0x20000\n+\n+try:\n+    from ssl import _DEFAULT_CIPHERS\n+except ImportError:\n+    _DEFAULT_CIPHERS = (\n+        'ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:ECDH+HIGH:'\n+        'DH+HIGH:ECDH+3DES:DH+3DES:RSA+AESGCM:RSA+AES:RSA+HIGH:RSA+3DES:ECDH+RC4:'\n+        'DH+RC4:RSA+RC4:!aNULL:!eNULL:!MD5'\n+    )\n+\n+try:\n+    from ssl import SSLContext  # Modern SSL?\n+except ImportError:\n+    import sys\n+\n+    class SSLContext(object):  # Platform-specific: Python 2 & 3.1\n+        supports_set_ciphers = sys.version_info >= (2, 7)\n+\n+        def __init__(self, protocol_version):\n+            self.protocol = protocol_version\n+            # Use default values from a real SSLContext\n+            self.check_hostname = False\n+            self.verify_mode = ssl.CERT_NONE\n+            self.ca_certs = None\n+            self.options = 0\n+            self.certfile = None\n+            self.keyfile = None\n+            self.ciphers = None\n+\n+        def load_cert_chain(self, certfile, keyfile):\n+            self.certfile = certfile\n+            self.keyfile = keyfile\n+\n+        def load_verify_locations(self, location):\n+            self.ca_certs = location\n+\n+        def set_ciphers(self, cipher_suite):\n+            if not self.supports_set_ciphers:\n+                raise TypeError(\n+                    'Your version of Python does not support setting '\n+                    'a custom cipher suite. Please upgrade to Python '\n+                    '2.7, 3.2, or later if you need this functionality.'\n+                )\n+            self.ciphers = cipher_suite\n+\n+        def wrap_socket(self, socket, server_hostname=None):\n+            kwargs = {\n+                'keyfile': self.keyfile,\n+                'certfile': self.certfile,\n+                'ca_certs': self.ca_certs,\n+                'cert_reqs': self.verify_mode,\n+                'ssl_version': self.protocol,\n+            }\n+            if self.supports_set_ciphers:  # Platform-specific: Python 2.7+\n+                return wrap_socket(socket, ciphers=self.ciphers, **kwargs)\n+            else:  # Platform-specific: Python 2.6\n+                return wrap_socket(socket, **kwargs)\n+\n+\n def assert_fingerprint(cert, fingerprint):\n     \"\"\"\n     Checks if given fingerprint matches the supplied certificate.\n@@ -91,42 +157,98 @@ def resolve_ssl_version(candidate):\n     return candidate\n \n \n-if SSLContext is not None:  # Python 3.2+\n+def create_urllib3_context(ssl_version=None, cert_reqs=ssl.CERT_REQUIRED,\n+                           options=None, ciphers=None):\n+    \"\"\"All arguments have the same meaning as ``ssl_wrap_socket``.\n+\n+    By default, this function does a lot of the same work that\n+    ``ssl.create_default_context`` does on Python 3.4+. It:\n+\n+    - Disables SSLv2, SSLv3, and compression\n+    - Sets a restricted set of server ciphers\n+\n+    If you wish to enable SSLv3, you can do::\n+\n+        from urllib3.util import ssl_\n+        context = ssl_.create_urllib3_context()\n+        context.options &= ~ssl_.OP_NO_SSLv3\n+\n+    You can do the same to enable compression (substituting ``COMPRESSION``\n+    for ``SSLv3`` in the last line above).\n+\n+    :param ssl_version:\n+        The desired protocol version to use. This will default to\n+        PROTOCOL_SSLv23 which will negotiate the highest protocol that both\n+        the server and your installation of OpenSSL support.\n+    :param cert_reqs:\n+        Whether to require the certificate verification. This defaults to\n+        ``ssl.CERT_REQUIRED``.\n+    :param options:\n+        Specific OpenSSL options. These default to ``ssl.OP_NO_SSLv2``,\n+        ``ssl.OP_NO_SSLv3``, ``ssl.OP_NO_COMPRESSION``.\n+    :param ciphers:\n+        Which cipher suites to allow the server to select.\n+    :returns:\n+        Constructed SSLContext object with specified options\n+    :rtype: SSLContext\n+    \"\"\"\n+    context = SSLContext(ssl_version or ssl.PROTOCOL_SSLv23)\n+\n+    if options is None:\n+        options = 0\n+        # SSLv2 is easily broken and is considered harmful and dangerous\n+        options |= OP_NO_SSLv2\n+        # SSLv3 has several problems and is now dangerous\n+        options |= OP_NO_SSLv3\n+        # Disable compression to prevent CRIME attacks for OpenSSL 1.0+\n+        # (issue #309)\n+        options |= OP_NO_COMPRESSION\n+\n+    context.options |= options\n+\n+    if getattr(context, 'supports_set_ciphers', True):  # Platform-specific: Python 2.6\n+        context.set_ciphers(ciphers or _DEFAULT_CIPHERS)\n+\n+    context.verify_mode = cert_reqs\n+    if getattr(context, 'check_hostname', None) is not None:  # Platform-specific: Python 3.2\n+        context.check_hostname = (context.verify_mode == ssl.CERT_REQUIRED)\n+    return context\n+\n+\n def ssl_wrap_socket(sock, keyfile=None, certfile=None, cert_reqs=None,\n                     ca_certs=None, server_hostname=None,\n-                        ssl_version=None):\n+                    ssl_version=None, ciphers=None, ssl_context=None):\n     \"\"\"\n-        All arguments except `server_hostname` have the same meaning as for\n-        :func:`ssl.wrap_socket`\n+    All arguments except for server_hostname and ssl_context have the same\n+    meaning as they do when using :func:`ssl.wrap_socket`.\n \n     :param server_hostname:\n-            Hostname of the expected certificate\n+        When SNI is supported, the expected hostname of the certificate\n+    :param ssl_context:\n+        A pre-made :class:`SSLContext` object. If none is provided, one will\n+        be created using :func:`create_urllib3_context`.\n+    :param ciphers:\n+        A string of ciphers we wish the client to support. This is not\n+        supported on Python 2.6 as the ssl module does not support it.\n     \"\"\"\n-        context = SSLContext(ssl_version)\n-        context.verify_mode = cert_reqs\n-\n-        # Disable TLS compression to migitate CRIME attack (issue #309)\n-        OP_NO_COMPRESSION = 0x20000\n-        context.options |= OP_NO_COMPRESSION\n+    context = ssl_context\n+    if context is None:\n+        context = create_urllib3_context(ssl_version, cert_reqs,\n+                                         ciphers=ciphers)\n \n     if ca_certs:\n         try:\n             context.load_verify_locations(ca_certs)\n-            # Py32 raises IOError\n-            # Py33 raises FileNotFoundError\n-            except Exception as e:  # Reraise as SSLError\n+        except IOError as e:  # Platform-specific: Python 2.6, 2.7, 3.2\n             raise SSLError(e)\n+        # Py33 raises FileNotFoundError which subclasses OSError\n+        # These are not equivalent unless we check the errno attribute\n+        except OSError as e:  # Platform-specific: Python 3.3 and beyond\n+            if e.errno == errno.ENOENT:\n+                raise SSLError(e)\n+            raise\n     if certfile:\n-            # FIXME: This block needs a test.\n         context.load_cert_chain(certfile, keyfile)\n     if HAS_SNI:  # Platform-specific: OpenSSL with enabled SNI\n         return context.wrap_socket(sock, server_hostname=server_hostname)\n     return context.wrap_socket(sock)\n-\n-else:  # Python 3.1 and earlier\n-    def ssl_wrap_socket(sock, keyfile=None, certfile=None, cert_reqs=None,\n-                        ca_certs=None, server_hostname=None,\n-                        ssl_version=None):\n-        return wrap_socket(sock, keyfile=keyfile, certfile=certfile,\n-                           ca_certs=ca_certs, cert_reqs=cert_reqs,\n-                           ssl_version=ssl_version)\n\n@@ -40,6 +40,48 @@ class Url(namedtuple('Url', url_attrs)):\n             return '%s:%d' % (self.host, self.port)\n         return self.host\n \n+    @property\n+    def url(self):\n+        \"\"\"\n+        Convert self into a url\n+\n+        This function should more or less round-trip with :func:`.parse_url`. The\n+        returned url may not be exactly the same as the url inputted to\n+        :func:`.parse_url`, but it should be equivalent by the RFC (e.g., urls\n+        with a blank port will have : removed).\n+\n+        Example: ::\n+\n+            >>> U = parse_url('http://google.com/mail/')\n+            >>> U.url\n+            'http://google.com/mail/'\n+            >>> Url('http', 'username:password', 'host.com', 80,\n+            ... '/path', 'query', 'fragment').url\n+            'http://username:password@host.com:80/path?query#fragment'\n+        \"\"\"\n+        scheme, auth, host, port, path, query, fragment = self\n+        url = ''\n+\n+        # We use \"is not None\" we want things to happen with empty strings (or 0 port)\n+        if scheme is not None:\n+            url += scheme + '://'\n+        if auth is not None:\n+            url += auth + '@'\n+        if host is not None:\n+            url += host\n+        if port is not None:\n+            url += ':' + str(port)\n+        if path is not None:\n+            url += path\n+        if query is not None:\n+            url += '?' + query\n+        if fragment is not None:\n+            url += '#' + fragment\n+\n+        return url\n+\n+    def __str__(self):\n+        return self.url\n \n def split_first(s, delims):\n     \"\"\"\n@@ -84,7 +126,7 @@ def parse_url(url):\n     Example::\n \n         >>> parse_url('http://google.com/mail/')\n-        Url(scheme='http', host='google.com', port=None, path='/', ...)\n+        Url(scheme='http', host='google.com', port=None, path='/mail/', ...)\n         >>> parse_url('google.com:80')\n         Url(scheme=None, host='google.com', port=80, path=None, ...)\n         >>> parse_url('/foo?bar')\n@@ -162,7 +204,6 @@ def parse_url(url):\n \n     return Url(scheme, auth, host, port, path, query, fragment)\n \n-\n def get_host(url):\n     \"\"\"\n     Deprecated. Use :func:`.parse_url` instead.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#cf82d4406be55c71983d05d7f6e18917540b5c69", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 6 | Methods Changed: 5 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 12 | Churn Cumulative: 4875 | Contributors (this commit): 88 | Commits (past 90d): 11 | Contributors (cumulative): 88 | DMM Complexity: None\n\nDIFF:\n@@ -258,7 +258,7 @@ class RequestsTestCase(unittest.TestCase):\n         \"\"\"Do not send headers in Session.headers with None values.\"\"\"\n         ses = requests.Session()\n         ses.headers['Accept-Encoding'] = None\n-        req = requests.Request('GET', 'http://httpbin.org/get')\n+        req = requests.Request('GET', httpbin('get'))\n         prep = ses.prepare_request(req)\n         assert 'Accept-Encoding' not in prep.headers\n \n@@ -1008,7 +1008,7 @@ class RequestsTestCase(unittest.TestCase):\n         assert s == \"Basic dGVzdDp0ZXN0\"\n \n     def test_requests_history_is_saved(self):\n-        r = requests.get('https://httpbin.org/redirect/5')\n+        r = requests.get(httpbin('redirect/5'))\n         total = r.history[-1].history\n         i = 0\n         for item in r.history:\n@@ -1350,7 +1350,7 @@ class TestMorselToCookieMaxAge(unittest.TestCase):\n class TestTimeout:\n     def test_stream_timeout(self):\n         try:\n-            requests.get('https://httpbin.org/delay/10', timeout=2.0)\n+            requests.get(httpbin('delay/10'), timeout=2.0)\n         except requests.exceptions.Timeout as e:\n             assert 'Read timed out' in e.args[0].args[0]\n \n@@ -1450,7 +1450,7 @@ class TestRedirects:\n \n     def test_requests_are_updated_each_time(self):\n         session = RedirectSession([303, 307])\n-        prep = requests.Request('POST', 'http://httpbin.org/post').prepare()\n+        prep = requests.Request('POST', httpbin('post')).prepare()\n         r0 = session.send(prep)\n         assert r0.request.method == 'POST'\n         assert session.calls[-1] == SendCall((r0.request,), {})\n@@ -1534,12 +1534,12 @@ def test_prepare_unicode_url():\n def test_urllib3_retries():\n     from requests.packages.urllib3.util import Retry\n     s = requests.Session()\n-    s.mount('https://', HTTPAdapter(max_retries=Retry(\n+    s.mount('http://', HTTPAdapter(max_retries=Retry(\n         total=2, status_forcelist=[500]\n     )))\n \n     with pytest.raises(RetryError):\n-        s.get('https://httpbin.org/status/500')\n+        s.get(httpbin('status/500'))\n \n if __name__ == '__main__':\n     unittest.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#33b25176b86efcfa79bc93bae9be8e4affc48262", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 565 | Contributors (this commit): 11 | Commits (past 90d): 4 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -42,8 +42,8 @@ is at <http://python-requests.org>.\n \"\"\"\n \n __title__ = 'requests'\n-__version__ = '2.4.3'\n-__build__ = 0x020403\n+__version__ = '2.5.0'\n+__build__ = 0x020500\n __author__ = 'Kenneth Reitz'\n __license__ = 'Apache 2.0'\n __copyright__ = 'Copyright 2014 Kenneth Reitz'\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#d61540551943df57aa0dece5e44e130309dcafec", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 78 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 3 | Complexity Δ (Sum/Max): 13/13 | Churn Δ: 79 | Churn Cumulative: 88 | Contributors (this commit): 2 | Commits (past 90d): 1 | Contributors (cumulative): 2 | DMM Complexity: 0.15789473684210525\n\nDIFF:\n@@ -1,3 +1,80 @@\n+\"\"\"\n+pip._vendor is for vendoring dependencies of pip to prevent needing pip to\n+depend on something external.\n+\n+Files inside of pip._vendor should be considered immutable and should only be\n+updated to versions from upstream.\n+\"\"\"\n from __future__ import absolute_import\n \n-from . import urllib3\n+import sys\n+\n+\n+class VendorAlias(object):\n+\n+    def __init__(self):\n+        self._vendor_name = __name__\n+        self._vendor_pkg = self._vendor_name + \".\"\n+\n+    def find_module(self, fullname, path=None):\n+        if fullname.startswith(self._vendor_pkg):\n+            return self\n+\n+    def load_module(self, name):\n+        # Ensure that this only works for the vendored name\n+        if not name.startswith(self._vendor_pkg):\n+            raise ImportError(\n+                \"Cannot import %s, must be a subpackage of '%s'.\" % (\n+                    name, self._vendor_name,\n+                )\n+            )\n+\n+        # Check to see if we already have this item in sys.modules, if we do\n+        # then simply return that.\n+        if name in sys.modules:\n+            return sys.modules[name]\n+\n+        # Check to see if we can import the vendor name\n+        try:\n+            # We do this dance here because we want to try and import this\n+            # module without hitting a recursion error because of a bunch of\n+            # VendorAlias instances on sys.meta_path\n+            real_meta_path = sys.meta_path[:]\n+            try:\n+                sys.meta_path = [\n+                    m for m in sys.meta_path\n+                    if not isinstance(m, VendorAlias)\n+                ]\n+                __import__(name)\n+                module = sys.modules[name]\n+            finally:\n+                # Re-add any additions to sys.meta_path that were made while\n+                # during the import we just did, otherwise things like\n+                # pip._vendor.six.moves will fail.\n+                for m in sys.meta_path:\n+                    if m not in real_meta_path:\n+                        real_meta_path.append(m)\n+\n+                # Restore sys.meta_path with any new items.\n+                sys.meta_path = real_meta_path\n+        except ImportError:\n+            # We can't import the vendor name, so we'll try to import the\n+            # \"real\" name.\n+            real_name = name[len(self._vendor_pkg):]\n+            try:\n+                __import__(real_name)\n+                module = sys.modules[real_name]\n+            except ImportError:\n+                raise ImportError(\"No module named '%s'\" % (name,))\n+\n+        # If we've gotten here we've found the module we're looking for, either\n+        # as part of our vendored package, or as the real name, so we'll add\n+        # it to sys.modules as the vendored name so that we don't have to do\n+        # the lookup again.\n+        sys.modules[name] = module\n+\n+        # Finally, return the loaded module\n+        return module\n+\n+\n+sys.meta_path.append(VendorAlias())\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
