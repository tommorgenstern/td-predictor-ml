{"custom_id": "scrapy#6e50f94406884f29f61735620907b125b55cea9d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 1851 | Contributors (this commit): 5 | Commits (past 90d): 16 | Contributors (cumulative): 5 | DMM Complexity: 0.5\n\nDIFF:\n@@ -95,7 +95,8 @@ class ExecutionEngine(object):\n             return\n \n         if self.paused:\n-            return slot.nextcall.schedule(5)\n+            slot.nextcall.schedule(5)\n+            return\n \n         while not self._needs_backout(spider):\n             if not self._next_request_from_scheduler(spider):\n@@ -235,7 +236,8 @@ class ExecutionEngine(object):\n             spider=spider, dont_log=DontCloseSpider)\n         if any(isinstance(x, Failure) and isinstance(x.value, DontCloseSpider) \\\n                 for _, x in res):\n-            return self.slots[spider].nextcall.schedule(5)\n+            self.slots[spider].nextcall.schedule(5)\n+            return\n \n         if self.spider_is_idle(spider):\n             self.close_spider(spider, reason='finished')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#6f0e492390ec6c59d3b0d39ff5bd2ba3bfc51bc9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 3 | Methods Changed: 5 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 735 | Contributors (this commit): 3 | Commits (past 90d): 8 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -43,11 +43,11 @@ class Slot(object):\n \n     def next_response_request_deferred(self):\n         response, request, deferred = self.queue.popleft()\n-        self.active.add(response)\n+        self.active.add(request)\n         return response, request, deferred\n \n-    def finish_response(self, response):\n-        self.active.remove(response)\n+    def finish_response(self, response, request):\n+        self.active.remove(request)\n         if isinstance(response, Response):\n             self.active_size -= max(len(response.body), self.MIN_RESPONSE_SIZE)\n         else:\n@@ -98,7 +98,7 @@ class Scraper(object):\n         slot = self.slots[spider]\n         dfd = slot.add_response_request(response, request)\n         def finish_scraping(_):\n-            slot.finish_response(response)\n+            slot.finish_response(response, request)\n             self._check_if_closing(spider, slot)\n             self._scrape_next(spider, slot)\n             return _\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#70493c754d1f5b16ac25161cbbb79e31ae488e69", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 57 | Contributors (this commit): 3 | Commits (past 90d): 2 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -20,7 +20,7 @@ About HTTP errors to consider:\n \n from twisted.internet.error import TimeoutError as ServerTimeoutError, DNSLookupError, \\\n                                    ConnectionRefusedError, ConnectionDone, ConnectError, \\\n-                                   ConnectionLost\n+                                   ConnectionLost, TCPTimedOutError\n from twisted.internet.defer import TimeoutError as UserTimeoutError\n from twisted.web.client import PartialDownloadError\n \n@@ -35,7 +35,8 @@ class RetryMiddleware(object):\n     # decompress an empty response\n     EXCEPTIONS_TO_RETRY = (ServerTimeoutError, UserTimeoutError, DNSLookupError,\n                            ConnectionRefusedError, ConnectionDone, ConnectError,\n-                           ConnectionLost, PartialDownloadError, IOError)\n+                           ConnectionLost, PartialDownloadError, TCPTimedOutError,\n+                           IOError)\n \n     def __init__(self):\n         if not settings.getbool('RETRY_ENABLED'):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#dd020e184fe1ecd50b399321b9194ba0bd7777fc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 18 | Files Changed: 1 | Hunks: 7 | Methods Changed: 5 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 18 | Churn Cumulative: 382 | Contributors (this commit): 2 | Commits (past 90d): 6 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -1,7 +1,3 @@\n-\"\"\"\n-Download web pages using asynchronous IO\n-\"\"\"\n-\n import random\n from time import time\n from collections import deque\n@@ -56,10 +52,6 @@ class Slot(object):\n \n \n class Downloader(object):\n-    \"\"\"Mantain many concurrent downloads and provide an HTTP abstraction.\n-    It supports a limited number of connections per spider and many spiders in\n-    parallel.\n-    \"\"\"\n \n     def __init__(self):\n         self.slots = {}\n@@ -68,12 +60,6 @@ class Downloader(object):\n         self.concurrent_spiders = settings.getint('CONCURRENT_SPIDERS')\n \n     def fetch(self, request, spider):\n-        \"\"\"Main method to use to request a download\n-\n-        This method includes middleware mangling. Middleware can returns a\n-        Response object, then request never reach downloader queue, and it will\n-        not be downloaded from site.\n-        \"\"\"\n         slot = self.slots[spider]\n \n         slot.active.add(request)\n@@ -85,7 +71,6 @@ class Downloader(object):\n         return dfd.addBoth(_deactivate)\n \n     def enqueue(self, request, spider):\n-        \"\"\"Enqueue a Request for a effective download from site\"\"\"\n         slot = self.slots[spider]\n \n         def _downloaded(response):\n@@ -99,7 +84,6 @@ class Downloader(object):\n         return deferred\n \n     def _process_queue(self, spider):\n-        \"\"\"Effective download requests from slot queue\"\"\"\n         slot = self.slots.get(spider)\n         if not slot:\n             return\n@@ -142,12 +126,10 @@ class Downloader(object):\n         return dfd.addBoth(finish_transferring)\n \n     def open_spider(self, spider):\n-        \"\"\"Allocate resources to begin processing a spider\"\"\"\n         assert spider not in self.slots, \"Spider already opened: %s\" % spider\n         self.slots[spider] = Slot(spider)\n \n     def close_spider(self, spider):\n-        \"\"\"Free any resources associated with the given spider\"\"\"\n         assert spider in self.slots, \"Spider not opened: %s\" % spider\n         slot = self.slots.pop(spider)\n         slot.cancel_request_calls()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#cb9c937f50aaeaf67aba3f54cecdf6bb854aabf7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 2237 | Contributors (this commit): 5 | Commits (past 90d): 24 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -57,7 +57,6 @@ class Downloader(object):\n         self.slots = {}\n         self.handlers = DownloadHandlers()\n         self.middleware = DownloaderMiddlewareManager.from_settings(settings)\n-        self.concurrent_spiders = settings.getint('CONCURRENT_SPIDERS')\n \n     def fetch(self, request, spider):\n         slot = self.slots[spider]\n\n@@ -59,6 +59,7 @@ class ExecutionEngine(object):\n         self.scheduler = load_object(settings['SCHEDULER'])()\n         self.downloader = Downloader()\n         self.scraper = Scraper(self, self.settings)\n+        self._concurrent_spiders = settings.getint('CONCURRENT_SPIDERS')\n         self._spider_closed_callback = spider_closed_callback\n \n     @defer.inlineCallbacks\n@@ -164,7 +165,7 @@ class ExecutionEngine(object):\n \n     def has_capacity(self):\n         \"\"\"Does the engine have capacity to handle more spiders\"\"\"\n-        return len(self.downloader.slots) < self.downloader.concurrent_spiders\n+        return len(self.slots) < self._concurrent_spiders\n \n     def crawl(self, request, spider):\n         assert spider in self.open_spiders, \\\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#549298e38dbbe64f3cfafdc5bb722ab9e9e6992f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 3 | Churn Cumulative: 84 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -33,7 +33,10 @@ class SpiderManager(object):\n         return cls(settings.getlist('SPIDER_MODULES'))\n \n     def create(self, spider_name, **spider_kwargs):\n+        try:\n             return self._spiders[spider_name](**spider_kwargs)\n+        except KeyError:\n+            raise KeyError(\"Spider not found: %s\" % spider_name)\n \n     def find_by_request(self, request):\n         return [name for name, cls in self._spiders.iteritems()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#90b716f7e490c1b52a2a48477948a85f87b3c4af", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 10 | Files Changed: 1 | Hunks: 6 | Methods Changed: 7 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 16 | Churn Cumulative: 399 | Contributors (this commit): 2 | Commits (past 90d): 8 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -66,10 +66,10 @@ class Downloader(object):\n             slot.active.remove(request)\n             return response\n \n-        dfd = self.middleware.download(self.enqueue, request, spider)\n+        dfd = self.middleware.download(self._enqueue_request, request, spider)\n         return dfd.addBoth(_deactivate)\n \n-    def enqueue(self, request, spider):\n+    def _enqueue_request(self, request, spider):\n         slot = self.slots[spider]\n \n         def _downloaded(response):\n@@ -79,14 +79,10 @@ class Downloader(object):\n \n         deferred = defer.Deferred().addCallback(_downloaded)\n         slot.queue.append((request, deferred))\n-        self._process_queue(spider)\n+        self._process_queue(spider, slot)\n         return deferred\n \n-    def _process_queue(self, spider):\n-        slot = self.slots.get(spider)\n-        if not slot:\n-            return\n-\n+    def _process_queue(self, spider, slot):\n         # Delay queue processing if a download_delay is configured\n         now = time()\n         delay = slot.download_delay()\n@@ -95,7 +91,7 @@ class Downloader(object):\n             if penalty > 0 and slot.free_transfer_slots():\n                 d = defer.Deferred()\n                 d.addCallback(self._process_queue)\n-                call = reactor.callLater(penalty, d.callback, spider)\n+                call = reactor.callLater(penalty, d.callback, spider, slot)\n                 slot.next_request_calls.add(call)\n                 d.addBoth(lambda x: slot.next_request_calls.remove(call))\n                 return\n@@ -120,7 +116,7 @@ class Downloader(object):\n         slot.transferring.add(request)\n         def finish_transferring(_):\n             slot.transferring.remove(request)\n-            self._process_queue(spider)\n+            self._process_queue(spider, slot)\n             return _\n         return dfd.addBoth(finish_transferring)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#c59340150f60209af63677349449746a6c0fdebf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 185 | Lines Deleted: 46 | Files Changed: 6 | Hunks: 8 | Methods Changed: 26 | Complexity Δ (Sum/Max): 29/29 | Churn Δ: 231 | Churn Cumulative: 763 | Contributors (this commit): 3 | Commits (past 90d): 8 | Contributors (cumulative): 8 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,46 +0,0 @@\n-from collections import defaultdict\n-\n-from twisted.internet import reactor, defer\n-from twisted.internet.base import ThreadedResolver\n-\n-from scrapy.xlib.pydispatch import dispatcher\n-from scrapy.utils.httpobj import urlparse_cached\n-from scrapy import signals\n-\n-\n-class CachingResolver(object):\n-    \"\"\"Scrapy extension to use a caching resolver, instead of default one\"\"\"\n-\n-    def __init__(self):\n-        self.spider_hostnames = defaultdict(set)\n-        self.resolver = _CachingThreadedResolver(reactor)\n-        reactor.installResolver(self.resolver)\n-        dispatcher.connect(self.request_received, signals.request_received)\n-        dispatcher.connect(self.spider_closed, signal=signals.spider_closed)\n-\n-    def request_received(self, request, spider):\n-        url_hostname = urlparse_cached(request).hostname\n-        self.spider_hostnames[spider].add(url_hostname)\n-\n-    def spider_closed(self, spider):\n-        for hostname in self.spider_hostnames[spider]:\n-            self.resolver._cache.pop(hostname, None)\n-        self.spider_hostnames.pop(spider, None)\n-\n-\n-class _CachingThreadedResolver(ThreadedResolver):\n-\n-    def __init__(self, *args, **kwargs):\n-        ThreadedResolver.__init__(self, *args, **kwargs)\n-        self._cache = {}\n-\n-    def getHostByName(self, name, timeout = (1, 3, 11, 45)):\n-        if name in self._cache:\n-            return defer.succeed(self._cache[name])\n-        dfd = ThreadedResolver.getHostByName(self, name, timeout)\n-        dfd.addCallback(self._cache_result, name)\n-        return dfd\n-\n-    def _cache_result(self, result, name):\n-        self._cache[name] = result\n-        return result\n\n@@ -4,6 +4,7 @@ from twisted.internet import reactor, defer\n \n from scrapy.xlib.pydispatch import dispatcher\n from scrapy.core.engine import ExecutionEngine\n+from scrapy.resolver import CachingThreadedResolver\n from scrapy.extension import ExtensionManager\n from scrapy.utils.ossignal import install_shutdown_handlers, signal_names\n from scrapy.utils.misc import load_object\n@@ -69,6 +70,7 @@ class CrawlerProcess(Crawler):\n \n     def start(self):\n         super(CrawlerProcess, self).start()\n+        reactor.installResolver(CachingThreadedResolver(reactor))\n         reactor.addSystemEventTrigger('before', 'shutdown', self.stop)\n         reactor.run(installSignalHandlers=False) # blocking call\n \n\n@@ -0,0 +1,27 @@\n+import socket\n+\n+from twisted.internet import defer\n+from twisted.internet.base import ThreadedResolver\n+\n+from scrapy.utils.datatypes import LocalCache\n+\n+\n+dnscache = LocalCache(10000) # XXX: make size a setting?\n+\n+def gethostbyname(hostname):\n+    if hostname not in dnscache:\n+        dnscache[hostname] = socket.gethostbyname(hostname)\n+    return dnscache[hostname]\n+\n+class CachingThreadedResolver(ThreadedResolver):\n+\n+    def getHostByName(self, name, timeout = (1, 3, 11, 45)):\n+        if name in dnscache:\n+            return defer.succeed(dnscache[name])\n+        d = ThreadedResolver.getHostByName(self, name, timeout)\n+        d.addCallback(self._cache_result, name)\n+        return d\n+\n+    def _cache_result(self, result, name):\n+        dnscache[name] = result\n+        return result\n\n@@ -9,6 +9,9 @@ import copy\n from collections import deque, defaultdict\n from itertools import chain\n \n+from scrapy.utils.py27 import OrderedDict\n+\n+\n class MultiValueDictKeyError(KeyError):\n     pass\n \n@@ -342,3 +345,19 @@ class PriorityStack(PriorityQueue):\n         else:\n             self.positems[priority].append(item)\n \n+\n+class LocalCache(OrderedDict):\n+    \"\"\"Dictionary with a finite number of keys.\n+\n+    Older items expires first.\n+\n+    \"\"\"\n+\n+    def __init__(self, limit=None):\n+        super(LocalCache, self).__init__()\n+        self.limit = limit\n+\n+    def __setitem__(self, key, value):\n+        while len(self) >= self.limit:\n+            self.popitem(last=False)\n+        super(LocalCache, self).__setitem__(key, value)\n\n@@ -0,0 +1,10 @@\n+\"\"\"\n+Similar to scrapy.utils.py26, but for Python 2.7\n+\"\"\"\n+\n+__all__ = ['OrderedDict']\n+\n+try:\n+    from collections import OrderedDict\n+except ImportError:\n+    from scrapy.xlib.ordereddict import OrderedDict\n\n@@ -0,0 +1,127 @@\n+# Copyright (c) 2009 Raymond Hettinger\r\n+#\r\n+# Permission is hereby granted, free of charge, to any person\r\n+# obtaining a copy of this software and associated documentation files\r\n+# (the \"Software\"), to deal in the Software without restriction,\r\n+# including without limitation the rights to use, copy, modify, merge,\r\n+# publish, distribute, sublicense, and/or sell copies of the Software,\r\n+# and to permit persons to whom the Software is furnished to do so,\r\n+# subject to the following conditions:\r\n+#\r\n+#     The above copyright notice and this permission notice shall be\r\n+#     included in all copies or substantial portions of the Software.\r\n+#\r\n+#     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\r\n+#     EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\r\n+#     OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\r\n+#     NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\r\n+#     HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\r\n+#     WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\r\n+#     FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\r\n+#     OTHER DEALINGS IN THE SOFTWARE.\r\n+\r\n+from UserDict import DictMixin\r\n+\r\n+class OrderedDict(dict, DictMixin):\r\n+\r\n+    def __init__(self, *args, **kwds):\r\n+        if len(args) > 1:\r\n+            raise TypeError('expected at most 1 arguments, got %d' % len(args))\r\n+        try:\r\n+            self.__end\r\n+        except AttributeError:\r\n+            self.clear()\r\n+        self.update(*args, **kwds)\r\n+\r\n+    def clear(self):\r\n+        self.__end = end = []\r\n+        end += [None, end, end]         # sentinel node for doubly linked list\r\n+        self.__map = {}                 # key --> [key, prev, next]\r\n+        dict.clear(self)\r\n+\r\n+    def __setitem__(self, key, value):\r\n+        if key not in self:\r\n+            end = self.__end\r\n+            curr = end[1]\r\n+            curr[2] = end[1] = self.__map[key] = [key, curr, end]\r\n+        dict.__setitem__(self, key, value)\r\n+\r\n+    def __delitem__(self, key):\r\n+        dict.__delitem__(self, key)\r\n+        key, prev, next = self.__map.pop(key)\r\n+        prev[2] = next\r\n+        next[1] = prev\r\n+\r\n+    def __iter__(self):\r\n+        end = self.__end\r\n+        curr = end[2]\r\n+        while curr is not end:\r\n+            yield curr[0]\r\n+            curr = curr[2]\r\n+\r\n+    def __reversed__(self):\r\n+        end = self.__end\r\n+        curr = end[1]\r\n+        while curr is not end:\r\n+            yield curr[0]\r\n+            curr = curr[1]\r\n+\r\n+    def popitem(self, last=True):\r\n+        if not self:\r\n+            raise KeyError('dictionary is empty')\r\n+        if last:\r\n+            key = reversed(self).next()\r\n+        else:\r\n+            key = iter(self).next()\r\n+        value = self.pop(key)\r\n+        return key, value\r\n+\r\n+    def __reduce__(self):\r\n+        items = [[k, self[k]] for k in self]\r\n+        tmp = self.__map, self.__end\r\n+        del self.__map, self.__end\r\n+        inst_dict = vars(self).copy()\r\n+        self.__map, self.__end = tmp\r\n+        if inst_dict:\r\n+            return (self.__class__, (items,), inst_dict)\r\n+        return self.__class__, (items,)\r\n+\r\n+    def keys(self):\r\n+        return list(self)\r\n+\r\n+    setdefault = DictMixin.setdefault\r\n+    update = DictMixin.update\r\n+    pop = DictMixin.pop\r\n+    values = DictMixin.values\r\n+    items = DictMixin.items\r\n+    iterkeys = DictMixin.iterkeys\r\n+    itervalues = DictMixin.itervalues\r\n+    iteritems = DictMixin.iteritems\r\n+\r\n+    def __repr__(self):\r\n+        if not self:\r\n+            return '%s()' % (self.__class__.__name__,)\r\n+        return '%s(%r)' % (self.__class__.__name__, self.items())\r\n+\r\n+    def copy(self):\r\n+        return self.__class__(self)\r\n+\r\n+    @classmethod\r\n+    def fromkeys(cls, iterable, value=None):\r\n+        d = cls()\r\n+        for key in iterable:\r\n+            d[key] = value\r\n+        return d\r\n+\r\n+    def __eq__(self, other):\r\n+        if isinstance(other, OrderedDict):\r\n+            if len(self) != len(other):\r\n+                return False\r\n+            for p, q in  zip(self.items(), other.items()):\r\n+                if p != q:\r\n+                    return False\r\n+            return True\r\n+        return dict.__eq__(self, other)\r\n+\r\n+    def __ne__(self, other):\r\n+        return not self == other\r\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#b47f5330fd969eb6a071cc7cf7314411a1aca87a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 36 | Lines Deleted: 20 | Files Changed: 2 | Hunks: 10 | Methods Changed: 9 | Complexity Δ (Sum/Max): 4/3 | Churn Δ: 56 | Churn Cumulative: 115 | Contributors (this commit): 3 | Commits (past 90d): 2 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -6,23 +6,24 @@ its documentation in: docs/topics/link-extractors.rst\n \"\"\"\n \n class Link(object):\n-    \"\"\"Link objects represent an extracted link by the LinkExtractor.\n-    At the moment, it contains just the url and link text.\n-    \"\"\"\n+    \"\"\"Link objects represent an extracted link by the LinkExtractor.\"\"\"\n \n-    __slots__ = ['url', 'text', 'nofollow']\n+    __slots__ = ['url', 'text', 'fragment', 'nofollow']\n \n-    def __init__(self, url, text='', nofollow=False):\n+    def __init__(self, url, text='', fragment='', nofollow=False):\n         self.url = url\n         self.text = text\n+        self.fragment = fragment\n         self.nofollow = nofollow\n \n     def __eq__(self, other):\n-        return self.url == other.url and self.text == other.text and self.nofollow == other.nofollow\n+        return self.url == other.url and self.text == other.text and \\\n+            self.fragment == other.fragment and self.nofollow == other.nofollow\n    \n     def __hash__(self):\n-        return hash(self.url) ^ hash(self.text) ^ hash(self.nofollow)\n+        return hash(self.url) ^ hash(self.text) ^ hash(self.fragment) ^ hash(self.nofollow)\n \n     def __repr__(self):\n-        return 'Link(url=%r, text=%r, nofollow=%r)' % (self.url, self.text, self.nofollow)\n+        return 'Link(url=%r, text=%r, fragment=%r, nofollow=%r)' % \\\n+            (self.url, self.text, self.fragment, self.nofollow)\n \n\n@@ -4,25 +4,40 @@ from scrapy.link import Link\n \n class LinkTest(unittest.TestCase):\n \n+    def _assert_same_links(self, link1, link2):\n+        self.assertEqual(link1, link2)\n+        self.assertEqual(hash(link1), hash(link2))\n+\n+    def _assert_different_links(self, link1, link2):\n+        self.assertNotEqual(link1, link2)\n+        self.assertNotEqual(hash(link1), hash(link2))\n+\n     def test_eq_and_hash(self):\n         l1 = Link(\"http://www.example.com\")\n         l2 = Link(\"http://www.example.com/other\")\n         l3 = Link(\"http://www.example.com\")\n \n-        self.assertEqual(l1, l1)\n-        self.assertEqual(hash(l1), hash(l1))\n-        self.assertNotEqual(l1, l2)\n-        self.assertNotEqual(hash(l1), hash(l2))\n-        self.assertEqual(l1, l3)\n-        self.assertEqual(hash(l1), hash(l3))\n+        self._assert_same_links(l1, l1)\n+        self._assert_different_links(l1, l2)\n+        self._assert_same_links(l1, l3)\n \n         l4 = Link(\"http://www.example.com\", text=\"test\")\n         l5 = Link(\"http://www.example.com\", text=\"test2\")\n         l6 = Link(\"http://www.example.com\", text=\"test\")\n \n-        self.assertEqual(l4, l4)\n-        self.assertEqual(hash(l4), hash(l4))\n-        self.assertNotEqual(l4, l5)\n-        self.assertNotEqual(hash(l4), hash(l5))\n-        self.assertEqual(l4, l6)\n-        self.assertEqual(hash(l4), hash(l6))\n+        self._assert_same_links(l4, l4)\n+        self._assert_different_links(l4, l5)\n+        self._assert_same_links(l4, l6)\n+\n+        l7 = Link(\"http://www.example.com\", text=\"test\", fragment='something', nofollow=False)\n+        l8 = Link(\"http://www.example.com\", text=\"test\", fragment='something', nofollow=False)\n+        l9 = Link(\"http://www.example.com\", text=\"test\", fragment='something', nofollow=True)\n+        l10 = Link(\"http://www.example.com\", text=\"test\", fragment='other', nofollow=False)\n+        self._assert_same_links(l7, l8)\n+        self._assert_different_links(l7, l9)\n+        self._assert_different_links(l7, l10)\n+\n+    def test_repr(self):\n+        l1 = Link(\"http://www.example.com\", text=\"test\", fragment='something', nofollow=True)\n+        l2 = eval(repr(l1))\n+        self._assert_same_links(l1, l2)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#a45dca32f5496b7de3e37809504bb72e634a8a6c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 16 | Files Changed: 1 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): -4/0 | Churn Δ: 18 | Churn Cumulative: 179 | Contributors (this commit): 2 | Commits (past 90d): 1 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -4,9 +4,7 @@ Item pipeline\n See documentation in docs/item-pipeline.rst\n \"\"\"\n \n-from scrapy import log\n from scrapy.middleware import MiddlewareManager\n-from scrapy.utils.python import get_func_args\n \n class ItemPipelineManager(MiddlewareManager):\n \n@@ -16,22 +14,10 @@ class ItemPipelineManager(MiddlewareManager):\n     def _get_mwlist_from_settings(cls, settings):\n         return settings.getlist('ITEM_PIPELINES')\n \n-    # FIXME: remove in Scrapy 0.11\n-    def _wrap_old_process_item(self, old):\n-        def new(item, spider):\n-            return old(spider, item)\n-        return new\n-\n     def _add_middleware(self, pipe):\n         super(ItemPipelineManager, self)._add_middleware(pipe)\n-        func = getattr(pipe, 'process_item', None)\n-        if func:\n-            # FIXME: remove in Scrapy 0.11\n-            fargs = get_func_args(func.im_func)\n-            if fargs and fargs[1] == 'spider':\n-                log.msg(\"Update %s.process_item() method to receive (item, spider) instead of (spider, item) or they will stop working on Scrapy 0.11\" % pipe.__class__.__name__, log.WARNING)\n-                func = self._wrap_old_process_item(func)\n-            self.methods['process_item'].append(func)\n+        if hasattr(pipe, 'process_item'):\n+            self.methods['process_item'].append(pipe.process_item)\n \n     def process_item(self, item, spider):\n         return self._process_chain('process_item', item, spider)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#ce38022665d1718f0454ee6b5921aecfa95feed9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 31 | Lines Deleted: 13 | Files Changed: 1 | Hunks: 9 | Methods Changed: 8 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 44 | Churn Cumulative: 540 | Contributors (this commit): 2 | Commits (past 90d): 10 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -22,9 +22,9 @@ from .handlers import DownloadHandlers\n class Slot(object):\n     \"\"\"Downloader slot\"\"\"\n \n-    def __init__(self, concurrency, settings):\n+    def __init__(self, concurrency, delay, settings):\n         self.concurrency = concurrency\n-        self.delay = settings.getfloat('DOWNLOAD_DELAY')\n+        self.delay = delay\n         self.randomize_delay = settings.getbool('RANDOMIZE_DOWNLOAD_DELAY')\n         self.active = set()\n         self.queue = deque()\n@@ -40,6 +40,28 @@ class Slot(object):\n         return self.delay\n \n \n+def _get_concurrency_delay(concurrency, spider, settings):\n+    delay = settings.getfloat('DOWNLOAD_DELAY')\n+    if hasattr(spider, 'download_delay'):\n+        delay = spider.download_delay\n+\n+    # TODO: remove for Scrapy 0.15\n+    c = settings.getint('CONCURRENT_REQUESTS_PER_SPIDER')\n+    if c:\n+        warnings.warn(\"CONCURRENT_REQUESTS_PER_SPIDER setting is deprecated, \" \\\n+            \"use CONCURRENT_REQUESTS_PER_DOMAIN instead\", DeprecationWarning)\n+        concurrency = c\n+    # ----------------------------\n+\n+    if hasattr(spider, 'max_concurrent_requests'):\n+        concurrency = spider.max_concurrent_requests\n+\n+    if delay > 0:\n+        concurrency = 1 # force concurrency=1 if download delay required\n+\n+    return concurrency, delay\n+\n+\n class Downloader(object):\n \n     def __init__(self, settings):\n@@ -52,14 +74,9 @@ class Downloader(object):\n         self.ip_concurrency = settings.getint('CONCURRENT_REQUESTS_PER_IP')\n         self.middleware = DownloaderMiddlewareManager.from_settings(settings)\n \n-        # TODO: remove for Scrapy 0.15\n-        c = settings.getint('CONCURRENT_REQUESTS_PER_SPIDER')\n-        if c:\n-            warnings.warn(\"CONCURRENT_REQUESTS_PER_SPIDER setting is deprecated, use CONCURRENT_REQUESTS_PER_DOMAIN instead\", DeprecationWarning)\n-            self.domain_concurrency = c\n \n     def fetch(self, request, spider):\n-        key, slot = self._get_slot(request)\n+        key, slot = self._get_slot(request, spider)\n \n         self.active.add(request)\n         slot.active.add(request)\n@@ -77,8 +94,9 @@ class Downloader(object):\n     def needs_backout(self):\n         return len(self.active) >= self.total_concurrency\n \n-    def _get_slot(self, request):\n+    def _get_slot(self, request, spider):\n         key = urlparse_cached(request).hostname\n+        if key not in self.slots:\n             if self.ip_concurrency:\n                 concurrency = self.ip_concurrency\n                 try:\n@@ -87,8 +105,8 @@ class Downloader(object):\n                     pass\n             else:\n                 concurrency = self.domain_concurrency\n-        if key not in self.slots:\n-            self.slots[key] = Slot(concurrency, self.settings)\n+            concurrency, delay = _get_concurrency_delay(concurrency, spider, self.settings)\n+            self.slots[key] = Slot(concurrency, delay, self.settings)\n         return key, self.slots[key]\n \n     def _enqueue_request(self, request, spider, slot):\n@@ -110,8 +128,8 @@ class Downloader(object):\n             penalty = delay - now + slot.lastseen\n             if penalty > 0 and slot.free_transfer_slots():\n                 d = defer.Deferred()\n-                d.addCallback(self._process_queue)\n-                reactor.callLater(penalty, d.callback, spider, slot)\n+                d.addCallback(self._process_queue, slot)\n+                reactor.callLater(penalty, d.callback, spider)\n                 return\n         slot.lastseen = now\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#4d1e01a4d421a425f8de21abfe6a51ba759e7dc6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 598 | Files Changed: 3 | Hunks: 3 | Methods Changed: 18 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 598 | Churn Cumulative: 598 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 6 | DMM Complexity: 0.24316109422492402\n\nDIFF:\n@@ -1,370 +0,0 @@\n-from collections import deque, defaultdict\n-from heapq import heappush, heappop\n-import time\n-from itertools import chain\n-\n-#------------------------------------------------------------------------------\n-\n-class PriorityQueue1(object):\n-    \"\"\"heapq\n-\n-    A simple priority queue\n-    \"\"\"\n-\n-    def __init__(self, size=1):\n-        self.items = []\n-\n-    def push(self, item, priority=0):\n-        heappush(self.items, (priority, time.time(), item))\n-\n-    def pop(self):\n-        priority, _, item = heappop(self.items)\n-        return item, priority\n-\n-    def __len__(self):\n-        return len(self.items)\n-\n-    def __iter__(self):\n-        return ((item, priority) for priority, _, item in self.items)\n-\n-    def __nonzero__(self):\n-        return bool(self.items)\n-\n-\n-class PriorityQueue1b(PriorityQueue1):\n-    \"\"\"heapq+int\n-\n-    A simple priority queue using incremental integer instead of time.time()\n-    \"\"\"\n-    time = 0\n-\n-    def push(self, item, priority=0):\n-        self.time += 1\n-        heappush(self.items, (priority, time, item))\n-\n-#------------------------------------------------------------------------------\n-\n-class PriorityQueue2(object):\n-    \"\"\"dict+deque\n-\n-    @author: Federico Feroldi <federico@cloudify.me>\n-    \"\"\"\n-    def __init__(self, size=1):\n-        self.items = defaultdict(deque)\n-\n-    def push(self, item, priority=0):\n-        self.items[priority].appendleft(item)\n-\n-    def pop(self):\n-        priorities = self.items.keys()\n-        priorities.sort()\n-\n-        for priority in priorities:\n-            if len(self.items[priority]) > 0:\n-                return (self.items[priority].pop(), priority)\n-\n-        raise IndexError\n-\n-    def __len__(self):\n-        totlen = 0\n-        for q in self.items.values():\n-            totlen += len(q)\n-        return totlen\n-\n-    def __iter__(self):\n-        priorities = self.items.keys()\n-        priorities.sort()\n-\n-        for priority in priorities:\n-            for i in self.items[priority]:\n-                yield (i, priority)\n-\n-    def __nonzero__(self):\n-        for q in self.items.values():\n-            if len(q) > 0:\n-                return True\n-        return False\n-\n-#------------------------------------------------------------------------------\n-\n-class PriorityQueue3(object):\n-    \"\"\"deque+heapq\"\"\"\n-\n-    def __init__(self, size=1):\n-        self.negitems = []\n-        self.pzero = deque()\n-        self.positems = []\n-\n-    def push(self, item, priority=0):\n-        if priority == 0:\n-            self.pzero.appendleft(item)\n-        elif priority < 0:\n-            heappush(self.negitems, (priority, time.time(), item))\n-        else:\n-            heappush(self.positems, (priority, time.time(), item))\n-\n-    def pop(self):\n-        if self.negitems:\n-            priority, _, item = heappop(self.negitems)\n-            return item, priority\n-        elif self.pzero:\n-            return (self.pzero.pop(), 0)\n-        else:\n-            priority, _, item = heappop(self.positems)\n-            return item, priority\n-\n-    def __len__(self):\n-        return len(self.negitems) + len(self.pzero) + len(self.positems)\n-\n-    def __iter__(self):\n-        for priority, _, item in self.negitems:\n-            yield (item, priority)\n-        for item in self.pzero:\n-            yield (item, 0)\n-        for priority, _, item in self.positems:\n-            yield (item, priority)\n-\n-    def __nonzero__(self):\n-        return bool(self.negitems and self.pzero and self.positems)\n-\n-\n-class PriorityQueue3b(PriorityQueue3):\n-    \"\"\"deque+heapq+int\"\"\"\n-\n-    left_time = 0\n-    right_time = 0\n-\n-    def push(self, item, priority=0):\n-        if priority == 0:\n-            self.pzero.appendleft(item)\n-        elif priority < 0:\n-            self.left_time += 1\n-            heappush(self.negitems, (priority, self.left_time, item))\n-        else:\n-            self.right_time += 1\n-            heappush(self.positems, (priority, self.right_time, item))\n-\n-\n-#------------------------------------------------------------------------------\n-\n-class PriorityQueue4(object):\n-    \"\"\"deque+defaultdict+deque\"\"\"\n-\n-    def __init__(self, size=1):\n-        self.negitems = defaultdict(deque)\n-        self.pzero = deque()\n-        self.positems = defaultdict(deque)\n-\n-    def push(self, item, priority=0):\n-        if priority == 0:\n-            self.pzero.appendleft(item)\n-        elif priority < 0:\n-            self.negitems[priority].appendleft(item)\n-        else:\n-            self.positems[priority].appendleft(item)\n-\n-    def pop(self):\n-        if self.negitems:\n-            priorities = self.negitems.keys()\n-            priorities.sort()\n-            for priority in priorities:\n-                deq = self.negitems[priority]\n-                if deq:\n-                    t = (deq.pop(), priority)\n-                    if not deq:\n-                        del self.negitems[priority]\n-                    return t\n-        elif self.pzero:\n-            return (self.pzero.pop(), 0)\n-        else:\n-            priorities = self.positems.keys()\n-            priorities.sort()\n-            for priority in priorities:\n-                deq = self.positems[priority]\n-                if deq:\n-                    t = (deq.pop(), priority)\n-                    if not deq:\n-                        del self.positems[priority]\n-                    return t\n-        raise IndexError(\"pop from an empty queue\")\n-\n-    def __len__(self):\n-        total = sum(len(v) for v in self.negitems.values()) + \\\n-                len(self.pzero) + \\\n-                sum(len(v) for v in self.positems.values())\n-        return total\n-\n-    def __iter__(self):\n-        gen_negs = ((i, priority) \n-                    for priority in sorted(self.negitems.keys())\n-                    for i in reversed(self.negitems[priority]))\n-        gen_zeros = ((item,0) for item in self.pzero)\n-        gen_pos = ((i, priority) \n-                    for priority in sorted(self.positems.keys())\n-                    for i in reversed(self.positems[priority]))\n-        return chain(gen_negs, gen_zeros, gen_pos)\n-\n-\n-    def __nonzero__(self):\n-        return bool(self.negitems or self.pzero or self.positems)\n-\n-class PriorityQueue4b(object):\n-    \"\"\"deque+defaultdict+deque+cache\"\"\"\n-\n-    def __init__(self, size=1):\n-        self.negitems = defaultdict(deque)\n-        self.pzero = deque()\n-        self.positems = defaultdict(deque)\n-        self._sort_neg = False\n-        self._sort_pos = False\n-        self._cached_sorted_negitems = []\n-        self._cached_sorted_positems = []\n-\n-    def push(self, item, priority=0):\n-        if priority == 0:\n-            self.pzero.appendleft(item)\n-        elif priority < 0:\n-            if priority not in self.negitems:\n-                self._sort_neg = True\n-            self.negitems[priority].appendleft(item)\n-        else:\n-            if priority not in self.positems:\n-                self._sort_pos = True\n-            self.positems[priority].appendleft(item)\n-\n-    def pop(self):\n-        if self.negitems:\n-            if self._sort_neg:\n-                priorities = self.negitems.keys()\n-                priorities.sort()\n-                self._cached_sorted_negitems = priorities\n-                self._sort_neg = False\n-            else:\n-                priorities = self._cached_sorted_negitems\n-\n-            for priority in priorities:\n-                deq = self.negitems[priority]\n-                if deq:\n-                    t = (deq.pop(), priority)\n-                    if not deq:\n-                        self._sort_neg = True\n-                        del self.negitems[priority]\n-                    return t\n-        elif self.pzero:\n-            return (self.pzero.pop(), 0)\n-        else:\n-            if self._sort_pos:\n-                priorities = self.positems.keys()\n-                priorities.sort()\n-                self._cached_sorted_positems = priorities\n-                self._sort_pos = False\n-            else:\n-                priorities = self._cached_sorted_positems\n-\n-            priorities = self.positems.keys()\n-            priorities.sort()\n-            for priority in priorities:\n-                deq = self.positems[priority]\n-                if deq:\n-                    t = (deq.pop(), priority)\n-                    if not deq:\n-                        self._sort_pos = True\n-                        del self.positems[priority]\n-                    return t\n-        raise IndexError(\"pop from an empty queue\")\n-\n-    def __len__(self):\n-        total = sum(len(v) for v in self.negitems.values()) + \\\n-                len(self.pzero) + \\\n-                sum(len(v) for v in self.positems.values())\n-        return total\n-\n-    def __iter__(self):\n-        gen_negs = ((i, priority) \n-                    for priority in sorted(self.negitems.keys())\n-                    for i in reversed(self.negitems[priority]))\n-        gen_zeros = ((item,0) for item in self.pzero)\n-        gen_pos = ((i, priority) \n-                    for priority in sorted(self.positems.keys())\n-                    for i in reversed(self.positems[priority]))\n-        return chain(gen_negs, gen_zeros, gen_pos)\n-\n-\n-    def __nonzero__(self):\n-        return bool(self.negitems or self.pzero or self.positems)\n-\n-#------------------------------------------------------------------------------\n-\n-class PriorityQueue5(object):\n-    \"\"\"list+deque\"\"\"\n-\n-    def __init__(self, size=1):\n-        # preallocate deques for a fixed number of priorities\n-        size = size if size % 2 else size + 1\n-        self.zero = size // 2\n-        self.priolist = [deque() for _ in range(size)]\n-\n-    def push(self, item, priority=0):\n-        self.priolist[priority + self.zero].appendleft(item)\n-\n-    def pop(self):\n-        for prio, queue in enumerate(self.priolist):\n-            if len(queue):\n-                final = prio - self.zero\n-                return (queue.pop(), final)\n-\n-        raise IndexError(\"pop from an empty queue\")\n-\n-    def __len__(self):\n-        return sum(len(v) for v in self.priolist)\n-\n-    def __iter__(self):\n-        for prio, queue in enumerate(self.priolist):\n-            final = prio - self.zero\n-            for i in reversed(queue):\n-                yield (i, final)\n-\n-    def __nonzero__(self):\n-        return any(d for d in self.priolist)\n-\n-class PriorityQueue5b(PriorityQueue5):\n-    \"\"\"list+deque+cache\"\"\"\n-    index = 0\n-\n-    def push(self, item, priority=0):\n-        i = priority + self.zero\n-        self.priolist[i].appendleft(item)\n-        self.index = min(self.index, i)\n-\n-    def pop(self):\n-        cached = self.priolist[self.index]\n-        if cached:\n-            return (cached.pop(), self.index - self.zero)\n-\n-        for prio, queue in enumerate(self.priolist[self.index:]):\n-            if queue:\n-                self.index += prio\n-                return (queue.pop(), self.index - self.zero)\n-\n-        raise IndexError(\"pop from an empty queue\")\n-\n-\n-from itertools import islice\n-class PriorityQueue5c(PriorityQueue5b):\n-    \"\"\"list+deque+cache+islice\"\"\"\n-\n-    def pop(self):\n-        cached = self.priolist[self.index]\n-        if cached:\n-            return (cached.pop(), self.index - self.zero)\n-\n-        for prio, queue in enumerate(islice(self.priolist, self.index, None), self.index):\n-            if queue:\n-                self.index = prio\n-                return (queue.pop(), prio - self.zero)\n-\n-        raise IndexError(\"pop from an empty queue\")\n-\n-#------------------------------------------------------------------------------\n-\n-__all__ = [name for name in globals().keys() if name.startswith('PriorityQueue')]\n\n@@ -1,157 +0,0 @@\n-from __future__ import with_statement\n-import os\n-import timeit\n-import random\n-from optparse import OptionParser\n-from tempfile import mktemp\n-from pq_classes import *\n-\n-TESTID = os.getpid()\n-\n-TESTCASES = (\n-       (\"heapq\", PriorityQueue1),\n-       #(\"heapq+int\", PriorityQueue1b),\n-       (\"dict+deque\", PriorityQueue2),\n-       (\"deque+heapq\", PriorityQueue3),\n-       #(\"deque+heapq+int\", PriorityQueue3b),\n-       (\"deque+defaultdict+deque\", PriorityQueue4),\n-       (\"deque+defaultdict+deque+cache\", PriorityQueue4b),\n-       #('list+deque', PriorityQueue5),\n-       ('list+deque+cache', PriorityQueue5b),\n-       #('list+deque+cache+islice', PriorityQueue5c),\n-       )\n-\n-\n-stmt_fmt = \"\"\"\n-for n, prio in enumerate(randomprio):\n-    q.push(n, prio)\n-\n-try:\n-    while True:\n-        q.pop()\n-except IndexError:\n-    pass\n-\"\"\"\n-\n-setup_fmt = \"\"\"\n-from collections import deque\n-from __main__ import %(PriorityClass)s as PriorityQueue\n-q = PriorityQueue(%(priorities)i)\n-\n-randomprio = deque()\n-for line in open('%(samplefile)s'):\n-    prio = int(line.strip())\n-    randomprio.append(prio)\n-\"\"\"\n-\n-\n-def _distribution(priorities, distribution):\n-    half = priorities // 2\n-    prio = -priorities\n-    while not (-half <= prio <= half):\n-        prio = round(distribution())\n-    return min(max(prio, -half), half)\n-\n-def normal_priority(priorities):\n-    sigma = priorities / 4.0\n-    dist = lambda: random.normalvariate(mu=0, sigma=sigma)\n-    return _distribution(priorities, dist)\n-\n-def gauss_priority(priorities):\n-    sigma = priorities / 4.0\n-    dist = lambda: random.gauss(mu=0, sigma=sigma)\n-    return _distribution(priorities, dist)\n-\n-def triangular_priority(priorities):\n-    half = priorities // 2\n-    return random.triangular(-half-1, half+1, 0)\n-\n-def uniform_priority(priorities):\n-    return int(random.random() * priorities) - (priorities / 2)\n-\n-\n-PRIORITY_DISTRIBUTIONS = {\n-        'uniform': uniform_priority,\n-        'normal': normal_priority,\n-        'gauss': gauss_priority,\n-        'triangular': triangular_priority,\n-        }\n-\n-\n-def gen_samples(count, priorities, priority_distribution=uniform_priority):\n-    fn = '/tmp/pq-%i-%i-%i' % (TESTID, priorities, count)\n-\n-    with open(fn, 'w') as samplefile:\n-        for n in xrange(count):\n-            prio = priority_distribution(priorities)\n-            samplefile.write('%i\\n' % prio)\n-    return fn\n-\n-def runtests(pushpops=50*1000, times=30, priorities=1, samplefile=None, priority_distribution=uniform_priority):\n-    samplefile = samplefile or gen_samples(pushpops, priorities, priority_distribution)\n-\n-    print \"\\n== With %s priorities (%s) ==\\n\" % (priorities, samplefile)\n-    print \"pushpops = %s, times = %s\" % (pushpops, times)\n-\n-\n-    stmt = stmt_fmt\n-    for name, cls in TESTCASES:\n-        setup = setup_fmt % {\n-                'PriorityClass': cls.__name__,\n-                'priorities': priorities,\n-                'samplefile': samplefile,\n-                }\n-        t = timeit.Timer(stmt, setup)\n-        print \"%s implementation: %s\" % (name, t.timeit(number=times))\n-\n-\n-if __name__ == '__main__':\n-    o = OptionParser()\n-    o.add_option('-n', '--samples-count', type='int', default=50000, metavar='NUMBER',\n-            help='The max number or samples to generate')\n-    o.add_option('-r', '--retry-times', type='int', default=30, metavar='NUMBER',\n-            help='the times to retry each test')\n-    o.add_option('-s', '--samplefile', default=None, metavar='FILENAME',\n-            help='load samples from file, default: use sample generator')\n-    o.add_option('-p', '--priorities', default='1,3,5,10,100', metavar='CSV_PRIOLIST',\n-            help='a comma separated list of priorities to test')\n-    o.add_option('-d', '--priority-distribution', default='uniform', metavar='DISTRIBUTION',\n-            help='distribution used for random priority generator, default: uniform. possibles: %s' \\\n-                    % ','.join(PRIORITY_DISTRIBUTIONS.keys()))\n-\n-    opt, args = o.parse_args()\n-\n-    priolist = map(int, opt.priorities.split(','))\n-    distribution = PRIORITY_DISTRIBUTIONS[opt.priority_distribution]\n-    for prio in priolist:\n-        runtests(pushpops=opt.samples_count, priorities=prio, times=opt.retry_times,\n-                samplefile=opt.samplefile, priority_distribution=distribution)\n-\n-# Results (in seconds, on an intel core2 2.16ghz):\n-# == Without priorities ==\n-\n-# pushpops = 50000, times = 30\n-# heapq implementation: 7.7959010601\n-# dict+deque implementation: 5.6420109272\n-# deque+heapq implementation: 3.57563900948\n-\n-# == With 5 priorities ==\n-\n-# pushpops = 50000, times = 30\n-# heapq implementation: 9.83902192116\n-# dict+deque implementation: 9.21094298363\n-# deque+heapq implementation: 9.05321097374\n-\n-# == With 10 priorities ==\n-\n-# pushpops = 50000, times = 30\n-# heapq implementation: 9.97831392288\n-# dict+deque implementation: 11.9721341133\n-# deque+heapq implementation: 9.79048800468\n-\n-# == With 100 priorities ==\n-\n-# pushpops = 50000, times = 30\n-# heapq implementation: 10.4782910347\n-# dict+deque implementation: 64.6989660263\n-# deque+heapq implementation: 10.858932972\n\n@@ -1,71 +0,0 @@\n-import sys\n-import unittest\n-from pq_classes import *\n-\n-# (ITEM, PRIORITY)\n-INPUT = [(1, -5), (30, -1), (80, -3), (4, 1), (6, 3), (20, 0), (50, -1)]\n-OUTPUT = [(1, -5), (80, -3), (30, -1), (50, -1), (20, 0), (4, 1), (6, 3)]\n-\n-PRIOSIZE = reduce(max, (abs(i[1]) for i in INPUT + OUTPUT)) * 2\n-\n-class TestPriorityQueue(object):\n-\n-    def test_popping(self):\n-        pq = self.PriorityQueue(PRIOSIZE)\n-        for item, pr in INPUT:\n-            pq.push(item, pr)\n-        l = []\n-        while pq:\n-            l.append(pq.pop())\n-        self.assertEquals(l, OUTPUT)\n-\n-    def test_iter(self):\n-        pq = self.PriorityQueue(PRIOSIZE)\n-        for item, pr in INPUT:\n-            pq.push(item, pr)\n-        result = [x for x in pq]\n-        self.assertEquals(result, OUTPUT)\n-\n-    def test_nonzero(self):\n-        pq = self.PriorityQueue(PRIOSIZE)\n-        pq.push(80, -1)\n-        pq.push(20, 0)\n-        pq.push(30, 1)\n-\n-        pq.pop()\n-        self.assertEquals(bool(pq), True)\n-        pq.pop()\n-        self.assertEquals(bool(pq), True)\n-        pq.pop()\n-        self.assertEquals(bool(pq), False)\n-\n-    def test_len(self):\n-        pq = self.PriorityQueue(PRIOSIZE)\n-        pq.push(80, -1)\n-        pq.push(20, 0)\n-        pq.push(30, 1)\n-\n-        self.assertEquals(len(pq), 3)\n-        pq.pop()\n-        self.assertEquals(len(pq), 2)\n-        pq.pop()\n-        self.assertEquals(len(pq), 1)\n-        pq.pop()\n-        self.assertEquals(len(pq), 0)\n-\n-    def test_indexerror(self):\n-        pq = self.PriorityQueue(PRIOSIZE)\n-        self.assertRaises(IndexError, pq.pop)\n-\n-\n-# automatically test any PriorityQueueN class defined at pq_classes\n-prioclasses = [(name, cls) for name, cls in globals().items() if name.startswith('PriorityQueue')]\n-for name, cls in prioclasses:\n-    testname = '%sTestCase' % name\n-    testcase = type(testname, (TestPriorityQueue, unittest.TestCase), {'PriorityQueue': cls})\n-    setattr(sys.modules[__name__], testname, testcase)\n-\n-\n-if __name__ == '__main__':\n-    print \"\\n== Unit testing for every implementation ==\"\n-    unittest.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
