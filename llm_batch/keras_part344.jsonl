{"custom_id": "keras#f26e2d64349082c45701005dc7a358616274a18a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 36 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 4 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 36 | Churn Cumulative: 546 | Contributors (this commit): 3 | Commits (past 90d): 2 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -351,6 +351,42 @@ class KerasModelsTest(tf.test.TestCase, parameterized.TestCase):\n \n     train_steps(input_iterator)\n \n+  def test_nested_tf_functions_with_tf_function_passing_to_strategy_run(\n+      self, distribution):\n+    self.skipTest(\"b/190608193\")\n+\n+    inputs = np.random.random((10, 3)).astype(np.float32)\n+    targets = np.ones((10, 4), dtype=np.float32)\n+    dataset = tf.data.Dataset.from_tensor_slices((inputs, targets)).repeat()\n+    dataset = dataset.batch(10)\n+    input_iterator = iter(distribution.experimental_distribute_dataset(dataset))\n+\n+    def get_model():\n+      x = keras.layers.Input(shape=(3,), name=\"input\")\n+      y = keras.layers.Dense(4, name=\"dense\")(x)\n+      model = keras.Model(x, y)\n+      return model\n+\n+    with distribution.scope():\n+      model = get_model()\n+      optimizer = keras.optimizer_v2.gradient_descent.SGD(0.1, momentum=0.01)\n+\n+    @tf.function\n+    def compute_loss(images, targets):\n+      outputs = model(images)\n+      return keras.losses.mean_squared_error(targets, outputs)\n+\n+    @tf.function\n+    def step_fn(inputs):\n+      images, targets = inputs\n+      with tf.GradientTape() as tape:\n+        loss = compute_loss(images, targets)\n+      grads = tape.gradient(loss, model.variables)\n+      optimizer.apply_gradients(zip(grads, model.variables))\n+\n+    inputs = next(input_iterator)\n+    distribution.run(step_fn, args=(inputs,))\n+\n   def test_customized_tf_module_run(self, distribution):\n     dataset = _get_dataset()\n     input_iterator = iter(distribution.experimental_distribute_dataset(dataset))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c9b5ba76053f32da422fdb351dbe895e2f5482e5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 240 | Lines Deleted: 113 | Files Changed: 13 | Hunks: 78 | Methods Changed: 48 | Complexity Δ (Sum/Max): 16/12 | Churn Δ: 353 | Churn Cumulative: 32043 | Contributors (this commit): 108 | Commits (past 90d): 60 | Contributors (cumulative): 153 | DMM Complexity: 0.5932203389830508\n\nDIFF:\n@@ -341,6 +341,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n     # submitted.\n     self._build_input_shape = None\n     self._saved_model_inputs_spec = None\n+    self._saved_model_arg_spec = None\n \n     # `Layer.compute_mask` will be called at the end of `Layer.__call__` if\n     # `Layer.compute_mask` is overridden, or if the `Layer` subclass sets\n@@ -963,7 +964,6 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n     # - input_spec compatibility is only checked against `inputs`\n     # - mixed precision casting (autocast) is only applied to `inputs`,\n     #   not to any other argument.\n-    # - setting the SavedModel saving spec.\n     inputs, args, kwargs = self._split_out_first_arg(args, kwargs)\n     input_list = tf.nest.flatten(inputs)\n \n@@ -1041,7 +1041,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n         if self._supports_masking:\n           self._set_mask_metadata(inputs, outputs, input_masks, not eager)\n         if self._saved_model_inputs_spec is None:\n-          self._set_save_spec(inputs)\n+          self._set_save_spec(inputs, args, kwargs)\n \n         return outputs\n \n@@ -3015,20 +3015,54 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n   # SavedModel properties. Please see keras/saving/saved_model for details.\n \n   @tf.__internal__.tracking.no_automatic_dependency_tracking\n-  def _set_save_spec(self, inputs):\n+  def _set_save_spec(self, inputs, args=None, kwargs=None):\n+    \"\"\"Defines the save spec so that serialization is able to trace layer call.\n+\n+    The TensorSpecs of the call function `inputs`, `args`, and `kwargs` are\n+    saved into a tuple of `([inputs] + args, kwargs)`.\n+\n+    Args:\n+      inputs: possibly nested inputs passed into the call function.\n+      args: a list of positional arguments passed into call.\n+      kwargs: a dictionary of keyword arguments passed into call.\n+    \"\"\"\n     if self._saved_model_inputs_spec is not None:\n       return  # Already set.\n+    args = args or []\n+    kwargs = kwargs or {}\n \n-    self._saved_model_inputs_spec = tf.nest.map_structure(tf_utils.get_tensor_spec,\n-                                                       inputs)\n+    inputs_spec = tf.nest.map_structure(tf_utils.get_tensor_spec, inputs)\n \n-  def _get_save_spec(self, dynamic_batch=True):\n+    # Filter out non-tensor arguments from args and kwargs.\n+    args_spec = []\n+    for arg in args:\n+      flat_arg = tf.nest.flatten(arg)\n+      flat_specs = [tf_utils.get_tensor_spec(x) for x in flat_arg]\n+      if any(s is None for s in flat_specs):\n+        break  # Stop recording positional args once a non-tensor has been found\n+      args_spec.append(tf.nest.pack_sequence_as(arg, flat_specs))\n+    kwargs_spec = {}\n+    for key, kwarg in kwargs.items():\n+      if key == 'training':\n+        continue\n+      flat_kwarg = tf.nest.flatten(kwarg)\n+      flat_specs = [tf_utils.get_tensor_spec(x) for x in flat_kwarg]\n+      if any(s is None for s in flat_specs):\n+        continue\n+      kwargs[key] = args_spec.append(\n+          tf.nest.pack_sequence_as(kwarg, flat_specs))\n+\n+    self._saved_model_inputs_spec = inputs_spec\n+    self._saved_model_arg_spec = ([inputs_spec] + args_spec, kwargs_spec)\n+\n+  def _get_save_spec(self, dynamic_batch=True, inputs_only=True):\n     if self._saved_model_inputs_spec is None:\n       return None\n \n-    return tf.nest.map_structure(\n+    spec = tf.nest.map_structure(\n         lambda t: tf_utils.get_tensor_spec(t, dynamic_batch=dynamic_batch),\n-        self._saved_model_inputs_spec)\n+        self._saved_model_arg_spec)\n+    return spec[0][0] if inputs_only else spec\n \n   @property\n   def _trackable_saved_model_saver(self):\n\n@@ -799,6 +799,7 @@ class Layer(base_layer.Layer):\n             # TODO(b/120997007): This should be done in Eager as well, but\n             # causes garbage collection issues because of the placeholders\n             # created on the default Keras graph.\n+            self._set_save_spec(inputs, args, kwargs)\n             self._set_inputs(inputs, outputs)\n       else:\n         # Eager execution on data tensors.\n\n@@ -863,12 +863,12 @@ class Functional(training_lib.Model):\n   def _trackable_saved_model_saver(self):\n     return network_serialization.NetworkSavedModelSaver(self)\n \n-  def _get_save_spec(self, dynamic_batch=True):\n+  def _get_save_spec(self, dynamic_batch=True, inputs_only=True):\n     if getattr(self, '_has_explicit_input_shape', True):\n       # Functional models and Sequential models that have an explicit input\n       # shape should use the batch size set by the input layer.\n       dynamic_batch = False\n-    return super(Functional, self)._get_save_spec(dynamic_batch)\n+    return super(Functional, self)._get_save_spec(dynamic_batch, inputs_only)\n \n \n def _make_node_key(layer_name, node_index):\n\n@@ -286,6 +286,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     # Fault-tolerance handler. Set in `ModelCheckpoint`.\n     self._training_state = None\n     self._saved_model_inputs_spec = None\n+    self._saved_model_arg_spec = None\n     self._trackable_saver = saver_with_op_caching(self)\n \n     self._steps_per_execution = None\n@@ -2569,28 +2570,81 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     raise ValueError('Provide either a layer name or layer index.')\n \n   @tf.__internal__.tracking.no_automatic_dependency_tracking\n-  def _set_save_spec(self, inputs):\n+  def _set_save_spec(self, inputs, args=None, kwargs=None):\n+    \"\"\"Defines the save spec so that serialization is able to trace model call.\n+\n+    The TensorSpecs of the call function `inputs`, `args`, and `kwargs` are\n+    saved into a tuple of `([inputs] + args, kwargs)`. The input `TensorSpec`\n+    names are updated to match the built `input_names`.\n+\n+    The specs can be retrieved with the `save_spec` property.\n+\n+    Args:\n+      inputs: possibly nested inputs passed into the call function.\n+      args: a list of positional arguments passed into call.\n+      kwargs: a dictionary of keyword arguments passed into call.\n+    \"\"\"\n     if self._saved_model_inputs_spec is not None:\n       return  # Already set.\n+    args = args or []\n+    kwargs = kwargs or {}\n \n     input_names = self.input_names\n     if not input_names:\n       input_names = compile_utils.create_pseudo_input_names(inputs)\n \n     flat_inputs = tf.nest.flatten(inputs)\n-    specs = []\n+    inputs_spec = []\n     for name, tensor in zip(input_names, flat_inputs):\n-      specs.append(\n+      inputs_spec.append(\n           tf_utils.get_tensor_spec(tensor, dynamic_batch=False, name=name))\n-    specs = tf.nest.pack_sequence_as(inputs, specs)\n-\n-    self._saved_model_inputs_spec = specs\n+    inputs_spec = tf.nest.pack_sequence_as(inputs, inputs_spec)\n+    super(Model, self)._set_save_spec(inputs_spec, args, kwargs)\n \n     # Store the input shapes\n     if (self.__class__.__name__ == 'Sequential' and\n         self._build_input_shape is None):\n       self._build_input_shape = tf.nest.map_structure(\n-          lambda x: None if x is None else x.shape, specs)\n+          lambda x: None if x is None else x.shape, inputs_spec)\n+\n+  def save_spec(self, dynamic_batch=True):\n+    \"\"\"Returns the `tf.TensorSpec` of call inputs as a tuple `(args, kwargs)`.\n+\n+    This value is automatically defined after calling the model for the first\n+    time. Afterwards, you can use it when exporting the model for serving:\n+\n+    ```python\n+    model = tf.keras.Model(...)\n+\n+    @tf.function\n+    def serve(*args, **kwargs):\n+      outputs = model(*args, **kwargs)\n+      # Apply postprocessing steps, or add additional outputs.\n+      ...\n+      return outputs\n+\n+    # arg_specs is `[tf.TensorSpec(...), ...]`. kwarg_specs, in this example, is\n+    # an empty dict since functional models do not use keyword arguments.\n+    arg_specs, kwarg_specs = model.save_spec()\n+\n+    model.save(path, signatures={\n+      'serving_default': serve.get_concrete_function(*arg_specs, **kwarg_specs)\n+    })\n+    ```\n+\n+    Args:\n+      dynamic_batch: Whether to set the batch sizes of all the returned\n+        `tf.TensorSpec` to `None`. (Note that when defining functional or\n+        Sequential models with `tf.keras.Input([...], batch_size=X)`, the\n+        batch size will always be preserved). Defaults to `True`.\n+    Returns:\n+      If the model inputs are defined, returns a tuple `(args, kwargs)`. All\n+      elements in `args` and `kwargs` are `tf.TensorSpec`.\n+      If the model inputs are not defined, returns `None`.\n+      The model inputs are automatically set when calling the model,\n+      `model.fit`, `model.evaluate` or `model.predict`.\n+    \"\"\"\n+    return self._get_save_spec(dynamic_batch, inputs_only=False)\n \n   def _assert_weights_created(self):\n     \"\"\"Asserts that all the weights for the model have been created.\n\n@@ -128,6 +128,7 @@ def load(path, compile=True, options=None):  # pylint: disable=redefined-builtin\n     # When there are no Keras objects, return the results from the core loader\n     return tf.saved_model.load(path, options=options)\n \n+  metadata = _update_to_current_version(metadata)\n   # Recreate layers and metrics using the info stored in the metadata.\n   keras_loader = KerasObjectLoader(metadata, object_graph_def)\n   keras_loader.load_layers(compile=compile)\n@@ -173,6 +174,21 @@ def load(path, compile=True, options=None):  # pylint: disable=redefined-builtin\n   return model\n \n \n+def _update_to_current_version(metadata):\n+  \"\"\"Applies version updates to the metadata proto for backwards compat.\"\"\"\n+  for node in metadata.nodes:\n+    if node.version.producer == 1 and node.identifier in [\n+        constants.MODEL_IDENTIFIER, constants.SEQUENTIAL_IDENTIFIER,\n+        constants.NETWORK_IDENTIFIER]:\n+      node_metadata = json_utils.decode(node.metadata)\n+      save_spec = node_metadata.get('save_spec')\n+\n+      if save_spec is not None:\n+        node_metadata['full_save_spec'] = ([save_spec], {})\n+        node.metadata = json_utils.Encoder().encode(node_metadata)\n+  return metadata\n+\n+\n def _read_legacy_metadata(object_graph_def, metadata):\n   \"\"\"Builds a KerasMetadata proto from the SavedModel ObjectGraphDef.\"\"\"\n   # Older SavedModels store the metadata directly in the proto instead of the\n@@ -529,9 +545,11 @@ class KerasObjectLoader(object):\n     # Restore model save spec for subclassed models. (layers do not store a\n     # SaveSpec)\n     if isinstance(obj, training_lib.Model):\n-      save_spec = metadata.get('save_spec')\n-      if save_spec is not None:\n-        obj._set_save_spec(save_spec)\n+      full_save_spec = metadata.get('full_save_spec')\n+      if full_save_spec is not None:\n+        args_spec, kwargs_spec = full_save_spec\n+        inputs_spec = args_spec.pop(0)\n+        obj._set_save_spec(inputs_spec, args_spec, kwargs_spec)\n     # pylint: enable=protected-access\n \n     build_input_shape = metadata.get('build_input_shape')\n@@ -816,10 +834,22 @@ def _finalize_saved_model_layers(layers):\n         if not call_fn.concrete_functions:\n           continue\n         if call_fn.input_signature is None:\n-          inputs = infer_inputs_from_restored_call_function(call_fn)\n+          args, kwargs = infer_inputs_from_restored_call_function(call_fn)\n+          args = list(args)\n+          inputs = args.pop(0)\n         else:\n-          inputs = call_fn.input_signature[0]\n-        layer._set_inputs(inputs)  # pylint: disable=protected-access\n+          args = call_fn.input_signature\n+          args = list(args)\n+          inputs = args.pop(0)\n+          kwargs = None\n+        layer._set_save_spec(inputs, args, kwargs)  # pylint: disable=protected-access\n+\n+        # V1 models require calling _set_inputs to set the `.inputs` attr.\n+        # Skip this step when there are multiple tensor inputs (this behavior\n+        # is not well supported in V1 models).\n+        if not any(isinstance(x, tf.TensorSpec)\n+                   for x in tf.nest.flatten([args, kwargs])):\n+          layer._set_inputs(inputs)\n \n     # 3. Add losses that aren't generated by the layer.call function.\n     _restore_layer_unconditional_losses(layer)\n@@ -1124,9 +1154,13 @@ def infer_inputs_from_restored_call_function(fn):\n         one concrete function and that the inputs are in the first argument.\n \n   Returns:\n-    TensorSpec of call function inputs.\n+    TensorSpec of call function inputs in the form of (args, kwargs)\n   \"\"\"\n   def common_spec(x, y):\n+    if not isinstance(x, tf.TensorSpec):\n+      # Doesn't particularly matter what is returned in this case because the\n+      # result will be filtered out in _set_input_shape.\n+      return x\n     common_shape = get_common_shape(x.shape, y.shape)\n     if isinstance(x, tf.SparseTensorSpec):\n       return tf.SparseTensorSpec(common_shape, x.dtype)\n@@ -1134,9 +1168,9 @@ def infer_inputs_from_restored_call_function(fn):\n       return tf.RaggedTensorSpec(common_shape, x.dtype)\n     return tf.TensorSpec(common_shape, x.dtype, x.name)\n \n-  spec = fn.concrete_functions[0].structured_input_signature[0][0]\n+  spec = fn.concrete_functions[0].structured_input_signature\n   for concrete in fn.concrete_functions[1:]:\n-    spec2 = concrete.structured_input_signature[0][0]\n+    spec2 = concrete.structured_input_signature\n     spec = tf.nest.map_structure(common_spec, spec, spec2)\n   return spec\n \n\n@@ -32,7 +32,10 @@ class ModelSavedModelSaver(layer_serialization.LayerSavedModelSaver):\n     # Network stateful property is dependent on the child layers.\n     metadata.pop('stateful')\n     metadata['is_graph_network'] = self.obj._is_graph_network  # pylint: disable=protected-access\n-    metadata['save_spec'] = self.obj._get_save_spec(dynamic_batch=False)  # pylint: disable=protected-access\n+    spec = self.obj.save_spec(dynamic_batch=False)\n+    metadata['full_save_spec'] = spec\n+    # save_spec is saved for forward compatibility on older TF versions.\n+    metadata['save_spec'] = None if spec is None else spec[0][0]\n \n     metadata.update(\n         saving_utils.model_metadata(\n\n@@ -200,7 +200,7 @@ class ReviveTestBase(keras_parameterized.TestCase):\n                         self.evaluate(revived.weights))\n     input_arr = tf.constant(\n         np.random.random((2, 2, 3)).astype(np.float32))\n-    if isinstance(revived._saved_model_inputs_spec,\n+    if isinstance(revived.save_spec()[0][0],\n                   tf.SparseTensorSpec):\n       input_arr = tf.sparse.from_dense(input_arr)\n \n\n@@ -118,7 +118,7 @@ def generate_keras_metadata(saved_nodes, node_paths):\n           node_id=node_id,\n           node_path=node_path,\n           version=versions_pb2.VersionDef(\n-              producer=1, min_consumer=1, bad_consumers=[]),\n+              producer=2, min_consumer=1, bad_consumers=[]),\n           identifier=node._object_identifier,  # pylint: disable=protected-access\n           metadata=node._tracking_metadata)  # pylint: disable=protected-access\n \n\n@@ -193,9 +193,7 @@ def wrap_layer_functions(layer, serialization_cache):\n     with base_layer_utils.call_context().enter(\n         layer, inputs=None, build_graph=True, training=None, saving=True):\n       for fn in fns.values():\n-        if fn is not None and fn.input_signature is not None:\n-          if isinstance(fn, LayerCall):\n-            fn = fn.wrapped_call\n+        if fn is not None and not isinstance(fn, LayerCall):\n           fn.get_concrete_function()\n \n   # Restore overwritten functions and losses\n@@ -208,7 +206,6 @@ def wrap_layer_functions(layer, serialization_cache):\n def default_save_signature(layer):\n   original_losses = _reset_layer_losses(layer)\n   fn = saving_utils.trace_model_call(layer)\n-  fn.get_concrete_function()\n   _restore_layer_losses(original_losses)\n   return fn\n \n@@ -395,38 +392,31 @@ class LayerCallCollection(object):\n     self._training_arg_index = utils.get_training_arg_index(\n         self.layer_call_method)\n \n-    # If the layer call function has kwargs, then the traced function cannot\n-    # have an input signature.\n-    arg_spec = tf_inspect.getfullargspec(self.layer_call_method)\n-    self._has_kwargs = bool(self._expects_training_arg or\n-                            arg_spec.defaults or\n-                            arg_spec.kwonlyargs or\n-                            arg_spec.varkw)\n-\n-    self._input_signature = self._generate_input_signature(layer)\n+    self._layer_inputs = self._get_layer_inputs(layer)\n     self._functions = weakref.WeakValueDictionary()\n \n     # Get the input argument name from the args.\n+    arg_spec = tf_inspect.getfullargspec(self.layer_call_method)\n     args = arg_spec.args\n     if tf_inspect.ismethod(self.layer_call_method):\n       args = args[1:]\n     self._input_arg_name = args[0] if args else 'inputs'\n \n-  def _generate_input_signature(self, layer):\n+  def _get_layer_inputs(self, layer):\n     \"\"\"Inspects layer object and returns the inferred input signature.\n \n     Args:\n       layer: Layer object.\n \n     Returns:\n-      List of possibly nested TensorSpecs of the layer call function inputs.\n-      The list does not contain the `training` argument.\n+      List of possibly nested TensorSpecs of the layer call function inputs in\n+      the form of `(args, kwargs)`\n     \"\"\"\n     if (isinstance(layer.call, tf.__internal__.function.Function) and\n         layer.call.input_signature is not None):\n-      return layer.call.input_signature\n+      return layer.call.input_signature, {}\n     elif isinstance(layer, training_lib.Model):\n-      return saving_utils.model_input_signature(layer)\n+      return saving_utils.model_call_inputs(layer)\n     elif (layer.input_spec is not None and\n           layer._use_input_spec_as_call_signature):  # pylint: disable=protected-access\n \n@@ -437,14 +427,14 @@ class LayerCallCollection(object):\n         # inferred input signature.\n         # TODO(b/134962016): currently partial signatures are not supported.\n         if spec.shape == tf.TensorShape(None):\n-          return None\n+          return None, None\n         return spec\n       input_signature = [tf.nest.map_structure(\n           to_tensor_spec_or_none, layer.input_spec)]\n \n-      return input_signature\n+      return input_signature, {}\n     else:\n-      return None\n+      return None, None\n \n   def add_trace(self, *args, **kwargs):\n     \"\"\"Traces all functions with the same args and kwargs.\n@@ -469,18 +459,6 @@ class LayerCallCollection(object):\n       else:\n         add_trace_to_queue(fn, args, kwargs)\n \n-  @property\n-  def fn_input_signature(self):\n-    \"\"\"Returns input signature for the wrapped layer call function.\"\"\"\n-    if self._has_kwargs:\n-      # Input signatures may only describe tensor arguments and kwargs are not\n-      # supported.\n-      return None\n-    if None in tf.nest.flatten(self._input_signature):\n-      # TODO(b/134962016): If input signature cannot be partially defined.\n-      return None\n-    return self._input_signature\n-\n   def training_arg_was_passed(self, args, kwargs):\n     if not self.layer._expects_training_arg and self._expects_training_arg:  # pylint: disable=protected-access\n       return (utils.get_training_arg(self._training_arg_index, args, kwargs)\n@@ -554,17 +532,17 @@ class LayerCallCollection(object):\n     fn = LayerCall(\n         self,\n         self._maybe_wrap_with_training_arg(call_fn, match_layer_training_arg),\n-        name,\n-        input_signature=self.fn_input_signature)\n+        name)\n     self._functions[name] = fn.wrapped_call\n     return fn\n \n   def trace_with_input_signature(self):\n     \"\"\"Trace with the layer/models inferred input signature if possible.\"\"\"\n-    if (None not in tf.nest.flatten(self._input_signature) and self._has_kwargs):\n+    if None not in tf.nest.flatten(self._layer_inputs):\n       # Manually add traces for layers that have keyword arguments and have\n       # a fully defined input signature.\n-      self.add_trace(*self._input_signature)\n+      args, kwargs = self._layer_inputs\n+      self.add_trace(*args, **kwargs)\n \n \n def _filtered_inputs(inputs):\n@@ -606,7 +584,7 @@ def layer_call_wrapper(call_collection, method, name):\n class LayerCall(object):\n   \"\"\"Function that triggers traces of other functions in the same collection.\"\"\"\n \n-  def __init__(self, call_collection, call_fn, name, input_signature):\n+  def __init__(self, call_collection, call_fn, name):\n     \"\"\"Initializes a LayerCall object.\n \n     Args:\n@@ -615,13 +593,10 @@ class LayerCall(object):\n         functions should be traced with the same arguments.\n       call_fn: A call function.\n       name: Name of the call function.\n-      input_signature: Input signature of call_fn (can be None).\n     \"\"\"\n     self.call_collection = call_collection\n-    self.input_signature = input_signature\n     self.wrapped_call = tf.function(\n-        layer_call_wrapper(call_collection, call_fn, name),\n-        input_signature=input_signature)\n+        layer_call_wrapper(call_collection, call_fn, name))\n     self.original_layer_call = call_collection.layer_call_method\n \n   def _maybe_trace(self, args, kwargs):\n\n@@ -38,6 +38,9 @@ from keras import keras_parameterized\n from keras import regularizers\n from keras import testing_utils\n from keras.feature_column.dense_features import DenseFeatures\n+from keras.protobuf import saved_metadata_pb2\n+from keras.protobuf import versions_pb2\n+from keras.saving.saved_model import json_utils\n from keras.saving.saved_model import load as keras_load\n from keras.saving.saved_model import save_impl as keras_save\n from keras.utils import control_flow_util\n@@ -879,35 +882,32 @@ class TestSavedModelFormatAllModes(keras_parameterized.TestCase):\n     self.evaluate(tf.compat.v1.variables_initializer(loaded.variables))\n     self.assertAllClose(model.predict(f), loaded.predict(f))\n \n-  def testSaveLayerMultipleInputs(self):\n+  def testSaveMultipleInputs(self):\n     class CustomLayer(keras.layers.Layer):\n \n       def call(self, *input_list):\n         self.add_loss(input_list[-2] * 2, inputs=True)\n         return sum(input_list[:-1])  # The test's last input is a non-tensor arg\n \n-    # TODO(b/175902133): Models only support one input argument. Also, create a\n-    # subclassed model because functional/sequential models still have funky\n-    # behavior when calling with multiple non-nested arguments.\n     class CustomModel(keras.Model):\n \n       def build(self, _):\n         self.layer = CustomLayer()\n \n-      def call(self, inputs):\n-        inputs = inputs[:]\n+      def call(self, *inputs):\n+        inputs = list(inputs)\n         inputs.append(object())  # Test that the layer handles non-tensor inputs\n         return self.layer(*inputs)\n \n     model = CustomModel()\n     inp = [tf.constant(i, shape=[1, 1], dtype=tf.float32)\n            for i in range(1, 5)]\n-    expected = model(inp)\n+    expected = model(*inp)\n     expected_loss = model.get_losses_for(inp)\n     saved_model_dir = self._save_model_dir()\n     model.save(saved_model_dir, save_format='tf')\n     loaded = keras_load.load(saved_model_dir)\n-    actual = loaded(inp)\n+    actual = loaded(*inp)\n     actual_loss = loaded.get_losses_for(inp)\n     self.assertAllEqual(self.evaluate(expected),\n                         self.evaluate(actual))\n@@ -1321,5 +1321,25 @@ class MetricTest(tf.test.TestCase, parameterized.TestCase):\n     self.evaluate([v.initializer for v in loaded.variables])\n     loaded.fit(x, y)\n \n+\n+class TestUpdateMetadata(tf.test.TestCase):\n+\n+  def testAddFullSaveSpec(self):\n+    save_spec = tf.TensorSpec([3, 5], dtype=tf.int32)\n+    node_metadata = json_utils.Encoder().encode({'save_spec': save_spec})\n+\n+    metadata = saved_metadata_pb2.SavedMetadata()\n+    metadata.nodes.add(\n+        version=versions_pb2.VersionDef(\n+            producer=1, min_consumer=1, bad_consumers=[]),\n+        identifier='_tf_keras_model',\n+        metadata=node_metadata)  # pylint: disable=protected-access\n+\n+    new_metadata = keras_load._update_to_current_version(metadata)\n+    node_metadata = json_utils.decode(new_metadata.nodes[0].metadata)\n+    expected_full_spec = ([tf.TensorSpec(shape=(3, 5), dtype=tf.int32)], {})\n+    self.assertAllEqual(expected_full_spec, node_metadata.get('full_save_spec'))\n+\n+\n if __name__ == '__main__':\n   tf.test.main()\n\n@@ -191,7 +191,9 @@ class SerializedAttributes(object):\n       if key in function_dict:\n         if (function_dict[key] is not None and  # Not all functions are required\n             not isinstance(function_dict[key],\n-                           (tf.__internal__.function.Function, save_impl.LayerCall))):\n+                           (tf.__internal__.function.Function,\n+                            tf.types.experimental.ConcreteFunction,\n+                            save_impl.LayerCall))):\n           raise ValueError(\n               'Function dictionary contained a non-function object: {} (for key'\n               ' {})'.format(function_dict[key], key))\n\n@@ -14,9 +14,9 @@\n # ==============================================================================\n \"\"\"Utils related to keras model saving.\"\"\"\n \n+# pylint: disable=g-bad-import-order, g-direct-tensorflow-import\n import tensorflow.compat.v2 as tf\n \n-import collections\n import copy\n import os\n from keras import backend as K\n@@ -28,6 +28,7 @@ from keras.utils import generic_utils\n from keras.utils import version_utils\n from keras.utils.io_utils import ask_to_proceed_with_overwrite\n from tensorflow.python.platform import tf_logging as logging\n+# pylint: enable=g-bad-import-order, g-direct-tensorflow-import\n \n \n def extract_model_metrics(model):\n@@ -50,7 +51,7 @@ def extract_model_metrics(model):\n   return None\n \n \n-def model_input_signature(model, keep_original_batch_size=False):\n+def model_call_inputs(model, keep_original_batch_size=False):\n   \"\"\"Inspect model to get its input signature.\n \n   The model's input signature is a list with a single (possibly-nested) object.\n@@ -68,21 +69,15 @@ def model_input_signature(model, keep_original_batch_size=False):\n       `None`.\n \n   Returns:\n-    A list containing either a single TensorSpec or an object with nested\n-    TensorSpecs. This list does not contain the `training` argument.\n+    A tuple containing `(args, kwargs)` TensorSpecs of the model call function\n+    inputs.\n+    `kwargs` does not contain the `training` argument.\n   \"\"\"\n-  input_specs = model._get_save_spec(dynamic_batch=not keep_original_batch_size)  # pylint: disable=protected-access\n+  input_specs = model.save_spec(dynamic_batch=not keep_original_batch_size)\n   if input_specs is None:\n-    return None\n+    return None, None\n   input_specs = _enforce_names_consistency(input_specs)\n-  # Return a list with a single element as the model's input signature.\n-  if isinstance(input_specs,\n-                collections.abc.Sequence) and len(input_specs) == 1:\n-    # Note that the isinstance check filters out single-element dictionaries,\n-    # which should also be wrapped as a single-element list.\n   return input_specs\n-  else:\n-    return [input_specs]\n \n \n def raise_model_input_error(model):\n@@ -111,22 +106,23 @@ def trace_model_call(model, input_signature=None):\n     if isinstance(model.call, tf.__internal__.function.Function):\n       input_signature = model.call.input_signature\n \n-  if input_signature is None:\n-    input_signature = model_input_signature(model)\n+  if input_signature:\n+    model_args = input_signature\n+    model_kwargs = {}\n+  else:\n+    model_args, model_kwargs = model_call_inputs(model)\n+    input_signature = model_args  # store\n \n-  if input_signature is None:\n+    if model_args is None:\n       raise_model_input_error(model)\n \n-  @tf.function(input_signature=input_signature)\n-  def _wrapped_model(*args):\n+  @tf.function\n+  def _wrapped_model(*args, **kwargs):\n     \"\"\"A concrete tf.function that wraps the model's call function.\"\"\"\n-    # When given a single input, Keras models will call the model on the tensor\n-    # rather than a list consisting of the single tensor.\n-    inputs = args[0] if len(input_signature) == 1 else list(args)\n-\n+    kwargs['training'] = False\n     with base_layer_utils.call_context().enter(\n-        model, inputs=inputs, build_graph=False, training=False, saving=True):\n-      outputs = model(inputs, training=False)\n+        model, inputs=None, build_graph=False, training=False, saving=True):\n+      outputs = model(*args, **kwargs)\n \n     # Outputs always has to be a flat dict.\n     output_names = model.output_names  # Functional Model.\n@@ -136,7 +132,7 @@ def trace_model_call(model, input_signature=None):\n     outputs = tf.nest.flatten(outputs)\n     return {name: output for name, output in zip(output_names, outputs)}\n \n-  return _wrapped_model\n+  return _wrapped_model.get_concrete_function(*model_args, **model_kwargs)\n \n \n def model_metadata(model, include_optimizer=True, require_config=True):\n\n@@ -104,8 +104,10 @@ class TraceModelCallTest(keras_parameterized.TestCase):\n \n     model = testing_utils.get_multi_io_model(branch_a, branch_b)\n \n-    input_a_np = np.random.random((10, input_dim)).astype(np.float32)\n-    input_b_np = np.random.random((10, input_dim)).astype(np.float32)\n+    input_a_ts = tf.constant(\n+        np.random.random((10, input_dim)).astype(np.float32))\n+    input_b_ts = tf.constant(\n+        np.random.random((10, input_dim)).astype(np.float32))\n \n     if testing_utils.get_model_type() == 'subclass':\n       with self.assertRaisesRegex(ValueError, 'input shapes have not been set'):\n@@ -122,8 +124,15 @@ class TraceModelCallTest(keras_parameterized.TestCase):\n               epochs=2)\n \n     fn = saving_utils.trace_model_call(model)\n-    signature_outputs = fn([input_a_np, input_b_np])\n-    outputs = model([input_a_np, input_b_np])\n+    # tf.function requires that the input structures match when calling a\n+    # ConcreteFunction. For some reason V1 models defines the inputs as a list,\n+    # while V2 models sets the inputs as a tuple.\n+    if (not tf.executing_eagerly() and\n+        testing_utils.get_model_type() != 'functional'):\n+      signature_outputs = fn([input_a_ts, input_b_ts])\n+    else:\n+      signature_outputs = fn((input_a_ts, input_b_ts))\n+    outputs = model([input_a_ts, input_b_ts])\n     if model.output_names:\n       expected_outputs = {\n           model.output_names[0]: outputs[0],\n@@ -140,7 +149,7 @@ class TraceModelCallTest(keras_parameterized.TestCase):\n     model_input = {'x': tf.constant([[1.]])}\n     model.predict(model_input, steps=1)\n     fn = saving_utils.trace_model_call(model)\n-    self.assertAllClose({'output_1': [[1.]]}, fn({'x': [[1.]]}))\n+    self.assertAllClose({'output_1': [[1.]]}, fn(model_input))\n \n     columns = [\n         tf.feature_column.numeric_column('x'),\n@@ -151,8 +160,7 @@ class TraceModelCallTest(keras_parameterized.TestCase):\n                    'y': tf.constant([[2.]])}\n     model.predict(model_input, steps=1)\n     fn = saving_utils.trace_model_call(model)\n-    self.assertAllClose({'output_1': [[1., 2.]]},\n-                        fn({'x': [[1.]], 'y': [[2.]]}))\n+    self.assertAllClose({'output_1': [[1., 2.]]}, fn(model_input))\n \n   @combinations.generate(combinations.combine(mode=['graph', 'eager']))\n   def test_specify_input_signature(self):\n@@ -222,7 +230,7 @@ class TraceModelCallTest(keras_parameterized.TestCase):\n     train_step(x, y)\n \n     fn = saving_utils.trace_model_call(model)\n-    self.assertEqual(fn.input_signature[0].shape.as_list(),\n+    self.assertEqual(fn.structured_input_signature[0][0].shape.as_list(),\n                      tf.TensorShape([None, 5]).as_list())\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#99820e70d7d42100437441c975ff726feca53d32", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 5 | Methods Changed: 3 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 13 | Churn Cumulative: 11172 | Contributors (this commit): 22 | Commits (past 90d): 18 | Contributors (cumulative): 26 | DMM Complexity: 0.75\n\nDIFF:\n@@ -2116,6 +2116,7 @@ class AUC(Metric):\n               summation_method, list(metrics_utils.AUCSummationMethod)))\n \n     # Update properties.\n+    self._init_from_thresholds = thresholds is not None\n     if thresholds is not None:\n       # If specified, use the supplied thresholds.\n       self.num_thresholds = len(thresholds) + 2\n@@ -2444,13 +2445,15 @@ class AUC(Metric):\n         'num_thresholds': self.num_thresholds,\n         'curve': self.curve.value,\n         'summation_method': self.summation_method.value,\n-        # We remove the endpoint thresholds as an inverse of how the thresholds\n-        # were initialized. This ensures that a metric initialized from this\n-        # config has the same thresholds.\n-        'thresholds': self.thresholds[1:-1],\n         'multi_label': self.multi_label,\n         'label_weights': label_weights\n     }\n+    # optimization to avoid serializing a large number of generated thresholds\n+    if self._init_from_thresholds:\n+      # We remove the endpoint thresholds as an inverse of how the thresholds\n+      # were initialized. This ensures that a metric initialized from this\n+      # config has the same thresholds.\n+      config['thresholds'] = self.thresholds[1:-1]\n     base_config = super(AUC, self).get_config()\n     return dict(list(base_config.items()) + list(config.items()))\n \n\n@@ -1237,6 +1237,7 @@ class AUCTest(tf.test.TestCase, parameterized.TestCase):\n     self.assertEqual(auc_obj.summation_method,\n                      metrics_utils.AUCSummationMethod.MAJORING)\n     old_config = auc_obj.get_config()\n+    self.assertNotIn('thresholds', old_config)\n     self.assertDictEqual(old_config, json.loads(json.dumps(old_config)))\n \n     # Check save and restore config.\n@@ -1249,6 +1250,7 @@ class AUCTest(tf.test.TestCase, parameterized.TestCase):\n     self.assertEqual(auc_obj2.summation_method,\n                      metrics_utils.AUCSummationMethod.MAJORING)\n     new_config = auc_obj2.get_config()\n+    self.assertNotIn('thresholds', new_config)\n     self.assertDictEqual(old_config, new_config)\n     self.assertAllClose(auc_obj.thresholds, auc_obj2.thresholds)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7c073a1b5a22ff939255fcbef947336659707033", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 23 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 24 | Churn Cumulative: 2782 | Contributors (this commit): 6 | Commits (past 90d): 9 | Contributors (cumulative): 9 | DMM Complexity: 0.9333333333333333\n\nDIFF:\n@@ -1083,6 +1083,27 @@ class CategoricalCrossentropyTest(tf.test.TestCase):\n     loss = cce_obj(y_true, logits, sample_weight=sample_weight)\n     self.assertAlmostEqual(self.evaluate(loss), 0.1934, 3)\n \n+  def test_ragged_tensors_ragged_sample_weights(self):\n+    cce_obj = losses.CategoricalCrossentropy()\n+    y_true = tf.ragged.constant([[[1, 0, 0], [0, 1, 0]], [[0, 0, 1]]])\n+    y_pred = tf.ragged.constant(\n+        [[[.9, .05, .05], [.05, .89, .06]], [[.05, .01, .94]]],\n+        dtype=tf.float32)\n+    # batch losses [[0.1054, 0.1165], [0.0619]]\n+    # Use independent weights for each batch element\n+    sample_weight = tf.ragged.constant([[1.2, 3.4], [5.6]], dtype=tf.float32)\n+    loss = cce_obj(y_true, y_pred, sample_weight=sample_weight)\n+    # sum([0.1054*1.2, 0.1165*3.4, 0.0619*5.6])/3\n+    self.assertAlmostEqual(self.evaluate(loss), 0.2897, 3)\n+\n+    # Test with logits.\n+    logits = tf.ragged.constant([[[8., 1., 1.], [0., 9., 1.]],\n+                                          [[2., 3., 5.]]])\n+    cce_obj = losses.CategoricalCrossentropy(from_logits=True)\n+    # batch losses [[0.0018, 0.0004], [0.1698]]\n+    # sum([0.0018*1.2, 0.0004*3.4, 0.1698*5.6]) / 3\n+    loss = cce_obj(y_true, logits, sample_weight=sample_weight)\n+    self.assertAlmostEqual(self.evaluate(loss), 0.3181, 3)\n \n @combinations.generate(combinations.combine(mode=['graph', 'eager']))\n class SparseCategoricalCrossentropyTest(tf.test.TestCase):\n\n@@ -308,7 +308,8 @@ def compute_weighted_loss(losses,\n       losses = tf.convert_to_tensor(losses)\n     input_dtype = losses.dtype\n \n-    if not isinstance(sample_weight, keras_tensor.KerasTensor):\n+    if not isinstance(sample_weight,\n+                      (keras_tensor.KerasTensor, tf.RaggedTensor)):\n       sample_weight = tf.convert_to_tensor(sample_weight)\n \n     # TODO(psv): Handle casting here in a better way, eg. if losses is float64\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1232f05bce16db15ecac9c35b1b7604c22d208ae", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 18 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 18 | Churn Cumulative: 1614 | Contributors (this commit): 4 | Commits (past 90d): 6 | Contributors (cumulative): 4 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1468,21 +1468,3 @@ tf.__internal__.saved_model.load.register_revived_type(\n         min_consumer_version=1,\n         setter=RestoredOptimizer._set_hyper  # pylint: disable=protected-access\n     )])\n-\n-\n-def create_optimizer_with_warning(unused_proto):\n-  warnings.warn(\"IMPORTANT: Invalid Optimizer identifier detected, please \"\n-                \"sync and re-save the model by June 24, 2021.\")\n-  return RestoredOptimizer()\n-\n-# TODO(kathywu): Delete this registration.\n-tf.__internal__.saved_model.load.register_revived_type(\n-    \"oss_optimizer\",\n-    lambda _: False,  # Prefer the \"optimizer\" identifier.\n-    versions=[tf.__internal__.saved_model.load.VersionedTypeRegistration(\n-        object_factory=create_optimizer_with_warning,\n-        version=1,\n-        min_producer_version=1,\n-        min_consumer_version=1,\n-        setter=RestoredOptimizer._set_hyper  # pylint: disable=protected-access\n-    )])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#28c11877a990783e914764afc1198c17a9143624", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 5 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 17 | Churn Cumulative: 126 | Contributors (this commit): 2 | Commits (past 90d): 6 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -39,11 +39,13 @@ def deserialize_model_from_bytecode(serialized_model):\n   temp_dir = f\"ram://{uuid4()}\"\n   b = BytesIO(serialized_model)\n   with tarfile.open(fileobj=b, mode=\"r\") as archive:\n-    for fname in archive.getnames():\n-      dest_path = os.path.join(temp_dir, fname)\n+    for name in archive.getnames():\n+      dest_path = os.path.join(temp_dir, name)\n+      member = archive.getmember(name)\n       tf.io.gfile.makedirs(os.path.dirname(dest_path))\n+      if member.isfile():\n         with tf.io.gfile.GFile(dest_path, \"wb\") as f:\n-        f.write(archive.extractfile(fname).read())\n+          f.write(archive.extractfile(name).read())\n   model = load_model(temp_dir)\n   tf.io.gfile.rmtree(temp_dir)\n   return model\n@@ -63,9 +65,16 @@ def serialize_model_as_bytecode(model):\n   model.save(temp_dir)\n   b = BytesIO()\n   with tarfile.open(fileobj=b, mode=\"w\") as archive:\n-    for root, _, filenames in tf.io.gfile.walk(temp_dir):\n+    for root, dirs, filenames in tf.io.gfile.walk(temp_dir):\n+      for dirname in dirs:\n+        dest_path = os.path.join(root, dirname)\n+        t = tarfile.TarInfo(dest_path)\n+        t.type = tarfile.DIRTYPE\n+        archive.addfile(t)\n+        print(\"Adding \", dest_path)\n       for filename in filenames:\n         dest_path = os.path.join(root, filename)\n+        print(\"Adding \", dest_path)\n         with tf.io.gfile.GFile(dest_path, \"rb\") as f:\n           info = tarfile.TarInfo(name=os.path.relpath(dest_path, temp_dir))\n           info.size = f.size()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#434d29d277630a6b6ae2c405d4f7ea787db56ee9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 8 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 17 | Churn Cumulative: 9529 | Contributors (this commit): 23 | Commits (past 90d): 16 | Contributors (cumulative): 26 | DMM Complexity: 1.0\n\nDIFF:\n@@ -108,22 +108,28 @@ class ShardedVariableTest(tf.test.TestCase):\n \n   def test_keras_metrics(self):\n     with self.strategy.scope():\n+      fp = keras.metrics.FalsePositives(thresholds=[0.2, 0.5, 0.7, 0.8])\n       auc = keras.metrics.AUC(num_thresholds=10)\n \n     @tf.function\n     def update():\n+      fp.update_state([0., 1., 0., 0.], [0., 0., 0.3, 0.9])\n       auc.update_state([0, 0, 1, 1], [0, 0.5, 0.3, 0.9])\n \n     @tf.function\n     def reset():\n+      fp.reset_state()\n       auc.reset_state()\n \n     update()\n     self.assertEqual(auc.result(), 0.75)\n+    self.assertAllEqual(fp.result(), [2., 1., 1., 1.])\n     reset()\n     self.assertEqual(auc.result(), 0.0)\n+    self.assertAllEqual(fp.result(), [0., 0., 0., 0.])\n \n     self.assertTrue(hasattr(auc.true_positives, 'variables'))\n+    self.assertTrue(hasattr(fp.accumulator, 'variables'))\n \n   def test_saved_model(self):\n \n\n@@ -1038,9 +1038,9 @@ class _ConfusionMatrixConditionCount(Metric):\n     return tf.convert_to_tensor(result)\n \n   def reset_state(self):\n-    num_thresholds = len(to_list(self.thresholds))\n-    backend.batch_set_value(\n-        [(v, np.zeros((num_thresholds,))) for v in self.variables])\n+    backend.batch_set_value([\n+        (v, np.zeros(v.shape.as_list())) for v in self.variables\n+    ])\n \n   def get_config(self):\n     config = {'thresholds': self.init_thresholds}\n@@ -3175,8 +3175,9 @@ class MeanTensor(Metric):\n \n   def reset_state(self):\n     if self._built:\n-      backend.batch_set_value(\n-          [(v, np.zeros(self._shape.as_list())) for v in self.variables])\n+      backend.batch_set_value([\n+          (v, np.zeros(v.shape.as_list())) for v in self.variables\n+      ])\n \n \n @keras_export('keras.metrics.BinaryCrossentropy')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#342b8cb1f25494c8ab4a2691d1dd8949a2329d31", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 36 | Lines Deleted: 37 | Files Changed: 1 | Hunks: 15 | Methods Changed: 5 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 73 | Churn Cumulative: 357 | Contributors (this commit): 3 | Commits (past 90d): 1 | Contributors (cumulative): 3 | DMM Complexity: 0.0\n\nDIFF:\n@@ -14,19 +14,11 @@\n # ==============================================================================\n \"\"\"Tests for automatic outside compilation for TF 2.0/Keras.\"\"\"\n \n-import tensorflow.compat.v2 as tf\n-\n+import collections\n import os\n \n from absl import flags\n-import numpy as np\n-\n-from tensorboard.plugins.histogram import summary_v2 as histogram_summary_v2\n-from tensorboard.plugins.image import summary_v2 as image_summary_v2\n-from tensorboard.plugins.scalar import summary_v2 as scalar_summary_v2\n-from tensorflow.python.eager.context import set_soft_device_placement\n from keras import callbacks\n-from keras import initializers\n from keras.distribute import distribute_strategy_test\n from keras.engine import base_layer\n from keras.engine import sequential as sequential_model_lib\n@@ -34,6 +26,13 @@ from keras.engine import training\n from keras.layers import convolutional as conv_layer_lib\n from keras.layers import core as layer_lib\n from keras.layers import pooling as pool_layer_lib\n+import numpy as np\n+import tensorflow.compat.v2 as tf\n+\n+from tensorboard.plugins.histogram import summary_v2 as histogram_summary_v2\n+from tensorboard.plugins.image import summary_v2 as image_summary_v2\n+from tensorboard.plugins.scalar import summary_v2 as scalar_summary_v2\n+from tensorflow.python.eager.context import set_soft_device_placement\n \n NUM_CLASSES = 4\n \n@@ -155,16 +154,21 @@ class AutoOutsideCompilationWithKerasTest(tf.test.TestCase):\n     set_soft_device_placement(True)\n     self.summary_dir = self.get_temp_dir()\n \n-  def validate_recorded_sumary_file(self, event_files, summary_dict,\n-                                    expected_count):\n+  def validate_recorded_sumary_file(self, event_files, expected_event_counts):\n+    event_counts = collections.defaultdict(int)\n     for event_file in event_files:\n       for e in tf.compat.v1.train.summary_iterator(event_file):\n         for v in e.summary.value:\n-          if v.tag in summary_dict:\n-            summary_dict[v.tag] += 1\n+          event_counts[v.tag] += 1\n \n-    for key in summary_dict:\n-      self.assertEqual(summary_dict[key], expected_count)\n+    event_counts = dict(event_counts)  # Avoid defaultdict type in repr below.\n+    actual_event_counts = {\n+        k: v for k, v in event_counts.items() if k in expected_event_counts\n+    }\n+    self.assertEqual(\n+        expected_event_counts,\n+        actual_event_counts,\n+        msg='expected counts not found; all event counts: %r' % event_counts)\n \n   def testV2SummaryWithKerasSequentialModel(self):\n     strategy = get_tpu_strategy()\n@@ -182,19 +186,17 @@ class AutoOutsideCompilationWithKerasTest(tf.test.TestCase):\n           epochs=1,\n           callbacks=[tensorboard_callback])\n \n-      events_count_dictionary = {\n-          'sequential/layer_for_histogram_summary/custom_histogram_summary_v2':\n-              0,\n-          'sequential/layer_for_image_summary/custom_image_summary_v2':\n-              0,\n-      }\n-\n       event_files = tf.io.gfile.glob(\n           os.path.join(self.summary_dir, 'train', 'event*'))\n       # Since total of 10 steps are ran and summary ops should be invoked\n-      # every 2 batches, we should see total of 5 event logs.\n-      self.validate_recorded_sumary_file(event_files, events_count_dictionary,\n-                                         5)\n+      # every 2 batches, we should see total of 5 event logs for each summary.\n+      expected_event_counts = {\n+          'sequential/layer_for_histogram_summary/custom_histogram_summary_v2':\n+              5,\n+          'sequential/layer_for_image_summary/custom_image_summary_v2':\n+              5,\n+      }\n+      self.validate_recorded_sumary_file(event_files, expected_event_counts)\n \n   def testV2SummaryWithKerasSubclassedModel(self):\n     strategy = get_tpu_strategy()\n@@ -214,19 +216,17 @@ class AutoOutsideCompilationWithKerasTest(tf.test.TestCase):\n \n       event_files = tf.io.gfile.glob(\n           os.path.join(self.summary_dir, 'train', 'event*'))\n-      events_count_dictionary = {\n+      # Since total of 10 steps are ran and summary ops should be invoked\n+      # every 2 batches, we should see total of 5 event logs for each summary.\n+      expected_event_counts = {\n           ('custom_model/layer_for_scalar_summary/'\n            'custom_scalar_summary_v2'):\n-              0,\n+              5,\n           ('custom_model/layer_for_histogram_summary/'\n            'custom_histogram_summary_v2'):\n-              0\n+              5\n       }\n-\n-      # Since total of 10 steps are ran and summary ops should be invoked\n-      # every 2 batches, we should see total of 5 event logs.\n-      self.validate_recorded_sumary_file(event_files, events_count_dictionary,\n-                                         5)\n+      self.validate_recorded_sumary_file(event_files, expected_event_counts)\n \n   def testSummaryWithCustomTrainingLoop(self):\n     strategy = get_tpu_strategy()\n@@ -262,11 +262,10 @@ class AutoOutsideCompilationWithKerasTest(tf.test.TestCase):\n \n     event_files = tf.io.gfile.glob(\n         os.path.join(self.summary_dir, 'event*'))\n-    events_count_dictionary = {\n-        ('logits'): 0,\n+    expected_event_counts = {\n+        'logits': 1,\n     }\n-    self.validate_recorded_sumary_file(event_files, events_count_dictionary,\n-                                       1)\n+    self.validate_recorded_sumary_file(event_files, expected_event_counts)\n \n \n if __name__ == '__main__':\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
