{"custom_id": "keras#c30000041b7f37de4955c12c3a768d24295e26ea", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 309 | Lines Deleted: 10 | Files Changed: 4 | Hunks: 7 | Methods Changed: 48 | Complexity Δ (Sum/Max): 47/23 | Churn Δ: 319 | Churn Cumulative: 1115 | Contributors (this commit): 5 | Commits (past 90d): 14 | Contributors (cumulative): 12 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,142 @@\n+import os\n+import sys\n+from io import StringIO\n+\n+from keras_core.testing import test_case\n+from keras_core.utils.code_stats import count_loc\n+\n+\n+class TestCountLoc(test_case.TestCase):\n+    def setUp(self):\n+        self.test_dir = \"test_directory\"\n+        os.makedirs(self.test_dir, exist_ok=True)\n+\n+    def tearDown(self):\n+        for root, dirs, files in os.walk(self.test_dir, topdown=False):\n+            for name in files:\n+                os.remove(os.path.join(root, name))\n+            for name in dirs:\n+                os.rmdir(os.path.join(root, name))\n+\n+    def create_file(self, filename, content):\n+        with open(\n+            os.path.join(self.test_dir, filename), \"w\", encoding=\"utf-8\"\n+        ) as f:\n+            f.write(content)\n+\n+    def test_count_loc_valid_python(self):\n+        self.create_file(\n+            \"sample.py\", \"# This is a test file\\n\\nprint('Hello')\\n\"\n+        )\n+        loc = count_loc(self.test_dir)\n+        self.assertEqual(loc, 1)\n+\n+    def test_exclude_test_files(self):\n+        self.create_file(\"sample_test.py\", \"print('Hello')\\n\")\n+        loc = count_loc(self.test_dir, exclude=(\"_test\",))\n+        self.assertEqual(loc, 0)\n+\n+    def test_other_extensions(self):\n+        self.create_file(\"sample.txt\", \"Hello\\n\")\n+        loc = count_loc(self.test_dir, extensions=(\".py\",))\n+        self.assertEqual(loc, 0)\n+\n+    def test_comment_lines(self):\n+        self.create_file(\n+            \"sample.py\", \"# Comment\\nprint('Hello')\\n# Another comment\\n\"\n+        )\n+        loc = count_loc(self.test_dir)\n+        self.assertEqual(loc, 1)\n+\n+    def test_empty_file(self):\n+        self.create_file(\"empty.py\", \"\")\n+        loc = count_loc(self.test_dir)\n+        self.assertEqual(loc, 0)\n+\n+    def test_whitespace_only(self):\n+        self.create_file(\"whitespace.py\", \"     \\n\\t\\n\")\n+        loc = count_loc(self.test_dir)\n+        self.assertEqual(loc, 0)\n+\n+    def test_inline_comments_after_code(self):\n+        content = 'print(\"Hello\") # This is an inline comment'\n+        self.create_file(\"inline_comment_sample.py\", content)\n+        loc = count_loc(self.test_dir)\n+        self.assertEqual(loc, 1)  # The comment shouldn't affect the count\n+\n+    def test_directory_structure(self):\n+        content1 = 'print(\"Hello from file1\")'\n+        content2 = 'print(\"Hello from file2\")'\n+        os.mkdir(os.path.join(self.test_dir, \"subdir\"))\n+        self.create_file(\"sample1.py\", content1)\n+        self.create_file(os.path.join(\"subdir\", \"sample2.py\"), content2)\n+        loc = count_loc(self.test_dir)\n+        self.assertEqual(loc, 2)  # Both files should be counted\n+\n+    def test_normal_directory_name(self):\n+        content = 'print(\"Hello from a regular directory\")'\n+        os.makedirs(os.path.join(self.test_dir, \"some_test_dir\"))\n+        self.create_file(os.path.join(\"some_test_dir\", \"sample.py\"), content)\n+        loc = count_loc(self.test_dir)\n+        self.assertEqual(loc, 1)  # Should count normally\n+\n+    def test_exclude_directory_name(self):\n+        content = 'print(\"Hello from an excluded directory\")'\n+        os.makedirs(os.path.join(self.test_dir, \"dir_test\"))\n+        self.create_file(os.path.join(\"dir_test\", \"sample.py\"), content)\n+        loc = count_loc(self.test_dir)\n+        self.assertEqual(loc, 0)\n+        # Shouldn't count the file in dir_test due to the exclusion pattern\n+\n+    def test_verbose_output(self):\n+        content = 'print(\"Hello\")'\n+        self.create_file(\"sample.py\", content)\n+        original_stdout = sys.stdout\n+        sys.stdout = StringIO()\n+        count_loc(self.test_dir, verbose=1)\n+        output = sys.stdout.getvalue()\n+        sys.stdout = original_stdout\n+        self.assertIn(\"Count LoCs in\", output)\n+\n+    def test_multiline_string_same_line(self):\n+        content = '''\"\"\"This is a multiline string ending on the same line\"\"\"\n+        print(\"Outside string\")'''\n+        self.create_file(\"same_line_multiline.py\", content)\n+        loc = count_loc(self.test_dir)\n+        self.assertEqual(loc, 1)  # Only the print statement should count\n+\n+    def test_multiline_string_ends_on_same_line(self):\n+        content = '\"\"\"a multiline string end on same line\"\"\"\\nprint(\"Outstr\")'\n+        self.create_file(\"same_line_multiline.py\", content)\n+        loc = count_loc(self.test_dir)\n+        self.assertEqual(loc, 1)  # Only the print statement should count\n+\n+    def test_multiline_string_ends_in_middle_of_line(self):\n+        content = '''print(\"Start\")\n+        \"\"\"This is a multiline string ending in the middle of a line\"\"\"\n+        \"\"\"This is another multiline string.\"\"\"\n+        print(\"End\")'''\n+        self.create_file(\"multiline_in_middle.py\", content)\n+        loc = count_loc(self.test_dir)\n+        self.assertEqual(loc, 2)  # Both print statements should count\n+\n+    def test_line_starting_with_triple_quotes_not_ending(self):\n+        content = '\"\"\"\\nThis is a multiline string\\n'\n+        self.create_file(\"test_file_2.py\", content)\n+        path = os.path.join(self.test_dir, \"test_file_2.py\")\n+        self.assertEqual(count_loc(path), 0)\n+        # Because it's part of a multiline string\n+\n+    def test_line_starting_and_ending_with_triple_quotes(self):\n+        content = '\"\"\"This is a one-liner docstring.\"\"\"\\n'\n+        self.create_file(\"test_file_3.py\", content)\n+        path = os.path.join(self.test_dir, \"test_file_3.py\")\n+        self.assertEqual(count_loc(path), 0)\n+        # This is still considered a comment/docstring\n+\n+    def test_string_open_true_line_starting_with_triple_quotes(self):\n+        content = '\"\"\"\\nEnd of the multiline string.\"\"\"\\n'\n+        self.create_file(\"test_file_4.py\", content)\n+        path = os.path.join(self.test_dir, \"test_file_4.py\")\n+        self.assertEqual(count_loc(path), 0)\n+        # Entire content is a multiline string/comment\n\n@@ -1,19 +1,20 @@\n from keras_core import backend\n from keras_core import ops\n \n+DTYPE_TO_SIZE = {\n+    **{f\"float{i}\": i for i in (16, 32, 64)},\n+    **{f\"int{i}\": i for i in (8, 16, 32, 64)},\n+    **{f\"uint{i}\": i for i in (8, 16, 32, 64)},\n+    \"bfloat16\": 16,\n+    \"bool\": 1,\n+}\n+\n \n def dtype_size(dtype):\n-    if dtype in (\"bfloat16\", \"float16\"):\n-        return 16\n-    if dtype in (\"float32\", \"int32\"):\n-        return 32\n-    if dtype in (\"float64\", \"int64\"):\n-        return 64\n-    if dtype == \"uint8\":\n-        return 8\n-    if dtype == \"bool\":\n-        return 1\n+    size = DTYPE_TO_SIZE.get(dtype, None)\n+    if size is None:\n         raise ValueError(f\"Invalid dtype: {dtype}\")\n+    return size\n \n \n def is_float(dtype):\n\n@@ -0,0 +1,57 @@\n+from unittest.mock import patch\n+\n+from keras_core.testing import test_case\n+from keras_core.utils import io_utils\n+\n+\n+class TestIoUtils(test_case.TestCase):\n+    def test_enable_interactive_logging(self):\n+        io_utils.enable_interactive_logging()\n+        self.assertTrue(io_utils.is_interactive_logging_enabled())\n+\n+    def test_disable_interactive_logging(self):\n+        io_utils.disable_interactive_logging()\n+        self.assertFalse(io_utils.is_interactive_logging_enabled())\n+\n+    def test_set_logging_verbosity_valid(self):\n+        valid_levels = [\"FATAL\", \"ERROR\", \"WARNING\", \"INFO\", \"DEBUG\"]\n+        for level in valid_levels:\n+            io_utils.set_logging_verbosity(level)\n+\n+    def test_set_logging_verbosity_invalid(self):\n+        with self.assertRaises(ValueError):\n+            io_utils.set_logging_verbosity(\"INVALID\")\n+\n+    @patch(\"builtins.input\", side_effect=[\"y\"])\n+    def test_ask_to_proceed_with_overwrite_yes(self, _):\n+        self.assertTrue(io_utils.ask_to_proceed_with_overwrite(\"test_path\"))\n+\n+    @patch(\"builtins.input\", side_effect=[\"n\"])\n+    def test_ask_to_proceed_with_overwrite_no(self, _):\n+        self.assertFalse(io_utils.ask_to_proceed_with_overwrite(\"test_path\"))\n+\n+    @patch(\"sys.stdout.write\")\n+    def test_print_msg_interactive_with_line_break(self, mock_write):\n+        io_utils.enable_interactive_logging()\n+        io_utils.print_msg(\"Hello\", line_break=True)\n+        mock_write.assert_called_once_with(\"Hello\\n\")\n+\n+    @patch(\"sys.stdout.write\")\n+    def test_print_msg_interactive_without_line_break(self, mock_write):\n+        io_utils.enable_interactive_logging()\n+        io_utils.print_msg(\"Hello\", line_break=False)\n+        mock_write.assert_called_once_with(\"Hello\")\n+\n+    @patch(\"absl.logging.info\")\n+    def test_print_msg_non_interactive(self, mock_logging):\n+        io_utils.disable_interactive_logging()\n+        io_utils.print_msg(\"Hello\")\n+        mock_logging.assert_called_once_with(\"Hello\")\n+\n+    @patch(\"builtins.input\", side_effect=[\"invalid\", \"invalid\", \"y\"])\n+    def test_ask_to_proceed_with_overwrite_invalid_then_yes(self, _):\n+        self.assertTrue(io_utils.ask_to_proceed_with_overwrite(\"test_path\"))\n+\n+    @patch(\"builtins.input\", side_effect=[\"invalid\", \"n\"])\n+    def test_ask_to_proceed_with_overwrite_invalid_then_no(self, _):\n+        self.assertFalse(io_utils.ask_to_proceed_with_overwrite(\"test_path\"))\n\n@@ -3,6 +3,11 @@ from keras_core.utils import naming\n \n \n class NamingUtilsTest(test_case.TestCase):\n+    def test_uniquify_unique_name(self):\n+        name = \"the_unique_name\"\n+        unique_name = naming.uniquify(name)\n+        self.assertEqual(unique_name, name)\n+\n     def test_auto_name(self):\n         self.assertEqual(naming.auto_name(\"unique_name\"), \"unique_name\")\n         self.assertEqual(naming.auto_name(\"unique_name\"), \"unique_name_1\")\n@@ -12,3 +17,97 @@ class NamingUtilsTest(test_case.TestCase):\n         self.assertEqual(naming.get_uid(\"very_unique_name\"), 1)\n         self.assertEqual(naming.get_uid(\"very_unique_name\"), 2)\n         self.assertEqual(naming.get_uid(\"very_unique_name\"), 3)\n+\n+    def test_uniquify_non_unique_name(self):\n+        name = \"non_unique_name\"\n+        naming.uniquify(name)\n+        unique_name = naming.uniquify(name)\n+        self.assertEqual(unique_name, name + \"_1\")\n+\n+    def test_to_snake_case_snake_case_name(self):\n+        name = \"snake_case_name\"\n+        snake_case_name = naming.to_snake_case(name)\n+        self.assertEqual(snake_case_name, name)\n+\n+    def test_get_uid_existing_prefix(self):\n+        prefix = \"existing_prefix\"\n+        naming.get_uid(prefix)\n+        uid = naming.get_uid(prefix)\n+        self.assertEqual(uid, 2)\n+\n+    def test_reset_uids(self):\n+        naming.get_uid(\"unique_name\")\n+        naming.reset_uids()\n+        uid = naming.get_uid(\"unique_name\")\n+        self.assertEqual(uid, 1)\n+\n+    def test_get_object_name_no_name_attribute(self):\n+        class ObjectWithoutName:\n+            __name__ = \"ObjectWithoutName\"\n+\n+        obj = ObjectWithoutName()\n+        object_name = naming.get_object_name(obj)\n+        self.assertEqual(object_name, \"object_without_name\")\n+\n+    def test_get_object_name_no_name_or_class_attribute(self):\n+        class ObjectWithoutNameOrClass:\n+            pass\n+\n+        obj = ObjectWithoutNameOrClass()\n+        object_name = naming.get_object_name(obj)\n+        self.assertEqual(object_name, \"object_without_name_or_class\")\n+\n+    def test_uniquify_already_uniquified_name(self):\n+        name = \"unique_name\"\n+        unique_name = naming.uniquify(name)\n+        new_unique_name = naming.uniquify(unique_name)\n+        self.assertEqual(new_unique_name, unique_name)\n+\n+    def test_to_snake_case_capital_after_any_character(self):\n+        name = \"myVariableNameHere\"\n+        snake_case_name = naming.to_snake_case(name)\n+        self.assertEqual(snake_case_name, \"my_variable_name_here\")\n+\n+    def test_to_snake_case_lower_before_upper(self):\n+        name = \"convertTHIS\"\n+        snake_case_name = naming.to_snake_case(name)\n+        self.assertEqual(snake_case_name, \"convert_this\")\n+\n+    def test_to_snake_case_already_snake_cased(self):\n+        name = \"already_snake_cased\"\n+        snake_case_name = naming.to_snake_case(name)\n+        self.assertEqual(snake_case_name, name)\n+\n+    def test_to_snake_case_no_changes(self):\n+        name = \"lowercase\"\n+        snake_case_name = naming.to_snake_case(name)\n+        self.assertEqual(snake_case_name, name)\n+\n+    def test_to_snake_case_single_uppercase_word(self):\n+        name = \"UPPERCASE\"\n+        snake_case_name = naming.to_snake_case(name)\n+        self.assertEqual(snake_case_name, \"uppercase\")\n+\n+    def test_get_object_name_for_keras_objects(self):\n+        class MockKerasObject:\n+            name = \"mock_object\"\n+\n+        obj = MockKerasObject()\n+        result = naming.get_object_name(obj)\n+        self.assertEqual(\n+            result, \"mock_object\", f\"Expected 'mock_object' but got {result}\"\n+        )\n+\n+    # Test for function objects that have a `__name__` attribute.\n+    def test_get_object_name_for_functions(self):\n+        def mock_function():\n+            pass\n+\n+        result = naming.get_object_name(mock_function)\n+        # Assumes to_snake_case works correctly.\n+        expected_name = naming.to_snake_case(mock_function.__name__)\n+        self.assertEqual(\n+            result,\n+            expected_name,\n+            f\"Expected '{expected_name}' but got {result}\",\n+        )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1e6d1eb9a8148268f56879bfb15567435c8d6352", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 23 | Lines Deleted: 10 | Files Changed: 2 | Hunks: 9 | Methods Changed: 3 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 33 | Churn Cumulative: 737 | Contributors (this commit): 5 | Commits (past 90d): 8 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -256,7 +256,7 @@ class StochasticDepth(layers.Layer):\n         if training:\n             keep_prob = 1 - self.drop_prob\n             shape = (keras.ops.shape(x)[0],) + (1,) * (len(x.shape) - 1)\n-            random_tensor = keep_prob + keras.random.random.uniform(shape, 0, 1)\n+            random_tensor = keep_prob + keras.random.uniform(shape, 0, 1)\n             random_tensor = keras.ops.floor(random_tensor)\n             return (x / keep_prob) * random_tensor\n         return x\n\n@@ -1,6 +1,6 @@\n import numpy as np\n \n-from keras_core import backend, ops\n+from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n from keras_core.utils import argument_validation\n@@ -17,9 +17,13 @@ class Discretization(Layer):\n     contiguous ranges and output an integer index indicating which range each\n     element was placed in.\n \n-    This layer can also always be used as part of an input preprocessing\n-    pipeline with any backend (outside the model itself), which is how we\n-    recommend to use this layer.\n+    **Note:** This layer uses TensorFlow internally. It cannot\n+    be used as part of the compiled computation graph of a model with\n+    any backend other than TensorFlow.\n+    It can however be used with any backend when running eagerly.\n+    It can also always be used as part of an input preprocessing pipeline\n+    with any backend (outside the model itself), which is how we recommend\n+    to use this layer.\n \n     **Note:** This layer is safe to use inside a `tf.data` pipeline\n     (independently of which backend you're using).\n@@ -74,14 +78,14 @@ class Discretization(Layer):\n \n     Examples:\n \n-    Digitize float values based on provided buckets.\n+    Bucketize float values based on provided buckets.\n     >>> input = np.array([[-1.5, 1.0, 3.4, .5], [0.0, 3.0, 1.3, 0.0]])\n     >>> layer = Discretization(bin_boundaries=[0., 1., 2.])\n     >>> layer(input)\n     array([[0, 2, 3, 1],\n            [1, 3, 2, 1]])\n \n-    Digitize float values based on a number of buckets to compute.\n+    Bucketize float values based on a number of buckets to compute.\n     >>> input = np.array([[-1.5, 1.0, 3.4, .5], [0.0, 3.0, 1.3, 0.0]])\n     >>> layer = Discretization(num_bins=4, epsilon=0.01)\n     >>> layer.adapt(input)\n@@ -237,15 +241,20 @@ class Discretization(Layer):\n         if not isinstance(\n             inputs,\n             (\n+                tf.Tensor,\n+                tf.SparseTensor,\n+                tf.RaggedTensor,\n                 np.ndarray,\n                 backend.KerasTensor,\n             ),\n         ):\n-            inputs = backend.convert_to_tensor(\n-                inputs, dtype=self.input_dtype\n+            inputs = tf.convert_to_tensor(\n+                backend.convert_to_numpy(inputs), dtype=self.input_dtype\n             )\n \n-        indices = ops.digitize(inputs, self.bin_boundaries)\n+        from keras_core.backend.tensorflow.numpy import digitize\n+\n+        indices = digitize(inputs, self.bin_boundaries)\n \n         outputs = tf_utils.encode_categorical_inputs(\n             indices,\n@@ -361,3 +370,7 @@ def compress_summary(summary, epsilon):\n     )\n     summary = np.stack((new_bins, new_weights))\n     return summary.astype(\"float32\")\n+\n+\n+def bucketize(inputs, boundaries):\n+    return tf.raw_ops.Bucketize(input=inputs, boundaries=boundaries)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f09974ab5febef89db4b8a195f544fbaa3c66da3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 142 | Lines Deleted: 59 | Files Changed: 10 | Hunks: 26 | Methods Changed: 15 | Complexity Δ (Sum/Max): 6/4 | Churn Δ: 201 | Churn Cumulative: 3967 | Contributors (this commit): 13 | Commits (past 90d): 72 | Contributors (cumulative): 51 | DMM Complexity: 1.0\n\nDIFF:\n@@ -298,3 +298,7 @@ def istft(\n     else:\n         end = expected_output_len\n     return x[..., start:end]\n+\n+\n+def rsqrt(x):\n+    return 1.0 / np.sqrt(x)\n\n@@ -201,21 +201,21 @@ class BatchNormalization(Layer):\n             mean, variance = ops.moments(\n                 inputs, axes=self._reduction_axes, keepdims=True\n             )\n-            outputs = (inputs - mean) / ops.sqrt(variance + self.epsilon)\n-            mean = ops.squeeze(mean, self._reduction_axes)\n-            variance = ops.squeeze(variance, self._reduction_axes)\n             moving_mean = ops.cast(self.moving_mean, inputs.dtype)\n             moving_variance = ops.cast(self.moving_variance, inputs.dtype)\n             self.moving_mean.assign(\n                 ops.cast(\n-                    moving_mean * self.momentum + mean * (1.0 - self.momentum),\n+                    moving_mean * self.momentum\n+                    + ops.squeeze(mean, self._reduction_axes)\n+                    * (1.0 - self.momentum),\n                     inputs.dtype,\n                 )\n             )\n             self.moving_variance.assign(\n                 ops.cast(\n                     moving_variance * self.momentum\n-                    + variance * (1.0 - self.momentum),\n+                    + ops.squeeze(variance, self._reduction_axes)\n+                    * (1.0 - self.momentum),\n                     inputs.dtype,\n                 )\n             )\n@@ -224,17 +224,24 @@ class BatchNormalization(Layer):\n             moving_variance = ops.cast(self.moving_variance, inputs.dtype)\n             moving_mean = ops.reshape(moving_mean, broadcast_shape)\n             moving_variance = ops.reshape(moving_variance, broadcast_shape)\n-            outputs = (inputs - moving_mean) / ops.sqrt(\n-                moving_variance + self.epsilon\n-            )\n+            mean = moving_mean\n+            variance = moving_variance\n+\n+        inv = ops.rsqrt(variance + self.epsilon)\n         if self.scale:\n             gamma = ops.reshape(self.gamma, broadcast_shape)\n-            gamma = ops.cast(gamma, outputs.dtype)\n-            outputs = outputs * gamma\n+            gamma = ops.cast(gamma, inputs.dtype)\n+            inv = inv * gamma\n+\n+        res = -mean * inv\n         if self.center:\n             beta = ops.reshape(self.beta, broadcast_shape)\n-            beta = ops.cast(beta, outputs.dtype)\n-            outputs = outputs + beta\n+            beta = ops.cast(beta, inputs.dtype)\n+            res = res + beta\n+\n+        # Note: Folding BatchNormalization depends on the precise order of ops\n+        # that are generated by the expression below\n+        outputs = inputs * inv + res\n         return ops.cast(outputs, input_dtype)\n \n     def get_config(self):\n\n@@ -171,37 +171,26 @@ class GroupNormalization(Layer):\n         axis = -2 if self.axis == -1 else self.axis - 1\n         group_reduction_axes.pop(axis)\n \n+        broadcast_shape = self._create_broadcast_shape(input_shape)\n         mean, variance = ops.moments(\n             reshaped_inputs, axes=group_reduction_axes, keepdims=True\n         )\n-        gamma, beta = self._get_reshaped_weights(input_shape)\n \n         # Compute the batch normalization.\n-        inv = 1 / ops.sqrt(variance + self.epsilon)\n-\n-        if gamma is not None:\n-            inv = ops.multiply(inv, gamma)\n-\n-        if beta is not None:\n-            x = beta - ops.multiply(mean, inv)\n-        else:\n-            x = -ops.multiply(mean, inv)\n-\n-        normalized_inputs = reshaped_inputs * ops.cast(\n-            inv, reshaped_inputs.dtype\n-        ) + ops.cast(x, reshaped_inputs.dtype)\n-        normalized_inputs = ops.cast(normalized_inputs, reshaped_inputs.dtype)\n-        return normalized_inputs\n-\n-    def _get_reshaped_weights(self, input_shape):\n-        broadcast_shape = self._create_broadcast_shape(input_shape)\n-        gamma = None\n-        beta = None\n+        inv = ops.rsqrt(variance + self.epsilon)\n         if self.scale:\n             gamma = ops.reshape(self.gamma, broadcast_shape)\n+            gamma = ops.cast(gamma, reshaped_inputs.dtype)\n+            inv = inv * gamma\n+\n+        res = -mean * inv\n         if self.center:\n             beta = ops.reshape(self.beta, broadcast_shape)\n-        return gamma, beta\n+            beta = ops.cast(beta, reshaped_inputs.dtype)\n+            res = res + beta\n+\n+        normalized_inputs = reshaped_inputs * inv + res\n+        return normalized_inputs\n \n     def _create_broadcast_shape(self, input_shape):\n         broadcast_shape = [1] * len(input_shape)\n\n@@ -41,6 +41,51 @@ class GroupNormalizationTest(testing.TestCase):\n             supports_masking=True,\n         )\n \n+    def test_undefined_dim_error(self):\n+        inputs = layers.Input(shape=(2, 2, 2, None))\n+        layer = layers.GroupNormalization()\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            (\n+                \"input tensor should have a defined dimension but the layer \"\n+                \"received an input with shape\"\n+            ),\n+        ):\n+            _ = layer(inputs)\n+\n+    def test_groups_bigger_than_dim_error(self):\n+        inputs = np.ones(shape=(2, 2, 2, 4))\n+        layer = layers.GroupNormalization(groups=5)\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"cannot be more than the number of channels\",\n+        ):\n+            _ = layer(inputs)\n+\n+    def test_groups_not_a_multiple_of_dim_error(self):\n+        inputs = np.ones(shape=(2, 2, 2, 4))\n+        layer = layers.GroupNormalization(groups=3)\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"must be a multiple of the number of channels\",\n+        ):\n+            _ = layer(inputs)\n+\n+    def test_groups_instance_norm(self):\n+        # GroupNormalization with groups=-1 will become InstanceNormalization\n+        instance_norm_layer_1 = layers.GroupNormalization(\n+            groups=-1, axis=-1, scale=False, center=False\n+        )\n+        instance_norm_layer_2 = layers.GroupNormalization(\n+            groups=4, axis=-1, scale=False, center=False\n+        )\n+        inputs = np.array([[[-1.0, 1.0, 0, 2.0], [1.0, 3.0, -4, -2.0]]])\n+\n+        outputs_1 = instance_norm_layer_1(inputs)\n+        outputs_2 = instance_norm_layer_2(inputs)\n+\n+        self.assertAllClose(outputs_1, outputs_2)\n+\n     def test_correctness_instance_norm(self):\n         instance_norm_layer = layers.GroupNormalization(\n             groups=4, axis=-1, scale=False, center=False\n\n@@ -206,33 +206,29 @@ class LayerNormalization(Layer):\n         if self.rms_scaling:\n             # Calculate outputs with only variance and gamma if rms scaling\n             # is enabled\n-            # Calculate the variance along last axis (layer activations).\n+            # Calculate the variance along self.axis (layer activations).\n             variance = ops.var(inputs, axis=self.axis, keepdims=True)\n-            inv = 1 / ops.sqrt(variance + self.epsilon)\n-            outputs = inputs * ops.cast(inv, inputs.dtype) * self.gamma\n+            inv = ops.rsqrt(variance + self.epsilon)\n+\n+            outputs = inputs * inv * ops.cast(self.gamma, inputs.dtype)\n         else:\n-            # Calculate the mean & variance along last axis (layer activations).\n+            # Calculate the mean & variance along self.axis (layer activations).\n             mean, variance = ops.moments(inputs, axes=self.axis, keepdims=True)\n-            inv = 1 / ops.sqrt(variance + self.epsilon)\n-            scale, offset = _broadcast(self.gamma), _broadcast(self.beta)\n-            if scale is not None:\n-                scale = ops.cast(scale, inputs.dtype)\n-                inv = inv * scale\n-            x = -mean * inv\n-            if offset is not None:\n-                offset = ops.cast(offset, inputs.dtype)\n-                x = offset + x\n+            gamma, beta = _broadcast(self.gamma), _broadcast(self.beta)\n \n-            outputs = inputs * ops.cast(inv, inputs.dtype) + ops.cast(\n-                x, inputs.dtype\n-            )\n+            inv = ops.rsqrt(variance + self.epsilon)\n+            if gamma is not None:\n+                gamma = ops.cast(gamma, inputs.dtype)\n+                inv = inv * gamma\n \n-        outputs = ops.cast(outputs, input_dtype)\n+            res = -mean * inv\n+            if beta is not None:\n+                beta = ops.cast(beta, inputs.dtype)\n+                res = res + beta\n \n-        # If some components of the shape got lost due to adjustments, fix that.\n-        outputs = ops.reshape(outputs, ops.shape(inputs))\n+            outputs = inputs * inv + res\n \n-        return outputs\n+        return ops.cast(outputs, input_dtype)\n \n     def compute_output_shape(self, input_shape):\n         return input_shape\n\n@@ -83,6 +83,16 @@ class LayerNormalizationTest(testing.TestCase):\n             supports_masking=True,\n         )\n \n+    def test_invalid_axis(self):\n+        with self.assertRaisesRegex(\n+            TypeError,\n+            (\n+                \"Expected an int or a list/tuple of ints for the argument \"\n+                \"'axis'\"\n+            ),\n+        ):\n+            layers.LayerNormalization(axis={\"axis\": -1})\n+\n     def test_correctness(self):\n         layer = layers.LayerNormalization(dtype=\"float32\")\n         layer.build(input_shape=(2, 2, 2))\n\n@@ -20,6 +20,32 @@ class SpectralNormalizationTest(testing.TestCase):\n             expected_num_losses=0,\n             supports_masking=False,\n         )\n+        self.run_layer_test(\n+            layers.SpectralNormalization,\n+            init_kwargs={\"layer\": layers.Embedding(10, 4)},\n+            input_data=np.random.randint(10, size=(10,)),\n+            expected_output_shape=(10, 4),\n+            expected_num_trainable_weights=1,\n+            expected_num_non_trainable_weights=1,\n+            expected_num_seed_generators=0,\n+            expected_num_losses=0,\n+            supports_masking=False,\n+            run_training_check=False,\n+        )\n+\n+    def test_invalid_power_iterations(self):\n+        with self.assertRaisesRegex(\n+            ValueError, \"`power_iterations` should be greater than zero.\"\n+        ):\n+            layers.SpectralNormalization(layers.Dense(2), power_iterations=0)\n+\n+    def test_invalid_layer(self):\n+        layer = layers.SpectralNormalization(layers.ReLU())\n+        inputs = np.ones(shape=(4, 2))\n+        with self.assertRaisesRegex(\n+            ValueError, \"object has no attribute 'kernel' nor 'embeddings'\"\n+        ):\n+            layer(inputs)\n \n     def test_apply_layer(self):\n         images = np.ones((1, 2, 2, 1))\n\n@@ -45,7 +45,7 @@ class UnitNormalization(Layer):\n         x = ops.cast(inputs, self.compute_dtype)\n \n         square_sum = ops.sum(ops.square(x), axis=self.axis, keepdims=True)\n-        x_inv_norm = 1 / ops.sqrt(ops.maximum(square_sum, 1e-12))\n+        x_inv_norm = ops.rsqrt(ops.maximum(square_sum, 1e-12))\n         return ops.multiply(x, x_inv_norm)\n \n     def compute_output_shape(self, input_shape):\n\n@@ -29,6 +29,16 @@ class UnitNormalizationTest(testing.TestCase):\n             supports_masking=True,\n         )\n \n+    def test_invalid_axis(self):\n+        with self.assertRaisesRegex(\n+            TypeError,\n+            (\n+                \"Invalid value for `axis` argument: expected an int or a \"\n+                \"list/tuple of ints.\"\n+            ),\n+        ):\n+            layers.UnitNormalization(axis={\"axis\": -1})\n+\n     def test_correctness(self):\n         layer = layers.UnitNormalization(axis=-1)\n         inputs = np.random.normal(size=(2, 3))\n\n@@ -831,10 +831,6 @@ class MathOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             ref = ref[..., truncated_len:-truncated_len]\n         self.assertAllClose(output, ref, atol=1e-5, rtol=1e-5)\n \n-    @pytest.mark.skipif(\n-        backend.backend() == \"numpy\",\n-        reason=\"Numpy does not support rsqrt.\",\n-    )\n     def test_rsqrt(self):\n         x = np.array([[1, 4, 9], [16, 25, 36]], dtype=\"float32\")\n         self.assertAllClose(kmath.rsqrt(x), 1 / np.sqrt(x))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#723bb1dc97cfb6e37c9f31ef4fe78cc90baccfee", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 92 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -22,7 +22,7 @@ class TorchDataLoaderAdapter(DataAdapter):\n \n     def get_numpy_iterator(self):\n         for batch in self._dataloader:\n-            yield tuple(tree.map_structure(lambda x: x.numpy(), batch))\n+            yield tuple(tree.map_structure(lambda x: x.cpu().numpy(), batch))\n \n     def get_torch_dataloader(self):\n         return self._dataloader\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#11c0ea2a696de5f57860f5f9dc9793ed16b39a3a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 23 | Lines Deleted: 10 | Files Changed: 3 | Hunks: 8 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 33 | Churn Cumulative: 1416 | Contributors (this commit): 3 | Commits (past 90d): 16 | Contributors (cumulative): 6 | DMM Complexity: 0.0\n\nDIFF:\n@@ -491,6 +491,7 @@ def _get_save_spec(model):\n     return specs\n \n \n+@keras_core_export(\"keras_core.layers.TFSMLayer\")\n class TFSMLayer(Layer):\n     \"\"\"Reload a Keras model/layer that was saved via SavedModel / ExportArchive.\n \n@@ -557,9 +558,13 @@ class TFSMLayer(Layer):\n             self.call_endpoint_fn = self._reloaded_obj.signatures[call_endpoint]\n         else:\n             raise ValueError(\n-                f\"The endpoint '{call_endpoint}' is neither an \"\n-                \"attribute of the reloaded SavedModel, nor an entry \"\n-                \"in the `signatures` field of the reloaded SavedModel. \"\n+                f\"The endpoint '{call_endpoint}' \"\n+                \"is neither an attribute of the reloaded SavedModel, \"\n+                \"nor an entry in the `signatures` field of \"\n+                \"the reloaded SavedModel. Select another endpoint via \"\n+                \"the `call_endpoint` argument. Available endpoints for \"\n+                \"this SavedModel: \"\n+                f\"{list(self._reloaded_obj.signatures.keys())}\"\n             )\n \n         # Resolving the training function.\n@@ -574,10 +579,12 @@ class TFSMLayer(Layer):\n                 ]\n             else:\n                 raise ValueError(\n-                    f\"The endpoint '{call_training_endpoint}' is \"\n-                    \"neither an attribute of the reloaded SavedModel, \"\n+                    f\"The endpoint '{call_training_endpoint}' \"\n+                    \"is neither an attribute of the reloaded SavedModel, \"\n                     \"nor an entry in the `signatures` field of \"\n-                    \"the reloaded SavedModel. \"\n+                    \"the reloaded SavedModel. Available endpoints for \"\n+                    \"this SavedModel: \"\n+                    f\"{list(self._reloaded_obj.signatures.keys())}\"\n                 )\n \n         # Add trainable and non-trainable weights from the call_endpoint_fn.\n\n@@ -194,7 +194,13 @@ def load_model(filepath, custom_objects=None, compile=True, safe_mode=True):\n             \"Keras Core only supports V3 `.keras` files and \"\n             \"legacy H5 format files (`.h5` extension). \"\n             \"Note that the legacy SavedModel format is not \"\n-            \"supported in Keras Core.\"\n+            \"supported by `load_model()` in Keras Core. In \"\n+            \"order to reload a TensorFlow SavedModel as an \"\n+            \"inference-only layer in Keras Core, use \"\n+            \"`keras_core.layers.TFSMLayer(\"\n+            f\"{filepath}, call_endpoint='serving_default')` \"\n+            \"(note that your `call_endpoint` \"\n+            \"might have a different name).\"\n         )\n \n \n@@ -232,5 +238,5 @@ def load_weights(model, filepath, skip_mismatch=False, **kwargs):\n         raise ValueError(\n             f\"File format not supported: filepath={filepath}. \"\n             \"Keras Core only supports V3 `.keras` and `.weights.h5` \"\n-            \"files.\"\n+            \"files, or legacy V1/V2 `.h5` files.\"\n         )\n\n@@ -2,7 +2,7 @@ from keras_core.api_export import keras_core_export\n from keras_core.layers import Layer\n \n \n-@keras_core_export(\"keras_core.utils.TorchModuleWrapper\")\n+@keras_core_export(\"keras_core.layers.TorchModuleWrapper\")\n class TorchModuleWrapper(Layer):\n     \"\"\"Torch module wrapper layer.\n \n@@ -27,7 +27,7 @@ class TorchModuleWrapper(Layer):\n     import torch.nn.functional as F\n \n     import keras_core\n-    from keras_core.backend.torch import TorchModuleWrapper\n+    from keras_core.layers import TorchModuleWrapper\n \n     class Classifier(keras_core.Model):\n         def __init__(self, *args, **kwargs):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8b3c2d5fac0d8458ac03d0234908dde076d11362", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 625 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 16 | Complexity Δ (Sum/Max): 34/34 | Churn Δ: 625 | Churn Cumulative: 625 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,625 @@\n+\"\"\"\n+Title: Distilling Vision Transformers\n+Author: [Sayak Paul](https://twitter.com/RisingSayak)\n+Date created: 2022/04/05\n+Last modified: 2023/09/16\n+Description: Distillation of Vision Transformers through attention.\n+Accelerator: GPU\n+\"\"\"\n+\"\"\"\n+## Introduction\n+\n+In the original *Vision Transformers* (ViT) paper\n+([Dosovitskiy et al.](https://arxiv.org/abs/2010.11929)),\n+the authors concluded that to perform on par with Convolutional Neural Networks (CNNs),\n+ViTs need to be pre-trained on larger datasets. The larger the better. This is mainly\n+due to the lack of inductive biases in the ViT architecture -- unlike CNNs,\n+they don't have layers that exploit locality. In a follow-up paper\n+([Steiner et al.](https://arxiv.org/abs/2106.10270)),\n+the authors show that it is possible to substantially improve the performance of ViTs\n+with stronger regularization and longer training.\n+\n+Many groups have proposed different ways to deal with the problem\n+of data-intensiveness of ViT training.\n+One such way was shown in the *Data-efficient image Transformers*,\n+(DeiT) paper ([Touvron et al.](https://arxiv.org/abs/2012.12877)). The\n+authors introduced a distillation technique that is specific to transformer-based vision\n+models. DeiT is among the first works to show that it's possible to train ViTs well\n+without using larger datasets.\n+\n+In this example, we implement the distillation recipe proposed in DeiT. This\n+requires us to slightly tweak the original ViT architecture and write a custom training\n+loop to implement the distillation recipe.\n+\n+To comfortably navigate through this example, you'll be expected to know how a ViT and\n+knowledge distillation work. The following are good resources in case you needed a\n+refresher:\n+\n+* [ViT on keras.io](https://keras.io/examples/vision/image_classification_with_vision_transformer)\n+* [Knowledge distillation on keras.io](https://keras.io/examples/vision/knowledge_distillation/)\n+\"\"\"\n+\n+\"\"\"\n+## Imports\n+\"\"\"\n+\n+import os\n+\n+os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n+\n+import tensorflow as tf\n+import tensorflow_datasets as tfds\n+import keras_core as keras\n+from keras_core import layers\n+\n+tfds.disable_progress_bar()\n+keras.utils.set_random_seed(42)\n+\n+\"\"\"\n+## Constants\n+\"\"\"\n+\n+# Model\n+MODEL_TYPE = \"deit_distilled_tiny_patch16_224\"\n+RESOLUTION = 224\n+PATCH_SIZE = 16\n+NUM_PATCHES = (RESOLUTION // PATCH_SIZE) ** 2\n+LAYER_NORM_EPS = 1e-6\n+PROJECTION_DIM = 192\n+NUM_HEADS = 3\n+NUM_LAYERS = 12\n+MLP_UNITS = [\n+    PROJECTION_DIM * 4,\n+    PROJECTION_DIM,\n+]\n+DROPOUT_RATE = 0.0\n+DROP_PATH_RATE = 0.1\n+\n+# Training\n+NUM_EPOCHS = 20\n+BASE_LR = 0.0005\n+WEIGHT_DECAY = 0.0001\n+\n+# Data\n+BATCH_SIZE = 256\n+AUTO = tf.data.AUTOTUNE\n+NUM_CLASSES = 5\n+\n+\"\"\"\n+You probably noticed that `DROPOUT_RATE` has been set 0.0. Dropout has been used\n+in the implementation to keep it complete. For smaller models (like the one used in\n+this example), you don't need it, but for bigger models, using dropout helps.\n+\"\"\"\n+\n+\"\"\"\n+## Load the `tf_flowers` dataset and prepare preprocessing utilities\n+\n+The authors use an array of different augmentation techniques, including MixUp\n+([Zhang et al.](https://arxiv.org/abs/1710.09412)),\n+RandAugment ([Cubuk et al.](https://arxiv.org/abs/1909.13719)),\n+and so on. However, to keep the example simple to work through, we'll discard them.\n+\"\"\"\n+\n+\n+def preprocess_dataset(is_training=True):\n+    def fn(image, label):\n+        if is_training:\n+            # Resize to a bigger spatial resolution and take the random\n+            # crops.\n+            image = tf.image.resize(image, (RESOLUTION + 20, RESOLUTION + 20))\n+            image = tf.image.random_crop(image, (RESOLUTION, RESOLUTION, 3))\n+            image = tf.image.random_flip_left_right(image)\n+        else:\n+            image = tf.image.resize(image, (RESOLUTION, RESOLUTION))\n+        label = tf.one_hot(label, depth=NUM_CLASSES)\n+        return image, label\n+\n+    return fn\n+\n+\n+def prepare_dataset(dataset, is_training=True):\n+    if is_training:\n+        dataset = dataset.shuffle(BATCH_SIZE * 10)\n+    dataset = dataset.map(\n+        preprocess_dataset(is_training), num_parallel_calls=AUTO\n+    )\n+    return dataset.batch(BATCH_SIZE).prefetch(AUTO)\n+\n+\n+train_dataset, val_dataset = tfds.load(\n+    \"tf_flowers\", split=[\"train[:90%]\", \"train[90%:]\"], as_supervised=True\n+)\n+num_train = train_dataset.cardinality()\n+num_val = val_dataset.cardinality()\n+print(f\"Number of training examples: {num_train}\")\n+print(f\"Number of validation examples: {num_val}\")\n+\n+train_dataset = prepare_dataset(train_dataset, is_training=True)\n+val_dataset = prepare_dataset(val_dataset, is_training=False)\n+\n+\"\"\"\n+## Implementing the DeiT variants of ViT\n+\n+Since DeiT is an extension of ViT it'd make sense to first implement ViT and then extend\n+it to support DeiT's components.\n+\n+First, we'll implement a layer for Stochastic Depth\n+([Huang et al.](https://arxiv.org/abs/1603.09382))\n+which is used in DeiT for regularization.\n+\"\"\"\n+\n+\n+# Referred from: github.com:rwightman/pytorch-image-models.\n+class StochasticDepth(layers.Layer):\n+    def __init__(self, drop_prop, **kwargs):\n+        super().__init__(**kwargs)\n+        self.drop_prob = drop_prop\n+\n+    def call(self, x, training=True):\n+        if training:\n+            keep_prob = 1 - self.drop_prob\n+            shape = (tf.shape(x)[0],) + (1,) * (len(x.shape) - 1)\n+            random_tensor = keep_prob + tf.random.uniform(shape, 0, 1)\n+            random_tensor = tf.floor(random_tensor)\n+            return (x / keep_prob) * random_tensor\n+        return x\n+\n+\n+\"\"\"\n+Now, we'll implement the MLP and Transformer blocks.\n+\"\"\"\n+\n+\n+def mlp(x, dropout_rate: float, hidden_units):\n+    \"\"\"FFN for a Transformer block.\"\"\"\n+    # Iterate over the hidden units and\n+    # add Dense => Dropout.\n+    for idx, units in enumerate(hidden_units):\n+        x = layers.Dense(\n+            units,\n+            activation=tf.nn.gelu if idx == 0 else None,\n+        )(x)\n+        x = layers.Dropout(dropout_rate)(x)\n+    return x\n+\n+\n+def transformer(drop_prob: float, name: str) -> keras.Model:\n+    \"\"\"Transformer block with pre-norm.\"\"\"\n+    num_patches = (\n+        NUM_PATCHES + 2 if \"distilled\" in MODEL_TYPE else NUM_PATCHES + 1\n+    )\n+    encoded_patches = layers.Input((num_patches, PROJECTION_DIM))\n+\n+    # Layer normalization 1.\n+    x1 = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)(encoded_patches)\n+\n+    # Multi Head Self Attention layer 1.\n+    attention_output = layers.MultiHeadAttention(\n+        num_heads=NUM_HEADS,\n+        key_dim=PROJECTION_DIM,\n+        dropout=DROPOUT_RATE,\n+    )(x1, x1)\n+    attention_output = (\n+        StochasticDepth(drop_prob)(attention_output)\n+        if drop_prob\n+        else attention_output\n+    )\n+\n+    # Skip connection 1.\n+    x2 = layers.Add()([attention_output, encoded_patches])\n+\n+    # Layer normalization 2.\n+    x3 = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)(x2)\n+\n+    # MLP layer 1.\n+    x4 = mlp(x3, hidden_units=MLP_UNITS, dropout_rate=DROPOUT_RATE)\n+    x4 = StochasticDepth(drop_prob)(x4) if drop_prob else x4\n+\n+    # Skip connection 2.\n+    outputs = layers.Add()([x2, x4])\n+\n+    return keras.Model(encoded_patches, outputs, name=name)\n+\n+\n+\"\"\"\n+We'll now implement a `ViTClassifier` class building on top of the components we just\n+developed. Here we'll be following the original pooling strategy used in the ViT paper --\n+use a class token and use the feature representations corresponding to it for\n+classification.\n+\"\"\"\n+\n+\n+class ViTClassifier(keras.Model):\n+    \"\"\"Vision Transformer base class.\"\"\"\n+\n+    def __init__(self, **kwargs):\n+        super().__init__(**kwargs)\n+\n+        # Patchify + linear projection + reshaping.\n+        self.projection = keras.Sequential(\n+            [\n+                layers.Conv2D(\n+                    filters=PROJECTION_DIM,\n+                    kernel_size=(PATCH_SIZE, PATCH_SIZE),\n+                    strides=(PATCH_SIZE, PATCH_SIZE),\n+                    padding=\"VALID\",\n+                    name=\"conv_projection\",\n+                ),\n+                layers.Reshape(\n+                    target_shape=(NUM_PATCHES, PROJECTION_DIM),\n+                    name=\"flatten_projection\",\n+                ),\n+            ],\n+            name=\"projection\",\n+        )\n+\n+        # Positional embedding.\n+        init_shape = (\n+            1,\n+            NUM_PATCHES + 1,\n+            PROJECTION_DIM,\n+        )\n+        self.positional_embedding = tf.Variable(\n+            tf.zeros(init_shape), name=\"pos_embedding\"\n+        )\n+\n+        # Transformer blocks.\n+        dpr = [x for x in tf.linspace(0.0, DROP_PATH_RATE, NUM_LAYERS)]\n+        self.transformer_blocks = [\n+            transformer(drop_prob=dpr[i], name=f\"transformer_block_{i}\")\n+            for i in range(NUM_LAYERS)\n+        ]\n+\n+        # CLS token.\n+        initial_value = tf.zeros((1, 1, PROJECTION_DIM))\n+        self.cls_token = tf.Variable(\n+            initial_value=initial_value, trainable=True, name=\"cls\"\n+        )\n+\n+        # Other layers.\n+        self.dropout = layers.Dropout(DROPOUT_RATE)\n+        self.layer_norm = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)\n+        self.head = layers.Dense(\n+            NUM_CLASSES,\n+            name=\"classification_head\",\n+        )\n+\n+    def call(self, inputs):\n+        n = tf.shape(inputs)[0]\n+\n+        # Create patches and project the patches.\n+        projected_patches = self.projection(inputs)\n+\n+        # Append class token if needed.\n+        cls_token = tf.tile(self.cls_token, (n, 1, 1))\n+        cls_token = tf.cast(cls_token, projected_patches.dtype)\n+        projected_patches = tf.concat([cls_token, projected_patches], axis=1)\n+\n+        # Add positional embeddings to the projected patches.\n+        encoded_patches = (\n+            self.positional_embedding + projected_patches\n+        )  # (B, number_patches, projection_dim)\n+        encoded_patches = self.dropout(encoded_patches)\n+\n+        # Iterate over the number of layers and stack up blocks of\n+        # Transformer.\n+        for transformer_module in self.transformer_blocks:\n+            # Add a Transformer block.\n+            encoded_patches = transformer_module(encoded_patches)\n+\n+        # Final layer normalization.\n+        representation = self.layer_norm(encoded_patches)\n+\n+        # Pool representation.\n+        encoded_patches = representation[:, 0]\n+\n+        # Classification head.\n+        output = self.head(encoded_patches)\n+        return output\n+\n+\n+\"\"\"\n+This class can be used standalone as ViT and is end-to-end trainable. Just remove the\n+`distilled` phrase in `MODEL_TYPE` and it should work with `vit_tiny = ViTClassifier()`.\n+Let's now extend it to DeiT. The following figure presents the schematic of DeiT (taken\n+from the DeiT paper):\n+\n+![](https://i.imgur.com/5lmg2Xs.png)\n+\n+Apart from the class token, DeiT has another token for distillation. During distillation,\n+the logits corresponding to the class token are compared to the true labels, and the\n+logits corresponding to the distillation token are compared to the teacher's predictions.\n+\"\"\"\n+\n+\n+class ViTDistilled(ViTClassifier):\n+    def __init__(self, regular_training=False, **kwargs):\n+        super().__init__(**kwargs)\n+        self.num_tokens = 2\n+        self.regular_training = regular_training\n+\n+        # CLS and distillation tokens, positional embedding.\n+        init_value = tf.zeros((1, 1, PROJECTION_DIM))\n+        self.dist_token = tf.Variable(init_value, name=\"dist_token\")\n+        self.positional_embedding = tf.Variable(\n+            tf.zeros(\n+                (\n+                    1,\n+                    NUM_PATCHES + self.num_tokens,\n+                    PROJECTION_DIM,\n+                )\n+            ),\n+            name=\"pos_embedding\",\n+        )\n+\n+        # Head layers.\n+        self.head = layers.Dense(\n+            NUM_CLASSES,\n+            name=\"classification_head\",\n+        )\n+        self.head_dist = layers.Dense(\n+            NUM_CLASSES,\n+            name=\"distillation_head\",\n+        )\n+\n+    def call(self, inputs, training=False):\n+        n = tf.shape(inputs)[0]\n+\n+        # Create patches and project the patches.\n+        projected_patches = self.projection(inputs)\n+\n+        # Append the tokens.\n+        cls_token = tf.tile(self.cls_token, (n, 1, 1))\n+        dist_token = tf.tile(self.dist_token, (n, 1, 1))\n+        cls_token = tf.cast(cls_token, projected_patches.dtype)\n+        dist_token = tf.cast(dist_token, projected_patches.dtype)\n+        projected_patches = tf.concat(\n+            [cls_token, dist_token, projected_patches], axis=1\n+        )\n+\n+        # Add positional embeddings to the projected patches.\n+        encoded_patches = (\n+            self.positional_embedding + projected_patches\n+        )  # (B, number_patches, projection_dim)\n+        encoded_patches = self.dropout(encoded_patches)\n+\n+        # Iterate over the number of layers and stack up blocks of\n+        # Transformer.\n+        for transformer_module in self.transformer_blocks:\n+            # Add a Transformer block.\n+            encoded_patches = transformer_module(encoded_patches)\n+\n+        # Final layer normalization.\n+        representation = self.layer_norm(encoded_patches)\n+\n+        # Classification heads.\n+        x, x_dist = (\n+            self.head(representation[:, 0]),\n+            self.head_dist(representation[:, 1]),\n+        )\n+\n+        if not training or self.regular_training:\n+            # During standard train / finetune, inference average the classifier\n+            # predictions.\n+            return (x + x_dist) / 2\n+\n+        elif training:\n+            # Only return separate classification predictions when training in distilled\n+            # mode.\n+            return x, x_dist\n+\n+\n+\"\"\"\n+Let's verify if the `ViTDistilled` class can be initialized and called as expected.\n+\"\"\"\n+\n+deit_tiny_distilled = ViTDistilled()\n+\n+dummy_inputs = tf.ones((2, 224, 224, 3))\n+outputs = deit_tiny_distilled(dummy_inputs, training=False)\n+print(f\"output_shape: {outputs.shape}\")\n+\n+\"\"\"\n+## Implementing the trainer\n+\n+Unlike what happens in standard knowledge distillation\n+([Hinton et al.](https://arxiv.org/abs/1503.02531)),\n+where a temperature-scaled softmax is used as well as KL divergence,\n+DeiT authors use the following loss function:\n+\n+![](https://i.imgur.com/bXdxsBq.png)\n+\n+\n+Here,\n+\n+* CE is cross-entropy\n+* `psi` is the softmax function\n+* Z_s denotes student predictions\n+* y denotes true labels\n+* y_t denotes teacher predictions\n+\"\"\"\n+\n+\n+class DeiT(keras.Model):\n+    # Reference:\n+    # https://keras.io/examples/vision/knowledge_distillation/\n+    def __init__(self, student, teacher, **kwargs):\n+        super().__init__(**kwargs)\n+        self.student = student\n+        self.teacher = teacher\n+        self.student_loss_tracker = keras.metrics.Mean(name=\"student_loss\")\n+        self.distillation_loss_tracker = keras.metrics.Mean(\n+            name=\"distillation_loss\"\n+        )\n+        self.accuracy = keras.metrics.CategoricalAccuracy(name=\"accuracy\")\n+\n+    @property\n+    def metrics(self):\n+        return [\n+            self.accuracy,\n+            self.student_loss_tracker,\n+            self.distillation_loss_tracker,\n+        ]\n+\n+    def compile(\n+        self,\n+        optimizer,\n+        student_loss_fn,\n+        distillation_loss_fn,\n+        run_eagerly=False,\n+        jit_compile=False,\n+    ):\n+        super().compile(\n+            optimizer=optimizer,\n+            run_eagerly=run_eagerly,\n+            jit_compile=jit_compile,\n+        )\n+        self.student_loss_fn = student_loss_fn\n+        self.distillation_loss_fn = distillation_loss_fn\n+\n+    def train_step(self, data):\n+        # Unpack data.\n+        x, y = data\n+\n+        # Forward pass of teacher\n+        teacher_predictions = self.teacher(x)[\"dense\"]\n+        teacher_predictions = tf.nn.softmax(teacher_predictions, axis=-1)\n+\n+        with tf.GradientTape() as tape:\n+            # Forward pass of student.\n+            cls_predictions, dist_predictions = self.student(\n+                x / 255.0, training=True\n+            )\n+\n+            # Compute losses.\n+            student_loss = self.student_loss_fn(y, cls_predictions)\n+            distillation_loss = self.distillation_loss_fn(\n+                teacher_predictions, dist_predictions\n+            )\n+            loss = (student_loss + distillation_loss) / 2\n+\n+        # Compute gradients.\n+        trainable_vars = self.student.trainable_variables\n+        gradients = tape.gradient(loss, trainable_vars)\n+\n+        # Update weights.\n+        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n+\n+        # Update the metrics configured in `compile()`.\n+        student_predictions = (cls_predictions + dist_predictions) / 2\n+        self.student_loss_tracker.update_state(student_loss)\n+        self.distillation_loss_tracker.update_state(distillation_loss)\n+        self.accuracy.update_state(y, student_predictions)\n+\n+        # Return a dict of performance.\n+        return {m.name: m.result() for m in self.metrics}\n+\n+    def test_step(self, data):\n+        # Unpack the data.\n+        x, y = data\n+\n+        # Compute predictions.\n+        y_prediction = self.student(x / 255.0)\n+\n+        # Calculate the loss.\n+        student_loss = self.student_loss_fn(y, y_prediction)\n+\n+        # Update the metrics.\n+        self.student_loss_tracker.update_state(student_loss)\n+        self.accuracy.update_state(y, y_prediction)\n+\n+        # Return a dict of performance.\n+        results = {m.name: m.result() for m in self.metrics}\n+        return results\n+\n+    def call(self, inputs):\n+        return self.student(inputs / 255.0)\n+\n+\n+\"\"\"\n+## Load the teacher model\n+\n+This model is based on the BiT family of ResNets\n+([Kolesnikov et al.](https://arxiv.org/abs/1912.11370))\n+fine-tuned on the `tf_flowers` dataset. You can refer to\n+[this notebook](https://github.com/sayakpaul/deit-tf/blob/main/notebooks/bit-teacher.ipynb)\n+to know how the training was performed. The teacher model has about 212 Million parameters\n+which is about **40x more** than the student.\n+\"\"\"\n+\n+\"\"\"shell\n+wget -q https://github.com/sayakpaul/deit-tf/releases/download/v0.1.0/bit_teacher_flowers.zip\n+unzip -q bit_teacher_flowers.zip\n+\"\"\"\n+\n+bit_teacher_flowers = keras.layers.TFSMLayer(\n+    filepath=\"bit_teacher_flowers\",\n+    call_endpoint=\"serving_default\",\n+)\n+\n+\n+\"\"\"\n+## Training through distillation\n+\"\"\"\n+\n+deit_tiny = ViTDistilled()\n+deit_distiller = DeiT(student=deit_tiny, teacher=bit_teacher_flowers)\n+\n+lr_scaled = (BASE_LR / 512) * BATCH_SIZE\n+deit_distiller.compile(\n+    optimizer=keras.optimizers.AdamW(\n+        weight_decay=WEIGHT_DECAY, learning_rate=lr_scaled\n+    ),\n+    student_loss_fn=keras.losses.CategoricalCrossentropy(\n+        from_logits=True, label_smoothing=0.1\n+    ),\n+    distillation_loss_fn=keras.losses.CategoricalCrossentropy(from_logits=True),\n+)\n+_ = deit_distiller.fit(\n+    train_dataset, validation_data=val_dataset, epochs=NUM_EPOCHS\n+)\n+\n+\"\"\"\n+If we had trained the same model (the `ViTClassifier`) from scratch with the exact same\n+hyperparameters, the model would have scored about 59% accuracy. You can adapt the following code\n+to reproduce this result:\n+\n+```\n+vit_tiny = ViTClassifier()\n+\n+inputs = keras.Input((RESOLUTION, RESOLUTION, 3))\n+x = keras.layers.Rescaling(scale=1./255)(inputs)\n+outputs = deit_tiny(x)\n+model = keras.Model(inputs, outputs)\n+\n+model.compile(...)\n+model.fit(...)\n+```\n+\"\"\"\n+\n+\"\"\"\n+## Notes\n+\n+* Through the use of distillation, we're effectively transferring the inductive biases of\n+a CNN-based teacher model.\n+* Interestingly enough, this distillation strategy works better with a CNN as the teacher\n+model rather than a Transformer as shown in the paper.\n+* The use of regularization to train DeiT models is very important.\n+* ViT models are initialized with a combination of different initializers including\n+truncated normal, random normal, Glorot uniform, etc. If you're looking for\n+end-to-end reproduction of the original results, don't forget to initialize the ViTs well.\n+* If you want to explore the pre-trained DeiT models in TensorFlow and Keras with code\n+for fine-tuning, [check out these models on TF-Hub](https://tfhub.dev/sayakpaul/collections/deit/1).\n+\n+## Acknowledgements\n+\n+* Ross Wightman for keeping\n+[`timm`](https://github.com/rwightman/pytorch-image-models)\n+updated with readable implementations. I referred to the implementations of ViT and DeiT\n+a lot during implementing them in TensorFlow.\n+* [Aritra Roy Gosthipaty](https://github.com/ariG23498)\n+who implemented some portions of the `ViTClassifier` in another project.\n+* [Google Developers Experts](https://developers.google.com/programs/experts/)\n+program for supporting me with GCP credits which were used to run experiments for this\n+example.\n+\"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
