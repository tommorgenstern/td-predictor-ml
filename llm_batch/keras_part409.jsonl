{"custom_id": "keras#3bdb22959658215fdc907d26d231f1b365716d43", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 157 | Lines Deleted: 68 | Files Changed: 6 | Hunks: 25 | Methods Changed: 16 | Complexity Δ (Sum/Max): 8/6 | Churn Δ: 225 | Churn Cumulative: 25463 | Contributors (this commit): 131 | Commits (past 90d): 40 | Contributors (cumulative): 162 | DMM Complexity: 1.0\n\nDIFF:\n@@ -14,7 +14,6 @@\n # ==============================================================================\n \"\"\"Tests for Keras callbacks.\"\"\"\n \n-import tensorflow.compat.v2 as tf\n \n import collections\n import csv\n@@ -29,7 +28,6 @@ import unittest\n from unittest import mock\n \n from absl.testing import parameterized\n-import numpy as np\n import keras\n from keras import keras_parameterized\n from keras import testing_utils\n@@ -42,6 +40,8 @@ from keras.optimizer_v2 import gradient_descent\n from keras.optimizer_v2 import learning_rate_schedule\n from keras.utils import io_utils\n from keras.utils import np_utils\n+import numpy as np\n+import tensorflow.compat.v2 as tf\n from tensorflow.python.platform import tf_logging as logging\n \n try:\n@@ -3215,6 +3215,10 @@ class SummaryOpsTest(tf.test.TestCase):\n         x = self.dense(inputs)\n         return self.activation(x)\n \n+      # Intentionally erroring out at json serialization to test the warning.\n+      def get_config(self):\n+        raise NotImplementedError\n+\n     model = SimpleSubclass()\n     with tf.compat.v1.test.mock.patch.object(logging, 'warning') as mock_log:\n       self.assertFalse(\n\n@@ -15,7 +15,6 @@\n # pylint: disable=protected-access\n \"\"\"A `Network` is way to compose layers: the topological form of a `Model`.\"\"\"\n \n-import tensorflow.compat.v2 as tf\n \n import collections\n import copy\n@@ -34,6 +33,7 @@ from keras.saving.saved_model import network_serialization\n from keras.utils import generic_utils\n from keras.utils import tf_inspect\n from keras.utils import tf_utils\n+import tensorflow.compat.v2 as tf\n from tensorflow.python.platform import tf_logging as logging\n from tensorflow.tools.docs import doc_controls\n \n@@ -683,51 +683,6 @@ class Functional(training_lib.Model):\n   def get_config(self):\n     return copy.deepcopy(get_network_config(self))\n \n-  @classmethod\n-  def from_config(cls, config, custom_objects=None):\n-    \"\"\"Instantiates a Model from its config (output of `get_config()`).\n-\n-    Args:\n-        config: Model config dictionary.\n-        custom_objects: Optional dictionary mapping names\n-            (strings) to custom classes or functions to be\n-            considered during deserialization.\n-\n-    Returns:\n-        A model instance.\n-\n-    Raises:\n-        ValueError: In case of improperly formatted config dict.\n-        TypeError: In case the config does match the cls constructor.\n-    \"\"\"\n-\n-    with generic_utils.SharedObjectLoadingScope():\n-      if all(key in config for key in [\n-          'name', 'layers', 'input_layers', 'output_layers']):\n-        input_tensors, output_tensors, created_layers = reconstruct_from_config(\n-            config, custom_objects)\n-        model = cls(\n-            inputs=input_tensors,\n-            outputs=output_tensors,\n-            name=config.get('name'))\n-        connect_ancillary_layers(model, created_layers)\n-        return model\n-      # The config does not contain all the information necessary to revive a\n-      # Functional model. This happens when the user creates subclassed models\n-      # with a Functional constructor and has overridden the `get_config` method\n-      # to return a completely new dictionary.\n-      try:\n-        return cls(**config)\n-      except TypeError as e:\n-        raise TypeError('Unable to revive model from config. When overriding '\n-                        'the `get_config`, make sure that the returned config '\n-                        'contains all items used as arguments in the '\n-                        f'constructor to {cls}, which is the default behavior. '\n-                        'You can override this default behavior by defining a '\n-                        '`from_config` method to specify how to create an '\n-                        f'instance of {cls.__name__} from the config. \\n\\n'\n-                        f'Error encountered during deserialization:\\n{e}')\n-\n   def _validate_graph_inputs_and_outputs(self):\n     \"\"\"Validates the inputs and outputs of a Graph Network.\"\"\"\n     # Check for redundancy in inputs.\n\n@@ -2637,7 +2637,32 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     return model_config\n \n   def get_config(self):\n-    raise NotImplementedError\n+    \"\"\"Returns the config of the `Model`.\n+\n+    Config is a Python dictionary (serializable) containing the configuration of\n+    an object, which in this case is a `Model`. This allows the `Model` to be\n+    be reinstantiated later (without its trained weights) from this\n+    configuration.\n+\n+    Note that `get_config()` does not guarantee to return a fresh copy of dict\n+    every time it is called. The callers should make a copy of the returned dict\n+    if they want to modify it.\n+\n+    Developers of subclassed `Model` are advised to override this method, and\n+    continue to update the dict from `super(MyModel, self).get_config()`\n+    to provide the proper configuration of this `Model`. The default config\n+    is an empty dict. Optionally, raise `NotImplementedError` to allow Keras to\n+    attempt a default serialization.\n+\n+    Returns:\n+        Python dictionary containing the configuration of this `Model`.\n+    \"\"\"\n+\n+    # Return an empty dict here because otherwise subclass model developers may\n+    # see their model's `__init__()` be fed with unexpected keyword argument, if\n+    # their `__init__()` takes no argument for example, and they don't override\n+    # `from_config()`, which would use `cls(**config)` as a result.\n+    return {}\n \n   @classmethod\n   def from_config(cls, config, custom_objects=None):\n@@ -2647,15 +2672,33 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     # `cls(...)` instead of `Functional.from_config`.\n     from keras.engine import functional  # pylint: disable=g-import-not-at-top\n     with generic_utils.SharedObjectLoadingScope():\n-      input_tensors, output_tensors, created_layers = (\n-          functional.reconstruct_from_config(config, custom_objects))\n-      # Initialize a model belonging to `cls`, which can be user-defined or\n-      # `Functional`.\n-      model = cls(inputs=input_tensors, outputs=output_tensors,\n-                  name=config.get('name'))\n-      functional.connect_ancillary_layers(model, created_layers)\n+      functional_model_keys = [\n+          'name', 'layers', 'input_layers', 'output_layers'\n+      ]\n+      if all(key in config for key in functional_model_keys):\n+        inputs, outputs, layers = functional.reconstruct_from_config(\n+            config, custom_objects)\n+        model = cls(inputs=inputs, outputs=outputs, name=config.get('name'))\n+        functional.connect_ancillary_layers(model, layers)\n         return model\n \n+      # The config does not contain all the information necessary to revive a\n+      # Functional model. This happens when the user creates subclassed models\n+      # where `get_config()` is returning insufficient information to be\n+      # considered a Functional model. In this case, we fall back to provide\n+      # all config into the constructor of the class.\n+      try:\n+        return cls(**config)\n+      except TypeError as e:\n+        raise TypeError('Unable to revive model from config. When overriding '\n+                        'the `get_config()`, make sure that the returned '\n+                        'config contains all items used as arguments in the '\n+                        f'constructor to {cls}, which is the default behavior. '\n+                        'You can override this default behavior by defining a '\n+                        '`from_config` method to specify how to create an '\n+                        f'instance of {cls.__name__} from the config. \\n\\n'\n+                        f'Error encountered during deserialization:\\n{e}')\n+\n   def to_json(self, **kwargs):\n     \"\"\"Returns a JSON string containing the network configuration.\n \n\n@@ -632,10 +632,16 @@ class TestSavedModelFormatAllModes(keras_parameterized.TestCase):\n     saved_model_dir = self._save_model_dir()\n     model.save(saved_model_dir, save_format='tf')\n \n+    with keras.utils.generic_utils.custom_object_scope({'Model': Model}):\n       loaded = keras_load.load(saved_model_dir)\n     self.assertAllClose(prediction,\n                         loaded.predict(np.ones([1, 3]).astype('float32')))\n \n+    loaded_without_scope = keras_load.load(saved_model_dir)\n+    if tf.__internal__.tf2.enabled():\n+      with self.assertRaises(NotImplementedError):\n+        loaded_without_scope.predict(np.ones([1, 3]).astype('float32'))\n+\n   def testFeatureColumns(self):\n     # TODO(b/120099662): Error with table initialization with Keras models in\n     # graph mode.\n@@ -974,9 +980,9 @@ class TestSavedModelFormat(tf.test.TestCase):\n     self.addCleanup(shutil.rmtree, temp_dir, ignore_errors=True)\n     return os.path.join(temp_dir, dirname)\n \n-  def test_load_with_partially_failed_serialization(self):\n+  def test_load_with_custom_model_and_layer(self):\n \n-    class BadCustomLayer(keras.layers.Layer):\n+    class CustomLayer(keras.layers.Layer):\n \n       def __call__(self, inputs):\n         return inputs\n@@ -985,7 +991,7 @@ class TestSavedModelFormat(tf.test.TestCase):\n \n       def __init__(self):\n         super(Model, self).__init__()\n-        self.layer = BadCustomLayer()\n+        self.layer = CustomLayer()\n \n       @tf.function(\n           input_signature=[tf.TensorSpec([None, 1])])\n@@ -998,10 +1004,32 @@ class TestSavedModelFormat(tf.test.TestCase):\n     saved_model_dir = self._save_model_dir()\n     model.save(saved_model_dir, save_format='tf')\n \n+    # Even if the `CustomLayer` is not provided in `custom_object_scope`,\n+    # `Model` still has that reference.\n+    with keras.utils.generic_utils.custom_object_scope({'Model': Model}):\n       loaded = keras_load.load(saved_model_dir)\n     self.assertAllEqual([[1.0]], self.evaluate(loaded(inp)))\n-    with self.assertRaisesRegex(ValueError, 'call function was not serialized'):\n-      loaded.layer(inp)\n+    self.assertAllEqual([[1.0]], self.evaluate(loaded.layer(inp)))\n+    self.assertIsInstance(loaded.layer, CustomLayer)\n+\n+    # If `CustomLayer` is provided in `custom_object_scope`, it should of\n+    # course use that custom class.\n+    with keras.utils.generic_utils.custom_object_scope({\n+        'Model': Model,\n+        'CustomLayer': CustomLayer\n+    }):\n+      loaded = keras_load.load(saved_model_dir)\n+    self.assertAllEqual([[1.0]], self.evaluate(loaded(inp)))\n+    self.assertAllEqual([[1.0]], self.evaluate(loaded.layer(inp)))\n+    self.assertIsInstance(loaded.layer, CustomLayer)\n+\n+    # If the symbol is no longer available, loading should raise an error.\n+    del CustomLayer\n+    with keras.utils.generic_utils.custom_object_scope({'Model': Model}):\n+      with self.assertRaisesRegex(\n+          NameError, 'free variable \\'CustomLayer\\' referenced '\n+          'before assignment in enclosing scope'):\n+        loaded = keras_load.load(saved_model_dir)\n \n   def test_save_without_tracing(self):\n \n\n@@ -14,16 +14,12 @@\n # ==============================================================================\n \"\"\"Utilities for unit-testing Keras.\"\"\"\n \n-import tensorflow.compat.v2 as tf\n \n import collections\n import contextlib\n import functools\n import itertools\n import threading\n-\n-import numpy as np\n-from tensorflow.python.framework import test_util\n from keras import backend\n from keras import layers\n from keras import models\n@@ -37,6 +33,9 @@ from keras.optimizer_v2 import nadam as nadam_v2\n from keras.optimizer_v2 import rmsprop as rmsprop_v2\n from keras.utils import tf_contextlib\n from keras.utils import tf_inspect\n+import numpy as np\n+import tensorflow.compat.v2 as tf\n+from tensorflow.python.framework import test_util\n \n \n def string_test(actual, expected):\n@@ -538,6 +537,11 @@ class _SubclassModel(models.Model):\n       x = layer(x)\n     return x\n \n+  def get_config(self):\n+    # This test model relies on the default Keras serialization of a model,\n+    # rather than providing the details of `model_layers`.\n+    raise NotImplementedError\n+\n \n class _SubclassModelCustomBuild(models.Model):\n   \"\"\"A Keras subclass model that uses a custom build method.\"\"\"\n\n@@ -14,14 +14,16 @@\n # ==============================================================================\n \"\"\"Tests for Keras generic Python utils.\"\"\"\n \n-import tensorflow.compat.v2 as tf\n \n from functools import partial\n-\n-import numpy as np\n+import os\n+import sys\n \n import keras\n from keras.utils import generic_utils\n+from keras.utils import io_utils\n+import numpy as np\n+import tensorflow.compat.v2 as tf\n \n \n class SnakeCaseTest(tf.test.TestCase):\n@@ -458,6 +460,59 @@ class SharedObjectScopeTest(tf.test.TestCase):\n       self.assertIsNotNone(scope_1.get_config(my_obj))\n     self.assertIsNone(generic_utils._shared_object_saving_scope())\n \n+  def test_custom_object_scope_correct_class(self):\n+    train_step_message = 'This is my training step'\n+    temp_dir = os.path.join(self.get_temp_dir(), 'my_model')\n+\n+    class CustomModelX(keras.Model):\n+\n+      def __init__(self, *args, **kwargs):\n+        super().__init__(*args, **kwargs)\n+        self.dense1 = keras.layers.Dense(1)\n+\n+      def call(self, inputs):\n+        return self.dense1(inputs)\n+\n+      def train_step(self, data):\n+        tf.print(train_step_message)\n+        x, y = data\n+        with tf.GradientTape() as tape:\n+          y_pred = self(x)\n+          loss = self.compiled_loss(y, y_pred)\n+\n+        gradients = tape.gradient(loss, self.trainable_variables)\n+        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n+        return {}\n+\n+      def func_that_returns_one(self):\n+        return 1\n+\n+    subclassed_model = CustomModelX()\n+    subclassed_model.compile(optimizer='adam', loss='mse')\n+\n+    x = np.random.random((100, 32))\n+    y = np.random.random((100, 1))\n+    subclassed_model.fit(x, y, epochs=1)\n+    subclassed_model.save(temp_dir, save_format='tf')\n+\n+    with keras.utils.generic_utils.custom_object_scope(\n+        {'CustomModelX': CustomModelX}):\n+      loaded_model = keras.models.load_model(temp_dir)\n+\n+    io_utils.enable_interactive_logging()\n+    # `tf.print` writes to stderr.\n+    with self.captureWritesToStream(sys.stderr) as printed:\n+      loaded_model.fit(x, y, epochs=1)\n+      if tf.__internal__.tf2.enabled():\n+        # `tf.print` message is only available in stderr in TF2. Check that\n+        # custom `train_step` is used.\n+        self.assertRegex(printed.contents(), train_step_message)\n+\n+    # Check that the custom class does get used.\n+    self.assertIsInstance(loaded_model, CustomModelX)\n+    # Check that the custom method is available.\n+    self.assertEqual(loaded_model.func_that_returns_one(), 1)\n+\n \n if __name__ == '__main__':\n   tf.test.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2cdfbd18a750cabaff1499fad7473dd91f3c7fa7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 82 | Lines Deleted: 105 | Files Changed: 52 | Hunks: 130 | Methods Changed: 8 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 187 | Churn Cumulative: 17048 | Contributors (this commit): 26 | Commits (past 90d): 74 | Contributors (cumulative): 179 | DMM Complexity: None\n\nDIFF:\n@@ -18,10 +18,12 @@ import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n from keras import layers\n+from keras import testing_utils\n from keras.engine import training\n from keras.optimizer_v2 import gradient_descent as gradient_descent_keras\n \n \n+@testing_utils.run_v2_only\n @tf.__internal__.distribute.combinations.generate(\n     tf.__internal__.test.combinations.combine(\n         strategy=[\n@@ -67,5 +69,4 @@ class MultiWorkerMirroredStrategyTest(tf.test.TestCase, parameterized.TestCase):\n \n \n if __name__ == '__main__':\n-  tf.compat.v1.enable_v2_behavior()\n   tf.__internal__.distribute.multi_process_runner.test_main()\n\n@@ -17,6 +17,7 @@\n from absl.testing import parameterized\n import keras\n from keras import optimizers\n+from keras import testing_utils\n from keras.applications import resnet_v2\n from keras.datasets import fashion_mnist\n from keras.distribute import optimizer_combinations\n@@ -216,13 +217,13 @@ def iteration_outside_func(initial_weights,\n             training_accuracy.result())\n \n \n+@testing_utils.run_v2_only\n class TestDistributionStrategyDnnCorrectness(tf.test.TestCase,\n                                              parameterized.TestCase):\n   \"\"\"Test custom training loop correctness with a simple DNN model.\"\"\"\n \n   def setUp(self):\n     super(TestDistributionStrategyDnnCorrectness, self).setUp()\n-    tf.compat.v1.enable_v2_behavior()\n     np.random.seed(_RANDOM_SEED)\n     tf.compat.v1.set_random_seed(_RANDOM_SEED)\n \n\n@@ -16,11 +16,13 @@\n \"\"\"Tests for `DatasetCreator` with `Model.fit` across usages and strategies.\"\"\"\n \n from keras import callbacks as callbacks_lib\n+from keras import testing_utils\n from keras.distribute import dataset_creator_model_fit_test_base as test_base\n from keras.distribute import strategy_combinations\n import tensorflow.compat.v2 as tf\n \n \n+@testing_utils.run_v2_only\n @tf.__internal__.distribute.combinations.generate(\n     tf.__internal__.test.combinations.combine(\n         strategy=strategy_combinations.parameter_server_strategies_multi_worker,\n@@ -132,5 +134,4 @@ class DatasetCreatorModelFitParameterServerStrategyOnlyTest(\n \n \n if __name__ == \"__main__\":\n-  tf.compat.v1.enable_v2_behavior()\n   tf.__internal__.distribute.multi_process_runner.test_main()\n\n@@ -19,6 +19,7 @@ import tensorflow.compat.v2 as tf\n \n import numpy as np\n from tensorflow.python.framework import test_util\n+from keras import testing_utils\n from keras.distribute import dataset_creator_model_fit_test_base as test_base\n from keras.distribute import strategy_combinations\n from keras.utils import dataset_creator\n@@ -26,6 +27,7 @@ from keras.utils import dataset_creator\n \n # TODO(rchao): Investigate why there cannot be single worker and multi worker\n # PS strategies running in the same shard.\n+@testing_utils.run_v2_only\n @tf.__internal__.distribute.combinations.generate(\n     tf.__internal__.test.combinations.combine(\n         strategy=strategy_combinations.all_strategies +\n@@ -251,9 +253,9 @@ class DatasetCreatorModelFitTest(test_base.DatasetCreatorModelFitTestBase):\n \n   def testModelTrainTFFunction(self, strategy):\n     model = self._model_fit(strategy)\n-    self.assertIsInstance(model.train_tf_function, tf.__internal__.function.Function)\n+    self.assertIsInstance(model.train_tf_function,\n+                          tf.__internal__.function.Function)\n \n \n if __name__ == \"__main__\":\n-  tf.compat.v1.enable_v2_behavior()\n   tf.__internal__.distribute.multi_process_runner.test_main()\n\n@@ -20,6 +20,7 @@ import tensorflow.compat.v2 as tf\n import time\n \n import keras\n+from keras import testing_utils\n from tensorflow.python.distribute import multi_worker_test_base\n from tensorflow.python.distribute.cluster_resolver import SimpleClusterResolver\n from tensorflow.python.ops import resource_variable_ops\n@@ -87,6 +88,7 @@ class MeanMetricAsCompositeTensor(keras.metrics.Mean,\n     return KerasMetricTypeSpec(self.__class__, self.get_config(), self.weights)\n \n \n+@testing_utils.run_v2_only\n class EvaluationTest(tf.test.TestCase):\n \n   @classmethod\n@@ -183,5 +185,4 @@ class EvaluationTest(tf.test.TestCase):\n \n \n if __name__ == \"__main__\":\n-  tf.compat.v1.enable_v2_behavior()\n   tf.__internal__.distribute.multi_process_runner.test_main()\n\n@@ -22,6 +22,7 @@ from keras.distribute import model_combinations\n from keras.distribute import saved_model_test_base as test_base\n \n \n+@testing_utils.run_v2_only\n @testing_utils.run_all_without_tensor_float_32(\n     'Uses Dense layers, which call matmul')\n class SavedModelKerasModelTest(test_base.TestSavedModelBase):\n@@ -83,6 +84,7 @@ class SavedModelKerasModelTest(test_base.TestSavedModelBase):\n           self.assertEmpty(n.device)\n \n \n+@testing_utils.run_v2_only\n class SavedModelTFModuleTest(test_base.TestSavedModelBase):\n \n   def setUp(self):\n@@ -169,5 +171,4 @@ class SavedModelTFModuleTest(test_base.TestSavedModelBase):\n \n \n if __name__ == '__main__':\n-  tf.compat.v1.enable_eager_execution()\n   tf.test.main()\n\n@@ -15,7 +15,6 @@\n # ==============================================================================\n \"\"\"Test covering sidecar_evaluator.py.\"\"\"\n \n-\n import enum\n import os\n import threading\n@@ -23,6 +22,7 @@ import time\n \n from absl.testing import parameterized\n import keras\n+from keras import testing_utils\n from keras.distribute import sidecar_evaluator as sidecar_evaluator_lib\n from keras.optimizer_v2 import gradient_descent\n import numpy as np\n@@ -72,6 +72,7 @@ def _test_model_builder(model_type: ModelType, compile_model, build_model):\n   return model\n \n \n+@testing_utils.run_v2_only\n class SidecarEvaluatorTest(tf.test.TestCase, parameterized.TestCase):\n \n   def assertSummaryEventsWritten(self, log_dir):\n@@ -302,5 +303,4 @@ class SidecarEvaluatorTest(tf.test.TestCase, parameterized.TestCase):\n \n \n if __name__ == '__main__':\n-  tf.compat.v1.enable_v2_behavior()\n   tf.test.main()\n\n@@ -57,6 +57,7 @@ class InvalidLayer(base_layer.Layer):\n     raise ValueError('You did something wrong!')\n \n \n+@testing_utils.run_v2_only\n class BaseLayerTest(keras_parameterized.TestCase):\n \n   @combinations.generate(combinations.keras_mode_combinations())\n@@ -1002,6 +1003,7 @@ class BaseLayerTest(keras_parameterized.TestCase):\n     self.assertLen(model.non_trainable_variables, 2)\n \n \n+@testing_utils.run_v2_only\n class SymbolicSupportTest(keras_parameterized.TestCase):\n \n   def test_using_symbolic_tensors_with_tf_ops(self):\n@@ -1127,6 +1129,7 @@ class SymbolicSupportTest(keras_parameterized.TestCase):\n       layer(x)\n \n \n+@testing_utils.run_v2_only\n @combinations.generate(combinations.combine(mode=['graph', 'eager']))\n class NestedTrackingTest(tf.test.TestCase):\n \n@@ -1300,6 +1303,7 @@ class NestedTrackingTest(tf.test.TestCase):\n     self.assertLen(s.weights, 4)\n \n \n+@testing_utils.run_v2_only\n @combinations.generate(combinations.combine(mode=['graph', 'eager']))\n class NameScopingTest(keras_parameterized.TestCase):\n \n@@ -1430,6 +1434,7 @@ class NameScopingTest(keras_parameterized.TestCase):\n     ]\n \n \n+@testing_utils.run_v2_only\n @combinations.generate(combinations.keras_mode_combinations(mode=['eager']))\n class AutographControlFlowTest(keras_parameterized.TestCase):\n \n@@ -1708,6 +1713,7 @@ class IdentityLayer(base_layer.Layer):\n     return inputs\n \n \n+@testing_utils.run_v2_only\n @combinations.generate(combinations.combine(mode=['graph', 'eager']))\n class DTypeTest(keras_parameterized.TestCase):\n \n@@ -1877,5 +1883,4 @@ class DTypeTest(keras_parameterized.TestCase):\n \n \n if __name__ == '__main__':\n-  tf.compat.v1.enable_eager_execution()\n   tf.test.main()\n\n@@ -30,6 +30,7 @@ except ImportError:\n   h5py = None\n \n \n+@testing_utils.run_v2_only\n class TestDeferredSequential(keras_parameterized.TestCase):\n \n   @keras_parameterized.run_all_keras_modes(always_skip_v1=True)\n@@ -213,5 +214,4 @@ def get_model():\n \n \n if __name__ == '__main__':\n-  tf.compat.v1.enable_v2_behavior()\n   tf.test.main()\n\n@@ -20,6 +20,7 @@ import tensorflow.compat.v2 as tf\n from absl.testing import parameterized\n from keras import keras_parameterized\n from keras import layers\n+from keras import testing_utils\n from keras.engine import keras_tensor\n from keras.engine import training\n \n@@ -46,6 +47,7 @@ class CustomTypeSpec2(CustomTypeSpec):\n     return CustomTypeSpec2(new_shape, self.dtype)\n \n \n+@testing_utils.run_v2_only\n class KerasTensorTest(keras_parameterized.TestCase):\n \n   def test_repr_and_string(self):\n@@ -218,6 +220,4 @@ class KerasTensorTest(keras_parameterized.TestCase):\n \n \n if __name__ == \"__main__\":\n-  tf.compat.v1.enable_eager_execution()\n-  tf.compat.v1.enable_v2_tensorshape()\n   tf.test.main()\n\n@@ -20,9 +20,11 @@ from absl.testing import parameterized\n import numpy as np\n from keras import keras_parameterized\n from keras import layers\n+from keras import testing_utils\n from keras.engine import training\n \n \n+@testing_utils.run_v2_only\n class RaggedKerasTensorTest(keras_parameterized.TestCase):\n \n   @parameterized.parameters(\n@@ -179,6 +181,7 @@ class RaggedKerasTensorTest(keras_parameterized.TestCase):\n       self.assertAllEqual(a, b)\n \n \n+@testing_utils.run_v2_only\n class RaggedTensorClassMethodAsLayerTest(keras_parameterized.TestCase):\n \n   def test_from_value_rowids(self):\n@@ -372,6 +375,4 @@ class RaggedTensorClassMethodAsLayerTest(keras_parameterized.TestCase):\n \n \n if __name__ == '__main__':\n-  tf.compat.v1.enable_eager_execution()\n-  tf.compat.v1.enable_v2_tensorshape()\n   tf.test.main()\n\n@@ -20,6 +20,7 @@ import os\n import random\n import tempfile\n from absl.testing import parameterized\n+from keras import testing_utils\n import numpy as np\n import portpicker\n import tensorflow.compat.v2 as tf\n@@ -66,6 +67,7 @@ def create_in_process_cluster(num_workers, num_ps):\n   return cluster_spec\n \n \n+@testing_utils.run_v2_only\n class KPLTest(tf.test.TestCase, parameterized.TestCase):\n \n   def setUp(self):\n@@ -262,6 +264,7 @@ class KPLTest(tf.test.TestCase, parameterized.TestCase):\n       self.assertIn(prediction1, (\"yes\", \"no\"))\n \n \n+@testing_utils.run_v2_only\n class KPLCreatedInDatasetsFromFunctionTest(tf.test.TestCase,\n                                            parameterized.TestCase):\n \n@@ -320,5 +323,4 @@ class KPLCreatedInDatasetsFromFunctionTest(tf.test.TestCase,\n \n \n if __name__ == \"__main__\":\n-  tf.compat.v1.enable_v2_behavior()\n   tf.test.main()\n\n@@ -26,6 +26,7 @@ def squared_l2_norm(x):\n   return tf.reduce_sum(x ** 2)\n \n \n+@testing_utils.run_v2_only\n class UnitNormalizationTest(keras_parameterized.TestCase):\n \n   @keras_parameterized.run_all_keras_modes\n@@ -74,5 +75,4 @@ class UnitNormalizationTest(keras_parameterized.TestCase):\n \n \n if __name__ == '__main__':\n-  tf.compat.v1.enable_v2_behavior()\n   tf.test.main()\n\n@@ -23,9 +23,6 @@ from tensorflow.python.eager.def_function import function as tf_function\n from keras.layers.preprocessing import discretization\n from keras.layers.preprocessing.benchmarks import feature_column_benchmark as fc_bm\n \n-# This is required as of 3/2021 because otherwise we drop into graph mode.\n-tf.compat.v1.enable_v2_behavior()\n-\n NUM_REPEATS = 10  # The number of times to run each benchmark.\n BATCH_SIZES = [32, 256]\n \n\n@@ -23,8 +23,6 @@ import numpy as np\n import keras\n from keras.layers.preprocessing import category_encoding\n \n-tf.compat.v1.enable_v2_behavior()\n-\n \n class BenchmarkLayer(tf.test.Benchmark):\n   \"\"\"Benchmark the layer forward pass.\"\"\"\n\n@@ -21,9 +21,6 @@ from tensorflow.python.eager.def_function import function as tf_function\n from keras.layers.preprocessing import hashing\n from keras.layers.preprocessing.benchmarks import feature_column_benchmark as fc_bm\n \n-# This is required as of 3/2021 because otherwise we drop into graph mode.\n-tf.compat.v1.enable_v2_behavior()\n-\n NUM_REPEATS = 10\n BATCH_SIZES = [32, 256]\n \n\n@@ -21,9 +21,6 @@ from tensorflow.python.eager.def_function import function as tf_function\n from keras.layers.preprocessing import hashing\n from keras.layers.preprocessing.benchmarks import feature_column_benchmark as fc_bm\n \n-# This is required as of 3/2021 because otherwise we drop into graph mode.\n-tf.compat.v1.enable_v2_behavior()\n-\n NUM_REPEATS = 10\n BATCH_SIZES = [32, 256]\n \n\n@@ -23,9 +23,6 @@ from tensorflow.python.eager.def_function import function as tf_function\n from keras.layers.preprocessing import string_lookup\n from keras.layers.preprocessing.benchmarks import feature_column_benchmark as fc_bm\n \n-# This is required as of 3/2021 because otherwise we drop into graph mode.\n-tf.compat.v1.enable_v2_behavior()\n-\n NUM_REPEATS = 10\n BATCH_SIZES = [32, 256]\n \n\n@@ -23,9 +23,6 @@ from tensorflow.python.eager.def_function import function as tf_function\n from keras.layers.preprocessing import string_lookup\n from keras.layers.preprocessing.benchmarks import feature_column_benchmark as fc_bm\n \n-# This is required as of 3/2021 because otherwise we drop into graph mode.\n-tf.compat.v1.enable_v2_behavior()\n-\n NUM_REPEATS = 10\n BATCH_SIZES = [32, 256]\n \n\n@@ -21,9 +21,6 @@ from tensorflow.python.eager.def_function import function as tf_function\n from keras.layers.preprocessing import string_lookup\n from keras.layers.preprocessing.benchmarks import feature_column_benchmark as fc_bm\n \n-# This is required as of 3/2021 because otherwise we drop into graph mode.\n-tf.compat.v1.enable_v2_behavior()\n-\n NUM_REPEATS = 10\n BATCH_SIZES = [32, 256]\n \n\n@@ -22,9 +22,6 @@ from keras.layers.preprocessing import category_encoding\n from keras.layers.preprocessing import string_lookup\n from keras.layers.preprocessing.benchmarks import feature_column_benchmark as fc_bm\n \n-# This is required as of 3/2021 because otherwise we drop into graph mode.\n-tf.compat.v1.enable_v2_behavior()\n-\n NUM_REPEATS = 10\n BATCH_SIZES = [32, 256]\n \n\n@@ -22,9 +22,6 @@ from keras.layers.preprocessing import category_encoding\n from keras.layers.preprocessing import string_lookup\n from keras.layers.preprocessing.benchmarks import feature_column_benchmark as fc_bm\n \n-# This is required as of 3/2021 because otherwise we drop into graph mode.\n-tf.compat.v1.enable_v2_behavior()\n-\n NUM_REPEATS = 10\n BATCH_SIZES = [32, 256]\n \n\n@@ -21,9 +21,6 @@ from tensorflow.python.eager.def_function import function as tf_function\n from keras.layers.preprocessing import string_lookup\n from keras.layers.preprocessing.benchmarks import feature_column_benchmark as fc_bm\n \n-# This is required as of 3/2021 because otherwise we drop into graph mode.\n-tf.compat.v1.enable_v2_behavior()\n-\n NUM_REPEATS = 10\n BATCH_SIZES = [32, 256]\n \n\n@@ -25,8 +25,6 @@ from keras.layers.preprocessing import discretization\n \n EPSILON = 0.1\n \n-tf.compat.v1.enable_v2_behavior()\n-\n \n def reduce_fn(state, values, epsilon=EPSILON):\n   \"\"\"tf.data.Dataset-friendly implementation of mean and variance.\"\"\"\n\n@@ -20,9 +20,6 @@ import keras\n from tensorflow.python.eager.def_function import function as tf_function\n from keras.layers.preprocessing.benchmarks import feature_column_benchmark as fc_bm\n \n-# This is required as of 3/2021 because otherwise we drop into graph mode.\n-tf.compat.v1.enable_v2_behavior()\n-\n NUM_REPEATS = 10\n BATCH_SIZES = [32, 256]\n \n\n@@ -20,9 +20,6 @@ import keras\n from tensorflow.python.eager.def_function import function as tf_function\n from keras.layers.preprocessing.benchmarks import feature_column_benchmark as fc_bm\n \n-# This is required as of 3/2021 because otherwise we drop into graph mode.\n-tf.compat.v1.enable_v2_behavior()\n-\n NUM_REPEATS = 10\n BATCH_SIZES = [32, 256]\n \n\n@@ -25,9 +25,6 @@ import numpy as np\n \n import keras\n \n-# This is required as of 3/2021 because otherwise we drop into graph mode.\n-tf.compat.v1.enable_v2_behavior()\n-\n \n class LayerBenchmark(tf.test.Benchmark):\n   \"\"\"Benchmark the layer forward pass.\"\"\"\n\n@@ -21,8 +21,6 @@ from keras.layers.preprocessing.benchmarks import feature_column_benchmark as fc\n import tensorflow.compat.v2 as tf\n from tensorflow.python.eager.def_function import function as tf_function\n \n-tf.compat.v1.enable_v2_behavior()\n-\n NUM_REPEATS = 10\n BATCH_SIZES = [32, 256]\n \n\n@@ -26,8 +26,6 @@ import numpy as np\n import keras\n from keras.layers.preprocessing import hashing\n \n-tf.compat.v1.enable_v2_behavior()\n-\n \n # word_gen creates random sequences of ASCII letters (both lowercase and upper).\n # The number of unique strings is ~2,700.\n\n@@ -24,8 +24,6 @@ import numpy as np\n import keras\n from keras.layers.preprocessing import image_preprocessing\n \n-tf.compat.v1.enable_v2_behavior()\n-\n LOWER = .2\n UPPER = .4\n BATCH_SIZE = 32\n\n@@ -26,8 +26,6 @@ import numpy as np\n import keras\n from keras.layers.preprocessing import index_lookup\n \n-tf.compat.v1.enable_v2_behavior()\n-\n \n # word_gen creates random sequences of ASCII letters (both lowercase and upper).\n # The number of unique strings is ~2,700.\n\n@@ -23,8 +23,6 @@ import numpy as np\n import keras\n from keras.layers.preprocessing import normalization\n \n-tf.compat.v1.enable_v2_behavior()\n-\n \n def reduce_fn(state, values):\n   \"\"\"tf.data.Dataset-friendly implementation of mean and variance.\"\"\"\n\n@@ -20,9 +20,6 @@ import keras\n from tensorflow.python.eager.def_function import function as tf_function\n from keras.layers.preprocessing.benchmarks import feature_column_benchmark as fc_bm\n \n-# This is required as of 3/2021 because otherwise we drop into graph mode.\n-tf.compat.v1.enable_v2_behavior()\n-\n NUM_REPEATS = 10\n BATCH_SIZES = [32, 256]\n \n\n@@ -19,6 +19,7 @@\n import keras\n from keras import backend\n from keras import keras_parameterized\n+from keras import testing_utils\n from keras.distribute import strategy_combinations\n from keras.layers.preprocessing import category_encoding\n from keras.layers.preprocessing import preprocessing_test_utils\n@@ -38,6 +39,7 @@ def batch_wrapper(dataset, batch_size, strategy, repeat=None):\n     return dataset.batch(batch_size)\n \n \n+@testing_utils.run_v2_only\n @tf.__internal__.distribute.combinations.generate(\n     tf.__internal__.test.combinations.combine(\n         strategy=strategy_combinations.all_strategies +\n@@ -76,5 +78,4 @@ class CategoryEncodingDistributionTest(\n \n \n if __name__ == \"__main__\":\n-  tf.compat.v1.enable_v2_behavior()\n   tf.__internal__.distribute.multi_process_runner.test_main()\n\n@@ -18,6 +18,7 @@\n \n import keras\n from keras import keras_parameterized\n+from keras import testing_utils\n from keras.distribute import strategy_combinations\n from keras.layers.preprocessing import discretization\n from keras.layers.preprocessing import preprocessing_test_utils\n@@ -25,6 +26,7 @@ import numpy as np\n import tensorflow.compat.v2 as tf\n \n \n+@testing_utils.run_v2_only\n @tf.__internal__.distribute.combinations.generate(\n     tf.__internal__.test.combinations.combine(\n         strategy=strategy_combinations.all_strategies +\n@@ -56,5 +58,4 @@ class DiscretizationDistributionTest(\n \n \n if __name__ == \"__main__\":\n-  tf.compat.v1.enable_v2_behavior()\n   tf.__internal__.distribute.multi_process_runner.test_main()\n\n@@ -164,5 +164,4 @@ class HashedCrossingTest(keras_parameterized.TestCase):\n \n \n if __name__ == '__main__':\n-  tf.compat.v1.enable_v2_behavior()\n   tf.test.main()\n\n@@ -19,6 +19,7 @@\n import keras\n from keras import backend\n from keras import keras_parameterized\n+from keras import testing_utils\n from keras.distribute import strategy_combinations\n from keras.layers.preprocessing import hashing\n from keras.layers.preprocessing import preprocessing_test_utils\n@@ -27,6 +28,7 @@ import tensorflow.compat.v2 as tf\n from tensorflow.python.framework import test_util\n \n \n+@testing_utils.run_v2_only\n @tf.__internal__.distribute.combinations.generate(\n     tf.__internal__.test.combinations.combine(\n         strategy=strategy_combinations.all_strategies +\n@@ -59,5 +61,4 @@ class HashingDistributionTest(keras_parameterized.TestCase,\n \n \n if __name__ == \"__main__\":\n-  tf.compat.v1.enable_v2_behavior()\n   tf.__internal__.distribute.multi_process_runner.test_main()\n\n@@ -16,6 +16,7 @@\n \n import keras\n from keras import keras_parameterized\n+from keras import testing_utils\n from keras.distribute import strategy_combinations\n from keras.layers.preprocessing import image_preprocessing\n from keras.layers.preprocessing import preprocessing_test_utils\n@@ -23,6 +24,7 @@ import numpy as np\n import tensorflow.compat.v2 as tf\n \n \n+@testing_utils.run_v2_only\n @tf.__internal__.distribute.combinations.generate(\n     tf.__internal__.test.combinations.combine(\n         strategy=strategy_combinations.all_strategies +\n@@ -59,5 +61,4 @@ class ImagePreprocessingDistributionTest(\n \n \n if __name__ == \"__main__\":\n-  tf.compat.v1.enable_v2_behavior()\n   tf.__internal__.distribute.multi_process_runner.test_main()\n\n@@ -21,6 +21,7 @@ import os\n import keras\n from keras import backend\n from keras import keras_parameterized\n+from keras import testing_utils\n from keras.distribute import strategy_combinations\n from keras.layers.preprocessing import index_lookup\n from keras.layers.preprocessing import preprocessing_test_utils\n@@ -29,6 +30,7 @@ import tensorflow.compat.v2 as tf\n from tensorflow.python.framework import test_util\n \n \n+@testing_utils.run_v2_only\n @tf.__internal__.distribute.combinations.generate(\n     tf.__internal__.test.combinations.combine(\n         strategy=strategy_combinations.all_strategies +\n@@ -147,5 +149,4 @@ class IndexLookupDistributionTest(\n \n \n if __name__ == \"__main__\":\n-  tf.compat.v1.enable_v2_behavior()\n   tf.__internal__.distribute.multi_process_runner.test_main()\n\n@@ -615,6 +615,4 @@ class IntegerLookupSavingTest(keras_parameterized.TestCase,\n \n \n if __name__ == \"__main__\":\n-  # IntegerLookup is only exported as a TF2 API.\n-  tf.compat.v1.enable_v2_behavior()\n   tf.test.main()\n\n@@ -17,6 +17,7 @@\n \n import keras\n from keras import keras_parameterized\n+from keras import testing_utils\n from keras.distribute import strategy_combinations\n from keras.layers.preprocessing import normalization\n from keras.layers.preprocessing import preprocessing_test_utils\n@@ -89,6 +90,7 @@ def _get_layer_computation_test_cases():\n   return crossed_test_cases\n \n \n+@testing_utils.run_v2_only\n @tf.__internal__.distribute.combinations.generate(\n     tf.__internal__.test.combinations.times(\n         tf.__internal__.test.combinations.combine(\n@@ -119,5 +121,4 @@ class NormalizationTest(keras_parameterized.TestCase,\n \n \n if __name__ == \"__main__\":\n-  tf.compat.v1.enable_v2_behavior()\n   tf.__internal__.distribute.multi_process_runner.test_main()\n\n@@ -364,8 +364,7 @@ class StringLookupVocabularyTest(keras_parameterized.TestCase,\n   def test_ragged_string_input_multi_bucket(self):\n     vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n     input_array = tf.ragged.constant([[\"earth\", \"wind\", \"fire\"],\n-                                               [\"fire\", \"and\", \"earth\",\n-                                                \"ohio\"]])\n+                                      [\"fire\", \"and\", \"earth\", \"ohio\"]])\n     expected_output = [[2, 3, 5], [5, 4, 2, 1]]\n \n     input_data = keras.Input(shape=(None,), dtype=tf.string, ragged=True)\n@@ -388,6 +387,4 @@ class StringLookupVocabularyTest(keras_parameterized.TestCase,\n       fn()\n \n if __name__ == \"__main__\":\n-  # StringLookup is only exported as a TF2 API.\n-  tf.compat.v1.enable_v2_behavior()\n   tf.test.main()\n\n@@ -19,6 +19,7 @@\n import keras\n from keras import backend\n from keras import keras_parameterized\n+from keras import testing_utils as keras_testing_utils\n from keras.distribute import strategy_combinations\n from keras.layers.preprocessing import preprocessing_test_utils\n from keras.layers.preprocessing import text_vectorization\n@@ -27,6 +28,7 @@ import tensorflow.compat.v2 as tf\n from tensorflow.python.framework import test_util\n \n \n+@keras_testing_utils.run_v2_only\n @tf.__internal__.distribute.combinations.generate(\n     tf.__internal__.test.combinations.combine(\n         strategy=strategy_combinations.all_strategies +\n@@ -101,5 +103,4 @@ class TextVectorizationDistributionTest(\n     self.assertAllEqual(expected_output, output_dataset)\n \n if __name__ == \"__main__\":\n-  tf.compat.v1.enable_v2_behavior()\n   tf.__internal__.distribute.multi_process_runner.test_main()\n\n@@ -266,6 +266,7 @@ def _get_end_to_end_test_cases():\n   return crossed_test_cases\n \n \n+@testing_utils.run_v2_only\n @keras_parameterized.run_all_keras_modes(always_skip_v1=True)\n class TextVectorizationLayerTest(keras_parameterized.TestCase,\n                                  preprocessing_test_utils.PreprocessingLayerTest\n@@ -479,6 +480,7 @@ class TextVectorizationLayerTest(keras_parameterized.TestCase,\n     self.assertAllEqual(expected, output)\n \n \n+@testing_utils.run_v2_only\n @keras_parameterized.run_all_keras_modes(always_skip_v1=True)\n class TextVectorizationPreprocessingTest(\n     keras_parameterized.TestCase,\n@@ -858,6 +860,7 @@ class TextVectorizationPreprocessingTest(\n     self.assertAllEqual(expected_output, output_dataset)\n \n \n+@testing_utils.run_v2_only\n @keras_parameterized.run_all_keras_modes(always_skip_v1=True)\n class TextVectorizationDistributionTest(\n     keras_parameterized.TestCase,\n@@ -885,6 +888,7 @@ class TextVectorizationDistributionTest(\n     self.assertAllEqual(expected_output, output_dataset)\n \n \n+@testing_utils.run_v2_only\n @keras_parameterized.run_all_keras_modes(always_skip_v1=True)\n class TextVectorizationOutputTest(\n     keras_parameterized.TestCase,\n@@ -1445,6 +1449,7 @@ class TextVectorizationOutputTest(\n     _ = layer(input_array)\n \n \n+@testing_utils.run_v2_only\n @keras_parameterized.run_all_keras_modes(always_skip_v1=True)\n class TextVectorizationModelBuildingTest(\n     keras_parameterized.TestCase,\n@@ -1529,6 +1534,7 @@ class TextVectorizationModelBuildingTest(\n     _ = model.predict(input_array)\n \n \n+@testing_utils.run_v2_only\n @keras_parameterized.run_all_keras_modes(always_skip_v1=True)\n class TextVectorizationVocbularyTest(\n     keras_parameterized.TestCase,\n@@ -1559,6 +1565,7 @@ class TextVectorizationVocbularyTest(\n         [\"earth\", \"wind\", \"and\", \"fire\"])\n \n \n+@testing_utils.run_v2_only\n @keras_parameterized.run_all_keras_modes(always_skip_v1=True)\n class TextVectorizationErrorTest(keras_parameterized.TestCase,\n                                  preprocessing_test_utils.PreprocessingLayerTest\n@@ -1688,6 +1695,7 @@ def custom_split_fn(x):\n   return tf.strings.split(x, sep=\">\")\n \n \n+@testing_utils.run_v2_only\n @keras_parameterized.run_all_keras_modes(always_skip_v1=True)\n class TextVectorizationSavingTest(\n     keras_parameterized.TestCase,\n@@ -1870,6 +1878,7 @@ class TextVectorizationSavingTest(\n     self.assertAllEqual(expected_output, new_output_dataset)\n \n \n+@testing_utils.run_v2_only\n @keras_parameterized.run_all_keras_modes(always_skip_v1=True)\n class TextVectorizationE2ETest(keras_parameterized.TestCase,\n                                preprocessing_test_utils.PreprocessingLayerTest):\n@@ -1905,6 +1914,4 @@ class TextVectorizationE2ETest(keras_parameterized.TestCase,\n \n \n if __name__ == \"__main__\":\n-  # TextVectorization is only exported as a TF2 API.\n-  tf.compat.v1.enable_v2_behavior()\n   tf.test.main()\n\n@@ -21,6 +21,7 @@ import numpy as np\n from keras import keras_parameterized\n from keras import layers\n from keras import models\n+from keras import testing_utils\n from keras.layers import advanced_activations\n from keras.layers import attention\n from keras.layers import convolutional\n@@ -61,6 +62,7 @@ def _create_normalization_layer_without_adapt():\n   )\n \n \n+@testing_utils.run_v2_only\n class LayerCorrectnessTest(keras_parameterized.TestCase):\n \n   def setUp(self):\n@@ -261,5 +263,4 @@ class LayerCorrectnessTest(keras_parameterized.TestCase):\n \n \n if __name__ == '__main__':\n-  tf.compat.v1.enable_v2_behavior()\n   tf.test.main()\n\n@@ -21,6 +21,7 @@ import shutil\n \n import numpy as np\n from keras import keras_parameterized\n+from keras import testing_utils\n from keras.preprocessing import image as image_preproc\n from keras.preprocessing import image_dataset\n \n@@ -30,6 +31,7 @@ except ImportError:\n   PIL = None\n \n \n+@testing_utils.run_v2_only\n class ImageDatasetFromDirectoryTest(keras_parameterized.TestCase):\n \n   def _get_images(self, count=16, color_mode='rgb'):\n@@ -361,5 +363,4 @@ class ImageDatasetFromDirectoryTest(keras_parameterized.TestCase):\n     self.assertEqual(len(sample.shape), 3)\n \n if __name__ == '__main__':\n-  tf.compat.v1.enable_v2_behavior()\n   tf.test.main()\n\n@@ -24,6 +24,7 @@ from absl.testing import parameterized\n import numpy as np\n from keras import keras_parameterized\n from keras import layers\n+from keras import testing_utils\n from keras.engine import sequential\n from keras.preprocessing import image as preprocessing_image\n \n@@ -51,6 +52,7 @@ def _generate_test_images():\n   return [rgb_images, gray_images]\n \n \n+@testing_utils.run_v2_only\n class TestImage(keras_parameterized.TestCase):\n \n   def test_smart_resize(self):\n@@ -443,5 +445,4 @@ class TestImage(keras_parameterized.TestCase):\n \n \n if __name__ == '__main__':\n-  tf.compat.v1.enable_v2_behavior()\n   tf.test.main()\n\n@@ -21,9 +21,11 @@ import random\n import shutil\n import string\n from keras import keras_parameterized\n+from keras import testing_utils\n from keras.preprocessing import text_dataset\n \n \n+@testing_utils.run_v2_only\n class TextDatasetFromDirectoryTest(keras_parameterized.TestCase):\n \n   def _prepare_directory(self,\n@@ -258,5 +260,4 @@ class TextDatasetFromDirectoryTest(keras_parameterized.TestCase):\n \n \n if __name__ == '__main__':\n-  tf.compat.v1.enable_v2_behavior()\n   tf.test.main()\n\n@@ -17,9 +17,11 @@\n import tensorflow.compat.v2 as tf\n \n import numpy as np\n+from keras import testing_utils\n from keras.preprocessing import timeseries\n \n \n+@testing_utils.run_v2_only\n class TimeseriesDatasetTest(tf.test.TestCase):\n \n   def test_basics(self):\n@@ -183,5 +185,4 @@ class TimeseriesDatasetTest(tf.test.TestCase):\n     self.assertEqual(len(sample.shape), 1)\n \n if __name__ == '__main__':\n-  tf.compat.v1.enable_v2_behavior()\n   tf.test.main()\n\n@@ -20,6 +20,7 @@ import contextlib\n import functools\n import itertools\n import threading\n+import unittest\n from keras import backend\n from keras import layers\n from keras import models\n@@ -1009,7 +1010,7 @@ def run_all_without_tensor_float_32(description):  # pylint: disable=unused-argu\n   return for_all_test_methods(run_without_tensor_float_32, description)\n \n \n-def run_v2_only(func=None):\n+def run_v2_only(obj=None):\n   \"\"\"Execute the decorated test only if running in v2 mode.\n \n   This function is intended to be applied to tests that exercise v2 only\n@@ -1019,28 +1020,28 @@ def run_v2_only(func=None):\n   v1/v2/eager/graph combinations.\n \n   Args:\n-    func: function to be annotated. If `func` is None, this method returns a\n-      decorator the can be applied to a function. If `func` is not None this\n-      returns the decorator applied to `func`.\n+    obj: function to be annotated. If None, return a\n+      decorator the can be applied to a function or class. If `obj` is not None,\n+      return the decorator applied to `obj`.\n \n   Returns:\n     Returns a decorator that will conditionally skip the decorated test method.\n   \"\"\"\n+  condition = not tf.__internal__.tf2.enabled()\n+  reason = 'Test is only compatible with TF v2.'\n \n   def decorator(f):\n     if tf_inspect.isclass(f):\n-      raise ValueError('`run_v2_only` only supports test methods.')\n+      return unittest.skipIf(condition=condition, reason=reason)(obj)\n \n     def decorated(self, *args, **kwargs):\n-      if not tf.__internal__.tf2.enabled():\n-        self.skipTest('Test is only compatible with v2')\n-\n+      if condition:\n+        self.skipTest(reason)\n       return f(self, *args, **kwargs)\n-\n     return decorated\n \n-  if func is not None:\n-    return decorator(func)\n+  if obj is not None:\n+    return decorator(obj)\n \n   return decorator\n \n\n@@ -19,6 +19,7 @@ import os\n \n from absl import flags\n from keras import callbacks\n+from keras import testing_utils\n from keras.distribute import distribute_strategy_test\n from keras.engine import base_layer\n from keras.engine import sequential as sequential_model_lib\n@@ -153,11 +154,11 @@ def mnist_model(input_shape, enable_histograms=True):\n   return model\n \n \n+@testing_utils.run_v2_only\n class AutoOutsideCompilationWithKerasTest(tf.test.TestCase):\n \n   def setUp(self):\n     super(AutoOutsideCompilationWithKerasTest, self).setUp()\n-    tf.compat.v1.enable_v2_behavior()\n     set_soft_device_placement(True)\n     self.summary_dir = self.get_temp_dir()\n \n@@ -286,5 +287,4 @@ class AutoOutsideCompilationWithKerasTest(tf.test.TestCase):\n \n \n if __name__ == '__main__':\n-  tf.compat.v1.enable_eager_execution()\n   tf.test.main()\n\n@@ -19,6 +19,7 @@ import tensorflow.compat.v2 as tf\n from absl.testing import parameterized\n from tensorflow.python.distribute.cluster_resolver import SimpleClusterResolver\n from keras import combinations\n+from keras import testing_utils\n from keras.distribute import multi_worker_testing_utils\n from keras.engine import data_adapter\n from keras.engine import sequential\n@@ -28,6 +29,7 @@ from keras.utils import dataset_creator\n from tensorflow.python.training.server_lib import ClusterSpec\n \n \n+@testing_utils.run_v2_only\n class DatasetCreatorTest(tf.test.TestCase, parameterized.TestCase):\n \n   def test_dataset_creator(self):\n@@ -139,5 +141,4 @@ class DatasetCreatorTest(tf.test.TestCase, parameterized.TestCase):\n \n \n if __name__ == \"__main__\":\n-  tf.compat.v1.enable_v2_behavior()\n   tf.test.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
