{"custom_id": "keras#b261385bb7212dfe33aeaeebe80b4bd209a36cbf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 4 | Methods Changed: 0 | Complexity Δ (Sum/Max): 12/12 | Churn Δ: 12 | Churn Cumulative: 173 | Contributors (this commit): 1 | Commits (past 90d): 7 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -1,3 +1,9 @@\n+# flake8: noqa\n+import os\n+\n+# Set backend env to torch\n+os.environ[\"KERAS_BACKEND\"] = \"torch\"\n+\n import torch\n import torch.nn as nn\n import torch.optim as optim\n@@ -5,6 +11,7 @@ from keras_core import layers\n import keras_core\n import numpy as np\n \n+\n # Model / data parameters\n num_classes = 10\n input_shape = (28, 28, 1)\n\n@@ -1,4 +1,9 @@\n+# flake8: noqa\n import os\n+\n+# Set backend env to torch\n+os.environ[\"KERAS_BACKEND\"] = \"torch\"\n+\n import torch\n import torch.nn as nn\n import torch.optim as optim\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c537a9914b2feb912f9556212d72a57d012fa764", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 16 | Methods Changed: 9 | Complexity Δ (Sum/Max): 16/16 | Churn Δ: 22 | Churn Cumulative: 100 | Contributors (this commit): 2 | Commits (past 90d): 10 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -98,51 +98,61 @@ class Tracker:\n \n class TrackedList(list):\n     # TODO: override item removal methods?\n-    def __init__(self, values, tracker):\n+    def __init__(self, values=None, tracker=None):\n         self.tracker = tracker\n+        if tracker and values:\n             values = [tracker.track(v) for v in values]\n-        super().__init__(values)\n+        super().__init__(values or [])\n \n     def append(self, value):\n+        if self.tracker:\n             self.tracker.track(value)\n         super().append(value)\n \n     def insert(self, value):\n+        if self.tracker:\n             self.tracker.track(value)\n         super().insert(value)\n \n     def extend(self, values):\n+        if self.tracker:\n             values = [self.tracker.track(v) for v in values]\n         super().extend(values)\n \n \n class TrackedDict(dict):\n     # TODO: override item removal methods?\n-    def __init__(self, values, tracker):\n+    def __init__(self, values=None, tracker=None):\n         self.tracker = tracker\n+        if tracker and values:\n             values = {k: tracker.track(v) for k, v in values.items()}\n-        super().__init__(values)\n+        super().__init__(values or [])\n \n     def __setitem__(self, key, value):\n+        if self.tracker:\n             self.tracker.track(value)\n         super().__setitem__(key, value)\n \n     def update(self, mapping):\n+        if self.tracker:\n             mapping = {k: self.tracker.track(v) for k, v in mapping.items()}\n         super().update(mapping)\n \n \n class TrackedSet(set):\n     # TODO: override item removal methods?\n-    def __init__(self, values, tracker):\n+    def __init__(self, values=None, tracker=None):\n         self.tracker = tracker\n+        if tracker and values:\n             values = {tracker.track(v) for v in values}\n-        super().__init__(values)\n+        super().__init__(values or [])\n \n     def add(self, value):\n+        if self.tracker:\n             self.tracker.track(value)\n         super().add(value)\n \n     def update(self, values):\n+        if self.tracker:\n             values = [self.tracker.track(v) for v in values]\n         super().update(values)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e71c5de460647cf68c80322daefd5fb709d9f676", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 92 | Lines Deleted: 101 | Files Changed: 8 | Hunks: 39 | Methods Changed: 23 | Complexity Δ (Sum/Max): 6/9 | Churn Δ: 193 | Churn Cumulative: 2428 | Contributors (this commit): 2 | Commits (past 90d): 46 | Contributors (cumulative): 10 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,10 +1,13 @@\n-from keras_core import operations as ops\n+import tensorflow as tf\n+\n+from keras_core import backend\n from keras_core.api_export import keras_core_export\n-from keras_core.layers.preprocessing.tf_data_layer import TFDataLayer\n+from keras_core.layers.layer import Layer\n+from keras_core.utils import backend_utils\n \n \n @keras_core_export(\"keras_core.layers.CategoryEncoding\")\n-class CategoryEncoding(TFDataLayer):\n+class CategoryEncoding(Layer):\n     \"\"\"A preprocessing layer which encodes integer features.\n \n     This layer provides options for condensing data into a categorical encoding\n@@ -82,12 +85,6 @@ class CategoryEncoding(TFDataLayer):\n     \"\"\"\n \n     def __init__(self, num_tokens=None, output_mode=\"multi_hot\", **kwargs):\n-        # max_tokens is an old name for the num_tokens arg we continue to\n-        # support because of usage.\n-        if \"max_tokens\" in kwargs:\n-            num_tokens = kwargs[\"max_tokens\"]\n-            del kwargs[\"max_tokens\"]\n-\n         super().__init__(**kwargs)\n \n         # Support deprecated names for output_modes.\n@@ -107,18 +104,19 @@ class CategoryEncoding(TFDataLayer):\n             raise ValueError(\n                 f\"`num_tokens` must be >= 1. Received: num_tokens={num_tokens}.\"\n             )\n-\n         self.num_tokens = num_tokens\n         self.output_mode = output_mode\n \n+        self.layer = tf.keras.layers.CategoryEncoding(\n+            num_tokens=num_tokens,\n+            output_mode=output_mode,\n+            **kwargs,\n+        )\n+        self._allow_non_tensor_positional_args = True\n+        self._convert_input_args = False\n+\n     def compute_output_shape(self, input_shape):\n-        input_shape = list(input_shape)\n-        if not input_shape:\n-            return ops.shape(self.num_tokens)\n-        if self.output_mode == \"one_hot\" and input_shape[-1] != 1:\n-            return tuple(input_shape + [self.num_tokens])\n-        else:\n-            return tuple(input_shape[:-1] + [self.num_tokens])\n+        return tuple(self.layer.compute_output_shape(input_shape))\n \n     def get_config(self):\n         config = {\n@@ -128,79 +126,11 @@ class CategoryEncoding(TFDataLayer):\n         base_config = super().get_config()\n         return {**base_config, **config}\n \n-    def call(self, inputs, count_weights=None):\n-        if count_weights is not None:\n-            if self.output_mode != \"count\":\n-                raise ValueError(\n-                    \"`count_weights` is not used when `output_mode` is not \"\n-                    f\"`'count'`. Received `count_weights={count_weights}`.\"\n-                )\n-            count_weights = self.backend.cast(count_weights, self.compute_dtype)\n-\n-        depth = self.num_tokens\n-\n-        max_value = self.backend.numpy.amax(inputs)\n-        min_value = self.backend.numpy.amin(inputs)\n-        condition = self.backend.numpy.logical_and(\n-            self.backend.numpy.greater(\n-                self.backend.cast(depth, max_value.dtype), max_value\n-            ),\n-            self.backend.numpy.greater_equal(\n-                min_value, self.backend.cast(0, min_value.dtype)\n-            ),\n-        )\n-        try:\n-            # Check value range in eager mode only.\n-            condition = bool(condition.__array__())\n-            if not condition:\n-                raise ValueError(\n-                    \"Input values must be in the range 0 <= values < num_tokens\"\n-                    f\" with num_tokens={depth}\"\n-                )\n-        except:\n-            pass\n-\n-        return self._encode_categorical_inputs(\n-            inputs,\n-            output_mode=self.output_mode,\n-            depth=depth,\n-            count_weights=count_weights,\n-        )\n-\n-    def _encode_categorical_inputs(\n-        self,\n-        inputs,\n-        output_mode,\n-        depth,\n-        count_weights=None,\n+    def call(self, inputs):\n+        outputs = self.layer.call(inputs)\n+        if (\n+            backend.backend() != \"tensorflow\"\n+            and not backend_utils.in_tf_graph()\n         ):\n-        # In all cases, we should uprank scalar input to a single sample.\n-        if len(inputs.shape) == 0:\n-            inputs = self.backend.numpy.expand_dims(inputs, -1)\n-        # One hot will uprank only if the final output dimension\n-        # is not already 1.\n-        if output_mode == \"one_hot\":\n-            if len(inputs.shape) > 1 and inputs.shape[-1] != 1:\n-                inputs = self.backend.numpy.expand_dims(inputs, -1)\n-\n-        # TODO(b/190445202): remove output rank restriction.\n-        if len(inputs.shape) > 2:\n-            raise ValueError(\n-                \"When output_mode is not `'int'`, maximum supported \"\n-                f\"output rank is 2. Received output_mode {output_mode} \"\n-                f\"and input shape {inputs.shape}, \"\n-                f\"which would result in output rank {len(inputs.shape)}.\"\n-            )\n-\n-        binary_output = output_mode in (\"multi_hot\", \"one_hot\")\n-        inputs = self.backend.cast(inputs, \"int32\")\n-\n-        if binary_output:\n-            bincounts = self.backend.nn.one_hot(inputs, num_classes=depth)\n-            if output_mode == \"multi_hot\":\n-                bincounts = self.backend.numpy.sum(bincounts, axis=0)\n-        else:\n-            bincounts = self.backend.numpy.bincount(\n-                inputs, minlength=depth, weights=count_weights\n-            )\n-        return bincounts\n+            outputs = backend.convert_to_tensor(outputs)\n+        return outputs\n\n@@ -6,6 +6,8 @@ from keras_core import testing\n \n \n class CategoryEncodingTest(testing.TestCase):\n+    # TODO: test coverage is insufficient.\n+    # Must test > 1 batch size, unbatch cases separately\n     def test_count_output(self):\n         input_array = np.array([[1, 2, 3, 1], [0, 3, 1, 0]])\n         expected_output = np.array([[0, 2, 1, 1, 0, 0], [2, 1, 0, 1, 0, 0]])\n\n@@ -119,9 +119,7 @@ class Discretization(Layer):\n             dtype=dtype,\n             **kwargs,\n         )\n-        self.bin_boundaries = (\n-            bin_boundaries if bin_boundaries is not None else []\n-        )\n+        self.bin_boundaries = bin_boundaries\n         if self.bin_boundaries:\n             self.built = True\n         self._convert_input_args = False\n@@ -184,8 +182,8 @@ class Discretization(Layer):\n     def reset_state(self):\n         self.layer.reset_state()\n \n-    def compute_output_shape(self, input_shape):\n-        return input_shape\n+    def compute_output_spec(self, inputs):\n+        return backend.KerasTensor(shape=inputs.shape, dtype=\"int32\")\n \n     def __call__(self, inputs):\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, backend.KerasTensor)):\n\n@@ -100,7 +100,32 @@ class HashedCrossing(Layer):\n         self.supports_jit = False\n \n     def compute_output_shape(self, input_shape):\n-        return tuple(self.layer.compute_output_shape(input_shape))\n+        if (\n+            not len(input_shape) == 2\n+            or not isinstance(input_shape[0], tuple)\n+            or not isinstance(input_shape[1], tuple)\n+        ):\n+            raise ValueError(\n+                \"Expected as input a list/tuple of 2 tensors. \"\n+                f\"Received input_shape={input_shape}\"\n+            )\n+        if input_shape[0][-1] != input_shape[1][-1]:\n+            raise ValueError(\n+                \"Expected the two input tensors to have identical shapes. \"\n+                f\"Received input_shape={input_shape}\"\n+            )\n+\n+        if not input_shape:\n+            if self.output_mode == \"int\":\n+                return ()\n+            return (self.num_bins,)\n+        if self.output_mode == \"int\":\n+            return input_shape[0]\n+\n+        if self.output_mode == \"one_hot\" and input_shape[0][-1] != 1:\n+            output_shape = tuple(input_shape[0]) + (self.num_bins,)\n+        output_shape = tuple(input_shape[0])[:-1] + (self.num_bins,)\n+        return output_shape\n \n     def call(self, inputs):\n         outputs = self.layer.call(inputs)\n\n@@ -127,7 +127,7 @@ class Hashing(Layer):\n         of shape `(batch_size, ...,)`.\n \n     Output shape:\n-        An `int64` tensor of shape `(batch_size, ...)`.\n+        An `int32` tensor of shape `(batch_size, ...)`.\n \n     Reference:\n \n@@ -186,8 +186,8 @@ class Hashing(Layer):\n             outputs = backend.convert_to_tensor(outputs)\n         return outputs\n \n-    def compute_output_shape(self, input_shape):\n-        return input_shape\n+    def compute_output_spec(self, inputs):\n+        return backend.KerasTensor(shape=inputs.shape, dtype=\"int32\")\n \n     def get_config(self):\n         config = super().get_config()\n\n@@ -453,13 +453,25 @@ class IntegerLookup(Layer):\n         return outputs\n \n     def save_own_variables(self, store):\n+        if hasattr(self.layer, \"save_own_variables\"):\n             self.layer.save_own_variables(store)\n+        else:\n+            self.layer._save_own_variables(store)\n \n     def load_own_variables(self, store):\n+        if hasattr(self.layer, \"load_own_variables\"):\n             self.layer.load_own_variables(store)\n+        else:\n+            self.layer._load_own_variables(store)\n \n     def save_assets(self, dir_path):\n+        if hasattr(self.layer, \"save_assets\"):\n             self.layer.save_assets(dir_path)\n+        else:\n+            self.layer._save_assets(dir_path)\n \n     def load_assets(self, dir_path):\n+        if hasattr(self.layer, \"save_assets\"):\n             self.layer.load_assets(dir_path)\n+        else:\n+            self.layer._load_assets(dir_path)\n\n@@ -447,13 +447,25 @@ class StringLookup(Layer):\n         return outputs\n \n     def save_own_variables(self, store):\n+        if hasattr(self.layer, \"save_own_variables\"):\n             self.layer.save_own_variables(store)\n+        else:\n+            self.layer._save_own_variables(store)\n \n     def load_own_variables(self, store):\n+        if hasattr(self.layer, \"load_own_variables\"):\n             self.layer.load_own_variables(store)\n+        else:\n+            self.layer._load_own_variables(store)\n \n     def save_assets(self, dir_path):\n+        if hasattr(self.layer, \"save_assets\"):\n             self.layer.save_assets(dir_path)\n+        else:\n+            self.layer._save_assets(dir_path)\n \n     def load_assets(self, dir_path):\n+        if hasattr(self.layer, \"save_assets\"):\n             self.layer.load_assets(dir_path)\n+        else:\n+            self.layer._load_assets(dir_path)\n\n@@ -370,13 +370,25 @@ class TextVectorization(Layer):\n         return outputs\n \n     def save_own_variables(self, store):\n+        if hasattr(self.layer, \"save_own_variables\"):\n             self.layer.save_own_variables(store)\n+        else:\n+            self.layer._save_own_variables(store)\n \n     def load_own_variables(self, store):\n+        if hasattr(self.layer, \"load_own_variables\"):\n             self.layer.load_own_variables(store)\n+        else:\n+            self.layer._load_own_variables(store)\n \n     def save_assets(self, dir_path):\n+        if hasattr(self.layer, \"save_assets\"):\n             self.layer.save_assets(dir_path)\n+        else:\n+            self.layer._save_assets(dir_path)\n \n     def load_assets(self, dir_path):\n+        if hasattr(self.layer, \"save_assets\"):\n             self.layer.load_assets(dir_path)\n+        else:\n+            self.layer._load_assets(dir_path)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7180554f65cac8ec3fb7a577ae7d53cda50e65ad", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 491 | Contributors (this commit): 10 | Commits (past 90d): 43 | Contributors (cumulative): 11 | DMM Complexity: 1.0\n\nDIFF:\n@@ -46,6 +46,7 @@ from keras_core.metrics.regression_metrics import MeanSquaredLogarithmicError\n from keras_core.metrics.regression_metrics import R2Score\n from keras_core.metrics.regression_metrics import RootMeanSquaredError\n from keras_core.saving import serialization_lib\n+from keras_core.utils.naming import to_snake_case\n \n ALL_OBJECTS = {\n     # Base\n@@ -102,6 +103,9 @@ ALL_OBJECTS = {\n     OneHotMeanIoU,\n }\n ALL_OBJECTS_DICT = {cls.__name__: cls for cls in ALL_OBJECTS}\n+ALL_OBJECTS_DICT.update(\n+    {to_snake_case(cls.__name__): cls for cls in ALL_OBJECTS}\n+)\n ALL_OBJECTS_DICT.update(\n     {\n         \"mse\": MeanSquaredError,\n\n@@ -112,6 +112,12 @@ class MetricTest(testing.TestCase):\n         metric = metrics_module.get(\"mse\")\n         self.assertTrue(isinstance(metric, metrics_module.MeanSquaredError))\n \n+        metric = metrics_module.get(\"mean_squared_error\")\n+        self.assertTrue(isinstance(metric, metrics_module.MeanSquaredError))\n+\n+        metric = metrics_module.get(\"categorical_accuracy\")\n+        self.assertTrue(isinstance(metric, metrics_module.CategoricalAccuracy))\n+\n         metric = metrics_module.get(None)\n         self.assertEqual(metric, None)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1a9e850af25b4ed4fafeebd8ad76687ed937015d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 399 | Lines Deleted: 16 | Files Changed: 6 | Hunks: 22 | Methods Changed: 13 | Complexity Δ (Sum/Max): 15/15 | Churn Δ: 415 | Churn Cumulative: 1372 | Contributors (this commit): 3 | Commits (past 90d): 16 | Contributors (cumulative): 8 | DMM Complexity: 1.0\n\nDIFF:\n@@ -50,9 +50,11 @@ model = keras_core.Sequential(\n ######## Writing a torch training loop for a Keras model ########\n #################################################################\n \n+\n def get_keras_model():\n     pass\n \n+\n model = get_keras_model()\n \n # Instantiate the torch optimizer\n@@ -61,6 +63,7 @@ optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n # Instantiate the torch loss function\n loss_fn = nn.CrossEntropyLoss()\n \n+\n def train_step(data):\n     x, y = data\n     y_pred = model(x)\n@@ -70,6 +73,7 @@ def train_step(data):\n     optimizer.step()\n     return loss\n \n+\n # Create a TensorDataset\n dataset = torch.utils.data.TensorDataset(\n     torch.from_numpy(x_train), torch.from_numpy(y_train)\n@@ -122,6 +126,7 @@ train(model, train_loader, num_epochs, optimizer, loss_fn)\n ######## Using a Keras model or layer in a torch Module ########\n ################################################################\n \n+\n class MyModel(nn.Module):\n     def __init__(self):\n         super().__init__()\n\n@@ -24,6 +24,7 @@ learning_rate = 0.01\n batch_size = 128\n num_epochs = 1\n \n+\n def get_data():\n     # Load the data and split it between train and test sets\n     (x_train, y_train), (x_test, y_test) = keras_core.datasets.mnist.load_data()\n@@ -44,6 +45,7 @@ def get_data():\n     )\n     return dataset\n \n+\n def get_model():\n     # Create the Keras model\n     model = keras_core.Sequential(\n@@ -108,16 +110,17 @@ def train(model, train_loader, num_epochs, optimizer, loss_fn):\n                 )\n                 running_loss = 0.0\n \n+\n def setup(current_gpu_index, num_gpu):\n     # Device setup\n-    os.environ['MASTER_ADDR'] = 'keras-core-torch'\n-    os.environ['MASTER_PORT'] = '56492'\n+    os.environ[\"MASTER_ADDR\"] = \"keras-core-torch\"\n+    os.environ[\"MASTER_PORT\"] = \"56492\"\n     device = torch.device(\"cuda:{}\".format(current_gpu_index))\n     dist.init_process_group(\n-        backend='nccl',\n-        init_method='env://',\n+        backend=\"nccl\",\n+        init_method=\"env://\",\n         world_size=num_gpu,\n-        rank=current_gpu_index\n+        rank=current_gpu_index,\n     )\n     torch.cuda.set_device(device)\n \n@@ -140,6 +143,7 @@ def prepare(dataset, current_gpu_index, num_gpu, batch_size):\n \n     return train_loader\n \n+\n def cleanup():\n     # Cleanup\n     dist.destroy_process_group()\n@@ -167,7 +171,9 @@ def main(current_gpu_index, num_gpu):\n \n     # Put model on device\n     model = model.to(current_gpu_index)\n-    ddp_model = DDP(model, device_ids=[current_gpu_index], output_device=current_gpu_index)\n+    ddp_model = DDP(\n+        model, device_ids=[current_gpu_index], output_device=current_gpu_index\n+    )\n \n     train(ddp_model, dataloader, num_epochs, optimizer, loss_fn)\n \n@@ -176,7 +182,11 @@ def main(current_gpu_index, num_gpu):\n     ################################################################\n \n     torch_module = MyModel().to(current_gpu_index)\n-    ddp_torch_module = DDP(torch_module, device_ids=[current_gpu_index], output_device=current_gpu_index)\n+    ddp_torch_module = DDP(\n+        torch_module,\n+        device_ids=[current_gpu_index],\n+        output_device=current_gpu_index,\n+    )\n \n     # Instantiate the torch optimizer\n     optimizer = optim.Adam(torch_module.parameters(), lr=learning_rate)\n\n@@ -54,5 +54,9 @@ You can use the trained model hosted on [Hugging Face Hub](https://huggingface.c\n and try the demo on [Hugging Face Spaces](https://huggingface.co/spaces/keras-io/bidirectional_lstm_imdb).\n \"\"\"\n \n-model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n-model.fit(x_train, y_train, batch_size=32, epochs=2, validation_data=(x_val, y_val))\n+model.compile(\n+    optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n+)\n+model.fit(\n+    x_train, y_train, batch_size=32, epochs=2, validation_data=(x_val, y_val)\n+)\n\n@@ -0,0 +1,350 @@\n+\"\"\"\n+Title: Writing Keras Models With TensorFlow NumPy\n+Author: [lukewood](https://lukewood.xyz)\n+Date created: 2021/08/28\n+Last modified: 2021/08/28\n+Description: Overview of how to use the TensorFlow NumPy API to write Keras models.\n+Accelerator: GPU\n+\"\"\"\n+\"\"\"\n+## Introduction\n+\n+[NumPy](https://numpy.org/) is a hugely successful Python linear algebra library.\n+\n+TensorFlow recently launched [tf_numpy](https://www.tensorflow.org/guide/tf_numpy), a\n+TensorFlow implementation of a large subset of the NumPy API.\n+Thanks to `tf_numpy`, you can write Keras layers or models in the NumPy style!\n+\n+The TensorFlow NumPy API has full integration with the TensorFlow ecosystem.\n+Features such as automatic differentiation, TensorBoard, Keras model callbacks,\n+TPU distribution and model exporting are all supported.\n+\n+Let's run through a few examples.\n+\"\"\"\n+\n+\"\"\"\n+## Setup\n+TensorFlow NumPy requires TensorFlow 2.5 or later.\n+\"\"\"\n+\n+import tensorflow as tf\n+import tensorflow.experimental.numpy as tnp\n+import keras_core as keras\n+from keras_core import layers\n+\n+\"\"\"\n+Optionally, you can call `tnp.experimental_enable_numpy_behavior()` to enable type promotion in TensorFlow.\n+This allows TNP to more closely follow the NumPy standard.\n+\"\"\"\n+\n+tnp.experimental_enable_numpy_behavior()\n+\n+\"\"\"\n+To test our models we will use the Boston housing prices regression dataset.\n+\"\"\"\n+\n+(x_train, y_train), (x_test, y_test) = keras.datasets.boston_housing.load_data(\n+    path=\"boston_housing.npz\", test_split=0.2, seed=113\n+)\n+input_dim = x_train.shape[1]\n+\n+\n+def evaluate_model(model: keras.Model):\n+    [loss, percent_error] = model.evaluate(x_test, y_test, verbose=0)\n+    print(\"Mean absolute percent error before training: \", percent_error)\n+    model.fit(x_train, y_train, epochs=200, verbose=0)\n+    [loss, percent_error] = model.evaluate(x_test, y_test, verbose=0)\n+    print(\"Mean absolute percent error after training:\", percent_error)\n+\n+\n+\"\"\"\n+## Subclassing keras.Model with TNP\n+\n+The most flexible way to make use of the Keras API is to subclass the\n+[`keras.Model`](https://keras.io/api/models/model/) class.  Subclassing the Model class\n+gives you the ability to fully customize what occurs in the training loop.  This makes\n+subclassing Model a popular option for researchers.\n+\n+In this example, we will implement a `Model` subclass that performs regression over the\n+boston housing dataset using the TNP API.  Note that differentiation and gradient\n+descent is handled automatically when using the TNP API alongside keras.\n+\n+First let's define a simple `TNPForwardFeedRegressionNetwork` class.\n+\"\"\"\n+\n+\n+class TNPForwardFeedRegressionNetwork(keras.Model):\n+    def __init__(self, blocks=None, **kwargs):\n+        super().__init__(**kwargs)\n+        if not isinstance(blocks, list):\n+            raise ValueError(f\"blocks must be a list, got blocks={blocks}\")\n+        self.blocks = blocks\n+        self.block_weights = None\n+        self.biases = None\n+\n+    def build(self, input_shape):\n+        current_shape = input_shape[1]\n+        self.block_weights = []\n+        self.biases = []\n+        for i, block in enumerate(self.blocks):\n+            self.block_weights.append(\n+                self.add_weight(\n+                    shape=(current_shape, block),\n+                    trainable=True,\n+                    name=f\"block-{i}\",\n+                    initializer=\"glorot_normal\",\n+                )\n+            )\n+            self.biases.append(\n+                self.add_weight(\n+                    shape=(block,),\n+                    trainable=True,\n+                    name=f\"bias-{i}\",\n+                    initializer=\"zeros\",\n+                )\n+            )\n+            current_shape = block\n+\n+        self.linear_layer = self.add_weight(\n+            shape=(current_shape, 1),\n+            name=\"linear_projector\",\n+            trainable=True,\n+            initializer=\"glorot_normal\",\n+        )\n+\n+    def call(self, inputs):\n+        activations = inputs\n+        for w, b in zip(self.block_weights, self.biases):\n+            activations = tnp.matmul(activations, w) + b\n+            # ReLu activation function\n+            activations = tnp.maximum(activations, 0.0)\n+\n+        return tnp.matmul(activations, self.linear_layer)\n+\n+\n+\"\"\"\n+Just like with any other Keras model we can utilize any supported optimizer, loss,\n+metrics or callbacks that we want.\n+\n+Let's see how the model performs!\n+\"\"\"\n+\n+model = TNPForwardFeedRegressionNetwork(blocks=[3, 3])\n+model.compile(\n+    optimizer=\"adam\",\n+    loss=\"mean_squared_error\",\n+    metrics=[keras.metrics.MeanAbsolutePercentageError()],\n+)\n+evaluate_model(model)\n+\n+\"\"\"\n+Great!  Our model seems to be effectively learning to solve the problem at hand.\n+\n+We can also write our own custom loss function using TNP.\n+\"\"\"\n+\n+\n+def tnp_mse(y_true, y_pred):\n+    return tnp.mean(tnp.square(y_true - y_pred), axis=0)\n+\n+\n+keras.backend.clear_session()\n+model = TNPForwardFeedRegressionNetwork(blocks=[3, 3])\n+model.compile(\n+    optimizer=\"adam\",\n+    loss=tnp_mse,\n+    metrics=[keras.metrics.MeanAbsolutePercentageError()],\n+)\n+evaluate_model(model)\n+\n+\"\"\"\n+## Implementing a Keras Layer Based Model with TNP\n+\n+If desired, TNP can also be used in layer oriented Keras code structure.  Let's\n+implement the same model, but using a layered approach!\n+\"\"\"\n+\n+\n+def tnp_relu(x):\n+    return tnp.maximum(x, 0)\n+\n+\n+class TNPDense(keras.layers.Layer):\n+    def __init__(self, units, activation=None):\n+        super().__init__()\n+        self.units = units\n+        self.activation = activation\n+\n+    def build(self, input_shape):\n+        self.w = self.add_weight(\n+            name=\"weights\",\n+            shape=(input_shape[1], self.units),\n+            initializer=\"random_normal\",\n+            trainable=True,\n+        )\n+        self.bias = self.add_weight(\n+            name=\"bias\",\n+            shape=(self.units,),\n+            initializer=\"zeros\",\n+            trainable=True,\n+        )\n+\n+    def call(self, inputs):\n+        outputs = tnp.matmul(inputs, self.w) + self.bias\n+        if self.activation:\n+            return self.activation(outputs)\n+        return outputs\n+\n+\n+def create_layered_tnp_model():\n+    return keras.Sequential(\n+        [\n+            TNPDense(3, activation=tnp_relu),\n+            TNPDense(3, activation=tnp_relu),\n+            TNPDense(1),\n+        ]\n+    )\n+\n+\n+model = create_layered_tnp_model()\n+model.compile(\n+    optimizer=\"adam\",\n+    loss=\"mean_squared_error\",\n+    metrics=[keras.metrics.MeanAbsolutePercentageError()],\n+)\n+model.build((None, input_dim))\n+model.summary()\n+\n+evaluate_model(model)\n+\n+\"\"\"\n+You can also seamlessly switch between TNP layers and native Keras layers!\n+\"\"\"\n+\n+\n+def create_mixed_model():\n+    return keras.Sequential(\n+        [\n+            TNPDense(3, activation=tnp_relu),\n+            # The model will have no issue using a normal Dense layer\n+            layers.Dense(3, activation=\"relu\"),\n+            # ... or switching back to tnp layers!\n+            TNPDense(1),\n+        ]\n+    )\n+\n+\n+model = create_mixed_model()\n+model.compile(\n+    optimizer=\"adam\",\n+    loss=\"mean_squared_error\",\n+    metrics=[keras.metrics.MeanAbsolutePercentageError()],\n+)\n+model.build((None, input_dim))\n+model.summary()\n+\n+evaluate_model(model)\n+\n+\"\"\"\n+The Keras API offers a wide variety of layers.  The ability to use them alongside NumPy\n+code can be a huge time saver in projects.\n+\"\"\"\n+\n+\"\"\"\n+## Distribution Strategy\n+\n+TensorFlow NumPy and Keras integrate with\n+[TensorFlow Distribution Strategies](https://www.tensorflow.org/guide/distributed_training).\n+This makes it simple to perform distributed training across multiple GPUs,\n+or even an entire TPU Pod.\n+\"\"\"\n+\n+gpus = tf.config.list_logical_devices(\"GPU\")\n+if gpus:\n+    strategy = tf.distribute.MirroredStrategy(gpus)\n+else:\n+    # We can fallback to a no-op CPU strategy.\n+    strategy = tf.distribute.get_strategy()\n+print(\"Running with strategy:\", str(strategy.__class__.__name__))\n+\n+with strategy.scope():\n+    model = create_layered_tnp_model()\n+    model.compile(\n+        optimizer=\"adam\",\n+        loss=\"mean_squared_error\",\n+        metrics=[keras.metrics.MeanAbsolutePercentageError()],\n+    )\n+    model.build((None, input_dim))\n+    model.summary()\n+    evaluate_model(model)\n+\n+\"\"\"\n+## TensorBoard Integration\n+\n+One of the many benefits of using the Keras API is the ability to monitor training\n+through TensorBoard.  Using the TensorFlow NumPy API alongside Keras allows you to easily\n+leverage TensorBoard.\n+\"\"\"\n+\n+keras.backend.clear_session()\n+\n+\"\"\"\n+To load the TensorBoard from a Jupyter notebook, you can run the following magic:\n+```\n+%load_ext tensorboard\n+```\n+\n+\"\"\"\n+\n+models = [\n+    (\n+        TNPForwardFeedRegressionNetwork(blocks=[3, 3]),\n+        \"TNPForwardFeedRegressionNetwork\",\n+    ),\n+    (create_layered_tnp_model(), \"layered_tnp_model\"),\n+    (create_mixed_model(), \"mixed_model\"),\n+]\n+for model, model_name in models:\n+    model.compile(\n+        optimizer=\"adam\",\n+        loss=\"mean_squared_error\",\n+        metrics=[keras.metrics.MeanAbsolutePercentageError()],\n+    )\n+    model.fit(\n+        x_train,\n+        y_train,\n+        epochs=200,\n+        verbose=0,\n+        callbacks=[keras.callbacks.TensorBoard(log_dir=f\"logs/{model_name}\")],\n+    )\n+\n+\"\"\"\n+To load the TensorBoard from a Jupyter notebook you can use the `%tensorboard` magic:\n+\n+```\n+%tensorboard --logdir logs\n+```\n+\n+The TensorBoard monitor metrics and examine the training curve.\n+\n+![Tensorboard training graph](https://i.imgur.com/wsOuFnz.png)\n+\n+The TensorBoard also allows you to explore the computation graph used in your models.\n+\n+![Tensorboard graph exploration](https://i.imgur.com/tOrezDL.png)\n+\n+The ability to introspect into your models can be valuable during debugging.\n+\"\"\"\n+\n+\"\"\"\n+## Conclusion\n+\n+Porting existing NumPy code to Keras models using the `tensorflow_numpy` API is easy!\n+By integrating with Keras you gain the ability to use existing Keras callbacks, metrics\n+and optimizers, easily distribute your training and use Tensorboard.\n+\n+Migrating a more complex model, such as a ResNet, to the TensorFlow NumPy API would be a\n+great follow up learning exercise.\n+\n+Several open source NumPy ResNet implementations are available online.\n+\"\"\"\n\n@@ -70,7 +70,9 @@ def show_collage(examples):\n     )\n     for row_idx in range(num_rows):\n         for col_idx in range(num_cols):\n-            array = (np.array(examples[row_idx, col_idx]) * 255).astype(np.uint8)\n+            array = (np.array(examples[row_idx, col_idx]) * 255).astype(\n+                np.uint8\n+            )\n             collage.paste(\n                 Image.fromarray(array), (col_idx * box_size, row_idx * box_size)\n             )\n@@ -127,7 +129,9 @@ class AnchorPositivePairs(keras.utils.PyDataset):\n         return self.num_batchs\n \n     def __getitem__(self, _idx):\n-        x = np.empty((2, num_classes, height_width, height_width, 3), dtype=np.float32)\n+        x = np.empty(\n+            (2, num_classes, height_width, height_width, 3), dtype=np.float32\n+        )\n         for class_idx in range(num_classes):\n             examples_for_class = class_idx_to_train_idxs[class_idx]\n             anchor_idx = random.choice(examples_for_class)\n@@ -206,7 +210,9 @@ this model is intentionally small.\n \"\"\"\n \n inputs = layers.Input(shape=(height_width, height_width, 3))\n-x = layers.Conv2D(filters=32, kernel_size=3, strides=2, activation=\"relu\")(inputs)\n+x = layers.Conv2D(filters=32, kernel_size=3, strides=2, activation=\"relu\")(\n+    inputs\n+)\n x = layers.Conv2D(filters=64, kernel_size=3, strides=2, activation=\"relu\")(x)\n x = layers.Conv2D(filters=128, kernel_size=3, strides=2, activation=\"relu\")(x)\n x = layers.GlobalAveragePooling2D()(x)\n@@ -243,7 +249,9 @@ near_neighbours_per_example = 10\n \n embeddings = model.predict(x_test)\n gram_matrix = np.einsum(\"ae,be->ab\", embeddings, embeddings)\n-near_neighbours = np.argsort(gram_matrix.T)[:, -(near_neighbours_per_example + 1) :]\n+near_neighbours = np.argsort(gram_matrix.T)[\n+    :, -(near_neighbours_per_example + 1) :\n+]\n \n \"\"\"\n As a visual check of these embeddings we can build a collage of the near neighbours for 5\n@@ -308,6 +316,10 @@ labels = [\n     \"Ship\",\n     \"Truck\",\n ]\n-disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix, display_labels=labels)\n-disp.plot(include_values=True, cmap=\"viridis\", ax=None, xticks_rotation=\"vertical\")\n+disp = ConfusionMatrixDisplay(\n+    confusion_matrix=confusion_matrix, display_labels=labels\n+)\n+disp.plot(\n+    include_values=True, cmap=\"viridis\", ax=None, xticks_rotation=\"vertical\"\n+)\n plt.show()\n\n@@ -141,7 +141,9 @@ np.random.RandomState(seed=32).shuffle(negative_images)\n negative_dataset = tf.data.Dataset.from_tensor_slices(negative_images)\n negative_dataset = negative_dataset.shuffle(buffer_size=4096)\n \n-dataset = tf.data.Dataset.zip((anchor_dataset, positive_dataset, negative_dataset))\n+dataset = tf.data.Dataset.zip(\n+    (anchor_dataset, positive_dataset, negative_dataset)\n+)\n dataset = dataset.shuffle(buffer_size=1024)\n dataset = dataset.map(preprocess_triplets)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f235ef65989048bd36fc91a067c7470416b8c4b7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 28 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 8/8 | Churn Δ: 28 | Churn Cumulative: 1133 | Contributors (this commit): 6 | Commits (past 90d): 39 | Contributors (cumulative): 6 | DMM Complexity: 0.09523809523809523\n\nDIFF:\n@@ -1,3 +1,4 @@\n+import platform\n import warnings\n \n from keras_core import backend\n@@ -357,3 +358,30 @@ class Trainer:\n             else:\n                 msg += f\"calling `{method_name}()`.\"\n             raise ValueError(msg)\n+\n+    @property\n+    def supports_jit(self):\n+        if (\n+            platform.system() == \"Darwin\"\n+            and \"arm\" in platform.processor().lower()\n+        ):\n+            if backend.backend() == \"tensorflow\":\n+                import tensorflow as tf\n+\n+                if tf.config.list_physical_devices(\"GPU\"):\n+                    warnings.warn(\n+                        \"XLA (`jit_compile`) is not yet supported \"\n+                        \"on GPU on Apple M1/M2 ARM processors with \"\n+                        \"TensorFlow-Metal. \"\n+                        \"Falling back to `jit_compile=False`.\",\n+                        stacklevel=1,\n+                    )\n+                    return False\n+        if all(x.supports_jit for x in self._flatten_layers()):\n+            return True\n+        return False\n+\n+    @supports_jit.setter\n+    def supports_jit(self, _):\n+        # The property is computed, rather than set.\n+        pass\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d790fccf25a537b15a8bdae9a31f0880e9c6d545", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 14 | Files Changed: 1 | Hunks: 5 | Methods Changed: 4 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 19 | Churn Cumulative: 1152 | Contributors (this commit): 6 | Commits (past 90d): 40 | Contributors (cumulative): 6 | DMM Complexity: 0.6666666666666666\n\nDIFF:\n@@ -43,7 +43,7 @@ class Trainer:\n         else:\n             self._compile_metrics = None\n         if jit_compile == \"auto\":\n-            if all(x.supports_jit for x in self._flatten_layers()):\n+            if model_supports_jit(self):\n                 jit_compile = True\n             else:\n                 jit_compile = False\n@@ -359,12 +359,9 @@ class Trainer:\n                 msg += f\"calling `{method_name}()`.\"\n             raise ValueError(msg)\n \n-    @property\n-    def supports_jit(self):\n-        if (\n-            platform.system() == \"Darwin\"\n-            and \"arm\" in platform.processor().lower()\n-        ):\n+\n+def model_supports_jit(model):\n+    if platform.system() == \"Darwin\" and \"arm\" in platform.processor().lower():\n         if backend.backend() == \"tensorflow\":\n             import tensorflow as tf\n \n@@ -374,14 +371,8 @@ class Trainer:\n                     \"on GPU on Apple M1/M2 ARM processors with \"\n                     \"TensorFlow-Metal. \"\n                     \"Falling back to `jit_compile=False`.\",\n-                        stacklevel=1,\n                 )\n                 return False\n-        if all(x.supports_jit for x in self._flatten_layers()):\n+    if all(x.supports_jit for x in model._flatten_layers()):\n         return True\n     return False\n-\n-    @supports_jit.setter\n-    def supports_jit(self, _):\n-        # The property is computed, rather than set.\n-        pass\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5c4d8d1f446d18512c57f2db92ec415a8599f0b7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 1158 | Contributors (this commit): 6 | Commits (past 90d): 41 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -366,12 +366,6 @@ def model_supports_jit(model):\n             import tensorflow as tf\n \n             if tf.config.list_physical_devices(\"GPU\"):\n-                warnings.warn(\n-                    \"XLA (`jit_compile`) is not yet supported \"\n-                    \"on GPU on Apple M1/M2 ARM processors with \"\n-                    \"TensorFlow-Metal. \"\n-                    \"Falling back to `jit_compile=False`.\",\n-                )\n                 return False\n     if all(x.supports_jit for x in model._flatten_layers()):\n         return True\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0202a5e08baa3c96eb75531c806eeff474d7e2e0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 298 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 298 | Churn Cumulative: 298 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,298 @@\n+\"\"\"\n+Title: Next-Frame Video Prediction with Convolutional LSTMs\n+Author: [Amogh Joshi](https://github.com/amogh7joshi)\n+Date created: 2021/06/02\n+Last modified: 2021/06/05\n+Description: How to build and train a convolutional LSTM model for next-frame video prediction.\n+Accelerator: GPU\n+\"\"\"\n+\n+\"\"\"\n+## Introduction\n+\n+The\n+[Convolutional LSTM](https://papers.nips.cc/paper/2015/file/07563a3fe3bbe7e3ba84431ad9d055af-Paper.pdf)\n+architectures bring together time series processing and computer vision by\n+introducing a convolutional recurrent cell in a LSTM layer. In this example, we will explore the\n+Convolutional LSTM model in an application to next-frame prediction, the process\n+of predicting what video frames come next given a series of past frames.\n+\"\"\"\n+\n+\"\"\"\n+## Setup\n+\"\"\"\n+\n+import numpy as np\n+import matplotlib.pyplot as plt\n+\n+import keras_core as keras\n+from keras_core import layers\n+\n+import io\n+import imageio\n+from IPython.display import Image, display\n+from ipywidgets import widgets, Layout, HBox\n+\n+\"\"\"\n+## Dataset Construction\n+\n+For this example, we will be using the\n+[Moving MNIST](http://www.cs.toronto.edu/~nitish/unsupervised_video/)\n+dataset.\n+\n+We will download the dataset and then construct and\n+preprocess training and validation sets.\n+\n+For next-frame prediction, our model will be using a previous frame,\n+which we'll call `f_n`, to predict a new frame, called `f_(n + 1)`.\n+To allow the model to create these predictions, we'll need to process\n+the data such that we have \"shifted\" inputs and outputs, where the\n+input data is frame `x_n`, being used to predict frame `y_(n + 1)`.\n+\"\"\"\n+\n+# Download and load the dataset.\n+fpath = keras.utils.get_file(\n+    \"moving_mnist.npy\",\n+    \"http://www.cs.toronto.edu/~nitish/unsupervised_video/mnist_test_seq.npy\",\n+)\n+dataset = np.load(fpath)\n+\n+# Swap the axes representing the number of frames and number of data samples.\n+dataset = np.swapaxes(dataset, 0, 1)\n+# We'll pick out 1000 of the 10000 total examples and use those.\n+dataset = dataset[:1000, ...]\n+# Add a channel dimension since the images are grayscale.\n+dataset = np.expand_dims(dataset, axis=-1)\n+\n+# Split into train and validation sets using indexing to optimize memory.\n+indexes = np.arange(dataset.shape[0])\n+np.random.shuffle(indexes)\n+train_index = indexes[: int(0.9 * dataset.shape[0])]\n+val_index = indexes[int(0.9 * dataset.shape[0]) :]\n+train_dataset = dataset[train_index]\n+val_dataset = dataset[val_index]\n+\n+# Normalize the data to the 0-1 range.\n+train_dataset = train_dataset / 255\n+val_dataset = val_dataset / 255\n+\n+\n+# We'll define a helper function to shift the frames, where\n+# `x` is frames 0 to n - 1, and `y` is frames 1 to n.\n+def create_shifted_frames(data):\n+    x = data[:, 0 : data.shape[1] - 1, :, :]\n+    y = data[:, 1 : data.shape[1], :, :]\n+    return x, y\n+\n+\n+# Apply the processing function to the datasets.\n+x_train, y_train = create_shifted_frames(train_dataset)\n+x_val, y_val = create_shifted_frames(val_dataset)\n+\n+# Inspect the dataset.\n+print(\n+    \"Training Dataset Shapes: \" + str(x_train.shape) + \", \" + str(y_train.shape)\n+)\n+print(\n+    \"Validation Dataset Shapes: \" + str(x_val.shape) + \", \" + str(y_val.shape)\n+)\n+\n+\"\"\"\n+## Data Visualization\n+\n+Our data consists of sequences of frames, each of which\n+are used to predict the upcoming frame. Let's take a look\n+at some of these sequential frames.\n+\"\"\"\n+\n+# Construct a figure on which we will visualize the images.\n+fig, axes = plt.subplots(4, 5, figsize=(10, 8))\n+\n+# Plot each of the sequential images for one random data example.\n+data_choice = np.random.choice(range(len(train_dataset)), size=1)[0]\n+for idx, ax in enumerate(axes.flat):\n+    ax.imshow(np.squeeze(train_dataset[data_choice][idx]), cmap=\"gray\")\n+    ax.set_title(f\"Frame {idx + 1}\")\n+    ax.axis(\"off\")\n+\n+# Print information and display the figure.\n+print(f\"Displaying frames for example {data_choice}.\")\n+plt.show()\n+\n+\"\"\"\n+## Model Construction\n+\n+To build a Convolutional LSTM model, we will use the\n+`ConvLSTM2D` layer, which will accept inputs of shape\n+`(batch_size, num_frames, width, height, channels)`, and return\n+a prediction movie of the same shape.\n+\"\"\"\n+\n+# Construct the input layer with no definite frame size.\n+inp = layers.Input(shape=(None, *x_train.shape[2:]))\n+\n+# We will construct 3 `ConvLSTM2D` layers with batch normalization,\n+# followed by a `Conv3D` layer for the spatiotemporal outputs.\n+x = layers.ConvLSTM2D(\n+    filters=64,\n+    kernel_size=(5, 5),\n+    padding=\"same\",\n+    return_sequences=True,\n+    activation=\"relu\",\n+)(inp)\n+x = layers.BatchNormalization()(x)\n+x = layers.ConvLSTM2D(\n+    filters=64,\n+    kernel_size=(3, 3),\n+    padding=\"same\",\n+    return_sequences=True,\n+    activation=\"relu\",\n+)(x)\n+x = layers.BatchNormalization()(x)\n+x = layers.ConvLSTM2D(\n+    filters=64,\n+    kernel_size=(1, 1),\n+    padding=\"same\",\n+    return_sequences=True,\n+    activation=\"relu\",\n+)(x)\n+x = layers.Conv3D(\n+    filters=1, kernel_size=(3, 3, 3), activation=\"sigmoid\", padding=\"same\"\n+)(x)\n+\n+# Next, we will build the complete model and compile it.\n+model = keras.models.Model(inp, x)\n+model.compile(\n+    loss=keras.losses.binary_crossentropy,\n+    optimizer=keras.optimizers.Adam(),\n+)\n+\n+\"\"\"\n+## Model Training\n+\n+With our model and data constructed, we can now train the model.\n+\"\"\"\n+\n+# Define some callbacks to improve training.\n+early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n+reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5)\n+\n+# Define modifiable training hyperparameters.\n+epochs = 20\n+batch_size = 5\n+\n+# Fit the model to the training data.\n+model.fit(\n+    x_train,\n+    y_train,\n+    batch_size=batch_size,\n+    epochs=epochs,\n+    validation_data=(x_val, y_val),\n+    callbacks=[early_stopping, reduce_lr],\n+)\n+\n+\"\"\"\n+## Frame Prediction Visualizations\n+\n+With our model now constructed and trained, we can generate\n+some example frame predictions based on a new video.\n+\n+We'll pick a random example from the validation set and\n+then choose the first ten frames from them. From there, we can\n+allow the model to predict 10 new frames, which we can compare\n+to the ground truth frame predictions.\n+\"\"\"\n+\n+# Select a random example from the validation dataset.\n+example = val_dataset[np.random.choice(range(len(val_dataset)), size=1)[0]]\n+\n+# Pick the first/last ten frames from the example.\n+frames = example[:10, ...]\n+original_frames = example[10:, ...]\n+\n+# Predict a new set of 10 frames.\n+for _ in range(10):\n+    # Extract the model's prediction and post-process it.\n+    new_prediction = model.predict(np.expand_dims(frames, axis=0))\n+    new_prediction = np.squeeze(new_prediction, axis=0)\n+    predicted_frame = np.expand_dims(new_prediction[-1, ...], axis=0)\n+\n+    # Extend the set of prediction frames.\n+    frames = np.concatenate((frames, predicted_frame), axis=0)\n+\n+# Construct a figure for the original and new frames.\n+fig, axes = plt.subplots(2, 10, figsize=(20, 4))\n+\n+# Plot the original frames.\n+for idx, ax in enumerate(axes[0]):\n+    ax.imshow(np.squeeze(original_frames[idx]), cmap=\"gray\")\n+    ax.set_title(f\"Frame {idx + 11}\")\n+    ax.axis(\"off\")\n+\n+# Plot the new frames.\n+new_frames = frames[10:, ...]\n+for idx, ax in enumerate(axes[1]):\n+    ax.imshow(np.squeeze(new_frames[idx]), cmap=\"gray\")\n+    ax.set_title(f\"Frame {idx + 11}\")\n+    ax.axis(\"off\")\n+\n+# Display the figure.\n+plt.show()\n+\n+\"\"\"\n+## Predicted Videos\n+\n+Finally, we'll pick a few examples from the validation set\n+and construct some GIFs with them to see the model's\n+predicted videos.\n+\n+You can use the trained model hosted on [Hugging Face Hub](https://huggingface.co/keras-io/conv-lstm)\n+and try the demo on [Hugging Face Spaces](https://huggingface.co/spaces/keras-io/conv-lstm).\n+\"\"\"\n+\n+# Select a few random examples from the dataset.\n+examples = val_dataset[np.random.choice(range(len(val_dataset)), size=5)]\n+\n+# Iterate over the examples and predict the frames.\n+predicted_videos = []\n+for example in examples:\n+    # Pick the first/last ten frames from the example.\n+    frames = example[:10, ...]\n+    original_frames = example[10:, ...]\n+    new_predictions = np.zeros(shape=(10, *frames[0].shape))\n+\n+    # Predict a new set of 10 frames.\n+    for i in range(10):\n+        # Extract the model's prediction and post-process it.\n+        frames = example[: 10 + i + 1, ...]\n+        new_prediction = model.predict(np.expand_dims(frames, axis=0))\n+        new_prediction = np.squeeze(new_prediction, axis=0)\n+        predicted_frame = np.expand_dims(new_prediction[-1, ...], axis=0)\n+\n+        # Extend the set of prediction frames.\n+        new_predictions[i] = predicted_frame\n+\n+    # Create and save GIFs for each of the ground truth/prediction images.\n+    for frame_set in [original_frames, new_predictions]:\n+        # Construct a GIF from the selected video frames.\n+        current_frames = np.squeeze(frame_set)\n+        current_frames = current_frames[..., np.newaxis] * np.ones(3)\n+        current_frames = (current_frames * 255).astype(np.uint8)\n+        current_frames = list(current_frames)\n+\n+        # Construct a GIF from the frames.\n+        with io.BytesIO() as gif:\n+            imageio.mimsave(gif, current_frames, \"GIF\", duration=200)\n+            predicted_videos.append(gif.getvalue())\n+\n+# Display the videos.\n+print(\" Truth\\tPrediction\")\n+for i in range(0, len(predicted_videos), 2):\n+    # Construct and display an `HBox` with the ground truth and prediction.\n+    box = HBox(\n+        [\n+            widgets.Image(value=predicted_videos[i]),\n+            widgets.Image(value=predicted_videos[i + 1]),\n+        ]\n+    )\n+    display(box)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
