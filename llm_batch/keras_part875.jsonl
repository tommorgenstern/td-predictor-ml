{"custom_id": "keras#2c95bfe4578f0470fbc72e8fb06190b52280fa01", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 206 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -183,9 +183,7 @@ class RandomShearTest(testing.TestCase):\n         )\n \n         transformation = {\n-            \"shear_factor\": backend_utils.convert_tf_tensor(\n-                np.array(translation)\n-            ),\n+            \"shear_factor\": np.array(translation),\n             \"input_shape\": image_shape,\n         }\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a91d0067149dc08741aace2cabe9b828a5cbc60d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 48 | Contributors (this commit): 4 | Commits (past 90d): 2 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -37,6 +37,7 @@ class BackupAndRestore(Callback):\n     >>> callback = keras.callbacks.BackupAndRestore(backup_dir=\"/tmp/backup\")\n     >>> model = keras.models.Sequential([keras.layers.Dense(10)])\n     >>> model.compile(keras.optimizers.SGD(), loss='mse')\n+    >>> model.build(input_shape=(None, 20))\n     >>> try:\n     ...   model.fit(np.arange(100).reshape(5, 20), np.zeros(5), epochs=10,\n     ...             batch_size=1, callbacks=[callback, InterruptingCallback()],\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#41c429e3f1ab98fda6244974effcf314e372e3e3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 22 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -1,7 +1,7 @@\n from keras.src.api_export import keras_export\n \n # Unique source of truth for the version number.\n-__version__ = \"3.7.0\"\n+__version__ = \"3.8.0\"\n \n \n @keras_export(\"keras.version\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#881d8dae1c07c05e0b08b24e30424a4d7d5b50f9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 209 | Lines Deleted: 43 | Files Changed: 3 | Hunks: 9 | Methods Changed: 8 | Complexity Δ (Sum/Max): 28/27 | Churn Δ: 252 | Churn Cumulative: 636 | Contributors (this commit): 1 | Commits (past 90d): 5 | Contributors (cumulative): 3 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1,12 +1,11 @@\n-import pathlib\n-import tempfile\n-\n from keras.src import backend\n from keras.src import tree\n from keras.src.export.export_utils import convert_spec_to_tensor\n from keras.src.export.export_utils import get_input_signature\n-from keras.src.export.saved_model import export_saved_model\n-from keras.src.utils.module_utils import tensorflow as tf\n+from keras.src.export.export_utils import make_tf_tensor_spec\n+from keras.src.export.saved_model import DEFAULT_ENDPOINT_NAME\n+from keras.src.export.saved_model import ExportArchive\n+from keras.src.export.tf2onnx_lib import patch_tf2onnx\n \n \n def export_onnx(model, filepath, verbose=True, input_signature=None, **kwargs):\n@@ -65,18 +64,18 @@ def export_onnx(model, filepath, verbose=True, input_signature=None, **kwargs):\n             )\n \n     if backend.backend() in (\"tensorflow\", \"jax\"):\n-        working_dir = pathlib.Path(filepath).parent\n-        with tempfile.TemporaryDirectory(dir=working_dir) as temp_dir:\n-            if backend.backend() == \"jax\":\n-                kwargs = _check_jax_kwargs(kwargs)\n-            export_saved_model(\n-                model,\n-                temp_dir,\n-                verbose,\n-                input_signature,\n-                **kwargs,\n+        from keras.src.utils.module_utils import tf2onnx\n+\n+        input_signature = tree.map_structure(\n+            make_tf_tensor_spec, input_signature\n+        )\n+        decorated_fn = get_concrete_fn(model, input_signature, **kwargs)\n+\n+        # Use `tf2onnx` to convert the `decorated_fn` to the ONNX format.\n+        patch_tf2onnx()  # TODO: Remove this once `tf2onnx` supports numpy 2.\n+        tf2onnx.convert.from_function(\n+            decorated_fn, input_signature, output_path=filepath\n         )\n-            saved_model_to_onnx(temp_dir, filepath, model.name)\n \n     elif backend.backend() == \"torch\":\n         import torch\n@@ -133,30 +132,14 @@ def _check_jax_kwargs(kwargs):\n     return kwargs\n \n \n-def saved_model_to_onnx(saved_model_dir, filepath, name):\n-    from keras.src.utils.module_utils import tf2onnx\n-\n-    # Convert to ONNX using `tf2onnx` library.\n-    (graph_def, inputs, outputs, initialized_tables, tensors_to_rename) = (\n-        tf2onnx.tf_loader.from_saved_model(\n-            saved_model_dir,\n-            None,\n-            None,\n-            return_initialized_tables=True,\n-            return_tensors_to_rename=True,\n-        )\n-    )\n-\n-    with tf.device(\"/cpu:0\"):\n-        _ = tf2onnx.convert._convert_common(\n-            graph_def,\n-            name=name,\n-            target=[],\n-            custom_op_handlers={},\n-            extra_opset=[],\n-            input_names=inputs,\n-            output_names=outputs,\n-            tensors_to_rename=tensors_to_rename,\n-            initialized_tables=initialized_tables,\n-            output_path=filepath,\n+def get_concrete_fn(model, input_signature, **kwargs):\n+    \"\"\"Get the `tf.function` associated with the model.\"\"\"\n+    if backend.backend() == \"jax\":\n+        kwargs = _check_jax_kwargs(kwargs)\n+    export_archive = ExportArchive()\n+    export_archive.track_and_add_endpoint(\n+        DEFAULT_ENDPOINT_NAME, model, input_signature, **kwargs\n     )\n+    if backend.backend() == \"tensorflow\":\n+        export_archive._filter_and_track_resources()\n+    return export_archive._get_concrete_fn(DEFAULT_ENDPOINT_NAME)\n\n@@ -35,6 +35,9 @@ else:\n     )\n \n \n+DEFAULT_ENDPOINT_NAME = \"serve\"\n+\n+\n @keras_export(\"keras.export.ExportArchive\")\n class ExportArchive(BackendExportArchive):\n     \"\"\"ExportArchive is used to write SavedModel artifacts (e.g. for inference).\n@@ -623,7 +626,7 @@ def export_saved_model(\n         input_signature = get_input_signature(model)\n \n     export_archive.track_and_add_endpoint(\n-        \"serve\", model, input_signature, **kwargs\n+        DEFAULT_ENDPOINT_NAME, model, input_signature, **kwargs\n     )\n     export_archive.write_out(filepath, verbose=verbose)\n \n\n@@ -0,0 +1,180 @@\n+import copy\n+import functools\n+import logging\n+import traceback\n+\n+import numpy as np\n+\n+\n+@functools.lru_cache()\n+def patch_tf2onnx():\n+    \"\"\"Patches `tf2onnx` to ensure compatibility with numpy>=2.0.0.\"\"\"\n+\n+    from onnx import AttributeProto\n+    from onnx import TensorProto\n+\n+    from keras.src.utils.module_utils import tf2onnx\n+\n+    logger = logging.getLogger(tf2onnx.__name__)\n+\n+    def patched_rewrite_constant_fold(g, ops):\n+        \"\"\"\n+        We call tensorflow transform with constant folding but in some cases\n+        tensorflow does fold all constants. Since there are a bunch of ops in\n+        onnx that use attributes where tensorflow has dynamic inputs, we badly\n+        want constant folding to work. For cases where tensorflow missed\n+        something, make another pass over the graph and fix want we care about.\n+        \"\"\"\n+        func_map = {\n+            \"Add\": np.add,\n+            \"GreaterEqual\": np.greater_equal,\n+            \"Cast\": np.asarray,\n+            \"ConcatV2\": np.concatenate,\n+            \"Less\": np.less,\n+            \"ListDiff\": np.setdiff1d,\n+            \"Mul\": np.multiply,\n+            \"Pack\": np.stack,\n+            \"Range\": np.arange,\n+            \"Sqrt\": np.sqrt,\n+            \"Sub\": np.subtract,\n+        }\n+        ops = list(ops)\n+\n+        keep_looking = True\n+        while keep_looking:\n+            keep_looking = False\n+            for idx, op in enumerate(ops):\n+                func = func_map.get(op.type)\n+                if func is None:\n+                    continue\n+                if set(op.output) & set(g.outputs):\n+                    continue\n+                try:\n+                    inputs = []\n+                    for node in op.inputs:\n+                        if not node.is_const():\n+                            break\n+                        inputs.append(node.get_tensor_value(as_list=False))\n+\n+                    logger.debug(\n+                        \"op name %s, %s, %s\",\n+                        op.name,\n+                        len(op.input),\n+                        len(inputs),\n+                    )\n+                    if inputs and len(op.input) == len(inputs):\n+                        logger.info(\n+                            \"folding node type=%s, name=%s\" % (op.type, op.name)\n+                        )\n+                        if op.type == \"Cast\":\n+                            dst = op.get_attr_int(\"to\")\n+                            np_type = tf2onnx.utils.map_onnx_to_numpy_type(dst)\n+                            val = np.asarray(*inputs, dtype=np_type)\n+                        elif op.type == \"ConcatV2\":\n+                            axis = inputs[-1]\n+                            values = inputs[:-1]\n+                            val = func(tuple(values), axis)\n+                        elif op.type == \"ListDiff\":\n+                            out_type = op.get_attr_int(\"out_idx\")\n+                            np_type = tf2onnx.utils.map_onnx_to_numpy_type(\n+                                out_type\n+                            )\n+                            val = func(*inputs)\n+                            val = val.astype(np_type)\n+                        elif op.type in [\"Pack\"]:\n+                            # handle ops that need input array and axis\n+                            axis = op.get_attr_int(\"axis\")\n+                            val = func(inputs, axis=axis)\n+                        elif op.type == \"Range\":\n+                            dtype = op.get_attr_int(\"Tidx\")\n+                            np_type = tf2onnx.utils.map_onnx_to_numpy_type(\n+                                dtype\n+                            )\n+                            val = func(*inputs, dtype=np_type)\n+                        else:\n+                            val = func(*inputs)\n+\n+                        new_node_name = tf2onnx.utils.make_name(op.name)\n+                        new_output_name = new_node_name\n+                        old_output_name = op.output[0]\n+                        old_node_name = op.name\n+                        logger.debug(\n+                            \"create const node [%s] replacing [%s]\",\n+                            new_node_name,\n+                            old_node_name,\n+                        )\n+                        ops[idx] = g.make_const(new_node_name, val)\n+\n+                        logger.debug(\n+                            \"replace old output [%s] with new output [%s]\",\n+                            old_output_name,\n+                            new_output_name,\n+                        )\n+                        # need to re-write the consumers input name to use the\n+                        # const name\n+                        consumers = g.find_output_consumers(old_output_name)\n+                        if consumers:\n+                            for consumer in consumers:\n+                                g.replace_input(\n+                                    consumer, old_output_name, new_output_name\n+                                )\n+\n+                        # keep looking until there is nothing we can fold.\n+                        # We keep the graph in topological order so if we\n+                        # folded, the result might help a following op.\n+                        keep_looking = True\n+                except Exception as ex:\n+                    tb = traceback.format_exc()\n+                    logger.info(\"exception: %s, details: %s\", ex, tb)\n+                    # ignore errors\n+\n+        return ops\n+\n+    def patched_get_value_attr(self, external_tensor_storage=None):\n+        \"\"\"\n+        Return onnx attr for value property of node.\n+        Attr is modified to point to external tensor data stored in\n+        external_tensor_storage, if included.\n+        \"\"\"\n+        a = self._attr[\"value\"]\n+        if (\n+            external_tensor_storage is not None\n+            and self in external_tensor_storage.node_to_modified_value_attr\n+        ):\n+            return external_tensor_storage.node_to_modified_value_attr[self]\n+        if external_tensor_storage is None or a.type != AttributeProto.TENSOR:\n+            return a\n+\n+        def prod(x):\n+            if hasattr(np, \"product\"):\n+                return np.product(x)\n+            else:\n+                return np.prod(x)\n+\n+        if (\n+            prod(a.t.dims)\n+            > external_tensor_storage.external_tensor_size_threshold\n+        ):\n+            a = copy.deepcopy(a)\n+            tensor_name = (\n+                self.name.strip()\n+                + \"_\"\n+                + str(external_tensor_storage.name_counter)\n+            )\n+            for c in '~\"#%&*:<>?/\\\\{|}':\n+                tensor_name = tensor_name.replace(c, \"_\")\n+            external_tensor_storage.name_counter += 1\n+            external_tensor_storage.name_to_tensor_data[tensor_name] = (\n+                a.t.raw_data\n+            )\n+            external_tensor_storage.node_to_modified_value_attr[self] = a\n+            a.t.raw_data = b\"\"\n+            a.t.ClearField(\"raw_data\")\n+            location = a.t.external_data.add()\n+            location.key = \"location\"\n+            location.value = tensor_name\n+            a.t.data_location = TensorProto.EXTERNAL\n+        return a\n+\n+    tf2onnx.tfonnx.rewrite_constant_fold = patched_rewrite_constant_fold\n+    tf2onnx.graph.Node.get_value_attr = patched_get_value_attr\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1adaaec659523bd5d3d4a84904b09aa81a4fa913", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 5/5 | Churn Δ: 13 | Churn Cumulative: 210 | Contributors (this commit): 1 | Commits (past 90d): 2 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -112,6 +112,19 @@ class RandomColorJitter(BaseImagePreprocessingLayer):\n                 seed=self.seed,\n             )\n \n+    def build(self, input_shape):\n+        if self.brightness_factor is not None:\n+            self.random_brightness.build(input_shape)\n+\n+        if self.contrast_factor is not None:\n+            self.random_contrast.build(input_shape)\n+\n+        if self.saturation_factor is not None:\n+            self.random_saturation.build(input_shape)\n+\n+        if self.hue_factor is not None:\n+            self.random_hue.build(input_shape)\n+\n     def transform_images(self, images, transformation, training=True):\n         if training:\n             if backend_utils.in_tf_graph():\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8f0461690d9a885ffae5e0a7117aff460ab27ab7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 346 | Contributors (this commit): 8 | Commits (past 90d): 3 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -888,7 +888,7 @@ def istft(\n         sequence_length: An integer representing the sequence length.\n         sequence_stride: An integer representing the sequence hop size.\n         fft_length: An integer representing the size of the FFT that produced\n-            `stft`.\n+            `stft`. Should be of type `int32`.\n         length: An integer representing the output is clipped to exactly length.\n             If not specified, no padding or clipping take place. Defaults to\n             `None`.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ab3c8f5fff12d4a7c27c8ea2754c7e6c0920210e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 361 | Lines Deleted: 4 | Files Changed: 7 | Hunks: 10 | Methods Changed: 18 | Complexity Δ (Sum/Max): 31/18 | Churn Δ: 365 | Churn Cumulative: 1545 | Contributors (this commit): 7 | Commits (past 90d): 46 | Contributors (cumulative): 28 | DMM Complexity: 1.0\n\nDIFF:\n@@ -152,6 +152,9 @@ from keras.src.layers.preprocessing.image_preprocessing.max_num_bounding_box imp\n     MaxNumBoundingBoxes,\n )\n from keras.src.layers.preprocessing.image_preprocessing.mix_up import MixUp\n+from keras.src.layers.preprocessing.image_preprocessing.rand_augment import (\n+    RandAugment,\n+)\n from keras.src.layers.preprocessing.image_preprocessing.random_brightness import (\n     RandomBrightness,\n )\n\n@@ -152,6 +152,9 @@ from keras.src.layers.preprocessing.image_preprocessing.max_num_bounding_box imp\n     MaxNumBoundingBoxes,\n )\n from keras.src.layers.preprocessing.image_preprocessing.mix_up import MixUp\n+from keras.src.layers.preprocessing.image_preprocessing.rand_augment import (\n+    RandAugment,\n+)\n from keras.src.layers.preprocessing.image_preprocessing.random_brightness import (\n     RandomBrightness,\n )\n\n@@ -96,6 +96,9 @@ from keras.src.layers.preprocessing.image_preprocessing.max_num_bounding_box imp\n     MaxNumBoundingBoxes,\n )\n from keras.src.layers.preprocessing.image_preprocessing.mix_up import MixUp\n+from keras.src.layers.preprocessing.image_preprocessing.rand_augment import (\n+    RandAugment,\n+)\n from keras.src.layers.preprocessing.image_preprocessing.random_brightness import (\n     RandomBrightness,\n )\n\n@@ -0,0 +1,235 @@\n+import random\n+\n+import keras.src.layers as layers\n+from keras.src.api_export import keras_export\n+from keras.src.layers.preprocessing.image_preprocessing.base_image_preprocessing_layer import (  # noqa: E501\n+    BaseImagePreprocessingLayer,\n+)\n+from keras.src.random import SeedGenerator\n+from keras.src.utils import backend_utils\n+\n+\n+@keras_export(\"keras.layers.RandAugment\")\n+class RandAugment(BaseImagePreprocessingLayer):\n+    \"\"\"RandAugment performs the Rand Augment operation on input images.\n+\n+    This layer can be thought of as an all-in-one image augmentation layer. The\n+    policy implemented by this layer has been benchmarked extensively and is\n+    effective on a wide variety of datasets.\n+\n+    References:\n+        - [RandAugment](https://arxiv.org/abs/1909.13719)\n+\n+    Args:\n+        value_range: The range of values the input image can take.\n+            Default is `(0, 255)`. Typically, this would be `(0, 1)`\n+            for normalized images or `(0, 255)` for raw images.\n+        num_ops: The number of augmentation operations to apply sequentially\n+            to each image. Default is 2.\n+        factor: The strength of the augmentation as a normalized value\n+            between 0 and 1. Default is 0.5.\n+        interpolation: The interpolation method to use for resizing operations.\n+            Options include `nearest`, `bilinear`. Default is `bilinear`.\n+        seed: Integer. Used to create a random seed.\n+\n+    \"\"\"\n+\n+    _USE_BASE_FACTOR = False\n+    _FACTOR_BOUNDS = (0, 1)\n+\n+    _AUGMENT_LAYERS = [\n+        \"random_shear\",\n+        \"random_translation\",\n+        \"random_rotation\",\n+        \"random_brightness\",\n+        \"random_color_degeneration\",\n+        \"random_contrast\",\n+        \"random_sharpness\",\n+        \"random_posterization\",\n+        \"solarization\",\n+        \"auto_contrast\",\n+        \"equalization\",\n+    ]\n+\n+    def __init__(\n+        self,\n+        value_range=(0, 255),\n+        num_ops=2,\n+        factor=0.5,\n+        interpolation=\"bilinear\",\n+        seed=None,\n+        data_format=None,\n+        **kwargs,\n+    ):\n+        super().__init__(data_format=data_format, **kwargs)\n+\n+        self.value_range = value_range\n+        self.num_ops = num_ops\n+        self._set_factor(factor)\n+        self.interpolation = interpolation\n+        self.seed = seed\n+        self.generator = SeedGenerator(seed)\n+\n+        self.random_shear = layers.RandomShear(\n+            x_factor=self.factor,\n+            y_factor=self.factor,\n+            interpolation=interpolation,\n+            seed=self.seed,\n+            data_format=data_format,\n+            **kwargs,\n+        )\n+\n+        self.random_translation = layers.RandomTranslation(\n+            height_factor=self.factor,\n+            width_factor=self.factor,\n+            interpolation=interpolation,\n+            seed=self.seed,\n+            data_format=data_format,\n+            **kwargs,\n+        )\n+\n+        self.random_rotation = layers.RandomRotation(\n+            factor=self.factor,\n+            interpolation=interpolation,\n+            seed=self.seed,\n+            data_format=data_format,\n+            **kwargs,\n+        )\n+\n+        self.random_brightness = layers.RandomBrightness(\n+            factor=self.factor,\n+            value_range=self.value_range,\n+            seed=self.seed,\n+            data_format=data_format,\n+            **kwargs,\n+        )\n+\n+        self.random_color_degeneration = layers.RandomColorDegeneration(\n+            factor=self.factor,\n+            value_range=self.value_range,\n+            seed=self.seed,\n+            data_format=data_format,\n+            **kwargs,\n+        )\n+\n+        self.random_contrast = layers.RandomContrast(\n+            factor=self.factor,\n+            value_range=self.value_range,\n+            seed=self.seed,\n+            data_format=data_format,\n+            **kwargs,\n+        )\n+\n+        self.random_sharpness = layers.RandomSharpness(\n+            factor=self.factor,\n+            value_range=self.value_range,\n+            seed=self.seed,\n+            data_format=data_format,\n+            **kwargs,\n+        )\n+\n+        self.solarization = layers.Solarization(\n+            addition_factor=self.factor,\n+            threshold_factor=self.factor,\n+            value_range=self.value_range,\n+            seed=self.seed,\n+            data_format=data_format,\n+            **kwargs,\n+        )\n+\n+        self.random_posterization = layers.RandomPosterization(\n+            factor=max(1, int(8 * self.factor[1])),\n+            value_range=self.value_range,\n+            seed=self.seed,\n+            data_format=data_format,\n+            **kwargs,\n+        )\n+\n+        self.auto_contrast = layers.AutoContrast(\n+            value_range=self.value_range, data_format=data_format, **kwargs\n+        )\n+\n+        self.equalization = layers.Equalization(\n+            value_range=self.value_range, data_format=data_format, **kwargs\n+        )\n+\n+    def build(self, input_shape):\n+        for layer_name in self._AUGMENT_LAYERS:\n+            augmentation_layer = getattr(self, layer_name)\n+            augmentation_layer.build(input_shape)\n+\n+    def get_random_transformation(self, data, training=True, seed=None):\n+        if not training:\n+            return None\n+\n+        if backend_utils.in_tf_graph():\n+            self.backend.set_backend(\"tensorflow\")\n+\n+            for layer_name in self._AUGMENT_LAYERS:\n+                augmentation_layer = getattr(self, layer_name)\n+                augmentation_layer.backend.set_backend(\"tensorflow\")\n+\n+        transformation = {}\n+        random.shuffle(self._AUGMENT_LAYERS)\n+        for layer_name in self._AUGMENT_LAYERS[: self.num_ops]:\n+            augmentation_layer = getattr(self, layer_name)\n+            transformation[layer_name] = (\n+                augmentation_layer.get_random_transformation(\n+                    data,\n+                    training=training,\n+                    seed=self._get_seed_generator(self.backend._backend),\n+                )\n+            )\n+\n+        return transformation\n+\n+    def transform_images(self, images, transformation, training=True):\n+        if training:\n+            images = self.backend.cast(images, self.compute_dtype)\n+\n+            for layer_name, transformation_value in transformation.items():\n+                augmentation_layer = getattr(self, layer_name)\n+                images = augmentation_layer.transform_images(\n+                    images, transformation_value\n+                )\n+\n+        images = self.backend.cast(images, self.compute_dtype)\n+        return images\n+\n+    def transform_labels(self, labels, transformation, training=True):\n+        return labels\n+\n+    def transform_bounding_boxes(\n+        self,\n+        bounding_boxes,\n+        transformation,\n+        training=True,\n+    ):\n+        if training:\n+            for layer_name, transformation_value in transformation.items():\n+                augmentation_layer = getattr(self, layer_name)\n+                bounding_boxes = augmentation_layer.transform_bounding_boxes(\n+                    bounding_boxes, transformation_value, training=training\n+                )\n+        return bounding_boxes\n+\n+    def transform_segmentation_masks(\n+        self, segmentation_masks, transformation, training=True\n+    ):\n+        return self.transform_images(\n+            segmentation_masks, transformation, training=training\n+        )\n+\n+    def compute_output_shape(self, input_shape):\n+        return input_shape\n+\n+    def get_config(self):\n+        config = {\n+            \"value_range\": self.value_range,\n+            \"num_ops\": self.num_ops,\n+            \"factor\": self.factor,\n+            \"interpolation\": self.interpolation,\n+            \"seed\": self.seed,\n+        }\n+        base_config = super().get_config()\n+        return {**base_config, **config}\n\n@@ -0,0 +1,114 @@\n+import numpy as np\n+import pytest\n+from tensorflow import data as tf_data\n+\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n+\n+\n+class RandAugmentTest(testing.TestCase):\n+    @pytest.mark.requires_trainable_backend\n+    def test_layer(self):\n+        self.run_layer_test(\n+            layers.RandAugment,\n+            init_kwargs={\n+                \"value_range\": (0, 255),\n+                \"num_ops\": 2,\n+                \"factor\": 1,\n+                \"interpolation\": \"nearest\",\n+                \"seed\": 1,\n+                \"data_format\": \"channels_last\",\n+            },\n+            input_shape=(8, 3, 4, 3),\n+            supports_masking=False,\n+            expected_output_shape=(8, 3, 4, 3),\n+        )\n+\n+    def test_rand_augment_inference(self):\n+        seed = 3481\n+        layer = layers.RandAugment()\n+\n+        np.random.seed(seed)\n+        inputs = np.random.randint(0, 255, size=(224, 224, 3))\n+        output = layer(inputs, training=False)\n+        self.assertAllClose(inputs, output)\n+\n+    def test_rand_augment_basic(self):\n+        data_format = backend.config.image_data_format()\n+        if data_format == \"channels_last\":\n+            input_data = np.random.random((2, 8, 8, 3))\n+        else:\n+            input_data = np.random.random((2, 3, 8, 8))\n+        layer = layers.RandAugment(data_format=data_format)\n+\n+        augmented_image = layer(input_data)\n+        self.assertEqual(augmented_image.shape, input_data.shape)\n+\n+    def test_rand_augment_no_operations(self):\n+        data_format = backend.config.image_data_format()\n+        if data_format == \"channels_last\":\n+            input_data = np.random.random((2, 8, 8, 3))\n+        else:\n+            input_data = np.random.random((2, 3, 8, 8))\n+        layer = layers.RandAugment(num_ops=0, data_format=data_format)\n+\n+        augmented_image = layer(input_data)\n+        self.assertAllClose(\n+            backend.convert_to_numpy(augmented_image), input_data\n+        )\n+\n+    def test_random_augment_randomness(self):\n+        data_format = backend.config.image_data_format()\n+        if data_format == \"channels_last\":\n+            input_data = np.random.random((2, 8, 8, 3))\n+        else:\n+            input_data = np.random.random((2, 3, 8, 8))\n+\n+        layer = layers.RandAugment(num_ops=11, data_format=data_format)\n+        augmented_image = layer(input_data)\n+\n+        self.assertNotAllClose(\n+            backend.convert_to_numpy(augmented_image), input_data\n+        )\n+\n+    def test_tf_data_compatibility(self):\n+        data_format = backend.config.image_data_format()\n+        if data_format == \"channels_last\":\n+            input_data = np.random.random((2, 8, 8, 3))\n+        else:\n+            input_data = np.random.random((2, 3, 8, 8))\n+        layer = layers.RandAugment(data_format=data_format)\n+\n+        ds = tf_data.Dataset.from_tensor_slices(input_data).batch(2).map(layer)\n+        for output in ds.take(1):\n+            output.numpy()\n+\n+    def test_rand_augment_tf_data_bounding_boxes(self):\n+        data_format = backend.config.image_data_format()\n+        if data_format == \"channels_last\":\n+            image_shape = (1, 10, 8, 3)\n+        else:\n+            image_shape = (1, 3, 10, 8)\n+        input_image = np.random.random(image_shape)\n+        bounding_boxes = {\n+            \"boxes\": np.array(\n+                [\n+                    [\n+                        [2, 1, 4, 3],\n+                        [6, 4, 8, 6],\n+                    ]\n+                ]\n+            ),\n+            \"labels\": np.array([[1, 2]]),\n+        }\n+\n+        input_data = {\"images\": input_image, \"bounding_boxes\": bounding_boxes}\n+\n+        ds = tf_data.Dataset.from_tensor_slices(input_data)\n+        layer = layers.RandAugment(\n+            data_format=data_format,\n+            seed=42,\n+            bounding_box_format=\"xyxy\",\n+        )\n+        ds.map(layer)\n\n@@ -34,7 +34,7 @@ class RandomBrightnessTest(testing.TestCase):\n         seed = 2390\n \n         # Always scale up, but randomly between 0 ~ 255\n-        layer = layers.RandomBrightness([0, 1.0])\n+        layer = layers.RandomBrightness([0.1, 1.0])\n         np.random.seed(seed)\n         inputs = np.random.randint(0, 255, size=(224, 224, 3))\n         output = backend.convert_to_numpy(layer(inputs))\n@@ -44,7 +44,7 @@ class RandomBrightnessTest(testing.TestCase):\n         self.assertTrue(np.mean(diff) > 0)\n \n         # Always scale down, but randomly between 0 ~ 255\n-        layer = layers.RandomBrightness([-1.0, 0.0])\n+        layer = layers.RandomBrightness([-1.0, -0.1])\n         np.random.seed(seed)\n         inputs = np.random.randint(0, 255, size=(224, 224, 3))\n         output = backend.convert_to_numpy(layer(inputs))\n\n@@ -182,12 +182,11 @@ class RandomRotation(BaseImagePreprocessingLayer):\n             images = data\n         shape = ops.core.shape(images)\n         if len(shape) == 4:\n-            if self.data_format == \"channels_last\":\n             batch_size = shape[0]\n+            if self.data_format == \"channels_last\":\n                 image_height = shape[1]\n                 image_width = shape[2]\n             else:\n-                batch_size = shape[1]\n                 image_height = shape[2]\n                 image_width = shape[3]\n         else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fbf0af76130beecae2273a513242255826b42c04", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 32 | Lines Deleted: 18 | Files Changed: 5 | Hunks: 20 | Methods Changed: 16 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 50 | Churn Cumulative: 773 | Contributors (this commit): 12 | Commits (past 90d): 13 | Contributors (cumulative): 32 | DMM Complexity: 0.75\n\nDIFF:\n@@ -100,7 +100,7 @@ def distribute_tensor(tensor, layout):\n         return global_value\n \n \n-def distribute_data_input(per_process_batch, layout):\n+def distribute_data_input(per_process_batch, layout, batch_dim_name):\n     \"\"\"Distribute the input data with the corresponding layout.\n \n     Note that the inputs here is a local worker batch. Within the local worker,\n@@ -117,9 +117,13 @@ def distribute_data_input(per_process_batch, layout):\n     if not isinstance(layout, jax.sharding.Sharding):\n         layout = _to_jax_layout(layout)\n \n-    mesh_shape = list(layout.mesh.shape.values())\n-    num_model_replicas_total = mesh_shape[0]  # batch dimension of the mesh\n-    mesh_model_dim_size = mesh_shape[1] if len(mesh_shape) > 1 else 1\n+    num_model_replicas_total = layout.mesh.shape[batch_dim_name]\n+\n+    mesh_model_dim_size = 1\n+    for name, dim_size in layout.mesh.shape.items():\n+        if not name == batch_dim_name:\n+            mesh_model_dim_size *= dim_size\n+\n     num_model_replicas_per_process = num_model_replicas_total / num_processes()\n     per_process_batch_size = per_process_batch.shape[0]\n \n\n@@ -337,7 +337,9 @@ class JaxDistributionLibTest(testing.TestCase):\n             mesh, jax.sharding.PartitionSpec(\"batch\", None)\n         )\n \n-        result = backend_dlib.distribute_data_input(per_process_batch, layout)\n+        result = backend_dlib.distribute_data_input(\n+            per_process_batch, layout, \"batch\"\n+        )\n \n         # Check the shape of the global batch array\n         self.assertEqual(\n\n@@ -1,5 +1,6 @@\n import collections\n import itertools\n+from functools import partial\n \n import jax\n import numpy as np\n@@ -988,15 +989,18 @@ class JAXTrainer(base_trainer.Trainer):\n \n def _distribute_data(data, layouts=None):\n     distribution = distribution_lib.distribution()\n+\n     if distribution is not None:\n         if layouts is None:\n             layouts = tree.map_structure(\n                 lambda d: distribution.get_data_layout(d.shape),\n                 data,\n             )\n-        return tree.map_structure(\n-            jax_distribution_lib.distribute_data_input, data, layouts\n+        jax_dist_data_input = partial(\n+            jax_distribution_lib.distribute_data_input,\n+            batch_dim_name=distribution.batch_dim_name,\n         )\n+        return tree.map_structure(jax_dist_data_input, data, layouts)\n \n     return tree.map_structure(jax.device_put, data)\n \n\n@@ -287,8 +287,9 @@ class Distribution:\n         device_mesh: A `DeviceMesh` instance.\n     \"\"\"\n \n-    def __init__(self, device_mesh):\n+    def __init__(self, device_mesh, batch_dim_name=None):\n         self._device_mesh = device_mesh\n+        self._batch_dim_name = batch_dim_name\n \n     def get_data_layout(self, data_shape):\n         \"\"\"Retrieve the `TensorLayout` for the input data.\n@@ -341,6 +342,10 @@ class Distribution:\n     def device_mesh(self):\n         return self._device_mesh\n \n+    @property\n+    def batch_dim_name(self):\n+        return self._batch_dim_name\n+\n     def distribute_dataset(self, dataset):\n         \"\"\"Create a distributed dataset instance from the original user dataset.\n \n@@ -395,7 +400,6 @@ class DataParallel(Distribution):\n         else:\n             self._initialize_mesh_from_list_devices()\n \n-        self._batch_dim_name = self.device_mesh.axis_names[0]\n         # Those following attributes might get convert to public methods.\n         self._num_process = distribution_lib.num_processes()\n         self._process_id = distribution_lib.process_id()\n@@ -408,7 +412,7 @@ class DataParallel(Distribution):\n                 \"Expect `mesh` to be an instance of `DeviceMesh`. \"\n                 f\"Received: mesh={device_mesh} (of type {type(device_mesh)})\"\n             )\n-        super().__init__(device_mesh)\n+        super().__init__(device_mesh, device_mesh.axis_names[0])\n         if self.device_mesh.devices.ndim != 1:\n             warnings.warn(\n                 \"Expect the input mesh to be 1D, but received \"\n@@ -424,7 +428,7 @@ class DataParallel(Distribution):\n             axis_names=[DEFAULT_BATCH_DIM_NAME],\n             devices=devices,\n         )\n-        super().__init__(device_mesh)\n+        super().__init__(device_mesh, DEFAULT_BATCH_DIM_NAME)\n \n     def _initialize_mesh_from_list_devices(self):\n         devices = np.array(list_devices())\n@@ -433,11 +437,11 @@ class DataParallel(Distribution):\n             axis_names=[DEFAULT_BATCH_DIM_NAME],\n             devices=devices,\n         )\n-        super().__init__(device_mesh)\n+        super().__init__(device_mesh, DEFAULT_BATCH_DIM_NAME)\n \n     def get_data_layout(self, data_shape):\n         data_shard_spec = [None] * len(data_shape)\n-        data_shard_spec[0] = self._batch_dim_name  # Shard on the first dim\n+        data_shard_spec[0] = self.batch_dim_name  # Shard on the first dim\n         return TensorLayout(data_shard_spec, self.device_mesh)\n \n     def get_variable_layout(self, variable):\n@@ -590,7 +594,7 @@ class ModelParallel(Distribution):\n \n     def get_data_layout(self, data_shape):\n         data_shard_spec = [None] * len(data_shape)\n-        data_shard_spec[0] = self._batch_dim_name  # Shard on the first dim\n+        data_shard_spec[0] = self.batch_dim_name  # Shard on the first dim\n         return TensorLayout(data_shard_spec, self.device_mesh)\n \n     def get_variable_layout(self, variable):\n@@ -631,7 +635,7 @@ class ModelParallel(Distribution):\n         # Note that this might be smaller than one if model replicas are sharded\n         # across multiple processes.\n         mesh_batch_dim_index = self.device_mesh.axis_names.index(\n-            self._batch_dim_name\n+            self.batch_dim_name\n         )\n         num_model_replicas = self.device_mesh.shape[mesh_batch_dim_index]\n         if num_model_replicas == 1:\n\n@@ -186,7 +186,7 @@ class DataParallelDistributionTest(testing.TestCase):\n         device_mesh = distribution.device_mesh\n         self.assertEqual(len(device_mesh.devices), 8)\n         self.assertEqual(device_mesh.axis_names, [\"data\"])\n-        self.assertEqual(distribution._batch_dim_name, \"data\")\n+        self.assertEqual(distribution.batch_dim_name, \"data\")\n \n         self.assertFalse(distribution._is_multi_process)\n         self.assertEqual(distribution._process_id, 0)\n@@ -197,7 +197,7 @@ class DataParallelDistributionTest(testing.TestCase):\n         device_mesh = distribution.device_mesh\n         self.assertEqual(len(device_mesh.devices), 8)\n         self.assertEqual(device_mesh.axis_names, [\"batch\"])\n-        self.assertEqual(distribution._batch_dim_name, \"batch\")\n+        self.assertEqual(distribution.batch_dim_name, \"batch\")\n \n     @mock.patch.object(\n         distribution_lib,\n@@ -211,7 +211,7 @@ class DataParallelDistributionTest(testing.TestCase):\n         device_mesh = distribution.device_mesh\n         self.assertEqual(len(device_mesh.devices), 8)\n         self.assertEqual(device_mesh.axis_names, [\"batch\"])\n-        self.assertEqual(distribution._batch_dim_name, \"batch\")\n+        self.assertEqual(distribution.batch_dim_name, \"batch\")\n \n     def test_get_data_layout(self):\n         distribution = distribution_lib.DataParallel(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#26e71f5aff68ccac9c7651f6de802af81f720b1d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 58 | Lines Deleted: 18 | Files Changed: 4 | Hunks: 13 | Methods Changed: 6 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 76 | Churn Cumulative: 648 | Contributors (this commit): 9 | Commits (past 90d): 12 | Contributors (cumulative): 18 | DMM Complexity: 0.0\n\nDIFF:\n@@ -119,7 +119,7 @@ class JaxExportArchive:\n                     self._tf_trackable.non_trainable_variables,\n                     non_trainable_variables,\n                 ):\n-                    var.assign(new_value)\n+                    var.assign(tf.cast(new_value, var.dtype))\n                 return output\n \n             stateful_fn.__signature__ = inspect.Signature(\n\n@@ -85,12 +85,10 @@ class Layer(BackendLayer, Operation, KerasSaveable):\n         trainable: Boolean, whether the layer's variables should be trainable.\n         name: String name of the layer.\n         dtype: The dtype of the layer's computations and weights. Can also be a\n-            `keras.DTypePolicy`,\n-            which allows the computation and\n-            weight dtype to differ. Defaults to `None`. `None` means to use\n-            `keras.config.dtype_policy()`,\n-            which is a `float32` policy unless set to different value\n-            (via `keras.config.set_dtype_policy()`).\n+            `keras.DTypePolicy`, which allows the computation and weight dtype\n+            to differ. Defaults to `None`. `None` means to use\n+            `keras.config.dtype_policy()`, which is a `float32` policy unless\n+            set to different value (via `keras.config.set_dtype_policy()`).\n \n     Attributes:\n         name: The name of the layer (string).\n\n@@ -5,6 +5,8 @@ import numpy as np\n from keras.src import backend\n from keras.src import tree\n from keras.src.api_export import keras_export\n+from keras.src.backend.common.variables import is_float_dtype\n+from keras.src.backend.common.variables import standardize_dtype\n from keras.src.layers.layer import Layer\n from keras.src.saving import serialization_lib\n from keras.src.utils import jax_utils\n@@ -204,6 +206,8 @@ class JaxLayer(Layer):\n             argument, then `init_fn` is called at build time to initialize the\n             non-trainable state of the model.\n       seed: Seed for random number generator. Optional.\n+      dtype: The dtype of the layer's computations and weights. Can also be a\n+            `keras.DTypePolicy`. Optional. Defaults to the default policy.\n     \"\"\"\n \n     def __init__(\n@@ -213,6 +217,7 @@ class JaxLayer(Layer):\n         params=None,\n         state=None,\n         seed=None,\n+        dtype=None,\n         **kwargs,\n     ):\n         if backend.backend() != \"jax\":\n@@ -226,9 +231,10 @@ class JaxLayer(Layer):\n                 \"`init_fn`, `params` and `state` cannot all be `None`.\"\n             )\n \n-        super().__init__(**kwargs)\n+        super().__init__(dtype=dtype, **kwargs)\n         self.call_fn = call_fn\n         self.init_fn = init_fn\n+        self.has_dtype_policy = dtype is not None\n         self.seed_generator = backend.random.SeedGenerator(seed)\n         self.tracked_params = self._create_variables(params, trainable=True)\n         self.tracked_state = self._create_variables(state, trainable=False)\n@@ -291,18 +297,28 @@ class JaxLayer(Layer):\n         \"\"\"\n \n         def create_variable(value):\n-            if backend.is_tensor(value) or isinstance(value, np.ndarray):\n-                variable = self.add_weight(\n-                    value.shape, initializer=\"zeros\", trainable=trainable\n+            if backend.is_tensor(value) or isinstance(\n+                value, (np.ndarray, np.generic)\n+            ):\n+                dtype = value.dtype\n+                if self.has_dtype_policy and is_float_dtype(dtype):\n+                    dtype = None  # Use the layer dtype policy\n+                return self.add_weight(\n+                    value.shape,\n+                    initializer=value,\n+                    dtype=dtype,\n+                    trainable=trainable,\n                 )\n-                variable.assign(value)\n-                return variable\n-            elif isinstance(value, (np.generic, int, float)):\n-                variable = self.add_weight(\n-                    (), initializer=\"zeros\", trainable=trainable\n+            elif isinstance(value, (bool, int, float)):\n+                dtype = standardize_dtype(type(value))\n+                if self.has_dtype_policy and is_float_dtype(dtype):\n+                    dtype = None  # Use the layer dtype policy\n+                return self.add_weight(\n+                    (),\n+                    initializer=backend.convert_to_tensor(value),\n+                    dtype=dtype,\n+                    trainable=trainable,\n                 )\n-                variable.assign(value)\n-                return variable\n             else:\n                 return value\n \n\n@@ -15,6 +15,7 @@ from keras.src import saving\n from keras.src import testing\n from keras.src import tree\n from keras.src import utils\n+from keras.src.dtype_policies.dtype_policy import DTypePolicy\n from keras.src.saving import object_registration\n from keras.src.utils.jax_layer import FlaxLayer\n from keras.src.utils.jax_layer import JaxLayer\n@@ -362,6 +363,18 @@ class TestJaxLayer(testing.TestCase):\n             \"non_trainable_weights\": 1,\n             \"non_trainable_params\": 1,\n         },\n+        {\n+            \"testcase_name\": \"training_state_dtype_policy\",\n+            \"init_kwargs\": {\n+                \"call_fn\": jax_stateful_apply,\n+                \"init_fn\": jax_stateful_init,\n+                \"dtype\": DTypePolicy(\"mixed_float16\"),\n+            },\n+            \"trainable_weights\": 6,\n+            \"trainable_params\": 266610,\n+            \"non_trainable_weights\": 1,\n+            \"non_trainable_params\": 1,\n+        },\n     )\n     def test_jax_layer(\n         self,\n@@ -414,6 +427,19 @@ class TestJaxLayer(testing.TestCase):\n             \"non_trainable_weights\": 8,\n             \"non_trainable_params\": 536,\n         },\n+        {\n+            \"testcase_name\": \"training_rng_unbound_method_dtype_policy\",\n+            \"flax_model_class\": \"FlaxDropoutModel\",\n+            \"flax_model_method\": None,\n+            \"init_kwargs\": {\n+                \"method\": \"flax_dropout_wrapper\",\n+                \"dtype\": DTypePolicy(\"mixed_float16\"),\n+            },\n+            \"trainable_weights\": 8,\n+            \"trainable_params\": 648226,\n+            \"non_trainable_weights\": 0,\n+            \"non_trainable_params\": 0,\n+        },\n     )\n     @pytest.mark.skipif(flax is None, reason=\"Flax library is not available.\")\n     def test_flax_layer(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f97be63281f505530cf5e88187e2faadbeb2ea07", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 31 | Lines Deleted: 8 | Files Changed: 2 | Hunks: 8 | Methods Changed: 5 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 39 | Churn Cumulative: 812 | Contributors (this commit): 4 | Commits (past 90d): 5 | Contributors (cumulative): 7 | DMM Complexity: 1.0\n\nDIFF:\n@@ -232,7 +232,7 @@ class STFTSpectrogram(layers.Layer):\n         self.built = True\n \n     def _adjust_shapes(self, outputs):\n-        _, channels, freq_channels, time_seq = outputs.shape\n+        _, channels, freq_channels, time_seq = ops.shape(outputs)\n         batch_size = -1\n         if self.data_format == \"channels_last\":\n             if self.expand_dims:\n@@ -258,11 +258,11 @@ class STFTSpectrogram(layers.Layer):\n \n     def _apply_conv(self, inputs, kernel):\n         if self.data_format == \"channels_last\":\n-            _, time_seq, channels = inputs.shape\n+            _, time_seq, channels = ops.shape(inputs)\n             inputs = ops.transpose(inputs, [0, 2, 1])\n             inputs = ops.reshape(inputs, [-1, time_seq, 1])\n         else:\n-            _, channels, time_seq = inputs.shape\n+            _, channels, time_seq = ops.shape(inputs)\n             inputs = ops.reshape(inputs, [-1, 1, time_seq])\n \n         outputs = ops.conv(\n@@ -274,14 +274,14 @@ class STFTSpectrogram(layers.Layer):\n         )\n         batch_size = -1\n         if self.data_format == \"channels_last\":\n-            _, time_seq, freq_channels = outputs.shape\n+            _, time_seq, freq_channels = ops.shape(outputs)\n             outputs = ops.transpose(outputs, [0, 2, 1])\n             outputs = ops.reshape(\n                 outputs,\n                 [batch_size, channels, freq_channels, time_seq],\n             )\n         else:\n-            _, freq_channels, time_seq = outputs.shape\n+            _, freq_channels, time_seq = ops.shape(outputs)\n             outputs = ops.reshape(\n                 outputs,\n                 [batch_size, channels, freq_channels, time_seq],\n\n@@ -273,6 +273,30 @@ class TestSpectrogram(testing.TestCase):\n             supports_masking=False,\n         )\n \n+    @pytest.mark.skipif(\n+        backend.backend() != \"tensorflow\",\n+        reason=\"Backend does not support dynamic shapes\",\n+    )\n+    def test_spectrogram_dynamic_shape(self):\n+        model = Sequential(\n+            [\n+                Input(shape=(None, 1), dtype=TestSpectrogram.DTYPE),\n+                layers.STFTSpectrogram(\n+                    frame_length=500,\n+                    frame_step=25,\n+                    fft_length=1024,\n+                    mode=\"stft\",\n+                    data_format=\"channels_last\",\n+                ),\n+            ]\n+        )\n+\n+        def generator():\n+            yield (np.random.random((2, 16000, 1)),)\n+            yield (np.random.random((3, 8000, 1)),)\n+\n+        model.predict(generator())\n+\n     @pytest.mark.requires_trainable_backend\n     def test_spectrogram_error(self):\n         rnd = np.random.RandomState(41)\n@@ -310,10 +334,9 @@ class TestSpectrogram(testing.TestCase):\n             init_args[\"mode\"] = \"angle\"\n             y_true, y = self._calc_spectrograms(x, **init_args)\n \n-            pi = np.arccos(np.float128(-1)).astype(y_true.dtype)\n             mask = np.isclose(y, y_true, **tol_kwargs)\n-            mask |= np.isclose(y + 2 * pi, y_true, **tol_kwargs)\n-            mask |= np.isclose(y - 2 * pi, y_true, **tol_kwargs)\n+            mask |= np.isclose(y + 2 * np.pi, y_true, **tol_kwargs)\n+            mask |= np.isclose(y - 2 * np.pi, y_true, **tol_kwargs)\n             mask |= np.isclose(np.cos(y), np.cos(y_true), **tol_kwargs)\n             mask |= np.isclose(np.sin(y), np.sin(y_true), **tol_kwargs)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
