{"custom_id": "keras#8e95a38e7a4be3a3edd8139dbd26e994e50d0a0c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 183 | Lines Deleted: 64 | Files Changed: 7 | Hunks: 41 | Methods Changed: 27 | Complexity Δ (Sum/Max): 17/9 | Churn Δ: 247 | Churn Cumulative: 8659 | Contributors (this commit): 13 | Commits (past 90d): 58 | Contributors (cumulative): 23 | DMM Complexity: 0.6923076923076923\n\nDIFF:\n@@ -28,8 +28,6 @@ from absl.testing import parameterized\n \n # pylint: disable=g-direct-tensorflow-import\n import keras\n-from tensorflow.python.distribute import distribute_coordinator as dc\n-from tensorflow.python.distribute import multi_worker_test_base as test_base\n from keras import backend\n from keras import callbacks\n from keras import metrics as metrics_module\n@@ -120,7 +118,7 @@ class MultiWorkerVerificationCallback(callbacks.Callback):\n     self._num_worker = num_worker\n     self._task_dict = {\n         key: collections.defaultdict(lambda: collections.defaultdict(int))\n-        for key in ['ps', 'worker']\n+        for key in ['ps', 'worker', 'chief']\n     }\n     self._lock = threading.Lock()\n     self._is_between_graph = None\n@@ -168,42 +166,34 @@ class MultiWorkerVerificationCallback(callbacks.Callback):\n     else:\n       # If in-graph, only the first worker calls callback methods.\n       worker_call_count = {0: method_count_dict}\n+    chief_call_count = {0: method_count_dict}\n+    task_config = json.loads(os.environ['TF_CONFIG'])['task']['type']\n     test_case.assertDictEqual(\n         self._task_dict,\n         {\n             # PS' callback is not supposed to be called.\n             'ps': {},\n-            # Each of the Worker should be called num_epoch of times.\n-            'worker': worker_call_count\n+            # Worker or chief should only be called on worker/chief.\n+            'worker': worker_call_count if task_config == 'worker' else {},\n+            'chief': chief_call_count if task_config == 'chief' else {}\n         })\n \n \n-class KerasMultiWorkerTestIndependentWorker(test_base.IndependentWorkerTestBase,\n+class KerasMultiWorkerTestIndependentWorker(tf.test.TestCase,\n                                             parameterized.TestCase):\n \n   @tf.__internal__.distribute.combinations.generate(\n       tf.__internal__.test.combinations.combine(\n-          mode=['graph'],\n-          strategy_cls=[\n-              tf.distribute.MultiWorkerMirroredStrategy,\n-          ],\n-          required_gpus=[0, 1]))\n-  def testSimpleModelIndependentWorkerSync(self, strategy_cls):\n-    num_workers = 2\n-    num_epoch = 2\n-\n-    cluster_spec = tf.__internal__.distribute.multi_process_runner.create_cluster_spec(num_workers=num_workers)\n-    self._barrier = dc._Barrier(2)\n-\n-    # The verification callback will be shared by multiple threads.\n+          mode=['eager'],\n+          strategy=[\n+              tf.__internal__.distribute.combinations.multi_worker_mirrored_2x1_cpu,\n+              tf.__internal__.distribute.combinations.multi_worker_mirrored_2x1_gpu,\n+          ]))\n+  def testSimpleModelIndependentWorkerSync(self, strategy):\n     verification_callback = MultiWorkerVerificationCallback(\n-        num_epoch=num_epoch, num_worker=num_workers)\n-\n-    def _independent_worker_fn(*args, **kwargs):  # pylint: disable=unused-argument\n-      \"\"\"Simulates an Independent Worker inside of a thread.\"\"\"\n-      with tf.compat.v1.test.mock.patch.object(dc, '_run_std_server',\n-                                  self._make_mock_run_std_server()):\n-        strategy = strategy_cls()\n+        num_epoch=2,\n+        num_worker=len(\n+            json.loads(os.environ['TF_CONFIG'])['cluster']['worker']))\n     verification_callback.is_between_graph = \\\n         strategy.extended.experimental_between_graph\n     batch_size = 64\n@@ -213,30 +203,15 @@ class KerasMultiWorkerTestIndependentWorker(test_base.IndependentWorkerTestBase,\n     with strategy.scope():\n       model = multi_worker_testing_utils.get_mnist_model((28, 28, 1))\n     orig_loss, _ = model.evaluate(train_ds, steps=steps)\n-        callbacks_for_fit = tf.nest.flatten(\n-            kwargs.get('verification_callback', []))\n     history = model.fit(\n         x=train_ds,\n-            epochs=num_epoch,\n+        epochs=2,\n         steps_per_epoch=steps,\n-            callbacks=callbacks_for_fit)\n+        callbacks=[verification_callback])\n     self.assertIsInstance(history, keras.callbacks.History)\n     trained_loss, _ = model.evaluate(train_ds, steps=steps)\n     self.assertLess(trained_loss, orig_loss)\n \n-    threads = self.run_multiple_tasks_in_threads(\n-        _independent_worker_fn,\n-        cluster_spec,\n-        verification_callback=verification_callback)\n-\n-    threads_to_join = []\n-    strategy = strategy_cls()\n-    if strategy.extended.experimental_between_graph:\n-      for ts in threads.values():\n-        threads_to_join.extend(ts)\n-    else:\n-      threads_to_join = [threads['worker'][0]]\n-    self.join_independent_workers(threads_to_join)\n     verification_callback.verify(self)\n \n \n\n@@ -76,7 +76,4 @@ def get_mnist_model(input_shape):\n def make_parameter_server_cluster(num_workers, num_ps):\n   cluster_def = multi_worker_test_base.create_in_process_cluster(\n       num_workers=num_workers, num_ps=num_ps, rpc_layer=\"grpc\")\n-  cluster_def[\"chief\"] = [\n-      \"localhost:%d\" % multi_worker_test_base.pick_unused_port()\n-  ]\n   return SimpleClusterResolver(ClusterSpec(cluster_def), rpc_layer=\"grpc\")\n\n@@ -517,7 +517,8 @@ class DatasetCreatorAdapter(DataAdapter):\n     return None  # To be inferred by `DataHandler`.\n \n   def get_dataset(self):\n-    return self.strategy.distribute_datasets_from_function(self.dataset_creator)\n+    return self.strategy.distribute_datasets_from_function(\n+        self.dataset_creator, options=self.dataset_creator.input_options)\n \n   def batch_size(self):\n     raise NotImplementedError()\n@@ -1329,7 +1330,8 @@ class _ClusterCoordinatorDataHandler(DataHandler):\n                       \"`DatasetCreator`.\")\n \n     def per_worker_dataset_fn():\n-      return strategy.distribute_datasets_from_function(x)\n+      return strategy.distribute_datasets_from_function(\n+          x, options=x.input_options)\n \n     self._dataset = self._model._cluster_coordinator.create_per_worker_dataset(  # pylint: disable=protected-access\n         per_worker_dataset_fn)\n\n@@ -1196,13 +1196,15 @@ def mean_squared_error(y_true, y_pred):\n   return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n \n \n-def _ragged_tensor_apply_loss(loss_fn, y_true, y_pred):\n+def _ragged_tensor_apply_loss(loss_fn, y_true, y_pred, y_pred_extra_dim=False):\n   \"\"\"Apply a loss function on a per batch basis.\n \n   Args:\n     loss_fn: The loss function\n     y_true: truth values (RaggedTensor)\n     y_pred: predicted values (RaggedTensor)\n+    y_pred_extra_dim: whether y_pred has an additional dimension compared to\n+      y_true\n \n   Returns:\n     Loss-function result. A dense tensor if the output has a single dimension\n@@ -1225,17 +1227,36 @@ def _ragged_tensor_apply_loss(loss_fn, y_true, y_pred):\n     ])\n \n   def _convert_to_dense(inputs):\n-    return tuple(rt.to_tensor() for rt in inputs)\n+    return tuple(\n+        rt.to_tensor() if isinstance(rt, tf.RaggedTensor) else rt\n+        for rt in inputs)\n \n-  def _wrapper(inputs):\n+  def _call_loss(inputs, ragged_output):\n+    \"\"\" Adapt the result to ragged or dense tensor according to the expected\n+\n+        output type. This is done so that all the return values of the map\n+        operation have the same type.\n+    \"\"\"\n+    r = loss_fn(*inputs)\n+    if ragged_output and not isinstance(r, tf.RaggedTensor):\n+      r = tf.RaggedTensor.from_tensor(r)\n+    elif not ragged_output and isinstance(r, tf.RaggedTensor):\n+      r = r.to_tensor()\n+    return r\n+\n+  def _wrapper(inputs, ragged_output):\n     _, y_pred = inputs\n     if isinstance(y_pred, tf.RaggedTensor):\n       return tf.compat.v1.cond(\n           rt_is_equiv_dense(y_pred),\n-          lambda: loss_fn(*_convert_to_dense(inputs)), lambda: loss_fn(*inputs))\n+          lambda: _call_loss(_convert_to_dense(inputs), ragged_output),\n+          lambda: _call_loss(inputs, ragged_output))\n \n     return loss_fn(*inputs)\n \n+  if not isinstance(y_true, tf.RaggedTensor):\n+    return loss_fn(y_true, y_pred.to_tensor())\n+\n   lshape = y_pred.shape.as_list()[1:-1]\n   if len(lshape) > 0:\n     spec = tf.RaggedTensorSpec(shape=lshape, dtype=y_pred.dtype)\n@@ -1243,9 +1264,14 @@ def _ragged_tensor_apply_loss(loss_fn, y_true, y_pred):\n     spec = tf.TensorSpec(shape=[], dtype=y_pred.dtype)\n \n   nested_splits_list = [rt.nested_row_splits for rt in (y_true, y_pred)]\n+  if y_pred_extra_dim:\n+    nested_splits_list[1] = nested_splits_list[1][:-1]\n+\n+  map_fn = functools.partial(_wrapper, ragged_output=len(lshape) > 1)\n+\n   assertion_list = ragged_util.assert_splits_match(nested_splits_list)\n   with tf.control_dependencies(assertion_list):\n-    return ragged_map_ops.map_fn(_wrapper, elems=(y_true, y_pred), dtype=spec)\n+    return ragged_map_ops.map_fn(map_fn, elems=(y_true, y_pred), dtype=spec)\n \n \n @dispatch.dispatch_for_types(mean_squared_error, tf.RaggedTensor)\n@@ -1694,6 +1720,29 @@ def sparse_categorical_crossentropy(y_true, y_pred, from_logits=False, axis=-1):\n       y_true, y_pred, from_logits=from_logits, axis=axis)\n \n \n+@dispatch.dispatch_for_types(sparse_categorical_crossentropy,\n+                             tf.RaggedTensor)\n+def _ragged_tensor_sparse_categorical_crossentropy(y_true,\n+                                                   y_pred,\n+                                                   from_logits=False,\n+                                                   axis=-1):\n+  \"\"\" Implements support for handling RaggedTensors.\n+\n+      Expected y_pred shape: (batch, sequence_len, n_classes) with sequence_len\n+      being variable per batch.\n+      Return shape: (batch, sequence_len).\n+\n+      When used by SparseCategoricalCrossentropy() with the default reduction\n+      (SUM_OVER_BATCH_SIZE), the reduction averages the loss over the\n+      number of elements independent of the batch. E.g. if the RaggedTensor\n+      has 2 batches with [2, 1] values respectively, the resulting loss is\n+      the sum of the individual loss values divided by 3.\n+  \"\"\"\n+  fn = functools.partial(\n+      sparse_categorical_crossentropy, from_logits=from_logits, axis=axis)\n+  return _ragged_tensor_apply_loss(fn, y_true, y_pred, y_pred_extra_dim=True)\n+\n+\n @keras_export('keras.metrics.binary_crossentropy',\n               'keras.losses.binary_crossentropy')\n @tf.__internal__.dispatch.add_dispatch_support\n\n@@ -1144,6 +1144,36 @@ class SparseCategoricalCrossentropyTest(tf.test.TestCase):\n     loss = cce_obj(y_true, y_pred, sample_weight=2.3)\n     self.assertAlmostEqual(self.evaluate(loss), .7449, 3)\n \n+  def test_ragged_tensors(self):\n+    cce_obj = losses.SparseCategoricalCrossentropy()\n+    y_true = tf.ragged.constant([[0, 1], [2]])\n+    y_pred = tf.ragged.constant(\n+        [[[.9, .05, .05], [.5, .89, .6]], [[.05, .01, .94]]],\n+        dtype=tf.float32)\n+    # batch losses [[0.1054, 0.8047], [0.0619]]\n+    sample_weight = tf.constant([[1.2], [3.4]], shape=(2, 1))\n+    loss = cce_obj(y_true, y_pred, sample_weight=sample_weight)\n+    # sum([0.1054, 0.8047, 0.0619]) / 3\n+    self.assertAlmostEqual(self.evaluate(loss), 0.4341, 3)\n+\n+    # Test with logits.\n+    logits = tf.ragged.constant([[[8., 1., 1.], [0., 9., 1.]],\n+                                          [[2., 3., 5.]]])\n+    cce_obj = losses.SparseCategoricalCrossentropy(from_logits=True)\n+    # batch losses [[0.0018, 0.0004], [0.1698]]\n+    loss = cce_obj(y_true, logits, sample_weight=sample_weight)\n+    self.assertAlmostEqual(self.evaluate(loss), 0.1934, 3)\n+\n+  def test_ragged_tensors_3d(self):\n+    # shape [2, 1, None]\n+    y_true = tf.ragged.constant([[[1, 1]], [[0]]])\n+    # shape [2, 1, None, 2]\n+    y_pred = tf.ragged.constant([[[[0.1, 0.9], [0.1, 0.9]]],\n+                                          [[[0.9, 0.1]]]])\n+    cce_obj = losses.SparseCategoricalCrossentropy()\n+    loss = cce_obj(y_true, y_pred)\n+    self.assertAlmostEqual(self.evaluate(loss), 0.1054, 3)\n+\n \n @combinations.generate(combinations.combine(mode=['graph', 'eager']))\n class HingeTest(tf.test.TestCase):\n\n@@ -42,7 +42,11 @@ class DatasetCreator(object):\n     dataset = dataset.prefetch(2)\n     return dataset\n \n-  model.fit(DatasetCreator(dataset_fn), epochs=10, steps_per_epoch=10)\n+  input_options = tf.distribute.InputOptions(\n+      experimental_fetch_to_device=True,\n+      experimental_per_replica_buffer_size=2)\n+  model.fit(DatasetCreator(dataset_fn, input_options=input_options),\n+      epochs=10, steps_per_epoch=10)\n   ```\n \n   `Model.fit` usage with `DatasetCreator` is intended to work across all\n@@ -67,12 +71,24 @@ class DatasetCreator(object):\n       cross-worker input pipeline sharding (if neither is needed, the\n       `InputContext` parameter can be ignored in the `dataset_fn`), and returns\n       a `tf.data.Dataset`.\n+    input_options: Optional `tf.distribute.InputOptions`, used for specific\n+      options when used with distribution, for example, whether to prefetch\n+      dataset elements to accelerator device memory or host device memory, and\n+      prefetch buffer size in the replica device memory. No effect if not used\n+      with distributed training. See `tf.distribute.InputOptions` for more\n+      information.\n   \"\"\"\n \n-  def __init__(self, dataset_fn):\n+  def __init__(self, dataset_fn, input_options=None):\n     if not callable(dataset_fn):\n       raise TypeError('`dataset_fn` for `DatasetCreator` must be a `callable`.')\n+    if input_options and (not isinstance(input_options,\n+                                         tf.distribute.InputOptions)):\n+      raise TypeError('`input_options` for `DatasetCreator` must be a '\n+                      '`tf.distribute.InputOptions`.')\n+\n     self.dataset_fn = dataset_fn\n+    self.input_options = input_options\n \n   def __call__(self, *args, **kwargs):\n     # When a `DatasetCreator` is invoked, it forwards args/kwargs straight to\n\n@@ -15,8 +15,12 @@\n \"\"\"Tests for dataset_creator.\"\"\"\n \n import tensorflow.compat.v2 as tf\n+\n+from absl.testing import parameterized\n from tensorflow.python.distribute import multi_worker_test_base\n from tensorflow.python.distribute.cluster_resolver import SimpleClusterResolver\n+from keras import combinations\n+from keras.engine import data_adapter\n from keras.engine import sequential\n from keras.layers import core as core_layers\n from keras.optimizer_v2 import gradient_descent\n@@ -24,7 +28,7 @@ from keras.utils import dataset_creator\n from tensorflow.python.training.server_lib import ClusterSpec\n \n \n-class DatasetCreatorTest(tf.test.TestCase):\n+class DatasetCreatorTest(tf.test.TestCase, parameterized.TestCase):\n \n   def test_dataset_creator(self):\n     with self.assertRaisesRegex(\n@@ -57,36 +61,82 @@ class DatasetCreatorTest(tf.test.TestCase):\n \n     return dataset_fn\n \n-  def test_dataset_creator_model_fit_without_strategy(self):\n+  @combinations.generate(combinations.combine(use_input_options=[True, False]))\n+  def test_dataset_creator_model_fit_without_strategy(self, use_input_options):\n     model = sequential.Sequential([core_layers.Dense(10)])\n     model.compile(gradient_descent.SGD(), loss=\"mse\")\n \n+    input_options = tf.distribute.InputOptions() if use_input_options else None\n     history = model.fit(\n-        dataset_creator.DatasetCreator(self._get_dataset_fn()),\n+        dataset_creator.DatasetCreator(self._get_dataset_fn(), input_options),\n         epochs=10,\n         steps_per_epoch=10,\n         verbose=0)\n     self.assertLen(history.history[\"loss\"], 10)\n \n-  def test_dataset_creator_usage_in_parameter_server_model_fit(self):\n+  def _get_parameter_server_strategy(self):\n     cluster_def = multi_worker_test_base.create_in_process_cluster(\n         num_workers=2, num_ps=1, rpc_layer=\"grpc\")\n-    cluster_def[\"chief\"] = [\n-        \"localhost:%d\" % multi_worker_test_base.pick_unused_port()\n-    ]\n-    strategy = tf.distribute.experimental.ParameterServerStrategy(\n+    return tf.distribute.experimental.ParameterServerStrategy(\n         SimpleClusterResolver(ClusterSpec(cluster_def), rpc_layer=\"grpc\"))\n+\n+  @combinations.generate(combinations.combine(use_input_options=[True, False]))\n+  def test_dataset_creator_usage_in_parameter_server_model_fit(\n+      self, use_input_options):\n+    strategy = self._get_parameter_server_strategy()\n     with strategy.scope():\n       model = sequential.Sequential([core_layers.Dense(10)])\n     model.compile(gradient_descent.SGD(), loss=\"mse\")\n \n+    input_options = tf.distribute.InputOptions() if use_input_options else None\n     history = model.fit(\n-        dataset_creator.DatasetCreator(self._get_dataset_fn()),\n+        dataset_creator.DatasetCreator(self._get_dataset_fn(), input_options),\n         epochs=10,\n         steps_per_epoch=10,\n         verbose=0)\n     self.assertLen(history.history[\"loss\"], 10)\n \n+  def test_dataset_creator_input_options(self):\n+    dataset_fn = lambda _: tf.data.Dataset.from_tensor_slices([1, 1])\n+    input_options = tf.distribute.InputOptions(\n+        experimental_fetch_to_device=True,\n+        experimental_per_replica_buffer_size=2)\n+    x = dataset_creator.DatasetCreator(dataset_fn, input_options=input_options)\n+    with tf.distribute.MultiWorkerMirroredStrategy().scope():\n+      data_handler = data_adapter.get_data_handler(\n+          x,\n+          steps_per_epoch=2,\n+          model=sequential.Sequential([core_layers.Dense(10)]))\n+\n+    # Ensuring the resulting `DistributedDatasetsFromFunction` has the right\n+    # options.\n+    self.assertTrue(data_handler._dataset._options.experimental_fetch_to_device)\n+    self.assertEqual(\n+        data_handler._dataset._options.experimental_per_replica_buffer_size, 2)\n+\n+  def test_dataset_creator_input_options_with_cluster_coordinator(self):\n+    dataset_fn = lambda _: tf.data.Dataset.from_tensor_slices([1, 1])\n+    input_options = tf.distribute.InputOptions(\n+        experimental_fetch_to_device=True,\n+        experimental_per_replica_buffer_size=2)\n+    x = dataset_creator.DatasetCreator(dataset_fn, input_options=input_options)\n+    strategy = self._get_parameter_server_strategy()\n+    with strategy.scope():\n+      model = sequential.Sequential([core_layers.Dense(10)])\n+      model._cluster_coordinator = tf.distribute.experimental.coordinator.ClusterCoordinator(\n+          strategy)\n+      data_handler = data_adapter.get_data_handler(\n+          x, steps_per_epoch=2, model=model)\n+\n+    iter_rv = iter(data_handler._dataset)._values[0]\n+    iter_rv._rebuild_on(model._cluster_coordinator._cluster.workers[0])\n+    distributed_iterator = iter_rv._get_values()\n+\n+    # Ensuring the resulting `DistributedIterator` has the right options.\n+    self.assertTrue(distributed_iterator._options.experimental_fetch_to_device)\n+    self.assertEqual(\n+        distributed_iterator._options.experimental_per_replica_buffer_size, 2)\n+\n \n if __name__ == \"__main__\":\n   tf.compat.v1.enable_v2_behavior()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#68d25714cfbb81df2a7231b0961306bfcab08739", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 30 | Lines Deleted: 12 | Files Changed: 1 | Hunks: 11 | Methods Changed: 12 | Complexity Δ (Sum/Max): 7/7 | Churn Δ: 42 | Churn Cumulative: 418 | Contributors (this commit): 3 | Commits (past 90d): 4 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -14,16 +14,15 @@\n # ==============================================================================\n \"\"\"Tests for Keras callbacks in multi-worker training with TF2.\"\"\"\n \n-import tensorflow.compat.v2 as tf\n \n import json\n import os\n \n from absl.testing import parameterized\n-from tensorflow.python.distribute import multi_worker_test_base as test_base\n from keras import callbacks\n from keras.distribute import distributed_file_utils\n from keras.distribute import multi_worker_testing_utils\n+import tensorflow.compat.v2 as tf\n \n \n def checkpoint_exists(filepath):\n@@ -65,10 +64,31 @@ def _model_setup(test_obj, file_format):\n   return model, saving_filepath, train_ds, steps\n \n \n-def _get_task_config():\n+def get_tf_config_task():\n   return json.loads(os.environ['TF_CONFIG'])['task']\n \n \n+def get_tf_config_task():\n+  return json.loads(os.environ['TF_CONFIG'])['task']\n+\n+\n+def get_tf_config_cluster_spec():\n+  return json.loads(os.environ['TF_CONFIG'])['cluster']\n+\n+\n+def get_task_type():\n+  return get_tf_config_task()['type']\n+\n+\n+def get_task_index():\n+  return get_tf_config_task()['index']\n+\n+\n+def is_chief():\n+  return ('chief' not in get_tf_config_cluster_spec() and\n+          get_task_type() == 'worker' and get_task_index() == 0)\n+\n+\n class KerasCallbackMultiProcessTest(parameterized.TestCase, tf.test.TestCase):\n \n   @tf.__internal__.distribute.combinations.generate(\n@@ -91,7 +111,7 @@ class KerasCallbackMultiProcessTest(parameterized.TestCase, tf.test.TestCase):\n       # ensure every worker has a unique path. Note that in normal use case the\n       # saving_filepath will be the same for all workers, but we use different\n       # ones here just to test out chief saves checkpoint but non-chief doesn't.\n-      task_config = _get_task_config()\n+      task_config = get_tf_config_task()\n       saving_filepath = os.path.join(\n           test_obj.get_temp_dir(), 'checkpoint_%s_%d%s' %\n           (task_config['type'], task_config['index'], extension))\n@@ -111,8 +131,7 @@ class KerasCallbackMultiProcessTest(parameterized.TestCase, tf.test.TestCase):\n           ])\n \n       # If it's chief, the model should be saved; if not, the model shouldn't.\n-      test_obj.assertEqual(\n-          checkpoint_exists(saving_filepath), test_base.is_chief())\n+      test_obj.assertEqual(checkpoint_exists(saving_filepath), is_chief())\n \n       # If it's chief, the model should be saved (`write_filepath` should\n       # simply return `saving_filepath`); if not, i.e. for non-chief workers,\n@@ -121,8 +140,7 @@ class KerasCallbackMultiProcessTest(parameterized.TestCase, tf.test.TestCase):\n       test_obj.assertEqual(\n           checkpoint_exists(\n               distributed_file_utils.write_filepath(\n-                  saving_filepath, model._distribution_strategy)),\n-          test_base.is_chief())\n+                  saving_filepath, model._distribution_strategy)), is_chief())\n \n     tf.__internal__.distribute.multi_process_runner.run(\n         proc_model_checkpoint_saves_on_chief_but_not_otherwise,\n@@ -231,7 +249,7 @@ class KerasCallbackMultiProcessTest(parameterized.TestCase, tf.test.TestCase):\n       # ensure every worker has a unique path. Note that in normal use case the\n       # saving_filepath will be the same for all workers, but we use different\n       # ones here just to test out chief saves summaries but non-chief doesn't.\n-      task_config = _get_task_config()\n+      task_config = get_tf_config_task()\n       saving_filepath = os.path.join(\n           test_obj.get_temp_dir(),\n           'logfile_%s_%d' % (task_config['type'], task_config['index']))\n@@ -250,8 +268,7 @@ class KerasCallbackMultiProcessTest(parameterized.TestCase, tf.test.TestCase):\n       # `file_io.list_directory()` since the directory may be created at this\n       # point.\n       test_obj.assertEqual(\n-          bool(tf.io.gfile.listdir(saving_filepath)),\n-          test_base.is_chief())\n+          bool(tf.io.gfile.listdir(saving_filepath)), is_chief())\n \n     tf.__internal__.distribute.multi_process_runner.run(\n         proc_tensorboard_saves_on_chief_but_not_otherwise,\n@@ -266,7 +283,8 @@ class KerasCallbackMultiProcessTest(parameterized.TestCase, tf.test.TestCase):\n       num_epoch = 2\n \n       saving_filepath = os.path.join(\n-          test_obj.get_temp_dir(), 'logfile_%s' % (_get_task_config()['type']))\n+          test_obj.get_temp_dir(),\n+          'logfile_%s' % (get_tf_config_task()['type']))\n \n       saving_filepath_for_temp = os.path.join(saving_filepath, 'workertemp_1')\n       os.mkdir(saving_filepath)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3fd3a0a499d456940de174aa051b9ee36f35afb5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 141 | Lines Deleted: 122 | Files Changed: 14 | Hunks: 74 | Methods Changed: 26 | Complexity Δ (Sum/Max): -6/13 | Churn Δ: 263 | Churn Cumulative: 41881 | Contributors (this commit): 144 | Commits (past 90d): 101 | Contributors (cumulative): 187 | DMM Complexity: 1.0\n\nDIFF:\n@@ -43,7 +43,6 @@ from keras.utils import object_identity\n from keras.utils import tf_contextlib\n from keras.utils import tf_inspect\n from tensorflow.python.platform import tf_logging as logging\n-from tensorflow.python.util import keras_deps\n from tensorflow.python.util.tf_export import keras_export\n from tensorflow.tools.docs import doc_controls\n \n@@ -280,7 +279,7 @@ def clear_session():\n \n # Inject the clear_session function to keras_deps to remove the dependency\n # from TFLite to Keras.\n-keras_deps.register_clear_session_function(clear_session)\n+tf.__internal__.register_clear_session_function(clear_session)\n \n \n @keras_export('keras.backend.manual_variable_initialization')\n@@ -711,7 +710,7 @@ def get_session(op_input_list=()):\n \n # Inject the get_session function to keras_deps to remove the dependency\n # from TFLite to Keras.\n-keras_deps.register_get_session_function(get_session)\n+tf.__internal__.register_get_session_function(get_session)\n \n # Inject the get_session function to tracking_util to avoid the backward\n # dependency from TF to Keras.\n\n@@ -214,6 +214,14 @@ class CallbackList:\n \n     # Performance optimization: determines if batch hooks need to be called.\n     # pylint: disable=protected-access\n+    self._supports_tf_logs = all(\n+        getattr(cb, '_supports_tf_logs', False) for cb in self.callbacks)\n+    self._batch_hooks_support_tf_logs = all(\n+        getattr(cb, '_supports_tf_logs', False)\n+        for cb in self.callbacks\n+        if cb._implements_train_batch_hooks() or cb\n+        ._implements_test_batch_hooks() or cb._implements_predict_batch_hooks())\n+\n     self._should_call_train_batch_hooks = any(\n         cb._implements_train_batch_hooks() for cb in self.callbacks)\n     self._should_call_test_batch_hooks = any(\n@@ -252,6 +260,16 @@ class CallbackList:\n       self._history = History()\n       self.callbacks.append(self._history)\n \n+  def _process_logs(self, logs, is_batch_hook=False):\n+    \"\"\"Turns tensors into numpy arrays or Python scalars if necessary.\"\"\"\n+    if logs is None:\n+      return {}\n+    if self._supports_tf_logs:\n+      return logs\n+    if is_batch_hook and self._batch_hooks_support_tf_logs:\n+      return logs\n+    return tf_utils.sync_to_numpy_or_python_type(logs)\n+\n   def append(self, callback):\n     self.callbacks.append(callback)\n \n@@ -327,19 +345,13 @@ class CallbackList:\n \n   def _call_batch_hook_helper(self, hook_name, batch, logs):\n     \"\"\"Helper function for `on_*_batch_*` methods.\"\"\"\n-    logs = logs or {}\n-    numpy_logs = None\n     if self._check_timing:\n       start_time = time.time()\n \n+    logs = self._process_logs(logs, is_batch_hook=True)\n     for callback in self.callbacks:\n       hook = getattr(callback, hook_name)\n-      if getattr(callback, '_supports_tf_logs', False):\n       hook(batch, logs)\n-      else:\n-        if numpy_logs is None:  # Only convert once.\n-          numpy_logs = tf_utils.sync_to_numpy_or_python_type(logs)\n-        hook(batch, numpy_logs)\n \n     if self._check_timing:\n       if hook_name not in self._hook_times:\n@@ -382,15 +394,9 @@ class CallbackList:\n         logs: Dict. Currently no data is passed to this argument for this method\n           but that may change in the future.\n     \"\"\"\n-    logs = logs or {}\n-    numpy_logs = None\n+    logs = self._process_logs(logs)\n     for callback in self.callbacks:\n-      if getattr(callback, '_supports_tf_logs', False):\n       callback.on_epoch_begin(epoch, logs)\n-      else:\n-        if numpy_logs is None:  # Only convert once.\n-          numpy_logs = tf_utils.sync_to_numpy_or_python_type(logs)\n-        callback.on_epoch_begin(epoch, numpy_logs)\n \n   def on_epoch_end(self, epoch, logs=None):\n     \"\"\"Calls the `on_epoch_end` methods of its callbacks.\n@@ -403,15 +409,9 @@ class CallbackList:\n           validation epoch if validation is performed. Validation result keys\n           are prefixed with `val_`.\n     \"\"\"\n-    logs = logs or {}\n-    numpy_logs = None\n+    logs = self._process_logs(logs)\n     for callback in self.callbacks:\n-      if getattr(callback, '_supports_tf_logs', False):\n       callback.on_epoch_end(epoch, logs)\n-      else:\n-        if numpy_logs is None:  # Only convert once.\n-          numpy_logs = tf_utils.sync_to_numpy_or_python_type(logs)\n-        callback.on_epoch_end(epoch, numpy_logs)\n \n   def on_train_batch_begin(self, batch, logs=None):\n     \"\"\"Calls the `on_train_batch_begin` methods of its callbacks.\n@@ -486,15 +486,9 @@ class CallbackList:\n         logs: Dict. Currently no data is passed to this argument for this method\n           but that may change in the future.\n     \"\"\"\n-    logs = logs or {}\n-    numpy_logs = None\n+    logs = self._process_logs(logs)\n     for callback in self.callbacks:\n-      if getattr(callback, '_supports_tf_logs', False):\n       callback.on_train_begin(logs)\n-      else:\n-        if numpy_logs is None:  # Only convert once.\n-          numpy_logs = tf_utils.sync_to_numpy_or_python_type(logs)\n-        callback.on_train_begin(numpy_logs)\n \n   def on_train_end(self, logs=None):\n     \"\"\"Calls the `on_train_end` methods of its callbacks.\n@@ -503,15 +497,9 @@ class CallbackList:\n         logs: Dict. Currently no data is passed to this argument for this method\n           but that may change in the future.\n     \"\"\"\n-    logs = logs or {}\n-    numpy_logs = None\n+    logs = self._process_logs(logs)\n     for callback in self.callbacks:\n-      if getattr(callback, '_supports_tf_logs', False):\n       callback.on_train_end(logs)\n-      else:\n-        if numpy_logs is None:  # Only convert once.\n-          numpy_logs = tf_utils.sync_to_numpy_or_python_type(logs)\n-        callback.on_train_end(numpy_logs)\n \n   def on_test_begin(self, logs=None):\n     \"\"\"Calls the `on_test_begin` methods of its callbacks.\n@@ -520,15 +508,9 @@ class CallbackList:\n         logs: Dict. Currently no data is passed to this argument for this method\n           but that may change in the future.\n     \"\"\"\n-    logs = logs or {}\n-    numpy_logs = None\n+    logs = self._process_logs(logs)\n     for callback in self.callbacks:\n-      if getattr(callback, '_supports_tf_logs', False):\n       callback.on_test_begin(logs)\n-      else:\n-        if numpy_logs is None:  # Only convert once.\n-          numpy_logs = tf_utils.sync_to_numpy_or_python_type(logs)\n-        callback.on_test_begin(numpy_logs)\n \n   def on_test_end(self, logs=None):\n     \"\"\"Calls the `on_test_end` methods of its callbacks.\n@@ -537,15 +519,9 @@ class CallbackList:\n         logs: Dict. Currently no data is passed to this argument for this method\n           but that may change in the future.\n     \"\"\"\n-    logs = logs or {}\n-    numpy_logs = None\n+    logs = self._process_logs(logs)\n     for callback in self.callbacks:\n-      if getattr(callback, '_supports_tf_logs', False):\n       callback.on_test_end(logs)\n-      else:\n-        if numpy_logs is None:  # Only convert once.\n-          numpy_logs = tf_utils.sync_to_numpy_or_python_type(logs)\n-        callback.on_test_end(numpy_logs)\n \n   def on_predict_begin(self, logs=None):\n     \"\"\"Calls the 'on_predict_begin` methods of its callbacks.\n@@ -554,15 +530,9 @@ class CallbackList:\n         logs: Dict. Currently no data is passed to this argument for this method\n           but that may change in the future.\n     \"\"\"\n-    logs = logs or {}\n-    numpy_logs = None\n+    logs = self._process_logs(logs)\n     for callback in self.callbacks:\n-      if getattr(callback, '_supports_tf_logs', False):\n       callback.on_predict_begin(logs)\n-      else:\n-        if numpy_logs is None:  # Only convert once.\n-          numpy_logs = tf_utils.sync_to_numpy_or_python_type(logs)\n-        callback.on_predict_begin(numpy_logs)\n \n   def on_predict_end(self, logs=None):\n     \"\"\"Calls the `on_predict_end` methods of its callbacks.\n@@ -571,15 +541,9 @@ class CallbackList:\n         logs: Dict. Currently no data is passed to this argument for this method\n           but that may change in the future.\n     \"\"\"\n-    logs = logs or {}\n-    numpy_logs = None\n+    logs = self._process_logs(logs)\n     for callback in self.callbacks:\n-      if getattr(callback, '_supports_tf_logs', False):\n       callback.on_predict_end(logs)\n-      else:\n-        if numpy_logs is None:  # Only convert once.\n-          numpy_logs = tf_utils.sync_to_numpy_or_python_type(logs)\n-        callback.on_predict_end(numpy_logs)\n \n   def __iter__(self):\n     return iter(self.callbacks)\n\n@@ -59,6 +59,14 @@ INPUT_DIM = 3\n NUM_HIDDEN = 5\n BATCH_SIZE = 5\n \n+CALLBACK_HOOKS = [\n+    'on_batch_begin', 'on_batch_end', 'on_epoch_begin', 'on_epoch_end',\n+    'on_predict_batch_begin', 'on_predict_batch_end', 'on_predict_begin',\n+    'on_predict_end', 'on_test_batch_begin', 'on_test_batch_end',\n+    'on_test_begin', 'on_test_end', 'on_train_batch_begin',\n+    'on_train_batch_end', 'on_train_begin', 'on_train_end'\n+]\n+\n \n class Counter(keras.callbacks.Callback):\n   \"\"\"Counts the number of times each callback method was run.\n@@ -70,14 +78,7 @@ class Counter(keras.callbacks.Callback):\n \n   def __init__(self):\n     self.method_counts = collections.defaultdict(int)\n-    methods_to_count = [\n-        'on_batch_begin', 'on_batch_end', 'on_epoch_begin', 'on_epoch_end',\n-        'on_predict_batch_begin', 'on_predict_batch_end', 'on_predict_begin',\n-        'on_predict_end', 'on_test_batch_begin', 'on_test_batch_end',\n-        'on_test_begin', 'on_test_end', 'on_train_batch_begin',\n-        'on_train_batch_end', 'on_train_begin', 'on_train_end'\n-    ]\n-    for method_name in methods_to_count:\n+    for method_name in CALLBACK_HOOKS:\n       setattr(self, method_name,\n               self.wrap_with_counts(method_name, getattr(self, method_name)))\n \n@@ -90,6 +91,17 @@ class Counter(keras.callbacks.Callback):\n     return _call_and_count\n \n \n+class CallAllHooks(keras.callbacks.Callback):\n+  \"\"\"A callback that calls self._run for all hooks\"\"\"\n+\n+  def __init__(self):\n+    for method_name in CALLBACK_HOOKS:\n+      setattr(self, method_name, self._run)\n+\n+  def _run(self, *args, logs=None):\n+    raise NotImplementedError\n+\n+\n def _get_numpy():\n   return np.ones((10, 10)), np.ones((10, 1))\n \n@@ -1666,6 +1678,12 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n       def on_predict_batch_end(self, batch, logs=None):\n         self.predict_batches += 1\n \n+    class MyCallbackWithTFBatchHooks(keras.callbacks.Callback):\n+\n+      def __init__(self):\n+        super(MyCallbackWithTFBatchHooks, self).__init__()\n+        self._supports_tf_logs = True\n+\n     class MyCallbackWithoutBatchHooks(keras.callbacks.Callback):\n \n       def __init__(self):\n@@ -1683,6 +1701,7 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n     self.assertTrue(cb_list._should_call_train_batch_hooks)\n     self.assertTrue(cb_list._should_call_test_batch_hooks)\n     self.assertTrue(cb_list._should_call_predict_batch_hooks)\n+    self.assertFalse(cb_list._batch_hooks_support_tf_logs)\n \n     model.fit(x, y, epochs=2, batch_size=10, callbacks=[my_cb], verbose=0)\n     model.evaluate(x, y, batch_size=10, callbacks=[my_cb], verbose=0)\n@@ -1692,6 +1711,10 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n     self.assertEqual(my_cb.test_batches, 1)\n     self.assertEqual(my_cb.predict_batches, 1)\n \n+    my_cb = MyCallbackWithTFBatchHooks()\n+    cb_list = keras.callbacks.CallbackList([my_cb], verbose=0)\n+    self.assertTrue(cb_list._batch_hooks_support_tf_logs)\n+\n     my_cb = MyCallbackWithoutBatchHooks()\n     cb_list = keras.callbacks.CallbackList([my_cb], verbose=0)\n     self.assertLen(cb_list.callbacks, 1)\n@@ -1703,6 +1726,61 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n     model.evaluate(x, y, batch_size=10, callbacks=[my_cb], verbose=0)\n     model.predict(x, batch_size=10, callbacks=[my_cb], verbose=0)\n \n+  @keras_parameterized.run_all_keras_modes(always_skip_v1=True)\n+  def test_logs_conversion(self):\n+    assert_dict_equal = self.assertDictEqual\n+\n+    class MutateNumpyLogs(CallAllHooks):\n+\n+      def _run(self, *args, logs=None):\n+        logs = logs or args[-1]\n+        logs['numpy'] = 1\n+\n+    class MutateTensorFlowLogs(CallAllHooks):\n+\n+      def __init__(self):\n+        super(MutateTensorFlowLogs, self).__init__()\n+        self._supports_tf_logs = True\n+\n+      def _run(self, *args, logs=None):\n+        logs = logs or args[-1]\n+        logs['tf'] = 2\n+\n+    class AssertNumpyLogs(CallAllHooks):\n+\n+      def _run(self, *args, logs=None):\n+        logs = logs or args[-1]\n+        assert_dict_equal(logs, {'all': 0, 'numpy': 1, 'tf': 2})\n+\n+    class AssertTensorFlowLogs(AssertNumpyLogs):\n+\n+      def __init__(self):\n+        super(AssertTensorFlowLogs, self).__init__()\n+        self._supports_tf_logs = True\n+\n+    cb_list = keras.callbacks.CallbackList([\n+        MutateNumpyLogs(),\n+        MutateTensorFlowLogs(),\n+        AssertNumpyLogs(),\n+        AssertTensorFlowLogs()\n+    ])\n+\n+    assert len(cb_list.callbacks) == 4\n+    cb_list.on_epoch_begin(0, logs={'all': 0})\n+    cb_list.on_epoch_end(0, logs={'all': 0})\n+    cb_list.on_predict_batch_begin(0, logs={'all': 0})\n+    cb_list.on_predict_batch_end(0, logs={'all': 0})\n+    cb_list.on_predict_begin(logs={'all': 0})\n+    cb_list.on_predict_end(logs={'all': 0})\n+    cb_list.on_test_batch_begin(0, logs={'all': 0})\n+    cb_list.on_test_batch_end(0, logs={'all': 0})\n+    cb_list.on_test_begin(logs={'all': 0})\n+    cb_list.on_test_end(logs={'all': 0})\n+    cb_list.on_train_batch_begin(0, logs={'all': 0})\n+    cb_list.on_train_batch_end(0, logs={'all': 0})\n+    cb_list.on_train_begin(logs={'all': 0})\n+    cb_list.on_train_end(logs={'all': 0})\n+\n   @keras_parameterized.run_all_keras_modes(always_skip_v1=True)\n   def test_implements_batch_hooks_override(self):\n \n\n@@ -23,7 +23,6 @@ import numpy as np\n \n import keras\n from tensorflow.python.distribute import multi_worker_test_base\n-from tensorflow.python.distribute import strategy_combinations\n from tensorflow.python.distribute.cluster_resolver import SimpleClusterResolver\n from keras import backend\n from keras import testing_utils\n@@ -233,7 +232,7 @@ def all_strategy_minus_default_and_tpu_combinations():\n           tf.__internal__.distribute.combinations.one_device_strategy_gpu,\n           tf.__internal__.distribute.combinations.mirrored_strategy_with_gpu_and_cpu,\n           tf.__internal__.distribute.combinations.mirrored_strategy_with_two_gpus,\n-          strategy_combinations.mirrored_strategy_with_two_gpus_no_merge_call,\n+          tf.__internal__.distribute.combinations.mirrored_strategy_with_two_gpus_no_merge_call,\n       ],\n       mode=['graph', 'eager'])\n \n@@ -1289,7 +1288,7 @@ class TestDistributionStrategyWithDatasets(tf.test.TestCase,\n           distribution=[\n               tf.__internal__.distribute.combinations.mirrored_strategy_with_gpu_and_cpu,\n               tf.__internal__.distribute.combinations.mirrored_strategy_with_two_gpus,\n-              strategy_combinations\n+              tf.__internal__.distribute.combinations\n               .mirrored_strategy_with_two_gpus_no_merge_call,\n           ],\n           mode=['graph', 'eager']))\n@@ -2027,7 +2026,7 @@ class TestDistributionStrategyWithKerasModels(tf.test.TestCase,\n           distribution=[\n               tf.__internal__.distribute.combinations.mirrored_strategy_with_gpu_and_cpu,\n               tf.__internal__.distribute.combinations.mirrored_strategy_with_two_gpus,\n-              strategy_combinations\n+              tf.__internal__.distribute.combinations\n               .mirrored_strategy_with_two_gpus_no_merge_call,\n           ],\n           mode=['graph', 'eager'],\n@@ -2185,7 +2184,7 @@ class TestDistributionStrategyWithKerasModels(tf.test.TestCase,\n               tf.__internal__.distribute.combinations.one_device_strategy_gpu,\n               tf.__internal__.distribute.combinations.mirrored_strategy_with_gpu_and_cpu,\n               tf.__internal__.distribute.combinations.mirrored_strategy_with_two_gpus,\n-              strategy_combinations\n+              tf.__internal__.distribute.combinations\n               .mirrored_strategy_with_two_gpus_no_merge_call,\n           ],\n           mode=['eager']))\n\n@@ -21,7 +21,6 @@ import functools\n \n import numpy as np\n from tensorflow.python.distribute import distribute_coordinator_context as dc_context\n-from tensorflow.python.distribute import multi_worker_util\n from keras import backend\n from keras import callbacks\n from keras import metrics as metrics_module\n@@ -383,13 +382,7 @@ def _wait_for_variable_initialization(session):\n \n def init_restore_or_wait_for_variables():\n   \"\"\"Initialize or restore variables or wait for variables to be initialized.\"\"\"\n-  session = backend._get_session()  # pylint: disable=protected-access\n-  if not multi_worker_util.has_worker_context(\n-  ) or multi_worker_util.should_load_checkpoint():\n-    # TODO(yuefengz): if checkpoints exist, restore from checkpoint.\n-    backend._initialize_variables(session)  # pylint: disable=protected-access\n-  else:\n-    _wait_for_variable_initialization(session)\n+  backend._initialize_variables(backend._get_session())  # pylint: disable=protected-access\n \n \n def validate_inputs(x, y):\n\n@@ -17,7 +17,6 @@\n import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n-from tensorflow.python.distribute import strategy_combinations\n from keras import metrics\n \n \n@@ -71,7 +70,7 @@ def all_combinations():\n           tf.__internal__.distribute.combinations.one_device_strategy,\n           tf.__internal__.distribute.combinations.mirrored_strategy_with_gpu_and_cpu,\n           tf.__internal__.distribute.combinations.mirrored_strategy_with_two_gpus,\n-          strategy_combinations.mirrored_strategy_with_two_gpus_no_merge_call,\n+          tf.__internal__.distribute.combinations.mirrored_strategy_with_two_gpus_no_merge_call,\n       ],\n       mode=[\"graph\"])\n \n\n@@ -18,7 +18,6 @@ import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np\n-from tensorflow.python.distribute import strategy_combinations\n from keras.engine import sequential\n from keras.layers import core\n from keras.optimizer_v2 import adagrad\n@@ -35,7 +34,7 @@ def strategy_combinations_eager_data_fn():\n           tf.__internal__.distribute.combinations.one_device_strategy_gpu,\n           tf.__internal__.distribute.combinations.mirrored_strategy_with_gpu_and_cpu,\n           tf.__internal__.distribute.combinations.mirrored_strategy_with_two_gpus,\n-          strategy_combinations.mirrored_strategy_with_two_gpus_no_merge_call,\n+          tf.__internal__.distribute.combinations.mirrored_strategy_with_two_gpus_no_merge_call,\n           tf.__internal__.distribute.combinations.multi_worker_mirrored_2x1_cpu,\n           tf.__internal__.distribute.combinations.multi_worker_mirrored_2x1_gpu,\n           tf.__internal__.distribute.combinations.multi_worker_mirrored_2x2_gpu,\n\n@@ -18,7 +18,6 @@ import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy\n-from tensorflow.python.distribute import strategy_combinations\n from keras.distribute import optimizer_combinations\n from keras.distribute.test_example import batchnorm_example\n from keras.distribute.test_example import minimize_loss_example\n@@ -289,7 +288,7 @@ class MinimizeLossStepTest(tf.test.TestCase, parameterized.TestCase):\n                   tf.__internal__.distribute.combinations.one_device_strategy,\n                   tf.__internal__.distribute.combinations.mirrored_strategy_with_gpu_and_cpu,\n                   tf.__internal__.distribute.combinations.mirrored_strategy_with_two_gpus,\n-                  strategy_combinations\n+                  tf.__internal__.distribute.combinations\n                   .mirrored_strategy_with_two_gpus_no_merge_call,\n               ]),\n               tf.__internal__.test.combinations.times(\n\n@@ -15,8 +15,6 @@\n \"\"\"Strategy and optimizer combinations for combinations.combine().\"\"\"\n \n import tensorflow.compat.v2 as tf\n-\n-from tensorflow.python.distribute import strategy_combinations as strategy_combinations_base\n from keras.optimizer_v2 import adadelta as adadelta_keras_v2\n from keras.optimizer_v2 import adagrad as adagrad_keras_v2\n from keras.optimizer_v2 import adam as adam_keras_v2\n@@ -77,7 +75,7 @@ def distributions_and_v1_optimizers():\n           tf.__internal__.distribute.combinations.one_device_strategy,\n           tf.__internal__.distribute.combinations.mirrored_strategy_with_gpu_and_cpu,\n           tf.__internal__.distribute.combinations.mirrored_strategy_with_two_gpus,\n-          strategy_combinations_base\n+          tf.__internal__.distribute.combinations\n           .mirrored_strategy_with_two_gpus_no_merge_call,\n       ],\n       optimizer_fn=optimizers_v1)\n@@ -90,7 +88,7 @@ def distributions_and_v2_optimizers():\n           tf.__internal__.distribute.combinations.one_device_strategy,\n           tf.__internal__.distribute.combinations.mirrored_strategy_with_gpu_and_cpu,\n           tf.__internal__.distribute.combinations.mirrored_strategy_with_two_gpus,\n-          strategy_combinations_base\n+          tf.__internal__.distribute.combinations\n           .mirrored_strategy_with_two_gpus_no_merge_call,\n       ],\n       optimizer_fn=optimizers_v2)\n@@ -103,7 +101,7 @@ def distributions_and_v1_and_v2_optimizers():\n           tf.__internal__.distribute.combinations.one_device_strategy,\n           tf.__internal__.distribute.combinations.mirrored_strategy_with_gpu_and_cpu,\n           tf.__internal__.distribute.combinations.mirrored_strategy_with_two_gpus,\n-          strategy_combinations_base\n+          tf.__internal__.distribute.combinations\n           .mirrored_strategy_with_two_gpus_no_merge_call,\n       ],\n       optimizer_fn=optimizers_v1_and_v2)\n\n@@ -16,13 +16,11 @@\n \n import tensorflow.compat.v2 as tf\n \n-from tensorflow.python.distribute import strategy_combinations\n-\n \n multidevice_strategies = [\n     tf.__internal__.distribute.combinations.mirrored_strategy_with_gpu_and_cpu,\n     tf.__internal__.distribute.combinations.mirrored_strategy_with_two_gpus,\n-    strategy_combinations.mirrored_strategy_with_two_gpus_no_merge_call,\n+    tf.__internal__.distribute.combinations.mirrored_strategy_with_two_gpus_no_merge_call,\n     tf.__internal__.distribute.combinations.tpu_strategy,\n ]\n \n@@ -30,7 +28,7 @@ multiworker_strategies = [\n     tf.__internal__.distribute.combinations.multi_worker_mirrored_2x1_cpu,\n     tf.__internal__.distribute.combinations.multi_worker_mirrored_2x1_gpu,\n     tf.__internal__.distribute.combinations.multi_worker_mirrored_2x2_gpu,\n-    strategy_combinations.multi_worker_mirrored_2x2_gpu_no_merge_call\n+    tf.__internal__.distribute.combinations.multi_worker_mirrored_2x2_gpu_no_merge_call\n ]\n \n strategies_minus_default_minus_tpu = [\n@@ -38,7 +36,7 @@ strategies_minus_default_minus_tpu = [\n     tf.__internal__.distribute.combinations.one_device_strategy_gpu,\n     tf.__internal__.distribute.combinations.mirrored_strategy_with_gpu_and_cpu,\n     tf.__internal__.distribute.combinations.mirrored_strategy_with_two_gpus,\n-    strategy_combinations.mirrored_strategy_with_two_gpus_no_merge_call,\n+    tf.__internal__.distribute.combinations.mirrored_strategy_with_two_gpus_no_merge_call,\n     tf.__internal__.distribute.combinations.central_storage_strategy_with_gpu_and_cpu\n ]\n \n@@ -48,7 +46,7 @@ strategies_minus_tpu = [\n     tf.__internal__.distribute.combinations.one_device_strategy_gpu,\n     tf.__internal__.distribute.combinations.mirrored_strategy_with_gpu_and_cpu,\n     tf.__internal__.distribute.combinations.mirrored_strategy_with_two_gpus,\n-    strategy_combinations.mirrored_strategy_with_two_gpus_no_merge_call,\n+    tf.__internal__.distribute.combinations.mirrored_strategy_with_two_gpus_no_merge_call,\n     tf.__internal__.distribute.combinations.central_storage_strategy_with_gpu_and_cpu\n ]\n \n@@ -56,7 +54,7 @@ multi_worker_mirrored_strategies = [\n     tf.__internal__.distribute.combinations.multi_worker_mirrored_2x1_cpu,\n     tf.__internal__.distribute.combinations.multi_worker_mirrored_2x1_gpu,\n     tf.__internal__.distribute.combinations.multi_worker_mirrored_2x2_gpu,\n-    strategy_combinations.multi_worker_mirrored_2x2_gpu_no_merge_call\n+    tf.__internal__.distribute.combinations.multi_worker_mirrored_2x2_gpu_no_merge_call\n ]\n \n tpu_strategies = [\n\n@@ -20,22 +20,18 @@ import os\n import sys\n \n from absl.testing import parameterized\n-from tensorflow.python.distribute import multi_worker_test_base as test_base\n from keras import callbacks\n from keras.distribute import multi_worker_testing_utils\n \n \n-class ModelCheckpointTest(test_base.IndependentWorkerTestBase,\n-                          parameterized.TestCase):\n+class ModelCheckpointTest(tf.test.TestCase, parameterized.TestCase):\n \n   @tf.__internal__.distribute.combinations.generate(\n       tf.__internal__.test.combinations.combine(\n-          mode=['graph'],\n-          required_gpus=[0, 1],\n+          mode=['eager'],\n           file_format=['h5', 'tf'],\n           save_weights_only=[True, False]))\n   def testCheckpointExists(self, file_format, save_weights_only):\n-    with self.cached_session():\n     train_ds, _ = multi_worker_testing_utils.mnist_synthetic_dataset(64, 2)\n     model = multi_worker_testing_utils.get_mnist_model((28, 28, 1))\n     saving_dir = self.get_temp_dir()\n@@ -45,13 +41,11 @@ class ModelCheckpointTest(test_base.IndependentWorkerTestBase,\n             filepath=saving_filepath, save_weights_only=save_weights_only)\n     ]\n     self.assertFalse(tf.io.gfile.exists(saving_filepath))\n-      model.fit(\n-          x=train_ds, epochs=2, steps_per_epoch=2, callbacks=callbacks_list)\n+    model.fit(x=train_ds, epochs=2, steps_per_epoch=2, callbacks=callbacks_list)\n     tf_saved_model_exists = tf.io.gfile.exists(saving_filepath)\n-      tf_weights_only_checkpoint_exists = tf.io.gfile.exists(\n-          saving_filepath + '.index')\n-      self.assertTrue(\n-          tf_saved_model_exists or tf_weights_only_checkpoint_exists)\n+    tf_weights_only_checkpoint_exists = tf.io.gfile.exists(saving_filepath +\n+                                                               '.index')\n+    self.assertTrue(tf_saved_model_exists or tf_weights_only_checkpoint_exists)\n \n \n if __name__ == '__main__':\n\n@@ -22,7 +22,6 @@ from keras import backend\n from keras.utils import control_flow_util\n from keras.utils import tf_inspect\n from keras.utils import tf_utils\n-from tensorflow.python.util import keras_deps\n from tensorflow.python.util.tf_export import keras_export\n \n _call_context = threading.local()\n@@ -418,7 +417,7 @@ def call_context():\n \n # Inject the call_context function to keras_deps to remove the dependency\n # from TFLite to Keras.\n-keras_deps.register_call_context_function(call_context)\n+tf.__internal__.register_call_context_function(call_context)\n \n \n class CallContext(object):\n\n@@ -2102,7 +2102,8 @@ class SeparableConv2D(SeparableConv):\n     strides: An integer or tuple/list of 2 integers,\n       specifying the strides of the convolution along the height and width.\n       Can be a single integer to specify the same value for\n-      all spatial dimensions.\n+      all spatial dimensions. Current implementation only supports equal \n+      length strides in the row and column dimensions.\n       Specifying any stride value != 1 is incompatible with specifying\n       any `dilation_rate` value != 1.\n     padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n\n@@ -22,7 +22,6 @@ from keras.saving.saved_model import load_context\n from keras.saving.saved_model import save as saved_model_save\n from keras.utils import generic_utils\n from keras.utils.io_utils import path_to_string\n-from tensorflow.python.util import keras_deps\n from tensorflow.python.util.tf_export import keras_export\n \n # pylint: disable=g-import-not-at-top\n@@ -211,4 +210,4 @@ def load_model(filepath, custom_objects=None, compile=True, options=None):  # py\n \n # Inject the load_model function to keras_deps to remove the dependency\n # from TFLite to Keras.\n-keras_deps.register_load_model_function(load_model)\n+tf.__internal__.register_load_model_function(load_model)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
