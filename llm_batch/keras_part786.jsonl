{"custom_id": "keras#92dcd8fd137455976d8a3880339030a894626aea", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 93 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 4 | Methods Changed: 6 | Complexity Δ (Sum/Max): 9/6 | Churn Δ: 93 | Churn Cumulative: 2637 | Contributors (this commit): 10 | Commits (past 90d): 17 | Contributors (cumulative): 16 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1840,3 +1840,57 @@ def ctc_loss(target, output, target_length, output_length, mask_index=0):\n     return backend.nn.ctc_loss(\n         target, output, target_length, output_length, mask_index\n     )\n+\n+\n+class Normalize(Operation):\n+    def __init__(self, axis=-1, order=2):\n+        super().__init__()\n+        self.axis = axis\n+        self.order = order\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(shape=x.shape)\n+\n+    def call(self, x):\n+        return _normalize(x, self.order, self.axis)\n+\n+\n+@keras_export(\n+    [\n+        \"keras.ops.normalize\",\n+        \"keras.ops.nn.normalize\",\n+    ]\n+)\n+def normalize(x, axis=-1, order=2):\n+    \"\"\"Perform Lp normalization of a tensor over the specified axis.\n+\n+    It is defined as: `normalize(x) = x / max(norm(x), epsilon)`.\n+\n+    Args:\n+        x: Input tensor.\n+        axis: The axis or axes along which to perform normalization. Default: 1.\n+        order: The exponent value in the norm formulation. Default: 2.\n+\n+    Returns:\n+        The normalized array.\n+\n+    Example:\n+\n+    >>> x = keras.ops.convert_to_tensor([[1, 2, 3], [4, 5, 6]])\n+    >>> x_norm = keras.ops.math.normalize(x)\n+    >>> print(x_norm)\n+    array([[0.26726124 0.5345225  0.8017837 ]\n+           [0.45584232 0.5698029  0.68376344]], shape=(2, 3), dtype=float32)\n+\n+    \"\"\"\n+    if any_symbolic_tensors((x,)):\n+        return Normalize(axis, order).symbolic_call(x)\n+    return _normalize(x, axis, order)\n+\n+\n+def _normalize(x, axis=-1, order=2):\n+    x = backend.convert_to_tensor(x)\n+    epsilon = backend.config.epsilon()\n+    norm = backend.linalg.norm(x, ord=order, axis=axis, keepdims=True)\n+    denom = backend.numpy.maximum(norm, epsilon)\n+    return backend.numpy.divide(x, denom)\n\n@@ -607,6 +607,10 @@ class NNOpsDynamicShapeTest(testing.TestCase, parameterized.TestCase):\n             scale=KerasTensor([3]),\n         )\n \n+    def test_normalize(self):\n+        x = KerasTensor([None, 2, 3])\n+        self.assertEqual(knn.normalize(x).shape, (None, 2, 3))\n+\n \n class NNOpsStaticShapeTest(testing.TestCase):\n     def test_relu(self):\n@@ -1049,6 +1053,10 @@ class NNOpsStaticShapeTest(testing.TestCase):\n         y_lengths = KerasTensor([10], dtype=\"int32\")\n         self.assertEqual(knn.ctc_loss(x, y, x_lengths, y_lengths).shape, (10,))\n \n+    def test_normalize(self):\n+        x = KerasTensor([1, 2, 3])\n+        self.assertEqual(knn.normalize(x).shape, (1, 2, 3))\n+\n \n class NNOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n     def test_relu(self):\n@@ -1844,6 +1852,37 @@ class NNOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         result = knn.ctc_loss(labels, outputs, label_length, output_length)\n         self.assertAllClose(result, np.array([3.4411672, 1.91680186]))\n \n+    def test_normalize(self):\n+        x = np.array([[1, 2, 3], [1, 2, 3]], dtype=np.float32)\n+        self.assertAllClose(\n+            knn.normalize(x, axis=None),\n+            [\n+                [0.18898225, 0.3779645, 0.56694674],\n+                [0.18898225, 0.3779645, 0.56694674],\n+            ],\n+        )\n+        self.assertAllClose(\n+            knn.normalize(x, axis=0),\n+            [\n+                [0.70710677, 0.70710677, 0.70710677],\n+                [0.70710677, 0.70710677, 0.70710677],\n+            ],\n+        )\n+        self.assertAllClose(\n+            knn.normalize(x, axis=-1),\n+            [\n+                [0.26726124, 0.53452247, 0.8017837],\n+                [0.26726124, 0.53452247, 0.8017837],\n+            ],\n+        )\n+        self.assertAllClose(\n+            knn.normalize(x, order=3),\n+            [\n+                [0.30285344, 0.6057069, 0.9085603],\n+                [0.30285344, 0.6057069, 0.9085603],\n+            ],\n+        )\n+\n \n class TestLogitRecovery(testing.TestCase):\n     def test_logit_recovery_binary_crossentropy(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9a1328d12bcc7f374d567b5ef0f13c21b265a8fc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 20 | Files Changed: 2 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): -1/3 | Churn Δ: 33 | Churn Cumulative: 646 | Contributors (this commit): 9 | Commits (past 90d): 13 | Contributors (cumulative): 10 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1862,14 +1862,16 @@ class Normalize(Operation):\n     ]\n )\n def normalize(x, axis=-1, order=2):\n-    \"\"\"Perform Lp normalization of a tensor over the specified axis.\n+    \"\"\"Normalizes `x` over the specified axis.\n \n     It is defined as: `normalize(x) = x / max(norm(x), epsilon)`.\n \n     Args:\n         x: Input tensor.\n-        axis: The axis or axes along which to perform normalization. Default: 1.\n-        order: The exponent value in the norm formulation. Default: 2.\n+        axis: The axis or axes along which to perform normalization.\n+            Default to -1.\n+        order: The exponent value in the norm formulation.\n+            Defaults to 2.\n \n     Returns:\n         The normalized array.\n@@ -1889,8 +1891,14 @@ def normalize(x, axis=-1, order=2):\n \n \n def _normalize(x, axis=-1, order=2):\n+    if not isinstance(order, int) or not order >= 1:\n+        raise ValueError(\n+            f\"Argument `order` must be an int >= 1. Received: order={order}\"\n+        )\n     x = backend.convert_to_tensor(x)\n-    epsilon = backend.config.epsilon()\n+    if len(x.shape) == 0:\n+        x = backend.numpy.expand_dims(x, axis=0)\n+    epsilon = backend.epsilon()\n     norm = backend.linalg.norm(x, ord=order, axis=axis, keepdims=True)\n     denom = backend.numpy.maximum(norm, epsilon)\n     return backend.numpy.divide(x, denom)\n\n@@ -21,10 +21,6 @@ def normalize(x, axis=-1, order=2):\n     \"\"\"\n     from keras import ops\n \n-    if not isinstance(order, int) or not order >= 1:\n-        raise ValueError(\n-            \"Argument `order` must be an int >= 1. \" f\"Received: order={order}\"\n-        )\n     if isinstance(x, np.ndarray):\n         # NumPy input\n         norm = np.atleast_1d(np.linalg.norm(x, order, axis))\n@@ -35,18 +31,7 @@ def normalize(x, axis=-1, order=2):\n         return x / np.expand_dims(norm, axis)\n \n     # Backend tensor input\n-    if len(x.shape) == 0:\n-        x = ops.expand_dims(x, axis=0)\n-    epsilon = backend.epsilon()\n-    if order == 2:\n-        power_sum = ops.sum(ops.square(x), axis=axis, keepdims=True)\n-        norm = ops.reciprocal(ops.sqrt(ops.maximum(power_sum, epsilon)))\n-    else:\n-        power_sum = ops.sum(ops.power(x, order), axis=axis, keepdims=True)\n-        norm = ops.reciprocal(\n-            ops.power(ops.maximum(power_sum, epsilon), 1.0 / order)\n-        )\n-    return ops.multiply(x, norm)\n+    return ops.nn.normalize(x, axis=axis, order=order)\n \n \n @keras_export(\"keras.utils.to_categorical\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0d7523ffd1f855fe062d027b24d0a7b66b09c7dc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 26 | Lines Deleted: 5 | Files Changed: 3 | Hunks: 5 | Methods Changed: 4 | Complexity Δ (Sum/Max): 6/6 | Churn Δ: 31 | Churn Cumulative: 676 | Contributors (this commit): 7 | Commits (past 90d): 14 | Contributors (cumulative): 10 | DMM Complexity: 1.0\n\nDIFF:\n@@ -199,6 +199,15 @@ class DeviceMesh:\n     def devices(self):\n         return self._devices\n \n+    def __repr__(self):\n+        return (\n+            f\"<{self.__class__.__name__} \"\n+            f\"shape={self.shape}, axis_names={self.axis_names}>\"\n+        )\n+\n+    def __str__(self):\n+        return self.__repr__()\n+\n \n @keras_export(\"keras.distribution.TensorLayout\")\n class TensorLayout:\n@@ -254,6 +263,15 @@ class TensorLayout:\n                     f\"names: {valid_axis_names}, Got {axis_names}\"\n                 )\n \n+    def __repr__(self):\n+        return (\n+            f\"<{self.__class__.__name__} \"\n+            f\"axes={self.axes}, device_mesh={self.device_mesh}>\"\n+        )\n+\n+    def __str__(self):\n+        return self.__repr__()\n+\n \n class Distribution:\n     \"\"\"Base class for variable distribution strategies.\n@@ -338,6 +356,12 @@ class Distribution:\n         \"\"\"\n         raise NotImplementedError()\n \n+    def __repr__(self):\n+        return f\"<{self.__class__.__name__} device_mesh={self.device_mesh}>\"\n+\n+    def __str__(self):\n+        return self.__repr__()\n+\n \n @keras_export(\"keras.distribution.DataParallel\")\n class DataParallel(Distribution):\n\n@@ -1260,10 +1260,7 @@ class Layer(BackendLayer, Operation):\n         )\n \n     def __str__(self):\n-        return (\n-            f\"<{self.__class__.__name__} \"\n-            f\"name={self.name}, built={self.built}>\"\n-        )\n+        return self.__repr__()\n \n     def __setattr__(self, name, value):\n         # Track Variables, Layers, Metrics, SeedGenerators.\n\n@@ -222,4 +222,4 @@ class Metric:\n         return f\"<{self.__class__.__name__} \" f\"name={self.name}>\"\n \n     def __str__(self):\n-        return f\"<{self.__class__.__name__} \" f\"name={self.name}>\"\n+        return self.__repr__()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f38b96c6774b9be63d7ee7cd6530c9ddd9654293", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 306 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -142,7 +142,7 @@ def distribute_data_input(inputs, layout):\n                 f\"{num_split}\"\n             )\n         global_batch_size = per_process_batch_size * jax.process_count()\n-        per_replica_batches = np.split(inputs, num_split, axis=0)\n+        per_replica_batches = jax.numpy.split(inputs, num_split, axis=0)\n     elif mesh_rank == 2:\n         # Data+Model parallel\n         # In this case, we need to check if the mesh batch dim shape is large\n@@ -164,7 +164,9 @@ def distribute_data_input(inputs, layout):\n             global_batch_size = per_process_batch_size * (\n                 mesh_batch_dim_size // local_device_count\n             )\n-            per_replica_batches = np.split(inputs, local_device_count, axis=0)\n+            per_replica_batches = jax.numpy.split(\n+                inputs, local_device_count, axis=0\n+            )\n     else:\n         raise ValueError(\n             \"Only 1D or 2D mesh is supported at the moment. \"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#02c1a4118a51be1bd076324fb4849e7353ee2544", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 433 | Contributors (this commit): 6 | Commits (past 90d): 13 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -946,9 +946,9 @@ def _distribute_data(data):\n             layout = distribution.get_data_layout(d.shape)\n             return jax_distribution_lib.distribute_data_input(d, layout)\n \n-        return jax.tree_util.tree_map(distribute_single_value, data)\n+        return tree.map_structure(distribute_single_value, data)\n     else:\n-        return jax.tree_util.tree_map(jax.device_put, data)\n+        return tree.map_structure(jax.device_put, data)\n \n \n class JAXEpochIterator(EpochIterator):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e6e62405fa1b4444102601636d871610d91e5783", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 19 | Contributors (this commit): 1 | Commits (past 90d): 5 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -1,7 +1,7 @@\n from keras.api_export import keras_export\n \n # Unique source of truth for the version number.\n-__version__ = \"3.0.4\"\n+__version__ = \"3.0.5\"\n \n \n @keras_export(\"keras.version\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d5a452155a415d5fcbe568eb2a8441f64e57aa90", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 21 | Contributors (this commit): 1 | Commits (past 90d): 6 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -1,7 +1,7 @@\n from keras.api_export import keras_export\n \n # Unique source of truth for the version number.\n-__version__ = \"3.0.5\"\n+__version__ = \"3.1.0\"\n \n \n @keras_export(\"keras.version\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#da06a0c922957c4a9613c9d213cb013e569969fc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 59 | Lines Deleted: 8 | Files Changed: 2 | Hunks: 7 | Methods Changed: 7 | Complexity Δ (Sum/Max): 4/3 | Churn Δ: 67 | Churn Cumulative: 4106 | Contributors (this commit): 12 | Commits (past 90d): 3 | Contributors (cumulative): 21 | DMM Complexity: 1.0\n\nDIFF:\n@@ -107,17 +107,30 @@ class CategoryEncoding(TFDataLayer):\n         self._allow_non_tensor_positional_args = True\n         self._convert_input_args = False\n \n-    def _count(self, inputs, axis=-1):\n+    def _count(self, inputs, axis=-1, count_weights=None):\n         reduction_axis = 1 if len(inputs.shape) > 1 else 0\n-        outputs = self.backend.numpy.sum(\n-            self.backend.nn.one_hot(\n+\n+        one_hot_encoding = self.backend.nn.one_hot(\n             inputs, self.num_tokens, axis=axis, dtype=self.dtype\n-            ),\n+        )\n+        if count_weights is not None:\n+            split_weights = self.backend.numpy.split(\n+                count_weights,\n+                count_weights.shape[reduction_axis],\n+                reduction_axis,\n+            )\n+            stacked_weights = self.backend.numpy.stack(\n+                split_weights, axis=reduction_axis\n+            )\n+            one_hot_encoding = one_hot_encoding * stacked_weights\n+\n+        outputs = self.backend.numpy.sum(\n+            one_hot_encoding,\n             axis=reduction_axis,\n         )\n         return outputs\n \n-    def _encode(self, inputs):\n+    def _encode(self, inputs, count_weights=None):\n         if self.output_mode == \"multi_hot\":\n             outputs = self.backend.nn.multi_hot(\n                 inputs, self.num_tokens, dtype=self.dtype\n@@ -127,7 +140,7 @@ class CategoryEncoding(TFDataLayer):\n                 inputs, self.num_tokens, dtype=self.dtype\n             )\n         elif self.output_mode == \"count\":\n-            outputs = self._count(inputs)\n+            outputs = self._count(inputs, count_weights=count_weights)\n \n         return outputs\n \n@@ -147,6 +160,15 @@ class CategoryEncoding(TFDataLayer):\n         base_config = super().get_config()\n         return {**base_config, **config}\n \n-    def call(self, inputs):\n-        outputs = self._encode(inputs)\n+    def call(self, inputs, count_weights=None):\n+        if count_weights is not None:\n+            if self.output_mode != \"count\":\n+                raise ValueError(\n+                    \"`count_weights` is not used when `output_mode` is not \"\n+                    \"`'count'`. Received `count_weights={count_weights}`.\"\n+                )\n+            count_weights = self.backend.convert_to_tensor(\n+                count_weights, dtype=self.compute_dtype\n+            )\n+        outputs = self._encode(inputs, count_weights)\n         return backend_utils.convert_tf_tensor(outputs)\n\n@@ -25,6 +25,35 @@ class CategoryEncodingTest(testing.TestCase):\n         self.assertEqual(expected_output_shape, output.shape)\n         self.assertEqual(\"float32\", output.dtype)\n \n+    def test_count_weighted_output(self):\n+        input_array = np.array([[0, 1], [0, 0], [1, 2], [3, 1]])\n+        count_weights = np.array(\n+            [[0.1, 0.2], [0.1, 0.1], [0.2, 0.3], [0.4, 0.2]]\n+        )\n+        expected_output = np.array(\n+            [\n+                [0.1, 0.2, 0.0, 0.0],\n+                [0.2, 0.0, 0.0, 0.0],\n+                [0.0, 0.2, 0.3, 0.0],\n+                [0.0, 0.2, 0.0, 0.4],\n+            ]\n+        )\n+\n+        num_tokens = 4\n+        expected_output_shape = (num_tokens, num_tokens)\n+\n+        layer = layers.CategoryEncoding(num_tokens=4, output_mode=\"count\")\n+        int_data = layer(input_array, count_weights=count_weights)\n+        self.assertEqual(expected_output_shape, int_data.shape)\n+        self.assertAllClose(int_data, expected_output)\n+\n+        # Test symbolic call.\n+        output = layer(\n+            layers.Input(batch_shape=input_array.shape, dtype=\"int32\")\n+        )\n+        self.assertEqual(expected_output_shape, output.shape)\n+        self.assertEqual(\"float32\", output.dtype)\n+\n     def test_batched_count_output(self):\n         input_array = np.array([[1, 2, 3, 1], [0, 3, 1, 0]])\n         expected_output = np.array([[0, 2, 1, 1, 0, 0], [2, 1, 0, 1, 0, 0]])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#56124f0eea96272734aca70f1acf88f2de2b304d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 175 | Lines Deleted: 3 | Files Changed: 3 | Hunks: 13 | Methods Changed: 13 | Complexity Δ (Sum/Max): 18/16 | Churn Δ: 178 | Churn Cumulative: 335 | Contributors (this commit): 4 | Commits (past 90d): 4 | Contributors (cumulative): 6 | DMM Complexity: 0.5087719298245614\n\nDIFF:\n@@ -7,15 +7,20 @@ import tree\n from keras import backend\n from keras import ops\n from keras.backend.common import global_state\n+from keras.layers.core.input_layer import Input\n+from keras.layers.core.input_layer import InputLayer\n from keras.layers.input_spec import InputSpec\n from keras.layers.layer import Layer\n from keras.legacy.saving import saving_utils\n from keras.legacy.saving import serialization as legacy_serialization\n from keras.models.model import Model\n from keras.ops.function import Function\n+from keras.ops.function import _build_map\n from keras.ops.function import make_node_key\n+from keras.ops.node import Node\n from keras.saving import serialization_lib\n from keras.utils import tracking\n+from keras.utils.nest import pack_sequence_as\n \n \n class Functional(Function, Model):\n@@ -148,6 +153,9 @@ class Functional(Function, Model):\n \n         trainable = kwargs.pop(\"trainable\", None)\n \n+        if not all([is_input_keras_tensor(t) for t in tree.flatten(inputs)]):\n+            inputs, outputs = clone_graph_nodes(inputs, outputs)\n+\n         Function.__init__(self, inputs, outputs, name=name, **kwargs)\n \n         if trainable is not None:\n@@ -666,3 +674,127 @@ def deserialize_node(node_data, created_layers):\n     args = tree.map_structure(convert_revived_tensor, args)\n     kwargs = tree.map_structure(convert_revived_tensor, kwargs)\n     return args, kwargs\n+\n+\n+def is_input_keras_tensor(x):\n+    (\n+        operation,\n+        node_index,\n+        _,\n+    ) = x._keras_history\n+    node = operation._inbound_nodes[node_index]\n+    return node.is_input\n+\n+\n+def clone_single_keras_tensor(x):\n+    return backend.KerasTensor(\n+        shape=x.shape, dtype=x.dtype, sparse=x.sparse, name=x.name + \"_clone\"\n+    )\n+\n+\n+def clone_keras_tensors(tensors, kt_id_mapping):\n+    def swap(x):\n+        if not isinstance(x, backend.KerasTensor):\n+            return x\n+        if id(x) in kt_id_mapping:\n+            return kt_id_mapping[id(x)]\n+        new_x = clone_single_keras_tensor(x)\n+        kt_id_mapping[id(x)] = new_x\n+        return new_x\n+\n+    return tree.map_structure(swap, tensors)\n+\n+\n+def find_nodes_by_inputs_and_outputs(inputs, outputs):\n+    nodes, _ = _build_map(inputs, outputs)\n+    return nodes\n+\n+\n+def clone_graph_nodes(inputs, outputs):\n+    \"\"\"Clone the `Node` between the inputs and output tensors.\n+\n+    This function is used to create a new functional model from any intermediate\n+    Keras tensors. The clone of the nodes mimic the behavior of reconstructing\n+    the functional graph network by re-executing all the `__call__()` methods.\n+    The cloned nodes will be appended to the layers.\n+\n+    Note that a new `keras.Input` will be created for any items in the\n+    `inputs`\n+\n+    Args:\n+    inputs: A nested structure of `KerasTensor` instances.\n+    outputs: A nested structure of `KerasTensor` instances.\n+\n+    Returns:\n+        A pair of inputs and outputs, with cloned `KerasTensor` instances.\n+        They can be used to create a new functional model.\n+    \"\"\"\n+    nodes_to_clone = find_nodes_by_inputs_and_outputs(inputs, outputs)\n+    cloned_inputs = []\n+    cloned_outputs = []\n+    # We not only need to create copies of Nodes (mimic the calls), also need to\n+    # clone Keras tensors to avoid the override of _keras_history attached on\n+    # the Keras tensor. The following dict is used to track any keras tensor we\n+    # cloned The key is the string ID of the original keras tensor, and value is\n+    # the cloned Keras tensor instance.\n+    kt_id_mapping = {}\n+    op_id_mapping = {}\n+\n+    for kt_input in tree.flatten(inputs):\n+        if is_input_keras_tensor(kt_input):\n+            # For any existing Keras tensor from keras.Input, leave them as is.\n+            cloned_inputs.append(kt_input)\n+            kt_id_mapping[id(kt_input)] = kt_input\n+        else:\n+            # We need to create a new Keras tensor for any intermediate tensor\n+            cloned_input = Input(\n+                batch_shape=kt_input.shape,\n+                dtype=kt_input.dtype,\n+                sparse=kt_input.sparse,\n+                name=kt_input.name + \"CLONE\",\n+            )\n+            cloned_inputs.append(cloned_input)\n+            kt_id_mapping[id(kt_input)] = cloned_input\n+            op_id_mapping[id(kt_input._keras_history[0])] = (\n+                cloned_input._keras_history[0]\n+            )\n+    cloned_inputs = pack_sequence_as(inputs, cloned_inputs)\n+\n+    for kt_output in tree.flatten(outputs):\n+        cpy = clone_single_keras_tensor(kt_output)\n+        # We reuse the _keras_history here, which contains the old information.\n+        cpy._keras_history = kt_output._keras_history\n+        cloned_outputs.append(cpy)\n+        kt_id_mapping[id(kt_output)] = cpy\n+    cloned_outputs = pack_sequence_as(outputs, cloned_outputs)\n+\n+    for node in nodes_to_clone:\n+        if id(node.operation) in op_id_mapping:\n+            operation = op_id_mapping[id(node.operation)]\n+        else:\n+            operation = node.operation\n+        # Clone any Keras tensor to avoid override of _keras_history\n+        # Or reuse an existing Keras tensor if it has already been cloned.\n+        output_copy = clone_keras_tensors(node.output_tensors, kt_id_mapping)\n+        if not isinstance(operation, InputLayer):\n+            call_args_copy = clone_keras_tensors(\n+                node.arguments.args, kt_id_mapping\n+            )\n+            call_kwargs_copy = clone_keras_tensors(\n+                node.arguments.kwargs, kt_id_mapping\n+            )\n+        else:\n+            call_args_copy = ()\n+            call_kwargs_copy = {}\n+        # Creating new nodes based on the existing node information.  Node wires\n+        # itself to inbound and outbound layers.  The Node constructor actually\n+        # updates this layer's self._inbound_nodes, sets _keras_history on the\n+        # outputs, and adds itself to the `_outbound_nodes` of the layers that\n+        # produced the inputs to this layer call.\n+        Node(\n+            operation,\n+            call_args=call_args_copy,\n+            call_kwargs=call_kwargs_copy,\n+            outputs=output_copy,\n+        )\n+    return cloned_inputs, cloned_outputs\n\n@@ -335,6 +335,43 @@ class FunctionalTest(testing.TestCase):\n             model(np.zeros((2, 3, 3)))\n         model(np.zeros((2, 4, 3)))\n \n+    def test_functional_slicing(self):\n+        inputs = Input(shape=(None, 2), name=\"input\")\n+        x1 = layers.Dense(3, name=\"dense1\")(inputs)\n+        x2 = layers.Dense(4, name=\"dense2\")(x1)\n+        outputs = layers.Dense(5, name=\"dense3\")(x2)\n+\n+        full_model = Functional(inputs, outputs, name=\"full_model\")\n+        self.assertLen(full_model.layers, 4)\n+\n+        partial_model_1 = Functional(x2, outputs, name=\"partial1\")\n+        self.assertLen(partial_model_1.layers, 2)  # input_layer, dense3\n+        self.assertIsInstance(partial_model_1.layers[0], layers.InputLayer)\n+        self.assertEqual(partial_model_1.layers[1].name, \"dense3\")\n+\n+        partial_model_2 = Functional(x1, x2, name=\"partial2\")\n+        self.assertLen(partial_model_2.layers, 2)  # input_layer, dense2\n+        self.assertIsInstance(partial_model_2.layers[0], layers.InputLayer)\n+        self.assertEqual(partial_model_2.layers[1].name, \"dense2\")\n+\n+        partial_model_3 = Functional(\n+            full_model.get_layer(\"dense2\").input, outputs, name=\"partial3\"\n+        )\n+        self.assertLen(partial_model_3.layers, 3)  # input_layer, dense2, dense3\n+        self.assertIsInstance(partial_model_3.layers[0], layers.InputLayer)\n+        self.assertEqual(partial_model_3.layers[1].name, \"dense2\")\n+        self.assertEqual(partial_model_3.layers[2].name, \"dense3\")\n+\n+        partial_model_4 = Functional(\n+            full_model.get_layer(\"dense1\").input,\n+            full_model.get_layer(\"dense2\").output,\n+            name=\"partial4\",\n+        )\n+        self.assertLen(partial_model_4.layers, 3)  # input_layer, dense1, dense2\n+        self.assertIsInstance(partial_model_4.layers[0], layers.InputLayer)\n+        self.assertEqual(partial_model_4.layers[1].name, \"dense1\")\n+        self.assertEqual(partial_model_4.layers[2].name, \"dense2\")\n+\n     def test_add_loss(self):\n         # TODO\n         pass\n\n@@ -213,7 +213,7 @@ def map_graph(inputs, outputs):\n     \"\"\"\n     # \"depth\" is number of operations between output Node and the Node.\n     # Nodes are ordered from inputs -> outputs.\n-    nodes_in_decreasing_depth, operation_indices = _build_map(outputs)\n+    nodes_in_decreasing_depth, operation_indices = _build_map(inputs, outputs)\n     network_nodes = {\n         make_node_key(node.operation, node.operation._inbound_nodes.index(node))\n         for node in nodes_in_decreasing_depth\n@@ -317,7 +317,7 @@ def map_graph(inputs, outputs):\n     return network_nodes, nodes_by_depth, operations, operations_by_depth\n \n \n-def _build_map(outputs):\n+def _build_map(inputs, outputs):\n     \"\"\"Topologically sort nodes in order from inputs to outputs.\n \n     It uses a depth-first search to topologically sort nodes that appear in the\n@@ -345,6 +345,7 @@ def _build_map(outputs):\n     operation_indices = {}  # operation -> in traversal order.\n     for output in tree.flatten(outputs):\n         _build_map_helper(\n+            inputs,\n             output,\n             finished_nodes,\n             nodes_in_progress,\n@@ -355,6 +356,7 @@ def _build_map(outputs):\n \n \n def _build_map_helper(\n+    inputs,\n     tensor,\n     finished_nodes,\n     nodes_in_progress,\n@@ -389,9 +391,10 @@ def _build_map_helper(\n \n     # Propagate to all previous tensors connected to this node.\n     nodes_in_progress.add(node)\n-    if not node.is_input:\n+    if not node.is_input and tensor not in tree.flatten(inputs):\n         for tensor in node.input_tensors:\n             _build_map_helper(\n+                inputs,\n                 tensor,\n                 finished_nodes,\n                 nodes_in_progress,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#436937dea3d52eecff3cb6f1bd5161f23c825fae", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 37 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 34 | Methods Changed: 34 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 37 | Churn Cumulative: 542 | Contributors (this commit): 6 | Commits (past 90d): 16 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -181,11 +181,13 @@ def zeros(shape, dtype=None):\n \n @sparse.elementwise_unary(linear=False)\n def absolute(x):\n+    x = convert_to_tensor(x)\n     return jnp.absolute(x)\n \n \n @sparse.elementwise_unary(linear=False)\n def abs(x):\n+    x = convert_to_tensor(x)\n     return jnp.absolute(x)\n \n \n@@ -376,16 +378,19 @@ def concatenate(xs, axis=0):\n \n @sparse.elementwise_unary(linear=True)\n def conjugate(x):\n+    x = convert_to_tensor(x)\n     return jnp.conjugate(x)\n \n \n @sparse.elementwise_unary(linear=True)\n def conj(x):\n+    x = convert_to_tensor(x)\n     return jnp.conjugate(x)\n \n \n @sparse.elementwise_unary(linear=True)\n def copy(x):\n+    x = convert_to_tensor(x)\n     return jnp.copy(x)\n \n \n@@ -416,6 +421,8 @@ def count_nonzero(x, axis=None):\n \n \n def cross(x1, x2, axisa=-1, axisb=-1, axisc=-1, axis=None):\n+    x1 = convert_to_tensor(x1)\n+    x2 = convert_to_tensor(x2)\n     return jnp.cross(\n         x1,\n         x2,\n@@ -427,10 +434,12 @@ def cross(x1, x2, axisa=-1, axisb=-1, axisc=-1, axis=None):\n \n \n def cumprod(x, axis=None, dtype=None):\n+    x = convert_to_tensor(x)\n     return jnp.cumprod(x, axis=axis, dtype=dtype)\n \n \n def cumsum(x, axis=None, dtype=None):\n+    x = convert_to_tensor(x)\n     return jnp.cumsum(x, axis=axis, dtype=dtype)\n \n \n@@ -440,6 +449,7 @@ def diag(x, k=0):\n \n \n def diagonal(x, offset=0, axis1=0, axis2=1):\n+    x = convert_to_tensor(x)\n     return jnp.diagonal(\n         x,\n         offset=offset,\n@@ -449,6 +459,7 @@ def diagonal(x, offset=0, axis1=0, axis2=1):\n \n \n def diff(a, n=1, axis=-1):\n+    a = convert_to_tensor(a)\n     return jnp.diff(a, n=n, axis=axis)\n \n \n@@ -459,6 +470,8 @@ def digitize(x, bins):\n \n \n def dot(x, y):\n+    x = convert_to_tensor(x)\n+    y = convert_to_tensor(y)\n     return jnp.dot(x, y)\n \n \n@@ -483,6 +496,7 @@ def exp(x):\n \n \n def expand_dims(x, axis):\n+    x = convert_to_tensor(x)\n     if isinstance(x, jax_sparse.BCOO):\n         (\n             _,\n@@ -550,6 +564,7 @@ def identity(n, dtype=None):\n \n @sparse.elementwise_unary(linear=True)\n def imag(x):\n+    x = convert_to_tensor(x)\n     return jnp.imag(x)\n \n \n@@ -561,16 +576,19 @@ def isclose(x1, x2):\n \n @sparse.densifying_unary\n def isfinite(x):\n+    x = convert_to_tensor(x)\n     return jnp.isfinite(x)\n \n \n @sparse.elementwise_unary(linear=False)\n def isinf(x):\n+    x = convert_to_tensor(x)\n     return jnp.isinf(x)\n \n \n @sparse.elementwise_unary(linear=False)\n def isnan(x):\n+    x = convert_to_tensor(x)\n     return jnp.isnan(x)\n \n \n@@ -648,6 +666,7 @@ def logical_and(x1, x2):\n \n \n def logical_not(x):\n+    x = convert_to_tensor(x)\n     return jnp.logical_not(x)\n \n \n@@ -698,6 +717,7 @@ def meshgrid(*x, indexing=\"xy\"):\n \n \n def min(x, axis=None, keepdims=False, initial=None):\n+    x = convert_to_tensor(x)\n     return jnp.min(x, axis=axis, keepdims=keepdims, initial=initial)\n \n \n@@ -719,6 +739,7 @@ def moveaxis(x, source, destination):\n \n \n def nan_to_num(x):\n+    x = convert_to_tensor(x)\n     return jnp.nan_to_num(x)\n \n \n@@ -749,6 +770,7 @@ def outer(x1, x2):\n \n \n def pad(x, pad_width, mode=\"constant\", constant_values=None):\n+    x = convert_to_tensor(x)\n     kwargs = {}\n     if constant_values is not None:\n         if mode != \"constant\":\n@@ -762,6 +784,7 @@ def pad(x, pad_width, mode=\"constant\", constant_values=None):\n \n \n def prod(x, axis=None, keepdims=False, dtype=None):\n+    x = convert_to_tensor(x)\n     return jnp.prod(x, axis=axis, keepdims=keepdims, dtype=dtype)\n \n \n@@ -781,20 +804,24 @@ def quantile(x, q, axis=None, method=\"linear\", keepdims=False):\n \n \n def ravel(x):\n+    x = convert_to_tensor(x)\n     return jnp.ravel(x)\n \n \n @sparse.elementwise_unary(linear=True)\n def real(x):\n+    x = convert_to_tensor(x)\n     return jnp.real(x)\n \n \n @sparse.densifying_unary\n def reciprocal(x):\n+    x = convert_to_tensor(x)\n     return jnp.reciprocal(x)\n \n \n def repeat(x, repeats, axis=None):\n+    x = convert_to_tensor(x)\n     return jnp.repeat(x, repeats, axis=axis)\n \n \n@@ -818,6 +845,7 @@ def roll(x, shift, axis=None):\n \n @sparse.elementwise_unary(linear=False)\n def sign(x):\n+    x = convert_to_tensor(x)\n     return jnp.sign(x)\n \n \n@@ -848,6 +876,7 @@ def size(x):\n \n \n def sort(x, axis=-1):\n+    x = convert_to_tensor(x)\n     return jnp.sort(x, axis=axis)\n \n \n@@ -867,6 +896,7 @@ def std(x, axis=None, keepdims=False):\n \n \n def swapaxes(x, axis1, axis2):\n+    x = convert_to_tensor(x)\n     return jnp.swapaxes(x, axis1=axis1, axis2=axis2)\n \n \n@@ -910,6 +940,7 @@ def tensordot(x1, x2, axes=2):\n \n @sparse.elementwise_unary(linear=False)\n def round(x, decimals=0):\n+    x = convert_to_tensor(x)\n     return jnp.round(x, decimals=decimals)\n \n \n@@ -931,14 +962,18 @@ def tri(N, M=None, k=0, dtype=None):\n \n \n def tril(x, k=0):\n+    x = convert_to_tensor(x)\n     return jnp.tril(x, k=k)\n \n \n def triu(x, k=0):\n+    x = convert_to_tensor(x)\n     return jnp.triu(x, k=k)\n \n \n def vdot(x1, x2):\n+    x1 = convert_to_tensor(x1)\n+    x2 = convert_to_tensor(x2)\n     return jnp.vdot(x1, x2)\n \n \n@@ -975,11 +1010,13 @@ def power(x1, x2):\n \n @sparse.elementwise_unary(linear=True)\n def negative(x):\n+    x = convert_to_tensor(x)\n     return jnp.negative(x)\n \n \n @sparse.elementwise_unary(linear=False)\n def square(x):\n+    x = convert_to_tensor(x)\n     return jnp.square(x)\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7ce3d62af7cc6959fc5a5841cfe17043dfcb8615", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 80 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -3,7 +3,7 @@ import scipy.linalg as sl\n \n from keras.backend import standardize_dtype\n from keras.backend.common import dtypes\n-from keras.backend.torch.core import convert_to_tensor\n+from keras.backend.numpy.core import convert_to_tensor\n \n \n def cholesky(a):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7a0e6707bdc181dc70b1bfc1d1bd0f1b3f9b5404", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 26 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 5 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 26 | Churn Cumulative: 9800 | Contributors (this commit): 25 | Commits (past 90d): 4 | Contributors (cumulative): 38 | DMM Complexity: 1.0\n\nDIFF:\n@@ -492,6 +492,10 @@ class TextVectorization(Layer):\n             config[\"split\"] = serialization_lib.deserialize_keras_object(\n                 config[\"split\"]\n             )\n+\n+        if isinstance(config[\"ngrams\"], list):\n+            config[\"ngrams\"] = tuple(config[\"ngrams\"])\n+\n         return cls(**config)\n \n     def set_vocabulary(self, vocabulary, idf_weights=None):\n\n@@ -1,11 +1,15 @@\n+import os\n+\n import numpy as np\n import pytest\n import tensorflow as tf\n from tensorflow import data as tf_data\n \n+from keras import Sequential\n from keras import backend\n from keras import layers\n from keras import models\n+from keras import saving\n from keras import testing\n \n \n@@ -62,6 +66,24 @@ class TextVectorizationTest(testing.TestCase):\n         self.assertTrue(backend.is_tensor(output))\n         self.assertAllClose(output, np.array([[4, 1, 3, 0], [1, 2, 0, 0]]))\n \n+    @pytest.mark.skipif(\n+        backend.backend() != \"tensorflow\", reason=\"Requires string input dtype\"\n+    )\n+    def test_save_load_with_ngrams_flow(self):\n+        input_data = np.array([\"foo bar\", \"bar baz\", \"baz bada boom\"])\n+        model = Sequential(\n+            [\n+                layers.Input(dtype=\"string\", shape=(1,)),\n+                layers.TextVectorization(ngrams=(1, 2)),\n+            ]\n+        )\n+        model.layers[0].adapt(input_data)\n+        output = model(input_data)\n+        temp_filepath = os.path.join(self.get_temp_dir(), \"model.keras\")\n+        model.save(temp_filepath)\n+        model = saving.load_model(temp_filepath)\n+        self.assertAllClose(output, model(input_data))\n+\n     def test_tf_data_compatibility(self):\n         max_tokens = 5000\n         max_len = 4\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ec67b760ba25e1ccc392d288f7d8c6e9e153eea2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 316 | Lines Deleted: 38 | Files Changed: 2 | Hunks: 14 | Methods Changed: 8 | Complexity Δ (Sum/Max): 29/24 | Churn Δ: 354 | Churn Cumulative: 689 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 4 | DMM Complexity: 0.4835680751173709\n\nDIFF:\n@@ -563,6 +563,71 @@ class PadImages(Operation):\n         )\n \n \n+@keras_export(\"keras.ops.image.pad_images\")\n+def pad_images(\n+    images,\n+    top_padding=None,\n+    left_padding=None,\n+    target_height=None,\n+    target_width=None,\n+    bottom_padding=None,\n+    right_padding=None,\n+):\n+    \"\"\"Pad `images` with zeros to the specified `height` and `width`.\n+\n+    Args:\n+        images: 4D Tensor of shape `(batch, height, width, channels)` or 3D\n+            Tensor of shape `(height, width, channels)`.\n+        top_padding: Number of rows of zeros to add on top.\n+        bottom_padding: Number of rows of zeros to add at the bottom.\n+        left_padding: Number of columns of zeros to add on the left.\n+        right_padding: Number of columns of zeros to add on the right.\n+        target_height: Height of output images.\n+        target_width: Width of output images.\n+\n+    Returns:\n+        If `images` were 4D, a 4D float Tensor of shape\n+            `(batch, target_height, target_width, channels)`\n+        If `images` were 3D, a 3D float Tensor of shape\n+            `(target_height, target_width, channels)`\n+\n+    Example:\n+\n+    >>> images = np.random.random((15, 25, 3))\n+    >>> padded_images = keras.ops.image.pad_images(\n+    ...     images, 2, 3, target_height=20, target_width=30\n+    ... )\n+    >>> padded_images.shape\n+    (20, 30, 3)\n+\n+    >>> batch_images = np.random.random((2, 15, 25, 3))\n+    >>> padded_batch = keras.ops.image.pad_images(\n+    ...     batch_images, 2, 3, target_height=20, target_width=30\n+    ... )\n+    >>> padded_batch.shape\n+    (2, 20, 30, 3)\"\"\"\n+\n+    if any_symbolic_tensors((images,)):\n+        return PadImages(\n+            top_padding,\n+            bottom_padding,\n+            left_padding,\n+            right_padding,\n+            target_height,\n+            target_width,\n+        ).symbolic_call(images)\n+\n+    return _pad_images(\n+        images,\n+        top_padding,\n+        bottom_padding,\n+        left_padding,\n+        right_padding,\n+        target_height,\n+        target_width,\n+    )\n+\n+\n def _pad_images(\n     images,\n     top_padding,\n@@ -662,27 +727,92 @@ def _pad_images(\n     return padded\n \n \n-@keras_export(\"keras.ops.image.pad_images\")\n-def pad_images(\n+class CropImages(Operation):\n+    def __init__(\n+        self,\n+        top_cropping,\n+        bottom_cropping,\n+        left_cropping,\n+        right_cropping,\n+        target_height,\n+        target_width,\n+    ):\n+        super().__init__()\n+        self.top_cropping = top_cropping\n+        self.bottom_cropping = bottom_cropping\n+        self.left_cropping = left_cropping\n+        self.right_cropping = right_cropping\n+        self.target_height = target_height\n+        self.target_width = target_width\n+\n+    def call(self, images):\n+        return _crop_images(\n             images,\n-    top_padding=None,\n-    left_padding=None,\n+            self.top_cropping,\n+            self.bottom_cropping,\n+            self.left_cropping,\n+            self.right_cropping,\n+            self.target_height,\n+            self.target_width,\n+        )\n+\n+    def compute_output_spec(self, images):\n+        images_shape = ops.shape(images)\n+        out_shape = (\n+            images_shape[0],\n+            self.target_height,\n+            self.target_width,\n+            images_shape[-1],\n+        )\n+        if self.target_height is None:\n+            height_axis = 0 if len(images_shape) == 3 else 1\n+            self.target_height = (\n+                self.top_cropping\n+                - images_shape[height_axis]\n+                - self.bottom_cropping\n+            )\n+        if self.target_width is None:\n+            width_axis = 0 if len(images_shape) == 3 else 2\n+            self.target_width = (\n+                self.left_cropping\n+                - images_shape[width_axis]\n+                - self.right_cropping\n+            )\n+        out_shape = (\n+            images_shape[0],\n+            self.target_height,\n+            self.target_width,\n+            images_shape[-1],\n+        )\n+        if len(images_shape) == 3:\n+            out_shape = out_shape[1:]\n+        return KerasTensor(\n+            shape=out_shape,\n+            dtype=images.dtype,\n+        )\n+\n+\n+@keras_export(\"keras.ops.image.crop_images\")\n+def crop_images(\n+    images,\n+    top_cropping=None,\n+    left_cropping=None,\n     target_height=None,\n     target_width=None,\n-    bottom_padding=None,\n-    right_padding=None,\n+    bottom_cropping=None,\n+    right_cropping=None,\n ):\n-    \"\"\"Pad `images` with zeros to the specified `height` and `width`.\n+    \"\"\"Crop `images` to a specified `height` and `width`.\n \n     Args:\n-        images: 4D Tensor of shape `(batch, height, width, channels)` or 3D\n-            Tensor of shape `(height, width, channels)`.\n-        top_padding: Number of rows of zeros to add on top.\n-        bottom_padding: Number of rows of zeros to add at the bottom.\n-        left_padding: Number of columns of zeros to add on the left.\n-        right_padding: Number of columns of zeros to add on the right.\n-        target_height: Height of output images.\n-        target_width: Width of output images.\n+        images: 4-D batch of images of shape `(batch, height, width, channels)`\n+             or 3-D single image of shape `(height, width, channels)`.\n+        top_cropping: Number of columns to crop from the top.\n+        bottom_cropping: Number of columns to crop from the bottom.\n+        left_cropping: Number of columns to crop from the left.\n+        right_cropping: Number of columns to crop from the right.\n+        target_height: Height of the output images.\n+        target_width: Width of the output images.\n \n     Returns:\n         If `images` were 4D, a 4D float Tensor of shape\n@@ -692,36 +822,117 @@ def pad_images(\n \n     Example:\n \n-    >>> images = np.random.random((15, 25, 3))\n-    >>> padded_images = keras.ops.image.pad_images(\n-    ...     images, 2, 3, target_height=20, target_width=30\n-    ... )\n-    >>> padded_images.shape\n-    (20, 30, 3)\n-\n-    >>> batch_images = np.random.random((2, 15, 25, 3))\n-    >>> padded_batch = keras.ops.image.pad_images(\n-    ...     batch_images, 2, 3, target_height=20, target_width=30\n-    ... )\n-    >>> padded_batch.shape\n-    (2, 20, 30, 3)\"\"\"\n+    >>> images = np.reshape(np.arange(1, 28, dtype=\"float32\"), [3, 3, 3])\n+    >>> images[:,:,0] # print the first channel of the images\n+    array([[ 1.,  4.,  7.],\n+           [10., 13., 16.],\n+           [19., 22., 25.]], dtype=float32)\n+    >>> cropped_images = keras.image.crop_images(images, 0, 0, 2, 2)\n+    >>> cropped_images[:,:,0] # print the first channel of the cropped images\n+    array([[ 1.,  4.],\n+           [10., 13.]], dtype=float32)\"\"\"\n \n     if any_symbolic_tensors((images,)):\n-        return PadImages(\n-            top_padding,\n-            bottom_padding,\n-            left_padding,\n-            right_padding,\n+        return CropImages(\n+            top_cropping,\n+            bottom_cropping,\n+            left_cropping,\n+            right_cropping,\n             target_height,\n             target_width,\n         ).symbolic_call(images)\n \n-    return _pad_images(\n+    return _crop_images(\n         images,\n-        top_padding,\n-        bottom_padding,\n-        left_padding,\n-        right_padding,\n+        top_cropping,\n+        bottom_cropping,\n+        left_cropping,\n+        right_cropping,\n         target_height,\n         target_width,\n     )\n+\n+\n+def _crop_images(\n+    images,\n+    top_cropping,\n+    bottom_cropping,\n+    left_cropping,\n+    right_cropping,\n+    target_height,\n+    target_width,\n+):\n+    images = backend.convert_to_tensor(images)\n+    is_batch = True\n+    images_shape = ops.shape(images)\n+    if len(images_shape) == 3:\n+        is_batch = False\n+        images = backend.numpy.expand_dims(images, 0)\n+    elif len(images_shape) != 4:\n+        raise ValueError(\n+            f\"Invalid shape for argument `images`: \"\n+            \"it must have rank 3 or 4. \"\n+            f\"Received: images.shape={images_shape}\"\n+        )\n+\n+    batch, height, width, depth = ops.shape(images)\n+\n+    if [top_cropping, bottom_cropping, target_height].count(None) != 1:\n+        raise ValueError(\n+            \"Must specify exactly two of \"\n+            \"top_cropping, bottom_cropping, target_height. \"\n+            f\"Received: top_cropping={top_cropping}, \"\n+            f\"bottom_cropping={bottom_cropping}, \"\n+            f\"target_height={target_height}\"\n+        )\n+    if [left_cropping, right_cropping, target_width].count(None) != 1:\n+        raise ValueError(\n+            \"Must specify exactly two of \"\n+            \"left_cropping, right_cropping, target_width. \"\n+            f\"Received: left_cropping={left_cropping}, \"\n+            f\"right_cropping={right_cropping}, \"\n+            f\"target_width={target_width}\"\n+        )\n+\n+    if top_cropping is None:\n+        top_cropping = height - target_height - bottom_cropping\n+    if target_height is None:\n+        target_height = height - bottom_cropping - top_cropping\n+    if left_cropping is None:\n+        left_cropping = width - target_width - right_cropping\n+    if target_width is None:\n+        target_width = width - right_cropping - left_cropping\n+\n+    if top_cropping < 0:\n+        raise ValueError(\n+            \"top_cropping must be >= 0. \"\n+            f\"Received: top_cropping={top_cropping}\"\n+        )\n+    if target_height < 0:\n+        raise ValueError(\n+            \"target_height must be >= 0. \"\n+            f\"Received: target_height={target_height}\"\n+        )\n+    if left_cropping < 0:\n+        raise ValueError(\n+            \"left_cropping must be >= 0. \"\n+            f\"Received: left_cropping={left_cropping}\"\n+        )\n+    if target_width < 0:\n+        raise ValueError(\n+            \"target_width must be >= 0. \"\n+            f\"Received: target_width={target_width}\"\n+        )\n+\n+    cropped = ops.slice(\n+        images,\n+        backend.numpy.stack([0, top_cropping, left_cropping, 0]),\n+        backend.numpy.stack([batch, target_height, target_width, depth]),\n+    )\n+\n+    cropped_shape = [batch, target_height, target_width, depth]\n+    cropped = backend.numpy.reshape(cropped, cropped_shape)\n+\n+    if not is_batch:\n+        cropped = backend.numpy.squeeze(cropped, axis=[0])\n+    return cropped\n\n@@ -51,6 +51,15 @@ class ImageOpsDynamicShapeTest(testing.TestCase):\n         out = kimage.pad_images(x, 2, 3, target_height=20, target_width=30)\n         self.assertEqual(out.shape, (20, 30, 3))\n \n+    def test_crop_images(self):\n+        x = KerasTensor([None, 15, 25, 3])\n+        out = kimage.crop_images(x, 2, 3, target_height=10, target_width=20)\n+        self.assertEqual(out.shape, (None, 10, 20, 3))\n+\n+        x = KerasTensor([None, None, 3])\n+        out = kimage.crop_images(x, 2, 3, target_height=10, target_width=20)\n+        self.assertEqual(out.shape, (10, 20, 3))\n+\n \n class ImageOpsStaticShapeTest(testing.TestCase):\n     def test_resize(self):\n@@ -89,6 +98,17 @@ class ImageOpsStaticShapeTest(testing.TestCase):\n         )\n         self.assertEqual(out_batch.shape, (2, 20, 30, 3))\n \n+    def test_crop_images(self):\n+        x = KerasTensor([15, 25, 3])\n+        out = kimage.crop_images(x, 2, 3, target_height=10, target_width=20)\n+        self.assertEqual(out.shape, (10, 20, 3))\n+\n+        x_batch = KerasTensor([2, 15, 25, 3])\n+        out_batch = kimage.crop_images(\n+            x_batch, 2, 3, target_height=10, target_width=20\n+        )\n+        self.assertEqual(out_batch.shape, (2, 10, 20, 3))\n+\n \n AFFINE_TRANSFORM_INTERPOLATIONS = {  # map to order\n     \"nearest\": 0,\n@@ -480,3 +500,50 @@ class ImageOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             backend.convert_to_numpy(padded_image),\n             atol=1e-5,\n         )\n+\n+    @parameterized.parameters(\n+        [\n+            (0, 0, 3, 3, None, None),\n+            (1, 0, 4, 3, None, None),\n+            (0, 1, 3, 4, None, None),\n+            (0, 0, 4, 3, None, None),\n+            (0, 0, 3, 4, None, None),\n+            (0, 0, None, None, 0, 1),\n+            (0, 0, None, None, 1, 0),\n+            (1, 2, None, None, 3, 4),\n+        ]\n+    )\n+    def test_crop_images(\n+        self,\n+        top_cropping,\n+        left_cropping,\n+        target_height,\n+        target_width,\n+        bottom_cropping,\n+        right_cropping,\n+    ):\n+        image = np.random.uniform(size=(10, 10, 1))\n+        cropped_image = kimage.crop_images(\n+            image,\n+            top_cropping,\n+            left_cropping,\n+            target_height,\n+            target_width,\n+            bottom_cropping,\n+            right_cropping,\n+        )\n+        if target_height is None:\n+            target_height = image.shape[0] - top_cropping - bottom_cropping\n+        if target_width is None:\n+            target_width = image.shape[1] - left_cropping - right_cropping\n+        ref_cropped_image = tf.image.crop_to_bounding_box(\n+            image, top_cropping, left_cropping, target_height, target_width\n+        )\n+        self.assertEqual(\n+            tuple(cropped_image.shape), tuple(ref_cropped_image.shape)\n+        )\n+        self.assertAllClose(\n+            ref_cropped_image.numpy(),\n+            backend.convert_to_numpy(cropped_image),\n+            atol=1e-5,\n+        )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
