{"custom_id": "keras#d695e974a2550d492f9df0f9c007e1737d9c0893", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 175 | Lines Deleted: 12 | Files Changed: 5 | Hunks: 15 | Methods Changed: 13 | Complexity Δ (Sum/Max): 11/9 | Churn Δ: 187 | Churn Cumulative: 2531 | Contributors (this commit): 7 | Commits (past 90d): 41 | Contributors (cumulative): 17 | DMM Complexity: 1.0\n\nDIFF:\n@@ -4,6 +4,7 @@ from keras_core.api_export import keras_core_export\n from keras_core.losses.loss import Loss\n from keras_core.losses.loss import squeeze_to_same_rank\n from keras_core.saving import serialization_lib\n+from keras_core.utils.numerical_utils import l2_normalize\n \n \n class LossFunctionWrapper(Loss):\n@@ -44,7 +45,7 @@ class MeanSquaredError(LossFunctionWrapper):\n     Args:\n         reduction: Type of reduction to apply to loss. For almost all cases\n             this defaults to `\"sum_over_batch_size\"`. Options are `\"sum\"`,\n-            `\"sum_over_batch_size\"` or None.\n+            `\"sum_over_batch_size\"` or `None`.\n         name: Optional name for the instance.\n     \"\"\"\n \n@@ -70,7 +71,7 @@ class MeanAbsoluteError(LossFunctionWrapper):\n     Args:\n         reduction: Type of reduction to apply to loss. For almost all cases\n             this defaults to `\"sum_over_batch_size\"`. Options are `\"sum\"`,\n-            `\"sum_over_batch_size\"` or None.\n+            `\"sum_over_batch_size\"` or `None`.\n         name: Optional name for the instance.\n     \"\"\"\n \n@@ -96,7 +97,7 @@ class MeanAbsolutePercentageError(LossFunctionWrapper):\n     Args:\n         reduction: Type of reduction to apply to loss. For almost all cases\n             this defaults to `\"sum_over_batch_size\"`. Options are `\"sum\"`,\n-            `\"sum_over_batch_size\"` or None.\n+            `\"sum_over_batch_size\"` or `None`.\n         name: Optional name for the instance.\n     \"\"\"\n \n@@ -126,7 +127,7 @@ class MeanSquaredLogarithmicError(LossFunctionWrapper):\n     Args:\n         reduction: Type of reduction to apply to loss. For almost all cases\n             this defaults to `\"sum_over_batch_size\"`. Options are `\"sum\"`,\n-            `\"sum_over_batch_size\"` or None.\n+            `\"sum_over_batch_size\"` or `None`.\n         name: Optional name for the instance.\n     \"\"\"\n \n@@ -143,6 +144,43 @@ class MeanSquaredLogarithmicError(LossFunctionWrapper):\n         return Loss.get_config(self)\n \n \n+@keras_core_export(\"keras_core.losses.CosineSimilarity\")\n+class CosineSimilarity(LossFunctionWrapper):\n+    \"\"\"Computes the cosine similarity between `y_true` & `y_pred`.\n+\n+    Note that it is a number between -1 and 1. When it is a negative number\n+    between -1 and 0, 0 indicates orthogonality and values closer to -1\n+    indicate greater similarity. This makes it usable as a loss function in a\n+    setting where you try to maximize the proximity between predictions and\n+    targets. If either `y_true` or `y_pred` is a zero vector, cosine similarity\n+    will be 0 regardless of the proximity between predictions and targets.\n+\n+    Formula:\n+\n+    ```python\n+    loss = mean(square(log(y_true + 1) - log(y_pred + 1)))\n+    ```\n+\n+    Args:\n+        axis: The axis along which the cosine similarity is computed\n+            (the features axis). Defaults to -1.\n+        reduction: Type of reduction to apply to loss. Options are `\"sum\"`,\n+            `\"sum_over_batch_size\"` or `None`. Defaults to\n+            `\"sum_over_batch_size\"`.\n+        name: Optional name for the instance.\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        axis=-1,\n+        reduction=\"sum_over_batch_size\",\n+        name=\"cosine_similarity\",\n+    ):\n+        super().__init__(\n+            cosine_similarity, reduction=reduction, name=name, axis=axis\n+        )\n+\n+\n @keras_core_export(\"keras_core.losses.Hinge\")\n class Hinge(LossFunctionWrapper):\n     \"\"\"Computes the hinge loss between `y_true` & `y_pred`.\n@@ -159,7 +197,7 @@ class Hinge(LossFunctionWrapper):\n     Args:\n         reduction: Type of reduction to apply to loss. For almost all cases\n             this defaults to `\"sum_over_batch_size\"`. Options are `\"sum\"`,\n-            `\"sum_over_batch_size\"` or None.\n+            `\"sum_over_batch_size\"` or `None`.\n         name: Optional name for the instance. Defaults to `\"hinge\"`\n     \"\"\"\n \n@@ -186,7 +224,7 @@ class SquaredHinge(LossFunctionWrapper):\n     Args:\n         reduction: Type of reduction to apply to loss. For almost all cases\n             this defaults to `\"sum_over_batch_size\"`. Options are `\"sum\"`,\n-            `\"sum_over_batch_size\"` or None.\n+            `\"sum_over_batch_size\"` or `None`.\n         name: Optional name for the instance. Defaults to `\"squared_hinge\"`\n     \"\"\"\n \n@@ -212,7 +250,7 @@ class CategoricalHinge(LossFunctionWrapper):\n     Args:\n         reduction: Type of reduction to apply to loss. For almost all cases\n             this defaults to `\"sum_over_batch_size\"`. Options are `\"sum\"`,\n-            `\"sum_over_batch_size\"` or None.\n+            `\"sum_over_batch_size\"` or `None`.\n         name: Optional name for the instance. Defaults to\n             `\"categorical_hinge\"`\n     \"\"\"\n@@ -505,3 +543,42 @@ def mean_squared_logarithmic_error(y_true, y_pred):\n     first_log = ops.log(ops.maximum(y_pred, epsilon) + 1.0)\n     second_log = ops.log(ops.maximum(y_true, epsilon) + 1.0)\n     return ops.mean(ops.square(first_log - second_log), axis=-1)\n+\n+\n+@keras_core_export(\"keras_core.losses.cosine_similarity\")\n+def cosine_similarity(y_true, y_pred, axis=-1):\n+    \"\"\"Computes the cosine similarity between labels and predictions.\n+\n+    Formula:\n+    ```python\n+    loss = -sum(l2_norm(y_true) * l2_norm(y_pred))\n+    ```\n+\n+    Note that it is a number between -1 and 1. When it is a negative number\n+    between -1 and 0, 0 indicates orthogonality and values closer to -1\n+    indicate greater similarity. This makes it usable as a loss function in a\n+    setting where you try to maximize the proximity between predictions and\n+    targets. If either `y_true` or `y_pred` is a zero vector, cosine\n+    similarity will be 0 regardless of the proximity between predictions\n+    and targets.\n+\n+    Standalone usage:\n+    >>> y_true = [[0., 1.], [1., 1.], [1., 1.]]\n+    >>> y_pred = [[1., 0.], [1., 1.], [-1., -1.]]\n+    >>> loss = keras_core.losses.cosine_similarity(y_true, y_pred, axis=-1)\n+    [-0., -0.99999994, 0.99999994]\n+\n+    Args:\n+        y_true: Tensor of true targets.\n+        y_pred: Tensor of predicted targets.\n+        axis: Axis along which to determine similarity. Defaults to -1.\n+\n+    Returns:\n+        Cosine similarity tensor.\n+    \"\"\"\n+    y_pred = ops.convert_to_tensor(y_pred)\n+    y_true = ops.convert_to_tensor(y_true, dtype=y_pred.dtype)\n+    y_true, y_pred = squeeze_to_same_rank(y_true, y_pred)\n+    y_pred = l2_normalize(y_pred, axis=axis)\n+    y_true = l2_normalize(y_true, axis=axis)\n+    return -ops.sum(y_true * y_pred, axis=axis)\n\n@@ -382,3 +382,83 @@ class CategoricalHingeTest(testing.TestCase):\n         hinge_obj = losses.CategoricalHinge()\n         loss = hinge_obj(y_true, y_pred, sample_weight=sample_weight)\n         self.assertEqual(loss, 0.0)\n+\n+\n+class CosineSimilarityTest(testing.TestCase):\n+    def l2_norm(self, x, axis):\n+        epsilon = 1e-12\n+        square_sum = np.sum(np.square(x), axis=axis, keepdims=True)\n+        x_inv_norm = 1 / np.sqrt(np.maximum(square_sum, epsilon))\n+        return np.multiply(x, x_inv_norm)\n+\n+    def setup(self, axis=1):\n+        self.np_y_true = np.asarray([[1, 9, 2], [-5, -2, 6]], dtype=np.float32)\n+        self.np_y_pred = np.asarray([[4, 8, 12], [8, 1, 3]], dtype=np.float32)\n+\n+        y_true = self.l2_norm(self.np_y_true, axis)\n+        y_pred = self.l2_norm(self.np_y_pred, axis)\n+        self.expected_loss = np.sum(np.multiply(y_true, y_pred), axis=(axis,))\n+\n+        self.y_true = self.np_y_true\n+        self.y_pred = self.np_y_pred\n+\n+    def test_config(self):\n+        cosine_obj = losses.CosineSimilarity(\n+            axis=2, reduction=\"sum\", name=\"cosine_loss\"\n+        )\n+        self.assertEqual(cosine_obj.name, \"cosine_loss\")\n+        self.assertEqual(cosine_obj.reduction, \"sum\")\n+\n+    def test_unweighted(self):\n+        self.setup()\n+        cosine_obj = losses.CosineSimilarity()\n+        loss = cosine_obj(self.y_true, self.y_pred)\n+        expected_loss = -np.mean(self.expected_loss)\n+        self.assertAlmostEqual(loss, expected_loss, 3)\n+\n+    def test_scalar_weighted(self):\n+        self.setup()\n+        cosine_obj = losses.CosineSimilarity()\n+        sample_weight = 2.3\n+        loss = cosine_obj(self.y_true, self.y_pred, sample_weight=sample_weight)\n+        expected_loss = -np.mean(self.expected_loss * sample_weight)\n+        self.assertAlmostEqual(loss, expected_loss, 3)\n+\n+    def test_sample_weighted(self):\n+        self.setup()\n+        cosine_obj = losses.CosineSimilarity()\n+        sample_weight = np.asarray([1.2, 3.4])\n+        loss = cosine_obj(self.y_true, self.y_pred, sample_weight=sample_weight)\n+        expected_loss = -np.mean(self.expected_loss * sample_weight)\n+        self.assertAlmostEqual(loss, expected_loss, 3)\n+\n+    def test_timestep_weighted(self):\n+        self.setup()\n+        cosine_obj = losses.CosineSimilarity()\n+        np_y_true = self.np_y_true.reshape((2, 3, 1))\n+        np_y_pred = self.np_y_pred.reshape((2, 3, 1))\n+        sample_weight = np.asarray([3, 6, 5, 0, 4, 2]).reshape((2, 3))\n+\n+        y_true = self.l2_norm(np_y_true, 2)\n+        y_pred = self.l2_norm(np_y_pred, 2)\n+        expected_loss = np.sum(np.multiply(y_true, y_pred), axis=(2,))\n+\n+        y_true = np_y_true\n+        y_pred = np_y_pred\n+        loss = cosine_obj(y_true, y_pred, sample_weight=sample_weight)\n+\n+        expected_loss = -np.mean(expected_loss * sample_weight)\n+        self.assertAlmostEqual(loss, expected_loss, 3)\n+\n+    def test_zero_weighted(self):\n+        self.setup()\n+        cosine_obj = losses.CosineSimilarity()\n+        loss = cosine_obj(self.y_true, self.y_pred, sample_weight=0)\n+        self.assertAlmostEqual(loss, 0.0, 3)\n+\n+    def test_axis(self):\n+        self.setup(axis=1)\n+        cosine_obj = losses.CosineSimilarity(axis=1)\n+        loss = cosine_obj(self.y_true, self.y_pred)\n+        expected_loss = -np.mean(self.expected_loss)\n+        self.assertAlmostEqual(loss, expected_loss, 3)\n\n@@ -1,6 +1,7 @@\n from keras_core import backend\n from keras_core import operations as ops\n from keras_core.api_export import keras_core_export\n+from keras_core.backend import floatx\n from keras_core.losses.loss import squeeze_to_same_rank\n from keras_core.metrics import reduction_metrics\n \n\n@@ -2,6 +2,7 @@ import math\n \n from keras_core import operations as ops\n from keras_core.api_export import keras_core_export\n+from keras_core.utils.numerical_utils import l2_normalize\n \n \n @keras_core_export(\n@@ -344,8 +345,3 @@ def validate_float_arg(value, name):\n             f\"Received: {name}={value}\"\n         )\n     return float(value)\n-\n-\n-def l2_normalize(x, axis=0):\n-    l2_norm = ops.sqrt(ops.sum(ops.square(x), axis=axis))\n-    return x / l2_norm\n\n@@ -0,0 +1,9 @@\n+from keras_core import backend\n+from keras_core import operations as ops\n+\n+\n+def l2_normalize(x, axis=0):\n+    epsilon = backend.epsilon()\n+    square_sum = ops.sum(ops.square(x), axis=axis, keepdims=True)\n+    l2_norm = ops.reciprocal(ops.sqrt(ops.maximum(square_sum, epsilon)))\n+    return ops.multiply(x, l2_norm)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1a273b1de69372dccaf4e058ecc887c5db1f3a73", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 21 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 3/2 | Churn Δ: 22 | Churn Cumulative: 917 | Contributors (this commit): 6 | Commits (past 90d): 58 | Contributors (cumulative): 9 | DMM Complexity: 0.8666666666666667\n\nDIFF:\n@@ -340,6 +340,7 @@ class Layer(Operation):\n         # TODO: Populate mask argument(s)\n \n         # Call the layer.\n+        try:\n             with backend.name_scope(self.name):\n                 if self.autocast and self.compute_dtype != self.variable_dtype:\n                     # For mixed precision, we automatically cast layer variables\n@@ -356,7 +357,7 @@ class Layer(Operation):\n \n             # TODO: Set masks on outputs\n             # self._set_mask_metadata(inputs, outputs, previous_mask)\n-\n+        finally:\n             # Destroy call context if we created it\n             self._maybe_reset_call_context()\n         return outputs\n\n@@ -228,6 +228,25 @@ class LayerTest(testing.TestCase):\n         y = layer(x, training=False)\n         self.assertEqual(ops.min(y), 0)\n \n+        # Test that layer interruption does not cause\n+        # the call context to linger\n+        class BadLayer(layers.Layer):\n+            def call(self, x, training=False):\n+                raise RuntimeError(\"oops!\")\n+\n+        x = np.ones((4, 4))\n+        layer = BadLayer()\n+        try:\n+            # training=True will be recorded\n+            # in the call context\n+            layer(x, training=True)\n+        except RuntimeError:\n+            pass\n+        layer = TrainingLayer()\n+        # But this layer call should not see it\n+        y = layer(x)\n+        self.assertEqual(ops.min(y), 1)\n+\n     def test_mixed_precision(self):\n         x = np.ones((4, 4))\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#038d7bb200c0722bbffdfe14ea5d72353b63096e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 508 | Lines Deleted: 0 | Files Changed: 5 | Hunks: 7 | Methods Changed: 20 | Complexity Δ (Sum/Max): 58/31 | Churn Δ: 508 | Churn Cumulative: 524 | Contributors (this commit): 4 | Commits (past 90d): 10 | Contributors (cumulative): 8 | DMM Complexity: 0.7192429022082019\n\nDIFF:\n@@ -1,5 +1,6 @@\n from keras_core.callbacks.callback import Callback\n from keras_core.callbacks.callback_list import CallbackList\n+from keras_core.callbacks.early_stopping import EarlyStopping\n from keras_core.callbacks.history import History\n from keras_core.callbacks.lambda_callback import LambdaCallback\n from keras_core.callbacks.progbar_logger import ProgbarLogger\n\n@@ -0,0 +1,185 @@\n+import warnings\n+\n+from keras_core import operations as ops\n+from keras_core.api_export import keras_core_export\n+from keras_core.callbacks.callback import Callback\n+from keras_core.utils import io_utils\n+\n+\n+@keras_core_export(\"keras_core.callbacks.EarlyStopping\")\n+class EarlyStopping(Callback):\n+    \"\"\"Stop training when a monitored metric has stopped improving.\n+\n+    Assuming the goal of a training is to minimize the loss. With this, the\n+    metric to be monitored would be `'loss'`, and mode would be `'min'`. A\n+    `model.fit()` training loop will check at end of every epoch whether\n+    the loss is no longer decreasing, considering the `min_delta` and\n+    `patience` if applicable. Once it's found no longer decreasing,\n+    `model.stop_training` is marked True and the training terminates.\n+\n+    The quantity to be monitored needs to be available in `logs` dict.\n+    To make it so, pass the loss or metrics at `model.compile()`.\n+\n+    Args:\n+        monitor: Quantity to be monitored. Defaults to `\"val_loss\"`.\n+        min_delta: Minimum change in the monitored quantity to qualify as an\n+            improvement, i.e. an absolute change of less than min_delta, will\n+            count as no improvement. Defaults to `0`.\n+        patience: Number of epochs with no improvement after which training will\n+            be stopped. Defaults to `0`.\n+        verbose: Verbosity mode, 0 or 1. Mode 0 is silent, and mode 1 displays\n+            messages when the callback takes an action. Defaults to `0`.\n+        mode: One of `{\"auto\", \"min\", \"max\"}`. In `min` mode, training will stop\n+            when the quantity monitored has stopped decreasing; in `\"max\"` mode\n+            it will stop when the quantity monitored has stopped increasing; in\n+            `\"auto\"` mode, the direction is automatically inferred from the name\n+            of the monitored quantity. Defaults to `\"auto\"`.\n+        baseline: Baseline value for the monitored quantity. If not `None`,\n+            training will stop if the model doesn't show improvement over the\n+            baseline. Defaults to `None`.\n+        restore_best_weights: Whether to restore model weights from the epoch\n+            with the best value of the monitored quantity. If `False`, the model\n+            weights obtained at the last step of training are used. An epoch\n+            will be restored regardless of the performance relative to the\n+            `baseline`. If no epoch improves on `baseline`, training will run\n+            for `patience` epochs and restore weights from the best epoch in\n+            that set. Defaults to `False`.\n+        start_from_epoch: Number of epochs to wait before starting to monitor\n+            improvement. This allows for a warm-up period in which no\n+            improvement is expected and thus training will not be stopped.\n+            Defaults to `0`.\n+\n+\n+    Example:\n+\n+    >>> callback = keras_core.callbacks.EarlyStopping(monitor='loss',\n+    ...                                               patience=3)\n+    >>> # This callback will stop the training when there is no improvement in\n+    >>> # the loss for three consecutive epochs.\n+    >>> model = keras_core.models.Sequential([keras_core.layers.Dense(10)])\n+    >>> model.compile(keras_core.optimizers.SGD(), loss='mse')\n+    >>> history = model.fit(np.arange(100).reshape(5, 20), np.zeros(5),\n+    ...                     epochs=10, batch_size=1, callbacks=[callback],\n+    ...                     verbose=0)\n+    >>> len(history.history['loss'])  # Only 4 epochs are run.\n+    4\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        monitor=\"val_loss\",\n+        min_delta=0,\n+        patience=0,\n+        verbose=0,\n+        mode=\"auto\",\n+        baseline=None,\n+        restore_best_weights=False,\n+        start_from_epoch=0,\n+    ):\n+        super().__init__()\n+\n+        self.monitor = monitor\n+        self.patience = patience\n+        self.verbose = verbose\n+        self.baseline = baseline\n+        self.min_delta = abs(min_delta)\n+        self.wait = 0\n+        self.stopped_epoch = 0\n+        self.restore_best_weights = restore_best_weights\n+        self.best_weights = None\n+        self.start_from_epoch = start_from_epoch\n+\n+        if mode not in [\"auto\", \"min\", \"max\"]:\n+            warnings.warn(\n+                f\"EarlyStopping mode {mode} is unknown, fallback to auto mode.\",\n+                stacklevel=2,\n+            )\n+            mode = \"auto\"\n+\n+        if mode == \"min\":\n+            self.monitor_op = ops.less\n+        elif mode == \"max\":\n+            self.monitor_op = ops.greater\n+        else:\n+            if (\n+                self.monitor.endswith(\"acc\")\n+                or self.monitor.endswith(\"accuracy\")\n+                or self.monitor.endswith(\"auc\")\n+            ):\n+                self.monitor_op = ops.greater\n+            else:\n+                self.monitor_op = ops.less\n+\n+        if self.monitor_op == ops.greater:\n+            self.min_delta *= 1\n+        else:\n+            self.min_delta *= -1\n+\n+    def on_train_begin(self, logs=None):\n+        # Allow instances to be re-used\n+        self.wait = 0\n+        self.stopped_epoch = 0\n+        self.best = (\n+            float(\"inf\") if self.monitor_op == ops.less else -float(\"inf\")\n+        )\n+        self.best_weights = None\n+        self.best_epoch = 0\n+\n+    def on_epoch_end(self, epoch, logs=None):\n+        current = self.get_monitor_value(logs)\n+        if current is None or epoch < self.start_from_epoch:\n+            # If no monitor value exists or still in initial warm-up stage.\n+            return\n+        if self.restore_best_weights and self.best_weights is None:\n+            # Restore the weights after first epoch if no progress is ever made.\n+            self.best_weights = self.model.get_weights()\n+\n+        self.wait += 1\n+        if self._is_improvement(current, self.best):\n+            self.best = current\n+            self.best_epoch = epoch\n+            if self.restore_best_weights:\n+                self.best_weights = self.model.get_weights()\n+            # Only restart wait if we beat both the baseline and our previous\n+            # best.\n+            if self.baseline is None or self._is_improvement(\n+                current, self.baseline\n+            ):\n+                self.wait = 0\n+            return\n+\n+        # Only check after the first epoch.\n+        if self.wait >= self.patience and epoch > 0:\n+            self.stopped_epoch = epoch\n+            self.model.stop_training = True\n+            if self.restore_best_weights and self.best_weights is not None:\n+                if self.verbose > 0:\n+                    io_utils.print_msg(\n+                        \"Restoring model weights from \"\n+                        \"the end of the best epoch: \"\n+                        f\"{self.best_epoch + 1}.\"\n+                    )\n+                self.model.set_weights(self.best_weights)\n+\n+    def on_train_end(self, logs=None):\n+        if self.stopped_epoch > 0 and self.verbose > 0:\n+            io_utils.print_msg(\n+                f\"Epoch {self.stopped_epoch + 1}: early stopping\"\n+            )\n+\n+    def get_monitor_value(self, logs):\n+        logs = logs or {}\n+        monitor_value = logs.get(self.monitor)\n+        if monitor_value is None:\n+            warnings.warn(\n+                (\n+                    f\"Early stopping conditioned on metric `{self.monitor}` \"\n+                    \"which is not available. \"\n+                    f\"Available metrics are: {','.join(list(logs.keys()))}\"\n+                ),\n+                stacklevel=2,\n+            )\n+        return monitor_value\n+\n+    def _is_improvement(self, monitor_value, reference_value):\n+        return self.monitor_op(monitor_value - self.min_delta, reference_value)\n\n@@ -0,0 +1,207 @@\n+import numpy as np\n+\n+from keras_core import callbacks\n+from keras_core import layers\n+from keras_core import models\n+from keras_core import testing\n+\n+\n+class EarlyStoppingTest(testing.TestCase):\n+    def test_early_stopping(self):\n+        x_train = np.random.random((10, 5))\n+        y_train = np.random.random((10, 1))\n+        x_test = np.random.random((10, 5))\n+        y_test = np.random.random((10, 1))\n+        model = models.Sequential(\n+            (\n+                layers.Dense(1, activation=\"relu\"),\n+                layers.Dense(1, activation=\"relu\"),\n+            )\n+        )\n+        model.compile(\n+            loss=\"mae\",\n+            optimizer=\"adam\",\n+            metrics=[\"mse\"],\n+        )\n+\n+        cases = [\n+            (\"max\", \"val_mse\"),\n+            (\"min\", \"val_loss\"),\n+            (\"auto\", \"val_mse\"),\n+            (\"auto\", \"loss\"),\n+            (\"unknown\", \"unknown\"),\n+        ]\n+        for mode, monitor in cases:\n+            patience = 0\n+            cbks = [\n+                callbacks.EarlyStopping(\n+                    patience=patience, monitor=monitor, mode=mode\n+                )\n+            ]\n+            model.fit(\n+                x_train,\n+                y_train,\n+                batch_size=5,\n+                validation_data=(x_test, y_test),\n+                callbacks=cbks,\n+                epochs=5,\n+                verbose=0,\n+            )\n+\n+    def test_early_stopping_patience(self):\n+        cases = [0, 1, 2, 3]\n+        losses = [10.0, 9.0, 8.0, 9.0, 8.9, 8.8, 8.7, 8.6, 8.5]\n+\n+        for patience in cases:\n+            stopper = callbacks.EarlyStopping(monitor=\"loss\", patience=patience)\n+            stopper.model = models.Sequential()\n+            stopper.model.compile(loss=\"mse\", optimizer=\"sgd\")\n+            stopper.on_train_begin()\n+\n+            for epoch, loss in enumerate(losses):\n+                stopper.on_epoch_end(epoch=epoch, logs={\"loss\": loss})\n+                if stopper.model.stop_training:\n+                    break\n+\n+            self.assertEqual(stopper.stopped_epoch, max(patience, 1) + 2)\n+\n+    def test_early_stopping_reuse(self):\n+        patience = 3\n+        data = np.random.random((100, 1))\n+        labels = np.where(data > 0.5, 1, 0)\n+        model = models.Sequential(\n+            (\n+                layers.Dense(1, activation=\"relu\"),\n+                layers.Dense(1, activation=\"relu\"),\n+            )\n+        )\n+        model.compile(\n+            optimizer=\"sgd\",\n+            loss=\"mae\",\n+            metrics=[\"mse\"],\n+        )\n+        weights = model.get_weights()\n+\n+        # This should allow training to go for at least `patience` epochs\n+        model.set_weights(weights)\n+\n+        stopper = callbacks.EarlyStopping(monitor=\"mse\", patience=patience)\n+        hist = model.fit(\n+            data, labels, callbacks=[stopper], verbose=0, epochs=20\n+        )\n+        assert len(hist.epoch) >= patience\n+\n+    def test_early_stopping_with_baseline(self):\n+        baseline = 0.6\n+        x_train = np.random.random((10, 5))\n+        y_train = np.random.random((10, 1))\n+        model = models.Sequential(\n+            (\n+                layers.Dense(1, activation=\"relu\"),\n+                layers.Dense(1, activation=\"relu\"),\n+            )\n+        )\n+        model.compile(optimizer=\"sgd\", loss=\"mae\", metrics=[\"mse\"])\n+\n+        patience = 3\n+        stopper = callbacks.EarlyStopping(\n+            monitor=\"mse\", patience=patience, baseline=baseline\n+        )\n+        hist = model.fit(\n+            x_train, y_train, callbacks=[stopper], verbose=0, epochs=20\n+        )\n+        assert len(hist.epoch) >= patience\n+\n+    def test_early_stopping_final_weights_when_restoring_model_weights(self):\n+        class DummyModel:\n+            def __init__(self):\n+                self.stop_training = False\n+                self.weights = -1\n+\n+            def get_weights(self):\n+                return self.weights\n+\n+            def set_weights(self, weights):\n+                self.weights = weights\n+\n+            def set_weight_to_epoch(self, epoch):\n+                self.weights = epoch\n+\n+        early_stop = callbacks.EarlyStopping(\n+            monitor=\"val_loss\", patience=2, restore_best_weights=True\n+        )\n+        early_stop.model = DummyModel()\n+        losses = [0.2, 0.15, 0.1, 0.11, 0.12]\n+        # The best configuration is in the epoch 2 (loss = 0.1000).\n+        epochs_trained = 0\n+        early_stop.on_train_begin()\n+        for epoch in range(len(losses)):\n+            epochs_trained += 1\n+            early_stop.model.set_weight_to_epoch(epoch=epoch)\n+            early_stop.on_epoch_end(epoch, logs={\"val_loss\": losses[epoch]})\n+            if early_stop.model.stop_training:\n+                break\n+        # The best configuration is in epoch 2 (loss = 0.1000),\n+        # and while patience = 2, we're restoring the best weights,\n+        # so we end up at the epoch with the best weights, i.e. epoch 2\n+        self.assertEqual(early_stop.model.get_weights(), 2)\n+\n+        # Check early stopping when no model beats the baseline.\n+        early_stop = callbacks.EarlyStopping(\n+            monitor=\"val_loss\",\n+            patience=5,\n+            baseline=0.5,\n+            restore_best_weights=True,\n+        )\n+        early_stop.model = DummyModel()\n+        losses = [0.9, 0.8, 0.7, 0.71, 0.72, 0.73]\n+        # The best configuration is in the epoch 2 (loss = 0.7000).\n+        epochs_trained = 0\n+        early_stop.on_train_begin()\n+        for epoch in range(len(losses)):\n+            epochs_trained += 1\n+            early_stop.model.set_weight_to_epoch(epoch=epoch)\n+            early_stop.on_epoch_end(epoch, logs={\"val_loss\": losses[epoch]})\n+            if early_stop.model.stop_training:\n+                break\n+        # No epoch improves on the baseline, so we should train for only 5\n+        # epochs, and restore the second model.\n+        self.assertEqual(epochs_trained, 5)\n+        self.assertEqual(early_stop.model.get_weights(), 2)\n+\n+    def test_early_stopping_with_start_from_epoch(self):\n+        x_train = np.random.random((10, 5))\n+        y_train = np.random.random((10, 1))\n+        model = models.Sequential(\n+            (\n+                layers.Dense(1, activation=\"relu\"),\n+                layers.Dense(1, activation=\"relu\"),\n+            )\n+        )\n+        model.compile(optimizer=\"sgd\", loss=\"mae\", metrics=[\"mse\"])\n+        start_from_epoch = 2\n+        patience = 3\n+        stopper = callbacks.EarlyStopping(\n+            monitor=\"mse\",\n+            patience=patience,\n+            start_from_epoch=start_from_epoch,\n+        )\n+        history = model.fit(\n+            x_train, y_train, callbacks=[stopper], verbose=0, epochs=20\n+        )\n+        # Test 'patience' argument functions correctly when used\n+        # in conjunction with 'start_from_epoch'.\n+        self.assertGreaterEqual(len(history.epoch), patience + start_from_epoch)\n+\n+        start_from_epoch = 2\n+        patience = 0\n+        stopper = callbacks.EarlyStopping(\n+            monitor=\"mse\",\n+            patience=patience,\n+            start_from_epoch=start_from_epoch,\n+        )\n+        history = model.fit(\n+            x_train, y_train, callbacks=[stopper], verbose=0, epochs=20\n+        )\n+        # Test for boundary condition when 'patience' = 0.\n+        self.assertGreaterEqual(len(history.epoch), start_from_epoch)\n\n@@ -1,5 +1,8 @@\n+import numpy as np\n+\n from keras_core import backend\n from keras_core import operations as ops\n+from keras_core.api_export import keras_core_export\n \n \n def l2_normalize(x, axis=0):\n@@ -7,3 +10,61 @@ def l2_normalize(x, axis=0):\n     square_sum = ops.sum(ops.square(x), axis=axis, keepdims=True)\n     l2_norm = ops.reciprocal(ops.sqrt(ops.maximum(square_sum, epsilon)))\n     return ops.multiply(x, l2_norm)\n+\n+\n+@keras_core_export(\"keras_core.utils.to_categorical\")\n+def to_categorical(x, num_classes=None):\n+    \"\"\"Converts a class vector (integers) to binary class matrix.\n+\n+    E.g. for use with `categorical_crossentropy`.\n+\n+    Args:\n+        x: Array-like with class values to be converted into a matrix\n+            (integers from 0 to `num_classes - 1`).\n+        num_classes: Total number of classes. If `None`, this would be inferred\n+            as `max(x) + 1`. Defaults to `None`.\n+\n+    Returns:\n+        A binary matrix representation of the input as a NumPy array. The class\n+        axis is placed last.\n+\n+    Example:\n+\n+    >>> a = keras_core.utils.to_categorical([0, 1, 2, 3], num_classes=4)\n+    >>> print(a)\n+    [[1. 0. 0. 0.]\n+     [0. 1. 0. 0.]\n+     [0. 0. 1. 0.]\n+     [0. 0. 0. 1.]]\n+\n+    >>> b = np.array([.9, .04, .03, .03,\n+    ...               .3, .45, .15, .13,\n+    ...               .04, .01, .94, .05,\n+    ...               .12, .21, .5, .17],\n+    ...               shape=[4, 4])\n+    >>> loss = keras_core.backend.categorical_crossentropy(a, b)\n+    >>> print(np.around(loss, 5))\n+    [0.10536 0.82807 0.1011  1.77196]\n+\n+    >>> loss = keras_core.backend.categorical_crossentropy(a, a)\n+    >>> print(np.around(loss, 5))\n+    [0. 0. 0. 0.]\n+    \"\"\"\n+    if backend.is_tensor(x):\n+        return backend.nn.one_hot(x, num_classes)\n+    x = np.array(x, dtype=\"int64\")\n+    input_shape = x.shape\n+\n+    # Shrink the last dimension if the shape is (..., 1).\n+    if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n+        input_shape = tuple(input_shape[:-1])\n+\n+    x = x.reshape(-1)\n+    if not num_classes:\n+        num_classes = np.max(x) + 1\n+    batch_size = x.shape[0]\n+    categorical = np.zeros((batch_size, num_classes))\n+    categorical[np.arange(batch_size), x] = 1\n+    output_shape = input_shape + (num_classes,)\n+    categorical = np.reshape(categorical, output_shape)\n+    return categorical\n\n@@ -0,0 +1,54 @@\n+import numpy as np\n+from absl.testing import parameterized\n+\n+from keras_core import backend\n+from keras_core import testing\n+from keras_core.utils import numerical_utils\n+\n+NUM_CLASSES = 5\n+\n+\n+class TestNumericalUtils(testing.TestCase, parameterized.TestCase):\n+    @parameterized.parameters(\n+        [\n+            ((1,), (1, NUM_CLASSES)),\n+            ((3,), (3, NUM_CLASSES)),\n+            ((4, 3), (4, 3, NUM_CLASSES)),\n+            ((5, 4, 3), (5, 4, 3, NUM_CLASSES)),\n+            ((3, 1), (3, NUM_CLASSES)),\n+            ((3, 2, 1), (3, 2, NUM_CLASSES)),\n+        ]\n+    )\n+    def test_to_categorical(self, shape, expected_shape):\n+        label = np.random.randint(0, NUM_CLASSES, shape)\n+        one_hot = numerical_utils.to_categorical(label, NUM_CLASSES)\n+        # Check shape\n+        self.assertEqual(one_hot.shape, expected_shape)\n+        # Make sure there is only one 1 in a row\n+        self.assertTrue(np.all(one_hot.sum(axis=-1) == 1))\n+        # Get original labels back from one hots\n+        self.assertTrue(\n+            np.all(np.argmax(one_hot, -1).reshape(label.shape) == label)\n+        )\n+\n+    def test_to_categorial_without_num_classes(self):\n+        label = [0, 2, 5]\n+        one_hot = numerical_utils.to_categorical(label)\n+        self.assertEqual(one_hot.shape, (3, 5 + 1))\n+\n+    def test_to_categorical_with_backend_tensor(self):\n+        label = backend.convert_to_tensor(np.array([0, 2, 1, 3, 4]))\n+        expected = backend.convert_to_tensor(\n+            np.array(\n+                [\n+                    [1, 0, 0, 0, 0],\n+                    [0, 0, 1, 0, 0],\n+                    [0, 1, 0, 0, 0],\n+                    [0, 0, 0, 1, 0],\n+                    [0, 0, 0, 0, 1],\n+                ]\n+            )\n+        )\n+        one_hot = numerical_utils.to_categorical(label, NUM_CLASSES)\n+        assert backend.is_tensor(one_hot)\n+        self.assertAllClose(one_hot, expected)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e7c4d09b6303c5c8bbd0da8772d39ba75a0e1acc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 184 | Lines Deleted: 43 | Files Changed: 7 | Hunks: 21 | Methods Changed: 23 | Complexity Δ (Sum/Max): 411/204 | Churn Δ: 227 | Churn Cumulative: 13219 | Contributors (this commit): 20 | Commits (past 90d): 26 | Contributors (cumulative): 63 | DMM Complexity: 1.0\n\nDIFF:\n@@ -120,6 +120,23 @@ class TestDeferredSequential(test_combinations.TestCase):\n         # Check that inputs and outputs are connected\n         _ = extractor(np.random.random((4, 6)))\n \n+    @test_combinations.run_all_keras_modes(always_skip_v1=True)\n+    def test_saving_keras_v3(self):\n+        model = get_model()\n+        model(np.random.random((3, 6)))  # Build model\n+\n+        path = os.path.join(self.get_temp_dir(), \"model_path.keras\")\n+        model.save(path)\n+        new_model = keras.models.load_model(path)\n+        model_layers = model._flatten_layers(include_self=True, recursive=False)\n+        new_model_layers = new_model._flatten_layers(\n+            include_self=True, recursive=False\n+        )\n+        for layer1, layer2 in zip(model_layers, new_model_layers):\n+            self.assertEqual(layer1.name, layer2.name)\n+            for w1, w2 in zip(layer1.weights, layer2.weights):\n+                self.assertAllClose(w1, w2)\n+\n     @test_combinations.run_all_keras_modes(always_skip_v1=True)\n     def test_saving_savedmodel(self):\n         model = get_model()\n\n@@ -28,6 +28,7 @@ from keras.engine import functional\n from keras.engine import input_layer as input_layer_lib\n from keras.engine import sequential\n from keras.engine import training as training_lib\n+from keras.saving import object_registration\n from keras.saving.legacy import save\n from keras.testing_infra import test_combinations\n from keras.testing_infra import test_utils\n@@ -1875,7 +1876,7 @@ class DefaultShapeInferenceBehaviorTest(test_combinations.TestCase):\n         test_combinations.combine(mode=[\"graph\", \"eager\"])\n     )\n     @test_utils.run_v2_only\n-    def test_save_load_with_single_elem_list_inputs(self):\n+    def test_save_load_with_single_elem_list_inputs_saved_model(self):\n         class MyLayer(layers.Layer):\n             def __init__(self):\n                 super().__init__()\n@@ -1893,6 +1894,26 @@ class DefaultShapeInferenceBehaviorTest(test_combinations.TestCase):\n \n         save.load_model(\"/tmp/km2\")\n \n+    @test_utils.run_v2_only\n+    def test_save_load_with_single_elem_list_inputs_keras_v3(self):\n+        @object_registration.register_keras_serializable()\n+        class MyLayer(layers.Layer):\n+            def __init__(self):\n+                super().__init__()\n+                self._preserve_input_structure_in_config = True\n+\n+            def call(self, inputs):\n+                return inputs[0]\n+\n+        inputs = input_layer_lib.Input(shape=(3,))\n+        layer = MyLayer()\n+        outputs = layer([inputs])\n+\n+        model = training_lib.Model(inputs=inputs, outputs=outputs)\n+        model.save(\"/tmp/model.keras\")\n+\n+        models.load_model(\"/tmp/model.keras\")\n+\n     @test_combinations.generate(\n         test_combinations.combine(mode=[\"graph\", \"eager\"])\n     )\n\n@@ -151,11 +151,6 @@ class FunctionalModelSlideTest(test_combinations.TestCase):\n         model.fit(\n             np.random.randn(batch_size, 32), np.random.randn(batch_size, 16)\n         )\n-        # Test for model saving\n-        output_path = os.path.join(self.get_temp_dir(), \"tf_keras_saved_model\")\n-        model.save(output_path, save_format=\"tf\")\n-        loaded_model = models.load_model(output_path)\n-        self.assertEqual(model.summary(), loaded_model.summary())\n \n         # Also make sure the original inputs and y can still be used to build\n         # model\n@@ -167,6 +162,27 @@ class FunctionalModelSlideTest(test_combinations.TestCase):\n         self.assertIs(new_model.layers[1], layer1)\n         self.assertIs(new_model.layers[2], layer2)\n \n+        # Test for model saving\n+        with self.subTest(\"savedmodel\"):\n+            output_path = os.path.join(\n+                self.get_temp_dir(), \"tf_keras_saved_model\"\n+            )\n+            model.save(output_path, save_format=\"tf\")\n+            loaded_model = models.load_model(output_path)\n+            self.assertEqual(model.summary(), loaded_model.summary())\n+\n+        with self.subTest(\"keras_v3\"):\n+            if not tf.__internal__.tf2.enabled():\n+                self.skipTest(\n+                    \"TF2 must be enabled to use the new `.keras` saving.\"\n+                )\n+            output_path = os.path.join(\n+                self.get_temp_dir(), \"tf_keras_v3_model.keras\"\n+            )\n+            model.save(output_path, save_format=\"keras_v3\")\n+            loaded_model = models.load_model(output_path)\n+            self.assertEqual(model.summary(), loaded_model.summary())\n+\n     def test_build_model_from_intermediate_tensor_with_complicated_model(self):\n         # The topology is like below:\n         # input1 -> dense1 -> a\n@@ -212,10 +228,6 @@ class FunctionalModelSlideTest(test_combinations.TestCase):\n             ],\n             np.random.randn(batch_size, 8),\n         )\n-        output_path = os.path.join(self.get_temp_dir(), \"tf_keras_saved_model\")\n-        model.save(output_path, save_format=\"tf\")\n-        loaded_model = models.load_model(output_path)\n-        self.assertEqual(model.summary(), loaded_model.summary())\n \n         model2 = models.Model([a, b], d)\n         # 2 input layers and 2 Add layer.\n@@ -230,6 +242,26 @@ class FunctionalModelSlideTest(test_combinations.TestCase):\n             np.random.randn(batch_size, 8),\n         )\n \n+        with self.subTest(\"savedmodel\"):\n+            output_path = os.path.join(\n+                self.get_temp_dir(), \"tf_keras_saved_model\"\n+            )\n+            model.save(output_path, save_format=\"tf\")\n+            loaded_model = models.load_model(output_path)\n+            self.assertEqual(model.summary(), loaded_model.summary())\n+\n+        with self.subTest(\"keras_v3\"):\n+            if not tf.__internal__.tf2.enabled():\n+                self.skipTest(\n+                    \"TF2 must be enabled to use the new `.keras` saving.\"\n+                )\n+            output_path = os.path.join(\n+                self.get_temp_dir(), \"tf_keras_v3_model.keras\"\n+            )\n+            model.save(output_path, save_format=\"keras_v3\")\n+            loaded_model = models.load_model(output_path)\n+            self.assertEqual(model.summary(), loaded_model.summary())\n+\n \n if __name__ == \"__main__\":\n     tf.test.main()\n\n@@ -89,7 +89,7 @@ class DropoutLayersTest(test_combinations.TestCase):\n         # Test that dropout mask is shared across second dim.\n         self.assertAllClose(out_np[:, 0, :], out_np[:, 1, :])\n \n-    def test_dropout_with_savemodel(self):\n+    def test_dropout_with_saving(self):\n         inputs = keras.Input(shape=(5, 10))\n         layer = keras.layers.Dropout(0.5, force_generator=True)\n         outputs = layer(inputs)\n@@ -105,8 +105,10 @@ class DropoutLayersTest(test_combinations.TestCase):\n         # Make sure the layer does dropout value when training\n         self.assertNotAllClose(train, predict)\n \n+        with self.subTest(\"savedmodel\"):\n             model.save(\n-            os.path.join(self.get_temp_dir(), \"savedmodel\"), save_format=\"tf\"\n+                os.path.join(self.get_temp_dir(), \"savedmodel\"),\n+                save_format=\"tf\",\n             )\n             loaded_model = keras.models.load_model(\n                 os.path.join(self.get_temp_dir(), \"savedmodel\")\n@@ -119,8 +121,26 @@ class DropoutLayersTest(test_combinations.TestCase):\n             self.assertNotAllClose(train, train2)\n             self.assertIsNotNone(loaded_model.layers[1]._random_generator)\n \n-        # Also make sure the checkpoint doesn't contain any variable from the\n-        # dropout layer, to keep the backward compatibility.\n+        with self.subTest(\"keras_v3\"):\n+            if not tf.__internal__.tf2.enabled():\n+                self.skipTest(\n+                    \"TF2 must be enabled to use the new `.keras` saving.\"\n+                )\n+            model.save(os.path.join(self.get_temp_dir(), \"model.keras\"))\n+            loaded_model = keras.models.load_model(\n+                os.path.join(self.get_temp_dir(), \"model.keras\")\n+            )\n+            predict2 = loaded_model(np.ones((20, 5, 10)))\n+\n+            self.assertAllClose(predict, predict2)\n+            # Make sure the model dropout different value after loading\n+            train2 = loaded_model(np.ones((20, 5, 10)), training=True)\n+            self.assertNotAllClose(train, train2)\n+            self.assertIsNotNone(loaded_model.layers[1]._random_generator)\n+\n+        with self.subTest(\"checkpoint\"):\n+            # Also make sure the checkpoint doesn't contain any variable from\n+            # the dropout layer, to keep the backward compatibility.\n             checkpoint = tf.train.Checkpoint(model)\n             save_path = checkpoint.save(\n                 os.path.join(self.get_temp_dir(), \"checkpoint\")\n\n@@ -109,6 +109,7 @@ class SharpnessAwareMinimizationTest(tf.test.TestCase, parameterized.TestCase):\n \n         sam_model.fit(data, label)\n \n+        with self.subTest(\"savedmodel\"):\n             path = os.path.join(self.get_temp_dir(), \"model\")\n             sam_model.save(path)\n             loaded_sam_model = keras.models.load_model(path)\n@@ -116,6 +117,14 @@ class SharpnessAwareMinimizationTest(tf.test.TestCase, parameterized.TestCase):\n \n             self.assertAllClose(sam_model(data), loaded_sam_model(data))\n \n+        with self.subTest(\"keras_v3\"):\n+            path = os.path.join(self.get_temp_dir(), \"model.keras\")\n+            sam_model.save(path)\n+            loaded_sam_model = keras.models.load_model(path)\n+            loaded_sam_model.load_weights(path)\n+\n+            self.assertAllClose(sam_model(data), loaded_sam_model(data))\n+\n     def test_checkpoint_sam(self):\n         model = keras.Sequential(\n             [\n\n@@ -527,6 +527,17 @@ class OptimizerFuntionalityTest(tf.test.TestCase, parameterized.TestCase):\n         loaded_optimizer.build(loaded_model.trainable_variables)\n         self.assertAllClose(optimizer.variables, loaded_optimizer.variables)\n \n+        # Save in `.keras` format.\n+        path = os.path.join(self.get_temp_dir(), \"model.keras\")\n+        model.save(path)\n+        loaded_model = keras.models.load_model(path)\n+        loaded_model.load_weights(path)\n+        loaded_optimizer = loaded_model.optimizer\n+        self.assertEqual(type(optimizer), type(loaded_optimizer))\n+        self.assertEqual(loaded_optimizer.learning_rate, 0.002)\n+        self.assertEqual(loaded_optimizer.clipnorm, 0.1)\n+        self.assertAllClose(optimizer.variables, loaded_optimizer.variables)\n+\n     @parameterized.product(optimizer_fn=OPTIMIZER_FN)\n     def testSparseGradientsWorkAsExpected(self, optimizer_fn):\n         optimizer_1 = optimizer_fn()\n\n@@ -25,6 +25,7 @@ import tensorflow.compat.v2 as tf\n import keras\n from keras.saving import serialization_lib\n from keras.saving.legacy import serialization\n+from keras.testing_infra import test_utils\n from keras.utils import generic_utils\n from keras.utils import io_utils\n \n@@ -324,6 +325,30 @@ class MaybeSharedObject:\n     pass\n \n \n+class CustomModelX(keras.Model):\n+    def __init__(self, *args, **kwargs):\n+        super().__init__(*args, **kwargs)\n+        self.dense1 = keras.layers.Dense(1)\n+        self.train_step_message = \"This is my training step\"\n+\n+    def call(self, inputs):\n+        return self.dense1(inputs)\n+\n+    def train_step(self, data):\n+        tf.print(self.train_step_message)\n+        x, y = data\n+        with tf.GradientTape() as tape:\n+            y_pred = self(x)\n+            loss = self.compiled_loss(y, y_pred)\n+\n+        gradients = tape.gradient(loss, self.trainable_variables)\n+        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n+        return {}\n+\n+    def func_that_returns_one(self):\n+        return 1\n+\n+\n class SharedObjectScopeTest(tf.test.TestCase):\n     def test_shared_object_saving_scope_single_object_doesnt_export_id(self):\n         with serialization.SharedObjectSavingScope() as scope:\n@@ -375,40 +400,16 @@ class SharedObjectScopeTest(tf.test.TestCase):\n             self.assertIsNotNone(scope_1.get_config(my_obj))\n         self.assertIsNone(serialization._shared_object_saving_scope())\n \n-    def test_custom_object_scope_correct_class(self):\n-        train_step_message = \"This is my training step\"\n+    def test_custom_object_scope_correct_class_saved_model(self):\n         temp_dir = os.path.join(self.get_temp_dir(), \"my_model\")\n \n-        class CustomModelX(keras.Model):\n-            def __init__(self, *args, **kwargs):\n-                super().__init__(*args, **kwargs)\n-                self.dense1 = keras.layers.Dense(1)\n-\n-            def call(self, inputs):\n-                return self.dense1(inputs)\n-\n-            def train_step(self, data):\n-                tf.print(train_step_message)\n-                x, y = data\n-                with tf.GradientTape() as tape:\n-                    y_pred = self(x)\n-                    loss = self.compiled_loss(y, y_pred)\n-\n-                gradients = tape.gradient(loss, self.trainable_variables)\n-                self.optimizer.apply_gradients(\n-                    zip(gradients, self.trainable_variables)\n-                )\n-                return {}\n-\n-            def func_that_returns_one(self):\n-                return 1\n-\n         subclassed_model = CustomModelX()\n         subclassed_model.compile(optimizer=\"adam\", loss=\"mse\")\n \n         x = np.random.random((100, 32))\n         y = np.random.random((100, 1))\n         subclassed_model.fit(x, y, epochs=1)\n+\n         subclassed_model.save(temp_dir, save_format=\"tf\")\n \n         with keras.utils.custom_object_scope({\"CustomModelX\": CustomModelX}):\n@@ -419,9 +420,39 @@ class SharedObjectScopeTest(tf.test.TestCase):\n         with self.captureWritesToStream(sys.stderr) as printed:\n             loaded_model.fit(x, y, epochs=1)\n             if tf.__internal__.tf2.enabled():\n-                # `tf.print` message is only available in stderr in TF2. Check\n-                # that custom `train_step` is used.\n-                self.assertRegex(printed.contents(), train_step_message)\n+                # `tf.print` message is only available in stderr in TF2.\n+                # Check that custom `train_step` is used.\n+                self.assertRegex(printed.contents(), \"This is my training step\")\n+\n+        # Check that the custom class does get used.\n+        self.assertIsInstance(loaded_model, CustomModelX)\n+        # Check that the custom method is available.\n+        self.assertEqual(loaded_model.func_that_returns_one(), 1)\n+\n+    @test_utils.run_v2_only\n+    def test_custom_object_scope_correct_class_keras_v3(self):\n+        temp_dir = os.path.join(self.get_temp_dir(), \"my_model.keras\")\n+\n+        subclassed_model = CustomModelX()\n+        subclassed_model.compile(optimizer=\"adam\", loss=\"mse\")\n+\n+        x = np.random.random((100, 32))\n+        y = np.random.random((100, 1))\n+        subclassed_model.fit(x, y, epochs=1)\n+\n+        subclassed_model.save(temp_dir, save_format=\"keras_v3\")\n+\n+        with keras.utils.custom_object_scope({\"CustomModelX\": CustomModelX}):\n+            loaded_model = keras.models.load_model(temp_dir)\n+\n+        io_utils.enable_interactive_logging()\n+        # `tf.print` writes to stderr.\n+        with self.captureWritesToStream(sys.stderr) as printed:\n+            loaded_model.fit(x, y, epochs=1)\n+            if tf.__internal__.tf2.enabled():\n+                # `tf.print` message is only available in stderr in TF2.\n+                # Check that custom `train_step` is used.\n+                self.assertRegex(printed.contents(), \"This is my training step\")\n \n         # Check that the custom class does get used.\n         self.assertIsInstance(loaded_model, CustomModelX)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
