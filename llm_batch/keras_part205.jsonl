{"custom_id": "keras#59f9894ff7a00df6e6f14c5bec781493b3684d2d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 127 | Lines Deleted: 66 | Files Changed: 4 | Hunks: 32 | Methods Changed: 12 | Complexity Δ (Sum/Max): 9/9 | Churn Δ: 193 | Churn Cumulative: 4103 | Contributors (this commit): 57 | Commits (past 90d): 27 | Contributors (cumulative): 63 | DMM Complexity: 1.0\n\nDIFF:\n@@ -105,7 +105,8 @@ else:\n                                      batch_size=batch_size),\n                         steps_per_epoch=x_train.shape[0] // batch_size,\n                         epochs=epochs,\n-                        validation_data=(x_test, y_test))\n+                        validation_data=(x_test, y_test),\n+                        workers=4)\n \n # Save model and weights\n if not os.path.isdir(save_dir):\n@@ -129,14 +130,17 @@ with open(label_list_path, mode='rb') as f:\n \n # Evaluate model with test data set and share sample prediction results\n evaluation = model.evaluate_generator(datagen.flow(x_test, y_test,\n-                                      batch_size=batch_size),\n-                                      steps=x_test.shape[0] // batch_size)\n-\n+                                                   batch_size=batch_size,\n+                                                   shuffle=False),\n+                                      steps=x_test.shape[0] // batch_size,\n+                                      workers=4)\n print('Model Accuracy = %.2f' % (evaluation[1]))\n \n predict_gen = model.predict_generator(datagen.flow(x_test, y_test,\n-                                      batch_size=batch_size),\n-                                      steps=x_test.shape[0] // batch_size)\n+                                                   batch_size=batch_size,\n+                                                   shuffle=False),\n+                                      steps=x_test.shape[0] // batch_size,\n+                                      workers=4)\n \n for predict_index, predicted_y in enumerate(predict_gen):\n     actual_label = labels['label_names'][np.argmax(y_test[predict_index])]\n\n@@ -17,6 +17,7 @@ import multiprocessing.pool\n from functools import partial\n \n from .. import backend as K\n+from ..utils.data_utils import Sequence\n \n try:\n     from PIL import Image as pil_image\n@@ -684,7 +685,7 @@ class ImageDataGenerator(object):\n             self.principal_components = np.dot(np.dot(u, np.diag(1. / np.sqrt(s + self.zca_epsilon))), u.T)\n \n \n-class Iterator(object):\n+class Iterator(Sequence):\n     \"\"\"Abstract base class for image data iterators.\n \n     # Arguments\n@@ -697,36 +698,60 @@ class Iterator(object):\n     def __init__(self, n, batch_size, shuffle, seed):\n         self.n = n\n         self.batch_size = batch_size\n+        self.seed = seed\n         self.shuffle = shuffle\n         self.batch_index = 0\n         self.total_batches_seen = 0\n         self.lock = threading.Lock()\n-        self.index_generator = self._flow_index(n, batch_size, shuffle, seed)\n+        self.index_array = None\n+        self.index_generator = self._flow_index()\n+\n+    def _set_index_array(self):\n+        self.index_array = np.arange(self.n)\n+        if self.shuffle:\n+            self.index_array = np.random.permutation(self.n)\n+\n+    def __getitem__(self, idx):\n+        if idx >= len(self):\n+            raise ValueError('Asked to retrieve element {idx}, '\n+                             'but the Sequence '\n+                             'has length {length}'.format(idx=idx,\n+                                                          length=len(self)))\n+        if self.seed is not None:\n+            np.random.seed(self.seed + self.total_batches_seen)\n+        self.total_batches_seen += 1\n+        if self.index_array is None:\n+            self._set_index_array()\n+        index_array = self.index_array[self.batch_size * idx:\n+                                       self.batch_size * (idx + 1)]\n+        return self._get_batches_of_transformed_samples(index_array)\n+\n+    def __len__(self):\n+        return int(np.ceil(self.n / float(self.batch_size)))\n+\n+    def on_epoch_end(self):\n+        self._set_index_array()\n \n     def reset(self):\n         self.batch_index = 0\n \n-    def _flow_index(self, n, batch_size=32, shuffle=False, seed=None):\n+    def _flow_index(self):\n         # Ensure self.batch_index is 0.\n         self.reset()\n         while 1:\n-            if seed is not None:\n-                np.random.seed(seed + self.total_batches_seen)\n+            if self.seed is not None:\n+                np.random.seed(self.seed + self.total_batches_seen)\n             if self.batch_index == 0:\n-                index_array = np.arange(n)\n-                if shuffle:\n-                    index_array = np.random.permutation(n)\n+                self._set_index_array()\n \n-            current_index = (self.batch_index * batch_size) % n\n-            if n > current_index + batch_size:\n-                current_batch_size = batch_size\n+            current_index = (self.batch_index * self.batch_size) % self.n\n+            if self.n > current_index + self.batch_size:\n                 self.batch_index += 1\n             else:\n-                current_batch_size = n - current_index\n                 self.batch_index = 0\n             self.total_batches_seen += 1\n-            yield (index_array[current_index: current_index + current_batch_size],\n-                   current_index, current_batch_size)\n+            yield self.index_array[current_index:\n+                                   current_index + self.batch_size]\n \n     def __iter__(self):\n         # Needed if we want to do something like:\n@@ -796,6 +821,27 @@ class NumpyArrayIterator(Iterator):\n         self.save_format = save_format\n         super(NumpyArrayIterator, self).__init__(x.shape[0], batch_size, shuffle, seed)\n \n+    def _get_batches_of_transformed_samples(self, index_array):\n+        batch_x = np.zeros(tuple([len(index_array)] + list(self.x.shape)[1:]),\n+                           dtype=K.floatx())\n+        for i, j in enumerate(index_array):\n+            x = self.x[j]\n+            x = self.image_data_generator.random_transform(x.astype(K.floatx()))\n+            x = self.image_data_generator.standardize(x)\n+            batch_x[i] = x\n+        if self.save_to_dir:\n+            for i, j in enumerate(index_array):\n+                img = array_to_img(batch_x[i], self.data_format, scale=True)\n+                fname = '{prefix}_{index}_{hash}.{format}'.format(prefix=self.save_prefix,\n+                                                                  index=j,\n+                                                                  hash=np.random.randint(1e4),\n+                                                                  format=self.save_format)\n+                img.save(os.path.join(self.save_to_dir, fname))\n+        if self.y is None:\n+            return batch_x\n+        batch_y = self.y[index_array]\n+        return batch_x, batch_y\n+\n     def next(self):\n         \"\"\"For python 2.x.\n \n@@ -805,27 +851,10 @@ class NumpyArrayIterator(Iterator):\n         # Keeps under lock only the mechanism which advances\n         # the indexing of each batch.\n         with self.lock:\n-            index_array, current_index, current_batch_size = next(self.index_generator)\n+            index_array = next(self.index_generator)\n         # The transformation of images is not under thread lock\n         # so it can be done in parallel\n-        batch_x = np.zeros(tuple([current_batch_size] + list(self.x.shape)[1:]), dtype=K.floatx())\n-        for i, j in enumerate(index_array):\n-            x = self.x[j]\n-            x = self.image_data_generator.random_transform(x.astype(K.floatx()))\n-            x = self.image_data_generator.standardize(x)\n-            batch_x[i] = x\n-        if self.save_to_dir:\n-            for i in range(current_batch_size):\n-                img = array_to_img(batch_x[i], self.data_format, scale=True)\n-                fname = '{prefix}_{index}_{hash}.{format}'.format(prefix=self.save_prefix,\n-                                                                  index=current_index + i,\n-                                                                  hash=np.random.randint(1e4),\n-                                                                  format=self.save_format)\n-                img.save(os.path.join(self.save_to_dir, fname))\n-        if self.y is None:\n-            return batch_x\n-        batch_y = self.y[index_array]\n-        return batch_x, batch_y\n+        return self._get_batches_of_transformed_samples(index_array)\n \n \n def _count_valid_files_in_directory(directory, white_list_formats, follow_links):\n@@ -1013,17 +1042,8 @@ class DirectoryIterator(Iterator):\n         pool.join()\n         super(DirectoryIterator, self).__init__(self.samples, batch_size, shuffle, seed)\n \n-    def next(self):\n-        \"\"\"For python 2.x.\n-\n-        # Returns\n-            The next batch.\n-        \"\"\"\n-        with self.lock:\n-            index_array, current_index, current_batch_size = next(self.index_generator)\n-        # The transformation of images is not under thread lock\n-        # so it can be done in parallel\n-        batch_x = np.zeros((current_batch_size,) + self.image_shape, dtype=K.floatx())\n+    def _get_batches_of_transformed_samples(self, index_array):\n+        batch_x = np.zeros((len(index_array),) + self.image_shape, dtype=K.floatx())\n         grayscale = self.color_mode == 'grayscale'\n         # build batch of image data\n         for i, j in enumerate(index_array):\n@@ -1037,10 +1057,10 @@ class DirectoryIterator(Iterator):\n             batch_x[i] = x\n         # optionally save augmented images to disk for debugging purposes\n         if self.save_to_dir:\n-            for i in range(current_batch_size):\n+            for i, j in enumerate(index_array):\n                 img = array_to_img(batch_x[i], self.data_format, scale=True)\n                 fname = '{prefix}_{index}_{hash}.{format}'.format(prefix=self.save_prefix,\n-                                                                  index=current_index + i,\n+                                                                  index=j,\n                                                                   hash=np.random.randint(1e4),\n                                                                   format=self.save_format)\n                 img.save(os.path.join(self.save_to_dir, fname))\n@@ -1058,3 +1078,15 @@ class DirectoryIterator(Iterator):\n         else:\n             return batch_x\n         return batch_x, batch_y\n+\n+    def next(self):\n+        \"\"\"For python 2.x.\n+\n+        # Returns\n+            The next batch.\n+        \"\"\"\n+        with self.lock:\n+            index_array = next(self.index_generator)\n+        # The transformation of images is not under thread lock\n+        # so it can be done in parallel\n+        return self._get_batches_of_transformed_samples(index_array)\n\n@@ -313,15 +313,16 @@ class Sequence(object):\n     # and `y_set` are the associated classes.\n \n     class CIFAR10Sequence(Sequence):\n+\n         def __init__(self, x_set, y_set, batch_size):\n-            self.X,self.y = x_set,y_set\n+            self.x, self.y = x_set, y_set\n             self.batch_size = batch_size\n \n         def __len__(self):\n-            return len(self.X) // self.batch_size\n+            return len(self.x) // self.batch_size\n \n         def __getitem__(self, idx):\n-            batch_x = self.X[idx*self.batch_size:(idx+1)*self.batch_size]\n+            batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n             batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n \n             return np.array([\n\n@@ -5,20 +5,20 @@ import numpy as np\n import os\n \n \n-class TestImage:\n+class TestImage(object):\n \n     def setup_class(cls):\n-        img_w = img_h = 20\n+        cls.img_w = cls.img_h = 20\n         rgb_images = []\n         gray_images = []\n         for n in range(8):\n-            bias = np.random.rand(img_w, img_h, 1) * 64\n-            variance = np.random.rand(img_w, img_h, 1) * (255 - 64)\n-            imarray = np.random.rand(img_w, img_h, 3) * variance + bias\n+            bias = np.random.rand(cls.img_w, cls.img_h, 1) * 64\n+            variance = np.random.rand(cls.img_w, cls.img_h, 1) * (255 - 64)\n+            imarray = np.random.rand(cls.img_w, cls.img_h, 3) * variance + bias\n             im = Image.fromarray(imarray.astype('uint8')).convert('RGB')\n             rgb_images.append(im)\n \n-            imarray = np.random.rand(img_w, img_h, 1) * variance + bias\n+            imarray = np.random.rand(cls.img_w, cls.img_h, 1) * variance + bias\n             im = Image.fromarray(imarray.astype('uint8').squeeze()).convert('L')\n             gray_images.append(im)\n \n@@ -53,10 +53,19 @@ class TestImage:\n             generator.fit(images, augment=True)\n \n             for x, y in generator.flow(images, np.arange(images.shape[0]),\n-                                       shuffle=True, save_to_dir=str(tmpdir)):\n-                assert x.shape[1:] == images.shape[1:]\n+                                       shuffle=True, save_to_dir=str(tmpdir),\n+                                       batch_size=3):\n+                assert x.shape == images[:3].shape\n                 break\n \n+            # Test `flow` behavior as Sequence\n+            seq = generator.flow(images, np.arange(images.shape[0]),\n+                                 shuffle=True, save_to_dir=str(tmpdir),\n+                                 batch_size=3)\n+            assert len(seq) == images.shape[0] // 3 + 1\n+            x, y = seq[0]\n+            assert x.shape == images[:3].shape\n+\n     def test_image_data_generator_invalid_data(self):\n         generator = image.ImageDataGenerator(\n             featurewise_center=True,\n@@ -140,9 +149,9 @@ class TestImage:\n         dir_iterator = generator.flow_from_directory(str(tmpdir))\n \n         # check number of classes and images\n-        assert(len(dir_iterator.class_indices) == num_classes)\n-        assert(len(dir_iterator.classes) == count)\n-        assert(sorted(dir_iterator.filenames) == sorted(filenames))\n+        assert len(dir_iterator.class_indices) == num_classes\n+        assert len(dir_iterator.classes) == count\n+        assert sorted(dir_iterator.filenames) == sorted(filenames)\n \n         # Test invalid use cases\n         with pytest.raises(ValueError):\n@@ -150,6 +159,21 @@ class TestImage:\n         with pytest.raises(ValueError):\n             generator.flow_from_directory(str(tmpdir), class_mode='output')\n \n+        # Test usage as Sequence\n+        generator = image.ImageDataGenerator()\n+        dir_seq = generator.flow_from_directory(str(tmpdir),\n+                                                target_size=(26, 26),\n+                                                color_mode='rgb',\n+                                                batch_size=3,\n+                                                class_mode='categorical')\n+        assert len(dir_seq) == count // 3 + 1\n+        x1, y1 = dir_seq[1]\n+        assert x1.shape == (3, 26, 26, 3)\n+        assert y1.shape == (3, num_classes)\n+        x1, y1 = dir_seq[5]\n+        with pytest.raises(ValueError):\n+            x1, y1 = dir_seq[9]\n+\n     def test_directory_iterator_class_mode_input(self, tmpdir):\n         tmpdir.join('class-1').mkdir()\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ebd0f08c715129094cece5a7ba5be321ba8aac61", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 151 | Lines Deleted: 66 | Files Changed: 4 | Hunks: 32 | Methods Changed: 12 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 217 | Churn Cumulative: 4320 | Contributors (this commit): 57 | Commits (past 90d): 31 | Contributors (cumulative): 63 | DMM Complexity: 1.0\n\nDIFF:\n@@ -105,7 +105,8 @@ else:\n                                      batch_size=batch_size),\n                         steps_per_epoch=x_train.shape[0] // batch_size,\n                         epochs=epochs,\n-                        validation_data=(x_test, y_test))\n+                        validation_data=(x_test, y_test),\n+                        workers=4)\n \n # Save model and weights\n if not os.path.isdir(save_dir):\n@@ -129,14 +130,17 @@ with open(label_list_path, mode='rb') as f:\n \n # Evaluate model with test data set and share sample prediction results\n evaluation = model.evaluate_generator(datagen.flow(x_test, y_test,\n-                                      batch_size=batch_size),\n-                                      steps=x_test.shape[0] // batch_size)\n-\n+                                                   batch_size=batch_size,\n+                                                   shuffle=False),\n+                                      steps=x_test.shape[0] // batch_size,\n+                                      workers=4)\n print('Model Accuracy = %.2f' % (evaluation[1]))\n \n predict_gen = model.predict_generator(datagen.flow(x_test, y_test,\n-                                      batch_size=batch_size),\n-                                      steps=x_test.shape[0] // batch_size)\n+                                                   batch_size=batch_size,\n+                                                   shuffle=False),\n+                                      steps=x_test.shape[0] // batch_size,\n+                                      workers=4)\n \n for predict_index, predicted_y in enumerate(predict_gen):\n     actual_label = labels['label_names'][np.argmax(y_test[predict_index])]\n\n@@ -17,6 +17,7 @@ import multiprocessing.pool\n from functools import partial\n \n from .. import backend as K\n+from ..utils.data_utils import Sequence\n \n try:\n     from PIL import Image as pil_image\n@@ -684,7 +685,7 @@ class ImageDataGenerator(object):\n             self.principal_components = np.dot(np.dot(u, np.diag(1. / np.sqrt(s + self.zca_epsilon))), u.T)\n \n \n-class Iterator(object):\n+class Iterator(Sequence):\n     \"\"\"Abstract base class for image data iterators.\n \n     # Arguments\n@@ -697,36 +698,60 @@ class Iterator(object):\n     def __init__(self, n, batch_size, shuffle, seed):\n         self.n = n\n         self.batch_size = batch_size\n+        self.seed = seed\n         self.shuffle = shuffle\n         self.batch_index = 0\n         self.total_batches_seen = 0\n         self.lock = threading.Lock()\n-        self.index_generator = self._flow_index(n, batch_size, shuffle, seed)\n+        self.index_array = None\n+        self.index_generator = self._flow_index()\n+\n+    def _set_index_array(self):\n+        self.index_array = np.arange(self.n)\n+        if self.shuffle:\n+            self.index_array = np.random.permutation(self.n)\n+\n+    def __getitem__(self, idx):\n+        if idx >= len(self):\n+            raise ValueError('Asked to retrieve element {idx}, '\n+                             'but the Sequence '\n+                             'has length {length}'.format(idx=idx,\n+                                                          length=len(self)))\n+        if self.seed is not None:\n+            np.random.seed(self.seed + self.total_batches_seen)\n+        self.total_batches_seen += 1\n+        if self.index_array is None:\n+            self._set_index_array()\n+        index_array = self.index_array[self.batch_size * idx:\n+                                       self.batch_size * (idx + 1)]\n+        return self._get_batches_of_transformed_samples(index_array)\n+\n+    def __len__(self):\n+        return int(np.ceil(self.n / float(self.batch_size)))\n+\n+    def on_epoch_end(self):\n+        self._set_index_array()\n \n     def reset(self):\n         self.batch_index = 0\n \n-    def _flow_index(self, n, batch_size=32, shuffle=False, seed=None):\n+    def _flow_index(self):\n         # Ensure self.batch_index is 0.\n         self.reset()\n         while 1:\n-            if seed is not None:\n-                np.random.seed(seed + self.total_batches_seen)\n+            if self.seed is not None:\n+                np.random.seed(self.seed + self.total_batches_seen)\n             if self.batch_index == 0:\n-                index_array = np.arange(n)\n-                if shuffle:\n-                    index_array = np.random.permutation(n)\n+                self._set_index_array()\n \n-            current_index = (self.batch_index * batch_size) % n\n-            if n > current_index + batch_size:\n-                current_batch_size = batch_size\n+            current_index = (self.batch_index * self.batch_size) % self.n\n+            if self.n > current_index + self.batch_size:\n                 self.batch_index += 1\n             else:\n-                current_batch_size = n - current_index\n                 self.batch_index = 0\n             self.total_batches_seen += 1\n-            yield (index_array[current_index: current_index + current_batch_size],\n-                   current_index, current_batch_size)\n+            yield self.index_array[current_index:\n+                                   current_index + self.batch_size]\n \n     def __iter__(self):\n         # Needed if we want to do something like:\n@@ -796,6 +821,27 @@ class NumpyArrayIterator(Iterator):\n         self.save_format = save_format\n         super(NumpyArrayIterator, self).__init__(x.shape[0], batch_size, shuffle, seed)\n \n+    def _get_batches_of_transformed_samples(self, index_array):\n+        batch_x = np.zeros(tuple([len(index_array)] + list(self.x.shape)[1:]),\n+                           dtype=K.floatx())\n+        for i, j in enumerate(index_array):\n+            x = self.x[j]\n+            x = self.image_data_generator.random_transform(x.astype(K.floatx()))\n+            x = self.image_data_generator.standardize(x)\n+            batch_x[i] = x\n+        if self.save_to_dir:\n+            for i, j in enumerate(index_array):\n+                img = array_to_img(batch_x[i], self.data_format, scale=True)\n+                fname = '{prefix}_{index}_{hash}.{format}'.format(prefix=self.save_prefix,\n+                                                                  index=j,\n+                                                                  hash=np.random.randint(1e4),\n+                                                                  format=self.save_format)\n+                img.save(os.path.join(self.save_to_dir, fname))\n+        if self.y is None:\n+            return batch_x\n+        batch_y = self.y[index_array]\n+        return batch_x, batch_y\n+\n     def next(self):\n         \"\"\"For python 2.x.\n \n@@ -805,27 +851,10 @@ class NumpyArrayIterator(Iterator):\n         # Keeps under lock only the mechanism which advances\n         # the indexing of each batch.\n         with self.lock:\n-            index_array, current_index, current_batch_size = next(self.index_generator)\n+            index_array = next(self.index_generator)\n         # The transformation of images is not under thread lock\n         # so it can be done in parallel\n-        batch_x = np.zeros(tuple([current_batch_size] + list(self.x.shape)[1:]), dtype=K.floatx())\n-        for i, j in enumerate(index_array):\n-            x = self.x[j]\n-            x = self.image_data_generator.random_transform(x.astype(K.floatx()))\n-            x = self.image_data_generator.standardize(x)\n-            batch_x[i] = x\n-        if self.save_to_dir:\n-            for i in range(current_batch_size):\n-                img = array_to_img(batch_x[i], self.data_format, scale=True)\n-                fname = '{prefix}_{index}_{hash}.{format}'.format(prefix=self.save_prefix,\n-                                                                  index=current_index + i,\n-                                                                  hash=np.random.randint(1e4),\n-                                                                  format=self.save_format)\n-                img.save(os.path.join(self.save_to_dir, fname))\n-        if self.y is None:\n-            return batch_x\n-        batch_y = self.y[index_array]\n-        return batch_x, batch_y\n+        return self._get_batches_of_transformed_samples(index_array)\n \n \n def _count_valid_files_in_directory(directory, white_list_formats, follow_links):\n@@ -1013,17 +1042,8 @@ class DirectoryIterator(Iterator):\n         pool.join()\n         super(DirectoryIterator, self).__init__(self.samples, batch_size, shuffle, seed)\n \n-    def next(self):\n-        \"\"\"For python 2.x.\n-\n-        # Returns\n-            The next batch.\n-        \"\"\"\n-        with self.lock:\n-            index_array, current_index, current_batch_size = next(self.index_generator)\n-        # The transformation of images is not under thread lock\n-        # so it can be done in parallel\n-        batch_x = np.zeros((current_batch_size,) + self.image_shape, dtype=K.floatx())\n+    def _get_batches_of_transformed_samples(self, index_array):\n+        batch_x = np.zeros((len(index_array),) + self.image_shape, dtype=K.floatx())\n         grayscale = self.color_mode == 'grayscale'\n         # build batch of image data\n         for i, j in enumerate(index_array):\n@@ -1037,10 +1057,10 @@ class DirectoryIterator(Iterator):\n             batch_x[i] = x\n         # optionally save augmented images to disk for debugging purposes\n         if self.save_to_dir:\n-            for i in range(current_batch_size):\n+            for i, j in enumerate(index_array):\n                 img = array_to_img(batch_x[i], self.data_format, scale=True)\n                 fname = '{prefix}_{index}_{hash}.{format}'.format(prefix=self.save_prefix,\n-                                                                  index=current_index + i,\n+                                                                  index=j,\n                                                                   hash=np.random.randint(1e4),\n                                                                   format=self.save_format)\n                 img.save(os.path.join(self.save_to_dir, fname))\n@@ -1058,3 +1078,15 @@ class DirectoryIterator(Iterator):\n         else:\n             return batch_x\n         return batch_x, batch_y\n+\n+    def next(self):\n+        \"\"\"For python 2.x.\n+\n+        # Returns\n+            The next batch.\n+        \"\"\"\n+        with self.lock:\n+            index_array = next(self.index_generator)\n+        # The transformation of images is not under thread lock\n+        # so it can be done in parallel\n+        return self._get_batches_of_transformed_samples(index_array)\n\n@@ -313,15 +313,16 @@ class Sequence(object):\n     # and `y_set` are the associated classes.\n \n     class CIFAR10Sequence(Sequence):\n+\n         def __init__(self, x_set, y_set, batch_size):\n-            self.X,self.y = x_set,y_set\n+            self.x, self.y = x_set, y_set\n             self.batch_size = batch_size\n \n         def __len__(self):\n-            return len(self.X) // self.batch_size\n+            return len(self.x) // self.batch_size\n \n         def __getitem__(self, idx):\n-            batch_x = self.X[idx*self.batch_size:(idx+1)*self.batch_size]\n+            batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n             batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n \n             return np.array([\n\n@@ -5,20 +5,20 @@ import numpy as np\n import os\n \n \n-class TestImage:\n+class TestImage(object):\n \n     def setup_class(cls):\n-        img_w = img_h = 20\n+        cls.img_w = cls.img_h = 20\n         rgb_images = []\n         gray_images = []\n         for n in range(8):\n-            bias = np.random.rand(img_w, img_h, 1) * 64\n-            variance = np.random.rand(img_w, img_h, 1) * (255 - 64)\n-            imarray = np.random.rand(img_w, img_h, 3) * variance + bias\n+            bias = np.random.rand(cls.img_w, cls.img_h, 1) * 64\n+            variance = np.random.rand(cls.img_w, cls.img_h, 1) * (255 - 64)\n+            imarray = np.random.rand(cls.img_w, cls.img_h, 3) * variance + bias\n             im = Image.fromarray(imarray.astype('uint8')).convert('RGB')\n             rgb_images.append(im)\n \n-            imarray = np.random.rand(img_w, img_h, 1) * variance + bias\n+            imarray = np.random.rand(cls.img_w, cls.img_h, 1) * variance + bias\n             im = Image.fromarray(imarray.astype('uint8').squeeze()).convert('L')\n             gray_images.append(im)\n \n@@ -53,10 +53,43 @@ class TestImage:\n             generator.fit(images, augment=True)\n \n             for x, y in generator.flow(images, np.arange(images.shape[0]),\n-                                       shuffle=True, save_to_dir=str(tmpdir)):\n-                assert x.shape[1:] == images.shape[1:]\n+                                       shuffle=False, save_to_dir=str(tmpdir),\n+                                       batch_size=3):\n+                assert x.shape == images[:3].shape\n+                assert list(y) == [0, 1, 2]\n                 break\n \n+            # Test with `shuffle=True`\n+            for x, y in generator.flow(images, np.arange(images.shape[0]),\n+                                       shuffle=True, save_to_dir=str(tmpdir),\n+                                       batch_size=3):\n+                assert x.shape == images[:3].shape\n+                # Check that the sequence is shuffled.\n+                assert list(y) != [0, 1, 2]\n+                break\n+\n+            # Test `flow` behavior as Sequence\n+            seq = generator.flow(images, np.arange(images.shape[0]),\n+                                 shuffle=False, save_to_dir=str(tmpdir),\n+                                 batch_size=3)\n+            assert len(seq) == images.shape[0] // 3 + 1\n+            x, y = seq[0]\n+            assert x.shape == images[:3].shape\n+            assert list(y) == [0, 1, 2]\n+\n+            # Test with `shuffle=True`\n+            seq = generator.flow(images, np.arange(images.shape[0]),\n+                                 shuffle=True, save_to_dir=str(tmpdir),\n+                                 batch_size=3, seed=123)\n+            x, y = seq[0]\n+            # Check that the sequence is shuffled.\n+            assert list(y) != [0, 1, 2]\n+\n+            # `on_epoch_end` should reshuffle the sequence.\n+            seq.on_epoch_end()\n+            x2, y2 = seq[0]\n+            assert list(y) != list(y2)\n+\n     def test_image_data_generator_invalid_data(self):\n         generator = image.ImageDataGenerator(\n             featurewise_center=True,\n@@ -140,9 +173,9 @@ class TestImage:\n         dir_iterator = generator.flow_from_directory(str(tmpdir))\n \n         # check number of classes and images\n-        assert(len(dir_iterator.class_indices) == num_classes)\n-        assert(len(dir_iterator.classes) == count)\n-        assert(sorted(dir_iterator.filenames) == sorted(filenames))\n+        assert len(dir_iterator.class_indices) == num_classes\n+        assert len(dir_iterator.classes) == count\n+        assert sorted(dir_iterator.filenames) == sorted(filenames)\n \n         # Test invalid use cases\n         with pytest.raises(ValueError):\n@@ -150,6 +183,21 @@ class TestImage:\n         with pytest.raises(ValueError):\n             generator.flow_from_directory(str(tmpdir), class_mode='output')\n \n+        # Test usage as Sequence\n+        generator = image.ImageDataGenerator()\n+        dir_seq = generator.flow_from_directory(str(tmpdir),\n+                                                target_size=(26, 26),\n+                                                color_mode='rgb',\n+                                                batch_size=3,\n+                                                class_mode='categorical')\n+        assert len(dir_seq) == count // 3 + 1\n+        x1, y1 = dir_seq[1]\n+        assert x1.shape == (3, 26, 26, 3)\n+        assert y1.shape == (3, num_classes)\n+        x1, y1 = dir_seq[5]\n+        with pytest.raises(ValueError):\n+            x1, y1 = dir_seq[9]\n+\n     def test_directory_iterator_class_mode_input(self, tmpdir):\n         tmpdir.join('class-1').mkdir()\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0f1c8550576c0320632c5541caa42325833f1335", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 386 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -33,10 +33,11 @@ from ..layers import MaxPooling2D\n from ..utils.data_utils import get_file\n from ..engine.topology import get_source_inputs\n from ..applications.imagenet_utils import _obtain_input_shape\n+from ..applications.imagenet_utils import decode_predictions\n from .. import backend as K\n \n \n-BASE_WEIGHT_URL = 'https://github.com/myutwo150/keras-inception-resnet-v2/releases/download/v0.1/'\n+BASE_WEIGHT_URL = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.7/'\n \n \n def preprocess_input(x):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0b3dc16b603a549a20f4a92447c79042fecd0c0b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 50 | Lines Deleted: 25 | Files Changed: 5 | Hunks: 12 | Methods Changed: 6 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 75 | Churn Cumulative: 2778 | Contributors (this commit): 10 | Commits (past 90d): 27 | Contributors (cumulative): 19 | DMM Complexity: 0.0\n\nDIFF:\n@@ -8,12 +8,19 @@ CLASS_INDEX = None\n CLASS_INDEX_PATH = 'https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json'\n \n \n-def preprocess_input(x, data_format=None):\n+def preprocess_input(x, data_format=None, mode='caffe'):\n     \"\"\"Preprocesses a tensor encoding a batch of images.\n \n     # Arguments\n         x: input Numpy tensor, 4D.\n         data_format: data format of the image tensor.\n+        mode: One of \"caffe\", \"tf\".\n+            - caffe: will convert the images from RGB to BGR,\n+                then will zero-center each color channel with\n+                respect to the ImageNet dataset,\n+                without scaling.\n+            - tf: will scale pixels between -1 and 1,\n+                sample-wise.\n \n     # Returns\n         Preprocessed tensor.\n@@ -22,6 +29,12 @@ def preprocess_input(x, data_format=None):\n         data_format = K.image_data_format()\n     assert data_format in {'channels_last', 'channels_first'}\n \n+    if mode == 'tf':\n+        x /= 255.\n+        x -= 0.5\n+        x *= 2.\n+        return x\n+\n     if data_format == 'channels_first':\n         if x.ndim == 3:\n             # 'RGB'->'BGR'\n\n@@ -32,8 +32,9 @@ from ..layers import Lambda\n from ..layers import MaxPooling2D\n from ..utils.data_utils import get_file\n from ..engine.topology import get_source_inputs\n-from ..applications.imagenet_utils import _obtain_input_shape\n-from ..applications.imagenet_utils import decode_predictions\n+from . import imagenet_utils\n+from .imagenet_utils import _obtain_input_shape\n+from .imagenet_utils import decode_predictions\n from .. import backend as K\n \n \n@@ -43,20 +44,13 @@ BASE_WEIGHT_URL = 'https://github.com/fchollet/deep-learning-models/releases/dow\n def preprocess_input(x):\n     \"\"\"Preprocesses a numpy array encoding a batch of images.\n \n-    This function applies the \"Inception\" preprocessing which converts\n-    the RGB values from [0, 255] to [-1, 1]. Note that this preprocessing\n-    function is different from `imagenet_utils.preprocess_input()`.\n-\n     # Arguments\n         x: a 4D numpy array consists of RGB values within [0, 255].\n \n     # Returns\n         Preprocessed array.\n     \"\"\"\n-    x /= 255.\n-    x -= 0.5\n-    x *= 2.\n-    return x\n+    return imagenet_utils.preprocess_input(x, mode='tf')\n \n \n def conv2d_bn(x,\n\n@@ -29,6 +29,7 @@ from ..layers import GlobalMaxPooling2D\n from ..engine.topology import get_source_inputs\n from ..utils.data_utils import get_file\n from .. import backend as K\n+from . import imagenet_utils\n from .imagenet_utils import decode_predictions\n from .imagenet_utils import _obtain_input_shape\n \n@@ -388,7 +389,12 @@ def InceptionV3(include_top=True,\n \n \n def preprocess_input(x):\n-    x /= 255.\n-    x -= 0.5\n-    x *= 2.\n-    return x\n+    \"\"\"Preprocesses a numpy array encoding a batch of images.\n+\n+    # Arguments\n+        x: a 4D numpy array consists of RGB values within [0, 255].\n+\n+    # Returns\n+        Preprocessed array.\n+    \"\"\"\n+    return imagenet_utils.preprocess_input(x, mode='tf')\n\n@@ -71,8 +71,9 @@ from ..utils import conv_utils\n from ..utils.data_utils import get_file\n from ..engine.topology import get_source_inputs\n from ..engine import InputSpec\n-from ..applications.imagenet_utils import _obtain_input_shape\n-from ..applications.imagenet_utils import decode_predictions\n+from . import imagenet_utils\n+from .imagenet_utils import _obtain_input_shape\n+from .imagenet_utils import decode_predictions\n from .. import backend as K\n \n \n@@ -84,10 +85,15 @@ def relu6(x):\n \n \n def preprocess_input(x):\n-    x /= 255.\n-    x -= 0.5\n-    x *= 2.\n-    return x\n+    \"\"\"Preprocesses a numpy array encoding a batch of images.\n+\n+    # Arguments\n+        x: a 4D numpy array consists of RGB values within [0, 255].\n+\n+    # Returns\n+        Preprocessed array.\n+    \"\"\"\n+    return imagenet_utils.preprocess_input(x, mode='tf')\n \n \n class DepthwiseConv2D(Conv2D):\n\n@@ -36,6 +36,7 @@ from ..layers import GlobalMaxPooling2D\n from ..engine.topology import get_source_inputs\n from ..utils.data_utils import get_file\n from .. import backend as K\n+from . import imagenet_utils\n from .imagenet_utils import decode_predictions\n from .imagenet_utils import _obtain_input_shape\n \n@@ -261,7 +262,12 @@ def Xception(include_top=True, weights='imagenet',\n \n \n def preprocess_input(x):\n-    x /= 255.\n-    x -= 0.5\n-    x *= 2.\n-    return x\n+    \"\"\"Preprocesses a numpy array encoding a batch of images.\n+\n+    # Arguments\n+        x: a 4D numpy array consists of RGB values within [0, 255].\n+\n+    # Returns\n+        Preprocessed array.\n+    \"\"\"\n+    return imagenet_utils.preprocess_input(x, mode='tf')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ba29c60461bcca5d3ae25dde691118bcd559796d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 15 | Lines Deleted: 38 | Files Changed: 2 | Hunks: 10 | Methods Changed: 10 | Complexity Δ (Sum/Max): -1/1 | Churn Δ: 53 | Churn Cumulative: 11401 | Contributors (this commit): 91 | Commits (past 90d): 50 | Contributors (cumulative): 105 | DMM Complexity: 0.0\n\nDIFF:\n@@ -180,32 +180,6 @@ def set_session(session):\n \n # VARIABLE MANIPULATION\n \n-def _convert_string_dtype(dtype):\n-    \"\"\"Get the type from a string.\n-\n-    # Arguments\n-        dtype: A string representation of a type.\n-\n-    # Returns\n-        The type requested.\n-\n-    # Raises\n-        ValueError: if `dtype` is not supported.\n-    \"\"\"\n-    mapping = {'float16': tf.float16,\n-               'float32': tf.float32,\n-               'float64': tf.float64,\n-               'int16': tf.int16,\n-               'int32': tf.int32,\n-               'int64': tf.int64,\n-               'uint8': tf.int8,\n-               'uint16': tf.uint16}\n-\n-    if dtype not in mapping:\n-        raise ValueError('Unsupported dtype:', dtype)\n-    return mapping[dtype]\n-\n-\n def _to_tensor(x, dtype):\n     \"\"\"Convert the input `x` to a tensor of type `dtype`.\n \n@@ -313,7 +287,7 @@ def variable(value, dtype=None, name=None, constraint=None):\n         v._keras_shape = sparse_coo.shape\n         v._uses_learning_phase = False\n         return v\n-    v = tf.Variable(value, dtype=_convert_string_dtype(dtype), name=name)\n+    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n     if isinstance(value, np.ndarray):\n         v._keras_shape = value.shape\n     elif hasattr(value, 'get_shape'):\n@@ -621,7 +595,7 @@ def zeros(shape, dtype=None, name=None):\n     \"\"\"\n     if dtype is None:\n         dtype = floatx()\n-    tf_dtype = _convert_string_dtype(dtype)\n+    tf_dtype = tf.as_dtype(dtype)\n     return variable(tf.constant_initializer(0., dtype=tf_dtype)(shape),\n                     dtype, name)\n \n@@ -649,7 +623,7 @@ def ones(shape, dtype=None, name=None):\n     \"\"\"\n     if dtype is None:\n         dtype = floatx()\n-    tf_dtype = _convert_string_dtype(dtype)\n+    tf_dtype = tf.as_dtype(dtype)\n     return variable(tf.constant_initializer(1., dtype=tf_dtype)(shape),\n                     dtype, name)\n \n@@ -769,7 +743,7 @@ def random_uniform_variable(shape, low, high, dtype=None,\n     \"\"\"\n     if dtype is None:\n         dtype = floatx()\n-    tf_dtype = _convert_string_dtype(dtype)\n+    tf_dtype = tf.as_dtype(dtype)\n     if seed is None:\n         # ensure that randomness is conditioned by the Numpy RNG\n         seed = np.random.randint(10e8)\n@@ -806,7 +780,7 @@ def random_normal_variable(shape, mean, scale, dtype=None,\n     \"\"\"\n     if dtype is None:\n         dtype = floatx()\n-    tf_dtype = _convert_string_dtype(dtype)\n+    tf_dtype = tf.as_dtype(dtype)\n     if seed is None:\n         # ensure that randomness is conditioned by the Numpy RNG\n         seed = np.random.randint(10e8)\n@@ -2154,7 +2128,7 @@ def set_value(x, value):\n             (of the same shape).\n     \"\"\"\n     value = np.asarray(value, dtype=dtype(x))\n-    tf_dtype = _convert_string_dtype(x.dtype.name.split('_')[0])\n+    tf_dtype = tf.as_dtype(x.dtype.name.split('_')[0])\n     if hasattr(x, '_assign_placeholder'):\n         assign_placeholder = x._assign_placeholder\n         assign_op = x._assign_op\n@@ -2178,7 +2152,7 @@ def batch_set_value(tuples):\n         feed_dict = {}\n         for x, value in tuples:\n             value = np.asarray(value, dtype=dtype(x))\n-            tf_dtype = _convert_string_dtype(x.dtype.name.split('_')[0])\n+            tf_dtype = tf.as_dtype(x.dtype.name.split('_')[0])\n             if hasattr(x, '_assign_placeholder'):\n                 assign_placeholder = x._assign_placeholder\n                 assign_op = x._assign_op\n\n@@ -217,11 +217,6 @@ class TestBackend(object):\n                                       mean=0., scale=1.,\n                                       shape_or_val=False, assert_value_equality=False)\n \n-        # not supported dtype\n-        for dtype in ['int16', 'int32', 'int64', 'uint8', 'uint16', 'double']:\n-            with pytest.raises(ValueError):\n-                ztf = KTF.random_normal_variable((2, 3), 0, 1, dtype=dtype)\n-\n     @pytest.mark.parametrize('k', [KTF], ids=['TensorFlow'])\n     def test_batch_dot_shape(self, k):\n         x_batch = k.ones(shape=(32, 20))\n@@ -1397,6 +1392,14 @@ class TestBackend(object):\n         # Restore old value\n         set_floatx(old_floatx)\n \n+    def test_variable_support_bool_dtype(self):\n+        # Github issue: 7819\n+        if K.backend() == 'tensorflow':\n+            assert K.dtype(K.variable(1, dtype='int16')) == 'int16'\n+            assert K.dtype(K.variable(False, dtype='bool')) == 'bool'\n+            with pytest.raises(TypeError):\n+                K.variable('', dtype='unsupported')\n+\n \n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#419105bd371460720332dcacee0b681322375e9e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 2813 | Contributors (this commit): 40 | Commits (past 90d): 20 | Contributors (cumulative): 45 | DMM Complexity: None\n\nDIFF:\n@@ -910,7 +910,7 @@ def _list_valid_filenames_in_directory(directory, white_list_formats,\n     subdir = os.path.basename(directory)\n     basedir = os.path.dirname(directory)\n     for root, _, files in _recursive_list(directory):\n-        for fname in files:\n+        for fname in sorted(files):\n             is_valid = False\n             for extension in white_list_formats:\n                 if fname.lower().endswith('.' + extension):\n\n@@ -175,7 +175,7 @@ class TestImage(object):\n         # check number of classes and images\n         assert len(dir_iterator.class_indices) == num_classes\n         assert len(dir_iterator.classes) == count\n-        assert sorted(dir_iterator.filenames) == sorted(filenames)\n+        assert dir_iterator.filenames == sorted(filenames)\n \n         # Test invalid use cases\n         with pytest.raises(ValueError):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#66c4fdb8937abe725018de7156c5f66f2ec335ed", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 358 | Contributors (this commit): 14 | Commits (past 90d): 5 | Contributors (cumulative): 16 | DMM Complexity: 1.0\n\nDIFF:\n@@ -67,7 +67,7 @@ class HDF5Matrix(object):\n             if start is None:\n                 start = 0\n             if stop is None:\n-                stop = self.data.shape[0]\n+                stop = self.shape[0]\n             if stop + self.start <= self.end:\n                 idx = slice(start + self.start, stop + self.start)\n             else:\n\n@@ -73,6 +73,9 @@ def test_io_utils(in_tmpdir):\n     assert out_eval.shape == (), 'Shape of evaluation does not match'\n     assert out_eval > 0, 'Evaluation value does not meet criteria: {}'.format(out_eval)\n \n+    # test slicing for shortened array\n+    assert len(X_train[0:]) == len(X_train), 'Incorrect shape for sliced data'\n+\n     os.remove(h5_path)\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#98c2b2b23a27e541b760ee754dd067af2aec8e75", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 2773 | Contributors (this commit): 58 | Commits (past 90d): 14 | Contributors (cumulative): 58 | DMM Complexity: None\n\nDIFF:\n@@ -228,7 +228,8 @@ class BaseLogger(Callback):\n \n \n class TerminateOnNaN(Callback):\n-    \"\"\"Callback that terminates training when a NaN loss is encountered.\"\"\"\n+    \"\"\"Callback that terminates training when a NaN loss is encountered.\n+    \"\"\"\n \n     def __init__(self):\n         super(TerminateOnNaN, self).__init__()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2df5650ab64a173973a3a4b434d2f801b4694ce3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 203 | Contributors (this commit): 8 | Commits (past 90d): 2 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -106,7 +106,7 @@ print('Preparing embedding matrix.')\n \n # prepare embedding matrix\n num_words = min(MAX_NB_WORDS, len(word_index))\n-embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n+embedding_matrix = np.zeros((num_words + 1, EMBEDDING_DIM))\n for word, i in word_index.items():\n     if i >= MAX_NB_WORDS:\n         continue\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b8515d4b7b46a2d17c3ebda63482f3b992db27d3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 2780 | Contributors (this commit): 59 | Commits (past 90d): 15 | Contributors (cumulative): 59 | DMM Complexity: 1.0\n\nDIFF:\n@@ -21,10 +21,6 @@ try:\n except ImportError:\n     requests = None\n \n-if K.backend() == 'tensorflow':\n-    import tensorflow as tf\n-    from tensorflow.contrib.tensorboard.plugins import projector\n-\n \n class CallbackList(object):\n     \"\"\"Container abstracting a list of callbacks.\n@@ -636,6 +632,9 @@ class TensorBoard(Callback):\n         if K.backend() != 'tensorflow':\n             raise RuntimeError('TensorBoard callback only works '\n                                'with the TensorFlow backend.')\n+        global tf, projector\n+        import tensorflow as tf\n+        from tensorflow.contrib.tensorboard.plugins import projector\n         self.log_dir = log_dir\n         self.histogram_freq = histogram_freq\n         self.merged = None\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
