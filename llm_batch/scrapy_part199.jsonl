{"custom_id": "scrapy#75d3d033827ef7d0611ff1a0dc8d953ffe6e22c1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 401 | Contributors (this commit): 9 | Commits (past 90d): 2 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -45,5 +45,6 @@ setup(\n         'cssselect>=0.9',\n         'six>=1.5.2',\n         'PyDispatcher>=2.0.5',\n+        'service_identity',\n     ],\n )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#ce21884a976a35d28fd0d1a3b8efd73c178a7595", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 156 | Files Changed: 3 | Hunks: 15 | Methods Changed: 21 | Complexity Δ (Sum/Max): -41/0 | Churn Δ: 170 | Churn Cumulative: 995 | Contributors (this commit): 15 | Commits (past 90d): 8 | Contributors (cumulative): 24 | DMM Complexity: 0.21176470588235294\n\nDIFF:\n@@ -2,36 +2,18 @@\n XPath selectors based on lxml\n \"\"\"\n \n-from lxml import etree\n-import six\n-\n-from scrapy.utils.misc import extract_regex\n from scrapy.utils.trackref import object_ref\n-from scrapy.utils.python import to_bytes, flatten, iflatten\n-from scrapy.utils.decorators import deprecated\n+from scrapy.utils.python import to_bytes\n from scrapy.http import HtmlResponse, XmlResponse\n+from scrapy.utils.decorators import deprecated\n+from parsel import Selector as ParselSelector, SelectorList\n+from parsel.unified import _ctgroup\n from .lxmldocument import LxmlDocument\n-from .csstranslator import ScrapyHTMLTranslator, ScrapyGenericTranslator\n \n \n __all__ = ['Selector', 'SelectorList']\n \n \n-class SafeXMLParser(etree.XMLParser):\n-    def __init__(self, *args, **kwargs):\n-        kwargs.setdefault('resolve_entities', False)\n-        super(SafeXMLParser, self).__init__(*args, **kwargs)\n-\n-_ctgroup = {\n-    'html': {'_parser': etree.HTMLParser,\n-             '_csstranslator': ScrapyHTMLTranslator(),\n-             '_tostring_method': 'html'},\n-    'xml': {'_parser': SafeXMLParser,\n-            '_csstranslator': ScrapyGenericTranslator(),\n-            '_tostring_method': 'xml'},\n-}\n-\n-\n def _st(response, st):\n     if st is None:\n         return 'xml' if isinstance(response, XmlResponse) else 'html'\n@@ -47,111 +29,25 @@ def _response_from_text(text, st):\n               body=to_bytes(text, 'utf-8'))\n \n \n-class Selector(object_ref):\n+class Selector(ParselSelector, object_ref):\n \n-    __slots__ = ['response', 'text', 'namespaces', 'type', '_expr', '_root',\n-                 '__weakref__', '_parser', '_csstranslator', '_tostring_method']\n+    __slots__ = ['response']\n \n-    _default_type = None\n-    _default_namespaces = {\n-        \"re\": \"http://exslt.org/regular-expressions\",\n+    def __init__(self, response=None, text=None, type=None, root=None, **kwargs):\n+        st = _st(response, type or self._default_type)\n+        root = kwargs.get('root', root)\n \n-        # supported in libxslt:\n-        # set:difference\n-        # set:has-same-node\n-        # set:intersection\n-        # set:leading\n-        # set:trailing\n-        \"set\": \"http://exslt.org/sets\"\n-    }\n-    _lxml_smart_strings = False\n-\n-    def __init__(self, response=None, text=None, type=None, namespaces=None,\n-                 _root=None, _expr=None):\n-        self.type = st = _st(response, type or self._default_type)\n         self._parser = _ctgroup[st]['_parser']\n-        self._csstranslator = _ctgroup[st]['_csstranslator']\n-        self._tostring_method = _ctgroup[st]['_tostring_method']\n \n         if text is not None:\n             response = _response_from_text(text, st)\n \n         if response is not None:\n-            _root = LxmlDocument(response, self._parser)\n+            root = LxmlDocument(response, self._parser)\n \n         self.response = response\n-        self.namespaces = dict(self._default_namespaces)\n-        if namespaces is not None:\n-            self.namespaces.update(namespaces)\n-        self._root = _root\n-        self._expr = _expr\n-\n-    def xpath(self, query):\n-        try:\n-            xpathev = self._root.xpath\n-        except AttributeError:\n-            return SelectorList([])\n-\n-        try:\n-            result = xpathev(query, namespaces=self.namespaces,\n-                             smart_strings=self._lxml_smart_strings)\n-        except etree.XPathError:\n-            msg = u\"Invalid XPath: %s\" % query\n-            raise ValueError(msg if six.PY3 else msg.encode(\"unicode_escape\"))\n-\n-        if type(result) is not list:\n-            result = [result]\n-\n-        result = [self.__class__(_root=x, _expr=query,\n-                                 namespaces=self.namespaces,\n-                                 type=self.type)\n-                  for x in result]\n-        return SelectorList(result)\n-\n-    def css(self, query):\n-        return self.xpath(self._css2xpath(query))\n-\n-    def _css2xpath(self, query):\n-        return self._csstranslator.css_to_xpath(query)\n-\n-    def re(self, regex):\n-        return extract_regex(regex, self.extract())\n-\n-    def extract(self):\n-        try:\n-            return etree.tostring(self._root,\n-                                  method=self._tostring_method,\n-                                  encoding=\"unicode\",\n-                                  with_tail=False)\n-        except (AttributeError, TypeError):\n-            if self._root is True:\n-                return u'1'\n-            elif self._root is False:\n-                return u'0'\n-            else:\n-                return six.text_type(self._root)\n-\n-    def register_namespace(self, prefix, uri):\n-        if self.namespaces is None:\n-            self.namespaces = {}\n-        self.namespaces[prefix] = uri\n-\n-    def remove_namespaces(self):\n-        for el in self._root.iter('*'):\n-            if el.tag.startswith('{'):\n-                el.tag = el.tag.split('}', 1)[1]\n-            # loop on element attributes also\n-            for an in el.attrib.keys():\n-                if an.startswith('{'):\n-                    el.attrib[an.split('}', 1)[1]] = el.attrib.pop(an)\n-\n-    def __nonzero__(self):\n-        return bool(self.extract())\n-\n-    def __str__(self):\n-        data = repr(self.extract()[:40])\n-        return \"<%s xpath=%r data=%s>\" % (type(self).__name__, self._expr, data)\n-    __repr__ = __str__\n+        text = response.body_as_unicode() if response else None\n+        super(Selector, self).__init__(text=text, type=st, root=root, **kwargs)\n \n     # Deprecated api\n     @deprecated(use_instead='.xpath()')\n@@ -162,42 +58,3 @@ class Selector(object_ref):\n     def extract_unquoted(self):\n         return self.extract()\n \n-\n-class SelectorList(list):\n-\n-    def __getslice__(self, i, j):\n-        return self.__class__(list.__getslice__(self, i, j))\n-\n-    def xpath(self, xpath):\n-        return self.__class__(flatten([x.xpath(xpath) for x in self]))\n-\n-    def css(self, xpath):\n-        return self.__class__(flatten([x.css(xpath) for x in self]))\n-\n-    def re(self, regex):\n-        return flatten([x.re(regex) for x in self])\n-\n-    def re_first(self, regex):\n-        for el in iflatten(x.re(regex) for x in self):\n-            return el\n-\n-    def extract(self):\n-        return [x.extract() for x in self]\n-\n-    def extract_first(self, default=None):\n-        for x in self:\n-            return x.extract()\n-        else:\n-            return default\n-\n-    @deprecated(use_instead='.extract()')\n-    def extract_unquoted(self):\n-        return [x.extract_unquoted() for x in self]\n-\n-    @deprecated(use_instead='.xpath()')\n-    def x(self, xpath):\n-        return self.select(xpath)\n-\n-    @deprecated(use_instead='.xpath()')\n-    def select(self, xpath):\n-        return self.xpath(xpath)\n\n@@ -44,6 +44,7 @@ setup(\n         'pyOpenSSL',\n         'cssselect>=0.9',\n         'six>=1.5.2',\n+        'parsel>=0.9.0',\n         'PyDispatcher>=2.0.5',\n         'service_identity',\n     ],\n\n@@ -332,7 +332,7 @@ class SelectorTestCase(unittest.TestCase):\n \n     def test_weakref_slots(self):\n         \"\"\"Check that classes are using slots and are weak-referenceable\"\"\"\n-        x = self.sscls()\n+        x = self.sscls(text='')\n         weakref.ref(x)\n         assert not hasattr(x, '__dict__'), \"%s does not use __slots__\" % \\\n             x.__class__.__name__\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#c7b29d118d97b6fb510ba5b6ae3fb8eea41196c0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 524 | Contributors (this commit): 9 | Commits (past 90d): 4 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -35,7 +35,9 @@ class Selector(ParselSelector, object_ref):\n \n     def __init__(self, response=None, text=None, type=None, root=None, **kwargs):\n         st = _st(response, type or self._default_type)\n-        root = kwargs.get('root', root)\n+\n+        # supporting legacy _root argument\n+        root = kwargs.get('_root', root)\n \n         self._parser = _ctgroup[st]['_parser']\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#3a572e2f3b494327c918c2ac4a7150727c448f30", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 88 | Files Changed: 1 | Hunks: 1 | Methods Changed: 7 | Complexity Δ (Sum/Max): -16/0 | Churn Δ: 94 | Churn Cumulative: 182 | Contributors (this commit): 2 | Commits (past 90d): 1 | Contributors (cumulative): 2 | DMM Complexity: 0.25\n\nDIFF:\n@@ -1,88 +1,6 @@\n-from cssselect import GenericTranslator, HTMLTranslator\n-from cssselect.xpath import _unicode_safe_getattr, XPathExpr, ExpressionError\n-from cssselect.parser import FunctionalPseudoElement\n-\n-\n-class ScrapyXPathExpr(XPathExpr):\n-\n-    textnode = False\n-    attribute = None\n-\n-    @classmethod\n-    def from_xpath(cls, xpath, textnode=False, attribute=None):\n-        x = cls(path=xpath.path, element=xpath.element, condition=xpath.condition)\n-        x.textnode = textnode\n-        x.attribute = attribute\n-        return x\n-\n-    def __str__(self):\n-        path = super(ScrapyXPathExpr, self).__str__()\n-        if self.textnode:\n-            if path == '*':\n-                path = 'text()'\n-            elif path.endswith('::*/*'):\n-                path = path[:-3] + 'text()'\n-            else:\n-                path += '/text()'\n-\n-        if self.attribute is not None:\n-            if path.endswith('::*/*'):\n-                path = path[:-2]\n-            path += '/@%s' % self.attribute\n-\n-        return path\n-\n-    def join(self, combiner, other):\n-        super(ScrapyXPathExpr, self).join(combiner, other)\n-        self.textnode = other.textnode\n-        self.attribute = other.attribute\n-        return self\n-\n-\n-class TranslatorMixin(object):\n-\n-    def xpath_element(self, selector):\n-        xpath = super(TranslatorMixin, self).xpath_element(selector)\n-        return ScrapyXPathExpr.from_xpath(xpath)\n-\n-    def xpath_pseudo_element(self, xpath, pseudo_element):\n-        if isinstance(pseudo_element, FunctionalPseudoElement):\n-            method = 'xpath_%s_functional_pseudo_element' % (\n-                pseudo_element.name.replace('-', '_'))\n-            method = _unicode_safe_getattr(self, method, None)\n-            if not method:\n-                raise ExpressionError(\n-                    \"The functional pseudo-element ::%s() is unknown\"\n-                % pseudo_element.name)\n-            xpath = method(xpath, pseudo_element)\n-        else:\n-            method = 'xpath_%s_simple_pseudo_element' % (\n-                pseudo_element.replace('-', '_'))\n-            method = _unicode_safe_getattr(self, method, None)\n-            if not method:\n-                raise ExpressionError(\n-                    \"The pseudo-element ::%s is unknown\"\n-                    % pseudo_element)\n-            xpath = method(xpath)\n-        return xpath\n-\n-    def xpath_attr_functional_pseudo_element(self, xpath, function):\n-        if function.argument_types() not in (['STRING'], ['IDENT']):\n-            raise ExpressionError(\n-                \"Expected a single string or ident for ::attr(), got %r\"\n-                % function.arguments)\n-        return ScrapyXPathExpr.from_xpath(xpath,\n-            attribute=function.arguments[0].value)\n-\n-    def xpath_text_simple_pseudo_element(self, xpath):\n-        \"\"\"Support selecting text nodes using ::text pseudo-element\"\"\"\n-        return ScrapyXPathExpr.from_xpath(xpath, textnode=True)\n-\n-\n-class ScrapyGenericTranslator(TranslatorMixin, GenericTranslator):\n-    pass\n-\n-\n-class ScrapyHTMLTranslator(TranslatorMixin, HTMLTranslator):\n-    pass\n-\n+from parsel.csstranslator import (\n+    ScrapyXPathExpr,\n+    TranslatorMixin,\n+    ScrapyGenericTranslator,\n+    ScrapyHTMLTranslator\n+)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#01d948f0fd792c3700306efe1bd38ae2163cb042", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 11 | Files Changed: 2 | Hunks: 9 | Methods Changed: 3 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 31 | Churn Cumulative: 628 | Contributors (this commit): 10 | Commits (past 90d): 8 | Contributors (cumulative): 15 | DMM Complexity: 0.0\n\nDIFF:\n@@ -2,13 +2,13 @@\n XPath selectors based on lxml\n \"\"\"\n \n+import warnings\n+from parsel import Selector as ParselSelector, SelectorList\n from scrapy.utils.trackref import object_ref\n from scrapy.utils.python import to_bytes\n from scrapy.http import HtmlResponse, XmlResponse\n from scrapy.utils.decorators import deprecated\n-from parsel import Selector as ParselSelector, SelectorList\n-from parsel.unified import _ctgroup\n-from .lxmldocument import LxmlDocument\n+from scrapy.exceptions import ScrapyDeprecationWarning\n \n \n __all__ = ['Selector', 'SelectorList']\n@@ -33,22 +33,21 @@ class Selector(ParselSelector, object_ref):\n \n     __slots__ = ['response']\n \n-    def __init__(self, response=None, text=None, type=None, root=None, **kwargs):\n+    def __init__(self, response=None, text=None, type=None, root=None, _root=None, **kwargs):\n         st = _st(response, type or self._default_type)\n \n-        # supporting legacy _root argument\n-        root = kwargs.get('_root', root)\n-\n-        self._parser = _ctgroup[st]['_parser']\n+        if root is None and _root is not None:\n+            warnings.warn(\"Argument `_root` is deprecated, use `root` instead\",\n+                          ScrapyDeprecationWarning, stacklevel=2)\n+            root = _root\n \n         if text is not None:\n             response = _response_from_text(text, st)\n \n         if response is not None:\n-            root = LxmlDocument(response, self._parser)\n+            text = response.body_as_unicode()\n \n         self.response = response\n-        text = response.body_as_unicode() if response else None\n         super(Selector, self).__init__(text=text, type=st, root=root, **kwargs)\n \n     # Deprecated api\n@@ -59,4 +58,3 @@ class Selector(ParselSelector, object_ref):\n     @deprecated(use_instead='.extract()')\n     def extract_unquoted(self):\n         return self.extract()\n-\n\n@@ -7,6 +7,8 @@ from scrapy.exceptions import ScrapyDeprecationWarning\n from scrapy.http import TextResponse, HtmlResponse, XmlResponse\n from scrapy.selector import Selector\n from scrapy.selector.lxmlsel import XmlXPathSelector, HtmlXPathSelector, XPathSelector\n+from lxml import etree\n+from tests import mock\n \n \n class SelectorTestCase(unittest.TestCase):\n@@ -37,6 +39,15 @@ class SelectorTestCase(unittest.TestCase):\n         self.assertEqual([x.extract() for x in sel.xpath(\"concat(//input[@name='a']/@value, //input[@name='b']/@value)\")],\n                          [u'12'])\n \n+    @mock.patch('scrapy.selector.unified.warnings')\n+    def test_deprecated_root_argument(self, warnings):\n+        root = etree.fromstring(u'<html/>')\n+        sel = self.sscls(_root=root)\n+        self.assertEqual(root, sel._root)\n+        warnings.warn.assert_called_once_with(\n+            'Argument `_root` is deprecated, use `root` instead',\n+            mock.ANY, stacklevel=2)\n+\n     def test_representation_slice(self):\n         body = u\"<p><input name='{}' value='\\xa9'/></p>\".format(50 * 'b')\n         response = TextResponse(url=\"http://example.com\", body=body, encoding='utf8')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#17d7347a3698ac7e3650f539578777d63c933262", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 8 | Files Changed: 3 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 25 | Churn Cumulative: 693 | Contributors (this commit): 13 | Commits (past 90d): 10 | Contributors (cumulative): 17 | DMM Complexity: None\n\nDIFF:\n@@ -1,6 +1,15 @@\n-from parsel.csstranslator import (\n-    ScrapyXPathExpr,\n-    TranslatorMixin,\n-    ScrapyGenericTranslator,\n-    ScrapyHTMLTranslator\n-)\n+from parsel.csstranslator import XPathExpr, GenericTranslator, HTMLTranslator\n+from scrapy.utils.deprecate import create_deprecated_class\n+\n+\n+ScrapyXPathExpr = create_deprecated_class(\n+    'ScrapyXPathExpr', XPathExpr,\n+    new_class_path='parsel.csstranslator.XPathExpr')\n+\n+ScrapyGenericTranslator = create_deprecated_class(\n+    'ScrapyGenericTranslator', GenericTranslator,\n+    new_class_path='parsel.csstranslator.GenericTranslator')\n+\n+ScrapyHTMLTranslator = create_deprecated_class(\n+    'ScrapyHTMLTranslator', HTMLTranslator,\n+    new_class_path='parsel.csstranslator.HTMLTranslator')\n\n@@ -44,7 +44,7 @@ setup(\n         'pyOpenSSL',\n         'cssselect>=0.9',\n         'six>=1.5.2',\n-        'parsel>=0.9.0',\n+        'parsel>=0.9.1',\n         'PyDispatcher>=2.0.5',\n         'service_identity',\n     ],\n\n@@ -43,7 +43,7 @@ class SelectorTestCase(unittest.TestCase):\n     def test_deprecated_root_argument(self, warnings):\n         root = etree.fromstring(u'<html/>')\n         sel = self.sscls(_root=root)\n-        self.assertEqual(root, sel._root)\n+        self.assertIs(root, sel._root)\n         warnings.warn.assert_called_once_with(\n             'Argument `_root` is deprecated, use `root` instead',\n             mock.ANY, stacklevel=2)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#35c1dcdbc2eeaace7fce5e58e22f395625b87422", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 6 | Files Changed: 2 | Hunks: 6 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 31 | Contributors (this commit): 4 | Commits (past 90d): 5 | Contributors (cumulative): 7 | DMM Complexity: 0.0\n\nDIFF:\n@@ -65,9 +65,8 @@ class LxmlParserLinkExtractor(object):\n                 if self.unique else links\n \n     def extract_links(self, response):\n-        html = Selector(response)\n         base_url = get_base_url(response)\n-        return self._extract_links(html, response.url, response.encoding, base_url)\n+        return self._extract_links(response.selector, response.url, response.encoding, base_url)\n \n     def _process_links(self, links):\n         \"\"\" Normalize and filter extracted links\n@@ -95,14 +94,13 @@ class LxmlLinkExtractor(FilteringLinkExtractor):\n             canonicalize=canonicalize, deny_extensions=deny_extensions)\n \n     def extract_links(self, response):\n-        html = Selector(response)\n         base_url = get_base_url(response)\n         if self.restrict_xpaths:\n             docs = [subdoc\n                     for x in self.restrict_xpaths\n-                    for subdoc in html.xpath(x)]\n+                    for subdoc in response.xpath(x)]\n         else:\n-            docs = [html]\n+            docs = [response.selector]\n         all_links = []\n         for doc in docs:\n             links = self._extract_links(doc, response.url, response.encoding, base_url)\n\n@@ -127,7 +127,7 @@ class SgmlLinkExtractor(FilteringLinkExtractor):\n     def extract_links(self, response):\n         base_url = None\n         if self.restrict_xpaths:\n-            sel = Selector(response)\n+            sel = response.selector\n             base_url = get_base_url(response)\n             body = u''.join(f\n                             for x in self.restrict_xpaths\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#6287fc310948d15869c14fff9781800fd3ccc3c7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 10 | Churn Cumulative: 692 | Contributors (this commit): 15 | Commits (past 90d): 3 | Contributors (cumulative): 15 | DMM Complexity: 1.0\n\nDIFF:\n@@ -7,6 +7,7 @@ See documentation in docs/topics/request-response.rst\n \n from six.moves.urllib.parse import urljoin, urlencode\n import lxml.html\n+from lxml import etree\n import six\n from scrapy.http.request import Request\n from scrapy.utils.python import to_bytes, is_listlike\n@@ -54,10 +55,15 @@ def _urlencode(seq, enc):\n     return urlencode(values, doseq=1)\n \n \n+def _create_parser_from_response(response, parser_cls):\n+    body = response.body_as_unicode().strip().encode('utf8') or b'<html/>'\n+    parser = parser_cls(recover=True, encoding='utf8')\n+    return etree.fromstring(body, parser=parser, base_url=response.url)\n+\n+\n def _get_form(response, formname, formid, formnumber, formxpath):\n     \"\"\"Find the form element \"\"\"\n-    from scrapy.selector.lxmldocument import LxmlDocument\n-    root = LxmlDocument(response, lxml.html.HTMLParser)\n+    root = _create_parser_from_response(response, lxml.html.HTMLParser)\n     forms = root.xpath('//form')\n     if not forms:\n         raise ValueError(\"No <form> element found in %s\" % response)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#94c3a345b75db3e28dc0cca565650008d69e8992", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 57 | Files Changed: 2 | Hunks: 2 | Methods Changed: 5 | Complexity Δ (Sum/Max): -7/0 | Churn Δ: 57 | Churn Cumulative: 94 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 5 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1,31 +0,0 @@\n-\"\"\"\n-This module contains a simple class (LxmlDocument) which provides cache and\n-garbage collection to lxml element tree documents.\n-\"\"\"\n-\n-import weakref\n-from lxml import etree\n-from scrapy.utils.trackref import object_ref\n-\n-\n-def _factory(response, parser_cls):\n-    url = response.url\n-    body = response.body_as_unicode().strip().encode('utf8') or '<html/>'\n-    parser = parser_cls(recover=True, encoding='utf8')\n-    return etree.fromstring(body, parser=parser, base_url=url)\n-\n-\n-class LxmlDocument(object_ref):\n-\n-    cache = weakref.WeakKeyDictionary()\n-    __slots__ = ['__weakref__']\n-\n-    def __new__(cls, response, parser=etree.HTMLParser):\n-        cache = cls.cache.setdefault(response, {})\n-        if parser not in cache:\n-            obj = object_ref.__new__(cls)\n-            cache[parser] = _factory(response, parser)\n-        return cache[parser]\n-\n-    def __str__(self):\n-        return \"<LxmlDocument %s>\" % self.root.tag\n\n@@ -1,26 +0,0 @@\n-import unittest\n-from scrapy.selector.lxmldocument import LxmlDocument\n-from scrapy.http import TextResponse, HtmlResponse\n-\n-\n-class LxmlDocumentTest(unittest.TestCase):\n-\n-    def test_caching(self):\n-        r1 = HtmlResponse('http://www.example.com', body=b'<html><head></head><body></body></html>')\n-        r2 = r1.copy()\n-\n-        doc1 = LxmlDocument(r1)\n-        doc2 = LxmlDocument(r1)\n-        doc3 = LxmlDocument(r2)\n-\n-        # make sure it's cached\n-        assert doc1 is doc2\n-        assert doc1 is not doc3\n-\n-    def test_null_char(self):\n-        # make sure bodies with null char ('\\x00') don't raise a TypeError exception\n-        body = b'test problematic \\x00 body'\n-        response = TextResponse('http://example.com/catalog/product/blabla-123',\n-                                headers={'Content-Type': 'text/plain; charset=utf-8'},\n-                                body=body)\n-        LxmlDocument(response)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#67c98b185b4ee2a55c71dd1c0266b200fd3bcc04", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 3 | Churn Cumulative: 547 | Contributors (this commit): 9 | Commits (past 90d): 6 | Contributors (cumulative): 9 | DMM Complexity: 0.0\n\nDIFF:\n@@ -17,10 +17,7 @@ __all__ = ['Selector', 'SelectorList']\n def _st(response, st):\n     if st is None:\n         return 'xml' if isinstance(response, XmlResponse) else 'html'\n-    elif st in ('xml', 'html'):\n     return st\n-    else:\n-        raise ValueError('Invalid type: %s' % st)\n \n \n def _response_from_text(text, st):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#2fe6d128f51f94f55ac9d83ac05eb9c763c478b8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 3 | Files Changed: 4 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 12 | Churn Cumulative: 1061 | Contributors (this commit): 15 | Commits (past 90d): 20 | Contributors (cumulative): 27 | DMM Complexity: 1.0\n\nDIFF:\n@@ -47,7 +47,7 @@ class LxmlParserLinkExtractor(object):\n     def _extract_links(self, selector, response_url, response_encoding, base_url):\n         links = []\n         # hacky way to get the underlying lxml parsed document\n-        for el, attr, attr_val in self._iter_links(selector._root):\n+        for el, attr, attr_val in self._iter_links(selector.root):\n             # pseudo lxml.html.HtmlElement.make_links_absolute(base_url)\n             attr_val = urljoin(base_url, attr_val)\n             url = self.process_attr(attr_val)\n\n@@ -48,6 +48,12 @@ class Selector(ParselSelector, object_ref):\n         super(Selector, self).__init__(text=text, type=st, root=root, **kwargs)\n \n     # Deprecated api\n+    @property\n+    def _root(self):\n+        warnings.warn(\"Attribute `_root` is deprecated, use `root` instead\",\n+                      ScrapyDeprecationWarning, stacklevel=2)\n+        return self.root\n+\n     @deprecated(use_instead='.xpath()')\n     def select(self, xpath):\n         return self.xpath(xpath)\n\n@@ -44,7 +44,7 @@ setup(\n         'pyOpenSSL',\n         'cssselect>=0.9',\n         'six>=1.5.2',\n-        'parsel>=0.9.1',\n+        'parsel>=0.9.2',\n         'PyDispatcher>=2.0.5',\n         'service_identity',\n     ],\n\n@@ -43,7 +43,7 @@ class SelectorTestCase(unittest.TestCase):\n     def test_deprecated_root_argument(self, warnings):\n         root = etree.fromstring(u'<html/>')\n         sel = self.sscls(_root=root)\n-        self.assertIs(root, sel._root)\n+        self.assertIs(root, sel.root)\n         warnings.warn.assert_called_once_with(\n             'Argument `_root` is deprecated, use `root` instead',\n             mock.ANY, stacklevel=2)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#26ebccd37a22e15eb522d6e7d979fd816ebbcdd8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 9 | Files Changed: 2 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 13 | Churn Cumulative: 1111 | Contributors (this commit): 19 | Commits (past 90d): 10 | Contributors (cumulative): 24 | DMM Complexity: 0.0\n\nDIFF:\n@@ -7,7 +7,7 @@ See documentation in docs/topics/request-response.rst\n \n from six.moves.urllib.parse import urljoin, urlencode\n import lxml.html\n-from lxml import etree\n+from parsel.selector import create_root_node\n import six\n from scrapy.http.request import Request\n from scrapy.utils.python import to_bytes, is_listlike\n@@ -55,15 +55,10 @@ def _urlencode(seq, enc):\n     return urlencode(values, doseq=1)\n \n \n-def _create_parser_from_response(response, parser_cls):\n-    body = response.body_as_unicode().strip().encode('utf8') or b'<html/>'\n-    parser = parser_cls(recover=True, encoding='utf8')\n-    return etree.fromstring(body, parser=parser, base_url=response.url)\n-\n-\n def _get_form(response, formname, formid, formnumber, formxpath):\n     \"\"\"Find the form element \"\"\"\n-    root = _create_parser_from_response(response, lxml.html.HTMLParser)\n+    text = response.body_as_unicode()\n+    root = create_root_node(text, lxml.html.HTMLParser, base_url=response.url)\n     forms = root.xpath('//form')\n     if not forms:\n         raise ValueError(\"No <form> element found in %s\" % response)\n\n@@ -44,7 +44,7 @@ setup(\n         'pyOpenSSL',\n         'cssselect>=0.9',\n         'six>=1.5.2',\n-        'parsel>=0.9.2',\n+        'parsel>=0.9.3',\n         'PyDispatcher>=2.0.5',\n         'service_identity',\n     ],\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#12579b9afa20612734355c6d0d10481857dbd184", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 9 | Files Changed: 3 | Hunks: 8 | Methods Changed: 5 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 26 | Churn Cumulative: 686 | Contributors (this commit): 10 | Commits (past 90d): 18 | Contributors (cumulative): 19 | DMM Complexity: 0.6666666666666666\n\nDIFF:\n@@ -127,11 +127,10 @@ class SgmlLinkExtractor(FilteringLinkExtractor):\n     def extract_links(self, response):\n         base_url = None\n         if self.restrict_xpaths:\n-            sel = response.selector\n             base_url = get_base_url(response)\n             body = u''.join(f\n                             for x in self.restrict_xpaths\n-                            for f in sel.xpath(x).extract()\n+                            for f in response.xpath(x).extract()\n                             ).encode(response.encoding, errors='xmlcharrefreplace')\n         else:\n             body = response.body\n\n@@ -33,10 +33,13 @@ class Selector(ParselSelector, object_ref):\n     def __init__(self, response=None, text=None, type=None, root=None, _root=None, **kwargs):\n         st = _st(response, type or self._default_type)\n \n-        if root is None and _root is not None:\n+        if _root is not None:\n             warnings.warn(\"Argument `_root` is deprecated, use `root` instead\",\n                           ScrapyDeprecationWarning, stacklevel=2)\n+            if root is None:\n                 root = _root\n+            else:\n+                warnings.warn(\"Ignoring deprecated `_root` argument, using provided `root`\")\n \n         if text is not None:\n             response = _response_from_text(text, st)\n\n@@ -8,7 +8,6 @@ from scrapy.http import TextResponse, HtmlResponse, XmlResponse\n from scrapy.selector import Selector\n from scrapy.selector.lxmlsel import XmlXPathSelector, HtmlXPathSelector, XPathSelector\n from lxml import etree\n-from tests import mock\n \n \n class SelectorTestCase(unittest.TestCase):\n@@ -39,14 +38,21 @@ class SelectorTestCase(unittest.TestCase):\n         self.assertEqual([x.extract() for x in sel.xpath(\"concat(//input[@name='a']/@value, //input[@name='b']/@value)\")],\n                          [u'12'])\n \n-    @mock.patch('scrapy.selector.unified.warnings')\n-    def test_deprecated_root_argument(self, warnings):\n+    def test_deprecated_root_argument(self):\n+        with warnings.catch_warnings(record=True) as w:\n             root = etree.fromstring(u'<html/>')\n             sel = self.sscls(_root=root)\n             self.assertIs(root, sel.root)\n-        warnings.warn.assert_called_once_with(\n-            'Argument `_root` is deprecated, use `root` instead',\n-            mock.ANY, stacklevel=2)\n+            self.assertEqual(str(w[-1].message),\n+                             'Argument `_root` is deprecated, use `root` instead')\n+\n+    def test_deprecated_root_argument_ambiguous(self):\n+        with warnings.catch_warnings(record=True) as w:\n+            _root = etree.fromstring(u'<xml/>')\n+            root = etree.fromstring(u'<html/>')\n+            sel = self.sscls(_root=_root, root=root)\n+            self.assertIs(root, sel.root)\n+            self.assertIn('Ignoring deprecated `_root` argument', str(w[-1].message))\n \n     def test_representation_slice(self):\n         body = u\"<p><input name='{}' value='\\xa9'/></p>\".format(50 * 'b')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#3a03ef7c08f0b4b454d13933ea2239b053824675", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 28 | Lines Deleted: 628 | Files Changed: 2 | Hunks: 21 | Methods Changed: 52 | Complexity Δ (Sum/Max): -59/0 | Churn Δ: 656 | Churn Cumulative: 764 | Contributors (this commit): 7 | Commits (past 90d): 9 | Contributors (cumulative): 9 | DMM Complexity: 0.0\n\nDIFF:\n@@ -12,18 +12,16 @@ from lxml import etree\n \n class SelectorTestCase(unittest.TestCase):\n \n-    sscls = Selector\n-\n     def test_simple_selection(self):\n         \"\"\"Simple selector tests\"\"\"\n-        body = \"<p><input name='a'value='1'/><input name='b'value='2'/></p>\"\n-        response = TextResponse(url=\"http://example.com\", body=body)\n-        sel = self.sscls(response)\n+        body = u\"<p><input name='a'value='1'/><input name='b'value='2'/></p>\"\n+        response = TextResponse(url=\"http://example.com\", body=body, encoding='utf-8')\n+        sel = Selector(response)\n \n         xl = sel.xpath('//input')\n         self.assertEqual(2, len(xl))\n         for x in xl:\n-            assert isinstance(x, self.sscls)\n+            assert isinstance(x, Selector)\n \n         self.assertEqual(sel.xpath('//input').extract(),\n                          [x.extract() for x in sel.xpath('//input')])\n@@ -41,7 +39,7 @@ class SelectorTestCase(unittest.TestCase):\n     def test_deprecated_root_argument(self):\n         with warnings.catch_warnings(record=True) as w:\n             root = etree.fromstring(u'<html/>')\n-            sel = self.sscls(_root=root)\n+            sel = Selector(_root=root)\n             self.assertIs(root, sel.root)\n             self.assertEqual(str(w[-1].message),\n                              'Argument `_root` is deprecated, use `root` instead')\n@@ -50,238 +48,22 @@ class SelectorTestCase(unittest.TestCase):\n         with warnings.catch_warnings(record=True) as w:\n             _root = etree.fromstring(u'<xml/>')\n             root = etree.fromstring(u'<html/>')\n-            sel = self.sscls(_root=_root, root=root)\n+            sel = Selector(_root=_root, root=root)\n             self.assertIs(root, sel.root)\n             self.assertIn('Ignoring deprecated `_root` argument', str(w[-1].message))\n \n-    def test_representation_slice(self):\n-        body = u\"<p><input name='{}' value='\\xa9'/></p>\".format(50 * 'b')\n-        response = TextResponse(url=\"http://example.com\", body=body, encoding='utf8')\n-        sel = self.sscls(response)\n-\n-        self.assertEqual(\n-            map(repr, sel.xpath('//input/@name')),\n-            [\"<Selector xpath='//input/@name' data=u'{}'>\".format(40 * 'b')]\n-        )\n-\n-    def test_representation_unicode_query(self):\n-        body = u\"<p><input name='{}' value='\\xa9'/></p>\".format(50 * 'b')\n-        response = TextResponse(url=\"http://example.com\", body=body, encoding='utf8')\n-        sel = self.sscls(response)\n-        self.assertEqual(\n-            map(repr, sel.xpath(u'//input[@value=\"\\xa9\"]/@value')),\n-            [\"<Selector xpath=u'//input[@value=\\\"\\\\xa9\\\"]/@value' data=u'\\\\xa9'>\"]\n-        )\n-\n-    def test_extract_first(self):\n-        \"\"\"Test if extract_first() returns first element\"\"\"\n-        body = '<ul><li id=\"1\">1</li><li id=\"2\">2</li></ul>'\n-        response = TextResponse(url=\"http://example.com\", body=body)\n-        sel = self.sscls(response)\n-\n-        self.assertEqual(sel.xpath('//ul/li/text()').extract_first(),\n-                         sel.xpath('//ul/li/text()').extract()[0])\n-\n-        self.assertEqual(sel.xpath('//ul/li[@id=\"1\"]/text()').extract_first(),\n-                         sel.xpath('//ul/li[@id=\"1\"]/text()').extract()[0])\n-\n-        self.assertEqual(sel.xpath('//ul/li[2]/text()').extract_first(),\n-                         sel.xpath('//ul/li/text()').extract()[1])\n-\n-        self.assertEqual(sel.xpath('/ul/li[@id=\"doesnt-exist\"]/text()').extract_first(), None)\n-\n-    def test_extract_first_default(self):\n-        \"\"\"Test if extract_first() returns default value when no results found\"\"\"\n-        body = '<ul><li id=\"1\">1</li><li id=\"2\">2</li></ul>'\n-        response = TextResponse(url=\"http://example.com\", body=body)\n-        sel = self.sscls(response)\n-\n-        self.assertEqual(sel.xpath('//div/text()').extract_first(default='missing'), 'missing')\n-\n-    def test_re_first(self):\n-        \"\"\"Test if re_first() returns first matched element\"\"\"\n-        body = '<ul><li id=\"1\">1</li><li id=\"2\">2</li></ul>'\n-        response = TextResponse(url=\"http://example.com\", body=body)\n-        sel = self.sscls(response)\n-\n-        self.assertEqual(sel.xpath('//ul/li/text()').re_first('\\d'),\n-                         sel.xpath('//ul/li/text()').re('\\d')[0])\n-\n-        self.assertEqual(sel.xpath('//ul/li[@id=\"1\"]/text()').re_first('\\d'),\n-                         sel.xpath('//ul/li[@id=\"1\"]/text()').re('\\d')[0])\n-\n-        self.assertEqual(sel.xpath('//ul/li[2]/text()').re_first('\\d'),\n-                         sel.xpath('//ul/li/text()').re('\\d')[1])\n-\n-        self.assertEqual(sel.xpath('/ul/li/text()').re_first('\\w+'), None)\n-        self.assertEqual(sel.xpath('/ul/li[@id=\"doesnt-exist\"]/text()').re_first('\\d'), None)\n-\n-    def test_select_unicode_query(self):\n-        body = u\"<p><input name='\\xa9' value='1'/></p>\"\n-        response = TextResponse(url=\"http://example.com\", body=body, encoding='utf8')\n-        sel = self.sscls(response)\n-        self.assertEqual(sel.xpath(u'//input[@name=\"\\xa9\"]/@value').extract(), [u'1'])\n-\n-    def test_list_elements_type(self):\n-        \"\"\"Test Selector returning the same type in selection methods\"\"\"\n-        text = '<p>test<p>'\n-        assert isinstance(self.sscls(text=text).xpath(\"//p\")[0], self.sscls)\n-        assert isinstance(self.sscls(text=text).css(\"p\")[0], self.sscls)\n-\n-    def test_boolean_result(self):\n-        body = \"<p><input name='a'value='1'/><input name='b'value='2'/></p>\"\n-        response = TextResponse(url=\"http://example.com\", body=body)\n-        xs = self.sscls(response)\n-        self.assertEquals(xs.xpath(\"//input[@name='a']/@name='a'\").extract(), [u'1'])\n-        self.assertEquals(xs.xpath(\"//input[@name='a']/@name='n'\").extract(), [u'0'])\n-\n-    def test_differences_parsing_xml_vs_html(self):\n-        \"\"\"Test that XML and HTML Selector's behave differently\"\"\"\n-        # some text which is parsed differently by XML and HTML flavors\n-        text = '<div><img src=\"a.jpg\"><p>Hello</div>'\n-        hs = self.sscls(text=text, type='html')\n-        self.assertEqual(hs.xpath(\"//div\").extract(),\n-                         [u'<div><img src=\"a.jpg\"><p>Hello</p></div>'])\n-\n-        xs = self.sscls(text=text, type='xml')\n-        self.assertEqual(xs.xpath(\"//div\").extract(),\n-                         [u'<div><img src=\"a.jpg\"><p>Hello</p></img></div>'])\n-\n     def test_flavor_detection(self):\n-        text = '<div><img src=\"a.jpg\"><p>Hello</div>'\n-        sel = self.sscls(XmlResponse('http://example.com', body=text))\n+        text = u'<div><img src=\"a.jpg\"><p>Hello</div>'\n+        sel = Selector(XmlResponse('http://example.com', body=text, encoding='utf-8'))\n         self.assertEqual(sel.type, 'xml')\n         self.assertEqual(sel.xpath(\"//div\").extract(),\n                          [u'<div><img src=\"a.jpg\"><p>Hello</p></img></div>'])\n \n-        sel = self.sscls(HtmlResponse('http://example.com', body=text))\n+        sel = Selector(HtmlResponse('http://example.com', body=text, encoding='utf-8'))\n         self.assertEqual(sel.type, 'html')\n         self.assertEqual(sel.xpath(\"//div\").extract(),\n                          [u'<div><img src=\"a.jpg\"><p>Hello</p></div>'])\n \n-    def test_nested_selectors(self):\n-        \"\"\"Nested selector tests\"\"\"\n-        body = \"\"\"<body>\n-                    <div class='one'>\n-                      <ul>\n-                        <li>one</li><li>two</li>\n-                      </ul>\n-                    </div>\n-                    <div class='two'>\n-                      <ul>\n-                        <li>four</li><li>five</li><li>six</li>\n-                      </ul>\n-                    </div>\n-                  </body>\"\"\"\n-\n-        response = HtmlResponse(url=\"http://example.com\", body=body)\n-        x = self.sscls(response)\n-        divtwo = x.xpath('//div[@class=\"two\"]')\n-        self.assertEqual(divtwo.xpath(\"//li\").extract(),\n-                         [\"<li>one</li>\", \"<li>two</li>\", \"<li>four</li>\", \"<li>five</li>\", \"<li>six</li>\"])\n-        self.assertEqual(divtwo.xpath(\"./ul/li\").extract(),\n-                         [\"<li>four</li>\", \"<li>five</li>\", \"<li>six</li>\"])\n-        self.assertEqual(divtwo.xpath(\".//li\").extract(),\n-                         [\"<li>four</li>\", \"<li>five</li>\", \"<li>six</li>\"])\n-        self.assertEqual(divtwo.xpath(\"./li\").extract(), [])\n-\n-    def test_mixed_nested_selectors(self):\n-        body = '''<body>\n-                    <div id=1>not<span>me</span></div>\n-                    <div class=\"dos\"><p>text</p><a href='#'>foo</a></div>\n-               </body>'''\n-        sel = self.sscls(text=body)\n-        self.assertEqual(sel.xpath('//div[@id=\"1\"]').css('span::text').extract(), [u'me'])\n-        self.assertEqual(sel.css('#1').xpath('./span/text()').extract(), [u'me'])\n-\n-    def test_dont_strip(self):\n-        sel = self.sscls(text='<div>fff: <a href=\"#\">zzz</a></div>')\n-        self.assertEqual(sel.xpath(\"//text()\").extract(), [u'fff: ', u'zzz'])\n-\n-    def test_namespaces_simple(self):\n-        body = \"\"\"\n-        <test xmlns:somens=\"http://scrapy.org\">\n-           <somens:a id=\"foo\">take this</a>\n-           <a id=\"bar\">found</a>\n-        </test>\n-        \"\"\"\n-\n-        response = XmlResponse(url=\"http://example.com\", body=body)\n-        x = self.sscls(response)\n-\n-        x.register_namespace(\"somens\", \"http://scrapy.org\")\n-        self.assertEqual(x.xpath(\"//somens:a/text()\").extract(),\n-                         [u'take this'])\n-\n-    def test_namespaces_multiple(self):\n-        body = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n-<BrowseNode xmlns=\"http://webservices.amazon.com/AWSECommerceService/2005-10-05\"\n-            xmlns:b=\"http://somens.com\"\n-            xmlns:p=\"http://www.scrapy.org/product\" >\n-    <b:Operation>hello</b:Operation>\n-    <TestTag b:att=\"value\"><Other>value</Other></TestTag>\n-    <p:SecondTestTag><material>iron</material><price>90</price><p:name>Dried Rose</p:name></p:SecondTestTag>\n-</BrowseNode>\n-        \"\"\"\n-        response = XmlResponse(url=\"http://example.com\", body=body)\n-        x = self.sscls(response)\n-        x.register_namespace(\"xmlns\", \"http://webservices.amazon.com/AWSECommerceService/2005-10-05\")\n-        x.register_namespace(\"p\", \"http://www.scrapy.org/product\")\n-        x.register_namespace(\"b\", \"http://somens.com\")\n-        self.assertEqual(len(x.xpath(\"//xmlns:TestTag\")), 1)\n-        self.assertEqual(x.xpath(\"//b:Operation/text()\").extract()[0], 'hello')\n-        self.assertEqual(x.xpath(\"//xmlns:TestTag/@b:att\").extract()[0], 'value')\n-        self.assertEqual(x.xpath(\"//p:SecondTestTag/xmlns:price/text()\").extract()[0], '90')\n-        self.assertEqual(x.xpath(\"//p:SecondTestTag\").xpath(\"./xmlns:price/text()\")[0].extract(), '90')\n-        self.assertEqual(x.xpath(\"//p:SecondTestTag/xmlns:material/text()\").extract()[0], 'iron')\n-\n-    def test_re(self):\n-        body = \"\"\"<div>Name: Mary\n-                    <ul>\n-                      <li>Name: John</li>\n-                      <li>Age: 10</li>\n-                      <li>Name: Paul</li>\n-                      <li>Age: 20</li>\n-                    </ul>\n-                    Age: 20\n-                  </div>\"\"\"\n-        response = HtmlResponse(url=\"http://example.com\", body=body)\n-        x = self.sscls(response)\n-\n-        name_re = re.compile(\"Name: (\\w+)\")\n-        self.assertEqual(x.xpath(\"//ul/li\").re(name_re),\n-                         [\"John\", \"Paul\"])\n-        self.assertEqual(x.xpath(\"//ul/li\").re(\"Age: (\\d+)\"),\n-                         [\"10\", \"20\"])\n-\n-    def test_re_intl(self):\n-        body = \"\"\"<div>Evento: cumplea\\xc3\\xb1os</div>\"\"\"\n-        response = HtmlResponse(url=\"http://example.com\", body=body, encoding='utf-8')\n-        x = self.sscls(response)\n-        self.assertEqual(x.xpath(\"//div\").re(\"Evento: (\\w+)\"), [u'cumplea\\xf1os'])\n-\n-    def test_selector_over_text(self):\n-        hs = self.sscls(text='<root>lala</root>')\n-        self.assertEqual(hs.extract(), u'<html><body><root>lala</root></body></html>')\n-        xs = self.sscls(text='<root>lala</root>', type='xml')\n-        self.assertEqual(xs.extract(), u'<root>lala</root>')\n-        self.assertEqual(xs.xpath('.').extract(), [u'<root>lala</root>'])\n-\n-    def test_invalid_xpath(self):\n-        \"Test invalid xpath raises ValueError with the invalid xpath\"\n-        response = XmlResponse(url=\"http://example.com\", body=\"<html></html>\")\n-        x = self.sscls(response)\n-        xpath = \"//test[@foo='bar]\"\n-        self.assertRaisesRegexp(ValueError, re.escape(xpath), x.xpath, xpath)\n-\n-    def test_invalid_xpath_unicode(self):\n-        \"Test *Unicode* invalid xpath raises ValueError with the invalid xpath\"\n-        response = XmlResponse(url=\"http://example.com\", body=\"<html></html>\")\n-        x = self.sscls(response)\n-        xpath = u\"//test[@foo='\\u0431ar]\"\n-        encoded = xpath if six.PY3 else xpath.encode('unicode_escape')\n-        self.assertRaisesRegexp(ValueError, re.escape(encoded), x.xpath, xpath)\n-\n     def test_http_header_encoding_precedence(self):\n         # u'\\xa3'     = pound symbol in unicode\n         # u'\\xc2\\xa3' = pound symbol in utf-8\n@@ -297,136 +79,28 @@ class SelectorTestCase(unittest.TestCase):\n \n         headers = {'Content-Type': ['text/html; charset=utf-8']}\n         response = HtmlResponse(url=\"http://example.com\", headers=headers, body=html_utf8)\n-        x = self.sscls(response)\n+        x = Selector(response)\n         self.assertEquals(x.xpath(\"//span[@id='blank']/text()\").extract(),\n                           [u'\\xa3'])\n \n-    def test_empty_bodies(self):\n-        # shouldn't raise errors\n-        r1 = TextResponse('http://www.example.com', body='')\n-        self.sscls(r1).xpath('//text()').extract()\n-\n-    def test_null_bytes(self):\n-        # shouldn't raise errors\n-        r1 = TextResponse('http://www.example.com', \\\n-                          body='<root>pre\\x00post</root>', \\\n-                          encoding='utf-8')\n-        self.sscls(r1).xpath('//text()').extract()\n-\n     def test_badly_encoded_body(self):\n         # \\xe9 alone isn't valid utf8 sequence\n         r1 = TextResponse('http://www.example.com', \\\n-                          body='<html><p>an Jos\\xe9 de</p><html>', \\\n+                          body=u'<html><p>an Jos\\xe9 de</p><html>', \\\n                           encoding='utf-8')\n-        self.sscls(r1).xpath('//text()').extract()\n-\n-    def test_select_on_unevaluable_nodes(self):\n-        r = self.sscls(text=u'<span class=\"big\">some text</span>')\n-        # Text node\n-        x1 = r.xpath('//text()')\n-        self.assertEquals(x1.extract(), [u'some text'])\n-        self.assertEquals(x1.xpath('.//b').extract(), [])\n-        # Tag attribute\n-        x1 = r.xpath('//span/@class')\n-        self.assertEquals(x1.extract(), [u'big'])\n-        self.assertEquals(x1.xpath('.//text()').extract(), [])\n-\n-    def test_select_on_text_nodes(self):\n-        r = self.sscls(text=u'<div><b>Options:</b>opt1</div><div><b>Other</b>opt2</div>')\n-        x1 = r.xpath(\"//div/descendant::text()[preceding-sibling::b[contains(text(), 'Options')]]\")\n-        self.assertEquals(x1.extract(), [u'opt1'])\n-\n-        x1 = r.xpath(\"//div/descendant::text()/preceding-sibling::b[contains(text(), 'Options')]\")\n-        self.assertEquals(x1.extract(), [u'<b>Options:</b>'])\n-\n-    def test_nested_select_on_text_nodes(self):\n-        # FIXME: does not work with lxml backend [upstream]\n-        r = self.sscls(text=u'<div><b>Options:</b>opt1</div><div><b>Other</b>opt2</div>')\n-        x1 = r.xpath(\"//div/descendant::text()\")\n-        x2 = x1.xpath(\"./preceding-sibling::b[contains(text(), 'Options')]\")\n-        self.assertEquals(x2.extract(), [u'<b>Options:</b>'])\n-    test_nested_select_on_text_nodes.skip = \"Text nodes lost parent node reference in lxml\"\n+        Selector(r1).xpath('//text()').extract()\n \n     def test_weakref_slots(self):\n         \"\"\"Check that classes are using slots and are weak-referenceable\"\"\"\n-        x = self.sscls(text='')\n+        x = Selector(text='')\n         weakref.ref(x)\n         assert not hasattr(x, '__dict__'), \"%s does not use __slots__\" % \\\n             x.__class__.__name__\n \n-    def test_remove_namespaces(self):\n-        xml = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n-<feed xmlns=\"http://www.w3.org/2005/Atom\" xml:lang=\"en-US\" xmlns:media=\"http://search.yahoo.com/mrss/\">\n-  <link type=\"text/html\">\n-  <link type=\"application/atom+xml\">\n-</feed>\n-\"\"\"\n-        sel = self.sscls(XmlResponse(\"http://example.com/feed.atom\", body=xml))\n-        self.assertEqual(len(sel.xpath(\"//link\")), 0)\n-        sel.remove_namespaces()\n-        self.assertEqual(len(sel.xpath(\"//link\")), 2)\n-\n-    def test_remove_attributes_namespaces(self):\n-        xml = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n-<feed xmlns:atom=\"http://www.w3.org/2005/Atom\" xml:lang=\"en-US\" xmlns:media=\"http://search.yahoo.com/mrss/\">\n-  <link atom:type=\"text/html\">\n-  <link atom:type=\"application/atom+xml\">\n-</feed>\n-\"\"\"\n-        sel = self.sscls(XmlResponse(\"http://example.com/feed.atom\", body=xml))\n-        self.assertEqual(len(sel.xpath(\"//link/@type\")), 0)\n-        sel.remove_namespaces()\n-        self.assertEqual(len(sel.xpath(\"//link/@type\")), 2)\n-\n-    def test_smart_strings(self):\n-        \"\"\"Lxml smart strings return values\"\"\"\n-\n-        class SmartStringsSelector(Selector):\n-            _lxml_smart_strings = True\n-\n-        body = \"\"\"<body>\n-                    <div class='one'>\n-                      <ul>\n-                        <li>one</li><li>two</li>\n-                      </ul>\n-                    </div>\n-                    <div class='two'>\n-                      <ul>\n-                        <li>four</li><li>five</li><li>six</li>\n-                      </ul>\n-                    </div>\n-                  </body>\"\"\"\n-\n-        response = HtmlResponse(url=\"http://example.com\", body=body)\n-\n-        # .getparent() is available for text nodes and attributes\n-        # only when smart_strings are on\n-        x = self.sscls(response)\n-        li_text = x.xpath('//li/text()')\n-        self.assertFalse(any(map(lambda e: hasattr(e._root, 'getparent'), li_text)))\n-        div_class = x.xpath('//div/@class')\n-        self.assertFalse(any(map(lambda e: hasattr(e._root, 'getparent'), div_class)))\n-\n-        x = SmartStringsSelector(response)\n-        li_text = x.xpath('//li/text()')\n-        self.assertTrue(all(map(lambda e: hasattr(e._root, 'getparent'), li_text)))\n-        div_class = x.xpath('//div/@class')\n-        self.assertTrue(all(map(lambda e: hasattr(e._root, 'getparent'), div_class)))\n-\n-    def test_xml_entity_expansion(self):\n-        malicious_xml = '<?xml version=\"1.0\" encoding=\"ISO-8859-1\"?>'\\\n-            '<!DOCTYPE foo [ <!ELEMENT foo ANY > <!ENTITY xxe SYSTEM '\\\n-            '\"file:///etc/passwd\" >]><foo>&xxe;</foo>'\n-\n-        response = XmlResponse('http://example.com', body=malicious_xml)\n-        sel = self.sscls(response=response)\n-\n-        self.assertEqual(sel.extract(), '<foo>&xxe;</foo>')\n-\n \n class DeprecatedXpathSelectorTest(unittest.TestCase):\n \n-    text = '<div><img src=\"a.jpg\"><p>Hello</div>'\n+    text = u'<div><img src=\"a.jpg\"><p>Hello</div>'\n \n     def test_warnings_xpathselector(self):\n         cls = XPathSelector\n@@ -505,146 +179,3 @@ class DeprecatedXpathSelectorTest(unittest.TestCase):\n             self.assertTrue(isinstance(usel, Selector))\n             self.assertTrue(isinstance(sel, XPathSelector))\n             self.assertTrue(isinstance(usel, XPathSelector))\n\\ No newline at end of file\n-\n-    def test_xpathselector(self):\n-        with warnings.catch_warnings():\n-            warnings.simplefilter('ignore', ScrapyDeprecationWarning)\n-            hs = XPathSelector(text=self.text)\n-            self.assertEqual(hs.select(\"//div\").extract(),\n-                             [u'<div><img src=\"a.jpg\"><p>Hello</p></div>'])\n-            self.assertRaises(RuntimeError, hs.css, 'div')\n-\n-    def test_htmlxpathselector(self):\n-        with warnings.catch_warnings():\n-            warnings.simplefilter('ignore', ScrapyDeprecationWarning)\n-            hs = HtmlXPathSelector(text=self.text)\n-            self.assertEqual(hs.select(\"//div\").extract(),\n-                             [u'<div><img src=\"a.jpg\"><p>Hello</p></div>'])\n-            self.assertRaises(RuntimeError, hs.css, 'div')\n-\n-    def test_xmlxpathselector(self):\n-        with warnings.catch_warnings():\n-            warnings.simplefilter('ignore', ScrapyDeprecationWarning)\n-            xs = XmlXPathSelector(text=self.text)\n-            self.assertEqual(xs.select(\"//div\").extract(),\n-                             [u'<div><img src=\"a.jpg\"><p>Hello</p></img></div>'])\n-            self.assertRaises(RuntimeError, xs.css, 'div')\n-\n-\n-class ExsltTestCase(unittest.TestCase):\n-\n-    sscls = Selector\n-\n-    def test_regexp(self):\n-        \"\"\"EXSLT regular expression tests\"\"\"\n-        body = \"\"\"\n-        <p><input name='a' value='1'/><input name='b' value='2'/></p>\n-        <div class=\"links\">\n-        <a href=\"/first.html\">first link</a>\n-        <a href=\"/second.html\">second link</a>\n-        <a href=\"http://www.bayes.co.uk/xml/index.xml?/xml/utils/rechecker.xml\">EXSLT match example</a>\n-        </div>\n-        \"\"\"\n-        response = TextResponse(url=\"http://example.com\", body=body)\n-        sel = self.sscls(response)\n-\n-        # re:test()\n-        self.assertEqual(\n-            sel.xpath(\n-                '//input[re:test(@name, \"[A-Z]+\", \"i\")]').extract(),\n-            [x.extract() for x in sel.xpath('//input[re:test(@name, \"[A-Z]+\", \"i\")]')])\n-        self.assertEqual(\n-            [x.extract()\n-             for x in sel.xpath(\n-                 '//a[re:test(@href, \"\\.html$\")]/text()')],\n-            [u'first link', u'second link'])\n-        self.assertEqual(\n-            [x.extract()\n-             for x in sel.xpath(\n-                 '//a[re:test(@href, \"first\")]/text()')],\n-            [u'first link'])\n-        self.assertEqual(\n-            [x.extract()\n-             for x in sel.xpath(\n-                 '//a[re:test(@href, \"second\")]/text()')],\n-            [u'second link'])\n-\n-\n-        # re:match() is rather special: it returns a node-set of <match> nodes\n-        #[u'<match>http://www.bayes.co.uk/xml/index.xml?/xml/utils/rechecker.xml</match>',\n-        #u'<match>http</match>',\n-        #u'<match>www.bayes.co.uk</match>',\n-        #u'<match></match>',\n-        #u'<match>/xml/index.xml?/xml/utils/rechecker.xml</match>']\n-        self.assertEqual(\n-            sel.xpath('re:match(//a[re:test(@href, \"\\.xml$\")]/@href,'\n-                      '\"(\\w+):\\/\\/([^/:]+)(:\\d*)?([^# ]*)\")/text()').extract(),\n-            [u'http://www.bayes.co.uk/xml/index.xml?/xml/utils/rechecker.xml',\n-             u'http',\n-             u'www.bayes.co.uk',\n-             u'',\n-             u'/xml/index.xml?/xml/utils/rechecker.xml'])\n-\n-\n-\n-        # re:replace()\n-        self.assertEqual(\n-            sel.xpath('re:replace(//a[re:test(@href, \"\\.xml$\")]/@href,'\n-                      '\"(\\w+)://(.+)(\\.xml)\", \"\",\"https://\\\\2.html\")').extract(),\n-            [u'https://www.bayes.co.uk/xml/index.xml?/xml/utils/rechecker.html'])\n-\n-    def test_set(self):\n-        \"\"\"EXSLT set manipulation tests\"\"\"\n-        # microdata example from http://schema.org/Event\n-        body=\"\"\"\n-        <div itemscope itemtype=\"http://schema.org/Event\">\n-          <a itemprop=\"url\" href=\"nba-miami-philidelphia-game3.html\">\n-          NBA Eastern Conference First Round Playoff Tickets:\n-          <span itemprop=\"name\"> Miami Heat at Philadelphia 76ers - Game 3 (Home Game 1) </span>\n-          </a>\n-\n-          <meta itemprop=\"startDate\" content=\"2016-04-21T20:00\">\n-            Thu, 04/21/16\n-            8:00 p.m.\n-\n-          <div itemprop=\"location\" itemscope itemtype=\"http://schema.org/Place\">\n-            <a itemprop=\"url\" href=\"wells-fargo-center.html\">\n-            Wells Fargo Center\n-            </a>\n-            <div itemprop=\"address\" itemscope itemtype=\"http://schema.org/PostalAddress\">\n-              <span itemprop=\"addressLocality\">Philadelphia</span>,\n-              <span itemprop=\"addressRegion\">PA</span>\n-            </div>\n-          </div>\n-\n-          <div itemprop=\"offers\" itemscope itemtype=\"http://schema.org/AggregateOffer\">\n-            Priced from: <span itemprop=\"lowPrice\">$35</span>\n-            <span itemprop=\"offerCount\">1938</span> tickets left\n-          </div>\n-        </div>\n-        \"\"\"\n-        response = TextResponse(url=\"http://example.com\", body=body)\n-        sel = self.sscls(response)\n-\n-        self.assertEqual(\n-            sel.xpath('''//div[@itemtype=\"http://schema.org/Event\"]\n-                            //@itemprop''').extract(),\n-            [u'url',\n-             u'name',\n-             u'startDate',\n-             u'location',\n-             u'url',\n-             u'address',\n-             u'addressLocality',\n-             u'addressRegion',\n-             u'offers',\n-             u'lowPrice',\n-             u'offerCount']\n-        )\n-\n-        self.assertEqual(sel.xpath('''\n-                set:difference(//div[@itemtype=\"http://schema.org/Event\"]\n-                                    //@itemprop,\n-                               //div[@itemtype=\"http://schema.org/Event\"]\n-                                    //*[@itemscope]/*/@itemprop)''').extract(),\n-                         [u'url', u'name', u'startDate', u'location', u'offers'])\n\n@@ -1,153 +1,22 @@\n \"\"\"\n Selector tests for cssselect backend\n \"\"\"\n+import warnings\n from twisted.trial import unittest\n-from scrapy.http import HtmlResponse\n-from scrapy.selector.csstranslator import ScrapyHTMLTranslator\n-from scrapy.selector import Selector\n-from cssselect.parser import SelectorSyntaxError\n-from cssselect.xpath import ExpressionError\n+from scrapy.selector.csstranslator import (\n+    ScrapyHTMLTranslator,\n+    ScrapyGenericTranslator,\n+    ScrapyXPathExpr\n+)\n \n \n-HTMLBODY = b'''\n-<html>\n-<body>\n-<div>\n- <a id=\"name-anchor\" name=\"foo\"></a>\n- <a id=\"tag-anchor\" rel=\"tag\" href=\"http://localhost/foo\">link</a>\n- <a id=\"nofollow-anchor\" rel=\"nofollow\" href=\"https://example.org\"> link</a>\n- <p id=\"paragraph\">\n-   lorem ipsum text\n-   <b id=\"p-b\">hi</b> <em id=\"p-em\">there</em>\n-   <b id=\"p-b2\">guy</b>\n-   <input type=\"checkbox\" id=\"checkbox-unchecked\" />\n-   <input type=\"checkbox\" id=\"checkbox-disabled\" disabled=\"\" />\n-   <input type=\"text\" id=\"text-checked\" checked=\"checked\" />\n-   <input type=\"hidden\" />\n-   <input type=\"hidden\" disabled=\"disabled\" />\n-   <input type=\"checkbox\" id=\"checkbox-checked\" checked=\"checked\" />\n-   <input type=\"checkbox\" id=\"checkbox-disabled-checked\"\n-          disabled=\"disabled\" checked=\"checked\" />\n-   <fieldset id=\"fieldset\" disabled=\"disabled\">\n-     <input type=\"checkbox\" id=\"checkbox-fieldset-disabled\" />\n-     <input type=\"hidden\" />\n-   </fieldset>\n- </p>\n- <map name=\"dummymap\">\n-   <area shape=\"circle\" coords=\"200,250,25\" href=\"foo.html\" id=\"area-href\" />\n-   <area shape=\"default\" id=\"area-nohref\" />\n- </map>\n-</div>\n-<div class=\"cool-footer\" id=\"foobar-div\" foobar=\"ab bc cde\">\n-    <span id=\"foobar-span\">foo ter</span>\n-</div>\n-</body></html>\n-'''\n+class DeprecatedClassesTest(unittest.TestCase):\n+\n+    def test_deprecated_warnings(self):\n+        for cls in [ScrapyHTMLTranslator, ScrapyGenericTranslator, ScrapyXPathExpr]:\n+            with warnings.catch_warnings(record=True) as w:\n+                obj = cls()\n+                self.assertIn('%s is deprecated' % cls.__name__, str(w[-1].message),\n+                              'Missing deprecate warning for %s' % cls.__name__)\n \n \n-class TranslatorMixinTest(unittest.TestCase):\n-\n-    tr_cls = ScrapyHTMLTranslator\n-\n-    def setUp(self):\n-        self.tr = self.tr_cls()\n-        self.c2x = self.tr.css_to_xpath\n-\n-    def test_attr_function(self):\n-        cases = [\n-            ('::attr(name)', u'descendant-or-self::*/@name'),\n-            ('a::attr(href)', u'descendant-or-self::a/@href'),\n-            ('a ::attr(img)', u'descendant-or-self::a/descendant-or-self::*/@img'),\n-            ('a > ::attr(class)', u'descendant-or-self::a/*/@class'),\n-        ]\n-        for css, xpath in cases:\n-            self.assertEqual(self.c2x(css), xpath, css)\n-\n-    def test_attr_function_exception(self):\n-        cases = [\n-            ('::attr(12)', ExpressionError),\n-            ('::attr(34test)', ExpressionError),\n-            ('::attr(@href)', SelectorSyntaxError),\n-        ]\n-        for css, exc in cases:\n-            self.assertRaises(exc, self.c2x, css)\n-\n-    def test_text_pseudo_element(self):\n-        cases = [\n-            ('::text', u'descendant-or-self::text()'),\n-            ('p::text', u'descendant-or-self::p/text()'),\n-            ('p ::text', u'descendant-or-self::p/descendant-or-self::text()'),\n-            ('#id::text', u\"descendant-or-self::*[@id = 'id']/text()\"),\n-            ('p#id::text', u\"descendant-or-self::p[@id = 'id']/text()\"),\n-            ('p#id ::text', u\"descendant-or-self::p[@id = 'id']/descendant-or-self::text()\"),\n-            ('p#id > ::text', u\"descendant-or-self::p[@id = 'id']/*/text()\"),\n-            ('p#id ~ ::text', u\"descendant-or-self::p[@id = 'id']/following-sibling::*/text()\"),\n-            ('a[href]::text', u'descendant-or-self::a[@href]/text()'),\n-            ('a[href] ::text', u'descendant-or-self::a[@href]/descendant-or-self::text()'),\n-            ('p::text, a::text', u\"descendant-or-self::p/text() | descendant-or-self::a/text()\"),\n-        ]\n-        for css, xpath in cases:\n-            self.assertEqual(self.c2x(css), xpath, css)\n-\n-    def test_pseudo_function_exception(self):\n-        cases = [\n-            ('::attribute(12)', ExpressionError),\n-            ('::text()', ExpressionError),\n-            ('::attr(@href)', SelectorSyntaxError),\n-        ]\n-        for css, exc in cases:\n-            self.assertRaises(exc, self.c2x, css)\n-\n-    def test_unknown_pseudo_element(self):\n-        cases = [\n-            ('::text-node', ExpressionError),\n-        ]\n-        for css, exc in cases:\n-            self.assertRaises(exc, self.c2x, css)\n-\n-    def test_unknown_pseudo_class(self):\n-        cases = [\n-            (':text', ExpressionError),\n-            (':attribute(name)', ExpressionError),\n-        ]\n-        for css, exc in cases:\n-            self.assertRaises(exc, self.c2x, css)\n-\n-\n-class CSSSelectorTest(unittest.TestCase):\n-\n-    sscls = Selector\n-\n-    def setUp(self):\n-        self.htmlresponse = HtmlResponse('http://example.com', body=HTMLBODY)\n-        self.sel = self.sscls(self.htmlresponse)\n-\n-    def x(self, *a, **kw):\n-        return [v.strip() for v in self.sel.css(*a, **kw).extract() if v.strip()]\n-\n-    def test_selector_simple(self):\n-        for x in self.sel.css('input'):\n-            self.assertTrue(isinstance(x, self.sel.__class__), x)\n-        self.assertEqual(self.sel.css('input').extract(),\n-                         [x.extract() for x in self.sel.css('input')])\n-\n-    def test_text_pseudo_element(self):\n-        self.assertEqual(self.x('#p-b2'), [u'<b id=\"p-b2\">guy</b>'])\n-        self.assertEqual(self.x('#p-b2::text'), [u'guy'])\n-        self.assertEqual(self.x('#p-b2 ::text'), [u'guy'])\n-        self.assertEqual(self.x('#paragraph::text'), [u'lorem ipsum text'])\n-        self.assertEqual(self.x('#paragraph ::text'), [u'lorem ipsum text', u'hi', u'there', u'guy'])\n-        self.assertEqual(self.x('p::text'), [u'lorem ipsum text'])\n-        self.assertEqual(self.x('p ::text'), [u'lorem ipsum text', u'hi', u'there', u'guy'])\n-\n-    def test_attribute_function(self):\n-        self.assertEqual(self.x('#p-b2::attr(id)'), [u'p-b2'])\n-        self.assertEqual(self.x('.cool-footer::attr(class)'), [u'cool-footer'])\n-        self.assertEqual(self.x('.cool-footer ::attr(id)'), [u'foobar-div', u'foobar-span'])\n-        self.assertEqual(self.x('map[name=\"dummymap\"] ::attr(shape)'), [u'circle', u'default'])\n-\n-    def test_nested_selector(self):\n-        self.assertEqual(self.sel.css('p').css('b::text').extract(),\n-                         [u'hi', u'guy'])\n-        self.assertEqual(self.sel.css('div').css('area:last-child').extract(),\n-                         [u'<area shape=\"default\" id=\"area-nohref\">'])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
