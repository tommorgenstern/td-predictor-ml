{"custom_id": "keras#b470a595f7278acf5e7e47521edf25d3c4f479f1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 135 | Lines Deleted: 5 | Files Changed: 5 | Hunks: 8 | Methods Changed: 6 | Complexity Δ (Sum/Max): 19/8 | Churn Δ: 140 | Churn Cumulative: 23667 | Contributors (this commit): 142 | Commits (past 90d): 62 | Contributors (cumulative): 246 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1542,7 +1542,55 @@ def conv2d(x, kernel, strides=(1, 1), padding='valid',\n \n def separable_conv1d(x, depthwise_kernel, pointwise_kernel, strides=1,\n                      padding='valid', data_format=None, dilation_rate=1):\n-    raise NotImplementedError\n+    if data_format is None:\n+        data_format = image_data_format()\n+    if data_format not in {'channels_first', 'channels_last'}:\n+        raise ValueError('Unknown data_format ' + str(data_format))\n+    if isinstance(strides, int):\n+        strides = (strides,)\n+    if isinstance(dilation_rate, int):\n+        dilation_rate = (dilation_rate,)\n+\n+    if data_format == 'channels_last':\n+        spatial_start_dim = 2\n+    else:\n+        spatial_start_dim = 3\n+    x = expand_dims(x, spatial_start_dim)\n+    depthwise_kernel = expand_dims(depthwise_kernel, 1)\n+    pointwise_kernel = expand_dims(pointwise_kernel, 1)\n+    strides = (1,) + strides + (1,)\n+    dilation_rate = (1,) + dilation_rate\n+\n+    x = _preprocess_conv2d_input(x, data_format)\n+    depthwise_kernel = _preprocess_conv2d_kernel(depthwise_kernel, data_format)\n+    depthwise_kernel = C.reshape(C.transpose(depthwise_kernel, (1, 0, 2, 3)),\n+                                 (-1, 1) + depthwise_kernel.shape[2:])\n+    pointwise_kernel = _preprocess_conv2d_kernel(pointwise_kernel, data_format)\n+    padding = _preprocess_border_mode(padding)\n+\n+    if dilation_rate == (1, 1):\n+        x = C.convolution(depthwise_kernel, x,\n+                          strides=strides,\n+                          auto_padding=[False, padding, padding],\n+                          groups=x.shape[0])\n+        x = C.convolution(pointwise_kernel, x,\n+                          strides=(1, 1, 1),\n+                          auto_padding=[False])\n+    else:\n+        if dilation_rate[0] != dilation_rate[1]:\n+            raise ValueError('CNTK Backend: non-square dilation_rate is '\n+                             'not supported.')\n+        if strides != (1, 1):\n+            raise ValueError('Invalid strides for dilated convolution')\n+        x = C.convolution(depthwise_kernel, x,\n+                          strides=strides,\n+                          auto_padding=[False, padding, padding],\n+                          groups=x.shape[0])\n+        x = C.convolution(pointwise_kernel, x,\n+                          strides=(1, 1, 1),\n+                          auto_padding=[False])\n+    x = _postprocess_conv2d_output(x, data_format)\n+    return squeeze(x, spatial_start_dim)\n \n \n def separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1),\n\n@@ -3558,6 +3558,10 @@ def separable_conv1d(x, depthwise_kernel, pointwise_kernel, strides=1,\n         data_format = image_data_format()\n     if data_format not in {'channels_first', 'channels_last'}:\n         raise ValueError('Unknown data_format: ' + str(data_format))\n+    if isinstance(strides, int):\n+        strides = (strides,)\n+    if isinstance(dilation_rate, int):\n+        dilation_rate = (dilation_rate,)\n \n     x, tf_data_format = _preprocess_conv1d_input(x, data_format)\n     padding = _preprocess_padding(padding)\n\n@@ -1989,7 +1989,82 @@ def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n \n def separable_conv1d(x, depthwise_kernel, pointwise_kernel, strides=1,\n                      padding='valid', data_format=None, dilation_rate=1):\n-    raise NotImplementedError\n+    \"\"\"1D convolution with separable filters.\n+\n+    # Arguments\n+        x: input tensor\n+        depthwise_kernel: convolution kernel for the depthwise convolution.\n+        pointwise_kernel: kernel for the 1x1 convolution.\n+        strides: strides integer.\n+        padding: string, `\"same\"` or `\"valid\"`.\n+        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n+        dilation_rate: integer dilation rate.\n+\n+    # Returns\n+        Output tensor.\n+\n+    # Raises\n+        ValueError: if `data_format` is neither `\"channels_last\"` or `\"channels_first\"`.\n+    \"\"\"\n+    if data_format is None:\n+        data_format = image_data_format()\n+    if data_format not in {'channels_first', 'channels_last'}:\n+        raise ValueError('Unknown data_format ', data_format)\n+    if isinstance(strides, int):\n+        strides = (strides,)\n+    if isinstance(dilation_rate, int):\n+        dilation_rate = (dilation_rate,)\n+\n+    if data_format == 'channels_last':\n+        spatial_start_dim = 2\n+    else:\n+        spatial_start_dim = 3\n+    x = expand_dims(x, spatial_start_dim)\n+    depthwise_kernel = expand_dims(depthwise_kernel, 1)\n+    pointwise_kernel = expand_dims(pointwise_kernel, 1)\n+    strides = strides + (1,)\n+    dilation_rate = dilation_rate + (1,)\n+\n+    image_shape = _preprocess_conv2d_image_shape(int_shape(x), data_format)\n+    depthwise_kernel_shape = int_shape(depthwise_kernel)\n+    if depthwise_kernel_shape is None:\n+        depthwise_kernel_shape = depthwise_kernel.eval().shape  # in case of a shared variable\n+    depthwise_kernel_shape = _preprocess_conv2d_filter_shape(depthwise_kernel_shape, data_format)\n+    pointwise_kernel_shape = int_shape(pointwise_kernel)\n+    if pointwise_kernel_shape is None:\n+        pointwise_kernel_shape = pointwise_kernel.eval().shape  # in case of a shared variable\n+    pointwise_kernel_shape = _preprocess_conv2d_filter_shape(pointwise_kernel_shape, data_format)\n+\n+    x = _preprocess_conv2d_input(x, data_format)\n+    depthwise_kernel = _preprocess_conv2d_kernel(depthwise_kernel, data_format)\n+    pointwise_kernel = _preprocess_conv2d_kernel(pointwise_kernel, data_format)\n+    th_padding = _preprocess_padding(padding)\n+\n+    input_depth = depthwise_kernel_shape[1]\n+    output_depth = depthwise_kernel_shape[0]\n+    depthwise_kernel_shape = (input_depth * output_depth, 1) + depthwise_kernel_shape[2:]\n+    depthwise_kernel = depthwise_kernel.dimshuffle((1, 0, 2, 3))\n+    depthwise_kernel = reshape(depthwise_kernel, depthwise_kernel_shape)\n+    depthwise_kernel = depthwise_kernel[:, :, ::-1, ::-1]\n+\n+    conv_out = T.nnet.conv2d(x, depthwise_kernel,\n+                             border_mode=th_padding,\n+                             subsample=strides,\n+                             input_shape=image_shape,\n+                             filter_shape=depthwise_kernel_shape,\n+                             filter_dilation=dilation_rate,\n+                             num_groups=input_depth)\n+    conv_out = T.nnet.conv2d(conv_out, pointwise_kernel,\n+                             border_mode=th_padding,\n+                             subsample=(1, 1),\n+                             input_shape=None,\n+                             filter_shape=pointwise_kernel_shape,\n+                             filter_dilation=dilation_rate)\n+    conv_out = _postprocess_conv2d_output(conv_out, x, padding,\n+                                          pointwise_kernel_shape,\n+                                          strides, data_format)\n+    conv_out = squeeze(conv_out, spatial_start_dim)\n+    return conv_out\n \n \n def separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1),\n\n@@ -1084,16 +1084,18 @@ class TestBackend(object):\n                                        data_format=data_format)\n \n     @pytest.mark.parametrize('op,input_shape,kernel_shape,depth_multiplier,padding,data_format', [\n+        ('separable_conv1d', (2, 8, 2), (3,), 1, 'same', 'channels_last'),\n+        ('separable_conv1d', (1, 8, 2), (3,), 2, 'valid', 'channels_last'),\n         ('separable_conv2d', (2, 3, 4, 5), (3, 3), 1, 'same', 'channels_first'),\n         ('separable_conv2d', (2, 3, 5, 6), (4, 3), 2, 'valid', 'channels_first'),\n         ('separable_conv2d', (1, 6, 5, 3), (3, 4), 1, 'valid', 'channels_last'),\n         ('separable_conv2d', (1, 7, 6, 3), (3, 3), 2, 'same', 'channels_last'),\n     ])\n-    def test_separable_conv2d(self, op, input_shape, kernel_shape, depth_multiplier, padding, data_format):\n+    def test_separable_conv(self, op, input_shape, kernel_shape, depth_multiplier, padding, data_format):\n         input_depth = input_shape[1] if data_format == 'channels_first' else input_shape[-1]\n         _, x = parse_shape_or_val(input_shape)\n         _, depthwise = parse_shape_or_val(kernel_shape + (input_depth, depth_multiplier))\n-        _, pointwise = parse_shape_or_val((1, 1) + (input_depth * depth_multiplier, 7))\n+        _, pointwise = parse_shape_or_val((1,) * len(kernel_shape) + (input_depth * depth_multiplier, 7))\n         y1 = reference_operations.separable_conv(x, depthwise, pointwise, padding, data_format)\n         if K.backend() == 'cntk':\n             y2 = cntk_func_three_tensor(\n\n@@ -228,7 +228,6 @@ def test_conv2d_transpose():\n                                                           batch_input_shape=(None, None, 5, None))])\n \n \n-@pytest.mark.skipif(K.backend() != 'tensorflow', reason='Requires TF backend')\n @keras_test\n def test_separable_conv_1d():\n     num_samples = 2\n@@ -244,6 +243,8 @@ def test_separable_conv_1d():\n                         continue\n                     if dilation_rate != 1 and strides != 1:\n                         continue\n+                    if dilation_rate != 1 and K.backend() == 'cntk':\n+                        continue\n \n                     layer_test(convolutional.SeparableConv1D,\n                                kwargs={'filters': filters,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#84e168b5fa55933e02e767ff7c86fcc0232aecc6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 15 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 12 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 16 | Churn Cumulative: 782 | Contributors (this commit): 13 | Commits (past 90d): 3 | Contributors (cumulative): 16 | DMM Complexity: 0.9230769230769231\n\nDIFF:\n@@ -38,6 +38,8 @@ def _preprocess_numpy_input(x, data_format, mode):\n     # Returns\n         Preprocessed Numpy array.\n     \"\"\"\n+    x = x.astype(K.floatx())\n+\n     if mode == 'tf':\n         x /= 127.5\n         x -= 1.\n\n@@ -8,23 +8,35 @@ from keras.layers import Input, Lambda\n \n \n def test_preprocess_input():\n-    # Test image batch\n+    # Test image batch with float and int image input\n     x = np.random.uniform(0, 255, (2, 10, 10, 3))\n+    xint = x.astype('int32')\n     assert utils.preprocess_input(x).shape == x.shape\n+    assert utils.preprocess_input(xint).shape == xint.shape\n \n     out1 = utils.preprocess_input(x, 'channels_last')\n+    out1int = utils.preprocess_input(xint, 'channels_last')\n     out2 = utils.preprocess_input(np.transpose(x, (0, 3, 1, 2)),\n                                   'channels_first')\n+    out2int = utils.preprocess_input(np.transpose(xint, (0, 3, 1, 2)),\n+                                     'channels_first')\n     assert_allclose(out1, out2.transpose(0, 2, 3, 1))\n+    assert_allclose(out1int, out2int.transpose(0, 2, 3, 1))\n \n     # Test single image\n     x = np.random.uniform(0, 255, (10, 10, 3))\n+    xint = x.astype('int32')\n     assert utils.preprocess_input(x).shape == x.shape\n+    assert utils.preprocess_input(xint).shape == xint.shape\n \n     out1 = utils.preprocess_input(x, 'channels_last')\n+    out1int = utils.preprocess_input(xint, 'channels_last')\n     out2 = utils.preprocess_input(np.transpose(x, (2, 0, 1)),\n                                   'channels_first')\n+    out2int = utils.preprocess_input(np.transpose(xint, (2, 0, 1)),\n+                                     'channels_first')\n     assert_allclose(out1, out2.transpose(1, 2, 0))\n+    assert_allclose(out1int, out2int.transpose(1, 2, 0))\n \n \n def test_preprocess_input_symbolic():\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f6fabd1a370c27aff4e8a82e5a3edce52aaf9c2b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 10 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 14 | Churn Cumulative: 1526 | Contributors (this commit): 9 | Commits (past 90d): 5 | Contributors (cumulative): 9 | DMM Complexity: 0.0\n\nDIFF:\n@@ -15,6 +15,8 @@ pytestmark = pytest.mark.skipif(\n     reason='Runs only when the relevant files have been modified.')\n \n \n+MOBILENET_LIST = [(applications.MobileNet, 1024),\n+                  (applications.MobileNetV2, 1280)]\n DENSENET_LIST = [(applications.DenseNet121, 1024),\n                  (applications.DenseNet169, 1664),\n                  (applications.DenseNet201, 1920)]\n@@ -136,22 +138,14 @@ def test_inceptionresnetv2():\n \n \n def test_mobilenet():\n-    app = applications.MobileNet\n-    last_dim = 1024\n+    app, last_dim = random.choice(MOBILENET_LIST)\n     _test_application_basic(app)\n     _test_application_notop(app, last_dim)\n     _test_application_variable_input_channels(app, last_dim)\n+    if app == applications.MobileNet:\n         _test_app_pooling(app, last_dim)\n \n \n-def test_mobilenetv2():\n-    app = applications.MobileNetV2\n-    last_dim = 1280\n-    _test_application_basic(app)\n-    _test_application_notop(app, last_dim)\n-    _test_application_variable_input_channels(app, last_dim)\n-\n-\n def test_densenet():\n     app, last_dim = random.choice(DENSENET_LIST)\n     _test_application_basic(app)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c8728e4e47569a2eb918600fe75f36a6dae4e623", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 31 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 10 | Methods Changed: 6 | Complexity Δ (Sum/Max): 5/4 | Churn Δ: 35 | Churn Cumulative: 4334 | Contributors (this commit): 57 | Commits (past 90d): 23 | Contributors (cumulative): 69 | DMM Complexity: 0.047619047619047616\n\nDIFF:\n@@ -712,7 +712,7 @@ class ImageDataGenerator(object):\n                               'which overrides setting of '\n                               '`samplewise_center`.')\n \n-    def flow(self, x, y=None, batch_size=32, shuffle=True, seed=None,\n+    def flow(self, x, y=None, batch_size=32, shuffle=True, sample_weight=None, seed=None,\n              save_to_dir=None, save_prefix='', save_format='png', subset=None):\n         \"\"\"Takes numpy data & label arrays, and generates batches of augmented data.\n \n@@ -732,6 +732,7 @@ class ImageDataGenerator(object):\n             y: Labels.\n             batch_size: Int (default: 32).\n             shuffle: Boolean (default: True).\n+            sample_weight: Sample weights.\n             seed: Int (default: None).\n             save_to_dir: None or str (default: None).\n                 This allows you to optionally specify a directory\n@@ -751,12 +752,15 @@ class ImageDataGenerator(object):\n                 (in the case of a single image input) or a list\n                 of numpy arrays (in the case with\n                 additional inputs) and `y` is a numpy array\n-                of corresponding labels.\n+                of corresponding labels. If 'sample_weight' is not None,\n+                the yielded tuples are of the form `(x, y, sample_weight)`.\n+                If `y` is None, only the numpy array `x` is returned.\n         \"\"\"\n         return NumpyArrayIterator(\n             x, y, self,\n             batch_size=batch_size,\n             shuffle=shuffle,\n+            sample_weight=sample_weight,\n             seed=seed,\n             data_format=self.data_format,\n             save_to_dir=save_to_dir,\n@@ -1199,6 +1203,7 @@ class NumpyArrayIterator(Iterator):\n             to use for random transformations and normalization.\n         batch_size: Integer, size of a batch.\n         shuffle: Boolean, whether to shuffle the data between epochs.\n+        sample_weight: Numpy array of sample weights.\n         seed: Random seed for data shuffling.\n         data_format: String, one of `channels_first`, `channels_last`.\n         save_to_dir: Optional directory where to save the pictures\n@@ -1214,8 +1219,8 @@ class NumpyArrayIterator(Iterator):\n     \"\"\"\n \n     def __init__(self, x, y, image_data_generator,\n-                 batch_size=32, shuffle=False, seed=None,\n-                 data_format=None,\n+                 batch_size=32, shuffle=False, sample_weight=None,\n+                 seed=None, data_format=None,\n                  save_to_dir=None, save_prefix='', save_format='png',\n                  subset=None):\n         if (type(x) is tuple) or (type(x) is list):\n@@ -1239,6 +1244,11 @@ class NumpyArrayIterator(Iterator):\n                              'should have the same length. '\n                              'Found: x.shape = %s, y.shape = %s' %\n                              (np.asarray(x).shape, np.asarray(y).shape))\n+        if sample_weight is not None and len(x) != len(sample_weight):\n+            raise ValueError('`x` (images tensor) and `sample_weight` '\n+                             'should have the same length. '\n+                             'Found: x.shape = %s, sample_weight.shape = %s' %\n+                             (np.asarray(x).shape, np.asarray(sample_weight).shape))\n         if subset is not None:\n             if subset not in {'training', 'validation'}:\n                 raise ValueError('Invalid subset name:', subset,\n@@ -1276,6 +1286,10 @@ class NumpyArrayIterator(Iterator):\n             self.y = np.asarray(y)\n         else:\n             self.y = None\n+        if sample_weight is not None:\n+            self.sample_weight = np.asarray(sample_weight)\n+        else:\n+            self.sample_weight = None\n         self.image_data_generator = image_data_generator\n         self.data_format = data_format\n         self.save_to_dir = save_to_dir\n@@ -1311,6 +1325,8 @@ class NumpyArrayIterator(Iterator):\n         if self.y is None:\n             return output[0]\n         output += (self.y[index_array],)\n+        if self.sample_weight is not None:\n+            output += (self.sample_weight[index_array],)\n         return output\n \n     def next(self):\n\n@@ -62,6 +62,17 @@ class TestImage(object):\n                 assert list(y) == [0, 1, 2]\n                 break\n \n+            # Test with sample weights\n+            for x, y, w in generator.flow(images, np.arange(images.shape[0]),\n+                                          shuffle=False,\n+                                          sample_weight=np.arange(images.shape[0]) + 1,\n+                                          save_to_dir=str(tmpdir),\n+                                          batch_size=3):\n+                assert x.shape == images[:3].shape\n+                assert list(y) == [0, 1, 2]\n+                assert list(w) == [1, 2, 3]\n+                break\n+\n             # Test with `shuffle=True`\n             for x, y in generator.flow(images, np.arange(images.shape[0]),\n                                        shuffle=True, save_to_dir=str(tmpdir),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#db57395ebda0cb15a528da6a1f5ebc1c44d6bda7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 45 | Lines Deleted: 43 | Files Changed: 2 | Hunks: 21 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 88 | Churn Cumulative: 15383 | Contributors (this commit): 134 | Commits (past 90d): 27 | Contributors (cumulative): 192 | DMM Complexity: 0.0\n\nDIFF:\n@@ -2679,48 +2679,46 @@ def rnn(step_function, inputs, initial_states,\n     \"\"\"Iterates over the time dimension of a tensor.\n \n     # Arguments\n-        step_function: RNN step function.\n+        step_function:\n             Parameters:\n-                inputs: tensor with shape `(samples, ...)` (no time dimension),\n+                inputs: Tensor with shape (samples, ...) (no time dimension),\n                     representing input for the batch of samples at a certain\n                     time step.\n-                states: list of tensors.\n+                states: List of tensors.\n             Returns:\n-                outputs: tensor with shape `(samples, output_dim)`\n-                    (no time dimension).\n-                new_states: list of tensors, same length and shapes\n-                    as 'states'. The first state in the list must be the\n-                    output tensor at the previous timestep.\n-        inputs: tensor of temporal data of shape `(samples, time, ...)`\n+                outputs: Tensor with shape (samples, ...) (no time dimension),\n+                new_states: Tist of tensors, same length and shapes\n+                    as 'states'.\n+        inputs: Tensor of temporal data of shape (samples, time, ...)\n             (at least 3D).\n-        initial_states: tensor with shape (samples, output_dim)\n-            (no time dimension),\n+        initial_states: Tensor with shape (samples, ...) (no time dimension),\n             containing the initial values for the states used in\n             the step function.\n-        go_backwards: boolean. If True, do the iteration over the time\n+        go_backwards: Boolean. If True, do the iteration over the time\n             dimension in reverse order and return the reversed sequence.\n-        mask: binary tensor with shape `(samples, time, 1)`,\n+        mask: Binary tensor with shape (samples, time),\n             with a zero for every element that is masked.\n-        constants: a list of constant values passed at each step.\n-        unroll: whether to unroll the RNN or to use a symbolic loop (`while_loop` or `scan` depending on backend).\n-        input_length: not relevant in the TensorFlow implementation.\n-            Must be specified if using unrolling with Theano.\n+        constants: A list of constant values passed at each step.\n+        unroll: Whether to unroll the RNN or to use a symbolic loop\n+            (`while_loop` or `scan` depending on backend).\n+        input_length: Static number of timesteps in the input.\n \n     # Returns\n         A tuple, `(last_output, outputs, new_states)`.\n \n-            last_output: the latest output of the rnn, of shape `(samples, ...)`\n-            outputs: tensor with shape `(samples, time, ...)` where each\n+        last_output: The latest output of the rnn, of shape `(samples, ...)`\n+        outputs: Tensor with shape `(samples, time, ...)` where each\n             entry `outputs[s, t]` is the output of the step function\n             at time `t` for sample `s`.\n-            new_states: list of tensors, latest states returned by\n+        new_states: List of tensors, latest states returned by\n             the step function, of shape `(samples, ...)`.\n \n     # Raises\n-        ValueError: if input dimension is less than 3.\n-        ValueError: if `unroll` is `True` but input timestep is not a fixed number.\n-        ValueError: if `mask` is provided (not `None`) but states is not provided\n-            (`len(states)` == 0).\n+        ValueError: If input dimension is less than 3.\n+        ValueError: If `unroll` is `True`\n+            but input timestep is not a fixed number.\n+        ValueError: If `mask` is provided (not `None`)\n+            but states is not provided (`len(states)` == 0).\n     \"\"\"\n     ndim = len(inputs.get_shape())\n     if ndim < 3:\n@@ -2906,7 +2904,8 @@ def rnn(step_function, inputs, initial_states,\n             body=_step,\n             loop_vars=(time, output_ta) + states,\n             parallel_iterations=32,\n-            swap_memory=True)\n+            swap_memory=True,\n+            maximum_iterations=input_length)\n         last_time = final_outputs[0]\n         output_ta = final_outputs[1]\n         new_states = final_outputs[2:]\n\n@@ -1287,37 +1287,40 @@ def rnn(step_function, inputs, initial_states,\n     \"\"\"Iterates over the time dimension of a tensor.\n \n     # Arguments\n-        inputs: tensor of temporal data of shape (samples, time, ...)\n-            (at least 3D).\n         step_function:\n             Parameters:\n-                inputs: tensor with shape (samples, ...) (no time dimension),\n+                inputs: Tensor with shape (samples, ...) (no time dimension),\n                     representing input for the batch of samples at a certain\n                     time step.\n-                states: list of tensors.\n+                states: List of tensors.\n             Returns:\n-                outputs: tensor with shape (samples, ...) (no time dimension),\n-                new_states: list of tensors, same length and shapes\n+                outputs: Tensor with shape (samples, ...) (no time dimension),\n+                new_states: Tist of tensors, same length and shapes\n                     as 'states'.\n-        initial_states: tensor with shape (samples, ...) (no time dimension),\n+        inputs: Tensor of temporal data of shape (samples, time, ...)\n+            (at least 3D).\n+        initial_states: Tensor with shape (samples, ...) (no time dimension),\n             containing the initial values for the states used in\n             the step function.\n-        go_backwards: boolean. If True, do the iteration over the time\n+        go_backwards: Boolean. If True, do the iteration over the time\n             dimension in reverse order and return the reversed sequence.\n-        mask: binary tensor with shape (samples, time),\n+        mask: Binary tensor with shape (samples, time),\n             with a zero for every element that is masked.\n-        constants: a list of constant values passed at each step.\n-        unroll: whether to unroll the RNN or to use a symbolic loop (`while_loop` or `scan` depending on backend).\n-        input_length: must be specified if using `unroll`.\n+        constants: A list of constant values passed at each step.\n+        unroll: Whether to unroll the RNN or to use a symbolic loop\n+            (`while_loop` or `scan` depending on backend).\n+        input_length: Static number of timesteps in the input.\n+            Must be specified if using `unroll`.\n \n     # Returns\n         A tuple (last_output, outputs, new_states).\n-            last_output: the latest output of the rnn, of shape (samples, ...)\n-            outputs: tensor with shape (samples, time, ...) where each\n-                entry outputs[s, t] is the output of the step function\n-                at time t for sample s.\n-            new_states: list of tensors, latest states returned by\n-                the step function, of shape (samples, ...).\n+\n+        last_output: The latest output of the rnn, of shape `(samples, ...)`\n+        outputs: Tensor with shape `(samples, time, ...)` where each\n+            entry `outputs[s, t]` is the output of the step function\n+            at time `t` for sample `s`.\n+        new_states: List of tensors, latest states returned by\n+            the step function, of shape `(samples, ...)`.\n     \"\"\"\n     ndim = inputs.ndim\n     assert ndim >= 3, 'Input should be at least 3D.'\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#52d40f89d20a4ca4dfc2f4f9c1a928a99ca176a9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 9604 | Contributors (this commit): 111 | Commits (past 90d): 16 | Contributors (cumulative): 111 | DMM Complexity: None\n\nDIFF:\n@@ -1221,7 +1221,7 @@ def gather(reference, indices):\n     # Returns\n         A tensor of same type as `reference`.\n     \"\"\"\n-    return tf.gather(reference, indices)\n+    return tf.nn.embedding_lookup(reference, indices)\n \n \n # ELEMENT-WISE OPERATIONS\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#027d37961afff8a7963836ca87ccdbbf65a78811", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 146 | Lines Deleted: 101 | Files Changed: 2 | Hunks: 88 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 247 | Churn Cumulative: 12060 | Contributors (this commit): 59 | Commits (past 90d): 13 | Contributors (cumulative): 66 | DMM Complexity: None\n\nDIFF:\n@@ -49,10 +49,10 @@ class _Conv(Layer):\n             any `dilation_rate` value != 1.\n         padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n         data_format: A string,\n-            one of `channels_last` (default) or `channels_first`.\n+            one of `\"channels_last\"` or `\"channels_first\"`.\n             The ordering of the dimensions in the inputs.\n-            `channels_last` corresponds to inputs with shape\n-            `(batch, ..., channels)` while `channels_first` corresponds to\n+            `\"channels_last\"` corresponds to inputs with shape\n+            `(batch, ..., channels)` while `\"channels_first\"` corresponds to\n             inputs with shape `(batch, channels, ...)`.\n             It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n@@ -267,6 +267,12 @@ class Conv1D(_Conv):\n             does not depend on input[t+1:]. Useful when modeling temporal data\n             where the model should not violate the temporal order.\n             See [WaveNet: A Generative Model for Raw Audio, section 2.1](https://arxiv.org/abs/1609.03499).\n+        data_format: A string,\n+            one of `\"channels_last\"` (default) or `\"channels_first\"`.\n+            The ordering of the dimensions in the inputs.\n+            `\"channels_last\"` corresponds to inputs with shape\n+            `(batch, length, channels)` while `\"channels_first\"`\n+            corresponds to inputs with shape `(batch, channels, length)`.\n         dilation_rate: an integer or tuple/list of a single integer, specifying\n             the dilation rate to use for dilated convolution.\n             Currently, specifying any `dilation_rate` value != 1 is\n@@ -306,6 +312,7 @@ class Conv1D(_Conv):\n                  kernel_size,\n                  strides=1,\n                  padding='valid',\n+                 data_format='channels_last',\n                  dilation_rate=1,\n                  activation=None,\n                  use_bias=True,\n@@ -323,7 +330,7 @@ class Conv1D(_Conv):\n             kernel_size=kernel_size,\n             strides=strides,\n             padding=padding,\n-            data_format='channels_last',\n+            data_format=data_format,\n             dilation_rate=dilation_rate,\n             activation=activation,\n             use_bias=use_bias,\n@@ -340,7 +347,6 @@ class Conv1D(_Conv):\n     def get_config(self):\n         config = super(Conv1D, self).get_config()\n         config.pop('rank')\n-        config.pop('data_format')\n         return config\n \n \n@@ -363,11 +369,12 @@ class Conv2D(_Conv):\n         filters: Integer, the dimensionality of the output space\n             (i.e. the number of output filters in the convolution).\n         kernel_size: An integer or tuple/list of 2 integers, specifying the\n-            width and height of the 2D convolution window.\n+            height and width of the 2D convolution window.\n             Can be a single integer to specify the same value for\n             all spatial dimensions.\n         strides: An integer or tuple/list of 2 integers,\n-            specifying the strides of the convolution along the width and height.\n+            specifying the strides of the convolution\n+            along the height and width.\n             Can be a single integer to specify the same value for\n             all spatial dimensions.\n             Specifying any stride value != 1 is incompatible with specifying\n@@ -377,10 +384,10 @@ class Conv2D(_Conv):\n             `strides` != 1, as described\n             [here](https://github.com/keras-team/keras/pull/9473#issuecomment-372166860)\n         data_format: A string,\n-            one of `channels_last` (default) or `channels_first`.\n+            one of `\"channels_last\"` or `\"channels_first\"`.\n             The ordering of the dimensions in the inputs.\n-            `channels_last` corresponds to inputs with shape\n-            `(batch, height, width, channels)` while `channels_first`\n+            `\"channels_last\"` corresponds to inputs with shape\n+            `(batch, height, width, channels)` while `\"channels_first\"`\n             corresponds to inputs with shape\n             `(batch, channels, height, width)`.\n             It defaults to the `image_data_format` value found in your\n@@ -416,15 +423,19 @@ class Conv2D(_Conv):\n \n     # Input shape\n         4D tensor with shape:\n-        `(samples, channels, rows, cols)` if data_format='channels_first'\n+        `(samples, channels, rows, cols)`\n+        if `data_format` is `\"channels_first\"`\n         or 4D tensor with shape:\n-        `(samples, rows, cols, channels)` if data_format='channels_last'.\n+        `(samples, rows, cols, channels)`\n+        if `data_format` is `\"channels_last\"`.\n \n     # Output shape\n         4D tensor with shape:\n-        `(samples, filters, new_rows, new_cols)` if data_format='channels_first'\n+        `(samples, filters, new_rows, new_cols)`\n+        if `data_format` is `\"channels_first\"`\n         or 4D tensor with shape:\n-        `(samples, new_rows, new_cols, filters)` if data_format='channels_last'.\n+        `(samples, new_rows, new_cols, filters)`\n+        if `data_format` is `\"channels_last\"`.\n         `rows` and `cols` values might have changed due to padding.\n     \"\"\"\n \n@@ -502,11 +513,11 @@ class Conv3D(_Conv):\n             any `dilation_rate` value != 1.\n         padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n         data_format: A string,\n-            one of `channels_last` (default) or `channels_first`.\n+            one of `\"channels_last\"` or `\"channels_first\"`.\n             The ordering of the dimensions in the inputs.\n-            `channels_last` corresponds to inputs with shape\n+            `\"channels_last\"` corresponds to inputs with shape\n             `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n-            while `channels_first` corresponds to inputs with shape\n+            while `\"channels_first\"` corresponds to inputs with shape\n             `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n             It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n@@ -541,15 +552,19 @@ class Conv3D(_Conv):\n \n     # Input shape\n         5D tensor with shape:\n-        `(samples, channels, conv_dim1, conv_dim2, conv_dim3)` if data_format='channels_first'\n+        `(samples, channels, conv_dim1, conv_dim2, conv_dim3)`\n+        if `data_format` is `\"channels_first\"`\n         or 5D tensor with shape:\n-        `(samples, conv_dim1, conv_dim2, conv_dim3, channels)` if data_format='channels_last'.\n+        `(samples, conv_dim1, conv_dim2, conv_dim3, channels)`\n+        if `data_format` is `\"channels_last\"`.\n \n     # Output shape\n         5D tensor with shape:\n-        `(samples, filters, new_conv_dim1, new_conv_dim2, new_conv_dim3)` if data_format='channels_first'\n+        `(samples, filters, new_conv_dim1, new_conv_dim2, new_conv_dim3)`\n+        if `data_format` is `\"channels_first\"`\n         or 5D tensor with shape:\n-        `(samples, new_conv_dim1, new_conv_dim2, new_conv_dim3, filters)` if data_format='channels_last'.\n+        `(samples, new_conv_dim1, new_conv_dim2, new_conv_dim3, filters)`\n+        if `data_format` is `\"channels_last\"`.\n         `new_conv_dim1`, `new_conv_dim2` and `new_conv_dim3` values might have changed due to padding.\n     \"\"\"\n \n@@ -616,21 +631,22 @@ class Conv2DTranspose(Conv2D):\n         filters: Integer, the dimensionality of the output space\n             (i.e. the number of output filters in the convolution).\n         kernel_size: An integer or tuple/list of 2 integers, specifying the\n-            width and height of the 2D convolution window.\n+            height and width of the 2D convolution window.\n             Can be a single integer to specify the same value for\n             all spatial dimensions.\n         strides: An integer or tuple/list of 2 integers,\n-            specifying the strides of the convolution along the width and height.\n+            specifying the strides of the convolution\n+            along the height and width.\n             Can be a single integer to specify the same value for\n             all spatial dimensions.\n             Specifying any stride value != 1 is incompatible with specifying\n             any `dilation_rate` value != 1.\n         padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n         data_format: A string,\n-            one of `channels_last` (default) or `channels_first`.\n+            one of `\"channels_last\"` or `\"channels_first\"`.\n             The ordering of the dimensions in the inputs.\n-            `channels_last` corresponds to inputs with shape\n-            `(batch, height, width, channels)` while `channels_first`\n+            `\"channels_last\"` corresponds to inputs with shape\n+            `(batch, height, width, channels)` while `\"channels_first\"`\n             corresponds to inputs with shape\n             `(batch, channels, height, width)`.\n             It defaults to the `image_data_format` value found in your\n@@ -666,15 +682,19 @@ class Conv2DTranspose(Conv2D):\n \n     # Input shape\n         4D tensor with shape:\n-        `(batch, channels, rows, cols)` if data_format='channels_first'\n+        `(batch, channels, rows, cols)`\n+        if `data_format` is `\"channels_first\"`\n         or 4D tensor with shape:\n-        `(batch, rows, cols, channels)` if data_format='channels_last'.\n+        `(batch, rows, cols, channels)`\n+        if `data_format` is `\"channels_last\"`.\n \n     # Output shape\n         4D tensor with shape:\n-        `(batch, filters, new_rows, new_cols)` if data_format='channels_first'\n+        `(batch, filters, new_rows, new_cols)`\n+        if `data_format` is `\"channels_first\"`\n         or 4D tensor with shape:\n-        `(batch, new_rows, new_cols, filters)` if data_format='channels_last'.\n+        `(batch, new_rows, new_cols, filters)`\n+        if `data_format` is `\"channels_last\"`.\n         `rows` and `cols` values might have changed due to padding.\n \n     # References\n@@ -833,21 +853,22 @@ class Conv3DTranspose(Conv3D):\n         filters: Integer, the dimensionality of the output space\n             (i.e. the number of output filters in the convolution).\n         kernel_size: An integer or tuple/list of 3 integers, specifying the\n-            width and height of the 3D convolution window.\n+            height and width of the 3D convolution window.\n             Can be a single integer to specify the same value for\n             all spatial dimensions.\n         strides: An integer or tuple/list of 3 integers,\n-            specifying the strides of the convolution along the width and height.\n+            specifying the strides of the convolution\n+            along the height and width.\n             Can be a single integer to specify the same value for\n             all spatial dimensions.\n             Specifying any stride value != 1 is incompatible with specifying\n             any `dilation_rate` value != 1.\n         padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n         data_format: A string,\n-            one of `channels_last` (default) or `channels_first`.\n+            one of `\"channels_last\"` or `\"channels_first\"`.\n             The ordering of the dimensions in the inputs.\n-            `channels_last` corresponds to inputs with shape\n-            `(batch, depth, height, width, channels)` while `channels_first`\n+            `\"channels_last\"` corresponds to inputs with shape\n+            `(batch, depth, height, width, channels)` while `\"channels_first\"`\n             corresponds to inputs with shape\n             `(batch, channels, depth, height, width)`.\n             It defaults to the `image_data_format` value found in your\n@@ -883,15 +904,19 @@ class Conv3DTranspose(Conv3D):\n \n     # Input shape\n         5D tensor with shape:\n-        `(batch, channels, depth, rows, cols)` if data_format='channels_first'\n+        `(batch, channels, depth, rows, cols)`\n+        if `data_format` is `\"channels_first\"`\n         or 5D tensor with shape:\n-        `(batch, depth, rows, cols, channels)` if data_format='channels_last'.\n+        `(batch, depth, rows, cols, channels)`\n+        if `data_format` is `\"channels_last\"`.\n \n     # Output shape\n         5D tensor with shape:\n-        `(batch, filters, new_depth, new_rows, new_cols)` if data_format='channels_first'\n+        `(batch, filters, new_depth, new_rows, new_cols)`\n+        if `data_format` is `\"channels_first\"`\n         or 5D tensor with shape:\n-        `(batch, new_depth, new_rows, new_cols, filters)` if data_format='channels_last'.\n+        `(batch, new_depth, new_rows, new_cols, filters)`\n+        if `data_format` is `\"channels_last\"`.\n         `depth` and `rows` and `cols` values might have changed due to padding.\n \n     # References\n@@ -1064,21 +1089,22 @@ class _SeparableConv(_Conv):\n         filters: Integer, the dimensionality of the output space\n             (i.e. the number of output filters in the convolution).\n         kernel_size: An integer or tuple/list of 2 integers, specifying the\n-            width and height of the 2D convolution window.\n+            height and width of the 2D convolution window.\n             Can be a single integer to specify the same value for\n             all spatial dimensions.\n         strides: An integer or tuple/list of 2 integers,\n-            specifying the strides of the convolution along the width and height.\n+            specifying the strides of the convolution\n+            along the height and width.\n             Can be a single integer to specify the same value for\n             all spatial dimensions.\n             Specifying any stride value != 1 is incompatible with specifying\n             any `dilation_rate` value != 1.\n         padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n         data_format: A string,\n-            one of `channels_last` (default) or `channels_first`.\n+            one of `\"channels_last\"` or `\"channels_first\"`.\n             The ordering of the dimensions in the inputs.\n-            `channels_last` corresponds to inputs with shape\n-            `(batch, height, width, channels)` while `channels_first`\n+            `\"channels_last\"` corresponds to inputs with shape\n+            `(batch, height, width, channels)` while `\"channels_first\"`\n             corresponds to inputs with shape\n             `(batch, channels, height, width)`.\n             It defaults to the `image_data_format` value found in your\n@@ -1127,15 +1153,19 @@ class _SeparableConv(_Conv):\n \n     # Input shape\n         4D tensor with shape:\n-        `(batch, channels, rows, cols)` if data_format='channels_first'\n+        `(batch, channels, rows, cols)`\n+        if `data_format` is `\"channels_first\"`\n         or 4D tensor with shape:\n-        `(batch, rows, cols, channels)` if data_format='channels_last'.\n+        `(batch, rows, cols, channels)`\n+        if `data_format` is `\"channels_last\"`.\n \n     # Output shape\n         4D tensor with shape:\n-        `(batch, filters, new_rows, new_cols)` if data_format='channels_first'\n+        `(batch, filters, new_rows, new_cols)`\n+        if `data_format` is `\"channels_first\"`\n         or 4D tensor with shape:\n-        `(batch, new_rows, new_cols, filters)` if data_format='channels_last'.\n+        `(batch, new_rows, new_cols, filters)`\n+        if `data_format` is `\"channels_last\"`.\n         `rows` and `cols` values might have changed due to padding.\n     \"\"\"\n \n@@ -1292,10 +1322,10 @@ class SeparableConv1D(_SeparableConv):\n             any `dilation_rate` value != 1.\n         padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n         data_format: A string,\n-            one of `channels_last` (default) or `channels_first`.\n+            one of `\"channels_last\"` or `\"channels_first\"`.\n             The ordering of the dimensions in the inputs.\n-            `channels_last` corresponds to inputs with shape\n-            `(batch, height, width, channels)` while `channels_first`\n+            `\"channels_last\"` corresponds to inputs with shape\n+            `(batch, height, width, channels)` while `\"channels_first\"`\n             corresponds to inputs with shape\n             `(batch, channels, height, width)`.\n             It defaults to the `image_data_format` value found in your\n@@ -1342,15 +1372,19 @@ class SeparableConv1D(_SeparableConv):\n \n     # Input shape\n         3D tensor with shape:\n-        `(batch, channels, steps)` if data_format='channels_first'\n+        `(batch, channels, steps)`\n+        if `data_format` is `\"channels_first\"`\n         or 3D tensor with shape:\n-        `(batch, steps, channels)` if data_format='channels_last'.\n+        `(batch, steps, channels)`\n+        if `data_format` is `\"channels_last\"`.\n \n     # Output shape\n         3D tensor with shape:\n-        `(batch, filters, new_steps)` if data_format='channels_first'\n+        `(batch, filters, new_steps)`\n+        if `data_format` is `\"channels_first\"`\n         or 3D tensor with shape:\n-        `(batch, new_steps, filters)` if data_format='channels_last'.\n+        `(batch, new_steps, filters)`\n+        if `data_format` is `\"channels_last\"`.\n         `new_steps` values might have changed due to padding or strides.\n     \"\"\"\n \n@@ -1416,21 +1450,22 @@ class SeparableConv2D(_SeparableConv):\n         filters: Integer, the dimensionality of the output space\n             (i.e. the number of output filters in the convolution).\n         kernel_size: An integer or tuple/list of 2 integers, specifying the\n-            width and height of the 2D convolution window.\n+            height and width of the 2D convolution window.\n             Can be a single integer to specify the same value for\n             all spatial dimensions.\n         strides: An integer or tuple/list of 2 integers,\n-            specifying the strides of the convolution along the width and height.\n+            specifying the strides of the convolution\n+            along the height and width.\n             Can be a single integer to specify the same value for\n             all spatial dimensions.\n             Specifying any stride value != 1 is incompatible with specifying\n             any `dilation_rate` value != 1.\n         padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n         data_format: A string,\n-            one of `channels_last` (default) or `channels_first`.\n+            one of `\"channels_last\"` or `\"channels_first\"`.\n             The ordering of the dimensions in the inputs.\n-            `channels_last` corresponds to inputs with shape\n-            `(batch, height, width, channels)` while `channels_first`\n+            `\"channels_last\"` corresponds to inputs with shape\n+            `(batch, height, width, channels)` while `\"channels_first\"`\n             corresponds to inputs with shape\n             `(batch, channels, height, width)`.\n             It defaults to the `image_data_format` value found in your\n@@ -1477,15 +1512,19 @@ class SeparableConv2D(_SeparableConv):\n \n     # Input shape\n         4D tensor with shape:\n-        `(batch, channels, rows, cols)` if data_format='channels_first'\n+        `(batch, channels, rows, cols)`\n+        if `data_format` is `\"channels_first\"`\n         or 4D tensor with shape:\n-        `(batch, rows, cols, channels)` if data_format='channels_last'.\n+        `(batch, rows, cols, channels)`\n+        if `data_format` is `\"channels_last\"`.\n \n     # Output shape\n         4D tensor with shape:\n-        `(batch, filters, new_rows, new_cols)` if data_format='channels_first'\n+        `(batch, filters, new_rows, new_cols)`\n+        if `data_format` is `\"channels_first\"`\n         or 4D tensor with shape:\n-        `(batch, new_rows, new_cols, filters)` if data_format='channels_last'.\n+        `(batch, new_rows, new_cols, filters)`\n+        if `data_format` is `\"channels_last\"`.\n         `rows` and `cols` values might have changed due to padding.\n     \"\"\"\n \n@@ -1545,11 +1584,12 @@ class DepthwiseConv2D(Conv2D):\n \n     # Arguments\n         kernel_size: An integer or tuple/list of 2 integers, specifying the\n-            width and height of the 2D convolution window.\n+            height and width of the 2D convolution window.\n             Can be a single integer to specify the same value for\n             all spatial dimensions.\n         strides: An integer or tuple/list of 2 integers,\n-            specifying the strides of the convolution along the width and height.\n+            specifying the strides of the convolution\n+            along the height and width.\n             Can be a single integer to specify the same value for\n             all spatial dimensions.\n             Specifying any stride value != 1 is incompatible with specifying\n@@ -1560,10 +1600,10 @@ class DepthwiseConv2D(Conv2D):\n             The total number of depthwise convolution output\n             channels will be equal to `filters_in * depth_multiplier`.\n         data_format: A string,\n-            one of `channels_last` (default) or `channels_first`.\n+            one of `\"channels_last\"` or `\"channels_first\"`.\n             The ordering of the dimensions in the inputs.\n-            `channels_last` corresponds to inputs with shape\n-            `(batch, height, width, channels)` while `channels_first`\n+            `\"channels_last\"` corresponds to inputs with shape\n+            `(batch, height, width, channels)` while `\"channels_first\"`\n             corresponds to inputs with shape\n             `(batch, channels, height, width)`.\n             It defaults to the `image_data_format` value found in your\n@@ -1594,15 +1634,19 @@ class DepthwiseConv2D(Conv2D):\n \n     # Input shape\n         4D tensor with shape:\n-        `[batch, channels, rows, cols]` if data_format='channels_first'\n+        `[batch, channels, rows, cols]`\n+        if `data_format` is `\"channels_first\"`\n         or 4D tensor with shape:\n-        `[batch, rows, cols, channels]` if data_format='channels_last'.\n+        `[batch, rows, cols, channels]`\n+        if `data_format` is `\"channels_last\"`.\n \n     # Output shape\n         4D tensor with shape:\n-        `[batch, filters, new_rows, new_cols]` if data_format='channels_first'\n+        `[batch, filters, new_rows, new_cols]`\n+        if `data_format` is `\"channels_first\"`\n         or 4D tensor with shape:\n-        `[batch, new_rows, new_cols, filters]` if data_format='channels_last'.\n+        `[batch, new_rows, new_cols, filters]`\n+        if `data_format` is `\"channels_last\"`.\n         `rows` and `cols` values might have changed due to padding.\n     \"\"\"\n \n@@ -1776,10 +1820,10 @@ class UpSampling2D(Layer):\n         size: int, or tuple of 2 integers.\n             The upsampling factors for rows and columns.\n         data_format: A string,\n-            one of `channels_last` (default) or `channels_first`.\n+            one of `\"channels_last\"` or `\"channels_first\"`.\n             The ordering of the dimensions in the inputs.\n-            `channels_last` corresponds to inputs with shape\n-            `(batch, height, width, channels)` while `channels_first`\n+            `\"channels_last\"` corresponds to inputs with shape\n+            `(batch, height, width, channels)` while `\"channels_first\"`\n             corresponds to inputs with shape\n             `(batch, channels, height, width)`.\n             It defaults to the `image_data_format` value found in your\n@@ -1845,11 +1889,11 @@ class UpSampling3D(Layer):\n         size: int, or tuple of 3 integers.\n             The upsampling factors for dim1, dim2 and dim3.\n         data_format: A string,\n-            one of `channels_last` (default) or `channels_first`.\n+            one of `\"channels_last\"` or `\"channels_first\"`.\n             The ordering of the dimensions in the inputs.\n-            `channels_last` corresponds to inputs with shape\n+            `\"channels_last\"` corresponds to inputs with shape\n             `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n-            while `channels_first` corresponds to inputs with shape\n+            while `\"channels_first\"` corresponds to inputs with shape\n             `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n             It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n@@ -1960,7 +2004,7 @@ class ZeroPadding2D(Layer):\n     # Arguments\n         padding: int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.\n             - If int: the same symmetric padding\n-                is applied to width and height.\n+                is applied to height and width.\n             - If tuple of 2 ints:\n                 interpreted as two different\n                 symmetric padding values for height and width:\n@@ -1969,10 +2013,10 @@ class ZeroPadding2D(Layer):\n                 interpreted as\n                 `((top_pad, bottom_pad), (left_pad, right_pad))`\n         data_format: A string,\n-            one of `channels_last` (default) or `channels_first`.\n+            one of `\"channels_last\"` or `\"channels_first\"`.\n             The ordering of the dimensions in the inputs.\n-            `channels_last` corresponds to inputs with shape\n-            `(batch, height, width, channels)` while `channels_first`\n+            `\"channels_last\"` corresponds to inputs with shape\n+            `(batch, height, width, channels)` while `\"channels_first\"`\n             corresponds to inputs with shape\n             `(batch, channels, height, width)`.\n             It defaults to the `image_data_format` value found in your\n@@ -2067,7 +2111,7 @@ class ZeroPadding3D(Layer):\n     # Arguments\n         padding: int, or tuple of 3 ints, or tuple of 3 tuples of 2 ints.\n             - If int: the same symmetric padding\n-                is applied to width and height.\n+                is applied to height and width.\n             - If tuple of 3 ints:\n                 interpreted as two different\n                 symmetric padding values for height and width:\n@@ -2076,11 +2120,11 @@ class ZeroPadding3D(Layer):\n                 interpreted as\n                 `((left_dim1_pad, right_dim1_pad), (left_dim2_pad, right_dim2_pad), (left_dim3_pad, right_dim3_pad))`\n         data_format: A string,\n-            one of `channels_last` (default) or `channels_first`.\n+            one of `\"channels_last\"` or `\"channels_first\"`.\n             The ordering of the dimensions in the inputs.\n-            `channels_last` corresponds to inputs with shape\n+            `\"channels_last\"` corresponds to inputs with shape\n             `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n-            while `channels_first` corresponds to inputs with shape\n+            while `\"channels_first\"` corresponds to inputs with shape\n             `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n             It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n@@ -2227,12 +2271,12 @@ class Cropping1D(Layer):\n class Cropping2D(Layer):\n     \"\"\"Cropping layer for 2D input (e.g. picture).\n \n-    It crops along spatial dimensions, i.e. width and height.\n+    It crops along spatial dimensions, i.e. height and width.\n \n     # Arguments\n         cropping: int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.\n             - If int: the same symmetric cropping\n-                is applied to width and height.\n+                is applied to height and width.\n             - If tuple of 2 ints:\n                 interpreted as two different\n                 symmetric cropping values for height and width:\n@@ -2241,10 +2285,10 @@ class Cropping2D(Layer):\n                 interpreted as\n                 `((top_crop, bottom_crop), (left_crop, right_crop))`\n         data_format: A string,\n-            one of `channels_last` (default) or `channels_first`.\n+            one of `\"channels_last\"` or `\"channels_first\"`.\n             The ordering of the dimensions in the inputs.\n-            `channels_last` corresponds to inputs with shape\n-            `(batch, height, width, channels)` while `channels_first`\n+            `\"channels_last\"` corresponds to inputs with shape\n+            `(batch, height, width, channels)` while `\"channels_first\"`\n             corresponds to inputs with shape\n             `(batch, channels, height, width)`.\n             It defaults to the `image_data_format` value found in your\n@@ -2382,11 +2426,11 @@ class Cropping3D(Layer):\n                 interpreted as\n                 `((left_dim1_crop, right_dim1_crop), (left_dim2_crop, right_dim2_crop), (left_dim3_crop, right_dim3_crop))`\n         data_format: A string,\n-            one of `channels_last` (default) or `channels_first`.\n+            one of `\"channels_last\"` or `\"channels_first\"`.\n             The ordering of the dimensions in the inputs.\n-            `channels_last` corresponds to inputs with shape\n+            `\"channels_last\"` corresponds to inputs with shape\n             `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n-            while `channels_first` corresponds to inputs with shape\n+            while `\"channels_first\"` corresponds to inputs with shape\n             `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n             It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n\n@@ -100,14 +100,15 @@ def test_conv_1d():\n                kwargs={'filters': filters,\n                        'kernel_size': kernel_size,\n                        'padding': padding,\n-                       'dilation_rate': 2,\n-                       'activation': None},\n+                       'dilation_rate': 2},\n                input_shape=(batch_size, steps, input_dim))\n \n-    convolutional.Conv1D(filters=filters,\n-                         kernel_size=kernel_size,\n-                         padding=padding,\n-                         input_shape=(input_dim,))\n+    # Test channels_last\n+    layer_test(convolutional.Conv1D,\n+               kwargs={'filters': filters,\n+                       'kernel_size': kernel_size,\n+                       'data_format': 'channels_last'},\n+               input_shape=(batch_size, input_dim, steps))\n \n \n @keras_test\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
